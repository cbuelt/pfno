INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=579.22265625MB; mem (CPU total)=8685.37109375MB
INFO:root:############### Starting experiment with config file sswe/sfno_sr_reparam_2_1.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=590.125MB; mem (CPU total)=8693.92578125MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=591.5390625MB; mem (CPU total)=8693.92578125MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2240.44140625MB; mem (CPU total)=10072.7265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2250.09765625MB; mem (CPU total)=10081.9921875MB
INFO:root:[    1] Training loss: 1.24528715, Validation loss: 1.23328151, Gradient norm: 0.12647131
INFO:root:At the start of the epoch: mem (CPU python)=4428.9765625MB; mem (CPU total)=11828.88671875MB
INFO:root:[    2] Training loss: 1.22404954, Validation loss: 1.20884531, Gradient norm: 0.10297869
INFO:root:At the start of the epoch: mem (CPU python)=4450.08203125MB; mem (CPU total)=11881.6796875MB
INFO:root:[    3] Training loss: 1.19542282, Validation loss: 1.18710599, Gradient norm: 0.13428140
INFO:root:At the start of the epoch: mem (CPU python)=4471.328125MB; mem (CPU total)=11669.0625MB
INFO:root:[    4] Training loss: 1.17817316, Validation loss: 1.17482578, Gradient norm: 0.15309032
INFO:root:At the start of the epoch: mem (CPU python)=4492.51171875MB; mem (CPU total)=11993.7890625MB
INFO:root:[    5] Training loss: 1.17146426, Validation loss: 1.16962654, Gradient norm: 0.15118073
INFO:root:At the start of the epoch: mem (CPU python)=4513.69140625MB; mem (CPU total)=12046.49609375MB
INFO:root:[    6] Training loss: 1.16865687, Validation loss: 1.16880804, Gradient norm: 0.15140470
INFO:root:At the start of the epoch: mem (CPU python)=4534.875MB; mem (CPU total)=12101.6328125MB
INFO:root:[    7] Training loss: 1.16474511, Validation loss: 1.16039228, Gradient norm: 0.15964480
INFO:root:At the start of the epoch: mem (CPU python)=4556.0546875MB; mem (CPU total)=12158.19921875MB
INFO:root:[    8] Training loss: 1.16015459, Validation loss: 1.15942445, Gradient norm: 0.17395698
INFO:root:At the start of the epoch: mem (CPU python)=4577.703125MB; mem (CPU total)=11941.83203125MB
INFO:root:[    9] Training loss: 1.15827132, Validation loss: 1.15755202, Gradient norm: 0.15812703
INFO:root:At the start of the epoch: mem (CPU python)=4599.51953125MB; mem (CPU total)=14267.83984375MB
INFO:root:[   10] Training loss: 1.15729209, Validation loss: 1.15719110, Gradient norm: 0.16750638
INFO:root:At the start of the epoch: mem (CPU python)=4622.59765625MB; mem (CPU total)=12624.80078125MB
INFO:root:[   11] Training loss: 1.15619382, Validation loss: 1.15735955, Gradient norm: 0.15858877
INFO:root:At the start of the epoch: mem (CPU python)=4644.09375MB; mem (CPU total)=12641.30859375MB
INFO:root:[   12] Training loss: 1.15550678, Validation loss: 1.15570356, Gradient norm: 0.16350316
INFO:root:At the start of the epoch: mem (CPU python)=4665.26171875MB; mem (CPU total)=12713.83203125MB
INFO:root:[   13] Training loss: 1.15447440, Validation loss: 1.15696713, Gradient norm: 0.16725896
INFO:root:At the start of the epoch: mem (CPU python)=4686.42578125MB; mem (CPU total)=13116.8046875MB
INFO:root:[   14] Training loss: 1.15385950, Validation loss: 1.15583237, Gradient norm: 0.16523705
INFO:root:At the start of the epoch: mem (CPU python)=4707.5859375MB; mem (CPU total)=13250.94921875MB
INFO:root:[   15] Training loss: 1.15355215, Validation loss: 1.15579158, Gradient norm: 0.17439642
INFO:root:At the start of the epoch: mem (CPU python)=4728.75MB; mem (CPU total)=13363.89453125MB
INFO:root:[   16] Training loss: 1.15297244, Validation loss: 1.15799066, Gradient norm: 0.17630296
INFO:root:At the start of the epoch: mem (CPU python)=4749.91796875MB; mem (CPU total)=13423.09765625MB
INFO:root:[   17] Training loss: 1.15275489, Validation loss: 1.16116948, Gradient norm: 0.19011776
INFO:root:At the start of the epoch: mem (CPU python)=4771.078125MB; mem (CPU total)=13489.05859375MB
INFO:root:[   18] Training loss: 1.15467897, Validation loss: 1.18267053, Gradient norm: 0.25825440
INFO:root:At the start of the epoch: mem (CPU python)=4792.2421875MB; mem (CPU total)=13535.59765625MB
INFO:root:[   19] Training loss: 1.15990085, Validation loss: 1.20203924, Gradient norm: 0.37954895
INFO:root:At the start of the epoch: mem (CPU python)=4813.40625MB; mem (CPU total)=13584.75390625MB
INFO:root:[   20] Training loss: 1.16188159, Validation loss: 1.19079677, Gradient norm: 0.49701345
INFO:root:At the start of the epoch: mem (CPU python)=4834.5703125MB; mem (CPU total)=13642.83203125MB
INFO:root:[   21] Training loss: 1.15315826, Validation loss: 1.20480489, Gradient norm: 0.44979439
INFO:root:At the start of the epoch: mem (CPU python)=4855.734375MB; mem (CPU total)=13707.6484375MB
INFO:root:[   22] Training loss: 1.15165226, Validation loss: 1.20968100, Gradient norm: 0.46570213
INFO:root:At the start of the epoch: mem (CPU python)=4876.90234375MB; mem (CPU total)=13788.7734375MB
INFO:root:[   23] Training loss: 1.14966352, Validation loss: 1.21266225, Gradient norm: 0.51643955
INFO:root:At the start of the epoch: mem (CPU python)=4898.06640625MB; mem (CPU total)=13844.6796875MB
INFO:root:[   24] Training loss: 1.14957648, Validation loss: 1.21887680, Gradient norm: 0.55117805
INFO:root:At the start of the epoch: mem (CPU python)=4919.23046875MB; mem (CPU total)=13907.484375MB
INFO:root:[   25] Training loss: 1.14827601, Validation loss: 1.21155934, Gradient norm: 0.58328533
INFO:root:At the start of the epoch: mem (CPU python)=4940.3984375MB; mem (CPU total)=13938.4140625MB
INFO:root:[   26] Training loss: 1.15034257, Validation loss: 1.21228154, Gradient norm: 0.62051179
INFO:root:At the start of the epoch: mem (CPU python)=4961.5625MB; mem (CPU total)=14030.984375MB
INFO:root:[   27] Training loss: 1.14605097, Validation loss: 1.23069846, Gradient norm: 0.62049894
INFO:root:At the start of the epoch: mem (CPU python)=4982.7265625MB; mem (CPU total)=14085.32421875MB
INFO:root:[   28] Training loss: 1.14628759, Validation loss: 1.23061445, Gradient norm: 0.65287047
INFO:root:At the start of the epoch: mem (CPU python)=5003.89453125MB; mem (CPU total)=14145.42578125MB
INFO:root:[   29] Training loss: 1.14620314, Validation loss: 1.21785764, Gradient norm: 0.69089732
INFO:root:At the start of the epoch: mem (CPU python)=5025.05859375MB; mem (CPU total)=14192.6796875MB
INFO:root:[   30] Training loss: 1.14319924, Validation loss: 1.22103054, Gradient norm: 0.65883066
INFO:root:At the start of the epoch: mem (CPU python)=5046.22265625MB; mem (CPU total)=14270.6171875MB
INFO:root:[   31] Training loss: 1.14407381, Validation loss: 1.22857966, Gradient norm: 0.65369643
INFO:root:At the start of the epoch: mem (CPU python)=5067.38671875MB; mem (CPU total)=14268.9296875MB
INFO:root:[   32] Training loss: 1.14359727, Validation loss: 1.22524003, Gradient norm: 0.66478942
INFO:root:At the start of the epoch: mem (CPU python)=5088.55078125MB; mem (CPU total)=14330.1953125MB
INFO:root:[   33] Training loss: 1.14222093, Validation loss: 1.22446022, Gradient norm: 0.58705631
INFO:root:At the start of the epoch: mem (CPU python)=5109.71484375MB; mem (CPU total)=14344.109375MB
INFO:root:[   34] Training loss: 1.14251521, Validation loss: 1.22372939, Gradient norm: 0.62043454
INFO:root:At the start of the epoch: mem (CPU python)=5130.875MB; mem (CPU total)=14378.921875MB
INFO:root:[   35] Training loss: 1.14287848, Validation loss: 1.22398332, Gradient norm: 0.69023154
INFO:root:At the start of the epoch: mem (CPU python)=5152.0390625MB; mem (CPU total)=14406.88671875MB
INFO:root:[   36] Training loss: 1.14242878, Validation loss: 1.22177574, Gradient norm: 0.63359011
INFO:root:At the start of the epoch: mem (CPU python)=5173.203125MB; mem (CPU total)=14455.80078125MB
INFO:root:[   37] Training loss: 1.14153030, Validation loss: 1.22801161, Gradient norm: 0.66098917
INFO:root:At the start of the epoch: mem (CPU python)=5194.37109375MB; mem (CPU total)=14433.16015625MB
INFO:root:[   38] Training loss: 1.14072683, Validation loss: 1.22428189, Gradient norm: 0.61172402
INFO:root:At the start of the epoch: mem (CPU python)=5215.53515625MB; mem (CPU total)=14612.94140625MB
INFO:root:[   39] Training loss: 1.14196110, Validation loss: 1.28254630, Gradient norm: 0.70651536
INFO:root:At the start of the epoch: mem (CPU python)=5236.69921875MB; mem (CPU total)=14631.31640625MB
INFO:root:[   40] Training loss: 1.14309246, Validation loss: 1.23556587, Gradient norm: 0.69693083
INFO:root:At the start of the epoch: mem (CPU python)=5257.86328125MB; mem (CPU total)=14660.58203125MB
INFO:root:[   41] Training loss: 1.14312890, Validation loss: 1.23638106, Gradient norm: 0.70649174
INFO:root:At the start of the epoch: mem (CPU python)=5279.02734375MB; mem (CPU total)=14694.32421875MB
INFO:root:[   42] Training loss: 1.14271436, Validation loss: 1.22428011, Gradient norm: 0.64010922
INFO:root:At the start of the epoch: mem (CPU python)=5300.1875MB; mem (CPU total)=14713.0703125MB
INFO:root:[   43] Training loss: 1.14114766, Validation loss: 1.23362137, Gradient norm: 0.68562630
INFO:root:At the start of the epoch: mem (CPU python)=5321.3515625MB; mem (CPU total)=14740.8984375MB
INFO:root:[   44] Training loss: 1.14185292, Validation loss: 1.22648194, Gradient norm: 0.71615110
INFO:root:At the start of the epoch: mem (CPU python)=5342.51953125MB; mem (CPU total)=14766.8125MB
INFO:root:[   45] Training loss: 1.14092529, Validation loss: 1.22650003, Gradient norm: 0.62640387
INFO:root:At the start of the epoch: mem (CPU python)=5363.68359375MB; mem (CPU total)=14853.609375MB
INFO:root:[   46] Training loss: 1.14147900, Validation loss: 1.25231676, Gradient norm: 0.68324580
INFO:root:At the start of the epoch: mem (CPU python)=5384.84765625MB; mem (CPU total)=14927.88671875MB
INFO:root:[   47] Training loss: 1.14097943, Validation loss: 1.24547235, Gradient norm: 0.68738747
INFO:root:At the start of the epoch: mem (CPU python)=5406.01171875MB; mem (CPU total)=14998.2109375MB
INFO:root:[   48] Training loss: 1.14096528, Validation loss: 1.22827412, Gradient norm: 0.68194134
INFO:root:At the start of the epoch: mem (CPU python)=5427.17578125MB; mem (CPU total)=15060.45703125MB
INFO:root:[   49] Training loss: 1.14104930, Validation loss: 1.23573843, Gradient norm: 0.70422473
INFO:root:At the start of the epoch: mem (CPU python)=5448.34375MB; mem (CPU total)=15160.984375MB
INFO:root:[   50] Training loss: 1.14133366, Validation loss: 1.22930386, Gradient norm: 0.74237274
INFO:root:At the start of the epoch: mem (CPU python)=5469.5078125MB; mem (CPU total)=15210.67578125MB
INFO:root:[   51] Training loss: 1.13953040, Validation loss: 1.23543803, Gradient norm: 0.66244281
INFO:root:At the start of the epoch: mem (CPU python)=5490.6640625MB; mem (CPU total)=15290.2890625MB
INFO:root:[   52] Training loss: 1.14191666, Validation loss: 1.23598857, Gradient norm: 0.77816149
INFO:root:At the start of the epoch: mem (CPU python)=5511.828125MB; mem (CPU total)=15381.6484375MB
INFO:root:[   53] Training loss: 1.14056927, Validation loss: 1.23493847, Gradient norm: 0.71979516
INFO:root:At the start of the epoch: mem (CPU python)=5532.9921875MB; mem (CPU total)=15451.23828125MB
INFO:root:[   54] Training loss: 1.13967816, Validation loss: 1.22756402, Gradient norm: 0.66124872
INFO:root:At the start of the epoch: mem (CPU python)=5554.15625MB; mem (CPU total)=15499.1875MB
INFO:root:[   55] Training loss: 1.14122033, Validation loss: 1.23407743, Gradient norm: 0.71770226
INFO:root:At the start of the epoch: mem (CPU python)=5575.32421875MB; mem (CPU total)=15576.5390625MB
INFO:root:[   56] Training loss: 1.13978317, Validation loss: 1.23151751, Gradient norm: 0.67393322
INFO:root:At the start of the epoch: mem (CPU python)=5596.48828125MB; mem (CPU total)=15650.87890625MB
INFO:root:[   57] Training loss: 1.14042336, Validation loss: 1.23557096, Gradient norm: 0.69486285
INFO:root:At the start of the epoch: mem (CPU python)=5617.65234375MB; mem (CPU total)=15727.44921875MB
INFO:root:[   58] Training loss: 1.14150124, Validation loss: 1.23881948, Gradient norm: 0.77205431
INFO:root:At the start of the epoch: mem (CPU python)=5638.81640625MB; mem (CPU total)=15801.1640625MB
INFO:root:[   59] Training loss: 1.14294555, Validation loss: 1.23676444, Gradient norm: 0.80512253
INFO:root:At the start of the epoch: mem (CPU python)=5659.98046875MB; mem (CPU total)=15872.828125MB
INFO:root:[   60] Training loss: 1.14033037, Validation loss: 1.25052595, Gradient norm: 0.77319219
INFO:root:At the start of the epoch: mem (CPU python)=5681.1484375MB; mem (CPU total)=15942.54296875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 1.14011378, Validation loss: 1.23578285, Gradient norm: 0.73058157
INFO:root:At the start of the epoch: mem (CPU python)=5702.30859375MB; mem (CPU total)=16018.921875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 1.13538574, Validation loss: 1.26302131, Gradient norm: 0.52580572
INFO:root:At the start of the epoch: mem (CPU python)=5723.47265625MB; mem (CPU total)=16091.26953125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   63] Training loss: 1.13296119, Validation loss: 1.23190169, Gradient norm: 0.46134725
INFO:root:At the start of the epoch: mem (CPU python)=5744.63671875MB; mem (CPU total)=16169.60546875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:EP 63: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [0.00015625]
INFO:root:At the start of the epoch: mem (CPU python)=5765.8046875MB; mem (CPU total)=16237.79296875MB
INFO:root:[   65] Training loss: 0.52359413, Validation loss: 0.88863781, Gradient norm: 1.16873240
INFO:root:At the start of the epoch: mem (CPU python)=5786.97265625MB; mem (CPU total)=16365.0234375MB
INFO:root:[   66] Training loss: 0.47901701, Validation loss: 0.89143831, Gradient norm: 1.42228400
INFO:root:At the start of the epoch: mem (CPU python)=5821.01171875MB; mem (CPU total)=16494.4453125MB
INFO:root:[   67] Training loss: 0.47056203, Validation loss: 0.89194912, Gradient norm: 1.58834683
INFO:root:At the start of the epoch: mem (CPU python)=5842.80078125MB; mem (CPU total)=16608.42578125MB
INFO:root:[   68] Training loss: 0.46461959, Validation loss: 0.88716199, Gradient norm: 1.81456796
INFO:root:At the start of the epoch: mem (CPU python)=5863.96484375MB; mem (CPU total)=16729.0546875MB
INFO:root:[   69] Training loss: 0.45953383, Validation loss: 0.88080316, Gradient norm: 1.95307146
INFO:root:At the start of the epoch: mem (CPU python)=5886.50390625MB; mem (CPU total)=16845.3203125MB
INFO:root:[   70] Training loss: 0.45616744, Validation loss: 0.87824534, Gradient norm: 2.08763063
INFO:root:At the start of the epoch: mem (CPU python)=5910.68359375MB; mem (CPU total)=18114.0546875MB
INFO:root:[   71] Training loss: 0.45308626, Validation loss: 0.87382622, Gradient norm: 2.23258205
INFO:root:At the start of the epoch: mem (CPU python)=5940.8828125MB; mem (CPU total)=16970.640625MB
INFO:root:[   72] Training loss: 0.45074764, Validation loss: 0.87168170, Gradient norm: 2.44108294
INFO:root:At the start of the epoch: mem (CPU python)=5962.06640625MB; mem (CPU total)=17174.140625MB
INFO:root:[   73] Training loss: 0.44709653, Validation loss: 0.86914474, Gradient norm: 2.57945075
INFO:root:At the start of the epoch: mem (CPU python)=5983.23828125MB; mem (CPU total)=17327.59375MB
INFO:root:[   74] Training loss: 0.44579500, Validation loss: 0.86643476, Gradient norm: 2.74175435
INFO:root:At the start of the epoch: mem (CPU python)=6004.40625MB; mem (CPU total)=17464.2578125MB
INFO:root:[   75] Training loss: 0.44400340, Validation loss: 0.86580255, Gradient norm: 2.94985367
INFO:root:At the start of the epoch: mem (CPU python)=6025.58984375MB; mem (CPU total)=17601.5703125MB
INFO:root:[   76] Training loss: 0.44135875, Validation loss: 0.85899758, Gradient norm: 3.15983952
INFO:root:At the start of the epoch: mem (CPU python)=6046.77734375MB; mem (CPU total)=17708.609375MB
INFO:root:[   77] Training loss: 0.43941741, Validation loss: 0.85961286, Gradient norm: 3.23973587
INFO:root:At the start of the epoch: mem (CPU python)=6067.96484375MB; mem (CPU total)=17803.3515625MB
INFO:root:[   78] Training loss: 0.43798656, Validation loss: 0.85741254, Gradient norm: 3.47108265
INFO:root:At the start of the epoch: mem (CPU python)=6089.14453125MB; mem (CPU total)=17900.16796875MB
INFO:root:[   79] Training loss: 0.43653900, Validation loss: 0.85410483, Gradient norm: 3.72729817
INFO:root:At the start of the epoch: mem (CPU python)=6110.30859375MB; mem (CPU total)=18019.90234375MB
INFO:root:[   80] Training loss: 0.43514454, Validation loss: 0.85294510, Gradient norm: 4.03867440
INFO:root:At the start of the epoch: mem (CPU python)=6131.5390625MB; mem (CPU total)=18128.359375MB
INFO:root:[   81] Training loss: 0.43339314, Validation loss: 0.85273096, Gradient norm: 4.18093908
INFO:root:At the start of the epoch: mem (CPU python)=6152.75MB; mem (CPU total)=18218.7265625MB
INFO:root:[   82] Training loss: 0.43229268, Validation loss: 0.85096265, Gradient norm: 4.40662134
INFO:root:At the start of the epoch: mem (CPU python)=6173.92578125MB; mem (CPU total)=18330.2421875MB
INFO:root:[   83] Training loss: 0.43146186, Validation loss: 0.84953496, Gradient norm: 4.49901409
INFO:root:At the start of the epoch: mem (CPU python)=6195.109375MB; mem (CPU total)=18417.75MB
INFO:root:[   84] Training loss: 0.42998686, Validation loss: 0.85035240, Gradient norm: 4.94238865
INFO:root:At the start of the epoch: mem (CPU python)=6216.26171875MB; mem (CPU total)=18491.51171875MB
INFO:root:[   85] Training loss: 0.42898506, Validation loss: 0.84815140, Gradient norm: 5.25852880
INFO:root:At the start of the epoch: mem (CPU python)=6237.42578125MB; mem (CPU total)=18570.93359375MB
INFO:root:[   86] Training loss: 0.42749752, Validation loss: 0.84577072, Gradient norm: 5.46595881
INFO:root:At the start of the epoch: mem (CPU python)=6258.58984375MB; mem (CPU total)=18663.39453125MB
INFO:root:[   87] Training loss: 0.42665699, Validation loss: 0.84653945, Gradient norm: 5.83551617
INFO:root:At the start of the epoch: mem (CPU python)=6279.75MB; mem (CPU total)=18731.35546875MB
INFO:root:[   88] Training loss: 0.42578824, Validation loss: 0.84507147, Gradient norm: 6.12810972
INFO:root:At the start of the epoch: mem (CPU python)=6300.91796875MB; mem (CPU total)=18827.5MB
INFO:root:[   89] Training loss: 0.42490834, Validation loss: 0.84762560, Gradient norm: 6.45396052
INFO:root:At the start of the epoch: mem (CPU python)=6322.08203125MB; mem (CPU total)=18907.984375MB
INFO:root:[   90] Training loss: 0.42450958, Validation loss: 0.84296492, Gradient norm: 7.22687713
INFO:root:At the start of the epoch: mem (CPU python)=6343.24609375MB; mem (CPU total)=18986.64453125MB
INFO:root:[   91] Training loss: 0.42306590, Validation loss: 0.84294938, Gradient norm: 7.28279169
INFO:root:At the start of the epoch: mem (CPU python)=6364.49609375MB; mem (CPU total)=19062.1015625MB
INFO:root:[   92] Training loss: 0.42301302, Validation loss: 0.84036436, Gradient norm: 7.49885386
INFO:root:At the start of the epoch: mem (CPU python)=6386.046875MB; mem (CPU total)=19151.3203125MB
INFO:root:[   93] Training loss: 0.42125446, Validation loss: 0.84472092, Gradient norm: 8.01631749
INFO:root:At the start of the epoch: mem (CPU python)=6407.76953125MB; mem (CPU total)=19236.59375MB
INFO:root:[   94] Training loss: 0.42098344, Validation loss: 0.84093764, Gradient norm: 8.18939120
INFO:root:At the start of the epoch: mem (CPU python)=6429.6875MB; mem (CPU total)=19301.3671875MB
INFO:root:[   95] Training loss: 0.41997781, Validation loss: 0.84158151, Gradient norm: 8.55823080
INFO:root:At the start of the epoch: mem (CPU python)=6450.8515625MB; mem (CPU total)=19323.1015625MB
INFO:root:[   96] Training loss: 0.41929406, Validation loss: 0.84008298, Gradient norm: 9.08922047
INFO:root:At the start of the epoch: mem (CPU python)=6472.01953125MB; mem (CPU total)=19355.77734375MB
INFO:root:[   97] Training loss: 0.41898898, Validation loss: 0.84163239, Gradient norm: 9.59801027
INFO:root:At the start of the epoch: mem (CPU python)=6493.18359375MB; mem (CPU total)=19381.421875MB
INFO:root:[   98] Training loss: 0.41798685, Validation loss: 0.83911541, Gradient norm: 10.14524047
INFO:root:At the start of the epoch: mem (CPU python)=6514.34375MB; mem (CPU total)=19407.2890625MB
INFO:root:[   99] Training loss: 0.41743594, Validation loss: 0.83479864, Gradient norm: 10.61948928
INFO:root:At the start of the epoch: mem (CPU python)=6535.51171875MB; mem (CPU total)=19429.76953125MB
INFO:root:[  100] Training loss: 0.41667066, Validation loss: 0.83761918, Gradient norm: 11.52665591
INFO:root:At the start of the epoch: mem (CPU python)=6556.67578125MB; mem (CPU total)=19452.98828125MB
INFO:root:[  101] Training loss: 0.41647176, Validation loss: 0.83667732, Gradient norm: 11.79092309
INFO:root:At the start of the epoch: mem (CPU python)=6577.8359375MB; mem (CPU total)=19473.52734375MB
INFO:root:[  102] Training loss: 0.41596658, Validation loss: 0.83982958, Gradient norm: 12.48763567
INFO:root:At the start of the epoch: mem (CPU python)=6599.0MB; mem (CPU total)=19565.078125MB
INFO:root:[  103] Training loss: 0.41500947, Validation loss: 0.83421575, Gradient norm: 12.81937399
INFO:root:At the start of the epoch: mem (CPU python)=6620.16796875MB; mem (CPU total)=19670.98828125MB
INFO:root:[  104] Training loss: 0.41482289, Validation loss: 0.83317883, Gradient norm: 13.60429184
INFO:root:At the start of the epoch: mem (CPU python)=6641.328125MB; mem (CPU total)=19771.38671875MB
INFO:root:[  105] Training loss: 0.41447374, Validation loss: 0.83409446, Gradient norm: 14.32215495
INFO:root:At the start of the epoch: mem (CPU python)=6662.4921875MB; mem (CPU total)=19887.66015625MB
INFO:root:[  106] Training loss: 0.41345411, Validation loss: 0.83415544, Gradient norm: 13.91897388
INFO:root:At the start of the epoch: mem (CPU python)=6683.66015625MB; mem (CPU total)=19990.453125MB
INFO:root:[  107] Training loss: 0.41300563, Validation loss: 0.83275416, Gradient norm: 15.15739047
INFO:root:At the start of the epoch: mem (CPU python)=6704.82421875MB; mem (CPU total)=20095.0078125MB
INFO:root:[  108] Training loss: 0.41277407, Validation loss: 0.83573957, Gradient norm: 15.70210290
INFO:root:At the start of the epoch: mem (CPU python)=6725.984375MB; mem (CPU total)=20194.59375MB
INFO:root:[  109] Training loss: 0.41217935, Validation loss: 0.83289799, Gradient norm: 16.23881540
INFO:root:At the start of the epoch: mem (CPU python)=6747.1484375MB; mem (CPU total)=20293.75MB
INFO:root:[  110] Training loss: 0.41111153, Validation loss: 0.83253055, Gradient norm: 16.56634999
INFO:root:At the start of the epoch: mem (CPU python)=6768.3125MB; mem (CPU total)=20401.84765625MB
INFO:root:[  111] Training loss: 0.41072356, Validation loss: 0.83014076, Gradient norm: 17.52390453
INFO:root:At the start of the epoch: mem (CPU python)=6789.48046875MB; mem (CPU total)=20505.2265625MB
INFO:root:[  112] Training loss: 0.41006853, Validation loss: 0.83676345, Gradient norm: 17.77354383
INFO:root:At the start of the epoch: mem (CPU python)=6810.640625MB; mem (CPU total)=20610.73828125MB
INFO:root:[  113] Training loss: 0.40929519, Validation loss: 0.83755242, Gradient norm: 18.54084345
INFO:root:At the start of the epoch: mem (CPU python)=6831.8125MB; mem (CPU total)=20712.0546875MB
INFO:root:[  114] Training loss: 0.40988438, Validation loss: 0.82976350, Gradient norm: 19.28360336
INFO:root:At the start of the epoch: mem (CPU python)=6852.9765625MB; mem (CPU total)=20801.48828125MB
INFO:root:[  115] Training loss: 0.40869368, Validation loss: 0.82929149, Gradient norm: 20.34379485
INFO:root:At the start of the epoch: mem (CPU python)=6874.140625MB; mem (CPU total)=20907.5859375MB
INFO:root:[  116] Training loss: 0.40837897, Validation loss: 0.82884450, Gradient norm: 20.00818189
INFO:root:At the start of the epoch: mem (CPU python)=6895.3046875MB; mem (CPU total)=21019.5625MB
INFO:root:[  117] Training loss: 0.40830462, Validation loss: 0.83189689, Gradient norm: 21.47996780
INFO:root:At the start of the epoch: mem (CPU python)=6916.46484375MB; mem (CPU total)=21106.70703125MB
INFO:root:[  118] Training loss: 0.40702726, Validation loss: 0.83382375, Gradient norm: 21.70789702
INFO:root:At the start of the epoch: mem (CPU python)=6937.6328125MB; mem (CPU total)=21203.64453125MB
INFO:root:[  119] Training loss: 0.40668940, Validation loss: 0.82940325, Gradient norm: 21.51174545
INFO:root:At the start of the epoch: mem (CPU python)=6958.79296875MB; mem (CPU total)=21317.0859375MB
INFO:root:[  120] Training loss: 0.40680057, Validation loss: 0.82705038, Gradient norm: 23.21726635
INFO:root:At the start of the epoch: mem (CPU python)=6979.9609375MB; mem (CPU total)=21406.42578125MB
INFO:root:[  121] Training loss: 0.40572024, Validation loss: 0.82781761, Gradient norm: 23.90549458
INFO:root:At the start of the epoch: mem (CPU python)=7001.125MB; mem (CPU total)=21527.8359375MB
INFO:root:[  122] Training loss: 0.40523043, Validation loss: 0.83210995, Gradient norm: 24.30775311
INFO:root:At the start of the epoch: mem (CPU python)=7022.28515625MB; mem (CPU total)=21621.51171875MB
INFO:root:[  123] Training loss: 0.40486263, Validation loss: 0.83270845, Gradient norm: 24.34523695
INFO:root:At the start of the epoch: mem (CPU python)=7043.44921875MB; mem (CPU total)=21714.6875MB
INFO:root:[  124] Training loss: 0.40492530, Validation loss: 0.83340289, Gradient norm: 26.71470471
INFO:root:At the start of the epoch: mem (CPU python)=7064.6171875MB; mem (CPU total)=21817.69921875MB
INFO:root:[  125] Training loss: 0.40410582, Validation loss: 0.82729154, Gradient norm: 26.38331049
INFO:root:At the start of the epoch: mem (CPU python)=7085.78125MB; mem (CPU total)=21905.70703125MB
INFO:root:[  126] Training loss: 0.40394852, Validation loss: 0.82991421, Gradient norm: 26.73413564
INFO:root:At the start of the epoch: mem (CPU python)=7106.9453125MB; mem (CPU total)=22011.26171875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  127] Training loss: 0.40372411, Validation loss: 0.83061257, Gradient norm: 27.21799706
INFO:root:At the start of the epoch: mem (CPU python)=7128.10546875MB; mem (CPU total)=22120.27734375MB
INFO:root:[  128] Training loss: 0.40181463, Validation loss: 0.82660133, Gradient norm: 23.06775901
INFO:root:At the start of the epoch: mem (CPU python)=7149.2734375MB; mem (CPU total)=22224.9765625MB
INFO:root:[  129] Training loss: 0.40150292, Validation loss: 0.82454112, Gradient norm: 23.81330883
INFO:root:At the start of the epoch: mem (CPU python)=7170.4375MB; mem (CPU total)=22324.36328125MB
INFO:root:[  130] Training loss: 0.40147200, Validation loss: 0.82470414, Gradient norm: 23.35936659
INFO:root:At the start of the epoch: mem (CPU python)=7191.6015625MB; mem (CPU total)=22424.53515625MB
INFO:root:[  131] Training loss: 0.40097299, Validation loss: 0.82591477, Gradient norm: 25.34016166
INFO:root:At the start of the epoch: mem (CPU python)=7212.765625MB; mem (CPU total)=22508.30859375MB
INFO:root:[  132] Training loss: 0.40095408, Validation loss: 0.82605359, Gradient norm: 25.88804388
INFO:root:At the start of the epoch: mem (CPU python)=7233.9296875MB; mem (CPU total)=22604.94921875MB
INFO:root:[  133] Training loss: 0.40070557, Validation loss: 0.82738996, Gradient norm: 25.10925976
INFO:root:At the start of the epoch: mem (CPU python)=7255.09765625MB; mem (CPU total)=22697.7421875MB
INFO:root:[  134] Training loss: 0.40003585, Validation loss: 0.82575229, Gradient norm: 26.03491870
INFO:root:At the start of the epoch: mem (CPU python)=7276.2578125MB; mem (CPU total)=22802.5625MB
INFO:root:[  135] Training loss: 0.40058668, Validation loss: 0.82662869, Gradient norm: 26.98552639
INFO:root:At the start of the epoch: mem (CPU python)=7297.42578125MB; mem (CPU total)=22901.60546875MB
INFO:root:[  136] Training loss: 0.40009185, Validation loss: 0.82808169, Gradient norm: 27.91939597
INFO:root:At the start of the epoch: mem (CPU python)=7318.58203125MB; mem (CPU total)=22987.46875MB
INFO:root:[  137] Training loss: 0.39988295, Validation loss: 0.82588514, Gradient norm: 28.83447208
INFO:root:At the start of the epoch: mem (CPU python)=7339.74609375MB; mem (CPU total)=23062.61328125MB
INFO:root:[  138] Training loss: 0.39938435, Validation loss: 0.82639962, Gradient norm: 28.79587950
INFO:root:At the start of the epoch: mem (CPU python)=7360.91015625MB; mem (CPU total)=23151.18359375MB
INFO:root:EP 138: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=7382.07421875MB; mem (CPU total)=23225.953125MB
INFO:root:Training the model took 14052.824s.
INFO:root:Emptying the cuda cache took 0.132s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.65634
INFO:root:EnergyScoreValidation: 0.65407
INFO:root:CRPSValidation: 0.25887
INFO:root:Gaussian NLLValidation: 218271815.24538
INFO:root:CoverageValidation: 0.00218
INFO:root:IntervalWidthValidation: 0.00203
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.51947
INFO:root:EnergyScoreTest: 0.51399
INFO:root:CRPSTest: 0.20161
INFO:root:Gaussian NLLTest: 42816483868.67198
INFO:root:CoverageTest: 2e-05
INFO:root:IntervalWidthTest: 3e-05
INFO:root:After validation: mem (CPU python)=7397.08203125MB; mem (CPU total)=23676.859375MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=7397.14453125MB; mem (CPU total)=23675.5390625MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 88080384
INFO:root:After setting up the model: mem (CPU python)=7397.14453125MB; mem (CPU total)=23684.0MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=7397.14453125MB; mem (CPU total)=23678.44140625MB
INFO:root:[    1] Training loss: 1.24419099, Validation loss: 1.22885447, Gradient norm: 0.12179352
INFO:root:At the start of the epoch: mem (CPU python)=7418.203125MB; mem (CPU total)=23727.421875MB
INFO:root:[    2] Training loss: 1.21923354, Validation loss: 1.20058916, Gradient norm: 0.11173741
INFO:root:At the start of the epoch: mem (CPU python)=7439.890625MB; mem (CPU total)=23778.55078125MB
INFO:root:[    3] Training loss: 1.19219114, Validation loss: 1.18516336, Gradient norm: 0.13041730
INFO:root:At the start of the epoch: mem (CPU python)=7461.53515625MB; mem (CPU total)=23844.37109375MB
INFO:root:[    4] Training loss: 1.18049434, Validation loss: 1.17709067, Gradient norm: 0.13544703
INFO:root:At the start of the epoch: mem (CPU python)=7482.69921875MB; mem (CPU total)=23882.8203125MB
INFO:root:[    5] Training loss: 1.17300135, Validation loss: 1.17225309, Gradient norm: 0.14257650
INFO:root:At the start of the epoch: mem (CPU python)=7503.9375MB; mem (CPU total)=23943.046875MB
INFO:root:[    6] Training loss: 1.16916702, Validation loss: 1.16820027, Gradient norm: 0.14331491
INFO:root:At the start of the epoch: mem (CPU python)=7525.171875MB; mem (CPU total)=24007.01953125MB
INFO:root:[    7] Training loss: 1.16665455, Validation loss: 1.16810505, Gradient norm: 0.14457819
INFO:root:At the start of the epoch: mem (CPU python)=7546.33984375MB; mem (CPU total)=24042.63671875MB
INFO:root:[    8] Training loss: 1.16414759, Validation loss: 1.16226342, Gradient norm: 0.14717209
INFO:root:At the start of the epoch: mem (CPU python)=7567.5078125MB; mem (CPU total)=24097.375MB
INFO:root:[    9] Training loss: 1.15860041, Validation loss: 1.16037254, Gradient norm: 0.15129511
INFO:root:At the start of the epoch: mem (CPU python)=7588.66796875MB; mem (CPU total)=24151.52734375MB
INFO:root:[   10] Training loss: 1.15649824, Validation loss: 1.15780834, Gradient norm: 0.15906796
INFO:root:At the start of the epoch: mem (CPU python)=7609.8359375MB; mem (CPU total)=24203.3984375MB
INFO:root:[   11] Training loss: 1.15450956, Validation loss: 1.15585523, Gradient norm: 0.15379411
INFO:root:At the start of the epoch: mem (CPU python)=7633.48828125MB; mem (CPU total)=24259.375MB
INFO:root:[   12] Training loss: 1.15307699, Validation loss: 1.15740068, Gradient norm: 0.15901222
INFO:root:At the start of the epoch: mem (CPU python)=7654.6484375MB; mem (CPU total)=24314.46484375MB
INFO:root:[   13] Training loss: 1.15115575, Validation loss: 1.15458228, Gradient norm: 0.16742791
INFO:root:At the start of the epoch: mem (CPU python)=7676.2265625MB; mem (CPU total)=24366.20703125MB
INFO:root:[   14] Training loss: 1.14967828, Validation loss: 1.15341364, Gradient norm: 0.17242116
INFO:root:At the start of the epoch: mem (CPU python)=7697.4921875MB; mem (CPU total)=24431.00390625MB
INFO:root:[   15] Training loss: 1.15057723, Validation loss: 1.15629856, Gradient norm: 0.19682048
INFO:root:At the start of the epoch: mem (CPU python)=7718.65625MB; mem (CPU total)=24469.06640625MB
INFO:root:[   16] Training loss: 1.14929689, Validation loss: 1.15644964, Gradient norm: 0.20234983
INFO:root:At the start of the epoch: mem (CPU python)=7739.8203125MB; mem (CPU total)=24531.328125MB
INFO:root:[   17] Training loss: 1.14848714, Validation loss: 1.15858090, Gradient norm: 0.19452554
INFO:root:At the start of the epoch: mem (CPU python)=7760.984375MB; mem (CPU total)=24584.953125MB
INFO:root:[   18] Training loss: 1.15754278, Validation loss: 1.16524709, Gradient norm: 0.27474241
INFO:root:At the start of the epoch: mem (CPU python)=7782.14453125MB; mem (CPU total)=24637.90625MB
INFO:root:[   19] Training loss: 1.14843799, Validation loss: 1.15975229, Gradient norm: 0.25297024
INFO:root:At the start of the epoch: mem (CPU python)=7803.30859375MB; mem (CPU total)=24690.55078125MB
INFO:root:[   20] Training loss: 1.15248763, Validation loss: 1.16955746, Gradient norm: 0.28942926
INFO:root:At the start of the epoch: mem (CPU python)=7824.47265625MB; mem (CPU total)=24742.01953125MB
INFO:root:[   21] Training loss: 1.15182509, Validation loss: 1.17255152, Gradient norm: 0.31394239
INFO:root:At the start of the epoch: mem (CPU python)=7845.63671875MB; mem (CPU total)=24790.21875MB
INFO:root:[   22] Training loss: 1.15218758, Validation loss: 1.17187793, Gradient norm: 0.32384757
INFO:root:At the start of the epoch: mem (CPU python)=7866.80078125MB; mem (CPU total)=24847.12890625MB
INFO:root:[   23] Training loss: 1.15087401, Validation loss: 1.16829426, Gradient norm: 0.32835003
INFO:root:At the start of the epoch: mem (CPU python)=7887.96484375MB; mem (CPU total)=24904.2109375MB
INFO:root:[   24] Training loss: 1.14890379, Validation loss: 1.17073784, Gradient norm: 0.30656872
INFO:root:At the start of the epoch: mem (CPU python)=7909.1328125MB; mem (CPU total)=24964.859375MB
INFO:root:[   25] Training loss: 1.14899860, Validation loss: 1.18736635, Gradient norm: 0.31825994
INFO:root:At the start of the epoch: mem (CPU python)=7930.296875MB; mem (CPU total)=25022.90234375MB
INFO:root:[   26] Training loss: 1.15138058, Validation loss: 1.17355844, Gradient norm: 0.36078593
INFO:root:At the start of the epoch: mem (CPU python)=7951.4609375MB; mem (CPU total)=25066.921875MB
INFO:root:[   27] Training loss: 1.14783760, Validation loss: 1.18189356, Gradient norm: 0.33008044
INFO:root:At the start of the epoch: mem (CPU python)=7972.625MB; mem (CPU total)=25123.80078125MB
INFO:root:[   28] Training loss: 1.14954120, Validation loss: 1.18887612, Gradient norm: 0.37767467
INFO:root:At the start of the epoch: mem (CPU python)=7993.78515625MB; mem (CPU total)=25165.171875MB
INFO:root:[   29] Training loss: 1.15385700, Validation loss: 1.18279190, Gradient norm: 0.50400706
INFO:root:At the start of the epoch: mem (CPU python)=8014.95703125MB; mem (CPU total)=25211.47265625MB
INFO:root:[   30] Training loss: 1.14858039, Validation loss: 1.18151630, Gradient norm: 0.43816052
INFO:root:At the start of the epoch: mem (CPU python)=8036.12109375MB; mem (CPU total)=25256.09765625MB
INFO:root:[   31] Training loss: 1.15022277, Validation loss: 1.18442288, Gradient norm: 0.46641488
INFO:root:At the start of the epoch: mem (CPU python)=8057.28515625MB; mem (CPU total)=25316.77734375MB
INFO:root:[   32] Training loss: 1.14991423, Validation loss: 1.19520679, Gradient norm: 0.50036360
INFO:root:At the start of the epoch: mem (CPU python)=8078.44921875MB; mem (CPU total)=25363.62109375MB
INFO:root:[   33] Training loss: 1.14789005, Validation loss: 1.19506581, Gradient norm: 0.47340017
INFO:root:At the start of the epoch: mem (CPU python)=8099.61328125MB; mem (CPU total)=25431.0078125MB
INFO:root:[   34] Training loss: 1.14710010, Validation loss: 1.19222375, Gradient norm: 0.47159560
INFO:root:At the start of the epoch: mem (CPU python)=8120.77734375MB; mem (CPU total)=25476.453125MB
INFO:root:[   35] Training loss: 1.14682273, Validation loss: 1.20313307, Gradient norm: 0.49461130
INFO:root:At the start of the epoch: mem (CPU python)=8141.94140625MB; mem (CPU total)=25531.47265625MB
INFO:root:[   36] Training loss: 1.14672422, Validation loss: 1.19691436, Gradient norm: 0.47854992
INFO:root:At the start of the epoch: mem (CPU python)=8163.10546875MB; mem (CPU total)=26604.06640625MB
INFO:root:[   37] Training loss: 1.14606751, Validation loss: 1.19727152, Gradient norm: 0.50106170
INFO:root:At the start of the epoch: mem (CPU python)=8184.26953125MB; mem (CPU total)=25201.65234375MB
INFO:root:[   38] Training loss: 1.14542153, Validation loss: 1.19951735, Gradient norm: 0.50737336
INFO:root:At the start of the epoch: mem (CPU python)=8205.4296875MB; mem (CPU total)=25346.5390625MB
INFO:root:[   39] Training loss: 1.14400479, Validation loss: 1.19868943, Gradient norm: 0.47359439
INFO:root:At the start of the epoch: mem (CPU python)=8226.59375MB; mem (CPU total)=25409.91015625MB
INFO:root:[   40] Training loss: 1.14634870, Validation loss: 1.21011331, Gradient norm: 0.53978762
INFO:root:At the start of the epoch: mem (CPU python)=8247.76171875MB; mem (CPU total)=25527.72265625MB
INFO:root:[   41] Training loss: 1.14363798, Validation loss: 1.20617406, Gradient norm: 0.53824876
INFO:root:At the start of the epoch: mem (CPU python)=8268.92578125MB; mem (CPU total)=25589.8828125MB
INFO:root:[   42] Training loss: 1.14253322, Validation loss: 1.20705736, Gradient norm: 0.52983806
INFO:root:At the start of the epoch: mem (CPU python)=8290.08984375MB; mem (CPU total)=25677.296875MB
INFO:root:[   43] Training loss: 1.14465912, Validation loss: 1.20867782, Gradient norm: 0.57177655
INFO:root:At the start of the epoch: mem (CPU python)=8311.25390625MB; mem (CPU total)=25744.5703125MB
INFO:root:[   44] Training loss: 1.14318278, Validation loss: 1.22525117, Gradient norm: 0.54468395
INFO:root:At the start of the epoch: mem (CPU python)=8332.41796875MB; mem (CPU total)=25798.734375MB
INFO:root:[   45] Training loss: 1.14590003, Validation loss: 1.21495856, Gradient norm: 0.62533666
INFO:root:At the start of the epoch: mem (CPU python)=8353.58203125MB; mem (CPU total)=25868.25MB
INFO:root:[   46] Training loss: 1.14443580, Validation loss: 1.21434018, Gradient norm: 0.59702957
INFO:root:At the start of the epoch: mem (CPU python)=8374.75MB; mem (CPU total)=25920.4140625MB
INFO:root:[   47] Training loss: 1.14265517, Validation loss: 1.22313941, Gradient norm: 0.59089372
INFO:root:At the start of the epoch: mem (CPU python)=8395.91015625MB; mem (CPU total)=25998.875MB
INFO:root:[   48] Training loss: 1.14326925, Validation loss: 1.21975856, Gradient norm: 0.59098511
INFO:root:At the start of the epoch: mem (CPU python)=8417.07421875MB; mem (CPU total)=26060.55078125MB
INFO:root:[   49] Training loss: 1.14397044, Validation loss: 1.21909966, Gradient norm: 0.59027978
INFO:root:At the start of the epoch: mem (CPU python)=8438.23828125MB; mem (CPU total)=26112.54296875MB
INFO:root:[   50] Training loss: 1.14390186, Validation loss: 1.22236026, Gradient norm: 0.63288403
INFO:root:At the start of the epoch: mem (CPU python)=8459.40234375MB; mem (CPU total)=26171.71484375MB
INFO:root:[   51] Training loss: 1.14186551, Validation loss: 1.23166509, Gradient norm: 0.59083987
INFO:root:At the start of the epoch: mem (CPU python)=8480.5703125MB; mem (CPU total)=26217.32421875MB
INFO:root:[   52] Training loss: 1.14271519, Validation loss: 1.21997097, Gradient norm: 0.61593682
INFO:root:At the start of the epoch: mem (CPU python)=8501.73046875MB; mem (CPU total)=26278.2421875MB
INFO:root:[   53] Training loss: 1.14320821, Validation loss: 1.23688339, Gradient norm: 0.66857184
INFO:root:At the start of the epoch: mem (CPU python)=8522.89453125MB; mem (CPU total)=26332.24609375MB
INFO:root:[   54] Training loss: 1.14049242, Validation loss: 1.21910180, Gradient norm: 0.59286522
INFO:root:At the start of the epoch: mem (CPU python)=8544.05859375MB; mem (CPU total)=26383.69921875MB
INFO:root:[   55] Training loss: 1.14300734, Validation loss: 1.22686025, Gradient norm: 0.60667709
INFO:root:At the start of the epoch: mem (CPU python)=8565.22265625MB; mem (CPU total)=26438.57421875MB
INFO:root:[   56] Training loss: 1.14058827, Validation loss: 1.22037355, Gradient norm: 0.61096526
INFO:root:At the start of the epoch: mem (CPU python)=8586.390625MB; mem (CPU total)=26492.73046875MB
INFO:root:[   57] Training loss: 1.14013618, Validation loss: 1.22639918, Gradient norm: 0.61396976
INFO:root:At the start of the epoch: mem (CPU python)=8607.55078125MB; mem (CPU total)=26544.51171875MB
INFO:root:[   58] Training loss: 1.14013873, Validation loss: 1.22441730, Gradient norm: 0.57161537
INFO:root:At the start of the epoch: mem (CPU python)=8628.71484375MB; mem (CPU total)=26586.78125MB
INFO:root:[   59] Training loss: 1.14242102, Validation loss: 1.21984601, Gradient norm: 0.66319300
INFO:root:At the start of the epoch: mem (CPU python)=8649.87890625MB; mem (CPU total)=26635.13671875MB
INFO:root:[   60] Training loss: 1.14080390, Validation loss: 1.21857272, Gradient norm: 0.61890128
INFO:root:At the start of the epoch: mem (CPU python)=8671.04296875MB; mem (CPU total)=26683.5078125MB
INFO:root:[   61] Training loss: 1.14139639, Validation loss: 1.22154137, Gradient norm: 0.61616107
INFO:root:At the start of the epoch: mem (CPU python)=8692.20703125MB; mem (CPU total)=26738.01953125MB
INFO:root:[   62] Training loss: 1.13856697, Validation loss: 1.22471476, Gradient norm: 0.55606630
INFO:root:At the start of the epoch: mem (CPU python)=8713.375MB; mem (CPU total)=26794.7421875MB
INFO:root:[   63] Training loss: 1.14027944, Validation loss: 1.22552604, Gradient norm: 0.57610033
INFO:root:At the start of the epoch: mem (CPU python)=8734.5390625MB; mem (CPU total)=26820.76953125MB
INFO:root:[   64] Training loss: 1.14159737, Validation loss: 1.22181407, Gradient norm: 0.65664606
INFO:root:At the start of the epoch: mem (CPU python)=8755.703125MB; mem (CPU total)=26843.23046875MB
INFO:root:[   65] Training loss: 1.13961052, Validation loss: 1.22532539, Gradient norm: 0.55211800
INFO:root:At the start of the epoch: mem (CPU python)=8776.8671875MB; mem (CPU total)=26863.1640625MB
INFO:root:[   66] Training loss: 1.14009919, Validation loss: 1.23654700, Gradient norm: 0.60601824
INFO:root:At the start of the epoch: mem (CPU python)=8798.02734375MB; mem (CPU total)=26888.94921875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   67] Training loss: 1.14040919, Validation loss: 1.22744604, Gradient norm: 0.64920874
INFO:root:At the start of the epoch: mem (CPU python)=8819.19140625MB; mem (CPU total)=26910.40234375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   68] Training loss: 1.13421253, Validation loss: 1.22631141, Gradient norm: 0.47034023
INFO:root:At the start of the epoch: mem (CPU python)=8840.359375MB; mem (CPU total)=26936.921875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   69] Training loss: 1.13175960, Validation loss: 1.21953046, Gradient norm: 0.41082306
INFO:root:At the start of the epoch: mem (CPU python)=8861.51953125MB; mem (CPU total)=26967.640625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   70] Training loss: 1.12951733, Validation loss: 1.21639795, Gradient norm: 0.31637707
INFO:root:At the start of the epoch: mem (CPU python)=8882.68359375MB; mem (CPU total)=26975.51171875MB
INFO:root:[   71] Training loss: 1.12900087, Validation loss: 1.22428816, Gradient norm: 0.29500370
INFO:root:At the start of the epoch: mem (CPU python)=8903.8515625MB; mem (CPU total)=26984.26171875MB
INFO:root:[   72] Training loss: 1.12946362, Validation loss: 1.22348770, Gradient norm: 0.29704146
INFO:root:At the start of the epoch: mem (CPU python)=8925.015625MB; mem (CPU total)=27020.02734375MB
INFO:root:[   73] Training loss: 1.12903886, Validation loss: 1.22426777, Gradient norm: 0.29923468
INFO:root:At the start of the epoch: mem (CPU python)=8946.1796875MB; mem (CPU total)=27052.81640625MB
INFO:root:[   74] Training loss: 1.12906697, Validation loss: 1.22580981, Gradient norm: 0.31573900
INFO:root:At the start of the epoch: mem (CPU python)=8967.34765625MB; mem (CPU total)=27065.984375MB
INFO:root:[   75] Training loss: 1.12911598, Validation loss: 1.22198312, Gradient norm: 0.31626944
INFO:root:At the start of the epoch: mem (CPU python)=8988.5078125MB; mem (CPU total)=27084.234375MB
INFO:root:[   76] Training loss: 1.12866938, Validation loss: 1.22552402, Gradient norm: 0.35259764
INFO:root:At the start of the epoch: mem (CPU python)=9009.671875MB; mem (CPU total)=10248.69140625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   77] Training loss: 1.12833915, Validation loss: 1.23106998, Gradient norm: 0.32371303
INFO:root:At the start of the epoch: mem (CPU python)=9030.8359375MB; mem (CPU total)=13465.30859375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   78] Training loss: 1.12884939, Validation loss: 1.21968983, Gradient norm: 0.29903539
INFO:root:At the start of the epoch: mem (CPU python)=9052.0MB; mem (CPU total)=13529.109375MB
INFO:root:[   79] Training loss: 1.12784890, Validation loss: 1.22388692, Gradient norm: 0.28217422
INFO:root:At the start of the epoch: mem (CPU python)=9073.1640625MB; mem (CPU total)=13637.4609375MB
INFO:root:EP 79: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=9094.33203125MB; mem (CPU total)=13719.421875MB
INFO:root:[   81] Training loss: 0.55266098, Validation loss: 0.71199182, Gradient norm: 0.86151619
INFO:root:At the start of the epoch: mem (CPU python)=9115.49609375MB; mem (CPU total)=13851.5859375MB
INFO:root:[   82] Training loss: 0.48035161, Validation loss: 0.75529118, Gradient norm: 0.73805073
INFO:root:At the start of the epoch: mem (CPU python)=9136.66015625MB; mem (CPU total)=13984.7578125MB
INFO:root:[   83] Training loss: 0.46392397, Validation loss: 0.79192993, Gradient norm: 0.78520563
INFO:root:At the start of the epoch: mem (CPU python)=9160.82421875MB; mem (CPU total)=14132.0MB
INFO:root:[   84] Training loss: 0.45470181, Validation loss: 0.80802881, Gradient norm: 0.83447283
INFO:root:At the start of the epoch: mem (CPU python)=9181.98828125MB; mem (CPU total)=14262.84375MB
INFO:root:[   85] Training loss: 0.44845613, Validation loss: 0.81999730, Gradient norm: 0.88544469
INFO:root:At the start of the epoch: mem (CPU python)=9203.1484375MB; mem (CPU total)=14392.40625MB
INFO:root:[   86] Training loss: 0.44378767, Validation loss: 0.82676016, Gradient norm: 0.94457922
INFO:root:At the start of the epoch: mem (CPU python)=9224.3125MB; mem (CPU total)=14522.8203125MB
INFO:root:[   87] Training loss: 0.44025704, Validation loss: 0.82587427, Gradient norm: 1.01949748
INFO:root:At the start of the epoch: mem (CPU python)=9245.4765625MB; mem (CPU total)=14656.6015625MB
INFO:root:[   88] Training loss: 0.43695613, Validation loss: 0.83235912, Gradient norm: 1.04253868
INFO:root:At the start of the epoch: mem (CPU python)=9266.640625MB; mem (CPU total)=14786.1640625MB
INFO:root:[   89] Training loss: 0.43476915, Validation loss: 0.83087489, Gradient norm: 1.08961532
INFO:root:At the start of the epoch: mem (CPU python)=9287.8046875MB; mem (CPU total)=14939.8515625MB
INFO:root:[   90] Training loss: 0.43275006, Validation loss: 0.83112760, Gradient norm: 1.15390184
INFO:root:At the start of the epoch: mem (CPU python)=9308.96875MB; mem (CPU total)=15069.94140625MB
INFO:root:EP 90: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=9330.13671875MB; mem (CPU total)=15191.85546875MB
INFO:root:Training the model took 7401.906s.
INFO:root:Emptying the cuda cache took 0.138s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.75826
INFO:root:EnergyScoreValidation: 0.56886
INFO:root:CRPSValidation: 0.2801
INFO:root:Gaussian NLLValidation: 67.61182
INFO:root:CoverageValidation: 0.23445
INFO:root:IntervalWidthValidation: 0.37603
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.5875
INFO:root:EnergyScoreTest: 0.43972
INFO:root:CRPSTest: 0.23636
INFO:root:Gaussian NLLTest: 51338140860.41603
INFO:root:CoverageTest: 0.01917
INFO:root:IntervalWidthTest: 0.08997
INFO:root:After validation: mem (CPU python)=9336.79296875MB; mem (CPU total)=16091.140625MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=9336.79296875MB; mem (CPU total)=16096.98828125MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 44040192
INFO:root:After setting up the model: mem (CPU python)=9336.80859375MB; mem (CPU total)=16096.15625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=9336.80859375MB; mem (CPU total)=16100.73046875MB
INFO:root:[    1] Training loss: 1.24661442, Validation loss: 1.23354961, Gradient norm: 0.12547632
INFO:root:At the start of the epoch: mem (CPU python)=9357.8046875MB; mem (CPU total)=16184.9140625MB
INFO:root:[    2] Training loss: 1.22472565, Validation loss: 1.21048587, Gradient norm: 0.09876287
INFO:root:At the start of the epoch: mem (CPU python)=9378.9765625MB; mem (CPU total)=16264.9296875MB
INFO:root:[    3] Training loss: 1.19555968, Validation loss: 1.18281449, Gradient norm: 0.13517831
INFO:root:At the start of the epoch: mem (CPU python)=9400.140625MB; mem (CPU total)=16349.10546875MB
INFO:root:[    4] Training loss: 1.17427238, Validation loss: 1.16729133, Gradient norm: 0.16298364
INFO:root:At the start of the epoch: mem (CPU python)=9421.3046875MB; mem (CPU total)=16426.76171875MB
INFO:root:[    5] Training loss: 1.16487441, Validation loss: 1.16321429, Gradient norm: 0.16082024
INFO:root:At the start of the epoch: mem (CPU python)=9442.46875MB; mem (CPU total)=16507.98828125MB
INFO:root:[    6] Training loss: 1.16146228, Validation loss: 1.16226849, Gradient norm: 0.15768075
INFO:root:At the start of the epoch: mem (CPU python)=9463.6328125MB; mem (CPU total)=16585.03125MB
INFO:root:[    7] Training loss: 1.15951999, Validation loss: 1.16063852, Gradient norm: 0.16254698
INFO:root:At the start of the epoch: mem (CPU python)=9484.79296875MB; mem (CPU total)=16681.1328125MB
INFO:root:[    8] Training loss: 1.15802783, Validation loss: 1.15831406, Gradient norm: 0.15906557
INFO:root:At the start of the epoch: mem (CPU python)=9505.9609375MB; mem (CPU total)=16745.8515625MB
INFO:root:[    9] Training loss: 1.15705722, Validation loss: 1.15708024, Gradient norm: 0.15983073
INFO:root:At the start of the epoch: mem (CPU python)=9527.125MB; mem (CPU total)=16831.02734375MB
INFO:root:[   10] Training loss: 1.15622318, Validation loss: 1.15801533, Gradient norm: 0.16653078
INFO:root:At the start of the epoch: mem (CPU python)=9548.2890625MB; mem (CPU total)=16887.03515625MB
INFO:root:[   11] Training loss: 1.15541220, Validation loss: 1.15644897, Gradient norm: 0.17180742
INFO:root:At the start of the epoch: mem (CPU python)=9569.45703125MB; mem (CPU total)=16953.734375MB
INFO:root:[   12] Training loss: 1.15423191, Validation loss: 1.15603019, Gradient norm: 0.16801230
INFO:root:At the start of the epoch: mem (CPU python)=9590.62109375MB; mem (CPU total)=17009.171875MB
INFO:root:[   13] Training loss: 1.15399243, Validation loss: 1.15460775, Gradient norm: 0.17066334
INFO:root:At the start of the epoch: mem (CPU python)=9611.78515625MB; mem (CPU total)=17065.8203125MB
INFO:root:[   14] Training loss: 1.15327807, Validation loss: 1.15560342, Gradient norm: 0.17291627
INFO:root:At the start of the epoch: mem (CPU python)=9632.94921875MB; mem (CPU total)=17126.62109375MB
INFO:root:[   15] Training loss: 1.15261738, Validation loss: 1.15864296, Gradient norm: 0.18212655
INFO:root:At the start of the epoch: mem (CPU python)=9654.1171875MB; mem (CPU total)=17187.88671875MB
INFO:root:[   16] Training loss: 1.15215683, Validation loss: 1.15688101, Gradient norm: 0.17749390
INFO:root:At the start of the epoch: mem (CPU python)=9675.27734375MB; mem (CPU total)=17242.72265625MB
INFO:root:[   17] Training loss: 1.15205352, Validation loss: 1.15677978, Gradient norm: 0.18779740
INFO:root:At the start of the epoch: mem (CPU python)=9696.4375MB; mem (CPU total)=17307.74609375MB
INFO:root:[   18] Training loss: 1.15184330, Validation loss: 1.15514345, Gradient norm: 0.19595013
INFO:root:At the start of the epoch: mem (CPU python)=9717.6015625MB; mem (CPU total)=17383.796875MB
INFO:root:[   19] Training loss: 1.15318068, Validation loss: 1.15811462, Gradient norm: 0.21439252
INFO:root:At the start of the epoch: mem (CPU python)=9738.765625MB; mem (CPU total)=17442.2890625MB
INFO:root:[   20] Training loss: 1.15109879, Validation loss: 1.16077050, Gradient norm: 0.21649894
INFO:root:At the start of the epoch: mem (CPU python)=9759.93359375MB; mem (CPU total)=17502.0625MB
INFO:root:[   21] Training loss: 1.15309431, Validation loss: 1.15712171, Gradient norm: 0.23446431
INFO:root:At the start of the epoch: mem (CPU python)=9781.09765625MB; mem (CPU total)=17546.234375MB
INFO:root:[   22] Training loss: 1.15062974, Validation loss: 1.16102130, Gradient norm: 0.22077162
INFO:root:At the start of the epoch: mem (CPU python)=9802.26171875MB; mem (CPU total)=17616.6171875MB
INFO:root:[   23] Training loss: 1.15252453, Validation loss: 1.16150112, Gradient norm: 0.24789615
INFO:root:At the start of the epoch: mem (CPU python)=9823.42578125MB; mem (CPU total)=17672.98828125MB
INFO:root:[   24] Training loss: 1.15607411, Validation loss: 1.16055424, Gradient norm: 0.32853158
INFO:root:At the start of the epoch: mem (CPU python)=9844.58984375MB; mem (CPU total)=17736.44921875MB
INFO:root:[   25] Training loss: 1.15553213, Validation loss: 1.16710501, Gradient norm: 0.36601853
INFO:root:At the start of the epoch: mem (CPU python)=9865.75390625MB; mem (CPU total)=17802.37109375MB
INFO:root:[   26] Training loss: 1.15353887, Validation loss: 1.17010253, Gradient norm: 0.33948368
INFO:root:At the start of the epoch: mem (CPU python)=9886.91796875MB; mem (CPU total)=17856.8828125MB
INFO:root:[   27] Training loss: 1.15455614, Validation loss: 1.16472076, Gradient norm: 0.37777895
INFO:root:At the start of the epoch: mem (CPU python)=9908.08203125MB; mem (CPU total)=17924.19140625MB
INFO:root:[   28] Training loss: 1.15724844, Validation loss: 1.17277358, Gradient norm: 0.42176794
INFO:root:At the start of the epoch: mem (CPU python)=9929.24609375MB; mem (CPU total)=17983.3515625MB
INFO:root:[   29] Training loss: 1.15428371, Validation loss: 1.18380454, Gradient norm: 0.47113010
INFO:root:At the start of the epoch: mem (CPU python)=9950.41015625MB; mem (CPU total)=18045.84375MB
INFO:root:[   30] Training loss: 1.15477980, Validation loss: 1.17703609, Gradient norm: 0.51197462
INFO:root:At the start of the epoch: mem (CPU python)=9971.58984375MB; mem (CPU total)=18107.953125MB
INFO:root:[   31] Training loss: 1.15575487, Validation loss: 1.18548540, Gradient norm: 0.57955465
INFO:root:At the start of the epoch: mem (CPU python)=9992.7578125MB; mem (CPU total)=18163.84375MB
INFO:root:[   32] Training loss: 1.15488055, Validation loss: 1.19162729, Gradient norm: 0.59997356
INFO:root:At the start of the epoch: mem (CPU python)=10013.921875MB; mem (CPU total)=18212.5390625MB
INFO:root:[   33] Training loss: 1.15431448, Validation loss: 1.21289101, Gradient norm: 0.58669387
INFO:root:At the start of the epoch: mem (CPU python)=10035.08203125MB; mem (CPU total)=18278.00390625MB
INFO:root:[   34] Training loss: 1.15282372, Validation loss: 1.22630320, Gradient norm: 0.60226265
INFO:root:At the start of the epoch: mem (CPU python)=10056.24609375MB; mem (CPU total)=18339.0234375MB
INFO:root:[   35] Training loss: 1.15184586, Validation loss: 1.21162455, Gradient norm: 0.68296950
INFO:root:At the start of the epoch: mem (CPU python)=10077.41015625MB; mem (CPU total)=18398.55859375MB
INFO:root:[   36] Training loss: 1.15250868, Validation loss: 1.21222640, Gradient norm: 0.72762563
INFO:root:At the start of the epoch: mem (CPU python)=10098.5703125MB; mem (CPU total)=18462.6328125MB
INFO:root:[   37] Training loss: 1.15088505, Validation loss: 1.22495316, Gradient norm: 0.72397029
INFO:root:At the start of the epoch: mem (CPU python)=10119.73828125MB; mem (CPU total)=18520.66015625MB
INFO:root:[   38] Training loss: 1.14909376, Validation loss: 1.22007431, Gradient norm: 0.71111241
INFO:root:At the start of the epoch: mem (CPU python)=10140.90234375MB; mem (CPU total)=18580.9296875MB
INFO:root:[   39] Training loss: 1.15123273, Validation loss: 1.22725806, Gradient norm: 0.75721709
INFO:root:At the start of the epoch: mem (CPU python)=10162.06640625MB; mem (CPU total)=18636.0859375MB
INFO:root:[   40] Training loss: 1.14834062, Validation loss: 1.23791658, Gradient norm: 0.73581288
INFO:root:At the start of the epoch: mem (CPU python)=10183.23046875MB; mem (CPU total)=18693.91015625MB
INFO:root:[   41] Training loss: 1.14800177, Validation loss: 1.22919024, Gradient norm: 0.75186302
INFO:root:At the start of the epoch: mem (CPU python)=10204.39453125MB; mem (CPU total)=18757.55078125MB
INFO:root:[   42] Training loss: 1.14905330, Validation loss: 1.22910676, Gradient norm: 0.76190701
INFO:root:At the start of the epoch: mem (CPU python)=10225.5625MB; mem (CPU total)=18818.26171875MB
INFO:root:[   43] Training loss: 1.15197563, Validation loss: 1.22720777, Gradient norm: 0.79238913
INFO:root:At the start of the epoch: mem (CPU python)=10246.7265625MB; mem (CPU total)=18869.96484375MB
INFO:root:[   44] Training loss: 1.14757816, Validation loss: 1.22099019, Gradient norm: 0.75095097
INFO:root:At the start of the epoch: mem (CPU python)=10267.890625MB; mem (CPU total)=18928.1015625MB
INFO:root:[   45] Training loss: 1.14669685, Validation loss: 1.22353256, Gradient norm: 0.71400639
INFO:root:At the start of the epoch: mem (CPU python)=10289.05078125MB; mem (CPU total)=18984.25390625MB
INFO:root:[   46] Training loss: 1.14771199, Validation loss: 1.22949607, Gradient norm: 0.78080873
INFO:root:At the start of the epoch: mem (CPU python)=10310.21484375MB; mem (CPU total)=19046.85546875MB
INFO:root:[   47] Training loss: 1.14556829, Validation loss: 1.22382193, Gradient norm: 0.67678610
INFO:root:At the start of the epoch: mem (CPU python)=10331.3828125MB; mem (CPU total)=19096.53125MB
INFO:root:[   48] Training loss: 1.14757508, Validation loss: 1.23772699, Gradient norm: 0.78904368
INFO:root:At the start of the epoch: mem (CPU python)=10352.546875MB; mem (CPU total)=19127.828125MB
INFO:root:[   49] Training loss: 1.14572969, Validation loss: 1.24493463, Gradient norm: 0.68438156
INFO:root:At the start of the epoch: mem (CPU python)=10373.7109375MB; mem (CPU total)=19155.734375MB
INFO:root:[   50] Training loss: 1.14740752, Validation loss: 1.23330158, Gradient norm: 0.76020329
INFO:root:At the start of the epoch: mem (CPU python)=10394.87109375MB; mem (CPU total)=19192.79296875MB
INFO:root:[   51] Training loss: 1.14587469, Validation loss: 1.23073739, Gradient norm: 0.71813757
INFO:root:At the start of the epoch: mem (CPU python)=10416.03515625MB; mem (CPU total)=19207.59765625MB
INFO:root:[   52] Training loss: 1.14547018, Validation loss: 1.22288710, Gradient norm: 0.74752222
INFO:root:At the start of the epoch: mem (CPU python)=10437.19921875MB; mem (CPU total)=19231.12109375MB
INFO:root:[   53] Training loss: 1.14519711, Validation loss: 1.22995871, Gradient norm: 0.74442578
INFO:root:At the start of the epoch: mem (CPU python)=10458.3671875MB; mem (CPU total)=19255.7421875MB
INFO:root:[   54] Training loss: 1.14645037, Validation loss: 1.25571045, Gradient norm: 0.72599510
INFO:root:At the start of the epoch: mem (CPU python)=10479.52734375MB; mem (CPU total)=19431.46484375MB
INFO:root:[   55] Training loss: 1.14395735, Validation loss: 1.28474574, Gradient norm: 0.70180875
INFO:root:At the start of the epoch: mem (CPU python)=10500.69140625MB; mem (CPU total)=19453.00390625MB
INFO:root:[   56] Training loss: 1.14674471, Validation loss: 1.23739747, Gradient norm: 0.72258007
INFO:root:At the start of the epoch: mem (CPU python)=10521.85546875MB; mem (CPU total)=19484.29296875MB
INFO:root:[   57] Training loss: 1.14776285, Validation loss: 1.24753645, Gradient norm: 0.76295129
INFO:root:At the start of the epoch: mem (CPU python)=10543.01953125MB; mem (CPU total)=19498.45703125MB
INFO:root:[   58] Training loss: 1.14542096, Validation loss: 1.23150099, Gradient norm: 0.78380712
INFO:root:At the start of the epoch: mem (CPU python)=10564.18359375MB; mem (CPU total)=19520.57421875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   59] Training loss: 1.14362522, Validation loss: 1.22610997, Gradient norm: 0.68194902
INFO:root:At the start of the epoch: mem (CPU python)=10585.3515625MB; mem (CPU total)=19547.5703125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   60] Training loss: 1.13848579, Validation loss: 1.21908162, Gradient norm: 0.47168692
INFO:root:At the start of the epoch: mem (CPU python)=10606.515625MB; mem (CPU total)=19616.3828125MB
INFO:root:[   61] Training loss: 1.13581649, Validation loss: 1.23092601, Gradient norm: 0.40053893
INFO:root:At the start of the epoch: mem (CPU python)=10627.6796875MB; mem (CPU total)=19704.6796875MB
INFO:root:[   62] Training loss: 1.13369402, Validation loss: 1.23888653, Gradient norm: 0.44904808
INFO:root:At the start of the epoch: mem (CPU python)=10648.84375MB; mem (CPU total)=19771.67578125MB
INFO:root:[   63] Training loss: 1.13442949, Validation loss: 1.22549151, Gradient norm: 0.48124701
INFO:root:At the start of the epoch: mem (CPU python)=10670.0078125MB; mem (CPU total)=19860.34765625MB
INFO:root:[   64] Training loss: 1.13444909, Validation loss: 1.24481258, Gradient norm: 0.45921067
INFO:root:At the start of the epoch: mem (CPU python)=10691.171875MB; mem (CPU total)=19937.3828125MB
INFO:root:[   65] Training loss: 1.13519059, Validation loss: 1.22121103, Gradient norm: 0.50487153
INFO:root:At the start of the epoch: mem (CPU python)=10712.3359375MB; mem (CPU total)=20013.703125MB
INFO:root:[   66] Training loss: 1.13465596, Validation loss: 1.22080899, Gradient norm: 0.46376074
INFO:root:At the start of the epoch: mem (CPU python)=10733.5MB; mem (CPU total)=20090.38671875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   67] Training loss: 1.13417886, Validation loss: 1.22075322, Gradient norm: 0.47643858
INFO:root:At the start of the epoch: mem (CPU python)=10754.66015625MB; mem (CPU total)=20166.26953125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   68] Training loss: 1.13254006, Validation loss: 1.21962505, Gradient norm: 0.39797450
INFO:root:At the start of the epoch: mem (CPU python)=10775.82421875MB; mem (CPU total)=20253.56640625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   69] Training loss: 1.13174277, Validation loss: 1.22476871, Gradient norm: 0.35940085
INFO:root:At the start of the epoch: mem (CPU python)=10796.98828125MB; mem (CPU total)=20321.03515625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:EP 69: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=10818.15625MB; mem (CPU total)=20394.90234375MB
INFO:root:[   71] Training loss: 0.55783045, Validation loss: 0.78027378, Gradient norm: 0.97566552
INFO:root:At the start of the epoch: mem (CPU python)=10839.3203125MB; mem (CPU total)=20506.68359375MB
INFO:root:[   72] Training loss: 0.49606877, Validation loss: 0.82876482, Gradient norm: 0.81974659
INFO:root:At the start of the epoch: mem (CPU python)=10860.484375MB; mem (CPU total)=20601.23046875MB
INFO:root:[   73] Training loss: 0.48383042, Validation loss: 0.83210591, Gradient norm: 0.96068947
INFO:root:At the start of the epoch: mem (CPU python)=10881.64453125MB; mem (CPU total)=20723.30078125MB
INFO:root:[   74] Training loss: 0.47691198, Validation loss: 0.83398770, Gradient norm: 1.06985439
INFO:root:At the start of the epoch: mem (CPU python)=10902.80859375MB; mem (CPU total)=20826.3515625MB
INFO:root:[   75] Training loss: 0.47294579, Validation loss: 0.83539569, Gradient norm: 1.16806817
INFO:root:At the start of the epoch: mem (CPU python)=10923.97265625MB; mem (CPU total)=20937.07421875MB
INFO:root:[   76] Training loss: 0.46979999, Validation loss: 0.84138517, Gradient norm: 1.23264370
INFO:root:At the start of the epoch: mem (CPU python)=10945.140625MB; mem (CPU total)=21085.94140625MB
INFO:root:[   77] Training loss: 0.46627578, Validation loss: 0.84296757, Gradient norm: 1.31588811
INFO:root:At the start of the epoch: mem (CPU python)=10966.3046875MB; mem (CPU total)=21183.4296875MB
INFO:root:[   78] Training loss: 0.46524304, Validation loss: 0.84107092, Gradient norm: 1.39266150
INFO:root:At the start of the epoch: mem (CPU python)=10987.46875MB; mem (CPU total)=21301.28125MB
INFO:root:[   79] Training loss: 0.46294016, Validation loss: 0.83778860, Gradient norm: 1.44505071
INFO:root:At the start of the epoch: mem (CPU python)=11008.6328125MB; mem (CPU total)=21410.7265625MB
INFO:root:[   80] Training loss: 0.46140437, Validation loss: 0.84137533, Gradient norm: 1.48513438
INFO:root:At the start of the epoch: mem (CPU python)=11029.796875MB; mem (CPU total)=21524.1796875MB
INFO:root:EP 80: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=11050.96484375MB; mem (CPU total)=21630.5078125MB
INFO:root:Training the model took 6738.32s.
INFO:root:Emptying the cuda cache took 0.137s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.7685
INFO:root:EnergyScoreValidation: 0.63257
INFO:root:CRPSValidation: 0.28451
INFO:root:Gaussian NLLValidation: 1511.49098
INFO:root:CoverageValidation: 0.16934
INFO:root:IntervalWidthValidation: 0.22846
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.59055
INFO:root:EnergyScoreTest: 0.47632
INFO:root:CRPSTest: 0.23243
INFO:root:Gaussian NLLTest: 52965828362.24002
INFO:root:CoverageTest: 0.00976
INFO:root:IntervalWidthTest: 0.04267
INFO:root:After validation: mem (CPU python)=11057.765625MB; mem (CPU total)=22324.83203125MB
