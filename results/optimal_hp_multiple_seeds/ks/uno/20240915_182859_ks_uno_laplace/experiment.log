INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=583.21484375MB; mem (CPU total)=1077.40234375MB
INFO:root:############### Starting experiment with config file ks/uno_laplace.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12462.3828125MB; mem (CPU total)=1078.48828125MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12462.3828125MB; mem (CPU total)=1078.48828125MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=12462.3828125MB; mem (CPU total)=2280.2734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=2289.88671875MB
INFO:root:[    1] Training loss: 1.00579255, Validation loss: 0.99244265, Gradient norm: 0.06183903
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3464.78515625MB
INFO:root:[    2] Training loss: 0.98295375, Validation loss: 0.97706379, Gradient norm: 0.12466935
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3502.8828125MB
INFO:root:[    3] Training loss: 0.97468592, Validation loss: 0.97341547, Gradient norm: 0.17014908
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3541.1875MB
INFO:root:[    4] Training loss: 0.97086179, Validation loss: 0.97043617, Gradient norm: 0.17038083
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3579.33203125MB
INFO:root:[    5] Training loss: 0.96863299, Validation loss: 0.96731230, Gradient norm: 0.18017166
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3616.96484375MB
INFO:root:[    6] Training loss: 0.96681690, Validation loss: 0.96645216, Gradient norm: 0.18035106
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3655.36328125MB
INFO:root:[    7] Training loss: 0.96521655, Validation loss: 0.96475056, Gradient norm: 0.18618557
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3693.7109375MB
INFO:root:[    8] Training loss: 0.96366239, Validation loss: 0.96508908, Gradient norm: 0.18325662
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3731.70703125MB
INFO:root:[    9] Training loss: 0.96247896, Validation loss: 0.96231618, Gradient norm: 0.20096998
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3770.359375MB
INFO:root:[   10] Training loss: 0.96114317, Validation loss: 0.96122200, Gradient norm: 0.22346895
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3808.875MB
INFO:root:[   11] Training loss: 0.95980014, Validation loss: 0.96018233, Gradient norm: 0.22157535
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3847.21484375MB
INFO:root:[   12] Training loss: 0.95868316, Validation loss: 0.95838698, Gradient norm: 0.22567987
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3885.0078125MB
INFO:root:[   13] Training loss: 0.95767597, Validation loss: 0.95766321, Gradient norm: 0.23560769
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3923.1796875MB
INFO:root:[   14] Training loss: 0.95676964, Validation loss: 0.95669977, Gradient norm: 0.25078228
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3961.07421875MB
INFO:root:[   15] Training loss: 0.95591932, Validation loss: 0.95629497, Gradient norm: 0.24408606
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=3999.2734375MB
INFO:root:[   16] Training loss: 0.95532886, Validation loss: 0.95552170, Gradient norm: 0.24944810
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4037.6640625MB
INFO:root:[   17] Training loss: 0.95444988, Validation loss: 0.95432980, Gradient norm: 0.25349713
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4075.66796875MB
INFO:root:[   18] Training loss: 0.95391634, Validation loss: 0.95442694, Gradient norm: 0.26177165
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4114.1015625MB
INFO:root:[   19] Training loss: 0.95334751, Validation loss: 0.95310268, Gradient norm: 0.26107756
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4152.03125MB
INFO:root:[   20] Training loss: 0.95255155, Validation loss: 0.95265538, Gradient norm: 0.26219971
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4190.60546875MB
INFO:root:[   21] Training loss: 0.95207179, Validation loss: 0.95230492, Gradient norm: 0.26270749
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4228.578125MB
INFO:root:[   22] Training loss: 0.95166192, Validation loss: 0.95231112, Gradient norm: 0.27335235
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4266.42578125MB
INFO:root:[   23] Training loss: 0.95111331, Validation loss: 0.95064595, Gradient norm: 0.26861417
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4304.42578125MB
INFO:root:[   24] Training loss: 0.95071827, Validation loss: 0.95079008, Gradient norm: 0.27563863
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4342.40234375MB
INFO:root:[   25] Training loss: 0.95025986, Validation loss: 0.95064400, Gradient norm: 0.27391079
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4380.79296875MB
INFO:root:[   26] Training loss: 0.94991724, Validation loss: 0.95042838, Gradient norm: 0.29943951
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4419.10546875MB
INFO:root:[   27] Training loss: 0.94935984, Validation loss: 0.94964932, Gradient norm: 0.27197362
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4457.78125MB
INFO:root:[   28] Training loss: 0.94900952, Validation loss: 0.94883096, Gradient norm: 0.29947031
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4495.96484375MB
INFO:root:[   29] Training loss: 0.94866964, Validation loss: 0.95030232, Gradient norm: 0.27930596
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4534.484375MB
INFO:root:[   30] Training loss: 0.94831352, Validation loss: 0.94884547, Gradient norm: 0.28497395
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4572.42578125MB
INFO:root:[   31] Training loss: 0.94792801, Validation loss: 0.94828880, Gradient norm: 0.29325940
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4610.68359375MB
INFO:root:[   32] Training loss: 0.94752148, Validation loss: 0.94735896, Gradient norm: 0.29255930
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4648.484375MB
INFO:root:[   33] Training loss: 0.94712375, Validation loss: 0.94746106, Gradient norm: 0.29582663
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4686.64453125MB
INFO:root:[   34] Training loss: 0.94688889, Validation loss: 0.94631521, Gradient norm: 0.31120874
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4724.65234375MB
INFO:root:[   35] Training loss: 0.94657311, Validation loss: 0.94633652, Gradient norm: 0.30094227
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4762.8203125MB
INFO:root:[   36] Training loss: 0.94637897, Validation loss: 0.94613712, Gradient norm: 0.32414563
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4801.5859375MB
INFO:root:[   37] Training loss: 0.94580641, Validation loss: 0.94557537, Gradient norm: 0.29950197
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4839.359375MB
INFO:root:[   38] Training loss: 0.94557042, Validation loss: 0.94546430, Gradient norm: 0.32515761
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4877.8125MB
INFO:root:[   39] Training loss: 0.94517217, Validation loss: 0.94508371, Gradient norm: 0.30643301
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4915.7421875MB
INFO:root:[   40] Training loss: 0.94488622, Validation loss: 0.94582363, Gradient norm: 0.31143358
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4954.1484375MB
INFO:root:[   41] Training loss: 0.94450435, Validation loss: 0.94504624, Gradient norm: 0.33228000
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=4991.765625MB
INFO:root:[   42] Training loss: 0.94408417, Validation loss: 0.94389367, Gradient norm: 0.32107994
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5030.01953125MB
INFO:root:[   43] Training loss: 0.94378892, Validation loss: 0.94388334, Gradient norm: 0.34406298
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5067.15625MB
INFO:root:[   44] Training loss: 0.94333730, Validation loss: 0.94273279, Gradient norm: 0.33230967
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5105.39453125MB
INFO:root:[   45] Training loss: 0.94290830, Validation loss: 0.94348300, Gradient norm: 0.34508125
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5143.8046875MB
INFO:root:[   46] Training loss: 0.94249809, Validation loss: 0.94294624, Gradient norm: 0.33181799
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5181.90234375MB
INFO:root:[   47] Training loss: 0.94214938, Validation loss: 0.94225893, Gradient norm: 0.34458128
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5220.3359375MB
INFO:root:[   48] Training loss: 0.94181754, Validation loss: 0.94206877, Gradient norm: 0.33379165
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5258.33984375MB
INFO:root:[   49] Training loss: 0.94171094, Validation loss: 0.94191388, Gradient norm: 0.35659530
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5298.4375MB
INFO:root:[   50] Training loss: 0.94144204, Validation loss: 0.94096614, Gradient norm: 0.35515570
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5336.53515625MB
INFO:root:[   51] Training loss: 0.94098833, Validation loss: 0.94079061, Gradient norm: 0.32540850
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5374.8671875MB
INFO:root:[   52] Training loss: 0.94084229, Validation loss: 0.94064300, Gradient norm: 0.35325539
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5413.10546875MB
INFO:root:[   53] Training loss: 0.94048545, Validation loss: 0.94016026, Gradient norm: 0.34023170
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5451.53515625MB
INFO:root:[   54] Training loss: 0.94035851, Validation loss: 0.94004450, Gradient norm: 0.34624864
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5489.4921875MB
INFO:root:[   55] Training loss: 0.94037513, Validation loss: 0.94090416, Gradient norm: 0.36637324
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5527.63671875MB
INFO:root:[   56] Training loss: 0.93986799, Validation loss: 0.93986149, Gradient norm: 0.33822623
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5566.05859375MB
INFO:root:[   57] Training loss: 0.93989123, Validation loss: 0.93979488, Gradient norm: 0.36741864
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5604.60546875MB
INFO:root:[   58] Training loss: 0.93966995, Validation loss: 0.93952624, Gradient norm: 0.35826852
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5642.53125MB
INFO:root:[   59] Training loss: 0.93927987, Validation loss: 0.93988208, Gradient norm: 0.32614044
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5680.953125MB
INFO:root:[   60] Training loss: 0.93945759, Validation loss: 0.93924341, Gradient norm: 0.38035343
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5718.44140625MB
INFO:root:[   61] Training loss: 0.93902302, Validation loss: 0.93978994, Gradient norm: 0.33214764
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5756.81640625MB
INFO:root:[   62] Training loss: 0.93892187, Validation loss: 0.93870231, Gradient norm: 0.35677172
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5795.15625MB
INFO:root:[   63] Training loss: 0.93891969, Validation loss: 0.93909848, Gradient norm: 0.35867103
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5833.83203125MB
INFO:root:[   64] Training loss: 0.93864554, Validation loss: 0.93819213, Gradient norm: 0.34281633
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5871.953125MB
INFO:root:[   65] Training loss: 0.93845988, Validation loss: 0.94011268, Gradient norm: 0.34836501
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5910.09765625MB
INFO:root:[   66] Training loss: 0.93834337, Validation loss: 0.93847926, Gradient norm: 0.34608089
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5948.2421875MB
INFO:root:[   67] Training loss: 0.93816887, Validation loss: 0.93752638, Gradient norm: 0.35449115
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=5986.75390625MB
INFO:root:[   68] Training loss: 0.93786174, Validation loss: 0.93864972, Gradient norm: 0.33569885
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6024.8984375MB
INFO:root:[   69] Training loss: 0.93776528, Validation loss: 0.93778361, Gradient norm: 0.33700897
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6063.01171875MB
INFO:root:[   70] Training loss: 0.93774776, Validation loss: 0.93780057, Gradient norm: 0.33797444
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6101.15625MB
INFO:root:[   71] Training loss: 0.93753349, Validation loss: 0.93760033, Gradient norm: 0.35146936
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6139.546875MB
INFO:root:[   72] Training loss: 0.93743848, Validation loss: 0.93813589, Gradient norm: 0.33232781
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6177.6875MB
INFO:root:[   73] Training loss: 0.93738970, Validation loss: 0.93793947, Gradient norm: 0.35096362
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6215.40234375MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   74] Training loss: 0.93716387, Validation loss: 0.93781750, Gradient norm: 0.33924616
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6253.05859375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   75] Training loss: 0.93529727, Validation loss: 0.93530458, Gradient norm: 0.29222886
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6291.7265625MB
INFO:root:[   76] Training loss: 0.93422817, Validation loss: 0.93460425, Gradient norm: 0.25844724
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6329.99609375MB
INFO:root:[   77] Training loss: 0.93416533, Validation loss: 0.93529128, Gradient norm: 0.26184527
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6368.41796875MB
INFO:root:[   78] Training loss: 0.93413189, Validation loss: 0.93538793, Gradient norm: 0.27962183
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6406.5625MB
INFO:root:[   79] Training loss: 0.93411402, Validation loss: 0.93480631, Gradient norm: 0.27716125
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6444.69921875MB
INFO:root:[   80] Training loss: 0.93389911, Validation loss: 0.93465768, Gradient norm: 0.26849349
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6482.453125MB
INFO:root:[   81] Training loss: 0.93394567, Validation loss: 0.93487895, Gradient norm: 0.26349876
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6521.0625MB
INFO:root:[   82] Training loss: 0.93386049, Validation loss: 0.93472830, Gradient norm: 0.28382357
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6558.9296875MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   83] Training loss: 0.93386633, Validation loss: 0.93463399, Gradient norm: 0.27907923
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6596.98046875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[   84] Training loss: 0.93335609, Validation loss: 0.93468096, Gradient norm: 0.26151837
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6635.29296875MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[   85] Training loss: 0.93288376, Validation loss: 0.93461542, Gradient norm: 0.25029776
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6672.4921875MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[   86] Training loss: 0.93274838, Validation loss: 0.93415413, Gradient norm: 0.23730000
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6710.93359375MB
INFO:root:[   87] Training loss: 0.93265395, Validation loss: 0.93401323, Gradient norm: 0.23998526
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6747.97265625MB
INFO:root:[   88] Training loss: 0.93260123, Validation loss: 0.93410187, Gradient norm: 0.23399535
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6786.09375MB
INFO:root:[   89] Training loss: 0.93257953, Validation loss: 0.93385097, Gradient norm: 0.24920542
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6824.53125MB
INFO:root:[   90] Training loss: 0.93259271, Validation loss: 0.93412579, Gradient norm: 0.24459456
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6863.1875MB
INFO:root:[   91] Training loss: 0.93257906, Validation loss: 0.93380483, Gradient norm: 0.24591812
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6901.3671875MB
INFO:root:[   92] Training loss: 0.93255865, Validation loss: 0.93399769, Gradient norm: 0.24535941
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6939.39453125MB
INFO:root:[   93] Training loss: 0.93265624, Validation loss: 0.93408071, Gradient norm: 0.24285209
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=6977.52734375MB
INFO:root:[   94] Training loss: 0.93258092, Validation loss: 0.93384136, Gradient norm: 0.24043660
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7015.4140625MB
INFO:root:[   95] Training loss: 0.93259779, Validation loss: 0.93427934, Gradient norm: 0.24908588
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7053.72265625MB
INFO:root:[   96] Training loss: 0.93260119, Validation loss: 0.93429867, Gradient norm: 0.24370946
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7091.73828125MB
INFO:root:[   97] Training loss: 0.93258511, Validation loss: 0.93384944, Gradient norm: 0.24660723
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7129.90234375MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[   98] Training loss: 0.93253330, Validation loss: 0.93417472, Gradient norm: 0.24286281
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7167.8828125MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[   99] Training loss: 0.93251658, Validation loss: 0.93411727, Gradient norm: 0.24617714
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7205.65234375MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  100] Training loss: 0.93243308, Validation loss: 0.93404646, Gradient norm: 0.23931359
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7243.81640625MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:[  101] Training loss: 0.93249017, Validation loss: 0.93377606, Gradient norm: 0.23990420
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7282.66015625MB
INFO:root:[  102] Training loss: 0.93248259, Validation loss: 0.93419086, Gradient norm: 0.24892946
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7321.1015625MB
INFO:root:[  103] Training loss: 0.93248416, Validation loss: 0.93432850, Gradient norm: 0.23445520
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7359.046875MB
INFO:root:[  104] Training loss: 0.93250119, Validation loss: 0.93395991, Gradient norm: 0.24050257
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7397.44921875MB
INFO:root:[  105] Training loss: 0.93240750, Validation loss: 0.93395312, Gradient norm: 0.24756051
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7435.359375MB
INFO:root:[  106] Training loss: 0.93242780, Validation loss: 0.93431274, Gradient norm: 0.23809582
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7473.9140625MB
INFO:root:[  107] Training loss: 0.93242374, Validation loss: 0.93367782, Gradient norm: 0.24288196
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7512.0MB
INFO:root:[  108] Training loss: 0.93248486, Validation loss: 0.93413058, Gradient norm: 0.23657852
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7550.37890625MB
INFO:root:[  109] Training loss: 0.93251414, Validation loss: 0.93421162, Gradient norm: 0.24444835
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7588.2890625MB
INFO:root:[  110] Training loss: 0.93244095, Validation loss: 0.93418813, Gradient norm: 0.23689143
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7627.34765625MB
INFO:root:[  111] Training loss: 0.93254594, Validation loss: 0.93390597, Gradient norm: 0.23826823
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7664.99609375MB
INFO:root:[  112] Training loss: 0.93244261, Validation loss: 0.93382161, Gradient norm: 0.24121366
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7702.96484375MB
INFO:root:[  113] Training loss: 0.93247622, Validation loss: 0.93405405, Gradient norm: 0.24293872
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7741.109375MB
INFO:root:Learning rate reduced to: [4.8828125e-07]
INFO:root:[  114] Training loss: 0.93245441, Validation loss: 0.93402606, Gradient norm: 0.24068038
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7778.86328125MB
INFO:root:Learning rate reduced to: [2.44140625e-07]
INFO:root:[  115] Training loss: 0.93243065, Validation loss: 0.93391266, Gradient norm: 0.24112190
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7816.76171875MB
INFO:root:Learning rate reduced to: [1.220703125e-07]
INFO:root:[  116] Training loss: 0.93240976, Validation loss: 0.93437332, Gradient norm: 0.23778806
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=7854.90625MB
INFO:root:Learning rate reduced to: [6.103515625e-08]
INFO:root:EP 116: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12462.3828125MB; mem (CPU total)=7893.05078125MB
INFO:root:Training the model took 5432.501s.
INFO:root:Emptying the cuda cache took 0.012s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93868
INFO:root:EnergyScoreTrain: 0.81592
INFO:root:CRPSTrain: 0.65568
INFO:root:Gaussian NLLTrain: 437.63888
INFO:root:CoverageTrain: 0.15068
INFO:root:IntervalWidthTrain: 0.32509
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94261
INFO:root:EnergyScoreValidation: 0.81397
INFO:root:CRPSValidation: 0.65437
INFO:root:Gaussian NLLValidation: 324.82171
INFO:root:CoverageValidation: 0.15794
INFO:root:IntervalWidthValidation: 0.34552
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94178
INFO:root:EnergyScoreTest: 0.81885
INFO:root:CRPSTest: 0.65813
INFO:root:Gaussian NLLTest: 986.88035
INFO:root:CoverageTest: 0.15028
INFO:root:IntervalWidthTest: 0.32613
INFO:root:After validation: mem (CPU python)=12462.3828125MB; mem (CPU total)=8170.234375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12462.3828125MB; mem (CPU total)=8170.4765625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 180355072
INFO:root:After setting up the model: mem (CPU python)=12462.3828125MB; mem (CPU total)=8171.4609375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8171.70703125MB
INFO:root:[    1] Training loss: 1.00681387, Validation loss: 0.99090623, Gradient norm: 0.05185832
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8209.859375MB
INFO:root:[    2] Training loss: 0.98256390, Validation loss: 0.97795012, Gradient norm: 0.12203805
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8248.48046875MB
INFO:root:[    3] Training loss: 0.97466108, Validation loss: 0.97369105, Gradient norm: 0.13234755
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8285.3203125MB
INFO:root:[    4] Training loss: 0.97124978, Validation loss: 0.97031135, Gradient norm: 0.14068068
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8323.703125MB
INFO:root:[    5] Training loss: 0.96916155, Validation loss: 0.97070643, Gradient norm: 0.15947149
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8362.90625MB
INFO:root:[    6] Training loss: 0.96724837, Validation loss: 0.96745915, Gradient norm: 0.14631609
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8401.04296875MB
INFO:root:[    7] Training loss: 0.96535784, Validation loss: 0.96593462, Gradient norm: 0.15326283
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8438.8515625MB
INFO:root:[    8] Training loss: 0.96415955, Validation loss: 0.96463927, Gradient norm: 0.17223798
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8477.21875MB
INFO:root:[    9] Training loss: 0.96263205, Validation loss: 0.96296772, Gradient norm: 0.16435863
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8515.671875MB
INFO:root:[   10] Training loss: 0.96123250, Validation loss: 0.96130291, Gradient norm: 0.17195360
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8554.40234375MB
INFO:root:[   11] Training loss: 0.96027022, Validation loss: 0.95995101, Gradient norm: 0.18112975
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8592.0390625MB
INFO:root:[   12] Training loss: 0.95911188, Validation loss: 0.95859077, Gradient norm: 0.20596964
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8630.21484375MB
INFO:root:[   13] Training loss: 0.95790899, Validation loss: 0.95894823, Gradient norm: 0.21640586
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8668.60546875MB
INFO:root:[   14] Training loss: 0.95691176, Validation loss: 0.95685137, Gradient norm: 0.22174467
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8706.50390625MB
INFO:root:[   15] Training loss: 0.95577715, Validation loss: 0.95566436, Gradient norm: 0.23015852
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8745.59765625MB
INFO:root:[   16] Training loss: 0.95479174, Validation loss: 0.95428305, Gradient norm: 0.25281882
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8783.93359375MB
INFO:root:[   17] Training loss: 0.95399583, Validation loss: 0.95340226, Gradient norm: 0.25498094
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8821.8203125MB
INFO:root:[   18] Training loss: 0.95297105, Validation loss: 0.95340716, Gradient norm: 0.26733160
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8859.58984375MB
INFO:root:[   19] Training loss: 0.95211237, Validation loss: 0.95377358, Gradient norm: 0.26843083
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8897.734375MB
INFO:root:[   20] Training loss: 0.95157404, Validation loss: 0.95138953, Gradient norm: 0.27688243
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8935.94921875MB
INFO:root:[   21] Training loss: 0.95088033, Validation loss: 0.95116530, Gradient norm: 0.26382724
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=8974.35546875MB
INFO:root:[   22] Training loss: 0.95032823, Validation loss: 0.95139284, Gradient norm: 0.27537120
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9012.49609375MB
INFO:root:[   23] Training loss: 0.94974309, Validation loss: 0.95070753, Gradient norm: 0.27514932
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9051.02734375MB
INFO:root:[   24] Training loss: 0.94910943, Validation loss: 0.95027475, Gradient norm: 0.26853248
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9088.09375MB
INFO:root:[   25] Training loss: 0.94881259, Validation loss: 0.94939949, Gradient norm: 0.26817834
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9126.4375MB
INFO:root:[   26] Training loss: 0.94838965, Validation loss: 0.94812880, Gradient norm: 0.29628460
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9164.3828125MB
INFO:root:[   27] Training loss: 0.94778514, Validation loss: 0.94838725, Gradient norm: 0.26445835
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9202.23828125MB
INFO:root:[   28] Training loss: 0.94755816, Validation loss: 0.94809573, Gradient norm: 0.29309529
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9240.44140625MB
INFO:root:[   29] Training loss: 0.94706599, Validation loss: 0.94735176, Gradient norm: 0.27111729
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9278.86328125MB
INFO:root:[   30] Training loss: 0.94680427, Validation loss: 0.94778099, Gradient norm: 0.27328973
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9317.0078125MB
INFO:root:[   31] Training loss: 0.94658095, Validation loss: 0.94841530, Gradient norm: 0.28892828
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9354.875MB
INFO:root:[   32] Training loss: 0.94631972, Validation loss: 0.94665014, Gradient norm: 0.26803573
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9393.3984375MB
INFO:root:[   33] Training loss: 0.94635406, Validation loss: 0.94636424, Gradient norm: 0.30071526
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9431.30078125MB
INFO:root:[   34] Training loss: 0.94596894, Validation loss: 0.94612333, Gradient norm: 0.29629763
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9469.76171875MB
INFO:root:[   35] Training loss: 0.94549880, Validation loss: 0.94621334, Gradient norm: 0.26768704
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9508.13671875MB
INFO:root:[   36] Training loss: 0.94532077, Validation loss: 0.94639000, Gradient norm: 0.27549018
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9546.28125MB
INFO:root:[   37] Training loss: 0.94509073, Validation loss: 0.94637489, Gradient norm: 0.28970479
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9584.42578125MB
INFO:root:[   38] Training loss: 0.94499681, Validation loss: 0.94527532, Gradient norm: 0.29911841
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9622.7578125MB
INFO:root:[   39] Training loss: 0.94495576, Validation loss: 0.94600019, Gradient norm: 0.29581512
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9660.36328125MB
INFO:root:[   40] Training loss: 0.94472535, Validation loss: 0.94539696, Gradient norm: 0.29387637
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9698.20703125MB
INFO:root:[   41] Training loss: 0.94436300, Validation loss: 0.94558846, Gradient norm: 0.28009405
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9736.3515625MB
INFO:root:[   42] Training loss: 0.94449257, Validation loss: 0.94538582, Gradient norm: 0.29621649
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9775.09375MB
INFO:root:[   43] Training loss: 0.94403712, Validation loss: 0.94459729, Gradient norm: 0.30393665
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9813.8515625MB
INFO:root:[   44] Training loss: 0.94396570, Validation loss: 0.94414070, Gradient norm: 0.29217236
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9852.0625MB
INFO:root:[   45] Training loss: 0.94364567, Validation loss: 0.94459845, Gradient norm: 0.27941304
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9890.47265625MB
INFO:root:[   46] Training loss: 0.94358700, Validation loss: 0.94418125, Gradient norm: 0.29078015
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9928.390625MB
INFO:root:[   47] Training loss: 0.94338742, Validation loss: 0.94431838, Gradient norm: 0.29669143
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=9966.5546875MB
INFO:root:[   48] Training loss: 0.94325749, Validation loss: 0.94346913, Gradient norm: 0.30193850
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10004.71484375MB
INFO:root:[   49] Training loss: 0.94299761, Validation loss: 0.94337849, Gradient norm: 0.29450921
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10042.91015625MB
INFO:root:[   50] Training loss: 0.94297255, Validation loss: 0.94481406, Gradient norm: 0.31620879
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10081.18359375MB
INFO:root:[   51] Training loss: 0.94280097, Validation loss: 0.94422271, Gradient norm: 0.31541956
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10118.98828125MB
INFO:root:[   52] Training loss: 0.94258287, Validation loss: 0.94272667, Gradient norm: 0.31276332
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10156.84375MB
INFO:root:[   53] Training loss: 0.94233102, Validation loss: 0.94291407, Gradient norm: 0.30398568
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10195.67578125MB
INFO:root:[   54] Training loss: 0.94206243, Validation loss: 0.94291735, Gradient norm: 0.30631897
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10233.41796875MB
INFO:root:[   55] Training loss: 0.94198548, Validation loss: 0.94251948, Gradient norm: 0.32106066
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10271.75MB
INFO:root:[   56] Training loss: 0.94165933, Validation loss: 0.94205975, Gradient norm: 0.30169799
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10309.47265625MB
INFO:root:[   57] Training loss: 0.94144673, Validation loss: 0.94217343, Gradient norm: 0.31453263
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10347.63671875MB
INFO:root:[   58] Training loss: 0.94113934, Validation loss: 0.94246861, Gradient norm: 0.30210932
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10385.546875MB
INFO:root:[   59] Training loss: 0.94071571, Validation loss: 0.94188290, Gradient norm: 0.32332943
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10423.33984375MB
INFO:root:[   60] Training loss: 0.94059054, Validation loss: 0.94072815, Gradient norm: 0.33467709
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10461.59375MB
INFO:root:[   61] Training loss: 0.94039033, Validation loss: 0.94071507, Gradient norm: 0.34161747
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10499.8359375MB
INFO:root:[   62] Training loss: 0.94016474, Validation loss: 0.94127752, Gradient norm: 0.35953745
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10538.0390625MB
INFO:root:[   63] Training loss: 0.93982198, Validation loss: 0.94062782, Gradient norm: 0.32670354
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10577.25MB
INFO:root:[   64] Training loss: 0.93936297, Validation loss: 0.94049085, Gradient norm: 0.31752280
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10615.3515625MB
INFO:root:[   65] Training loss: 0.93929982, Validation loss: 0.93974062, Gradient norm: 0.34457412
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10653.5625MB
INFO:root:[   66] Training loss: 0.93889947, Validation loss: 0.93920383, Gradient norm: 0.33126493
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10691.48046875MB
INFO:root:[   67] Training loss: 0.93872829, Validation loss: 0.93926950, Gradient norm: 0.33701768
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10729.890625MB
INFO:root:[   68] Training loss: 0.93876046, Validation loss: 0.93937990, Gradient norm: 0.35273646
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10768.046875MB
INFO:root:[   69] Training loss: 0.93863098, Validation loss: 0.93922488, Gradient norm: 0.34118304
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10806.1796875MB
INFO:root:[   70] Training loss: 0.93827970, Validation loss: 0.93871933, Gradient norm: 0.32542178
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10844.08203125MB
INFO:root:[   71] Training loss: 0.93789070, Validation loss: 0.93952546, Gradient norm: 0.32133729
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10882.4921875MB
INFO:root:[   72] Training loss: 0.93795444, Validation loss: 0.93970564, Gradient norm: 0.34370172
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10920.65625MB
INFO:root:[   73] Training loss: 0.93781301, Validation loss: 0.93748422, Gradient norm: 0.32686416
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10958.3203125MB
INFO:root:[   74] Training loss: 0.93766566, Validation loss: 0.93853599, Gradient norm: 0.34949701
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=10997.07421875MB
INFO:root:[   75] Training loss: 0.93733354, Validation loss: 0.93792030, Gradient norm: 0.32677353
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11034.84375MB
INFO:root:[   76] Training loss: 0.93738005, Validation loss: 0.93773370, Gradient norm: 0.34141814
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11073.0078125MB
INFO:root:[   77] Training loss: 0.93705067, Validation loss: 0.93814347, Gradient norm: 0.33572324
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11111.171875MB
INFO:root:[   78] Training loss: 0.93694018, Validation loss: 0.93778931, Gradient norm: 0.32485376
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11149.3359375MB
INFO:root:[   79] Training loss: 0.93701677, Validation loss: 0.93725751, Gradient norm: 0.33683727
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11187.77734375MB
INFO:root:[   80] Training loss: 0.93664454, Validation loss: 0.93729379, Gradient norm: 0.32546561
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11225.921875MB
INFO:root:[   81] Training loss: 0.93656912, Validation loss: 0.93688029, Gradient norm: 0.33779897
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11263.9453125MB
INFO:root:[   82] Training loss: 0.93639752, Validation loss: 0.93708259, Gradient norm: 0.32554372
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11302.08984375MB
INFO:root:[   83] Training loss: 0.93630854, Validation loss: 0.93774768, Gradient norm: 0.33949052
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11340.23046875MB
INFO:root:[   84] Training loss: 0.93610246, Validation loss: 0.93663785, Gradient norm: 0.32995800
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11378.34375MB
INFO:root:[   85] Training loss: 0.93617397, Validation loss: 0.93711609, Gradient norm: 0.32914131
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11416.859375MB
INFO:root:[   86] Training loss: 0.93584790, Validation loss: 0.93763808, Gradient norm: 0.32406317
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11454.7578125MB
INFO:root:[   87] Training loss: 0.93591802, Validation loss: 0.93673276, Gradient norm: 0.33784011
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11492.65625MB
INFO:root:[   88] Training loss: 0.93577795, Validation loss: 0.93687639, Gradient norm: 0.34860942
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11530.76953125MB
INFO:root:[   89] Training loss: 0.93554068, Validation loss: 0.93589076, Gradient norm: 0.31896059
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11569.22265625MB
INFO:root:[   90] Training loss: 0.93531242, Validation loss: 0.93626024, Gradient norm: 0.32591423
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11607.58203125MB
INFO:root:[   91] Training loss: 0.93555576, Validation loss: 0.93641313, Gradient norm: 0.33727644
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11645.56640625MB
INFO:root:[   92] Training loss: 0.93525806, Validation loss: 0.93621647, Gradient norm: 0.33358597
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11683.46484375MB
INFO:root:[   93] Training loss: 0.93519626, Validation loss: 0.93572952, Gradient norm: 0.33263203
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11721.69921875MB
INFO:root:[   94] Training loss: 0.93489792, Validation loss: 0.93606274, Gradient norm: 0.31724724
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11760.05859375MB
INFO:root:[   95] Training loss: 0.93492459, Validation loss: 0.93549264, Gradient norm: 0.33803074
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11798.00390625MB
INFO:root:[   96] Training loss: 0.93483252, Validation loss: 0.93542102, Gradient norm: 0.30919047
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11836.05859375MB
INFO:root:[   97] Training loss: 0.93467116, Validation loss: 0.93564347, Gradient norm: 0.34577279
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11874.4375MB
INFO:root:[   98] Training loss: 0.93466012, Validation loss: 0.93574367, Gradient norm: 0.33575364
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11912.58203125MB
INFO:root:[   99] Training loss: 0.93457336, Validation loss: 0.93514434, Gradient norm: 0.33726886
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11950.52734375MB
INFO:root:[  100] Training loss: 0.93439101, Validation loss: 0.93518293, Gradient norm: 0.32533625
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=11988.91796875MB
INFO:root:[  101] Training loss: 0.93426810, Validation loss: 0.93522302, Gradient norm: 0.32036591
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=12026.7734375MB
INFO:root:[  102] Training loss: 0.93417184, Validation loss: 0.93499840, Gradient norm: 0.33269487
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=12065.2578125MB
INFO:root:[  103] Training loss: 0.93408770, Validation loss: 0.93502278, Gradient norm: 0.33371166
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=12103.88671875MB
INFO:root:[  104] Training loss: 0.93402658, Validation loss: 0.93485697, Gradient norm: 0.32911340
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=12142.21484375MB
INFO:root:[  105] Training loss: 0.93386163, Validation loss: 0.93528105, Gradient norm: 0.32475839
INFO:root:At the start of the epoch: mem (CPU python)=12462.3828125MB; mem (CPU total)=12180.63671875MB
INFO:root:[  106] Training loss: 0.93391166, Validation loss: 0.93514523, Gradient norm: 0.32734075
INFO:root:At the start of the epoch: mem (CPU python)=12483.8671875MB; mem (CPU total)=12217.796875MB
INFO:root:[  107] Training loss: 0.93369577, Validation loss: 0.93588740, Gradient norm: 0.31290576
INFO:root:At the start of the epoch: mem (CPU python)=12521.9609375MB; mem (CPU total)=12256.015625MB
INFO:root:[  108] Training loss: 0.93377792, Validation loss: 0.93482624, Gradient norm: 0.34518088
INFO:root:At the start of the epoch: mem (CPU python)=12560.0625MB; mem (CPU total)=12294.34375MB
INFO:root:[  109] Training loss: 0.93353947, Validation loss: 0.93473915, Gradient norm: 0.31834992
INFO:root:At the start of the epoch: mem (CPU python)=12598.15234375MB; mem (CPU total)=12331.921875MB
INFO:root:[  110] Training loss: 0.93343608, Validation loss: 0.93434265, Gradient norm: 0.32631497
INFO:root:At the start of the epoch: mem (CPU python)=12636.25MB; mem (CPU total)=12368.8671875MB
INFO:root:[  111] Training loss: 0.93343569, Validation loss: 0.93519560, Gradient norm: 0.32801637
INFO:root:At the start of the epoch: mem (CPU python)=12674.34375MB; mem (CPU total)=12406.51953125MB
INFO:root:[  112] Training loss: 0.93341962, Validation loss: 0.93466587, Gradient norm: 0.33376079
INFO:root:At the start of the epoch: mem (CPU python)=12712.44140625MB; mem (CPU total)=12444.91015625MB
INFO:root:[  113] Training loss: 0.93328216, Validation loss: 0.93411927, Gradient norm: 0.33374321
INFO:root:At the start of the epoch: mem (CPU python)=12750.53515625MB; mem (CPU total)=12483.45703125MB
INFO:root:[  114] Training loss: 0.93307318, Validation loss: 0.93437508, Gradient norm: 0.33093816
INFO:root:At the start of the epoch: mem (CPU python)=12788.62890625MB; mem (CPU total)=12521.6015625MB
INFO:root:[  115] Training loss: 0.93313248, Validation loss: 0.93442729, Gradient norm: 0.32141964
INFO:root:At the start of the epoch: mem (CPU python)=12826.7265625MB; mem (CPU total)=12559.71484375MB
INFO:root:[  116] Training loss: 0.93312177, Validation loss: 0.93385629, Gradient norm: 0.34127539
INFO:root:At the start of the epoch: mem (CPU python)=12864.82421875MB; mem (CPU total)=12598.08984375MB
INFO:root:[  117] Training loss: 0.93275326, Validation loss: 0.93431000, Gradient norm: 0.30620336
INFO:root:At the start of the epoch: mem (CPU python)=12902.9140625MB; mem (CPU total)=12636.234375MB
INFO:root:[  118] Training loss: 0.93268267, Validation loss: 0.93403222, Gradient norm: 0.31105902
INFO:root:At the start of the epoch: mem (CPU python)=12941.01171875MB; mem (CPU total)=12674.31640625MB
INFO:root:[  119] Training loss: 0.93273930, Validation loss: 0.93318921, Gradient norm: 0.32324219
INFO:root:At the start of the epoch: mem (CPU python)=12979.109375MB; mem (CPU total)=12713.0625MB
INFO:root:[  120] Training loss: 0.93252042, Validation loss: 0.93389366, Gradient norm: 0.31278160
INFO:root:At the start of the epoch: mem (CPU python)=13017.203125MB; mem (CPU total)=12750.9609375MB
INFO:root:[  121] Training loss: 0.93256308, Validation loss: 0.93318986, Gradient norm: 0.33146615
INFO:root:At the start of the epoch: mem (CPU python)=13055.296875MB; mem (CPU total)=12789.10546875MB
INFO:root:[  122] Training loss: 0.93244027, Validation loss: 0.93335410, Gradient norm: 0.32299719
INFO:root:At the start of the epoch: mem (CPU python)=13093.39453125MB; mem (CPU total)=12827.49609375MB
INFO:root:[  123] Training loss: 0.93244707, Validation loss: 0.93404786, Gradient norm: 0.33015911
INFO:root:At the start of the epoch: mem (CPU python)=13131.48828125MB; mem (CPU total)=12865.63671875MB
INFO:root:[  124] Training loss: 0.93247628, Validation loss: 0.93357164, Gradient norm: 0.34450954
INFO:root:At the start of the epoch: mem (CPU python)=13169.58203125MB; mem (CPU total)=12904.02734375MB
INFO:root:[  125] Training loss: 0.93214648, Validation loss: 0.93404007, Gradient norm: 0.30863920
INFO:root:At the start of the epoch: mem (CPU python)=13207.6796875MB; mem (CPU total)=12941.83203125MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  126] Training loss: 0.93210380, Validation loss: 0.93336032, Gradient norm: 0.30846918
INFO:root:At the start of the epoch: mem (CPU python)=13245.7734375MB; mem (CPU total)=12979.9765625MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  127] Training loss: 0.93047524, Validation loss: 0.93232379, Gradient norm: 0.28773364
INFO:root:At the start of the epoch: mem (CPU python)=13283.87109375MB; mem (CPU total)=13018.4296875MB
INFO:root:[  128] Training loss: 0.92950274, Validation loss: 0.93128671, Gradient norm: 0.25904251
INFO:root:At the start of the epoch: mem (CPU python)=13321.96875MB; mem (CPU total)=13056.453125MB
INFO:root:[  129] Training loss: 0.92944650, Validation loss: 0.93158336, Gradient norm: 0.27349017
INFO:root:At the start of the epoch: mem (CPU python)=13360.0625MB; mem (CPU total)=13095.00390625MB
INFO:root:[  130] Training loss: 0.92935182, Validation loss: 0.93150551, Gradient norm: 0.27006432
INFO:root:At the start of the epoch: mem (CPU python)=13398.15234375MB; mem (CPU total)=13132.99609375MB
INFO:root:[  131] Training loss: 0.92927568, Validation loss: 0.93129514, Gradient norm: 0.25859420
INFO:root:At the start of the epoch: mem (CPU python)=13436.25MB; mem (CPU total)=13171.140625MB
INFO:root:[  132] Training loss: 0.92924638, Validation loss: 0.93159066, Gradient norm: 0.27296766
INFO:root:At the start of the epoch: mem (CPU python)=13474.34765625MB; mem (CPU total)=13209.0390625MB
INFO:root:[  133] Training loss: 0.92926850, Validation loss: 0.93128803, Gradient norm: 0.26306214
INFO:root:At the start of the epoch: mem (CPU python)=13512.44140625MB; mem (CPU total)=13247.3984375MB
INFO:root:[  134] Training loss: 0.92925426, Validation loss: 0.93147326, Gradient norm: 0.28133019
INFO:root:At the start of the epoch: mem (CPU python)=13550.53515625MB; mem (CPU total)=13285.265625MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  135] Training loss: 0.92924052, Validation loss: 0.93110538, Gradient norm: 0.26898386
INFO:root:At the start of the epoch: mem (CPU python)=13588.63671875MB; mem (CPU total)=13323.75MB
INFO:root:[  136] Training loss: 0.92868341, Validation loss: 0.93101720, Gradient norm: 0.26631859
INFO:root:At the start of the epoch: mem (CPU python)=13626.73046875MB; mem (CPU total)=13362.19921875MB
INFO:root:[  137] Training loss: 0.92858592, Validation loss: 0.93121567, Gradient norm: 0.25544926
INFO:root:At the start of the epoch: mem (CPU python)=13664.8203125MB; mem (CPU total)=13400.34375MB
INFO:root:[  138] Training loss: 0.92859832, Validation loss: 0.93099928, Gradient norm: 0.25973825
INFO:root:At the start of the epoch: mem (CPU python)=13702.91796875MB; mem (CPU total)=13438.765625MB
INFO:root:[  139] Training loss: 0.92853190, Validation loss: 0.93083294, Gradient norm: 0.26043160
INFO:root:At the start of the epoch: mem (CPU python)=13741.015625MB; mem (CPU total)=13475.8046875MB
INFO:root:[  140] Training loss: 0.92854817, Validation loss: 0.93101371, Gradient norm: 0.25987318
INFO:root:At the start of the epoch: mem (CPU python)=13779.109375MB; mem (CPU total)=13513.4921875MB
INFO:root:[  141] Training loss: 0.92849175, Validation loss: 0.93101487, Gradient norm: 0.26519496
INFO:root:At the start of the epoch: mem (CPU python)=13817.203125MB; mem (CPU total)=13551.859375MB
INFO:root:[  142] Training loss: 0.92848015, Validation loss: 0.93113290, Gradient norm: 0.25585675
INFO:root:At the start of the epoch: mem (CPU python)=13855.30078125MB; mem (CPU total)=13589.97265625MB
INFO:root:[  143] Training loss: 0.92849257, Validation loss: 0.93098431, Gradient norm: 0.26125898
INFO:root:At the start of the epoch: mem (CPU python)=13893.39453125MB; mem (CPU total)=13628.11328125MB
INFO:root:[  144] Training loss: 0.92846558, Validation loss: 0.93067432, Gradient norm: 0.26869259
INFO:root:At the start of the epoch: mem (CPU python)=13931.4921875MB; mem (CPU total)=13666.66015625MB
INFO:root:[  145] Training loss: 0.92847498, Validation loss: 0.93114117, Gradient norm: 0.26686852
INFO:root:At the start of the epoch: mem (CPU python)=13969.58984375MB; mem (CPU total)=13704.8359375MB
INFO:root:[  146] Training loss: 0.92845765, Validation loss: 0.93089241, Gradient norm: 0.27392125
INFO:root:At the start of the epoch: mem (CPU python)=14007.68359375MB; mem (CPU total)=13742.98046875MB
INFO:root:[  147] Training loss: 0.92846170, Validation loss: 0.93110579, Gradient norm: 0.27306746
INFO:root:At the start of the epoch: mem (CPU python)=14045.77734375MB; mem (CPU total)=13781.125MB
INFO:root:[  148] Training loss: 0.92839261, Validation loss: 0.93103555, Gradient norm: 0.27532622
INFO:root:At the start of the epoch: mem (CPU python)=14083.87109375MB; mem (CPU total)=13819.76171875MB
INFO:root:[  149] Training loss: 0.92838760, Validation loss: 0.93068908, Gradient norm: 0.26053972
INFO:root:At the start of the epoch: mem (CPU python)=14121.96875MB; mem (CPU total)=13857.90625MB
INFO:root:[  150] Training loss: 0.92835186, Validation loss: 0.93094505, Gradient norm: 0.26745437
INFO:root:At the start of the epoch: mem (CPU python)=14160.0625MB; mem (CPU total)=13895.6484375MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  151] Training loss: 0.92834448, Validation loss: 0.93084492, Gradient norm: 0.26321416
INFO:root:At the start of the epoch: mem (CPU python)=14198.15625MB; mem (CPU total)=13933.6015625MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  152] Training loss: 0.92807602, Validation loss: 0.93057895, Gradient norm: 0.26438898
INFO:root:At the start of the epoch: mem (CPU python)=14236.2578125MB; mem (CPU total)=13972.359375MB
INFO:root:[  153] Training loss: 0.92786425, Validation loss: 0.93042435, Gradient norm: 0.24754774
INFO:root:At the start of the epoch: mem (CPU python)=14274.3515625MB; mem (CPU total)=14010.6484375MB
INFO:root:[  154] Training loss: 0.92782289, Validation loss: 0.93067176, Gradient norm: 0.24717982
INFO:root:At the start of the epoch: mem (CPU python)=14312.44140625MB; mem (CPU total)=14049.0546875MB
INFO:root:[  155] Training loss: 0.92782859, Validation loss: 0.93061233, Gradient norm: 0.24980276
INFO:root:At the start of the epoch: mem (CPU python)=14350.5390625MB; mem (CPU total)=14087.1953125MB
INFO:root:[  156] Training loss: 0.92782433, Validation loss: 0.93039518, Gradient norm: 0.24843767
INFO:root:At the start of the epoch: mem (CPU python)=14388.63671875MB; mem (CPU total)=14125.8125MB
INFO:root:[  157] Training loss: 0.92784428, Validation loss: 0.93058445, Gradient norm: 0.25216027
INFO:root:At the start of the epoch: mem (CPU python)=14426.73046875MB; mem (CPU total)=14164.46875MB
INFO:root:[  158] Training loss: 0.92782086, Validation loss: 0.93079750, Gradient norm: 0.25194178
INFO:root:At the start of the epoch: mem (CPU python)=14464.82421875MB; mem (CPU total)=14202.66796875MB
INFO:root:[  159] Training loss: 0.92782007, Validation loss: 0.93043676, Gradient norm: 0.25924354
INFO:root:At the start of the epoch: mem (CPU python)=14502.921875MB; mem (CPU total)=14240.34375MB
INFO:root:[  160] Training loss: 0.92779630, Validation loss: 0.93085410, Gradient norm: 0.24878946
INFO:root:At the start of the epoch: mem (CPU python)=14541.015625MB; mem (CPU total)=14278.26171875MB
INFO:root:[  161] Training loss: 0.92782744, Validation loss: 0.93097064, Gradient norm: 0.24766379
INFO:root:At the start of the epoch: mem (CPU python)=14579.109375MB; mem (CPU total)=14316.64453125MB
INFO:root:[  162] Training loss: 0.92785003, Validation loss: 0.93118685, Gradient norm: 0.25072774
INFO:root:At the start of the epoch: mem (CPU python)=14617.2109375MB; mem (CPU total)=14354.640625MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  163] Training loss: 0.92777681, Validation loss: 0.93050654, Gradient norm: 0.25342430
INFO:root:At the start of the epoch: mem (CPU python)=14655.3046875MB; mem (CPU total)=14392.8046875MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  164] Training loss: 0.92774423, Validation loss: 0.93108482, Gradient norm: 0.24644508
INFO:root:At the start of the epoch: mem (CPU python)=14693.3984375MB; mem (CPU total)=14431.21875MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  165] Training loss: 0.92764699, Validation loss: 0.93089915, Gradient norm: 0.25024857
INFO:root:At the start of the epoch: mem (CPU python)=14731.4921875MB; mem (CPU total)=14469.13671875MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  166] Training loss: 0.92759924, Validation loss: 0.93032281, Gradient norm: 0.24752512
INFO:root:At the start of the epoch: mem (CPU python)=14769.58984375MB; mem (CPU total)=14507.7578125MB
INFO:root:[  167] Training loss: 0.92760499, Validation loss: 0.93061005, Gradient norm: 0.24296079
INFO:root:At the start of the epoch: mem (CPU python)=14807.68359375MB; mem (CPU total)=14546.28515625MB
INFO:root:[  168] Training loss: 0.92762391, Validation loss: 0.93048652, Gradient norm: 0.24707445
INFO:root:At the start of the epoch: mem (CPU python)=14845.77734375MB; mem (CPU total)=14584.0703125MB
INFO:root:[  169] Training loss: 0.92754733, Validation loss: 0.93059255, Gradient norm: 0.24514853
INFO:root:At the start of the epoch: mem (CPU python)=14883.875MB; mem (CPU total)=14622.23828125MB
INFO:root:[  170] Training loss: 0.92761619, Validation loss: 0.93055077, Gradient norm: 0.24840530
INFO:root:At the start of the epoch: mem (CPU python)=14921.96875MB; mem (CPU total)=14660.15625MB
INFO:root:[  171] Training loss: 0.92760743, Validation loss: 0.93067309, Gradient norm: 0.24869926
INFO:root:At the start of the epoch: mem (CPU python)=14960.06640625MB; mem (CPU total)=14698.64453125MB
INFO:root:[  172] Training loss: 0.92758716, Validation loss: 0.93040450, Gradient norm: 0.24831944
INFO:root:At the start of the epoch: mem (CPU python)=14998.16015625MB; mem (CPU total)=14736.59765625MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:[  173] Training loss: 0.92759026, Validation loss: 0.93072481, Gradient norm: 0.24683556
INFO:root:At the start of the epoch: mem (CPU python)=15036.2578125MB; mem (CPU total)=14774.75MB
INFO:root:Learning rate reduced to: [4.8828125e-07]
INFO:root:[  174] Training loss: 0.92765849, Validation loss: 0.93075387, Gradient norm: 0.24802581
INFO:root:At the start of the epoch: mem (CPU python)=15074.3515625MB; mem (CPU total)=14813.15625MB
INFO:root:Learning rate reduced to: [2.44140625e-07]
INFO:root:[  175] Training loss: 0.92754938, Validation loss: 0.93053055, Gradient norm: 0.24696468
INFO:root:At the start of the epoch: mem (CPU python)=15112.4453125MB; mem (CPU total)=14851.32421875MB
INFO:root:Learning rate reduced to: [1.220703125e-07]
INFO:root:EP 175: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=15150.54296875MB; mem (CPU total)=14889.484375MB
INFO:root:Training the model took 9412.31s.
INFO:root:Emptying the cuda cache took 0.012s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92812
INFO:root:EnergyScoreTrain: 0.84895
INFO:root:CRPSTrain: 0.6827
INFO:root:Gaussian NLLTrain: 1034.75959
INFO:root:CoverageTrain: 0.09375
INFO:root:IntervalWidthTrain: 0.18898
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93355
INFO:root:EnergyScoreValidation: 0.85082
INFO:root:CRPSValidation: 0.68498
INFO:root:Gaussian NLLValidation: 1001.92008
INFO:root:CoverageValidation: 0.0966
INFO:root:IntervalWidthValidation: 0.19832
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93306
INFO:root:EnergyScoreTest: 0.85593
INFO:root:CRPSTest: 0.68881
INFO:root:Gaussian NLLTest: 1199.80515
INFO:root:CoverageTest: 0.09044
INFO:root:IntervalWidthTest: 0.18448
INFO:root:After validation: mem (CPU python)=15224.359375MB; mem (CPU total)=14965.74609375MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=15224.359375MB; mem (CPU total)=14965.74609375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=15226.08203125MB; mem (CPU total)=14967.22265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=15226.12109375MB; mem (CPU total)=14967.4765625MB
INFO:root:[    1] Training loss: 1.00455227, Validation loss: 0.98960042, Gradient norm: 0.06298074
INFO:root:At the start of the epoch: mem (CPU python)=15263.91015625MB; mem (CPU total)=15005.44921875MB
INFO:root:[    2] Training loss: 0.98101664, Validation loss: 0.97640366, Gradient norm: 0.12931851
INFO:root:At the start of the epoch: mem (CPU python)=15302.0078125MB; mem (CPU total)=15043.33984375MB
INFO:root:[    3] Training loss: 0.97374390, Validation loss: 0.97297368, Gradient norm: 0.13703656
INFO:root:At the start of the epoch: mem (CPU python)=15340.1171875MB; mem (CPU total)=15081.38671875MB
INFO:root:[    4] Training loss: 0.97077060, Validation loss: 0.97085811, Gradient norm: 0.13046637
INFO:root:At the start of the epoch: mem (CPU python)=15378.2265625MB; mem (CPU total)=15119.8515625MB
INFO:root:[    5] Training loss: 0.96905044, Validation loss: 0.96872919, Gradient norm: 0.14627284
INFO:root:At the start of the epoch: mem (CPU python)=15416.328125MB; mem (CPU total)=15157.75390625MB
INFO:root:[    6] Training loss: 0.96737242, Validation loss: 0.96755694, Gradient norm: 0.15145291
INFO:root:At the start of the epoch: mem (CPU python)=15454.42578125MB; mem (CPU total)=15196.27734375MB
INFO:root:[    7] Training loss: 0.96606852, Validation loss: 0.96606693, Gradient norm: 0.15692097
INFO:root:At the start of the epoch: mem (CPU python)=15492.51953125MB; mem (CPU total)=15234.79296875MB
INFO:root:[    8] Training loss: 0.96471977, Validation loss: 0.96485082, Gradient norm: 0.17696791
INFO:root:At the start of the epoch: mem (CPU python)=15530.61328125MB; mem (CPU total)=15273.17578125MB
INFO:root:[    9] Training loss: 0.96331092, Validation loss: 0.96375228, Gradient norm: 0.18949814
INFO:root:At the start of the epoch: mem (CPU python)=15568.7109375MB; mem (CPU total)=15311.14453125MB
INFO:root:[   10] Training loss: 0.96209296, Validation loss: 0.96253712, Gradient norm: 0.19915808
INFO:root:At the start of the epoch: mem (CPU python)=15606.80859375MB; mem (CPU total)=15349.5703125MB
INFO:root:[   11] Training loss: 0.96111877, Validation loss: 0.96075234, Gradient norm: 0.22412883
INFO:root:At the start of the epoch: mem (CPU python)=15644.90234375MB; mem (CPU total)=15387.84375MB
INFO:root:[   12] Training loss: 0.95988473, Validation loss: 0.95974471, Gradient norm: 0.21232626
INFO:root:At the start of the epoch: mem (CPU python)=15682.99609375MB; mem (CPU total)=15426.3671875MB
INFO:root:[   13] Training loss: 0.95905650, Validation loss: 0.95973489, Gradient norm: 0.23754786
INFO:root:At the start of the epoch: mem (CPU python)=15721.09375MB; mem (CPU total)=15464.8359375MB
INFO:root:[   14] Training loss: 0.95820066, Validation loss: 0.95825630, Gradient norm: 0.22694129
INFO:root:At the start of the epoch: mem (CPU python)=15759.1875MB; mem (CPU total)=15502.5MB
INFO:root:[   15] Training loss: 0.95717991, Validation loss: 0.95731278, Gradient norm: 0.24821693
INFO:root:At the start of the epoch: mem (CPU python)=15797.28125MB; mem (CPU total)=15540.80078125MB
INFO:root:[   16] Training loss: 0.95637830, Validation loss: 0.95768649, Gradient norm: 0.25258686
INFO:root:At the start of the epoch: mem (CPU python)=15835.37890625MB; mem (CPU total)=15579.18359375MB
INFO:root:[   17] Training loss: 0.95561316, Validation loss: 0.95563205, Gradient norm: 0.25153366
INFO:root:At the start of the epoch: mem (CPU python)=15873.47265625MB; mem (CPU total)=15617.0078125MB
INFO:root:[   18] Training loss: 0.95491722, Validation loss: 0.95572797, Gradient norm: 0.26429132
INFO:root:At the start of the epoch: mem (CPU python)=15911.56640625MB; mem (CPU total)=15655.421875MB
INFO:root:[   19] Training loss: 0.95450794, Validation loss: 0.95440658, Gradient norm: 0.26392599
INFO:root:At the start of the epoch: mem (CPU python)=15949.66796875MB; mem (CPU total)=15693.17578125MB
INFO:root:[   20] Training loss: 0.95369367, Validation loss: 0.95290534, Gradient norm: 0.24830045
INFO:root:At the start of the epoch: mem (CPU python)=15987.76171875MB; mem (CPU total)=15731.59375MB
INFO:root:[   21] Training loss: 0.95323396, Validation loss: 0.95325766, Gradient norm: 0.28774463
INFO:root:At the start of the epoch: mem (CPU python)=16025.85546875MB; mem (CPU total)=15769.70703125MB
INFO:root:[   22] Training loss: 0.95278364, Validation loss: 0.95344919, Gradient norm: 0.25561426
INFO:root:At the start of the epoch: mem (CPU python)=16063.94921875MB; mem (CPU total)=15807.8515625MB
INFO:root:[   23] Training loss: 0.95231025, Validation loss: 0.95197112, Gradient norm: 0.25426129
INFO:root:At the start of the epoch: mem (CPU python)=16102.046875MB; mem (CPU total)=15846.3203125MB
INFO:root:[   24] Training loss: 0.95187797, Validation loss: 0.95156801, Gradient norm: 0.26948415
INFO:root:At the start of the epoch: mem (CPU python)=16140.140625MB; mem (CPU total)=15883.67578125MB
INFO:root:[   25] Training loss: 0.95160445, Validation loss: 0.95202913, Gradient norm: 0.27332702
INFO:root:At the start of the epoch: mem (CPU python)=16178.234375MB; mem (CPU total)=15921.7890625MB
INFO:root:[   26] Training loss: 0.95124119, Validation loss: 0.95107886, Gradient norm: 0.26487942
INFO:root:At the start of the epoch: mem (CPU python)=16216.3359375MB; mem (CPU total)=15959.87890625MB
INFO:root:[   27] Training loss: 0.95090168, Validation loss: 0.95161758, Gradient norm: 0.27373208
INFO:root:At the start of the epoch: mem (CPU python)=16254.42578125MB; mem (CPU total)=15998.26953125MB
INFO:root:[   28] Training loss: 0.95065887, Validation loss: 0.95033014, Gradient norm: 0.28149336
INFO:root:At the start of the epoch: mem (CPU python)=16292.5234375MB; mem (CPU total)=16036.29296875MB
INFO:root:[   29] Training loss: 0.95040016, Validation loss: 0.94999292, Gradient norm: 0.27592678
INFO:root:At the start of the epoch: mem (CPU python)=16330.6171875MB; mem (CPU total)=16075.1484375MB
INFO:root:[   30] Training loss: 0.94996166, Validation loss: 0.95062377, Gradient norm: 0.27702532
INFO:root:At the start of the epoch: mem (CPU python)=16368.71484375MB; mem (CPU total)=16113.5390625MB
INFO:root:[   31] Training loss: 0.94977727, Validation loss: 0.95018846, Gradient norm: 0.27391100
INFO:root:At the start of the epoch: mem (CPU python)=16406.80859375MB; mem (CPU total)=16151.68359375MB
INFO:root:[   32] Training loss: 0.94960448, Validation loss: 0.95034707, Gradient norm: 0.29735262
INFO:root:At the start of the epoch: mem (CPU python)=16444.90234375MB; mem (CPU total)=16189.828125MB
INFO:root:[   33] Training loss: 0.94949059, Validation loss: 0.94997540, Gradient norm: 0.28890312
INFO:root:At the start of the epoch: mem (CPU python)=16483.0MB; mem (CPU total)=16227.09375MB
INFO:root:[   34] Training loss: 0.94935792, Validation loss: 0.94885017, Gradient norm: 0.28735017
INFO:root:At the start of the epoch: mem (CPU python)=16521.09765625MB; mem (CPU total)=16264.34765625MB
INFO:root:[   35] Training loss: 0.94893469, Validation loss: 0.94872794, Gradient norm: 0.27820428
INFO:root:At the start of the epoch: mem (CPU python)=16559.1953125MB; mem (CPU total)=16302.26953125MB
INFO:root:[   36] Training loss: 0.94862777, Validation loss: 0.94994073, Gradient norm: 0.27297501
INFO:root:At the start of the epoch: mem (CPU python)=16597.2890625MB; mem (CPU total)=16340.96484375MB
INFO:root:[   37] Training loss: 0.94840547, Validation loss: 0.94853469, Gradient norm: 0.26785432
INFO:root:At the start of the epoch: mem (CPU python)=16635.38671875MB; mem (CPU total)=16378.7890625MB
INFO:root:[   38] Training loss: 0.94856624, Validation loss: 0.94857964, Gradient norm: 0.30492005
INFO:root:At the start of the epoch: mem (CPU python)=16673.48046875MB; mem (CPU total)=16416.92578125MB
INFO:root:[   39] Training loss: 0.94807631, Validation loss: 0.94839301, Gradient norm: 0.27594226
INFO:root:At the start of the epoch: mem (CPU python)=16711.57421875MB; mem (CPU total)=16454.9140625MB
INFO:root:[   40] Training loss: 0.94792507, Validation loss: 0.94840231, Gradient norm: 0.28194163
INFO:root:At the start of the epoch: mem (CPU python)=16749.67578125MB; mem (CPU total)=16493.2421875MB
INFO:root:[   41] Training loss: 0.94785319, Validation loss: 0.94735968, Gradient norm: 0.29170915
INFO:root:At the start of the epoch: mem (CPU python)=16787.7734375MB; mem (CPU total)=16531.29296875MB
INFO:root:[   42] Training loss: 0.94753660, Validation loss: 0.94763844, Gradient norm: 0.28662832
INFO:root:At the start of the epoch: mem (CPU python)=16825.86328125MB; mem (CPU total)=16569.64453125MB
INFO:root:[   43] Training loss: 0.94743478, Validation loss: 0.94810207, Gradient norm: 0.29118980
INFO:root:At the start of the epoch: mem (CPU python)=16863.9609375MB; mem (CPU total)=16607.7890625MB
INFO:root:[   44] Training loss: 0.94716092, Validation loss: 0.94709357, Gradient norm: 0.28429880
INFO:root:At the start of the epoch: mem (CPU python)=16902.05859375MB; mem (CPU total)=16646.0625MB
INFO:root:[   45] Training loss: 0.94703550, Validation loss: 0.94768949, Gradient norm: 0.28329675
INFO:root:At the start of the epoch: mem (CPU python)=16940.15234375MB; mem (CPU total)=16684.2890625MB
INFO:root:[   46] Training loss: 0.94662992, Validation loss: 0.94681649, Gradient norm: 0.26760960
INFO:root:At the start of the epoch: mem (CPU python)=16978.24609375MB; mem (CPU total)=16722.5625MB
INFO:root:[   47] Training loss: 0.94654155, Validation loss: 0.94729808, Gradient norm: 0.29759114
INFO:root:At the start of the epoch: mem (CPU python)=17016.34375MB; mem (CPU total)=16760.953125MB
INFO:root:[   48] Training loss: 0.94636444, Validation loss: 0.94667685, Gradient norm: 0.30744618
INFO:root:At the start of the epoch: mem (CPU python)=17054.4375MB; mem (CPU total)=16799.0703125MB
INFO:root:[   49] Training loss: 0.94614865, Validation loss: 0.94640344, Gradient norm: 0.30485969
INFO:root:At the start of the epoch: mem (CPU python)=17092.53125MB; mem (CPU total)=16837.6484375MB
INFO:root:[   50] Training loss: 0.94602377, Validation loss: 0.94641444, Gradient norm: 0.30263766
INFO:root:At the start of the epoch: mem (CPU python)=17130.62890625MB; mem (CPU total)=16876.03125MB
INFO:root:[   51] Training loss: 0.94571219, Validation loss: 0.94618376, Gradient norm: 0.29573680
INFO:root:At the start of the epoch: mem (CPU python)=17168.7265625MB; mem (CPU total)=16913.890625MB
INFO:root:[   52] Training loss: 0.94552942, Validation loss: 0.94552412, Gradient norm: 0.30619776
INFO:root:At the start of the epoch: mem (CPU python)=17206.8203125MB; mem (CPU total)=16952.02734375MB
INFO:root:[   53] Training loss: 0.94550038, Validation loss: 0.94547717, Gradient norm: 0.31676426
INFO:root:At the start of the epoch: mem (CPU python)=17244.91796875MB; mem (CPU total)=16990.19921875MB
INFO:root:[   54] Training loss: 0.94498065, Validation loss: 0.94566976, Gradient norm: 0.27694852
INFO:root:At the start of the epoch: mem (CPU python)=17283.01171875MB; mem (CPU total)=17027.66015625MB
INFO:root:[   55] Training loss: 0.94508331, Validation loss: 0.94527549, Gradient norm: 0.32604863
INFO:root:At the start of the epoch: mem (CPU python)=17321.10546875MB; mem (CPU total)=17065.65234375MB
INFO:root:[   56] Training loss: 0.94470474, Validation loss: 0.94499377, Gradient norm: 0.29104204
INFO:root:At the start of the epoch: mem (CPU python)=17359.19921875MB; mem (CPU total)=17103.8828125MB
INFO:root:[   57] Training loss: 0.94447889, Validation loss: 0.94584291, Gradient norm: 0.31309579
INFO:root:At the start of the epoch: mem (CPU python)=17397.296875MB; mem (CPU total)=17142.2734375MB
INFO:root:[   58] Training loss: 0.94424284, Validation loss: 0.94463642, Gradient norm: 0.30444877
INFO:root:At the start of the epoch: mem (CPU python)=17435.390625MB; mem (CPU total)=17180.7578125MB
INFO:root:[   59] Training loss: 0.94397026, Validation loss: 0.94424469, Gradient norm: 0.31984549
INFO:root:At the start of the epoch: mem (CPU python)=17473.48828125MB; mem (CPU total)=17219.07421875MB
INFO:root:[   60] Training loss: 0.94379876, Validation loss: 0.94423254, Gradient norm: 0.30465626
INFO:root:At the start of the epoch: mem (CPU python)=17511.5859375MB; mem (CPU total)=17257.60546875MB
INFO:root:[   61] Training loss: 0.94364687, Validation loss: 0.94339331, Gradient norm: 0.33904705
INFO:root:At the start of the epoch: mem (CPU python)=17549.6796875MB; mem (CPU total)=17295.4140625MB
INFO:root:[   62] Training loss: 0.94336853, Validation loss: 0.94417576, Gradient norm: 0.31294246
INFO:root:At the start of the epoch: mem (CPU python)=17587.76953125MB; mem (CPU total)=17333.8046875MB
INFO:root:[   63] Training loss: 0.94292827, Validation loss: 0.94460517, Gradient norm: 0.30654459
INFO:root:At the start of the epoch: mem (CPU python)=17625.86328125MB; mem (CPU total)=17371.91796875MB
INFO:root:[   64] Training loss: 0.94282010, Validation loss: 0.94324101, Gradient norm: 0.33705345
INFO:root:At the start of the epoch: mem (CPU python)=17663.96484375MB; mem (CPU total)=17410.359375MB
INFO:root:[   65] Training loss: 0.94254710, Validation loss: 0.94320706, Gradient norm: 0.32720505
INFO:root:At the start of the epoch: mem (CPU python)=17702.05859375MB; mem (CPU total)=17447.546875MB
INFO:root:[   66] Training loss: 0.94216549, Validation loss: 0.94261790, Gradient norm: 0.32118410
INFO:root:At the start of the epoch: mem (CPU python)=17740.15234375MB; mem (CPU total)=17485.49609375MB
INFO:root:[   67] Training loss: 0.94201466, Validation loss: 0.94230827, Gradient norm: 0.34165046
INFO:root:At the start of the epoch: mem (CPU python)=17778.25MB; mem (CPU total)=17523.76171875MB
INFO:root:[   68] Training loss: 0.94168942, Validation loss: 0.94213254, Gradient norm: 0.34182614
INFO:root:At the start of the epoch: mem (CPU python)=17816.34375MB; mem (CPU total)=17562.05859375MB
INFO:root:[   69] Training loss: 0.94125348, Validation loss: 0.94091342, Gradient norm: 0.31746922
INFO:root:At the start of the epoch: mem (CPU python)=17854.44140625MB; mem (CPU total)=17599.42578125MB
INFO:root:[   70] Training loss: 0.94112800, Validation loss: 0.94135127, Gradient norm: 0.34206903
INFO:root:At the start of the epoch: mem (CPU python)=17892.5390625MB; mem (CPU total)=17637.81640625MB
INFO:root:[   71] Training loss: 0.94069311, Validation loss: 0.94094817, Gradient norm: 0.32266505
INFO:root:At the start of the epoch: mem (CPU python)=17930.6328125MB; mem (CPU total)=17675.9609375MB
INFO:root:[   72] Training loss: 0.94072026, Validation loss: 0.94135424, Gradient norm: 0.33371439
INFO:root:At the start of the epoch: mem (CPU python)=17968.7265625MB; mem (CPU total)=17713.828125MB
INFO:root:[   73] Training loss: 0.94027584, Validation loss: 0.94124709, Gradient norm: 0.34164674
INFO:root:At the start of the epoch: mem (CPU python)=18006.8203125MB; mem (CPU total)=17751.97265625MB
INFO:root:[   74] Training loss: 0.94011080, Validation loss: 0.94048651, Gradient norm: 0.33596327
INFO:root:At the start of the epoch: mem (CPU python)=18044.91796875MB; mem (CPU total)=17790.38671875MB
INFO:root:[   75] Training loss: 0.93987048, Validation loss: 0.93960413, Gradient norm: 0.35149815
INFO:root:At the start of the epoch: mem (CPU python)=18083.015625MB; mem (CPU total)=17828.73828125MB
INFO:root:[   76] Training loss: 0.93957317, Validation loss: 0.93928181, Gradient norm: 0.33703588
INFO:root:At the start of the epoch: mem (CPU python)=18121.109375MB; mem (CPU total)=17867.0703125MB
INFO:root:[   77] Training loss: 0.93954600, Validation loss: 0.93972144, Gradient norm: 0.35211705
INFO:root:At the start of the epoch: mem (CPU python)=18159.203125MB; mem (CPU total)=17905.4609375MB
INFO:root:[   78] Training loss: 0.93938043, Validation loss: 0.93956680, Gradient norm: 0.33549378
INFO:root:At the start of the epoch: mem (CPU python)=18197.30078125MB; mem (CPU total)=17943.16015625MB
INFO:root:[   79] Training loss: 0.93918453, Validation loss: 0.93964975, Gradient norm: 0.34169508
INFO:root:At the start of the epoch: mem (CPU python)=18235.39453125MB; mem (CPU total)=17982.875MB
INFO:root:[   80] Training loss: 0.93901167, Validation loss: 0.93873075, Gradient norm: 0.34797642
INFO:root:At the start of the epoch: mem (CPU python)=18273.48828125MB; mem (CPU total)=18020.79296875MB
INFO:root:[   81] Training loss: 0.93882256, Validation loss: 0.93853845, Gradient norm: 0.35644620
INFO:root:At the start of the epoch: mem (CPU python)=18311.5859375MB; mem (CPU total)=18058.71875MB
INFO:root:[   82] Training loss: 0.93849048, Validation loss: 0.93899334, Gradient norm: 0.33294046
INFO:root:At the start of the epoch: mem (CPU python)=18349.6796875MB; mem (CPU total)=18096.81640625MB
INFO:root:[   83] Training loss: 0.93860137, Validation loss: 0.93823776, Gradient norm: 0.36862674
INFO:root:At the start of the epoch: mem (CPU python)=18387.78125MB; mem (CPU total)=18135.72265625MB
INFO:root:[   84] Training loss: 0.93814333, Validation loss: 0.93894104, Gradient norm: 0.31778211
INFO:root:At the start of the epoch: mem (CPU python)=18425.875MB; mem (CPU total)=18173.19921875MB
INFO:root:[   85] Training loss: 0.93814572, Validation loss: 0.93890943, Gradient norm: 0.34560949
INFO:root:At the start of the epoch: mem (CPU python)=18463.96875MB; mem (CPU total)=18211.13671875MB
INFO:root:[   86] Training loss: 0.93804760, Validation loss: 0.93810113, Gradient norm: 0.35233688
INFO:root:At the start of the epoch: mem (CPU python)=18502.06640625MB; mem (CPU total)=18249.08203125MB
INFO:root:[   87] Training loss: 0.93795989, Validation loss: 0.93847593, Gradient norm: 0.36042277
INFO:root:At the start of the epoch: mem (CPU python)=18540.1640625MB; mem (CPU total)=18287.47265625MB
INFO:root:[   88] Training loss: 0.93764872, Validation loss: 0.93763648, Gradient norm: 0.34280273
INFO:root:At the start of the epoch: mem (CPU python)=18578.2578125MB; mem (CPU total)=18325.40234375MB
INFO:root:[   89] Training loss: 0.93748643, Validation loss: 0.93877553, Gradient norm: 0.34132202
INFO:root:At the start of the epoch: mem (CPU python)=18616.3515625MB; mem (CPU total)=18363.78515625MB
INFO:root:[   90] Training loss: 0.93745744, Validation loss: 0.93763287, Gradient norm: 0.32400738
INFO:root:At the start of the epoch: mem (CPU python)=18654.44921875MB; mem (CPU total)=18402.1015625MB
INFO:root:[   91] Training loss: 0.93745018, Validation loss: 0.93667743, Gradient norm: 0.36474512
INFO:root:At the start of the epoch: mem (CPU python)=18692.54296875MB; mem (CPU total)=18440.13671875MB
INFO:root:[   92] Training loss: 0.93727949, Validation loss: 0.93642102, Gradient norm: 0.35062531
INFO:root:At the start of the epoch: mem (CPU python)=18730.640625MB; mem (CPU total)=18478.3515625MB
INFO:root:[   93] Training loss: 0.93727327, Validation loss: 0.93722664, Gradient norm: 0.36498862
INFO:root:At the start of the epoch: mem (CPU python)=18768.73046875MB; mem (CPU total)=18516.3203125MB
INFO:root:[   94] Training loss: 0.93719789, Validation loss: 0.93749163, Gradient norm: 0.37152655
INFO:root:At the start of the epoch: mem (CPU python)=18806.83203125MB; mem (CPU total)=18554.32421875MB
INFO:root:[   95] Training loss: 0.93687455, Validation loss: 0.93679736, Gradient norm: 0.33532759
INFO:root:At the start of the epoch: mem (CPU python)=18844.921875MB; mem (CPU total)=18592.94921875MB
INFO:root:[   96] Training loss: 0.93679384, Validation loss: 0.93664311, Gradient norm: 0.34847301
INFO:root:At the start of the epoch: mem (CPU python)=18883.01953125MB; mem (CPU total)=18630.984375MB
INFO:root:[   97] Training loss: 0.93681259, Validation loss: 0.94060282, Gradient norm: 0.36604985
INFO:root:At the start of the epoch: mem (CPU python)=18921.11328125MB; mem (CPU total)=18669.2734375MB
INFO:root:[   98] Training loss: 0.93661229, Validation loss: 0.93633436, Gradient norm: 0.35449159
INFO:root:At the start of the epoch: mem (CPU python)=18959.2109375MB; mem (CPU total)=18707.60546875MB
INFO:root:[   99] Training loss: 0.93647801, Validation loss: 0.93669074, Gradient norm: 0.34595235
INFO:root:At the start of the epoch: mem (CPU python)=18997.3046875MB; mem (CPU total)=18745.98828125MB
INFO:root:[  100] Training loss: 0.93639572, Validation loss: 0.93620887, Gradient norm: 0.35471728
INFO:root:At the start of the epoch: mem (CPU python)=19035.40234375MB; mem (CPU total)=18784.1171875MB
INFO:root:[  101] Training loss: 0.93626174, Validation loss: 0.93657350, Gradient norm: 0.34155131
INFO:root:At the start of the epoch: mem (CPU python)=19073.49609375MB; mem (CPU total)=18822.5078125MB
INFO:root:[  102] Training loss: 0.93619295, Validation loss: 0.93673385, Gradient norm: 0.35670363
INFO:root:At the start of the epoch: mem (CPU python)=19111.58984375MB; mem (CPU total)=18860.65234375MB
INFO:root:[  103] Training loss: 0.93621532, Validation loss: 0.93739560, Gradient norm: 0.36448320
INFO:root:At the start of the epoch: mem (CPU python)=19149.6875MB; mem (CPU total)=18898.63671875MB
INFO:root:[  104] Training loss: 0.93636464, Validation loss: 0.93617145, Gradient norm: 0.36333922
INFO:root:At the start of the epoch: mem (CPU python)=19187.78515625MB; mem (CPU total)=18936.5625MB
INFO:root:[  105] Training loss: 0.93592655, Validation loss: 0.93584140, Gradient norm: 0.35370836
INFO:root:At the start of the epoch: mem (CPU python)=19225.87890625MB; mem (CPU total)=18973.65625MB
INFO:root:[  106] Training loss: 0.93598846, Validation loss: 0.93605162, Gradient norm: 0.37100212
INFO:root:At the start of the epoch: mem (CPU python)=19263.97265625MB; mem (CPU total)=19011.80078125MB
INFO:root:[  107] Training loss: 0.93573628, Validation loss: 0.93720034, Gradient norm: 0.34357834
INFO:root:At the start of the epoch: mem (CPU python)=19302.06640625MB; mem (CPU total)=19049.9765625MB
INFO:root:[  108] Training loss: 0.93564861, Validation loss: 0.93604285, Gradient norm: 0.35555257
INFO:root:At the start of the epoch: mem (CPU python)=19340.1640625MB; mem (CPU total)=19088.35546875MB
INFO:root:[  109] Training loss: 0.93555864, Validation loss: 0.93594616, Gradient norm: 0.35233341
INFO:root:At the start of the epoch: mem (CPU python)=19378.2578125MB; mem (CPU total)=19126.73828125MB
INFO:root:[  110] Training loss: 0.93557385, Validation loss: 0.93617219, Gradient norm: 0.35973634
INFO:root:At the start of the epoch: mem (CPU python)=19416.3515625MB; mem (CPU total)=19164.54296875MB
INFO:root:[  111] Training loss: 0.93551545, Validation loss: 0.93561788, Gradient norm: 0.35833742
INFO:root:At the start of the epoch: mem (CPU python)=19454.453125MB; mem (CPU total)=19203.2421875MB
INFO:root:[  112] Training loss: 0.93538518, Validation loss: 0.93513641, Gradient norm: 0.36368867
INFO:root:At the start of the epoch: mem (CPU python)=19492.546875MB; mem (CPU total)=19239.609375MB
INFO:root:[  113] Training loss: 0.93526200, Validation loss: 0.93568357, Gradient norm: 0.33978270
INFO:root:At the start of the epoch: mem (CPU python)=19530.640625MB; mem (CPU total)=19277.64453125MB
INFO:root:[  114] Training loss: 0.93530287, Validation loss: 0.93562482, Gradient norm: 0.35914080
INFO:root:At the start of the epoch: mem (CPU python)=19568.734375MB; mem (CPU total)=19315.8125MB
INFO:root:[  115] Training loss: 0.93508613, Validation loss: 0.93588859, Gradient norm: 0.34325087
INFO:root:At the start of the epoch: mem (CPU python)=19606.83203125MB; mem (CPU total)=19353.953125MB
INFO:root:[  116] Training loss: 0.93514492, Validation loss: 0.93551217, Gradient norm: 0.35985166
INFO:root:At the start of the epoch: mem (CPU python)=19644.92578125MB; mem (CPU total)=19392.22265625MB
INFO:root:[  117] Training loss: 0.93493267, Validation loss: 0.93507423, Gradient norm: 0.34354775
INFO:root:At the start of the epoch: mem (CPU python)=19683.0234375MB; mem (CPU total)=19428.91796875MB
INFO:root:[  118] Training loss: 0.93505942, Validation loss: 0.93543339, Gradient norm: 0.35484589
INFO:root:At the start of the epoch: mem (CPU python)=19721.1171875MB; mem (CPU total)=19467.08203125MB
INFO:root:[  119] Training loss: 0.93489056, Validation loss: 0.93558325, Gradient norm: 0.36344527
INFO:root:At the start of the epoch: mem (CPU python)=19759.2109375MB; mem (CPU total)=19505.49609375MB
INFO:root:[  120] Training loss: 0.93464571, Validation loss: 0.93484384, Gradient norm: 0.34089408
INFO:root:At the start of the epoch: mem (CPU python)=19797.30859375MB; mem (CPU total)=19543.40234375MB
INFO:root:[  121] Training loss: 0.93476618, Validation loss: 0.93534187, Gradient norm: 0.35415534
INFO:root:At the start of the epoch: mem (CPU python)=19835.40625MB; mem (CPU total)=19581.81640625MB
INFO:root:[  122] Training loss: 0.93471046, Validation loss: 0.93527295, Gradient norm: 0.36775350
INFO:root:At the start of the epoch: mem (CPU python)=19873.5MB; mem (CPU total)=19620.28125MB
INFO:root:[  123] Training loss: 0.93470356, Validation loss: 0.93517896, Gradient norm: 0.36377665
INFO:root:At the start of the epoch: mem (CPU python)=19911.59375MB; mem (CPU total)=19658.35546875MB
INFO:root:[  124] Training loss: 0.93449511, Validation loss: 0.93525009, Gradient norm: 0.34775887
INFO:root:At the start of the epoch: mem (CPU python)=19949.6875MB; mem (CPU total)=19696.27734375MB
INFO:root:[  125] Training loss: 0.93433367, Validation loss: 0.93452405, Gradient norm: 0.33919862
INFO:root:At the start of the epoch: mem (CPU python)=19987.79296875MB; mem (CPU total)=19734.69140625MB
INFO:root:[  126] Training loss: 0.93436510, Validation loss: 0.93418117, Gradient norm: 0.33831966
INFO:root:At the start of the epoch: mem (CPU python)=20025.88671875MB; mem (CPU total)=19771.9375MB
INFO:root:[  127] Training loss: 0.93435229, Validation loss: 0.93699795, Gradient norm: 0.35467661
INFO:root:At the start of the epoch: mem (CPU python)=20063.9765625MB; mem (CPU total)=19810.140625MB
INFO:root:[  128] Training loss: 0.93433841, Validation loss: 0.93457320, Gradient norm: 0.36022033
INFO:root:At the start of the epoch: mem (CPU python)=20102.07421875MB; mem (CPU total)=19847.80859375MB
INFO:root:[  129] Training loss: 0.93416374, Validation loss: 0.93477651, Gradient norm: 0.33903921
INFO:root:At the start of the epoch: mem (CPU python)=20140.171875MB; mem (CPU total)=19885.9765625MB
INFO:root:[  130] Training loss: 0.93413327, Validation loss: 0.93525894, Gradient norm: 0.32728529
INFO:root:At the start of the epoch: mem (CPU python)=20178.26171875MB; mem (CPU total)=19924.359375MB
INFO:root:[  131] Training loss: 0.93406254, Validation loss: 0.93427067, Gradient norm: 0.34284183
INFO:root:At the start of the epoch: mem (CPU python)=20216.359375MB; mem (CPU total)=19962.54296875MB
INFO:root:[  132] Training loss: 0.93407653, Validation loss: 0.93457044, Gradient norm: 0.34642524
INFO:root:At the start of the epoch: mem (CPU python)=20254.45703125MB; mem (CPU total)=20000.37109375MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  133] Training loss: 0.93408501, Validation loss: 0.93401789, Gradient norm: 0.34542257
INFO:root:At the start of the epoch: mem (CPU python)=20292.55078125MB; mem (CPU total)=20038.140625MB
INFO:root:[  134] Training loss: 0.93221734, Validation loss: 0.93313555, Gradient norm: 0.29045747
INFO:root:At the start of the epoch: mem (CPU python)=20330.64453125MB; mem (CPU total)=20076.65234375MB
INFO:root:[  135] Training loss: 0.93230113, Validation loss: 0.93391678, Gradient norm: 0.33701733
INFO:root:At the start of the epoch: mem (CPU python)=20368.7421875MB; mem (CPU total)=20114.84765625MB
INFO:root:[  136] Training loss: 0.93208079, Validation loss: 0.93293462, Gradient norm: 0.30104094
INFO:root:At the start of the epoch: mem (CPU python)=20406.83984375MB; mem (CPU total)=20153.14453125MB
INFO:root:[  137] Training loss: 0.93202696, Validation loss: 0.93349778, Gradient norm: 0.31241066
INFO:root:At the start of the epoch: mem (CPU python)=20444.9296875MB; mem (CPU total)=20191.72265625MB
INFO:root:[  138] Training loss: 0.93197791, Validation loss: 0.93298339, Gradient norm: 0.29465202
INFO:root:At the start of the epoch: mem (CPU python)=20483.03125MB; mem (CPU total)=20229.22265625MB
INFO:root:[  139] Training loss: 0.93210062, Validation loss: 0.93302261, Gradient norm: 0.32823811
INFO:root:At the start of the epoch: mem (CPU python)=20521.125MB; mem (CPU total)=20267.390625MB
INFO:root:[  140] Training loss: 0.93183236, Validation loss: 0.93275681, Gradient norm: 0.31135932
INFO:root:At the start of the epoch: mem (CPU python)=20559.21875MB; mem (CPU total)=20305.55859375MB
INFO:root:[  141] Training loss: 0.93195312, Validation loss: 0.93310082, Gradient norm: 0.30984376
INFO:root:At the start of the epoch: mem (CPU python)=20597.3125MB; mem (CPU total)=20343.4453125MB
INFO:root:[  142] Training loss: 0.93198999, Validation loss: 0.93294502, Gradient norm: 0.31401122
INFO:root:At the start of the epoch: mem (CPU python)=20635.41015625MB; mem (CPU total)=20381.60546875MB
INFO:root:[  143] Training loss: 0.93190071, Validation loss: 0.93327135, Gradient norm: 0.34026470
INFO:root:At the start of the epoch: mem (CPU python)=20673.50390625MB; mem (CPU total)=20420.16796875MB
INFO:root:[  144] Training loss: 0.93180225, Validation loss: 0.93326267, Gradient norm: 0.32518593
INFO:root:At the start of the epoch: mem (CPU python)=20711.59765625MB; mem (CPU total)=20457.9453125MB
INFO:root:[  145] Training loss: 0.93176391, Validation loss: 0.93285726, Gradient norm: 0.33044159
INFO:root:At the start of the epoch: mem (CPU python)=20749.6953125MB; mem (CPU total)=20496.265625MB
INFO:root:[  146] Training loss: 0.93168403, Validation loss: 0.93266275, Gradient norm: 0.32119450
INFO:root:At the start of the epoch: mem (CPU python)=20787.79296875MB; mem (CPU total)=20535.16796875MB
INFO:root:[  147] Training loss: 0.93160172, Validation loss: 0.93319734, Gradient norm: 0.32646119
INFO:root:At the start of the epoch: mem (CPU python)=20825.88671875MB; mem (CPU total)=20572.9453125MB
INFO:root:[  148] Training loss: 0.93156717, Validation loss: 0.93225363, Gradient norm: 0.31924456
INFO:root:At the start of the epoch: mem (CPU python)=20863.984375MB; mem (CPU total)=20611.19140625MB
INFO:root:[  149] Training loss: 0.93154432, Validation loss: 0.93283447, Gradient norm: 0.32115952
INFO:root:At the start of the epoch: mem (CPU python)=20902.08203125MB; mem (CPU total)=20649.38671875MB
INFO:root:[  150] Training loss: 0.93160048, Validation loss: 0.93264206, Gradient norm: 0.32229750
INFO:root:At the start of the epoch: mem (CPU python)=20940.17578125MB; mem (CPU total)=20687.57421875MB
INFO:root:[  151] Training loss: 0.93150216, Validation loss: 0.93310890, Gradient norm: 0.32296662
INFO:root:At the start of the epoch: mem (CPU python)=20978.26953125MB; mem (CPU total)=20725.7578125MB
INFO:root:[  152] Training loss: 0.93158797, Validation loss: 0.93309763, Gradient norm: 0.34041835
INFO:root:At the start of the epoch: mem (CPU python)=21016.3671875MB; mem (CPU total)=20763.92578125MB
INFO:root:[  153] Training loss: 0.93146385, Validation loss: 0.93281960, Gradient norm: 0.32390482
INFO:root:At the start of the epoch: mem (CPU python)=21054.4609375MB; mem (CPU total)=20801.64453125MB
INFO:root:[  154] Training loss: 0.93133382, Validation loss: 0.93281795, Gradient norm: 0.32306913
INFO:root:At the start of the epoch: mem (CPU python)=21092.55859375MB; mem (CPU total)=20840.02734375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  155] Training loss: 0.93130241, Validation loss: 0.93251289, Gradient norm: 0.31615419
INFO:root:At the start of the epoch: mem (CPU python)=21130.65234375MB; mem (CPU total)=20878.1953125MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  156] Training loss: 0.93038877, Validation loss: 0.93207594, Gradient norm: 0.29121323
INFO:root:At the start of the epoch: mem (CPU python)=21168.75MB; mem (CPU total)=20916.42578125MB
INFO:root:[  157] Training loss: 0.92981566, Validation loss: 0.93218920, Gradient norm: 0.27877279
INFO:root:At the start of the epoch: mem (CPU python)=21206.84375MB; mem (CPU total)=20954.59375MB
INFO:root:[  158] Training loss: 0.92976694, Validation loss: 0.93145871, Gradient norm: 0.28284418
INFO:root:At the start of the epoch: mem (CPU python)=21244.9453125MB; mem (CPU total)=20992.67578125MB
INFO:root:[  159] Training loss: 0.92962568, Validation loss: 0.93147998, Gradient norm: 0.28297235
INFO:root:At the start of the epoch: mem (CPU python)=21283.04296875MB; mem (CPU total)=21030.7890625MB
INFO:root:[  160] Training loss: 0.92965454, Validation loss: 0.93172926, Gradient norm: 0.29752806
INFO:root:At the start of the epoch: mem (CPU python)=21321.13671875MB; mem (CPU total)=21068.44921875MB
INFO:root:[  161] Training loss: 0.92961784, Validation loss: 0.93160007, Gradient norm: 0.29718006
INFO:root:At the start of the epoch: mem (CPU python)=21359.23046875MB; mem (CPU total)=21106.86328125MB
INFO:root:[  162] Training loss: 0.92965882, Validation loss: 0.93174195, Gradient norm: 0.29719756
INFO:root:At the start of the epoch: mem (CPU python)=21397.33203125MB; mem (CPU total)=21145.03125MB
INFO:root:[  163] Training loss: 0.92968709, Validation loss: 0.93157182, Gradient norm: 0.29776005
INFO:root:At the start of the epoch: mem (CPU python)=21435.42578125MB; mem (CPU total)=21183.078125MB
INFO:root:[  164] Training loss: 0.92965856, Validation loss: 0.93169789, Gradient norm: 0.30254585
INFO:root:At the start of the epoch: mem (CPU python)=21473.51953125MB; mem (CPU total)=21221.48046875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  165] Training loss: 0.92957102, Validation loss: 0.93172124, Gradient norm: 0.30564305
INFO:root:At the start of the epoch: mem (CPU python)=21511.61328125MB; mem (CPU total)=21259.40234375MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  166] Training loss: 0.92932580, Validation loss: 0.93167676, Gradient norm: 0.29728387
INFO:root:At the start of the epoch: mem (CPU python)=21549.7109375MB; mem (CPU total)=21300.87890625MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  167] Training loss: 0.92908435, Validation loss: 0.93140749, Gradient norm: 0.28217665
INFO:root:At the start of the epoch: mem (CPU python)=21587.8125MB; mem (CPU total)=21339.703125MB
INFO:root:[  168] Training loss: 0.92898672, Validation loss: 0.93137909, Gradient norm: 0.27022140
INFO:root:At the start of the epoch: mem (CPU python)=21625.90625MB; mem (CPU total)=21377.56640625MB
INFO:root:[  169] Training loss: 0.92897611, Validation loss: 0.93135089, Gradient norm: 0.27454747
INFO:root:At the start of the epoch: mem (CPU python)=21664.0MB; mem (CPU total)=21416.359375MB
INFO:root:[  170] Training loss: 0.92896599, Validation loss: 0.93157786, Gradient norm: 0.27924963
INFO:root:At the start of the epoch: mem (CPU python)=21702.09375MB; mem (CPU total)=21454.75MB
INFO:root:[  171] Training loss: 0.92898493, Validation loss: 0.93163709, Gradient norm: 0.28379034
INFO:root:At the start of the epoch: mem (CPU python)=21740.19140625MB; mem (CPU total)=21492.89453125MB
INFO:root:[  172] Training loss: 0.92892322, Validation loss: 0.93157321, Gradient norm: 0.28875483
INFO:root:At the start of the epoch: mem (CPU python)=21778.2890625MB; mem (CPU total)=21531.03125MB
INFO:root:[  173] Training loss: 0.92898120, Validation loss: 0.93142030, Gradient norm: 0.28492771
INFO:root:At the start of the epoch: mem (CPU python)=21816.3828125MB; mem (CPU total)=21569.17578125MB
INFO:root:[  174] Training loss: 0.92897168, Validation loss: 0.93146595, Gradient norm: 0.28400201
INFO:root:At the start of the epoch: mem (CPU python)=21854.4765625MB; mem (CPU total)=21607.22265625MB
INFO:root:[  175] Training loss: 0.92895237, Validation loss: 0.93132279, Gradient norm: 0.28396362
INFO:root:At the start of the epoch: mem (CPU python)=21892.57421875MB; mem (CPU total)=21645.6171875MB
INFO:root:[  176] Training loss: 0.92891689, Validation loss: 0.93163849, Gradient norm: 0.28252873
INFO:root:At the start of the epoch: mem (CPU python)=21930.66796875MB; mem (CPU total)=21683.79296875MB
INFO:root:[  177] Training loss: 0.92895930, Validation loss: 0.93150864, Gradient norm: 0.28431009
INFO:root:At the start of the epoch: mem (CPU python)=21968.76171875MB; mem (CPU total)=21721.84375MB
INFO:root:[  178] Training loss: 0.92896798, Validation loss: 0.93111639, Gradient norm: 0.28624180
INFO:root:At the start of the epoch: mem (CPU python)=22006.859375MB; mem (CPU total)=21758.9609375MB
INFO:root:[  179] Training loss: 0.92895795, Validation loss: 0.93107342, Gradient norm: 0.27759465
INFO:root:At the start of the epoch: mem (CPU python)=22044.95703125MB; mem (CPU total)=21796.625MB
INFO:root:[  180] Training loss: 0.92896148, Validation loss: 0.93144843, Gradient norm: 0.29075120
INFO:root:At the start of the epoch: mem (CPU python)=22083.05078125MB; mem (CPU total)=21834.70703125MB
INFO:root:[  181] Training loss: 0.92893743, Validation loss: 0.93114588, Gradient norm: 0.28397434
INFO:root:At the start of the epoch: mem (CPU python)=22121.14453125MB; mem (CPU total)=21873.09765625MB
INFO:root:[  182] Training loss: 0.92890614, Validation loss: 0.93106925, Gradient norm: 0.28682611
INFO:root:At the start of the epoch: mem (CPU python)=22159.23828125MB; mem (CPU total)=21911.55078125MB
INFO:root:[  183] Training loss: 0.92897409, Validation loss: 0.93149450, Gradient norm: 0.29249118
INFO:root:At the start of the epoch: mem (CPU python)=22197.3359375MB; mem (CPU total)=21949.6640625MB
INFO:root:[  184] Training loss: 0.92893232, Validation loss: 0.93149532, Gradient norm: 0.28656797
INFO:root:At the start of the epoch: mem (CPU python)=22235.4296875MB; mem (CPU total)=21987.80859375MB
INFO:root:[  185] Training loss: 0.92899338, Validation loss: 0.93150119, Gradient norm: 0.29219058
INFO:root:At the start of the epoch: mem (CPU python)=22273.5234375MB; mem (CPU total)=22025.953125MB
INFO:root:[  186] Training loss: 0.92889913, Validation loss: 0.93133157, Gradient norm: 0.29251438
INFO:root:At the start of the epoch: mem (CPU python)=22311.62109375MB; mem (CPU total)=22063.6640625MB
INFO:root:[  187] Training loss: 0.92892967, Validation loss: 0.93173464, Gradient norm: 0.29238754
INFO:root:At the start of the epoch: mem (CPU python)=22349.71484375MB; mem (CPU total)=22101.8046875MB
INFO:root:[  188] Training loss: 0.92893156, Validation loss: 0.93097698, Gradient norm: 0.28917083
INFO:root:At the start of the epoch: mem (CPU python)=22387.8125MB; mem (CPU total)=22140.12890625MB
INFO:root:[  189] Training loss: 0.92899579, Validation loss: 0.93129726, Gradient norm: 0.28898776
INFO:root:At the start of the epoch: mem (CPU python)=22425.91015625MB; mem (CPU total)=22178.58203125MB
INFO:root:[  190] Training loss: 0.92891763, Validation loss: 0.93084084, Gradient norm: 0.29033046
INFO:root:At the start of the epoch: mem (CPU python)=22464.00390625MB; mem (CPU total)=22216.23046875MB
INFO:root:[  191] Training loss: 0.92889672, Validation loss: 0.93134349, Gradient norm: 0.29834893
INFO:root:At the start of the epoch: mem (CPU python)=22502.09765625MB; mem (CPU total)=22254.61328125MB
INFO:root:[  192] Training loss: 0.92889248, Validation loss: 0.93147336, Gradient norm: 0.28506649
INFO:root:At the start of the epoch: mem (CPU python)=22540.19140625MB; mem (CPU total)=22293.23828125MB
INFO:root:[  193] Training loss: 0.92899513, Validation loss: 0.93103919, Gradient norm: 0.29498153
INFO:root:At the start of the epoch: mem (CPU python)=22578.2890625MB; mem (CPU total)=22331.3515625MB
INFO:root:[  194] Training loss: 0.92893301, Validation loss: 0.93147997, Gradient norm: 0.29138976
INFO:root:At the start of the epoch: mem (CPU python)=22616.3828125MB; mem (CPU total)=22369.24609375MB
INFO:root:[  195] Training loss: 0.92894814, Validation loss: 0.93153047, Gradient norm: 0.29184696
INFO:root:At the start of the epoch: mem (CPU python)=22654.4765625MB; mem (CPU total)=22407.1328125MB
INFO:root:[  196] Training loss: 0.92895083, Validation loss: 0.93156998, Gradient norm: 0.29343687
INFO:root:At the start of the epoch: mem (CPU python)=22692.57421875MB; mem (CPU total)=22445.12890625MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  197] Training loss: 0.92892939, Validation loss: 0.93138328, Gradient norm: 0.29107834
INFO:root:At the start of the epoch: mem (CPU python)=22730.671875MB; mem (CPU total)=22483.05859375MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  198] Training loss: 0.92889220, Validation loss: 0.93127193, Gradient norm: 0.29326400
INFO:root:At the start of the epoch: mem (CPU python)=22768.765625MB; mem (CPU total)=22521.44921875MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  199] Training loss: 0.92883369, Validation loss: 0.93128147, Gradient norm: 0.28851981
INFO:root:At the start of the epoch: mem (CPU python)=22806.859375MB; mem (CPU total)=22559.59375MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:EP 199: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=22844.86328125MB; mem (CPU total)=22597.73828125MB
INFO:root:Training the model took 12521.371s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.9313
INFO:root:EnergyScoreTrain: 0.82296
INFO:root:CRPSTrain: 0.66106
INFO:root:Gaussian NLLTrain: 695.66059
INFO:root:CoverageTrain: 0.13514
INFO:root:IntervalWidthTrain: 0.27734
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93701
INFO:root:EnergyScoreValidation: 0.82944
INFO:root:CRPSValidation: 0.66718
INFO:root:Gaussian NLLValidation: 415.51319
INFO:root:CoverageValidation: 0.13293
INFO:root:IntervalWidthValidation: 0.27455
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93526
INFO:root:EnergyScoreTest: 0.82919
INFO:root:CRPSTest: 0.66663
INFO:root:Gaussian NLLTest: 1293.0783
INFO:root:CoverageTest: 0.13071
INFO:root:IntervalWidthTest: 0.27083
INFO:root:After validation: mem (CPU python)=22918.59375MB; mem (CPU total)=22674.484375MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=22918.59375MB; mem (CPU total)=22674.484375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=22919.9609375MB; mem (CPU total)=22675.9609375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=22920.1171875MB; mem (CPU total)=22675.9609375MB
INFO:root:[    1] Training loss: 1.00685586, Validation loss: 0.99191548, Gradient norm: 0.06348639
INFO:root:At the start of the epoch: mem (CPU python)=22957.9609375MB; mem (CPU total)=22713.859375MB
INFO:root:[    2] Training loss: 0.98446665, Validation loss: 0.98054379, Gradient norm: 0.11514021
INFO:root:At the start of the epoch: mem (CPU python)=22996.05859375MB; mem (CPU total)=22751.92578125MB
INFO:root:[    3] Training loss: 0.97783726, Validation loss: 0.97655752, Gradient norm: 0.13275185
INFO:root:At the start of the epoch: mem (CPU python)=23034.171875MB; mem (CPU total)=22790.05859375MB
INFO:root:[    4] Training loss: 0.97431390, Validation loss: 0.97354437, Gradient norm: 0.15609293
INFO:root:At the start of the epoch: mem (CPU python)=23072.26953125MB; mem (CPU total)=22827.921875MB
INFO:root:[    5] Training loss: 0.97144755, Validation loss: 0.97112609, Gradient norm: 0.16969995
INFO:root:At the start of the epoch: mem (CPU python)=23110.36328125MB; mem (CPU total)=22866.140625MB
INFO:root:[    6] Training loss: 0.96946769, Validation loss: 0.96964590, Gradient norm: 0.17566994
INFO:root:At the start of the epoch: mem (CPU python)=23148.4609375MB; mem (CPU total)=22904.3828125MB
INFO:root:[    7] Training loss: 0.96791913, Validation loss: 0.96686866, Gradient norm: 0.17142302
INFO:root:At the start of the epoch: mem (CPU python)=23186.5546875MB; mem (CPU total)=22942.390625MB
INFO:root:[    8] Training loss: 0.96602361, Validation loss: 0.96459043, Gradient norm: 0.18450120
INFO:root:At the start of the epoch: mem (CPU python)=23224.65234375MB; mem (CPU total)=22980.4921875MB
INFO:root:[    9] Training loss: 0.96422103, Validation loss: 0.96351459, Gradient norm: 0.18682014
INFO:root:At the start of the epoch: mem (CPU python)=23262.75MB; mem (CPU total)=23018.17578125MB
INFO:root:[   10] Training loss: 0.96291131, Validation loss: 0.96300725, Gradient norm: 0.17978070
INFO:root:At the start of the epoch: mem (CPU python)=23300.8359375MB; mem (CPU total)=23056.3671875MB
INFO:root:[   11] Training loss: 0.96174801, Validation loss: 0.96151616, Gradient norm: 0.18886348
INFO:root:At the start of the epoch: mem (CPU python)=23338.9296875MB; mem (CPU total)=23094.81640625MB
INFO:root:[   12] Training loss: 0.96064448, Validation loss: 0.95982761, Gradient norm: 0.20405742
INFO:root:At the start of the epoch: mem (CPU python)=23377.0234375MB; mem (CPU total)=23133.26953125MB
INFO:root:[   13] Training loss: 0.95985923, Validation loss: 0.95898495, Gradient norm: 0.21928878
INFO:root:At the start of the epoch: mem (CPU python)=23415.12109375MB; mem (CPU total)=23170.23046875MB
INFO:root:[   14] Training loss: 0.95879937, Validation loss: 0.95826269, Gradient norm: 0.20782359
INFO:root:At the start of the epoch: mem (CPU python)=23453.21484375MB; mem (CPU total)=23208.65234375MB
INFO:root:[   15] Training loss: 0.95788912, Validation loss: 0.95812289, Gradient norm: 0.21792151
INFO:root:At the start of the epoch: mem (CPU python)=23491.3125MB; mem (CPU total)=23246.875MB
INFO:root:[   16] Training loss: 0.95706057, Validation loss: 0.95689787, Gradient norm: 0.21329245
INFO:root:At the start of the epoch: mem (CPU python)=23529.40625MB; mem (CPU total)=23285.14453125MB
INFO:root:[   17] Training loss: 0.95649648, Validation loss: 0.95606208, Gradient norm: 0.22438911
INFO:root:At the start of the epoch: mem (CPU python)=23567.50390625MB; mem (CPU total)=23323.44140625MB
INFO:root:[   18] Training loss: 0.95574290, Validation loss: 0.95632584, Gradient norm: 0.23282268
INFO:root:At the start of the epoch: mem (CPU python)=23605.59375MB; mem (CPU total)=23361.83203125MB
INFO:root:[   19] Training loss: 0.95525075, Validation loss: 0.95628099, Gradient norm: 0.23132499
INFO:root:At the start of the epoch: mem (CPU python)=23643.69140625MB; mem (CPU total)=23399.421875MB
INFO:root:[   20] Training loss: 0.95453877, Validation loss: 0.95379634, Gradient norm: 0.23299955
INFO:root:At the start of the epoch: mem (CPU python)=23681.7890625MB; mem (CPU total)=23437.3125MB
INFO:root:[   21] Training loss: 0.95403430, Validation loss: 0.95428132, Gradient norm: 0.23577319
INFO:root:At the start of the epoch: mem (CPU python)=23719.8828125MB; mem (CPU total)=23475.67578125MB
INFO:root:[   22] Training loss: 0.95348705, Validation loss: 0.95356271, Gradient norm: 0.22971403
INFO:root:At the start of the epoch: mem (CPU python)=23757.98828125MB; mem (CPU total)=23514.29296875MB
INFO:root:[   23] Training loss: 0.95290081, Validation loss: 0.95302796, Gradient norm: 0.23789166
INFO:root:At the start of the epoch: mem (CPU python)=23796.0859375MB; mem (CPU total)=23551.37890625MB
INFO:root:[   24] Training loss: 0.95267903, Validation loss: 0.95308125, Gradient norm: 0.25220718
INFO:root:At the start of the epoch: mem (CPU python)=23834.17578125MB; mem (CPU total)=23589.27734375MB
INFO:root:[   25] Training loss: 0.95226272, Validation loss: 0.95180023, Gradient norm: 0.23776384
INFO:root:At the start of the epoch: mem (CPU python)=23872.2734375MB; mem (CPU total)=23627.40625MB
INFO:root:[   26] Training loss: 0.95172917, Validation loss: 0.95180841, Gradient norm: 0.24597062
INFO:root:At the start of the epoch: mem (CPU python)=23910.3671875MB; mem (CPU total)=23665.796875MB
INFO:root:[   27] Training loss: 0.95133640, Validation loss: 0.95144146, Gradient norm: 0.24201810
INFO:root:At the start of the epoch: mem (CPU python)=23948.46484375MB; mem (CPU total)=23704.08203125MB
INFO:root:[   28] Training loss: 0.95111583, Validation loss: 0.95060581, Gradient norm: 0.24118588
INFO:root:At the start of the epoch: mem (CPU python)=23986.55859375MB; mem (CPU total)=23742.47265625MB
INFO:root:[   29] Training loss: 0.95080142, Validation loss: 0.95085464, Gradient norm: 0.26610347
INFO:root:At the start of the epoch: mem (CPU python)=24024.65234375MB; mem (CPU total)=23780.73046875MB
INFO:root:[   30] Training loss: 0.95069525, Validation loss: 0.95071496, Gradient norm: 0.26188521
INFO:root:At the start of the epoch: mem (CPU python)=24062.75MB; mem (CPU total)=23818.8671875MB
INFO:root:[   31] Training loss: 0.95035507, Validation loss: 0.95109501, Gradient norm: 0.25304488
INFO:root:At the start of the epoch: mem (CPU python)=24100.84765625MB; mem (CPU total)=23857.01171875MB
INFO:root:[   32] Training loss: 0.95006674, Validation loss: 0.95032566, Gradient norm: 0.25056616
INFO:root:At the start of the epoch: mem (CPU python)=24138.94140625MB; mem (CPU total)=23895.6171875MB
INFO:root:[   33] Training loss: 0.94969409, Validation loss: 0.94998560, Gradient norm: 0.24668131
INFO:root:At the start of the epoch: mem (CPU python)=24177.03515625MB; mem (CPU total)=23933.0390625MB
INFO:root:[   34] Training loss: 0.94941982, Validation loss: 0.95007121, Gradient norm: 0.24309720
INFO:root:At the start of the epoch: mem (CPU python)=24215.1328125MB; mem (CPU total)=23970.9375MB
INFO:root:[   35] Training loss: 0.94927420, Validation loss: 0.94905929, Gradient norm: 0.24420187
INFO:root:At the start of the epoch: mem (CPU python)=24253.2265625MB; mem (CPU total)=24009.453125MB
INFO:root:[   36] Training loss: 0.94899282, Validation loss: 0.94953694, Gradient norm: 0.25971980
INFO:root:At the start of the epoch: mem (CPU python)=24291.3203125MB; mem (CPU total)=24047.84375MB
INFO:root:[   37] Training loss: 0.94875295, Validation loss: 0.94881915, Gradient norm: 0.24991639
INFO:root:At the start of the epoch: mem (CPU python)=24329.41796875MB; mem (CPU total)=24085.54296875MB
INFO:root:[   38] Training loss: 0.94868669, Validation loss: 0.95003312, Gradient norm: 0.26712855
INFO:root:At the start of the epoch: mem (CPU python)=24367.51171875MB; mem (CPU total)=24123.83984375MB
INFO:root:[   39] Training loss: 0.94844187, Validation loss: 0.94875350, Gradient norm: 0.27143014
INFO:root:At the start of the epoch: mem (CPU python)=24405.609375MB; mem (CPU total)=24161.66015625MB
INFO:root:[   40] Training loss: 0.94828775, Validation loss: 0.94851873, Gradient norm: 0.25618072
INFO:root:At the start of the epoch: mem (CPU python)=24443.70703125MB; mem (CPU total)=24200.15625MB
INFO:root:[   41] Training loss: 0.94792063, Validation loss: 0.94778590, Gradient norm: 0.25760637
INFO:root:At the start of the epoch: mem (CPU python)=24481.80078125MB; mem (CPU total)=24238.578125MB
INFO:root:[   42] Training loss: 0.94772574, Validation loss: 0.94899075, Gradient norm: 0.25684933
INFO:root:At the start of the epoch: mem (CPU python)=24519.89453125MB; mem (CPU total)=24277.1953125MB
INFO:root:[   43] Training loss: 0.94754978, Validation loss: 0.94888844, Gradient norm: 0.27274763
INFO:root:At the start of the epoch: mem (CPU python)=24557.98828125MB; mem (CPU total)=24315.09375MB
INFO:root:[   44] Training loss: 0.94748489, Validation loss: 0.94804198, Gradient norm: 0.27894938
INFO:root:At the start of the epoch: mem (CPU python)=24596.0859375MB; mem (CPU total)=24353.23828125MB
INFO:root:[   45] Training loss: 0.94719111, Validation loss: 0.94755384, Gradient norm: 0.26508144
INFO:root:At the start of the epoch: mem (CPU python)=24634.18359375MB; mem (CPU total)=24391.203125MB
INFO:root:[   46] Training loss: 0.94707553, Validation loss: 0.94707049, Gradient norm: 0.28627856
INFO:root:At the start of the epoch: mem (CPU python)=24672.27734375MB; mem (CPU total)=24428.4375MB
INFO:root:[   47] Training loss: 0.94661478, Validation loss: 0.94681274, Gradient norm: 0.27652394
INFO:root:At the start of the epoch: mem (CPU python)=24710.375MB; mem (CPU total)=24466.890625MB
INFO:root:[   48] Training loss: 0.94632675, Validation loss: 0.94655703, Gradient norm: 0.27679016
INFO:root:At the start of the epoch: mem (CPU python)=24748.46875MB; mem (CPU total)=24505.3125MB
INFO:root:[   49] Training loss: 0.94618465, Validation loss: 0.94673178, Gradient norm: 0.28724883
INFO:root:At the start of the epoch: mem (CPU python)=24786.5625MB; mem (CPU total)=24543.45703125MB
INFO:root:[   50] Training loss: 0.94591986, Validation loss: 0.94628180, Gradient norm: 0.29483507
INFO:root:At the start of the epoch: mem (CPU python)=24824.65625MB; mem (CPU total)=24581.87890625MB
INFO:root:[   51] Training loss: 0.94564153, Validation loss: 0.94538408, Gradient norm: 0.29394796
INFO:root:At the start of the epoch: mem (CPU python)=24862.75390625MB; mem (CPU total)=24619.76171875MB
INFO:root:[   52] Training loss: 0.94521230, Validation loss: 0.94556754, Gradient norm: 0.29776736
INFO:root:At the start of the epoch: mem (CPU python)=24900.84765625MB; mem (CPU total)=24658.15234375MB
INFO:root:[   53] Training loss: 0.94473698, Validation loss: 0.94504524, Gradient norm: 0.27937009
INFO:root:At the start of the epoch: mem (CPU python)=24938.9453125MB; mem (CPU total)=24696.8984375MB
INFO:root:[   54] Training loss: 0.94459768, Validation loss: 0.94469949, Gradient norm: 0.28319127
INFO:root:At the start of the epoch: mem (CPU python)=24977.046875MB; mem (CPU total)=24735.30078125MB
INFO:root:[   55] Training loss: 0.94422783, Validation loss: 0.94432198, Gradient norm: 0.27118843
INFO:root:At the start of the epoch: mem (CPU python)=25015.140625MB; mem (CPU total)=24773.52734375MB
INFO:root:[   56] Training loss: 0.94403305, Validation loss: 0.94408877, Gradient norm: 0.29447116
INFO:root:At the start of the epoch: mem (CPU python)=25053.21875MB; mem (CPU total)=24811.625MB
INFO:root:[   57] Training loss: 0.94359066, Validation loss: 0.94444389, Gradient norm: 0.28627233
INFO:root:At the start of the epoch: mem (CPU python)=25091.30859375MB; mem (CPU total)=24850.0078125MB
INFO:root:[   58] Training loss: 0.94353007, Validation loss: 0.94437084, Gradient norm: 0.28838779
INFO:root:At the start of the epoch: mem (CPU python)=25129.41015625MB; mem (CPU total)=24887.8984375MB
INFO:root:[   59] Training loss: 0.94361427, Validation loss: 0.94310902, Gradient norm: 0.30466651
INFO:root:At the start of the epoch: mem (CPU python)=25167.50390625MB; mem (CPU total)=24926.16796875MB
INFO:root:[   60] Training loss: 0.94315114, Validation loss: 0.94376274, Gradient norm: 0.29444651
INFO:root:At the start of the epoch: mem (CPU python)=25205.59765625MB; mem (CPU total)=24964.3046875MB
INFO:root:[   61] Training loss: 0.94305762, Validation loss: 0.94233020, Gradient norm: 0.31319442
INFO:root:At the start of the epoch: mem (CPU python)=25243.6953125MB; mem (CPU total)=25002.54296875MB
INFO:root:[   62] Training loss: 0.94291895, Validation loss: 0.94279965, Gradient norm: 0.29614614
INFO:root:At the start of the epoch: mem (CPU python)=25281.7890625MB; mem (CPU total)=25040.9296875MB
INFO:root:[   63] Training loss: 0.94268592, Validation loss: 0.94259605, Gradient norm: 0.30444239
INFO:root:At the start of the epoch: mem (CPU python)=25319.8828125MB; mem (CPU total)=25078.55859375MB
INFO:root:[   64] Training loss: 0.94232213, Validation loss: 0.94236073, Gradient norm: 0.27222161
INFO:root:At the start of the epoch: mem (CPU python)=25357.98046875MB; mem (CPU total)=25116.69921875MB
INFO:root:[   65] Training loss: 0.94223766, Validation loss: 0.94335651, Gradient norm: 0.27808391
INFO:root:At the start of the epoch: mem (CPU python)=25396.07421875MB; mem (CPU total)=25155.08984375MB
INFO:root:[   66] Training loss: 0.94212874, Validation loss: 0.94254390, Gradient norm: 0.29148437
INFO:root:At the start of the epoch: mem (CPU python)=25434.16796875MB; mem (CPU total)=25193.078125MB
INFO:root:[   67] Training loss: 0.94209811, Validation loss: 0.94319609, Gradient norm: 0.30477697
INFO:root:At the start of the epoch: mem (CPU python)=25472.26171875MB; mem (CPU total)=25231.22265625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   68] Training loss: 0.94193924, Validation loss: 0.94198131, Gradient norm: 0.30899621
INFO:root:At the start of the epoch: mem (CPU python)=25510.36328125MB; mem (CPU total)=25269.734375MB
INFO:root:[   69] Training loss: 0.94021933, Validation loss: 0.94034112, Gradient norm: 0.24780431
INFO:root:At the start of the epoch: mem (CPU python)=25548.45703125MB; mem (CPU total)=25307.97265625MB
INFO:root:[   70] Training loss: 0.94012329, Validation loss: 0.94113224, Gradient norm: 0.27420530
INFO:root:At the start of the epoch: mem (CPU python)=25586.546875MB; mem (CPU total)=25345.87109375MB
INFO:root:[   71] Training loss: 0.93991299, Validation loss: 0.94013638, Gradient norm: 0.24886368
INFO:root:At the start of the epoch: mem (CPU python)=25624.6484375MB; mem (CPU total)=25383.8984375MB
INFO:root:[   72] Training loss: 0.93982661, Validation loss: 0.94060527, Gradient norm: 0.26985846
INFO:root:At the start of the epoch: mem (CPU python)=25662.73828125MB; mem (CPU total)=25422.03515625MB
INFO:root:[   73] Training loss: 0.93985821, Validation loss: 0.94008011, Gradient norm: 0.27078327
INFO:root:At the start of the epoch: mem (CPU python)=25700.83984375MB; mem (CPU total)=25460.1796875MB
INFO:root:[   74] Training loss: 0.93962391, Validation loss: 0.94054412, Gradient norm: 0.25514524
INFO:root:At the start of the epoch: mem (CPU python)=25738.93359375MB; mem (CPU total)=25498.32421875MB
INFO:root:[   75] Training loss: 0.93965487, Validation loss: 0.94020068, Gradient norm: 0.27817547
INFO:root:At the start of the epoch: mem (CPU python)=25777.03125MB; mem (CPU total)=25536.46875MB
INFO:root:[   76] Training loss: 0.93955855, Validation loss: 0.93986564, Gradient norm: 0.26808839
INFO:root:At the start of the epoch: mem (CPU python)=25815.125MB; mem (CPU total)=25574.984375MB
INFO:root:[   77] Training loss: 0.93945502, Validation loss: 0.94028650, Gradient norm: 0.26745811
INFO:root:At the start of the epoch: mem (CPU python)=25853.21875MB; mem (CPU total)=25613.11328125MB
INFO:root:[   78] Training loss: 0.93943107, Validation loss: 0.94005561, Gradient norm: 0.28160859
INFO:root:At the start of the epoch: mem (CPU python)=25891.31640625MB; mem (CPU total)=25651.2578125MB
INFO:root:[   79] Training loss: 0.93931559, Validation loss: 0.94001336, Gradient norm: 0.27182445
INFO:root:At the start of the epoch: mem (CPU python)=25929.41015625MB; mem (CPU total)=25689.703125MB
INFO:root:[   80] Training loss: 0.93925947, Validation loss: 0.93968982, Gradient norm: 0.26392297
INFO:root:At the start of the epoch: mem (CPU python)=25967.50390625MB; mem (CPU total)=25727.765625MB
INFO:root:[   81] Training loss: 0.93922847, Validation loss: 0.94007593, Gradient norm: 0.26842121
INFO:root:At the start of the epoch: mem (CPU python)=26005.60546875MB; mem (CPU total)=25765.91015625MB
INFO:root:[   82] Training loss: 0.93915342, Validation loss: 0.94001253, Gradient norm: 0.28307801
INFO:root:At the start of the epoch: mem (CPU python)=26043.69921875MB; mem (CPU total)=25804.296875MB
INFO:root:[   83] Training loss: 0.93910306, Validation loss: 0.94000860, Gradient norm: 0.26964843
INFO:root:At the start of the epoch: mem (CPU python)=26081.79296875MB; mem (CPU total)=25842.44140625MB
INFO:root:[   84] Training loss: 0.93896404, Validation loss: 0.93931291, Gradient norm: 0.27179882
INFO:root:At the start of the epoch: mem (CPU python)=26119.88671875MB; mem (CPU total)=25880.87890625MB
INFO:root:[   85] Training loss: 0.93887211, Validation loss: 0.93944467, Gradient norm: 0.27402333
INFO:root:At the start of the epoch: mem (CPU python)=26157.984375MB; mem (CPU total)=25919.0234375MB
INFO:root:[   86] Training loss: 0.93872398, Validation loss: 0.93950391, Gradient norm: 0.25232589
INFO:root:At the start of the epoch: mem (CPU python)=26196.078125MB; mem (CPU total)=25957.16796875MB
INFO:root:[   87] Training loss: 0.93865798, Validation loss: 0.93966936, Gradient norm: 0.26200381
INFO:root:At the start of the epoch: mem (CPU python)=26234.171875MB; mem (CPU total)=25995.3125MB
INFO:root:[   88] Training loss: 0.93875014, Validation loss: 0.93930424, Gradient norm: 0.29519741
INFO:root:At the start of the epoch: mem (CPU python)=26272.2734375MB; mem (CPU total)=26033.24609375MB
INFO:root:[   89] Training loss: 0.93867090, Validation loss: 0.93945180, Gradient norm: 0.27639004
INFO:root:At the start of the epoch: mem (CPU python)=26310.3671875MB; mem (CPU total)=26071.17578125MB
INFO:root:[   90] Training loss: 0.93856405, Validation loss: 0.93969228, Gradient norm: 0.27840048
INFO:root:At the start of the epoch: mem (CPU python)=26348.45703125MB; mem (CPU total)=26109.56640625MB
INFO:root:[   91] Training loss: 0.93842633, Validation loss: 0.93945645, Gradient norm: 0.27788726
INFO:root:At the start of the epoch: mem (CPU python)=26386.55859375MB; mem (CPU total)=26147.7109375MB
INFO:root:[   92] Training loss: 0.93837702, Validation loss: 0.93908484, Gradient norm: 0.26595513
INFO:root:At the start of the epoch: mem (CPU python)=26424.65234375MB; mem (CPU total)=26186.1015625MB
INFO:root:[   93] Training loss: 0.93827095, Validation loss: 0.93899378, Gradient norm: 0.27976474
INFO:root:At the start of the epoch: mem (CPU python)=26462.74609375MB; mem (CPU total)=26225.03515625MB
INFO:root:[   94] Training loss: 0.93828815, Validation loss: 0.93899771, Gradient norm: 0.27346344
INFO:root:At the start of the epoch: mem (CPU python)=26500.83984375MB; mem (CPU total)=26263.453125MB
INFO:root:[   95] Training loss: 0.93822310, Validation loss: 0.93913330, Gradient norm: 0.29124415
INFO:root:At the start of the epoch: mem (CPU python)=26538.9375MB; mem (CPU total)=26301.625MB
INFO:root:[   96] Training loss: 0.93816929, Validation loss: 0.93933878, Gradient norm: 0.28860335
INFO:root:At the start of the epoch: mem (CPU python)=26577.03125MB; mem (CPU total)=26339.1953125MB
INFO:root:[   97] Training loss: 0.93811550, Validation loss: 0.93881914, Gradient norm: 0.28459624
INFO:root:At the start of the epoch: mem (CPU python)=26615.12890625MB; mem (CPU total)=26377.4453125MB
INFO:root:[   98] Training loss: 0.93798286, Validation loss: 0.93903224, Gradient norm: 0.27781598
INFO:root:At the start of the epoch: mem (CPU python)=26653.2265625MB; mem (CPU total)=26415.609375MB
INFO:root:[   99] Training loss: 0.93800085, Validation loss: 0.93871909, Gradient norm: 0.28178499
INFO:root:At the start of the epoch: mem (CPU python)=26691.3203125MB; mem (CPU total)=26453.3203125MB
INFO:root:[  100] Training loss: 0.93795789, Validation loss: 0.93842124, Gradient norm: 0.27322070
INFO:root:At the start of the epoch: mem (CPU python)=26729.4140625MB; mem (CPU total)=26491.6171875MB
INFO:root:[  101] Training loss: 0.93788420, Validation loss: 0.93853174, Gradient norm: 0.29717099
INFO:root:At the start of the epoch: mem (CPU python)=26767.5078125MB; mem (CPU total)=26529.7265625MB
INFO:root:[  102] Training loss: 0.93780056, Validation loss: 0.93882192, Gradient norm: 0.26595651
INFO:root:At the start of the epoch: mem (CPU python)=26805.60546875MB; mem (CPU total)=26567.8984375MB
INFO:root:[  103] Training loss: 0.93776390, Validation loss: 0.93921112, Gradient norm: 0.29778676
INFO:root:At the start of the epoch: mem (CPU python)=26843.69921875MB; mem (CPU total)=26605.81640625MB
INFO:root:[  104] Training loss: 0.93760809, Validation loss: 0.93931976, Gradient norm: 0.27591647
INFO:root:At the start of the epoch: mem (CPU python)=26881.79296875MB; mem (CPU total)=26643.94921875MB
INFO:root:[  105] Training loss: 0.93759822, Validation loss: 0.93818880, Gradient norm: 0.27406279
INFO:root:At the start of the epoch: mem (CPU python)=26919.89453125MB; mem (CPU total)=26682.3671875MB
INFO:root:[  106] Training loss: 0.93749087, Validation loss: 0.93861168, Gradient norm: 0.27699097
INFO:root:At the start of the epoch: mem (CPU python)=26957.984375MB; mem (CPU total)=26720.2578125MB
INFO:root:[  107] Training loss: 0.93747571, Validation loss: 0.93859255, Gradient norm: 0.28852270
INFO:root:At the start of the epoch: mem (CPU python)=26996.08203125MB; mem (CPU total)=26758.4296875MB
INFO:root:[  108] Training loss: 0.93739633, Validation loss: 0.93822553, Gradient norm: 0.28236157
INFO:root:At the start of the epoch: mem (CPU python)=27034.1796875MB; mem (CPU total)=26796.10546875MB
INFO:root:[  109] Training loss: 0.93742294, Validation loss: 0.93843445, Gradient norm: 0.30077574
INFO:root:At the start of the epoch: mem (CPU python)=27072.2734375MB; mem (CPU total)=26834.21484375MB
INFO:root:[  110] Training loss: 0.93735046, Validation loss: 0.93839241, Gradient norm: 0.28543861
INFO:root:At the start of the epoch: mem (CPU python)=27110.3671875MB; mem (CPU total)=26872.38671875MB
INFO:root:[  111] Training loss: 0.93717317, Validation loss: 0.93826206, Gradient norm: 0.27582249
INFO:root:At the start of the epoch: mem (CPU python)=27148.4609375MB; mem (CPU total)=26910.8046875MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  112] Training loss: 0.93727861, Validation loss: 0.93820702, Gradient norm: 0.30148730
INFO:root:At the start of the epoch: mem (CPU python)=27186.55859375MB; mem (CPU total)=26949.0078125MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  113] Training loss: 0.93616939, Validation loss: 0.93783691, Gradient norm: 0.24197488
INFO:root:At the start of the epoch: mem (CPU python)=27224.65625MB; mem (CPU total)=26986.875MB
INFO:root:[  114] Training loss: 0.93557367, Validation loss: 0.93704010, Gradient norm: 0.23914617
INFO:root:At the start of the epoch: mem (CPU python)=27262.75MB; mem (CPU total)=27025.09375MB
INFO:root:[  115] Training loss: 0.93552839, Validation loss: 0.93718734, Gradient norm: 0.24901559
INFO:root:At the start of the epoch: mem (CPU python)=27300.84375MB; mem (CPU total)=27063.51171875MB
INFO:root:[  116] Training loss: 0.93544244, Validation loss: 0.93759368, Gradient norm: 0.23978021
INFO:root:At the start of the epoch: mem (CPU python)=27338.94140625MB; mem (CPU total)=27101.70703125MB
INFO:root:[  117] Training loss: 0.93539903, Validation loss: 0.93704513, Gradient norm: 0.24693716
INFO:root:At the start of the epoch: mem (CPU python)=27377.03515625MB; mem (CPU total)=27139.87109375MB
INFO:root:[  118] Training loss: 0.93540172, Validation loss: 0.93721060, Gradient norm: 0.24978550
INFO:root:At the start of the epoch: mem (CPU python)=27415.12890625MB; mem (CPU total)=27177.94921875MB
INFO:root:[  119] Training loss: 0.93541399, Validation loss: 0.93732946, Gradient norm: 0.25529574
INFO:root:At the start of the epoch: mem (CPU python)=27453.2265625MB; mem (CPU total)=27216.3671875MB
INFO:root:[  120] Training loss: 0.93539876, Validation loss: 0.93713277, Gradient norm: 0.25310258
INFO:root:At the start of the epoch: mem (CPU python)=27491.3203125MB; mem (CPU total)=27254.41796875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  121] Training loss: 0.93532968, Validation loss: 0.93718617, Gradient norm: 0.25258196
INFO:root:At the start of the epoch: mem (CPU python)=27529.4140625MB; mem (CPU total)=27292.34765625MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  122] Training loss: 0.93503749, Validation loss: 0.93697299, Gradient norm: 0.24875067
INFO:root:At the start of the epoch: mem (CPU python)=27567.515625MB; mem (CPU total)=27331.15625MB
INFO:root:[  123] Training loss: 0.93482499, Validation loss: 0.93701068, Gradient norm: 0.23773762
INFO:root:At the start of the epoch: mem (CPU python)=27605.60546875MB; mem (CPU total)=27369.57421875MB
INFO:root:[  124] Training loss: 0.93481852, Validation loss: 0.93676532, Gradient norm: 0.23984272
INFO:root:At the start of the epoch: mem (CPU python)=27643.703125MB; mem (CPU total)=27407.79296875MB
INFO:root:[  125] Training loss: 0.93479072, Validation loss: 0.93686489, Gradient norm: 0.23996995
INFO:root:At the start of the epoch: mem (CPU python)=27681.796875MB; mem (CPU total)=27445.94921875MB
INFO:root:[  126] Training loss: 0.93479727, Validation loss: 0.93692313, Gradient norm: 0.24217008
INFO:root:At the start of the epoch: mem (CPU python)=27719.89453125MB; mem (CPU total)=27484.12109375MB
INFO:root:[  127] Training loss: 0.93480895, Validation loss: 0.93649536, Gradient norm: 0.23954974
INFO:root:At the start of the epoch: mem (CPU python)=27757.98828125MB; mem (CPU total)=27522.47265625MB
INFO:root:[  128] Training loss: 0.93479870, Validation loss: 0.93676928, Gradient norm: 0.24094288
INFO:root:At the start of the epoch: mem (CPU python)=27796.08203125MB; mem (CPU total)=27560.52734375MB
INFO:root:[  129] Training loss: 0.93482579, Validation loss: 0.93680621, Gradient norm: 0.23753760
INFO:root:At the start of the epoch: mem (CPU python)=27834.1796875MB; mem (CPU total)=27598.5234375MB
INFO:root:[  130] Training loss: 0.93473919, Validation loss: 0.93671977, Gradient norm: 0.24262122
INFO:root:At the start of the epoch: mem (CPU python)=27872.2734375MB; mem (CPU total)=27636.94140625MB
INFO:root:[  131] Training loss: 0.93476125, Validation loss: 0.93710739, Gradient norm: 0.24381008
INFO:root:At the start of the epoch: mem (CPU python)=27910.3671875MB; mem (CPU total)=27675.08203125MB
INFO:root:[  132] Training loss: 0.93476798, Validation loss: 0.93706366, Gradient norm: 0.24750355
INFO:root:At the start of the epoch: mem (CPU python)=27948.46875MB; mem (CPU total)=27713.2578125MB
INFO:root:[  133] Training loss: 0.93475399, Validation loss: 0.93692661, Gradient norm: 0.24893694
INFO:root:At the start of the epoch: mem (CPU python)=27986.5625MB; mem (CPU total)=27751.4296875MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  134] Training loss: 0.93474376, Validation loss: 0.93686062, Gradient norm: 0.24576585
INFO:root:At the start of the epoch: mem (CPU python)=28024.65625MB; mem (CPU total)=27789.109375MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  135] Training loss: 0.93462864, Validation loss: 0.93669544, Gradient norm: 0.23753464
INFO:root:At the start of the epoch: mem (CPU python)=28062.75MB; mem (CPU total)=27827.28125MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  136] Training loss: 0.93457473, Validation loss: 0.93679688, Gradient norm: 0.24191424
INFO:root:At the start of the epoch: mem (CPU python)=28100.84765625MB; mem (CPU total)=27865.703125MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:EP 136: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=28138.9453125MB; mem (CPU total)=27903.62890625MB
INFO:root:Training the model took 9771.303s.
INFO:root:Emptying the cuda cache took 0.012s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.9359
INFO:root:EnergyScoreTrain: 0.84242
INFO:root:CRPSTrain: 0.68083
INFO:root:Gaussian NLLTrain: 797.476
INFO:root:CoverageTrain: 0.11098
INFO:root:IntervalWidthTrain: 0.2293
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9411
INFO:root:EnergyScoreValidation: 0.84781
INFO:root:CRPSValidation: 0.68618
INFO:root:Gaussian NLLValidation: 1578.12156
INFO:root:CoverageValidation: 0.10933
INFO:root:IntervalWidthValidation: 0.2278
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93973
INFO:root:EnergyScoreTest: 0.8429
INFO:root:CRPSTest: 0.68172
INFO:root:Gaussian NLLTest: 624.91229
INFO:root:CoverageTest: 0.11448
INFO:root:IntervalWidthTest: 0.23828
INFO:root:After validation: mem (CPU python)=28212.51171875MB; mem (CPU total)=27978.5MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=28212.51171875MB; mem (CPU total)=27978.54296875MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=28212.5234375MB; mem (CPU total)=27978.54296875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=28212.5234375MB; mem (CPU total)=27978.5546875MB
INFO:root:[    1] Training loss: 1.00508281, Validation loss: 0.98913194, Gradient norm: 0.05337469
INFO:root:At the start of the epoch: mem (CPU python)=28250.42578125MB; mem (CPU total)=28016.546875MB
INFO:root:[    2] Training loss: 0.98115287, Validation loss: 0.97747400, Gradient norm: 0.11475048
INFO:root:At the start of the epoch: mem (CPU python)=28288.53125MB; mem (CPU total)=28054.19921875MB
INFO:root:[    3] Training loss: 0.97398553, Validation loss: 0.97317586, Gradient norm: 0.12740833
INFO:root:At the start of the epoch: mem (CPU python)=28326.625MB; mem (CPU total)=28092.58203125MB
INFO:root:[    4] Training loss: 0.97042734, Validation loss: 0.97096207, Gradient norm: 0.12900642
INFO:root:At the start of the epoch: mem (CPU python)=28364.71875MB; mem (CPU total)=28130.78515625MB
INFO:root:[    5] Training loss: 0.96858244, Validation loss: 0.96950394, Gradient norm: 0.14038682
INFO:root:At the start of the epoch: mem (CPU python)=28402.8203125MB; mem (CPU total)=28168.80078125MB
INFO:root:[    6] Training loss: 0.96689589, Validation loss: 0.96878359, Gradient norm: 0.14421751
INFO:root:At the start of the epoch: mem (CPU python)=28440.9140625MB; mem (CPU total)=28206.9296875MB
INFO:root:[    7] Training loss: 0.96534931, Validation loss: 0.96587960, Gradient norm: 0.14527274
INFO:root:At the start of the epoch: mem (CPU python)=28479.0078125MB; mem (CPU total)=28245.3984375MB
INFO:root:[    8] Training loss: 0.96367236, Validation loss: 0.96446192, Gradient norm: 0.15804442
INFO:root:At the start of the epoch: mem (CPU python)=28517.10546875MB; mem (CPU total)=28283.87890625MB
INFO:root:[    9] Training loss: 0.96171740, Validation loss: 0.96231885, Gradient norm: 0.17445405
INFO:root:At the start of the epoch: mem (CPU python)=28555.19921875MB; mem (CPU total)=28321.71875MB
INFO:root:[   10] Training loss: 0.96004753, Validation loss: 0.95991156, Gradient norm: 0.18770414
INFO:root:At the start of the epoch: mem (CPU python)=28593.29296875MB; mem (CPU total)=28360.44921875MB
INFO:root:[   11] Training loss: 0.95826308, Validation loss: 0.95846287, Gradient norm: 0.19192883
INFO:root:At the start of the epoch: mem (CPU python)=28631.390625MB; mem (CPU total)=28398.06640625MB
INFO:root:[   12] Training loss: 0.95676831, Validation loss: 0.95659641, Gradient norm: 0.20627686
INFO:root:At the start of the epoch: mem (CPU python)=28669.48828125MB; mem (CPU total)=28435.62109375MB
INFO:root:[   13] Training loss: 0.95564554, Validation loss: 0.95549417, Gradient norm: 0.22675388
INFO:root:At the start of the epoch: mem (CPU python)=28707.58203125MB; mem (CPU total)=28474.33203125MB
INFO:root:[   14] Training loss: 0.95495146, Validation loss: 0.95483161, Gradient norm: 0.24207278
INFO:root:At the start of the epoch: mem (CPU python)=28745.67578125MB; mem (CPU total)=28511.99609375MB
INFO:root:[   15] Training loss: 0.95398017, Validation loss: 0.95408990, Gradient norm: 0.24774772
INFO:root:At the start of the epoch: mem (CPU python)=28783.7734375MB; mem (CPU total)=28550.18359375MB
INFO:root:[   16] Training loss: 0.95322729, Validation loss: 0.95271177, Gradient norm: 0.24727823
INFO:root:At the start of the epoch: mem (CPU python)=28821.8671875MB; mem (CPU total)=28588.5703125MB
INFO:root:[   17] Training loss: 0.95230491, Validation loss: 0.95200196, Gradient norm: 0.26692889
INFO:root:At the start of the epoch: mem (CPU python)=28859.9609375MB; mem (CPU total)=28626.69921875MB
INFO:root:[   18] Training loss: 0.95143452, Validation loss: 0.95243216, Gradient norm: 0.25886023
INFO:root:At the start of the epoch: mem (CPU python)=28898.0546875MB; mem (CPU total)=28664.84375MB
INFO:root:[   19] Training loss: 0.95070210, Validation loss: 0.95127394, Gradient norm: 0.25463386
INFO:root:At the start of the epoch: mem (CPU python)=28936.15625MB; mem (CPU total)=28701.7578125MB
INFO:root:[   20] Training loss: 0.94971627, Validation loss: 0.95052044, Gradient norm: 0.26665664
INFO:root:At the start of the epoch: mem (CPU python)=28974.24609375MB; mem (CPU total)=28740.1015625MB
INFO:root:[   21] Training loss: 0.94950059, Validation loss: 0.94957331, Gradient norm: 0.28986529
INFO:root:At the start of the epoch: mem (CPU python)=29012.34375MB; mem (CPU total)=28778.05859375MB
INFO:root:[   22] Training loss: 0.94861910, Validation loss: 0.94846453, Gradient norm: 0.29935460
INFO:root:At the start of the epoch: mem (CPU python)=29050.44140625MB; mem (CPU total)=28815.96484375MB
INFO:root:[   23] Training loss: 0.94822933, Validation loss: 0.94893078, Gradient norm: 0.29844912
INFO:root:At the start of the epoch: mem (CPU python)=29088.53515625MB; mem (CPU total)=28854.2734375MB
INFO:root:[   24] Training loss: 0.94754285, Validation loss: 0.94735888, Gradient norm: 0.28909836
INFO:root:At the start of the epoch: mem (CPU python)=29126.6328125MB; mem (CPU total)=28892.6953125MB
INFO:root:[   25] Training loss: 0.94691691, Validation loss: 0.94848040, Gradient norm: 0.28428156
INFO:root:At the start of the epoch: mem (CPU python)=29164.73046875MB; mem (CPU total)=28931.33203125MB
INFO:root:[   26] Training loss: 0.94663109, Validation loss: 0.94702045, Gradient norm: 0.31841724
INFO:root:At the start of the epoch: mem (CPU python)=29202.82421875MB; mem (CPU total)=28969.4609375MB
INFO:root:[   27] Training loss: 0.94611013, Validation loss: 0.94678196, Gradient norm: 0.30561175
INFO:root:At the start of the epoch: mem (CPU python)=29240.91796875MB; mem (CPU total)=29007.85546875MB
INFO:root:[   28] Training loss: 0.94561574, Validation loss: 0.94607459, Gradient norm: 0.31093711
INFO:root:At the start of the epoch: mem (CPU python)=29279.01171875MB; mem (CPU total)=29046.046875MB
INFO:root:[   29] Training loss: 0.94521630, Validation loss: 0.94549931, Gradient norm: 0.33360351
INFO:root:At the start of the epoch: mem (CPU python)=29317.109375MB; mem (CPU total)=29084.671875MB
INFO:root:[   30] Training loss: 0.94491639, Validation loss: 0.94529795, Gradient norm: 0.31862068
INFO:root:At the start of the epoch: mem (CPU python)=29355.20703125MB; mem (CPU total)=29122.01171875MB
INFO:root:[   31] Training loss: 0.94446535, Validation loss: 0.94504438, Gradient norm: 0.32079768
INFO:root:At the start of the epoch: mem (CPU python)=29393.30078125MB; mem (CPU total)=29160.6796875MB
INFO:root:[   32] Training loss: 0.94396477, Validation loss: 0.94469163, Gradient norm: 0.33604025
INFO:root:At the start of the epoch: mem (CPU python)=29431.3984375MB; mem (CPU total)=29198.453125MB
INFO:root:[   33] Training loss: 0.94350973, Validation loss: 0.94374615, Gradient norm: 0.32165186
INFO:root:At the start of the epoch: mem (CPU python)=29469.4921875MB; mem (CPU total)=29236.79296875MB
INFO:root:[   34] Training loss: 0.94352649, Validation loss: 0.94439616, Gradient norm: 0.34626834
INFO:root:At the start of the epoch: mem (CPU python)=29507.5859375MB; mem (CPU total)=29275.15234375MB
INFO:root:[   35] Training loss: 0.94316779, Validation loss: 0.94284882, Gradient norm: 0.33595712
INFO:root:At the start of the epoch: mem (CPU python)=29545.6796875MB; mem (CPU total)=29313.203125MB
INFO:root:[   36] Training loss: 0.94279923, Validation loss: 0.94298616, Gradient norm: 0.32671844
INFO:root:At the start of the epoch: mem (CPU python)=29583.77734375MB; mem (CPU total)=29351.41015625MB
INFO:root:[   37] Training loss: 0.94261356, Validation loss: 0.94273824, Gradient norm: 0.34219624
INFO:root:At the start of the epoch: mem (CPU python)=29621.875MB; mem (CPU total)=29389.73828125MB
INFO:root:[   38] Training loss: 0.94229523, Validation loss: 0.94250460, Gradient norm: 0.34495286
INFO:root:At the start of the epoch: mem (CPU python)=29659.96875MB; mem (CPU total)=29428.35546875MB
INFO:root:[   39] Training loss: 0.94187568, Validation loss: 0.94281953, Gradient norm: 0.32940471
INFO:root:At the start of the epoch: mem (CPU python)=29698.0625MB; mem (CPU total)=29466.5MB
INFO:root:[   40] Training loss: 0.94159372, Validation loss: 0.94317205, Gradient norm: 0.31262226
INFO:root:At the start of the epoch: mem (CPU python)=29736.15625MB; mem (CPU total)=29504.64453125MB
INFO:root:[   41] Training loss: 0.94157234, Validation loss: 0.94170708, Gradient norm: 0.33852934
INFO:root:At the start of the epoch: mem (CPU python)=29774.25390625MB; mem (CPU total)=29543.26953125MB
INFO:root:[   42] Training loss: 0.94146820, Validation loss: 0.94222866, Gradient norm: 0.33584076
INFO:root:At the start of the epoch: mem (CPU python)=29812.3515625MB; mem (CPU total)=29581.18359375MB
INFO:root:[   43] Training loss: 0.94131263, Validation loss: 0.94160081, Gradient norm: 0.33147242
INFO:root:At the start of the epoch: mem (CPU python)=29850.4453125MB; mem (CPU total)=29619.30078125MB
INFO:root:[   44] Training loss: 0.94101617, Validation loss: 0.94187592, Gradient norm: 0.32659436
INFO:root:At the start of the epoch: mem (CPU python)=29888.5390625MB; mem (CPU total)=29657.4453125MB
INFO:root:[   45] Training loss: 0.94072498, Validation loss: 0.94150383, Gradient norm: 0.32005914
INFO:root:At the start of the epoch: mem (CPU python)=29926.6328125MB; mem (CPU total)=29695.05078125MB
INFO:root:[   46] Training loss: 0.94054323, Validation loss: 0.94087885, Gradient norm: 0.32458836
INFO:root:At the start of the epoch: mem (CPU python)=29964.734375MB; mem (CPU total)=29733.65234375MB
INFO:root:[   47] Training loss: 0.94054694, Validation loss: 0.94224041, Gradient norm: 0.33932142
INFO:root:At the start of the epoch: mem (CPU python)=30002.82421875MB; mem (CPU total)=29771.98046875MB
INFO:root:[   48] Training loss: 0.94018204, Validation loss: 0.94204353, Gradient norm: 0.31915627
INFO:root:At the start of the epoch: mem (CPU python)=30040.91796875MB; mem (CPU total)=29810.125MB
INFO:root:[   49] Training loss: 0.94009443, Validation loss: 0.94004569, Gradient norm: 0.32090593
INFO:root:At the start of the epoch: mem (CPU python)=30079.01953125MB; mem (CPU total)=29848.12890625MB
INFO:root:[   50] Training loss: 0.93980464, Validation loss: 0.93990354, Gradient norm: 0.31390375
INFO:root:At the start of the epoch: mem (CPU python)=30117.11328125MB; mem (CPU total)=29886.7265625MB
INFO:root:[   51] Training loss: 0.93968602, Validation loss: 0.93972300, Gradient norm: 0.32596301
INFO:root:At the start of the epoch: mem (CPU python)=30155.20703125MB; mem (CPU total)=29924.80078125MB
INFO:root:[   52] Training loss: 0.93950843, Validation loss: 0.94062321, Gradient norm: 0.31233119
INFO:root:At the start of the epoch: mem (CPU python)=30193.30078125MB; mem (CPU total)=29963.19140625MB
INFO:root:[   53] Training loss: 0.93943569, Validation loss: 0.94004207, Gradient norm: 0.33090459
INFO:root:At the start of the epoch: mem (CPU python)=30231.40234375MB; mem (CPU total)=30000.92578125MB
INFO:root:[   54] Training loss: 0.93921858, Validation loss: 0.94006668, Gradient norm: 0.30565362
INFO:root:At the start of the epoch: mem (CPU python)=30269.49609375MB; mem (CPU total)=30038.8125MB
INFO:root:[   55] Training loss: 0.93907992, Validation loss: 0.93965641, Gradient norm: 0.31130408
INFO:root:At the start of the epoch: mem (CPU python)=30307.59375MB; mem (CPU total)=30077.37109375MB
INFO:root:[   56] Training loss: 0.93899495, Validation loss: 0.94005158, Gradient norm: 0.32241985
INFO:root:At the start of the epoch: mem (CPU python)=30345.6875MB; mem (CPU total)=30115.76171875MB
INFO:root:[   57] Training loss: 0.93870125, Validation loss: 0.93974817, Gradient norm: 0.29859544
INFO:root:At the start of the epoch: mem (CPU python)=30383.78515625MB; mem (CPU total)=30153.90625MB
INFO:root:[   58] Training loss: 0.93853676, Validation loss: 0.94079319, Gradient norm: 0.30979216
INFO:root:At the start of the epoch: mem (CPU python)=30421.87890625MB; mem (CPU total)=30192.05078125MB
INFO:root:[   59] Training loss: 0.93852819, Validation loss: 0.93974951, Gradient norm: 0.31777186
INFO:root:At the start of the epoch: mem (CPU python)=30459.9765625MB; mem (CPU total)=30229.91796875MB
INFO:root:[   60] Training loss: 0.93859286, Validation loss: 0.93982408, Gradient norm: 0.34324885
INFO:root:At the start of the epoch: mem (CPU python)=30498.0703125MB; mem (CPU total)=30268.30859375MB
INFO:root:[   61] Training loss: 0.93829638, Validation loss: 0.93967388, Gradient norm: 0.32177014
INFO:root:At the start of the epoch: mem (CPU python)=30536.1640625MB; mem (CPU total)=30306.03515625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   62] Training loss: 0.93803080, Validation loss: 0.93864345, Gradient norm: 0.29122137
INFO:root:At the start of the epoch: mem (CPU python)=30574.26171875MB; mem (CPU total)=30344.8515625MB
INFO:root:[   63] Training loss: 0.93639421, Validation loss: 0.93723822, Gradient norm: 0.26046805
INFO:root:At the start of the epoch: mem (CPU python)=30612.359375MB; mem (CPU total)=30383.4609375MB
INFO:root:[   64] Training loss: 0.93613225, Validation loss: 0.93745403, Gradient norm: 0.27472744
INFO:root:At the start of the epoch: mem (CPU python)=30650.44921875MB; mem (CPU total)=30421.60546875MB
INFO:root:[   65] Training loss: 0.93611019, Validation loss: 0.93774110, Gradient norm: 0.28416545
INFO:root:At the start of the epoch: mem (CPU python)=30688.55078125MB; mem (CPU total)=30459.75MB
INFO:root:[   66] Training loss: 0.93616748, Validation loss: 0.93773798, Gradient norm: 0.30484530
INFO:root:At the start of the epoch: mem (CPU python)=30726.6484375MB; mem (CPU total)=30497.89453125MB
INFO:root:[   67] Training loss: 0.93591716, Validation loss: 0.93716798, Gradient norm: 0.27729853
INFO:root:At the start of the epoch: mem (CPU python)=30764.7421875MB; mem (CPU total)=30536.28515625MB
INFO:root:[   68] Training loss: 0.93586559, Validation loss: 0.93715443, Gradient norm: 0.28428383
INFO:root:At the start of the epoch: mem (CPU python)=30802.8359375MB; mem (CPU total)=30574.87890625MB
INFO:root:[   69] Training loss: 0.93578415, Validation loss: 0.93678292, Gradient norm: 0.28613433
INFO:root:At the start of the epoch: mem (CPU python)=30840.93359375MB; mem (CPU total)=30612.91796875MB
INFO:root:[   70] Training loss: 0.93575597, Validation loss: 0.93667206, Gradient norm: 0.29948099
INFO:root:At the start of the epoch: mem (CPU python)=30879.03125MB; mem (CPU total)=30650.765625MB
INFO:root:[   71] Training loss: 0.93560010, Validation loss: 0.93701503, Gradient norm: 0.28310234
INFO:root:At the start of the epoch: mem (CPU python)=30917.12109375MB; mem (CPU total)=30688.6640625MB
INFO:root:[   72] Training loss: 0.93561454, Validation loss: 0.93686035, Gradient norm: 0.31635640
INFO:root:At the start of the epoch: mem (CPU python)=30955.21875MB; mem (CPU total)=30726.80859375MB
INFO:root:[   73] Training loss: 0.93542502, Validation loss: 0.93659069, Gradient norm: 0.28041187
INFO:root:At the start of the epoch: mem (CPU python)=30993.31640625MB; mem (CPU total)=30765.2578125MB
INFO:root:[   74] Training loss: 0.93554149, Validation loss: 0.93689489, Gradient norm: 0.30682447
INFO:root:At the start of the epoch: mem (CPU python)=31031.40625MB; mem (CPU total)=30803.63671875MB
INFO:root:[   75] Training loss: 0.93523824, Validation loss: 0.93683924, Gradient norm: 0.28880974
INFO:root:At the start of the epoch: mem (CPU python)=31069.5MB; mem (CPU total)=30841.78125MB
INFO:root:[   76] Training loss: 0.93515119, Validation loss: 0.93601596, Gradient norm: 0.28524431
INFO:root:At the start of the epoch: mem (CPU python)=31107.6015625MB; mem (CPU total)=30880.234375MB
INFO:root:[   77] Training loss: 0.93512257, Validation loss: 0.93661795, Gradient norm: 0.29247083
INFO:root:At the start of the epoch: mem (CPU python)=31145.6953125MB; mem (CPU total)=30917.390625MB
INFO:root:[   78] Training loss: 0.93504947, Validation loss: 0.93757516, Gradient norm: 0.29440821
INFO:root:At the start of the epoch: mem (CPU python)=31183.7890625MB; mem (CPU total)=30955.2890625MB
INFO:root:[   79] Training loss: 0.93496843, Validation loss: 0.93611474, Gradient norm: 0.29474814
INFO:root:At the start of the epoch: mem (CPU python)=31221.8828125MB; mem (CPU total)=30993.43359375MB
INFO:root:[   80] Training loss: 0.93492260, Validation loss: 0.93653701, Gradient norm: 0.30979727
INFO:root:At the start of the epoch: mem (CPU python)=31259.98046875MB; mem (CPU total)=31031.76171875MB
INFO:root:[   81] Training loss: 0.93472829, Validation loss: 0.93625607, Gradient norm: 0.28543450
INFO:root:At the start of the epoch: mem (CPU python)=31298.078125MB; mem (CPU total)=31069.90625MB
INFO:root:[   82] Training loss: 0.93475011, Validation loss: 0.93585881, Gradient norm: 0.29481683
INFO:root:At the start of the epoch: mem (CPU python)=31336.171875MB; mem (CPU total)=31110.2265625MB
INFO:root:[   83] Training loss: 0.93468274, Validation loss: 0.93617017, Gradient norm: 0.29747451
INFO:root:At the start of the epoch: mem (CPU python)=31374.26953125MB; mem (CPU total)=31148.6171875MB
INFO:root:[   84] Training loss: 0.93466955, Validation loss: 0.93586040, Gradient norm: 0.31071306
INFO:root:At the start of the epoch: mem (CPU python)=31412.36328125MB; mem (CPU total)=31186.80859375MB
INFO:root:[   85] Training loss: 0.93452177, Validation loss: 0.93650234, Gradient norm: 0.29173434
INFO:root:At the start of the epoch: mem (CPU python)=31450.45703125MB; mem (CPU total)=31224.69140625MB
INFO:root:[   86] Training loss: 0.93439047, Validation loss: 0.93596705, Gradient norm: 0.28829595
INFO:root:At the start of the epoch: mem (CPU python)=31488.55078125MB; mem (CPU total)=31262.7734375MB
INFO:root:[   87] Training loss: 0.93443991, Validation loss: 0.93596576, Gradient norm: 0.29871388
INFO:root:At the start of the epoch: mem (CPU python)=31526.6484375MB; mem (CPU total)=31301.1640625MB
INFO:root:[   88] Training loss: 0.93434853, Validation loss: 0.93597351, Gradient norm: 0.29966998
INFO:root:At the start of the epoch: mem (CPU python)=31564.7421875MB; mem (CPU total)=31339.30859375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   89] Training loss: 0.93436861, Validation loss: 0.93541481, Gradient norm: 0.29714536
INFO:root:At the start of the epoch: mem (CPU python)=31602.83984375MB; mem (CPU total)=31377.76171875MB
INFO:root:[   90] Training loss: 0.93322334, Validation loss: 0.93513848, Gradient norm: 0.26795784
INFO:root:At the start of the epoch: mem (CPU python)=31640.9375MB; mem (CPU total)=31415.3515625MB
INFO:root:[   91] Training loss: 0.93305497, Validation loss: 0.93476820, Gradient norm: 0.26076763
INFO:root:At the start of the epoch: mem (CPU python)=31679.03125MB; mem (CPU total)=31453.8984375MB
INFO:root:[   92] Training loss: 0.93303541, Validation loss: 0.93469409, Gradient norm: 0.26937366
INFO:root:At the start of the epoch: mem (CPU python)=31717.125MB; mem (CPU total)=31491.796875MB
INFO:root:[   93] Training loss: 0.93302217, Validation loss: 0.93483018, Gradient norm: 0.28968999
INFO:root:At the start of the epoch: mem (CPU python)=31755.22265625MB; mem (CPU total)=31530.41796875MB
INFO:root:[   94] Training loss: 0.93307539, Validation loss: 0.93456487, Gradient norm: 0.29305915
INFO:root:At the start of the epoch: mem (CPU python)=31793.31640625MB; mem (CPU total)=31568.32421875MB
INFO:root:[   95] Training loss: 0.93290649, Validation loss: 0.93522895, Gradient norm: 0.26931929
INFO:root:At the start of the epoch: mem (CPU python)=31831.41015625MB; mem (CPU total)=31606.46875MB
INFO:root:[   96] Training loss: 0.93291450, Validation loss: 0.93459168, Gradient norm: 0.27996341
INFO:root:At the start of the epoch: mem (CPU python)=31869.50390625MB; mem (CPU total)=31644.61328125MB
INFO:root:[   97] Training loss: 0.93287074, Validation loss: 0.93456288, Gradient norm: 0.27474731
INFO:root:At the start of the epoch: mem (CPU python)=31907.60546875MB; mem (CPU total)=31681.9609375MB
INFO:root:[   98] Training loss: 0.93282008, Validation loss: 0.93478112, Gradient norm: 0.28254097
INFO:root:At the start of the epoch: mem (CPU python)=31945.6953125MB; mem (CPU total)=31720.10546875MB
INFO:root:[   99] Training loss: 0.93279134, Validation loss: 0.93418517, Gradient norm: 0.28262522
INFO:root:At the start of the epoch: mem (CPU python)=31983.79296875MB; mem (CPU total)=31757.9296875MB
INFO:root:[  100] Training loss: 0.93270250, Validation loss: 0.93426941, Gradient norm: 0.27932693
INFO:root:At the start of the epoch: mem (CPU python)=32021.890625MB; mem (CPU total)=31795.78125MB
INFO:root:[  101] Training loss: 0.93277401, Validation loss: 0.93465241, Gradient norm: 0.27600935
INFO:root:At the start of the epoch: mem (CPU python)=32059.984375MB; mem (CPU total)=31834.1640625MB
INFO:root:[  102] Training loss: 0.93275401, Validation loss: 0.93438343, Gradient norm: 0.30282615
INFO:root:At the start of the epoch: mem (CPU python)=32098.08203125MB; mem (CPU total)=31873.26953125MB
INFO:root:[  103] Training loss: 0.93264346, Validation loss: 0.93457212, Gradient norm: 0.28960452
INFO:root:At the start of the epoch: mem (CPU python)=32136.17578125MB; mem (CPU total)=31911.3203125MB
INFO:root:[  104] Training loss: 0.93259589, Validation loss: 0.93456086, Gradient norm: 0.28726994
INFO:root:At the start of the epoch: mem (CPU python)=32174.7734375MB; mem (CPU total)=31949.96484375MB
INFO:root:[  105] Training loss: 0.93259917, Validation loss: 0.93445581, Gradient norm: 0.28572422
INFO:root:At the start of the epoch: mem (CPU python)=32212.8671875MB; mem (CPU total)=31988.109375MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  106] Training loss: 0.93253200, Validation loss: 0.93451601, Gradient norm: 0.29197034
INFO:root:At the start of the epoch: mem (CPU python)=32250.9609375MB; mem (CPU total)=32026.25390625MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  107] Training loss: 0.93193848, Validation loss: 0.93399201, Gradient norm: 0.25320704
INFO:root:At the start of the epoch: mem (CPU python)=32289.0625MB; mem (CPU total)=32064.14453125MB
INFO:root:[  108] Training loss: 0.93151713, Validation loss: 0.93364823, Gradient norm: 0.24603536
INFO:root:At the start of the epoch: mem (CPU python)=32327.16015625MB; mem (CPU total)=32102.375MB
INFO:root:[  109] Training loss: 0.93155401, Validation loss: 0.93400267, Gradient norm: 0.25708531
INFO:root:At the start of the epoch: mem (CPU python)=32365.25390625MB; mem (CPU total)=32140.44140625MB
INFO:root:[  110] Training loss: 0.93158725, Validation loss: 0.93372418, Gradient norm: 0.25364334
INFO:root:At the start of the epoch: mem (CPU python)=32403.3515625MB; mem (CPU total)=32178.578125MB
INFO:root:[  111] Training loss: 0.93149588, Validation loss: 0.93367096, Gradient norm: 0.25585541
INFO:root:At the start of the epoch: mem (CPU python)=32441.4453125MB; mem (CPU total)=32216.18359375MB
INFO:root:[  112] Training loss: 0.93147592, Validation loss: 0.93356953, Gradient norm: 0.25056961
INFO:root:At the start of the epoch: mem (CPU python)=32479.54296875MB; mem (CPU total)=32254.40234375MB
INFO:root:[  113] Training loss: 0.93151274, Validation loss: 0.93388099, Gradient norm: 0.26126683
INFO:root:At the start of the epoch: mem (CPU python)=32517.6328125MB; mem (CPU total)=32292.7890625MB
INFO:root:[  114] Training loss: 0.93141438, Validation loss: 0.93375493, Gradient norm: 0.25442353
INFO:root:At the start of the epoch: mem (CPU python)=32555.73046875MB; mem (CPU total)=32330.75MB
INFO:root:[  115] Training loss: 0.93146571, Validation loss: 0.93347399, Gradient norm: 0.25759762
INFO:root:At the start of the epoch: mem (CPU python)=32593.828125MB; mem (CPU total)=32368.89453125MB
INFO:root:[  116] Training loss: 0.93142011, Validation loss: 0.93359848, Gradient norm: 0.25964691
INFO:root:At the start of the epoch: mem (CPU python)=32631.921875MB; mem (CPU total)=32407.0703125MB
INFO:root:[  117] Training loss: 0.93136408, Validation loss: 0.93353151, Gradient norm: 0.26843556
INFO:root:At the start of the epoch: mem (CPU python)=32670.01953125MB; mem (CPU total)=32445.4609375MB
INFO:root:[  118] Training loss: 0.93141054, Validation loss: 0.93355974, Gradient norm: 0.26119107
INFO:root:At the start of the epoch: mem (CPU python)=32708.11328125MB; mem (CPU total)=32483.33203125MB
INFO:root:[  119] Training loss: 0.93142454, Validation loss: 0.93357421, Gradient norm: 0.26981369
INFO:root:At the start of the epoch: mem (CPU python)=32746.20703125MB; mem (CPU total)=32521.34375MB
INFO:root:[  120] Training loss: 0.93133830, Validation loss: 0.93386251, Gradient norm: 0.26389060
INFO:root:At the start of the epoch: mem (CPU python)=32784.30078125MB; mem (CPU total)=32559.48828125MB
INFO:root:[  121] Training loss: 0.93138293, Validation loss: 0.93361580, Gradient norm: 0.26772849
INFO:root:At the start of the epoch: mem (CPU python)=32822.3984375MB; mem (CPU total)=32596.88671875MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  122] Training loss: 0.93137885, Validation loss: 0.93365067, Gradient norm: 0.26594513
INFO:root:At the start of the epoch: mem (CPU python)=32860.4921875MB; mem (CPU total)=32634.859375MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  123] Training loss: 0.93115963, Validation loss: 0.93346988, Gradient norm: 0.25205959
INFO:root:At the start of the epoch: mem (CPU python)=32898.58984375MB; mem (CPU total)=32673.2421875MB
INFO:root:[  124] Training loss: 0.93107579, Validation loss: 0.93345181, Gradient norm: 0.24762893
INFO:root:At the start of the epoch: mem (CPU python)=32936.6875MB; mem (CPU total)=32711.7265625MB
INFO:root:[  125] Training loss: 0.93107779, Validation loss: 0.93357097, Gradient norm: 0.24949211
INFO:root:At the start of the epoch: mem (CPU python)=32974.78125MB; mem (CPU total)=32754.11328125MB
INFO:root:[  126] Training loss: 0.93104590, Validation loss: 0.93350175, Gradient norm: 0.25034913
INFO:root:At the start of the epoch: mem (CPU python)=33012.875MB; mem (CPU total)=32791.453125MB
INFO:root:[  127] Training loss: 0.93103234, Validation loss: 0.93383417, Gradient norm: 0.24579447
INFO:root:At the start of the epoch: mem (CPU python)=33050.97265625MB; mem (CPU total)=32829.3984375MB
INFO:root:[  128] Training loss: 0.93104426, Validation loss: 0.93302414, Gradient norm: 0.24856643
INFO:root:At the start of the epoch: mem (CPU python)=33089.06640625MB; mem (CPU total)=32866.95703125MB
INFO:root:[  129] Training loss: 0.93102732, Validation loss: 0.93339441, Gradient norm: 0.25577994
INFO:root:At the start of the epoch: mem (CPU python)=33127.16015625MB; mem (CPU total)=32904.703125MB
INFO:root:[  130] Training loss: 0.93104230, Validation loss: 0.93306205, Gradient norm: 0.24783857
INFO:root:At the start of the epoch: mem (CPU python)=33165.25390625MB; mem (CPU total)=32943.0625MB
INFO:root:[  131] Training loss: 0.93099338, Validation loss: 0.93321679, Gradient norm: 0.25082606
INFO:root:At the start of the epoch: mem (CPU python)=33203.3515625MB; mem (CPU total)=32981.20703125MB
INFO:root:[  132] Training loss: 0.93096417, Validation loss: 0.93340554, Gradient norm: 0.25106898
INFO:root:At the start of the epoch: mem (CPU python)=33241.44921875MB; mem (CPU total)=33019.28125MB
INFO:root:[  133] Training loss: 0.93103285, Validation loss: 0.93344719, Gradient norm: 0.25154362
INFO:root:At the start of the epoch: mem (CPU python)=33279.54296875MB; mem (CPU total)=33057.17578125MB
INFO:root:[  134] Training loss: 0.93101801, Validation loss: 0.93356634, Gradient norm: 0.25515658
INFO:root:At the start of the epoch: mem (CPU python)=33317.640625MB; mem (CPU total)=33095.56640625MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  135] Training loss: 0.93104092, Validation loss: 0.93333541, Gradient norm: 0.25225853
INFO:root:At the start of the epoch: mem (CPU python)=33355.734375MB; mem (CPU total)=33133.7109375MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  136] Training loss: 0.93091398, Validation loss: 0.93321353, Gradient norm: 0.24677911
INFO:root:At the start of the epoch: mem (CPU python)=33393.828125MB; mem (CPU total)=33171.8515625MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  137] Training loss: 0.93091468, Validation loss: 0.93353248, Gradient norm: 0.25309251
INFO:root:At the start of the epoch: mem (CPU python)=33431.921875MB; mem (CPU total)=33210.0078125MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:EP 137: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=33469.859375MB; mem (CPU total)=33247.8984375MB
INFO:root:Training the model took 10740.519s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93326
INFO:root:EnergyScoreTrain: 0.8384
INFO:root:CRPSTrain: 0.67493
INFO:root:Gaussian NLLTrain: 588.15445
INFO:root:CoverageTrain: 0.11674
INFO:root:IntervalWidthTrain: 0.23722
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93819
INFO:root:EnergyScoreValidation: 0.84292
INFO:root:CRPSValidation: 0.67925
INFO:root:Gaussian NLLValidation: 574.3043
INFO:root:CoverageValidation: 0.11595
INFO:root:IntervalWidthValidation: 0.23834
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93673
INFO:root:EnergyScoreTest: 0.84348
INFO:root:CRPSTest: 0.68038
INFO:root:Gaussian NLLTest: 1125.5847
INFO:root:CoverageTest: 0.11353
INFO:root:IntervalWidthTest: 0.23049
INFO:root:After validation: mem (CPU python)=33543.625MB; mem (CPU total)=33322.84375MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=33543.625MB; mem (CPU total)=33322.83984375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=33543.640625MB; mem (CPU total)=33322.83984375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=33543.640625MB; mem (CPU total)=33323.0859375MB
INFO:root:[    1] Training loss: 1.00473054, Validation loss: 0.98790422, Gradient norm: 0.05278338
INFO:root:At the start of the epoch: mem (CPU python)=33581.5MB; mem (CPU total)=33360.953125MB
INFO:root:[    2] Training loss: 0.98079617, Validation loss: 0.97723598, Gradient norm: 0.12305724
INFO:root:At the start of the epoch: mem (CPU python)=33619.59765625MB; mem (CPU total)=33399.12890625MB
INFO:root:[    3] Training loss: 0.97374327, Validation loss: 0.97250422, Gradient norm: 0.15655315
INFO:root:At the start of the epoch: mem (CPU python)=33657.69140625MB; mem (CPU total)=33437.28125MB
INFO:root:[    4] Training loss: 0.97048602, Validation loss: 0.97067162, Gradient norm: 0.16341817
INFO:root:At the start of the epoch: mem (CPU python)=33695.7890625MB; mem (CPU total)=33475.23828125MB
INFO:root:[    5] Training loss: 0.96824132, Validation loss: 0.96899012, Gradient norm: 0.15875308
INFO:root:At the start of the epoch: mem (CPU python)=33733.8828125MB; mem (CPU total)=33513.05859375MB
INFO:root:[    6] Training loss: 0.96633066, Validation loss: 0.96640039, Gradient norm: 0.17292131
INFO:root:At the start of the epoch: mem (CPU python)=33771.98046875MB; mem (CPU total)=33552.984375MB
INFO:root:[    7] Training loss: 0.96436241, Validation loss: 0.96458986, Gradient norm: 0.17139652
INFO:root:At the start of the epoch: mem (CPU python)=33810.07421875MB; mem (CPU total)=33589.87890625MB
INFO:root:[    8] Training loss: 0.96273046, Validation loss: 0.96390043, Gradient norm: 0.18765010
INFO:root:At the start of the epoch: mem (CPU python)=33848.171875MB; mem (CPU total)=33628.01953125MB
INFO:root:[    9] Training loss: 0.96153372, Validation loss: 0.96255631, Gradient norm: 0.19232525
INFO:root:At the start of the epoch: mem (CPU python)=33886.265625MB; mem (CPU total)=33665.76953125MB
INFO:root:[   10] Training loss: 0.96008247, Validation loss: 0.95962653, Gradient norm: 0.20541304
INFO:root:At the start of the epoch: mem (CPU python)=33924.36328125MB; mem (CPU total)=33704.19140625MB
INFO:root:[   11] Training loss: 0.95908050, Validation loss: 0.95891424, Gradient norm: 0.23228876
INFO:root:At the start of the epoch: mem (CPU python)=33962.45703125MB; mem (CPU total)=33741.94921875MB
INFO:root:[   12] Training loss: 0.95792926, Validation loss: 0.95788342, Gradient norm: 0.22210619
INFO:root:At the start of the epoch: mem (CPU python)=34000.55078125MB; mem (CPU total)=33779.48828125MB
INFO:root:[   13] Training loss: 0.95673227, Validation loss: 0.95698989, Gradient norm: 0.22466487
INFO:root:At the start of the epoch: mem (CPU python)=34038.6484375MB; mem (CPU total)=33817.70703125MB
INFO:root:[   14] Training loss: 0.95616232, Validation loss: 0.95583563, Gradient norm: 0.24589359
INFO:root:At the start of the epoch: mem (CPU python)=34076.7421875MB; mem (CPU total)=33856.19921875MB
INFO:root:[   15] Training loss: 0.95503292, Validation loss: 0.95434614, Gradient norm: 0.23882888
INFO:root:At the start of the epoch: mem (CPU python)=34114.83984375MB; mem (CPU total)=33894.15625MB
INFO:root:[   16] Training loss: 0.95457413, Validation loss: 0.95473847, Gradient norm: 0.23392826
INFO:root:At the start of the epoch: mem (CPU python)=34152.93359375MB; mem (CPU total)=33932.5078125MB
INFO:root:[   17] Training loss: 0.95395286, Validation loss: 0.95400858, Gradient norm: 0.25786982
INFO:root:At the start of the epoch: mem (CPU python)=34191.03125MB; mem (CPU total)=33970.55859375MB
INFO:root:[   18] Training loss: 0.95311158, Validation loss: 0.95372768, Gradient norm: 0.23779035
INFO:root:At the start of the epoch: mem (CPU python)=34229.125MB; mem (CPU total)=34009.08984375MB
INFO:root:[   19] Training loss: 0.95269266, Validation loss: 0.95283790, Gradient norm: 0.24748593
INFO:root:At the start of the epoch: mem (CPU python)=34267.21875MB; mem (CPU total)=34047.61328125MB
INFO:root:[   20] Training loss: 0.95215975, Validation loss: 0.95155768, Gradient norm: 0.25818315
INFO:root:At the start of the epoch: mem (CPU python)=34305.31640625MB; mem (CPU total)=34086.11328125MB
INFO:root:[   21] Training loss: 0.95153260, Validation loss: 0.95166049, Gradient norm: 0.26204833
INFO:root:At the start of the epoch: mem (CPU python)=34343.41015625MB; mem (CPU total)=34124.22265625MB
INFO:root:[   22] Training loss: 0.95102190, Validation loss: 0.95094157, Gradient norm: 0.25857315
INFO:root:At the start of the epoch: mem (CPU python)=34381.50390625MB; mem (CPU total)=34162.1015625MB
INFO:root:[   23] Training loss: 0.95056556, Validation loss: 0.95109925, Gradient norm: 0.25988452
INFO:root:At the start of the epoch: mem (CPU python)=34419.6015625MB; mem (CPU total)=34200.21875MB
INFO:root:[   24] Training loss: 0.95023415, Validation loss: 0.94978924, Gradient norm: 0.26055790
INFO:root:At the start of the epoch: mem (CPU python)=34457.69921875MB; mem (CPU total)=34239.63671875MB
INFO:root:[   25] Training loss: 0.94976281, Validation loss: 0.95031273, Gradient norm: 0.25541138
INFO:root:At the start of the epoch: mem (CPU python)=34495.7890625MB; mem (CPU total)=34278.05859375MB
INFO:root:[   26] Training loss: 0.94943770, Validation loss: 0.94973026, Gradient norm: 0.26349554
INFO:root:At the start of the epoch: mem (CPU python)=34533.88671875MB; mem (CPU total)=34316.06640625MB
INFO:root:[   27] Training loss: 0.94910092, Validation loss: 0.94893576, Gradient norm: 0.26927790
INFO:root:At the start of the epoch: mem (CPU python)=34571.984375MB; mem (CPU total)=34354.41796875MB
INFO:root:[   28] Training loss: 0.94897903, Validation loss: 0.94929501, Gradient norm: 0.27938100
INFO:root:At the start of the epoch: mem (CPU python)=34610.078125MB; mem (CPU total)=34392.59375MB
INFO:root:[   29] Training loss: 0.94846404, Validation loss: 0.94825400, Gradient norm: 0.27464234
INFO:root:At the start of the epoch: mem (CPU python)=34648.17578125MB; mem (CPU total)=34430.8359375MB
INFO:root:[   30] Training loss: 0.94816213, Validation loss: 0.94843229, Gradient norm: 0.27182518
INFO:root:At the start of the epoch: mem (CPU python)=34686.26953125MB; mem (CPU total)=34469.2578125MB
INFO:root:[   31] Training loss: 0.94795442, Validation loss: 0.94766052, Gradient norm: 0.26425823
INFO:root:At the start of the epoch: mem (CPU python)=34724.3671875MB; mem (CPU total)=34507.55859375MB
INFO:root:[   32] Training loss: 0.94776123, Validation loss: 0.94790238, Gradient norm: 0.27074903
INFO:root:At the start of the epoch: mem (CPU python)=34762.4609375MB; mem (CPU total)=34545.98046875MB
INFO:root:[   33] Training loss: 0.94739538, Validation loss: 0.94825872, Gradient norm: 0.26931422
INFO:root:At the start of the epoch: mem (CPU python)=34800.55859375MB; mem (CPU total)=34583.953125MB
INFO:root:[   34] Training loss: 0.94714520, Validation loss: 0.94718197, Gradient norm: 0.25963355
INFO:root:At the start of the epoch: mem (CPU python)=34838.65625MB; mem (CPU total)=34622.078125MB
INFO:root:[   35] Training loss: 0.94699512, Validation loss: 0.94699307, Gradient norm: 0.28366918
INFO:root:At the start of the epoch: mem (CPU python)=34876.74609375MB; mem (CPU total)=34660.3515625MB
INFO:root:[   36] Training loss: 0.94675206, Validation loss: 0.94709578, Gradient norm: 0.27473646
INFO:root:At the start of the epoch: mem (CPU python)=34914.84375MB; mem (CPU total)=34698.52734375MB
INFO:root:[   37] Training loss: 0.94662897, Validation loss: 0.94714247, Gradient norm: 0.28400655
INFO:root:At the start of the epoch: mem (CPU python)=34952.94140625MB; mem (CPU total)=34736.45703125MB
INFO:root:[   38] Training loss: 0.94658295, Validation loss: 0.94634554, Gradient norm: 0.29474681
INFO:root:At the start of the epoch: mem (CPU python)=34991.03515625MB; mem (CPU total)=34774.5859375MB
INFO:root:[   39] Training loss: 0.94613738, Validation loss: 0.94603956, Gradient norm: 0.27782851
INFO:root:At the start of the epoch: mem (CPU python)=35029.1328125MB; mem (CPU total)=34811.80859375MB
INFO:root:[   40] Training loss: 0.94604287, Validation loss: 0.94597456, Gradient norm: 0.27855587
INFO:root:At the start of the epoch: mem (CPU python)=35067.23046875MB; mem (CPU total)=34850.0703125MB
INFO:root:[   41] Training loss: 0.94615719, Validation loss: 0.94606738, Gradient norm: 0.30583792
INFO:root:At the start of the epoch: mem (CPU python)=35105.3203125MB; mem (CPU total)=34888.87890625MB
INFO:root:[   42] Training loss: 0.94566017, Validation loss: 0.94535282, Gradient norm: 0.29107516
INFO:root:At the start of the epoch: mem (CPU python)=35143.41796875MB; mem (CPU total)=34925.44921875MB
INFO:root:[   43] Training loss: 0.94553919, Validation loss: 0.94659603, Gradient norm: 0.28993908
INFO:root:At the start of the epoch: mem (CPU python)=35181.51171875MB; mem (CPU total)=34963.12890625MB
INFO:root:[   44] Training loss: 0.94524103, Validation loss: 0.94609969, Gradient norm: 0.28560928
INFO:root:At the start of the epoch: mem (CPU python)=35219.609375MB; mem (CPU total)=35001.734375MB
INFO:root:[   45] Training loss: 0.94508209, Validation loss: 0.94487167, Gradient norm: 0.28624438
INFO:root:At the start of the epoch: mem (CPU python)=35257.703125MB; mem (CPU total)=35039.1484375MB
INFO:root:[   46] Training loss: 0.94496830, Validation loss: 0.94423087, Gradient norm: 0.29826886
INFO:root:At the start of the epoch: mem (CPU python)=35295.80078125MB; mem (CPU total)=35077.70703125MB
INFO:root:[   47] Training loss: 0.94481505, Validation loss: 0.94446669, Gradient norm: 0.28816656
INFO:root:At the start of the epoch: mem (CPU python)=35333.89453125MB; mem (CPU total)=35115.9140625MB
INFO:root:[   48] Training loss: 0.94453159, Validation loss: 0.94521934, Gradient norm: 0.29176650
INFO:root:At the start of the epoch: mem (CPU python)=35371.98828125MB; mem (CPU total)=35154.0859375MB
INFO:root:[   49] Training loss: 0.94424294, Validation loss: 0.94400290, Gradient norm: 0.29988363
INFO:root:At the start of the epoch: mem (CPU python)=35410.0859375MB; mem (CPU total)=35192.38671875MB
INFO:root:[   50] Training loss: 0.94392797, Validation loss: 0.94364739, Gradient norm: 0.29459050
INFO:root:At the start of the epoch: mem (CPU python)=35448.18359375MB; mem (CPU total)=35230.1171875MB
INFO:root:[   51] Training loss: 0.94366805, Validation loss: 0.94389378, Gradient norm: 0.29635489
INFO:root:At the start of the epoch: mem (CPU python)=35486.27734375MB; mem (CPU total)=35268.046875MB
INFO:root:[   52] Training loss: 0.94339399, Validation loss: 0.94362519, Gradient norm: 0.29377119
INFO:root:At the start of the epoch: mem (CPU python)=35524.37109375MB; mem (CPU total)=35305.9921875MB
INFO:root:[   53] Training loss: 0.94330257, Validation loss: 0.94330963, Gradient norm: 0.31090532
INFO:root:At the start of the epoch: mem (CPU python)=35562.46484375MB; mem (CPU total)=35344.07421875MB
INFO:root:[   54] Training loss: 0.94285413, Validation loss: 0.94276693, Gradient norm: 0.30119658
INFO:root:At the start of the epoch: mem (CPU python)=35600.5625MB; mem (CPU total)=35381.31640625MB
INFO:root:[   55] Training loss: 0.94281515, Validation loss: 0.94399009, Gradient norm: 0.32639959
INFO:root:At the start of the epoch: mem (CPU python)=35638.65625MB; mem (CPU total)=35420.125MB
INFO:root:[   56] Training loss: 0.94240240, Validation loss: 0.94318973, Gradient norm: 0.32834824
INFO:root:At the start of the epoch: mem (CPU python)=35676.75MB; mem (CPU total)=35457.78515625MB
INFO:root:[   57] Training loss: 0.94213968, Validation loss: 0.94228101, Gradient norm: 0.32194579
INFO:root:At the start of the epoch: mem (CPU python)=35714.8515625MB; mem (CPU total)=35495.625MB
INFO:root:[   58] Training loss: 0.94169057, Validation loss: 0.94130609, Gradient norm: 0.29382947
INFO:root:At the start of the epoch: mem (CPU python)=35752.9453125MB; mem (CPU total)=35533.5546875MB
INFO:root:[   59] Training loss: 0.94181385, Validation loss: 0.94245010, Gradient norm: 0.33541732
INFO:root:At the start of the epoch: mem (CPU python)=35791.0390625MB; mem (CPU total)=35571.515625MB
INFO:root:[   60] Training loss: 0.94150747, Validation loss: 0.94158352, Gradient norm: 0.32566730
INFO:root:At the start of the epoch: mem (CPU python)=35829.12890625MB; mem (CPU total)=35609.6953125MB
INFO:root:[   61] Training loss: 0.94117110, Validation loss: 0.94237115, Gradient norm: 0.31430956
INFO:root:At the start of the epoch: mem (CPU python)=35867.23046875MB; mem (CPU total)=35647.8359375MB
INFO:root:[   62] Training loss: 0.94107462, Validation loss: 0.94194393, Gradient norm: 0.32922694
INFO:root:At the start of the epoch: mem (CPU python)=35905.32421875MB; mem (CPU total)=35686.18359375MB
INFO:root:[   63] Training loss: 0.94102687, Validation loss: 0.94158132, Gradient norm: 0.32880353
INFO:root:At the start of the epoch: mem (CPU python)=35943.41796875MB; mem (CPU total)=35724.109375MB
INFO:root:[   64] Training loss: 0.94081391, Validation loss: 0.94050590, Gradient norm: 0.32652621
INFO:root:At the start of the epoch: mem (CPU python)=35981.51953125MB; mem (CPU total)=35762.5625MB
INFO:root:[   65] Training loss: 0.94044137, Validation loss: 0.94117518, Gradient norm: 0.32108056
INFO:root:At the start of the epoch: mem (CPU python)=36019.609375MB; mem (CPU total)=35800.6640625MB
INFO:root:[   66] Training loss: 0.94040136, Validation loss: 0.94032131, Gradient norm: 0.30694640
INFO:root:At the start of the epoch: mem (CPU python)=36057.70703125MB; mem (CPU total)=35838.6640625MB
INFO:root:[   67] Training loss: 0.94019808, Validation loss: 0.94033072, Gradient norm: 0.31462410
INFO:root:At the start of the epoch: mem (CPU python)=36095.8046875MB; mem (CPU total)=35877.0859375MB
INFO:root:[   68] Training loss: 0.94020601, Validation loss: 0.94038251, Gradient norm: 0.33008804
INFO:root:At the start of the epoch: mem (CPU python)=36133.8984375MB; mem (CPU total)=35914.5859375MB
INFO:root:[   69] Training loss: 0.93991398, Validation loss: 0.94103271, Gradient norm: 0.30766771
INFO:root:At the start of the epoch: mem (CPU python)=36171.9921875MB; mem (CPU total)=35952.8359375MB
INFO:root:[   70] Training loss: 0.93990421, Validation loss: 0.94015456, Gradient norm: 0.32791034
INFO:root:At the start of the epoch: mem (CPU python)=36210.0859375MB; mem (CPU total)=35991.2578125MB
INFO:root:[   71] Training loss: 0.93971255, Validation loss: 0.93999663, Gradient norm: 0.32482712
INFO:root:At the start of the epoch: mem (CPU python)=36248.1875MB; mem (CPU total)=36029.8671875MB
INFO:root:[   72] Training loss: 0.93947631, Validation loss: 0.93981464, Gradient norm: 0.31858884
INFO:root:At the start of the epoch: mem (CPU python)=36286.28125MB; mem (CPU total)=36068.1015625MB
INFO:root:[   73] Training loss: 0.93957891, Validation loss: 0.94000805, Gradient norm: 0.32864265
INFO:root:At the start of the epoch: mem (CPU python)=36324.37109375MB; mem (CPU total)=36106.5546875MB
INFO:root:[   74] Training loss: 0.93929825, Validation loss: 0.93964062, Gradient norm: 0.33263896
INFO:root:At the start of the epoch: mem (CPU python)=36362.47265625MB; mem (CPU total)=36144.53125MB
INFO:root:[   75] Training loss: 0.93904719, Validation loss: 0.93946492, Gradient norm: 0.31781359
INFO:root:At the start of the epoch: mem (CPU python)=36400.56640625MB; mem (CPU total)=36182.6953125MB
INFO:root:[   76] Training loss: 0.93908785, Validation loss: 0.93993582, Gradient norm: 0.33471481
INFO:root:At the start of the epoch: mem (CPU python)=36438.66015625MB; mem (CPU total)=36221.46875MB
INFO:root:[   77] Training loss: 0.93889316, Validation loss: 0.93951326, Gradient norm: 0.32480665
INFO:root:At the start of the epoch: mem (CPU python)=36476.75390625MB; mem (CPU total)=36259.63671875MB
INFO:root:[   78] Training loss: 0.93892956, Validation loss: 0.93911568, Gradient norm: 0.35909324
INFO:root:At the start of the epoch: mem (CPU python)=36514.8515625MB; mem (CPU total)=36298.15234375MB
INFO:root:[   79] Training loss: 0.93861949, Validation loss: 0.93916237, Gradient norm: 0.33135237
INFO:root:At the start of the epoch: mem (CPU python)=36552.9453125MB; mem (CPU total)=36336.0234375MB
INFO:root:[   80] Training loss: 0.93847812, Validation loss: 0.93865914, Gradient norm: 0.32997263
INFO:root:At the start of the epoch: mem (CPU python)=36591.0390625MB; mem (CPU total)=36374.4140625MB
INFO:root:[   81] Training loss: 0.93821992, Validation loss: 0.93938903, Gradient norm: 0.31522043
INFO:root:At the start of the epoch: mem (CPU python)=36629.13671875MB; mem (CPU total)=36412.6796875MB
INFO:root:[   82] Training loss: 0.93819740, Validation loss: 0.93895403, Gradient norm: 0.33142165
INFO:root:At the start of the epoch: mem (CPU python)=36667.23046875MB; mem (CPU total)=36450.76171875MB
INFO:root:[   83] Training loss: 0.93805259, Validation loss: 0.93830158, Gradient norm: 0.33975237
INFO:root:At the start of the epoch: mem (CPU python)=36705.328125MB; mem (CPU total)=36489.30859375MB
INFO:root:[   84] Training loss: 0.93785476, Validation loss: 0.93863944, Gradient norm: 0.33529236
INFO:root:At the start of the epoch: mem (CPU python)=36743.421875MB; mem (CPU total)=36527.9375MB
INFO:root:[   85] Training loss: 0.93758053, Validation loss: 0.93799154, Gradient norm: 0.30569111
INFO:root:At the start of the epoch: mem (CPU python)=36781.51953125MB; mem (CPU total)=36565.7578125MB
INFO:root:[   86] Training loss: 0.93752411, Validation loss: 0.93774515, Gradient norm: 0.33964890
INFO:root:At the start of the epoch: mem (CPU python)=36819.61328125MB; mem (CPU total)=36604.03125MB
INFO:root:[   87] Training loss: 0.93726227, Validation loss: 0.93854834, Gradient norm: 0.31216454
INFO:root:At the start of the epoch: mem (CPU python)=36857.70703125MB; mem (CPU total)=36642.59765625MB
INFO:root:[   88] Training loss: 0.93719670, Validation loss: 0.93764457, Gradient norm: 0.34361492
INFO:root:At the start of the epoch: mem (CPU python)=36895.80859375MB; mem (CPU total)=36680.62109375MB
INFO:root:[   89] Training loss: 0.93710473, Validation loss: 0.93730320, Gradient norm: 0.33378640
INFO:root:At the start of the epoch: mem (CPU python)=36933.90234375MB; mem (CPU total)=36718.703125MB
INFO:root:[   90] Training loss: 0.93686326, Validation loss: 0.93726311, Gradient norm: 0.30856966
INFO:root:At the start of the epoch: mem (CPU python)=36971.99609375MB; mem (CPU total)=36757.0625MB
INFO:root:[   91] Training loss: 0.93683839, Validation loss: 0.93703163, Gradient norm: 0.35694547
INFO:root:At the start of the epoch: mem (CPU python)=37010.09375MB; mem (CPU total)=36795.58203125MB
INFO:root:[   92] Training loss: 0.93663815, Validation loss: 0.93696308, Gradient norm: 0.33555744
INFO:root:At the start of the epoch: mem (CPU python)=37048.1875MB; mem (CPU total)=36834.390625MB
INFO:root:[   93] Training loss: 0.93646175, Validation loss: 0.93727676, Gradient norm: 0.33529234
INFO:root:At the start of the epoch: mem (CPU python)=37086.28125MB; mem (CPU total)=36872.53515625MB
INFO:root:[   94] Training loss: 0.93651466, Validation loss: 0.93601858, Gradient norm: 0.35241017
INFO:root:At the start of the epoch: mem (CPU python)=37124.375MB; mem (CPU total)=36910.86328125MB
INFO:root:[   95] Training loss: 0.93614844, Validation loss: 0.93711575, Gradient norm: 0.32023632
INFO:root:At the start of the epoch: mem (CPU python)=37162.47265625MB; mem (CPU total)=36949.25390625MB
INFO:root:[   96] Training loss: 0.93591963, Validation loss: 0.93674395, Gradient norm: 0.32553858
INFO:root:At the start of the epoch: mem (CPU python)=37200.5703125MB; mem (CPU total)=36987.3046875MB
INFO:root:[   97] Training loss: 0.93614576, Validation loss: 0.93735121, Gradient norm: 0.34698093
INFO:root:At the start of the epoch: mem (CPU python)=37238.6640625MB; mem (CPU total)=37025.5234375MB
INFO:root:[   98] Training loss: 0.93572009, Validation loss: 0.93647781, Gradient norm: 0.34600405
INFO:root:At the start of the epoch: mem (CPU python)=37276.76171875MB; mem (CPU total)=37063.83203125MB
INFO:root:[   99] Training loss: 0.93555961, Validation loss: 0.93631510, Gradient norm: 0.33266749
INFO:root:At the start of the epoch: mem (CPU python)=37314.859375MB; mem (CPU total)=37101.96875MB
INFO:root:[  100] Training loss: 0.93559754, Validation loss: 0.93591547, Gradient norm: 0.35570129
INFO:root:At the start of the epoch: mem (CPU python)=37352.953125MB; mem (CPU total)=37140.3125MB
INFO:root:[  101] Training loss: 0.93547309, Validation loss: 0.93614631, Gradient norm: 0.34319139
INFO:root:At the start of the epoch: mem (CPU python)=37391.05078125MB; mem (CPU total)=37178.703125MB
INFO:root:[  102] Training loss: 0.93542817, Validation loss: 0.93625224, Gradient norm: 0.35328761
INFO:root:At the start of the epoch: mem (CPU python)=37429.14453125MB; mem (CPU total)=37216.6015625MB
INFO:root:[  103] Training loss: 0.93521372, Validation loss: 0.93588061, Gradient norm: 0.33522714
INFO:root:At the start of the epoch: mem (CPU python)=37467.23828125MB; mem (CPU total)=37255.0546875MB
INFO:root:[  104] Training loss: 0.93518237, Validation loss: 0.93564827, Gradient norm: 0.36451971
INFO:root:At the start of the epoch: mem (CPU python)=37505.3359375MB; mem (CPU total)=37293.37890625MB
INFO:root:[  105] Training loss: 0.93502740, Validation loss: 0.93504789, Gradient norm: 0.35263702
INFO:root:At the start of the epoch: mem (CPU python)=37543.43359375MB; mem (CPU total)=37331.109375MB
INFO:root:[  106] Training loss: 0.93480801, Validation loss: 0.93569762, Gradient norm: 0.32748725
INFO:root:At the start of the epoch: mem (CPU python)=37581.5234375MB; mem (CPU total)=37369.5859375MB
INFO:root:[  107] Training loss: 0.93468462, Validation loss: 0.93661513, Gradient norm: 0.33668754
INFO:root:At the start of the epoch: mem (CPU python)=37619.62109375MB; mem (CPU total)=37407.05078125MB
INFO:root:[  108] Training loss: 0.93457052, Validation loss: 0.93489140, Gradient norm: 0.34205245
INFO:root:At the start of the epoch: mem (CPU python)=37657.71875MB; mem (CPU total)=37445.734375MB
INFO:root:[  109] Training loss: 0.93447731, Validation loss: 0.93611182, Gradient norm: 0.34114107
INFO:root:At the start of the epoch: mem (CPU python)=37695.8125MB; mem (CPU total)=37483.62109375MB
INFO:root:[  110] Training loss: 0.93445264, Validation loss: 0.93511388, Gradient norm: 0.35262743
INFO:root:At the start of the epoch: mem (CPU python)=37733.90625MB; mem (CPU total)=37521.765625MB
INFO:root:[  111] Training loss: 0.93425053, Validation loss: 0.93534810, Gradient norm: 0.35129038
INFO:root:At the start of the epoch: mem (CPU python)=37772.0MB; mem (CPU total)=37558.9609375MB
INFO:root:[  112] Training loss: 0.93436295, Validation loss: 0.93508867, Gradient norm: 0.36575392
INFO:root:At the start of the epoch: mem (CPU python)=37810.09765625MB; mem (CPU total)=37597.2578125MB
INFO:root:[  113] Training loss: 0.93419125, Validation loss: 0.93475601, Gradient norm: 0.34726119
INFO:root:At the start of the epoch: mem (CPU python)=37848.1953125MB; mem (CPU total)=37635.51171875MB
INFO:root:[  114] Training loss: 0.93408307, Validation loss: 0.93494258, Gradient norm: 0.33343251
INFO:root:At the start of the epoch: mem (CPU python)=37886.28515625MB; mem (CPU total)=37673.40625MB
INFO:root:[  115] Training loss: 0.93374629, Validation loss: 0.93547529, Gradient norm: 0.32263037
INFO:root:At the start of the epoch: mem (CPU python)=37924.38671875MB; mem (CPU total)=37711.55078125MB
INFO:root:[  116] Training loss: 0.93371476, Validation loss: 0.93516296, Gradient norm: 0.34391475
INFO:root:At the start of the epoch: mem (CPU python)=37962.4765625MB; mem (CPU total)=37749.94140625MB
INFO:root:[  117] Training loss: 0.93373651, Validation loss: 0.93388961, Gradient norm: 0.34819475
INFO:root:At the start of the epoch: mem (CPU python)=38000.57421875MB; mem (CPU total)=37787.9765625MB
INFO:root:[  118] Training loss: 0.93363963, Validation loss: 0.93499968, Gradient norm: 0.36314740
INFO:root:At the start of the epoch: mem (CPU python)=38038.671875MB; mem (CPU total)=37825.828125MB
INFO:root:[  119] Training loss: 0.93346139, Validation loss: 0.93495859, Gradient norm: 0.35893705
INFO:root:At the start of the epoch: mem (CPU python)=38076.765625MB; mem (CPU total)=37864.25MB
INFO:root:[  120] Training loss: 0.93342419, Validation loss: 0.93460457, Gradient norm: 0.34278628
INFO:root:At the start of the epoch: mem (CPU python)=38114.859375MB; mem (CPU total)=37902.39453125MB
INFO:root:[  121] Training loss: 0.93332191, Validation loss: 0.93402787, Gradient norm: 0.34315544
INFO:root:At the start of the epoch: mem (CPU python)=38152.953125MB; mem (CPU total)=37940.21484375MB
INFO:root:[  122] Training loss: 0.93329049, Validation loss: 0.93431742, Gradient norm: 0.35778034
INFO:root:At the start of the epoch: mem (CPU python)=38191.05078125MB; mem (CPU total)=37978.60546875MB
INFO:root:[  123] Training loss: 0.93308710, Validation loss: 0.93424800, Gradient norm: 0.33741488
INFO:root:At the start of the epoch: mem (CPU python)=38229.1484375MB; mem (CPU total)=38016.75MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  124] Training loss: 0.93309398, Validation loss: 0.93464601, Gradient norm: 0.34788059
INFO:root:At the start of the epoch: mem (CPU python)=38267.2421875MB; mem (CPU total)=38054.17578125MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  125] Training loss: 0.93131362, Validation loss: 0.93247244, Gradient norm: 0.28400633
INFO:root:At the start of the epoch: mem (CPU python)=38305.33984375MB; mem (CPU total)=38093.1328125MB
INFO:root:[  126] Training loss: 0.93029239, Validation loss: 0.93203488, Gradient norm: 0.28207747
INFO:root:At the start of the epoch: mem (CPU python)=38343.43359375MB; mem (CPU total)=38131.6328125MB
INFO:root:[  127] Training loss: 0.93010171, Validation loss: 0.93193184, Gradient norm: 0.27073111
INFO:root:At the start of the epoch: mem (CPU python)=38381.52734375MB; mem (CPU total)=38169.671875MB
INFO:root:[  128] Training loss: 0.93002995, Validation loss: 0.93159763, Gradient norm: 0.29231600
INFO:root:At the start of the epoch: mem (CPU python)=38419.62109375MB; mem (CPU total)=38208.25MB
INFO:root:[  129] Training loss: 0.93004031, Validation loss: 0.93176975, Gradient norm: 0.28370378
INFO:root:At the start of the epoch: mem (CPU python)=38457.71875MB; mem (CPU total)=38246.87109375MB
INFO:root:[  130] Training loss: 0.92997400, Validation loss: 0.93199176, Gradient norm: 0.29323305
INFO:root:At the start of the epoch: mem (CPU python)=38495.8125MB; mem (CPU total)=38285.015625MB
INFO:root:[  131] Training loss: 0.92998231, Validation loss: 0.93181156, Gradient norm: 0.31035644
INFO:root:At the start of the epoch: mem (CPU python)=38533.91015625MB; mem (CPU total)=38322.3984375MB
INFO:root:[  132] Training loss: 0.92993013, Validation loss: 0.93152905, Gradient norm: 0.29307820
INFO:root:At the start of the epoch: mem (CPU python)=38572.0078125MB; mem (CPU total)=38360.578125MB
INFO:root:[  133] Training loss: 0.92985365, Validation loss: 0.93188910, Gradient norm: 0.30338096
INFO:root:At the start of the epoch: mem (CPU python)=38610.1015625MB; mem (CPU total)=38398.75390625MB
INFO:root:[  134] Training loss: 0.92981722, Validation loss: 0.93140675, Gradient norm: 0.30066396
INFO:root:At the start of the epoch: mem (CPU python)=38648.1953125MB; mem (CPU total)=38436.8046875MB
INFO:root:[  135] Training loss: 0.92985985, Validation loss: 0.93195836, Gradient norm: 0.31072251
INFO:root:At the start of the epoch: mem (CPU python)=38686.29296875MB; mem (CPU total)=38475.1953125MB
INFO:root:[  136] Training loss: 0.92973182, Validation loss: 0.93187932, Gradient norm: 0.30415042
INFO:root:At the start of the epoch: mem (CPU python)=38724.38671875MB; mem (CPU total)=38513.09375MB
INFO:root:[  137] Training loss: 0.92972642, Validation loss: 0.93161889, Gradient norm: 0.31341952
INFO:root:At the start of the epoch: mem (CPU python)=38762.484375MB; mem (CPU total)=38551.14453125MB
INFO:root:[  138] Training loss: 0.92969334, Validation loss: 0.93167816, Gradient norm: 0.29526340
INFO:root:At the start of the epoch: mem (CPU python)=38800.578125MB; mem (CPU total)=38589.86328125MB
INFO:root:[  139] Training loss: 0.92967526, Validation loss: 0.93190126, Gradient norm: 0.31746902
INFO:root:At the start of the epoch: mem (CPU python)=38838.67578125MB; mem (CPU total)=38627.58203125MB
INFO:root:[  140] Training loss: 0.92984926, Validation loss: 0.93166128, Gradient norm: 0.32115657
INFO:root:At the start of the epoch: mem (CPU python)=38876.76953125MB; mem (CPU total)=38665.484375MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  141] Training loss: 0.92956820, Validation loss: 0.93196413, Gradient norm: 0.30021057
INFO:root:At the start of the epoch: mem (CPU python)=38914.86328125MB; mem (CPU total)=38703.625MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  142] Training loss: 0.92906661, Validation loss: 0.93128101, Gradient norm: 0.28127702
INFO:root:At the start of the epoch: mem (CPU python)=38952.96484375MB; mem (CPU total)=38742.32421875MB
INFO:root:[  143] Training loss: 0.92872414, Validation loss: 0.93126925, Gradient norm: 0.27222371
INFO:root:At the start of the epoch: mem (CPU python)=38991.05859375MB; mem (CPU total)=38779.7578125MB
INFO:root:[  144] Training loss: 0.92865061, Validation loss: 0.93121578, Gradient norm: 0.28182498
INFO:root:At the start of the epoch: mem (CPU python)=39029.15234375MB; mem (CPU total)=38815.9921875MB
INFO:root:[  145] Training loss: 0.92860279, Validation loss: 0.93088190, Gradient norm: 0.28420957
INFO:root:At the start of the epoch: mem (CPU python)=39067.25390625MB; mem (CPU total)=38854.22265625MB
INFO:root:[  146] Training loss: 0.92864625, Validation loss: 0.93092440, Gradient norm: 0.27942759
INFO:root:At the start of the epoch: mem (CPU python)=39105.34765625MB; mem (CPU total)=38892.25MB
INFO:root:[  147] Training loss: 0.92868026, Validation loss: 0.93098701, Gradient norm: 0.28679309
INFO:root:At the start of the epoch: mem (CPU python)=39143.44140625MB; mem (CPU total)=38930.39453125MB
INFO:root:[  148] Training loss: 0.92864578, Validation loss: 0.93108881, Gradient norm: 0.28895594
INFO:root:At the start of the epoch: mem (CPU python)=39181.53515625MB; mem (CPU total)=38968.49609375MB
INFO:root:[  149] Training loss: 0.92850626, Validation loss: 0.93034820, Gradient norm: 0.28305911
INFO:root:At the start of the epoch: mem (CPU python)=39219.63671875MB; mem (CPU total)=39007.2421875MB
INFO:root:[  150] Training loss: 0.92868005, Validation loss: 0.93066031, Gradient norm: 0.30080588
INFO:root:At the start of the epoch: mem (CPU python)=39257.7265625MB; mem (CPU total)=39045.41796875MB
INFO:root:[  151] Training loss: 0.92858219, Validation loss: 0.93082058, Gradient norm: 0.28339177
INFO:root:At the start of the epoch: mem (CPU python)=39295.82421875MB; mem (CPU total)=39083.6484375MB
INFO:root:[  152] Training loss: 0.92861395, Validation loss: 0.93104535, Gradient norm: 0.28969356
INFO:root:At the start of the epoch: mem (CPU python)=39333.921875MB; mem (CPU total)=39121.5703125MB
INFO:root:[  153] Training loss: 0.92856337, Validation loss: 0.93137374, Gradient norm: 0.29266820
INFO:root:At the start of the epoch: mem (CPU python)=39372.015625MB; mem (CPU total)=39159.6953125MB
INFO:root:[  154] Training loss: 0.92857049, Validation loss: 0.93086001, Gradient norm: 0.28989171
INFO:root:At the start of the epoch: mem (CPU python)=39410.109375MB; mem (CPU total)=39198.0859375MB
INFO:root:[  155] Training loss: 0.92854426, Validation loss: 0.93110608, Gradient norm: 0.29506206
INFO:root:At the start of the epoch: mem (CPU python)=39448.203125MB; mem (CPU total)=39236.22265625MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  156] Training loss: 0.92847398, Validation loss: 0.93090116, Gradient norm: 0.29433426
INFO:root:At the start of the epoch: mem (CPU python)=39486.296875MB; mem (CPU total)=39274.3671875MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  157] Training loss: 0.92837011, Validation loss: 0.93101817, Gradient norm: 0.29044468
INFO:root:At the start of the epoch: mem (CPU python)=39524.39453125MB; mem (CPU total)=39312.265625MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  158] Training loss: 0.92826609, Validation loss: 0.93069509, Gradient norm: 0.28623615
INFO:root:At the start of the epoch: mem (CPU python)=39562.48828125MB; mem (CPU total)=39350.8203125MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:EP 158: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=39600.4296875MB; mem (CPU total)=39388.93359375MB
INFO:root:Training the model took 13577.864s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93004
INFO:root:EnergyScoreTrain: 0.83219
INFO:root:CRPSTrain: 0.67567
INFO:root:Gaussian NLLTrain: 1773.45964
INFO:root:CoverageTrain: 0.11754
INFO:root:IntervalWidthTrain: 0.22815
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93541
INFO:root:EnergyScoreValidation: 0.83911
INFO:root:CRPSValidation: 0.68138
INFO:root:Gaussian NLLValidation: 2533.55915
INFO:root:CoverageValidation: 0.11475
INFO:root:IntervalWidthValidation: 0.22503
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93498
INFO:root:EnergyScoreTest: 0.83825
INFO:root:CRPSTest: 0.6817
INFO:root:Gaussian NLLTest: 1371.07083
INFO:root:CoverageTest: 0.11402
INFO:root:IntervalWidthTest: 0.22357
INFO:root:After validation: mem (CPU python)=39674.265625MB; mem (CPU total)=39462.171875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=39674.265625MB; mem (CPU total)=39462.171875MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=39675.91015625MB; mem (CPU total)=39463.89453125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=39675.91796875MB; mem (CPU total)=39463.89453125MB
INFO:root:[    1] Training loss: 1.00423474, Validation loss: 0.99083124, Gradient norm: 0.05268471
INFO:root:At the start of the epoch: mem (CPU python)=39713.6171875MB; mem (CPU total)=39502.09375MB
INFO:root:[    2] Training loss: 0.98122712, Validation loss: 0.97847533, Gradient norm: 0.12729702
INFO:root:At the start of the epoch: mem (CPU python)=39751.7109375MB; mem (CPU total)=39539.25390625MB
INFO:root:[    3] Training loss: 0.97418176, Validation loss: 0.97303840, Gradient norm: 0.14443976
INFO:root:At the start of the epoch: mem (CPU python)=39789.80859375MB; mem (CPU total)=39577.34765625MB
INFO:root:[    4] Training loss: 0.97137987, Validation loss: 0.97202832, Gradient norm: 0.15438369
INFO:root:At the start of the epoch: mem (CPU python)=39827.90234375MB; mem (CPU total)=39615.72265625MB
INFO:root:[    5] Training loss: 0.96951672, Validation loss: 0.96968600, Gradient norm: 0.15937954
INFO:root:At the start of the epoch: mem (CPU python)=39865.99609375MB; mem (CPU total)=39654.0859375MB
INFO:root:[    6] Training loss: 0.96804939, Validation loss: 0.96900243, Gradient norm: 0.16510661
INFO:root:At the start of the epoch: mem (CPU python)=39904.09375MB; mem (CPU total)=39692.484375MB
INFO:root:[    7] Training loss: 0.96688154, Validation loss: 0.96725134, Gradient norm: 0.17811810
INFO:root:At the start of the epoch: mem (CPU python)=39942.1875MB; mem (CPU total)=39731.0MB
INFO:root:[    8] Training loss: 0.96560827, Validation loss: 0.96652421, Gradient norm: 0.18045131
INFO:root:At the start of the epoch: mem (CPU python)=39980.28515625MB; mem (CPU total)=39769.7578125MB
INFO:root:[    9] Training loss: 0.96448493, Validation loss: 0.96552669, Gradient norm: 0.19767990
INFO:root:At the start of the epoch: mem (CPU python)=40018.37890625MB; mem (CPU total)=39808.0234375MB
INFO:root:[   10] Training loss: 0.96364884, Validation loss: 0.96415236, Gradient norm: 0.21298703
INFO:root:At the start of the epoch: mem (CPU python)=40056.4765625MB; mem (CPU total)=39845.82421875MB
INFO:root:[   11] Training loss: 0.96288858, Validation loss: 0.96352873, Gradient norm: 0.20608673
INFO:root:At the start of the epoch: mem (CPU python)=40094.5703125MB; mem (CPU total)=39883.5078125MB
INFO:root:[   12] Training loss: 0.96224321, Validation loss: 0.96227472, Gradient norm: 0.20499209
INFO:root:At the start of the epoch: mem (CPU python)=40132.66796875MB; mem (CPU total)=39921.86328125MB
INFO:root:[   13] Training loss: 0.96176083, Validation loss: 0.96173025, Gradient norm: 0.21232402
INFO:root:At the start of the epoch: mem (CPU python)=40170.765625MB; mem (CPU total)=39959.4375MB
INFO:root:[   14] Training loss: 0.96121507, Validation loss: 0.96199049, Gradient norm: 0.22005339
INFO:root:At the start of the epoch: mem (CPU python)=40208.85546875MB; mem (CPU total)=39997.3359375MB
INFO:root:[   15] Training loss: 0.96053261, Validation loss: 0.96124193, Gradient norm: 0.21705191
INFO:root:At the start of the epoch: mem (CPU python)=40246.953125MB; mem (CPU total)=40035.97265625MB
INFO:root:[   16] Training loss: 0.96009569, Validation loss: 0.96053732, Gradient norm: 0.22654730
INFO:root:At the start of the epoch: mem (CPU python)=40285.05078125MB; mem (CPU total)=40074.2421875MB
INFO:root:[   17] Training loss: 0.95943269, Validation loss: 0.95993797, Gradient norm: 0.23119046
INFO:root:At the start of the epoch: mem (CPU python)=40323.14453125MB; mem (CPU total)=40112.8828125MB
INFO:root:[   18] Training loss: 0.95917607, Validation loss: 0.95952820, Gradient norm: 0.22960477
INFO:root:At the start of the epoch: mem (CPU python)=40361.23828125MB; mem (CPU total)=40151.69140625MB
INFO:root:[   19] Training loss: 0.95851331, Validation loss: 0.95979775, Gradient norm: 0.23301928
INFO:root:At the start of the epoch: mem (CPU python)=40399.33203125MB; mem (CPU total)=40190.1015625MB
INFO:root:[   20] Training loss: 0.95793862, Validation loss: 0.95846857, Gradient norm: 0.23776502
INFO:root:At the start of the epoch: mem (CPU python)=40437.43359375MB; mem (CPU total)=40228.078125MB
INFO:root:[   21] Training loss: 0.95745980, Validation loss: 0.95728577, Gradient norm: 0.23404450
INFO:root:At the start of the epoch: mem (CPU python)=40475.52734375MB; mem (CPU total)=40266.125MB
INFO:root:[   22] Training loss: 0.95683510, Validation loss: 0.95672767, Gradient norm: 0.26255769
INFO:root:At the start of the epoch: mem (CPU python)=40513.62109375MB; mem (CPU total)=40304.46875MB
INFO:root:[   23] Training loss: 0.95615059, Validation loss: 0.95697257, Gradient norm: 0.26150819
INFO:root:At the start of the epoch: mem (CPU python)=40551.71484375MB; mem (CPU total)=40343.10546875MB
INFO:root:[   24] Training loss: 0.95567335, Validation loss: 0.95569553, Gradient norm: 0.27416850
INFO:root:At the start of the epoch: mem (CPU python)=40589.8125MB; mem (CPU total)=40380.97265625MB
INFO:root:[   25] Training loss: 0.95517233, Validation loss: 0.95542242, Gradient norm: 0.26919754
INFO:root:At the start of the epoch: mem (CPU python)=40627.90625MB; mem (CPU total)=40419.25390625MB
INFO:root:[   26] Training loss: 0.95445506, Validation loss: 0.95463284, Gradient norm: 0.27014237
INFO:root:At the start of the epoch: mem (CPU python)=40666.0MB; mem (CPU total)=40457.734375MB
INFO:root:[   27] Training loss: 0.95418557, Validation loss: 0.95482736, Gradient norm: 0.28128002
INFO:root:At the start of the epoch: mem (CPU python)=40704.09765625MB; mem (CPU total)=40495.86328125MB
INFO:root:[   28] Training loss: 0.95368269, Validation loss: 0.95353763, Gradient norm: 0.26573620
INFO:root:At the start of the epoch: mem (CPU python)=40742.1953125MB; mem (CPU total)=40534.22265625MB
INFO:root:[   29] Training loss: 0.95311275, Validation loss: 0.95283996, Gradient norm: 0.28485471
INFO:root:At the start of the epoch: mem (CPU python)=40780.2890625MB; mem (CPU total)=40572.703125MB
INFO:root:[   30] Training loss: 0.95265180, Validation loss: 0.95269097, Gradient norm: 0.27545151
INFO:root:At the start of the epoch: mem (CPU python)=40818.38671875MB; mem (CPU total)=40611.171875MB
INFO:root:[   31] Training loss: 0.95226602, Validation loss: 0.95269397, Gradient norm: 0.27946781
INFO:root:At the start of the epoch: mem (CPU python)=40856.4765625MB; mem (CPU total)=40648.9296875MB
INFO:root:[   32] Training loss: 0.95191935, Validation loss: 0.95169769, Gradient norm: 0.28456123
INFO:root:At the start of the epoch: mem (CPU python)=40894.57421875MB; mem (CPU total)=40687.1171875MB
INFO:root:[   33] Training loss: 0.95142073, Validation loss: 0.95165693, Gradient norm: 0.27467750
INFO:root:At the start of the epoch: mem (CPU python)=40932.671875MB; mem (CPU total)=40725.53515625MB
INFO:root:[   34] Training loss: 0.95103053, Validation loss: 0.95057325, Gradient norm: 0.28370674
INFO:root:At the start of the epoch: mem (CPU python)=40970.765625MB; mem (CPU total)=40763.3203125MB
INFO:root:[   35] Training loss: 0.95068154, Validation loss: 0.95070596, Gradient norm: 0.28325372
INFO:root:At the start of the epoch: mem (CPU python)=41008.859375MB; mem (CPU total)=40801.46484375MB
INFO:root:[   36] Training loss: 0.95046228, Validation loss: 0.95046357, Gradient norm: 0.29061889
INFO:root:At the start of the epoch: mem (CPU python)=41046.953125MB; mem (CPU total)=40839.53125MB
INFO:root:[   37] Training loss: 0.95011578, Validation loss: 0.95044475, Gradient norm: 0.31155418
INFO:root:At the start of the epoch: mem (CPU python)=41085.0546875MB; mem (CPU total)=40877.453125MB
INFO:root:[   38] Training loss: 0.94962212, Validation loss: 0.94916029, Gradient norm: 0.27872750
INFO:root:At the start of the epoch: mem (CPU python)=41123.1484375MB; mem (CPU total)=40916.125MB
INFO:root:[   39] Training loss: 0.94951733, Validation loss: 0.94964651, Gradient norm: 0.31789994
INFO:root:At the start of the epoch: mem (CPU python)=41161.23828125MB; mem (CPU total)=40954.515625MB
INFO:root:[   40] Training loss: 0.94887882, Validation loss: 0.95055457, Gradient norm: 0.29699084
INFO:root:At the start of the epoch: mem (CPU python)=41199.3359375MB; mem (CPU total)=40992.62890625MB
INFO:root:[   41] Training loss: 0.94871640, Validation loss: 0.94908019, Gradient norm: 0.29453669
INFO:root:At the start of the epoch: mem (CPU python)=41237.43359375MB; mem (CPU total)=41030.953125MB
INFO:root:[   42] Training loss: 0.94826286, Validation loss: 0.94832137, Gradient norm: 0.30034381
INFO:root:At the start of the epoch: mem (CPU python)=41275.52734375MB; mem (CPU total)=41068.77734375MB
INFO:root:[   43] Training loss: 0.94780896, Validation loss: 0.94820289, Gradient norm: 0.29607499
INFO:root:At the start of the epoch: mem (CPU python)=41313.625MB; mem (CPU total)=41107.2734375MB
INFO:root:[   44] Training loss: 0.94772737, Validation loss: 0.94727561, Gradient norm: 0.30196762
INFO:root:At the start of the epoch: mem (CPU python)=41351.71875MB; mem (CPU total)=41145.44921875MB
INFO:root:[   45] Training loss: 0.94725440, Validation loss: 0.94730939, Gradient norm: 0.28857043
INFO:root:At the start of the epoch: mem (CPU python)=41389.8125MB; mem (CPU total)=41183.59375MB
INFO:root:[   46] Training loss: 0.94744302, Validation loss: 0.94734960, Gradient norm: 0.33722547
INFO:root:At the start of the epoch: mem (CPU python)=41427.90625MB; mem (CPU total)=41221.70703125MB
INFO:root:[   47] Training loss: 0.94667533, Validation loss: 0.94722715, Gradient norm: 0.31618834
INFO:root:At the start of the epoch: mem (CPU python)=41466.0078125MB; mem (CPU total)=41259.91015625MB
INFO:root:[   48] Training loss: 0.94652107, Validation loss: 0.94599503, Gradient norm: 0.31256120
INFO:root:At the start of the epoch: mem (CPU python)=41504.1015625MB; mem (CPU total)=41297.58984375MB
INFO:root:[   49] Training loss: 0.94632176, Validation loss: 0.94694906, Gradient norm: 0.31000797
INFO:root:At the start of the epoch: mem (CPU python)=41542.19140625MB; mem (CPU total)=41335.47265625MB
INFO:root:[   50] Training loss: 0.94611913, Validation loss: 0.94649670, Gradient norm: 0.32255806
INFO:root:At the start of the epoch: mem (CPU python)=41580.29296875MB; mem (CPU total)=41373.8828125MB
INFO:root:[   51] Training loss: 0.94576306, Validation loss: 0.94516034, Gradient norm: 0.31374704
INFO:root:At the start of the epoch: mem (CPU python)=41618.38671875MB; mem (CPU total)=41411.4453125MB
INFO:root:[   52] Training loss: 0.94554294, Validation loss: 0.94563134, Gradient norm: 0.33204345
INFO:root:At the start of the epoch: mem (CPU python)=41656.48046875MB; mem (CPU total)=41449.58984375MB
INFO:root:[   53] Training loss: 0.94537255, Validation loss: 0.94466478, Gradient norm: 0.35055854
INFO:root:At the start of the epoch: mem (CPU python)=41694.57421875MB; mem (CPU total)=41486.55859375MB
INFO:root:[   54] Training loss: 0.94495796, Validation loss: 0.94524474, Gradient norm: 0.31778873
INFO:root:At the start of the epoch: mem (CPU python)=41732.671875MB; mem (CPU total)=41524.640625MB
INFO:root:[   55] Training loss: 0.94491343, Validation loss: 0.94430191, Gradient norm: 0.35126906
INFO:root:At the start of the epoch: mem (CPU python)=41770.76953125MB; mem (CPU total)=41562.828125MB
INFO:root:[   56] Training loss: 0.94455385, Validation loss: 0.94439855, Gradient norm: 0.32541229
INFO:root:At the start of the epoch: mem (CPU python)=41808.859375MB; mem (CPU total)=41601.25MB
INFO:root:[   57] Training loss: 0.94425470, Validation loss: 0.94376981, Gradient norm: 0.33749340
INFO:root:At the start of the epoch: mem (CPU python)=41846.9609375MB; mem (CPU total)=41639.1875MB
INFO:root:[   58] Training loss: 0.94392210, Validation loss: 0.94415624, Gradient norm: 0.31620123
INFO:root:At the start of the epoch: mem (CPU python)=41885.0546875MB; mem (CPU total)=41677.3125MB
INFO:root:[   59] Training loss: 0.94378722, Validation loss: 0.94380668, Gradient norm: 0.33525736
INFO:root:At the start of the epoch: mem (CPU python)=41923.1484375MB; mem (CPU total)=41715.44140625MB
INFO:root:[   60] Training loss: 0.94363780, Validation loss: 0.94462557, Gradient norm: 0.34349388
INFO:root:At the start of the epoch: mem (CPU python)=41961.2421875MB; mem (CPU total)=41753.4921875MB
INFO:root:[   61] Training loss: 0.94344096, Validation loss: 0.94334741, Gradient norm: 0.34530389
INFO:root:At the start of the epoch: mem (CPU python)=41999.33984375MB; mem (CPU total)=41791.26953125MB
INFO:root:[   62] Training loss: 0.94316452, Validation loss: 0.94324854, Gradient norm: 0.34405884
INFO:root:At the start of the epoch: mem (CPU python)=42037.43359375MB; mem (CPU total)=41828.96484375MB
INFO:root:[   63] Training loss: 0.94286130, Validation loss: 0.94271707, Gradient norm: 0.31274888
INFO:root:At the start of the epoch: mem (CPU python)=42075.53125MB; mem (CPU total)=41866.90234375MB
INFO:root:[   64] Training loss: 0.94278282, Validation loss: 0.94278859, Gradient norm: 0.33084594
INFO:root:At the start of the epoch: mem (CPU python)=42113.625MB; mem (CPU total)=41904.78125MB
INFO:root:[   65] Training loss: 0.94264220, Validation loss: 0.94238047, Gradient norm: 0.34918636
INFO:root:At the start of the epoch: mem (CPU python)=42151.7265625MB; mem (CPU total)=41943.09375MB
INFO:root:[   66] Training loss: 0.94225650, Validation loss: 0.94195792, Gradient norm: 0.32799673
INFO:root:At the start of the epoch: mem (CPU python)=42189.8203125MB; mem (CPU total)=41981.7734375MB
INFO:root:[   67] Training loss: 0.94224709, Validation loss: 0.94233805, Gradient norm: 0.35879538
INFO:root:At the start of the epoch: mem (CPU python)=42227.91796875MB; mem (CPU total)=42020.078125MB
INFO:root:[   68] Training loss: 0.94192534, Validation loss: 0.94230065, Gradient norm: 0.33254792
INFO:root:At the start of the epoch: mem (CPU python)=42266.01171875MB; mem (CPU total)=42058.22265625MB
INFO:root:[   69] Training loss: 0.94197398, Validation loss: 0.94216529, Gradient norm: 0.35590588
INFO:root:At the start of the epoch: mem (CPU python)=42304.10546875MB; mem (CPU total)=42096.3046875MB
INFO:root:[   70] Training loss: 0.94182313, Validation loss: 0.94119470, Gradient norm: 0.33985419
INFO:root:At the start of the epoch: mem (CPU python)=42342.203125MB; mem (CPU total)=42134.54296875MB
INFO:root:[   71] Training loss: 0.94138962, Validation loss: 0.94156223, Gradient norm: 0.31926098
INFO:root:At the start of the epoch: mem (CPU python)=42380.296875MB; mem (CPU total)=42172.421875MB
INFO:root:[   72] Training loss: 0.94131217, Validation loss: 0.94114373, Gradient norm: 0.34166822
INFO:root:At the start of the epoch: mem (CPU python)=42418.39453125MB; mem (CPU total)=42210.796875MB
INFO:root:[   73] Training loss: 0.94139368, Validation loss: 0.94126133, Gradient norm: 0.35027271
INFO:root:At the start of the epoch: mem (CPU python)=42456.48828125MB; mem (CPU total)=42248.90234375MB
INFO:root:[   74] Training loss: 0.94106553, Validation loss: 0.94152811, Gradient norm: 0.32757927
INFO:root:At the start of the epoch: mem (CPU python)=42494.5859375MB; mem (CPU total)=42287.015625MB
INFO:root:[   75] Training loss: 0.94095830, Validation loss: 0.94058729, Gradient norm: 0.35274331
INFO:root:At the start of the epoch: mem (CPU python)=42532.6796875MB; mem (CPU total)=42324.78515625MB
INFO:root:[   76] Training loss: 0.94072239, Validation loss: 0.94091942, Gradient norm: 0.32736203
INFO:root:At the start of the epoch: mem (CPU python)=42570.7734375MB; mem (CPU total)=42362.9609375MB
INFO:root:[   77] Training loss: 0.94082337, Validation loss: 0.94147813, Gradient norm: 0.36294613
INFO:root:At the start of the epoch: mem (CPU python)=42608.8671875MB; mem (CPU total)=42400.84375MB
INFO:root:[   78] Training loss: 0.94048832, Validation loss: 0.94041927, Gradient norm: 0.36011044
INFO:root:At the start of the epoch: mem (CPU python)=42646.96875MB; mem (CPU total)=42439.203125MB
INFO:root:[   79] Training loss: 0.94028374, Validation loss: 0.94089143, Gradient norm: 0.34058632
INFO:root:At the start of the epoch: mem (CPU python)=42685.05859375MB; mem (CPU total)=42477.59375MB
INFO:root:[   80] Training loss: 0.94029030, Validation loss: 0.94010722, Gradient norm: 0.35685222
INFO:root:At the start of the epoch: mem (CPU python)=42723.15625MB; mem (CPU total)=42515.33984375MB
INFO:root:[   81] Training loss: 0.93999504, Validation loss: 0.94027834, Gradient norm: 0.33659190
INFO:root:At the start of the epoch: mem (CPU python)=42761.25MB; mem (CPU total)=42553.73046875MB
INFO:root:[   82] Training loss: 0.94003069, Validation loss: 0.94014870, Gradient norm: 0.37430011
INFO:root:At the start of the epoch: mem (CPU python)=42799.34765625MB; mem (CPU total)=42592.1640625MB
INFO:root:[   83] Training loss: 0.93985818, Validation loss: 0.94013285, Gradient norm: 0.36518892
INFO:root:At the start of the epoch: mem (CPU python)=42837.44140625MB; mem (CPU total)=42629.9453125MB
INFO:root:[   84] Training loss: 0.93964546, Validation loss: 0.93998351, Gradient norm: 0.34975257
INFO:root:At the start of the epoch: mem (CPU python)=42875.5390625MB; mem (CPU total)=42667.4140625MB
INFO:root:[   85] Training loss: 0.93943919, Validation loss: 0.93936451, Gradient norm: 0.33722040
INFO:root:At the start of the epoch: mem (CPU python)=42913.6328125MB; mem (CPU total)=42705.37109375MB
INFO:root:[   86] Training loss: 0.93935292, Validation loss: 0.93957460, Gradient norm: 0.35638221
INFO:root:At the start of the epoch: mem (CPU python)=42951.7265625MB; mem (CPU total)=42743.7578125MB
INFO:root:[   87] Training loss: 0.93913735, Validation loss: 0.93974081, Gradient norm: 0.36183956
INFO:root:At the start of the epoch: mem (CPU python)=42989.8203125MB; mem (CPU total)=42781.87109375MB
INFO:root:[   88] Training loss: 0.93908087, Validation loss: 0.93886656, Gradient norm: 0.35868633
INFO:root:At the start of the epoch: mem (CPU python)=43027.921875MB; mem (CPU total)=42820.015625MB
INFO:root:[   89] Training loss: 0.93891935, Validation loss: 0.93959760, Gradient norm: 0.35127251
INFO:root:At the start of the epoch: mem (CPU python)=43066.01171875MB; mem (CPU total)=42858.40625MB
INFO:root:[   90] Training loss: 0.93860040, Validation loss: 0.93862027, Gradient norm: 0.34501697
INFO:root:At the start of the epoch: mem (CPU python)=43104.109375MB; mem (CPU total)=42896.3046875MB
INFO:root:[   91] Training loss: 0.93856925, Validation loss: 0.93941241, Gradient norm: 0.34018593
INFO:root:At the start of the epoch: mem (CPU python)=43142.203125MB; mem (CPU total)=42934.44921875MB
INFO:root:[   92] Training loss: 0.93838546, Validation loss: 0.93855801, Gradient norm: 0.35520601
INFO:root:At the start of the epoch: mem (CPU python)=43180.30078125MB; mem (CPU total)=42972.96875MB
INFO:root:[   93] Training loss: 0.93815193, Validation loss: 0.93826933, Gradient norm: 0.32996391
INFO:root:At the start of the epoch: mem (CPU python)=43218.39453125MB; mem (CPU total)=43011.171875MB
INFO:root:[   94] Training loss: 0.93800776, Validation loss: 0.93852160, Gradient norm: 0.33760486
INFO:root:At the start of the epoch: mem (CPU python)=43256.48828125MB; mem (CPU total)=43049.0703125MB
INFO:root:[   95] Training loss: 0.93797222, Validation loss: 0.93808961, Gradient norm: 0.35201879
INFO:root:At the start of the epoch: mem (CPU python)=43294.58984375MB; mem (CPU total)=43088.015625MB
INFO:root:[   96] Training loss: 0.93791206, Validation loss: 0.93806876, Gradient norm: 0.36964958
INFO:root:At the start of the epoch: mem (CPU python)=43332.68359375MB; mem (CPU total)=43126.5078125MB
INFO:root:[   97] Training loss: 0.93769404, Validation loss: 0.93833069, Gradient norm: 0.34670170
INFO:root:At the start of the epoch: mem (CPU python)=43370.7734375MB; mem (CPU total)=43164.90625MB
INFO:root:[   98] Training loss: 0.93755420, Validation loss: 0.93802563, Gradient norm: 0.34698912
INFO:root:At the start of the epoch: mem (CPU python)=43408.875MB; mem (CPU total)=43203.11328125MB
INFO:root:[   99] Training loss: 0.93756871, Validation loss: 0.93737167, Gradient norm: 0.38017107
INFO:root:At the start of the epoch: mem (CPU python)=43446.96875MB; mem (CPU total)=43241.3828125MB
INFO:root:[  100] Training loss: 0.93730236, Validation loss: 0.93748532, Gradient norm: 0.34283577
INFO:root:At the start of the epoch: mem (CPU python)=43485.05859375MB; mem (CPU total)=43279.7734375MB
INFO:root:[  101] Training loss: 0.93719794, Validation loss: 0.93811422, Gradient norm: 0.36512647
INFO:root:At the start of the epoch: mem (CPU python)=43523.15625MB; mem (CPU total)=43318.18359375MB
INFO:root:[  102] Training loss: 0.93703549, Validation loss: 0.93773547, Gradient norm: 0.37016740
INFO:root:At the start of the epoch: mem (CPU python)=43561.25390625MB; mem (CPU total)=43355.91015625MB
INFO:root:[  103] Training loss: 0.93713245, Validation loss: 0.93779374, Gradient norm: 0.37157377
INFO:root:At the start of the epoch: mem (CPU python)=43599.3515625MB; mem (CPU total)=43393.80859375MB
INFO:root:[  104] Training loss: 0.93683341, Validation loss: 0.93767990, Gradient norm: 0.35659499
INFO:root:At the start of the epoch: mem (CPU python)=43637.4453125MB; mem (CPU total)=43432.34375MB
INFO:root:[  105] Training loss: 0.93667790, Validation loss: 0.93724936, Gradient norm: 0.34791162
INFO:root:At the start of the epoch: mem (CPU python)=43675.546875MB; mem (CPU total)=43471.15625MB
INFO:root:[  106] Training loss: 0.93656805, Validation loss: 0.93618708, Gradient norm: 0.36877438
INFO:root:At the start of the epoch: mem (CPU python)=43713.63671875MB; mem (CPU total)=43508.87109375MB
INFO:root:[  107] Training loss: 0.93640931, Validation loss: 0.93704875, Gradient norm: 0.34823958
INFO:root:At the start of the epoch: mem (CPU python)=43751.734375MB; mem (CPU total)=43547.265625MB
INFO:root:[  108] Training loss: 0.93624292, Validation loss: 0.93736011, Gradient norm: 0.36363822
INFO:root:At the start of the epoch: mem (CPU python)=43789.8359375MB; mem (CPU total)=43585.21875MB
INFO:root:[  109] Training loss: 0.93613659, Validation loss: 0.93626117, Gradient norm: 0.35121918
INFO:root:At the start of the epoch: mem (CPU python)=43827.9296875MB; mem (CPU total)=43623.2734375MB
INFO:root:[  110] Training loss: 0.93593763, Validation loss: 0.93635131, Gradient norm: 0.35479129
INFO:root:At the start of the epoch: mem (CPU python)=43866.0234375MB; mem (CPU total)=43661.453125MB
INFO:root:[  111] Training loss: 0.93586490, Validation loss: 0.93686830, Gradient norm: 0.35422755
INFO:root:At the start of the epoch: mem (CPU python)=43904.125MB; mem (CPU total)=43699.8828125MB
INFO:root:[  112] Training loss: 0.93589385, Validation loss: 0.93600865, Gradient norm: 0.35959053
INFO:root:At the start of the epoch: mem (CPU python)=43942.22265625MB; mem (CPU total)=43737.94140625MB
INFO:root:[  113] Training loss: 0.93558994, Validation loss: 0.93642158, Gradient norm: 0.33455153
INFO:root:At the start of the epoch: mem (CPU python)=43980.31640625MB; mem (CPU total)=43776.375MB
INFO:root:[  114] Training loss: 0.93566719, Validation loss: 0.93608629, Gradient norm: 0.36438739
INFO:root:At the start of the epoch: mem (CPU python)=44018.41015625MB; mem (CPU total)=43814.05078125MB
INFO:root:[  115] Training loss: 0.93559451, Validation loss: 0.93670180, Gradient norm: 0.37636062
INFO:root:At the start of the epoch: mem (CPU python)=44056.5078125MB; mem (CPU total)=43851.7109375MB
INFO:root:[  116] Training loss: 0.93528113, Validation loss: 0.93574512, Gradient norm: 0.33651328
INFO:root:At the start of the epoch: mem (CPU python)=44094.60546875MB; mem (CPU total)=43889.92578125MB
INFO:root:[  117] Training loss: 0.93501836, Validation loss: 0.93581459, Gradient norm: 0.34209990
INFO:root:At the start of the epoch: mem (CPU python)=44132.6953125MB; mem (CPU total)=43928.10546875MB
INFO:root:[  118] Training loss: 0.93515622, Validation loss: 0.93593950, Gradient norm: 0.34755198
INFO:root:At the start of the epoch: mem (CPU python)=44170.796875MB; mem (CPU total)=43966.53125MB
INFO:root:[  119] Training loss: 0.93496142, Validation loss: 0.93544698, Gradient norm: 0.33036549
INFO:root:At the start of the epoch: mem (CPU python)=44208.890625MB; mem (CPU total)=44004.69921875MB
INFO:root:[  120] Training loss: 0.93486730, Validation loss: 0.93568686, Gradient norm: 0.33904818
INFO:root:At the start of the epoch: mem (CPU python)=44246.984375MB; mem (CPU total)=44042.96875MB
INFO:root:[  121] Training loss: 0.93473838, Validation loss: 0.93446010, Gradient norm: 0.33626874
INFO:root:At the start of the epoch: mem (CPU python)=44285.078125MB; mem (CPU total)=44081.09765625MB
INFO:root:[  122] Training loss: 0.93463539, Validation loss: 0.93509126, Gradient norm: 0.33573173
INFO:root:At the start of the epoch: mem (CPU python)=44323.17578125MB; mem (CPU total)=44119.5234375MB
INFO:root:[  123] Training loss: 0.93457007, Validation loss: 0.93482279, Gradient norm: 0.32279973
INFO:root:At the start of the epoch: mem (CPU python)=44361.26953125MB; mem (CPU total)=44157.4921875MB
INFO:root:[  124] Training loss: 0.93446199, Validation loss: 0.93502659, Gradient norm: 0.33461988
INFO:root:At the start of the epoch: mem (CPU python)=44399.36328125MB; mem (CPU total)=44195.56640625MB
INFO:root:[  125] Training loss: 0.93428737, Validation loss: 0.93547079, Gradient norm: 0.33982453
INFO:root:At the start of the epoch: mem (CPU python)=44437.46484375MB; mem (CPU total)=44234.140625MB
INFO:root:[  126] Training loss: 0.93423501, Validation loss: 0.93468081, Gradient norm: 0.34015140
INFO:root:At the start of the epoch: mem (CPU python)=44475.55859375MB; mem (CPU total)=44271.44921875MB
INFO:root:[  127] Training loss: 0.93435485, Validation loss: 0.93593539, Gradient norm: 0.34743227
INFO:root:At the start of the epoch: mem (CPU python)=44513.65234375MB; mem (CPU total)=44309.5390625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  128] Training loss: 0.93413661, Validation loss: 0.93494315, Gradient norm: 0.33499904
INFO:root:At the start of the epoch: mem (CPU python)=44551.74609375MB; mem (CPU total)=44348.11328125MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  129] Training loss: 0.93260203, Validation loss: 0.93420935, Gradient norm: 0.28640574
INFO:root:At the start of the epoch: mem (CPU python)=44589.85546875MB; mem (CPU total)=44385.78515625MB
INFO:root:[  130] Training loss: 0.93162754, Validation loss: 0.93313167, Gradient norm: 0.26776483
INFO:root:At the start of the epoch: mem (CPU python)=44627.94921875MB; mem (CPU total)=44424.05859375MB
INFO:root:[  131] Training loss: 0.93153754, Validation loss: 0.93338168, Gradient norm: 0.27122025
INFO:root:At the start of the epoch: mem (CPU python)=44666.04296875MB; mem (CPU total)=44462.26953125MB
INFO:root:[  132] Training loss: 0.93154295, Validation loss: 0.93281119, Gradient norm: 0.27780099
INFO:root:At the start of the epoch: mem (CPU python)=44704.14453125MB; mem (CPU total)=44500.76171875MB
INFO:root:[  133] Training loss: 0.93143229, Validation loss: 0.93325879, Gradient norm: 0.28833327
INFO:root:At the start of the epoch: mem (CPU python)=44742.234375MB; mem (CPU total)=44539.1640625MB
INFO:root:[  134] Training loss: 0.93137910, Validation loss: 0.93302127, Gradient norm: 0.28517035
INFO:root:At the start of the epoch: mem (CPU python)=44780.328125MB; mem (CPU total)=44576.94921875MB
INFO:root:[  135] Training loss: 0.93138252, Validation loss: 0.93319029, Gradient norm: 0.28301779
INFO:root:At the start of the epoch: mem (CPU python)=44818.4296875MB; mem (CPU total)=44615.2890625MB
INFO:root:[  136] Training loss: 0.93140742, Validation loss: 0.93294516, Gradient norm: 0.28123861
INFO:root:At the start of the epoch: mem (CPU python)=44856.5234375MB; mem (CPU total)=44653.20703125MB
INFO:root:[  137] Training loss: 0.93134520, Validation loss: 0.93298733, Gradient norm: 0.28055127
INFO:root:At the start of the epoch: mem (CPU python)=44894.6171875MB; mem (CPU total)=44691.78125MB
INFO:root:[  138] Training loss: 0.93128015, Validation loss: 0.93332333, Gradient norm: 0.27596406
INFO:root:At the start of the epoch: mem (CPU python)=44932.7109375MB; mem (CPU total)=44729.5703125MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  139] Training loss: 0.93128369, Validation loss: 0.93301096, Gradient norm: 0.27696197
INFO:root:At the start of the epoch: mem (CPU python)=44970.80859375MB; mem (CPU total)=44767.703125MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  140] Training loss: 0.93073909, Validation loss: 0.93267321, Gradient norm: 0.25680753
INFO:root:At the start of the epoch: mem (CPU python)=45008.90625MB; mem (CPU total)=44805.96875MB
INFO:root:[  141] Training loss: 0.93037912, Validation loss: 0.93257836, Gradient norm: 0.24788858
INFO:root:At the start of the epoch: mem (CPU python)=45047.0MB; mem (CPU total)=44844.2421875MB
INFO:root:[  142] Training loss: 0.93044626, Validation loss: 0.93253230, Gradient norm: 0.24707813
INFO:root:At the start of the epoch: mem (CPU python)=45085.09765625MB; mem (CPU total)=44882.6796875MB
INFO:root:[  143] Training loss: 0.93042333, Validation loss: 0.93215642, Gradient norm: 0.25534618
INFO:root:At the start of the epoch: mem (CPU python)=45123.19140625MB; mem (CPU total)=44921.04296875MB
INFO:root:[  144] Training loss: 0.93040078, Validation loss: 0.93271339, Gradient norm: 0.25715039
INFO:root:At the start of the epoch: mem (CPU python)=45161.28515625MB; mem (CPU total)=44959.84765625MB
INFO:root:[  145] Training loss: 0.93038985, Validation loss: 0.93268021, Gradient norm: 0.25314284
INFO:root:At the start of the epoch: mem (CPU python)=45199.37890625MB; mem (CPU total)=44997.765625MB
INFO:root:[  146] Training loss: 0.93033847, Validation loss: 0.93200825, Gradient norm: 0.26094896
INFO:root:At the start of the epoch: mem (CPU python)=45237.4765625MB; mem (CPU total)=45036.13671875MB
INFO:root:[  147] Training loss: 0.93036309, Validation loss: 0.93288012, Gradient norm: 0.25994540
INFO:root:At the start of the epoch: mem (CPU python)=45275.5703125MB; mem (CPU total)=45074.56640625MB
INFO:root:[  148] Training loss: 0.93028370, Validation loss: 0.93222419, Gradient norm: 0.25351719
INFO:root:At the start of the epoch: mem (CPU python)=45313.6640625MB; mem (CPU total)=45112.5MB
INFO:root:[  149] Training loss: 0.93030708, Validation loss: 0.93272179, Gradient norm: 0.25521827
INFO:root:At the start of the epoch: mem (CPU python)=45351.76171875MB; mem (CPU total)=45150.09375MB
INFO:root:[  150] Training loss: 0.93031591, Validation loss: 0.93279405, Gradient norm: 0.26545714
INFO:root:At the start of the epoch: mem (CPU python)=45389.859375MB; mem (CPU total)=45188.27734375MB
INFO:root:[  151] Training loss: 0.93028128, Validation loss: 0.93246974, Gradient norm: 0.25928849
INFO:root:At the start of the epoch: mem (CPU python)=45427.953125MB; mem (CPU total)=45227.46484375MB
INFO:root:[  152] Training loss: 0.93029202, Validation loss: 0.93245149, Gradient norm: 0.25689607
INFO:root:At the start of the epoch: mem (CPU python)=45466.05078125MB; mem (CPU total)=45265.50390625MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  153] Training loss: 0.93029261, Validation loss: 0.93264314, Gradient norm: 0.26347384
INFO:root:At the start of the epoch: mem (CPU python)=45504.14453125MB; mem (CPU total)=45303.1875MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  154] Training loss: 0.93013856, Validation loss: 0.93270036, Gradient norm: 0.24967853
INFO:root:At the start of the epoch: mem (CPU python)=45542.23828125MB; mem (CPU total)=45341.6171875MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  155] Training loss: 0.93002526, Validation loss: 0.93245830, Gradient norm: 0.24330898
INFO:root:At the start of the epoch: mem (CPU python)=45580.33203125MB; mem (CPU total)=45380.04296875MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:EP 155: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=45618.3125MB; mem (CPU total)=45418.203125MB
INFO:root:Training the model took 14619.489s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93088
INFO:root:EnergyScoreTrain: 0.8419
INFO:root:CRPSTrain: 0.67822
INFO:root:Gaussian NLLTrain: 765.81886
INFO:root:CoverageTrain: 0.10834
INFO:root:IntervalWidthTrain: 0.21627
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93642
INFO:root:EnergyScoreValidation: 0.8462
INFO:root:CRPSValidation: 0.68294
INFO:root:Gaussian NLLValidation: 698.25237
INFO:root:CoverageValidation: 0.1081
INFO:root:IntervalWidthValidation: 0.21805
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93571
INFO:root:EnergyScoreTest: 0.84737
INFO:root:CRPSTest: 0.68319
INFO:root:Gaussian NLLTest: 643.71074
INFO:root:CoverageTest: 0.10623
INFO:root:IntervalWidthTest: 0.21472
INFO:root:After validation: mem (CPU python)=45691.98828125MB; mem (CPU total)=45492.71875MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=45691.98828125MB; mem (CPU total)=45491.796875MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=45692.0234375MB; mem (CPU total)=45491.796875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=45692.0234375MB; mem (CPU total)=45492.18359375MB
INFO:root:[    1] Training loss: 1.00516878, Validation loss: 0.98862997, Gradient norm: 0.05865077
INFO:root:At the start of the epoch: mem (CPU python)=45729.875MB; mem (CPU total)=45529.8515625MB
INFO:root:[    2] Training loss: 0.98055534, Validation loss: 0.97712273, Gradient norm: 0.11693189
INFO:root:At the start of the epoch: mem (CPU python)=45767.96875MB; mem (CPU total)=45568.2265625MB
INFO:root:[    3] Training loss: 0.97403124, Validation loss: 0.97404554, Gradient norm: 0.14304776
INFO:root:At the start of the epoch: mem (CPU python)=45806.06640625MB; mem (CPU total)=45605.42578125MB
INFO:root:[    4] Training loss: 0.97093688, Validation loss: 0.97066406, Gradient norm: 0.14041668
INFO:root:At the start of the epoch: mem (CPU python)=45844.16015625MB; mem (CPU total)=45644.02734375MB
INFO:root:[    5] Training loss: 0.96883945, Validation loss: 0.96829393, Gradient norm: 0.16244516
INFO:root:At the start of the epoch: mem (CPU python)=45882.25390625MB; mem (CPU total)=45682.16796875MB
INFO:root:[    6] Training loss: 0.96712642, Validation loss: 0.96774670, Gradient norm: 0.16059137
INFO:root:At the start of the epoch: mem (CPU python)=45920.3515625MB; mem (CPU total)=45720.44140625MB
INFO:root:[    7] Training loss: 0.96595962, Validation loss: 0.96594191, Gradient norm: 0.16988751
INFO:root:At the start of the epoch: mem (CPU python)=45958.4453125MB; mem (CPU total)=45758.65234375MB
INFO:root:[    8] Training loss: 0.96466442, Validation loss: 0.96434165, Gradient norm: 0.16715905
INFO:root:At the start of the epoch: mem (CPU python)=45996.54296875MB; mem (CPU total)=45796.61328125MB
INFO:root:[    9] Training loss: 0.96376514, Validation loss: 0.96400720, Gradient norm: 0.16893610
INFO:root:At the start of the epoch: mem (CPU python)=46034.6328125MB; mem (CPU total)=45834.8359375MB
INFO:root:[   10] Training loss: 0.96274140, Validation loss: 0.96250046, Gradient norm: 0.17275864
INFO:root:At the start of the epoch: mem (CPU python)=46072.734375MB; mem (CPU total)=45873.296875MB
INFO:root:[   11] Training loss: 0.96191620, Validation loss: 0.96183303, Gradient norm: 0.18051572
INFO:root:At the start of the epoch: mem (CPU python)=46110.828125MB; mem (CPU total)=45911.375MB
INFO:root:[   12] Training loss: 0.96095246, Validation loss: 0.96074919, Gradient norm: 0.17533737
INFO:root:At the start of the epoch: mem (CPU python)=46148.921875MB; mem (CPU total)=45949.73828125MB
INFO:root:[   13] Training loss: 0.95985048, Validation loss: 0.95936483, Gradient norm: 0.20299855
INFO:root:At the start of the epoch: mem (CPU python)=46187.01953125MB; mem (CPU total)=45987.55859375MB
INFO:root:[   14] Training loss: 0.95887503, Validation loss: 0.95856803, Gradient norm: 0.19864048
INFO:root:At the start of the epoch: mem (CPU python)=46225.11328125MB; mem (CPU total)=46025.8984375MB
INFO:root:[   15] Training loss: 0.95791290, Validation loss: 0.95856404, Gradient norm: 0.20012852
INFO:root:At the start of the epoch: mem (CPU python)=46263.20703125MB; mem (CPU total)=46064.3671875MB
INFO:root:[   16] Training loss: 0.95705917, Validation loss: 0.95705417, Gradient norm: 0.21477404
INFO:root:At the start of the epoch: mem (CPU python)=46301.3046875MB; mem (CPU total)=46102.62109375MB
INFO:root:[   17] Training loss: 0.95639819, Validation loss: 0.95625851, Gradient norm: 0.21995247
INFO:root:At the start of the epoch: mem (CPU python)=46339.40234375MB; mem (CPU total)=46140.46875MB
INFO:root:[   18] Training loss: 0.95548154, Validation loss: 0.95556316, Gradient norm: 0.21055375
INFO:root:At the start of the epoch: mem (CPU python)=46377.49609375MB; mem (CPU total)=46177.96484375MB
INFO:root:[   19] Training loss: 0.95492108, Validation loss: 0.95485749, Gradient norm: 0.22512570
INFO:root:At the start of the epoch: mem (CPU python)=46415.58984375MB; mem (CPU total)=46216.2421875MB
INFO:root:[   20] Training loss: 0.95422657, Validation loss: 0.95324238, Gradient norm: 0.22899054
INFO:root:At the start of the epoch: mem (CPU python)=46453.6875MB; mem (CPU total)=46253.3984375MB
INFO:root:[   21] Training loss: 0.95352434, Validation loss: 0.95421198, Gradient norm: 0.23618439
INFO:root:At the start of the epoch: mem (CPU python)=46491.78125MB; mem (CPU total)=46291.7890625MB
INFO:root:[   22] Training loss: 0.95287409, Validation loss: 0.95272756, Gradient norm: 0.22399063
INFO:root:At the start of the epoch: mem (CPU python)=46529.875MB; mem (CPU total)=46329.95703125MB
INFO:root:[   23] Training loss: 0.95238201, Validation loss: 0.95230039, Gradient norm: 0.23456767
INFO:root:At the start of the epoch: mem (CPU python)=46567.9765625MB; mem (CPU total)=46368.0859375MB
INFO:root:[   24] Training loss: 0.95196424, Validation loss: 0.95217518, Gradient norm: 0.24246462
INFO:root:At the start of the epoch: mem (CPU python)=46606.0703125MB; mem (CPU total)=46406.15234375MB
INFO:root:[   25] Training loss: 0.95149398, Validation loss: 0.95115201, Gradient norm: 0.22911358
INFO:root:At the start of the epoch: mem (CPU python)=46644.1640625MB; mem (CPU total)=46444.47265625MB
INFO:root:[   26] Training loss: 0.95103318, Validation loss: 0.95098140, Gradient norm: 0.22994897
INFO:root:At the start of the epoch: mem (CPU python)=46682.2578125MB; mem (CPU total)=46482.625MB
INFO:root:[   27] Training loss: 0.95079695, Validation loss: 0.95063373, Gradient norm: 0.24367213
INFO:root:At the start of the epoch: mem (CPU python)=46720.35546875MB; mem (CPU total)=46520.35546875MB
INFO:root:[   28] Training loss: 0.95028332, Validation loss: 0.95004086, Gradient norm: 0.23614318
INFO:root:At the start of the epoch: mem (CPU python)=46758.44921875MB; mem (CPU total)=46558.453125MB
INFO:root:[   29] Training loss: 0.94976826, Validation loss: 0.94885073, Gradient norm: 0.22986673
INFO:root:At the start of the epoch: mem (CPU python)=46796.54296875MB; mem (CPU total)=46596.8125MB
INFO:root:[   30] Training loss: 0.94945951, Validation loss: 0.94857998, Gradient norm: 0.23554765
INFO:root:At the start of the epoch: mem (CPU python)=46834.640625MB; mem (CPU total)=46634.78125MB
INFO:root:[   31] Training loss: 0.94910610, Validation loss: 0.94876375, Gradient norm: 0.24827735
INFO:root:At the start of the epoch: mem (CPU python)=46872.734375MB; mem (CPU total)=46673.70703125MB
INFO:root:[   32] Training loss: 0.94874312, Validation loss: 0.94937794, Gradient norm: 0.22788244
INFO:root:At the start of the epoch: mem (CPU python)=46910.828125MB; mem (CPU total)=46711.73828125MB
INFO:root:[   33] Training loss: 0.94859911, Validation loss: 0.94817562, Gradient norm: 0.24016430
INFO:root:At the start of the epoch: mem (CPU python)=46948.92578125MB; mem (CPU total)=46749.66796875MB
INFO:root:[   34] Training loss: 0.94808153, Validation loss: 0.94855900, Gradient norm: 0.22733603
INFO:root:At the start of the epoch: mem (CPU python)=46987.01953125MB; mem (CPU total)=46788.05859375MB
INFO:root:[   35] Training loss: 0.94796393, Validation loss: 0.94794346, Gradient norm: 0.24803761
INFO:root:At the start of the epoch: mem (CPU python)=47025.1171875MB; mem (CPU total)=46825.66015625MB
INFO:root:[   36] Training loss: 0.94771319, Validation loss: 0.94873769, Gradient norm: 0.23245207
INFO:root:At the start of the epoch: mem (CPU python)=47063.2109375MB; mem (CPU total)=46863.55859375MB
INFO:root:[   37] Training loss: 0.94744980, Validation loss: 0.94698594, Gradient norm: 0.24375786
INFO:root:At the start of the epoch: mem (CPU python)=47101.30859375MB; mem (CPU total)=46901.85546875MB
INFO:root:[   38] Training loss: 0.94725092, Validation loss: 0.94723256, Gradient norm: 0.24650160
INFO:root:At the start of the epoch: mem (CPU python)=47139.40234375MB; mem (CPU total)=46940.19921875MB
INFO:root:[   39] Training loss: 0.94689196, Validation loss: 0.94779870, Gradient norm: 0.23639343
INFO:root:At the start of the epoch: mem (CPU python)=47177.49609375MB; mem (CPU total)=46978.34375MB
INFO:root:[   40] Training loss: 0.94675953, Validation loss: 0.94646302, Gradient norm: 0.24845451
INFO:root:At the start of the epoch: mem (CPU python)=47215.59765625MB; mem (CPU total)=47016.2421875MB
INFO:root:[   41] Training loss: 0.94632296, Validation loss: 0.94649748, Gradient norm: 0.23592978
INFO:root:At the start of the epoch: mem (CPU python)=47253.6875MB; mem (CPU total)=47054.61328125MB
INFO:root:[   42] Training loss: 0.94636772, Validation loss: 0.94665406, Gradient norm: 0.24657767
INFO:root:At the start of the epoch: mem (CPU python)=47291.78515625MB; mem (CPU total)=47092.7578125MB
INFO:root:[   43] Training loss: 0.94613759, Validation loss: 0.94558957, Gradient norm: 0.24932879
INFO:root:At the start of the epoch: mem (CPU python)=47329.87890625MB; mem (CPU total)=47129.234375MB
INFO:root:[   44] Training loss: 0.94584029, Validation loss: 0.94658122, Gradient norm: 0.24326278
INFO:root:At the start of the epoch: mem (CPU python)=47367.9765625MB; mem (CPU total)=47166.9375MB
INFO:root:[   45] Training loss: 0.94557900, Validation loss: 0.94585791, Gradient norm: 0.23579321
INFO:root:At the start of the epoch: mem (CPU python)=47406.0703125MB; mem (CPU total)=47205.30859375MB
INFO:root:[   46] Training loss: 0.94545321, Validation loss: 0.94639236, Gradient norm: 0.24815695
INFO:root:At the start of the epoch: mem (CPU python)=47444.1640625MB; mem (CPU total)=47243.08984375MB
INFO:root:[   47] Training loss: 0.94517602, Validation loss: 0.94483199, Gradient norm: 0.24073152
INFO:root:At the start of the epoch: mem (CPU python)=47482.26171875MB; mem (CPU total)=47281.69140625MB
INFO:root:[   48] Training loss: 0.94523046, Validation loss: 0.94508413, Gradient norm: 0.25806229
INFO:root:At the start of the epoch: mem (CPU python)=47520.35546875MB; mem (CPU total)=47319.8359375MB
INFO:root:[   49] Training loss: 0.94489698, Validation loss: 0.94577194, Gradient norm: 0.24545644
INFO:root:At the start of the epoch: mem (CPU python)=47558.44921875MB; mem (CPU total)=47358.26953125MB
INFO:root:[   50] Training loss: 0.94468254, Validation loss: 0.94520866, Gradient norm: 0.25734356
INFO:root:At the start of the epoch: mem (CPU python)=47596.54296875MB; mem (CPU total)=47396.29296875MB
INFO:root:[   51] Training loss: 0.94451511, Validation loss: 0.94487434, Gradient norm: 0.24269898
INFO:root:At the start of the epoch: mem (CPU python)=47634.640625MB; mem (CPU total)=47434.3203125MB
INFO:root:[   52] Training loss: 0.94431122, Validation loss: 0.94431305, Gradient norm: 0.25237588
INFO:root:At the start of the epoch: mem (CPU python)=47672.73828125MB; mem (CPU total)=47472.65234375MB
INFO:root:[   53] Training loss: 0.94414431, Validation loss: 0.94466142, Gradient norm: 0.25790470
INFO:root:At the start of the epoch: mem (CPU python)=47710.83203125MB; mem (CPU total)=47510.7890625MB
INFO:root:[   54] Training loss: 0.94395577, Validation loss: 0.94499674, Gradient norm: 0.25496989
INFO:root:At the start of the epoch: mem (CPU python)=47748.9296875MB; mem (CPU total)=47549.1796875MB
INFO:root:[   55] Training loss: 0.94377582, Validation loss: 0.94383340, Gradient norm: 0.25064994
INFO:root:At the start of the epoch: mem (CPU python)=47787.0234375MB; mem (CPU total)=47587.76953125MB
INFO:root:[   56] Training loss: 0.94350871, Validation loss: 0.94390647, Gradient norm: 0.25895227
INFO:root:At the start of the epoch: mem (CPU python)=47825.12109375MB; mem (CPU total)=47625.7734375MB
INFO:root:[   57] Training loss: 0.94343965, Validation loss: 0.94343920, Gradient norm: 0.26160354
INFO:root:At the start of the epoch: mem (CPU python)=47863.22265625MB; mem (CPU total)=47664.2578125MB
INFO:root:[   58] Training loss: 0.94315923, Validation loss: 0.94328832, Gradient norm: 0.26920475
INFO:root:At the start of the epoch: mem (CPU python)=47901.31640625MB; mem (CPU total)=47702.99609375MB
INFO:root:[   59] Training loss: 0.94293947, Validation loss: 0.94294167, Gradient norm: 0.26084320
INFO:root:At the start of the epoch: mem (CPU python)=47939.41015625MB; mem (CPU total)=47741.34375MB
INFO:root:[   60] Training loss: 0.94266186, Validation loss: 0.94281694, Gradient norm: 0.28133429
INFO:root:At the start of the epoch: mem (CPU python)=47977.50390625MB; mem (CPU total)=47779.90234375MB
INFO:root:[   61] Training loss: 0.94250349, Validation loss: 0.94262435, Gradient norm: 0.27139899
INFO:root:At the start of the epoch: mem (CPU python)=48015.6015625MB; mem (CPU total)=47817.58203125MB
INFO:root:[   62] Training loss: 0.94226483, Validation loss: 0.94295641, Gradient norm: 0.27135411
INFO:root:At the start of the epoch: mem (CPU python)=48053.6953125MB; mem (CPU total)=47855.8359375MB
INFO:root:[   63] Training loss: 0.94197907, Validation loss: 0.94190732, Gradient norm: 0.27323450
INFO:root:At the start of the epoch: mem (CPU python)=48091.7890625MB; mem (CPU total)=47894.10546875MB
INFO:root:[   64] Training loss: 0.94169120, Validation loss: 0.94122082, Gradient norm: 0.28393887
INFO:root:At the start of the epoch: mem (CPU python)=48129.88671875MB; mem (CPU total)=47932.359375MB
INFO:root:[   65] Training loss: 0.94144183, Validation loss: 0.94162815, Gradient norm: 0.27547041
INFO:root:At the start of the epoch: mem (CPU python)=48167.98046875MB; mem (CPU total)=47970.5MB
INFO:root:[   66] Training loss: 0.94137522, Validation loss: 0.94136316, Gradient norm: 0.28084089
INFO:root:At the start of the epoch: mem (CPU python)=48206.07421875MB; mem (CPU total)=48008.85546875MB
INFO:root:[   67] Training loss: 0.94116148, Validation loss: 0.94182648, Gradient norm: 0.27472326
INFO:root:At the start of the epoch: mem (CPU python)=48244.16796875MB; mem (CPU total)=48046.421875MB
INFO:root:[   68] Training loss: 0.94103117, Validation loss: 0.94130096, Gradient norm: 0.27459525
INFO:root:At the start of the epoch: mem (CPU python)=48282.265625MB; mem (CPU total)=48084.42578125MB
INFO:root:[   69] Training loss: 0.94086138, Validation loss: 0.94182218, Gradient norm: 0.28535229
INFO:root:At the start of the epoch: mem (CPU python)=48320.36328125MB; mem (CPU total)=48122.81640625MB
INFO:root:[   70] Training loss: 0.94076894, Validation loss: 0.94140068, Gradient norm: 0.29277810
INFO:root:At the start of the epoch: mem (CPU python)=48358.45703125MB; mem (CPU total)=48161.20703125MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   71] Training loss: 0.94047200, Validation loss: 0.94151076, Gradient norm: 0.27716490
INFO:root:At the start of the epoch: mem (CPU python)=48396.5546875MB; mem (CPU total)=48199.34765625MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   72] Training loss: 0.93882325, Validation loss: 0.93935299, Gradient norm: 0.24090556
INFO:root:At the start of the epoch: mem (CPU python)=48434.6484375MB; mem (CPU total)=48237.640625MB
INFO:root:[   73] Training loss: 0.93787013, Validation loss: 0.93857804, Gradient norm: 0.22114701
INFO:root:At the start of the epoch: mem (CPU python)=48472.7421875MB; mem (CPU total)=48276.00390625MB
INFO:root:[   74] Training loss: 0.93771828, Validation loss: 0.93876506, Gradient norm: 0.22329499
INFO:root:At the start of the epoch: mem (CPU python)=48510.83984375MB; mem (CPU total)=48314.5703125MB
INFO:root:[   75] Training loss: 0.93768689, Validation loss: 0.93867009, Gradient norm: 0.22227586
INFO:root:At the start of the epoch: mem (CPU python)=48548.93359375MB; mem (CPU total)=48352.9609375MB
INFO:root:[   76] Training loss: 0.93765429, Validation loss: 0.93863133, Gradient norm: 0.23601916
INFO:root:At the start of the epoch: mem (CPU python)=48587.02734375MB; mem (CPU total)=48390.796875MB
INFO:root:[   77] Training loss: 0.93767155, Validation loss: 0.93864110, Gradient norm: 0.24467429
INFO:root:At the start of the epoch: mem (CPU python)=48625.125MB; mem (CPU total)=48429.171875MB
INFO:root:[   78] Training loss: 0.93756786, Validation loss: 0.93847940, Gradient norm: 0.23858195
INFO:root:At the start of the epoch: mem (CPU python)=48663.22265625MB; mem (CPU total)=48467.47265625MB
INFO:root:[   79] Training loss: 0.93747238, Validation loss: 0.93820758, Gradient norm: 0.23806239
INFO:root:At the start of the epoch: mem (CPU python)=48701.31640625MB; mem (CPU total)=48505.46484375MB
INFO:root:[   80] Training loss: 0.93739018, Validation loss: 0.93819484, Gradient norm: 0.23569975
INFO:root:At the start of the epoch: mem (CPU python)=48739.41015625MB; mem (CPU total)=48543.33984375MB
INFO:root:[   81] Training loss: 0.93743134, Validation loss: 0.93822601, Gradient norm: 0.24981659
INFO:root:At the start of the epoch: mem (CPU python)=48777.5078125MB; mem (CPU total)=48581.703125MB
INFO:root:[   82] Training loss: 0.93737210, Validation loss: 0.93794501, Gradient norm: 0.26244317
INFO:root:At the start of the epoch: mem (CPU python)=48815.60546875MB; mem (CPU total)=48619.671875MB
INFO:root:[   83] Training loss: 0.93728858, Validation loss: 0.93827087, Gradient norm: 0.24497673
INFO:root:At the start of the epoch: mem (CPU python)=48853.6953125MB; mem (CPU total)=48658.0625MB
INFO:root:[   84] Training loss: 0.93723625, Validation loss: 0.93836189, Gradient norm: 0.24299473
INFO:root:At the start of the epoch: mem (CPU python)=48891.7890625MB; mem (CPU total)=48695.9609375MB
INFO:root:[   85] Training loss: 0.93728469, Validation loss: 0.93820475, Gradient norm: 0.25432284
INFO:root:At the start of the epoch: mem (CPU python)=48929.88671875MB; mem (CPU total)=48734.76171875MB
INFO:root:[   86] Training loss: 0.93716080, Validation loss: 0.93806058, Gradient norm: 0.24166014
INFO:root:At the start of the epoch: mem (CPU python)=48967.984375MB; mem (CPU total)=48772.77734375MB
INFO:root:[   87] Training loss: 0.93710582, Validation loss: 0.93786914, Gradient norm: 0.24296493
INFO:root:At the start of the epoch: mem (CPU python)=49006.078125MB; mem (CPU total)=48810.95703125MB
INFO:root:[   88] Training loss: 0.93708398, Validation loss: 0.93800406, Gradient norm: 0.24280552
INFO:root:At the start of the epoch: mem (CPU python)=49044.17578125MB; mem (CPU total)=48849.33203125MB
INFO:root:[   89] Training loss: 0.93703201, Validation loss: 0.93854533, Gradient norm: 0.23879757
INFO:root:At the start of the epoch: mem (CPU python)=49082.26953125MB; mem (CPU total)=48887.4765625MB
INFO:root:[   90] Training loss: 0.93704247, Validation loss: 0.93853695, Gradient norm: 0.25136880
INFO:root:At the start of the epoch: mem (CPU python)=49120.36328125MB; mem (CPU total)=48925.3125MB
INFO:root:[   91] Training loss: 0.93694136, Validation loss: 0.93802121, Gradient norm: 0.24084245
INFO:root:At the start of the epoch: mem (CPU python)=49158.4609375MB; mem (CPU total)=48963.72265625MB
INFO:root:[   92] Training loss: 0.93691817, Validation loss: 0.93809681, Gradient norm: 0.26094648
INFO:root:At the start of the epoch: mem (CPU python)=49196.55859375MB; mem (CPU total)=49001.99609375MB
INFO:root:[   93] Training loss: 0.93691664, Validation loss: 0.93759622, Gradient norm: 0.25275102
INFO:root:At the start of the epoch: mem (CPU python)=49234.65234375MB; mem (CPU total)=49040.15234375MB
INFO:root:[   94] Training loss: 0.93682627, Validation loss: 0.93823034, Gradient norm: 0.25128460
INFO:root:At the start of the epoch: mem (CPU python)=49272.74609375MB; mem (CPU total)=49078.359375MB
INFO:root:[   95] Training loss: 0.93676516, Validation loss: 0.93796592, Gradient norm: 0.24990646
INFO:root:At the start of the epoch: mem (CPU python)=49310.84375MB; mem (CPU total)=49116.421875MB
INFO:root:[   96] Training loss: 0.93673140, Validation loss: 0.93805234, Gradient norm: 0.25382872
INFO:root:At the start of the epoch: mem (CPU python)=49348.9375MB; mem (CPU total)=49154.50390625MB
INFO:root:[   97] Training loss: 0.93668756, Validation loss: 0.93793865, Gradient norm: 0.25653548
INFO:root:At the start of the epoch: mem (CPU python)=49387.03125MB; mem (CPU total)=49192.4765625MB
INFO:root:[   98] Training loss: 0.93667645, Validation loss: 0.93759597, Gradient norm: 0.25620189
INFO:root:At the start of the epoch: mem (CPU python)=49425.1328125MB; mem (CPU total)=49230.82421875MB
INFO:root:[   99] Training loss: 0.93668960, Validation loss: 0.93766205, Gradient norm: 0.25616975
INFO:root:At the start of the epoch: mem (CPU python)=49463.22265625MB; mem (CPU total)=49269.20703125MB
INFO:root:[  100] Training loss: 0.93661219, Validation loss: 0.93717210, Gradient norm: 0.25165699
INFO:root:At the start of the epoch: mem (CPU python)=49501.3203125MB; mem (CPU total)=49307.3046875MB
INFO:root:[  101] Training loss: 0.93657327, Validation loss: 0.93774254, Gradient norm: 0.25147071
INFO:root:At the start of the epoch: mem (CPU python)=49539.41015625MB; mem (CPU total)=49345.44921875MB
INFO:root:[  102] Training loss: 0.93653691, Validation loss: 0.93779105, Gradient norm: 0.24829005
INFO:root:At the start of the epoch: mem (CPU python)=49577.5078125MB; mem (CPU total)=49384.0859375MB
INFO:root:[  103] Training loss: 0.93655361, Validation loss: 0.93772968, Gradient norm: 0.26850555
INFO:root:At the start of the epoch: mem (CPU python)=49615.60546875MB; mem (CPU total)=49421.7265625MB
INFO:root:[  104] Training loss: 0.93643892, Validation loss: 0.93737520, Gradient norm: 0.26246879
INFO:root:At the start of the epoch: mem (CPU python)=49653.69921875MB; mem (CPU total)=49459.85546875MB
INFO:root:[  105] Training loss: 0.93633381, Validation loss: 0.93759016, Gradient norm: 0.25140651
INFO:root:At the start of the epoch: mem (CPU python)=49691.796875MB; mem (CPU total)=49497.99609375MB
INFO:root:[  106] Training loss: 0.93634903, Validation loss: 0.93775460, Gradient norm: 0.25313014
INFO:root:At the start of the epoch: mem (CPU python)=49729.890625MB; mem (CPU total)=49536.140625MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  107] Training loss: 0.93629585, Validation loss: 0.93707063, Gradient norm: 0.25343487
INFO:root:At the start of the epoch: mem (CPU python)=49767.98828125MB; mem (CPU total)=49573.59765625MB
INFO:root:[  108] Training loss: 0.93571153, Validation loss: 0.93721540, Gradient norm: 0.22927843
INFO:root:At the start of the epoch: mem (CPU python)=49806.08203125MB; mem (CPU total)=49611.7421875MB
INFO:root:[  109] Training loss: 0.93573155, Validation loss: 0.93687547, Gradient norm: 0.23774071
INFO:root:At the start of the epoch: mem (CPU python)=49844.1796875MB; mem (CPU total)=49650.0625MB
INFO:root:[  110] Training loss: 0.93565178, Validation loss: 0.93674264, Gradient norm: 0.23880311
INFO:root:At the start of the epoch: mem (CPU python)=49882.2734375MB; mem (CPU total)=49688.46875MB
INFO:root:[  111] Training loss: 0.93571411, Validation loss: 0.93681905, Gradient norm: 0.26724249
INFO:root:At the start of the epoch: mem (CPU python)=49920.36328125MB; mem (CPU total)=49726.61328125MB
INFO:root:[  112] Training loss: 0.93556626, Validation loss: 0.93752232, Gradient norm: 0.24517946
INFO:root:At the start of the epoch: mem (CPU python)=49958.46484375MB; mem (CPU total)=49764.9375MB
INFO:root:[  113] Training loss: 0.93553341, Validation loss: 0.93734903, Gradient norm: 0.24738883
INFO:root:At the start of the epoch: mem (CPU python)=49996.55859375MB; mem (CPU total)=49803.046875MB
INFO:root:[  114] Training loss: 0.93554169, Validation loss: 0.93685523, Gradient norm: 0.24311456
INFO:root:At the start of the epoch: mem (CPU python)=50034.65234375MB; mem (CPU total)=49841.4375MB
INFO:root:[  115] Training loss: 0.93553343, Validation loss: 0.93675801, Gradient norm: 0.24951910
INFO:root:At the start of the epoch: mem (CPU python)=50072.75MB; mem (CPU total)=49879.1015625MB
INFO:root:[  116] Training loss: 0.93549493, Validation loss: 0.93719095, Gradient norm: 0.25310818
INFO:root:At the start of the epoch: mem (CPU python)=50110.84375MB; mem (CPU total)=49917.0MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  117] Training loss: 0.93541930, Validation loss: 0.93703995, Gradient norm: 0.24742487
INFO:root:At the start of the epoch: mem (CPU python)=50148.9375MB; mem (CPU total)=49955.14453125MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  118] Training loss: 0.93519179, Validation loss: 0.93682024, Gradient norm: 0.23291341
INFO:root:At the start of the epoch: mem (CPU python)=50187.03515625MB; mem (CPU total)=49993.2890625MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  119] Training loss: 0.93497187, Validation loss: 0.93661985, Gradient norm: 0.22718225
INFO:root:At the start of the epoch: mem (CPU python)=50225.1328125MB; mem (CPU total)=50031.55859375MB
INFO:root:[  120] Training loss: 0.93482939, Validation loss: 0.93645893, Gradient norm: 0.23002684
INFO:root:At the start of the epoch: mem (CPU python)=50263.2265625MB; mem (CPU total)=50069.7890625MB
INFO:root:[  121] Training loss: 0.93477475, Validation loss: 0.93664956, Gradient norm: 0.22188981
INFO:root:At the start of the epoch: mem (CPU python)=50301.3203125MB; mem (CPU total)=50107.89453125MB
INFO:root:[  122] Training loss: 0.93481874, Validation loss: 0.93656358, Gradient norm: 0.22288471
INFO:root:At the start of the epoch: mem (CPU python)=50339.41796875MB; mem (CPU total)=50146.16796875MB
INFO:root:[  123] Training loss: 0.93482988, Validation loss: 0.93654145, Gradient norm: 0.23230824
INFO:root:At the start of the epoch: mem (CPU python)=50377.51171875MB; mem (CPU total)=50184.1875MB
INFO:root:[  124] Training loss: 0.93479707, Validation loss: 0.93695856, Gradient norm: 0.22406025
INFO:root:At the start of the epoch: mem (CPU python)=50415.60546875MB; mem (CPU total)=50222.0859375MB
INFO:root:[  125] Training loss: 0.93485983, Validation loss: 0.93702600, Gradient norm: 0.23036211
INFO:root:At the start of the epoch: mem (CPU python)=50453.703125MB; mem (CPU total)=50260.47265625MB
INFO:root:[  126] Training loss: 0.93486632, Validation loss: 0.93658600, Gradient norm: 0.22973322
INFO:root:At the start of the epoch: mem (CPU python)=50491.796875MB; mem (CPU total)=50298.88671875MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  127] Training loss: 0.93482960, Validation loss: 0.93654856, Gradient norm: 0.23201860
INFO:root:At the start of the epoch: mem (CPU python)=50529.890625MB; mem (CPU total)=50336.88671875MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  128] Training loss: 0.93478793, Validation loss: 0.93657078, Gradient norm: 0.22371513
INFO:root:At the start of the epoch: mem (CPU python)=50567.98828125MB; mem (CPU total)=50375.03125MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  129] Training loss: 0.93474591, Validation loss: 0.93673776, Gradient norm: 0.22118148
INFO:root:At the start of the epoch: mem (CPU python)=50606.0859375MB; mem (CPU total)=50413.18359375MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:EP 129: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=50644.140625MB; mem (CPU total)=50451.2109375MB
INFO:root:Training the model took 12958.69s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93879
INFO:root:EnergyScoreTrain: 0.82843
INFO:root:CRPSTrain: 0.66829
INFO:root:Gaussian NLLTrain: 727.26759
INFO:root:CoverageTrain: 0.13265
INFO:root:IntervalWidthTrain: 0.28109
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9431
INFO:root:EnergyScoreValidation: 0.83096
INFO:root:CRPSValidation: 0.67036
INFO:root:Gaussian NLLValidation: 453.08564
INFO:root:CoverageValidation: 0.1346
INFO:root:IntervalWidthValidation: 0.28783
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94211
INFO:root:EnergyScoreTest: 0.83321
INFO:root:CRPSTest: 0.67282
INFO:root:Gaussian NLLTest: 1256.91435
INFO:root:CoverageTest: 0.1292
INFO:root:IntervalWidthTest: 0.27683
INFO:root:After validation: mem (CPU python)=50717.7421875MB; mem (CPU total)=50526.890625MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=50717.7421875MB; mem (CPU total)=50527.1640625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=50717.96875MB; mem (CPU total)=50527.1640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=50717.96875MB; mem (CPU total)=50527.41015625MB
INFO:root:[    1] Training loss: 1.00800240, Validation loss: 0.99260853, Gradient norm: 0.05079273
INFO:root:At the start of the epoch: mem (CPU python)=50755.67578125MB; mem (CPU total)=50564.6640625MB
INFO:root:[    2] Training loss: 0.98273350, Validation loss: 0.97822637, Gradient norm: 0.11035727
INFO:root:At the start of the epoch: mem (CPU python)=50793.7734375MB; mem (CPU total)=50603.22265625MB
INFO:root:[    3] Training loss: 0.97503274, Validation loss: 0.97420170, Gradient norm: 0.14528363
INFO:root:At the start of the epoch: mem (CPU python)=50831.8671875MB; mem (CPU total)=50641.4609375MB
INFO:root:[    4] Training loss: 0.97163696, Validation loss: 0.97103752, Gradient norm: 0.13773846
INFO:root:At the start of the epoch: mem (CPU python)=50869.9609375MB; mem (CPU total)=50679.44921875MB
INFO:root:[    5] Training loss: 0.96946839, Validation loss: 0.96888222, Gradient norm: 0.14645414
INFO:root:At the start of the epoch: mem (CPU python)=50908.05859375MB; mem (CPU total)=50717.671875MB
INFO:root:[    6] Training loss: 0.96756388, Validation loss: 0.96813439, Gradient norm: 0.15268744
INFO:root:At the start of the epoch: mem (CPU python)=50946.15234375MB; mem (CPU total)=50755.9140625MB
INFO:root:[    7] Training loss: 0.96596042, Validation loss: 0.96668912, Gradient norm: 0.15867228
INFO:root:At the start of the epoch: mem (CPU python)=50984.24609375MB; mem (CPU total)=50794.09375MB
INFO:root:[    8] Training loss: 0.96459572, Validation loss: 0.96508984, Gradient norm: 0.16678651
INFO:root:At the start of the epoch: mem (CPU python)=51022.34375MB; mem (CPU total)=50831.90234375MB
INFO:root:[    9] Training loss: 0.96312909, Validation loss: 0.96358958, Gradient norm: 0.17363218
INFO:root:At the start of the epoch: mem (CPU python)=51060.4375MB; mem (CPU total)=50870.33984375MB
INFO:root:[   10] Training loss: 0.96226100, Validation loss: 0.96264782, Gradient norm: 0.18801624
INFO:root:At the start of the epoch: mem (CPU python)=51098.53515625MB; mem (CPU total)=50908.4453125MB
INFO:root:[   11] Training loss: 0.96131116, Validation loss: 0.96179594, Gradient norm: 0.19685858
INFO:root:At the start of the epoch: mem (CPU python)=51136.62890625MB; mem (CPU total)=50946.9765625MB
INFO:root:[   12] Training loss: 0.96030169, Validation loss: 0.96313396, Gradient norm: 0.20511392
INFO:root:At the start of the epoch: mem (CPU python)=51174.7265625MB; mem (CPU total)=50985.48828125MB
INFO:root:[   13] Training loss: 0.95948497, Validation loss: 0.96027089, Gradient norm: 0.22174046
INFO:root:At the start of the epoch: mem (CPU python)=51212.8203125MB; mem (CPU total)=51023.5390625MB
INFO:root:[   14] Training loss: 0.95868449, Validation loss: 0.95817483, Gradient norm: 0.21672279
INFO:root:At the start of the epoch: mem (CPU python)=51250.91796875MB; mem (CPU total)=51061.09375MB
INFO:root:[   15] Training loss: 0.95762383, Validation loss: 0.95704484, Gradient norm: 0.23002839
INFO:root:At the start of the epoch: mem (CPU python)=51289.015625MB; mem (CPU total)=51099.609375MB
INFO:root:[   16] Training loss: 0.95672170, Validation loss: 0.95631183, Gradient norm: 0.23422431
INFO:root:At the start of the epoch: mem (CPU python)=51327.109375MB; mem (CPU total)=51138.1015625MB
INFO:root:[   17] Training loss: 0.95592813, Validation loss: 0.95629635, Gradient norm: 0.23646392
INFO:root:At the start of the epoch: mem (CPU python)=51365.203125MB; mem (CPU total)=51175.86328125MB
INFO:root:[   18] Training loss: 0.95516748, Validation loss: 0.95455633, Gradient norm: 0.23397990
INFO:root:At the start of the epoch: mem (CPU python)=51403.296875MB; mem (CPU total)=51213.984375MB
INFO:root:[   19] Training loss: 0.95453898, Validation loss: 0.95489897, Gradient norm: 0.24209089
INFO:root:At the start of the epoch: mem (CPU python)=51441.39453125MB; mem (CPU total)=51252.36328125MB
INFO:root:[   20] Training loss: 0.95369938, Validation loss: 0.95397649, Gradient norm: 0.25390549
INFO:root:At the start of the epoch: mem (CPU python)=51479.48828125MB; mem (CPU total)=51290.33984375MB
INFO:root:[   21] Training loss: 0.95296760, Validation loss: 0.95248962, Gradient norm: 0.25242430
INFO:root:At the start of the epoch: mem (CPU python)=51517.5859375MB; mem (CPU total)=51328.484375MB
INFO:root:[   22] Training loss: 0.95219639, Validation loss: 0.95252657, Gradient norm: 0.25181816
INFO:root:At the start of the epoch: mem (CPU python)=51555.6796875MB; mem (CPU total)=51366.875MB
INFO:root:[   23] Training loss: 0.95185194, Validation loss: 0.95073180, Gradient norm: 0.24351434
INFO:root:At the start of the epoch: mem (CPU python)=51593.77734375MB; mem (CPU total)=51404.83203125MB
INFO:root:[   24] Training loss: 0.95114705, Validation loss: 0.95118001, Gradient norm: 0.25456447
INFO:root:At the start of the epoch: mem (CPU python)=51631.8671875MB; mem (CPU total)=51443.13671875MB
INFO:root:[   25] Training loss: 0.95068206, Validation loss: 0.95090536, Gradient norm: 0.26624478
INFO:root:At the start of the epoch: mem (CPU python)=51669.9609375MB; mem (CPU total)=51480.94140625MB
INFO:root:[   26] Training loss: 0.95026621, Validation loss: 0.95078200, Gradient norm: 0.26988211
INFO:root:At the start of the epoch: mem (CPU python)=51708.0625MB; mem (CPU total)=51518.8984375MB
INFO:root:[   27] Training loss: 0.94984865, Validation loss: 0.95033317, Gradient norm: 0.26560441
INFO:root:At the start of the epoch: mem (CPU python)=51746.15625MB; mem (CPU total)=51557.4140625MB
INFO:root:[   28] Training loss: 0.94932183, Validation loss: 0.94872085, Gradient norm: 0.28635557
INFO:root:At the start of the epoch: mem (CPU python)=51784.25MB; mem (CPU total)=51595.60546875MB
INFO:root:[   29] Training loss: 0.94888801, Validation loss: 0.94984659, Gradient norm: 0.27207509
INFO:root:At the start of the epoch: mem (CPU python)=51822.34765625MB; mem (CPU total)=51634.171875MB
INFO:root:[   30] Training loss: 0.94874087, Validation loss: 0.94939498, Gradient norm: 0.28924343
INFO:root:At the start of the epoch: mem (CPU python)=51860.44140625MB; mem (CPU total)=51672.26171875MB
INFO:root:[   31] Training loss: 0.94811303, Validation loss: 0.94944463, Gradient norm: 0.27966986
INFO:root:At the start of the epoch: mem (CPU python)=51898.53515625MB; mem (CPU total)=51710.12890625MB
INFO:root:[   32] Training loss: 0.94787288, Validation loss: 0.94757030, Gradient norm: 0.28354447
INFO:root:At the start of the epoch: mem (CPU python)=51936.63671875MB; mem (CPU total)=51747.34765625MB
INFO:root:[   33] Training loss: 0.94767764, Validation loss: 0.94798484, Gradient norm: 0.30157459
INFO:root:At the start of the epoch: mem (CPU python)=51974.7265625MB; mem (CPU total)=51785.23046875MB
INFO:root:[   34] Training loss: 0.94715688, Validation loss: 0.94831871, Gradient norm: 0.27330233
INFO:root:At the start of the epoch: mem (CPU python)=52012.82421875MB; mem (CPU total)=51823.62109375MB
INFO:root:[   35] Training loss: 0.94692397, Validation loss: 0.94801639, Gradient norm: 0.27834698
INFO:root:At the start of the epoch: mem (CPU python)=52050.91796875MB; mem (CPU total)=51861.10546875MB
INFO:root:[   36] Training loss: 0.94681377, Validation loss: 0.94712148, Gradient norm: 0.28581256
INFO:root:At the start of the epoch: mem (CPU python)=52089.015625MB; mem (CPU total)=51899.875MB
INFO:root:[   37] Training loss: 0.94655291, Validation loss: 0.94801457, Gradient norm: 0.29241465
INFO:root:At the start of the epoch: mem (CPU python)=52127.109375MB; mem (CPU total)=51938.296875MB
INFO:root:[   38] Training loss: 0.94622358, Validation loss: 0.94699157, Gradient norm: 0.28635387
INFO:root:At the start of the epoch: mem (CPU python)=52165.20703125MB; mem (CPU total)=51976.62109375MB
INFO:root:[   39] Training loss: 0.94585098, Validation loss: 0.94633508, Gradient norm: 0.28343307
INFO:root:At the start of the epoch: mem (CPU python)=52203.3046875MB; mem (CPU total)=52013.50390625MB
INFO:root:[   40] Training loss: 0.94608405, Validation loss: 0.94611632, Gradient norm: 0.30614907
INFO:root:At the start of the epoch: mem (CPU python)=52241.3984375MB; mem (CPU total)=52051.859375MB
INFO:root:[   41] Training loss: 0.94554088, Validation loss: 0.94648137, Gradient norm: 0.29773347
INFO:root:At the start of the epoch: mem (CPU python)=52279.48828125MB; mem (CPU total)=52090.171875MB
INFO:root:[   42] Training loss: 0.94517721, Validation loss: 0.94587754, Gradient norm: 0.28466458
INFO:root:At the start of the epoch: mem (CPU python)=52317.5859375MB; mem (CPU total)=52128.1484375MB
INFO:root:[   43] Training loss: 0.94501699, Validation loss: 0.94627226, Gradient norm: 0.29084967
INFO:root:At the start of the epoch: mem (CPU python)=52355.68359375MB; mem (CPU total)=52165.98046875MB
INFO:root:[   44] Training loss: 0.94489707, Validation loss: 0.94501885, Gradient norm: 0.29382587
INFO:root:At the start of the epoch: mem (CPU python)=52393.78125MB; mem (CPU total)=52204.36328125MB
INFO:root:[   45] Training loss: 0.94464230, Validation loss: 0.94522403, Gradient norm: 0.28062159
INFO:root:At the start of the epoch: mem (CPU python)=52431.87109375MB; mem (CPU total)=52242.75390625MB
INFO:root:[   46] Training loss: 0.94453498, Validation loss: 0.94468804, Gradient norm: 0.29921677
INFO:root:At the start of the epoch: mem (CPU python)=52469.96875MB; mem (CPU total)=52281.41015625MB
INFO:root:[   47] Training loss: 0.94449690, Validation loss: 0.94496788, Gradient norm: 0.30803229
INFO:root:At the start of the epoch: mem (CPU python)=52508.06640625MB; mem (CPU total)=52319.55078125MB
INFO:root:[   48] Training loss: 0.94416706, Validation loss: 0.94535196, Gradient norm: 0.30650566
INFO:root:At the start of the epoch: mem (CPU python)=52546.16015625MB; mem (CPU total)=52357.6953125MB
INFO:root:[   49] Training loss: 0.94377550, Validation loss: 0.94522685, Gradient norm: 0.29884313
INFO:root:At the start of the epoch: mem (CPU python)=52584.26171875MB; mem (CPU total)=52396.29296875MB
INFO:root:[   50] Training loss: 0.94374906, Validation loss: 0.94437293, Gradient norm: 0.29203488
INFO:root:At the start of the epoch: mem (CPU python)=52622.35546875MB; mem (CPU total)=52434.546875MB
INFO:root:[   51] Training loss: 0.94332660, Validation loss: 0.94350696, Gradient norm: 0.29518314
INFO:root:At the start of the epoch: mem (CPU python)=52660.44921875MB; mem (CPU total)=52473.09375MB
INFO:root:[   52] Training loss: 0.94300555, Validation loss: 0.94371224, Gradient norm: 0.27461616
INFO:root:At the start of the epoch: mem (CPU python)=52698.54296875MB; mem (CPU total)=52510.5546875MB
INFO:root:[   53] Training loss: 0.94295080, Validation loss: 0.94319576, Gradient norm: 0.29772962
INFO:root:At the start of the epoch: mem (CPU python)=52736.640625MB; mem (CPU total)=52548.08984375MB
INFO:root:[   54] Training loss: 0.94276589, Validation loss: 0.94385716, Gradient norm: 0.28614470
INFO:root:At the start of the epoch: mem (CPU python)=52774.734375MB; mem (CPU total)=52586.203125MB
INFO:root:[   55] Training loss: 0.94252480, Validation loss: 0.94340330, Gradient norm: 0.28855411
INFO:root:At the start of the epoch: mem (CPU python)=52812.828125MB; mem (CPU total)=52624.59375MB
INFO:root:[   56] Training loss: 0.94241749, Validation loss: 0.94231646, Gradient norm: 0.32125046
INFO:root:At the start of the epoch: mem (CPU python)=52850.9296875MB; mem (CPU total)=52662.73828125MB
INFO:root:[   57] Training loss: 0.94206278, Validation loss: 0.94303866, Gradient norm: 0.29385530
INFO:root:At the start of the epoch: mem (CPU python)=52889.01953125MB; mem (CPU total)=52701.64453125MB
INFO:root:[   58] Training loss: 0.94175236, Validation loss: 0.94214759, Gradient norm: 0.29401015
INFO:root:At the start of the epoch: mem (CPU python)=52927.1171875MB; mem (CPU total)=52739.6015625MB
INFO:root:[   59] Training loss: 0.94178659, Validation loss: 0.94268417, Gradient norm: 0.31432844
INFO:root:At the start of the epoch: mem (CPU python)=52965.2109375MB; mem (CPU total)=52777.81640625MB
INFO:root:[   60] Training loss: 0.94122009, Validation loss: 0.94164754, Gradient norm: 0.31334045
INFO:root:At the start of the epoch: mem (CPU python)=53003.30859375MB; mem (CPU total)=52815.77734375MB
INFO:root:[   61] Training loss: 0.94112881, Validation loss: 0.94141315, Gradient norm: 0.33134945
INFO:root:At the start of the epoch: mem (CPU python)=53041.40234375MB; mem (CPU total)=52854.26171875MB
INFO:root:[   62] Training loss: 0.94088319, Validation loss: 0.94157148, Gradient norm: 0.31492125
INFO:root:At the start of the epoch: mem (CPU python)=53079.49609375MB; mem (CPU total)=52892.65234375MB
INFO:root:[   63] Training loss: 0.94041773, Validation loss: 0.94114630, Gradient norm: 0.30073334
INFO:root:At the start of the epoch: mem (CPU python)=53117.59765625MB; mem (CPU total)=52930.3515625MB
INFO:root:[   64] Training loss: 0.94023680, Validation loss: 0.94064922, Gradient norm: 0.31690360
INFO:root:At the start of the epoch: mem (CPU python)=53155.69140625MB; mem (CPU total)=52968.44140625MB
INFO:root:[   65] Training loss: 0.94002047, Validation loss: 0.94049538, Gradient norm: 0.31072799
INFO:root:At the start of the epoch: mem (CPU python)=53193.78515625MB; mem (CPU total)=53006.84765625MB
INFO:root:[   66] Training loss: 0.93985795, Validation loss: 0.93953895, Gradient norm: 0.31978253
INFO:root:At the start of the epoch: mem (CPU python)=53231.8828125MB; mem (CPU total)=53045.06640625MB
INFO:root:[   67] Training loss: 0.93946748, Validation loss: 0.94007654, Gradient norm: 0.32088734
INFO:root:At the start of the epoch: mem (CPU python)=53269.9765625MB; mem (CPU total)=53083.2109375MB
INFO:root:[   68] Training loss: 0.93925880, Validation loss: 0.94091569, Gradient norm: 0.32075790
INFO:root:At the start of the epoch: mem (CPU python)=53308.0703125MB; mem (CPU total)=53121.22265625MB
INFO:root:[   69] Training loss: 0.93925595, Validation loss: 0.94026925, Gradient norm: 0.32495091
INFO:root:At the start of the epoch: mem (CPU python)=53346.1640625MB; mem (CPU total)=53158.93359375MB
INFO:root:[   70] Training loss: 0.93911908, Validation loss: 0.93937593, Gradient norm: 0.31614509
INFO:root:At the start of the epoch: mem (CPU python)=53384.265625MB; mem (CPU total)=53196.6953125MB
INFO:root:[   71] Training loss: 0.93880892, Validation loss: 0.93939342, Gradient norm: 0.31309618
INFO:root:At the start of the epoch: mem (CPU python)=53422.35546875MB; mem (CPU total)=53234.82421875MB
INFO:root:[   72] Training loss: 0.93859203, Validation loss: 0.93850646, Gradient norm: 0.33087764
INFO:root:At the start of the epoch: mem (CPU python)=53460.453125MB; mem (CPU total)=53273.35546875MB
INFO:root:[   73] Training loss: 0.93837230, Validation loss: 0.93863758, Gradient norm: 0.30594554
INFO:root:At the start of the epoch: mem (CPU python)=53498.546875MB; mem (CPU total)=53311.5MB
INFO:root:[   74] Training loss: 0.93835553, Validation loss: 0.94000672, Gradient norm: 0.34458633
INFO:root:At the start of the epoch: mem (CPU python)=53536.64453125MB; mem (CPU total)=53349.9375MB
INFO:root:[   75] Training loss: 0.93824451, Validation loss: 0.93982832, Gradient norm: 0.31441010
INFO:root:At the start of the epoch: mem (CPU python)=53574.73828125MB; mem (CPU total)=53387.37109375MB
INFO:root:[   76] Training loss: 0.93811636, Validation loss: 0.93830882, Gradient norm: 0.32520073
INFO:root:At the start of the epoch: mem (CPU python)=53612.83203125MB; mem (CPU total)=53425.50390625MB
INFO:root:[   77] Training loss: 0.93788971, Validation loss: 0.93964907, Gradient norm: 0.32580993
INFO:root:At the start of the epoch: mem (CPU python)=53650.9296875MB; mem (CPU total)=53463.43359375MB
INFO:root:[   78] Training loss: 0.93778547, Validation loss: 0.93867300, Gradient norm: 0.30462134
INFO:root:At the start of the epoch: mem (CPU python)=53689.0234375MB; mem (CPU total)=53501.57421875MB
INFO:root:[   79] Training loss: 0.93753194, Validation loss: 0.93770206, Gradient norm: 0.31213650
INFO:root:At the start of the epoch: mem (CPU python)=53727.1171875MB; mem (CPU total)=53540.24609375MB
INFO:root:[   80] Training loss: 0.93753029, Validation loss: 0.93899087, Gradient norm: 0.32554894
INFO:root:At the start of the epoch: mem (CPU python)=53765.21484375MB; mem (CPU total)=53578.91015625MB
INFO:root:[   81] Training loss: 0.93747623, Validation loss: 0.93777710, Gradient norm: 0.32405571
INFO:root:At the start of the epoch: mem (CPU python)=53803.30859375MB; mem (CPU total)=53617.03125MB
INFO:root:[   82] Training loss: 0.93740291, Validation loss: 0.93812371, Gradient norm: 0.32535613
INFO:root:At the start of the epoch: mem (CPU python)=53841.40625MB; mem (CPU total)=53655.03515625MB
INFO:root:[   83] Training loss: 0.93723795, Validation loss: 0.93787259, Gradient norm: 0.32746128
INFO:root:At the start of the epoch: mem (CPU python)=53879.50390625MB; mem (CPU total)=53693.16796875MB
INFO:root:[   84] Training loss: 0.93711023, Validation loss: 0.93764481, Gradient norm: 0.32082161
INFO:root:At the start of the epoch: mem (CPU python)=53917.59765625MB; mem (CPU total)=53731.65234375MB
INFO:root:[   85] Training loss: 0.93689781, Validation loss: 0.93780382, Gradient norm: 0.29329118
INFO:root:At the start of the epoch: mem (CPU python)=53955.69140625MB; mem (CPU total)=53771.04296875MB
INFO:root:[   86] Training loss: 0.93678565, Validation loss: 0.93806811, Gradient norm: 0.30389562
INFO:root:At the start of the epoch: mem (CPU python)=53993.78515625MB; mem (CPU total)=53807.578125MB
INFO:root:[   87] Training loss: 0.93676384, Validation loss: 0.93745080, Gradient norm: 0.32864060
INFO:root:At the start of the epoch: mem (CPU python)=54031.8828125MB; mem (CPU total)=53845.0078125MB
INFO:root:[   88] Training loss: 0.93664750, Validation loss: 0.93771576, Gradient norm: 0.31760909
INFO:root:At the start of the epoch: mem (CPU python)=54069.9765625MB; mem (CPU total)=53883.234375MB
INFO:root:[   89] Training loss: 0.93654634, Validation loss: 0.93697292, Gradient norm: 0.30799698
INFO:root:At the start of the epoch: mem (CPU python)=54108.07421875MB; mem (CPU total)=53921.359375MB
INFO:root:[   90] Training loss: 0.93644209, Validation loss: 0.93728866, Gradient norm: 0.30995626
INFO:root:At the start of the epoch: mem (CPU python)=54146.16796875MB; mem (CPU total)=53959.546875MB
INFO:root:[   91] Training loss: 0.93649218, Validation loss: 0.93694442, Gradient norm: 0.31598977
INFO:root:At the start of the epoch: mem (CPU python)=54184.265625MB; mem (CPU total)=53997.68359375MB
INFO:root:[   92] Training loss: 0.93637161, Validation loss: 0.93689668, Gradient norm: 0.31129096
INFO:root:At the start of the epoch: mem (CPU python)=54222.359375MB; mem (CPU total)=54036.18359375MB
INFO:root:[   93] Training loss: 0.93626082, Validation loss: 0.93764681, Gradient norm: 0.31544798
INFO:root:At the start of the epoch: mem (CPU python)=54260.44921875MB; mem (CPU total)=54073.87890625MB
INFO:root:[   94] Training loss: 0.93611703, Validation loss: 0.93644701, Gradient norm: 0.31536498
INFO:root:At the start of the epoch: mem (CPU python)=54298.55078125MB; mem (CPU total)=54111.94140625MB
INFO:root:[   95] Training loss: 0.93602303, Validation loss: 0.93735262, Gradient norm: 0.30183052
INFO:root:At the start of the epoch: mem (CPU python)=54336.64453125MB; mem (CPU total)=54149.87890625MB
INFO:root:[   96] Training loss: 0.93593066, Validation loss: 0.93773656, Gradient norm: 0.30783953
INFO:root:At the start of the epoch: mem (CPU python)=54374.73828125MB; mem (CPU total)=54188.0859375MB
INFO:root:[   97] Training loss: 0.93590969, Validation loss: 0.93752843, Gradient norm: 0.32576000
INFO:root:At the start of the epoch: mem (CPU python)=54412.8359375MB; mem (CPU total)=54226.30859375MB
INFO:root:[   98] Training loss: 0.93588915, Validation loss: 0.93732428, Gradient norm: 0.31875335
INFO:root:At the start of the epoch: mem (CPU python)=54450.9296875MB; mem (CPU total)=54264.28125MB
INFO:root:[   99] Training loss: 0.93565215, Validation loss: 0.93639191, Gradient norm: 0.30267579
INFO:root:At the start of the epoch: mem (CPU python)=54489.02734375MB; mem (CPU total)=54302.82421875MB
INFO:root:[  100] Training loss: 0.93567301, Validation loss: 0.93689363, Gradient norm: 0.31087154
INFO:root:At the start of the epoch: mem (CPU python)=54527.12109375MB; mem (CPU total)=54340.96484375MB
INFO:root:[  101] Training loss: 0.93563205, Validation loss: 0.93654005, Gradient norm: 0.31527710
INFO:root:At the start of the epoch: mem (CPU python)=54565.21875MB; mem (CPU total)=54377.97265625MB
INFO:root:[  102] Training loss: 0.93555525, Validation loss: 0.93690461, Gradient norm: 0.31140107
INFO:root:At the start of the epoch: mem (CPU python)=54603.3125MB; mem (CPU total)=54417.23046875MB
INFO:root:[  103] Training loss: 0.93552051, Validation loss: 0.93572155, Gradient norm: 0.30715560
INFO:root:At the start of the epoch: mem (CPU python)=54641.40625MB; mem (CPU total)=54455.1875MB
INFO:root:[  104] Training loss: 0.93539003, Validation loss: 0.93613157, Gradient norm: 0.31252876
INFO:root:At the start of the epoch: mem (CPU python)=54679.50390625MB; mem (CPU total)=54493.82421875MB
INFO:root:[  105] Training loss: 0.93525239, Validation loss: 0.93589897, Gradient norm: 0.32984259
INFO:root:At the start of the epoch: mem (CPU python)=54717.59765625MB; mem (CPU total)=54531.96875MB
INFO:root:[  106] Training loss: 0.93520012, Validation loss: 0.93624856, Gradient norm: 0.31020902
INFO:root:At the start of the epoch: mem (CPU python)=54755.69140625MB; mem (CPU total)=54570.0390625MB
INFO:root:[  107] Training loss: 0.93509782, Validation loss: 0.93681040, Gradient norm: 0.31521114
INFO:root:At the start of the epoch: mem (CPU python)=54793.79296875MB; mem (CPU total)=54610.484375MB
INFO:root:[  108] Training loss: 0.93506641, Validation loss: 0.93563049, Gradient norm: 0.29984001
INFO:root:At the start of the epoch: mem (CPU python)=54831.88671875MB; mem (CPU total)=54649.9453125MB
INFO:root:[  109] Training loss: 0.93499535, Validation loss: 0.93628064, Gradient norm: 0.31093503
INFO:root:At the start of the epoch: mem (CPU python)=54869.98046875MB; mem (CPU total)=54687.10546875MB
INFO:root:[  110] Training loss: 0.93498970, Validation loss: 0.93652042, Gradient norm: 0.29815803
INFO:root:At the start of the epoch: mem (CPU python)=54908.07421875MB; mem (CPU total)=54725.02734375MB
INFO:root:[  111] Training loss: 0.93475968, Validation loss: 0.93604397, Gradient norm: 0.30467710
INFO:root:At the start of the epoch: mem (CPU python)=54946.171875MB; mem (CPU total)=54762.86328125MB
INFO:root:[  112] Training loss: 0.93497748, Validation loss: 0.93547677, Gradient norm: 0.32148792
INFO:root:At the start of the epoch: mem (CPU python)=54984.265625MB; mem (CPU total)=54801.60546875MB
INFO:root:[  113] Training loss: 0.93460858, Validation loss: 0.93620809, Gradient norm: 0.31011326
INFO:root:At the start of the epoch: mem (CPU python)=55022.359375MB; mem (CPU total)=54840.0234375MB
INFO:root:[  114] Training loss: 0.93458541, Validation loss: 0.93534339, Gradient norm: 0.29456207
INFO:root:At the start of the epoch: mem (CPU python)=55060.4609375MB; mem (CPU total)=54880.45703125MB
INFO:root:[  115] Training loss: 0.93460991, Validation loss: 0.93636246, Gradient norm: 0.30369370
INFO:root:At the start of the epoch: mem (CPU python)=55098.5234375MB; mem (CPU total)=54882.30859375MB
INFO:root:[  116] Training loss: 0.93443910, Validation loss: 0.93558478, Gradient norm: 0.31220949
INFO:root:At the start of the epoch: mem (CPU python)=55136.6171875MB; mem (CPU total)=54919.625MB
INFO:root:[  117] Training loss: 0.93434073, Validation loss: 0.93619138, Gradient norm: 0.29853016
INFO:root:At the start of the epoch: mem (CPU python)=55174.71484375MB; mem (CPU total)=54959.671875MB
INFO:root:[  118] Training loss: 0.93432226, Validation loss: 0.93526633, Gradient norm: 0.29097487
INFO:root:At the start of the epoch: mem (CPU python)=55212.8125MB; mem (CPU total)=54997.1328125MB
INFO:root:[  119] Training loss: 0.93435820, Validation loss: 0.93577153, Gradient norm: 0.29781184
INFO:root:At the start of the epoch: mem (CPU python)=55250.90625MB; mem (CPU total)=55036.28515625MB
INFO:root:[  120] Training loss: 0.93422004, Validation loss: 0.93525821, Gradient norm: 0.29635285
INFO:root:At the start of the epoch: mem (CPU python)=55289.0MB; mem (CPU total)=55072.484375MB
INFO:root:[  121] Training loss: 0.93416385, Validation loss: 0.93573914, Gradient norm: 0.29553027
INFO:root:At the start of the epoch: mem (CPU python)=55327.09765625MB; mem (CPU total)=55110.61328125MB
INFO:root:[  122] Training loss: 0.93408104, Validation loss: 0.93543293, Gradient norm: 0.29243173
INFO:root:At the start of the epoch: mem (CPU python)=55365.19140625MB; mem (CPU total)=55150.50390625MB
INFO:root:[  123] Training loss: 0.93402959, Validation loss: 0.93484991, Gradient norm: 0.29508274
INFO:root:At the start of the epoch: mem (CPU python)=55403.2890625MB; mem (CPU total)=55190.15234375MB
INFO:root:[  124] Training loss: 0.93400392, Validation loss: 0.93513411, Gradient norm: 0.30939195
INFO:root:At the start of the epoch: mem (CPU python)=55441.3828125MB; mem (CPU total)=55226.97265625MB
INFO:root:[  125] Training loss: 0.93402562, Validation loss: 0.93520298, Gradient norm: 0.30158484
INFO:root:At the start of the epoch: mem (CPU python)=55479.4765625MB; mem (CPU total)=55263.6953125MB
INFO:root:[  126] Training loss: 0.93391837, Validation loss: 0.93525668, Gradient norm: 0.30767392
INFO:root:At the start of the epoch: mem (CPU python)=55517.57421875MB; mem (CPU total)=55303.6640625MB
INFO:root:[  127] Training loss: 0.93392285, Validation loss: 0.93522167, Gradient norm: 0.31535737
INFO:root:At the start of the epoch: mem (CPU python)=55555.66796875MB; mem (CPU total)=55341.33984375MB
INFO:root:[  128] Training loss: 0.93353866, Validation loss: 0.93524983, Gradient norm: 0.29657322
INFO:root:At the start of the epoch: mem (CPU python)=55593.765625MB; mem (CPU total)=55380.296875MB
INFO:root:[  129] Training loss: 0.93358232, Validation loss: 0.93456365, Gradient norm: 0.29712353
INFO:root:At the start of the epoch: mem (CPU python)=55631.859375MB; mem (CPU total)=55419.17578125MB
INFO:root:[  130] Training loss: 0.93354909, Validation loss: 0.93541248, Gradient norm: 0.30755885
INFO:root:At the start of the epoch: mem (CPU python)=55669.953125MB; mem (CPU total)=55454.12890625MB
INFO:root:[  131] Training loss: 0.93356438, Validation loss: 0.93481897, Gradient norm: 0.30527988
INFO:root:At the start of the epoch: mem (CPU python)=55708.05078125MB; mem (CPU total)=55492.60546875MB
INFO:root:[  132] Training loss: 0.93355157, Validation loss: 0.93454927, Gradient norm: 0.30332873
INFO:root:At the start of the epoch: mem (CPU python)=55746.1484375MB; mem (CPU total)=55531.921875MB
INFO:root:[  133] Training loss: 0.93341933, Validation loss: 0.93505194, Gradient norm: 0.29454576
INFO:root:At the start of the epoch: mem (CPU python)=55784.23828125MB; mem (CPU total)=55570.77734375MB
INFO:root:[  134] Training loss: 0.93343180, Validation loss: 0.93434126, Gradient norm: 0.30900441
INFO:root:At the start of the epoch: mem (CPU python)=55822.33984375MB; mem (CPU total)=55609.40625MB
INFO:root:[  135] Training loss: 0.93322976, Validation loss: 0.93447057, Gradient norm: 0.30994481
INFO:root:At the start of the epoch: mem (CPU python)=55860.4296875MB; mem (CPU total)=55647.07421875MB
INFO:root:[  136] Training loss: 0.93325828, Validation loss: 0.93400553, Gradient norm: 0.29350227
INFO:root:At the start of the epoch: mem (CPU python)=55898.52734375MB; mem (CPU total)=55682.625MB
INFO:root:[  137] Training loss: 0.93315616, Validation loss: 0.93417678, Gradient norm: 0.30992033
INFO:root:At the start of the epoch: mem (CPU python)=55936.62109375MB; mem (CPU total)=55723.04296875MB
INFO:root:[  138] Training loss: 0.93297735, Validation loss: 0.93431382, Gradient norm: 0.29983549
INFO:root:At the start of the epoch: mem (CPU python)=55974.71875MB; mem (CPU total)=55759.1015625MB
INFO:root:[  139] Training loss: 0.93302588, Validation loss: 0.93370096, Gradient norm: 0.31072031
INFO:root:At the start of the epoch: mem (CPU python)=56012.8125MB; mem (CPU total)=55799.0MB
INFO:root:[  140] Training loss: 0.93311589, Validation loss: 0.93528541, Gradient norm: 0.32354184
INFO:root:At the start of the epoch: mem (CPU python)=56050.90625MB; mem (CPU total)=55835.1328125MB
INFO:root:[  141] Training loss: 0.93274849, Validation loss: 0.93424200, Gradient norm: 0.29870808
INFO:root:At the start of the epoch: mem (CPU python)=56089.00390625MB; mem (CPU total)=55873.75390625MB
INFO:root:[  142] Training loss: 0.93271436, Validation loss: 0.93395407, Gradient norm: 0.31083400
INFO:root:At the start of the epoch: mem (CPU python)=56127.1015625MB; mem (CPU total)=55913.55078125MB
INFO:root:[  143] Training loss: 0.93271832, Validation loss: 0.93378560, Gradient norm: 0.31868078
INFO:root:At the start of the epoch: mem (CPU python)=56165.1953125MB; mem (CPU total)=55949.98046875MB
INFO:root:[  144] Training loss: 0.93270238, Validation loss: 0.93387024, Gradient norm: 0.31300253
INFO:root:At the start of the epoch: mem (CPU python)=56203.2890625MB; mem (CPU total)=55989.87109375MB
INFO:root:[  145] Training loss: 0.93275279, Validation loss: 0.93340898, Gradient norm: 0.32473948
INFO:root:At the start of the epoch: mem (CPU python)=56241.38671875MB; mem (CPU total)=56026.26953125MB
INFO:root:[  146] Training loss: 0.93249710, Validation loss: 0.93350276, Gradient norm: 0.32832738
INFO:root:At the start of the epoch: mem (CPU python)=56279.48046875MB; mem (CPU total)=56063.9375MB
INFO:root:[  147] Training loss: 0.93261260, Validation loss: 0.93331036, Gradient norm: 0.34213134
INFO:root:At the start of the epoch: mem (CPU python)=56317.57421875MB; mem (CPU total)=56112.32421875MB
INFO:root:[  148] Training loss: 0.93230786, Validation loss: 0.93362371, Gradient norm: 0.31854290
INFO:root:At the start of the epoch: mem (CPU python)=56355.671875MB; mem (CPU total)=56139.640625MB
INFO:root:[  149] Training loss: 0.93232879, Validation loss: 0.93340011, Gradient norm: 0.32122466
INFO:root:At the start of the epoch: mem (CPU python)=56393.765625MB; mem (CPU total)=56178.26171875MB
INFO:root:[  150] Training loss: 0.93222208, Validation loss: 0.93412782, Gradient norm: 0.31722208
INFO:root:At the start of the epoch: mem (CPU python)=56431.859375MB; mem (CPU total)=56215.98828125MB
INFO:root:[  151] Training loss: 0.93215678, Validation loss: 0.93346685, Gradient norm: 0.33784527
INFO:root:At the start of the epoch: mem (CPU python)=56469.95703125MB; mem (CPU total)=56256.11328125MB
INFO:root:[  152] Training loss: 0.93210597, Validation loss: 0.93383538, Gradient norm: 0.32450176
INFO:root:At the start of the epoch: mem (CPU python)=56508.05078125MB; mem (CPU total)=56294.765625MB
INFO:root:[  153] Training loss: 0.93197326, Validation loss: 0.93333148, Gradient norm: 0.31881656
INFO:root:At the start of the epoch: mem (CPU python)=56546.1484375MB; mem (CPU total)=56331.94921875MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  154] Training loss: 0.93189381, Validation loss: 0.93319207, Gradient norm: 0.31315483
INFO:root:At the start of the epoch: mem (CPU python)=56584.2421875MB; mem (CPU total)=56368.62890625MB
INFO:root:[  155] Training loss: 0.93035777, Validation loss: 0.93205470, Gradient norm: 0.27135243
INFO:root:At the start of the epoch: mem (CPU python)=56622.33984375MB; mem (CPU total)=56405.79296875MB
INFO:root:[  156] Training loss: 0.93021377, Validation loss: 0.93179280, Gradient norm: 0.29460789
INFO:root:At the start of the epoch: mem (CPU python)=56660.4375MB; mem (CPU total)=56447.10546875MB
INFO:root:[  157] Training loss: 0.93018675, Validation loss: 0.93179626, Gradient norm: 0.28911615
INFO:root:At the start of the epoch: mem (CPU python)=56698.52734375MB; mem (CPU total)=56483.57421875MB
INFO:root:[  158] Training loss: 0.93005944, Validation loss: 0.93181436, Gradient norm: 0.28900089
INFO:root:At the start of the epoch: mem (CPU python)=56736.625MB; mem (CPU total)=56523.65625MB
INFO:root:[  159] Training loss: 0.92997966, Validation loss: 0.93185389, Gradient norm: 0.29272732
INFO:root:At the start of the epoch: mem (CPU python)=56774.72265625MB; mem (CPU total)=56559.67578125MB
INFO:root:[  160] Training loss: 0.92997818, Validation loss: 0.93213509, Gradient norm: 0.31243491
INFO:root:At the start of the epoch: mem (CPU python)=56812.8203125MB; mem (CPU total)=56597.578125MB
INFO:root:[  161] Training loss: 0.92992100, Validation loss: 0.93149297, Gradient norm: 0.28744116
INFO:root:At the start of the epoch: mem (CPU python)=56850.9140625MB; mem (CPU total)=56636.6640625MB
INFO:root:[  162] Training loss: 0.92978336, Validation loss: 0.93105838, Gradient norm: 0.30364720
INFO:root:At the start of the epoch: mem (CPU python)=56889.01171875MB; mem (CPU total)=56674.03125MB
INFO:root:[  163] Training loss: 0.92982984, Validation loss: 0.93209116, Gradient norm: 0.29428473
INFO:root:At the start of the epoch: mem (CPU python)=56927.10546875MB; mem (CPU total)=56714.96484375MB
INFO:root:[  164] Training loss: 0.92980002, Validation loss: 0.93191810, Gradient norm: 0.29446221
INFO:root:At the start of the epoch: mem (CPU python)=56965.19921875MB; mem (CPU total)=56751.91015625MB
INFO:root:[  165] Training loss: 0.92977918, Validation loss: 0.93164989, Gradient norm: 0.29872309
INFO:root:At the start of the epoch: mem (CPU python)=57003.296875MB; mem (CPU total)=56788.6796875MB
INFO:root:[  166] Training loss: 0.92971093, Validation loss: 0.93103439, Gradient norm: 0.29373802
INFO:root:At the start of the epoch: mem (CPU python)=57041.39453125MB; mem (CPU total)=56826.89453125MB
INFO:root:[  167] Training loss: 0.92966793, Validation loss: 0.93137520, Gradient norm: 0.30788167
INFO:root:At the start of the epoch: mem (CPU python)=57079.484375MB; mem (CPU total)=56864.78515625MB
INFO:root:[  168] Training loss: 0.92959944, Validation loss: 0.93178023, Gradient norm: 0.31223033
INFO:root:At the start of the epoch: mem (CPU python)=57117.58203125MB; mem (CPU total)=56904.8984375MB
INFO:root:[  169] Training loss: 0.92952558, Validation loss: 0.93089024, Gradient norm: 0.29832888
INFO:root:At the start of the epoch: mem (CPU python)=57155.6796875MB; mem (CPU total)=56941.421875MB
INFO:root:[  170] Training loss: 0.92963530, Validation loss: 0.93158865, Gradient norm: 0.31144943
INFO:root:At the start of the epoch: mem (CPU python)=57193.7734375MB; mem (CPU total)=56982.5234375MB
INFO:root:[  171] Training loss: 0.92934940, Validation loss: 0.93126674, Gradient norm: 0.28724467
INFO:root:At the start of the epoch: mem (CPU python)=57231.8671875MB; mem (CPU total)=57021.28125MB
INFO:root:[  172] Training loss: 0.92939715, Validation loss: 0.93155568, Gradient norm: 0.30122300
INFO:root:At the start of the epoch: mem (CPU python)=57269.96484375MB; mem (CPU total)=57056.19921875MB
INFO:root:[  173] Training loss: 0.92937305, Validation loss: 0.93117717, Gradient norm: 0.30801064
INFO:root:At the start of the epoch: mem (CPU python)=57308.05859375MB; mem (CPU total)=57095.5625MB
INFO:root:[  174] Training loss: 0.92930183, Validation loss: 0.93107457, Gradient norm: 0.29603769
INFO:root:At the start of the epoch: mem (CPU python)=57346.15234375MB; mem (CPU total)=57132.2734375MB
INFO:root:[  175] Training loss: 0.92937056, Validation loss: 0.93132545, Gradient norm: 0.32330327
INFO:root:At the start of the epoch: mem (CPU python)=57384.25MB; mem (CPU total)=57172.65625MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  176] Training loss: 0.92921552, Validation loss: 0.93163672, Gradient norm: 0.31299977
INFO:root:At the start of the epoch: mem (CPU python)=57422.3515625MB; mem (CPU total)=57208.57421875MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  177] Training loss: 0.92832377, Validation loss: 0.93072806, Gradient norm: 0.28624603
INFO:root:At the start of the epoch: mem (CPU python)=57450.20703125MB; mem (CPU total)=57246.73046875MB
INFO:root:[  178] Training loss: 0.92772229, Validation loss: 0.93073227, Gradient norm: 0.26591836
INFO:root:At the start of the epoch: mem (CPU python)=57456.54296875MB; mem (CPU total)=57285.1171875MB
INFO:root:[  179] Training loss: 0.92766921, Validation loss: 0.93051919, Gradient norm: 0.26724147
INFO:root:At the start of the epoch: mem (CPU python)=57490.859375MB; mem (CPU total)=57322.90234375MB
INFO:root:[  180] Training loss: 0.92765805, Validation loss: 0.93036764, Gradient norm: 0.26711031
INFO:root:At the start of the epoch: mem (CPU python)=57528.94140625MB; mem (CPU total)=57363.5546875MB
INFO:root:[  181] Training loss: 0.92766437, Validation loss: 0.92994621, Gradient norm: 0.26296484
INFO:root:At the start of the epoch: mem (CPU python)=57567.03515625MB; mem (CPU total)=57400.7109375MB
INFO:root:[  182] Training loss: 0.92765717, Validation loss: 0.93033030, Gradient norm: 0.27501985
INFO:root:At the start of the epoch: mem (CPU python)=57603.9453125MB; mem (CPU total)=57437.65234375MB
INFO:root:[  183] Training loss: 0.92759659, Validation loss: 0.93027052, Gradient norm: 0.28291101
INFO:root:At the start of the epoch: mem (CPU python)=57642.0390625MB; mem (CPU total)=57475.7890625MB
INFO:root:[  184] Training loss: 0.92759390, Validation loss: 0.93042872, Gradient norm: 0.28005608
INFO:root:At the start of the epoch: mem (CPU python)=57680.13671875MB; mem (CPU total)=57513.5703125MB
INFO:root:[  185] Training loss: 0.92757232, Validation loss: 0.93007142, Gradient norm: 0.28354306
INFO:root:At the start of the epoch: mem (CPU python)=57718.234375MB; mem (CPU total)=57553.8984375MB
INFO:root:[  186] Training loss: 0.92753640, Validation loss: 0.93008861, Gradient norm: 0.28637036
INFO:root:At the start of the epoch: mem (CPU python)=57756.328125MB; mem (CPU total)=57590.5703125MB
INFO:root:[  187] Training loss: 0.92751116, Validation loss: 0.93039775, Gradient norm: 0.28261521
INFO:root:At the start of the epoch: mem (CPU python)=57794.421875MB; mem (CPU total)=57628.54296875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  188] Training loss: 0.92749843, Validation loss: 0.93028889, Gradient norm: 0.28517840
INFO:root:At the start of the epoch: mem (CPU python)=57831.359375MB; mem (CPU total)=57667.01171875MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  189] Training loss: 0.92728481, Validation loss: 0.92972848, Gradient norm: 0.26983829
INFO:root:At the start of the epoch: mem (CPU python)=57850.53125MB; mem (CPU total)=57705.40234375MB
INFO:root:[  190] Training loss: 0.92708146, Validation loss: 0.92992608, Gradient norm: 0.26187111
INFO:root:At the start of the epoch: mem (CPU python)=57884.24609375MB; mem (CPU total)=57745.29296875MB
INFO:root:[  191] Training loss: 0.92703949, Validation loss: 0.93029036, Gradient norm: 0.26087940
INFO:root:At the start of the epoch: mem (CPU python)=57920.15234375MB; mem (CPU total)=57781.734375MB
INFO:root:[  192] Training loss: 0.92701179, Validation loss: 0.92946343, Gradient norm: 0.26616690
INFO:root:At the start of the epoch: mem (CPU python)=57958.25390625MB; mem (CPU total)=57824.44921875MB
INFO:root:[  193] Training loss: 0.92700268, Validation loss: 0.93015006, Gradient norm: 0.25710341
INFO:root:At the start of the epoch: mem (CPU python)=57996.34375MB; mem (CPU total)=57863.375MB
INFO:root:[  194] Training loss: 0.92699208, Validation loss: 0.92987587, Gradient norm: 0.26897156
INFO:root:At the start of the epoch: mem (CPU python)=58034.44140625MB; mem (CPU total)=57900.53515625MB
INFO:root:[  195] Training loss: 0.92702316, Validation loss: 0.93000170, Gradient norm: 0.26723651
INFO:root:At the start of the epoch: mem (CPU python)=58072.53515625MB; mem (CPU total)=57938.79296875MB
INFO:root:[  196] Training loss: 0.92704317, Validation loss: 0.92964130, Gradient norm: 0.26916952
INFO:root:At the start of the epoch: mem (CPU python)=58110.6328125MB; mem (CPU total)=57976.67578125MB
INFO:root:[  197] Training loss: 0.92706905, Validation loss: 0.93012309, Gradient norm: 0.26285027
INFO:root:At the start of the epoch: mem (CPU python)=58148.7265625MB; mem (CPU total)=58015.09765625MB
INFO:root:[  198] Training loss: 0.92700680, Validation loss: 0.93027194, Gradient norm: 0.26920500
INFO:root:At the start of the epoch: mem (CPU python)=58186.8203125MB; mem (CPU total)=58053.22265625MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  199] Training loss: 0.92704404, Validation loss: 0.92954834, Gradient norm: 0.27072628
INFO:root:At the start of the epoch: mem (CPU python)=58224.91796875MB; mem (CPU total)=58091.3671875MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  200] Training loss: 0.92694860, Validation loss: 0.92989258, Gradient norm: 0.26626787
INFO:root:At the start of the epoch: mem (CPU python)=58263.01171875MB; mem (CPU total)=58130.00390625MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  201] Training loss: 0.92684582, Validation loss: 0.92975770, Gradient norm: 0.26484858
INFO:root:At the start of the epoch: mem (CPU python)=58301.109375MB; mem (CPU total)=58168.1484375MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:EP 201: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=58339.1015625MB; mem (CPU total)=58206.2890625MB
INFO:root:Training the model took 22181.844s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92594
INFO:root:EnergyScoreTrain: 0.85412
INFO:root:CRPSTrain: 0.69281
INFO:root:Gaussian NLLTrain: 3008.93895
INFO:root:CoverageTrain: 0.08203
INFO:root:IntervalWidthTrain: 0.15301
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93203
INFO:root:EnergyScoreValidation: 0.86114
INFO:root:CRPSValidation: 0.69879
INFO:root:Gaussian NLLValidation: 4410.81159
INFO:root:CoverageValidation: 0.08036
INFO:root:IntervalWidthValidation: 0.15178
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93079
INFO:root:EnergyScoreTest: 0.86116
INFO:root:CRPSTest: 0.69744
INFO:root:Gaussian NLLTest: 2639.24759
INFO:root:CoverageTest: 0.08007
INFO:root:IntervalWidthTest: 0.15135
INFO:root:After validation: mem (CPU python)=58413.25MB; mem (CPU total)=58286.18359375MB
