,0,1,2,3,4,5,6,7,8
dataset_name,KS,KS,KS,KS,KS,KS,KS,KS,KS
max_training_set_size,10000,10000,10000,10000,10000,10000,10000,10000,10000
downscaling_factor,1,1,1,1,1,1,1,1,1
temporal_downscaling,2,2,2,2,2,2,2,2,2
init_steps,20,20,20,20,20,20,20,20,20
t_start,0,0,0,0,0,0,0,0,0
pred_horizon,20,20,20,20,20,20,20,20,20
seed,123456789,123456789,123456789,123456789,123456789,123456789,123456789,123456789,123456789
model,UNO,UNO,UNO,UNO,UNO,UNO,UNO,UNO,UNO
uncertainty_quantification,laplace,laplace,laplace,laplace,laplace,laplace,laplace,laplace,laplace
batch_size,32,32,32,32,32,32,32,32,32
n_epochs,1000,1000,1000,1000,1000,1000,1000,1000,1000
early_stopping,10,10,10,10,10,10,10,10,10
init,default,default,default,default,default,default,default,default,default
learning_rate,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
lr_schedule,no,no,no,no,no,no,no,no,no
optimizer,adam,adam,adam,adam,adam,adam,adam,adam,adam
gradient_clipping,1,1,1,1,1,1,1,1,1
layer_normalization,True,True,True,True,True,True,True,True,True
data_loader_pin_memory,False,False,False,False,False,False,False,False,False
data_loader_num_workers,0,0,0,0,0,0,0,0,0
distributed_training,False,False,False,False,False,False,False,False,False
alpha,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05
n_samples_uq,100,100,100,100,100,100,100,100,100
weight_decay,0,0,0,0,0,0,0,0,0
dropout,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
fourier_dropout,,,,,,,,,
hidden_channels,16,16,16,16,16,16,16,16,16
projection_channels,32,32,32,32,32,32,32,32,32
lifting_channels,32,32,32,32,32,32,32,32,32
n_samples,3,3,3,3,3,3,3,3,3
filename_to_validate,results/optimal_hp_multiple_seeds/ks/uno/20240915_182859_ks_uno_laplace/Datetime_20240915_182949_Loss_KS_UNO_laplace_dropout_0.001.pt,results/optimal_hp_multiple_seeds/ks/uno/20240915_182859_ks_uno_laplace/Datetime_20240915_200247_Loss_KS_UNO_laplace_dropout_0.001.pt,results/optimal_hp_multiple_seeds/ks/uno/20240915_182859_ks_uno_laplace/Datetime_20240915_224148_Loss_KS_UNO_laplace_dropout_0.001.pt,results/optimal_hp_multiple_seeds/ks/uno/20240915_182859_ks_uno_laplace/Datetime_20240916_021248_Loss_KS_UNO_laplace_dropout_0.001.pt,results/optimal_hp_multiple_seeds/ks/uno/20240915_182859_ks_uno_laplace/Datetime_20240916_045804_Loss_KS_UNO_laplace_dropout_0.001.pt,results/optimal_hp_multiple_seeds/ks/uno/20240915_182859_ks_uno_laplace/Datetime_20240916_075940_Loss_KS_UNO_laplace_dropout_0.001.pt,results/optimal_hp_multiple_seeds/ks/uno/20240915_182859_ks_uno_laplace/Datetime_20240916_114837_Loss_KS_UNO_laplace_dropout_0.001.pt,results/optimal_hp_multiple_seeds/ks/uno/20240915_182859_ks_uno_laplace/Datetime_20240916_155504_Loss_KS_UNO_laplace_dropout_0.001.pt,results/optimal_hp_multiple_seeds/ks/uno/20240915_182859_ks_uno_laplace/Datetime_20240916_193359_Loss_KS_UNO_laplace_dropout_0.001.pt
uno_out_channels,"[16, 32, 64, 128, 64, 32, 16]","[16, 32, 64, 128, 64, 32, 16]","[16, 32, 64, 128, 64, 32, 16]","[16, 32, 64, 128, 64, 32, 16]","[16, 32, 64, 128, 64, 32, 16]","[16, 32, 64, 128, 64, 32, 16]","[16, 32, 64, 128, 64, 32, 16]","[16, 32, 64, 128, 64, 32, 16]","[16, 32, 64, 128, 64, 32, 16]"
uno_scalings,"[[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]]","[[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]]","[[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]]","[[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]]","[[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]]","[[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]]","[[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]]","[[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]]","[[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]]"
uno_n_modes,"[[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]","[[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]","[[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]","[[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]","[[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]","[[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]","[[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]","[[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]","[[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]"
t_training,-1,-1,-1,-1,-1,-1,-1,-1,-1
MSETrain,0.93622,0.93262,0.93759,0.93826,1.01159,0.92945,0.93182,0.9438,0.9467
EnergyScoreTrain,0.82003,0.85398,0.83331,0.84865,0.90932,0.83598,0.84553,0.8373,0.87447
CRPSTrain,0.6598,0.68845,0.6722,0.68751,0.74464,0.6793,0.68245,0.67724,0.71305
Gaussian NLLTrain,22.41828,60.06061,26.46094,51.63072,34.07715,81.34558,43.35344,31.37905,139.35268
CoverageTrain,0.33491,0.21569,0.29556,0.24615,0.23813,0.25876,0.243,0.29563,0.17916
IntervalWidthTrain,0.77398,0.45712,0.66184,0.53575,0.62208,0.5347,0.51219,0.67612,0.37768
MSEValidation,0.94043,0.93806,0.94293,0.94339,1.01468,0.93477,0.93712,0.94763,0.95213
EnergyScoreValidation,0.82365,0.85903,0.83847,0.85324,0.91231,0.84134,0.85058,0.84087,0.87967
CRPSValidation,0.66308,0.69316,0.67679,0.6917,0.74736,0.68433,0.68725,0.68057,0.71778
Gaussian NLLValidation,22.47799,60.37295,26.77111,51.44024,34.1563,82.4099,43.82154,31.53675,139.63704
CoverageValidation,0.33525,0.21494,0.29372,0.24558,0.23712,0.25555,0.24118,0.29375,0.17785
IntervalWidthValidation,0.78102,0.46055,0.66317,0.53946,0.62206,0.53317,0.51342,0.67601,0.37882
MSETest,0.93959,0.93733,0.9424,0.94227,1.01443,0.93394,0.93635,0.94695,0.95126
EnergyScoreTest,0.82223,0.8584,0.83747,0.85205,0.91124,0.84034,0.84955,0.83984,0.87893
CRPSTest,0.66209,0.69269,0.67619,0.69068,0.7464,0.68352,0.6863,0.67999,0.71707
Gaussian NLLTest,22.24315,59.77291,26.2824,50.9555,33.41835,82.25562,43.32817,31.36103,139.42009
CoverageTest,0.33628,0.21438,0.29516,0.24689,0.23954,0.25665,0.2416,0.29545,0.17797
IntervalWidthTest,0.78343,0.45926,0.66958,0.54124,0.62958,0.53558,0.5148,0.68159,0.37813
