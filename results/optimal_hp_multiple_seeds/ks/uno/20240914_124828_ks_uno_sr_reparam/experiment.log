INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=579.86328125MB; mem (CPU total)=1064.3828125MB
INFO:root:############### Starting experiment with config file ks/uno_sr_reparam.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12459.2265625MB; mem (CPU total)=1071.32421875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12459.2265625MB; mem (CPU total)=1071.09375MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=12459.2265625MB; mem (CPU total)=2283.23828125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=2292.703125MB
INFO:root:[    1] Training loss: 0.71532141, Validation loss: 0.70416875, Gradient norm: 0.05633682
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3462.2890625MB
INFO:root:[    2] Training loss: 0.69788366, Validation loss: 0.69348697, Gradient norm: 0.06805396
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3501.828125MB
INFO:root:[    3] Training loss: 0.69193863, Validation loss: 0.69031604, Gradient norm: 0.08183672
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3540.9140625MB
INFO:root:[    4] Training loss: 0.68919846, Validation loss: 0.68737755, Gradient norm: 0.08943760
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3578.56640625MB
INFO:root:[    5] Training loss: 0.68768431, Validation loss: 0.68774393, Gradient norm: 0.09325933
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3616.48046875MB
INFO:root:[    6] Training loss: 0.68643021, Validation loss: 0.68506700, Gradient norm: 0.09143661
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3654.6953125MB
INFO:root:[    7] Training loss: 0.68547822, Validation loss: 0.68535403, Gradient norm: 0.09831121
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3693.4765625MB
INFO:root:[    8] Training loss: 0.68441433, Validation loss: 0.68362052, Gradient norm: 0.10163617
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3731.5859375MB
INFO:root:[    9] Training loss: 0.68332179, Validation loss: 0.68278444, Gradient norm: 0.09628998
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3769.75390625MB
INFO:root:[   10] Training loss: 0.68259930, Validation loss: 0.68166949, Gradient norm: 0.10502224
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3810.203125MB
INFO:root:[   11] Training loss: 0.68165776, Validation loss: 0.68031527, Gradient norm: 0.10491947
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3848.19140625MB
INFO:root:[   12] Training loss: 0.68087988, Validation loss: 0.68070347, Gradient norm: 0.11495929
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3886.46875MB
INFO:root:[   13] Training loss: 0.67990538, Validation loss: 0.67896797, Gradient norm: 0.11048164
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3924.55078125MB
INFO:root:[   14] Training loss: 0.67921444, Validation loss: 0.67817323, Gradient norm: 0.11841585
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=3963.01171875MB
INFO:root:[   15] Training loss: 0.67842253, Validation loss: 0.67772073, Gradient norm: 0.11332233
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4001.83984375MB
INFO:root:[   16] Training loss: 0.67782078, Validation loss: 0.67690177, Gradient norm: 0.11661246
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4039.81640625MB
INFO:root:[   17] Training loss: 0.67747319, Validation loss: 0.67671900, Gradient norm: 0.12467757
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4077.78125MB
INFO:root:[   18] Training loss: 0.67698609, Validation loss: 0.67604143, Gradient norm: 0.12166235
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4116.46484375MB
INFO:root:[   19] Training loss: 0.67652643, Validation loss: 0.67630407, Gradient norm: 0.12998757
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4154.83984375MB
INFO:root:[   20] Training loss: 0.67596463, Validation loss: 0.67554712, Gradient norm: 0.12277851
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4192.98828125MB
INFO:root:[   21] Training loss: 0.67542113, Validation loss: 0.67512268, Gradient norm: 0.12765113
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4231.390625MB
INFO:root:[   22] Training loss: 0.67531173, Validation loss: 0.67437640, Gradient norm: 0.13322309
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4268.91015625MB
INFO:root:[   23] Training loss: 0.67460593, Validation loss: 0.67393617, Gradient norm: 0.13317066
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4307.14453125MB
INFO:root:[   24] Training loss: 0.67435749, Validation loss: 0.67300848, Gradient norm: 0.13263082
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4345.8828125MB
INFO:root:[   25] Training loss: 0.67374156, Validation loss: 0.67310711, Gradient norm: 0.13218181
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4384.01171875MB
INFO:root:[   26] Training loss: 0.67357925, Validation loss: 0.67236721, Gradient norm: 0.13484295
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4422.23046875MB
INFO:root:[   27] Training loss: 0.67315723, Validation loss: 0.67253596, Gradient norm: 0.13218836
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4460.63671875MB
INFO:root:[   28] Training loss: 0.67308528, Validation loss: 0.67171625, Gradient norm: 0.14304932
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4499.14453125MB
INFO:root:[   29] Training loss: 0.67259608, Validation loss: 0.67173923, Gradient norm: 0.13620453
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4537.421875MB
INFO:root:[   30] Training loss: 0.67230875, Validation loss: 0.67126886, Gradient norm: 0.13649787
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4574.9296875MB
INFO:root:[   31] Training loss: 0.67214451, Validation loss: 0.67134158, Gradient norm: 0.13480098
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4612.640625MB
INFO:root:[   32] Training loss: 0.67206164, Validation loss: 0.67161431, Gradient norm: 0.14056607
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4650.5390625MB
INFO:root:[   33] Training loss: 0.67177746, Validation loss: 0.67095486, Gradient norm: 0.14121137
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4689.31640625MB
INFO:root:[   34] Training loss: 0.67148344, Validation loss: 0.67137604, Gradient norm: 0.14225436
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4727.53125MB
INFO:root:[   35] Training loss: 0.67139674, Validation loss: 0.67091230, Gradient norm: 0.13834239
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4766.2109375MB
INFO:root:[   36] Training loss: 0.67124231, Validation loss: 0.67134840, Gradient norm: 0.14105468
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4804.25390625MB
INFO:root:[   37] Training loss: 0.67115834, Validation loss: 0.67027606, Gradient norm: 0.13694933
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4842.26171875MB
INFO:root:[   38] Training loss: 0.67100615, Validation loss: 0.67020124, Gradient norm: 0.13765491
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4879.06640625MB
INFO:root:[   39] Training loss: 0.67084546, Validation loss: 0.66958017, Gradient norm: 0.13285559
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4917.19140625MB
INFO:root:[   40] Training loss: 0.67086936, Validation loss: 0.67024963, Gradient norm: 0.14820403
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4955.62890625MB
INFO:root:[   41] Training loss: 0.67066679, Validation loss: 0.67008738, Gradient norm: 0.14035715
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=4993.79296875MB
INFO:root:[   42] Training loss: 0.67058352, Validation loss: 0.66971219, Gradient norm: 0.14223589
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5031.6796875MB
INFO:root:[   43] Training loss: 0.67029565, Validation loss: 0.66932056, Gradient norm: 0.13761053
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5070.76953125MB
INFO:root:[   44] Training loss: 0.67038790, Validation loss: 0.66947898, Gradient norm: 0.14154771
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5108.5390625MB
INFO:root:[   45] Training loss: 0.67023384, Validation loss: 0.66961941, Gradient norm: 0.13804017
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5146.703125MB
INFO:root:[   46] Training loss: 0.67011821, Validation loss: 0.66970991, Gradient norm: 0.13661002
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5184.73828125MB
INFO:root:[   47] Training loss: 0.67017699, Validation loss: 0.66890998, Gradient norm: 0.14493288
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5223.16015625MB
INFO:root:[   48] Training loss: 0.66981684, Validation loss: 0.66933386, Gradient norm: 0.14882158
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5261.51953125MB
INFO:root:[   49] Training loss: 0.66970105, Validation loss: 0.66875691, Gradient norm: 0.13906082
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5300.2890625MB
INFO:root:[   50] Training loss: 0.66963220, Validation loss: 0.66855866, Gradient norm: 0.14485948
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5338.9921875MB
INFO:root:[   51] Training loss: 0.66955658, Validation loss: 0.66887048, Gradient norm: 0.14520181
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5378.03125MB
INFO:root:[   52] Training loss: 0.66930025, Validation loss: 0.66970957, Gradient norm: 0.15133451
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5416.171875MB
INFO:root:[   53] Training loss: 0.66910725, Validation loss: 0.66771668, Gradient norm: 0.14277916
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5454.4296875MB
INFO:root:[   54] Training loss: 0.66894978, Validation loss: 0.66844454, Gradient norm: 0.14525319
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5492.33984375MB
INFO:root:[   55] Training loss: 0.66885965, Validation loss: 0.66753737, Gradient norm: 0.14661890
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5530.8984375MB
INFO:root:[   56] Training loss: 0.66883097, Validation loss: 0.66784098, Gradient norm: 0.15516821
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5569.04296875MB
INFO:root:[   57] Training loss: 0.66842737, Validation loss: 0.66728749, Gradient norm: 0.15070240
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5607.34375MB
INFO:root:[   58] Training loss: 0.66839533, Validation loss: 0.66750433, Gradient norm: 0.16104286
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5645.7421875MB
INFO:root:[   59] Training loss: 0.66797369, Validation loss: 0.66602126, Gradient norm: 0.15130368
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5683.46875MB
INFO:root:[   60] Training loss: 0.66769227, Validation loss: 0.66682835, Gradient norm: 0.15341912
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5721.8125MB
INFO:root:[   61] Training loss: 0.66771316, Validation loss: 0.66614056, Gradient norm: 0.16030643
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5759.953125MB
INFO:root:[   62] Training loss: 0.66747555, Validation loss: 0.66649045, Gradient norm: 0.15993012
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5798.09765625MB
INFO:root:[   63] Training loss: 0.66736542, Validation loss: 0.66562663, Gradient norm: 0.16063854
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5836.51171875MB
INFO:root:[   64] Training loss: 0.66709669, Validation loss: 0.66627038, Gradient norm: 0.16723033
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5874.6484375MB
INFO:root:[   65] Training loss: 0.66692552, Validation loss: 0.66537381, Gradient norm: 0.15928901
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5912.7109375MB
INFO:root:[   66] Training loss: 0.66692226, Validation loss: 0.66560213, Gradient norm: 0.16878738
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5950.88671875MB
INFO:root:[   67] Training loss: 0.66654162, Validation loss: 0.66526074, Gradient norm: 0.15826908
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=5988.875MB
INFO:root:[   68] Training loss: 0.66670442, Validation loss: 0.66577361, Gradient norm: 0.16359914
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6027.265625MB
INFO:root:[   69] Training loss: 0.66628933, Validation loss: 0.66563502, Gradient norm: 0.15970929
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6065.40234375MB
INFO:root:[   70] Training loss: 0.66636136, Validation loss: 0.66589309, Gradient norm: 0.16758966
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6103.515625MB
INFO:root:[   71] Training loss: 0.66635824, Validation loss: 0.66549461, Gradient norm: 0.16734344
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6141.69140625MB
INFO:root:[   72] Training loss: 0.66609039, Validation loss: 0.66466484, Gradient norm: 0.16243472
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6180.30078125MB
INFO:root:[   73] Training loss: 0.66594486, Validation loss: 0.66451215, Gradient norm: 0.16429015
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6217.015625MB
INFO:root:[   74] Training loss: 0.66605069, Validation loss: 0.66493899, Gradient norm: 0.16128995
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6254.84765625MB
INFO:root:[   75] Training loss: 0.66562626, Validation loss: 0.66501529, Gradient norm: 0.15006468
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6293.23828125MB
INFO:root:[   76] Training loss: 0.66585102, Validation loss: 0.66517057, Gradient norm: 0.17435564
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6331.375MB
INFO:root:[   77] Training loss: 0.66567988, Validation loss: 0.66494140, Gradient norm: 0.15651707
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6369.51171875MB
INFO:root:[   78] Training loss: 0.66558052, Validation loss: 0.66411428, Gradient norm: 0.15986910
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6407.53125MB
INFO:root:[   79] Training loss: 0.66548366, Validation loss: 0.66422870, Gradient norm: 0.15932636
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6445.67578125MB
INFO:root:[   80] Training loss: 0.66532790, Validation loss: 0.66455786, Gradient norm: 0.16144496
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6483.8203125MB
INFO:root:[   81] Training loss: 0.66532321, Validation loss: 0.66414319, Gradient norm: 0.16158609
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6521.96484375MB
INFO:root:[   82] Training loss: 0.66513396, Validation loss: 0.66497487, Gradient norm: 0.16153424
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6559.125MB
INFO:root:[   83] Training loss: 0.66520210, Validation loss: 0.66387522, Gradient norm: 0.15212521
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6598.546875MB
INFO:root:[   84] Training loss: 0.66498504, Validation loss: 0.66399264, Gradient norm: 0.16450133
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6636.47265625MB
INFO:root:[   85] Training loss: 0.66508597, Validation loss: 0.66403050, Gradient norm: 0.15938410
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6674.6640625MB
INFO:root:[   86] Training loss: 0.66498540, Validation loss: 0.66320150, Gradient norm: 0.16397490
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6712.96875MB
INFO:root:[   87] Training loss: 0.66499073, Validation loss: 0.66399328, Gradient norm: 0.17135435
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6751.12890625MB
INFO:root:[   88] Training loss: 0.66473423, Validation loss: 0.66361430, Gradient norm: 0.15558422
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6789.29296875MB
INFO:root:[   89] Training loss: 0.66474345, Validation loss: 0.66347341, Gradient norm: 0.16345622
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6827.71875MB
INFO:root:[   90] Training loss: 0.66462282, Validation loss: 0.66419083, Gradient norm: 0.16014802
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6865.45703125MB
INFO:root:[   91] Training loss: 0.66468458, Validation loss: 0.66335128, Gradient norm: 0.16577140
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6903.8671875MB
INFO:root:[   92] Training loss: 0.66438646, Validation loss: 0.66371055, Gradient norm: 0.15619231
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6941.78515625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   93] Training loss: 0.66455504, Validation loss: 0.66384220, Gradient norm: 0.17285941
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=6980.05859375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   94] Training loss: 0.66337360, Validation loss: 0.66252690, Gradient norm: 0.13535153
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7018.57421875MB
INFO:root:[   95] Training loss: 0.66280090, Validation loss: 0.66192782, Gradient norm: 0.12440653
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7056.86328125MB
INFO:root:[   96] Training loss: 0.66278874, Validation loss: 0.66189003, Gradient norm: 0.12562357
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7094.953125MB
INFO:root:[   97] Training loss: 0.66273220, Validation loss: 0.66251561, Gradient norm: 0.13253448
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7133.39453125MB
INFO:root:[   98] Training loss: 0.66275599, Validation loss: 0.66211236, Gradient norm: 0.13942855
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7171.09375MB
INFO:root:[   99] Training loss: 0.66266044, Validation loss: 0.66248259, Gradient norm: 0.13583181
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7209.0078125MB
INFO:root:[  100] Training loss: 0.66250310, Validation loss: 0.66211153, Gradient norm: 0.13738727
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7246.92578125MB
INFO:root:[  101] Training loss: 0.66258553, Validation loss: 0.66200745, Gradient norm: 0.13318483
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7285.3359375MB
INFO:root:[  102] Training loss: 0.66261846, Validation loss: 0.66166464, Gradient norm: 0.14751020
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7323.828125MB
INFO:root:[  103] Training loss: 0.66247042, Validation loss: 0.66177294, Gradient norm: 0.14387519
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7362.20703125MB
INFO:root:[  104] Training loss: 0.66257437, Validation loss: 0.66225197, Gradient norm: 0.13980949
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7400.37109375MB
INFO:root:[  105] Training loss: 0.66245291, Validation loss: 0.66170387, Gradient norm: 0.13622901
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7438.53515625MB
INFO:root:[  106] Training loss: 0.66239374, Validation loss: 0.66143086, Gradient norm: 0.13915244
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7476.6328125MB
INFO:root:[  107] Training loss: 0.66243615, Validation loss: 0.66172266, Gradient norm: 0.13847724
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7515.04296875MB
INFO:root:[  108] Training loss: 0.66231011, Validation loss: 0.66160898, Gradient norm: 0.13924148
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7553.20703125MB
INFO:root:[  109] Training loss: 0.66242210, Validation loss: 0.66195060, Gradient norm: 0.15023437
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7591.36328125MB
INFO:root:[  110] Training loss: 0.66235832, Validation loss: 0.66188632, Gradient norm: 0.14209848
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7629.61328125MB
INFO:root:[  111] Training loss: 0.66234977, Validation loss: 0.66150617, Gradient norm: 0.14346982
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7667.7265625MB
INFO:root:[  112] Training loss: 0.66241971, Validation loss: 0.66113864, Gradient norm: 0.15259256
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7705.92578125MB
INFO:root:[  113] Training loss: 0.66232761, Validation loss: 0.66169227, Gradient norm: 0.14459334
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7744.2578125MB
INFO:root:[  114] Training loss: 0.66228953, Validation loss: 0.66162000, Gradient norm: 0.14862237
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7782.15625MB
INFO:root:[  115] Training loss: 0.66231712, Validation loss: 0.66156390, Gradient norm: 0.14531207
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7820.30078125MB
INFO:root:[  116] Training loss: 0.66225260, Validation loss: 0.66190129, Gradient norm: 0.14406486
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7858.04296875MB
INFO:root:[  117] Training loss: 0.66218887, Validation loss: 0.66197317, Gradient norm: 0.14506737
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7896.43359375MB
INFO:root:[  118] Training loss: 0.66229843, Validation loss: 0.66156982, Gradient norm: 0.13912747
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7934.5703125MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  119] Training loss: 0.66215243, Validation loss: 0.66137285, Gradient norm: 0.14611248
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=7972.40625MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  120] Training loss: 0.66179165, Validation loss: 0.66131193, Gradient norm: 0.13647472
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8010.7890625MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  121] Training loss: 0.66180361, Validation loss: 0.66094218, Gradient norm: 0.13149171
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8049.078125MB
INFO:root:[  122] Training loss: 0.66151813, Validation loss: 0.66152020, Gradient norm: 0.12380879
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8087.25390625MB
INFO:root:[  123] Training loss: 0.66147618, Validation loss: 0.66106798, Gradient norm: 0.12954518
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8125.4296875MB
INFO:root:[  124] Training loss: 0.66167331, Validation loss: 0.66094438, Gradient norm: 0.12499806
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8163.55078125MB
INFO:root:[  125] Training loss: 0.66158043, Validation loss: 0.66127960, Gradient norm: 0.13128521
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8201.6953125MB
INFO:root:[  126] Training loss: 0.66143525, Validation loss: 0.66120844, Gradient norm: 0.12825704
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8239.83984375MB
INFO:root:[  127] Training loss: 0.66156028, Validation loss: 0.66093069, Gradient norm: 0.13671815
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8276.94140625MB
INFO:root:[  128] Training loss: 0.66146062, Validation loss: 0.66110460, Gradient norm: 0.12662352
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8315.33203125MB
INFO:root:[  129] Training loss: 0.66161224, Validation loss: 0.66096504, Gradient norm: 0.13093080
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8353.0703125MB
INFO:root:[  130] Training loss: 0.66138336, Validation loss: 0.66118537, Gradient norm: 0.13003342
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8391.453125MB
INFO:root:[  131] Training loss: 0.66154298, Validation loss: 0.66150596, Gradient norm: 0.13212459
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8429.59765625MB
INFO:root:[  132] Training loss: 0.66152728, Validation loss: 0.66092753, Gradient norm: 0.13249740
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8467.546875MB
INFO:root:[  133] Training loss: 0.66153006, Validation loss: 0.66086388, Gradient norm: 0.13324833
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8506.0MB
INFO:root:[  134] Training loss: 0.66134765, Validation loss: 0.66123038, Gradient norm: 0.13272116
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8544.1328125MB
INFO:root:[  135] Training loss: 0.66151049, Validation loss: 0.66102779, Gradient norm: 0.13565215
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8582.30078125MB
INFO:root:[  136] Training loss: 0.66161422, Validation loss: 0.66107340, Gradient norm: 0.12607427
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8620.19140625MB
INFO:root:[  137] Training loss: 0.66148366, Validation loss: 0.66136775, Gradient norm: 0.13131278
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8658.3359375MB
INFO:root:[  138] Training loss: 0.66152298, Validation loss: 0.66096017, Gradient norm: 0.12947442
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8696.7265625MB
INFO:root:[  139] Training loss: 0.66135951, Validation loss: 0.66116251, Gradient norm: 0.13222875
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8734.87109375MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  140] Training loss: 0.66140438, Validation loss: 0.66085672, Gradient norm: 0.13327741
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8772.8828125MB
INFO:root:[  141] Training loss: 0.66143647, Validation loss: 0.66125482, Gradient norm: 0.13514809
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8811.3359375MB
INFO:root:[  142] Training loss: 0.66131591, Validation loss: 0.66072959, Gradient norm: 0.13102860
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8849.234375MB
INFO:root:[  143] Training loss: 0.66135748, Validation loss: 0.66102912, Gradient norm: 0.12947568
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8887.625MB
INFO:root:[  144] Training loss: 0.66133186, Validation loss: 0.66122139, Gradient norm: 0.13083419
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8925.76953125MB
INFO:root:[  145] Training loss: 0.66140377, Validation loss: 0.66097880, Gradient norm: 0.12915884
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=8963.9140625MB
INFO:root:[  146] Training loss: 0.66150931, Validation loss: 0.66112861, Gradient norm: 0.13178061
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9002.05078125MB
INFO:root:[  147] Training loss: 0.66128636, Validation loss: 0.66085395, Gradient norm: 0.13229112
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9040.3046875MB
INFO:root:[  148] Training loss: 0.66135972, Validation loss: 0.66121273, Gradient norm: 0.13340432
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9078.47265625MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  149] Training loss: 0.66140596, Validation loss: 0.66139829, Gradient norm: 0.12852810
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9116.6171875MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  150] Training loss: 0.66147654, Validation loss: 0.66097098, Gradient norm: 0.13254308
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9155.0078125MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  151] Training loss: 0.66137858, Validation loss: 0.66108151, Gradient norm: 0.13111157
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9192.90625MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:EP 151: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12459.2265625MB; mem (CPU total)=9231.046875MB
INFO:root:Training the model took 7232.167s.
INFO:root:Emptying the cuda cache took 0.012s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93515
INFO:root:EnergyScoreTrain: 0.65814
INFO:root:CRPSTrain: 0.52917
INFO:root:Gaussian NLLTrain: 1.84689
INFO:root:CoverageTrain: 0.90865
INFO:root:IntervalWidthTrain: 3.37167
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93926
INFO:root:EnergyScoreValidation: 0.66107
INFO:root:CRPSValidation: 0.53173
INFO:root:Gaussian NLLValidation: 1.861
INFO:root:CoverageValidation: 0.90821
INFO:root:IntervalWidthValidation: 3.37623
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93884
INFO:root:EnergyScoreTest: 0.66077
INFO:root:CRPSTest: 0.53173
INFO:root:Gaussian NLLTest: 1.86693
INFO:root:CoverageTest: 0.90735
INFO:root:IntervalWidthTest: 3.37367
INFO:root:After validation: mem (CPU python)=12459.2265625MB; mem (CPU total)=9318.609375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12459.2265625MB; mem (CPU total)=9318.359375MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 174063616
INFO:root:After setting up the model: mem (CPU python)=12459.2265625MB; mem (CPU total)=9318.05078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9318.05078125MB
INFO:root:[    1] Training loss: 0.71360731, Validation loss: 0.70349196, Gradient norm: 0.04402096
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9356.2421875MB
INFO:root:[    2] Training loss: 0.69829623, Validation loss: 0.69446874, Gradient norm: 0.06332225
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9394.41015625MB
INFO:root:[    3] Training loss: 0.69223536, Validation loss: 0.69001814, Gradient norm: 0.07824617
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9432.6328125MB
INFO:root:[    4] Training loss: 0.68916053, Validation loss: 0.68829132, Gradient norm: 0.07901748
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9469.78125MB
INFO:root:[    5] Training loss: 0.68730762, Validation loss: 0.68640844, Gradient norm: 0.08136372
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9508.22265625MB
INFO:root:[    6] Training loss: 0.68586468, Validation loss: 0.68539003, Gradient norm: 0.08474059
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9545.87109375MB
INFO:root:[    7] Training loss: 0.68500725, Validation loss: 0.68369114, Gradient norm: 0.08844109
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9583.97265625MB
INFO:root:[    8] Training loss: 0.68412418, Validation loss: 0.68316261, Gradient norm: 0.08652144
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9622.0703125MB
INFO:root:[    9] Training loss: 0.68341673, Validation loss: 0.68274932, Gradient norm: 0.08637073
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9660.41796875MB
INFO:root:[   10] Training loss: 0.68260123, Validation loss: 0.68254231, Gradient norm: 0.09285116
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9698.4609375MB
INFO:root:[   11] Training loss: 0.68192836, Validation loss: 0.68081998, Gradient norm: 0.08989526
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9735.6015625MB
INFO:root:[   12] Training loss: 0.68103405, Validation loss: 0.68002778, Gradient norm: 0.09539615
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9773.75MB
INFO:root:[   13] Training loss: 0.68023773, Validation loss: 0.67894259, Gradient norm: 0.09699194
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9811.4765625MB
INFO:root:[   14] Training loss: 0.67920633, Validation loss: 0.67895719, Gradient norm: 0.10224825
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9849.88671875MB
INFO:root:[   15] Training loss: 0.67858788, Validation loss: 0.67770803, Gradient norm: 0.11018309
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9887.89453125MB
INFO:root:[   16] Training loss: 0.67788297, Validation loss: 0.67701098, Gradient norm: 0.10823380
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9924.64453125MB
INFO:root:[   17] Training loss: 0.67739202, Validation loss: 0.67659089, Gradient norm: 0.11631196
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=9962.83984375MB
INFO:root:[   18] Training loss: 0.67680783, Validation loss: 0.67590178, Gradient norm: 0.11664228
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10000.7265625MB
INFO:root:[   19] Training loss: 0.67648091, Validation loss: 0.67534881, Gradient norm: 0.12432241
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10039.24609375MB
INFO:root:[   20] Training loss: 0.67603957, Validation loss: 0.67482169, Gradient norm: 0.12005914
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10077.59765625MB
INFO:root:[   21] Training loss: 0.67548466, Validation loss: 0.67520869, Gradient norm: 0.12202359
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10115.73046875MB
INFO:root:[   22] Training loss: 0.67500660, Validation loss: 0.67404236, Gradient norm: 0.12012902
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10154.03515625MB
INFO:root:[   23] Training loss: 0.67467283, Validation loss: 0.67368391, Gradient norm: 0.12926765
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10192.296875MB
INFO:root:[   24] Training loss: 0.67433624, Validation loss: 0.67366254, Gradient norm: 0.12489306
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10230.92578125MB
INFO:root:[   25] Training loss: 0.67368092, Validation loss: 0.67308837, Gradient norm: 0.12455521
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10269.29296875MB
INFO:root:[   26] Training loss: 0.67353428, Validation loss: 0.67235735, Gradient norm: 0.13075456
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10307.40625MB
INFO:root:[   27] Training loss: 0.67301929, Validation loss: 0.67210894, Gradient norm: 0.13210352
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10345.5MB
INFO:root:[   28] Training loss: 0.67305036, Validation loss: 0.67245849, Gradient norm: 0.14023382
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10383.60546875MB
INFO:root:[   29] Training loss: 0.67255803, Validation loss: 0.67163727, Gradient norm: 0.12939946
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10421.90625MB
INFO:root:[   30] Training loss: 0.67239242, Validation loss: 0.67135733, Gradient norm: 0.13588953
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10459.82421875MB
INFO:root:[   31] Training loss: 0.67194342, Validation loss: 0.67116702, Gradient norm: 0.13252635
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10497.55859375MB
INFO:root:[   32] Training loss: 0.67180827, Validation loss: 0.67112294, Gradient norm: 0.13475693
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10536.19921875MB
INFO:root:[   33] Training loss: 0.67163399, Validation loss: 0.67105450, Gradient norm: 0.13541531
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10573.99609375MB
INFO:root:[   34] Training loss: 0.67136819, Validation loss: 0.67048765, Gradient norm: 0.13678442
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10612.4375MB
INFO:root:[   35] Training loss: 0.67113040, Validation loss: 0.66999629, Gradient norm: 0.13458968
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10650.75MB
INFO:root:[   36] Training loss: 0.67084992, Validation loss: 0.66961205, Gradient norm: 0.13353399
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10689.0078125MB
INFO:root:[   37] Training loss: 0.67075908, Validation loss: 0.66959797, Gradient norm: 0.14238852
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10727.421875MB
INFO:root:[   38] Training loss: 0.67055476, Validation loss: 0.66925677, Gradient norm: 0.14905193
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10765.6953125MB
INFO:root:[   39] Training loss: 0.67022746, Validation loss: 0.66923138, Gradient norm: 0.13966824
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10803.8671875MB
INFO:root:[   40] Training loss: 0.67011527, Validation loss: 0.66962603, Gradient norm: 0.14027958
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10842.2421875MB
INFO:root:[   41] Training loss: 0.67005978, Validation loss: 0.66856643, Gradient norm: 0.14171379
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10879.87890625MB
INFO:root:[   42] Training loss: 0.66981352, Validation loss: 0.66856098, Gradient norm: 0.14659755
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10917.8359375MB
INFO:root:[   43] Training loss: 0.66935552, Validation loss: 0.66846765, Gradient norm: 0.14431137
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10956.1328125MB
INFO:root:[   44] Training loss: 0.66960681, Validation loss: 0.66831604, Gradient norm: 0.16082952
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=10994.578125MB
INFO:root:[   45] Training loss: 0.66937831, Validation loss: 0.66819293, Gradient norm: 0.15243276
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11032.78515625MB
INFO:root:[   46] Training loss: 0.66918815, Validation loss: 0.66765596, Gradient norm: 0.14409561
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11070.99609375MB
INFO:root:[   47] Training loss: 0.66890250, Validation loss: 0.66810669, Gradient norm: 0.15032443
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11108.40234375MB
INFO:root:[   48] Training loss: 0.66890842, Validation loss: 0.66773123, Gradient norm: 0.15438925
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11146.24609375MB
INFO:root:[   49] Training loss: 0.66851770, Validation loss: 0.66765082, Gradient norm: 0.14506043
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11184.54296875MB
INFO:root:[   50] Training loss: 0.66862987, Validation loss: 0.66844156, Gradient norm: 0.16109828
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11222.9375MB
INFO:root:[   51] Training loss: 0.66825795, Validation loss: 0.66768114, Gradient norm: 0.15000440
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11260.87890625MB
INFO:root:[   52] Training loss: 0.66829959, Validation loss: 0.66733188, Gradient norm: 0.16407907
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11299.01953125MB
INFO:root:[   53] Training loss: 0.66812302, Validation loss: 0.66673909, Gradient norm: 0.15131347
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11336.86328125MB
INFO:root:[   54] Training loss: 0.66797269, Validation loss: 0.66648983, Gradient norm: 0.15011398
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11375.0234375MB
INFO:root:[   55] Training loss: 0.66789411, Validation loss: 0.66648236, Gradient norm: 0.17048144
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11413.19921875MB
INFO:root:[   56] Training loss: 0.66774624, Validation loss: 0.66648749, Gradient norm: 0.16184447
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11451.3359375MB
INFO:root:[   57] Training loss: 0.66755575, Validation loss: 0.66656687, Gradient norm: 0.15408900
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11489.51171875MB
INFO:root:[   58] Training loss: 0.66738619, Validation loss: 0.66625140, Gradient norm: 0.15688345
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11527.93359375MB
INFO:root:[   59] Training loss: 0.66716797, Validation loss: 0.66577120, Gradient norm: 0.16735182
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11566.15625MB
INFO:root:[   60] Training loss: 0.66708677, Validation loss: 0.66569323, Gradient norm: 0.16377545
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11604.58984375MB
INFO:root:[   61] Training loss: 0.66680684, Validation loss: 0.66516649, Gradient norm: 0.16666406
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11642.75390625MB
INFO:root:[   62] Training loss: 0.66678224, Validation loss: 0.66512827, Gradient norm: 0.17191314
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11681.17578125MB
INFO:root:[   63] Training loss: 0.66668415, Validation loss: 0.66499557, Gradient norm: 0.17140763
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11719.375MB
INFO:root:[   64] Training loss: 0.66646879, Validation loss: 0.66485468, Gradient norm: 0.17036700
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11757.828125MB
INFO:root:[   65] Training loss: 0.66616110, Validation loss: 0.66456556, Gradient norm: 0.16915452
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11796.05078125MB
INFO:root:[   66] Training loss: 0.66591033, Validation loss: 0.66422137, Gradient norm: 0.17004404
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11834.2421875MB
INFO:root:[   67] Training loss: 0.66565584, Validation loss: 0.66433845, Gradient norm: 0.16378417
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11872.109375MB
INFO:root:[   68] Training loss: 0.66547424, Validation loss: 0.66456943, Gradient norm: 0.16669860
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11910.22265625MB
INFO:root:[   69] Training loss: 0.66535096, Validation loss: 0.66382525, Gradient norm: 0.16770033
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11949.01171875MB
INFO:root:[   70] Training loss: 0.66501374, Validation loss: 0.66391550, Gradient norm: 0.16381869
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=11987.43359375MB
INFO:root:[   71] Training loss: 0.66508933, Validation loss: 0.66408349, Gradient norm: 0.16540101
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=12025.3125MB
INFO:root:[   72] Training loss: 0.66473394, Validation loss: 0.66438180, Gradient norm: 0.16920846
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=12063.8828125MB
INFO:root:[   73] Training loss: 0.66446271, Validation loss: 0.66289213, Gradient norm: 0.16304812
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=12102.47265625MB
INFO:root:[   74] Training loss: 0.66446687, Validation loss: 0.66289825, Gradient norm: 0.17079356
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=12140.81640625MB
INFO:root:[   75] Training loss: 0.66431384, Validation loss: 0.66282080, Gradient norm: 0.17541502
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=12179.2109375MB
INFO:root:[   76] Training loss: 0.66416313, Validation loss: 0.66300291, Gradient norm: 0.16722969
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=12216.82421875MB
INFO:root:[   77] Training loss: 0.66407608, Validation loss: 0.66288248, Gradient norm: 0.17227887
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=12254.79296875MB
INFO:root:[   78] Training loss: 0.66402779, Validation loss: 0.66293141, Gradient norm: 0.17578660
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=12293.375MB
INFO:root:[   79] Training loss: 0.66383809, Validation loss: 0.66292053, Gradient norm: 0.17346445
INFO:root:At the start of the epoch: mem (CPU python)=12459.2265625MB; mem (CPU total)=12333.1953125MB
INFO:root:[   80] Training loss: 0.66352776, Validation loss: 0.66236386, Gradient norm: 0.16239497
INFO:root:At the start of the epoch: mem (CPU python)=12489.49609375MB; mem (CPU total)=12371.0703125MB
INFO:root:[   81] Training loss: 0.66361351, Validation loss: 0.66183597, Gradient norm: 0.16238501
INFO:root:At the start of the epoch: mem (CPU python)=12527.58984375MB; mem (CPU total)=12408.734375MB
INFO:root:[   82] Training loss: 0.66342905, Validation loss: 0.66275496, Gradient norm: 0.17078906
INFO:root:At the start of the epoch: mem (CPU python)=12565.6796875MB; mem (CPU total)=12447.1171875MB
INFO:root:[   83] Training loss: 0.66338857, Validation loss: 0.66224586, Gradient norm: 0.17155482
INFO:root:At the start of the epoch: mem (CPU python)=12603.77734375MB; mem (CPU total)=12485.30078125MB
INFO:root:[   84] Training loss: 0.66335319, Validation loss: 0.66217099, Gradient norm: 0.16722947
INFO:root:At the start of the epoch: mem (CPU python)=12641.87109375MB; mem (CPU total)=12523.31640625MB
INFO:root:[   85] Training loss: 0.66339797, Validation loss: 0.66134624, Gradient norm: 0.16737121
INFO:root:At the start of the epoch: mem (CPU python)=12679.96875MB; mem (CPU total)=12561.3359375MB
INFO:root:[   86] Training loss: 0.66293706, Validation loss: 0.66180349, Gradient norm: 0.16372830
INFO:root:At the start of the epoch: mem (CPU python)=12718.0625MB; mem (CPU total)=12599.7265625MB
INFO:root:[   87] Training loss: 0.66315556, Validation loss: 0.66146408, Gradient norm: 0.16818242
INFO:root:At the start of the epoch: mem (CPU python)=12756.16015625MB; mem (CPU total)=12637.83984375MB
INFO:root:[   88] Training loss: 0.66302291, Validation loss: 0.66186881, Gradient norm: 0.17973453
INFO:root:At the start of the epoch: mem (CPU python)=12794.25390625MB; mem (CPU total)=12675.984375MB
INFO:root:[   89] Training loss: 0.66259608, Validation loss: 0.66231704, Gradient norm: 0.15921106
INFO:root:At the start of the epoch: mem (CPU python)=12832.34765625MB; mem (CPU total)=12714.125MB
INFO:root:[   90] Training loss: 0.66262925, Validation loss: 0.66227509, Gradient norm: 0.16476060
INFO:root:At the start of the epoch: mem (CPU python)=12870.4453125MB; mem (CPU total)=12752.26953125MB
INFO:root:[   91] Training loss: 0.66260275, Validation loss: 0.66161049, Gradient norm: 0.16815650
INFO:root:At the start of the epoch: mem (CPU python)=12908.5390625MB; mem (CPU total)=12790.3515625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   92] Training loss: 0.66243131, Validation loss: 0.66141569, Gradient norm: 0.16677808
INFO:root:At the start of the epoch: mem (CPU python)=12946.6328125MB; mem (CPU total)=12828.49609375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   93] Training loss: 0.66126436, Validation loss: 0.66050453, Gradient norm: 0.14236162
INFO:root:At the start of the epoch: mem (CPU python)=12984.734375MB; mem (CPU total)=12866.6953125MB
INFO:root:[   94] Training loss: 0.66069126, Validation loss: 0.66019616, Gradient norm: 0.13893760
INFO:root:At the start of the epoch: mem (CPU python)=13022.828125MB; mem (CPU total)=12902.87109375MB
INFO:root:[   95] Training loss: 0.66073279, Validation loss: 0.65995829, Gradient norm: 0.13885456
INFO:root:At the start of the epoch: mem (CPU python)=13060.921875MB; mem (CPU total)=12941.328125MB
INFO:root:[   96] Training loss: 0.66059344, Validation loss: 0.66005794, Gradient norm: 0.13644961
INFO:root:At the start of the epoch: mem (CPU python)=13099.01953125MB; mem (CPU total)=12979.265625MB
INFO:root:[   97] Training loss: 0.66053538, Validation loss: 0.65994246, Gradient norm: 0.14763790
INFO:root:At the start of the epoch: mem (CPU python)=13137.11328125MB; mem (CPU total)=13017.3046875MB
INFO:root:[   98] Training loss: 0.66056156, Validation loss: 0.65947061, Gradient norm: 0.14516319
INFO:root:At the start of the epoch: mem (CPU python)=13175.20703125MB; mem (CPU total)=13055.62109375MB
INFO:root:[   99] Training loss: 0.66058724, Validation loss: 0.65955748, Gradient norm: 0.15042575
INFO:root:At the start of the epoch: mem (CPU python)=13213.30078125MB; mem (CPU total)=13093.703125MB
INFO:root:[  100] Training loss: 0.66050862, Validation loss: 0.65993847, Gradient norm: 0.13992273
INFO:root:At the start of the epoch: mem (CPU python)=13251.3984375MB; mem (CPU total)=13131.6015625MB
INFO:root:[  101] Training loss: 0.66046590, Validation loss: 0.65985223, Gradient norm: 0.15299809
INFO:root:At the start of the epoch: mem (CPU python)=13289.4921875MB; mem (CPU total)=13169.73828125MB
INFO:root:[  102] Training loss: 0.66029204, Validation loss: 0.65932659, Gradient norm: 0.14705720
INFO:root:At the start of the epoch: mem (CPU python)=13327.58984375MB; mem (CPU total)=13208.21875MB
INFO:root:[  103] Training loss: 0.66035293, Validation loss: 0.65985503, Gradient norm: 0.14608509
INFO:root:At the start of the epoch: mem (CPU python)=13365.68359375MB; mem (CPU total)=13246.85546875MB
INFO:root:[  104] Training loss: 0.66045493, Validation loss: 0.65964474, Gradient norm: 0.14883431
INFO:root:At the start of the epoch: mem (CPU python)=13403.78125MB; mem (CPU total)=13284.9921875MB
INFO:root:[  105] Training loss: 0.66036423, Validation loss: 0.65966609, Gradient norm: 0.14256074
INFO:root:At the start of the epoch: mem (CPU python)=13441.875MB; mem (CPU total)=13322.65234375MB
INFO:root:[  106] Training loss: 0.66032577, Validation loss: 0.65943453, Gradient norm: 0.15263840
INFO:root:At the start of the epoch: mem (CPU python)=13479.96875MB; mem (CPU total)=13360.7890625MB
INFO:root:[  107] Training loss: 0.66015270, Validation loss: 0.65950162, Gradient norm: 0.14889364
INFO:root:At the start of the epoch: mem (CPU python)=13518.06640625MB; mem (CPU total)=13399.1796875MB
INFO:root:[  108] Training loss: 0.66025948, Validation loss: 0.65943552, Gradient norm: 0.14239008
INFO:root:At the start of the epoch: mem (CPU python)=13556.1640625MB; mem (CPU total)=13436.89453125MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  109] Training loss: 0.66020464, Validation loss: 0.65892970, Gradient norm: 0.14945923
INFO:root:At the start of the epoch: mem (CPU python)=13594.26171875MB; mem (CPU total)=13475.359375MB
INFO:root:[  110] Training loss: 0.65989519, Validation loss: 0.65917085, Gradient norm: 0.13530411
INFO:root:At the start of the epoch: mem (CPU python)=13632.35546875MB; mem (CPU total)=13514.00390625MB
INFO:root:[  111] Training loss: 0.65979456, Validation loss: 0.65900814, Gradient norm: 0.13721132
INFO:root:At the start of the epoch: mem (CPU python)=13670.44921875MB; mem (CPU total)=13552.51953125MB
INFO:root:[  112] Training loss: 0.65962993, Validation loss: 0.65931560, Gradient norm: 0.14484032
INFO:root:At the start of the epoch: mem (CPU python)=13708.54296875MB; mem (CPU total)=13590.71484375MB
INFO:root:[  113] Training loss: 0.65975276, Validation loss: 0.65936872, Gradient norm: 0.13841257
INFO:root:At the start of the epoch: mem (CPU python)=13746.64453125MB; mem (CPU total)=13629.12890625MB
INFO:root:[  114] Training loss: 0.65972116, Validation loss: 0.65914859, Gradient norm: 0.14049515
INFO:root:At the start of the epoch: mem (CPU python)=13784.73828125MB; mem (CPU total)=13667.29296875MB
INFO:root:[  115] Training loss: 0.65977656, Validation loss: 0.65871985, Gradient norm: 0.13840829
INFO:root:At the start of the epoch: mem (CPU python)=13822.8359375MB; mem (CPU total)=13705.41796875MB
INFO:root:[  116] Training loss: 0.65970892, Validation loss: 0.65910667, Gradient norm: 0.13824491
INFO:root:At the start of the epoch: mem (CPU python)=13860.92578125MB; mem (CPU total)=13743.69140625MB
INFO:root:[  117] Training loss: 0.65974757, Validation loss: 0.65936520, Gradient norm: 0.14278462
INFO:root:At the start of the epoch: mem (CPU python)=13899.0234375MB; mem (CPU total)=13781.6328125MB
INFO:root:[  118] Training loss: 0.65966211, Validation loss: 0.65893935, Gradient norm: 0.14494104
INFO:root:At the start of the epoch: mem (CPU python)=13937.1171875MB; mem (CPU total)=13820.19140625MB
INFO:root:[  119] Training loss: 0.65966161, Validation loss: 0.65896621, Gradient norm: 0.14327519
INFO:root:At the start of the epoch: mem (CPU python)=13975.2109375MB; mem (CPU total)=13858.2109375MB
INFO:root:[  120] Training loss: 0.65967945, Validation loss: 0.65961013, Gradient norm: 0.15105374
INFO:root:At the start of the epoch: mem (CPU python)=14013.3125MB; mem (CPU total)=13896.15625MB
INFO:root:[  121] Training loss: 0.65966048, Validation loss: 0.65913044, Gradient norm: 0.14681209
INFO:root:At the start of the epoch: mem (CPU python)=14051.41015625MB; mem (CPU total)=13934.2265625MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  122] Training loss: 0.65957090, Validation loss: 0.65914747, Gradient norm: 0.14397590
INFO:root:At the start of the epoch: mem (CPU python)=14089.50390625MB; mem (CPU total)=13972.640625MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  123] Training loss: 0.65941945, Validation loss: 0.65925833, Gradient norm: 0.13539813
INFO:root:At the start of the epoch: mem (CPU python)=14127.59765625MB; mem (CPU total)=14010.80859375MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  124] Training loss: 0.65939285, Validation loss: 0.65924224, Gradient norm: 0.13678490
INFO:root:At the start of the epoch: mem (CPU python)=14165.6953125MB; mem (CPU total)=14048.97265625MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:EP 124: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=14203.65234375MB; mem (CPU total)=14087.1328125MB
INFO:root:Training the model took 6765.967s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93193
INFO:root:EnergyScoreTrain: 0.65589
INFO:root:CRPSTrain: 0.53172
INFO:root:Gaussian NLLTrain: 1.51845
INFO:root:CoverageTrain: 0.91392
INFO:root:IntervalWidthTrain: 3.43068
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93637
INFO:root:EnergyScoreValidation: 0.65906
INFO:root:CRPSValidation: 0.53443
INFO:root:Gaussian NLLValidation: 1.49068
INFO:root:CoverageValidation: 0.91305
INFO:root:IntervalWidthValidation: 3.4332
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.9357
INFO:root:EnergyScoreTest: 0.65857
INFO:root:CRPSTest: 0.53417
INFO:root:Gaussian NLLTest: 1.52614
INFO:root:CoverageTest: 0.91272
INFO:root:IntervalWidthTest: 3.43207
INFO:root:After validation: mem (CPU python)=14248.3203125MB; mem (CPU total)=14131.75390625MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=14248.3203125MB; mem (CPU total)=14131.79296875MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 297795584
INFO:root:After setting up the model: mem (CPU python)=14248.35546875MB; mem (CPU total)=14087.00390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=14248.35546875MB; mem (CPU total)=14086.8046875MB
INFO:root:[    1] Training loss: 0.71293563, Validation loss: 0.70242547, Gradient norm: 0.03917157
INFO:root:At the start of the epoch: mem (CPU python)=14248.35546875MB; mem (CPU total)=14127.95703125MB
INFO:root:[    2] Training loss: 0.69666547, Validation loss: 0.69179019, Gradient norm: 0.06142974
INFO:root:At the start of the epoch: mem (CPU python)=14281.546875MB; mem (CPU total)=14166.546875MB
INFO:root:[    3] Training loss: 0.69054948, Validation loss: 0.68868864, Gradient norm: 0.08431775
INFO:root:At the start of the epoch: mem (CPU python)=14319.64453125MB; mem (CPU total)=14204.0859375MB
INFO:root:[    4] Training loss: 0.68816664, Validation loss: 0.68667339, Gradient norm: 0.08275607
INFO:root:At the start of the epoch: mem (CPU python)=14357.76953125MB; mem (CPU total)=14242.49609375MB
INFO:root:[    5] Training loss: 0.68648439, Validation loss: 0.68563019, Gradient norm: 0.08483597
INFO:root:At the start of the epoch: mem (CPU python)=14395.8671875MB; mem (CPU total)=14280.62890625MB
INFO:root:[    6] Training loss: 0.68536847, Validation loss: 0.68487164, Gradient norm: 0.09128606
INFO:root:At the start of the epoch: mem (CPU python)=14433.9765625MB; mem (CPU total)=14318.9140625MB
INFO:root:[    7] Training loss: 0.68412004, Validation loss: 0.68425316, Gradient norm: 0.09381747
INFO:root:At the start of the epoch: mem (CPU python)=14472.1015625MB; mem (CPU total)=14357.34375MB
INFO:root:[    8] Training loss: 0.68338328, Validation loss: 0.68210673, Gradient norm: 0.09103524
INFO:root:At the start of the epoch: mem (CPU python)=14510.19921875MB; mem (CPU total)=14395.50390625MB
INFO:root:[    9] Training loss: 0.68270671, Validation loss: 0.68197048, Gradient norm: 0.09379302
INFO:root:At the start of the epoch: mem (CPU python)=14548.30859375MB; mem (CPU total)=14433.97265625MB
INFO:root:[   10] Training loss: 0.68153671, Validation loss: 0.68140844, Gradient norm: 0.09409408
INFO:root:At the start of the epoch: mem (CPU python)=14586.41015625MB; mem (CPU total)=14472.05859375MB
INFO:root:[   11] Training loss: 0.68119582, Validation loss: 0.68041855, Gradient norm: 0.10244828
INFO:root:At the start of the epoch: mem (CPU python)=14624.50390625MB; mem (CPU total)=14510.0625MB
INFO:root:[   12] Training loss: 0.68051885, Validation loss: 0.68002249, Gradient norm: 0.10284160
INFO:root:At the start of the epoch: mem (CPU python)=14662.59765625MB; mem (CPU total)=14548.62890625MB
INFO:root:[   13] Training loss: 0.67992122, Validation loss: 0.67953138, Gradient norm: 0.11201833
INFO:root:At the start of the epoch: mem (CPU python)=14700.6953125MB; mem (CPU total)=14587.13671875MB
INFO:root:[   14] Training loss: 0.67942546, Validation loss: 0.67819915, Gradient norm: 0.11199827
INFO:root:At the start of the epoch: mem (CPU python)=14738.79296875MB; mem (CPU total)=14625.609375MB
INFO:root:[   15] Training loss: 0.67880459, Validation loss: 0.67872350, Gradient norm: 0.11464354
INFO:root:At the start of the epoch: mem (CPU python)=14776.8828125MB; mem (CPU total)=14663.765625MB
INFO:root:[   16] Training loss: 0.67809836, Validation loss: 0.67730416, Gradient norm: 0.11939584
INFO:root:At the start of the epoch: mem (CPU python)=14814.98046875MB; mem (CPU total)=14702.62109375MB
INFO:root:[   17] Training loss: 0.67774306, Validation loss: 0.67654504, Gradient norm: 0.11720424
INFO:root:At the start of the epoch: mem (CPU python)=14853.078125MB; mem (CPU total)=14740.734375MB
INFO:root:[   18] Training loss: 0.67734776, Validation loss: 0.67657757, Gradient norm: 0.12570885
INFO:root:At the start of the epoch: mem (CPU python)=14891.16796875MB; mem (CPU total)=14779.1484375MB
INFO:root:[   19] Training loss: 0.67684844, Validation loss: 0.67528783, Gradient norm: 0.12283368
INFO:root:At the start of the epoch: mem (CPU python)=14929.265625MB; mem (CPU total)=14817.328125MB
INFO:root:[   20] Training loss: 0.67643213, Validation loss: 0.67557938, Gradient norm: 0.12710786
INFO:root:At the start of the epoch: mem (CPU python)=14967.36328125MB; mem (CPU total)=14855.15234375MB
INFO:root:[   21] Training loss: 0.67598752, Validation loss: 0.67499349, Gradient norm: 0.12999083
INFO:root:At the start of the epoch: mem (CPU python)=15005.46484375MB; mem (CPU total)=14893.328125MB
INFO:root:[   22] Training loss: 0.67543592, Validation loss: 0.67500634, Gradient norm: 0.12307208
INFO:root:At the start of the epoch: mem (CPU python)=15043.5546875MB; mem (CPU total)=14931.4921875MB
INFO:root:[   23] Training loss: 0.67518567, Validation loss: 0.67404526, Gradient norm: 0.12714578
INFO:root:At the start of the epoch: mem (CPU python)=15081.65234375MB; mem (CPU total)=14969.80078125MB
INFO:root:[   24] Training loss: 0.67486503, Validation loss: 0.67395711, Gradient norm: 0.13264631
INFO:root:At the start of the epoch: mem (CPU python)=15119.74609375MB; mem (CPU total)=15008.40234375MB
INFO:root:[   25] Training loss: 0.67457468, Validation loss: 0.67326335, Gradient norm: 0.12604603
INFO:root:At the start of the epoch: mem (CPU python)=15157.84375MB; mem (CPU total)=15046.890625MB
INFO:root:[   26] Training loss: 0.67403801, Validation loss: 0.67346397, Gradient norm: 0.13372643
INFO:root:At the start of the epoch: mem (CPU python)=15195.9375MB; mem (CPU total)=15085.296875MB
INFO:root:[   27] Training loss: 0.67366629, Validation loss: 0.67266284, Gradient norm: 0.13252739
INFO:root:At the start of the epoch: mem (CPU python)=15234.0390625MB; mem (CPU total)=15121.7578125MB
INFO:root:[   28] Training loss: 0.67339896, Validation loss: 0.67229344, Gradient norm: 0.13525046
INFO:root:At the start of the epoch: mem (CPU python)=15272.1328125MB; mem (CPU total)=15160.2578125MB
INFO:root:[   29] Training loss: 0.67310409, Validation loss: 0.67205530, Gradient norm: 0.13698131
INFO:root:At the start of the epoch: mem (CPU python)=15310.2265625MB; mem (CPU total)=15198.8203125MB
INFO:root:[   30] Training loss: 0.67266459, Validation loss: 0.67215387, Gradient norm: 0.13181091
INFO:root:At the start of the epoch: mem (CPU python)=15348.31640625MB; mem (CPU total)=15237.1640625MB
INFO:root:[   31] Training loss: 0.67257368, Validation loss: 0.67107006, Gradient norm: 0.13704400
INFO:root:At the start of the epoch: mem (CPU python)=15386.41796875MB; mem (CPU total)=15274.76171875MB
INFO:root:[   32] Training loss: 0.67221071, Validation loss: 0.67092748, Gradient norm: 0.13422246
INFO:root:At the start of the epoch: mem (CPU python)=15424.51171875MB; mem (CPU total)=15312.96484375MB
INFO:root:[   33] Training loss: 0.67196272, Validation loss: 0.67066214, Gradient norm: 0.14222822
INFO:root:At the start of the epoch: mem (CPU python)=15462.60546875MB; mem (CPU total)=15351.23046875MB
INFO:root:[   34] Training loss: 0.67190221, Validation loss: 0.67049136, Gradient norm: 0.13702212
INFO:root:At the start of the epoch: mem (CPU python)=15500.70703125MB; mem (CPU total)=15389.59765625MB
INFO:root:[   35] Training loss: 0.67165013, Validation loss: 0.67116280, Gradient norm: 0.14987411
INFO:root:At the start of the epoch: mem (CPU python)=15538.796875MB; mem (CPU total)=15427.7421875MB
INFO:root:[   36] Training loss: 0.67162814, Validation loss: 0.67035535, Gradient norm: 0.14485374
INFO:root:At the start of the epoch: mem (CPU python)=15576.89453125MB; mem (CPU total)=15465.703125MB
INFO:root:[   37] Training loss: 0.67128064, Validation loss: 0.67051820, Gradient norm: 0.13960718
INFO:root:At the start of the epoch: mem (CPU python)=15614.984375MB; mem (CPU total)=15504.0546875MB
INFO:root:[   38] Training loss: 0.67131017, Validation loss: 0.66977444, Gradient norm: 0.14478904
INFO:root:At the start of the epoch: mem (CPU python)=15653.0859375MB; mem (CPU total)=15542.0859375MB
INFO:root:[   39] Training loss: 0.67081039, Validation loss: 0.67006605, Gradient norm: 0.14862382
INFO:root:At the start of the epoch: mem (CPU python)=15691.17578125MB; mem (CPU total)=15580.46875MB
INFO:root:[   40] Training loss: 0.67080107, Validation loss: 0.66947105, Gradient norm: 0.13648888
INFO:root:At the start of the epoch: mem (CPU python)=15729.2734375MB; mem (CPU total)=15618.5703125MB
INFO:root:[   41] Training loss: 0.67067278, Validation loss: 0.67022005, Gradient norm: 0.15321995
INFO:root:At the start of the epoch: mem (CPU python)=15767.37109375MB; mem (CPU total)=15657.6328125MB
INFO:root:[   42] Training loss: 0.67050631, Validation loss: 0.66945023, Gradient norm: 0.13824004
INFO:root:At the start of the epoch: mem (CPU python)=15805.46484375MB; mem (CPU total)=15695.70703125MB
INFO:root:[   43] Training loss: 0.67025411, Validation loss: 0.66940096, Gradient norm: 0.14223698
INFO:root:At the start of the epoch: mem (CPU python)=15843.5625MB; mem (CPU total)=15734.25390625MB
INFO:root:[   44] Training loss: 0.67023307, Validation loss: 0.66919312, Gradient norm: 0.15095713
INFO:root:At the start of the epoch: mem (CPU python)=15881.66015625MB; mem (CPU total)=15772.28515625MB
INFO:root:[   45] Training loss: 0.66993062, Validation loss: 0.66872828, Gradient norm: 0.14688533
INFO:root:At the start of the epoch: mem (CPU python)=15919.75390625MB; mem (CPU total)=15810.5234375MB
INFO:root:[   46] Training loss: 0.66991772, Validation loss: 0.66936954, Gradient norm: 0.14977411
INFO:root:At the start of the epoch: mem (CPU python)=15957.84375MB; mem (CPU total)=15848.6953125MB
INFO:root:[   47] Training loss: 0.66978735, Validation loss: 0.66874426, Gradient norm: 0.15243217
INFO:root:At the start of the epoch: mem (CPU python)=15995.9375MB; mem (CPU total)=15886.859375MB
INFO:root:[   48] Training loss: 0.66968043, Validation loss: 0.66908329, Gradient norm: 0.14784282
INFO:root:At the start of the epoch: mem (CPU python)=16034.03515625MB; mem (CPU total)=15924.99609375MB
INFO:root:[   49] Training loss: 0.66944780, Validation loss: 0.66824544, Gradient norm: 0.15253380
INFO:root:At the start of the epoch: mem (CPU python)=16072.1328125MB; mem (CPU total)=15963.37109375MB
INFO:root:[   50] Training loss: 0.66930353, Validation loss: 0.66869416, Gradient norm: 0.15097479
INFO:root:At the start of the epoch: mem (CPU python)=16110.2265625MB; mem (CPU total)=16001.7265625MB
INFO:root:[   51] Training loss: 0.66933674, Validation loss: 0.66873959, Gradient norm: 0.15339261
INFO:root:At the start of the epoch: mem (CPU python)=16148.328125MB; mem (CPU total)=16039.31640625MB
INFO:root:[   52] Training loss: 0.66925613, Validation loss: 0.66763775, Gradient norm: 0.15491404
INFO:root:At the start of the epoch: mem (CPU python)=16186.421875MB; mem (CPU total)=16077.734375MB
INFO:root:[   53] Training loss: 0.66897833, Validation loss: 0.66757520, Gradient norm: 0.15765844
INFO:root:At the start of the epoch: mem (CPU python)=16224.51953125MB; mem (CPU total)=16116.00390625MB
INFO:root:[   54] Training loss: 0.66886089, Validation loss: 0.66775653, Gradient norm: 0.16488851
INFO:root:At the start of the epoch: mem (CPU python)=16262.609375MB; mem (CPU total)=16154.42578125MB
INFO:root:[   55] Training loss: 0.66870784, Validation loss: 0.66808904, Gradient norm: 0.16203274
INFO:root:At the start of the epoch: mem (CPU python)=16300.70703125MB; mem (CPU total)=16192.5703125MB
INFO:root:[   56] Training loss: 0.66851151, Validation loss: 0.66739454, Gradient norm: 0.16080184
INFO:root:At the start of the epoch: mem (CPU python)=16338.8046875MB; mem (CPU total)=16230.484375MB
INFO:root:[   57] Training loss: 0.66837541, Validation loss: 0.66756367, Gradient norm: 0.15756513
INFO:root:At the start of the epoch: mem (CPU python)=16376.89453125MB; mem (CPU total)=16269.08984375MB
INFO:root:[   58] Training loss: 0.66828054, Validation loss: 0.66732353, Gradient norm: 0.16277894
INFO:root:At the start of the epoch: mem (CPU python)=16414.9921875MB; mem (CPU total)=16306.99609375MB
INFO:root:[   59] Training loss: 0.66786821, Validation loss: 0.66698599, Gradient norm: 0.15380123
INFO:root:At the start of the epoch: mem (CPU python)=16453.08984375MB; mem (CPU total)=16345.51171875MB
INFO:root:[   60] Training loss: 0.66768752, Validation loss: 0.66717964, Gradient norm: 0.16614742
INFO:root:At the start of the epoch: mem (CPU python)=16491.18359375MB; mem (CPU total)=16383.890625MB
INFO:root:[   61] Training loss: 0.66775167, Validation loss: 0.66633238, Gradient norm: 0.17178387
INFO:root:At the start of the epoch: mem (CPU python)=16529.28515625MB; mem (CPU total)=16421.91796875MB
INFO:root:[   62] Training loss: 0.66737140, Validation loss: 0.66606400, Gradient norm: 0.16396761
INFO:root:At the start of the epoch: mem (CPU python)=16567.375MB; mem (CPU total)=16459.97265625MB
INFO:root:[   63] Training loss: 0.66750676, Validation loss: 0.66600151, Gradient norm: 0.17519820
INFO:root:At the start of the epoch: mem (CPU python)=16605.47265625MB; mem (CPU total)=16498.29296875MB
INFO:root:[   64] Training loss: 0.66712544, Validation loss: 0.66591656, Gradient norm: 0.16645384
INFO:root:At the start of the epoch: mem (CPU python)=16643.56640625MB; mem (CPU total)=16536.515625MB
INFO:root:[   65] Training loss: 0.66689181, Validation loss: 0.66575772, Gradient norm: 0.17106143
INFO:root:At the start of the epoch: mem (CPU python)=16681.6640625MB; mem (CPU total)=16574.53515625MB
INFO:root:[   66] Training loss: 0.66678096, Validation loss: 0.66597791, Gradient norm: 0.16516452
INFO:root:At the start of the epoch: mem (CPU python)=16719.75390625MB; mem (CPU total)=16612.43359375MB
INFO:root:[   67] Training loss: 0.66669689, Validation loss: 0.66500511, Gradient norm: 0.17415167
INFO:root:At the start of the epoch: mem (CPU python)=16757.8515625MB; mem (CPU total)=16649.6015625MB
INFO:root:[   68] Training loss: 0.66650675, Validation loss: 0.66489567, Gradient norm: 0.17028283
INFO:root:At the start of the epoch: mem (CPU python)=16795.94921875MB; mem (CPU total)=16687.80078125MB
INFO:root:[   69] Training loss: 0.66664740, Validation loss: 0.66498867, Gradient norm: 0.18332091
INFO:root:At the start of the epoch: mem (CPU python)=16834.04296875MB; mem (CPU total)=16726.1875MB
INFO:root:[   70] Training loss: 0.66645705, Validation loss: 0.66504929, Gradient norm: 0.18106432
INFO:root:At the start of the epoch: mem (CPU python)=16872.13671875MB; mem (CPU total)=16764.03515625MB
INFO:root:[   71] Training loss: 0.66612389, Validation loss: 0.66469855, Gradient norm: 0.18360733
INFO:root:At the start of the epoch: mem (CPU python)=16910.234375MB; mem (CPU total)=16802.44921875MB
INFO:root:[   72] Training loss: 0.66593930, Validation loss: 0.66513460, Gradient norm: 0.17275613
INFO:root:At the start of the epoch: mem (CPU python)=16948.328125MB; mem (CPU total)=16840.8359375MB
INFO:root:[   73] Training loss: 0.66588232, Validation loss: 0.66458004, Gradient norm: 0.17953418
INFO:root:At the start of the epoch: mem (CPU python)=16986.42578125MB; mem (CPU total)=16878.8125MB
INFO:root:[   74] Training loss: 0.66571969, Validation loss: 0.66454486, Gradient norm: 0.18106817
INFO:root:At the start of the epoch: mem (CPU python)=17024.51953125MB; mem (CPU total)=16917.21875MB
INFO:root:[   75] Training loss: 0.66582624, Validation loss: 0.66431577, Gradient norm: 0.18340500
INFO:root:At the start of the epoch: mem (CPU python)=17062.61328125MB; mem (CPU total)=16955.703125MB
INFO:root:[   76] Training loss: 0.66544348, Validation loss: 0.66389898, Gradient norm: 0.17358070
INFO:root:At the start of the epoch: mem (CPU python)=17100.7109375MB; mem (CPU total)=16993.95703125MB
INFO:root:[   77] Training loss: 0.66545549, Validation loss: 0.66423788, Gradient norm: 0.18726160
INFO:root:At the start of the epoch: mem (CPU python)=17138.8046875MB; mem (CPU total)=17032.5859375MB
INFO:root:[   78] Training loss: 0.66515384, Validation loss: 0.66436220, Gradient norm: 0.17194687
INFO:root:At the start of the epoch: mem (CPU python)=17176.90234375MB; mem (CPU total)=17070.453125MB
INFO:root:[   79] Training loss: 0.66539530, Validation loss: 0.66338828, Gradient norm: 0.19318070
INFO:root:At the start of the epoch: mem (CPU python)=17215.0MB; mem (CPU total)=17108.484375MB
INFO:root:[   80] Training loss: 0.66511828, Validation loss: 0.66395281, Gradient norm: 0.17784663
INFO:root:At the start of the epoch: mem (CPU python)=17253.08984375MB; mem (CPU total)=17146.87109375MB
INFO:root:[   81] Training loss: 0.66513098, Validation loss: 0.66469420, Gradient norm: 0.18625611
INFO:root:At the start of the epoch: mem (CPU python)=17291.18359375MB; mem (CPU total)=17185.03125MB
INFO:root:[   82] Training loss: 0.66503410, Validation loss: 0.66353928, Gradient norm: 0.18857044
INFO:root:At the start of the epoch: mem (CPU python)=17329.28125MB; mem (CPU total)=17222.9296875MB
INFO:root:[   83] Training loss: 0.66471607, Validation loss: 0.66355698, Gradient norm: 0.17162858
INFO:root:At the start of the epoch: mem (CPU python)=17367.37890625MB; mem (CPU total)=17261.07421875MB
INFO:root:[   84] Training loss: 0.66468351, Validation loss: 0.66380292, Gradient norm: 0.17167381
INFO:root:At the start of the epoch: mem (CPU python)=17405.47265625MB; mem (CPU total)=17299.33984375MB
INFO:root:[   85] Training loss: 0.66437762, Validation loss: 0.66347526, Gradient norm: 0.17007562
INFO:root:At the start of the epoch: mem (CPU python)=17443.5703125MB; mem (CPU total)=17337.484375MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   86] Training loss: 0.66433878, Validation loss: 0.66363858, Gradient norm: 0.17794361
INFO:root:At the start of the epoch: mem (CPU python)=17481.6640625MB; mem (CPU total)=17375.3828125MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   87] Training loss: 0.66325817, Validation loss: 0.66200388, Gradient norm: 0.15808584
INFO:root:At the start of the epoch: mem (CPU python)=17519.76171875MB; mem (CPU total)=17413.328125MB
INFO:root:[   88] Training loss: 0.66269081, Validation loss: 0.66181285, Gradient norm: 0.14123371
INFO:root:At the start of the epoch: mem (CPU python)=17557.85546875MB; mem (CPU total)=17451.75MB
INFO:root:[   89] Training loss: 0.66250106, Validation loss: 0.66134946, Gradient norm: 0.14745207
INFO:root:At the start of the epoch: mem (CPU python)=17595.953125MB; mem (CPU total)=17489.95703125MB
INFO:root:[   90] Training loss: 0.66231988, Validation loss: 0.66132760, Gradient norm: 0.14909434
INFO:root:At the start of the epoch: mem (CPU python)=17634.046875MB; mem (CPU total)=17528.26171875MB
INFO:root:[   91] Training loss: 0.66234424, Validation loss: 0.66151750, Gradient norm: 0.16088371
INFO:root:At the start of the epoch: mem (CPU python)=17672.13671875MB; mem (CPU total)=17566.08984375MB
INFO:root:[   92] Training loss: 0.66243978, Validation loss: 0.66156488, Gradient norm: 0.15190823
INFO:root:At the start of the epoch: mem (CPU python)=17710.23828125MB; mem (CPU total)=17604.5MB
INFO:root:[   93] Training loss: 0.66223392, Validation loss: 0.66155904, Gradient norm: 0.15818042
INFO:root:At the start of the epoch: mem (CPU python)=17748.3359375MB; mem (CPU total)=17642.36328125MB
INFO:root:[   94] Training loss: 0.66238151, Validation loss: 0.66164667, Gradient norm: 0.15580087
INFO:root:At the start of the epoch: mem (CPU python)=17786.4296875MB; mem (CPU total)=17680.3046875MB
INFO:root:[   95] Training loss: 0.66220718, Validation loss: 0.66111112, Gradient norm: 0.16143371
INFO:root:At the start of the epoch: mem (CPU python)=17824.53125MB; mem (CPU total)=17717.25MB
INFO:root:[   96] Training loss: 0.66217734, Validation loss: 0.66118112, Gradient norm: 0.15895252
INFO:root:At the start of the epoch: mem (CPU python)=17862.62109375MB; mem (CPU total)=17755.640625MB
INFO:root:[   97] Training loss: 0.66214222, Validation loss: 0.66124748, Gradient norm: 0.15402624
INFO:root:At the start of the epoch: mem (CPU python)=17900.71484375MB; mem (CPU total)=17794.05859375MB
INFO:root:[   98] Training loss: 0.66197504, Validation loss: 0.66146576, Gradient norm: 0.15774526
INFO:root:At the start of the epoch: mem (CPU python)=17938.80859375MB; mem (CPU total)=17832.1953125MB
INFO:root:[   99] Training loss: 0.66199383, Validation loss: 0.66135074, Gradient norm: 0.16456725
INFO:root:At the start of the epoch: mem (CPU python)=17976.90625MB; mem (CPU total)=17870.09375MB
INFO:root:[  100] Training loss: 0.66208387, Validation loss: 0.66148825, Gradient norm: 0.15839284
INFO:root:At the start of the epoch: mem (CPU python)=18015.00390625MB; mem (CPU total)=17908.1171875MB
INFO:root:[  101] Training loss: 0.66200024, Validation loss: 0.66154546, Gradient norm: 0.16315187
INFO:root:At the start of the epoch: mem (CPU python)=18053.09765625MB; mem (CPU total)=17946.2265625MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  102] Training loss: 0.66195294, Validation loss: 0.66106205, Gradient norm: 0.15993216
INFO:root:At the start of the epoch: mem (CPU python)=18091.1953125MB; mem (CPU total)=17984.3984375MB
INFO:root:[  103] Training loss: 0.66161480, Validation loss: 0.66079680, Gradient norm: 0.15138783
INFO:root:At the start of the epoch: mem (CPU python)=18129.2890625MB; mem (CPU total)=18022.60546875MB
INFO:root:[  104] Training loss: 0.66154942, Validation loss: 0.66079098, Gradient norm: 0.14771550
INFO:root:At the start of the epoch: mem (CPU python)=18167.38671875MB; mem (CPU total)=18060.84375MB
INFO:root:[  105] Training loss: 0.66150355, Validation loss: 0.66081462, Gradient norm: 0.15046134
INFO:root:At the start of the epoch: mem (CPU python)=18205.4765625MB; mem (CPU total)=18098.78125MB
INFO:root:[  106] Training loss: 0.66155174, Validation loss: 0.66091184, Gradient norm: 0.15344016
INFO:root:At the start of the epoch: mem (CPU python)=18243.57421875MB; mem (CPU total)=18137.296875MB
INFO:root:[  107] Training loss: 0.66159610, Validation loss: 0.66041051, Gradient norm: 0.15042139
INFO:root:At the start of the epoch: mem (CPU python)=18281.671875MB; mem (CPU total)=18174.34375MB
INFO:root:[  108] Training loss: 0.66156238, Validation loss: 0.66078650, Gradient norm: 0.15741993
INFO:root:At the start of the epoch: mem (CPU python)=18319.76171875MB; mem (CPU total)=18212.734375MB
INFO:root:[  109] Training loss: 0.66147379, Validation loss: 0.66049124, Gradient norm: 0.15543323
INFO:root:At the start of the epoch: mem (CPU python)=18357.859375MB; mem (CPU total)=18250.84765625MB
INFO:root:[  110] Training loss: 0.66154160, Validation loss: 0.66066681, Gradient norm: 0.15575285
INFO:root:At the start of the epoch: mem (CPU python)=18395.95703125MB; mem (CPU total)=18288.98828125MB
INFO:root:[  111] Training loss: 0.66129096, Validation loss: 0.66135372, Gradient norm: 0.17070146
INFO:root:At the start of the epoch: mem (CPU python)=18434.05078125MB; mem (CPU total)=18326.88671875MB
INFO:root:[  112] Training loss: 0.66143513, Validation loss: 0.66050964, Gradient norm: 0.16141687
INFO:root:At the start of the epoch: mem (CPU python)=18472.1484375MB; mem (CPU total)=18364.88671875MB
INFO:root:[  113] Training loss: 0.66127567, Validation loss: 0.66112630, Gradient norm: 0.15651736
INFO:root:At the start of the epoch: mem (CPU python)=18510.2421875MB; mem (CPU total)=18403.27734375MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  114] Training loss: 0.66142733, Validation loss: 0.66045456, Gradient norm: 0.16527644
INFO:root:At the start of the epoch: mem (CPU python)=18548.3359375MB; mem (CPU total)=18441.421875MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  115] Training loss: 0.66126415, Validation loss: 0.66038440, Gradient norm: 0.15471480
INFO:root:At the start of the epoch: mem (CPU python)=18586.4375MB; mem (CPU total)=18479.26171875MB
INFO:root:[  116] Training loss: 0.66116460, Validation loss: 0.66030406, Gradient norm: 0.15163354
INFO:root:At the start of the epoch: mem (CPU python)=18624.53515625MB; mem (CPU total)=18517.74609375MB
INFO:root:[  117] Training loss: 0.66101973, Validation loss: 0.66049471, Gradient norm: 0.15251385
INFO:root:At the start of the epoch: mem (CPU python)=18662.62890625MB; mem (CPU total)=18556.3828125MB
INFO:root:[  118] Training loss: 0.66101630, Validation loss: 0.66035850, Gradient norm: 0.14983743
INFO:root:At the start of the epoch: mem (CPU python)=18700.72265625MB; mem (CPU total)=18594.52734375MB
INFO:root:[  119] Training loss: 0.66096429, Validation loss: 0.66048480, Gradient norm: 0.15387043
INFO:root:At the start of the epoch: mem (CPU python)=18738.8203125MB; mem (CPU total)=18632.41796875MB
INFO:root:[  120] Training loss: 0.66097942, Validation loss: 0.66066148, Gradient norm: 0.15185910
INFO:root:At the start of the epoch: mem (CPU python)=18776.9140625MB; mem (CPU total)=18670.5234375MB
INFO:root:[  121] Training loss: 0.66102726, Validation loss: 0.66075909, Gradient norm: 0.15155894
INFO:root:At the start of the epoch: mem (CPU python)=18815.01953125MB; mem (CPU total)=18709.21484375MB
INFO:root:[  122] Training loss: 0.66112623, Validation loss: 0.66037817, Gradient norm: 0.15451165
INFO:root:At the start of the epoch: mem (CPU python)=18853.1015625MB; mem (CPU total)=18746.9921875MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  123] Training loss: 0.66102258, Validation loss: 0.66060491, Gradient norm: 0.15029532
INFO:root:At the start of the epoch: mem (CPU python)=18891.19921875MB; mem (CPU total)=18785.15234375MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  124] Training loss: 0.66094972, Validation loss: 0.66055206, Gradient norm: 0.15654371
INFO:root:At the start of the epoch: mem (CPU python)=18929.296875MB; mem (CPU total)=18823.3203125MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  125] Training loss: 0.66099533, Validation loss: 0.65989923, Gradient norm: 0.15082165
INFO:root:At the start of the epoch: mem (CPU python)=18967.390625MB; mem (CPU total)=18861.49609375MB
INFO:root:[  126] Training loss: 0.66089776, Validation loss: 0.66062920, Gradient norm: 0.15072554
INFO:root:At the start of the epoch: mem (CPU python)=19005.484375MB; mem (CPU total)=18898.65625MB
INFO:root:[  127] Training loss: 0.66095794, Validation loss: 0.66029341, Gradient norm: 0.14885825
INFO:root:At the start of the epoch: mem (CPU python)=19043.58203125MB; mem (CPU total)=18937.01171875MB
INFO:root:[  128] Training loss: 0.66084693, Validation loss: 0.66043289, Gradient norm: 0.14851980
INFO:root:At the start of the epoch: mem (CPU python)=19081.67578125MB; mem (CPU total)=18975.19921875MB
INFO:root:[  129] Training loss: 0.66089313, Validation loss: 0.66065340, Gradient norm: 0.14628995
INFO:root:At the start of the epoch: mem (CPU python)=19119.7734375MB; mem (CPU total)=19013.390625MB
INFO:root:[  130] Training loss: 0.66082038, Validation loss: 0.66034982, Gradient norm: 0.15441201
INFO:root:At the start of the epoch: mem (CPU python)=19157.8671875MB; mem (CPU total)=19051.6875MB
INFO:root:[  131] Training loss: 0.66079566, Validation loss: 0.66052831, Gradient norm: 0.15158766
INFO:root:At the start of the epoch: mem (CPU python)=19195.9609375MB; mem (CPU total)=19089.609375MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  132] Training loss: 0.66091338, Validation loss: 0.66076743, Gradient norm: 0.15280854
INFO:root:At the start of the epoch: mem (CPU python)=19234.0546875MB; mem (CPU total)=19127.77734375MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:[  133] Training loss: 0.66089041, Validation loss: 0.66057424, Gradient norm: 0.15072365
INFO:root:At the start of the epoch: mem (CPU python)=19272.15234375MB; mem (CPU total)=19166.4375MB
INFO:root:Learning rate reduced to: [4.8828125e-07]
INFO:root:[  134] Training loss: 0.66087997, Validation loss: 0.66051403, Gradient norm: 0.14883185
INFO:root:At the start of the epoch: mem (CPU python)=19310.25MB; mem (CPU total)=19204.3515625MB
INFO:root:Learning rate reduced to: [2.44140625e-07]
INFO:root:EP 134: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19348.34375MB; mem (CPU total)=19242.65625MB
INFO:root:Training the model took 8140.944s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93394
INFO:root:EnergyScoreTrain: 0.65728
INFO:root:CRPSTrain: 0.5287
INFO:root:Gaussian NLLTrain: 1.39569
INFO:root:CoverageTrain: 0.92685
INFO:root:IntervalWidthTrain: 3.44441
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93828
INFO:root:EnergyScoreValidation: 0.66038
INFO:root:CRPSValidation: 0.53147
INFO:root:Gaussian NLLValidation: 1.40247
INFO:root:CoverageValidation: 0.92584
INFO:root:IntervalWidthValidation: 3.44751
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93762
INFO:root:EnergyScoreTest: 0.6599
INFO:root:CRPSTest: 0.53112
INFO:root:Gaussian NLLTest: 1.4019
INFO:root:CoverageTest: 0.92568
INFO:root:IntervalWidthTest: 3.44598
INFO:root:After validation: mem (CPU python)=19434.25390625MB; mem (CPU total)=19330.6953125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=19434.25390625MB; mem (CPU total)=19282.17578125MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=19434.25390625MB; mem (CPU total)=19286.51171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=19434.25390625MB; mem (CPU total)=19286.515625MB
INFO:root:[    1] Training loss: 0.71370955, Validation loss: 0.70222236, Gradient norm: 0.04286513
INFO:root:At the start of the epoch: mem (CPU python)=19434.25390625MB; mem (CPU total)=19324.5546875MB
INFO:root:[    2] Training loss: 0.69748223, Validation loss: 0.69422752, Gradient norm: 0.06502078
INFO:root:At the start of the epoch: mem (CPU python)=19467.65625MB; mem (CPU total)=19362.64453125MB
INFO:root:[    3] Training loss: 0.69226279, Validation loss: 0.68950367, Gradient norm: 0.08444516
INFO:root:At the start of the epoch: mem (CPU python)=19505.765625MB; mem (CPU total)=19401.29296875MB
INFO:root:[    4] Training loss: 0.68899970, Validation loss: 0.68753270, Gradient norm: 0.09292916
INFO:root:At the start of the epoch: mem (CPU python)=19543.8671875MB; mem (CPU total)=19439.2734375MB
INFO:root:[    5] Training loss: 0.68700973, Validation loss: 0.68553795, Gradient norm: 0.10056760
INFO:root:At the start of the epoch: mem (CPU python)=19581.9609375MB; mem (CPU total)=19477.32421875MB
INFO:root:[    6] Training loss: 0.68556114, Validation loss: 0.68451228, Gradient norm: 0.10001141
INFO:root:At the start of the epoch: mem (CPU python)=19620.0546875MB; mem (CPU total)=19515.3046875MB
INFO:root:[    7] Training loss: 0.68423707, Validation loss: 0.68339786, Gradient norm: 0.10221810
INFO:root:At the start of the epoch: mem (CPU python)=19658.15234375MB; mem (CPU total)=19553.51953125MB
INFO:root:[    8] Training loss: 0.68331481, Validation loss: 0.68215646, Gradient norm: 0.10556545
INFO:root:At the start of the epoch: mem (CPU python)=19696.25MB; mem (CPU total)=19592.08984375MB
INFO:root:[    9] Training loss: 0.68245172, Validation loss: 0.68133985, Gradient norm: 0.10307648
INFO:root:At the start of the epoch: mem (CPU python)=19735.90625MB; mem (CPU total)=19632.65234375MB
INFO:root:[   10] Training loss: 0.68164658, Validation loss: 0.68153990, Gradient norm: 0.10308078
INFO:root:At the start of the epoch: mem (CPU python)=19773.99609375MB; mem (CPU total)=19670.63671875MB
INFO:root:[   11] Training loss: 0.68092382, Validation loss: 0.67999278, Gradient norm: 0.11090265
INFO:root:At the start of the epoch: mem (CPU python)=19812.09375MB; mem (CPU total)=19709.0390625MB
INFO:root:[   12] Training loss: 0.68038159, Validation loss: 0.67890327, Gradient norm: 0.11242600
INFO:root:At the start of the epoch: mem (CPU python)=19850.19140625MB; mem (CPU total)=19747.4921875MB
INFO:root:[   13] Training loss: 0.67968369, Validation loss: 0.67856994, Gradient norm: 0.12416088
INFO:root:At the start of the epoch: mem (CPU python)=19888.28515625MB; mem (CPU total)=19786.0546875MB
INFO:root:[   14] Training loss: 0.67909497, Validation loss: 0.67811963, Gradient norm: 0.12512606
INFO:root:At the start of the epoch: mem (CPU python)=19926.3828125MB; mem (CPU total)=19823.35546875MB
INFO:root:[   15] Training loss: 0.67842818, Validation loss: 0.67776670, Gradient norm: 0.11619389
INFO:root:At the start of the epoch: mem (CPU python)=19964.484375MB; mem (CPU total)=19861.69140625MB
INFO:root:[   16] Training loss: 0.67807283, Validation loss: 0.67712288, Gradient norm: 0.12782892
INFO:root:At the start of the epoch: mem (CPU python)=20002.578125MB; mem (CPU total)=19899.88671875MB
INFO:root:[   17] Training loss: 0.67751390, Validation loss: 0.67690988, Gradient norm: 0.12168810
INFO:root:At the start of the epoch: mem (CPU python)=20040.671875MB; mem (CPU total)=19938.13671875MB
INFO:root:[   18] Training loss: 0.67709861, Validation loss: 0.67605466, Gradient norm: 0.12819610
INFO:root:At the start of the epoch: mem (CPU python)=20078.765625MB; mem (CPU total)=19975.42578125MB
INFO:root:[   19] Training loss: 0.67674730, Validation loss: 0.67559290, Gradient norm: 0.12797983
INFO:root:At the start of the epoch: mem (CPU python)=20116.86328125MB; mem (CPU total)=20013.390625MB
INFO:root:[   20] Training loss: 0.67647692, Validation loss: 0.67590236, Gradient norm: 0.13925554
INFO:root:At the start of the epoch: mem (CPU python)=20154.953125MB; mem (CPU total)=20051.98046875MB
INFO:root:[   21] Training loss: 0.67583878, Validation loss: 0.67511949, Gradient norm: 0.13332460
INFO:root:At the start of the epoch: mem (CPU python)=20193.0546875MB; mem (CPU total)=20089.88671875MB
INFO:root:[   22] Training loss: 0.67555658, Validation loss: 0.67510213, Gradient norm: 0.13707746
INFO:root:At the start of the epoch: mem (CPU python)=20231.14453125MB; mem (CPU total)=20128.18359375MB
INFO:root:[   23] Training loss: 0.67507815, Validation loss: 0.67329295, Gradient norm: 0.12827761
INFO:root:At the start of the epoch: mem (CPU python)=20269.25MB; mem (CPU total)=20167.1328125MB
INFO:root:[   24] Training loss: 0.67475978, Validation loss: 0.67429962, Gradient norm: 0.13676774
INFO:root:At the start of the epoch: mem (CPU python)=20307.34375MB; mem (CPU total)=20205.12109375MB
INFO:root:[   25] Training loss: 0.67433361, Validation loss: 0.67355047, Gradient norm: 0.12952523
INFO:root:At the start of the epoch: mem (CPU python)=20345.4375MB; mem (CPU total)=20243.0859375MB
INFO:root:[   26] Training loss: 0.67405167, Validation loss: 0.67277565, Gradient norm: 0.14006309
INFO:root:At the start of the epoch: mem (CPU python)=20383.53125MB; mem (CPU total)=20282.15625MB
INFO:root:[   27] Training loss: 0.67354376, Validation loss: 0.67298380, Gradient norm: 0.13552020
INFO:root:At the start of the epoch: mem (CPU python)=20421.625MB; mem (CPU total)=20319.5390625MB
INFO:root:[   28] Training loss: 0.67301138, Validation loss: 0.67204584, Gradient norm: 0.13809359
INFO:root:At the start of the epoch: mem (CPU python)=20459.7265625MB; mem (CPU total)=20357.75390625MB
INFO:root:[   29] Training loss: 0.67278419, Validation loss: 0.67122783, Gradient norm: 0.14091794
INFO:root:At the start of the epoch: mem (CPU python)=20497.8203125MB; mem (CPU total)=20396.10546875MB
INFO:root:[   30] Training loss: 0.67226667, Validation loss: 0.67090907, Gradient norm: 0.13434132
INFO:root:At the start of the epoch: mem (CPU python)=20535.9140625MB; mem (CPU total)=20433.75390625MB
INFO:root:[   31] Training loss: 0.67219191, Validation loss: 0.67181616, Gradient norm: 0.13968389
INFO:root:At the start of the epoch: mem (CPU python)=20574.01171875MB; mem (CPU total)=20472.12890625MB
INFO:root:[   32] Training loss: 0.67180660, Validation loss: 0.67102072, Gradient norm: 0.14367810
INFO:root:At the start of the epoch: mem (CPU python)=20612.10546875MB; mem (CPU total)=20510.30078125MB
INFO:root:[   33] Training loss: 0.67148553, Validation loss: 0.67071217, Gradient norm: 0.14084121
INFO:root:At the start of the epoch: mem (CPU python)=20650.203125MB; mem (CPU total)=20548.640625MB
INFO:root:[   34] Training loss: 0.67129630, Validation loss: 0.67066348, Gradient norm: 0.14633622
INFO:root:At the start of the epoch: mem (CPU python)=20688.296875MB; mem (CPU total)=20586.68359375MB
INFO:root:[   35] Training loss: 0.67098211, Validation loss: 0.67047494, Gradient norm: 0.13686228
INFO:root:At the start of the epoch: mem (CPU python)=20726.39453125MB; mem (CPU total)=20624.46484375MB
INFO:root:[   36] Training loss: 0.67100938, Validation loss: 0.66987625, Gradient norm: 0.14974228
INFO:root:At the start of the epoch: mem (CPU python)=20764.48828125MB; mem (CPU total)=20662.46875MB
INFO:root:[   37] Training loss: 0.67058369, Validation loss: 0.66960023, Gradient norm: 0.14202015
INFO:root:At the start of the epoch: mem (CPU python)=20802.58203125MB; mem (CPU total)=20700.70703125MB
INFO:root:[   38] Training loss: 0.67032020, Validation loss: 0.66982573, Gradient norm: 0.13642080
INFO:root:At the start of the epoch: mem (CPU python)=20840.6796875MB; mem (CPU total)=20739.09375MB
INFO:root:[   39] Training loss: 0.67028058, Validation loss: 0.66976563, Gradient norm: 0.15526424
INFO:root:At the start of the epoch: mem (CPU python)=20878.7734375MB; mem (CPU total)=20777.05859375MB
INFO:root:[   40] Training loss: 0.67013345, Validation loss: 0.66908178, Gradient norm: 0.14399619
INFO:root:At the start of the epoch: mem (CPU python)=20916.87109375MB; mem (CPU total)=20819.921875MB
INFO:root:[   41] Training loss: 0.66997509, Validation loss: 0.66969269, Gradient norm: 0.15358542
INFO:root:At the start of the epoch: mem (CPU python)=20954.96484375MB; mem (CPU total)=20858.2734375MB
INFO:root:[   42] Training loss: 0.66990628, Validation loss: 0.66955427, Gradient norm: 0.15720079
INFO:root:At the start of the epoch: mem (CPU python)=20993.05859375MB; mem (CPU total)=20896.109375MB
INFO:root:[   43] Training loss: 0.66950980, Validation loss: 0.66806149, Gradient norm: 0.14153748
INFO:root:At the start of the epoch: mem (CPU python)=21031.15625MB; mem (CPU total)=20934.31640625MB
INFO:root:[   44] Training loss: 0.66937647, Validation loss: 0.66907915, Gradient norm: 0.15911710
INFO:root:At the start of the epoch: mem (CPU python)=21069.24609375MB; mem (CPU total)=20972.703125MB
INFO:root:[   45] Training loss: 0.66919629, Validation loss: 0.66848191, Gradient norm: 0.14832389
INFO:root:At the start of the epoch: mem (CPU python)=21107.34765625MB; mem (CPU total)=21010.78125MB
INFO:root:[   46] Training loss: 0.66912736, Validation loss: 0.66827063, Gradient norm: 0.16019926
INFO:root:At the start of the epoch: mem (CPU python)=21145.44140625MB; mem (CPU total)=21048.6796875MB
INFO:root:[   47] Training loss: 0.66889976, Validation loss: 0.66796688, Gradient norm: 0.14992883
INFO:root:At the start of the epoch: mem (CPU python)=21183.5390625MB; mem (CPU total)=21086.91015625MB
INFO:root:[   48] Training loss: 0.66874456, Validation loss: 0.66777404, Gradient norm: 0.16602903
INFO:root:At the start of the epoch: mem (CPU python)=21221.63671875MB; mem (CPU total)=21125.3046875MB
INFO:root:[   49] Training loss: 0.66859177, Validation loss: 0.66830799, Gradient norm: 0.17169863
INFO:root:At the start of the epoch: mem (CPU python)=21259.7265625MB; mem (CPU total)=21163.4609375MB
INFO:root:[   50] Training loss: 0.66815181, Validation loss: 0.66713517, Gradient norm: 0.15582612
INFO:root:At the start of the epoch: mem (CPU python)=21297.82421875MB; mem (CPU total)=21201.62109375MB
INFO:root:[   51] Training loss: 0.66811584, Validation loss: 0.66708167, Gradient norm: 0.16870337
INFO:root:At the start of the epoch: mem (CPU python)=21335.91796875MB; mem (CPU total)=21239.640625MB
INFO:root:[   52] Training loss: 0.66791117, Validation loss: 0.66701368, Gradient norm: 0.15632710
INFO:root:At the start of the epoch: mem (CPU python)=21374.015625MB; mem (CPU total)=21278.109375MB
INFO:root:[   53] Training loss: 0.66748690, Validation loss: 0.66644560, Gradient norm: 0.17248091
INFO:root:At the start of the epoch: mem (CPU python)=21412.109375MB; mem (CPU total)=21316.60546875MB
INFO:root:[   54] Training loss: 0.66740178, Validation loss: 0.66621489, Gradient norm: 0.15982456
INFO:root:At the start of the epoch: mem (CPU python)=21450.203125MB; mem (CPU total)=21354.515625MB
INFO:root:[   55] Training loss: 0.66717844, Validation loss: 0.66563730, Gradient norm: 0.15959369
INFO:root:At the start of the epoch: mem (CPU python)=21488.30078125MB; mem (CPU total)=21392.96875MB
INFO:root:[   56] Training loss: 0.66729317, Validation loss: 0.66601558, Gradient norm: 0.18125405
INFO:root:At the start of the epoch: mem (CPU python)=21526.39453125MB; mem (CPU total)=21431.32421875MB
INFO:root:[   57] Training loss: 0.66723412, Validation loss: 0.66587924, Gradient norm: 0.17682739
INFO:root:At the start of the epoch: mem (CPU python)=21564.48828125MB; mem (CPU total)=21469.48046875MB
INFO:root:[   58] Training loss: 0.66693124, Validation loss: 0.66602386, Gradient norm: 0.16466217
INFO:root:At the start of the epoch: mem (CPU python)=21602.5859375MB; mem (CPU total)=21507.6171875MB
INFO:root:[   59] Training loss: 0.66665462, Validation loss: 0.66588463, Gradient norm: 0.17396269
INFO:root:At the start of the epoch: mem (CPU python)=21640.6796875MB; mem (CPU total)=21545.515625MB
INFO:root:[   60] Training loss: 0.66674244, Validation loss: 0.66545039, Gradient norm: 0.16796689
INFO:root:At the start of the epoch: mem (CPU python)=21678.77734375MB; mem (CPU total)=21583.31640625MB
INFO:root:[   61] Training loss: 0.66663626, Validation loss: 0.66585859, Gradient norm: 0.16800690
INFO:root:At the start of the epoch: mem (CPU python)=21716.8671875MB; mem (CPU total)=21621.70703125MB
INFO:root:[   62] Training loss: 0.66647871, Validation loss: 0.66487939, Gradient norm: 0.17203356
INFO:root:At the start of the epoch: mem (CPU python)=21754.96875MB; mem (CPU total)=21659.90625MB
INFO:root:[   63] Training loss: 0.66605288, Validation loss: 0.66516549, Gradient norm: 0.15684401
INFO:root:At the start of the epoch: mem (CPU python)=21793.0625MB; mem (CPU total)=21698.57421875MB
INFO:root:[   64] Training loss: 0.66637256, Validation loss: 0.66460225, Gradient norm: 0.16505171
INFO:root:At the start of the epoch: mem (CPU python)=21831.16015625MB; mem (CPU total)=21736.55859375MB
INFO:root:[   65] Training loss: 0.66601156, Validation loss: 0.66515289, Gradient norm: 0.16975763
INFO:root:At the start of the epoch: mem (CPU python)=21869.25390625MB; mem (CPU total)=21774.91796875MB
INFO:root:[   66] Training loss: 0.66582019, Validation loss: 0.66458170, Gradient norm: 0.17048463
INFO:root:At the start of the epoch: mem (CPU python)=21907.35546875MB; mem (CPU total)=21812.90625MB
INFO:root:[   67] Training loss: 0.66570038, Validation loss: 0.66567228, Gradient norm: 0.16625744
INFO:root:At the start of the epoch: mem (CPU python)=21945.4453125MB; mem (CPU total)=21851.28125MB
INFO:root:[   68] Training loss: 0.66587341, Validation loss: 0.66544816, Gradient norm: 0.17407232
INFO:root:At the start of the epoch: mem (CPU python)=21983.54296875MB; mem (CPU total)=21889.44921875MB
INFO:root:[   69] Training loss: 0.66590256, Validation loss: 0.66509200, Gradient norm: 0.17902577
INFO:root:At the start of the epoch: mem (CPU python)=22021.640625MB; mem (CPU total)=21927.5859375MB
INFO:root:[   70] Training loss: 0.66554460, Validation loss: 0.66464786, Gradient norm: 0.16987851
INFO:root:At the start of the epoch: mem (CPU python)=22059.734375MB; mem (CPU total)=21965.86328125MB
INFO:root:[   71] Training loss: 0.66563236, Validation loss: 0.66502316, Gradient norm: 0.16651586
INFO:root:At the start of the epoch: mem (CPU python)=22097.828125MB; mem (CPU total)=22003.9140625MB
INFO:root:[   72] Training loss: 0.66550967, Validation loss: 0.66442018, Gradient norm: 0.18355753
INFO:root:At the start of the epoch: mem (CPU python)=22135.9296875MB; mem (CPU total)=22042.26171875MB
INFO:root:[   73] Training loss: 0.66526736, Validation loss: 0.66425087, Gradient norm: 0.16915523
INFO:root:At the start of the epoch: mem (CPU python)=22174.0234375MB; mem (CPU total)=22080.75MB
INFO:root:[   74] Training loss: 0.66530778, Validation loss: 0.66415388, Gradient norm: 0.17387483
INFO:root:At the start of the epoch: mem (CPU python)=22212.1171875MB; mem (CPU total)=22118.609375MB
INFO:root:[   75] Training loss: 0.66507681, Validation loss: 0.66453409, Gradient norm: 0.16704847
INFO:root:At the start of the epoch: mem (CPU python)=22250.2109375MB; mem (CPU total)=22156.69140625MB
INFO:root:[   76] Training loss: 0.66501713, Validation loss: 0.66437919, Gradient norm: 0.16338739
INFO:root:At the start of the epoch: mem (CPU python)=22288.3046875MB; mem (CPU total)=22194.8359375MB
INFO:root:[   77] Training loss: 0.66494511, Validation loss: 0.66386792, Gradient norm: 0.17049867
INFO:root:At the start of the epoch: mem (CPU python)=22326.40234375MB; mem (CPU total)=22232.94140625MB
INFO:root:[   78] Training loss: 0.66507800, Validation loss: 0.66461617, Gradient norm: 0.17379732
INFO:root:At the start of the epoch: mem (CPU python)=22364.4921875MB; mem (CPU total)=22271.33203125MB
INFO:root:[   79] Training loss: 0.66490039, Validation loss: 0.66477867, Gradient norm: 0.17189718
INFO:root:At the start of the epoch: mem (CPU python)=22402.59375MB; mem (CPU total)=22309.5MB
INFO:root:[   80] Training loss: 0.66474688, Validation loss: 0.66343245, Gradient norm: 0.17019307
INFO:root:At the start of the epoch: mem (CPU python)=22440.69140625MB; mem (CPU total)=22347.72265625MB
INFO:root:[   81] Training loss: 0.66482264, Validation loss: 0.66392354, Gradient norm: 0.16215229
INFO:root:At the start of the epoch: mem (CPU python)=22478.78125MB; mem (CPU total)=22384.8828125MB
INFO:root:[   82] Training loss: 0.66445126, Validation loss: 0.66350171, Gradient norm: 0.15797584
INFO:root:At the start of the epoch: mem (CPU python)=22516.87890625MB; mem (CPU total)=22423.75390625MB
INFO:root:[   83] Training loss: 0.66469075, Validation loss: 0.66387598, Gradient norm: 0.17487992
INFO:root:At the start of the epoch: mem (CPU python)=22554.97265625MB; mem (CPU total)=22460.92578125MB
INFO:root:[   84] Training loss: 0.66457774, Validation loss: 0.66322274, Gradient norm: 0.17198013
INFO:root:At the start of the epoch: mem (CPU python)=22593.0703125MB; mem (CPU total)=22499.3359375MB
INFO:root:[   85] Training loss: 0.66456707, Validation loss: 0.66337439, Gradient norm: 0.17173545
INFO:root:At the start of the epoch: mem (CPU python)=22631.16015625MB; mem (CPU total)=22537.66796875MB
INFO:root:[   86] Training loss: 0.66443063, Validation loss: 0.66358809, Gradient norm: 0.16223161
INFO:root:At the start of the epoch: mem (CPU python)=22669.26171875MB; mem (CPU total)=22575.80859375MB
INFO:root:[   87] Training loss: 0.66446046, Validation loss: 0.66353086, Gradient norm: 0.17873629
INFO:root:At the start of the epoch: mem (CPU python)=22707.35546875MB; mem (CPU total)=22613.953125MB
INFO:root:[   88] Training loss: 0.66432742, Validation loss: 0.66369358, Gradient norm: 0.16027023
INFO:root:At the start of the epoch: mem (CPU python)=22745.44921875MB; mem (CPU total)=22652.08984375MB
INFO:root:[   89] Training loss: 0.66429688, Validation loss: 0.66334877, Gradient norm: 0.16886298
INFO:root:At the start of the epoch: mem (CPU python)=22783.546875MB; mem (CPU total)=22690.35546875MB
INFO:root:[   90] Training loss: 0.66414773, Validation loss: 0.66296221, Gradient norm: 0.16219182
INFO:root:At the start of the epoch: mem (CPU python)=22821.64453125MB; mem (CPU total)=22727.97265625MB
INFO:root:[   91] Training loss: 0.66425805, Validation loss: 0.66337786, Gradient norm: 0.16763942
INFO:root:At the start of the epoch: mem (CPU python)=22859.734375MB; mem (CPU total)=22766.35546875MB
INFO:root:[   92] Training loss: 0.66420474, Validation loss: 0.66350480, Gradient norm: 0.16076253
INFO:root:At the start of the epoch: mem (CPU python)=22897.83203125MB; mem (CPU total)=22804.5MB
INFO:root:[   93] Training loss: 0.66411718, Validation loss: 0.66319293, Gradient norm: 0.16256322
INFO:root:At the start of the epoch: mem (CPU python)=22935.92578125MB; mem (CPU total)=22842.85546875MB
INFO:root:[   94] Training loss: 0.66410880, Validation loss: 0.66274925, Gradient norm: 0.15744336
INFO:root:At the start of the epoch: mem (CPU python)=22974.0234375MB; mem (CPU total)=22880.76953125MB
INFO:root:[   95] Training loss: 0.66382724, Validation loss: 0.66265639, Gradient norm: 0.16217184
INFO:root:At the start of the epoch: mem (CPU python)=23012.1171875MB; mem (CPU total)=22919.06640625MB
INFO:root:[   96] Training loss: 0.66398535, Validation loss: 0.66310274, Gradient norm: 0.17071221
INFO:root:At the start of the epoch: mem (CPU python)=23050.21484375MB; mem (CPU total)=22957.45703125MB
INFO:root:[   97] Training loss: 0.66395261, Validation loss: 0.66342542, Gradient norm: 0.16613371
INFO:root:At the start of the epoch: mem (CPU python)=23088.30859375MB; mem (CPU total)=22995.6015625MB
INFO:root:[   98] Training loss: 0.66389949, Validation loss: 0.66387285, Gradient norm: 0.16493523
INFO:root:At the start of the epoch: mem (CPU python)=23126.40234375MB; mem (CPU total)=23033.74609375MB
INFO:root:[   99] Training loss: 0.66390761, Validation loss: 0.66249894, Gradient norm: 0.17259199
INFO:root:At the start of the epoch: mem (CPU python)=23164.50390625MB; mem (CPU total)=23071.75390625MB
INFO:root:[  100] Training loss: 0.66376264, Validation loss: 0.66270488, Gradient norm: 0.16320729
INFO:root:At the start of the epoch: mem (CPU python)=23202.59375MB; mem (CPU total)=23110.140625MB
INFO:root:[  101] Training loss: 0.66373235, Validation loss: 0.66276326, Gradient norm: 0.16894086
INFO:root:At the start of the epoch: mem (CPU python)=23240.6875MB; mem (CPU total)=23148.37109375MB
INFO:root:[  102] Training loss: 0.66346207, Validation loss: 0.66290890, Gradient norm: 0.16568161
INFO:root:At the start of the epoch: mem (CPU python)=23278.78515625MB; mem (CPU total)=23186.390625MB
INFO:root:[  103] Training loss: 0.66361410, Validation loss: 0.66295915, Gradient norm: 0.16858445
INFO:root:At the start of the epoch: mem (CPU python)=23316.8828125MB; mem (CPU total)=23224.53515625MB
INFO:root:[  104] Training loss: 0.66373768, Validation loss: 0.66245182, Gradient norm: 0.15966267
INFO:root:At the start of the epoch: mem (CPU python)=23354.98046875MB; mem (CPU total)=23262.7265625MB
INFO:root:[  105] Training loss: 0.66375934, Validation loss: 0.66336203, Gradient norm: 0.19451849
INFO:root:At the start of the epoch: mem (CPU python)=23393.0703125MB; mem (CPU total)=23300.8984375MB
INFO:root:[  106] Training loss: 0.66358891, Validation loss: 0.66299186, Gradient norm: 0.16765489
INFO:root:At the start of the epoch: mem (CPU python)=23431.16796875MB; mem (CPU total)=23338.7890625MB
INFO:root:[  107] Training loss: 0.66368115, Validation loss: 0.66314851, Gradient norm: 0.17401973
INFO:root:At the start of the epoch: mem (CPU python)=23469.26171875MB; mem (CPU total)=23377.1796875MB
INFO:root:[  108] Training loss: 0.66358664, Validation loss: 0.66292450, Gradient norm: 0.15730362
INFO:root:At the start of the epoch: mem (CPU python)=23507.359375MB; mem (CPU total)=23415.32421875MB
INFO:root:[  109] Training loss: 0.66369647, Validation loss: 0.66269473, Gradient norm: 0.16461567
INFO:root:At the start of the epoch: mem (CPU python)=23545.45703125MB; mem (CPU total)=23453.86328125MB
INFO:root:[  110] Training loss: 0.66353679, Validation loss: 0.66356000, Gradient norm: 0.16298262
INFO:root:At the start of the epoch: mem (CPU python)=23583.5546875MB; mem (CPU total)=23492.26953125MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  111] Training loss: 0.66346782, Validation loss: 0.66282861, Gradient norm: 0.16227928
INFO:root:At the start of the epoch: mem (CPU python)=23621.64453125MB; mem (CPU total)=23530.14453125MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  112] Training loss: 0.66237775, Validation loss: 0.66221704, Gradient norm: 0.14538373
INFO:root:At the start of the epoch: mem (CPU python)=23659.7421875MB; mem (CPU total)=23568.36328125MB
INFO:root:[  113] Training loss: 0.66180832, Validation loss: 0.66172758, Gradient norm: 0.13260539
INFO:root:At the start of the epoch: mem (CPU python)=23697.83984375MB; mem (CPU total)=23606.92578125MB
INFO:root:[  114] Training loss: 0.66173844, Validation loss: 0.66141544, Gradient norm: 0.13765536
INFO:root:At the start of the epoch: mem (CPU python)=23735.9375MB; mem (CPU total)=23644.81640625MB
INFO:root:[  115] Training loss: 0.66181462, Validation loss: 0.66148401, Gradient norm: 0.13806414
INFO:root:At the start of the epoch: mem (CPU python)=23774.02734375MB; mem (CPU total)=23683.20703125MB
INFO:root:[  116] Training loss: 0.66172240, Validation loss: 0.66095718, Gradient norm: 0.14601662
INFO:root:At the start of the epoch: mem (CPU python)=23812.12890625MB; mem (CPU total)=23721.24609375MB
INFO:root:[  117] Training loss: 0.66166171, Validation loss: 0.66141271, Gradient norm: 0.13760490
INFO:root:At the start of the epoch: mem (CPU python)=23850.21875MB; mem (CPU total)=23759.63671875MB
INFO:root:[  118] Training loss: 0.66160407, Validation loss: 0.66139666, Gradient norm: 0.14600077
INFO:root:At the start of the epoch: mem (CPU python)=23888.3125MB; mem (CPU total)=23797.53515625MB
INFO:root:[  119] Training loss: 0.66174590, Validation loss: 0.66133634, Gradient norm: 0.14560975
INFO:root:At the start of the epoch: mem (CPU python)=23926.40625MB; mem (CPU total)=23835.68359375MB
INFO:root:[  120] Training loss: 0.66161440, Validation loss: 0.66180039, Gradient norm: 0.14857584
INFO:root:At the start of the epoch: mem (CPU python)=23964.5078125MB; mem (CPU total)=23873.50390625MB
INFO:root:[  121] Training loss: 0.66165956, Validation loss: 0.66139286, Gradient norm: 0.15703633
INFO:root:At the start of the epoch: mem (CPU python)=24002.6015625MB; mem (CPU total)=23911.7890625MB
INFO:root:[  122] Training loss: 0.66158370, Validation loss: 0.66124998, Gradient norm: 0.14508048
INFO:root:At the start of the epoch: mem (CPU python)=24040.6953125MB; mem (CPU total)=23950.1640625MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  123] Training loss: 0.66154527, Validation loss: 0.66152819, Gradient norm: 0.14038848
INFO:root:At the start of the epoch: mem (CPU python)=24078.79296875MB; mem (CPU total)=23988.30078125MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  124] Training loss: 0.66120252, Validation loss: 0.66102817, Gradient norm: 0.13524674
INFO:root:At the start of the epoch: mem (CPU python)=24116.88671875MB; mem (CPU total)=24026.1953125MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  125] Training loss: 0.66091330, Validation loss: 0.66100520, Gradient norm: 0.12662069
INFO:root:At the start of the epoch: mem (CPU python)=24154.98046875MB; mem (CPU total)=24064.33984375MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  126] Training loss: 0.66093755, Validation loss: 0.66091504, Gradient norm: 0.12827372
INFO:root:At the start of the epoch: mem (CPU python)=24193.08203125MB; mem (CPU total)=24102.91796875MB
INFO:root:[  127] Training loss: 0.66091530, Validation loss: 0.66079120, Gradient norm: 0.12525250
INFO:root:At the start of the epoch: mem (CPU python)=24231.17578125MB; mem (CPU total)=24140.953125MB
INFO:root:[  128] Training loss: 0.66079142, Validation loss: 0.66109324, Gradient norm: 0.12917500
INFO:root:At the start of the epoch: mem (CPU python)=24269.2734375MB; mem (CPU total)=24178.734375MB
INFO:root:[  129] Training loss: 0.66108879, Validation loss: 0.66088659, Gradient norm: 0.12607518
INFO:root:At the start of the epoch: mem (CPU python)=24307.3671875MB; mem (CPU total)=24217.125MB
INFO:root:[  130] Training loss: 0.66088172, Validation loss: 0.66103794, Gradient norm: 0.12755926
INFO:root:At the start of the epoch: mem (CPU python)=24345.46484375MB; mem (CPU total)=24255.23828125MB
INFO:root:[  131] Training loss: 0.66078860, Validation loss: 0.66073845, Gradient norm: 0.12695773
INFO:root:At the start of the epoch: mem (CPU python)=24383.55859375MB; mem (CPU total)=24293.51171875MB
INFO:root:[  132] Training loss: 0.66081681, Validation loss: 0.66122459, Gradient norm: 0.13007155
INFO:root:At the start of the epoch: mem (CPU python)=24421.65234375MB; mem (CPU total)=24331.8828125MB
INFO:root:[  133] Training loss: 0.66082031, Validation loss: 0.66103061, Gradient norm: 0.12559528
INFO:root:At the start of the epoch: mem (CPU python)=24459.75MB; mem (CPU total)=24369.37890625MB
INFO:root:[  134] Training loss: 0.66087637, Validation loss: 0.66099033, Gradient norm: 0.12890507
INFO:root:At the start of the epoch: mem (CPU python)=24497.84375MB; mem (CPU total)=24407.5546875MB
INFO:root:[  135] Training loss: 0.66074967, Validation loss: 0.66109230, Gradient norm: 0.12534462
INFO:root:At the start of the epoch: mem (CPU python)=24535.9375MB; mem (CPU total)=24445.44921875MB
INFO:root:[  136] Training loss: 0.66087641, Validation loss: 0.66105939, Gradient norm: 0.12689927
INFO:root:At the start of the epoch: mem (CPU python)=24574.03515625MB; mem (CPU total)=24483.30078125MB
INFO:root:[  137] Training loss: 0.66110052, Validation loss: 0.66039114, Gradient norm: 0.13021674
INFO:root:At the start of the epoch: mem (CPU python)=24612.13671875MB; mem (CPU total)=24521.76953125MB
INFO:root:[  138] Training loss: 0.66083344, Validation loss: 0.66094509, Gradient norm: 0.13090575
INFO:root:At the start of the epoch: mem (CPU python)=24650.2265625MB; mem (CPU total)=24559.9140625MB
INFO:root:[  139] Training loss: 0.66096051, Validation loss: 0.66102974, Gradient norm: 0.12810180
INFO:root:At the start of the epoch: mem (CPU python)=24688.3203125MB; mem (CPU total)=24598.05859375MB
INFO:root:[  140] Training loss: 0.66080702, Validation loss: 0.66103265, Gradient norm: 0.13150433
INFO:root:At the start of the epoch: mem (CPU python)=24726.41796875MB; mem (CPU total)=24636.07421875MB
INFO:root:[  141] Training loss: 0.66091256, Validation loss: 0.66077700, Gradient norm: 0.13112215
INFO:root:At the start of the epoch: mem (CPU python)=24764.51171875MB; mem (CPU total)=24674.125MB
INFO:root:[  142] Training loss: 0.66082093, Validation loss: 0.66117681, Gradient norm: 0.12729832
INFO:root:At the start of the epoch: mem (CPU python)=24802.60546875MB; mem (CPU total)=24712.515625MB
INFO:root:[  143] Training loss: 0.66105184, Validation loss: 0.66101222, Gradient norm: 0.12354197
INFO:root:At the start of the epoch: mem (CPU python)=24840.70703125MB; mem (CPU total)=24750.66015625MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  144] Training loss: 0.66077875, Validation loss: 0.66097993, Gradient norm: 0.12633482
INFO:root:At the start of the epoch: mem (CPU python)=24878.80078125MB; mem (CPU total)=24788.48828125MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  145] Training loss: 0.66095578, Validation loss: 0.66068867, Gradient norm: 0.12598079
INFO:root:At the start of the epoch: mem (CPU python)=24916.89453125MB; mem (CPU total)=24826.34765625MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  146] Training loss: 0.66086300, Validation loss: 0.66087232, Gradient norm: 0.12898452
INFO:root:At the start of the epoch: mem (CPU python)=24954.98828125MB; mem (CPU total)=24864.4921875MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:EP 146: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=24992.953125MB; mem (CPU total)=24902.8828125MB
INFO:root:Training the model took 9885.706s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93424
INFO:root:EnergyScoreTrain: 0.6575
INFO:root:CRPSTrain: 0.53063
INFO:root:Gaussian NLLTrain: 8.79588
INFO:root:CoverageTrain: 0.91896
INFO:root:IntervalWidthTrain: 3.42826
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93907
INFO:root:EnergyScoreValidation: 0.66094
INFO:root:CRPSValidation: 0.53373
INFO:root:Gaussian NLLValidation: 4.52424
INFO:root:CoverageValidation: 0.91786
INFO:root:IntervalWidthValidation: 3.43133
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93792
INFO:root:EnergyScoreTest: 0.66012
INFO:root:CRPSTest: 0.53309
INFO:root:Gaussian NLLTest: 9.66356
INFO:root:CoverageTest: 0.91817
INFO:root:IntervalWidthTest: 3.43165
INFO:root:After validation: mem (CPU python)=25076.97265625MB; mem (CPU total)=24987.1171875MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=25076.97265625MB; mem (CPU total)=24987.36328125MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=25077.0078125MB; mem (CPU total)=24987.36328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=25077.0078125MB; mem (CPU total)=24987.36328125MB
INFO:root:[    1] Training loss: 0.71340534, Validation loss: 0.70210766, Gradient norm: 0.03922629
INFO:root:At the start of the epoch: mem (CPU python)=25114.921875MB; mem (CPU total)=25024.9140625MB
INFO:root:[    2] Training loss: 0.69627721, Validation loss: 0.69209404, Gradient norm: 0.07065595
INFO:root:At the start of the epoch: mem (CPU python)=25153.00390625MB; mem (CPU total)=25063.4453125MB
INFO:root:[    3] Training loss: 0.69089402, Validation loss: 0.68888825, Gradient norm: 0.08079937
INFO:root:At the start of the epoch: mem (CPU python)=25191.1171875MB; mem (CPU total)=25101.578125MB
INFO:root:[    4] Training loss: 0.68833989, Validation loss: 0.68849904, Gradient norm: 0.09263789
INFO:root:At the start of the epoch: mem (CPU python)=25229.21484375MB; mem (CPU total)=25139.94921875MB
INFO:root:[    5] Training loss: 0.68636335, Validation loss: 0.68524086, Gradient norm: 0.08717903
INFO:root:At the start of the epoch: mem (CPU python)=25267.31640625MB; mem (CPU total)=25177.890625MB
INFO:root:[    6] Training loss: 0.68478072, Validation loss: 0.68387902, Gradient norm: 0.08886155
INFO:root:At the start of the epoch: mem (CPU python)=25305.41015625MB; mem (CPU total)=25216.390625MB
INFO:root:[    7] Training loss: 0.68380103, Validation loss: 0.68347936, Gradient norm: 0.09401753
INFO:root:At the start of the epoch: mem (CPU python)=25343.50390625MB; mem (CPU total)=25254.3828125MB
INFO:root:[    8] Training loss: 0.68259840, Validation loss: 0.68180259, Gradient norm: 0.09349259
INFO:root:At the start of the epoch: mem (CPU python)=25381.6015625MB; mem (CPU total)=25292.984375MB
INFO:root:[    9] Training loss: 0.68185307, Validation loss: 0.68140697, Gradient norm: 0.09909820
INFO:root:At the start of the epoch: mem (CPU python)=25419.69921875MB; mem (CPU total)=25331.6484375MB
INFO:root:[   10] Training loss: 0.68093936, Validation loss: 0.68054422, Gradient norm: 0.10006731
INFO:root:At the start of the epoch: mem (CPU python)=25457.80078125MB; mem (CPU total)=25369.9296875MB
INFO:root:[   11] Training loss: 0.68001343, Validation loss: 0.67930269, Gradient norm: 0.10522798
INFO:root:At the start of the epoch: mem (CPU python)=25495.8984375MB; mem (CPU total)=25407.9296875MB
INFO:root:[   12] Training loss: 0.67922534, Validation loss: 0.67782595, Gradient norm: 0.11197972
INFO:root:At the start of the epoch: mem (CPU python)=25533.9921875MB; mem (CPU total)=25445.94921875MB
INFO:root:[   13] Training loss: 0.67861859, Validation loss: 0.67720883, Gradient norm: 0.11875190
INFO:root:At the start of the epoch: mem (CPU python)=25572.08984375MB; mem (CPU total)=25484.28125MB
INFO:root:[   14] Training loss: 0.67765246, Validation loss: 0.67727054, Gradient norm: 0.11583148
INFO:root:At the start of the epoch: mem (CPU python)=25610.1796875MB; mem (CPU total)=25522.69921875MB
INFO:root:[   15] Training loss: 0.67686792, Validation loss: 0.67648294, Gradient norm: 0.12048479
INFO:root:At the start of the epoch: mem (CPU python)=25648.27734375MB; mem (CPU total)=25560.65625MB
INFO:root:[   16] Training loss: 0.67649404, Validation loss: 0.67521878, Gradient norm: 0.12883017
INFO:root:At the start of the epoch: mem (CPU python)=25686.375MB; mem (CPU total)=25598.51953125MB
INFO:root:[   17] Training loss: 0.67589467, Validation loss: 0.67534873, Gradient norm: 0.13636701
INFO:root:At the start of the epoch: mem (CPU python)=25724.46875MB; mem (CPU total)=25637.26953125MB
INFO:root:[   18] Training loss: 0.67536732, Validation loss: 0.67460609, Gradient norm: 0.13131560
INFO:root:At the start of the epoch: mem (CPU python)=25762.5625MB; mem (CPU total)=25674.890625MB
INFO:root:[   19] Training loss: 0.67485980, Validation loss: 0.67373594, Gradient norm: 0.13667410
INFO:root:At the start of the epoch: mem (CPU python)=25800.66015625MB; mem (CPU total)=25713.4765625MB
INFO:root:[   20] Training loss: 0.67431350, Validation loss: 0.67418963, Gradient norm: 0.13346420
INFO:root:At the start of the epoch: mem (CPU python)=25838.75390625MB; mem (CPU total)=25751.89453125MB
INFO:root:[   21] Training loss: 0.67410517, Validation loss: 0.67334812, Gradient norm: 0.14771612
INFO:root:At the start of the epoch: mem (CPU python)=25876.8515625MB; mem (CPU total)=25789.62109375MB
INFO:root:[   22] Training loss: 0.67335380, Validation loss: 0.67282870, Gradient norm: 0.13550465
INFO:root:At the start of the epoch: mem (CPU python)=25914.94921875MB; mem (CPU total)=25828.55859375MB
INFO:root:[   23] Training loss: 0.67346328, Validation loss: 0.67304883, Gradient norm: 0.14981577
INFO:root:At the start of the epoch: mem (CPU python)=25953.0390625MB; mem (CPU total)=25866.8359375MB
INFO:root:[   24] Training loss: 0.67310343, Validation loss: 0.67212448, Gradient norm: 0.14366285
INFO:root:At the start of the epoch: mem (CPU python)=25991.13671875MB; mem (CPU total)=25904.96484375MB
INFO:root:[   25] Training loss: 0.67274301, Validation loss: 0.67199771, Gradient norm: 0.13715034
INFO:root:At the start of the epoch: mem (CPU python)=26029.23046875MB; mem (CPU total)=25943.375MB
INFO:root:[   26] Training loss: 0.67262212, Validation loss: 0.67157701, Gradient norm: 0.14718054
INFO:root:At the start of the epoch: mem (CPU python)=26067.328125MB; mem (CPU total)=25981.5MB
INFO:root:[   27] Training loss: 0.67218892, Validation loss: 0.67133400, Gradient norm: 0.14613891
INFO:root:At the start of the epoch: mem (CPU python)=26105.42578125MB; mem (CPU total)=26019.625MB
INFO:root:[   28] Training loss: 0.67204869, Validation loss: 0.67073618, Gradient norm: 0.14999933
INFO:root:At the start of the epoch: mem (CPU python)=26143.51953125MB; mem (CPU total)=26057.9453125MB
INFO:root:[   29] Training loss: 0.67188664, Validation loss: 0.67088796, Gradient norm: 0.14716682
INFO:root:At the start of the epoch: mem (CPU python)=26181.61328125MB; mem (CPU total)=26096.28515625MB
INFO:root:[   30] Training loss: 0.67176706, Validation loss: 0.67081668, Gradient norm: 0.15384671
INFO:root:At the start of the epoch: mem (CPU python)=26219.70703125MB; mem (CPU total)=26134.44921875MB
INFO:root:[   31] Training loss: 0.67143456, Validation loss: 0.67090232, Gradient norm: 0.15618969
INFO:root:At the start of the epoch: mem (CPU python)=26257.80078125MB; mem (CPU total)=26172.62109375MB
INFO:root:[   32] Training loss: 0.67123481, Validation loss: 0.67071990, Gradient norm: 0.14107925
INFO:root:At the start of the epoch: mem (CPU python)=26295.8984375MB; mem (CPU total)=26210.640625MB
INFO:root:[   33] Training loss: 0.67119660, Validation loss: 0.67014573, Gradient norm: 0.14777597
INFO:root:At the start of the epoch: mem (CPU python)=26333.99609375MB; mem (CPU total)=26248.36328125MB
INFO:root:[   34] Training loss: 0.67096458, Validation loss: 0.67031928, Gradient norm: 0.15170008
INFO:root:At the start of the epoch: mem (CPU python)=26372.08984375MB; mem (CPU total)=26287.0234375MB
INFO:root:[   35] Training loss: 0.67099593, Validation loss: 0.67004566, Gradient norm: 0.15115775
INFO:root:At the start of the epoch: mem (CPU python)=26410.18359375MB; mem (CPU total)=26325.2734375MB
INFO:root:[   36] Training loss: 0.67063181, Validation loss: 0.67021147, Gradient norm: 0.15547089
INFO:root:At the start of the epoch: mem (CPU python)=26448.28125MB; mem (CPU total)=26363.25390625MB
INFO:root:[   37] Training loss: 0.67054020, Validation loss: 0.66960239, Gradient norm: 0.15957030
INFO:root:At the start of the epoch: mem (CPU python)=26486.37890625MB; mem (CPU total)=26400.7265625MB
INFO:root:[   38] Training loss: 0.67048886, Validation loss: 0.66883910, Gradient norm: 0.15290739
INFO:root:At the start of the epoch: mem (CPU python)=26524.47265625MB; mem (CPU total)=26439.13671875MB
INFO:root:[   39] Training loss: 0.67009490, Validation loss: 0.66950817, Gradient norm: 0.15573980
INFO:root:At the start of the epoch: mem (CPU python)=26562.5703125MB; mem (CPU total)=26477.30859375MB
INFO:root:[   40] Training loss: 0.67000805, Validation loss: 0.66887809, Gradient norm: 0.15783145
INFO:root:At the start of the epoch: mem (CPU python)=26600.6640625MB; mem (CPU total)=26515.875MB
INFO:root:[   41] Training loss: 0.66975569, Validation loss: 0.66913244, Gradient norm: 0.16553744
INFO:root:At the start of the epoch: mem (CPU python)=26638.76171875MB; mem (CPU total)=26553.87109375MB
INFO:root:[   42] Training loss: 0.66946972, Validation loss: 0.66869662, Gradient norm: 0.15511144
INFO:root:At the start of the epoch: mem (CPU python)=26676.85546875MB; mem (CPU total)=26591.53515625MB
INFO:root:[   43] Training loss: 0.66944653, Validation loss: 0.66924919, Gradient norm: 0.15886006
INFO:root:At the start of the epoch: mem (CPU python)=26714.94921875MB; mem (CPU total)=26629.921875MB
INFO:root:[   44] Training loss: 0.66907359, Validation loss: 0.66836201, Gradient norm: 0.16595285
INFO:root:At the start of the epoch: mem (CPU python)=26753.046875MB; mem (CPU total)=26667.92578125MB
INFO:root:[   45] Training loss: 0.66889053, Validation loss: 0.66779131, Gradient norm: 0.16501874
INFO:root:At the start of the epoch: mem (CPU python)=26791.14453125MB; mem (CPU total)=26706.4765625MB
INFO:root:[   46] Training loss: 0.66873384, Validation loss: 0.66768765, Gradient norm: 0.15526564
INFO:root:At the start of the epoch: mem (CPU python)=26829.2421875MB; mem (CPU total)=26744.4296875MB
INFO:root:[   47] Training loss: 0.66856686, Validation loss: 0.66782838, Gradient norm: 0.16691494
INFO:root:At the start of the epoch: mem (CPU python)=26867.33203125MB; mem (CPU total)=26783.09375MB
INFO:root:[   48] Training loss: 0.66861070, Validation loss: 0.66736737, Gradient norm: 0.16927016
INFO:root:At the start of the epoch: mem (CPU python)=26905.4296875MB; mem (CPU total)=26821.25MB
INFO:root:[   49] Training loss: 0.66832445, Validation loss: 0.66792538, Gradient norm: 0.16131908
INFO:root:At the start of the epoch: mem (CPU python)=26943.51953125MB; mem (CPU total)=26859.640625MB
INFO:root:[   50] Training loss: 0.66822309, Validation loss: 0.66697630, Gradient norm: 0.15895324
INFO:root:At the start of the epoch: mem (CPU python)=26981.62109375MB; mem (CPU total)=26897.3828125MB
INFO:root:[   51] Training loss: 0.66799082, Validation loss: 0.66841804, Gradient norm: 0.16056421
INFO:root:At the start of the epoch: mem (CPU python)=27019.71484375MB; mem (CPU total)=26935.5546875MB
INFO:root:[   52] Training loss: 0.66785866, Validation loss: 0.66705204, Gradient norm: 0.16383055
INFO:root:At the start of the epoch: mem (CPU python)=27057.80859375MB; mem (CPU total)=26973.234375MB
INFO:root:[   53] Training loss: 0.66789123, Validation loss: 0.66696106, Gradient norm: 0.15749715
INFO:root:At the start of the epoch: mem (CPU python)=27095.91015625MB; mem (CPU total)=27011.6015625MB
INFO:root:[   54] Training loss: 0.66771447, Validation loss: 0.66718521, Gradient norm: 0.15896466
INFO:root:At the start of the epoch: mem (CPU python)=27134.0MB; mem (CPU total)=27050.30078125MB
INFO:root:[   55] Training loss: 0.66760857, Validation loss: 0.66677930, Gradient norm: 0.16076741
INFO:root:At the start of the epoch: mem (CPU python)=27172.09765625MB; mem (CPU total)=27088.71875MB
INFO:root:[   56] Training loss: 0.66749194, Validation loss: 0.66605401, Gradient norm: 0.15592293
INFO:root:At the start of the epoch: mem (CPU python)=27210.1953125MB; mem (CPU total)=27126.74609375MB
INFO:root:[   57] Training loss: 0.66752809, Validation loss: 0.66655462, Gradient norm: 0.17157262
INFO:root:At the start of the epoch: mem (CPU python)=27248.28515625MB; mem (CPU total)=27164.88671875MB
INFO:root:[   58] Training loss: 0.66739327, Validation loss: 0.66634404, Gradient norm: 0.16856033
INFO:root:At the start of the epoch: mem (CPU python)=27286.3828125MB; mem (CPU total)=27203.296875MB
INFO:root:[   59] Training loss: 0.66724786, Validation loss: 0.66600244, Gradient norm: 0.16136392
INFO:root:At the start of the epoch: mem (CPU python)=27324.4765625MB; mem (CPU total)=27241.21875MB
INFO:root:[   60] Training loss: 0.66698698, Validation loss: 0.66620745, Gradient norm: 0.14847159
INFO:root:At the start of the epoch: mem (CPU python)=27362.57421875MB; mem (CPU total)=27279.14453125MB
INFO:root:[   61] Training loss: 0.66713143, Validation loss: 0.66601882, Gradient norm: 0.16654969
INFO:root:At the start of the epoch: mem (CPU python)=27400.66796875MB; mem (CPU total)=27317.30859375MB
INFO:root:[   62] Training loss: 0.66689471, Validation loss: 0.66624869, Gradient norm: 0.15396383
INFO:root:At the start of the epoch: mem (CPU python)=27438.76171875MB; mem (CPU total)=27355.05078125MB
INFO:root:[   63] Training loss: 0.66694168, Validation loss: 0.66616913, Gradient norm: 0.15580255
INFO:root:At the start of the epoch: mem (CPU python)=27476.859375MB; mem (CPU total)=27393.01953125MB
INFO:root:[   64] Training loss: 0.66666678, Validation loss: 0.66617849, Gradient norm: 0.16480661
INFO:root:At the start of the epoch: mem (CPU python)=27514.953125MB; mem (CPU total)=27431.41015625MB
INFO:root:[   65] Training loss: 0.66670682, Validation loss: 0.66630284, Gradient norm: 0.15535240
INFO:root:At the start of the epoch: mem (CPU python)=27553.05078125MB; mem (CPU total)=27469.55078125MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   66] Training loss: 0.66659542, Validation loss: 0.66570739, Gradient norm: 0.15053165
INFO:root:At the start of the epoch: mem (CPU python)=27591.14453125MB; mem (CPU total)=27507.296875MB
INFO:root:[   67] Training loss: 0.66545803, Validation loss: 0.66487351, Gradient norm: 0.14412573
INFO:root:At the start of the epoch: mem (CPU python)=27629.2421875MB; mem (CPU total)=27545.78125MB
INFO:root:[   68] Training loss: 0.66557346, Validation loss: 0.66443971, Gradient norm: 0.14612004
INFO:root:At the start of the epoch: mem (CPU python)=27667.3359375MB; mem (CPU total)=27584.54296875MB
INFO:root:[   69] Training loss: 0.66527485, Validation loss: 0.66442699, Gradient norm: 0.13464125
INFO:root:At the start of the epoch: mem (CPU python)=27705.43359375MB; mem (CPU total)=27622.8125MB
INFO:root:[   70] Training loss: 0.66516557, Validation loss: 0.66431746, Gradient norm: 0.15170140
INFO:root:At the start of the epoch: mem (CPU python)=27743.53125MB; mem (CPU total)=27661.58984375MB
INFO:root:[   71] Training loss: 0.66513061, Validation loss: 0.66464047, Gradient norm: 0.14475932
INFO:root:At the start of the epoch: mem (CPU python)=27781.62109375MB; mem (CPU total)=27699.75MB
INFO:root:[   72] Training loss: 0.66497942, Validation loss: 0.66452892, Gradient norm: 0.14120171
INFO:root:At the start of the epoch: mem (CPU python)=27819.71484375MB; mem (CPU total)=27737.5859375MB
INFO:root:[   73] Training loss: 0.66504385, Validation loss: 0.66541565, Gradient norm: 0.14826490
INFO:root:At the start of the epoch: mem (CPU python)=27857.81640625MB; mem (CPU total)=27775.578125MB
INFO:root:[   74] Training loss: 0.66515118, Validation loss: 0.66437350, Gradient norm: 0.14682592
INFO:root:At the start of the epoch: mem (CPU python)=27895.91015625MB; mem (CPU total)=27813.61328125MB
INFO:root:[   75] Training loss: 0.66498643, Validation loss: 0.66426745, Gradient norm: 0.14346438
INFO:root:At the start of the epoch: mem (CPU python)=27934.00390625MB; mem (CPU total)=27851.3203125MB
INFO:root:[   76] Training loss: 0.66503808, Validation loss: 0.66426709, Gradient norm: 0.14397837
INFO:root:At the start of the epoch: mem (CPU python)=27972.09765625MB; mem (CPU total)=27889.51171875MB
INFO:root:[   77] Training loss: 0.66498437, Validation loss: 0.66465806, Gradient norm: 0.14973087
INFO:root:At the start of the epoch: mem (CPU python)=28010.1953125MB; mem (CPU total)=27927.90234375MB
INFO:root:[   78] Training loss: 0.66487952, Validation loss: 0.66435100, Gradient norm: 0.14794274
INFO:root:At the start of the epoch: mem (CPU python)=28048.2890625MB; mem (CPU total)=27966.09375MB
INFO:root:[   79] Training loss: 0.66482098, Validation loss: 0.66446658, Gradient norm: 0.14676975
INFO:root:At the start of the epoch: mem (CPU python)=28086.3828125MB; mem (CPU total)=28003.9296875MB
INFO:root:[   80] Training loss: 0.66489781, Validation loss: 0.66442566, Gradient norm: 0.14486203
INFO:root:At the start of the epoch: mem (CPU python)=28124.48046875MB; mem (CPU total)=28041.734375MB
INFO:root:[   81] Training loss: 0.66484607, Validation loss: 0.66399004, Gradient norm: 0.14369702
INFO:root:At the start of the epoch: mem (CPU python)=28162.58203125MB; mem (CPU total)=28080.1328125MB
INFO:root:[   82] Training loss: 0.66470816, Validation loss: 0.66408916, Gradient norm: 0.15295034
INFO:root:At the start of the epoch: mem (CPU python)=28200.671875MB; mem (CPU total)=28118.69140625MB
INFO:root:[   83] Training loss: 0.66472859, Validation loss: 0.66409627, Gradient norm: 0.15251148
INFO:root:At the start of the epoch: mem (CPU python)=28238.765625MB; mem (CPU total)=28156.99609375MB
INFO:root:[   84] Training loss: 0.66460395, Validation loss: 0.66431896, Gradient norm: 0.15007573
INFO:root:At the start of the epoch: mem (CPU python)=28276.8671875MB; mem (CPU total)=28195.13671875MB
INFO:root:[   85] Training loss: 0.66472820, Validation loss: 0.66398771, Gradient norm: 0.14999554
INFO:root:At the start of the epoch: mem (CPU python)=28314.96484375MB; mem (CPU total)=28233.01171875MB
INFO:root:[   86] Training loss: 0.66448416, Validation loss: 0.66409743, Gradient norm: 0.15451700
INFO:root:At the start of the epoch: mem (CPU python)=28353.0546875MB; mem (CPU total)=28270.96875MB
INFO:root:[   87] Training loss: 0.66456045, Validation loss: 0.66443776, Gradient norm: 0.14537633
INFO:root:At the start of the epoch: mem (CPU python)=28391.15234375MB; mem (CPU total)=28309.33203125MB
INFO:root:[   88] Training loss: 0.66431617, Validation loss: 0.66380709, Gradient norm: 0.14999366
INFO:root:At the start of the epoch: mem (CPU python)=28429.25MB; mem (CPU total)=28347.66015625MB
INFO:root:[   89] Training loss: 0.66438837, Validation loss: 0.66372237, Gradient norm: 0.14737277
INFO:root:At the start of the epoch: mem (CPU python)=28467.34375MB; mem (CPU total)=28385.31640625MB
INFO:root:[   90] Training loss: 0.66426268, Validation loss: 0.66395151, Gradient norm: 0.14444702
INFO:root:At the start of the epoch: mem (CPU python)=28505.44140625MB; mem (CPU total)=28423.70703125MB
INFO:root:[   91] Training loss: 0.66442458, Validation loss: 0.66410284, Gradient norm: 0.15224871
INFO:root:At the start of the epoch: mem (CPU python)=28543.53515625MB; mem (CPU total)=28461.8515625MB
INFO:root:[   92] Training loss: 0.66425505, Validation loss: 0.66442157, Gradient norm: 0.15024523
INFO:root:At the start of the epoch: mem (CPU python)=28581.62890625MB; mem (CPU total)=28499.99609375MB
INFO:root:[   93] Training loss: 0.66431410, Validation loss: 0.66380205, Gradient norm: 0.14637928
INFO:root:At the start of the epoch: mem (CPU python)=28619.72265625MB; mem (CPU total)=28537.5546875MB
INFO:root:[   94] Training loss: 0.66413608, Validation loss: 0.66379518, Gradient norm: 0.14102730
INFO:root:At the start of the epoch: mem (CPU python)=28657.8203125MB; mem (CPU total)=28576.1171875MB
INFO:root:[   95] Training loss: 0.66420141, Validation loss: 0.66414223, Gradient norm: 0.15416512
INFO:root:At the start of the epoch: mem (CPU python)=28695.9140625MB; mem (CPU total)=28614.23828125MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   96] Training loss: 0.66409183, Validation loss: 0.66379751, Gradient norm: 0.14749145
INFO:root:At the start of the epoch: mem (CPU python)=28734.01171875MB; mem (CPU total)=28652.3828125MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   97] Training loss: 0.66363056, Validation loss: 0.66340415, Gradient norm: 0.14338132
INFO:root:At the start of the epoch: mem (CPU python)=28772.109375MB; mem (CPU total)=28690.58984375MB
INFO:root:[   98] Training loss: 0.66310934, Validation loss: 0.66298978, Gradient norm: 0.12203995
INFO:root:At the start of the epoch: mem (CPU python)=28810.203125MB; mem (CPU total)=28728.91015625MB
INFO:root:[   99] Training loss: 0.66310736, Validation loss: 0.66302903, Gradient norm: 0.12373682
INFO:root:At the start of the epoch: mem (CPU python)=28848.296875MB; mem (CPU total)=28766.80859375MB
INFO:root:[  100] Training loss: 0.66315492, Validation loss: 0.66316277, Gradient norm: 0.12317966
INFO:root:At the start of the epoch: mem (CPU python)=28886.390625MB; mem (CPU total)=28803.9453125MB
INFO:root:[  101] Training loss: 0.66292124, Validation loss: 0.66291479, Gradient norm: 0.13160684
INFO:root:At the start of the epoch: mem (CPU python)=28924.4921875MB; mem (CPU total)=28842.23046875MB
INFO:root:[  102] Training loss: 0.66317205, Validation loss: 0.66319196, Gradient norm: 0.13106452
INFO:root:At the start of the epoch: mem (CPU python)=28962.58203125MB; mem (CPU total)=28880.2109375MB
INFO:root:[  103] Training loss: 0.66295403, Validation loss: 0.66291133, Gradient norm: 0.13296483
INFO:root:At the start of the epoch: mem (CPU python)=29000.6796875MB; mem (CPU total)=28918.07421875MB
INFO:root:[  104] Training loss: 0.66305833, Validation loss: 0.66289414, Gradient norm: 0.13376463
INFO:root:At the start of the epoch: mem (CPU python)=29038.77734375MB; mem (CPU total)=28955.9765625MB
INFO:root:[  105] Training loss: 0.66293982, Validation loss: 0.66277787, Gradient norm: 0.12936673
INFO:root:At the start of the epoch: mem (CPU python)=29076.87109375MB; mem (CPU total)=28994.53515625MB
INFO:root:[  106] Training loss: 0.66299660, Validation loss: 0.66300635, Gradient norm: 0.12924267
INFO:root:At the start of the epoch: mem (CPU python)=29114.9609375MB; mem (CPU total)=29036.0MB
INFO:root:[  107] Training loss: 0.66296520, Validation loss: 0.66296464, Gradient norm: 0.14062122
INFO:root:At the start of the epoch: mem (CPU python)=29153.05859375MB; mem (CPU total)=29074.265625MB
INFO:root:[  108] Training loss: 0.66276236, Validation loss: 0.66252831, Gradient norm: 0.13184003
INFO:root:At the start of the epoch: mem (CPU python)=29191.15625MB; mem (CPU total)=29110.7734375MB
INFO:root:[  109] Training loss: 0.66277185, Validation loss: 0.66257293, Gradient norm: 0.13595107
INFO:root:At the start of the epoch: mem (CPU python)=29229.24609375MB; mem (CPU total)=29148.29296875MB
INFO:root:[  110] Training loss: 0.66293275, Validation loss: 0.66289644, Gradient norm: 0.13598956
INFO:root:At the start of the epoch: mem (CPU python)=29267.34375MB; mem (CPU total)=29185.48828125MB
INFO:root:[  111] Training loss: 0.66282950, Validation loss: 0.66282619, Gradient norm: 0.13021566
INFO:root:At the start of the epoch: mem (CPU python)=29305.44140625MB; mem (CPU total)=29223.37109375MB
INFO:root:[  112] Training loss: 0.66279666, Validation loss: 0.66279078, Gradient norm: 0.13605285
INFO:root:At the start of the epoch: mem (CPU python)=29343.53515625MB; mem (CPU total)=29261.19921875MB
INFO:root:[  113] Training loss: 0.66275607, Validation loss: 0.66249694, Gradient norm: 0.13950139
INFO:root:At the start of the epoch: mem (CPU python)=29381.6328125MB; mem (CPU total)=29299.60546875MB
INFO:root:[  114] Training loss: 0.66281876, Validation loss: 0.66259169, Gradient norm: 0.13600740
INFO:root:At the start of the epoch: mem (CPU python)=29419.7265625MB; mem (CPU total)=29337.984375MB
INFO:root:[  115] Training loss: 0.66277600, Validation loss: 0.66329582, Gradient norm: 0.13102778
INFO:root:At the start of the epoch: mem (CPU python)=29457.8203125MB; mem (CPU total)=29376.16015625MB
INFO:root:[  116] Training loss: 0.66275045, Validation loss: 0.66307743, Gradient norm: 0.13769129
INFO:root:At the start of the epoch: mem (CPU python)=29495.9140625MB; mem (CPU total)=29413.8125MB
INFO:root:[  117] Training loss: 0.66281737, Validation loss: 0.66273251, Gradient norm: 0.13107533
INFO:root:At the start of the epoch: mem (CPU python)=29534.01171875MB; mem (CPU total)=29451.859375MB
INFO:root:[  118] Training loss: 0.66264468, Validation loss: 0.66268602, Gradient norm: 0.13409293
INFO:root:At the start of the epoch: mem (CPU python)=29572.109375MB; mem (CPU total)=29490.625MB
INFO:root:[  119] Training loss: 0.66288197, Validation loss: 0.66306117, Gradient norm: 0.13574962
INFO:root:At the start of the epoch: mem (CPU python)=29610.203125MB; mem (CPU total)=29528.07421875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  120] Training loss: 0.66277008, Validation loss: 0.66258326, Gradient norm: 0.13097069
INFO:root:At the start of the epoch: mem (CPU python)=29648.296875MB; mem (CPU total)=29565.75MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  121] Training loss: 0.66250741, Validation loss: 0.66239338, Gradient norm: 0.12933592
INFO:root:At the start of the epoch: mem (CPU python)=29686.40234375MB; mem (CPU total)=29603.44921875MB
INFO:root:[  122] Training loss: 0.66253807, Validation loss: 0.66264670, Gradient norm: 0.12541380
INFO:root:At the start of the epoch: mem (CPU python)=29724.4921875MB; mem (CPU total)=29641.5859375MB
INFO:root:[  123] Training loss: 0.66248739, Validation loss: 0.66287927, Gradient norm: 0.12823199
INFO:root:At the start of the epoch: mem (CPU python)=29762.5859375MB; mem (CPU total)=29680.0078125MB
INFO:root:[  124] Training loss: 0.66242643, Validation loss: 0.66236977, Gradient norm: 0.12340223
INFO:root:At the start of the epoch: mem (CPU python)=29800.6875MB; mem (CPU total)=29718.53515625MB
INFO:root:[  125] Training loss: 0.66232296, Validation loss: 0.66261561, Gradient norm: 0.12806905
INFO:root:At the start of the epoch: mem (CPU python)=29838.78125MB; mem (CPU total)=29756.6796875MB
INFO:root:[  126] Training loss: 0.66253043, Validation loss: 0.66264997, Gradient norm: 0.12360631
INFO:root:At the start of the epoch: mem (CPU python)=29876.875MB; mem (CPU total)=29794.328125MB
INFO:root:[  127] Training loss: 0.66243155, Validation loss: 0.66240465, Gradient norm: 0.12908040
INFO:root:At the start of the epoch: mem (CPU python)=29914.96875MB; mem (CPU total)=29832.47265625MB
INFO:root:[  128] Training loss: 0.66232190, Validation loss: 0.66246709, Gradient norm: 0.12558192
INFO:root:At the start of the epoch: mem (CPU python)=29953.0625MB; mem (CPU total)=29870.03125MB
INFO:root:[  129] Training loss: 0.66234478, Validation loss: 0.66239500, Gradient norm: 0.12821752
INFO:root:At the start of the epoch: mem (CPU python)=29991.16015625MB; mem (CPU total)=29908.66796875MB
INFO:root:[  130] Training loss: 0.66235244, Validation loss: 0.66261139, Gradient norm: 0.13005081
INFO:root:At the start of the epoch: mem (CPU python)=30029.25390625MB; mem (CPU total)=29947.2890625MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  131] Training loss: 0.66238332, Validation loss: 0.66233258, Gradient norm: 0.12839766
INFO:root:At the start of the epoch: mem (CPU python)=30067.35546875MB; mem (CPU total)=29985.53515625MB
INFO:root:[  132] Training loss: 0.66228837, Validation loss: 0.66229760, Gradient norm: 0.12704781
INFO:root:At the start of the epoch: mem (CPU python)=30105.44921875MB; mem (CPU total)=30023.6796875MB
INFO:root:[  133] Training loss: 0.66242255, Validation loss: 0.66255600, Gradient norm: 0.12790782
INFO:root:At the start of the epoch: mem (CPU python)=30143.5390625MB; mem (CPU total)=30061.83984375MB
INFO:root:[  134] Training loss: 0.66242732, Validation loss: 0.66214876, Gradient norm: 0.12938050
INFO:root:At the start of the epoch: mem (CPU python)=30181.63671875MB; mem (CPU total)=30099.953125MB
INFO:root:[  135] Training loss: 0.66229846, Validation loss: 0.66234183, Gradient norm: 0.12638540
INFO:root:At the start of the epoch: mem (CPU python)=30219.73828125MB; mem (CPU total)=30138.33984375MB
INFO:root:[  136] Training loss: 0.66228096, Validation loss: 0.66256059, Gradient norm: 0.12460985
INFO:root:At the start of the epoch: mem (CPU python)=30257.83203125MB; mem (CPU total)=30176.484375MB
INFO:root:[  137] Training loss: 0.66230206, Validation loss: 0.66204414, Gradient norm: 0.12677844
INFO:root:At the start of the epoch: mem (CPU python)=30295.9296875MB; mem (CPU total)=30214.81640625MB
INFO:root:[  138] Training loss: 0.66211457, Validation loss: 0.66212947, Gradient norm: 0.12707280
INFO:root:At the start of the epoch: mem (CPU python)=30334.0234375MB; mem (CPU total)=30253.171875MB
INFO:root:[  139] Training loss: 0.66234675, Validation loss: 0.66232262, Gradient norm: 0.12809167
INFO:root:At the start of the epoch: mem (CPU python)=30372.1171875MB; mem (CPU total)=30291.5625MB
INFO:root:[  140] Training loss: 0.66212517, Validation loss: 0.66247227, Gradient norm: 0.12760978
INFO:root:At the start of the epoch: mem (CPU python)=30410.2109375MB; mem (CPU total)=30329.70703125MB
INFO:root:[  141] Training loss: 0.66238234, Validation loss: 0.66255045, Gradient norm: 0.12678620
INFO:root:At the start of the epoch: mem (CPU python)=30448.30859375MB; mem (CPU total)=30367.703125MB
INFO:root:[  142] Training loss: 0.66234792, Validation loss: 0.66252216, Gradient norm: 0.12663933
INFO:root:At the start of the epoch: mem (CPU python)=30486.40625MB; mem (CPU total)=30406.0625MB
INFO:root:[  143] Training loss: 0.66224954, Validation loss: 0.66248048, Gradient norm: 0.12770841
INFO:root:At the start of the epoch: mem (CPU python)=30524.5MB; mem (CPU total)=30444.20703125MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  144] Training loss: 0.66227139, Validation loss: 0.66238412, Gradient norm: 0.12504825
INFO:root:At the start of the epoch: mem (CPU python)=30562.59375MB; mem (CPU total)=30482.34765625MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  145] Training loss: 0.66226220, Validation loss: 0.66249048, Gradient norm: 0.12747643
INFO:root:At the start of the epoch: mem (CPU python)=30600.69140625MB; mem (CPU total)=30520.73828125MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  146] Training loss: 0.66244900, Validation loss: 0.66230424, Gradient norm: 0.12487621
INFO:root:At the start of the epoch: mem (CPU python)=30638.78515625MB; mem (CPU total)=30558.6328125MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:EP 146: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=30676.87890625MB; mem (CPU total)=30596.77734375MB
INFO:root:Training the model took 10950.991s.
INFO:root:Emptying the cuda cache took 0.009s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93703
INFO:root:EnergyScoreTrain: 0.65947
INFO:root:CRPSTrain: 0.5305
INFO:root:Gaussian NLLTrain: 1.40608
INFO:root:CoverageTrain: 0.92359
INFO:root:IntervalWidthTrain: 3.43804
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94128
INFO:root:EnergyScoreValidation: 0.66249
INFO:root:CRPSValidation: 0.5333
INFO:root:Gaussian NLLValidation: 1.41174
INFO:root:CoverageValidation: 0.92246
INFO:root:IntervalWidthValidation: 3.44079
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94029
INFO:root:EnergyScoreTest: 0.66178
INFO:root:CRPSTest: 0.53271
INFO:root:Gaussian NLLTest: 1.41021
INFO:root:CoverageTest: 0.92235
INFO:root:IntervalWidthTest: 3.43813
INFO:root:After validation: mem (CPU python)=30720.296875MB; mem (CPU total)=30642.30859375MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=30720.296875MB; mem (CPU total)=30642.1171875MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=30720.4453125MB; mem (CPU total)=30642.1171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=30720.47265625MB; mem (CPU total)=30642.3828125MB
INFO:root:[    1] Training loss: 0.71230468, Validation loss: 0.70170356, Gradient norm: 0.03867746
INFO:root:At the start of the epoch: mem (CPU python)=30758.24609375MB; mem (CPU total)=30680.3984375MB
INFO:root:[    2] Training loss: 0.69744933, Validation loss: 0.69362169, Gradient norm: 0.06508917
INFO:root:At the start of the epoch: mem (CPU python)=30796.3359375MB; mem (CPU total)=30717.62890625MB
INFO:root:[    3] Training loss: 0.69184851, Validation loss: 0.69042471, Gradient norm: 0.08783510
INFO:root:At the start of the epoch: mem (CPU python)=30834.4375MB; mem (CPU total)=30755.72265625MB
INFO:root:[    4] Training loss: 0.68885885, Validation loss: 0.68741631, Gradient norm: 0.09637241
INFO:root:At the start of the epoch: mem (CPU python)=30872.53125MB; mem (CPU total)=30793.6484375MB
INFO:root:[    5] Training loss: 0.68679887, Validation loss: 0.68590318, Gradient norm: 0.09672435
INFO:root:At the start of the epoch: mem (CPU python)=30910.625MB; mem (CPU total)=30832.10546875MB
INFO:root:[    6] Training loss: 0.68532152, Validation loss: 0.68468177, Gradient norm: 0.09913506
INFO:root:At the start of the epoch: mem (CPU python)=30948.71875MB; mem (CPU total)=30869.76953125MB
INFO:root:[    7] Training loss: 0.68421394, Validation loss: 0.68313963, Gradient norm: 0.10768348
INFO:root:At the start of the epoch: mem (CPU python)=30986.81640625MB; mem (CPU total)=30908.23828125MB
INFO:root:[    8] Training loss: 0.68301155, Validation loss: 0.68221521, Gradient norm: 0.10220391
INFO:root:At the start of the epoch: mem (CPU python)=31024.91015625MB; mem (CPU total)=30946.38671875MB
INFO:root:[    9] Training loss: 0.68230450, Validation loss: 0.68140313, Gradient norm: 0.10363983
INFO:root:At the start of the epoch: mem (CPU python)=31063.0078125MB; mem (CPU total)=30984.91796875MB
INFO:root:[   10] Training loss: 0.68157679, Validation loss: 0.68128338, Gradient norm: 0.11047454
INFO:root:At the start of the epoch: mem (CPU python)=31101.10546875MB; mem (CPU total)=31023.52734375MB
INFO:root:[   11] Training loss: 0.68087082, Validation loss: 0.68020562, Gradient norm: 0.11094678
INFO:root:At the start of the epoch: mem (CPU python)=31139.19921875MB; mem (CPU total)=31061.671875MB
INFO:root:[   12] Training loss: 0.68026304, Validation loss: 0.67920988, Gradient norm: 0.11818518
INFO:root:At the start of the epoch: mem (CPU python)=31177.29296875MB; mem (CPU total)=31099.29296875MB
INFO:root:[   13] Training loss: 0.67969103, Validation loss: 0.67866443, Gradient norm: 0.12836806
INFO:root:At the start of the epoch: mem (CPU python)=31215.38671875MB; mem (CPU total)=31137.83984375MB
INFO:root:[   14] Training loss: 0.67884520, Validation loss: 0.67718755, Gradient norm: 0.11687279
INFO:root:At the start of the epoch: mem (CPU python)=31253.484375MB; mem (CPU total)=31176.2578125MB
INFO:root:[   15] Training loss: 0.67805265, Validation loss: 0.67712159, Gradient norm: 0.11737980
INFO:root:At the start of the epoch: mem (CPU python)=31291.578125MB; mem (CPU total)=31214.9765625MB
INFO:root:[   16] Training loss: 0.67762830, Validation loss: 0.67623918, Gradient norm: 0.12346062
INFO:root:At the start of the epoch: mem (CPU python)=31329.67578125MB; mem (CPU total)=31252.35546875MB
INFO:root:[   17] Training loss: 0.67707530, Validation loss: 0.67608787, Gradient norm: 0.12592682
INFO:root:At the start of the epoch: mem (CPU python)=31367.7734375MB; mem (CPU total)=31291.0859375MB
INFO:root:[   18] Training loss: 0.67657997, Validation loss: 0.67520182, Gradient norm: 0.13061838
INFO:root:At the start of the epoch: mem (CPU python)=31405.8671875MB; mem (CPU total)=31329.6796875MB
INFO:root:[   19] Training loss: 0.67607640, Validation loss: 0.67534390, Gradient norm: 0.12700093
INFO:root:At the start of the epoch: mem (CPU python)=31443.95703125MB; mem (CPU total)=31368.0390625MB
INFO:root:[   20] Training loss: 0.67574415, Validation loss: 0.67435087, Gradient norm: 0.12682230
INFO:root:At the start of the epoch: mem (CPU python)=31482.05859375MB; mem (CPU total)=31406.1328125MB
INFO:root:[   21] Training loss: 0.67519657, Validation loss: 0.67457590, Gradient norm: 0.13495132
INFO:root:At the start of the epoch: mem (CPU python)=31520.1484375MB; mem (CPU total)=31444.5234375MB
INFO:root:[   22] Training loss: 0.67457527, Validation loss: 0.67355503, Gradient norm: 0.13131430
INFO:root:At the start of the epoch: mem (CPU python)=31558.24609375MB; mem (CPU total)=31482.83984375MB
INFO:root:[   23] Training loss: 0.67424261, Validation loss: 0.67312383, Gradient norm: 0.13982632
INFO:root:At the start of the epoch: mem (CPU python)=31596.33984375MB; mem (CPU total)=31521.49609375MB
INFO:root:[   24] Training loss: 0.67406524, Validation loss: 0.67262388, Gradient norm: 0.14086077
INFO:root:At the start of the epoch: mem (CPU python)=31634.4375MB; mem (CPU total)=31558.78125MB
INFO:root:[   25] Training loss: 0.67359599, Validation loss: 0.67280263, Gradient norm: 0.13227685
INFO:root:At the start of the epoch: mem (CPU python)=31672.53125MB; mem (CPU total)=31597.19921875MB
INFO:root:[   26] Training loss: 0.67331120, Validation loss: 0.67259439, Gradient norm: 0.14249068
INFO:root:At the start of the epoch: mem (CPU python)=31710.62890625MB; mem (CPU total)=31635.03125MB
INFO:root:[   27] Training loss: 0.67300653, Validation loss: 0.67221929, Gradient norm: 0.13669079
INFO:root:At the start of the epoch: mem (CPU python)=31748.7265625MB; mem (CPU total)=31673.73828125MB
INFO:root:[   28] Training loss: 0.67289320, Validation loss: 0.67175164, Gradient norm: 0.13518241
INFO:root:At the start of the epoch: mem (CPU python)=31786.8203125MB; mem (CPU total)=31712.05078125MB
INFO:root:[   29] Training loss: 0.67281027, Validation loss: 0.67190849, Gradient norm: 0.14482147
INFO:root:At the start of the epoch: mem (CPU python)=31824.9140625MB; mem (CPU total)=31750.19140625MB
INFO:root:[   30] Training loss: 0.67247762, Validation loss: 0.67101927, Gradient norm: 0.13830805
INFO:root:At the start of the epoch: mem (CPU python)=31863.0078125MB; mem (CPU total)=31788.0859375MB
INFO:root:[   31] Training loss: 0.67222906, Validation loss: 0.67094776, Gradient norm: 0.13801708
INFO:root:At the start of the epoch: mem (CPU python)=31901.10546875MB; mem (CPU total)=31826.1640625MB
INFO:root:[   32] Training loss: 0.67209130, Validation loss: 0.67161523, Gradient norm: 0.14696486
INFO:root:At the start of the epoch: mem (CPU python)=31939.19921875MB; mem (CPU total)=31864.5234375MB
INFO:root:[   33] Training loss: 0.67173069, Validation loss: 0.67060761, Gradient norm: 0.13927100
INFO:root:At the start of the epoch: mem (CPU python)=31977.29296875MB; mem (CPU total)=31902.8671875MB
INFO:root:[   34] Training loss: 0.67178222, Validation loss: 0.67050556, Gradient norm: 0.14150864
INFO:root:At the start of the epoch: mem (CPU python)=32015.39453125MB; mem (CPU total)=31940.87890625MB
INFO:root:[   35] Training loss: 0.67156814, Validation loss: 0.67069360, Gradient norm: 0.14510411
INFO:root:At the start of the epoch: mem (CPU python)=32053.484375MB; mem (CPU total)=31979.26171875MB
INFO:root:[   36] Training loss: 0.67115794, Validation loss: 0.67069854, Gradient norm: 0.13905342
INFO:root:At the start of the epoch: mem (CPU python)=32091.578125MB; mem (CPU total)=32017.16015625MB
INFO:root:[   37] Training loss: 0.67108960, Validation loss: 0.66997003, Gradient norm: 0.14052175
INFO:root:At the start of the epoch: mem (CPU python)=32129.6796875MB; mem (CPU total)=32055.14453125MB
INFO:root:[   38] Training loss: 0.67090069, Validation loss: 0.67042813, Gradient norm: 0.14556499
INFO:root:At the start of the epoch: mem (CPU python)=32167.7734375MB; mem (CPU total)=32093.71484375MB
INFO:root:[   39] Training loss: 0.67073448, Validation loss: 0.66938416, Gradient norm: 0.13980242
INFO:root:At the start of the epoch: mem (CPU python)=32205.8671875MB; mem (CPU total)=32131.78125MB
INFO:root:[   40] Training loss: 0.67033550, Validation loss: 0.66947799, Gradient norm: 0.13897688
INFO:root:At the start of the epoch: mem (CPU python)=32243.9609375MB; mem (CPU total)=32170.171875MB
INFO:root:[   41] Training loss: 0.67041740, Validation loss: 0.66951549, Gradient norm: 0.15821792
INFO:root:At the start of the epoch: mem (CPU python)=32282.05859375MB; mem (CPU total)=32208.0703125MB
INFO:root:[   42] Training loss: 0.67004743, Validation loss: 0.66908279, Gradient norm: 0.13830528
INFO:root:At the start of the epoch: mem (CPU python)=32320.15625MB; mem (CPU total)=32246.26953125MB
INFO:root:[   43] Training loss: 0.66985458, Validation loss: 0.66967296, Gradient norm: 0.14616195
INFO:root:At the start of the epoch: mem (CPU python)=32358.24609375MB; mem (CPU total)=32284.59765625MB
INFO:root:[   44] Training loss: 0.66962870, Validation loss: 0.66798851, Gradient norm: 0.14334274
INFO:root:At the start of the epoch: mem (CPU python)=32396.34765625MB; mem (CPU total)=32322.62109375MB
INFO:root:[   45] Training loss: 0.66949751, Validation loss: 0.66896526, Gradient norm: 0.14234564
INFO:root:At the start of the epoch: mem (CPU python)=32434.44140625MB; mem (CPU total)=32361.33984375MB
INFO:root:[   46] Training loss: 0.66947704, Validation loss: 0.66833181, Gradient norm: 0.15093242
INFO:root:At the start of the epoch: mem (CPU python)=32472.53515625MB; mem (CPU total)=32399.12109375MB
INFO:root:[   47] Training loss: 0.66928592, Validation loss: 0.66804349, Gradient norm: 0.14687084
INFO:root:At the start of the epoch: mem (CPU python)=32510.62890625MB; mem (CPU total)=32437.265625MB
INFO:root:[   48] Training loss: 0.66902365, Validation loss: 0.66761134, Gradient norm: 0.14332923
INFO:root:At the start of the epoch: mem (CPU python)=32548.73046875MB; mem (CPU total)=32475.3046875MB
INFO:root:[   49] Training loss: 0.66901798, Validation loss: 0.66768691, Gradient norm: 0.14544604
INFO:root:At the start of the epoch: mem (CPU python)=32586.8203125MB; mem (CPU total)=32513.66796875MB
INFO:root:[   50] Training loss: 0.66880376, Validation loss: 0.66776351, Gradient norm: 0.14295760
INFO:root:At the start of the epoch: mem (CPU python)=32624.9140625MB; mem (CPU total)=32551.80859375MB
INFO:root:[   51] Training loss: 0.66856792, Validation loss: 0.66707494, Gradient norm: 0.14947077
INFO:root:At the start of the epoch: mem (CPU python)=32663.015625MB; mem (CPU total)=32589.828125MB
INFO:root:[   52] Training loss: 0.66868864, Validation loss: 0.66730041, Gradient norm: 0.15522465
INFO:root:At the start of the epoch: mem (CPU python)=32701.10546875MB; mem (CPU total)=32628.21875MB
INFO:root:[   53] Training loss: 0.66836344, Validation loss: 0.66729293, Gradient norm: 0.15311395
INFO:root:At the start of the epoch: mem (CPU python)=32739.19921875MB; mem (CPU total)=32666.01171875MB
INFO:root:[   54] Training loss: 0.66851578, Validation loss: 0.66727150, Gradient norm: 0.15935724
INFO:root:At the start of the epoch: mem (CPU python)=32777.30078125MB; mem (CPU total)=32703.91015625MB
INFO:root:[   55] Training loss: 0.66820292, Validation loss: 0.66671810, Gradient norm: 0.14601125
INFO:root:At the start of the epoch: mem (CPU python)=32815.39453125MB; mem (CPU total)=32740.76171875MB
INFO:root:[   56] Training loss: 0.66812555, Validation loss: 0.66710779, Gradient norm: 0.15123100
INFO:root:At the start of the epoch: mem (CPU python)=32853.48828125MB; mem (CPU total)=32778.9296875MB
INFO:root:[   57] Training loss: 0.66804834, Validation loss: 0.66694350, Gradient norm: 0.15393330
INFO:root:At the start of the epoch: mem (CPU python)=32891.58203125MB; mem (CPU total)=32817.07421875MB
INFO:root:[   58] Training loss: 0.66802054, Validation loss: 0.66663697, Gradient norm: 0.16403920
INFO:root:At the start of the epoch: mem (CPU python)=32929.6796875MB; mem (CPU total)=32855.18359375MB
INFO:root:[   59] Training loss: 0.66781315, Validation loss: 0.66672790, Gradient norm: 0.16025796
INFO:root:At the start of the epoch: mem (CPU python)=32967.7734375MB; mem (CPU total)=32893.328125MB
INFO:root:[   60] Training loss: 0.66774837, Validation loss: 0.66710665, Gradient norm: 0.15270661
INFO:root:At the start of the epoch: mem (CPU python)=33005.8671875MB; mem (CPU total)=32931.7265625MB
INFO:root:[   61] Training loss: 0.66759407, Validation loss: 0.66660341, Gradient norm: 0.14858923
INFO:root:At the start of the epoch: mem (CPU python)=33043.96875MB; mem (CPU total)=32970.04296875MB
INFO:root:[   62] Training loss: 0.66771121, Validation loss: 0.66615974, Gradient norm: 0.16781893
INFO:root:At the start of the epoch: mem (CPU python)=33082.0625MB; mem (CPU total)=33008.08203125MB
INFO:root:[   63] Training loss: 0.66758842, Validation loss: 0.66650236, Gradient norm: 0.17147618
INFO:root:At the start of the epoch: mem (CPU python)=33120.15625MB; mem (CPU total)=33046.47265625MB
INFO:root:[   64] Training loss: 0.66730860, Validation loss: 0.66625715, Gradient norm: 0.15728635
INFO:root:At the start of the epoch: mem (CPU python)=33158.25MB; mem (CPU total)=33084.609375MB
INFO:root:[   65] Training loss: 0.66725017, Validation loss: 0.66596560, Gradient norm: 0.15863017
INFO:root:At the start of the epoch: mem (CPU python)=33196.3515625MB; mem (CPU total)=33123.2265625MB
INFO:root:[   66] Training loss: 0.66723658, Validation loss: 0.66618758, Gradient norm: 0.16882246
INFO:root:At the start of the epoch: mem (CPU python)=33234.44140625MB; mem (CPU total)=33161.12109375MB
INFO:root:[   67] Training loss: 0.66707934, Validation loss: 0.66581963, Gradient norm: 0.15535117
INFO:root:At the start of the epoch: mem (CPU python)=33272.5390625MB; mem (CPU total)=33198.765625MB
INFO:root:[   68] Training loss: 0.66710929, Validation loss: 0.66592612, Gradient norm: 0.16081789
INFO:root:At the start of the epoch: mem (CPU python)=33310.6328125MB; mem (CPU total)=33237.14453125MB
INFO:root:[   69] Training loss: 0.66693946, Validation loss: 0.66616467, Gradient norm: 0.17066930
INFO:root:At the start of the epoch: mem (CPU python)=33348.7265625MB; mem (CPU total)=33275.53515625MB
INFO:root:[   70] Training loss: 0.66677118, Validation loss: 0.66560964, Gradient norm: 0.16957869
INFO:root:At the start of the epoch: mem (CPU python)=33386.82421875MB; mem (CPU total)=33311.9921875MB
INFO:root:[   71] Training loss: 0.66665863, Validation loss: 0.66503623, Gradient norm: 0.16819663
INFO:root:At the start of the epoch: mem (CPU python)=33424.921875MB; mem (CPU total)=33350.01953125MB
INFO:root:[   72] Training loss: 0.66629954, Validation loss: 0.66504471, Gradient norm: 0.16121459
INFO:root:At the start of the epoch: mem (CPU python)=33463.015625MB; mem (CPU total)=33387.91015625MB
INFO:root:[   73] Training loss: 0.66595359, Validation loss: 0.66483343, Gradient norm: 0.15953208
INFO:root:At the start of the epoch: mem (CPU python)=33501.11328125MB; mem (CPU total)=33425.625MB
INFO:root:[   74] Training loss: 0.66595800, Validation loss: 0.66448645, Gradient norm: 0.17846115
INFO:root:At the start of the epoch: mem (CPU python)=33539.20703125MB; mem (CPU total)=33463.421875MB
INFO:root:[   75] Training loss: 0.66568409, Validation loss: 0.66496290, Gradient norm: 0.17215513
INFO:root:At the start of the epoch: mem (CPU python)=33577.30078125MB; mem (CPU total)=33501.34375MB
INFO:root:[   76] Training loss: 0.66537274, Validation loss: 0.66442459, Gradient norm: 0.17711561
INFO:root:At the start of the epoch: mem (CPU python)=33615.3984375MB; mem (CPU total)=33539.39453125MB
INFO:root:[   77] Training loss: 0.66535942, Validation loss: 0.66424101, Gradient norm: 0.17674197
INFO:root:At the start of the epoch: mem (CPU python)=33653.4921875MB; mem (CPU total)=33577.1640625MB
INFO:root:[   78] Training loss: 0.66517263, Validation loss: 0.66372039, Gradient norm: 0.17750929
INFO:root:At the start of the epoch: mem (CPU python)=33691.58984375MB; mem (CPU total)=33615.59375MB
INFO:root:[   79] Training loss: 0.66485402, Validation loss: 0.66329345, Gradient norm: 0.17534217
INFO:root:At the start of the epoch: mem (CPU python)=33729.68359375MB; mem (CPU total)=33653.76953125MB
INFO:root:[   80] Training loss: 0.66493551, Validation loss: 0.66395091, Gradient norm: 0.17417042
INFO:root:At the start of the epoch: mem (CPU python)=33767.77734375MB; mem (CPU total)=33692.16015625MB
INFO:root:[   81] Training loss: 0.66482396, Validation loss: 0.66310083, Gradient norm: 0.17476318
INFO:root:At the start of the epoch: mem (CPU python)=33805.87109375MB; mem (CPU total)=33730.12109375MB
INFO:root:[   82] Training loss: 0.66462224, Validation loss: 0.66312351, Gradient norm: 0.17363636
INFO:root:At the start of the epoch: mem (CPU python)=33843.96875MB; mem (CPU total)=33767.76953125MB
INFO:root:[   83] Training loss: 0.66465005, Validation loss: 0.66353202, Gradient norm: 0.18277802
INFO:root:At the start of the epoch: mem (CPU python)=33882.0625MB; mem (CPU total)=33806.16015625MB
INFO:root:[   84] Training loss: 0.66448887, Validation loss: 0.66295501, Gradient norm: 0.16755231
INFO:root:At the start of the epoch: mem (CPU python)=33920.16015625MB; mem (CPU total)=33844.0625MB
INFO:root:[   85] Training loss: 0.66409286, Validation loss: 0.66264803, Gradient norm: 0.16741387
INFO:root:At the start of the epoch: mem (CPU python)=33958.2578125MB; mem (CPU total)=33882.33984375MB
INFO:root:[   86] Training loss: 0.66410249, Validation loss: 0.66288783, Gradient norm: 0.17084583
INFO:root:At the start of the epoch: mem (CPU python)=33996.34765625MB; mem (CPU total)=33920.7578125MB
INFO:root:[   87] Training loss: 0.66414458, Validation loss: 0.66276523, Gradient norm: 0.18136489
INFO:root:At the start of the epoch: mem (CPU python)=34034.44140625MB; mem (CPU total)=33958.9375MB
INFO:root:[   88] Training loss: 0.66405516, Validation loss: 0.66252129, Gradient norm: 0.17910951
INFO:root:At the start of the epoch: mem (CPU python)=34072.54296875MB; mem (CPU total)=33996.921875MB
INFO:root:[   89] Training loss: 0.66391644, Validation loss: 0.66282401, Gradient norm: 0.17160660
INFO:root:At the start of the epoch: mem (CPU python)=34110.6328125MB; mem (CPU total)=34035.63671875MB
INFO:root:[   90] Training loss: 0.66393722, Validation loss: 0.66303362, Gradient norm: 0.18861701
INFO:root:At the start of the epoch: mem (CPU python)=34148.73046875MB; mem (CPU total)=34073.78125MB
INFO:root:[   91] Training loss: 0.66359089, Validation loss: 0.66224146, Gradient norm: 0.16984631
INFO:root:At the start of the epoch: mem (CPU python)=34186.828125MB; mem (CPU total)=34111.51171875MB
INFO:root:[   92] Training loss: 0.66363616, Validation loss: 0.66319094, Gradient norm: 0.17386524
INFO:root:At the start of the epoch: mem (CPU python)=34224.921875MB; mem (CPU total)=34149.31640625MB
INFO:root:[   93] Training loss: 0.66360640, Validation loss: 0.66228842, Gradient norm: 0.17991489
INFO:root:At the start of the epoch: mem (CPU python)=34263.015625MB; mem (CPU total)=34188.0234375MB
INFO:root:[   94] Training loss: 0.66356152, Validation loss: 0.66280039, Gradient norm: 0.18763538
INFO:root:At the start of the epoch: mem (CPU python)=34301.109375MB; mem (CPU total)=34226.1953125MB
INFO:root:[   95] Training loss: 0.66335288, Validation loss: 0.66200111, Gradient norm: 0.16610408
INFO:root:At the start of the epoch: mem (CPU python)=34339.2109375MB; mem (CPU total)=34264.37109375MB
INFO:root:[   96] Training loss: 0.66335185, Validation loss: 0.66203258, Gradient norm: 0.16726056
INFO:root:At the start of the epoch: mem (CPU python)=34377.30078125MB; mem (CPU total)=34302.578125MB
INFO:root:[   97] Training loss: 0.66321990, Validation loss: 0.66229890, Gradient norm: 0.17116133
INFO:root:At the start of the epoch: mem (CPU python)=34415.39453125MB; mem (CPU total)=34340.19140625MB
INFO:root:[   98] Training loss: 0.66326231, Validation loss: 0.66144183, Gradient norm: 0.16844643
INFO:root:At the start of the epoch: mem (CPU python)=34453.4921875MB; mem (CPU total)=34376.96875MB
INFO:root:[   99] Training loss: 0.66326841, Validation loss: 0.66219620, Gradient norm: 0.17461670
INFO:root:At the start of the epoch: mem (CPU python)=34491.58984375MB; mem (CPU total)=34415.5390625MB
INFO:root:[  100] Training loss: 0.66295130, Validation loss: 0.66226538, Gradient norm: 0.16802953
INFO:root:At the start of the epoch: mem (CPU python)=34529.68359375MB; mem (CPU total)=34453.66015625MB
INFO:root:[  101] Training loss: 0.66300146, Validation loss: 0.66161595, Gradient norm: 0.17172041
INFO:root:At the start of the epoch: mem (CPU python)=34567.77734375MB; mem (CPU total)=34491.06640625MB
INFO:root:[  102] Training loss: 0.66302809, Validation loss: 0.66183390, Gradient norm: 0.17959266
INFO:root:At the start of the epoch: mem (CPU python)=34605.875MB; mem (CPU total)=34529.0703125MB
INFO:root:[  103] Training loss: 0.66284546, Validation loss: 0.66142246, Gradient norm: 0.15792955
INFO:root:At the start of the epoch: mem (CPU python)=34643.97265625MB; mem (CPU total)=34568.03515625MB
INFO:root:[  104] Training loss: 0.66290678, Validation loss: 0.66220262, Gradient norm: 0.17947197
INFO:root:At the start of the epoch: mem (CPU python)=34682.06640625MB; mem (CPU total)=34606.109375MB
INFO:root:[  105] Training loss: 0.66266653, Validation loss: 0.66175738, Gradient norm: 0.16229214
INFO:root:At the start of the epoch: mem (CPU python)=34720.1640625MB; mem (CPU total)=34644.1875MB
INFO:root:[  106] Training loss: 0.66254666, Validation loss: 0.66187664, Gradient norm: 0.16859651
INFO:root:At the start of the epoch: mem (CPU python)=34758.2578125MB; mem (CPU total)=34682.08203125MB
INFO:root:[  107] Training loss: 0.66277566, Validation loss: 0.66136934, Gradient norm: 0.19681175
INFO:root:At the start of the epoch: mem (CPU python)=34796.35546875MB; mem (CPU total)=34720.65625MB
INFO:root:[  108] Training loss: 0.66243663, Validation loss: 0.66164355, Gradient norm: 0.17309282
INFO:root:At the start of the epoch: mem (CPU python)=34834.4453125MB; mem (CPU total)=34758.5546875MB
INFO:root:[  109] Training loss: 0.66246547, Validation loss: 0.66202768, Gradient norm: 0.17393254
INFO:root:At the start of the epoch: mem (CPU python)=34872.54296875MB; mem (CPU total)=34796.9765625MB
INFO:root:[  110] Training loss: 0.66214509, Validation loss: 0.66211059, Gradient norm: 0.18380180
INFO:root:At the start of the epoch: mem (CPU python)=34910.63671875MB; mem (CPU total)=34835.6171875MB
INFO:root:[  111] Training loss: 0.66229058, Validation loss: 0.66119580, Gradient norm: 0.17384552
INFO:root:At the start of the epoch: mem (CPU python)=34948.734375MB; mem (CPU total)=34873.72265625MB
INFO:root:[  112] Training loss: 0.66215751, Validation loss: 0.66189855, Gradient norm: 0.16120379
INFO:root:At the start of the epoch: mem (CPU python)=34986.828125MB; mem (CPU total)=34911.86328125MB
INFO:root:[  113] Training loss: 0.66242882, Validation loss: 0.66111902, Gradient norm: 0.18162413
INFO:root:At the start of the epoch: mem (CPU python)=35024.92578125MB; mem (CPU total)=34950.87109375MB
INFO:root:[  114] Training loss: 0.66212649, Validation loss: 0.66059030, Gradient norm: 0.17333227
INFO:root:At the start of the epoch: mem (CPU python)=35063.0234375MB; mem (CPU total)=34989.125MB
INFO:root:[  115] Training loss: 0.66205645, Validation loss: 0.66102544, Gradient norm: 0.18257184
INFO:root:At the start of the epoch: mem (CPU python)=35101.1171875MB; mem (CPU total)=35027.48046875MB
INFO:root:[  116] Training loss: 0.66201506, Validation loss: 0.66095094, Gradient norm: 0.17798967
INFO:root:At the start of the epoch: mem (CPU python)=35139.21484375MB; mem (CPU total)=35065.87109375MB
INFO:root:[  117] Training loss: 0.66184194, Validation loss: 0.66176251, Gradient norm: 0.16935855
INFO:root:At the start of the epoch: mem (CPU python)=35177.30859375MB; mem (CPU total)=35103.546875MB
INFO:root:[  118] Training loss: 0.66202727, Validation loss: 0.66111038, Gradient norm: 0.17631244
INFO:root:At the start of the epoch: mem (CPU python)=35215.40234375MB; mem (CPU total)=35141.15625MB
INFO:root:[  119] Training loss: 0.66181638, Validation loss: 0.66095977, Gradient norm: 0.17541743
INFO:root:At the start of the epoch: mem (CPU python)=35253.5MB; mem (CPU total)=35179.58203125MB
INFO:root:[  120] Training loss: 0.66190968, Validation loss: 0.66093054, Gradient norm: 0.17806309
INFO:root:At the start of the epoch: mem (CPU python)=35291.59765625MB; mem (CPU total)=35217.6640625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  121] Training loss: 0.66167093, Validation loss: 0.66063877, Gradient norm: 0.16625729
INFO:root:At the start of the epoch: mem (CPU python)=35329.69140625MB; mem (CPU total)=35255.83984375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  122] Training loss: 0.66061785, Validation loss: 0.66003860, Gradient norm: 0.15347053
INFO:root:At the start of the epoch: mem (CPU python)=35367.79296875MB; mem (CPU total)=35294.43359375MB
INFO:root:[  123] Training loss: 0.66004971, Validation loss: 0.65945026, Gradient norm: 0.13677862
INFO:root:At the start of the epoch: mem (CPU python)=35405.88671875MB; mem (CPU total)=35332.66015625MB
INFO:root:[  124] Training loss: 0.65985556, Validation loss: 0.65871458, Gradient norm: 0.15388733
INFO:root:At the start of the epoch: mem (CPU python)=35443.98046875MB; mem (CPU total)=35371.30078125MB
INFO:root:[  125] Training loss: 0.65985507, Validation loss: 0.65908908, Gradient norm: 0.14689173
INFO:root:At the start of the epoch: mem (CPU python)=35482.07421875MB; mem (CPU total)=35409.12890625MB
INFO:root:[  126] Training loss: 0.65986421, Validation loss: 0.65916411, Gradient norm: 0.14384002
INFO:root:At the start of the epoch: mem (CPU python)=35520.171875MB; mem (CPU total)=35447.515625MB
INFO:root:[  127] Training loss: 0.65988784, Validation loss: 0.65911474, Gradient norm: 0.15284924
INFO:root:At the start of the epoch: mem (CPU python)=35558.265625MB; mem (CPU total)=35485.6796875MB
INFO:root:[  128] Training loss: 0.65981057, Validation loss: 0.65911584, Gradient norm: 0.14352263
INFO:root:At the start of the epoch: mem (CPU python)=35596.36328125MB; mem (CPU total)=35523.484375MB
INFO:root:[  129] Training loss: 0.65991968, Validation loss: 0.65888076, Gradient norm: 0.15149014
INFO:root:At the start of the epoch: mem (CPU python)=35634.4609375MB; mem (CPU total)=35561.875MB
INFO:root:[  130] Training loss: 0.65978697, Validation loss: 0.65911140, Gradient norm: 0.15850214
INFO:root:At the start of the epoch: mem (CPU python)=35672.5546875MB; mem (CPU total)=35600.2265625MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  131] Training loss: 0.65969440, Validation loss: 0.65936717, Gradient norm: 0.15138255
INFO:root:At the start of the epoch: mem (CPU python)=35710.6484375MB; mem (CPU total)=35638.1171875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  132] Training loss: 0.65946162, Validation loss: 0.65920744, Gradient norm: 0.14093419
INFO:root:At the start of the epoch: mem (CPU python)=35748.7421875MB; mem (CPU total)=35676.796875MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  133] Training loss: 0.65935803, Validation loss: 0.65880232, Gradient norm: 0.14048865
INFO:root:At the start of the epoch: mem (CPU python)=35786.83984375MB; mem (CPU total)=35714.6953125MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  134] Training loss: 0.65913101, Validation loss: 0.65834134, Gradient norm: 0.13182901
INFO:root:At the start of the epoch: mem (CPU python)=35824.9375MB; mem (CPU total)=35753.1796875MB
INFO:root:[  135] Training loss: 0.65919960, Validation loss: 0.65877546, Gradient norm: 0.12612014
INFO:root:At the start of the epoch: mem (CPU python)=35863.02734375MB; mem (CPU total)=35791.734375MB
INFO:root:[  136] Training loss: 0.65910099, Validation loss: 0.65845456, Gradient norm: 0.13180164
INFO:root:At the start of the epoch: mem (CPU python)=35901.125MB; mem (CPU total)=35830.12109375MB
INFO:root:[  137] Training loss: 0.65908411, Validation loss: 0.65853300, Gradient norm: 0.13463901
INFO:root:At the start of the epoch: mem (CPU python)=35939.21875MB; mem (CPU total)=35867.8359375MB
INFO:root:[  138] Training loss: 0.65903593, Validation loss: 0.65854388, Gradient norm: 0.12799841
INFO:root:At the start of the epoch: mem (CPU python)=35977.31640625MB; mem (CPU total)=35905.671875MB
INFO:root:[  139] Training loss: 0.65910937, Validation loss: 0.65899913, Gradient norm: 0.13164316
INFO:root:At the start of the epoch: mem (CPU python)=36015.4140625MB; mem (CPU total)=35943.8359375MB
INFO:root:[  140] Training loss: 0.65900318, Validation loss: 0.65861200, Gradient norm: 0.13337646
INFO:root:At the start of the epoch: mem (CPU python)=36053.5078125MB; mem (CPU total)=35981.98046875MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  141] Training loss: 0.65915491, Validation loss: 0.65884853, Gradient norm: 0.13126730
INFO:root:At the start of the epoch: mem (CPU python)=36091.6015625MB; mem (CPU total)=36020.37109375MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  142] Training loss: 0.65887050, Validation loss: 0.65882975, Gradient norm: 0.13078517
INFO:root:At the start of the epoch: mem (CPU python)=36129.6953125MB; mem (CPU total)=36058.421875MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  143] Training loss: 0.65899338, Validation loss: 0.65842912, Gradient norm: 0.12853510
INFO:root:At the start of the epoch: mem (CPU python)=36167.79296875MB; mem (CPU total)=36096.35546875MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:EP 143: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=36205.88671875MB; mem (CPU total)=36134.265625MB
INFO:root:Training the model took 11860.475s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93147
INFO:root:EnergyScoreTrain: 0.65555
INFO:root:CRPSTrain: 0.53331
INFO:root:Gaussian NLLTrain: 18.19598
INFO:root:CoverageTrain: 0.88857
INFO:root:IntervalWidthTrain: 3.35149
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93583
INFO:root:EnergyScoreValidation: 0.65865
INFO:root:CRPSValidation: 0.53618
INFO:root:Gaussian NLLValidation: 18.23353
INFO:root:CoverageValidation: 0.88779
INFO:root:IntervalWidthValidation: 3.3546
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93493
INFO:root:EnergyScoreTest: 0.65801
INFO:root:CRPSTest: 0.53561
INFO:root:Gaussian NLLTest: 18.49898
INFO:root:CoverageTest: 0.88765
INFO:root:IntervalWidthTest: 3.35339
INFO:root:After validation: mem (CPU python)=36261.21875MB; mem (CPU total)=36184.515625MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=36261.21875MB; mem (CPU total)=36184.31640625MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=36261.21875MB; mem (CPU total)=36184.31640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=36261.21875MB; mem (CPU total)=36184.22265625MB
INFO:root:[    1] Training loss: 0.71428524, Validation loss: 0.70280112, Gradient norm: 0.05322514
INFO:root:At the start of the epoch: mem (CPU python)=36289.40625MB; mem (CPU total)=36222.07421875MB
INFO:root:[    2] Training loss: 0.69743039, Validation loss: 0.69307980, Gradient norm: 0.05920622
INFO:root:At the start of the epoch: mem (CPU python)=36327.5MB; mem (CPU total)=36260.41796875MB
INFO:root:[    3] Training loss: 0.69143657, Validation loss: 0.68980598, Gradient norm: 0.07752667
INFO:root:At the start of the epoch: mem (CPU python)=36365.59375MB; mem (CPU total)=36298.31640625MB
INFO:root:[    4] Training loss: 0.68847231, Validation loss: 0.68773131, Gradient norm: 0.07832941
INFO:root:At the start of the epoch: mem (CPU python)=36403.6875MB; mem (CPU total)=36336.94921875MB
INFO:root:[    5] Training loss: 0.68721770, Validation loss: 0.68667293, Gradient norm: 0.08248651
INFO:root:At the start of the epoch: mem (CPU python)=36441.78515625MB; mem (CPU total)=36373.75MB
INFO:root:[    6] Training loss: 0.68592541, Validation loss: 0.68596167, Gradient norm: 0.08438421
INFO:root:At the start of the epoch: mem (CPU python)=36479.87890625MB; mem (CPU total)=36411.5234375MB
INFO:root:[    7] Training loss: 0.68488258, Validation loss: 0.68432784, Gradient norm: 0.08494222
INFO:root:At the start of the epoch: mem (CPU python)=36517.97265625MB; mem (CPU total)=36449.59765625MB
INFO:root:[    8] Training loss: 0.68421413, Validation loss: 0.68401418, Gradient norm: 0.09052066
INFO:root:At the start of the epoch: mem (CPU python)=36556.06640625MB; mem (CPU total)=36488.01953125MB
INFO:root:[    9] Training loss: 0.68371475, Validation loss: 0.68367583, Gradient norm: 0.09187122
INFO:root:At the start of the epoch: mem (CPU python)=36594.1640625MB; mem (CPU total)=36526.84375MB
INFO:root:[   10] Training loss: 0.68312322, Validation loss: 0.68296010, Gradient norm: 0.09485203
INFO:root:At the start of the epoch: mem (CPU python)=36632.26171875MB; mem (CPU total)=36565.08203125MB
INFO:root:[   11] Training loss: 0.68254148, Validation loss: 0.68191806, Gradient norm: 0.09580127
INFO:root:At the start of the epoch: mem (CPU python)=36670.359375MB; mem (CPU total)=36602.51953125MB
INFO:root:[   12] Training loss: 0.68199969, Validation loss: 0.68163869, Gradient norm: 0.09666614
INFO:root:At the start of the epoch: mem (CPU python)=36708.453125MB; mem (CPU total)=36639.7265625MB
INFO:root:[   13] Training loss: 0.68154023, Validation loss: 0.68150716, Gradient norm: 0.10185951
INFO:root:At the start of the epoch: mem (CPU python)=36746.546875MB; mem (CPU total)=36678.16796875MB
INFO:root:[   14] Training loss: 0.68085834, Validation loss: 0.68079262, Gradient norm: 0.09955312
INFO:root:At the start of the epoch: mem (CPU python)=36784.640625MB; mem (CPU total)=36716.734375MB
INFO:root:[   15] Training loss: 0.68075953, Validation loss: 0.67987260, Gradient norm: 0.10823849
INFO:root:At the start of the epoch: mem (CPU python)=36822.73828125MB; mem (CPU total)=36754.7109375MB
INFO:root:[   16] Training loss: 0.68037801, Validation loss: 0.67952067, Gradient norm: 0.10704557
INFO:root:At the start of the epoch: mem (CPU python)=36860.83203125MB; mem (CPU total)=36792.98046875MB
INFO:root:[   17] Training loss: 0.67989579, Validation loss: 0.67920767, Gradient norm: 0.11029852
INFO:root:At the start of the epoch: mem (CPU python)=36898.9296875MB; mem (CPU total)=36830.87109375MB
INFO:root:[   18] Training loss: 0.67957401, Validation loss: 0.67882687, Gradient norm: 0.11389949
INFO:root:At the start of the epoch: mem (CPU python)=36937.02734375MB; mem (CPU total)=36869.1875MB
INFO:root:[   19] Training loss: 0.67939919, Validation loss: 0.67869147, Gradient norm: 0.11143098
INFO:root:At the start of the epoch: mem (CPU python)=36975.12109375MB; mem (CPU total)=36906.76171875MB
INFO:root:[   20] Training loss: 0.67905475, Validation loss: 0.67840021, Gradient norm: 0.11641054
INFO:root:At the start of the epoch: mem (CPU python)=37013.21484375MB; mem (CPU total)=36945.21484375MB
INFO:root:[   21] Training loss: 0.67868960, Validation loss: 0.67785008, Gradient norm: 0.12362516
INFO:root:At the start of the epoch: mem (CPU python)=37051.3125MB; mem (CPU total)=36983.7265625MB
INFO:root:[   22] Training loss: 0.67826790, Validation loss: 0.67795108, Gradient norm: 0.11715326
INFO:root:At the start of the epoch: mem (CPU python)=37089.40234375MB; mem (CPU total)=37021.90625MB
INFO:root:[   23] Training loss: 0.67790153, Validation loss: 0.67727087, Gradient norm: 0.12464444
INFO:root:At the start of the epoch: mem (CPU python)=37127.5MB; mem (CPU total)=37060.0546875MB
INFO:root:[   24] Training loss: 0.67756645, Validation loss: 0.67601860, Gradient norm: 0.13306089
INFO:root:At the start of the epoch: mem (CPU python)=37165.59375MB; mem (CPU total)=37098.109375MB
INFO:root:[   25] Training loss: 0.67712359, Validation loss: 0.67597687, Gradient norm: 0.13696784
INFO:root:At the start of the epoch: mem (CPU python)=37203.69140625MB; mem (CPU total)=37135.484375MB
INFO:root:[   26] Training loss: 0.67663423, Validation loss: 0.67537928, Gradient norm: 0.14329015
INFO:root:At the start of the epoch: mem (CPU python)=37241.7890625MB; mem (CPU total)=37172.703125MB
INFO:root:[   27] Training loss: 0.67600400, Validation loss: 0.67491641, Gradient norm: 0.14549372
INFO:root:At the start of the epoch: mem (CPU python)=37279.8828125MB; mem (CPU total)=37212.13671875MB
INFO:root:[   28] Training loss: 0.67588709, Validation loss: 0.67475369, Gradient norm: 0.14101710
INFO:root:At the start of the epoch: mem (CPU python)=37317.98046875MB; mem (CPU total)=37250.234375MB
INFO:root:[   29] Training loss: 0.67534778, Validation loss: 0.67470456, Gradient norm: 0.15020718
INFO:root:At the start of the epoch: mem (CPU python)=37356.07421875MB; mem (CPU total)=37288.515625MB
INFO:root:[   30] Training loss: 0.67506686, Validation loss: 0.67432262, Gradient norm: 0.15421656
INFO:root:At the start of the epoch: mem (CPU python)=37394.16796875MB; mem (CPU total)=37327.0625MB
INFO:root:[   31] Training loss: 0.67468917, Validation loss: 0.67355145, Gradient norm: 0.14746070
INFO:root:At the start of the epoch: mem (CPU python)=37432.26171875MB; mem (CPU total)=37364.875MB
INFO:root:[   32] Training loss: 0.67430432, Validation loss: 0.67413995, Gradient norm: 0.14685859
INFO:root:At the start of the epoch: mem (CPU python)=37470.359375MB; mem (CPU total)=37403.26171875MB
INFO:root:[   33] Training loss: 0.67429043, Validation loss: 0.67280805, Gradient norm: 0.15830835
INFO:root:At the start of the epoch: mem (CPU python)=37508.45703125MB; mem (CPU total)=37441.578125MB
INFO:root:[   34] Training loss: 0.67385999, Validation loss: 0.67287023, Gradient norm: 0.15015343
INFO:root:At the start of the epoch: mem (CPU python)=37546.546875MB; mem (CPU total)=37479.96875MB
INFO:root:[   35] Training loss: 0.67344768, Validation loss: 0.67283378, Gradient norm: 0.16124826
INFO:root:At the start of the epoch: mem (CPU python)=37584.64453125MB; mem (CPU total)=37518.0MB
INFO:root:[   36] Training loss: 0.67300210, Validation loss: 0.67244886, Gradient norm: 0.15597799
INFO:root:At the start of the epoch: mem (CPU python)=37622.7421875MB; mem (CPU total)=37555.93359375MB
INFO:root:[   37] Training loss: 0.67275436, Validation loss: 0.67176649, Gradient norm: 0.15735512
INFO:root:At the start of the epoch: mem (CPU python)=37660.8359375MB; mem (CPU total)=37594.26171875MB
INFO:root:[   38] Training loss: 0.67253452, Validation loss: 0.67101570, Gradient norm: 0.15994889
INFO:root:At the start of the epoch: mem (CPU python)=37698.93359375MB; mem (CPU total)=37632.6640625MB
INFO:root:[   39] Training loss: 0.67230048, Validation loss: 0.67141550, Gradient norm: 0.16465327
INFO:root:At the start of the epoch: mem (CPU python)=37737.02734375MB; mem (CPU total)=37670.5625MB
INFO:root:[   40] Training loss: 0.67194165, Validation loss: 0.67132707, Gradient norm: 0.16500662
INFO:root:At the start of the epoch: mem (CPU python)=37775.12109375MB; mem (CPU total)=37708.70703125MB
INFO:root:[   41] Training loss: 0.67161469, Validation loss: 0.67103431, Gradient norm: 0.16334045
INFO:root:At the start of the epoch: mem (CPU python)=37813.21484375MB; mem (CPU total)=37746.72265625MB
INFO:root:[   42] Training loss: 0.67132204, Validation loss: 0.67083964, Gradient norm: 0.15054505
INFO:root:At the start of the epoch: mem (CPU python)=37851.31640625MB; mem (CPU total)=37785.5546875MB
INFO:root:[   43] Training loss: 0.67128768, Validation loss: 0.67043846, Gradient norm: 0.16463580
INFO:root:At the start of the epoch: mem (CPU python)=37889.41015625MB; mem (CPU total)=37824.3671875MB
INFO:root:[   44] Training loss: 0.67103984, Validation loss: 0.67039954, Gradient norm: 0.16990972
INFO:root:At the start of the epoch: mem (CPU python)=37927.50390625MB; mem (CPU total)=37862.1171875MB
INFO:root:[   45] Training loss: 0.67078108, Validation loss: 0.66958326, Gradient norm: 0.17365104
INFO:root:At the start of the epoch: mem (CPU python)=37965.6015625MB; mem (CPU total)=37899.6796875MB
INFO:root:[   46] Training loss: 0.67068342, Validation loss: 0.66963958, Gradient norm: 0.16314700
INFO:root:At the start of the epoch: mem (CPU python)=38003.6953125MB; mem (CPU total)=37938.07421875MB
INFO:root:[   47] Training loss: 0.67048516, Validation loss: 0.66959706, Gradient norm: 0.17431484
INFO:root:At the start of the epoch: mem (CPU python)=38041.7890625MB; mem (CPU total)=37976.21875MB
INFO:root:[   48] Training loss: 0.67025448, Validation loss: 0.66894951, Gradient norm: 0.16323098
INFO:root:At the start of the epoch: mem (CPU python)=38079.8828125MB; mem (CPU total)=38014.61328125MB
INFO:root:[   49] Training loss: 0.67026278, Validation loss: 0.66978543, Gradient norm: 0.17388312
INFO:root:At the start of the epoch: mem (CPU python)=38117.98046875MB; mem (CPU total)=38053.06640625MB
INFO:root:[   50] Training loss: 0.66994483, Validation loss: 0.66843575, Gradient norm: 0.16707751
INFO:root:At the start of the epoch: mem (CPU python)=38156.078125MB; mem (CPU total)=38091.16796875MB
INFO:root:[   51] Training loss: 0.67010977, Validation loss: 0.66832261, Gradient norm: 0.16958003
INFO:root:At the start of the epoch: mem (CPU python)=38194.171875MB; mem (CPU total)=38129.73828125MB
INFO:root:[   52] Training loss: 0.66970538, Validation loss: 0.66803795, Gradient norm: 0.17284288
INFO:root:At the start of the epoch: mem (CPU python)=38232.26953125MB; mem (CPU total)=38167.2109375MB
INFO:root:[   53] Training loss: 0.66974860, Validation loss: 0.66862053, Gradient norm: 0.17222667
INFO:root:At the start of the epoch: mem (CPU python)=38270.359375MB; mem (CPU total)=38205.3828125MB
INFO:root:[   54] Training loss: 0.66963519, Validation loss: 0.66837404, Gradient norm: 0.17482795
INFO:root:At the start of the epoch: mem (CPU python)=38308.453125MB; mem (CPU total)=38243.8046875MB
INFO:root:[   55] Training loss: 0.66935039, Validation loss: 0.66819712, Gradient norm: 0.17282638
INFO:root:At the start of the epoch: mem (CPU python)=38346.55078125MB; mem (CPU total)=38282.19921875MB
INFO:root:[   56] Training loss: 0.66919336, Validation loss: 0.66785162, Gradient norm: 0.16852959
INFO:root:At the start of the epoch: mem (CPU python)=38384.6484375MB; mem (CPU total)=38320.328125MB
INFO:root:[   57] Training loss: 0.66890672, Validation loss: 0.66820511, Gradient norm: 0.16980527
INFO:root:At the start of the epoch: mem (CPU python)=38422.7421875MB; mem (CPU total)=38358.78515625MB
INFO:root:[   58] Training loss: 0.66904446, Validation loss: 0.66744508, Gradient norm: 0.17587237
INFO:root:At the start of the epoch: mem (CPU python)=38460.83984375MB; mem (CPU total)=38396.640625MB
INFO:root:[   59] Training loss: 0.66886811, Validation loss: 0.66798377, Gradient norm: 0.17002976
INFO:root:At the start of the epoch: mem (CPU python)=38498.93359375MB; mem (CPU total)=38434.7890625MB
INFO:root:[   60] Training loss: 0.66868281, Validation loss: 0.66760246, Gradient norm: 0.16602701
INFO:root:At the start of the epoch: mem (CPU python)=38537.02734375MB; mem (CPU total)=38472.6875MB
INFO:root:[   61] Training loss: 0.66849435, Validation loss: 0.66739217, Gradient norm: 0.17671554
INFO:root:At the start of the epoch: mem (CPU python)=38575.125MB; mem (CPU total)=38510.1953125MB
INFO:root:[   62] Training loss: 0.66855011, Validation loss: 0.66763635, Gradient norm: 0.16917711
INFO:root:At the start of the epoch: mem (CPU python)=38613.22265625MB; mem (CPU total)=38548.39453125MB
INFO:root:[   63] Training loss: 0.66823283, Validation loss: 0.66734394, Gradient norm: 0.16756988
INFO:root:At the start of the epoch: mem (CPU python)=38651.31640625MB; mem (CPU total)=38586.50390625MB
INFO:root:[   64] Training loss: 0.66820611, Validation loss: 0.66714090, Gradient norm: 0.16773248
INFO:root:At the start of the epoch: mem (CPU python)=38689.41015625MB; mem (CPU total)=38624.59375MB
INFO:root:[   65] Training loss: 0.66805244, Validation loss: 0.66702823, Gradient norm: 0.16096355
INFO:root:At the start of the epoch: mem (CPU python)=38727.50390625MB; mem (CPU total)=38663.12109375MB
INFO:root:[   66] Training loss: 0.66800265, Validation loss: 0.66665822, Gradient norm: 0.17141721
INFO:root:At the start of the epoch: mem (CPU python)=38765.6015625MB; mem (CPU total)=38701.25MB
INFO:root:[   67] Training loss: 0.66781673, Validation loss: 0.66762991, Gradient norm: 0.16782426
INFO:root:At the start of the epoch: mem (CPU python)=38803.6953125MB; mem (CPU total)=38739.640625MB
INFO:root:[   68] Training loss: 0.66777256, Validation loss: 0.66680812, Gradient norm: 0.17610832
INFO:root:At the start of the epoch: mem (CPU python)=38841.7890625MB; mem (CPU total)=38777.4453125MB
INFO:root:[   69] Training loss: 0.66801043, Validation loss: 0.66662384, Gradient norm: 0.18419642
INFO:root:At the start of the epoch: mem (CPU python)=38879.890625MB; mem (CPU total)=38815.4921875MB
INFO:root:[   70] Training loss: 0.66741039, Validation loss: 0.66667617, Gradient norm: 0.16930837
INFO:root:At the start of the epoch: mem (CPU python)=38917.98046875MB; mem (CPU total)=38853.8828125MB
INFO:root:[   71] Training loss: 0.66744942, Validation loss: 0.66650522, Gradient norm: 0.16392860
INFO:root:At the start of the epoch: mem (CPU python)=38956.078125MB; mem (CPU total)=38891.8125MB
INFO:root:[   72] Training loss: 0.66736710, Validation loss: 0.66617426, Gradient norm: 0.16908383
INFO:root:At the start of the epoch: mem (CPU python)=38994.17578125MB; mem (CPU total)=38930.24609375MB
INFO:root:[   73] Training loss: 0.66734755, Validation loss: 0.66619019, Gradient norm: 0.16379749
INFO:root:At the start of the epoch: mem (CPU python)=39032.26953125MB; mem (CPU total)=38968.8515625MB
INFO:root:[   74] Training loss: 0.66705490, Validation loss: 0.66577461, Gradient norm: 0.17426426
INFO:root:At the start of the epoch: mem (CPU python)=39070.3671875MB; mem (CPU total)=39006.8125MB
INFO:root:[   75] Training loss: 0.66700997, Validation loss: 0.66635982, Gradient norm: 0.16760709
INFO:root:At the start of the epoch: mem (CPU python)=39108.45703125MB; mem (CPU total)=39044.95703125MB
INFO:root:[   76] Training loss: 0.66691615, Validation loss: 0.66616267, Gradient norm: 0.17819593
INFO:root:At the start of the epoch: mem (CPU python)=39146.5546875MB; mem (CPU total)=39083.125MB
INFO:root:[   77] Training loss: 0.66701000, Validation loss: 0.66593903, Gradient norm: 0.16947386
INFO:root:At the start of the epoch: mem (CPU python)=39184.6484375MB; mem (CPU total)=39120.7734375MB
INFO:root:[   78] Training loss: 0.66676321, Validation loss: 0.66562079, Gradient norm: 0.16147483
INFO:root:At the start of the epoch: mem (CPU python)=39222.74609375MB; mem (CPU total)=39159.31640625MB
INFO:root:[   79] Training loss: 0.66679101, Validation loss: 0.66573145, Gradient norm: 0.17186679
INFO:root:At the start of the epoch: mem (CPU python)=39260.83984375MB; mem (CPU total)=39197.69921875MB
INFO:root:[   80] Training loss: 0.66678023, Validation loss: 0.66582385, Gradient norm: 0.17855720
INFO:root:At the start of the epoch: mem (CPU python)=39298.9375MB; mem (CPU total)=39235.59765625MB
INFO:root:[   81] Training loss: 0.66643623, Validation loss: 0.66551060, Gradient norm: 0.16505087
INFO:root:At the start of the epoch: mem (CPU python)=39337.03125MB; mem (CPU total)=39273.64453125MB
INFO:root:[   82] Training loss: 0.66651395, Validation loss: 0.66604719, Gradient norm: 0.17117473
INFO:root:At the start of the epoch: mem (CPU python)=39375.125MB; mem (CPU total)=39312.09765625MB
INFO:root:[   83] Training loss: 0.66638041, Validation loss: 0.66570934, Gradient norm: 0.17252071
INFO:root:At the start of the epoch: mem (CPU python)=39413.22265625MB; mem (CPU total)=39349.9609375MB
INFO:root:[   84] Training loss: 0.66626194, Validation loss: 0.66571040, Gradient norm: 0.16658407
INFO:root:At the start of the epoch: mem (CPU python)=39451.31640625MB; mem (CPU total)=39387.75MB
INFO:root:[   85] Training loss: 0.66631718, Validation loss: 0.66564748, Gradient norm: 0.16823882
INFO:root:At the start of the epoch: mem (CPU python)=39489.41015625MB; mem (CPU total)=39425.91796875MB
INFO:root:[   86] Training loss: 0.66609412, Validation loss: 0.66497289, Gradient norm: 0.17382604
INFO:root:At the start of the epoch: mem (CPU python)=39527.51171875MB; mem (CPU total)=39463.99609375MB
INFO:root:[   87] Training loss: 0.66617961, Validation loss: 0.66581381, Gradient norm: 0.17201930
INFO:root:At the start of the epoch: mem (CPU python)=39565.6015625MB; mem (CPU total)=39502.38671875MB
INFO:root:[   88] Training loss: 0.66608822, Validation loss: 0.66492585, Gradient norm: 0.18229370
INFO:root:At the start of the epoch: mem (CPU python)=39603.69921875MB; mem (CPU total)=39540.93359375MB
INFO:root:[   89] Training loss: 0.66593993, Validation loss: 0.66471005, Gradient norm: 0.17699869
INFO:root:At the start of the epoch: mem (CPU python)=39641.796875MB; mem (CPU total)=39579.86328125MB
INFO:root:[   90] Training loss: 0.66584093, Validation loss: 0.66539571, Gradient norm: 0.17309740
INFO:root:At the start of the epoch: mem (CPU python)=39679.890625MB; mem (CPU total)=39618.03515625MB
INFO:root:[   91] Training loss: 0.66569341, Validation loss: 0.66489700, Gradient norm: 0.16889368
INFO:root:At the start of the epoch: mem (CPU python)=39717.984375MB; mem (CPU total)=39656.39453125MB
INFO:root:[   92] Training loss: 0.66548360, Validation loss: 0.66460744, Gradient norm: 0.18776447
INFO:root:At the start of the epoch: mem (CPU python)=39756.08203125MB; mem (CPU total)=39693.90625MB
INFO:root:[   93] Training loss: 0.66559677, Validation loss: 0.66423651, Gradient norm: 0.18243901
INFO:root:At the start of the epoch: mem (CPU python)=39794.1796875MB; mem (CPU total)=39732.44140625MB
INFO:root:[   94] Training loss: 0.66537499, Validation loss: 0.66391848, Gradient norm: 0.17097714
INFO:root:At the start of the epoch: mem (CPU python)=39832.2734375MB; mem (CPU total)=39770.17578125MB
INFO:root:[   95] Training loss: 0.66532618, Validation loss: 0.66429697, Gradient norm: 0.17706788
INFO:root:At the start of the epoch: mem (CPU python)=39870.36328125MB; mem (CPU total)=39809.03125MB
INFO:root:[   96] Training loss: 0.66542904, Validation loss: 0.66402458, Gradient norm: 0.18400245
INFO:root:At the start of the epoch: mem (CPU python)=39908.46484375MB; mem (CPU total)=39847.02734375MB
INFO:root:[   97] Training loss: 0.66507549, Validation loss: 0.66394108, Gradient norm: 0.18042060
INFO:root:At the start of the epoch: mem (CPU python)=39946.55859375MB; mem (CPU total)=39885.078125MB
INFO:root:[   98] Training loss: 0.66506501, Validation loss: 0.66379924, Gradient norm: 0.17920605
INFO:root:At the start of the epoch: mem (CPU python)=39984.66015625MB; mem (CPU total)=39923.515625MB
INFO:root:[   99] Training loss: 0.66485859, Validation loss: 0.66364169, Gradient norm: 0.18157127
INFO:root:At the start of the epoch: mem (CPU python)=40022.75390625MB; mem (CPU total)=39961.78515625MB
INFO:root:[  100] Training loss: 0.66482255, Validation loss: 0.66351276, Gradient norm: 0.17112335
INFO:root:At the start of the epoch: mem (CPU python)=40060.84765625MB; mem (CPU total)=40000.22265625MB
INFO:root:[  101] Training loss: 0.66463559, Validation loss: 0.66376958, Gradient norm: 0.16592583
INFO:root:At the start of the epoch: mem (CPU python)=40098.94140625MB; mem (CPU total)=40038.3671875MB
INFO:root:[  102] Training loss: 0.66481137, Validation loss: 0.66375894, Gradient norm: 0.18527800
INFO:root:At the start of the epoch: mem (CPU python)=40137.03515625MB; mem (CPU total)=40076.5078125MB
INFO:root:[  103] Training loss: 0.66458277, Validation loss: 0.66377527, Gradient norm: 0.17674558
INFO:root:At the start of the epoch: mem (CPU python)=40175.1328125MB; mem (CPU total)=40114.7265625MB
INFO:root:[  104] Training loss: 0.66457621, Validation loss: 0.66342385, Gradient norm: 0.17694672
INFO:root:At the start of the epoch: mem (CPU python)=40213.23046875MB; mem (CPU total)=40152.42578125MB
INFO:root:[  105] Training loss: 0.66433460, Validation loss: 0.66344010, Gradient norm: 0.17567134
INFO:root:At the start of the epoch: mem (CPU python)=40251.32421875MB; mem (CPU total)=40190.5703125MB
INFO:root:[  106] Training loss: 0.66441851, Validation loss: 0.66376747, Gradient norm: 0.19237591
INFO:root:At the start of the epoch: mem (CPU python)=40289.421875MB; mem (CPU total)=40228.578125MB
INFO:root:[  107] Training loss: 0.66423442, Validation loss: 0.66330195, Gradient norm: 0.17774791
INFO:root:At the start of the epoch: mem (CPU python)=40327.515625MB; mem (CPU total)=40266.84375MB
INFO:root:[  108] Training loss: 0.66432026, Validation loss: 0.66291989, Gradient norm: 0.18583121
INFO:root:At the start of the epoch: mem (CPU python)=40365.61328125MB; mem (CPU total)=40304.8671875MB
INFO:root:[  109] Training loss: 0.66401351, Validation loss: 0.66328603, Gradient norm: 0.17451918
INFO:root:At the start of the epoch: mem (CPU python)=40403.703125MB; mem (CPU total)=40343.07421875MB
INFO:root:[  110] Training loss: 0.66404817, Validation loss: 0.66333932, Gradient norm: 0.17326575
INFO:root:At the start of the epoch: mem (CPU python)=40441.8046875MB; mem (CPU total)=40381.09375MB
INFO:root:[  111] Training loss: 0.66424963, Validation loss: 0.66232236, Gradient norm: 0.19285715
INFO:root:At the start of the epoch: mem (CPU python)=40479.90234375MB; mem (CPU total)=40419.71484375MB
INFO:root:[  112] Training loss: 0.66394595, Validation loss: 0.66277110, Gradient norm: 0.17521354
INFO:root:At the start of the epoch: mem (CPU python)=40517.9921875MB; mem (CPU total)=40457.89453125MB
INFO:root:[  113] Training loss: 0.66376313, Validation loss: 0.66239776, Gradient norm: 0.17049716
INFO:root:At the start of the epoch: mem (CPU python)=40556.08984375MB; mem (CPU total)=40496.31640625MB
INFO:root:[  114] Training loss: 0.66375099, Validation loss: 0.66229121, Gradient norm: 0.18524033
INFO:root:At the start of the epoch: mem (CPU python)=40594.1875MB; mem (CPU total)=40534.83203125MB
INFO:root:[  115] Training loss: 0.66383681, Validation loss: 0.66323523, Gradient norm: 0.17889151
INFO:root:At the start of the epoch: mem (CPU python)=40632.28125MB; mem (CPU total)=40573.19140625MB
INFO:root:[  116] Training loss: 0.66366180, Validation loss: 0.66234452, Gradient norm: 0.18329178
INFO:root:At the start of the epoch: mem (CPU python)=40670.375MB; mem (CPU total)=40611.11328125MB
INFO:root:[  117] Training loss: 0.66367982, Validation loss: 0.66304694, Gradient norm: 0.19167684
INFO:root:At the start of the epoch: mem (CPU python)=40708.46875MB; mem (CPU total)=40648.70703125MB
INFO:root:[  118] Training loss: 0.66356573, Validation loss: 0.66193018, Gradient norm: 0.18292344
INFO:root:At the start of the epoch: mem (CPU python)=40746.5703125MB; mem (CPU total)=40687.1015625MB
INFO:root:[  119] Training loss: 0.66329909, Validation loss: 0.66294140, Gradient norm: 0.16708161
INFO:root:At the start of the epoch: mem (CPU python)=40784.66015625MB; mem (CPU total)=40726.28125MB
INFO:root:[  120] Training loss: 0.66330293, Validation loss: 0.66289592, Gradient norm: 0.17516806
INFO:root:At the start of the epoch: mem (CPU python)=40822.7578125MB; mem (CPU total)=40764.87890625MB
INFO:root:[  121] Training loss: 0.66315754, Validation loss: 0.66241391, Gradient norm: 0.17350401
INFO:root:At the start of the epoch: mem (CPU python)=40860.8515625MB; mem (CPU total)=40802.6015625MB
INFO:root:[  122] Training loss: 0.66323545, Validation loss: 0.66181147, Gradient norm: 0.18039325
INFO:root:At the start of the epoch: mem (CPU python)=40898.94921875MB; mem (CPU total)=40840.7265625MB
INFO:root:[  123] Training loss: 0.66342409, Validation loss: 0.66289074, Gradient norm: 0.18675058
INFO:root:At the start of the epoch: mem (CPU python)=40937.046875MB; mem (CPU total)=40878.89453125MB
INFO:root:[  124] Training loss: 0.66308737, Validation loss: 0.66198356, Gradient norm: 0.17487980
INFO:root:At the start of the epoch: mem (CPU python)=40975.140625MB; mem (CPU total)=40916.8671875MB
INFO:root:[  125] Training loss: 0.66294959, Validation loss: 0.66184076, Gradient norm: 0.16803791
INFO:root:At the start of the epoch: mem (CPU python)=41013.234375MB; mem (CPU total)=40954.96875MB
INFO:root:[  126] Training loss: 0.66296370, Validation loss: 0.66206345, Gradient norm: 0.18251637
INFO:root:At the start of the epoch: mem (CPU python)=41051.328125MB; mem (CPU total)=40992.9921875MB
INFO:root:[  127] Training loss: 0.66296339, Validation loss: 0.66188768, Gradient norm: 0.17444977
INFO:root:At the start of the epoch: mem (CPU python)=41089.42578125MB; mem (CPU total)=41031.5625MB
INFO:root:[  128] Training loss: 0.66279229, Validation loss: 0.66243267, Gradient norm: 0.18700465
INFO:root:At the start of the epoch: mem (CPU python)=41127.5234375MB; mem (CPU total)=41069.34765625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  129] Training loss: 0.66273247, Validation loss: 0.66150881, Gradient norm: 0.16982263
INFO:root:At the start of the epoch: mem (CPU python)=41165.62109375MB; mem (CPU total)=41107.61328125MB
INFO:root:[  130] Training loss: 0.66169609, Validation loss: 0.66098977, Gradient norm: 0.14985636
INFO:root:At the start of the epoch: mem (CPU python)=41203.71875MB; mem (CPU total)=41146.1484375MB
INFO:root:[  131] Training loss: 0.66168399, Validation loss: 0.66067656, Gradient norm: 0.15607897
INFO:root:At the start of the epoch: mem (CPU python)=41241.8125MB; mem (CPU total)=41184.5546875MB
INFO:root:[  132] Training loss: 0.66165865, Validation loss: 0.66044792, Gradient norm: 0.15934749
INFO:root:At the start of the epoch: mem (CPU python)=41279.90625MB; mem (CPU total)=41222.4453125MB
INFO:root:[  133] Training loss: 0.66148591, Validation loss: 0.66042070, Gradient norm: 0.15577426
INFO:root:At the start of the epoch: mem (CPU python)=41318.0MB; mem (CPU total)=41260.6171875MB
INFO:root:[  134] Training loss: 0.66156733, Validation loss: 0.66057360, Gradient norm: 0.15682785
INFO:root:At the start of the epoch: mem (CPU python)=41356.09765625MB; mem (CPU total)=41299.21875MB
INFO:root:[  135] Training loss: 0.66147753, Validation loss: 0.66071921, Gradient norm: 0.15317109
INFO:root:At the start of the epoch: mem (CPU python)=41394.19140625MB; mem (CPU total)=41337.359375MB
INFO:root:[  136] Training loss: 0.66149722, Validation loss: 0.66065147, Gradient norm: 0.16454776
INFO:root:At the start of the epoch: mem (CPU python)=41432.28515625MB; mem (CPU total)=41375.2578125MB
INFO:root:[  137] Training loss: 0.66141270, Validation loss: 0.66104333, Gradient norm: 0.15873495
INFO:root:At the start of the epoch: mem (CPU python)=41470.3828125MB; mem (CPU total)=41413.40234375MB
INFO:root:[  138] Training loss: 0.66138490, Validation loss: 0.66030016, Gradient norm: 0.16299426
INFO:root:At the start of the epoch: mem (CPU python)=41508.48046875MB; mem (CPU total)=41454.0703125MB
INFO:root:[  139] Training loss: 0.66130145, Validation loss: 0.66049329, Gradient norm: 0.16113462
INFO:root:At the start of the epoch: mem (CPU python)=41546.5703125MB; mem (CPU total)=41491.96875MB
INFO:root:[  140] Training loss: 0.66135574, Validation loss: 0.66084247, Gradient norm: 0.16569892
INFO:root:At the start of the epoch: mem (CPU python)=41584.671875MB; mem (CPU total)=41530.11328125MB
INFO:root:[  141] Training loss: 0.66123654, Validation loss: 0.66026571, Gradient norm: 0.15533257
INFO:root:At the start of the epoch: mem (CPU python)=41622.76953125MB; mem (CPU total)=41568.51953125MB
INFO:root:[  142] Training loss: 0.66105195, Validation loss: 0.66076010, Gradient norm: 0.15494899
INFO:root:At the start of the epoch: mem (CPU python)=41660.859375MB; mem (CPU total)=41606.703125MB
INFO:root:[  143] Training loss: 0.66115040, Validation loss: 0.66065642, Gradient norm: 0.15531383
INFO:root:At the start of the epoch: mem (CPU python)=41698.953125MB; mem (CPU total)=41644.59375MB
INFO:root:[  144] Training loss: 0.66131716, Validation loss: 0.66006569, Gradient norm: 0.15881078
INFO:root:At the start of the epoch: mem (CPU python)=41737.0546875MB; mem (CPU total)=41682.56640625MB
INFO:root:[  145] Training loss: 0.66110776, Validation loss: 0.66022409, Gradient norm: 0.15837568
INFO:root:At the start of the epoch: mem (CPU python)=41775.14453125MB; mem (CPU total)=41720.953125MB
INFO:root:[  146] Training loss: 0.66113184, Validation loss: 0.66072257, Gradient norm: 0.15620133
INFO:root:At the start of the epoch: mem (CPU python)=41813.23828125MB; mem (CPU total)=41758.8515625MB
INFO:root:[  147] Training loss: 0.66096795, Validation loss: 0.66058940, Gradient norm: 0.16065677
INFO:root:At the start of the epoch: mem (CPU python)=41851.33984375MB; mem (CPU total)=41796.65625MB
INFO:root:[  148] Training loss: 0.66102760, Validation loss: 0.66053364, Gradient norm: 0.15966054
INFO:root:At the start of the epoch: mem (CPU python)=41889.43359375MB; mem (CPU total)=41835.046875MB
INFO:root:[  149] Training loss: 0.66086334, Validation loss: 0.66063374, Gradient norm: 0.16188922
INFO:root:At the start of the epoch: mem (CPU python)=41927.52734375MB; mem (CPU total)=41872.19921875MB
INFO:root:[  150] Training loss: 0.66094756, Validation loss: 0.66057484, Gradient norm: 0.14965325
INFO:root:At the start of the epoch: mem (CPU python)=41965.62109375MB; mem (CPU total)=41910.33984375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  151] Training loss: 0.66093875, Validation loss: 0.66007085, Gradient norm: 0.15704907
INFO:root:At the start of the epoch: mem (CPU python)=42003.71875MB; mem (CPU total)=41948.2265625MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  152] Training loss: 0.66016587, Validation loss: 0.66005805, Gradient norm: 0.13771016
INFO:root:At the start of the epoch: mem (CPU python)=42041.81640625MB; mem (CPU total)=41986.96875MB
INFO:root:[  153] Training loss: 0.65976851, Validation loss: 0.65950836, Gradient norm: 0.13422663
INFO:root:At the start of the epoch: mem (CPU python)=42079.91015625MB; mem (CPU total)=42024.44921875MB
INFO:root:[  154] Training loss: 0.65980631, Validation loss: 0.65946847, Gradient norm: 0.13935588
INFO:root:At the start of the epoch: mem (CPU python)=42118.0078125MB; mem (CPU total)=42062.90234375MB
INFO:root:[  155] Training loss: 0.65982903, Validation loss: 0.65994448, Gradient norm: 0.14177845
INFO:root:At the start of the epoch: mem (CPU python)=42156.09765625MB; mem (CPU total)=42101.3203125MB
INFO:root:[  156] Training loss: 0.65985769, Validation loss: 0.65953110, Gradient norm: 0.14074503
INFO:root:At the start of the epoch: mem (CPU python)=42194.1953125MB; mem (CPU total)=42139.41015625MB
INFO:root:[  157] Training loss: 0.65976298, Validation loss: 0.65949457, Gradient norm: 0.14312815
INFO:root:At the start of the epoch: mem (CPU python)=42232.29296875MB; mem (CPU total)=42177.37109375MB
INFO:root:[  158] Training loss: 0.65980784, Validation loss: 0.65950196, Gradient norm: 0.14190606
INFO:root:At the start of the epoch: mem (CPU python)=42270.38671875MB; mem (CPU total)=42215.01953125MB
INFO:root:[  159] Training loss: 0.65983380, Validation loss: 0.65936719, Gradient norm: 0.14464775
INFO:root:At the start of the epoch: mem (CPU python)=42308.48046875MB; mem (CPU total)=42254.02734375MB
INFO:root:[  160] Training loss: 0.65972571, Validation loss: 0.65928891, Gradient norm: 0.13958014
INFO:root:At the start of the epoch: mem (CPU python)=42346.578125MB; mem (CPU total)=42292.2578125MB
INFO:root:[  161] Training loss: 0.65972429, Validation loss: 0.65963114, Gradient norm: 0.14537705
INFO:root:At the start of the epoch: mem (CPU python)=42384.671875MB; mem (CPU total)=42330.14453125MB
INFO:root:[  162] Training loss: 0.65971412, Validation loss: 0.65974409, Gradient norm: 0.14059204
INFO:root:At the start of the epoch: mem (CPU python)=42422.765625MB; mem (CPU total)=42368.11328125MB
INFO:root:[  163] Training loss: 0.65980599, Validation loss: 0.65932923, Gradient norm: 0.14545951
INFO:root:At the start of the epoch: mem (CPU python)=42460.86328125MB; mem (CPU total)=42405.74609375MB
INFO:root:[  164] Training loss: 0.65975548, Validation loss: 0.65948577, Gradient norm: 0.14311285
INFO:root:At the start of the epoch: mem (CPU python)=42498.9609375MB; mem (CPU total)=42443.7734375MB
INFO:root:[  165] Training loss: 0.65972895, Validation loss: 0.65959313, Gradient norm: 0.14373741
INFO:root:At the start of the epoch: mem (CPU python)=42537.0546875MB; mem (CPU total)=42482.16015625MB
INFO:root:[  166] Training loss: 0.65993900, Validation loss: 0.65942081, Gradient norm: 0.14947734
INFO:root:At the start of the epoch: mem (CPU python)=42575.1484375MB; mem (CPU total)=42520.3046875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  167] Training loss: 0.65979290, Validation loss: 0.65938845, Gradient norm: 0.14251547
INFO:root:At the start of the epoch: mem (CPU python)=42613.2421875MB; mem (CPU total)=42558.44921875MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  168] Training loss: 0.65950045, Validation loss: 0.65957019, Gradient norm: 0.14137497
INFO:root:At the start of the epoch: mem (CPU python)=42651.33984375MB; mem (CPU total)=42596.8671875MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  169] Training loss: 0.65940992, Validation loss: 0.65982261, Gradient norm: 0.13766295
INFO:root:At the start of the epoch: mem (CPU python)=42689.43359375MB; mem (CPU total)=42634.75MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:EP 169: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=42727.52734375MB; mem (CPU total)=42672.89453125MB
INFO:root:Training the model took 15157.874s.
INFO:root:Emptying the cuda cache took 0.011s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93232
INFO:root:EnergyScoreTrain: 0.65615
INFO:root:CRPSTrain: 0.52778
INFO:root:Gaussian NLLTrain: 1.45287
INFO:root:CoverageTrain: 0.92597
INFO:root:IntervalWidthTrain: 3.44164
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93704
INFO:root:EnergyScoreValidation: 0.65951
INFO:root:CRPSValidation: 0.53083
INFO:root:Gaussian NLLValidation: 1.42822
INFO:root:CoverageValidation: 0.92481
INFO:root:IntervalWidthValidation: 3.44463
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93611
INFO:root:EnergyScoreTest: 0.65884
INFO:root:CRPSTest: 0.53026
INFO:root:Gaussian NLLTest: 1.41847
INFO:root:CoverageTest: 0.92475
INFO:root:IntervalWidthTest: 3.44241
INFO:root:After validation: mem (CPU python)=42770.515625MB; mem (CPU total)=42718.0546875MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=42770.515625MB; mem (CPU total)=42718.046875MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=42770.54296875MB; mem (CPU total)=42718.046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=42770.54296875MB; mem (CPU total)=42717.75390625MB
INFO:root:[    1] Training loss: 0.71481047, Validation loss: 0.70362401, Gradient norm: 0.04553561
INFO:root:At the start of the epoch: mem (CPU python)=42808.4609375MB; mem (CPU total)=42756.171875MB
INFO:root:[    2] Training loss: 0.69783531, Validation loss: 0.69352998, Gradient norm: 0.06124146
INFO:root:At the start of the epoch: mem (CPU python)=42846.5546875MB; mem (CPU total)=42794.34375MB
INFO:root:[    3] Training loss: 0.69211583, Validation loss: 0.68982967, Gradient norm: 0.07643784
INFO:root:At the start of the epoch: mem (CPU python)=42884.65234375MB; mem (CPU total)=42832.3671875MB
INFO:root:[    4] Training loss: 0.68921069, Validation loss: 0.68764781, Gradient norm: 0.08680668
INFO:root:At the start of the epoch: mem (CPU python)=42922.74609375MB; mem (CPU total)=42870.5703125MB
INFO:root:[    5] Training loss: 0.68733109, Validation loss: 0.68614462, Gradient norm: 0.08798787
INFO:root:At the start of the epoch: mem (CPU python)=42960.83984375MB; mem (CPU total)=42907.375MB
INFO:root:[    6] Training loss: 0.68600860, Validation loss: 0.68482297, Gradient norm: 0.08891306
INFO:root:At the start of the epoch: mem (CPU python)=42998.9375MB; mem (CPU total)=42945.69921875MB
INFO:root:[    7] Training loss: 0.68483607, Validation loss: 0.68408407, Gradient norm: 0.08933471
INFO:root:At the start of the epoch: mem (CPU python)=43037.03515625MB; mem (CPU total)=42983.84375MB
INFO:root:[    8] Training loss: 0.68408695, Validation loss: 0.68348634, Gradient norm: 0.09575838
INFO:root:At the start of the epoch: mem (CPU python)=43075.12890625MB; mem (CPU total)=43022.046875MB
INFO:root:[    9] Training loss: 0.68313482, Validation loss: 0.68226619, Gradient norm: 0.08854313
INFO:root:At the start of the epoch: mem (CPU python)=43113.22265625MB; mem (CPU total)=43060.5703125MB
INFO:root:[   10] Training loss: 0.68224059, Validation loss: 0.68177030, Gradient norm: 0.09335393
INFO:root:At the start of the epoch: mem (CPU python)=43151.3203125MB; mem (CPU total)=43099.32421875MB
INFO:root:[   11] Training loss: 0.68149519, Validation loss: 0.68103027, Gradient norm: 0.09228338
INFO:root:At the start of the epoch: mem (CPU python)=43189.4140625MB; mem (CPU total)=43135.984375MB
INFO:root:[   12] Training loss: 0.68079945, Validation loss: 0.68080726, Gradient norm: 0.09619529
INFO:root:At the start of the epoch: mem (CPU python)=43227.5078125MB; mem (CPU total)=43174.25MB
INFO:root:[   13] Training loss: 0.68047605, Validation loss: 0.67936714, Gradient norm: 0.10282946
INFO:root:At the start of the epoch: mem (CPU python)=43265.60546875MB; mem (CPU total)=43212.82421875MB
INFO:root:[   14] Training loss: 0.67971489, Validation loss: 0.67905685, Gradient norm: 0.10280137
INFO:root:At the start of the epoch: mem (CPU python)=43303.69921875MB; mem (CPU total)=43251.046875MB
INFO:root:[   15] Training loss: 0.67933959, Validation loss: 0.67809946, Gradient norm: 0.10148482
INFO:root:At the start of the epoch: mem (CPU python)=43341.796875MB; mem (CPU total)=43289.625MB
INFO:root:[   16] Training loss: 0.67868086, Validation loss: 0.67765843, Gradient norm: 0.10977400
INFO:root:At the start of the epoch: mem (CPU python)=43379.890625MB; mem (CPU total)=43327.65625MB
INFO:root:[   17] Training loss: 0.67824214, Validation loss: 0.67744780, Gradient norm: 0.11162526
INFO:root:At the start of the epoch: mem (CPU python)=43417.98828125MB; mem (CPU total)=43365.80859375MB
INFO:root:[   18] Training loss: 0.67766222, Validation loss: 0.67701523, Gradient norm: 0.11373058
INFO:root:At the start of the epoch: mem (CPU python)=43456.08203125MB; mem (CPU total)=43404.67578125MB
INFO:root:[   19] Training loss: 0.67699517, Validation loss: 0.67686091, Gradient norm: 0.11051501
INFO:root:At the start of the epoch: mem (CPU python)=43494.17578125MB; mem (CPU total)=43442.8125MB
INFO:root:[   20] Training loss: 0.67685848, Validation loss: 0.67617595, Gradient norm: 0.11677352
INFO:root:At the start of the epoch: mem (CPU python)=43532.2734375MB; mem (CPU total)=43481.03515625MB
INFO:root:[   21] Training loss: 0.67634542, Validation loss: 0.67559640, Gradient norm: 0.11898638
INFO:root:At the start of the epoch: mem (CPU python)=43570.37109375MB; mem (CPU total)=43519.48828125MB
INFO:root:[   22] Training loss: 0.67598663, Validation loss: 0.67461204, Gradient norm: 0.11965943
INFO:root:At the start of the epoch: mem (CPU python)=43608.46484375MB; mem (CPU total)=43557.55078125MB
INFO:root:[   23] Training loss: 0.67520216, Validation loss: 0.67467903, Gradient norm: 0.11338105
INFO:root:At the start of the epoch: mem (CPU python)=43646.5546875MB; mem (CPU total)=43595.9375MB
INFO:root:[   24] Training loss: 0.67523136, Validation loss: 0.67342781, Gradient norm: 0.11899009
INFO:root:At the start of the epoch: mem (CPU python)=43684.65625MB; mem (CPU total)=43633.89453125MB
INFO:root:[   25] Training loss: 0.67462010, Validation loss: 0.67350547, Gradient norm: 0.12223704
INFO:root:At the start of the epoch: mem (CPU python)=43722.74609375MB; mem (CPU total)=43672.0390625MB
INFO:root:[   26] Training loss: 0.67432355, Validation loss: 0.67314240, Gradient norm: 0.12909044
INFO:root:At the start of the epoch: mem (CPU python)=43760.84375MB; mem (CPU total)=43710.26171875MB
INFO:root:[   27] Training loss: 0.67378730, Validation loss: 0.67263887, Gradient norm: 0.12090307
INFO:root:At the start of the epoch: mem (CPU python)=43798.94140625MB; mem (CPU total)=43747.828125MB
INFO:root:[   28] Training loss: 0.67353168, Validation loss: 0.67303787, Gradient norm: 0.12421617
INFO:root:At the start of the epoch: mem (CPU python)=43837.03515625MB; mem (CPU total)=43786.34375MB
INFO:root:[   29] Training loss: 0.67316198, Validation loss: 0.67201207, Gradient norm: 0.12954606
INFO:root:At the start of the epoch: mem (CPU python)=43875.1328125MB; mem (CPU total)=43824.13671875MB
INFO:root:[   30] Training loss: 0.67260520, Validation loss: 0.67148791, Gradient norm: 0.12330580
INFO:root:At the start of the epoch: mem (CPU python)=43913.23046875MB; mem (CPU total)=43862.4765625MB
INFO:root:[   31] Training loss: 0.67260113, Validation loss: 0.67177358, Gradient norm: 0.12515649
INFO:root:At the start of the epoch: mem (CPU python)=43951.3203125MB; mem (CPU total)=43900.8671875MB
INFO:root:[   32] Training loss: 0.67232890, Validation loss: 0.67142204, Gradient norm: 0.12565349
INFO:root:At the start of the epoch: mem (CPU python)=43989.41796875MB; mem (CPU total)=43939.09375MB
INFO:root:[   33] Training loss: 0.67212201, Validation loss: 0.67123525, Gradient norm: 0.12456765
INFO:root:At the start of the epoch: mem (CPU python)=44027.51171875MB; mem (CPU total)=43977.83984375MB
INFO:root:[   34] Training loss: 0.67175538, Validation loss: 0.67066254, Gradient norm: 0.12581229
INFO:root:At the start of the epoch: mem (CPU python)=44065.609375MB; mem (CPU total)=44015.83203125MB
INFO:root:[   35] Training loss: 0.67155204, Validation loss: 0.67110231, Gradient norm: 0.12557953
INFO:root:At the start of the epoch: mem (CPU python)=44103.703125MB; mem (CPU total)=44053.6796875MB
INFO:root:[   36] Training loss: 0.67134121, Validation loss: 0.67068809, Gradient norm: 0.13459865
INFO:root:At the start of the epoch: mem (CPU python)=44141.796875MB; mem (CPU total)=44091.82421875MB
INFO:root:[   37] Training loss: 0.67125265, Validation loss: 0.67024892, Gradient norm: 0.12837489
INFO:root:At the start of the epoch: mem (CPU python)=44179.8984375MB; mem (CPU total)=44130.046875MB
INFO:root:[   38] Training loss: 0.67135966, Validation loss: 0.67043092, Gradient norm: 0.14047142
INFO:root:At the start of the epoch: mem (CPU python)=44217.98828125MB; mem (CPU total)=44168.32421875MB
INFO:root:[   39] Training loss: 0.67112773, Validation loss: 0.66954664, Gradient norm: 0.12660014
INFO:root:At the start of the epoch: mem (CPU python)=44256.0859375MB; mem (CPU total)=44206.27734375MB
INFO:root:[   40] Training loss: 0.67070612, Validation loss: 0.66945446, Gradient norm: 0.12376842
INFO:root:At the start of the epoch: mem (CPU python)=44294.1796875MB; mem (CPU total)=44244.55859375MB
INFO:root:[   41] Training loss: 0.67063921, Validation loss: 0.66949981, Gradient norm: 0.12891915
INFO:root:At the start of the epoch: mem (CPU python)=44332.27734375MB; mem (CPU total)=44282.97265625MB
INFO:root:[   42] Training loss: 0.67056039, Validation loss: 0.66969570, Gradient norm: 0.12690047
INFO:root:At the start of the epoch: mem (CPU python)=44370.37109375MB; mem (CPU total)=44321.0859375MB
INFO:root:[   43] Training loss: 0.67033946, Validation loss: 0.66927633, Gradient norm: 0.12886240
INFO:root:At the start of the epoch: mem (CPU python)=44408.46484375MB; mem (CPU total)=44359.33984375MB
INFO:root:[   44] Training loss: 0.67022357, Validation loss: 0.66880438, Gradient norm: 0.12775909
INFO:root:At the start of the epoch: mem (CPU python)=44446.5625MB; mem (CPU total)=44397.60546875MB
INFO:root:[   45] Training loss: 0.66994113, Validation loss: 0.66894988, Gradient norm: 0.12396563
INFO:root:At the start of the epoch: mem (CPU python)=44484.65625MB; mem (CPU total)=44435.99609375MB
INFO:root:[   46] Training loss: 0.67001008, Validation loss: 0.66870960, Gradient norm: 0.12795560
INFO:root:At the start of the epoch: mem (CPU python)=44522.75390625MB; mem (CPU total)=44474.18359375MB
INFO:root:[   47] Training loss: 0.66981821, Validation loss: 0.66878146, Gradient norm: 0.12806186
INFO:root:At the start of the epoch: mem (CPU python)=44560.84765625MB; mem (CPU total)=44512.32421875MB
INFO:root:[   48] Training loss: 0.66970478, Validation loss: 0.66874421, Gradient norm: 0.12618909
INFO:root:At the start of the epoch: mem (CPU python)=44598.94140625MB; mem (CPU total)=44550.46484375MB
INFO:root:[   49] Training loss: 0.66978774, Validation loss: 0.66892416, Gradient norm: 0.12679660
INFO:root:At the start of the epoch: mem (CPU python)=44637.03515625MB; mem (CPU total)=44588.0234375MB
INFO:root:[   50] Training loss: 0.66966944, Validation loss: 0.66781871, Gradient norm: 0.12314055
INFO:root:At the start of the epoch: mem (CPU python)=44675.1328125MB; mem (CPU total)=44626.3359375MB
INFO:root:[   51] Training loss: 0.66941744, Validation loss: 0.66834147, Gradient norm: 0.13664228
INFO:root:At the start of the epoch: mem (CPU python)=44713.23046875MB; mem (CPU total)=44664.7265625MB
INFO:root:[   52] Training loss: 0.66926159, Validation loss: 0.66815648, Gradient norm: 0.13305032
INFO:root:At the start of the epoch: mem (CPU python)=44751.32421875MB; mem (CPU total)=44703.109375MB
INFO:root:[   53] Training loss: 0.66916237, Validation loss: 0.66921897, Gradient norm: 0.12925695
INFO:root:At the start of the epoch: mem (CPU python)=44789.41796875MB; mem (CPU total)=44740.8125MB
INFO:root:[   54] Training loss: 0.66923601, Validation loss: 0.66857734, Gradient norm: 0.14088370
INFO:root:At the start of the epoch: mem (CPU python)=44827.515625MB; mem (CPU total)=44778.46484375MB
INFO:root:[   55] Training loss: 0.66907566, Validation loss: 0.66790605, Gradient norm: 0.13296867
INFO:root:At the start of the epoch: mem (CPU python)=44865.609375MB; mem (CPU total)=44816.85546875MB
INFO:root:[   56] Training loss: 0.66900768, Validation loss: 0.66793792, Gradient norm: 0.12634292
INFO:root:At the start of the epoch: mem (CPU python)=44903.703125MB; mem (CPU total)=44855.24609375MB
INFO:root:[   57] Training loss: 0.66882910, Validation loss: 0.66751035, Gradient norm: 0.12674458
INFO:root:At the start of the epoch: mem (CPU python)=44941.80078125MB; mem (CPU total)=44893.78125MB
INFO:root:[   58] Training loss: 0.66866693, Validation loss: 0.66828595, Gradient norm: 0.13590557
INFO:root:At the start of the epoch: mem (CPU python)=44979.8984375MB; mem (CPU total)=44931.95703125MB
INFO:root:[   59] Training loss: 0.66869492, Validation loss: 0.66810045, Gradient norm: 0.14053257
INFO:root:At the start of the epoch: mem (CPU python)=45017.9921875MB; mem (CPU total)=44969.42578125MB
INFO:root:[   60] Training loss: 0.66851774, Validation loss: 0.66788417, Gradient norm: 0.13374708
INFO:root:At the start of the epoch: mem (CPU python)=45056.0859375MB; mem (CPU total)=45007.19921875MB
INFO:root:[   61] Training loss: 0.66849924, Validation loss: 0.66704472, Gradient norm: 0.13010682
INFO:root:At the start of the epoch: mem (CPU python)=45094.1875MB; mem (CPU total)=45047.40625MB
INFO:root:[   62] Training loss: 0.66847030, Validation loss: 0.66738873, Gradient norm: 0.13129832
INFO:root:At the start of the epoch: mem (CPU python)=45132.27734375MB; mem (CPU total)=45085.73046875MB
INFO:root:[   63] Training loss: 0.66845716, Validation loss: 0.66731424, Gradient norm: 0.12760788
INFO:root:At the start of the epoch: mem (CPU python)=45170.37109375MB; mem (CPU total)=45123.78125MB
INFO:root:[   64] Training loss: 0.66811585, Validation loss: 0.66710202, Gradient norm: 0.13492930
INFO:root:At the start of the epoch: mem (CPU python)=45208.46875MB; mem (CPU total)=45161.83203125MB
INFO:root:[   65] Training loss: 0.66810782, Validation loss: 0.66705251, Gradient norm: 0.12710302
INFO:root:At the start of the epoch: mem (CPU python)=45246.5625MB; mem (CPU total)=45200.6015625MB
INFO:root:[   66] Training loss: 0.66806606, Validation loss: 0.66728122, Gradient norm: 0.13599229
INFO:root:At the start of the epoch: mem (CPU python)=45284.66015625MB; mem (CPU total)=45238.4765625MB
INFO:root:[   67] Training loss: 0.66820378, Validation loss: 0.66701268, Gradient norm: 0.13547955
INFO:root:At the start of the epoch: mem (CPU python)=45322.7578125MB; mem (CPU total)=45276.734375MB
INFO:root:[   68] Training loss: 0.66801828, Validation loss: 0.66737834, Gradient norm: 0.13048180
INFO:root:At the start of the epoch: mem (CPU python)=45360.8515625MB; mem (CPU total)=45314.875MB
INFO:root:[   69] Training loss: 0.66761058, Validation loss: 0.66672337, Gradient norm: 0.13270168
INFO:root:At the start of the epoch: mem (CPU python)=45398.94921875MB; mem (CPU total)=45353.48046875MB
INFO:root:[   70] Training loss: 0.66777101, Validation loss: 0.66651285, Gradient norm: 0.13390401
INFO:root:At the start of the epoch: mem (CPU python)=45437.04296875MB; mem (CPU total)=45390.99609375MB
INFO:root:[   71] Training loss: 0.66773358, Validation loss: 0.66714028, Gradient norm: 0.13413304
INFO:root:At the start of the epoch: mem (CPU python)=45475.13671875MB; mem (CPU total)=45428.88671875MB
INFO:root:[   72] Training loss: 0.66784791, Validation loss: 0.66648972, Gradient norm: 0.14410391
INFO:root:At the start of the epoch: mem (CPU python)=45513.234375MB; mem (CPU total)=45466.58203125MB
INFO:root:[   73] Training loss: 0.66757064, Validation loss: 0.66647957, Gradient norm: 0.13157963
INFO:root:At the start of the epoch: mem (CPU python)=45551.328125MB; mem (CPU total)=45504.55859375MB
INFO:root:[   74] Training loss: 0.66739570, Validation loss: 0.66675540, Gradient norm: 0.13559391
INFO:root:At the start of the epoch: mem (CPU python)=45589.41796875MB; mem (CPU total)=45542.45703125MB
INFO:root:[   75] Training loss: 0.66739033, Validation loss: 0.66709302, Gradient norm: 0.13549905
INFO:root:At the start of the epoch: mem (CPU python)=45627.51953125MB; mem (CPU total)=45581.1015625MB
INFO:root:[   76] Training loss: 0.66733818, Validation loss: 0.66653912, Gradient norm: 0.13597163
INFO:root:At the start of the epoch: mem (CPU python)=45665.6171875MB; mem (CPU total)=45619.0859375MB
INFO:root:[   77] Training loss: 0.66722009, Validation loss: 0.66652527, Gradient norm: 0.13857615
INFO:root:At the start of the epoch: mem (CPU python)=45703.7109375MB; mem (CPU total)=45656.5390625MB
INFO:root:[   78] Training loss: 0.66683672, Validation loss: 0.66601460, Gradient norm: 0.12690118
INFO:root:At the start of the epoch: mem (CPU python)=45741.80859375MB; mem (CPU total)=45694.41796875MB
INFO:root:[   79] Training loss: 0.66686208, Validation loss: 0.66633705, Gradient norm: 0.14008700
INFO:root:At the start of the epoch: mem (CPU python)=45779.8984375MB; mem (CPU total)=45732.5546875MB
INFO:root:[   80] Training loss: 0.66694120, Validation loss: 0.66541696, Gradient norm: 0.13958911
INFO:root:At the start of the epoch: mem (CPU python)=45818.0MB; mem (CPU total)=45770.734375MB
INFO:root:[   81] Training loss: 0.66663866, Validation loss: 0.66574214, Gradient norm: 0.13401702
INFO:root:At the start of the epoch: mem (CPU python)=45856.09375MB; mem (CPU total)=45808.83984375MB
INFO:root:[   82] Training loss: 0.66670074, Validation loss: 0.66606345, Gradient norm: 0.14823165
INFO:root:At the start of the epoch: mem (CPU python)=45894.1875MB; mem (CPU total)=45847.23046875MB
INFO:root:[   83] Training loss: 0.66655505, Validation loss: 0.66511420, Gradient norm: 0.14927313
INFO:root:At the start of the epoch: mem (CPU python)=45932.28125MB; mem (CPU total)=45885.25MB
INFO:root:[   84] Training loss: 0.66630958, Validation loss: 0.66493070, Gradient norm: 0.13206580
INFO:root:At the start of the epoch: mem (CPU python)=45970.37890625MB; mem (CPU total)=45923.5859375MB
INFO:root:[   85] Training loss: 0.66614470, Validation loss: 0.66493360, Gradient norm: 0.14364393
INFO:root:At the start of the epoch: mem (CPU python)=46008.4765625MB; mem (CPU total)=45961.9765625MB
INFO:root:[   86] Training loss: 0.66597213, Validation loss: 0.66489605, Gradient norm: 0.13122340
INFO:root:At the start of the epoch: mem (CPU python)=46046.57421875MB; mem (CPU total)=45998.8046875MB
INFO:root:[   87] Training loss: 0.66575905, Validation loss: 0.66448449, Gradient norm: 0.14594417
INFO:root:At the start of the epoch: mem (CPU python)=46084.66796875MB; mem (CPU total)=46036.71875MB
INFO:root:[   88] Training loss: 0.66558197, Validation loss: 0.66472258, Gradient norm: 0.13846177
INFO:root:At the start of the epoch: mem (CPU python)=46122.76171875MB; mem (CPU total)=46075.1328125MB
INFO:root:[   89] Training loss: 0.66536764, Validation loss: 0.66450739, Gradient norm: 0.13593701
INFO:root:At the start of the epoch: mem (CPU python)=46160.85546875MB; mem (CPU total)=46113.27734375MB
INFO:root:[   90] Training loss: 0.66522358, Validation loss: 0.66463133, Gradient norm: 0.15021781
INFO:root:At the start of the epoch: mem (CPU python)=46198.94921875MB; mem (CPU total)=46150.75MB
INFO:root:[   91] Training loss: 0.66495079, Validation loss: 0.66409442, Gradient norm: 0.14800212
INFO:root:At the start of the epoch: mem (CPU python)=46237.046875MB; mem (CPU total)=46189.23828125MB
INFO:root:[   92] Training loss: 0.66498327, Validation loss: 0.66290303, Gradient norm: 0.15217656
INFO:root:At the start of the epoch: mem (CPU python)=46275.14453125MB; mem (CPU total)=46227.5078125MB
INFO:root:[   93] Training loss: 0.66471358, Validation loss: 0.66321663, Gradient norm: 0.13058856
INFO:root:At the start of the epoch: mem (CPU python)=46313.23828125MB; mem (CPU total)=46265.9296875MB
INFO:root:[   94] Training loss: 0.66463190, Validation loss: 0.66357373, Gradient norm: 0.14378766
INFO:root:At the start of the epoch: mem (CPU python)=46351.33203125MB; mem (CPU total)=46304.14453125MB
INFO:root:[   95] Training loss: 0.66449687, Validation loss: 0.66315784, Gradient norm: 0.14156145
INFO:root:At the start of the epoch: mem (CPU python)=46389.4296875MB; mem (CPU total)=46342.1640625MB
INFO:root:[   96] Training loss: 0.66440646, Validation loss: 0.66288907, Gradient norm: 0.14102489
INFO:root:At the start of the epoch: mem (CPU python)=46427.52734375MB; mem (CPU total)=46379.9296875MB
INFO:root:[   97] Training loss: 0.66410782, Validation loss: 0.66307431, Gradient norm: 0.13828551
INFO:root:At the start of the epoch: mem (CPU python)=46465.6171875MB; mem (CPU total)=46418.3515625MB
INFO:root:[   98] Training loss: 0.66411152, Validation loss: 0.66287112, Gradient norm: 0.14400811
INFO:root:At the start of the epoch: mem (CPU python)=46503.71875MB; mem (CPU total)=46456.7421875MB
INFO:root:[   99] Training loss: 0.66388762, Validation loss: 0.66345888, Gradient norm: 0.14079396
INFO:root:At the start of the epoch: mem (CPU python)=46541.80859375MB; mem (CPU total)=46494.88671875MB
INFO:root:[  100] Training loss: 0.66386043, Validation loss: 0.66329873, Gradient norm: 0.13871129
INFO:root:At the start of the epoch: mem (CPU python)=46579.90234375MB; mem (CPU total)=46533.03125MB
INFO:root:[  101] Training loss: 0.66408285, Validation loss: 0.66269334, Gradient norm: 0.15124354
INFO:root:At the start of the epoch: mem (CPU python)=46618.0MB; mem (CPU total)=46571.69921875MB
INFO:root:[  102] Training loss: 0.66362952, Validation loss: 0.66246155, Gradient norm: 0.14257086
INFO:root:At the start of the epoch: mem (CPU python)=46656.09765625MB; mem (CPU total)=46609.35546875MB
INFO:root:[  103] Training loss: 0.66375673, Validation loss: 0.66311791, Gradient norm: 0.14689938
INFO:root:At the start of the epoch: mem (CPU python)=46694.19140625MB; mem (CPU total)=46647.484375MB
INFO:root:[  104] Training loss: 0.66360846, Validation loss: 0.66264493, Gradient norm: 0.14746234
INFO:root:At the start of the epoch: mem (CPU python)=46732.28515625MB; mem (CPU total)=46685.66015625MB
INFO:root:[  105] Training loss: 0.66355620, Validation loss: 0.66330748, Gradient norm: 0.13702197
INFO:root:At the start of the epoch: mem (CPU python)=46770.3828125MB; mem (CPU total)=46723.40234375MB
INFO:root:[  106] Training loss: 0.66344118, Validation loss: 0.66302028, Gradient norm: 0.14914166
INFO:root:At the start of the epoch: mem (CPU python)=46808.4765625MB; mem (CPU total)=46762.0390625MB
INFO:root:[  107] Training loss: 0.66335895, Validation loss: 0.66192756, Gradient norm: 0.13521394
INFO:root:At the start of the epoch: mem (CPU python)=46846.57421875MB; mem (CPU total)=46800.5390625MB
INFO:root:[  108] Training loss: 0.66311803, Validation loss: 0.66212308, Gradient norm: 0.14389832
INFO:root:At the start of the epoch: mem (CPU python)=46884.6640625MB; mem (CPU total)=46838.49609375MB
INFO:root:[  109] Training loss: 0.66331974, Validation loss: 0.66199361, Gradient norm: 0.13985335
INFO:root:At the start of the epoch: mem (CPU python)=46922.765625MB; mem (CPU total)=46876.63671875MB
INFO:root:[  110] Training loss: 0.66320710, Validation loss: 0.66216451, Gradient norm: 0.15013404
INFO:root:At the start of the epoch: mem (CPU python)=46960.859375MB; mem (CPU total)=46913.98046875MB
INFO:root:[  111] Training loss: 0.66311747, Validation loss: 0.66226662, Gradient norm: 0.15174025
INFO:root:At the start of the epoch: mem (CPU python)=46998.953125MB; mem (CPU total)=46952.3359375MB
INFO:root:[  112] Training loss: 0.66294298, Validation loss: 0.66178961, Gradient norm: 0.13929374
INFO:root:At the start of the epoch: mem (CPU python)=47037.0546875MB; mem (CPU total)=46991.22265625MB
INFO:root:[  113] Training loss: 0.66270768, Validation loss: 0.66208950, Gradient norm: 0.14048809
INFO:root:At the start of the epoch: mem (CPU python)=47075.14453125MB; mem (CPU total)=47028.65234375MB
INFO:root:[  114] Training loss: 0.66263351, Validation loss: 0.66141431, Gradient norm: 0.13252171
INFO:root:At the start of the epoch: mem (CPU python)=47113.2421875MB; mem (CPU total)=47067.16015625MB
INFO:root:[  115] Training loss: 0.66278195, Validation loss: 0.66165651, Gradient norm: 0.14160664
INFO:root:At the start of the epoch: mem (CPU python)=47151.3359375MB; mem (CPU total)=47104.99609375MB
INFO:root:[  116] Training loss: 0.66256126, Validation loss: 0.66189067, Gradient norm: 0.14297161
INFO:root:At the start of the epoch: mem (CPU python)=47189.4296875MB; mem (CPU total)=47143.1328125MB
INFO:root:[  117] Training loss: 0.66259451, Validation loss: 0.66164230, Gradient norm: 0.14454663
INFO:root:At the start of the epoch: mem (CPU python)=47227.52734375MB; mem (CPU total)=47181.4609375MB
INFO:root:[  118] Training loss: 0.66260175, Validation loss: 0.66149774, Gradient norm: 0.14161998
INFO:root:At the start of the epoch: mem (CPU python)=47265.62109375MB; mem (CPU total)=47219.359375MB
INFO:root:[  119] Training loss: 0.66245157, Validation loss: 0.66107498, Gradient norm: 0.14817244
INFO:root:At the start of the epoch: mem (CPU python)=47303.71875MB; mem (CPU total)=47257.58203125MB
INFO:root:[  120] Training loss: 0.66239451, Validation loss: 0.66130357, Gradient norm: 0.14490723
INFO:root:At the start of the epoch: mem (CPU python)=47341.8125MB; mem (CPU total)=47295.5546875MB
INFO:root:[  121] Training loss: 0.66230266, Validation loss: 0.66174962, Gradient norm: 0.14640429
INFO:root:At the start of the epoch: mem (CPU python)=47379.90625MB; mem (CPU total)=47334.19140625MB
INFO:root:[  122] Training loss: 0.66221106, Validation loss: 0.66157891, Gradient norm: 0.14628474
INFO:root:At the start of the epoch: mem (CPU python)=47418.00390625MB; mem (CPU total)=47372.265625MB
INFO:root:[  123] Training loss: 0.66214340, Validation loss: 0.66144570, Gradient norm: 0.13918209
INFO:root:At the start of the epoch: mem (CPU python)=47456.09765625MB; mem (CPU total)=47410.03515625MB
INFO:root:[  124] Training loss: 0.66229438, Validation loss: 0.66148943, Gradient norm: 0.15575637
INFO:root:At the start of the epoch: mem (CPU python)=47494.19140625MB; mem (CPU total)=47448.85546875MB
INFO:root:[  125] Training loss: 0.66194093, Validation loss: 0.66103680, Gradient norm: 0.13930188
INFO:root:At the start of the epoch: mem (CPU python)=47532.2890625MB; mem (CPU total)=47486.4296875MB
INFO:root:[  126] Training loss: 0.66206717, Validation loss: 0.66098130, Gradient norm: 0.15565863
INFO:root:At the start of the epoch: mem (CPU python)=47570.38671875MB; mem (CPU total)=47524.7109375MB
INFO:root:[  127] Training loss: 0.66193542, Validation loss: 0.66143948, Gradient norm: 0.14302508
INFO:root:At the start of the epoch: mem (CPU python)=47608.48046875MB; mem (CPU total)=47563.140625MB
INFO:root:[  128] Training loss: 0.66193641, Validation loss: 0.66098088, Gradient norm: 0.14830453
INFO:root:At the start of the epoch: mem (CPU python)=47646.578125MB; mem (CPU total)=47601.203125MB
INFO:root:[  129] Training loss: 0.66184870, Validation loss: 0.66121466, Gradient norm: 0.15239576
INFO:root:At the start of the epoch: mem (CPU python)=47684.671875MB; mem (CPU total)=47639.7890625MB
INFO:root:[  130] Training loss: 0.66164104, Validation loss: 0.66111265, Gradient norm: 0.14755145
INFO:root:At the start of the epoch: mem (CPU python)=47722.765625MB; mem (CPU total)=47677.97265625MB
INFO:root:[  131] Training loss: 0.66171722, Validation loss: 0.66129766, Gradient norm: 0.14894225
INFO:root:At the start of the epoch: mem (CPU python)=47760.859375MB; mem (CPU total)=47716.09375MB
INFO:root:[  132] Training loss: 0.66175727, Validation loss: 0.66057427, Gradient norm: 0.15772167
INFO:root:At the start of the epoch: mem (CPU python)=47798.9609375MB; mem (CPU total)=47754.4375MB
INFO:root:[  133] Training loss: 0.66171366, Validation loss: 0.66089148, Gradient norm: 0.16427896
INFO:root:At the start of the epoch: mem (CPU python)=47837.0546875MB; mem (CPU total)=47792.62109375MB
INFO:root:[  134] Training loss: 0.66165295, Validation loss: 0.66057519, Gradient norm: 0.15404451
INFO:root:At the start of the epoch: mem (CPU python)=47875.1484375MB; mem (CPU total)=47830.8046875MB
INFO:root:[  135] Training loss: 0.66146745, Validation loss: 0.66104948, Gradient norm: 0.16337833
INFO:root:At the start of the epoch: mem (CPU python)=47913.2421875MB; mem (CPU total)=47868.92578125MB
INFO:root:[  136] Training loss: 0.66144426, Validation loss: 0.66041299, Gradient norm: 0.15412581
INFO:root:At the start of the epoch: mem (CPU python)=47951.34375MB; mem (CPU total)=47907.41796875MB
INFO:root:[  137] Training loss: 0.66138770, Validation loss: 0.66094917, Gradient norm: 0.15377263
INFO:root:At the start of the epoch: mem (CPU python)=47989.43359375MB; mem (CPU total)=47945.35546875MB
INFO:root:[  138] Training loss: 0.66137641, Validation loss: 0.66171080, Gradient norm: 0.15982984
INFO:root:At the start of the epoch: mem (CPU python)=48027.52734375MB; mem (CPU total)=47983.72265625MB
INFO:root:[  139] Training loss: 0.66111901, Validation loss: 0.66087732, Gradient norm: 0.15094877
INFO:root:At the start of the epoch: mem (CPU python)=48065.625MB; mem (CPU total)=48021.64453125MB
INFO:root:[  140] Training loss: 0.66132526, Validation loss: 0.66100107, Gradient norm: 0.16978093
INFO:root:At the start of the epoch: mem (CPU python)=48103.71875MB; mem (CPU total)=48060.07421875MB
INFO:root:[  141] Training loss: 0.66126849, Validation loss: 0.66039977, Gradient norm: 0.16065721
INFO:root:At the start of the epoch: mem (CPU python)=48141.81640625MB; mem (CPU total)=48098.52734375MB
INFO:root:[  142] Training loss: 0.66109163, Validation loss: 0.66013697, Gradient norm: 0.15284215
INFO:root:At the start of the epoch: mem (CPU python)=48179.91015625MB; mem (CPU total)=48136.8359375MB
INFO:root:[  143] Training loss: 0.66111624, Validation loss: 0.66015569, Gradient norm: 0.16680526
INFO:root:At the start of the epoch: mem (CPU python)=48218.00390625MB; mem (CPU total)=48175.01953125MB
INFO:root:[  144] Training loss: 0.66102518, Validation loss: 0.66089832, Gradient norm: 0.15735527
INFO:root:At the start of the epoch: mem (CPU python)=48256.1015625MB; mem (CPU total)=48213.00390625MB
INFO:root:[  145] Training loss: 0.66102530, Validation loss: 0.66065166, Gradient norm: 0.16593533
INFO:root:At the start of the epoch: mem (CPU python)=48294.1953125MB; mem (CPU total)=48250.90625MB
INFO:root:[  146] Training loss: 0.66075053, Validation loss: 0.65996732, Gradient norm: 0.15507427
INFO:root:At the start of the epoch: mem (CPU python)=48332.29296875MB; mem (CPU total)=48289.4921875MB
INFO:root:[  147] Training loss: 0.66069522, Validation loss: 0.65989276, Gradient norm: 0.15552548
INFO:root:At the start of the epoch: mem (CPU python)=48370.390625MB; mem (CPU total)=48328.31640625MB
INFO:root:[  148] Training loss: 0.66075512, Validation loss: 0.65976872, Gradient norm: 0.14960436
INFO:root:At the start of the epoch: mem (CPU python)=48408.484375MB; mem (CPU total)=48366.58203125MB
INFO:root:[  149] Training loss: 0.66073791, Validation loss: 0.66000578, Gradient norm: 0.16488424
INFO:root:At the start of the epoch: mem (CPU python)=48446.578125MB; mem (CPU total)=48405.2421875MB
INFO:root:[  150] Training loss: 0.66078786, Validation loss: 0.65963928, Gradient norm: 0.16194614
INFO:root:At the start of the epoch: mem (CPU python)=48484.67578125MB; mem (CPU total)=48444.1015625MB
INFO:root:[  151] Training loss: 0.66060799, Validation loss: 0.65994502, Gradient norm: 0.16817005
INFO:root:At the start of the epoch: mem (CPU python)=48522.765625MB; mem (CPU total)=48482.53125MB
INFO:root:[  152] Training loss: 0.66049458, Validation loss: 0.65953077, Gradient norm: 0.15804237
INFO:root:At the start of the epoch: mem (CPU python)=48560.86328125MB; mem (CPU total)=48520.30078125MB
INFO:root:[  153] Training loss: 0.66058812, Validation loss: 0.65964563, Gradient norm: 0.15772790
INFO:root:At the start of the epoch: mem (CPU python)=48598.9609375MB; mem (CPU total)=48558.453125MB
INFO:root:[  154] Training loss: 0.66057969, Validation loss: 0.65962537, Gradient norm: 0.15940347
INFO:root:At the start of the epoch: mem (CPU python)=48637.0546875MB; mem (CPU total)=48596.390625MB
INFO:root:[  155] Training loss: 0.66035887, Validation loss: 0.65948503, Gradient norm: 0.16000845
INFO:root:At the start of the epoch: mem (CPU python)=48675.15234375MB; mem (CPU total)=48634.51171875MB
INFO:root:[  156] Training loss: 0.66024822, Validation loss: 0.65993420, Gradient norm: 0.15739272
INFO:root:At the start of the epoch: mem (CPU python)=48713.24609375MB; mem (CPU total)=48672.9140625MB
INFO:root:[  157] Training loss: 0.66020433, Validation loss: 0.65923835, Gradient norm: 0.15703299
INFO:root:At the start of the epoch: mem (CPU python)=48751.34375MB; mem (CPU total)=48711.11328125MB
INFO:root:[  158] Training loss: 0.66024927, Validation loss: 0.65997313, Gradient norm: 0.16366785
INFO:root:At the start of the epoch: mem (CPU python)=48789.43359375MB; mem (CPU total)=48749.26171875MB
INFO:root:[  159] Training loss: 0.66033230, Validation loss: 0.65959676, Gradient norm: 0.16404147
INFO:root:At the start of the epoch: mem (CPU python)=48827.53125MB; mem (CPU total)=48787.19921875MB
INFO:root:[  160] Training loss: 0.66011884, Validation loss: 0.65939116, Gradient norm: 0.16679422
INFO:root:At the start of the epoch: mem (CPU python)=48865.62890625MB; mem (CPU total)=48825.07421875MB
INFO:root:[  161] Training loss: 0.66013114, Validation loss: 0.65923177, Gradient norm: 0.17113053
INFO:root:At the start of the epoch: mem (CPU python)=48903.72265625MB; mem (CPU total)=48863.83203125MB
INFO:root:[  162] Training loss: 0.66014779, Validation loss: 0.65944848, Gradient norm: 0.16271772
INFO:root:At the start of the epoch: mem (CPU python)=48941.81640625MB; mem (CPU total)=48902.140625MB
INFO:root:[  163] Training loss: 0.66010158, Validation loss: 0.65947399, Gradient norm: 0.16306823
INFO:root:At the start of the epoch: mem (CPU python)=48979.9140625MB; mem (CPU total)=48940.078125MB
INFO:root:[  164] Training loss: 0.66013104, Validation loss: 0.65957136, Gradient norm: 0.16364437
INFO:root:At the start of the epoch: mem (CPU python)=49018.0078125MB; mem (CPU total)=48978.19921875MB
INFO:root:[  165] Training loss: 0.66014867, Validation loss: 0.65921049, Gradient norm: 0.16311160
INFO:root:At the start of the epoch: mem (CPU python)=49056.10546875MB; mem (CPU total)=49016.3046875MB
INFO:root:[  166] Training loss: 0.65992817, Validation loss: 0.65965879, Gradient norm: 0.16608108
INFO:root:At the start of the epoch: mem (CPU python)=49094.19921875MB; mem (CPU total)=49055.125MB
INFO:root:[  167] Training loss: 0.66008670, Validation loss: 0.65985660, Gradient norm: 0.16875999
INFO:root:At the start of the epoch: mem (CPU python)=49132.29296875MB; mem (CPU total)=49092.30859375MB
INFO:root:[  168] Training loss: 0.65994761, Validation loss: 0.65900141, Gradient norm: 0.15589003
INFO:root:At the start of the epoch: mem (CPU python)=49170.390625MB; mem (CPU total)=49130.7734375MB
INFO:root:[  169] Training loss: 0.65980062, Validation loss: 0.65978150, Gradient norm: 0.16204099
INFO:root:At the start of the epoch: mem (CPU python)=49208.48046875MB; mem (CPU total)=49168.94921875MB
INFO:root:[  170] Training loss: 0.65994603, Validation loss: 0.65889265, Gradient norm: 0.16148783
INFO:root:At the start of the epoch: mem (CPU python)=49246.58203125MB; mem (CPU total)=49206.6875MB
INFO:root:[  171] Training loss: 0.65994996, Validation loss: 0.65922739, Gradient norm: 0.16633515
INFO:root:At the start of the epoch: mem (CPU python)=49284.67578125MB; mem (CPU total)=49244.640625MB
INFO:root:[  172] Training loss: 0.65984016, Validation loss: 0.65929930, Gradient norm: 0.16709587
INFO:root:At the start of the epoch: mem (CPU python)=49322.76953125MB; mem (CPU total)=49282.0625MB
INFO:root:[  173] Training loss: 0.65965024, Validation loss: 0.65905810, Gradient norm: 0.16210659
INFO:root:At the start of the epoch: mem (CPU python)=49360.8671875MB; mem (CPU total)=49320.66015625MB
INFO:root:[  174] Training loss: 0.65980443, Validation loss: 0.65981096, Gradient norm: 0.16884766
INFO:root:At the start of the epoch: mem (CPU python)=49398.9609375MB; mem (CPU total)=49358.84375MB
INFO:root:[  175] Training loss: 0.65956983, Validation loss: 0.65891217, Gradient norm: 0.15607114
INFO:root:At the start of the epoch: mem (CPU python)=49437.0546875MB; mem (CPU total)=49396.546875MB
INFO:root:[  176] Training loss: 0.65959699, Validation loss: 0.65946143, Gradient norm: 0.16434890
INFO:root:At the start of the epoch: mem (CPU python)=49475.15234375MB; mem (CPU total)=49435.140625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  177] Training loss: 0.65954569, Validation loss: 0.65929429, Gradient norm: 0.16546944
INFO:root:At the start of the epoch: mem (CPU python)=49513.25MB; mem (CPU total)=49473.32421875MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  178] Training loss: 0.65869792, Validation loss: 0.65827739, Gradient norm: 0.14748162
INFO:root:At the start of the epoch: mem (CPU python)=49551.34765625MB; mem (CPU total)=49511.6328125MB
INFO:root:[  179] Training loss: 0.65792649, Validation loss: 0.65772532, Gradient norm: 0.13859530
INFO:root:At the start of the epoch: mem (CPU python)=49589.44140625MB; mem (CPU total)=49550.30859375MB
INFO:root:[  180] Training loss: 0.65778950, Validation loss: 0.65791215, Gradient norm: 0.14167898
INFO:root:At the start of the epoch: mem (CPU python)=49627.53515625MB; mem (CPU total)=49588.21875MB
INFO:root:[  181] Training loss: 0.65774755, Validation loss: 0.65784945, Gradient norm: 0.14163408
INFO:root:At the start of the epoch: mem (CPU python)=49665.62890625MB; mem (CPU total)=49626.40234375MB
INFO:root:[  182] Training loss: 0.65788805, Validation loss: 0.65808066, Gradient norm: 0.14760277
INFO:root:At the start of the epoch: mem (CPU python)=49703.72265625MB; mem (CPU total)=49664.28515625MB
INFO:root:[  183] Training loss: 0.65785241, Validation loss: 0.65770234, Gradient norm: 0.14623317
INFO:root:At the start of the epoch: mem (CPU python)=49741.82421875MB; mem (CPU total)=49702.359375MB
INFO:root:[  184] Training loss: 0.65800624, Validation loss: 0.65774632, Gradient norm: 0.14810254
INFO:root:At the start of the epoch: mem (CPU python)=49779.91796875MB; mem (CPU total)=49740.2578125MB
INFO:root:[  185] Training loss: 0.65781695, Validation loss: 0.65793821, Gradient norm: 0.15511778
INFO:root:At the start of the epoch: mem (CPU python)=49818.01171875MB; mem (CPU total)=49778.25390625MB
INFO:root:[  186] Training loss: 0.65774275, Validation loss: 0.65778025, Gradient norm: 0.15396159
INFO:root:At the start of the epoch: mem (CPU python)=49856.10546875MB; mem (CPU total)=49816.01171875MB
INFO:root:[  187] Training loss: 0.65768887, Validation loss: 0.65784576, Gradient norm: 0.15304546
INFO:root:At the start of the epoch: mem (CPU python)=49894.203125MB; mem (CPU total)=49854.40234375MB
INFO:root:[  188] Training loss: 0.65756925, Validation loss: 0.65754285, Gradient norm: 0.15049703
INFO:root:At the start of the epoch: mem (CPU python)=49932.30078125MB; mem (CPU total)=49892.359375MB
INFO:root:[  189] Training loss: 0.65774332, Validation loss: 0.65787475, Gradient norm: 0.15166366
INFO:root:At the start of the epoch: mem (CPU python)=49970.39453125MB; mem (CPU total)=49930.24609375MB
INFO:root:[  190] Training loss: 0.65777607, Validation loss: 0.65759244, Gradient norm: 0.15594883
INFO:root:At the start of the epoch: mem (CPU python)=50008.4921875MB; mem (CPU total)=49968.66796875MB
INFO:root:[  191] Training loss: 0.65767980, Validation loss: 0.65791006, Gradient norm: 0.15524198
INFO:root:At the start of the epoch: mem (CPU python)=50046.5859375MB; mem (CPU total)=50006.53125MB
INFO:root:[  192] Training loss: 0.65776173, Validation loss: 0.65774475, Gradient norm: 0.16522556
INFO:root:At the start of the epoch: mem (CPU python)=50084.67578125MB; mem (CPU total)=50044.67578125MB
INFO:root:[  193] Training loss: 0.65775682, Validation loss: 0.65732589, Gradient norm: 0.15368385
INFO:root:At the start of the epoch: mem (CPU python)=50122.77734375MB; mem (CPU total)=50083.16015625MB
INFO:root:[  194] Training loss: 0.65763996, Validation loss: 0.65739925, Gradient norm: 0.15253968
INFO:root:At the start of the epoch: mem (CPU python)=50160.875MB; mem (CPU total)=50121.3046875MB
INFO:root:[  195] Training loss: 0.65757347, Validation loss: 0.65779174, Gradient norm: 0.15731509
INFO:root:At the start of the epoch: mem (CPU python)=50198.96875MB; mem (CPU total)=50159.6953125MB
INFO:root:[  196] Training loss: 0.65767717, Validation loss: 0.65759575, Gradient norm: 0.15040836
INFO:root:At the start of the epoch: mem (CPU python)=50237.05859375MB; mem (CPU total)=50197.28515625MB
INFO:root:[  197] Training loss: 0.65745629, Validation loss: 0.65762848, Gradient norm: 0.15471233
INFO:root:At the start of the epoch: mem (CPU python)=50275.16015625MB; mem (CPU total)=50235.17578125MB
INFO:root:[  198] Training loss: 0.65751235, Validation loss: 0.65775958, Gradient norm: 0.15114422
INFO:root:At the start of the epoch: mem (CPU python)=50313.25390625MB; mem (CPU total)=50273.56640625MB
INFO:root:[  199] Training loss: 0.65757699, Validation loss: 0.65759532, Gradient norm: 0.15815322
INFO:root:At the start of the epoch: mem (CPU python)=50351.34765625MB; mem (CPU total)=50311.7109375MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  200] Training loss: 0.65750864, Validation loss: 0.65747080, Gradient norm: 0.15651386
INFO:root:At the start of the epoch: mem (CPU python)=50389.44921875MB; mem (CPU total)=50350.1015625MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  201] Training loss: 0.65717465, Validation loss: 0.65785856, Gradient norm: 0.15255344
INFO:root:At the start of the epoch: mem (CPU python)=50427.5390625MB; mem (CPU total)=50387.9921875MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  202] Training loss: 0.65702777, Validation loss: 0.65776188, Gradient norm: 0.13978964
INFO:root:At the start of the epoch: mem (CPU python)=50465.63671875MB; mem (CPU total)=50426.3828125MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  203] Training loss: 0.65686749, Validation loss: 0.65724938, Gradient norm: 0.13686570
INFO:root:At the start of the epoch: mem (CPU python)=50503.73046875MB; mem (CPU total)=50465.0546875MB
INFO:root:[  204] Training loss: 0.65688221, Validation loss: 0.65764697, Gradient norm: 0.13954950
INFO:root:At the start of the epoch: mem (CPU python)=50541.828125MB; mem (CPU total)=50502.953125MB
INFO:root:[  205] Training loss: 0.65674009, Validation loss: 0.65762765, Gradient norm: 0.14023466
INFO:root:At the start of the epoch: mem (CPU python)=50579.921875MB; mem (CPU total)=50541.09765625MB
INFO:root:[  206] Training loss: 0.65682411, Validation loss: 0.65705245, Gradient norm: 0.14053555
INFO:root:At the start of the epoch: mem (CPU python)=50618.01953125MB; mem (CPU total)=50579.55078125MB
INFO:root:[  207] Training loss: 0.65681172, Validation loss: 0.65748712, Gradient norm: 0.14159998
INFO:root:At the start of the epoch: mem (CPU python)=50656.11328125MB; mem (CPU total)=50617.94140625MB
INFO:root:[  208] Training loss: 0.65691890, Validation loss: 0.65733911, Gradient norm: 0.14077636
INFO:root:At the start of the epoch: mem (CPU python)=50694.20703125MB; mem (CPU total)=50656.08203125MB
INFO:root:[  209] Training loss: 0.65683272, Validation loss: 0.65750927, Gradient norm: 0.13863842
INFO:root:At the start of the epoch: mem (CPU python)=50732.3046875MB; mem (CPU total)=50693.9453125MB
INFO:root:[  210] Training loss: 0.65677900, Validation loss: 0.65737951, Gradient norm: 0.13922196
INFO:root:At the start of the epoch: mem (CPU python)=50770.3984375MB; mem (CPU total)=50732.0390625MB
INFO:root:[  211] Training loss: 0.65681184, Validation loss: 0.65756374, Gradient norm: 0.14176989
INFO:root:At the start of the epoch: mem (CPU python)=50808.49609375MB; mem (CPU total)=50770.18359375MB
INFO:root:[  212] Training loss: 0.65689082, Validation loss: 0.65738975, Gradient norm: 0.13999689
INFO:root:At the start of the epoch: mem (CPU python)=50846.58984375MB; mem (CPU total)=50808.328125MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  213] Training loss: 0.65673119, Validation loss: 0.65747133, Gradient norm: 0.14197655
INFO:root:At the start of the epoch: mem (CPU python)=50884.68359375MB; mem (CPU total)=50846.71875MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  214] Training loss: 0.65676797, Validation loss: 0.65762241, Gradient norm: 0.13792449
INFO:root:At the start of the epoch: mem (CPU python)=50922.78125MB; mem (CPU total)=50884.6171875MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  215] Training loss: 0.65672237, Validation loss: 0.65781617, Gradient norm: 0.13906452
INFO:root:At the start of the epoch: mem (CPU python)=50960.875MB; mem (CPU total)=50922.6640625MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:EP 215: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=50998.96875MB; mem (CPU total)=50960.80859375MB
INFO:root:Training the model took 21450.97s.
INFO:root:Emptying the cuda cache took 0.011s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92827
INFO:root:EnergyScoreTrain: 0.65329
INFO:root:CRPSTrain: 0.52539
INFO:root:Gaussian NLLTrain: 1.62054
INFO:root:CoverageTrain: 0.91725
INFO:root:IntervalWidthTrain: 3.39
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93403
INFO:root:EnergyScoreValidation: 0.6574
INFO:root:CRPSValidation: 0.52908
INFO:root:Gaussian NLLValidation: 1.64162
INFO:root:CoverageValidation: 0.91549
INFO:root:IntervalWidthValidation: 3.39228
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93353
INFO:root:EnergyScoreTest: 0.65704
INFO:root:CRPSTest: 0.52908
INFO:root:Gaussian NLLTest: 1.68507
INFO:root:CoverageTest: 0.91505
INFO:root:IntervalWidthTest: 3.39159
INFO:root:After validation: mem (CPU python)=51057.3828125MB; mem (CPU total)=51019.20703125MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=51057.3828125MB; mem (CPU total)=50957.88671875MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=51057.3828125MB; mem (CPU total)=50960.74609375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=51057.3828125MB; mem (CPU total)=50960.8671875MB
INFO:root:[    1] Training loss: 0.71440841, Validation loss: 0.70324711, Gradient norm: 0.04860867
INFO:root:At the start of the epoch: mem (CPU python)=51057.3828125MB; mem (CPU total)=50999.4453125MB
INFO:root:[    2] Training loss: 0.69659395, Validation loss: 0.69258460, Gradient norm: 0.07377980
INFO:root:At the start of the epoch: mem (CPU python)=51075.203125MB; mem (CPU total)=51038.22265625MB
INFO:root:[    3] Training loss: 0.69056834, Validation loss: 0.68986193, Gradient norm: 0.08754012
INFO:root:At the start of the epoch: mem (CPU python)=51114.859375MB; mem (CPU total)=51077.10546875MB
INFO:root:[    4] Training loss: 0.68848864, Validation loss: 0.68707689, Gradient norm: 0.08806257
INFO:root:At the start of the epoch: mem (CPU python)=51152.95703125MB; mem (CPU total)=51115.6640625MB
INFO:root:[    5] Training loss: 0.68696660, Validation loss: 0.68582791, Gradient norm: 0.08925971
INFO:root:At the start of the epoch: mem (CPU python)=51191.05078125MB; mem (CPU total)=51153.65625MB
INFO:root:[    6] Training loss: 0.68588918, Validation loss: 0.68500358, Gradient norm: 0.09277848
INFO:root:At the start of the epoch: mem (CPU python)=51229.1484375MB; mem (CPU total)=51191.3828125MB
INFO:root:[    7] Training loss: 0.68478764, Validation loss: 0.68463699, Gradient norm: 0.08600251
INFO:root:At the start of the epoch: mem (CPU python)=51267.2421875MB; mem (CPU total)=51229.48046875MB
INFO:root:[    8] Training loss: 0.68395209, Validation loss: 0.68380273, Gradient norm: 0.09254840
INFO:root:At the start of the epoch: mem (CPU python)=51305.33984375MB; mem (CPU total)=51267.58203125MB
INFO:root:[    9] Training loss: 0.68290586, Validation loss: 0.68175289, Gradient norm: 0.09161227
INFO:root:At the start of the epoch: mem (CPU python)=51343.43359375MB; mem (CPU total)=51304.63671875MB
INFO:root:[   10] Training loss: 0.68219300, Validation loss: 0.68167119, Gradient norm: 0.10254561
INFO:root:At the start of the epoch: mem (CPU python)=51381.53125MB; mem (CPU total)=51343.05859375MB
INFO:root:[   11] Training loss: 0.68136971, Validation loss: 0.68038903, Gradient norm: 0.10109215
INFO:root:At the start of the epoch: mem (CPU python)=51419.625MB; mem (CPU total)=51381.3125MB
INFO:root:[   12] Training loss: 0.68065233, Validation loss: 0.68010622, Gradient norm: 0.11225159
INFO:root:At the start of the epoch: mem (CPU python)=51457.71875MB; mem (CPU total)=51418.99609375MB
INFO:root:[   13] Training loss: 0.67982680, Validation loss: 0.67905544, Gradient norm: 0.11518935
INFO:root:At the start of the epoch: mem (CPU python)=51495.8125MB; mem (CPU total)=51456.38671875MB
INFO:root:[   14] Training loss: 0.67931435, Validation loss: 0.67818042, Gradient norm: 0.12856832
INFO:root:At the start of the epoch: mem (CPU python)=51533.9140625MB; mem (CPU total)=51494.609375MB
INFO:root:[   15] Training loss: 0.67868703, Validation loss: 0.67807771, Gradient norm: 0.13110748
INFO:root:At the start of the epoch: mem (CPU python)=51572.0078125MB; mem (CPU total)=51532.734375MB
INFO:root:[   16] Training loss: 0.67774922, Validation loss: 0.67679322, Gradient norm: 0.13152028
INFO:root:At the start of the epoch: mem (CPU python)=51610.1015625MB; mem (CPU total)=51571.21875MB
INFO:root:[   17] Training loss: 0.67737328, Validation loss: 0.67622148, Gradient norm: 0.14507801
INFO:root:At the start of the epoch: mem (CPU python)=51648.19921875MB; mem (CPU total)=51609.83984375MB
INFO:root:[   18] Training loss: 0.67679601, Validation loss: 0.67604954, Gradient norm: 0.15087780
INFO:root:At the start of the epoch: mem (CPU python)=51686.29296875MB; mem (CPU total)=51648.17578125MB
INFO:root:[   19] Training loss: 0.67627181, Validation loss: 0.67524530, Gradient norm: 0.15340468
INFO:root:At the start of the epoch: mem (CPU python)=51724.38671875MB; mem (CPU total)=51686.64453125MB
INFO:root:[   20] Training loss: 0.67602729, Validation loss: 0.67467545, Gradient norm: 0.15901037
INFO:root:At the start of the epoch: mem (CPU python)=51762.484375MB; mem (CPU total)=51725.2578125MB
INFO:root:[   21] Training loss: 0.67547240, Validation loss: 0.67433638, Gradient norm: 0.15804440
INFO:root:At the start of the epoch: mem (CPU python)=51800.578125MB; mem (CPU total)=51763.07421875MB
INFO:root:[   22] Training loss: 0.67495854, Validation loss: 0.67386057, Gradient norm: 0.16183961
INFO:root:At the start of the epoch: mem (CPU python)=51838.67578125MB; mem (CPU total)=51801.28125MB
INFO:root:[   23] Training loss: 0.67463402, Validation loss: 0.67420686, Gradient norm: 0.17827711
INFO:root:At the start of the epoch: mem (CPU python)=51876.765625MB; mem (CPU total)=51839.37890625MB
INFO:root:[   24] Training loss: 0.67428502, Validation loss: 0.67338303, Gradient norm: 0.16335149
INFO:root:At the start of the epoch: mem (CPU python)=51914.8671875MB; mem (CPU total)=51878.05078125MB
INFO:root:[   25] Training loss: 0.67378066, Validation loss: 0.67331236, Gradient norm: 0.16813424
INFO:root:At the start of the epoch: mem (CPU python)=51952.9609375MB; mem (CPU total)=51916.84375MB
INFO:root:[   26] Training loss: 0.67334057, Validation loss: 0.67250146, Gradient norm: 0.16418585
INFO:root:At the start of the epoch: mem (CPU python)=51991.0546875MB; mem (CPU total)=51954.609375MB
INFO:root:[   27] Training loss: 0.67298798, Validation loss: 0.67244208, Gradient norm: 0.16745224
INFO:root:At the start of the epoch: mem (CPU python)=52029.15234375MB; mem (CPU total)=51992.921875MB
INFO:root:[   28] Training loss: 0.67282140, Validation loss: 0.67204567, Gradient norm: 0.18895125
INFO:root:At the start of the epoch: mem (CPU python)=52067.24609375MB; mem (CPU total)=52031.2734375MB
INFO:root:[   29] Training loss: 0.67226367, Validation loss: 0.67166409, Gradient norm: 0.16342662
INFO:root:At the start of the epoch: mem (CPU python)=52105.33984375MB; mem (CPU total)=52069.27734375MB
INFO:root:[   30] Training loss: 0.67218592, Validation loss: 0.67079539, Gradient norm: 0.16279099
INFO:root:At the start of the epoch: mem (CPU python)=52143.43359375MB; mem (CPU total)=52106.79296875MB
INFO:root:[   31] Training loss: 0.67197352, Validation loss: 0.67081143, Gradient norm: 0.17683644
INFO:root:At the start of the epoch: mem (CPU python)=52181.53125MB; mem (CPU total)=52144.9375MB
INFO:root:[   32] Training loss: 0.67142414, Validation loss: 0.67083961, Gradient norm: 0.15870850
INFO:root:At the start of the epoch: mem (CPU python)=52219.625MB; mem (CPU total)=52182.69140625MB
INFO:root:[   33] Training loss: 0.67141396, Validation loss: 0.67015758, Gradient norm: 0.17429256
INFO:root:At the start of the epoch: mem (CPU python)=52257.72265625MB; mem (CPU total)=52221.17578125MB
INFO:root:[   34] Training loss: 0.67117574, Validation loss: 0.67025099, Gradient norm: 0.16410193
INFO:root:At the start of the epoch: mem (CPU python)=52295.8203125MB; mem (CPU total)=52259.51171875MB
INFO:root:[   35] Training loss: 0.67108730, Validation loss: 0.67070636, Gradient norm: 0.17230446
INFO:root:At the start of the epoch: mem (CPU python)=52333.9140625MB; mem (CPU total)=52297.94140625MB
INFO:root:[   36] Training loss: 0.67090124, Validation loss: 0.67028858, Gradient norm: 0.16739977
INFO:root:At the start of the epoch: mem (CPU python)=52372.0078125MB; mem (CPU total)=52336.26953125MB
INFO:root:[   37] Training loss: 0.67061876, Validation loss: 0.66987071, Gradient norm: 0.17790092
INFO:root:At the start of the epoch: mem (CPU python)=52410.10546875MB; mem (CPU total)=52373.97265625MB
INFO:root:[   38] Training loss: 0.67069869, Validation loss: 0.66946045, Gradient norm: 0.17281102
INFO:root:At the start of the epoch: mem (CPU python)=52448.203125MB; mem (CPU total)=52411.421875MB
INFO:root:[   39] Training loss: 0.67039875, Validation loss: 0.66948854, Gradient norm: 0.16842434
INFO:root:At the start of the epoch: mem (CPU python)=52486.29296875MB; mem (CPU total)=52449.56640625MB
INFO:root:[   40] Training loss: 0.67028754, Validation loss: 0.66920955, Gradient norm: 0.18045945
INFO:root:At the start of the epoch: mem (CPU python)=52524.390625MB; mem (CPU total)=52488.03125MB
INFO:root:[   41] Training loss: 0.67002313, Validation loss: 0.66886769, Gradient norm: 0.15446222
INFO:root:At the start of the epoch: mem (CPU python)=52562.48828125MB; mem (CPU total)=52526.59765625MB
INFO:root:[   42] Training loss: 0.67010805, Validation loss: 0.66934707, Gradient norm: 0.16507043
INFO:root:At the start of the epoch: mem (CPU python)=52600.5859375MB; mem (CPU total)=52564.34375MB
INFO:root:[   43] Training loss: 0.66988266, Validation loss: 0.66906018, Gradient norm: 0.17118288
INFO:root:At the start of the epoch: mem (CPU python)=52638.6796875MB; mem (CPU total)=52602.2109375MB
INFO:root:[   44] Training loss: 0.66962125, Validation loss: 0.66932772, Gradient norm: 0.16917295
INFO:root:At the start of the epoch: mem (CPU python)=52676.77734375MB; mem (CPU total)=52640.26171875MB
INFO:root:[   45] Training loss: 0.66970498, Validation loss: 0.66879458, Gradient norm: 0.16924231
INFO:root:At the start of the epoch: mem (CPU python)=52714.875MB; mem (CPU total)=52678.17578125MB
INFO:root:[   46] Training loss: 0.66973755, Validation loss: 0.66891331, Gradient norm: 0.17053663
INFO:root:At the start of the epoch: mem (CPU python)=52752.96484375MB; mem (CPU total)=52716.3203125MB
INFO:root:[   47] Training loss: 0.66940806, Validation loss: 0.66907744, Gradient norm: 0.17040939
INFO:root:At the start of the epoch: mem (CPU python)=52791.05859375MB; mem (CPU total)=52754.7109375MB
INFO:root:[   48] Training loss: 0.66945948, Validation loss: 0.66910646, Gradient norm: 0.16302477
INFO:root:At the start of the epoch: mem (CPU python)=52829.15625MB; mem (CPU total)=52792.66796875MB
INFO:root:[   49] Training loss: 0.66948037, Validation loss: 0.66913649, Gradient norm: 0.19028005
INFO:root:At the start of the epoch: mem (CPU python)=52867.25390625MB; mem (CPU total)=52830.67578125MB
INFO:root:[   50] Training loss: 0.66922220, Validation loss: 0.66831664, Gradient norm: 0.16916345
INFO:root:At the start of the epoch: mem (CPU python)=52905.34765625MB; mem (CPU total)=52869.21875MB
INFO:root:[   51] Training loss: 0.66903165, Validation loss: 0.66745420, Gradient norm: 0.15978837
INFO:root:At the start of the epoch: mem (CPU python)=52943.4453125MB; mem (CPU total)=52907.1640625MB
INFO:root:[   52] Training loss: 0.66893909, Validation loss: 0.66755207, Gradient norm: 0.15843986
INFO:root:At the start of the epoch: mem (CPU python)=52981.5390625MB; mem (CPU total)=52945.7890625MB
INFO:root:[   53] Training loss: 0.66873444, Validation loss: 0.66719842, Gradient norm: 0.16563065
INFO:root:At the start of the epoch: mem (CPU python)=53019.6328125MB; mem (CPU total)=52983.63671875MB
INFO:root:[   54] Training loss: 0.66889972, Validation loss: 0.66797957, Gradient norm: 0.17797546
INFO:root:At the start of the epoch: mem (CPU python)=53057.7265625MB; mem (CPU total)=53021.3046875MB
INFO:root:[   55] Training loss: 0.66871473, Validation loss: 0.66761784, Gradient norm: 0.18425271
INFO:root:At the start of the epoch: mem (CPU python)=53095.82421875MB; mem (CPU total)=53059.171875MB
INFO:root:[   56] Training loss: 0.66862198, Validation loss: 0.66748104, Gradient norm: 0.16865331
INFO:root:At the start of the epoch: mem (CPU python)=53133.91796875MB; mem (CPU total)=53097.453125MB
INFO:root:[   57] Training loss: 0.66849480, Validation loss: 0.66706539, Gradient norm: 0.17526352
INFO:root:At the start of the epoch: mem (CPU python)=53172.015625MB; mem (CPU total)=53136.18359375MB
INFO:root:[   58] Training loss: 0.66825954, Validation loss: 0.66720515, Gradient norm: 0.17839194
INFO:root:At the start of the epoch: mem (CPU python)=53210.109375MB; mem (CPU total)=53174.328125MB
INFO:root:[   59] Training loss: 0.66801830, Validation loss: 0.66706739, Gradient norm: 0.16976069
INFO:root:At the start of the epoch: mem (CPU python)=53248.203125MB; mem (CPU total)=53212.47265625MB
INFO:root:[   60] Training loss: 0.66792417, Validation loss: 0.66710547, Gradient norm: 0.18202024
INFO:root:At the start of the epoch: mem (CPU python)=53286.30078125MB; mem (CPU total)=53250.05078125MB
INFO:root:[   61] Training loss: 0.66780973, Validation loss: 0.66665888, Gradient norm: 0.17017318
INFO:root:At the start of the epoch: mem (CPU python)=53324.40234375MB; mem (CPU total)=53288.44921875MB
INFO:root:[   62] Training loss: 0.66756902, Validation loss: 0.66673656, Gradient norm: 0.17365523
INFO:root:At the start of the epoch: mem (CPU python)=53362.4921875MB; mem (CPU total)=53326.8359375MB
INFO:root:[   63] Training loss: 0.66739882, Validation loss: 0.66642802, Gradient norm: 0.17031672
INFO:root:At the start of the epoch: mem (CPU python)=53400.58984375MB; mem (CPU total)=53364.34765625MB
INFO:root:[   64] Training loss: 0.66721796, Validation loss: 0.66585565, Gradient norm: 0.17085131
INFO:root:At the start of the epoch: mem (CPU python)=53438.68359375MB; mem (CPU total)=53402.64453125MB
INFO:root:[   65] Training loss: 0.66713597, Validation loss: 0.66518232, Gradient norm: 0.18716933
INFO:root:At the start of the epoch: mem (CPU python)=53476.78125MB; mem (CPU total)=53441.109375MB
INFO:root:[   66] Training loss: 0.66696218, Validation loss: 0.66584140, Gradient norm: 0.16465352
INFO:root:At the start of the epoch: mem (CPU python)=53514.87109375MB; mem (CPU total)=53479.37109375MB
INFO:root:[   67] Training loss: 0.66663000, Validation loss: 0.66640228, Gradient norm: 0.17756624
INFO:root:At the start of the epoch: mem (CPU python)=53552.96484375MB; mem (CPU total)=53516.9921875MB
INFO:root:[   68] Training loss: 0.66646918, Validation loss: 0.66557106, Gradient norm: 0.18672360
INFO:root:At the start of the epoch: mem (CPU python)=53591.06640625MB; mem (CPU total)=53555.1953125MB
INFO:root:[   69] Training loss: 0.66651397, Validation loss: 0.66487649, Gradient norm: 0.17753291
INFO:root:At the start of the epoch: mem (CPU python)=53629.1640625MB; mem (CPU total)=53593.77734375MB
INFO:root:[   70] Training loss: 0.66620694, Validation loss: 0.66485617, Gradient norm: 0.17775855
INFO:root:At the start of the epoch: mem (CPU python)=53667.25390625MB; mem (CPU total)=53631.30859375MB
INFO:root:[   71] Training loss: 0.66612162, Validation loss: 0.66480101, Gradient norm: 0.18311756
INFO:root:At the start of the epoch: mem (CPU python)=53705.3515625MB; mem (CPU total)=53668.81640625MB
INFO:root:[   72] Training loss: 0.66606604, Validation loss: 0.66461851, Gradient norm: 0.17269693
INFO:root:At the start of the epoch: mem (CPU python)=53743.44921875MB; mem (CPU total)=53707.28515625MB
INFO:root:[   73] Training loss: 0.66600375, Validation loss: 0.66475238, Gradient norm: 0.17610622
INFO:root:At the start of the epoch: mem (CPU python)=53781.5390625MB; mem (CPU total)=53745.3984375MB
INFO:root:[   74] Training loss: 0.66575571, Validation loss: 0.66470119, Gradient norm: 0.18086546
INFO:root:At the start of the epoch: mem (CPU python)=53819.63671875MB; mem (CPU total)=53783.296875MB
INFO:root:[   75] Training loss: 0.66558937, Validation loss: 0.66487085, Gradient norm: 0.16636839
INFO:root:At the start of the epoch: mem (CPU python)=53857.734375MB; mem (CPU total)=53821.89453125MB
INFO:root:[   76] Training loss: 0.66558997, Validation loss: 0.66433321, Gradient norm: 0.16257489
INFO:root:At the start of the epoch: mem (CPU python)=53895.828125MB; mem (CPU total)=53859.5703125MB
INFO:root:[   77] Training loss: 0.66550416, Validation loss: 0.66433066, Gradient norm: 0.18751970
INFO:root:At the start of the epoch: mem (CPU python)=53933.921875MB; mem (CPU total)=53898.0234375MB
INFO:root:[   78] Training loss: 0.66520043, Validation loss: 0.66421001, Gradient norm: 0.17066049
INFO:root:At the start of the epoch: mem (CPU python)=53972.0234375MB; mem (CPU total)=53936.72265625MB
INFO:root:[   79] Training loss: 0.66535863, Validation loss: 0.66434236, Gradient norm: 0.19125598
INFO:root:At the start of the epoch: mem (CPU python)=54010.11328125MB; mem (CPU total)=53974.671875MB
INFO:root:[   80] Training loss: 0.66541342, Validation loss: 0.66374855, Gradient norm: 0.15801525
INFO:root:At the start of the epoch: mem (CPU python)=54048.2109375MB; mem (CPU total)=54012.8359375MB
INFO:root:[   81] Training loss: 0.66517980, Validation loss: 0.66453645, Gradient norm: 0.15854135
INFO:root:At the start of the epoch: mem (CPU python)=54086.30078125MB; mem (CPU total)=54051.2265625MB
INFO:root:[   82] Training loss: 0.66507729, Validation loss: 0.66379411, Gradient norm: 0.16413442
INFO:root:At the start of the epoch: mem (CPU python)=54124.3984375MB; mem (CPU total)=54090.32421875MB
INFO:root:[   83] Training loss: 0.66499220, Validation loss: 0.66411721, Gradient norm: 0.16156671
INFO:root:At the start of the epoch: mem (CPU python)=54162.49609375MB; mem (CPU total)=54128.375MB
INFO:root:[   84] Training loss: 0.66499422, Validation loss: 0.66337291, Gradient norm: 0.17913014
INFO:root:At the start of the epoch: mem (CPU python)=54200.58984375MB; mem (CPU total)=54167.15234375MB
INFO:root:[   85] Training loss: 0.66477620, Validation loss: 0.66387811, Gradient norm: 0.15972070
INFO:root:At the start of the epoch: mem (CPU python)=54238.68359375MB; mem (CPU total)=54205.3984375MB
INFO:root:[   86] Training loss: 0.66476850, Validation loss: 0.66343693, Gradient norm: 0.17907890
INFO:root:At the start of the epoch: mem (CPU python)=54276.78125MB; mem (CPU total)=54244.03515625MB
INFO:root:[   87] Training loss: 0.66472564, Validation loss: 0.66394997, Gradient norm: 0.15897776
INFO:root:At the start of the epoch: mem (CPU python)=54314.875MB; mem (CPU total)=54281.7578125MB
INFO:root:[   88] Training loss: 0.66472246, Validation loss: 0.66277881, Gradient norm: 0.17055607
INFO:root:At the start of the epoch: mem (CPU python)=54352.97265625MB; mem (CPU total)=54320.1171875MB
INFO:root:[   89] Training loss: 0.66468142, Validation loss: 0.66370294, Gradient norm: 0.16908726
INFO:root:At the start of the epoch: mem (CPU python)=54391.06640625MB; mem (CPU total)=54358.046875MB
INFO:root:[   90] Training loss: 0.66463948, Validation loss: 0.66299048, Gradient norm: 0.16352444
INFO:root:At the start of the epoch: mem (CPU python)=54429.16015625MB; mem (CPU total)=54396.05859375MB
INFO:root:[   91] Training loss: 0.66449884, Validation loss: 0.66292632, Gradient norm: 0.17191790
INFO:root:At the start of the epoch: mem (CPU python)=54467.2578125MB; mem (CPU total)=54434.38671875MB
INFO:root:[   92] Training loss: 0.66427052, Validation loss: 0.66283123, Gradient norm: 0.15066995
INFO:root:At the start of the epoch: mem (CPU python)=54505.35546875MB; mem (CPU total)=54472.77734375MB
INFO:root:[   93] Training loss: 0.66433380, Validation loss: 0.66347121, Gradient norm: 0.16526262
INFO:root:At the start of the epoch: mem (CPU python)=54543.44921875MB; mem (CPU total)=54510.8984375MB
INFO:root:[   94] Training loss: 0.66426999, Validation loss: 0.66321230, Gradient norm: 0.16801276
INFO:root:At the start of the epoch: mem (CPU python)=54581.54296875MB; mem (CPU total)=54549.29296875MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   95] Training loss: 0.66413637, Validation loss: 0.66336069, Gradient norm: 0.15201871
INFO:root:At the start of the epoch: mem (CPU python)=54619.640625MB; mem (CPU total)=54587.4296875MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   96] Training loss: 0.66325781, Validation loss: 0.66251187, Gradient norm: 0.14359194
INFO:root:At the start of the epoch: mem (CPU python)=54657.73828125MB; mem (CPU total)=54626.02734375MB
INFO:root:[   97] Training loss: 0.66261532, Validation loss: 0.66172134, Gradient norm: 0.13062728
INFO:root:At the start of the epoch: mem (CPU python)=54695.83203125MB; mem (CPU total)=54664.91015625MB
INFO:root:[   98] Training loss: 0.66242308, Validation loss: 0.66186530, Gradient norm: 0.13080556
INFO:root:At the start of the epoch: mem (CPU python)=54733.921875MB; mem (CPU total)=54702.28515625MB
INFO:root:[   99] Training loss: 0.66232102, Validation loss: 0.66164002, Gradient norm: 0.13358060
INFO:root:At the start of the epoch: mem (CPU python)=54772.0234375MB; mem (CPU total)=54740.9140625MB
INFO:root:[  100] Training loss: 0.66241670, Validation loss: 0.66174751, Gradient norm: 0.14412981
INFO:root:At the start of the epoch: mem (CPU python)=54810.11328125MB; mem (CPU total)=54778.74609375MB
INFO:root:[  101] Training loss: 0.66243460, Validation loss: 0.66187531, Gradient norm: 0.13559099
INFO:root:At the start of the epoch: mem (CPU python)=54848.2109375MB; mem (CPU total)=54816.80078125MB
INFO:root:[  102] Training loss: 0.66247311, Validation loss: 0.66141011, Gradient norm: 0.13543210
INFO:root:At the start of the epoch: mem (CPU python)=54886.30859375MB; mem (CPU total)=54855.9296875MB
INFO:root:[  103] Training loss: 0.66247291, Validation loss: 0.66147960, Gradient norm: 0.13978486
INFO:root:At the start of the epoch: mem (CPU python)=54924.40234375MB; mem (CPU total)=54894.453125MB
INFO:root:[  104] Training loss: 0.66227705, Validation loss: 0.66148733, Gradient norm: 0.13271592
INFO:root:At the start of the epoch: mem (CPU python)=54962.49609375MB; mem (CPU total)=54932.1953125MB
INFO:root:[  105] Training loss: 0.66241182, Validation loss: 0.66161662, Gradient norm: 0.13307807
INFO:root:At the start of the epoch: mem (CPU python)=55000.58984375MB; mem (CPU total)=54970.45703125MB
INFO:root:[  106] Training loss: 0.66237788, Validation loss: 0.66133666, Gradient norm: 0.13292978
INFO:root:At the start of the epoch: mem (CPU python)=55038.69140625MB; mem (CPU total)=55011.296875MB
INFO:root:[  107] Training loss: 0.66222633, Validation loss: 0.66176116, Gradient norm: 0.14948896
INFO:root:At the start of the epoch: mem (CPU python)=55076.78125MB; mem (CPU total)=55049.38671875MB
INFO:root:[  108] Training loss: 0.66224527, Validation loss: 0.66182088, Gradient norm: 0.14224438
INFO:root:At the start of the epoch: mem (CPU python)=55114.875MB; mem (CPU total)=55087.52734375MB
INFO:root:[  109] Training loss: 0.66224352, Validation loss: 0.66151624, Gradient norm: 0.14167594
INFO:root:At the start of the epoch: mem (CPU python)=55152.9765625MB; mem (CPU total)=55125.90234375MB
INFO:root:[  110] Training loss: 0.66214806, Validation loss: 0.66158868, Gradient norm: 0.13315405
INFO:root:At the start of the epoch: mem (CPU python)=55191.0703125MB; mem (CPU total)=55164.04296875MB
INFO:root:[  111] Training loss: 0.66222188, Validation loss: 0.66120555, Gradient norm: 0.14725355
INFO:root:At the start of the epoch: mem (CPU python)=55229.1640625MB; mem (CPU total)=55203.6171875MB
INFO:root:[  112] Training loss: 0.66223368, Validation loss: 0.66165435, Gradient norm: 0.14000488
INFO:root:At the start of the epoch: mem (CPU python)=55267.26171875MB; mem (CPU total)=55240.80078125MB
INFO:root:[  113] Training loss: 0.66226106, Validation loss: 0.66160277, Gradient norm: 0.14210672
INFO:root:At the start of the epoch: mem (CPU python)=55305.359375MB; mem (CPU total)=55278.83203125MB
INFO:root:[  114] Training loss: 0.66222708, Validation loss: 0.66145006, Gradient norm: 0.14756642
INFO:root:At the start of the epoch: mem (CPU python)=55343.453125MB; mem (CPU total)=55316.9296875MB
INFO:root:[  115] Training loss: 0.66219880, Validation loss: 0.66132241, Gradient norm: 0.13725369
INFO:root:At the start of the epoch: mem (CPU python)=55381.546875MB; mem (CPU total)=55356.1328125MB
INFO:root:[  116] Training loss: 0.66204618, Validation loss: 0.66132205, Gradient norm: 0.13894237
INFO:root:At the start of the epoch: mem (CPU python)=55419.64453125MB; mem (CPU total)=55394.35546875MB
INFO:root:[  117] Training loss: 0.66210571, Validation loss: 0.66138582, Gradient norm: 0.14153704
INFO:root:At the start of the epoch: mem (CPU python)=55457.7421875MB; mem (CPU total)=55432.546875MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  118] Training loss: 0.66201709, Validation loss: 0.66153569, Gradient norm: 0.14422132
INFO:root:At the start of the epoch: mem (CPU python)=55495.8359375MB; mem (CPU total)=55470.99609375MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  119] Training loss: 0.66182068, Validation loss: 0.66078543, Gradient norm: 0.12884575
INFO:root:At the start of the epoch: mem (CPU python)=55533.93359375MB; mem (CPU total)=55509.46484375MB
INFO:root:[  120] Training loss: 0.66162248, Validation loss: 0.66105083, Gradient norm: 0.12432886
INFO:root:At the start of the epoch: mem (CPU python)=55572.02734375MB; mem (CPU total)=55547.44140625MB
INFO:root:[  121] Training loss: 0.66161301, Validation loss: 0.66101240, Gradient norm: 0.12380714
INFO:root:At the start of the epoch: mem (CPU python)=55610.12109375MB; mem (CPU total)=55585.5859375MB
INFO:root:[  122] Training loss: 0.66143283, Validation loss: 0.66114815, Gradient norm: 0.12769853
INFO:root:At the start of the epoch: mem (CPU python)=55648.21484375MB; mem (CPU total)=55623.8515625MB
INFO:root:[  123] Training loss: 0.66160943, Validation loss: 0.66133041, Gradient norm: 0.12721195
INFO:root:At the start of the epoch: mem (CPU python)=55686.3125MB; mem (CPU total)=55662.234375MB
INFO:root:[  124] Training loss: 0.66154194, Validation loss: 0.66116460, Gradient norm: 0.12471523
INFO:root:At the start of the epoch: mem (CPU python)=55724.41015625MB; mem (CPU total)=55700.625MB
INFO:root:[  125] Training loss: 0.66155939, Validation loss: 0.66105591, Gradient norm: 0.12690842
INFO:root:At the start of the epoch: mem (CPU python)=55762.50390625MB; mem (CPU total)=55739.49609375MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  126] Training loss: 0.66160524, Validation loss: 0.66104732, Gradient norm: 0.12787221
INFO:root:At the start of the epoch: mem (CPU python)=55800.6015625MB; mem (CPU total)=55777.8984375MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  127] Training loss: 0.66135452, Validation loss: 0.66088435, Gradient norm: 0.12345988
INFO:root:At the start of the epoch: mem (CPU python)=55838.6953125MB; mem (CPU total)=55816.27734375MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  128] Training loss: 0.66150621, Validation loss: 0.66131099, Gradient norm: 0.12847444
INFO:root:At the start of the epoch: mem (CPU python)=55876.7890625MB; mem (CPU total)=55854.16796875MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:EP 128: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=55914.88671875MB; mem (CPU total)=55892.55859375MB
INFO:root:Training the model took 13898.147s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93532
INFO:root:EnergyScoreTrain: 0.65826
INFO:root:CRPSTrain: 0.53291
INFO:root:Gaussian NLLTrain: 9.36408
INFO:root:CoverageTrain: 0.88672
INFO:root:IntervalWidthTrain: 3.32381
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93944
INFO:root:EnergyScoreValidation: 0.66119
INFO:root:CRPSValidation: 0.53573
INFO:root:Gaussian NLLValidation: 8.05049
INFO:root:CoverageValidation: 0.88578
INFO:root:IntervalWidthValidation: 3.32732
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93873
INFO:root:EnergyScoreTest: 0.66069
INFO:root:CRPSTest: 0.53545
INFO:root:Gaussian NLLTest: 11.60372
INFO:root:CoverageTest: 0.88573
INFO:root:IntervalWidthTest: 3.32633
INFO:root:After validation: mem (CPU python)=56006.90234375MB; mem (CPU total)=55979.7734375MB
