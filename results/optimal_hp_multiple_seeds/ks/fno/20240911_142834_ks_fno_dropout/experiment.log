INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=574.27734375MB; mem (CPU total)=1436.265625MB
INFO:root:############### Starting experiment with config file ks/fno_dropout.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12453.59765625MB; mem (CPU total)=1476.1796875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12453.59765625MB; mem (CPU total)=1476.1796875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12453.59765625MB; mem (CPU total)=3844.890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=3861.9921875MB
INFO:root:[    1] Training loss: 1.02202596, Validation loss: 1.01811590, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6220.265625MB
INFO:root:[    2] Training loss: 1.01655382, Validation loss: 1.01452423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6295.55859375MB
INFO:root:[    3] Training loss: 1.00922503, Validation loss: 1.00370171, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6371.41015625MB
INFO:root:[    4] Training loss: 0.99631103, Validation loss: 0.99276934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6446.5625MB
INFO:root:[    5] Training loss: 0.98745866, Validation loss: 0.98516528, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6523.2109375MB
INFO:root:[    6] Training loss: 0.97999290, Validation loss: 0.97805611, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6599.86328125MB
INFO:root:[    7] Training loss: 0.97330286, Validation loss: 0.97390167, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6675.421875MB
INFO:root:[    8] Training loss: 0.96748722, Validation loss: 0.96735575, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6752.18359375MB
INFO:root:[    9] Training loss: 0.96214294, Validation loss: 0.96400155, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6827.30078125MB
INFO:root:[   10] Training loss: 0.95732183, Validation loss: 0.95805520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6901.12890625MB
INFO:root:[   11] Training loss: 0.95338093, Validation loss: 0.95570892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=6977.59765625MB
INFO:root:[   12] Training loss: 0.94960657, Validation loss: 0.95126504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7053.58984375MB
INFO:root:[   13] Training loss: 0.94595273, Validation loss: 0.94805132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7129.7265625MB
INFO:root:[   14] Training loss: 0.94273706, Validation loss: 0.94685412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7206.0859375MB
INFO:root:[   15] Training loss: 0.93986310, Validation loss: 0.94208733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7282.75390625MB
INFO:root:[   16] Training loss: 0.93721444, Validation loss: 0.94069416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7359.6328125MB
INFO:root:[   17] Training loss: 0.93450522, Validation loss: 0.93753833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7436.453125MB
INFO:root:[   18] Training loss: 0.93213395, Validation loss: 0.93543261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7513.03125MB
INFO:root:[   19] Training loss: 0.92940971, Validation loss: 0.93360633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7588.80859375MB
INFO:root:[   20] Training loss: 0.92741281, Validation loss: 0.93190262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7664.9921875MB
INFO:root:[   21] Training loss: 0.92493924, Validation loss: 0.92982070, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7741.81640625MB
INFO:root:[   22] Training loss: 0.92295671, Validation loss: 0.92754289, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7818.8125MB
INFO:root:[   23] Training loss: 0.92079924, Validation loss: 0.92579351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7895.234375MB
INFO:root:[   24] Training loss: 0.91870891, Validation loss: 0.92460734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=7971.62890625MB
INFO:root:[   25] Training loss: 0.91717011, Validation loss: 0.92123624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8048.51171875MB
INFO:root:[   26] Training loss: 0.91519547, Validation loss: 0.92103501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8124.53515625MB
INFO:root:[   27] Training loss: 0.91356475, Validation loss: 0.91979425, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8200.078125MB
INFO:root:[   28] Training loss: 0.91205774, Validation loss: 0.91770217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8276.6015625MB
INFO:root:[   29] Training loss: 0.91052040, Validation loss: 0.91674366, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8352.94921875MB
INFO:root:[   30] Training loss: 0.90914275, Validation loss: 0.91625043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8429.73828125MB
INFO:root:[   31] Training loss: 0.90779912, Validation loss: 0.91503087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8506.625MB
INFO:root:[   32] Training loss: 0.90658782, Validation loss: 0.91300142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8583.21875MB
INFO:root:[   33] Training loss: 0.90493075, Validation loss: 0.91227835, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8660.3984375MB
INFO:root:[   34] Training loss: 0.90393625, Validation loss: 0.91189423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8736.97265625MB
INFO:root:[   35] Training loss: 0.90269802, Validation loss: 0.91037224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8813.30078125MB
INFO:root:[   36] Training loss: 0.90131832, Validation loss: 0.91007423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8889.13671875MB
INFO:root:[   37] Training loss: 0.90054365, Validation loss: 0.90919632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=8965.37890625MB
INFO:root:[   38] Training loss: 0.89936307, Validation loss: 0.90754641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9042.10546875MB
INFO:root:[   39] Training loss: 0.89828808, Validation loss: 0.90701372, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9118.5MB
INFO:root:[   40] Training loss: 0.89735458, Validation loss: 0.90624076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9195.23046875MB
INFO:root:[   41] Training loss: 0.89658245, Validation loss: 0.90582818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9272.13671875MB
INFO:root:[   42] Training loss: 0.89573075, Validation loss: 0.90490824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9348.6484375MB
INFO:root:[   43] Training loss: 0.89470627, Validation loss: 0.90428118, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9425.09765625MB
INFO:root:[   44] Training loss: 0.89392913, Validation loss: 0.90370877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9501.4140625MB
INFO:root:[   45] Training loss: 0.89282867, Validation loss: 0.90276284, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9578.203125MB
INFO:root:[   46] Training loss: 0.89220922, Validation loss: 0.90208591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9655.0MB
INFO:root:[   47] Training loss: 0.89161480, Validation loss: 0.90229487, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9731.79296875MB
INFO:root:[   48] Training loss: 0.89054092, Validation loss: 0.90079277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9808.52734375MB
INFO:root:[   49] Training loss: 0.88991361, Validation loss: 0.90195252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9883.515625MB
INFO:root:[   50] Training loss: 0.88907809, Validation loss: 0.90098174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=9959.08203125MB
INFO:root:[   51] Training loss: 0.88865162, Validation loss: 0.90029733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10034.890625MB
INFO:root:[   52] Training loss: 0.88772924, Validation loss: 0.90058472, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10109.96484375MB
INFO:root:[   53] Training loss: 0.88716101, Validation loss: 0.89944255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10185.765625MB
INFO:root:[   54] Training loss: 0.88651485, Validation loss: 0.89816769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10261.6875MB
INFO:root:[   55] Training loss: 0.88574122, Validation loss: 0.89877115, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10336.859375MB
INFO:root:[   56] Training loss: 0.88512834, Validation loss: 0.89884106, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10412.640625MB
INFO:root:[   57] Training loss: 0.88448326, Validation loss: 0.89760581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10487.98828125MB
INFO:root:[   58] Training loss: 0.88419434, Validation loss: 0.89740650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10563.703125MB
INFO:root:[   59] Training loss: 0.88334001, Validation loss: 0.89750610, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10639.51171875MB
INFO:root:[   60] Training loss: 0.88257468, Validation loss: 0.89775148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10715.32421875MB
INFO:root:[   61] Training loss: 0.88246331, Validation loss: 0.89713987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10790.67578125MB
INFO:root:[   62] Training loss: 0.88185828, Validation loss: 0.89664233, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10865.203125MB
INFO:root:[   63] Training loss: 0.88131176, Validation loss: 0.89555655, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=10941.01171875MB
INFO:root:[   64] Training loss: 0.88026873, Validation loss: 0.89621009, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11016.85546875MB
INFO:root:[   65] Training loss: 0.88010232, Validation loss: 0.89600205, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11093.0546875MB
INFO:root:[   66] Training loss: 0.87963347, Validation loss: 0.89667617, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11168.44140625MB
INFO:root:[   67] Training loss: 0.87920867, Validation loss: 0.89583043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11243.9765625MB
INFO:root:[   68] Training loss: 0.87843467, Validation loss: 0.89462688, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11319.81640625MB
INFO:root:[   69] Training loss: 0.87816129, Validation loss: 0.89518103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11395.13671875MB
INFO:root:[   70] Training loss: 0.87771552, Validation loss: 0.89502641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11471.22265625MB
INFO:root:[   71] Training loss: 0.87714423, Validation loss: 0.89420908, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11546.99609375MB
INFO:root:[   72] Training loss: 0.87641021, Validation loss: 0.89463272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11622.98828125MB
INFO:root:[   73] Training loss: 0.87642157, Validation loss: 0.89449259, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11699.46875MB
INFO:root:[   74] Training loss: 0.87558701, Validation loss: 0.89283153, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11775.4453125MB
INFO:root:[   75] Training loss: 0.87503767, Validation loss: 0.89402573, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11851.4609375MB
INFO:root:[   76] Training loss: 0.87479246, Validation loss: 0.89359289, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=11927.75390625MB
INFO:root:[   77] Training loss: 0.87410134, Validation loss: 0.89357503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12003.60546875MB
INFO:root:[   78] Training loss: 0.87382036, Validation loss: 0.89353105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12079.53125MB
INFO:root:[   79] Training loss: 0.87349975, Validation loss: 0.89388378, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12156.42578125MB
INFO:root:[   80] Training loss: 0.87314322, Validation loss: 0.89495769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12212.65234375MB
INFO:root:[   81] Training loss: 0.87272216, Validation loss: 0.89195792, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12264.203125MB
INFO:root:[   82] Training loss: 0.87238072, Validation loss: 0.89285762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12530.46484375MB
INFO:root:[   83] Training loss: 0.87155760, Validation loss: 0.89271940, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12584.7421875MB
INFO:root:[   84] Training loss: 0.87155030, Validation loss: 0.89352449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12662.0859375MB
INFO:root:[   85] Training loss: 0.87146486, Validation loss: 0.89294487, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12740.75MB
INFO:root:[   86] Training loss: 0.87079163, Validation loss: 0.89179212, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12817.6640625MB
INFO:root:[   87] Training loss: 0.87062529, Validation loss: 0.89223468, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12893.46875MB
INFO:root:[   88] Training loss: 0.87002073, Validation loss: 0.89302503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=12970.03515625MB
INFO:root:[   89] Training loss: 0.86991316, Validation loss: 0.89079649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13047.19140625MB
INFO:root:[   90] Training loss: 0.86921466, Validation loss: 0.89170102, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13123.91015625MB
INFO:root:[   91] Training loss: 0.86877432, Validation loss: 0.89254933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13202.4453125MB
INFO:root:[   92] Training loss: 0.86855683, Validation loss: 0.89110629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13279.71875MB
INFO:root:[   93] Training loss: 0.86809739, Validation loss: 0.89221245, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13357.49609375MB
INFO:root:[   94] Training loss: 0.86785590, Validation loss: 0.89146810, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13435.265625MB
INFO:root:[   95] Training loss: 0.86760173, Validation loss: 0.89111625, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13513.76953125MB
INFO:root:[   96] Training loss: 0.86694574, Validation loss: 0.89363902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13591.77734375MB
INFO:root:[   97] Training loss: 0.86688166, Validation loss: 0.89209405, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13669.296875MB
INFO:root:[   98] Training loss: 0.86625352, Validation loss: 0.89175337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=13747.80078125MB
INFO:root:EP 98: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12453.59765625MB; mem (CPU total)=13819.4140625MB
INFO:root:Training the model took 3568.996s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84784
INFO:root:EnergyScoreTrain: 0.73778
INFO:root:CRPSTrain: 0.58734
INFO:root:Gaussian NLLTrain: 106.46539
INFO:root:CoverageTrain: 0.36271
INFO:root:IntervalWidthTrain: 0.6067
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8731
INFO:root:EnergyScoreValidation: 0.76245
INFO:root:CRPSValidation: 0.60852
INFO:root:Gaussian NLLValidation: 107.46035
INFO:root:CoverageValidation: 0.34929
INFO:root:IntervalWidthValidation: 0.60685
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8734
INFO:root:EnergyScoreTest: 0.76293
INFO:root:CRPSTest: 0.60846
INFO:root:Gaussian NLLTest: 107.67316
INFO:root:CoverageTest: 0.34968
INFO:root:IntervalWidthTest: 0.60578
INFO:root:After validation: mem (CPU python)=12453.59765625MB; mem (CPU total)=14162.19921875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12453.59765625MB; mem (CPU total)=14169.33203125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12453.59765625MB; mem (CPU total)=14170.5625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14176.22265625MB
INFO:root:[    1] Training loss: 1.02267267, Validation loss: 1.01825458, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14253.33984375MB
INFO:root:[    2] Training loss: 1.01642578, Validation loss: 1.01393715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14331.08203125MB
INFO:root:[    3] Training loss: 1.00626330, Validation loss: 0.99836400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14407.47265625MB
INFO:root:[    4] Training loss: 0.99059877, Validation loss: 0.98433733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14485.50390625MB
INFO:root:[    5] Training loss: 0.97810054, Validation loss: 0.97324260, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14563.078125MB
INFO:root:[    6] Training loss: 0.96755333, Validation loss: 0.96477438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14640.3515625MB
INFO:root:[    7] Training loss: 0.95920740, Validation loss: 0.95757542, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14717.87109375MB
INFO:root:[    8] Training loss: 0.95263744, Validation loss: 0.95211827, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14795.734375MB
INFO:root:[    9] Training loss: 0.94755238, Validation loss: 0.94755330, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14873.1640625MB
INFO:root:[   10] Training loss: 0.94287695, Validation loss: 0.94291901, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=14949.25390625MB
INFO:root:[   11] Training loss: 0.93877226, Validation loss: 0.93959520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15025.0859375MB
INFO:root:[   12] Training loss: 0.93537354, Validation loss: 0.93583440, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15101.62109375MB
INFO:root:[   13] Training loss: 0.93182896, Validation loss: 0.93294601, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15178.15625MB
INFO:root:[   14] Training loss: 0.92959162, Validation loss: 0.93032385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15254.6328125MB
INFO:root:[   15] Training loss: 0.92653329, Validation loss: 0.92866778, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15330.70703125MB
INFO:root:[   16] Training loss: 0.92448374, Validation loss: 0.92700924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15407.2421875MB
INFO:root:[   17] Training loss: 0.92199771, Validation loss: 0.92442667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15484.26953125MB
INFO:root:[   18] Training loss: 0.91981686, Validation loss: 0.92306719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15561.93359375MB
INFO:root:[   19] Training loss: 0.91762007, Validation loss: 0.92070818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15639.19140625MB
INFO:root:[   20] Training loss: 0.91590608, Validation loss: 0.91962534, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15715.41796875MB
INFO:root:[   21] Training loss: 0.91426262, Validation loss: 0.91764338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15792.94921875MB
INFO:root:[   22] Training loss: 0.91216264, Validation loss: 0.91698755, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15870.453125MB
INFO:root:[   23] Training loss: 0.91088005, Validation loss: 0.91504563, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=15947.49609375MB
INFO:root:[   24] Training loss: 0.90903249, Validation loss: 0.91319842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16024.99609375MB
INFO:root:[   25] Training loss: 0.90755704, Validation loss: 0.91196817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16102.171875MB
INFO:root:[   26] Training loss: 0.90652218, Validation loss: 0.91081786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16179.453125MB
INFO:root:[   27] Training loss: 0.90503030, Validation loss: 0.91100900, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16255.79296875MB
INFO:root:[   28] Training loss: 0.90404875, Validation loss: 0.90803884, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16333.7578125MB
INFO:root:[   29] Training loss: 0.90251610, Validation loss: 0.90698531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16410.9375MB
INFO:root:[   30] Training loss: 0.90125553, Validation loss: 0.90785212, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16487.98046875MB
INFO:root:[   31] Training loss: 0.90018019, Validation loss: 0.90655793, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16566.25390625MB
INFO:root:[   32] Training loss: 0.89916855, Validation loss: 0.90486682, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16643.7890625MB
INFO:root:[   33] Training loss: 0.89808049, Validation loss: 0.90441013, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16721.04296875MB
INFO:root:[   34] Training loss: 0.89709703, Validation loss: 0.90344993, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16799.57421875MB
INFO:root:[   35] Training loss: 0.89587037, Validation loss: 0.90345731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16876.7421875MB
INFO:root:[   36] Training loss: 0.89502541, Validation loss: 0.90165604, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=16954.30078125MB
INFO:root:[   37] Training loss: 0.89448928, Validation loss: 0.90199117, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17031.98046875MB
INFO:root:[   38] Training loss: 0.89363176, Validation loss: 0.90161807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17110.0078125MB
INFO:root:[   39] Training loss: 0.89265442, Validation loss: 0.89848966, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17187.515625MB
INFO:root:[   40] Training loss: 0.89159511, Validation loss: 0.89938878, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17265.24609375MB
INFO:root:[   41] Training loss: 0.89086006, Validation loss: 0.90080438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17343.0234375MB
INFO:root:[   42] Training loss: 0.89007399, Validation loss: 0.89873070, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17420.58984375MB
INFO:root:[   43] Training loss: 0.88898788, Validation loss: 0.89831783, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17498.60546875MB
INFO:root:[   44] Training loss: 0.88840691, Validation loss: 0.89710370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17576.83203125MB
INFO:root:[   45] Training loss: 0.88756472, Validation loss: 0.89693117, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17654.88671875MB
INFO:root:[   46] Training loss: 0.88685660, Validation loss: 0.89615005, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17732.66796875MB
INFO:root:[   47] Training loss: 0.88623122, Validation loss: 0.89590654, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17810.41015625MB
INFO:root:[   48] Training loss: 0.88546158, Validation loss: 0.89600297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17887.23828125MB
INFO:root:[   49] Training loss: 0.88461633, Validation loss: 0.89396929, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=17963.6484375MB
INFO:root:[   50] Training loss: 0.88382118, Validation loss: 0.89346328, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18040.19140625MB
INFO:root:[   51] Training loss: 0.88320411, Validation loss: 0.89454603, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18115.99609375MB
INFO:root:[   52] Training loss: 0.88281086, Validation loss: 0.89279594, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18192.28515625MB
INFO:root:[   53] Training loss: 0.88195743, Validation loss: 0.89331877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18268.7734375MB
INFO:root:[   54] Training loss: 0.88148181, Validation loss: 0.89273170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18346.5859375MB
INFO:root:[   55] Training loss: 0.88085021, Validation loss: 0.89298139, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18424.859375MB
INFO:root:[   56] Training loss: 0.88035243, Validation loss: 0.89148352, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18502.8828125MB
INFO:root:[   57] Training loss: 0.87984989, Validation loss: 0.89003145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18580.87109375MB
INFO:root:[   58] Training loss: 0.87910319, Validation loss: 0.89046093, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18658.65234375MB
INFO:root:[   59] Training loss: 0.87815420, Validation loss: 0.89059236, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18734.171875MB
INFO:root:[   60] Training loss: 0.87790722, Validation loss: 0.89164876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18787.8046875MB
INFO:root:[   61] Training loss: 0.87742171, Validation loss: 0.88969428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18855.20703125MB
INFO:root:[   62] Training loss: 0.87666098, Validation loss: 0.88915555, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=18926.10546875MB
INFO:root:[   63] Training loss: 0.87631218, Validation loss: 0.88976484, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19003.76171875MB
INFO:root:[   64] Training loss: 0.87531025, Validation loss: 0.88841392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19082.2734375MB
INFO:root:[   65] Training loss: 0.87510327, Validation loss: 0.88880357, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19160.51953125MB
INFO:root:[   66] Training loss: 0.87447489, Validation loss: 0.88782021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19239.01953125MB
INFO:root:[   67] Training loss: 0.87406716, Validation loss: 0.88787145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19316.78125MB
INFO:root:[   68] Training loss: 0.87350974, Validation loss: 0.88691324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19395.03125MB
INFO:root:[   69] Training loss: 0.87298005, Validation loss: 0.88690836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19472.92578125MB
INFO:root:[   70] Training loss: 0.87256224, Validation loss: 0.88728038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19551.4296875MB
INFO:root:[   71] Training loss: 0.87220462, Validation loss: 0.88647351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19629.65234375MB
INFO:root:[   72] Training loss: 0.87167754, Validation loss: 0.88667786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19708.1484375MB
INFO:root:[   73] Training loss: 0.87139283, Validation loss: 0.88635520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19786.46875MB
INFO:root:[   74] Training loss: 0.87096323, Validation loss: 0.88504492, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19864.48828125MB
INFO:root:[   75] Training loss: 0.87033584, Validation loss: 0.88432709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=19942.4609375MB
INFO:root:[   76] Training loss: 0.86989767, Validation loss: 0.88580736, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20020.6015625MB
INFO:root:[   77] Training loss: 0.86951548, Validation loss: 0.88521973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20099.64453125MB
INFO:root:[   78] Training loss: 0.86890026, Validation loss: 0.88503068, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20177.40625MB
INFO:root:[   79] Training loss: 0.86861687, Validation loss: 0.88580039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20254.12890625MB
INFO:root:[   80] Training loss: 0.86782849, Validation loss: 0.88512578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20330.4140625MB
INFO:root:[   81] Training loss: 0.86771056, Validation loss: 0.88492997, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20406.65625MB
INFO:root:[   82] Training loss: 0.86718516, Validation loss: 0.88527507, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20482.69921875MB
INFO:root:[   83] Training loss: 0.86688038, Validation loss: 0.88449904, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20559.48046875MB
INFO:root:[   84] Training loss: 0.86654623, Validation loss: 0.88441443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20635.69140625MB
INFO:root:[   85] Training loss: 0.86601654, Validation loss: 0.88408485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20713.9921875MB
INFO:root:[   86] Training loss: 0.86600804, Validation loss: 0.88429213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20792.01953125MB
INFO:root:[   87] Training loss: 0.86535987, Validation loss: 0.88451365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20869.828125MB
INFO:root:[   88] Training loss: 0.86501671, Validation loss: 0.88439435, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=20948.00390625MB
INFO:root:[   89] Training loss: 0.86433130, Validation loss: 0.88381674, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21026.80078125MB
INFO:root:[   90] Training loss: 0.86419922, Validation loss: 0.88295757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21104.48828125MB
INFO:root:[   91] Training loss: 0.86362701, Validation loss: 0.88330135, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21182.98828125MB
INFO:root:[   92] Training loss: 0.86335639, Validation loss: 0.88468062, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21261.71484375MB
INFO:root:[   93] Training loss: 0.86335444, Validation loss: 0.88349929, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21339.28515625MB
INFO:root:[   94] Training loss: 0.86257253, Validation loss: 0.88344461, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21417.98828125MB
INFO:root:[   95] Training loss: 0.86247777, Validation loss: 0.88317536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21496.265625MB
INFO:root:[   96] Training loss: 0.86225317, Validation loss: 0.88259966, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21574.71875MB
INFO:root:[   97] Training loss: 0.86168982, Validation loss: 0.88288834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21653.015625MB
INFO:root:[   98] Training loss: 0.86136691, Validation loss: 0.88331453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21731.83984375MB
INFO:root:[   99] Training loss: 0.86096848, Validation loss: 0.88265660, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21810.484375MB
INFO:root:[  100] Training loss: 0.86069824, Validation loss: 0.88246943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21888.98828125MB
INFO:root:[  101] Training loss: 0.86034206, Validation loss: 0.88259893, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=21968.01953125MB
INFO:root:[  102] Training loss: 0.86010705, Validation loss: 0.88455019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22046.51171875MB
INFO:root:[  103] Training loss: 0.85944605, Validation loss: 0.88134938, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22124.40625MB
INFO:root:[  104] Training loss: 0.85950329, Validation loss: 0.88313286, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22202.171875MB
INFO:root:[  105] Training loss: 0.85909017, Validation loss: 0.88154198, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22278.98046875MB
INFO:root:[  106] Training loss: 0.85886164, Validation loss: 0.88165187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22354.89453125MB
INFO:root:[  107] Training loss: 0.85842469, Validation loss: 0.88342138, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22431.3359375MB
INFO:root:[  108] Training loss: 0.85786544, Validation loss: 0.88236022, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22507.87109375MB
INFO:root:[  109] Training loss: 0.85774732, Validation loss: 0.88327504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22583.9140625MB
INFO:root:[  110] Training loss: 0.85740886, Validation loss: 0.88205157, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22660.66015625MB
INFO:root:[  111] Training loss: 0.85732343, Validation loss: 0.88104153, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22738.94921875MB
INFO:root:[  112] Training loss: 0.85675708, Validation loss: 0.88160058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22819.30859375MB
INFO:root:[  113] Training loss: 0.85673963, Validation loss: 0.88283400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22897.29296875MB
INFO:root:[  114] Training loss: 0.85642882, Validation loss: 0.88134062, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=22975.43359375MB
INFO:root:[  115] Training loss: 0.85598075, Validation loss: 0.88225344, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=23053.4921875MB
INFO:root:[  116] Training loss: 0.85558081, Validation loss: 0.88111781, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=23131.578125MB
INFO:root:[  117] Training loss: 0.85555231, Validation loss: 0.88106829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=23210.7578125MB
INFO:root:[  118] Training loss: 0.85493209, Validation loss: 0.88111983, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=23288.4765625MB
INFO:root:[  119] Training loss: 0.85479908, Validation loss: 0.88194577, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=23367.18359375MB
INFO:root:[  120] Training loss: 0.85458747, Validation loss: 0.88177490, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=23444.98828125MB
INFO:root:EP 120: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12453.59765625MB; mem (CPU total)=23508.203125MB
INFO:root:Training the model took 5005.616s.
INFO:root:Emptying the cuda cache took 0.022s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83384
INFO:root:EnergyScoreTrain: 0.72095
INFO:root:CRPSTrain: 0.5685
INFO:root:Gaussian NLLTrain: 69.48251
INFO:root:CoverageTrain: 0.39025
INFO:root:IntervalWidthTrain: 0.6404
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86159
INFO:root:EnergyScoreValidation: 0.74818
INFO:root:CRPSValidation: 0.59132
INFO:root:Gaussian NLLValidation: 70.83742
INFO:root:CoverageValidation: 0.37658
INFO:root:IntervalWidthValidation: 0.63915
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86189
INFO:root:EnergyScoreTest: 0.74856
INFO:root:CRPSTest: 0.59163
INFO:root:Gaussian NLLTest: 69.91716
INFO:root:CoverageTest: 0.37564
INFO:root:IntervalWidthTest: 0.63861
INFO:root:After validation: mem (CPU python)=12453.59765625MB; mem (CPU total)=23813.4453125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12453.59765625MB; mem (CPU total)=23766.875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12453.59765625MB; mem (CPU total)=23771.53515625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=23784.234375MB
INFO:root:[    1] Training loss: 1.02210435, Validation loss: 1.01778351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=23863.2734375MB
INFO:root:[    2] Training loss: 1.01664537, Validation loss: 1.01469781, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=23939.8515625MB
INFO:root:[    3] Training loss: 1.00841828, Validation loss: 1.00060956, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=24016.15234375MB
INFO:root:[    4] Training loss: 0.99451874, Validation loss: 0.98942454, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=24095.46875MB
INFO:root:[    5] Training loss: 0.98250036, Validation loss: 0.97824738, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=24151.44921875MB
INFO:root:[    6] Training loss: 0.97163696, Validation loss: 0.96839554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=24219.15625MB
INFO:root:[    7] Training loss: 0.96312620, Validation loss: 0.96046656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=24281.78515625MB
INFO:root:[    8] Training loss: 0.95584050, Validation loss: 0.95404805, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=24360.3046875MB
INFO:root:[    9] Training loss: 0.95026573, Validation loss: 0.94876401, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=24438.84765625MB
INFO:root:[   10] Training loss: 0.94534454, Validation loss: 0.94489963, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=24516.31640625MB
INFO:root:[   11] Training loss: 0.94134178, Validation loss: 0.94148811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12453.59765625MB; mem (CPU total)=24593.87890625MB
INFO:root:[   12] Training loss: 0.93755841, Validation loss: 0.93817130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12485.33984375MB; mem (CPU total)=24672.09765625MB
INFO:root:[   13] Training loss: 0.93394658, Validation loss: 0.93429678, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12523.43359375MB; mem (CPU total)=24750.0MB
INFO:root:[   14] Training loss: 0.93074827, Validation loss: 0.93087207, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12561.53125MB; mem (CPU total)=24828.26953125MB
INFO:root:[   15] Training loss: 0.92773144, Validation loss: 0.92871581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12599.625MB; mem (CPU total)=24905.2421875MB
INFO:root:[   16] Training loss: 0.92505819, Validation loss: 0.92504749, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12637.71875MB; mem (CPU total)=24983.17578125MB
INFO:root:[   17] Training loss: 0.92254413, Validation loss: 0.92427962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12675.81640625MB; mem (CPU total)=25061.23828125MB
INFO:root:[   18] Training loss: 0.92027119, Validation loss: 0.92222084, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12713.91015625MB; mem (CPU total)=25139.05859375MB
INFO:root:[   19] Training loss: 0.91800466, Validation loss: 0.91889191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12752.00390625MB; mem (CPU total)=25216.6484375MB
INFO:root:[   20] Training loss: 0.91622808, Validation loss: 0.91775339, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12790.09765625MB; mem (CPU total)=25294.60546875MB
INFO:root:[   21] Training loss: 0.91433466, Validation loss: 0.91706050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12828.19921875MB; mem (CPU total)=25372.92578125MB
INFO:root:[   22] Training loss: 0.91248864, Validation loss: 0.91400449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12866.28125MB; mem (CPU total)=25450.21875MB
INFO:root:[   23] Training loss: 0.91062316, Validation loss: 0.91431340, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12904.375MB; mem (CPU total)=25528.23828125MB
INFO:root:[   24] Training loss: 0.90920144, Validation loss: 0.91182387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12942.47265625MB; mem (CPU total)=25605.80078125MB
INFO:root:[   25] Training loss: 0.90742846, Validation loss: 0.91093465, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12980.56640625MB; mem (CPU total)=25683.29296875MB
INFO:root:[   26] Training loss: 0.90631923, Validation loss: 0.90963662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13018.66015625MB; mem (CPU total)=25759.72265625MB
INFO:root:[   27] Training loss: 0.90501334, Validation loss: 0.90858932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13056.7578125MB; mem (CPU total)=25837.99609375MB
INFO:root:[   28] Training loss: 0.90364171, Validation loss: 0.90714573, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13094.8515625MB; mem (CPU total)=25915.4921875MB
INFO:root:[   29] Training loss: 0.90217307, Validation loss: 0.90555768, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13132.94921875MB; mem (CPU total)=25993.98046875MB
INFO:root:[   30] Training loss: 0.90101377, Validation loss: 0.90579007, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13171.04296875MB; mem (CPU total)=26071.25MB
INFO:root:[   31] Training loss: 0.90005604, Validation loss: 0.90438508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13209.140625MB; mem (CPU total)=26148.609375MB
INFO:root:[   32] Training loss: 0.89867463, Validation loss: 0.90315776, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13247.234375MB; mem (CPU total)=26226.109375MB
INFO:root:[   33] Training loss: 0.89750249, Validation loss: 0.90284999, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13285.328125MB; mem (CPU total)=26304.078125MB
INFO:root:[   34] Training loss: 0.89638880, Validation loss: 0.90186799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13323.42578125MB; mem (CPU total)=26380.671875MB
INFO:root:[   35] Training loss: 0.89560898, Validation loss: 0.90055271, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13361.51953125MB; mem (CPU total)=26457.19140625MB
INFO:root:[   36] Training loss: 0.89439102, Validation loss: 0.90064952, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13399.61328125MB; mem (CPU total)=26532.23828125MB
INFO:root:[   37] Training loss: 0.89356561, Validation loss: 0.90000609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13437.7109375MB; mem (CPU total)=26609.515625MB
INFO:root:[   38] Training loss: 0.89251597, Validation loss: 0.89840670, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13475.80859375MB; mem (CPU total)=26686.109375MB
INFO:root:[   39] Training loss: 0.89170693, Validation loss: 0.89743745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13513.90234375MB; mem (CPU total)=26762.40234375MB
INFO:root:[   40] Training loss: 0.89078484, Validation loss: 0.89729949, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13551.99609375MB; mem (CPU total)=26839.45703125MB
INFO:root:[   41] Training loss: 0.89013040, Validation loss: 0.89667524, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13590.09375MB; mem (CPU total)=26915.140625MB
INFO:root:[   42] Training loss: 0.88876996, Validation loss: 0.89630057, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13628.1875MB; mem (CPU total)=26991.4140625MB
INFO:root:[   43] Training loss: 0.88817411, Validation loss: 0.89550742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13666.28125MB; mem (CPU total)=27068.24609375MB
INFO:root:[   44] Training loss: 0.88725528, Validation loss: 0.89510014, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13704.37890625MB; mem (CPU total)=27144.265625MB
INFO:root:[   45] Training loss: 0.88654457, Validation loss: 0.89450351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13742.47265625MB; mem (CPU total)=27221.00390625MB
INFO:root:[   46] Training loss: 0.88582755, Validation loss: 0.89361692, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13780.5703125MB; mem (CPU total)=27296.79296875MB
INFO:root:[   47] Training loss: 0.88477166, Validation loss: 0.89323768, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13818.6640625MB; mem (CPU total)=27373.06640625MB
INFO:root:[   48] Training loss: 0.88406143, Validation loss: 0.89164535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13856.76171875MB; mem (CPU total)=27449.66796875MB
INFO:root:[   49] Training loss: 0.88354888, Validation loss: 0.89264961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13894.85546875MB; mem (CPU total)=27526.00390625MB
INFO:root:[   50] Training loss: 0.88276813, Validation loss: 0.89209961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13932.94921875MB; mem (CPU total)=27602.8046875MB
INFO:root:[   51] Training loss: 0.88193012, Validation loss: 0.89069196, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13971.046875MB; mem (CPU total)=27680.83203125MB
INFO:root:[   52] Training loss: 0.88129128, Validation loss: 0.89145039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14009.140625MB; mem (CPU total)=27758.58203125MB
INFO:root:[   53] Training loss: 0.88048666, Validation loss: 0.89132847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14047.234375MB; mem (CPU total)=27835.13671875MB
INFO:root:[   54] Training loss: 0.87977164, Validation loss: 0.88992921, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14085.33203125MB; mem (CPU total)=27911.39453125MB
INFO:root:[   55] Training loss: 0.87915349, Validation loss: 0.88959288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14123.4296875MB; mem (CPU total)=27988.3828125MB
INFO:root:[   56] Training loss: 0.87862577, Validation loss: 0.88931575, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14161.5234375MB; mem (CPU total)=28065.8671875MB
INFO:root:[   57] Training loss: 0.87789531, Validation loss: 0.88872195, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14199.6171875MB; mem (CPU total)=28143.7734375MB
INFO:root:[   58] Training loss: 0.87748951, Validation loss: 0.88862326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14237.71484375MB; mem (CPU total)=28220.3203125MB
INFO:root:[   59] Training loss: 0.87679847, Validation loss: 0.88851516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14275.80859375MB; mem (CPU total)=28297.1171875MB
INFO:root:[   60] Training loss: 0.87638208, Validation loss: 0.88870057, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14313.90234375MB; mem (CPU total)=28374.41015625MB
INFO:root:[   61] Training loss: 0.87558321, Validation loss: 0.88717952, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14352.00390625MB; mem (CPU total)=28451.671875MB
INFO:root:[   62] Training loss: 0.87525673, Validation loss: 0.88664446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14390.09765625MB; mem (CPU total)=28529.23828125MB
INFO:root:[   63] Training loss: 0.87437617, Validation loss: 0.88603572, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14428.1875MB; mem (CPU total)=28605.79296875MB
INFO:root:[   64] Training loss: 0.87372335, Validation loss: 0.88764617, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14466.28515625MB; mem (CPU total)=28682.09765625MB
INFO:root:[   65] Training loss: 0.87348039, Validation loss: 0.88656910, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14504.38671875MB; mem (CPU total)=28759.3828125MB
INFO:root:[   66] Training loss: 0.87302791, Validation loss: 0.88656784, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14542.48046875MB; mem (CPU total)=28836.91796875MB
INFO:root:[   67] Training loss: 0.87215217, Validation loss: 0.88534901, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14580.57421875MB; mem (CPU total)=28913.47265625MB
INFO:root:[   68] Training loss: 0.87196266, Validation loss: 0.88455265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14618.671875MB; mem (CPU total)=28990.515625MB
INFO:root:[   69] Training loss: 0.87134980, Validation loss: 0.88417012, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14656.765625MB; mem (CPU total)=29066.51953125MB
INFO:root:[   70] Training loss: 0.87082334, Validation loss: 0.88528558, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14694.859375MB; mem (CPU total)=29143.5546875MB
INFO:root:[   71] Training loss: 0.87057375, Validation loss: 0.88467986, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14732.95703125MB; mem (CPU total)=29221.3125MB
INFO:root:[   72] Training loss: 0.86978853, Validation loss: 0.88510628, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14771.0546875MB; mem (CPU total)=29298.11328125MB
INFO:root:[   73] Training loss: 0.86942055, Validation loss: 0.88343406, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14809.1484375MB; mem (CPU total)=29374.80859375MB
INFO:root:[   74] Training loss: 0.86902297, Validation loss: 0.88374158, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14847.3203125MB; mem (CPU total)=29447.1328125MB
INFO:root:[   75] Training loss: 0.86841822, Validation loss: 0.88303513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14885.41796875MB; mem (CPU total)=29502.9921875MB
INFO:root:[   76] Training loss: 0.86803246, Validation loss: 0.88323516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14923.51171875MB; mem (CPU total)=29584.5859375MB
INFO:root:[   77] Training loss: 0.86756231, Validation loss: 0.88425605, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14961.60546875MB; mem (CPU total)=29651.71484375MB
INFO:root:[   78] Training loss: 0.86681142, Validation loss: 0.88238931, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14999.70703125MB; mem (CPU total)=29727.85546875MB
INFO:root:[   79] Training loss: 0.86661233, Validation loss: 0.88427209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15037.796875MB; mem (CPU total)=29803.671875MB
INFO:root:[   80] Training loss: 0.86624904, Validation loss: 0.88225017, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15075.89453125MB; mem (CPU total)=29879.75MB
INFO:root:[   81] Training loss: 0.86616356, Validation loss: 0.88406179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15113.98828125MB; mem (CPU total)=29955.31640625MB
INFO:root:[   82] Training loss: 0.86561770, Validation loss: 0.88240766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15152.0859375MB; mem (CPU total)=30030.75390625MB
INFO:root:[   83] Training loss: 0.86497188, Validation loss: 0.88211574, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15190.1796875MB; mem (CPU total)=30105.74609375MB
INFO:root:[   84] Training loss: 0.86502543, Validation loss: 0.88242173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15228.2734375MB; mem (CPU total)=30181.8046875MB
INFO:root:[   85] Training loss: 0.86407235, Validation loss: 0.88208367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15266.37109375MB; mem (CPU total)=30257.12890625MB
INFO:root:[   86] Training loss: 0.86392164, Validation loss: 0.88253248, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15304.46484375MB; mem (CPU total)=30333.40625MB
INFO:root:[   87] Training loss: 0.86353311, Validation loss: 0.88309961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15342.55859375MB; mem (CPU total)=30408.97265625MB
INFO:root:[   88] Training loss: 0.86334408, Validation loss: 0.88096859, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15380.65625MB; mem (CPU total)=30483.984375MB
INFO:root:[   89] Training loss: 0.86276310, Validation loss: 0.88151658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15418.75390625MB; mem (CPU total)=30560.046875MB
INFO:root:[   90] Training loss: 0.86221322, Validation loss: 0.88152907, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15456.84765625MB; mem (CPU total)=30635.86328125MB
INFO:root:[   91] Training loss: 0.86200208, Validation loss: 0.88210307, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15494.94140625MB; mem (CPU total)=30711.82421875MB
INFO:root:[   92] Training loss: 0.86148251, Validation loss: 0.88108202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15533.0390625MB; mem (CPU total)=30787.21484375MB
INFO:root:[   93] Training loss: 0.86121861, Validation loss: 0.88214715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15571.1328125MB; mem (CPU total)=30863.03125MB
INFO:root:[   94] Training loss: 0.86082590, Validation loss: 0.88138647, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15609.2265625MB; mem (CPU total)=30938.1484375MB
INFO:root:[   95] Training loss: 0.86052835, Validation loss: 0.88179667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15647.33203125MB; mem (CPU total)=31013.234375MB
INFO:root:[   96] Training loss: 0.86040119, Validation loss: 0.88098296, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15685.42578125MB; mem (CPU total)=31088.80078125MB
INFO:root:[   97] Training loss: 0.85974128, Validation loss: 0.88057448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15723.51953125MB; mem (CPU total)=31164.62890625MB
INFO:root:[   98] Training loss: 0.85968770, Validation loss: 0.88246459, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15761.61328125MB; mem (CPU total)=31245.75390625MB
INFO:root:[   99] Training loss: 0.85941125, Validation loss: 0.87961072, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15799.7109375MB; mem (CPU total)=31321.25390625MB
INFO:root:[  100] Training loss: 0.85868228, Validation loss: 0.88251330, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15837.8046875MB; mem (CPU total)=31396.23046875MB
INFO:root:[  101] Training loss: 0.85854037, Validation loss: 0.88089985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15875.8984375MB; mem (CPU total)=31471.16015625MB
INFO:root:[  102] Training loss: 0.85810472, Validation loss: 0.88116409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15914.0MB; mem (CPU total)=31545.875MB
INFO:root:[  103] Training loss: 0.85781042, Validation loss: 0.88052501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15952.09375MB; mem (CPU total)=31622.18359375MB
INFO:root:[  104] Training loss: 0.85769369, Validation loss: 0.88233105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15990.19140625MB; mem (CPU total)=31697.73828125MB
INFO:root:[  105] Training loss: 0.85739747, Validation loss: 0.88151322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16028.28515625MB; mem (CPU total)=31773.421875MB
INFO:root:[  106] Training loss: 0.85689066, Validation loss: 0.88235415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16066.3828125MB; mem (CPU total)=31847.859375MB
INFO:root:[  107] Training loss: 0.85685869, Validation loss: 0.88060170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16104.4765625MB; mem (CPU total)=31922.57421875MB
INFO:root:[  108] Training loss: 0.85619250, Validation loss: 0.88048267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16142.5703125MB; mem (CPU total)=31997.40234375MB
INFO:root:EP 108: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16180.6640625MB; mem (CPU total)=32071.48828125MB
INFO:root:Training the model took 5139.011s.
INFO:root:Emptying the cuda cache took 0.023s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83806
INFO:root:EnergyScoreTrain: 0.72977
INFO:root:CRPSTrain: 0.57568
INFO:root:Gaussian NLLTrain: 85.90797
INFO:root:CoverageTrain: 0.3737
INFO:root:IntervalWidthTrain: 0.60265
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86231
INFO:root:EnergyScoreValidation: 0.75361
INFO:root:CRPSValidation: 0.59579
INFO:root:Gaussian NLLValidation: 87.0352
INFO:root:CoverageValidation: 0.36163
INFO:root:IntervalWidthValidation: 0.60192
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8637
INFO:root:EnergyScoreTest: 0.75507
INFO:root:CRPSTest: 0.59706
INFO:root:Gaussian NLLTest: 87.25332
INFO:root:CoverageTest: 0.36043
INFO:root:IntervalWidthTest: 0.60105
INFO:root:After validation: mem (CPU python)=16280.37109375MB; mem (CPU total)=32361.8046875MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=16280.37109375MB; mem (CPU total)=32309.48046875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=16280.37109375MB; mem (CPU total)=32314.5859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=16280.37109375MB; mem (CPU total)=32333.54296875MB
INFO:root:[    1] Training loss: 1.02222444, Validation loss: 1.01787662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16280.37109375MB; mem (CPU total)=32408.25MB
INFO:root:[    2] Training loss: 1.01621943, Validation loss: 1.01392642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16297.87890625MB; mem (CPU total)=32482.83203125MB
INFO:root:[    3] Training loss: 1.00671242, Validation loss: 0.99998675, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16335.98828125MB; mem (CPU total)=32557.4765625MB
INFO:root:[    4] Training loss: 0.99465328, Validation loss: 0.99071027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16374.1015625MB; mem (CPU total)=32632.4375MB
INFO:root:[    5] Training loss: 0.98514973, Validation loss: 0.98157024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16412.2109375MB; mem (CPU total)=32707.10546875MB
INFO:root:[    6] Training loss: 0.97581101, Validation loss: 0.97355946, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16450.3046875MB; mem (CPU total)=32782.13671875MB
INFO:root:[    7] Training loss: 0.96702604, Validation loss: 0.96420760, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16488.3984375MB; mem (CPU total)=32856.75390625MB
INFO:root:[    8] Training loss: 0.95927758, Validation loss: 0.95721662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16526.5390625MB; mem (CPU total)=32931.484375MB
INFO:root:[    9] Training loss: 0.95239647, Validation loss: 0.95071729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16564.66015625MB; mem (CPU total)=33005.05859375MB
INFO:root:[   10] Training loss: 0.94635032, Validation loss: 0.94506798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16602.7578125MB; mem (CPU total)=33080.13671875MB
INFO:root:[   11] Training loss: 0.94130949, Validation loss: 0.94060401, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16640.85546875MB; mem (CPU total)=33154.96875MB
INFO:root:[   12] Training loss: 0.93680010, Validation loss: 0.93605235, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16679.02734375MB; mem (CPU total)=33229.76953125MB
INFO:root:[   13] Training loss: 0.93269178, Validation loss: 0.93362255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16717.12109375MB; mem (CPU total)=33305.03515625MB
INFO:root:[   14] Training loss: 0.92896654, Validation loss: 0.92950521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16755.52734375MB; mem (CPU total)=33379.0MB
INFO:root:[   15] Training loss: 0.92585949, Validation loss: 0.92757986, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16794.3125MB; mem (CPU total)=33453.9453125MB
INFO:root:[   16] Training loss: 0.92299552, Validation loss: 0.92322590, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16833.34375MB; mem (CPU total)=33529.5546875MB
INFO:root:[   17] Training loss: 0.92019970, Validation loss: 0.92171242, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16871.7421875MB; mem (CPU total)=33603.890625MB
INFO:root:[   18] Training loss: 0.91762353, Validation loss: 0.91922848, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16910.3828125MB; mem (CPU total)=33680.41796875MB
INFO:root:[   19] Training loss: 0.91530954, Validation loss: 0.91716896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16948.4765625MB; mem (CPU total)=33756.67578125MB
INFO:root:[   20] Training loss: 0.91316691, Validation loss: 0.91561148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16986.5703125MB; mem (CPU total)=33832.93359375MB
INFO:root:[   21] Training loss: 0.91108518, Validation loss: 0.91366461, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17024.66796875MB; mem (CPU total)=33909.64453125MB
INFO:root:[   22] Training loss: 0.90934922, Validation loss: 0.91322342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17062.76171875MB; mem (CPU total)=33985.8828125MB
INFO:root:[   23] Training loss: 0.90769503, Validation loss: 0.91026832, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17100.85546875MB; mem (CPU total)=34061.90234375MB
INFO:root:[   24] Training loss: 0.90592017, Validation loss: 0.90887491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17138.94921875MB; mem (CPU total)=34138.43359375MB
INFO:root:[   25] Training loss: 0.90432376, Validation loss: 0.90818813, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17177.05078125MB; mem (CPU total)=34214.46875MB
INFO:root:[   26] Training loss: 0.90255556, Validation loss: 0.90671869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17215.14453125MB; mem (CPU total)=34291.25MB
INFO:root:[   27] Training loss: 0.90091132, Validation loss: 0.90539612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17253.23828125MB; mem (CPU total)=34367.5078125MB
INFO:root:[   28] Training loss: 0.89990491, Validation loss: 0.90338202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17291.3359375MB; mem (CPU total)=34443.20703125MB
INFO:root:[   29] Training loss: 0.89847465, Validation loss: 0.90320404, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17329.4296875MB; mem (CPU total)=34519.8984375MB
INFO:root:[   30] Training loss: 0.89720238, Validation loss: 0.90218448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17367.5234375MB; mem (CPU total)=34595.02734375MB
INFO:root:[   31] Training loss: 0.89610516, Validation loss: 0.90027958, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17405.62109375MB; mem (CPU total)=34669.8125MB
INFO:root:[   32] Training loss: 0.89464233, Validation loss: 0.89971781, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17443.71875MB; mem (CPU total)=34743.88671875MB
INFO:root:[   33] Training loss: 0.89354559, Validation loss: 0.90050285, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17481.81640625MB; mem (CPU total)=34817.9609375MB
INFO:root:[   34] Training loss: 0.89276091, Validation loss: 0.89818645, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17519.91015625MB; mem (CPU total)=34892.03515625MB
INFO:root:[   35] Training loss: 0.89158645, Validation loss: 0.89749772, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17558.0078125MB; mem (CPU total)=34965.859375MB
INFO:root:[   36] Training loss: 0.89082536, Validation loss: 0.89638051, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17596.1015625MB; mem (CPU total)=35040.62890625MB
INFO:root:[   37] Training loss: 0.88971440, Validation loss: 0.89532933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17634.1953125MB; mem (CPU total)=35115.19140625MB
INFO:root:[   38] Training loss: 0.88884912, Validation loss: 0.89440003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17672.296875MB; mem (CPU total)=35189.50390625MB
INFO:root:[   39] Training loss: 0.88777370, Validation loss: 0.89385020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17710.390625MB; mem (CPU total)=35264.09765625MB
INFO:root:[   40] Training loss: 0.88697594, Validation loss: 0.89382092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17748.484375MB; mem (CPU total)=35335.76171875MB
INFO:root:[   41] Training loss: 0.88602295, Validation loss: 0.89282226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17786.58203125MB; mem (CPU total)=35394.984375MB
INFO:root:[   42] Training loss: 0.88531849, Validation loss: 0.89349842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17824.6796875MB; mem (CPU total)=35471.234375MB
INFO:root:[   43] Training loss: 0.88427533, Validation loss: 0.89209678, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17862.7734375MB; mem (CPU total)=35541.41015625MB
INFO:root:[   44] Training loss: 0.88365674, Validation loss: 0.89214221, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17900.8671875MB; mem (CPU total)=35614.8359375MB
INFO:root:[   45] Training loss: 0.88299769, Validation loss: 0.89067878, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17938.96484375MB; mem (CPU total)=35689.390625MB
INFO:root:[   46] Training loss: 0.88235698, Validation loss: 0.89110676, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17977.05859375MB; mem (CPU total)=35763.3828125MB
INFO:root:[   47] Training loss: 0.88151053, Validation loss: 0.88905955, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18015.15234375MB; mem (CPU total)=35837.26171875MB
INFO:root:[   48] Training loss: 0.88056429, Validation loss: 0.88972600, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18053.24609375MB; mem (CPU total)=35910.84375MB
INFO:root:[   49] Training loss: 0.88012238, Validation loss: 0.88913475, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18091.34765625MB; mem (CPU total)=35984.17578125MB
INFO:root:[   50] Training loss: 0.87944892, Validation loss: 0.88762275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18129.44140625MB; mem (CPU total)=36057.71484375MB
INFO:root:[   51] Training loss: 0.87871102, Validation loss: 0.88919184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18167.53515625MB; mem (CPU total)=36132.19140625MB
INFO:root:[   52] Training loss: 0.87795274, Validation loss: 0.88854150, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18205.6328125MB; mem (CPU total)=36205.99609375MB
INFO:root:[   53] Training loss: 0.87752120, Validation loss: 0.88669882, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18243.7265625MB; mem (CPU total)=36280.078125MB
INFO:root:[   54] Training loss: 0.87671131, Validation loss: 0.88830381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18281.8203125MB; mem (CPU total)=36355.1171875MB
INFO:root:[   55] Training loss: 0.87646033, Validation loss: 0.88751277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18319.91796875MB; mem (CPU total)=36430.41015625MB
INFO:root:[   56] Training loss: 0.87567175, Validation loss: 0.88621754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18358.01171875MB; mem (CPU total)=36505.73046875MB
INFO:root:[   57] Training loss: 0.87491404, Validation loss: 0.88623662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18396.10546875MB; mem (CPU total)=36580.5625MB
INFO:root:[   58] Training loss: 0.87452503, Validation loss: 0.88479825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18434.203125MB; mem (CPU total)=36654.328125MB
INFO:root:[   59] Training loss: 0.87378984, Validation loss: 0.88586069, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18472.30078125MB; mem (CPU total)=36728.390625MB
INFO:root:[   60] Training loss: 0.87330775, Validation loss: 0.88472862, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18510.39453125MB; mem (CPU total)=36805.46875MB
INFO:root:[   61] Training loss: 0.87305986, Validation loss: 0.88457708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18548.48828125MB; mem (CPU total)=36881.5625MB
INFO:root:[   62] Training loss: 0.87263225, Validation loss: 0.88501706, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18586.5859375MB; mem (CPU total)=36958.7265625MB
INFO:root:[   63] Training loss: 0.87178590, Validation loss: 0.88525958, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18624.6796875MB; mem (CPU total)=37034.80859375MB
INFO:root:[   64] Training loss: 0.87145440, Validation loss: 0.88338541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18662.7734375MB; mem (CPU total)=37110.79296875MB
INFO:root:[   65] Training loss: 0.87088554, Validation loss: 0.88345854, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18700.8671875MB; mem (CPU total)=37187.30859375MB
INFO:root:[   66] Training loss: 0.87042256, Validation loss: 0.88295740, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18738.96875MB; mem (CPU total)=37263.03515625MB
INFO:root:[   67] Training loss: 0.86982597, Validation loss: 0.88304747, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18777.0625MB; mem (CPU total)=37339.33984375MB
INFO:root:[   68] Training loss: 0.86955002, Validation loss: 0.88341859, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18815.15625MB; mem (CPU total)=37415.6484375MB
INFO:root:[   69] Training loss: 0.86894256, Validation loss: 0.88266485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18853.2578125MB; mem (CPU total)=37492.19140625MB
INFO:root:[   70] Training loss: 0.86868424, Validation loss: 0.88299007, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18891.37109375MB; mem (CPU total)=37568.74609375MB
INFO:root:[   71] Training loss: 0.86790977, Validation loss: 0.88264742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18929.46484375MB; mem (CPU total)=37645.25390625MB
INFO:root:[   72] Training loss: 0.86749203, Validation loss: 0.88158918, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18967.5625MB; mem (CPU total)=37721.26171875MB
INFO:root:[   73] Training loss: 0.86695717, Validation loss: 0.88269480, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19005.65625MB; mem (CPU total)=37797.81640625MB
INFO:root:[   74] Training loss: 0.86687315, Validation loss: 0.88255140, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19043.75MB; mem (CPU total)=37874.27734375MB
INFO:root:[   75] Training loss: 0.86623641, Validation loss: 0.88361749, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19081.84375MB; mem (CPU total)=37950.046875MB
INFO:root:[   76] Training loss: 0.86608691, Validation loss: 0.88166710, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19119.9453125MB; mem (CPU total)=38026.5390625MB
INFO:root:[   77] Training loss: 0.86549967, Validation loss: 0.88123995, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19158.0390625MB; mem (CPU total)=38102.6328125MB
INFO:root:[   78] Training loss: 0.86515394, Validation loss: 0.88084104, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19196.1328125MB; mem (CPU total)=38179.21875MB
INFO:root:[   79] Training loss: 0.86486418, Validation loss: 0.88129209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19234.23046875MB; mem (CPU total)=38254.37109375MB
INFO:root:[   80] Training loss: 0.86458346, Validation loss: 0.88227563, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19272.32421875MB; mem (CPU total)=38329.05859375MB
INFO:root:[   81] Training loss: 0.86407244, Validation loss: 0.88174854, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19310.41796875MB; mem (CPU total)=38405.1171875MB
INFO:root:[   82] Training loss: 0.86385878, Validation loss: 0.87985745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19348.51171875MB; mem (CPU total)=38479.84375MB
INFO:root:[   83] Training loss: 0.86338872, Validation loss: 0.88110847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19386.61328125MB; mem (CPU total)=38555.33203125MB
INFO:root:[   84] Training loss: 0.86280943, Validation loss: 0.88063027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19424.70703125MB; mem (CPU total)=38630.265625MB
INFO:root:[   85] Training loss: 0.86286076, Validation loss: 0.88023959, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19462.80078125MB; mem (CPU total)=38705.34375MB
INFO:root:[   86] Training loss: 0.86210529, Validation loss: 0.88130348, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19500.8984375MB; mem (CPU total)=38780.4453125MB
INFO:root:[   87] Training loss: 0.86185107, Validation loss: 0.88026980, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19538.9921875MB; mem (CPU total)=38855.77734375MB
INFO:root:[   88] Training loss: 0.86133081, Validation loss: 0.88083466, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19577.0859375MB; mem (CPU total)=38930.98828125MB
INFO:root:[   89] Training loss: 0.86122698, Validation loss: 0.87983702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19615.18359375MB; mem (CPU total)=39006.3046875MB
INFO:root:[   90] Training loss: 0.86088947, Validation loss: 0.87948935, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19653.27734375MB; mem (CPU total)=39082.1875MB
INFO:root:[   91] Training loss: 0.86070360, Validation loss: 0.88019134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19691.375MB; mem (CPU total)=39157.515625MB
INFO:root:[   92] Training loss: 0.86013918, Validation loss: 0.87937125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19729.46875MB; mem (CPU total)=39233.0859375MB
INFO:root:[   93] Training loss: 0.85955215, Validation loss: 0.88015706, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19767.56640625MB; mem (CPU total)=39308.640625MB
INFO:root:[   94] Training loss: 0.85949521, Validation loss: 0.87903102, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19806.7109375MB; mem (CPU total)=39385.43359375MB
INFO:root:[   95] Training loss: 0.85908549, Validation loss: 0.87936613, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19844.8046875MB; mem (CPU total)=39460.48046875MB
INFO:root:[   96] Training loss: 0.85884615, Validation loss: 0.88022221, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19882.90234375MB; mem (CPU total)=39535.80078125MB
INFO:root:[   97] Training loss: 0.85832965, Validation loss: 0.88032268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19920.99609375MB; mem (CPU total)=39610.57421875MB
INFO:root:[   98] Training loss: 0.85828222, Validation loss: 0.87815578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19959.09375MB; mem (CPU total)=39686.41015625MB
INFO:root:[   99] Training loss: 0.85809791, Validation loss: 0.87915180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19997.1875MB; mem (CPU total)=39761.734375MB
INFO:root:[  100] Training loss: 0.85772285, Validation loss: 0.87881520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20035.28125MB; mem (CPU total)=39837.734375MB
INFO:root:[  101] Training loss: 0.85764312, Validation loss: 0.87947576, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20073.37890625MB; mem (CPU total)=39913.0625MB
INFO:root:[  102] Training loss: 0.85689836, Validation loss: 0.87925237, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20111.47265625MB; mem (CPU total)=39989.125MB
INFO:root:[  103] Training loss: 0.85674115, Validation loss: 0.88007597, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20149.5703125MB; mem (CPU total)=40065.4296875MB
INFO:root:[  104] Training loss: 0.85659406, Validation loss: 0.87939423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20187.6640625MB; mem (CPU total)=40141.421875MB
INFO:root:[  105] Training loss: 0.85614944, Validation loss: 0.88011587, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20225.7578125MB; mem (CPU total)=40217.23828125MB
INFO:root:[  106] Training loss: 0.85618721, Validation loss: 0.87879088, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20263.85546875MB; mem (CPU total)=40292.15234375MB
INFO:root:[  107] Training loss: 0.85580204, Validation loss: 0.87833470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20301.94921875MB; mem (CPU total)=40368.4609375MB
INFO:root:EP 107: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=20340.04296875MB; mem (CPU total)=40431.48046875MB
INFO:root:Training the model took 5622.753s.
INFO:root:Emptying the cuda cache took 0.024s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83727
INFO:root:EnergyScoreTrain: 0.72914
INFO:root:CRPSTrain: 0.57627
INFO:root:Gaussian NLLTrain: 121.58434
INFO:root:CoverageTrain: 0.37077
INFO:root:IntervalWidthTrain: 0.59588
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86024
INFO:root:EnergyScoreValidation: 0.75179
INFO:root:CRPSValidation: 0.59522
INFO:root:Gaussian NLLValidation: 123.12732
INFO:root:CoverageValidation: 0.35902
INFO:root:IntervalWidthValidation: 0.59472
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.862
INFO:root:EnergyScoreTest: 0.75358
INFO:root:CRPSTest: 0.59683
INFO:root:Gaussian NLLTest: 122.76139
INFO:root:CoverageTest: 0.35786
INFO:root:IntervalWidthTest: 0.59422
INFO:root:After validation: mem (CPU python)=20442.63671875MB; mem (CPU total)=40716.40234375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=20442.63671875MB; mem (CPU total)=40663.47265625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=20442.63671875MB; mem (CPU total)=40666.40625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=20442.63671875MB; mem (CPU total)=40684.37890625MB
INFO:root:[    1] Training loss: 1.02178636, Validation loss: 1.01736251, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20442.63671875MB; mem (CPU total)=40759.75MB
INFO:root:[    2] Training loss: 1.01512098, Validation loss: 1.01012371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20459.58203125MB; mem (CPU total)=40835.59765625MB
INFO:root:[    3] Training loss: 1.00321941, Validation loss: 0.99734965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20497.69140625MB; mem (CPU total)=40911.62890625MB
INFO:root:[    4] Training loss: 0.99270286, Validation loss: 0.98796053, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20535.78515625MB; mem (CPU total)=40987.7265625MB
INFO:root:[    5] Training loss: 0.98341049, Validation loss: 0.97899834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20573.87890625MB; mem (CPU total)=41064.05078125MB
INFO:root:[    6] Training loss: 0.97387272, Validation loss: 0.97018355, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20611.9765625MB; mem (CPU total)=41139.76171875MB
INFO:root:[    7] Training loss: 0.96563583, Validation loss: 0.96279160, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20650.07421875MB; mem (CPU total)=41214.90234375MB
INFO:root:[    8] Training loss: 0.95881025, Validation loss: 0.95696359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20688.16796875MB; mem (CPU total)=41291.15234375MB
INFO:root:[    9] Training loss: 0.95284587, Validation loss: 0.95181820, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20726.265625MB; mem (CPU total)=41366.609375MB
INFO:root:[   10] Training loss: 0.94782380, Validation loss: 0.94679295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20764.36328125MB; mem (CPU total)=41442.1796875MB
INFO:root:[   11] Training loss: 0.94336139, Validation loss: 0.94412961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20802.4609375MB; mem (CPU total)=41518.21484375MB
INFO:root:[   12] Training loss: 0.93936691, Validation loss: 0.94099896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20840.55859375MB; mem (CPU total)=41594.30859375MB
INFO:root:[   13] Training loss: 0.93635295, Validation loss: 0.93673536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20878.65625MB; mem (CPU total)=41672.3359375MB
INFO:root:[   14] Training loss: 0.93308271, Validation loss: 0.93363194, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20916.75MB; mem (CPU total)=41739.71484375MB
INFO:root:[   15] Training loss: 0.93027056, Validation loss: 0.93040664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20954.84375MB; mem (CPU total)=41809.32421875MB
INFO:root:[   16] Training loss: 0.92783875, Validation loss: 0.92937243, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20992.94140625MB; mem (CPU total)=41886.734375MB
INFO:root:[   17] Training loss: 0.92571791, Validation loss: 0.92711222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21031.03515625MB; mem (CPU total)=41962.56640625MB
INFO:root:[   18] Training loss: 0.92333938, Validation loss: 0.92603238, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21069.12890625MB; mem (CPU total)=42039.35546875MB
INFO:root:[   19] Training loss: 0.92142821, Validation loss: 0.92379624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21107.2265625MB; mem (CPU total)=42115.3828125MB
INFO:root:[   20] Training loss: 0.91956070, Validation loss: 0.92221855, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21145.32421875MB; mem (CPU total)=42191.38671875MB
INFO:root:[   21] Training loss: 0.91803525, Validation loss: 0.92080517, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21183.41796875MB; mem (CPU total)=42268.28125MB
INFO:root:[   22] Training loss: 0.91619302, Validation loss: 0.91846232, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21221.51171875MB; mem (CPU total)=42344.3203125MB
INFO:root:[   23] Training loss: 0.91468099, Validation loss: 0.91787303, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21259.609375MB; mem (CPU total)=42420.58203125MB
INFO:root:[   24] Training loss: 0.91284565, Validation loss: 0.91584595, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21297.703125MB; mem (CPU total)=42496.2109375MB
INFO:root:[   25] Training loss: 0.91127933, Validation loss: 0.91533447, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21335.796875MB; mem (CPU total)=42572.45703125MB
INFO:root:[   26] Training loss: 0.90984261, Validation loss: 0.91378200, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21373.89453125MB; mem (CPU total)=42648.9921875MB
INFO:root:[   27] Training loss: 0.90849089, Validation loss: 0.91146092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21411.98828125MB; mem (CPU total)=42725.05859375MB
INFO:root:[   28] Training loss: 0.90721862, Validation loss: 0.91142427, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21450.078125MB; mem (CPU total)=42801.14453125MB
INFO:root:[   29] Training loss: 0.90589476, Validation loss: 0.91020423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21488.17578125MB; mem (CPU total)=42877.6953125MB
INFO:root:[   30] Training loss: 0.90482695, Validation loss: 0.91015450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21526.2734375MB; mem (CPU total)=42953.765625MB
INFO:root:[   31] Training loss: 0.90364250, Validation loss: 0.90877205, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21564.3671875MB; mem (CPU total)=43030.30078125MB
INFO:root:[   32] Training loss: 0.90249719, Validation loss: 0.90804702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21602.4609375MB; mem (CPU total)=43106.29296875MB
INFO:root:[   33] Training loss: 0.90148957, Validation loss: 0.90645360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21640.55859375MB; mem (CPU total)=43182.3046875MB
INFO:root:[   34] Training loss: 0.90079940, Validation loss: 0.90585199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21678.65234375MB; mem (CPU total)=43259.33203125MB
INFO:root:[   35] Training loss: 0.89941948, Validation loss: 0.90523839, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21716.74609375MB; mem (CPU total)=43335.34375MB
INFO:root:[   36] Training loss: 0.89872145, Validation loss: 0.90487596, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21754.84375MB; mem (CPU total)=43411.6328125MB
INFO:root:[   37] Training loss: 0.89757211, Validation loss: 0.90344299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21792.94140625MB; mem (CPU total)=43488.65625MB
INFO:root:[   38] Training loss: 0.89662127, Validation loss: 0.90313892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21831.03515625MB; mem (CPU total)=43564.81640625MB
INFO:root:[   39] Training loss: 0.89581426, Validation loss: 0.90189941, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21869.12890625MB; mem (CPU total)=43641.31640625MB
INFO:root:[   40] Training loss: 0.89509101, Validation loss: 0.90119983, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21907.2265625MB; mem (CPU total)=43717.5703125MB
INFO:root:[   41] Training loss: 0.89431979, Validation loss: 0.90106217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21945.3203125MB; mem (CPU total)=43793.08203125MB
INFO:root:[   42] Training loss: 0.89307664, Validation loss: 0.90081000, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21983.4140625MB; mem (CPU total)=43870.58984375MB
INFO:root:[   43] Training loss: 0.89232523, Validation loss: 0.89925271, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22021.515625MB; mem (CPU total)=43946.87890625MB
INFO:root:[   44] Training loss: 0.89181931, Validation loss: 0.89869362, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22059.609375MB; mem (CPU total)=44023.05859375MB
INFO:root:[   45] Training loss: 0.89080934, Validation loss: 0.89825662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22097.70703125MB; mem (CPU total)=44099.34765625MB
INFO:root:[   46] Training loss: 0.89039698, Validation loss: 0.89847974, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22135.80078125MB; mem (CPU total)=44175.63671875MB
INFO:root:[   47] Training loss: 0.88946368, Validation loss: 0.89719071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22173.8984375MB; mem (CPU total)=44251.6171875MB
INFO:root:[   48] Training loss: 0.88854359, Validation loss: 0.89684051, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22211.9921875MB; mem (CPU total)=44328.65625MB
INFO:root:[   49] Training loss: 0.88785116, Validation loss: 0.89536890, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22250.0859375MB; mem (CPU total)=44406.19921875MB
INFO:root:[   50] Training loss: 0.88759639, Validation loss: 0.89577922, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22288.18359375MB; mem (CPU total)=44482.26171875MB
INFO:root:[   51] Training loss: 0.88688574, Validation loss: 0.89573696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22326.27734375MB; mem (CPU total)=44559.3125MB
INFO:root:[   52] Training loss: 0.88586753, Validation loss: 0.89453733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22364.37109375MB; mem (CPU total)=44635.14453125MB
INFO:root:[   53] Training loss: 0.88559511, Validation loss: 0.89517602, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22402.46875MB; mem (CPU total)=44711.45703125MB
INFO:root:[   54] Training loss: 0.88456190, Validation loss: 0.89486765, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22440.56640625MB; mem (CPU total)=44787.9453125MB
INFO:root:[   55] Training loss: 0.88441564, Validation loss: 0.89471804, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22478.66015625MB; mem (CPU total)=44864.0078125MB
INFO:root:[   56] Training loss: 0.88356752, Validation loss: 0.89414878, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22516.75390625MB; mem (CPU total)=44940.56640625MB
INFO:root:[   57] Training loss: 0.88313398, Validation loss: 0.89297320, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22554.8515625MB; mem (CPU total)=45017.40234375MB
INFO:root:[   58] Training loss: 0.88265099, Validation loss: 0.89390481, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22592.9453125MB; mem (CPU total)=45093.98828125MB
INFO:root:[   59] Training loss: 0.88209777, Validation loss: 0.89309802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22631.0390625MB; mem (CPU total)=45170.26171875MB
INFO:root:[   60] Training loss: 0.88158791, Validation loss: 0.89195461, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22669.13671875MB; mem (CPU total)=45246.6484375MB
INFO:root:[   61] Training loss: 0.88089163, Validation loss: 0.89226761, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22707.234375MB; mem (CPU total)=45323.6640625MB
INFO:root:[   62] Training loss: 0.88063295, Validation loss: 0.89211812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22745.328125MB; mem (CPU total)=45399.9765625MB
INFO:root:[   63] Training loss: 0.88015250, Validation loss: 0.89231131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22783.421875MB; mem (CPU total)=45476.703125MB
INFO:root:[   64] Training loss: 0.87960860, Validation loss: 0.89121016, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22821.52734375MB; mem (CPU total)=45552.9453125MB
INFO:root:[   65] Training loss: 0.87908961, Validation loss: 0.89020798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22859.625MB; mem (CPU total)=45628.79296875MB
INFO:root:[   66] Training loss: 0.87858776, Validation loss: 0.88975057, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22897.72265625MB; mem (CPU total)=45705.59765625MB
INFO:root:[   67] Training loss: 0.87790609, Validation loss: 0.89079876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22935.8203125MB; mem (CPU total)=45781.6640625MB
INFO:root:[   68] Training loss: 0.87771357, Validation loss: 0.89036363, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22973.9140625MB; mem (CPU total)=45858.15234375MB
INFO:root:[   69] Training loss: 0.87728647, Validation loss: 0.88868763, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23012.0078125MB; mem (CPU total)=45934.63671875MB
INFO:root:[   70] Training loss: 0.87673012, Validation loss: 0.88994103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23050.109375MB; mem (CPU total)=46010.203125MB
INFO:root:[   71] Training loss: 0.87607858, Validation loss: 0.89002666, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23088.203125MB; mem (CPU total)=46086.23828125MB
INFO:root:[   72] Training loss: 0.87600538, Validation loss: 0.88938281, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23126.296875MB; mem (CPU total)=46163.234375MB
INFO:root:[   73] Training loss: 0.87547268, Validation loss: 0.88814978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23164.390625MB; mem (CPU total)=46238.921875MB
INFO:root:[   74] Training loss: 0.87508769, Validation loss: 0.88945948, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23202.48828125MB; mem (CPU total)=46314.98046875MB
INFO:root:[   75] Training loss: 0.87450922, Validation loss: 0.88779130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23240.58203125MB; mem (CPU total)=46391.015625MB
INFO:root:[   76] Training loss: 0.87422103, Validation loss: 0.88958641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23278.67578125MB; mem (CPU total)=46466.84765625MB
INFO:root:[   77] Training loss: 0.87370125, Validation loss: 0.88824005, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23316.77734375MB; mem (CPU total)=46542.66796875MB
INFO:root:[   78] Training loss: 0.87348437, Validation loss: 0.88780910, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23354.87109375MB; mem (CPU total)=46620.015625MB
INFO:root:[   79] Training loss: 0.87327566, Validation loss: 0.88803461, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23392.9609375MB; mem (CPU total)=46696.44921875MB
INFO:root:[   80] Training loss: 0.87261428, Validation loss: 0.88844950, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23431.05859375MB; mem (CPU total)=46773.09765625MB
INFO:root:[   81] Training loss: 0.87230559, Validation loss: 0.88586436, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23469.15625MB; mem (CPU total)=46849.01171875MB
INFO:root:[   82] Training loss: 0.87192289, Validation loss: 0.88721500, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23507.25MB; mem (CPU total)=46925.32421875MB
INFO:root:[   83] Training loss: 0.87148808, Validation loss: 0.88668350, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23545.34375MB; mem (CPU total)=47001.63671875MB
INFO:root:[   84] Training loss: 0.87135010, Validation loss: 0.88676352, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23583.44140625MB; mem (CPU total)=47078.484375MB
INFO:root:[   85] Training loss: 0.87104767, Validation loss: 0.88672426, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23621.53515625MB; mem (CPU total)=47154.40234375MB
INFO:root:[   86] Training loss: 0.87036209, Validation loss: 0.88618859, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23659.6328125MB; mem (CPU total)=47230.23828125MB
INFO:root:[   87] Training loss: 0.87008536, Validation loss: 0.88744027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23697.73046875MB; mem (CPU total)=47306.55078125MB
INFO:root:[   88] Training loss: 0.86982837, Validation loss: 0.88601268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23735.82421875MB; mem (CPU total)=47382.86328125MB
INFO:root:[   89] Training loss: 0.86950247, Validation loss: 0.88621391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23773.91796875MB; mem (CPU total)=47459.27734375MB
INFO:root:[   90] Training loss: 0.86904135, Validation loss: 0.88623930, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23812.01171875MB; mem (CPU total)=47536.0078125MB
INFO:root:[   91] Training loss: 0.86883858, Validation loss: 0.88538911, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23850.109375MB; mem (CPU total)=47611.875MB
INFO:root:[   92] Training loss: 0.86849180, Validation loss: 0.88677705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23888.203125MB; mem (CPU total)=47688.43359375MB
INFO:root:[   93] Training loss: 0.86801169, Validation loss: 0.88692742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23926.296875MB; mem (CPU total)=47764.7421875MB
INFO:root:[   94] Training loss: 0.86798620, Validation loss: 0.88542796, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23964.39453125MB; mem (CPU total)=47840.80859375MB
INFO:root:[   95] Training loss: 0.86708577, Validation loss: 0.88558974, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24002.4921875MB; mem (CPU total)=47917.57421875MB
INFO:root:[   96] Training loss: 0.86731532, Validation loss: 0.88627828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24040.5859375MB; mem (CPU total)=47993.80859375MB
INFO:root:[   97] Training loss: 0.86705352, Validation loss: 0.88537895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24078.6796875MB; mem (CPU total)=48069.859375MB
INFO:root:[   98] Training loss: 0.86692797, Validation loss: 0.88526787, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24116.77734375MB; mem (CPU total)=48146.21484375MB
INFO:root:[   99] Training loss: 0.86630945, Validation loss: 0.88537358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24154.87109375MB; mem (CPU total)=48222.7890625MB
INFO:root:[  100] Training loss: 0.86608996, Validation loss: 0.88350677, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24192.96484375MB; mem (CPU total)=48297.828125MB
INFO:root:[  101] Training loss: 0.86587488, Validation loss: 0.88435280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24231.0625MB; mem (CPU total)=48360.5390625MB
INFO:root:[  102] Training loss: 0.86537459, Validation loss: 0.88478954, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24269.15625MB; mem (CPU total)=48449.58984375MB
INFO:root:[  103] Training loss: 0.86490505, Validation loss: 0.88533455, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24307.25390625MB; mem (CPU total)=48491.1640625MB
INFO:root:[  104] Training loss: 0.86463622, Validation loss: 0.88447502, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24345.3515625MB; mem (CPU total)=48566.08984375MB
INFO:root:[  105] Training loss: 0.86464951, Validation loss: 0.88453412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24383.4453125MB; mem (CPU total)=48641.4140625MB
INFO:root:[  106] Training loss: 0.86450877, Validation loss: 0.88462806, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24421.5390625MB; mem (CPU total)=48717.1796875MB
INFO:root:[  107] Training loss: 0.86429661, Validation loss: 0.88435271, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24459.6328125MB; mem (CPU total)=48793.73828125MB
INFO:root:[  108] Training loss: 0.86345916, Validation loss: 0.88480142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24497.73046875MB; mem (CPU total)=48870.05078125MB
INFO:root:[  109] Training loss: 0.86306586, Validation loss: 0.88354468, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24535.82421875MB; mem (CPU total)=48946.3125MB
INFO:root:[  110] Training loss: 0.86293449, Validation loss: 0.88350066, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24573.91796875MB; mem (CPU total)=49021.91015625MB
INFO:root:[  111] Training loss: 0.86286016, Validation loss: 0.88434632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24612.01953125MB; mem (CPU total)=49098.5MB
INFO:root:[  112] Training loss: 0.86262704, Validation loss: 0.88487449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24650.11328125MB; mem (CPU total)=49174.859375MB
INFO:root:[  113] Training loss: 0.86220681, Validation loss: 0.88394879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24688.20703125MB; mem (CPU total)=49251.171875MB
INFO:root:[  114] Training loss: 0.86193946, Validation loss: 0.88468664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24726.30078125MB; mem (CPU total)=49328.0078125MB
INFO:root:[  115] Training loss: 0.86183394, Validation loss: 0.88554531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24764.3984375MB; mem (CPU total)=49404.28515625MB
INFO:root:[  116] Training loss: 0.86138647, Validation loss: 0.88438988, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24802.4921875MB; mem (CPU total)=49480.34765625MB
INFO:root:[  117] Training loss: 0.86122148, Validation loss: 0.88459572, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24840.5859375MB; mem (CPU total)=49556.57421875MB
INFO:root:[  118] Training loss: 0.86100269, Validation loss: 0.88484087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24878.68359375MB; mem (CPU total)=49632.88671875MB
INFO:root:[  119] Training loss: 0.86088883, Validation loss: 0.88507623, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24916.77734375MB; mem (CPU total)=49709.09375MB
INFO:root:EP 119: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=24954.87109375MB; mem (CPU total)=49763.73828125MB
INFO:root:Training the model took 6966.66s.
INFO:root:Emptying the cuda cache took 0.022s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84287
INFO:root:EnergyScoreTrain: 0.73437
INFO:root:CRPSTrain: 0.58308
INFO:root:Gaussian NLLTrain: 139.99117
INFO:root:CoverageTrain: 0.36361
INFO:root:IntervalWidthTrain: 0.59659
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86603
INFO:root:EnergyScoreValidation: 0.75736
INFO:root:CRPSValidation: 0.60245
INFO:root:Gaussian NLLValidation: 141.46438
INFO:root:CoverageValidation: 0.35142
INFO:root:IntervalWidthValidation: 0.59423
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86735
INFO:root:EnergyScoreTest: 0.75864
INFO:root:CRPSTest: 0.60366
INFO:root:Gaussian NLLTest: 141.88366
INFO:root:CoverageTest: 0.35057
INFO:root:IntervalWidthTest: 0.59422
INFO:root:After validation: mem (CPU python)=25057.44140625MB; mem (CPU total)=50031.6640625MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=25057.44140625MB; mem (CPU total)=49978.640625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=25057.44140625MB; mem (CPU total)=49981.0859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=25057.44140625MB; mem (CPU total)=50003.4921875MB
INFO:root:[    1] Training loss: 1.02216903, Validation loss: 1.01762197, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25057.44140625MB; mem (CPU total)=50077.6484375MB
INFO:root:[    2] Training loss: 1.01638856, Validation loss: 1.01458777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25074.41015625MB; mem (CPU total)=50152.0546875MB
INFO:root:[    3] Training loss: 1.00836683, Validation loss: 1.00152630, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25112.50390625MB; mem (CPU total)=50226.8203125MB
INFO:root:[    4] Training loss: 0.99604681, Validation loss: 0.99227728, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25150.59765625MB; mem (CPU total)=50300.80859375MB
INFO:root:[    5] Training loss: 0.98736835, Validation loss: 0.98350311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25188.6953125MB; mem (CPU total)=50374.62890625MB
INFO:root:[    6] Training loss: 0.97906142, Validation loss: 0.97654097, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25226.7890625MB; mem (CPU total)=50448.82421875MB
INFO:root:[    7] Training loss: 0.97090899, Validation loss: 0.97033077, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25264.8828125MB; mem (CPU total)=50522.41796875MB
INFO:root:[    8] Training loss: 0.96334829, Validation loss: 0.96097040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25302.9765625MB; mem (CPU total)=50596.18359375MB
INFO:root:[    9] Training loss: 0.95683882, Validation loss: 0.95505568, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25341.078125MB; mem (CPU total)=50670.5859375MB
INFO:root:[   10] Training loss: 0.95105298, Validation loss: 0.94943516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25379.171875MB; mem (CPU total)=50745.17578125MB
INFO:root:[   11] Training loss: 0.94609159, Validation loss: 0.94559773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25417.265625MB; mem (CPU total)=50821.98046875MB
INFO:root:[   12] Training loss: 0.94164110, Validation loss: 0.94237349, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25455.36328125MB; mem (CPU total)=50897.77734375MB
INFO:root:[   13] Training loss: 0.93800141, Validation loss: 0.93898462, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25493.45703125MB; mem (CPU total)=50974.33203125MB
INFO:root:[   14] Training loss: 0.93461031, Validation loss: 0.93618011, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25531.55078125MB; mem (CPU total)=51051.0234375MB
INFO:root:[   15] Training loss: 0.93123885, Validation loss: 0.93160371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25569.64453125MB; mem (CPU total)=51127.08203125MB
INFO:root:[   16] Training loss: 0.92861480, Validation loss: 0.92911321, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25607.7421875MB; mem (CPU total)=51203.28515625MB
INFO:root:[   17] Training loss: 0.92601695, Validation loss: 0.92743114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25645.83984375MB; mem (CPU total)=51279.34765625MB
INFO:root:[   18] Training loss: 0.92363249, Validation loss: 0.92578014, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25683.93359375MB; mem (CPU total)=51354.9140625MB
INFO:root:[   19] Training loss: 0.92116764, Validation loss: 0.92194196, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25722.03125MB; mem (CPU total)=51432.0625MB
INFO:root:[   20] Training loss: 0.91921488, Validation loss: 0.92061257, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25760.125MB; mem (CPU total)=51508.39453125MB
INFO:root:[   21] Training loss: 0.91721804, Validation loss: 0.91882888, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25798.21875MB; mem (CPU total)=51585.5703125MB
INFO:root:[   22] Training loss: 0.91550392, Validation loss: 0.91681505, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25836.31640625MB; mem (CPU total)=51658.3828125MB
INFO:root:[   23] Training loss: 0.91345637, Validation loss: 0.91572106, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25874.41015625MB; mem (CPU total)=51730.41015625MB
INFO:root:[   24] Training loss: 0.91171892, Validation loss: 0.91472701, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25912.50390625MB; mem (CPU total)=51803.28515625MB
INFO:root:[   25] Training loss: 0.91034695, Validation loss: 0.91313385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25950.61328125MB; mem (CPU total)=51876.17578125MB
INFO:root:[   26] Training loss: 0.90881075, Validation loss: 0.91220364, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25988.7109375MB; mem (CPU total)=51949.05859375MB
INFO:root:[   27] Training loss: 0.90741884, Validation loss: 0.91123641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26026.8046875MB; mem (CPU total)=52021.1640625MB
INFO:root:[   28] Training loss: 0.90593870, Validation loss: 0.90856629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26064.8984375MB; mem (CPU total)=52093.62890625MB
INFO:root:[   29] Training loss: 0.90483371, Validation loss: 0.90859958, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26102.99609375MB; mem (CPU total)=52166.05078125MB
INFO:root:[   30] Training loss: 0.90322509, Validation loss: 0.90726902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26141.08984375MB; mem (CPU total)=52238.6484375MB
INFO:root:[   31] Training loss: 0.90215707, Validation loss: 0.90654538, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26179.18359375MB; mem (CPU total)=52311.76953125MB
INFO:root:[   32] Training loss: 0.90072318, Validation loss: 0.90450586, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26217.27734375MB; mem (CPU total)=52386.55078125MB
INFO:root:[   33] Training loss: 0.89964216, Validation loss: 0.90409025, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26255.37890625MB; mem (CPU total)=52462.80859375MB
INFO:root:[   34] Training loss: 0.89818259, Validation loss: 0.90377820, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26293.47265625MB; mem (CPU total)=52540.0859375MB
INFO:root:[   35] Training loss: 0.89750037, Validation loss: 0.90247654, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26331.56640625MB; mem (CPU total)=52616.26171875MB
INFO:root:[   36] Training loss: 0.89640066, Validation loss: 0.90175586, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26369.6640625MB; mem (CPU total)=52692.1953125MB
INFO:root:[   37] Training loss: 0.89570275, Validation loss: 0.90107995, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26407.7578125MB; mem (CPU total)=52768.15234375MB
INFO:root:[   38] Training loss: 0.89446243, Validation loss: 0.90097688, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26445.8515625MB; mem (CPU total)=52845.2109375MB
INFO:root:[   39] Training loss: 0.89383541, Validation loss: 0.89985775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26483.94921875MB; mem (CPU total)=52921.5625MB
INFO:root:[   40] Training loss: 0.89275724, Validation loss: 0.89831223, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26522.04296875MB; mem (CPU total)=52997.62109375MB
INFO:root:[   41] Training loss: 0.89177991, Validation loss: 0.89759506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26560.140625MB; mem (CPU total)=53073.90234375MB
INFO:root:[   42] Training loss: 0.89078183, Validation loss: 0.89701017, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26598.234375MB; mem (CPU total)=53147.73046875MB
INFO:root:[   43] Training loss: 0.89015524, Validation loss: 0.89715079, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26636.33203125MB; mem (CPU total)=53219.140625MB
INFO:root:[   44] Training loss: 0.88933298, Validation loss: 0.89604627, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26674.42578125MB; mem (CPU total)=53292.4765625MB
INFO:root:[   45] Training loss: 0.88869634, Validation loss: 0.89527906, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26712.51953125MB; mem (CPU total)=53365.60546875MB
INFO:root:[   46] Training loss: 0.88785912, Validation loss: 0.89545147, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26750.6171875MB; mem (CPU total)=53437.7109375MB
INFO:root:[   47] Training loss: 0.88704145, Validation loss: 0.89444079, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26788.71484375MB; mem (CPU total)=53510.30859375MB
INFO:root:[   48] Training loss: 0.88645259, Validation loss: 0.89442539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26826.80859375MB; mem (CPU total)=53582.28515625MB
INFO:root:[   49] Training loss: 0.88550226, Validation loss: 0.89478676, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26864.90234375MB; mem (CPU total)=53654.3828125MB
INFO:root:[   50] Training loss: 0.88477526, Validation loss: 0.89238983, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26903.0MB; mem (CPU total)=53727.44140625MB
INFO:root:[   51] Training loss: 0.88409773, Validation loss: 0.89241054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26941.09375MB; mem (CPU total)=53800.0859375MB
INFO:root:[   52] Training loss: 0.88331207, Validation loss: 0.89249932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26979.1875MB; mem (CPU total)=53875.359375MB
INFO:root:[   53] Training loss: 0.88305638, Validation loss: 0.89154485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27017.28515625MB; mem (CPU total)=53951.6640625MB
INFO:root:[   54] Training loss: 0.88196372, Validation loss: 0.89091988, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27055.37890625MB; mem (CPU total)=54027.83203125MB
INFO:root:[   55] Training loss: 0.88160891, Validation loss: 0.88983912, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27093.4765625MB; mem (CPU total)=54104.58203125MB
INFO:root:[   56] Training loss: 0.88124947, Validation loss: 0.89104794, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27131.5703125MB; mem (CPU total)=54181.1171875MB
INFO:root:[   57] Training loss: 0.88037403, Validation loss: 0.89019172, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27169.66796875MB; mem (CPU total)=54256.9140625MB
INFO:root:[   58] Training loss: 0.87973467, Validation loss: 0.88972385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27207.76171875MB; mem (CPU total)=54333.54296875MB
INFO:root:[   59] Training loss: 0.87914380, Validation loss: 0.89019026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27245.85546875MB; mem (CPU total)=54409.76171875MB
INFO:root:[   60] Training loss: 0.87862351, Validation loss: 0.88892144, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27283.953125MB; mem (CPU total)=54486.05078125MB
INFO:root:[   61] Training loss: 0.87767973, Validation loss: 0.88773692, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27322.046875MB; mem (CPU total)=54563.11328125MB
INFO:root:[   62] Training loss: 0.87748013, Validation loss: 0.88809224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27360.140625MB; mem (CPU total)=54637.92578125MB
INFO:root:[   63] Training loss: 0.87653642, Validation loss: 0.88771638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27398.2421875MB; mem (CPU total)=54709.86328125MB
INFO:root:[   64] Training loss: 0.87645927, Validation loss: 0.88775470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27436.33203125MB; mem (CPU total)=54781.9609375MB
INFO:root:[   65] Training loss: 0.87584872, Validation loss: 0.88725589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27474.4296875MB; mem (CPU total)=54850.7421875MB
INFO:root:[   66] Training loss: 0.87505101, Validation loss: 0.88617217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27512.5234375MB; mem (CPU total)=54941.625MB
INFO:root:[   67] Training loss: 0.87474807, Validation loss: 0.88637318, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27550.6171875MB; mem (CPU total)=54980.27734375MB
INFO:root:[   68] Training loss: 0.87454842, Validation loss: 0.88647743, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27588.71484375MB; mem (CPU total)=55056.1953125MB
INFO:root:[   69] Training loss: 0.87387901, Validation loss: 0.88615040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27626.80859375MB; mem (CPU total)=55132.71484375MB
INFO:root:[   70] Training loss: 0.87339438, Validation loss: 0.88543154, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27664.90625MB; mem (CPU total)=55209.25MB
INFO:root:[   71] Training loss: 0.87278418, Validation loss: 0.88687452, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27703.0MB; mem (CPU total)=55285.77734375MB
INFO:root:[   72] Training loss: 0.87230165, Validation loss: 0.88479553, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27741.09375MB; mem (CPU total)=55362.14453125MB
INFO:root:[   73] Training loss: 0.87171222, Validation loss: 0.88358529, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27779.1953125MB; mem (CPU total)=55437.84765625MB
INFO:root:[   74] Training loss: 0.87177173, Validation loss: 0.88562685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27817.2890625MB; mem (CPU total)=55514.90234375MB
INFO:root:[   75] Training loss: 0.87097043, Validation loss: 0.88417730, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27855.3828125MB; mem (CPU total)=55591.2421875MB
INFO:root:[   76] Training loss: 0.87072529, Validation loss: 0.88375166, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27893.4765625MB; mem (CPU total)=55667.8125MB
INFO:root:[   77] Training loss: 0.87026243, Validation loss: 0.88380431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27931.57421875MB; mem (CPU total)=55743.71875MB
INFO:root:[   78] Training loss: 0.86953336, Validation loss: 0.88370598, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27969.66796875MB; mem (CPU total)=55819.54296875MB
INFO:root:[   79] Training loss: 0.86929379, Validation loss: 0.88487438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28007.76171875MB; mem (CPU total)=55894.81640625MB
INFO:root:[   80] Training loss: 0.86889405, Validation loss: 0.88362864, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28045.859375MB; mem (CPU total)=55967.66015625MB
INFO:root:[   81] Training loss: 0.86841978, Validation loss: 0.88279536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28083.953125MB; mem (CPU total)=56040.046875MB
INFO:root:[   82] Training loss: 0.86809282, Validation loss: 0.88341863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28122.046875MB; mem (CPU total)=56113.9296875MB
INFO:root:[   83] Training loss: 0.86771872, Validation loss: 0.88227121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28160.14453125MB; mem (CPU total)=56186.51953125MB
INFO:root:[   84] Training loss: 0.86717297, Validation loss: 0.88223275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28198.2421875MB; mem (CPU total)=56259.78125MB
INFO:root:[   85] Training loss: 0.86708941, Validation loss: 0.88268278, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28236.3359375MB; mem (CPU total)=56333.10546875MB
INFO:root:[   86] Training loss: 0.86639479, Validation loss: 0.88306719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28274.4296875MB; mem (CPU total)=56406.1953125MB
INFO:root:[   87] Training loss: 0.86633847, Validation loss: 0.88200183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28312.52734375MB; mem (CPU total)=56479.79296875MB
INFO:root:[   88] Training loss: 0.86576773, Validation loss: 0.88115495, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28350.62109375MB; mem (CPU total)=56553.16015625MB
INFO:root:[   89] Training loss: 0.86544868, Validation loss: 0.88032883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28388.71875MB; mem (CPU total)=56626.25MB
INFO:root:[   90] Training loss: 0.86502329, Validation loss: 0.88053862, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28426.81640625MB; mem (CPU total)=56699.3046875MB
INFO:root:[   91] Training loss: 0.86499896, Validation loss: 0.88158299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28464.9140625MB; mem (CPU total)=56774.296875MB
INFO:root:[   92] Training loss: 0.86423144, Validation loss: 0.88030295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28503.0078125MB; mem (CPU total)=56850.37890625MB
INFO:root:[   93] Training loss: 0.86393322, Validation loss: 0.88127143, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28541.1015625MB; mem (CPU total)=56926.80859375MB
INFO:root:[   94] Training loss: 0.86359251, Validation loss: 0.88024925, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28579.19921875MB; mem (CPU total)=57002.8828125MB
INFO:root:[   95] Training loss: 0.86340374, Validation loss: 0.88026267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28617.41015625MB; mem (CPU total)=57079.35546875MB
INFO:root:[   96] Training loss: 0.86280614, Validation loss: 0.88087530, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28655.50390625MB; mem (CPU total)=57155.640625MB
INFO:root:[   97] Training loss: 0.86280573, Validation loss: 0.87990120, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28693.60546875MB; mem (CPU total)=57231.9140625MB
INFO:root:[   98] Training loss: 0.86219706, Validation loss: 0.88146869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28731.69921875MB; mem (CPU total)=57308.6640625MB
INFO:root:[   99] Training loss: 0.86175960, Validation loss: 0.87951876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28769.7890625MB; mem (CPU total)=57384.73828125MB
INFO:root:[  100] Training loss: 0.86132975, Validation loss: 0.87978476, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28807.88671875MB; mem (CPU total)=57461.54296875MB
INFO:root:[  101] Training loss: 0.86158684, Validation loss: 0.87939918, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28845.984375MB; mem (CPU total)=57537.48046875MB
INFO:root:[  102] Training loss: 0.86080082, Validation loss: 0.88024624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28884.078125MB; mem (CPU total)=57613.73828125MB
INFO:root:[  103] Training loss: 0.86067095, Validation loss: 0.88019420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28922.171875MB; mem (CPU total)=57690.51953125MB
INFO:root:[  104] Training loss: 0.86019382, Validation loss: 0.88035593, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28960.26953125MB; mem (CPU total)=57766.33203125MB
INFO:root:[  105] Training loss: 0.86010822, Validation loss: 0.87852318, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28998.36328125MB; mem (CPU total)=57840.828125MB
INFO:root:[  106] Training loss: 0.85956904, Validation loss: 0.88164370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29036.45703125MB; mem (CPU total)=57914.12109375MB
INFO:root:[  107] Training loss: 0.85925139, Validation loss: 0.87906968, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29074.55859375MB; mem (CPU total)=57986.96484375MB
INFO:root:[  108] Training loss: 0.85934484, Validation loss: 0.87876669, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29112.65234375MB; mem (CPU total)=58060.30078125MB
INFO:root:[  109] Training loss: 0.85876605, Validation loss: 0.87915579, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29150.74609375MB; mem (CPU total)=58133.640625MB
INFO:root:[  110] Training loss: 0.85859188, Validation loss: 0.87904812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29188.83984375MB; mem (CPU total)=58205.93359375MB
INFO:root:[  111] Training loss: 0.85812602, Validation loss: 0.87885189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29226.9375MB; mem (CPU total)=58279.13671875MB
INFO:root:[  112] Training loss: 0.85797549, Validation loss: 0.87937781, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29265.03125MB; mem (CPU total)=58353.2421875MB
INFO:root:[  113] Training loss: 0.85742970, Validation loss: 0.87870553, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29303.12890625MB; mem (CPU total)=58425.50390625MB
INFO:root:[  114] Training loss: 0.85707858, Validation loss: 0.87925559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29341.22265625MB; mem (CPU total)=58498.59765625MB
INFO:root:EP 114: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=29379.3203125MB; mem (CPU total)=58568.48046875MB
INFO:root:Training the model took 7217.097s.
INFO:root:Emptying the cuda cache took 0.024s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83987
INFO:root:EnergyScoreTrain: 0.73292
INFO:root:CRPSTrain: 0.5797
INFO:root:Gaussian NLLTrain: 120.66178
INFO:root:CoverageTrain: 0.36645
INFO:root:IntervalWidthTrain: 0.58477
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86134
INFO:root:EnergyScoreValidation: 0.75404
INFO:root:CRPSValidation: 0.59755
INFO:root:Gaussian NLLValidation: 121.66363
INFO:root:CoverageValidation: 0.35536
INFO:root:IntervalWidthValidation: 0.58422
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86302
INFO:root:EnergyScoreTest: 0.75586
INFO:root:CRPSTest: 0.59932
INFO:root:Gaussian NLLTest: 122.03492
INFO:root:CoverageTest: 0.35364
INFO:root:IntervalWidthTest: 0.58261
INFO:root:After validation: mem (CPU python)=29481.68359375MB; mem (CPU total)=58810.17578125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=29481.68359375MB; mem (CPU total)=58761.671875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=29481.68359375MB; mem (CPU total)=58764.609375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=29481.68359375MB; mem (CPU total)=58788.71875MB
INFO:root:[    1] Training loss: 1.02169841, Validation loss: 1.01780731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29481.68359375MB; mem (CPU total)=58862.625MB
INFO:root:[    2] Training loss: 1.01570084, Validation loss: 1.01230291, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29498.71484375MB; mem (CPU total)=58934.69140625MB
INFO:root:[    3] Training loss: 1.00472048, Validation loss: 0.99794772, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29536.81640625MB; mem (CPU total)=59007.03515625MB
INFO:root:[    4] Training loss: 0.98987524, Validation loss: 0.98308284, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29574.91796875MB; mem (CPU total)=59077.78515625MB
INFO:root:[    5] Training loss: 0.97632520, Validation loss: 0.97153030, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29613.01171875MB; mem (CPU total)=59149.140625MB
INFO:root:[    6] Training loss: 0.96553122, Validation loss: 0.96111708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29651.10546875MB; mem (CPU total)=59221.953125MB
INFO:root:[    7] Training loss: 0.95660702, Validation loss: 0.95425673, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29689.203125MB; mem (CPU total)=59297.99609375MB
INFO:root:[    8] Training loss: 0.94938654, Validation loss: 0.94760093, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29727.296875MB; mem (CPU total)=59374.45703125MB
INFO:root:[    9] Training loss: 0.94326622, Validation loss: 0.94233118, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29765.390625MB; mem (CPU total)=59450.484375MB
INFO:root:[   10] Training loss: 0.93848085, Validation loss: 0.93805118, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29803.48828125MB; mem (CPU total)=59526.7734375MB
INFO:root:[   11] Training loss: 0.93408011, Validation loss: 0.93367991, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29841.69921875MB; mem (CPU total)=59603.09375MB
INFO:root:[   12] Training loss: 0.93021827, Validation loss: 0.93015629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29879.79296875MB; mem (CPU total)=59679.59765625MB
INFO:root:[   13] Training loss: 0.92688511, Validation loss: 0.92659328, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29917.89453125MB; mem (CPU total)=59755.60546875MB
INFO:root:[   14] Training loss: 0.92380303, Validation loss: 0.92419639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29955.98828125MB; mem (CPU total)=59831.6796875MB
INFO:root:[   15] Training loss: 0.92098988, Validation loss: 0.92290619, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29994.08203125MB; mem (CPU total)=59908.14453125MB
INFO:root:[   16] Training loss: 0.91853032, Validation loss: 0.91889811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30032.17578125MB; mem (CPU total)=59984.7109375MB
INFO:root:[   17] Training loss: 0.91602671, Validation loss: 0.91721705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30070.2734375MB; mem (CPU total)=60061.265625MB
INFO:root:[   18] Training loss: 0.91374533, Validation loss: 0.91542230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30108.3671875MB; mem (CPU total)=60135.32421875MB
INFO:root:[   19] Training loss: 0.91171045, Validation loss: 0.91389552, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30146.4609375MB; mem (CPU total)=60208.3046875MB
INFO:root:[   20] Training loss: 0.90975565, Validation loss: 0.91240942, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30184.55859375MB; mem (CPU total)=60281.1484375MB
INFO:root:[   21] Training loss: 0.90756619, Validation loss: 0.91012218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30222.65625MB; mem (CPU total)=60354.515625MB
INFO:root:[   22] Training loss: 0.90605131, Validation loss: 0.90958523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30260.75MB; mem (CPU total)=60426.11328125MB
INFO:root:[   23] Training loss: 0.90454779, Validation loss: 0.90788606, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30298.84375MB; mem (CPU total)=60497.48046875MB
INFO:root:[   24] Training loss: 0.90276284, Validation loss: 0.90626256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30336.94140625MB; mem (CPU total)=60568.66796875MB
INFO:root:[   25] Training loss: 0.90131633, Validation loss: 0.90579423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30375.03515625MB; mem (CPU total)=60641.78515625MB
INFO:root:[   26] Training loss: 0.90021682, Validation loss: 0.90385682, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30413.12890625MB; mem (CPU total)=60714.64453125MB
INFO:root:[   27] Training loss: 0.89875193, Validation loss: 0.90258612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30451.2265625MB; mem (CPU total)=60787.43359375MB
INFO:root:[   28] Training loss: 0.89720054, Validation loss: 0.90200477, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30489.3203125MB; mem (CPU total)=60861.5859375MB
INFO:root:[   29] Training loss: 0.89621791, Validation loss: 0.90152093, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30527.41796875MB; mem (CPU total)=60937.578125MB
INFO:root:[   30] Training loss: 0.89502385, Validation loss: 0.89943496, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30565.515625MB; mem (CPU total)=61013.67578125MB
INFO:root:[   31] Training loss: 0.89368146, Validation loss: 0.89933964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30603.609375MB; mem (CPU total)=61089.9765625MB
INFO:root:[   32] Training loss: 0.89256117, Validation loss: 0.89725686, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30641.703125MB; mem (CPU total)=61166.5078125MB
INFO:root:[   33] Training loss: 0.89171915, Validation loss: 0.89808892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30679.796875MB; mem (CPU total)=61242.8203125MB
INFO:root:[   34] Training loss: 0.89067809, Validation loss: 0.89654366, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30717.89453125MB; mem (CPU total)=61326.5234375MB
INFO:root:[   35] Training loss: 0.88966571, Validation loss: 0.89601069, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30755.98828125MB; mem (CPU total)=61394.7890625MB
INFO:root:[   36] Training loss: 0.88848428, Validation loss: 0.89329021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30794.08203125MB; mem (CPU total)=61469.265625MB
INFO:root:[   37] Training loss: 0.88766436, Validation loss: 0.89333429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30832.18359375MB; mem (CPU total)=61507.3125MB
INFO:root:[   38] Training loss: 0.88677373, Validation loss: 0.89298782, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30870.27734375MB; mem (CPU total)=61545.484375MB
INFO:root:[   39] Training loss: 0.88579864, Validation loss: 0.89308044, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30908.37109375MB; mem (CPU total)=30833.98828125MB
INFO:root:[   40] Training loss: 0.88472414, Validation loss: 0.89108565, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30946.54296875MB; mem (CPU total)=30871.44140625MB
INFO:root:[   41] Training loss: 0.88408983, Validation loss: 0.89149815, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30984.640625MB; mem (CPU total)=30909.33984375MB
INFO:root:[   42] Training loss: 0.88299772, Validation loss: 0.89061385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31022.734375MB; mem (CPU total)=30947.453125MB
INFO:root:[   43] Training loss: 0.88245981, Validation loss: 0.88962915, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31060.828125MB; mem (CPU total)=30985.19921875MB
INFO:root:[   44] Training loss: 0.88160839, Validation loss: 0.88938657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31098.92578125MB; mem (CPU total)=31022.76171875MB
INFO:root:[   45] Training loss: 0.88080083, Validation loss: 0.88950566, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31137.0234375MB; mem (CPU total)=31061.1484375MB
INFO:root:[   46] Training loss: 0.88040167, Validation loss: 0.88807128, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31175.1171875MB; mem (CPU total)=31098.80078125MB
INFO:root:[   47] Training loss: 0.87917604, Validation loss: 0.88823314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31213.21875MB; mem (CPU total)=31136.71484375MB
INFO:root:[   48] Training loss: 0.87852327, Validation loss: 0.88658765, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31251.3125MB; mem (CPU total)=31174.515625MB
INFO:root:[   49] Training loss: 0.87782880, Validation loss: 0.88712415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31289.40625MB; mem (CPU total)=31212.64453125MB
INFO:root:[   50] Training loss: 0.87712275, Validation loss: 0.88570589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31327.5MB; mem (CPU total)=31251.03515625MB
INFO:root:[   51] Training loss: 0.87667161, Validation loss: 0.88664895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31365.59765625MB; mem (CPU total)=31289.1796875MB
INFO:root:[   52] Training loss: 0.87555080, Validation loss: 0.88516715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31403.69140625MB; mem (CPU total)=31327.546875MB
INFO:root:[   53] Training loss: 0.87520713, Validation loss: 0.88381450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31441.7890625MB; mem (CPU total)=31365.421875MB
INFO:root:[   54] Training loss: 0.87451111, Validation loss: 0.88572933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31479.88671875MB; mem (CPU total)=31403.40625MB
INFO:root:[   55] Training loss: 0.87384296, Validation loss: 0.88371123, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31517.98046875MB; mem (CPU total)=31441.51953125MB
INFO:root:[   56] Training loss: 0.87304785, Validation loss: 0.88391624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31556.07421875MB; mem (CPU total)=31479.578125MB
INFO:root:[   57] Training loss: 0.87256842, Validation loss: 0.88370382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31594.16796875MB; mem (CPU total)=31517.9375MB
INFO:root:[   58] Training loss: 0.87207280, Validation loss: 0.88266254, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31632.265625MB; mem (CPU total)=31556.07421875MB
INFO:root:[   59] Training loss: 0.87150060, Validation loss: 0.88314362, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31670.359375MB; mem (CPU total)=31594.1875MB
INFO:root:[   60] Training loss: 0.87128976, Validation loss: 0.88343258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31708.45703125MB; mem (CPU total)=31633.01171875MB
INFO:root:[   61] Training loss: 0.87025108, Validation loss: 0.88159182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31746.55078125MB; mem (CPU total)=31671.18359375MB
INFO:root:[   62] Training loss: 0.86975779, Validation loss: 0.88154450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31784.6484375MB; mem (CPU total)=31708.91796875MB
INFO:root:[   63] Training loss: 0.86903719, Validation loss: 0.88138542, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31822.7421875MB; mem (CPU total)=31746.84375MB
INFO:root:[   64] Training loss: 0.86878034, Validation loss: 0.88045000, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31860.83984375MB; mem (CPU total)=31784.93359375MB
INFO:root:[   65] Training loss: 0.86823171, Validation loss: 0.88256932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31898.93359375MB; mem (CPU total)=31823.00390625MB
INFO:root:[   66] Training loss: 0.86787857, Validation loss: 0.88076529, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31937.02734375MB; mem (CPU total)=31861.16015625MB
INFO:root:[   67] Training loss: 0.86736826, Validation loss: 0.87941683, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31975.12109375MB; mem (CPU total)=31899.1171875MB
INFO:root:[   68] Training loss: 0.86663272, Validation loss: 0.87918464, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32013.21875MB; mem (CPU total)=31937.046875MB
INFO:root:[   69] Training loss: 0.86568080, Validation loss: 0.87912390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32051.3125MB; mem (CPU total)=31975.58984375MB
INFO:root:[   70] Training loss: 0.86537849, Validation loss: 0.88019450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32089.41015625MB; mem (CPU total)=32013.75390625MB
INFO:root:[   71] Training loss: 0.86518872, Validation loss: 0.87899054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32127.5078125MB; mem (CPU total)=32052.41796875MB
INFO:root:[   72] Training loss: 0.86454966, Validation loss: 0.87881619, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32165.6015625MB; mem (CPU total)=32090.55859375MB
INFO:root:[   73] Training loss: 0.86417035, Validation loss: 0.87906144, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32203.6953125MB; mem (CPU total)=32128.484375MB
INFO:root:[   74] Training loss: 0.86344785, Validation loss: 0.87979896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32241.7890625MB; mem (CPU total)=32166.6484375MB
INFO:root:[   75] Training loss: 0.86314160, Validation loss: 0.87763691, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32279.88671875MB; mem (CPU total)=32204.54296875MB
INFO:root:[   76] Training loss: 0.86297938, Validation loss: 0.87754091, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32317.98046875MB; mem (CPU total)=32242.74609375MB
INFO:root:[   77] Training loss: 0.86199841, Validation loss: 0.87912547, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32356.07421875MB; mem (CPU total)=32282.32421875MB
INFO:root:[   78] Training loss: 0.86181149, Validation loss: 0.87780748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32394.17578125MB; mem (CPU total)=32320.48828125MB
INFO:root:[   79] Training loss: 0.86149701, Validation loss: 0.87726816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32432.26953125MB; mem (CPU total)=32358.62109375MB
INFO:root:[   80] Training loss: 0.86069954, Validation loss: 0.87696574, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32470.36328125MB; mem (CPU total)=32396.64453125MB
INFO:root:[   81] Training loss: 0.86040720, Validation loss: 0.87688625, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32508.4609375MB; mem (CPU total)=32433.83984375MB
INFO:root:[   82] Training loss: 0.86034755, Validation loss: 0.87571915, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32546.5546875MB; mem (CPU total)=32471.7578125MB
INFO:root:[   83] Training loss: 0.85973660, Validation loss: 0.87731163, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32584.6484375MB; mem (CPU total)=32509.92578125MB
INFO:root:[   84] Training loss: 0.85948164, Validation loss: 0.87614578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32622.7421875MB; mem (CPU total)=32547.8515625MB
INFO:root:[   85] Training loss: 0.85880231, Validation loss: 0.87623417, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32660.83984375MB; mem (CPU total)=32585.9921875MB
INFO:root:[   86] Training loss: 0.85830094, Validation loss: 0.87634527, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32698.9375MB; mem (CPU total)=32624.25MB
INFO:root:[   87] Training loss: 0.85793495, Validation loss: 0.87567413, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32737.03125MB; mem (CPU total)=32662.4140625MB
INFO:root:[   88] Training loss: 0.85736747, Validation loss: 0.87575542, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32775.12890625MB; mem (CPU total)=32700.33984375MB
INFO:root:[   89] Training loss: 0.85719512, Validation loss: 0.87561583, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32813.2265625MB; mem (CPU total)=32738.7890625MB
INFO:root:[   90] Training loss: 0.85696990, Validation loss: 0.87542309, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32851.3203125MB; mem (CPU total)=32776.953125MB
INFO:root:[   91] Training loss: 0.85634830, Validation loss: 0.87416156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32889.4140625MB; mem (CPU total)=32815.3359375MB
INFO:root:[   92] Training loss: 0.85619972, Validation loss: 0.87513692, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32927.51171875MB; mem (CPU total)=32853.47265625MB
INFO:root:[   93] Training loss: 0.85541752, Validation loss: 0.87487134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32965.60546875MB; mem (CPU total)=32891.1484375MB
INFO:root:[   94] Training loss: 0.85544886, Validation loss: 0.87611290, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33003.703125MB; mem (CPU total)=32929.0MB
INFO:root:[   95] Training loss: 0.85482662, Validation loss: 0.87592726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33041.796875MB; mem (CPU total)=32967.625MB
INFO:root:[   96] Training loss: 0.85460890, Validation loss: 0.87613044, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33079.89453125MB; mem (CPU total)=33005.796875MB
INFO:root:[   97] Training loss: 0.85479736, Validation loss: 0.87441178, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33117.98828125MB; mem (CPU total)=33043.96875MB
INFO:root:[   98] Training loss: 0.85393753, Validation loss: 0.87425455, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33156.0859375MB; mem (CPU total)=33082.140625MB
INFO:root:[   99] Training loss: 0.85372025, Validation loss: 0.87511554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33194.1796875MB; mem (CPU total)=33120.30859375MB
INFO:root:[  100] Training loss: 0.85318302, Validation loss: 0.87496636, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33232.2734375MB; mem (CPU total)=33158.48046875MB
INFO:root:EP 100: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=33270.328125MB; mem (CPU total)=33196.8828125MB
INFO:root:Training the model took 7019.497s.
INFO:root:Emptying the cuda cache took 0.026s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83546
INFO:root:EnergyScoreTrain: 0.72772
INFO:root:CRPSTrain: 0.57277
INFO:root:Gaussian NLLTrain: 87.10679
INFO:root:CoverageTrain: 0.37483
INFO:root:IntervalWidthTrain: 0.59995
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8565
INFO:root:EnergyScoreValidation: 0.74819
INFO:root:CRPSValidation: 0.58983
INFO:root:Gaussian NLLValidation: 87.9516
INFO:root:CoverageValidation: 0.36543
INFO:root:IntervalWidthValidation: 0.60062
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.85872
INFO:root:EnergyScoreTest: 0.7507
INFO:root:CRPSTest: 0.59224
INFO:root:Gaussian NLLTest: 88.20675
INFO:root:CoverageTest: 0.36226
INFO:root:IntervalWidthTest: 0.59825
INFO:root:After validation: mem (CPU python)=33343.27734375MB; mem (CPU total)=33270.1875MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=33343.27734375MB; mem (CPU total)=33270.203125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=33343.75390625MB; mem (CPU total)=33270.6953125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=33343.76171875MB; mem (CPU total)=33270.60546875MB
INFO:root:[    1] Training loss: 1.02234999, Validation loss: 1.01858390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33381.8515625MB; mem (CPU total)=33309.12109375MB
INFO:root:[    2] Training loss: 1.01675760, Validation loss: 1.01553122, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33419.9453125MB; mem (CPU total)=33346.80078125MB
INFO:root:[    3] Training loss: 1.01231943, Validation loss: 1.00670377, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33458.0390625MB; mem (CPU total)=33385.25MB
INFO:root:[    4] Training loss: 0.99888159, Validation loss: 0.99334308, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33496.13671875MB; mem (CPU total)=33423.68359375MB
INFO:root:[    5] Training loss: 0.98800670, Validation loss: 0.98509553, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33534.234375MB; mem (CPU total)=33461.83203125MB
INFO:root:[    6] Training loss: 0.97929777, Validation loss: 0.97582165, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33572.328125MB; mem (CPU total)=33499.73828125MB
INFO:root:[    7] Training loss: 0.97000180, Validation loss: 0.96657043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33610.421875MB; mem (CPU total)=33537.41015625MB
INFO:root:[    8] Training loss: 0.96181863, Validation loss: 0.95949427, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33648.51953125MB; mem (CPU total)=33575.61328125MB
INFO:root:[    9] Training loss: 0.95514520, Validation loss: 0.95444817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33686.61328125MB; mem (CPU total)=33614.03125MB
INFO:root:[   10] Training loss: 0.94929686, Validation loss: 0.94802085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33724.71484375MB; mem (CPU total)=33652.1640625MB
INFO:root:[   11] Training loss: 0.94421708, Validation loss: 0.94446421, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33762.80859375MB; mem (CPU total)=33690.5390625MB
INFO:root:[   12] Training loss: 0.93983488, Validation loss: 0.93991644, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33800.90625MB; mem (CPU total)=33728.46484375MB
INFO:root:[   13] Training loss: 0.93590699, Validation loss: 0.93511824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33839.0MB; mem (CPU total)=33766.421875MB
INFO:root:[   14] Training loss: 0.93257202, Validation loss: 0.93311493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33877.09765625MB; mem (CPU total)=33804.39453125MB
INFO:root:[   15] Training loss: 0.92964120, Validation loss: 0.93084766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33915.1953125MB; mem (CPU total)=33842.0625MB
INFO:root:[   16] Training loss: 0.92684559, Validation loss: 0.92828235, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33953.2890625MB; mem (CPU total)=33880.234375MB
INFO:root:[   17] Training loss: 0.92427837, Validation loss: 0.92624689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33991.3828125MB; mem (CPU total)=33918.3984375MB
INFO:root:[   18] Training loss: 0.92217922, Validation loss: 0.92311379, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34029.48046875MB; mem (CPU total)=33956.6015625MB
INFO:root:[   19] Training loss: 0.91998988, Validation loss: 0.92252565, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34067.57421875MB; mem (CPU total)=33994.51953125MB
INFO:root:[   20] Training loss: 0.91772382, Validation loss: 0.91921771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34105.671875MB; mem (CPU total)=34032.9375MB
INFO:root:[   21] Training loss: 0.91596347, Validation loss: 0.91854262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34143.765625MB; mem (CPU total)=34070.86328125MB
INFO:root:[   22] Training loss: 0.91446103, Validation loss: 0.91795462, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34181.86328125MB; mem (CPU total)=34109.2734375MB
INFO:root:[   23] Training loss: 0.91263338, Validation loss: 0.91614888, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34219.95703125MB; mem (CPU total)=34147.38671875MB
INFO:root:[   24] Training loss: 0.91100269, Validation loss: 0.91506455, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34258.05078125MB; mem (CPU total)=34185.0546875MB
INFO:root:[   25] Training loss: 0.90944461, Validation loss: 0.91324738, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34296.1484375MB; mem (CPU total)=34223.53515625MB
INFO:root:[   26] Training loss: 0.90776069, Validation loss: 0.91066326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34334.2421875MB; mem (CPU total)=34261.421875MB
INFO:root:[   27] Training loss: 0.90680385, Validation loss: 0.91035156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34372.3359375MB; mem (CPU total)=34299.5859375MB
INFO:root:[   28] Training loss: 0.90528746, Validation loss: 0.90938513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34410.4296875MB; mem (CPU total)=34337.96875MB
INFO:root:[   29] Training loss: 0.90421513, Validation loss: 0.90825421, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34448.53125MB; mem (CPU total)=34375.89453125MB
INFO:root:[   30] Training loss: 0.90266888, Validation loss: 0.90771948, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34486.625MB; mem (CPU total)=34414.33984375MB
INFO:root:[   31] Training loss: 0.90140661, Validation loss: 0.90678837, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34524.71875MB; mem (CPU total)=34452.37109375MB
INFO:root:[   32] Training loss: 0.90030650, Validation loss: 0.90613469, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34562.81640625MB; mem (CPU total)=34490.51953125MB
INFO:root:[   33] Training loss: 0.89949201, Validation loss: 0.90631174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34600.91015625MB; mem (CPU total)=34528.69140625MB
INFO:root:[   34] Training loss: 0.89820583, Validation loss: 0.90335311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34639.00390625MB; mem (CPU total)=34566.73046875MB
INFO:root:[   35] Training loss: 0.89709426, Validation loss: 0.90436180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34677.1015625MB; mem (CPU total)=34604.87109375MB
INFO:root:[   36] Training loss: 0.89625360, Validation loss: 0.90351439, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34715.1953125MB; mem (CPU total)=34643.45703125MB
INFO:root:[   37] Training loss: 0.89534255, Validation loss: 0.90301828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34753.29296875MB; mem (CPU total)=34681.6328125MB
INFO:root:[   38] Training loss: 0.89432063, Validation loss: 0.90135567, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34791.38671875MB; mem (CPU total)=34720.0234375MB
INFO:root:[   39] Training loss: 0.89345151, Validation loss: 0.90091964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34829.484375MB; mem (CPU total)=34757.7265625MB
INFO:root:[   40] Training loss: 0.89238753, Validation loss: 0.90038816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34867.578125MB; mem (CPU total)=34796.16796875MB
INFO:root:[   41] Training loss: 0.89187646, Validation loss: 0.89877579, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34905.671875MB; mem (CPU total)=34834.55859375MB
INFO:root:[   42] Training loss: 0.89089608, Validation loss: 0.89890396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34943.7734375MB; mem (CPU total)=34872.703125MB
INFO:root:[   43] Training loss: 0.89024956, Validation loss: 0.89803791, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34981.87109375MB; mem (CPU total)=34910.71875MB
INFO:root:[   44] Training loss: 0.88903392, Validation loss: 0.89680030, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35019.96484375MB; mem (CPU total)=34948.80078125MB
INFO:root:[   45] Training loss: 0.88845019, Validation loss: 0.89835196, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35058.05859375MB; mem (CPU total)=34986.9453125MB
INFO:root:[   46] Training loss: 0.88778719, Validation loss: 0.89734122, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35096.15625MB; mem (CPU total)=35024.84375MB
INFO:root:[   47] Training loss: 0.88704206, Validation loss: 0.89558258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35134.25MB; mem (CPU total)=35063.859375MB
INFO:root:[   48] Training loss: 0.88628720, Validation loss: 0.89481620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35172.34375MB; mem (CPU total)=35101.6328125MB
INFO:root:[   49] Training loss: 0.88582646, Validation loss: 0.89358301, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35210.4375MB; mem (CPU total)=35139.80859375MB
INFO:root:[   50] Training loss: 0.88494762, Validation loss: 0.89499771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35248.53515625MB; mem (CPU total)=35177.9453125MB
INFO:root:[   51] Training loss: 0.88475664, Validation loss: 0.89292670, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35286.62890625MB; mem (CPU total)=35216.08984375MB
INFO:root:[   52] Training loss: 0.88361544, Validation loss: 0.89290881, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35324.7265625MB; mem (CPU total)=35254.44921875MB
INFO:root:[   53] Training loss: 0.88316962, Validation loss: 0.89368297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35362.8203125MB; mem (CPU total)=35292.34765625MB
INFO:root:[   54] Training loss: 0.88250485, Validation loss: 0.89240726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35400.91796875MB; mem (CPU total)=35330.72265625MB
INFO:root:[   55] Training loss: 0.88189741, Validation loss: 0.89336937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35439.01171875MB; mem (CPU total)=35368.86328125MB
INFO:root:[   56] Training loss: 0.88149089, Validation loss: 0.89205558, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35477.109375MB; mem (CPU total)=35407.0546875MB
INFO:root:[   57] Training loss: 0.88083035, Validation loss: 0.89195801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35515.203125MB; mem (CPU total)=35445.4375MB
INFO:root:[   58] Training loss: 0.88018512, Validation loss: 0.89028224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35553.296875MB; mem (CPU total)=35483.58203125MB
INFO:root:[   59] Training loss: 0.87951786, Validation loss: 0.89032924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35591.39453125MB; mem (CPU total)=35520.734375MB
INFO:root:[   60] Training loss: 0.87938348, Validation loss: 0.89053714, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35629.4921875MB; mem (CPU total)=35558.6015625MB
INFO:root:[   61] Training loss: 0.87828289, Validation loss: 0.89003638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35667.5859375MB; mem (CPU total)=35596.7421875MB
INFO:root:[   62] Training loss: 0.87792628, Validation loss: 0.88981847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35705.6796875MB; mem (CPU total)=35634.91796875MB
INFO:root:[   63] Training loss: 0.87758984, Validation loss: 0.89016836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35743.77734375MB; mem (CPU total)=35673.30859375MB
INFO:root:[   64] Training loss: 0.87722177, Validation loss: 0.88918115, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35781.87109375MB; mem (CPU total)=35711.45703125MB
INFO:root:[   65] Training loss: 0.87645222, Validation loss: 0.88946783, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35819.96484375MB; mem (CPU total)=35749.31640625MB
INFO:root:[   66] Training loss: 0.87600834, Validation loss: 0.88927253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35858.0625MB; mem (CPU total)=35787.70703125MB
INFO:root:[   67] Training loss: 0.87538273, Validation loss: 0.88953886, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35896.15625MB; mem (CPU total)=35825.60546875MB
INFO:root:[   68] Training loss: 0.87501553, Validation loss: 0.88872999, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35934.25MB; mem (CPU total)=35863.74609375MB
INFO:root:[   69] Training loss: 0.87448896, Validation loss: 0.88857668, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35972.3515625MB; mem (CPU total)=35902.1640625MB
INFO:root:[   70] Training loss: 0.87430190, Validation loss: 0.88774308, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36010.4453125MB; mem (CPU total)=35940.33984375MB
INFO:root:[   71] Training loss: 0.87357547, Validation loss: 0.88700403, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36048.5390625MB; mem (CPU total)=35978.73046875MB
INFO:root:[   72] Training loss: 0.87314455, Validation loss: 0.88758873, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36086.6328125MB; mem (CPU total)=36017.1171875MB
INFO:root:[   73] Training loss: 0.87291429, Validation loss: 0.88576964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36124.73046875MB; mem (CPU total)=36055.00390625MB
INFO:root:[   74] Training loss: 0.87248524, Validation loss: 0.88675164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36162.82421875MB; mem (CPU total)=36093.36328125MB
INFO:root:[   75] Training loss: 0.87205202, Validation loss: 0.88687769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36200.91796875MB; mem (CPU total)=36131.2578125MB
INFO:root:[   76] Training loss: 0.87186313, Validation loss: 0.88675293, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36239.015625MB; mem (CPU total)=36169.30078125MB
INFO:root:[   77] Training loss: 0.87114231, Validation loss: 0.88780398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36277.109375MB; mem (CPU total)=36207.8671875MB
INFO:root:[   78] Training loss: 0.87080887, Validation loss: 0.88640448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36315.20703125MB; mem (CPU total)=36246.01171875MB
INFO:root:[   79] Training loss: 0.87016349, Validation loss: 0.88523161, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36353.30078125MB; mem (CPU total)=36284.15625MB
INFO:root:[   80] Training loss: 0.87001294, Validation loss: 0.88490887, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36391.3984375MB; mem (CPU total)=36321.9765625MB
INFO:root:[   81] Training loss: 0.86980326, Validation loss: 0.88617621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36429.4921875MB; mem (CPU total)=36360.140625MB
INFO:root:[   82] Training loss: 0.86918112, Validation loss: 0.88580753, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36467.5859375MB; mem (CPU total)=36398.28515625MB
INFO:root:[   83] Training loss: 0.86863108, Validation loss: 0.88437110, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36505.68359375MB; mem (CPU total)=36436.70703125MB
INFO:root:[   84] Training loss: 0.86822619, Validation loss: 0.88486052, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36543.77734375MB; mem (CPU total)=36475.125MB
INFO:root:[   85] Training loss: 0.86790234, Validation loss: 0.88450603, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36581.87109375MB; mem (CPU total)=36512.9921875MB
INFO:root:[   86] Training loss: 0.86771906, Validation loss: 0.88362863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36619.97265625MB; mem (CPU total)=36551.16015625MB
INFO:root:[   87] Training loss: 0.86743092, Validation loss: 0.88468371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36658.06640625MB; mem (CPU total)=36589.2734375MB
INFO:root:[   88] Training loss: 0.86688652, Validation loss: 0.88582202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36696.16015625MB; mem (CPU total)=36627.44140625MB
INFO:root:[   89] Training loss: 0.86668653, Validation loss: 0.88465049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36734.25390625MB; mem (CPU total)=36665.63671875MB
INFO:root:[   90] Training loss: 0.86630587, Validation loss: 0.88533142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36772.3515625MB; mem (CPU total)=36703.71875MB
INFO:root:[   91] Training loss: 0.86607824, Validation loss: 0.88583229, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36810.4453125MB; mem (CPU total)=36741.86328125MB
INFO:root:[   92] Training loss: 0.86562386, Validation loss: 0.88282317, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36848.5390625MB; mem (CPU total)=36780.0390625MB
INFO:root:[   93] Training loss: 0.86533840, Validation loss: 0.88306325, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36886.63671875MB; mem (CPU total)=36818.2109375MB
INFO:root:[   94] Training loss: 0.86495223, Validation loss: 0.88271579, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36924.73046875MB; mem (CPU total)=36856.35546875MB
INFO:root:[   95] Training loss: 0.86474126, Validation loss: 0.88405114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36962.82421875MB; mem (CPU total)=36894.5MB
INFO:root:[   96] Training loss: 0.86458300, Validation loss: 0.88457442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37000.921875MB; mem (CPU total)=36932.86328125MB
INFO:root:[   97] Training loss: 0.86402546, Validation loss: 0.88312546, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37039.01953125MB; mem (CPU total)=36971.24609375MB
INFO:root:[   98] Training loss: 0.86383171, Validation loss: 0.88306346, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37077.11328125MB; mem (CPU total)=37009.59765625MB
INFO:root:[   99] Training loss: 0.86356478, Validation loss: 0.88291100, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37115.20703125MB; mem (CPU total)=37047.98046875MB
INFO:root:[  100] Training loss: 0.86320683, Validation loss: 0.88457327, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37153.3046875MB; mem (CPU total)=37085.87890625MB
INFO:root:[  101] Training loss: 0.86298790, Validation loss: 0.88349735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37191.3984375MB; mem (CPU total)=37123.76953125MB
INFO:root:[  102] Training loss: 0.86269008, Validation loss: 0.88312310, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37229.4921875MB; mem (CPU total)=37162.15625MB
INFO:root:[  103] Training loss: 0.86218397, Validation loss: 0.88244982, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37267.59375MB; mem (CPU total)=37200.296875MB
INFO:root:[  104] Training loss: 0.86194915, Validation loss: 0.88365828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37305.6875MB; mem (CPU total)=37238.9765625MB
INFO:root:[  105] Training loss: 0.86198865, Validation loss: 0.88421729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37343.78125MB; mem (CPU total)=37277.10546875MB
INFO:root:[  106] Training loss: 0.86177593, Validation loss: 0.88315658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37381.875MB; mem (CPU total)=37315.00390625MB
INFO:root:[  107] Training loss: 0.86118193, Validation loss: 0.88401367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37419.97265625MB; mem (CPU total)=37353.1171875MB
INFO:root:[  108] Training loss: 0.86122124, Validation loss: 0.88406181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37458.06640625MB; mem (CPU total)=37391.1796875MB
INFO:root:[  109] Training loss: 0.86070593, Validation loss: 0.88392493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37496.16015625MB; mem (CPU total)=37429.56640625MB
INFO:root:[  110] Training loss: 0.86026402, Validation loss: 0.88438346, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37534.26171875MB; mem (CPU total)=37467.953125MB
INFO:root:[  111] Training loss: 0.86030105, Validation loss: 0.88229071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37572.3515625MB; mem (CPU total)=37505.9140625MB
INFO:root:[  112] Training loss: 0.85978277, Validation loss: 0.88283872, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37610.44921875MB; mem (CPU total)=37544.34375MB
INFO:root:[  113] Training loss: 0.85947694, Validation loss: 0.88337277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37648.54296875MB; mem (CPU total)=37582.23046875MB
INFO:root:[  114] Training loss: 0.85945312, Validation loss: 0.88252652, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37686.640625MB; mem (CPU total)=37620.375MB
INFO:root:[  115] Training loss: 0.85907937, Validation loss: 0.88432023, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37724.734375MB; mem (CPU total)=37658.734375MB
INFO:root:[  116] Training loss: 0.85901657, Validation loss: 0.88450688, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37762.83203125MB; mem (CPU total)=37696.62890625MB
INFO:root:[  117] Training loss: 0.85852884, Validation loss: 0.88226115, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37800.9296875MB; mem (CPU total)=37735.05078125MB
INFO:root:[  118] Training loss: 0.85884780, Validation loss: 0.88347777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37839.0234375MB; mem (CPU total)=37773.47265625MB
INFO:root:[  119] Training loss: 0.85820664, Validation loss: 0.88273124, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37877.12109375MB; mem (CPU total)=37811.140625MB
INFO:root:[  120] Training loss: 0.85809126, Validation loss: 0.88331712, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37915.21875MB; mem (CPU total)=37849.55859375MB
INFO:root:[  121] Training loss: 0.85772311, Validation loss: 0.88193165, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37953.3125MB; mem (CPU total)=37887.5390625MB
INFO:root:[  122] Training loss: 0.85743271, Validation loss: 0.88167182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37991.40625MB; mem (CPU total)=37925.71484375MB
INFO:root:[  123] Training loss: 0.85717867, Validation loss: 0.88245181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38029.5MB; mem (CPU total)=37963.8203125MB
INFO:root:[  124] Training loss: 0.85692860, Validation loss: 0.88186954, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38067.59765625MB; mem (CPU total)=38002.45703125MB
INFO:root:[  125] Training loss: 0.85664550, Validation loss: 0.88282259, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38105.69140625MB; mem (CPU total)=38040.59765625MB
INFO:root:[  126] Training loss: 0.85670271, Validation loss: 0.88366734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38143.78515625MB; mem (CPU total)=38078.1875MB
INFO:root:[  127] Training loss: 0.85631010, Validation loss: 0.88242963, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38181.8828125MB; mem (CPU total)=38116.33203125MB
INFO:root:[  128] Training loss: 0.85622780, Validation loss: 0.88175025, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38219.98046875MB; mem (CPU total)=38154.6953125MB
INFO:root:[  129] Training loss: 0.85579185, Validation loss: 0.88309836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38258.07421875MB; mem (CPU total)=38192.83203125MB
INFO:root:[  130] Training loss: 0.85549485, Validation loss: 0.88294998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38296.16796875MB; mem (CPU total)=38230.859375MB
INFO:root:[  131] Training loss: 0.85554794, Validation loss: 0.88293764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38334.265625MB; mem (CPU total)=38269.25MB
INFO:root:EP 131: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=38372.30078125MB; mem (CPU total)=38307.1484375MB
INFO:root:Training the model took 9707.913s.
INFO:root:Emptying the cuda cache took 0.025s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83566
INFO:root:EnergyScoreTrain: 0.72554
INFO:root:CRPSTrain: 0.57267
INFO:root:Gaussian NLLTrain: 98.11845
INFO:root:CoverageTrain: 0.37903
INFO:root:IntervalWidthTrain: 0.62278
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8636
INFO:root:EnergyScoreValidation: 0.753
INFO:root:CRPSValidation: 0.59577
INFO:root:Gaussian NLLValidation: 99.66317
INFO:root:CoverageValidation: 0.36485
INFO:root:IntervalWidthValidation: 0.62163
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86459
INFO:root:EnergyScoreTest: 0.75422
INFO:root:CRPSTest: 0.59655
INFO:root:Gaussian NLLTest: 98.90344
INFO:root:CoverageTest: 0.36444
INFO:root:IntervalWidthTest: 0.61977
INFO:root:After validation: mem (CPU python)=38416.8203125MB; mem (CPU total)=38351.88671875MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=38416.8203125MB; mem (CPU total)=38351.9296875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=38417.2421875MB; mem (CPU total)=38352.421875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=38417.2421875MB; mem (CPU total)=38352.109375MB
INFO:root:[    1] Training loss: 1.02248892, Validation loss: 1.01835636, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38455.32421875MB; mem (CPU total)=38390.58203125MB
INFO:root:[    2] Training loss: 1.01616063, Validation loss: 1.01309867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38493.41796875MB; mem (CPU total)=38428.7265625MB
INFO:root:[    3] Training loss: 1.00615325, Validation loss: 0.99920802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38531.515625MB; mem (CPU total)=38466.92578125MB
INFO:root:[    4] Training loss: 0.99235946, Validation loss: 0.98691776, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38569.61328125MB; mem (CPU total)=38504.828125MB
INFO:root:[    5] Training loss: 0.97960863, Validation loss: 0.97446740, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38607.70703125MB; mem (CPU total)=38542.97265625MB
INFO:root:[    6] Training loss: 0.96758609, Validation loss: 0.96255047, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38645.8046875MB; mem (CPU total)=38581.36328125MB
INFO:root:[    7] Training loss: 0.95792546, Validation loss: 0.95541148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38683.8984375MB; mem (CPU total)=38619.2109375MB
INFO:root:[    8] Training loss: 0.95038284, Validation loss: 0.94884725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38721.9921875MB; mem (CPU total)=38657.62109375MB
INFO:root:[    9] Training loss: 0.94409535, Validation loss: 0.94323793, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38760.08984375MB; mem (CPU total)=38696.51953125MB
INFO:root:[   10] Training loss: 0.93899423, Validation loss: 0.93794643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38798.18359375MB; mem (CPU total)=38734.546875MB
INFO:root:[   11] Training loss: 0.93430500, Validation loss: 0.93372962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38836.27734375MB; mem (CPU total)=38772.66015625MB
INFO:root:[   12] Training loss: 0.93051372, Validation loss: 0.93044730, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38874.375MB; mem (CPU total)=38810.57421875MB
INFO:root:[   13] Training loss: 0.92711238, Validation loss: 0.92629911, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38912.47265625MB; mem (CPU total)=38848.6875MB
INFO:root:[   14] Training loss: 0.92402549, Validation loss: 0.92443345, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38950.56640625MB; mem (CPU total)=38886.859375MB
INFO:root:[   15] Training loss: 0.92109742, Validation loss: 0.92291906, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38988.66015625MB; mem (CPU total)=38925.23046875MB
INFO:root:[   16] Training loss: 0.91876100, Validation loss: 0.92000533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39026.7578125MB; mem (CPU total)=38963.36328125MB
INFO:root:[   17] Training loss: 0.91638947, Validation loss: 0.91812387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39064.8515625MB; mem (CPU total)=39001.28515625MB
INFO:root:[   18] Training loss: 0.91397828, Validation loss: 0.91646265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39102.9453125MB; mem (CPU total)=39039.4296875MB
INFO:root:[   19] Training loss: 0.91196210, Validation loss: 0.91448257, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39141.04296875MB; mem (CPU total)=39077.57421875MB
INFO:root:[   20] Training loss: 0.90991675, Validation loss: 0.91264361, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39179.140625MB; mem (CPU total)=39115.70703125MB
INFO:root:[   21] Training loss: 0.90816466, Validation loss: 0.91123157, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39217.234375MB; mem (CPU total)=39154.09765625MB
INFO:root:[   22] Training loss: 0.90642491, Validation loss: 0.90951425, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39255.328125MB; mem (CPU total)=39192.44140625MB
INFO:root:[   23] Training loss: 0.90479164, Validation loss: 0.90825734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39293.42578125MB; mem (CPU total)=39230.87890625MB
INFO:root:[   24] Training loss: 0.90292118, Validation loss: 0.90632780, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39331.51953125MB; mem (CPU total)=39268.765625MB
INFO:root:[   25] Training loss: 0.90162522, Validation loss: 0.90528906, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39369.61328125MB; mem (CPU total)=39307.03515625MB
INFO:root:[   26] Training loss: 0.90023256, Validation loss: 0.90392504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39407.7109375MB; mem (CPU total)=39345.0390625MB
INFO:root:[   27] Training loss: 0.89897316, Validation loss: 0.90349516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39445.8046875MB; mem (CPU total)=39383.2109375MB
INFO:root:[   28] Training loss: 0.89767299, Validation loss: 0.90191049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39483.90234375MB; mem (CPU total)=39421.59765625MB
INFO:root:[   29] Training loss: 0.89668202, Validation loss: 0.90073670, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39521.99609375MB; mem (CPU total)=39459.7421875MB
INFO:root:[   30] Training loss: 0.89509715, Validation loss: 0.90025217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39560.09375MB; mem (CPU total)=39497.640625MB
INFO:root:[   31] Training loss: 0.89405634, Validation loss: 0.89957144, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39598.1875MB; mem (CPU total)=39536.2578125MB
INFO:root:[   32] Training loss: 0.89265126, Validation loss: 0.89894569, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39636.28125MB; mem (CPU total)=39574.42578125MB
INFO:root:[   33] Training loss: 0.89188834, Validation loss: 0.89767326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39674.37890625MB; mem (CPU total)=39612.78515625MB
INFO:root:[   34] Training loss: 0.89085919, Validation loss: 0.89586615, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39712.47265625MB; mem (CPU total)=39650.7109375MB
INFO:root:[   35] Training loss: 0.88971011, Validation loss: 0.89612231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39750.56640625MB; mem (CPU total)=39688.60546875MB
INFO:root:[   36] Training loss: 0.88878519, Validation loss: 0.89500315, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39788.6640625MB; mem (CPU total)=39726.98828125MB
INFO:root:[   37] Training loss: 0.88784687, Validation loss: 0.89371430, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39826.76171875MB; mem (CPU total)=39765.37890625MB
INFO:root:[   38] Training loss: 0.88688830, Validation loss: 0.89283627, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39864.85546875MB; mem (CPU total)=39804.0390625MB
INFO:root:[   39] Training loss: 0.88608927, Validation loss: 0.89306985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39902.94921875MB; mem (CPU total)=39842.171875MB
INFO:root:[   40] Training loss: 0.88511693, Validation loss: 0.89172207, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39941.046875MB; mem (CPU total)=39880.0703125MB
INFO:root:[   41] Training loss: 0.88436630, Validation loss: 0.89155975, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39979.140625MB; mem (CPU total)=39918.18359375MB
INFO:root:[   42] Training loss: 0.88355546, Validation loss: 0.89143975, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40017.234375MB; mem (CPU total)=39956.328125MB
INFO:root:[   43] Training loss: 0.88286530, Validation loss: 0.89070413, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40055.33203125MB; mem (CPU total)=39993.9609375MB
INFO:root:[   44] Training loss: 0.88242060, Validation loss: 0.89045960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40093.42578125MB; mem (CPU total)=40032.13671875MB
INFO:root:[   45] Training loss: 0.88124856, Validation loss: 0.88925237, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40131.5234375MB; mem (CPU total)=40070.00390625MB
INFO:root:[   46] Training loss: 0.88058890, Validation loss: 0.88883135, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40169.6171875MB; mem (CPU total)=40110.0MB
INFO:root:[   47] Training loss: 0.88004460, Validation loss: 0.88859486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40207.71484375MB; mem (CPU total)=40148.12890625MB
INFO:root:[   48] Training loss: 0.87918724, Validation loss: 0.88690389, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40245.80859375MB; mem (CPU total)=40186.02734375MB
INFO:root:[   49] Training loss: 0.87853574, Validation loss: 0.88754201, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40283.90234375MB; mem (CPU total)=40224.203125MB
INFO:root:[   50] Training loss: 0.87776817, Validation loss: 0.88701114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40322.00390625MB; mem (CPU total)=40262.1015625MB
INFO:root:[   51] Training loss: 0.87730694, Validation loss: 0.88775891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40360.09765625MB; mem (CPU total)=40300.1796875MB
INFO:root:[   52] Training loss: 0.87671018, Validation loss: 0.88607494, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40398.19140625MB; mem (CPU total)=40338.26171875MB
INFO:root:[   53] Training loss: 0.87593607, Validation loss: 0.88552341, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40436.2890625MB; mem (CPU total)=40376.44921875MB
INFO:root:[   54] Training loss: 0.87538207, Validation loss: 0.88511891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40474.38671875MB; mem (CPU total)=40414.82421875MB
INFO:root:[   55] Training loss: 0.87484366, Validation loss: 0.88549936, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40512.48046875MB; mem (CPU total)=40452.75MB
INFO:root:[   56] Training loss: 0.87427863, Validation loss: 0.88504787, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40550.57421875MB; mem (CPU total)=40490.94921875MB
INFO:root:[   57] Training loss: 0.87391976, Validation loss: 0.88408961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40588.671875MB; mem (CPU total)=40529.30859375MB
INFO:root:[   58] Training loss: 0.87299839, Validation loss: 0.88372983, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40626.765625MB; mem (CPU total)=40567.484375MB
INFO:root:[   59] Training loss: 0.87256398, Validation loss: 0.88497071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40664.86328125MB; mem (CPU total)=40605.62890625MB
INFO:root:[   60] Training loss: 0.87204439, Validation loss: 0.88359800, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40702.9609375MB; mem (CPU total)=40644.01953125MB
INFO:root:[   61] Training loss: 0.87150906, Validation loss: 0.88316762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40741.0546875MB; mem (CPU total)=40681.796875MB
INFO:root:[   62] Training loss: 0.87083190, Validation loss: 0.88274146, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40779.1484375MB; mem (CPU total)=40720.2109375MB
INFO:root:[   63] Training loss: 0.87041916, Validation loss: 0.88285551, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40817.2421875MB; mem (CPU total)=40758.35546875MB
INFO:root:[   64] Training loss: 0.87000938, Validation loss: 0.88121968, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40855.33984375MB; mem (CPU total)=40796.328125MB
INFO:root:[   65] Training loss: 0.86919180, Validation loss: 0.88175388, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40893.43359375MB; mem (CPU total)=40834.46875MB
INFO:root:[   66] Training loss: 0.86895624, Validation loss: 0.88177867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40931.52734375MB; mem (CPU total)=40872.55078125MB
INFO:root:[   67] Training loss: 0.86858338, Validation loss: 0.88142160, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40969.625MB; mem (CPU total)=40910.6953125MB
INFO:root:[   68] Training loss: 0.86778098, Validation loss: 0.88108868, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41007.72265625MB; mem (CPU total)=40949.31640625MB
INFO:root:[   69] Training loss: 0.86765230, Validation loss: 0.88091892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41045.81640625MB; mem (CPU total)=40987.4765625MB
INFO:root:[   70] Training loss: 0.86698639, Validation loss: 0.88040381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41083.91015625MB; mem (CPU total)=41025.19140625MB
INFO:root:[   71] Training loss: 0.86661001, Validation loss: 0.88089041, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41122.0078125MB; mem (CPU total)=41063.58203125MB
INFO:root:[   72] Training loss: 0.86623518, Validation loss: 0.87988801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41160.1015625MB; mem (CPU total)=41101.7265625MB
INFO:root:[   73] Training loss: 0.86570052, Validation loss: 0.87882167, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41198.1953125MB; mem (CPU total)=41139.87109375MB
INFO:root:[   74] Training loss: 0.86532838, Validation loss: 0.88057549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41236.29296875MB; mem (CPU total)=41178.2578125MB
INFO:root:[   75] Training loss: 0.86494143, Validation loss: 0.87921458, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41274.38671875MB; mem (CPU total)=41216.4375MB
INFO:root:[   76] Training loss: 0.86459311, Validation loss: 0.87973863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41312.48046875MB; mem (CPU total)=41254.296875MB
INFO:root:[   77] Training loss: 0.86380935, Validation loss: 0.87938411, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41350.58203125MB; mem (CPU total)=41292.37890625MB
INFO:root:[   78] Training loss: 0.86344985, Validation loss: 0.87889824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41388.67578125MB; mem (CPU total)=41329.5078125MB
INFO:root:[   79] Training loss: 0.86301852, Validation loss: 0.87915465, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41426.76953125MB; mem (CPU total)=41368.87890625MB
INFO:root:[   80] Training loss: 0.86281424, Validation loss: 0.87913133, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41464.86328125MB; mem (CPU total)=41407.265625MB
INFO:root:[   81] Training loss: 0.86209308, Validation loss: 0.87731306, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41502.9609375MB; mem (CPU total)=41445.1953125MB
INFO:root:[   82] Training loss: 0.86184223, Validation loss: 0.87801648, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41541.0546875MB; mem (CPU total)=41483.33984375MB
INFO:root:[   83] Training loss: 0.86165788, Validation loss: 0.87813975, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41579.15234375MB; mem (CPU total)=41521.671875MB
INFO:root:[   84] Training loss: 0.86117733, Validation loss: 0.87739116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41617.25MB; mem (CPU total)=41560.0859375MB
INFO:root:[   85] Training loss: 0.86076606, Validation loss: 0.87750526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41655.34375MB; mem (CPU total)=41598.23046875MB
INFO:root:[   86] Training loss: 0.86060115, Validation loss: 0.87793931, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41693.4375MB; mem (CPU total)=41636.5546875MB
INFO:root:[   87] Training loss: 0.85982132, Validation loss: 0.87678260, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41731.53125MB; mem (CPU total)=41674.578125MB
INFO:root:[   88] Training loss: 0.85980113, Validation loss: 0.87752985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41769.62890625MB; mem (CPU total)=41712.75390625MB
INFO:root:[   89] Training loss: 0.85924788, Validation loss: 0.87838584, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41807.72265625MB; mem (CPU total)=41750.71484375MB
INFO:root:[   90] Training loss: 0.85893442, Validation loss: 0.87657470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41845.81640625MB; mem (CPU total)=41788.98828125MB
INFO:root:[   91] Training loss: 0.85869740, Validation loss: 0.87706387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41883.9140625MB; mem (CPU total)=41826.91015625MB
INFO:root:[   92] Training loss: 0.85834059, Validation loss: 0.87760209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41922.0078125MB; mem (CPU total)=41865.33203125MB
INFO:root:[   93] Training loss: 0.85772444, Validation loss: 0.87599650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41960.1015625MB; mem (CPU total)=41903.5078125MB
INFO:root:[   94] Training loss: 0.85736335, Validation loss: 0.87623653, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41998.19921875MB; mem (CPU total)=41941.63671875MB
INFO:root:[   95] Training loss: 0.85760289, Validation loss: 0.87762919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42036.296875MB; mem (CPU total)=41979.8046875MB
INFO:root:[   96] Training loss: 0.85675021, Validation loss: 0.87647655, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42074.390625MB; mem (CPU total)=42017.98046875MB
INFO:root:[   97] Training loss: 0.85646731, Validation loss: 0.87751406, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42112.484375MB; mem (CPU total)=42056.671875MB
INFO:root:[   98] Training loss: 0.85630673, Validation loss: 0.87538724, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42150.58203125MB; mem (CPU total)=42094.30859375MB
INFO:root:[   99] Training loss: 0.85592006, Validation loss: 0.87783098, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42188.67578125MB; mem (CPU total)=42132.46875MB
INFO:root:[  100] Training loss: 0.85556090, Validation loss: 0.87617437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42226.7734375MB; mem (CPU total)=42170.64453125MB
INFO:root:[  101] Training loss: 0.85524042, Validation loss: 0.87560501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42264.87109375MB; mem (CPU total)=42208.3203125MB
INFO:root:[  102] Training loss: 0.85491228, Validation loss: 0.87653820, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42302.96484375MB; mem (CPU total)=42246.921875MB
INFO:root:[  103] Training loss: 0.85446439, Validation loss: 0.87566262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42341.05859375MB; mem (CPU total)=42285.09765625MB
INFO:root:[  104] Training loss: 0.85469375, Validation loss: 0.87632524, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42379.15234375MB; mem (CPU total)=42322.94140625MB
INFO:root:[  105] Training loss: 0.85373574, Validation loss: 0.87509760, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42417.25MB; mem (CPU total)=42361.3828125MB
INFO:root:[  106] Training loss: 0.85356376, Validation loss: 0.87559741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42455.34375MB; mem (CPU total)=42399.0703125MB
INFO:root:[  107] Training loss: 0.85316402, Validation loss: 0.87638702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42493.4375MB; mem (CPU total)=42437.03125MB
INFO:root:[  108] Training loss: 0.85317323, Validation loss: 0.87629445, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42531.5390625MB; mem (CPU total)=42475.44140625MB
INFO:root:[  109] Training loss: 0.85287903, Validation loss: 0.87636385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42569.6328125MB; mem (CPU total)=42513.57421875MB
INFO:root:[  110] Training loss: 0.85282941, Validation loss: 0.87588494, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42607.7265625MB; mem (CPU total)=42551.75MB
INFO:root:[  111] Training loss: 0.85226211, Validation loss: 0.87605837, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42645.82421875MB; mem (CPU total)=42589.4609375MB
INFO:root:[  112] Training loss: 0.85219283, Validation loss: 0.87562885, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42683.91796875MB; mem (CPU total)=42627.625MB
INFO:root:[  113] Training loss: 0.85156630, Validation loss: 0.87695642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42722.01171875MB; mem (CPU total)=42665.5546875MB
INFO:root:[  114] Training loss: 0.85137634, Validation loss: 0.87658656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42760.10546875MB; mem (CPU total)=42704.22265625MB
INFO:root:EP 114: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=42798.203125MB; mem (CPU total)=42745.08984375MB
INFO:root:Training the model took 9281.314s.
INFO:root:Emptying the cuda cache took 0.023s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8322
INFO:root:EnergyScoreTrain: 0.72248
INFO:root:CRPSTrain: 0.56947
INFO:root:Gaussian NLLTrain: 123.73796
INFO:root:CoverageTrain: 0.3797
INFO:root:IntervalWidthTrain: 0.60926
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.85617
INFO:root:EnergyScoreValidation: 0.74601
INFO:root:CRPSValidation: 0.58906
INFO:root:Gaussian NLLValidation: 124.01066
INFO:root:CoverageValidation: 0.3677
INFO:root:IntervalWidthValidation: 0.60868
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8572
INFO:root:EnergyScoreTest: 0.74727
INFO:root:CRPSTest: 0.59079
INFO:root:Gaussian NLLTest: 125.29998
INFO:root:CoverageTest: 0.36504
INFO:root:IntervalWidthTest: 0.60664
INFO:root:After validation: mem (CPU python)=42841.0859375MB; mem (CPU total)=42787.9296875MB
