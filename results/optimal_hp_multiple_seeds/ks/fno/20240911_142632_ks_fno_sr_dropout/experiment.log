INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.96484375MB; mem (CPU total)=13914.7734375MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12455.51171875MB; mem (CPU total)=13959.4296875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12455.51171875MB; mem (CPU total)=13959.4296875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12455.51171875MB; mem (CPU total)=15138.83984375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=15146.9609375MB
INFO:root:[    1] Training loss: 0.78510183, Validation loss: 0.72790136, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=16364.796875MB
INFO:root:[    2] Training loss: 0.72502136, Validation loss: 0.72311503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=16441.28125MB
INFO:root:[    3] Training loss: 0.72239900, Validation loss: 0.72195643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=16510.93359375MB
INFO:root:[    4] Training loss: 0.72130356, Validation loss: 0.72087746, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=16579.5703125MB
INFO:root:[    5] Training loss: 0.72086471, Validation loss: 0.72002045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=16648.94921875MB
INFO:root:[    6] Training loss: 0.72047135, Validation loss: 0.72084597, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=16718.30078125MB
INFO:root:[    7] Training loss: 0.71973507, Validation loss: 0.72009844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=16787.63671875MB
INFO:root:[    8] Training loss: 0.71952131, Validation loss: 0.72023095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=16857.03515625MB
INFO:root:[    9] Training loss: 0.71914322, Validation loss: 0.71918736, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=16932.09375MB
INFO:root:[   10] Training loss: 0.71891813, Validation loss: 0.71850293, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17007.64453125MB
INFO:root:[   11] Training loss: 0.71819941, Validation loss: 0.71840918, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17080.94140625MB
INFO:root:[   12] Training loss: 0.71709416, Validation loss: 0.71564024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17150.38671875MB
INFO:root:[   13] Training loss: 0.71302630, Validation loss: 0.70985905, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17220.36328125MB
INFO:root:[   14] Training loss: 0.70504024, Validation loss: 0.70083610, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17290.9609375MB
INFO:root:[   15] Training loss: 0.69660506, Validation loss: 0.69251777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17360.8125MB
INFO:root:[   16] Training loss: 0.68943621, Validation loss: 0.68722469, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17430.9375MB
INFO:root:[   17] Training loss: 0.68388787, Validation loss: 0.68104843, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17502.30078125MB
INFO:root:[   18] Training loss: 0.67889478, Validation loss: 0.67777696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17578.58984375MB
INFO:root:[   19] Training loss: 0.67479545, Validation loss: 0.67420184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17655.125MB
INFO:root:[   20] Training loss: 0.67084088, Validation loss: 0.67147665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17726.7265625MB
INFO:root:[   21] Training loss: 0.66772971, Validation loss: 0.66818798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17796.26953125MB
INFO:root:[   22] Training loss: 0.66535264, Validation loss: 0.66584156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17865.79296875MB
INFO:root:[   23] Training loss: 0.66311727, Validation loss: 0.66362938, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=17937.625MB
INFO:root:[   24] Training loss: 0.66104678, Validation loss: 0.66112006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18008.40625MB
INFO:root:[   25] Training loss: 0.65962458, Validation loss: 0.66043358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18079.31640625MB
INFO:root:[   26] Training loss: 0.65777460, Validation loss: 0.65914943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18151.29296875MB
INFO:root:[   27] Training loss: 0.65615928, Validation loss: 0.65804431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18227.84375MB
INFO:root:[   28] Training loss: 0.65482191, Validation loss: 0.65609693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18304.34765625MB
INFO:root:[   29] Training loss: 0.65390818, Validation loss: 0.65469987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18374.0546875MB
INFO:root:[   30] Training loss: 0.65269141, Validation loss: 0.65397621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18444.60546875MB
INFO:root:[   31] Training loss: 0.65123821, Validation loss: 0.65337291, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18515.23828125MB
INFO:root:[   32] Training loss: 0.65068588, Validation loss: 0.65199648, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18585.640625MB
INFO:root:[   33] Training loss: 0.64988271, Validation loss: 0.65195022, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18655.54296875MB
INFO:root:[   34] Training loss: 0.64917909, Validation loss: 0.65109790, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18726.6796875MB
INFO:root:[   35] Training loss: 0.64796900, Validation loss: 0.65022721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18800.42578125MB
INFO:root:[   36] Training loss: 0.64699979, Validation loss: 0.64947253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18876.47265625MB
INFO:root:[   37] Training loss: 0.64632951, Validation loss: 0.64921314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=18952.44921875MB
INFO:root:[   38] Training loss: 0.64551377, Validation loss: 0.64705073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19024.56640625MB
INFO:root:[   39] Training loss: 0.64452669, Validation loss: 0.64710764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19094.9375MB
INFO:root:[   40] Training loss: 0.64380747, Validation loss: 0.64658230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19168.9296875MB
INFO:root:[   41] Training loss: 0.64257959, Validation loss: 0.64486851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19239.8046875MB
INFO:root:[   42] Training loss: 0.64223417, Validation loss: 0.64649072, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19310.16796875MB
INFO:root:[   43] Training loss: 0.64135005, Validation loss: 0.64453739, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19380.80078125MB
INFO:root:[   44] Training loss: 0.64063102, Validation loss: 0.64440856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19451.6640625MB
INFO:root:[   45] Training loss: 0.63976021, Validation loss: 0.64290162, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19528.7421875MB
INFO:root:[   46] Training loss: 0.63919200, Validation loss: 0.64303871, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19604.734375MB
INFO:root:[   47] Training loss: 0.63910291, Validation loss: 0.64210452, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19678.87890625MB
INFO:root:[   48] Training loss: 0.63749019, Validation loss: 0.64017874, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19748.83984375MB
INFO:root:[   49] Training loss: 0.63683026, Validation loss: 0.64134696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19862.859375MB
INFO:root:[   50] Training loss: 0.63652315, Validation loss: 0.64021560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19922.85546875MB
INFO:root:[   51] Training loss: 0.63595242, Validation loss: 0.63917886, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=19934.10546875MB
INFO:root:[   52] Training loss: 0.63525782, Validation loss: 0.63913256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20010.31640625MB
INFO:root:[   53] Training loss: 0.63426344, Validation loss: 0.63902902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20081.23046875MB
INFO:root:[   54] Training loss: 0.63408447, Validation loss: 0.63639132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20152.09375MB
INFO:root:[   55] Training loss: 0.63312192, Validation loss: 0.63725755, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20222.46484375MB
INFO:root:[   56] Training loss: 0.63261402, Validation loss: 0.63637292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20293.53515625MB
INFO:root:[   57] Training loss: 0.63209246, Validation loss: 0.63525367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20364.09375MB
INFO:root:[   58] Training loss: 0.63140658, Validation loss: 0.63587483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20434.484375MB
INFO:root:[   59] Training loss: 0.63131851, Validation loss: 0.63561296, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20506.77734375MB
INFO:root:[   60] Training loss: 0.63045038, Validation loss: 0.63596470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20583.6328125MB
INFO:root:[   61] Training loss: 0.62956482, Validation loss: 0.63415026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20660.11328125MB
INFO:root:[   62] Training loss: 0.62932637, Validation loss: 0.63344181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20735.0703125MB
INFO:root:[   63] Training loss: 0.62894956, Validation loss: 0.63343596, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20805.2109375MB
INFO:root:[   64] Training loss: 0.62826664, Validation loss: 0.63261834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20875.6640625MB
INFO:root:[   65] Training loss: 0.62729292, Validation loss: 0.63247810, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=20947.06640625MB
INFO:root:[   66] Training loss: 0.62708936, Validation loss: 0.63167544, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21017.84375MB
INFO:root:[   67] Training loss: 0.62656396, Validation loss: 0.63197419, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21088.37890625MB
INFO:root:[   68] Training loss: 0.62592725, Validation loss: 0.63237849, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21159.01953125MB
INFO:root:[   69] Training loss: 0.62556372, Validation loss: 0.63023464, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21232.2890625MB
INFO:root:[   70] Training loss: 0.62531924, Validation loss: 0.63016397, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21308.48046875MB
INFO:root:[   71] Training loss: 0.62448796, Validation loss: 0.62912798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21384.87890625MB
INFO:root:[   72] Training loss: 0.62444298, Validation loss: 0.62920016, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21459.36328125MB
INFO:root:[   73] Training loss: 0.62373489, Validation loss: 0.62990763, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21529.01171875MB
INFO:root:[   74] Training loss: 0.62374904, Validation loss: 0.62955713, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21599.90234375MB
INFO:root:[   75] Training loss: 0.62359352, Validation loss: 0.62827824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21669.80859375MB
INFO:root:[   76] Training loss: 0.62288326, Validation loss: 0.62863961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21740.69921875MB
INFO:root:[   77] Training loss: 0.62215463, Validation loss: 0.62831240, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21811.5625MB
INFO:root:[   78] Training loss: 0.62173706, Validation loss: 0.62911782, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21881.890625MB
INFO:root:[   79] Training loss: 0.62131846, Validation loss: 0.62782859, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=21956.7109375MB
INFO:root:[   80] Training loss: 0.62128528, Validation loss: 0.62773671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22033.4375MB
INFO:root:[   81] Training loss: 0.62066100, Validation loss: 0.62731684, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22109.3671875MB
INFO:root:[   82] Training loss: 0.61987177, Validation loss: 0.62673371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22181.44921875MB
INFO:root:[   83] Training loss: 0.61955451, Validation loss: 0.62578728, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22251.60546875MB
INFO:root:[   84] Training loss: 0.61915579, Validation loss: 0.62712398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22322.48046875MB
INFO:root:[   85] Training loss: 0.61914383, Validation loss: 0.62586222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22393.5703125MB
INFO:root:[   86] Training loss: 0.61871915, Validation loss: 0.62475970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22464.609375MB
INFO:root:[   87] Training loss: 0.61840512, Validation loss: 0.62529717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22534.109375MB
INFO:root:[   88] Training loss: 0.61818760, Validation loss: 0.62481326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22606.0234375MB
INFO:root:[   89] Training loss: 0.61752820, Validation loss: 0.62577877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22682.7109375MB
INFO:root:[   90] Training loss: 0.61755616, Validation loss: 0.62486657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22758.6171875MB
INFO:root:[   91] Training loss: 0.61718052, Validation loss: 0.62483824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22833.63671875MB
INFO:root:[   92] Training loss: 0.61675204, Validation loss: 0.62467891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22904.41796875MB
INFO:root:[   93] Training loss: 0.61596951, Validation loss: 0.62566474, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=22973.97265625MB
INFO:root:[   94] Training loss: 0.61573633, Validation loss: 0.62326156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23044.078125MB
INFO:root:[   95] Training loss: 0.61558550, Validation loss: 0.62356199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23114.25390625MB
INFO:root:[   96] Training loss: 0.61512975, Validation loss: 0.62480842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23183.890625MB
INFO:root:[   97] Training loss: 0.61539060, Validation loss: 0.62431562, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23254.78125MB
INFO:root:[   98] Training loss: 0.61497840, Validation loss: 0.62229415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23329.859375MB
INFO:root:[   99] Training loss: 0.61487283, Validation loss: 0.62373984, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23406.41015625MB
INFO:root:[  100] Training loss: 0.61468721, Validation loss: 0.62186939, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23482.2265625MB
INFO:root:[  101] Training loss: 0.61355970, Validation loss: 0.62380724, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23554.8125MB
INFO:root:[  102] Training loss: 0.61352071, Validation loss: 0.62338082, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23624.71875MB
INFO:root:[  103] Training loss: 0.61359775, Validation loss: 0.62368372, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23695.1171875MB
INFO:root:[  104] Training loss: 0.61277309, Validation loss: 0.62159627, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23765.5390625MB
INFO:root:[  105] Training loss: 0.61253252, Validation loss: 0.62304885, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23836.1640625MB
INFO:root:[  106] Training loss: 0.61257936, Validation loss: 0.62228055, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23906.3203125MB
INFO:root:[  107] Training loss: 0.61191290, Validation loss: 0.62131726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=23978.421875MB
INFO:root:[  108] Training loss: 0.61171150, Validation loss: 0.62233156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24053.86328125MB
INFO:root:[  109] Training loss: 0.61136626, Validation loss: 0.62237356, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24129.875MB
INFO:root:[  110] Training loss: 0.61153084, Validation loss: 0.62092155, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24206.86328125MB
INFO:root:[  111] Training loss: 0.61046380, Validation loss: 0.62175513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24275.4921875MB
INFO:root:[  112] Training loss: 0.61078060, Validation loss: 0.62169768, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24346.2421875MB
INFO:root:[  113] Training loss: 0.61052669, Validation loss: 0.62050134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24418.05078125MB
INFO:root:[  114] Training loss: 0.60988045, Validation loss: 0.62100460, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24487.90625MB
INFO:root:[  115] Training loss: 0.60953736, Validation loss: 0.62013836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24557.89453125MB
INFO:root:[  116] Training loss: 0.60932159, Validation loss: 0.62077429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24628.27734375MB
INFO:root:[  117] Training loss: 0.60931255, Validation loss: 0.62180439, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24704.10546875MB
INFO:root:[  118] Training loss: 0.60932737, Validation loss: 0.62025228, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24780.37890625MB
INFO:root:[  119] Training loss: 0.60815688, Validation loss: 0.62041003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24856.90625MB
INFO:root:[  120] Training loss: 0.60822617, Validation loss: 0.61963283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24926.55078125MB
INFO:root:[  121] Training loss: 0.60826617, Validation loss: 0.62022232, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=24996.43359375MB
INFO:root:[  122] Training loss: 0.60771245, Validation loss: 0.61968545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25066.78125MB
INFO:root:[  123] Training loss: 0.60768840, Validation loss: 0.62061211, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25136.640625MB
INFO:root:[  124] Training loss: 0.60727441, Validation loss: 0.62046700, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25206.25390625MB
INFO:root:[  125] Training loss: 0.60719549, Validation loss: 0.61939566, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25276.1328125MB
INFO:root:[  126] Training loss: 0.60669438, Validation loss: 0.61801469, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25351.9609375MB
INFO:root:[  127] Training loss: 0.60669619, Validation loss: 0.61953363, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25427.4921875MB
INFO:root:[  128] Training loss: 0.60641181, Validation loss: 0.61956121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25504.02734375MB
INFO:root:[  129] Training loss: 0.60661908, Validation loss: 0.62010460, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25576.37890625MB
INFO:root:[  130] Training loss: 0.60591256, Validation loss: 0.61911707, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25645.23828125MB
INFO:root:[  131] Training loss: 0.60562062, Validation loss: 0.61993150, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25714.61328125MB
INFO:root:[  132] Training loss: 0.60540344, Validation loss: 0.61972645, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25784.49609375MB
INFO:root:[  133] Training loss: 0.60537581, Validation loss: 0.61732874, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25853.953125MB
INFO:root:[  134] Training loss: 0.60482353, Validation loss: 0.61886727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25923.875MB
INFO:root:[  135] Training loss: 0.60474818, Validation loss: 0.62034998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=25998.46484375MB
INFO:root:[  136] Training loss: 0.60426474, Validation loss: 0.62029631, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26074.234375MB
INFO:root:[  137] Training loss: 0.60422415, Validation loss: 0.61843558, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26150.30859375MB
INFO:root:[  138] Training loss: 0.60398324, Validation loss: 0.61811381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26223.64453125MB
INFO:root:[  139] Training loss: 0.60349635, Validation loss: 0.61772575, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26293.2890625MB
INFO:root:[  140] Training loss: 0.60338928, Validation loss: 0.61847905, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26363.39453125MB
INFO:root:[  141] Training loss: 0.60327956, Validation loss: 0.61928907, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26433.0390625MB
INFO:root:[  142] Training loss: 0.60331479, Validation loss: 0.61820841, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26503.17578125MB
INFO:root:EP 142: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12455.51171875MB; mem (CPU total)=26570.57421875MB
INFO:root:Training the model took 6247.163s.
INFO:root:Emptying the cuda cache took 0.049s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85787
INFO:root:EnergyScoreTrain: 0.60424
INFO:root:CRPSTrain: 0.53276
INFO:root:Gaussian NLLTrain: 2.64961
INFO:root:CoverageTrain: 0.77128
INFO:root:IntervalWidthTrain: 3.00268
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87825
INFO:root:EnergyScoreValidation: 0.61868
INFO:root:CRPSValidation: 0.54448
INFO:root:Gaussian NLLValidation: 2.68735
INFO:root:CoverageValidation: 0.76471
INFO:root:IntervalWidthValidation: 2.9982
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87927
INFO:root:EnergyScoreTest: 0.6195
INFO:root:CRPSTest: 0.54524
INFO:root:Gaussian NLLTest: 2.69643
INFO:root:CoverageTest: 0.76394
INFO:root:IntervalWidthTest: 2.99226
INFO:root:After validation: mem (CPU python)=12455.51171875MB; mem (CPU total)=26796.3984375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12455.51171875MB; mem (CPU total)=26804.125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=12455.51171875MB; mem (CPU total)=26806.546875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26808.73046875MB
INFO:root:[    1] Training loss: 0.78902975, Validation loss: 0.72472200, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26884.03515625MB
INFO:root:[    2] Training loss: 0.72338396, Validation loss: 0.72248701, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=26954.10546875MB
INFO:root:[    3] Training loss: 0.72133632, Validation loss: 0.72081762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27023.2421875MB
INFO:root:[    4] Training loss: 0.72050654, Validation loss: 0.72050788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27092.1171875MB
INFO:root:[    5] Training loss: 0.72020070, Validation loss: 0.71984482, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27161.2421875MB
INFO:root:[    6] Training loss: 0.71963823, Validation loss: 0.71958532, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27231.11328125MB
INFO:root:[    7] Training loss: 0.71908827, Validation loss: 0.71870835, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27304.0390625MB
INFO:root:[    8] Training loss: 0.71833661, Validation loss: 0.71893242, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27379.02734375MB
INFO:root:[    9] Training loss: 0.71753071, Validation loss: 0.71623674, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27455.24609375MB
INFO:root:[   10] Training loss: 0.71435954, Validation loss: 0.71254808, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27530.796875MB
INFO:root:[   11] Training loss: 0.70875043, Validation loss: 0.70637654, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27600.1640625MB
INFO:root:[   12] Training loss: 0.70211164, Validation loss: 0.69934452, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27670.51953125MB
INFO:root:[   13] Training loss: 0.69665710, Validation loss: 0.69326511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27740.078125MB
INFO:root:[   14] Training loss: 0.69178686, Validation loss: 0.69004254, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27808.9765625MB
INFO:root:[   15] Training loss: 0.68757551, Validation loss: 0.68603983, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27879.10546875MB
INFO:root:[   16] Training loss: 0.68395676, Validation loss: 0.68295305, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=27951.45703125MB
INFO:root:[   17] Training loss: 0.68093034, Validation loss: 0.67973999, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28027.703125MB
INFO:root:[   18] Training loss: 0.67824786, Validation loss: 0.67747275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28104.0546875MB
INFO:root:[   19] Training loss: 0.67580162, Validation loss: 0.67599766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28180.51171875MB
INFO:root:[   20] Training loss: 0.67373873, Validation loss: 0.67436883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28250.890625MB
INFO:root:[   21] Training loss: 0.67193013, Validation loss: 0.67193718, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28320.53515625MB
INFO:root:[   22] Training loss: 0.66999495, Validation loss: 0.67104170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28390.88671875MB
INFO:root:[   23] Training loss: 0.66874048, Validation loss: 0.66881643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28460.52734375MB
INFO:root:[   24] Training loss: 0.66695840, Validation loss: 0.66849934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28529.87109375MB
INFO:root:[   25] Training loss: 0.66552597, Validation loss: 0.66492246, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28600.08203125MB
INFO:root:[   26] Training loss: 0.66460407, Validation loss: 0.66541759, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28676.2890625MB
INFO:root:[   27] Training loss: 0.66300299, Validation loss: 0.66315104, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28752.578125MB
INFO:root:[   28] Training loss: 0.66187385, Validation loss: 0.66196929, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28829.11328125MB
INFO:root:[   29] Training loss: 0.66002561, Validation loss: 0.66221024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28901.95703125MB
INFO:root:[   30] Training loss: 0.65903009, Validation loss: 0.66055275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=28971.109375MB
INFO:root:[   31] Training loss: 0.65913797, Validation loss: 0.66035181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29041.0546875MB
INFO:root:[   32] Training loss: 0.65739242, Validation loss: 0.65814663, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29111.19140625MB
INFO:root:[   33] Training loss: 0.65642804, Validation loss: 0.65763400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29181.6796875MB
INFO:root:[   34] Training loss: 0.65520978, Validation loss: 0.65739817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29251.69140625MB
INFO:root:[   35] Training loss: 0.65442686, Validation loss: 0.65679847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29325.0390625MB
INFO:root:[   36] Training loss: 0.65362445, Validation loss: 0.65526668, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29401.34765625MB
INFO:root:[   37] Training loss: 0.65298464, Validation loss: 0.65494302, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29478.1796875MB
INFO:root:[   38] Training loss: 0.65230949, Validation loss: 0.65288281, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29554.70703125MB
INFO:root:[   39] Training loss: 0.65170243, Validation loss: 0.65229061, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29625.3515625MB
INFO:root:[   40] Training loss: 0.65063900, Validation loss: 0.65259914, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29695.50390625MB
INFO:root:[   41] Training loss: 0.64974370, Validation loss: 0.65190239, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29766.03125MB
INFO:root:[   42] Training loss: 0.64811241, Validation loss: 0.65165043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29835.94140625MB
INFO:root:[   43] Training loss: 0.64740005, Validation loss: 0.65062089, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29906.09765625MB
INFO:root:[   44] Training loss: 0.64739202, Validation loss: 0.64758429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=29976.5859375MB
INFO:root:[   45] Training loss: 0.64644421, Validation loss: 0.64790949, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30050.671875MB
INFO:root:[   46] Training loss: 0.64615436, Validation loss: 0.64754316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30126.765625MB
INFO:root:[   47] Training loss: 0.64489599, Validation loss: 0.64630845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30203.26171875MB
INFO:root:[   48] Training loss: 0.64439726, Validation loss: 0.64546640, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30278.82421875MB
INFO:root:[   49] Training loss: 0.64288597, Validation loss: 0.64531200, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30348.23828125MB
INFO:root:[   50] Training loss: 0.64325332, Validation loss: 0.64479054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30418.125MB
INFO:root:[   51] Training loss: 0.64174435, Validation loss: 0.64430386, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30488.109375MB
INFO:root:[   52] Training loss: 0.64178877, Validation loss: 0.64243714, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30558.51171875MB
INFO:root:[   53] Training loss: 0.64147684, Validation loss: 0.64307695, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30628.90625MB
INFO:root:[   54] Training loss: 0.64013437, Validation loss: 0.64278220, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30699.3046875MB
INFO:root:[   55] Training loss: 0.64010805, Validation loss: 0.64385491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30775.61328125MB
INFO:root:[   56] Training loss: 0.63918239, Validation loss: 0.64179314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30851.921875MB
INFO:root:[   57] Training loss: 0.63869939, Validation loss: 0.64062652, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=30928.90625MB
INFO:root:[   58] Training loss: 0.63783993, Validation loss: 0.64024502, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31003.48828125MB
INFO:root:[   59] Training loss: 0.63756812, Validation loss: 0.64047844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31072.3046875MB
INFO:root:[   60] Training loss: 0.63716099, Validation loss: 0.64110908, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31141.95703125MB
INFO:root:[   61] Training loss: 0.63647610, Validation loss: 0.63853442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31211.8671875MB
INFO:root:[   62] Training loss: 0.63594424, Validation loss: 0.63909825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31281.80078125MB
INFO:root:[   63] Training loss: 0.63588798, Validation loss: 0.64018169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31351.69140625MB
INFO:root:[   64] Training loss: 0.63483551, Validation loss: 0.63859775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31425.046875MB
INFO:root:[   65] Training loss: 0.63520326, Validation loss: 0.64027919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31500.86328125MB
INFO:root:[   66] Training loss: 0.63360531, Validation loss: 0.63679605, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31577.171875MB
INFO:root:[   67] Training loss: 0.63331170, Validation loss: 0.63605410, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31654.1328125MB
INFO:root:[   68] Training loss: 0.63308985, Validation loss: 0.63533254, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31725.73046875MB
INFO:root:[   69] Training loss: 0.63196890, Validation loss: 0.63412162, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31795.63671875MB
INFO:root:[   70] Training loss: 0.63218344, Validation loss: 0.63566977, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31865.0MB
INFO:root:[   71] Training loss: 0.63141164, Validation loss: 0.63536372, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=31935.39453125MB
INFO:root:[   72] Training loss: 0.63157750, Validation loss: 0.63447950, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32005.05859375MB
INFO:root:[   73] Training loss: 0.63098170, Validation loss: 0.63559743, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32074.9609375MB
INFO:root:[   74] Training loss: 0.63016511, Validation loss: 0.63320482, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32150.5390625MB
INFO:root:[   75] Training loss: 0.62922123, Validation loss: 0.63224415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32227.46875MB
INFO:root:[   76] Training loss: 0.62938327, Validation loss: 0.63291391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32302.75MB
INFO:root:[   77] Training loss: 0.62918047, Validation loss: 0.63119811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32378.9921875MB
INFO:root:[   78] Training loss: 0.62842482, Validation loss: 0.63321370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32448.17578125MB
INFO:root:[   79] Training loss: 0.62807824, Validation loss: 0.63045614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32518.06640625MB
INFO:root:[   80] Training loss: 0.62773169, Validation loss: 0.63208940, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32587.7109375MB
INFO:root:[   81] Training loss: 0.62647519, Validation loss: 0.62976202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32657.56640625MB
INFO:root:[   82] Training loss: 0.62713824, Validation loss: 0.63011841, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32727.953125MB
INFO:root:[   83] Training loss: 0.62640714, Validation loss: 0.62991423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32799.375MB
INFO:root:[   84] Training loss: 0.62555412, Validation loss: 0.63117227, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32875.93359375MB
INFO:root:[   85] Training loss: 0.62558272, Validation loss: 0.62852844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=32952.4609375MB
INFO:root:[   86] Training loss: 0.62505407, Validation loss: 0.62970853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=33028.27734375MB
INFO:root:[   87] Training loss: 0.62507848, Validation loss: 0.62963521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=33102.58203125MB
INFO:root:[   88] Training loss: 0.62411695, Validation loss: 0.62816424, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12455.51171875MB; mem (CPU total)=33171.85546875MB
INFO:root:[   89] Training loss: 0.62376809, Validation loss: 0.62951954, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12459.26171875MB; mem (CPU total)=33241.25390625MB
INFO:root:[   90] Training loss: 0.62362895, Validation loss: 0.62880585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12497.359375MB; mem (CPU total)=33311.6328125MB
INFO:root:[   91] Training loss: 0.62314904, Validation loss: 0.62722358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12535.453125MB; mem (CPU total)=33381.26171875MB
INFO:root:[   92] Training loss: 0.62223326, Validation loss: 0.62626457, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12573.546875MB; mem (CPU total)=33451.66015625MB
INFO:root:[   93] Training loss: 0.62218227, Validation loss: 0.62559104, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12611.640625MB; mem (CPU total)=33535.1953125MB
INFO:root:[   94] Training loss: 0.62226449, Validation loss: 0.62558077, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12649.7421875MB; mem (CPU total)=33599.46484375MB
INFO:root:[   95] Training loss: 0.62210391, Validation loss: 0.62529797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12687.8359375MB; mem (CPU total)=33644.27734375MB
INFO:root:[   96] Training loss: 0.62060631, Validation loss: 0.62763370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12725.9296875MB; mem (CPU total)=33720.5703125MB
INFO:root:[   97] Training loss: 0.62112822, Validation loss: 0.62611042, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12764.02734375MB; mem (CPU total)=33796.828125MB
INFO:root:[   98] Training loss: 0.62026792, Validation loss: 0.62483566, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12802.12109375MB; mem (CPU total)=33872.6015625MB
INFO:root:[   99] Training loss: 0.62041535, Validation loss: 0.62572723, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12840.21484375MB; mem (CPU total)=33942.47265625MB
INFO:root:[  100] Training loss: 0.62040719, Validation loss: 0.62444198, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12878.30859375MB; mem (CPU total)=34012.85546875MB
INFO:root:[  101] Training loss: 0.61951059, Validation loss: 0.62387792, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12916.40625MB; mem (CPU total)=34082.4453125MB
INFO:root:[  102] Training loss: 0.61911130, Validation loss: 0.62319938, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12954.50390625MB; mem (CPU total)=34152.828125MB
INFO:root:[  103] Training loss: 0.61936780, Validation loss: 0.62329075, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12992.59765625MB; mem (CPU total)=34222.46875MB
INFO:root:[  104] Training loss: 0.61904838, Validation loss: 0.62321223, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13030.6953125MB; mem (CPU total)=34293.54296875MB
INFO:root:[  105] Training loss: 0.61867879, Validation loss: 0.62364798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13068.7890625MB; mem (CPU total)=34370.078125MB
INFO:root:[  106] Training loss: 0.61847798, Validation loss: 0.62217835, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13106.8828125MB; mem (CPU total)=34446.09765625MB
INFO:root:[  107] Training loss: 0.61779975, Validation loss: 0.62168734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13144.98046875MB; mem (CPU total)=34522.37890625MB
INFO:root:[  108] Training loss: 0.61752906, Validation loss: 0.62064679, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13183.07421875MB; mem (CPU total)=34599.16015625MB
INFO:root:[  109] Training loss: 0.61675920, Validation loss: 0.62248288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13221.171875MB; mem (CPU total)=34670.03515625MB
INFO:root:[  110] Training loss: 0.61695960, Validation loss: 0.62264663, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13259.265625MB; mem (CPU total)=34739.84765625MB
INFO:root:[  111] Training loss: 0.61630818, Validation loss: 0.62212936, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13297.3671875MB; mem (CPU total)=34809.7109375MB
INFO:root:[  112] Training loss: 0.61642745, Validation loss: 0.62181646, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13335.4609375MB; mem (CPU total)=34880.0078125MB
INFO:root:[  113] Training loss: 0.61589152, Validation loss: 0.62194726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13373.5546875MB; mem (CPU total)=34949.75MB
INFO:root:[  114] Training loss: 0.61597412, Validation loss: 0.62074024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13411.65234375MB; mem (CPU total)=35020.13671875MB
INFO:root:[  115] Training loss: 0.61493897, Validation loss: 0.62103803, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13449.74609375MB; mem (CPU total)=35095.4609375MB
INFO:root:[  116] Training loss: 0.61505092, Validation loss: 0.61969810, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13487.83984375MB; mem (CPU total)=35171.72265625MB
INFO:root:[  117] Training loss: 0.61435920, Validation loss: 0.62084100, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13525.93359375MB; mem (CPU total)=35247.8203125MB
INFO:root:[  118] Training loss: 0.61431630, Validation loss: 0.61953434, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13564.0390625MB; mem (CPU total)=35323.84375MB
INFO:root:[  119] Training loss: 0.61371343, Validation loss: 0.61973785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13602.1328125MB; mem (CPU total)=35396.390625MB
INFO:root:[  120] Training loss: 0.61437362, Validation loss: 0.61897625, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13640.23046875MB; mem (CPU total)=35466.28125MB
INFO:root:[  121] Training loss: 0.61324787, Validation loss: 0.61870050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13678.328125MB; mem (CPU total)=35534.9765625MB
INFO:root:[  122] Training loss: 0.61277471, Validation loss: 0.62000921, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13716.421875MB; mem (CPU total)=35603.828125MB
INFO:root:[  123] Training loss: 0.61283553, Validation loss: 0.61846252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13754.515625MB; mem (CPU total)=35672.71875MB
INFO:root:[  124] Training loss: 0.61291354, Validation loss: 0.61856768, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13792.61328125MB; mem (CPU total)=35742.88671875MB
INFO:root:[  125] Training loss: 0.61210028, Validation loss: 0.61886571, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13830.70703125MB; mem (CPU total)=35819.16796875MB
INFO:root:[  126] Training loss: 0.61214556, Validation loss: 0.61939878, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13868.80078125MB; mem (CPU total)=35895.19140625MB
INFO:root:[  127] Training loss: 0.61201282, Validation loss: 0.61815629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13906.8984375MB; mem (CPU total)=35971.7109375MB
INFO:root:[  128] Training loss: 0.61269692, Validation loss: 0.61733865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13944.99609375MB; mem (CPU total)=36047.9453125MB
INFO:root:[  129] Training loss: 0.61164690, Validation loss: 0.61604415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13983.08984375MB; mem (CPU total)=36117.54296875MB
INFO:root:[  130] Training loss: 0.61168979, Validation loss: 0.61689969, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14021.18359375MB; mem (CPU total)=36187.65234375MB
INFO:root:[  131] Training loss: 0.61124273, Validation loss: 0.61664203, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14059.28125MB; mem (CPU total)=36257.05078125MB
INFO:root:[  132] Training loss: 0.61089729, Validation loss: 0.61671649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14097.375MB; mem (CPU total)=36327.1875MB
INFO:root:[  133] Training loss: 0.60987688, Validation loss: 0.61809262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14135.46875MB; mem (CPU total)=36396.5546875MB
INFO:root:[  134] Training loss: 0.61032993, Validation loss: 0.61680599, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14173.5625MB; mem (CPU total)=36468.10546875MB
INFO:root:[  135] Training loss: 0.60981606, Validation loss: 0.61473002, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14211.6640625MB; mem (CPU total)=36544.82421875MB
INFO:root:[  136] Training loss: 0.60949705, Validation loss: 0.61556613, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14249.7578125MB; mem (CPU total)=36620.71875MB
INFO:root:[  137] Training loss: 0.60970882, Validation loss: 0.61478207, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14287.8515625MB; mem (CPU total)=36697.484375MB
INFO:root:[  138] Training loss: 0.60928790, Validation loss: 0.61617187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14325.94921875MB; mem (CPU total)=36773.71875MB
INFO:root:[  139] Training loss: 0.60929677, Validation loss: 0.61458533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14364.04296875MB; mem (CPU total)=36842.671875MB
INFO:root:[  140] Training loss: 0.60874660, Validation loss: 0.61390230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14402.13671875MB; mem (CPU total)=36913.08984375MB
INFO:root:[  141] Training loss: 0.60814918, Validation loss: 0.61566480, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14440.23828125MB; mem (CPU total)=36982.9921875MB
INFO:root:[  142] Training loss: 0.60818733, Validation loss: 0.61493201, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14478.3359375MB; mem (CPU total)=37052.3828125MB
INFO:root:[  143] Training loss: 0.60842620, Validation loss: 0.61409236, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14516.4296875MB; mem (CPU total)=37122.24609375MB
INFO:root:[  144] Training loss: 0.60777322, Validation loss: 0.61440006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14554.5234375MB; mem (CPU total)=37193.8046875MB
INFO:root:[  145] Training loss: 0.60781967, Validation loss: 0.61410564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14592.62109375MB; mem (CPU total)=37269.79296875MB
INFO:root:[  146] Training loss: 0.60708666, Validation loss: 0.61425007, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14630.71484375MB; mem (CPU total)=37346.01953125MB
INFO:root:[  147] Training loss: 0.60734582, Validation loss: 0.61441224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14668.80859375MB; mem (CPU total)=37422.72265625MB
INFO:root:[  148] Training loss: 0.60656441, Validation loss: 0.61377039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14706.90625MB; mem (CPU total)=37499.52734375MB
INFO:root:[  149] Training loss: 0.60680862, Validation loss: 0.61282992, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14745.0MB; mem (CPU total)=37569.44921875MB
INFO:root:[  150] Training loss: 0.60614415, Validation loss: 0.61285191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14783.09375MB; mem (CPU total)=37639.3359375MB
INFO:root:[  151] Training loss: 0.60632264, Validation loss: 0.61311527, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14821.1875MB; mem (CPU total)=37709.2265625MB
INFO:root:[  152] Training loss: 0.60607420, Validation loss: 0.61252213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14859.28515625MB; mem (CPU total)=37780.39453125MB
INFO:root:[  153] Training loss: 0.60602533, Validation loss: 0.61258873, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14897.38671875MB; mem (CPU total)=37850.06640625MB
INFO:root:[  154] Training loss: 0.60661118, Validation loss: 0.61186690, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14935.48046875MB; mem (CPU total)=37920.95703125MB
INFO:root:[  155] Training loss: 0.60534430, Validation loss: 0.61316323, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14973.578125MB; mem (CPU total)=37997.04296875MB
INFO:root:[  156] Training loss: 0.60537878, Validation loss: 0.61165114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15011.671875MB; mem (CPU total)=38073.328125MB
INFO:root:[  157] Training loss: 0.60454965, Validation loss: 0.61278292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15049.765625MB; mem (CPU total)=38149.625MB
INFO:root:[  158] Training loss: 0.60515103, Validation loss: 0.61390505, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15087.86328125MB; mem (CPU total)=38225.640625MB
INFO:root:[  159] Training loss: 0.60474094, Validation loss: 0.61293058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15125.95703125MB; mem (CPU total)=38298.234375MB
INFO:root:[  160] Training loss: 0.60449128, Validation loss: 0.61146726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15164.05078125MB; mem (CPU total)=38369.2109375MB
INFO:root:[  161] Training loss: 0.60406631, Validation loss: 0.61282984, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15202.14453125MB; mem (CPU total)=38438.296875MB
INFO:root:[  162] Training loss: 0.60379357, Validation loss: 0.61258453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15240.2421875MB; mem (CPU total)=38508.4765625MB
INFO:root:[  163] Training loss: 0.60439496, Validation loss: 0.61092889, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15278.3359375MB; mem (CPU total)=38578.359375MB
INFO:root:[  164] Training loss: 0.60391066, Validation loss: 0.61101406, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15316.43359375MB; mem (CPU total)=38649.02734375MB
INFO:root:[  165] Training loss: 0.60327408, Validation loss: 0.61138520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15354.53125MB; mem (CPU total)=38722.8515625MB
INFO:root:[  166] Training loss: 0.60340045, Validation loss: 0.61051029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15392.625MB; mem (CPU total)=38798.48828125MB
INFO:root:[  167] Training loss: 0.60323758, Validation loss: 0.61029751, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15430.71875MB; mem (CPU total)=38874.77734375MB
INFO:root:[  168] Training loss: 0.60285650, Validation loss: 0.61089804, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15468.8125MB; mem (CPU total)=38951.0390625MB
INFO:root:[  169] Training loss: 0.60255871, Validation loss: 0.61059215, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15506.9140625MB; mem (CPU total)=39027.0703125MB
INFO:root:[  170] Training loss: 0.60225640, Validation loss: 0.60913896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15545.0078125MB; mem (CPU total)=39098.66796875MB
INFO:root:[  171] Training loss: 0.60237119, Validation loss: 0.61087442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15583.1015625MB; mem (CPU total)=39168.8203125MB
INFO:root:[  172] Training loss: 0.60205774, Validation loss: 0.60969495, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15621.19921875MB; mem (CPU total)=39238.9765625MB
INFO:root:[  173] Training loss: 0.60199331, Validation loss: 0.61028326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15659.29296875MB; mem (CPU total)=39309.13671875MB
INFO:root:[  174] Training loss: 0.60187468, Validation loss: 0.60782640, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15697.38671875MB; mem (CPU total)=39379.76953125MB
INFO:root:[  175] Training loss: 0.60209266, Validation loss: 0.61074644, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15735.48828125MB; mem (CPU total)=39449.89453125MB
INFO:root:[  176] Training loss: 0.60138105, Validation loss: 0.60905284, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15773.58203125MB; mem (CPU total)=39523.73046875MB
INFO:root:[  177] Training loss: 0.60061157, Validation loss: 0.60803223, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15811.67578125MB; mem (CPU total)=39600.30078125MB
INFO:root:[  178] Training loss: 0.60127669, Validation loss: 0.60970641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15849.76953125MB; mem (CPU total)=39676.6015625MB
INFO:root:[  179] Training loss: 0.60071977, Validation loss: 0.61048497, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15887.8671875MB; mem (CPU total)=39752.90234375MB
INFO:root:[  180] Training loss: 0.60053457, Validation loss: 0.60866837, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15925.9609375MB; mem (CPU total)=39829.09765625MB
INFO:root:[  181] Training loss: 0.60052637, Validation loss: 0.60972239, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15964.0546875MB; mem (CPU total)=39901.859375MB
INFO:root:[  182] Training loss: 0.60063629, Validation loss: 0.60793628, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16002.15234375MB; mem (CPU total)=39971.42578125MB
INFO:root:[  183] Training loss: 0.60022162, Validation loss: 0.60802876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16040.25MB; mem (CPU total)=40042.84375MB
INFO:root:EP 183: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16078.34375MB; mem (CPU total)=40096.5078125MB
INFO:root:Training the model took 9338.526s.
INFO:root:Emptying the cuda cache took 0.048s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85259
INFO:root:EnergyScoreTrain: 0.60132
INFO:root:CRPSTrain: 0.54011
INFO:root:Gaussian NLLTrain: 3.17992
INFO:root:CoverageTrain: 0.76002
INFO:root:IntervalWidthTrain: 3.13122
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86461
INFO:root:EnergyScoreValidation: 0.60959
INFO:root:CRPSValidation: 0.5465
INFO:root:Gaussian NLLValidation: 3.1915
INFO:root:CoverageValidation: 0.75722
INFO:root:IntervalWidthValidation: 3.13508
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86677
INFO:root:EnergyScoreTest: 0.61103
INFO:root:CRPSTest: 0.54774
INFO:root:Gaussian NLLTest: 3.20331
INFO:root:CoverageTest: 0.7551
INFO:root:IntervalWidthTest: 3.12179
INFO:root:After validation: mem (CPU python)=16121.26953125MB; mem (CPU total)=40292.48046875MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=16121.26953125MB; mem (CPU total)=40303.80078125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=16121.54296875MB; mem (CPU total)=40304.5390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=16121.7265625MB; mem (CPU total)=40321.515625MB
INFO:root:[    1] Training loss: 0.78798496, Validation loss: 0.72631200, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16160.80078125MB; mem (CPU total)=40393.42578125MB
INFO:root:[    2] Training loss: 0.72266731, Validation loss: 0.72450003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16198.8984375MB; mem (CPU total)=40463.64453125MB
INFO:root:[    3] Training loss: 0.72136781, Validation loss: 0.72072261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16237.0078125MB; mem (CPU total)=40533.29296875MB
INFO:root:[    4] Training loss: 0.72063998, Validation loss: 0.72330597, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16275.1171875MB; mem (CPU total)=40604.48046875MB
INFO:root:[    5] Training loss: 0.72076341, Validation loss: 0.72051566, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16313.23046875MB; mem (CPU total)=40675.37890625MB
INFO:root:[    6] Training loss: 0.71966011, Validation loss: 0.72034658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16351.33984375MB; mem (CPU total)=40751.65625MB
INFO:root:[    7] Training loss: 0.71962374, Validation loss: 0.71879530, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16389.44921875MB; mem (CPU total)=40828.23828125MB
INFO:root:[    8] Training loss: 0.71909962, Validation loss: 0.71810560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16427.5625MB; mem (CPU total)=40904.7734375MB
INFO:root:[    9] Training loss: 0.71829920, Validation loss: 0.71752368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16465.65625MB; mem (CPU total)=40980.7578125MB
INFO:root:[   10] Training loss: 0.71609374, Validation loss: 0.71453599, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16503.75MB; mem (CPU total)=41057.56640625MB
INFO:root:[   11] Training loss: 0.71011033, Validation loss: 0.70685342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16541.84375MB; mem (CPU total)=41129.4453125MB
INFO:root:[   12] Training loss: 0.70313261, Validation loss: 0.70011973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16579.94140625MB; mem (CPU total)=41200.34375MB
INFO:root:[   13] Training loss: 0.69748405, Validation loss: 0.69518028, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16618.0390625MB; mem (CPU total)=41270.9921875MB
INFO:root:[   14] Training loss: 0.69280303, Validation loss: 0.69060175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16656.1328125MB; mem (CPU total)=41342.13671875MB
INFO:root:[   15] Training loss: 0.68811946, Validation loss: 0.68609673, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16694.23046875MB; mem (CPU total)=41412.1796875MB
INFO:root:[   16] Training loss: 0.68440060, Validation loss: 0.68147090, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16732.32421875MB; mem (CPU total)=41483.0546875MB
INFO:root:[   17] Training loss: 0.68077979, Validation loss: 0.68011749, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16770.41796875MB; mem (CPU total)=41553.703125MB
INFO:root:[   18] Training loss: 0.67818236, Validation loss: 0.67817192, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16808.515625MB; mem (CPU total)=41629.76171875MB
INFO:root:[   19] Training loss: 0.67496696, Validation loss: 0.67393480, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16846.61328125MB; mem (CPU total)=41706.0703125MB
INFO:root:[   20] Training loss: 0.67290849, Validation loss: 0.67311812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16884.70703125MB; mem (CPU total)=41782.078125MB
INFO:root:[   21] Training loss: 0.67084751, Validation loss: 0.67175778, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16922.80078125MB; mem (CPU total)=41858.2265625MB
INFO:root:[   22] Training loss: 0.66910071, Validation loss: 0.66929960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16960.8984375MB; mem (CPU total)=41934.5234375MB
INFO:root:[   23] Training loss: 0.66792876, Validation loss: 0.66719775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16998.9921875MB; mem (CPU total)=42009.32421875MB
INFO:root:[   24] Training loss: 0.66606998, Validation loss: 0.66714932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17037.0859375MB; mem (CPU total)=42079.20703125MB
INFO:root:[   25] Training loss: 0.66446928, Validation loss: 0.66552863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17075.18359375MB; mem (CPU total)=42150.2890625MB
INFO:root:[   26] Training loss: 0.66378611, Validation loss: 0.66334968, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17113.27734375MB; mem (CPU total)=42221.4296875MB
INFO:root:[   27] Training loss: 0.66198867, Validation loss: 0.66111286, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17151.375MB; mem (CPU total)=42292.59765625MB
INFO:root:[   28] Training loss: 0.66066911, Validation loss: 0.66105825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17189.46875MB; mem (CPU total)=42363.27734375MB
INFO:root:[   29] Training loss: 0.65987669, Validation loss: 0.66008531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17227.56640625MB; mem (CPU total)=42435.29296875MB
INFO:root:[   30] Training loss: 0.65810684, Validation loss: 0.65983943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17265.66015625MB; mem (CPU total)=42506.09765625MB
INFO:root:[   31] Training loss: 0.65740471, Validation loss: 0.65914728, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17303.75390625MB; mem (CPU total)=42582.41015625MB
INFO:root:[   32] Training loss: 0.65665967, Validation loss: 0.65808851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17341.8515625MB; mem (CPU total)=42658.82421875MB
INFO:root:[   33] Training loss: 0.65502456, Validation loss: 0.65606483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17379.94921875MB; mem (CPU total)=42734.87890625MB
INFO:root:[   34] Training loss: 0.65471777, Validation loss: 0.65594010, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17418.04296875MB; mem (CPU total)=42811.61328125MB
INFO:root:[   35] Training loss: 0.65265982, Validation loss: 0.65510236, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17456.140625MB; mem (CPU total)=42887.92578125MB
INFO:root:[   36] Training loss: 0.65206415, Validation loss: 0.65276851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17494.23828125MB; mem (CPU total)=42964.0234375MB
INFO:root:[   37] Training loss: 0.65154426, Validation loss: 0.65500812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17532.33203125MB; mem (CPU total)=43040.140625MB
INFO:root:[   38] Training loss: 0.65114155, Validation loss: 0.65191039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17570.42578125MB; mem (CPU total)=43110.78515625MB
INFO:root:[   39] Training loss: 0.64930692, Validation loss: 0.65030230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17608.5234375MB; mem (CPU total)=43182.00390625MB
INFO:root:[   40] Training loss: 0.64838586, Validation loss: 0.64995431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17646.62109375MB; mem (CPU total)=43253.640625MB
INFO:root:[   41] Training loss: 0.64684402, Validation loss: 0.64925820, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17684.7109375MB; mem (CPU total)=43325.51953125MB
INFO:root:[   42] Training loss: 0.64591234, Validation loss: 0.64808853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17722.8125MB; mem (CPU total)=43397.2578125MB
INFO:root:[   43] Training loss: 0.64583817, Validation loss: 0.64888326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17760.90625MB; mem (CPU total)=43469.5546875MB
INFO:root:[   44] Training loss: 0.64493234, Validation loss: 0.64820396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17799.0MB; mem (CPU total)=43541.42578125MB
INFO:root:[   45] Training loss: 0.64387788, Validation loss: 0.64649794, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17837.09375MB; mem (CPU total)=43613.0625MB
INFO:root:[   46] Training loss: 0.64326362, Validation loss: 0.64670759, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17875.19140625MB; mem (CPU total)=43689.62109375MB
INFO:root:[   47] Training loss: 0.64223262, Validation loss: 0.64564539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17913.28515625MB; mem (CPU total)=43765.890625MB
INFO:root:[   48] Training loss: 0.64202749, Validation loss: 0.64465757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17951.3828125MB; mem (CPU total)=43842.1953125MB
INFO:root:[   49] Training loss: 0.64054933, Validation loss: 0.64291304, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17989.48046875MB; mem (CPU total)=43918.26171875MB
INFO:root:[   50] Training loss: 0.64058634, Validation loss: 0.64331950, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18027.57421875MB; mem (CPU total)=43994.32421875MB
INFO:root:[   51] Training loss: 0.64000567, Validation loss: 0.64218958, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18065.66796875MB; mem (CPU total)=44070.78515625MB
INFO:root:[   52] Training loss: 0.63868676, Validation loss: 0.64080522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18103.76171875MB; mem (CPU total)=44147.34375MB
INFO:root:[   53] Training loss: 0.63777541, Validation loss: 0.64111501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18141.859375MB; mem (CPU total)=44221.4296875MB
INFO:root:[   54] Training loss: 0.63729214, Validation loss: 0.64034942, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18179.953125MB; mem (CPU total)=44293.796875MB
INFO:root:[   55] Training loss: 0.63654184, Validation loss: 0.63948292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18218.05078125MB; mem (CPU total)=44365.2890625MB
INFO:root:[   56] Training loss: 0.63605862, Validation loss: 0.64098304, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18256.1484375MB; mem (CPU total)=44437.4140625MB
INFO:root:[   57] Training loss: 0.63573322, Validation loss: 0.63938335, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18294.2421875MB; mem (CPU total)=44510.03515625MB
INFO:root:[   58] Training loss: 0.63578353, Validation loss: 0.63694635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18332.3359375MB; mem (CPU total)=44582.1640625MB
INFO:root:[   59] Training loss: 0.63438816, Validation loss: 0.63819149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18370.43359375MB; mem (CPU total)=44654.77734375MB
INFO:root:[   60] Training loss: 0.63304672, Validation loss: 0.63633729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18408.52734375MB; mem (CPU total)=44727.3515625MB
INFO:root:[   61] Training loss: 0.63293051, Validation loss: 0.63489738, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18446.62109375MB; mem (CPU total)=44799.2265625MB
INFO:root:[   62] Training loss: 0.63308468, Validation loss: 0.63488499, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18484.71484375MB; mem (CPU total)=44873.078125MB
INFO:root:[   63] Training loss: 0.63206732, Validation loss: 0.63508756, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18522.8125MB; mem (CPU total)=44949.32421875MB
INFO:root:[   64] Training loss: 0.63238398, Validation loss: 0.63686471, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18560.91015625MB; mem (CPU total)=45025.9375MB
INFO:root:[   65] Training loss: 0.63136661, Validation loss: 0.63425082, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18599.00390625MB; mem (CPU total)=45101.97265625MB
INFO:root:[   66] Training loss: 0.63106464, Validation loss: 0.63463870, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18637.1015625MB; mem (CPU total)=45177.76953125MB
INFO:root:[   67] Training loss: 0.63081911, Validation loss: 0.63319801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18675.1953125MB; mem (CPU total)=45254.04296875MB
INFO:root:[   68] Training loss: 0.62941161, Validation loss: 0.63231073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18713.2890625MB; mem (CPU total)=45329.69921875MB
INFO:root:[   69] Training loss: 0.62915026, Validation loss: 0.63296749, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18751.3828125MB; mem (CPU total)=45405.890625MB
INFO:root:[   70] Training loss: 0.62880976, Validation loss: 0.63191016, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18789.484375MB; mem (CPU total)=45513.78515625MB
INFO:root:[   71] Training loss: 0.62854059, Validation loss: 0.63364386, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18827.578125MB; mem (CPU total)=45549.50390625MB
INFO:root:[   72] Training loss: 0.62790944, Validation loss: 0.63301819, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18865.671875MB; mem (CPU total)=45601.21484375MB
INFO:root:[   73] Training loss: 0.62792835, Validation loss: 0.63188825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18903.76953125MB; mem (CPU total)=45677.5078125MB
INFO:root:[   74] Training loss: 0.62777123, Validation loss: 0.63113735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18941.86328125MB; mem (CPU total)=45753.55078125MB
INFO:root:[   75] Training loss: 0.62677106, Validation loss: 0.63044741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18979.95703125MB; mem (CPU total)=45825.95703125MB
INFO:root:[   76] Training loss: 0.62717966, Validation loss: 0.63132005, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19018.0546875MB; mem (CPU total)=45898.5078125MB
INFO:root:[   77] Training loss: 0.62615975, Validation loss: 0.63227889, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19056.15234375MB; mem (CPU total)=45970.87890625MB
INFO:root:[   78] Training loss: 0.62609655, Validation loss: 0.62913420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19094.24609375MB; mem (CPU total)=46043.0078125MB
INFO:root:[   79] Training loss: 0.62519487, Validation loss: 0.62998156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19132.33984375MB; mem (CPU total)=46116.015625MB
INFO:root:[   80] Training loss: 0.62467667, Validation loss: 0.62908291, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19170.4375MB; mem (CPU total)=46188.3828125MB
INFO:root:[   81] Training loss: 0.62423922, Validation loss: 0.62776214, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19208.53125MB; mem (CPU total)=46260.78515625MB
INFO:root:[   82] Training loss: 0.62388216, Validation loss: 0.62866292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19246.625MB; mem (CPU total)=46333.38671875MB
INFO:root:[   83] Training loss: 0.62431361, Validation loss: 0.62896637, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19284.72265625MB; mem (CPU total)=46406.234375MB
INFO:root:[   84] Training loss: 0.62407364, Validation loss: 0.62766245, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19322.81640625MB; mem (CPU total)=46479.1015625MB
INFO:root:[   85] Training loss: 0.62295753, Validation loss: 0.62653131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19360.91015625MB; mem (CPU total)=46555.4140625MB
INFO:root:[   86] Training loss: 0.62216702, Validation loss: 0.62784408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19399.01171875MB; mem (CPU total)=46631.796875MB
INFO:root:[   87] Training loss: 0.62176250, Validation loss: 0.62727189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19437.109375MB; mem (CPU total)=46707.29296875MB
INFO:root:[   88] Training loss: 0.62214350, Validation loss: 0.62786219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19475.203125MB; mem (CPU total)=46783.0859375MB
INFO:root:[   89] Training loss: 0.62159328, Validation loss: 0.62415285, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19513.296875MB; mem (CPU total)=46859.4453125MB
INFO:root:[   90] Training loss: 0.62071897, Validation loss: 0.62571743, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19551.39453125MB; mem (CPU total)=46937.0625MB
INFO:root:[   91] Training loss: 0.62067896, Validation loss: 0.62613483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19589.48828125MB; mem (CPU total)=47013.58984375MB
INFO:root:[   92] Training loss: 0.62137566, Validation loss: 0.62597011, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19627.58203125MB; mem (CPU total)=47089.9296875MB
INFO:root:[   93] Training loss: 0.62056146, Validation loss: 0.62491679, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19665.6796875MB; mem (CPU total)=47166.0625MB
INFO:root:[   94] Training loss: 0.62001106, Validation loss: 0.62278771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19703.77734375MB; mem (CPU total)=47240.13671875MB
INFO:root:[   95] Training loss: 0.61990611, Validation loss: 0.62437369, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19741.87109375MB; mem (CPU total)=47312.875MB
INFO:root:[   96] Training loss: 0.61930999, Validation loss: 0.62363740, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19779.96484375MB; mem (CPU total)=47385.1953125MB
INFO:root:[   97] Training loss: 0.61888610, Validation loss: 0.62367754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19818.0625MB; mem (CPU total)=47458.31640625MB
INFO:root:[   98] Training loss: 0.61900925, Validation loss: 0.62434082, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19856.15625MB; mem (CPU total)=47530.69921875MB
INFO:root:[   99] Training loss: 0.61768067, Validation loss: 0.62327717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19894.25MB; mem (CPU total)=47603.6328125MB
INFO:root:[  100] Training loss: 0.61889671, Validation loss: 0.62474931, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19932.3515625MB; mem (CPU total)=47676.734375MB
INFO:root:[  101] Training loss: 0.61816446, Validation loss: 0.62135403, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19970.4453125MB; mem (CPU total)=47749.6015625MB
INFO:root:[  102] Training loss: 0.61729505, Validation loss: 0.62292750, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20008.53515625MB; mem (CPU total)=47823.0859375MB
INFO:root:[  103] Training loss: 0.61751953, Validation loss: 0.62284639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20046.62890625MB; mem (CPU total)=47895.67578125MB
INFO:root:[  104] Training loss: 0.61751645, Validation loss: 0.62331799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20084.734375MB; mem (CPU total)=47968.75390625MB
INFO:root:[  105] Training loss: 0.61739071, Validation loss: 0.62237875, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20122.828125MB; mem (CPU total)=48043.8125MB
INFO:root:[  106] Training loss: 0.61693374, Validation loss: 0.62187313, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20160.921875MB; mem (CPU total)=48119.76171875MB
INFO:root:[  107] Training loss: 0.61612723, Validation loss: 0.62022098, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20199.015625MB; mem (CPU total)=48196.328125MB
INFO:root:[  108] Training loss: 0.61659218, Validation loss: 0.62232822, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20237.11328125MB; mem (CPU total)=48272.59765625MB
INFO:root:[  109] Training loss: 0.61632989, Validation loss: 0.61981569, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20275.20703125MB; mem (CPU total)=48348.734375MB
INFO:root:[  110] Training loss: 0.61535312, Validation loss: 0.62197396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20313.30859375MB; mem (CPU total)=48425.28515625MB
INFO:root:[  111] Training loss: 0.61512534, Validation loss: 0.62079818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20351.40234375MB; mem (CPU total)=48501.57421875MB
INFO:root:[  112] Training loss: 0.61507817, Validation loss: 0.62210195, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20389.49609375MB; mem (CPU total)=48578.1015625MB
INFO:root:[  113] Training loss: 0.61530195, Validation loss: 0.62149164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20427.58984375MB; mem (CPU total)=48654.21875MB
INFO:root:[  114] Training loss: 0.61529579, Validation loss: 0.62093157, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20465.6875MB; mem (CPU total)=48730.19140625MB
INFO:root:[  115] Training loss: 0.61482755, Validation loss: 0.62036894, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20503.78125MB; mem (CPU total)=48806.48046875MB
INFO:root:[  116] Training loss: 0.61393252, Validation loss: 0.62096016, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20541.875MB; mem (CPU total)=48880.0625MB
INFO:root:[  117] Training loss: 0.61435917, Validation loss: 0.62045869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20579.97265625MB; mem (CPU total)=48953.15234375MB
INFO:root:[  118] Training loss: 0.61296953, Validation loss: 0.62016726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20618.0703125MB; mem (CPU total)=49025.2265625MB
INFO:root:EP 118: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=20656.1328125MB; mem (CPU total)=49075.08984375MB
INFO:root:Training the model took 6959.74s.
INFO:root:Emptying the cuda cache took 0.046s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87244
INFO:root:EnergyScoreTrain: 0.61539
INFO:root:CRPSTrain: 0.56515
INFO:root:Gaussian NLLTrain: 4.3591
INFO:root:CoverageTrain: 0.72953
INFO:root:IntervalWidthTrain: 3.07851
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88136
INFO:root:EnergyScoreValidation: 0.62149
INFO:root:CRPSValidation: 0.56995
INFO:root:Gaussian NLLValidation: 4.37621
INFO:root:CoverageValidation: 0.72719
INFO:root:IntervalWidthValidation: 3.07638
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88234
INFO:root:EnergyScoreTest: 0.62216
INFO:root:CRPSTest: 0.57076
INFO:root:Gaussian NLLTest: 4.38065
INFO:root:CoverageTest: 0.72591
INFO:root:IntervalWidthTest: 3.07464
INFO:root:After validation: mem (CPU python)=20699.08203125MB; mem (CPU total)=49270.2890625MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=20699.08203125MB; mem (CPU total)=49272.7890625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=20699.53515625MB; mem (CPU total)=49274.015625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=20699.53515625MB; mem (CPU total)=49297.39453125MB
INFO:root:[    1] Training loss: 0.78242197, Validation loss: 0.72338053, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20737.51953125MB; mem (CPU total)=49370.30859375MB
INFO:root:[    2] Training loss: 0.72341877, Validation loss: 0.72135950, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20775.6171875MB; mem (CPU total)=49443.421875MB
INFO:root:[    3] Training loss: 0.72144628, Validation loss: 0.72032721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20813.734375MB; mem (CPU total)=49515.828125MB
INFO:root:[    4] Training loss: 0.72001472, Validation loss: 0.72072493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20851.84375MB; mem (CPU total)=49588.6875MB
INFO:root:[    5] Training loss: 0.72001264, Validation loss: 0.71934382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20889.953125MB; mem (CPU total)=49661.5546875MB
INFO:root:[    6] Training loss: 0.71922890, Validation loss: 0.71973716, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20928.06640625MB; mem (CPU total)=49734.66015625MB
INFO:root:[    7] Training loss: 0.71859080, Validation loss: 0.71820641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20966.17578125MB; mem (CPU total)=49806.10546875MB
INFO:root:[    8] Training loss: 0.71781219, Validation loss: 0.71695424, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21004.26953125MB; mem (CPU total)=49881.1875MB
INFO:root:[    9] Training loss: 0.71551765, Validation loss: 0.71351049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21042.36328125MB; mem (CPU total)=49957.76171875MB
INFO:root:[   10] Training loss: 0.70931822, Validation loss: 0.70492542, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21080.4609375MB; mem (CPU total)=50033.8125MB
INFO:root:[   11] Training loss: 0.69965201, Validation loss: 0.69540779, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21118.55859375MB; mem (CPU total)=50110.56640625MB
INFO:root:[   12] Training loss: 0.69040239, Validation loss: 0.68630878, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21156.65234375MB; mem (CPU total)=50186.38671875MB
INFO:root:[   13] Training loss: 0.68337701, Validation loss: 0.68228349, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21194.75MB; mem (CPU total)=50262.4375MB
INFO:root:[   14] Training loss: 0.67860250, Validation loss: 0.67714465, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21232.84375MB; mem (CPU total)=50339.2109375MB
INFO:root:[   15] Training loss: 0.67442542, Validation loss: 0.67323278, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21270.9375MB; mem (CPU total)=50415.5234375MB
INFO:root:[   16] Training loss: 0.67069328, Validation loss: 0.67064973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21309.03515625MB; mem (CPU total)=50492.21875MB
INFO:root:[   17] Training loss: 0.66775400, Validation loss: 0.66749301, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21347.1328125MB; mem (CPU total)=50568.28515625MB
INFO:root:[   18] Training loss: 0.66481329, Validation loss: 0.66522035, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21385.22265625MB; mem (CPU total)=50640.6796875MB
INFO:root:[   19] Training loss: 0.66294445, Validation loss: 0.66293086, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21423.3203125MB; mem (CPU total)=50713.38671875MB
INFO:root:[   20] Training loss: 0.66060935, Validation loss: 0.66200103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21461.41796875MB; mem (CPU total)=50786.30859375MB
INFO:root:[   21] Training loss: 0.65918566, Validation loss: 0.65973607, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21499.51171875MB; mem (CPU total)=50858.0078125MB
INFO:root:[   22] Training loss: 0.65715211, Validation loss: 0.65894033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21537.60546875MB; mem (CPU total)=50930.1328125MB
INFO:root:[   23] Training loss: 0.65552264, Validation loss: 0.65670855, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21575.7109375MB; mem (CPU total)=51003.4296875MB
INFO:root:[   24] Training loss: 0.65433570, Validation loss: 0.65492846, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21613.80078125MB; mem (CPU total)=51076.4609375MB
INFO:root:[   25] Training loss: 0.65332667, Validation loss: 0.65515732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21651.8984375MB; mem (CPU total)=51148.69140625MB
INFO:root:[   26] Training loss: 0.65201204, Validation loss: 0.65346011, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21689.9921875MB; mem (CPU total)=51222.05078125MB
INFO:root:[   27] Training loss: 0.65090983, Validation loss: 0.65196889, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21728.08984375MB; mem (CPU total)=51294.66015625MB
INFO:root:[   28] Training loss: 0.64974747, Validation loss: 0.65165769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21766.18359375MB; mem (CPU total)=51371.01171875MB
INFO:root:[   29] Training loss: 0.64805631, Validation loss: 0.65063798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21804.27734375MB; mem (CPU total)=51447.3125MB
INFO:root:[   30] Training loss: 0.64762802, Validation loss: 0.64942045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21842.375MB; mem (CPU total)=51523.87109375MB
INFO:root:[   31] Training loss: 0.64679443, Validation loss: 0.64975457, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21880.47265625MB; mem (CPU total)=51600.18359375MB
INFO:root:[   32] Training loss: 0.64605303, Validation loss: 0.64772397, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21918.56640625MB; mem (CPU total)=51676.49609375MB
INFO:root:[   33] Training loss: 0.64505972, Validation loss: 0.64676416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21956.66015625MB; mem (CPU total)=51752.5625MB
INFO:root:[   34] Training loss: 0.64417380, Validation loss: 0.64648968, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21994.75390625MB; mem (CPU total)=51829.125MB
INFO:root:[   35] Training loss: 0.64351473, Validation loss: 0.64553633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22032.84765625MB; mem (CPU total)=51905.91796875MB
INFO:root:[   36] Training loss: 0.64248797, Validation loss: 0.64458621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22070.94140625MB; mem (CPU total)=51981.01953125MB
INFO:root:[   37] Training loss: 0.64176079, Validation loss: 0.64415725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22109.04296875MB; mem (CPU total)=52052.1484375MB
INFO:root:[   38] Training loss: 0.64081864, Validation loss: 0.64267085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22147.13671875MB; mem (CPU total)=52124.046875MB
INFO:root:[   39] Training loss: 0.64016754, Validation loss: 0.64211969, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22185.23046875MB; mem (CPU total)=52195.859375MB
INFO:root:[   40] Training loss: 0.63981785, Validation loss: 0.64284060, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22223.3515625MB; mem (CPU total)=52268.4609375MB
INFO:root:[   41] Training loss: 0.63848135, Validation loss: 0.64131201, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22261.4453125MB; mem (CPU total)=52340.55859375MB
INFO:root:[   42] Training loss: 0.63775660, Validation loss: 0.64095342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22299.5390625MB; mem (CPU total)=52412.41015625MB
INFO:root:[   43] Training loss: 0.63739746, Validation loss: 0.64171865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22337.6328125MB; mem (CPU total)=52483.9609375MB
INFO:root:[   44] Training loss: 0.63656366, Validation loss: 0.64048148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22375.73046875MB; mem (CPU total)=52555.77734375MB
INFO:root:[   45] Training loss: 0.63586351, Validation loss: 0.63881656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22413.82421875MB; mem (CPU total)=52630.1328125MB
INFO:root:[   46] Training loss: 0.63549011, Validation loss: 0.63949033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22451.91796875MB; mem (CPU total)=52706.4296875MB
INFO:root:[   47] Training loss: 0.63457665, Validation loss: 0.63852314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22490.01953125MB; mem (CPU total)=52783.27734375MB
INFO:root:[   48] Training loss: 0.63394910, Validation loss: 0.63782017, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22528.109375MB; mem (CPU total)=52859.7578125MB
INFO:root:[   49] Training loss: 0.63363444, Validation loss: 0.63759806, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22566.20703125MB; mem (CPU total)=52935.82421875MB
INFO:root:[   50] Training loss: 0.63288688, Validation loss: 0.63623650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22604.3046875MB; mem (CPU total)=53012.13671875MB
INFO:root:[   51] Training loss: 0.63181307, Validation loss: 0.63590685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22642.3984375MB; mem (CPU total)=53088.6640625MB
INFO:root:[   52] Training loss: 0.63138884, Validation loss: 0.63617114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22680.4921875MB; mem (CPU total)=53164.69140625MB
INFO:root:[   53] Training loss: 0.63098242, Validation loss: 0.63460836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22718.5859375MB; mem (CPU total)=53241.4375MB
INFO:root:[   54] Training loss: 0.63067625, Validation loss: 0.63538762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22756.68359375MB; mem (CPU total)=53314.08203125MB
INFO:root:[   55] Training loss: 0.62973060, Validation loss: 0.63482094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22794.77734375MB; mem (CPU total)=53385.96484375MB
INFO:root:[   56] Training loss: 0.62976540, Validation loss: 0.63445129, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22832.875MB; mem (CPU total)=53457.83984375MB
INFO:root:[   57] Training loss: 0.62844770, Validation loss: 0.63371829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22870.97265625MB; mem (CPU total)=53529.41796875MB
INFO:root:[   58] Training loss: 0.62809582, Validation loss: 0.63310551, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22909.06640625MB; mem (CPU total)=53600.94921875MB
INFO:root:[   59] Training loss: 0.62785159, Validation loss: 0.63356587, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22947.16015625MB; mem (CPU total)=53673.08203125MB
INFO:root:[   60] Training loss: 0.62700828, Validation loss: 0.63204283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22985.2578125MB; mem (CPU total)=53744.82421875MB
INFO:root:[   61] Training loss: 0.62651681, Validation loss: 0.63367649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23023.35546875MB; mem (CPU total)=53815.72265625MB
INFO:root:[   62] Training loss: 0.62600832, Validation loss: 0.63220214, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23061.453125MB; mem (CPU total)=53890.3125MB
INFO:root:[   63] Training loss: 0.62628524, Validation loss: 0.63228646, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23099.546875MB; mem (CPU total)=53966.10546875MB
INFO:root:[   64] Training loss: 0.62518383, Validation loss: 0.63108719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23137.64453125MB; mem (CPU total)=54042.3203125MB
INFO:root:[   65] Training loss: 0.62500339, Validation loss: 0.63108406, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23175.73828125MB; mem (CPU total)=54118.796875MB
INFO:root:[   66] Training loss: 0.62463771, Validation loss: 0.63012451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23213.83203125MB; mem (CPU total)=54195.39453125MB
INFO:root:[   67] Training loss: 0.62402194, Validation loss: 0.62908357, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23251.9296875MB; mem (CPU total)=54271.6875MB
INFO:root:[   68] Training loss: 0.62369821, Validation loss: 0.62946231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23290.0234375MB; mem (CPU total)=54348.0234375MB
INFO:root:[   69] Training loss: 0.62294364, Validation loss: 0.62914521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23328.1171875MB; mem (CPU total)=54424.328125MB
INFO:root:[   70] Training loss: 0.62262714, Validation loss: 0.62908451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23366.21484375MB; mem (CPU total)=54499.1328125MB
INFO:root:[   71] Training loss: 0.62235781, Validation loss: 0.62943193, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23404.30859375MB; mem (CPU total)=54570.25MB
INFO:root:[   72] Training loss: 0.62196250, Validation loss: 0.62786955, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23442.40625MB; mem (CPU total)=54641.0859375MB
INFO:root:[   73] Training loss: 0.62167179, Validation loss: 0.62967188, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23480.5MB; mem (CPU total)=54712.46875MB
INFO:root:[   74] Training loss: 0.62136811, Validation loss: 0.62811110, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23518.59765625MB; mem (CPU total)=54784.66015625MB
INFO:root:[   75] Training loss: 0.62088988, Validation loss: 0.63006689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23556.69140625MB; mem (CPU total)=54855.80078125MB
INFO:root:[   76] Training loss: 0.62054437, Validation loss: 0.62749131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23594.78515625MB; mem (CPU total)=54927.69140625MB
INFO:root:[   77] Training loss: 0.62020727, Validation loss: 0.62734580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23632.87890625MB; mem (CPU total)=54999.0546875MB
INFO:root:[   78] Training loss: 0.62011794, Validation loss: 0.62606752, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23670.9765625MB; mem (CPU total)=55072.890625MB
INFO:root:[   79] Training loss: 0.61951833, Validation loss: 0.62610991, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23709.0703125MB; mem (CPU total)=55149.20703125MB
INFO:root:[   80] Training loss: 0.61896222, Validation loss: 0.62521817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23747.16796875MB; mem (CPU total)=55225.515625MB
INFO:root:[   81] Training loss: 0.61866133, Validation loss: 0.62644249, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23785.265625MB; mem (CPU total)=55301.95703125MB
INFO:root:[   82] Training loss: 0.61886305, Validation loss: 0.62749587, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23823.359375MB; mem (CPU total)=55378.0234375MB
INFO:root:[   83] Training loss: 0.61810428, Validation loss: 0.62538449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23861.453125MB; mem (CPU total)=55454.33203125MB
INFO:root:[   84] Training loss: 0.61770553, Validation loss: 0.62454604, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23899.55078125MB; mem (CPU total)=55530.91015625MB
INFO:root:[   85] Training loss: 0.61754662, Validation loss: 0.62542513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23937.64453125MB; mem (CPU total)=55607.19140625MB
INFO:root:[   86] Training loss: 0.61728068, Validation loss: 0.62443412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23975.73828125MB; mem (CPU total)=55679.0703125MB
INFO:root:[   87] Training loss: 0.61674362, Validation loss: 0.62546934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24013.83203125MB; mem (CPU total)=55749.72265625MB
INFO:root:[   88] Training loss: 0.61662773, Validation loss: 0.62546263, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24051.93359375MB; mem (CPU total)=55820.8359375MB
INFO:root:[   89] Training loss: 0.61616036, Validation loss: 0.62374446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24090.02734375MB; mem (CPU total)=55892.3046875MB
INFO:root:[   90] Training loss: 0.61522649, Validation loss: 0.62449782, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24128.12109375MB; mem (CPU total)=55963.9609375MB
INFO:root:[   91] Training loss: 0.61534331, Validation loss: 0.62367147, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24166.21875MB; mem (CPU total)=56034.61328125MB
INFO:root:[   92] Training loss: 0.61509840, Validation loss: 0.62224040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24204.31640625MB; mem (CPU total)=56105.99609375MB
INFO:root:[   93] Training loss: 0.61510663, Validation loss: 0.62423150, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24242.41015625MB; mem (CPU total)=56179.8828125MB
INFO:root:[   94] Training loss: 0.61435761, Validation loss: 0.62251672, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24280.50390625MB; mem (CPU total)=56256.75390625MB
INFO:root:[   95] Training loss: 0.61405266, Validation loss: 0.62318178, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24318.6015625MB; mem (CPU total)=56333.49609375MB
INFO:root:[   96] Training loss: 0.61370542, Validation loss: 0.62343534, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24356.69921875MB; mem (CPU total)=56409.8125MB
INFO:root:[   97] Training loss: 0.61387772, Validation loss: 0.62285728, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24394.79296875MB; mem (CPU total)=56486.046875MB
INFO:root:[   98] Training loss: 0.61403351, Validation loss: 0.62270916, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24432.890625MB; mem (CPU total)=56562.66015625MB
INFO:root:[   99] Training loss: 0.61300505, Validation loss: 0.62171536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24470.984375MB; mem (CPU total)=56638.98046875MB
INFO:root:[  100] Training loss: 0.61311903, Validation loss: 0.62256040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24509.078125MB; mem (CPU total)=56714.28125MB
INFO:root:[  101] Training loss: 0.61250206, Validation loss: 0.62283197, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24547.17578125MB; mem (CPU total)=56784.640625MB
INFO:root:[  102] Training loss: 0.61217603, Validation loss: 0.62311502, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24585.26953125MB; mem (CPU total)=56855.23828125MB
INFO:root:[  103] Training loss: 0.61185742, Validation loss: 0.62330947, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24623.36328125MB; mem (CPU total)=56926.16015625MB
INFO:root:[  104] Training loss: 0.61198972, Validation loss: 0.62359280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24661.4609375MB; mem (CPU total)=56997.15234375MB
INFO:root:[  105] Training loss: 0.61128647, Validation loss: 0.62153364, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24699.55859375MB; mem (CPU total)=57068.484375MB
INFO:root:[  106] Training loss: 0.61131491, Validation loss: 0.62116096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24737.65234375MB; mem (CPU total)=57139.3671875MB
INFO:root:[  107] Training loss: 0.61130247, Validation loss: 0.62052064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24775.74609375MB; mem (CPU total)=57211.8125MB
INFO:root:[  108] Training loss: 0.61073826, Validation loss: 0.62188910, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24813.84375MB; mem (CPU total)=57287.8515625MB
INFO:root:[  109] Training loss: 0.61002547, Validation loss: 0.62180170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24851.9375MB; mem (CPU total)=57364.140625MB
INFO:root:[  110] Training loss: 0.60990525, Validation loss: 0.62046850, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24890.03125MB; mem (CPU total)=57440.66796875MB
INFO:root:[  111] Training loss: 0.61031914, Validation loss: 0.62067039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24928.125MB; mem (CPU total)=57517.14453125MB
INFO:root:[  112] Training loss: 0.60981372, Validation loss: 0.62121740, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24966.22265625MB; mem (CPU total)=57593.46484375MB
INFO:root:[  113] Training loss: 0.60908168, Validation loss: 0.62093738, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25004.3203125MB; mem (CPU total)=57669.0390625MB
INFO:root:[  114] Training loss: 0.60964960, Validation loss: 0.62121964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25042.4140625MB; mem (CPU total)=57745.48828125MB
INFO:root:[  115] Training loss: 0.60879381, Validation loss: 0.62184814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25080.51171875MB; mem (CPU total)=57817.015625MB
INFO:root:[  116] Training loss: 0.60842347, Validation loss: 0.62047127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25118.60546875MB; mem (CPU total)=57887.59765625MB
INFO:root:[  117] Training loss: 0.60828731, Validation loss: 0.61996514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25156.69921875MB; mem (CPU total)=57959.02734375MB
INFO:root:[  118] Training loss: 0.60846620, Validation loss: 0.62066642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25194.796875MB; mem (CPU total)=58030.42578125MB
INFO:root:[  119] Training loss: 0.60793372, Validation loss: 0.62028436, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25232.890625MB; mem (CPU total)=58101.046875MB
INFO:root:[  120] Training loss: 0.60771611, Validation loss: 0.62009019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25270.984375MB; mem (CPU total)=58171.796875MB
INFO:root:[  121] Training loss: 0.60721256, Validation loss: 0.62137428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25309.078125MB; mem (CPU total)=58241.44140625MB
INFO:root:[  122] Training loss: 0.60692383, Validation loss: 0.62032842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25347.1796875MB; mem (CPU total)=58321.2734375MB
INFO:root:[  123] Training loss: 0.60693033, Validation loss: 0.62096939, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25385.2734375MB; mem (CPU total)=58385.00390625MB
INFO:root:[  124] Training loss: 0.60669321, Validation loss: 0.61985924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25423.3671875MB; mem (CPU total)=58432.49609375MB
INFO:root:[  125] Training loss: 0.60659947, Validation loss: 0.61968978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25461.46484375MB; mem (CPU total)=58503.23828125MB
INFO:root:[  126] Training loss: 0.60638392, Validation loss: 0.61861610, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25499.55859375MB; mem (CPU total)=58576.11328125MB
INFO:root:[  127] Training loss: 0.60611235, Validation loss: 0.61888786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25537.65234375MB; mem (CPU total)=58652.89453125MB
INFO:root:[  128] Training loss: 0.60591754, Validation loss: 0.62079864, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25575.74609375MB; mem (CPU total)=58729.1796875MB
INFO:root:[  129] Training loss: 0.60563438, Validation loss: 0.61920075, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25613.84375MB; mem (CPU total)=58805.6640625MB
INFO:root:[  130] Training loss: 0.60561802, Validation loss: 0.61968523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25651.94140625MB; mem (CPU total)=58881.4296875MB
INFO:root:[  131] Training loss: 0.60495335, Validation loss: 0.61741168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25690.03515625MB; mem (CPU total)=58957.98828125MB
INFO:root:[  132] Training loss: 0.60498286, Validation loss: 0.61822381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25728.1328125MB; mem (CPU total)=59034.74609375MB
INFO:root:[  133] Training loss: 0.60466989, Validation loss: 0.61897342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25766.2265625MB; mem (CPU total)=59110.26171875MB
INFO:root:[  134] Training loss: 0.60483827, Validation loss: 0.61898736, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25804.3203125MB; mem (CPU total)=59184.71875MB
INFO:root:[  135] Training loss: 0.60421825, Validation loss: 0.61896862, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25842.421875MB; mem (CPU total)=59255.34765625MB
INFO:root:[  136] Training loss: 0.60420459, Validation loss: 0.61846320, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25880.51953125MB; mem (CPU total)=59327.16015625MB
INFO:root:[  137] Training loss: 0.60350545, Validation loss: 0.61849279, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25918.61328125MB; mem (CPU total)=59398.8046875MB
INFO:root:[  138] Training loss: 0.60377051, Validation loss: 0.61800338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25956.7109375MB; mem (CPU total)=59469.91796875MB
INFO:root:[  139] Training loss: 0.60329350, Validation loss: 0.61937554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25994.8046875MB; mem (CPU total)=59540.76953125MB
INFO:root:[  140] Training loss: 0.60364235, Validation loss: 0.61898890, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26032.90234375MB; mem (CPU total)=59611.5390625MB
INFO:root:EP 140: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=26070.75MB; mem (CPU total)=59683.09375MB
INFO:root:Training the model took 9024.667s.
INFO:root:Emptying the cuda cache took 0.048s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85776
INFO:root:EnergyScoreTrain: 0.60405
INFO:root:CRPSTrain: 0.53215
INFO:root:Gaussian NLLTrain: 2.55036
INFO:root:CoverageTrain: 0.77955
INFO:root:IntervalWidthTrain: 3.07911
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87798
INFO:root:EnergyScoreValidation: 0.61825
INFO:root:CRPSValidation: 0.54353
INFO:root:Gaussian NLLValidation: 2.58548
INFO:root:CoverageValidation: 0.77317
INFO:root:IntervalWidthValidation: 3.07623
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87956
INFO:root:EnergyScoreTest: 0.61944
INFO:root:CRPSTest: 0.54453
INFO:root:Gaussian NLLTest: 2.58428
INFO:root:CoverageTest: 0.77238
INFO:root:IntervalWidthTest: 3.07244
INFO:root:After validation: mem (CPU python)=26113.86328125MB; mem (CPU total)=59840.953125MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=26113.86328125MB; mem (CPU total)=59865.80859375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=26114.06640625MB; mem (CPU total)=59867.0390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=26114.3046875MB; mem (CPU total)=59880.05078125MB
INFO:root:[    1] Training loss: 0.78651340, Validation loss: 0.72543209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26152.37890625MB; mem (CPU total)=59955.89453125MB
INFO:root:[    2] Training loss: 0.72425580, Validation loss: 0.72111105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26190.4765625MB; mem (CPU total)=60031.80078125MB
INFO:root:[    3] Training loss: 0.72125238, Validation loss: 0.72049383, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26228.5859375MB; mem (CPU total)=60108.11328125MB
INFO:root:[    4] Training loss: 0.72035274, Validation loss: 0.71919526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26266.6953125MB; mem (CPU total)=60180.11328125MB
INFO:root:[    5] Training loss: 0.72014764, Validation loss: 0.71936315, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26304.80859375MB; mem (CPU total)=60249.2578125MB
INFO:root:[    6] Training loss: 0.71950793, Validation loss: 0.71888822, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26342.90234375MB; mem (CPU total)=60318.1875MB
INFO:root:[    7] Training loss: 0.71931935, Validation loss: 0.71863415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26380.99609375MB; mem (CPU total)=60387.30859375MB
INFO:root:[    8] Training loss: 0.71883585, Validation loss: 0.71888070, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26419.09375MB; mem (CPU total)=60457.69140625MB
INFO:root:[    9] Training loss: 0.71845954, Validation loss: 0.71906437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26457.19140625MB; mem (CPU total)=60527.82421875MB
INFO:root:[   10] Training loss: 0.71754194, Validation loss: 0.71620929, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26495.28515625MB; mem (CPU total)=60603.64453125MB
INFO:root:[   11] Training loss: 0.71381525, Validation loss: 0.71053357, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26533.37890625MB; mem (CPU total)=60679.8515625MB
INFO:root:[   12] Training loss: 0.70682324, Validation loss: 0.70376256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26571.48046875MB; mem (CPU total)=60755.80859375MB
INFO:root:[   13] Training loss: 0.70038020, Validation loss: 0.69834635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26609.57421875MB; mem (CPU total)=60832.00390625MB
INFO:root:[   14] Training loss: 0.69569259, Validation loss: 0.69392684, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26647.66796875MB; mem (CPU total)=60908.27734375MB
INFO:root:[   15] Training loss: 0.69115226, Validation loss: 0.69057062, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26685.765625MB; mem (CPU total)=60984.8046875MB
INFO:root:[   16] Training loss: 0.68801712, Validation loss: 0.68723960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26723.859375MB; mem (CPU total)=61060.734375MB
INFO:root:[   17] Training loss: 0.68472311, Validation loss: 0.68511222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26761.95703125MB; mem (CPU total)=61129.19140625MB
INFO:root:[   18] Training loss: 0.68208337, Validation loss: 0.68191168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26800.05078125MB; mem (CPU total)=61199.3203125MB
INFO:root:[   19] Training loss: 0.67974315, Validation loss: 0.67989462, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26838.1484375MB; mem (CPU total)=61269.41796875MB
INFO:root:[   20] Training loss: 0.67740880, Validation loss: 0.67657845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26876.25390625MB; mem (CPU total)=61338.7109375MB
INFO:root:[   21] Training loss: 0.67523890, Validation loss: 0.67557255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26914.78515625MB; mem (CPU total)=61408.1875MB
INFO:root:[   22] Training loss: 0.67308925, Validation loss: 0.67323513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26952.9453125MB; mem (CPU total)=61481.49609375MB
INFO:root:[   23] Training loss: 0.67108475, Validation loss: 0.67225404, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26991.0390625MB; mem (CPU total)=61557.98046875MB
INFO:root:[   24] Training loss: 0.66910344, Validation loss: 0.67003504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27029.13671875MB; mem (CPU total)=61634.23828125MB
INFO:root:[   25] Training loss: 0.66764180, Validation loss: 0.66819422, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27067.234375MB; mem (CPU total)=61710.390625MB
INFO:root:[   26] Training loss: 0.66596441, Validation loss: 0.66762733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27105.33203125MB; mem (CPU total)=61791.53515625MB
INFO:root:[   27] Training loss: 0.66491605, Validation loss: 0.66494142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27143.42578125MB; mem (CPU total)=61867.5234375MB
INFO:root:[   28] Training loss: 0.66334414, Validation loss: 0.66505217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27181.51953125MB; mem (CPU total)=61944.046875MB
INFO:root:[   29] Training loss: 0.66162640, Validation loss: 0.66345958, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27219.6171875MB; mem (CPU total)=62015.3984375MB
INFO:root:[   30] Training loss: 0.66051366, Validation loss: 0.66227095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27257.71484375MB; mem (CPU total)=62084.7890625MB
INFO:root:[   31] Training loss: 0.65926514, Validation loss: 0.66050630, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27295.80859375MB; mem (CPU total)=62153.8515625MB
INFO:root:[   32] Training loss: 0.65839604, Validation loss: 0.66064389, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27333.90625MB; mem (CPU total)=62223.7421875MB
INFO:root:[   33] Training loss: 0.65721674, Validation loss: 0.65912441, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27372.0MB; mem (CPU total)=62293.609375MB
INFO:root:[   34] Training loss: 0.65565827, Validation loss: 0.65796127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27410.09375MB; mem (CPU total)=62363.890625MB
INFO:root:[   35] Training loss: 0.65511732, Validation loss: 0.65671241, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27448.1875MB; mem (CPU total)=62440.12109375MB
INFO:root:[   36] Training loss: 0.65440332, Validation loss: 0.65669168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27486.28125MB; mem (CPU total)=62516.41015625MB
INFO:root:[   37] Training loss: 0.65298677, Validation loss: 0.65565403, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27524.3828125MB; mem (CPU total)=62592.92578125MB
INFO:root:[   38] Training loss: 0.65218203, Validation loss: 0.65609629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27562.48046875MB; mem (CPU total)=62669.15625MB
INFO:root:[   39] Training loss: 0.65136742, Validation loss: 0.65321884, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27600.578125MB; mem (CPU total)=62745.12890625MB
INFO:root:[   40] Training loss: 0.65055730, Validation loss: 0.65386920, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27638.671875MB; mem (CPU total)=62821.90234375MB
INFO:root:[   41] Training loss: 0.64972183, Validation loss: 0.65286506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27676.765625MB; mem (CPU total)=62896.97265625MB
INFO:root:[   42] Training loss: 0.64905241, Validation loss: 0.65153911, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27714.859375MB; mem (CPU total)=62965.82421875MB
INFO:root:[   43] Training loss: 0.64830037, Validation loss: 0.65040525, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27752.95703125MB; mem (CPU total)=63035.74609375MB
INFO:root:[   44] Training loss: 0.64737287, Validation loss: 0.65004169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27791.05078125MB; mem (CPU total)=63105.3515625MB
INFO:root:[   45] Training loss: 0.64682654, Validation loss: 0.65055099, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27829.1484375MB; mem (CPU total)=63174.0078125MB
INFO:root:[   46] Training loss: 0.64630157, Validation loss: 0.64943886, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27867.24609375MB; mem (CPU total)=63244.1015625MB
INFO:root:[   47] Training loss: 0.64513448, Validation loss: 0.64792667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27905.33984375MB; mem (CPU total)=63317.4296875MB
INFO:root:[   48] Training loss: 0.64468101, Validation loss: 0.64739615, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27943.43359375MB; mem (CPU total)=63394.1953125MB
INFO:root:[   49] Training loss: 0.64351981, Validation loss: 0.64606280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27981.53125MB; mem (CPU total)=63471.68359375MB
INFO:root:[   50] Training loss: 0.64351622, Validation loss: 0.64684948, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28019.625MB; mem (CPU total)=63548.81640625MB
INFO:root:[   51] Training loss: 0.64251117, Validation loss: 0.64595774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28057.71875MB; mem (CPU total)=63624.81640625MB
INFO:root:[   52] Training loss: 0.64180351, Validation loss: 0.64547118, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28095.8125MB; mem (CPU total)=63700.8359375MB
INFO:root:[   53] Training loss: 0.64116593, Validation loss: 0.64462065, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28133.9140625MB; mem (CPU total)=63777.390625MB
INFO:root:[   54] Training loss: 0.64080392, Validation loss: 0.64423709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28172.0078125MB; mem (CPU total)=63852.21875MB
INFO:root:[   55] Training loss: 0.64047099, Validation loss: 0.64425726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28210.1015625MB; mem (CPU total)=63921.64453125MB
INFO:root:[   56] Training loss: 0.63981945, Validation loss: 0.64321998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28248.19921875MB; mem (CPU total)=63991.87890625MB
INFO:root:[   57] Training loss: 0.63898593, Validation loss: 0.64403546, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28286.29296875MB; mem (CPU total)=64061.484375MB
INFO:root:[   58] Training loss: 0.63876096, Validation loss: 0.64373134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28324.38671875MB; mem (CPU total)=64130.078125MB
INFO:root:[   59] Training loss: 0.63761052, Validation loss: 0.64299213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28362.48046875MB; mem (CPU total)=64201.01171875MB
INFO:root:[   60] Training loss: 0.63769231, Validation loss: 0.64119539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28400.578125MB; mem (CPU total)=64274.796875MB
INFO:root:[   61] Training loss: 0.63645163, Validation loss: 0.63978731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28438.67578125MB; mem (CPU total)=64350.7421875MB
INFO:root:[   62] Training loss: 0.63673569, Validation loss: 0.64151321, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28476.76953125MB; mem (CPU total)=64426.01953125MB
INFO:root:[   63] Training loss: 0.63577045, Validation loss: 0.64118679, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28514.8671875MB; mem (CPU total)=64502.50390625MB
INFO:root:[   64] Training loss: 0.63543522, Validation loss: 0.63978925, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28552.9609375MB; mem (CPU total)=64578.5703125MB
INFO:root:[   65] Training loss: 0.63457945, Validation loss: 0.63963829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28591.0546875MB; mem (CPU total)=64654.83203125MB
INFO:root:[   66] Training loss: 0.63390895, Validation loss: 0.63760681, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28629.15234375MB; mem (CPU total)=64731.63671875MB
INFO:root:[   67] Training loss: 0.63419426, Validation loss: 0.63916611, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28667.24609375MB; mem (CPU total)=64807.70703125MB
INFO:root:[   68] Training loss: 0.63368566, Validation loss: 0.63914189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28705.33984375MB; mem (CPU total)=64879.83984375MB
INFO:root:[   69] Training loss: 0.63357597, Validation loss: 0.63807643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28743.43359375MB; mem (CPU total)=64949.72265625MB
INFO:root:[   70] Training loss: 0.63249374, Validation loss: 0.63769574, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28781.5390625MB; mem (CPU total)=65019.83984375MB
INFO:root:[   71] Training loss: 0.63235901, Validation loss: 0.63736261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28819.6328125MB; mem (CPU total)=65089.19140625MB
INFO:root:[   72] Training loss: 0.63167486, Validation loss: 0.63714762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28857.7265625MB; mem (CPU total)=65161.33984375MB
INFO:root:[   73] Training loss: 0.63126845, Validation loss: 0.63650613, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28895.82421875MB; mem (CPU total)=65233.02734375MB
INFO:root:[   74] Training loss: 0.63060294, Validation loss: 0.63741038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28933.91796875MB; mem (CPU total)=65304.63671875MB
INFO:root:[   75] Training loss: 0.63032424, Validation loss: 0.63518158, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28972.01171875MB; mem (CPU total)=65380.69140625MB
INFO:root:[   76] Training loss: 0.63004280, Validation loss: 0.63600889, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29010.10546875MB; mem (CPU total)=65457.5MB
INFO:root:[   77] Training loss: 0.62967329, Validation loss: 0.63614328, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29048.20703125MB; mem (CPU total)=65533.80859375MB
INFO:root:[   78] Training loss: 0.62899635, Validation loss: 0.63460207, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29086.30078125MB; mem (CPU total)=65609.8671875MB
INFO:root:[   79] Training loss: 0.62892431, Validation loss: 0.63509263, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29124.39453125MB; mem (CPU total)=65686.6640625MB
INFO:root:[   80] Training loss: 0.62863610, Validation loss: 0.63516737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29162.4921875MB; mem (CPU total)=65762.71875MB
INFO:root:[   81] Training loss: 0.62828570, Validation loss: 0.63306556, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29200.5859375MB; mem (CPU total)=65838.78515625MB
INFO:root:[   82] Training loss: 0.62786318, Validation loss: 0.63461923, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29238.6796875MB; mem (CPU total)=65915.8671875MB
INFO:root:[   83] Training loss: 0.62749379, Validation loss: 0.63320661, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29276.77734375MB; mem (CPU total)=65986.7578125MB
INFO:root:[   84] Training loss: 0.62696508, Validation loss: 0.63401648, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29314.87109375MB; mem (CPU total)=66057.41015625MB
INFO:root:[   85] Training loss: 0.62658217, Validation loss: 0.63391565, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29352.96484375MB; mem (CPU total)=66128.98828125MB
INFO:root:[   86] Training loss: 0.62619323, Validation loss: 0.63345343, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29391.05859375MB; mem (CPU total)=66199.3671875MB
INFO:root:[   87] Training loss: 0.62609239, Validation loss: 0.63333560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29429.16015625MB; mem (CPU total)=66270.0234375MB
INFO:root:[   88] Training loss: 0.62561069, Validation loss: 0.63309869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29467.25390625MB; mem (CPU total)=66340.14453125MB
INFO:root:[   89] Training loss: 0.62537416, Validation loss: 0.63230257, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29505.34765625MB; mem (CPU total)=66412.19140625MB
INFO:root:[   90] Training loss: 0.62491208, Validation loss: 0.63190275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29543.4453125MB; mem (CPU total)=66487.75MB
INFO:root:[   91] Training loss: 0.62444071, Validation loss: 0.63150332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29581.5390625MB; mem (CPU total)=66564.38671875MB
INFO:root:[   92] Training loss: 0.62424940, Validation loss: 0.63200732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29619.6328125MB; mem (CPU total)=66640.640625MB
INFO:root:[   93] Training loss: 0.62335523, Validation loss: 0.63190671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29657.7265625MB; mem (CPU total)=66716.7109375MB
INFO:root:[   94] Training loss: 0.62359103, Validation loss: 0.63181027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29695.828125MB; mem (CPU total)=66792.78125MB
INFO:root:[   95] Training loss: 0.62307030, Validation loss: 0.63137609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29733.921875MB; mem (CPU total)=66869.7734375MB
INFO:root:[   96] Training loss: 0.62295645, Validation loss: 0.63112599, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29772.015625MB; mem (CPU total)=66945.3359375MB
INFO:root:[   97] Training loss: 0.62295279, Validation loss: 0.63059844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29810.11328125MB; mem (CPU total)=67021.89453125MB
INFO:root:[   98] Training loss: 0.62232837, Validation loss: 0.63069033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29848.20703125MB; mem (CPU total)=67098.24609375MB
INFO:root:[   99] Training loss: 0.62249149, Validation loss: 0.63071315, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29886.30078125MB; mem (CPU total)=67171.3359375MB
INFO:root:[  100] Training loss: 0.62206812, Validation loss: 0.62951341, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29924.40234375MB; mem (CPU total)=67242.46875MB
INFO:root:[  101] Training loss: 0.62153213, Validation loss: 0.62937354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29962.49609375MB; mem (CPU total)=67314.5703125MB
INFO:root:[  102] Training loss: 0.62126906, Validation loss: 0.62984116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30000.58984375MB; mem (CPU total)=67385.51953125MB
INFO:root:[  103] Training loss: 0.62059331, Validation loss: 0.63003861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30038.6796875MB; mem (CPU total)=67456.9140625MB
INFO:root:[  104] Training loss: 0.62056816, Validation loss: 0.62984628, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30076.78125MB; mem (CPU total)=67527.78515625MB
INFO:root:[  105] Training loss: 0.62031897, Validation loss: 0.62915033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30114.875MB; mem (CPU total)=67601.16015625MB
INFO:root:[  106] Training loss: 0.62005969, Validation loss: 0.62909860, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30152.96875MB; mem (CPU total)=67672.328125MB
INFO:root:[  107] Training loss: 0.61967060, Validation loss: 0.62843295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30191.06640625MB; mem (CPU total)=67747.9453125MB
INFO:root:[  108] Training loss: 0.61940291, Validation loss: 0.62875727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30229.16015625MB; mem (CPU total)=67824.4453125MB
INFO:root:[  109] Training loss: 0.61920809, Validation loss: 0.62831019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30267.2578125MB; mem (CPU total)=67900.9765625MB
INFO:root:[  110] Training loss: 0.61921937, Validation loss: 0.62755645, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30305.3515625MB; mem (CPU total)=67977.19140625MB
INFO:root:[  111] Training loss: 0.61883558, Validation loss: 0.62778572, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30343.4453125MB; mem (CPU total)=68053.57421875MB
INFO:root:[  112] Training loss: 0.61862089, Validation loss: 0.62850074, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30381.546875MB; mem (CPU total)=68133.703125MB
INFO:root:[  113] Training loss: 0.61849814, Validation loss: 0.62734009, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30419.640625MB; mem (CPU total)=68209.65625MB
INFO:root:[  114] Training loss: 0.61774117, Validation loss: 0.62890005, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30457.73828125MB; mem (CPU total)=68285.9140625MB
INFO:root:[  115] Training loss: 0.61747339, Validation loss: 0.62863361, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30495.83203125MB; mem (CPU total)=68362.20703125MB
INFO:root:[  116] Training loss: 0.61741866, Validation loss: 0.62713883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30533.92578125MB; mem (CPU total)=68438.5234375MB
INFO:root:[  117] Training loss: 0.61672904, Validation loss: 0.62694348, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30572.0234375MB; mem (CPU total)=68514.16796875MB
INFO:root:[  118] Training loss: 0.61704841, Validation loss: 0.62730883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30610.1171875MB; mem (CPU total)=68584.59765625MB
INFO:root:[  119] Training loss: 0.61670744, Validation loss: 0.62729389, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30648.2109375MB; mem (CPU total)=68656.23828125MB
INFO:root:[  120] Training loss: 0.61620851, Validation loss: 0.62679064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30686.3046875MB; mem (CPU total)=68729.0859375MB
INFO:root:[  121] Training loss: 0.61627641, Validation loss: 0.62667087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30724.40234375MB; mem (CPU total)=68802.453125MB
INFO:root:[  122] Training loss: 0.61591250, Validation loss: 0.62759406, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30762.5MB; mem (CPU total)=68873.359375MB
INFO:root:[  123] Training loss: 0.61543817, Validation loss: 0.62648793, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30800.59375MB; mem (CPU total)=68944.9765625MB
INFO:root:[  124] Training loss: 0.61557887, Validation loss: 0.62617244, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30838.69140625MB; mem (CPU total)=69016.91796875MB
INFO:root:[  125] Training loss: 0.61507090, Validation loss: 0.62615979, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30876.78515625MB; mem (CPU total)=69089.97265625MB
INFO:root:[  126] Training loss: 0.61477313, Validation loss: 0.62560157, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30914.87890625MB; mem (CPU total)=69164.07421875MB
INFO:root:[  127] Training loss: 0.61444439, Validation loss: 0.62745865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30952.97265625MB; mem (CPU total)=69240.12890625MB
INFO:root:[  128] Training loss: 0.61421177, Validation loss: 0.62496179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30991.0703125MB; mem (CPU total)=69316.6796875MB
INFO:root:[  129] Training loss: 0.61392686, Validation loss: 0.62703737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31029.1640625MB; mem (CPU total)=69393.03515625MB
INFO:root:[  130] Training loss: 0.61402445, Validation loss: 0.62563649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31067.2578125MB; mem (CPU total)=69469.05859375MB
INFO:root:[  131] Training loss: 0.61351258, Validation loss: 0.62531482, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31105.359375MB; mem (CPU total)=69546.03125MB
INFO:root:[  132] Training loss: 0.61347005, Validation loss: 0.62578362, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31143.453125MB; mem (CPU total)=69635.3515625MB
INFO:root:[  133] Training loss: 0.61304028, Validation loss: 0.62575549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31181.546875MB; mem (CPU total)=69709.75390625MB
INFO:root:[  134] Training loss: 0.61340752, Validation loss: 0.62568708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31219.64453125MB; mem (CPU total)=69748.6640625MB
INFO:root:[  135] Training loss: 0.61218945, Validation loss: 0.62619821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31257.73828125MB; mem (CPU total)=69825.109375MB
INFO:root:[  136] Training loss: 0.61296043, Validation loss: 0.62595450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31295.83203125MB; mem (CPU total)=69901.3125MB
INFO:root:[  137] Training loss: 0.61231584, Validation loss: 0.62585835, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31333.9296875MB; mem (CPU total)=69978.16015625MB
INFO:root:EP 137: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=31371.91796875MB; mem (CPU total)=70045.3828125MB
INFO:root:Training the model took 9766.993s.
INFO:root:Emptying the cuda cache took 0.047s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87127
INFO:root:EnergyScoreTrain: 0.61368
INFO:root:CRPSTrain: 0.54433
INFO:root:Gaussian NLLTrain: 2.50845
INFO:root:CoverageTrain: 0.77151
INFO:root:IntervalWidthTrain: 3.11175
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88958
INFO:root:EnergyScoreValidation: 0.62651
INFO:root:CRPSValidation: 0.55466
INFO:root:Gaussian NLLValidation: 2.53841
INFO:root:CoverageValidation: 0.7657
INFO:root:IntervalWidthValidation: 3.10679
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89148
INFO:root:EnergyScoreTest: 0.62783
INFO:root:CRPSTest: 0.55596
INFO:root:Gaussian NLLTest: 2.54533
INFO:root:CoverageTest: 0.76403
INFO:root:IntervalWidthTest: 3.10007
INFO:root:After validation: mem (CPU python)=31414.91796875MB; mem (CPU total)=70207.23828125MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=31414.91796875MB; mem (CPU total)=70212.0703125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=31415.35546875MB; mem (CPU total)=70211.92578125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=31415.35546875MB; mem (CPU total)=70236.0546875MB
INFO:root:[    1] Training loss: 0.78391384, Validation loss: 0.72525067, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31453.41796875MB; mem (CPU total)=70308.421875MB
INFO:root:[    2] Training loss: 0.72473651, Validation loss: 0.72132995, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31491.51171875MB; mem (CPU total)=70381.484375MB
INFO:root:[    3] Training loss: 0.72127346, Validation loss: 0.72047773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31529.609375MB; mem (CPU total)=70453.49609375MB
INFO:root:[    4] Training loss: 0.72025412, Validation loss: 0.72022972, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31567.703125MB; mem (CPU total)=70526.11328125MB
INFO:root:[    5] Training loss: 0.72009565, Validation loss: 0.71970314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31605.796875MB; mem (CPU total)=70598.4296875MB
INFO:root:[    6] Training loss: 0.71973581, Validation loss: 0.71993568, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31643.89453125MB; mem (CPU total)=70670.890625MB
INFO:root:[    7] Training loss: 0.71933583, Validation loss: 0.72075684, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31681.9921875MB; mem (CPU total)=70746.3828125MB
INFO:root:[    8] Training loss: 0.71858735, Validation loss: 0.71775854, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31720.0859375MB; mem (CPU total)=70823.19140625MB
INFO:root:[    9] Training loss: 0.71734654, Validation loss: 0.71599499, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31758.18359375MB; mem (CPU total)=70899.234375MB
INFO:root:[   10] Training loss: 0.71360872, Validation loss: 0.70973739, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31796.27734375MB; mem (CPU total)=70975.796875MB
INFO:root:[   11] Training loss: 0.70587906, Validation loss: 0.70129978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31834.375MB; mem (CPU total)=71052.328125MB
INFO:root:[   12] Training loss: 0.69599407, Validation loss: 0.69259087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31872.46875MB; mem (CPU total)=71128.52734375MB
INFO:root:[   13] Training loss: 0.68730896, Validation loss: 0.68439424, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31910.56640625MB; mem (CPU total)=71205.31640625MB
INFO:root:[   14] Training loss: 0.67997924, Validation loss: 0.67740425, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31948.66015625MB; mem (CPU total)=71280.8515625MB
INFO:root:[   15] Training loss: 0.67424263, Validation loss: 0.67218627, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31986.7578125MB; mem (CPU total)=71357.06640625MB
INFO:root:[   16] Training loss: 0.66983790, Validation loss: 0.66851754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32024.8515625MB; mem (CPU total)=71433.6015625MB
INFO:root:[   17] Training loss: 0.66674060, Validation loss: 0.66578603, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32062.9453125MB; mem (CPU total)=71510.13671875MB
INFO:root:[   18] Training loss: 0.66328718, Validation loss: 0.66352316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32101.04296875MB; mem (CPU total)=71586.66796875MB
INFO:root:[   19] Training loss: 0.66131308, Validation loss: 0.66113467, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32139.13671875MB; mem (CPU total)=71662.94140625MB
INFO:root:[   20] Training loss: 0.65942573, Validation loss: 0.65892461, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32177.234375MB; mem (CPU total)=71739.4765625MB
INFO:root:[   21] Training loss: 0.65730158, Validation loss: 0.65780533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32215.328125MB; mem (CPU total)=71813.22265625MB
INFO:root:[   22] Training loss: 0.65572078, Validation loss: 0.65699253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32253.42578125MB; mem (CPU total)=71884.05859375MB
INFO:root:[   23] Training loss: 0.65384165, Validation loss: 0.65580791, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32291.51953125MB; mem (CPU total)=71957.078125MB
INFO:root:[   24] Training loss: 0.65276872, Validation loss: 0.65301506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32329.6171875MB; mem (CPU total)=72030.8828125MB
INFO:root:[   25] Training loss: 0.65174078, Validation loss: 0.65333431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32367.7109375MB; mem (CPU total)=72103.234375MB
INFO:root:[   26] Training loss: 0.65061931, Validation loss: 0.65191947, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32405.8046875MB; mem (CPU total)=72175.8671875MB
INFO:root:[   27] Training loss: 0.64923440, Validation loss: 0.65054443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32443.8984375MB; mem (CPU total)=72248.9765625MB
INFO:root:[   28] Training loss: 0.64837343, Validation loss: 0.64973847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32482.00390625MB; mem (CPU total)=72321.42578125MB
INFO:root:[   29] Training loss: 0.64695248, Validation loss: 0.64984226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32520.09765625MB; mem (CPU total)=72394.9765625MB
INFO:root:[   30] Training loss: 0.64610351, Validation loss: 0.64799998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32558.1953125MB; mem (CPU total)=72466.953125MB
INFO:root:[   31] Training loss: 0.64561551, Validation loss: 0.64800409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32596.29296875MB; mem (CPU total)=72539.3046875MB
INFO:root:[   32] Training loss: 0.64440635, Validation loss: 0.64639879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32634.38671875MB; mem (CPU total)=72615.45703125MB
INFO:root:[   33] Training loss: 0.64356464, Validation loss: 0.64587367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32672.48046875MB; mem (CPU total)=72692.23828125MB
INFO:root:[   34] Training loss: 0.64272054, Validation loss: 0.64530856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32710.57421875MB; mem (CPU total)=72768.51953125MB
INFO:root:[   35] Training loss: 0.64200166, Validation loss: 0.64442471, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32748.67578125MB; mem (CPU total)=72844.30859375MB
INFO:root:[   36] Training loss: 0.64137853, Validation loss: 0.64311617, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32786.76953125MB; mem (CPU total)=72920.796875MB
INFO:root:[   37] Training loss: 0.64108134, Validation loss: 0.64388061, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32824.86328125MB; mem (CPU total)=72997.28515625MB
INFO:root:[   38] Training loss: 0.63978652, Validation loss: 0.64300843, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32862.9609375MB; mem (CPU total)=73073.76953125MB
INFO:root:[   39] Training loss: 0.63923477, Validation loss: 0.64189244, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32901.0546875MB; mem (CPU total)=73150.0703125MB
INFO:root:[   40] Training loss: 0.63820201, Validation loss: 0.64144888, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32939.1484375MB; mem (CPU total)=73226.11328125MB
INFO:root:[   41] Training loss: 0.63795308, Validation loss: 0.64110469, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32977.24609375MB; mem (CPU total)=73302.89453125MB
INFO:root:[   42] Training loss: 0.63682752, Validation loss: 0.64054565, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33015.33984375MB; mem (CPU total)=73379.3515625MB
INFO:root:[   43] Training loss: 0.63626535, Validation loss: 0.63997905, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33053.43359375MB; mem (CPU total)=73455.03515625MB
INFO:root:[   44] Training loss: 0.63540158, Validation loss: 0.63958496, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33091.53125MB; mem (CPU total)=73531.24609375MB
INFO:root:[   45] Training loss: 0.63512858, Validation loss: 0.63830150, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33129.62890625MB; mem (CPU total)=73607.3203125MB
INFO:root:[   46] Training loss: 0.63449114, Validation loss: 0.63877867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33167.72265625MB; mem (CPU total)=73682.5546875MB
INFO:root:[   47] Training loss: 0.63351715, Validation loss: 0.63836645, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33205.81640625MB; mem (CPU total)=73755.0625MB
INFO:root:[   48] Training loss: 0.63332371, Validation loss: 0.63733026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33243.9140625MB; mem (CPU total)=73829.08984375MB
INFO:root:[   49] Training loss: 0.63277368, Validation loss: 0.63773210, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33282.0078125MB; mem (CPU total)=73901.1875MB
INFO:root:[   50] Training loss: 0.63200929, Validation loss: 0.63759815, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33320.1015625MB; mem (CPU total)=73973.53125MB
INFO:root:[   51] Training loss: 0.63144510, Validation loss: 0.63741265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33358.19921875MB; mem (CPU total)=74047.58984375MB
INFO:root:[   52] Training loss: 0.63128138, Validation loss: 0.63606811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33396.296875MB; mem (CPU total)=74120.33984375MB
INFO:root:[   53] Training loss: 0.63052718, Validation loss: 0.63528731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33434.390625MB; mem (CPU total)=74193.39453125MB
INFO:root:[   54] Training loss: 0.62950618, Validation loss: 0.63415745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33472.484375MB; mem (CPU total)=74266.19921875MB
INFO:root:[   55] Training loss: 0.62915317, Validation loss: 0.63403423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33510.58203125MB; mem (CPU total)=74338.828125MB
INFO:root:[   56] Training loss: 0.62878610, Validation loss: 0.63472715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33548.67578125MB; mem (CPU total)=74411.8671875MB
INFO:root:[   57] Training loss: 0.62867489, Validation loss: 0.63333767, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33586.76953125MB; mem (CPU total)=74484.45703125MB
INFO:root:[   58] Training loss: 0.62785807, Validation loss: 0.63363381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33624.8671875MB; mem (CPU total)=74560.74609375MB
INFO:root:[   59] Training loss: 0.62780632, Validation loss: 0.63451970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33662.96484375MB; mem (CPU total)=74637.2734375MB
INFO:root:[   60] Training loss: 0.62703144, Validation loss: 0.63244934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33701.0625MB; mem (CPU total)=74713.5625MB
INFO:root:[   61] Training loss: 0.62658691, Validation loss: 0.63250492, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33739.15625MB; mem (CPU total)=74789.55859375MB
INFO:root:[   62] Training loss: 0.62601786, Validation loss: 0.63247329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33777.25390625MB; mem (CPU total)=74865.53515625MB
INFO:root:[   63] Training loss: 0.62572248, Validation loss: 0.63211228, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33815.34765625MB; mem (CPU total)=74941.79296875MB
INFO:root:[   64] Training loss: 0.62553936, Validation loss: 0.63037972, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33853.44140625MB; mem (CPU total)=75018.3984375MB
INFO:root:[   65] Training loss: 0.62503968, Validation loss: 0.63128537, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33891.5390625MB; mem (CPU total)=75094.6875MB
INFO:root:[   66] Training loss: 0.62440169, Validation loss: 0.63068026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33929.6328125MB; mem (CPU total)=75171.4375MB
INFO:root:[   67] Training loss: 0.62432003, Validation loss: 0.63037671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33967.7265625MB; mem (CPU total)=75247.48046875MB
INFO:root:[   68] Training loss: 0.62361136, Validation loss: 0.63040151, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34005.8203125MB; mem (CPU total)=75323.7890625MB
INFO:root:[   69] Training loss: 0.62326793, Validation loss: 0.62947985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34043.91796875MB; mem (CPU total)=75400.54296875MB
INFO:root:[   70] Training loss: 0.62253106, Validation loss: 0.63038945, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34082.01171875MB; mem (CPU total)=75476.5859375MB
INFO:root:[   71] Training loss: 0.62234932, Validation loss: 0.62866925, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34120.10546875MB; mem (CPU total)=75553.01171875MB
INFO:root:[   72] Training loss: 0.62191771, Validation loss: 0.62918213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34158.203125MB; mem (CPU total)=75629.5546875MB
INFO:root:[   73] Training loss: 0.62118031, Validation loss: 0.62750303, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34196.30078125MB; mem (CPU total)=75705.10546875MB
INFO:root:[   74] Training loss: 0.62145008, Validation loss: 0.62920735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34234.39453125MB; mem (CPU total)=75777.4375MB
INFO:root:[   75] Training loss: 0.62110945, Validation loss: 0.62732459, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34272.4921875MB; mem (CPU total)=75849.296875MB
INFO:root:[   76] Training loss: 0.62053539, Validation loss: 0.62737821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34310.5859375MB; mem (CPU total)=75923.140625MB
INFO:root:[   77] Training loss: 0.62013690, Validation loss: 0.62647256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34348.6796875MB; mem (CPU total)=75995.76953125MB
INFO:root:[   78] Training loss: 0.61976974, Validation loss: 0.62794072, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34386.7734375MB; mem (CPU total)=76067.875MB
INFO:root:[   79] Training loss: 0.61927993, Validation loss: 0.62686426, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34424.875MB; mem (CPU total)=76140.91015625MB
INFO:root:[   80] Training loss: 0.61891229, Validation loss: 0.62736332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34462.96875MB; mem (CPU total)=76219.5234375MB
INFO:root:[   81] Training loss: 0.61873971, Validation loss: 0.62732316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34501.0625MB; mem (CPU total)=76290.30078125MB
INFO:root:[   82] Training loss: 0.61827403, Validation loss: 0.62588136, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34539.16015625MB; mem (CPU total)=76362.671875MB
INFO:root:[   83] Training loss: 0.61825657, Validation loss: 0.62571821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34577.25390625MB; mem (CPU total)=76434.74609375MB
INFO:root:[   84] Training loss: 0.61783711, Validation loss: 0.62503329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34615.34765625MB; mem (CPU total)=76509.08203125MB
INFO:root:[   85] Training loss: 0.61699098, Validation loss: 0.62626708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34653.44140625MB; mem (CPU total)=76584.96484375MB
INFO:root:[   86] Training loss: 0.61693409, Validation loss: 0.62634953, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34691.54296875MB; mem (CPU total)=76661.25390625MB
INFO:root:[   87] Training loss: 0.61648906, Validation loss: 0.62466223, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34729.63671875MB; mem (CPU total)=76737.6953125MB
INFO:root:[   88] Training loss: 0.61643105, Validation loss: 0.62466479, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34767.73046875MB; mem (CPU total)=76813.95703125MB
INFO:root:[   89] Training loss: 0.61599892, Validation loss: 0.62507413, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34805.828125MB; mem (CPU total)=76890.4609375MB
INFO:root:[   90] Training loss: 0.61579869, Validation loss: 0.62445612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34843.921875MB; mem (CPU total)=76966.75MB
INFO:root:[   91] Training loss: 0.61518125, Validation loss: 0.62335955, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34882.015625MB; mem (CPU total)=77042.93359375MB
INFO:root:[   92] Training loss: 0.61503910, Validation loss: 0.62405381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34920.11328125MB; mem (CPU total)=77119.19140625MB
INFO:root:[   93] Training loss: 0.61476454, Validation loss: 0.62463769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34958.2109375MB; mem (CPU total)=77195.7421875MB
INFO:root:[   94] Training loss: 0.61455371, Validation loss: 0.62343522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34996.3046875MB; mem (CPU total)=77271.984375MB
INFO:root:[   95] Training loss: 0.61413946, Validation loss: 0.62418213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35034.3984375MB; mem (CPU total)=77348.19921875MB
INFO:root:[   96] Training loss: 0.61379366, Validation loss: 0.62412187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35072.49609375MB; mem (CPU total)=77424.4921875MB
INFO:root:[   97] Training loss: 0.61402141, Validation loss: 0.62337537, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35110.58984375MB; mem (CPU total)=77500.6484375MB
INFO:root:[   98] Training loss: 0.61360384, Validation loss: 0.62301161, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35148.68359375MB; mem (CPU total)=77577.30078125MB
INFO:root:[   99] Training loss: 0.61305971, Validation loss: 0.62226317, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35186.78125MB; mem (CPU total)=77653.75390625MB
INFO:root:[  100] Training loss: 0.61289112, Validation loss: 0.62375083, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35224.875MB; mem (CPU total)=77730.01171875MB
INFO:root:[  101] Training loss: 0.61269200, Validation loss: 0.62224546, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35262.96875MB; mem (CPU total)=77802.609375MB
INFO:root:[  102] Training loss: 0.61231338, Validation loss: 0.62192964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35301.0703125MB; mem (CPU total)=77875.20703125MB
INFO:root:[  103] Training loss: 0.61177874, Validation loss: 0.62276438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35339.16796875MB; mem (CPU total)=77949.71875MB
INFO:root:[  104] Training loss: 0.61161761, Validation loss: 0.62172715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35377.26171875MB; mem (CPU total)=78021.78125MB
INFO:root:[  105] Training loss: 0.61122839, Validation loss: 0.62178258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35415.35546875MB; mem (CPU total)=78094.41015625MB
INFO:root:[  106] Training loss: 0.61092478, Validation loss: 0.62195950, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35453.453125MB; mem (CPU total)=78168.25MB
INFO:root:[  107] Training loss: 0.61068999, Validation loss: 0.62195078, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35491.546875MB; mem (CPU total)=78240.84375MB
INFO:root:[  108] Training loss: 0.61079168, Validation loss: 0.62177300, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35529.64453125MB; mem (CPU total)=78313.65625MB
INFO:root:[  109] Training loss: 0.61037661, Validation loss: 0.62048833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35567.7421875MB; mem (CPU total)=78386.9921875MB
INFO:root:[  110] Training loss: 0.60998135, Validation loss: 0.62297290, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35605.8359375MB; mem (CPU total)=78460.37109375MB
INFO:root:[  111] Training loss: 0.60938591, Validation loss: 0.62039656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35643.9296875MB; mem (CPU total)=78532.7265625MB
INFO:root:[  112] Training loss: 0.60983050, Validation loss: 0.62052343, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35682.0234375MB; mem (CPU total)=78609.48046875MB
INFO:root:[  113] Training loss: 0.60920760, Validation loss: 0.62120397, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35720.12109375MB; mem (CPU total)=78685.85546875MB
INFO:root:[  114] Training loss: 0.60916860, Validation loss: 0.62109098, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35758.21484375MB; mem (CPU total)=78761.578125MB
INFO:root:[  115] Training loss: 0.60842450, Validation loss: 0.62056992, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35796.30859375MB; mem (CPU total)=78837.84765625MB
INFO:root:[  116] Training loss: 0.60846152, Validation loss: 0.62132436, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35834.40625MB; mem (CPU total)=78914.4453125MB
INFO:root:[  117] Training loss: 0.60870745, Validation loss: 0.61940481, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35872.50390625MB; mem (CPU total)=78991.01171875MB
INFO:root:[  118] Training loss: 0.60840474, Validation loss: 0.62199866, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35910.59765625MB; mem (CPU total)=79067.6484375MB
INFO:root:[  119] Training loss: 0.60841766, Validation loss: 0.62066823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35948.69140625MB; mem (CPU total)=79143.94921875MB
INFO:root:[  120] Training loss: 0.60800999, Validation loss: 0.62032623, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35986.7890625MB; mem (CPU total)=79219.828125MB
INFO:root:[  121] Training loss: 0.60744819, Validation loss: 0.62097345, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36024.8828125MB; mem (CPU total)=79296.01953125MB
INFO:root:[  122] Training loss: 0.60717622, Validation loss: 0.62031082, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36062.9765625MB; mem (CPU total)=79372.11328125MB
INFO:root:[  123] Training loss: 0.60716921, Validation loss: 0.62039336, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36101.07421875MB; mem (CPU total)=79448.6640625MB
INFO:root:[  124] Training loss: 0.60650511, Validation loss: 0.61975433, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36139.16796875MB; mem (CPU total)=79524.73828125MB
INFO:root:[  125] Training loss: 0.60688911, Validation loss: 0.62042788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36177.265625MB; mem (CPU total)=79601.3046875MB
INFO:root:[  126] Training loss: 0.60593931, Validation loss: 0.61867558, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36216.61328125MB; mem (CPU total)=79679.515625MB
INFO:root:[  127] Training loss: 0.60570423, Validation loss: 0.61914589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36254.70703125MB; mem (CPU total)=79755.5703125MB
INFO:root:[  128] Training loss: 0.60582497, Validation loss: 0.61982212, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36292.796875MB; mem (CPU total)=79831.87890625MB
INFO:root:[  129] Training loss: 0.60569296, Validation loss: 0.61956509, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36332.140625MB; mem (CPU total)=79909.171875MB
INFO:root:[  130] Training loss: 0.60535620, Validation loss: 0.61981585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36370.23828125MB; mem (CPU total)=79985.39453125MB
INFO:root:[  131] Training loss: 0.60505365, Validation loss: 0.61981400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36408.3359375MB; mem (CPU total)=80060.51171875MB
INFO:root:[  132] Training loss: 0.60458699, Validation loss: 0.61970418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36446.4296875MB; mem (CPU total)=80132.67578125MB
INFO:root:[  133] Training loss: 0.60473718, Validation loss: 0.61836556, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36484.52734375MB; mem (CPU total)=80207.296875MB
INFO:root:[  134] Training loss: 0.60457251, Validation loss: 0.61920292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36522.62109375MB; mem (CPU total)=80283.11328125MB
INFO:root:[  135] Training loss: 0.60434001, Validation loss: 0.61857043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36560.71875MB; mem (CPU total)=80355.25MB
INFO:root:[  136] Training loss: 0.60391130, Validation loss: 0.61884379, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36598.8125MB; mem (CPU total)=80429.9765625MB
INFO:root:[  137] Training loss: 0.60384402, Validation loss: 0.61888596, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36636.91015625MB; mem (CPU total)=80504.6484375MB
INFO:root:[  138] Training loss: 0.60392385, Validation loss: 0.61900830, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36675.00390625MB; mem (CPU total)=80577.94921875MB
INFO:root:[  139] Training loss: 0.60385672, Validation loss: 0.61893028, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36713.09765625MB; mem (CPU total)=80653.74609375MB
INFO:root:[  140] Training loss: 0.60320947, Validation loss: 0.61826461, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36751.1953125MB; mem (CPU total)=80727.06640625MB
INFO:root:[  141] Training loss: 0.60288622, Validation loss: 0.61937579, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36789.2890625MB; mem (CPU total)=80800.671875MB
INFO:root:[  142] Training loss: 0.60285490, Validation loss: 0.61883303, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36827.38671875MB; mem (CPU total)=80876.46484375MB
INFO:root:[  143] Training loss: 0.60195269, Validation loss: 0.61821821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36865.48828125MB; mem (CPU total)=80950.51171875MB
INFO:root:[  144] Training loss: 0.60191199, Validation loss: 0.61834117, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36903.58203125MB; mem (CPU total)=81024.53125MB
INFO:root:[  145] Training loss: 0.60157574, Validation loss: 0.61914445, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36941.6796875MB; mem (CPU total)=81099.09765625MB
INFO:root:[  146] Training loss: 0.60219647, Validation loss: 0.61820344, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36979.7734375MB; mem (CPU total)=81173.25MB
INFO:root:[  147] Training loss: 0.60167451, Validation loss: 0.61795261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37017.87109375MB; mem (CPU total)=81247.84765625MB
INFO:root:[  148] Training loss: 0.60113244, Validation loss: 0.61772861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37055.96484375MB; mem (CPU total)=81322.4921875MB
INFO:root:[  149] Training loss: 0.60111276, Validation loss: 0.61830255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37094.05859375MB; mem (CPU total)=81398.28515625MB
INFO:root:[  150] Training loss: 0.60155385, Validation loss: 0.61744157, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37132.15625MB; mem (CPU total)=81474.3359375MB
INFO:root:[  151] Training loss: 0.60140911, Validation loss: 0.61710406, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37170.25MB; mem (CPU total)=81550.83203125MB
INFO:root:[  152] Training loss: 0.60113995, Validation loss: 0.61897006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37208.34765625MB; mem (CPU total)=81627.04296875MB
INFO:root:[  153] Training loss: 0.60062653, Validation loss: 0.61803756, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37246.44140625MB; mem (CPU total)=81703.33203125MB
INFO:root:[  154] Training loss: 0.60091043, Validation loss: 0.61791397, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37284.5390625MB; mem (CPU total)=81780.296875MB
INFO:root:[  155] Training loss: 0.59943992, Validation loss: 0.61819716, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37322.6328125MB; mem (CPU total)=81855.51953125MB
INFO:root:[  156] Training loss: 0.59961995, Validation loss: 0.61762856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37360.7265625MB; mem (CPU total)=81931.2265625MB
INFO:root:[  157] Training loss: 0.59915213, Validation loss: 0.61858093, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37398.82421875MB; mem (CPU total)=82008.28125MB
INFO:root:[  158] Training loss: 0.59989477, Validation loss: 0.61770762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37436.91796875MB; mem (CPU total)=82084.25390625MB
INFO:root:[  159] Training loss: 0.59949899, Validation loss: 0.61664065, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37475.01171875MB; mem (CPU total)=82160.5234375MB
INFO:root:[  160] Training loss: 0.59928398, Validation loss: 0.61768400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37513.11328125MB; mem (CPU total)=82237.05859375MB
INFO:root:[  161] Training loss: 0.59907650, Validation loss: 0.61827559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37551.20703125MB; mem (CPU total)=82313.34765625MB
INFO:root:[  162] Training loss: 0.59858561, Validation loss: 0.61732703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37589.30078125MB; mem (CPU total)=82389.63671875MB
INFO:root:[  163] Training loss: 0.59870984, Validation loss: 0.61768125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37627.39453125MB; mem (CPU total)=82466.09765625MB
INFO:root:[  164] Training loss: 0.59846328, Validation loss: 0.61854035, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37665.4921875MB; mem (CPU total)=82542.62890625MB
INFO:root:[  165] Training loss: 0.59834509, Validation loss: 0.61877417, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37703.5859375MB; mem (CPU total)=82630.37109375MB
INFO:root:[  166] Training loss: 0.59775445, Validation loss: 0.61773043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37741.6796875MB; mem (CPU total)=82696.00390625MB
INFO:root:[  167] Training loss: 0.59797369, Validation loss: 0.61818360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37779.77734375MB; mem (CPU total)=82737.1015625MB
INFO:root:[  168] Training loss: 0.59756188, Validation loss: 0.61773046, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37817.87109375MB; mem (CPU total)=82811.453125MB
INFO:root:EP 168: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=37855.96875MB; mem (CPU total)=82887.25MB
INFO:root:Training the model took 13375.736s.
INFO:root:Emptying the cuda cache took 0.054s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84919
INFO:root:EnergyScoreTrain: 0.59817
INFO:root:CRPSTrain: 0.52221
INFO:root:Gaussian NLLTrain: 2.79008
INFO:root:CoverageTrain: 0.79905
INFO:root:IntervalWidthTrain: 3.13945
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87706
INFO:root:EnergyScoreValidation: 0.61752
INFO:root:CRPSValidation: 0.5378
INFO:root:Gaussian NLLValidation: 2.83478
INFO:root:CoverageValidation: 0.79058
INFO:root:IntervalWidthValidation: 3.13234
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87824
INFO:root:EnergyScoreTest: 0.6184
INFO:root:CRPSTest: 0.53866
INFO:root:Gaussian NLLTest: 2.82408
INFO:root:CoverageTest: 0.79022
INFO:root:IntervalWidthTest: 3.1364
INFO:root:After validation: mem (CPU python)=37898.69921875MB; mem (CPU total)=83028.9453125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=37898.69921875MB; mem (CPU total)=83045.0078125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 157286400
INFO:root:After setting up the model: mem (CPU python)=37899.2578125MB; mem (CPU total)=83045.5MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=37899.2578125MB; mem (CPU total)=83070.80859375MB
INFO:root:[    1] Training loss: 0.78596897, Validation loss: 0.72480395, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37937.390625MB; mem (CPU total)=83146.23828125MB
INFO:root:[    2] Training loss: 0.72319183, Validation loss: 0.72139438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37975.48828125MB; mem (CPU total)=83218.8359375MB
INFO:root:[    3] Training loss: 0.72139131, Validation loss: 0.72099940, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38013.58203125MB; mem (CPU total)=83294.0859375MB
INFO:root:[    4] Training loss: 0.72043194, Validation loss: 0.72013904, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38051.68359375MB; mem (CPU total)=83367.68359375MB
INFO:root:[    5] Training loss: 0.71998393, Validation loss: 0.71952712, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38089.78125MB; mem (CPU total)=83442.1796875MB
INFO:root:[    6] Training loss: 0.72006634, Validation loss: 0.71938913, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38127.87890625MB; mem (CPU total)=83518.421875MB
INFO:root:[    7] Training loss: 0.71933063, Validation loss: 0.71969948, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38165.97265625MB; mem (CPU total)=83592.9609375MB
INFO:root:[    8] Training loss: 0.71907133, Validation loss: 0.71907240, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38204.06640625MB; mem (CPU total)=83667.9140625MB
INFO:root:[    9] Training loss: 0.71873886, Validation loss: 0.71948073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38242.1640625MB; mem (CPU total)=83742.9609375MB
INFO:root:[   10] Training loss: 0.71818481, Validation loss: 0.71804711, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38280.2578125MB; mem (CPU total)=83817.6875MB
INFO:root:[   11] Training loss: 0.71677815, Validation loss: 0.71583479, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38318.3515625MB; mem (CPU total)=83893.8828125MB
INFO:root:[   12] Training loss: 0.71119305, Validation loss: 0.70606635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38356.44921875MB; mem (CPU total)=83968.01171875MB
INFO:root:[   13] Training loss: 0.70002275, Validation loss: 0.69510703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38394.546875MB; mem (CPU total)=84043.02734375MB
INFO:root:[   14] Training loss: 0.69072469, Validation loss: 0.68762857, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38432.640625MB; mem (CPU total)=84118.58984375MB
INFO:root:[   15] Training loss: 0.68341804, Validation loss: 0.68176867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38470.734375MB; mem (CPU total)=84193.69921875MB
INFO:root:[   16] Training loss: 0.67762868, Validation loss: 0.67640771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38508.83203125MB; mem (CPU total)=84269.21875MB
INFO:root:[   17] Training loss: 0.67276908, Validation loss: 0.67209760, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38546.92578125MB; mem (CPU total)=84344.5546875MB
INFO:root:[   18] Training loss: 0.66940238, Validation loss: 0.66891647, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38585.01953125MB; mem (CPU total)=84418.828125MB
INFO:root:[   19] Training loss: 0.66595322, Validation loss: 0.66591145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38623.1171875MB; mem (CPU total)=84494.125MB
INFO:root:[   20] Training loss: 0.66361593, Validation loss: 0.66432116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38661.2109375MB; mem (CPU total)=84570.3515625MB
INFO:root:[   21] Training loss: 0.66153652, Validation loss: 0.66122911, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38699.3046875MB; mem (CPU total)=84646.96875MB
INFO:root:[   22] Training loss: 0.65967171, Validation loss: 0.66026472, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38737.40625MB; mem (CPU total)=84723.23046875MB
INFO:root:[   23] Training loss: 0.65796181, Validation loss: 0.65938369, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38775.5MB; mem (CPU total)=84799.98046875MB
INFO:root:[   24] Training loss: 0.65635884, Validation loss: 0.65729149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38813.59375MB; mem (CPU total)=84876.21484375MB
INFO:root:[   25] Training loss: 0.65489967, Validation loss: 0.65669826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38851.7421875MB; mem (CPU total)=84952.609375MB
INFO:root:[   26] Training loss: 0.65344660, Validation loss: 0.65598054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38889.78515625MB; mem (CPU total)=85028.90234375MB
INFO:root:[   27] Training loss: 0.65251101, Validation loss: 0.65474164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38927.87890625MB; mem (CPU total)=85105.38671875MB
INFO:root:[   28] Training loss: 0.65133207, Validation loss: 0.65320354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38965.97265625MB; mem (CPU total)=85182.6328125MB
INFO:root:[   29] Training loss: 0.65030000, Validation loss: 0.65160721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39004.0703125MB; mem (CPU total)=85259.16796875MB
INFO:root:[   30] Training loss: 0.64919243, Validation loss: 0.65066357, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39042.16796875MB; mem (CPU total)=85335.4921875MB
INFO:root:[   31] Training loss: 0.64809347, Validation loss: 0.65089553, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39080.26171875MB; mem (CPU total)=85411.7109375MB
INFO:root:[   32] Training loss: 0.64702803, Validation loss: 0.64910151, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39118.35546875MB; mem (CPU total)=85488.03125MB
INFO:root:[   33] Training loss: 0.64649858, Validation loss: 0.64942245, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39156.453125MB; mem (CPU total)=85564.00390625MB
INFO:root:[   34] Training loss: 0.64529746, Validation loss: 0.64822978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39194.546875MB; mem (CPU total)=85640.57421875MB
INFO:root:[   35] Training loss: 0.64449015, Validation loss: 0.64776087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39232.640625MB; mem (CPU total)=85716.29296875MB
INFO:root:[   36] Training loss: 0.64362471, Validation loss: 0.64566786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39270.73828125MB; mem (CPU total)=85792.31640625MB
INFO:root:[   37] Training loss: 0.64266155, Validation loss: 0.64520513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39308.83984375MB; mem (CPU total)=85869.1328125MB
INFO:root:[   38] Training loss: 0.64188582, Validation loss: 0.64512148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39346.93359375MB; mem (CPU total)=85945.453125MB
INFO:root:[   39] Training loss: 0.64158089, Validation loss: 0.64438685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39385.03125MB; mem (CPU total)=86022.0234375MB
INFO:root:[   40] Training loss: 0.64072092, Validation loss: 0.64330633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39423.125MB; mem (CPU total)=86098.3203125MB
INFO:root:[   41] Training loss: 0.63972795, Validation loss: 0.64200894, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39461.21875MB; mem (CPU total)=86174.34375MB
INFO:root:[   42] Training loss: 0.63864804, Validation loss: 0.64233283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39499.31640625MB; mem (CPU total)=86250.83984375MB
INFO:root:[   43] Training loss: 0.63842878, Validation loss: 0.64191396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39537.41015625MB; mem (CPU total)=86327.36328125MB
INFO:root:[   44] Training loss: 0.63727590, Validation loss: 0.64106422, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39575.5078125MB; mem (CPU total)=86403.77734375MB
INFO:root:[   45] Training loss: 0.63665375, Validation loss: 0.64025972, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39613.6015625MB; mem (CPU total)=86480.62109375MB
INFO:root:[   46] Training loss: 0.63603899, Validation loss: 0.63906002, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39651.69921875MB; mem (CPU total)=86556.6953125MB
INFO:root:[   47] Training loss: 0.63537955, Validation loss: 0.63987576, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39689.79296875MB; mem (CPU total)=86633.35546875MB
INFO:root:[   48] Training loss: 0.63491831, Validation loss: 0.63784742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39727.88671875MB; mem (CPU total)=86709.73046875MB
INFO:root:[   49] Training loss: 0.63417529, Validation loss: 0.63815981, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39765.98046875MB; mem (CPU total)=86785.734375MB
INFO:root:[   50] Training loss: 0.63387685, Validation loss: 0.63759710, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39804.08203125MB; mem (CPU total)=86862.109375MB
INFO:root:[   51] Training loss: 0.63279790, Validation loss: 0.63758931, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39842.17578125MB; mem (CPU total)=86938.078125MB
INFO:root:[   52] Training loss: 0.63215014, Validation loss: 0.63711759, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39880.26953125MB; mem (CPU total)=87014.15234375MB
INFO:root:[   53] Training loss: 0.63177510, Validation loss: 0.63565535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39918.3671875MB; mem (CPU total)=87090.75390625MB
INFO:root:[   54] Training loss: 0.63085739, Validation loss: 0.63603171, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39956.4609375MB; mem (CPU total)=87167.3828125MB
INFO:root:[   55] Training loss: 0.63030352, Validation loss: 0.63610660, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39994.55859375MB; mem (CPU total)=87243.6796875MB
INFO:root:[   56] Training loss: 0.63014003, Validation loss: 0.63483451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40032.65625MB; mem (CPU total)=87319.91796875MB
INFO:root:[   57] Training loss: 0.62956028, Validation loss: 0.63396125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40070.75MB; mem (CPU total)=87395.8671875MB
INFO:root:[   58] Training loss: 0.62907362, Validation loss: 0.63454249, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40108.84375MB; mem (CPU total)=87471.1875MB
INFO:root:[   59] Training loss: 0.62826261, Validation loss: 0.63345218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40146.9375MB; mem (CPU total)=87544.578125MB
INFO:root:[   60] Training loss: 0.62796520, Validation loss: 0.63326501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40185.03515625MB; mem (CPU total)=87620.26171875MB
INFO:root:[   61] Training loss: 0.62734555, Validation loss: 0.63281377, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40223.12890625MB; mem (CPU total)=87692.3515625MB
INFO:root:[   62] Training loss: 0.62678162, Validation loss: 0.63177320, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40261.22265625MB; mem (CPU total)=87767.44140625MB
INFO:root:[   63] Training loss: 0.62615576, Validation loss: 0.63201785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40299.3203125MB; mem (CPU total)=87839.421875MB
INFO:root:[   64] Training loss: 0.62567322, Validation loss: 0.63126124, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40337.41796875MB; mem (CPU total)=87914.01171875MB
INFO:root:[   65] Training loss: 0.62549055, Validation loss: 0.63091504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40375.51171875MB; mem (CPU total)=87987.828125MB
INFO:root:[   66] Training loss: 0.62500060, Validation loss: 0.63129299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40413.60546875MB; mem (CPU total)=88064.8203125MB
INFO:root:[   67] Training loss: 0.62462211, Validation loss: 0.63029795, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40451.703125MB; mem (CPU total)=88138.58984375MB
INFO:root:[   68] Training loss: 0.62448923, Validation loss: 0.62978100, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40489.796875MB; mem (CPU total)=88212.4140625MB
INFO:root:[   69] Training loss: 0.62392626, Validation loss: 0.63004771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40527.890625MB; mem (CPU total)=88287.22265625MB
INFO:root:[   70] Training loss: 0.62283553, Validation loss: 0.63011254, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40565.98828125MB; mem (CPU total)=88360.56640625MB
INFO:root:[   71] Training loss: 0.62293510, Validation loss: 0.62942572, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40604.0859375MB; mem (CPU total)=88435.82421875MB
INFO:root:[   72] Training loss: 0.62256698, Validation loss: 0.62955645, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40642.1796875MB; mem (CPU total)=88509.640625MB
INFO:root:[   73] Training loss: 0.62226849, Validation loss: 0.62929688, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40680.27734375MB; mem (CPU total)=88584.26953125MB
INFO:root:[   74] Training loss: 0.62167140, Validation loss: 0.62953643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40718.37109375MB; mem (CPU total)=88657.63671875MB
INFO:root:[   75] Training loss: 0.62145115, Validation loss: 0.62737456, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40756.46484375MB; mem (CPU total)=88732.75390625MB
INFO:root:[   76] Training loss: 0.62060009, Validation loss: 0.62816527, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40794.55859375MB; mem (CPU total)=88809.19921875MB
INFO:root:[   77] Training loss: 0.62008543, Validation loss: 0.62775857, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40832.65625MB; mem (CPU total)=88884.828125MB
INFO:root:[   78] Training loss: 0.61998705, Validation loss: 0.62696498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40870.75MB; mem (CPU total)=88961.1484375MB
INFO:root:[   79] Training loss: 0.61952723, Validation loss: 0.62729116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40908.84375MB; mem (CPU total)=89037.94140625MB
INFO:root:[   80] Training loss: 0.61933051, Validation loss: 0.62644204, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40946.94921875MB; mem (CPU total)=89114.26171875MB
INFO:root:[   81] Training loss: 0.61897360, Validation loss: 0.62615264, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40985.04296875MB; mem (CPU total)=89190.58203125MB
INFO:root:[   82] Training loss: 0.61887303, Validation loss: 0.62569286, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41023.13671875MB; mem (CPU total)=89266.58984375MB
INFO:root:[   83] Training loss: 0.61831955, Validation loss: 0.62674845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41061.23046875MB; mem (CPU total)=89342.93359375MB
INFO:root:[   84] Training loss: 0.61788233, Validation loss: 0.62530253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41099.328125MB; mem (CPU total)=89419.703125MB
INFO:root:[   85] Training loss: 0.61721284, Validation loss: 0.62580892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41137.42578125MB; mem (CPU total)=89496.14453125MB
INFO:root:[   86] Training loss: 0.61742449, Validation loss: 0.62533944, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41175.51953125MB; mem (CPU total)=89572.38671875MB
INFO:root:[   87] Training loss: 0.61647449, Validation loss: 0.62418508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41213.6171875MB; mem (CPU total)=89648.21484375MB
INFO:root:[   88] Training loss: 0.61640366, Validation loss: 0.62401877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41251.7109375MB; mem (CPU total)=89724.9609375MB
INFO:root:[   89] Training loss: 0.61592959, Validation loss: 0.62614597, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41289.8046875MB; mem (CPU total)=89801.265625MB
INFO:root:[   90] Training loss: 0.61571761, Validation loss: 0.62509244, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41327.90234375MB; mem (CPU total)=89877.95703125MB
INFO:root:[   91] Training loss: 0.61552332, Validation loss: 0.62397556, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41365.99609375MB; mem (CPU total)=89954.3125MB
INFO:root:[   92] Training loss: 0.61511581, Validation loss: 0.62390049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41404.08984375MB; mem (CPU total)=90029.85546875MB
INFO:root:[   93] Training loss: 0.61486446, Validation loss: 0.62388852, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41442.1875MB; mem (CPU total)=90106.41015625MB
INFO:root:[   94] Training loss: 0.61445334, Validation loss: 0.62490835, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41480.28515625MB; mem (CPU total)=90182.69921875MB
INFO:root:[   95] Training loss: 0.61427862, Validation loss: 0.62356671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41518.37890625MB; mem (CPU total)=90259.0390625MB
INFO:root:[   96] Training loss: 0.61393294, Validation loss: 0.62351139, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41556.47265625MB; mem (CPU total)=90335.58984375MB
INFO:root:[   97] Training loss: 0.61387121, Validation loss: 0.62333830, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41594.5703125MB; mem (CPU total)=90411.66015625MB
INFO:root:[   98] Training loss: 0.61298800, Validation loss: 0.62344012, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41632.6640625MB; mem (CPU total)=90488.0234375MB
INFO:root:[   99] Training loss: 0.61293715, Validation loss: 0.62414210, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41670.7578125MB; mem (CPU total)=90564.31640625MB
INFO:root:[  100] Training loss: 0.61264470, Validation loss: 0.62415009, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41708.8515625MB; mem (CPU total)=90637.5625MB
INFO:root:[  101] Training loss: 0.61219179, Validation loss: 0.62380132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41746.953125MB; mem (CPU total)=90711.6640625MB
INFO:root:[  102] Training loss: 0.61191994, Validation loss: 0.62469172, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41785.046875MB; mem (CPU total)=90782.765625MB
INFO:root:[  103] Training loss: 0.61163001, Validation loss: 0.62323833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41823.140625MB; mem (CPU total)=90856.5078125MB
INFO:root:[  104] Training loss: 0.61180186, Validation loss: 0.62195209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41861.23828125MB; mem (CPU total)=90929.921875MB
INFO:root:[  105] Training loss: 0.61129343, Validation loss: 0.62283822, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41899.33203125MB; mem (CPU total)=91003.01953125MB
INFO:root:[  106] Training loss: 0.61083004, Validation loss: 0.62359732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41937.42578125MB; mem (CPU total)=91076.1328125MB
INFO:root:[  107] Training loss: 0.61063074, Validation loss: 0.62190580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41975.5234375MB; mem (CPU total)=91148.453125MB
INFO:root:[  108] Training loss: 0.61008261, Validation loss: 0.62092085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42013.6171875MB; mem (CPU total)=91221.8125MB
INFO:root:[  109] Training loss: 0.61003707, Validation loss: 0.62171352, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42051.71484375MB; mem (CPU total)=91294.34375MB
INFO:root:[  110] Training loss: 0.61022135, Validation loss: 0.62160268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42089.80859375MB; mem (CPU total)=91368.6640625MB
INFO:root:[  111] Training loss: 0.60946167, Validation loss: 0.62169920, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42127.90625MB; mem (CPU total)=91441.39453125MB
INFO:root:[  112] Training loss: 0.60978400, Validation loss: 0.62007099, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42166.0MB; mem (CPU total)=91517.921875MB
INFO:root:[  113] Training loss: 0.60899854, Validation loss: 0.62134840, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42204.09375MB; mem (CPU total)=91594.26171875MB
INFO:root:[  114] Training loss: 0.60890839, Validation loss: 0.62229535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42242.19140625MB; mem (CPU total)=91670.55078125MB
INFO:root:[  115] Training loss: 0.60852687, Validation loss: 0.62014962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42280.28515625MB; mem (CPU total)=91746.78125MB
INFO:root:[  116] Training loss: 0.60838241, Validation loss: 0.62019900, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42318.3828125MB; mem (CPU total)=91823.1328125MB
INFO:root:[  117] Training loss: 0.60835319, Validation loss: 0.62150822, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42356.48046875MB; mem (CPU total)=91899.203125MB
INFO:root:[  118] Training loss: 0.60792024, Validation loss: 0.62169060, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42394.578125MB; mem (CPU total)=91975.80078125MB
INFO:root:[  119] Training loss: 0.60728492, Validation loss: 0.62115496, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42432.671875MB; mem (CPU total)=92051.88671875MB
INFO:root:[  120] Training loss: 0.60714511, Validation loss: 0.61947245, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42470.765625MB; mem (CPU total)=92128.69140625MB
INFO:root:[  121] Training loss: 0.60713491, Validation loss: 0.62110149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42508.86328125MB; mem (CPU total)=92204.9453125MB
INFO:root:[  122] Training loss: 0.60645953, Validation loss: 0.62115951, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42546.95703125MB; mem (CPU total)=92281.08203125MB
INFO:root:[  123] Training loss: 0.60656882, Validation loss: 0.62001863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42585.0546875MB; mem (CPU total)=92357.1328125MB
INFO:root:[  124] Training loss: 0.60624698, Validation loss: 0.62065694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42623.15234375MB; mem (CPU total)=92434.17578125MB
INFO:root:[  125] Training loss: 0.60574714, Validation loss: 0.61998491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42661.24609375MB; mem (CPU total)=92510.765625MB
INFO:root:[  126] Training loss: 0.60567254, Validation loss: 0.62076762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42699.34375MB; mem (CPU total)=92587.33203125MB
INFO:root:[  127] Training loss: 0.60513275, Validation loss: 0.61996013, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42737.4375MB; mem (CPU total)=92663.62109375MB
INFO:root:[  128] Training loss: 0.60512496, Validation loss: 0.61914283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42775.53125MB; mem (CPU total)=92738.21875MB
INFO:root:[  129] Training loss: 0.60479974, Validation loss: 0.61970577, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42813.62890625MB; mem (CPU total)=92809.12890625MB
INFO:root:[  130] Training loss: 0.60511010, Validation loss: 0.61959502, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42851.72265625MB; mem (CPU total)=92882.21875MB
INFO:root:[  131] Training loss: 0.60481991, Validation loss: 0.61968833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42889.8203125MB; mem (CPU total)=92952.84375MB
INFO:root:[  132] Training loss: 0.60423881, Validation loss: 0.61973041, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42927.9140625MB; mem (CPU total)=93025.95703125MB
INFO:root:[  133] Training loss: 0.60394160, Validation loss: 0.61987735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42966.0078125MB; mem (CPU total)=93096.2734375MB
INFO:root:[  134] Training loss: 0.60454517, Validation loss: 0.62083791, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43004.1015625MB; mem (CPU total)=93170.2734375MB
INFO:root:[  135] Training loss: 0.60403114, Validation loss: 0.62082528, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43042.203125MB; mem (CPU total)=93240.296875MB
INFO:root:[  136] Training loss: 0.60357468, Validation loss: 0.61837130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43080.29296875MB; mem (CPU total)=93314.19140625MB
INFO:root:[  137] Training loss: 0.60341555, Validation loss: 0.61964614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43118.38671875MB; mem (CPU total)=93388.82421875MB
INFO:root:[  138] Training loss: 0.60336583, Validation loss: 0.61869429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43156.48828125MB; mem (CPU total)=93464.91015625MB
INFO:root:[  139] Training loss: 0.60316539, Validation loss: 0.61881705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43194.58203125MB; mem (CPU total)=93541.4375MB
INFO:root:[  140] Training loss: 0.60261040, Validation loss: 0.61941203, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43232.67578125MB; mem (CPU total)=93617.27734375MB
INFO:root:[  141] Training loss: 0.60230338, Validation loss: 0.61943342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43270.77734375MB; mem (CPU total)=93693.59765625MB
INFO:root:[  142] Training loss: 0.60208053, Validation loss: 0.61882501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43308.87109375MB; mem (CPU total)=93769.91796875MB
INFO:root:[  143] Training loss: 0.60173767, Validation loss: 0.61855385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43346.96484375MB; mem (CPU total)=93846.421875MB
INFO:root:[  144] Training loss: 0.60171157, Validation loss: 0.61827657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43385.05859375MB; mem (CPU total)=93922.7578125MB
INFO:root:[  145] Training loss: 0.60191777, Validation loss: 0.61897042, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43423.15625MB; mem (CPU total)=93998.89453125MB
INFO:root:[  146] Training loss: 0.60154454, Validation loss: 0.61958178, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43461.25MB; mem (CPU total)=94075.52734375MB
INFO:root:[  147] Training loss: 0.60148237, Validation loss: 0.61915452, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43499.34375MB; mem (CPU total)=94151.3671875MB
INFO:root:[  148] Training loss: 0.60104817, Validation loss: 0.61866748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43537.44140625MB; mem (CPU total)=94227.046875MB
INFO:root:[  149] Training loss: 0.60058662, Validation loss: 0.61918341, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43575.53515625MB; mem (CPU total)=94303.83984375MB
INFO:root:[  150] Training loss: 0.60033042, Validation loss: 0.61933769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43613.6328125MB; mem (CPU total)=94378.68359375MB
INFO:root:[  151] Training loss: 0.59991464, Validation loss: 0.61920926, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43651.7265625MB; mem (CPU total)=94450.46875MB
INFO:root:[  152] Training loss: 0.59994361, Validation loss: 0.61826689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43689.82421875MB; mem (CPU total)=94520.14453125MB
INFO:root:[  153] Training loss: 0.60017532, Validation loss: 0.61865783, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43727.91796875MB; mem (CPU total)=94593.140625MB
INFO:root:[  154] Training loss: 0.59955974, Validation loss: 0.61885210, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43766.01171875MB; mem (CPU total)=94663.015625MB
INFO:root:[  155] Training loss: 0.59978818, Validation loss: 0.61915483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43804.109375MB; mem (CPU total)=94735.87890625MB
INFO:root:[  156] Training loss: 0.59990300, Validation loss: 0.62007091, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43842.203125MB; mem (CPU total)=94805.33203125MB
INFO:root:[  157] Training loss: 0.59900872, Validation loss: 0.61877353, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43880.296875MB; mem (CPU total)=94878.20703125MB
INFO:root:[  158] Training loss: 0.59898276, Validation loss: 0.61853429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43918.39453125MB; mem (CPU total)=94952.2734375MB
INFO:root:[  159] Training loss: 0.59878931, Validation loss: 0.61922077, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43956.48828125MB; mem (CPU total)=95028.9296875MB
INFO:root:[  160] Training loss: 0.59862059, Validation loss: 0.61899866, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43994.5859375MB; mem (CPU total)=95105.49609375MB
INFO:root:[  161] Training loss: 0.59831131, Validation loss: 0.61840543, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44032.6796875MB; mem (CPU total)=95181.5390625MB
INFO:root:EP 161: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=44070.77734375MB; mem (CPU total)=95244.78515625MB
INFO:root:Training the model took 13979.41s.
INFO:root:Emptying the cuda cache took 0.05s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85062
INFO:root:EnergyScoreTrain: 0.59911
INFO:root:CRPSTrain: 0.52354
INFO:root:Gaussian NLLTrain: 2.64292
INFO:root:CoverageTrain: 0.79495
INFO:root:IntervalWidthTrain: 3.11518
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87814
INFO:root:EnergyScoreValidation: 0.61841
INFO:root:CRPSValidation: 0.53916
INFO:root:Gaussian NLLValidation: 2.69229
INFO:root:CoverageValidation: 0.78674
INFO:root:IntervalWidthValidation: 3.11012
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87971
INFO:root:EnergyScoreTest: 0.6196
INFO:root:CRPSTest: 0.5401
INFO:root:Gaussian NLLTest: 2.69087
INFO:root:CoverageTest: 0.78616
INFO:root:IntervalWidthTest: 3.10738
INFO:root:After validation: mem (CPU python)=44113.64453125MB; mem (CPU total)=95377.40234375MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=44113.6484375MB; mem (CPU total)=95409.88671875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=44114.09765625MB; mem (CPU total)=95411.36328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=44114.09765625MB; mem (CPU total)=95415.6640625MB
INFO:root:[    1] Training loss: 0.79958559, Validation loss: 0.72838170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44154.7109375MB; mem (CPU total)=95494.16796875MB
INFO:root:[    2] Training loss: 0.72336137, Validation loss: 0.72219990, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44192.80078125MB; mem (CPU total)=95570.6953125MB
INFO:root:[    3] Training loss: 0.72068309, Validation loss: 0.72039706, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44230.8984375MB; mem (CPU total)=95647.015625MB
INFO:root:[    4] Training loss: 0.72000051, Validation loss: 0.72089934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44268.99609375MB; mem (CPU total)=95723.50390625MB
INFO:root:[    5] Training loss: 0.72003844, Validation loss: 0.72101259, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44307.08984375MB; mem (CPU total)=95799.84375MB
INFO:root:[    6] Training loss: 0.71951160, Validation loss: 0.72013674, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44345.18359375MB; mem (CPU total)=95875.89453125MB
INFO:root:[    7] Training loss: 0.71929068, Validation loss: 0.71870101, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44383.28125MB; mem (CPU total)=95952.34375MB
INFO:root:[    8] Training loss: 0.71829604, Validation loss: 0.71782381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44421.375MB; mem (CPU total)=96028.81640625MB
INFO:root:[    9] Training loss: 0.71761314, Validation loss: 0.71750978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44459.46875MB; mem (CPU total)=96105.359375MB
INFO:root:[   10] Training loss: 0.71446765, Validation loss: 0.71172395, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44497.56640625MB; mem (CPU total)=96180.93359375MB
INFO:root:[   11] Training loss: 0.70793562, Validation loss: 0.70467539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44535.6640625MB; mem (CPU total)=96251.546875MB
INFO:root:[   12] Training loss: 0.70118517, Validation loss: 0.69934827, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44573.7578125MB; mem (CPU total)=96322.87109375MB
INFO:root:[   13] Training loss: 0.69610860, Validation loss: 0.69465960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44611.8515625MB; mem (CPU total)=96393.9453125MB
INFO:root:[   14] Training loss: 0.69203269, Validation loss: 0.69070704, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44649.94921875MB; mem (CPU total)=96465.35546875MB
INFO:root:[   15] Training loss: 0.68738725, Validation loss: 0.68673633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44688.046875MB; mem (CPU total)=96536.24609375MB
INFO:root:[   16] Training loss: 0.68400686, Validation loss: 0.68408607, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44726.140625MB; mem (CPU total)=96607.859375MB
INFO:root:[   17] Training loss: 0.68114041, Validation loss: 0.68085655, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44764.2421875MB; mem (CPU total)=96677.90625MB
INFO:root:[   18] Training loss: 0.67807644, Validation loss: 0.67822970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44802.3359375MB; mem (CPU total)=96753.4921875MB
INFO:root:[   19] Training loss: 0.67550004, Validation loss: 0.67614450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44840.4296875MB; mem (CPU total)=96829.53515625MB
INFO:root:[   20] Training loss: 0.67286843, Validation loss: 0.67312861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44878.5234375MB; mem (CPU total)=96906.23046875MB
INFO:root:[   21] Training loss: 0.67057030, Validation loss: 0.67056390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44916.62109375MB; mem (CPU total)=96982.28125MB
INFO:root:[   22] Training loss: 0.66862966, Validation loss: 0.67040678, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44954.71484375MB; mem (CPU total)=97058.62890625MB
INFO:root:[   23] Training loss: 0.66705696, Validation loss: 0.66786853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44992.80859375MB; mem (CPU total)=97134.91796875MB
INFO:root:[   24] Training loss: 0.66487286, Validation loss: 0.66648091, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45030.91015625MB; mem (CPU total)=97211.15234375MB
INFO:root:[   25] Training loss: 0.66353369, Validation loss: 0.66538086, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45069.00390625MB; mem (CPU total)=97287.8828125MB
INFO:root:[   26] Training loss: 0.66181063, Validation loss: 0.66193399, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45107.09765625MB; mem (CPU total)=97362.9296875MB
INFO:root:[   27] Training loss: 0.66046844, Validation loss: 0.66190498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45145.19140625MB; mem (CPU total)=97439.2109375MB
INFO:root:[   28] Training loss: 0.65965044, Validation loss: 0.65967325, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45183.2890625MB; mem (CPU total)=97516.078125MB
INFO:root:[   29] Training loss: 0.65798034, Validation loss: 0.65908353, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45221.3828125MB; mem (CPU total)=97592.12109375MB
INFO:root:[   30] Training loss: 0.65705773, Validation loss: 0.65780873, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45259.4765625MB; mem (CPU total)=97668.6171875MB
INFO:root:[   31] Training loss: 0.65581747, Validation loss: 0.65579236, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45297.57421875MB; mem (CPU total)=97741.921875MB
INFO:root:[   32] Training loss: 0.65464617, Validation loss: 0.65568270, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45335.671875MB; mem (CPU total)=97814.51953125MB
INFO:root:[   33] Training loss: 0.65303140, Validation loss: 0.65587142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45373.765625MB; mem (CPU total)=97883.61328125MB
INFO:root:[   34] Training loss: 0.65254330, Validation loss: 0.65252470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45411.86328125MB; mem (CPU total)=97957.0390625MB
INFO:root:[   35] Training loss: 0.65116989, Validation loss: 0.65379048, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45449.95703125MB; mem (CPU total)=98026.09765625MB
INFO:root:[   36] Training loss: 0.65099556, Validation loss: 0.65197853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45488.05078125MB; mem (CPU total)=98098.171875MB
INFO:root:[   37] Training loss: 0.64994428, Validation loss: 0.65070360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45526.14453125MB; mem (CPU total)=98168.27734375MB
INFO:root:[   38] Training loss: 0.64924327, Validation loss: 0.65176436, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45564.2421875MB; mem (CPU total)=98241.14453125MB
INFO:root:[   39] Training loss: 0.64747879, Validation loss: 0.65094472, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45602.33984375MB; mem (CPU total)=98317.5703125MB
INFO:root:[   40] Training loss: 0.64731793, Validation loss: 0.64905439, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45640.43359375MB; mem (CPU total)=98394.1171875MB
INFO:root:[   41] Training loss: 0.64574710, Validation loss: 0.64936400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45678.53125MB; mem (CPU total)=98470.6015625MB
INFO:root:[   42] Training loss: 0.64605947, Validation loss: 0.64823451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45716.625MB; mem (CPU total)=98547.11328125MB
INFO:root:[   43] Training loss: 0.64476706, Validation loss: 0.64740547, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45754.71875MB; mem (CPU total)=98623.078125MB
INFO:root:[   44] Training loss: 0.64381681, Validation loss: 0.64622560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45792.8125MB; mem (CPU total)=98699.61328125MB
INFO:root:[   45] Training loss: 0.64376486, Validation loss: 0.64640731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45830.91015625MB; mem (CPU total)=98792.1328125MB
INFO:root:[   46] Training loss: 0.64269194, Validation loss: 0.64526385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45869.00390625MB; mem (CPU total)=98859.84375MB
INFO:root:[   47] Training loss: 0.64203167, Validation loss: 0.64460148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45907.1015625MB; mem (CPU total)=98903.84765625MB
INFO:root:[   48] Training loss: 0.64086679, Validation loss: 0.64277881, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45945.19921875MB; mem (CPU total)=98976.0546875MB
INFO:root:[   49] Training loss: 0.64073091, Validation loss: 0.64276545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45983.29296875MB; mem (CPU total)=99051.63671875MB
INFO:root:[   50] Training loss: 0.63975023, Validation loss: 0.64177669, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46021.38671875MB; mem (CPU total)=99127.91796875MB
INFO:root:[   51] Training loss: 0.63899054, Validation loss: 0.63962237, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46059.484375MB; mem (CPU total)=99205.62890625MB
INFO:root:[   52] Training loss: 0.63859019, Validation loss: 0.64027483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46097.578125MB; mem (CPU total)=99282.1640625MB
INFO:root:[   53] Training loss: 0.63777473, Validation loss: 0.64072328, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46135.671875MB; mem (CPU total)=99358.3046875MB
INFO:root:[   54] Training loss: 0.63763355, Validation loss: 0.63972098, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46173.765625MB; mem (CPU total)=99434.296875MB
INFO:root:[   55] Training loss: 0.63659547, Validation loss: 0.64071396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46211.8671875MB; mem (CPU total)=99511.22265625MB
INFO:root:[   56] Training loss: 0.63628321, Validation loss: 0.63928632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46249.9609375MB; mem (CPU total)=99587.48828125MB
INFO:root:[   57] Training loss: 0.63559106, Validation loss: 0.63865622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46288.0546875MB; mem (CPU total)=99663.53125MB
INFO:root:[   58] Training loss: 0.63510423, Validation loss: 0.63677069, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46326.15234375MB; mem (CPU total)=99740.04296875MB
INFO:root:[   59] Training loss: 0.63430005, Validation loss: 0.63694570, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46364.24609375MB; mem (CPU total)=99816.140625MB
INFO:root:[   60] Training loss: 0.63357881, Validation loss: 0.63763555, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46402.33984375MB; mem (CPU total)=99892.93359375MB
INFO:root:[   61] Training loss: 0.63347149, Validation loss: 0.63674433, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46440.43359375MB; mem (CPU total)=99969.23046875MB
INFO:root:[   62] Training loss: 0.63273348, Validation loss: 0.63542258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46478.53125MB; mem (CPU total)=100044.98828125MB
INFO:root:[   63] Training loss: 0.63249818, Validation loss: 0.63649540, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46516.625MB; mem (CPU total)=100116.94140625MB
INFO:root:[   64] Training loss: 0.63172088, Validation loss: 0.63505370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46554.72265625MB; mem (CPU total)=100187.3125MB
INFO:root:[   65] Training loss: 0.63198556, Validation loss: 0.63472911, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46592.8203125MB; mem (CPU total)=100259.89453125MB
INFO:root:[   66] Training loss: 0.63113743, Validation loss: 0.63447665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46630.9140625MB; mem (CPU total)=100330.9296875MB
INFO:root:[   67] Training loss: 0.63097765, Validation loss: 0.63534788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46669.0078125MB; mem (CPU total)=100403.01953125MB
INFO:root:[   68] Training loss: 0.63004475, Validation loss: 0.63459202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46707.10546875MB; mem (CPU total)=100473.078125MB
INFO:root:[   69] Training loss: 0.62924724, Validation loss: 0.63377187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46745.19921875MB; mem (CPU total)=100544.1640625MB
INFO:root:[   70] Training loss: 0.62896940, Validation loss: 0.63262173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46783.296875MB; mem (CPU total)=100617.8203125MB
INFO:root:[   71] Training loss: 0.62852465, Validation loss: 0.63129213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46821.390625MB; mem (CPU total)=100694.140625MB
INFO:root:[   72] Training loss: 0.62843482, Validation loss: 0.63287531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46859.48828125MB; mem (CPU total)=100770.078125MB
INFO:root:[   73] Training loss: 0.62750069, Validation loss: 0.63162582, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46897.58203125MB; mem (CPU total)=100846.3984375MB
INFO:root:[   74] Training loss: 0.62699562, Validation loss: 0.63142559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46935.67578125MB; mem (CPU total)=100922.78515625MB
INFO:root:[   75] Training loss: 0.62717788, Validation loss: 0.63196614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46973.7734375MB; mem (CPU total)=100999.3125MB
INFO:root:[   76] Training loss: 0.62603036, Validation loss: 0.63058261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47011.8671875MB; mem (CPU total)=101076.35546875MB
INFO:root:[   77] Training loss: 0.62664205, Validation loss: 0.63150210, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47049.9609375MB; mem (CPU total)=101152.3984375MB
INFO:root:[   78] Training loss: 0.62583688, Validation loss: 0.62967806, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47088.05859375MB; mem (CPU total)=101228.1875MB
INFO:root:[   79] Training loss: 0.62538214, Validation loss: 0.63001762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47126.15625MB; mem (CPU total)=101304.9609375MB
INFO:root:[   80] Training loss: 0.62472519, Validation loss: 0.62969038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47164.25MB; mem (CPU total)=101381.07421875MB
INFO:root:[   81] Training loss: 0.62481896, Validation loss: 0.62947053, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47202.34375MB; mem (CPU total)=101457.296875MB
INFO:root:[   82] Training loss: 0.62402444, Validation loss: 0.62826111, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47240.44140625MB; mem (CPU total)=101533.83203125MB
INFO:root:[   83] Training loss: 0.62386779, Validation loss: 0.62832443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47278.53515625MB; mem (CPU total)=101609.875MB
INFO:root:[   84] Training loss: 0.62441648, Validation loss: 0.62836162, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47316.62890625MB; mem (CPU total)=101685.39453125MB
INFO:root:[   85] Training loss: 0.62314937, Validation loss: 0.62664149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47354.7265625MB; mem (CPU total)=101757.2421875MB
INFO:root:[   86] Training loss: 0.62271492, Validation loss: 0.62705789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47392.8203125MB; mem (CPU total)=101826.88671875MB
INFO:root:[   87] Training loss: 0.62218011, Validation loss: 0.62696354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47430.91796875MB; mem (CPU total)=101900.19921875MB
INFO:root:[   88] Training loss: 0.62244460, Validation loss: 0.62596233, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47469.01171875MB; mem (CPU total)=101970.83203125MB
INFO:root:[   89] Training loss: 0.62167647, Validation loss: 0.62737284, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47507.109375MB; mem (CPU total)=102042.40625MB
INFO:root:[   90] Training loss: 0.62105523, Validation loss: 0.62579285, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47545.203125MB; mem (CPU total)=102113.55859375MB
INFO:root:[   91] Training loss: 0.62152697, Validation loss: 0.62693346, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47583.296875MB; mem (CPU total)=102183.1875MB
INFO:root:[   92] Training loss: 0.61975618, Validation loss: 0.62587928, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47621.3984375MB; mem (CPU total)=102258.23046875MB
INFO:root:[   93] Training loss: 0.62069505, Validation loss: 0.62441073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47659.48828125MB; mem (CPU total)=102334.75MB
INFO:root:[   94] Training loss: 0.62009442, Validation loss: 0.62350137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47697.5859375MB; mem (CPU total)=102411.51171875MB
INFO:root:[   95] Training loss: 0.61978834, Validation loss: 0.62420046, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47735.6796875MB; mem (CPU total)=102487.83203125MB
INFO:root:[   96] Training loss: 0.61977820, Validation loss: 0.62469280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47773.77734375MB; mem (CPU total)=102564.39453125MB
INFO:root:[   97] Training loss: 0.61884026, Validation loss: 0.62422734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47811.87109375MB; mem (CPU total)=102640.5625MB
INFO:root:[   98] Training loss: 0.61867976, Validation loss: 0.62460809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47849.96875MB; mem (CPU total)=102716.6171875MB
INFO:root:[   99] Training loss: 0.61874166, Validation loss: 0.62445584, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47888.06640625MB; mem (CPU total)=102792.65234375MB
INFO:root:[  100] Training loss: 0.61839286, Validation loss: 0.62332569, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47926.16015625MB; mem (CPU total)=102868.94140625MB
INFO:root:[  101] Training loss: 0.61842295, Validation loss: 0.62299865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47964.25390625MB; mem (CPU total)=102945.41796875MB
INFO:root:[  102] Training loss: 0.61783741, Validation loss: 0.62247145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48002.3515625MB; mem (CPU total)=103021.4609375MB
INFO:root:[  103] Training loss: 0.61781099, Validation loss: 0.62332408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48040.4453125MB; mem (CPU total)=103097.60546875MB
INFO:root:[  104] Training loss: 0.61654620, Validation loss: 0.62330971, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48078.54296875MB; mem (CPU total)=103173.875MB
INFO:root:[  105] Training loss: 0.61714874, Validation loss: 0.62255428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48116.63671875MB; mem (CPU total)=103250.08984375MB
INFO:root:[  106] Training loss: 0.61652184, Validation loss: 0.62166757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48154.734375MB; mem (CPU total)=103327.0625MB
INFO:root:[  107] Training loss: 0.61632071, Validation loss: 0.62129649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48192.828125MB; mem (CPU total)=103397.03515625MB
INFO:root:[  108] Training loss: 0.61601090, Validation loss: 0.61962938, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48230.921875MB; mem (CPU total)=103470.37109375MB
INFO:root:[  109] Training loss: 0.61623755, Validation loss: 0.62222903, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48269.01953125MB; mem (CPU total)=103540.375MB
INFO:root:[  110] Training loss: 0.61521679, Validation loss: 0.62192407, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48307.12109375MB; mem (CPU total)=103612.70703125MB
INFO:root:[  111] Training loss: 0.61606135, Validation loss: 0.62077142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48345.21484375MB; mem (CPU total)=103683.78125MB
INFO:root:[  112] Training loss: 0.61511833, Validation loss: 0.61962080, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48383.3125MB; mem (CPU total)=103754.3828125MB
INFO:root:[  113] Training loss: 0.61487223, Validation loss: 0.62157613, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48421.41015625MB; mem (CPU total)=103826.4140625MB
INFO:root:[  114] Training loss: 0.61451173, Validation loss: 0.61985050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48459.50390625MB; mem (CPU total)=103899.25390625MB
INFO:root:[  115] Training loss: 0.61423338, Validation loss: 0.61969879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48497.59765625MB; mem (CPU total)=103975.54296875MB
INFO:root:[  116] Training loss: 0.61361933, Validation loss: 0.62014358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48535.6953125MB; mem (CPU total)=104051.8671875MB
INFO:root:[  117] Training loss: 0.61366656, Validation loss: 0.62028396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48573.7890625MB; mem (CPU total)=104128.1640625MB
INFO:root:[  118] Training loss: 0.61307422, Validation loss: 0.61995128, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48611.88671875MB; mem (CPU total)=104204.66015625MB
INFO:root:[  119] Training loss: 0.61304918, Validation loss: 0.61917722, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48649.984375MB; mem (CPU total)=104280.703125MB
INFO:root:[  120] Training loss: 0.61280063, Validation loss: 0.62022644, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48688.07421875MB; mem (CPU total)=104356.79296875MB
INFO:root:[  121] Training loss: 0.61301789, Validation loss: 0.61933643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48726.171875MB; mem (CPU total)=104433.484375MB
INFO:root:[  122] Training loss: 0.61280950, Validation loss: 0.61786176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48764.265625MB; mem (CPU total)=104509.453125MB
INFO:root:[  123] Training loss: 0.61243702, Validation loss: 0.61881349, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48802.36328125MB; mem (CPU total)=104585.98046875MB
INFO:root:[  124] Training loss: 0.61165239, Validation loss: 0.61901125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48840.45703125MB; mem (CPU total)=104662.51171875MB
INFO:root:[  125] Training loss: 0.61191312, Validation loss: 0.61791440, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48878.55078125MB; mem (CPU total)=104738.7265625MB
INFO:root:[  126] Training loss: 0.61138135, Validation loss: 0.61852107, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48916.6484375MB; mem (CPU total)=104815.1640625MB
INFO:root:[  127] Training loss: 0.61139640, Validation loss: 0.61959694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48954.74609375MB; mem (CPU total)=104891.1796875MB
INFO:root:[  128] Training loss: 0.61059440, Validation loss: 0.61826674, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48992.83984375MB; mem (CPU total)=104967.4296875MB
INFO:root:[  129] Training loss: 0.61110244, Validation loss: 0.61521357, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49030.93359375MB; mem (CPU total)=105040.7421875MB
INFO:root:[  130] Training loss: 0.61076209, Validation loss: 0.61758688, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49069.03125MB; mem (CPU total)=105112.01953125MB
INFO:root:[  131] Training loss: 0.61032615, Validation loss: 0.61830557, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49107.125MB; mem (CPU total)=105181.93359375MB
INFO:root:[  132] Training loss: 0.61017002, Validation loss: 0.61603793, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49145.21875MB; mem (CPU total)=105254.4140625MB
INFO:root:[  133] Training loss: 0.61007700, Validation loss: 0.61669374, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49183.31640625MB; mem (CPU total)=105326.3984375MB
INFO:root:[  134] Training loss: 0.61007638, Validation loss: 0.61798556, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49221.4140625MB; mem (CPU total)=105398.05078125MB
INFO:root:[  135] Training loss: 0.61063737, Validation loss: 0.61729591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49259.5078125MB; mem (CPU total)=105470.06640625MB
INFO:root:[  136] Training loss: 0.60943467, Validation loss: 0.61696539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49297.60546875MB; mem (CPU total)=105541.4765625MB
INFO:root:[  137] Training loss: 0.60900768, Validation loss: 0.61684131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49335.69921875MB; mem (CPU total)=105617.5MB
INFO:root:[  138] Training loss: 0.60841839, Validation loss: 0.61497522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49373.79296875MB; mem (CPU total)=105693.99609375MB
INFO:root:[  139] Training loss: 0.60814146, Validation loss: 0.61532534, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49411.88671875MB; mem (CPU total)=105769.43359375MB
INFO:root:[  140] Training loss: 0.60772414, Validation loss: 0.61504829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49449.98828125MB; mem (CPU total)=105846.25MB
INFO:root:[  141] Training loss: 0.60830463, Validation loss: 0.61600670, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49488.078125MB; mem (CPU total)=105922.484375MB
INFO:root:[  142] Training loss: 0.60821788, Validation loss: 0.61446804, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49526.17578125MB; mem (CPU total)=105998.7890625MB
INFO:root:[  143] Training loss: 0.60802729, Validation loss: 0.61555497, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49564.26953125MB; mem (CPU total)=106075.7578125MB
INFO:root:[  144] Training loss: 0.60773727, Validation loss: 0.61369643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49602.3671875MB; mem (CPU total)=106151.3984375MB
INFO:root:[  145] Training loss: 0.60731057, Validation loss: 0.61376730, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49640.4609375MB; mem (CPU total)=106227.93359375MB
INFO:root:[  146] Training loss: 0.60737093, Validation loss: 0.61515386, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49678.5546875MB; mem (CPU total)=106304.25390625MB
INFO:root:[  147] Training loss: 0.60680736, Validation loss: 0.61360127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49716.65234375MB; mem (CPU total)=106380.53125MB
INFO:root:[  148] Training loss: 0.60696079, Validation loss: 0.61471422, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49754.74609375MB; mem (CPU total)=106457.25MB
INFO:root:[  149] Training loss: 0.60666128, Validation loss: 0.61530861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49792.83984375MB; mem (CPU total)=106533.3671875MB
INFO:root:[  150] Training loss: 0.60625082, Validation loss: 0.61351513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49830.9375MB; mem (CPU total)=106606.49609375MB
INFO:root:[  151] Training loss: 0.60621253, Validation loss: 0.61362845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49869.03125MB; mem (CPU total)=106674.9453125MB
INFO:root:[  152] Training loss: 0.60623118, Validation loss: 0.61252272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49907.1328125MB; mem (CPU total)=106746.4296875MB
INFO:root:[  153] Training loss: 0.60597181, Validation loss: 0.61378003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49945.23046875MB; mem (CPU total)=106817.54296875MB
INFO:root:[  154] Training loss: 0.60473092, Validation loss: 0.61413591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49983.32421875MB; mem (CPU total)=106888.44921875MB
INFO:root:[  155] Training loss: 0.60536165, Validation loss: 0.61222372, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50021.41796875MB; mem (CPU total)=106961.04296875MB
INFO:root:[  156] Training loss: 0.60499856, Validation loss: 0.61312104, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50059.51171875MB; mem (CPU total)=107032.10546875MB
INFO:root:[  157] Training loss: 0.60538246, Validation loss: 0.61292120, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50097.609375MB; mem (CPU total)=107106.73046875MB
INFO:root:[  158] Training loss: 0.60482690, Validation loss: 0.61439501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50135.70703125MB; mem (CPU total)=107183.2421875MB
INFO:root:[  159] Training loss: 0.60521823, Validation loss: 0.61134457, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50173.80078125MB; mem (CPU total)=107259.30859375MB
INFO:root:[  160] Training loss: 0.60419622, Validation loss: 0.61230322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50211.8984375MB; mem (CPU total)=107335.38671875MB
INFO:root:[  161] Training loss: 0.60449400, Validation loss: 0.61342297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50249.9921875MB; mem (CPU total)=107412.40234375MB
INFO:root:[  162] Training loss: 0.60443983, Validation loss: 0.61214474, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50288.0859375MB; mem (CPU total)=107488.69140625MB
INFO:root:[  163] Training loss: 0.60373861, Validation loss: 0.61218363, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50326.1796875MB; mem (CPU total)=107564.7109375MB
INFO:root:[  164] Training loss: 0.60320513, Validation loss: 0.61300423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50364.27734375MB; mem (CPU total)=107640.51953125MB
INFO:root:[  165] Training loss: 0.60399341, Validation loss: 0.61184440, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50402.37109375MB; mem (CPU total)=107716.59765625MB
INFO:root:[  166] Training loss: 0.60332112, Validation loss: 0.61305254, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50440.46875MB; mem (CPU total)=107793.04296875MB
INFO:root:[  167] Training loss: 0.60356201, Validation loss: 0.61505615, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50478.5625MB; mem (CPU total)=107868.859375MB
INFO:root:[  168] Training loss: 0.60305316, Validation loss: 0.61239197, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50516.66015625MB; mem (CPU total)=107945.6796875MB
INFO:root:EP 168: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=50554.75390625MB; mem (CPU total)=107984.29296875MB
INFO:root:Training the model took 15715.288s.
INFO:root:Emptying the cuda cache took 0.054s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85661
INFO:root:EnergyScoreTrain: 0.60418
INFO:root:CRPSTrain: 0.54462
INFO:root:Gaussian NLLTrain: 3.43
INFO:root:CoverageTrain: 0.75759
INFO:root:IntervalWidthTrain: 3.10709
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8694
INFO:root:EnergyScoreValidation: 0.61301
INFO:root:CRPSValidation: 0.55161
INFO:root:Gaussian NLLValidation: 3.45554
INFO:root:CoverageValidation: 0.75401
INFO:root:IntervalWidthValidation: 3.10618
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87119
INFO:root:EnergyScoreTest: 0.61426
INFO:root:CRPSTest: 0.55283
INFO:root:Gaussian NLLTest: 3.47311
INFO:root:CoverageTest: 0.75208
INFO:root:IntervalWidthTest: 3.09883
INFO:root:After validation: mem (CPU python)=50597.66015625MB; mem (CPU total)=108126.78125MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=50597.66015625MB; mem (CPU total)=108141.96875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=50598.12109375MB; mem (CPU total)=108142.21484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=50598.12109375MB; mem (CPU total)=108179.8203125MB
INFO:root:[    1] Training loss: 0.76578499, Validation loss: 0.72359246, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50636.21875MB; mem (CPU total)=108251.09765625MB
INFO:root:[    2] Training loss: 0.72235120, Validation loss: 0.72222723, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50674.31640625MB; mem (CPU total)=108323.51171875MB
INFO:root:[    3] Training loss: 0.72108348, Validation loss: 0.71998816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50712.41015625MB; mem (CPU total)=108394.3125MB
INFO:root:[    4] Training loss: 0.71996498, Validation loss: 0.71977732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50750.50390625MB; mem (CPU total)=108465.25390625MB
INFO:root:[    5] Training loss: 0.71924562, Validation loss: 0.71883966, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50788.6015625MB; mem (CPU total)=108537.63671875MB
INFO:root:[    6] Training loss: 0.71906131, Validation loss: 0.71806365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50826.6953125MB; mem (CPU total)=108607.3203125MB
INFO:root:[    7] Training loss: 0.71722438, Validation loss: 0.71612863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50864.7890625MB; mem (CPU total)=108677.98046875MB
INFO:root:[    8] Training loss: 0.71336732, Validation loss: 0.71100553, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50902.8828125MB; mem (CPU total)=108751.48828125MB
INFO:root:[    9] Training loss: 0.70742231, Validation loss: 0.70450070, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50940.984375MB; mem (CPU total)=108827.34765625MB
INFO:root:[   10] Training loss: 0.70127197, Validation loss: 0.69893218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50979.078125MB; mem (CPU total)=108903.36328125MB
INFO:root:[   11] Training loss: 0.69563903, Validation loss: 0.69427735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51017.171875MB; mem (CPU total)=108980.6640625MB
INFO:root:[   12] Training loss: 0.69039511, Validation loss: 0.68926158, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51055.26953125MB; mem (CPU total)=109056.23046875MB
INFO:root:[   13] Training loss: 0.68610042, Validation loss: 0.68440551, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51093.3671875MB; mem (CPU total)=109132.54296875MB
INFO:root:[   14] Training loss: 0.68188709, Validation loss: 0.68104426, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51131.4609375MB; mem (CPU total)=109208.84765625MB
INFO:root:[   15] Training loss: 0.67771397, Validation loss: 0.67849650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51169.5546875MB; mem (CPU total)=109285.703125MB
INFO:root:[   16] Training loss: 0.67504888, Validation loss: 0.67492143, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51207.65625MB; mem (CPU total)=109361.77734375MB
INFO:root:[   17] Training loss: 0.67228434, Validation loss: 0.67194721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51245.75MB; mem (CPU total)=109438.01953125MB
INFO:root:[   18] Training loss: 0.66971471, Validation loss: 0.66981520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51283.84375MB; mem (CPU total)=109515.6015625MB
INFO:root:[   19] Training loss: 0.66777518, Validation loss: 0.66770508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51321.94140625MB; mem (CPU total)=109591.19140625MB
INFO:root:[   20] Training loss: 0.66516581, Validation loss: 0.66554761, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51360.03515625MB; mem (CPU total)=109667.2578125MB
INFO:root:[   21] Training loss: 0.66329113, Validation loss: 0.66423808, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51398.1328125MB; mem (CPU total)=109744.03515625MB
INFO:root:[   22] Training loss: 0.66162065, Validation loss: 0.66312052, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51436.23046875MB; mem (CPU total)=109820.32421875MB
INFO:root:[   23] Training loss: 0.65983425, Validation loss: 0.66042186, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51474.32421875MB; mem (CPU total)=109896.734375MB
INFO:root:[   24] Training loss: 0.65838997, Validation loss: 0.65797224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51512.41796875MB; mem (CPU total)=109972.56640625MB
INFO:root:[   25] Training loss: 0.65694235, Validation loss: 0.65794050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51550.51171875MB; mem (CPU total)=110050.3203125MB
INFO:root:[   26] Training loss: 0.65538854, Validation loss: 0.65692656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51588.61328125MB; mem (CPU total)=110125.64453125MB
INFO:root:[   27] Training loss: 0.65448652, Validation loss: 0.65704816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51626.70703125MB; mem (CPU total)=110201.703125MB
INFO:root:[   28] Training loss: 0.65347650, Validation loss: 0.65411206, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51664.80078125MB; mem (CPU total)=110277.95703125MB
INFO:root:[   29] Training loss: 0.65218677, Validation loss: 0.65380100, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51702.8984375MB; mem (CPU total)=110354.39453125MB
INFO:root:[   30] Training loss: 0.65086008, Validation loss: 0.65292175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51740.9921875MB; mem (CPU total)=110430.65625MB
INFO:root:[   31] Training loss: 0.64971077, Validation loss: 0.65227105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51779.0859375MB; mem (CPU total)=110506.98046875MB
INFO:root:[   32] Training loss: 0.64849773, Validation loss: 0.65127210, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51817.18359375MB; mem (CPU total)=110560.11328125MB
INFO:root:[   33] Training loss: 0.64794912, Validation loss: 0.64929642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51855.2578125MB; mem (CPU total)=110639.98828125MB
INFO:root:[   34] Training loss: 0.64691660, Validation loss: 0.64841095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51893.3515625MB; mem (CPU total)=110713.0625MB
INFO:root:[   35] Training loss: 0.64614093, Validation loss: 0.64836175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51931.4453125MB; mem (CPU total)=110788.85546875MB
INFO:root:[   36] Training loss: 0.64497680, Validation loss: 0.64708592, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51969.5390625MB; mem (CPU total)=110855.25MB
INFO:root:[   37] Training loss: 0.64431585, Validation loss: 0.64576265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52007.6328125MB; mem (CPU total)=110930.31640625MB
INFO:root:[   38] Training loss: 0.64336940, Validation loss: 0.64587501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52045.7265625MB; mem (CPU total)=111006.93359375MB
INFO:root:[   39] Training loss: 0.64279111, Validation loss: 0.64572516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52083.82421875MB; mem (CPU total)=111077.09765625MB
INFO:root:[   40] Training loss: 0.64181746, Validation loss: 0.64400166, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52121.921875MB; mem (CPU total)=111152.72265625MB
INFO:root:[   41] Training loss: 0.64135858, Validation loss: 0.64377330, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52160.015625MB; mem (CPU total)=111226.890625MB
INFO:root:[   42] Training loss: 0.64044265, Validation loss: 0.64336103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52198.109375MB; mem (CPU total)=111299.61328125MB
INFO:root:[   43] Training loss: 0.63960755, Validation loss: 0.64270667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52236.20703125MB; mem (CPU total)=111375.359375MB
INFO:root:[   44] Training loss: 0.63909200, Validation loss: 0.64248165, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52274.30078125MB; mem (CPU total)=111448.68359375MB
INFO:root:[   45] Training loss: 0.63864963, Validation loss: 0.64102825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52312.39453125MB; mem (CPU total)=111552.73046875MB
INFO:root:[   46] Training loss: 0.63782676, Validation loss: 0.64111029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52350.49609375MB; mem (CPU total)=111594.05859375MB
INFO:root:[   47] Training loss: 0.63702425, Validation loss: 0.64046409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52388.5859375MB; mem (CPU total)=111630.359375MB
INFO:root:[   48] Training loss: 0.63672918, Validation loss: 0.64004833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52426.6796875MB; mem (CPU total)=111670.4296875MB
INFO:root:[   49] Training loss: 0.63646006, Validation loss: 0.63923796, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52464.77734375MB; mem (CPU total)=52288.14453125MB
INFO:root:[   50] Training loss: 0.63574635, Validation loss: 0.63811023, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52502.875MB; mem (CPU total)=52325.49609375MB
INFO:root:[   51] Training loss: 0.63487833, Validation loss: 0.63884482, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52540.96875MB; mem (CPU total)=52364.5625MB
INFO:root:[   52] Training loss: 0.63440638, Validation loss: 0.63798507, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52579.0625MB; mem (CPU total)=52401.8515625MB
INFO:root:[   53] Training loss: 0.63396458, Validation loss: 0.63725545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52617.16015625MB; mem (CPU total)=52440.4765625MB
INFO:root:[   54] Training loss: 0.63300126, Validation loss: 0.63692374, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52655.25390625MB; mem (CPU total)=52478.8984375MB
INFO:root:[   55] Training loss: 0.63270372, Validation loss: 0.63730978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52693.3515625MB; mem (CPU total)=52517.03125MB
INFO:root:[   56] Training loss: 0.63232190, Validation loss: 0.63607329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52731.44921875MB; mem (CPU total)=52554.12109375MB
INFO:root:[   57] Training loss: 0.63188403, Validation loss: 0.63571846, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52769.54296875MB; mem (CPU total)=52591.921875MB
INFO:root:[   58] Training loss: 0.63128235, Validation loss: 0.63429532, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52807.63671875MB; mem (CPU total)=52630.078125MB
INFO:root:[   59] Training loss: 0.63082566, Validation loss: 0.63664511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52845.73046875MB; mem (CPU total)=52667.9296875MB
INFO:root:[   60] Training loss: 0.63070366, Validation loss: 0.63516447, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52883.828125MB; mem (CPU total)=52706.03125MB
INFO:root:[   61] Training loss: 0.62987607, Validation loss: 0.63381979, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52921.921875MB; mem (CPU total)=52744.40234375MB
INFO:root:[   62] Training loss: 0.62916485, Validation loss: 0.63399897, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52960.015625MB; mem (CPU total)=52782.52734375MB
INFO:root:[   63] Training loss: 0.62886512, Validation loss: 0.63510397, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52998.11328125MB; mem (CPU total)=52820.93359375MB
INFO:root:[   64] Training loss: 0.62860993, Validation loss: 0.63276160, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53036.20703125MB; mem (CPU total)=52859.15625MB
INFO:root:[   65] Training loss: 0.62824619, Validation loss: 0.63481098, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53074.3046875MB; mem (CPU total)=52897.08203125MB
INFO:root:[   66] Training loss: 0.62769541, Validation loss: 0.63293897, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53112.3984375MB; mem (CPU total)=52935.75MB
INFO:root:[   67] Training loss: 0.62731298, Validation loss: 0.63227898, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53150.49609375MB; mem (CPU total)=52974.1015625MB
INFO:root:[   68] Training loss: 0.62689945, Validation loss: 0.63226813, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53188.59375MB; mem (CPU total)=53011.81640625MB
INFO:root:[   69] Training loss: 0.62616478, Validation loss: 0.63264694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53226.6875MB; mem (CPU total)=53049.7734375MB
INFO:root:[   70] Training loss: 0.62613120, Validation loss: 0.63140748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53264.78515625MB; mem (CPU total)=53087.94140625MB
INFO:root:[   71] Training loss: 0.62592180, Validation loss: 0.63101368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53302.8828125MB; mem (CPU total)=53126.3671875MB
INFO:root:[   72] Training loss: 0.62515040, Validation loss: 0.63123299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53340.9765625MB; mem (CPU total)=53164.3984375MB
INFO:root:[   73] Training loss: 0.62474453, Validation loss: 0.63094530, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53379.07421875MB; mem (CPU total)=53202.5625MB
INFO:root:[   74] Training loss: 0.62478357, Validation loss: 0.63085160, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53417.16796875MB; mem (CPU total)=53240.3671875MB
INFO:root:[   75] Training loss: 0.62400362, Validation loss: 0.63015323, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53455.26171875MB; mem (CPU total)=53278.0234375MB
INFO:root:[   76] Training loss: 0.62360866, Validation loss: 0.63006186, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53493.359375MB; mem (CPU total)=53316.44140625MB
INFO:root:[   77] Training loss: 0.62348312, Validation loss: 0.63040332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53531.45703125MB; mem (CPU total)=53354.62109375MB
INFO:root:[   78] Training loss: 0.62299150, Validation loss: 0.62926369, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53569.55078125MB; mem (CPU total)=53392.8046875MB
INFO:root:[   79] Training loss: 0.62250407, Validation loss: 0.63057966, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53607.64453125MB; mem (CPU total)=53430.97265625MB
INFO:root:[   80] Training loss: 0.62229150, Validation loss: 0.62987526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53645.74609375MB; mem (CPU total)=53468.89453125MB
INFO:root:[   81] Training loss: 0.62187009, Validation loss: 0.62918927, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53683.83984375MB; mem (CPU total)=53507.56640625MB
INFO:root:[   82] Training loss: 0.62172350, Validation loss: 0.62990869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53721.93359375MB; mem (CPU total)=53546.37890625MB
INFO:root:[   83] Training loss: 0.62141507, Validation loss: 0.62896724, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53760.02734375MB; mem (CPU total)=53584.1640625MB
INFO:root:[   84] Training loss: 0.62113164, Validation loss: 0.62846711, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53798.125MB; mem (CPU total)=53622.2890625MB
INFO:root:[   85] Training loss: 0.62101289, Validation loss: 0.62767175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53836.21875MB; mem (CPU total)=53660.2109375MB
INFO:root:[   86] Training loss: 0.62029083, Validation loss: 0.62868707, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53874.31640625MB; mem (CPU total)=53698.390625MB
INFO:root:[   87] Training loss: 0.62008793, Validation loss: 0.62713021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53912.4140625MB; mem (CPU total)=53736.05859375MB
INFO:root:[   88] Training loss: 0.61975759, Validation loss: 0.62761841, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53950.5078125MB; mem (CPU total)=53774.7265625MB
INFO:root:[   89] Training loss: 0.61939468, Validation loss: 0.62727301, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53988.6015625MB; mem (CPU total)=53812.66015625MB
INFO:root:[   90] Training loss: 0.61883561, Validation loss: 0.62649194, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54026.69921875MB; mem (CPU total)=53850.59765625MB
INFO:root:[   91] Training loss: 0.61887418, Validation loss: 0.62667014, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54064.79296875MB; mem (CPU total)=53889.328125MB
INFO:root:[   92] Training loss: 0.61837631, Validation loss: 0.62633299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54102.88671875MB; mem (CPU total)=53927.1171875MB
INFO:root:[   93] Training loss: 0.61850073, Validation loss: 0.62783184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54140.98046875MB; mem (CPU total)=53964.92578125MB
INFO:root:[   94] Training loss: 0.61831224, Validation loss: 0.62596702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54179.078125MB; mem (CPU total)=54003.6015625MB
INFO:root:[   95] Training loss: 0.61737370, Validation loss: 0.62470539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54217.171875MB; mem (CPU total)=54041.52734375MB
INFO:root:[   96] Training loss: 0.61697400, Validation loss: 0.62675967, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54255.265625MB; mem (CPU total)=54079.70703125MB
INFO:root:[   97] Training loss: 0.61735536, Validation loss: 0.62569772, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54293.36328125MB; mem (CPU total)=54118.0234375MB
INFO:root:[   98] Training loss: 0.61710954, Validation loss: 0.62646184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54331.4609375MB; mem (CPU total)=54156.19921875MB
INFO:root:[   99] Training loss: 0.61646872, Validation loss: 0.62668048, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54369.5546875MB; mem (CPU total)=54193.76953125MB
INFO:root:[  100] Training loss: 0.61638256, Validation loss: 0.62548138, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54407.6484375MB; mem (CPU total)=54231.89453125MB
INFO:root:[  101] Training loss: 0.61592139, Validation loss: 0.62596314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54445.74609375MB; mem (CPU total)=54270.06640625MB
INFO:root:[  102] Training loss: 0.61558383, Validation loss: 0.62586538, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54483.83984375MB; mem (CPU total)=54308.24609375MB
INFO:root:[  103] Training loss: 0.61547845, Validation loss: 0.62547613, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54521.93359375MB; mem (CPU total)=54345.94140625MB
INFO:root:[  104] Training loss: 0.61520189, Validation loss: 0.62481416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54560.03515625MB; mem (CPU total)=54384.609375MB
INFO:root:[  105] Training loss: 0.61509157, Validation loss: 0.62375409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54598.12890625MB; mem (CPU total)=54422.8125MB
INFO:root:[  106] Training loss: 0.61460633, Validation loss: 0.62518945, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54636.22265625MB; mem (CPU total)=54460.75MB
INFO:root:[  107] Training loss: 0.61449021, Validation loss: 0.62474791, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54674.3203125MB; mem (CPU total)=54499.1875MB
INFO:root:[  108] Training loss: 0.61444222, Validation loss: 0.62459415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54712.4140625MB; mem (CPU total)=54536.48046875MB
INFO:root:[  109] Training loss: 0.61383475, Validation loss: 0.62459591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54750.5078125MB; mem (CPU total)=54574.62109375MB
INFO:root:[  110] Training loss: 0.61355217, Validation loss: 0.62507635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54788.6015625MB; mem (CPU total)=54612.82421875MB
INFO:root:[  111] Training loss: 0.61356501, Validation loss: 0.62480071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54826.69921875MB; mem (CPU total)=54651.23046875MB
INFO:root:[  112] Training loss: 0.61332973, Validation loss: 0.62477339, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54864.796875MB; mem (CPU total)=54689.16796875MB
INFO:root:[  113] Training loss: 0.61256086, Validation loss: 0.62466767, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54902.890625MB; mem (CPU total)=54727.59765625MB
INFO:root:[  114] Training loss: 0.61281936, Validation loss: 0.62363188, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54940.98828125MB; mem (CPU total)=54765.5625MB
INFO:root:[  115] Training loss: 0.61277962, Validation loss: 0.62430218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54979.078125MB; mem (CPU total)=54803.71484375MB
INFO:root:[  116] Training loss: 0.61203298, Validation loss: 0.62528957, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55017.17578125MB; mem (CPU total)=54842.31640625MB
INFO:root:[  117] Training loss: 0.61207666, Validation loss: 0.62359021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55055.26953125MB; mem (CPU total)=54880.48046875MB
INFO:root:[  118] Training loss: 0.61124957, Validation loss: 0.62316915, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55093.3671875MB; mem (CPU total)=54918.6953125MB
INFO:root:[  119] Training loss: 0.61150901, Validation loss: 0.62429382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55131.4609375MB; mem (CPU total)=54956.6328125MB
INFO:root:[  120] Training loss: 0.61088953, Validation loss: 0.62244624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55169.5546875MB; mem (CPU total)=54994.78515625MB
INFO:root:[  121] Training loss: 0.61072908, Validation loss: 0.62325139, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55207.65234375MB; mem (CPU total)=58585.17578125MB
INFO:root:[  122] Training loss: 0.61105690, Validation loss: 0.62177765, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55245.74609375MB; mem (CPU total)=57823.75MB
INFO:root:[  123] Training loss: 0.61028710, Validation loss: 0.62229058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55283.84375MB; mem (CPU total)=57916.5078125MB
INFO:root:[  124] Training loss: 0.61024626, Validation loss: 0.62167674, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55321.94140625MB; mem (CPU total)=58012.0078125MB
INFO:root:[  125] Training loss: 0.60996064, Validation loss: 0.62438747, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55360.03515625MB; mem (CPU total)=58104.85546875MB
INFO:root:[  126] Training loss: 0.61016618, Validation loss: 0.62167876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55398.12890625MB; mem (CPU total)=58200.7109375MB
INFO:root:[  127] Training loss: 0.60997638, Validation loss: 0.62184852, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55436.22265625MB; mem (CPU total)=58293.71484375MB
INFO:root:[  128] Training loss: 0.60960961, Validation loss: 0.62323275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55474.3203125MB; mem (CPU total)=58387.5078125MB
INFO:root:[  129] Training loss: 0.60880434, Validation loss: 0.62266219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55512.4140625MB; mem (CPU total)=58482.453125MB
INFO:root:[  130] Training loss: 0.60913916, Validation loss: 0.62262618, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55550.51171875MB; mem (CPU total)=58574.90234375MB
INFO:root:[  131] Training loss: 0.60856116, Validation loss: 0.62068291, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55588.609375MB; mem (CPU total)=58669.03515625MB
INFO:root:[  132] Training loss: 0.60863682, Validation loss: 0.62284465, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55626.703125MB; mem (CPU total)=58763.48828125MB
INFO:root:[  133] Training loss: 0.60791909, Validation loss: 0.62217559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55664.796875MB; mem (CPU total)=58858.30859375MB
INFO:root:[  134] Training loss: 0.60808730, Validation loss: 0.62199982, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55702.890625MB; mem (CPU total)=58950.65625MB
INFO:root:[  135] Training loss: 0.60777215, Validation loss: 0.62233696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55740.98828125MB; mem (CPU total)=59045.90234375MB
INFO:root:[  136] Training loss: 0.60759668, Validation loss: 0.62202667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55779.08203125MB; mem (CPU total)=59136.6796875MB
INFO:root:[  137] Training loss: 0.60730037, Validation loss: 0.62160762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55817.17578125MB; mem (CPU total)=59231.78515625MB
INFO:root:[  138] Training loss: 0.60743697, Validation loss: 0.62090116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55855.2734375MB; mem (CPU total)=59325.171875MB
INFO:root:[  139] Training loss: 0.60708374, Validation loss: 0.62248074, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55893.37109375MB; mem (CPU total)=59419.07421875MB
INFO:root:[  140] Training loss: 0.60673687, Validation loss: 0.62162327, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55931.4609375MB; mem (CPU total)=59514.9140625MB
INFO:root:EP 140: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=55969.5625MB; mem (CPU total)=59574.4765625MB
INFO:root:Training the model took 14190.076s.
INFO:root:Emptying the cuda cache took 0.059s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86296
INFO:root:EnergyScoreTrain: 0.60777
INFO:root:CRPSTrain: 0.5377
INFO:root:Gaussian NLLTrain: 2.90282
INFO:root:CoverageTrain: 0.7754
INFO:root:IntervalWidthTrain: 3.07982
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88333
INFO:root:EnergyScoreValidation: 0.62207
INFO:root:CRPSValidation: 0.54931
INFO:root:Gaussian NLLValidation: 2.93047
INFO:root:CoverageValidation: 0.76881
INFO:root:IntervalWidthValidation: 3.07911
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88546
INFO:root:EnergyScoreTest: 0.62362
INFO:root:CRPSTest: 0.55078
INFO:root:Gaussian NLLTest: 2.95241
INFO:root:CoverageTest: 0.76658
INFO:root:IntervalWidthTest: 3.0628
INFO:root:After validation: mem (CPU python)=56012.3359375MB; mem (CPU total)=59763.1640625MB
