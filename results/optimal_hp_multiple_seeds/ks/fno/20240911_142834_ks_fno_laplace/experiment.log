INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=578.51953125MB; mem (CPU total)=1436.703125MB
INFO:root:############### Starting experiment with config file ks/fno_laplace.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12457.29296875MB; mem (CPU total)=6759.35546875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12457.29296875MB; mem (CPU total)=6758.9609375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12457.29296875MB; mem (CPU total)=3845.13671875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=3862.0MB
INFO:root:[    1] Training loss: 1.02174537, Validation loss: 1.01769428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6220.265625MB
INFO:root:[    2] Training loss: 1.01656846, Validation loss: 1.01466936, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6296.05078125MB
INFO:root:[    3] Training loss: 1.00991755, Validation loss: 1.00214856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6371.41015625MB
INFO:root:[    4] Training loss: 0.99389541, Validation loss: 0.98602438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6447.0234375MB
INFO:root:[    5] Training loss: 0.98098703, Validation loss: 0.97291617, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6523.2109375MB
INFO:root:[    6] Training loss: 0.96862475, Validation loss: 0.96007075, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6599.37109375MB
INFO:root:[    7] Training loss: 0.95679472, Validation loss: 0.94896643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6675.12890625MB
INFO:root:[    8] Training loss: 0.94701198, Validation loss: 0.94073400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6751.3984375MB
INFO:root:[    9] Training loss: 0.94000556, Validation loss: 0.93454825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6825.87109375MB
INFO:root:[   10] Training loss: 0.93456992, Validation loss: 0.92892329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6899.40625MB
INFO:root:[   11] Training loss: 0.93009034, Validation loss: 0.92568430, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=6975.3046875MB
INFO:root:[   12] Training loss: 0.92616516, Validation loss: 0.92165834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7050.8828125MB
INFO:root:[   13] Training loss: 0.92269965, Validation loss: 0.91907721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7126.03515625MB
INFO:root:[   14] Training loss: 0.91963912, Validation loss: 0.91630651, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7201.90234375MB
INFO:root:[   15] Training loss: 0.91659315, Validation loss: 0.91299283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7277.953125MB
INFO:root:[   16] Training loss: 0.91419960, Validation loss: 0.91138373, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7353.7265625MB
INFO:root:[   17] Training loss: 0.91176534, Validation loss: 0.90847062, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7430.0546875MB
INFO:root:[   18] Training loss: 0.90945544, Validation loss: 0.90665851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7506.0859375MB
INFO:root:[   19] Training loss: 0.90748339, Validation loss: 0.90529659, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7580.96484375MB
INFO:root:[   20] Training loss: 0.90504966, Validation loss: 0.90380387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7656.4296875MB
INFO:root:[   21] Training loss: 0.90321044, Validation loss: 0.90087380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7732.4921875MB
INFO:root:[   22] Training loss: 0.90125019, Validation loss: 0.90098915, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7809.3125MB
INFO:root:[   23] Training loss: 0.89942886, Validation loss: 0.89781724, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7884.65234375MB
INFO:root:[   24] Training loss: 0.89793803, Validation loss: 0.89712980, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=7960.890625MB
INFO:root:[   25] Training loss: 0.89629210, Validation loss: 0.89506566, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8036.48046875MB
INFO:root:[   26] Training loss: 0.89496890, Validation loss: 0.89517208, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8112.23046875MB
INFO:root:[   27] Training loss: 0.89339148, Validation loss: 0.89343343, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8186.81640625MB
INFO:root:[   28] Training loss: 0.89168751, Validation loss: 0.89158889, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8262.50390625MB
INFO:root:[   29] Training loss: 0.89031354, Validation loss: 0.89092622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8338.47265625MB
INFO:root:[   30] Training loss: 0.88926060, Validation loss: 0.88984071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8414.7890625MB
INFO:root:[   31] Training loss: 0.88788997, Validation loss: 0.88928483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8490.6015625MB
INFO:root:[   32] Training loss: 0.88681244, Validation loss: 0.88841116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8566.8359375MB
INFO:root:[   33] Training loss: 0.88559750, Validation loss: 0.88811626, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8643.20703125MB
INFO:root:[   34] Training loss: 0.88417557, Validation loss: 0.88620720, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8718.76171875MB
INFO:root:[   35] Training loss: 0.88309381, Validation loss: 0.88568911, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8794.96484375MB
INFO:root:[   36] Training loss: 0.88208758, Validation loss: 0.88613233, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8870.4375MB
INFO:root:[   37] Training loss: 0.88118081, Validation loss: 0.88504381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=8945.28125MB
INFO:root:[   38] Training loss: 0.88001994, Validation loss: 0.88347788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9021.5546875MB
INFO:root:[   39] Training loss: 0.87880491, Validation loss: 0.88323627, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9097.875MB
INFO:root:[   40] Training loss: 0.87802397, Validation loss: 0.88258176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9173.35546875MB
INFO:root:[   41] Training loss: 0.87706915, Validation loss: 0.88259633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9249.7109375MB
INFO:root:[   42] Training loss: 0.87584471, Validation loss: 0.88210964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9325.01953125MB
INFO:root:[   43] Training loss: 0.87487766, Validation loss: 0.88090701, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9401.04296875MB
INFO:root:[   44] Training loss: 0.87403524, Validation loss: 0.88077970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9477.0546875MB
INFO:root:[   45] Training loss: 0.87322439, Validation loss: 0.87920953, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9552.359375MB
INFO:root:[   46] Training loss: 0.87257016, Validation loss: 0.87907833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9628.66015625MB
INFO:root:[   47] Training loss: 0.87146256, Validation loss: 0.87898715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9704.71875MB
INFO:root:[   48] Training loss: 0.87080029, Validation loss: 0.87877259, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9780.46875MB
INFO:root:[   49] Training loss: 0.87005570, Validation loss: 0.87882263, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9857.1796875MB
INFO:root:[   50] Training loss: 0.86924420, Validation loss: 0.87781546, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=9934.21875MB
INFO:root:[   51] Training loss: 0.86810800, Validation loss: 0.87755070, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10011.26171875MB
INFO:root:[   52] Training loss: 0.86746369, Validation loss: 0.87761602, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10088.546875MB
INFO:root:[   53] Training loss: 0.86670971, Validation loss: 0.87822814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10165.5859375MB
INFO:root:[   54] Training loss: 0.86571193, Validation loss: 0.87668986, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10242.375MB
INFO:root:[   55] Training loss: 0.86489514, Validation loss: 0.87654581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10319.875MB
INFO:root:[   56] Training loss: 0.86422344, Validation loss: 0.87745817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10397.37890625MB
INFO:root:[   57] Training loss: 0.86346585, Validation loss: 0.87582240, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10474.171875MB
INFO:root:[   58] Training loss: 0.86280899, Validation loss: 0.87532319, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10551.984375MB
INFO:root:[   59] Training loss: 0.86219790, Validation loss: 0.87633741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10628.68359375MB
INFO:root:[   60] Training loss: 0.86123727, Validation loss: 0.87521531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10705.96875MB
INFO:root:[   61] Training loss: 0.86040735, Validation loss: 0.87522101, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10782.859375MB
INFO:root:[   62] Training loss: 0.85983496, Validation loss: 0.87514642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10859.1015625MB
INFO:root:[   63] Training loss: 0.85931923, Validation loss: 0.87625362, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=10936.3359375MB
INFO:root:[   64] Training loss: 0.85857609, Validation loss: 0.87412175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11013.1640625MB
INFO:root:[   65] Training loss: 0.85802325, Validation loss: 0.87540987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11089.70703125MB
INFO:root:[   66] Training loss: 0.85692905, Validation loss: 0.87495778, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11166.2265625MB
INFO:root:[   67] Training loss: 0.85656347, Validation loss: 0.87422050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11242.00390625MB
INFO:root:[   68] Training loss: 0.85587785, Validation loss: 0.87523290, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11318.33984375MB
INFO:root:[   69] Training loss: 0.85526475, Validation loss: 0.87331341, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11395.13671875MB
INFO:root:[   70] Training loss: 0.85464670, Validation loss: 0.87369729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11471.22265625MB
INFO:root:[   71] Training loss: 0.85383923, Validation loss: 0.87349258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11547.98046875MB
INFO:root:[   72] Training loss: 0.85320519, Validation loss: 0.87389532, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11625.14453125MB
INFO:root:[   73] Training loss: 0.85266098, Validation loss: 0.87346518, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11702.17578125MB
INFO:root:[   74] Training loss: 0.85203203, Validation loss: 0.87376534, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11778.64453125MB
INFO:root:[   75] Training loss: 0.85148306, Validation loss: 0.87396965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11856.72265625MB
INFO:root:[   76] Training loss: 0.85099052, Validation loss: 0.87382632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=11934.18359375MB
INFO:root:[   77] Training loss: 0.85002565, Validation loss: 0.87369898, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=12010.453125MB
INFO:root:[   78] Training loss: 0.84950021, Validation loss: 0.87409584, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=12087.40625MB
INFO:root:EP 78: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12457.29296875MB; mem (CPU total)=12159.87109375MB
INFO:root:Training the model took 2824.658s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85853
INFO:root:EnergyScoreTrain: 0.68685
INFO:root:CRPSTrain: 0.57691
INFO:root:Gaussian NLLTrain: 41807.27701
INFO:root:CoverageTrain: 0.2279
INFO:root:IntervalWidthTrain: 0.38901
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89061
INFO:root:EnergyScoreValidation: 0.71949
INFO:root:CRPSValidation: 0.60318
INFO:root:Gaussian NLLValidation: 1199.25943
INFO:root:CoverageValidation: 0.21754
INFO:root:IntervalWidthValidation: 0.38471
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89279
INFO:root:EnergyScoreTest: 0.72284
INFO:root:CRPSTest: 0.6062
INFO:root:Gaussian NLLTest: 538.90069
INFO:root:CoverageTest: 0.21395
INFO:root:IntervalWidthTest: 0.3804
INFO:root:After validation: mem (CPU python)=12457.29296875MB; mem (CPU total)=12585.20703125MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12457.29296875MB; mem (CPU total)=12588.6796875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 190840832
INFO:root:After setting up the model: mem (CPU python)=12457.29296875MB; mem (CPU total)=12593.109375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=12597.48046875MB
INFO:root:[    1] Training loss: 1.02239357, Validation loss: 1.01777891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=12672.56640625MB
INFO:root:[    2] Training loss: 1.01618483, Validation loss: 1.01322622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=12746.6875MB
INFO:root:[    3] Training loss: 1.00386340, Validation loss: 0.99253816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=12821.48046875MB
INFO:root:[    4] Training loss: 0.98479893, Validation loss: 0.97509365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=12895.68359375MB
INFO:root:[    5] Training loss: 0.97066939, Validation loss: 0.96137748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=12970.52734375MB
INFO:root:[    6] Training loss: 0.95889246, Validation loss: 0.95178496, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13045.9609375MB
INFO:root:[    7] Training loss: 0.94932073, Validation loss: 0.94190741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13121.44921875MB
INFO:root:[    8] Training loss: 0.94174516, Validation loss: 0.93644481, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13198.26171875MB
INFO:root:[    9] Training loss: 0.93600038, Validation loss: 0.93135358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13273.56640625MB
INFO:root:[   10] Training loss: 0.93125168, Validation loss: 0.92655283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13347.65234375MB
INFO:root:[   11] Training loss: 0.92711442, Validation loss: 0.92239635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13423.08984375MB
INFO:root:[   12] Training loss: 0.92347743, Validation loss: 0.91856512, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13497.52734375MB
INFO:root:[   13] Training loss: 0.92003020, Validation loss: 0.91538492, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13571.59765625MB
INFO:root:[   14] Training loss: 0.91698384, Validation loss: 0.91260338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13646.90234375MB
INFO:root:[   15] Training loss: 0.91384291, Validation loss: 0.91107238, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13721.9609375MB
INFO:root:[   16] Training loss: 0.91154785, Validation loss: 0.90836686, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13796.52734375MB
INFO:root:[   17] Training loss: 0.90885452, Validation loss: 0.90582719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13880.56640625MB
INFO:root:[   18] Training loss: 0.90639568, Validation loss: 0.90526101, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13924.65625MB
INFO:root:[   19] Training loss: 0.90431574, Validation loss: 0.90232428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=13968.9453125MB
INFO:root:[   20] Training loss: 0.90210863, Validation loss: 0.90039142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14013.2265625MB
INFO:root:[   21] Training loss: 0.90051012, Validation loss: 0.89901941, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14057.75390625MB
INFO:root:[   22] Training loss: 0.89855220, Validation loss: 0.89869139, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14101.796875MB
INFO:root:[   23] Training loss: 0.89694512, Validation loss: 0.89601252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14145.95703125MB
INFO:root:[   24] Training loss: 0.89528394, Validation loss: 0.89453895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14202.30859375MB
INFO:root:[   25] Training loss: 0.89375772, Validation loss: 0.89275954, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14277.4921875MB
INFO:root:[   26] Training loss: 0.89220289, Validation loss: 0.89191863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14352.5625MB
INFO:root:[   27] Training loss: 0.89053814, Validation loss: 0.89255026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14427.1796875MB
INFO:root:[   28] Training loss: 0.88941215, Validation loss: 0.88992622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14502.7109375MB
INFO:root:[   29] Training loss: 0.88822396, Validation loss: 0.88848982, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14577.59765625MB
INFO:root:[   30] Training loss: 0.88663265, Validation loss: 0.88872737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14653.39453125MB
INFO:root:[   31] Training loss: 0.88552589, Validation loss: 0.88820714, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14728.69921875MB
INFO:root:[   32] Training loss: 0.88437017, Validation loss: 0.88670514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14804.1015625MB
INFO:root:[   33] Training loss: 0.88305019, Validation loss: 0.88621397, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14879.609375MB
INFO:root:[   34] Training loss: 0.88215157, Validation loss: 0.88547305, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=14954.765625MB
INFO:root:[   35] Training loss: 0.88077987, Validation loss: 0.88493609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15029.73046875MB
INFO:root:[   36] Training loss: 0.87975785, Validation loss: 0.88432989, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15105.3125MB
INFO:root:[   37] Training loss: 0.87874975, Validation loss: 0.88374263, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15180.83203125MB
INFO:root:[   38] Training loss: 0.87774564, Validation loss: 0.88259522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15256.35546875MB
INFO:root:[   39] Training loss: 0.87656563, Validation loss: 0.88072322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15331.69140625MB
INFO:root:[   40] Training loss: 0.87556618, Validation loss: 0.88026980, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15407.2421875MB
INFO:root:[   41] Training loss: 0.87478902, Validation loss: 0.88192993, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15483.77734375MB
INFO:root:[   42] Training loss: 0.87368350, Validation loss: 0.88013620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15560.10546875MB
INFO:root:[   43] Training loss: 0.87265407, Validation loss: 0.87976974, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15636.265625MB
INFO:root:[   44] Training loss: 0.87178524, Validation loss: 0.87871562, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15711.5546875MB
INFO:root:[   45] Training loss: 0.87114066, Validation loss: 0.87870663, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15788.2734375MB
INFO:root:[   46] Training loss: 0.87040562, Validation loss: 0.87835706, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15864.546875MB
INFO:root:[   47] Training loss: 0.86928113, Validation loss: 0.87768187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=15940.80078125MB
INFO:root:[   48] Training loss: 0.86838221, Validation loss: 0.87720968, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16017.0703125MB
INFO:root:[   49] Training loss: 0.86743572, Validation loss: 0.87658827, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16091.18359375MB
INFO:root:[   50] Training loss: 0.86677438, Validation loss: 0.87640391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16166.90234375MB
INFO:root:[   51] Training loss: 0.86579629, Validation loss: 0.87675820, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16241.97265625MB
INFO:root:[   52] Training loss: 0.86484336, Validation loss: 0.87611921, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16317.01953125MB
INFO:root:[   53] Training loss: 0.86454030, Validation loss: 0.87551475, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16392.09375MB
INFO:root:[   54] Training loss: 0.86369055, Validation loss: 0.87602877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16467.55078125MB
INFO:root:[   55] Training loss: 0.86294468, Validation loss: 0.87536329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16542.625MB
INFO:root:[   56] Training loss: 0.86227645, Validation loss: 0.87434477, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16617.6953125MB
INFO:root:[   57] Training loss: 0.86153178, Validation loss: 0.87370277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16693.015625MB
INFO:root:[   58] Training loss: 0.86055119, Validation loss: 0.87374567, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16769.28125MB
INFO:root:[   59] Training loss: 0.85985163, Validation loss: 0.87397330, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16843.26953125MB
INFO:root:[   60] Training loss: 0.85938505, Validation loss: 0.87519891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16918.58203125MB
INFO:root:[   61] Training loss: 0.85819741, Validation loss: 0.87506836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=16993.828125MB
INFO:root:[   62] Training loss: 0.85783030, Validation loss: 0.87360993, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17068.90234375MB
INFO:root:[   63] Training loss: 0.85706703, Validation loss: 0.87443990, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17143.9765625MB
INFO:root:[   64] Training loss: 0.85652347, Validation loss: 0.87406753, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17218.9765625MB
INFO:root:[   65] Training loss: 0.85578903, Validation loss: 0.87364409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17294.29296875MB
INFO:root:[   66] Training loss: 0.85493337, Validation loss: 0.87267545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17369.14453125MB
INFO:root:[   67] Training loss: 0.85439604, Validation loss: 0.87352322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17444.21484375MB
INFO:root:[   68] Training loss: 0.85393774, Validation loss: 0.87310448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17519.7734375MB
INFO:root:[   69] Training loss: 0.85333826, Validation loss: 0.87203748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17593.8125MB
INFO:root:[   70] Training loss: 0.85252705, Validation loss: 0.87362435, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17669.1640625MB
INFO:root:[   71] Training loss: 0.85199498, Validation loss: 0.87225086, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17744.23828125MB
INFO:root:[   72] Training loss: 0.85151657, Validation loss: 0.87260924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17819.26953125MB
INFO:root:[   73] Training loss: 0.85105376, Validation loss: 0.87518175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17893.87890625MB
INFO:root:[   74] Training loss: 0.85040270, Validation loss: 0.87134372, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=17969.30859375MB
INFO:root:[   75] Training loss: 0.84964986, Validation loss: 0.87160398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18044.3671875MB
INFO:root:[   76] Training loss: 0.84875891, Validation loss: 0.87303703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18118.703125MB
INFO:root:[   77] Training loss: 0.84882109, Validation loss: 0.87177012, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18193.26953125MB
INFO:root:[   78] Training loss: 0.84777597, Validation loss: 0.87297527, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18268.7734375MB
INFO:root:[   79] Training loss: 0.84708924, Validation loss: 0.87353605, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18345.10546875MB
INFO:root:[   80] Training loss: 0.84662117, Validation loss: 0.87343685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18421.41015625MB
INFO:root:[   81] Training loss: 0.84602483, Validation loss: 0.87279103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18497.7109375MB
INFO:root:[   82] Training loss: 0.84550033, Validation loss: 0.87392222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18573.9765625MB
INFO:root:[   83] Training loss: 0.84498080, Validation loss: 0.87449020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18650.28125MB
INFO:root:EP 83: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12457.29296875MB; mem (CPU total)=18717.23046875MB
INFO:root:Training the model took 3190.131s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85253
INFO:root:EnergyScoreTrain: 0.67802
INFO:root:CRPSTrain: 0.56656
INFO:root:Gaussian NLLTrain: 567.27786
INFO:root:CoverageTrain: 0.23645
INFO:root:IntervalWidthTrain: 0.40296
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88967
INFO:root:EnergyScoreValidation: 0.71094
INFO:root:CRPSValidation: 0.59397
INFO:root:Gaussian NLLValidation: 424.47758
INFO:root:CoverageValidation: 0.2306
INFO:root:IntervalWidthValidation: 0.41262
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88915
INFO:root:EnergyScoreTest: 0.7128
INFO:root:CRPSTest: 0.59682
INFO:root:Gaussian NLLTest: 429.46461
INFO:root:CoverageTest: 0.22599
INFO:root:IntervalWidthTest: 0.40113
INFO:root:After validation: mem (CPU python)=12457.29296875MB; mem (CPU total)=18897.7890625MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12457.29296875MB; mem (CPU total)=18907.87890625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 190840832
INFO:root:After setting up the model: mem (CPU python)=12457.29296875MB; mem (CPU total)=18908.86328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18916.00390625MB
INFO:root:[    1] Training loss: 1.02181053, Validation loss: 1.01733193, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=18993.9140625MB
INFO:root:[    2] Training loss: 1.01662649, Validation loss: 1.01476176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19068.55078125MB
INFO:root:[    3] Training loss: 1.00899021, Validation loss: 0.99923771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19143.5390625MB
INFO:root:[    4] Training loss: 0.99215264, Validation loss: 0.98411732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19218.1015625MB
INFO:root:[    5] Training loss: 0.97865172, Validation loss: 0.97203297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19292.171875MB
INFO:root:[    6] Training loss: 0.96759621, Validation loss: 0.96125576, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19366.9765625MB
INFO:root:[    7] Training loss: 0.95866882, Validation loss: 0.95234671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19441.70703125MB
INFO:root:[    8] Training loss: 0.95094226, Validation loss: 0.94514175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19515.9921875MB
INFO:root:[    9] Training loss: 0.94478930, Validation loss: 0.93954512, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19590.5546875MB
INFO:root:[   10] Training loss: 0.93940933, Validation loss: 0.93440471, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19665.82421875MB
INFO:root:[   11] Training loss: 0.93497445, Validation loss: 0.93090389, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19740.41796875MB
INFO:root:[   12] Training loss: 0.93081061, Validation loss: 0.92811622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19814.29296875MB
INFO:root:[   13] Training loss: 0.92714921, Validation loss: 0.92404373, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19888.8515625MB
INFO:root:[   14] Training loss: 0.92420557, Validation loss: 0.92080181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=19963.625MB
INFO:root:[   15] Training loss: 0.92134367, Validation loss: 0.91832902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20038.8125MB
INFO:root:[   16] Training loss: 0.91866202, Validation loss: 0.91647024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20112.93359375MB
INFO:root:[   17] Training loss: 0.91633560, Validation loss: 0.91443981, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20187.484375MB
INFO:root:[   18] Training loss: 0.91380663, Validation loss: 0.91327790, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20262.7421875MB
INFO:root:[   19] Training loss: 0.91164747, Validation loss: 0.90952375, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20336.765625MB
INFO:root:[   20] Training loss: 0.90945143, Validation loss: 0.90845478, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20411.578125MB
INFO:root:[   21] Training loss: 0.90773542, Validation loss: 0.90712523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20485.8984375MB
INFO:root:[   22] Training loss: 0.90563583, Validation loss: 0.90471491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20561.44921875MB
INFO:root:[   23] Training loss: 0.90389288, Validation loss: 0.90473225, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20635.69140625MB
INFO:root:[   24] Training loss: 0.90227827, Validation loss: 0.90194360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20712.0234375MB
INFO:root:[   25] Training loss: 0.90069060, Validation loss: 0.90118846, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20788.328125MB
INFO:root:[   26] Training loss: 0.89910347, Validation loss: 0.90027732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20864.4140625MB
INFO:root:[   27] Training loss: 0.89738175, Validation loss: 0.89846580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=20940.5546875MB
INFO:root:[   28] Training loss: 0.89615327, Validation loss: 0.89852538, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21017.44921875MB
INFO:root:[   29] Training loss: 0.89482112, Validation loss: 0.89699122, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21093.66015625MB
INFO:root:[   30] Training loss: 0.89328328, Validation loss: 0.89650570, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21168.96484375MB
INFO:root:[   31] Training loss: 0.89223023, Validation loss: 0.89552453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21244.04296875MB
INFO:root:[   32] Training loss: 0.89092258, Validation loss: 0.89384681, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21318.125MB
INFO:root:[   33] Training loss: 0.88971716, Validation loss: 0.89347077, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21392.9453125MB
INFO:root:[   34] Training loss: 0.88870477, Validation loss: 0.89305660, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21467.7109375MB
INFO:root:[   35] Training loss: 0.88762579, Validation loss: 0.89249672, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21542.5390625MB
INFO:root:[   36] Training loss: 0.88614898, Validation loss: 0.89132997, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21616.58984375MB
INFO:root:[   37] Training loss: 0.88505912, Validation loss: 0.89099298, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21690.796875MB
INFO:root:[   38] Training loss: 0.88403470, Validation loss: 0.88983468, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21766.0234375MB
INFO:root:[   39] Training loss: 0.88332764, Validation loss: 0.88979339, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21841.2421875MB
INFO:root:[   40] Training loss: 0.88172660, Validation loss: 0.88925367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21915.078125MB
INFO:root:[   41] Training loss: 0.88125968, Validation loss: 0.88883230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=21988.96484375MB
INFO:root:[   42] Training loss: 0.88027731, Validation loss: 0.88831364, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22063.73828125MB
INFO:root:[   43] Training loss: 0.87912358, Validation loss: 0.88703446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22138.43359375MB
INFO:root:[   44] Training loss: 0.87849253, Validation loss: 0.88858750, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22212.75MB
INFO:root:[   45] Training loss: 0.87736994, Validation loss: 0.88725968, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22287.34765625MB
INFO:root:[   46] Training loss: 0.87635988, Validation loss: 0.88610441, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22361.69921875MB
INFO:root:[   47] Training loss: 0.87558067, Validation loss: 0.88574787, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22436.50390625MB
INFO:root:[   48] Training loss: 0.87468616, Validation loss: 0.88583826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22510.0859375MB
INFO:root:[   49] Training loss: 0.87377659, Validation loss: 0.88650135, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22584.40625MB
INFO:root:[   50] Training loss: 0.87327950, Validation loss: 0.88563765, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22660.171875MB
INFO:root:[   51] Training loss: 0.87200914, Validation loss: 0.88439676, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22736.734375MB
INFO:root:[   52] Training loss: 0.87119145, Validation loss: 0.88439353, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22814.38671875MB
INFO:root:[   53] Training loss: 0.87048722, Validation loss: 0.88481095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22890.5546875MB
INFO:root:[   54] Training loss: 0.86986473, Validation loss: 0.88410543, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=22967.09375MB
INFO:root:[   55] Training loss: 0.86903957, Validation loss: 0.88455363, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=23043.40234375MB
INFO:root:[   56] Training loss: 0.86842307, Validation loss: 0.88339550, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=23119.30078125MB
INFO:root:[   57] Training loss: 0.86796954, Validation loss: 0.88362366, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12457.29296875MB; mem (CPU total)=23195.65234375MB
INFO:root:[   58] Training loss: 0.86695348, Validation loss: 0.88302440, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12458.62890625MB; mem (CPU total)=23269.890625MB
INFO:root:[   59] Training loss: 0.86611476, Validation loss: 0.88322893, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12496.72265625MB; mem (CPU total)=23343.61328125MB
INFO:root:[   60] Training loss: 0.86544313, Validation loss: 0.88365811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12534.81640625MB; mem (CPU total)=23417.33203125MB
INFO:root:[   61] Training loss: 0.86489285, Validation loss: 0.88329351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12572.91796875MB; mem (CPU total)=23492.20703125MB
INFO:root:[   62] Training loss: 0.86394840, Validation loss: 0.88189067, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12611.01171875MB; mem (CPU total)=23576.90234375MB
INFO:root:[   63] Training loss: 0.86370336, Validation loss: 0.88246746, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12649.10546875MB; mem (CPU total)=23622.00390625MB
INFO:root:[   64] Training loss: 0.86270859, Validation loss: 0.88322938, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12687.19921875MB; mem (CPU total)=23667.44921875MB
INFO:root:[   65] Training loss: 0.86226395, Validation loss: 0.88282367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12725.296875MB; mem (CPU total)=23712.5625MB
INFO:root:[   66] Training loss: 0.86138616, Validation loss: 0.88318210, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12763.390625MB; mem (CPU total)=23757.73046875MB
INFO:root:[   67] Training loss: 0.86067554, Validation loss: 0.88201371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12801.484375MB; mem (CPU total)=23802.89453125MB
INFO:root:[   68] Training loss: 0.86015564, Validation loss: 0.88265213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12839.5859375MB; mem (CPU total)=23799.37109375MB
INFO:root:[   69] Training loss: 0.85957037, Validation loss: 0.88302083, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12877.6796875MB; mem (CPU total)=23874.07421875MB
INFO:root:[   70] Training loss: 0.85877971, Validation loss: 0.88245010, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12915.7734375MB; mem (CPU total)=23949.421875MB
INFO:root:[   71] Training loss: 0.85810798, Validation loss: 0.88266821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12953.87109375MB; mem (CPU total)=24024.2734375MB
INFO:root:EP 71: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12991.8984375MB; mem (CPU total)=24091.93359375MB
INFO:root:Training the model took 3010.682s.
INFO:root:Emptying the cuda cache took 0.022s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86584
INFO:root:EnergyScoreTrain: 0.70478
INFO:root:CRPSTrain: 0.58925
INFO:root:Gaussian NLLTrain: 686.51865
INFO:root:CoverageTrain: 0.20911
INFO:root:IntervalWidthTrain: 0.35803
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89602
INFO:root:EnergyScoreValidation: 0.73527
INFO:root:CRPSValidation: 0.61346
INFO:root:Gaussian NLLValidation: 596.23233
INFO:root:CoverageValidation: 0.20258
INFO:root:IntervalWidthValidation: 0.35554
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89914
INFO:root:EnergyScoreTest: 0.73558
INFO:root:CRPSTest: 0.6159
INFO:root:Gaussian NLLTest: 645.02248
INFO:root:CoverageTest: 0.2012
INFO:root:IntervalWidthTest: 0.36277
INFO:root:After validation: mem (CPU python)=13065.59765625MB; mem (CPU total)=24264.70703125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=13065.59765625MB; mem (CPU total)=24279.3203125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 190840832
INFO:root:After setting up the model: mem (CPU python)=13065.84765625MB; mem (CPU total)=24280.55078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=13065.98828125MB; mem (CPU total)=24281.046875MB
INFO:root:[    1] Training loss: 1.02195680, Validation loss: 1.01739841, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13104.0MB; mem (CPU total)=24357.625MB
INFO:root:[    2] Training loss: 1.01591018, Validation loss: 1.01335769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13142.09765625MB; mem (CPU total)=24434.171875MB
INFO:root:[    3] Training loss: 1.00511934, Validation loss: 0.99544114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13180.2109375MB; mem (CPU total)=24510.46875MB
INFO:root:[    4] Training loss: 0.99060609, Validation loss: 0.98444124, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13218.3203125MB; mem (CPU total)=24586.58203125MB
INFO:root:[    5] Training loss: 0.97925088, Validation loss: 0.97294847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13256.4296875MB; mem (CPU total)=24662.74609375MB
INFO:root:[    6] Training loss: 0.96842599, Validation loss: 0.96331306, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13294.54296875MB; mem (CPU total)=24739.16796875MB
INFO:root:[    7] Training loss: 0.95944912, Validation loss: 0.95367424, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13332.63671875MB; mem (CPU total)=24815.71484375MB
INFO:root:[    8] Training loss: 0.95174039, Validation loss: 0.94586357, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13370.73046875MB; mem (CPU total)=24891.77734375MB
INFO:root:[    9] Training loss: 0.94526109, Validation loss: 0.94047642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13408.82421875MB; mem (CPU total)=24967.9140625MB
INFO:root:[   10] Training loss: 0.94004558, Validation loss: 0.93567826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13446.92578125MB; mem (CPU total)=25043.51171875MB
INFO:root:[   11] Training loss: 0.93531898, Validation loss: 0.93079658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13485.01953125MB; mem (CPU total)=25118.734375MB
INFO:root:[   12] Training loss: 0.93092602, Validation loss: 0.92654145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13523.11328125MB; mem (CPU total)=25193.45703125MB
INFO:root:[   13] Training loss: 0.92725957, Validation loss: 0.92462680, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13561.2109375MB; mem (CPU total)=25268.3125MB
INFO:root:[   14] Training loss: 0.92366742, Validation loss: 0.92134135, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13599.3046875MB; mem (CPU total)=25342.65234375MB
INFO:root:[   15] Training loss: 0.92081952, Validation loss: 0.91867599, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13637.3984375MB; mem (CPU total)=25418.46484375MB
INFO:root:[   16] Training loss: 0.91786502, Validation loss: 0.91516922, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13675.4921875MB; mem (CPU total)=25493.53125MB
INFO:root:[   17] Training loss: 0.91502667, Validation loss: 0.91340408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13713.59375MB; mem (CPU total)=25567.84765625MB
INFO:root:[   18] Training loss: 0.91271454, Validation loss: 0.91110169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13751.6875MB; mem (CPU total)=25642.4765625MB
INFO:root:[   19] Training loss: 0.91046750, Validation loss: 0.90933707, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13789.78125MB; mem (CPU total)=25717.75390625MB
INFO:root:[   20] Training loss: 0.90820498, Validation loss: 0.90739681, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13827.87890625MB; mem (CPU total)=25792.953125MB
INFO:root:[   21] Training loss: 0.90611057, Validation loss: 0.90539485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13865.97265625MB; mem (CPU total)=25868.2734375MB
INFO:root:[   22] Training loss: 0.90405696, Validation loss: 0.90376186, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13904.06640625MB; mem (CPU total)=25942.5703125MB
INFO:root:[   23] Training loss: 0.90213636, Validation loss: 0.90170375, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13942.16796875MB; mem (CPU total)=26018.08203125MB
INFO:root:[   24] Training loss: 0.90011123, Validation loss: 0.90058149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13980.26171875MB; mem (CPU total)=26094.3203125MB
INFO:root:[   25] Training loss: 0.89852939, Validation loss: 0.89896948, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14018.359375MB; mem (CPU total)=26169.2890625MB
INFO:root:[   26] Training loss: 0.89671193, Validation loss: 0.89721191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14056.453125MB; mem (CPU total)=26244.56640625MB
INFO:root:[   27] Training loss: 0.89498351, Validation loss: 0.89631732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14094.55078125MB; mem (CPU total)=26318.8984375MB
INFO:root:[   28] Training loss: 0.89366000, Validation loss: 0.89484864, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14132.64453125MB; mem (CPU total)=26395.1953125MB
INFO:root:[   29] Training loss: 0.89225578, Validation loss: 0.89482725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14170.73828125MB; mem (CPU total)=26470.73046875MB
INFO:root:[   30] Training loss: 0.89055629, Validation loss: 0.89372832, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14208.8359375MB; mem (CPU total)=26545.0390625MB
INFO:root:[   31] Training loss: 0.88922977, Validation loss: 0.89196361, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14246.9296875MB; mem (CPU total)=26620.984375MB
INFO:root:[   32] Training loss: 0.88809452, Validation loss: 0.89069319, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14285.0234375MB; mem (CPU total)=26695.94921875MB
INFO:root:[   33] Training loss: 0.88650205, Validation loss: 0.89117703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14323.12109375MB; mem (CPU total)=26771.75390625MB
INFO:root:[   34] Training loss: 0.88548037, Validation loss: 0.88953807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14361.21875MB; mem (CPU total)=26848.27734375MB
INFO:root:[   35] Training loss: 0.88428947, Validation loss: 0.88824645, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14399.3125MB; mem (CPU total)=26922.76953125MB
INFO:root:[   36] Training loss: 0.88318238, Validation loss: 0.88757235, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14437.40625MB; mem (CPU total)=26997.5703125MB
INFO:root:[   37] Training loss: 0.88194190, Validation loss: 0.88741213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14475.50390625MB; mem (CPU total)=27073.4140625MB
INFO:root:[   38] Training loss: 0.88113732, Validation loss: 0.88591439, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14513.59765625MB; mem (CPU total)=27148.9453125MB
INFO:root:[   39] Training loss: 0.87986711, Validation loss: 0.88509003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14551.6953125MB; mem (CPU total)=27224.6953125MB
INFO:root:[   40] Training loss: 0.87876447, Validation loss: 0.88505864, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14589.7890625MB; mem (CPU total)=27299.25390625MB
INFO:root:[   41] Training loss: 0.87797660, Validation loss: 0.88467444, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14627.8828125MB; mem (CPU total)=27373.55859375MB
INFO:root:[   42] Training loss: 0.87695485, Validation loss: 0.88409847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14665.98046875MB; mem (CPU total)=27449.66796875MB
INFO:root:[   43] Training loss: 0.87597722, Validation loss: 0.88422753, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14704.07421875MB; mem (CPU total)=27526.00390625MB
INFO:root:[   44] Training loss: 0.87520296, Validation loss: 0.88432460, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14742.171875MB; mem (CPU total)=27602.3125MB
INFO:root:[   45] Training loss: 0.87427014, Validation loss: 0.88251173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14780.265625MB; mem (CPU total)=27678.61328125MB
INFO:root:[   46] Training loss: 0.87341929, Validation loss: 0.88343168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14818.359375MB; mem (CPU total)=27754.890625MB
INFO:root:[   47] Training loss: 0.87247344, Validation loss: 0.88190862, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14856.45703125MB; mem (CPU total)=27831.44140625MB
INFO:root:[   48] Training loss: 0.87151753, Validation loss: 0.88092783, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14894.5546875MB; mem (CPU total)=27907.703125MB
INFO:root:[   49] Training loss: 0.87069148, Validation loss: 0.88068166, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14932.6484375MB; mem (CPU total)=27983.953125MB
INFO:root:[   50] Training loss: 0.87007791, Validation loss: 0.88032326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14970.7421875MB; mem (CPU total)=28059.95703125MB
INFO:root:[   51] Training loss: 0.86922164, Validation loss: 0.88008217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15008.83984375MB; mem (CPU total)=28136.64453125MB
INFO:root:[   52] Training loss: 0.86833332, Validation loss: 0.88063062, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15046.93359375MB; mem (CPU total)=28212.93359375MB
INFO:root:[   53] Training loss: 0.86743863, Validation loss: 0.87956979, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15085.02734375MB; mem (CPU total)=28289.734375MB
INFO:root:[   54] Training loss: 0.86679445, Validation loss: 0.88007329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15123.125MB; mem (CPU total)=28366.0390625MB
INFO:root:[   55] Training loss: 0.86593993, Validation loss: 0.87986230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15161.22265625MB; mem (CPU total)=28442.0703125MB
INFO:root:[   56] Training loss: 0.86495582, Validation loss: 0.87953314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15199.31640625MB; mem (CPU total)=28519.046875MB
INFO:root:[   57] Training loss: 0.86463115, Validation loss: 0.87971500, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15237.4140625MB; mem (CPU total)=28594.9609375MB
INFO:root:[   58] Training loss: 0.86374132, Validation loss: 0.87760959, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15275.51171875MB; mem (CPU total)=28671.265625MB
INFO:root:[   59] Training loss: 0.86308430, Validation loss: 0.87983990, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15313.60546875MB; mem (CPU total)=28747.8125MB
INFO:root:[   60] Training loss: 0.86228097, Validation loss: 0.87830577, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15351.69921875MB; mem (CPU total)=28823.87109375MB
INFO:root:[   61] Training loss: 0.86163979, Validation loss: 0.87899371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15389.796875MB; mem (CPU total)=28900.17578125MB
INFO:root:[   62] Training loss: 0.86108690, Validation loss: 0.88076255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15427.890625MB; mem (CPU total)=28976.73046875MB
INFO:root:[   63] Training loss: 0.86027010, Validation loss: 0.87918549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15465.984375MB; mem (CPU total)=29052.703125MB
INFO:root:[   64] Training loss: 0.85971971, Validation loss: 0.87828078, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15504.0859375MB; mem (CPU total)=29129.3046875MB
INFO:root:[   65] Training loss: 0.85884394, Validation loss: 0.87841723, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15542.1796875MB; mem (CPU total)=29205.8046875MB
INFO:root:[   66] Training loss: 0.85814613, Validation loss: 0.87783796, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15580.2734375MB; mem (CPU total)=29281.8671875MB
INFO:root:[   67] Training loss: 0.85759294, Validation loss: 0.87784868, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15618.3671875MB; mem (CPU total)=29358.12109375MB
INFO:root:EP 67: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=15656.4453125MB; mem (CPU total)=29416.40234375MB
INFO:root:Training the model took 3108.233s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.863
INFO:root:EnergyScoreTrain: 0.71767
INFO:root:CRPSTrain: 0.59084
INFO:root:Gaussian NLLTrain: 752.2625
INFO:root:CoverageTrain: 0.19581
INFO:root:IntervalWidthTrain: 0.31934
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89075
INFO:root:EnergyScoreValidation: 0.74702
INFO:root:CRPSValidation: 0.61411
INFO:root:Gaussian NLLValidation: 782.62174
INFO:root:CoverageValidation: 0.18607
INFO:root:IntervalWidthValidation: 0.31531
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89142
INFO:root:EnergyScoreTest: 0.74065
INFO:root:CRPSTest: 0.61187
INFO:root:Gaussian NLLTest: 624.30414
INFO:root:CoverageTest: 0.1939
INFO:root:IntervalWidthTest: 0.33119
INFO:root:After validation: mem (CPU python)=15730.07421875MB; mem (CPU total)=29584.58984375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=15730.07421875MB; mem (CPU total)=29592.953125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 190840832
INFO:root:After setting up the model: mem (CPU python)=15730.45703125MB; mem (CPU total)=29594.0859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=15730.45703125MB; mem (CPU total)=29612.89453125MB
INFO:root:[    1] Training loss: 1.02152104, Validation loss: 1.01695013, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15769.125MB; mem (CPU total)=29690.20703125MB
INFO:root:[    2] Training loss: 1.01543985, Validation loss: 1.01152459, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15807.234375MB; mem (CPU total)=29766.99609375MB
INFO:root:[    3] Training loss: 1.00299063, Validation loss: 0.99375665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15845.3359375MB; mem (CPU total)=29844.28515625MB
INFO:root:[    4] Training loss: 0.98883227, Validation loss: 0.98177551, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15883.4296875MB; mem (CPU total)=29922.0859375MB
INFO:root:[    5] Training loss: 0.97733872, Validation loss: 0.96998294, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15921.5234375MB; mem (CPU total)=29998.19140625MB
INFO:root:[    6] Training loss: 0.96593762, Validation loss: 0.95809388, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15959.625MB; mem (CPU total)=30075.0546875MB
INFO:root:[    7] Training loss: 0.95628717, Validation loss: 0.94864121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15997.71875MB; mem (CPU total)=30152.265625MB
INFO:root:[    8] Training loss: 0.94806750, Validation loss: 0.94200312, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16035.8125MB; mem (CPU total)=30228.8203125MB
INFO:root:[    9] Training loss: 0.94183824, Validation loss: 0.93667394, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16073.91015625MB; mem (CPU total)=30306.359375MB
INFO:root:[   10] Training loss: 0.93653957, Validation loss: 0.93162728, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16112.00390625MB; mem (CPU total)=30383.125MB
INFO:root:[   11] Training loss: 0.93200423, Validation loss: 0.92878288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16150.09765625MB; mem (CPU total)=30460.6640625MB
INFO:root:[   12] Training loss: 0.92796129, Validation loss: 0.92421530, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16188.1953125MB; mem (CPU total)=30537.890625MB
INFO:root:[   13] Training loss: 0.92474521, Validation loss: 0.92113052, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16226.29296875MB; mem (CPU total)=30615.4296875MB
INFO:root:[   14] Training loss: 0.92124927, Validation loss: 0.91778087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16264.38671875MB; mem (CPU total)=30692.4765625MB
INFO:root:[   15] Training loss: 0.91819953, Validation loss: 0.91526519, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16302.48046875MB; mem (CPU total)=30768.4765625MB
INFO:root:[   16] Training loss: 0.91571170, Validation loss: 0.91313489, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16340.578125MB; mem (CPU total)=30845.30859375MB
INFO:root:[   17] Training loss: 0.91306471, Validation loss: 0.91165202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16378.671875MB; mem (CPU total)=30921.640625MB
INFO:root:[   18] Training loss: 0.91085611, Validation loss: 0.90989094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16416.765625MB; mem (CPU total)=30998.19921875MB
INFO:root:[   19] Training loss: 0.90850139, Validation loss: 0.90898788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16454.859375MB; mem (CPU total)=31074.76953125MB
INFO:root:[   20] Training loss: 0.90636194, Validation loss: 0.90605481, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16492.9609375MB; mem (CPU total)=31150.8515625MB
INFO:root:[   21] Training loss: 0.90463775, Validation loss: 0.90462090, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16531.0546875MB; mem (CPU total)=31232.21484375MB
INFO:root:[   22] Training loss: 0.90250757, Validation loss: 0.90239769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16569.1484375MB; mem (CPU total)=31308.453125MB
INFO:root:[   23] Training loss: 0.90057851, Validation loss: 0.90180547, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16607.24609375MB; mem (CPU total)=31385.0078125MB
INFO:root:[   24] Training loss: 0.89898997, Validation loss: 0.89961621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16645.33984375MB; mem (CPU total)=31462.46875MB
INFO:root:[   25] Training loss: 0.89707782, Validation loss: 0.89892549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16683.43359375MB; mem (CPU total)=31537.50390625MB
INFO:root:[   26] Training loss: 0.89572392, Validation loss: 0.89731428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16721.53125MB; mem (CPU total)=31614.05859375MB
INFO:root:[   27] Training loss: 0.89378627, Validation loss: 0.89469918, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16759.62890625MB; mem (CPU total)=31690.10546875MB
INFO:root:[   28] Training loss: 0.89256145, Validation loss: 0.89496454, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16797.72265625MB; mem (CPU total)=31766.4140625MB
INFO:root:[   29] Training loss: 0.89118507, Validation loss: 0.89401141, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16835.8203125MB; mem (CPU total)=31843.18359375MB
INFO:root:[   30] Training loss: 0.88993052, Validation loss: 0.89308268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16873.91796875MB; mem (CPU total)=31918.7890625MB
INFO:root:[   31] Training loss: 0.88817341, Validation loss: 0.89231802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16912.01171875MB; mem (CPU total)=31995.19140625MB
INFO:root:[   32] Training loss: 0.88745741, Validation loss: 0.89161292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16950.10546875MB; mem (CPU total)=32131.25390625MB
INFO:root:[   33] Training loss: 0.88586083, Validation loss: 0.89024881, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16988.203125MB; mem (CPU total)=32178.37109375MB
INFO:root:[   34] Training loss: 0.88514454, Validation loss: 0.88936408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17026.296875MB; mem (CPU total)=32224.49609375MB
INFO:root:[   35] Training loss: 0.88377092, Validation loss: 0.88863559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17064.390625MB; mem (CPU total)=32270.43359375MB
INFO:root:[   36] Training loss: 0.88250930, Validation loss: 0.88803448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17102.48828125MB; mem (CPU total)=32316.90625MB
INFO:root:[   37] Training loss: 0.88172686, Validation loss: 0.88734322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17140.5859375MB; mem (CPU total)=32361.72265625MB
INFO:root:[   38] Training loss: 0.88052907, Validation loss: 0.88706430, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17178.6796875MB; mem (CPU total)=32371.94140625MB
INFO:root:[   39] Training loss: 0.87950371, Validation loss: 0.88554887, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17216.7734375MB; mem (CPU total)=32449.5390625MB
INFO:root:[   40] Training loss: 0.87843846, Validation loss: 0.88606662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17254.87109375MB; mem (CPU total)=32527.140625MB
INFO:root:[   41] Training loss: 0.87723917, Validation loss: 0.88546262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17292.96484375MB; mem (CPU total)=32604.984375MB
INFO:root:[   42] Training loss: 0.87633247, Validation loss: 0.88417924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17331.05859375MB; mem (CPU total)=32682.7734375MB
INFO:root:[   43] Training loss: 0.87544064, Validation loss: 0.88407869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17369.15625MB; mem (CPU total)=32760.7578125MB
INFO:root:[   44] Training loss: 0.87486456, Validation loss: 0.88413495, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17407.25MB; mem (CPU total)=32837.51953125MB
INFO:root:[   45] Training loss: 0.87386767, Validation loss: 0.88371205, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17445.34375MB; mem (CPU total)=32914.10546875MB
INFO:root:[   46] Training loss: 0.87281330, Validation loss: 0.88306689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17483.44140625MB; mem (CPU total)=32990.2890625MB
INFO:root:[   47] Training loss: 0.87188215, Validation loss: 0.88202276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17521.5390625MB; mem (CPU total)=33066.59765625MB
INFO:root:[   48] Training loss: 0.87116594, Validation loss: 0.88240567, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17559.6328125MB; mem (CPU total)=33143.3984375MB
INFO:root:[   49] Training loss: 0.87023985, Validation loss: 0.88165305, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17597.7265625MB; mem (CPU total)=33219.67578125MB
INFO:root:[   50] Training loss: 0.86962022, Validation loss: 0.88183026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17635.82421875MB; mem (CPU total)=33295.984375MB
INFO:root:[   51] Training loss: 0.86862567, Validation loss: 0.88103009, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17673.91796875MB; mem (CPU total)=33371.86328125MB
INFO:root:[   52] Training loss: 0.86784447, Validation loss: 0.88048219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17712.01171875MB; mem (CPU total)=33448.90625MB
INFO:root:[   53] Training loss: 0.86717782, Validation loss: 0.88046664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17750.10546875MB; mem (CPU total)=33527.09375MB
INFO:root:[   54] Training loss: 0.86594586, Validation loss: 0.88060951, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17788.20703125MB; mem (CPU total)=33603.64453125MB
INFO:root:[   55] Training loss: 0.86542191, Validation loss: 0.88127228, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17826.30078125MB; mem (CPU total)=33681.40234375MB
INFO:root:[   56] Training loss: 0.86485407, Validation loss: 0.88055485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17864.39453125MB; mem (CPU total)=33759.13671875MB
INFO:root:[   57] Training loss: 0.86429074, Validation loss: 0.88133594, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17902.4921875MB; mem (CPU total)=33837.1171875MB
INFO:root:[   58] Training loss: 0.86313309, Validation loss: 0.88021245, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17940.5859375MB; mem (CPU total)=33915.55078125MB
INFO:root:[   59] Training loss: 0.86268026, Validation loss: 0.88066078, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17978.6796875MB; mem (CPU total)=33994.25MB
INFO:root:[   60] Training loss: 0.86204589, Validation loss: 0.87879155, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18016.77734375MB; mem (CPU total)=34072.484375MB
INFO:root:[   61] Training loss: 0.86106237, Validation loss: 0.87999827, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18054.87109375MB; mem (CPU total)=34151.23046875MB
INFO:root:[   62] Training loss: 0.86059218, Validation loss: 0.87992625, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18092.96875MB; mem (CPU total)=34228.7421875MB
INFO:root:[   63] Training loss: 0.86007734, Validation loss: 0.88151349, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18131.05859375MB; mem (CPU total)=34307.4921875MB
INFO:root:[   64] Training loss: 0.85929693, Validation loss: 0.87976257, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18169.16015625MB; mem (CPU total)=34385.47265625MB
INFO:root:[   65] Training loss: 0.85874461, Validation loss: 0.87936700, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18207.25390625MB; mem (CPU total)=34463.87890625MB
INFO:root:[   66] Training loss: 0.85770635, Validation loss: 0.87788789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18245.34765625MB; mem (CPU total)=34542.5625MB
INFO:root:[   67] Training loss: 0.85719489, Validation loss: 0.87998392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18283.4453125MB; mem (CPU total)=34620.375MB
INFO:root:[   68] Training loss: 0.85650938, Validation loss: 0.87892271, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18321.5390625MB; mem (CPU total)=34699.09765625MB
INFO:root:[   69] Training loss: 0.85598400, Validation loss: 0.87882677, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18359.640625MB; mem (CPU total)=34777.6015625MB
INFO:root:[   70] Training loss: 0.85534503, Validation loss: 0.87895943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18397.73828125MB; mem (CPU total)=34855.859375MB
INFO:root:[   71] Training loss: 0.85468854, Validation loss: 0.87899431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18435.8359375MB; mem (CPU total)=34934.609375MB
INFO:root:[   72] Training loss: 0.85406870, Validation loss: 0.87948664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18473.9296875MB; mem (CPU total)=35013.3125MB
INFO:root:[   73] Training loss: 0.85307587, Validation loss: 0.87838274, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18512.0234375MB; mem (CPU total)=35092.80078125MB
INFO:root:[   74] Training loss: 0.85279529, Validation loss: 0.87937318, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18550.12109375MB; mem (CPU total)=35169.078125MB
INFO:root:[   75] Training loss: 0.85245497, Validation loss: 0.87839272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18588.21484375MB; mem (CPU total)=35245.39453125MB
INFO:root:EP 75: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=18626.1796875MB; mem (CPU total)=35301.75MB
INFO:root:Training the model took 3850.726s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85812
INFO:root:EnergyScoreTrain: 0.70279
INFO:root:CRPSTrain: 0.58663
INFO:root:Gaussian NLLTrain: 1133.53152
INFO:root:CoverageTrain: 0.20247
INFO:root:IntervalWidthTrain: 0.33483
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89336
INFO:root:EnergyScoreValidation: 0.73617
INFO:root:CRPSValidation: 0.61505
INFO:root:Gaussian NLLValidation: 988.46922
INFO:root:CoverageValidation: 0.19381
INFO:root:IntervalWidthValidation: 0.33612
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89349
INFO:root:EnergyScoreTest: 0.73757
INFO:root:CRPSTest: 0.61603
INFO:root:Gaussian NLLTest: 857.21843
INFO:root:CoverageTest: 0.19128
INFO:root:IntervalWidthTest: 0.33134
INFO:root:After validation: mem (CPU python)=18699.91015625MB; mem (CPU total)=35471.01953125MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=18699.91015625MB; mem (CPU total)=35474.43359375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 190840832
INFO:root:After setting up the model: mem (CPU python)=18700.2890625MB; mem (CPU total)=35475.41796875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=18700.2890625MB; mem (CPU total)=35498.55078125MB
INFO:root:[    1] Training loss: 1.02189865, Validation loss: 1.01726650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18738.3671875MB; mem (CPU total)=35576.69140625MB
INFO:root:[    2] Training loss: 1.01622624, Validation loss: 1.01401540, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18776.4609375MB; mem (CPU total)=35655.1875MB
INFO:root:[    3] Training loss: 1.00635907, Validation loss: 0.99714578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18814.5703125MB; mem (CPU total)=35734.1015625MB
INFO:root:[    4] Training loss: 0.99232540, Validation loss: 0.98600976, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18852.66796875MB; mem (CPU total)=35813.578125MB
INFO:root:[    5] Training loss: 0.98238088, Validation loss: 0.97545691, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18890.7578125MB; mem (CPU total)=35890.6640625MB
INFO:root:[    6] Training loss: 0.97259609, Validation loss: 0.96692993, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18928.85546875MB; mem (CPU total)=35966.703125MB
INFO:root:[    7] Training loss: 0.96351961, Validation loss: 0.95931893, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18966.94921875MB; mem (CPU total)=36043.1953125MB
INFO:root:[    8] Training loss: 0.95558525, Validation loss: 0.95009180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19005.046875MB; mem (CPU total)=36119.484375MB
INFO:root:[    9] Training loss: 0.94852659, Validation loss: 0.94254711, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19043.140625MB; mem (CPU total)=36194.9296875MB
INFO:root:[   10] Training loss: 0.94213261, Validation loss: 0.93683063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19081.234375MB; mem (CPU total)=36270.72265625MB
INFO:root:[   11] Training loss: 0.93671994, Validation loss: 0.93186465, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19119.33203125MB; mem (CPU total)=36346.9921875MB
INFO:root:[   12] Training loss: 0.93207939, Validation loss: 0.92713126, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19157.4296875MB; mem (CPU total)=36423.5234375MB
INFO:root:[   13] Training loss: 0.92813263, Validation loss: 0.92504164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19195.5234375MB; mem (CPU total)=36499.57421875MB
INFO:root:[   14] Training loss: 0.92473439, Validation loss: 0.92009798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19233.6171875MB; mem (CPU total)=36576.37890625MB
INFO:root:[   15] Training loss: 0.92102298, Validation loss: 0.91616277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19271.71484375MB; mem (CPU total)=36652.359375MB
INFO:root:[   16] Training loss: 0.91806142, Validation loss: 0.91345409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19309.80859375MB; mem (CPU total)=36728.390625MB
INFO:root:[   17] Training loss: 0.91548245, Validation loss: 0.91193748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19347.90234375MB; mem (CPU total)=36807.19140625MB
INFO:root:[   18] Training loss: 0.91317499, Validation loss: 0.91109740, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19386.0MB; mem (CPU total)=36884.51953125MB
INFO:root:[   19] Training loss: 0.91072795, Validation loss: 0.90690970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19424.09375MB; mem (CPU total)=36962.51953125MB
INFO:root:[   20] Training loss: 0.90840380, Validation loss: 0.90551341, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19462.1875MB; mem (CPU total)=37040.22265625MB
INFO:root:[   21] Training loss: 0.90642786, Validation loss: 0.90360885, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19500.28515625MB; mem (CPU total)=37117.68359375MB
INFO:root:[   22] Training loss: 0.90467617, Validation loss: 0.90209170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19538.3828125MB; mem (CPU total)=37194.94140625MB
INFO:root:[   23] Training loss: 0.90288354, Validation loss: 0.90020603, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19576.48046875MB; mem (CPU total)=37271.8984375MB
INFO:root:[   24] Training loss: 0.90103194, Validation loss: 0.89993397, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19614.57421875MB; mem (CPU total)=37350.171875MB
INFO:root:[   25] Training loss: 0.89934267, Validation loss: 0.89777982, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19652.671875MB; mem (CPU total)=37428.203125MB
INFO:root:[   26] Training loss: 0.89772180, Validation loss: 0.89825020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19690.765625MB; mem (CPU total)=37506.9609375MB
INFO:root:[   27] Training loss: 0.89631290, Validation loss: 0.89521277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19728.859375MB; mem (CPU total)=37584.25390625MB
INFO:root:[   28] Training loss: 0.89466439, Validation loss: 0.89484168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19766.95703125MB; mem (CPU total)=37661.9921875MB
INFO:root:[   29] Training loss: 0.89357027, Validation loss: 0.89377480, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19805.0546875MB; mem (CPU total)=37739.48046875MB
INFO:root:[   30] Training loss: 0.89211765, Validation loss: 0.89288841, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19843.1484375MB; mem (CPU total)=37817.22265625MB
INFO:root:[   31] Training loss: 0.89056748, Validation loss: 0.89167195, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19881.2421875MB; mem (CPU total)=37894.4921875MB
INFO:root:[   32] Training loss: 0.88926704, Validation loss: 0.89047789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19919.33984375MB; mem (CPU total)=37971.4453125MB
INFO:root:[   33] Training loss: 0.88816897, Validation loss: 0.88930151, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19957.43359375MB; mem (CPU total)=38049.43359375MB
INFO:root:[   34] Training loss: 0.88688702, Validation loss: 0.88915148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19995.52734375MB; mem (CPU total)=38126.7578125MB
INFO:root:[   35] Training loss: 0.88598779, Validation loss: 0.88781585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20033.625MB; mem (CPU total)=38204.57421875MB
INFO:root:[   36] Training loss: 0.88477073, Validation loss: 0.88771073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20071.71875MB; mem (CPU total)=38282.2890625MB
INFO:root:[   37] Training loss: 0.88365866, Validation loss: 0.88725959, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20109.81640625MB; mem (CPU total)=38359.0859375MB
INFO:root:[   38] Training loss: 0.88250774, Validation loss: 0.88660169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20147.9140625MB; mem (CPU total)=38437.04296875MB
INFO:root:[   39] Training loss: 0.88160950, Validation loss: 0.88613812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20186.01171875MB; mem (CPU total)=38514.32421875MB
INFO:root:[   40] Training loss: 0.88070247, Validation loss: 0.88484444, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20224.10546875MB; mem (CPU total)=38592.140625MB
INFO:root:[   41] Training loss: 0.87992233, Validation loss: 0.88421039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20262.19921875MB; mem (CPU total)=38670.04296875MB
INFO:root:[   42] Training loss: 0.87856238, Validation loss: 0.88436259, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20300.296875MB; mem (CPU total)=38747.70703125MB
INFO:root:[   43] Training loss: 0.87777890, Validation loss: 0.88363936, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20338.390625MB; mem (CPU total)=38824.8671875MB
INFO:root:[   44] Training loss: 0.87706976, Validation loss: 0.88316080, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20376.484375MB; mem (CPU total)=38902.82421875MB
INFO:root:[   45] Training loss: 0.87614657, Validation loss: 0.88253810, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20414.58203125MB; mem (CPU total)=38980.21875MB
INFO:root:[   46] Training loss: 0.87521958, Validation loss: 0.88167532, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20452.6796875MB; mem (CPU total)=39057.25390625MB
INFO:root:[   47] Training loss: 0.87468527, Validation loss: 0.88201990, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20490.7734375MB; mem (CPU total)=39133.14453125MB
INFO:root:[   48] Training loss: 0.87375716, Validation loss: 0.88230041, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20528.8671875MB; mem (CPU total)=39209.453125MB
INFO:root:[   49] Training loss: 0.87308968, Validation loss: 0.88234257, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20566.96484375MB; mem (CPU total)=39286.2421875MB
INFO:root:[   50] Training loss: 0.87221565, Validation loss: 0.88022523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20605.05859375MB; mem (CPU total)=39363.4921875MB
INFO:root:[   51] Training loss: 0.87130588, Validation loss: 0.88016139, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20643.15234375MB; mem (CPU total)=39439.30859375MB
INFO:root:[   52] Training loss: 0.87050795, Validation loss: 0.88026634, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20681.25MB; mem (CPU total)=39516.0078125MB
INFO:root:[   53] Training loss: 0.87020913, Validation loss: 0.88061249, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20719.34765625MB; mem (CPU total)=39591.9921875MB
INFO:root:[   54] Training loss: 0.86927481, Validation loss: 0.87965036, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20757.44140625MB; mem (CPU total)=39668.19140625MB
INFO:root:[   55] Training loss: 0.86831874, Validation loss: 0.87923877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20795.5390625MB; mem (CPU total)=39744.75MB
INFO:root:[   56] Training loss: 0.86779861, Validation loss: 0.87973240, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20833.6328125MB; mem (CPU total)=39821.48828125MB
INFO:root:[   57] Training loss: 0.86697766, Validation loss: 0.87867938, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20871.7265625MB; mem (CPU total)=39897.55078125MB
INFO:root:[   58] Training loss: 0.86675178, Validation loss: 0.87884775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20909.8203125MB; mem (CPU total)=39973.6171875MB
INFO:root:[   59] Training loss: 0.86576882, Validation loss: 0.87933130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20947.91796875MB; mem (CPU total)=40050.171875MB
INFO:root:[   60] Training loss: 0.86503980, Validation loss: 0.87901686, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20986.01171875MB; mem (CPU total)=40126.65234375MB
INFO:root:[   61] Training loss: 0.86452384, Validation loss: 0.87778179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21024.10546875MB; mem (CPU total)=40203.20703125MB
INFO:root:[   62] Training loss: 0.86368150, Validation loss: 0.87774633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21062.20703125MB; mem (CPU total)=40279.25MB
INFO:root:[   63] Training loss: 0.86301251, Validation loss: 0.87838157, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21100.30078125MB; mem (CPU total)=40355.4140625MB
INFO:root:[   64] Training loss: 0.86256231, Validation loss: 0.87870068, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21138.39453125MB; mem (CPU total)=40493.71484375MB
INFO:root:[   65] Training loss: 0.86247097, Validation loss: 0.87790338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21176.48828125MB; mem (CPU total)=40541.21484375MB
INFO:root:[   66] Training loss: 0.86152099, Validation loss: 0.87797960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21214.5859375MB; mem (CPU total)=40589.22265625MB
INFO:root:[   67] Training loss: 0.86079101, Validation loss: 0.87685326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21252.6796875MB; mem (CPU total)=40636.0MB
INFO:root:[   68] Training loss: 0.86002886, Validation loss: 0.87753453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21290.7734375MB; mem (CPU total)=40683.515625MB
INFO:root:[   69] Training loss: 0.85948237, Validation loss: 0.87870725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21328.87109375MB; mem (CPU total)=40666.41015625MB
INFO:root:[   70] Training loss: 0.85944039, Validation loss: 0.87774549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21366.96875MB; mem (CPU total)=40742.7734375MB
INFO:root:[   71] Training loss: 0.85859565, Validation loss: 0.87781608, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21405.0625MB; mem (CPU total)=40819.1015625MB
INFO:root:[   72] Training loss: 0.85762848, Validation loss: 0.87649626, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21443.16015625MB; mem (CPU total)=40895.3828125MB
INFO:root:[   73] Training loss: 0.85674539, Validation loss: 0.87655077, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21481.25390625MB; mem (CPU total)=40971.72265625MB
INFO:root:[   74] Training loss: 0.85693028, Validation loss: 0.87770061, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21519.34765625MB; mem (CPU total)=41048.2734375MB
INFO:root:[   75] Training loss: 0.85614284, Validation loss: 0.87719523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21557.44140625MB; mem (CPU total)=41124.52734375MB
INFO:root:[   76] Training loss: 0.85572940, Validation loss: 0.87794387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21595.54296875MB; mem (CPU total)=41200.87109375MB
INFO:root:[   77] Training loss: 0.85491655, Validation loss: 0.87743870, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21633.6328125MB; mem (CPU total)=41277.64453125MB
INFO:root:[   78] Training loss: 0.85436229, Validation loss: 0.87707169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21671.73046875MB; mem (CPU total)=41353.80859375MB
INFO:root:[   79] Training loss: 0.85407248, Validation loss: 0.87719006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21709.828125MB; mem (CPU total)=41429.87109375MB
INFO:root:[   80] Training loss: 0.85336909, Validation loss: 0.87777661, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21747.921875MB; mem (CPU total)=41506.3984375MB
INFO:root:[   81] Training loss: 0.85314600, Validation loss: 0.87706611, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21786.015625MB; mem (CPU total)=41582.4921875MB
INFO:root:EP 81: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=21823.890625MB; mem (CPU total)=41645.75MB
INFO:root:Training the model took 4485.113s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85653
INFO:root:EnergyScoreTrain: 0.70693
INFO:root:CRPSTrain: 0.58189
INFO:root:Gaussian NLLTrain: 675.08504
INFO:root:CoverageTrain: 0.20705
INFO:root:IntervalWidthTrain: 0.33625
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88906
INFO:root:EnergyScoreValidation: 0.73886
INFO:root:CRPSValidation: 0.60825
INFO:root:Gaussian NLLValidation: 580.62843
INFO:root:CoverageValidation: 0.19817
INFO:root:IntervalWidthValidation: 0.33632
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89117
INFO:root:EnergyScoreTest: 0.73863
INFO:root:CRPSTest: 0.60914
INFO:root:Gaussian NLLTest: 1255.37375
INFO:root:CoverageTest: 0.1999
INFO:root:IntervalWidthTest: 0.34176
INFO:root:After validation: mem (CPU python)=21897.73046875MB; mem (CPU total)=41800.69921875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=21897.73046875MB; mem (CPU total)=41809.07421875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 190840832
INFO:root:After setting up the model: mem (CPU python)=21898.12890625MB; mem (CPU total)=41809.07421875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=21898.1796875MB; mem (CPU total)=41829.75390625MB
INFO:root:[    1] Training loss: 1.02141026, Validation loss: 1.01745758, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21936.21875MB; mem (CPU total)=41906.91796875MB
INFO:root:[    2] Training loss: 1.01615352, Validation loss: 1.01352287, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21974.31640625MB; mem (CPU total)=41982.25MB
INFO:root:[    3] Training loss: 1.00651743, Validation loss: 0.99692316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22012.4140625MB; mem (CPU total)=42058.55078125MB
INFO:root:[    4] Training loss: 0.98827200, Validation loss: 0.97762403, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22050.5078125MB; mem (CPU total)=42134.296875MB
INFO:root:[    5] Training loss: 0.97203295, Validation loss: 0.96358194, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22088.6015625MB; mem (CPU total)=42209.8515625MB
INFO:root:[    6] Training loss: 0.95935093, Validation loss: 0.95051781, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22126.69921875MB; mem (CPU total)=42285.99609375MB
INFO:root:[    7] Training loss: 0.94855814, Validation loss: 0.94079729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22164.79296875MB; mem (CPU total)=42361.69140625MB
INFO:root:[    8] Training loss: 0.94000612, Validation loss: 0.93400085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22202.890625MB; mem (CPU total)=42437.51171875MB
INFO:root:[    9] Training loss: 0.93337202, Validation loss: 0.92815726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22240.984375MB; mem (CPU total)=42512.65625MB
INFO:root:[   10] Training loss: 0.92822143, Validation loss: 0.92338041, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22279.08203125MB; mem (CPU total)=42588.453125MB
INFO:root:[   11] Training loss: 0.92343739, Validation loss: 0.91840555, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22317.17578125MB; mem (CPU total)=42664.98828125MB
INFO:root:[   12] Training loss: 0.91957701, Validation loss: 0.91527372, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22355.26953125MB; mem (CPU total)=42740.4453125MB
INFO:root:[   13] Training loss: 0.91636545, Validation loss: 0.91149311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22393.36328125MB; mem (CPU total)=42815.87890625MB
INFO:root:[   14] Training loss: 0.91299887, Validation loss: 0.90867225, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22431.4609375MB; mem (CPU total)=42892.21484375MB
INFO:root:[   15] Training loss: 0.91007690, Validation loss: 0.90649334, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22469.5546875MB; mem (CPU total)=42967.79296875MB
INFO:root:[   16] Training loss: 0.90736739, Validation loss: 0.90359591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22507.6484375MB; mem (CPU total)=43043.34375MB
INFO:root:[   17] Training loss: 0.90497920, Validation loss: 0.90108714, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22545.74609375MB; mem (CPU total)=43118.59765625MB
INFO:root:[   18] Training loss: 0.90243621, Validation loss: 0.90117777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22583.84375MB; mem (CPU total)=43193.625MB
INFO:root:[   19] Training loss: 0.90040288, Validation loss: 0.89745925, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22621.9375MB; mem (CPU total)=43270.16015625MB
INFO:root:[   20] Training loss: 0.89815953, Validation loss: 0.89645131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22660.03515625MB; mem (CPU total)=43345.6796875MB
INFO:root:[   21] Training loss: 0.89619408, Validation loss: 0.89419073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22698.12890625MB; mem (CPU total)=43421.72265625MB
INFO:root:[   22] Training loss: 0.89460236, Validation loss: 0.89336935, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22736.22265625MB; mem (CPU total)=43498.25390625MB
INFO:root:[   23] Training loss: 0.89295425, Validation loss: 0.89270172, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22774.31640625MB; mem (CPU total)=43573.42578125MB
INFO:root:[   24] Training loss: 0.89083934, Validation loss: 0.89107164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22812.4140625MB; mem (CPU total)=43649.4375MB
INFO:root:[   25] Training loss: 0.88937992, Validation loss: 0.88949089, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22850.5078125MB; mem (CPU total)=43724.953125MB
INFO:root:[   26] Training loss: 0.88791946, Validation loss: 0.88822676, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22888.60546875MB; mem (CPU total)=43799.921875MB
INFO:root:[   27] Training loss: 0.88668514, Validation loss: 0.88674241, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22926.703125MB; mem (CPU total)=43876.49609375MB
INFO:root:[   28] Training loss: 0.88491903, Validation loss: 0.88553600, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22964.796875MB; mem (CPU total)=43952.29296875MB
INFO:root:[   29] Training loss: 0.88345627, Validation loss: 0.88520117, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23002.890625MB; mem (CPU total)=44027.734375MB
INFO:root:[   30] Training loss: 0.88252116, Validation loss: 0.88404554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23040.984375MB; mem (CPU total)=44104.26953125MB
INFO:root:[   31] Training loss: 0.88095072, Validation loss: 0.88281370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23079.08203125MB; mem (CPU total)=44180.06640625MB
INFO:root:[   32] Training loss: 0.87967123, Validation loss: 0.88137996, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23117.17578125MB; mem (CPU total)=44255.30859375MB
INFO:root:[   33] Training loss: 0.87855375, Validation loss: 0.88184398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23155.26953125MB; mem (CPU total)=44331.6953125MB
INFO:root:[   34] Training loss: 0.87755155, Validation loss: 0.88069892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23193.3671875MB; mem (CPU total)=44408.90625MB
INFO:root:[   35] Training loss: 0.87615283, Validation loss: 0.88060360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23231.46484375MB; mem (CPU total)=44484.72265625MB
INFO:root:[   36] Training loss: 0.87505530, Validation loss: 0.87903200, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23269.55859375MB; mem (CPU total)=44561.28125MB
INFO:root:[   37] Training loss: 0.87385981, Validation loss: 0.87874325, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23307.65625MB; mem (CPU total)=44636.375MB
INFO:root:[   38] Training loss: 0.87290947, Validation loss: 0.87745021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23345.75MB; mem (CPU total)=44712.44140625MB
INFO:root:[   39] Training loss: 0.87158510, Validation loss: 0.87777364, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23383.84375MB; mem (CPU total)=44788.19140625MB
INFO:root:[   40] Training loss: 0.87062891, Validation loss: 0.87640370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23421.9375MB; mem (CPU total)=44864.0078125MB
INFO:root:[   41] Training loss: 0.87014970, Validation loss: 0.87598946, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23460.03515625MB; mem (CPU total)=44940.56640625MB
INFO:root:[   42] Training loss: 0.86847973, Validation loss: 0.87562902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23498.12890625MB; mem (CPU total)=45016.91015625MB
INFO:root:[   43] Training loss: 0.86759714, Validation loss: 0.87550848, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23536.2265625MB; mem (CPU total)=45093.49609375MB
INFO:root:[   44] Training loss: 0.86703478, Validation loss: 0.87474155, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23574.32421875MB; mem (CPU total)=45169.5234375MB
INFO:root:[   45] Training loss: 0.86558022, Validation loss: 0.87522868, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23612.41796875MB; mem (CPU total)=45245.6640625MB
INFO:root:[   46] Training loss: 0.86532173, Validation loss: 0.87324366, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23650.51171875MB; mem (CPU total)=45322.43359375MB
INFO:root:[   47] Training loss: 0.86374019, Validation loss: 0.87315448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23688.60546875MB; mem (CPU total)=45398.5MB
INFO:root:[   48] Training loss: 0.86308145, Validation loss: 0.87248792, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23726.703125MB; mem (CPU total)=45474.98046875MB
INFO:root:[   49] Training loss: 0.86239977, Validation loss: 0.87303050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23764.796875MB; mem (CPU total)=45551.46484375MB
INFO:root:[   50] Training loss: 0.86161977, Validation loss: 0.87243347, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23802.89453125MB; mem (CPU total)=45627.31640625MB
INFO:root:[   51] Training loss: 0.86058480, Validation loss: 0.87212858, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23840.9921875MB; mem (CPU total)=45704.12109375MB
INFO:root:[   52] Training loss: 0.85945065, Validation loss: 0.87150594, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23879.0859375MB; mem (CPU total)=45780.1875MB
INFO:root:[   53] Training loss: 0.85911632, Validation loss: 0.87023294, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23917.1796875MB; mem (CPU total)=45856.28125MB
INFO:root:[   54] Training loss: 0.85826745, Validation loss: 0.87071618, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23955.27734375MB; mem (CPU total)=45933.16015625MB
INFO:root:[   55] Training loss: 0.85751253, Validation loss: 0.87104603, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23993.37109375MB; mem (CPU total)=46008.97265625MB
INFO:root:[   56] Training loss: 0.85628931, Validation loss: 0.87108004, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24031.46484375MB; mem (CPU total)=46085.25390625MB
INFO:root:[   57] Training loss: 0.85565879, Validation loss: 0.87033771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24069.55859375MB; mem (CPU total)=46161.80078125MB
INFO:root:[   58] Training loss: 0.85520464, Validation loss: 0.87005741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24107.65625MB; mem (CPU total)=46238.18359375MB
INFO:root:[   59] Training loss: 0.85393694, Validation loss: 0.86991269, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24145.75MB; mem (CPU total)=46314.48828125MB
INFO:root:[   60] Training loss: 0.85354805, Validation loss: 0.87038908, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24183.84765625MB; mem (CPU total)=46391.015625MB
INFO:root:[   61] Training loss: 0.85291290, Validation loss: 0.86946021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24221.9453125MB; mem (CPU total)=46466.84765625MB
INFO:root:[   62] Training loss: 0.85184768, Validation loss: 0.86980324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24260.0390625MB; mem (CPU total)=46543.16015625MB
INFO:root:[   63] Training loss: 0.85115730, Validation loss: 0.86983859, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24298.1328125MB; mem (CPU total)=46620.99609375MB
INFO:root:[   64] Training loss: 0.85060066, Validation loss: 0.86886869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24336.2265625MB; mem (CPU total)=46698.6640625MB
INFO:root:[   65] Training loss: 0.84999898, Validation loss: 0.87276346, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24374.32421875MB; mem (CPU total)=46775.4140625MB
INFO:root:[   66] Training loss: 0.84916782, Validation loss: 0.87014472, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24412.41796875MB; mem (CPU total)=46852.70703125MB
INFO:root:[   67] Training loss: 0.84869699, Validation loss: 0.86917523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24450.515625MB; mem (CPU total)=46930.0MB
INFO:root:[   68] Training loss: 0.84791297, Validation loss: 0.86885105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24488.61328125MB; mem (CPU total)=47007.05859375MB
INFO:root:[   69] Training loss: 0.84724510, Validation loss: 0.86829177, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24526.70703125MB; mem (CPU total)=47084.23828125MB
INFO:root:[   70] Training loss: 0.84664666, Validation loss: 0.86837851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24564.80078125MB; mem (CPU total)=47161.09765625MB
INFO:root:[   71] Training loss: 0.84620632, Validation loss: 0.86945713, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24602.8984375MB; mem (CPU total)=47238.36328125MB
INFO:root:[   72] Training loss: 0.84529791, Validation loss: 0.86953227, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24640.9921875MB; mem (CPU total)=47315.90625MB
INFO:root:[   73] Training loss: 0.84484188, Validation loss: 0.86978531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24679.0859375MB; mem (CPU total)=47394.609375MB
INFO:root:[   74] Training loss: 0.84408202, Validation loss: 0.86950972, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24717.18359375MB; mem (CPU total)=47472.23046875MB
INFO:root:[   75] Training loss: 0.84334360, Validation loss: 0.86796052, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24755.28125MB; mem (CPU total)=47550.80859375MB
INFO:root:[   76] Training loss: 0.84279887, Validation loss: 0.87005155, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24793.37109375MB; mem (CPU total)=47629.10546875MB
INFO:root:[   77] Training loss: 0.84222448, Validation loss: 0.87077018, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24831.46484375MB; mem (CPU total)=47706.89453125MB
INFO:root:[   78] Training loss: 0.84149936, Validation loss: 0.86883596, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24869.56640625MB; mem (CPU total)=47785.421875MB
INFO:root:[   79] Training loss: 0.84106651, Validation loss: 0.86959553, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24907.66015625MB; mem (CPU total)=47863.45703125MB
INFO:root:[   80] Training loss: 0.84046250, Validation loss: 0.86904080, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24945.75390625MB; mem (CPU total)=47942.19140625MB
INFO:root:[   81] Training loss: 0.83994338, Validation loss: 0.86934376, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24983.84765625MB; mem (CPU total)=48020.640625MB
INFO:root:[   82] Training loss: 0.83946163, Validation loss: 0.86835169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25021.9453125MB; mem (CPU total)=48098.90625MB
INFO:root:[   83] Training loss: 0.83870636, Validation loss: 0.86978107, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25060.0390625MB; mem (CPU total)=48177.74609375MB
INFO:root:[   84] Training loss: 0.83825471, Validation loss: 0.86940648, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25098.13671875MB; mem (CPU total)=48256.140625MB
INFO:root:EP 84: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=25136.21484375MB; mem (CPU total)=48300.2890625MB
INFO:root:Training the model took 4948.001s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84179
INFO:root:EnergyScoreTrain: 0.69103
INFO:root:CRPSTrain: 0.56439
INFO:root:Gaussian NLLTrain: 760.59944
INFO:root:CoverageTrain: 0.21794
INFO:root:IntervalWidthTrain: 0.34651
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88128
INFO:root:EnergyScoreValidation: 0.72954
INFO:root:CRPSValidation: 0.59591
INFO:root:Gaussian NLLValidation: 490.39178
INFO:root:CoverageValidation: 0.20789
INFO:root:IntervalWidthValidation: 0.34657
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88177
INFO:root:EnergyScoreTest: 0.7331
INFO:root:CRPSTest: 0.59846
INFO:root:Gaussian NLLTest: 476.57617
INFO:root:CoverageTest: 0.2043
INFO:root:IntervalWidthTest: 0.33589
INFO:root:After validation: mem (CPU python)=25209.81640625MB; mem (CPU total)=48449.58984375MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=25209.81640625MB; mem (CPU total)=48483.953125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 190840832
INFO:root:After setting up the model: mem (CPU python)=25210.20703125MB; mem (CPU total)=48484.0546875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=25210.234375MB; mem (CPU total)=48488.2109375MB
INFO:root:[    1] Training loss: 1.02212682, Validation loss: 1.01822562, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25248.3046875MB; mem (CPU total)=48564.859375MB
INFO:root:[    2] Training loss: 1.01671808, Validation loss: 1.01530865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25286.40234375MB; mem (CPU total)=48641.4140625MB
INFO:root:[    3] Training loss: 1.01161686, Validation loss: 1.00368029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25324.5MB; mem (CPU total)=48718.1640625MB
INFO:root:[    4] Training loss: 0.99559786, Validation loss: 0.98800512, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25362.59375MB; mem (CPU total)=48795.953125MB
INFO:root:[    5] Training loss: 0.98386070, Validation loss: 0.97914500, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25400.6875MB; mem (CPU total)=48873.98828125MB
INFO:root:[    6] Training loss: 0.97442703, Validation loss: 0.96889591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25438.78125MB; mem (CPU total)=48951.484375MB
INFO:root:[    7] Training loss: 0.96541330, Validation loss: 0.96008561, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25476.87890625MB; mem (CPU total)=49028.3125MB
INFO:root:[    8] Training loss: 0.95746459, Validation loss: 0.95253861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25514.97265625MB; mem (CPU total)=49106.39453125MB
INFO:root:[    9] Training loss: 0.95100448, Validation loss: 0.94845797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25553.06640625MB; mem (CPU total)=49184.4609375MB
INFO:root:[   10] Training loss: 0.94537680, Validation loss: 0.94096932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25591.1640625MB; mem (CPU total)=49262.28125MB
INFO:root:[   11] Training loss: 0.93995677, Validation loss: 0.93747076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25629.26171875MB; mem (CPU total)=49340.5625MB
INFO:root:[   12] Training loss: 0.93561439, Validation loss: 0.93236661, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25667.35546875MB; mem (CPU total)=49418.31640625MB
INFO:root:[   13] Training loss: 0.93133064, Validation loss: 0.92723834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25705.453125MB; mem (CPU total)=49496.10546875MB
INFO:root:[   14] Training loss: 0.92779821, Validation loss: 0.92482876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25743.546875MB; mem (CPU total)=49574.30078125MB
INFO:root:[   15] Training loss: 0.92443819, Validation loss: 0.92147578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25781.640625MB; mem (CPU total)=49652.08984375MB
INFO:root:[   16] Training loss: 0.92122399, Validation loss: 0.91842935, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25819.734375MB; mem (CPU total)=49730.265625MB
INFO:root:[   17] Training loss: 0.91849622, Validation loss: 0.91699960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25857.83203125MB; mem (CPU total)=49853.53125MB
INFO:root:[   18] Training loss: 0.91596664, Validation loss: 0.91325503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25895.9296875MB; mem (CPU total)=49901.54296875MB
INFO:root:[   19] Training loss: 0.91368577, Validation loss: 0.91192888, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25934.0234375MB; mem (CPU total)=49950.29296875MB
INFO:root:[   20] Training loss: 0.91146154, Validation loss: 0.90868232, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25972.12109375MB; mem (CPU total)=49998.484375MB
INFO:root:[   21] Training loss: 0.90932153, Validation loss: 0.90797978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26010.21875MB; mem (CPU total)=49981.3359375MB
INFO:root:[   22] Training loss: 0.90753723, Validation loss: 0.90746094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26048.3125MB; mem (CPU total)=50057.953125MB
INFO:root:[   23] Training loss: 0.90532572, Validation loss: 0.90530664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26086.40625MB; mem (CPU total)=50133.8359375MB
INFO:root:[   24] Training loss: 0.90363882, Validation loss: 0.90445047, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26124.50390625MB; mem (CPU total)=50210.671875MB
INFO:root:[   25] Training loss: 0.90201690, Validation loss: 0.90202950, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26162.59765625MB; mem (CPU total)=50287.515625MB
INFO:root:[   26] Training loss: 0.90030787, Validation loss: 0.89991589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26200.69140625MB; mem (CPU total)=50363.8046875MB
INFO:root:[   27] Training loss: 0.89901223, Validation loss: 0.89932965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26238.79296875MB; mem (CPU total)=50440.578125MB
INFO:root:[   28] Training loss: 0.89713037, Validation loss: 0.89919756, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26276.88671875MB; mem (CPU total)=50516.01953125MB
INFO:root:[   29] Training loss: 0.89614040, Validation loss: 0.89710463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26314.98046875MB; mem (CPU total)=50592.24609375MB
INFO:root:[   30] Training loss: 0.89459108, Validation loss: 0.89670158, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26353.078125MB; mem (CPU total)=50668.86328125MB
INFO:root:[   31] Training loss: 0.89309638, Validation loss: 0.89570211, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26391.171875MB; mem (CPU total)=50745.9140625MB
INFO:root:[   32] Training loss: 0.89163863, Validation loss: 0.89428113, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26429.265625MB; mem (CPU total)=50825.42578125MB
INFO:root:[   33] Training loss: 0.89051165, Validation loss: 0.89451234, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26467.359375MB; mem (CPU total)=50904.17578125MB
INFO:root:[   34] Training loss: 0.88920237, Validation loss: 0.89225651, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26505.4609375MB; mem (CPU total)=50983.6875MB
INFO:root:[   35] Training loss: 0.88803437, Validation loss: 0.89334528, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26543.55078125MB; mem (CPU total)=51062.34765625MB
INFO:root:[   36] Training loss: 0.88690619, Validation loss: 0.89208622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26581.6484375MB; mem (CPU total)=51141.0703125MB
INFO:root:[   37] Training loss: 0.88584524, Validation loss: 0.89291461, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26619.74609375MB; mem (CPU total)=51220.2734375MB
INFO:root:[   38] Training loss: 0.88458431, Validation loss: 0.88988225, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26657.83984375MB; mem (CPU total)=51300.02734375MB
INFO:root:[   39] Training loss: 0.88361503, Validation loss: 0.88998462, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26695.93359375MB; mem (CPU total)=51380.0546875MB
INFO:root:[   40] Training loss: 0.88277228, Validation loss: 0.88871637, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26734.02734375MB; mem (CPU total)=51460.36328125MB
INFO:root:[   41] Training loss: 0.88150071, Validation loss: 0.88784379, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26772.125MB; mem (CPU total)=51540.890625MB
INFO:root:[   42] Training loss: 0.88072336, Validation loss: 0.88795451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26810.21875MB; mem (CPU total)=51622.484375MB
INFO:root:[   43] Training loss: 0.87948558, Validation loss: 0.88742867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26848.31640625MB; mem (CPU total)=51699.8828125MB
INFO:root:[   44] Training loss: 0.87871927, Validation loss: 0.88648316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26886.41015625MB; mem (CPU total)=51776.203125MB
INFO:root:[   45] Training loss: 0.87778127, Validation loss: 0.88830887, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26924.5078125MB; mem (CPU total)=51852.40625MB
INFO:root:[   46] Training loss: 0.87711149, Validation loss: 0.88601766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26962.6015625MB; mem (CPU total)=51928.87890625MB
INFO:root:[   47] Training loss: 0.87597282, Validation loss: 0.88597811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27000.69921875MB; mem (CPU total)=52004.921875MB
INFO:root:[   48] Training loss: 0.87523067, Validation loss: 0.88481819, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27038.79296875MB; mem (CPU total)=52081.078125MB
INFO:root:[   49] Training loss: 0.87439492, Validation loss: 0.88448075, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27076.88671875MB; mem (CPU total)=52157.68359375MB
INFO:root:[   50] Training loss: 0.87373529, Validation loss: 0.88410080, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27114.98046875MB; mem (CPU total)=52234.21875MB
INFO:root:[   51] Training loss: 0.87308338, Validation loss: 0.88273864, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27153.08203125MB; mem (CPU total)=52310.5390625MB
INFO:root:[   52] Training loss: 0.87199626, Validation loss: 0.88336497, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27191.17578125MB; mem (CPU total)=52388.765625MB
INFO:root:[   53] Training loss: 0.87129037, Validation loss: 0.88459231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27229.26953125MB; mem (CPU total)=52468.9609375MB
INFO:root:[   54] Training loss: 0.87015207, Validation loss: 0.88277153, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27267.3671875MB; mem (CPU total)=52550.59375MB
INFO:root:[   55] Training loss: 0.86972045, Validation loss: 0.88430522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27305.4609375MB; mem (CPU total)=52630.45703125MB
INFO:root:[   56] Training loss: 0.86897677, Validation loss: 0.88313215, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27343.5546875MB; mem (CPU total)=52710.65234375MB
INFO:root:[   57] Training loss: 0.86817358, Validation loss: 0.88292394, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27381.6484375MB; mem (CPU total)=52790.30078125MB
INFO:root:[   58] Training loss: 0.86736553, Validation loss: 0.88190816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27419.74609375MB; mem (CPU total)=52871.08203125MB
INFO:root:[   59] Training loss: 0.86672804, Validation loss: 0.88213893, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27457.83984375MB; mem (CPU total)=52951.09375MB
INFO:root:[   60] Training loss: 0.86622798, Validation loss: 0.88269842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27495.9375MB; mem (CPU total)=53031.0859375MB
INFO:root:[   61] Training loss: 0.86537707, Validation loss: 0.88200176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27534.03515625MB; mem (CPU total)=53111.80078125MB
INFO:root:[   62] Training loss: 0.86492745, Validation loss: 0.88269348, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27572.12890625MB; mem (CPU total)=53188.3359375MB
INFO:root:[   63] Training loss: 0.86450532, Validation loss: 0.88292197, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27610.22265625MB; mem (CPU total)=53264.421875MB
INFO:root:[   64] Training loss: 0.86372944, Validation loss: 0.88147514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27648.3203125MB; mem (CPU total)=53341.2421875MB
INFO:root:[   65] Training loss: 0.86288263, Validation loss: 0.88215189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27686.4140625MB; mem (CPU total)=53417.53125MB
INFO:root:[   66] Training loss: 0.86242352, Validation loss: 0.88286391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27724.5078125MB; mem (CPU total)=53493.8203125MB
INFO:root:[   67] Training loss: 0.86158500, Validation loss: 0.88309502, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27762.6015625MB; mem (CPU total)=53570.109375MB
INFO:root:[   68] Training loss: 0.86143116, Validation loss: 0.88312187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27800.703125MB; mem (CPU total)=53646.26171875MB
INFO:root:[   69] Training loss: 0.86078322, Validation loss: 0.88268482, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27838.796875MB; mem (CPU total)=53722.765625MB
INFO:root:[   70] Training loss: 0.85982523, Validation loss: 0.88238121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27876.890625MB; mem (CPU total)=53799.34765625MB
INFO:root:[   71] Training loss: 0.85929663, Validation loss: 0.88191154, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27914.98828125MB; mem (CPU total)=53877.57421875MB
INFO:root:[   72] Training loss: 0.85891000, Validation loss: 0.88214744, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27953.08203125MB; mem (CPU total)=53958.0625MB
INFO:root:[   73] Training loss: 0.85877951, Validation loss: 0.88072315, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27991.17578125MB; mem (CPU total)=54038.16796875MB
INFO:root:[   74] Training loss: 0.85772435, Validation loss: 0.88192169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28029.26953125MB; mem (CPU total)=54118.1171875MB
INFO:root:[   75] Training loss: 0.85728733, Validation loss: 0.88195380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28067.3671875MB; mem (CPU total)=54198.34375MB
INFO:root:[   76] Training loss: 0.85656258, Validation loss: 0.88273635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28105.46484375MB; mem (CPU total)=54278.6015625MB
INFO:root:[   77] Training loss: 0.85626315, Validation loss: 0.88311272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28143.55859375MB; mem (CPU total)=54359.62109375MB
INFO:root:[   78] Training loss: 0.85538320, Validation loss: 0.88343776, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28181.65625MB; mem (CPU total)=54439.78515625MB
INFO:root:[   79] Training loss: 0.85481092, Validation loss: 0.88308365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28219.75MB; mem (CPU total)=54520.50390625MB
INFO:root:[   80] Training loss: 0.85432445, Validation loss: 0.88235498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28257.84375MB; mem (CPU total)=54600.765625MB
INFO:root:[   81] Training loss: 0.85390507, Validation loss: 0.88297584, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28295.94140625MB; mem (CPU total)=54677.32421875MB
INFO:root:[   82] Training loss: 0.85339523, Validation loss: 0.88399840, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28334.03515625MB; mem (CPU total)=54753.66015625MB
INFO:root:EP 82: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=28372.1328125MB; mem (CPU total)=54800.43359375MB
INFO:root:Training the model took 5273.052s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86031
INFO:root:EnergyScoreTrain: 0.70038
INFO:root:CRPSTrain: 0.58306
INFO:root:Gaussian NLLTrain: 592.97618
INFO:root:CoverageTrain: 0.21218
INFO:root:IntervalWidthTrain: 0.36076
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89596
INFO:root:EnergyScoreValidation: 0.73453
INFO:root:CRPSValidation: 0.61079
INFO:root:Gaussian NLLValidation: 595.29401
INFO:root:CoverageValidation: 0.20377
INFO:root:IntervalWidthValidation: 0.3638
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89741
INFO:root:EnergyScoreTest: 0.7362
INFO:root:CRPSTest: 0.61287
INFO:root:Gaussian NLLTest: 546.92318
INFO:root:CoverageTest: 0.20233
INFO:root:IntervalWidthTest: 0.36313
INFO:root:After validation: mem (CPU python)=28445.671875MB; mem (CPU total)=54941.625MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=28445.671875MB; mem (CPU total)=54979.78515625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 190840832
INFO:root:After setting up the model: mem (CPU python)=28445.96875MB; mem (CPU total)=54980.27734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=28446.09765625MB; mem (CPU total)=54985.69140625MB
INFO:root:[    1] Training loss: 1.02207896, Validation loss: 1.01791128, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28484.18359375MB; mem (CPU total)=55064.06640625MB
INFO:root:[    2] Training loss: 1.01604121, Validation loss: 1.01259462, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28522.27734375MB; mem (CPU total)=55143.046875MB
INFO:root:[    3] Training loss: 1.00384840, Validation loss: 0.99377634, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28560.37109375MB; mem (CPU total)=55222.05078125MB
INFO:root:[    4] Training loss: 0.98703374, Validation loss: 0.97796040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28598.46484375MB; mem (CPU total)=55301.77734375MB
INFO:root:[    5] Training loss: 0.97220608, Validation loss: 0.96318521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28636.56640625MB; mem (CPU total)=55381.1015625MB
INFO:root:[    6] Training loss: 0.95966441, Validation loss: 0.95086245, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28674.66015625MB; mem (CPU total)=55459.51171875MB
INFO:root:[    7] Training loss: 0.94977353, Validation loss: 0.94305356, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28712.75390625MB; mem (CPU total)=55540.04296875MB
INFO:root:[    8] Training loss: 0.94201033, Validation loss: 0.93603038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28750.8515625MB; mem (CPU total)=55620.25390625MB
INFO:root:[    9] Training loss: 0.93571012, Validation loss: 0.93020659, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28788.9453125MB; mem (CPU total)=55700.5625MB
INFO:root:[   10] Training loss: 0.93041923, Validation loss: 0.92526966, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28827.0390625MB; mem (CPU total)=55779.3984375MB
INFO:root:[   11] Training loss: 0.92564052, Validation loss: 0.92041125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28865.1328125MB; mem (CPU total)=55857.6875MB
INFO:root:[   12] Training loss: 0.92161481, Validation loss: 0.91751247, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28903.23046875MB; mem (CPU total)=55934.19140625MB
INFO:root:[   13] Training loss: 0.91818321, Validation loss: 0.91237962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28941.32421875MB; mem (CPU total)=56010.234375MB
INFO:root:[   14] Training loss: 0.91487205, Validation loss: 0.91041501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28979.421875MB; mem (CPU total)=56087.265625MB
INFO:root:[   15] Training loss: 0.91198508, Validation loss: 0.90882260, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29017.51953125MB; mem (CPU total)=56163.41796875MB
INFO:root:[   16] Training loss: 0.90952403, Validation loss: 0.90574020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29055.61328125MB; mem (CPU total)=56239.35546875MB
INFO:root:[   17] Training loss: 0.90695317, Validation loss: 0.90367299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29093.70703125MB; mem (CPU total)=56316.16796875MB
INFO:root:[   18] Training loss: 0.90428001, Validation loss: 0.90258570, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29131.8046875MB; mem (CPU total)=56392.4140625MB
INFO:root:[   19] Training loss: 0.90242667, Validation loss: 0.89952431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29169.8984375MB; mem (CPU total)=56468.71875MB
INFO:root:[   20] Training loss: 0.90041716, Validation loss: 0.89758223, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29207.9921875MB; mem (CPU total)=56545.0390625MB
INFO:root:[   21] Training loss: 0.89806289, Validation loss: 0.89665082, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29246.0859375MB; mem (CPU total)=56621.08203125MB
INFO:root:[   22] Training loss: 0.89621965, Validation loss: 0.89466964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29284.1875MB; mem (CPU total)=56697.859375MB
INFO:root:[   23] Training loss: 0.89427185, Validation loss: 0.89183612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29322.28125MB; mem (CPU total)=56775.03515625MB
INFO:root:[   24] Training loss: 0.89262037, Validation loss: 0.89031723, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29360.375MB; mem (CPU total)=56854.53125MB
INFO:root:[   25] Training loss: 0.89118251, Validation loss: 0.88931483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29398.47265625MB; mem (CPU total)=56934.9296875MB
INFO:root:[   26] Training loss: 0.88966919, Validation loss: 0.88826829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29436.56640625MB; mem (CPU total)=57014.7265625MB
INFO:root:[   27] Training loss: 0.88791884, Validation loss: 0.88770706, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29474.66015625MB; mem (CPU total)=57094.12109375MB
INFO:root:[   28] Training loss: 0.88653871, Validation loss: 0.88612872, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29512.75390625MB; mem (CPU total)=57173.359375MB
INFO:root:[   29] Training loss: 0.88534114, Validation loss: 0.88565775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29550.85546875MB; mem (CPU total)=57252.09375MB
INFO:root:[   30] Training loss: 0.88383099, Validation loss: 0.88453231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29588.94921875MB; mem (CPU total)=57331.55078125MB
INFO:root:[   31] Training loss: 0.88264009, Validation loss: 0.88434858, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29627.04296875MB; mem (CPU total)=57410.33203125MB
INFO:root:[   32] Training loss: 0.88128031, Validation loss: 0.88326144, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29665.140625MB; mem (CPU total)=57489.62890625MB
INFO:root:[   33] Training loss: 0.87996459, Validation loss: 0.88173348, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29703.234375MB; mem (CPU total)=57569.6875MB
INFO:root:[   34] Training loss: 0.87872695, Validation loss: 0.88017322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29741.328125MB; mem (CPU total)=57650.40625MB
INFO:root:[   35] Training loss: 0.87774131, Validation loss: 0.88067178, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29779.42578125MB; mem (CPU total)=57728.6484375MB
INFO:root:[   36] Training loss: 0.87664116, Validation loss: 0.87964973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29817.51953125MB; mem (CPU total)=57806.13671875MB
INFO:root:[   37] Training loss: 0.87556873, Validation loss: 0.87824559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29855.6171875MB; mem (CPU total)=57882.62109375MB
INFO:root:[   38] Training loss: 0.87429292, Validation loss: 0.87829730, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29893.7109375MB; mem (CPU total)=57959.15625MB
INFO:root:[   39] Training loss: 0.87347940, Validation loss: 0.87828733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29931.80859375MB; mem (CPU total)=58035.19921875MB
INFO:root:[   40] Training loss: 0.87238496, Validation loss: 0.87551585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29969.90234375MB; mem (CPU total)=58111.98046875MB
INFO:root:[   41] Training loss: 0.87171519, Validation loss: 0.87579652, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30007.99609375MB; mem (CPU total)=58187.5234375MB
INFO:root:[   42] Training loss: 0.87107724, Validation loss: 0.87537103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30046.09375MB; mem (CPU total)=58263.6328125MB
INFO:root:[   43] Training loss: 0.87022448, Validation loss: 0.87496771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30084.1875MB; mem (CPU total)=58340.4453125MB
INFO:root:[   44] Training loss: 0.86877870, Validation loss: 0.87498903, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30122.28125MB; mem (CPU total)=58415.90625MB
INFO:root:[   45] Training loss: 0.86778329, Validation loss: 0.87395098, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30160.375MB; mem (CPU total)=58492.4453125MB
INFO:root:[   46] Training loss: 0.86709925, Validation loss: 0.87407067, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30198.4765625MB; mem (CPU total)=58633.828125MB
INFO:root:[   47] Training loss: 0.86645491, Validation loss: 0.87307366, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30236.5703125MB; mem (CPU total)=58682.98828125MB
INFO:root:[   48] Training loss: 0.86525906, Validation loss: 0.87195420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30274.6640625MB; mem (CPU total)=58732.69921875MB
INFO:root:[   49] Training loss: 0.86471119, Validation loss: 0.87289891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30312.76171875MB; mem (CPU total)=58782.3671875MB
INFO:root:[   50] Training loss: 0.86401015, Validation loss: 0.87231037, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30350.85546875MB; mem (CPU total)=58764.6015625MB
INFO:root:[   51] Training loss: 0.86312155, Validation loss: 0.87289654, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30388.94921875MB; mem (CPU total)=58840.72265625MB
INFO:root:[   52] Training loss: 0.86226898, Validation loss: 0.87158050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30427.046875MB; mem (CPU total)=58917.21875MB
INFO:root:[   53] Training loss: 0.86188840, Validation loss: 0.87170628, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30465.140625MB; mem (CPU total)=58993.5MB
INFO:root:[   54] Training loss: 0.86076469, Validation loss: 0.87025659, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30503.23828125MB; mem (CPU total)=59069.171875MB
INFO:root:[   55] Training loss: 0.86013584, Validation loss: 0.87052734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30541.33203125MB; mem (CPU total)=59145.94140625MB
INFO:root:[   56] Training loss: 0.85972320, Validation loss: 0.87105297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30579.4296875MB; mem (CPU total)=59222.19921875MB
INFO:root:[   57] Training loss: 0.85871126, Validation loss: 0.87027498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30617.5234375MB; mem (CPU total)=59301.93359375MB
INFO:root:[   58] Training loss: 0.85805746, Validation loss: 0.86982940, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30655.6171875MB; mem (CPU total)=59382.578125MB
INFO:root:[   59] Training loss: 0.85720929, Validation loss: 0.87055021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30693.71484375MB; mem (CPU total)=59461.8046875MB
INFO:root:[   60] Training loss: 0.85659877, Validation loss: 0.87014910, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30731.80859375MB; mem (CPU total)=59541.78515625MB
INFO:root:[   61] Training loss: 0.85580474, Validation loss: 0.86950647, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30769.90234375MB; mem (CPU total)=59621.765625MB
INFO:root:[   62] Training loss: 0.85543978, Validation loss: 0.86981416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30807.99609375MB; mem (CPU total)=59701.68359375MB
INFO:root:[   63] Training loss: 0.85451117, Validation loss: 0.87060694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30846.09375MB; mem (CPU total)=59781.4453125MB
INFO:root:[   64] Training loss: 0.85397050, Validation loss: 0.86925007, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30884.19140625MB; mem (CPU total)=59861.703125MB
INFO:root:[   65] Training loss: 0.85319934, Validation loss: 0.86965225, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30922.28515625MB; mem (CPU total)=59942.10546875MB
INFO:root:[   66] Training loss: 0.85246965, Validation loss: 0.86925735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30960.3828125MB; mem (CPU total)=60023.12109375MB
INFO:root:[   67] Training loss: 0.85211001, Validation loss: 0.86959478, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30998.4765625MB; mem (CPU total)=60099.15625MB
INFO:root:[   68] Training loss: 0.85145853, Validation loss: 0.86925170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31036.5703125MB; mem (CPU total)=60175.375MB
INFO:root:[   69] Training loss: 0.85095185, Validation loss: 0.86918597, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31074.671875MB; mem (CPU total)=60251.6171875MB
INFO:root:[   70] Training loss: 0.85043796, Validation loss: 0.86889324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31112.765625MB; mem (CPU total)=60328.18359375MB
INFO:root:[   71] Training loss: 0.84979096, Validation loss: 0.86939103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31150.859375MB; mem (CPU total)=60404.703125MB
INFO:root:[   72] Training loss: 0.84900534, Validation loss: 0.87069719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31188.95703125MB; mem (CPU total)=60480.9921875MB
INFO:root:[   73] Training loss: 0.84886100, Validation loss: 0.86867110, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31227.0546875MB; mem (CPU total)=60556.85546875MB
INFO:root:[   74] Training loss: 0.84791560, Validation loss: 0.86959483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31265.1484375MB; mem (CPU total)=60633.171875MB
INFO:root:[   75] Training loss: 0.84724594, Validation loss: 0.86959176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31303.2421875MB; mem (CPU total)=60709.72265625MB
INFO:root:[   76] Training loss: 0.84710755, Validation loss: 0.86913365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31341.3515625MB; mem (CPU total)=60785.7109375MB
INFO:root:[   77] Training loss: 0.84615598, Validation loss: 0.87029042, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31379.4453125MB; mem (CPU total)=60864.046875MB
INFO:root:[   78] Training loss: 0.84580002, Validation loss: 0.86892622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31417.54296875MB; mem (CPU total)=60944.46875MB
INFO:root:[   79] Training loss: 0.84534846, Validation loss: 0.86903019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31455.63671875MB; mem (CPU total)=61024.015625MB
INFO:root:[   80] Training loss: 0.84434598, Validation loss: 0.87091590, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31493.734375MB; mem (CPU total)=61104.5MB
INFO:root:[   81] Training loss: 0.84385167, Validation loss: 0.86891469, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31531.828125MB; mem (CPU total)=61184.4765625MB
INFO:root:[   82] Training loss: 0.84345642, Validation loss: 0.86939190, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31569.921875MB; mem (CPU total)=61264.9765625MB
INFO:root:EP 82: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=31607.8828125MB; mem (CPU total)=61318.8828125MB
INFO:root:Training the model took 5703.214s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84706
INFO:root:EnergyScoreTrain: 0.70011
INFO:root:CRPSTrain: 0.57607
INFO:root:Gaussian NLLTrain: 892.39109
INFO:root:CoverageTrain: 0.20671
INFO:root:IntervalWidthTrain: 0.32296
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88096
INFO:root:EnergyScoreValidation: 0.73113
INFO:root:CRPSValidation: 0.60287
INFO:root:Gaussian NLLValidation: 35151.15767
INFO:root:CoverageValidation: 0.20041
INFO:root:IntervalWidthValidation: 0.32716
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88156
INFO:root:EnergyScoreTest: 0.73737
INFO:root:CRPSTest: 0.60564
INFO:root:Gaussian NLLTest: 1083.88157
INFO:root:CoverageTest: 0.19411
INFO:root:IntervalWidthTest: 0.31519
INFO:root:After validation: mem (CPU python)=31681.5625MB; mem (CPU total)=61465.66796875MB
