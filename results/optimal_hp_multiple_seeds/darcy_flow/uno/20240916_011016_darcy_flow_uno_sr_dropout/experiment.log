INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=578.25390625MB; mem (CPU total)=1021.61328125MB
INFO:root:############### Starting experiment with config file darcy_flow/uno_sr_dropout.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'DarcyFlow', 'max_training_set_size': 10000, 'downscaling_factor': 2}
INFO:root:After loading the datasets: mem (CPU python)=1998.515625MB; mem (CPU total)=1033.59765625MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=1998.515625MB; mem (CPU total)=1033.59765625MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 44040192
INFO:root:After setting up the model: mem (CPU python)=2220.19921875MB; mem (CPU total)=2412.015625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2220.19921875MB; mem (CPU total)=2419.4921875MB
INFO:root:[    1] Training loss: 0.25296556, Validation loss: 0.17908874, Gradient norm: 1.92355605
INFO:root:At the start of the epoch: mem (CPU python)=4465.9453125MB; mem (CPU total)=4210.58984375MB
INFO:root:[    2] Training loss: 0.16195733, Validation loss: 0.17470795, Gradient norm: 1.87351324
INFO:root:At the start of the epoch: mem (CPU python)=4542.16796875MB; mem (CPU total)=4286.89453125MB
INFO:root:[    3] Training loss: 0.14593040, Validation loss: 0.15433606, Gradient norm: 1.81966337
INFO:root:At the start of the epoch: mem (CPU python)=4618.99609375MB; mem (CPU total)=4364.91796875MB
INFO:root:[    4] Training loss: 0.13354987, Validation loss: 0.14588400, Gradient norm: 1.60719392
INFO:root:At the start of the epoch: mem (CPU python)=4696.05078125MB; mem (CPU total)=4441.13671875MB
INFO:root:[    5] Training loss: 0.13065101, Validation loss: 0.14303716, Gradient norm: 1.64583934
INFO:root:At the start of the epoch: mem (CPU python)=4772.2734375MB; mem (CPU total)=4517.26171875MB
INFO:root:[    6] Training loss: 0.12372005, Validation loss: 0.14670577, Gradient norm: 1.51294841
INFO:root:At the start of the epoch: mem (CPU python)=4848.48828125MB; mem (CPU total)=4594.0390625MB
INFO:root:[    7] Training loss: 0.11812605, Validation loss: 0.14138332, Gradient norm: 1.57614513
INFO:root:At the start of the epoch: mem (CPU python)=4924.7109375MB; mem (CPU total)=4670.94921875MB
INFO:root:[    8] Training loss: 0.11301176, Validation loss: 0.13920053, Gradient norm: 1.34312473
INFO:root:At the start of the epoch: mem (CPU python)=5000.9296875MB; mem (CPU total)=4747.53125MB
INFO:root:[    9] Training loss: 0.10967447, Validation loss: 0.16139909, Gradient norm: 1.25196455
INFO:root:At the start of the epoch: mem (CPU python)=5077.14453125MB; mem (CPU total)=4823.21484375MB
INFO:root:[   10] Training loss: 0.11486601, Validation loss: 0.14448379, Gradient norm: 1.44377459
INFO:root:At the start of the epoch: mem (CPU python)=5153.375MB; mem (CPU total)=4899.98828125MB
INFO:root:[   11] Training loss: 0.10792618, Validation loss: 0.13982188, Gradient norm: 1.31587751
INFO:root:At the start of the epoch: mem (CPU python)=5229.61328125MB; mem (CPU total)=4975.52734375MB
INFO:root:[   12] Training loss: 0.10962756, Validation loss: 0.15494527, Gradient norm: 1.57146832
INFO:root:At the start of the epoch: mem (CPU python)=5305.828125MB; mem (CPU total)=5052.49609375MB
INFO:root:[   13] Training loss: 0.10374216, Validation loss: 0.14693818, Gradient norm: 1.08009288
INFO:root:At the start of the epoch: mem (CPU python)=5382.04296875MB; mem (CPU total)=5128.75390625MB
INFO:root:[   14] Training loss: 0.10605013, Validation loss: 0.16084958, Gradient norm: 1.47959339
INFO:root:At the start of the epoch: mem (CPU python)=5458.25MB; mem (CPU total)=5204.94140625MB
INFO:root:[   15] Training loss: 0.10342174, Validation loss: 0.13620471, Gradient norm: 1.15032890
INFO:root:At the start of the epoch: mem (CPU python)=5534.48828125MB; mem (CPU total)=5280.9296875MB
INFO:root:[   16] Training loss: 0.10209141, Validation loss: 0.13330810, Gradient norm: 1.25197420
INFO:root:At the start of the epoch: mem (CPU python)=5610.71875MB; mem (CPU total)=5357.03125MB
INFO:root:[   17] Training loss: 0.09758758, Validation loss: 0.13452326, Gradient norm: 0.96600574
INFO:root:At the start of the epoch: mem (CPU python)=5686.921875MB; mem (CPU total)=5433.4140625MB
INFO:root:[   18] Training loss: 0.09977566, Validation loss: 0.13889379, Gradient norm: 1.24726948
INFO:root:At the start of the epoch: mem (CPU python)=5763.125MB; mem (CPU total)=5509.2734375MB
INFO:root:[   19] Training loss: 0.10068696, Validation loss: 0.13342666, Gradient norm: 1.47742524
INFO:root:At the start of the epoch: mem (CPU python)=5839.31640625MB; mem (CPU total)=5586.01953125MB
INFO:root:[   20] Training loss: 0.09349054, Validation loss: 0.13263928, Gradient norm: 1.06737593
INFO:root:At the start of the epoch: mem (CPU python)=5915.5234375MB; mem (CPU total)=5662.5MB
INFO:root:[   21] Training loss: 0.09350702, Validation loss: 0.14700175, Gradient norm: 1.11808750
INFO:root:At the start of the epoch: mem (CPU python)=5991.7265625MB; mem (CPU total)=5738.80859375MB
INFO:root:[   22] Training loss: 0.09719846, Validation loss: 0.17072156, Gradient norm: 1.30150046
INFO:root:At the start of the epoch: mem (CPU python)=6067.9609375MB; mem (CPU total)=5815.19921875MB
INFO:root:[   23] Training loss: 0.09467557, Validation loss: 0.17003868, Gradient norm: 1.21326811
INFO:root:At the start of the epoch: mem (CPU python)=6144.19140625MB; mem (CPU total)=5891.2109375MB
INFO:root:[   24] Training loss: 0.08928424, Validation loss: 0.13974121, Gradient norm: 1.08822489
INFO:root:At the start of the epoch: mem (CPU python)=6220.3984375MB; mem (CPU total)=5967.80859375MB
INFO:root:[   25] Training loss: 0.08813135, Validation loss: 0.12806469, Gradient norm: 1.08760289
INFO:root:At the start of the epoch: mem (CPU python)=6296.6015625MB; mem (CPU total)=6044.3515625MB
INFO:root:[   26] Training loss: 0.08925369, Validation loss: 0.17417961, Gradient norm: 1.24039766
INFO:root:At the start of the epoch: mem (CPU python)=6372.796875MB; mem (CPU total)=6121.21484375MB
INFO:root:[   27] Training loss: 0.08689445, Validation loss: 0.15638950, Gradient norm: 1.07925784
INFO:root:At the start of the epoch: mem (CPU python)=6448.9921875MB; mem (CPU total)=6197.76953125MB
INFO:root:[   28] Training loss: 0.08891498, Validation loss: 0.14646601, Gradient norm: 1.24764578
INFO:root:At the start of the epoch: mem (CPU python)=6525.1953125MB; mem (CPU total)=6273.51953125MB
INFO:root:[   29] Training loss: 0.08445215, Validation loss: 0.16108621, Gradient norm: 0.86679756
INFO:root:At the start of the epoch: mem (CPU python)=6601.390625MB; mem (CPU total)=6349.81640625MB
INFO:root:[   30] Training loss: 0.08762135, Validation loss: 0.15552886, Gradient norm: 1.35835518
INFO:root:At the start of the epoch: mem (CPU python)=6677.5703125MB; mem (CPU total)=6426.12109375MB
INFO:root:[   31] Training loss: 0.08518261, Validation loss: 0.16807199, Gradient norm: 1.18856165
INFO:root:At the start of the epoch: mem (CPU python)=6753.76171875MB; mem (CPU total)=6502.49609375MB
INFO:root:[   32] Training loss: 0.08222928, Validation loss: 0.16769576, Gradient norm: 0.92166474
INFO:root:At the start of the epoch: mem (CPU python)=6829.953125MB; mem (CPU total)=6579.25MB
INFO:root:[   33] Training loss: 0.08382000, Validation loss: 0.17730665, Gradient norm: 1.26313877
INFO:root:At the start of the epoch: mem (CPU python)=6906.14453125MB; mem (CPU total)=6655.30078125MB
INFO:root:[   34] Training loss: 0.08308409, Validation loss: 0.19161995, Gradient norm: 1.28089986
INFO:root:At the start of the epoch: mem (CPU python)=6982.3359375MB; mem (CPU total)=6731.82421875MB
INFO:root:[   35] Training loss: 0.08062646, Validation loss: 0.18711237, Gradient norm: 1.06460994
INFO:root:At the start of the epoch: mem (CPU python)=7058.52734375MB; mem (CPU total)=6807.4296875MB
INFO:root:[   36] Training loss: 0.08277950, Validation loss: 0.15954578, Gradient norm: 1.08671919
INFO:root:At the start of the epoch: mem (CPU python)=7134.72265625MB; mem (CPU total)=6883.47265625MB
INFO:root:[   37] Training loss: 0.07966045, Validation loss: 0.18283158, Gradient norm: 0.99605921
INFO:root:At the start of the epoch: mem (CPU python)=7210.9140625MB; mem (CPU total)=6960.2734375MB
INFO:root:[   38] Training loss: 0.07816391, Validation loss: 0.17270762, Gradient norm: 1.03305695
INFO:root:At the start of the epoch: mem (CPU python)=7287.10546875MB; mem (CPU total)=7036.3203125MB
INFO:root:[   39] Training loss: 0.07923924, Validation loss: 0.16440132, Gradient norm: 0.98726470
INFO:root:At the start of the epoch: mem (CPU python)=7363.29296875MB; mem (CPU total)=7112.59765625MB
INFO:root:[   40] Training loss: 0.07657630, Validation loss: 0.18471812, Gradient norm: 0.93695579
INFO:root:At the start of the epoch: mem (CPU python)=7439.484375MB; mem (CPU total)=7188.640625MB
INFO:root:[   41] Training loss: 0.07756860, Validation loss: 0.16569396, Gradient norm: 1.08726193
INFO:root:At the start of the epoch: mem (CPU python)=7515.67578125MB; mem (CPU total)=7265.15234375MB
INFO:root:[   42] Training loss: 0.07884046, Validation loss: 0.19481660, Gradient norm: 1.08523536
INFO:root:At the start of the epoch: mem (CPU python)=7591.87109375MB; mem (CPU total)=7341.91015625MB
INFO:root:[   43] Training loss: 0.07760515, Validation loss: 0.19566166, Gradient norm: 1.10181779
INFO:root:At the start of the epoch: mem (CPU python)=7668.0703125MB; mem (CPU total)=7417.97265625MB
INFO:root:[   44] Training loss: 0.07693738, Validation loss: 0.16542991, Gradient norm: 0.89996799
INFO:root:At the start of the epoch: mem (CPU python)=7744.2578125MB; mem (CPU total)=7493.71875MB
INFO:root:[   45] Training loss: 0.07725227, Validation loss: 0.18881226, Gradient norm: 1.07575576
INFO:root:At the start of the epoch: mem (CPU python)=7820.48828125MB; mem (CPU total)=7569.64453125MB
INFO:root:[   46] Training loss: 0.07558651, Validation loss: 0.15407792, Gradient norm: 0.98077874
INFO:root:At the start of the epoch: mem (CPU python)=7897.1875MB; mem (CPU total)=7646.6875MB
INFO:root:[   47] Training loss: 0.07464840, Validation loss: 0.18252750, Gradient norm: 1.09130640
INFO:root:At the start of the epoch: mem (CPU python)=7973.66015625MB; mem (CPU total)=7723.1875MB
INFO:root:[   48] Training loss: 0.07574260, Validation loss: 0.17474120, Gradient norm: 0.98339037
INFO:root:At the start of the epoch: mem (CPU python)=8050.8125MB; mem (CPU total)=7799.88671875MB
INFO:root:[   49] Training loss: 0.07442490, Validation loss: 0.18217660, Gradient norm: 0.94823235
INFO:root:At the start of the epoch: mem (CPU python)=8127.1328125MB; mem (CPU total)=7876.26171875MB
INFO:root:[   50] Training loss: 0.07360471, Validation loss: 0.15464844, Gradient norm: 1.06512237
INFO:root:At the start of the epoch: mem (CPU python)=8203.32421875MB; mem (CPU total)=7951.796875MB
INFO:root:[   51] Training loss: 0.07335120, Validation loss: 0.15663103, Gradient norm: 0.97059579
INFO:root:At the start of the epoch: mem (CPU python)=8279.515625MB; mem (CPU total)=8027.8359375MB
INFO:root:[   52] Training loss: 0.07533062, Validation loss: 0.18078256, Gradient norm: 0.98964284
INFO:root:At the start of the epoch: mem (CPU python)=8355.70703125MB; mem (CPU total)=8103.55859375MB
INFO:root:[   53] Training loss: 0.07259401, Validation loss: 0.17356344, Gradient norm: 0.87571576
INFO:root:At the start of the epoch: mem (CPU python)=8431.890625MB; mem (CPU total)=8179.5546875MB
INFO:root:[   54] Training loss: 0.07314760, Validation loss: 0.16678619, Gradient norm: 0.94318228
INFO:root:At the start of the epoch: mem (CPU python)=8508.08203125MB; mem (CPU total)=8255.81640625MB
INFO:root:[   55] Training loss: 0.07235259, Validation loss: 0.15560599, Gradient norm: 0.88332195
INFO:root:At the start of the epoch: mem (CPU python)=8584.2734375MB; mem (CPU total)=8332.5703125MB
INFO:root:[   56] Training loss: 0.07139665, Validation loss: 0.16188702, Gradient norm: 0.87038501
INFO:root:At the start of the epoch: mem (CPU python)=8660.47265625MB; mem (CPU total)=8408.828125MB
INFO:root:[   57] Training loss: 0.07236946, Validation loss: 0.16403269, Gradient norm: 0.87060085
INFO:root:At the start of the epoch: mem (CPU python)=8736.6640625MB; mem (CPU total)=8485.3203125MB
INFO:root:[   58] Training loss: 0.07200028, Validation loss: 0.18923306, Gradient norm: 0.97115712
INFO:root:At the start of the epoch: mem (CPU python)=8812.85546875MB; mem (CPU total)=8561.5546875MB
INFO:root:[   59] Training loss: 0.07162235, Validation loss: 0.19362741, Gradient norm: 1.00380306
INFO:root:At the start of the epoch: mem (CPU python)=8889.046875MB; mem (CPU total)=8637.83984375MB
INFO:root:[   60] Training loss: 0.07403941, Validation loss: 0.16390004, Gradient norm: 0.91887595
INFO:root:At the start of the epoch: mem (CPU python)=8965.23828125MB; mem (CPU total)=8714.29296875MB
INFO:root:[   61] Training loss: 0.07012551, Validation loss: 0.17140477, Gradient norm: 0.89692332
INFO:root:At the start of the epoch: mem (CPU python)=9041.421875MB; mem (CPU total)=8790.296875MB
INFO:root:[   62] Training loss: 0.07418555, Validation loss: 0.17343726, Gradient norm: 1.03789125
INFO:root:At the start of the epoch: mem (CPU python)=9117.61328125MB; mem (CPU total)=8867.01953125MB
INFO:root:[   63] Training loss: 0.07051513, Validation loss: 0.17172967, Gradient norm: 0.81206417
INFO:root:At the start of the epoch: mem (CPU python)=9193.80859375MB; mem (CPU total)=8943.296875MB
INFO:root:[   64] Training loss: 0.07045092, Validation loss: 0.15980598, Gradient norm: 0.86960112
INFO:root:At the start of the epoch: mem (CPU python)=9270.0MB; mem (CPU total)=9019.53125MB
INFO:root:EP 64: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=9346.1875MB; mem (CPU total)=9096.015625MB
INFO:root:Training the model took 4982.146s.
INFO:root:Emptying the cuda cache took 0.033s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.14666
INFO:root:EnergyScoreTrain: 0.10699
INFO:root:CRPSTrain: 0.08307
INFO:root:Gaussian NLLTrain: -0.72142
INFO:root:CoverageTrain: 0.98605
INFO:root:IntervalWidthTrain: 0.69432
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.17898
INFO:root:EnergyScoreValidation: 0.12823
INFO:root:CRPSValidation: 0.10437
INFO:root:Gaussian NLLValidation: -0.28892
INFO:root:CoverageValidation: 0.87019
INFO:root:IntervalWidthValidation: 0.60727
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.18205
INFO:root:EnergyScoreTest: 0.13043
INFO:root:CRPSTest: 0.10666
INFO:root:Gaussian NLLTest: -0.26567
INFO:root:CoverageTest: 0.86428
INFO:root:IntervalWidthTest: 0.60631
INFO:root:After validation: mem (CPU python)=9439.328125MB; mem (CPU total)=9184.984375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=9439.328125MB; mem (CPU total)=9184.921875MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 150994944
INFO:root:After setting up the model: mem (CPU python)=9440.51171875MB; mem (CPU total)=9185.90234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=9440.51171875MB; mem (CPU total)=9186.140625MB
INFO:root:[    1] Training loss: 0.24619692, Validation loss: 0.18037314, Gradient norm: 1.72412479
INFO:root:At the start of the epoch: mem (CPU python)=9519.859375MB; mem (CPU total)=9265.125MB
INFO:root:[    2] Training loss: 0.16490494, Validation loss: 0.18588626, Gradient norm: 1.90403812
INFO:root:At the start of the epoch: mem (CPU python)=9596.05078125MB; mem (CPU total)=9341.65625MB
INFO:root:[    3] Training loss: 0.14789019, Validation loss: 0.16758697, Gradient norm: 1.73254468
INFO:root:At the start of the epoch: mem (CPU python)=9672.26171875MB; mem (CPU total)=9418.2421875MB
INFO:root:[    4] Training loss: 0.13784034, Validation loss: 0.14850970, Gradient norm: 1.75388397
INFO:root:At the start of the epoch: mem (CPU python)=9748.46875MB; mem (CPU total)=9492.359375MB
INFO:root:[    5] Training loss: 0.12717418, Validation loss: 0.14619118, Gradient norm: 1.49459470
INFO:root:At the start of the epoch: mem (CPU python)=9824.6796875MB; mem (CPU total)=9569.75MB
INFO:root:[    6] Training loss: 0.12271006, Validation loss: 0.14002955, Gradient norm: 1.45703566
INFO:root:At the start of the epoch: mem (CPU python)=9900.88671875MB; mem (CPU total)=9645.64453125MB
INFO:root:[    7] Training loss: 0.12086757, Validation loss: 0.14228837, Gradient norm: 1.49749023
INFO:root:At the start of the epoch: mem (CPU python)=9977.08984375MB; mem (CPU total)=9721.953125MB
INFO:root:[    8] Training loss: 0.11501446, Validation loss: 0.14202763, Gradient norm: 1.36971766
INFO:root:At the start of the epoch: mem (CPU python)=10053.30078125MB; mem (CPU total)=9798.5MB
INFO:root:[    9] Training loss: 0.11234065, Validation loss: 0.13529855, Gradient norm: 1.31891591
INFO:root:At the start of the epoch: mem (CPU python)=10129.5078125MB; mem (CPU total)=9874.6484375MB
INFO:root:[   10] Training loss: 0.10935158, Validation loss: 0.13678257, Gradient norm: 1.36761878
INFO:root:At the start of the epoch: mem (CPU python)=10205.7109375MB; mem (CPU total)=9951.33984375MB
INFO:root:[   11] Training loss: 0.11085481, Validation loss: 0.13562426, Gradient norm: 1.40786247
INFO:root:At the start of the epoch: mem (CPU python)=10281.8984375MB; mem (CPU total)=10027.67578125MB
INFO:root:[   12] Training loss: 0.10584150, Validation loss: 0.13563681, Gradient norm: 1.19501282
INFO:root:At the start of the epoch: mem (CPU python)=10358.08984375MB; mem (CPU total)=10104.234375MB
INFO:root:[   13] Training loss: 0.10757013, Validation loss: 0.14200909, Gradient norm: 1.44982927
INFO:root:At the start of the epoch: mem (CPU python)=10434.2890625MB; mem (CPU total)=10180.9140625MB
INFO:root:[   14] Training loss: 0.10447356, Validation loss: 0.14519976, Gradient norm: 1.30534719
INFO:root:At the start of the epoch: mem (CPU python)=10510.4765625MB; mem (CPU total)=10256.9609375MB
INFO:root:[   15] Training loss: 0.10406578, Validation loss: 0.13946194, Gradient norm: 1.68870320
INFO:root:At the start of the epoch: mem (CPU python)=10586.66796875MB; mem (CPU total)=10333.265625MB
INFO:root:[   16] Training loss: 0.09855889, Validation loss: 0.14373065, Gradient norm: 1.08259269
INFO:root:At the start of the epoch: mem (CPU python)=10662.859375MB; mem (CPU total)=10409.77734375MB
INFO:root:[   17] Training loss: 0.10313457, Validation loss: 0.14599900, Gradient norm: 1.56388539
INFO:root:At the start of the epoch: mem (CPU python)=10739.05078125MB; mem (CPU total)=10486.0859375MB
INFO:root:[   18] Training loss: 0.09568735, Validation loss: 0.14557038, Gradient norm: 1.16469350
INFO:root:At the start of the epoch: mem (CPU python)=10815.2421875MB; mem (CPU total)=10562.63671875MB
INFO:root:[   19] Training loss: 0.10016200, Validation loss: 0.13823822, Gradient norm: 1.48005577
INFO:root:At the start of the epoch: mem (CPU python)=10891.43359375MB; mem (CPU total)=10638.9609375MB
INFO:root:[   20] Training loss: 0.09581043, Validation loss: 0.17126741, Gradient norm: 1.34662710
INFO:root:At the start of the epoch: mem (CPU python)=10967.625MB; mem (CPU total)=10715.015625MB
INFO:root:[   21] Training loss: 0.09555563, Validation loss: 0.16130195, Gradient norm: 1.30272584
INFO:root:At the start of the epoch: mem (CPU python)=11043.81640625MB; mem (CPU total)=10791.55859375MB
INFO:root:[   22] Training loss: 0.08999448, Validation loss: 0.15870723, Gradient norm: 1.11553437
INFO:root:At the start of the epoch: mem (CPU python)=11120.00390625MB; mem (CPU total)=10867.73046875MB
INFO:root:[   23] Training loss: 0.09151246, Validation loss: 0.16300386, Gradient norm: 1.30406982
INFO:root:At the start of the epoch: mem (CPU python)=11196.1953125MB; mem (CPU total)=10943.75390625MB
INFO:root:[   24] Training loss: 0.09126019, Validation loss: 0.18260954, Gradient norm: 1.30650333
INFO:root:At the start of the epoch: mem (CPU python)=11272.38671875MB; mem (CPU total)=11019.23828125MB
INFO:root:[   25] Training loss: 0.09002833, Validation loss: 0.16330462, Gradient norm: 1.23145422
INFO:root:At the start of the epoch: mem (CPU python)=11348.578125MB; mem (CPU total)=11095.81640625MB
INFO:root:[   26] Training loss: 0.08854879, Validation loss: 0.14501259, Gradient norm: 1.23727409
INFO:root:At the start of the epoch: mem (CPU python)=11424.765625MB; mem (CPU total)=11172.33203125MB
INFO:root:[   27] Training loss: 0.08391545, Validation loss: 0.17045392, Gradient norm: 0.91826087
INFO:root:At the start of the epoch: mem (CPU python)=11500.95703125MB; mem (CPU total)=11248.625MB
INFO:root:[   28] Training loss: 0.08468797, Validation loss: 0.17765675, Gradient norm: 1.12058156
INFO:root:At the start of the epoch: mem (CPU python)=11577.15234375MB; mem (CPU total)=11324.8828125MB
INFO:root:[   29] Training loss: 0.08402305, Validation loss: 0.16986847, Gradient norm: 1.14271128
INFO:root:At the start of the epoch: mem (CPU python)=11653.33984375MB; mem (CPU total)=11400.91796875MB
INFO:root:[   30] Training loss: 0.08294898, Validation loss: 0.18600735, Gradient norm: 1.03562617
INFO:root:At the start of the epoch: mem (CPU python)=11729.53125MB; mem (CPU total)=11477.3671875MB
INFO:root:[   31] Training loss: 0.08402235, Validation loss: 0.18145181, Gradient norm: 1.16818026
INFO:root:At the start of the epoch: mem (CPU python)=11805.71875MB; mem (CPU total)=11553.86328125MB
INFO:root:[   32] Training loss: 0.08084380, Validation loss: 0.17114067, Gradient norm: 1.05528762
INFO:root:At the start of the epoch: mem (CPU python)=11881.9140625MB; mem (CPU total)=11630.11328125MB
INFO:root:[   33] Training loss: 0.08043146, Validation loss: 0.15766616, Gradient norm: 1.15684803
INFO:root:At the start of the epoch: mem (CPU python)=11958.10546875MB; mem (CPU total)=11706.58203125MB
INFO:root:[   34] Training loss: 0.08404909, Validation loss: 0.18739599, Gradient norm: 1.10553140
INFO:root:At the start of the epoch: mem (CPU python)=12034.29296875MB; mem (CPU total)=11782.7734375MB
INFO:root:[   35] Training loss: 0.08077581, Validation loss: 0.15394569, Gradient norm: 1.15071061
INFO:root:At the start of the epoch: mem (CPU python)=12110.484375MB; mem (CPU total)=11859.05859375MB
INFO:root:[   36] Training loss: 0.08032476, Validation loss: 0.19335200, Gradient norm: 1.12941179
INFO:root:At the start of the epoch: mem (CPU python)=12186.67578125MB; mem (CPU total)=11935.7734375MB
INFO:root:[   37] Training loss: 0.08023550, Validation loss: 0.15675807, Gradient norm: 1.06603107
INFO:root:At the start of the epoch: mem (CPU python)=12262.8671875MB; mem (CPU total)=12013.19140625MB
INFO:root:[   38] Training loss: 0.08161059, Validation loss: 0.15195067, Gradient norm: 1.28480371
INFO:root:At the start of the epoch: mem (CPU python)=12339.05859375MB; mem (CPU total)=12089.6875MB
INFO:root:[   39] Training loss: 0.07683164, Validation loss: 0.17116905, Gradient norm: 0.94342695
INFO:root:At the start of the epoch: mem (CPU python)=12415.24609375MB; mem (CPU total)=12165.2265625MB
INFO:root:[   40] Training loss: 0.08004722, Validation loss: 0.17968236, Gradient norm: 1.18046505
INFO:root:At the start of the epoch: mem (CPU python)=12491.4375MB; mem (CPU total)=12242.28125MB
INFO:root:[   41] Training loss: 0.07961434, Validation loss: 0.17278452, Gradient norm: 1.33609490
INFO:root:At the start of the epoch: mem (CPU python)=12567.62890625MB; mem (CPU total)=12318.77734375MB
INFO:root:[   42] Training loss: 0.07837775, Validation loss: 0.18559117, Gradient norm: 1.23317192
INFO:root:At the start of the epoch: mem (CPU python)=12643.8203125MB; mem (CPU total)=12394.18359375MB
INFO:root:[   43] Training loss: 0.07468592, Validation loss: 0.17638804, Gradient norm: 0.87049118
INFO:root:At the start of the epoch: mem (CPU python)=12720.0078125MB; mem (CPU total)=12469.984375MB
INFO:root:[   44] Training loss: 0.07465483, Validation loss: 0.19191431, Gradient norm: 0.91547417
INFO:root:At the start of the epoch: mem (CPU python)=12796.203125MB; mem (CPU total)=12546.01171875MB
INFO:root:[   45] Training loss: 0.07563159, Validation loss: 0.16460778, Gradient norm: 0.96731894
INFO:root:At the start of the epoch: mem (CPU python)=12872.39453125MB; mem (CPU total)=12622.26953125MB
INFO:root:[   46] Training loss: 0.07539678, Validation loss: 0.17553558, Gradient norm: 1.07197159
INFO:root:At the start of the epoch: mem (CPU python)=12948.58203125MB; mem (CPU total)=12698.99609375MB
INFO:root:[   47] Training loss: 0.07452051, Validation loss: 0.16958454, Gradient norm: 0.86860910
INFO:root:At the start of the epoch: mem (CPU python)=13024.7734375MB; mem (CPU total)=12775.00390625MB
INFO:root:[   48] Training loss: 0.07379684, Validation loss: 0.17439609, Gradient norm: 0.95534213
INFO:root:At the start of the epoch: mem (CPU python)=13100.96484375MB; mem (CPU total)=12851.55078125MB
INFO:root:[   49] Training loss: 0.07525510, Validation loss: 0.15616862, Gradient norm: 1.02639719
INFO:root:At the start of the epoch: mem (CPU python)=13177.16015625MB; mem (CPU total)=12927.30859375MB
INFO:root:[   50] Training loss: 0.07457860, Validation loss: 0.17552878, Gradient norm: 1.08819269
INFO:root:At the start of the epoch: mem (CPU python)=13253.3515625MB; mem (CPU total)=13004.02734375MB
INFO:root:[   51] Training loss: 0.07458818, Validation loss: 0.18837716, Gradient norm: 0.89484427
INFO:root:At the start of the epoch: mem (CPU python)=13329.5390625MB; mem (CPU total)=13080.4921875MB
INFO:root:[   52] Training loss: 0.07912253, Validation loss: 0.19516634, Gradient norm: 1.50649711
INFO:root:At the start of the epoch: mem (CPU python)=13405.734375MB; mem (CPU total)=13156.50390625MB
INFO:root:[   53] Training loss: 0.07291147, Validation loss: 0.17648197, Gradient norm: 1.02598046
INFO:root:At the start of the epoch: mem (CPU python)=13481.921875MB; mem (CPU total)=13237.16796875MB
INFO:root:[   54] Training loss: 0.07320961, Validation loss: 0.16273633, Gradient norm: 0.87933835
INFO:root:At the start of the epoch: mem (CPU python)=13558.11328125MB; mem (CPU total)=13311.5703125MB
INFO:root:[   55] Training loss: 0.07183576, Validation loss: 0.18561593, Gradient norm: 0.96118717
INFO:root:At the start of the epoch: mem (CPU python)=13634.3046875MB; mem (CPU total)=13388.03515625MB
INFO:root:[   56] Training loss: 0.07471590, Validation loss: 0.18805057, Gradient norm: 1.17557822
INFO:root:At the start of the epoch: mem (CPU python)=13710.49609375MB; mem (CPU total)=13464.59765625MB
INFO:root:[   57] Training loss: 0.07074017, Validation loss: 0.19029061, Gradient norm: 0.95316001
INFO:root:At the start of the epoch: mem (CPU python)=13786.6875MB; mem (CPU total)=13540.6015625MB
INFO:root:[   58] Training loss: 0.07096241, Validation loss: 0.19305952, Gradient norm: 0.93263598
INFO:root:At the start of the epoch: mem (CPU python)=13862.875MB; mem (CPU total)=13617.125MB
INFO:root:[   59] Training loss: 0.07228007, Validation loss: 0.17809471, Gradient norm: 0.97063836
INFO:root:At the start of the epoch: mem (CPU python)=13939.06640625MB; mem (CPU total)=13693.38671875MB
INFO:root:[   60] Training loss: 0.07286853, Validation loss: 0.18079934, Gradient norm: 1.09536715
INFO:root:At the start of the epoch: mem (CPU python)=14015.2578125MB; mem (CPU total)=13769.6328125MB
INFO:root:[   61] Training loss: 0.06943963, Validation loss: 0.16596167, Gradient norm: 0.96117798
INFO:root:At the start of the epoch: mem (CPU python)=14091.44921875MB; mem (CPU total)=13846.1875MB
INFO:root:[   62] Training loss: 0.07314509, Validation loss: 0.18385680, Gradient norm: 1.14334941
INFO:root:At the start of the epoch: mem (CPU python)=14167.640625MB; mem (CPU total)=13922.18359375MB
INFO:root:[   63] Training loss: 0.07132578, Validation loss: 0.18298471, Gradient norm: 0.95661773
INFO:root:At the start of the epoch: mem (CPU python)=14243.828125MB; mem (CPU total)=13998.6796875MB
INFO:root:EP 63: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=14320.01953125MB; mem (CPU total)=14075.171875MB
INFO:root:Training the model took 5122.323s.
INFO:root:Emptying the cuda cache took 0.031s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.13926
INFO:root:EnergyScoreTrain: 0.10381
INFO:root:CRPSTrain: 0.08249
INFO:root:Gaussian NLLTrain: -0.6269
INFO:root:CoverageTrain: 0.98001
INFO:root:IntervalWidthTrain: 0.71731
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.19053
INFO:root:EnergyScoreValidation: 0.13564
INFO:root:CRPSValidation: 0.10974
INFO:root:Gaussian NLLValidation: -0.28766
INFO:root:CoverageValidation: 0.9031
INFO:root:IntervalWidthValidation: 0.6879
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.19351
INFO:root:EnergyScoreTest: 0.13785
INFO:root:CRPSTest: 0.11169
INFO:root:Gaussian NLLTest: -0.27596
INFO:root:CoverageTest: 0.90048
INFO:root:IntervalWidthTest: 0.68964
INFO:root:After validation: mem (CPU python)=14405.3125MB; mem (CPU total)=14164.0859375MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=14405.3125MB; mem (CPU total)=14164.0234375MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 58720256
INFO:root:After setting up the model: mem (CPU python)=14406.6640625MB; mem (CPU total)=14165.5MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=14406.66796875MB; mem (CPU total)=14165.49609375MB
INFO:root:[    1] Training loss: 0.28040389, Validation loss: 0.19140172, Gradient norm: 2.44067167
INFO:root:At the start of the epoch: mem (CPU python)=14483.26171875MB; mem (CPU total)=14242.8671875MB
INFO:root:[    2] Training loss: 0.17822649, Validation loss: 0.17871493, Gradient norm: 2.05152879
INFO:root:At the start of the epoch: mem (CPU python)=14559.453125MB; mem (CPU total)=14318.5625MB
INFO:root:[    3] Training loss: 0.15869915, Validation loss: 0.17769549, Gradient norm: 1.97345569
INFO:root:At the start of the epoch: mem (CPU python)=14635.65625MB; mem (CPU total)=14395.5078125MB
INFO:root:[    4] Training loss: 0.14629144, Validation loss: 0.16362790, Gradient norm: 1.66705551
INFO:root:At the start of the epoch: mem (CPU python)=14711.86328125MB; mem (CPU total)=14472.10546875MB
INFO:root:[    5] Training loss: 0.13470747, Validation loss: 0.14905582, Gradient norm: 1.88501446
INFO:root:At the start of the epoch: mem (CPU python)=14788.0703125MB; mem (CPU total)=14548.08984375MB
INFO:root:[    6] Training loss: 0.12571350, Validation loss: 0.14736187, Gradient norm: 1.57389480
INFO:root:At the start of the epoch: mem (CPU python)=14864.27734375MB; mem (CPU total)=14624.28515625MB
INFO:root:[    7] Training loss: 0.12515383, Validation loss: 0.15186937, Gradient norm: 1.66159238
INFO:root:At the start of the epoch: mem (CPU python)=14940.484375MB; mem (CPU total)=14701.0234375MB
INFO:root:[    8] Training loss: 0.12336936, Validation loss: 0.15085340, Gradient norm: 1.83857869
INFO:root:At the start of the epoch: mem (CPU python)=15016.6875MB; mem (CPU total)=14777.3046875MB
INFO:root:[    9] Training loss: 0.12289215, Validation loss: 0.14712771, Gradient norm: 1.91886353
INFO:root:At the start of the epoch: mem (CPU python)=15092.89453125MB; mem (CPU total)=14854.640625MB
INFO:root:[   10] Training loss: 0.12051697, Validation loss: 0.14815419, Gradient norm: 1.83202790
INFO:root:At the start of the epoch: mem (CPU python)=15169.078125MB; mem (CPU total)=14932.01953125MB
INFO:root:[   11] Training loss: 0.12034886, Validation loss: 0.15199202, Gradient norm: 2.02095208
INFO:root:At the start of the epoch: mem (CPU python)=15245.2734375MB; mem (CPU total)=15008.578125MB
INFO:root:[   12] Training loss: 0.11591565, Validation loss: 0.14691335, Gradient norm: 1.54314945
INFO:root:At the start of the epoch: mem (CPU python)=15321.46875MB; mem (CPU total)=15083.74609375MB
INFO:root:[   13] Training loss: 0.11117945, Validation loss: 0.14172845, Gradient norm: 1.40195070
INFO:root:At the start of the epoch: mem (CPU python)=15397.65625MB; mem (CPU total)=15159.71484375MB
INFO:root:[   14] Training loss: 0.11032765, Validation loss: 0.14183350, Gradient norm: 1.48204902
INFO:root:At the start of the epoch: mem (CPU python)=15473.84765625MB; mem (CPU total)=15236.30859375MB
INFO:root:[   15] Training loss: 0.10837353, Validation loss: 0.13916435, Gradient norm: 1.36665940
INFO:root:At the start of the epoch: mem (CPU python)=15550.03515625MB; mem (CPU total)=15311.9375MB
INFO:root:[   16] Training loss: 0.10439886, Validation loss: 0.16073355, Gradient norm: 1.26657843
INFO:root:At the start of the epoch: mem (CPU python)=15626.2265625MB; mem (CPU total)=15388.7890625MB
INFO:root:[   17] Training loss: 0.10659450, Validation loss: 0.13957774, Gradient norm: 1.68905826
INFO:root:At the start of the epoch: mem (CPU python)=15702.421875MB; mem (CPU total)=15465.42578125MB
INFO:root:[   18] Training loss: 0.10305914, Validation loss: 0.15423495, Gradient norm: 1.39523034
INFO:root:At the start of the epoch: mem (CPU python)=15778.609375MB; mem (CPU total)=15541.4609375MB
INFO:root:[   19] Training loss: 0.10356771, Validation loss: 0.14371777, Gradient norm: 1.45356225
INFO:root:At the start of the epoch: mem (CPU python)=15854.80078125MB; mem (CPU total)=15617.609375MB
INFO:root:[   20] Training loss: 0.10027821, Validation loss: 0.17671062, Gradient norm: 1.41892845
INFO:root:At the start of the epoch: mem (CPU python)=15930.98828125MB; mem (CPU total)=15693.7265625MB
INFO:root:[   21] Training loss: 0.09900710, Validation loss: 0.14654268, Gradient norm: 1.48118324
INFO:root:At the start of the epoch: mem (CPU python)=16007.18359375MB; mem (CPU total)=15769.45703125MB
INFO:root:[   22] Training loss: 0.09744732, Validation loss: 0.14778872, Gradient norm: 1.22999968
INFO:root:At the start of the epoch: mem (CPU python)=16083.37109375MB; mem (CPU total)=15845.21875MB
INFO:root:[   23] Training loss: 0.09497326, Validation loss: 0.15880235, Gradient norm: 1.17680934
INFO:root:At the start of the epoch: mem (CPU python)=16159.56640625MB; mem (CPU total)=15921.5703125MB
INFO:root:[   24] Training loss: 0.09517644, Validation loss: 0.15774401, Gradient norm: 1.39823603
INFO:root:At the start of the epoch: mem (CPU python)=16235.7578125MB; mem (CPU total)=15997.80078125MB
INFO:root:[   25] Training loss: 0.09202145, Validation loss: 0.16641167, Gradient norm: 1.17864872
INFO:root:At the start of the epoch: mem (CPU python)=16311.9453125MB; mem (CPU total)=16074.05859375MB
INFO:root:[   26] Training loss: 0.09227756, Validation loss: 0.15263739, Gradient norm: 1.45722594
INFO:root:At the start of the epoch: mem (CPU python)=16388.14453125MB; mem (CPU total)=16150.53515625MB
INFO:root:[   27] Training loss: 0.09271136, Validation loss: 0.15759650, Gradient norm: 1.26835610
INFO:root:At the start of the epoch: mem (CPU python)=16464.3359375MB; mem (CPU total)=16226.50390625MB
INFO:root:[   28] Training loss: 0.09233669, Validation loss: 0.16998222, Gradient norm: 1.41200342
INFO:root:At the start of the epoch: mem (CPU python)=16540.52734375MB; mem (CPU total)=16303.22265625MB
INFO:root:[   29] Training loss: 0.09091783, Validation loss: 0.18516111, Gradient norm: 1.32821096
INFO:root:At the start of the epoch: mem (CPU python)=16616.71875MB; mem (CPU total)=16379.69921875MB
INFO:root:[   30] Training loss: 0.09097770, Validation loss: 0.19137899, Gradient norm: 1.30404319
INFO:root:At the start of the epoch: mem (CPU python)=16692.90625MB; mem (CPU total)=16455.85546875MB
INFO:root:[   31] Training loss: 0.08773782, Validation loss: 0.16523823, Gradient norm: 1.29206827
INFO:root:At the start of the epoch: mem (CPU python)=16769.09765625MB; mem (CPU total)=16532.35546875MB
INFO:root:[   32] Training loss: 0.08629289, Validation loss: 0.19616389, Gradient norm: 1.32994890
INFO:root:At the start of the epoch: mem (CPU python)=16845.2890625MB; mem (CPU total)=16608.5703125MB
INFO:root:[   33] Training loss: 0.08472828, Validation loss: 0.16272049, Gradient norm: 1.19140102
INFO:root:At the start of the epoch: mem (CPU python)=16921.48046875MB; mem (CPU total)=16685.0234375MB
INFO:root:[   34] Training loss: 0.08685996, Validation loss: 0.16679554, Gradient norm: 1.24938582
INFO:root:At the start of the epoch: mem (CPU python)=16997.67578125MB; mem (CPU total)=16761.296875MB
INFO:root:[   35] Training loss: 0.08709658, Validation loss: 0.18465590, Gradient norm: 1.55117423
INFO:root:At the start of the epoch: mem (CPU python)=17073.86328125MB; mem (CPU total)=16837.3203125MB
INFO:root:[   36] Training loss: 0.08389916, Validation loss: 0.18120977, Gradient norm: 1.28281929
INFO:root:At the start of the epoch: mem (CPU python)=17150.0546875MB; mem (CPU total)=16913.54296875MB
INFO:root:[   37] Training loss: 0.08653557, Validation loss: 0.17447965, Gradient norm: 1.41365969
INFO:root:At the start of the epoch: mem (CPU python)=17226.2421875MB; mem (CPU total)=16990.06640625MB
INFO:root:[   38] Training loss: 0.08418231, Validation loss: 0.15463965, Gradient norm: 1.33719289
INFO:root:At the start of the epoch: mem (CPU python)=17302.43359375MB; mem (CPU total)=17066.515625MB
INFO:root:[   39] Training loss: 0.08441766, Validation loss: 0.18322107, Gradient norm: 1.30025620
INFO:root:At the start of the epoch: mem (CPU python)=17378.62109375MB; mem (CPU total)=17142.78125MB
INFO:root:[   40] Training loss: 0.08129081, Validation loss: 0.18061676, Gradient norm: 1.08869386
INFO:root:At the start of the epoch: mem (CPU python)=17454.81640625MB; mem (CPU total)=17219.28515625MB
INFO:root:[   41] Training loss: 0.08099596, Validation loss: 0.18467756, Gradient norm: 1.17376378
INFO:root:At the start of the epoch: mem (CPU python)=17531.0078125MB; mem (CPU total)=17295.54296875MB
INFO:root:[   42] Training loss: 0.08142166, Validation loss: 0.18600261, Gradient norm: 1.27434472
INFO:root:At the start of the epoch: mem (CPU python)=17607.1953125MB; mem (CPU total)=17371.54296875MB
INFO:root:[   43] Training loss: 0.07916328, Validation loss: 0.17940063, Gradient norm: 1.05215674
INFO:root:At the start of the epoch: mem (CPU python)=17683.38671875MB; mem (CPU total)=17448.2421875MB
INFO:root:[   44] Training loss: 0.08302604, Validation loss: 0.18901519, Gradient norm: 1.33856417
INFO:root:At the start of the epoch: mem (CPU python)=17759.578125MB; mem (CPU total)=17524.02734375MB
INFO:root:[   45] Training loss: 0.08012879, Validation loss: 0.17792012, Gradient norm: 1.13799661
INFO:root:At the start of the epoch: mem (CPU python)=17835.76953125MB; mem (CPU total)=17601.92578125MB
INFO:root:[   46] Training loss: 0.07788453, Validation loss: 0.16591797, Gradient norm: 1.12872723
INFO:root:At the start of the epoch: mem (CPU python)=17911.9609375MB; mem (CPU total)=17678.41796875MB
INFO:root:[   47] Training loss: 0.07911922, Validation loss: 0.18535931, Gradient norm: 1.10649000
INFO:root:At the start of the epoch: mem (CPU python)=17988.1484375MB; mem (CPU total)=17754.9375MB
INFO:root:[   48] Training loss: 0.07845156, Validation loss: 0.17717062, Gradient norm: 1.22220234
INFO:root:At the start of the epoch: mem (CPU python)=18064.34375MB; mem (CPU total)=17831.49609375MB
INFO:root:[   49] Training loss: 0.07617966, Validation loss: 0.17630573, Gradient norm: 1.12646949
INFO:root:At the start of the epoch: mem (CPU python)=18140.53125MB; mem (CPU total)=17907.6875MB
INFO:root:[   50] Training loss: 0.07655638, Validation loss: 0.17246813, Gradient norm: 1.08542145
INFO:root:At the start of the epoch: mem (CPU python)=18216.72265625MB; mem (CPU total)=17983.78125MB
INFO:root:[   51] Training loss: 0.07602609, Validation loss: 0.16315378, Gradient norm: 1.04519084
INFO:root:At the start of the epoch: mem (CPU python)=18292.9140625MB; mem (CPU total)=18060.27734375MB
INFO:root:[   52] Training loss: 0.07961561, Validation loss: 0.17327294, Gradient norm: 1.32159243
INFO:root:At the start of the epoch: mem (CPU python)=18369.10546875MB; mem (CPU total)=18136.796875MB
INFO:root:[   53] Training loss: 0.07736474, Validation loss: 0.16517327, Gradient norm: 1.35247885
INFO:root:At the start of the epoch: mem (CPU python)=18445.296875MB; mem (CPU total)=18213.3203125MB
INFO:root:[   54] Training loss: 0.07527189, Validation loss: 0.16759274, Gradient norm: 1.10227989
INFO:root:At the start of the epoch: mem (CPU python)=18521.484375MB; mem (CPU total)=18289.37890625MB
INFO:root:[   55] Training loss: 0.07376295, Validation loss: 0.16525268, Gradient norm: 0.95347729
INFO:root:At the start of the epoch: mem (CPU python)=18597.6796875MB; mem (CPU total)=18365.9296875MB
INFO:root:[   56] Training loss: 0.07549099, Validation loss: 0.17152906, Gradient norm: 1.14388968
INFO:root:At the start of the epoch: mem (CPU python)=18673.8671875MB; mem (CPU total)=18442.2265625MB
INFO:root:[   57] Training loss: 0.07379273, Validation loss: 0.18348575, Gradient norm: 0.92106434
INFO:root:At the start of the epoch: mem (CPU python)=18750.05859375MB; mem (CPU total)=18518.29296875MB
INFO:root:[   58] Training loss: 0.07612268, Validation loss: 0.16784044, Gradient norm: 1.26474242
INFO:root:At the start of the epoch: mem (CPU python)=18826.25MB; mem (CPU total)=18595.01953125MB
INFO:root:[   59] Training loss: 0.07506771, Validation loss: 0.19726988, Gradient norm: 1.25941353
INFO:root:At the start of the epoch: mem (CPU python)=18902.44140625MB; mem (CPU total)=18671.0390625MB
INFO:root:[   60] Training loss: 0.07349560, Validation loss: 0.16749212, Gradient norm: 1.01670183
INFO:root:At the start of the epoch: mem (CPU python)=18978.6328125MB; mem (CPU total)=18747.30859375MB
INFO:root:[   61] Training loss: 0.07286843, Validation loss: 0.18673458, Gradient norm: 0.98216583
INFO:root:At the start of the epoch: mem (CPU python)=19054.8203125MB; mem (CPU total)=18823.8046875MB
INFO:root:[   62] Training loss: 0.07473148, Validation loss: 0.18824819, Gradient norm: 1.11911295
INFO:root:At the start of the epoch: mem (CPU python)=19131.01171875MB; mem (CPU total)=18900.12890625MB
INFO:root:EP 62: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19207.20703125MB; mem (CPU total)=18976.3984375MB
INFO:root:Training the model took 5394.658s.
INFO:root:Emptying the cuda cache took 0.032s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.13815
INFO:root:EnergyScoreTrain: 0.10365
INFO:root:CRPSTrain: 0.08175
INFO:root:Gaussian NLLTrain: -0.62099
INFO:root:CoverageTrain: 0.98049
INFO:root:IntervalWidthTrain: 0.7259
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.19728
INFO:root:EnergyScoreValidation: 0.14094
INFO:root:CRPSValidation: 0.1144
INFO:root:Gaussian NLLValidation: -0.18761
INFO:root:CoverageValidation: 0.87941
INFO:root:IntervalWidthValidation: 0.68527
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.20052
INFO:root:EnergyScoreTest: 0.14324
INFO:root:CRPSTest: 0.11639
INFO:root:Gaussian NLLTest: -0.17476
INFO:root:CoverageTest: 0.8766
INFO:root:IntervalWidthTest: 0.68486
INFO:root:After validation: mem (CPU python)=19292.4140625MB; mem (CPU total)=19061.42578125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=19292.4140625MB; mem (CPU total)=19061.328125MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 58720256
INFO:root:After setting up the model: mem (CPU python)=19293.765625MB; mem (CPU total)=19062.8046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=19293.76953125MB; mem (CPU total)=19062.80078125MB
INFO:root:[    1] Training loss: 0.26279074, Validation loss: 0.24453637, Gradient norm: 2.12328146
INFO:root:At the start of the epoch: mem (CPU python)=19370.76171875MB; mem (CPU total)=19139.58984375MB
INFO:root:[    2] Training loss: 0.17772128, Validation loss: 0.18435142, Gradient norm: 2.03945089
INFO:root:At the start of the epoch: mem (CPU python)=19446.9453125MB; mem (CPU total)=19216.1875MB
INFO:root:[    3] Training loss: 0.15695104, Validation loss: 0.16236576, Gradient norm: 1.85258064
INFO:root:At the start of the epoch: mem (CPU python)=19523.15625MB; mem (CPU total)=19292.49609375MB
INFO:root:[    4] Training loss: 0.14190657, Validation loss: 0.19261212, Gradient norm: 1.56204754
INFO:root:At the start of the epoch: mem (CPU python)=19599.36328125MB; mem (CPU total)=19368.12109375MB
INFO:root:[    5] Training loss: 0.13032231, Validation loss: 0.15147497, Gradient norm: 1.45698346
INFO:root:At the start of the epoch: mem (CPU python)=19675.56640625MB; mem (CPU total)=19444.1875MB
INFO:root:[    6] Training loss: 0.12853060, Validation loss: 0.16382874, Gradient norm: 1.65745621
INFO:root:At the start of the epoch: mem (CPU python)=19751.77734375MB; mem (CPU total)=19520.66796875MB
INFO:root:[    7] Training loss: 0.12674729, Validation loss: 0.14805800, Gradient norm: 1.78979319
INFO:root:At the start of the epoch: mem (CPU python)=19827.98046875MB; mem (CPU total)=19596.98046875MB
INFO:root:[    8] Training loss: 0.12165176, Validation loss: 0.14230291, Gradient norm: 1.65927365
INFO:root:At the start of the epoch: mem (CPU python)=19904.1875MB; mem (CPU total)=19673.06640625MB
INFO:root:[    9] Training loss: 0.11648825, Validation loss: 0.13668539, Gradient norm: 1.18087741
INFO:root:At the start of the epoch: mem (CPU python)=19980.37890625MB; mem (CPU total)=19749.9765625MB
INFO:root:[   10] Training loss: 0.11456223, Validation loss: 0.14694050, Gradient norm: 1.60792719
INFO:root:At the start of the epoch: mem (CPU python)=20056.5703125MB; mem (CPU total)=19826.828125MB
INFO:root:[   11] Training loss: 0.11101560, Validation loss: 0.14204844, Gradient norm: 1.27091653
INFO:root:At the start of the epoch: mem (CPU python)=20132.76171875MB; mem (CPU total)=19902.921875MB
INFO:root:[   12] Training loss: 0.11044068, Validation loss: 0.13131505, Gradient norm: 1.33206450
INFO:root:At the start of the epoch: mem (CPU python)=20208.953125MB; mem (CPU total)=19979.53125MB
INFO:root:[   13] Training loss: 0.10751559, Validation loss: 0.13192814, Gradient norm: 1.39047548
INFO:root:At the start of the epoch: mem (CPU python)=20285.140625MB; mem (CPU total)=20055.49609375MB
INFO:root:[   14] Training loss: 0.10686605, Validation loss: 0.13729192, Gradient norm: 1.29291886
INFO:root:At the start of the epoch: mem (CPU python)=20361.33203125MB; mem (CPU total)=20131.7890625MB
INFO:root:[   15] Training loss: 0.10914381, Validation loss: 0.13099369, Gradient norm: 1.64212483
INFO:root:At the start of the epoch: mem (CPU python)=20437.5234375MB; mem (CPU total)=20208.109375MB
INFO:root:[   16] Training loss: 0.10504723, Validation loss: 0.14666162, Gradient norm: 1.35192985
INFO:root:At the start of the epoch: mem (CPU python)=20513.71484375MB; mem (CPU total)=20284.28125MB
INFO:root:[   17] Training loss: 0.10494952, Validation loss: 0.13858191, Gradient norm: 1.39455257
INFO:root:At the start of the epoch: mem (CPU python)=20589.90234375MB; mem (CPU total)=20360.2421875MB
INFO:root:[   18] Training loss: 0.10410146, Validation loss: 0.13379944, Gradient norm: 1.37688341
INFO:root:At the start of the epoch: mem (CPU python)=20666.09765625MB; mem (CPU total)=20437.01953125MB
INFO:root:[   19] Training loss: 0.10269707, Validation loss: 0.13368155, Gradient norm: 1.39663785
INFO:root:At the start of the epoch: mem (CPU python)=20742.28515625MB; mem (CPU total)=20512.9140625MB
INFO:root:[   20] Training loss: 0.10132839, Validation loss: 0.16068722, Gradient norm: 1.32698897
INFO:root:At the start of the epoch: mem (CPU python)=20818.4765625MB; mem (CPU total)=20590.7265625MB
INFO:root:[   21] Training loss: 0.09520816, Validation loss: 0.14349244, Gradient norm: 1.05120415
INFO:root:At the start of the epoch: mem (CPU python)=20894.66796875MB; mem (CPU total)=20667.29296875MB
INFO:root:[   22] Training loss: 0.09373502, Validation loss: 0.14402722, Gradient norm: 0.91532105
INFO:root:At the start of the epoch: mem (CPU python)=20970.859375MB; mem (CPU total)=20743.7890625MB
INFO:root:[   23] Training loss: 0.09304347, Validation loss: 0.16114544, Gradient norm: 1.18228299
INFO:root:At the start of the epoch: mem (CPU python)=21047.05078125MB; mem (CPU total)=20820.10546875MB
INFO:root:[   24] Training loss: 0.09242347, Validation loss: 0.16106896, Gradient norm: 1.14989569
INFO:root:At the start of the epoch: mem (CPU python)=21123.23828125MB; mem (CPU total)=20895.86328125MB
INFO:root:[   25] Training loss: 0.09087055, Validation loss: 0.16953234, Gradient norm: 1.21868585
INFO:root:At the start of the epoch: mem (CPU python)=21199.4296875MB; mem (CPU total)=20972.37109375MB
INFO:root:[   26] Training loss: 0.09093351, Validation loss: 0.13711621, Gradient norm: 1.20853099
INFO:root:At the start of the epoch: mem (CPU python)=21275.62109375MB; mem (CPU total)=21048.59765625MB
INFO:root:[   27] Training loss: 0.09284199, Validation loss: 0.17448230, Gradient norm: 1.45903587
INFO:root:At the start of the epoch: mem (CPU python)=21351.8125MB; mem (CPU total)=21124.3359375MB
INFO:root:[   28] Training loss: 0.08906039, Validation loss: 0.15514010, Gradient norm: 1.18173003
INFO:root:At the start of the epoch: mem (CPU python)=21428.00390625MB; mem (CPU total)=21200.609375MB
INFO:root:[   29] Training loss: 0.09051340, Validation loss: 0.19415162, Gradient norm: 1.52612951
INFO:root:At the start of the epoch: mem (CPU python)=21504.19140625MB; mem (CPU total)=21276.2578125MB
INFO:root:[   30] Training loss: 0.08644892, Validation loss: 0.15752826, Gradient norm: 1.02874078
INFO:root:At the start of the epoch: mem (CPU python)=21580.38671875MB; mem (CPU total)=21352.78125MB
INFO:root:[   31] Training loss: 0.08449506, Validation loss: 0.17381705, Gradient norm: 1.09345586
INFO:root:At the start of the epoch: mem (CPU python)=21656.57421875MB; mem (CPU total)=21428.99609375MB
INFO:root:[   32] Training loss: 0.08236157, Validation loss: 0.15251368, Gradient norm: 0.92771656
INFO:root:At the start of the epoch: mem (CPU python)=21732.765625MB; mem (CPU total)=21505.234375MB
INFO:root:[   33] Training loss: 0.08317557, Validation loss: 0.15734197, Gradient norm: 0.96918481
INFO:root:At the start of the epoch: mem (CPU python)=21808.95703125MB; mem (CPU total)=21581.7109375MB
INFO:root:[   34] Training loss: 0.08040660, Validation loss: 0.15260047, Gradient norm: 0.95738615
INFO:root:At the start of the epoch: mem (CPU python)=21885.1484375MB; mem (CPU total)=21657.7265625MB
INFO:root:[   35] Training loss: 0.08255669, Validation loss: 0.17078779, Gradient norm: 1.11967717
INFO:root:At the start of the epoch: mem (CPU python)=21961.33984375MB; mem (CPU total)=21734.15625MB
INFO:root:[   36] Training loss: 0.08012008, Validation loss: 0.17072567, Gradient norm: 0.91947276
INFO:root:At the start of the epoch: mem (CPU python)=22037.52734375MB; mem (CPU total)=21811.9140625MB
INFO:root:[   37] Training loss: 0.08095420, Validation loss: 0.16523130, Gradient norm: 1.02994107
INFO:root:At the start of the epoch: mem (CPU python)=22113.71875MB; mem (CPU total)=21887.44140625MB
INFO:root:[   38] Training loss: 0.08363464, Validation loss: 0.15244695, Gradient norm: 1.19055690
INFO:root:At the start of the epoch: mem (CPU python)=22189.9140625MB; mem (CPU total)=21963.26953125MB
INFO:root:[   39] Training loss: 0.07962761, Validation loss: 0.15726708, Gradient norm: 1.13397796
INFO:root:At the start of the epoch: mem (CPU python)=22266.1015625MB; mem (CPU total)=22039.390625MB
INFO:root:[   40] Training loss: 0.07792036, Validation loss: 0.16374968, Gradient norm: 0.83495160
INFO:root:At the start of the epoch: mem (CPU python)=22342.29296875MB; mem (CPU total)=22115.84375MB
INFO:root:[   41] Training loss: 0.07659451, Validation loss: 0.17711976, Gradient norm: 0.91806955
INFO:root:At the start of the epoch: mem (CPU python)=22418.484375MB; mem (CPU total)=22192.0546875MB
INFO:root:[   42] Training loss: 0.07895757, Validation loss: 0.16722807, Gradient norm: 1.16186358
INFO:root:At the start of the epoch: mem (CPU python)=22494.67578125MB; mem (CPU total)=22268.26171875MB
INFO:root:[   43] Training loss: 0.07802118, Validation loss: 0.14912005, Gradient norm: 1.10942655
INFO:root:At the start of the epoch: mem (CPU python)=22570.86328125MB; mem (CPU total)=22344.5078125MB
INFO:root:[   44] Training loss: 0.07640296, Validation loss: 0.15997533, Gradient norm: 0.96738662
INFO:root:At the start of the epoch: mem (CPU python)=22647.0546875MB; mem (CPU total)=22420.52734375MB
INFO:root:[   45] Training loss: 0.07679715, Validation loss: 0.15636659, Gradient norm: 0.99278235
INFO:root:At the start of the epoch: mem (CPU python)=22723.25MB; mem (CPU total)=22496.9921875MB
INFO:root:[   46] Training loss: 0.07713658, Validation loss: 0.15353914, Gradient norm: 1.00854245
INFO:root:At the start of the epoch: mem (CPU python)=22799.4375MB; mem (CPU total)=22573.15625MB
INFO:root:[   47] Training loss: 0.07694809, Validation loss: 0.16039106, Gradient norm: 1.08845449
INFO:root:At the start of the epoch: mem (CPU python)=22875.62890625MB; mem (CPU total)=22649.62109375MB
INFO:root:[   48] Training loss: 0.07482541, Validation loss: 0.18955476, Gradient norm: 1.04186585
INFO:root:At the start of the epoch: mem (CPU python)=22951.81640625MB; mem (CPU total)=22726.3125MB
INFO:root:[   49] Training loss: 0.07658084, Validation loss: 0.16035759, Gradient norm: 1.16447429
INFO:root:At the start of the epoch: mem (CPU python)=23028.01171875MB; mem (CPU total)=22801.84765625MB
INFO:root:[   50] Training loss: 0.07428452, Validation loss: 0.15503620, Gradient norm: 1.01701902
INFO:root:At the start of the epoch: mem (CPU python)=23104.203125MB; mem (CPU total)=22878.3515625MB
INFO:root:[   51] Training loss: 0.07417325, Validation loss: 0.16450578, Gradient norm: 0.93533748
INFO:root:At the start of the epoch: mem (CPU python)=23180.390625MB; mem (CPU total)=22954.546875MB
INFO:root:[   52] Training loss: 0.07527581, Validation loss: 0.16588363, Gradient norm: 1.07648288
INFO:root:At the start of the epoch: mem (CPU python)=23256.58203125MB; mem (CPU total)=23038.13671875MB
INFO:root:[   53] Training loss: 0.07580932, Validation loss: 0.14707857, Gradient norm: 1.01096006
INFO:root:At the start of the epoch: mem (CPU python)=23332.76953125MB; mem (CPU total)=23117.875MB
INFO:root:[   54] Training loss: 0.07428114, Validation loss: 0.16425189, Gradient norm: 0.99053673
INFO:root:At the start of the epoch: mem (CPU python)=23408.96875MB; mem (CPU total)=23193.44140625MB
INFO:root:[   55] Training loss: 0.07327703, Validation loss: 0.17329832, Gradient norm: 1.01430590
INFO:root:At the start of the epoch: mem (CPU python)=23485.1640625MB; mem (CPU total)=23263.140625MB
INFO:root:[   56] Training loss: 0.07340517, Validation loss: 0.15266912, Gradient norm: 0.87176928
INFO:root:At the start of the epoch: mem (CPU python)=23561.3515625MB; mem (CPU total)=23338.54296875MB
INFO:root:[   57] Training loss: 0.07427423, Validation loss: 0.16802678, Gradient norm: 1.04016422
INFO:root:At the start of the epoch: mem (CPU python)=23637.54296875MB; mem (CPU total)=23414.53515625MB
INFO:root:[   58] Training loss: 0.07061296, Validation loss: 0.17791673, Gradient norm: 0.78228189
INFO:root:At the start of the epoch: mem (CPU python)=23713.734375MB; mem (CPU total)=23491.28515625MB
INFO:root:[   59] Training loss: 0.07353774, Validation loss: 0.16568239, Gradient norm: 0.96014419
INFO:root:At the start of the epoch: mem (CPU python)=23789.92578125MB; mem (CPU total)=23568.515625MB
INFO:root:[   60] Training loss: 0.07329329, Validation loss: 0.16088650, Gradient norm: 0.99991985
INFO:root:At the start of the epoch: mem (CPU python)=23866.11328125MB; mem (CPU total)=23644.48046875MB
INFO:root:[   61] Training loss: 0.07241711, Validation loss: 0.16065629, Gradient norm: 0.86546839
INFO:root:At the start of the epoch: mem (CPU python)=23942.30859375MB; mem (CPU total)=23720.94921875MB
INFO:root:[   62] Training loss: 0.07112866, Validation loss: 0.17406031, Gradient norm: 0.81162930
INFO:root:At the start of the epoch: mem (CPU python)=24018.5MB; mem (CPU total)=23797.2109375MB
INFO:root:EP 62: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=24094.6875MB; mem (CPU total)=23873.453125MB
INFO:root:Training the model took 5754.759s.
INFO:root:Emptying the cuda cache took 0.033s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.13398
INFO:root:EnergyScoreTrain: 0.10126
INFO:root:CRPSTrain: 0.07916
INFO:root:Gaussian NLLTrain: -0.66999
INFO:root:CoverageTrain: 0.98449
INFO:root:IntervalWidthTrain: 0.73591
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.18608
INFO:root:EnergyScoreValidation: 0.13234
INFO:root:CRPSValidation: 0.10688
INFO:root:Gaussian NLLValidation: -0.29797
INFO:root:CoverageValidation: 0.90626
INFO:root:IntervalWidthValidation: 0.69836
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.18839
INFO:root:EnergyScoreTest: 0.13388
INFO:root:CRPSTest: 0.10844
INFO:root:Gaussian NLLTest: -0.28559
INFO:root:CoverageTest: 0.90398
INFO:root:IntervalWidthTest: 0.70007
INFO:root:After validation: mem (CPU python)=24179.984375MB; mem (CPU total)=23958.515625MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=24179.984375MB; mem (CPU total)=23958.19921875MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 58720256
INFO:root:After setting up the model: mem (CPU python)=24181.3203125MB; mem (CPU total)=23959.42578125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=24181.3203125MB; mem (CPU total)=23959.671875MB
INFO:root:[    1] Training loss: 0.28007439, Validation loss: 0.19385524, Gradient norm: 1.92055970
INFO:root:At the start of the epoch: mem (CPU python)=24257.57421875MB; mem (CPU total)=24035.359375MB
INFO:root:[    2] Training loss: 0.16856550, Validation loss: 0.16415751, Gradient norm: 1.85642384
INFO:root:At the start of the epoch: mem (CPU python)=24333.765625MB; mem (CPU total)=24111.85546875MB
INFO:root:[    3] Training loss: 0.15207974, Validation loss: 0.15393279, Gradient norm: 1.90895216
INFO:root:At the start of the epoch: mem (CPU python)=24409.97265625MB; mem (CPU total)=24188.2421875MB
INFO:root:[    4] Training loss: 0.14171202, Validation loss: 0.16912538, Gradient norm: 1.78218933
INFO:root:At the start of the epoch: mem (CPU python)=24486.17578125MB; mem (CPU total)=24264.6796875MB
INFO:root:[    5] Training loss: 0.13370889, Validation loss: 0.14114386, Gradient norm: 1.60930698
INFO:root:At the start of the epoch: mem (CPU python)=24562.38671875MB; mem (CPU total)=24340.56640625MB
INFO:root:[    6] Training loss: 0.12838762, Validation loss: 0.13984959, Gradient norm: 1.61555541
INFO:root:At the start of the epoch: mem (CPU python)=24638.58984375MB; mem (CPU total)=24417.12890625MB
INFO:root:[    7] Training loss: 0.12240267, Validation loss: 0.15555716, Gradient norm: 1.60065120
INFO:root:At the start of the epoch: mem (CPU python)=24714.796875MB; mem (CPU total)=24493.95703125MB
INFO:root:[    8] Training loss: 0.12346327, Validation loss: 0.14553082, Gradient norm: 1.96518791
INFO:root:At the start of the epoch: mem (CPU python)=24790.98828125MB; mem (CPU total)=24570.3046875MB
INFO:root:[    9] Training loss: 0.11764423, Validation loss: 0.16232530, Gradient norm: 1.58847199
INFO:root:At the start of the epoch: mem (CPU python)=24867.17578125MB; mem (CPU total)=24645.92578125MB
INFO:root:[   10] Training loss: 0.11508107, Validation loss: 0.13973287, Gradient norm: 1.45386188
INFO:root:At the start of the epoch: mem (CPU python)=24943.37109375MB; mem (CPU total)=24722.875MB
INFO:root:[   11] Training loss: 0.11343889, Validation loss: 0.14024616, Gradient norm: 1.53370963
INFO:root:At the start of the epoch: mem (CPU python)=25019.55859375MB; mem (CPU total)=24799.59765625MB
INFO:root:[   12] Training loss: 0.11296206, Validation loss: 0.13056008, Gradient norm: 1.56377895
INFO:root:At the start of the epoch: mem (CPU python)=25095.75390625MB; mem (CPU total)=24875.89453125MB
INFO:root:[   13] Training loss: 0.10582405, Validation loss: 0.13874585, Gradient norm: 1.13811737
INFO:root:At the start of the epoch: mem (CPU python)=25171.9453125MB; mem (CPU total)=24951.7421875MB
INFO:root:[   14] Training loss: 0.10727787, Validation loss: 0.13522152, Gradient norm: 1.30885719
INFO:root:At the start of the epoch: mem (CPU python)=25248.1328125MB; mem (CPU total)=25028.4140625MB
INFO:root:[   15] Training loss: 0.10357788, Validation loss: 0.14376267, Gradient norm: 1.21993785
INFO:root:At the start of the epoch: mem (CPU python)=25324.32421875MB; mem (CPU total)=25104.31640625MB
INFO:root:[   16] Training loss: 0.10472655, Validation loss: 0.13441515, Gradient norm: 1.40793860
INFO:root:At the start of the epoch: mem (CPU python)=25400.515625MB; mem (CPU total)=25180.7734375MB
INFO:root:[   17] Training loss: 0.10545353, Validation loss: 0.13594185, Gradient norm: 1.33529037
INFO:root:At the start of the epoch: mem (CPU python)=25476.70703125MB; mem (CPU total)=25256.765625MB
INFO:root:[   18] Training loss: 0.09973025, Validation loss: 0.13864342, Gradient norm: 1.16620566
INFO:root:At the start of the epoch: mem (CPU python)=25552.89453125MB; mem (CPU total)=25333.23828125MB
INFO:root:[   19] Training loss: 0.10194262, Validation loss: 0.16198276, Gradient norm: 1.67094598
INFO:root:At the start of the epoch: mem (CPU python)=25629.0859375MB; mem (CPU total)=25409.7109375MB
INFO:root:[   20] Training loss: 0.10394620, Validation loss: 0.16429474, Gradient norm: 1.76650208
INFO:root:At the start of the epoch: mem (CPU python)=25705.27734375MB; mem (CPU total)=25486.23828125MB
INFO:root:[   21] Training loss: 0.09837553, Validation loss: 0.14364311, Gradient norm: 1.32946859
INFO:root:At the start of the epoch: mem (CPU python)=25781.484375MB; mem (CPU total)=25564.171875MB
INFO:root:[   22] Training loss: 0.09263913, Validation loss: 0.16215811, Gradient norm: 0.97464386
INFO:root:At the start of the epoch: mem (CPU python)=25857.6640625MB; mem (CPU total)=25639.71484375MB
INFO:root:[   23] Training loss: 0.09812403, Validation loss: 0.18158923, Gradient norm: 1.63352115
INFO:root:At the start of the epoch: mem (CPU python)=25933.8515625MB; mem (CPU total)=25716.2421875MB
INFO:root:[   24] Training loss: 0.09637926, Validation loss: 0.15377754, Gradient norm: 1.51949850
INFO:root:At the start of the epoch: mem (CPU python)=26010.046875MB; mem (CPU total)=25792.76171875MB
INFO:root:[   25] Training loss: 0.09116400, Validation loss: 0.14839935, Gradient norm: 1.18777849
INFO:root:At the start of the epoch: mem (CPU python)=26086.23828125MB; mem (CPU total)=25869.05078125MB
INFO:root:[   26] Training loss: 0.09057426, Validation loss: 0.16916311, Gradient norm: 1.29747392
INFO:root:At the start of the epoch: mem (CPU python)=26162.42578125MB; mem (CPU total)=25945.68359375MB
INFO:root:[   27] Training loss: 0.08735801, Validation loss: 0.16299527, Gradient norm: 1.04306309
INFO:root:At the start of the epoch: mem (CPU python)=26238.6171875MB; mem (CPU total)=26021.68359375MB
INFO:root:[   28] Training loss: 0.08941699, Validation loss: 0.17320443, Gradient norm: 1.24874435
INFO:root:At the start of the epoch: mem (CPU python)=26314.80859375MB; mem (CPU total)=26097.96484375MB
INFO:root:[   29] Training loss: 0.09004711, Validation loss: 0.15678157, Gradient norm: 1.37505600
INFO:root:At the start of the epoch: mem (CPU python)=26391.0MB; mem (CPU total)=26174.41796875MB
INFO:root:[   30] Training loss: 0.08668742, Validation loss: 0.16017516, Gradient norm: 1.27604955
INFO:root:At the start of the epoch: mem (CPU python)=26467.19140625MB; mem (CPU total)=26250.48046875MB
INFO:root:[   31] Training loss: 0.08436319, Validation loss: 0.15844854, Gradient norm: 1.13091155
INFO:root:At the start of the epoch: mem (CPU python)=26543.37890625MB; mem (CPU total)=26327.27734375MB
INFO:root:[   32] Training loss: 0.08412717, Validation loss: 0.16484709, Gradient norm: 1.23091007
INFO:root:At the start of the epoch: mem (CPU python)=26619.5703125MB; mem (CPU total)=26402.96875MB
INFO:root:[   33] Training loss: 0.08670079, Validation loss: 0.16811422, Gradient norm: 1.36497992
INFO:root:At the start of the epoch: mem (CPU python)=26695.765625MB; mem (CPU total)=26478.96484375MB
INFO:root:[   34] Training loss: 0.08649993, Validation loss: 0.15182656, Gradient norm: 1.30752163
INFO:root:At the start of the epoch: mem (CPU python)=26771.95703125MB; mem (CPU total)=26555.47265625MB
INFO:root:[   35] Training loss: 0.08145879, Validation loss: 0.15716432, Gradient norm: 1.16790568
INFO:root:At the start of the epoch: mem (CPU python)=26848.14453125MB; mem (CPU total)=26632.01171875MB
INFO:root:[   36] Training loss: 0.08018296, Validation loss: 0.17144816, Gradient norm: 1.01348696
INFO:root:At the start of the epoch: mem (CPU python)=26924.3359375MB; mem (CPU total)=26708.5078125MB
INFO:root:[   37] Training loss: 0.08064949, Validation loss: 0.15558194, Gradient norm: 1.10970192
INFO:root:At the start of the epoch: mem (CPU python)=27000.52734375MB; mem (CPU total)=26784.80859375MB
INFO:root:[   38] Training loss: 0.07831357, Validation loss: 0.18039506, Gradient norm: 1.01616849
INFO:root:At the start of the epoch: mem (CPU python)=27076.71875MB; mem (CPU total)=26860.89453125MB
INFO:root:[   39] Training loss: 0.07984870, Validation loss: 0.17863043, Gradient norm: 1.04936544
INFO:root:At the start of the epoch: mem (CPU python)=27152.91015625MB; mem (CPU total)=26937.42578125MB
INFO:root:[   40] Training loss: 0.07636459, Validation loss: 0.16991009, Gradient norm: 0.95540967
INFO:root:At the start of the epoch: mem (CPU python)=27229.1015625MB; mem (CPU total)=27013.4609375MB
INFO:root:[   41] Training loss: 0.07583987, Validation loss: 0.17198070, Gradient norm: 0.89300043
INFO:root:At the start of the epoch: mem (CPU python)=27305.29296875MB; mem (CPU total)=27090.00390625MB
INFO:root:[   42] Training loss: 0.07726541, Validation loss: 0.15690423, Gradient norm: 0.97588637
INFO:root:At the start of the epoch: mem (CPU python)=27381.484375MB; mem (CPU total)=27166.28515625MB
INFO:root:[   43] Training loss: 0.07620636, Validation loss: 0.20034272, Gradient norm: 1.02769936
INFO:root:At the start of the epoch: mem (CPU python)=27457.671875MB; mem (CPU total)=27242.5546875MB
INFO:root:[   44] Training loss: 0.07559686, Validation loss: 0.15566848, Gradient norm: 0.96541019
INFO:root:At the start of the epoch: mem (CPU python)=27533.86328125MB; mem (CPU total)=27319.06640625MB
INFO:root:[   45] Training loss: 0.07607635, Validation loss: 0.17698116, Gradient norm: 1.00844290
INFO:root:At the start of the epoch: mem (CPU python)=27610.0546875MB; mem (CPU total)=27394.6875MB
INFO:root:[   46] Training loss: 0.07485062, Validation loss: 0.17823496, Gradient norm: 0.98966002
INFO:root:At the start of the epoch: mem (CPU python)=27686.24609375MB; mem (CPU total)=27471.2265625MB
INFO:root:[   47] Training loss: 0.07565517, Validation loss: 0.15574879, Gradient norm: 1.09732552
INFO:root:At the start of the epoch: mem (CPU python)=27762.4375MB; mem (CPU total)=27547.51953125MB
INFO:root:[   48] Training loss: 0.07520395, Validation loss: 0.17315126, Gradient norm: 0.98454526
INFO:root:At the start of the epoch: mem (CPU python)=27838.625MB; mem (CPU total)=27624.3046875MB
INFO:root:[   49] Training loss: 0.07690093, Validation loss: 0.17331938, Gradient norm: 1.10334325
INFO:root:At the start of the epoch: mem (CPU python)=27914.8203125MB; mem (CPU total)=27700.31640625MB
INFO:root:[   50] Training loss: 0.07468725, Validation loss: 0.16982340, Gradient norm: 1.02190237
INFO:root:At the start of the epoch: mem (CPU python)=27991.0078125MB; mem (CPU total)=27776.19140625MB
INFO:root:[   51] Training loss: 0.07635691, Validation loss: 0.17440678, Gradient norm: 0.96637296
INFO:root:At the start of the epoch: mem (CPU python)=28067.19921875MB; mem (CPU total)=27853.07421875MB
INFO:root:[   52] Training loss: 0.07264470, Validation loss: 0.16071043, Gradient norm: 0.93842318
INFO:root:At the start of the epoch: mem (CPU python)=28143.38671875MB; mem (CPU total)=27929.375MB
INFO:root:[   53] Training loss: 0.07348853, Validation loss: 0.15348652, Gradient norm: 0.93495931
INFO:root:At the start of the epoch: mem (CPU python)=28219.58203125MB; mem (CPU total)=28005.453125MB
INFO:root:[   54] Training loss: 0.07354948, Validation loss: 0.17725251, Gradient norm: 0.91442463
INFO:root:At the start of the epoch: mem (CPU python)=28295.7734375MB; mem (CPU total)=28081.98828125MB
INFO:root:[   55] Training loss: 0.07469676, Validation loss: 0.18389576, Gradient norm: 1.02643444
INFO:root:At the start of the epoch: mem (CPU python)=28371.9609375MB; mem (CPU total)=28157.546875MB
INFO:root:[   56] Training loss: 0.07436382, Validation loss: 0.15647429, Gradient norm: 1.03724593
INFO:root:At the start of the epoch: mem (CPU python)=28448.15625MB; mem (CPU total)=28234.28125MB
INFO:root:[   57] Training loss: 0.07636799, Validation loss: 0.15846115, Gradient norm: 1.32100767
INFO:root:At the start of the epoch: mem (CPU python)=28524.34375MB; mem (CPU total)=28310.84375MB
INFO:root:[   58] Training loss: 0.07327485, Validation loss: 0.16454058, Gradient norm: 0.84911662
INFO:root:At the start of the epoch: mem (CPU python)=28600.53515625MB; mem (CPU total)=28386.24609375MB
INFO:root:[   59] Training loss: 0.07132077, Validation loss: 0.17005502, Gradient norm: 0.81386090
INFO:root:At the start of the epoch: mem (CPU python)=28676.7265625MB; mem (CPU total)=28463.00390625MB
INFO:root:[   60] Training loss: 0.07247460, Validation loss: 0.16074217, Gradient norm: 0.89725001
INFO:root:At the start of the epoch: mem (CPU python)=28752.9140625MB; mem (CPU total)=28538.76953125MB
INFO:root:[   61] Training loss: 0.07330002, Validation loss: 0.15533181, Gradient norm: 1.02823153
INFO:root:At the start of the epoch: mem (CPU python)=28829.109375MB; mem (CPU total)=28615.30078125MB
INFO:root:[   62] Training loss: 0.07376259, Validation loss: 0.17953589, Gradient norm: 1.01576852
INFO:root:At the start of the epoch: mem (CPU python)=28905.296875MB; mem (CPU total)=28692.12890625MB
INFO:root:EP 62: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=28981.48828125MB; mem (CPU total)=28768.21875MB
INFO:root:Training the model took 6075.308s.
INFO:root:Emptying the cuda cache took 0.033s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.13474
INFO:root:EnergyScoreTrain: 0.10281
INFO:root:CRPSTrain: 0.08174
INFO:root:Gaussian NLLTrain: -0.61641
INFO:root:CoverageTrain: 0.98381
INFO:root:IntervalWidthTrain: 0.75395
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.18426
INFO:root:EnergyScoreValidation: 0.13219
INFO:root:CRPSValidation: 0.10648
INFO:root:Gaussian NLLValidation: -0.32911
INFO:root:CoverageValidation: 0.93627
INFO:root:IntervalWidthValidation: 0.73569
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.18758
INFO:root:EnergyScoreTest: 0.13442
INFO:root:CRPSTest: 0.10849
INFO:root:Gaussian NLLTest: -0.3204
INFO:root:CoverageTest: 0.93493
INFO:root:IntervalWidthTest: 0.73894
INFO:root:After validation: mem (CPU python)=29067.1015625MB; mem (CPU total)=28853.92578125MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=29067.1015625MB; mem (CPU total)=28853.88671875MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 268435456
INFO:root:After setting up the model: mem (CPU python)=29067.87890625MB; mem (CPU total)=28854.375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=29068.05859375MB; mem (CPU total)=28854.61328125MB
INFO:root:[    1] Training loss: 0.24624587, Validation loss: 0.17359095, Gradient norm: 1.58648092
INFO:root:At the start of the epoch: mem (CPU python)=29144.83203125MB; mem (CPU total)=28931.83984375MB
INFO:root:[    2] Training loss: 0.16133678, Validation loss: 0.15725237, Gradient norm: 1.92478240
INFO:root:At the start of the epoch: mem (CPU python)=29221.01953125MB; mem (CPU total)=29008.45703125MB
INFO:root:[    3] Training loss: 0.14573257, Validation loss: 0.16846348, Gradient norm: 1.49207051
INFO:root:At the start of the epoch: mem (CPU python)=29297.22265625MB; mem (CPU total)=29084.99609375MB
INFO:root:[    4] Training loss: 0.13885355, Validation loss: 0.15071872, Gradient norm: 1.55193429
INFO:root:At the start of the epoch: mem (CPU python)=29373.43359375MB; mem (CPU total)=29161.84375MB
INFO:root:[    5] Training loss: 0.12990794, Validation loss: 0.13471164, Gradient norm: 1.35916929
INFO:root:At the start of the epoch: mem (CPU python)=29449.640625MB; mem (CPU total)=29238.51171875MB
INFO:root:[    6] Training loss: 0.12534446, Validation loss: 0.14152532, Gradient norm: 1.51600702
INFO:root:At the start of the epoch: mem (CPU python)=29525.828125MB; mem (CPU total)=29314.75MB
INFO:root:[    7] Training loss: 0.11675618, Validation loss: 0.13909566, Gradient norm: 1.26331858
INFO:root:At the start of the epoch: mem (CPU python)=29602.0234375MB; mem (CPU total)=29391.25MB
INFO:root:[    8] Training loss: 0.11600788, Validation loss: 0.14704160, Gradient norm: 1.44006084
INFO:root:At the start of the epoch: mem (CPU python)=29678.2109375MB; mem (CPU total)=29466.3203125MB
INFO:root:[    9] Training loss: 0.11289379, Validation loss: 0.12968630, Gradient norm: 1.14903471
INFO:root:At the start of the epoch: mem (CPU python)=29754.40234375MB; mem (CPU total)=29542.05859375MB
INFO:root:[   10] Training loss: 0.11386510, Validation loss: 0.13558609, Gradient norm: 1.30607467
INFO:root:At the start of the epoch: mem (CPU python)=29830.58984375MB; mem (CPU total)=29619.015625MB
INFO:root:[   11] Training loss: 0.10971028, Validation loss: 0.12972843, Gradient norm: 1.35977549
INFO:root:At the start of the epoch: mem (CPU python)=29906.78125MB; mem (CPU total)=29696.703125MB
INFO:root:[   12] Training loss: 0.11080038, Validation loss: 0.15266331, Gradient norm: 1.49780510
INFO:root:At the start of the epoch: mem (CPU python)=29982.9765625MB; mem (CPU total)=29772.6171875MB
INFO:root:[   13] Training loss: 0.10921738, Validation loss: 0.13216857, Gradient norm: 1.35507892
INFO:root:At the start of the epoch: mem (CPU python)=30059.1640625MB; mem (CPU total)=29848.71875MB
INFO:root:[   14] Training loss: 0.10489926, Validation loss: 0.14763823, Gradient norm: 1.15010150
INFO:root:At the start of the epoch: mem (CPU python)=30135.35546875MB; mem (CPU total)=29925.234375MB
INFO:root:[   15] Training loss: 0.10283199, Validation loss: 0.14561604, Gradient norm: 1.07693695
INFO:root:At the start of the epoch: mem (CPU python)=30211.546875MB; mem (CPU total)=30001.58203125MB
INFO:root:[   16] Training loss: 0.10216273, Validation loss: 0.15159008, Gradient norm: 1.23550472
INFO:root:At the start of the epoch: mem (CPU python)=30287.73828125MB; mem (CPU total)=30077.83203125MB
INFO:root:[   17] Training loss: 0.10088807, Validation loss: 0.15795650, Gradient norm: 1.24263687
INFO:root:At the start of the epoch: mem (CPU python)=30363.9296875MB; mem (CPU total)=30154.0625MB
INFO:root:[   18] Training loss: 0.09944507, Validation loss: 0.14570290, Gradient norm: 1.17145555
INFO:root:At the start of the epoch: mem (CPU python)=30440.1171875MB; mem (CPU total)=30230.51953125MB
INFO:root:[   19] Training loss: 0.09753245, Validation loss: 0.16406011, Gradient norm: 1.25558349
INFO:root:At the start of the epoch: mem (CPU python)=30516.3125MB; mem (CPU total)=30306.73828125MB
INFO:root:[   20] Training loss: 0.10090110, Validation loss: 0.16733444, Gradient norm: 1.37972198
INFO:root:At the start of the epoch: mem (CPU python)=30592.5MB; mem (CPU total)=30383.02734375MB
INFO:root:[   21] Training loss: 0.09641742, Validation loss: 0.14854643, Gradient norm: 1.26899975
INFO:root:At the start of the epoch: mem (CPU python)=30668.69140625MB; mem (CPU total)=30459.54296875MB
INFO:root:[   22] Training loss: 0.09052248, Validation loss: 0.15633505, Gradient norm: 0.94666860
INFO:root:At the start of the epoch: mem (CPU python)=30744.8828125MB; mem (CPU total)=30535.5546875MB
INFO:root:[   23] Training loss: 0.09282013, Validation loss: 0.14858563, Gradient norm: 1.31184492
INFO:root:At the start of the epoch: mem (CPU python)=30821.07421875MB; mem (CPU total)=30611.82421875MB
INFO:root:[   24] Training loss: 0.08918563, Validation loss: 0.14902372, Gradient norm: 1.05753990
INFO:root:At the start of the epoch: mem (CPU python)=30897.265625MB; mem (CPU total)=30688.3515625MB
INFO:root:[   25] Training loss: 0.08959139, Validation loss: 0.17670532, Gradient norm: 1.12879439
INFO:root:At the start of the epoch: mem (CPU python)=30973.45703125MB; mem (CPU total)=30765.1015625MB
INFO:root:[   26] Training loss: 0.08870214, Validation loss: 0.16541750, Gradient norm: 1.22147229
INFO:root:At the start of the epoch: mem (CPU python)=31049.6484375MB; mem (CPU total)=30841.03125MB
INFO:root:[   27] Training loss: 0.08756604, Validation loss: 0.17731602, Gradient norm: 0.94320716
INFO:root:At the start of the epoch: mem (CPU python)=31125.83984375MB; mem (CPU total)=30917.26171875MB
INFO:root:[   28] Training loss: 0.08726948, Validation loss: 0.16380033, Gradient norm: 1.16313014
INFO:root:At the start of the epoch: mem (CPU python)=31202.03125MB; mem (CPU total)=30993.51171875MB
INFO:root:[   29] Training loss: 0.09106086, Validation loss: 0.16446600, Gradient norm: 1.22840724
INFO:root:At the start of the epoch: mem (CPU python)=31278.22265625MB; mem (CPU total)=31070.0MB
INFO:root:[   30] Training loss: 0.08648113, Validation loss: 0.17986548, Gradient norm: 1.11971493
INFO:root:At the start of the epoch: mem (CPU python)=31354.41015625MB; mem (CPU total)=31146.4921875MB
INFO:root:[   31] Training loss: 0.08450607, Validation loss: 0.17056836, Gradient norm: 1.06891876
INFO:root:At the start of the epoch: mem (CPU python)=31430.6015625MB; mem (CPU total)=31222.77734375MB
INFO:root:[   32] Training loss: 0.08457348, Validation loss: 0.18013451, Gradient norm: 1.16918942
INFO:root:At the start of the epoch: mem (CPU python)=31506.79296875MB; mem (CPU total)=31299.078125MB
INFO:root:[   33] Training loss: 0.08498081, Validation loss: 0.18087438, Gradient norm: 1.09439681
INFO:root:At the start of the epoch: mem (CPU python)=31582.984375MB; mem (CPU total)=31375.32421875MB
INFO:root:[   34] Training loss: 0.08166414, Validation loss: 0.18250566, Gradient norm: 0.93529670
INFO:root:At the start of the epoch: mem (CPU python)=31659.17578125MB; mem (CPU total)=31451.2265625MB
INFO:root:[   35] Training loss: 0.08517002, Validation loss: 0.17113960, Gradient norm: 1.29551276
INFO:root:At the start of the epoch: mem (CPU python)=31735.3671875MB; mem (CPU total)=31527.68359375MB
INFO:root:[   36] Training loss: 0.08076969, Validation loss: 0.15913395, Gradient norm: 0.92012188
INFO:root:At the start of the epoch: mem (CPU python)=31811.55859375MB; mem (CPU total)=31604.2265625MB
INFO:root:[   37] Training loss: 0.08081673, Validation loss: 0.15859964, Gradient norm: 1.11592284
INFO:root:At the start of the epoch: mem (CPU python)=31887.74609375MB; mem (CPU total)=31680.484375MB
INFO:root:[   38] Training loss: 0.08024631, Validation loss: 0.16215995, Gradient norm: 1.11991601
INFO:root:At the start of the epoch: mem (CPU python)=31963.9375MB; mem (CPU total)=31756.5546875MB
INFO:root:[   39] Training loss: 0.08114512, Validation loss: 0.16774622, Gradient norm: 1.04870372
INFO:root:At the start of the epoch: mem (CPU python)=32040.12890625MB; mem (CPU total)=31832.43359375MB
INFO:root:[   40] Training loss: 0.08063048, Validation loss: 0.16186555, Gradient norm: 1.01683559
INFO:root:At the start of the epoch: mem (CPU python)=32116.3203125MB; mem (CPU total)=31908.6796875MB
INFO:root:[   41] Training loss: 0.07779574, Validation loss: 0.17153722, Gradient norm: 0.94462708
INFO:root:At the start of the epoch: mem (CPU python)=32192.51171875MB; mem (CPU total)=31985.17578125MB
INFO:root:[   42] Training loss: 0.07691872, Validation loss: 0.16815388, Gradient norm: 1.00806172
INFO:root:At the start of the epoch: mem (CPU python)=32268.69921875MB; mem (CPU total)=32061.66796875MB
INFO:root:[   43] Training loss: 0.07658515, Validation loss: 0.16271174, Gradient norm: 0.90446846
INFO:root:At the start of the epoch: mem (CPU python)=32344.890625MB; mem (CPU total)=32139.5859375MB
INFO:root:[   44] Training loss: 0.07903978, Validation loss: 0.18653969, Gradient norm: 1.08737501
INFO:root:At the start of the epoch: mem (CPU python)=32421.0859375MB; mem (CPU total)=32214.91015625MB
INFO:root:[   45] Training loss: 0.07590595, Validation loss: 0.15431053, Gradient norm: 0.99268881
INFO:root:At the start of the epoch: mem (CPU python)=32497.27734375MB; mem (CPU total)=32291.140625MB
INFO:root:[   46] Training loss: 0.07612981, Validation loss: 0.17990737, Gradient norm: 1.08132372
INFO:root:At the start of the epoch: mem (CPU python)=32573.46875MB; mem (CPU total)=32367.59765625MB
INFO:root:[   47] Training loss: 0.07542744, Validation loss: 0.17750348, Gradient norm: 0.93926989
INFO:root:At the start of the epoch: mem (CPU python)=32649.66015625MB; mem (CPU total)=32443.88671875MB
INFO:root:[   48] Training loss: 0.07592379, Validation loss: 0.16957121, Gradient norm: 1.00041646
INFO:root:At the start of the epoch: mem (CPU python)=32725.8515625MB; mem (CPU total)=32520.20703125MB
INFO:root:[   49] Training loss: 0.07802398, Validation loss: 0.16950843, Gradient norm: 1.24479609
INFO:root:At the start of the epoch: mem (CPU python)=32802.0390625MB; mem (CPU total)=32596.69921875MB
INFO:root:[   50] Training loss: 0.07538380, Validation loss: 0.16618693, Gradient norm: 0.95099076
INFO:root:At the start of the epoch: mem (CPU python)=32878.23046875MB; mem (CPU total)=32672.73828125MB
INFO:root:[   51] Training loss: 0.07426016, Validation loss: 0.18989609, Gradient norm: 0.94292951
INFO:root:At the start of the epoch: mem (CPU python)=32954.42578125MB; mem (CPU total)=32748.99609375MB
INFO:root:[   52] Training loss: 0.07738281, Validation loss: 0.15680445, Gradient norm: 1.33061197
INFO:root:At the start of the epoch: mem (CPU python)=33030.61328125MB; mem (CPU total)=32825.24609375MB
INFO:root:[   53] Training loss: 0.07438910, Validation loss: 0.17155893, Gradient norm: 1.02827596
INFO:root:At the start of the epoch: mem (CPU python)=33106.8046875MB; mem (CPU total)=32901.94921875MB
INFO:root:[   54] Training loss: 0.07203586, Validation loss: 0.16227516, Gradient norm: 0.87307096
INFO:root:At the start of the epoch: mem (CPU python)=33182.9921875MB; mem (CPU total)=32978.20703125MB
INFO:root:[   55] Training loss: 0.07398701, Validation loss: 0.17120419, Gradient norm: 1.11078140
INFO:root:At the start of the epoch: mem (CPU python)=33259.1875MB; mem (CPU total)=33054.0MB
INFO:root:[   56] Training loss: 0.07385668, Validation loss: 0.17212503, Gradient norm: 0.97401195
INFO:root:At the start of the epoch: mem (CPU python)=33335.37890625MB; mem (CPU total)=33130.28515625MB
INFO:root:[   57] Training loss: 0.07273277, Validation loss: 0.17057593, Gradient norm: 0.89186719
INFO:root:At the start of the epoch: mem (CPU python)=33411.56640625MB; mem (CPU total)=33206.3046875MB
INFO:root:[   58] Training loss: 0.07496309, Validation loss: 0.17084424, Gradient norm: 1.00535945
INFO:root:At the start of the epoch: mem (CPU python)=33487.76171875MB; mem (CPU total)=33282.76171875MB
INFO:root:[   59] Training loss: 0.07367706, Validation loss: 0.18075849, Gradient norm: 0.94921757
INFO:root:At the start of the epoch: mem (CPU python)=33563.94921875MB; mem (CPU total)=33358.96875MB
INFO:root:[   60] Training loss: 0.07358933, Validation loss: 0.16997506, Gradient norm: 1.11278918
INFO:root:At the start of the epoch: mem (CPU python)=33640.14453125MB; mem (CPU total)=33435.49609375MB
INFO:root:[   61] Training loss: 0.07262342, Validation loss: 0.16081675, Gradient norm: 0.98008531
INFO:root:At the start of the epoch: mem (CPU python)=33716.33203125MB; mem (CPU total)=33511.109375MB
INFO:root:[   62] Training loss: 0.07476698, Validation loss: 0.15348670, Gradient norm: 1.13214908
INFO:root:At the start of the epoch: mem (CPU python)=33792.5234375MB; mem (CPU total)=33587.83203125MB
INFO:root:[   63] Training loss: 0.07159610, Validation loss: 0.17482894, Gradient norm: 0.84019955
INFO:root:At the start of the epoch: mem (CPU python)=33868.71484375MB; mem (CPU total)=33664.0703125MB
INFO:root:[   64] Training loss: 0.07127081, Validation loss: 0.16652018, Gradient norm: 0.94255048
INFO:root:At the start of the epoch: mem (CPU python)=33944.90625MB; mem (CPU total)=33740.33203125MB
INFO:root:[   65] Training loss: 0.07152638, Validation loss: 0.16956688, Gradient norm: 0.80356613
INFO:root:At the start of the epoch: mem (CPU python)=34021.09765625MB; mem (CPU total)=33816.82421875MB
INFO:root:[   66] Training loss: 0.07378708, Validation loss: 0.16248523, Gradient norm: 1.09793471
INFO:root:At the start of the epoch: mem (CPU python)=34097.28515625MB; mem (CPU total)=33893.08203125MB
INFO:root:[   67] Training loss: 0.07198966, Validation loss: 0.17130658, Gradient norm: 0.99751957
INFO:root:At the start of the epoch: mem (CPU python)=34173.4765625MB; mem (CPU total)=33969.625MB
INFO:root:[   68] Training loss: 0.07059964, Validation loss: 0.15529071, Gradient norm: 0.96950619
INFO:root:At the start of the epoch: mem (CPU python)=34249.671875MB; mem (CPU total)=34045.8671875MB
INFO:root:[   69] Training loss: 0.07237993, Validation loss: 0.19078349, Gradient norm: 0.88965585
INFO:root:At the start of the epoch: mem (CPU python)=34325.859375MB; mem (CPU total)=34122.08203125MB
INFO:root:[   70] Training loss: 0.07226337, Validation loss: 0.18787632, Gradient norm: 0.91904559
INFO:root:At the start of the epoch: mem (CPU python)=34402.05078125MB; mem (CPU total)=34198.61328125MB
INFO:root:[   71] Training loss: 0.07201736, Validation loss: 0.17281121, Gradient norm: 1.15674276
INFO:root:At the start of the epoch: mem (CPU python)=34478.23828125MB; mem (CPU total)=34274.89453125MB
INFO:root:EP 71: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=34554.43359375MB; mem (CPU total)=34351.18359375MB
INFO:root:Training the model took 7278.148s.
INFO:root:Emptying the cuda cache took 0.036s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.14678
INFO:root:EnergyScoreTrain: 0.10828
INFO:root:CRPSTrain: 0.08605
INFO:root:Gaussian NLLTrain: -0.57647
INFO:root:CoverageTrain: 0.98016
INFO:root:IntervalWidthTrain: 0.74731
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.18163
INFO:root:EnergyScoreValidation: 0.12959
INFO:root:CRPSValidation: 0.10448
INFO:root:Gaussian NLLValidation: -0.36276
INFO:root:CoverageValidation: 0.931
INFO:root:IntervalWidthValidation: 0.72262
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.18587
INFO:root:EnergyScoreTest: 0.13243
INFO:root:CRPSTest: 0.10694
INFO:root:Gaussian NLLTest: -0.34608
INFO:root:CoverageTest: 0.92711
INFO:root:IntervalWidthTest: 0.7229
INFO:root:After validation: mem (CPU python)=34645.72265625MB; mem (CPU total)=34444.22265625MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=34645.72265625MB; mem (CPU total)=34444.171875MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 58720256
INFO:root:After setting up the model: mem (CPU python)=34646.9765625MB; mem (CPU total)=34445.40234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=34646.98046875MB; mem (CPU total)=34445.44140625MB
INFO:root:[    1] Training loss: 0.24399995, Validation loss: 0.17751013, Gradient norm: 1.33285196
INFO:root:At the start of the epoch: mem (CPU python)=34723.28125MB; mem (CPU total)=34521.67578125MB
INFO:root:[    2] Training loss: 0.16052218, Validation loss: 0.16821302, Gradient norm: 1.24882595
INFO:root:At the start of the epoch: mem (CPU python)=34799.4921875MB; mem (CPU total)=34597.6796875MB
INFO:root:[    3] Training loss: 0.14691932, Validation loss: 0.17363368, Gradient norm: 1.45810673
INFO:root:At the start of the epoch: mem (CPU python)=34875.6953125MB; mem (CPU total)=34674.14453125MB
INFO:root:[    4] Training loss: 0.13355142, Validation loss: 0.14976825, Gradient norm: 1.19006014
INFO:root:At the start of the epoch: mem (CPU python)=34951.89453125MB; mem (CPU total)=34750.890625MB
INFO:root:[    5] Training loss: 0.12824672, Validation loss: 0.14609075, Gradient norm: 1.19398846
INFO:root:At the start of the epoch: mem (CPU python)=35028.0859375MB; mem (CPU total)=34826.125MB
INFO:root:[    6] Training loss: 0.12734578, Validation loss: 0.13992576, Gradient norm: 1.45286234
INFO:root:At the start of the epoch: mem (CPU python)=35104.2734375MB; mem (CPU total)=34902.0MB
INFO:root:[    7] Training loss: 0.12441531, Validation loss: 0.14947598, Gradient norm: 1.23310695
INFO:root:At the start of the epoch: mem (CPU python)=35180.46875MB; mem (CPU total)=34978.91015625MB
INFO:root:[    8] Training loss: 0.11959077, Validation loss: 0.14623032, Gradient norm: 1.22967901
INFO:root:At the start of the epoch: mem (CPU python)=35256.65625MB; mem (CPU total)=35054.8984375MB
INFO:root:[    9] Training loss: 0.11906314, Validation loss: 0.15699202, Gradient norm: 1.35115854
INFO:root:At the start of the epoch: mem (CPU python)=35332.84765625MB; mem (CPU total)=35131.3125MB
INFO:root:[   10] Training loss: 0.11305136, Validation loss: 0.14570187, Gradient norm: 1.06237802
INFO:root:At the start of the epoch: mem (CPU python)=35409.03515625MB; mem (CPU total)=35207.80078125MB
INFO:root:[   11] Training loss: 0.11429381, Validation loss: 0.14932507, Gradient norm: 1.38493796
INFO:root:At the start of the epoch: mem (CPU python)=35485.2265625MB; mem (CPU total)=35283.81640625MB
INFO:root:[   12] Training loss: 0.10939277, Validation loss: 0.14552588, Gradient norm: 1.29983563
INFO:root:At the start of the epoch: mem (CPU python)=35561.421875MB; mem (CPU total)=35360.546875MB
INFO:root:[   13] Training loss: 0.10958701, Validation loss: 0.14243930, Gradient norm: 1.24023527
INFO:root:At the start of the epoch: mem (CPU python)=35637.609375MB; mem (CPU total)=35437.27734375MB
INFO:root:[   14] Training loss: 0.10624100, Validation loss: 0.14410939, Gradient norm: 1.22534033
INFO:root:At the start of the epoch: mem (CPU python)=35713.8046875MB; mem (CPU total)=35513.03515625MB
INFO:root:[   15] Training loss: 0.10590327, Validation loss: 0.14786908, Gradient norm: 1.28719771
INFO:root:At the start of the epoch: mem (CPU python)=35789.9921875MB; mem (CPU total)=35589.28125MB
INFO:root:[   16] Training loss: 0.10378026, Validation loss: 0.15050974, Gradient norm: 1.28281657
INFO:root:At the start of the epoch: mem (CPU python)=35866.18359375MB; mem (CPU total)=35665.32421875MB
INFO:root:[   17] Training loss: 0.10114838, Validation loss: 0.14722723, Gradient norm: 1.17313096
INFO:root:At the start of the epoch: mem (CPU python)=35942.375MB; mem (CPU total)=35741.8359375MB
INFO:root:[   18] Training loss: 0.10046990, Validation loss: 0.15689355, Gradient norm: 1.26060170
INFO:root:At the start of the epoch: mem (CPU python)=36018.56640625MB; mem (CPU total)=35818.33203125MB
INFO:root:[   19] Training loss: 0.09669813, Validation loss: 0.16013237, Gradient norm: 1.16610028
INFO:root:At the start of the epoch: mem (CPU python)=36094.7578125MB; mem (CPU total)=35894.6015625MB
INFO:root:[   20] Training loss: 0.09661425, Validation loss: 0.14289513, Gradient norm: 1.46776056
INFO:root:At the start of the epoch: mem (CPU python)=36170.94921875MB; mem (CPU total)=35970.58203125MB
INFO:root:[   21] Training loss: 0.08993465, Validation loss: 0.16405386, Gradient norm: 0.95121774
INFO:root:At the start of the epoch: mem (CPU python)=36247.140625MB; mem (CPU total)=36045.9296875MB
INFO:root:[   22] Training loss: 0.09183734, Validation loss: 0.18391342, Gradient norm: 1.19812250
INFO:root:At the start of the epoch: mem (CPU python)=36323.33203125MB; mem (CPU total)=36122.44921875MB
INFO:root:[   23] Training loss: 0.09224287, Validation loss: 0.14513122, Gradient norm: 1.19966433
INFO:root:At the start of the epoch: mem (CPU python)=36399.5234375MB; mem (CPU total)=36198.984375MB
INFO:root:[   24] Training loss: 0.08889049, Validation loss: 0.15651258, Gradient norm: 1.13231988
INFO:root:At the start of the epoch: mem (CPU python)=36475.71484375MB; mem (CPU total)=36275.26171875MB
INFO:root:[   25] Training loss: 0.08908104, Validation loss: 0.16474533, Gradient norm: 1.09031810
INFO:root:At the start of the epoch: mem (CPU python)=36551.90234375MB; mem (CPU total)=36351.40234375MB
INFO:root:[   26] Training loss: 0.08505017, Validation loss: 0.15320029, Gradient norm: 0.91495370
INFO:root:At the start of the epoch: mem (CPU python)=36628.09375MB; mem (CPU total)=36427.4140625MB
INFO:root:[   27] Training loss: 0.08637121, Validation loss: 0.16352028, Gradient norm: 1.06419362
INFO:root:At the start of the epoch: mem (CPU python)=36704.28125MB; mem (CPU total)=36505.15234375MB
INFO:root:[   28] Training loss: 0.08661810, Validation loss: 0.17783831, Gradient norm: 1.12889785
INFO:root:At the start of the epoch: mem (CPU python)=36780.4765625MB; mem (CPU total)=36581.69140625MB
INFO:root:[   29] Training loss: 0.08533418, Validation loss: 0.16537656, Gradient norm: 1.12833379
INFO:root:At the start of the epoch: mem (CPU python)=36856.66796875MB; mem (CPU total)=36657.703125MB
INFO:root:[   30] Training loss: 0.08528296, Validation loss: 0.15604777, Gradient norm: 1.08225570
INFO:root:At the start of the epoch: mem (CPU python)=36932.85546875MB; mem (CPU total)=36733.82421875MB
INFO:root:[   31] Training loss: 0.08547884, Validation loss: 0.15408383, Gradient norm: 1.28261902
INFO:root:At the start of the epoch: mem (CPU python)=37009.046875MB; mem (CPU total)=36809.87109375MB
INFO:root:[   32] Training loss: 0.08358381, Validation loss: 0.17656370, Gradient norm: 1.11055403
INFO:root:At the start of the epoch: mem (CPU python)=37085.23828125MB; mem (CPU total)=36886.4140625MB
INFO:root:[   33] Training loss: 0.08035121, Validation loss: 0.15554738, Gradient norm: 0.89036464
INFO:root:At the start of the epoch: mem (CPU python)=37161.4296875MB; mem (CPU total)=36962.2421875MB
INFO:root:[   34] Training loss: 0.08197176, Validation loss: 0.17978398, Gradient norm: 0.98809151
INFO:root:At the start of the epoch: mem (CPU python)=37237.625MB; mem (CPU total)=37038.48828125MB
INFO:root:[   35] Training loss: 0.07999009, Validation loss: 0.16899783, Gradient norm: 1.06087232
INFO:root:At the start of the epoch: mem (CPU python)=37313.8125MB; mem (CPU total)=37115.41015625MB
INFO:root:[   36] Training loss: 0.08278740, Validation loss: 0.15405907, Gradient norm: 1.14522861
INFO:root:At the start of the epoch: mem (CPU python)=37390.015625MB; mem (CPU total)=37191.98046875MB
INFO:root:[   37] Training loss: 0.08228185, Validation loss: 0.16738074, Gradient norm: 1.21391359
INFO:root:At the start of the epoch: mem (CPU python)=37466.203125MB; mem (CPU total)=37268.7578125MB
INFO:root:[   38] Training loss: 0.07981501, Validation loss: 0.16576263, Gradient norm: 1.10122074
INFO:root:At the start of the epoch: mem (CPU python)=37542.39453125MB; mem (CPU total)=37345.0625MB
INFO:root:[   39] Training loss: 0.07910577, Validation loss: 0.15893076, Gradient norm: 0.91335422
INFO:root:At the start of the epoch: mem (CPU python)=37618.5859375MB; mem (CPU total)=37420.38671875MB
INFO:root:[   40] Training loss: 0.08012007, Validation loss: 0.18335215, Gradient norm: 1.14638965
INFO:root:At the start of the epoch: mem (CPU python)=37694.7734375MB; mem (CPU total)=37496.87890625MB
INFO:root:[   41] Training loss: 0.08012303, Validation loss: 0.19479378, Gradient norm: 1.07464367
INFO:root:At the start of the epoch: mem (CPU python)=37770.96875MB; mem (CPU total)=37572.89453125MB
INFO:root:[   42] Training loss: 0.07928099, Validation loss: 0.14973629, Gradient norm: 0.94609381
INFO:root:At the start of the epoch: mem (CPU python)=37847.15625MB; mem (CPU total)=37649.90625MB
INFO:root:[   43] Training loss: 0.07806902, Validation loss: 0.17048815, Gradient norm: 0.92091255
INFO:root:At the start of the epoch: mem (CPU python)=37923.34765625MB; mem (CPU total)=37726.32421875MB
INFO:root:[   44] Training loss: 0.07756585, Validation loss: 0.15299221, Gradient norm: 1.02963930
INFO:root:At the start of the epoch: mem (CPU python)=37999.53515625MB; mem (CPU total)=37802.36328125MB
INFO:root:[   45] Training loss: 0.07833372, Validation loss: 0.15073597, Gradient norm: 1.10645763
INFO:root:At the start of the epoch: mem (CPU python)=38075.73046875MB; mem (CPU total)=37878.65234375MB
INFO:root:[   46] Training loss: 0.07615718, Validation loss: 0.15619326, Gradient norm: 0.95800349
INFO:root:At the start of the epoch: mem (CPU python)=38151.921875MB; mem (CPU total)=37954.671875MB
INFO:root:[   47] Training loss: 0.07697623, Validation loss: 0.16137777, Gradient norm: 1.01516875
INFO:root:At the start of the epoch: mem (CPU python)=38228.109375MB; mem (CPU total)=38030.9375MB
INFO:root:[   48] Training loss: 0.07874988, Validation loss: 0.16704676, Gradient norm: 1.07220816
INFO:root:At the start of the epoch: mem (CPU python)=38304.30078125MB; mem (CPU total)=38107.5MB
INFO:root:[   49] Training loss: 0.07571744, Validation loss: 0.15503329, Gradient norm: 0.94698777
INFO:root:At the start of the epoch: mem (CPU python)=38380.4921875MB; mem (CPU total)=38183.55078125MB
INFO:root:[   50] Training loss: 0.07573563, Validation loss: 0.17223803, Gradient norm: 0.98276271
INFO:root:At the start of the epoch: mem (CPU python)=38456.68359375MB; mem (CPU total)=38260.3203125MB
INFO:root:[   51] Training loss: 0.07511757, Validation loss: 0.15543782, Gradient norm: 0.90099584
INFO:root:At the start of the epoch: mem (CPU python)=38532.875MB; mem (CPU total)=38336.10546875MB
INFO:root:[   52] Training loss: 0.07553787, Validation loss: 0.18713162, Gradient norm: 1.02502217
INFO:root:At the start of the epoch: mem (CPU python)=38609.0625MB; mem (CPU total)=38412.5703125MB
INFO:root:[   53] Training loss: 0.07652895, Validation loss: 0.16649958, Gradient norm: 1.04257088
INFO:root:At the start of the epoch: mem (CPU python)=38685.25390625MB; mem (CPU total)=38489.32421875MB
INFO:root:[   54] Training loss: 0.07583924, Validation loss: 0.17554885, Gradient norm: 1.00106423
INFO:root:At the start of the epoch: mem (CPU python)=38761.4453125MB; mem (CPU total)=38565.375MB
INFO:root:[   55] Training loss: 0.07531313, Validation loss: 0.16315769, Gradient norm: 0.98771172
INFO:root:At the start of the epoch: mem (CPU python)=38837.63671875MB; mem (CPU total)=38641.75MB
INFO:root:[   56] Training loss: 0.07482761, Validation loss: 0.18210917, Gradient norm: 0.80746268
INFO:root:At the start of the epoch: mem (CPU python)=38913.828125MB; mem (CPU total)=38718.3046875MB
INFO:root:[   57] Training loss: 0.07426177, Validation loss: 0.17396891, Gradient norm: 0.80040273
INFO:root:At the start of the epoch: mem (CPU python)=38990.015625MB; mem (CPU total)=38794.33203125MB
INFO:root:[   58] Training loss: 0.07409889, Validation loss: 0.17702014, Gradient norm: 0.91768077
INFO:root:At the start of the epoch: mem (CPU python)=39066.2109375MB; mem (CPU total)=38870.8671875MB
INFO:root:[   59] Training loss: 0.07412751, Validation loss: 0.17718780, Gradient norm: 0.88038017
INFO:root:At the start of the epoch: mem (CPU python)=39142.40234375MB; mem (CPU total)=38946.890625MB
INFO:root:[   60] Training loss: 0.07626960, Validation loss: 0.16232494, Gradient norm: 1.12850511
INFO:root:At the start of the epoch: mem (CPU python)=39218.59375MB; mem (CPU total)=39023.41796875MB
INFO:root:[   61] Training loss: 0.07338689, Validation loss: 0.18466206, Gradient norm: 0.90004433
INFO:root:At the start of the epoch: mem (CPU python)=39294.78125MB; mem (CPU total)=39099.94921875MB
INFO:root:[   62] Training loss: 0.07304304, Validation loss: 0.17180364, Gradient norm: 0.85651521
INFO:root:At the start of the epoch: mem (CPU python)=39370.9765625MB; mem (CPU total)=39176.00390625MB
INFO:root:[   63] Training loss: 0.07356264, Validation loss: 0.17418303, Gradient norm: 0.91980774
INFO:root:At the start of the epoch: mem (CPU python)=39447.16796875MB; mem (CPU total)=39252.5859375MB
INFO:root:[   64] Training loss: 0.07263847, Validation loss: 0.18306366, Gradient norm: 0.74946286
INFO:root:At the start of the epoch: mem (CPU python)=39523.35546875MB; mem (CPU total)=39328.87109375MB
INFO:root:[   65] Training loss: 0.07033390, Validation loss: 0.17608053, Gradient norm: 0.66948073
INFO:root:At the start of the epoch: mem (CPU python)=39599.55078125MB; mem (CPU total)=39405.37890625MB
INFO:root:[   66] Training loss: 0.07239796, Validation loss: 0.15912510, Gradient norm: 1.03099762
INFO:root:At the start of the epoch: mem (CPU python)=39675.73828125MB; mem (CPU total)=39481.6640625MB
INFO:root:[   67] Training loss: 0.07289454, Validation loss: 0.18235153, Gradient norm: 0.81132752
INFO:root:At the start of the epoch: mem (CPU python)=39751.9296875MB; mem (CPU total)=39558.0MB
INFO:root:[   68] Training loss: 0.07258307, Validation loss: 0.16023364, Gradient norm: 0.91427931
INFO:root:At the start of the epoch: mem (CPU python)=39828.125MB; mem (CPU total)=39633.921875MB
INFO:root:[   69] Training loss: 0.07228852, Validation loss: 0.18233047, Gradient norm: 0.83461382
INFO:root:At the start of the epoch: mem (CPU python)=39904.3125MB; mem (CPU total)=39709.3203125MB
INFO:root:[   70] Training loss: 0.07170758, Validation loss: 0.17466822, Gradient norm: 0.80692959
INFO:root:At the start of the epoch: mem (CPU python)=39980.50390625MB; mem (CPU total)=39785.5546875MB
INFO:root:[   71] Training loss: 0.07531376, Validation loss: 0.18042537, Gradient norm: 1.21681225
INFO:root:At the start of the epoch: mem (CPU python)=40056.69140625MB; mem (CPU total)=39861.76171875MB
INFO:root:[   72] Training loss: 0.07455331, Validation loss: 0.18228712, Gradient norm: 1.01021757
INFO:root:At the start of the epoch: mem (CPU python)=40132.88671875MB; mem (CPU total)=39937.75MB
INFO:root:[   73] Training loss: 0.07234847, Validation loss: 0.17207220, Gradient norm: 1.03763603
INFO:root:At the start of the epoch: mem (CPU python)=40209.078125MB; mem (CPU total)=40014.4765625MB
INFO:root:[   74] Training loss: 0.07037685, Validation loss: 0.17943933, Gradient norm: 0.79431772
INFO:root:At the start of the epoch: mem (CPU python)=40285.265625MB; mem (CPU total)=40090.73828125MB
INFO:root:[   75] Training loss: 0.07215826, Validation loss: 0.16049480, Gradient norm: 0.99283359
INFO:root:At the start of the epoch: mem (CPU python)=40361.45703125MB; mem (CPU total)=40167.66796875MB
INFO:root:EP 75: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=40437.6484375MB; mem (CPU total)=40243.9296875MB
INFO:root:Training the model took 8187.81s.
INFO:root:Emptying the cuda cache took 0.04s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.15975
INFO:root:EnergyScoreTrain: 0.11883
INFO:root:CRPSTrain: 0.09504
INFO:root:Gaussian NLLTrain: -0.45151
INFO:root:CoverageTrain: 0.96768
INFO:root:IntervalWidthTrain: 0.79078
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.19393
INFO:root:EnergyScoreValidation: 0.13983
INFO:root:CRPSValidation: 0.11328
INFO:root:Gaussian NLLValidation: -0.23896
INFO:root:CoverageValidation: 0.92619
INFO:root:IntervalWidthValidation: 0.77152
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.19837
INFO:root:EnergyScoreTest: 0.14322
INFO:root:CRPSTest: 0.11624
INFO:root:Gaussian NLLTest: -0.21417
INFO:root:CoverageTest: 0.92151
INFO:root:IntervalWidthTest: 0.77089
INFO:root:After validation: mem (CPU python)=40522.94921875MB; mem (CPU total)=40329.46484375MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=40522.94921875MB; mem (CPU total)=40329.38671875MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 58720256
INFO:root:After setting up the model: mem (CPU python)=40524.21875MB; mem (CPU total)=40330.61328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=40524.21875MB; mem (CPU total)=40330.84375MB
INFO:root:[    1] Training loss: 0.26306641, Validation loss: 0.19688452, Gradient norm: 2.06044212
INFO:root:At the start of the epoch: mem (CPU python)=40600.52734375MB; mem (CPU total)=40409.0546875MB
INFO:root:[    2] Training loss: 0.16611670, Validation loss: 0.18223809, Gradient norm: 1.50038225
INFO:root:At the start of the epoch: mem (CPU python)=40676.71484375MB; mem (CPU total)=40486.14453125MB
INFO:root:[    3] Training loss: 0.14911275, Validation loss: 0.16386149, Gradient norm: 1.63617567
INFO:root:At the start of the epoch: mem (CPU python)=40752.90625MB; mem (CPU total)=40561.5546875MB
INFO:root:[    4] Training loss: 0.14347755, Validation loss: 0.16853275, Gradient norm: 1.91182382
INFO:root:At the start of the epoch: mem (CPU python)=40829.09375MB; mem (CPU total)=40638.5234375MB
INFO:root:[    5] Training loss: 0.13216606, Validation loss: 0.18800434, Gradient norm: 1.74944514
INFO:root:At the start of the epoch: mem (CPU python)=40905.2890625MB; mem (CPU total)=40715.06640625MB
INFO:root:[    6] Training loss: 0.12231648, Validation loss: 0.17299455, Gradient norm: 1.41075312
INFO:root:At the start of the epoch: mem (CPU python)=40981.4765625MB; mem (CPU total)=40790.796875MB
INFO:root:[    7] Training loss: 0.11621865, Validation loss: 0.13690560, Gradient norm: 1.38004289
INFO:root:At the start of the epoch: mem (CPU python)=41057.671875MB; mem (CPU total)=40867.171875MB
INFO:root:[    8] Training loss: 0.12408964, Validation loss: 0.14882280, Gradient norm: 2.07984460
INFO:root:At the start of the epoch: mem (CPU python)=41133.86328125MB; mem (CPU total)=40943.27734375MB
INFO:root:[    9] Training loss: 0.11699806, Validation loss: 0.16172342, Gradient norm: 1.79545602
INFO:root:At the start of the epoch: mem (CPU python)=41210.05078125MB; mem (CPU total)=41019.5390625MB
INFO:root:[   10] Training loss: 0.11514799, Validation loss: 0.13519250, Gradient norm: 1.73748762
INFO:root:At the start of the epoch: mem (CPU python)=41286.24609375MB; mem (CPU total)=41095.828125MB
INFO:root:[   11] Training loss: 0.11035543, Validation loss: 0.13442561, Gradient norm: 1.26269441
INFO:root:At the start of the epoch: mem (CPU python)=41362.44140625MB; mem (CPU total)=41172.30859375MB
INFO:root:[   12] Training loss: 0.11005431, Validation loss: 0.13181056, Gradient norm: 1.57388303
INFO:root:At the start of the epoch: mem (CPU python)=41438.6328125MB; mem (CPU total)=41249.28515625MB
INFO:root:[   13] Training loss: 0.11058152, Validation loss: 0.14738614, Gradient norm: 1.79476832
INFO:root:At the start of the epoch: mem (CPU python)=41514.82421875MB; mem (CPU total)=41325.63671875MB
INFO:root:[   14] Training loss: 0.11202907, Validation loss: 0.13322473, Gradient norm: 1.72386832
INFO:root:At the start of the epoch: mem (CPU python)=41591.01171875MB; mem (CPU total)=41401.0625MB
INFO:root:[   15] Training loss: 0.10798349, Validation loss: 0.12953070, Gradient norm: 1.55379976
INFO:root:At the start of the epoch: mem (CPU python)=41667.203125MB; mem (CPU total)=41476.8203125MB
INFO:root:[   16] Training loss: 0.10682467, Validation loss: 0.14160582, Gradient norm: 1.45161203
INFO:root:At the start of the epoch: mem (CPU python)=41743.390625MB; mem (CPU total)=41552.87109375MB
INFO:root:[   17] Training loss: 0.10015320, Validation loss: 0.13871201, Gradient norm: 1.16093719
INFO:root:At the start of the epoch: mem (CPU python)=41819.5859375MB; mem (CPU total)=41628.890625MB
INFO:root:[   18] Training loss: 0.10505403, Validation loss: 0.13174523, Gradient norm: 1.37207607
INFO:root:At the start of the epoch: mem (CPU python)=41895.77734375MB; mem (CPU total)=41705.37890625MB
INFO:root:[   19] Training loss: 0.09953315, Validation loss: 0.14636838, Gradient norm: 1.32971075
INFO:root:At the start of the epoch: mem (CPU python)=41971.96484375MB; mem (CPU total)=41781.86328125MB
INFO:root:[   20] Training loss: 0.10267603, Validation loss: 0.17675645, Gradient norm: 1.51598759
INFO:root:At the start of the epoch: mem (CPU python)=42048.16015625MB; mem (CPU total)=41857.8984375MB
INFO:root:[   21] Training loss: 0.10060625, Validation loss: 0.16025610, Gradient norm: 1.41739700
INFO:root:At the start of the epoch: mem (CPU python)=42124.34765625MB; mem (CPU total)=41934.6171875MB
INFO:root:[   22] Training loss: 0.09410804, Validation loss: 0.16713482, Gradient norm: 1.03940394
INFO:root:At the start of the epoch: mem (CPU python)=42200.5390625MB; mem (CPU total)=42010.83203125MB
INFO:root:[   23] Training loss: 0.09663875, Validation loss: 0.17127798, Gradient norm: 1.37124809
INFO:root:At the start of the epoch: mem (CPU python)=42276.73046875MB; mem (CPU total)=42087.53515625MB
INFO:root:[   24] Training loss: 0.09621890, Validation loss: 0.16279481, Gradient norm: 1.39264861
INFO:root:At the start of the epoch: mem (CPU python)=42352.921875MB; mem (CPU total)=42163.734375MB
INFO:root:[   25] Training loss: 0.09363640, Validation loss: 0.15106008, Gradient norm: 1.29318788
INFO:root:At the start of the epoch: mem (CPU python)=42429.11328125MB; mem (CPU total)=42239.9765625MB
INFO:root:[   26] Training loss: 0.09170512, Validation loss: 0.15517413, Gradient norm: 1.19937513
INFO:root:At the start of the epoch: mem (CPU python)=42505.30078125MB; mem (CPU total)=42316.60546875MB
INFO:root:[   27] Training loss: 0.08997558, Validation loss: 0.15734691, Gradient norm: 1.19237946
INFO:root:At the start of the epoch: mem (CPU python)=42581.49609375MB; mem (CPU total)=42392.33203125MB
INFO:root:[   28] Training loss: 0.09234348, Validation loss: 0.14922829, Gradient norm: 1.34362083
INFO:root:At the start of the epoch: mem (CPU python)=42657.68359375MB; mem (CPU total)=42469.28515625MB
INFO:root:[   29] Training loss: 0.09001468, Validation loss: 0.21372071, Gradient norm: 1.26171492
INFO:root:At the start of the epoch: mem (CPU python)=42733.875MB; mem (CPU total)=42545.0703125MB
INFO:root:[   30] Training loss: 0.09208049, Validation loss: 0.14643437, Gradient norm: 1.25020506
INFO:root:At the start of the epoch: mem (CPU python)=42810.06640625MB; mem (CPU total)=42621.31640625MB
INFO:root:[   31] Training loss: 0.08572300, Validation loss: 0.17489724, Gradient norm: 1.12762532
INFO:root:At the start of the epoch: mem (CPU python)=42886.2578125MB; mem (CPU total)=42698.046875MB
INFO:root:[   32] Training loss: 0.08759073, Validation loss: 0.15445101, Gradient norm: 1.08467619
INFO:root:At the start of the epoch: mem (CPU python)=42962.4609375MB; mem (CPU total)=42775.55078125MB
INFO:root:[   33] Training loss: 0.08756561, Validation loss: 0.17395667, Gradient norm: 1.31883545
INFO:root:At the start of the epoch: mem (CPU python)=43038.63671875MB; mem (CPU total)=42852.0859375MB
INFO:root:[   34] Training loss: 0.08491078, Validation loss: 0.16026708, Gradient norm: 1.28015377
INFO:root:At the start of the epoch: mem (CPU python)=43114.83203125MB; mem (CPU total)=42928.375MB
INFO:root:[   35] Training loss: 0.08454541, Validation loss: 0.16227566, Gradient norm: 1.07669439
INFO:root:At the start of the epoch: mem (CPU python)=43191.0234375MB; mem (CPU total)=43004.8984375MB
INFO:root:[   36] Training loss: 0.08771295, Validation loss: 0.16891572, Gradient norm: 1.25863850
INFO:root:At the start of the epoch: mem (CPU python)=43267.2109375MB; mem (CPU total)=43081.65234375MB
INFO:root:[   37] Training loss: 0.08063156, Validation loss: 0.18210082, Gradient norm: 0.96708899
INFO:root:At the start of the epoch: mem (CPU python)=43343.40234375MB; mem (CPU total)=43157.28125MB
INFO:root:[   38] Training loss: 0.08312749, Validation loss: 0.17422755, Gradient norm: 1.28402501
INFO:root:At the start of the epoch: mem (CPU python)=43419.58984375MB; mem (CPU total)=43233.5625MB
INFO:root:[   39] Training loss: 0.07992589, Validation loss: 0.15805089, Gradient norm: 0.94642679
INFO:root:At the start of the epoch: mem (CPU python)=43495.78515625MB; mem (CPU total)=43309.82421875MB
INFO:root:[   40] Training loss: 0.08065537, Validation loss: 0.15292512, Gradient norm: 1.17589916
INFO:root:At the start of the epoch: mem (CPU python)=43571.97265625MB; mem (CPU total)=43386.41015625MB
INFO:root:[   41] Training loss: 0.07857795, Validation loss: 0.17473426, Gradient norm: 1.03704649
INFO:root:At the start of the epoch: mem (CPU python)=43648.1640625MB; mem (CPU total)=43462.953125MB
INFO:root:[   42] Training loss: 0.07830940, Validation loss: 0.17151739, Gradient norm: 1.10533616
INFO:root:At the start of the epoch: mem (CPU python)=43724.359375MB; mem (CPU total)=43538.34765625MB
INFO:root:[   43] Training loss: 0.07855050, Validation loss: 0.18311222, Gradient norm: 1.14145167
INFO:root:At the start of the epoch: mem (CPU python)=43800.55078125MB; mem (CPU total)=43613.328125MB
INFO:root:[   44] Training loss: 0.07639153, Validation loss: 0.18270583, Gradient norm: 0.96299622
INFO:root:At the start of the epoch: mem (CPU python)=43876.7421875MB; mem (CPU total)=43689.66796875MB
INFO:root:[   45] Training loss: 0.07512883, Validation loss: 0.15096275, Gradient norm: 0.82927377
INFO:root:At the start of the epoch: mem (CPU python)=43952.9296875MB; mem (CPU total)=43766.3671875MB
INFO:root:[   46] Training loss: 0.07821387, Validation loss: 0.16311543, Gradient norm: 1.16294641
INFO:root:At the start of the epoch: mem (CPU python)=44029.12109375MB; mem (CPU total)=43843.1328125MB
INFO:root:[   47] Training loss: 0.07685257, Validation loss: 0.19996131, Gradient norm: 1.00988833
INFO:root:At the start of the epoch: mem (CPU python)=44105.3125MB; mem (CPU total)=43918.8515625MB
INFO:root:[   48] Training loss: 0.07730303, Validation loss: 0.16498144, Gradient norm: 1.11913596
INFO:root:At the start of the epoch: mem (CPU python)=44181.50390625MB; mem (CPU total)=43995.328125MB
INFO:root:[   49] Training loss: 0.07654086, Validation loss: 0.16786473, Gradient norm: 1.25542786
INFO:root:At the start of the epoch: mem (CPU python)=44257.6953125MB; mem (CPU total)=44071.79296875MB
INFO:root:[   50] Training loss: 0.07706095, Validation loss: 0.15606363, Gradient norm: 1.18717864
INFO:root:At the start of the epoch: mem (CPU python)=44333.8828125MB; mem (CPU total)=44148.16015625MB
INFO:root:[   51] Training loss: 0.07710268, Validation loss: 0.16260350, Gradient norm: 1.12395926
INFO:root:At the start of the epoch: mem (CPU python)=44410.078125MB; mem (CPU total)=44224.59765625MB
INFO:root:[   52] Training loss: 0.07425783, Validation loss: 0.17884003, Gradient norm: 1.00621950
INFO:root:At the start of the epoch: mem (CPU python)=44486.26953125MB; mem (CPU total)=44300.62109375MB
INFO:root:[   53] Training loss: 0.07595708, Validation loss: 0.17443600, Gradient norm: 1.16133639
INFO:root:At the start of the epoch: mem (CPU python)=44562.4609375MB; mem (CPU total)=44378.96484375MB
INFO:root:[   54] Training loss: 0.07267898, Validation loss: 0.17477794, Gradient norm: 0.97340273
INFO:root:At the start of the epoch: mem (CPU python)=44638.65234375MB; mem (CPU total)=44455.25MB
INFO:root:[   55] Training loss: 0.07557569, Validation loss: 0.17682918, Gradient norm: 1.05823441
INFO:root:At the start of the epoch: mem (CPU python)=44714.83984375MB; mem (CPU total)=44531.56640625MB
INFO:root:[   56] Training loss: 0.07599307, Validation loss: 0.16853931, Gradient norm: 1.26846728
INFO:root:At the start of the epoch: mem (CPU python)=44791.03515625MB; mem (CPU total)=44608.06640625MB
INFO:root:[   57] Training loss: 0.07411238, Validation loss: 0.16462888, Gradient norm: 1.09778954
INFO:root:At the start of the epoch: mem (CPU python)=44867.22265625MB; mem (CPU total)=44683.56640625MB
INFO:root:[   58] Training loss: 0.07240706, Validation loss: 0.17048989, Gradient norm: 0.99819185
INFO:root:At the start of the epoch: mem (CPU python)=44943.4140625MB; mem (CPU total)=44760.15625MB
INFO:root:[   59] Training loss: 0.07245969, Validation loss: 0.16459148, Gradient norm: 0.91123190
INFO:root:At the start of the epoch: mem (CPU python)=45019.60546875MB; mem (CPU total)=44836.8125MB
INFO:root:[   60] Training loss: 0.07371784, Validation loss: 0.17172455, Gradient norm: 1.00717709
INFO:root:At the start of the epoch: mem (CPU python)=45095.796875MB; mem (CPU total)=44912.8515625MB
INFO:root:[   61] Training loss: 0.07268273, Validation loss: 0.17437976, Gradient norm: 0.98415616
INFO:root:At the start of the epoch: mem (CPU python)=45171.98828125MB; mem (CPU total)=44989.6328125MB
INFO:root:[   62] Training loss: 0.07309452, Validation loss: 0.19253309, Gradient norm: 1.10622395
INFO:root:At the start of the epoch: mem (CPU python)=45248.17578125MB; mem (CPU total)=45065.421875MB
INFO:root:[   63] Training loss: 0.07246517, Validation loss: 0.18627063, Gradient norm: 0.91711686
INFO:root:At the start of the epoch: mem (CPU python)=45324.37109375MB; mem (CPU total)=45141.73828125MB
INFO:root:[   64] Training loss: 0.07084394, Validation loss: 0.17983421, Gradient norm: 0.91891372
INFO:root:At the start of the epoch: mem (CPU python)=45400.5625MB; mem (CPU total)=45217.546875MB
INFO:root:[   65] Training loss: 0.07270239, Validation loss: 0.17959061, Gradient norm: 1.06890575
INFO:root:At the start of the epoch: mem (CPU python)=45476.75MB; mem (CPU total)=45293.5078125MB
INFO:root:[   66] Training loss: 0.07364303, Validation loss: 0.16006065, Gradient norm: 1.14264552
INFO:root:At the start of the epoch: mem (CPU python)=45552.94140625MB; mem (CPU total)=45370.2109375MB
INFO:root:[   67] Training loss: 0.07070521, Validation loss: 0.18123016, Gradient norm: 0.89334862
INFO:root:At the start of the epoch: mem (CPU python)=45629.1328125MB; mem (CPU total)=45446.234375MB
INFO:root:[   68] Training loss: 0.07220716, Validation loss: 0.17121084, Gradient norm: 1.16014329
INFO:root:At the start of the epoch: mem (CPU python)=45705.328125MB; mem (CPU total)=45522.5234375MB
INFO:root:[   69] Training loss: 0.07152175, Validation loss: 0.17552976, Gradient norm: 1.06652491
INFO:root:At the start of the epoch: mem (CPU python)=45781.51953125MB; mem (CPU total)=45599.0234375MB
INFO:root:[   70] Training loss: 0.07293577, Validation loss: 0.16503682, Gradient norm: 1.08241787
INFO:root:At the start of the epoch: mem (CPU python)=45857.70703125MB; mem (CPU total)=45674.4453125MB
INFO:root:[   71] Training loss: 0.06996509, Validation loss: 0.15917539, Gradient norm: 0.89322773
INFO:root:At the start of the epoch: mem (CPU python)=45933.8984375MB; mem (CPU total)=45751.86328125MB
INFO:root:[   72] Training loss: 0.07035510, Validation loss: 0.17793503, Gradient norm: 0.96540910
INFO:root:At the start of the epoch: mem (CPU python)=46010.0859375MB; mem (CPU total)=45827.87109375MB
INFO:root:[   73] Training loss: 0.07014182, Validation loss: 0.18438386, Gradient norm: 0.92292547
INFO:root:At the start of the epoch: mem (CPU python)=46086.28125MB; mem (CPU total)=45904.36328125MB
INFO:root:[   74] Training loss: 0.07569758, Validation loss: 0.17478518, Gradient norm: 1.25662785
INFO:root:At the start of the epoch: mem (CPU python)=46162.46875MB; mem (CPU total)=45980.859375MB
INFO:root:[   75] Training loss: 0.06992170, Validation loss: 0.17442468, Gradient norm: 0.91609241
INFO:root:At the start of the epoch: mem (CPU python)=46238.66015625MB; mem (CPU total)=46056.84375MB
INFO:root:[   76] Training loss: 0.07146318, Validation loss: 0.18795103, Gradient norm: 1.08999443
INFO:root:At the start of the epoch: mem (CPU python)=46314.85546875MB; mem (CPU total)=46133.0859375MB
INFO:root:[   77] Training loss: 0.06950578, Validation loss: 0.17838071, Gradient norm: 0.96532357
INFO:root:At the start of the epoch: mem (CPU python)=46391.04296875MB; mem (CPU total)=46208.80078125MB
INFO:root:[   78] Training loss: 0.07230302, Validation loss: 0.16454568, Gradient norm: 1.04505443
INFO:root:At the start of the epoch: mem (CPU python)=46467.234375MB; mem (CPU total)=46284.99609375MB
INFO:root:[   79] Training loss: 0.07143828, Validation loss: 0.17466480, Gradient norm: 0.99782199
INFO:root:At the start of the epoch: mem (CPU python)=46543.421875MB; mem (CPU total)=46361.51953125MB
INFO:root:[   80] Training loss: 0.07399623, Validation loss: 0.18941626, Gradient norm: 1.23885384
INFO:root:At the start of the epoch: mem (CPU python)=46619.61328125MB; mem (CPU total)=46437.484375MB
INFO:root:EP 80: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=46695.80859375MB; mem (CPU total)=46513.7109375MB
INFO:root:Training the model took 9181.569s.
INFO:root:Emptying the cuda cache took 0.041s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.1379
INFO:root:EnergyScoreTrain: 0.10209
INFO:root:CRPSTrain: 0.08004
INFO:root:Gaussian NLLTrain: -0.67929
INFO:root:CoverageTrain: 0.98342
INFO:root:IntervalWidthTrain: 0.70302
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.18448
INFO:root:EnergyScoreValidation: 0.13164
INFO:root:CRPSValidation: 0.10646
INFO:root:Gaussian NLLValidation: -0.33188
INFO:root:CoverageValidation: 0.90558
INFO:root:IntervalWidthValidation: 0.6676
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.18664
INFO:root:EnergyScoreTest: 0.13304
INFO:root:CRPSTest: 0.1078
INFO:root:Gaussian NLLTest: -0.32564
INFO:root:CoverageTest: 0.90338
INFO:root:IntervalWidthTest: 0.66842
INFO:root:After validation: mem (CPU python)=46781.1484375MB; mem (CPU total)=46600.91015625MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=46781.1484375MB; mem (CPU total)=46600.859375MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 58720256
INFO:root:After setting up the model: mem (CPU python)=46782.38671875MB; mem (CPU total)=46601.84375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=46782.38671875MB; mem (CPU total)=46601.8359375MB
INFO:root:[    1] Training loss: 0.27878415, Validation loss: 0.18461627, Gradient norm: 2.13123247
INFO:root:At the start of the epoch: mem (CPU python)=46858.6875MB; mem (CPU total)=46678.36328125MB
INFO:root:[    2] Training loss: 0.17797807, Validation loss: 0.21764609, Gradient norm: 2.14752214
INFO:root:At the start of the epoch: mem (CPU python)=46934.875MB; mem (CPU total)=46754.6171875MB
INFO:root:[    3] Training loss: 0.15977445, Validation loss: 0.17133084, Gradient norm: 1.88685797
INFO:root:At the start of the epoch: mem (CPU python)=47011.0703125MB; mem (CPU total)=46831.6640625MB
INFO:root:[    4] Training loss: 0.14552976, Validation loss: 0.15893876, Gradient norm: 1.73010592
INFO:root:At the start of the epoch: mem (CPU python)=47087.26171875MB; mem (CPU total)=46907.62109375MB
INFO:root:[    5] Training loss: 0.13186100, Validation loss: 0.17098319, Gradient norm: 1.34558699
INFO:root:At the start of the epoch: mem (CPU python)=47163.44921875MB; mem (CPU total)=46983.34375MB
INFO:root:[    6] Training loss: 0.13092191, Validation loss: 0.14869329, Gradient norm: 1.72165341
INFO:root:At the start of the epoch: mem (CPU python)=47239.640625MB; mem (CPU total)=47059.69921875MB
INFO:root:[    7] Training loss: 0.12831830, Validation loss: 0.14371242, Gradient norm: 1.75680232
INFO:root:At the start of the epoch: mem (CPU python)=47315.83203125MB; mem (CPU total)=47135.9765625MB
INFO:root:[    8] Training loss: 0.12671097, Validation loss: 0.14338645, Gradient norm: 1.91234507
INFO:root:At the start of the epoch: mem (CPU python)=47392.0234375MB; mem (CPU total)=47213.25MB
INFO:root:[    9] Training loss: 0.11925989, Validation loss: 0.15314032, Gradient norm: 1.34994671
INFO:root:At the start of the epoch: mem (CPU python)=47468.21484375MB; mem (CPU total)=47289.515625MB
INFO:root:[   10] Training loss: 0.11607357, Validation loss: 0.15231191, Gradient norm: 1.36539254
INFO:root:At the start of the epoch: mem (CPU python)=47544.40234375MB; mem (CPU total)=47365.77734375MB
INFO:root:[   11] Training loss: 0.11593401, Validation loss: 0.14491423, Gradient norm: 1.61426197
INFO:root:At the start of the epoch: mem (CPU python)=47620.59375MB; mem (CPU total)=47441.19140625MB
INFO:root:[   12] Training loss: 0.11022483, Validation loss: 0.13743650, Gradient norm: 1.26301063
INFO:root:At the start of the epoch: mem (CPU python)=47696.78515625MB; mem (CPU total)=47518.19921875MB
INFO:root:[   13] Training loss: 0.11098107, Validation loss: 0.13153819, Gradient norm: 1.34475550
INFO:root:At the start of the epoch: mem (CPU python)=47772.9765625MB; mem (CPU total)=47594.46484375MB
INFO:root:[   14] Training loss: 0.11002363, Validation loss: 0.12858129, Gradient norm: 1.40398789
INFO:root:At the start of the epoch: mem (CPU python)=47849.1640625MB; mem (CPU total)=47670.8359375MB
INFO:root:[   15] Training loss: 0.10916417, Validation loss: 0.13710644, Gradient norm: 1.62159718
INFO:root:At the start of the epoch: mem (CPU python)=47925.35546875MB; mem (CPU total)=47747.84765625MB
INFO:root:[   16] Training loss: 0.10507407, Validation loss: 0.13477177, Gradient norm: 1.14602623
INFO:root:At the start of the epoch: mem (CPU python)=48001.5546875MB; mem (CPU total)=47823.484375MB
INFO:root:[   17] Training loss: 0.10619835, Validation loss: 0.17384077, Gradient norm: 1.43413090
INFO:root:At the start of the epoch: mem (CPU python)=48077.7421875MB; mem (CPU total)=47900.12890625MB
INFO:root:[   18] Training loss: 0.10536764, Validation loss: 0.16071994, Gradient norm: 1.46392991
INFO:root:At the start of the epoch: mem (CPU python)=48153.93359375MB; mem (CPU total)=47976.41796875MB
INFO:root:[   19] Training loss: 0.10585947, Validation loss: 0.14788267, Gradient norm: 1.58316007
INFO:root:At the start of the epoch: mem (CPU python)=48230.12109375MB; mem (CPU total)=48052.52734375MB
INFO:root:[   20] Training loss: 0.10058717, Validation loss: 0.12906085, Gradient norm: 1.27728054
INFO:root:At the start of the epoch: mem (CPU python)=48306.31640625MB; mem (CPU total)=48128.640625MB
INFO:root:[   21] Training loss: 0.09729808, Validation loss: 0.13247602, Gradient norm: 1.07890205
INFO:root:At the start of the epoch: mem (CPU python)=48382.5078125MB; mem (CPU total)=48205.1796875MB
INFO:root:[   22] Training loss: 0.09931697, Validation loss: 0.15548339, Gradient norm: 1.23336044
INFO:root:At the start of the epoch: mem (CPU python)=48458.6953125MB; mem (CPU total)=48281.18359375MB
INFO:root:[   23] Training loss: 0.09801722, Validation loss: 0.13831443, Gradient norm: 1.34715725
INFO:root:At the start of the epoch: mem (CPU python)=48534.890625MB; mem (CPU total)=48357.5078125MB
INFO:root:[   24] Training loss: 0.09554475, Validation loss: 0.17719285, Gradient norm: 1.03968355
INFO:root:At the start of the epoch: mem (CPU python)=48611.078125MB; mem (CPU total)=48433.5703125MB
INFO:root:[   25] Training loss: 0.09801246, Validation loss: 0.16619603, Gradient norm: 1.31715691
INFO:root:At the start of the epoch: mem (CPU python)=48687.26953125MB; mem (CPU total)=48510.046875MB
INFO:root:[   26] Training loss: 0.09936923, Validation loss: 0.15643409, Gradient norm: 1.53460210
INFO:root:At the start of the epoch: mem (CPU python)=48763.4609375MB; mem (CPU total)=48586.828125MB
INFO:root:[   27] Training loss: 0.09124998, Validation loss: 0.15935884, Gradient norm: 1.08863599
INFO:root:At the start of the epoch: mem (CPU python)=48839.65234375MB; mem (CPU total)=48663.1171875MB
INFO:root:[   28] Training loss: 0.09202574, Validation loss: 0.16185879, Gradient norm: 1.26032281
INFO:root:At the start of the epoch: mem (CPU python)=48915.84765625MB; mem (CPU total)=48739.24609375MB
INFO:root:[   29] Training loss: 0.09179363, Validation loss: 0.16711830, Gradient norm: 1.45020792
INFO:root:At the start of the epoch: mem (CPU python)=48992.03515625MB; mem (CPU total)=48815.234375MB
INFO:root:[   30] Training loss: 0.09297551, Validation loss: 0.15425470, Gradient norm: 1.45962309
INFO:root:At the start of the epoch: mem (CPU python)=49068.2265625MB; mem (CPU total)=48890.94921875MB
INFO:root:[   31] Training loss: 0.09073049, Validation loss: 0.14655639, Gradient norm: 1.26724727
INFO:root:At the start of the epoch: mem (CPU python)=49144.41796875MB; mem (CPU total)=48967.45703125MB
INFO:root:[   32] Training loss: 0.09157822, Validation loss: 0.16965233, Gradient norm: 1.41249689
INFO:root:At the start of the epoch: mem (CPU python)=49220.609375MB; mem (CPU total)=49043.9296875MB
INFO:root:[   33] Training loss: 0.08669388, Validation loss: 0.19402631, Gradient norm: 0.98911257
INFO:root:At the start of the epoch: mem (CPU python)=49296.80078125MB; mem (CPU total)=49120.37109375MB
INFO:root:[   34] Training loss: 0.08692761, Validation loss: 0.16939630, Gradient norm: 1.12938711
INFO:root:At the start of the epoch: mem (CPU python)=49372.98828125MB; mem (CPU total)=49196.421875MB
INFO:root:[   35] Training loss: 0.08926158, Validation loss: 0.17225057, Gradient norm: 1.20874217
INFO:root:At the start of the epoch: mem (CPU python)=49449.1796875MB; mem (CPU total)=49272.6953125MB
INFO:root:[   36] Training loss: 0.08456195, Validation loss: 0.18285314, Gradient norm: 1.07075749
INFO:root:At the start of the epoch: mem (CPU python)=49525.37109375MB; mem (CPU total)=49349.41015625MB
INFO:root:[   37] Training loss: 0.08722370, Validation loss: 0.15273308, Gradient norm: 1.21306620
INFO:root:At the start of the epoch: mem (CPU python)=49601.5625MB; mem (CPU total)=49425.37890625MB
INFO:root:[   38] Training loss: 0.08524131, Validation loss: 0.17078152, Gradient norm: 1.25920227
INFO:root:At the start of the epoch: mem (CPU python)=49677.75390625MB; mem (CPU total)=49501.64453125MB
INFO:root:[   39] Training loss: 0.08624203, Validation loss: 0.17428589, Gradient norm: 1.38470006
INFO:root:At the start of the epoch: mem (CPU python)=49753.94140625MB; mem (CPU total)=49577.91015625MB
INFO:root:[   40] Training loss: 0.08354392, Validation loss: 0.15775720, Gradient norm: 1.13649835
INFO:root:At the start of the epoch: mem (CPU python)=49830.13671875MB; mem (CPU total)=49653.62890625MB
INFO:root:[   41] Training loss: 0.08192701, Validation loss: 0.17137838, Gradient norm: 1.05256082
INFO:root:At the start of the epoch: mem (CPU python)=49906.328125MB; mem (CPU total)=49729.87890625MB
INFO:root:[   42] Training loss: 0.08321788, Validation loss: 0.16499817, Gradient norm: 1.11278966
INFO:root:At the start of the epoch: mem (CPU python)=49982.51953125MB; mem (CPU total)=49806.109375MB
INFO:root:[   43] Training loss: 0.08002592, Validation loss: 0.18101646, Gradient norm: 0.95344168
INFO:root:At the start of the epoch: mem (CPU python)=50058.7109375MB; mem (CPU total)=49882.38671875MB
INFO:root:[   44] Training loss: 0.08187464, Validation loss: 0.17183756, Gradient norm: 1.22691638
INFO:root:At the start of the epoch: mem (CPU python)=50134.8984375MB; mem (CPU total)=49958.859375MB
INFO:root:[   45] Training loss: 0.07936827, Validation loss: 0.16753728, Gradient norm: 0.99294651
INFO:root:At the start of the epoch: mem (CPU python)=50211.08984375MB; mem (CPU total)=50035.1171875MB
INFO:root:[   46] Training loss: 0.07936128, Validation loss: 0.17607932, Gradient norm: 1.15652146
INFO:root:At the start of the epoch: mem (CPU python)=50287.28125MB; mem (CPU total)=50111.828125MB
INFO:root:[   47] Training loss: 0.08068925, Validation loss: 0.15047270, Gradient norm: 1.03158801
INFO:root:At the start of the epoch: mem (CPU python)=50363.47265625MB; mem (CPU total)=50187.83203125MB
INFO:root:[   48] Training loss: 0.07848695, Validation loss: 0.18203411, Gradient norm: 1.07974656
INFO:root:At the start of the epoch: mem (CPU python)=50439.66015625MB; mem (CPU total)=50263.5390625MB
INFO:root:[   49] Training loss: 0.07800839, Validation loss: 0.17362180, Gradient norm: 1.07046094
INFO:root:At the start of the epoch: mem (CPU python)=50515.8515625MB; mem (CPU total)=50340.5MB
INFO:root:[   50] Training loss: 0.07794448, Validation loss: 0.17033695, Gradient norm: 1.00539111
INFO:root:At the start of the epoch: mem (CPU python)=50592.046875MB; mem (CPU total)=50416.859375MB
INFO:root:[   51] Training loss: 0.07685559, Validation loss: 0.18007368, Gradient norm: 1.02994293
INFO:root:At the start of the epoch: mem (CPU python)=50668.234375MB; mem (CPU total)=50492.84375MB
INFO:root:[   52] Training loss: 0.07516399, Validation loss: 0.18493144, Gradient norm: 0.97535146
INFO:root:At the start of the epoch: mem (CPU python)=50744.42578125MB; mem (CPU total)=50568.97265625MB
INFO:root:[   53] Training loss: 0.07697414, Validation loss: 0.15048032, Gradient norm: 1.02568419
INFO:root:At the start of the epoch: mem (CPU python)=50820.61328125MB; mem (CPU total)=50645.43359375MB
INFO:root:[   54] Training loss: 0.07885419, Validation loss: 0.16472862, Gradient norm: 1.24489221
INFO:root:At the start of the epoch: mem (CPU python)=50896.80859375MB; mem (CPU total)=50721.9296875MB
INFO:root:[   55] Training loss: 0.07487117, Validation loss: 0.15886401, Gradient norm: 0.95170301
INFO:root:At the start of the epoch: mem (CPU python)=50973.0MB; mem (CPU total)=50798.37109375MB
INFO:root:[   56] Training loss: 0.07616789, Validation loss: 0.15528778, Gradient norm: 1.16376813
INFO:root:At the start of the epoch: mem (CPU python)=51049.1875MB; mem (CPU total)=50874.16015625MB
INFO:root:[   57] Training loss: 0.07363862, Validation loss: 0.16857206, Gradient norm: 1.00270877
INFO:root:At the start of the epoch: mem (CPU python)=51125.37890625MB; mem (CPU total)=50950.421875MB
INFO:root:[   58] Training loss: 0.07706517, Validation loss: 0.16085106, Gradient norm: 1.14694056
INFO:root:At the start of the epoch: mem (CPU python)=51201.56640625MB; mem (CPU total)=51028.31640625MB
INFO:root:[   59] Training loss: 0.07597403, Validation loss: 0.17159324, Gradient norm: 1.10607277
INFO:root:At the start of the epoch: mem (CPU python)=51277.76171875MB; mem (CPU total)=51104.421875MB
INFO:root:[   60] Training loss: 0.07297094, Validation loss: 0.17192913, Gradient norm: 0.86373118
INFO:root:At the start of the epoch: mem (CPU python)=51353.953125MB; mem (CPU total)=51180.375MB
INFO:root:[   61] Training loss: 0.07421458, Validation loss: 0.16880063, Gradient norm: 1.07256883
INFO:root:At the start of the epoch: mem (CPU python)=51430.140625MB; mem (CPU total)=51256.875MB
INFO:root:[   62] Training loss: 0.07416872, Validation loss: 0.18086267, Gradient norm: 1.09709952
INFO:root:At the start of the epoch: mem (CPU python)=51506.33203125MB; mem (CPU total)=51333.04296875MB
INFO:root:EP 62: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=51582.51953125MB; mem (CPU total)=51409.27734375MB
INFO:root:Training the model took 7535.057s.
INFO:root:Emptying the cuda cache took 0.034s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.14087
INFO:root:EnergyScoreTrain: 0.10557
INFO:root:CRPSTrain: 0.08371
INFO:root:Gaussian NLLTrain: -0.61791
INFO:root:CoverageTrain: 0.98476
INFO:root:IntervalWidthTrain: 0.76184
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.18097
INFO:root:EnergyScoreValidation: 0.12915
INFO:root:CRPSValidation: 0.10399
INFO:root:Gaussian NLLValidation: -0.36547
INFO:root:CoverageValidation: 0.93124
INFO:root:IntervalWidthValidation: 0.71657
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.18212
INFO:root:EnergyScoreTest: 0.13008
INFO:root:CRPSTest: 0.105
INFO:root:Gaussian NLLTest: -0.36195
INFO:root:CoverageTest: 0.92944
INFO:root:IntervalWidthTest: 0.71658
INFO:root:After validation: mem (CPU python)=51667.81640625MB; mem (CPU total)=51493.83984375MB
