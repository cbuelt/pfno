INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.2734375MB; mem (CPU total)=1018.3671875MB
INFO:root:############### Starting experiment with config file darcy_flow/fno_laplace.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'DarcyFlow', 'max_training_set_size': 10000, 'downscaling_factor': 2}
INFO:root:After loading the datasets: mem (CPU python)=1995.390625MB; mem (CPU total)=1029.66015625MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=1995.390625MB; mem (CPU total)=1029.66015625MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 4194304
INFO:root:After setting up the model: mem (CPU python)=2207.0625MB; mem (CPU total)=2407.84765625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2216.31640625MB; mem (CPU total)=2416.70703125MB
INFO:root:[    1] Training loss: 0.38991352, Validation loss: 0.27796870, Gradient norm: 0.95571053
INFO:root:At the start of the epoch: mem (CPU python)=4460.84375MB; mem (CPU total)=4203.47265625MB
INFO:root:[    2] Training loss: 0.16514801, Validation loss: 0.21844068, Gradient norm: 1.38886810
INFO:root:At the start of the epoch: mem (CPU python)=4537.75390625MB; mem (CPU total)=4279.3046875MB
INFO:root:[    3] Training loss: 0.13221800, Validation loss: 0.20108069, Gradient norm: 0.98578652
INFO:root:At the start of the epoch: mem (CPU python)=4614.0078125MB; mem (CPU total)=4355.59765625MB
INFO:root:[    4] Training loss: 0.12303841, Validation loss: 0.19429137, Gradient norm: 1.07457234
INFO:root:At the start of the epoch: mem (CPU python)=4690.1015625MB; mem (CPU total)=4431.921875MB
INFO:root:[    5] Training loss: 0.10810568, Validation loss: 0.16716599, Gradient norm: 0.85620389
INFO:root:At the start of the epoch: mem (CPU python)=4766.421875MB; mem (CPU total)=4509.0390625MB
INFO:root:[    6] Training loss: 0.10912348, Validation loss: 0.16176776, Gradient norm: 1.15925634
INFO:root:At the start of the epoch: mem (CPU python)=4842.63671875MB; mem (CPU total)=4585.546875MB
INFO:root:[    7] Training loss: 0.09707055, Validation loss: 0.15840400, Gradient norm: 0.78791570
INFO:root:At the start of the epoch: mem (CPU python)=4918.85546875MB; mem (CPU total)=4661.93359375MB
INFO:root:[    8] Training loss: 0.09667051, Validation loss: 0.15001835, Gradient norm: 0.87983162
INFO:root:At the start of the epoch: mem (CPU python)=4995.0703125MB; mem (CPU total)=4737.91015625MB
INFO:root:[    9] Training loss: 0.09490793, Validation loss: 0.15224763, Gradient norm: 0.94679201
INFO:root:At the start of the epoch: mem (CPU python)=5071.28515625MB; mem (CPU total)=4813.76171875MB
INFO:root:[   10] Training loss: 0.09201893, Validation loss: 0.14564423, Gradient norm: 0.92246763
INFO:root:At the start of the epoch: mem (CPU python)=5147.5MB; mem (CPU total)=4890.00390625MB
INFO:root:[   11] Training loss: 0.08874866, Validation loss: 0.14634898, Gradient norm: 0.83887016
INFO:root:At the start of the epoch: mem (CPU python)=5223.7109375MB; mem (CPU total)=4966.265625MB
INFO:root:[   12] Training loss: 0.08935735, Validation loss: 0.14233287, Gradient norm: 0.88781909
INFO:root:At the start of the epoch: mem (CPU python)=5299.92578125MB; mem (CPU total)=5042.87109375MB
INFO:root:[   13] Training loss: 0.08532614, Validation loss: 0.14267116, Gradient norm: 0.73245600
INFO:root:At the start of the epoch: mem (CPU python)=5376.140625MB; mem (CPU total)=5118.921875MB
INFO:root:[   14] Training loss: 0.08636781, Validation loss: 0.14451499, Gradient norm: 0.96674822
INFO:root:At the start of the epoch: mem (CPU python)=5452.34765625MB; mem (CPU total)=5195.82421875MB
INFO:root:[   15] Training loss: 0.08386355, Validation loss: 0.13842720, Gradient norm: 0.89591465
INFO:root:At the start of the epoch: mem (CPU python)=5528.5625MB; mem (CPU total)=5272.203125MB
INFO:root:[   16] Training loss: 0.08101245, Validation loss: 0.14042798, Gradient norm: 0.80854721
INFO:root:At the start of the epoch: mem (CPU python)=5604.76953125MB; mem (CPU total)=5348.4375MB
INFO:root:[   17] Training loss: 0.07985211, Validation loss: 0.13803378, Gradient norm: 0.77035344
INFO:root:At the start of the epoch: mem (CPU python)=5680.96484375MB; mem (CPU total)=5425.046875MB
INFO:root:[   18] Training loss: 0.07883531, Validation loss: 0.13678140, Gradient norm: 0.78800835
INFO:root:At the start of the epoch: mem (CPU python)=5757.1953125MB; mem (CPU total)=5501.328125MB
INFO:root:[   19] Training loss: 0.07801739, Validation loss: 0.13114244, Gradient norm: 0.76290977
INFO:root:At the start of the epoch: mem (CPU python)=5833.38671875MB; mem (CPU total)=5577.390625MB
INFO:root:[   20] Training loss: 0.07484276, Validation loss: 0.14000230, Gradient norm: 0.73342521
INFO:root:At the start of the epoch: mem (CPU python)=5909.5859375MB; mem (CPU total)=5653.80078125MB
INFO:root:[   21] Training loss: 0.07404578, Validation loss: 0.12726707, Gradient norm: 0.75984278
INFO:root:At the start of the epoch: mem (CPU python)=5985.78125MB; mem (CPU total)=5730.3359375MB
INFO:root:[   22] Training loss: 0.07255014, Validation loss: 0.12962911, Gradient norm: 0.66001574
INFO:root:At the start of the epoch: mem (CPU python)=6061.97265625MB; mem (CPU total)=5806.70703125MB
INFO:root:[   23] Training loss: 0.07166808, Validation loss: 0.13222972, Gradient norm: 0.65478547
INFO:root:At the start of the epoch: mem (CPU python)=6138.16796875MB; mem (CPU total)=5883.046875MB
INFO:root:[   24] Training loss: 0.07147933, Validation loss: 0.13033154, Gradient norm: 0.76780068
INFO:root:At the start of the epoch: mem (CPU python)=6214.37109375MB; mem (CPU total)=5959.31640625MB
INFO:root:[   25] Training loss: 0.07008541, Validation loss: 0.13473550, Gradient norm: 0.65323281
INFO:root:At the start of the epoch: mem (CPU python)=6290.578125MB; mem (CPU total)=6035.66015625MB
INFO:root:[   26] Training loss: 0.06796395, Validation loss: 0.12217526, Gradient norm: 0.58600385
INFO:root:At the start of the epoch: mem (CPU python)=6366.76953125MB; mem (CPU total)=6112.25MB
INFO:root:[   27] Training loss: 0.07052559, Validation loss: 0.12648917, Gradient norm: 0.84006900
INFO:root:At the start of the epoch: mem (CPU python)=6442.96875MB; mem (CPU total)=6188.3671875MB
INFO:root:[   28] Training loss: 0.06567704, Validation loss: 0.11822331, Gradient norm: 0.58339906
INFO:root:At the start of the epoch: mem (CPU python)=6519.16015625MB; mem (CPU total)=6264.8984375MB
INFO:root:[   29] Training loss: 0.06637116, Validation loss: 0.13924947, Gradient norm: 0.74665827
INFO:root:At the start of the epoch: mem (CPU python)=6595.35546875MB; mem (CPU total)=6341.0234375MB
INFO:root:[   30] Training loss: 0.06531551, Validation loss: 0.12118484, Gradient norm: 0.63571786
INFO:root:At the start of the epoch: mem (CPU python)=6671.55078125MB; mem (CPU total)=6417.50390625MB
INFO:root:[   31] Training loss: 0.06647468, Validation loss: 0.11931730, Gradient norm: 0.70571793
INFO:root:At the start of the epoch: mem (CPU python)=6747.7421875MB; mem (CPU total)=6493.53515625MB
INFO:root:[   32] Training loss: 0.06396729, Validation loss: 0.11850942, Gradient norm: 0.67685597
INFO:root:At the start of the epoch: mem (CPU python)=6823.9453125MB; mem (CPU total)=6570.16796875MB
INFO:root:[   33] Training loss: 0.06731036, Validation loss: 0.11787997, Gradient norm: 0.87258688
INFO:root:At the start of the epoch: mem (CPU python)=6900.140625MB; mem (CPU total)=6645.42578125MB
INFO:root:[   34] Training loss: 0.06165210, Validation loss: 0.11942930, Gradient norm: 0.59581429
INFO:root:At the start of the epoch: mem (CPU python)=6976.34375MB; mem (CPU total)=6721.35546875MB
INFO:root:[   35] Training loss: 0.06178906, Validation loss: 0.13132145, Gradient norm: 0.66719801
INFO:root:At the start of the epoch: mem (CPU python)=7052.53515625MB; mem (CPU total)=6800.2265625MB
INFO:root:[   36] Training loss: 0.06173861, Validation loss: 0.11970180, Gradient norm: 0.70828739
INFO:root:At the start of the epoch: mem (CPU python)=7128.71875MB; mem (CPU total)=6875.29296875MB
INFO:root:[   37] Training loss: 0.06022683, Validation loss: 0.11936115, Gradient norm: 0.56718892
INFO:root:At the start of the epoch: mem (CPU python)=7204.921875MB; mem (CPU total)=6951.7109375MB
INFO:root:[   38] Training loss: 0.05872732, Validation loss: 0.11657511, Gradient norm: 0.55021966
INFO:root:At the start of the epoch: mem (CPU python)=7281.12109375MB; mem (CPU total)=7027.98828125MB
INFO:root:[   39] Training loss: 0.06039434, Validation loss: 0.12551535, Gradient norm: 0.68846397
INFO:root:At the start of the epoch: mem (CPU python)=7357.3203125MB; mem (CPU total)=7103.7109375MB
INFO:root:[   40] Training loss: 0.05777672, Validation loss: 0.11977996, Gradient norm: 0.51362725
INFO:root:At the start of the epoch: mem (CPU python)=7433.53125MB; mem (CPU total)=7180.19921875MB
INFO:root:[   41] Training loss: 0.05696276, Validation loss: 0.12247625, Gradient norm: 0.53496426
INFO:root:At the start of the epoch: mem (CPU python)=7509.72265625MB; mem (CPU total)=7256.44140625MB
INFO:root:[   42] Training loss: 0.05765667, Validation loss: 0.11091047, Gradient norm: 0.67332115
INFO:root:At the start of the epoch: mem (CPU python)=7585.93359375MB; mem (CPU total)=7332.84375MB
INFO:root:[   43] Training loss: 0.05562857, Validation loss: 0.12386610, Gradient norm: 0.54323265
INFO:root:At the start of the epoch: mem (CPU python)=7662.1328125MB; mem (CPU total)=7409.1484375MB
INFO:root:[   44] Training loss: 0.05536887, Validation loss: 0.11340338, Gradient norm: 0.55460703
INFO:root:At the start of the epoch: mem (CPU python)=7738.3359375MB; mem (CPU total)=7485.4921875MB
INFO:root:[   45] Training loss: 0.05554911, Validation loss: 0.13038888, Gradient norm: 0.57373307
INFO:root:At the start of the epoch: mem (CPU python)=7814.55859375MB; mem (CPU total)=7562.18359375MB
INFO:root:[   46] Training loss: 0.05684272, Validation loss: 0.11162058, Gradient norm: 0.69325431
INFO:root:At the start of the epoch: mem (CPU python)=7890.7578125MB; mem (CPU total)=7638.19140625MB
INFO:root:[   47] Training loss: 0.05391775, Validation loss: 0.11442736, Gradient norm: 0.53645165
INFO:root:At the start of the epoch: mem (CPU python)=7966.94921875MB; mem (CPU total)=7714.6484375MB
INFO:root:[   48] Training loss: 0.05532062, Validation loss: 0.10879785, Gradient norm: 0.68499963
INFO:root:At the start of the epoch: mem (CPU python)=8043.14453125MB; mem (CPU total)=7790.55078125MB
INFO:root:[   49] Training loss: 0.05454866, Validation loss: 0.11292997, Gradient norm: 0.60778374
INFO:root:At the start of the epoch: mem (CPU python)=8119.34375MB; mem (CPU total)=7866.9140625MB
INFO:root:[   50] Training loss: 0.05309926, Validation loss: 0.11303749, Gradient norm: 0.51781592
INFO:root:At the start of the epoch: mem (CPU python)=8195.53515625MB; mem (CPU total)=7943.58203125MB
INFO:root:[   51] Training loss: 0.05256307, Validation loss: 0.11134048, Gradient norm: 0.60252903
INFO:root:At the start of the epoch: mem (CPU python)=8271.73046875MB; mem (CPU total)=8020.265625MB
INFO:root:[   52] Training loss: 0.05206878, Validation loss: 0.11647471, Gradient norm: 0.51142246
INFO:root:At the start of the epoch: mem (CPU python)=8347.91796875MB; mem (CPU total)=8096.16015625MB
INFO:root:[   53] Training loss: 0.05270820, Validation loss: 0.11630291, Gradient norm: 0.66013505
INFO:root:At the start of the epoch: mem (CPU python)=8424.109375MB; mem (CPU total)=8172.19921875MB
INFO:root:[   54] Training loss: 0.05137216, Validation loss: 0.11945362, Gradient norm: 0.54386096
INFO:root:At the start of the epoch: mem (CPU python)=8500.3046875MB; mem (CPU total)=8248.4765625MB
INFO:root:[   55] Training loss: 0.05523594, Validation loss: 0.11541584, Gradient norm: 0.74231661
INFO:root:At the start of the epoch: mem (CPU python)=8576.49609375MB; mem (CPU total)=8325.0078125MB
INFO:root:[   56] Training loss: 0.05049570, Validation loss: 0.11152564, Gradient norm: 0.50117686
INFO:root:At the start of the epoch: mem (CPU python)=8652.68359375MB; mem (CPU total)=8401.21875MB
INFO:root:[   57] Training loss: 0.05056697, Validation loss: 0.11549464, Gradient norm: 0.52034046
INFO:root:At the start of the epoch: mem (CPU python)=8728.87890625MB; mem (CPU total)=8477.23828125MB
INFO:root:[   58] Training loss: 0.04997329, Validation loss: 0.11419340, Gradient norm: 0.53640593
INFO:root:At the start of the epoch: mem (CPU python)=8805.06640625MB; mem (CPU total)=8553.30859375MB
INFO:root:[   59] Training loss: 0.04947031, Validation loss: 0.11844569, Gradient norm: 0.50505820
INFO:root:At the start of the epoch: mem (CPU python)=8881.2578125MB; mem (CPU total)=8629.5859375MB
INFO:root:[   60] Training loss: 0.04932181, Validation loss: 0.11278956, Gradient norm: 0.52118336
INFO:root:At the start of the epoch: mem (CPU python)=8957.4453125MB; mem (CPU total)=8706.3515625MB
INFO:root:[   61] Training loss: 0.04945076, Validation loss: 0.11301197, Gradient norm: 0.56985064
INFO:root:At the start of the epoch: mem (CPU python)=9033.6328125MB; mem (CPU total)=8782.6328125MB
INFO:root:[   62] Training loss: 0.04912875, Validation loss: 0.11091970, Gradient norm: 0.58677514
INFO:root:At the start of the epoch: mem (CPU python)=9109.828125MB; mem (CPU total)=8858.9375MB
INFO:root:[   63] Training loss: 0.04965670, Validation loss: 0.11380953, Gradient norm: 0.59862769
INFO:root:At the start of the epoch: mem (CPU python)=9186.015625MB; mem (CPU total)=8935.2421875MB
INFO:root:[   64] Training loss: 0.04991645, Validation loss: 0.10931465, Gradient norm: 0.58324224
INFO:root:At the start of the epoch: mem (CPU python)=9262.2109375MB; mem (CPU total)=9011.53125MB
INFO:root:[   65] Training loss: 0.05007828, Validation loss: 0.11177470, Gradient norm: 0.63352567
INFO:root:At the start of the epoch: mem (CPU python)=9338.39453125MB; mem (CPU total)=9088.05859375MB
INFO:root:[   66] Training loss: 0.04781183, Validation loss: 0.11504098, Gradient norm: 0.52012868
INFO:root:At the start of the epoch: mem (CPU python)=9414.58984375MB; mem (CPU total)=9164.34375MB
INFO:root:[   67] Training loss: 0.04698919, Validation loss: 0.11240776, Gradient norm: 0.47241108
INFO:root:At the start of the epoch: mem (CPU python)=9490.78125MB; mem (CPU total)=9240.62109375MB
INFO:root:[   68] Training loss: 0.04778346, Validation loss: 0.10833067, Gradient norm: 0.50415481
INFO:root:At the start of the epoch: mem (CPU python)=9566.97265625MB; mem (CPU total)=9317.18359375MB
INFO:root:[   69] Training loss: 0.04783537, Validation loss: 0.12475928, Gradient norm: 0.62713285
INFO:root:At the start of the epoch: mem (CPU python)=9643.1640625MB; mem (CPU total)=9393.22265625MB
INFO:root:[   70] Training loss: 0.04917102, Validation loss: 0.11337093, Gradient norm: 0.72448052
INFO:root:At the start of the epoch: mem (CPU python)=9719.3515625MB; mem (CPU total)=9469.7578125MB
INFO:root:[   71] Training loss: 0.04768164, Validation loss: 0.10464904, Gradient norm: 0.56759199
INFO:root:At the start of the epoch: mem (CPU python)=9795.54296875MB; mem (CPU total)=9546.29296875MB
INFO:root:[   72] Training loss: 0.04670719, Validation loss: 0.10723275, Gradient norm: 0.48183783
INFO:root:At the start of the epoch: mem (CPU python)=9871.734375MB; mem (CPU total)=9621.62109375MB
INFO:root:[   73] Training loss: 0.04512453, Validation loss: 0.11165888, Gradient norm: 0.48243330
INFO:root:At the start of the epoch: mem (CPU python)=9947.921875MB; mem (CPU total)=9698.19921875MB
INFO:root:[   74] Training loss: 0.04595215, Validation loss: 0.11003471, Gradient norm: 0.51697131
INFO:root:At the start of the epoch: mem (CPU python)=10024.12109375MB; mem (CPU total)=9774.75MB
INFO:root:[   75] Training loss: 0.04496376, Validation loss: 0.10660652, Gradient norm: 0.50139415
INFO:root:At the start of the epoch: mem (CPU python)=10100.30859375MB; mem (CPU total)=9850.78125MB
INFO:root:[   76] Training loss: 0.04494818, Validation loss: 0.10743940, Gradient norm: 0.46196751
INFO:root:At the start of the epoch: mem (CPU python)=10176.5MB; mem (CPU total)=9927.53125MB
INFO:root:[   77] Training loss: 0.04441912, Validation loss: 0.10457291, Gradient norm: 0.44552544
INFO:root:At the start of the epoch: mem (CPU python)=10252.6875MB; mem (CPU total)=10003.8515625MB
INFO:root:[   78] Training loss: 0.04584872, Validation loss: 0.11505570, Gradient norm: 0.57508988
INFO:root:At the start of the epoch: mem (CPU python)=10328.8828125MB; mem (CPU total)=10080.140625MB
INFO:root:[   79] Training loss: 0.04887908, Validation loss: 0.10484274, Gradient norm: 0.69397118
INFO:root:At the start of the epoch: mem (CPU python)=10405.07421875MB; mem (CPU total)=10156.4296875MB
INFO:root:[   80] Training loss: 0.04395625, Validation loss: 0.10529291, Gradient norm: 0.45003906
INFO:root:At the start of the epoch: mem (CPU python)=10481.26171875MB; mem (CPU total)=10232.96484375MB
INFO:root:[   81] Training loss: 0.04350969, Validation loss: 0.10483926, Gradient norm: 0.41140079
INFO:root:At the start of the epoch: mem (CPU python)=10557.453125MB; mem (CPU total)=10309.25390625MB
INFO:root:[   82] Training loss: 0.04432248, Validation loss: 0.11697608, Gradient norm: 0.48459579
INFO:root:At the start of the epoch: mem (CPU python)=10633.64453125MB; mem (CPU total)=10385.5234375MB
INFO:root:[   83] Training loss: 0.04462318, Validation loss: 0.10745949, Gradient norm: 0.57077791
INFO:root:At the start of the epoch: mem (CPU python)=10709.8359375MB; mem (CPU total)=10461.81640625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   84] Training loss: 0.04445702, Validation loss: 0.10715529, Gradient norm: 0.49041726
INFO:root:At the start of the epoch: mem (CPU python)=10786.02734375MB; mem (CPU total)=10538.39453125MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   85] Training loss: 0.04058032, Validation loss: 0.10697436, Gradient norm: 0.34764278
INFO:root:At the start of the epoch: mem (CPU python)=10862.21484375MB; mem (CPU total)=10614.58203125MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   86] Training loss: 0.03917506, Validation loss: 0.11131333, Gradient norm: 0.28948973
INFO:root:At the start of the epoch: mem (CPU python)=10938.41015625MB; mem (CPU total)=10690.86328125MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:EP 86: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=11014.59765625MB; mem (CPU total)=10766.69140625MB
INFO:root:Training the model took 3293.959s.
INFO:root:Emptying the cuda cache took 0.026s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09273
INFO:root:EnergyScoreTrain: 0.04699
INFO:root:CRPSTrain: 0.0382
INFO:root:Gaussian NLLTrain: 2.18111
INFO:root:CoverageTrain: 0.72186
INFO:root:IntervalWidthTrain: 0.25377
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.13938
INFO:root:EnergyScoreValidation: 0.0818
INFO:root:CRPSValidation: 0.066
INFO:root:Gaussian NLLValidation: 8.17132
INFO:root:CoverageValidation: 0.56707
INFO:root:IntervalWidthValidation: 0.23704
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.14402
INFO:root:EnergyScoreTest: 0.08784
INFO:root:CRPSTest: 0.071
INFO:root:Gaussian NLLTest: 9.15905
INFO:root:CoverageTest: 0.55647
INFO:root:IntervalWidthTest: 0.22621
INFO:root:After validation: mem (CPU python)=11486.96875MB; mem (CPU total)=11102.859375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=11486.97265625MB; mem (CPU total)=11102.8515625MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 308281344
INFO:root:After setting up the model: mem (CPU python)=11488.18359375MB; mem (CPU total)=11104.078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=11488.18359375MB; mem (CPU total)=11104.078125MB
INFO:root:[    1] Training loss: 0.39206239, Validation loss: 0.26088762, Gradient norm: 1.05087369
INFO:root:At the start of the epoch: mem (CPU python)=11584.265625MB; mem (CPU total)=11200.65625MB
INFO:root:[    2] Training loss: 0.16959116, Validation loss: 0.21328078, Gradient norm: 1.45302052
INFO:root:At the start of the epoch: mem (CPU python)=11660.66015625MB; mem (CPU total)=11277.20703125MB
INFO:root:[    3] Training loss: 0.14337937, Validation loss: 0.17408393, Gradient norm: 1.43142002
INFO:root:At the start of the epoch: mem (CPU python)=11736.8671875MB; mem (CPU total)=11353.703125MB
INFO:root:[    4] Training loss: 0.13044897, Validation loss: 0.16111357, Gradient norm: 1.40903547
INFO:root:At the start of the epoch: mem (CPU python)=11813.07421875MB; mem (CPU total)=11430.203125MB
INFO:root:[    5] Training loss: 0.11267104, Validation loss: 0.14488946, Gradient norm: 0.90442543
INFO:root:At the start of the epoch: mem (CPU python)=11889.28125MB; mem (CPU total)=11506.51953125MB
INFO:root:[    6] Training loss: 0.10629590, Validation loss: 0.13905013, Gradient norm: 0.97605312
INFO:root:At the start of the epoch: mem (CPU python)=11965.484375MB; mem (CPU total)=11583.0546875MB
INFO:root:[    7] Training loss: 0.10124422, Validation loss: 0.14685018, Gradient norm: 0.94889458
INFO:root:At the start of the epoch: mem (CPU python)=12041.69921875MB; mem (CPU total)=11659.5546875MB
INFO:root:[    8] Training loss: 0.09747013, Validation loss: 0.13139193, Gradient norm: 0.91047373
INFO:root:At the start of the epoch: mem (CPU python)=12117.91015625MB; mem (CPU total)=11736.3671875MB
INFO:root:[    9] Training loss: 0.09415332, Validation loss: 0.12529556, Gradient norm: 0.93572652
INFO:root:At the start of the epoch: mem (CPU python)=12194.11328125MB; mem (CPU total)=11812.4296875MB
INFO:root:[   10] Training loss: 0.09306473, Validation loss: 0.14103523, Gradient norm: 0.93773224
INFO:root:At the start of the epoch: mem (CPU python)=12270.33203125MB; mem (CPU total)=11888.703125MB
INFO:root:[   11] Training loss: 0.08972768, Validation loss: 0.11873547, Gradient norm: 0.85424534
INFO:root:At the start of the epoch: mem (CPU python)=12346.51953125MB; mem (CPU total)=11965.25390625MB
INFO:root:[   12] Training loss: 0.08695034, Validation loss: 0.12044960, Gradient norm: 0.81161421
INFO:root:At the start of the epoch: mem (CPU python)=12422.71484375MB; mem (CPU total)=12041.53515625MB
INFO:root:[   13] Training loss: 0.08538603, Validation loss: 0.11623889, Gradient norm: 0.78659697
INFO:root:At the start of the epoch: mem (CPU python)=12498.90234375MB; mem (CPU total)=12118.1015625MB
INFO:root:[   14] Training loss: 0.08617177, Validation loss: 0.11232568, Gradient norm: 0.95364624
INFO:root:At the start of the epoch: mem (CPU python)=12575.09375MB; mem (CPU total)=12193.8984375MB
INFO:root:[   15] Training loss: 0.08418863, Validation loss: 0.10576230, Gradient norm: 0.84992022
INFO:root:At the start of the epoch: mem (CPU python)=12651.28515625MB; mem (CPU total)=12270.21484375MB
INFO:root:[   16] Training loss: 0.08182212, Validation loss: 0.10912428, Gradient norm: 0.91748619
INFO:root:At the start of the epoch: mem (CPU python)=12727.47265625MB; mem (CPU total)=12346.23828125MB
INFO:root:[   17] Training loss: 0.08076807, Validation loss: 0.11918591, Gradient norm: 0.84284845
INFO:root:At the start of the epoch: mem (CPU python)=12803.66796875MB; mem (CPU total)=12422.75390625MB
INFO:root:[   18] Training loss: 0.07833574, Validation loss: 0.11835425, Gradient norm: 0.85470755
INFO:root:At the start of the epoch: mem (CPU python)=12879.85546875MB; mem (CPU total)=12499.2890625MB
INFO:root:[   19] Training loss: 0.07543866, Validation loss: 0.10674122, Gradient norm: 0.66998475
INFO:root:At the start of the epoch: mem (CPU python)=12956.046875MB; mem (CPU total)=12575.3125MB
INFO:root:[   20] Training loss: 0.07512072, Validation loss: 0.10596227, Gradient norm: 0.77616925
INFO:root:At the start of the epoch: mem (CPU python)=13032.23828125MB; mem (CPU total)=12651.58984375MB
INFO:root:[   21] Training loss: 0.07482286, Validation loss: 0.10149987, Gradient norm: 0.85660497
INFO:root:At the start of the epoch: mem (CPU python)=13108.42578125MB; mem (CPU total)=12726.625MB
INFO:root:[   22] Training loss: 0.07133599, Validation loss: 0.12317679, Gradient norm: 0.65254393
INFO:root:At the start of the epoch: mem (CPU python)=13184.62109375MB; mem (CPU total)=12802.63671875MB
INFO:root:[   23] Training loss: 0.07244984, Validation loss: 0.10334053, Gradient norm: 0.85152297
INFO:root:At the start of the epoch: mem (CPU python)=13260.80859375MB; mem (CPU total)=12879.37890625MB
INFO:root:[   24] Training loss: 0.07030846, Validation loss: 0.11182375, Gradient norm: 0.70001136
INFO:root:At the start of the epoch: mem (CPU python)=13337.0MB; mem (CPU total)=12955.40234375MB
INFO:root:[   25] Training loss: 0.07216203, Validation loss: 0.10314561, Gradient norm: 0.86692342
INFO:root:At the start of the epoch: mem (CPU python)=13413.1953125MB; mem (CPU total)=13031.92578125MB
INFO:root:[   26] Training loss: 0.06912980, Validation loss: 0.09624208, Gradient norm: 0.73257118
INFO:root:At the start of the epoch: mem (CPU python)=13489.3828125MB; mem (CPU total)=13108.484375MB
INFO:root:[   27] Training loss: 0.06850163, Validation loss: 0.10693108, Gradient norm: 0.68533999
INFO:root:At the start of the epoch: mem (CPU python)=13565.57421875MB; mem (CPU total)=13184.5MB
INFO:root:[   28] Training loss: 0.07096796, Validation loss: 0.12351625, Gradient norm: 0.88812799
INFO:root:At the start of the epoch: mem (CPU python)=13641.76171875MB; mem (CPU total)=13260.9921875MB
INFO:root:[   29] Training loss: 0.06662509, Validation loss: 0.10387102, Gradient norm: 0.74407080
INFO:root:At the start of the epoch: mem (CPU python)=13717.953125MB; mem (CPU total)=13337.26171875MB
INFO:root:[   30] Training loss: 0.06354681, Validation loss: 0.10961962, Gradient norm: 0.52678310
INFO:root:At the start of the epoch: mem (CPU python)=13794.140625MB; mem (CPU total)=13413.546875MB
INFO:root:[   31] Training loss: 0.06456661, Validation loss: 0.11089676, Gradient norm: 0.70437647
INFO:root:At the start of the epoch: mem (CPU python)=13870.3359375MB; mem (CPU total)=13490.3125MB
INFO:root:[   32] Training loss: 0.06191946, Validation loss: 0.09450963, Gradient norm: 0.55829678
INFO:root:At the start of the epoch: mem (CPU python)=13946.52734375MB; mem (CPU total)=13566.40234375MB
INFO:root:[   33] Training loss: 0.06451747, Validation loss: 0.11305141, Gradient norm: 0.78711601
INFO:root:At the start of the epoch: mem (CPU python)=14022.71875MB; mem (CPU total)=13642.65234375MB
INFO:root:[   34] Training loss: 0.06161364, Validation loss: 0.10601719, Gradient norm: 0.61606728
INFO:root:At the start of the epoch: mem (CPU python)=14098.91015625MB; mem (CPU total)=13718.91796875MB
INFO:root:[   35] Training loss: 0.06109170, Validation loss: 0.10183588, Gradient norm: 0.68947921
INFO:root:At the start of the epoch: mem (CPU python)=14175.1015625MB; mem (CPU total)=13795.68359375MB
INFO:root:[   36] Training loss: 0.05901918, Validation loss: 0.09460458, Gradient norm: 0.60224763
INFO:root:At the start of the epoch: mem (CPU python)=14251.29296875MB; mem (CPU total)=13871.69921875MB
INFO:root:[   37] Training loss: 0.05911933, Validation loss: 0.10026709, Gradient norm: 0.61322746
INFO:root:At the start of the epoch: mem (CPU python)=14327.48828125MB; mem (CPU total)=13947.96484375MB
INFO:root:[   38] Training loss: 0.06014364, Validation loss: 0.10261833, Gradient norm: 0.71719303
INFO:root:At the start of the epoch: mem (CPU python)=14403.67578125MB; mem (CPU total)=14024.25390625MB
INFO:root:[   39] Training loss: 0.05851805, Validation loss: 0.10369195, Gradient norm: 0.68195373
INFO:root:At the start of the epoch: mem (CPU python)=14479.8671875MB; mem (CPU total)=14100.4375MB
INFO:root:[   40] Training loss: 0.05746034, Validation loss: 0.09636823, Gradient norm: 0.57099591
INFO:root:At the start of the epoch: mem (CPU python)=14556.0546875MB; mem (CPU total)=14176.97265625MB
INFO:root:[   41] Training loss: 0.05742721, Validation loss: 0.10262154, Gradient norm: 0.67170711
INFO:root:At the start of the epoch: mem (CPU python)=14632.25MB; mem (CPU total)=14253.26171875MB
INFO:root:[   42] Training loss: 0.05645060, Validation loss: 0.10750239, Gradient norm: 0.54807433
INFO:root:At the start of the epoch: mem (CPU python)=14708.44140625MB; mem (CPU total)=14329.53515625MB
INFO:root:[   43] Training loss: 0.05759726, Validation loss: 0.09824737, Gradient norm: 0.64727829
INFO:root:At the start of the epoch: mem (CPU python)=14784.6328125MB; mem (CPU total)=14405.80859375MB
INFO:root:[   44] Training loss: 0.05589507, Validation loss: 0.10248554, Gradient norm: 0.56404579
INFO:root:At the start of the epoch: mem (CPU python)=14860.82421875MB; mem (CPU total)=14482.07421875MB
INFO:root:[   45] Training loss: 0.05363100, Validation loss: 0.09732391, Gradient norm: 0.47469186
INFO:root:At the start of the epoch: mem (CPU python)=14937.01171875MB; mem (CPU total)=14558.58984375MB
INFO:root:[   46] Training loss: 0.05565586, Validation loss: 0.11335405, Gradient norm: 0.68030985
INFO:root:At the start of the epoch: mem (CPU python)=15013.203125MB; mem (CPU total)=14634.86328125MB
INFO:root:[   47] Training loss: 0.05471037, Validation loss: 0.10146250, Gradient norm: 0.63347209
INFO:root:At the start of the epoch: mem (CPU python)=15089.39453125MB; mem (CPU total)=14711.15234375MB
INFO:root:[   48] Training loss: 0.05368670, Validation loss: 0.10128291, Gradient norm: 0.58983002
INFO:root:At the start of the epoch: mem (CPU python)=15165.5859375MB; mem (CPU total)=14787.6796875MB
INFO:root:[   49] Training loss: 0.05326631, Validation loss: 0.11619073, Gradient norm: 0.57373453
INFO:root:At the start of the epoch: mem (CPU python)=15241.77734375MB; mem (CPU total)=14863.71484375MB
INFO:root:[   50] Training loss: 0.05168420, Validation loss: 0.10786591, Gradient norm: 0.50317968
INFO:root:At the start of the epoch: mem (CPU python)=15317.96484375MB; mem (CPU total)=14940.234375MB
INFO:root:[   51] Training loss: 0.05172267, Validation loss: 0.10427519, Gradient norm: 0.59110946
INFO:root:At the start of the epoch: mem (CPU python)=15394.16015625MB; mem (CPU total)=15016.265625MB
INFO:root:[   52] Training loss: 0.05178612, Validation loss: 0.10897756, Gradient norm: 0.60600491
INFO:root:At the start of the epoch: mem (CPU python)=15470.34765625MB; mem (CPU total)=15092.53125MB
INFO:root:[   53] Training loss: 0.05170559, Validation loss: 0.10141321, Gradient norm: 0.60181860
INFO:root:At the start of the epoch: mem (CPU python)=15546.5390625MB; mem (CPU total)=15169.05859375MB
INFO:root:[   54] Training loss: 0.05130737, Validation loss: 0.10838315, Gradient norm: 0.64909523
INFO:root:At the start of the epoch: mem (CPU python)=15622.75MB; mem (CPU total)=15244.79296875MB
INFO:root:[   55] Training loss: 0.04981846, Validation loss: 0.10955028, Gradient norm: 0.50306751
INFO:root:At the start of the epoch: mem (CPU python)=15698.9453125MB; mem (CPU total)=15321.19921875MB
INFO:root:[   56] Training loss: 0.05105310, Validation loss: 0.09738286, Gradient norm: 0.60043930
INFO:root:At the start of the epoch: mem (CPU python)=15775.15234375MB; mem (CPU total)=15397.40625MB
INFO:root:[   57] Training loss: 0.05049646, Validation loss: 0.09863528, Gradient norm: 0.63854943
INFO:root:At the start of the epoch: mem (CPU python)=15851.33203125MB; mem (CPU total)=15473.9296875MB
INFO:root:[   58] Training loss: 0.05057735, Validation loss: 0.09924363, Gradient norm: 0.62443698
INFO:root:At the start of the epoch: mem (CPU python)=15927.5234375MB; mem (CPU total)=15550.69921875MB
INFO:root:[   59] Training loss: 0.04946275, Validation loss: 0.09930029, Gradient norm: 0.61738917
INFO:root:At the start of the epoch: mem (CPU python)=16003.71484375MB; mem (CPU total)=15626.73828125MB
INFO:root:[   60] Training loss: 0.05040393, Validation loss: 0.11647723, Gradient norm: 0.66933117
INFO:root:At the start of the epoch: mem (CPU python)=16079.90234375MB; mem (CPU total)=15703.26953125MB
INFO:root:[   61] Training loss: 0.05064624, Validation loss: 0.10551965, Gradient norm: 0.67545716
INFO:root:At the start of the epoch: mem (CPU python)=16156.09375MB; mem (CPU total)=15779.55859375MB
INFO:root:[   62] Training loss: 0.04972736, Validation loss: 0.10018571, Gradient norm: 0.67908062
INFO:root:At the start of the epoch: mem (CPU python)=16232.28515625MB; mem (CPU total)=15856.12109375MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   63] Training loss: 0.04864008, Validation loss: 0.10612820, Gradient norm: 0.65078761
INFO:root:At the start of the epoch: mem (CPU python)=16308.4765625MB; mem (CPU total)=15932.3828125MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   64] Training loss: 0.04477197, Validation loss: 0.10424956, Gradient norm: 0.45188334
INFO:root:At the start of the epoch: mem (CPU python)=16384.6640625MB; mem (CPU total)=16008.68359375MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   65] Training loss: 0.04245759, Validation loss: 0.09744803, Gradient norm: 0.31250869
INFO:root:At the start of the epoch: mem (CPU python)=16460.85546875MB; mem (CPU total)=16085.21484375MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:EP 65: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16536.95703125MB; mem (CPU total)=16161.2578125MB
INFO:root:Training the model took 2877.546s.
INFO:root:Emptying the cuda cache took 0.024s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.10505
INFO:root:EnergyScoreTrain: 0.05567
INFO:root:CRPSTrain: 0.04533
INFO:root:Gaussian NLLTrain: 3.69921
INFO:root:CoverageTrain: 0.68293
INFO:root:IntervalWidthTrain: 0.25024
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.12851
INFO:root:EnergyScoreValidation: 0.07167
INFO:root:CRPSValidation: 0.05871
INFO:root:Gaussian NLLValidation: 5.07558
INFO:root:CoverageValidation: 0.60715
INFO:root:IntervalWidthValidation: 0.24602
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.12477
INFO:root:EnergyScoreTest: 0.06888
INFO:root:CRPSTest: 0.05609
INFO:root:Gaussian NLLTest: 4.67515
INFO:root:CoverageTest: 0.63604
INFO:root:IntervalWidthTest: 0.25715
INFO:root:After validation: mem (CPU python)=16683.64453125MB; mem (CPU total)=16308.64453125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=16683.64453125MB; mem (CPU total)=16308.8828125MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 299892736
INFO:root:After setting up the model: mem (CPU python)=16684.9375MB; mem (CPU total)=16310.11328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=16685.04296875MB; mem (CPU total)=16310.359375MB
INFO:root:[    1] Training loss: 0.38646601, Validation loss: 0.61098846, Gradient norm: 1.20181564
INFO:root:At the start of the epoch: mem (CPU python)=16761.6953125MB; mem (CPU total)=16387.40234375MB
INFO:root:[    2] Training loss: 0.16242540, Validation loss: 0.36975447, Gradient norm: 1.18050481
INFO:root:At the start of the epoch: mem (CPU python)=16837.88671875MB; mem (CPU total)=16463.4765625MB
INFO:root:[    3] Training loss: 0.13214873, Validation loss: 0.28829798, Gradient norm: 1.20317950
INFO:root:At the start of the epoch: mem (CPU python)=16914.09375MB; mem (CPU total)=16539.5859375MB
INFO:root:[    4] Training loss: 0.11727781, Validation loss: 0.25228257, Gradient norm: 1.03939268
INFO:root:At the start of the epoch: mem (CPU python)=16990.296875MB; mem (CPU total)=16616.640625MB
INFO:root:[    5] Training loss: 0.11557279, Validation loss: 0.22157735, Gradient norm: 1.28760618
INFO:root:At the start of the epoch: mem (CPU python)=17066.50390625MB; mem (CPU total)=16692.7265625MB
INFO:root:[    6] Training loss: 0.10443065, Validation loss: 0.20750158, Gradient norm: 0.94185459
INFO:root:At the start of the epoch: mem (CPU python)=17142.71484375MB; mem (CPU total)=16769.07421875MB
INFO:root:[    7] Training loss: 0.10055933, Validation loss: 0.19701188, Gradient norm: 1.02195812
INFO:root:At the start of the epoch: mem (CPU python)=17218.91796875MB; mem (CPU total)=16845.71875MB
INFO:root:[    8] Training loss: 0.10051330, Validation loss: 0.18245231, Gradient norm: 1.23816600
INFO:root:At the start of the epoch: mem (CPU python)=17295.125MB; mem (CPU total)=16921.8828125MB
INFO:root:[    9] Training loss: 0.09525570, Validation loss: 0.16580114, Gradient norm: 1.00725988
INFO:root:At the start of the epoch: mem (CPU python)=17371.31640625MB; mem (CPU total)=16998.6171875MB
INFO:root:[   10] Training loss: 0.09534001, Validation loss: 0.15701635, Gradient norm: 1.14008685
INFO:root:At the start of the epoch: mem (CPU python)=17447.5078125MB; mem (CPU total)=17074.453125MB
INFO:root:[   11] Training loss: 0.08891549, Validation loss: 0.15589187, Gradient norm: 0.73076747
INFO:root:At the start of the epoch: mem (CPU python)=17523.69921875MB; mem (CPU total)=17151.35546875MB
INFO:root:[   12] Training loss: 0.08733372, Validation loss: 0.14532345, Gradient norm: 0.90378759
INFO:root:At the start of the epoch: mem (CPU python)=17599.890625MB; mem (CPU total)=17226.98046875MB
INFO:root:[   13] Training loss: 0.08825161, Validation loss: 0.15470194, Gradient norm: 0.97837859
INFO:root:At the start of the epoch: mem (CPU python)=17676.08203125MB; mem (CPU total)=17303.21875MB
INFO:root:[   14] Training loss: 0.08304019, Validation loss: 0.15140934, Gradient norm: 0.77865831
INFO:root:At the start of the epoch: mem (CPU python)=17752.26953125MB; mem (CPU total)=17380.14453125MB
INFO:root:[   15] Training loss: 0.08322054, Validation loss: 0.14209388, Gradient norm: 0.89606436
INFO:root:At the start of the epoch: mem (CPU python)=17828.4609375MB; mem (CPU total)=17455.82421875MB
INFO:root:[   16] Training loss: 0.07881272, Validation loss: 0.14162009, Gradient norm: 0.67183651
INFO:root:At the start of the epoch: mem (CPU python)=17904.65234375MB; mem (CPU total)=17532.421875MB
INFO:root:[   17] Training loss: 0.07908482, Validation loss: 0.14529061, Gradient norm: 0.74981291
INFO:root:At the start of the epoch: mem (CPU python)=17980.84375MB; mem (CPU total)=17608.51171875MB
INFO:root:[   18] Training loss: 0.07904534, Validation loss: 0.13683397, Gradient norm: 0.82545612
INFO:root:At the start of the epoch: mem (CPU python)=18057.03515625MB; mem (CPU total)=17685.1328125MB
INFO:root:[   19] Training loss: 0.08317946, Validation loss: 0.14832060, Gradient norm: 1.21827280
INFO:root:At the start of the epoch: mem (CPU python)=18133.22265625MB; mem (CPU total)=17760.89453125MB
INFO:root:[   20] Training loss: 0.07664129, Validation loss: 0.12917220, Gradient norm: 0.74049416
INFO:root:At the start of the epoch: mem (CPU python)=18209.41796875MB; mem (CPU total)=17837.4296875MB
INFO:root:[   21] Training loss: 0.07459966, Validation loss: 0.13488894, Gradient norm: 0.73291425
INFO:root:At the start of the epoch: mem (CPU python)=18285.60546875MB; mem (CPU total)=17914.10546875MB
INFO:root:[   22] Training loss: 0.07320603, Validation loss: 0.13514606, Gradient norm: 0.68130548
INFO:root:At the start of the epoch: mem (CPU python)=18361.80078125MB; mem (CPU total)=17989.95703125MB
INFO:root:[   23] Training loss: 0.07181059, Validation loss: 0.12402256, Gradient norm: 0.71443944
INFO:root:At the start of the epoch: mem (CPU python)=18437.98828125MB; mem (CPU total)=18066.2578125MB
INFO:root:[   24] Training loss: 0.06901791, Validation loss: 0.12393799, Gradient norm: 0.64470265
INFO:root:At the start of the epoch: mem (CPU python)=18514.17578125MB; mem (CPU total)=18142.5234375MB
INFO:root:[   25] Training loss: 0.07333848, Validation loss: 0.12332141, Gradient norm: 0.85711697
INFO:root:At the start of the epoch: mem (CPU python)=18590.37109375MB; mem (CPU total)=18218.69921875MB
INFO:root:[   26] Training loss: 0.06923089, Validation loss: 0.12165387, Gradient norm: 0.72062149
INFO:root:At the start of the epoch: mem (CPU python)=18666.55859375MB; mem (CPU total)=18295.27734375MB
INFO:root:[   27] Training loss: 0.06789458, Validation loss: 0.12069528, Gradient norm: 0.74187287
INFO:root:At the start of the epoch: mem (CPU python)=18742.75MB; mem (CPU total)=18371.56640625MB
INFO:root:[   28] Training loss: 0.06664025, Validation loss: 0.12763044, Gradient norm: 0.60980165
INFO:root:At the start of the epoch: mem (CPU python)=18818.94140625MB; mem (CPU total)=18447.8515625MB
INFO:root:[   29] Training loss: 0.06506786, Validation loss: 0.12348374, Gradient norm: 0.64900932
INFO:root:At the start of the epoch: mem (CPU python)=18895.1328125MB; mem (CPU total)=18524.171875MB
INFO:root:[   30] Training loss: 0.06583560, Validation loss: 0.12083630, Gradient norm: 0.74564475
INFO:root:At the start of the epoch: mem (CPU python)=18971.3359375MB; mem (CPU total)=18600.87109375MB
INFO:root:[   31] Training loss: 0.06300531, Validation loss: 0.12157027, Gradient norm: 0.61647828
INFO:root:At the start of the epoch: mem (CPU python)=19047.52734375MB; mem (CPU total)=18676.78125MB
INFO:root:[   32] Training loss: 0.06485552, Validation loss: 0.12178405, Gradient norm: 0.73508880
INFO:root:At the start of the epoch: mem (CPU python)=19123.71875MB; mem (CPU total)=18752.76171875MB
INFO:root:[   33] Training loss: 0.06160220, Validation loss: 0.11805548, Gradient norm: 0.61512515
INFO:root:At the start of the epoch: mem (CPU python)=19199.94921875MB; mem (CPU total)=18829.1640625MB
INFO:root:[   34] Training loss: 0.06417286, Validation loss: 0.11968176, Gradient norm: 0.83183932
INFO:root:At the start of the epoch: mem (CPU python)=19276.13671875MB; mem (CPU total)=18905.20703125MB
INFO:root:[   35] Training loss: 0.06094061, Validation loss: 0.11366054, Gradient norm: 0.62915553
INFO:root:At the start of the epoch: mem (CPU python)=19352.328125MB; mem (CPU total)=18981.28125MB
INFO:root:[   36] Training loss: 0.06188326, Validation loss: 0.11594062, Gradient norm: 0.72119580
INFO:root:At the start of the epoch: mem (CPU python)=19428.51953125MB; mem (CPU total)=19057.56640625MB
INFO:root:[   37] Training loss: 0.05856622, Validation loss: 0.11889212, Gradient norm: 0.58213196
INFO:root:At the start of the epoch: mem (CPU python)=19504.71484375MB; mem (CPU total)=19134.1015625MB
INFO:root:[   38] Training loss: 0.05902565, Validation loss: 0.11946412, Gradient norm: 0.68723080
INFO:root:At the start of the epoch: mem (CPU python)=19580.8984375MB; mem (CPU total)=19210.390625MB
INFO:root:[   39] Training loss: 0.05896323, Validation loss: 0.12804187, Gradient norm: 0.66046898
INFO:root:At the start of the epoch: mem (CPU python)=19657.08984375MB; mem (CPU total)=19286.671875MB
INFO:root:[   40] Training loss: 0.05905168, Validation loss: 0.12557290, Gradient norm: 0.70089758
INFO:root:At the start of the epoch: mem (CPU python)=19733.28125MB; mem (CPU total)=19363.23828125MB
INFO:root:[   41] Training loss: 0.05785338, Validation loss: 0.12550147, Gradient norm: 0.68498057
INFO:root:At the start of the epoch: mem (CPU python)=19809.47265625MB; mem (CPU total)=19439.42578125MB
INFO:root:[   42] Training loss: 0.05659539, Validation loss: 0.11883340, Gradient norm: 0.58764444
INFO:root:At the start of the epoch: mem (CPU python)=19885.6640625MB; mem (CPU total)=19515.95703125MB
INFO:root:[   43] Training loss: 0.05475670, Validation loss: 0.11613610, Gradient norm: 0.55997739
INFO:root:At the start of the epoch: mem (CPU python)=19961.8515625MB; mem (CPU total)=19592.24609375MB
INFO:root:[   44] Training loss: 0.05684380, Validation loss: 0.12024608, Gradient norm: 0.66154412
INFO:root:At the start of the epoch: mem (CPU python)=20038.046875MB; mem (CPU total)=19668.92578125MB
INFO:root:[   45] Training loss: 0.05533820, Validation loss: 0.11210492, Gradient norm: 0.63697469
INFO:root:At the start of the epoch: mem (CPU python)=20114.234375MB; mem (CPU total)=19745.109375MB
INFO:root:[   46] Training loss: 0.05539430, Validation loss: 0.11798317, Gradient norm: 0.62044902
INFO:root:At the start of the epoch: mem (CPU python)=20190.42578125MB; mem (CPU total)=19821.203125MB
INFO:root:[   47] Training loss: 0.05454586, Validation loss: 0.11677060, Gradient norm: 0.64055104
INFO:root:At the start of the epoch: mem (CPU python)=20266.6171875MB; mem (CPU total)=19901.17578125MB
INFO:root:[   48] Training loss: 0.05562089, Validation loss: 0.11497677, Gradient norm: 0.72437860
INFO:root:At the start of the epoch: mem (CPU python)=20342.8046875MB; mem (CPU total)=19977.4140625MB
INFO:root:[   49] Training loss: 0.05301512, Validation loss: 0.12392674, Gradient norm: 0.58343345
INFO:root:At the start of the epoch: mem (CPU python)=20419.0MB; mem (CPU total)=20050.70703125MB
INFO:root:[   50] Training loss: 0.05354660, Validation loss: 0.11291185, Gradient norm: 0.64494272
INFO:root:At the start of the epoch: mem (CPU python)=20495.1875MB; mem (CPU total)=20127.21484375MB
INFO:root:[   51] Training loss: 0.05233257, Validation loss: 0.11405011, Gradient norm: 0.63766955
INFO:root:At the start of the epoch: mem (CPU python)=20571.37890625MB; mem (CPU total)=20203.40234375MB
INFO:root:[   52] Training loss: 0.05415377, Validation loss: 0.11217842, Gradient norm: 0.72790188
INFO:root:At the start of the epoch: mem (CPU python)=20647.57421875MB; mem (CPU total)=20279.69921875MB
INFO:root:[   53] Training loss: 0.05324554, Validation loss: 0.10745927, Gradient norm: 0.64358436
INFO:root:At the start of the epoch: mem (CPU python)=20723.765625MB; mem (CPU total)=20356.7578125MB
INFO:root:[   54] Training loss: 0.05170188, Validation loss: 0.11667629, Gradient norm: 0.53216543
INFO:root:At the start of the epoch: mem (CPU python)=20799.9609375MB; mem (CPU total)=20432.75390625MB
INFO:root:[   55] Training loss: 0.05504836, Validation loss: 0.11341418, Gradient norm: 0.89066571
INFO:root:At the start of the epoch: mem (CPU python)=20876.14453125MB; mem (CPU total)=20509.25390625MB
INFO:root:[   56] Training loss: 0.05242605, Validation loss: 0.11347103, Gradient norm: 0.65480553
INFO:root:At the start of the epoch: mem (CPU python)=20952.33984375MB; mem (CPU total)=20585.765625MB
INFO:root:[   57] Training loss: 0.05165857, Validation loss: 0.11667105, Gradient norm: 0.64617008
INFO:root:At the start of the epoch: mem (CPU python)=21028.52734375MB; mem (CPU total)=20661.7890625MB
INFO:root:[   58] Training loss: 0.05137332, Validation loss: 0.11296238, Gradient norm: 0.61043696
INFO:root:At the start of the epoch: mem (CPU python)=21104.72265625MB; mem (CPU total)=20738.546875MB
INFO:root:[   59] Training loss: 0.05000803, Validation loss: 0.11226921, Gradient norm: 0.56936411
INFO:root:At the start of the epoch: mem (CPU python)=21180.91015625MB; mem (CPU total)=20814.48828125MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   60] Training loss: 0.05069919, Validation loss: 0.11285003, Gradient norm: 0.60851497
INFO:root:At the start of the epoch: mem (CPU python)=21257.10546875MB; mem (CPU total)=20891.015625MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   61] Training loss: 0.04737600, Validation loss: 0.11112003, Gradient norm: 0.56289590
INFO:root:At the start of the epoch: mem (CPU python)=21333.296875MB; mem (CPU total)=20967.5234375MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   62] Training loss: 0.04476522, Validation loss: 0.11121636, Gradient norm: 0.41592911
INFO:root:At the start of the epoch: mem (CPU python)=21409.484375MB; mem (CPU total)=21043.54296875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:EP 62: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=21485.671875MB; mem (CPU total)=21120.046875MB
INFO:root:Training the model took 3102.427s.
INFO:root:Emptying the cuda cache took 0.025s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09751
INFO:root:EnergyScoreTrain: 0.05058
INFO:root:CRPSTrain: 0.04084
INFO:root:Gaussian NLLTrain: 2.7595
INFO:root:CoverageTrain: 0.70247
INFO:root:IntervalWidthTrain: 0.25552
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.13953
INFO:root:EnergyScoreValidation: 0.08044
INFO:root:CRPSValidation: 0.06509
INFO:root:Gaussian NLLValidation: 16.02409
INFO:root:CoverageValidation: 0.57984
INFO:root:IntervalWidthValidation: 0.24942
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.13942
INFO:root:EnergyScoreTest: 0.07887
INFO:root:CRPSTest: 0.06407
INFO:root:Gaussian NLLTest: 6.84682
INFO:root:CoverageTest: 0.59284
INFO:root:IntervalWidthTest: 0.25777
INFO:root:After validation: mem (CPU python)=21632.1484375MB; mem (CPU total)=21266.42578125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=21632.1484375MB; mem (CPU total)=21266.47265625MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 299892736
INFO:root:After setting up the model: mem (CPU python)=21633.4140625MB; mem (CPU total)=21267.45703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=21633.55859375MB; mem (CPU total)=21267.69921875MB
INFO:root:[    1] Training loss: 0.38424999, Validation loss: 0.33226590, Gradient norm: 0.98124829
INFO:root:At the start of the epoch: mem (CPU python)=21709.74609375MB; mem (CPU total)=21343.8984375MB
INFO:root:[    2] Training loss: 0.17087661, Validation loss: 0.25712053, Gradient norm: 1.24542317
INFO:root:At the start of the epoch: mem (CPU python)=21785.93359375MB; mem (CPU total)=21420.16796875MB
INFO:root:[    3] Training loss: 0.13526164, Validation loss: 0.21939362, Gradient norm: 1.04727285
INFO:root:At the start of the epoch: mem (CPU python)=21862.14453125MB; mem (CPU total)=21496.7265625MB
INFO:root:[    4] Training loss: 0.12185373, Validation loss: 0.20076719, Gradient norm: 1.10109517
INFO:root:At the start of the epoch: mem (CPU python)=21938.3515625MB; mem (CPU total)=21573.0390625MB
INFO:root:[    5] Training loss: 0.11299762, Validation loss: 0.17989020, Gradient norm: 1.07138049
INFO:root:At the start of the epoch: mem (CPU python)=22014.5546875MB; mem (CPU total)=21649.82421875MB
INFO:root:[    6] Training loss: 0.10680905, Validation loss: 0.17717461, Gradient norm: 1.03709090
INFO:root:At the start of the epoch: mem (CPU python)=22090.765625MB; mem (CPU total)=21725.80859375MB
INFO:root:[    7] Training loss: 0.10139565, Validation loss: 0.17033544, Gradient norm: 0.98820986
INFO:root:At the start of the epoch: mem (CPU python)=22166.96875MB; mem (CPU total)=21802.5625MB
INFO:root:[    8] Training loss: 0.10160658, Validation loss: 0.15368334, Gradient norm: 1.17204590
INFO:root:At the start of the epoch: mem (CPU python)=22243.17578125MB; mem (CPU total)=21879.078125MB
INFO:root:[    9] Training loss: 0.09482025, Validation loss: 0.15529156, Gradient norm: 0.90314117
INFO:root:At the start of the epoch: mem (CPU python)=22319.36328125MB; mem (CPU total)=21955.375MB
INFO:root:[   10] Training loss: 0.09174772, Validation loss: 0.14944310, Gradient norm: 0.80900746
INFO:root:At the start of the epoch: mem (CPU python)=22395.55859375MB; mem (CPU total)=22031.6328125MB
INFO:root:[   11] Training loss: 0.08870599, Validation loss: 0.15894836, Gradient norm: 0.69478889
INFO:root:At the start of the epoch: mem (CPU python)=22471.74609375MB; mem (CPU total)=22107.90234375MB
INFO:root:[   12] Training loss: 0.08835739, Validation loss: 0.15421294, Gradient norm: 0.90834776
INFO:root:At the start of the epoch: mem (CPU python)=22547.9375MB; mem (CPU total)=22184.1796875MB
INFO:root:[   13] Training loss: 0.08995805, Validation loss: 0.14054629, Gradient norm: 0.99453762
INFO:root:At the start of the epoch: mem (CPU python)=22624.12890625MB; mem (CPU total)=22260.4296875MB
INFO:root:[   14] Training loss: 0.08512615, Validation loss: 0.13703751, Gradient norm: 0.88858299
INFO:root:At the start of the epoch: mem (CPU python)=22700.3203125MB; mem (CPU total)=22336.7109375MB
INFO:root:[   15] Training loss: 0.08491045, Validation loss: 0.13391511, Gradient norm: 0.86812186
INFO:root:At the start of the epoch: mem (CPU python)=22776.51171875MB; mem (CPU total)=22412.98828125MB
INFO:root:[   16] Training loss: 0.08141082, Validation loss: 0.12962300, Gradient norm: 0.78944619
INFO:root:At the start of the epoch: mem (CPU python)=22852.703125MB; mem (CPU total)=22489.7265625MB
INFO:root:[   17] Training loss: 0.08156577, Validation loss: 0.12933681, Gradient norm: 0.83719890
INFO:root:At the start of the epoch: mem (CPU python)=22928.890625MB; mem (CPU total)=22566.3203125MB
INFO:root:[   18] Training loss: 0.07845929, Validation loss: 0.12635147, Gradient norm: 0.68204953
INFO:root:At the start of the epoch: mem (CPU python)=23005.08203125MB; mem (CPU total)=22642.625MB
INFO:root:[   19] Training loss: 0.07769815, Validation loss: 0.12761323, Gradient norm: 0.80024404
INFO:root:At the start of the epoch: mem (CPU python)=23081.2734375MB; mem (CPU total)=22718.62890625MB
INFO:root:[   20] Training loss: 0.07578244, Validation loss: 0.12425990, Gradient norm: 0.68032961
INFO:root:At the start of the epoch: mem (CPU python)=23157.46484375MB; mem (CPU total)=22794.9453125MB
INFO:root:[   21] Training loss: 0.07471096, Validation loss: 0.12478254, Gradient norm: 0.67679908
INFO:root:At the start of the epoch: mem (CPU python)=23233.65625MB; mem (CPU total)=22871.00390625MB
INFO:root:[   22] Training loss: 0.07561384, Validation loss: 0.12597789, Gradient norm: 0.83804041
INFO:root:At the start of the epoch: mem (CPU python)=23309.84765625MB; mem (CPU total)=22947.29296875MB
INFO:root:[   23] Training loss: 0.07310776, Validation loss: 0.11924095, Gradient norm: 0.67410525
INFO:root:At the start of the epoch: mem (CPU python)=23386.0390625MB; mem (CPU total)=23023.83984375MB
INFO:root:[   24] Training loss: 0.07454526, Validation loss: 0.12258024, Gradient norm: 0.96529529
INFO:root:At the start of the epoch: mem (CPU python)=23462.2265625MB; mem (CPU total)=23100.0625MB
INFO:root:[   25] Training loss: 0.06830094, Validation loss: 0.11564880, Gradient norm: 0.59365266
INFO:root:At the start of the epoch: mem (CPU python)=23538.421875MB; mem (CPU total)=23176.68359375MB
INFO:root:[   26] Training loss: 0.06951896, Validation loss: 0.11866710, Gradient norm: 0.72364042
INFO:root:At the start of the epoch: mem (CPU python)=23614.609375MB; mem (CPU total)=23252.7265625MB
INFO:root:[   27] Training loss: 0.06975476, Validation loss: 0.11941645, Gradient norm: 0.78980632
INFO:root:At the start of the epoch: mem (CPU python)=23690.8046875MB; mem (CPU total)=23329.2265625MB
INFO:root:[   28] Training loss: 0.06860099, Validation loss: 0.12539526, Gradient norm: 0.75964348
INFO:root:At the start of the epoch: mem (CPU python)=23766.99609375MB; mem (CPU total)=23405.96484375MB
INFO:root:[   29] Training loss: 0.06744780, Validation loss: 0.11245964, Gradient norm: 0.76202051
INFO:root:At the start of the epoch: mem (CPU python)=23843.1875MB; mem (CPU total)=23482.359375MB
INFO:root:[   30] Training loss: 0.06722556, Validation loss: 0.12314338, Gradient norm: 0.75231367
INFO:root:At the start of the epoch: mem (CPU python)=23919.37890625MB; mem (CPU total)=23558.65234375MB
INFO:root:[   31] Training loss: 0.06704907, Validation loss: 0.11589514, Gradient norm: 0.74950794
INFO:root:At the start of the epoch: mem (CPU python)=23995.56640625MB; mem (CPU total)=23634.65625MB
INFO:root:[   32] Training loss: 0.06377736, Validation loss: 0.11845182, Gradient norm: 0.63178175
INFO:root:At the start of the epoch: mem (CPU python)=24071.76171875MB; mem (CPU total)=23710.6953125MB
INFO:root:[   33] Training loss: 0.06223444, Validation loss: 0.11428616, Gradient norm: 0.57136574
INFO:root:At the start of the epoch: mem (CPU python)=24147.953125MB; mem (CPU total)=23786.96484375MB
INFO:root:[   34] Training loss: 0.06010270, Validation loss: 0.11935811, Gradient norm: 0.55098346
INFO:root:At the start of the epoch: mem (CPU python)=24224.140625MB; mem (CPU total)=23863.2578125MB
INFO:root:[   35] Training loss: 0.06440499, Validation loss: 0.11890291, Gradient norm: 0.78963124
INFO:root:At the start of the epoch: mem (CPU python)=24300.3359375MB; mem (CPU total)=23939.234375MB
INFO:root:[   36] Training loss: 0.05961216, Validation loss: 0.11429112, Gradient norm: 0.54935263
INFO:root:At the start of the epoch: mem (CPU python)=24376.5234375MB; mem (CPU total)=24015.27734375MB
INFO:root:[   37] Training loss: 0.06061306, Validation loss: 0.11633685, Gradient norm: 0.63841684
INFO:root:At the start of the epoch: mem (CPU python)=24452.71484375MB; mem (CPU total)=24092.28515625MB
INFO:root:[   38] Training loss: 0.05854554, Validation loss: 0.11359583, Gradient norm: 0.57528354
INFO:root:At the start of the epoch: mem (CPU python)=24528.90625MB; mem (CPU total)=24168.5625MB
INFO:root:[   39] Training loss: 0.05706459, Validation loss: 0.11288805, Gradient norm: 0.48200516
INFO:root:At the start of the epoch: mem (CPU python)=24605.09765625MB; mem (CPU total)=24244.828125MB
INFO:root:[   40] Training loss: 0.05845994, Validation loss: 0.11425581, Gradient norm: 0.65969357
INFO:root:At the start of the epoch: mem (CPU python)=24681.2890625MB; mem (CPU total)=24321.10546875MB
INFO:root:[   41] Training loss: 0.05714112, Validation loss: 0.11819048, Gradient norm: 0.57327236
INFO:root:At the start of the epoch: mem (CPU python)=24757.4765625MB; mem (CPU total)=24397.3671875MB
INFO:root:[   42] Training loss: 0.05704853, Validation loss: 0.11408121, Gradient norm: 0.63084143
INFO:root:At the start of the epoch: mem (CPU python)=24833.66796875MB; mem (CPU total)=24473.4921875MB
INFO:root:[   43] Training loss: 0.05666576, Validation loss: 0.11460977, Gradient norm: 0.67857485
INFO:root:At the start of the epoch: mem (CPU python)=24909.859375MB; mem (CPU total)=24549.80078125MB
INFO:root:[   44] Training loss: 0.05691762, Validation loss: 0.11893753, Gradient norm: 0.63159231
INFO:root:At the start of the epoch: mem (CPU python)=24986.05078125MB; mem (CPU total)=24626.11328125MB
INFO:root:[   45] Training loss: 0.05594335, Validation loss: 0.12022631, Gradient norm: 0.61705330
INFO:root:At the start of the epoch: mem (CPU python)=25062.2421875MB; mem (CPU total)=24702.7890625MB
INFO:root:[   46] Training loss: 0.05663470, Validation loss: 0.11279558, Gradient norm: 0.70549263
INFO:root:At the start of the epoch: mem (CPU python)=25138.4296875MB; mem (CPU total)=24778.9296875MB
INFO:root:[   47] Training loss: 0.05424475, Validation loss: 0.11865475, Gradient norm: 0.58579580
INFO:root:At the start of the epoch: mem (CPU python)=25214.625MB; mem (CPU total)=24855.4375MB
INFO:root:[   48] Training loss: 0.05401371, Validation loss: 0.11146154, Gradient norm: 0.64763147
INFO:root:At the start of the epoch: mem (CPU python)=25290.8125MB; mem (CPU total)=24931.765625MB
INFO:root:[   49] Training loss: 0.05403729, Validation loss: 0.11110969, Gradient norm: 0.62376778
INFO:root:At the start of the epoch: mem (CPU python)=25367.00390625MB; mem (CPU total)=25008.14453125MB
INFO:root:[   50] Training loss: 0.05234128, Validation loss: 0.11020789, Gradient norm: 0.55089466
INFO:root:At the start of the epoch: mem (CPU python)=25443.1953125MB; mem (CPU total)=25084.1171875MB
INFO:root:[   51] Training loss: 0.05276552, Validation loss: 0.11215812, Gradient norm: 0.55896946
INFO:root:At the start of the epoch: mem (CPU python)=25519.3828125MB; mem (CPU total)=25160.390625MB
INFO:root:[   52] Training loss: 0.05244646, Validation loss: 0.11259156, Gradient norm: 0.58300278
INFO:root:At the start of the epoch: mem (CPU python)=25595.578125MB; mem (CPU total)=25236.6953125MB
INFO:root:[   53] Training loss: 0.05296104, Validation loss: 0.10767295, Gradient norm: 0.61435663
INFO:root:At the start of the epoch: mem (CPU python)=25671.76953125MB; mem (CPU total)=25312.875MB
INFO:root:[   54] Training loss: 0.05057590, Validation loss: 0.10779170, Gradient norm: 0.50716013
INFO:root:At the start of the epoch: mem (CPU python)=25747.96484375MB; mem (CPU total)=25389.21875MB
INFO:root:[   55] Training loss: 0.05122398, Validation loss: 0.11131933, Gradient norm: 0.54763657
INFO:root:At the start of the epoch: mem (CPU python)=25824.15625MB; mem (CPU total)=25465.453125MB
INFO:root:[   56] Training loss: 0.05096836, Validation loss: 0.10607434, Gradient norm: 0.54937495
INFO:root:At the start of the epoch: mem (CPU python)=25900.34375MB; mem (CPU total)=25542.0234375MB
INFO:root:[   57] Training loss: 0.05338991, Validation loss: 0.11183943, Gradient norm: 0.69638594
INFO:root:At the start of the epoch: mem (CPU python)=25976.53515625MB; mem (CPU total)=25618.2890625MB
INFO:root:[   58] Training loss: 0.05175158, Validation loss: 0.10724134, Gradient norm: 0.61714897
INFO:root:At the start of the epoch: mem (CPU python)=26052.72265625MB; mem (CPU total)=25694.55859375MB
INFO:root:[   59] Training loss: 0.04974218, Validation loss: 0.10903632, Gradient norm: 0.52431504
INFO:root:At the start of the epoch: mem (CPU python)=26128.9140625MB; mem (CPU total)=25771.03515625MB
INFO:root:[   60] Training loss: 0.04871503, Validation loss: 0.10733739, Gradient norm: 0.47524177
INFO:root:At the start of the epoch: mem (CPU python)=26205.10546875MB; mem (CPU total)=25847.30078125MB
INFO:root:[   61] Training loss: 0.04936938, Validation loss: 0.11698379, Gradient norm: 0.60228533
INFO:root:At the start of the epoch: mem (CPU python)=26281.296875MB; mem (CPU total)=25923.56640625MB
INFO:root:[   62] Training loss: 0.04916014, Validation loss: 0.11123455, Gradient norm: 0.58408070
INFO:root:At the start of the epoch: mem (CPU python)=26357.484375MB; mem (CPU total)=25999.76953125MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   63] Training loss: 0.04805712, Validation loss: 0.10486643, Gradient norm: 0.49887858
INFO:root:At the start of the epoch: mem (CPU python)=26433.67578125MB; mem (CPU total)=26076.375MB
INFO:root:[   64] Training loss: 0.04526628, Validation loss: 0.10400994, Gradient norm: 0.38970833
INFO:root:At the start of the epoch: mem (CPU python)=26509.87109375MB; mem (CPU total)=26152.71484375MB
INFO:root:[   65] Training loss: 0.04512485, Validation loss: 0.11233332, Gradient norm: 0.49274839
INFO:root:At the start of the epoch: mem (CPU python)=26586.05859375MB; mem (CPU total)=26229.50390625MB
INFO:root:[   66] Training loss: 0.04387604, Validation loss: 0.10335100, Gradient norm: 0.39856749
INFO:root:At the start of the epoch: mem (CPU python)=26662.24609375MB; mem (CPU total)=26305.81640625MB
INFO:root:[   67] Training loss: 0.04455645, Validation loss: 0.10737318, Gradient norm: 0.42956587
INFO:root:At the start of the epoch: mem (CPU python)=26738.4375MB; mem (CPU total)=26382.3203125MB
INFO:root:[   68] Training loss: 0.04451090, Validation loss: 0.10825774, Gradient norm: 0.46009774
INFO:root:At the start of the epoch: mem (CPU python)=26814.62890625MB; mem (CPU total)=26458.578125MB
INFO:root:[   69] Training loss: 0.04540741, Validation loss: 0.11361914, Gradient norm: 0.57290592
INFO:root:At the start of the epoch: mem (CPU python)=26890.8203125MB; mem (CPU total)=26535.05859375MB
INFO:root:[   70] Training loss: 0.04346968, Validation loss: 0.10429961, Gradient norm: 0.38163054
INFO:root:At the start of the epoch: mem (CPU python)=26967.0078125MB; mem (CPU total)=26610.83203125MB
INFO:root:[   71] Training loss: 0.04382233, Validation loss: 0.10522947, Gradient norm: 0.41787489
INFO:root:At the start of the epoch: mem (CPU python)=27043.19921875MB; mem (CPU total)=26687.27734375MB
INFO:root:[   72] Training loss: 0.04284853, Validation loss: 0.10933858, Gradient norm: 0.33097645
INFO:root:At the start of the epoch: mem (CPU python)=27119.390625MB; mem (CPU total)=26763.54296875MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   73] Training loss: 0.04390139, Validation loss: 0.10778279, Gradient norm: 0.49885793
INFO:root:At the start of the epoch: mem (CPU python)=27195.58203125MB; mem (CPU total)=26839.58984375MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   74] Training loss: 0.04235560, Validation loss: 0.11046386, Gradient norm: 0.36994938
INFO:root:At the start of the epoch: mem (CPU python)=27271.7734375MB; mem (CPU total)=26915.796875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[   75] Training loss: 0.04124769, Validation loss: 0.10726851, Gradient norm: 0.32046200
INFO:root:At the start of the epoch: mem (CPU python)=27347.9609375MB; mem (CPU total)=26991.61328125MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:EP 75: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=27424.1015625MB; mem (CPU total)=27068.13671875MB
INFO:root:Training the model took 4281.064s.
INFO:root:Emptying the cuda cache took 0.026s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09642
INFO:root:EnergyScoreTrain: 0.05002
INFO:root:CRPSTrain: 0.04052
INFO:root:Gaussian NLLTrain: 2.01661
INFO:root:CoverageTrain: 0.7109
INFO:root:IntervalWidthTrain: 0.2516
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.13871
INFO:root:EnergyScoreValidation: 0.07943
INFO:root:CRPSValidation: 0.06509
INFO:root:Gaussian NLLValidation: 12.51034
INFO:root:CoverageValidation: 0.56159
INFO:root:IntervalWidthValidation: 0.24567
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.14045
INFO:root:EnergyScoreTest: 0.07928
INFO:root:CRPSTest: 0.06526
INFO:root:Gaussian NLLTest: 5.56955
INFO:root:CoverageTest: 0.56118
INFO:root:IntervalWidthTest: 0.25429
INFO:root:After validation: mem (CPU python)=27570.5859375MB; mem (CPU total)=27214.33984375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=27570.5859375MB; mem (CPU total)=27214.3359375MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 299892736
INFO:root:After setting up the model: mem (CPU python)=27571.90625MB; mem (CPU total)=27215.3203125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=27571.953125MB; mem (CPU total)=27215.5546875MB
INFO:root:[    1] Training loss: 0.38385960, Validation loss: 0.24078812, Gradient norm: 1.02610992
INFO:root:At the start of the epoch: mem (CPU python)=27648.21484375MB; mem (CPU total)=27292.1640625MB
INFO:root:[    2] Training loss: 0.16693975, Validation loss: 0.21034717, Gradient norm: 1.26809360
INFO:root:At the start of the epoch: mem (CPU python)=27724.40234375MB; mem (CPU total)=27368.72265625MB
INFO:root:[    3] Training loss: 0.13234137, Validation loss: 0.16999756, Gradient norm: 0.99987000
INFO:root:At the start of the epoch: mem (CPU python)=27800.6171875MB; mem (CPU total)=27445.34765625MB
INFO:root:[    4] Training loss: 0.12007508, Validation loss: 0.18452026, Gradient norm: 1.14818054
INFO:root:At the start of the epoch: mem (CPU python)=27876.8203125MB; mem (CPU total)=27521.34375MB
INFO:root:[    5] Training loss: 0.11566247, Validation loss: 0.15531743, Gradient norm: 1.31480335
INFO:root:At the start of the epoch: mem (CPU python)=27953.02734375MB; mem (CPU total)=27597.890625MB
INFO:root:[    6] Training loss: 0.10596926, Validation loss: 0.14709009, Gradient norm: 1.06340672
INFO:root:At the start of the epoch: mem (CPU python)=28029.234375MB; mem (CPU total)=27674.50390625MB
INFO:root:[    7] Training loss: 0.10197666, Validation loss: 0.16136410, Gradient norm: 0.94452321
INFO:root:At the start of the epoch: mem (CPU python)=28105.42578125MB; mem (CPU total)=27750.5078125MB
INFO:root:[    8] Training loss: 0.09715117, Validation loss: 0.13767980, Gradient norm: 0.95397063
INFO:root:At the start of the epoch: mem (CPU python)=28181.62109375MB; mem (CPU total)=27827.30078125MB
INFO:root:[    9] Training loss: 0.09425434, Validation loss: 0.13195280, Gradient norm: 0.86638970
INFO:root:At the start of the epoch: mem (CPU python)=28257.80859375MB; mem (CPU total)=27903.859375MB
INFO:root:[   10] Training loss: 0.09101366, Validation loss: 0.13611695, Gradient norm: 0.87152284
INFO:root:At the start of the epoch: mem (CPU python)=28334.00390625MB; mem (CPU total)=27979.6484375MB
INFO:root:[   11] Training loss: 0.08893353, Validation loss: 0.13991644, Gradient norm: 0.89202178
INFO:root:At the start of the epoch: mem (CPU python)=28410.1953125MB; mem (CPU total)=28056.12109375MB
INFO:root:[   12] Training loss: 0.08724023, Validation loss: 0.12502480, Gradient norm: 0.86761609
INFO:root:At the start of the epoch: mem (CPU python)=28486.3828125MB; mem (CPU total)=28132.76953125MB
INFO:root:[   13] Training loss: 0.08636781, Validation loss: 0.12728114, Gradient norm: 0.84539557
INFO:root:At the start of the epoch: mem (CPU python)=28562.578125MB; mem (CPU total)=28208.71484375MB
INFO:root:[   14] Training loss: 0.08387247, Validation loss: 0.12388672, Gradient norm: 0.90451073
INFO:root:At the start of the epoch: mem (CPU python)=28638.765625MB; mem (CPU total)=28284.83984375MB
INFO:root:[   15] Training loss: 0.08132049, Validation loss: 0.12671061, Gradient norm: 0.80798986
INFO:root:At the start of the epoch: mem (CPU python)=28714.95703125MB; mem (CPU total)=28361.1328125MB
INFO:root:[   16] Training loss: 0.07912317, Validation loss: 0.14043931, Gradient norm: 0.76897159
INFO:root:At the start of the epoch: mem (CPU python)=28791.1484375MB; mem (CPU total)=28437.66015625MB
INFO:root:[   17] Training loss: 0.07850578, Validation loss: 0.12199058, Gradient norm: 0.80801641
INFO:root:At the start of the epoch: mem (CPU python)=28867.3359375MB; mem (CPU total)=28513.96484375MB
INFO:root:[   18] Training loss: 0.07691430, Validation loss: 0.12268615, Gradient norm: 0.72380060
INFO:root:At the start of the epoch: mem (CPU python)=28943.53125MB; mem (CPU total)=28590.234375MB
INFO:root:[   19] Training loss: 0.07577244, Validation loss: 0.11345447, Gradient norm: 0.79636185
INFO:root:At the start of the epoch: mem (CPU python)=29019.71875MB; mem (CPU total)=28666.765625MB
INFO:root:[   20] Training loss: 0.07537668, Validation loss: 0.11840615, Gradient norm: 0.80359701
INFO:root:At the start of the epoch: mem (CPU python)=29095.91015625MB; mem (CPU total)=28742.8046875MB
INFO:root:[   21] Training loss: 0.07427026, Validation loss: 0.12205015, Gradient norm: 0.75193930
INFO:root:At the start of the epoch: mem (CPU python)=29172.09765625MB; mem (CPU total)=28819.578125MB
INFO:root:[   22] Training loss: 0.07205653, Validation loss: 0.11342967, Gradient norm: 0.73407592
INFO:root:At the start of the epoch: mem (CPU python)=29248.29296875MB; mem (CPU total)=28895.609375MB
INFO:root:[   23] Training loss: 0.07166092, Validation loss: 0.11666484, Gradient norm: 0.76129492
INFO:root:At the start of the epoch: mem (CPU python)=29324.484375MB; mem (CPU total)=28971.90234375MB
INFO:root:[   24] Training loss: 0.07266372, Validation loss: 0.11824173, Gradient norm: 0.79291321
INFO:root:At the start of the epoch: mem (CPU python)=29400.671875MB; mem (CPU total)=29048.375MB
INFO:root:[   25] Training loss: 0.06962890, Validation loss: 0.10930354, Gradient norm: 0.67451132
INFO:root:At the start of the epoch: mem (CPU python)=29476.8671875MB; mem (CPU total)=29124.91796875MB
INFO:root:[   26] Training loss: 0.06967996, Validation loss: 0.11402022, Gradient norm: 0.74097759
INFO:root:At the start of the epoch: mem (CPU python)=29553.0546875MB; mem (CPU total)=29201.22265625MB
INFO:root:[   27] Training loss: 0.06663784, Validation loss: 0.11039204, Gradient norm: 0.59305841
INFO:root:At the start of the epoch: mem (CPU python)=29629.24609375MB; mem (CPU total)=29277.7265625MB
INFO:root:[   28] Training loss: 0.06764981, Validation loss: 0.11561349, Gradient norm: 0.71535672
INFO:root:At the start of the epoch: mem (CPU python)=29705.4375MB; mem (CPU total)=29354.26953125MB
INFO:root:[   29] Training loss: 0.06496957, Validation loss: 0.10570024, Gradient norm: 0.57108034
INFO:root:At the start of the epoch: mem (CPU python)=29781.625MB; mem (CPU total)=29430.35546875MB
INFO:root:[   30] Training loss: 0.06377171, Validation loss: 0.10755389, Gradient norm: 0.57475188
INFO:root:At the start of the epoch: mem (CPU python)=29857.8203125MB; mem (CPU total)=29506.8671875MB
INFO:root:[   31] Training loss: 0.06553582, Validation loss: 0.11628478, Gradient norm: 0.70265468
INFO:root:At the start of the epoch: mem (CPU python)=29934.0078125MB; mem (CPU total)=29583.1640625MB
INFO:root:[   32] Training loss: 0.06352036, Validation loss: 0.10512625, Gradient norm: 0.69685847
INFO:root:At the start of the epoch: mem (CPU python)=30010.19921875MB; mem (CPU total)=29659.9921875MB
INFO:root:[   33] Training loss: 0.06339423, Validation loss: 0.11228447, Gradient norm: 0.63356097
INFO:root:At the start of the epoch: mem (CPU python)=30086.390625MB; mem (CPU total)=29736.02734375MB
INFO:root:[   34] Training loss: 0.06103812, Validation loss: 0.11720975, Gradient norm: 0.62551457
INFO:root:At the start of the epoch: mem (CPU python)=30162.58203125MB; mem (CPU total)=29812.55078125MB
INFO:root:[   35] Training loss: 0.05987610, Validation loss: 0.10367167, Gradient norm: 0.59162043
INFO:root:At the start of the epoch: mem (CPU python)=30238.77734375MB; mem (CPU total)=29888.84765625MB
INFO:root:[   36] Training loss: 0.06086490, Validation loss: 0.10931263, Gradient norm: 0.66325598
INFO:root:At the start of the epoch: mem (CPU python)=30314.96484375MB; mem (CPU total)=29964.78125MB
INFO:root:[   37] Training loss: 0.05840387, Validation loss: 0.10543806, Gradient norm: 0.55592581
INFO:root:At the start of the epoch: mem (CPU python)=30391.16015625MB; mem (CPU total)=30041.484375MB
INFO:root:[   38] Training loss: 0.05758442, Validation loss: 0.10648440, Gradient norm: 0.48321626
INFO:root:At the start of the epoch: mem (CPU python)=30467.34765625MB; mem (CPU total)=30117.99609375MB
INFO:root:[   39] Training loss: 0.05853508, Validation loss: 0.10286244, Gradient norm: 0.61769604
INFO:root:At the start of the epoch: mem (CPU python)=30543.5390625MB; mem (CPU total)=30194.32421875MB
INFO:root:[   40] Training loss: 0.05605543, Validation loss: 0.10772345, Gradient norm: 0.51107620
INFO:root:At the start of the epoch: mem (CPU python)=30619.73046875MB; mem (CPU total)=30270.5546875MB
INFO:root:[   41] Training loss: 0.05705504, Validation loss: 0.10114103, Gradient norm: 0.59160052
INFO:root:At the start of the epoch: mem (CPU python)=30695.91796875MB; mem (CPU total)=30346.82421875MB
INFO:root:[   42] Training loss: 0.05681677, Validation loss: 0.10427032, Gradient norm: 0.64152605
INFO:root:At the start of the epoch: mem (CPU python)=30772.11328125MB; mem (CPU total)=30422.87890625MB
INFO:root:[   43] Training loss: 0.05497032, Validation loss: 0.10528687, Gradient norm: 0.52962981
INFO:root:At the start of the epoch: mem (CPU python)=30848.30078125MB; mem (CPU total)=30498.8984375MB
INFO:root:[   44] Training loss: 0.05484275, Validation loss: 0.11058921, Gradient norm: 0.57758755
INFO:root:At the start of the epoch: mem (CPU python)=30924.4921875MB; mem (CPU total)=30575.296875MB
INFO:root:[   45] Training loss: 0.05592970, Validation loss: 0.11154773, Gradient norm: 0.63515172
INFO:root:At the start of the epoch: mem (CPU python)=31000.68359375MB; mem (CPU total)=30651.546875MB
INFO:root:[   46] Training loss: 0.05571243, Validation loss: 0.09911583, Gradient norm: 0.63614308
INFO:root:At the start of the epoch: mem (CPU python)=31076.87109375MB; mem (CPU total)=30727.8125MB
INFO:root:[   47] Training loss: 0.05389042, Validation loss: 0.10373168, Gradient norm: 0.58993827
INFO:root:At the start of the epoch: mem (CPU python)=31153.06640625MB; mem (CPU total)=30804.05859375MB
INFO:root:[   48] Training loss: 0.05179106, Validation loss: 0.09929484, Gradient norm: 0.47951561
INFO:root:At the start of the epoch: mem (CPU python)=31229.25390625MB; mem (CPU total)=30880.34375MB
INFO:root:[   49] Training loss: 0.05226838, Validation loss: 0.10076894, Gradient norm: 0.53226980
INFO:root:At the start of the epoch: mem (CPU python)=31305.4453125MB; mem (CPU total)=30956.875MB
INFO:root:[   50] Training loss: 0.05175106, Validation loss: 0.10826814, Gradient norm: 0.53602855
INFO:root:At the start of the epoch: mem (CPU python)=31381.640625MB; mem (CPU total)=31032.91796875MB
INFO:root:[   51] Training loss: 0.05298491, Validation loss: 0.10129033, Gradient norm: 0.59033864
INFO:root:At the start of the epoch: mem (CPU python)=31457.828125MB; mem (CPU total)=31109.90625MB
INFO:root:[   52] Training loss: 0.05431335, Validation loss: 0.10037428, Gradient norm: 0.69265117
INFO:root:At the start of the epoch: mem (CPU python)=31534.01953125MB; mem (CPU total)=31186.14453125MB
INFO:root:[   53] Training loss: 0.05053324, Validation loss: 0.09658180, Gradient norm: 0.50344834
INFO:root:At the start of the epoch: mem (CPU python)=31610.2109375MB; mem (CPU total)=31262.71875MB
INFO:root:[   54] Training loss: 0.05068415, Validation loss: 0.09619829, Gradient norm: 0.60989594
INFO:root:At the start of the epoch: mem (CPU python)=31686.40625MB; mem (CPU total)=31339.3125MB
INFO:root:[   55] Training loss: 0.05082903, Validation loss: 0.09763483, Gradient norm: 0.58557103
INFO:root:At the start of the epoch: mem (CPU python)=31762.59375MB; mem (CPU total)=31415.55859375MB
INFO:root:[   56] Training loss: 0.04942137, Validation loss: 0.10392197, Gradient norm: 0.48369817
INFO:root:At the start of the epoch: mem (CPU python)=31838.78515625MB; mem (CPU total)=31491.82421875MB
INFO:root:[   57] Training loss: 0.04998454, Validation loss: 0.09972262, Gradient norm: 0.58414901
INFO:root:At the start of the epoch: mem (CPU python)=31914.97265625MB; mem (CPU total)=31568.33203125MB
INFO:root:[   58] Training loss: 0.04802537, Validation loss: 0.09593907, Gradient norm: 0.48341129
INFO:root:At the start of the epoch: mem (CPU python)=31991.16796875MB; mem (CPU total)=31644.59765625MB
INFO:root:[   59] Training loss: 0.04931289, Validation loss: 0.09541875, Gradient norm: 0.60965314
INFO:root:At the start of the epoch: mem (CPU python)=32067.36328125MB; mem (CPU total)=31720.94140625MB
INFO:root:[   60] Training loss: 0.04921879, Validation loss: 0.09719826, Gradient norm: 0.56593487
INFO:root:At the start of the epoch: mem (CPU python)=32143.55078125MB; mem (CPU total)=31797.1796875MB
INFO:root:[   61] Training loss: 0.04881154, Validation loss: 0.09549481, Gradient norm: 0.63023131
INFO:root:At the start of the epoch: mem (CPU python)=32219.7421875MB; mem (CPU total)=31873.6484375MB
INFO:root:[   62] Training loss: 0.04771760, Validation loss: 0.10438906, Gradient norm: 0.50932134
INFO:root:At the start of the epoch: mem (CPU python)=32295.9375MB; mem (CPU total)=31950.375MB
INFO:root:[   63] Training loss: 0.04833880, Validation loss: 0.09604706, Gradient norm: 0.63729103
INFO:root:At the start of the epoch: mem (CPU python)=32372.125MB; mem (CPU total)=32026.3671875MB
INFO:root:[   64] Training loss: 0.04724615, Validation loss: 0.09715922, Gradient norm: 0.49201089
INFO:root:At the start of the epoch: mem (CPU python)=32448.31640625MB; mem (CPU total)=32105.6875MB
INFO:root:[   65] Training loss: 0.04717162, Validation loss: 0.09358480, Gradient norm: 0.53839022
INFO:root:At the start of the epoch: mem (CPU python)=32524.50390625MB; mem (CPU total)=32182.0625MB
INFO:root:[   66] Training loss: 0.04753354, Validation loss: 0.09825187, Gradient norm: 0.55305444
INFO:root:At the start of the epoch: mem (CPU python)=32600.6953125MB; mem (CPU total)=32257.40234375MB
INFO:root:[   67] Training loss: 0.04791949, Validation loss: 0.09566724, Gradient norm: 0.58654094
INFO:root:At the start of the epoch: mem (CPU python)=32676.88671875MB; mem (CPU total)=32333.8828125MB
INFO:root:[   68] Training loss: 0.04600112, Validation loss: 0.09819907, Gradient norm: 0.49428934
INFO:root:At the start of the epoch: mem (CPU python)=32753.07421875MB; mem (CPU total)=32410.1171875MB
INFO:root:[   69] Training loss: 0.04608660, Validation loss: 0.09636965, Gradient norm: 0.53382131
INFO:root:At the start of the epoch: mem (CPU python)=32829.265625MB; mem (CPU total)=32486.83203125MB
INFO:root:[   70] Training loss: 0.04693482, Validation loss: 0.09799007, Gradient norm: 0.63361387
INFO:root:At the start of the epoch: mem (CPU python)=32905.453125MB; mem (CPU total)=32562.7578125MB
INFO:root:[   71] Training loss: 0.04659174, Validation loss: 0.10166869, Gradient norm: 0.59831628
INFO:root:At the start of the epoch: mem (CPU python)=32981.6484375MB; mem (CPU total)=32639.02734375MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   72] Training loss: 0.04731543, Validation loss: 0.10106964, Gradient norm: 0.61898313
INFO:root:At the start of the epoch: mem (CPU python)=33057.8359375MB; mem (CPU total)=32715.546875MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   73] Training loss: 0.04306147, Validation loss: 0.09462247, Gradient norm: 0.46015778
INFO:root:At the start of the epoch: mem (CPU python)=33134.02734375MB; mem (CPU total)=32791.5625MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   74] Training loss: 0.04042885, Validation loss: 0.09709526, Gradient norm: 0.30055064
INFO:root:At the start of the epoch: mem (CPU python)=33210.22265625MB; mem (CPU total)=32867.8359375MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[   75] Training loss: 0.03940768, Validation loss: 0.09349576, Gradient norm: 0.23610098
INFO:root:At the start of the epoch: mem (CPU python)=33286.421875MB; mem (CPU total)=32945.62890625MB
INFO:root:[   76] Training loss: 0.03933129, Validation loss: 0.09363154, Gradient norm: 0.22144607
INFO:root:At the start of the epoch: mem (CPU python)=33362.61328125MB; mem (CPU total)=33021.65625MB
INFO:root:[   77] Training loss: 0.03883926, Validation loss: 0.09475386, Gradient norm: 0.23658544
INFO:root:At the start of the epoch: mem (CPU python)=33438.80078125MB; mem (CPU total)=33098.171875MB
INFO:root:[   78] Training loss: 0.03897309, Validation loss: 0.09377364, Gradient norm: 0.24141093
INFO:root:At the start of the epoch: mem (CPU python)=33514.9921875MB; mem (CPU total)=33174.21875MB
INFO:root:[   79] Training loss: 0.03881061, Validation loss: 0.09504781, Gradient norm: 0.24989612
INFO:root:At the start of the epoch: mem (CPU python)=33591.1953125MB; mem (CPU total)=33249.9140625MB
INFO:root:[   80] Training loss: 0.03914281, Validation loss: 0.09557240, Gradient norm: 0.23656169
INFO:root:At the start of the epoch: mem (CPU python)=33667.38671875MB; mem (CPU total)=33326.45703125MB
INFO:root:[   81] Training loss: 0.03885908, Validation loss: 0.09494568, Gradient norm: 0.25019632
INFO:root:At the start of the epoch: mem (CPU python)=33743.578125MB; mem (CPU total)=33402.96484375MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[   82] Training loss: 0.03855742, Validation loss: 0.09770855, Gradient norm: 0.22825167
INFO:root:At the start of the epoch: mem (CPU python)=33819.75390625MB; mem (CPU total)=33479.2265625MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[   83] Training loss: 0.03873664, Validation loss: 0.09336171, Gradient norm: 0.22789227
INFO:root:At the start of the epoch: mem (CPU python)=33895.94921875MB; mem (CPU total)=33556.17578125MB
INFO:root:[   84] Training loss: 0.03825782, Validation loss: 0.09430458, Gradient norm: 0.20127139
INFO:root:At the start of the epoch: mem (CPU python)=33972.140625MB; mem (CPU total)=33631.578125MB
INFO:root:[   85] Training loss: 0.03854778, Validation loss: 0.09312159, Gradient norm: 0.21387613
INFO:root:At the start of the epoch: mem (CPU python)=34048.328125MB; mem (CPU total)=33708.40625MB
INFO:root:[   86] Training loss: 0.03808186, Validation loss: 0.09337452, Gradient norm: 0.20287943
INFO:root:At the start of the epoch: mem (CPU python)=34124.51953125MB; mem (CPU total)=33784.421875MB
INFO:root:[   87] Training loss: 0.03821022, Validation loss: 0.09411421, Gradient norm: 0.18729000
INFO:root:At the start of the epoch: mem (CPU python)=34200.70703125MB; mem (CPU total)=33860.94921875MB
INFO:root:[   88] Training loss: 0.03830722, Validation loss: 0.09332323, Gradient norm: 0.23618822
INFO:root:At the start of the epoch: mem (CPU python)=34276.90234375MB; mem (CPU total)=33936.4375MB
INFO:root:[   89] Training loss: 0.03835971, Validation loss: 0.09305491, Gradient norm: 0.21787477
INFO:root:At the start of the epoch: mem (CPU python)=34353.08984375MB; mem (CPU total)=34013.28125MB
INFO:root:[   90] Training loss: 0.03829280, Validation loss: 0.09303176, Gradient norm: 0.19826555
INFO:root:At the start of the epoch: mem (CPU python)=34429.28125MB; mem (CPU total)=34090.2578125MB
INFO:root:[   91] Training loss: 0.03810635, Validation loss: 0.09665948, Gradient norm: 0.21353608
INFO:root:At the start of the epoch: mem (CPU python)=34505.4765625MB; mem (CPU total)=34166.12109375MB
INFO:root:[   92] Training loss: 0.03828938, Validation loss: 0.09353872, Gradient norm: 0.22354518
INFO:root:At the start of the epoch: mem (CPU python)=34581.66796875MB; mem (CPU total)=34242.40625MB
INFO:root:[   93] Training loss: 0.03825246, Validation loss: 0.09440668, Gradient norm: 0.19572387
INFO:root:At the start of the epoch: mem (CPU python)=34657.859375MB; mem (CPU total)=34318.6953125MB
INFO:root:[   94] Training loss: 0.03839124, Validation loss: 0.09298397, Gradient norm: 0.22492110
INFO:root:At the start of the epoch: mem (CPU python)=34734.046875MB; mem (CPU total)=34395.046875MB
INFO:root:[   95] Training loss: 0.03782268, Validation loss: 0.09417066, Gradient norm: 0.21188445
INFO:root:At the start of the epoch: mem (CPU python)=34810.2421875MB; mem (CPU total)=34471.35546875MB
INFO:root:[   96] Training loss: 0.03832506, Validation loss: 0.09635152, Gradient norm: 0.21235886
INFO:root:At the start of the epoch: mem (CPU python)=34886.43359375MB; mem (CPU total)=34547.92578125MB
INFO:root:[   97] Training loss: 0.03841854, Validation loss: 0.09277639, Gradient norm: 0.22497812
INFO:root:At the start of the epoch: mem (CPU python)=34962.62109375MB; mem (CPU total)=34624.20703125MB
INFO:root:[   98] Training loss: 0.03834737, Validation loss: 0.09339456, Gradient norm: 0.20128225
INFO:root:At the start of the epoch: mem (CPU python)=35038.8125MB; mem (CPU total)=34700.12890625MB
INFO:root:[   99] Training loss: 0.03818837, Validation loss: 0.09334869, Gradient norm: 0.21089562
INFO:root:At the start of the epoch: mem (CPU python)=35115.00390625MB; mem (CPU total)=34776.62109375MB
INFO:root:[  100] Training loss: 0.03856033, Validation loss: 0.09429191, Gradient norm: 0.21929003
INFO:root:At the start of the epoch: mem (CPU python)=35191.1953125MB; mem (CPU total)=34852.8984375MB
INFO:root:[  101] Training loss: 0.03795728, Validation loss: 0.09421600, Gradient norm: 0.21176811
INFO:root:At the start of the epoch: mem (CPU python)=35267.38671875MB; mem (CPU total)=34929.15625MB
INFO:root:[  102] Training loss: 0.03814498, Validation loss: 0.09303974, Gradient norm: 0.22231690
INFO:root:At the start of the epoch: mem (CPU python)=35343.57421875MB; mem (CPU total)=35004.83203125MB
INFO:root:[  103] Training loss: 0.03785454, Validation loss: 0.09570462, Gradient norm: 0.20143070
INFO:root:At the start of the epoch: mem (CPU python)=35419.76953125MB; mem (CPU total)=35080.34375MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  104] Training loss: 0.03828480, Validation loss: 0.09574797, Gradient norm: 0.20590401
INFO:root:At the start of the epoch: mem (CPU python)=35495.95703125MB; mem (CPU total)=35156.8125MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  105] Training loss: 0.03809563, Validation loss: 0.09570911, Gradient norm: 0.19695290
INFO:root:At the start of the epoch: mem (CPU python)=35572.1484375MB; mem (CPU total)=35233.359375MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  106] Training loss: 0.03809571, Validation loss: 0.09562077, Gradient norm: 0.20199229
INFO:root:At the start of the epoch: mem (CPU python)=35648.33984375MB; mem (CPU total)=35309.6328125MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:EP 106: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=35724.47265625MB; mem (CPU total)=35385.921875MB
INFO:root:Training the model took 6943.648s.
INFO:root:Emptying the cuda cache took 0.024s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.0977
INFO:root:EnergyScoreTrain: 0.05078
INFO:root:CRPSTrain: 0.04117
INFO:root:Gaussian NLLTrain: 1.99135
INFO:root:CoverageTrain: 0.70757
INFO:root:IntervalWidthTrain: 0.25282
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.14025
INFO:root:EnergyScoreValidation: 0.08243
INFO:root:CRPSValidation: 0.06605
INFO:root:Gaussian NLLValidation: 8.11146
INFO:root:CoverageValidation: 0.60407
INFO:root:IntervalWidthValidation: 0.25532
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.1323
INFO:root:EnergyScoreTest: 0.07583
INFO:root:CRPSTest: 0.06114
INFO:root:Gaussian NLLTest: 5.17787
INFO:root:CoverageTest: 0.61865
INFO:root:IntervalWidthTest: 0.24311
INFO:root:After validation: mem (CPU python)=35871.015625MB; mem (CPU total)=35531.6484375MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=35871.015625MB; mem (CPU total)=35531.67578125MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 299892736
INFO:root:After setting up the model: mem (CPU python)=35872.359375MB; mem (CPU total)=35533.15234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=35872.359375MB; mem (CPU total)=35533.15234375MB
INFO:root:[    1] Training loss: 0.37674285, Validation loss: 0.23076971, Gradient norm: 0.75467099
INFO:root:At the start of the epoch: mem (CPU python)=35948.5859375MB; mem (CPU total)=35609.70703125MB
INFO:root:[    2] Training loss: 0.16498668, Validation loss: 0.18495384, Gradient norm: 1.33949188
INFO:root:At the start of the epoch: mem (CPU python)=36024.76953125MB; mem (CPU total)=35685.62109375MB
INFO:root:[    3] Training loss: 0.13352231, Validation loss: 0.15877167, Gradient norm: 1.01235798
INFO:root:At the start of the epoch: mem (CPU python)=36100.98046875MB; mem (CPU total)=35765.734375MB
INFO:root:[    4] Training loss: 0.12366585, Validation loss: 0.14976546, Gradient norm: 1.26947628
INFO:root:At the start of the epoch: mem (CPU python)=36177.1875MB; mem (CPU total)=35842.0078125MB
INFO:root:[    5] Training loss: 0.11639438, Validation loss: 0.13786035, Gradient norm: 1.14944924
INFO:root:At the start of the epoch: mem (CPU python)=36253.390625MB; mem (CPU total)=35917.6953125MB
INFO:root:[    6] Training loss: 0.10812597, Validation loss: 0.12601147, Gradient norm: 0.96236404
INFO:root:At the start of the epoch: mem (CPU python)=36329.5859375MB; mem (CPU total)=35994.0078125MB
INFO:root:[    7] Training loss: 0.10437813, Validation loss: 0.12597835, Gradient norm: 1.04977206
INFO:root:At the start of the epoch: mem (CPU python)=36405.77734375MB; mem (CPU total)=36070.328125MB
INFO:root:[    8] Training loss: 0.09937752, Validation loss: 0.12631505, Gradient norm: 0.89527635
INFO:root:At the start of the epoch: mem (CPU python)=36481.96484375MB; mem (CPU total)=36146.6015625MB
INFO:root:[    9] Training loss: 0.09833268, Validation loss: 0.11653412, Gradient norm: 1.02734612
INFO:root:At the start of the epoch: mem (CPU python)=36558.16015625MB; mem (CPU total)=36222.90234375MB
INFO:root:[   10] Training loss: 0.09646487, Validation loss: 0.11191021, Gradient norm: 1.00702856
INFO:root:At the start of the epoch: mem (CPU python)=36634.34765625MB; mem (CPU total)=36299.3515625MB
INFO:root:[   11] Training loss: 0.09006499, Validation loss: 0.11840870, Gradient norm: 0.70728148
INFO:root:At the start of the epoch: mem (CPU python)=36710.5390625MB; mem (CPU total)=36375.3515625MB
INFO:root:[   12] Training loss: 0.08881639, Validation loss: 0.11326019, Gradient norm: 0.83306670
INFO:root:At the start of the epoch: mem (CPU python)=36786.7265625MB; mem (CPU total)=36451.33984375MB
INFO:root:[   13] Training loss: 0.08555889, Validation loss: 0.10776444, Gradient norm: 0.70692120
INFO:root:At the start of the epoch: mem (CPU python)=36862.91796875MB; mem (CPU total)=36527.81640625MB
INFO:root:[   14] Training loss: 0.08574206, Validation loss: 0.11297389, Gradient norm: 0.83001504
INFO:root:At the start of the epoch: mem (CPU python)=36939.11328125MB; mem (CPU total)=36603.59375MB
INFO:root:[   15] Training loss: 0.08658207, Validation loss: 0.10334018, Gradient norm: 0.89844636
INFO:root:At the start of the epoch: mem (CPU python)=37015.3046875MB; mem (CPU total)=36680.14453125MB
INFO:root:[   16] Training loss: 0.08352706, Validation loss: 0.10507612, Gradient norm: 0.85464987
INFO:root:At the start of the epoch: mem (CPU python)=37091.5MB; mem (CPU total)=36756.390625MB
INFO:root:[   17] Training loss: 0.08321382, Validation loss: 0.10133331, Gradient norm: 0.83617777
INFO:root:At the start of the epoch: mem (CPU python)=37167.6875MB; mem (CPU total)=36832.87890625MB
INFO:root:[   18] Training loss: 0.08036056, Validation loss: 0.10513319, Gradient norm: 0.73611724
INFO:root:At the start of the epoch: mem (CPU python)=37243.87890625MB; mem (CPU total)=36909.125MB
INFO:root:[   19] Training loss: 0.07648263, Validation loss: 0.09685358, Gradient norm: 0.60018583
INFO:root:At the start of the epoch: mem (CPU python)=37320.06640625MB; mem (CPU total)=36985.8515625MB
INFO:root:[   20] Training loss: 0.07556182, Validation loss: 0.09859259, Gradient norm: 0.58330862
INFO:root:At the start of the epoch: mem (CPU python)=37396.2578125MB; mem (CPU total)=37061.359375MB
INFO:root:[   21] Training loss: 0.07558209, Validation loss: 0.10068376, Gradient norm: 0.67315567
INFO:root:At the start of the epoch: mem (CPU python)=37472.44921875MB; mem (CPU total)=37137.40625MB
INFO:root:[   22] Training loss: 0.07414715, Validation loss: 0.09470370, Gradient norm: 0.61971488
INFO:root:At the start of the epoch: mem (CPU python)=37548.640625MB; mem (CPU total)=37213.984375MB
INFO:root:[   23] Training loss: 0.07696224, Validation loss: 0.09922755, Gradient norm: 0.86761237
INFO:root:At the start of the epoch: mem (CPU python)=37624.8359375MB; mem (CPU total)=37290.27734375MB
INFO:root:[   24] Training loss: 0.07166232, Validation loss: 0.09990368, Gradient norm: 0.65210553
INFO:root:At the start of the epoch: mem (CPU python)=37701.01953125MB; mem (CPU total)=37366.54296875MB
INFO:root:[   25] Training loss: 0.06952309, Validation loss: 0.09984241, Gradient norm: 0.58696155
INFO:root:At the start of the epoch: mem (CPU python)=37777.21484375MB; mem (CPU total)=37443.0546875MB
INFO:root:[   26] Training loss: 0.07029080, Validation loss: 0.09476951, Gradient norm: 0.56136166
INFO:root:At the start of the epoch: mem (CPU python)=37853.40625MB; mem (CPU total)=37519.21484375MB
INFO:root:[   27] Training loss: 0.07392983, Validation loss: 0.09319776, Gradient norm: 0.89109650
INFO:root:At the start of the epoch: mem (CPU python)=37929.59375MB; mem (CPU total)=37595.78125MB
INFO:root:[   28] Training loss: 0.06868674, Validation loss: 0.09746542, Gradient norm: 0.66292106
INFO:root:At the start of the epoch: mem (CPU python)=38005.78515625MB; mem (CPU total)=37672.578125MB
INFO:root:[   29] Training loss: 0.06824955, Validation loss: 0.09218759, Gradient norm: 0.68692048
INFO:root:At the start of the epoch: mem (CPU python)=38081.9765625MB; mem (CPU total)=37748.44921875MB
INFO:root:[   30] Training loss: 0.06581837, Validation loss: 0.09570988, Gradient norm: 0.54441818
INFO:root:At the start of the epoch: mem (CPU python)=38158.171875MB; mem (CPU total)=37824.77734375MB
INFO:root:[   31] Training loss: 0.06548260, Validation loss: 0.10435889, Gradient norm: 0.56130147
INFO:root:At the start of the epoch: mem (CPU python)=38234.359375MB; mem (CPU total)=37901.00390625MB
INFO:root:[   32] Training loss: 0.06404391, Validation loss: 0.09244925, Gradient norm: 0.53493184
INFO:root:At the start of the epoch: mem (CPU python)=38310.546875MB; mem (CPU total)=37977.77734375MB
INFO:root:[   33] Training loss: 0.06208264, Validation loss: 0.09522379, Gradient norm: 0.49821629
INFO:root:At the start of the epoch: mem (CPU python)=38386.7421875MB; mem (CPU total)=38054.02734375MB
INFO:root:[   34] Training loss: 0.06270781, Validation loss: 0.09394024, Gradient norm: 0.59443545
INFO:root:At the start of the epoch: mem (CPU python)=38462.9296875MB; mem (CPU total)=38130.5390625MB
INFO:root:[   35] Training loss: 0.06417931, Validation loss: 0.09401363, Gradient norm: 0.69441366
INFO:root:At the start of the epoch: mem (CPU python)=38539.12109375MB; mem (CPU total)=38206.55078125MB
INFO:root:[   36] Training loss: 0.06274415, Validation loss: 0.09534098, Gradient norm: 0.65321680
INFO:root:At the start of the epoch: mem (CPU python)=38615.3125MB; mem (CPU total)=38282.8203125MB
INFO:root:[   37] Training loss: 0.05985896, Validation loss: 0.09860419, Gradient norm: 0.58458523
INFO:root:At the start of the epoch: mem (CPU python)=38691.50390625MB; mem (CPU total)=38359.078125MB
INFO:root:[   38] Training loss: 0.05919969, Validation loss: 0.09724284, Gradient norm: 0.46866793
INFO:root:At the start of the epoch: mem (CPU python)=38767.69921875MB; mem (CPU total)=38435.87109375MB
INFO:root:[   39] Training loss: 0.06045757, Validation loss: 0.09664897, Gradient norm: 0.61352680
INFO:root:At the start of the epoch: mem (CPU python)=38843.88671875MB; mem (CPU total)=38511.87109375MB
INFO:root:[   40] Training loss: 0.05942250, Validation loss: 0.09289255, Gradient norm: 0.59284525
INFO:root:At the start of the epoch: mem (CPU python)=38920.078125MB; mem (CPU total)=38588.41015625MB
INFO:root:[   41] Training loss: 0.05971942, Validation loss: 0.09184893, Gradient norm: 0.62634366
INFO:root:At the start of the epoch: mem (CPU python)=38996.26953125MB; mem (CPU total)=38664.84765625MB
INFO:root:[   42] Training loss: 0.05772478, Validation loss: 0.09490743, Gradient norm: 0.54517970
INFO:root:At the start of the epoch: mem (CPU python)=39072.4609375MB; mem (CPU total)=38740.91015625MB
INFO:root:[   43] Training loss: 0.05729541, Validation loss: 0.08932540, Gradient norm: 0.55564283
INFO:root:At the start of the epoch: mem (CPU python)=39148.65234375MB; mem (CPU total)=38817.7265625MB
INFO:root:[   44] Training loss: 0.05821837, Validation loss: 0.09021258, Gradient norm: 0.64452777
INFO:root:At the start of the epoch: mem (CPU python)=39224.84375MB; mem (CPU total)=38893.78125MB
INFO:root:[   45] Training loss: 0.05568136, Validation loss: 0.09113577, Gradient norm: 0.51458388
INFO:root:At the start of the epoch: mem (CPU python)=39301.03515625MB; mem (CPU total)=38970.77734375MB
INFO:root:[   46] Training loss: 0.05574779, Validation loss: 0.09400378, Gradient norm: 0.52010003
INFO:root:At the start of the epoch: mem (CPU python)=39377.22265625MB; mem (CPU total)=39046.78515625MB
INFO:root:[   47] Training loss: 0.05486857, Validation loss: 0.09690507, Gradient norm: 0.53195925
INFO:root:At the start of the epoch: mem (CPU python)=39453.41796875MB; mem (CPU total)=39123.1796875MB
INFO:root:[   48] Training loss: 0.05450175, Validation loss: 0.09285106, Gradient norm: 0.52924145
INFO:root:At the start of the epoch: mem (CPU python)=39529.60546875MB; mem (CPU total)=39199.671875MB
INFO:root:[   49] Training loss: 0.05554001, Validation loss: 0.09228388, Gradient norm: 0.62140942
INFO:root:At the start of the epoch: mem (CPU python)=39605.796875MB; mem (CPU total)=39275.94140625MB
INFO:root:[   50] Training loss: 0.05423939, Validation loss: 0.09438466, Gradient norm: 0.56219388
INFO:root:At the start of the epoch: mem (CPU python)=39681.98828125MB; mem (CPU total)=39352.171875MB
INFO:root:[   51] Training loss: 0.05472437, Validation loss: 0.09654992, Gradient norm: 0.57484854
INFO:root:At the start of the epoch: mem (CPU python)=39758.17578125MB; mem (CPU total)=39428.31640625MB
INFO:root:[   52] Training loss: 0.05239817, Validation loss: 0.08858695, Gradient norm: 0.48214859
INFO:root:At the start of the epoch: mem (CPU python)=39834.37109375MB; mem (CPU total)=39504.6875MB
INFO:root:[   53] Training loss: 0.05329664, Validation loss: 0.09082568, Gradient norm: 0.58391934
INFO:root:At the start of the epoch: mem (CPU python)=39910.55859375MB; mem (CPU total)=39580.7265625MB
INFO:root:[   54] Training loss: 0.05175729, Validation loss: 0.08730891, Gradient norm: 0.54152054
INFO:root:At the start of the epoch: mem (CPU python)=39986.7578125MB; mem (CPU total)=39657.7578125MB
INFO:root:[   55] Training loss: 0.05113476, Validation loss: 0.09308322, Gradient norm: 0.52439010
INFO:root:At the start of the epoch: mem (CPU python)=40062.9453125MB; mem (CPU total)=39733.79296875MB
INFO:root:[   56] Training loss: 0.05207676, Validation loss: 0.09183428, Gradient norm: 0.59953352
INFO:root:At the start of the epoch: mem (CPU python)=40139.13671875MB; mem (CPU total)=39810.30078125MB
INFO:root:[   57] Training loss: 0.05145787, Validation loss: 0.09028339, Gradient norm: 0.55960097
INFO:root:At the start of the epoch: mem (CPU python)=40215.328125MB; mem (CPU total)=39886.5546875MB
INFO:root:[   58] Training loss: 0.05027836, Validation loss: 0.09388899, Gradient norm: 0.50538994
INFO:root:At the start of the epoch: mem (CPU python)=40291.515625MB; mem (CPU total)=39962.45703125MB
INFO:root:[   59] Training loss: 0.05092925, Validation loss: 0.09613610, Gradient norm: 0.57281238
INFO:root:At the start of the epoch: mem (CPU python)=40367.7109375MB; mem (CPU total)=40038.9296875MB
INFO:root:[   60] Training loss: 0.04963948, Validation loss: 0.09037323, Gradient norm: 0.49470169
INFO:root:At the start of the epoch: mem (CPU python)=40443.90234375MB; mem (CPU total)=40115.4375MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   61] Training loss: 0.04904718, Validation loss: 0.09033960, Gradient norm: 0.48458075
INFO:root:At the start of the epoch: mem (CPU python)=40520.09375MB; mem (CPU total)=40191.9609375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   62] Training loss: 0.04576180, Validation loss: 0.08819470, Gradient norm: 0.37045043
INFO:root:At the start of the epoch: mem (CPU python)=40596.28515625MB; mem (CPU total)=40267.71484375MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   63] Training loss: 0.04428905, Validation loss: 0.08975887, Gradient norm: 0.35460116
INFO:root:At the start of the epoch: mem (CPU python)=40672.47265625MB; mem (CPU total)=40344.23828125MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:EP 63: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=40748.5390625MB; mem (CPU total)=40420.52734375MB
INFO:root:Training the model took 4619.371s.
INFO:root:Emptying the cuda cache took 0.026s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.1009
INFO:root:EnergyScoreTrain: 0.05309
INFO:root:CRPSTrain: 0.04304
INFO:root:Gaussian NLLTrain: 2.65978
INFO:root:CoverageTrain: 0.69625
INFO:root:IntervalWidthTrain: 0.24938
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.12451
INFO:root:EnergyScoreValidation: 0.07009
INFO:root:CRPSValidation: 0.05688
INFO:root:Gaussian NLLValidation: 5.12658
INFO:root:CoverageValidation: 0.62962
INFO:root:IntervalWidthValidation: 0.24783
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.12368
INFO:root:EnergyScoreTest: 0.06866
INFO:root:CRPSTest: 0.0557
INFO:root:Gaussian NLLTest: 3.30864
INFO:root:CoverageTest: 0.61176
INFO:root:IntervalWidthTest: 0.23655
INFO:root:After validation: mem (CPU python)=40895.1484375MB; mem (CPU total)=40567.69921875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=40895.15234375MB; mem (CPU total)=40567.65234375MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 299892736
INFO:root:After setting up the model: mem (CPU python)=40896.5MB; mem (CPU total)=40568.63671875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=40896.5MB; mem (CPU total)=40568.85546875MB
INFO:root:[    1] Training loss: 0.37505025, Validation loss: 0.20530201, Gradient norm: 0.98897040
INFO:root:At the start of the epoch: mem (CPU python)=40975.55859375MB; mem (CPU total)=40647.6953125MB
INFO:root:[    2] Training loss: 0.16498436, Validation loss: 0.16283054, Gradient norm: 1.42326344
INFO:root:At the start of the epoch: mem (CPU python)=41051.74609375MB; mem (CPU total)=40724.34765625MB
INFO:root:[    3] Training loss: 0.13386521, Validation loss: 0.14666000, Gradient norm: 1.17953765
INFO:root:At the start of the epoch: mem (CPU python)=41127.953125MB; mem (CPU total)=40800.38671875MB
INFO:root:[    4] Training loss: 0.11833453, Validation loss: 0.14241994, Gradient norm: 1.06156327
INFO:root:At the start of the epoch: mem (CPU python)=41204.1484375MB; mem (CPU total)=40877.13671875MB
INFO:root:[    5] Training loss: 0.11199656, Validation loss: 0.14585387, Gradient norm: 1.03386319
INFO:root:At the start of the epoch: mem (CPU python)=41280.3359375MB; mem (CPU total)=40953.12109375MB
INFO:root:[    6] Training loss: 0.10461156, Validation loss: 0.12861660, Gradient norm: 0.91135948
INFO:root:At the start of the epoch: mem (CPU python)=41356.53125MB; mem (CPU total)=41029.9765625MB
INFO:root:[    7] Training loss: 0.10421833, Validation loss: 0.14795155, Gradient norm: 1.03432047
INFO:root:At the start of the epoch: mem (CPU python)=41432.71875MB; mem (CPU total)=41106.01953125MB
INFO:root:[    8] Training loss: 0.09983758, Validation loss: 0.12711039, Gradient norm: 1.06603192
INFO:root:At the start of the epoch: mem (CPU python)=41508.91015625MB; mem (CPU total)=41182.3515625MB
INFO:root:[    9] Training loss: 0.09736774, Validation loss: 0.13674800, Gradient norm: 1.11388348
INFO:root:At the start of the epoch: mem (CPU python)=41585.1015625MB; mem (CPU total)=41258.41015625MB
INFO:root:[   10] Training loss: 0.09419656, Validation loss: 0.11710171, Gradient norm: 0.97202061
INFO:root:At the start of the epoch: mem (CPU python)=41661.29296875MB; mem (CPU total)=41335.0078125MB
INFO:root:[   11] Training loss: 0.08902780, Validation loss: 0.13473460, Gradient norm: 0.81925223
INFO:root:At the start of the epoch: mem (CPU python)=41737.484375MB; mem (CPU total)=41411.01953125MB
INFO:root:[   12] Training loss: 0.09035993, Validation loss: 0.11600762, Gradient norm: 0.97630795
INFO:root:At the start of the epoch: mem (CPU python)=41813.671875MB; mem (CPU total)=41487.60546875MB
INFO:root:[   13] Training loss: 0.08633039, Validation loss: 0.11014312, Gradient norm: 0.80595667
INFO:root:At the start of the epoch: mem (CPU python)=41889.86328125MB; mem (CPU total)=41564.015625MB
INFO:root:[   14] Training loss: 0.08424728, Validation loss: 0.12015759, Gradient norm: 0.81978289
INFO:root:At the start of the epoch: mem (CPU python)=41966.0546875MB; mem (CPU total)=41640.30859375MB
INFO:root:[   15] Training loss: 0.08463235, Validation loss: 0.11709876, Gradient norm: 0.95597365
INFO:root:At the start of the epoch: mem (CPU python)=42042.24609375MB; mem (CPU total)=41721.01171875MB
INFO:root:[   16] Training loss: 0.08076392, Validation loss: 0.10842169, Gradient norm: 0.73093384
INFO:root:At the start of the epoch: mem (CPU python)=42118.4375MB; mem (CPU total)=41796.0703125MB
INFO:root:[   17] Training loss: 0.08009733, Validation loss: 0.10468119, Gradient norm: 0.75727088
INFO:root:At the start of the epoch: mem (CPU python)=42194.625MB; mem (CPU total)=41872.6796875MB
INFO:root:[   18] Training loss: 0.07920802, Validation loss: 0.10444431, Gradient norm: 0.84185324
INFO:root:At the start of the epoch: mem (CPU python)=42270.8203125MB; mem (CPU total)=41948.93359375MB
INFO:root:[   19] Training loss: 0.07889613, Validation loss: 0.10673598, Gradient norm: 0.84136938
INFO:root:At the start of the epoch: mem (CPU python)=42347.0078125MB; mem (CPU total)=42024.7421875MB
INFO:root:[   20] Training loss: 0.07707115, Validation loss: 0.11499159, Gradient norm: 0.72919604
INFO:root:At the start of the epoch: mem (CPU python)=42423.19921875MB; mem (CPU total)=42100.796875MB
INFO:root:[   21] Training loss: 0.07751919, Validation loss: 0.10469490, Gradient norm: 0.95976022
INFO:root:At the start of the epoch: mem (CPU python)=42499.39453125MB; mem (CPU total)=42177.3203125MB
INFO:root:[   22] Training loss: 0.07281436, Validation loss: 0.10176661, Gradient norm: 0.70603296
INFO:root:At the start of the epoch: mem (CPU python)=42575.58203125MB; mem (CPU total)=42253.36328125MB
INFO:root:[   23] Training loss: 0.07505251, Validation loss: 0.11551004, Gradient norm: 0.75784810
INFO:root:At the start of the epoch: mem (CPU python)=42651.7734375MB; mem (CPU total)=42329.671875MB
INFO:root:[   24] Training loss: 0.07628126, Validation loss: 0.09921686, Gradient norm: 0.90660822
INFO:root:At the start of the epoch: mem (CPU python)=42727.9609375MB; mem (CPU total)=42406.18359375MB
INFO:root:[   25] Training loss: 0.07110064, Validation loss: 0.09566386, Gradient norm: 0.67411090
INFO:root:At the start of the epoch: mem (CPU python)=42804.15625MB; mem (CPU total)=42482.73828125MB
INFO:root:[   26] Training loss: 0.07225038, Validation loss: 0.11101429, Gradient norm: 0.82881132
INFO:root:At the start of the epoch: mem (CPU python)=42880.34375MB; mem (CPU total)=42558.96875MB
INFO:root:[   27] Training loss: 0.06943514, Validation loss: 0.09436948, Gradient norm: 0.65441614
INFO:root:At the start of the epoch: mem (CPU python)=42956.53515625MB; mem (CPU total)=42635.5234375MB
INFO:root:[   28] Training loss: 0.06762266, Validation loss: 0.10265166, Gradient norm: 0.66941847
INFO:root:At the start of the epoch: mem (CPU python)=43032.7265625MB; mem (CPU total)=42711.7578125MB
INFO:root:[   29] Training loss: 0.06641768, Validation loss: 0.09665484, Gradient norm: 0.59037427
INFO:root:At the start of the epoch: mem (CPU python)=43108.9140625MB; mem (CPU total)=42788.01953125MB
INFO:root:[   30] Training loss: 0.06627469, Validation loss: 0.09291851, Gradient norm: 0.69378159
INFO:root:At the start of the epoch: mem (CPU python)=43185.109375MB; mem (CPU total)=42863.99609375MB
INFO:root:[   31] Training loss: 0.06458626, Validation loss: 0.10222106, Gradient norm: 0.65364149
INFO:root:At the start of the epoch: mem (CPU python)=43261.296875MB; mem (CPU total)=42940.44140625MB
INFO:root:[   32] Training loss: 0.06468452, Validation loss: 0.09426904, Gradient norm: 0.60763638
INFO:root:At the start of the epoch: mem (CPU python)=43337.4921875MB; mem (CPU total)=43016.671875MB
INFO:root:[   33] Training loss: 0.06387839, Validation loss: 0.10050122, Gradient norm: 0.67977063
INFO:root:At the start of the epoch: mem (CPU python)=43413.6875MB; mem (CPU total)=43093.5MB
INFO:root:[   34] Training loss: 0.06271543, Validation loss: 0.09614539, Gradient norm: 0.64910318
INFO:root:At the start of the epoch: mem (CPU python)=43489.875MB; mem (CPU total)=43169.66015625MB
INFO:root:[   35] Training loss: 0.06131873, Validation loss: 0.10353952, Gradient norm: 0.60131425
INFO:root:At the start of the epoch: mem (CPU python)=43566.06640625MB; mem (CPU total)=43246.1328125MB
INFO:root:[   36] Training loss: 0.06041034, Validation loss: 0.09237827, Gradient norm: 0.60743372
INFO:root:At the start of the epoch: mem (CPU python)=43642.25390625MB; mem (CPU total)=43322.4296875MB
INFO:root:[   37] Training loss: 0.06388042, Validation loss: 0.09414413, Gradient norm: 0.80892354
INFO:root:At the start of the epoch: mem (CPU python)=43718.44921875MB; mem (CPU total)=43398.4140625MB
INFO:root:[   38] Training loss: 0.05932443, Validation loss: 0.10004331, Gradient norm: 0.54085678
INFO:root:At the start of the epoch: mem (CPU python)=43794.640625MB; mem (CPU total)=43474.88671875MB
INFO:root:[   39] Training loss: 0.06097122, Validation loss: 0.09214942, Gradient norm: 0.69180740
INFO:root:At the start of the epoch: mem (CPU python)=43870.83203125MB; mem (CPU total)=43550.65234375MB
INFO:root:[   40] Training loss: 0.06064022, Validation loss: 0.09532652, Gradient norm: 0.70741683
INFO:root:At the start of the epoch: mem (CPU python)=43947.0234375MB; mem (CPU total)=43626.6484375MB
INFO:root:[   41] Training loss: 0.06032438, Validation loss: 0.09083166, Gradient norm: 0.74212844
INFO:root:At the start of the epoch: mem (CPU python)=44023.21484375MB; mem (CPU total)=43703.46875MB
INFO:root:[   42] Training loss: 0.05741856, Validation loss: 0.10029222, Gradient norm: 0.55318254
INFO:root:At the start of the epoch: mem (CPU python)=44099.40625MB; mem (CPU total)=43779.70703125MB
INFO:root:[   43] Training loss: 0.05755490, Validation loss: 0.08978072, Gradient norm: 0.57966312
INFO:root:At the start of the epoch: mem (CPU python)=44175.59375MB; mem (CPU total)=43856.375MB
INFO:root:[   44] Training loss: 0.05514148, Validation loss: 0.09232348, Gradient norm: 0.44455809
INFO:root:At the start of the epoch: mem (CPU python)=44251.78515625MB; mem (CPU total)=43932.625MB
INFO:root:[   45] Training loss: 0.05562366, Validation loss: 0.10690943, Gradient norm: 0.60649161
INFO:root:At the start of the epoch: mem (CPU python)=44327.9765625MB; mem (CPU total)=44008.875MB
INFO:root:[   46] Training loss: 0.05719105, Validation loss: 0.09353685, Gradient norm: 0.62098616
INFO:root:At the start of the epoch: mem (CPU python)=44404.16796875MB; mem (CPU total)=44085.63671875MB
INFO:root:[   47] Training loss: 0.05459562, Validation loss: 0.09813098, Gradient norm: 0.54871301
INFO:root:At the start of the epoch: mem (CPU python)=44480.359375MB; mem (CPU total)=44161.390625MB
INFO:root:[   48] Training loss: 0.05304037, Validation loss: 0.08992165, Gradient norm: 0.46019720
INFO:root:At the start of the epoch: mem (CPU python)=44556.546875MB; mem (CPU total)=44237.9375MB
INFO:root:[   49] Training loss: 0.05333377, Validation loss: 0.08868203, Gradient norm: 0.52668307
INFO:root:At the start of the epoch: mem (CPU python)=44632.73828125MB; mem (CPU total)=44313.6875MB
INFO:root:[   50] Training loss: 0.05288874, Validation loss: 0.09482584, Gradient norm: 0.52545298
INFO:root:At the start of the epoch: mem (CPU python)=44708.93359375MB; mem (CPU total)=44390.0MB
INFO:root:[   51] Training loss: 0.05236955, Validation loss: 0.09518594, Gradient norm: 0.49657569
INFO:root:At the start of the epoch: mem (CPU python)=44785.12109375MB; mem (CPU total)=44466.5MB
INFO:root:[   52] Training loss: 0.05441008, Validation loss: 0.09722173, Gradient norm: 0.67822650
INFO:root:At the start of the epoch: mem (CPU python)=44861.3125MB; mem (CPU total)=44542.78125MB
INFO:root:[   53] Training loss: 0.05126820, Validation loss: 0.08994752, Gradient norm: 0.49128999
INFO:root:At the start of the epoch: mem (CPU python)=44937.50390625MB; mem (CPU total)=44619.2265625MB
INFO:root:[   54] Training loss: 0.05119132, Validation loss: 0.08905193, Gradient norm: 0.60247432
INFO:root:At the start of the epoch: mem (CPU python)=45013.69921875MB; mem (CPU total)=44695.81640625MB
INFO:root:[   55] Training loss: 0.05240800, Validation loss: 0.09015798, Gradient norm: 0.62592824
INFO:root:At the start of the epoch: mem (CPU python)=45089.890625MB; mem (CPU total)=44771.828125MB
INFO:root:[   56] Training loss: 0.05093183, Validation loss: 0.09093827, Gradient norm: 0.55712743
INFO:root:At the start of the epoch: mem (CPU python)=45166.078125MB; mem (CPU total)=44848.4375MB
INFO:root:[   57] Training loss: 0.05271916, Validation loss: 0.09866463, Gradient norm: 0.68724757
INFO:root:At the start of the epoch: mem (CPU python)=45242.26953125MB; mem (CPU total)=44924.73828125MB
INFO:root:[   58] Training loss: 0.05188772, Validation loss: 0.09457223, Gradient norm: 0.64224842
INFO:root:At the start of the epoch: mem (CPU python)=45318.4609375MB; mem (CPU total)=45000.546875MB
INFO:root:[   59] Training loss: 0.05021389, Validation loss: 0.09511348, Gradient norm: 0.49809405
INFO:root:At the start of the epoch: mem (CPU python)=45394.65234375MB; mem (CPU total)=45077.30859375MB
INFO:root:[   60] Training loss: 0.05106971, Validation loss: 0.09776227, Gradient norm: 0.69592006
INFO:root:At the start of the epoch: mem (CPU python)=45470.83984375MB; mem (CPU total)=45153.375MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   61] Training loss: 0.05151280, Validation loss: 0.09107249, Gradient norm: 0.64290219
INFO:root:At the start of the epoch: mem (CPU python)=45547.03515625MB; mem (CPU total)=45229.94140625MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   62] Training loss: 0.04622860, Validation loss: 0.09493793, Gradient norm: 0.44046281
INFO:root:At the start of the epoch: mem (CPU python)=45623.22265625MB; mem (CPU total)=45306.234375MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   63] Training loss: 0.04414959, Validation loss: 0.08684580, Gradient norm: 0.37100927
INFO:root:At the start of the epoch: mem (CPU python)=45699.421875MB; mem (CPU total)=45383.27734375MB
INFO:root:[   64] Training loss: 0.04312619, Validation loss: 0.08832645, Gradient norm: 0.33161634
INFO:root:At the start of the epoch: mem (CPU python)=45775.609375MB; mem (CPU total)=45458.6953125MB
INFO:root:[   65] Training loss: 0.04276881, Validation loss: 0.09169710, Gradient norm: 0.29473520
INFO:root:At the start of the epoch: mem (CPU python)=45851.796875MB; mem (CPU total)=45535.53125MB
INFO:root:[   66] Training loss: 0.04265206, Validation loss: 0.09036602, Gradient norm: 0.27829150
INFO:root:At the start of the epoch: mem (CPU python)=45927.984375MB; mem (CPU total)=45611.7734375MB
INFO:root:[   67] Training loss: 0.04274409, Validation loss: 0.08828846, Gradient norm: 0.33429272
INFO:root:At the start of the epoch: mem (CPU python)=46004.1796875MB; mem (CPU total)=45687.6875MB
INFO:root:[   68] Training loss: 0.04263947, Validation loss: 0.09267423, Gradient norm: 0.31658270
INFO:root:At the start of the epoch: mem (CPU python)=46080.3671875MB; mem (CPU total)=45763.91015625MB
INFO:root:[   69] Training loss: 0.04235880, Validation loss: 0.08960033, Gradient norm: 0.26427646
INFO:root:At the start of the epoch: mem (CPU python)=46156.5625MB; mem (CPU total)=45840.16796875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[   70] Training loss: 0.04281432, Validation loss: 0.08953413, Gradient norm: 0.33311572
INFO:root:At the start of the epoch: mem (CPU python)=46232.75MB; mem (CPU total)=45916.671875MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[   71] Training loss: 0.04185667, Validation loss: 0.09011365, Gradient norm: 0.28008777
INFO:root:At the start of the epoch: mem (CPU python)=46308.94140625MB; mem (CPU total)=45993.67578125MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[   72] Training loss: 0.04148458, Validation loss: 0.09031078, Gradient norm: 0.23209306
INFO:root:At the start of the epoch: mem (CPU python)=46385.13671875MB; mem (CPU total)=46068.91015625MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:EP 72: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=46461.19140625MB; mem (CPU total)=46145.18359375MB
INFO:root:Training the model took 5714.635s.
INFO:root:Emptying the cuda cache took 0.026s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09475
INFO:root:EnergyScoreTrain: 0.04945
INFO:root:CRPSTrain: 0.04004
INFO:root:Gaussian NLLTrain: 1.8098
INFO:root:CoverageTrain: 0.71477
INFO:root:IntervalWidthTrain: 0.25011
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.1287
INFO:root:EnergyScoreValidation: 0.07219
INFO:root:CRPSValidation: 0.05833
INFO:root:Gaussian NLLValidation: 3.44841
INFO:root:CoverageValidation: 0.61982
INFO:root:IntervalWidthValidation: 0.24263
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.1311
INFO:root:EnergyScoreTest: 0.07154
INFO:root:CRPSTest: 0.05792
INFO:root:Gaussian NLLTest: 3.5654
INFO:root:CoverageTest: 0.61822
INFO:root:IntervalWidthTest: 0.25678
INFO:root:After validation: mem (CPU python)=46607.83984375MB; mem (CPU total)=46289.078125MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=46607.83984375MB; mem (CPU total)=46288.9375MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 299892736
INFO:root:After setting up the model: mem (CPU python)=46609.1875MB; mem (CPU total)=46290.4140625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=46609.1875MB; mem (CPU total)=46290.39453125MB
INFO:root:[    1] Training loss: 0.37360683, Validation loss: 0.26468999, Gradient norm: 0.86037754
INFO:root:At the start of the epoch: mem (CPU python)=46685.44921875MB; mem (CPU total)=46366.89453125MB
INFO:root:[    2] Training loss: 0.15911603, Validation loss: 0.19746932, Gradient norm: 1.10277208
INFO:root:At the start of the epoch: mem (CPU python)=46761.640625MB; mem (CPU total)=46443.9140625MB
INFO:root:[    3] Training loss: 0.13727362, Validation loss: 0.17762479, Gradient norm: 1.33875619
INFO:root:At the start of the epoch: mem (CPU python)=46837.84375MB; mem (CPU total)=46519.90234375MB
INFO:root:[    4] Training loss: 0.12310762, Validation loss: 0.17620340, Gradient norm: 1.13800331
INFO:root:At the start of the epoch: mem (CPU python)=46914.03515625MB; mem (CPU total)=46595.98828125MB
INFO:root:[    5] Training loss: 0.11000900, Validation loss: 0.15853509, Gradient norm: 0.87977140
INFO:root:At the start of the epoch: mem (CPU python)=46990.22265625MB; mem (CPU total)=46672.5234375MB
INFO:root:[    6] Training loss: 0.10665325, Validation loss: 0.15256179, Gradient norm: 1.00834940
INFO:root:At the start of the epoch: mem (CPU python)=47066.41796875MB; mem (CPU total)=46749.0546875MB
INFO:root:[    7] Training loss: 0.10050226, Validation loss: 0.14532557, Gradient norm: 0.84022233
INFO:root:At the start of the epoch: mem (CPU python)=47142.60546875MB; mem (CPU total)=46825.375MB
INFO:root:[    8] Training loss: 0.09951649, Validation loss: 0.13917641, Gradient norm: 0.94619567
INFO:root:At the start of the epoch: mem (CPU python)=47218.796875MB; mem (CPU total)=46901.7890625MB
INFO:root:[    9] Training loss: 0.09708472, Validation loss: 0.14246770, Gradient norm: 1.00081934
INFO:root:At the start of the epoch: mem (CPU python)=47294.99609375MB; mem (CPU total)=46977.8671875MB
INFO:root:[   10] Training loss: 0.09181664, Validation loss: 0.15603200, Gradient norm: 0.79524231
INFO:root:At the start of the epoch: mem (CPU python)=47371.18359375MB; mem (CPU total)=47054.890625MB
INFO:root:[   11] Training loss: 0.08972593, Validation loss: 0.13101179, Gradient norm: 0.82612584
INFO:root:At the start of the epoch: mem (CPU python)=47447.375MB; mem (CPU total)=47131.22265625MB
INFO:root:[   12] Training loss: 0.08757343, Validation loss: 0.13847774, Gradient norm: 0.80311706
INFO:root:At the start of the epoch: mem (CPU python)=47523.5625MB; mem (CPU total)=47207.22265625MB
INFO:root:[   13] Training loss: 0.08729276, Validation loss: 0.12419912, Gradient norm: 0.82592030
INFO:root:At the start of the epoch: mem (CPU python)=47599.75390625MB; mem (CPU total)=47284.08203125MB
INFO:root:[   14] Training loss: 0.08424659, Validation loss: 0.12033784, Gradient norm: 0.68949979
INFO:root:At the start of the epoch: mem (CPU python)=47675.94921875MB; mem (CPU total)=47360.6796875MB
INFO:root:[   15] Training loss: 0.08289734, Validation loss: 0.12283001, Gradient norm: 0.82389688
INFO:root:At the start of the epoch: mem (CPU python)=47752.13671875MB; mem (CPU total)=47436.4453125MB
INFO:root:[   16] Training loss: 0.08411129, Validation loss: 0.12560176, Gradient norm: 0.83192616
INFO:root:At the start of the epoch: mem (CPU python)=47828.328125MB; mem (CPU total)=47512.7265625MB
INFO:root:[   17] Training loss: 0.08197375, Validation loss: 0.12153968, Gradient norm: 0.76037126
INFO:root:At the start of the epoch: mem (CPU python)=47904.515625MB; mem (CPU total)=47589.21875MB
INFO:root:[   18] Training loss: 0.07839186, Validation loss: 0.12412267, Gradient norm: 0.70226528
INFO:root:At the start of the epoch: mem (CPU python)=47980.7109375MB; mem (CPU total)=47664.765625MB
INFO:root:[   19] Training loss: 0.07709572, Validation loss: 0.12297472, Gradient norm: 0.71236630
INFO:root:At the start of the epoch: mem (CPU python)=48056.90234375MB; mem (CPU total)=47741.1015625MB
INFO:root:[   20] Training loss: 0.07676164, Validation loss: 0.12165183, Gradient norm: 0.75789417
INFO:root:At the start of the epoch: mem (CPU python)=48133.09375MB; mem (CPU total)=47817.39453125MB
INFO:root:[   21] Training loss: 0.07581886, Validation loss: 0.11938406, Gradient norm: 0.74849640
INFO:root:At the start of the epoch: mem (CPU python)=48209.28515625MB; mem (CPU total)=47894.140625MB
INFO:root:[   22] Training loss: 0.07315599, Validation loss: 0.11631954, Gradient norm: 0.63627061
INFO:root:At the start of the epoch: mem (CPU python)=48285.47265625MB; mem (CPU total)=47970.2109375MB
INFO:root:[   23] Training loss: 0.07044104, Validation loss: 0.12040112, Gradient norm: 0.60213699
INFO:root:At the start of the epoch: mem (CPU python)=48361.6640625MB; mem (CPU total)=48046.46484375MB
INFO:root:[   24] Training loss: 0.06959998, Validation loss: 0.11830814, Gradient norm: 0.62699202
INFO:root:At the start of the epoch: mem (CPU python)=48437.8515625MB; mem (CPU total)=48122.49609375MB
INFO:root:[   25] Training loss: 0.07155868, Validation loss: 0.11908667, Gradient norm: 0.71797238
INFO:root:At the start of the epoch: mem (CPU python)=48514.046875MB; mem (CPU total)=48198.9375MB
INFO:root:[   26] Training loss: 0.06986846, Validation loss: 0.11910278, Gradient norm: 0.74484555
INFO:root:At the start of the epoch: mem (CPU python)=48590.23828125MB; mem (CPU total)=48275.18359375MB
INFO:root:[   27] Training loss: 0.06745031, Validation loss: 0.11267241, Gradient norm: 0.55256704
INFO:root:At the start of the epoch: mem (CPU python)=48666.42578125MB; mem (CPU total)=48351.7109375MB
INFO:root:[   28] Training loss: 0.06690252, Validation loss: 0.11647772, Gradient norm: 0.61618328
INFO:root:At the start of the epoch: mem (CPU python)=48742.6171875MB; mem (CPU total)=48427.9296875MB
INFO:root:[   29] Training loss: 0.06527137, Validation loss: 0.11105968, Gradient norm: 0.56965972
INFO:root:At the start of the epoch: mem (CPU python)=48818.8046875MB; mem (CPU total)=48504.44921875MB
INFO:root:[   30] Training loss: 0.06444206, Validation loss: 0.11623754, Gradient norm: 0.58967799
INFO:root:At the start of the epoch: mem (CPU python)=48895.0MB; mem (CPU total)=48580.9296875MB
INFO:root:[   31] Training loss: 0.06368461, Validation loss: 0.10849793, Gradient norm: 0.51020504
INFO:root:At the start of the epoch: mem (CPU python)=48971.19140625MB; mem (CPU total)=48657.484375MB
INFO:root:[   32] Training loss: 0.06360754, Validation loss: 0.11356038, Gradient norm: 0.67059912
INFO:root:At the start of the epoch: mem (CPU python)=49047.37890625MB; mem (CPU total)=48733.74609375MB
INFO:root:[   33] Training loss: 0.06260027, Validation loss: 0.11608252, Gradient norm: 0.58449661
INFO:root:At the start of the epoch: mem (CPU python)=49123.57421875MB; mem (CPU total)=48810.2265625MB
INFO:root:[   34] Training loss: 0.06167431, Validation loss: 0.10901226, Gradient norm: 0.58575834
INFO:root:At the start of the epoch: mem (CPU python)=49199.76171875MB; mem (CPU total)=48886.30859375MB
INFO:root:[   35] Training loss: 0.05933879, Validation loss: 0.10766995, Gradient norm: 0.48863249
INFO:root:At the start of the epoch: mem (CPU python)=49275.953125MB; mem (CPU total)=48962.09765625MB
INFO:root:[   36] Training loss: 0.05985058, Validation loss: 0.10782358, Gradient norm: 0.53658961
INFO:root:At the start of the epoch: mem (CPU python)=49352.1484375MB; mem (CPU total)=49038.6015625MB
INFO:root:[   37] Training loss: 0.06100907, Validation loss: 0.11020112, Gradient norm: 0.66865319
INFO:root:At the start of the epoch: mem (CPU python)=49428.33203125MB; mem (CPU total)=49114.8671875MB
INFO:root:[   38] Training loss: 0.05785754, Validation loss: 0.11461310, Gradient norm: 0.47794863
INFO:root:At the start of the epoch: mem (CPU python)=49504.52734375MB; mem (CPU total)=49191.62890625MB
INFO:root:[   39] Training loss: 0.05732915, Validation loss: 0.10687055, Gradient norm: 0.51071769
INFO:root:At the start of the epoch: mem (CPU python)=49580.71484375MB; mem (CPU total)=49267.87109375MB
INFO:root:[   40] Training loss: 0.05893587, Validation loss: 0.10741776, Gradient norm: 0.66379875
INFO:root:At the start of the epoch: mem (CPU python)=49656.90625MB; mem (CPU total)=49344.203125MB
INFO:root:[   41] Training loss: 0.05778608, Validation loss: 0.10684379, Gradient norm: 0.62244340
INFO:root:At the start of the epoch: mem (CPU python)=49733.1015625MB; mem (CPU total)=49421.24609375MB
INFO:root:[   42] Training loss: 0.05646293, Validation loss: 0.10616623, Gradient norm: 0.61086349
INFO:root:At the start of the epoch: mem (CPU python)=49809.29296875MB; mem (CPU total)=49497.54296875MB
INFO:root:[   43] Training loss: 0.05787243, Validation loss: 0.10844347, Gradient norm: 0.70646678
INFO:root:At the start of the epoch: mem (CPU python)=49885.484375MB; mem (CPU total)=49573.58203125MB
INFO:root:[   44] Training loss: 0.05670594, Validation loss: 0.10647503, Gradient norm: 0.64562727
INFO:root:At the start of the epoch: mem (CPU python)=49961.671875MB; mem (CPU total)=49650.12109375MB
INFO:root:[   45] Training loss: 0.05370728, Validation loss: 0.10409961, Gradient norm: 0.48187199
INFO:root:At the start of the epoch: mem (CPU python)=50037.8671875MB; mem (CPU total)=49726.08984375MB
INFO:root:[   46] Training loss: 0.05332301, Validation loss: 0.10861780, Gradient norm: 0.45824407
INFO:root:At the start of the epoch: mem (CPU python)=50114.0546875MB; mem (CPU total)=49802.0078125MB
INFO:root:[   47] Training loss: 0.05379989, Validation loss: 0.11009375, Gradient norm: 0.52959816
INFO:root:At the start of the epoch: mem (CPU python)=50190.25MB; mem (CPU total)=49878.578125MB
INFO:root:[   48] Training loss: 0.05371373, Validation loss: 0.10544092, Gradient norm: 0.56250551
INFO:root:At the start of the epoch: mem (CPU python)=50266.4453125MB; mem (CPU total)=49955.5MB
INFO:root:[   49] Training loss: 0.05425336, Validation loss: 0.10160075, Gradient norm: 0.71750066
INFO:root:At the start of the epoch: mem (CPU python)=50342.6328125MB; mem (CPU total)=50031.4453125MB
INFO:root:[   50] Training loss: 0.05183126, Validation loss: 0.10997411, Gradient norm: 0.51053703
INFO:root:At the start of the epoch: mem (CPU python)=50418.82421875MB; mem (CPU total)=50107.76171875MB
INFO:root:[   51] Training loss: 0.05098029, Validation loss: 0.11821255, Gradient norm: 0.45482484
INFO:root:At the start of the epoch: mem (CPU python)=50495.01171875MB; mem (CPU total)=50184.07421875MB
INFO:root:[   52] Training loss: 0.05331679, Validation loss: 0.10233991, Gradient norm: 0.63649508
INFO:root:At the start of the epoch: mem (CPU python)=50571.20703125MB; mem (CPU total)=50259.94921875MB
INFO:root:[   53] Training loss: 0.05002001, Validation loss: 0.10158884, Gradient norm: 0.46562539
INFO:root:At the start of the epoch: mem (CPU python)=50647.40234375MB; mem (CPU total)=50336.29296875MB
INFO:root:[   54] Training loss: 0.04954793, Validation loss: 0.10904096, Gradient norm: 0.47631379
INFO:root:At the start of the epoch: mem (CPU python)=50723.58984375MB; mem (CPU total)=50412.10546875MB
INFO:root:[   55] Training loss: 0.05078938, Validation loss: 0.10217158, Gradient norm: 0.55124455
INFO:root:At the start of the epoch: mem (CPU python)=50799.78125MB; mem (CPU total)=50488.640625MB
INFO:root:[   56] Training loss: 0.05028326, Validation loss: 0.10096734, Gradient norm: 0.52112923
INFO:root:At the start of the epoch: mem (CPU python)=50875.96875MB; mem (CPU total)=50565.5546875MB
INFO:root:[   57] Training loss: 0.05037241, Validation loss: 0.10438242, Gradient norm: 0.62652820
INFO:root:At the start of the epoch: mem (CPU python)=50952.16015625MB; mem (CPU total)=50641.47265625MB
INFO:root:[   58] Training loss: 0.05157137, Validation loss: 0.10440852, Gradient norm: 0.66792899
INFO:root:At the start of the epoch: mem (CPU python)=51028.3515625MB; mem (CPU total)=50718.015625MB
INFO:root:[   59] Training loss: 0.04916662, Validation loss: 0.11449675, Gradient norm: 0.52697971
INFO:root:At the start of the epoch: mem (CPU python)=51104.54296875MB; mem (CPU total)=50793.44140625MB
INFO:root:[   60] Training loss: 0.05032041, Validation loss: 0.11087520, Gradient norm: 0.62339821
INFO:root:At the start of the epoch: mem (CPU python)=51180.73046875MB; mem (CPU total)=50869.75MB
INFO:root:[   61] Training loss: 0.04944444, Validation loss: 0.10542901, Gradient norm: 0.60656543
INFO:root:At the start of the epoch: mem (CPU python)=51256.92578125MB; mem (CPU total)=50946.546875MB
INFO:root:[   62] Training loss: 0.05003397, Validation loss: 0.10498795, Gradient norm: 0.63797872
INFO:root:At the start of the epoch: mem (CPU python)=51333.1171875MB; mem (CPU total)=51022.57421875MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   63] Training loss: 0.04848817, Validation loss: 0.10363020, Gradient norm: 0.51888047
INFO:root:At the start of the epoch: mem (CPU python)=51409.3046875MB; mem (CPU total)=51098.83984375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   64] Training loss: 0.04457804, Validation loss: 0.09944083, Gradient norm: 0.40358598
INFO:root:At the start of the epoch: mem (CPU python)=51485.49609375MB; mem (CPU total)=51175.13671875MB
INFO:root:[   65] Training loss: 0.04250072, Validation loss: 0.10388358, Gradient norm: 0.29511104
INFO:root:At the start of the epoch: mem (CPU python)=51561.6875MB; mem (CPU total)=51251.453125MB
INFO:root:[   66] Training loss: 0.04265121, Validation loss: 0.10117345, Gradient norm: 0.34818776
INFO:root:At the start of the epoch: mem (CPU python)=51637.875MB; mem (CPU total)=51327.94921875MB
INFO:root:[   67] Training loss: 0.04208679, Validation loss: 0.10365345, Gradient norm: 0.31193513
INFO:root:At the start of the epoch: mem (CPU python)=51714.06640625MB; mem (CPU total)=51404.4453125MB
INFO:root:[   68] Training loss: 0.04236432, Validation loss: 0.10117893, Gradient norm: 0.41570001
INFO:root:At the start of the epoch: mem (CPU python)=51790.25390625MB; mem (CPU total)=51480.4609375MB
INFO:root:[   69] Training loss: 0.04158361, Validation loss: 0.10550091, Gradient norm: 0.36672166
INFO:root:At the start of the epoch: mem (CPU python)=51866.44921875MB; mem (CPU total)=51556.7578125MB
INFO:root:[   70] Training loss: 0.04131297, Validation loss: 0.10282270, Gradient norm: 0.31162378
INFO:root:At the start of the epoch: mem (CPU python)=51942.640625MB; mem (CPU total)=51633.04296875MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   71] Training loss: 0.04173572, Validation loss: 0.10597852, Gradient norm: 0.35829472
INFO:root:At the start of the epoch: mem (CPU python)=52018.828125MB; mem (CPU total)=51709.7890625MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[   72] Training loss: 0.04119999, Validation loss: 0.10150433, Gradient norm: 0.33611528
INFO:root:At the start of the epoch: mem (CPU python)=52095.01953125MB; mem (CPU total)=51786.578125MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[   73] Training loss: 0.04013914, Validation loss: 0.10206982, Gradient norm: 0.25839171
INFO:root:At the start of the epoch: mem (CPU python)=52171.20703125MB; mem (CPU total)=51862.6484375MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:EP 73: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=52247.28515625MB; mem (CPU total)=51938.94921875MB
INFO:root:Training the model took 6398.866s.
INFO:root:Emptying the cuda cache took 0.027s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09651
INFO:root:EnergyScoreTrain: 0.05014
INFO:root:CRPSTrain: 0.04082
INFO:root:Gaussian NLLTrain: 1.86166
INFO:root:CoverageTrain: 0.70717
INFO:root:IntervalWidthTrain: 0.24817
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.13658
INFO:root:EnergyScoreValidation: 0.07896
INFO:root:CRPSValidation: 0.06367
INFO:root:Gaussian NLLValidation: 5.03792
INFO:root:CoverageValidation: 0.59245
INFO:root:IntervalWidthValidation: 0.23916
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.13466
INFO:root:EnergyScoreTest: 0.07593
INFO:root:CRPSTest: 0.06102
INFO:root:Gaussian NLLTest: 5.5197
INFO:root:CoverageTest: 0.61535
INFO:root:IntervalWidthTest: 0.24945
INFO:root:After validation: mem (CPU python)=52393.87890625MB; mem (CPU total)=52086.4375MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=52393.87890625MB; mem (CPU total)=52086.40625MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 299892736
INFO:root:After setting up the model: mem (CPU python)=52395.20703125MB; mem (CPU total)=52087.8828125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=52395.20703125MB; mem (CPU total)=52087.8671875MB
INFO:root:[    1] Training loss: 0.37876049, Validation loss: 0.21055983, Gradient norm: 0.94363151
INFO:root:At the start of the epoch: mem (CPU python)=52471.48828125MB; mem (CPU total)=52164.23046875MB
INFO:root:[    2] Training loss: 0.16600049, Validation loss: 0.16448385, Gradient norm: 1.13289759
INFO:root:At the start of the epoch: mem (CPU python)=52547.6796875MB; mem (CPU total)=52240.9375MB
INFO:root:[    3] Training loss: 0.13788244, Validation loss: 0.13940033, Gradient norm: 1.13459884
INFO:root:At the start of the epoch: mem (CPU python)=52623.8671875MB; mem (CPU total)=52316.66796875MB
INFO:root:[    4] Training loss: 0.12292014, Validation loss: 0.13452595, Gradient norm: 1.05682887
INFO:root:At the start of the epoch: mem (CPU python)=52700.0546875MB; mem (CPU total)=52392.6796875MB
INFO:root:[    5] Training loss: 0.11136716, Validation loss: 0.12721934, Gradient norm: 0.85176382
INFO:root:At the start of the epoch: mem (CPU python)=52776.25390625MB; mem (CPU total)=52469.22265625MB
INFO:root:[    6] Training loss: 0.10763199, Validation loss: 0.12367196, Gradient norm: 1.04811114
INFO:root:At the start of the epoch: mem (CPU python)=52852.44140625MB; mem (CPU total)=52545.50390625MB
INFO:root:[    7] Training loss: 0.10122282, Validation loss: 0.12399056, Gradient norm: 0.87627866
INFO:root:At the start of the epoch: mem (CPU python)=52928.63671875MB; mem (CPU total)=52621.7734375MB
INFO:root:[    8] Training loss: 0.09674194, Validation loss: 0.13380625, Gradient norm: 0.74394648
INFO:root:At the start of the epoch: mem (CPU python)=53004.828125MB; mem (CPU total)=52697.828125MB
INFO:root:[    9] Training loss: 0.09369177, Validation loss: 0.11243780, Gradient norm: 0.72959539
INFO:root:At the start of the epoch: mem (CPU python)=53081.015625MB; mem (CPU total)=52773.8515625MB
INFO:root:[   10] Training loss: 0.09268602, Validation loss: 0.10954689, Gradient norm: 0.85220463
INFO:root:At the start of the epoch: mem (CPU python)=53157.2109375MB; mem (CPU total)=52849.90234375MB
INFO:root:[   11] Training loss: 0.08698695, Validation loss: 0.10750162, Gradient norm: 0.68410460
INFO:root:At the start of the epoch: mem (CPU python)=53233.3984375MB; mem (CPU total)=52926.484375MB
INFO:root:[   12] Training loss: 0.08740233, Validation loss: 0.11505792, Gradient norm: 0.83727067
INFO:root:At the start of the epoch: mem (CPU python)=53309.58984375MB; mem (CPU total)=53002.7421875MB
INFO:root:[   13] Training loss: 0.08536878, Validation loss: 0.10699540, Gradient norm: 0.82751052
INFO:root:At the start of the epoch: mem (CPU python)=53385.78125MB; mem (CPU total)=53078.8671875MB
INFO:root:[   14] Training loss: 0.08299637, Validation loss: 0.10096306, Gradient norm: 0.69457460
INFO:root:At the start of the epoch: mem (CPU python)=53461.97265625MB; mem (CPU total)=53155.16015625MB
INFO:root:[   15] Training loss: 0.08014730, Validation loss: 0.10708886, Gradient norm: 0.64218225
INFO:root:At the start of the epoch: mem (CPU python)=53538.1640625MB; mem (CPU total)=53231.9609375MB
INFO:root:[   16] Training loss: 0.08030836, Validation loss: 0.10208989, Gradient norm: 0.75421262
INFO:root:At the start of the epoch: mem (CPU python)=53614.35546875MB; mem (CPU total)=53308.2265625MB
INFO:root:[   17] Training loss: 0.07612963, Validation loss: 0.10377159, Gradient norm: 0.61721909
INFO:root:At the start of the epoch: mem (CPU python)=53690.54296875MB; mem (CPU total)=53384.40234375MB
INFO:root:[   18] Training loss: 0.07750496, Validation loss: 0.11358923, Gradient norm: 0.70800304
INFO:root:At the start of the epoch: mem (CPU python)=53766.734375MB; mem (CPU total)=53460.67578125MB
INFO:root:[   19] Training loss: 0.07739879, Validation loss: 0.11622388, Gradient norm: 0.85167288
INFO:root:At the start of the epoch: mem (CPU python)=53842.921875MB; mem (CPU total)=53536.97265625MB
INFO:root:[   20] Training loss: 0.07728498, Validation loss: 0.10198684, Gradient norm: 0.79709960
INFO:root:At the start of the epoch: mem (CPU python)=53919.1171875MB; mem (CPU total)=53613.21875MB
INFO:root:[   21] Training loss: 0.07569912, Validation loss: 0.10118122, Gradient norm: 0.80248058
INFO:root:At the start of the epoch: mem (CPU python)=53995.3046875MB; mem (CPU total)=53689.72265625MB
INFO:root:[   22] Training loss: 0.07456474, Validation loss: 0.10277998, Gradient norm: 0.88458943
INFO:root:At the start of the epoch: mem (CPU python)=54071.49609375MB; mem (CPU total)=53766.01171875MB
INFO:root:[   23] Training loss: 0.06924724, Validation loss: 0.09972313, Gradient norm: 0.54699684
INFO:root:At the start of the epoch: mem (CPU python)=54147.6875MB; mem (CPU total)=53842.33203125MB
INFO:root:[   24] Training loss: 0.07240660, Validation loss: 0.10143548, Gradient norm: 0.80411646
INFO:root:At the start of the epoch: mem (CPU python)=54223.875MB; mem (CPU total)=53918.3515625MB
INFO:root:[   25] Training loss: 0.06982873, Validation loss: 0.10383629, Gradient norm: 0.64973135
INFO:root:At the start of the epoch: mem (CPU python)=54300.0703125MB; mem (CPU total)=53994.82421875MB
INFO:root:[   26] Training loss: 0.06976289, Validation loss: 0.09633496, Gradient norm: 0.81169915
INFO:root:At the start of the epoch: mem (CPU python)=54376.2578125MB; mem (CPU total)=54071.3203125MB
INFO:root:[   27] Training loss: 0.06650759, Validation loss: 0.09961893, Gradient norm: 0.59448681
INFO:root:At the start of the epoch: mem (CPU python)=54452.44921875MB; mem (CPU total)=54147.58984375MB
INFO:root:[   28] Training loss: 0.06765072, Validation loss: 0.09587139, Gradient norm: 0.66610696
INFO:root:At the start of the epoch: mem (CPU python)=54528.640625MB; mem (CPU total)=54224.22265625MB
INFO:root:[   29] Training loss: 0.06632081, Validation loss: 0.09879845, Gradient norm: 0.71154446
INFO:root:At the start of the epoch: mem (CPU python)=54604.83203125MB; mem (CPU total)=54300.1953125MB
INFO:root:[   30] Training loss: 0.06344486, Validation loss: 0.09577141, Gradient norm: 0.53648965
INFO:root:At the start of the epoch: mem (CPU python)=54681.0234375MB; mem (CPU total)=54376.80078125MB
INFO:root:[   31] Training loss: 0.06333206, Validation loss: 0.09424380, Gradient norm: 0.63025628
INFO:root:At the start of the epoch: mem (CPU python)=54757.2109375MB; mem (CPU total)=54452.89453125MB
INFO:root:[   32] Training loss: 0.06369746, Validation loss: 0.10081766, Gradient norm: 0.63707455
INFO:root:At the start of the epoch: mem (CPU python)=54833.40625MB; mem (CPU total)=54529.40625MB
INFO:root:[   33] Training loss: 0.06100229, Validation loss: 0.09751998, Gradient norm: 0.55565965
INFO:root:At the start of the epoch: mem (CPU python)=54909.59765625MB; mem (CPU total)=54605.6328125MB
INFO:root:[   34] Training loss: 0.06172638, Validation loss: 0.09552354, Gradient norm: 0.64286570
INFO:root:At the start of the epoch: mem (CPU python)=54985.78515625MB; mem (CPU total)=54682.12890625MB
INFO:root:[   35] Training loss: 0.06219297, Validation loss: 0.09945475, Gradient norm: 0.69602587
INFO:root:At the start of the epoch: mem (CPU python)=55061.9765625MB; mem (CPU total)=54758.39453125MB
INFO:root:[   36] Training loss: 0.06048836, Validation loss: 0.09564642, Gradient norm: 0.64885636
INFO:root:At the start of the epoch: mem (CPU python)=55138.1640625MB; mem (CPU total)=54834.40625MB
INFO:root:[   37] Training loss: 0.05789604, Validation loss: 0.09414116, Gradient norm: 0.49268727
INFO:root:At the start of the epoch: mem (CPU python)=55214.359375MB; mem (CPU total)=54911.21484375MB
INFO:root:[   38] Training loss: 0.05864960, Validation loss: 0.10100496, Gradient norm: 0.59593294
INFO:root:At the start of the epoch: mem (CPU python)=55290.546875MB; mem (CPU total)=54986.96875MB
INFO:root:[   39] Training loss: 0.05889378, Validation loss: 0.09269185, Gradient norm: 0.66868431
INFO:root:At the start of the epoch: mem (CPU python)=55366.73828125MB; mem (CPU total)=55063.68359375MB
INFO:root:[   40] Training loss: 0.05877138, Validation loss: 0.09478971, Gradient norm: 0.66466370
INFO:root:At the start of the epoch: mem (CPU python)=55442.93359375MB; mem (CPU total)=55139.953125MB
INFO:root:[   41] Training loss: 0.05698550, Validation loss: 0.09715121, Gradient norm: 0.57501667
INFO:root:At the start of the epoch: mem (CPU python)=55519.12109375MB; mem (CPU total)=55216.46484375MB
INFO:root:[   42] Training loss: 0.05726418, Validation loss: 0.10138793, Gradient norm: 0.67998253
INFO:root:At the start of the epoch: mem (CPU python)=55595.3125MB; mem (CPU total)=55292.1328125MB
INFO:root:[   43] Training loss: 0.05879049, Validation loss: 0.09692850, Gradient norm: 0.78214500
INFO:root:At the start of the epoch: mem (CPU python)=55671.5MB; mem (CPU total)=55368.58984375MB
INFO:root:[   44] Training loss: 0.05552977, Validation loss: 0.09374364, Gradient norm: 0.55400652
INFO:root:At the start of the epoch: mem (CPU python)=55747.6953125MB; mem (CPU total)=55444.38671875MB
INFO:root:[   45] Training loss: 0.05390303, Validation loss: 0.09251459, Gradient norm: 0.46151723
INFO:root:At the start of the epoch: mem (CPU python)=55823.88671875MB; mem (CPU total)=55520.6953125MB
INFO:root:[   46] Training loss: 0.05414562, Validation loss: 0.09817893, Gradient norm: 0.55936118
INFO:root:At the start of the epoch: mem (CPU python)=55900.07421875MB; mem (CPU total)=55596.93359375MB
INFO:root:[   47] Training loss: 0.05428597, Validation loss: 0.09268503, Gradient norm: 0.63049304
INFO:root:At the start of the epoch: mem (CPU python)=55976.265625MB; mem (CPU total)=55673.33984375MB
INFO:root:[   48] Training loss: 0.05380919, Validation loss: 0.09843731, Gradient norm: 0.56129348
INFO:root:At the start of the epoch: mem (CPU python)=56052.453125MB; mem (CPU total)=55750.30859375MB
INFO:root:[   49] Training loss: 0.05430947, Validation loss: 0.09467515, Gradient norm: 0.67422207
INFO:root:At the start of the epoch: mem (CPU python)=56128.64453125MB; mem (CPU total)=55826.58203125MB
INFO:root:[   50] Training loss: 0.05446323, Validation loss: 0.09333958, Gradient norm: 0.69613544
INFO:root:At the start of the epoch: mem (CPU python)=56204.83984375MB; mem (CPU total)=55902.89453125MB
INFO:root:[   51] Training loss: 0.05345973, Validation loss: 0.09210448, Gradient norm: 0.59170825
INFO:root:At the start of the epoch: mem (CPU python)=56281.02734375MB; mem (CPU total)=55979.24609375MB
INFO:root:[   52] Training loss: 0.05176155, Validation loss: 0.09537187, Gradient norm: 0.54971140
INFO:root:At the start of the epoch: mem (CPU python)=56357.21875MB; mem (CPU total)=56055.5859375MB
INFO:root:[   53] Training loss: 0.05041418, Validation loss: 0.09334745, Gradient norm: 0.47803393
INFO:root:At the start of the epoch: mem (CPU python)=56433.41015625MB; mem (CPU total)=56132.11328125MB
INFO:root:[   54] Training loss: 0.04980708, Validation loss: 0.09563580, Gradient norm: 0.48237042
INFO:root:At the start of the epoch: mem (CPU python)=56509.60546875MB; mem (CPU total)=56208.5859375MB
INFO:root:[   55] Training loss: 0.05159689, Validation loss: 0.09048757, Gradient norm: 0.62839403
INFO:root:At the start of the epoch: mem (CPU python)=56585.79296875MB; mem (CPU total)=56284.671875MB
INFO:root:[   56] Training loss: 0.05150794, Validation loss: 0.09087734, Gradient norm: 0.68214360
INFO:root:At the start of the epoch: mem (CPU python)=56661.984375MB; mem (CPU total)=56360.703125MB
INFO:root:[   57] Training loss: 0.05136893, Validation loss: 0.09385844, Gradient norm: 0.59069516
INFO:root:At the start of the epoch: mem (CPU python)=56738.171875MB; mem (CPU total)=56437.2265625MB
INFO:root:[   58] Training loss: 0.04970631, Validation loss: 0.09315911, Gradient norm: 0.54285222
INFO:root:At the start of the epoch: mem (CPU python)=56814.3671875MB; mem (CPU total)=56513.21484375MB
INFO:root:[   59] Training loss: 0.04938403, Validation loss: 0.09264817, Gradient norm: 0.52609294
INFO:root:At the start of the epoch: mem (CPU python)=56890.55859375MB; mem (CPU total)=56589.49609375MB
INFO:root:[   60] Training loss: 0.04947220, Validation loss: 0.09309925, Gradient norm: 0.53882918
INFO:root:At the start of the epoch: mem (CPU python)=56966.74609375MB; mem (CPU total)=56666.2578125MB
INFO:root:[   61] Training loss: 0.05012630, Validation loss: 0.09652863, Gradient norm: 0.63208446
INFO:root:At the start of the epoch: mem (CPU python)=57042.9453125MB; mem (CPU total)=56742.2890625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[   62] Training loss: 0.04910087, Validation loss: 0.09562290, Gradient norm: 0.58263137
INFO:root:At the start of the epoch: mem (CPU python)=57119.13671875MB; mem (CPU total)=56819.0859375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[   63] Training loss: 0.04542463, Validation loss: 0.09181913, Gradient norm: 0.44282234
INFO:root:At the start of the epoch: mem (CPU python)=57195.32421875MB; mem (CPU total)=56895.1328125MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[   64] Training loss: 0.04316877, Validation loss: 0.09378747, Gradient norm: 0.31404065
INFO:root:At the start of the epoch: mem (CPU python)=57271.515625MB; mem (CPU total)=56971.421875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:EP 64: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=57347.66796875MB; mem (CPU total)=57047.7109375MB
INFO:root:Training the model took 5986.842s.
INFO:root:Emptying the cuda cache took 0.025s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09907
INFO:root:EnergyScoreTrain: 0.05095
INFO:root:CRPSTrain: 0.0415
INFO:root:Gaussian NLLTrain: 2.07809
INFO:root:CoverageTrain: 0.70289
INFO:root:IntervalWidthTrain: 0.25546
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.13099
INFO:root:EnergyScoreValidation: 0.07525
INFO:root:CRPSValidation: 0.06071
INFO:root:Gaussian NLLValidation: 4.85912
INFO:root:CoverageValidation: 0.60583
INFO:root:IntervalWidthValidation: 0.23751
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.12739
INFO:root:EnergyScoreTest: 0.0729
INFO:root:CRPSTest: 0.05884
INFO:root:Gaussian NLLTest: 8.81087
INFO:root:CoverageTest: 0.62248
INFO:root:IntervalWidthTest: 0.23926
INFO:root:After validation: mem (CPU python)=57494.1875MB; mem (CPU total)=57193.96875MB
