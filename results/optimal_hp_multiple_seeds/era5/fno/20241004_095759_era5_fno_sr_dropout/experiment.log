INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=576.57421875MB; mem (CPU total)=1153.00390625MB
INFO:root:############### Starting experiment with config file era5/fno_sr_dropout.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'era5', 'max_training_set_size': 20000, 'init_steps': 10, 'pred_horizon': 10}
INFO:root:After loading the datasets: mem (CPU python)=5495.5MB; mem (CPU total)=1190.09765625MB
INFO:root:###1 out of 1 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=5495.5MB; mem (CPU total)=1189.28515625MB
INFO:root:NumberParameters: 2695717
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=5495.5MB; mem (CPU total)=2564.0234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=2572.08984375MB
INFO:root:[    1] Training loss: 0.02158637, Validation loss: 0.02025001, Gradient norm: 0.14862045
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=3804.08203125MB
INFO:root:[    2] Training loss: 0.01841335, Validation loss: 0.01834569, Gradient norm: 0.11828419
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=3909.265625MB
INFO:root:[    3] Training loss: 0.01765014, Validation loss: 0.01758621, Gradient norm: 0.10660880
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=3969.54296875MB
INFO:root:[    4] Training loss: 0.01712916, Validation loss: 0.01701187, Gradient norm: 0.10001629
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4032.44140625MB
INFO:root:[    5] Training loss: 0.01663329, Validation loss: 0.01668135, Gradient norm: 0.09615910
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4090.703125MB
INFO:root:[    6] Training loss: 0.01628855, Validation loss: 0.01624746, Gradient norm: 0.09322829
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4153.28125MB
INFO:root:[    7] Training loss: 0.01588972, Validation loss: 0.01595890, Gradient norm: 0.09414244
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4213.609375MB
INFO:root:[    8] Training loss: 0.01546941, Validation loss: 0.01536751, Gradient norm: 0.09007092
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4278.38671875MB
INFO:root:[    9] Training loss: 0.01509689, Validation loss: 0.01579561, Gradient norm: 0.08865393
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4339.3203125MB
INFO:root:[   10] Training loss: 0.01479964, Validation loss: 0.01501619, Gradient norm: 0.08700625
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4400.32421875MB
INFO:root:[   11] Training loss: 0.01461730, Validation loss: 0.01515652, Gradient norm: 0.08648469
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4462.76171875MB
INFO:root:[   12] Training loss: 0.01441103, Validation loss: 0.01549295, Gradient norm: 0.08768069
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4524.78125MB
INFO:root:[   13] Training loss: 0.01415748, Validation loss: 0.01499059, Gradient norm: 0.08342822
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4584.6953125MB
INFO:root:[   14] Training loss: 0.01400964, Validation loss: 0.01473651, Gradient norm: 0.08405199
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4646.1328125MB
INFO:root:[   15] Training loss: 0.01390941, Validation loss: 0.01438276, Gradient norm: 0.08546987
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4707.90625MB
INFO:root:[   16] Training loss: 0.01371817, Validation loss: 0.01478279, Gradient norm: 0.07973425
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4770.10546875MB
INFO:root:[   17] Training loss: 0.01364212, Validation loss: 0.01416183, Gradient norm: 0.08239787
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4831.34375MB
INFO:root:[   18] Training loss: 0.01357524, Validation loss: 0.01401826, Gradient norm: 0.08544019
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4893.10546875MB
INFO:root:[   19] Training loss: 0.01341687, Validation loss: 0.01431428, Gradient norm: 0.08059009
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=4955.4375MB
INFO:root:[   20] Training loss: 0.01335081, Validation loss: 0.01373543, Gradient norm: 0.07740769
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=5015.68359375MB
INFO:root:[   21] Training loss: 0.01329019, Validation loss: 0.01368458, Gradient norm: 0.08148414
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=5080.21484375MB
INFO:root:[   22] Training loss: 0.01314346, Validation loss: 0.01364280, Gradient norm: 0.07520454
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=5140.73828125MB
INFO:root:[   23] Training loss: 0.01312669, Validation loss: 0.01397163, Gradient norm: 0.07859522
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=5203.41015625MB
INFO:root:[   24] Training loss: 0.01307069, Validation loss: 0.01352205, Gradient norm: 0.07931910
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=5264.234375MB
INFO:root:[   25] Training loss: 0.01300072, Validation loss: 0.01393368, Gradient norm: 0.07726148
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=5326.46484375MB
INFO:root:[   26] Training loss: 0.01298868, Validation loss: 0.01379525, Gradient norm: 0.08094847
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=5390.84765625MB
INFO:root:[   27] Training loss: 0.01286912, Validation loss: 0.01353633, Gradient norm: 0.07509270
INFO:root:At the start of the epoch: mem (CPU python)=5495.5MB; mem (CPU total)=5450.91015625MB
INFO:root:[   28] Training loss: 0.01283264, Validation loss: 0.01377640, Gradient norm: 0.07521767
INFO:root:At the start of the epoch: mem (CPU python)=5536.984375MB; mem (CPU total)=5512.21484375MB
INFO:root:[   29] Training loss: 0.01277819, Validation loss: 0.01333324, Gradient norm: 0.07435449
INFO:root:At the start of the epoch: mem (CPU python)=5598.73828125MB; mem (CPU total)=5573.22265625MB
INFO:root:[   30] Training loss: 0.01270397, Validation loss: 0.01321274, Gradient norm: 0.07073574
INFO:root:At the start of the epoch: mem (CPU python)=5660.40625MB; mem (CPU total)=5635.56640625MB
INFO:root:[   31] Training loss: 0.01273490, Validation loss: 0.01327908, Gradient norm: 0.07843235
INFO:root:At the start of the epoch: mem (CPU python)=5721.98046875MB; mem (CPU total)=5697.7265625MB
INFO:root:[   32] Training loss: 0.01266569, Validation loss: 0.01334775, Gradient norm: 0.07534692
INFO:root:At the start of the epoch: mem (CPU python)=5786.25390625MB; mem (CPU total)=5761.38671875MB
INFO:root:[   33] Training loss: 0.01258259, Validation loss: 0.01360473, Gradient norm: 0.07366263
INFO:root:At the start of the epoch: mem (CPU python)=5842.76953125MB; mem (CPU total)=5821.63671875MB
INFO:root:[   34] Training loss: 0.01256916, Validation loss: 0.01317510, Gradient norm: 0.07215108
INFO:root:At the start of the epoch: mem (CPU python)=5904.54296875MB; mem (CPU total)=5880.13671875MB
INFO:root:[   35] Training loss: 0.01250921, Validation loss: 0.01308897, Gradient norm: 0.07248614
INFO:root:At the start of the epoch: mem (CPU python)=5966.49609375MB; mem (CPU total)=5940.46484375MB
INFO:root:[   36] Training loss: 0.01248863, Validation loss: 0.01347813, Gradient norm: 0.07149557
INFO:root:At the start of the epoch: mem (CPU python)=6028.35546875MB; mem (CPU total)=6004.30859375MB
INFO:root:[   37] Training loss: 0.01247225, Validation loss: 0.01400809, Gradient norm: 0.07555527
INFO:root:At the start of the epoch: mem (CPU python)=6089.99609375MB; mem (CPU total)=6064.6796875MB
INFO:root:[   38] Training loss: 0.01243740, Validation loss: 0.01345008, Gradient norm: 0.07309948
INFO:root:At the start of the epoch: mem (CPU python)=6151.76171875MB; mem (CPU total)=6125.06640625MB
INFO:root:[   39] Training loss: 0.01240336, Validation loss: 0.01357858, Gradient norm: 0.07337339
INFO:root:At the start of the epoch: mem (CPU python)=6213.41015625MB; mem (CPU total)=6186.45703125MB
INFO:root:[   40] Training loss: 0.01235035, Validation loss: 0.01312685, Gradient norm: 0.07001460
INFO:root:At the start of the epoch: mem (CPU python)=6275.3203125MB; mem (CPU total)=6249.37109375MB
INFO:root:[   41] Training loss: 0.01235697, Validation loss: 0.01296492, Gradient norm: 0.07406595
INFO:root:At the start of the epoch: mem (CPU python)=6336.57421875MB; mem (CPU total)=6309.59375MB
INFO:root:[   42] Training loss: 0.01230952, Validation loss: 0.01296333, Gradient norm: 0.07330450
INFO:root:At the start of the epoch: mem (CPU python)=6398.6328125MB; mem (CPU total)=6371.2578125MB
INFO:root:[   43] Training loss: 0.01233332, Validation loss: 0.01292452, Gradient norm: 0.07317587
INFO:root:At the start of the epoch: mem (CPU python)=6460.515625MB; mem (CPU total)=6433.54296875MB
INFO:root:[   44] Training loss: 0.01225762, Validation loss: 0.01303850, Gradient norm: 0.07108695
INFO:root:At the start of the epoch: mem (CPU python)=6523.70703125MB; mem (CPU total)=6495.46484375MB
INFO:root:[   45] Training loss: 0.01227131, Validation loss: 0.01344411, Gradient norm: 0.07420710
INFO:root:At the start of the epoch: mem (CPU python)=6585.49609375MB; mem (CPU total)=6557.40234375MB
INFO:root:[   46] Training loss: 0.01221637, Validation loss: 0.01292339, Gradient norm: 0.07092209
INFO:root:At the start of the epoch: mem (CPU python)=6647.2265625MB; mem (CPU total)=6619.68359375MB
INFO:root:[   47] Training loss: 0.01219563, Validation loss: 0.01281556, Gradient norm: 0.07182146
INFO:root:At the start of the epoch: mem (CPU python)=6708.7578125MB; mem (CPU total)=6680.7109375MB
INFO:root:[   48] Training loss: 0.01220497, Validation loss: 0.01299112, Gradient norm: 0.07570360
INFO:root:At the start of the epoch: mem (CPU python)=6770.4375MB; mem (CPU total)=6743.61328125MB
INFO:root:[   49] Training loss: 0.01218836, Validation loss: 0.01310779, Gradient norm: 0.07322076
INFO:root:At the start of the epoch: mem (CPU python)=6832.16796875MB; mem (CPU total)=6804.7109375MB
INFO:root:[   50] Training loss: 0.01213379, Validation loss: 0.01279313, Gradient norm: 0.07144752
INFO:root:At the start of the epoch: mem (CPU python)=6895.265625MB; mem (CPU total)=6867.33203125MB
INFO:root:[   51] Training loss: 0.01210622, Validation loss: 0.01276983, Gradient norm: 0.07166062
INFO:root:At the start of the epoch: mem (CPU python)=6957.21484375MB; mem (CPU total)=6929.08203125MB
INFO:root:[   52] Training loss: 0.01212032, Validation loss: 0.01278115, Gradient norm: 0.07238615
INFO:root:At the start of the epoch: mem (CPU python)=7019.01171875MB; mem (CPU total)=6992.48046875MB
INFO:root:[   53] Training loss: 0.01212818, Validation loss: 0.01290430, Gradient norm: 0.07178177
INFO:root:At the start of the epoch: mem (CPU python)=7080.7421875MB; mem (CPU total)=7054.328125MB
INFO:root:[   54] Training loss: 0.01209370, Validation loss: 0.01293577, Gradient norm: 0.07536049
INFO:root:At the start of the epoch: mem (CPU python)=7142.54296875MB; mem (CPU total)=7117.015625MB
INFO:root:[   55] Training loss: 0.01203908, Validation loss: 0.01272007, Gradient norm: 0.06795677
INFO:root:At the start of the epoch: mem (CPU python)=7204.109375MB; mem (CPU total)=7178.71484375MB
INFO:root:[   56] Training loss: 0.01200228, Validation loss: 0.01257238, Gradient norm: 0.06862915
INFO:root:At the start of the epoch: mem (CPU python)=7265.96875MB; mem (CPU total)=7240.7109375MB
INFO:root:[   57] Training loss: 0.01204689, Validation loss: 0.01279064, Gradient norm: 0.07179377
INFO:root:At the start of the epoch: mem (CPU python)=7327.31640625MB; mem (CPU total)=7303.171875MB
INFO:root:[   58] Training loss: 0.01197811, Validation loss: 0.01324474, Gradient norm: 0.07057478
INFO:root:At the start of the epoch: mem (CPU python)=7389.28515625MB; mem (CPU total)=7364.7421875MB
INFO:root:[   59] Training loss: 0.01195982, Validation loss: 0.01270125, Gradient norm: 0.06873408
INFO:root:At the start of the epoch: mem (CPU python)=7451.30078125MB; mem (CPU total)=7426.12109375MB
INFO:root:[   60] Training loss: 0.01198579, Validation loss: 0.01308330, Gradient norm: 0.07327185
INFO:root:At the start of the epoch: mem (CPU python)=7512.984375MB; mem (CPU total)=7489.87890625MB
INFO:root:[   61] Training loss: 0.01192789, Validation loss: 0.01268779, Gradient norm: 0.06748093
INFO:root:At the start of the epoch: mem (CPU python)=7574.73828125MB; mem (CPU total)=7552.59765625MB
INFO:root:[   62] Training loss: 0.01193860, Validation loss: 0.01254181, Gradient norm: 0.06933742
INFO:root:At the start of the epoch: mem (CPU python)=7636.6171875MB; mem (CPU total)=7613.703125MB
INFO:root:[   63] Training loss: 0.01191390, Validation loss: 0.01264216, Gradient norm: 0.06898875
INFO:root:At the start of the epoch: mem (CPU python)=7698.28515625MB; mem (CPU total)=7675.9453125MB
INFO:root:[   64] Training loss: 0.01191219, Validation loss: 0.01286158, Gradient norm: 0.06949116
INFO:root:At the start of the epoch: mem (CPU python)=7759.81640625MB; mem (CPU total)=7740.5MB
INFO:root:[   65] Training loss: 0.01192407, Validation loss: 0.01280796, Gradient norm: 0.07169280
INFO:root:At the start of the epoch: mem (CPU python)=7821.60546875MB; mem (CPU total)=7801.578125MB
INFO:root:[   66] Training loss: 0.01190995, Validation loss: 0.01253701, Gradient norm: 0.07110807
INFO:root:At the start of the epoch: mem (CPU python)=7883.28125MB; mem (CPU total)=7862.71875MB
INFO:root:[   67] Training loss: 0.01185559, Validation loss: 0.01271427, Gradient norm: 0.06846043
INFO:root:At the start of the epoch: mem (CPU python)=7945.24609375MB; mem (CPU total)=7924.58203125MB
INFO:root:[   68] Training loss: 0.01186029, Validation loss: 0.01272258, Gradient norm: 0.06974462
INFO:root:At the start of the epoch: mem (CPU python)=8007.02734375MB; mem (CPU total)=7985.90234375MB
INFO:root:[   69] Training loss: 0.01187287, Validation loss: 0.01259420, Gradient norm: 0.07077084
INFO:root:At the start of the epoch: mem (CPU python)=8068.79296875MB; mem (CPU total)=8048.0859375MB
INFO:root:[   70] Training loss: 0.01184832, Validation loss: 0.01260174, Gradient norm: 0.07201348
INFO:root:At the start of the epoch: mem (CPU python)=8130.65625MB; mem (CPU total)=8109.87109375MB
INFO:root:[   71] Training loss: 0.01178324, Validation loss: 0.01330886, Gradient norm: 0.06719382
INFO:root:At the start of the epoch: mem (CPU python)=8192.19140625MB; mem (CPU total)=8173.35546875MB
INFO:root:[   72] Training loss: 0.01179270, Validation loss: 0.01249633, Gradient norm: 0.06865257
INFO:root:At the start of the epoch: mem (CPU python)=8253.77734375MB; mem (CPU total)=8232.69921875MB
INFO:root:[   73] Training loss: 0.01180931, Validation loss: 0.01246687, Gradient norm: 0.07029557
INFO:root:At the start of the epoch: mem (CPU python)=8315.60546875MB; mem (CPU total)=8294.1328125MB
INFO:root:[   74] Training loss: 0.01182521, Validation loss: 0.01234758, Gradient norm: 0.07338040
INFO:root:At the start of the epoch: mem (CPU python)=8377.36328125MB; mem (CPU total)=8356.00390625MB
INFO:root:[   75] Training loss: 0.01175741, Validation loss: 0.01263156, Gradient norm: 0.06705990
INFO:root:At the start of the epoch: mem (CPU python)=8440.53125MB; mem (CPU total)=8420.71484375MB
INFO:root:[   76] Training loss: 0.01177764, Validation loss: 0.01263372, Gradient norm: 0.06756702
INFO:root:At the start of the epoch: mem (CPU python)=8502.5078125MB; mem (CPU total)=8481.37890625MB
INFO:root:[   77] Training loss: 0.01177209, Validation loss: 0.01268882, Gradient norm: 0.07164940
INFO:root:At the start of the epoch: mem (CPU python)=8564.171875MB; mem (CPU total)=8543.88671875MB
INFO:root:[   78] Training loss: 0.01176921, Validation loss: 0.01247701, Gradient norm: 0.06977885
INFO:root:At the start of the epoch: mem (CPU python)=8625.99609375MB; mem (CPU total)=8604.58203125MB
INFO:root:[   79] Training loss: 0.01171404, Validation loss: 0.01249228, Gradient norm: 0.06768616
INFO:root:At the start of the epoch: mem (CPU python)=8687.5625MB; mem (CPU total)=8666.38671875MB
INFO:root:[   80] Training loss: 0.01171889, Validation loss: 0.01240724, Gradient norm: 0.06833032
INFO:root:At the start of the epoch: mem (CPU python)=8748.9453125MB; mem (CPU total)=8728.81640625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   81] Training loss: 0.01168320, Validation loss: 0.01234227, Gradient norm: 0.06833909
INFO:root:At the start of the epoch: mem (CPU python)=8811.03125MB; mem (CPU total)=8790.7734375MB
INFO:root:[   82] Training loss: 0.01124073, Validation loss: 0.01200438, Gradient norm: 0.05103059
INFO:root:At the start of the epoch: mem (CPU python)=8873.09375MB; mem (CPU total)=8852.1953125MB
INFO:root:[   83] Training loss: 0.01116437, Validation loss: 0.01199199, Gradient norm: 0.05145021
INFO:root:At the start of the epoch: mem (CPU python)=8934.5859375MB; mem (CPU total)=8913.6328125MB
INFO:root:[   84] Training loss: 0.01114403, Validation loss: 0.01206829, Gradient norm: 0.05333779
INFO:root:At the start of the epoch: mem (CPU python)=8996.453125MB; mem (CPU total)=8976.0MB
INFO:root:[   85] Training loss: 0.01110331, Validation loss: 0.01199902, Gradient norm: 0.05073428
INFO:root:At the start of the epoch: mem (CPU python)=9058.24609375MB; mem (CPU total)=9038.95703125MB
INFO:root:[   86] Training loss: 0.01109534, Validation loss: 0.01208770, Gradient norm: 0.05298841
INFO:root:At the start of the epoch: mem (CPU python)=9119.98046875MB; mem (CPU total)=9101.171875MB
INFO:root:[   87] Training loss: 0.01108558, Validation loss: 0.01201203, Gradient norm: 0.05314955
INFO:root:At the start of the epoch: mem (CPU python)=9181.71484375MB; mem (CPU total)=9163.3359375MB
INFO:root:[   88] Training loss: 0.01106920, Validation loss: 0.01187251, Gradient norm: 0.05200241
INFO:root:At the start of the epoch: mem (CPU python)=9243.13671875MB; mem (CPU total)=9224.03125MB
INFO:root:[   89] Training loss: 0.01105243, Validation loss: 0.01189303, Gradient norm: 0.05217962
INFO:root:At the start of the epoch: mem (CPU python)=9304.89453125MB; mem (CPU total)=9286.10546875MB
INFO:root:[   90] Training loss: 0.01106068, Validation loss: 0.01194542, Gradient norm: 0.05484028
INFO:root:At the start of the epoch: mem (CPU python)=9366.98046875MB; mem (CPU total)=9348.0703125MB
INFO:root:[   91] Training loss: 0.01103071, Validation loss: 0.01213989, Gradient norm: 0.05332033
INFO:root:At the start of the epoch: mem (CPU python)=9428.5078125MB; mem (CPU total)=9409.734375MB
INFO:root:[   92] Training loss: 0.01104011, Validation loss: 0.01178127, Gradient norm: 0.05350200
INFO:root:At the start of the epoch: mem (CPU python)=9490.50390625MB; mem (CPU total)=9470.31640625MB
INFO:root:[   93] Training loss: 0.01103270, Validation loss: 0.01184488, Gradient norm: 0.05503605
INFO:root:At the start of the epoch: mem (CPU python)=9552.30078125MB; mem (CPU total)=9532.80078125MB
INFO:root:[   94] Training loss: 0.01102912, Validation loss: 0.01185381, Gradient norm: 0.05425575
INFO:root:At the start of the epoch: mem (CPU python)=9613.9375MB; mem (CPU total)=9593.74609375MB
INFO:root:[   95] Training loss: 0.01097812, Validation loss: 0.01177034, Gradient norm: 0.04903564
INFO:root:At the start of the epoch: mem (CPU python)=9675.77734375MB; mem (CPU total)=9655.65234375MB
INFO:root:[   96] Training loss: 0.01099771, Validation loss: 0.01184337, Gradient norm: 0.05281204
INFO:root:At the start of the epoch: mem (CPU python)=9737.2578125MB; mem (CPU total)=9719.16796875MB
INFO:root:[   97] Training loss: 0.01100223, Validation loss: 0.01183480, Gradient norm: 0.05384050
INFO:root:At the start of the epoch: mem (CPU python)=9798.80078125MB; mem (CPU total)=9779.36328125MB
INFO:root:[   98] Training loss: 0.01098821, Validation loss: 0.01187998, Gradient norm: 0.05252133
INFO:root:At the start of the epoch: mem (CPU python)=9860.83203125MB; mem (CPU total)=9840.10546875MB
INFO:root:[   99] Training loss: 0.01098143, Validation loss: 0.01174327, Gradient norm: 0.05414563
INFO:root:At the start of the epoch: mem (CPU python)=9922.64453125MB; mem (CPU total)=9902.55078125MB
INFO:root:[  100] Training loss: 0.01098264, Validation loss: 0.01170487, Gradient norm: 0.05467009
INFO:root:At the start of the epoch: mem (CPU python)=9984.48046875MB; mem (CPU total)=9963.4453125MB
INFO:root:[  101] Training loss: 0.01097333, Validation loss: 0.01196922, Gradient norm: 0.05526917
INFO:root:At the start of the epoch: mem (CPU python)=10046.23046875MB; mem (CPU total)=10027.11328125MB
INFO:root:[  102] Training loss: 0.01096135, Validation loss: 0.01174377, Gradient norm: 0.05319119
INFO:root:At the start of the epoch: mem (CPU python)=10107.984375MB; mem (CPU total)=10089.8125MB
INFO:root:[  103] Training loss: 0.01093060, Validation loss: 0.01191129, Gradient norm: 0.04966229
INFO:root:At the start of the epoch: mem (CPU python)=10169.671875MB; mem (CPU total)=10152.19140625MB
INFO:root:[  104] Training loss: 0.01094686, Validation loss: 0.01179556, Gradient norm: 0.05220971
INFO:root:At the start of the epoch: mem (CPU python)=10231.20703125MB; mem (CPU total)=10214.33984375MB
INFO:root:[  105] Training loss: 0.01093269, Validation loss: 0.01176744, Gradient norm: 0.05196180
INFO:root:At the start of the epoch: mem (CPU python)=10292.953125MB; mem (CPU total)=10275.3046875MB
INFO:root:[  106] Training loss: 0.01093674, Validation loss: 0.01169832, Gradient norm: 0.05315795
INFO:root:At the start of the epoch: mem (CPU python)=10354.80859375MB; mem (CPU total)=10335.84765625MB
INFO:root:[  107] Training loss: 0.01091039, Validation loss: 0.01178274, Gradient norm: 0.04967262
INFO:root:At the start of the epoch: mem (CPU python)=10416.5859375MB; mem (CPU total)=10398.2421875MB
INFO:root:[  108] Training loss: 0.01092163, Validation loss: 0.01176610, Gradient norm: 0.05352681
INFO:root:At the start of the epoch: mem (CPU python)=10478.484375MB; mem (CPU total)=10459.98828125MB
INFO:root:[  109] Training loss: 0.01091261, Validation loss: 0.01217886, Gradient norm: 0.05340367
INFO:root:At the start of the epoch: mem (CPU python)=10540.27734375MB; mem (CPU total)=10522.7734375MB
INFO:root:[  110] Training loss: 0.01089660, Validation loss: 0.01173504, Gradient norm: 0.05033305
INFO:root:At the start of the epoch: mem (CPU python)=10602.0MB; mem (CPU total)=10583.21484375MB
INFO:root:[  111] Training loss: 0.01090703, Validation loss: 0.01167508, Gradient norm: 0.05387159
INFO:root:At the start of the epoch: mem (CPU python)=10663.73046875MB; mem (CPU total)=10646.19921875MB
INFO:root:[  112] Training loss: 0.01091221, Validation loss: 0.01165761, Gradient norm: 0.05316960
INFO:root:At the start of the epoch: mem (CPU python)=10725.14453125MB; mem (CPU total)=10708.01953125MB
INFO:root:[  113] Training loss: 0.01091506, Validation loss: 0.01165474, Gradient norm: 0.05449945
INFO:root:At the start of the epoch: mem (CPU python)=10786.81640625MB; mem (CPU total)=10769.8046875MB
INFO:root:[  114] Training loss: 0.01088212, Validation loss: 0.01187189, Gradient norm: 0.05108365
INFO:root:At the start of the epoch: mem (CPU python)=10848.609375MB; mem (CPU total)=10832.96484375MB
INFO:root:[  115] Training loss: 0.01089678, Validation loss: 0.01170359, Gradient norm: 0.05149619
INFO:root:At the start of the epoch: mem (CPU python)=10910.578125MB; mem (CPU total)=10894.62890625MB
INFO:root:[  116] Training loss: 0.01088257, Validation loss: 0.01163353, Gradient norm: 0.05365344
INFO:root:At the start of the epoch: mem (CPU python)=10972.56640625MB; mem (CPU total)=10957.49609375MB
INFO:root:[  117] Training loss: 0.01089334, Validation loss: 0.01178466, Gradient norm: 0.05535271
INFO:root:At the start of the epoch: mem (CPU python)=11034.2578125MB; mem (CPU total)=11017.1328125MB
INFO:root:[  118] Training loss: 0.01088968, Validation loss: 0.01163718, Gradient norm: 0.05377997
INFO:root:At the start of the epoch: mem (CPU python)=11096.04296875MB; mem (CPU total)=11078.8125MB
INFO:root:[  119] Training loss: 0.01086017, Validation loss: 0.01166075, Gradient norm: 0.05223055
INFO:root:At the start of the epoch: mem (CPU python)=11157.75MB; mem (CPU total)=11140.91796875MB
INFO:root:[  120] Training loss: 0.01085845, Validation loss: 0.01189532, Gradient norm: 0.05135660
INFO:root:At the start of the epoch: mem (CPU python)=11219.390625MB; mem (CPU total)=11203.0625MB
INFO:root:[  121] Training loss: 0.01088030, Validation loss: 0.01175442, Gradient norm: 0.05351549
INFO:root:At the start of the epoch: mem (CPU python)=11281.37890625MB; mem (CPU total)=11264.8671875MB
INFO:root:[  122] Training loss: 0.01086618, Validation loss: 0.01165909, Gradient norm: 0.05467362
INFO:root:At the start of the epoch: mem (CPU python)=11342.7734375MB; mem (CPU total)=11327.1328125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[  123] Training loss: 0.01085150, Validation loss: 0.01167042, Gradient norm: 0.05235735
INFO:root:At the start of the epoch: mem (CPU python)=11404.515625MB; mem (CPU total)=11390.15625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[  124] Training loss: 0.01063043, Validation loss: 0.01146390, Gradient norm: 0.03939588
INFO:root:At the start of the epoch: mem (CPU python)=11466.51171875MB; mem (CPU total)=11451.2890625MB
INFO:root:[  125] Training loss: 0.01049046, Validation loss: 0.01137185, Gradient norm: 0.03356347
INFO:root:At the start of the epoch: mem (CPU python)=11528.41015625MB; mem (CPU total)=11513.85546875MB
INFO:root:[  126] Training loss: 0.01046987, Validation loss: 0.01135380, Gradient norm: 0.03473867
INFO:root:At the start of the epoch: mem (CPU python)=11590.15234375MB; mem (CPU total)=11576.01953125MB
INFO:root:[  127] Training loss: 0.01045164, Validation loss: 0.01137460, Gradient norm: 0.03628878
INFO:root:At the start of the epoch: mem (CPU python)=11651.796875MB; mem (CPU total)=11641.73828125MB
INFO:root:[  128] Training loss: 0.01042776, Validation loss: 0.01133549, Gradient norm: 0.03497963
INFO:root:At the start of the epoch: mem (CPU python)=11713.2734375MB; mem (CPU total)=11702.44921875MB
INFO:root:[  129] Training loss: 0.01042452, Validation loss: 0.01133188, Gradient norm: 0.03731340
INFO:root:At the start of the epoch: mem (CPU python)=11775.0390625MB; mem (CPU total)=11764.91015625MB
INFO:root:[  130] Training loss: 0.01041434, Validation loss: 0.01134441, Gradient norm: 0.03546204
INFO:root:At the start of the epoch: mem (CPU python)=11836.953125MB; mem (CPU total)=11826.47265625MB
INFO:root:[  131] Training loss: 0.01040237, Validation loss: 0.01134907, Gradient norm: 0.03403808
INFO:root:At the start of the epoch: mem (CPU python)=11898.51171875MB; mem (CPU total)=11887.38671875MB
INFO:root:[  132] Training loss: 0.01040570, Validation loss: 0.01131271, Gradient norm: 0.03638688
INFO:root:At the start of the epoch: mem (CPU python)=11960.55859375MB; mem (CPU total)=11948.30078125MB
INFO:root:[  133] Training loss: 0.01040124, Validation loss: 0.01135791, Gradient norm: 0.03632157
INFO:root:At the start of the epoch: mem (CPU python)=12022.33984375MB; mem (CPU total)=12011.7734375MB
INFO:root:[  134] Training loss: 0.01039254, Validation loss: 0.01128840, Gradient norm: 0.03626518
INFO:root:At the start of the epoch: mem (CPU python)=12084.0703125MB; mem (CPU total)=12072.828125MB
INFO:root:[  135] Training loss: 0.01038933, Validation loss: 0.01126441, Gradient norm: 0.03496563
INFO:root:At the start of the epoch: mem (CPU python)=12145.94921875MB; mem (CPU total)=12135.19140625MB
INFO:root:[  136] Training loss: 0.01037833, Validation loss: 0.01132517, Gradient norm: 0.03511879
INFO:root:At the start of the epoch: mem (CPU python)=12207.29296875MB; mem (CPU total)=12195.5625MB
INFO:root:[  137] Training loss: 0.01038046, Validation loss: 0.01132137, Gradient norm: 0.03590938
INFO:root:At the start of the epoch: mem (CPU python)=12269.04296875MB; mem (CPU total)=12257.55859375MB
INFO:root:[  138] Training loss: 0.01036982, Validation loss: 0.01129220, Gradient norm: 0.03440067
INFO:root:At the start of the epoch: mem (CPU python)=12331.0546875MB; mem (CPU total)=12319.83984375MB
INFO:root:[  139] Training loss: 0.01037182, Validation loss: 0.01134334, Gradient norm: 0.03703646
INFO:root:At the start of the epoch: mem (CPU python)=12392.5MB; mem (CPU total)=12381.796875MB
INFO:root:[  140] Training loss: 0.01036176, Validation loss: 0.01132108, Gradient norm: 0.03568766
INFO:root:At the start of the epoch: mem (CPU python)=12454.515625MB; mem (CPU total)=12446.0703125MB
INFO:root:[  141] Training loss: 0.01036926, Validation loss: 0.01140751, Gradient norm: 0.03612927
INFO:root:At the start of the epoch: mem (CPU python)=12516.26171875MB; mem (CPU total)=12505.265625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[  142] Training loss: 0.01036210, Validation loss: 0.01127089, Gradient norm: 0.03668946
INFO:root:At the start of the epoch: mem (CPU python)=12578.046875MB; mem (CPU total)=12566.65625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  143] Training loss: 0.01031168, Validation loss: 0.01122751, Gradient norm: 0.03081198
INFO:root:At the start of the epoch: mem (CPU python)=12639.9765625MB; mem (CPU total)=12628.62109375MB
INFO:root:[  144] Training loss: 0.01025659, Validation loss: 0.01123659, Gradient norm: 0.02695683
INFO:root:At the start of the epoch: mem (CPU python)=12701.52734375MB; mem (CPU total)=12691.26953125MB
INFO:root:[  145] Training loss: 0.01025215, Validation loss: 0.01119478, Gradient norm: 0.02754669
INFO:root:At the start of the epoch: mem (CPU python)=12763.01953125MB; mem (CPU total)=12753.265625MB
INFO:root:[  146] Training loss: 0.01025243, Validation loss: 0.01121723, Gradient norm: 0.02860561
INFO:root:At the start of the epoch: mem (CPU python)=12825.01953125MB; mem (CPU total)=12816.5859375MB
INFO:root:[  147] Training loss: 0.01024602, Validation loss: 0.01119164, Gradient norm: 0.02797542
INFO:root:At the start of the epoch: mem (CPU python)=12886.62890625MB; mem (CPU total)=12876.2734375MB
INFO:root:[  148] Training loss: 0.01024280, Validation loss: 0.01120206, Gradient norm: 0.02783484
INFO:root:At the start of the epoch: mem (CPU python)=12948.54296875MB; mem (CPU total)=12938.9296875MB
INFO:root:[  149] Training loss: 0.01023463, Validation loss: 0.01117914, Gradient norm: 0.02813802
INFO:root:At the start of the epoch: mem (CPU python)=13010.3515625MB; mem (CPU total)=13001.29296875MB
INFO:root:[  150] Training loss: 0.01023437, Validation loss: 0.01118915, Gradient norm: 0.02773511
INFO:root:At the start of the epoch: mem (CPU python)=13072.140625MB; mem (CPU total)=13065.578125MB
INFO:root:[  151] Training loss: 0.01023340, Validation loss: 0.01120285, Gradient norm: 0.02779983
INFO:root:At the start of the epoch: mem (CPU python)=13133.96484375MB; mem (CPU total)=13126.22265625MB
INFO:root:[  152] Training loss: 0.01022880, Validation loss: 0.01118712, Gradient norm: 0.02836853
INFO:root:At the start of the epoch: mem (CPU python)=13195.5078125MB; mem (CPU total)=13188.09375MB
INFO:root:[  153] Training loss: 0.01023363, Validation loss: 0.01122759, Gradient norm: 0.02834874
INFO:root:At the start of the epoch: mem (CPU python)=13258.52734375MB; mem (CPU total)=13251.34375MB
INFO:root:[  154] Training loss: 0.01023356, Validation loss: 0.01118969, Gradient norm: 0.02822191
INFO:root:At the start of the epoch: mem (CPU python)=13320.1328125MB; mem (CPU total)=13313.8515625MB
INFO:root:[  155] Training loss: 0.01022383, Validation loss: 0.01116628, Gradient norm: 0.02812505
INFO:root:At the start of the epoch: mem (CPU python)=13381.91796875MB; mem (CPU total)=13373.2578125MB
INFO:root:[  156] Training loss: 0.01022218, Validation loss: 0.01118808, Gradient norm: 0.02756818
INFO:root:At the start of the epoch: mem (CPU python)=13443.87109375MB; mem (CPU total)=13435.7421875MB
INFO:root:[  157] Training loss: 0.01021900, Validation loss: 0.01116529, Gradient norm: 0.02826085
INFO:root:At the start of the epoch: mem (CPU python)=13500.4609375MB; mem (CPU total)=13491.00390625MB
INFO:root:[  158] Training loss: 0.01022903, Validation loss: 0.01117898, Gradient norm: 0.02877876
INFO:root:At the start of the epoch: mem (CPU python)=13563.55859375MB; mem (CPU total)=13555.2890625MB
INFO:root:[  159] Training loss: 0.01021117, Validation loss: 0.01117427, Gradient norm: 0.02803945
INFO:root:At the start of the epoch: mem (CPU python)=13625.1953125MB; mem (CPU total)=13618.49609375MB
INFO:root:[  160] Training loss: 0.01021366, Validation loss: 0.01117953, Gradient norm: 0.02778318
INFO:root:At the start of the epoch: mem (CPU python)=13688.30078125MB; mem (CPU total)=13681.08203125MB
INFO:root:[  161] Training loss: 0.01022119, Validation loss: 0.01116965, Gradient norm: 0.02769783
INFO:root:At the start of the epoch: mem (CPU python)=13749.984375MB; mem (CPU total)=13744.1015625MB
INFO:root:[  162] Training loss: 0.01021226, Validation loss: 0.01123351, Gradient norm: 0.02807421
INFO:root:At the start of the epoch: mem (CPU python)=13811.5MB; mem (CPU total)=13805.1640625MB
INFO:root:[  163] Training loss: 0.01020545, Validation loss: 0.01115295, Gradient norm: 0.02806802
INFO:root:At the start of the epoch: mem (CPU python)=13873.2890625MB; mem (CPU total)=13866.046875MB
INFO:root:[  164] Training loss: 0.01020523, Validation loss: 0.01116447, Gradient norm: 0.02800175
INFO:root:At the start of the epoch: mem (CPU python)=13935.1796875MB; mem (CPU total)=13930.16796875MB
INFO:root:[  165] Training loss: 0.01020572, Validation loss: 0.01117509, Gradient norm: 0.02756527
INFO:root:At the start of the epoch: mem (CPU python)=13997.09765625MB; mem (CPU total)=13991.2109375MB
INFO:root:[  166] Training loss: 0.01020639, Validation loss: 0.01115408, Gradient norm: 0.02805391
INFO:root:At the start of the epoch: mem (CPU python)=14058.76171875MB; mem (CPU total)=14053.0703125MB
INFO:root:[  167] Training loss: 0.01020667, Validation loss: 0.01114700, Gradient norm: 0.02809216
INFO:root:At the start of the epoch: mem (CPU python)=14120.60546875MB; mem (CPU total)=14112.84375MB
INFO:root:[  168] Training loss: 0.01019910, Validation loss: 0.01117642, Gradient norm: 0.02796670
INFO:root:At the start of the epoch: mem (CPU python)=14182.40625MB; mem (CPU total)=14174.48828125MB
INFO:root:[  169] Training loss: 0.01019723, Validation loss: 0.01115703, Gradient norm: 0.02818773
INFO:root:At the start of the epoch: mem (CPU python)=14243.9453125MB; mem (CPU total)=14236.78515625MB
INFO:root:[  170] Training loss: 0.01020146, Validation loss: 0.01117459, Gradient norm: 0.02842834
INFO:root:At the start of the epoch: mem (CPU python)=14305.7578125MB; mem (CPU total)=14298.859375MB
INFO:root:[  171] Training loss: 0.01019911, Validation loss: 0.01116433, Gradient norm: 0.02829078
INFO:root:At the start of the epoch: mem (CPU python)=14367.29296875MB; mem (CPU total)=14362.0078125MB
INFO:root:[  172] Training loss: 0.01019743, Validation loss: 0.01115621, Gradient norm: 0.02857191
INFO:root:At the start of the epoch: mem (CPU python)=14429.20703125MB; mem (CPU total)=14422.66796875MB
INFO:root:[  173] Training loss: 0.01019827, Validation loss: 0.01115338, Gradient norm: 0.02837989
INFO:root:At the start of the epoch: mem (CPU python)=14491.19921875MB; mem (CPU total)=14485.5MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  174] Training loss: 0.01019265, Validation loss: 0.01115299, Gradient norm: 0.02857612
INFO:root:At the start of the epoch: mem (CPU python)=14552.94140625MB; mem (CPU total)=14546.84375MB
INFO:root:[  175] Training loss: 0.01018447, Validation loss: 0.01114734, Gradient norm: 0.02654697
INFO:root:At the start of the epoch: mem (CPU python)=14614.61328125MB; mem (CPU total)=14609.7265625MB
INFO:root:[  176] Training loss: 0.01017863, Validation loss: 0.01114893, Gradient norm: 0.02627611
INFO:root:At the start of the epoch: mem (CPU python)=14676.40234375MB; mem (CPU total)=14672.76953125MB
INFO:root:[  177] Training loss: 0.01016542, Validation loss: 0.01110305, Gradient norm: 0.02701040
INFO:root:At the start of the epoch: mem (CPU python)=14737.80078125MB; mem (CPU total)=14732.4453125MB
INFO:root:[  178] Training loss: 0.01015459, Validation loss: 0.01113089, Gradient norm: 0.02682979
INFO:root:At the start of the epoch: mem (CPU python)=14799.75MB; mem (CPU total)=14793.80859375MB
INFO:root:[  179] Training loss: 0.01014767, Validation loss: 0.01112369, Gradient norm: 0.02770370
INFO:root:At the start of the epoch: mem (CPU python)=14861.2109375MB; mem (CPU total)=14855.71484375MB
INFO:root:[  180] Training loss: 0.01013935, Validation loss: 0.01111278, Gradient norm: 0.02701105
INFO:root:At the start of the epoch: mem (CPU python)=14923.1484375MB; mem (CPU total)=14917.6640625MB
INFO:root:[  181] Training loss: 0.01012988, Validation loss: 0.01111547, Gradient norm: 0.02648173
INFO:root:At the start of the epoch: mem (CPU python)=14985.21875MB; mem (CPU total)=14978.578125MB
INFO:root:[  182] Training loss: 0.01013093, Validation loss: 0.01112065, Gradient norm: 0.02692690
INFO:root:At the start of the epoch: mem (CPU python)=15048.29296875MB; mem (CPU total)=15041.60546875MB
INFO:root:[  183] Training loss: 0.01013325, Validation loss: 0.01110952, Gradient norm: 0.02712945
INFO:root:At the start of the epoch: mem (CPU python)=15109.9921875MB; mem (CPU total)=15103.984375MB
INFO:root:[  184] Training loss: 0.01012830, Validation loss: 0.01110795, Gradient norm: 0.02738303
INFO:root:At the start of the epoch: mem (CPU python)=15171.66015625MB; mem (CPU total)=15167.33984375MB
INFO:root:[  185] Training loss: 0.01013067, Validation loss: 0.01110853, Gradient norm: 0.02715995
INFO:root:At the start of the epoch: mem (CPU python)=15233.13671875MB; mem (CPU total)=15228.25MB
INFO:root:[  186] Training loss: 0.01012765, Validation loss: 0.01109336, Gradient norm: 0.02675744
INFO:root:At the start of the epoch: mem (CPU python)=15294.875MB; mem (CPU total)=15287.484375MB
INFO:root:[  187] Training loss: 0.01012161, Validation loss: 0.01109566, Gradient norm: 0.02709886
INFO:root:At the start of the epoch: mem (CPU python)=15356.84375MB; mem (CPU total)=15350.078125MB
INFO:root:[  188] Training loss: 0.01012034, Validation loss: 0.01109929, Gradient norm: 0.02613461
INFO:root:At the start of the epoch: mem (CPU python)=15418.5078125MB; mem (CPU total)=15413.234375MB
INFO:root:[  189] Training loss: 0.01012203, Validation loss: 0.01110418, Gradient norm: 0.02751984
INFO:root:At the start of the epoch: mem (CPU python)=15480.5546875MB; mem (CPU total)=15474.734375MB
INFO:root:[  190] Training loss: 0.01012635, Validation loss: 0.01110501, Gradient norm: 0.02701233
INFO:root:At the start of the epoch: mem (CPU python)=15542.2265625MB; mem (CPU total)=15537.3203125MB
INFO:root:[  191] Training loss: 0.01011971, Validation loss: 0.01109269, Gradient norm: 0.02748768
INFO:root:At the start of the epoch: mem (CPU python)=15604.0078125MB; mem (CPU total)=15597.91796875MB
INFO:root:[  192] Training loss: 0.01011728, Validation loss: 0.01109384, Gradient norm: 0.02714229
INFO:root:At the start of the epoch: mem (CPU python)=15665.77734375MB; mem (CPU total)=15660.15234375MB
INFO:root:[  193] Training loss: 0.01012283, Validation loss: 0.01110994, Gradient norm: 0.02713789
INFO:root:At the start of the epoch: mem (CPU python)=15727.26171875MB; mem (CPU total)=15721.70703125MB
INFO:root:[  194] Training loss: 0.01012114, Validation loss: 0.01111679, Gradient norm: 0.02744209
INFO:root:At the start of the epoch: mem (CPU python)=15789.0234375MB; mem (CPU total)=15783.56640625MB
INFO:root:[  195] Training loss: 0.01011709, Validation loss: 0.01110304, Gradient norm: 0.02683923
INFO:root:At the start of the epoch: mem (CPU python)=15850.609375MB; mem (CPU total)=15844.81640625MB
INFO:root:[  196] Training loss: 0.01011434, Validation loss: 0.01108199, Gradient norm: 0.02777037
INFO:root:At the start of the epoch: mem (CPU python)=15912.6015625MB; mem (CPU total)=15906.50390625MB
INFO:root:[  197] Training loss: 0.01011495, Validation loss: 0.01109469, Gradient norm: 0.02729054
INFO:root:At the start of the epoch: mem (CPU python)=15975.90234375MB; mem (CPU total)=15971.04296875MB
INFO:root:[  198] Training loss: 0.01012406, Validation loss: 0.01111089, Gradient norm: 0.02801918
INFO:root:At the start of the epoch: mem (CPU python)=16037.59375MB; mem (CPU total)=16032.328125MB
INFO:root:[  199] Training loss: 0.01011828, Validation loss: 0.01110843, Gradient norm: 0.02741062
INFO:root:At the start of the epoch: mem (CPU python)=16099.35546875MB; mem (CPU total)=16092.33203125MB
INFO:root:[  200] Training loss: 0.01012015, Validation loss: 0.01110381, Gradient norm: 0.02809080
INFO:root:At the start of the epoch: mem (CPU python)=16161.03125MB; mem (CPU total)=16155.1953125MB
INFO:root:[  201] Training loss: 0.01011588, Validation loss: 0.01107362, Gradient norm: 0.02787854
INFO:root:At the start of the epoch: mem (CPU python)=16222.69140625MB; mem (CPU total)=16218.6640625MB
INFO:root:[  202] Training loss: 0.01011616, Validation loss: 0.01110369, Gradient norm: 0.02711158
INFO:root:At the start of the epoch: mem (CPU python)=16278.84375MB; mem (CPU total)=16275.3671875MB
INFO:root:[  203] Training loss: 0.01011726, Validation loss: 0.01107578, Gradient norm: 0.02810392
INFO:root:At the start of the epoch: mem (CPU python)=16343.4921875MB; mem (CPU total)=16340.734375MB
INFO:root:[  204] Training loss: 0.01011780, Validation loss: 0.01109474, Gradient norm: 0.02767133
INFO:root:At the start of the epoch: mem (CPU python)=16405.1796875MB; mem (CPU total)=16401.66015625MB
INFO:root:[  205] Training loss: 0.01011423, Validation loss: 0.01109018, Gradient norm: 0.02705786
INFO:root:At the start of the epoch: mem (CPU python)=16467.1875MB; mem (CPU total)=16464.44140625MB
INFO:root:[  206] Training loss: 0.01011887, Validation loss: 0.01112038, Gradient norm: 0.02804161
INFO:root:At the start of the epoch: mem (CPU python)=16529.09765625MB; mem (CPU total)=16525.9921875MB
INFO:root:[  207] Training loss: 0.01011431, Validation loss: 0.01108329, Gradient norm: 0.02745177
INFO:root:At the start of the epoch: mem (CPU python)=16590.68359375MB; mem (CPU total)=16587.87109375MB
INFO:root:[  208] Training loss: 0.01011713, Validation loss: 0.01110899, Gradient norm: 0.02823124
INFO:root:At the start of the epoch: mem (CPU python)=16652.52734375MB; mem (CPU total)=16649.59375MB
INFO:root:[  209] Training loss: 0.01011325, Validation loss: 0.01109816, Gradient norm: 0.02735991
INFO:root:At the start of the epoch: mem (CPU python)=16716.5546875MB; mem (CPU total)=16713.55859375MB
INFO:root:[  210] Training loss: 0.01011230, Validation loss: 0.01109326, Gradient norm: 0.02705134
INFO:root:At the start of the epoch: mem (CPU python)=16778.328125MB; mem (CPU total)=16776.41796875MB
INFO:root:EP 210: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16837.359375MB; mem (CPU total)=16833.77734375MB
INFO:root:Training the model took 258880.474s.
INFO:root:Emptying the cuda cache took 0.081s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
