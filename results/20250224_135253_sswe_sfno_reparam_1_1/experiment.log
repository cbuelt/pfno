INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.4765625MB; mem (CPU total)=8941.46875MB
INFO:root:############### Starting experiment with config file sswe/sfno_sr_reparam_1_1_batch_32.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=587.23828125MB; mem (CPU total)=8943.6796875MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=588.66015625MB; mem (CPU total)=8943.6796875MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2269.9453125MB; mem (CPU total)=10369.2109375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2279.48046875MB; mem (CPU total)=10378.76953125MB
INFO:root:[    1] Training loss: 0.58670616, Validation loss: 0.51985873, Gradient norm: 0.46616542
INFO:root:At the start of the epoch: mem (CPU python)=4475.36328125MB; mem (CPU total)=12118.18359375MB
INFO:root:[    2] Training loss: 0.51986014, Validation loss: 0.51829867, Gradient norm: 0.32792968
INFO:root:At the start of the epoch: mem (CPU python)=4485.328125MB; mem (CPU total)=9990.42578125MB
INFO:root:[    3] Training loss: 0.51747808, Validation loss: 0.51588918, Gradient norm: 0.23460576
INFO:root:At the start of the epoch: mem (CPU python)=4530.55859375MB; mem (CPU total)=10179.0MB
INFO:root:[    4] Training loss: 0.50838894, Validation loss: 0.49580620, Gradient norm: 0.29795546
INFO:root:At the start of the epoch: mem (CPU python)=4533.7890625MB; mem (CPU total)=12380.6953125MB
INFO:root:[    5] Training loss: 0.47941460, Validation loss: 0.45051422, Gradient norm: 0.40886038
INFO:root:At the start of the epoch: mem (CPU python)=4560.75MB; mem (CPU total)=10345.546875MB
INFO:root:[    6] Training loss: 0.43547808, Validation loss: 0.42422602, Gradient norm: 0.49995782
INFO:root:At the start of the epoch: mem (CPU python)=4576.62890625MB; mem (CPU total)=12538.69140625MB
INFO:root:[    7] Training loss: 0.41503320, Validation loss: 0.41155857, Gradient norm: 0.52658525
INFO:root:At the start of the epoch: mem (CPU python)=4595.1171875MB; mem (CPU total)=12615.4140625MB
INFO:root:[    8] Training loss: 0.40029556, Validation loss: 0.39428983, Gradient norm: 0.53186563
INFO:root:At the start of the epoch: mem (CPU python)=4616.72265625MB; mem (CPU total)=12704.3203125MB
INFO:root:[    9] Training loss: 0.38183197, Validation loss: 0.36981658, Gradient norm: 0.64693902
INFO:root:At the start of the epoch: mem (CPU python)=4643.4609375MB; mem (CPU total)=12805.26171875MB
INFO:root:[   10] Training loss: 0.35878734, Validation loss: 0.35378802, Gradient norm: 0.72733614
INFO:root:At the start of the epoch: mem (CPU python)=4666.1875MB; mem (CPU total)=12909.6015625MB
INFO:root:[   11] Training loss: 0.34105579, Validation loss: 0.33664888, Gradient norm: 0.74621140
INFO:root:At the start of the epoch: mem (CPU python)=4682.13671875MB; mem (CPU total)=12967.71875MB
INFO:root:[   12] Training loss: 0.32685563, Validation loss: 0.33559213, Gradient norm: 0.80102701
INFO:root:At the start of the epoch: mem (CPU python)=4709.875MB; mem (CPU total)=13045.2109375MB
INFO:root:[   13] Training loss: 0.31441740, Validation loss: 0.32885743, Gradient norm: 0.86884035
INFO:root:At the start of the epoch: mem (CPU python)=4739.0703125MB; mem (CPU total)=13047.43359375MB
INFO:root:[   14] Training loss: 0.30403603, Validation loss: 0.31309468, Gradient norm: 0.95101733
INFO:root:At the start of the epoch: mem (CPU python)=4745.57421875MB; mem (CPU total)=13068.73046875MB
INFO:root:[   15] Training loss: 0.29653961, Validation loss: 0.30279177, Gradient norm: 0.99011865
INFO:root:At the start of the epoch: mem (CPU python)=4767.40625MB; mem (CPU total)=13100.89453125MB
INFO:root:[   16] Training loss: 0.29276125, Validation loss: 0.31804410, Gradient norm: 1.14827758
INFO:root:At the start of the epoch: mem (CPU python)=4780.953125MB; mem (CPU total)=10860.4453125MB
INFO:root:[   17] Training loss: 0.28581771, Validation loss: 0.30068977, Gradient norm: 1.14022129
INFO:root:At the start of the epoch: mem (CPU python)=4805.4140625MB; mem (CPU total)=10945.8359375MB
INFO:root:[   18] Training loss: 0.28462329, Validation loss: 0.31583876, Gradient norm: 1.22988914
INFO:root:At the start of the epoch: mem (CPU python)=4838.078125MB; mem (CPU total)=11021.1875MB
INFO:root:[   19] Training loss: 0.28012852, Validation loss: 0.31347287, Gradient norm: 1.29582258
INFO:root:At the start of the epoch: mem (CPU python)=4857.609375MB; mem (CPU total)=11124.19921875MB
INFO:root:[   20] Training loss: 0.28069112, Validation loss: 0.31367571, Gradient norm: 1.46580473
INFO:root:At the start of the epoch: mem (CPU python)=4872.00390625MB; mem (CPU total)=11182.34375MB
INFO:root:[   21] Training loss: 0.27442532, Validation loss: 0.33431454, Gradient norm: 1.38627260
INFO:root:At the start of the epoch: mem (CPU python)=4897.69140625MB; mem (CPU total)=11235.64453125MB
INFO:root:[   22] Training loss: 0.27257790, Validation loss: 0.37899842, Gradient norm: 1.84626940
INFO:root:At the start of the epoch: mem (CPU python)=4916.11328125MB; mem (CPU total)=11340.40234375MB
INFO:root:[   23] Training loss: 0.26661842, Validation loss: 0.44380099, Gradient norm: 1.50241467
INFO:root:At the start of the epoch: mem (CPU python)=4936.6875MB; mem (CPU total)=11420.0MB
INFO:root:[   24] Training loss: 0.26240963, Validation loss: 0.43694325, Gradient norm: 1.82022965
INFO:root:At the start of the epoch: mem (CPU python)=4954.73828125MB; mem (CPU total)=11499.50390625MB
INFO:root:[   25] Training loss: 0.25850753, Validation loss: 0.46186619, Gradient norm: 1.80789782
INFO:root:At the start of the epoch: mem (CPU python)=4976.82421875MB; mem (CPU total)=11580.359375MB
INFO:root:[   26] Training loss: 0.25785287, Validation loss: 0.45155988, Gradient norm: 1.79541831
INFO:root:At the start of the epoch: mem (CPU python)=4997.6328125MB; mem (CPU total)=13895.9921875MB
INFO:root:[   27] Training loss: 0.25029688, Validation loss: 0.44296487, Gradient norm: 1.60107842
INFO:root:At the start of the epoch: mem (CPU python)=5021.7890625MB; mem (CPU total)=13966.61328125MB
INFO:root:[   28] Training loss: 0.24575979, Validation loss: 0.46310059, Gradient norm: 1.94998697
INFO:root:At the start of the epoch: mem (CPU python)=5041.046875MB; mem (CPU total)=11817.67578125MB
INFO:root:[   29] Training loss: 0.24452999, Validation loss: 0.44085209, Gradient norm: 1.84661780
INFO:root:At the start of the epoch: mem (CPU python)=5070.59375MB; mem (CPU total)=11897.35546875MB
INFO:root:[   30] Training loss: 0.24456125, Validation loss: 0.43687823, Gradient norm: 2.10956658
INFO:root:At the start of the epoch: mem (CPU python)=5083.47265625MB; mem (CPU total)=14288.77734375MB
