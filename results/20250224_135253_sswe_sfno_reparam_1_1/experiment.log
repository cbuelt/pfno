INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.4765625MB; mem (CPU total)=8941.46875MB
INFO:root:############### Starting experiment with config file sswe/sfno_sr_reparam_1_1_batch_32.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=587.23828125MB; mem (CPU total)=8943.6796875MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=588.66015625MB; mem (CPU total)=8943.6796875MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2269.9453125MB; mem (CPU total)=10369.2109375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2279.48046875MB; mem (CPU total)=10378.76953125MB
INFO:root:[    1] Training loss: 0.58670616, Validation loss: 0.51985873, Gradient norm: 0.46616542
INFO:root:At the start of the epoch: mem (CPU python)=4475.36328125MB; mem (CPU total)=12118.18359375MB
INFO:root:[    2] Training loss: 0.51986014, Validation loss: 0.51829867, Gradient norm: 0.32792968
INFO:root:At the start of the epoch: mem (CPU python)=4485.328125MB; mem (CPU total)=9990.42578125MB
INFO:root:[    3] Training loss: 0.51747808, Validation loss: 0.51588918, Gradient norm: 0.23460576
INFO:root:At the start of the epoch: mem (CPU python)=4530.55859375MB; mem (CPU total)=10179.0MB
INFO:root:[    4] Training loss: 0.50838894, Validation loss: 0.49580620, Gradient norm: 0.29795546
INFO:root:At the start of the epoch: mem (CPU python)=4533.7890625MB; mem (CPU total)=12380.6953125MB
INFO:root:[    5] Training loss: 0.47941460, Validation loss: 0.45051422, Gradient norm: 0.40886038
INFO:root:At the start of the epoch: mem (CPU python)=4560.75MB; mem (CPU total)=10345.546875MB
INFO:root:[    6] Training loss: 0.43547808, Validation loss: 0.42422602, Gradient norm: 0.49995782
INFO:root:At the start of the epoch: mem (CPU python)=4576.62890625MB; mem (CPU total)=12538.69140625MB
INFO:root:[    7] Training loss: 0.41503320, Validation loss: 0.41155857, Gradient norm: 0.52658525
INFO:root:At the start of the epoch: mem (CPU python)=4595.1171875MB; mem (CPU total)=12615.4140625MB
INFO:root:[    8] Training loss: 0.40029556, Validation loss: 0.39428983, Gradient norm: 0.53186563
INFO:root:At the start of the epoch: mem (CPU python)=4616.72265625MB; mem (CPU total)=12704.3203125MB
INFO:root:[    9] Training loss: 0.38183197, Validation loss: 0.36981658, Gradient norm: 0.64693902
INFO:root:At the start of the epoch: mem (CPU python)=4643.4609375MB; mem (CPU total)=12805.26171875MB
INFO:root:[   10] Training loss: 0.35878734, Validation loss: 0.35378802, Gradient norm: 0.72733614
INFO:root:At the start of the epoch: mem (CPU python)=4666.1875MB; mem (CPU total)=12909.6015625MB
