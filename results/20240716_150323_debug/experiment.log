INFO:root:Starting the logger.
INFO:root:Using cpu.
INFO:root:############### Starting experiment with config file debug.ini ###############
INFO:root:###1 out of 2 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SWE', 'max_training_set_size': 10000, 'downscaling_factor': 2, 'temporal_downscaling': 4, 'init_steps': 10, 't_start': 10, 'pred_horizon': 5}
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1, 'early_stopping': 10, 'dropout': 0.0, 'init': 'default', 'learning_rate': 0.0001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'fourier_dropout': 0.0, 'hidden_channels': 32, 'projection_channels': 64, 'alpha': 0.05, 'n_samples_uq': 10, 'n_samples': 3, 'lifting_channels': 128, 'n_modes': (16, 16), 'uno_out_channels': [32, 64, 64, 32], 'uno_scalings': [[1.0, 1.0], [0.5, 0.5], [1, 1], [2, 2]], 'uno_n_modes': [[16, 16], [8, 8], [8, 8], [16, 16]]}
INFO:root:Number parameters: 1192101
INFO:root:Memory allocated: 0
INFO:root:Training starts now.
INFO:root:[    1] Training loss: 4.97746300, Validation loss: 28.61792994, Gradient norm: 3.17648163
INFO:root:Training the model took 11.647s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on train data.
INFO:root:MSEtrain: 3.57425
INFO:root:EnergyScoretrain: 8.06852
INFO:root:Coveragetrain: 0.0
INFO:root:IntervalWidthtrain: 0.0
INFO:root:Evaluating the model on validation data.
INFO:root:MSEvalidation: 0.98312
INFO:root:EnergyScorevalidation: 2.2193
INFO:root:Coveragevalidation: 0.0
INFO:root:IntervalWidthvalidation: 0.0
INFO:root:Evaluating the model on test data.
INFO:root:MSEtest: 1.64647
INFO:root:EnergyScoretest: 3.71641
INFO:root:Coveragetest: 0.0
INFO:root:IntervalWidthtest: 0.0
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1, 'early_stopping': 10, 'dropout': 0.0, 'init': 'default', 'learning_rate': 0.0001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'fourier_dropout': 0.0, 'hidden_channels': 32, 'projection_channels': 64, 'alpha': 0.05, 'n_samples_uq': 10, 'n_samples': 3, 'lifting_channels': 128, 'n_modes': (16, 16), 'uno_out_channels': [32, 64, 64, 32], 'uno_scalings': [[1.0, 1.0], [0.5, 0.5], [1, 1], [2, 2]], 'uno_n_modes': [[16, 16], [8, 8], [8, 8], [16, 16]]}
INFO:root:Number parameters: 1192101
INFO:root:Memory allocated: 0
INFO:root:Training starts now.
INFO:root:[    1] Training loss: 4.78836671, Validation loss: 27.41735077, Gradient norm: 2.85990117
INFO:root:Training the model took 10.18s.
INFO:root:Emptying the cuda cache took 0.0s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on train data.
INFO:root:MSEtrain: 3.42483
INFO:root:EnergyScoretrain: 7.34986
INFO:root:Coveragetrain: 4e-05
INFO:root:IntervalWidthtrain: 66.65202331542969
INFO:root:Evaluating the model on validation data.
INFO:root:MSEvalidation: 0.92246
INFO:root:EnergyScorevalidation: 1.97307
INFO:root:Coveragevalidation: 1e-05
INFO:root:IntervalWidthvalidation: 18.25157928466797
INFO:root:Evaluating the model on test data.
INFO:root:MSEtest: 1.55205
INFO:root:EnergyScoretest: 3.32045
INFO:root:Coveragetest: 3e-05
INFO:root:IntervalWidthtest: 33.25983810424805
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1, 'early_stopping': 10, 'dropout': 0.0, 'init': 'default', 'learning_rate': 0.0001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'fourier_dropout': 0.0, 'hidden_channels': 32, 'projection_channels': 64, 'alpha': 0.05, 'n_samples_uq': 10, 'n_samples': 3, 'lifting_channels': 128, 'n_modes': (16, 16), 'uno_out_channels': [32, 64, 64, 32], 'uno_scalings': [[1.0, 1.0], [0.5, 0.5], [1, 1], [2, 2]], 'uno_n_modes': [[16, 16], [8, 8], [8, 8], [16, 16]]}
INFO:root:Number parameters: 1192101
INFO:root:Memory allocated: 0
INFO:root:Training starts now.
