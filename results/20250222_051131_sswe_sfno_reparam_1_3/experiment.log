INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=576.9296875MB; mem (CPU total)=10889.25MB
INFO:root:############### Starting experiment with config file sswe/sfno_sr_reparam_1_3.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=587.7109375MB; mem (CPU total)=10895.71875MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=589.1328125MB; mem (CPU total)=10896.3671875MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2227.265625MB; mem (CPU total)=12265.7265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2236.9296875MB; mem (CPU total)=12274.3671875MB
INFO:root:[    1] Training loss: 0.53898089, Validation loss: 0.51908193, Gradient norm: 0.37078816
INFO:root:At the start of the epoch: mem (CPU python)=4410.7890625MB; mem (CPU total)=14025.1171875MB
INFO:root:[    2] Training loss: 0.45971183, Validation loss: 0.40872331, Gradient norm: 0.46354754
INFO:root:At the start of the epoch: mem (CPU python)=4436.0703125MB; mem (CPU total)=14098.3671875MB
INFO:root:[    3] Training loss: 0.38331701, Validation loss: 0.36601085, Gradient norm: 0.59792647
INFO:root:At the start of the epoch: mem (CPU python)=4457.30859375MB; mem (CPU total)=14168.8046875MB
INFO:root:[    4] Training loss: 0.35305397, Validation loss: 0.33550285, Gradient norm: 0.72837820
INFO:root:At the start of the epoch: mem (CPU python)=4478.4921875MB; mem (CPU total)=14235.4453125MB
INFO:root:[    5] Training loss: 0.32635931, Validation loss: 0.32085891, Gradient norm: 0.87148432
INFO:root:At the start of the epoch: mem (CPU python)=4499.671875MB; mem (CPU total)=14304.16015625MB
INFO:root:[    6] Training loss: 0.31029080, Validation loss: 0.32924129, Gradient norm: 0.96976351
INFO:root:At the start of the epoch: mem (CPU python)=4520.8515625MB; mem (CPU total)=14372.921875MB
INFO:root:[    7] Training loss: 0.29979125, Validation loss: 0.30389268, Gradient norm: 1.10494364
INFO:root:At the start of the epoch: mem (CPU python)=4542.25MB; mem (CPU total)=14445.3828125MB
INFO:root:[    8] Training loss: 0.28978431, Validation loss: 0.30404631, Gradient norm: 1.19450928
INFO:root:At the start of the epoch: mem (CPU python)=4563.58203125MB; mem (CPU total)=14509.40234375MB
INFO:root:[    9] Training loss: 0.28367145, Validation loss: 0.31003201, Gradient norm: 1.39525545
INFO:root:At the start of the epoch: mem (CPU python)=4585.87109375MB; mem (CPU total)=14580.94921875MB
INFO:root:[   10] Training loss: 0.27899491, Validation loss: 0.30435747, Gradient norm: 1.46534036
INFO:root:At the start of the epoch: mem (CPU python)=4607.03515625MB; mem (CPU total)=14653.01171875MB
INFO:root:[   11] Training loss: 0.27454571, Validation loss: 0.30325071, Gradient norm: 1.67121790
INFO:root:At the start of the epoch: mem (CPU python)=4628.203125MB; mem (CPU total)=14723.9453125MB
INFO:root:[   12] Training loss: 0.27226861, Validation loss: 0.30303584, Gradient norm: 1.81463839
INFO:root:At the start of the epoch: mem (CPU python)=4649.3671875MB; mem (CPU total)=14790.03125MB
INFO:root:[   13] Training loss: 0.26989414, Validation loss: 0.30834123, Gradient norm: 1.95129788
INFO:root:At the start of the epoch: mem (CPU python)=4670.52734375MB; mem (CPU total)=14859.98046875MB
INFO:root:[   14] Training loss: 0.26841505, Validation loss: 0.31694757, Gradient norm: 2.08124941
INFO:root:At the start of the epoch: mem (CPU python)=4691.69140625MB; mem (CPU total)=14931.3203125MB
INFO:root:[   15] Training loss: 0.26622992, Validation loss: 0.32921343, Gradient norm: 2.19817373
INFO:root:At the start of the epoch: mem (CPU python)=4712.85546875MB; mem (CPU total)=15002.9296875MB
INFO:root:[   16] Training loss: 0.26373340, Validation loss: 0.34991827, Gradient norm: 2.32558392
INFO:root:At the start of the epoch: mem (CPU python)=4734.01953125MB; mem (CPU total)=15066.9140625MB
INFO:root:[   17] Training loss: 0.26471021, Validation loss: 0.34438798, Gradient norm: 2.40744392
INFO:root:At the start of the epoch: mem (CPU python)=4764.89453125MB; mem (CPU total)=15146.140625MB
INFO:root:[   18] Training loss: 0.26072192, Validation loss: 0.36046658, Gradient norm: 2.57349597
INFO:root:At the start of the epoch: mem (CPU python)=4786.09765625MB; mem (CPU total)=15216.2421875MB
INFO:root:[   19] Training loss: 0.26062821, Validation loss: 0.39845708, Gradient norm: 2.55386289
INFO:root:At the start of the epoch: mem (CPU python)=4807.26171875MB; mem (CPU total)=15287.609375MB
INFO:root:[   20] Training loss: 0.25961779, Validation loss: 0.38847913, Gradient norm: 2.57833059
INFO:root:At the start of the epoch: mem (CPU python)=4828.42578125MB; mem (CPU total)=15356.76171875MB
INFO:root:[   21] Training loss: 0.25854456, Validation loss: 0.41208292, Gradient norm: 2.66337535
INFO:root:At the start of the epoch: mem (CPU python)=4849.58984375MB; mem (CPU total)=15422.3359375MB
INFO:root:[   22] Training loss: 0.25488711, Validation loss: 0.43699464, Gradient norm: 2.64598720
INFO:root:At the start of the epoch: mem (CPU python)=4870.7578125MB; mem (CPU total)=15492.6953125MB
INFO:root:[   23] Training loss: 0.25176771, Validation loss: 0.43767113, Gradient norm: 2.75788358
INFO:root:At the start of the epoch: mem (CPU python)=4891.921875MB; mem (CPU total)=15561.37109375MB
INFO:root:[   24] Training loss: 0.25018559, Validation loss: 0.44513099, Gradient norm: 2.77363644
INFO:root:At the start of the epoch: mem (CPU python)=4913.0859375MB; mem (CPU total)=15633.70703125MB
INFO:root:[   25] Training loss: 0.25081073, Validation loss: 0.43021863, Gradient norm: 2.80259189
INFO:root:At the start of the epoch: mem (CPU python)=4934.25MB; mem (CPU total)=15698.17578125MB
INFO:root:[   26] Training loss: 0.24970498, Validation loss: 0.41946912, Gradient norm: 2.83975529
INFO:root:At the start of the epoch: mem (CPU python)=4955.4140625MB; mem (CPU total)=15764.8515625MB
INFO:root:[   27] Training loss: 0.24720658, Validation loss: 0.42635618, Gradient norm: 2.98741643
INFO:root:At the start of the epoch: mem (CPU python)=4980.1640625MB; mem (CPU total)=15838.23828125MB
INFO:root:[   28] Training loss: 0.24715462, Validation loss: 0.43844978, Gradient norm: 2.95394705
INFO:root:At the start of the epoch: mem (CPU python)=5001.4921875MB; mem (CPU total)=15894.5625MB
INFO:root:[   29] Training loss: 0.24451356, Validation loss: 0.44350188, Gradient norm: 2.97693316
INFO:root:At the start of the epoch: mem (CPU python)=5022.66015625MB; mem (CPU total)=15949.41796875MB
INFO:root:[   30] Training loss: 0.24129750, Validation loss: 0.41901464, Gradient norm: 3.02015619
INFO:root:At the start of the epoch: mem (CPU python)=5043.82421875MB; mem (CPU total)=16001.8359375MB
INFO:root:[   31] Training loss: 0.24273026, Validation loss: 0.42940183, Gradient norm: 2.93776469
INFO:root:At the start of the epoch: mem (CPU python)=5064.98828125MB; mem (CPU total)=16056.71875MB
INFO:root:[   32] Training loss: 0.24209701, Validation loss: 0.43280481, Gradient norm: 2.92556604
INFO:root:At the start of the epoch: mem (CPU python)=5086.1484375MB; mem (CPU total)=16109.51171875MB
INFO:root:[   33] Training loss: 0.24084478, Validation loss: 0.44957004, Gradient norm: 2.85164503
INFO:root:At the start of the epoch: mem (CPU python)=5107.31640625MB; mem (CPU total)=16163.99609375MB
INFO:root:[   34] Training loss: 0.23791420, Validation loss: 0.43928921, Gradient norm: 2.96645177
INFO:root:At the start of the epoch: mem (CPU python)=5128.4765625MB; mem (CPU total)=16216.15234375MB
INFO:root:[   35] Training loss: 0.23666264, Validation loss: 0.43782565, Gradient norm: 2.85920522
INFO:root:At the start of the epoch: mem (CPU python)=5149.640625MB; mem (CPU total)=16271.03515625MB
INFO:root:[   36] Training loss: 0.23445007, Validation loss: 0.43409869, Gradient norm: 3.05701000
INFO:root:At the start of the epoch: mem (CPU python)=5170.80859375MB; mem (CPU total)=16322.98046875MB
INFO:root:[   37] Training loss: 0.23419130, Validation loss: 0.44148079, Gradient norm: 3.05310024
INFO:root:At the start of the epoch: mem (CPU python)=5191.97265625MB; mem (CPU total)=16380.25390625MB
INFO:root:[   38] Training loss: 0.23315299, Validation loss: 0.45597470, Gradient norm: 3.08936038
INFO:root:At the start of the epoch: mem (CPU python)=5213.1328125MB; mem (CPU total)=16430.19921875MB
INFO:root:[   39] Training loss: 0.23161549, Validation loss: 0.44949563, Gradient norm: 3.17463126
INFO:root:At the start of the epoch: mem (CPU python)=5234.30078125MB; mem (CPU total)=16486.56640625MB
INFO:root:[   40] Training loss: 0.22748205, Validation loss: 0.46044031, Gradient norm: 3.11231051
INFO:root:At the start of the epoch: mem (CPU python)=5255.46484375MB; mem (CPU total)=16537.24609375MB
INFO:root:[   41] Training loss: 0.22676212, Validation loss: 0.45511483, Gradient norm: 3.27507032
INFO:root:At the start of the epoch: mem (CPU python)=5276.62890625MB; mem (CPU total)=16592.88671875MB
INFO:root:[   42] Training loss: 0.22468325, Validation loss: 0.46022976, Gradient norm: 3.26737382
INFO:root:At the start of the epoch: mem (CPU python)=5297.7890625MB; mem (CPU total)=16644.37890625MB
INFO:root:[   43] Training loss: 0.22220980, Validation loss: 0.45475241, Gradient norm: 3.20772204
INFO:root:At the start of the epoch: mem (CPU python)=5318.953125MB; mem (CPU total)=16699.52734375MB
INFO:root:[   44] Training loss: 0.22150296, Validation loss: 0.46254627, Gradient norm: 3.37713415
INFO:root:At the start of the epoch: mem (CPU python)=5340.12109375MB; mem (CPU total)=16751.46875MB
INFO:root:[   45] Training loss: 0.22079439, Validation loss: 0.45374736, Gradient norm: 3.35706511
INFO:root:At the start of the epoch: mem (CPU python)=5361.28515625MB; mem (CPU total)=16804.83203125MB
INFO:root:[   46] Training loss: 0.21688279, Validation loss: 0.45198532, Gradient norm: 3.25142916
INFO:root:At the start of the epoch: mem (CPU python)=5382.9140625MB; mem (CPU total)=16860.3984375MB
INFO:root:[   47] Training loss: 0.21584295, Validation loss: 0.47646286, Gradient norm: 3.34538958
INFO:root:At the start of the epoch: mem (CPU python)=5404.375MB; mem (CPU total)=16912.9921875MB
INFO:root:[   48] Training loss: 0.21195895, Validation loss: 0.44436943, Gradient norm: 3.30869019
INFO:root:At the start of the epoch: mem (CPU python)=5426.16796875MB; mem (CPU total)=16968.36328125MB
INFO:root:[   49] Training loss: 0.21066414, Validation loss: 0.45310076, Gradient norm: 3.34036889
INFO:root:At the start of the epoch: mem (CPU python)=5447.3515625MB; mem (CPU total)=17019.86328125MB
INFO:root:[   50] Training loss: 0.21051106, Validation loss: 0.44688666, Gradient norm: 3.37530819
INFO:root:At the start of the epoch: mem (CPU python)=5468.5234375MB; mem (CPU total)=17074.5703125MB
INFO:root:[   51] Training loss: 0.20691875, Validation loss: 0.45456510, Gradient norm: 3.35287914
INFO:root:At the start of the epoch: mem (CPU python)=5489.6953125MB; mem (CPU total)=17126.93359375MB
INFO:root:[   52] Training loss: 0.20590210, Validation loss: 0.44651268, Gradient norm: 3.39809489
INFO:root:At the start of the epoch: mem (CPU python)=5510.875MB; mem (CPU total)=17181.18359375MB
INFO:root:[   53] Training loss: 0.20394171, Validation loss: 0.45744186, Gradient norm: 3.32404232
INFO:root:At the start of the epoch: mem (CPU python)=5532.07421875MB; mem (CPU total)=17232.8984375MB
INFO:root:[   54] Training loss: 0.20373823, Validation loss: 0.45836979, Gradient norm: 3.36157779
INFO:root:At the start of the epoch: mem (CPU python)=5553.24609375MB; mem (CPU total)=17288.09375MB
INFO:root:[   55] Training loss: 0.20302625, Validation loss: 0.44239512, Gradient norm: 3.45764122
INFO:root:At the start of the epoch: mem (CPU python)=5574.421875MB; mem (CPU total)=17341.59375MB
INFO:root:[   56] Training loss: 0.20242298, Validation loss: 0.45537146, Gradient norm: 3.40088143
INFO:root:At the start of the epoch: mem (CPU python)=5595.59765625MB; mem (CPU total)=17396.23046875MB
INFO:root:[   57] Training loss: 0.19857417, Validation loss: 0.45244071, Gradient norm: 3.30736354
INFO:root:At the start of the epoch: mem (CPU python)=5616.78125MB; mem (CPU total)=17448.09765625MB
INFO:root:[   58] Training loss: 0.19994557, Validation loss: 0.46481190, Gradient norm: 3.44067436
INFO:root:At the start of the epoch: mem (CPU python)=5637.96484375MB; mem (CPU total)=17502.875MB
INFO:root:[   59] Training loss: 0.20107599, Validation loss: 0.44144981, Gradient norm: 3.47274306
INFO:root:At the start of the epoch: mem (CPU python)=5659.15625MB; mem (CPU total)=17554.33203125MB
INFO:root:[   60] Training loss: 0.19886931, Validation loss: 0.45596733, Gradient norm: 3.40514670
INFO:root:At the start of the epoch: mem (CPU python)=5680.32421875MB; mem (CPU total)=17608.609375MB
INFO:root:[   61] Training loss: 0.19899263, Validation loss: 0.47486118, Gradient norm: 3.40135433
INFO:root:At the start of the epoch: mem (CPU python)=5701.5078125MB; mem (CPU total)=17660.515625MB
INFO:root:[   62] Training loss: 0.19875687, Validation loss: 0.45472860, Gradient norm: 3.40039717
INFO:root:At the start of the epoch: mem (CPU python)=5722.6796875MB; mem (CPU total)=17714.984375MB
INFO:root:[   63] Training loss: 0.19489680, Validation loss: 0.47314203, Gradient norm: 3.40412447
INFO:root:At the start of the epoch: mem (CPU python)=5743.85546875MB; mem (CPU total)=17766.46484375MB
INFO:root:[   64] Training loss: 0.19579776, Validation loss: 0.45379128, Gradient norm: 3.40362523
INFO:root:At the start of the epoch: mem (CPU python)=5765.01953125MB; mem (CPU total)=17820.921875MB
INFO:root:[   65] Training loss: 0.19467753, Validation loss: 0.44738882, Gradient norm: 3.38769390
INFO:root:At the start of the epoch: mem (CPU python)=5786.1953125MB; mem (CPU total)=17872.66796875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   66] Training loss: 0.19459420, Validation loss: 0.47173896, Gradient norm: 3.34822514
INFO:root:At the start of the epoch: mem (CPU python)=5807.37890625MB; mem (CPU total)=17927.34375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   67] Training loss: 0.17918132, Validation loss: 0.42095238, Gradient norm: 2.65041408
INFO:root:At the start of the epoch: mem (CPU python)=5828.5625MB; mem (CPU total)=17978.98828125MB
INFO:root:[   68] Training loss: 0.17225336, Validation loss: 0.43553379, Gradient norm: 2.29390012
INFO:root:At the start of the epoch: mem (CPU python)=5849.7421875MB; mem (CPU total)=18033.12109375MB
INFO:root:[   69] Training loss: 0.17174242, Validation loss: 0.42523257, Gradient norm: 2.95542493
INFO:root:At the start of the epoch: mem (CPU python)=5870.91796875MB; mem (CPU total)=18084.4140625MB
INFO:root:[   70] Training loss: 0.17021840, Validation loss: 0.42205052, Gradient norm: 3.00035702
INFO:root:At the start of the epoch: mem (CPU python)=5892.08203125MB; mem (CPU total)=18138.93359375MB
INFO:root:[   71] Training loss: 0.17149154, Validation loss: 0.41904854, Gradient norm: 3.97194556
INFO:root:At the start of the epoch: mem (CPU python)=5913.265625MB; mem (CPU total)=18177.3203125MB
INFO:root:[   72] Training loss: 0.17186209, Validation loss: 0.43209449, Gradient norm: 4.43577987
INFO:root:At the start of the epoch: mem (CPU python)=5934.4296875MB; mem (CPU total)=18200.4453125MB
INFO:root:[   73] Training loss: 0.17075767, Validation loss: 0.43054410, Gradient norm: 4.18366542
INFO:root:At the start of the epoch: mem (CPU python)=5955.59765625MB; mem (CPU total)=18224.33203125MB
INFO:root:[   74] Training loss: 0.17085601, Validation loss: 0.43558664, Gradient norm: 5.10295352
INFO:root:At the start of the epoch: mem (CPU python)=5976.77734375MB; mem (CPU total)=18248.0625MB
INFO:root:[   75] Training loss: 0.17164547, Validation loss: 0.42959574, Gradient norm: 5.51497915
INFO:root:At the start of the epoch: mem (CPU python)=5997.9296875MB; mem (CPU total)=18271.41796875MB
INFO:root:[   76] Training loss: 0.17062701, Validation loss: 0.43874219, Gradient norm: 5.10146094
INFO:root:At the start of the epoch: mem (CPU python)=6019.09375MB; mem (CPU total)=18295.02734375MB
INFO:root:[   77] Training loss: 0.17171684, Validation loss: 0.43168275, Gradient norm: 5.99061299
INFO:root:At the start of the epoch: mem (CPU python)=6040.2578125MB; mem (CPU total)=18318.66796875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   78] Training loss: 0.17129755, Validation loss: 0.42882743, Gradient norm: 6.07813355
INFO:root:At the start of the epoch: mem (CPU python)=6061.42578125MB; mem (CPU total)=18342.78125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   79] Training loss: 0.16740630, Validation loss: 0.42632559, Gradient norm: 4.78548671
INFO:root:At the start of the epoch: mem (CPU python)=6082.5859375MB; mem (CPU total)=18366.27734375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   80] Training loss: 0.16444691, Validation loss: 0.43521768, Gradient norm: 3.50232958
INFO:root:At the start of the epoch: mem (CPU python)=6103.75MB; mem (CPU total)=18388.41015625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:EP 80: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=6124.91015625MB; mem (CPU total)=18410.5859375MB
INFO:root:Training the model took 5546.9s.
INFO:root:Emptying the cuda cache took 0.066s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.40956
INFO:root:EnergyScoreValidation: 0.30302
INFO:root:CRPSValidation: 0.16367
INFO:root:Gaussian NLLValidation: 21544738630.78166
INFO:root:CoverageValidation: 0.08498
INFO:root:IntervalWidthValidation: 0.14234
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.44928
INFO:root:EnergyScoreTest: 0.33772
INFO:root:CRPSTest: 0.17776
INFO:root:Gaussian NLLTest: 25266941460.48001
INFO:root:CoverageTest: 0.08398
INFO:root:IntervalWidthTest: 0.14197
INFO:root:After validation: mem (CPU python)=6142.54296875MB; mem (CPU total)=18712.77734375MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=6142.54296875MB; mem (CPU total)=18714.49609375MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 65011712
INFO:root:After setting up the model: mem (CPU python)=6142.546875MB; mem (CPU total)=18714.49609375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=6142.546875MB; mem (CPU total)=18715.97265625MB
INFO:root:[    1] Training loss: 0.53840746, Validation loss: 0.50735973, Gradient norm: 0.29923983
INFO:root:At the start of the epoch: mem (CPU python)=6176.69921875MB; mem (CPU total)=18794.75MB
INFO:root:[    2] Training loss: 0.47466567, Validation loss: 0.42735256, Gradient norm: 0.32574420
INFO:root:At the start of the epoch: mem (CPU python)=6198.15234375MB; mem (CPU total)=18859.98828125MB
INFO:root:[    3] Training loss: 0.39985249, Validation loss: 0.38364910, Gradient norm: 0.43114061
INFO:root:At the start of the epoch: mem (CPU python)=6219.3359375MB; mem (CPU total)=18927.66015625MB
INFO:root:[    4] Training loss: 0.35914033, Validation loss: 0.34529617, Gradient norm: 0.49403927
INFO:root:At the start of the epoch: mem (CPU python)=6240.51171875MB; mem (CPU total)=18992.11328125MB
INFO:root:[    5] Training loss: 0.33286499, Validation loss: 0.32430369, Gradient norm: 0.57142868
INFO:root:At the start of the epoch: mem (CPU python)=6261.67578125MB; mem (CPU total)=19055.578125MB
INFO:root:[    6] Training loss: 0.30879468, Validation loss: 0.31029525, Gradient norm: 0.60730568
INFO:root:At the start of the epoch: mem (CPU python)=6282.84375MB; mem (CPU total)=19119.2109375MB
INFO:root:[    7] Training loss: 0.29119729, Validation loss: 0.29601001, Gradient norm: 0.65242810
INFO:root:At the start of the epoch: mem (CPU python)=6304.99609375MB; mem (CPU total)=19183.63671875MB
INFO:root:[    8] Training loss: 0.27948586, Validation loss: 0.29194798, Gradient norm: 0.69483611
INFO:root:At the start of the epoch: mem (CPU python)=6330.796875MB; mem (CPU total)=19253.75MB
INFO:root:[    9] Training loss: 0.27033783, Validation loss: 0.29380191, Gradient norm: 0.71448234
INFO:root:At the start of the epoch: mem (CPU python)=6351.95703125MB; mem (CPU total)=19319.19921875MB
INFO:root:[   10] Training loss: 0.26463415, Validation loss: 0.28639639, Gradient norm: 0.73950869
INFO:root:At the start of the epoch: mem (CPU python)=6373.125MB; mem (CPU total)=19384.87890625MB
INFO:root:[   11] Training loss: 0.25922232, Validation loss: 0.29159541, Gradient norm: 0.74729912
INFO:root:At the start of the epoch: mem (CPU python)=6394.28125MB; mem (CPU total)=19450.234375MB
INFO:root:[   12] Training loss: 0.25530175, Validation loss: 0.29220632, Gradient norm: 0.77127792
INFO:root:At the start of the epoch: mem (CPU python)=6415.44921875MB; mem (CPU total)=19516.09375MB
INFO:root:[   13] Training loss: 0.25234535, Validation loss: 0.28356282, Gradient norm: 0.82466668
INFO:root:At the start of the epoch: mem (CPU python)=6436.61328125MB; mem (CPU total)=19581.296875MB
INFO:root:[   14] Training loss: 0.25085166, Validation loss: 0.27761913, Gradient norm: 0.86830349
INFO:root:At the start of the epoch: mem (CPU python)=6457.77734375MB; mem (CPU total)=19647.0MB
INFO:root:[   15] Training loss: 0.24746663, Validation loss: 0.29198832, Gradient norm: 0.90973105
INFO:root:At the start of the epoch: mem (CPU python)=6478.94140625MB; mem (CPU total)=19712.0859375MB
INFO:root:[   16] Training loss: 0.24600833, Validation loss: 0.28319306, Gradient norm: 0.98234962
INFO:root:At the start of the epoch: mem (CPU python)=6500.10546875MB; mem (CPU total)=19776.58203125MB
INFO:root:[   17] Training loss: 0.24378774, Validation loss: 0.28415125, Gradient norm: 1.08443586
INFO:root:At the start of the epoch: mem (CPU python)=6521.2734375MB; mem (CPU total)=19842.3359375MB
INFO:root:[   18] Training loss: 0.24231562, Validation loss: 0.30125447, Gradient norm: 1.15911916
INFO:root:At the start of the epoch: mem (CPU python)=6542.4375MB; mem (CPU total)=19907.9375MB
INFO:root:[   19] Training loss: 0.23952483, Validation loss: 0.28389748, Gradient norm: 1.25356195
INFO:root:At the start of the epoch: mem (CPU python)=6563.6015625MB; mem (CPU total)=19971.85546875MB
INFO:root:[   20] Training loss: 0.23910869, Validation loss: 0.28734204, Gradient norm: 1.37150471
INFO:root:At the start of the epoch: mem (CPU python)=6584.76171875MB; mem (CPU total)=20035.64453125MB
INFO:root:[   21] Training loss: 0.23836263, Validation loss: 0.28024427, Gradient norm: 1.47402546
INFO:root:At the start of the epoch: mem (CPU python)=6605.92578125MB; mem (CPU total)=20099.3671875MB
INFO:root:[   22] Training loss: 0.23804326, Validation loss: 0.29275242, Gradient norm: 1.65354421
INFO:root:At the start of the epoch: mem (CPU python)=6627.08984375MB; mem (CPU total)=20162.8515625MB
INFO:root:[   23] Training loss: 0.23710489, Validation loss: 0.29267405, Gradient norm: 1.81743655
INFO:root:At the start of the epoch: mem (CPU python)=6648.25390625MB; mem (CPU total)=20226.5625MB
INFO:root:[   24] Training loss: 0.23599954, Validation loss: 0.32268061, Gradient norm: 1.89174926
INFO:root:At the start of the epoch: mem (CPU python)=6673.35546875MB; mem (CPU total)=20294.73046875MB
INFO:root:[   25] Training loss: 0.23645550, Validation loss: 0.30680390, Gradient norm: 1.98878899
INFO:root:At the start of the epoch: mem (CPU python)=6694.70703125MB; mem (CPU total)=20357.69140625MB
INFO:root:[   26] Training loss: 0.23395138, Validation loss: 0.31604668, Gradient norm: 2.07129264
INFO:root:At the start of the epoch: mem (CPU python)=6715.87109375MB; mem (CPU total)=20421.375MB
INFO:root:[   27] Training loss: 0.23610290, Validation loss: 0.31831083, Gradient norm: 2.13366131
INFO:root:At the start of the epoch: mem (CPU python)=6737.03515625MB; mem (CPU total)=20485.14453125MB
INFO:root:[   28] Training loss: 0.23347877, Validation loss: 0.30714526, Gradient norm: 2.27146144
INFO:root:At the start of the epoch: mem (CPU python)=6758.203125MB; mem (CPU total)=20549.3515625MB
INFO:root:[   29] Training loss: 0.23440481, Validation loss: 0.33071631, Gradient norm: 2.39044014
INFO:root:At the start of the epoch: mem (CPU python)=6779.3671875MB; mem (CPU total)=20613.53515625MB
INFO:root:[   30] Training loss: 0.23524428, Validation loss: 0.33572825, Gradient norm: 2.32881799
INFO:root:At the start of the epoch: mem (CPU python)=6800.53125MB; mem (CPU total)=20677.76171875MB
INFO:root:[   31] Training loss: 0.23229680, Validation loss: 0.34880284, Gradient norm: 2.48920025
INFO:root:At the start of the epoch: mem (CPU python)=6821.6953125MB; mem (CPU total)=20741.51171875MB
INFO:root:[   32] Training loss: 0.23006861, Validation loss: 0.38513115, Gradient norm: 2.45646600
INFO:root:At the start of the epoch: mem (CPU python)=6842.859375MB; mem (CPU total)=20805.44140625MB
INFO:root:[   33] Training loss: 0.23035869, Validation loss: 0.38073130, Gradient norm: 2.57343927
INFO:root:At the start of the epoch: mem (CPU python)=6864.0234375MB; mem (CPU total)=20869.671875MB
INFO:root:[   34] Training loss: 0.23038501, Validation loss: 0.39944396, Gradient norm: 2.63693024
INFO:root:At the start of the epoch: mem (CPU python)=6885.1875MB; mem (CPU total)=20933.4296875MB
INFO:root:[   35] Training loss: 0.22973861, Validation loss: 0.40163777, Gradient norm: 2.71492271
INFO:root:At the start of the epoch: mem (CPU python)=6906.3515625MB; mem (CPU total)=20997.93359375MB
INFO:root:[   36] Training loss: 0.23359885, Validation loss: 0.42095042, Gradient norm: 2.81329726
INFO:root:At the start of the epoch: mem (CPU python)=6927.51953125MB; mem (CPU total)=21063.5MB
INFO:root:[   37] Training loss: 0.23068204, Validation loss: 0.40322715, Gradient norm: 2.65781285
INFO:root:At the start of the epoch: mem (CPU python)=6948.68359375MB; mem (CPU total)=21126.52734375MB
INFO:root:[   38] Training loss: 0.22932677, Validation loss: 0.41004951, Gradient norm: 2.81041250
INFO:root:At the start of the epoch: mem (CPU python)=6969.84765625MB; mem (CPU total)=21192.625MB
INFO:root:[   39] Training loss: 0.22984522, Validation loss: 0.38831257, Gradient norm: 2.68954015
INFO:root:At the start of the epoch: mem (CPU python)=6991.0078125MB; mem (CPU total)=21256.40234375MB
INFO:root:[   40] Training loss: 0.22683103, Validation loss: 0.38664740, Gradient norm: 2.83972848
INFO:root:At the start of the epoch: mem (CPU python)=7012.171875MB; mem (CPU total)=21319.125MB
INFO:root:[   41] Training loss: 0.22676074, Validation loss: 0.40457033, Gradient norm: 2.88773368
INFO:root:At the start of the epoch: mem (CPU python)=7033.3359375MB; mem (CPU total)=21382.48046875MB
INFO:root:[   42] Training loss: 0.22593508, Validation loss: 0.38139073, Gradient norm: 2.88750368
INFO:root:At the start of the epoch: mem (CPU python)=7054.625MB; mem (CPU total)=21445.9375MB
INFO:root:[   43] Training loss: 0.22811686, Validation loss: 0.39352593, Gradient norm: 2.88291249
INFO:root:At the start of the epoch: mem (CPU python)=7076.0390625MB; mem (CPU total)=21509.43359375MB
INFO:root:[   44] Training loss: 0.22437612, Validation loss: 0.39005573, Gradient norm: 2.94575892
INFO:root:At the start of the epoch: mem (CPU python)=7097.203125MB; mem (CPU total)=21572.99609375MB
INFO:root:[   45] Training loss: 0.22417542, Validation loss: 0.40796106, Gradient norm: 2.92618883
INFO:root:At the start of the epoch: mem (CPU python)=7118.3671875MB; mem (CPU total)=21636.48828125MB
INFO:root:[   46] Training loss: 0.22543101, Validation loss: 0.39239982, Gradient norm: 2.96647517
INFO:root:At the start of the epoch: mem (CPU python)=7141.359375MB; mem (CPU total)=21701.69921875MB
INFO:root:[   47] Training loss: 0.22399627, Validation loss: 0.39989423, Gradient norm: 2.97710152
INFO:root:At the start of the epoch: mem (CPU python)=7162.5703125MB; mem (CPU total)=21764.94140625MB
INFO:root:[   48] Training loss: 0.22272634, Validation loss: 0.42488512, Gradient norm: 3.01736633
INFO:root:At the start of the epoch: mem (CPU python)=7183.73828125MB; mem (CPU total)=21828.4140625MB
INFO:root:[   49] Training loss: 0.22325932, Validation loss: 0.39638673, Gradient norm: 2.96730648
INFO:root:At the start of the epoch: mem (CPU python)=7204.8984375MB; mem (CPU total)=21891.609375MB
INFO:root:[   50] Training loss: 0.22266697, Validation loss: 0.38966232, Gradient norm: 3.15516421
INFO:root:At the start of the epoch: mem (CPU python)=7226.0625MB; mem (CPU total)=21950.6953125MB
INFO:root:[   51] Training loss: 0.22231479, Validation loss: 0.41155377, Gradient norm: 3.10331833
INFO:root:At the start of the epoch: mem (CPU python)=7247.2265625MB; mem (CPU total)=21999.60546875MB
INFO:root:[   52] Training loss: 0.22041426, Validation loss: 0.38667152, Gradient norm: 3.20160680
INFO:root:At the start of the epoch: mem (CPU python)=7268.390625MB; mem (CPU total)=22054.50390625MB
INFO:root:[   53] Training loss: 0.22044251, Validation loss: 0.40217323, Gradient norm: 3.16565316
INFO:root:At the start of the epoch: mem (CPU python)=7289.55859375MB; mem (CPU total)=22101.64453125MB
INFO:root:[   54] Training loss: 0.22123588, Validation loss: 0.39629639, Gradient norm: 3.28787850
INFO:root:At the start of the epoch: mem (CPU python)=7310.72265625MB; mem (CPU total)=22155.171875MB
INFO:root:[   55] Training loss: 0.22158523, Validation loss: 0.40868348, Gradient norm: 3.25742091
INFO:root:At the start of the epoch: mem (CPU python)=7331.88671875MB; mem (CPU total)=22204.421875MB
INFO:root:[   56] Training loss: 0.21976844, Validation loss: 0.40543369, Gradient norm: 3.34014934
INFO:root:At the start of the epoch: mem (CPU python)=7353.05078125MB; mem (CPU total)=22258.28125MB
INFO:root:[   57] Training loss: 0.22073990, Validation loss: 0.40153313, Gradient norm: 3.37055670
INFO:root:At the start of the epoch: mem (CPU python)=7374.21484375MB; mem (CPU total)=22310.70703125MB
INFO:root:[   58] Training loss: 0.21871952, Validation loss: 0.39785867, Gradient norm: 3.39384470
INFO:root:At the start of the epoch: mem (CPU python)=7395.375MB; mem (CPU total)=22360.69140625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   59] Training loss: 0.21887781, Validation loss: 0.39742994, Gradient norm: 3.53749936
INFO:root:At the start of the epoch: mem (CPU python)=7416.5390625MB; mem (CPU total)=22416.046875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   60] Training loss: 0.20124013, Validation loss: 0.37825872, Gradient norm: 2.72573278
INFO:root:At the start of the epoch: mem (CPU python)=7437.703125MB; mem (CPU total)=22463.81640625MB
INFO:root:[   61] Training loss: 0.19084783, Validation loss: 0.37696360, Gradient norm: 2.49208973
INFO:root:At the start of the epoch: mem (CPU python)=7458.8671875MB; mem (CPU total)=22517.015625MB
INFO:root:[   62] Training loss: 0.18940608, Validation loss: 0.37244822, Gradient norm: 2.65672352
INFO:root:At the start of the epoch: mem (CPU python)=7480.03125MB; mem (CPU total)=22565.875MB
INFO:root:[   63] Training loss: 0.18869655, Validation loss: 0.38167531, Gradient norm: 3.15521163
INFO:root:At the start of the epoch: mem (CPU python)=7501.1953125MB; mem (CPU total)=22620.2578125MB
INFO:root:[   64] Training loss: 0.18796353, Validation loss: 0.36222706, Gradient norm: 3.16813508
INFO:root:At the start of the epoch: mem (CPU python)=7522.36328125MB; mem (CPU total)=22669.98046875MB
INFO:root:[   65] Training loss: 0.18837568, Validation loss: 0.36350060, Gradient norm: 3.92469684
INFO:root:At the start of the epoch: mem (CPU python)=7543.52734375MB; mem (CPU total)=22723.1171875MB
INFO:root:[   66] Training loss: 0.18811131, Validation loss: 0.36444987, Gradient norm: 3.75571734
INFO:root:At the start of the epoch: mem (CPU python)=7564.69140625MB; mem (CPU total)=22776.2421875MB
INFO:root:[   67] Training loss: 0.18758287, Validation loss: 0.36810812, Gradient norm: 4.12646851
INFO:root:At the start of the epoch: mem (CPU python)=7585.8515625MB; mem (CPU total)=22825.65234375MB
INFO:root:[   68] Training loss: 0.18828297, Validation loss: 0.37252960, Gradient norm: 4.90709161
INFO:root:At the start of the epoch: mem (CPU python)=7607.015625MB; mem (CPU total)=22880.7109375MB
INFO:root:[   69] Training loss: 0.18811736, Validation loss: 0.36682783, Gradient norm: 4.45769870
INFO:root:At the start of the epoch: mem (CPU python)=7628.1796875MB; mem (CPU total)=22927.953125MB
INFO:root:[   70] Training loss: 0.18809390, Validation loss: 0.37118485, Gradient norm: 4.89568351
INFO:root:At the start of the epoch: mem (CPU python)=7649.3515625MB; mem (CPU total)=22981.65234375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   71] Training loss: 0.18888815, Validation loss: 0.36957308, Gradient norm: 5.67054790
INFO:root:At the start of the epoch: mem (CPU python)=7670.515625MB; mem (CPU total)=23030.5703125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   72] Training loss: 0.18336065, Validation loss: 0.36229856, Gradient norm: 4.07402768
INFO:root:At the start of the epoch: mem (CPU python)=7691.6796875MB; mem (CPU total)=23084.80859375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   73] Training loss: 0.17977129, Validation loss: 0.35585418, Gradient norm: 3.34157238
INFO:root:At the start of the epoch: mem (CPU python)=7712.84375MB; mem (CPU total)=23136.48046875MB
INFO:root:[   74] Training loss: 0.17808478, Validation loss: 0.35468780, Gradient norm: 2.82091273
INFO:root:At the start of the epoch: mem (CPU python)=7734.0078125MB; mem (CPU total)=23186.43359375MB
INFO:root:[   75] Training loss: 0.17770397, Validation loss: 0.35479677, Gradient norm: 2.84420504
INFO:root:At the start of the epoch: mem (CPU python)=7755.171875MB; mem (CPU total)=23242.03515625MB
INFO:root:[   76] Training loss: 0.17718838, Validation loss: 0.35671271, Gradient norm: 3.03596421
INFO:root:At the start of the epoch: mem (CPU python)=7776.3359375MB; mem (CPU total)=23289.19140625MB
INFO:root:[   77] Training loss: 0.17740908, Validation loss: 0.35613293, Gradient norm: 3.43795171
INFO:root:At the start of the epoch: mem (CPU python)=7797.49609375MB; mem (CPU total)=23342.81640625MB
INFO:root:[   78] Training loss: 0.17736369, Validation loss: 0.35677742, Gradient norm: 3.38105160
INFO:root:At the start of the epoch: mem (CPU python)=7818.66015625MB; mem (CPU total)=23391.9921875MB
INFO:root:[   79] Training loss: 0.17748543, Validation loss: 0.35637069, Gradient norm: 3.59233033
INFO:root:At the start of the epoch: mem (CPU python)=7839.82421875MB; mem (CPU total)=23444.95703125MB
INFO:root:[   80] Training loss: 0.17733380, Validation loss: 0.35187228, Gradient norm: 3.57387393
INFO:root:At the start of the epoch: mem (CPU python)=7860.98828125MB; mem (CPU total)=23497.15625MB
INFO:root:[   81] Training loss: 0.17718204, Validation loss: 0.35235184, Gradient norm: 3.86056624
INFO:root:At the start of the epoch: mem (CPU python)=7882.15234375MB; mem (CPU total)=23547.859375MB
INFO:root:[   82] Training loss: 0.17745822, Validation loss: 0.35237046, Gradient norm: 3.97127315
INFO:root:At the start of the epoch: mem (CPU python)=7903.3203125MB; mem (CPU total)=23603.0234375MB
INFO:root:[   83] Training loss: 0.17727158, Validation loss: 0.35615374, Gradient norm: 3.91390423
INFO:root:At the start of the epoch: mem (CPU python)=7924.484375MB; mem (CPU total)=23650.57421875MB
INFO:root:[   84] Training loss: 0.17753704, Validation loss: 0.35420371, Gradient norm: 4.14990413
INFO:root:At the start of the epoch: mem (CPU python)=7945.6484375MB; mem (CPU total)=23703.921875MB
INFO:root:[   85] Training loss: 0.17734709, Validation loss: 0.35582695, Gradient norm: 4.24420660
INFO:root:At the start of the epoch: mem (CPU python)=7966.8125MB; mem (CPU total)=23752.453125MB
INFO:root:[   86] Training loss: 0.17762209, Validation loss: 0.35508020, Gradient norm: 4.41494820
INFO:root:At the start of the epoch: mem (CPU python)=7987.97265625MB; mem (CPU total)=23806.1640625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   87] Training loss: 0.17806089, Validation loss: 0.35239376, Gradient norm: 4.47027088
INFO:root:At the start of the epoch: mem (CPU python)=8009.140625MB; mem (CPU total)=23857.5703125MB
INFO:root:[   88] Training loss: 0.17717775, Validation loss: 0.35285119, Gradient norm: 3.88908747
INFO:root:At the start of the epoch: mem (CPU python)=8030.3046875MB; mem (CPU total)=23908.4921875MB
INFO:root:[   89] Training loss: 0.17739491, Validation loss: 0.35227218, Gradient norm: 4.19393744
INFO:root:At the start of the epoch: mem (CPU python)=8051.46875MB; mem (CPU total)=23963.64453125MB
INFO:root:EP 89: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=8072.6328125MB; mem (CPU total)=24009.58203125MB
INFO:root:Training the model took 6229.35s.
INFO:root:Emptying the cuda cache took 0.067s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.38369
INFO:root:EnergyScoreValidation: 0.27756
INFO:root:CRPSValidation: 0.15075
INFO:root:Gaussian NLLValidation: 15621450832.03942
INFO:root:CoverageValidation: 0.0952
INFO:root:IntervalWidthValidation: 0.15806
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.40815
INFO:root:EnergyScoreTest: 0.29717
INFO:root:CRPSTest: 0.16392
INFO:root:Gaussian NLLTest: 17707855245.312
INFO:root:CoverageTest: 0.09473
INFO:root:IntervalWidthTest: 0.16101
INFO:root:After validation: mem (CPU python)=8079.5MB; mem (CPU total)=24309.03125MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=8079.5MB; mem (CPU total)=24312.6875MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 65011712
INFO:root:After setting up the model: mem (CPU python)=8079.5MB; mem (CPU total)=24312.6875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=8079.5MB; mem (CPU total)=24312.94921875MB
INFO:root:[    1] Training loss: 0.53576407, Validation loss: 0.50486252, Gradient norm: 0.32790127
INFO:root:At the start of the epoch: mem (CPU python)=8100.3046875MB; mem (CPU total)=24335.80859375MB
INFO:root:[    2] Training loss: 0.47594938, Validation loss: 0.41893217, Gradient norm: 0.33617919
INFO:root:At the start of the epoch: mem (CPU python)=8121.484375MB; mem (CPU total)=24360.20703125MB
INFO:root:[    3] Training loss: 0.39220906, Validation loss: 0.37160767, Gradient norm: 0.46890473
INFO:root:At the start of the epoch: mem (CPU python)=8142.65625MB; mem (CPU total)=24384.859375MB
INFO:root:[    4] Training loss: 0.35555050, Validation loss: 0.34105204, Gradient norm: 0.47809591
INFO:root:At the start of the epoch: mem (CPU python)=8163.82421875MB; mem (CPU total)=24409.26953125MB
INFO:root:[    5] Training loss: 0.32572510, Validation loss: 0.31560085, Gradient norm: 0.56230629
INFO:root:At the start of the epoch: mem (CPU python)=8184.98828125MB; mem (CPU total)=24431.96875MB
INFO:root:[    6] Training loss: 0.30343008, Validation loss: 0.29589829, Gradient norm: 0.64092861
INFO:root:At the start of the epoch: mem (CPU python)=8206.15234375MB; mem (CPU total)=24454.63671875MB
INFO:root:[    7] Training loss: 0.29053622, Validation loss: 0.29258958, Gradient norm: 0.68091150
INFO:root:At the start of the epoch: mem (CPU python)=8227.31640625MB; mem (CPU total)=24480.0234375MB
INFO:root:[    8] Training loss: 0.28084191, Validation loss: 0.28593687, Gradient norm: 0.68179211
INFO:root:At the start of the epoch: mem (CPU python)=8248.484375MB; mem (CPU total)=24502.0078125MB
INFO:root:[    9] Training loss: 0.27279420, Validation loss: 0.27626346, Gradient norm: 0.68587561
INFO:root:At the start of the epoch: mem (CPU python)=8269.6484375MB; mem (CPU total)=24523.12109375MB
INFO:root:[   10] Training loss: 0.26647512, Validation loss: 0.27886332, Gradient norm: 0.73896151
INFO:root:At the start of the epoch: mem (CPU python)=8290.8046875MB; mem (CPU total)=24545.6640625MB
INFO:root:[   11] Training loss: 0.26041542, Validation loss: 0.27871999, Gradient norm: 0.73823884
INFO:root:At the start of the epoch: mem (CPU python)=8311.97265625MB; mem (CPU total)=24567.79296875MB
INFO:root:[   12] Training loss: 0.25665471, Validation loss: 0.27230620, Gradient norm: 0.74514866
INFO:root:At the start of the epoch: mem (CPU python)=8333.13671875MB; mem (CPU total)=24589.81640625MB
INFO:root:[   13] Training loss: 0.25250273, Validation loss: 0.26184132, Gradient norm: 0.73969043
INFO:root:At the start of the epoch: mem (CPU python)=8354.30078125MB; mem (CPU total)=24613.0546875MB
INFO:root:[   14] Training loss: 0.24910419, Validation loss: 0.26896559, Gradient norm: 0.74163843
INFO:root:At the start of the epoch: mem (CPU python)=8375.46484375MB; mem (CPU total)=8363.4609375MB
INFO:root:[   15] Training loss: 0.24726902, Validation loss: 0.27718099, Gradient norm: 0.76336330
INFO:root:At the start of the epoch: mem (CPU python)=8396.62890625MB; mem (CPU total)=11695.92578125MB
INFO:root:[   16] Training loss: 0.24514190, Validation loss: 0.27570953, Gradient norm: 0.79053430
INFO:root:At the start of the epoch: mem (CPU python)=8417.79296875MB; mem (CPU total)=11781.12109375MB
INFO:root:[   17] Training loss: 0.24267558, Validation loss: 0.27982197, Gradient norm: 0.77242667
INFO:root:At the start of the epoch: mem (CPU python)=8438.95703125MB; mem (CPU total)=11868.1796875MB
INFO:root:[   18] Training loss: 0.24053450, Validation loss: 0.30779178, Gradient norm: 0.79583791
INFO:root:At the start of the epoch: mem (CPU python)=8460.12109375MB; mem (CPU total)=11954.26953125MB
INFO:root:[   19] Training loss: 0.23719340, Validation loss: 0.36692524, Gradient norm: 0.78195513
INFO:root:At the start of the epoch: mem (CPU python)=8481.28515625MB; mem (CPU total)=12041.46875MB
INFO:root:[   20] Training loss: 0.23358416, Validation loss: 0.37274647, Gradient norm: 0.81524927
INFO:root:At the start of the epoch: mem (CPU python)=8502.44921875MB; mem (CPU total)=12126.80078125MB
INFO:root:[   21] Training loss: 0.22786695, Validation loss: 0.37808190, Gradient norm: 0.79138882
INFO:root:At the start of the epoch: mem (CPU python)=8523.61328125MB; mem (CPU total)=12212.23046875MB
INFO:root:[   22] Training loss: 0.22415325, Validation loss: 0.37711022, Gradient norm: 0.79204826
INFO:root:At the start of the epoch: mem (CPU python)=8544.77734375MB; mem (CPU total)=12298.76171875MB
INFO:root:[   23] Training loss: 0.22024023, Validation loss: 0.38428349, Gradient norm: 0.82091794
INFO:root:At the start of the epoch: mem (CPU python)=8565.94140625MB; mem (CPU total)=12383.59375MB
INFO:root:[   24] Training loss: 0.21493909, Validation loss: 0.37374201, Gradient norm: 0.80009757
INFO:root:At the start of the epoch: mem (CPU python)=8587.10546875MB; mem (CPU total)=12468.75MB
INFO:root:[   25] Training loss: 0.21249352, Validation loss: 0.38556929, Gradient norm: 0.89273924
INFO:root:At the start of the epoch: mem (CPU python)=8608.26953125MB; mem (CPU total)=12553.34375MB
INFO:root:[   26] Training loss: 0.20844044, Validation loss: 0.38406964, Gradient norm: 0.82064363
INFO:root:At the start of the epoch: mem (CPU python)=8629.43359375MB; mem (CPU total)=12640.703125MB
INFO:root:[   27] Training loss: 0.20609550, Validation loss: 0.38234478, Gradient norm: 0.86797915
INFO:root:At the start of the epoch: mem (CPU python)=8650.59765625MB; mem (CPU total)=12726.34375MB
INFO:root:[   28] Training loss: 0.20317192, Validation loss: 0.39701130, Gradient norm: 0.87263070
INFO:root:At the start of the epoch: mem (CPU python)=8671.76171875MB; mem (CPU total)=12811.9921875MB
INFO:root:[   29] Training loss: 0.20147486, Validation loss: 0.39513264, Gradient norm: 0.87820724
INFO:root:At the start of the epoch: mem (CPU python)=8692.921875MB; mem (CPU total)=12896.74609375MB
INFO:root:[   30] Training loss: 0.19966770, Validation loss: 0.38924082, Gradient norm: 0.89956114
INFO:root:At the start of the epoch: mem (CPU python)=8714.08984375MB; mem (CPU total)=12985.11328125MB
INFO:root:[   31] Training loss: 0.19790529, Validation loss: 0.42213896, Gradient norm: 0.91934606
INFO:root:At the start of the epoch: mem (CPU python)=8735.25390625MB; mem (CPU total)=13068.99609375MB
INFO:root:[   32] Training loss: 0.19547790, Validation loss: 0.39898976, Gradient norm: 0.85054041
INFO:root:At the start of the epoch: mem (CPU python)=8756.41796875MB; mem (CPU total)=13152.6796875MB
INFO:root:[   33] Training loss: 0.19585306, Validation loss: 0.41136356, Gradient norm: 1.00592869
INFO:root:At the start of the epoch: mem (CPU python)=8777.58203125MB; mem (CPU total)=13236.953125MB
INFO:root:[   34] Training loss: 0.19256293, Validation loss: 0.41047975, Gradient norm: 0.89206359
INFO:root:At the start of the epoch: mem (CPU python)=8798.74609375MB; mem (CPU total)=13319.84375MB
INFO:root:[   35] Training loss: 0.19290542, Validation loss: 0.41167734, Gradient norm: 0.96120145
INFO:root:At the start of the epoch: mem (CPU python)=8819.9140625MB; mem (CPU total)=13403.96484375MB
INFO:root:[   36] Training loss: 0.19148845, Validation loss: 0.40569994, Gradient norm: 0.91721211
INFO:root:At the start of the epoch: mem (CPU python)=8841.078125MB; mem (CPU total)=13487.1171875MB
INFO:root:[   37] Training loss: 0.19031939, Validation loss: 0.41138029, Gradient norm: 0.98468458
INFO:root:At the start of the epoch: mem (CPU python)=8862.2421875MB; mem (CPU total)=13572.484375MB
INFO:root:[   38] Training loss: 0.18991235, Validation loss: 0.42731978, Gradient norm: 0.97484881
INFO:root:At the start of the epoch: mem (CPU python)=8883.40234375MB; mem (CPU total)=13659.125MB
INFO:root:[   39] Training loss: 0.18921925, Validation loss: 0.42686153, Gradient norm: 0.99026527
INFO:root:At the start of the epoch: mem (CPU python)=8904.56640625MB; mem (CPU total)=13741.31640625MB
INFO:root:[   40] Training loss: 0.18886226, Validation loss: 0.41824781, Gradient norm: 0.99770822
INFO:root:At the start of the epoch: mem (CPU python)=8925.73046875MB; mem (CPU total)=13823.83203125MB
INFO:root:[   41] Training loss: 0.18863191, Validation loss: 0.41536654, Gradient norm: 1.07559883
INFO:root:At the start of the epoch: mem (CPU python)=8946.89453125MB; mem (CPU total)=13908.01171875MB
INFO:root:[   42] Training loss: 0.18815293, Validation loss: 0.41740877, Gradient norm: 1.07222561
INFO:root:At the start of the epoch: mem (CPU python)=8968.05859375MB; mem (CPU total)=13990.0078125MB
INFO:root:[   43] Training loss: 0.18734655, Validation loss: 0.42209602, Gradient norm: 1.05011315
INFO:root:At the start of the epoch: mem (CPU python)=8989.22265625MB; mem (CPU total)=14073.42578125MB
INFO:root:[   44] Training loss: 0.18620401, Validation loss: 0.41355359, Gradient norm: 1.02535616
INFO:root:At the start of the epoch: mem (CPU python)=9010.38671875MB; mem (CPU total)=14155.0234375MB
INFO:root:[   45] Training loss: 0.18596971, Validation loss: 0.41846393, Gradient norm: 1.02018812
INFO:root:At the start of the epoch: mem (CPU python)=9031.55078125MB; mem (CPU total)=14236.9921875MB
INFO:root:[   46] Training loss: 0.18498232, Validation loss: 0.42597556, Gradient norm: 0.99657092
INFO:root:At the start of the epoch: mem (CPU python)=9052.71875MB; mem (CPU total)=14318.32421875MB
INFO:root:[   47] Training loss: 0.18486162, Validation loss: 0.42775032, Gradient norm: 1.05946787
INFO:root:At the start of the epoch: mem (CPU python)=9073.87890625MB; mem (CPU total)=14401.2421875MB
INFO:root:[   48] Training loss: 0.18389610, Validation loss: 0.42210900, Gradient norm: 1.01656671
INFO:root:At the start of the epoch: mem (CPU python)=9095.04296875MB; mem (CPU total)=14488.125MB
INFO:root:[   49] Training loss: 0.18404098, Validation loss: 0.42414286, Gradient norm: 1.03672390
INFO:root:At the start of the epoch: mem (CPU python)=9116.20703125MB; mem (CPU total)=14570.08984375MB
INFO:root:[   50] Training loss: 0.18475577, Validation loss: 0.43775331, Gradient norm: 1.13857049
INFO:root:At the start of the epoch: mem (CPU python)=9137.37109375MB; mem (CPU total)=14650.76171875MB
INFO:root:[   51] Training loss: 0.18335167, Validation loss: 0.41827712, Gradient norm: 1.06920853
INFO:root:At the start of the epoch: mem (CPU python)=9158.5390625MB; mem (CPU total)=14730.79296875MB
INFO:root:[   52] Training loss: 0.18255499, Validation loss: 0.43996675, Gradient norm: 1.04642613
INFO:root:At the start of the epoch: mem (CPU python)=9179.703125MB; mem (CPU total)=14812.25390625MB
INFO:root:[   53] Training loss: 0.18276135, Validation loss: 0.43367158, Gradient norm: 1.14114213
INFO:root:At the start of the epoch: mem (CPU python)=9200.87109375MB; mem (CPU total)=14894.69140625MB
INFO:root:[   54] Training loss: 0.18240659, Validation loss: 0.42757689, Gradient norm: 1.10264820
INFO:root:At the start of the epoch: mem (CPU python)=9222.03515625MB; mem (CPU total)=14960.5078125MB
INFO:root:[   55] Training loss: 0.18160625, Validation loss: 0.42155602, Gradient norm: 1.08380328
INFO:root:At the start of the epoch: mem (CPU python)=9243.19921875MB; mem (CPU total)=15021.5703125MB
INFO:root:[   56] Training loss: 0.18201395, Validation loss: 0.43224505, Gradient norm: 1.12942448
INFO:root:At the start of the epoch: mem (CPU python)=9264.36328125MB; mem (CPU total)=15079.87890625MB
INFO:root:[   57] Training loss: 0.18155405, Validation loss: 0.43200132, Gradient norm: 1.10976617
INFO:root:At the start of the epoch: mem (CPU python)=9285.5390625MB; mem (CPU total)=15139.66015625MB
INFO:root:[   58] Training loss: 0.18129360, Validation loss: 0.43139828, Gradient norm: 1.13901414
INFO:root:At the start of the epoch: mem (CPU python)=9306.703125MB; mem (CPU total)=15199.7265625MB
INFO:root:[   59] Training loss: 0.18111451, Validation loss: 0.43190811, Gradient norm: 1.13956731
INFO:root:At the start of the epoch: mem (CPU python)=9327.8671875MB; mem (CPU total)=15263.61328125MB
INFO:root:[   60] Training loss: 0.18129256, Validation loss: 0.43445701, Gradient norm: 1.14444588
INFO:root:At the start of the epoch: mem (CPU python)=9349.03125MB; mem (CPU total)=15324.01171875MB
INFO:root:[   61] Training loss: 0.18102064, Validation loss: 0.42955824, Gradient norm: 1.21966749
INFO:root:At the start of the epoch: mem (CPU python)=9370.1953125MB; mem (CPU total)=17579.6328125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   62] Training loss: 0.18110092, Validation loss: 0.42128066, Gradient norm: 1.18604353
INFO:root:At the start of the epoch: mem (CPU python)=9391.359375MB; mem (CPU total)=17650.80859375MB
INFO:root:[   63] Training loss: 0.17045817, Validation loss: 0.41531498, Gradient norm: 0.76060459
INFO:root:At the start of the epoch: mem (CPU python)=9412.5234375MB; mem (CPU total)=15752.81640625MB
INFO:root:[   64] Training loss: 0.17034503, Validation loss: 0.43716682, Gradient norm: 0.93356197
INFO:root:At the start of the epoch: mem (CPU python)=9433.69140625MB; mem (CPU total)=15560.984375MB
INFO:root:[   65] Training loss: 0.17053605, Validation loss: 0.41968765, Gradient norm: 1.01628348
INFO:root:At the start of the epoch: mem (CPU python)=9454.85546875MB; mem (CPU total)=15620.5078125MB
INFO:root:[   66] Training loss: 0.17060197, Validation loss: 0.41733341, Gradient norm: 1.09286915
INFO:root:At the start of the epoch: mem (CPU python)=9476.015625MB; mem (CPU total)=15681.0859375MB
INFO:root:[   67] Training loss: 0.17037184, Validation loss: 0.43362504, Gradient norm: 1.11830038
INFO:root:At the start of the epoch: mem (CPU python)=9497.1796875MB; mem (CPU total)=15750.29296875MB
INFO:root:[   68] Training loss: 0.17029140, Validation loss: 0.43226948, Gradient norm: 1.14721808
INFO:root:At the start of the epoch: mem (CPU python)=9518.34375MB; mem (CPU total)=16073.93359375MB
INFO:root:[   69] Training loss: 0.17086578, Validation loss: 0.41082261, Gradient norm: 1.28258312
INFO:root:At the start of the epoch: mem (CPU python)=9539.51171875MB; mem (CPU total)=16132.5078125MB
INFO:root:[   70] Training loss: 0.17117341, Validation loss: 0.41361405, Gradient norm: 1.35852210
INFO:root:At the start of the epoch: mem (CPU python)=9560.67578125MB; mem (CPU total)=16191.53125MB
INFO:root:[   71] Training loss: 0.17122255, Validation loss: 0.42829219, Gradient norm: 1.36204354
INFO:root:At the start of the epoch: mem (CPU python)=9581.83984375MB; mem (CPU total)=16250.6640625MB
INFO:root:[   72] Training loss: 0.17171017, Validation loss: 0.41582213, Gradient norm: 1.50561882
INFO:root:At the start of the epoch: mem (CPU python)=9603.00390625MB; mem (CPU total)=16310.46484375MB
INFO:root:[   73] Training loss: 0.17107829, Validation loss: 0.41916291, Gradient norm: 1.46688156
INFO:root:At the start of the epoch: mem (CPU python)=9624.16796875MB; mem (CPU total)=16369.76953125MB
INFO:root:[   74] Training loss: 0.17189753, Validation loss: 0.42561993, Gradient norm: 1.59458925
INFO:root:At the start of the epoch: mem (CPU python)=9645.33203125MB; mem (CPU total)=16429.625MB
INFO:root:[   75] Training loss: 0.17184935, Validation loss: 0.41508661, Gradient norm: 1.58676759
INFO:root:At the start of the epoch: mem (CPU python)=9666.49609375MB; mem (CPU total)=16488.95703125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   76] Training loss: 0.17155437, Validation loss: 0.43143109, Gradient norm: 1.68509251
INFO:root:At the start of the epoch: mem (CPU python)=9687.65625MB; mem (CPU total)=16547.8125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 0.16619707, Validation loss: 0.41864126, Gradient norm: 1.17340270
INFO:root:At the start of the epoch: mem (CPU python)=9708.8203125MB; mem (CPU total)=16607.39453125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 0.16374022, Validation loss: 0.41662443, Gradient norm: 0.99869313
INFO:root:At the start of the epoch: mem (CPU python)=9729.984375MB; mem (CPU total)=16666.53515625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:EP 78: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=9751.0234375MB; mem (CPU total)=16722.88671875MB
INFO:root:Training the model took 5706.503s.
INFO:root:Emptying the cuda cache took 0.068s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.36531
INFO:root:EnergyScoreValidation: 0.26184
INFO:root:CRPSValidation: 0.14363
INFO:root:Gaussian NLLValidation: 10899398879.85732
INFO:root:CoverageValidation: 0.19963
INFO:root:IntervalWidthValidation: 0.24182
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.38828
INFO:root:EnergyScoreTest: 0.27938
INFO:root:CRPSTest: 0.15404
INFO:root:Gaussian NLLTest: 12232494813.184
INFO:root:CoverageTest: 0.20286
INFO:root:IntervalWidthTest: 0.25284
INFO:root:After validation: mem (CPU python)=9755.76953125MB; mem (CPU total)=17066.48046875MB
