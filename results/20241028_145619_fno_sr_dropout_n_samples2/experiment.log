INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.20703125MB; mem (CPU total)=983.27734375MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12454.140625MB; mem (CPU total)=995.4375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.140625MB; mem (CPU total)=995.53515625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12454.140625MB; mem (CPU total)=2366.37890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=2380.234375MB
INFO:root:[    1] Training loss: 0.72542970, Validation loss: 0.72117178, Gradient norm: 0.01814071
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4118.1796875MB
INFO:root:[    2] Training loss: 0.72028238, Validation loss: 0.71932257, Gradient norm: 0.00546118
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4172.9921875MB
INFO:root:[    3] Training loss: 0.71902711, Validation loss: 0.71746348, Gradient norm: 0.00753384
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4218.7890625MB
INFO:root:[    4] Training loss: 0.71609800, Validation loss: 0.70969785, Gradient norm: 0.01619139
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4281.609375MB
INFO:root:[    5] Training loss: 0.71099852, Validation loss: 0.70442515, Gradient norm: 0.03027599
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4284.05859375MB
INFO:root:[    6] Training loss: 0.70724564, Validation loss: 0.70022888, Gradient norm: 0.04111438
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4402.69921875MB
INFO:root:[    7] Training loss: 0.70408192, Validation loss: 0.69617345, Gradient norm: 0.04214546
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4441.05859375MB
INFO:root:[    8] Training loss: 0.70113872, Validation loss: 0.69348063, Gradient norm: 0.04662086
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4398.90625MB
INFO:root:[    9] Training loss: 0.69879216, Validation loss: 0.68966619, Gradient norm: 0.05206371
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4474.37109375MB
INFO:root:[   10] Training loss: 0.69608429, Validation loss: 0.68582605, Gradient norm: 0.06107032
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4466.85546875MB
INFO:root:[   11] Training loss: 0.69381917, Validation loss: 0.68384311, Gradient norm: 0.07517372
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4513.4296875MB
INFO:root:[   12] Training loss: 0.69147675, Validation loss: 0.68114839, Gradient norm: 0.08308767
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4552.55078125MB
INFO:root:[   13] Training loss: 0.68968701, Validation loss: 0.67824313, Gradient norm: 0.08968825
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4653.12109375MB
INFO:root:[   14] Training loss: 0.68794492, Validation loss: 0.67869516, Gradient norm: 0.11158554
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4691.25MB
