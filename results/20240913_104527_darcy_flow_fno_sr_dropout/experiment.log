INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=573.375MB; mem (CPU total)=1055.80078125MB
INFO:root:############### Starting experiment with config file darcy_flow/fno_sr_dropout.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'DarcyFlow', 'max_training_set_size': 10000, 'downscaling_factor': 2}
INFO:root:After loading the datasets: mem (CPU python)=1993.58984375MB; mem (CPU total)=1065.73828125MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=1993.58984375MB; mem (CPU total)=1065.28125MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 4194304
INFO:root:After setting up the model: mem (CPU python)=2005.33984375MB; mem (CPU total)=2272.921875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2014.62109375MB; mem (CPU total)=2281.16015625MB
INFO:root:[    1] Training loss: 0.33480666, Validation loss: 0.14107147, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=3649.96875MB; mem (CPU total)=3531.18359375MB
INFO:root:[    2] Training loss: 0.12124152, Validation loss: 0.10390920, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=3726.19921875MB; mem (CPU total)=3607.36328125MB
INFO:root:[    3] Training loss: 0.10200891, Validation loss: 0.09008527, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=3802.3984375MB; mem (CPU total)=3683.7109375MB
INFO:root:[    4] Training loss: 0.09191461, Validation loss: 0.08729881, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=3878.61328125MB; mem (CPU total)=3759.24609375MB
INFO:root:[    5] Training loss: 0.08288942, Validation loss: 0.07866040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=3954.828125MB; mem (CPU total)=3835.578125MB
INFO:root:[    6] Training loss: 0.08247111, Validation loss: 0.09016879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4031.0078125MB; mem (CPU total)=3911.87109375MB
INFO:root:[    7] Training loss: 0.07432607, Validation loss: 0.07328713, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4107.2421875MB; mem (CPU total)=3988.5078125MB
INFO:root:[    8] Training loss: 0.07697747, Validation loss: 0.07786659, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4183.45703125MB; mem (CPU total)=4064.53125MB
INFO:root:[    9] Training loss: 0.07182336, Validation loss: 0.07631675, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4259.671875MB; mem (CPU total)=4140.88671875MB
INFO:root:[   10] Training loss: 0.06990915, Validation loss: 0.06898657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4335.89453125MB; mem (CPU total)=4217.87109375MB
INFO:root:[   11] Training loss: 0.06884926, Validation loss: 0.07197934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4412.13671875MB; mem (CPU total)=4293.98828125MB
INFO:root:[   12] Training loss: 0.06855119, Validation loss: 0.06717082, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4488.35546875MB; mem (CPU total)=4370.41796875MB
INFO:root:[   13] Training loss: 0.06521336, Validation loss: 0.07195324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4564.5703125MB; mem (CPU total)=4446.41015625MB
INFO:root:[   14] Training loss: 0.06452315, Validation loss: 0.06602821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4640.80078125MB; mem (CPU total)=4523.53515625MB
INFO:root:[   15] Training loss: 0.06412154, Validation loss: 0.06855006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4717.01953125MB; mem (CPU total)=4599.38671875MB
INFO:root:[   16] Training loss: 0.06274700, Validation loss: 0.07098265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4793.234375MB; mem (CPU total)=4675.96875MB
INFO:root:[   17] Training loss: 0.06065055, Validation loss: 0.06802733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4869.43359375MB; mem (CPU total)=4751.96484375MB
INFO:root:[   18] Training loss: 0.06040688, Validation loss: 0.08235456, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4945.62890625MB; mem (CPU total)=4828.203125MB
INFO:root:[   19] Training loss: 0.06166487, Validation loss: 0.06303834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5021.82421875MB; mem (CPU total)=4904.953125MB
INFO:root:[   20] Training loss: 0.05802945, Validation loss: 0.06596459, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5098.03125MB; mem (CPU total)=4980.91015625MB
INFO:root:[   21] Training loss: 0.05877912, Validation loss: 0.06563037, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5174.2421875MB; mem (CPU total)=5057.48046875MB
INFO:root:[   22] Training loss: 0.05740984, Validation loss: 0.06904262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5250.46875MB; mem (CPU total)=5134.1328125MB
INFO:root:[   23] Training loss: 0.05836381, Validation loss: 0.06151322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5326.66796875MB; mem (CPU total)=5210.24609375MB
INFO:root:[   24] Training loss: 0.05746944, Validation loss: 0.06144073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5402.8671875MB; mem (CPU total)=5286.82421875MB
INFO:root:[   25] Training loss: 0.05583772, Validation loss: 0.06258837, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5479.08984375MB; mem (CPU total)=5362.8515625MB
INFO:root:[   26] Training loss: 0.05521388, Validation loss: 0.06195973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5555.28515625MB; mem (CPU total)=5439.4609375MB
INFO:root:[   27] Training loss: 0.05595811, Validation loss: 0.06723493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5631.4921875MB; mem (CPU total)=5515.6796875MB
INFO:root:[   28] Training loss: 0.05507349, Validation loss: 0.06446391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5707.6953125MB; mem (CPU total)=5591.37109375MB
INFO:root:[   29] Training loss: 0.05557167, Validation loss: 0.06265019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5783.875MB; mem (CPU total)=5667.90234375MB
INFO:root:[   30] Training loss: 0.05507185, Validation loss: 0.06069970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5860.06640625MB; mem (CPU total)=5744.48828125MB
INFO:root:[   31] Training loss: 0.05270495, Validation loss: 0.05998934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5936.2578125MB; mem (CPU total)=5821.10546875MB
INFO:root:[   32] Training loss: 0.05241147, Validation loss: 0.07051664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6012.453125MB; mem (CPU total)=5897.16796875MB
INFO:root:[   33] Training loss: 0.05365137, Validation loss: 0.06101283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6088.640625MB; mem (CPU total)=5973.25MB
INFO:root:[   34] Training loss: 0.05197401, Validation loss: 0.05796875, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6164.83203125MB; mem (CPU total)=6049.46875MB
INFO:root:[   35] Training loss: 0.05015655, Validation loss: 0.06437802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6241.02734375MB; mem (CPU total)=6125.77734375MB
INFO:root:[   36] Training loss: 0.05130391, Validation loss: 0.05772056, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6317.21484375MB; mem (CPU total)=6202.26171875MB
INFO:root:[   37] Training loss: 0.05042596, Validation loss: 0.05911635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6393.40625MB; mem (CPU total)=6278.53515625MB
INFO:root:[   38] Training loss: 0.04948742, Validation loss: 0.06026541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6469.59375MB; mem (CPU total)=6354.875MB
INFO:root:[   39] Training loss: 0.04856210, Validation loss: 0.05814665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6545.79296875MB; mem (CPU total)=6431.43359375MB
INFO:root:[   40] Training loss: 0.04876733, Validation loss: 0.06135650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6621.98046875MB; mem (CPU total)=6507.49609375MB
INFO:root:[   41] Training loss: 0.04952223, Validation loss: 0.05836747, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6698.171875MB; mem (CPU total)=6584.05078125MB
INFO:root:[   42] Training loss: 0.04858001, Validation loss: 0.05549500, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6774.36328125MB; mem (CPU total)=6660.1640625MB
INFO:root:[   43] Training loss: 0.04682546, Validation loss: 0.06213551, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6850.55078125MB; mem (CPU total)=6735.98046875MB
INFO:root:[   44] Training loss: 0.04785441, Validation loss: 0.06227844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6926.74609375MB; mem (CPU total)=6812.53515625MB
INFO:root:[   45] Training loss: 0.04757268, Validation loss: 0.05882928, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7002.93359375MB; mem (CPU total)=6888.546875MB
INFO:root:[   46] Training loss: 0.04642073, Validation loss: 0.05762766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7079.125MB; mem (CPU total)=6964.609375MB
INFO:root:[   47] Training loss: 0.04825777, Validation loss: 0.06225253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7155.3203125MB; mem (CPU total)=7041.55859375MB
INFO:root:[   48] Training loss: 0.04565187, Validation loss: 0.05789018, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7231.51171875MB; mem (CPU total)=7117.13671875MB
INFO:root:[   49] Training loss: 0.04550366, Validation loss: 0.06159969, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7307.703125MB; mem (CPU total)=7193.69140625MB
INFO:root:[   50] Training loss: 0.04585586, Validation loss: 0.06009418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7383.890625MB; mem (CPU total)=7270.0MB
INFO:root:[   51] Training loss: 0.04635050, Validation loss: 0.06021457, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7460.73828125MB; mem (CPU total)=7347.15234375MB
INFO:root:[   52] Training loss: 0.04522383, Validation loss: 0.05741221, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7537.15234375MB; mem (CPU total)=7423.8046875MB
INFO:root:[   53] Training loss: 0.04488554, Validation loss: 0.05857334, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7613.4375MB; mem (CPU total)=7499.2734375MB
INFO:root:[   54] Training loss: 0.04421018, Validation loss: 0.07180017, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7690.05859375MB; mem (CPU total)=7576.2421875MB
INFO:root:[   55] Training loss: 0.04373851, Validation loss: 0.05724446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7768.07421875MB; mem (CPU total)=7654.328125MB
INFO:root:[   56] Training loss: 0.04340518, Validation loss: 0.06215651, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7844.6015625MB; mem (CPU total)=7730.92578125MB
INFO:root:[   57] Training loss: 0.04363310, Validation loss: 0.05643891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7921.1328125MB; mem (CPU total)=7807.80078125MB
INFO:root:[   58] Training loss: 0.04267229, Validation loss: 0.05970741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7997.32421875MB; mem (CPU total)=7883.84375MB
INFO:root:[   59] Training loss: 0.04312454, Validation loss: 0.05612974, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8073.515625MB; mem (CPU total)=7960.37890625MB
INFO:root:[   60] Training loss: 0.04369757, Validation loss: 0.06487184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8149.703125MB; mem (CPU total)=8036.9140625MB
INFO:root:[   61] Training loss: 0.04266820, Validation loss: 0.05808766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8225.8984375MB; mem (CPU total)=8113.19140625MB
INFO:root:[   62] Training loss: 0.04167904, Validation loss: 0.06067282, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8302.0859375MB; mem (CPU total)=8189.7265625MB
INFO:root:[   63] Training loss: 0.04225283, Validation loss: 0.06450416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8378.27734375MB; mem (CPU total)=8265.5234375MB
INFO:root:[   64] Training loss: 0.04123824, Validation loss: 0.05638479, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8454.46875MB; mem (CPU total)=8342.05859375MB
INFO:root:[   65] Training loss: 0.04131384, Validation loss: 0.05633012, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8530.66015625MB; mem (CPU total)=8418.58203125MB
INFO:root:[   66] Training loss: 0.04012054, Validation loss: 0.05777057, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8606.8515625MB; mem (CPU total)=8494.6171875MB
INFO:root:[   67] Training loss: 0.04076368, Validation loss: 0.05811044, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8683.0390625MB; mem (CPU total)=8571.171875MB
INFO:root:[   68] Training loss: 0.03951968, Validation loss: 0.05883486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8759.23046875MB; mem (CPU total)=8647.0078125MB
INFO:root:EP 68: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=8835.42578125MB; mem (CPU total)=8723.54296875MB
INFO:root:Training the model took 3679.809s.
INFO:root:Emptying the cuda cache took 0.066s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.05561
INFO:root:EnergyScoreTrain: 0.04582
INFO:root:CRPSTrain: 0.03647
INFO:root:Gaussian NLLTrain: -1.38999
INFO:root:CoverageTrain: 0.99625
INFO:root:IntervalWidthTrain: 0.40433
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.07771
INFO:root:EnergyScoreValidation: 0.05775
INFO:root:CRPSValidation: 0.04653
INFO:root:Gaussian NLLValidation: -1.29456
INFO:root:CoverageValidation: 0.98619
INFO:root:IntervalWidthValidation: 0.40122
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.08005
INFO:root:EnergyScoreTest: 0.05884
INFO:root:CRPSTest: 0.0475
INFO:root:Gaussian NLLTest: -1.28006
INFO:root:CoverageTest: 0.9861
INFO:root:IntervalWidthTest: 0.40133
INFO:root:After validation: mem (CPU python)=8927.91796875MB; mem (CPU total)=8811.546875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=8927.921875MB; mem (CPU total)=8811.3828125MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 71303168
INFO:root:After setting up the model: mem (CPU python)=8929.19140625MB; mem (CPU total)=8812.55078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=8929.19140625MB; mem (CPU total)=8812.796875MB
INFO:root:[    1] Training loss: 0.33813077, Validation loss: 0.15565145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9008.1875MB; mem (CPU total)=8891.44140625MB
INFO:root:[    2] Training loss: 0.12469893, Validation loss: 0.13138481, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9084.37890625MB; mem (CPU total)=8966.74609375MB
INFO:root:[    3] Training loss: 0.09957657, Validation loss: 0.09402786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9160.59375MB; mem (CPU total)=9043.28125MB
INFO:root:[    4] Training loss: 0.09108085, Validation loss: 0.08891560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9236.80859375MB; mem (CPU total)=9119.6015625MB
INFO:root:[    5] Training loss: 0.08043340, Validation loss: 0.07875637, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9313.015625MB; mem (CPU total)=9195.66796875MB
INFO:root:[    6] Training loss: 0.07665787, Validation loss: 0.07529375, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9389.2890625MB; mem (CPU total)=9272.46484375MB
INFO:root:[    7] Training loss: 0.07594331, Validation loss: 0.09338913, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9465.49609375MB; mem (CPU total)=9348.28515625MB
INFO:root:[    8] Training loss: 0.07390926, Validation loss: 0.07386272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9541.70703125MB; mem (CPU total)=9424.578125MB
INFO:root:[    9] Training loss: 0.06877754, Validation loss: 0.06921957, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9617.9140625MB; mem (CPU total)=9501.25MB
INFO:root:[   10] Training loss: 0.06700933, Validation loss: 0.06553184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9694.12109375MB; mem (CPU total)=9577.0703125MB
INFO:root:[   11] Training loss: 0.06636449, Validation loss: 0.06869492, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9770.3203125MB; mem (CPU total)=9653.37890625MB
INFO:root:[   12] Training loss: 0.06396244, Validation loss: 0.06594765, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9846.51171875MB; mem (CPU total)=9729.69140625MB
INFO:root:[   13] Training loss: 0.06469389, Validation loss: 0.06989732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9922.703125MB; mem (CPU total)=9806.0MB
INFO:root:[   14] Training loss: 0.06375056, Validation loss: 0.06715374, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9998.890625MB; mem (CPU total)=9882.28125MB
INFO:root:[   15] Training loss: 0.06175913, Validation loss: 0.06412145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10075.08203125MB; mem (CPU total)=9958.62109375MB
INFO:root:[   16] Training loss: 0.06026806, Validation loss: 0.06464812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10151.27734375MB; mem (CPU total)=10034.68359375MB
INFO:root:[   17] Training loss: 0.06203024, Validation loss: 0.07403706, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10227.46484375MB; mem (CPU total)=10111.46875MB
INFO:root:[   18] Training loss: 0.05975445, Validation loss: 0.06941535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10303.65625MB; mem (CPU total)=10187.5625MB
INFO:root:[   19] Training loss: 0.05885995, Validation loss: 0.06085587, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10379.84375MB; mem (CPU total)=10263.61328125MB
INFO:root:[   20] Training loss: 0.05611880, Validation loss: 0.06358033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10456.0390625MB; mem (CPU total)=10339.5MB
INFO:root:[   21] Training loss: 0.05522004, Validation loss: 0.06164806, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10532.23046875MB; mem (CPU total)=10415.8671875MB
INFO:root:[   22] Training loss: 0.05662018, Validation loss: 0.06617623, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10608.41796875MB; mem (CPU total)=10492.19921875MB
INFO:root:[   23] Training loss: 0.05608924, Validation loss: 0.05978561, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10684.609375MB; mem (CPU total)=10568.40234375MB
INFO:root:[   24] Training loss: 0.05731071, Validation loss: 0.06046634, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10760.80078125MB; mem (CPU total)=10644.7109375MB
INFO:root:[   25] Training loss: 0.05510902, Validation loss: 0.06147207, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10836.9921875MB; mem (CPU total)=10721.265625MB
INFO:root:[   26] Training loss: 0.05294080, Validation loss: 0.06187904, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10913.18359375MB; mem (CPU total)=10797.85546875MB
INFO:root:[   27] Training loss: 0.05530026, Validation loss: 0.06073295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10989.375MB; mem (CPU total)=10874.1640625MB
INFO:root:[   28] Training loss: 0.05303229, Validation loss: 0.05870036, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11065.56640625MB; mem (CPU total)=10950.78515625MB
INFO:root:[   29] Training loss: 0.05238606, Validation loss: 0.07242359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11141.75390625MB; mem (CPU total)=11026.81640625MB
INFO:root:[   30] Training loss: 0.05158821, Validation loss: 0.06517668, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11217.9453125MB; mem (CPU total)=11103.12890625MB
INFO:root:[   31] Training loss: 0.05159852, Validation loss: 0.06189171, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11294.1328125MB; mem (CPU total)=11179.34375MB
INFO:root:[   32] Training loss: 0.05164934, Validation loss: 0.05897506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11370.328125MB; mem (CPU total)=11255.65625MB
INFO:root:[   33] Training loss: 0.05005304, Validation loss: 0.06147704, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11446.51953125MB; mem (CPU total)=11332.21484375MB
INFO:root:[   34] Training loss: 0.05059205, Validation loss: 0.05714950, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11522.70703125MB; mem (CPU total)=11408.5546875MB
INFO:root:[   35] Training loss: 0.04819035, Validation loss: 0.05725383, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11598.8984375MB; mem (CPU total)=11485.17578125MB
INFO:root:[   36] Training loss: 0.04899149, Validation loss: 0.06128629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11675.0859375MB; mem (CPU total)=11561.5078125MB
INFO:root:[   37] Training loss: 0.04925668, Validation loss: 0.06006780, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11751.28125MB; mem (CPU total)=11637.91796875MB
INFO:root:[   38] Training loss: 0.04754197, Validation loss: 0.06439038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11827.47265625MB; mem (CPU total)=11714.22265625MB
INFO:root:[   39] Training loss: 0.04803942, Validation loss: 0.06184134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11903.6640625MB; mem (CPU total)=11790.53125MB
INFO:root:[   40] Training loss: 0.04768059, Validation loss: 0.05846932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11979.859375MB; mem (CPU total)=11866.265625MB
INFO:root:[   41] Training loss: 0.04627837, Validation loss: 0.06656178, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12056.046875MB; mem (CPU total)=11942.61328125MB
INFO:root:[   42] Training loss: 0.04680584, Validation loss: 0.05901151, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12132.23828125MB; mem (CPU total)=12019.03125MB
INFO:root:[   43] Training loss: 0.04517831, Validation loss: 0.05692548, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12208.4296875MB; mem (CPU total)=12095.15234375MB
INFO:root:[   44] Training loss: 0.04514619, Validation loss: 0.05831434, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12284.6171875MB; mem (CPU total)=12171.93359375MB
INFO:root:[   45] Training loss: 0.04454529, Validation loss: 0.06142793, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12360.8125MB; mem (CPU total)=12248.25390625MB
INFO:root:[   46] Training loss: 0.04475068, Validation loss: 0.05568679, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12437.0MB; mem (CPU total)=12324.2109375MB
INFO:root:[   47] Training loss: 0.04777410, Validation loss: 0.06308287, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12513.19140625MB; mem (CPU total)=12400.5MB
INFO:root:[   48] Training loss: 0.04397080, Validation loss: 0.06394382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12589.3828125MB; mem (CPU total)=12477.06640625MB
INFO:root:[   49] Training loss: 0.04361900, Validation loss: 0.05940343, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12665.57421875MB; mem (CPU total)=12553.32421875MB
INFO:root:[   50] Training loss: 0.04367616, Validation loss: 0.05710638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12741.765625MB; mem (CPU total)=12629.3671875MB
INFO:root:[   51] Training loss: 0.04551297, Validation loss: 0.06796965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12817.953125MB; mem (CPU total)=12705.6484375MB
INFO:root:[   52] Training loss: 0.04436677, Validation loss: 0.05914896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12894.1484375MB; mem (CPU total)=12782.11328125MB
INFO:root:[   53] Training loss: 0.04488630, Validation loss: 0.05921593, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12970.3359375MB; mem (CPU total)=12858.78515625MB
INFO:root:[   54] Training loss: 0.04203666, Validation loss: 0.05716986, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13046.52734375MB; mem (CPU total)=12935.07421875MB
INFO:root:[   55] Training loss: 0.04141957, Validation loss: 0.05809942, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13122.71875MB; mem (CPU total)=13011.36328125MB
INFO:root:[   56] Training loss: 0.04242367, Validation loss: 0.05681748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13198.91015625MB; mem (CPU total)=13087.89453125MB
INFO:root:[   57] Training loss: 0.04143413, Validation loss: 0.05786357, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13275.1015625MB; mem (CPU total)=13163.9375MB
INFO:root:[   58] Training loss: 0.04240304, Validation loss: 0.05993497, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13351.2890625MB; mem (CPU total)=13239.48046875MB
INFO:root:[   59] Training loss: 0.04172024, Validation loss: 0.05561336, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13427.48046875MB; mem (CPU total)=13316.578125MB
INFO:root:[   60] Training loss: 0.04049080, Validation loss: 0.05690793, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13503.67578125MB; mem (CPU total)=13392.8671875MB
INFO:root:[   61] Training loss: 0.04274138, Validation loss: 0.06000472, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13579.8671875MB; mem (CPU total)=13469.59375MB
INFO:root:[   62] Training loss: 0.03989294, Validation loss: 0.05650708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13656.05859375MB; mem (CPU total)=13545.8203125MB
INFO:root:[   63] Training loss: 0.03986672, Validation loss: 0.05943488, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13732.24609375MB; mem (CPU total)=13622.1328125MB
INFO:root:[   64] Training loss: 0.04043892, Validation loss: 0.06109861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13808.4375MB; mem (CPU total)=13698.125MB
INFO:root:[   65] Training loss: 0.03867242, Validation loss: 0.05817267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13884.625MB; mem (CPU total)=13774.4140625MB
INFO:root:[   66] Training loss: 0.03968116, Validation loss: 0.05633937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13960.82421875MB; mem (CPU total)=13850.703125MB
INFO:root:[   67] Training loss: 0.03963133, Validation loss: 0.05422239, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14037.015625MB; mem (CPU total)=13927.0703125MB
INFO:root:[   68] Training loss: 0.03853374, Validation loss: 0.06034160, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14113.203125MB; mem (CPU total)=14003.57421875MB
INFO:root:[   69] Training loss: 0.03860655, Validation loss: 0.06003463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14189.39453125MB; mem (CPU total)=14080.37890625MB
INFO:root:[   70] Training loss: 0.04005104, Validation loss: 0.05894692, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14265.5859375MB; mem (CPU total)=14156.19921875MB
INFO:root:[   71] Training loss: 0.03833963, Validation loss: 0.06293021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14341.77734375MB; mem (CPU total)=14232.59375MB
INFO:root:[   72] Training loss: 0.03781829, Validation loss: 0.05587920, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14417.98046875MB; mem (CPU total)=14308.83203125MB
INFO:root:[   73] Training loss: 0.03697894, Validation loss: 0.05703418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14494.171875MB; mem (CPU total)=14385.08203125MB
INFO:root:[   74] Training loss: 0.03628177, Validation loss: 0.05929491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14570.36328125MB; mem (CPU total)=14461.3203125MB
INFO:root:[   75] Training loss: 0.03649450, Validation loss: 0.05681252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14646.55078125MB; mem (CPU total)=14537.609375MB
INFO:root:[   76] Training loss: 0.03796791, Validation loss: 0.05621354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14722.7421875MB; mem (CPU total)=14613.89453125MB
INFO:root:EP 76: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=14798.93359375MB; mem (CPU total)=14690.18359375MB
INFO:root:Training the model took 4442.465s.
INFO:root:Emptying the cuda cache took 0.068s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.0414
INFO:root:EnergyScoreTrain: 0.03643
INFO:root:CRPSTrain: 0.02889
INFO:root:Gaussian NLLTrain: -1.57326
INFO:root:CoverageTrain: 0.99758
INFO:root:IntervalWidthTrain: 0.34381
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.07501
INFO:root:EnergyScoreValidation: 0.05566
INFO:root:CRPSValidation: 0.04517
INFO:root:Gaussian NLLValidation: -1.40754
INFO:root:CoverageValidation: 0.97896
INFO:root:IntervalWidthValidation: 0.34024
INFO:root:Evaluating the model on Test data.
