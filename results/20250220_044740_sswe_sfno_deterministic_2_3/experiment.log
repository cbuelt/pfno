INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=580.23828125MB; mem (CPU total)=4473.83203125MB
INFO:root:############### Starting experiment with config file sswe/sfno_deterministic_2_3.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=591.15234375MB; mem (CPU total)=4476.76953125MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'SFNO', 'uncertainty_quantification': 'deterministic', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=592.57421875MB; mem (CPU total)=4477.26171875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2304.0078125MB; mem (CPU total)=5896.14453125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2313.7265625MB; mem (CPU total)=5905.98828125MB
INFO:root:[    1] Training loss: 0.83171742, Validation loss: 0.73499825, Gradient norm: 0.71136608
INFO:root:At the start of the epoch: mem (CPU python)=4469.08984375MB; mem (CPU total)=7598.2890625MB
INFO:root:[    2] Training loss: 0.73572556, Validation loss: 0.73283154, Gradient norm: 0.45118241
INFO:root:At the start of the epoch: mem (CPU python)=4491.15625MB; mem (CPU total)=7620.69140625MB
INFO:root:[    3] Training loss: 0.73221042, Validation loss: 0.72841891, Gradient norm: 0.40281652
INFO:root:At the start of the epoch: mem (CPU python)=4512.5390625MB; mem (CPU total)=7643.328125MB
INFO:root:[    4] Training loss: 0.71269774, Validation loss: 0.68386024, Gradient norm: 0.57198171
INFO:root:At the start of the epoch: mem (CPU python)=4533.66015625MB; mem (CPU total)=7590.5234375MB
INFO:root:[    5] Training loss: 0.65284699, Validation loss: 0.61335791, Gradient norm: 0.76307603
INFO:root:At the start of the epoch: mem (CPU python)=4556.66796875MB; mem (CPU total)=7712.28515625MB
INFO:root:[    6] Training loss: 0.60015664, Validation loss: 0.58200885, Gradient norm: 0.93218743
INFO:root:At the start of the epoch: mem (CPU python)=4574.8671875MB; mem (CPU total)=7718.51953125MB
INFO:root:[    7] Training loss: 0.57772892, Validation loss: 0.56136231, Gradient norm: 1.02671097
INFO:root:At the start of the epoch: mem (CPU python)=4596.21875MB; mem (CPU total)=7737.84375MB
INFO:root:[    8] Training loss: 0.55933334, Validation loss: 0.56006267, Gradient norm: 1.15432610
INFO:root:At the start of the epoch: mem (CPU python)=4617.76953125MB; mem (CPU total)=7751.578125MB
INFO:root:[    9] Training loss: 0.55325513, Validation loss: 0.54666337, Gradient norm: 1.41056990
INFO:root:At the start of the epoch: mem (CPU python)=4638.6796875MB; mem (CPU total)=7774.375MB
INFO:root:[   10] Training loss: 0.53649333, Validation loss: 0.51901797, Gradient norm: 1.46634167
INFO:root:At the start of the epoch: mem (CPU python)=4661.16796875MB; mem (CPU total)=7810.68359375MB
INFO:root:[   11] Training loss: 0.52221454, Validation loss: 0.51485447, Gradient norm: 1.42569877
INFO:root:At the start of the epoch: mem (CPU python)=4680.21484375MB; mem (CPU total)=7811.4453125MB
INFO:root:[   12] Training loss: 0.50746668, Validation loss: 0.50149708, Gradient norm: 1.45483333
INFO:root:At the start of the epoch: mem (CPU python)=4704.26171875MB; mem (CPU total)=7850.57421875MB
INFO:root:[   13] Training loss: 0.50920475, Validation loss: 0.49592520, Gradient norm: 1.92878034
INFO:root:At the start of the epoch: mem (CPU python)=4726.265625MB; mem (CPU total)=7872.15234375MB
INFO:root:[   14] Training loss: 0.49787763, Validation loss: 0.49714670, Gradient norm: 1.92899982
INFO:root:At the start of the epoch: mem (CPU python)=4746.82421875MB; mem (CPU total)=7880.0390625MB
INFO:root:[   15] Training loss: 0.49718026, Validation loss: 0.49106390, Gradient norm: 1.78225271
INFO:root:At the start of the epoch: mem (CPU python)=4768.66015625MB; mem (CPU total)=7908.34765625MB
INFO:root:[   16] Training loss: 0.49425458, Validation loss: 0.50913884, Gradient norm: 2.03546745
INFO:root:At the start of the epoch: mem (CPU python)=4790.85546875MB; mem (CPU total)=7909.99609375MB
INFO:root:[   17] Training loss: 0.49343295, Validation loss: 0.47164067, Gradient norm: 2.20054702
INFO:root:At the start of the epoch: mem (CPU python)=4809.921875MB; mem (CPU total)=7937.5MB
INFO:root:[   18] Training loss: 0.48726107, Validation loss: 0.47157453, Gradient norm: 2.24259351
INFO:root:At the start of the epoch: mem (CPU python)=4832.1171875MB; mem (CPU total)=7979.765625MB
INFO:root:[   19] Training loss: 0.48643007, Validation loss: 0.47758367, Gradient norm: 2.27843639
INFO:root:At the start of the epoch: mem (CPU python)=4854.1171875MB; mem (CPU total)=7969.0234375MB
INFO:root:[   20] Training loss: 0.48236871, Validation loss: 0.49792444, Gradient norm: 2.42021323
INFO:root:At the start of the epoch: mem (CPU python)=4873.78515625MB; mem (CPU total)=7781.60546875MB
INFO:root:[   21] Training loss: 0.47755494, Validation loss: 0.46909034, Gradient norm: 2.74537492
INFO:root:At the start of the epoch: mem (CPU python)=4896.13671875MB; mem (CPU total)=8049.84375MB
INFO:root:[   22] Training loss: 0.47577363, Validation loss: 0.46827763, Gradient norm: 2.50530412
INFO:root:At the start of the epoch: mem (CPU python)=4916.60546875MB; mem (CPU total)=7849.26171875MB
INFO:root:[   23] Training loss: 0.47596646, Validation loss: 0.45734498, Gradient norm: 2.83845337
INFO:root:At the start of the epoch: mem (CPU python)=4938.66796875MB; mem (CPU total)=7951.04296875MB
INFO:root:[   24] Training loss: 0.47453140, Validation loss: 0.45155997, Gradient norm: 2.97686465
INFO:root:At the start of the epoch: mem (CPU python)=4958.51953125MB; mem (CPU total)=8072.76953125MB
INFO:root:[   25] Training loss: 0.47161470, Validation loss: 0.45829821, Gradient norm: 2.86553264
INFO:root:At the start of the epoch: mem (CPU python)=4978.26171875MB; mem (CPU total)=8079.08203125MB
INFO:root:[   26] Training loss: 0.47250143, Validation loss: 0.45437488, Gradient norm: 3.04967089
INFO:root:At the start of the epoch: mem (CPU python)=5001.046875MB; mem (CPU total)=8142.84765625MB
INFO:root:[   27] Training loss: 0.47147501, Validation loss: 0.45758626, Gradient norm: 2.86872693
INFO:root:At the start of the epoch: mem (CPU python)=5025.27734375MB; mem (CPU total)=8176.88671875MB
INFO:root:[   28] Training loss: 0.46577739, Validation loss: 0.45680579, Gradient norm: 3.04017632
INFO:root:At the start of the epoch: mem (CPU python)=5048.53125MB; mem (CPU total)=8196.86328125MB
INFO:root:[   29] Training loss: 0.46501607, Validation loss: 0.48162911, Gradient norm: 2.66600274
INFO:root:At the start of the epoch: mem (CPU python)=5068.296875MB; mem (CPU total)=8196.74609375MB
INFO:root:[   30] Training loss: 0.46816209, Validation loss: 0.46244670, Gradient norm: 2.79373640
INFO:root:At the start of the epoch: mem (CPU python)=5088.0859375MB; mem (CPU total)=8231.671875MB
INFO:root:[   31] Training loss: 0.46449156, Validation loss: 0.45652235, Gradient norm: 3.09181291
INFO:root:At the start of the epoch: mem (CPU python)=5110.515625MB; mem (CPU total)=8260.8046875MB
INFO:root:[   32] Training loss: 0.46245204, Validation loss: 0.44330596, Gradient norm: 3.08406159
INFO:root:At the start of the epoch: mem (CPU python)=5130.265625MB; mem (CPU total)=8271.125MB
INFO:root:[   33] Training loss: 0.46009759, Validation loss: 0.46570960, Gradient norm: 3.27532192
INFO:root:At the start of the epoch: mem (CPU python)=5151.0625MB; mem (CPU total)=8281.6484375MB
INFO:root:[   34] Training loss: 0.46347146, Validation loss: 0.45813062, Gradient norm: 3.24679136
INFO:root:At the start of the epoch: mem (CPU python)=5173.3359375MB; mem (CPU total)=8297.52734375MB
INFO:root:[   35] Training loss: 0.45950949, Validation loss: 0.46305696, Gradient norm: 2.91705675
INFO:root:At the start of the epoch: mem (CPU python)=5195.12109375MB; mem (CPU total)=8311.5234375MB
INFO:root:[   36] Training loss: 0.45980213, Validation loss: 0.46074661, Gradient norm: 3.09044843
INFO:root:At the start of the epoch: mem (CPU python)=5216.484375MB; mem (CPU total)=8351.64453125MB
INFO:root:[   37] Training loss: 0.45564011, Validation loss: 0.43912411, Gradient norm: 3.30973913
INFO:root:At the start of the epoch: mem (CPU python)=5238.34375MB; mem (CPU total)=8366.46484375MB
INFO:root:[   38] Training loss: 0.45891034, Validation loss: 0.43527364, Gradient norm: 3.35465557
INFO:root:At the start of the epoch: mem (CPU python)=5260.78125MB; mem (CPU total)=8389.3515625MB
INFO:root:[   39] Training loss: 0.45591186, Validation loss: 0.44615670, Gradient norm: 3.12957963
INFO:root:At the start of the epoch: mem (CPU python)=5283.1875MB; mem (CPU total)=8412.359375MB
INFO:root:[   40] Training loss: 0.45037482, Validation loss: 0.43225440, Gradient norm: 3.30101645
INFO:root:At the start of the epoch: mem (CPU python)=5305.3125MB; mem (CPU total)=8425.2109375MB
INFO:root:[   41] Training loss: 0.44943336, Validation loss: 0.44333801, Gradient norm: 3.00058952
INFO:root:At the start of the epoch: mem (CPU python)=5326.47265625MB; mem (CPU total)=8311.27734375MB
INFO:root:[   42] Training loss: 0.44703033, Validation loss: 0.45558524, Gradient norm: 3.69175037
INFO:root:At the start of the epoch: mem (CPU python)=5347.90234375MB; mem (CPU total)=8288.234375MB
INFO:root:[   43] Training loss: 0.44916368, Validation loss: 0.43877680, Gradient norm: 3.88320755
INFO:root:At the start of the epoch: mem (CPU python)=5369.92578125MB; mem (CPU total)=8375.921875MB
INFO:root:[   44] Training loss: 0.44383449, Validation loss: 0.44095919, Gradient norm: 3.71088733
INFO:root:At the start of the epoch: mem (CPU python)=5391.08984375MB; mem (CPU total)=8514.15234375MB
INFO:root:[   45] Training loss: 0.44453139, Validation loss: 0.44915160, Gradient norm: 3.95302137
INFO:root:At the start of the epoch: mem (CPU python)=5412.2578125MB; mem (CPU total)=8534.875MB
INFO:root:[   46] Training loss: 0.44215895, Validation loss: 0.44881883, Gradient norm: 3.73913953
INFO:root:At the start of the epoch: mem (CPU python)=5433.421875MB; mem (CPU total)=8591.5MB
INFO:root:[   47] Training loss: 0.44461103, Validation loss: 0.42859189, Gradient norm: 3.40339339
INFO:root:At the start of the epoch: mem (CPU python)=5454.5859375MB; mem (CPU total)=8595.5078125MB
INFO:root:[   48] Training loss: 0.43767996, Validation loss: 0.43436554, Gradient norm: 3.68955401
INFO:root:At the start of the epoch: mem (CPU python)=5476.23828125MB; mem (CPU total)=8621.4375MB
INFO:root:[   49] Training loss: 0.43709381, Validation loss: 0.43181605, Gradient norm: 4.09792782
INFO:root:At the start of the epoch: mem (CPU python)=5497.40234375MB; mem (CPU total)=8626.421875MB
INFO:root:[   50] Training loss: 0.43976991, Validation loss: 0.43224528, Gradient norm: 3.92329957
INFO:root:At the start of the epoch: mem (CPU python)=5518.828125MB; mem (CPU total)=8670.8515625MB
INFO:root:[   51] Training loss: 0.43806066, Validation loss: 0.45214102, Gradient norm: 4.05435492
INFO:root:At the start of the epoch: mem (CPU python)=5540.00390625MB; mem (CPU total)=8711.14453125MB
INFO:root:[   52] Training loss: 0.42627768, Validation loss: 0.41177569, Gradient norm: 3.91600746
INFO:root:At the start of the epoch: mem (CPU python)=5561.29296875MB; mem (CPU total)=8700.8828125MB
INFO:root:[   53] Training loss: 0.43390971, Validation loss: 0.43469856, Gradient norm: 3.65506373
INFO:root:At the start of the epoch: mem (CPU python)=5582.703125MB; mem (CPU total)=8715.36328125MB
INFO:root:[   54] Training loss: 0.43643982, Validation loss: 0.40813318, Gradient norm: 4.27468450
INFO:root:At the start of the epoch: mem (CPU python)=5603.87109375MB; mem (CPU total)=8760.54296875MB
INFO:root:[   55] Training loss: 0.42502434, Validation loss: 0.41800339, Gradient norm: 3.83352288
INFO:root:At the start of the epoch: mem (CPU python)=5623.921875MB; mem (CPU total)=8779.57421875MB
INFO:root:[   56] Training loss: 0.42549313, Validation loss: 0.42278699, Gradient norm: 3.99261955
INFO:root:At the start of the epoch: mem (CPU python)=5645.15625MB; mem (CPU total)=8783.43359375MB
INFO:root:[   57] Training loss: 0.42775089, Validation loss: 0.42045404, Gradient norm: 4.40170785
INFO:root:At the start of the epoch: mem (CPU python)=5666.98828125MB; mem (CPU total)=8811.7265625MB
INFO:root:[   58] Training loss: 0.42595304, Validation loss: 0.44000507, Gradient norm: 4.42680632
INFO:root:At the start of the epoch: mem (CPU python)=5688.15234375MB; mem (CPU total)=8841.94140625MB
INFO:root:[   59] Training loss: 0.42785465, Validation loss: 0.43674593, Gradient norm: 4.51478608
INFO:root:At the start of the epoch: mem (CPU python)=5709.31640625MB; mem (CPU total)=8851.72265625MB
INFO:root:[   60] Training loss: 0.42922613, Validation loss: 0.41644618, Gradient norm: 4.27255141
INFO:root:At the start of the epoch: mem (CPU python)=5731.18359375MB; mem (CPU total)=8877.55859375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.42065858, Validation loss: 0.40254809, Gradient norm: 4.21452718
INFO:root:At the start of the epoch: mem (CPU python)=5752.05078125MB; mem (CPU total)=8902.96875MB
INFO:root:[   62] Training loss: 0.39503103, Validation loss: 0.38328723, Gradient norm: 3.43595864
INFO:root:At the start of the epoch: mem (CPU python)=5773.875MB; mem (CPU total)=8922.17578125MB
INFO:root:[   63] Training loss: 0.39420335, Validation loss: 0.39396907, Gradient norm: 3.55085846
INFO:root:At the start of the epoch: mem (CPU python)=5794.25MB; mem (CPU total)=8947.26953125MB
INFO:root:[   64] Training loss: 0.39190364, Validation loss: 0.38535288, Gradient norm: 4.14857571
INFO:root:At the start of the epoch: mem (CPU python)=5815.890625MB; mem (CPU total)=8953.8125MB
INFO:root:[   65] Training loss: 0.39192980, Validation loss: 0.38351111, Gradient norm: 4.57133523
INFO:root:At the start of the epoch: mem (CPU python)=5836.921875MB; mem (CPU total)=8933.0703125MB
INFO:root:[   66] Training loss: 0.39148333, Validation loss: 0.38662499, Gradient norm: 4.80857909
INFO:root:At the start of the epoch: mem (CPU python)=5858.00390625MB; mem (CPU total)=9003.38671875MB
INFO:root:[   67] Training loss: 0.39273960, Validation loss: 0.38293174, Gradient norm: 5.05824494
INFO:root:At the start of the epoch: mem (CPU python)=5879.76171875MB; mem (CPU total)=9016.0625MB
INFO:root:[   68] Training loss: 0.39132268, Validation loss: 0.39375139, Gradient norm: 4.96473132
INFO:root:At the start of the epoch: mem (CPU python)=5902.1640625MB; mem (CPU total)=8991.7421875MB
INFO:root:[   69] Training loss: 0.38870270, Validation loss: 0.38725398, Gradient norm: 5.32102512
INFO:root:At the start of the epoch: mem (CPU python)=5921.74609375MB; mem (CPU total)=9056.03515625MB
INFO:root:[   70] Training loss: 0.39163384, Validation loss: 0.39415849, Gradient norm: 5.51649972
INFO:root:At the start of the epoch: mem (CPU python)=5942.91015625MB; mem (CPU total)=9088.0546875MB
INFO:root:[   71] Training loss: 0.38980327, Validation loss: 0.37796749, Gradient norm: 6.11560433
INFO:root:At the start of the epoch: mem (CPU python)=5963.84765625MB; mem (CPU total)=9005.17578125MB
INFO:root:[   72] Training loss: 0.39306540, Validation loss: 0.37775474, Gradient norm: 6.63585699
INFO:root:At the start of the epoch: mem (CPU python)=5985.00390625MB; mem (CPU total)=9119.515625MB
INFO:root:[   73] Training loss: 0.39078445, Validation loss: 0.39694479, Gradient norm: 6.08537026
INFO:root:At the start of the epoch: mem (CPU python)=6006.6953125MB; mem (CPU total)=9141.32421875MB
INFO:root:[   74] Training loss: 0.38852271, Validation loss: 0.37494225, Gradient norm: 6.08014125
INFO:root:At the start of the epoch: mem (CPU python)=6028.828125MB; mem (CPU total)=9166.64453125MB
INFO:root:[   75] Training loss: 0.39356828, Validation loss: 0.39751081, Gradient norm: 6.48967614
INFO:root:At the start of the epoch: mem (CPU python)=6050.84765625MB; mem (CPU total)=9138.7890625MB
INFO:root:[   76] Training loss: 0.39311098, Validation loss: 0.40376516, Gradient norm: 6.82229291
INFO:root:At the start of the epoch: mem (CPU python)=6071.94140625MB; mem (CPU total)=9052.87890625MB
INFO:root:[   77] Training loss: 0.39382003, Validation loss: 0.39638719, Gradient norm: 6.72139663
INFO:root:At the start of the epoch: mem (CPU python)=6093.015625MB; mem (CPU total)=9222.2890625MB
INFO:root:[   78] Training loss: 0.39002873, Validation loss: 0.38049280, Gradient norm: 6.96504422
INFO:root:At the start of the epoch: mem (CPU python)=6114.3984375MB; mem (CPU total)=9232.49609375MB
INFO:root:[   79] Training loss: 0.39240252, Validation loss: 0.39329041, Gradient norm: 7.09860749
INFO:root:At the start of the epoch: mem (CPU python)=6136.48046875MB; mem (CPU total)=9266.64453125MB
INFO:root:[   80] Training loss: 0.39210091, Validation loss: 0.39272290, Gradient norm: 6.90072197
INFO:root:At the start of the epoch: mem (CPU python)=6158.26953125MB; mem (CPU total)=9278.50390625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   81] Training loss: 0.39007103, Validation loss: 0.38785595, Gradient norm: 7.28082596
INFO:root:At the start of the epoch: mem (CPU python)=6179.765625MB; mem (CPU total)=9045.88671875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   82] Training loss: 0.37739296, Validation loss: 0.36952413, Gradient norm: 5.23721886
INFO:root:At the start of the epoch: mem (CPU python)=6200.296875MB; mem (CPU total)=9340.11328125MB
INFO:root:[   83] Training loss: 0.36928738, Validation loss: 0.36212802, Gradient norm: 3.48561853
INFO:root:At the start of the epoch: mem (CPU python)=6222.88671875MB; mem (CPU total)=9362.328125MB
INFO:root:[   84] Training loss: 0.36832051, Validation loss: 0.36150278, Gradient norm: 3.92590278
INFO:root:At the start of the epoch: mem (CPU python)=6243.65234375MB; mem (CPU total)=9377.390625MB
INFO:root:[   85] Training loss: 0.36815442, Validation loss: 0.36095704, Gradient norm: 4.40017665
INFO:root:At the start of the epoch: mem (CPU python)=6264.1171875MB; mem (CPU total)=9397.578125MB
INFO:root:[   86] Training loss: 0.36929072, Validation loss: 0.36092911, Gradient norm: 4.75382595
INFO:root:At the start of the epoch: mem (CPU python)=6285.9453125MB; mem (CPU total)=9379.66796875MB
INFO:root:[   87] Training loss: 0.36749068, Validation loss: 0.36227090, Gradient norm: 5.01183229
INFO:root:At the start of the epoch: mem (CPU python)=6308.5546875MB; mem (CPU total)=9449.3671875MB
INFO:root:[   88] Training loss: 0.36765640, Validation loss: 0.36203401, Gradient norm: 5.89249870
INFO:root:At the start of the epoch: mem (CPU python)=6327.97265625MB; mem (CPU total)=9396.49609375MB
INFO:root:[   89] Training loss: 0.36713610, Validation loss: 0.35985813, Gradient norm: 5.89667601
INFO:root:At the start of the epoch: mem (CPU python)=6350.4765625MB; mem (CPU total)=9487.2265625MB
INFO:root:[   90] Training loss: 0.36681716, Validation loss: 0.36044983, Gradient norm: 6.37848068
INFO:root:At the start of the epoch: mem (CPU python)=6369.6640625MB; mem (CPU total)=9506.6875MB
INFO:root:[   91] Training loss: 0.36658930, Validation loss: 0.35971179, Gradient norm: 6.47931362
INFO:root:At the start of the epoch: mem (CPU python)=6392.875MB; mem (CPU total)=9521.02734375MB
INFO:root:[   92] Training loss: 0.36652413, Validation loss: 0.36181718, Gradient norm: 6.83687778
INFO:root:At the start of the epoch: mem (CPU python)=6414.3671875MB; mem (CPU total)=9554.1875MB
INFO:root:[   93] Training loss: 0.36655126, Validation loss: 0.36153169, Gradient norm: 7.18134086
INFO:root:At the start of the epoch: mem (CPU python)=6434.19921875MB; mem (CPU total)=9571.97265625MB
INFO:root:[   94] Training loss: 0.36669114, Validation loss: 0.35835051, Gradient norm: 7.36478835
INFO:root:At the start of the epoch: mem (CPU python)=6456.81640625MB; mem (CPU total)=9587.32421875MB
INFO:root:[   95] Training loss: 0.36788984, Validation loss: 0.36063918, Gradient norm: 7.41760242
INFO:root:At the start of the epoch: mem (CPU python)=6477.5MB; mem (CPU total)=9596.60546875MB
INFO:root:[   96] Training loss: 0.36653537, Validation loss: 0.35890421, Gradient norm: 8.08980124
INFO:root:At the start of the epoch: mem (CPU python)=6498.6484375MB; mem (CPU total)=9644.87109375MB
INFO:root:[   97] Training loss: 0.36633778, Validation loss: 0.35875674, Gradient norm: 8.40929942
INFO:root:At the start of the epoch: mem (CPU python)=6521.1875MB; mem (CPU total)=9660.04296875MB
INFO:root:[   98] Training loss: 0.36619799, Validation loss: 0.36112424, Gradient norm: 8.46035943
INFO:root:At the start of the epoch: mem (CPU python)=6541.609375MB; mem (CPU total)=9673.78125MB
INFO:root:[   99] Training loss: 0.36668952, Validation loss: 0.37744508, Gradient norm: 8.82759242
INFO:root:At the start of the epoch: mem (CPU python)=6562.3359375MB; mem (CPU total)=9694.046875MB
INFO:root:[  100] Training loss: 0.37207430, Validation loss: 0.36439575, Gradient norm: 12.80356139
INFO:root:At the start of the epoch: mem (CPU python)=6583.69140625MB; mem (CPU total)=9713.76171875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[  101] Training loss: 0.36995565, Validation loss: 0.36005551, Gradient norm: 10.88496487
INFO:root:At the start of the epoch: mem (CPU python)=6604.54296875MB; mem (CPU total)=9745.46875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  102] Training loss: 0.36528499, Validation loss: 0.35705600, Gradient norm: 6.13364119
INFO:root:At the start of the epoch: mem (CPU python)=6627.3203125MB; mem (CPU total)=9759.06640625MB
INFO:root:[  103] Training loss: 0.36229490, Validation loss: 0.35505819, Gradient norm: 3.68221840
INFO:root:At the start of the epoch: mem (CPU python)=6648.28515625MB; mem (CPU total)=9781.40625MB
INFO:root:[  104] Training loss: 0.36259274, Validation loss: 0.35545448, Gradient norm: 3.65499361
INFO:root:At the start of the epoch: mem (CPU python)=6670.1796875MB; mem (CPU total)=9800.2265625MB
INFO:root:[  105] Training loss: 0.36152278, Validation loss: 0.35489656, Gradient norm: 3.67946664
INFO:root:At the start of the epoch: mem (CPU python)=6692.07421875MB; mem (CPU total)=9824.6015625MB
INFO:root:[  106] Training loss: 0.36110471, Validation loss: 0.35530394, Gradient norm: 4.08231351
INFO:root:At the start of the epoch: mem (CPU python)=6713.7890625MB; mem (CPU total)=9853.06640625MB
INFO:root:[  107] Training loss: 0.36186267, Validation loss: 0.35534947, Gradient norm: 5.68455776
INFO:root:At the start of the epoch: mem (CPU python)=6735.171875MB; mem (CPU total)=9867.76953125MB
INFO:root:[  108] Training loss: 0.36115748, Validation loss: 0.35440649, Gradient norm: 5.34552572
INFO:root:At the start of the epoch: mem (CPU python)=6756.79296875MB; mem (CPU total)=9891.1796875MB
INFO:root:[  109] Training loss: 0.36132449, Validation loss: 0.35459401, Gradient norm: 6.17697816
INFO:root:At the start of the epoch: mem (CPU python)=6778.4609375MB; mem (CPU total)=9867.1015625MB
INFO:root:[  110] Training loss: 0.36114463, Validation loss: 0.35500840, Gradient norm: 4.45906370
INFO:root:At the start of the epoch: mem (CPU python)=6800.46484375MB; mem (CPU total)=9931.8828125MB
INFO:root:[  111] Training loss: 0.36025929, Validation loss: 0.35468718, Gradient norm: 5.31038678
INFO:root:At the start of the epoch: mem (CPU python)=6821.78125MB; mem (CPU total)=9972.05859375MB
INFO:root:[  112] Training loss: 0.36096820, Validation loss: 0.35484056, Gradient norm: 5.01113963
INFO:root:At the start of the epoch: mem (CPU python)=6842.9453125MB; mem (CPU total)=9969.73046875MB
INFO:root:[  113] Training loss: 0.36113150, Validation loss: 0.35427690, Gradient norm: 5.34616983
INFO:root:At the start of the epoch: mem (CPU python)=6864.109375MB; mem (CPU total)=9971.90625MB
INFO:root:[  114] Training loss: 0.36093699, Validation loss: 0.35456620, Gradient norm: 5.62610417
INFO:root:At the start of the epoch: mem (CPU python)=6885.2734375MB; mem (CPU total)=10017.61328125MB
INFO:root:[  115] Training loss: 0.36111623, Validation loss: 0.35485338, Gradient norm: 6.16018087
INFO:root:At the start of the epoch: mem (CPU python)=6906.4453125MB; mem (CPU total)=10026.73046875MB
INFO:root:[  116] Training loss: 0.36063365, Validation loss: 0.35437680, Gradient norm: 5.95921148
INFO:root:At the start of the epoch: mem (CPU python)=6928.359375MB; mem (CPU total)=10051.0859375MB
INFO:root:[  117] Training loss: 0.36071618, Validation loss: 0.35523459, Gradient norm: 6.59286795
INFO:root:At the start of the epoch: mem (CPU python)=6949.77734375MB; mem (CPU total)=10085.76953125MB
INFO:root:[  118] Training loss: 0.36171877, Validation loss: 0.35403636, Gradient norm: 9.61096204
INFO:root:At the start of the epoch: mem (CPU python)=6971.44140625MB; mem (CPU total)=10108.19140625MB
INFO:root:[  119] Training loss: 0.36092402, Validation loss: 0.35446881, Gradient norm: 7.01735897
INFO:root:At the start of the epoch: mem (CPU python)=6992.6171875MB; mem (CPU total)=10115.65625MB
INFO:root:[  120] Training loss: 0.36041198, Validation loss: 0.35476542, Gradient norm: 5.98173719
INFO:root:At the start of the epoch: mem (CPU python)=7013.78515625MB; mem (CPU total)=10150.1484375MB
INFO:root:[  121] Training loss: 0.36175864, Validation loss: 0.35457161, Gradient norm: 7.37474270
INFO:root:At the start of the epoch: mem (CPU python)=7034.9453125MB; mem (CPU total)=10171.45703125MB
INFO:root:[  122] Training loss: 0.36065056, Validation loss: 0.35420980, Gradient norm: 6.72887964
INFO:root:At the start of the epoch: mem (CPU python)=7056.1171875MB; mem (CPU total)=10190.3515625MB
INFO:root:[  123] Training loss: 0.36063050, Validation loss: 0.35417278, Gradient norm: 6.49727933
INFO:root:At the start of the epoch: mem (CPU python)=7077.28515625MB; mem (CPU total)=10203.12109375MB
INFO:root:[  124] Training loss: 0.36105286, Validation loss: 0.35475716, Gradient norm: 6.61160750
INFO:root:At the start of the epoch: mem (CPU python)=7098.44921875MB; mem (CPU total)=10237.23828125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  125] Training loss: 0.36193388, Validation loss: 0.35632138, Gradient norm: 9.14589980
INFO:root:At the start of the epoch: mem (CPU python)=7119.703125MB; mem (CPU total)=10258.05078125MB
INFO:root:[  126] Training loss: 0.36018688, Validation loss: 0.35319975, Gradient norm: 5.23109718
INFO:root:At the start of the epoch: mem (CPU python)=7140.86328125MB; mem (CPU total)=10279.7890625MB
INFO:root:[  127] Training loss: 0.35955836, Validation loss: 0.35378512, Gradient norm: 4.96925445
INFO:root:At the start of the epoch: mem (CPU python)=7162.3203125MB; mem (CPU total)=10302.5546875MB
INFO:root:[  128] Training loss: 0.36011964, Validation loss: 0.35337852, Gradient norm: 5.27225882
INFO:root:At the start of the epoch: mem (CPU python)=7182.015625MB; mem (CPU total)=10316.8359375MB
INFO:root:[  129] Training loss: 0.35971007, Validation loss: 0.35351318, Gradient norm: 5.64134317
INFO:root:At the start of the epoch: mem (CPU python)=7202.92578125MB; mem (CPU total)=10320.9453125MB
INFO:root:[  130] Training loss: 0.35962845, Validation loss: 0.35286018, Gradient norm: 4.97757317
INFO:root:At the start of the epoch: mem (CPU python)=7224.46484375MB; mem (CPU total)=10337.9375MB
INFO:root:[  131] Training loss: 0.35987112, Validation loss: 0.35393066, Gradient norm: 5.72557411
INFO:root:At the start of the epoch: mem (CPU python)=7245.62890625MB; mem (CPU total)=10382.46875MB
INFO:root:[  132] Training loss: 0.35979407, Validation loss: 0.35338810, Gradient norm: 7.04533881
INFO:root:At the start of the epoch: mem (CPU python)=7268.03515625MB; mem (CPU total)=10407.20703125MB
INFO:root:[  133] Training loss: 0.35911794, Validation loss: 0.35379241, Gradient norm: 5.72254282
INFO:root:At the start of the epoch: mem (CPU python)=7289.7890625MB; mem (CPU total)=10409.80859375MB
INFO:root:[  134] Training loss: 0.35964030, Validation loss: 0.35321701, Gradient norm: 6.94309901
INFO:root:At the start of the epoch: mem (CPU python)=7311.140625MB; mem (CPU total)=10430.609375MB
INFO:root:[  135] Training loss: 0.35938765, Validation loss: 0.35381486, Gradient norm: 6.24702285
INFO:root:At the start of the epoch: mem (CPU python)=7332.546875MB; mem (CPU total)=10487.87890625MB
INFO:root:[  136] Training loss: 0.35930763, Validation loss: 0.35331554, Gradient norm: 6.17508445
INFO:root:At the start of the epoch: mem (CPU python)=7354.51953125MB; mem (CPU total)=10493.66796875MB
INFO:root:[  137] Training loss: 0.35987397, Validation loss: 0.35363326, Gradient norm: 5.73399301
INFO:root:At the start of the epoch: mem (CPU python)=7376.1484375MB; mem (CPU total)=10509.5234375MB
INFO:root:[  138] Training loss: 0.35900944, Validation loss: 0.35341650, Gradient norm: 6.00612479
INFO:root:At the start of the epoch: mem (CPU python)=7395.83984375MB; mem (CPU total)=10527.90625MB
INFO:root:[  139] Training loss: 0.35967034, Validation loss: 0.35312262, Gradient norm: 6.69725952
INFO:root:At the start of the epoch: mem (CPU python)=7417.74609375MB; mem (CPU total)=10546.71484375MB
INFO:root:[  140] Training loss: 0.35977103, Validation loss: 0.35263472, Gradient norm: 6.80492529
INFO:root:At the start of the epoch: mem (CPU python)=7437.8359375MB; mem (CPU total)=10576.6171875MB
INFO:root:[  141] Training loss: 0.35936234, Validation loss: 0.35291368, Gradient norm: 6.08116510
INFO:root:At the start of the epoch: mem (CPU python)=7459.734375MB; mem (CPU total)=10592.4375MB
INFO:root:[  142] Training loss: 0.35964701, Validation loss: 0.35257693, Gradient norm: 7.72482940
INFO:root:At the start of the epoch: mem (CPU python)=7480.5703125MB; mem (CPU total)=10599.4921875MB
INFO:root:[  143] Training loss: 0.35933670, Validation loss: 0.35342268, Gradient norm: 7.23380611
INFO:root:At the start of the epoch: mem (CPU python)=7503.2421875MB; mem (CPU total)=10609.0546875MB
INFO:root:[  144] Training loss: 0.35878116, Validation loss: 0.35330432, Gradient norm: 7.64539387
INFO:root:At the start of the epoch: mem (CPU python)=7523.16015625MB; mem (CPU total)=10655.48046875MB
INFO:root:[  145] Training loss: 0.35964494, Validation loss: 0.35348033, Gradient norm: 7.02368150
INFO:root:At the start of the epoch: mem (CPU python)=7546.51171875MB; mem (CPU total)=10668.51171875MB
INFO:root:[  146] Training loss: 0.35938809, Validation loss: 0.35335787, Gradient norm: 6.28839385
INFO:root:At the start of the epoch: mem (CPU python)=7566.8359375MB; mem (CPU total)=10699.984375MB
INFO:root:[  147] Training loss: 0.35922517, Validation loss: 0.35285327, Gradient norm: 7.75939478
INFO:root:At the start of the epoch: mem (CPU python)=7586.3125MB; mem (CPU total)=10718.5390625MB
INFO:root:[  148] Training loss: 0.35964454, Validation loss: 0.35224605, Gradient norm: 7.30301829
INFO:root:At the start of the epoch: mem (CPU python)=7608.7109375MB; mem (CPU total)=10743.23046875MB
INFO:root:[  149] Training loss: 0.36046583, Validation loss: 0.35312616, Gradient norm: 7.22833828
INFO:root:At the start of the epoch: mem (CPU python)=7630.03515625MB; mem (CPU total)=10717.82421875MB
INFO:root:[  150] Training loss: 0.35913865, Validation loss: 0.35308264, Gradient norm: 7.72079977
INFO:root:At the start of the epoch: mem (CPU python)=7651.30859375MB; mem (CPU total)=10775.5390625MB
INFO:root:[  151] Training loss: 0.35945361, Validation loss: 0.35276596, Gradient norm: 8.44334474
INFO:root:At the start of the epoch: mem (CPU python)=7673.1484375MB; mem (CPU total)=10794.76953125MB
INFO:root:[  152] Training loss: 0.35942553, Validation loss: 0.35298021, Gradient norm: 7.33690899
INFO:root:At the start of the epoch: mem (CPU python)=7693.35546875MB; mem (CPU total)=10827.26953125MB
INFO:root:[  153] Training loss: 0.35938939, Validation loss: 0.35348524, Gradient norm: 9.64257371
INFO:root:At the start of the epoch: mem (CPU python)=7715.51953125MB; mem (CPU total)=10852.87890625MB
INFO:root:[  154] Training loss: 0.35970469, Validation loss: 0.35285003, Gradient norm: 11.01366023
INFO:root:At the start of the epoch: mem (CPU python)=7736.76171875MB; mem (CPU total)=10873.97265625MB
INFO:root:[  155] Training loss: 0.35942010, Validation loss: 0.35274218, Gradient norm: 9.37601059
INFO:root:At the start of the epoch: mem (CPU python)=7758.9140625MB; mem (CPU total)=10900.13671875MB
INFO:root:[  156] Training loss: 0.35929213, Validation loss: 0.35313515, Gradient norm: 7.87381248
INFO:root:At the start of the epoch: mem (CPU python)=7779.92578125MB; mem (CPU total)=10901.44921875MB
INFO:root:[  157] Training loss: 0.35901603, Validation loss: 0.35276789, Gradient norm: 7.76046756
INFO:root:At the start of the epoch: mem (CPU python)=7801.12890625MB; mem (CPU total)=10940.42578125MB
INFO:root:EP 157: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=7822.109375MB; mem (CPU total)=10951.55859375MB
INFO:root:[  159] Training loss: 0.44271625, Validation loss: 0.43089877, Gradient norm: 28.92361198
INFO:root:At the start of the epoch: mem (CPU python)=7843.37109375MB; mem (CPU total)=10984.21875MB
INFO:root:[  160] Training loss: 0.44048577, Validation loss: 0.42999385, Gradient norm: 27.47152202
INFO:root:At the start of the epoch: mem (CPU python)=7864.7421875MB; mem (CPU total)=11005.03515625MB
INFO:root:[  161] Training loss: 0.44083181, Validation loss: 0.43030805, Gradient norm: 29.71192905
INFO:root:At the start of the epoch: mem (CPU python)=7884.37890625MB; mem (CPU total)=11014.7265625MB
INFO:root:[  162] Training loss: 0.44091975, Validation loss: 0.43017749, Gradient norm: 27.95746113
INFO:root:At the start of the epoch: mem (CPU python)=7905.53515625MB; mem (CPU total)=11030.1171875MB
INFO:root:[  163] Training loss: 0.43979261, Validation loss: 0.42908772, Gradient norm: 27.22345765
INFO:root:At the start of the epoch: mem (CPU python)=7928.57421875MB; mem (CPU total)=11048.265625MB
INFO:root:[  164] Training loss: 0.43942756, Validation loss: 0.43118236, Gradient norm: 18.63330251
INFO:root:At the start of the epoch: mem (CPU python)=7948.546875MB; mem (CPU total)=11074.640625MB
INFO:root:[  165] Training loss: 0.43952764, Validation loss: 0.42944634, Gradient norm: 23.40912866
INFO:root:At the start of the epoch: mem (CPU python)=7970.97265625MB; mem (CPU total)=11081.94140625MB
INFO:root:[  166] Training loss: 0.43901041, Validation loss: 0.42907671, Gradient norm: 22.68070963
INFO:root:At the start of the epoch: mem (CPU python)=7991.36328125MB; mem (CPU total)=11114.17578125MB
INFO:root:[  167] Training loss: 0.43928699, Validation loss: 0.42982678, Gradient norm: 22.37034092
INFO:root:At the start of the epoch: mem (CPU python)=8013.13671875MB; mem (CPU total)=11142.72265625MB
INFO:root:[  168] Training loss: 0.43872097, Validation loss: 0.42851787, Gradient norm: 23.13978931
INFO:root:At the start of the epoch: mem (CPU python)=8034.25MB; mem (CPU total)=11156.62890625MB
INFO:root:[  169] Training loss: 0.43801557, Validation loss: 0.42869077, Gradient norm: 17.91524048
INFO:root:At the start of the epoch: mem (CPU python)=8055.76171875MB; mem (CPU total)=11176.81640625MB
INFO:root:[  170] Training loss: 0.43921685, Validation loss: 0.42997860, Gradient norm: 31.88253459
INFO:root:At the start of the epoch: mem (CPU python)=8078.34765625MB; mem (CPU total)=11221.90234375MB
INFO:root:[  171] Training loss: 0.43823424, Validation loss: 0.42829279, Gradient norm: 23.07965591
INFO:root:At the start of the epoch: mem (CPU python)=8096.9140625MB; mem (CPU total)=11205.14453125MB
INFO:root:[  172] Training loss: 0.43894264, Validation loss: 0.42891378, Gradient norm: 23.98645543
INFO:root:At the start of the epoch: mem (CPU python)=8119.16015625MB; mem (CPU total)=11243.06640625MB
INFO:root:[  173] Training loss: 0.43890492, Validation loss: 0.42991234, Gradient norm: 27.30330875
INFO:root:At the start of the epoch: mem (CPU python)=8140.28515625MB; mem (CPU total)=11260.9453125MB
INFO:root:[  174] Training loss: 0.43870228, Validation loss: 0.43179341, Gradient norm: 21.32805633
INFO:root:At the start of the epoch: mem (CPU python)=8162.65234375MB; mem (CPU total)=11299.1015625MB
INFO:root:[  175] Training loss: 0.43813317, Validation loss: 0.42845775, Gradient norm: 22.67996408
INFO:root:At the start of the epoch: mem (CPU python)=8183.6875MB; mem (CPU total)=11308.59765625MB
INFO:root:[  176] Training loss: 0.43825456, Validation loss: 0.42796503, Gradient norm: 24.56987483
INFO:root:At the start of the epoch: mem (CPU python)=8205.08984375MB; mem (CPU total)=11336.3828125MB
INFO:root:[  177] Training loss: 0.43789302, Validation loss: 0.42839463, Gradient norm: 18.36680100
INFO:root:At the start of the epoch: mem (CPU python)=8209.6171875MB; mem (CPU total)=11337.37890625MB
INFO:root:[  178] Training loss: 0.43821547, Validation loss: 0.42816105, Gradient norm: 21.97667531
INFO:root:At the start of the epoch: mem (CPU python)=8228.85546875MB; mem (CPU total)=11354.3515625MB
INFO:root:[  179] Training loss: 0.43770266, Validation loss: 0.42811629, Gradient norm: 20.84002588
INFO:root:At the start of the epoch: mem (CPU python)=8250.0234375MB; mem (CPU total)=11368.20703125MB
INFO:root:[  180] Training loss: 0.43830741, Validation loss: 0.42854982, Gradient norm: 22.24068981
INFO:root:At the start of the epoch: mem (CPU python)=8271.1875MB; mem (CPU total)=11390.92578125MB
INFO:root:[  181] Training loss: 0.43790578, Validation loss: 0.42766505, Gradient norm: 23.77611930
INFO:root:At the start of the epoch: mem (CPU python)=8292.3515625MB; mem (CPU total)=11419.2578125MB
INFO:root:[  182] Training loss: 0.43772586, Validation loss: 0.42886639, Gradient norm: 22.22482265
INFO:root:At the start of the epoch: mem (CPU python)=8313.51171875MB; mem (CPU total)=11803.01171875MB
INFO:root:[  183] Training loss: 0.43765089, Validation loss: 0.42898808, Gradient norm: 22.03381361
INFO:root:At the start of the epoch: mem (CPU python)=8334.67578125MB; mem (CPU total)=11812.31640625MB
INFO:root:[  184] Training loss: 0.43757294, Validation loss: 0.42789788, Gradient norm: 20.67343261
INFO:root:At the start of the epoch: mem (CPU python)=8355.84375MB; mem (CPU total)=11481.7265625MB
INFO:root:[  185] Training loss: 0.43809070, Validation loss: 0.42818559, Gradient norm: 26.18965775
INFO:root:At the start of the epoch: mem (CPU python)=8377.0078125MB; mem (CPU total)=11531.33203125MB
INFO:root:[  186] Training loss: 0.43765666, Validation loss: 0.42796551, Gradient norm: 22.84367177
INFO:root:At the start of the epoch: mem (CPU python)=8398.171875MB; mem (CPU total)=12336.19140625MB
INFO:root:[  187] Training loss: 0.43777266, Validation loss: 0.42824075, Gradient norm: 19.65931635
INFO:root:At the start of the epoch: mem (CPU python)=8419.33984375MB; mem (CPU total)=12349.078125MB
INFO:root:[  188] Training loss: 0.43732181, Validation loss: 0.42785695, Gradient norm: 21.26373518
INFO:root:At the start of the epoch: mem (CPU python)=8440.50390625MB; mem (CPU total)=12367.2578125MB
INFO:root:[  189] Training loss: 0.43689590, Validation loss: 0.42966822, Gradient norm: 21.86136771
INFO:root:At the start of the epoch: mem (CPU python)=8461.6640625MB; mem (CPU total)=11605.859375MB
INFO:root:[  190] Training loss: 0.43754089, Validation loss: 0.42767757, Gradient norm: 24.34297077
INFO:root:At the start of the epoch: mem (CPU python)=8483.08984375MB; mem (CPU total)=11633.71484375MB
INFO:root:[  191] Training loss: 0.43757621, Validation loss: 0.42737789, Gradient norm: 22.39409751
INFO:root:At the start of the epoch: mem (CPU python)=8504.25390625MB; mem (CPU total)=11654.36328125MB
INFO:root:[  192] Training loss: 0.43742649, Validation loss: 0.42725003, Gradient norm: 31.08730853
INFO:root:At the start of the epoch: mem (CPU python)=8525.90625MB; mem (CPU total)=11673.49609375MB
INFO:root:[  193] Training loss: 0.43738402, Validation loss: 0.42778035, Gradient norm: 22.98182421
INFO:root:At the start of the epoch: mem (CPU python)=8547.0703125MB; mem (CPU total)=11710.875MB
INFO:root:[  194] Training loss: 0.43710364, Validation loss: 0.42697592, Gradient norm: 23.23723228
INFO:root:At the start of the epoch: mem (CPU python)=8568.23828125MB; mem (CPU total)=11728.01171875MB
INFO:root:[  195] Training loss: 0.43698242, Validation loss: 0.42702170, Gradient norm: 20.71063189
INFO:root:At the start of the epoch: mem (CPU python)=8589.3984375MB; mem (CPU total)=11754.51953125MB
INFO:root:[  196] Training loss: 0.43712208, Validation loss: 0.42772666, Gradient norm: 19.27480750
INFO:root:At the start of the epoch: mem (CPU python)=8610.56640625MB; mem (CPU total)=11755.13671875MB
INFO:root:[  197] Training loss: 0.43735529, Validation loss: 0.42900427, Gradient norm: 25.86422522
INFO:root:At the start of the epoch: mem (CPU python)=8631.73046875MB; mem (CPU total)=11788.54296875MB
INFO:root:[  198] Training loss: 0.43728590, Validation loss: 0.42767543, Gradient norm: 25.48224704
INFO:root:At the start of the epoch: mem (CPU python)=8652.89453125MB; mem (CPU total)=11824.171875MB
INFO:root:[  199] Training loss: 0.43704960, Validation loss: 0.42737436, Gradient norm: 22.17630482
INFO:root:At the start of the epoch: mem (CPU python)=8674.0625MB; mem (CPU total)=11823.6328125MB
INFO:root:[  200] Training loss: 0.43646908, Validation loss: 0.42788017, Gradient norm: 20.84500339
INFO:root:At the start of the epoch: mem (CPU python)=8695.2265625MB; mem (CPU total)=11837.9609375MB
INFO:root:[  201] Training loss: 0.43714155, Validation loss: 0.42721145, Gradient norm: 23.33296140
INFO:root:At the start of the epoch: mem (CPU python)=8716.390625MB; mem (CPU total)=11885.59375MB
INFO:root:[  202] Training loss: 0.43725036, Validation loss: 0.42718488, Gradient norm: 20.41282499
INFO:root:At the start of the epoch: mem (CPU python)=8737.5546875MB; mem (CPU total)=11901.0703125MB
INFO:root:[  203] Training loss: 0.43675404, Validation loss: 0.42708666, Gradient norm: 28.60640188
INFO:root:At the start of the epoch: mem (CPU python)=8758.71875MB; mem (CPU total)=11902.8828125MB
INFO:root:EP 203: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=8779.8828125MB; mem (CPU total)=11923.7265625MB
INFO:root:Training the model took 5625.303s.
INFO:root:Emptying the cuda cache took 0.049s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification deterministic
INFO:root:Evaluating the model on Validation data.
