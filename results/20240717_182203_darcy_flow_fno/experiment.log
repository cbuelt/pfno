INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:############### Starting experiment with config file darcy_flow/fno.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'DarcyFlow', 'max_training_set_size': 10000, 'downscaling_factor': 2}
INFO:root:###1 out of 48 training parameter combinations ###
INFO:root:Training parameters: {'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.0001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': 0.01, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:NumberParameters: 710305
INFO:root:Memory allocated: 4194304
INFO:root:Training starts now.
INFO:root:[    1] Training loss: 0.05557221, Validation loss: 1.84681235, Gradient norm: 0.66333786
INFO:root:[    2] Training loss: 0.02614351, Validation loss: 1.29044240, Gradient norm: 0.82754323
INFO:root:[    3] Training loss: 0.02000679, Validation loss: 0.99048319, Gradient norm: 0.79017440
INFO:root:[    4] Training loss: 0.01750037, Validation loss: 0.93251082, Gradient norm: 0.68148831
INFO:root:[    5] Training loss: 0.01664063, Validation loss: 0.86324354, Gradient norm: 0.68032667
INFO:root:[    6] Training loss: 0.01538628, Validation loss: 1.04325121, Gradient norm: 0.62207449
INFO:root:[    7] Training loss: 0.01469396, Validation loss: 0.91714943, Gradient norm: 0.62988418
INFO:root:[    8] Training loss: 0.01369478, Validation loss: 0.76181525, Gradient norm: 0.56013712
INFO:root:[    9] Training loss: 0.01322453, Validation loss: 0.67911480, Gradient norm: 0.58490604
INFO:root:[   10] Training loss: 0.01210556, Validation loss: 0.64291437, Gradient norm: 0.47785065
INFO:root:[   11] Training loss: 0.01195275, Validation loss: 0.70253916, Gradient norm: 0.51313210
INFO:root:[   12] Training loss: 0.01139777, Validation loss: 0.60884657, Gradient norm: 0.50180248
INFO:root:[   13] Training loss: 0.01107541, Validation loss: 0.56928996, Gradient norm: 0.49183088
INFO:root:[   14] Training loss: 0.01049733, Validation loss: 0.57488591, Gradient norm: 0.37813238
INFO:root:[   15] Training loss: 0.01015295, Validation loss: 0.58508171, Gradient norm: 0.38683116
