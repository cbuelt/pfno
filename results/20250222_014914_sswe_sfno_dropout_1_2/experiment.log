INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=584.48828125MB; mem (CPU total)=7888.75390625MB
INFO:root:############### Starting experiment with config file sswe/sfno_dropout_1_2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=595.36328125MB; mem (CPU total)=7892.73046875MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=597.0234375MB; mem (CPU total)=7892.51171875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2241.86328125MB; mem (CPU total)=9265.77734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2251.51171875MB; mem (CPU total)=9277.58984375MB
INFO:root:[    1] Training loss: 0.76703233, Validation loss: 0.72087687, Gradient norm: 0.49975548
INFO:root:At the start of the epoch: mem (CPU python)=4410.390625MB; mem (CPU total)=11006.26953125MB
INFO:root:[    2] Training loss: 0.66609289, Validation loss: 0.59928291, Gradient norm: 0.91307301
INFO:root:At the start of the epoch: mem (CPU python)=4433.76953125MB; mem (CPU total)=11119.1171875MB
INFO:root:[    3] Training loss: 0.57588816, Validation loss: 0.56429507, Gradient norm: 1.30755252
INFO:root:At the start of the epoch: mem (CPU python)=4457.6171875MB; mem (CPU total)=11019.015625MB
INFO:root:[    4] Training loss: 0.53446197, Validation loss: 0.50346921, Gradient norm: 1.60557570
INFO:root:At the start of the epoch: mem (CPU python)=4478.8359375MB; mem (CPU total)=11042.625MB
INFO:root:[    5] Training loss: 0.50523968, Validation loss: 0.51809730, Gradient norm: 1.90806268
INFO:root:At the start of the epoch: mem (CPU python)=4500.015625MB; mem (CPU total)=11127.66015625MB
INFO:root:[    6] Training loss: 0.49267635, Validation loss: 0.48587039, Gradient norm: 2.08097112
INFO:root:At the start of the epoch: mem (CPU python)=4521.19921875MB; mem (CPU total)=11105.99609375MB
INFO:root:[    7] Training loss: 0.48627320, Validation loss: 0.47426327, Gradient norm: 2.33145565
INFO:root:At the start of the epoch: mem (CPU python)=4542.92578125MB; mem (CPU total)=11133.47265625MB
INFO:root:[    8] Training loss: 0.48243077, Validation loss: 0.49081885, Gradient norm: 2.34226341
INFO:root:At the start of the epoch: mem (CPU python)=4566.671875MB; mem (CPU total)=11149.6640625MB
INFO:root:[    9] Training loss: 0.47798705, Validation loss: 0.47770639, Gradient norm: 2.44947550
INFO:root:At the start of the epoch: mem (CPU python)=4587.87109375MB; mem (CPU total)=11190.62109375MB
INFO:root:[   10] Training loss: 0.47648416, Validation loss: 0.47685375, Gradient norm: 2.51246496
INFO:root:At the start of the epoch: mem (CPU python)=4610.35546875MB; mem (CPU total)=11224.3203125MB
INFO:root:[   11] Training loss: 0.47341304, Validation loss: 0.48625692, Gradient norm: 2.70398725
INFO:root:At the start of the epoch: mem (CPU python)=4634.34765625MB; mem (CPU total)=11214.3203125MB
INFO:root:[   12] Training loss: 0.47016483, Validation loss: 0.46715671, Gradient norm: 2.75657272
INFO:root:At the start of the epoch: mem (CPU python)=4659.171875MB; mem (CPU total)=11237.48046875MB
INFO:root:[   13] Training loss: 0.46739951, Validation loss: 0.45910168, Gradient norm: 2.97759960
INFO:root:At the start of the epoch: mem (CPU python)=4680.68359375MB; mem (CPU total)=11271.94140625MB
INFO:root:[   14] Training loss: 0.46543992, Validation loss: 0.47218714, Gradient norm: 3.11416280
INFO:root:At the start of the epoch: mem (CPU python)=4701.84765625MB; mem (CPU total)=11374.875MB
INFO:root:[   15] Training loss: 0.45993636, Validation loss: 0.46264636, Gradient norm: 3.26223112
INFO:root:At the start of the epoch: mem (CPU python)=4723.02734375MB; mem (CPU total)=11160.67578125MB
INFO:root:[   16] Training loss: 0.45724416, Validation loss: 0.45140238, Gradient norm: 3.31392201
INFO:root:At the start of the epoch: mem (CPU python)=4744.19140625MB; mem (CPU total)=11324.43359375MB
INFO:root:[   17] Training loss: 0.45600022, Validation loss: 0.45860108, Gradient norm: 3.30496481
INFO:root:At the start of the epoch: mem (CPU python)=4765.375MB; mem (CPU total)=11343.26171875MB
INFO:root:[   18] Training loss: 0.45427725, Validation loss: 0.46019440, Gradient norm: 3.24530684
INFO:root:At the start of the epoch: mem (CPU python)=4786.54296875MB; mem (CPU total)=11396.4765625MB
INFO:root:[   19] Training loss: 0.45112825, Validation loss: 0.45376974, Gradient norm: 3.30545094
INFO:root:At the start of the epoch: mem (CPU python)=4807.71484375MB; mem (CPU total)=11399.03125MB
INFO:root:[   20] Training loss: 0.44855299, Validation loss: 0.46935697, Gradient norm: 3.35452187
INFO:root:At the start of the epoch: mem (CPU python)=4828.87890625MB; mem (CPU total)=11367.3046875MB
INFO:root:[   21] Training loss: 0.44831287, Validation loss: 0.44048120, Gradient norm: 3.36824375
INFO:root:At the start of the epoch: mem (CPU python)=4850.0546875MB; mem (CPU total)=11444.17578125MB
INFO:root:[   22] Training loss: 0.44573998, Validation loss: 0.43565335, Gradient norm: 3.58739725
INFO:root:At the start of the epoch: mem (CPU python)=4872.03515625MB; mem (CPU total)=11442.16015625MB
INFO:root:[   23] Training loss: 0.44383804, Validation loss: 0.47739365, Gradient norm: 3.64954535
INFO:root:At the start of the epoch: mem (CPU python)=4893.34765625MB; mem (CPU total)=11498.8203125MB
INFO:root:[   24] Training loss: 0.44454572, Validation loss: 0.43881168, Gradient norm: 3.54278567
INFO:root:At the start of the epoch: mem (CPU python)=4914.51171875MB; mem (CPU total)=11493.8984375MB
INFO:root:[   25] Training loss: 0.44311855, Validation loss: 0.45780623, Gradient norm: 3.88717132
INFO:root:At the start of the epoch: mem (CPU python)=4940.4609375MB; mem (CPU total)=11407.45703125MB
INFO:root:[   26] Training loss: 0.44217358, Validation loss: 0.45256397, Gradient norm: 3.85909506
INFO:root:At the start of the epoch: mem (CPU python)=4962.09765625MB; mem (CPU total)=11620.5546875MB
INFO:root:[   27] Training loss: 0.44289225, Validation loss: 0.46412299, Gradient norm: 3.96502018
INFO:root:At the start of the epoch: mem (CPU python)=4983.265625MB; mem (CPU total)=11570.75390625MB
INFO:root:[   28] Training loss: 0.44290290, Validation loss: 0.45852749, Gradient norm: 4.13398372
INFO:root:At the start of the epoch: mem (CPU python)=5007.1484375MB; mem (CPU total)=11590.984375MB
INFO:root:[   29] Training loss: 0.44184287, Validation loss: 0.45435843, Gradient norm: 4.21957520
INFO:root:At the start of the epoch: mem (CPU python)=5028.32421875MB; mem (CPU total)=11614.6953125MB
INFO:root:[   30] Training loss: 0.44208187, Validation loss: 0.46094031, Gradient norm: 4.44578925
INFO:root:At the start of the epoch: mem (CPU python)=5049.77734375MB; mem (CPU total)=11662.015625MB
INFO:root:[   31] Training loss: 0.44207420, Validation loss: 0.44919791, Gradient norm: 4.45221185
INFO:root:At the start of the epoch: mem (CPU python)=5070.9453125MB; mem (CPU total)=11665.16796875MB
INFO:root:[   32] Training loss: 0.44200580, Validation loss: 0.45221455, Gradient norm: 4.65535299
INFO:root:At the start of the epoch: mem (CPU python)=5091.95703125MB; mem (CPU total)=11682.890625MB
INFO:root:[   33] Training loss: 0.44316025, Validation loss: 0.44268098, Gradient norm: 4.72339692
INFO:root:At the start of the epoch: mem (CPU python)=5114.23046875MB; mem (CPU total)=11724.8984375MB
INFO:root:[   34] Training loss: 0.44176946, Validation loss: 0.46446361, Gradient norm: 4.76910905
INFO:root:At the start of the epoch: mem (CPU python)=5135.48828125MB; mem (CPU total)=11710.3203125MB
INFO:root:[   35] Training loss: 0.43938222, Validation loss: 0.45021348, Gradient norm: 4.83148583
INFO:root:At the start of the epoch: mem (CPU python)=5156.6953125MB; mem (CPU total)=11745.96875MB
INFO:root:[   36] Training loss: 0.43914976, Validation loss: 0.46440199, Gradient norm: 4.90956848
INFO:root:At the start of the epoch: mem (CPU python)=5177.8828125MB; mem (CPU total)=11745.25390625MB
INFO:root:[   37] Training loss: 0.43841359, Validation loss: 0.44347407, Gradient norm: 5.16198622
INFO:root:At the start of the epoch: mem (CPU python)=5199.0703125MB; mem (CPU total)=11783.95703125MB
INFO:root:[   38] Training loss: 0.44074886, Validation loss: 0.43672322, Gradient norm: 5.16128398
INFO:root:At the start of the epoch: mem (CPU python)=5220.25390625MB; mem (CPU total)=11906.78125MB
INFO:root:[   39] Training loss: 0.43982719, Validation loss: 0.43748076, Gradient norm: 5.07058399
INFO:root:At the start of the epoch: mem (CPU python)=5242.66796875MB; mem (CPU total)=11863.875MB
INFO:root:[   40] Training loss: 0.43487668, Validation loss: 0.44101181, Gradient norm: 5.08391819
INFO:root:At the start of the epoch: mem (CPU python)=5264.1796875MB; mem (CPU total)=11872.8515625MB
INFO:root:[   41] Training loss: 0.43576107, Validation loss: 0.42671042, Gradient norm: 5.24630896
INFO:root:At the start of the epoch: mem (CPU python)=5285.578125MB; mem (CPU total)=11875.67578125MB
INFO:root:[   42] Training loss: 0.43626467, Validation loss: 0.44359000, Gradient norm: 5.19782110
INFO:root:At the start of the epoch: mem (CPU python)=5306.953125MB; mem (CPU total)=11885.42578125MB
INFO:root:[   43] Training loss: 0.43747190, Validation loss: 0.45081256, Gradient norm: 5.38836677
INFO:root:At the start of the epoch: mem (CPU python)=5329.94140625MB; mem (CPU total)=11888.62890625MB
INFO:root:[   44] Training loss: 0.43465072, Validation loss: 0.45051230, Gradient norm: 5.56208768
INFO:root:At the start of the epoch: mem (CPU python)=5351.59375MB; mem (CPU total)=11939.14453125MB
INFO:root:[   45] Training loss: 0.43582759, Validation loss: 0.45708546, Gradient norm: 5.59792566
INFO:root:At the start of the epoch: mem (CPU python)=5373.14453125MB; mem (CPU total)=11997.78125MB
INFO:root:[   46] Training loss: 0.43727772, Validation loss: 0.46255048, Gradient norm: 5.57754717
INFO:root:At the start of the epoch: mem (CPU python)=5394.765625MB; mem (CPU total)=11972.703125MB
INFO:root:[   47] Training loss: 0.43648577, Validation loss: 0.43843569, Gradient norm: 5.70422559
INFO:root:At the start of the epoch: mem (CPU python)=5415.953125MB; mem (CPU total)=11981.48046875MB
INFO:root:[   48] Training loss: 0.44177564, Validation loss: 0.46032913, Gradient norm: 6.31759961
INFO:root:At the start of the epoch: mem (CPU python)=5439.69921875MB; mem (CPU total)=12049.01953125MB
INFO:root:[   49] Training loss: 0.44442680, Validation loss: 0.45334267, Gradient norm: 6.75018419
INFO:root:At the start of the epoch: mem (CPU python)=5460.88671875MB; mem (CPU total)=12044.53515625MB
INFO:root:[   50] Training loss: 0.44127951, Validation loss: 0.45532216, Gradient norm: 6.57226551
INFO:root:At the start of the epoch: mem (CPU python)=5482.04296875MB; mem (CPU total)=12202.22265625MB
INFO:root:[   51] Training loss: 0.44361472, Validation loss: 0.45619340, Gradient norm: 6.58113828
INFO:root:At the start of the epoch: mem (CPU python)=5503.296875MB; mem (CPU total)=12116.98046875MB
INFO:root:[   52] Training loss: 0.43973896, Validation loss: 0.46107291, Gradient norm: 6.36210897
INFO:root:At the start of the epoch: mem (CPU python)=5528.609375MB; mem (CPU total)=12140.37109375MB
INFO:root:[   53] Training loss: 0.43848767, Validation loss: 0.45858819, Gradient norm: 6.23746138
INFO:root:At the start of the epoch: mem (CPU python)=5561.9296875MB; mem (CPU total)=12161.625MB
INFO:root:[   54] Training loss: 0.43813865, Validation loss: 0.46345938, Gradient norm: 6.10732492
INFO:root:At the start of the epoch: mem (CPU python)=5583.1328125MB; mem (CPU total)=12181.3828125MB
INFO:root:[   55] Training loss: 0.43560955, Validation loss: 0.43408418, Gradient norm: 6.09861770
INFO:root:At the start of the epoch: mem (CPU python)=5604.59375MB; mem (CPU total)=12240.5234375MB
INFO:root:[   56] Training loss: 0.43590229, Validation loss: 0.42941546, Gradient norm: 6.12961806
INFO:root:At the start of the epoch: mem (CPU python)=5625.79296875MB; mem (CPU total)=12207.0390625MB
INFO:root:[   57] Training loss: 0.43335437, Validation loss: 0.43919260, Gradient norm: 5.98330808
INFO:root:At the start of the epoch: mem (CPU python)=5647.02734375MB; mem (CPU total)=12227.06640625MB
INFO:root:[   58] Training loss: 0.43517952, Validation loss: 0.43284815, Gradient norm: 6.03839116
INFO:root:At the start of the epoch: mem (CPU python)=5668.23828125MB; mem (CPU total)=11995.47265625MB
INFO:root:[   59] Training loss: 0.43379956, Validation loss: 0.46623298, Gradient norm: 5.79102244
INFO:root:At the start of the epoch: mem (CPU python)=5689.44140625MB; mem (CPU total)=12298.1171875MB
INFO:root:[   60] Training loss: 0.42917513, Validation loss: 0.46043295, Gradient norm: 6.04204503
INFO:root:At the start of the epoch: mem (CPU python)=5710.6484375MB; mem (CPU total)=12296.94140625MB
INFO:root:[   61] Training loss: 0.43280194, Validation loss: 0.44500977, Gradient norm: 5.95493934
INFO:root:At the start of the epoch: mem (CPU python)=5731.81640625MB; mem (CPU total)=12403.15625MB
INFO:root:[   62] Training loss: 0.42895178, Validation loss: 0.44362457, Gradient norm: 6.03031655
INFO:root:At the start of the epoch: mem (CPU python)=5752.98828125MB; mem (CPU total)=12332.8671875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.42938782, Validation loss: 0.43099741, Gradient norm: 6.03692573
INFO:root:At the start of the epoch: mem (CPU python)=5774.2109375MB; mem (CPU total)=12393.26171875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.39870257, Validation loss: 0.40827656, Gradient norm: 5.39111888
INFO:root:At the start of the epoch: mem (CPU python)=5795.4140625MB; mem (CPU total)=12368.203125MB
INFO:root:[   65] Training loss: 0.38802416, Validation loss: 0.40141495, Gradient norm: 5.46021532
INFO:root:At the start of the epoch: mem (CPU python)=5816.6328125MB; mem (CPU total)=12396.94921875MB
INFO:root:[   66] Training loss: 0.38553583, Validation loss: 0.40286081, Gradient norm: 6.64293420
INFO:root:At the start of the epoch: mem (CPU python)=5841.296875MB; mem (CPU total)=12434.38671875MB
INFO:root:[   67] Training loss: 0.38699665, Validation loss: 0.40313898, Gradient norm: 7.98687494
INFO:root:At the start of the epoch: mem (CPU python)=5862.56640625MB; mem (CPU total)=12449.00390625MB
INFO:root:[   68] Training loss: 0.38721581, Validation loss: 0.40426049, Gradient norm: 9.35888318
INFO:root:At the start of the epoch: mem (CPU python)=5883.73046875MB; mem (CPU total)=12478.86328125MB
INFO:root:[   69] Training loss: 0.38943221, Validation loss: 0.40229357, Gradient norm: 10.15447875
INFO:root:At the start of the epoch: mem (CPU python)=5904.90234375MB; mem (CPU total)=12486.05078125MB
INFO:root:[   70] Training loss: 0.39076088, Validation loss: 0.40110979, Gradient norm: 10.80827281
INFO:root:At the start of the epoch: mem (CPU python)=5926.078125MB; mem (CPU total)=12524.84765625MB
INFO:root:[   71] Training loss: 0.39139940, Validation loss: 0.40396853, Gradient norm: 12.13988152
INFO:root:At the start of the epoch: mem (CPU python)=5947.234375MB; mem (CPU total)=12531.8046875MB
INFO:root:[   72] Training loss: 0.39254368, Validation loss: 0.41472205, Gradient norm: 13.06354368
INFO:root:At the start of the epoch: mem (CPU python)=5968.40625MB; mem (CPU total)=12646.9375MB
INFO:root:[   73] Training loss: 0.39444664, Validation loss: 0.40945635, Gradient norm: 13.59767461
INFO:root:At the start of the epoch: mem (CPU python)=5989.57421875MB; mem (CPU total)=12526.98828125MB
INFO:root:[   74] Training loss: 0.39664322, Validation loss: 0.41571434, Gradient norm: 14.26377571
INFO:root:At the start of the epoch: mem (CPU python)=6010.74609375MB; mem (CPU total)=12707.46484375MB
INFO:root:[   75] Training loss: 0.39590817, Validation loss: 0.41121303, Gradient norm: 14.97838216
INFO:root:At the start of the epoch: mem (CPU python)=6031.8671875MB; mem (CPU total)=12640.31640625MB
INFO:root:[   76] Training loss: 0.39531151, Validation loss: 0.41240602, Gradient norm: 15.05291105
INFO:root:At the start of the epoch: mem (CPU python)=6053.0703125MB; mem (CPU total)=12645.94921875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 0.39645970, Validation loss: 0.40945432, Gradient norm: 15.66184364
INFO:root:At the start of the epoch: mem (CPU python)=6074.234375MB; mem (CPU total)=12679.578125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 0.38309815, Validation loss: 0.39649291, Gradient norm: 11.24310134
INFO:root:At the start of the epoch: mem (CPU python)=6095.3984375MB; mem (CPU total)=12688.5625MB
INFO:root:[   79] Training loss: 0.37828984, Validation loss: 0.39658344, Gradient norm: 9.87971227
INFO:root:At the start of the epoch: mem (CPU python)=6116.5625MB; mem (CPU total)=12748.09375MB
INFO:root:[   80] Training loss: 0.37821609, Validation loss: 0.39681823, Gradient norm: 10.48042741
INFO:root:At the start of the epoch: mem (CPU python)=6137.72265625MB; mem (CPU total)=12747.31640625MB
INFO:root:[   81] Training loss: 0.37767603, Validation loss: 0.39548544, Gradient norm: 12.64221843
INFO:root:At the start of the epoch: mem (CPU python)=6158.890625MB; mem (CPU total)=12753.30078125MB
INFO:root:[   82] Training loss: 0.37833458, Validation loss: 0.39384668, Gradient norm: 13.07948379
INFO:root:At the start of the epoch: mem (CPU python)=6180.0546875MB; mem (CPU total)=12763.5078125MB
INFO:root:[   83] Training loss: 0.37902191, Validation loss: 0.40127620, Gradient norm: 14.73948122
INFO:root:At the start of the epoch: mem (CPU python)=6201.21875MB; mem (CPU total)=12809.375MB
INFO:root:[   84] Training loss: 0.38002689, Validation loss: 0.39383732, Gradient norm: 16.24366277
INFO:root:At the start of the epoch: mem (CPU python)=6224.1875MB; mem (CPU total)=12822.7734375MB
INFO:root:[   85] Training loss: 0.37840719, Validation loss: 0.40272247, Gradient norm: 15.33624465
INFO:root:At the start of the epoch: mem (CPU python)=6251.90234375MB; mem (CPU total)=12879.12109375MB
INFO:root:[   86] Training loss: 0.37923172, Validation loss: 0.39648601, Gradient norm: 15.78703538
INFO:root:At the start of the epoch: mem (CPU python)=6273.0703125MB; mem (CPU total)=12923.1875MB
INFO:root:[   87] Training loss: 0.37949186, Validation loss: 0.39213172, Gradient norm: 17.07002578
INFO:root:At the start of the epoch: mem (CPU python)=6294.43359375MB; mem (CPU total)=12908.6953125MB
INFO:root:[   88] Training loss: 0.38137993, Validation loss: 0.39390226, Gradient norm: 20.09431928
INFO:root:At the start of the epoch: mem (CPU python)=6320.30859375MB; mem (CPU total)=12901.9375MB
INFO:root:[   89] Training loss: 0.38167349, Validation loss: 0.39459999, Gradient norm: 20.12695546
INFO:root:At the start of the epoch: mem (CPU python)=6341.78125MB; mem (CPU total)=13036.8515625MB
INFO:root:[   90] Training loss: 0.38032715, Validation loss: 0.39370090, Gradient norm: 18.67532677
INFO:root:At the start of the epoch: mem (CPU python)=6362.94140625MB; mem (CPU total)=12977.66796875MB
INFO:root:[   91] Training loss: 0.38121962, Validation loss: 0.39563038, Gradient norm: 20.27790965
INFO:root:At the start of the epoch: mem (CPU python)=6384.10546875MB; mem (CPU total)=12838.2421875MB
INFO:root:[   92] Training loss: 0.38081723, Validation loss: 0.39935556, Gradient norm: 20.69663197
INFO:root:At the start of the epoch: mem (CPU python)=6405.2734375MB; mem (CPU total)=13002.15625MB
INFO:root:[   93] Training loss: 0.38213077, Validation loss: 0.39903676, Gradient norm: 22.26241957
INFO:root:At the start of the epoch: mem (CPU python)=6426.4375MB; mem (CPU total)=12975.5625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   94] Training loss: 0.38047201, Validation loss: 0.39461285, Gradient norm: 22.32897829
INFO:root:At the start of the epoch: mem (CPU python)=6447.6015625MB; mem (CPU total)=13099.1015625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   95] Training loss: 0.37835109, Validation loss: 0.39314964, Gradient norm: 17.94991970
INFO:root:At the start of the epoch: mem (CPU python)=6468.765625MB; mem (CPU total)=13076.22265625MB
INFO:root:[   96] Training loss: 0.37558076, Validation loss: 0.39079322, Gradient norm: 14.32284872
INFO:root:At the start of the epoch: mem (CPU python)=6489.9296875MB; mem (CPU total)=13075.6328125MB
INFO:root:[   97] Training loss: 0.37592811, Validation loss: 0.38946696, Gradient norm: 14.16167806
INFO:root:At the start of the epoch: mem (CPU python)=6511.1015625MB; mem (CPU total)=13111.30859375MB
INFO:root:[   98] Training loss: 0.37501582, Validation loss: 0.39053443, Gradient norm: 14.87014149
INFO:root:At the start of the epoch: mem (CPU python)=6532.265625MB; mem (CPU total)=13146.08984375MB
INFO:root:[   99] Training loss: 0.37494981, Validation loss: 0.39027654, Gradient norm: 15.28036272
INFO:root:At the start of the epoch: mem (CPU python)=6553.42578125MB; mem (CPU total)=13159.99609375MB
INFO:root:[  100] Training loss: 0.37521131, Validation loss: 0.39070874, Gradient norm: 16.15817444
INFO:root:At the start of the epoch: mem (CPU python)=6576.55078125MB; mem (CPU total)=12895.41796875MB
INFO:root:[  101] Training loss: 0.37552914, Validation loss: 0.39026681, Gradient norm: 16.14716826
INFO:root:At the start of the epoch: mem (CPU python)=6597.71484375MB; mem (CPU total)=13221.32421875MB
INFO:root:[  102] Training loss: 0.37644043, Validation loss: 0.39192879, Gradient norm: 16.88997800
INFO:root:At the start of the epoch: mem (CPU python)=6618.87890625MB; mem (CPU total)=13201.59375MB
INFO:root:[  103] Training loss: 0.37582440, Validation loss: 0.39029525, Gradient norm: 17.54851421
INFO:root:At the start of the epoch: mem (CPU python)=6640.2578125MB; mem (CPU total)=13244.06640625MB
INFO:root:[  104] Training loss: 0.37576872, Validation loss: 0.38989470, Gradient norm: 18.31745208
INFO:root:At the start of the epoch: mem (CPU python)=6661.421875MB; mem (CPU total)=13363.69921875MB
INFO:root:[  105] Training loss: 0.37607235, Validation loss: 0.39116284, Gradient norm: 17.45324735
INFO:root:At the start of the epoch: mem (CPU python)=6682.953125MB; mem (CPU total)=13283.12890625MB
INFO:root:[  106] Training loss: 0.37647071, Validation loss: 0.39039705, Gradient norm: 18.62035240
INFO:root:At the start of the epoch: mem (CPU python)=6704.3671875MB; mem (CPU total)=13316.44140625MB
INFO:root:EP 106: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=6725.65234375MB; mem (CPU total)=13333.06640625MB
INFO:root:Training the model took 2649.664s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.34135
INFO:root:EnergyScoreValidation: 0.25715
INFO:root:CRPSValidation: 0.10255
INFO:root:Gaussian NLLValidation: -0.07541
INFO:root:CoverageValidation: 0.76271
INFO:root:IntervalWidthValidation: 0.39249
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.36575
INFO:root:EnergyScoreTest: 0.27895
INFO:root:CRPSTest: 0.11159
INFO:root:Gaussian NLLTest: 0.17235
INFO:root:CoverageTest: 0.7336
INFO:root:IntervalWidthTest: 0.39026
INFO:root:After validation: mem (CPU python)=6746.3125MB; mem (CPU total)=13349.5625MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=6746.31640625MB; mem (CPU total)=13349.74609375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 60817408
INFO:root:After setting up the model: mem (CPU python)=6749.06640625MB; mem (CPU total)=13352.23828125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=6749.06640625MB; mem (CPU total)=13337.56640625MB
INFO:root:[    1] Training loss: 0.76046531, Validation loss: 0.71245716, Gradient norm: 0.35049073
INFO:root:At the start of the epoch: mem (CPU python)=6773.23828125MB; mem (CPU total)=13384.34765625MB
INFO:root:[    2] Training loss: 0.66230750, Validation loss: 0.61313523, Gradient norm: 0.44043758
INFO:root:At the start of the epoch: mem (CPU python)=6794.65234375MB; mem (CPU total)=13394.08203125MB
INFO:root:[    3] Training loss: 0.59358340, Validation loss: 0.57427914, Gradient norm: 0.55093530
INFO:root:At the start of the epoch: mem (CPU python)=6815.9296875MB; mem (CPU total)=13410.59765625MB
INFO:root:[    4] Training loss: 0.55993092, Validation loss: 0.56888799, Gradient norm: 0.74936753
INFO:root:At the start of the epoch: mem (CPU python)=6837.09765625MB; mem (CPU total)=13436.73046875MB
INFO:root:[    5] Training loss: 0.52598475, Validation loss: 0.51113194, Gradient norm: 0.94487429
INFO:root:At the start of the epoch: mem (CPU python)=6858.265625MB; mem (CPU total)=13502.90625MB
INFO:root:[    6] Training loss: 0.49638639, Validation loss: 0.48825505, Gradient norm: 1.28486798
INFO:root:At the start of the epoch: mem (CPU python)=6879.43359375MB; mem (CPU total)=13506.0MB
INFO:root:[    7] Training loss: 0.47867944, Validation loss: 0.47466425, Gradient norm: 1.59848130
INFO:root:At the start of the epoch: mem (CPU python)=6900.59765625MB; mem (CPU total)=13527.5546875MB
INFO:root:[    8] Training loss: 0.47406034, Validation loss: 0.47279585, Gradient norm: 2.18447533
INFO:root:At the start of the epoch: mem (CPU python)=6921.76171875MB; mem (CPU total)=13591.28125MB
INFO:root:[    9] Training loss: 0.47268227, Validation loss: 0.47408443, Gradient norm: 2.66183026
INFO:root:At the start of the epoch: mem (CPU python)=6942.92578125MB; mem (CPU total)=13527.78515625MB
INFO:root:[   10] Training loss: 0.47209057, Validation loss: 0.48281510, Gradient norm: 3.09839171
INFO:root:At the start of the epoch: mem (CPU python)=6964.08984375MB; mem (CPU total)=13598.1328125MB
INFO:root:[   11] Training loss: 0.47189420, Validation loss: 0.47208735, Gradient norm: 3.65642510
INFO:root:At the start of the epoch: mem (CPU python)=6986.046875MB; mem (CPU total)=13589.3359375MB
INFO:root:[   12] Training loss: 0.46940765, Validation loss: 0.45561234, Gradient norm: 3.68899146
INFO:root:At the start of the epoch: mem (CPU python)=7007.609375MB; mem (CPU total)=13613.21484375MB
INFO:root:[   13] Training loss: 0.47050827, Validation loss: 0.46910496, Gradient norm: 4.14297672
INFO:root:At the start of the epoch: mem (CPU python)=7034.4375MB; mem (CPU total)=13647.17578125MB
INFO:root:[   14] Training loss: 0.47000923, Validation loss: 0.46209800, Gradient norm: 4.34029617
INFO:root:At the start of the epoch: mem (CPU python)=7055.96484375MB; mem (CPU total)=13673.5859375MB
INFO:root:[   15] Training loss: 0.47277303, Validation loss: 0.47280054, Gradient norm: 4.60922308
INFO:root:At the start of the epoch: mem (CPU python)=7080.703125MB; mem (CPU total)=13654.28515625MB
INFO:root:[   16] Training loss: 0.46941081, Validation loss: 0.47517609, Gradient norm: 4.75830033
INFO:root:At the start of the epoch: mem (CPU python)=7101.8671875MB; mem (CPU total)=13709.5078125MB
INFO:root:[   17] Training loss: 0.46929839, Validation loss: 0.46590439, Gradient norm: 5.12619194
INFO:root:At the start of the epoch: mem (CPU python)=7124.51953125MB; mem (CPU total)=13730.78125MB
INFO:root:[   18] Training loss: 0.47012261, Validation loss: 0.46434195, Gradient norm: 5.33024168
INFO:root:At the start of the epoch: mem (CPU python)=7145.98828125MB; mem (CPU total)=13733.234375MB
INFO:root:[   19] Training loss: 0.46986831, Validation loss: 0.46588895, Gradient norm: 5.58262054
INFO:root:At the start of the epoch: mem (CPU python)=7167.359375MB; mem (CPU total)=13794.8671875MB
INFO:root:[   20] Training loss: 0.46845563, Validation loss: 0.46398585, Gradient norm: 5.94828437
INFO:root:At the start of the epoch: mem (CPU python)=7191.359375MB; mem (CPU total)=13801.44140625MB
INFO:root:[   21] Training loss: 0.46873061, Validation loss: 0.50057469, Gradient norm: 5.91556421
INFO:root:At the start of the epoch: mem (CPU python)=7213.33984375MB; mem (CPU total)=13809.42578125MB
INFO:root:[   22] Training loss: 0.46895054, Validation loss: 0.47989620, Gradient norm: 6.36080126
INFO:root:At the start of the epoch: mem (CPU python)=7234.5078125MB; mem (CPU total)=13823.5234375MB
INFO:root:[   23] Training loss: 0.46987578, Validation loss: 0.47135313, Gradient norm: 6.38818228
INFO:root:At the start of the epoch: mem (CPU python)=7255.73046875MB; mem (CPU total)=13955.296875MB
INFO:root:[   24] Training loss: 0.46949625, Validation loss: 0.47199762, Gradient norm: 6.55713858
INFO:root:At the start of the epoch: mem (CPU python)=7276.8984375MB; mem (CPU total)=13984.7890625MB
INFO:root:[   25] Training loss: 0.46812291, Validation loss: 0.45712089, Gradient norm: 6.55935907
INFO:root:At the start of the epoch: mem (CPU python)=7305.96484375MB; mem (CPU total)=13906.01171875MB
INFO:root:[   26] Training loss: 0.46666744, Validation loss: 0.46469136, Gradient norm: 6.88069188
INFO:root:At the start of the epoch: mem (CPU python)=7327.484375MB; mem (CPU total)=13939.1640625MB
INFO:root:[   27] Training loss: 0.46371290, Validation loss: 0.46465481, Gradient norm: 6.84942187
INFO:root:At the start of the epoch: mem (CPU python)=7348.65234375MB; mem (CPU total)=13956.25MB
INFO:root:[   28] Training loss: 0.46414564, Validation loss: 0.48545377, Gradient norm: 7.08497417
INFO:root:At the start of the epoch: mem (CPU python)=7369.81640625MB; mem (CPU total)=13873.82421875MB
INFO:root:[   29] Training loss: 0.46511189, Validation loss: 0.47142803, Gradient norm: 6.99083535
INFO:root:At the start of the epoch: mem (CPU python)=7390.98046875MB; mem (CPU total)=13982.76171875MB
INFO:root:[   30] Training loss: 0.46498964, Validation loss: 0.46739311, Gradient norm: 7.11178893
INFO:root:At the start of the epoch: mem (CPU python)=7421.05859375MB; mem (CPU total)=14018.265625MB
INFO:root:[   31] Training loss: 0.46432049, Validation loss: 0.45112351, Gradient norm: 7.38104379
INFO:root:At the start of the epoch: mem (CPU python)=7442.2265625MB; mem (CPU total)=14044.1015625MB
INFO:root:[   32] Training loss: 0.46151487, Validation loss: 0.51899632, Gradient norm: 7.34902802
INFO:root:At the start of the epoch: mem (CPU python)=7463.640625MB; mem (CPU total)=14059.5234375MB
INFO:root:[   33] Training loss: 0.44648785, Validation loss: 0.46775416, Gradient norm: 8.78351079
INFO:root:At the start of the epoch: mem (CPU python)=7485.015625MB; mem (CPU total)=14116.8046875MB
INFO:root:[   34] Training loss: 0.44035174, Validation loss: 0.43009846, Gradient norm: 9.09178271
INFO:root:At the start of the epoch: mem (CPU python)=7506.1796875MB; mem (CPU total)=14096.91015625MB
INFO:root:[   35] Training loss: 0.44260422, Validation loss: 0.45872476, Gradient norm: 9.20605434
INFO:root:At the start of the epoch: mem (CPU python)=7527.33984375MB; mem (CPU total)=14133.48828125MB
INFO:root:[   36] Training loss: 0.49535185, Validation loss: 0.74599580, Gradient norm: 10.56678092
INFO:root:At the start of the epoch: mem (CPU python)=7548.50390625MB; mem (CPU total)=14135.66796875MB
INFO:root:[   37] Training loss: 0.55318561, Validation loss: 0.48027094, Gradient norm: 11.56013225
INFO:root:At the start of the epoch: mem (CPU python)=7569.66796875MB; mem (CPU total)=14132.17578125MB
INFO:root:[   38] Training loss: 0.47142755, Validation loss: 0.46771491, Gradient norm: 9.64792427
INFO:root:At the start of the epoch: mem (CPU python)=7590.83203125MB; mem (CPU total)=14511.5390625MB
INFO:root:[   39] Training loss: 0.52150331, Validation loss: 0.86923720, Gradient norm: 12.24265847
INFO:root:At the start of the epoch: mem (CPU python)=7612.0MB; mem (CPU total)=14766.37109375MB
INFO:root:[   40] Training loss: 0.79104999, Validation loss: 0.55364927, Gradient norm: 15.49444265
INFO:root:At the start of the epoch: mem (CPU python)=7633.1640625MB; mem (CPU total)=14214.55078125MB
INFO:root:[   41] Training loss: 0.52415924, Validation loss: 0.52251777, Gradient norm: 12.01968027
INFO:root:At the start of the epoch: mem (CPU python)=7654.33203125MB; mem (CPU total)=15061.171875MB
INFO:root:[   42] Training loss: 0.49107260, Validation loss: 0.52106623, Gradient norm: 12.12839476
INFO:root:At the start of the epoch: mem (CPU python)=7675.4921875MB; mem (CPU total)=14993.59375MB
INFO:root:[   43] Training loss: 0.47829381, Validation loss: 0.45194905, Gradient norm: 12.64137633
INFO:root:At the start of the epoch: mem (CPU python)=7696.8984375MB; mem (CPU total)=15135.71875MB
INFO:root:[   44] Training loss: 0.47365004, Validation loss: 0.49044624, Gradient norm: 12.40119921
INFO:root:At the start of the epoch: mem (CPU python)=7721.08203125MB; mem (CPU total)=15138.71875MB
INFO:root:[   45] Training loss: 0.47579516, Validation loss: 0.45359010, Gradient norm: 13.28526979
INFO:root:At the start of the epoch: mem (CPU python)=7742.24609375MB; mem (CPU total)=15113.2109375MB
INFO:root:[   46] Training loss: 0.46994021, Validation loss: 0.47778185, Gradient norm: 12.68464476
INFO:root:At the start of the epoch: mem (CPU python)=7763.53515625MB; mem (CPU total)=15028.359375MB
INFO:root:[   47] Training loss: 0.47031658, Validation loss: 0.49692021, Gradient norm: 12.77957893
INFO:root:At the start of the epoch: mem (CPU python)=7784.69921875MB; mem (CPU total)=14426.59765625MB
INFO:root:[   48] Training loss: 0.48012203, Validation loss: 0.47863121, Gradient norm: 14.36408519
INFO:root:At the start of the epoch: mem (CPU python)=7805.86328125MB; mem (CPU total)=14429.4921875MB
INFO:root:[   49] Training loss: 0.49409489, Validation loss: 0.48775166, Gradient norm: 15.26709328
INFO:root:At the start of the epoch: mem (CPU python)=7827.03125MB; mem (CPU total)=14450.484375MB
INFO:root:[   50] Training loss: 0.47388628, Validation loss: 0.50236129, Gradient norm: 13.55964803
INFO:root:At the start of the epoch: mem (CPU python)=7848.1953125MB; mem (CPU total)=14476.91796875MB
INFO:root:[   51] Training loss: 0.46674747, Validation loss: 0.46176535, Gradient norm: 12.62650554
INFO:root:At the start of the epoch: mem (CPU python)=7869.35546875MB; mem (CPU total)=14353.70703125MB
INFO:root:[   52] Training loss: 0.46226473, Validation loss: 0.48381079, Gradient norm: 12.92335470
INFO:root:At the start of the epoch: mem (CPU python)=7906.47265625MB; mem (CPU total)=14091.93359375MB
INFO:root:[   53] Training loss: 0.60841878, Validation loss: 0.60946489, Gradient norm: 18.53495603
INFO:root:At the start of the epoch: mem (CPU python)=7927.76171875MB; mem (CPU total)=14614.890625MB
INFO:root:[   54] Training loss: 0.50107390, Validation loss: 0.51005243, Gradient norm: 14.96636864
INFO:root:At the start of the epoch: mem (CPU python)=7954.5390625MB; mem (CPU total)=14592.10546875MB
INFO:root:[   55] Training loss: 0.50085929, Validation loss: 0.59978517, Gradient norm: 14.50201526
INFO:root:At the start of the epoch: mem (CPU python)=7976.09375MB; mem (CPU total)=14610.0234375MB
INFO:root:[   56] Training loss: 0.66141452, Validation loss: 0.59495047, Gradient norm: 24.58696761
INFO:root:At the start of the epoch: mem (CPU python)=7997.2578125MB; mem (CPU total)=14659.84375MB
INFO:root:[   57] Training loss: 0.58106364, Validation loss: 0.57159149, Gradient norm: 11.49406277
INFO:root:At the start of the epoch: mem (CPU python)=8018.421875MB; mem (CPU total)=14634.0859375MB
INFO:root:[   58] Training loss: 0.49476615, Validation loss: 0.47162943, Gradient norm: 13.19392438
INFO:root:At the start of the epoch: mem (CPU python)=8039.5859375MB; mem (CPU total)=14655.53515625MB
INFO:root:[   59] Training loss: 0.47064430, Validation loss: 0.47330353, Gradient norm: 12.62255340
INFO:root:At the start of the epoch: mem (CPU python)=8060.75MB; mem (CPU total)=14667.1953125MB
INFO:root:[   60] Training loss: 0.48093144, Validation loss: 0.48456130, Gradient norm: 14.55626187
INFO:root:At the start of the epoch: mem (CPU python)=8081.9140625MB; mem (CPU total)=14694.79296875MB
INFO:root:[   61] Training loss: 0.47427061, Validation loss: 0.48661462, Gradient norm: 13.64335819
INFO:root:At the start of the epoch: mem (CPU python)=8103.078125MB; mem (CPU total)=14730.7109375MB
INFO:root:[   62] Training loss: 0.46312653, Validation loss: 0.45250885, Gradient norm: 12.96985838
INFO:root:At the start of the epoch: mem (CPU python)=8124.2421875MB; mem (CPU total)=14704.94921875MB
INFO:root:[   63] Training loss: 0.55078800, Validation loss: 0.57622382, Gradient norm: 19.15258473
INFO:root:At the start of the epoch: mem (CPU python)=8145.40625MB; mem (CPU total)=14729.9140625MB
INFO:root:[   64] Training loss: 0.49303401, Validation loss: 0.46094847, Gradient norm: 14.93928589
INFO:root:At the start of the epoch: mem (CPU python)=8166.5703125MB; mem (CPU total)=14772.55078125MB
INFO:root:[   65] Training loss: 0.46689550, Validation loss: 0.47555229, Gradient norm: 13.55139124
INFO:root:At the start of the epoch: mem (CPU python)=8187.734375MB; mem (CPU total)=14809.90234375MB
INFO:root:[   66] Training loss: 0.49477435, Validation loss: 0.70048905, Gradient norm: 14.63158596
INFO:root:At the start of the epoch: mem (CPU python)=8208.90234375MB; mem (CPU total)=14825.67578125MB
INFO:root:[   67] Training loss: 0.53533915, Validation loss: 0.47683109, Gradient norm: 17.12929798
INFO:root:At the start of the epoch: mem (CPU python)=8230.0703125MB; mem (CPU total)=14918.92578125MB
INFO:root:[   68] Training loss: 0.47638656, Validation loss: 0.49227104, Gradient norm: 14.13082249
INFO:root:At the start of the epoch: mem (CPU python)=8251.23046875MB; mem (CPU total)=14878.04296875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   69] Training loss: 0.47340236, Validation loss: 0.48682578, Gradient norm: 15.10521582
INFO:root:At the start of the epoch: mem (CPU python)=8272.39453125MB; mem (CPU total)=14900.68359375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   70] Training loss: 0.44055221, Validation loss: 0.45384031, Gradient norm: 13.43494151
INFO:root:At the start of the epoch: mem (CPU python)=8293.5546875MB; mem (CPU total)=14903.25MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   71] Training loss: 0.43041910, Validation loss: 0.43430892, Gradient norm: 13.53377332
INFO:root:At the start of the epoch: mem (CPU python)=8314.71875MB; mem (CPU total)=14919.1328125MB
INFO:root:[   72] Training loss: 0.42461131, Validation loss: 0.43103439, Gradient norm: 13.42111189
INFO:root:At the start of the epoch: mem (CPU python)=8335.88671875MB; mem (CPU total)=14958.72265625MB
INFO:root:[   73] Training loss: 0.42428444, Validation loss: 0.43026269, Gradient norm: 15.61575324
INFO:root:At the start of the epoch: mem (CPU python)=8357.05078125MB; mem (CPU total)=14954.578125MB
INFO:root:[   74] Training loss: 0.42524548, Validation loss: 0.43951518, Gradient norm: 21.65779292
INFO:root:At the start of the epoch: mem (CPU python)=8378.21484375MB; mem (CPU total)=15002.6015625MB
INFO:root:[   75] Training loss: 0.42526446, Validation loss: 0.43215734, Gradient norm: 19.86134584
INFO:root:At the start of the epoch: mem (CPU python)=8399.37890625MB; mem (CPU total)=15002.4453125MB
INFO:root:[   76] Training loss: 0.42611270, Validation loss: 0.42817951, Gradient norm: 26.53232817
INFO:root:At the start of the epoch: mem (CPU python)=8422.54296875MB; mem (CPU total)=15031.234375MB
INFO:root:[   77] Training loss: 0.42748070, Validation loss: 0.43465620, Gradient norm: 26.84128650
INFO:root:At the start of the epoch: mem (CPU python)=8444.90625MB; mem (CPU total)=15051.05078125MB
INFO:root:[   78] Training loss: 0.42594025, Validation loss: 0.43312525, Gradient norm: 27.71392469
INFO:root:At the start of the epoch: mem (CPU python)=8466.0703125MB; mem (CPU total)=15093.2421875MB
INFO:root:[   79] Training loss: 0.42625527, Validation loss: 0.43248262, Gradient norm: 30.66043131
INFO:root:At the start of the epoch: mem (CPU python)=8487.546875MB; mem (CPU total)=15075.58984375MB
INFO:root:[   80] Training loss: 0.42804481, Validation loss: 0.43502643, Gradient norm: 32.91586763
INFO:root:At the start of the epoch: mem (CPU python)=8508.70703125MB; mem (CPU total)=15137.51171875MB
INFO:root:[   81] Training loss: 0.42821758, Validation loss: 0.43736658, Gradient norm: 37.52113386
INFO:root:At the start of the epoch: mem (CPU python)=8529.87109375MB; mem (CPU total)=15213.21484375MB
INFO:root:[   82] Training loss: 0.42937917, Validation loss: 0.43653217, Gradient norm: 39.98807457
INFO:root:At the start of the epoch: mem (CPU python)=8551.03515625MB; mem (CPU total)=15239.85546875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   83] Training loss: 0.42894745, Validation loss: 0.44001053, Gradient norm: 42.19033053
INFO:root:At the start of the epoch: mem (CPU python)=8572.203125MB; mem (CPU total)=15219.875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   84] Training loss: 0.42513729, Validation loss: 0.43512293, Gradient norm: 36.08293233
INFO:root:At the start of the epoch: mem (CPU python)=8593.3671875MB; mem (CPU total)=15204.4453125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   85] Training loss: 0.41928426, Validation loss: 0.42752988, Gradient norm: 21.27147463
INFO:root:At the start of the epoch: mem (CPU python)=8614.53125MB; mem (CPU total)=15202.453125MB
INFO:root:[   86] Training loss: 0.41812825, Validation loss: 0.42612717, Gradient norm: 18.64431391
INFO:root:At the start of the epoch: mem (CPU python)=8636.60546875MB; mem (CPU total)=15232.91015625MB
INFO:root:[   87] Training loss: 0.41827863, Validation loss: 0.42516233, Gradient norm: 19.62993181
INFO:root:At the start of the epoch: mem (CPU python)=8657.76953125MB; mem (CPU total)=15232.03125MB
INFO:root:[   88] Training loss: 0.41837559, Validation loss: 0.42353089, Gradient norm: 20.55386633
INFO:root:At the start of the epoch: mem (CPU python)=8679.15234375MB; mem (CPU total)=15283.203125MB
INFO:root:[   89] Training loss: 0.41702779, Validation loss: 0.42529467, Gradient norm: 20.59449109
INFO:root:At the start of the epoch: mem (CPU python)=8700.30859375MB; mem (CPU total)=15293.94921875MB
INFO:root:[   90] Training loss: 0.41840647, Validation loss: 0.42269645, Gradient norm: 23.44304449
INFO:root:At the start of the epoch: mem (CPU python)=8721.48046875MB; mem (CPU total)=15321.34375MB
INFO:root:[   91] Training loss: 0.41748002, Validation loss: 0.42774030, Gradient norm: 23.70401289
INFO:root:At the start of the epoch: mem (CPU python)=8742.64453125MB; mem (CPU total)=15347.2421875MB
INFO:root:[   92] Training loss: 0.41782815, Validation loss: 0.42455794, Gradient norm: 24.83475805
INFO:root:At the start of the epoch: mem (CPU python)=8763.8125MB; mem (CPU total)=15366.61328125MB
INFO:root:[   93] Training loss: 0.41887363, Validation loss: 0.42461948, Gradient norm: 25.39742723
INFO:root:At the start of the epoch: mem (CPU python)=8784.9765625MB; mem (CPU total)=15391.06640625MB
INFO:root:[   94] Training loss: 0.41774060, Validation loss: 0.42414794, Gradient norm: 25.38028228
INFO:root:At the start of the epoch: mem (CPU python)=8806.140625MB; mem (CPU total)=15414.45703125MB
INFO:root:[   95] Training loss: 0.41739116, Validation loss: 0.42494271, Gradient norm: 26.67058636
INFO:root:At the start of the epoch: mem (CPU python)=8827.3046875MB; mem (CPU total)=15002.15625MB
INFO:root:[   96] Training loss: 0.41720857, Validation loss: 0.42540815, Gradient norm: 27.04423859
INFO:root:At the start of the epoch: mem (CPU python)=8848.47265625MB; mem (CPU total)=15533.73046875MB
INFO:root:[   97] Training loss: 0.41791058, Validation loss: 0.42366992, Gradient norm: 26.73310511
INFO:root:At the start of the epoch: mem (CPU python)=8869.63671875MB; mem (CPU total)=15474.95703125MB
INFO:root:[   98] Training loss: 0.41676944, Validation loss: 0.42644753, Gradient norm: 28.08767473
INFO:root:At the start of the epoch: mem (CPU python)=8890.80078125MB; mem (CPU total)=15481.109375MB
INFO:root:[   99] Training loss: 0.41829369, Validation loss: 0.42512498, Gradient norm: 29.72966160
INFO:root:At the start of the epoch: mem (CPU python)=8911.9609375MB; mem (CPU total)=15500.93359375MB
INFO:root:EP 99: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=8933.125MB; mem (CPU total)=15523.89453125MB
INFO:root:Training the model took 2515.16s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.36157
INFO:root:EnergyScoreValidation: 0.2679
INFO:root:CRPSValidation: 0.11127
INFO:root:Gaussian NLLValidation: 0.01337
INFO:root:CoverageValidation: 0.74114
INFO:root:IntervalWidthValidation: 0.4313
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.38214
INFO:root:EnergyScoreTest: 0.28559
INFO:root:CRPSTest: 0.12066
INFO:root:Gaussian NLLTest: 0.24851
INFO:root:CoverageTest: 0.70303
INFO:root:IntervalWidthTest: 0.42934
INFO:root:After validation: mem (CPU python)=8940.1484375MB; mem (CPU total)=15544.671875MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=8940.1484375MB; mem (CPU total)=15542.62109375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 60817408
INFO:root:After setting up the model: mem (CPU python)=8940.17578125MB; mem (CPU total)=15542.59375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=8940.17578125MB; mem (CPU total)=15544.2109375MB
INFO:root:[    1] Training loss: 0.75980501, Validation loss: 0.71159565, Gradient norm: 0.33985212
INFO:root:At the start of the epoch: mem (CPU python)=8960.81640625MB; mem (CPU total)=15565.51953125MB
INFO:root:[    2] Training loss: 0.64910996, Validation loss: 0.59742374, Gradient norm: 0.35771704
INFO:root:At the start of the epoch: mem (CPU python)=8981.99609375MB; mem (CPU total)=15590.9375MB
INFO:root:[    3] Training loss: 0.57343479, Validation loss: 0.55957744, Gradient norm: 0.47113360
INFO:root:At the start of the epoch: mem (CPU python)=9003.16796875MB; mem (CPU total)=15604.3828125MB
INFO:root:[    4] Training loss: 0.54675669, Validation loss: 0.53555980, Gradient norm: 0.51253786
INFO:root:At the start of the epoch: mem (CPU python)=9024.33203125MB; mem (CPU total)=15547.76953125MB
INFO:root:[    5] Training loss: 0.52469057, Validation loss: 0.50425102, Gradient norm: 0.54798975
INFO:root:At the start of the epoch: mem (CPU python)=9045.49609375MB; mem (CPU total)=15639.53515625MB
INFO:root:[    6] Training loss: 0.48384502, Validation loss: 0.48531479, Gradient norm: 0.70154101
INFO:root:At the start of the epoch: mem (CPU python)=9066.6640625MB; mem (CPU total)=15712.359375MB
INFO:root:[    7] Training loss: 0.46582072, Validation loss: 0.45902784, Gradient norm: 0.82303722
INFO:root:At the start of the epoch: mem (CPU python)=9087.828125MB; mem (CPU total)=15790.234375MB
INFO:root:[    8] Training loss: 0.45513298, Validation loss: 0.44754959, Gradient norm: 0.94857103
INFO:root:At the start of the epoch: mem (CPU python)=9108.9921875MB; mem (CPU total)=15805.26171875MB
INFO:root:[    9] Training loss: 0.44353964, Validation loss: 0.44856014, Gradient norm: 1.06428519
INFO:root:At the start of the epoch: mem (CPU python)=9130.15234375MB; mem (CPU total)=15737.44921875MB
INFO:root:[   10] Training loss: 0.43287113, Validation loss: 0.43455259, Gradient norm: 1.30342065
INFO:root:At the start of the epoch: mem (CPU python)=9151.31640625MB; mem (CPU total)=15778.63671875MB
INFO:root:[   11] Training loss: 0.42493139, Validation loss: 0.43305841, Gradient norm: 1.51285369
INFO:root:At the start of the epoch: mem (CPU python)=9172.48046875MB; mem (CPU total)=15786.484375MB
INFO:root:[   12] Training loss: 0.42261479, Validation loss: 0.41616730, Gradient norm: 1.75594141
INFO:root:At the start of the epoch: mem (CPU python)=9193.64453125MB; mem (CPU total)=15804.1640625MB
INFO:root:[   13] Training loss: 0.41957685, Validation loss: 0.42223357, Gradient norm: 1.94705205
INFO:root:At the start of the epoch: mem (CPU python)=9214.8046875MB; mem (CPU total)=15825.625MB
INFO:root:[   14] Training loss: 0.41872496, Validation loss: 0.43523986, Gradient norm: 2.41246288
INFO:root:At the start of the epoch: mem (CPU python)=9235.97265625MB; mem (CPU total)=15846.83203125MB
INFO:root:[   15] Training loss: 0.41823242, Validation loss: 0.42718972, Gradient norm: 2.75094312
INFO:root:At the start of the epoch: mem (CPU python)=9257.13671875MB; mem (CPU total)=15919.66796875MB
INFO:root:[   16] Training loss: 0.41889745, Validation loss: 0.43251092, Gradient norm: 3.10247875
INFO:root:At the start of the epoch: mem (CPU python)=9278.30078125MB; mem (CPU total)=15908.75MB
INFO:root:[   17] Training loss: 0.41865136, Validation loss: 0.41281864, Gradient norm: 3.34345163
INFO:root:At the start of the epoch: mem (CPU python)=9303.859375MB; mem (CPU total)=15931.8125MB
INFO:root:[   18] Training loss: 0.41902186, Validation loss: 0.42055705, Gradient norm: 3.62164468
INFO:root:At the start of the epoch: mem (CPU python)=9325.18359375MB; mem (CPU total)=15921.22265625MB
INFO:root:[   19] Training loss: 0.42154484, Validation loss: 0.42437072, Gradient norm: 3.83725196
INFO:root:At the start of the epoch: mem (CPU python)=9346.34765625MB; mem (CPU total)=15999.35546875MB
INFO:root:[   20] Training loss: 0.41832547, Validation loss: 0.42608562, Gradient norm: 4.11680102
INFO:root:At the start of the epoch: mem (CPU python)=9367.51171875MB; mem (CPU total)=15994.76953125MB
INFO:root:[   21] Training loss: 0.41985623, Validation loss: 0.43244337, Gradient norm: 4.27081433
INFO:root:At the start of the epoch: mem (CPU python)=9388.67578125MB; mem (CPU total)=16095.7734375MB
INFO:root:[   22] Training loss: 0.41978709, Validation loss: 0.40251695, Gradient norm: 4.43814969
INFO:root:At the start of the epoch: mem (CPU python)=9409.83984375MB; mem (CPU total)=16114.44921875MB
INFO:root:[   23] Training loss: 0.42129698, Validation loss: 0.43143313, Gradient norm: 4.58433158
INFO:root:At the start of the epoch: mem (CPU python)=9431.00390625MB; mem (CPU total)=16066.56640625MB
INFO:root:[   24] Training loss: 0.42002456, Validation loss: 0.41747146, Gradient norm: 4.91657875
INFO:root:At the start of the epoch: mem (CPU python)=9452.171875MB; mem (CPU total)=16071.7109375MB
INFO:root:[   25] Training loss: 0.42044347, Validation loss: 0.41827870, Gradient norm: 4.95412593
INFO:root:At the start of the epoch: mem (CPU python)=9473.33203125MB; mem (CPU total)=16077.6015625MB
INFO:root:[   26] Training loss: 0.42016740, Validation loss: 0.42090553, Gradient norm: 4.97376292
INFO:root:At the start of the epoch: mem (CPU python)=9496.15234375MB; mem (CPU total)=16103.01171875MB
INFO:root:[   27] Training loss: 0.41738347, Validation loss: 0.42178822, Gradient norm: 5.19419874
INFO:root:At the start of the epoch: mem (CPU python)=9517.53515625MB; mem (CPU total)=16133.73828125MB
INFO:root:[   28] Training loss: 0.41857902, Validation loss: 0.40885262, Gradient norm: 5.21998075
INFO:root:At the start of the epoch: mem (CPU python)=9538.703125MB; mem (CPU total)=16217.4609375MB
INFO:root:[   29] Training loss: 0.41770741, Validation loss: 0.41078216, Gradient norm: 5.30570327
INFO:root:At the start of the epoch: mem (CPU python)=9559.8671875MB; mem (CPU total)=16158.11328125MB
INFO:root:[   30] Training loss: 0.41651185, Validation loss: 0.40781903, Gradient norm: 5.60395527
INFO:root:At the start of the epoch: mem (CPU python)=9584.56640625MB; mem (CPU total)=16192.671875MB
INFO:root:[   31] Training loss: 0.41728937, Validation loss: 0.41982013, Gradient norm: 5.54632401
INFO:root:At the start of the epoch: mem (CPU python)=9605.9453125MB; mem (CPU total)=16214.8125MB
INFO:root:[   32] Training loss: 0.41773013, Validation loss: 0.42091333, Gradient norm: 5.66962505
INFO:root:At the start of the epoch: mem (CPU python)=9628.890625MB; mem (CPU total)=16269.90625MB
INFO:root:[   33] Training loss: 0.41397401, Validation loss: 0.42805889, Gradient norm: 5.54857036
INFO:root:At the start of the epoch: mem (CPU python)=9650.5234375MB; mem (CPU total)=16272.328125MB
INFO:root:[   34] Training loss: 0.41781133, Validation loss: 0.41156257, Gradient norm: 5.89585864
INFO:root:At the start of the epoch: mem (CPU python)=9671.69140625MB; mem (CPU total)=16283.80078125MB
INFO:root:[   35] Training loss: 0.41375747, Validation loss: 0.43737304, Gradient norm: 5.71067523
INFO:root:At the start of the epoch: mem (CPU python)=9692.85546875MB; mem (CPU total)=16352.5390625MB
INFO:root:[   36] Training loss: 0.41323117, Validation loss: 0.41562660, Gradient norm: 5.77850828
INFO:root:At the start of the epoch: mem (CPU python)=9714.01953125MB; mem (CPU total)=16341.64453125MB
INFO:root:[   37] Training loss: 0.41425184, Validation loss: 0.43467047, Gradient norm: 5.79209992
INFO:root:At the start of the epoch: mem (CPU python)=9737.37109375MB; mem (CPU total)=16384.78125MB
INFO:root:[   38] Training loss: 0.41408693, Validation loss: 0.43102879, Gradient norm: 5.93788931
INFO:root:At the start of the epoch: mem (CPU python)=9758.97265625MB; mem (CPU total)=16369.58984375MB
INFO:root:[   39] Training loss: 0.41317662, Validation loss: 0.41458331, Gradient norm: 5.99122524
INFO:root:At the start of the epoch: mem (CPU python)=9780.140625MB; mem (CPU total)=16406.796875MB
INFO:root:[   40] Training loss: 0.41264917, Validation loss: 0.43314977, Gradient norm: 5.88326517
INFO:root:At the start of the epoch: mem (CPU python)=9802.12109375MB; mem (CPU total)=16408.453125MB
INFO:root:[   41] Training loss: 0.41054804, Validation loss: 0.41458617, Gradient norm: 5.98870236
INFO:root:At the start of the epoch: mem (CPU python)=9824.625MB; mem (CPU total)=16434.39453125MB
INFO:root:[   42] Training loss: 0.41027328, Validation loss: 0.41324119, Gradient norm: 6.04280363
INFO:root:At the start of the epoch: mem (CPU python)=9845.8984375MB; mem (CPU total)=16479.2578125MB
INFO:root:[   43] Training loss: 0.41117083, Validation loss: 0.46912086, Gradient norm: 6.08443097
INFO:root:At the start of the epoch: mem (CPU python)=9867.06640625MB; mem (CPU total)=16500.75MB
INFO:root:[   44] Training loss: 0.41043427, Validation loss: 0.41540760, Gradient norm: 6.12838603
INFO:root:At the start of the epoch: mem (CPU python)=9888.28515625MB; mem (CPU total)=16507.6640625MB
INFO:root:[   45] Training loss: 0.41141521, Validation loss: 0.42768254, Gradient norm: 6.24478346
INFO:root:At the start of the epoch: mem (CPU python)=9909.92578125MB; mem (CPU total)=16566.8671875MB
INFO:root:[   46] Training loss: 0.41036674, Validation loss: 0.41937374, Gradient norm: 6.34711682
INFO:root:At the start of the epoch: mem (CPU python)=9936.2421875MB; mem (CPU total)=16548.66796875MB
INFO:root:[   47] Training loss: 0.41107866, Validation loss: 0.42625032, Gradient norm: 6.32939237
INFO:root:At the start of the epoch: mem (CPU python)=9957.40625MB; mem (CPU total)=16577.73828125MB
INFO:root:[   48] Training loss: 0.41118843, Validation loss: 0.44737098, Gradient norm: 6.39557696
INFO:root:At the start of the epoch: mem (CPU python)=9979.08203125MB; mem (CPU total)=16568.625MB
INFO:root:[   49] Training loss: 0.41056347, Validation loss: 0.42085823, Gradient norm: 6.24361114
INFO:root:At the start of the epoch: mem (CPU python)=10003.27734375MB; mem (CPU total)=16658.97265625MB
INFO:root:[   50] Training loss: 0.40986520, Validation loss: 0.41135830, Gradient norm: 6.48642873
INFO:root:At the start of the epoch: mem (CPU python)=10024.7421875MB; mem (CPU total)=16643.85546875MB
INFO:root:[   51] Training loss: 0.40894394, Validation loss: 0.41408912, Gradient norm: 6.45128858
INFO:root:At the start of the epoch: mem (CPU python)=10046.0078125MB; mem (CPU total)=16668.29296875MB
INFO:root:[   52] Training loss: 0.41082515, Validation loss: 0.44380316, Gradient norm: 6.59952361
INFO:root:At the start of the epoch: mem (CPU python)=10067.2265625MB; mem (CPU total)=16690.55078125MB
INFO:root:[   53] Training loss: 0.40915396, Validation loss: 0.40099257, Gradient norm: 6.55704966
INFO:root:At the start of the epoch: mem (CPU python)=10088.390625MB; mem (CPU total)=16700.25MB
INFO:root:[   54] Training loss: 0.40812363, Validation loss: 0.40840116, Gradient norm: 6.67878020
INFO:root:At the start of the epoch: mem (CPU python)=10109.62109375MB; mem (CPU total)=16732.2578125MB
INFO:root:[   55] Training loss: 0.40777650, Validation loss: 0.43296456, Gradient norm: 6.85659373
INFO:root:At the start of the epoch: mem (CPU python)=10130.796875MB; mem (CPU total)=16726.99609375MB
INFO:root:[   56] Training loss: 0.41005046, Validation loss: 0.40534063, Gradient norm: 6.91075684
INFO:root:At the start of the epoch: mem (CPU python)=10161.99609375MB; mem (CPU total)=16761.05859375MB
INFO:root:[   57] Training loss: 0.49434248, Validation loss: 0.43003404, Gradient norm: 8.74829338
INFO:root:At the start of the epoch: mem (CPU python)=10186.125MB; mem (CPU total)=16795.27734375MB
INFO:root:[   58] Training loss: 0.41123603, Validation loss: 0.41673584, Gradient norm: 6.64559070
INFO:root:At the start of the epoch: mem (CPU python)=10207.53125MB; mem (CPU total)=16833.43359375MB
INFO:root:[   59] Training loss: 0.40636919, Validation loss: 0.41660812, Gradient norm: 6.66491032
INFO:root:At the start of the epoch: mem (CPU python)=10228.90625MB; mem (CPU total)=16818.421875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   60] Training loss: 0.40571236, Validation loss: 0.44096061, Gradient norm: 6.60404588
INFO:root:At the start of the epoch: mem (CPU python)=10250.0703125MB; mem (CPU total)=16703.10546875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   61] Training loss: 0.37997993, Validation loss: 0.39054073, Gradient norm: 5.89385655
INFO:root:At the start of the epoch: mem (CPU python)=10271.734375MB; mem (CPU total)=16875.2421875MB
INFO:root:[   62] Training loss: 0.36836283, Validation loss: 0.38027177, Gradient norm: 6.22574082
INFO:root:At the start of the epoch: mem (CPU python)=10292.8984375MB; mem (CPU total)=16995.703125MB
INFO:root:[   63] Training loss: 0.36727053, Validation loss: 0.37893084, Gradient norm: 7.80331492
INFO:root:At the start of the epoch: mem (CPU python)=10314.3203125MB; mem (CPU total)=17005.390625MB
INFO:root:[   64] Training loss: 0.36984736, Validation loss: 0.39000686, Gradient norm: 10.31740236
INFO:root:At the start of the epoch: mem (CPU python)=10335.484375MB; mem (CPU total)=16953.7109375MB
INFO:root:[   65] Training loss: 0.37247808, Validation loss: 0.38816876, Gradient norm: 10.97902731
INFO:root:At the start of the epoch: mem (CPU python)=10358.484375MB; mem (CPU total)=16975.29296875MB
INFO:root:[   66] Training loss: 0.37149503, Validation loss: 0.38573903, Gradient norm: 11.63312286
INFO:root:At the start of the epoch: mem (CPU python)=10379.6484375MB; mem (CPU total)=16951.91796875MB
INFO:root:[   67] Training loss: 0.37250276, Validation loss: 0.38392874, Gradient norm: 13.05461752
INFO:root:At the start of the epoch: mem (CPU python)=10401.23046875MB; mem (CPU total)=17008.4921875MB
INFO:root:[   68] Training loss: 0.37426772, Validation loss: 0.38768409, Gradient norm: 14.37513677
INFO:root:At the start of the epoch: mem (CPU python)=10423.19921875MB; mem (CPU total)=17034.3984375MB
INFO:root:[   69] Training loss: 0.37444690, Validation loss: 0.38549921, Gradient norm: 15.34861086
INFO:root:At the start of the epoch: mem (CPU python)=10444.36328125MB; mem (CPU total)=17063.21484375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   70] Training loss: 0.37692557, Validation loss: 0.38508010, Gradient norm: 16.49737354
INFO:root:At the start of the epoch: mem (CPU python)=10465.84765625MB; mem (CPU total)=17076.64453125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   71] Training loss: 0.36719929, Validation loss: 0.37751752, Gradient norm: 13.96766664
INFO:root:At the start of the epoch: mem (CPU python)=10488.640625MB; mem (CPU total)=17114.66796875MB
INFO:root:[   72] Training loss: 0.36108842, Validation loss: 0.37417194, Gradient norm: 11.16489977
INFO:root:At the start of the epoch: mem (CPU python)=10510.05078125MB; mem (CPU total)=17122.0703125MB
INFO:root:[   73] Training loss: 0.36080919, Validation loss: 0.37501445, Gradient norm: 12.04833191
INFO:root:At the start of the epoch: mem (CPU python)=10531.21875MB; mem (CPU total)=17161.7421875MB
INFO:root:[   74] Training loss: 0.36154954, Validation loss: 0.37560941, Gradient norm: 14.27378628
INFO:root:At the start of the epoch: mem (CPU python)=10552.3828125MB; mem (CPU total)=17176.203125MB
INFO:root:[   75] Training loss: 0.36140801, Validation loss: 0.37509502, Gradient norm: 14.77708206
INFO:root:At the start of the epoch: mem (CPU python)=10574.01953125MB; mem (CPU total)=17179.98828125MB
INFO:root:[   76] Training loss: 0.36112234, Validation loss: 0.37467865, Gradient norm: 14.94777648
INFO:root:At the start of the epoch: mem (CPU python)=10595.4609375MB; mem (CPU total)=17281.34765625MB
INFO:root:[   77] Training loss: 0.36237457, Validation loss: 0.37416202, Gradient norm: 18.72835283
INFO:root:At the start of the epoch: mem (CPU python)=10616.625MB; mem (CPU total)=17243.66796875MB
INFO:root:[   78] Training loss: 0.36335347, Validation loss: 0.37789343, Gradient norm: 18.75357417
INFO:root:At the start of the epoch: mem (CPU python)=10638.94140625MB; mem (CPU total)=17252.23828125MB
INFO:root:[   79] Training loss: 0.36260942, Validation loss: 0.37265894, Gradient norm: 18.69811639
INFO:root:At the start of the epoch: mem (CPU python)=10660.34765625MB; mem (CPU total)=17316.3671875MB
INFO:root:[   80] Training loss: 0.36298276, Validation loss: 0.37536352, Gradient norm: 19.00734393
INFO:root:At the start of the epoch: mem (CPU python)=10683.5703125MB; mem (CPU total)=17296.8046875MB
INFO:root:[   81] Training loss: 0.36503395, Validation loss: 0.38185683, Gradient norm: 23.93364880
INFO:root:At the start of the epoch: mem (CPU python)=10704.734375MB; mem (CPU total)=17294.4453125MB
INFO:root:[   82] Training loss: 0.36362972, Validation loss: 0.37603613, Gradient norm: 21.91059450
INFO:root:At the start of the epoch: mem (CPU python)=10726.1953125MB; mem (CPU total)=17348.4609375MB
INFO:root:[   83] Training loss: 0.36338975, Validation loss: 0.37712675, Gradient norm: 22.22785847
INFO:root:At the start of the epoch: mem (CPU python)=10747.359375MB; mem (CPU total)=17397.41796875MB
INFO:root:[   84] Training loss: 0.36436735, Validation loss: 0.37988322, Gradient norm: 23.44478457
INFO:root:At the start of the epoch: mem (CPU python)=10768.5234375MB; mem (CPU total)=17374.54296875MB
INFO:root:[   85] Training loss: 0.36604352, Validation loss: 0.38063636, Gradient norm: 27.72177620
INFO:root:At the start of the epoch: mem (CPU python)=10791.84375MB; mem (CPU total)=17398.9609375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   86] Training loss: 0.36491551, Validation loss: 0.37902267, Gradient norm: 25.66913047
INFO:root:At the start of the epoch: mem (CPU python)=10817.01171875MB; mem (CPU total)=17431.671875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   87] Training loss: 0.36043748, Validation loss: 0.37338800, Gradient norm: 19.86638972
INFO:root:At the start of the epoch: mem (CPU python)=10838.171875MB; mem (CPU total)=17267.1640625MB
INFO:root:[   88] Training loss: 0.35861297, Validation loss: 0.36979886, Gradient norm: 15.35587467
INFO:root:At the start of the epoch: mem (CPU python)=10859.546875MB; mem (CPU total)=17480.98046875MB
INFO:root:[   89] Training loss: 0.35836970, Validation loss: 0.37031236, Gradient norm: 15.68944257
INFO:root:At the start of the epoch: mem (CPU python)=10880.7109375MB; mem (CPU total)=17560.4140625MB
INFO:root:[   90] Training loss: 0.35818924, Validation loss: 0.37018369, Gradient norm: 15.89678922
INFO:root:At the start of the epoch: mem (CPU python)=10901.875MB; mem (CPU total)=17587.65234375MB
INFO:root:[   91] Training loss: 0.35853072, Validation loss: 0.37001606, Gradient norm: 17.47718416
INFO:root:At the start of the epoch: mem (CPU python)=10923.046875MB; mem (CPU total)=17547.23046875MB
INFO:root:[   92] Training loss: 0.35891249, Validation loss: 0.37155390, Gradient norm: 17.86926262
INFO:root:At the start of the epoch: mem (CPU python)=10944.59765625MB; mem (CPU total)=17565.06640625MB
INFO:root:[   93] Training loss: 0.35929335, Validation loss: 0.36981287, Gradient norm: 17.92813672
INFO:root:At the start of the epoch: mem (CPU python)=10966.49609375MB; mem (CPU total)=17566.03515625MB
INFO:root:[   94] Training loss: 0.35878164, Validation loss: 0.37023216, Gradient norm: 18.36356202
INFO:root:At the start of the epoch: mem (CPU python)=10990.5MB; mem (CPU total)=17602.46875MB
INFO:root:[   95] Training loss: 0.35862497, Validation loss: 0.37049468, Gradient norm: 19.91711147
INFO:root:At the start of the epoch: mem (CPU python)=11012.08984375MB; mem (CPU total)=17624.87890625MB
INFO:root:[   96] Training loss: 0.35866977, Validation loss: 0.36921455, Gradient norm: 19.10196727
INFO:root:At the start of the epoch: mem (CPU python)=11033.2578125MB; mem (CPU total)=17658.54296875MB
INFO:root:[   97] Training loss: 0.35862998, Validation loss: 0.37000032, Gradient norm: 19.84199417
INFO:root:At the start of the epoch: mem (CPU python)=11060.046875MB; mem (CPU total)=17682.80859375MB
INFO:root:[   98] Training loss: 0.35910352, Validation loss: 0.36902528, Gradient norm: 20.85216843
INFO:root:At the start of the epoch: mem (CPU python)=11081.2109375MB; mem (CPU total)=17667.5234375MB
INFO:root:[   99] Training loss: 0.35866346, Validation loss: 0.37353140, Gradient norm: 21.91034731
INFO:root:At the start of the epoch: mem (CPU python)=11102.74609375MB; mem (CPU total)=17679.6953125MB
INFO:root:[  100] Training loss: 0.35890711, Validation loss: 0.37159444, Gradient norm: 20.83735484
INFO:root:At the start of the epoch: mem (CPU python)=11123.91015625MB; mem (CPU total)=17724.01171875MB
INFO:root:[  101] Training loss: 0.35891780, Validation loss: 0.37414519, Gradient norm: 21.76018501
INFO:root:At the start of the epoch: mem (CPU python)=11145.07421875MB; mem (CPU total)=17754.953125MB
INFO:root:[  102] Training loss: 0.35923267, Validation loss: 0.37065934, Gradient norm: 22.64951406
INFO:root:At the start of the epoch: mem (CPU python)=11166.2421875MB; mem (CPU total)=17737.45703125MB
INFO:root:[  103] Training loss: 0.35954201, Validation loss: 0.37153461, Gradient norm: 23.91998922
INFO:root:At the start of the epoch: mem (CPU python)=11193.06640625MB; mem (CPU total)=17835.99609375MB
INFO:root:[  104] Training loss: 0.35930527, Validation loss: 0.37265335, Gradient norm: 23.18522832
INFO:root:At the start of the epoch: mem (CPU python)=11214.48828125MB; mem (CPU total)=17832.578125MB
INFO:root:[  105] Training loss: 0.35948796, Validation loss: 0.37075952, Gradient norm: 24.91224087
INFO:root:At the start of the epoch: mem (CPU python)=11235.74609375MB; mem (CPU total)=17863.88671875MB
INFO:root:[  106] Training loss: 0.35906756, Validation loss: 0.36990093, Gradient norm: 24.04136939
INFO:root:At the start of the epoch: mem (CPU python)=11256.90625MB; mem (CPU total)=17850.79296875MB
INFO:root:[  107] Training loss: 0.35985007, Validation loss: 0.37102040, Gradient norm: 26.24162937
INFO:root:At the start of the epoch: mem (CPU python)=11278.0703125MB; mem (CPU total)=17876.6875MB
INFO:root:EP 107: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=11299.02734375MB; mem (CPU total)=17901.74609375MB
INFO:root:Training the model took 2905.231s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.32518
INFO:root:EnergyScoreValidation: 0.24535
INFO:root:CRPSValidation: 0.09814
INFO:root:Gaussian NLLValidation: -0.11151
INFO:root:CoverageValidation: 0.76444
INFO:root:IntervalWidthValidation: 0.37509
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.34998
INFO:root:EnergyScoreTest: 0.26753
INFO:root:CRPSTest: 0.10818
INFO:root:Gaussian NLLTest: 0.186
INFO:root:CoverageTest: 0.72598
INFO:root:IntervalWidthTest: 0.37397
INFO:root:After validation: mem (CPU python)=11306.140625MB; mem (CPU total)=17951.24609375MB
