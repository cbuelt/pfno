INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=574.828125MB; mem (CPU total)=969.69921875MB
INFO:root:############### Starting experiment with config file ks/uno_dropout.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12453.890625MB; mem (CPU total)=979.43359375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12453.890625MB; mem (CPU total)=979.43359375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=12453.890625MB; mem (CPU total)=2173.21875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=2181.96484375MB
INFO:root:[    1] Training loss: 1.01177202, Validation loss: 1.00114928, Gradient norm: 0.03093198
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3356.5859375MB
INFO:root:[    2] Training loss: 0.99409220, Validation loss: 0.99092839, Gradient norm: 0.05182582
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3396.2109375MB
INFO:root:[    3] Training loss: 0.98779604, Validation loss: 0.98736555, Gradient norm: 0.05582589
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3434.390625MB
INFO:root:[    4] Training loss: 0.98510302, Validation loss: 0.98548282, Gradient norm: 0.05712546
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3471.5MB
INFO:root:[    5] Training loss: 0.98363344, Validation loss: 0.98325359, Gradient norm: 0.06094974
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3509.6796875MB
INFO:root:[    6] Training loss: 0.98254904, Validation loss: 0.98216409, Gradient norm: 0.06479776
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3548.21484375MB
INFO:root:[    7] Training loss: 0.98155810, Validation loss: 0.98151884, Gradient norm: 0.06551295
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3586.734375MB
INFO:root:[    8] Training loss: 0.98054946, Validation loss: 0.98241153, Gradient norm: 0.06561578
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3625.140625MB
INFO:root:[    9] Training loss: 0.97967161, Validation loss: 0.98051041, Gradient norm: 0.06797365
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3663.625MB
INFO:root:[   10] Training loss: 0.97897932, Validation loss: 0.98001860, Gradient norm: 0.07676434
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3702.14453125MB
INFO:root:[   11] Training loss: 0.97812784, Validation loss: 0.97942712, Gradient norm: 0.07363467
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3740.1640625MB
INFO:root:[   12] Training loss: 0.97746112, Validation loss: 0.97842659, Gradient norm: 0.07871543
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3778.3359375MB
INFO:root:[   13] Training loss: 0.97669885, Validation loss: 0.97751771, Gradient norm: 0.07680843
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3817.03125MB
INFO:root:[   14] Training loss: 0.97621546, Validation loss: 0.97690731, Gradient norm: 0.08878792
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3855.08203125MB
INFO:root:[   15] Training loss: 0.97554457, Validation loss: 0.97753902, Gradient norm: 0.08572628
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3893.4921875MB
INFO:root:[   16] Training loss: 0.97502020, Validation loss: 0.97600792, Gradient norm: 0.08915763
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3931.75390625MB
INFO:root:[   17] Training loss: 0.97457729, Validation loss: 0.97513485, Gradient norm: 0.09187542
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=3969.7578125MB
INFO:root:[   18] Training loss: 0.97395024, Validation loss: 0.97462653, Gradient norm: 0.09354962
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4008.68359375MB
INFO:root:[   19] Training loss: 0.97337860, Validation loss: 0.97423493, Gradient norm: 0.08996959
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4046.1328125MB
INFO:root:[   20] Training loss: 0.97286592, Validation loss: 0.97379030, Gradient norm: 0.09986360
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4084.71875MB
INFO:root:[   21] Training loss: 0.97241615, Validation loss: 0.97323427, Gradient norm: 0.08997751
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4123.32421875MB
INFO:root:[   22] Training loss: 0.97195725, Validation loss: 0.97358448, Gradient norm: 0.09917041
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4161.30078125MB
INFO:root:[   23] Training loss: 0.97148467, Validation loss: 0.97213523, Gradient norm: 0.09389054
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4199.22265625MB
INFO:root:[   24] Training loss: 0.97096081, Validation loss: 0.97153680, Gradient norm: 0.09321385
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4237.5859375MB
INFO:root:[   25] Training loss: 0.97060849, Validation loss: 0.97165846, Gradient norm: 0.09481246
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4276.07421875MB
INFO:root:[   26] Training loss: 0.97041573, Validation loss: 0.97087752, Gradient norm: 0.09921247
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4313.71484375MB
INFO:root:[   27] Training loss: 0.96995530, Validation loss: 0.97073966, Gradient norm: 0.09891033
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4351.859375MB
INFO:root:[   28] Training loss: 0.96969455, Validation loss: 0.97072710, Gradient norm: 0.09536809
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4390.40234375MB
INFO:root:[   29] Training loss: 0.96945836, Validation loss: 0.96990973, Gradient norm: 0.09802647
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4428.80078125MB
INFO:root:[   30] Training loss: 0.96909589, Validation loss: 0.96972288, Gradient norm: 0.09584849
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4467.17578125MB
INFO:root:[   31] Training loss: 0.96891839, Validation loss: 0.96959979, Gradient norm: 0.09960785
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4505.59765625MB
INFO:root:[   32] Training loss: 0.96851814, Validation loss: 0.96931820, Gradient norm: 0.09344508
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4544.12890625MB
INFO:root:[   33] Training loss: 0.96824787, Validation loss: 0.96950255, Gradient norm: 0.09778055
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4582.28515625MB
INFO:root:[   34] Training loss: 0.96818788, Validation loss: 0.96912583, Gradient norm: 0.10331603
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4620.67578125MB
INFO:root:[   35] Training loss: 0.96820116, Validation loss: 0.96888753, Gradient norm: 0.10897010
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4658.90234375MB
INFO:root:[   36] Training loss: 0.96785562, Validation loss: 0.96974373, Gradient norm: 0.09703896
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4697.30078125MB
INFO:root:[   37] Training loss: 0.96749388, Validation loss: 0.96893343, Gradient norm: 0.09487799
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4735.43359375MB
INFO:root:[   38] Training loss: 0.96742413, Validation loss: 0.96939693, Gradient norm: 0.10311321
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4773.59375MB
INFO:root:[   39] Training loss: 0.96722091, Validation loss: 0.96795309, Gradient norm: 0.09998595
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4811.02734375MB
INFO:root:[   40] Training loss: 0.96709878, Validation loss: 0.96761548, Gradient norm: 0.10187023
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4849.3828125MB
INFO:root:[   41] Training loss: 0.96694810, Validation loss: 0.96759525, Gradient norm: 0.10282009
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4887.8515625MB
INFO:root:[   42] Training loss: 0.96688905, Validation loss: 0.96721413, Gradient norm: 0.10100589
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4925.91015625MB
INFO:root:[   43] Training loss: 0.96644369, Validation loss: 0.96859258, Gradient norm: 0.10078080
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=4964.31640625MB
INFO:root:[   44] Training loss: 0.96655734, Validation loss: 0.96707578, Gradient norm: 0.10562322
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5002.1875MB
INFO:root:[   45] Training loss: 0.96623232, Validation loss: 0.96801729, Gradient norm: 0.10176957
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5040.59375MB
INFO:root:[   46] Training loss: 0.96638488, Validation loss: 0.96716794, Gradient norm: 0.11037352
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5078.83984375MB
INFO:root:[   47] Training loss: 0.96581082, Validation loss: 0.96786905, Gradient norm: 0.09703274
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5117.18359375MB
INFO:root:[   48] Training loss: 0.96577494, Validation loss: 0.96646112, Gradient norm: 0.10260054
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5155.3671875MB
INFO:root:[   49] Training loss: 0.96565791, Validation loss: 0.96670141, Gradient norm: 0.10301202
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5194.83203125MB
INFO:root:[   50] Training loss: 0.96535627, Validation loss: 0.96621240, Gradient norm: 0.10895875
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5233.3359375MB
INFO:root:[   51] Training loss: 0.96528636, Validation loss: 0.96653443, Gradient norm: 0.10820140
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5272.80859375MB
INFO:root:[   52] Training loss: 0.96519013, Validation loss: 0.96592692, Gradient norm: 0.10505167
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5310.84375MB
INFO:root:[   53] Training loss: 0.96500353, Validation loss: 0.96610431, Gradient norm: 0.11493198
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5349.26953125MB
INFO:root:[   54] Training loss: 0.96481410, Validation loss: 0.96597250, Gradient norm: 0.10854683
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5387.1484375MB
INFO:root:[   55] Training loss: 0.96464170, Validation loss: 0.96574890, Gradient norm: 0.10440058
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5425.5078125MB
INFO:root:[   56] Training loss: 0.96432292, Validation loss: 0.96538940, Gradient norm: 0.10184316
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5462.73046875MB
INFO:root:[   57] Training loss: 0.96432610, Validation loss: 0.96577027, Gradient norm: 0.11011399
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5501.12109375MB
INFO:root:[   58] Training loss: 0.96402038, Validation loss: 0.96553925, Gradient norm: 0.10657619
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5539.51171875MB
INFO:root:[   59] Training loss: 0.96386248, Validation loss: 0.96597528, Gradient norm: 0.10818062
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5577.65625MB
INFO:root:[   60] Training loss: 0.96385532, Validation loss: 0.96487179, Gradient norm: 0.10853538
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5615.78125MB
INFO:root:[   61] Training loss: 0.96353793, Validation loss: 0.96416343, Gradient norm: 0.10812837
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5654.05078125MB
INFO:root:[   62] Training loss: 0.96346889, Validation loss: 0.96431061, Gradient norm: 0.10903527
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5692.1796875MB
INFO:root:[   63] Training loss: 0.96316568, Validation loss: 0.96482794, Gradient norm: 0.10715714
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5730.32421875MB
INFO:root:[   64] Training loss: 0.96306938, Validation loss: 0.96412619, Gradient norm: 0.10404150
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5767.8203125MB
INFO:root:[   65] Training loss: 0.96287390, Validation loss: 0.96420661, Gradient norm: 0.10586795
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5806.203125MB
INFO:root:[   66] Training loss: 0.96286829, Validation loss: 0.96401617, Gradient norm: 0.11226858
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5844.33984375MB
INFO:root:[   67] Training loss: 0.96274663, Validation loss: 0.96342219, Gradient norm: 0.10513370
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5882.19140625MB
INFO:root:[   68] Training loss: 0.96258102, Validation loss: 0.96373740, Gradient norm: 0.10841790
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5920.80078125MB
INFO:root:[   69] Training loss: 0.96241620, Validation loss: 0.96312417, Gradient norm: 0.11285132
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5958.74609375MB
INFO:root:[   70] Training loss: 0.96225330, Validation loss: 0.96371898, Gradient norm: 0.11244825
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=5997.3828125MB
INFO:root:[   71] Training loss: 0.96241104, Validation loss: 0.96325181, Gradient norm: 0.11591545
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6035.49609375MB
INFO:root:[   72] Training loss: 0.96204888, Validation loss: 0.96360003, Gradient norm: 0.10925358
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6073.640625MB
INFO:root:[   73] Training loss: 0.96197487, Validation loss: 0.96338349, Gradient norm: 0.11576687
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6111.53515625MB
INFO:root:[   74] Training loss: 0.96173952, Validation loss: 0.96286739, Gradient norm: 0.11068917
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6150.53515625MB
INFO:root:[   75] Training loss: 0.96161863, Validation loss: 0.96229326, Gradient norm: 0.10722517
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6187.296875MB
INFO:root:[   76] Training loss: 0.96145686, Validation loss: 0.96261286, Gradient norm: 0.10815954
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6225.6796875MB
INFO:root:[   77] Training loss: 0.96149150, Validation loss: 0.96268454, Gradient norm: 0.11006787
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6263.06640625MB
INFO:root:[   78] Training loss: 0.96137301, Validation loss: 0.96229479, Gradient norm: 0.10988931
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6301.6953125MB
INFO:root:[   79] Training loss: 0.96120649, Validation loss: 0.96225252, Gradient norm: 0.11234830
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6340.08984375MB
INFO:root:[   80] Training loss: 0.96108017, Validation loss: 0.96240020, Gradient norm: 0.11249447
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6378.2265625MB
INFO:root:[   81] Training loss: 0.96087443, Validation loss: 0.96384833, Gradient norm: 0.11321418
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6416.37109375MB
INFO:root:[   82] Training loss: 0.96083396, Validation loss: 0.96185593, Gradient norm: 0.11096540
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6454.5234375MB
INFO:root:[   83] Training loss: 0.96076823, Validation loss: 0.96177876, Gradient norm: 0.11687831
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6492.6171875MB
INFO:root:[   84] Training loss: 0.96059068, Validation loss: 0.96174433, Gradient norm: 0.11174793
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6530.71484375MB
INFO:root:[   85] Training loss: 0.96047515, Validation loss: 0.96178525, Gradient norm: 0.11775704
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6569.33203125MB
INFO:root:[   86] Training loss: 0.96024680, Validation loss: 0.96136793, Gradient norm: 0.11227091
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6607.015625MB
INFO:root:[   87] Training loss: 0.96038170, Validation loss: 0.96155048, Gradient norm: 0.12016671
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6644.93359375MB
INFO:root:[   88] Training loss: 0.96013206, Validation loss: 0.96127361, Gradient norm: 0.11023891
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6682.94140625MB
INFO:root:[   89] Training loss: 0.96008426, Validation loss: 0.96016423, Gradient norm: 0.11462394
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6721.1015625MB
INFO:root:[   90] Training loss: 0.95995354, Validation loss: 0.96127385, Gradient norm: 0.11281534
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6759.48046875MB
INFO:root:[   91] Training loss: 0.95994289, Validation loss: 0.96120601, Gradient norm: 0.11595444
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6797.1796875MB
INFO:root:[   92] Training loss: 0.95973152, Validation loss: 0.96067101, Gradient norm: 0.12037421
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6835.578125MB
INFO:root:[   93] Training loss: 0.95947750, Validation loss: 0.96048767, Gradient norm: 0.11351928
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6873.7421875MB
INFO:root:[   94] Training loss: 0.95948263, Validation loss: 0.96041323, Gradient norm: 0.11786474
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6912.14453125MB
INFO:root:[   95] Training loss: 0.95937324, Validation loss: 0.96072415, Gradient norm: 0.11700459
INFO:root:At the start of the epoch: mem (CPU python)=12453.890625MB; mem (CPU total)=6949.9921875MB
