INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=581.2578125MB; mem (CPU total)=971.78125MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12460.72265625MB; mem (CPU total)=982.71484375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=12460.72265625MB; mem (CPU total)=982.8125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12460.72265625MB; mem (CPU total)=2176.7109375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=2186.9453125MB
INFO:root:[    1] Training loss: 0.78267257, Validation loss: 0.72598350, Gradient norm: 0.51867716
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3368.10546875MB
INFO:root:[    2] Training loss: 0.72356128, Validation loss: 0.72152505, Gradient norm: 0.46957764
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3406.68359375MB
INFO:root:[    3] Training loss: 0.72085831, Validation loss: 0.72104941, Gradient norm: 0.34329228
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3444.8046875MB
INFO:root:[    4] Training loss: 0.72023231, Validation loss: 0.72008729, Gradient norm: 0.30607830
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3483.30078125MB
INFO:root:[    5] Training loss: 0.71980910, Validation loss: 0.72004788, Gradient norm: 0.21377462
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3521.75390625MB
INFO:root:[    6] Training loss: 0.71950705, Validation loss: 0.71994954, Gradient norm: 0.21062008
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3560.3125MB
INFO:root:[    7] Training loss: 0.71929971, Validation loss: 0.71965892, Gradient norm: 0.32183471
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3598.25MB
INFO:root:[    8] Training loss: 0.71883353, Validation loss: 0.71876909, Gradient norm: 0.28532160
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3636.1796875MB
INFO:root:[    9] Training loss: 0.71766566, Validation loss: 0.71682707, Gradient norm: 0.20805685
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3674.765625MB
INFO:root:[   10] Training loss: 0.71173757, Validation loss: 0.70651721, Gradient norm: 0.20161162
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3713.125MB
INFO:root:[   11] Training loss: 0.70127023, Validation loss: 0.69590333, Gradient norm: 0.16282083
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3749.32421875MB
INFO:root:[   12] Training loss: 0.69047718, Validation loss: 0.68571523, Gradient norm: 0.17950516
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3788.0MB
INFO:root:[   13] Training loss: 0.68197861, Validation loss: 0.67866659, Gradient norm: 0.15664435
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3825.7421875MB
INFO:root:[   14] Training loss: 0.67511583, Validation loss: 0.67333929, Gradient norm: 0.13746175
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3864.0MB
INFO:root:[   15] Training loss: 0.67005957, Validation loss: 0.66793187, Gradient norm: 0.09943638
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3902.453125MB
INFO:root:[   16] Training loss: 0.66589997, Validation loss: 0.66522438, Gradient norm: 0.08709631
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3940.26953125MB
INFO:root:[   17] Training loss: 0.66257191, Validation loss: 0.66214218, Gradient norm: 0.08218147
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3978.9296875MB
INFO:root:[   18] Training loss: 0.65985307, Validation loss: 0.65954560, Gradient norm: 0.08813826
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4017.125MB
INFO:root:[   19] Training loss: 0.65749341, Validation loss: 0.65812610, Gradient norm: 0.08587556
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4055.2265625MB
INFO:root:[   20] Training loss: 0.65547668, Validation loss: 0.65638601, Gradient norm: 0.07348737
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4093.61328125MB
INFO:root:[   21] Training loss: 0.65362247, Validation loss: 0.65431094, Gradient norm: 0.08175713
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4131.546875MB
INFO:root:[   22] Training loss: 0.65190967, Validation loss: 0.65396630, Gradient norm: 0.08792776
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4170.02734375MB
INFO:root:[   23] Training loss: 0.65040106, Validation loss: 0.65150465, Gradient norm: 0.09313262
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4208.00390625MB
INFO:root:[   24] Training loss: 0.64884012, Validation loss: 0.65088790, Gradient norm: 0.07006307
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4246.1640625MB
INFO:root:[   25] Training loss: 0.64775090, Validation loss: 0.64955191, Gradient norm: 0.07823388
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4284.4921875MB
INFO:root:[   26] Training loss: 0.64657596, Validation loss: 0.64841378, Gradient norm: 0.06719764
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4322.6640625MB
INFO:root:[   27] Training loss: 0.64528110, Validation loss: 0.64709252, Gradient norm: 0.06526272
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4361.2265625MB
INFO:root:[   28] Training loss: 0.64410681, Validation loss: 0.64588678, Gradient norm: 0.06743645
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4399.28125MB
INFO:root:[   29] Training loss: 0.64312519, Validation loss: 0.64543938, Gradient norm: 0.06828997
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4437.1953125MB
INFO:root:[   30] Training loss: 0.64213285, Validation loss: 0.64382508, Gradient norm: 0.07029238
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4475.99609375MB
INFO:root:[   31] Training loss: 0.64111654, Validation loss: 0.64398255, Gradient norm: 0.06766864
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4514.328125MB
INFO:root:[   32] Training loss: 0.64022029, Validation loss: 0.64254362, Gradient norm: 0.06474622
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4552.78125MB
INFO:root:[   33] Training loss: 0.63929407, Validation loss: 0.64231090, Gradient norm: 0.07248838
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4591.1796875MB
INFO:root:[   34] Training loss: 0.63835721, Validation loss: 0.64114321, Gradient norm: 0.07368900
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4629.3125MB
INFO:root:[   35] Training loss: 0.63738532, Validation loss: 0.64098643, Gradient norm: 0.07141309
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4667.6640625MB
INFO:root:[   36] Training loss: 0.63671527, Validation loss: 0.64036425, Gradient norm: 0.07006857
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4705.8515625MB
INFO:root:[   37] Training loss: 0.63579529, Validation loss: 0.63946251, Gradient norm: 0.07437154
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4743.75MB
INFO:root:[   38] Training loss: 0.63468481, Validation loss: 0.63870682, Gradient norm: 0.07401843
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4782.12890625MB
INFO:root:[   39] Training loss: 0.63410017, Validation loss: 0.63783822, Gradient norm: 0.06749207
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4820.01953125MB
INFO:root:[   40] Training loss: 0.63317297, Validation loss: 0.63724660, Gradient norm: 0.06663148
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4858.15234375MB
INFO:root:[   41] Training loss: 0.63252370, Validation loss: 0.63652452, Gradient norm: 0.07455545
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4896.28515625MB
INFO:root:[   42] Training loss: 0.63171903, Validation loss: 0.63678685, Gradient norm: 0.06843056
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4934.18359375MB
INFO:root:[   43] Training loss: 0.63104155, Validation loss: 0.63532921, Gradient norm: 0.07392563
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4972.59375MB
INFO:root:[   44] Training loss: 0.63022357, Validation loss: 0.63509271, Gradient norm: 0.06999278
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5010.73828125MB
INFO:root:[   45] Training loss: 0.62956155, Validation loss: 0.63424387, Gradient norm: 0.07299977
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5049.12890625MB
INFO:root:[   46] Training loss: 0.62929093, Validation loss: 0.63482609, Gradient norm: 0.07014462
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5087.20703125MB
INFO:root:[   47] Training loss: 0.62840463, Validation loss: 0.63396829, Gradient norm: 0.07205690
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5125.1328125MB
INFO:root:[   48] Training loss: 0.62769888, Validation loss: 0.63265873, Gradient norm: 0.06470576
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5163.55078125MB
INFO:root:[   49] Training loss: 0.62693163, Validation loss: 0.63328809, Gradient norm: 0.08064071
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5201.6015625MB
INFO:root:[   50] Training loss: 0.62649538, Validation loss: 0.63173253, Gradient norm: 0.07070849
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5239.74609375MB
INFO:root:[   51] Training loss: 0.62562049, Validation loss: 0.63185219, Gradient norm: 0.06697738
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5278.08984375MB
INFO:root:[   52] Training loss: 0.62529050, Validation loss: 0.63137372, Gradient norm: 0.07278011
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5316.24609375MB
INFO:root:[   53] Training loss: 0.62455126, Validation loss: 0.63063846, Gradient norm: 0.06991579
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5354.171875MB
INFO:root:[   54] Training loss: 0.62408621, Validation loss: 0.63021433, Gradient norm: 0.06849573
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5392.5625MB
INFO:root:[   55] Training loss: 0.62344309, Validation loss: 0.62939740, Gradient norm: 0.07347293
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5430.69921875MB
INFO:root:[   56] Training loss: 0.62285053, Validation loss: 0.63004407, Gradient norm: 0.07116799
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5468.8828125MB
INFO:root:[   57] Training loss: 0.62230945, Validation loss: 0.62837166, Gradient norm: 0.07631449
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5507.48046875MB
INFO:root:[   58] Training loss: 0.62191093, Validation loss: 0.62846271, Gradient norm: 0.06594623
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5545.609375MB
INFO:root:[   59] Training loss: 0.62125431, Validation loss: 0.62808983, Gradient norm: 0.07625460
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5583.7734375MB
INFO:root:[   60] Training loss: 0.62066259, Validation loss: 0.62738514, Gradient norm: 0.06883433
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5621.9296875MB
