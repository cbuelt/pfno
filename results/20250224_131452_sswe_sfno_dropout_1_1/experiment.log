INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=581.27734375MB; mem (CPU total)=13951.40625MB
INFO:root:############### Starting experiment with config file sswe/sfno_dropout_1_1.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=592.46875MB; mem (CPU total)=13956.44921875MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=593.75390625MB; mem (CPU total)=13955.9765625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2273.66796875MB; mem (CPU total)=15369.1171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2283.19140625MB; mem (CPU total)=15377.36328125MB
INFO:root:[    1] Training loss: 0.83808260, Validation loss: 0.74359441, Gradient norm: 0.47009988
INFO:root:At the start of the epoch: mem (CPU python)=4442.31640625MB; mem (CPU total)=17100.19140625MB
INFO:root:[    2] Training loss: 0.74054285, Validation loss: 0.73566619, Gradient norm: 0.31325288
INFO:root:At the start of the epoch: mem (CPU python)=4464.6015625MB; mem (CPU total)=17126.0859375MB
INFO:root:[    3] Training loss: 0.72478950, Validation loss: 0.71516372, Gradient norm: 0.27101548
INFO:root:At the start of the epoch: mem (CPU python)=4484.56640625MB; mem (CPU total)=17148.44921875MB
INFO:root:[    4] Training loss: 0.70609154, Validation loss: 0.68652052, Gradient norm: 0.38207889
INFO:root:At the start of the epoch: mem (CPU python)=4506.62890625MB; mem (CPU total)=17173.796875MB
INFO:root:[    5] Training loss: 0.65917501, Validation loss: 0.62309711, Gradient norm: 0.50712923
INFO:root:At the start of the epoch: mem (CPU python)=4527.0625MB; mem (CPU total)=17199.69921875MB
INFO:root:[    6] Training loss: 0.59841538, Validation loss: 0.58211272, Gradient norm: 0.69477243
INFO:root:At the start of the epoch: mem (CPU python)=4548.5MB; mem (CPU total)=17226.27734375MB
INFO:root:[    7] Training loss: 0.57526744, Validation loss: 0.56294851, Gradient norm: 0.82148435
INFO:root:At the start of the epoch: mem (CPU python)=4569.15625MB; mem (CPU total)=17251.3671875MB
INFO:root:[    8] Training loss: 0.56180592, Validation loss: 0.55217313, Gradient norm: 0.99865651
INFO:root:At the start of the epoch: mem (CPU python)=4590.52734375MB; mem (CPU total)=17276.71484375MB
INFO:root:[    9] Training loss: 0.55662758, Validation loss: 0.55728687, Gradient norm: 1.35983604
INFO:root:At the start of the epoch: mem (CPU python)=4612.88671875MB; mem (CPU total)=17302.5625MB
INFO:root:[   10] Training loss: 0.54188911, Validation loss: 0.53950595, Gradient norm: 1.38925400
INFO:root:At the start of the epoch: mem (CPU python)=4634.36328125MB; mem (CPU total)=17327.64453125MB
INFO:root:[   11] Training loss: 0.52343274, Validation loss: 0.51285687, Gradient norm: 1.37882107
INFO:root:At the start of the epoch: mem (CPU python)=4655.53125MB; mem (CPU total)=17354.40625MB
INFO:root:[   12] Training loss: 0.52272602, Validation loss: 0.52492691, Gradient norm: 1.81968590
INFO:root:At the start of the epoch: mem (CPU python)=4676.6953125MB; mem (CPU total)=17378.22265625MB
INFO:root:[   13] Training loss: 0.51322910, Validation loss: 0.50397828, Gradient norm: 1.81993283
INFO:root:At the start of the epoch: mem (CPU python)=4697.859375MB; mem (CPU total)=17402.33203125MB
INFO:root:[   14] Training loss: 0.50294108, Validation loss: 0.50049456, Gradient norm: 1.71339009
INFO:root:At the start of the epoch: mem (CPU python)=4719.0234375MB; mem (CPU total)=17427.91015625MB
INFO:root:[   15] Training loss: 0.49803787, Validation loss: 0.50703272, Gradient norm: 1.95995513
INFO:root:At the start of the epoch: mem (CPU python)=4740.19140625MB; mem (CPU total)=15200.42578125MB
INFO:root:[   16] Training loss: 0.50063809, Validation loss: 0.49397220, Gradient norm: 1.96663771
INFO:root:At the start of the epoch: mem (CPU python)=4762.0703125MB; mem (CPU total)=15229.45703125MB
INFO:root:[   17] Training loss: 0.49360384, Validation loss: 0.48780164, Gradient norm: 2.06853196
INFO:root:At the start of the epoch: mem (CPU python)=4783.65625MB; mem (CPU total)=17481.71484375MB
INFO:root:[   18] Training loss: 0.49212142, Validation loss: 0.49095614, Gradient norm: 2.37207092
INFO:root:At the start of the epoch: mem (CPU python)=4804.8203125MB; mem (CPU total)=17506.5390625MB
INFO:root:[   19] Training loss: 0.49256349, Validation loss: 0.50106706, Gradient norm: 2.15249955
INFO:root:At the start of the epoch: mem (CPU python)=4825.984375MB; mem (CPU total)=17531.50390625MB
INFO:root:[   20] Training loss: 0.48741704, Validation loss: 0.48759853, Gradient norm: 2.43722840
INFO:root:At the start of the epoch: mem (CPU python)=4847.1484375MB; mem (CPU total)=17566.26171875MB
INFO:root:[   21] Training loss: 0.48737412, Validation loss: 0.48477112, Gradient norm: 2.34360857
INFO:root:At the start of the epoch: mem (CPU python)=4868.30859375MB; mem (CPU total)=17595.0546875MB
INFO:root:[   22] Training loss: 0.48410428, Validation loss: 0.48151350, Gradient norm: 2.31855345
INFO:root:At the start of the epoch: mem (CPU python)=4889.47265625MB; mem (CPU total)=17618.93359375MB
INFO:root:[   23] Training loss: 0.48187698, Validation loss: 0.47867870, Gradient norm: 2.67528387
INFO:root:At the start of the epoch: mem (CPU python)=4910.63671875MB; mem (CPU total)=17643.69921875MB
INFO:root:[   24] Training loss: 0.48079106, Validation loss: 0.47540626, Gradient norm: 2.34389613
INFO:root:At the start of the epoch: mem (CPU python)=4931.8125MB; mem (CPU total)=17667.8828125MB
INFO:root:[   25] Training loss: 0.48000112, Validation loss: 0.48730758, Gradient norm: 2.76476388
INFO:root:At the start of the epoch: mem (CPU python)=4952.98046875MB; mem (CPU total)=17693.23828125MB
INFO:root:[   26] Training loss: 0.48535490, Validation loss: 0.49481538, Gradient norm: 2.83396081
INFO:root:At the start of the epoch: mem (CPU python)=4974.1484375MB; mem (CPU total)=17719.43359375MB
INFO:root:[   27] Training loss: 0.47845776, Validation loss: 0.48104812, Gradient norm: 2.95618669
INFO:root:At the start of the epoch: mem (CPU python)=4995.3125MB; mem (CPU total)=17744.78125MB
INFO:root:[   28] Training loss: 0.47755102, Validation loss: 0.47000525, Gradient norm: 2.85301350
INFO:root:At the start of the epoch: mem (CPU python)=5016.640625MB; mem (CPU total)=17775.28515625MB
INFO:root:[   29] Training loss: 0.47491007, Validation loss: 0.47402977, Gradient norm: 2.89035997
INFO:root:At the start of the epoch: mem (CPU python)=5038.015625MB; mem (CPU total)=17800.640625MB
INFO:root:[   30] Training loss: 0.47606303, Validation loss: 0.47429569, Gradient norm: 2.97662697
INFO:root:At the start of the epoch: mem (CPU python)=5059.18359375MB; mem (CPU total)=17824.94140625MB
INFO:root:[   31] Training loss: 0.47813659, Validation loss: 0.47815197, Gradient norm: 3.37759064
INFO:root:At the start of the epoch: mem (CPU python)=5081.33203125MB; mem (CPU total)=17851.87890625MB
INFO:root:[   32] Training loss: 0.47542422, Validation loss: 0.47510591, Gradient norm: 3.12626283
INFO:root:At the start of the epoch: mem (CPU python)=5102.640625MB; mem (CPU total)=17877.96484375MB
INFO:root:[   33] Training loss: 0.47193268, Validation loss: 0.45865569, Gradient norm: 3.49482697
INFO:root:At the start of the epoch: mem (CPU python)=5123.81640625MB; mem (CPU total)=17903.05859375MB
INFO:root:[   34] Training loss: 0.46951525, Validation loss: 0.46386156, Gradient norm: 3.08610791
INFO:root:At the start of the epoch: mem (CPU python)=5144.9765625MB; mem (CPU total)=17929.14453125MB
INFO:root:[   35] Training loss: 0.46233891, Validation loss: 0.46029812, Gradient norm: 2.90577398
INFO:root:At the start of the epoch: mem (CPU python)=5166.140625MB; mem (CPU total)=17954.24609375MB
INFO:root:[   36] Training loss: 0.46470905, Validation loss: 0.45880685, Gradient norm: 3.81081421
INFO:root:At the start of the epoch: mem (CPU python)=5187.3046875MB; mem (CPU total)=17980.33203125MB
INFO:root:[   37] Training loss: 0.46764626, Validation loss: 0.45918673, Gradient norm: 3.49113638
INFO:root:At the start of the epoch: mem (CPU python)=5208.85546875MB; mem (CPU total)=18007.61328125MB
INFO:root:[   38] Training loss: 0.46514230, Validation loss: 0.47700249, Gradient norm: 4.09503864
INFO:root:At the start of the epoch: mem (CPU python)=5230.02734375MB; mem (CPU total)=18032.28515625MB
INFO:root:[   39] Training loss: 0.46572242, Validation loss: 0.44747074, Gradient norm: 3.66536085
INFO:root:At the start of the epoch: mem (CPU python)=5251.19140625MB; mem (CPU total)=18058.6796875MB
INFO:root:[   40] Training loss: 0.47017705, Validation loss: 0.45742988, Gradient norm: 4.25828255
INFO:root:At the start of the epoch: mem (CPU python)=5272.35546875MB; mem (CPU total)=18083.2265625MB
INFO:root:[   41] Training loss: 0.46305952, Validation loss: 0.46531827, Gradient norm: 3.96018309
INFO:root:At the start of the epoch: mem (CPU python)=5293.51953125MB; mem (CPU total)=18109.06640625MB
INFO:root:[   42] Training loss: 0.46844676, Validation loss: 0.48364807, Gradient norm: 4.01063001
INFO:root:At the start of the epoch: mem (CPU python)=5314.68359375MB; mem (CPU total)=18135.84765625MB
INFO:root:[   43] Training loss: 0.46647843, Validation loss: 0.45179866, Gradient norm: 4.21065141
INFO:root:At the start of the epoch: mem (CPU python)=5335.8515625MB; mem (CPU total)=18162.03125MB
INFO:root:[   44] Training loss: 0.46167049, Validation loss: 0.46621470, Gradient norm: 4.09250740
INFO:root:At the start of the epoch: mem (CPU python)=5357.015625MB; mem (CPU total)=18187.8671875MB
INFO:root:[   45] Training loss: 0.46515129, Validation loss: 0.46069379, Gradient norm: 4.35042287
INFO:root:At the start of the epoch: mem (CPU python)=5378.55859375MB; mem (CPU total)=18213.22265625MB
INFO:root:[   46] Training loss: 0.46289138, Validation loss: 0.46955149, Gradient norm: 4.42544552
INFO:root:At the start of the epoch: mem (CPU python)=5399.72265625MB; mem (CPU total)=18239.80859375MB
INFO:root:[   47] Training loss: 0.46330500, Validation loss: 0.45802120, Gradient norm: 4.03989079
INFO:root:At the start of the epoch: mem (CPU python)=5422.5MB; mem (CPU total)=16013.734375MB
INFO:root:[   48] Training loss: 0.46005169, Validation loss: 0.44776269, Gradient norm: 4.36157338
INFO:root:At the start of the epoch: mem (CPU python)=5443.9296875MB; mem (CPU total)=16039.0859375MB
INFO:root:[   49] Training loss: 0.46199832, Validation loss: 0.45147981, Gradient norm: 4.71159491
INFO:root:At the start of the epoch: mem (CPU python)=5465.09375MB; mem (CPU total)=16063.45703125MB
INFO:root:[   50] Training loss: 0.45810942, Validation loss: 0.44728567, Gradient norm: 4.53759389
INFO:root:At the start of the epoch: mem (CPU python)=5486.2578125MB; mem (CPU total)=16088.84375MB
INFO:root:[   51] Training loss: 0.46206105, Validation loss: 0.46065711, Gradient norm: 4.79911688
INFO:root:At the start of the epoch: mem (CPU python)=5507.421875MB; mem (CPU total)=16114.3515625MB
INFO:root:[   52] Training loss: 0.45792431, Validation loss: 0.48167265, Gradient norm: 4.53022903
INFO:root:At the start of the epoch: mem (CPU python)=5528.58984375MB; mem (CPU total)=16140.44140625MB
INFO:root:[   53] Training loss: 0.45968081, Validation loss: 0.44772713, Gradient norm: 4.85841573
INFO:root:At the start of the epoch: mem (CPU python)=5551.1875MB; mem (CPU total)=16166.96484375MB
INFO:root:[   54] Training loss: 0.45802914, Validation loss: 0.48278533, Gradient norm: 4.90820266
INFO:root:At the start of the epoch: mem (CPU python)=5572.43359375MB; mem (CPU total)=16192.31640625MB
INFO:root:[   55] Training loss: 0.45991095, Validation loss: 0.46315745, Gradient norm: 4.89692808
INFO:root:At the start of the epoch: mem (CPU python)=5593.59765625MB; mem (CPU total)=16217.42578125MB
INFO:root:[   56] Training loss: 0.45845994, Validation loss: 0.47169815, Gradient norm: 5.26595432
INFO:root:At the start of the epoch: mem (CPU python)=5614.76171875MB; mem (CPU total)=16243.109375MB
INFO:root:[   57] Training loss: 0.45875691, Validation loss: 0.46181137, Gradient norm: 5.08637325
INFO:root:At the start of the epoch: mem (CPU python)=5635.921875MB; mem (CPU total)=16268.87890625MB
INFO:root:[   58] Training loss: 0.45578545, Validation loss: 0.45079766, Gradient norm: 4.72537753
INFO:root:At the start of the epoch: mem (CPU python)=5657.54296875MB; mem (CPU total)=16294.97265625MB
INFO:root:[   59] Training loss: 0.45275940, Validation loss: 0.43643062, Gradient norm: 5.23416306
INFO:root:At the start of the epoch: mem (CPU python)=5679.0078125MB; mem (CPU total)=16319.58984375MB
INFO:root:[   60] Training loss: 0.45063210, Validation loss: 0.44252223, Gradient norm: 5.10206328
INFO:root:At the start of the epoch: mem (CPU python)=5700.16796875MB; mem (CPU total)=16344.99609375MB
INFO:root:[   61] Training loss: 0.45366244, Validation loss: 0.45874899, Gradient norm: 5.24706166
INFO:root:At the start of the epoch: mem (CPU python)=5721.3359375MB; mem (CPU total)=16370.765625MB
INFO:root:[   62] Training loss: 0.46199317, Validation loss: 0.46766295, Gradient norm: 5.44512851
INFO:root:At the start of the epoch: mem (CPU python)=5742.5MB; mem (CPU total)=16396.609375MB
INFO:root:[   63] Training loss: 0.45359764, Validation loss: 0.48801291, Gradient norm: 5.22687663
INFO:root:At the start of the epoch: mem (CPU python)=5763.6640625MB; mem (CPU total)=17250.51171875MB
INFO:root:[   64] Training loss: 0.45885849, Validation loss: 0.44315491, Gradient norm: 5.99200988
INFO:root:At the start of the epoch: mem (CPU python)=5785.20703125MB; mem (CPU total)=18759.45703125MB
INFO:root:[   65] Training loss: 0.45053834, Validation loss: 0.45585621, Gradient norm: 5.21910960
INFO:root:At the start of the epoch: mem (CPU python)=5806.375MB; mem (CPU total)=18815.03125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   66] Training loss: 0.45341665, Validation loss: 0.45312902, Gradient norm: 5.78073821
INFO:root:At the start of the epoch: mem (CPU python)=5828.01953125MB; mem (CPU total)=18818.53125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   67] Training loss: 0.42448987, Validation loss: 0.42507045, Gradient norm: 4.60433417
INFO:root:At the start of the epoch: mem (CPU python)=5849.796875MB; mem (CPU total)=18844.890625MB
INFO:root:[   68] Training loss: 0.41362228, Validation loss: 0.41811067, Gradient norm: 3.37727653
INFO:root:At the start of the epoch: mem (CPU python)=5871.11328125MB; mem (CPU total)=18870.73046875MB
INFO:root:[   69] Training loss: 0.41236898, Validation loss: 0.42345084, Gradient norm: 4.26579572
INFO:root:At the start of the epoch: mem (CPU python)=5892.26953125MB; mem (CPU total)=18936.05859375MB
INFO:root:[   70] Training loss: 0.41295557, Validation loss: 0.41653987, Gradient norm: 4.63151348
INFO:root:At the start of the epoch: mem (CPU python)=5913.453125MB; mem (CPU total)=18920.1953125MB
INFO:root:[   71] Training loss: 0.41285601, Validation loss: 0.41569597, Gradient norm: 5.24784346
INFO:root:At the start of the epoch: mem (CPU python)=5934.62109375MB; mem (CPU total)=18951.24609375MB
INFO:root:[   72] Training loss: 0.41112616, Validation loss: 0.41826630, Gradient norm: 5.87497920
INFO:root:At the start of the epoch: mem (CPU python)=5951.86328125MB; mem (CPU total)=18862.30078125MB
INFO:root:[   73] Training loss: 0.41549715, Validation loss: 0.41732435, Gradient norm: 6.55708863
INFO:root:At the start of the epoch: mem (CPU python)=5967.3203125MB; mem (CPU total)=18893.58984375MB
INFO:root:[   74] Training loss: 0.41418296, Validation loss: 0.42287534, Gradient norm: 6.73889260
INFO:root:At the start of the epoch: mem (CPU python)=5988.484375MB; mem (CPU total)=18920.671875MB
INFO:root:[   75] Training loss: 0.41320721, Validation loss: 0.41437700, Gradient norm: 7.43407399
INFO:root:At the start of the epoch: mem (CPU python)=6009.65234375MB; mem (CPU total)=17440.0703125MB
INFO:root:[   76] Training loss: 0.41288967, Validation loss: 0.41791583, Gradient norm: 7.36295364
INFO:root:At the start of the epoch: mem (CPU python)=6030.8046875MB; mem (CPU total)=19026.86328125MB
INFO:root:[   77] Training loss: 0.41395084, Validation loss: 0.41246557, Gradient norm: 7.57198215
INFO:root:At the start of the epoch: mem (CPU python)=6051.9765625MB; mem (CPU total)=19024.4921875MB
INFO:root:[   78] Training loss: 0.41678833, Validation loss: 0.42096998, Gradient norm: 8.54640849
INFO:root:At the start of the epoch: mem (CPU python)=6073.13671875MB; mem (CPU total)=19050.515625MB
INFO:root:[   79] Training loss: 0.41598948, Validation loss: 0.41987080, Gradient norm: 8.57101745
INFO:root:At the start of the epoch: mem (CPU python)=6094.3046875MB; mem (CPU total)=19076.30078125MB
INFO:root:[   80] Training loss: 0.41599986, Validation loss: 0.43259224, Gradient norm: 9.00444938
INFO:root:At the start of the epoch: mem (CPU python)=6115.46875MB; mem (CPU total)=18124.44140625MB
INFO:root:[   81] Training loss: 0.41594606, Validation loss: 0.44104416, Gradient norm: 9.35860083
INFO:root:At the start of the epoch: mem (CPU python)=6136.6328125MB; mem (CPU total)=16870.16015625MB
INFO:root:[   82] Training loss: 0.42032426, Validation loss: 0.42199061, Gradient norm: 10.21409718
INFO:root:At the start of the epoch: mem (CPU python)=6157.80078125MB; mem (CPU total)=16894.21875MB
INFO:root:[   83] Training loss: 0.41702783, Validation loss: 0.41900239, Gradient norm: 10.37799341
INFO:root:At the start of the epoch: mem (CPU python)=6178.96484375MB; mem (CPU total)=17114.44140625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   84] Training loss: 0.41841072, Validation loss: 0.42806137, Gradient norm: 10.19938120
INFO:root:At the start of the epoch: mem (CPU python)=6200.125MB; mem (CPU total)=19184.00390625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   85] Training loss: 0.41015218, Validation loss: 0.41451830, Gradient norm: 7.57058144
INFO:root:At the start of the epoch: mem (CPU python)=6221.5390625MB; mem (CPU total)=19224.94921875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   86] Training loss: 0.40562667, Validation loss: 0.41208536, Gradient norm: 6.59546149
INFO:root:At the start of the epoch: mem (CPU python)=6242.83203125MB; mem (CPU total)=16997.61328125MB
INFO:root:[   87] Training loss: 0.40256361, Validation loss: 0.40824381, Gradient norm: 3.84090751
INFO:root:At the start of the epoch: mem (CPU python)=6263.99609375MB; mem (CPU total)=17022.53125MB
INFO:root:[   88] Training loss: 0.40270192, Validation loss: 0.40856192, Gradient norm: 4.04838671
INFO:root:At the start of the epoch: mem (CPU python)=6285.16015625MB; mem (CPU total)=17243.95703125MB
INFO:root:[   89] Training loss: 0.40209137, Validation loss: 0.40793707, Gradient norm: 4.16102234
INFO:root:At the start of the epoch: mem (CPU python)=6306.32421875MB; mem (CPU total)=19329.19921875MB
INFO:root:[   90] Training loss: 0.40296484, Validation loss: 0.40734389, Gradient norm: 4.12859961
INFO:root:At the start of the epoch: mem (CPU python)=6327.48828125MB; mem (CPU total)=17099.3203125MB
INFO:root:[   91] Training loss: 0.40164759, Validation loss: 0.40804763, Gradient norm: 4.48527866
INFO:root:At the start of the epoch: mem (CPU python)=6348.65234375MB; mem (CPU total)=19357.85546875MB
INFO:root:[   92] Training loss: 0.40349410, Validation loss: 0.40721996, Gradient norm: 5.68860363
INFO:root:At the start of the epoch: mem (CPU python)=6369.8203125MB; mem (CPU total)=19387.8203125MB
INFO:root:[   93] Training loss: 0.40213105, Validation loss: 0.40829272, Gradient norm: 5.74415675
INFO:root:At the start of the epoch: mem (CPU python)=6390.984375MB; mem (CPU total)=19410.6484375MB
INFO:root:[   94] Training loss: 0.40254870, Validation loss: 0.40769094, Gradient norm: 5.68029042
INFO:root:At the start of the epoch: mem (CPU python)=6412.1484375MB; mem (CPU total)=19424.5MB
INFO:root:[   95] Training loss: 0.40298013, Validation loss: 0.40668233, Gradient norm: 6.29090559
INFO:root:At the start of the epoch: mem (CPU python)=6434.0859375MB; mem (CPU total)=17213.42578125MB
INFO:root:[   96] Training loss: 0.40289492, Validation loss: 0.40807878, Gradient norm: 5.42932801
INFO:root:At the start of the epoch: mem (CPU python)=6456.12109375MB; mem (CPU total)=8543.2890625MB
INFO:root:[   97] Training loss: 0.40232936, Validation loss: 0.40882002, Gradient norm: 6.18578996
INFO:root:At the start of the epoch: mem (CPU python)=6477.51171875MB; mem (CPU total)=8973.94140625MB
INFO:root:[   98] Training loss: 0.40155143, Validation loss: 0.40875436, Gradient norm: 6.93300233
INFO:root:At the start of the epoch: mem (CPU python)=6499.30859375MB; mem (CPU total)=12102.0625MB
INFO:root:[   99] Training loss: 0.40232794, Validation loss: 0.40877290, Gradient norm: 6.74778378
INFO:root:At the start of the epoch: mem (CPU python)=6520.4765625MB; mem (CPU total)=12117.1015625MB
INFO:root:[  100] Training loss: 0.40289052, Validation loss: 0.40830109, Gradient norm: 8.25162355
INFO:root:At the start of the epoch: mem (CPU python)=6541.64453125MB; mem (CPU total)=12154.92578125MB
INFO:root:[  101] Training loss: 0.40209693, Validation loss: 0.40664609, Gradient norm: 7.20354870
INFO:root:At the start of the epoch: mem (CPU python)=6562.8125MB; mem (CPU total)=9938.19140625MB
INFO:root:[  102] Training loss: 0.40241622, Validation loss: 0.40991118, Gradient norm: 7.86178067
INFO:root:At the start of the epoch: mem (CPU python)=6583.97265625MB; mem (CPU total)=10003.28125MB
INFO:root:[  103] Training loss: 0.40245476, Validation loss: 0.40764324, Gradient norm: 7.99164173
INFO:root:At the start of the epoch: mem (CPU python)=6605.13671875MB; mem (CPU total)=10047.43359375MB
INFO:root:[  104] Training loss: 0.40292838, Validation loss: 0.40747286, Gradient norm: 8.25344533
INFO:root:At the start of the epoch: mem (CPU python)=6626.3125MB; mem (CPU total)=10074.69921875MB
INFO:root:[  105] Training loss: 0.40275952, Validation loss: 0.40759998, Gradient norm: 8.52608758
INFO:root:At the start of the epoch: mem (CPU python)=6647.48828125MB; mem (CPU total)=10483.6875MB
INFO:root:[  106] Training loss: 0.40290192, Validation loss: 0.40813868, Gradient norm: 8.97500152
INFO:root:At the start of the epoch: mem (CPU python)=6668.6640625MB; mem (CPU total)=12344.74609375MB
INFO:root:[  107] Training loss: 0.40305465, Validation loss: 0.40858763, Gradient norm: 9.43743086
INFO:root:At the start of the epoch: mem (CPU python)=6689.828125MB; mem (CPU total)=12360.02734375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  108] Training loss: 0.40365381, Validation loss: 0.41001509, Gradient norm: 12.45387198
INFO:root:At the start of the epoch: mem (CPU python)=6711.00390625MB; mem (CPU total)=12403.50390625MB
INFO:root:[  109] Training loss: 0.40204701, Validation loss: 0.40624521, Gradient norm: 8.75219688
INFO:root:At the start of the epoch: mem (CPU python)=6732.16796875MB; mem (CPU total)=12446.73046875MB
INFO:root:[  110] Training loss: 0.40234579, Validation loss: 0.40615694, Gradient norm: 8.43557324
INFO:root:At the start of the epoch: mem (CPU python)=6753.328125MB; mem (CPU total)=12467.43359375MB
INFO:root:[  111] Training loss: 0.40218332, Validation loss: 0.40674757, Gradient norm: 6.85318047
INFO:root:At the start of the epoch: mem (CPU python)=6774.49609375MB; mem (CPU total)=12480.7109375MB
INFO:root:[  112] Training loss: 0.40192096, Validation loss: 0.40701902, Gradient norm: 8.09880955
INFO:root:At the start of the epoch: mem (CPU python)=6795.66015625MB; mem (CPU total)=12495.10546875MB
INFO:root:[  113] Training loss: 0.40199829, Validation loss: 0.40865462, Gradient norm: 9.03456820
INFO:root:At the start of the epoch: mem (CPU python)=6816.828125MB; mem (CPU total)=12527.77734375MB
INFO:root:[  114] Training loss: 0.40181221, Validation loss: 0.40704991, Gradient norm: 9.20364844
INFO:root:At the start of the epoch: mem (CPU python)=6837.99609375MB; mem (CPU total)=12565.63671875MB
INFO:root:[  115] Training loss: 0.40209447, Validation loss: 0.40908879, Gradient norm: 7.98804406
INFO:root:At the start of the epoch: mem (CPU python)=6859.16015625MB; mem (CPU total)=12613.89453125MB
INFO:root:[  116] Training loss: 0.40233832, Validation loss: 0.40797653, Gradient norm: 8.40952584
INFO:root:At the start of the epoch: mem (CPU python)=6880.32421875MB; mem (CPU total)=12618.55859375MB
INFO:root:[  117] Training loss: 0.40233605, Validation loss: 0.40713558, Gradient norm: 8.74870505
INFO:root:At the start of the epoch: mem (CPU python)=6901.48828125MB; mem (CPU total)=12655.8046875MB
INFO:root:[  118] Training loss: 0.40239811, Validation loss: 0.40728746, Gradient norm: 9.19251858
INFO:root:At the start of the epoch: mem (CPU python)=6922.66796875MB; mem (CPU total)=12693.55859375MB
INFO:root:[  119] Training loss: 0.40235883, Validation loss: 0.40596444, Gradient norm: 8.59913477
INFO:root:At the start of the epoch: mem (CPU python)=6943.83984375MB; mem (CPU total)=12723.65234375MB
INFO:root:[  120] Training loss: 0.40194144, Validation loss: 0.40968740, Gradient norm: 9.52063830
INFO:root:At the start of the epoch: mem (CPU python)=6964.99609375MB; mem (CPU total)=12752.1640625MB
INFO:root:[  121] Training loss: 0.40194482, Validation loss: 0.40779950, Gradient norm: 9.78994137
INFO:root:At the start of the epoch: mem (CPU python)=6986.1640625MB; mem (CPU total)=12767.51953125MB
INFO:root:[  122] Training loss: 0.40254273, Validation loss: 0.40793947, Gradient norm: 10.57968267
INFO:root:At the start of the epoch: mem (CPU python)=7007.33203125MB; mem (CPU total)=12787.578125MB
INFO:root:[  123] Training loss: 0.40212605, Validation loss: 0.40661911, Gradient norm: 11.28974569
INFO:root:At the start of the epoch: mem (CPU python)=7028.5078125MB; mem (CPU total)=12842.49609375MB
INFO:root:[  124] Training loss: 0.40154307, Validation loss: 0.40663810, Gradient norm: 10.06689229
INFO:root:At the start of the epoch: mem (CPU python)=7050.34765625MB; mem (CPU total)=12863.3515625MB
INFO:root:[  125] Training loss: 0.40190628, Validation loss: 0.40829636, Gradient norm: 9.93619258
INFO:root:At the start of the epoch: mem (CPU python)=7071.6171875MB; mem (CPU total)=12900.96484375MB
INFO:root:[  126] Training loss: 0.40213734, Validation loss: 0.40817926, Gradient norm: 10.86364344
INFO:root:At the start of the epoch: mem (CPU python)=7093.2265625MB; mem (CPU total)=12920.06640625MB
