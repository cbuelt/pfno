INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=580.3984375MB; mem (CPU total)=3236.3515625MB
INFO:root:############### Starting experiment with config file sswe/sfno_sr_dropout_2_2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=591.33203125MB; mem (CPU total)=3214.65625MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=592.77734375MB; mem (CPU total)=3223.1171875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2240.8046875MB; mem (CPU total)=4680.79296875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2250.43359375MB; mem (CPU total)=4632.04296875MB
INFO:root:[    1] Training loss: 1.76317458, Validation loss: 1.67338943, Gradient norm: 0.23153680
INFO:root:At the start of the epoch: mem (CPU python)=4414.24609375MB; mem (CPU total)=6366.2109375MB
INFO:root:[    2] Training loss: 1.72759661, Validation loss: 1.60014733, Gradient norm: 0.35848402
INFO:root:At the start of the epoch: mem (CPU python)=4435.54296875MB; mem (CPU total)=6406.7734375MB
INFO:root:[    3] Training loss: 1.68564935, Validation loss: 1.56529616, Gradient norm: 0.48015160
INFO:root:At the start of the epoch: mem (CPU python)=4457.40625MB; mem (CPU total)=6390.4765625MB
INFO:root:[    4] Training loss: 1.67046968, Validation loss: 1.55262368, Gradient norm: 0.63992465
INFO:root:At the start of the epoch: mem (CPU python)=4478.58984375MB; mem (CPU total)=6466.25390625MB
INFO:root:[    5] Training loss: 1.66368269, Validation loss: 1.54456493, Gradient norm: 0.73362596
INFO:root:At the start of the epoch: mem (CPU python)=4499.7734375MB; mem (CPU total)=6456.26171875MB
INFO:root:[    6] Training loss: 1.66022931, Validation loss: 1.55867742, Gradient norm: 0.78608031
INFO:root:At the start of the epoch: mem (CPU python)=4520.953125MB; mem (CPU total)=6448.90234375MB
INFO:root:[    7] Training loss: 1.65842624, Validation loss: 1.53687579, Gradient norm: 0.88415957
INFO:root:At the start of the epoch: mem (CPU python)=4542.140625MB; mem (CPU total)=6537.81640625MB
INFO:root:[    8] Training loss: 1.65612390, Validation loss: 1.53321751, Gradient norm: 0.95059121
INFO:root:At the start of the epoch: mem (CPU python)=4563.3125MB; mem (CPU total)=6457.78125MB
INFO:root:[    9] Training loss: 1.65653616, Validation loss: 1.52819086, Gradient norm: 1.01085595
INFO:root:At the start of the epoch: mem (CPU python)=4584.4765625MB; mem (CPU total)=6583.28125MB
INFO:root:[   10] Training loss: 1.65317075, Validation loss: 1.52809957, Gradient norm: 1.00913479
INFO:root:At the start of the epoch: mem (CPU python)=4605.64453125MB; mem (CPU total)=6510.69921875MB
INFO:root:[   11] Training loss: 1.65309457, Validation loss: 1.52794524, Gradient norm: 1.08222962
INFO:root:At the start of the epoch: mem (CPU python)=4626.80859375MB; mem (CPU total)=6568.51953125MB
INFO:root:[   12] Training loss: 1.65150205, Validation loss: 1.52618293, Gradient norm: 1.11237572
INFO:root:At the start of the epoch: mem (CPU python)=4647.9765625MB; mem (CPU total)=6632.39453125MB
INFO:root:[   13] Training loss: 1.65073023, Validation loss: 1.51895011, Gradient norm: 1.07446052
INFO:root:At the start of the epoch: mem (CPU python)=4669.140625MB; mem (CPU total)=6614.48828125MB
INFO:root:[   14] Training loss: 1.65076450, Validation loss: 1.52549374, Gradient norm: 1.13411231
INFO:root:At the start of the epoch: mem (CPU python)=4690.30078125MB; mem (CPU total)=6695.44140625MB
INFO:root:[   15] Training loss: 1.64914872, Validation loss: 1.52149008, Gradient norm: 1.10666257
INFO:root:At the start of the epoch: mem (CPU python)=4711.46484375MB; mem (CPU total)=6658.62890625MB
INFO:root:[   16] Training loss: 1.64897706, Validation loss: 1.51772440, Gradient norm: 1.11272661
INFO:root:At the start of the epoch: mem (CPU python)=4732.62890625MB; mem (CPU total)=6641.2109375MB
INFO:root:[   17] Training loss: 1.64835403, Validation loss: 1.51949283, Gradient norm: 1.14687773
INFO:root:At the start of the epoch: mem (CPU python)=4753.80078125MB; mem (CPU total)=6666.75390625MB
INFO:root:[   18] Training loss: 1.64809394, Validation loss: 1.51938732, Gradient norm: 1.16514887
INFO:root:At the start of the epoch: mem (CPU python)=4774.96484375MB; mem (CPU total)=6749.46875MB
INFO:root:[   19] Training loss: 1.64682781, Validation loss: 1.52319862, Gradient norm: 1.15404156
INFO:root:At the start of the epoch: mem (CPU python)=4796.12890625MB; mem (CPU total)=6776.3125MB
INFO:root:[   20] Training loss: 1.64638537, Validation loss: 1.52774485, Gradient norm: 1.13376298
INFO:root:At the start of the epoch: mem (CPU python)=4817.296875MB; mem (CPU total)=6807.35546875MB
INFO:root:[   21] Training loss: 1.64639588, Validation loss: 1.51190618, Gradient norm: 1.19886025
INFO:root:At the start of the epoch: mem (CPU python)=4838.4609375MB; mem (CPU total)=6751.51953125MB
INFO:root:[   22] Training loss: 1.64659388, Validation loss: 1.52463747, Gradient norm: 1.21111313
INFO:root:At the start of the epoch: mem (CPU python)=4859.625MB; mem (CPU total)=6870.73828125MB
INFO:root:[   23] Training loss: 1.64444443, Validation loss: 1.51706131, Gradient norm: 1.12804907
INFO:root:At the start of the epoch: mem (CPU python)=4880.7890625MB; mem (CPU total)=6846.32421875MB
INFO:root:[   24] Training loss: 1.64511088, Validation loss: 1.51266925, Gradient norm: 1.19576140
INFO:root:At the start of the epoch: mem (CPU python)=4901.94921875MB; mem (CPU total)=6892.7890625MB
INFO:root:[   25] Training loss: 1.64439507, Validation loss: 1.53166216, Gradient norm: 1.21481319
INFO:root:At the start of the epoch: mem (CPU python)=4923.11328125MB; mem (CPU total)=6905.38671875MB
INFO:root:[   26] Training loss: 1.64407620, Validation loss: 1.51008246, Gradient norm: 1.19794912
INFO:root:At the start of the epoch: mem (CPU python)=4944.27734375MB; mem (CPU total)=6877.984375MB
INFO:root:[   27] Training loss: 1.64367667, Validation loss: 1.52169953, Gradient norm: 1.24537462
INFO:root:At the start of the epoch: mem (CPU python)=4965.44140625MB; mem (CPU total)=6880.86328125MB
INFO:root:[   28] Training loss: 1.64361346, Validation loss: 1.51016027, Gradient norm: 1.22390897
INFO:root:At the start of the epoch: mem (CPU python)=4986.609375MB; mem (CPU total)=6936.66796875MB
INFO:root:[   29] Training loss: 1.64395704, Validation loss: 1.52335917, Gradient norm: 1.32853517
INFO:root:At the start of the epoch: mem (CPU python)=5007.7734375MB; mem (CPU total)=6952.96484375MB
INFO:root:[   30] Training loss: 1.64318192, Validation loss: 1.50998991, Gradient norm: 1.25783873
INFO:root:At the start of the epoch: mem (CPU python)=5028.9375MB; mem (CPU total)=6996.51171875MB
INFO:root:[   31] Training loss: 1.64339146, Validation loss: 1.51169182, Gradient norm: 1.26205691
INFO:root:At the start of the epoch: mem (CPU python)=5050.1015625MB; mem (CPU total)=6974.80078125MB
INFO:root:[   32] Training loss: 1.64298601, Validation loss: 1.52316831, Gradient norm: 1.32406991
INFO:root:At the start of the epoch: mem (CPU python)=5071.265625MB; mem (CPU total)=7053.30859375MB
INFO:root:[   33] Training loss: 1.64340714, Validation loss: 1.51984611, Gradient norm: 1.34163552
INFO:root:At the start of the epoch: mem (CPU python)=5092.4296875MB; mem (CPU total)=7053.53515625MB
INFO:root:[   34] Training loss: 1.64268059, Validation loss: 1.51750845, Gradient norm: 1.32176417
INFO:root:At the start of the epoch: mem (CPU python)=5113.59375MB; mem (CPU total)=7017.33203125MB
INFO:root:[   35] Training loss: 1.64273824, Validation loss: 1.51274099, Gradient norm: 1.35017894
INFO:root:At the start of the epoch: mem (CPU python)=5134.75390625MB; mem (CPU total)=7088.671875MB
INFO:root:[   36] Training loss: 1.64280580, Validation loss: 1.50932872, Gradient norm: 1.37352773
INFO:root:At the start of the epoch: mem (CPU python)=5155.91796875MB; mem (CPU total)=7090.609375MB
INFO:root:[   37] Training loss: 1.64227176, Validation loss: 1.51757054, Gradient norm: 1.35837459
INFO:root:At the start of the epoch: mem (CPU python)=5177.2109375MB; mem (CPU total)=7129.47265625MB
INFO:root:[   38] Training loss: 1.64270110, Validation loss: 1.50855687, Gradient norm: 1.42451547
INFO:root:At the start of the epoch: mem (CPU python)=5198.62109375MB; mem (CPU total)=7120.140625MB
INFO:root:[   39] Training loss: 1.64251132, Validation loss: 1.51266923, Gradient norm: 1.41106264
INFO:root:At the start of the epoch: mem (CPU python)=5219.78515625MB; mem (CPU total)=7142.6484375MB
INFO:root:[   40] Training loss: 1.65029467, Validation loss: 1.52335763, Gradient norm: 1.71171180
INFO:root:At the start of the epoch: mem (CPU python)=5240.953125MB; mem (CPU total)=7159.48046875MB
INFO:root:[   41] Training loss: 1.64409591, Validation loss: 1.50732417, Gradient norm: 1.50069322
INFO:root:At the start of the epoch: mem (CPU python)=5262.12109375MB; mem (CPU total)=7200.0546875MB
INFO:root:[   42] Training loss: 1.64149653, Validation loss: 1.51088528, Gradient norm: 1.33795600
INFO:root:At the start of the epoch: mem (CPU python)=5283.28125MB; mem (CPU total)=7228.20703125MB
INFO:root:[   43] Training loss: 1.64189957, Validation loss: 1.50675450, Gradient norm: 1.41763646
INFO:root:At the start of the epoch: mem (CPU python)=5304.4453125MB; mem (CPU total)=7222.82421875MB
INFO:root:[   44] Training loss: 1.64113224, Validation loss: 1.52027933, Gradient norm: 1.35861973
INFO:root:At the start of the epoch: mem (CPU python)=5325.609375MB; mem (CPU total)=7288.6484375MB
INFO:root:[   45] Training loss: 1.64115300, Validation loss: 1.51721448, Gradient norm: 1.45165037
INFO:root:At the start of the epoch: mem (CPU python)=5346.77734375MB; mem (CPU total)=7290.48828125MB
INFO:root:[   46] Training loss: 1.64064593, Validation loss: 1.51497367, Gradient norm: 1.36201796
INFO:root:At the start of the epoch: mem (CPU python)=5367.94140625MB; mem (CPU total)=7336.23046875MB
INFO:root:[   47] Training loss: 1.64086323, Validation loss: 1.52051213, Gradient norm: 1.50977508
INFO:root:At the start of the epoch: mem (CPU python)=5389.10546875MB; mem (CPU total)=7343.125MB
INFO:root:[   48] Training loss: 1.64123264, Validation loss: 1.52087236, Gradient norm: 1.50434521
INFO:root:At the start of the epoch: mem (CPU python)=5410.26953125MB; mem (CPU total)=7362.76953125MB
INFO:root:[   49] Training loss: 1.64605622, Validation loss: 1.53511220, Gradient norm: 1.62112675
INFO:root:At the start of the epoch: mem (CPU python)=5431.43359375MB; mem (CPU total)=7386.734375MB
INFO:root:[   50] Training loss: 1.66975470, Validation loss: 1.51418913, Gradient norm: 2.71964322
INFO:root:At the start of the epoch: mem (CPU python)=5452.6015625MB; mem (CPU total)=7412.49609375MB
INFO:root:[   51] Training loss: 1.64270088, Validation loss: 1.52514156, Gradient norm: 1.53466768
INFO:root:At the start of the epoch: mem (CPU python)=5473.765625MB; mem (CPU total)=7385.77734375MB
INFO:root:[   52] Training loss: 1.63995671, Validation loss: 1.50374302, Gradient norm: 1.42404048
INFO:root:At the start of the epoch: mem (CPU python)=5494.92578125MB; mem (CPU total)=7458.03515625MB
INFO:root:[   53] Training loss: 1.64587332, Validation loss: 1.52272092, Gradient norm: 1.61243608
INFO:root:At the start of the epoch: mem (CPU python)=5516.0859375MB; mem (CPU total)=7439.109375MB
INFO:root:[   54] Training loss: 1.64513797, Validation loss: 1.50700934, Gradient norm: 1.67956559
INFO:root:At the start of the epoch: mem (CPU python)=5537.25MB; mem (CPU total)=7495.234375MB
INFO:root:[   55] Training loss: 1.63993388, Validation loss: 1.51711550, Gradient norm: 1.42106479
INFO:root:At the start of the epoch: mem (CPU python)=5558.4140625MB; mem (CPU total)=7542.79296875MB
INFO:root:[   56] Training loss: 1.63943579, Validation loss: 1.51371909, Gradient norm: 1.48946441
INFO:root:At the start of the epoch: mem (CPU python)=5579.58203125MB; mem (CPU total)=7498.51171875MB
INFO:root:[   57] Training loss: 1.64020830, Validation loss: 1.51016538, Gradient norm: 1.51890644
INFO:root:At the start of the epoch: mem (CPU python)=5600.74609375MB; mem (CPU total)=7555.5859375MB
INFO:root:[   58] Training loss: 1.63971290, Validation loss: 1.50862310, Gradient norm: 1.46037602
INFO:root:At the start of the epoch: mem (CPU python)=5621.91015625MB; mem (CPU total)=7613.3359375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   59] Training loss: 1.63946775, Validation loss: 1.51557776, Gradient norm: 1.57338007
INFO:root:At the start of the epoch: mem (CPU python)=5643.07421875MB; mem (CPU total)=7584.6796875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   60] Training loss: 1.63273951, Validation loss: 1.50278980, Gradient norm: 1.28421685
INFO:root:At the start of the epoch: mem (CPU python)=5664.2421875MB; mem (CPU total)=7648.67578125MB
INFO:root:[   61] Training loss: 1.63079390, Validation loss: 1.50297689, Gradient norm: 1.24810766
INFO:root:At the start of the epoch: mem (CPU python)=5685.40234375MB; mem (CPU total)=7653.96484375MB
INFO:root:[   62] Training loss: 1.63029287, Validation loss: 1.50131737, Gradient norm: 1.69152404
INFO:root:At the start of the epoch: mem (CPU python)=5706.5703125MB; mem (CPU total)=7644.5234375MB
INFO:root:[   63] Training loss: 1.63110651, Validation loss: 1.50629509, Gradient norm: 2.28673300
INFO:root:At the start of the epoch: mem (CPU python)=5727.734375MB; mem (CPU total)=7678.44140625MB
INFO:root:[   64] Training loss: 1.63097598, Validation loss: 1.49823650, Gradient norm: 2.14335592
INFO:root:At the start of the epoch: mem (CPU python)=5748.8984375MB; mem (CPU total)=7730.76171875MB
INFO:root:[   65] Training loss: 1.63158095, Validation loss: 1.50095612, Gradient norm: 2.57275318
INFO:root:At the start of the epoch: mem (CPU python)=5770.06640625MB; mem (CPU total)=7737.49609375MB
INFO:root:[   66] Training loss: 1.63182356, Validation loss: 1.49841328, Gradient norm: 2.71424533
INFO:root:At the start of the epoch: mem (CPU python)=5791.23046875MB; mem (CPU total)=7731.91796875MB
INFO:root:[   67] Training loss: 1.63186155, Validation loss: 1.50066787, Gradient norm: 2.80699100
INFO:root:At the start of the epoch: mem (CPU python)=5812.39453125MB; mem (CPU total)=7810.83984375MB
INFO:root:[   68] Training loss: 1.63167472, Validation loss: 1.50529698, Gradient norm: 3.02097835
INFO:root:At the start of the epoch: mem (CPU python)=5833.5625MB; mem (CPU total)=7841.50390625MB
INFO:root:[   69] Training loss: 1.63181282, Validation loss: 1.50305396, Gradient norm: 3.22387695
INFO:root:At the start of the epoch: mem (CPU python)=5854.72265625MB; mem (CPU total)=7815.859375MB
INFO:root:[   70] Training loss: 1.63189119, Validation loss: 1.49841940, Gradient norm: 3.34626120
INFO:root:At the start of the epoch: mem (CPU python)=5875.88671875MB; mem (CPU total)=7876.71875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   71] Training loss: 1.63216225, Validation loss: 1.50557179, Gradient norm: 3.51386144
INFO:root:At the start of the epoch: mem (CPU python)=5897.046875MB; mem (CPU total)=7889.08203125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   72] Training loss: 1.62951025, Validation loss: 1.50345664, Gradient norm: 2.55385253
INFO:root:At the start of the epoch: mem (CPU python)=5918.2109375MB; mem (CPU total)=7892.63671875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   73] Training loss: 1.62819916, Validation loss: 1.50050557, Gradient norm: 2.20831167
INFO:root:At the start of the epoch: mem (CPU python)=5939.37890625MB; mem (CPU total)=7871.25MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   74] Training loss: 1.62766213, Validation loss: 1.49820494, Gradient norm: 1.77780651
INFO:root:At the start of the epoch: mem (CPU python)=5960.54296875MB; mem (CPU total)=7929.2890625MB
INFO:root:[   75] Training loss: 1.62739028, Validation loss: 1.49798606, Gradient norm: 1.44352459
INFO:root:At the start of the epoch: mem (CPU python)=5981.70703125MB; mem (CPU total)=7973.3515625MB
INFO:root:[   76] Training loss: 1.62732448, Validation loss: 1.49822329, Gradient norm: 1.71321581
INFO:root:At the start of the epoch: mem (CPU python)=6002.87109375MB; mem (CPU total)=7996.17578125MB
INFO:root:[   77] Training loss: 1.62737646, Validation loss: 1.49828118, Gradient norm: 1.75824964
INFO:root:At the start of the epoch: mem (CPU python)=6024.03515625MB; mem (CPU total)=7975.06640625MB
INFO:root:[   78] Training loss: 1.62731220, Validation loss: 1.49797334, Gradient norm: 1.77428846
INFO:root:At the start of the epoch: mem (CPU python)=6045.953125MB; mem (CPU total)=8038.89453125MB
INFO:root:[   79] Training loss: 1.62745602, Validation loss: 1.49885930, Gradient norm: 2.00484126
INFO:root:At the start of the epoch: mem (CPU python)=6067.74609375MB; mem (CPU total)=8063.12890625MB
INFO:root:[   80] Training loss: 1.62732581, Validation loss: 1.49737698, Gradient norm: 1.97192663
INFO:root:At the start of the epoch: mem (CPU python)=6088.921875MB; mem (CPU total)=8099.0546875MB
INFO:root:[   81] Training loss: 1.62745099, Validation loss: 1.49970596, Gradient norm: 2.12007907
INFO:root:At the start of the epoch: mem (CPU python)=6110.09765625MB; mem (CPU total)=8096.99609375MB
INFO:root:[   82] Training loss: 1.62736492, Validation loss: 1.49950588, Gradient norm: 2.21202344
INFO:root:At the start of the epoch: mem (CPU python)=6131.26171875MB; mem (CPU total)=8099.9453125MB
INFO:root:[   83] Training loss: 1.62747625, Validation loss: 1.49709631, Gradient norm: 2.16895535
INFO:root:At the start of the epoch: mem (CPU python)=6152.4375MB; mem (CPU total)=8156.03125MB
INFO:root:[   84] Training loss: 1.62752047, Validation loss: 1.49956369, Gradient norm: 2.39936420
INFO:root:At the start of the epoch: mem (CPU python)=6173.6171875MB; mem (CPU total)=8127.37109375MB
INFO:root:[   85] Training loss: 1.62751264, Validation loss: 1.49712234, Gradient norm: 2.41991016
INFO:root:At the start of the epoch: mem (CPU python)=6194.7890625MB; mem (CPU total)=8149.7265625MB
INFO:root:[   86] Training loss: 1.62748854, Validation loss: 1.49970297, Gradient norm: 2.52702013
INFO:root:At the start of the epoch: mem (CPU python)=6215.953125MB; mem (CPU total)=8205.9921875MB
INFO:root:[   87] Training loss: 1.62763025, Validation loss: 1.49834802, Gradient norm: 2.67098219
INFO:root:At the start of the epoch: mem (CPU python)=6237.1328125MB; mem (CPU total)=8222.5859375MB
INFO:root:[   88] Training loss: 1.62762450, Validation loss: 1.49853249, Gradient norm: 2.78018336
INFO:root:At the start of the epoch: mem (CPU python)=6258.3046875MB; mem (CPU total)=8258.5703125MB
INFO:root:[   89] Training loss: 1.62762704, Validation loss: 1.49867751, Gradient norm: 2.92544072
INFO:root:At the start of the epoch: mem (CPU python)=6279.4921875MB; mem (CPU total)=8245.66796875MB
INFO:root:[   90] Training loss: 1.62744122, Validation loss: 1.49804050, Gradient norm: 2.82258446
INFO:root:At the start of the epoch: mem (CPU python)=6300.66796875MB; mem (CPU total)=8327.109375MB
INFO:root:[   91] Training loss: 1.62758225, Validation loss: 1.49971425, Gradient norm: 3.08929885
INFO:root:At the start of the epoch: mem (CPU python)=6321.83203125MB; mem (CPU total)=8333.83984375MB
INFO:root:[   92] Training loss: 1.62753893, Validation loss: 1.50036754, Gradient norm: 2.91905074
INFO:root:At the start of the epoch: mem (CPU python)=6343.01953125MB; mem (CPU total)=8335.109375MB
INFO:root:EP 92: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=6364.19140625MB; mem (CPU total)=8330.69921875MB
INFO:root:[   94] Training loss: 0.65895477, Validation loss: 0.55011290, Gradient norm: 36.11248150
INFO:root:At the start of the epoch: mem (CPU python)=6385.3671875MB; mem (CPU total)=8376.375MB
INFO:root:[   95] Training loss: 0.65512230, Validation loss: 0.54569574, Gradient norm: 34.12524730
INFO:root:At the start of the epoch: mem (CPU python)=6406.5390625MB; mem (CPU total)=8433.01171875MB
INFO:root:[   96] Training loss: 0.65382656, Validation loss: 0.54497815, Gradient norm: 32.82401954
INFO:root:At the start of the epoch: mem (CPU python)=6427.71484375MB; mem (CPU total)=8427.1796875MB
INFO:root:[   97] Training loss: 0.65241493, Validation loss: 0.55061738, Gradient norm: 34.37286016
INFO:root:At the start of the epoch: mem (CPU python)=6448.890625MB; mem (CPU total)=8438.9375MB
INFO:root:[   98] Training loss: 0.65194036, Validation loss: 0.54612024, Gradient norm: 35.44620431
INFO:root:At the start of the epoch: mem (CPU python)=6470.109375MB; mem (CPU total)=8460.8515625MB
INFO:root:[   99] Training loss: 0.65069633, Validation loss: 0.54664758, Gradient norm: 34.50558703
INFO:root:At the start of the epoch: mem (CPU python)=6491.296875MB; mem (CPU total)=8513.484375MB
INFO:root:[  100] Training loss: 0.65122824, Validation loss: 0.54572395, Gradient norm: 36.42919910
INFO:root:At the start of the epoch: mem (CPU python)=6512.4921875MB; mem (CPU total)=8505.015625MB
INFO:root:[  101] Training loss: 0.65075819, Validation loss: 0.54914561, Gradient norm: 33.86847420
INFO:root:At the start of the epoch: mem (CPU python)=6533.66015625MB; mem (CPU total)=8556.20703125MB
INFO:root:[  102] Training loss: 0.65013152, Validation loss: 0.54487423, Gradient norm: 35.25198500
INFO:root:At the start of the epoch: mem (CPU python)=6554.82421875MB; mem (CPU total)=8579.5859375MB
INFO:root:[  103] Training loss: 0.64938276, Validation loss: 0.54732240, Gradient norm: 35.36077893
INFO:root:At the start of the epoch: mem (CPU python)=6575.984375MB; mem (CPU total)=8552.30859375MB
INFO:root:[  104] Training loss: 0.64918022, Validation loss: 0.54670606, Gradient norm: 34.75514738
INFO:root:At the start of the epoch: mem (CPU python)=6597.1484375MB; mem (CPU total)=8622.4140625MB
INFO:root:[  105] Training loss: 0.64911695, Validation loss: 0.54535710, Gradient norm: 35.20207852
INFO:root:At the start of the epoch: mem (CPU python)=6618.3125MB; mem (CPU total)=8663.7578125MB
INFO:root:[  106] Training loss: 0.64968898, Validation loss: 0.54425696, Gradient norm: 35.79129789
INFO:root:At the start of the epoch: mem (CPU python)=6639.48046875MB; mem (CPU total)=8690.9296875MB
INFO:root:[  107] Training loss: 0.64900320, Validation loss: 0.54599842, Gradient norm: 37.78372148
INFO:root:At the start of the epoch: mem (CPU python)=6660.64453125MB; mem (CPU total)=8650.515625MB
INFO:root:[  108] Training loss: 0.64833717, Validation loss: 0.54543441, Gradient norm: 34.50935882
INFO:root:At the start of the epoch: mem (CPU python)=6681.80859375MB; mem (CPU total)=8696.04296875MB
INFO:root:[  109] Training loss: 0.64788132, Validation loss: 0.54233952, Gradient norm: 36.62310589
INFO:root:At the start of the epoch: mem (CPU python)=6702.97265625MB; mem (CPU total)=8664.28125MB
INFO:root:[  110] Training loss: 0.64694054, Validation loss: 0.54198570, Gradient norm: 36.89726646
INFO:root:At the start of the epoch: mem (CPU python)=6724.13671875MB; mem (CPU total)=9010.70703125MB
INFO:root:[  111] Training loss: 0.64787263, Validation loss: 0.54341787, Gradient norm: 38.03975785
INFO:root:At the start of the epoch: mem (CPU python)=6745.30078125MB; mem (CPU total)=9286.58203125MB
INFO:root:[  112] Training loss: 0.64757343, Validation loss: 0.54256495, Gradient norm: 37.15055804
INFO:root:At the start of the epoch: mem (CPU python)=6766.46875MB; mem (CPU total)=9542.8203125MB
INFO:root:[  113] Training loss: 0.64812842, Validation loss: 0.54443571, Gradient norm: 39.68565842
INFO:root:At the start of the epoch: mem (CPU python)=6787.65234375MB; mem (CPU total)=9556.109375MB
INFO:root:[  114] Training loss: 0.64683244, Validation loss: 0.54483304, Gradient norm: 37.69230879
INFO:root:At the start of the epoch: mem (CPU python)=6809.10546875MB; mem (CPU total)=9630.85546875MB
INFO:root:[  115] Training loss: 0.64710958, Validation loss: 0.54604063, Gradient norm: 38.37942701
INFO:root:At the start of the epoch: mem (CPU python)=6830.89453125MB; mem (CPU total)=9630.515625MB
INFO:root:[  116] Training loss: 0.64717143, Validation loss: 0.54300155, Gradient norm: 38.46892829
INFO:root:At the start of the epoch: mem (CPU python)=6852.984375MB; mem (CPU total)=9655.0703125MB
INFO:root:[  117] Training loss: 0.64685811, Validation loss: 0.54298955, Gradient norm: 38.74426299
INFO:root:At the start of the epoch: mem (CPU python)=6874.4765625MB; mem (CPU total)=9677.046875MB
INFO:root:[  118] Training loss: 0.64665509, Validation loss: 0.54058322, Gradient norm: 40.36213079
INFO:root:At the start of the epoch: mem (CPU python)=6895.640625MB; mem (CPU total)=9666.8671875MB
INFO:root:[  119] Training loss: 0.64671110, Validation loss: 0.54036598, Gradient norm: 40.45432383
INFO:root:At the start of the epoch: mem (CPU python)=6916.8046875MB; mem (CPU total)=9717.05859375MB
INFO:root:[  120] Training loss: 0.64654360, Validation loss: 0.54319857, Gradient norm: 40.03879953
INFO:root:At the start of the epoch: mem (CPU python)=6937.96484375MB; mem (CPU total)=9721.71484375MB
INFO:root:[  121] Training loss: 0.64610262, Validation loss: 0.54352969, Gradient norm: 39.48314432
INFO:root:At the start of the epoch: mem (CPU python)=6959.12890625MB; mem (CPU total)=9712.53515625MB
INFO:root:[  122] Training loss: 0.64614101, Validation loss: 0.54234934, Gradient norm: 41.06166796
INFO:root:At the start of the epoch: mem (CPU python)=6980.29296875MB; mem (CPU total)=9756.734375MB
INFO:root:[  123] Training loss: 0.64571246, Validation loss: 0.54332465, Gradient norm: 41.89353611
INFO:root:At the start of the epoch: mem (CPU python)=7001.45703125MB; mem (CPU total)=9773.6640625MB
INFO:root:[  124] Training loss: 0.64606860, Validation loss: 0.54272665, Gradient norm: 42.00690979
INFO:root:At the start of the epoch: mem (CPU python)=7022.625MB; mem (CPU total)=9783.76953125MB
INFO:root:[  125] Training loss: 0.64539899, Validation loss: 0.54184762, Gradient norm: 42.01628379
INFO:root:At the start of the epoch: mem (CPU python)=7043.7890625MB; mem (CPU total)=9864.05078125MB
INFO:root:[  126] Training loss: 0.64591246, Validation loss: 0.54092776, Gradient norm: 43.81988030
INFO:root:At the start of the epoch: mem (CPU python)=7064.953125MB; mem (CPU total)=9819.1328125MB
INFO:root:[  127] Training loss: 0.64532715, Validation loss: 0.54120592, Gradient norm: 43.36249918
INFO:root:At the start of the epoch: mem (CPU python)=7086.11328125MB; mem (CPU total)=9894.1796875MB
INFO:root:[  128] Training loss: 0.64621664, Validation loss: 0.54086759, Gradient norm: 47.13079165
INFO:root:At the start of the epoch: mem (CPU python)=7107.27734375MB; mem (CPU total)=9910.00390625MB
INFO:root:[  129] Training loss: 0.64550482, Validation loss: 0.54023090, Gradient norm: 43.45633650
INFO:root:At the start of the epoch: mem (CPU python)=7128.4453125MB; mem (CPU total)=9887.21875MB
INFO:root:[  130] Training loss: 0.64569224, Validation loss: 0.54208172, Gradient norm: 44.39991462
INFO:root:At the start of the epoch: mem (CPU python)=7149.609375MB; mem (CPU total)=9919.21875MB
INFO:root:[  131] Training loss: 0.64585155, Validation loss: 0.54033850, Gradient norm: 45.31767680
INFO:root:At the start of the epoch: mem (CPU python)=7170.7734375MB; mem (CPU total)=9966.21875MB
INFO:root:[  132] Training loss: 0.64524520, Validation loss: 0.54065355, Gradient norm: 44.67609430
INFO:root:At the start of the epoch: mem (CPU python)=7191.9375MB; mem (CPU total)=9988.96484375MB
INFO:root:[  133] Training loss: 0.64475151, Validation loss: 0.54069369, Gradient norm: 45.35632217
INFO:root:At the start of the epoch: mem (CPU python)=7213.1015625MB; mem (CPU total)=9989.05859375MB
INFO:root:[  134] Training loss: 0.64463042, Validation loss: 0.53885629, Gradient norm: 45.42456034
INFO:root:At the start of the epoch: mem (CPU python)=7234.265625MB; mem (CPU total)=10014.078125MB
INFO:root:[  135] Training loss: 0.64540255, Validation loss: 0.54053711, Gradient norm: 46.56845707
INFO:root:At the start of the epoch: mem (CPU python)=7255.43359375MB; mem (CPU total)=10041.9609375MB
INFO:root:[  136] Training loss: 0.64470592, Validation loss: 0.53942924, Gradient norm: 46.41429790
INFO:root:At the start of the epoch: mem (CPU python)=7276.59765625MB; mem (CPU total)=10106.734375MB
INFO:root:[  137] Training loss: 0.64553190, Validation loss: 0.53816703, Gradient norm: 48.57264234
INFO:root:At the start of the epoch: mem (CPU python)=7297.7578125MB; mem (CPU total)=10103.78515625MB
INFO:root:[  138] Training loss: 0.64547685, Validation loss: 0.53935061, Gradient norm: 51.25706541
INFO:root:At the start of the epoch: mem (CPU python)=7318.91796875MB; mem (CPU total)=10149.515625MB
INFO:root:[  139] Training loss: 0.64448253, Validation loss: 0.54161781, Gradient norm: 45.84021247
INFO:root:At the start of the epoch: mem (CPU python)=7340.08203125MB; mem (CPU total)=10097.11328125MB
INFO:root:[  140] Training loss: 0.64476917, Validation loss: 0.54280442, Gradient norm: 48.18869962
INFO:root:At the start of the epoch: mem (CPU python)=7361.24609375MB; mem (CPU total)=10185.4921875MB
INFO:root:[  141] Training loss: 0.64443233, Validation loss: 0.54068284, Gradient norm: 48.05128995
INFO:root:At the start of the epoch: mem (CPU python)=7382.4140625MB; mem (CPU total)=10203.46484375MB
INFO:root:[  142] Training loss: 0.64363343, Validation loss: 0.54029777, Gradient norm: 47.22626864
INFO:root:At the start of the epoch: mem (CPU python)=7403.578125MB; mem (CPU total)=10194.11328125MB
INFO:root:[  143] Training loss: 0.64403107, Validation loss: 0.54078039, Gradient norm: 48.67956099
INFO:root:At the start of the epoch: mem (CPU python)=7424.7421875MB; mem (CPU total)=10254.8984375MB
INFO:root:[  144] Training loss: 0.64416530, Validation loss: 0.54143653, Gradient norm: 51.35033792
INFO:root:At the start of the epoch: mem (CPU python)=7445.91015625MB; mem (CPU total)=10242.3828125MB
INFO:root:[  145] Training loss: 0.64389708, Validation loss: 0.53919348, Gradient norm: 49.82178325
INFO:root:At the start of the epoch: mem (CPU python)=7467.07421875MB; mem (CPU total)=10255.5390625MB
INFO:root:[  146] Training loss: 0.64326294, Validation loss: 0.53801814, Gradient norm: 48.87964577
INFO:root:At the start of the epoch: mem (CPU python)=7488.23828125MB; mem (CPU total)=10285.11328125MB
INFO:root:[  147] Training loss: 0.64428012, Validation loss: 0.54042500, Gradient norm: 51.39253748
INFO:root:At the start of the epoch: mem (CPU python)=7509.40234375MB; mem (CPU total)=10296.796875MB
INFO:root:[  148] Training loss: 0.64474932, Validation loss: 0.53746260, Gradient norm: 53.12159179
INFO:root:At the start of the epoch: mem (CPU python)=7530.56640625MB; mem (CPU total)=10430.61328125MB
INFO:root:[  149] Training loss: 0.64391626, Validation loss: 0.53767774, Gradient norm: 52.37126206
INFO:root:At the start of the epoch: mem (CPU python)=7551.73046875MB; mem (CPU total)=10413.91015625MB
INFO:root:[  150] Training loss: 0.64317604, Validation loss: 0.53757343, Gradient norm: 50.37882378
INFO:root:At the start of the epoch: mem (CPU python)=7572.89453125MB; mem (CPU total)=10419.2734375MB
INFO:root:[  151] Training loss: 0.64382660, Validation loss: 0.54147147, Gradient norm: 52.30317658
INFO:root:At the start of the epoch: mem (CPU python)=7594.05859375MB; mem (CPU total)=10445.390625MB
INFO:root:[  152] Training loss: 0.64342560, Validation loss: 0.54284275, Gradient norm: 49.82320974
INFO:root:At the start of the epoch: mem (CPU python)=7615.2265625MB; mem (CPU total)=10495.11328125MB
INFO:root:[  153] Training loss: 0.64461672, Validation loss: 0.53956729, Gradient norm: 53.05006939
INFO:root:At the start of the epoch: mem (CPU python)=7636.390625MB; mem (CPU total)=10509.51953125MB
INFO:root:[  154] Training loss: 0.64327794, Validation loss: 0.54019176, Gradient norm: 53.01167351
INFO:root:At the start of the epoch: mem (CPU python)=7657.55078125MB; mem (CPU total)=10525.59375MB
INFO:root:[  155] Training loss: 0.64455366, Validation loss: 0.53975206, Gradient norm: 55.73725390
INFO:root:At the start of the epoch: mem (CPU python)=7678.7109375MB; mem (CPU total)=10575.43359375MB
INFO:root:[  156] Training loss: 0.64316017, Validation loss: 0.53849279, Gradient norm: 51.20866822
INFO:root:At the start of the epoch: mem (CPU python)=7699.87890625MB; mem (CPU total)=10603.85546875MB
INFO:root:[  157] Training loss: 0.64451183, Validation loss: 0.54260091, Gradient norm: 56.02216541
INFO:root:At the start of the epoch: mem (CPU python)=7721.04296875MB; mem (CPU total)=10572.54296875MB
INFO:root:[  158] Training loss: 0.64332432, Validation loss: 0.53735955, Gradient norm: 54.34148874
INFO:root:At the start of the epoch: mem (CPU python)=7742.20703125MB; mem (CPU total)=10567.15625MB
INFO:root:[  159] Training loss: 0.64320452, Validation loss: 0.54000460, Gradient norm: 54.73714961
INFO:root:At the start of the epoch: mem (CPU python)=7763.37109375MB; mem (CPU total)=10582.61328125MB
INFO:root:[  160] Training loss: 0.64384729, Validation loss: 0.53664719, Gradient norm: 54.53281708
INFO:root:At the start of the epoch: mem (CPU python)=7784.53515625MB; mem (CPU total)=10656.7265625MB
INFO:root:[  161] Training loss: 0.64424937, Validation loss: 0.54224428, Gradient norm: 56.40629400
INFO:root:At the start of the epoch: mem (CPU python)=7805.69921875MB; mem (CPU total)=10597.421875MB
INFO:root:[  162] Training loss: 0.64354193, Validation loss: 0.53626832, Gradient norm: 54.16118295
INFO:root:At the start of the epoch: mem (CPU python)=7826.86328125MB; mem (CPU total)=10632.30859375MB
INFO:root:[  163] Training loss: 0.64382899, Validation loss: 0.53960717, Gradient norm: 58.48455191
INFO:root:At the start of the epoch: mem (CPU python)=7848.03125MB; mem (CPU total)=10673.5625MB
INFO:root:[  164] Training loss: 0.64276443, Validation loss: 0.54045541, Gradient norm: 56.77121147
INFO:root:At the start of the epoch: mem (CPU python)=7869.1953125MB; mem (CPU total)=10682.3046875MB
INFO:root:[  165] Training loss: 0.64327842, Validation loss: 0.54112562, Gradient norm: 55.76113694
INFO:root:At the start of the epoch: mem (CPU python)=7890.35546875MB; mem (CPU total)=10748.49609375MB
INFO:root:[  166] Training loss: 0.64316549, Validation loss: 0.53622304, Gradient norm: 55.02629052
INFO:root:At the start of the epoch: mem (CPU python)=7911.51953125MB; mem (CPU total)=10703.19921875MB
INFO:root:[  167] Training loss: 0.64287856, Validation loss: 0.53979382, Gradient norm: 59.08472608
INFO:root:At the start of the epoch: mem (CPU python)=7932.6875MB; mem (CPU total)=10762.86328125MB
INFO:root:[  168] Training loss: 0.64229736, Validation loss: 0.53624753, Gradient norm: 59.22160142
INFO:root:At the start of the epoch: mem (CPU python)=7953.8515625MB; mem (CPU total)=10766.4609375MB
INFO:root:[  169] Training loss: 0.64332064, Validation loss: 0.53839614, Gradient norm: 58.88694957
INFO:root:At the start of the epoch: mem (CPU python)=7975.015625MB; mem (CPU total)=10819.78125MB
INFO:root:[  170] Training loss: 0.64306110, Validation loss: 0.53821297, Gradient norm: 58.64151907
INFO:root:At the start of the epoch: mem (CPU python)=7996.1796875MB; mem (CPU total)=10854.5390625MB
INFO:root:[  171] Training loss: 0.64496326, Validation loss: 0.61314699, Gradient norm: 59.25063063
INFO:root:At the start of the epoch: mem (CPU python)=8017.33984375MB; mem (CPU total)=10869.66015625MB
INFO:root:[  172] Training loss: 0.64368602, Validation loss: 0.53805322, Gradient norm: 61.62238097
INFO:root:At the start of the epoch: mem (CPU python)=8038.50390625MB; mem (CPU total)=10891.7421875MB
INFO:root:[  173] Training loss: 0.64274257, Validation loss: 0.53796829, Gradient norm: 59.61611497
INFO:root:At the start of the epoch: mem (CPU python)=8059.671875MB; mem (CPU total)=10911.61328125MB
INFO:root:[  174] Training loss: 0.64326403, Validation loss: 0.53791680, Gradient norm: 60.89055200
INFO:root:At the start of the epoch: mem (CPU python)=8080.83203125MB; mem (CPU total)=10937.51171875MB
INFO:root:[  175] Training loss: 0.64314624, Validation loss: 0.53928602, Gradient norm: 61.21188064
INFO:root:At the start of the epoch: mem (CPU python)=8101.99609375MB; mem (CPU total)=10985.10546875MB
INFO:root:EP 175: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=8123.16015625MB; mem (CPU total)=10985.46484375MB
INFO:root:Training the model took 14822.25s.
INFO:root:Emptying the cuda cache took 0.105s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.4578
INFO:root:EnergyScoreValidation: 0.34317
INFO:root:CRPSValidation: 0.14135
INFO:root:Gaussian NLLValidation: 0.27033
INFO:root:CoverageValidation: 0.76247
INFO:root:IntervalWidthValidation: 0.55149
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.37885
INFO:root:EnergyScoreTest: 0.29158
INFO:root:CRPSTest: 0.11793
INFO:root:Gaussian NLLTest: 0.4031
INFO:root:CoverageTest: 0.69688
INFO:root:IntervalWidthTest: 0.3845
INFO:root:After validation: mem (CPU python)=8138.15625MB; mem (CPU total)=11093.57421875MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=8138.15625MB; mem (CPU total)=11108.1015625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 62914560
INFO:root:After setting up the model: mem (CPU python)=8149.328125MB; mem (CPU total)=11110.640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=8149.328125MB; mem (CPU total)=11114.78515625MB
INFO:root:[    1] Training loss: 1.76109169, Validation loss: 1.68636499, Gradient norm: 0.15054221
INFO:root:At the start of the epoch: mem (CPU python)=8171.953125MB; mem (CPU total)=11198.578125MB
INFO:root:[    2] Training loss: 1.72116439, Validation loss: 1.60896867, Gradient norm: 0.16469812
INFO:root:At the start of the epoch: mem (CPU python)=8193.1328125MB; mem (CPU total)=11177.41015625MB
INFO:root:[    3] Training loss: 1.69381442, Validation loss: 1.59224195, Gradient norm: 0.18366169
INFO:root:At the start of the epoch: mem (CPU python)=8214.31640625MB; mem (CPU total)=11223.83984375MB
INFO:root:[    4] Training loss: 1.68092175, Validation loss: 1.56290631, Gradient norm: 0.23695335
INFO:root:At the start of the epoch: mem (CPU python)=8235.48828125MB; mem (CPU total)=11260.51953125MB
INFO:root:[    5] Training loss: 1.66729867, Validation loss: 1.54982688, Gradient norm: 0.31734013
INFO:root:At the start of the epoch: mem (CPU python)=8256.65234375MB; mem (CPU total)=11221.296875MB
INFO:root:[    6] Training loss: 1.65900081, Validation loss: 1.53658573, Gradient norm: 0.41746863
INFO:root:At the start of the epoch: mem (CPU python)=8277.81640625MB; mem (CPU total)=11287.3125MB
INFO:root:[    7] Training loss: 1.65600388, Validation loss: 1.53423326, Gradient norm: 0.58482784
INFO:root:At the start of the epoch: mem (CPU python)=8298.984375MB; mem (CPU total)=11264.83984375MB
INFO:root:[    8] Training loss: 1.65471302, Validation loss: 1.52737311, Gradient norm: 0.75918652
INFO:root:At the start of the epoch: mem (CPU python)=8320.1484375MB; mem (CPU total)=11288.11328125MB
INFO:root:[    9] Training loss: 1.65494574, Validation loss: 1.52809422, Gradient norm: 0.88781715
INFO:root:At the start of the epoch: mem (CPU python)=8341.3125MB; mem (CPU total)=11290.5MB
INFO:root:[   10] Training loss: 1.65337722, Validation loss: 1.54834752, Gradient norm: 0.98268835
INFO:root:At the start of the epoch: mem (CPU python)=8362.4765625MB; mem (CPU total)=11347.53515625MB
INFO:root:[   11] Training loss: 1.65405809, Validation loss: 1.54376223, Gradient norm: 1.09989167
INFO:root:At the start of the epoch: mem (CPU python)=8383.63671875MB; mem (CPU total)=11384.08984375MB
INFO:root:[   12] Training loss: 1.65237158, Validation loss: 1.53537665, Gradient norm: 1.11168888
INFO:root:At the start of the epoch: mem (CPU python)=8404.8046875MB; mem (CPU total)=11421.39453125MB
INFO:root:[   13] Training loss: 1.65026791, Validation loss: 1.52384835, Gradient norm: 1.16314181
INFO:root:At the start of the epoch: mem (CPU python)=8425.96875MB; mem (CPU total)=11408.27734375MB
INFO:root:[   14] Training loss: 1.64511163, Validation loss: 1.53759262, Gradient norm: 1.31866237
INFO:root:At the start of the epoch: mem (CPU python)=8447.1328125MB; mem (CPU total)=11414.19921875MB
INFO:root:[   15] Training loss: 1.64469832, Validation loss: 1.51124017, Gradient norm: 1.41000252
INFO:root:At the start of the epoch: mem (CPU python)=8468.296875MB; mem (CPU total)=11466.93359375MB
INFO:root:[   16] Training loss: 1.64410334, Validation loss: 1.50952666, Gradient norm: 1.42443784
INFO:root:At the start of the epoch: mem (CPU python)=8489.45703125MB; mem (CPU total)=11515.375MB
INFO:root:[   17] Training loss: 1.64385376, Validation loss: 1.52320088, Gradient norm: 1.42678955
INFO:root:At the start of the epoch: mem (CPU python)=8510.62109375MB; mem (CPU total)=11545.7421875MB
INFO:root:[   18] Training loss: 1.64403800, Validation loss: 1.52059475, Gradient norm: 1.48440166
INFO:root:At the start of the epoch: mem (CPU python)=8531.7890625MB; mem (CPU total)=11562.0078125MB
INFO:root:[   19] Training loss: 1.64305379, Validation loss: 1.51462259, Gradient norm: 1.54762197
INFO:root:At the start of the epoch: mem (CPU python)=8552.953125MB; mem (CPU total)=11598.0625MB
INFO:root:[   20] Training loss: 1.64272210, Validation loss: 1.51188865, Gradient norm: 1.53954463
INFO:root:At the start of the epoch: mem (CPU python)=8574.11328125MB; mem (CPU total)=11613.24609375MB
INFO:root:[   21] Training loss: 1.64307741, Validation loss: 1.50630606, Gradient norm: 1.58364491
INFO:root:At the start of the epoch: mem (CPU python)=8595.27734375MB; mem (CPU total)=11540.26171875MB
INFO:root:[   22] Training loss: 1.64266845, Validation loss: 1.51586928, Gradient norm: 1.61314257
INFO:root:At the start of the epoch: mem (CPU python)=8616.44140625MB; mem (CPU total)=11642.875MB
INFO:root:[   23] Training loss: 1.64280859, Validation loss: 1.52107413, Gradient norm: 1.63795179
INFO:root:At the start of the epoch: mem (CPU python)=8641.6171875MB; mem (CPU total)=11655.9453125MB
INFO:root:[   24] Training loss: 1.64289492, Validation loss: 1.50877067, Gradient norm: 1.64087558
INFO:root:At the start of the epoch: mem (CPU python)=8663.6484375MB; mem (CPU total)=11701.296875MB
INFO:root:[   25] Training loss: 1.64183193, Validation loss: 1.51426032, Gradient norm: 1.65916684
INFO:root:At the start of the epoch: mem (CPU python)=8684.81640625MB; mem (CPU total)=11687.0MB
INFO:root:[   26] Training loss: 1.64234244, Validation loss: 1.51205751, Gradient norm: 1.68474154
INFO:root:At the start of the epoch: mem (CPU python)=8705.98046875MB; mem (CPU total)=11744.796875MB
INFO:root:[   27] Training loss: 1.64178445, Validation loss: 1.51061352, Gradient norm: 1.67002377
INFO:root:At the start of the epoch: mem (CPU python)=8727.14453125MB; mem (CPU total)=11748.14453125MB
INFO:root:[   28] Training loss: 1.64204379, Validation loss: 1.51084827, Gradient norm: 1.75036254
INFO:root:At the start of the epoch: mem (CPU python)=8748.30859375MB; mem (CPU total)=11698.6171875MB
INFO:root:[   29] Training loss: 1.64128818, Validation loss: 1.51144405, Gradient norm: 1.65792680
INFO:root:At the start of the epoch: mem (CPU python)=8769.4765625MB; mem (CPU total)=11771.65234375MB
INFO:root:[   30] Training loss: 1.64134329, Validation loss: 1.52266848, Gradient norm: 1.76402054
INFO:root:At the start of the epoch: mem (CPU python)=8790.63671875MB; mem (CPU total)=11772.4453125MB
INFO:root:[   31] Training loss: 1.64181137, Validation loss: 1.52312618, Gradient norm: 1.76546408
INFO:root:At the start of the epoch: mem (CPU python)=8811.80078125MB; mem (CPU total)=11742.08203125MB
INFO:root:[   32] Training loss: 1.64101400, Validation loss: 1.51161246, Gradient norm: 1.74818179
INFO:root:At the start of the epoch: mem (CPU python)=8832.9609375MB; mem (CPU total)=11773.875MB
INFO:root:[   33] Training loss: 1.64106278, Validation loss: 1.50698951, Gradient norm: 1.76559717
INFO:root:At the start of the epoch: mem (CPU python)=8854.125MB; mem (CPU total)=11834.48828125MB
INFO:root:[   34] Training loss: 1.64080135, Validation loss: 1.50715967, Gradient norm: 1.81496797
INFO:root:At the start of the epoch: mem (CPU python)=8875.29296875MB; mem (CPU total)=11907.328125MB
INFO:root:[   35] Training loss: 1.64166303, Validation loss: 1.51604564, Gradient norm: 1.92658449
INFO:root:At the start of the epoch: mem (CPU python)=8896.45703125MB; mem (CPU total)=11834.08984375MB
INFO:root:[   36] Training loss: 1.64130134, Validation loss: 1.51907898, Gradient norm: 1.84105781
INFO:root:At the start of the epoch: mem (CPU python)=8917.62109375MB; mem (CPU total)=11917.51953125MB
INFO:root:[   37] Training loss: 1.64118779, Validation loss: 1.51873283, Gradient norm: 1.93015990
INFO:root:At the start of the epoch: mem (CPU python)=8938.78515625MB; mem (CPU total)=11946.8046875MB
INFO:root:[   38] Training loss: 1.64085044, Validation loss: 1.51170581, Gradient norm: 1.93291665
INFO:root:At the start of the epoch: mem (CPU python)=8959.953125MB; mem (CPU total)=11990.59375MB
INFO:root:[   39] Training loss: 1.64044977, Validation loss: 1.52186711, Gradient norm: 1.91764588
INFO:root:At the start of the epoch: mem (CPU python)=8981.1171875MB; mem (CPU total)=12009.16015625MB
INFO:root:[   40] Training loss: 1.64113658, Validation loss: 1.51798554, Gradient norm: 2.01085633
INFO:root:At the start of the epoch: mem (CPU python)=9002.28125MB; mem (CPU total)=12016.1953125MB
INFO:root:[   41] Training loss: 1.64060925, Validation loss: 1.52152321, Gradient norm: 1.95886560
INFO:root:At the start of the epoch: mem (CPU python)=9023.4453125MB; mem (CPU total)=12029.16796875MB
INFO:root:[   42] Training loss: 1.64087724, Validation loss: 1.51883110, Gradient norm: 2.00810903
INFO:root:At the start of the epoch: mem (CPU python)=9044.609375MB; mem (CPU total)=12031.0546875MB
INFO:root:[   43] Training loss: 1.63997799, Validation loss: 1.50931103, Gradient norm: 1.99356537
INFO:root:At the start of the epoch: mem (CPU python)=9065.7734375MB; mem (CPU total)=12091.390625MB
INFO:root:[   44] Training loss: 1.64156612, Validation loss: 1.52231576, Gradient norm: 2.08217832
INFO:root:At the start of the epoch: mem (CPU python)=9086.9375MB; mem (CPU total)=12094.56640625MB
INFO:root:[   45] Training loss: 1.64051339, Validation loss: 1.50631415, Gradient norm: 2.03301466
INFO:root:At the start of the epoch: mem (CPU python)=9108.10546875MB; mem (CPU total)=12132.8984375MB
INFO:root:[   46] Training loss: 1.64024677, Validation loss: 1.51358160, Gradient norm: 2.04965875
INFO:root:At the start of the epoch: mem (CPU python)=9129.26953125MB; mem (CPU total)=12165.8125MB
INFO:root:[   47] Training loss: 1.64114310, Validation loss: 1.52329918, Gradient norm: 2.16109527
INFO:root:At the start of the epoch: mem (CPU python)=9150.43359375MB; mem (CPU total)=12169.6171875MB
INFO:root:[   48] Training loss: 1.64036402, Validation loss: 1.51527532, Gradient norm: 2.18592306
INFO:root:At the start of the epoch: mem (CPU python)=9171.59375MB; mem (CPU total)=12195.40234375MB
INFO:root:[   49] Training loss: 1.81394802, Validation loss: 1.64829752, Gradient norm: 11.70619077
INFO:root:At the start of the epoch: mem (CPU python)=9192.75390625MB; mem (CPU total)=12169.328125MB
INFO:root:[   50] Training loss: 1.76474430, Validation loss: 1.57726854, Gradient norm: 5.18008851
INFO:root:At the start of the epoch: mem (CPU python)=9213.921875MB; mem (CPU total)=12248.765625MB
INFO:root:[   51] Training loss: 1.71240987, Validation loss: 1.57110455, Gradient norm: 3.30411157
INFO:root:At the start of the epoch: mem (CPU python)=9235.0859375MB; mem (CPU total)=12192.86328125MB
INFO:root:[   52] Training loss: 1.69513671, Validation loss: 1.55066770, Gradient norm: 2.83798906
INFO:root:At the start of the epoch: mem (CPU python)=9256.25MB; mem (CPU total)=12255.96484375MB
INFO:root:[   53] Training loss: 1.72217243, Validation loss: 1.61033749, Gradient norm: 7.27460521
INFO:root:At the start of the epoch: mem (CPU python)=9277.4140625MB; mem (CPU total)=12310.9375MB
INFO:root:[   54] Training loss: 1.72051016, Validation loss: 1.55108302, Gradient norm: 7.64504375
INFO:root:At the start of the epoch: mem (CPU python)=9298.578125MB; mem (CPU total)=12266.28515625MB
INFO:root:[   55] Training loss: 1.71367950, Validation loss: 1.55709345, Gradient norm: 7.10530681
INFO:root:At the start of the epoch: mem (CPU python)=9319.7421875MB; mem (CPU total)=12319.11328125MB
INFO:root:[   56] Training loss: 1.70211475, Validation loss: 1.54861832, Gradient norm: 6.70373210
INFO:root:At the start of the epoch: mem (CPU python)=9340.91015625MB; mem (CPU total)=12360.64453125MB
INFO:root:[   57] Training loss: 1.69746006, Validation loss: 1.54306081, Gradient norm: 5.19370699
INFO:root:At the start of the epoch: mem (CPU python)=9362.07421875MB; mem (CPU total)=12325.42578125MB
INFO:root:[   58] Training loss: 1.70192851, Validation loss: 1.54548567, Gradient norm: 6.21993235
INFO:root:At the start of the epoch: mem (CPU python)=9383.234375MB; mem (CPU total)=12369.9375MB
INFO:root:[   59] Training loss: 1.72361927, Validation loss: 1.55075065, Gradient norm: 8.14159458
INFO:root:At the start of the epoch: mem (CPU python)=9404.3984375MB; mem (CPU total)=12361.8125MB
INFO:root:[   60] Training loss: 1.70508384, Validation loss: 2.01875107, Gradient norm: 6.28930804
INFO:root:At the start of the epoch: mem (CPU python)=9425.56640625MB; mem (CPU total)=12374.33203125MB
INFO:root:[   61] Training loss: 1.74177759, Validation loss: 1.54450359, Gradient norm: 13.89896895
INFO:root:At the start of the epoch: mem (CPU python)=9446.7265625MB; mem (CPU total)=12477.7890625MB
INFO:root:[   62] Training loss: 1.68911156, Validation loss: 1.54434794, Gradient norm: 3.30473898
INFO:root:At the start of the epoch: mem (CPU python)=9467.89453125MB; mem (CPU total)=12499.11328125MB
INFO:root:[   63] Training loss: 1.68838821, Validation loss: 1.54505831, Gradient norm: 4.01475244
INFO:root:At the start of the epoch: mem (CPU python)=9489.05859375MB; mem (CPU total)=12507.7421875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   64] Training loss: 1.69426466, Validation loss: 1.54873289, Gradient norm: 5.51998720
INFO:root:At the start of the epoch: mem (CPU python)=9510.22265625MB; mem (CPU total)=12515.4453125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   65] Training loss: 1.68404463, Validation loss: 1.53464715, Gradient norm: 4.50483428
INFO:root:At the start of the epoch: mem (CPU python)=9531.38671875MB; mem (CPU total)=12573.67578125MB
INFO:root:[   66] Training loss: 1.68062627, Validation loss: 1.53554341, Gradient norm: 3.56907004
INFO:root:At the start of the epoch: mem (CPU python)=9552.546875MB; mem (CPU total)=12546.21875MB
INFO:root:[   67] Training loss: 1.67979185, Validation loss: 1.53469673, Gradient norm: 4.23846081
INFO:root:At the start of the epoch: mem (CPU python)=9573.70703125MB; mem (CPU total)=12554.69140625MB
INFO:root:[   68] Training loss: 1.67904492, Validation loss: 1.53276346, Gradient norm: 4.91561573
INFO:root:At the start of the epoch: mem (CPU python)=9594.875MB; mem (CPU total)=12637.23046875MB
INFO:root:[   69] Training loss: 1.67854031, Validation loss: 1.53203683, Gradient norm: 5.85623704
INFO:root:At the start of the epoch: mem (CPU python)=9616.0390625MB; mem (CPU total)=12639.8828125MB
INFO:root:[   70] Training loss: 1.67762092, Validation loss: 1.52780652, Gradient norm: 6.53883393
INFO:root:At the start of the epoch: mem (CPU python)=9637.203125MB; mem (CPU total)=12617.58203125MB
INFO:root:[   71] Training loss: 1.67824167, Validation loss: 1.53148650, Gradient norm: 8.10603838
INFO:root:At the start of the epoch: mem (CPU python)=9658.3671875MB; mem (CPU total)=12638.1796875MB
INFO:root:[   72] Training loss: 1.67660105, Validation loss: 1.52832542, Gradient norm: 7.82646330
INFO:root:At the start of the epoch: mem (CPU python)=9679.53125MB; mem (CPU total)=12688.87109375MB
INFO:root:[   73] Training loss: 1.67628658, Validation loss: 1.52842941, Gradient norm: 8.46879582
INFO:root:At the start of the epoch: mem (CPU python)=9700.69921875MB; mem (CPU total)=12679.9921875MB
INFO:root:[   74] Training loss: 1.67533029, Validation loss: 1.53588639, Gradient norm: 8.90925267
INFO:root:At the start of the epoch: mem (CPU python)=9721.86328125MB; mem (CPU total)=12707.13671875MB
INFO:root:[   75] Training loss: 1.67533637, Validation loss: 1.52692649, Gradient norm: 10.01908323
INFO:root:At the start of the epoch: mem (CPU python)=9743.02734375MB; mem (CPU total)=12712.890625MB
INFO:root:[   76] Training loss: 1.68721637, Validation loss: 1.53324634, Gradient norm: 18.09273568
INFO:root:At the start of the epoch: mem (CPU python)=9764.19140625MB; mem (CPU total)=12773.16796875MB
INFO:root:[   77] Training loss: 1.67722373, Validation loss: 1.51829819, Gradient norm: 14.70592866
INFO:root:At the start of the epoch: mem (CPU python)=9785.3515625MB; mem (CPU total)=12765.328125MB
INFO:root:[   78] Training loss: 1.67472537, Validation loss: 1.52729205, Gradient norm: 12.11934192
INFO:root:At the start of the epoch: mem (CPU python)=9806.515625MB; mem (CPU total)=12828.2109375MB
INFO:root:[   79] Training loss: 1.68676219, Validation loss: 1.52418277, Gradient norm: 20.31268919
INFO:root:At the start of the epoch: mem (CPU python)=9827.68359375MB; mem (CPU total)=12845.10546875MB
INFO:root:[   80] Training loss: 1.67591210, Validation loss: 1.52089844, Gradient norm: 13.67157639
INFO:root:At the start of the epoch: mem (CPU python)=9848.84765625MB; mem (CPU total)=12866.12109375MB
INFO:root:[   81] Training loss: 1.67739422, Validation loss: 1.53806312, Gradient norm: 13.78290915
INFO:root:At the start of the epoch: mem (CPU python)=9870.01171875MB; mem (CPU total)=12875.87109375MB
INFO:root:[   82] Training loss: 1.67862229, Validation loss: 1.52374704, Gradient norm: 18.03465550
INFO:root:At the start of the epoch: mem (CPU python)=9891.17578125MB; mem (CPU total)=12924.62109375MB
INFO:root:[   83] Training loss: 1.67461287, Validation loss: 1.52453677, Gradient norm: 13.85008161
INFO:root:At the start of the epoch: mem (CPU python)=9912.33984375MB; mem (CPU total)=12917.67578125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   84] Training loss: 1.67431430, Validation loss: 1.52629499, Gradient norm: 13.31374301
INFO:root:At the start of the epoch: mem (CPU python)=9933.50390625MB; mem (CPU total)=12967.45703125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   85] Training loss: 1.67099518, Validation loss: 1.52366148, Gradient norm: 8.58845819
INFO:root:At the start of the epoch: mem (CPU python)=9954.66796875MB; mem (CPU total)=12988.83984375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   86] Training loss: 1.66983345, Validation loss: 1.52087580, Gradient norm: 6.65966697
INFO:root:At the start of the epoch: mem (CPU python)=9975.828125MB; mem (CPU total)=12962.40625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:EP 86: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=9996.9921875MB; mem (CPU total)=12956.94140625MB
INFO:root:[   88] Training loss: 0.87744951, Validation loss: 0.74993666, Gradient norm: 20.13591027
INFO:root:At the start of the epoch: mem (CPU python)=10018.15625MB; mem (CPU total)=12991.23046875MB
INFO:root:[   89] Training loss: 0.87399901, Validation loss: 0.74907591, Gradient norm: 18.66307712
INFO:root:At the start of the epoch: mem (CPU python)=10039.3203125MB; mem (CPU total)=13035.20703125MB
INFO:root:[   90] Training loss: 0.87306754, Validation loss: 0.74766877, Gradient norm: 18.18239359
INFO:root:At the start of the epoch: mem (CPU python)=10060.484375MB; mem (CPU total)=13050.03515625MB
INFO:root:[   91] Training loss: 0.87217066, Validation loss: 0.74698077, Gradient norm: 18.40186324
INFO:root:At the start of the epoch: mem (CPU python)=10081.6484375MB; mem (CPU total)=13097.8515625MB
INFO:root:[   92] Training loss: 0.87129228, Validation loss: 0.74663184, Gradient norm: 18.53573053
INFO:root:At the start of the epoch: mem (CPU python)=10102.81640625MB; mem (CPU total)=13134.46484375MB
INFO:root:[   93] Training loss: 0.87057472, Validation loss: 0.74630805, Gradient norm: 19.16707554
INFO:root:At the start of the epoch: mem (CPU python)=10123.98046875MB; mem (CPU total)=13156.796875MB
INFO:root:[   94] Training loss: 0.87006451, Validation loss: 0.74596648, Gradient norm: 18.92850342
INFO:root:At the start of the epoch: mem (CPU python)=10145.14453125MB; mem (CPU total)=12357.33984375MB
INFO:root:[   95] Training loss: 0.86938596, Validation loss: 0.74458420, Gradient norm: 19.76224311
INFO:root:At the start of the epoch: mem (CPU python)=10166.30859375MB; mem (CPU total)=12374.98046875MB
INFO:root:[   96] Training loss: 0.86892235, Validation loss: 0.74386657, Gradient norm: 20.20998719
INFO:root:At the start of the epoch: mem (CPU python)=10187.46875MB; mem (CPU total)=11549.65234375MB
INFO:root:[   97] Training loss: 0.86864518, Validation loss: 0.74416826, Gradient norm: 20.00383897
INFO:root:At the start of the epoch: mem (CPU python)=10208.6328125MB; mem (CPU total)=11813.8125MB
INFO:root:[   98] Training loss: 0.86794530, Validation loss: 0.74371067, Gradient norm: 20.33362152
INFO:root:At the start of the epoch: mem (CPU python)=10229.80078125MB; mem (CPU total)=11889.90234375MB
INFO:root:[   99] Training loss: 0.86715881, Validation loss: 0.74351886, Gradient norm: 21.12776165
INFO:root:At the start of the epoch: mem (CPU python)=10250.96484375MB; mem (CPU total)=11920.6015625MB
INFO:root:[  100] Training loss: 0.86674643, Validation loss: 0.74276830, Gradient norm: 21.23046609
INFO:root:At the start of the epoch: mem (CPU python)=10272.12890625MB; mem (CPU total)=11876.546875MB
INFO:root:[  101] Training loss: 0.86628757, Validation loss: 0.74162333, Gradient norm: 20.57924632
INFO:root:At the start of the epoch: mem (CPU python)=10293.2890625MB; mem (CPU total)=11952.4921875MB
INFO:root:[  102] Training loss: 0.86587286, Validation loss: 0.74129732, Gradient norm: 21.25202227
INFO:root:At the start of the epoch: mem (CPU python)=10314.453125MB; mem (CPU total)=11965.69921875MB
INFO:root:[  103] Training loss: 0.86536292, Validation loss: 0.74150514, Gradient norm: 21.56821953
INFO:root:At the start of the epoch: mem (CPU python)=10335.62890625MB; mem (CPU total)=11978.765625MB
INFO:root:[  104] Training loss: 0.86506643, Validation loss: 0.74152101, Gradient norm: 21.50874030
INFO:root:At the start of the epoch: mem (CPU python)=10356.79296875MB; mem (CPU total)=11992.6875MB
INFO:root:[  105] Training loss: 0.86491416, Validation loss: 0.74082611, Gradient norm: 21.62585166
INFO:root:At the start of the epoch: mem (CPU python)=10377.953125MB; mem (CPU total)=12020.76953125MB
INFO:root:[  106] Training loss: 0.86424640, Validation loss: 0.74035946, Gradient norm: 22.83149387
INFO:root:At the start of the epoch: mem (CPU python)=10399.1171875MB; mem (CPU total)=12051.75390625MB
INFO:root:[  107] Training loss: 0.86405358, Validation loss: 0.73910132, Gradient norm: 22.49131036
INFO:root:At the start of the epoch: mem (CPU python)=10420.28125MB; mem (CPU total)=12058.19921875MB
INFO:root:[  108] Training loss: 0.86357653, Validation loss: 0.73921043, Gradient norm: 23.39951608
INFO:root:At the start of the epoch: mem (CPU python)=10441.4453125MB; mem (CPU total)=12093.48828125MB
INFO:root:[  109] Training loss: 0.86329784, Validation loss: 0.73873271, Gradient norm: 22.59308902
INFO:root:At the start of the epoch: mem (CPU python)=10462.61328125MB; mem (CPU total)=12115.96484375MB
INFO:root:[  110] Training loss: 0.86293576, Validation loss: 0.73932705, Gradient norm: 22.32382289
INFO:root:At the start of the epoch: mem (CPU python)=10483.77734375MB; mem (CPU total)=12124.2890625MB
INFO:root:[  111] Training loss: 0.86220708, Validation loss: 0.73987400, Gradient norm: 23.75908481
INFO:root:At the start of the epoch: mem (CPU python)=10504.94140625MB; mem (CPU total)=12127.33984375MB
INFO:root:[  112] Training loss: 0.86191795, Validation loss: 0.73909585, Gradient norm: 24.21022743
INFO:root:At the start of the epoch: mem (CPU python)=10526.10546875MB; mem (CPU total)=12167.640625MB
INFO:root:[  113] Training loss: 0.86192050, Validation loss: 0.73897840, Gradient norm: 23.61473406
INFO:root:At the start of the epoch: mem (CPU python)=10547.26953125MB; mem (CPU total)=12208.6796875MB
INFO:root:[  114] Training loss: 0.86198454, Validation loss: 0.73766263, Gradient norm: 24.68992761
INFO:root:At the start of the epoch: mem (CPU python)=10568.43359375MB; mem (CPU total)=12227.80859375MB
INFO:root:[  115] Training loss: 0.86118515, Validation loss: 0.73790749, Gradient norm: 24.23932524
INFO:root:At the start of the epoch: mem (CPU python)=10589.59765625MB; mem (CPU total)=12239.8125MB
INFO:root:[  116] Training loss: 0.86103424, Validation loss: 0.73655707, Gradient norm: 25.44380466
INFO:root:At the start of the epoch: mem (CPU python)=10610.765625MB; mem (CPU total)=12284.2890625MB
INFO:root:[  117] Training loss: 0.86073116, Validation loss: 0.73859984, Gradient norm: 25.24706223
INFO:root:At the start of the epoch: mem (CPU python)=10631.92578125MB; mem (CPU total)=12304.859375MB
INFO:root:[  118] Training loss: 0.86032007, Validation loss: 0.73687884, Gradient norm: 25.35975374
INFO:root:At the start of the epoch: mem (CPU python)=10653.09375MB; mem (CPU total)=12287.7578125MB
INFO:root:[  119] Training loss: 0.86028080, Validation loss: 0.73667808, Gradient norm: 25.72532004
INFO:root:At the start of the epoch: mem (CPU python)=10674.2578125MB; mem (CPU total)=12349.140625MB
INFO:root:[  120] Training loss: 0.85992504, Validation loss: 0.73693127, Gradient norm: 25.80694150
INFO:root:At the start of the epoch: mem (CPU python)=10695.421875MB; mem (CPU total)=12354.9921875MB
INFO:root:[  121] Training loss: 0.85962175, Validation loss: 0.73490722, Gradient norm: 26.41270440
INFO:root:At the start of the epoch: mem (CPU python)=10716.5859375MB; mem (CPU total)=12400.74609375MB
INFO:root:[  122] Training loss: 0.85956537, Validation loss: 0.73590696, Gradient norm: 26.32721662
INFO:root:At the start of the epoch: mem (CPU python)=10737.75MB; mem (CPU total)=12409.828125MB
INFO:root:[  123] Training loss: 0.85907457, Validation loss: 0.73558809, Gradient norm: 26.62852396
INFO:root:At the start of the epoch: mem (CPU python)=10758.9140625MB; mem (CPU total)=12435.06640625MB
INFO:root:[  124] Training loss: 0.85885619, Validation loss: 0.73509884, Gradient norm: 27.16910438
INFO:root:At the start of the epoch: mem (CPU python)=10780.078125MB; mem (CPU total)=12438.95703125MB
INFO:root:[  125] Training loss: 0.85889680, Validation loss: 0.73579204, Gradient norm: 27.17826344
INFO:root:At the start of the epoch: mem (CPU python)=10801.2421875MB; mem (CPU total)=12443.30859375MB
INFO:root:[  126] Training loss: 0.85830116, Validation loss: 0.73505019, Gradient norm: 26.51991829
INFO:root:At the start of the epoch: mem (CPU python)=10822.40625MB; mem (CPU total)=12496.31640625MB
INFO:root:[  127] Training loss: 0.85785047, Validation loss: 0.73531077, Gradient norm: 27.01883669
INFO:root:At the start of the epoch: mem (CPU python)=10843.5703125MB; mem (CPU total)=12525.984375MB
INFO:root:[  128] Training loss: 0.85777044, Validation loss: 0.73547980, Gradient norm: 28.10895796
INFO:root:At the start of the epoch: mem (CPU python)=10864.734375MB; mem (CPU total)=12542.78125MB
INFO:root:[  129] Training loss: 0.85800937, Validation loss: 0.73488932, Gradient norm: 28.47903779
INFO:root:At the start of the epoch: mem (CPU python)=10885.8984375MB; mem (CPU total)=12556.80078125MB
INFO:root:[  130] Training loss: 0.85791415, Validation loss: 0.73562916, Gradient norm: 29.07377303
INFO:root:At the start of the epoch: mem (CPU python)=10907.0625MB; mem (CPU total)=12576.078125MB
INFO:root:[  131] Training loss: 0.85769601, Validation loss: 0.73471119, Gradient norm: 28.85322728
INFO:root:At the start of the epoch: mem (CPU python)=10928.23046875MB; mem (CPU total)=12611.72265625MB
INFO:root:[  132] Training loss: 0.85701763, Validation loss: 0.73471758, Gradient norm: 28.58168886
INFO:root:At the start of the epoch: mem (CPU python)=10949.39453125MB; mem (CPU total)=12618.921875MB
INFO:root:[  133] Training loss: 0.85732858, Validation loss: 0.73444508, Gradient norm: 33.19323742
INFO:root:At the start of the epoch: mem (CPU python)=10970.5546875MB; mem (CPU total)=12632.140625MB
INFO:root:[  134] Training loss: 0.85677522, Validation loss: 0.73400311, Gradient norm: 28.74230225
INFO:root:At the start of the epoch: mem (CPU python)=10991.71875MB; mem (CPU total)=12673.86328125MB
INFO:root:[  135] Training loss: 0.85685746, Validation loss: 0.73414102, Gradient norm: 30.17557354
INFO:root:At the start of the epoch: mem (CPU python)=11012.87890625MB; mem (CPU total)=12696.73046875MB
INFO:root:[  136] Training loss: 0.85645101, Validation loss: 0.73314268, Gradient norm: 30.67236705
INFO:root:At the start of the epoch: mem (CPU python)=11034.046875MB; mem (CPU total)=12717.26953125MB
INFO:root:[  137] Training loss: 0.85634323, Validation loss: 0.73424079, Gradient norm: 29.26070275
INFO:root:At the start of the epoch: mem (CPU python)=11055.2109375MB; mem (CPU total)=12733.421875MB
INFO:root:[  138] Training loss: 0.85591512, Validation loss: 0.73379963, Gradient norm: 30.64716407
INFO:root:At the start of the epoch: mem (CPU python)=11076.375MB; mem (CPU total)=12762.58984375MB
INFO:root:[  139] Training loss: 0.85599579, Validation loss: 0.73243408, Gradient norm: 30.62310962
INFO:root:At the start of the epoch: mem (CPU python)=11097.5390625MB; mem (CPU total)=12773.9140625MB
INFO:root:[  140] Training loss: 0.85583599, Validation loss: 0.73236363, Gradient norm: 30.78696638
INFO:root:At the start of the epoch: mem (CPU python)=11118.703125MB; mem (CPU total)=12802.66015625MB
INFO:root:[  141] Training loss: 0.85562279, Validation loss: 0.73294862, Gradient norm: 31.56115625
INFO:root:At the start of the epoch: mem (CPU python)=11139.8671875MB; mem (CPU total)=12824.5859375MB
INFO:root:[  142] Training loss: 0.85556382, Validation loss: 0.73263315, Gradient norm: 33.42150590
INFO:root:At the start of the epoch: mem (CPU python)=11161.03125MB; mem (CPU total)=12834.48046875MB
INFO:root:[  143] Training loss: 0.85542882, Validation loss: 0.73256780, Gradient norm: 31.28820371
INFO:root:At the start of the epoch: mem (CPU python)=11182.1953125MB; mem (CPU total)=12861.3671875MB
INFO:root:[  144] Training loss: 0.85515594, Validation loss: 0.73298903, Gradient norm: 32.82007529
INFO:root:At the start of the epoch: mem (CPU python)=11203.359375MB; mem (CPU total)=12884.046875MB
INFO:root:[  145] Training loss: 0.85487592, Validation loss: 0.73236975, Gradient norm: 31.98178179
INFO:root:At the start of the epoch: mem (CPU python)=11224.5234375MB; mem (CPU total)=12913.01171875MB
INFO:root:[  146] Training loss: 0.85482761, Validation loss: 0.73140685, Gradient norm: 31.97166878
INFO:root:At the start of the epoch: mem (CPU python)=11245.6875MB; mem (CPU total)=12944.65625MB
INFO:root:[  147] Training loss: 0.85468613, Validation loss: 0.73116440, Gradient norm: 33.22189808
INFO:root:At the start of the epoch: mem (CPU python)=11266.8515625MB; mem (CPU total)=12951.25390625MB
INFO:root:[  148] Training loss: 0.85472950, Validation loss: 0.73276300, Gradient norm: 33.46365586
INFO:root:At the start of the epoch: mem (CPU python)=11288.015625MB; mem (CPU total)=12979.30078125MB
INFO:root:[  149] Training loss: 0.85396804, Validation loss: 0.73395291, Gradient norm: 33.90735643
INFO:root:At the start of the epoch: mem (CPU python)=11309.18359375MB; mem (CPU total)=12993.82421875MB
INFO:root:[  150] Training loss: 0.85430278, Validation loss: 0.73211581, Gradient norm: 34.09626825
INFO:root:At the start of the epoch: mem (CPU python)=11330.34765625MB; mem (CPU total)=13015.3671875MB
INFO:root:[  151] Training loss: 0.85427978, Validation loss: 0.73164728, Gradient norm: 34.57016931
INFO:root:At the start of the epoch: mem (CPU python)=11351.5078125MB; mem (CPU total)=13046.14453125MB
INFO:root:[  152] Training loss: 0.85398005, Validation loss: 0.73311731, Gradient norm: 33.57339264
INFO:root:At the start of the epoch: mem (CPU python)=11372.66796875MB; mem (CPU total)=13069.0390625MB
INFO:root:[  153] Training loss: 0.85369068, Validation loss: 0.73298350, Gradient norm: 34.10715562
INFO:root:At the start of the epoch: mem (CPU python)=11393.83984375MB; mem (CPU total)=13075.47265625MB
INFO:root:[  154] Training loss: 0.85347981, Validation loss: 0.73116171, Gradient norm: 35.29187471
INFO:root:At the start of the epoch: mem (CPU python)=11415.00390625MB; mem (CPU total)=13086.875MB
INFO:root:[  155] Training loss: 0.85368657, Validation loss: 0.73100476, Gradient norm: 33.69871102
INFO:root:At the start of the epoch: mem (CPU python)=11436.16796875MB; mem (CPU total)=13131.7265625MB
INFO:root:[  156] Training loss: 0.85321995, Validation loss: 0.73026633, Gradient norm: 34.89708669
INFO:root:At the start of the epoch: mem (CPU python)=11457.33203125MB; mem (CPU total)=13153.8828125MB
INFO:root:[  157] Training loss: 0.85294777, Validation loss: 0.73012572, Gradient norm: 35.29482416
INFO:root:At the start of the epoch: mem (CPU python)=11478.49609375MB; mem (CPU total)=13173.61328125MB
INFO:root:[  158] Training loss: 0.85285662, Validation loss: 0.72964091, Gradient norm: 35.94345972
INFO:root:At the start of the epoch: mem (CPU python)=11499.66015625MB; mem (CPU total)=13195.1484375MB
INFO:root:[  159] Training loss: 0.85282492, Validation loss: 0.73087143, Gradient norm: 36.62471036
INFO:root:At the start of the epoch: mem (CPU python)=11520.828125MB; mem (CPU total)=13209.66796875MB
INFO:root:[  160] Training loss: 0.85267403, Validation loss: 0.72975061, Gradient norm: 35.70005082
INFO:root:At the start of the epoch: mem (CPU python)=11541.9921875MB; mem (CPU total)=13208.50390625MB
INFO:root:[  161] Training loss: 0.85255112, Validation loss: 0.72967650, Gradient norm: 36.00633567
INFO:root:At the start of the epoch: mem (CPU python)=11563.15234375MB; mem (CPU total)=13266.28125MB
INFO:root:[  162] Training loss: 0.85269318, Validation loss: 0.72927043, Gradient norm: 40.26276577
INFO:root:At the start of the epoch: mem (CPU python)=11584.31640625MB; mem (CPU total)=13289.81640625MB
INFO:root:[  163] Training loss: 0.85222985, Validation loss: 0.72981250, Gradient norm: 36.58579667
INFO:root:At the start of the epoch: mem (CPU python)=11605.48046875MB; mem (CPU total)=13269.13671875MB
INFO:root:[  164] Training loss: 0.85228687, Validation loss: 0.73018239, Gradient norm: 37.10874586
INFO:root:At the start of the epoch: mem (CPU python)=11626.64453125MB; mem (CPU total)=13329.0859375MB
INFO:root:[  165] Training loss: 0.85217303, Validation loss: 0.72931730, Gradient norm: 36.94509207
INFO:root:At the start of the epoch: mem (CPU python)=11647.8125MB; mem (CPU total)=13326.1875MB
INFO:root:[  166] Training loss: 0.85210316, Validation loss: 0.73011333, Gradient norm: 36.62666395
INFO:root:At the start of the epoch: mem (CPU python)=11668.9765625MB; mem (CPU total)=13364.4375MB
INFO:root:[  167] Training loss: 0.85133050, Validation loss: 0.72885573, Gradient norm: 36.82350091
INFO:root:At the start of the epoch: mem (CPU python)=11690.140625MB; mem (CPU total)=13382.0859375MB
INFO:root:[  168] Training loss: 0.85160429, Validation loss: 0.72885142, Gradient norm: 36.85630564
INFO:root:At the start of the epoch: mem (CPU python)=11711.3046875MB; mem (CPU total)=13415.64453125MB
INFO:root:[  169] Training loss: 0.85139582, Validation loss: 0.72970195, Gradient norm: 38.03855302
INFO:root:At the start of the epoch: mem (CPU python)=11732.46484375MB; mem (CPU total)=13408.7890625MB
INFO:root:[  170] Training loss: 0.85145232, Validation loss: 0.72970459, Gradient norm: 37.96130800
INFO:root:At the start of the epoch: mem (CPU python)=11753.62890625MB; mem (CPU total)=13456.8984375MB
INFO:root:[  171] Training loss: 0.85099672, Validation loss: 0.72858461, Gradient norm: 39.19497709
INFO:root:At the start of the epoch: mem (CPU python)=11774.79296875MB; mem (CPU total)=13479.76171875MB
INFO:root:[  172] Training loss: 0.85120207, Validation loss: 0.72757898, Gradient norm: 38.50463430
INFO:root:At the start of the epoch: mem (CPU python)=11795.95703125MB; mem (CPU total)=13516.953125MB
INFO:root:[  173] Training loss: 0.85115522, Validation loss: 0.72942980, Gradient norm: 40.19629609
INFO:root:At the start of the epoch: mem (CPU python)=11817.12109375MB; mem (CPU total)=13533.1171875MB
INFO:root:[  174] Training loss: 0.85095579, Validation loss: 0.72948172, Gradient norm: 39.48330428
INFO:root:At the start of the epoch: mem (CPU python)=11838.28515625MB; mem (CPU total)=13534.1796875MB
INFO:root:[  175] Training loss: 0.85087323, Validation loss: 0.72773588, Gradient norm: 40.82877933
INFO:root:At the start of the epoch: mem (CPU python)=11859.44921875MB; mem (CPU total)=13563.51953125MB
INFO:root:[  176] Training loss: 0.85042134, Validation loss: 0.72932537, Gradient norm: 40.54462824
INFO:root:At the start of the epoch: mem (CPU python)=11880.61328125MB; mem (CPU total)=13586.77734375MB
INFO:root:[  177] Training loss: 0.85020799, Validation loss: 0.72819441, Gradient norm: 39.39281108
INFO:root:At the start of the epoch: mem (CPU python)=11901.78125MB; mem (CPU total)=13618.59765625MB
INFO:root:[  178] Training loss: 0.85027975, Validation loss: 0.72911149, Gradient norm: 41.17377587
INFO:root:At the start of the epoch: mem (CPU python)=11922.9453125MB; mem (CPU total)=13643.00390625MB
INFO:root:[  179] Training loss: 0.85018280, Validation loss: 0.72714429, Gradient norm: 42.89988858
INFO:root:At the start of the epoch: mem (CPU python)=11944.109375MB; mem (CPU total)=13653.0MB
INFO:root:[  180] Training loss: 0.84975701, Validation loss: 0.72678196, Gradient norm: 42.12237882
INFO:root:At the start of the epoch: mem (CPU python)=11965.26953125MB; mem (CPU total)=13672.41796875MB
INFO:root:[  181] Training loss: 0.85001652, Validation loss: 0.72798715, Gradient norm: 41.55089722
INFO:root:At the start of the epoch: mem (CPU python)=11986.43359375MB; mem (CPU total)=13686.57421875MB
INFO:root:[  182] Training loss: 0.84976794, Validation loss: 0.72817718, Gradient norm: 42.10232018
INFO:root:At the start of the epoch: mem (CPU python)=12007.6015625MB; mem (CPU total)=13715.31640625MB
INFO:root:[  183] Training loss: 0.84963221, Validation loss: 0.72679332, Gradient norm: 42.60040574
INFO:root:At the start of the epoch: mem (CPU python)=12028.765625MB; mem (CPU total)=13734.33203125MB
INFO:root:[  184] Training loss: 0.84960427, Validation loss: 0.72807844, Gradient norm: 41.28287777
INFO:root:At the start of the epoch: mem (CPU python)=12049.9296875MB; mem (CPU total)=13779.265625MB
INFO:root:[  185] Training loss: 0.84957286, Validation loss: 0.72655142, Gradient norm: 42.69478319
INFO:root:At the start of the epoch: mem (CPU python)=12071.09375MB; mem (CPU total)=13723.30078125MB
INFO:root:[  186] Training loss: 0.84886909, Validation loss: 0.72735384, Gradient norm: 42.55822430
INFO:root:At the start of the epoch: mem (CPU python)=12092.25390625MB; mem (CPU total)=13792.734375MB
INFO:root:[  187] Training loss: 0.84890761, Validation loss: 0.72596947, Gradient norm: 43.33973870
INFO:root:At the start of the epoch: mem (CPU python)=12113.41796875MB; mem (CPU total)=13822.18359375MB
INFO:root:[  188] Training loss: 0.84911309, Validation loss: 0.72680826, Gradient norm: 43.45869083
INFO:root:At the start of the epoch: mem (CPU python)=12134.5859375MB; mem (CPU total)=13831.50390625MB
INFO:root:[  189] Training loss: 0.84892097, Validation loss: 0.72711965, Gradient norm: 42.87623468
INFO:root:At the start of the epoch: mem (CPU python)=12155.75MB; mem (CPU total)=13834.18359375MB
INFO:root:[  190] Training loss: 0.84872708, Validation loss: 0.72610611, Gradient norm: 44.22432407
INFO:root:At the start of the epoch: mem (CPU python)=12176.91015625MB; mem (CPU total)=13886.765625MB
INFO:root:[  191] Training loss: 0.84875579, Validation loss: 0.72647514, Gradient norm: 42.94220541
INFO:root:At the start of the epoch: mem (CPU python)=12198.07421875MB; mem (CPU total)=13884.421875MB
INFO:root:[  192] Training loss: 0.84852796, Validation loss: 0.72631512, Gradient norm: 42.95571150
INFO:root:At the start of the epoch: mem (CPU python)=12219.23828125MB; mem (CPU total)=13932.07421875MB
INFO:root:[  193] Training loss: 0.84837372, Validation loss: 0.72652421, Gradient norm: 45.04895196
INFO:root:At the start of the epoch: mem (CPU python)=12240.40625MB; mem (CPU total)=13955.453125MB
INFO:root:[  194] Training loss: 0.84834108, Validation loss: 0.72535739, Gradient norm: 41.83006251
INFO:root:At the start of the epoch: mem (CPU python)=12261.5703125MB; mem (CPU total)=13963.87109375MB
INFO:root:[  195] Training loss: 0.84844152, Validation loss: 0.72642198, Gradient norm: 44.54019851
INFO:root:At the start of the epoch: mem (CPU python)=12282.734375MB; mem (CPU total)=13986.984375MB
INFO:root:[  196] Training loss: 0.84801753, Validation loss: 0.72576568, Gradient norm: 45.07866676
INFO:root:At the start of the epoch: mem (CPU python)=12303.90234375MB; mem (CPU total)=14011.91015625MB
INFO:root:[  197] Training loss: 0.84797721, Validation loss: 0.72656077, Gradient norm: 47.03823899
INFO:root:At the start of the epoch: mem (CPU python)=12325.06640625MB; mem (CPU total)=14041.05859375MB
INFO:root:[  198] Training loss: 0.84725015, Validation loss: 0.72571681, Gradient norm: 44.19316471
INFO:root:At the start of the epoch: mem (CPU python)=12346.234375MB; mem (CPU total)=14039.17578125MB
INFO:root:[  199] Training loss: 0.84763396, Validation loss: 0.72568748, Gradient norm: 45.88138842
INFO:root:At the start of the epoch: mem (CPU python)=12367.39453125MB; mem (CPU total)=14088.01953125MB
INFO:root:[  200] Training loss: 0.84745843, Validation loss: 0.72561031, Gradient norm: 43.74408344
INFO:root:At the start of the epoch: mem (CPU python)=12388.55859375MB; mem (CPU total)=14121.125MB
INFO:root:[  201] Training loss: 0.84767106, Validation loss: 0.72533943, Gradient norm: 45.56820614
INFO:root:At the start of the epoch: mem (CPU python)=12409.72265625MB; mem (CPU total)=14147.953125MB
INFO:root:[  202] Training loss: 0.84691927, Validation loss: 0.72340523, Gradient norm: 46.20924389
INFO:root:At the start of the epoch: mem (CPU python)=12430.88671875MB; mem (CPU total)=14140.09765625MB
INFO:root:[  203] Training loss: 0.84702467, Validation loss: 0.72565282, Gradient norm: 48.38572053
INFO:root:At the start of the epoch: mem (CPU python)=12452.046875MB; mem (CPU total)=14161.1015625MB
INFO:root:[  204] Training loss: 0.84700474, Validation loss: 0.72421305, Gradient norm: 47.18708604
INFO:root:At the start of the epoch: mem (CPU python)=12473.2109375MB; mem (CPU total)=14181.328125MB
INFO:root:[  205] Training loss: 0.84723739, Validation loss: 0.72427111, Gradient norm: 59.81060750
INFO:root:At the start of the epoch: mem (CPU python)=12494.37890625MB; mem (CPU total)=14197.93359375MB
INFO:root:[  206] Training loss: 0.84674043, Validation loss: 0.72484614, Gradient norm: 47.98052939
INFO:root:At the start of the epoch: mem (CPU python)=12515.54296875MB; mem (CPU total)=14224.19140625MB
INFO:root:[  207] Training loss: 0.84640862, Validation loss: 0.72361912, Gradient norm: 46.98849346
INFO:root:At the start of the epoch: mem (CPU python)=12536.70703125MB; mem (CPU total)=14240.6015625MB
INFO:root:[  208] Training loss: 0.84637479, Validation loss: 0.72621728, Gradient norm: 49.08262951
INFO:root:At the start of the epoch: mem (CPU python)=12557.87109375MB; mem (CPU total)=14265.67578125MB
INFO:root:[  209] Training loss: 0.84641347, Validation loss: 0.72470454, Gradient norm: 50.51382753
INFO:root:At the start of the epoch: mem (CPU python)=12579.03515625MB; mem (CPU total)=14280.2265625MB
INFO:root:[  210] Training loss: 0.84615960, Validation loss: 0.72440182, Gradient norm: 49.27543580
INFO:root:At the start of the epoch: mem (CPU python)=12600.19921875MB; mem (CPU total)=14305.0625MB
INFO:root:[  211] Training loss: 0.84621534, Validation loss: 0.72280962, Gradient norm: 49.53526824
INFO:root:At the start of the epoch: mem (CPU python)=12621.36328125MB; mem (CPU total)=14317.171875MB
INFO:root:[  212] Training loss: 0.84591593, Validation loss: 0.72254228, Gradient norm: 49.54695677
INFO:root:At the start of the epoch: mem (CPU python)=12642.52734375MB; mem (CPU total)=14333.09375MB
INFO:root:[  213] Training loss: 0.84542643, Validation loss: 0.72315642, Gradient norm: 49.50072660
INFO:root:At the start of the epoch: mem (CPU python)=12663.69140625MB; mem (CPU total)=14349.72265625MB
INFO:root:[  214] Training loss: 0.84534753, Validation loss: 0.72459544, Gradient norm: 48.79622168
INFO:root:At the start of the epoch: mem (CPU python)=12684.85546875MB; mem (CPU total)=14397.87109375MB
INFO:root:[  215] Training loss: 0.84518026, Validation loss: 0.72321046, Gradient norm: 51.79430955
INFO:root:At the start of the epoch: mem (CPU python)=12706.0234375MB; mem (CPU total)=14415.23828125MB
INFO:root:[  216] Training loss: 0.84529564, Validation loss: 0.72574208, Gradient norm: 50.86805038
INFO:root:At the start of the epoch: mem (CPU python)=12727.1875MB; mem (CPU total)=14435.8359375MB
INFO:root:[  217] Training loss: 0.84538159, Validation loss: 0.72340461, Gradient norm: 49.20602383
INFO:root:At the start of the epoch: mem (CPU python)=12748.3515625MB; mem (CPU total)=14506.8359375MB
INFO:root:[  218] Training loss: 0.84492107, Validation loss: 0.72299024, Gradient norm: 51.69879728
INFO:root:At the start of the epoch: mem (CPU python)=12769.51171875MB; mem (CPU total)=14518.8203125MB
INFO:root:[  219] Training loss: 0.84496970, Validation loss: 0.72230192, Gradient norm: 50.65472588
INFO:root:At the start of the epoch: mem (CPU python)=12790.67578125MB; mem (CPU total)=14539.4140625MB
INFO:root:[  220] Training loss: 0.84453902, Validation loss: 0.72439725, Gradient norm: 52.72012986
INFO:root:At the start of the epoch: mem (CPU python)=12811.8359375MB; mem (CPU total)=14564.953125MB
INFO:root:[  221] Training loss: 1.62826657, Validation loss: 0.72312519, Gradient norm: 2101.56807244
INFO:root:At the start of the epoch: mem (CPU python)=12833.00390625MB; mem (CPU total)=14597.33984375MB
INFO:root:[  222] Training loss: 0.84403689, Validation loss: 0.72352033, Gradient norm: 50.39915260
INFO:root:At the start of the epoch: mem (CPU python)=12854.16796875MB; mem (CPU total)=14604.5MB
INFO:root:[  223] Training loss: 0.84415304, Validation loss: 0.72253918, Gradient norm: 50.68544781
INFO:root:At the start of the epoch: mem (CPU python)=12875.33203125MB; mem (CPU total)=14635.7578125MB
INFO:root:[  224] Training loss: 0.84451356, Validation loss: 0.72338341, Gradient norm: 50.09441825
INFO:root:At the start of the epoch: mem (CPU python)=12896.49609375MB; mem (CPU total)=14643.8515625MB
INFO:root:[  225] Training loss: 0.84426709, Validation loss: 0.72163159, Gradient norm: 51.83715951
INFO:root:At the start of the epoch: mem (CPU python)=12917.66015625MB; mem (CPU total)=14661.33203125MB
INFO:root:[  226] Training loss: 0.84423863, Validation loss: 0.72167295, Gradient norm: 54.10002374
INFO:root:At the start of the epoch: mem (CPU python)=12938.82421875MB; mem (CPU total)=14716.609375MB
INFO:root:[  227] Training loss: 0.84404361, Validation loss: 0.72265113, Gradient norm: 53.16394933
INFO:root:At the start of the epoch: mem (CPU python)=12959.98828125MB; mem (CPU total)=14723.85546875MB
INFO:root:[  228] Training loss: 0.84386993, Validation loss: 0.72190856, Gradient norm: 51.03741256
INFO:root:At the start of the epoch: mem (CPU python)=12981.15234375MB; mem (CPU total)=14752.26171875MB
INFO:root:[  229] Training loss: 0.84417327, Validation loss: 0.72179738, Gradient norm: 53.23368526
INFO:root:At the start of the epoch: mem (CPU python)=13002.31640625MB; mem (CPU total)=14766.95703125MB
INFO:root:[  230] Training loss: 0.84376499, Validation loss: 0.72169993, Gradient norm: 55.71717081
INFO:root:At the start of the epoch: mem (CPU python)=13023.48046875MB; mem (CPU total)=14786.38671875MB
INFO:root:[  231] Training loss: 0.84390221, Validation loss: 0.72293256, Gradient norm: 53.37785738
INFO:root:At the start of the epoch: mem (CPU python)=13044.64453125MB; mem (CPU total)=14813.08984375MB
INFO:root:[  232] Training loss: 0.84368860, Validation loss: 0.72111845, Gradient norm: 54.03133392
INFO:root:At the start of the epoch: mem (CPU python)=13065.8125MB; mem (CPU total)=14841.12109375MB
INFO:root:[  233] Training loss: 0.84363185, Validation loss: 0.72247624, Gradient norm: 53.56435796
INFO:root:At the start of the epoch: mem (CPU python)=13086.9765625MB; mem (CPU total)=14834.56640625MB
INFO:root:[  234] Training loss: 0.84343802, Validation loss: 0.72260475, Gradient norm: 55.34663090
INFO:root:At the start of the epoch: mem (CPU python)=13108.140625MB; mem (CPU total)=14880.90234375MB
INFO:root:[  235] Training loss: 0.84323333, Validation loss: 0.72196966, Gradient norm: 52.68580159
INFO:root:At the start of the epoch: mem (CPU python)=13129.3046875MB; mem (CPU total)=14906.9609375MB
INFO:root:[  236] Training loss: 0.84349041, Validation loss: 0.72067834, Gradient norm: 67.81703217
INFO:root:At the start of the epoch: mem (CPU python)=13150.46875MB; mem (CPU total)=14940.3515625MB
INFO:root:[  237] Training loss: 0.84287075, Validation loss: 0.72289465, Gradient norm: 53.81648752
INFO:root:At the start of the epoch: mem (CPU python)=13171.625MB; mem (CPU total)=14941.92578125MB
INFO:root:[  238] Training loss: 0.84302541, Validation loss: 0.71983903, Gradient norm: 56.78974842
INFO:root:At the start of the epoch: mem (CPU python)=13192.79296875MB; mem (CPU total)=14987.3671875MB
INFO:root:[  239] Training loss: 0.84288310, Validation loss: 0.72009609, Gradient norm: 57.02172190
INFO:root:At the start of the epoch: mem (CPU python)=13213.9609375MB; mem (CPU total)=15010.0859375MB
INFO:root:[  240] Training loss: 0.84259141, Validation loss: 0.71954897, Gradient norm: 54.47290468
INFO:root:At the start of the epoch: mem (CPU python)=13235.125MB; mem (CPU total)=15027.46484375MB
INFO:root:[  241] Training loss: 0.84271737, Validation loss: 0.72033619, Gradient norm: 60.68741075
INFO:root:At the start of the epoch: mem (CPU python)=13256.2890625MB; mem (CPU total)=15034.08203125MB
INFO:root:[  242] Training loss: 0.84212085, Validation loss: 0.71923428, Gradient norm: 57.63459544
INFO:root:At the start of the epoch: mem (CPU python)=13277.453125MB; mem (CPU total)=15052.859375MB
INFO:root:[  243] Training loss: 0.84181863, Validation loss: 0.72084254, Gradient norm: 54.39517462
INFO:root:At the start of the epoch: mem (CPU python)=13298.6171875MB; mem (CPU total)=15081.52734375MB
INFO:root:[  244] Training loss: 0.84201880, Validation loss: 0.71931428, Gradient norm: 58.57231372
INFO:root:At the start of the epoch: mem (CPU python)=13319.78125MB; mem (CPU total)=15102.0078125MB
INFO:root:[  245] Training loss: 0.84312168, Validation loss: 0.71940865, Gradient norm: 75.25124657
INFO:root:At the start of the epoch: mem (CPU python)=13340.94921875MB; mem (CPU total)=15090.078125MB
INFO:root:[  246] Training loss: 0.84145181, Validation loss: 0.71917058, Gradient norm: 57.54465998
INFO:root:At the start of the epoch: mem (CPU python)=13362.109375MB; mem (CPU total)=15119.41015625MB
INFO:root:[  247] Training loss: 0.84184352, Validation loss: 0.71933890, Gradient norm: 57.17823401
INFO:root:At the start of the epoch: mem (CPU python)=13383.2734375MB; mem (CPU total)=15121.10546875MB
INFO:root:[  248] Training loss: 0.84136204, Validation loss: 0.71968419, Gradient norm: 59.08284317
INFO:root:At the start of the epoch: mem (CPU python)=13404.4375MB; mem (CPU total)=15160.47265625MB
INFO:root:[  249] Training loss: 0.84125852, Validation loss: 0.71859203, Gradient norm: 60.23741053
INFO:root:At the start of the epoch: mem (CPU python)=13425.6015625MB; mem (CPU total)=15183.93359375MB
INFO:root:[  250] Training loss: 0.84128320, Validation loss: 0.71891774, Gradient norm: 58.87074882
INFO:root:At the start of the epoch: mem (CPU python)=13446.76953125MB; mem (CPU total)=15190.76953125MB
INFO:root:[  251] Training loss: 0.84079325, Validation loss: 0.71808831, Gradient norm: 60.00204531
INFO:root:At the start of the epoch: mem (CPU python)=13467.93359375MB; mem (CPU total)=15227.8125MB
INFO:root:[  252] Training loss: 0.84047919, Validation loss: 0.71871857, Gradient norm: 58.44107058
INFO:root:At the start of the epoch: mem (CPU python)=13489.09765625MB; mem (CPU total)=15260.69140625MB
INFO:root:[  253] Training loss: 0.84195736, Validation loss: 0.71863616, Gradient norm: 97.29322140
INFO:root:At the start of the epoch: mem (CPU python)=13510.2578125MB; mem (CPU total)=15289.56640625MB
INFO:root:[  254] Training loss: 0.84046699, Validation loss: 0.71827321, Gradient norm: 62.14454301
INFO:root:At the start of the epoch: mem (CPU python)=13531.421875MB; mem (CPU total)=15311.69921875MB
INFO:root:[  255] Training loss: 0.84086974, Validation loss: 0.71755421, Gradient norm: 61.37339268
INFO:root:At the start of the epoch: mem (CPU python)=13552.58984375MB; mem (CPU total)=15312.4609375MB
INFO:root:[  256] Training loss: 0.84063226, Validation loss: 0.71774593, Gradient norm: 60.30708224
INFO:root:At the start of the epoch: mem (CPU python)=13573.75MB; mem (CPU total)=15333.828125MB
INFO:root:[  257] Training loss: 0.84229709, Validation loss: 0.71709907, Gradient norm: 108.94098427
INFO:root:At the start of the epoch: mem (CPU python)=13594.9140625MB; mem (CPU total)=15352.4375MB
INFO:root:[  258] Training loss: 0.84066836, Validation loss: 0.71825030, Gradient norm: 82.07191453
INFO:root:At the start of the epoch: mem (CPU python)=13616.078125MB; mem (CPU total)=15375.703125MB
INFO:root:[  259] Training loss: 0.83986968, Validation loss: 0.71791682, Gradient norm: 62.01058458
INFO:root:At the start of the epoch: mem (CPU python)=13637.2421875MB; mem (CPU total)=15399.0859375MB
INFO:root:[  260] Training loss: 0.83954511, Validation loss: 0.71649611, Gradient norm: 61.57128005
INFO:root:At the start of the epoch: mem (CPU python)=13658.40625MB; mem (CPU total)=15400.62890625MB
INFO:root:[  261] Training loss: 0.83956572, Validation loss: 0.71752303, Gradient norm: 62.88110636
INFO:root:At the start of the epoch: mem (CPU python)=13679.57421875MB; mem (CPU total)=15435.28125MB
INFO:root:[  262] Training loss: 0.83975278, Validation loss: 0.71764436, Gradient norm: 62.66814282
INFO:root:At the start of the epoch: mem (CPU python)=13700.73828125MB; mem (CPU total)=15479.31640625MB
INFO:root:[  263] Training loss: 0.84030973, Validation loss: 0.71678679, Gradient norm: 75.35681634
INFO:root:At the start of the epoch: mem (CPU python)=13721.90234375MB; mem (CPU total)=15484.4140625MB
INFO:root:[  264] Training loss: 0.83914691, Validation loss: 0.71710487, Gradient norm: 64.44418640
INFO:root:At the start of the epoch: mem (CPU python)=13743.06640625MB; mem (CPU total)=15504.6015625MB
INFO:root:[  265] Training loss: 0.83905411, Validation loss: 0.71662016, Gradient norm: 63.59920334
INFO:root:At the start of the epoch: mem (CPU python)=13764.23046875MB; mem (CPU total)=15530.47265625MB
INFO:root:[  266] Training loss: 0.83928314, Validation loss: 0.71828351, Gradient norm: 66.33429261
INFO:root:At the start of the epoch: mem (CPU python)=13785.390625MB; mem (CPU total)=15532.390625MB
INFO:root:[  267] Training loss: 0.83897892, Validation loss: 45.07206545, Gradient norm: 64.15549177
INFO:root:At the start of the epoch: mem (CPU python)=13806.55859375MB; mem (CPU total)=15569.078125MB
INFO:root:[  268] Training loss: 0.83860464, Validation loss: 0.71623122, Gradient norm: 64.22626596
INFO:root:At the start of the epoch: mem (CPU python)=13827.72265625MB; mem (CPU total)=15595.07421875MB
INFO:root:[  269] Training loss: 0.83861764, Validation loss: 0.71780807, Gradient norm: 66.43918506
INFO:root:At the start of the epoch: mem (CPU python)=13848.88671875MB; mem (CPU total)=15607.29296875MB
INFO:root:[  270] Training loss: 0.83902180, Validation loss: 0.71622582, Gradient norm: 86.44695125
INFO:root:At the start of the epoch: mem (CPU python)=13870.05078125MB; mem (CPU total)=15636.046875MB
INFO:root:[  271] Training loss: 0.83857562, Validation loss: 0.71620868, Gradient norm: 65.01144294
INFO:root:At the start of the epoch: mem (CPU python)=13891.2109375MB; mem (CPU total)=15659.828125MB
INFO:root:[  272] Training loss: 0.83968983, Validation loss: 0.71381238, Gradient norm: 89.46155792
INFO:root:At the start of the epoch: mem (CPU python)=13912.375MB; mem (CPU total)=15664.97265625MB
INFO:root:[  273] Training loss: 0.83796432, Validation loss: 0.71479677, Gradient norm: 66.33640794
INFO:root:At the start of the epoch: mem (CPU python)=13933.54296875MB; mem (CPU total)=15685.40625MB
INFO:root:[  274] Training loss: 0.83807460, Validation loss: 0.71503853, Gradient norm: 66.40914113
INFO:root:At the start of the epoch: mem (CPU python)=13954.703125MB; mem (CPU total)=15690.6015625MB
INFO:root:[  275] Training loss: 0.83779804, Validation loss: 0.71606909, Gradient norm: 62.65186228
INFO:root:At the start of the epoch: mem (CPU python)=13975.8671875MB; mem (CPU total)=15740.45703125MB
INFO:root:[  276] Training loss: 0.83785667, Validation loss: 0.71370261, Gradient norm: 70.86572733
INFO:root:At the start of the epoch: mem (CPU python)=13997.03125MB; mem (CPU total)=15754.37109375MB
INFO:root:[  277] Training loss: 0.83760200, Validation loss: 0.71438338, Gradient norm: 66.78707692
INFO:root:At the start of the epoch: mem (CPU python)=14018.1953125MB; mem (CPU total)=15767.2265625MB
INFO:root:[  278] Training loss: 0.83758240, Validation loss: 0.71399535, Gradient norm: 70.21729049
INFO:root:At the start of the epoch: mem (CPU python)=14039.36328125MB; mem (CPU total)=15778.62890625MB
INFO:root:[  279] Training loss: 0.83735667, Validation loss: 0.71742716, Gradient norm: 70.81681018
INFO:root:At the start of the epoch: mem (CPU python)=14060.53125MB; mem (CPU total)=15805.95703125MB
INFO:root:[  280] Training loss: 0.83734504, Validation loss: 0.71740688, Gradient norm: 70.22626160
INFO:root:At the start of the epoch: mem (CPU python)=14081.6953125MB; mem (CPU total)=15823.8984375MB
INFO:root:[  281] Training loss: 0.83693535, Validation loss: 0.71384578, Gradient norm: 80.66524527
INFO:root:At the start of the epoch: mem (CPU python)=14102.859375MB; mem (CPU total)=15844.24609375MB
INFO:root:[  282] Training loss: 0.83694712, Validation loss: 0.71453094, Gradient norm: 70.35413221
INFO:root:At the start of the epoch: mem (CPU python)=14124.02734375MB; mem (CPU total)=15866.0078125MB
INFO:root:[  283] Training loss: 0.83709817, Validation loss: 0.71505636, Gradient norm: 74.82287626
INFO:root:At the start of the epoch: mem (CPU python)=14145.19140625MB; mem (CPU total)=15892.83203125MB
INFO:root:[  284] Training loss: 15.18225168, Validation loss: 0.71439486, Gradient norm: 8137.57036676
INFO:root:At the start of the epoch: mem (CPU python)=14166.3515625MB; mem (CPU total)=15899.234375MB
INFO:root:[  285] Training loss: 0.83709005, Validation loss: 0.71460127, Gradient norm: 70.47751245
INFO:root:At the start of the epoch: mem (CPU python)=14187.515625MB; mem (CPU total)=15919.77734375MB
INFO:root:[  286] Training loss: 0.83679306, Validation loss: 0.71281432, Gradient norm: 93.35270483
INFO:root:At the start of the epoch: mem (CPU python)=14208.6796875MB; mem (CPU total)=15941.609375MB
INFO:root:[  287] Training loss: 0.83673198, Validation loss: 0.71301188, Gradient norm: 69.49336174
INFO:root:At the start of the epoch: mem (CPU python)=14229.83984375MB; mem (CPU total)=15966.0703125MB
INFO:root:[  288] Training loss: 0.83651458, Validation loss: 0.71385080, Gradient norm: 71.26806165
INFO:root:At the start of the epoch: mem (CPU python)=14251.00390625MB; mem (CPU total)=15993.48828125MB
INFO:root:[  289] Training loss: 0.83642790, Validation loss: 0.71414761, Gradient norm: 70.24617979
INFO:root:At the start of the epoch: mem (CPU python)=14272.171875MB; mem (CPU total)=15995.95703125MB
INFO:root:[  290] Training loss: 0.83633648, Validation loss: 0.71379389, Gradient norm: 70.78483059
INFO:root:At the start of the epoch: mem (CPU python)=14293.3359375MB; mem (CPU total)=16014.421875MB
INFO:root:[  291] Training loss: 0.83640499, Validation loss: 0.71531921, Gradient norm: 71.84580653
INFO:root:At the start of the epoch: mem (CPU python)=14314.5MB; mem (CPU total)=16051.12890625MB
INFO:root:[  292] Training loss: 0.83656080, Validation loss: 0.71421069, Gradient norm: 73.04641651
INFO:root:At the start of the epoch: mem (CPU python)=14335.6640625MB; mem (CPU total)=16071.93359375MB
INFO:root:[  293] Training loss: 0.83619773, Validation loss: 0.71405457, Gradient norm: 73.83888644
INFO:root:At the start of the epoch: mem (CPU python)=14356.82421875MB; mem (CPU total)=16082.03125MB
INFO:root:[  294] Training loss: 0.83619653, Validation loss: 0.71389182, Gradient norm: 73.36659161
INFO:root:At the start of the epoch: mem (CPU python)=14377.9921875MB; mem (CPU total)=16113.34375MB
INFO:root:[  295] Training loss: 0.83650130, Validation loss: 0.71399956, Gradient norm: 73.02050659
INFO:root:At the start of the epoch: mem (CPU python)=14399.15625MB; mem (CPU total)=16147.359375MB
INFO:root:[  296] Training loss: 0.83586588, Validation loss: 0.71253388, Gradient norm: 75.61207819
INFO:root:At the start of the epoch: mem (CPU python)=14420.3203125MB; mem (CPU total)=16144.89453125MB
INFO:root:[  297] Training loss: 0.83608091, Validation loss: 0.71765998, Gradient norm: 74.88325854
INFO:root:At the start of the epoch: mem (CPU python)=14441.484375MB; mem (CPU total)=16163.17578125MB
INFO:root:[  298] Training loss: 0.83540465, Validation loss: 0.71362660, Gradient norm: 70.53760033
INFO:root:At the start of the epoch: mem (CPU python)=14462.6484375MB; mem (CPU total)=16206.37109375MB
INFO:root:[  299] Training loss: 0.83613689, Validation loss: 0.71254381, Gradient norm: 77.66686381
INFO:root:At the start of the epoch: mem (CPU python)=14483.82421875MB; mem (CPU total)=16213.21484375MB
INFO:root:[  300] Training loss: 0.83546656, Validation loss: 0.71207189, Gradient norm: 76.51152663
INFO:root:At the start of the epoch: mem (CPU python)=14504.9921875MB; mem (CPU total)=16239.3125MB
INFO:root:[  301] Training loss: 0.83498433, Validation loss: 0.71298768, Gradient norm: 78.03761633
INFO:root:At the start of the epoch: mem (CPU python)=14526.15625MB; mem (CPU total)=16246.234375MB
INFO:root:[  302] Training loss: 0.83538059, Validation loss: 0.71286153, Gradient norm: 74.91375322
INFO:root:At the start of the epoch: mem (CPU python)=14547.3203125MB; mem (CPU total)=16261.40625MB
INFO:root:[  303] Training loss: 0.83524644, Validation loss: 0.71196309, Gradient norm: 76.65016368
INFO:root:At the start of the epoch: mem (CPU python)=14568.48046875MB; mem (CPU total)=16309.15625MB
INFO:root:[  304] Training loss: 0.83516289, Validation loss: 0.71116126, Gradient norm: 73.77967363
INFO:root:At the start of the epoch: mem (CPU python)=14589.64453125MB; mem (CPU total)=16326.73828125MB
INFO:root:[  305] Training loss: 0.83528774, Validation loss: 0.71449282, Gradient norm: 76.82157962
INFO:root:At the start of the epoch: mem (CPU python)=14610.8046875MB; mem (CPU total)=16347.4453125MB
INFO:root:[  306] Training loss: 0.83459750, Validation loss: 0.71245945, Gradient norm: 77.51701657
INFO:root:At the start of the epoch: mem (CPU python)=14631.96875MB; mem (CPU total)=16354.34765625MB
INFO:root:[  307] Training loss: 0.83466865, Validation loss: 0.71303997, Gradient norm: 77.22562899
INFO:root:At the start of the epoch: mem (CPU python)=14653.13671875MB; mem (CPU total)=16375.66796875MB
INFO:root:[  308] Training loss: 0.83475254, Validation loss: 0.71146313, Gradient norm: 77.08565524
INFO:root:At the start of the epoch: mem (CPU python)=14674.30078125MB; mem (CPU total)=16400.17578125MB
INFO:root:[  309] Training loss: 0.83423075, Validation loss: 0.71197487, Gradient norm: 75.25730043
INFO:root:At the start of the epoch: mem (CPU python)=14695.46484375MB; mem (CPU total)=16419.87109375MB
INFO:root:[  310] Training loss: 0.83471676, Validation loss: 0.71037576, Gradient norm: 76.91903027
INFO:root:At the start of the epoch: mem (CPU python)=14716.62890625MB; mem (CPU total)=16578.95703125MB
INFO:root:[  311] Training loss: 0.83492747, Validation loss: 0.71120193, Gradient norm: 101.10015812
INFO:root:At the start of the epoch: mem (CPU python)=14737.79296875MB; mem (CPU total)=16600.33203125MB
INFO:root:[  312] Training loss: 0.83429721, Validation loss: 0.71136943, Gradient norm: 74.99634172
INFO:root:At the start of the epoch: mem (CPU python)=14758.95703125MB; mem (CPU total)=16623.62109375MB
INFO:root:[  313] Training loss: 0.83377590, Validation loss: 0.71443487, Gradient norm: 74.72961939
INFO:root:At the start of the epoch: mem (CPU python)=14780.12109375MB; mem (CPU total)=16623.5390625MB
INFO:root:[  314] Training loss: 0.83519638, Validation loss: 14.35836561, Gradient norm: 116.91414432
INFO:root:At the start of the epoch: mem (CPU python)=14801.28515625MB; mem (CPU total)=16647.40234375MB
INFO:root:[  315] Training loss: 0.83424186, Validation loss: 0.71193179, Gradient norm: 80.07280698
INFO:root:At the start of the epoch: mem (CPU python)=14822.44921875MB; mem (CPU total)=16674.55078125MB
INFO:root:[  316] Training loss: 0.83344975, Validation loss: 0.71076677, Gradient norm: 76.67642738
INFO:root:At the start of the epoch: mem (CPU python)=14843.61328125MB; mem (CPU total)=16667.75MB
INFO:root:[  317] Training loss: 0.83360935, Validation loss: 0.71113463, Gradient norm: 81.97972918
INFO:root:At the start of the epoch: mem (CPU python)=14864.77734375MB; mem (CPU total)=16712.72265625MB
INFO:root:[  318] Training loss: 0.83352243, Validation loss: 0.71089143, Gradient norm: 78.95797306
INFO:root:At the start of the epoch: mem (CPU python)=14885.9453125MB; mem (CPU total)=16731.75MB
INFO:root:[  319] Training loss: 0.83358690, Validation loss: 0.70952769, Gradient norm: 81.07605550
INFO:root:At the start of the epoch: mem (CPU python)=14907.109375MB; mem (CPU total)=16763.59375MB
INFO:root:[  320] Training loss: 0.83338187, Validation loss: 0.71021867, Gradient norm: 80.21797660
INFO:root:At the start of the epoch: mem (CPU python)=14928.2734375MB; mem (CPU total)=16768.3828125MB
INFO:root:[  321] Training loss: 0.83327439, Validation loss: 0.81513406, Gradient norm: 81.04786752
INFO:root:At the start of the epoch: mem (CPU python)=14949.43359375MB; mem (CPU total)=16792.765625MB
INFO:root:[  322] Training loss: 0.83333127, Validation loss: 0.70921161, Gradient norm: 82.51444981
INFO:root:At the start of the epoch: mem (CPU python)=14970.59375MB; mem (CPU total)=16817.3125MB
INFO:root:[  323] Training loss: 0.83304575, Validation loss: 0.71040487, Gradient norm: 84.79804181
INFO:root:At the start of the epoch: mem (CPU python)=14991.76171875MB; mem (CPU total)=16825.171875MB
INFO:root:[  324] Training loss: 0.83326330, Validation loss: 0.71146432, Gradient norm: 81.98026252
INFO:root:At the start of the epoch: mem (CPU python)=15012.92578125MB; mem (CPU total)=16860.1640625MB
INFO:root:[  325] Training loss: 0.83330356, Validation loss: 0.71110074, Gradient norm: 98.18528529
INFO:root:At the start of the epoch: mem (CPU python)=15034.08984375MB; mem (CPU total)=16883.39453125MB
INFO:root:[  326] Training loss: 0.83294824, Validation loss: 167.98786635, Gradient norm: 80.57751845
INFO:root:At the start of the epoch: mem (CPU python)=15055.25390625MB; mem (CPU total)=16890.05859375MB
INFO:root:[  327] Training loss: 0.83290234, Validation loss: 0.71102669, Gradient norm: 83.51228747
INFO:root:At the start of the epoch: mem (CPU python)=15076.41796875MB; mem (CPU total)=16925.82421875MB
INFO:root:[  328] Training loss: 0.83294531, Validation loss: 0.71049751, Gradient norm: 85.98449618
INFO:root:At the start of the epoch: mem (CPU python)=15097.58203125MB; mem (CPU total)=16924.46875MB
INFO:root:[  329] Training loss: 0.83241111, Validation loss: 0.70923209, Gradient norm: 98.82559053
INFO:root:At the start of the epoch: mem (CPU python)=15118.75MB; mem (CPU total)=16952.69921875MB
INFO:root:[  330] Training loss: 0.83257328, Validation loss: 0.71026079, Gradient norm: 81.07308715
INFO:root:At the start of the epoch: mem (CPU python)=15139.9140625MB; mem (CPU total)=16989.82421875MB
INFO:root:[  331] Training loss: 0.83215034, Validation loss: 0.72327934, Gradient norm: 80.85999394
INFO:root:At the start of the epoch: mem (CPU python)=15161.07421875MB; mem (CPU total)=17004.78515625MB
INFO:root:EP 331: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=15182.23828125MB; mem (CPU total)=17032.515625MB
INFO:root:Training the model took 33536.822s.
INFO:root:Emptying the cuda cache took 0.105s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 24.91909
INFO:root:EnergyScoreValidation: 1.31294
INFO:root:CRPSValidation: 0.22083
INFO:root:Gaussian NLLValidation: 1.44293
INFO:root:CoverageValidation: 0.62669
INFO:root:IntervalWidthValidation: 14.01125
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.48826
INFO:root:EnergyScoreTest: 0.38296
INFO:root:CRPSTest: 0.15806
INFO:root:Gaussian NLLTest: 1.66656
INFO:root:CoverageTest: 0.57114
INFO:root:IntervalWidthTest: 0.36428
INFO:root:After validation: mem (CPU python)=15189.4609375MB; mem (CPU total)=17033.51171875MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=15189.4609375MB; mem (CPU total)=17032.4140625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 96468992
INFO:root:After setting up the model: mem (CPU python)=15189.4609375MB; mem (CPU total)=17032.47265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=15189.4609375MB; mem (CPU total)=17031.18359375MB
INFO:root:[    1] Training loss: 1.76037981, Validation loss: 1.68202173, Gradient norm: 0.14462833
INFO:root:At the start of the epoch: mem (CPU python)=15210.0234375MB; mem (CPU total)=17037.2734375MB
INFO:root:[    2] Training loss: 1.71737289, Validation loss: 1.61229350, Gradient norm: 0.13302166
INFO:root:At the start of the epoch: mem (CPU python)=15231.203125MB; mem (CPU total)=17057.48046875MB
INFO:root:[    3] Training loss: 1.68324580, Validation loss: 1.56377671, Gradient norm: 0.17084223
INFO:root:At the start of the epoch: mem (CPU python)=15252.375MB; mem (CPU total)=17064.37890625MB
INFO:root:[    4] Training loss: 1.65856165, Validation loss: 1.54818347, Gradient norm: 0.20098301
INFO:root:At the start of the epoch: mem (CPU python)=15273.54296875MB; mem (CPU total)=17099.5390625MB
INFO:root:[    5] Training loss: 1.65327904, Validation loss: 1.54914979, Gradient norm: 0.22745133
INFO:root:At the start of the epoch: mem (CPU python)=15294.70703125MB; mem (CPU total)=17110.234375MB
INFO:root:[    6] Training loss: 1.65108444, Validation loss: 1.54290957, Gradient norm: 0.26648398
INFO:root:At the start of the epoch: mem (CPU python)=15315.87109375MB; mem (CPU total)=17172.97265625MB
INFO:root:[    7] Training loss: 1.65018809, Validation loss: 1.54555717, Gradient norm: 0.32631486
INFO:root:At the start of the epoch: mem (CPU python)=15337.03515625MB; mem (CPU total)=17342.52734375MB
INFO:root:[    8] Training loss: 1.64954653, Validation loss: 1.53601490, Gradient norm: 0.40375691
INFO:root:At the start of the epoch: mem (CPU python)=15358.203125MB; mem (CPU total)=17486.37890625MB
INFO:root:[    9] Training loss: 1.64917047, Validation loss: 1.53921076, Gradient norm: 0.50459671
INFO:root:At the start of the epoch: mem (CPU python)=15379.3671875MB; mem (CPU total)=17673.02734375MB
INFO:root:[   10] Training loss: 1.64949629, Validation loss: 1.53415332, Gradient norm: 0.60539194
INFO:root:At the start of the epoch: mem (CPU python)=15400.53125MB; mem (CPU total)=17939.640625MB
INFO:root:[   11] Training loss: 1.64925171, Validation loss: 1.53426595, Gradient norm: 0.69157669
INFO:root:At the start of the epoch: mem (CPU python)=15421.69140625MB; mem (CPU total)=17956.1328125MB
INFO:root:[   12] Training loss: 1.64937325, Validation loss: 1.54032160, Gradient norm: 0.78338910
INFO:root:At the start of the epoch: mem (CPU python)=15442.8515625MB; mem (CPU total)=18087.8046875MB
INFO:root:[   13] Training loss: 1.64893616, Validation loss: 1.55285215, Gradient norm: 0.85202627
INFO:root:At the start of the epoch: mem (CPU python)=15464.01953125MB; mem (CPU total)=18102.109375MB
INFO:root:[   14] Training loss: 1.64898640, Validation loss: 1.54450060, Gradient norm: 0.92462943
INFO:root:At the start of the epoch: mem (CPU python)=15485.18359375MB; mem (CPU total)=18152.94140625MB
INFO:root:[   15] Training loss: 1.64918339, Validation loss: 1.53401247, Gradient norm: 0.93018903
INFO:root:At the start of the epoch: mem (CPU python)=15506.34765625MB; mem (CPU total)=18156.9375MB
INFO:root:[   16] Training loss: 1.64853069, Validation loss: 1.54347010, Gradient norm: 0.97470594
INFO:root:At the start of the epoch: mem (CPU python)=15527.51171875MB; mem (CPU total)=18157.5703125MB
INFO:root:[   17] Training loss: 1.64822705, Validation loss: 1.54175312, Gradient norm: 1.00630809
INFO:root:At the start of the epoch: mem (CPU python)=15548.6796875MB; mem (CPU total)=18183.62890625MB
INFO:root:[   18] Training loss: 1.64802625, Validation loss: 1.52859662, Gradient norm: 0.99313207
INFO:root:At the start of the epoch: mem (CPU python)=15569.84375MB; mem (CPU total)=18231.8671875MB
INFO:root:[   19] Training loss: 1.64735499, Validation loss: 1.53080348, Gradient norm: 1.02129360
INFO:root:At the start of the epoch: mem (CPU python)=15591.0078125MB; mem (CPU total)=18251.8359375MB
INFO:root:[   20] Training loss: 1.64745521, Validation loss: 1.53940913, Gradient norm: 1.10619491
INFO:root:At the start of the epoch: mem (CPU python)=15612.171875MB; mem (CPU total)=18274.23046875MB
INFO:root:[   21] Training loss: 1.64719333, Validation loss: 1.53687148, Gradient norm: 1.12398008
INFO:root:At the start of the epoch: mem (CPU python)=15633.3359375MB; mem (CPU total)=18281.88671875MB
INFO:root:[   22] Training loss: 1.64635561, Validation loss: 1.52803607, Gradient norm: 1.08039470
INFO:root:At the start of the epoch: mem (CPU python)=15654.49609375MB; mem (CPU total)=18319.55859375MB
INFO:root:[   23] Training loss: 1.64631216, Validation loss: 1.52773769, Gradient norm: 1.13265627
INFO:root:At the start of the epoch: mem (CPU python)=15675.6640625MB; mem (CPU total)=18323.5390625MB
INFO:root:[   24] Training loss: 1.64622193, Validation loss: 1.52926537, Gradient norm: 1.13394681
INFO:root:At the start of the epoch: mem (CPU python)=15696.828125MB; mem (CPU total)=18359.8828125MB
INFO:root:[   25] Training loss: 1.64633161, Validation loss: 1.52584604, Gradient norm: 1.23348834
INFO:root:At the start of the epoch: mem (CPU python)=15717.9921875MB; mem (CPU total)=18381.9453125MB
INFO:root:[   26] Training loss: 1.64566601, Validation loss: 1.52904735, Gradient norm: 1.16543982
INFO:root:At the start of the epoch: mem (CPU python)=15739.15625MB; mem (CPU total)=18370.10546875MB
INFO:root:[   27] Training loss: 1.64576978, Validation loss: 1.53137777, Gradient norm: 1.22410213
INFO:root:At the start of the epoch: mem (CPU python)=15760.3203125MB; mem (CPU total)=18424.1328125MB
INFO:root:[   28] Training loss: 1.64637341, Validation loss: 1.53336782, Gradient norm: 1.28511133
INFO:root:At the start of the epoch: mem (CPU python)=15781.48046875MB; mem (CPU total)=18414.90234375MB
INFO:root:[   29] Training loss: 1.64521922, Validation loss: 1.52253764, Gradient norm: 1.18940341
INFO:root:At the start of the epoch: mem (CPU python)=15802.65234375MB; mem (CPU total)=18464.7890625MB
INFO:root:[   30] Training loss: 1.64467932, Validation loss: 1.53718437, Gradient norm: 1.24219548
INFO:root:At the start of the epoch: mem (CPU python)=15823.8125MB; mem (CPU total)=18491.21875MB
INFO:root:[   31] Training loss: 1.64553168, Validation loss: 1.51989967, Gradient norm: 1.34402525
INFO:root:At the start of the epoch: mem (CPU python)=15844.97265625MB; mem (CPU total)=18508.4375MB
INFO:root:[   32] Training loss: 1.64554557, Validation loss: 1.52579167, Gradient norm: 1.31015649
INFO:root:At the start of the epoch: mem (CPU python)=15866.13671875MB; mem (CPU total)=18523.015625MB
INFO:root:[   33] Training loss: 1.64484263, Validation loss: 1.52882922, Gradient norm: 1.30719960
INFO:root:At the start of the epoch: mem (CPU python)=15887.30078125MB; mem (CPU total)=18549.875MB
INFO:root:[   34] Training loss: 1.64500828, Validation loss: 1.53048372, Gradient norm: 1.37546725
INFO:root:At the start of the epoch: mem (CPU python)=15908.46875MB; mem (CPU total)=18570.21484375MB
INFO:root:[   35] Training loss: 1.64407249, Validation loss: 1.53314450, Gradient norm: 1.31402994
INFO:root:At the start of the epoch: mem (CPU python)=15929.6328125MB; mem (CPU total)=18611.30859375MB
INFO:root:[   36] Training loss: 1.64435944, Validation loss: 1.53316747, Gradient norm: 1.35682169
INFO:root:At the start of the epoch: mem (CPU python)=15950.796875MB; mem (CPU total)=18600.1953125MB
INFO:root:[   37] Training loss: 1.64437152, Validation loss: 1.51954129, Gradient norm: 1.40574071
INFO:root:At the start of the epoch: mem (CPU python)=15971.9609375MB; mem (CPU total)=18653.8671875MB
INFO:root:[   38] Training loss: 1.64430723, Validation loss: 1.52603723, Gradient norm: 1.43101571
INFO:root:At the start of the epoch: mem (CPU python)=15993.125MB; mem (CPU total)=18641.2578125MB
INFO:root:[   39] Training loss: 1.64361580, Validation loss: 1.52478852, Gradient norm: 1.39304938
INFO:root:At the start of the epoch: mem (CPU python)=16014.2890625MB; mem (CPU total)=18681.38671875MB
INFO:root:[   40] Training loss: 1.64405997, Validation loss: 1.52649222, Gradient norm: 1.42190735
INFO:root:At the start of the epoch: mem (CPU python)=16035.45703125MB; mem (CPU total)=18701.875MB
INFO:root:[   41] Training loss: 1.64296873, Validation loss: 1.52841595, Gradient norm: 1.41891908
INFO:root:At the start of the epoch: mem (CPU python)=16056.6171875MB; mem (CPU total)=18722.88671875MB
INFO:root:[   42] Training loss: 1.64348793, Validation loss: 1.53042628, Gradient norm: 1.46288501
INFO:root:At the start of the epoch: mem (CPU python)=16077.78125MB; mem (CPU total)=18729.35546875MB
INFO:root:[   43] Training loss: 1.64355709, Validation loss: 1.52203573, Gradient norm: 1.48884354
INFO:root:At the start of the epoch: mem (CPU python)=16098.9453125MB; mem (CPU total)=18744.390625MB
INFO:root:[   44] Training loss: 1.64279955, Validation loss: 1.53122465, Gradient norm: 1.42347387
INFO:root:At the start of the epoch: mem (CPU python)=16120.109375MB; mem (CPU total)=18784.65625MB
INFO:root:[   45] Training loss: 1.64276382, Validation loss: 1.52523211, Gradient norm: 1.46721991
INFO:root:At the start of the epoch: mem (CPU python)=16141.27734375MB; mem (CPU total)=18810.6171875MB
INFO:root:[   46] Training loss: 1.64309594, Validation loss: 1.52600623, Gradient norm: 1.56156379
INFO:root:At the start of the epoch: mem (CPU python)=16162.44140625MB; mem (CPU total)=18801.2421875MB
INFO:root:[   47] Training loss: 1.64282093, Validation loss: 1.52119512, Gradient norm: 1.51895965
INFO:root:At the start of the epoch: mem (CPU python)=16183.60546875MB; mem (CPU total)=18832.7890625MB
INFO:root:[   48] Training loss: 1.64200812, Validation loss: 1.52231616, Gradient norm: 1.50421464
INFO:root:At the start of the epoch: mem (CPU python)=16204.76953125MB; mem (CPU total)=18870.1484375MB
INFO:root:[   49] Training loss: 1.64225733, Validation loss: 1.52664664, Gradient norm: 1.52425477
INFO:root:At the start of the epoch: mem (CPU python)=16225.93359375MB; mem (CPU total)=18877.72265625MB
INFO:root:[   50] Training loss: 1.64227176, Validation loss: 1.52795297, Gradient norm: 1.50650224
INFO:root:At the start of the epoch: mem (CPU python)=16247.09765625MB; mem (CPU total)=18898.48046875MB
INFO:root:[   51] Training loss: 2.19774186, Validation loss: 2.27717292, Gradient norm: 3.80344781
INFO:root:At the start of the epoch: mem (CPU python)=16268.26171875MB; mem (CPU total)=18951.65625MB
INFO:root:[   52] Training loss: 2.30691425, Validation loss: 2.27706144, Gradient norm: 5.87079943
INFO:root:At the start of the epoch: mem (CPU python)=16289.42578125MB; mem (CPU total)=18943.96484375MB
INFO:root:[   53] Training loss: 2.28398755, Validation loss: 2.27719348, Gradient norm: 1.20548762
INFO:root:At the start of the epoch: mem (CPU python)=16310.58984375MB; mem (CPU total)=18966.3359375MB
INFO:root:[   54] Training loss: 2.27755759, Validation loss: 2.27719713, Gradient norm: 0.00442442
INFO:root:At the start of the epoch: mem (CPU python)=16331.75390625MB; mem (CPU total)=18993.671875MB
INFO:root:[   55] Training loss: 2.27755838, Validation loss: 2.27719340, Gradient norm: 0.00453661
INFO:root:At the start of the epoch: mem (CPU python)=16352.91796875MB; mem (CPU total)=19007.109375MB
INFO:root:[   56] Training loss: 2.27755918, Validation loss: 2.27720017, Gradient norm: 0.00452370
INFO:root:At the start of the epoch: mem (CPU python)=16374.0859375MB; mem (CPU total)=19043.3515625MB
INFO:root:[   57] Training loss: 2.27755904, Validation loss: 2.27719706, Gradient norm: 0.00443805
INFO:root:At the start of the epoch: mem (CPU python)=16395.25MB; mem (CPU total)=19028.8984375MB
INFO:root:[   58] Training loss: 2.27755969, Validation loss: 2.27719212, Gradient norm: 0.00468444
INFO:root:At the start of the epoch: mem (CPU python)=16416.4140625MB; mem (CPU total)=19085.31640625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   59] Training loss: 2.27756201, Validation loss: 2.27719445, Gradient norm: 0.00479475
INFO:root:At the start of the epoch: mem (CPU python)=16437.578125MB; mem (CPU total)=19089.59375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   60] Training loss: 2.27755770, Validation loss: 2.27719323, Gradient norm: 0.00429531
INFO:root:At the start of the epoch: mem (CPU python)=16458.73828125MB; mem (CPU total)=19132.51171875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   61] Training loss: 2.27755677, Validation loss: 2.27719385, Gradient norm: 0.00441629
INFO:root:At the start of the epoch: mem (CPU python)=16479.90234375MB; mem (CPU total)=19136.90625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:EP 61: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [0.00015625]
INFO:root:At the start of the epoch: mem (CPU python)=16501.06640625MB; mem (CPU total)=19173.3203125MB
INFO:root:[   63] Training loss: 2.27713271, Validation loss: 2.27675131, Gradient norm: 0.00852007
INFO:root:At the start of the epoch: mem (CPU python)=16522.234375MB; mem (CPU total)=19191.921875MB
INFO:root:[   64] Training loss: 2.27713228, Validation loss: 2.27675198, Gradient norm: 0.00837167
INFO:root:At the start of the epoch: mem (CPU python)=16543.39453125MB; mem (CPU total)=19204.98046875MB
INFO:root:[   65] Training loss: 2.27713273, Validation loss: 2.27675071, Gradient norm: 0.00857324
INFO:root:At the start of the epoch: mem (CPU python)=16564.55859375MB; mem (CPU total)=19222.79296875MB
INFO:root:[   66] Training loss: 2.27713254, Validation loss: 2.27675089, Gradient norm: 0.00838478
INFO:root:At the start of the epoch: mem (CPU python)=16585.72265625MB; mem (CPU total)=19245.69921875MB
INFO:root:[   67] Training loss: 2.27713236, Validation loss: 2.27675248, Gradient norm: 0.00835873
INFO:root:At the start of the epoch: mem (CPU python)=16606.88671875MB; mem (CPU total)=19263.609375MB
INFO:root:[   68] Training loss: 2.27713265, Validation loss: 2.27675094, Gradient norm: 0.00828343
INFO:root:At the start of the epoch: mem (CPU python)=16628.0546875MB; mem (CPU total)=19285.84765625MB
INFO:root:[   69] Training loss: 2.27713262, Validation loss: 2.27675163, Gradient norm: 0.00845310
INFO:root:At the start of the epoch: mem (CPU python)=16649.21484375MB; mem (CPU total)=19326.71484375MB
INFO:root:[   70] Training loss: 2.27713253, Validation loss: 2.27675140, Gradient norm: 0.00846624
INFO:root:At the start of the epoch: mem (CPU python)=16670.37890625MB; mem (CPU total)=19350.8515625MB
INFO:root:[   71] Training loss: 2.27713252, Validation loss: 2.27675110, Gradient norm: 0.00853426
INFO:root:At the start of the epoch: mem (CPU python)=16691.54296875MB; mem (CPU total)=19362.48046875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   72] Training loss: 2.27713247, Validation loss: 2.27675154, Gradient norm: 0.00814405
INFO:root:At the start of the epoch: mem (CPU python)=16712.70703125MB; mem (CPU total)=19391.0390625MB
INFO:root:[   73] Training loss: 2.27713225, Validation loss: 2.27675116, Gradient norm: 0.00851718
INFO:root:At the start of the epoch: mem (CPU python)=16733.87109375MB; mem (CPU total)=19413.90625MB
INFO:root:[   74] Training loss: 2.27713200, Validation loss: 2.27675084, Gradient norm: 0.00844550
INFO:root:At the start of the epoch: mem (CPU python)=16755.0390625MB; mem (CPU total)=19408.38671875MB
INFO:root:EP 74: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16776.203125MB; mem (CPU total)=19455.99609375MB
INFO:root:Training the model took 5741.038s.
INFO:root:Emptying the cuda cache took 0.109s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 1.58252
INFO:root:EnergyScoreValidation: 1.58252
INFO:root:CRPSValidation: 0.72548
INFO:root:Gaussian NLLValidation: 417759028859.5136
INFO:root:CoverageValidation: 0.0
INFO:root:IntervalWidthValidation: 0.0
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 1.64808
INFO:root:EnergyScoreTest: 1.64776
INFO:root:CRPSTest: 0.75424
INFO:root:Gaussian NLLTest: 453007662120.95984
INFO:root:CoverageTest: 0.0
INFO:root:IntervalWidthTest: 0.0
INFO:root:After validation: mem (CPU python)=16783.0703125MB; mem (CPU total)=19452.15234375MB
