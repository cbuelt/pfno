INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:############### Starting experiment with config file debug.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SWE', 'max_training_set_size': 10000, 'downscaling_factor': 2, 'temporal_downscaling': 2, 'init_steps': 10, 't_start': 0, 'pred_horizon': 10}
INFO:root:###1 out of 1 training parameter combinations ###
INFO:root:Training parameters: {'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 10, 'early_stopping': 10, 'dropout': 0.1, 'init': 'default', 'learning_rate': 0.0001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'fourier_dropout': 0.0, 'hidden_channels': 32, 'projection_channels': 64, 'alpha': 0.05, 'n_samples_uq': 10, 'weight_decay': 0, 'n_samples': 3, 'lifting_channels': 128, 'n_modes': (2, 2, 2), 'uno_out_channels': [32, 64, 64, 32], 'uno_scalings': [[1.0, 1.0], [0.5, 0.5], [1, 1], [2, 2]], 'uno_n_modes': [[16, 16], [8, 8], [8, 8], [16, 16]]}
INFO:root:NumberParameters: 76705
INFO:root:Memory allocated: 2097152
INFO:root:Training starts now.
INFO:root:[    1] Training loss: 2.35438457, Validation loss: 2.20022039, Gradient norm: 2.72564268
INFO:root:[    2] Training loss: 1.96189057, Validation loss: 1.57809387, Gradient norm: 3.20790165
INFO:root:[    3] Training loss: 0.76326489, Validation loss: 0.17350048, Gradient norm: 5.40390388
INFO:root:[    4] Training loss: 0.13900128, Validation loss: 0.13004914, Gradient norm: 1.47459300
INFO:root:[    5] Training loss: 0.12662188, Validation loss: 0.12427314, Gradient norm: 0.35514375
INFO:root:[    6] Training loss: 0.12208307, Validation loss: 0.12135952, Gradient norm: 0.26778582
INFO:root:[    7] Training loss: 0.11934856, Validation loss: 0.11828884, Gradient norm: 0.47070116
INFO:root:[    8] Training loss: 0.11639953, Validation loss: 0.11686242, Gradient norm: 0.27147646
INFO:root:[    9] Training loss: 0.11424720, Validation loss: 0.11412726, Gradient norm: 0.24687972
INFO:root:[   10] Training loss: 0.11219475, Validation loss: 0.11141347, Gradient norm: 0.24173155
INFO:root:Training the model took 208.674s.
INFO:root:Emptying the cuda cache took 0.077s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
