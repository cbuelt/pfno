INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=550.80078125MB; mem (CPU total)=2638.4140625MB
INFO:root:############### Starting experiment with config file sswe/sfno_deterministic_2_1.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=562.04296875MB; mem (CPU total)=2642.77734375MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'SFNO', 'uncertainty_quantification': 'deterministic', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=563.296875MB; mem (CPU total)=2642.77734375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=811.1484375MB; mem (CPU total)=2873.44921875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=821.81640625MB; mem (CPU total)=2882.80078125MB
INFO:root:[    1] Training loss: 0.83109781, Validation loss: 0.73600879, Gradient norm: 0.57111445
INFO:root:At the start of the epoch: mem (CPU python)=1248.1875MB; mem (CPU total)=3174.04296875MB
INFO:root:[    2] Training loss: 0.73498742, Validation loss: 0.73344632, Gradient norm: 0.33862286
INFO:root:At the start of the epoch: mem (CPU python)=1272.3671875MB; mem (CPU total)=3200.2109375MB
INFO:root:[    3] Training loss: 0.72806579, Validation loss: 0.71577760, Gradient norm: 0.30216429
INFO:root:At the start of the epoch: mem (CPU python)=1293.765625MB; mem (CPU total)=3222.31640625MB
INFO:root:[    4] Training loss: 0.69866817, Validation loss: 0.66290771, Gradient norm: 0.46106944
INFO:root:At the start of the epoch: mem (CPU python)=1315.6796875MB; mem (CPU total)=3247.84375MB
INFO:root:[    5] Training loss: 0.64065188, Validation loss: 0.60652769, Gradient norm: 0.58653747
INFO:root:At the start of the epoch: mem (CPU python)=1336.8203125MB; mem (CPU total)=3268.69921875MB
INFO:root:[    6] Training loss: 0.59660449, Validation loss: 0.58869753, Gradient norm: 0.65670926
INFO:root:At the start of the epoch: mem (CPU python)=1357.9609375MB; mem (CPU total)=3287.8828125MB
INFO:root:[    7] Training loss: 0.57612761, Validation loss: 0.56613989, Gradient norm: 0.65606960
INFO:root:At the start of the epoch: mem (CPU python)=1379.1015625MB; mem (CPU total)=3307.30078125MB
INFO:root:[    8] Training loss: 0.56690577, Validation loss: 0.55905720, Gradient norm: 0.81183289
INFO:root:At the start of the epoch: mem (CPU python)=1400.2421875MB; mem (CPU total)=3328.421875MB
INFO:root:[    9] Training loss: 0.54674310, Validation loss: 0.52872827, Gradient norm: 0.74404422
INFO:root:At the start of the epoch: mem (CPU python)=1421.3828125MB; mem (CPU total)=3345.20703125MB
INFO:root:[   10] Training loss: 0.53061021, Validation loss: 0.52059826, Gradient norm: 0.90838350
INFO:root:At the start of the epoch: mem (CPU python)=1442.5234375MB; mem (CPU total)=3367.41015625MB
INFO:root:[   11] Training loss: 0.52731886, Validation loss: 0.50973817, Gradient norm: 1.19559143
INFO:root:At the start of the epoch: mem (CPU python)=1463.921875MB; mem (CPU total)=3389.21875MB
INFO:root:[   12] Training loss: 0.50989089, Validation loss: 0.50121238, Gradient norm: 1.01146107
INFO:root:At the start of the epoch: mem (CPU python)=1485.0625MB; mem (CPU total)=3410.86328125MB
INFO:root:[   13] Training loss: 0.50634775, Validation loss: 0.50523710, Gradient norm: 1.28770704
INFO:root:At the start of the epoch: mem (CPU python)=1506.203125MB; mem (CPU total)=3431.52734375MB
INFO:root:[   14] Training loss: 0.50143335, Validation loss: 0.49245347, Gradient norm: 1.39049478
INFO:root:At the start of the epoch: mem (CPU python)=1527.34375MB; mem (CPU total)=3450.7734375MB
INFO:root:[   15] Training loss: 0.49353456, Validation loss: 0.48186974, Gradient norm: 1.29456979
INFO:root:At the start of the epoch: mem (CPU python)=1548.484375MB; mem (CPU total)=3469.546875MB
INFO:root:[   16] Training loss: 0.48809970, Validation loss: 0.47784555, Gradient norm: 1.30898438
INFO:root:At the start of the epoch: mem (CPU python)=1569.625MB; mem (CPU total)=3491.8671875MB
INFO:root:[   17] Training loss: 0.48297397, Validation loss: 0.47934013, Gradient norm: 1.28210647
INFO:root:At the start of the epoch: mem (CPU python)=1590.765625MB; mem (CPU total)=3513.7578125MB
INFO:root:[   18] Training loss: 0.47983348, Validation loss: 0.47963673, Gradient norm: 1.35749301
INFO:root:At the start of the epoch: mem (CPU python)=1611.90625MB; mem (CPU total)=3534.18359375MB
INFO:root:[   19] Training loss: 0.47535439, Validation loss: 0.46717265, Gradient norm: 1.41992847
INFO:root:At the start of the epoch: mem (CPU python)=1633.046875MB; mem (CPU total)=3553.41796875MB
INFO:root:[   20] Training loss: 0.47166227, Validation loss: 0.46720012, Gradient norm: 1.50405867
INFO:root:At the start of the epoch: mem (CPU python)=1654.1875MB; mem (CPU total)=3575.0MB
INFO:root:[   21] Training loss: 0.47317447, Validation loss: 0.46823964, Gradient norm: 1.73506530
INFO:root:At the start of the epoch: mem (CPU python)=1675.5859375MB; mem (CPU total)=3596.40625MB
INFO:root:[   22] Training loss: 0.47282877, Validation loss: 0.46823538, Gradient norm: 1.86150501
INFO:root:At the start of the epoch: mem (CPU python)=1696.7265625MB; mem (CPU total)=3616.83203125MB
INFO:root:[   23] Training loss: 0.46430579, Validation loss: 0.45961258, Gradient norm: 1.72367063
INFO:root:At the start of the epoch: mem (CPU python)=1717.8671875MB; mem (CPU total)=3638.41015625MB
INFO:root:[   24] Training loss: 0.46155391, Validation loss: 0.46727713, Gradient norm: 1.84285656
INFO:root:At the start of the epoch: mem (CPU python)=1739.0078125MB; mem (CPU total)=3659.4765625MB
INFO:root:[   25] Training loss: 0.45862038, Validation loss: 0.44347886, Gradient norm: 2.11451844
INFO:root:At the start of the epoch: mem (CPU python)=1760.1484375MB; mem (CPU total)=3684.44140625MB
INFO:root:[   26] Training loss: 0.45310238, Validation loss: 0.44397903, Gradient norm: 1.90360234
INFO:root:At the start of the epoch: mem (CPU python)=1781.2890625MB; mem (CPU total)=3706.5625MB
INFO:root:[   27] Training loss: 0.45235909, Validation loss: 0.44579957, Gradient norm: 2.31765457
INFO:root:At the start of the epoch: mem (CPU python)=1802.4296875MB; mem (CPU total)=3728.4609375MB
INFO:root:[   28] Training loss: 0.44353219, Validation loss: 0.43467781, Gradient norm: 2.35817805
INFO:root:At the start of the epoch: mem (CPU python)=1823.5703125MB; mem (CPU total)=3748.28515625MB
INFO:root:[   29] Training loss: 0.43891075, Validation loss: 0.43116468, Gradient norm: 2.12670433
INFO:root:At the start of the epoch: mem (CPU python)=1844.7109375MB; mem (CPU total)=3768.2734375MB
INFO:root:[   30] Training loss: 0.43480174, Validation loss: 0.41991268, Gradient norm: 2.43262049
INFO:root:At the start of the epoch: mem (CPU python)=1865.8515625MB; mem (CPU total)=3790.05859375MB
INFO:root:[   31] Training loss: 0.43161127, Validation loss: 0.42151087, Gradient norm: 2.32198445
INFO:root:At the start of the epoch: mem (CPU python)=1886.9921875MB; mem (CPU total)=3810.9765625MB
INFO:root:[   32] Training loss: 0.43446299, Validation loss: 0.42573289, Gradient norm: 2.83289859
INFO:root:At the start of the epoch: mem (CPU python)=1908.390625MB; mem (CPU total)=3830.41796875MB
INFO:root:[   33] Training loss: 0.42775478, Validation loss: 0.41664048, Gradient norm: 2.31992019
INFO:root:At the start of the epoch: mem (CPU python)=1929.53125MB; mem (CPU total)=3851.76171875MB
INFO:root:[   34] Training loss: 0.42500132, Validation loss: 0.41809085, Gradient norm: 2.42022936
INFO:root:At the start of the epoch: mem (CPU python)=1950.671875MB; mem (CPU total)=3873.32421875MB
INFO:root:[   35] Training loss: 0.42390949, Validation loss: 0.40641982, Gradient norm: 2.86335114
INFO:root:At the start of the epoch: mem (CPU python)=1971.8125MB; mem (CPU total)=3893.6484375MB
INFO:root:[   36] Training loss: 0.42163853, Validation loss: 0.40527232, Gradient norm: 2.57587694
INFO:root:At the start of the epoch: mem (CPU python)=1992.953125MB; mem (CPU total)=3915.31640625MB
INFO:root:[   37] Training loss: 0.42169022, Validation loss: 0.41561768, Gradient norm: 2.56150885
INFO:root:At the start of the epoch: mem (CPU python)=2014.09375MB; mem (CPU total)=3935.98828125MB
INFO:root:[   38] Training loss: 0.42223261, Validation loss: 0.41146059, Gradient norm: 2.80888834
INFO:root:At the start of the epoch: mem (CPU python)=2035.234375MB; mem (CPU total)=3956.66015625MB
INFO:root:[   39] Training loss: 0.42400503, Validation loss: 0.41080547, Gradient norm: 2.88567950
INFO:root:At the start of the epoch: mem (CPU python)=2056.375MB; mem (CPU total)=3977.5703125MB
INFO:root:[   40] Training loss: 0.42180540, Validation loss: 0.42886378, Gradient norm: 2.82786279
INFO:root:At the start of the epoch: mem (CPU python)=2077.515625MB; mem (CPU total)=3997.99609375MB
INFO:root:[   41] Training loss: 0.42073808, Validation loss: 0.41516613, Gradient norm: 2.72496589
INFO:root:At the start of the epoch: mem (CPU python)=2098.65625MB; mem (CPU total)=4019.1484375MB
INFO:root:[   42] Training loss: 0.41655439, Validation loss: 0.41818247, Gradient norm: 2.92970449
INFO:root:At the start of the epoch: mem (CPU python)=2119.796875MB; mem (CPU total)=4040.55859375MB
INFO:root:[   43] Training loss: 0.41819287, Validation loss: 0.42264454, Gradient norm: 2.84164446
INFO:root:At the start of the epoch: mem (CPU python)=2141.1953125MB; mem (CPU total)=4062.65234375MB
INFO:root:[   44] Training loss: 0.41458584, Validation loss: 0.40148093, Gradient norm: 2.93327957
INFO:root:At the start of the epoch: mem (CPU python)=2162.3359375MB; mem (CPU total)=4084.5390625MB
INFO:root:[   45] Training loss: 0.41836072, Validation loss: 0.41424735, Gradient norm: 2.82541206
INFO:root:At the start of the epoch: mem (CPU python)=2183.4765625MB; mem (CPU total)=4105.03515625MB
INFO:root:[   46] Training loss: 0.41045781, Validation loss: 0.40188353, Gradient norm: 3.14828881
INFO:root:At the start of the epoch: mem (CPU python)=2204.6171875MB; mem (CPU total)=4125.45703125MB
INFO:root:[   47] Training loss: 0.40866624, Validation loss: 0.40089269, Gradient norm: 2.80838335
INFO:root:At the start of the epoch: mem (CPU python)=2225.7578125MB; mem (CPU total)=4146.07421875MB
INFO:root:[   48] Training loss: 0.41371245, Validation loss: 0.41256506, Gradient norm: 3.11167285
INFO:root:At the start of the epoch: mem (CPU python)=2246.8984375MB; mem (CPU total)=4167.91796875MB
INFO:root:[   49] Training loss: 0.41291729, Validation loss: 0.41207831, Gradient norm: 3.57011442
INFO:root:At the start of the epoch: mem (CPU python)=2268.0390625MB; mem (CPU total)=4189.32421875MB
INFO:root:[   50] Training loss: 0.41262060, Validation loss: 0.40421151, Gradient norm: 3.28943398
INFO:root:At the start of the epoch: mem (CPU python)=2289.1796875MB; mem (CPU total)=4209.99609375MB
INFO:root:[   51] Training loss: 0.41346251, Validation loss: 0.41690943, Gradient norm: 3.20425450
INFO:root:At the start of the epoch: mem (CPU python)=2310.3203125MB; mem (CPU total)=4231.65234375MB
INFO:root:[   52] Training loss: 0.41085088, Validation loss: 0.41363634, Gradient norm: 3.60101563
INFO:root:At the start of the epoch: mem (CPU python)=2331.4609375MB; mem (CPU total)=4252.5703125MB
INFO:root:[   53] Training loss: 0.40903156, Validation loss: 0.42544156, Gradient norm: 3.60525997
INFO:root:At the start of the epoch: mem (CPU python)=2352.6015625MB; mem (CPU total)=4279.14453125MB
