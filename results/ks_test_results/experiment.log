INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:############### Starting experiment with config file ks/fno.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:###1 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 20, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:NumberParameters: 231589
INFO:root:Memory allocated: 2097152
INFO:root:Training starts now.
INFO:root:[    1] Training loss: 0.75763205, Validation loss: 0.70739008, Gradient norm: 4.18268661
INFO:root:[    2] Training loss: 0.71257858, Validation loss: 0.70357210, Gradient norm: 4.22378581
INFO:root:[    3] Training loss: 0.70798245, Validation loss: 0.70556976, Gradient norm: 3.48234281
INFO:root:[    4] Training loss: 0.70580033, Validation loss: 0.70497050, Gradient norm: 3.17804128
INFO:root:[    5] Training loss: 0.70594505, Validation loss: 0.70402558, Gradient norm: 3.49968894
INFO:root:[    6] Training loss: 0.70370260, Validation loss: 0.70332924, Gradient norm: 2.74243990
INFO:root:[    7] Training loss: 0.70385882, Validation loss: 0.69924690, Gradient norm: 3.28837736
INFO:root:[    8] Training loss: 0.70112668, Validation loss: 0.69545453, Gradient norm: 3.18150666
INFO:root:[    9] Training loss: 0.69373092, Validation loss: 0.69448310, Gradient norm: 2.56595207
INFO:root:[   10] Training loss: 0.68771563, Validation loss: 0.68242903, Gradient norm: 2.43334011
INFO:root:[   11] Training loss: 0.68224936, Validation loss: 0.67814286, Gradient norm: 2.42670960
INFO:root:[   12] Training loss: 0.67766217, Validation loss: 0.67476854, Gradient norm: 2.51104933
INFO:root:[   13] Training loss: 0.67240044, Validation loss: 0.67469994, Gradient norm: 2.10816561
INFO:root:[   14] Training loss: 0.66924100, Validation loss: 0.66625564, Gradient norm: 2.46620182
INFO:root:[   15] Training loss: 0.66534299, Validation loss: 0.66679534, Gradient norm: 2.18663786
INFO:root:[   16] Training loss: 0.66297575, Validation loss: 0.66184035, Gradient norm: 2.32863610
INFO:root:[   17] Training loss: 0.65988146, Validation loss: 0.66351881, Gradient norm: 2.24033845
INFO:root:[   18] Training loss: 0.65744539, Validation loss: 0.66288043, Gradient norm: 2.09384047
INFO:root:[   19] Training loss: 0.65551032, Validation loss: 0.66136670, Gradient norm: 2.10748804
INFO:root:[   20] Training loss: 0.65363012, Validation loss: 0.65648044, Gradient norm: 2.07587036
INFO:root:Training the model took 663.406s.
INFO:root:Emptying the cuda cache took 0.048s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.9261
INFO:root:EnergyScoreTrain: 0.65225
INFO:root:CoverageTrain: 0.90366
INFO:root:IntervalWidthTrain: 9.56481
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93153
INFO:root:EnergyScoreValidation: 0.65617
INFO:root:CoverageValidation: 0.90122
INFO:root:IntervalWidthValidation: 9.55175
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.92986
INFO:root:EnergyScoreTest: 0.65497
INFO:root:CoverageTest: 0.90241
INFO:root:IntervalWidthTest: 9.5778
INFO:root:###2 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 20, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:NumberParameters: 234406
INFO:root:Memory allocated: 163577856
INFO:root:Training starts now.
INFO:root:[    1] Training loss: 0.71640122, Validation loss: 0.70081749, Gradient norm: 0.07416151
INFO:root:[    2] Training loss: 0.70080593, Validation loss: 0.69969924, Gradient norm: 0.01661682
INFO:root:[    3] Training loss: 0.69739170, Validation loss: 0.69359930, Gradient norm: 0.02488484
INFO:root:[    4] Training loss: 0.68934558, Validation loss: 0.68126015, Gradient norm: 0.03414165
INFO:root:[    5] Training loss: 0.68099269, Validation loss: 0.67302729, Gradient norm: 0.04081266
INFO:root:[    6] Training loss: 0.67328730, Validation loss: 0.66728839, Gradient norm: 0.03462575
INFO:root:[    7] Training loss: 0.66690985, Validation loss: 0.66117595, Gradient norm: 0.03421662
INFO:root:[    8] Training loss: 0.66126510, Validation loss: 0.65460965, Gradient norm: 0.03155155
INFO:root:[    9] Training loss: 0.65647029, Validation loss: 0.64877841, Gradient norm: 0.03881065
INFO:root:[   10] Training loss: 0.65124359, Validation loss: 0.64306274, Gradient norm: 0.03209525
INFO:root:[   11] Training loss: 0.64726743, Validation loss: 0.63978597, Gradient norm: 0.03483038
INFO:root:[   12] Training loss: 0.64385271, Validation loss: 0.63651228, Gradient norm: 0.03224705
INFO:root:[   13] Training loss: 0.64085991, Validation loss: 0.63346444, Gradient norm: 0.03653948
INFO:root:[   14] Training loss: 0.63831733, Validation loss: 0.63176704, Gradient norm: 0.03989074
INFO:root:[   15] Training loss: 0.63575296, Validation loss: 0.62833381, Gradient norm: 0.03514053
INFO:root:[   16] Training loss: 0.63368992, Validation loss: 0.62691702, Gradient norm: 0.03286913
INFO:root:[   17] Training loss: 0.63199992, Validation loss: 0.62429630, Gradient norm: 0.04219374
INFO:root:[   18] Training loss: 0.62985775, Validation loss: 0.62246986, Gradient norm: 0.03277649
INFO:root:[   19] Training loss: 0.62871341, Validation loss: 0.62171096, Gradient norm: 0.04304685
INFO:root:[   20] Training loss: 0.62704940, Validation loss: 0.61968310, Gradient norm: 0.04112426
INFO:root:Training the model took 549.244s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87343
INFO:root:EnergyScoreTrain: 0.6147
INFO:root:CoverageTrain: 0.9224
INFO:root:IntervalWidthTrain: 8.6529
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88071
INFO:root:EnergyScoreValidation: 0.61984
INFO:root:CoverageValidation: 0.91902
INFO:root:IntervalWidthValidation: 8.65426
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88249
INFO:root:EnergyScoreTest: 0.6211
INFO:root:CoverageTest: 0.91893
INFO:root:IntervalWidthTest: 8.66819
INFO:root:###3 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 20, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:NumberParameters: 231589
INFO:root:Memory allocated: 161480704
INFO:root:Training starts now.
INFO:root:[    1] Training loss: 0.99313409, Validation loss: 0.98955820, Gradient norm: 0.00797359
INFO:root:[    2] Training loss: 0.98440025, Validation loss: 0.97344735, Gradient norm: 0.02070032
INFO:root:[    3] Training loss: 0.96424740, Validation loss: 0.94841755, Gradient norm: 0.03351743
INFO:root:[    4] Training loss: 0.94347855, Validation loss: 0.92872211, Gradient norm: 0.03603471
INFO:root:[    5] Training loss: 0.92946160, Validation loss: 0.91664667, Gradient norm: 0.04373614
INFO:root:[    6] Training loss: 0.91913021, Validation loss: 0.90745303, Gradient norm: 0.04422173
INFO:root:[    7] Training loss: 0.91116127, Validation loss: 0.89976003, Gradient norm: 0.04365744
INFO:root:[    8] Training loss: 0.90558752, Validation loss: 0.89580798, Gradient norm: 0.04827448
INFO:root:[    9] Training loss: 0.90048891, Validation loss: 0.89036269, Gradient norm: 0.04765384
INFO:root:[   10] Training loss: 0.89623407, Validation loss: 0.88801997, Gradient norm: 0.05062698
INFO:root:[   11] Training loss: 0.89227193, Validation loss: 0.88292841, Gradient norm: 0.04938600
INFO:root:[   12] Training loss: 0.88956023, Validation loss: 0.87953592, Gradient norm: 0.05960491
INFO:root:[   13] Training loss: 0.88569179, Validation loss: 0.87877939, Gradient norm: 0.05321239
INFO:root:[   14] Training loss: 0.88354451, Validation loss: 0.87367737, Gradient norm: 0.06464736
INFO:root:[   15] Training loss: 0.88053904, Validation loss: 0.87032780, Gradient norm: 0.05780637
INFO:root:[   16] Training loss: 0.87790246, Validation loss: 0.86835926, Gradient norm: 0.05917553
INFO:root:[   17] Training loss: 0.87712639, Validation loss: 0.86783973, Gradient norm: 0.07668406
INFO:root:[   18] Training loss: 0.87394619, Validation loss: 0.86568192, Gradient norm: 0.05652816
INFO:root:[   19] Training loss: 0.87186565, Validation loss: 0.86229711, Gradient norm: 0.06140331
INFO:root:[   20] Training loss: 0.87086769, Validation loss: 0.86389138, Gradient norm: 0.07842971
INFO:root:Training the model took 511.179s.
INFO:root:Emptying the cuda cache took 0.018s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85365
INFO:root:EnergyScoreTrain: 0.8523
INFO:root:CoverageTrain: 0.0022
INFO:root:IntervalWidthTrain: 0.00681
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86279
INFO:root:EnergyScoreValidation: 0.86141
INFO:root:CoverageValidation: 0.00219
INFO:root:IntervalWidthValidation: 0.00688
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86421
INFO:root:EnergyScoreTest: 0.8629
INFO:root:CoverageTest: 0.00206
INFO:root:IntervalWidthTest: 0.0065
INFO:root:###4 out of 4 training parameter combinations ###
INFO:root:Training parameters: {'model': 'FNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 20, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:NumberParameters: 231589
INFO:root:Memory allocated: 297795584
INFO:root:Training starts now.
INFO:root:[    1] Training loss: 0.99308989, Validation loss: 0.99023715, Gradient norm: 0.00906158
INFO:root:[    2] Training loss: 0.98207587, Validation loss: 0.97151427, Gradient norm: 0.02142269
INFO:root:[    3] Training loss: 0.96095448, Validation loss: 0.95234066, Gradient norm: 0.03305385
INFO:root:[    4] Training loss: 0.94609733, Validation loss: 0.94324941, Gradient norm: 0.03599787
INFO:root:[    5] Training loss: 0.93641659, Validation loss: 0.93373091, Gradient norm: 0.03741189
INFO:root:[    6] Training loss: 0.92930554, Validation loss: 0.92842196, Gradient norm: 0.04277459
INFO:root:[    7] Training loss: 0.92315580, Validation loss: 0.92277719, Gradient norm: 0.03975109
INFO:root:[    8] Training loss: 0.91784475, Validation loss: 0.91896930, Gradient norm: 0.04286458
INFO:root:[    9] Training loss: 0.91349035, Validation loss: 0.91537563, Gradient norm: 0.04147721
INFO:root:[   10] Training loss: 0.91071830, Validation loss: 0.91204172, Gradient norm: 0.05282495
INFO:root:[   11] Training loss: 0.90645103, Validation loss: 0.91040021, Gradient norm: 0.04421480
INFO:root:[   12] Training loss: 0.90401814, Validation loss: 0.90823623, Gradient norm: 0.05292915
INFO:root:[   13] Training loss: 0.90099817, Validation loss: 0.90409431, Gradient norm: 0.04998378
INFO:root:[   14] Training loss: 0.89804080, Validation loss: 0.90135146, Gradient norm: 0.04940166
INFO:root:[   15] Training loss: 0.89651421, Validation loss: 0.89989276, Gradient norm: 0.05970220
INFO:root:[   16] Training loss: 0.89381385, Validation loss: 0.89978144, Gradient norm: 0.05809635
INFO:root:[   17] Training loss: 0.89204104, Validation loss: 0.89611642, Gradient norm: 0.06038492
INFO:root:[   18] Training loss: 0.88906619, Validation loss: 0.89471089, Gradient norm: 0.05407074
INFO:root:[   19] Training loss: 0.88838180, Validation loss: 0.89587481, Gradient norm: 0.06685111
INFO:root:[   20] Training loss: 0.88609422, Validation loss: 0.89200081, Gradient norm: 0.06149102
INFO:root:Training the model took 511.909s.
INFO:root:Emptying the cuda cache took 0.019s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86987
INFO:root:EnergyScoreTrain: 0.77734
INFO:root:CoverageTrain: 0.27112
INFO:root:IntervalWidthTrain: 1.25626
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87917
INFO:root:EnergyScoreValidation: 0.78676
INFO:root:CoverageValidation: 0.26463
INFO:root:IntervalWidthValidation: 1.25272
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87895
INFO:root:EnergyScoreTest: 0.78622
INFO:root:CoverageTest: 0.26648
INFO:root:IntervalWidthTest: 1.25788
