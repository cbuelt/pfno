INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=579.37890625MB; mem (CPU total)=1491.9296875MB
INFO:root:############### Starting experiment with config file sswe/sfno_sr_reparam_1_1.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=590.62890625MB; mem (CPU total)=1496.0859375MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=591.96875MB; mem (CPU total)=1497.0703125MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2231.859375MB; mem (CPU total)=4258.79296875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2241.5078125MB; mem (CPU total)=4289.11328125MB
INFO:root:[    1] Training loss: 0.53721623, Validation loss: 0.50907371, Gradient norm: 0.32939684
INFO:root:At the start of the epoch: mem (CPU python)=4414.7578125MB; mem (CPU total)=7705.91015625MB
INFO:root:[    2] Training loss: 0.46012310, Validation loss: 0.39935178, Gradient norm: 0.41574311
INFO:root:At the start of the epoch: mem (CPU python)=4436.3203125MB; mem (CPU total)=7787.6953125MB
INFO:root:[    3] Training loss: 0.37467196, Validation loss: 0.35621322, Gradient norm: 0.54637196
INFO:root:At the start of the epoch: mem (CPU python)=4460.56640625MB; mem (CPU total)=7873.60546875MB
INFO:root:[    4] Training loss: 0.33570410, Validation loss: 0.33014381, Gradient norm: 0.63044897
INFO:root:At the start of the epoch: mem (CPU python)=4483.6796875MB; mem (CPU total)=7959.8515625MB
INFO:root:[    5] Training loss: 0.31842794, Validation loss: 0.31553794, Gradient norm: 0.68246781
INFO:root:At the start of the epoch: mem (CPU python)=4504.85546875MB; mem (CPU total)=8042.73046875MB
INFO:root:[    6] Training loss: 0.30820656, Validation loss: 0.31199369, Gradient norm: 0.70699386
INFO:root:At the start of the epoch: mem (CPU python)=4526.03125MB; mem (CPU total)=8124.2734375MB
INFO:root:[    7] Training loss: 0.30173026, Validation loss: 0.30821855, Gradient norm: 0.73510969
INFO:root:At the start of the epoch: mem (CPU python)=4548.28515625MB; mem (CPU total)=8207.9375MB
INFO:root:[    8] Training loss: 0.29569548, Validation loss: 0.30835193, Gradient norm: 0.75716886
INFO:root:At the start of the epoch: mem (CPU python)=4569.45703125MB; mem (CPU total)=8290.96484375MB
INFO:root:[    9] Training loss: 0.28579233, Validation loss: 0.29561120, Gradient norm: 0.83171424
INFO:root:At the start of the epoch: mem (CPU python)=4590.625MB; mem (CPU total)=8374.1640625MB
INFO:root:[   10] Training loss: 0.27267677, Validation loss: 0.28232593, Gradient norm: 0.87829451
INFO:root:At the start of the epoch: mem (CPU python)=4611.78515625MB; mem (CPU total)=8455.3359375MB
INFO:root:[   11] Training loss: 0.26427180, Validation loss: 0.28531849, Gradient norm: 0.95796981
INFO:root:At the start of the epoch: mem (CPU python)=4632.94921875MB; mem (CPU total)=8537.15625MB
INFO:root:[   12] Training loss: 0.25858775, Validation loss: 0.29228995, Gradient norm: 1.05879335
INFO:root:At the start of the epoch: mem (CPU python)=4656.12109375MB; mem (CPU total)=8622.64453125MB
INFO:root:[   13] Training loss: 0.25339417, Validation loss: 0.30456667, Gradient norm: 1.11820755
INFO:root:At the start of the epoch: mem (CPU python)=4677.53125MB; mem (CPU total)=8703.03125MB
INFO:root:[   14] Training loss: 0.24922329, Validation loss: 0.30414422, Gradient norm: 1.26182322
INFO:root:At the start of the epoch: mem (CPU python)=4698.703125MB; mem (CPU total)=8783.2109375MB
INFO:root:[   15] Training loss: 0.24675776, Validation loss: 0.32694165, Gradient norm: 1.42077046
INFO:root:At the start of the epoch: mem (CPU python)=4719.859375MB; mem (CPU total)=8863.515625MB
INFO:root:[   16] Training loss: 0.24260105, Validation loss: 0.35270254, Gradient norm: 1.52099860
INFO:root:At the start of the epoch: mem (CPU python)=4741.01953125MB; mem (CPU total)=8943.97265625MB
INFO:root:[   17] Training loss: 0.24179645, Validation loss: 0.37466186, Gradient norm: 1.67252809
INFO:root:At the start of the epoch: mem (CPU python)=4762.1875MB; mem (CPU total)=9023.6328125MB
INFO:root:[   18] Training loss: 0.23719979, Validation loss: 0.40781366, Gradient norm: 1.76214909
INFO:root:At the start of the epoch: mem (CPU python)=4783.3515625MB; mem (CPU total)=9103.63671875MB
INFO:root:[   19] Training loss: 0.23520424, Validation loss: 0.38868946, Gradient norm: 1.84729187
INFO:root:At the start of the epoch: mem (CPU python)=4804.51953125MB; mem (CPU total)=9183.4140625MB
INFO:root:[   20] Training loss: 0.23297195, Validation loss: 0.38361456, Gradient norm: 2.01478671
INFO:root:At the start of the epoch: mem (CPU python)=4825.6796875MB; mem (CPU total)=9262.46875MB
INFO:root:[   21] Training loss: 0.23107699, Validation loss: 0.39630020, Gradient norm: 2.10338892
INFO:root:At the start of the epoch: mem (CPU python)=4846.84765625MB; mem (CPU total)=9341.65625MB
INFO:root:[   22] Training loss: 0.22923835, Validation loss: 0.40311081, Gradient norm: 2.22967993
INFO:root:At the start of the epoch: mem (CPU python)=4868.01171875MB; mem (CPU total)=9420.78515625MB
INFO:root:[   23] Training loss: 0.22654185, Validation loss: 0.39048750, Gradient norm: 2.36837959
INFO:root:At the start of the epoch: mem (CPU python)=4889.17578125MB; mem (CPU total)=9499.890625MB
INFO:root:[   24] Training loss: 0.22339318, Validation loss: 0.40844530, Gradient norm: 2.45939295
INFO:root:At the start of the epoch: mem (CPU python)=4910.33984375MB; mem (CPU total)=9579.578125MB
INFO:root:[   25] Training loss: 0.22255633, Validation loss: 0.39824752, Gradient norm: 2.60964228
INFO:root:At the start of the epoch: mem (CPU python)=4931.5078125MB; mem (CPU total)=9659.5703125MB
INFO:root:[   26] Training loss: 0.22071173, Validation loss: 0.40197862, Gradient norm: 2.71565068
INFO:root:At the start of the epoch: mem (CPU python)=4952.66796875MB; mem (CPU total)=9738.4921875MB
INFO:root:[   27] Training loss: 0.22188651, Validation loss: 0.39988474, Gradient norm: 2.80543363
INFO:root:At the start of the epoch: mem (CPU python)=4973.8359375MB; mem (CPU total)=9821.75390625MB
INFO:root:[   28] Training loss: 0.22096105, Validation loss: 0.40495575, Gradient norm: 2.77756371
INFO:root:At the start of the epoch: mem (CPU python)=4995.0078125MB; mem (CPU total)=9900.5234375MB
INFO:root:[   29] Training loss: 0.21619704, Validation loss: 0.42732601, Gradient norm: 2.81551039
INFO:root:At the start of the epoch: mem (CPU python)=5016.171875MB; mem (CPU total)=9978.8984375MB
INFO:root:[   30] Training loss: 0.21736091, Validation loss: 0.42101934, Gradient norm: 2.89321356
INFO:root:At the start of the epoch: mem (CPU python)=5037.33203125MB; mem (CPU total)=10063.02734375MB
INFO:root:[   31] Training loss: 0.21517853, Validation loss: 0.42560963, Gradient norm: 2.89773256
INFO:root:At the start of the epoch: mem (CPU python)=5058.5MB; mem (CPU total)=10140.453125MB
INFO:root:[   32] Training loss: 0.21243088, Validation loss: 0.42200083, Gradient norm: 2.88701066
INFO:root:At the start of the epoch: mem (CPU python)=5079.66015625MB; mem (CPU total)=10219.45703125MB
INFO:root:[   33] Training loss: 0.21277968, Validation loss: 0.43809427, Gradient norm: 2.92787672
INFO:root:At the start of the epoch: mem (CPU python)=5100.828125MB; mem (CPU total)=10299.00390625MB
INFO:root:[   34] Training loss: 0.21269939, Validation loss: 0.40452899, Gradient norm: 3.02689562
INFO:root:At the start of the epoch: mem (CPU python)=5122.0MB; mem (CPU total)=10376.5703125MB
INFO:root:[   35] Training loss: 0.20966577, Validation loss: 0.42251139, Gradient norm: 2.97733043
INFO:root:At the start of the epoch: mem (CPU python)=5143.15234375MB; mem (CPU total)=10458.05078125MB
INFO:root:[   36] Training loss: 0.20893271, Validation loss: 0.40232536, Gradient norm: 2.99852303
INFO:root:At the start of the epoch: mem (CPU python)=5164.3125MB; mem (CPU total)=10535.10546875MB
INFO:root:[   37] Training loss: 0.20752819, Validation loss: 0.41462227, Gradient norm: 2.98442282
INFO:root:At the start of the epoch: mem (CPU python)=5185.4765625MB; mem (CPU total)=10612.15625MB
INFO:root:[   38] Training loss: 0.20660159, Validation loss: 0.41799050, Gradient norm: 3.02166714
INFO:root:At the start of the epoch: mem (CPU python)=5206.64453125MB; mem (CPU total)=10694.34375MB
INFO:root:[   39] Training loss: 0.20629456, Validation loss: 0.41238523, Gradient norm: 2.99734313
INFO:root:At the start of the epoch: mem (CPU python)=5227.8046875MB; mem (CPU total)=10772.05078125MB
INFO:root:[   40] Training loss: 0.20643528, Validation loss: 0.41144265, Gradient norm: 3.05176696
INFO:root:At the start of the epoch: mem (CPU python)=5248.96875MB; mem (CPU total)=10848.46484375MB
INFO:root:[   41] Training loss: 0.20498321, Validation loss: 0.41870528, Gradient norm: 3.01747848
INFO:root:At the start of the epoch: mem (CPU python)=5270.1328125MB; mem (CPU total)=10926.33984375MB
INFO:root:[   42] Training loss: 0.20629074, Validation loss: 0.43205473, Gradient norm: 3.07007619
INFO:root:At the start of the epoch: mem (CPU python)=5291.296875MB; mem (CPU total)=11002.89453125MB
INFO:root:[   43] Training loss: 0.20366817, Validation loss: 0.41849490, Gradient norm: 3.07268125
INFO:root:At the start of the epoch: mem (CPU python)=5312.4609375MB; mem (CPU total)=11080.0703125MB
INFO:root:[   44] Training loss: 0.20278614, Validation loss: 0.42066916, Gradient norm: 3.07482001
INFO:root:At the start of the epoch: mem (CPU python)=5333.62890625MB; mem (CPU total)=11157.3671875MB
INFO:root:[   45] Training loss: 0.20104219, Validation loss: 0.42383378, Gradient norm: 3.08791998
INFO:root:At the start of the epoch: mem (CPU python)=5354.79296875MB; mem (CPU total)=11233.92578125MB
INFO:root:[   46] Training loss: 0.20383632, Validation loss: 0.42032671, Gradient norm: 3.09023859
INFO:root:At the start of the epoch: mem (CPU python)=5375.9609375MB; mem (CPU total)=11316.94921875MB
INFO:root:[   47] Training loss: 0.20191570, Validation loss: 0.42068818, Gradient norm: 2.98891522
INFO:root:At the start of the epoch: mem (CPU python)=5397.1171875MB; mem (CPU total)=11391.80078125MB
INFO:root:[   48] Training loss: 0.19926761, Validation loss: 0.40801898, Gradient norm: 3.02821817
INFO:root:At the start of the epoch: mem (CPU python)=5418.28125MB; mem (CPU total)=11468.11328125MB
INFO:root:[   49] Training loss: 0.19937328, Validation loss: 0.43300715, Gradient norm: 3.10387603
INFO:root:At the start of the epoch: mem (CPU python)=5439.44921875MB; mem (CPU total)=11544.91796875MB
INFO:root:[   50] Training loss: 0.19919127, Validation loss: 0.44335560, Gradient norm: 3.07894482
INFO:root:At the start of the epoch: mem (CPU python)=5460.61328125MB; mem (CPU total)=11621.18359375MB
INFO:root:[   51] Training loss: 0.19845436, Validation loss: 0.43434600, Gradient norm: 3.07638739
INFO:root:At the start of the epoch: mem (CPU python)=5481.77734375MB; mem (CPU total)=11702.03515625MB
INFO:root:[   52] Training loss: 0.20012370, Validation loss: 0.43875736, Gradient norm: 3.07391578
INFO:root:At the start of the epoch: mem (CPU python)=5502.94140625MB; mem (CPU total)=11777.2578125MB
INFO:root:[   53] Training loss: 0.19823082, Validation loss: 0.43563043, Gradient norm: 3.12778329
INFO:root:At the start of the epoch: mem (CPU python)=5524.1015625MB; mem (CPU total)=11853.69140625MB
INFO:root:[   54] Training loss: 0.19664799, Validation loss: 0.42357907, Gradient norm: 3.12740328
INFO:root:At the start of the epoch: mem (CPU python)=5545.26171875MB; mem (CPU total)=11933.1484375MB
INFO:root:[   55] Training loss: 0.19638280, Validation loss: 0.42767364, Gradient norm: 3.19605668
INFO:root:At the start of the epoch: mem (CPU python)=5566.55859375MB; mem (CPU total)=12011.1875MB
INFO:root:[   56] Training loss: 0.19583313, Validation loss: 0.42316446, Gradient norm: 3.18337235
INFO:root:At the start of the epoch: mem (CPU python)=5588.34765625MB; mem (CPU total)=12089.47265625MB
INFO:root:[   57] Training loss: 0.19716021, Validation loss: 0.43205136, Gradient norm: 3.26518938
INFO:root:At the start of the epoch: mem (CPU python)=5610.1484375MB; mem (CPU total)=12208.15234375MB
INFO:root:[   58] Training loss: 0.19590745, Validation loss: 0.41792382, Gradient norm: 3.20293221
INFO:root:At the start of the epoch: mem (CPU python)=5631.33203125MB; mem (CPU total)=12232.0078125MB
INFO:root:[   59] Training loss: 0.19570692, Validation loss: 0.44121076, Gradient norm: 3.11377048
INFO:root:At the start of the epoch: mem (CPU python)=5652.5234375MB; mem (CPU total)=12261.66796875MB
INFO:root:[   60] Training loss: 0.19488745, Validation loss: 0.41804325, Gradient norm: 3.25620144
INFO:root:At the start of the epoch: mem (CPU python)=5673.69921875MB; mem (CPU total)=12285.94921875MB
INFO:root:[   61] Training loss: 0.19573274, Validation loss: 0.42450306, Gradient norm: 3.24421337
INFO:root:At the start of the epoch: mem (CPU python)=5694.8671875MB; mem (CPU total)=12309.21875MB
INFO:root:[   62] Training loss: 0.19504595, Validation loss: 0.42928101, Gradient norm: 3.16294589
INFO:root:At the start of the epoch: mem (CPU python)=5716.0703125MB; mem (CPU total)=12332.8046875MB
INFO:root:[   63] Training loss: 0.19493250, Validation loss: 0.43794635, Gradient norm: 3.17919170
INFO:root:At the start of the epoch: mem (CPU python)=5737.234375MB; mem (CPU total)=12357.0MB
INFO:root:[   64] Training loss: 0.19501283, Validation loss: 0.43847778, Gradient norm: 3.17643538
INFO:root:At the start of the epoch: mem (CPU python)=5758.40234375MB; mem (CPU total)=12380.60546875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   65] Training loss: 0.19428624, Validation loss: 0.41811180, Gradient norm: 3.16141200
INFO:root:At the start of the epoch: mem (CPU python)=5779.5859375MB; mem (CPU total)=12408.79296875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   66] Training loss: 0.18174302, Validation loss: 0.41530737, Gradient norm: 2.60008308
INFO:root:At the start of the epoch: mem (CPU python)=5815.390625MB; mem (CPU total)=12551.38671875MB
INFO:root:[   67] Training loss: 0.17337527, Validation loss: 0.39947062, Gradient norm: 2.08835114
INFO:root:At the start of the epoch: mem (CPU python)=5815.46875MB; mem (CPU total)=12551.875MB
INFO:root:[   68] Training loss: 0.17245788, Validation loss: 0.39980712, Gradient norm: 2.49158086
INFO:root:At the start of the epoch: mem (CPU python)=5836.734375MB; mem (CPU total)=12588.05859375MB
INFO:root:[   69] Training loss: 0.17189782, Validation loss: 0.40523546, Gradient norm: 2.87422409
INFO:root:At the start of the epoch: mem (CPU python)=5857.921875MB; mem (CPU total)=12607.9609375MB
INFO:root:[   70] Training loss: 0.17218373, Validation loss: 0.38925771, Gradient norm: 3.28606269
INFO:root:At the start of the epoch: mem (CPU python)=5880.96875MB; mem (CPU total)=12686.4765625MB
INFO:root:[   71] Training loss: 0.17192386, Validation loss: 0.38288892, Gradient norm: 3.47149753
INFO:root:At the start of the epoch: mem (CPU python)=5906.125MB; mem (CPU total)=12774.08984375MB
INFO:root:[   72] Training loss: 0.17172283, Validation loss: 0.39021300, Gradient norm: 3.65700336
INFO:root:At the start of the epoch: mem (CPU python)=5927.44140625MB; mem (CPU total)=12851.87109375MB
INFO:root:[   73] Training loss: 0.17173358, Validation loss: 0.40875041, Gradient norm: 3.94073805
INFO:root:At the start of the epoch: mem (CPU python)=5948.6171875MB; mem (CPU total)=12929.9921875MB
INFO:root:[   74] Training loss: 0.17106198, Validation loss: 0.38592869, Gradient norm: 4.03820306
INFO:root:At the start of the epoch: mem (CPU python)=5969.80078125MB; mem (CPU total)=13009.31640625MB
INFO:root:[   75] Training loss: 0.17236125, Validation loss: 0.39638226, Gradient norm: 4.75283772
INFO:root:At the start of the epoch: mem (CPU python)=5990.96875MB; mem (CPU total)=13086.94921875MB
INFO:root:[   76] Training loss: 0.17114608, Validation loss: 0.40466215, Gradient norm: 4.40766297
INFO:root:At the start of the epoch: mem (CPU python)=6012.140625MB; mem (CPU total)=13163.74609375MB
INFO:root:[   77] Training loss: 0.17251345, Validation loss: 0.39501410, Gradient norm: 4.98566346
INFO:root:At the start of the epoch: mem (CPU python)=6033.3828125MB; mem (CPU total)=13242.5078125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   78] Training loss: 0.17151130, Validation loss: 0.38674255, Gradient norm: 4.75892728
INFO:root:At the start of the epoch: mem (CPU python)=6054.5546875MB; mem (CPU total)=13320.01953125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   79] Training loss: 0.16817513, Validation loss: 0.38463300, Gradient norm: 4.04749683
INFO:root:At the start of the epoch: mem (CPU python)=6075.73046875MB; mem (CPU total)=13396.875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   80] Training loss: 0.16532389, Validation loss: 0.38342839, Gradient norm: 3.18815569
INFO:root:At the start of the epoch: mem (CPU python)=6096.90234375MB; mem (CPU total)=13475.67578125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   81] Training loss: 0.16406499, Validation loss: 0.37764925, Gradient norm: 2.51824331
INFO:root:At the start of the epoch: mem (CPU python)=6118.08203125MB; mem (CPU total)=13552.35546875MB
INFO:root:[   82] Training loss: 0.16328749, Validation loss: 0.37730733, Gradient norm: 2.12172646
INFO:root:At the start of the epoch: mem (CPU python)=6139.2578125MB; mem (CPU total)=13630.07421875MB
INFO:root:[   83] Training loss: 0.16337511, Validation loss: 0.37679981, Gradient norm: 2.27910635
INFO:root:At the start of the epoch: mem (CPU python)=6160.4375MB; mem (CPU total)=13705.6015625MB
INFO:root:[   84] Training loss: 0.16304502, Validation loss: 0.37883097, Gradient norm: 2.32295956
INFO:root:At the start of the epoch: mem (CPU python)=6181.58984375MB; mem (CPU total)=13781.42578125MB
INFO:root:[   85] Training loss: 0.16329980, Validation loss: 0.37588416, Gradient norm: 2.43330888
INFO:root:At the start of the epoch: mem (CPU python)=6202.75390625MB; mem (CPU total)=13860.96875MB
INFO:root:[   86] Training loss: 0.16314770, Validation loss: 0.37740595, Gradient norm: 2.58702818
INFO:root:At the start of the epoch: mem (CPU python)=6223.91796875MB; mem (CPU total)=13934.84765625MB
INFO:root:[   87] Training loss: 0.16326996, Validation loss: 0.37703699, Gradient norm: 2.57442362
INFO:root:At the start of the epoch: mem (CPU python)=6245.078125MB; mem (CPU total)=14010.91796875MB
INFO:root:[   88] Training loss: 0.16316181, Validation loss: 0.37741988, Gradient norm: 2.75153984
INFO:root:At the start of the epoch: mem (CPU python)=6266.2421875MB; mem (CPU total)=14089.69140625MB
INFO:root:[   89] Training loss: 0.16294921, Validation loss: 0.37415853, Gradient norm: 2.75849812
INFO:root:At the start of the epoch: mem (CPU python)=6287.40625MB; mem (CPU total)=14165.51171875MB
INFO:root:[   90] Training loss: 0.16290557, Validation loss: 0.37430524, Gradient norm: 2.89065742
INFO:root:At the start of the epoch: mem (CPU python)=6308.5703125MB; mem (CPU total)=14244.78125MB
INFO:root:[   91] Training loss: 0.16279195, Validation loss: 0.37331047, Gradient norm: 2.93700732
INFO:root:At the start of the epoch: mem (CPU python)=6329.73046875MB; mem (CPU total)=14319.6171875MB
INFO:root:[   92] Training loss: 0.16296728, Validation loss: 0.37336530, Gradient norm: 3.14067186
INFO:root:At the start of the epoch: mem (CPU python)=6350.89453125MB; mem (CPU total)=14395.875MB
INFO:root:[   93] Training loss: 0.16297120, Validation loss: 0.37441836, Gradient norm: 3.17709830
INFO:root:At the start of the epoch: mem (CPU python)=6372.05859375MB; mem (CPU total)=14470.49609375MB
INFO:root:[   94] Training loss: 0.16293542, Validation loss: 0.37382091, Gradient norm: 3.07557192
INFO:root:At the start of the epoch: mem (CPU python)=6393.22265625MB; mem (CPU total)=14545.80078125MB
INFO:root:[   95] Training loss: 0.16297295, Validation loss: 0.37181411, Gradient norm: 3.33725236
INFO:root:At the start of the epoch: mem (CPU python)=6414.390625MB; mem (CPU total)=14623.375MB
INFO:root:[   96] Training loss: 0.16288339, Validation loss: 0.37403535, Gradient norm: 3.47987544
INFO:root:At the start of the epoch: mem (CPU python)=6435.55859375MB; mem (CPU total)=14697.3828125MB
INFO:root:[   97] Training loss: 0.16295626, Validation loss: 0.37345424, Gradient norm: 3.44222162
INFO:root:At the start of the epoch: mem (CPU python)=6456.72265625MB; mem (CPU total)=14775.16015625MB
INFO:root:[   98] Training loss: 0.16301617, Validation loss: 0.37501317, Gradient norm: 3.47519868
INFO:root:At the start of the epoch: mem (CPU python)=6477.88671875MB; mem (CPU total)=14850.21875MB
INFO:root:[   99] Training loss: 0.16289494, Validation loss: 0.37566033, Gradient norm: 3.89658253
INFO:root:At the start of the epoch: mem (CPU python)=6499.05078125MB; mem (CPU total)=14930.10546875MB
INFO:root:[  100] Training loss: 0.16274505, Validation loss: 0.37458666, Gradient norm: 3.72915200
INFO:root:At the start of the epoch: mem (CPU python)=6520.21484375MB; mem (CPU total)=15003.1640625MB
INFO:root:[  101] Training loss: 0.16306304, Validation loss: 0.37304119, Gradient norm: 3.87582232
INFO:root:At the start of the epoch: mem (CPU python)=6541.375MB; mem (CPU total)=15085.41796875MB
INFO:root:[  102] Training loss: 0.16287715, Validation loss: 0.37245658, Gradient norm: 3.96905946
INFO:root:At the start of the epoch: mem (CPU python)=6562.54296875MB; mem (CPU total)=15157.81640625MB
INFO:root:[  103] Training loss: 0.16272527, Validation loss: 0.37454367, Gradient norm: 3.87181476
INFO:root:At the start of the epoch: mem (CPU python)=6583.703125MB; mem (CPU total)=15234.1328125MB
INFO:root:[  104] Training loss: 0.16283500, Validation loss: 0.37292547, Gradient norm: 4.36731530
INFO:root:At the start of the epoch: mem (CPU python)=6604.875MB; mem (CPU total)=15307.21484375MB
INFO:root:EP 104: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=6626.02734375MB; mem (CPU total)=15381.98046875MB
INFO:root:Training the model took 7029.75s.
INFO:root:Emptying the cuda cache took 0.067s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.38876
INFO:root:EnergyScoreValidation: 0.28233
INFO:root:CRPSValidation: 0.15455
INFO:root:Gaussian NLLValidation: 14280175191.3131
INFO:root:CoverageValidation: 0.1415
INFO:root:IntervalWidthValidation: 0.185
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.40997
INFO:root:EnergyScoreTest: 0.2996
INFO:root:CRPSTest: 0.16421
INFO:root:Gaussian NLLTest: 15860514430.976
INFO:root:CoverageTest: 0.14089
INFO:root:IntervalWidthTest: 0.18757
INFO:root:After validation: mem (CPU python)=6641.953125MB; mem (CPU total)=15904.94140625MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=6641.953125MB; mem (CPU total)=15907.3984375MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 65011712
INFO:root:After setting up the model: mem (CPU python)=6641.953125MB; mem (CPU total)=15907.3984375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=6641.9609375MB; mem (CPU total)=15909.85546875MB
INFO:root:[    1] Training loss: 0.53507713, Validation loss: 0.50466655, Gradient norm: 0.30446168
INFO:root:At the start of the epoch: mem (CPU python)=6693.78125MB; mem (CPU total)=16016.515625MB
INFO:root:[    2] Training loss: 0.45878527, Validation loss: 0.40592010, Gradient norm: 0.40735751
INFO:root:At the start of the epoch: mem (CPU python)=6716.99609375MB; mem (CPU total)=16089.390625MB
INFO:root:[    3] Training loss: 0.37767669, Validation loss: 0.36103071, Gradient norm: 0.61334253
INFO:root:At the start of the epoch: mem (CPU python)=6743.93359375MB; mem (CPU total)=16169.625MB
INFO:root:[    4] Training loss: 0.34924244, Validation loss: 0.34514122, Gradient norm: 0.67484755
INFO:root:At the start of the epoch: mem (CPU python)=6765.19921875MB; mem (CPU total)=16240.9921875MB
INFO:root:[    5] Training loss: 0.33104967, Validation loss: 0.32848683, Gradient norm: 0.80128443
INFO:root:At the start of the epoch: mem (CPU python)=6786.36328125MB; mem (CPU total)=16316.265625MB
INFO:root:[    6] Training loss: 0.31202616, Validation loss: 0.31643677, Gradient norm: 0.98785598
INFO:root:At the start of the epoch: mem (CPU python)=6807.53515625MB; mem (CPU total)=16392.09765625MB
INFO:root:[    7] Training loss: 0.30473654, Validation loss: 0.31095810, Gradient norm: 1.04927511
INFO:root:At the start of the epoch: mem (CPU python)=6828.69921875MB; mem (CPU total)=16471.8359375MB
INFO:root:[    8] Training loss: 0.30085219, Validation loss: 0.31844969, Gradient norm: 1.16951930
INFO:root:At the start of the epoch: mem (CPU python)=6849.859375MB; mem (CPU total)=16546.58984375MB
INFO:root:[    9] Training loss: 0.29573199, Validation loss: 0.31057037, Gradient norm: 1.29983469
INFO:root:At the start of the epoch: mem (CPU python)=6871.0234375MB; mem (CPU total)=16617.19921875MB
INFO:root:[   10] Training loss: 0.29201509, Validation loss: 0.31425965, Gradient norm: 1.47497726
INFO:root:At the start of the epoch: mem (CPU python)=6892.3515625MB; mem (CPU total)=16692.89453125MB
INFO:root:[   11] Training loss: 0.28804197, Validation loss: 0.32354591, Gradient norm: 1.63635167
INFO:root:At the start of the epoch: mem (CPU python)=6913.7265625MB; mem (CPU total)=16767.46484375MB
INFO:root:[   12] Training loss: 0.28394452, Validation loss: 0.31619624, Gradient norm: 1.81505831
INFO:root:At the start of the epoch: mem (CPU python)=6934.890625MB; mem (CPU total)=16791.36328125MB
INFO:root:[   13] Training loss: 0.28044214, Validation loss: 0.32889875, Gradient norm: 2.00543611
INFO:root:At the start of the epoch: mem (CPU python)=6956.05859375MB; mem (CPU total)=16814.7578125MB
