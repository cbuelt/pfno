INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=572.91796875MB; mem (CPU total)=1055.515625MB
INFO:root:############### Starting experiment with config file sswe/sfno_dropout_1.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=583.5625MB; mem (CPU total)=1058.6171875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=585.109375MB; mem (CPU total)=1059.41796875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2259.74609375MB; mem (CPU total)=2507.09765625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2269.3515625MB; mem (CPU total)=2516.05078125MB
INFO:root:[    1] Training loss: 0.83809210, Validation loss: 0.74437924, Gradient norm: 0.46165115
INFO:root:At the start of the epoch: mem (CPU python)=4416.73046875MB; mem (CPU total)=4221.33984375MB
INFO:root:[    2] Training loss: 0.73993827, Validation loss: 0.73659317, Gradient norm: 0.28921321
INFO:root:At the start of the epoch: mem (CPU python)=4438.96875MB; mem (CPU total)=4243.0078125MB
INFO:root:[    3] Training loss: 0.72615816, Validation loss: 0.71430449, Gradient norm: 0.30628205
INFO:root:At the start of the epoch: mem (CPU python)=4462.56640625MB; mem (CPU total)=4267.07421875MB
INFO:root:[    4] Training loss: 0.70829020, Validation loss: 0.68935525, Gradient norm: 0.39444585
INFO:root:At the start of the epoch: mem (CPU python)=4483.87890625MB; mem (CPU total)=4287.796875MB
INFO:root:[    5] Training loss: 0.66313306, Validation loss: 0.62984116, Gradient norm: 0.48384226
INFO:root:At the start of the epoch: mem (CPU python)=4505.0703125MB; mem (CPU total)=4309.4140625MB
INFO:root:[    6] Training loss: 0.60540466, Validation loss: 0.58850876, Gradient norm: 0.72474141
INFO:root:At the start of the epoch: mem (CPU python)=4526.26171875MB; mem (CPU total)=4330.37890625MB
INFO:root:[    7] Training loss: 0.57818136, Validation loss: 0.56884290, Gradient norm: 0.83393507
INFO:root:At the start of the epoch: mem (CPU python)=4547.4453125MB; mem (CPU total)=4351.74609375MB
INFO:root:[    8] Training loss: 0.56814902, Validation loss: 0.56052680, Gradient norm: 1.03825233
INFO:root:At the start of the epoch: mem (CPU python)=4568.61328125MB; mem (CPU total)=4495.15234375MB
INFO:root:[    9] Training loss: 0.55415335, Validation loss: 0.56093633, Gradient norm: 1.23722591
INFO:root:At the start of the epoch: mem (CPU python)=4589.79296875MB; mem (CPU total)=4401.0703125MB
INFO:root:[   10] Training loss: 0.53900760, Validation loss: 0.52631065, Gradient norm: 1.38499793
INFO:root:At the start of the epoch: mem (CPU python)=4610.96484375MB; mem (CPU total)=4523.58203125MB
INFO:root:[   11] Training loss: 0.52767603, Validation loss: 0.52877789, Gradient norm: 1.46355989
INFO:root:At the start of the epoch: mem (CPU python)=4632.1328125MB; mem (CPU total)=4613.4921875MB
INFO:root:[   12] Training loss: 0.51680206, Validation loss: 0.52600565, Gradient norm: 1.60550614
INFO:root:At the start of the epoch: mem (CPU python)=4653.30078125MB; mem (CPU total)=4470.62109375MB
INFO:root:[   13] Training loss: 0.51275568, Validation loss: 0.50331458, Gradient norm: 1.88945456
INFO:root:At the start of the epoch: mem (CPU python)=4674.4765625MB; mem (CPU total)=4491.75MB
INFO:root:[   14] Training loss: 0.50633300, Validation loss: 0.49276491, Gradient norm: 1.69065068
INFO:root:At the start of the epoch: mem (CPU python)=4695.640625MB; mem (CPU total)=4512.37109375MB
INFO:root:[   15] Training loss: 0.50075187, Validation loss: 0.50946323, Gradient norm: 1.84546331
INFO:root:At the start of the epoch: mem (CPU python)=4716.8046875MB; mem (CPU total)=4532.91796875MB
INFO:root:[   16] Training loss: 0.50058963, Validation loss: 0.50174816, Gradient norm: 1.94657439
INFO:root:At the start of the epoch: mem (CPU python)=4737.98046875MB; mem (CPU total)=4554.6484375MB
INFO:root:[   17] Training loss: 0.49822182, Validation loss: 0.48810959, Gradient norm: 1.99343594
INFO:root:At the start of the epoch: mem (CPU python)=4759.1640625MB; mem (CPU total)=4575.375MB
INFO:root:[   18] Training loss: 0.49051425, Validation loss: 0.48182059, Gradient norm: 2.07338122
INFO:root:At the start of the epoch: mem (CPU python)=4780.56640625MB; mem (CPU total)=4596.42578125MB
INFO:root:[   19] Training loss: 0.48923769, Validation loss: 0.48732618, Gradient norm: 2.20660934
INFO:root:At the start of the epoch: mem (CPU python)=4801.8671875MB; mem (CPU total)=4617.48828125MB
INFO:root:[   20] Training loss: 0.48817002, Validation loss: 0.48841208, Gradient norm: 2.09806833
INFO:root:At the start of the epoch: mem (CPU python)=4823.06640625MB; mem (CPU total)=4638.57421875MB
INFO:root:[   21] Training loss: 0.48603138, Validation loss: 0.48790338, Gradient norm: 2.24154044
INFO:root:At the start of the epoch: mem (CPU python)=4844.23046875MB; mem (CPU total)=4659.546875MB
INFO:root:[   22] Training loss: 0.48757152, Validation loss: 0.49169889, Gradient norm: 2.31543086
INFO:root:At the start of the epoch: mem (CPU python)=4865.40625MB; mem (CPU total)=4680.859375MB
INFO:root:[   23] Training loss: 0.48388542, Validation loss: 0.48471068, Gradient norm: 2.38493260
INFO:root:At the start of the epoch: mem (CPU python)=4886.57421875MB; mem (CPU total)=4701.90625MB
INFO:root:[   24] Training loss: 0.48511116, Validation loss: 0.49031350, Gradient norm: 2.40762638
INFO:root:At the start of the epoch: mem (CPU python)=4907.73828125MB; mem (CPU total)=4723.40234375MB
INFO:root:[   25] Training loss: 0.48024187, Validation loss: 0.48023935, Gradient norm: 2.19309247
INFO:root:At the start of the epoch: mem (CPU python)=4928.91796875MB; mem (CPU total)=4744.09765625MB
INFO:root:[   26] Training loss: 0.48094238, Validation loss: 0.49442685, Gradient norm: 2.89003567
INFO:root:At the start of the epoch: mem (CPU python)=4950.09765625MB; mem (CPU total)=6125.80078125MB
INFO:root:[   27] Training loss: 0.48192637, Validation loss: 0.46869467, Gradient norm: 2.84605691
INFO:root:At the start of the epoch: mem (CPU python)=4971.26953125MB; mem (CPU total)=4793.9375MB
INFO:root:[   28] Training loss: 0.47785855, Validation loss: 0.48616392, Gradient norm: 2.74913090
INFO:root:At the start of the epoch: mem (CPU python)=4992.43359375MB; mem (CPU total)=4813.46875MB
INFO:root:[   29] Training loss: 0.47974191, Validation loss: 0.48193700, Gradient norm: 3.02545385
INFO:root:At the start of the epoch: mem (CPU python)=5013.609375MB; mem (CPU total)=6888.73828125MB
INFO:root:[   30] Training loss: 0.47615836, Validation loss: 0.47445760, Gradient norm: 2.81183175
INFO:root:At the start of the epoch: mem (CPU python)=5035.33203125MB; mem (CPU total)=6910.69921875MB
INFO:root:[   31] Training loss: 0.47675469, Validation loss: 0.46585351, Gradient norm: 3.02172771
INFO:root:At the start of the epoch: mem (CPU python)=5056.51171875MB; mem (CPU total)=6931.21484375MB
INFO:root:[   32] Training loss: 0.47538693, Validation loss: 0.48735621, Gradient norm: 2.63458199
INFO:root:At the start of the epoch: mem (CPU python)=5077.8671875MB; mem (CPU total)=6952.46484375MB
INFO:root:[   33] Training loss: 0.47155606, Validation loss: 0.46185638, Gradient norm: 2.73537273
INFO:root:At the start of the epoch: mem (CPU python)=5099.7578125MB; mem (CPU total)=6974.1015625MB
INFO:root:[   34] Training loss: 0.46984845, Validation loss: 0.48253413, Gradient norm: 3.32669058
INFO:root:At the start of the epoch: mem (CPU python)=5120.97265625MB; mem (CPU total)=5163.28515625MB
INFO:root:[   35] Training loss: 0.46834938, Validation loss: 0.45831491, Gradient norm: 2.87565173
INFO:root:At the start of the epoch: mem (CPU python)=5142.17578125MB; mem (CPU total)=4962.1015625MB
INFO:root:[   36] Training loss: 0.46570548, Validation loss: 0.47107214, Gradient norm: 2.97765802
INFO:root:At the start of the epoch: mem (CPU python)=5163.34375MB; mem (CPU total)=4979.3125MB
INFO:root:[   37] Training loss: 0.46584634, Validation loss: 0.46488899, Gradient norm: 3.67299927
INFO:root:At the start of the epoch: mem (CPU python)=5184.53515625MB; mem (CPU total)=5000.65234375MB
INFO:root:[   38] Training loss: 0.47028873, Validation loss: 0.46314438, Gradient norm: 3.28257091
INFO:root:At the start of the epoch: mem (CPU python)=5205.70703125MB; mem (CPU total)=5021.75MB
INFO:root:[   39] Training loss: 0.46482150, Validation loss: 0.45623651, Gradient norm: 3.70474817
INFO:root:At the start of the epoch: mem (CPU python)=5226.8359375MB; mem (CPU total)=5042.9140625MB
INFO:root:[   40] Training loss: 0.46473490, Validation loss: 0.45355445, Gradient norm: 3.59566350
INFO:root:At the start of the epoch: mem (CPU python)=5248.45703125MB; mem (CPU total)=5064.8828125MB
INFO:root:[   41] Training loss: 0.46722199, Validation loss: 0.45623987, Gradient norm: 3.62770670
INFO:root:At the start of the epoch: mem (CPU python)=5269.9921875MB; mem (CPU total)=5086.453125MB
INFO:root:[   42] Training loss: 0.46027566, Validation loss: 0.45364712, Gradient norm: 3.59765737
INFO:root:At the start of the epoch: mem (CPU python)=5291.49609375MB; mem (CPU total)=5107.43359375MB
INFO:root:[   43] Training loss: 0.46441324, Validation loss: 0.46200377, Gradient norm: 3.38423649
INFO:root:At the start of the epoch: mem (CPU python)=5312.66015625MB; mem (CPU total)=5128.58984375MB
INFO:root:[   44] Training loss: 0.46286386, Validation loss: 0.46343327, Gradient norm: 3.97259452
INFO:root:At the start of the epoch: mem (CPU python)=5333.80859375MB; mem (CPU total)=5149.68359375MB
INFO:root:[   45] Training loss: 0.46292682, Validation loss: 0.46796398, Gradient norm: 3.83203660
INFO:root:At the start of the epoch: mem (CPU python)=5354.98828125MB; mem (CPU total)=5171.1484375MB
INFO:root:[   46] Training loss: 0.45872801, Validation loss: 0.47931300, Gradient norm: 3.59696179
INFO:root:At the start of the epoch: mem (CPU python)=5376.15625MB; mem (CPU total)=5192.421875MB
INFO:root:[   47] Training loss: 0.45923175, Validation loss: 0.46299616, Gradient norm: 3.98613201
INFO:root:At the start of the epoch: mem (CPU python)=5397.32421875MB; mem (CPU total)=5213.95703125MB
INFO:root:[   48] Training loss: 0.45641880, Validation loss: 0.45068000, Gradient norm: 4.04481492
INFO:root:At the start of the epoch: mem (CPU python)=5418.48828125MB; mem (CPU total)=5234.8359375MB
INFO:root:[   49] Training loss: 0.45206673, Validation loss: 0.45185896, Gradient norm: 3.89853120
INFO:root:At the start of the epoch: mem (CPU python)=5439.7734375MB; mem (CPU total)=5256.0859375MB
INFO:root:[   50] Training loss: 0.46470290, Validation loss: 0.45149741, Gradient norm: 4.33363621
INFO:root:At the start of the epoch: mem (CPU python)=5461.30859375MB; mem (CPU total)=5277.91015625MB
INFO:root:[   51] Training loss: 0.46070744, Validation loss: 0.46956721, Gradient norm: 4.30073770
INFO:root:At the start of the epoch: mem (CPU python)=5482.26953125MB; mem (CPU total)=5299.19921875MB
INFO:root:[   52] Training loss: 0.45734176, Validation loss: 0.45506866, Gradient norm: 4.52274740
INFO:root:At the start of the epoch: mem (CPU python)=5503.90234375MB; mem (CPU total)=5320.27734375MB
INFO:root:[   53] Training loss: 0.45860738, Validation loss: 0.46119242, Gradient norm: 4.36784056
INFO:root:At the start of the epoch: mem (CPU python)=5525.07421875MB; mem (CPU total)=5341.5MB
INFO:root:[   54] Training loss: 0.45439692, Validation loss: 0.45145467, Gradient norm: 4.00959254
INFO:root:At the start of the epoch: mem (CPU python)=5546.24609375MB; mem (CPU total)=5362.375MB
INFO:root:[   55] Training loss: 0.45606667, Validation loss: 0.44200046, Gradient norm: 4.64819637
INFO:root:At the start of the epoch: mem (CPU python)=5567.921875MB; mem (CPU total)=5384.30859375MB
INFO:root:[   56] Training loss: 0.45705675, Validation loss: 0.45390645, Gradient norm: 4.50477918
INFO:root:At the start of the epoch: mem (CPU python)=5589.0546875MB; mem (CPU total)=5405.4453125MB
INFO:root:[   57] Training loss: 0.46179425, Validation loss: 0.45102873, Gradient norm: 4.54091198
INFO:root:At the start of the epoch: mem (CPU python)=5610.5078125MB; mem (CPU total)=5426.5234375MB
INFO:root:[   58] Training loss: 0.45076178, Validation loss: 0.44360555, Gradient norm: 4.30927527
INFO:root:At the start of the epoch: mem (CPU python)=5631.67578125MB; mem (CPU total)=5447.6640625MB
INFO:root:[   59] Training loss: 0.45138827, Validation loss: 0.45674308, Gradient norm: 4.85693457
INFO:root:At the start of the epoch: mem (CPU python)=5652.8359375MB; mem (CPU total)=5468.9140625MB
INFO:root:[   60] Training loss: 0.44687039, Validation loss: 0.44050633, Gradient norm: 4.60211866
INFO:root:At the start of the epoch: mem (CPU python)=5674.00390625MB; mem (CPU total)=5490.32421875MB
INFO:root:[   61] Training loss: 0.44922271, Validation loss: 0.46945857, Gradient norm: 4.72627481
INFO:root:At the start of the epoch: mem (CPU python)=5695.171875MB; mem (CPU total)=5511.54296875MB
INFO:root:[   62] Training loss: 0.45245051, Validation loss: 0.45173008, Gradient norm: 5.16229625
INFO:root:At the start of the epoch: mem (CPU python)=5716.33984375MB; mem (CPU total)=5532.51953125MB
INFO:root:[   63] Training loss: 0.45136865, Validation loss: 0.44545497, Gradient norm: 4.62279516
INFO:root:At the start of the epoch: mem (CPU python)=5737.51953125MB; mem (CPU total)=5553.734375MB
INFO:root:[   64] Training loss: 0.45432638, Validation loss: 0.47089894, Gradient norm: 5.33449436
INFO:root:At the start of the epoch: mem (CPU python)=5758.69921875MB; mem (CPU total)=5575.02734375MB
INFO:root:[   65] Training loss: 0.44366957, Validation loss: 0.47953712, Gradient norm: 4.42183907
INFO:root:At the start of the epoch: mem (CPU python)=5779.86328125MB; mem (CPU total)=5596.12109375MB
INFO:root:[   66] Training loss: 0.44904918, Validation loss: 0.44803427, Gradient norm: 5.62697028
INFO:root:At the start of the epoch: mem (CPU python)=5801.046875MB; mem (CPU total)=5617.53515625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   67] Training loss: 0.44204129, Validation loss: 0.43534289, Gradient norm: 5.03224727
INFO:root:At the start of the epoch: mem (CPU python)=5822.21484375MB; mem (CPU total)=5638.61328125MB
INFO:root:[   68] Training loss: 0.41635692, Validation loss: 0.42386688, Gradient norm: 4.29298987
INFO:root:At the start of the epoch: mem (CPU python)=5843.50390625MB; mem (CPU total)=5660.484375MB
INFO:root:[   69] Training loss: 0.41404099, Validation loss: 0.41825168, Gradient norm: 4.80556953
INFO:root:At the start of the epoch: mem (CPU python)=5864.6796875MB; mem (CPU total)=5681.015625MB
INFO:root:[   70] Training loss: 0.41289710, Validation loss: 0.42856109, Gradient norm: 4.82754122
INFO:root:At the start of the epoch: mem (CPU python)=5885.7578125MB; mem (CPU total)=5702.265625MB
INFO:root:[   71] Training loss: 0.41668352, Validation loss: 0.41825437, Gradient norm: 5.62114448
INFO:root:At the start of the epoch: mem (CPU python)=5907.9140625MB; mem (CPU total)=5724.6953125MB
INFO:root:[   72] Training loss: 0.41378612, Validation loss: 0.41794776, Gradient norm: 5.66565654
INFO:root:At the start of the epoch: mem (CPU python)=5929.56640625MB; mem (CPU total)=5745.86328125MB
INFO:root:[   73] Training loss: 0.41472448, Validation loss: 0.42011827, Gradient norm: 6.49035794
INFO:root:At the start of the epoch: mem (CPU python)=5950.73828125MB; mem (CPU total)=5767.421875MB
INFO:root:[   74] Training loss: 0.41435383, Validation loss: 0.42201233, Gradient norm: 6.73307124
INFO:root:At the start of the epoch: mem (CPU python)=5972.16015625MB; mem (CPU total)=5788.796875MB
INFO:root:[   75] Training loss: 0.41543685, Validation loss: 0.41204749, Gradient norm: 6.64307767
INFO:root:At the start of the epoch: mem (CPU python)=5993.33203125MB; mem (CPU total)=5810.18359375MB
INFO:root:[   76] Training loss: 0.41700970, Validation loss: 0.44289216, Gradient norm: 6.74400026
INFO:root:At the start of the epoch: mem (CPU python)=6014.625MB; mem (CPU total)=5831.328125MB
INFO:root:[   77] Training loss: 0.41815274, Validation loss: 0.42070741, Gradient norm: 7.80198222
INFO:root:At the start of the epoch: mem (CPU python)=6035.79296875MB; mem (CPU total)=5852.82421875MB
INFO:root:[   78] Training loss: 0.41800807, Validation loss: 0.41496332, Gradient norm: 7.49126882
INFO:root:At the start of the epoch: mem (CPU python)=6057.171875MB; mem (CPU total)=5874.5MB
INFO:root:[   79] Training loss: 0.41591997, Validation loss: 0.41497272, Gradient norm: 8.09922785
INFO:root:At the start of the epoch: mem (CPU python)=6078.46875MB; mem (CPU total)=5895.6640625MB
INFO:root:[   80] Training loss: 0.41564382, Validation loss: 0.43411110, Gradient norm: 7.42972101
INFO:root:At the start of the epoch: mem (CPU python)=6101.76953125MB; mem (CPU total)=5919.26171875MB
INFO:root:[   81] Training loss: 0.42010200, Validation loss: 0.43430587, Gradient norm: 9.26223357
INFO:root:At the start of the epoch: mem (CPU python)=6123.27734375MB; mem (CPU total)=5940.671875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   82] Training loss: 0.41827530, Validation loss: 0.41837777, Gradient norm: 9.00568481
INFO:root:At the start of the epoch: mem (CPU python)=6144.41796875MB; mem (CPU total)=5961.77734375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   83] Training loss: 0.40289831, Validation loss: 0.40000320, Gradient norm: 6.26578548
INFO:root:At the start of the epoch: mem (CPU python)=6165.79296875MB; mem (CPU total)=5982.671875MB
INFO:root:[   84] Training loss: 0.39470484, Validation loss: 0.39496941, Gradient norm: 6.64909263
INFO:root:At the start of the epoch: mem (CPU python)=6186.94140625MB; mem (CPU total)=6003.6015625MB
INFO:root:[   85] Training loss: 0.39094966, Validation loss: 0.39418517, Gradient norm: 5.01262676
INFO:root:At the start of the epoch: mem (CPU python)=6208.109375MB; mem (CPU total)=6024.9609375MB
INFO:root:[   86] Training loss: 0.39057289, Validation loss: 0.39469213, Gradient norm: 5.65241980
INFO:root:At the start of the epoch: mem (CPU python)=6229.2734375MB; mem (CPU total)=6045.7421875MB
INFO:root:[   87] Training loss: 0.39188639, Validation loss: 0.40980144, Gradient norm: 7.13525463
INFO:root:At the start of the epoch: mem (CPU python)=6250.55859375MB; mem (CPU total)=6067.38671875MB
INFO:root:[   88] Training loss: 0.39420251, Validation loss: 0.39507002, Gradient norm: 8.83642513
INFO:root:At the start of the epoch: mem (CPU python)=6271.72265625MB; mem (CPU total)=6088.54296875MB
INFO:root:[   89] Training loss: 0.39022643, Validation loss: 0.39409010, Gradient norm: 6.63482151
INFO:root:At the start of the epoch: mem (CPU python)=6292.88671875MB; mem (CPU total)=6109.703125MB
INFO:root:[   90] Training loss: 0.39027774, Validation loss: 0.39840861, Gradient norm: 7.54800449
INFO:root:At the start of the epoch: mem (CPU python)=6314.5234375MB; mem (CPU total)=6131.359375MB
INFO:root:[   91] Training loss: 0.39082178, Validation loss: 0.39409226, Gradient norm: 7.79172533
INFO:root:At the start of the epoch: mem (CPU python)=6335.6953125MB; mem (CPU total)=6152.52734375MB
INFO:root:[   92] Training loss: 0.39037080, Validation loss: 0.39775365, Gradient norm: 8.16658120
INFO:root:At the start of the epoch: mem (CPU python)=6357.21484375MB; mem (CPU total)=6174.17578125MB
INFO:root:[   93] Training loss: 0.38964802, Validation loss: 0.39662976, Gradient norm: 8.75669068
INFO:root:At the start of the epoch: mem (CPU python)=6378.37890625MB; mem (CPU total)=6195.34375MB
INFO:root:[   94] Training loss: 0.39060280, Validation loss: 0.39415297, Gradient norm: 9.65567635
INFO:root:At the start of the epoch: mem (CPU python)=6399.71484375MB; mem (CPU total)=6216.5078125MB
INFO:root:[   95] Training loss: 0.39159336, Validation loss: 0.40822465, Gradient norm: 9.58115883
INFO:root:At the start of the epoch: mem (CPU python)=6422.2890625MB; mem (CPU total)=6239.14453125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   96] Training loss: 0.39250056, Validation loss: 0.39301278, Gradient norm: 10.31950803
INFO:root:At the start of the epoch: mem (CPU python)=6443.453125MB; mem (CPU total)=6260.5546875MB
INFO:root:[   97] Training loss: 0.38728796, Validation loss: 0.39291070, Gradient norm: 6.68320681
INFO:root:At the start of the epoch: mem (CPU python)=6464.70703125MB; mem (CPU total)=6282.04296875MB
INFO:root:[   98] Training loss: 0.38616164, Validation loss: 0.38986880, Gradient norm: 6.88810862
INFO:root:At the start of the epoch: mem (CPU python)=6485.87109375MB; mem (CPU total)=6302.3203125MB
INFO:root:[   99] Training loss: 0.38607857, Validation loss: 0.38952361, Gradient norm: 7.85891931
INFO:root:At the start of the epoch: mem (CPU python)=6507.03515625MB; mem (CPU total)=6323.5234375MB
INFO:root:[  100] Training loss: 0.38668932, Validation loss: 0.39088890, Gradient norm: 7.81136935
INFO:root:At the start of the epoch: mem (CPU python)=6528.19921875MB; mem (CPU total)=6344.65234375MB
INFO:root:[  101] Training loss: 0.38643744, Validation loss: 0.39057239, Gradient norm: 9.11072904
INFO:root:At the start of the epoch: mem (CPU python)=6549.33203125MB; mem (CPU total)=6366.56640625MB
INFO:root:[  102] Training loss: 0.38653917, Validation loss: 0.39134864, Gradient norm: 8.94389766
INFO:root:At the start of the epoch: mem (CPU python)=6570.90625MB; mem (CPU total)=6387.734375MB
INFO:root:[  103] Training loss: 0.38526970, Validation loss: 0.39000858, Gradient norm: 9.60364332
INFO:root:At the start of the epoch: mem (CPU python)=6592.30859375MB; mem (CPU total)=6409.14453125MB
INFO:root:[  104] Training loss: 0.38652852, Validation loss: 0.39220732, Gradient norm: 9.96090917
INFO:root:At the start of the epoch: mem (CPU python)=6613.80078125MB; mem (CPU total)=6430.80078125MB
INFO:root:[  105] Training loss: 0.38585499, Validation loss: 0.39161353, Gradient norm: 10.78917872
INFO:root:At the start of the epoch: mem (CPU python)=6635.30078125MB; mem (CPU total)=6452.20703125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  106] Training loss: 0.38637220, Validation loss: 0.39014879, Gradient norm: 11.49839072
INFO:root:At the start of the epoch: mem (CPU python)=6656.68359375MB; mem (CPU total)=6473.39453125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  107] Training loss: 0.38449327, Validation loss: 0.38773426, Gradient norm: 7.57326667
INFO:root:At the start of the epoch: mem (CPU python)=6677.8515625MB; mem (CPU total)=6494.79296875MB
INFO:root:[  108] Training loss: 0.38325297, Validation loss: 0.38779465, Gradient norm: 5.50802134
INFO:root:At the start of the epoch: mem (CPU python)=6699.01171875MB; mem (CPU total)=6515.7265625MB
INFO:root:[  109] Training loss: 0.38270067, Validation loss: 0.38638176, Gradient norm: 6.84031345
INFO:root:At the start of the epoch: mem (CPU python)=6720.1796875MB; mem (CPU total)=6536.8671875MB
INFO:root:[  110] Training loss: 0.38246100, Validation loss: 0.38610696, Gradient norm: 6.49723670
INFO:root:At the start of the epoch: mem (CPU python)=6741.34375MB; mem (CPU total)=6557.984375MB
INFO:root:[  111] Training loss: 0.38310940, Validation loss: 0.38754385, Gradient norm: 5.78084228
INFO:root:At the start of the epoch: mem (CPU python)=6762.5078125MB; mem (CPU total)=6579.37890625MB
INFO:root:[  112] Training loss: 0.38291409, Validation loss: 0.38809464, Gradient norm: 6.42370683
INFO:root:At the start of the epoch: mem (CPU python)=6783.671875MB; mem (CPU total)=6600.51953125MB
INFO:root:[  113] Training loss: 0.38286846, Validation loss: 0.38662593, Gradient norm: 7.12895099
INFO:root:At the start of the epoch: mem (CPU python)=6804.83984375MB; mem (CPU total)=6621.67578125MB
INFO:root:[  114] Training loss: 0.38267504, Validation loss: 0.38910716, Gradient norm: 7.32600942
INFO:root:At the start of the epoch: mem (CPU python)=6826.00390625MB; mem (CPU total)=6642.83203125MB
INFO:root:[  115] Training loss: 0.38259108, Validation loss: 0.38781460, Gradient norm: 7.10545697
INFO:root:At the start of the epoch: mem (CPU python)=6848.2734375MB; mem (CPU total)=6665.47265625MB
INFO:root:[  116] Training loss: 0.38250061, Validation loss: 0.38653328, Gradient norm: 7.17357404
INFO:root:At the start of the epoch: mem (CPU python)=6869.828125MB; mem (CPU total)=6686.62890625MB
INFO:root:[  117] Training loss: 0.38228719, Validation loss: 0.38699479, Gradient norm: 7.91414370
INFO:root:At the start of the epoch: mem (CPU python)=6890.9921875MB; mem (CPU total)=6708.03515625MB
INFO:root:[  118] Training loss: 0.38251546, Validation loss: 0.38704511, Gradient norm: 7.62434838
INFO:root:At the start of the epoch: mem (CPU python)=6912.15625MB; mem (CPU total)=6729.1953125MB
INFO:root:[  119] Training loss: 0.38299915, Validation loss: 0.38815955, Gradient norm: 8.43028829
INFO:root:At the start of the epoch: mem (CPU python)=6933.32421875MB; mem (CPU total)=6750.3671875MB
INFO:root:[  120] Training loss: 0.38246174, Validation loss: 0.38593554, Gradient norm: 7.92348629
INFO:root:At the start of the epoch: mem (CPU python)=6954.48828125MB; mem (CPU total)=6771.4921875MB
INFO:root:[  121] Training loss: 0.38246271, Validation loss: 0.38670276, Gradient norm: 7.65586942
INFO:root:At the start of the epoch: mem (CPU python)=6975.65234375MB; mem (CPU total)=6792.6484375MB
INFO:root:[  122] Training loss: 0.38251000, Validation loss: 0.38665130, Gradient norm: 8.74727855
INFO:root:At the start of the epoch: mem (CPU python)=6996.8203125MB; mem (CPU total)=6813.80078125MB
INFO:root:[  123] Training loss: 0.38247265, Validation loss: 0.38652551, Gradient norm: 10.00724409
INFO:root:At the start of the epoch: mem (CPU python)=7017.984375MB; mem (CPU total)=6835.44921875MB
INFO:root:[  124] Training loss: 0.38322852, Validation loss: 0.38847187, Gradient norm: 9.36607454
INFO:root:At the start of the epoch: mem (CPU python)=7039.37890625MB; mem (CPU total)=6857.08984375MB
INFO:root:[  125] Training loss: 0.38187145, Validation loss: 0.38646915, Gradient norm: 10.37921302
INFO:root:At the start of the epoch: mem (CPU python)=7060.8125MB; mem (CPU total)=6877.77734375MB
INFO:root:[  126] Training loss: 0.38193557, Validation loss: 0.38588979, Gradient norm: 9.82214865
INFO:root:At the start of the epoch: mem (CPU python)=7082.1015625MB; mem (CPU total)=6898.953125MB
INFO:root:[  127] Training loss: 0.38298345, Validation loss: 0.38703201, Gradient norm: 11.70495810
INFO:root:At the start of the epoch: mem (CPU python)=7103.390625MB; mem (CPU total)=6920.09375MB
INFO:root:[  128] Training loss: 0.38303816, Validation loss: 0.38842590, Gradient norm: 12.73387492
INFO:root:At the start of the epoch: mem (CPU python)=7124.5546875MB; mem (CPU total)=6941.48828125MB
INFO:root:[  129] Training loss: 0.38249560, Validation loss: 0.38662089, Gradient norm: 10.91046016
INFO:root:At the start of the epoch: mem (CPU python)=7145.71875MB; mem (CPU total)=6962.640625MB
INFO:root:[  130] Training loss: 0.38280446, Validation loss: 0.38628160, Gradient norm: 10.42536300
INFO:root:At the start of the epoch: mem (CPU python)=7166.88671875MB; mem (CPU total)=6983.8046875MB
INFO:root:[  131] Training loss: 0.38267274, Validation loss: 0.38726218, Gradient norm: 11.43419297
INFO:root:At the start of the epoch: mem (CPU python)=7188.05078125MB; mem (CPU total)=7004.96875MB
INFO:root:[  132] Training loss: 0.38292899, Validation loss: 0.38770538, Gradient norm: 12.91667624
INFO:root:At the start of the epoch: mem (CPU python)=7210.1640625MB; mem (CPU total)=7027.109375MB
INFO:root:[  133] Training loss: 0.38304695, Validation loss: 0.38693543, Gradient norm: 12.63622139
INFO:root:At the start of the epoch: mem (CPU python)=7231.3671875MB; mem (CPU total)=7047.98828125MB
INFO:root:[  134] Training loss: 0.38233435, Validation loss: 0.38738199, Gradient norm: 10.43723988
INFO:root:At the start of the epoch: mem (CPU python)=7253.1796875MB; mem (CPU total)=7070.1328125MB
INFO:root:[  135] Training loss: 0.38262178, Validation loss: 0.38651758, Gradient norm: 11.23577726
INFO:root:At the start of the epoch: mem (CPU python)=7274.36328125MB; mem (CPU total)=7091.29296875MB
INFO:root:[  136] Training loss: 0.38289753, Validation loss: 0.38582665, Gradient norm: 12.65994980
INFO:root:At the start of the epoch: mem (CPU python)=7295.625MB; mem (CPU total)=7112.69140625MB
INFO:root:[  137] Training loss: 0.38265040, Validation loss: 0.38695933, Gradient norm: 13.52450272
INFO:root:At the start of the epoch: mem (CPU python)=7316.8046875MB; mem (CPU total)=7133.84375MB
INFO:root:[  138] Training loss: 0.38246821, Validation loss: 0.38613301, Gradient norm: 12.42583471
INFO:root:At the start of the epoch: mem (CPU python)=7337.96875MB; mem (CPU total)=7154.76171875MB
INFO:root:[  139] Training loss: 0.38271500, Validation loss: 0.38702535, Gradient norm: 13.15708506
INFO:root:At the start of the epoch: mem (CPU python)=7359.1328125MB; mem (CPU total)=7176.1640625MB
INFO:root:[  140] Training loss: 0.38326033, Validation loss: 0.38628820, Gradient norm: 12.81039267
INFO:root:At the start of the epoch: mem (CPU python)=7380.31640625MB; mem (CPU total)=7197.32421875MB
INFO:root:[  141] Training loss: 0.38224694, Validation loss: 0.38742893, Gradient norm: 12.57342832
INFO:root:At the start of the epoch: mem (CPU python)=7401.484375MB; mem (CPU total)=7218.484375MB
INFO:root:[  142] Training loss: 0.38276733, Validation loss: 0.38816354, Gradient norm: 17.20083443
INFO:root:At the start of the epoch: mem (CPU python)=7422.6640625MB; mem (CPU total)=7239.63671875MB
INFO:root:[  143] Training loss: 0.38274894, Validation loss: 0.38745598, Gradient norm: 13.94567053
INFO:root:At the start of the epoch: mem (CPU python)=7443.828125MB; mem (CPU total)=7261.03515625MB
INFO:root:[  144] Training loss: 0.38258122, Validation loss: 0.38699155, Gradient norm: 13.03624042
INFO:root:At the start of the epoch: mem (CPU python)=7465.01171875MB; mem (CPU total)=7282.1953125MB
INFO:root:[  145] Training loss: 0.38235061, Validation loss: 0.38613660, Gradient norm: 15.12600720
INFO:root:At the start of the epoch: mem (CPU python)=7486.54296875MB; mem (CPU total)=7304.33203125MB
INFO:root:EP 145: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=7507.51953125MB; mem (CPU total)=7325.49609375MB
INFO:root:Training the model took 3542.032s.
INFO:root:Emptying the cuda cache took 0.033s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.34251
INFO:root:EnergyScoreValidation: 0.25994
INFO:root:CRPSValidation: 0.10345
INFO:root:Gaussian NLLValidation: -0.02648
INFO:root:CoverageValidation: 0.754
INFO:root:IntervalWidthValidation: 0.37485
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.36347
INFO:root:EnergyScoreTest: 0.27894
INFO:root:CRPSTest: 0.11115
INFO:root:Gaussian NLLTest: 0.18581
INFO:root:CoverageTest: 0.73078
INFO:root:IntervalWidthTest: 0.37285
INFO:root:After validation: mem (CPU python)=7823.37109375MB; mem (CPU total)=7330.07421875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=7823.37109375MB; mem (CPU total)=7329.1953125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=7823.37109375MB; mem (CPU total)=7342.5703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7342.81640625MB
INFO:root:[    1] Training loss: 0.83613190, Validation loss: 0.74483995, Gradient norm: 0.47642193
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7366.59375MB
INFO:root:[    2] Training loss: 0.74033273, Validation loss: 0.74081696, Gradient norm: 0.32138638
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7387.50390625MB
INFO:root:[    3] Training loss: 0.73471337, Validation loss: 0.72813075, Gradient norm: 0.44381968
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7408.65625MB
INFO:root:[    4] Training loss: 0.71278792, Validation loss: 0.68616685, Gradient norm: 0.58456381
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7429.8125MB
INFO:root:[    5] Training loss: 0.66277704, Validation loss: 0.63484535, Gradient norm: 0.96535098
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7451.21875MB
INFO:root:[    6] Training loss: 0.62858580, Validation loss: 0.62186092, Gradient norm: 1.19442473
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7472.3828125MB
INFO:root:[    7] Training loss: 0.61732599, Validation loss: 0.60356244, Gradient norm: 1.27744507
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7493.546875MB
INFO:root:[    8] Training loss: 0.60759815, Validation loss: 0.59766281, Gradient norm: 1.49301374
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7515.1875MB
INFO:root:[    9] Training loss: 0.58980397, Validation loss: 0.57673916, Gradient norm: 1.38222159
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7536.83203125MB
INFO:root:[   10] Training loss: 0.57605605, Validation loss: 0.58561374, Gradient norm: 1.83401074
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7558.19921875MB
INFO:root:[   11] Training loss: 0.56225116, Validation loss: 0.57012210, Gradient norm: 1.74751853
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7579.31640625MB
INFO:root:[   12] Training loss: 0.54666572, Validation loss: 0.53210788, Gradient norm: 1.90134822
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7600.48046875MB
INFO:root:[   13] Training loss: 0.53113774, Validation loss: 0.52964793, Gradient norm: 2.09668403
INFO:root:At the start of the epoch: mem (CPU python)=7823.37109375MB; mem (CPU total)=7621.64453125MB
INFO:root:[   14] Training loss: 0.52363984, Validation loss: 0.52928094, Gradient norm: 1.80447970
INFO:root:At the start of the epoch: mem (CPU python)=7836.7421875MB; mem (CPU total)=7643.3203125MB
INFO:root:[   15] Training loss: 0.51868824, Validation loss: 0.51612420, Gradient norm: 2.32463850
INFO:root:At the start of the epoch: mem (CPU python)=7857.9140625MB; mem (CPU total)=7664.51171875MB
INFO:root:[   16] Training loss: 0.51114245, Validation loss: 0.50146578, Gradient norm: 1.85462793
INFO:root:At the start of the epoch: mem (CPU python)=7879.07421875MB; mem (CPU total)=7685.17578125MB
INFO:root:[   17] Training loss: 0.50938603, Validation loss: 0.49907540, Gradient norm: 2.68265992
INFO:root:At the start of the epoch: mem (CPU python)=7900.72265625MB; mem (CPU total)=7707.31640625MB
INFO:root:[   18] Training loss: 0.50423925, Validation loss: 0.49094088, Gradient norm: 2.34387328
INFO:root:At the start of the epoch: mem (CPU python)=7922.1640625MB; mem (CPU total)=7728.4765625MB
INFO:root:[   19] Training loss: 0.50379042, Validation loss: 0.50256114, Gradient norm: 2.62311984
INFO:root:At the start of the epoch: mem (CPU python)=7943.34375MB; mem (CPU total)=7749.6328125MB
INFO:root:[   20] Training loss: 0.49963966, Validation loss: 0.49187845, Gradient norm: 2.47205980
INFO:root:At the start of the epoch: mem (CPU python)=7964.51953125MB; mem (CPU total)=7770.7890625MB
INFO:root:[   21] Training loss: 0.49737738, Validation loss: 0.48231821, Gradient norm: 2.95726846
INFO:root:At the start of the epoch: mem (CPU python)=7985.69140625MB; mem (CPU total)=7792.1875MB
INFO:root:[   22] Training loss: 0.49638721, Validation loss: 0.50230031, Gradient norm: 2.78599692
INFO:root:At the start of the epoch: mem (CPU python)=8006.859375MB; mem (CPU total)=7813.6328125MB
INFO:root:[   23] Training loss: 0.49265669, Validation loss: 0.49003615, Gradient norm: 2.68155140
INFO:root:At the start of the epoch: mem (CPU python)=8028.03515625MB; mem (CPU total)=7835.0234375MB
INFO:root:[   24] Training loss: 0.48872251, Validation loss: 0.48141344, Gradient norm: 2.89329313
INFO:root:At the start of the epoch: mem (CPU python)=8049.203125MB; mem (CPU total)=7855.9296875MB
INFO:root:[   25] Training loss: 0.49044262, Validation loss: 0.48397664, Gradient norm: 2.66741219
INFO:root:At the start of the epoch: mem (CPU python)=8070.36328125MB; mem (CPU total)=7876.84375MB
INFO:root:[   26] Training loss: 0.48604058, Validation loss: 0.48820635, Gradient norm: 3.41851835
INFO:root:At the start of the epoch: mem (CPU python)=8091.54296875MB; mem (CPU total)=7897.41796875MB
INFO:root:[   27] Training loss: 0.48896089, Validation loss: 0.49035724, Gradient norm: 3.04887126
INFO:root:At the start of the epoch: mem (CPU python)=8112.71484375MB; mem (CPU total)=7918.578125MB
INFO:root:[   28] Training loss: 0.48403983, Validation loss: 0.49441101, Gradient norm: 2.90440369
INFO:root:At the start of the epoch: mem (CPU python)=8133.890625MB; mem (CPU total)=7939.7421875MB
INFO:root:[   29] Training loss: 0.48168171, Validation loss: 0.47156428, Gradient norm: 3.08375506
INFO:root:At the start of the epoch: mem (CPU python)=8155.0625MB; mem (CPU total)=7960.8984375MB
INFO:root:[   30] Training loss: 0.48066169, Validation loss: 0.48717292, Gradient norm: 3.26493364
INFO:root:At the start of the epoch: mem (CPU python)=8176.234375MB; mem (CPU total)=7982.05859375MB
INFO:root:[   31] Training loss: 0.48670431, Validation loss: 0.49043302, Gradient norm: 3.11239783
INFO:root:At the start of the epoch: mem (CPU python)=8197.40625MB; mem (CPU total)=8003.22265625MB
INFO:root:[   32] Training loss: 0.47551214, Validation loss: 0.47637650, Gradient norm: 3.00351100
INFO:root:At the start of the epoch: mem (CPU python)=8218.58203125MB; mem (CPU total)=8024.625MB
INFO:root:[   33] Training loss: 0.48055748, Validation loss: 0.49025825, Gradient norm: 3.50301719
INFO:root:At the start of the epoch: mem (CPU python)=8239.75MB; mem (CPU total)=8045.78515625MB
INFO:root:[   34] Training loss: 0.47815187, Validation loss: 0.51095981, Gradient norm: 3.34460635
INFO:root:At the start of the epoch: mem (CPU python)=8260.91796875MB; mem (CPU total)=8066.94140625MB
INFO:root:[   35] Training loss: 0.47772225, Validation loss: 0.47250895, Gradient norm: 3.41389193
INFO:root:At the start of the epoch: mem (CPU python)=8282.2734375MB; mem (CPU total)=8088.10546875MB
INFO:root:[   36] Training loss: 0.47580921, Validation loss: 0.50745060, Gradient norm: 3.56122452
INFO:root:At the start of the epoch: mem (CPU python)=8303.65234375MB; mem (CPU total)=8109.26953125MB
INFO:root:[   37] Training loss: 0.47726529, Validation loss: 0.48603720, Gradient norm: 3.33832159
INFO:root:At the start of the epoch: mem (CPU python)=8324.828125MB; mem (CPU total)=8130.42578125MB
INFO:root:[   38] Training loss: 0.47434553, Validation loss: 0.46613585, Gradient norm: 3.85571918
INFO:root:At the start of the epoch: mem (CPU python)=8345.9921875MB; mem (CPU total)=8152.0234375MB
INFO:root:[   39] Training loss: 0.47625956, Validation loss: 0.47125640, Gradient norm: 3.94773213
INFO:root:At the start of the epoch: mem (CPU python)=8367.203125MB; mem (CPU total)=8173.1015625MB
INFO:root:[   40] Training loss: 0.47440229, Validation loss: 0.46862434, Gradient norm: 3.92655518
INFO:root:At the start of the epoch: mem (CPU python)=8389.2265625MB; mem (CPU total)=8195.7421875MB
INFO:root:[   41] Training loss: 0.47938591, Validation loss: 0.47308695, Gradient norm: 3.72464488
INFO:root:At the start of the epoch: mem (CPU python)=8410.62890625MB; mem (CPU total)=8216.84765625MB
INFO:root:[   42] Training loss: 0.47095051, Validation loss: 0.48652649, Gradient norm: 3.62246547
INFO:root:At the start of the epoch: mem (CPU python)=8431.84765625MB; mem (CPU total)=8237.765625MB
INFO:root:[   43] Training loss: 0.47165693, Validation loss: 0.49154761, Gradient norm: 3.58085698
INFO:root:At the start of the epoch: mem (CPU python)=8453.0234375MB; mem (CPU total)=8259.17578125MB
INFO:root:[   44] Training loss: 0.46814097, Validation loss: 0.47739058, Gradient norm: 4.15333928
INFO:root:At the start of the epoch: mem (CPU python)=8474.1875MB; mem (CPU total)=8280.3359375MB
INFO:root:[   45] Training loss: 0.46461396, Validation loss: 0.46666665, Gradient norm: 3.56380764
INFO:root:At the start of the epoch: mem (CPU python)=8495.3515625MB; mem (CPU total)=8301.43359375MB
INFO:root:[   46] Training loss: 0.47162618, Validation loss: 0.47829900, Gradient norm: 4.44140341
INFO:root:At the start of the epoch: mem (CPU python)=8516.53515625MB; mem (CPU total)=8322.6015625MB
INFO:root:[   47] Training loss: 0.46635672, Validation loss: 0.46942757, Gradient norm: 4.14789278
INFO:root:At the start of the epoch: mem (CPU python)=8537.69921875MB; mem (CPU total)=8343.7734375MB
INFO:root:[   48] Training loss: 0.46875019, Validation loss: 0.47585589, Gradient norm: 4.37788342
INFO:root:At the start of the epoch: mem (CPU python)=8558.875MB; mem (CPU total)=8364.93359375MB
INFO:root:[   49] Training loss: 0.45401560, Validation loss: 0.44439191, Gradient norm: 4.88703751
INFO:root:At the start of the epoch: mem (CPU python)=8580.046875MB; mem (CPU total)=8386.34375MB
INFO:root:[   50] Training loss: 0.45340016, Validation loss: 0.45686265, Gradient norm: 4.50408965
INFO:root:At the start of the epoch: mem (CPU python)=8601.21875MB; mem (CPU total)=8407.5078125MB
INFO:root:[   51] Training loss: 0.44868873, Validation loss: 0.44167329, Gradient norm: 5.52122065
INFO:root:At the start of the epoch: mem (CPU python)=8622.390625MB; mem (CPU total)=8428.7109375MB
INFO:root:[   52] Training loss: 0.44364804, Validation loss: 0.44731845, Gradient norm: 4.83571762
INFO:root:At the start of the epoch: mem (CPU python)=8643.5703125MB; mem (CPU total)=8449.8828125MB
INFO:root:[   53] Training loss: 0.44534452, Validation loss: 0.45252920, Gradient norm: 4.77370708
INFO:root:At the start of the epoch: mem (CPU python)=8664.73828125MB; mem (CPU total)=8471.05078125MB
INFO:root:[   54] Training loss: 0.44499307, Validation loss: 0.45708614, Gradient norm: 4.91914936
INFO:root:At the start of the epoch: mem (CPU python)=8685.91015625MB; mem (CPU total)=8492.4609375MB
INFO:root:[   55] Training loss: 0.44660423, Validation loss: 0.43803786, Gradient norm: 5.24392261
INFO:root:At the start of the epoch: mem (CPU python)=8707.08203125MB; mem (CPU total)=8513.61328125MB
INFO:root:[   56] Training loss: 0.43844469, Validation loss: 0.44694921, Gradient norm: 4.60634206
INFO:root:At the start of the epoch: mem (CPU python)=8728.2421875MB; mem (CPU total)=8534.78515625MB
INFO:root:[   57] Training loss: 0.43887466, Validation loss: 0.44164421, Gradient norm: 5.05742423
INFO:root:At the start of the epoch: mem (CPU python)=8749.41796875MB; mem (CPU total)=8556.203125MB
INFO:root:[   58] Training loss: 0.44165242, Validation loss: 0.44411394, Gradient norm: 5.54964588
INFO:root:At the start of the epoch: mem (CPU python)=8770.5859375MB; mem (CPU total)=8577.37109375MB
INFO:root:[   59] Training loss: 0.43804275, Validation loss: 0.43773358, Gradient norm: 4.55017395
INFO:root:At the start of the epoch: mem (CPU python)=8792.52734375MB; mem (CPU total)=8599.5234375MB
INFO:root:[   60] Training loss: 0.43633248, Validation loss: 0.44662125, Gradient norm: 5.48247619
INFO:root:At the start of the epoch: mem (CPU python)=8814.0625MB; mem (CPU total)=8620.44140625MB
INFO:root:[   61] Training loss: 0.43722424, Validation loss: 0.45157982, Gradient norm: 4.79639213
INFO:root:At the start of the epoch: mem (CPU python)=8835.234375MB; mem (CPU total)=8641.61328125MB
INFO:root:[   62] Training loss: 0.43728145, Validation loss: 0.44543705, Gradient norm: 5.79385140
INFO:root:At the start of the epoch: mem (CPU python)=8856.40234375MB; mem (CPU total)=8663.0234375MB
INFO:root:[   63] Training loss: 0.44076646, Validation loss: 0.47365040, Gradient norm: 4.83744260
INFO:root:At the start of the epoch: mem (CPU python)=8877.7109375MB; mem (CPU total)=8684.66015625MB
INFO:root:[   64] Training loss: 0.43873510, Validation loss: 0.43771621, Gradient norm: 5.44565829
INFO:root:At the start of the epoch: mem (CPU python)=8899.12109375MB; mem (CPU total)=8705.8359375MB
INFO:root:[   65] Training loss: 0.44291991, Validation loss: 0.44641082, Gradient norm: 5.09474957
INFO:root:At the start of the epoch: mem (CPU python)=8920.30078125MB; mem (CPU total)=8727.25390625MB
INFO:root:[   66] Training loss: 0.42934073, Validation loss: 0.42737291, Gradient norm: 5.06427590
INFO:root:At the start of the epoch: mem (CPU python)=8941.46875MB; mem (CPU total)=8748.45703125MB
INFO:root:[   67] Training loss: 0.43527546, Validation loss: 0.46370810, Gradient norm: 5.92669089
INFO:root:At the start of the epoch: mem (CPU python)=8962.64453125MB; mem (CPU total)=8769.66015625MB
INFO:root:[   68] Training loss: 0.43513572, Validation loss: 0.46651611, Gradient norm: 5.29805070
INFO:root:At the start of the epoch: mem (CPU python)=8984.01953125MB; mem (CPU total)=8791.078125MB
INFO:root:[   69] Training loss: 0.44543904, Validation loss: 0.46082202, Gradient norm: 5.25383823
INFO:root:At the start of the epoch: mem (CPU python)=9006.30859375MB; mem (CPU total)=8813.47265625MB
INFO:root:[   70] Training loss: 0.43759237, Validation loss: 0.43163648, Gradient norm: 6.05102983
INFO:root:At the start of the epoch: mem (CPU python)=9027.484375MB; mem (CPU total)=8834.87109375MB
INFO:root:[   71] Training loss: 0.43757817, Validation loss: 0.44621627, Gradient norm: 5.30073224
INFO:root:At the start of the epoch: mem (CPU python)=9048.828125MB; mem (CPU total)=8855.78125MB
INFO:root:[   72] Training loss: 0.43580658, Validation loss: 0.46094982, Gradient norm: 5.53280027
INFO:root:At the start of the epoch: mem (CPU python)=9070.00390625MB; mem (CPU total)=8877.30078125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   73] Training loss: 0.44097916, Validation loss: 0.44175784, Gradient norm: 5.02885013
INFO:root:At the start of the epoch: mem (CPU python)=9091.16796875MB; mem (CPU total)=8898.6484375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   74] Training loss: 0.40387387, Validation loss: 0.41509645, Gradient norm: 4.50368763
INFO:root:At the start of the epoch: mem (CPU python)=9112.34765625MB; mem (CPU total)=8919.56640625MB
INFO:root:[   75] Training loss: 0.39475806, Validation loss: 0.40386321, Gradient norm: 3.25468957
INFO:root:At the start of the epoch: mem (CPU python)=9133.5078125MB; mem (CPU total)=8940.9765625MB
INFO:root:[   76] Training loss: 0.39246094, Validation loss: 0.40150231, Gradient norm: 3.87290650
INFO:root:At the start of the epoch: mem (CPU python)=9154.8125MB; mem (CPU total)=8962.3515625MB
INFO:root:[   77] Training loss: 0.39431998, Validation loss: 0.40095318, Gradient norm: 4.42777673
INFO:root:At the start of the epoch: mem (CPU python)=9176.234375MB; mem (CPU total)=8983.5390625MB
INFO:root:[   78] Training loss: 0.39348341, Validation loss: 0.40154761, Gradient norm: 4.97611855
INFO:root:At the start of the epoch: mem (CPU python)=9197.4140625MB; mem (CPU total)=9004.9375MB
INFO:root:[   79] Training loss: 0.39930398, Validation loss: 0.41511861, Gradient norm: 7.32844102
INFO:root:At the start of the epoch: mem (CPU python)=9218.578125MB; mem (CPU total)=9025.83203125MB
INFO:root:[   80] Training loss: 0.39633355, Validation loss: 0.40646955, Gradient norm: 6.54849333
INFO:root:At the start of the epoch: mem (CPU python)=9239.7421875MB; mem (CPU total)=9047.23046875MB
INFO:root:[   81] Training loss: 0.39564187, Validation loss: 0.40168289, Gradient norm: 6.21801872
INFO:root:At the start of the epoch: mem (CPU python)=9261.796875MB; mem (CPU total)=9070.10546875MB
INFO:root:[   82] Training loss: 0.39356636, Validation loss: 0.40723374, Gradient norm: 6.65355684
INFO:root:At the start of the epoch: mem (CPU python)=9283.2109375MB; mem (CPU total)=9091.0234375MB
INFO:root:[   83] Training loss: 0.39737958, Validation loss: 0.42556596, Gradient norm: 7.75131618
INFO:root:At the start of the epoch: mem (CPU python)=9304.39453125MB; mem (CPU total)=9112.1875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   84] Training loss: 0.39819329, Validation loss: 0.40912005, Gradient norm: 8.19283360
INFO:root:At the start of the epoch: mem (CPU python)=9325.55859375MB; mem (CPU total)=9133.3515625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   85] Training loss: 0.39288129, Validation loss: 0.40027482, Gradient norm: 6.23388203
INFO:root:At the start of the epoch: mem (CPU python)=9346.7421875MB; mem (CPU total)=9154.76171875MB
INFO:root:[   86] Training loss: 0.38646359, Validation loss: 0.39598533, Gradient norm: 4.65543884
INFO:root:At the start of the epoch: mem (CPU python)=9367.91015625MB; mem (CPU total)=9175.921875MB
INFO:root:[   87] Training loss: 0.38581491, Validation loss: 0.39730382, Gradient norm: 3.71730146
INFO:root:At the start of the epoch: mem (CPU python)=9389.0859375MB; mem (CPU total)=9197.08203125MB
INFO:root:[   88] Training loss: 0.38557328, Validation loss: 0.39639748, Gradient norm: 3.72360205
INFO:root:At the start of the epoch: mem (CPU python)=9410.25MB; mem (CPU total)=9218.23046875MB
INFO:root:[   89] Training loss: 0.38486267, Validation loss: 0.39731803, Gradient norm: 4.15592903
INFO:root:At the start of the epoch: mem (CPU python)=9431.42578125MB; mem (CPU total)=9239.5859375MB
INFO:root:[   90] Training loss: 0.38490332, Validation loss: 0.39502110, Gradient norm: 4.78256737
INFO:root:At the start of the epoch: mem (CPU python)=9453.58203125MB; mem (CPU total)=9261.9609375MB
INFO:root:[   91] Training loss: 0.38546509, Validation loss: 0.39720522, Gradient norm: 5.03443664
INFO:root:At the start of the epoch: mem (CPU python)=9474.75MB; mem (CPU total)=9282.88671875MB
INFO:root:[   92] Training loss: 0.38520640, Validation loss: 0.39580556, Gradient norm: 5.05178150
INFO:root:At the start of the epoch: mem (CPU python)=9496.0625MB; mem (CPU total)=9304.03125MB
INFO:root:[   93] Training loss: 0.38585614, Validation loss: 0.39916946, Gradient norm: 5.92933824
INFO:root:At the start of the epoch: mem (CPU python)=9518.02734375MB; mem (CPU total)=9326.4140625MB
INFO:root:[   94] Training loss: 0.38612907, Validation loss: 0.39396748, Gradient norm: 7.46778438
INFO:root:At the start of the epoch: mem (CPU python)=9539.4296875MB; mem (CPU total)=9347.44921875MB
INFO:root:[   95] Training loss: 0.38677376, Validation loss: 0.39690769, Gradient norm: 8.12001644
INFO:root:At the start of the epoch: mem (CPU python)=9560.70703125MB; mem (CPU total)=9368.8671875MB
INFO:root:[   96] Training loss: 0.38560046, Validation loss: 0.39568312, Gradient norm: 7.55839758
INFO:root:At the start of the epoch: mem (CPU python)=9581.875MB; mem (CPU total)=9389.7890625MB
INFO:root:[   97] Training loss: 0.38495388, Validation loss: 0.39500839, Gradient norm: 7.00065161
INFO:root:At the start of the epoch: mem (CPU python)=9603.05078125MB; mem (CPU total)=9410.94140625MB
INFO:root:[   98] Training loss: 0.38626761, Validation loss: 0.39565428, Gradient norm: 7.22887762
INFO:root:At the start of the epoch: mem (CPU python)=9625.4921875MB; mem (CPU total)=9433.54296875MB
INFO:root:[   99] Training loss: 0.38662509, Validation loss: 0.40160089, Gradient norm: 9.40139037
INFO:root:At the start of the epoch: mem (CPU python)=9646.89453125MB; mem (CPU total)=9454.71484375MB
INFO:root:[  100] Training loss: 0.38824109, Validation loss: 0.40129086, Gradient norm: 12.35655647
INFO:root:At the start of the epoch: mem (CPU python)=9668.0703125MB; mem (CPU total)=9476.29296875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  101] Training loss: 0.38768428, Validation loss: 0.39829630, Gradient norm: 10.64625724
INFO:root:At the start of the epoch: mem (CPU python)=9689.234375MB; mem (CPU total)=9497.30859375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  102] Training loss: 0.38408562, Validation loss: 0.39406414, Gradient norm: 6.15530059
INFO:root:At the start of the epoch: mem (CPU python)=9710.4140625MB; mem (CPU total)=9518.47265625MB
INFO:root:[  103] Training loss: 0.38400038, Validation loss: 0.39470200, Gradient norm: 4.28069228
INFO:root:At the start of the epoch: mem (CPU python)=9731.578125MB; mem (CPU total)=9539.65625MB
INFO:root:[  104] Training loss: 0.38269305, Validation loss: 0.39334514, Gradient norm: 4.31415214
INFO:root:At the start of the epoch: mem (CPU python)=9752.7578125MB; mem (CPU total)=9560.8125MB
INFO:root:[  105] Training loss: 0.38347979, Validation loss: 0.39369961, Gradient norm: 4.38040695
INFO:root:At the start of the epoch: mem (CPU python)=9773.92578125MB; mem (CPU total)=9581.96875MB
INFO:root:[  106] Training loss: 0.38328819, Validation loss: 0.39339598, Gradient norm: 5.04666885
INFO:root:At the start of the epoch: mem (CPU python)=9795.1015625MB; mem (CPU total)=9603.83984375MB
INFO:root:[  107] Training loss: 0.38375241, Validation loss: 0.39360824, Gradient norm: 5.66141709
INFO:root:At the start of the epoch: mem (CPU python)=9817.01171875MB; mem (CPU total)=9625.125MB
INFO:root:[  108] Training loss: 0.38385978, Validation loss: 0.39346043, Gradient norm: 4.86304387
INFO:root:At the start of the epoch: mem (CPU python)=9838.765625MB; mem (CPU total)=9647.42578125MB
INFO:root:[  109] Training loss: 0.38263587, Validation loss: 0.39355267, Gradient norm: 5.24266697
INFO:root:At the start of the epoch: mem (CPU python)=9859.9296875MB; mem (CPU total)=9668.1953125MB
INFO:root:[  110] Training loss: 0.38353416, Validation loss: 0.39373776, Gradient norm: 5.27733308
INFO:root:At the start of the epoch: mem (CPU python)=9881.28125MB; mem (CPU total)=9689.12109375MB
INFO:root:[  111] Training loss: 0.38328653, Validation loss: 0.39311282, Gradient norm: 5.02747915
INFO:root:At the start of the epoch: mem (CPU python)=9902.45703125MB; mem (CPU total)=9710.81640625MB
INFO:root:[  112] Training loss: 0.38296195, Validation loss: 0.39378012, Gradient norm: 5.61576722
INFO:root:At the start of the epoch: mem (CPU python)=9923.62109375MB; mem (CPU total)=9732.07421875MB
INFO:root:[  113] Training loss: 0.38381557, Validation loss: 0.39313432, Gradient norm: 6.02010017
INFO:root:At the start of the epoch: mem (CPU python)=9944.8046875MB; mem (CPU total)=9753.47265625MB
INFO:root:[  114] Training loss: 0.38343969, Validation loss: 0.39302654, Gradient norm: 6.19619299
INFO:root:At the start of the epoch: mem (CPU python)=9965.97265625MB; mem (CPU total)=9774.1875MB
INFO:root:[  115] Training loss: 0.38391259, Validation loss: 0.39448449, Gradient norm: 5.99298639
INFO:root:At the start of the epoch: mem (CPU python)=9987.15234375MB; mem (CPU total)=9795.359375MB
INFO:root:[  116] Training loss: 0.38367845, Validation loss: 0.39369813, Gradient norm: 6.60463360
INFO:root:At the start of the epoch: mem (CPU python)=10009.203125MB; mem (CPU total)=9818.0MB
INFO:root:[  117] Training loss: 0.38420060, Validation loss: 0.39484628, Gradient norm: 6.66251271
INFO:root:At the start of the epoch: mem (CPU python)=10033.94921875MB; mem (CPU total)=9842.8828125MB
INFO:root:[  118] Training loss: 0.38327776, Validation loss: 0.39463582, Gradient norm: 7.75166452
INFO:root:At the start of the epoch: mem (CPU python)=10055.36328125MB; mem (CPU total)=9864.05078125MB
INFO:root:[  119] Training loss: 0.38406978, Validation loss: 0.39387742, Gradient norm: 7.28377958
INFO:root:At the start of the epoch: mem (CPU python)=10076.5234375MB; mem (CPU total)=9884.734375MB
INFO:root:[  120] Training loss: 0.38360909, Validation loss: 0.39354778, Gradient norm: 7.54719672
INFO:root:At the start of the epoch: mem (CPU python)=10097.69140625MB; mem (CPU total)=9905.90234375MB
INFO:root:[  121] Training loss: 0.38336018, Validation loss: 0.39497830, Gradient norm: 8.34580555
INFO:root:At the start of the epoch: mem (CPU python)=10118.85546875MB; mem (CPU total)=9927.0703125MB
INFO:root:[  122] Training loss: 0.38376488, Validation loss: 0.39462201, Gradient norm: 8.32278002
INFO:root:At the start of the epoch: mem (CPU python)=10140.4921875MB; mem (CPU total)=9949.61328125MB
INFO:root:[  123] Training loss: 0.38357849, Validation loss: 0.39541290, Gradient norm: 7.03966596
INFO:root:At the start of the epoch: mem (CPU python)=10161.65625MB; mem (CPU total)=9970.35546875MB
INFO:root:EP 123: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=10183.09765625MB; mem (CPU total)=9991.27734375MB
INFO:root:Training the model took 3223.626s.
INFO:root:Emptying the cuda cache took 0.034s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.35012
INFO:root:EnergyScoreValidation: 0.26682
INFO:root:CRPSValidation: 0.10512
INFO:root:Gaussian NLLValidation: 0.01529
INFO:root:CoverageValidation: 0.74661
INFO:root:IntervalWidthValidation: 0.3748
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.37319
INFO:root:EnergyScoreTest: 0.28791
INFO:root:CRPSTest: 0.1147
INFO:root:Gaussian NLLTest: 0.31417
INFO:root:CoverageTest: 0.70938
INFO:root:IntervalWidthTest: 0.371
INFO:root:After validation: mem (CPU python)=10490.02734375MB; mem (CPU total)=9999.16796875MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=10490.02734375MB; mem (CPU total)=9999.171875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=10490.02734375MB; mem (CPU total)=9999.171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=9999.41796875MB
INFO:root:[    1] Training loss: 0.84318356, Validation loss: 0.74420653, Gradient norm: 0.47567241
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10021.2421875MB
INFO:root:[    2] Training loss: 0.74084361, Validation loss: 0.73895522, Gradient norm: 0.32114600
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10041.63671875MB
INFO:root:[    3] Training loss: 0.73224685, Validation loss: 0.71896538, Gradient norm: 0.38841615
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10063.109375MB
INFO:root:[    4] Training loss: 0.71612506, Validation loss: 0.71404349, Gradient norm: 0.50957593
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10084.53125MB
INFO:root:[    5] Training loss: 0.68625898, Validation loss: 0.66256365, Gradient norm: 0.72035487
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10106.09765625MB
INFO:root:[    6] Training loss: 0.64183012, Validation loss: 0.62216238, Gradient norm: 1.10854423
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10127.11328125MB
INFO:root:[    7] Training loss: 0.60399650, Validation loss: 0.59274895, Gradient norm: 1.07460296
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10148.2890625MB
INFO:root:[    8] Training loss: 0.58735455, Validation loss: 0.57260864, Gradient norm: 1.22773154
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10169.8515625MB
INFO:root:[    9] Training loss: 0.57784036, Validation loss: 0.57022898, Gradient norm: 1.67499642
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10190.62890625MB
INFO:root:[   10] Training loss: 0.56441685, Validation loss: 0.54936553, Gradient norm: 1.55183924
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10212.07421875MB
INFO:root:[   11] Training loss: 0.55062254, Validation loss: 0.54599383, Gradient norm: 1.62072526
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10233.6328125MB
INFO:root:[   12] Training loss: 0.54796597, Validation loss: 0.53596503, Gradient norm: 1.98345650
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10254.4140625MB
INFO:root:[   13] Training loss: 0.54044024, Validation loss: 0.53006862, Gradient norm: 2.10224952
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10276.5625MB
INFO:root:[   14] Training loss: 0.53092495, Validation loss: 0.53353886, Gradient norm: 1.93597400
INFO:root:At the start of the epoch: mem (CPU python)=10490.02734375MB; mem (CPU total)=10297.71875MB
INFO:root:[   15] Training loss: 0.52619120, Validation loss: 0.51851221, Gradient norm: 2.22741826
INFO:root:At the start of the epoch: mem (CPU python)=10509.71484375MB; mem (CPU total)=10318.87109375MB
INFO:root:[   16] Training loss: 0.52325358, Validation loss: 0.52281033, Gradient norm: 2.24603834
INFO:root:At the start of the epoch: mem (CPU python)=10530.8828125MB; mem (CPU total)=10340.03515625MB
INFO:root:[   17] Training loss: 0.51986089, Validation loss: 0.52931946, Gradient norm: 2.44961306
INFO:root:At the start of the epoch: mem (CPU python)=10552.046875MB; mem (CPU total)=10361.203125MB
INFO:root:[   18] Training loss: 0.52258363, Validation loss: 0.51573860, Gradient norm: 2.76349629
INFO:root:At the start of the epoch: mem (CPU python)=10573.2109375MB; mem (CPU total)=10382.12890625MB
INFO:root:[   19] Training loss: 0.51850665, Validation loss: 0.51702350, Gradient norm: 2.64458087
INFO:root:At the start of the epoch: mem (CPU python)=10594.4375MB; mem (CPU total)=10403.37890625MB
INFO:root:[   20] Training loss: 0.51835119, Validation loss: 0.51818885, Gradient norm: 2.75459456
INFO:root:At the start of the epoch: mem (CPU python)=10616.0390625MB; mem (CPU total)=10424.66796875MB
INFO:root:[   21] Training loss: 0.51374525, Validation loss: 0.50563688, Gradient norm: 2.82539277
INFO:root:At the start of the epoch: mem (CPU python)=10647.75390625MB; mem (CPU total)=10456.546875MB
INFO:root:[   22] Training loss: 0.51373211, Validation loss: 0.51339428, Gradient norm: 2.72075036
INFO:root:At the start of the epoch: mem (CPU python)=10668.9140625MB; mem (CPU total)=10477.71484375MB
INFO:root:[   23] Training loss: 0.51215092, Validation loss: 0.51667345, Gradient norm: 2.49129279
INFO:root:At the start of the epoch: mem (CPU python)=10690.16796875MB; mem (CPU total)=10498.8828125MB
INFO:root:[   24] Training loss: 0.51098051, Validation loss: 0.50629543, Gradient norm: 2.89287437
INFO:root:At the start of the epoch: mem (CPU python)=10711.328125MB; mem (CPU total)=10520.3125MB
INFO:root:[   25] Training loss: 0.50697196, Validation loss: 0.51160548, Gradient norm: 2.96489135
INFO:root:At the start of the epoch: mem (CPU python)=10732.4921875MB; mem (CPU total)=10541.48046875MB
INFO:root:[   26] Training loss: 0.50756054, Validation loss: 0.50121298, Gradient norm: 2.67677353
INFO:root:At the start of the epoch: mem (CPU python)=10753.66015625MB; mem (CPU total)=10562.90234375MB
INFO:root:[   27] Training loss: 0.51018705, Validation loss: 0.49445081, Gradient norm: 3.30235699
INFO:root:At the start of the epoch: mem (CPU python)=10774.82421875MB; mem (CPU total)=10584.07421875MB
INFO:root:[   28] Training loss: 0.50472036, Validation loss: 0.49977986, Gradient norm: 3.11874928
INFO:root:At the start of the epoch: mem (CPU python)=10795.98828125MB; mem (CPU total)=10605.22265625MB
INFO:root:[   29] Training loss: 0.50888367, Validation loss: 0.50803825, Gradient norm: 3.09535544
INFO:root:At the start of the epoch: mem (CPU python)=10817.15234375MB; mem (CPU total)=10626.63671875MB
INFO:root:[   30] Training loss: 0.50764903, Validation loss: 0.50905577, Gradient norm: 3.46106293
INFO:root:At the start of the epoch: mem (CPU python)=10838.31640625MB; mem (CPU total)=10647.796875MB
INFO:root:[   31] Training loss: 0.50324745, Validation loss: 0.50842117, Gradient norm: 3.14363244
INFO:root:At the start of the epoch: mem (CPU python)=10859.48046875MB; mem (CPU total)=10668.96875MB
INFO:root:[   32] Training loss: 0.50558440, Validation loss: 0.49304785, Gradient norm: 3.21904625
INFO:root:At the start of the epoch: mem (CPU python)=10880.66015625MB; mem (CPU total)=10690.14453125MB
INFO:root:[   33] Training loss: 0.49901666, Validation loss: 0.49040286, Gradient norm: 3.15870615
INFO:root:At the start of the epoch: mem (CPU python)=10901.8203125MB; mem (CPU total)=10711.07421875MB
INFO:root:[   34] Training loss: 0.50121087, Validation loss: 0.50886731, Gradient norm: 3.12301775
INFO:root:At the start of the epoch: mem (CPU python)=10922.984375MB; mem (CPU total)=10732.48828125MB
INFO:root:[   35] Training loss: 0.50255545, Validation loss: 0.49420846, Gradient norm: 3.53000189
INFO:root:At the start of the epoch: mem (CPU python)=10944.1484375MB; mem (CPU total)=10753.65234375MB
INFO:root:[   36] Training loss: 0.49722903, Validation loss: 0.49360963, Gradient norm: 3.62496468
INFO:root:At the start of the epoch: mem (CPU python)=10965.3125MB; mem (CPU total)=10775.05859375MB
INFO:root:[   37] Training loss: 0.49680032, Validation loss: 0.49226716, Gradient norm: 3.29596980
INFO:root:At the start of the epoch: mem (CPU python)=10986.48046875MB; mem (CPU total)=10796.2265625MB
INFO:root:[   38] Training loss: 0.49524059, Validation loss: 0.50293313, Gradient norm: 3.62049134
INFO:root:At the start of the epoch: mem (CPU python)=11007.64453125MB; mem (CPU total)=10817.38671875MB
INFO:root:[   39] Training loss: 0.49667885, Validation loss: 0.50263750, Gradient norm: 3.61543675
INFO:root:At the start of the epoch: mem (CPU python)=11029.08984375MB; mem (CPU total)=10838.81640625MB
INFO:root:[   40] Training loss: 0.49798510, Validation loss: 0.50057872, Gradient norm: 4.07724254
INFO:root:At the start of the epoch: mem (CPU python)=11050.61328125MB; mem (CPU total)=10860.6328125MB
INFO:root:[   41] Training loss: 0.49551402, Validation loss: 0.49660653, Gradient norm: 3.53950852
INFO:root:At the start of the epoch: mem (CPU python)=11071.97265625MB; mem (CPU total)=10881.9765625MB
INFO:root:[   42] Training loss: 0.49147085, Validation loss: 0.48546397, Gradient norm: 3.96122272
INFO:root:At the start of the epoch: mem (CPU python)=11093.13671875MB; mem (CPU total)=10903.12890625MB
INFO:root:[   43] Training loss: 0.49268670, Validation loss: 0.48841520, Gradient norm: 3.76682256
INFO:root:At the start of the epoch: mem (CPU python)=11114.86328125MB; mem (CPU total)=10924.89453125MB
INFO:root:[   44] Training loss: 0.49381096, Validation loss: 0.50418402, Gradient norm: 3.93360724
INFO:root:At the start of the epoch: mem (CPU python)=11138.1953125MB; mem (CPU total)=10948.37890625MB
INFO:root:[   45] Training loss: 0.48946258, Validation loss: 0.51561023, Gradient norm: 4.16049441
INFO:root:At the start of the epoch: mem (CPU python)=11159.359375MB; mem (CPU total)=10969.6171875MB
INFO:root:[   46] Training loss: 0.49782198, Validation loss: 0.49784731, Gradient norm: 4.14025617
INFO:root:At the start of the epoch: mem (CPU python)=11180.8671875MB; mem (CPU total)=10991.53125MB
INFO:root:[   47] Training loss: 0.49406308, Validation loss: 0.51897847, Gradient norm: 3.82499695
INFO:root:At the start of the epoch: mem (CPU python)=11202.03125MB; mem (CPU total)=11012.671875MB
INFO:root:[   48] Training loss: 0.49209599, Validation loss: 0.51572822, Gradient norm: 4.21325535
INFO:root:At the start of the epoch: mem (CPU python)=11223.1953125MB; mem (CPU total)=11033.5703125MB
INFO:root:[   49] Training loss: 0.49114935, Validation loss: 0.48495621, Gradient norm: 4.06961186
INFO:root:At the start of the epoch: mem (CPU python)=11244.36328125MB; mem (CPU total)=11054.75390625MB
INFO:root:[   50] Training loss: 0.48765300, Validation loss: 0.47190063, Gradient norm: 4.01660712
INFO:root:At the start of the epoch: mem (CPU python)=11265.52734375MB; mem (CPU total)=11076.15625MB
INFO:root:[   51] Training loss: 0.49025693, Validation loss: 0.50920455, Gradient norm: 4.02563502
INFO:root:At the start of the epoch: mem (CPU python)=11286.69140625MB; mem (CPU total)=11097.3125MB
INFO:root:[   52] Training loss: 0.49195123, Validation loss: 0.49484331, Gradient norm: 4.00889111
INFO:root:At the start of the epoch: mem (CPU python)=11308.65234375MB; mem (CPU total)=11119.6953125MB
INFO:root:[   53] Training loss: 0.48865492, Validation loss: 0.48973600, Gradient norm: 4.25549818
INFO:root:At the start of the epoch: mem (CPU python)=11329.81640625MB; mem (CPU total)=11140.7890625MB
INFO:root:[   54] Training loss: 0.48515103, Validation loss: 0.47833611, Gradient norm: 4.12229087
INFO:root:At the start of the epoch: mem (CPU python)=11351.3125MB; mem (CPU total)=11161.93359375MB
INFO:root:[   55] Training loss: 0.48618654, Validation loss: 0.47042837, Gradient norm: 4.11018584
INFO:root:At the start of the epoch: mem (CPU python)=11372.4765625MB; mem (CPU total)=11183.640625MB
INFO:root:[   56] Training loss: 0.49559951, Validation loss: 0.50033193, Gradient norm: 4.56503195
INFO:root:At the start of the epoch: mem (CPU python)=11393.63671875MB; mem (CPU total)=11204.546875MB
INFO:root:[   57] Training loss: 0.48394235, Validation loss: 0.48939072, Gradient norm: 4.14972482
INFO:root:At the start of the epoch: mem (CPU python)=11414.80078125MB; mem (CPU total)=11225.6875MB
INFO:root:[   58] Training loss: 0.48759307, Validation loss: 0.51782664, Gradient norm: 4.20977871
INFO:root:At the start of the epoch: mem (CPU python)=11435.96484375MB; mem (CPU total)=11246.83984375MB
INFO:root:[   59] Training loss: 0.48461157, Validation loss: 0.49946674, Gradient norm: 4.15387863
INFO:root:At the start of the epoch: mem (CPU python)=11458.46484375MB; mem (CPU total)=11269.46875MB
INFO:root:[   60] Training loss: 0.49169993, Validation loss: 0.47748027, Gradient norm: 4.69281174
INFO:root:At the start of the epoch: mem (CPU python)=11479.6328125MB; mem (CPU total)=11290.6328125MB
INFO:root:[   61] Training loss: 0.48764789, Validation loss: 0.48701719, Gradient norm: 4.19821746
INFO:root:At the start of the epoch: mem (CPU python)=11500.95703125MB; mem (CPU total)=11312.04296875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   62] Training loss: 0.48140022, Validation loss: 0.51955860, Gradient norm: 3.94472378
INFO:root:At the start of the epoch: mem (CPU python)=11522.12109375MB; mem (CPU total)=11333.19921875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   63] Training loss: 0.46142241, Validation loss: 0.45687190, Gradient norm: 3.17891522
INFO:root:At the start of the epoch: mem (CPU python)=11543.28515625MB; mem (CPU total)=11354.3828125MB
INFO:root:[   64] Training loss: 0.45007195, Validation loss: 0.45256010, Gradient norm: 2.53791220
INFO:root:At the start of the epoch: mem (CPU python)=11564.44921875MB; mem (CPU total)=11375.53125MB
INFO:root:[   65] Training loss: 0.44914548, Validation loss: 0.45515809, Gradient norm: 3.05416000
INFO:root:At the start of the epoch: mem (CPU python)=11585.61328125MB; mem (CPU total)=11396.67578125MB
INFO:root:[   66] Training loss: 0.45069764, Validation loss: 0.45060683, Gradient norm: 3.82463136
INFO:root:At the start of the epoch: mem (CPU python)=11606.78125MB; mem (CPU total)=11417.80859375MB
INFO:root:[   67] Training loss: 0.44998992, Validation loss: 0.45064513, Gradient norm: 4.24873675
INFO:root:At the start of the epoch: mem (CPU python)=11627.9453125MB; mem (CPU total)=11439.23828125MB
INFO:root:[   68] Training loss: 0.44914472, Validation loss: 0.45283216, Gradient norm: 4.59940704
INFO:root:At the start of the epoch: mem (CPU python)=11649.109375MB; mem (CPU total)=11460.3828125MB
INFO:root:[   69] Training loss: 0.44927886, Validation loss: 0.45178065, Gradient norm: 4.91840754
INFO:root:At the start of the epoch: mem (CPU python)=11670.2734375MB; mem (CPU total)=11481.53515625MB
INFO:root:[   70] Training loss: 0.44929017, Validation loss: 0.45516506, Gradient norm: 5.16177494
INFO:root:At the start of the epoch: mem (CPU python)=11691.4375MB; mem (CPU total)=11502.94140625MB
INFO:root:[   71] Training loss: 0.45009316, Validation loss: 0.45575405, Gradient norm: 5.80604421
INFO:root:At the start of the epoch: mem (CPU python)=11712.6015625MB; mem (CPU total)=11523.79296875MB
INFO:root:[   72] Training loss: 0.45092659, Validation loss: 0.45403243, Gradient norm: 6.03471248
INFO:root:At the start of the epoch: mem (CPU python)=11733.76171875MB; mem (CPU total)=11544.95703125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   73] Training loss: 0.45093794, Validation loss: 0.45429708, Gradient norm: 6.31790493
INFO:root:At the start of the epoch: mem (CPU python)=11754.92578125MB; mem (CPU total)=11566.3515625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   74] Training loss: 0.44751154, Validation loss: 0.44904081, Gradient norm: 5.17978623
INFO:root:At the start of the epoch: mem (CPU python)=11776.08984375MB; mem (CPU total)=11587.4140625MB
INFO:root:[   75] Training loss: 0.44370294, Validation loss: 0.44653217, Gradient norm: 3.57393324
INFO:root:At the start of the epoch: mem (CPU python)=11797.25390625MB; mem (CPU total)=11608.55859375MB
INFO:root:[   76] Training loss: 0.44295251, Validation loss: 0.44639358, Gradient norm: 3.25691980
INFO:root:At the start of the epoch: mem (CPU python)=11818.421875MB; mem (CPU total)=11629.70703125MB
INFO:root:[   77] Training loss: 0.44284031, Validation loss: 0.44699246, Gradient norm: 3.35702757
INFO:root:At the start of the epoch: mem (CPU python)=11839.5859375MB; mem (CPU total)=11651.08203125MB
INFO:root:[   78] Training loss: 0.44318631, Validation loss: 0.44789460, Gradient norm: 4.00881551
INFO:root:At the start of the epoch: mem (CPU python)=11862.35546875MB; mem (CPU total)=11674.21484375MB
INFO:root:[   79] Training loss: 0.44349146, Validation loss: 0.44752695, Gradient norm: 4.19695798
INFO:root:At the start of the epoch: mem (CPU python)=11883.79296875MB; mem (CPU total)=11695.37890625MB
INFO:root:[   80] Training loss: 0.44284207, Validation loss: 0.44683286, Gradient norm: 4.05069094
INFO:root:At the start of the epoch: mem (CPU python)=11904.953125MB; mem (CPU total)=11716.53515625MB
INFO:root:[   81] Training loss: 0.44253520, Validation loss: 0.44584823, Gradient norm: 4.27535322
INFO:root:At the start of the epoch: mem (CPU python)=11926.12109375MB; mem (CPU total)=11737.97265625MB
INFO:root:[   82] Training loss: 0.44253487, Validation loss: 0.44555229, Gradient norm: 4.93536066
INFO:root:At the start of the epoch: mem (CPU python)=11947.28515625MB; mem (CPU total)=11759.13671875MB
INFO:root:[   83] Training loss: 0.44382644, Validation loss: 0.44674590, Gradient norm: 6.36056045
INFO:root:At the start of the epoch: mem (CPU python)=11968.44921875MB; mem (CPU total)=11780.54296875MB
INFO:root:[   84] Training loss: 0.44315354, Validation loss: 0.44538762, Gradient norm: 6.64485800
INFO:root:At the start of the epoch: mem (CPU python)=11989.61328125MB; mem (CPU total)=11801.69140625MB
INFO:root:[   85] Training loss: 0.44304599, Validation loss: 0.44573424, Gradient norm: 5.74425817
INFO:root:At the start of the epoch: mem (CPU python)=12011.88671875MB; mem (CPU total)=11824.35546875MB
INFO:root:[   86] Training loss: 0.44292145, Validation loss: 0.44551620, Gradient norm: 5.59149122
INFO:root:At the start of the epoch: mem (CPU python)=12033.05078125MB; mem (CPU total)=11845.5078125MB
INFO:root:[   87] Training loss: 0.44294042, Validation loss: 0.44832961, Gradient norm: 5.98308310
INFO:root:At the start of the epoch: mem (CPU python)=12054.60546875MB; mem (CPU total)=11866.66796875MB
INFO:root:[   88] Training loss: 0.44246064, Validation loss: 0.44705102, Gradient norm: 6.27729077
INFO:root:At the start of the epoch: mem (CPU python)=12075.7734375MB; mem (CPU total)=11888.8125MB
INFO:root:[   89] Training loss: 0.44319025, Validation loss: 0.44600318, Gradient norm: 6.76080011
INFO:root:At the start of the epoch: mem (CPU python)=12096.93359375MB; mem (CPU total)=11909.94921875MB
INFO:root:[   90] Training loss: 0.44329483, Validation loss: 0.44491784, Gradient norm: 7.23822868
INFO:root:At the start of the epoch: mem (CPU python)=12118.09375MB; mem (CPU total)=11931.08203125MB
INFO:root:[   91] Training loss: 0.44333200, Validation loss: 0.44701573, Gradient norm: 7.32274723
INFO:root:At the start of the epoch: mem (CPU python)=12139.2578125MB; mem (CPU total)=11952.24609375MB
INFO:root:[   92] Training loss: 0.44247364, Validation loss: 0.44598698, Gradient norm: 7.79149653
INFO:root:At the start of the epoch: mem (CPU python)=12160.421875MB; mem (CPU total)=11973.40234375MB
INFO:root:[   93] Training loss: 0.44357207, Validation loss: 0.44558106, Gradient norm: 7.82786966
INFO:root:At the start of the epoch: mem (CPU python)=12181.5859375MB; mem (CPU total)=11994.3046875MB
INFO:root:[   94] Training loss: 0.44308044, Validation loss: 0.44702520, Gradient norm: 8.35233419
INFO:root:At the start of the epoch: mem (CPU python)=12202.75390625MB; mem (CPU total)=12015.7109375MB
INFO:root:[   95] Training loss: 0.44410515, Validation loss: 0.44708306, Gradient norm: 8.61090399
INFO:root:At the start of the epoch: mem (CPU python)=12223.91796875MB; mem (CPU total)=12036.828125MB
INFO:root:[   96] Training loss: 0.44312503, Validation loss: 0.44701060, Gradient norm: 9.08256160
INFO:root:At the start of the epoch: mem (CPU python)=12245.08203125MB; mem (CPU total)=12057.984375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   97] Training loss: 0.44313812, Validation loss: 0.45149286, Gradient norm: 8.93685230
INFO:root:At the start of the epoch: mem (CPU python)=12266.24609375MB; mem (CPU total)=12079.12890625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   98] Training loss: 0.44180097, Validation loss: 0.44469045, Gradient norm: 6.73394761
INFO:root:At the start of the epoch: mem (CPU python)=12287.4140625MB; mem (CPU total)=12100.27734375MB
INFO:root:[   99] Training loss: 0.44089761, Validation loss: 0.44408364, Gradient norm: 4.96550475
INFO:root:At the start of the epoch: mem (CPU python)=12308.57421875MB; mem (CPU total)=12121.6796875MB
INFO:root:[  100] Training loss: 0.44120887, Validation loss: 0.44372640, Gradient norm: 5.43318233
INFO:root:At the start of the epoch: mem (CPU python)=12329.73828125MB; mem (CPU total)=12142.5859375MB
INFO:root:[  101] Training loss: 0.44071745, Validation loss: 0.44513483, Gradient norm: 5.43019597
INFO:root:At the start of the epoch: mem (CPU python)=12350.90625MB; mem (CPU total)=12163.7421875MB
INFO:root:[  102] Training loss: 0.44134930, Validation loss: 0.44348738, Gradient norm: 5.20015972
INFO:root:At the start of the epoch: mem (CPU python)=12372.0703125MB; mem (CPU total)=12184.921875MB
INFO:root:[  103] Training loss: 0.44121990, Validation loss: 0.44365788, Gradient norm: 6.18051719
INFO:root:At the start of the epoch: mem (CPU python)=12393.234375MB; mem (CPU total)=12206.32421875MB
INFO:root:[  104] Training loss: 0.44159067, Validation loss: 0.44541899, Gradient norm: 5.95861772
INFO:root:At the start of the epoch: mem (CPU python)=12414.40234375MB; mem (CPU total)=12227.484375MB
INFO:root:[  105] Training loss: 0.44075999, Validation loss: 0.44472308, Gradient norm: 5.96663757
INFO:root:At the start of the epoch: mem (CPU python)=12435.56640625MB; mem (CPU total)=12248.64453125MB
INFO:root:[  106] Training loss: 0.44099445, Validation loss: 0.44393779, Gradient norm: 5.97339505
INFO:root:At the start of the epoch: mem (CPU python)=12456.7265625MB; mem (CPU total)=12269.79296875MB
INFO:root:[  107] Training loss: 0.44133603, Validation loss: 0.44387699, Gradient norm: 6.34377280
INFO:root:At the start of the epoch: mem (CPU python)=12477.890625MB; mem (CPU total)=12290.93359375MB
INFO:root:[  108] Training loss: 0.44053701, Validation loss: 0.44438625, Gradient norm: 6.54145553
INFO:root:At the start of the epoch: mem (CPU python)=12499.0546875MB; mem (CPU total)=12312.33203125MB
INFO:root:[  109] Training loss: 0.44090173, Validation loss: 0.44481244, Gradient norm: 6.58688101
INFO:root:At the start of the epoch: mem (CPU python)=12520.21875MB; mem (CPU total)=12333.69140625MB
INFO:root:[  110] Training loss: 0.44159779, Validation loss: 0.44426926, Gradient norm: 7.20005292
INFO:root:At the start of the epoch: mem (CPU python)=12541.3828125MB; mem (CPU total)=12355.07421875MB
INFO:root:[  111] Training loss: 0.44062786, Validation loss: 0.44405120, Gradient norm: 7.80662256
INFO:root:At the start of the epoch: mem (CPU python)=12562.546875MB; mem (CPU total)=12376.22265625MB
INFO:root:EP 111: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12583.7109375MB; mem (CPU total)=12397.13671875MB
INFO:root:Training the model took 3165.271s.
INFO:root:Emptying the cuda cache took 0.035s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.40802
INFO:root:EnergyScoreValidation: 0.32062
INFO:root:CRPSValidation: 0.13684
INFO:root:Gaussian NLLValidation: 1.57654
INFO:root:CoverageValidation: 0.5985
INFO:root:IntervalWidthValidation: 0.36466
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.42872
INFO:root:EnergyScoreTest: 0.34023
INFO:root:CRPSTest: 0.14476
INFO:root:Gaussian NLLTest: 1.85867
INFO:root:CoverageTest: 0.5762
INFO:root:IntervalWidthTest: 0.36083
INFO:root:After validation: mem (CPU python)=12890.34375MB; mem (CPU total)=12404.62109375MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12890.34375MB; mem (CPU total)=12404.6171875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=12890.34375MB; mem (CPU total)=12404.6171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12404.61328125MB
INFO:root:[    1] Training loss: 0.84074616, Validation loss: 0.74542628, Gradient norm: 0.48069239
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12429.3984375MB
INFO:root:[    2] Training loss: 0.74121849, Validation loss: 0.73910888, Gradient norm: 0.38069165
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12451.7890625MB
INFO:root:[    3] Training loss: 0.73630100, Validation loss: 0.72666589, Gradient norm: 0.43927918
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12473.1328125MB
INFO:root:[    4] Training loss: 0.71984989, Validation loss: 0.71141334, Gradient norm: 0.63750536
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12494.3203125MB
INFO:root:[    5] Training loss: 0.68208035, Validation loss: 0.66475070, Gradient norm: 0.83714767
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12515.73828125MB
INFO:root:[    6] Training loss: 0.63832690, Validation loss: 0.62927308, Gradient norm: 1.40906444
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12538.4765625MB
INFO:root:[    7] Training loss: 0.60160333, Validation loss: 0.57741637, Gradient norm: 1.43666486
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12558.06640625MB
INFO:root:[    8] Training loss: 0.58191526, Validation loss: 0.56277509, Gradient norm: 1.53447964
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12579.01171875MB
INFO:root:[    9] Training loss: 0.56431312, Validation loss: 0.57424871, Gradient norm: 1.48333166
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12600.17578125MB
INFO:root:[   10] Training loss: 0.55931642, Validation loss: 0.55171500, Gradient norm: 1.98353969
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12621.33984375MB
INFO:root:[   11] Training loss: 0.54812869, Validation loss: 0.53710416, Gradient norm: 1.87429188
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12642.5MB
INFO:root:[   12] Training loss: 0.53542300, Validation loss: 0.52812601, Gradient norm: 1.96814084
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12663.87890625MB
INFO:root:[   13] Training loss: 0.52649435, Validation loss: 0.51554757, Gradient norm: 2.45948943
INFO:root:At the start of the epoch: mem (CPU python)=12890.34375MB; mem (CPU total)=12685.046875MB
INFO:root:[   14] Training loss: 0.51987758, Validation loss: 0.51183239, Gradient norm: 2.32075857
INFO:root:At the start of the epoch: mem (CPU python)=12891.14453125MB; mem (CPU total)=12706.17578125MB
INFO:root:[   15] Training loss: 0.51074212, Validation loss: 0.49655030, Gradient norm: 2.32977355
INFO:root:At the start of the epoch: mem (CPU python)=12912.3125MB; mem (CPU total)=12727.16015625MB
INFO:root:[   16] Training loss: 0.50921731, Validation loss: 0.50272022, Gradient norm: 3.09425737
INFO:root:At the start of the epoch: mem (CPU python)=12933.4765625MB; mem (CPU total)=12748.58203125MB
INFO:root:[   17] Training loss: 0.50644230, Validation loss: 0.49628508, Gradient norm: 2.78095941
INFO:root:At the start of the epoch: mem (CPU python)=12954.7578125MB; mem (CPU total)=12770.17578125MB
INFO:root:[   18] Training loss: 0.50187411, Validation loss: 0.50416672, Gradient norm: 2.66272713
INFO:root:At the start of the epoch: mem (CPU python)=12975.921875MB; mem (CPU total)=12790.94140625MB
INFO:root:[   19] Training loss: 0.49745926, Validation loss: 0.49498900, Gradient norm: 2.85499797
INFO:root:At the start of the epoch: mem (CPU python)=12997.0859375MB; mem (CPU total)=12812.109375MB
INFO:root:[   20] Training loss: 0.49366764, Validation loss: 0.48839595, Gradient norm: 3.39226014
INFO:root:At the start of the epoch: mem (CPU python)=13018.25390625MB; mem (CPU total)=12833.5234375MB
INFO:root:[   21] Training loss: 0.49453609, Validation loss: 0.48545085, Gradient norm: 3.52608939
INFO:root:At the start of the epoch: mem (CPU python)=13039.41796875MB; mem (CPU total)=12854.69921875MB
INFO:root:[   22] Training loss: 0.48973980, Validation loss: 0.49374808, Gradient norm: 3.07467136
INFO:root:At the start of the epoch: mem (CPU python)=13060.58203125MB; mem (CPU total)=12875.875MB
INFO:root:[   23] Training loss: 0.49391465, Validation loss: 0.49868858, Gradient norm: 3.09231101
INFO:root:At the start of the epoch: mem (CPU python)=13081.74609375MB; mem (CPU total)=12897.04296875MB
INFO:root:[   24] Training loss: 0.48823230, Validation loss: 0.48524256, Gradient norm: 3.33728547
INFO:root:At the start of the epoch: mem (CPU python)=13102.90625MB; mem (CPU total)=12918.21875MB
INFO:root:[   25] Training loss: 0.48500512, Validation loss: 0.48901196, Gradient norm: 3.22885017
INFO:root:At the start of the epoch: mem (CPU python)=13124.0703125MB; mem (CPU total)=12939.609375MB
INFO:root:[   26] Training loss: 0.49105063, Validation loss: 0.50807911, Gradient norm: 3.36532039
INFO:root:At the start of the epoch: mem (CPU python)=13145.23046875MB; mem (CPU total)=12960.75MB
INFO:root:[   27] Training loss: 0.48619104, Validation loss: 0.48176599, Gradient norm: 3.45316554
INFO:root:At the start of the epoch: mem (CPU python)=13166.40234375MB; mem (CPU total)=12981.92578125MB
INFO:root:[   28] Training loss: 0.48272758, Validation loss: 0.47891232, Gradient norm: 3.54572994
INFO:root:At the start of the epoch: mem (CPU python)=13187.5625MB; mem (CPU total)=13003.12109375MB
INFO:root:[   29] Training loss: 0.48401061, Validation loss: 0.47862834, Gradient norm: 3.22812792
INFO:root:At the start of the epoch: mem (CPU python)=13208.7265625MB; mem (CPU total)=13024.29296875MB
INFO:root:[   30] Training loss: 0.47838920, Validation loss: 0.48187636, Gradient norm: 3.41082439
INFO:root:At the start of the epoch: mem (CPU python)=13229.890625MB; mem (CPU total)=13045.20703125MB
INFO:root:[   31] Training loss: 0.48187046, Validation loss: 0.47268550, Gradient norm: 4.12503595
INFO:root:At the start of the epoch: mem (CPU python)=13251.0546875MB; mem (CPU total)=13066.359375MB
INFO:root:[   32] Training loss: 0.48029728, Validation loss: 0.48145762, Gradient norm: 3.62026166
INFO:root:At the start of the epoch: mem (CPU python)=13272.21875MB; mem (CPU total)=13087.9140625MB
INFO:root:[   33] Training loss: 0.48009123, Validation loss: 0.48343422, Gradient norm: 3.48856141
INFO:root:At the start of the epoch: mem (CPU python)=13293.3828125MB; mem (CPU total)=13108.6953125MB
INFO:root:[   34] Training loss: 0.47954248, Validation loss: 0.49304675, Gradient norm: 3.27953922
INFO:root:At the start of the epoch: mem (CPU python)=13314.546875MB; mem (CPU total)=13130.109375MB
INFO:root:[   35] Training loss: 0.48002565, Validation loss: 0.46529164, Gradient norm: 3.77460515
INFO:root:At the start of the epoch: mem (CPU python)=13335.7109375MB; mem (CPU total)=13151.28125MB
INFO:root:[   36] Training loss: 0.47826429, Validation loss: 0.49134000, Gradient norm: 3.62198434
INFO:root:At the start of the epoch: mem (CPU python)=13356.875MB; mem (CPU total)=13173.22265625MB
INFO:root:[   37] Training loss: 0.47599622, Validation loss: 0.46887045, Gradient norm: 3.62501783
INFO:root:At the start of the epoch: mem (CPU python)=13378.0390625MB; mem (CPU total)=13194.36328125MB
INFO:root:[   38] Training loss: 0.48131403, Validation loss: 0.47354448, Gradient norm: 4.06607132
INFO:root:At the start of the epoch: mem (CPU python)=13399.20703125MB; mem (CPU total)=13215.48828125MB
INFO:root:[   39] Training loss: 0.47811637, Validation loss: 0.47547268, Gradient norm: 3.63315772
INFO:root:At the start of the epoch: mem (CPU python)=13420.37109375MB; mem (CPU total)=13236.90625MB
INFO:root:[   40] Training loss: 0.47824240, Validation loss: 0.46725241, Gradient norm: 4.00018087
INFO:root:At the start of the epoch: mem (CPU python)=13441.53515625MB; mem (CPU total)=13258.08203125MB
INFO:root:[   41] Training loss: 0.47239091, Validation loss: 0.46286875, Gradient norm: 3.67350158
INFO:root:At the start of the epoch: mem (CPU python)=13462.69921875MB; mem (CPU total)=13279.53515625MB
INFO:root:[   42] Training loss: 0.47240895, Validation loss: 0.47988485, Gradient norm: 3.64727067
INFO:root:At the start of the epoch: mem (CPU python)=13483.859375MB; mem (CPU total)=13300.7109375MB
INFO:root:[   43] Training loss: 0.47327484, Validation loss: 0.47946983, Gradient norm: 3.65221759
INFO:root:At the start of the epoch: mem (CPU python)=13505.0234375MB; mem (CPU total)=13321.88671875MB
INFO:root:[   44] Training loss: 0.47545105, Validation loss: 0.46842509, Gradient norm: 4.06904960
INFO:root:At the start of the epoch: mem (CPU python)=13526.1875MB; mem (CPU total)=13343.0625MB
INFO:root:[   45] Training loss: 0.46727584, Validation loss: 0.46291939, Gradient norm: 3.54792423
INFO:root:At the start of the epoch: mem (CPU python)=13547.3515625MB; mem (CPU total)=13364.484375MB
INFO:root:[   46] Training loss: 0.46919723, Validation loss: 0.47064849, Gradient norm: 3.70025422
INFO:root:At the start of the epoch: mem (CPU python)=13568.515625MB; mem (CPU total)=13385.375MB
INFO:root:[   47] Training loss: 0.46936684, Validation loss: 0.47743204, Gradient norm: 4.07388371
INFO:root:At the start of the epoch: mem (CPU python)=13589.6796875MB; mem (CPU total)=13406.53515625MB
INFO:root:[   48] Training loss: 0.47071470, Validation loss: 0.46412660, Gradient norm: 3.93123752
INFO:root:At the start of the epoch: mem (CPU python)=13610.84765625MB; mem (CPU total)=13427.96875MB
INFO:root:[   49] Training loss: 0.46816278, Validation loss: 0.46202984, Gradient norm: 3.89734609
INFO:root:At the start of the epoch: mem (CPU python)=13632.01171875MB; mem (CPU total)=13449.14453125MB
INFO:root:[   50] Training loss: 0.46792104, Validation loss: 0.46611046, Gradient norm: 3.17059602
INFO:root:At the start of the epoch: mem (CPU python)=13653.17578125MB; mem (CPU total)=13470.07421875MB
INFO:root:[   51] Training loss: 0.46006675, Validation loss: 0.46668739, Gradient norm: 4.58898187
INFO:root:At the start of the epoch: mem (CPU python)=13674.33984375MB; mem (CPU total)=13491.3359375MB
INFO:root:[   52] Training loss: 0.46925173, Validation loss: 0.46938671, Gradient norm: 4.05109035
INFO:root:At the start of the epoch: mem (CPU python)=13695.5MB; mem (CPU total)=13512.5MB
INFO:root:[   53] Training loss: 0.46289975, Validation loss: 0.46986323, Gradient norm: 4.33222724
INFO:root:At the start of the epoch: mem (CPU python)=13716.6640625MB; mem (CPU total)=13533.6640625MB
INFO:root:[   54] Training loss: 0.46404289, Validation loss: 0.47595308, Gradient norm: 3.94091890
INFO:root:At the start of the epoch: mem (CPU python)=13737.83203125MB; mem (CPU total)=13554.08203125MB
INFO:root:[   55] Training loss: 0.46307678, Validation loss: 0.47274060, Gradient norm: 3.76404543
INFO:root:At the start of the epoch: mem (CPU python)=13758.99609375MB; mem (CPU total)=13576.015625MB
INFO:root:[   56] Training loss: 0.45917161, Validation loss: 0.45674317, Gradient norm: 4.12054785
INFO:root:At the start of the epoch: mem (CPU python)=13780.16015625MB; mem (CPU total)=13597.3828125MB
INFO:root:[   57] Training loss: 0.46222161, Validation loss: 0.45688205, Gradient norm: 3.76662879
INFO:root:At the start of the epoch: mem (CPU python)=13801.32421875MB; mem (CPU total)=13618.28125MB
INFO:root:[   58] Training loss: 0.45706443, Validation loss: 0.44739020, Gradient norm: 4.58228185
INFO:root:At the start of the epoch: mem (CPU python)=13822.48828125MB; mem (CPU total)=13639.5MB
INFO:root:[   59] Training loss: 0.46216605, Validation loss: 0.44719785, Gradient norm: 4.06938655
INFO:root:At the start of the epoch: mem (CPU python)=13843.65625MB; mem (CPU total)=13660.90234375MB
INFO:root:[   60] Training loss: 0.45962256, Validation loss: 0.45807657, Gradient norm: 4.05957444
INFO:root:At the start of the epoch: mem (CPU python)=13864.81640625MB; mem (CPU total)=13682.0625MB
INFO:root:[   61] Training loss: 0.46182815, Validation loss: 0.45742148, Gradient norm: 4.39513841
INFO:root:At the start of the epoch: mem (CPU python)=13885.9765625MB; mem (CPU total)=13703.2265625MB
INFO:root:[   62] Training loss: 0.45459029, Validation loss: 0.45591829, Gradient norm: 4.08494056
INFO:root:At the start of the epoch: mem (CPU python)=13907.140625MB; mem (CPU total)=13724.390625MB
INFO:root:[   63] Training loss: 0.46275319, Validation loss: 0.46126765, Gradient norm: 4.27658060
INFO:root:At the start of the epoch: mem (CPU python)=13928.3046875MB; mem (CPU total)=13745.55078125MB
INFO:root:[   64] Training loss: 0.45683553, Validation loss: 0.44689224, Gradient norm: 4.41932036
INFO:root:At the start of the epoch: mem (CPU python)=13949.46875MB; mem (CPU total)=13766.70703125MB
INFO:root:[   65] Training loss: 0.45558100, Validation loss: 0.47270232, Gradient norm: 4.27078791
INFO:root:At the start of the epoch: mem (CPU python)=13970.6328125MB; mem (CPU total)=13788.11328125MB
INFO:root:[   66] Training loss: 0.45522661, Validation loss: 0.47320089, Gradient norm: 3.98042689
INFO:root:At the start of the epoch: mem (CPU python)=13991.80078125MB; mem (CPU total)=13809.2734375MB
INFO:root:[   67] Training loss: 0.45897042, Validation loss: 0.47135915, Gradient norm: 3.80477143
INFO:root:At the start of the epoch: mem (CPU python)=14012.96484375MB; mem (CPU total)=13830.6875MB
INFO:root:[   68] Training loss: 0.45910830, Validation loss: 0.45871894, Gradient norm: 4.55018569
INFO:root:At the start of the epoch: mem (CPU python)=14034.12890625MB; mem (CPU total)=13851.8046875MB
INFO:root:[   69] Training loss: 0.45600780, Validation loss: 0.45359584, Gradient norm: 4.30477529
INFO:root:At the start of the epoch: mem (CPU python)=14055.29296875MB; mem (CPU total)=13872.921875MB
INFO:root:[   70] Training loss: 0.45548640, Validation loss: 0.45090300, Gradient norm: 4.16012642
INFO:root:At the start of the epoch: mem (CPU python)=14076.45703125MB; mem (CPU total)=13894.078125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   71] Training loss: 0.45083133, Validation loss: 0.45211264, Gradient norm: 4.14987616
INFO:root:At the start of the epoch: mem (CPU python)=14097.62109375MB; mem (CPU total)=13915.24609375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   72] Training loss: 0.42445526, Validation loss: 0.42851170, Gradient norm: 3.13027788
INFO:root:At the start of the epoch: mem (CPU python)=14118.78515625MB; mem (CPU total)=13936.39453125MB
INFO:root:[   73] Training loss: 0.41480936, Validation loss: 0.41848597, Gradient norm: 2.26967641
INFO:root:At the start of the epoch: mem (CPU python)=14139.94921875MB; mem (CPU total)=13957.578125MB
INFO:root:[   74] Training loss: 0.41322635, Validation loss: 0.42125658, Gradient norm: 2.73188089
INFO:root:At the start of the epoch: mem (CPU python)=14161.11328125MB; mem (CPU total)=13978.72265625MB
INFO:root:[   75] Training loss: 0.41315971, Validation loss: 0.42108224, Gradient norm: 3.25390073
INFO:root:At the start of the epoch: mem (CPU python)=14182.27734375MB; mem (CPU total)=13999.87109375MB
INFO:root:[   76] Training loss: 0.41376573, Validation loss: 0.42472777, Gradient norm: 3.51326086
INFO:root:At the start of the epoch: mem (CPU python)=14203.4453125MB; mem (CPU total)=14021.26953125MB
INFO:root:[   77] Training loss: 0.41376081, Validation loss: 0.42155511, Gradient norm: 3.90682597
INFO:root:At the start of the epoch: mem (CPU python)=14224.60546875MB; mem (CPU total)=14042.42578125MB
INFO:root:[   78] Training loss: 0.41348342, Validation loss: 0.41700863, Gradient norm: 4.58363562
INFO:root:At the start of the epoch: mem (CPU python)=14245.77734375MB; mem (CPU total)=14063.5859375MB
INFO:root:[   79] Training loss: 0.41369544, Validation loss: 0.41881962, Gradient norm: 5.10589508
INFO:root:At the start of the epoch: mem (CPU python)=14266.9375MB; mem (CPU total)=14084.75MB
INFO:root:[   80] Training loss: 0.41371902, Validation loss: 0.41764829, Gradient norm: 5.27055108
INFO:root:At the start of the epoch: mem (CPU python)=14288.09765625MB; mem (CPU total)=14105.9140625MB
INFO:root:[   81] Training loss: 0.41425132, Validation loss: 0.41948468, Gradient norm: 5.67513314
INFO:root:At the start of the epoch: mem (CPU python)=14309.265625MB; mem (CPU total)=14127.32421875MB
INFO:root:[   82] Training loss: 0.41325796, Validation loss: 0.41959387, Gradient norm: 6.12090989
INFO:root:At the start of the epoch: mem (CPU python)=14330.4296875MB; mem (CPU total)=14148.43359375MB
INFO:root:[   83] Training loss: 0.41560875, Validation loss: 0.42282385, Gradient norm: 6.25981273
INFO:root:At the start of the epoch: mem (CPU python)=14351.59375MB; mem (CPU total)=14169.578125MB
INFO:root:[   84] Training loss: 0.41547551, Validation loss: 0.41773174, Gradient norm: 6.15524357
INFO:root:At the start of the epoch: mem (CPU python)=14372.7578125MB; mem (CPU total)=14190.7265625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   85] Training loss: 0.41540962, Validation loss: 0.42009374, Gradient norm: 7.15108552
INFO:root:At the start of the epoch: mem (CPU python)=14393.921875MB; mem (CPU total)=14211.875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   86] Training loss: 0.40974593, Validation loss: 0.41465442, Gradient norm: 5.09772281
INFO:root:At the start of the epoch: mem (CPU python)=14415.0859375MB; mem (CPU total)=14233.5078125MB
INFO:root:[   87] Training loss: 0.40689127, Validation loss: 0.41330842, Gradient norm: 3.25260846
INFO:root:At the start of the epoch: mem (CPU python)=14436.25390625MB; mem (CPU total)=14254.66015625MB
INFO:root:[   88] Training loss: 0.40706788, Validation loss: 0.41265346, Gradient norm: 3.31542386
INFO:root:At the start of the epoch: mem (CPU python)=14457.41796875MB; mem (CPU total)=14276.05078125MB
INFO:root:[   89] Training loss: 0.40664411, Validation loss: 0.41230924, Gradient norm: 3.87403661
INFO:root:At the start of the epoch: mem (CPU python)=14478.58203125MB; mem (CPU total)=14297.21484375MB
INFO:root:[   90] Training loss: 0.40768479, Validation loss: 0.41358481, Gradient norm: 5.78093375
INFO:root:At the start of the epoch: mem (CPU python)=14499.7421875MB; mem (CPU total)=14318.37109375MB
INFO:root:[   91] Training loss: 0.40675694, Validation loss: 0.41303286, Gradient norm: 4.39852468
INFO:root:At the start of the epoch: mem (CPU python)=14520.90625MB; mem (CPU total)=14339.51953125MB
INFO:root:[   92] Training loss: 0.40719664, Validation loss: 0.41342354, Gradient norm: 4.36162049
INFO:root:At the start of the epoch: mem (CPU python)=14542.0703125MB; mem (CPU total)=14360.95703125MB
INFO:root:[   93] Training loss: 0.40719690, Validation loss: 0.41273670, Gradient norm: 4.92460047
INFO:root:At the start of the epoch: mem (CPU python)=14563.234375MB; mem (CPU total)=14382.109375MB
INFO:root:[   94] Training loss: 0.40736610, Validation loss: 0.41334771, Gradient norm: 4.94634143
INFO:root:At the start of the epoch: mem (CPU python)=14584.3984375MB; mem (CPU total)=14403.26953125MB
INFO:root:[   95] Training loss: 0.40784303, Validation loss: 0.41247591, Gradient norm: 5.55698789
INFO:root:At the start of the epoch: mem (CPU python)=14605.5625MB; mem (CPU total)=14424.42578125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   96] Training loss: 0.40737492, Validation loss: 0.41378233, Gradient norm: 5.61197776
INFO:root:At the start of the epoch: mem (CPU python)=14626.7265625MB; mem (CPU total)=14445.85546875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   97] Training loss: 0.40598176, Validation loss: 0.41347488, Gradient norm: 4.16029202
INFO:root:At the start of the epoch: mem (CPU python)=14647.890625MB; mem (CPU total)=14467.01953125MB
INFO:root:[   98] Training loss: 0.40598636, Validation loss: 0.41144443, Gradient norm: 3.43798697
INFO:root:At the start of the epoch: mem (CPU python)=14669.05859375MB; mem (CPU total)=14487.9296875MB
INFO:root:[   99] Training loss: 0.40554630, Validation loss: 0.41247525, Gradient norm: 3.29733540
INFO:root:At the start of the epoch: mem (CPU python)=14690.21875MB; mem (CPU total)=14509.05078125MB
INFO:root:[  100] Training loss: 0.40509438, Validation loss: 0.41113413, Gradient norm: 3.48528231
INFO:root:At the start of the epoch: mem (CPU python)=14711.3828125MB; mem (CPU total)=14530.125MB
INFO:root:[  101] Training loss: 0.40544025, Validation loss: 0.41327972, Gradient norm: 3.58965859
INFO:root:At the start of the epoch: mem (CPU python)=14732.546875MB; mem (CPU total)=14551.28125MB
INFO:root:[  102] Training loss: 0.40576428, Validation loss: 0.41234803, Gradient norm: 3.38100887
INFO:root:At the start of the epoch: mem (CPU python)=14753.7109375MB; mem (CPU total)=14572.4453125MB
INFO:root:[  103] Training loss: 0.40626714, Validation loss: 0.41153193, Gradient norm: 3.57994392
INFO:root:At the start of the epoch: mem (CPU python)=14774.875MB; mem (CPU total)=14593.609375MB
INFO:root:[  104] Training loss: 0.40559173, Validation loss: 0.41171006, Gradient norm: 3.93687044
INFO:root:At the start of the epoch: mem (CPU python)=14796.04296875MB; mem (CPU total)=14614.7734375MB
INFO:root:[  105] Training loss: 0.40528354, Validation loss: 0.41211072, Gradient norm: 4.11583473
INFO:root:At the start of the epoch: mem (CPU python)=14817.20703125MB; mem (CPU total)=14636.17578125MB
INFO:root:[  106] Training loss: 0.40602696, Validation loss: 0.41284935, Gradient norm: 4.44909658
INFO:root:At the start of the epoch: mem (CPU python)=14838.37109375MB; mem (CPU total)=14657.35546875MB
INFO:root:[  107] Training loss: 0.40600455, Validation loss: 0.41251973, Gradient norm: 4.28375767
INFO:root:At the start of the epoch: mem (CPU python)=14859.53515625MB; mem (CPU total)=14678.51953125MB
INFO:root:[  108] Training loss: 0.40560971, Validation loss: 0.41200419, Gradient norm: 3.96254990
INFO:root:At the start of the epoch: mem (CPU python)=14880.6953125MB; mem (CPU total)=14699.67578125MB
INFO:root:[  109] Training loss: 0.40668597, Validation loss: 0.41170675, Gradient norm: 4.58510961
INFO:root:At the start of the epoch: mem (CPU python)=14901.859375MB; mem (CPU total)=14720.82421875MB
INFO:root:EP 109: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=14922.875MB; mem (CPU total)=14741.67578125MB
INFO:root:Training the model took 3368.618s.
INFO:root:Emptying the cuda cache took 0.038s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.36683
INFO:root:EnergyScoreValidation: 0.28027
INFO:root:CRPSValidation: 0.10948
INFO:root:Gaussian NLLValidation: 0.05133
INFO:root:CoverageValidation: 0.75308
INFO:root:IntervalWidthValidation: 0.38823
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.38867
INFO:root:EnergyScoreTest: 0.30008
INFO:root:CRPSTest: 0.11844
INFO:root:Gaussian NLLTest: 0.30477
INFO:root:CoverageTest: 0.72007
INFO:root:IntervalWidthTest: 0.38646
INFO:root:After validation: mem (CPU python)=15229.69140625MB; mem (CPU total)=14750.2265625MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=15229.69140625MB; mem (CPU total)=14750.2265625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=15229.69140625MB; mem (CPU total)=14750.2265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=14750.47265625MB
INFO:root:[    1] Training loss: 0.82936703, Validation loss: 0.74201301, Gradient norm: 0.41232760
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=14771.515625MB
INFO:root:[    2] Training loss: 0.74008875, Validation loss: 0.74365574, Gradient norm: 0.32649279
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=14792.64453125MB
INFO:root:[    3] Training loss: 0.73244902, Validation loss: 0.72230682, Gradient norm: 0.26250048
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=14813.0859375MB
INFO:root:[    4] Training loss: 0.71140959, Validation loss: 0.69527499, Gradient norm: 0.35726925
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=14834.2734375MB
INFO:root:[    5] Training loss: 0.66526280, Validation loss: 0.63832206, Gradient norm: 0.59994438
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=14855.21484375MB
INFO:root:[    6] Training loss: 0.62113405, Validation loss: 0.61062786, Gradient norm: 0.72621504
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=14876.87890625MB
INFO:root:[    7] Training loss: 0.59347140, Validation loss: 0.58494586, Gradient norm: 0.84603280
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=14898.0390625MB
INFO:root:[    8] Training loss: 0.57978134, Validation loss: 0.58020599, Gradient norm: 0.99340893
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=15052.81640625MB
INFO:root:[    9] Training loss: 0.57552004, Validation loss: 0.56631781, Gradient norm: 1.27919266
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=15360.87890625MB
INFO:root:[   10] Training loss: 0.56461452, Validation loss: 0.63304349, Gradient norm: 1.22453167
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17515.02734375MB
INFO:root:[   11] Training loss: 0.55962523, Validation loss: 0.55113861, Gradient norm: 1.65033579
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17534.875MB
INFO:root:[   12] Training loss: 0.54325626, Validation loss: 0.53753986, Gradient norm: 1.73070861
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17578.62109375MB
INFO:root:[   13] Training loss: 0.53611293, Validation loss: 0.52762694, Gradient norm: 1.76169430
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17597.80078125MB
INFO:root:[   14] Training loss: 0.52853631, Validation loss: 0.51862394, Gradient norm: 2.06224032
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17617.734375MB
INFO:root:[   15] Training loss: 0.51119224, Validation loss: 0.50532510, Gradient norm: 2.39889463
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17637.66015625MB
INFO:root:[   16] Training loss: 0.49997589, Validation loss: 0.48259923, Gradient norm: 2.21413696
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17658.328125MB
INFO:root:[   17] Training loss: 0.48790655, Validation loss: 0.49273677, Gradient norm: 2.63140475
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17679.0MB
INFO:root:[   18] Training loss: 0.48170626, Validation loss: 0.47904420, Gradient norm: 3.24246559
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17698.59765625MB
INFO:root:[   19] Training loss: 0.47833946, Validation loss: 0.47383015, Gradient norm: 2.97012779
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17719.87890625MB
INFO:root:[   20] Training loss: 0.47975243, Validation loss: 0.45965455, Gradient norm: 3.25315180
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17753.70703125MB
INFO:root:[   21] Training loss: 0.47364453, Validation loss: 0.45419095, Gradient norm: 3.14006608
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17779.61328125MB
INFO:root:[   22] Training loss: 0.46785192, Validation loss: 0.47206879, Gradient norm: 3.48275344
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17802.44140625MB
INFO:root:[   23] Training loss: 0.46826527, Validation loss: 0.48095557, Gradient norm: 3.56356876
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17822.70703125MB
INFO:root:[   24] Training loss: 0.46650841, Validation loss: 0.47045871, Gradient norm: 3.65552500
INFO:root:At the start of the epoch: mem (CPU python)=15229.69140625MB; mem (CPU total)=17842.8046875MB
INFO:root:[   25] Training loss: 0.46507063, Validation loss: 0.46211513, Gradient norm: 3.42690673
INFO:root:At the start of the epoch: mem (CPU python)=15234.74609375MB; mem (CPU total)=17862.96484375MB
INFO:root:[   26] Training loss: 0.46557071, Validation loss: 0.45397937, Gradient norm: 4.00836364
INFO:root:At the start of the epoch: mem (CPU python)=15255.90625MB; mem (CPU total)=17883.32421875MB
INFO:root:[   27] Training loss: 0.46014517, Validation loss: 0.45968877, Gradient norm: 4.04996369
INFO:root:At the start of the epoch: mem (CPU python)=15277.0703125MB; mem (CPU total)=17904.03515625MB
INFO:root:[   28] Training loss: 0.45638102, Validation loss: 0.45016003, Gradient norm: 3.80347651
INFO:root:At the start of the epoch: mem (CPU python)=15298.23828125MB; mem (CPU total)=17925.4609375MB
INFO:root:[   29] Training loss: 0.46399281, Validation loss: 0.46798776, Gradient norm: 4.34775560
INFO:root:At the start of the epoch: mem (CPU python)=15319.40234375MB; mem (CPU total)=17946.3828125MB
INFO:root:[   30] Training loss: 0.45923592, Validation loss: 0.45620239, Gradient norm: 3.80830986
INFO:root:At the start of the epoch: mem (CPU python)=15340.56640625MB; mem (CPU total)=17967.26953125MB
INFO:root:[   31] Training loss: 0.45614246, Validation loss: 0.47041883, Gradient norm: 4.10798957
INFO:root:At the start of the epoch: mem (CPU python)=15361.73046875MB; mem (CPU total)=17995.703125MB
INFO:root:[   32] Training loss: 0.45444609, Validation loss: 0.49191740, Gradient norm: 4.34903210
INFO:root:At the start of the epoch: mem (CPU python)=15382.8984375MB; mem (CPU total)=18017.48828125MB
INFO:root:[   33] Training loss: 0.45807939, Validation loss: 0.46224065, Gradient norm: 4.63956605
INFO:root:At the start of the epoch: mem (CPU python)=15404.0625MB; mem (CPU total)=18036.91796875MB
INFO:root:[   34] Training loss: 0.45277556, Validation loss: 0.50051901, Gradient norm: 4.11687093
INFO:root:At the start of the epoch: mem (CPU python)=15425.2265625MB; mem (CPU total)=18057.26953125MB
INFO:root:[   35] Training loss: 0.45489319, Validation loss: 0.47528493, Gradient norm: 4.57047619
INFO:root:At the start of the epoch: mem (CPU python)=15446.390625MB; mem (CPU total)=18077.9375MB
INFO:root:[   36] Training loss: 0.44491951, Validation loss: 0.44775748, Gradient norm: 4.15267682
INFO:root:At the start of the epoch: mem (CPU python)=15467.55078125MB; mem (CPU total)=18098.05859375MB
INFO:root:[   37] Training loss: 0.43976721, Validation loss: 0.44190859, Gradient norm: 4.53416950
INFO:root:At the start of the epoch: mem (CPU python)=15488.71484375MB; mem (CPU total)=18118.6171875MB
INFO:root:[   38] Training loss: 0.45211634, Validation loss: 0.44827053, Gradient norm: 5.54636206
INFO:root:At the start of the epoch: mem (CPU python)=15509.875MB; mem (CPU total)=18139.4296875MB
INFO:root:[   39] Training loss: 0.45502090, Validation loss: 0.49157618, Gradient norm: 5.24601009
INFO:root:At the start of the epoch: mem (CPU python)=15531.04296875MB; mem (CPU total)=18160.34765625MB
INFO:root:[   40] Training loss: 0.45564948, Validation loss: 0.45230404, Gradient norm: 5.41144107
INFO:root:At the start of the epoch: mem (CPU python)=15552.20703125MB; mem (CPU total)=18181.51171875MB
INFO:root:[   41] Training loss: 0.45167980, Validation loss: 0.45179187, Gradient norm: 4.84244497
INFO:root:At the start of the epoch: mem (CPU python)=15573.37109375MB; mem (CPU total)=18213.87890625MB
INFO:root:[   42] Training loss: 0.44342327, Validation loss: 0.45894771, Gradient norm: 5.12630076
INFO:root:At the start of the epoch: mem (CPU python)=15594.53515625MB; mem (CPU total)=18235.765625MB
INFO:root:[   43] Training loss: 0.45253242, Validation loss: 0.46714571, Gradient norm: 5.53475501
INFO:root:At the start of the epoch: mem (CPU python)=15615.69921875MB; mem (CPU total)=18255.66015625MB
INFO:root:[   44] Training loss: 0.45446843, Validation loss: 0.47694550, Gradient norm: 5.34836796
INFO:root:At the start of the epoch: mem (CPU python)=15636.8671875MB; mem (CPU total)=18274.91015625MB
INFO:root:[   45] Training loss: 0.45214311, Validation loss: 0.46755595, Gradient norm: 5.75063785
INFO:root:At the start of the epoch: mem (CPU python)=15658.02734375MB; mem (CPU total)=18295.7109375MB
INFO:root:[   46] Training loss: 0.45227381, Validation loss: 0.48056924, Gradient norm: 4.83112247
INFO:root:At the start of the epoch: mem (CPU python)=15679.19140625MB; mem (CPU total)=18316.625MB
INFO:root:[   47] Training loss: 0.45162730, Validation loss: 0.47882203, Gradient norm: 5.51394965
INFO:root:At the start of the epoch: mem (CPU python)=15700.35546875MB; mem (CPU total)=18337.3046875MB
INFO:root:[   48] Training loss: 0.44845294, Validation loss: 0.46128113, Gradient norm: 5.81315326
INFO:root:At the start of the epoch: mem (CPU python)=15721.51953125MB; mem (CPU total)=18358.16015625MB
INFO:root:[   49] Training loss: 0.44903881, Validation loss: 0.45327715, Gradient norm: 5.78614713
INFO:root:At the start of the epoch: mem (CPU python)=15742.6875MB; mem (CPU total)=18378.80859375MB
INFO:root:[   50] Training loss: 0.44894618, Validation loss: 0.45016142, Gradient norm: 5.74091800
INFO:root:At the start of the epoch: mem (CPU python)=15763.8515625MB; mem (CPU total)=18399.68359375MB
INFO:root:[   51] Training loss: 0.45597546, Validation loss: 0.46859704, Gradient norm: 5.98262423
INFO:root:At the start of the epoch: mem (CPU python)=15785.015625MB; mem (CPU total)=18519.45703125MB
INFO:root:[   52] Training loss: 0.44637703, Validation loss: 0.45830195, Gradient norm: 5.30406834
INFO:root:At the start of the epoch: mem (CPU python)=15806.1796875MB; mem (CPU total)=18544.09765625MB
INFO:root:[   53] Training loss: 0.44893882, Validation loss: 0.45051017, Gradient norm: 5.66422033
INFO:root:At the start of the epoch: mem (CPU python)=15827.34375MB; mem (CPU total)=18565.08203125MB
INFO:root:[   54] Training loss: 0.44637613, Validation loss: 0.43454247, Gradient norm: 5.65117299
INFO:root:At the start of the epoch: mem (CPU python)=15848.5078125MB; mem (CPU total)=18586.58203125MB
INFO:root:[   55] Training loss: 0.44334309, Validation loss: 0.46413573, Gradient norm: 6.16209573
INFO:root:At the start of the epoch: mem (CPU python)=15869.66796875MB; mem (CPU total)=18606.83203125MB
INFO:root:[   56] Training loss: 0.44714964, Validation loss: 0.48450268, Gradient norm: 6.24353095
INFO:root:At the start of the epoch: mem (CPU python)=15890.83203125MB; mem (CPU total)=18627.57421875MB
INFO:root:[   57] Training loss: 0.44792786, Validation loss: 0.44748484, Gradient norm: 6.03282446
INFO:root:At the start of the epoch: mem (CPU python)=15911.99609375MB; mem (CPU total)=18648.0703125MB
INFO:root:[   58] Training loss: 0.44197193, Validation loss: 0.42521308, Gradient norm: 5.94693763
INFO:root:At the start of the epoch: mem (CPU python)=15933.16015625MB; mem (CPU total)=18669.4375MB
INFO:root:[   59] Training loss: 0.44416631, Validation loss: 0.44158245, Gradient norm: 6.39439363
INFO:root:At the start of the epoch: mem (CPU python)=15954.32421875MB; mem (CPU total)=18689.2578125MB
INFO:root:[   60] Training loss: 0.45476194, Validation loss: 0.44524225, Gradient norm: 6.77943062
INFO:root:At the start of the epoch: mem (CPU python)=15975.48828125MB; mem (CPU total)=18710.40625MB
INFO:root:[   61] Training loss: 0.44400475, Validation loss: 0.42368443, Gradient norm: 6.22393446
INFO:root:At the start of the epoch: mem (CPU python)=15996.65625MB; mem (CPU total)=18731.06640625MB
INFO:root:[   62] Training loss: 0.44312152, Validation loss: 0.49362133, Gradient norm: 6.95691360
INFO:root:At the start of the epoch: mem (CPU python)=16017.8203125MB; mem (CPU total)=18751.5078125MB
INFO:root:[   63] Training loss: 0.45071561, Validation loss: 0.49513198, Gradient norm: 6.89816965
INFO:root:At the start of the epoch: mem (CPU python)=16038.984375MB; mem (CPU total)=18772.67578125MB
INFO:root:[   64] Training loss: 0.44861918, Validation loss: 0.44491573, Gradient norm: 6.95604106
INFO:root:At the start of the epoch: mem (CPU python)=16060.14453125MB; mem (CPU total)=18792.8359375MB
INFO:root:[   65] Training loss: 0.43852490, Validation loss: 0.45395248, Gradient norm: 6.30965598
INFO:root:At the start of the epoch: mem (CPU python)=16081.30859375MB; mem (CPU total)=18813.453125MB
INFO:root:[   66] Training loss: 0.45204489, Validation loss: 0.46526800, Gradient norm: 7.65012781
INFO:root:At the start of the epoch: mem (CPU python)=16102.4765625MB; mem (CPU total)=18834.39453125MB
INFO:root:[   67] Training loss: 0.44508080, Validation loss: 0.44507446, Gradient norm: 6.64116922
INFO:root:At the start of the epoch: mem (CPU python)=16123.640625MB; mem (CPU total)=18858.33984375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   68] Training loss: 0.45420830, Validation loss: 0.43246139, Gradient norm: 6.99536069
INFO:root:At the start of the epoch: mem (CPU python)=16144.8046875MB; mem (CPU total)=18883.234375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   69] Training loss: 0.41056660, Validation loss: 0.41376144, Gradient norm: 5.37151844
INFO:root:At the start of the epoch: mem (CPU python)=16165.96875MB; mem (CPU total)=18905.703125MB
INFO:root:[   70] Training loss: 0.39879675, Validation loss: 0.40441375, Gradient norm: 4.33197034
INFO:root:At the start of the epoch: mem (CPU python)=16187.1328125MB; mem (CPU total)=18927.0703125MB
INFO:root:[   71] Training loss: 0.39713137, Validation loss: 0.40826555, Gradient norm: 5.35961028
INFO:root:At the start of the epoch: mem (CPU python)=16208.296875MB; mem (CPU total)=18948.0703125MB
INFO:root:[   72] Training loss: 0.39787883, Validation loss: 0.40729557, Gradient norm: 6.13773429
INFO:root:At the start of the epoch: mem (CPU python)=16229.4609375MB; mem (CPU total)=18970.3125MB
INFO:root:[   73] Training loss: 0.40257809, Validation loss: 0.40601770, Gradient norm: 7.79130863
INFO:root:At the start of the epoch: mem (CPU python)=16250.62109375MB; mem (CPU total)=18994.30859375MB
INFO:root:[   74] Training loss: 0.39878066, Validation loss: 0.40457633, Gradient norm: 7.80702485
INFO:root:At the start of the epoch: mem (CPU python)=16271.78515625MB; mem (CPU total)=19014.50390625MB
INFO:root:[   75] Training loss: 0.39933323, Validation loss: 0.42188100, Gradient norm: 8.11378777
INFO:root:At the start of the epoch: mem (CPU python)=16292.94921875MB; mem (CPU total)=19034.6953125MB
INFO:root:[   76] Training loss: 0.40002142, Validation loss: 0.40456164, Gradient norm: 8.51909056
INFO:root:At the start of the epoch: mem (CPU python)=16314.11328125MB; mem (CPU total)=19055.3359375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 0.39899130, Validation loss: 0.40733039, Gradient norm: 9.50477007
INFO:root:At the start of the epoch: mem (CPU python)=16335.28125MB; mem (CPU total)=19076.25390625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 0.39334365, Validation loss: 0.40519097, Gradient norm: 6.27151377
INFO:root:At the start of the epoch: mem (CPU python)=16356.4453125MB; mem (CPU total)=19097.40625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   79] Training loss: 0.39120891, Validation loss: 0.39782984, Gradient norm: 5.78143761
INFO:root:At the start of the epoch: mem (CPU python)=16377.609375MB; mem (CPU total)=19117.82421875MB
INFO:root:[   80] Training loss: 0.38832231, Validation loss: 0.39659532, Gradient norm: 3.68889294
INFO:root:At the start of the epoch: mem (CPU python)=16398.7734375MB; mem (CPU total)=19139.03515625MB
INFO:root:[   81] Training loss: 0.38760061, Validation loss: 0.39581381, Gradient norm: 3.78549942
INFO:root:At the start of the epoch: mem (CPU python)=16419.94140625MB; mem (CPU total)=19159.7578125MB
INFO:root:[   82] Training loss: 0.38790138, Validation loss: 0.39842394, Gradient norm: 4.22433943
INFO:root:At the start of the epoch: mem (CPU python)=16441.1015625MB; mem (CPU total)=19182.453125MB
INFO:root:[   83] Training loss: 0.38848662, Validation loss: 0.39638857, Gradient norm: 5.04081536
INFO:root:At the start of the epoch: mem (CPU python)=16462.265625MB; mem (CPU total)=19207.390625MB
INFO:root:[   84] Training loss: 0.38763891, Validation loss: 0.39486394, Gradient norm: 5.32762145
INFO:root:At the start of the epoch: mem (CPU python)=16483.4296875MB; mem (CPU total)=19228.95703125MB
INFO:root:[   85] Training loss: 0.38773320, Validation loss: 0.39714711, Gradient norm: 4.51917967
INFO:root:At the start of the epoch: mem (CPU python)=16504.59375MB; mem (CPU total)=19250.5625MB
INFO:root:[   86] Training loss: 0.38815708, Validation loss: 0.39559709, Gradient norm: 4.68636816
INFO:root:At the start of the epoch: mem (CPU python)=16525.7578125MB; mem (CPU total)=19272.04296875MB
INFO:root:[   87] Training loss: 0.38798172, Validation loss: 0.39688709, Gradient norm: 6.06583105
INFO:root:At the start of the epoch: mem (CPU python)=16546.921875MB; mem (CPU total)=19292.76171875MB
INFO:root:[   88] Training loss: 0.38741068, Validation loss: 0.39579576, Gradient norm: 6.39992804
INFO:root:At the start of the epoch: mem (CPU python)=16568.08984375MB; mem (CPU total)=19313.42578125MB
INFO:root:[   89] Training loss: 0.38694327, Validation loss: 0.39628235, Gradient norm: 4.88754140
INFO:root:At the start of the epoch: mem (CPU python)=16589.25MB; mem (CPU total)=19335.08984375MB
INFO:root:[   90] Training loss: 0.38816283, Validation loss: 0.39608020, Gradient norm: 6.11684349
INFO:root:At the start of the epoch: mem (CPU python)=16610.4140625MB; mem (CPU total)=19355.05859375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   91] Training loss: 0.38755754, Validation loss: 0.39624846, Gradient norm: 5.80155625
INFO:root:At the start of the epoch: mem (CPU python)=16631.578125MB; mem (CPU total)=19376.0MB
INFO:root:[   92] Training loss: 0.38731410, Validation loss: 0.39655604, Gradient norm: 4.76225653
INFO:root:At the start of the epoch: mem (CPU python)=16652.7421875MB; mem (CPU total)=19397.265625MB
INFO:root:[   93] Training loss: 0.38698568, Validation loss: 0.39492861, Gradient norm: 4.79796647
INFO:root:At the start of the epoch: mem (CPU python)=16673.90625MB; mem (CPU total)=19418.25390625MB
INFO:root:EP 93: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16694.91796875MB; mem (CPU total)=19439.85546875MB
INFO:root:Training the model took 3059.463s.
INFO:root:Emptying the cuda cache took 0.038s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.34686
INFO:root:EnergyScoreValidation: 0.26127
INFO:root:CRPSValidation: 0.10397
INFO:root:Gaussian NLLValidation: -0.09861
INFO:root:CoverageValidation: 0.77144
INFO:root:IntervalWidthValidation: 0.40064
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.37125
INFO:root:EnergyScoreTest: 0.28324
INFO:root:CRPSTest: 0.11539
INFO:root:Gaussian NLLTest: 0.24337
INFO:root:CoverageTest: 0.71899
INFO:root:IntervalWidthTest: 0.3971
INFO:root:After validation: mem (CPU python)=17006.32421875MB; mem (CPU total)=19443.46484375MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=17006.32421875MB; mem (CPU total)=19442.72265625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=17006.32421875MB; mem (CPU total)=19442.72265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19442.7421875MB
INFO:root:[    1] Training loss: 0.83343926, Validation loss: 0.74250631, Gradient norm: 0.42035553
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19463.2578125MB
INFO:root:[    2] Training loss: 0.73960328, Validation loss: 0.73690199, Gradient norm: 0.29752155
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19484.42578125MB
INFO:root:[    3] Training loss: 0.73026076, Validation loss: 0.71910125, Gradient norm: 0.25676402
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19504.3046875MB
INFO:root:[    4] Training loss: 0.69968862, Validation loss: 0.67281660, Gradient norm: 0.38296561
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19525.02734375MB
INFO:root:[    5] Training loss: 0.65201354, Validation loss: 0.62625538, Gradient norm: 0.45190916
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19545.99609375MB
INFO:root:[    6] Training loss: 0.60888655, Validation loss: 0.60032538, Gradient norm: 0.61952880
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19566.84375MB
INFO:root:[    7] Training loss: 0.59048998, Validation loss: 0.58331896, Gradient norm: 0.72220043
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19587.390625MB
INFO:root:[    8] Training loss: 0.57821835, Validation loss: 0.57478956, Gradient norm: 0.77958431
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19608.34765625MB
INFO:root:[    9] Training loss: 0.56957736, Validation loss: 0.56497238, Gradient norm: 0.88607459
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19630.3828125MB
INFO:root:[   10] Training loss: 0.56005651, Validation loss: 0.55750730, Gradient norm: 1.15546521
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19650.85546875MB
INFO:root:[   11] Training loss: 0.55653129, Validation loss: 0.54368782, Gradient norm: 1.54231681
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19672.171875MB
INFO:root:[   12] Training loss: 0.54619752, Validation loss: 0.53649431, Gradient norm: 1.66832684
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19712.5078125MB
INFO:root:[   13] Training loss: 0.52912864, Validation loss: 0.52222166, Gradient norm: 1.65791653
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19777.04296875MB
INFO:root:[   14] Training loss: 0.52303098, Validation loss: 0.53211573, Gradient norm: 1.71882896
INFO:root:At the start of the epoch: mem (CPU python)=17006.32421875MB; mem (CPU total)=19838.55078125MB
INFO:root:[   15] Training loss: 0.51612922, Validation loss: 0.52235915, Gradient norm: 2.04939547
INFO:root:At the start of the epoch: mem (CPU python)=17023.82421875MB; mem (CPU total)=19895.73046875MB
INFO:root:[   16] Training loss: 0.51095452, Validation loss: 0.49856521, Gradient norm: 2.00017918
INFO:root:At the start of the epoch: mem (CPU python)=17044.984375MB; mem (CPU total)=19951.13671875MB
INFO:root:[   17] Training loss: 0.50098775, Validation loss: 0.50070858, Gradient norm: 2.28650813
INFO:root:At the start of the epoch: mem (CPU python)=17066.1484375MB; mem (CPU total)=20004.328125MB
INFO:root:[   18] Training loss: 0.49585678, Validation loss: 0.49160011, Gradient norm: 1.83799747
INFO:root:At the start of the epoch: mem (CPU python)=17087.31640625MB; mem (CPU total)=20056.421875MB
INFO:root:[   19] Training loss: 0.49206931, Validation loss: 0.47887564, Gradient norm: 2.58697591
INFO:root:At the start of the epoch: mem (CPU python)=17108.48046875MB; mem (CPU total)=20104.98046875MB
INFO:root:[   20] Training loss: 0.48760954, Validation loss: 0.50193876, Gradient norm: 2.71418951
INFO:root:At the start of the epoch: mem (CPU python)=17129.64453125MB; mem (CPU total)=20155.2734375MB
INFO:root:[   21] Training loss: 0.48873199, Validation loss: 0.48977846, Gradient norm: 2.57328805
INFO:root:At the start of the epoch: mem (CPU python)=17150.80859375MB; mem (CPU total)=20203.31640625MB
INFO:root:[   22] Training loss: 0.48454364, Validation loss: 0.51769107, Gradient norm: 2.89374015
INFO:root:At the start of the epoch: mem (CPU python)=17171.97265625MB; mem (CPU total)=20249.23828125MB
INFO:root:[   23] Training loss: 0.48385860, Validation loss: 0.49301311, Gradient norm: 3.01625992
INFO:root:At the start of the epoch: mem (CPU python)=17193.140625MB; mem (CPU total)=20293.93359375MB
INFO:root:[   24] Training loss: 0.48210089, Validation loss: 0.48023476, Gradient norm: 3.06859140
INFO:root:At the start of the epoch: mem (CPU python)=17214.3046875MB; mem (CPU total)=20337.1953125MB
INFO:root:[   25] Training loss: 0.47866475, Validation loss: 0.47333852, Gradient norm: 2.38723910
INFO:root:At the start of the epoch: mem (CPU python)=17235.46875MB; mem (CPU total)=21018.5390625MB
INFO:root:[   26] Training loss: 0.47754123, Validation loss: 0.47505983, Gradient norm: 3.32820490
INFO:root:At the start of the epoch: mem (CPU python)=17256.62890625MB; mem (CPU total)=21039.71875MB
INFO:root:[   27] Training loss: 0.47925195, Validation loss: 0.49436076, Gradient norm: 3.17818819
INFO:root:At the start of the epoch: mem (CPU python)=17277.79296875MB; mem (CPU total)=21060.8125MB
INFO:root:[   28] Training loss: 0.47936760, Validation loss: 0.47635760, Gradient norm: 3.56126919
INFO:root:At the start of the epoch: mem (CPU python)=17298.95703125MB; mem (CPU total)=21083.046875MB
INFO:root:[   29] Training loss: 0.47431009, Validation loss: 0.47834502, Gradient norm: 3.29203782
INFO:root:At the start of the epoch: mem (CPU python)=17320.12109375MB; mem (CPU total)=21105.49609375MB
INFO:root:[   30] Training loss: 0.47437107, Validation loss: 0.46933656, Gradient norm: 3.62260745
INFO:root:At the start of the epoch: mem (CPU python)=17341.28515625MB; mem (CPU total)=21125.734375MB
INFO:root:[   31] Training loss: 0.47822044, Validation loss: 0.47371366, Gradient norm: 3.48947842
INFO:root:At the start of the epoch: mem (CPU python)=17362.44921875MB; mem (CPU total)=21147.08203125MB
INFO:root:[   32] Training loss: 0.47507416, Validation loss: 0.47692356, Gradient norm: 3.90755854
INFO:root:At the start of the epoch: mem (CPU python)=17383.61328125MB; mem (CPU total)=21168.109375MB
INFO:root:[   33] Training loss: 0.47258286, Validation loss: 0.47520270, Gradient norm: 3.24155219
INFO:root:At the start of the epoch: mem (CPU python)=17404.77734375MB; mem (CPU total)=21189.015625MB
INFO:root:[   34] Training loss: 0.47650437, Validation loss: 0.48248816, Gradient norm: 4.18254761
INFO:root:At the start of the epoch: mem (CPU python)=17425.9453125MB; mem (CPU total)=21211.43359375MB
INFO:root:[   35] Training loss: 0.47394972, Validation loss: 0.47077456, Gradient norm: 3.58271911
INFO:root:At the start of the epoch: mem (CPU python)=17447.10546875MB; mem (CPU total)=21232.94140625MB
INFO:root:[   36] Training loss: 0.47316087, Validation loss: 0.46838973, Gradient norm: 4.07830750
INFO:root:At the start of the epoch: mem (CPU python)=17468.26953125MB; mem (CPU total)=21253.18359375MB
INFO:root:[   37] Training loss: 0.47456345, Validation loss: 0.46984342, Gradient norm: 4.01084600
INFO:root:At the start of the epoch: mem (CPU python)=17489.43359375MB; mem (CPU total)=21274.9609375MB
INFO:root:[   38] Training loss: 0.47295212, Validation loss: 0.46837625, Gradient norm: 3.91667436
INFO:root:At the start of the epoch: mem (CPU python)=17510.59765625MB; mem (CPU total)=21296.6171875MB
INFO:root:[   39] Training loss: 0.47371291, Validation loss: 0.50680057, Gradient norm: 4.17697993
INFO:root:At the start of the epoch: mem (CPU python)=17531.76171875MB; mem (CPU total)=21317.76171875MB
INFO:root:[   40] Training loss: 0.46893865, Validation loss: 0.45956450, Gradient norm: 3.96040985
INFO:root:At the start of the epoch: mem (CPU python)=17552.9296875MB; mem (CPU total)=21338.58203125MB
INFO:root:[   41] Training loss: 0.46935759, Validation loss: 0.46757246, Gradient norm: 3.93184446
INFO:root:At the start of the epoch: mem (CPU python)=17574.09375MB; mem (CPU total)=21360.11328125MB
INFO:root:[   42] Training loss: 0.46912913, Validation loss: 0.47377159, Gradient norm: 4.03455525
INFO:root:At the start of the epoch: mem (CPU python)=17595.2578125MB; mem (CPU total)=21381.03515625MB
INFO:root:[   43] Training loss: 0.46817096, Validation loss: 0.46762359, Gradient norm: 4.83008156
INFO:root:At the start of the epoch: mem (CPU python)=17616.421875MB; mem (CPU total)=21401.83984375MB
INFO:root:[   44] Training loss: 0.47520651, Validation loss: 0.48208390, Gradient norm: 4.75727210
INFO:root:At the start of the epoch: mem (CPU python)=17637.5859375MB; mem (CPU total)=21423.6796875MB
INFO:root:[   45] Training loss: 0.47004419, Validation loss: 0.47434279, Gradient norm: 4.47848099
INFO:root:At the start of the epoch: mem (CPU python)=17658.75MB; mem (CPU total)=21444.67578125MB
INFO:root:[   46] Training loss: 0.46883528, Validation loss: 0.48038363, Gradient norm: 4.13163360
INFO:root:At the start of the epoch: mem (CPU python)=17679.91015625MB; mem (CPU total)=21464.8984375MB
INFO:root:[   47] Training loss: 0.46657143, Validation loss: 0.47973263, Gradient norm: 4.65923195
INFO:root:At the start of the epoch: mem (CPU python)=17701.078125MB; mem (CPU total)=21486.99609375MB
INFO:root:[   48] Training loss: 0.47146757, Validation loss: 0.49661191, Gradient norm: 4.80993992
INFO:root:At the start of the epoch: mem (CPU python)=17722.2421875MB; mem (CPU total)=21508.453125MB
INFO:root:[   49] Training loss: 0.46633013, Validation loss: 0.46459115, Gradient norm: 4.71605009
INFO:root:At the start of the epoch: mem (CPU python)=17743.40625MB; mem (CPU total)=21528.44140625MB
INFO:root:[   50] Training loss: 0.46753158, Validation loss: 0.48544892, Gradient norm: 4.97365776
INFO:root:At the start of the epoch: mem (CPU python)=17764.5703125MB; mem (CPU total)=21549.6875MB
INFO:root:[   51] Training loss: 0.46975629, Validation loss: 0.47422121, Gradient norm: 4.64662483
INFO:root:At the start of the epoch: mem (CPU python)=17785.73828125MB; mem (CPU total)=21570.83203125MB
INFO:root:[   52] Training loss: 0.46748235, Validation loss: 0.48949627, Gradient norm: 4.82607302
INFO:root:At the start of the epoch: mem (CPU python)=17806.90234375MB; mem (CPU total)=21593.1875MB
INFO:root:[   53] Training loss: 0.46766966, Validation loss: 0.46526037, Gradient norm: 4.74454161
INFO:root:At the start of the epoch: mem (CPU python)=17828.06640625MB; mem (CPU total)=21614.0859375MB
INFO:root:[   54] Training loss: 0.45827875, Validation loss: 0.46097420, Gradient norm: 4.78589176
INFO:root:At the start of the epoch: mem (CPU python)=17849.2265625MB; mem (CPU total)=21635.23046875MB
INFO:root:[   55] Training loss: 0.44923216, Validation loss: 0.45542447, Gradient norm: 5.78219315
INFO:root:At the start of the epoch: mem (CPU python)=17870.39453125MB; mem (CPU total)=21655.6875MB
INFO:root:[   56] Training loss: 0.44641243, Validation loss: 0.44544426, Gradient norm: 5.35775095
INFO:root:At the start of the epoch: mem (CPU python)=17891.55859375MB; mem (CPU total)=21677.03515625MB
INFO:root:[   57] Training loss: 0.44417855, Validation loss: 0.44899216, Gradient norm: 6.06276888
INFO:root:At the start of the epoch: mem (CPU python)=17912.72265625MB; mem (CPU total)=21698.16796875MB
INFO:root:[   58] Training loss: 0.44597833, Validation loss: 0.44884413, Gradient norm: 6.25221703
INFO:root:At the start of the epoch: mem (CPU python)=17933.88671875MB; mem (CPU total)=21719.28515625MB
INFO:root:[   59] Training loss: 0.44386791, Validation loss: 0.45007490, Gradient norm: 5.63425940
INFO:root:At the start of the epoch: mem (CPU python)=17955.05078125MB; mem (CPU total)=21740.4609375MB
INFO:root:[   60] Training loss: 0.44351944, Validation loss: 0.44592371, Gradient norm: 6.09661484
INFO:root:At the start of the epoch: mem (CPU python)=17976.21484375MB; mem (CPU total)=21761.609375MB
INFO:root:[   61] Training loss: 0.44335225, Validation loss: 0.44809949, Gradient norm: 6.28147514
INFO:root:At the start of the epoch: mem (CPU python)=17997.37890625MB; mem (CPU total)=21782.18359375MB
INFO:root:[   62] Training loss: 0.44017044, Validation loss: 0.43399333, Gradient norm: 5.54101923
INFO:root:At the start of the epoch: mem (CPU python)=18018.546875MB; mem (CPU total)=21803.7890625MB
INFO:root:[   63] Training loss: 0.44701845, Validation loss: 0.46489028, Gradient norm: 6.33984753
INFO:root:At the start of the epoch: mem (CPU python)=18039.703125MB; mem (CPU total)=21824.94140625MB
INFO:root:[   64] Training loss: 0.44017532, Validation loss: 0.43354845, Gradient norm: 6.03901203
INFO:root:At the start of the epoch: mem (CPU python)=18060.8671875MB; mem (CPU total)=21846.06640625MB
INFO:root:[   65] Training loss: 0.43836589, Validation loss: 0.45095176, Gradient norm: 5.76981939
INFO:root:At the start of the epoch: mem (CPU python)=18082.03125MB; mem (CPU total)=21867.21875MB
INFO:root:[   66] Training loss: 0.43906558, Validation loss: 0.43428711, Gradient norm: 6.88057508
INFO:root:At the start of the epoch: mem (CPU python)=18103.1953125MB; mem (CPU total)=21888.6171875MB
INFO:root:[   67] Training loss: 0.43712897, Validation loss: 0.45393303, Gradient norm: 5.99280852
INFO:root:At the start of the epoch: mem (CPU python)=18124.359375MB; mem (CPU total)=21909.53125MB
INFO:root:[   68] Training loss: 0.44726557, Validation loss: 0.45337065, Gradient norm: 6.85449623
INFO:root:At the start of the epoch: mem (CPU python)=18145.52734375MB; mem (CPU total)=21930.46484375MB
INFO:root:[   69] Training loss: 0.43578660, Validation loss: 0.45111419, Gradient norm: 6.00112507
INFO:root:At the start of the epoch: mem (CPU python)=18166.69140625MB; mem (CPU total)=21951.6171875MB
INFO:root:[   70] Training loss: 0.44392458, Validation loss: 0.44763582, Gradient norm: 7.26235777
INFO:root:At the start of the epoch: mem (CPU python)=18187.85546875MB; mem (CPU total)=21973.515625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   71] Training loss: 0.44008590, Validation loss: 0.46307357, Gradient norm: 6.86179625
INFO:root:At the start of the epoch: mem (CPU python)=18209.01953125MB; mem (CPU total)=21994.359375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   72] Training loss: 0.41046351, Validation loss: 0.41513126, Gradient norm: 4.83040124
INFO:root:At the start of the epoch: mem (CPU python)=18230.1875MB; mem (CPU total)=22015.80078125MB
INFO:root:[   73] Training loss: 0.39634135, Validation loss: 0.40472309, Gradient norm: 4.21292782
INFO:root:At the start of the epoch: mem (CPU python)=18251.34765625MB; mem (CPU total)=22036.96484375MB
INFO:root:[   74] Training loss: 0.39518339, Validation loss: 0.40138314, Gradient norm: 4.68646655
INFO:root:At the start of the epoch: mem (CPU python)=18272.51171875MB; mem (CPU total)=22058.0234375MB
INFO:root:[   75] Training loss: 0.39654371, Validation loss: 0.40274587, Gradient norm: 5.45353178
INFO:root:At the start of the epoch: mem (CPU python)=18293.67578125MB; mem (CPU total)=22079.171875MB
INFO:root:[   76] Training loss: 0.39540343, Validation loss: 0.41006208, Gradient norm: 5.79472247
INFO:root:At the start of the epoch: mem (CPU python)=18314.83984375MB; mem (CPU total)=22100.56640625MB
INFO:root:[   77] Training loss: 0.39600481, Validation loss: 0.40334787, Gradient norm: 6.43675124
INFO:root:At the start of the epoch: mem (CPU python)=18336.00390625MB; mem (CPU total)=22121.96875MB
INFO:root:[   78] Training loss: 0.39489404, Validation loss: 0.40106372, Gradient norm: 6.80884404
INFO:root:At the start of the epoch: mem (CPU python)=18357.171875MB; mem (CPU total)=22143.11328125MB
INFO:root:[   79] Training loss: 0.39675935, Validation loss: 0.40262854, Gradient norm: 7.57340644
INFO:root:At the start of the epoch: mem (CPU python)=18378.3359375MB; mem (CPU total)=22164.25MB
INFO:root:[   80] Training loss: 0.39535826, Validation loss: 0.40058275, Gradient norm: 7.64621825
INFO:root:At the start of the epoch: mem (CPU python)=18399.5MB; mem (CPU total)=22185.6015625MB
INFO:root:[   81] Training loss: 0.39730239, Validation loss: 0.40706926, Gradient norm: 7.90257873
INFO:root:At the start of the epoch: mem (CPU python)=18420.66015625MB; mem (CPU total)=22208.546875MB
INFO:root:[   82] Training loss: 0.39732688, Validation loss: 0.40515984, Gradient norm: 8.38966165
INFO:root:At the start of the epoch: mem (CPU python)=18441.8203125MB; mem (CPU total)=22229.3203125MB
INFO:root:[   83] Training loss: 0.39697189, Validation loss: 0.40448450, Gradient norm: 9.38543718
INFO:root:At the start of the epoch: mem (CPU python)=18462.984375MB; mem (CPU total)=22250.73828125MB
INFO:root:[   84] Training loss: 0.39838645, Validation loss: 0.41091406, Gradient norm: 9.11435186
INFO:root:At the start of the epoch: mem (CPU python)=18484.15625MB; mem (CPU total)=22271.65234375MB
INFO:root:[   85] Training loss: 0.39851728, Validation loss: 0.40358781, Gradient norm: 9.03877695
INFO:root:At the start of the epoch: mem (CPU python)=18505.3203125MB; mem (CPU total)=22292.578125MB
INFO:root:[   86] Training loss: 0.39760459, Validation loss: 0.40105609, Gradient norm: 10.27808123
INFO:root:At the start of the epoch: mem (CPU python)=18526.484375MB; mem (CPU total)=22313.76171875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   87] Training loss: 0.39796060, Validation loss: 0.40057530, Gradient norm: 10.12514741
INFO:root:At the start of the epoch: mem (CPU python)=18547.6484375MB; mem (CPU total)=22334.95703125MB
INFO:root:[   88] Training loss: 0.39142236, Validation loss: 0.39804119, Gradient norm: 7.26403480
INFO:root:At the start of the epoch: mem (CPU python)=18568.8125MB; mem (CPU total)=22356.72265625MB
INFO:root:[   89] Training loss: 0.39121781, Validation loss: 0.39683070, Gradient norm: 7.75095642
INFO:root:At the start of the epoch: mem (CPU python)=18589.98046875MB; mem (CPU total)=22378.609375MB
INFO:root:[   90] Training loss: 0.39094529, Validation loss: 0.39807498, Gradient norm: 8.62210089
INFO:root:At the start of the epoch: mem (CPU python)=18611.14453125MB; mem (CPU total)=22399.78515625MB
INFO:root:[   91] Training loss: 0.39018557, Validation loss: 0.39770157, Gradient norm: 8.92186118
INFO:root:At the start of the epoch: mem (CPU python)=18632.30859375MB; mem (CPU total)=22420.9453125MB
INFO:root:[   92] Training loss: 0.39063086, Validation loss: 0.40071351, Gradient norm: 8.85935162
INFO:root:At the start of the epoch: mem (CPU python)=18653.46875MB; mem (CPU total)=22442.359375MB
INFO:root:[   93] Training loss: 0.39081839, Validation loss: 0.39582900, Gradient norm: 9.94759617
INFO:root:At the start of the epoch: mem (CPU python)=18674.6328125MB; mem (CPU total)=22464.04296875MB
INFO:root:[   94] Training loss: 0.39158808, Validation loss: 0.39579455, Gradient norm: 10.26442549
INFO:root:At the start of the epoch: mem (CPU python)=18695.796875MB; mem (CPU total)=22485.65625MB
INFO:root:[   95] Training loss: 0.39617017, Validation loss: 0.40383613, Gradient norm: 13.63465510
INFO:root:At the start of the epoch: mem (CPU python)=18716.96484375MB; mem (CPU total)=22506.5703125MB
INFO:root:[   96] Training loss: 0.39845359, Validation loss: 0.39984557, Gradient norm: 14.69860723
INFO:root:At the start of the epoch: mem (CPU python)=18738.12890625MB; mem (CPU total)=22531.12109375MB
INFO:root:[   97] Training loss: 0.39358139, Validation loss: 0.39995479, Gradient norm: 11.46161778
INFO:root:At the start of the epoch: mem (CPU python)=18759.2890625MB; mem (CPU total)=22551.0703125MB
INFO:root:[   98] Training loss: 0.39155339, Validation loss: 0.40575127, Gradient norm: 11.67881706
INFO:root:At the start of the epoch: mem (CPU python)=18780.453125MB; mem (CPU total)=22573.19140625MB
INFO:root:[   99] Training loss: 0.39349613, Validation loss: 0.39940594, Gradient norm: 11.58064099
INFO:root:At the start of the epoch: mem (CPU python)=18801.6171875MB; mem (CPU total)=22595.1953125MB
INFO:root:[  100] Training loss: 0.39214045, Validation loss: 0.40234688, Gradient norm: 12.43693118
INFO:root:At the start of the epoch: mem (CPU python)=18822.78125MB; mem (CPU total)=22616.59765625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[  101] Training loss: 0.39178667, Validation loss: 0.40111005, Gradient norm: 12.54825601
INFO:root:At the start of the epoch: mem (CPU python)=18843.9453125MB; mem (CPU total)=22637.3984375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  102] Training loss: 0.38826911, Validation loss: 0.39481056, Gradient norm: 8.98298192
INFO:root:At the start of the epoch: mem (CPU python)=18865.109375MB; mem (CPU total)=22657.90625MB
INFO:root:[  103] Training loss: 0.38566887, Validation loss: 0.39517834, Gradient norm: 6.23613122
INFO:root:At the start of the epoch: mem (CPU python)=18886.2734375MB; mem (CPU total)=22679.93359375MB
INFO:root:[  104] Training loss: 0.38620710, Validation loss: 0.39395279, Gradient norm: 7.53333921
INFO:root:At the start of the epoch: mem (CPU python)=18907.4375MB; mem (CPU total)=22700.9609375MB
INFO:root:[  105] Training loss: 0.38590742, Validation loss: 0.39392768, Gradient norm: 7.30890389
INFO:root:At the start of the epoch: mem (CPU python)=18928.6015625MB; mem (CPU total)=22721.796875MB
INFO:root:[  106] Training loss: 0.38493533, Validation loss: 0.39293740, Gradient norm: 7.78854776
INFO:root:At the start of the epoch: mem (CPU python)=18949.76953125MB; mem (CPU total)=22743.62109375MB
INFO:root:[  107] Training loss: 0.38540207, Validation loss: 0.39250110, Gradient norm: 8.42112492
INFO:root:At the start of the epoch: mem (CPU python)=18970.93359375MB; mem (CPU total)=22764.6171875MB
INFO:root:[  108] Training loss: 0.38532427, Validation loss: 0.39569253, Gradient norm: 9.43518269
INFO:root:At the start of the epoch: mem (CPU python)=18992.09765625MB; mem (CPU total)=22785.328125MB
INFO:root:[  109] Training loss: 0.38624373, Validation loss: 0.39236215, Gradient norm: 10.45633205
INFO:root:At the start of the epoch: mem (CPU python)=19013.26171875MB; mem (CPU total)=22806.90234375MB
INFO:root:[  110] Training loss: 0.38478553, Validation loss: 0.39254090, Gradient norm: 8.28959094
INFO:root:At the start of the epoch: mem (CPU python)=19034.42578125MB; mem (CPU total)=22828.1328125MB
INFO:root:[  111] Training loss: 0.38492920, Validation loss: 0.39452651, Gradient norm: 10.28068260
INFO:root:At the start of the epoch: mem (CPU python)=19055.58984375MB; mem (CPU total)=22848.65625MB
INFO:root:[  112] Training loss: 0.38512557, Validation loss: 0.39321256, Gradient norm: 9.07937625
INFO:root:At the start of the epoch: mem (CPU python)=19076.75390625MB; mem (CPU total)=22869.98046875MB
INFO:root:[  113] Training loss: 0.38475909, Validation loss: 0.39095874, Gradient norm: 8.11264393
INFO:root:At the start of the epoch: mem (CPU python)=19097.91796875MB; mem (CPU total)=22891.54296875MB
INFO:root:[  114] Training loss: 0.38486060, Validation loss: 0.39249093, Gradient norm: 8.57652604
INFO:root:At the start of the epoch: mem (CPU python)=19119.078125MB; mem (CPU total)=22912.3828125MB
INFO:root:[  115] Training loss: 0.38467822, Validation loss: 0.39272725, Gradient norm: 8.86562877
INFO:root:At the start of the epoch: mem (CPU python)=19140.2421875MB; mem (CPU total)=22933.796875MB
INFO:root:[  116] Training loss: 0.38472085, Validation loss: 0.39215668, Gradient norm: 9.46908181
INFO:root:At the start of the epoch: mem (CPU python)=19161.40625MB; mem (CPU total)=22956.05078125MB
INFO:root:[  117] Training loss: 0.38576380, Validation loss: 0.39344774, Gradient norm: 10.85627494
INFO:root:At the start of the epoch: mem (CPU python)=19182.57421875MB; mem (CPU total)=22976.0390625MB
INFO:root:[  118] Training loss: 0.38512206, Validation loss: 0.39348521, Gradient norm: 10.66974833
INFO:root:At the start of the epoch: mem (CPU python)=19203.73828125MB; mem (CPU total)=22997.74609375MB
INFO:root:[  119] Training loss: 0.38525080, Validation loss: 0.39243410, Gradient norm: 10.77645975
INFO:root:At the start of the epoch: mem (CPU python)=19224.90234375MB; mem (CPU total)=23019.00390625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  120] Training loss: 0.38625822, Validation loss: 0.39179788, Gradient norm: 16.61626856
INFO:root:At the start of the epoch: mem (CPU python)=19246.0625MB; mem (CPU total)=23040.09375MB
INFO:root:[  121] Training loss: 0.38377488, Validation loss: 0.39244393, Gradient norm: 8.20445954
INFO:root:At the start of the epoch: mem (CPU python)=19267.2265625MB; mem (CPU total)=23060.38671875MB
INFO:root:[  122] Training loss: 0.38378663, Validation loss: 0.38984808, Gradient norm: 8.76598807
INFO:root:At the start of the epoch: mem (CPU python)=19288.39453125MB; mem (CPU total)=23081.40234375MB
INFO:root:[  123] Training loss: 0.38371636, Validation loss: 0.39208054, Gradient norm: 8.66414078
INFO:root:At the start of the epoch: mem (CPU python)=19309.5546875MB; mem (CPU total)=23102.5625MB
INFO:root:[  124] Training loss: 0.38392309, Validation loss: 0.39155484, Gradient norm: 9.45627508
INFO:root:At the start of the epoch: mem (CPU python)=19330.72265625MB; mem (CPU total)=23123.7265625MB
INFO:root:[  125] Training loss: 0.38364575, Validation loss: 0.39199770, Gradient norm: 9.28835698
INFO:root:At the start of the epoch: mem (CPU python)=19351.88671875MB; mem (CPU total)=23144.828125MB
INFO:root:[  126] Training loss: 0.38412009, Validation loss: 0.39064009, Gradient norm: 9.46996930
INFO:root:At the start of the epoch: mem (CPU python)=19373.05078125MB; mem (CPU total)=23165.953125MB
INFO:root:[  127] Training loss: 0.38463233, Validation loss: 0.39191833, Gradient norm: 9.81511378
INFO:root:At the start of the epoch: mem (CPU python)=19394.21875MB; mem (CPU total)=23186.55078125MB
INFO:root:[  128] Training loss: 0.38379909, Validation loss: 0.39317785, Gradient norm: 9.65031628
INFO:root:At the start of the epoch: mem (CPU python)=19415.3828125MB; mem (CPU total)=23207.68359375MB
INFO:root:[  129] Training loss: 0.38362787, Validation loss: 0.39200250, Gradient norm: 11.84844289
INFO:root:At the start of the epoch: mem (CPU python)=19436.546875MB; mem (CPU total)=23228.85546875MB
INFO:root:[  130] Training loss: 0.38439125, Validation loss: 0.39291660, Gradient norm: 9.91978269
INFO:root:At the start of the epoch: mem (CPU python)=19457.7109375MB; mem (CPU total)=23250.03515625MB
INFO:root:[  131] Training loss: 0.38433398, Validation loss: 0.39025435, Gradient norm: 11.26471183
INFO:root:At the start of the epoch: mem (CPU python)=19478.87109375MB; mem (CPU total)=23270.703125MB
INFO:root:EP 131: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19500.03515625MB; mem (CPU total)=23291.62890625MB
INFO:root:Training the model took 4614.226s.
INFO:root:Emptying the cuda cache took 0.036s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.34753
INFO:root:EnergyScoreValidation: 0.26413
INFO:root:CRPSValidation: 0.10419
INFO:root:Gaussian NLLValidation: -0.02554
INFO:root:CoverageValidation: 0.76029
INFO:root:IntervalWidthValidation: 0.38102
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.36852
INFO:root:EnergyScoreTest: 0.28327
INFO:root:CRPSTest: 0.11259
INFO:root:Gaussian NLLTest: 0.22891
INFO:root:CoverageTest: 0.72889
INFO:root:IntervalWidthTest: 0.37784
INFO:root:After validation: mem (CPU python)=19806.8671875MB; mem (CPU total)=23298.98046875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=19806.8671875MB; mem (CPU total)=23299.44140625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=19806.8671875MB; mem (CPU total)=23299.046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23299.04296875MB
INFO:root:[    1] Training loss: 0.84016196, Validation loss: 0.74598627, Gradient norm: 0.59897650
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23319.80859375MB
INFO:root:[    2] Training loss: 0.74194691, Validation loss: 0.73773013, Gradient norm: 0.46110783
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23340.5MB
INFO:root:[    3] Training loss: 0.73372599, Validation loss: 0.72321359, Gradient norm: 0.54940244
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23361.46484375MB
INFO:root:[    4] Training loss: 0.71986887, Validation loss: 0.71661227, Gradient norm: 0.72760178
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23382.625MB
INFO:root:[    5] Training loss: 0.69801752, Validation loss: 0.67296020, Gradient norm: 1.04024352
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23403.73828125MB
INFO:root:[    6] Training loss: 0.64798050, Validation loss: 0.62952354, Gradient norm: 1.61887679
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23425.16015625MB
INFO:root:[    7] Training loss: 0.60863507, Validation loss: 0.60833408, Gradient norm: 1.68536163
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23446.2734375MB
INFO:root:[    8] Training loss: 0.59335562, Validation loss: 0.57794162, Gradient norm: 1.99365211
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23469.55859375MB
INFO:root:[    9] Training loss: 0.58281830, Validation loss: 0.56848680, Gradient norm: 2.17418374
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23490.9765625MB
INFO:root:[   10] Training loss: 0.56702988, Validation loss: 0.56037823, Gradient norm: 2.33972164
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23512.27734375MB
INFO:root:[   11] Training loss: 0.55584787, Validation loss: 0.59227703, Gradient norm: 2.40791074
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23533.2890625MB
INFO:root:[   12] Training loss: 0.55537574, Validation loss: 0.54190602, Gradient norm: 2.68251235
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23554.48046875MB
INFO:root:[   13] Training loss: 0.53858827, Validation loss: 0.53997168, Gradient norm: 2.74560764
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23575.87890625MB
INFO:root:[   14] Training loss: 0.53620653, Validation loss: 0.54560085, Gradient norm: 3.03635736
INFO:root:At the start of the epoch: mem (CPU python)=19806.8671875MB; mem (CPU total)=23597.29296875MB
INFO:root:[   15] Training loss: 0.52646067, Validation loss: 0.51853123, Gradient norm: 2.99538730
INFO:root:At the start of the epoch: mem (CPU python)=19824.28515625MB; mem (CPU total)=23617.96484375MB
INFO:root:[   16] Training loss: 0.52487047, Validation loss: 0.52759862, Gradient norm: 3.12433215
INFO:root:At the start of the epoch: mem (CPU python)=19845.4453125MB; mem (CPU total)=23638.72265625MB
INFO:root:[   17] Training loss: 0.52043151, Validation loss: 0.51773750, Gradient norm: 3.68180191
INFO:root:At the start of the epoch: mem (CPU python)=19866.6171875MB; mem (CPU total)=23660.13671875MB
INFO:root:[   18] Training loss: 0.51364846, Validation loss: 0.52187634, Gradient norm: 3.23785799
INFO:root:At the start of the epoch: mem (CPU python)=19887.7734375MB; mem (CPU total)=23681.2890625MB
INFO:root:[   19] Training loss: 0.51156334, Validation loss: 0.50799959, Gradient norm: 3.38055074
INFO:root:At the start of the epoch: mem (CPU python)=19908.94140625MB; mem (CPU total)=23702.484375MB
INFO:root:[   20] Training loss: 0.50891084, Validation loss: 0.50307211, Gradient norm: 3.41721610
INFO:root:At the start of the epoch: mem (CPU python)=19930.10546875MB; mem (CPU total)=23724.92578125MB
INFO:root:[   21] Training loss: 0.50713588, Validation loss: 0.50199161, Gradient norm: 3.53227386
INFO:root:At the start of the epoch: mem (CPU python)=19951.26953125MB; mem (CPU total)=23747.47265625MB
INFO:root:[   22] Training loss: 0.50598517, Validation loss: 0.50516551, Gradient norm: 3.59279891
INFO:root:At the start of the epoch: mem (CPU python)=19972.43359375MB; mem (CPU total)=23769.9140625MB
INFO:root:[   23] Training loss: 0.49940325, Validation loss: 0.49658920, Gradient norm: 3.87410236
INFO:root:At the start of the epoch: mem (CPU python)=19993.6015625MB; mem (CPU total)=23790.921875MB
INFO:root:[   24] Training loss: 0.49647404, Validation loss: 0.49394710, Gradient norm: 3.52292170
INFO:root:At the start of the epoch: mem (CPU python)=20014.765625MB; mem (CPU total)=23812.39453125MB
INFO:root:[   25] Training loss: 0.50102387, Validation loss: 0.49440643, Gradient norm: 4.09569587
INFO:root:At the start of the epoch: mem (CPU python)=20035.92578125MB; mem (CPU total)=23832.9765625MB
INFO:root:[   26] Training loss: 0.49839091, Validation loss: 0.48822768, Gradient norm: 3.87098457
INFO:root:At the start of the epoch: mem (CPU python)=20057.08984375MB; mem (CPU total)=23854.5703125MB
INFO:root:[   27] Training loss: 0.49471902, Validation loss: 0.49158605, Gradient norm: 4.13019097
INFO:root:At the start of the epoch: mem (CPU python)=20078.25390625MB; mem (CPU total)=23875.1015625MB
INFO:root:[   28] Training loss: 0.49778663, Validation loss: 0.49586199, Gradient norm: 3.82411813
INFO:root:At the start of the epoch: mem (CPU python)=20099.41796875MB; mem (CPU total)=23897.4609375MB
INFO:root:[   29] Training loss: 0.49528747, Validation loss: 0.49414387, Gradient norm: 3.93719294
INFO:root:At the start of the epoch: mem (CPU python)=20120.5859375MB; mem (CPU total)=23919.67578125MB
INFO:root:[   30] Training loss: 0.49238590, Validation loss: 0.50338197, Gradient norm: 4.18004246
INFO:root:At the start of the epoch: mem (CPU python)=20141.75MB; mem (CPU total)=23940.5703125MB
INFO:root:[   31] Training loss: 0.49287661, Validation loss: 0.50621965, Gradient norm: 3.73182394
INFO:root:At the start of the epoch: mem (CPU python)=20162.9140625MB; mem (CPU total)=23961.57421875MB
INFO:root:[   32] Training loss: 0.48919034, Validation loss: 0.47807879, Gradient norm: 3.94404523
INFO:root:At the start of the epoch: mem (CPU python)=20184.078125MB; mem (CPU total)=23983.296875MB
INFO:root:[   33] Training loss: 0.49438152, Validation loss: 0.49016202, Gradient norm: 3.92930744
INFO:root:At the start of the epoch: mem (CPU python)=20205.2421875MB; mem (CPU total)=24004.90234375MB
INFO:root:[   34] Training loss: 0.49091665, Validation loss: 0.48896096, Gradient norm: 3.88631454
INFO:root:At the start of the epoch: mem (CPU python)=20226.40625MB; mem (CPU total)=24025.6796875MB
INFO:root:[   35] Training loss: 0.48992302, Validation loss: 0.48840370, Gradient norm: 4.31947739
INFO:root:At the start of the epoch: mem (CPU python)=20247.56640625MB; mem (CPU total)=24046.8828125MB
INFO:root:[   36] Training loss: 0.48730402, Validation loss: 0.48017867, Gradient norm: 4.20213715
INFO:root:At the start of the epoch: mem (CPU python)=20268.73046875MB; mem (CPU total)=24068.38671875MB
INFO:root:[   37] Training loss: 0.48714748, Validation loss: 0.50113751, Gradient norm: 3.88041106
INFO:root:At the start of the epoch: mem (CPU python)=20289.89453125MB; mem (CPU total)=24089.17578125MB
INFO:root:[   38] Training loss: 0.48461261, Validation loss: 0.49941487, Gradient norm: 3.96230282
INFO:root:At the start of the epoch: mem (CPU python)=20311.05859375MB; mem (CPU total)=24109.79296875MB
INFO:root:[   39] Training loss: 0.48837061, Validation loss: 0.47937421, Gradient norm: 4.75439681
INFO:root:At the start of the epoch: mem (CPU python)=20332.2265625MB; mem (CPU total)=24131.70703125MB
INFO:root:[   40] Training loss: 0.48645068, Validation loss: 0.47880239, Gradient norm: 4.49014365
INFO:root:At the start of the epoch: mem (CPU python)=20353.390625MB; mem (CPU total)=24153.49609375MB
INFO:root:[   41] Training loss: 0.49015054, Validation loss: 0.49589467, Gradient norm: 4.78563972
INFO:root:At the start of the epoch: mem (CPU python)=20374.5546875MB; mem (CPU total)=24173.68359375MB
INFO:root:[   42] Training loss: 0.48478177, Validation loss: 0.48362950, Gradient norm: 4.28062493
INFO:root:At the start of the epoch: mem (CPU python)=20395.71875MB; mem (CPU total)=24194.7109375MB
INFO:root:[   43] Training loss: 0.48405205, Validation loss: 0.46626218, Gradient norm: 4.81668728
INFO:root:At the start of the epoch: mem (CPU python)=20416.8828125MB; mem (CPU total)=24215.64453125MB
INFO:root:[   44] Training loss: 0.48506097, Validation loss: 0.46605288, Gradient norm: 4.33101078
INFO:root:At the start of the epoch: mem (CPU python)=20438.04296875MB; mem (CPU total)=24236.40234375MB
INFO:root:[   45] Training loss: 0.48133012, Validation loss: 0.50531472, Gradient norm: 4.70138214
INFO:root:At the start of the epoch: mem (CPU python)=20459.20703125MB; mem (CPU total)=24257.32421875MB
INFO:root:[   46] Training loss: 0.47988489, Validation loss: 0.48288924, Gradient norm: 4.68012684
INFO:root:At the start of the epoch: mem (CPU python)=20480.375MB; mem (CPU total)=24278.2265625MB
INFO:root:[   47] Training loss: 0.48116570, Validation loss: 0.48782780, Gradient norm: 4.52494105
INFO:root:At the start of the epoch: mem (CPU python)=20501.5390625MB; mem (CPU total)=24299.13671875MB
INFO:root:[   48] Training loss: 0.47887191, Validation loss: 0.49320480, Gradient norm: 5.06010417
INFO:root:At the start of the epoch: mem (CPU python)=20522.703125MB; mem (CPU total)=24320.2578125MB
INFO:root:[   49] Training loss: 0.47729033, Validation loss: 0.48447770, Gradient norm: 4.75663844
INFO:root:At the start of the epoch: mem (CPU python)=20543.8671875MB; mem (CPU total)=24340.5MB
INFO:root:[   50] Training loss: 0.48338919, Validation loss: 0.47632819, Gradient norm: 5.29646055
INFO:root:At the start of the epoch: mem (CPU python)=20565.03515625MB; mem (CPU total)=24361.41796875MB
INFO:root:[   51] Training loss: 0.47078505, Validation loss: 0.46958585, Gradient norm: 4.91781473
INFO:root:At the start of the epoch: mem (CPU python)=20586.1953125MB; mem (CPU total)=24382.78125MB
INFO:root:[   52] Training loss: 0.47818882, Validation loss: 0.47924348, Gradient norm: 4.72531738
INFO:root:At the start of the epoch: mem (CPU python)=20607.359375MB; mem (CPU total)=24404.18359375MB
INFO:root:[   53] Training loss: 0.47358436, Validation loss: 0.48234546, Gradient norm: 5.21051606
INFO:root:At the start of the epoch: mem (CPU python)=20628.51953125MB; mem (CPU total)=24426.19140625MB
INFO:root:[   54] Training loss: 0.47786128, Validation loss: 0.47329862, Gradient norm: 5.13587602
INFO:root:At the start of the epoch: mem (CPU python)=20649.68359375MB; mem (CPU total)=24447.0625MB
INFO:root:[   55] Training loss: 0.47834689, Validation loss: 0.45844156, Gradient norm: 5.58351093
INFO:root:At the start of the epoch: mem (CPU python)=20670.84765625MB; mem (CPU total)=24467.96875MB
INFO:root:[   56] Training loss: 0.47569319, Validation loss: 0.47938979, Gradient norm: 5.19941037
INFO:root:At the start of the epoch: mem (CPU python)=20692.015625MB; mem (CPU total)=24489.05078125MB
INFO:root:[   57] Training loss: 0.47413832, Validation loss: 0.48532233, Gradient norm: 5.39255636
INFO:root:At the start of the epoch: mem (CPU python)=20713.1796875MB; mem (CPU total)=24510.19921875MB
INFO:root:[   58] Training loss: 0.48224830, Validation loss: 0.46409796, Gradient norm: 5.49751405
INFO:root:At the start of the epoch: mem (CPU python)=20734.34375MB; mem (CPU total)=24531.33984375MB
INFO:root:[   59] Training loss: 0.47607231, Validation loss: 0.48781190, Gradient norm: 5.51437633
INFO:root:At the start of the epoch: mem (CPU python)=20755.5078125MB; mem (CPU total)=24552.50390625MB
INFO:root:[   60] Training loss: 0.47729675, Validation loss: 0.47043499, Gradient norm: 5.52811815
INFO:root:At the start of the epoch: mem (CPU python)=20776.671875MB; mem (CPU total)=24573.45703125MB
INFO:root:[   61] Training loss: 0.47940554, Validation loss: 0.48369153, Gradient norm: 5.19474406
INFO:root:At the start of the epoch: mem (CPU python)=20797.83984375MB; mem (CPU total)=24594.37109375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   62] Training loss: 0.47233083, Validation loss: 0.47123300, Gradient norm: 6.42835330
INFO:root:At the start of the epoch: mem (CPU python)=20819.00390625MB; mem (CPU total)=24615.8359375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   63] Training loss: 0.44480424, Validation loss: 0.44034508, Gradient norm: 4.62106215
INFO:root:At the start of the epoch: mem (CPU python)=20840.1640625MB; mem (CPU total)=24636.8203125MB
INFO:root:[   64] Training loss: 0.43417356, Validation loss: 0.43572881, Gradient norm: 3.61937416
INFO:root:At the start of the epoch: mem (CPU python)=20861.328125MB; mem (CPU total)=24658.22265625MB
INFO:root:[   65] Training loss: 0.43366670, Validation loss: 0.43993291, Gradient norm: 4.27553925
INFO:root:At the start of the epoch: mem (CPU python)=20882.4921875MB; mem (CPU total)=24679.30859375MB
INFO:root:[   66] Training loss: 0.43475196, Validation loss: 0.43484488, Gradient norm: 5.29909760
INFO:root:At the start of the epoch: mem (CPU python)=20903.66015625MB; mem (CPU total)=24700.69140625MB
INFO:root:[   67] Training loss: 0.43479364, Validation loss: 0.43856842, Gradient norm: 5.87120427
INFO:root:At the start of the epoch: mem (CPU python)=20924.82421875MB; mem (CPU total)=24721.58984375MB
INFO:root:[   68] Training loss: 0.43422886, Validation loss: 0.43526570, Gradient norm: 6.70108039
INFO:root:At the start of the epoch: mem (CPU python)=20945.984375MB; mem (CPU total)=24742.734375MB
INFO:root:[   69] Training loss: 0.43418922, Validation loss: 0.43949508, Gradient norm: 6.71663646
INFO:root:At the start of the epoch: mem (CPU python)=20967.1484375MB; mem (CPU total)=24763.39453125MB
INFO:root:[   70] Training loss: 0.44350787, Validation loss: 0.44354615, Gradient norm: 9.44913533
INFO:root:At the start of the epoch: mem (CPU python)=20988.3125MB; mem (CPU total)=24784.296875MB
INFO:root:[   71] Training loss: 0.43720576, Validation loss: 0.43624307, Gradient norm: 7.73489091
INFO:root:At the start of the epoch: mem (CPU python)=21009.4765625MB; mem (CPU total)=24807.6875MB
INFO:root:[   72] Training loss: 0.43662518, Validation loss: 0.43873038, Gradient norm: 8.13542987
INFO:root:At the start of the epoch: mem (CPU python)=21030.640625MB; mem (CPU total)=24828.765625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   73] Training loss: 0.43701638, Validation loss: 0.44230464, Gradient norm: 8.26536259
INFO:root:At the start of the epoch: mem (CPU python)=21051.8046875MB; mem (CPU total)=24849.875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   74] Training loss: 0.43087776, Validation loss: 0.43237300, Gradient norm: 5.98185070
INFO:root:At the start of the epoch: mem (CPU python)=21072.96875MB; mem (CPU total)=24871.1796875MB
INFO:root:[   75] Training loss: 0.42642075, Validation loss: 0.42959921, Gradient norm: 4.40899801
INFO:root:At the start of the epoch: mem (CPU python)=21094.1328125MB; mem (CPU total)=24892.36328125MB
INFO:root:[   76] Training loss: 0.42632712, Validation loss: 0.42894396, Gradient norm: 3.94053589
INFO:root:At the start of the epoch: mem (CPU python)=21115.296875MB; mem (CPU total)=24913.78125MB
INFO:root:[   77] Training loss: 0.42624474, Validation loss: 0.42895332, Gradient norm: 4.73030087
INFO:root:At the start of the epoch: mem (CPU python)=21136.4609375MB; mem (CPU total)=24934.89453125MB
INFO:root:[   78] Training loss: 0.42519282, Validation loss: 0.42874901, Gradient norm: 4.92288481
INFO:root:At the start of the epoch: mem (CPU python)=21157.62890625MB; mem (CPU total)=24955.765625MB
INFO:root:[   79] Training loss: 0.42609938, Validation loss: 0.43536488, Gradient norm: 6.16195420
INFO:root:At the start of the epoch: mem (CPU python)=21178.79296875MB; mem (CPU total)=24976.56640625MB
INFO:root:[   80] Training loss: 0.42776484, Validation loss: 0.42930828, Gradient norm: 8.84115072
INFO:root:At the start of the epoch: mem (CPU python)=21199.95703125MB; mem (CPU total)=24997.73046875MB
INFO:root:[   81] Training loss: 0.42658607, Validation loss: 0.42951027, Gradient norm: 7.74266681
INFO:root:At the start of the epoch: mem (CPU python)=21221.12109375MB; mem (CPU total)=25018.88671875MB
INFO:root:[   82] Training loss: 0.42659020, Validation loss: 0.42818573, Gradient norm: 6.31476924
INFO:root:At the start of the epoch: mem (CPU python)=21242.28125MB; mem (CPU total)=25040.234375MB
INFO:root:[   83] Training loss: 0.42772115, Validation loss: 0.42964958, Gradient norm: 8.67036140
INFO:root:At the start of the epoch: mem (CPU python)=21263.4453125MB; mem (CPU total)=25061.69921875MB
INFO:root:[   84] Training loss: 0.42693075, Validation loss: 0.43056497, Gradient norm: 7.99202462
INFO:root:At the start of the epoch: mem (CPU python)=21284.61328125MB; mem (CPU total)=25083.79296875MB
INFO:root:[   85] Training loss: 0.42589355, Validation loss: 0.43084891, Gradient norm: 7.66545209
INFO:root:At the start of the epoch: mem (CPU python)=21305.7734375MB; mem (CPU total)=25105.78515625MB
INFO:root:[   86] Training loss: 0.42730850, Validation loss: 0.43040210, Gradient norm: 8.99567913
INFO:root:At the start of the epoch: mem (CPU python)=21326.9375MB; mem (CPU total)=25126.6953125MB
INFO:root:[   87] Training loss: 0.42648718, Validation loss: 0.42816666, Gradient norm: 8.26965769
INFO:root:At the start of the epoch: mem (CPU python)=21348.1015625MB; mem (CPU total)=25148.4140625MB
INFO:root:[   88] Training loss: 0.42665312, Validation loss: 0.43010216, Gradient norm: 8.89728673
INFO:root:At the start of the epoch: mem (CPU python)=21369.265625MB; mem (CPU total)=25170.85546875MB
INFO:root:[   89] Training loss: 0.42643956, Validation loss: 0.42892865, Gradient norm: 9.18237351
INFO:root:At the start of the epoch: mem (CPU python)=21390.4296875MB; mem (CPU total)=25191.8203125MB
INFO:root:[   90] Training loss: 0.42700155, Validation loss: 0.42769809, Gradient norm: 9.62805137
INFO:root:At the start of the epoch: mem (CPU python)=21411.59765625MB; mem (CPU total)=25212.1953125MB
INFO:root:[   91] Training loss: 0.42687606, Validation loss: 0.43045517, Gradient norm: 9.92512871
INFO:root:At the start of the epoch: mem (CPU python)=21432.7578125MB; mem (CPU total)=25233.48046875MB
INFO:root:[   92] Training loss: 0.42712363, Validation loss: 0.42870164, Gradient norm: 11.35482119
INFO:root:At the start of the epoch: mem (CPU python)=21453.921875MB; mem (CPU total)=25254.55859375MB
INFO:root:[   93] Training loss: 0.42685454, Validation loss: 0.43150540, Gradient norm: 11.17775313
INFO:root:At the start of the epoch: mem (CPU python)=21475.0859375MB; mem (CPU total)=25276.0859375MB
INFO:root:[   94] Training loss: 0.42740318, Validation loss: 0.42923663, Gradient norm: 11.67985559
INFO:root:At the start of the epoch: mem (CPU python)=21496.25MB; mem (CPU total)=25296.1953125MB
INFO:root:[   95] Training loss: 0.42746807, Validation loss: 0.43114752, Gradient norm: 12.32704137
INFO:root:At the start of the epoch: mem (CPU python)=21517.41796875MB; mem (CPU total)=25317.53515625MB
INFO:root:[   96] Training loss: 0.43171889, Validation loss: 0.43059573, Gradient norm: 18.73476119
INFO:root:At the start of the epoch: mem (CPU python)=21538.58203125MB; mem (CPU total)=25339.15234375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   97] Training loss: 0.42838336, Validation loss: 0.42922185, Gradient norm: 13.84058301
INFO:root:At the start of the epoch: mem (CPU python)=21559.74609375MB; mem (CPU total)=25360.94921875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   98] Training loss: 0.42579033, Validation loss: 0.42789947, Gradient norm: 9.69979805
INFO:root:At the start of the epoch: mem (CPU python)=21580.91015625MB; mem (CPU total)=25381.8515625MB
INFO:root:[   99] Training loss: 0.42382596, Validation loss: 0.42670203, Gradient norm: 6.75952339
INFO:root:At the start of the epoch: mem (CPU python)=21602.07421875MB; mem (CPU total)=25402.35546875MB
INFO:root:[  100] Training loss: 0.42431503, Validation loss: 0.42641780, Gradient norm: 6.63597015
INFO:root:At the start of the epoch: mem (CPU python)=21623.234375MB; mem (CPU total)=25422.54296875MB
INFO:root:[  101] Training loss: 0.42386490, Validation loss: 0.42658905, Gradient norm: 6.57086709
INFO:root:At the start of the epoch: mem (CPU python)=21644.3984375MB; mem (CPU total)=25444.015625MB
INFO:root:[  102] Training loss: 0.42345821, Validation loss: 0.42618177, Gradient norm: 7.16556405
INFO:root:At the start of the epoch: mem (CPU python)=21665.56640625MB; mem (CPU total)=25465.89453125MB
INFO:root:[  103] Training loss: 0.42394107, Validation loss: 0.42604239, Gradient norm: 7.55505816
INFO:root:At the start of the epoch: mem (CPU python)=21686.7265625MB; mem (CPU total)=25486.94140625MB
INFO:root:[  104] Training loss: 0.42442768, Validation loss: 0.42743259, Gradient norm: 7.80668048
INFO:root:At the start of the epoch: mem (CPU python)=21707.890625MB; mem (CPU total)=25508.3359375MB
INFO:root:[  105] Training loss: 0.42358796, Validation loss: 0.42523052, Gradient norm: 7.77828808
INFO:root:At the start of the epoch: mem (CPU python)=21729.0546875MB; mem (CPU total)=25529.66796875MB
INFO:root:[  106] Training loss: 0.42379290, Validation loss: 0.42823599, Gradient norm: 8.44357942
INFO:root:At the start of the epoch: mem (CPU python)=21750.21875MB; mem (CPU total)=25550.81640625MB
INFO:root:[  107] Training loss: 0.42427704, Validation loss: 0.42858380, Gradient norm: 8.24458057
INFO:root:At the start of the epoch: mem (CPU python)=21771.38671875MB; mem (CPU total)=25571.08203125MB
INFO:root:[  108] Training loss: 0.42374965, Validation loss: 0.42722449, Gradient norm: 8.56610529
INFO:root:At the start of the epoch: mem (CPU python)=21792.55078125MB; mem (CPU total)=25592.89453125MB
INFO:root:[  109] Training loss: 0.42352437, Validation loss: 0.42673756, Gradient norm: 8.84272234
INFO:root:At the start of the epoch: mem (CPU python)=21813.71484375MB; mem (CPU total)=25613.546875MB
INFO:root:[  110] Training loss: 0.42364750, Validation loss: 0.42642274, Gradient norm: 9.26471041
INFO:root:At the start of the epoch: mem (CPU python)=21834.875MB; mem (CPU total)=25634.6640625MB
INFO:root:[  111] Training loss: 0.42411074, Validation loss: 0.42664145, Gradient norm: 9.36949262
INFO:root:At the start of the epoch: mem (CPU python)=21856.04296875MB; mem (CPU total)=25655.8203125MB
INFO:root:[  112] Training loss: 0.42396433, Validation loss: 0.42681899, Gradient norm: 10.54791154
INFO:root:At the start of the epoch: mem (CPU python)=21877.20703125MB; mem (CPU total)=25676.9765625MB
INFO:root:[  113] Training loss: 0.42444006, Validation loss: 0.42764880, Gradient norm: 11.03681525
INFO:root:At the start of the epoch: mem (CPU python)=21898.37109375MB; mem (CPU total)=25698.07421875MB
INFO:root:[  114] Training loss: 0.42416566, Validation loss: 0.42744701, Gradient norm: 11.06894929
INFO:root:At the start of the epoch: mem (CPU python)=21919.53515625MB; mem (CPU total)=25719.2265625MB
INFO:root:EP 114: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=21940.55078125MB; mem (CPU total)=25740.62890625MB
INFO:root:Training the model took 4286.4s.
INFO:root:Emptying the cuda cache took 0.037s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.3843
INFO:root:EnergyScoreValidation: 0.2964
INFO:root:CRPSValidation: 0.11548
INFO:root:Gaussian NLLValidation: 0.21121
INFO:root:CoverageValidation: 0.74327
INFO:root:IntervalWidthValidation: 0.39015
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.40418
INFO:root:EnergyScoreTest: 0.31476
INFO:root:CRPSTest: 0.12416
INFO:root:Gaussian NLLTest: 0.4592
INFO:root:CoverageTest: 0.71139
INFO:root:IntervalWidthTest: 0.38762
INFO:root:After validation: mem (CPU python)=22247.34375MB; mem (CPU total)=25748.22265625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=22247.34375MB; mem (CPU total)=25748.20703125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=22247.34375MB; mem (CPU total)=25748.20703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25748.43359375MB
INFO:root:[    1] Training loss: 0.84681451, Validation loss: 0.74269419, Gradient norm: 0.40316568
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25769.47265625MB
INFO:root:[    2] Training loss: 0.74013127, Validation loss: 0.73655484, Gradient norm: 0.28848054
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25789.8984375MB
INFO:root:[    3] Training loss: 0.72929389, Validation loss: 0.71854420, Gradient norm: 0.30142509
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25811.0625MB
INFO:root:[    4] Training loss: 0.71314165, Validation loss: 0.70763662, Gradient norm: 0.34497777
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25831.984375MB
INFO:root:[    5] Training loss: 0.68542385, Validation loss: 0.65091837, Gradient norm: 0.47521417
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25853.171875MB
INFO:root:[    6] Training loss: 0.62345623, Validation loss: 0.60100469, Gradient norm: 0.61630222
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25874.5703125MB
INFO:root:[    7] Training loss: 0.58327786, Validation loss: 0.57646291, Gradient norm: 0.64415359
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25895.66796875MB
INFO:root:[    8] Training loss: 0.56368294, Validation loss: 0.55258567, Gradient norm: 0.76007249
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25916.7421875MB
INFO:root:[    9] Training loss: 0.55369774, Validation loss: 0.54570236, Gradient norm: 0.93820731
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25937.8515625MB
INFO:root:[   10] Training loss: 0.54112218, Validation loss: 0.53922850, Gradient norm: 1.20977527
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25959.25390625MB
INFO:root:[   11] Training loss: 0.53072042, Validation loss: 0.52908630, Gradient norm: 1.01016744
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=25982.41015625MB
INFO:root:[   12] Training loss: 0.52310234, Validation loss: 0.52216885, Gradient norm: 1.28528439
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=26003.1484375MB
INFO:root:[   13] Training loss: 0.51517668, Validation loss: 0.51443753, Gradient norm: 1.53891105
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=26024.09375MB
INFO:root:[   14] Training loss: 0.49970824, Validation loss: 0.51127394, Gradient norm: 1.48490674
INFO:root:At the start of the epoch: mem (CPU python)=22247.34375MB; mem (CPU total)=26045.54296875MB
INFO:root:[   15] Training loss: 0.49614736, Validation loss: 0.49316882, Gradient norm: 1.64867340
INFO:root:At the start of the epoch: mem (CPU python)=22264.921875MB; mem (CPU total)=26066.67578125MB
INFO:root:[   16] Training loss: 0.48596584, Validation loss: 0.48453431, Gradient norm: 1.48049376
INFO:root:At the start of the epoch: mem (CPU python)=22286.0859375MB; mem (CPU total)=26087.359375MB
INFO:root:[   17] Training loss: 0.48073155, Validation loss: 0.47806324, Gradient norm: 2.02597777
INFO:root:At the start of the epoch: mem (CPU python)=22307.25MB; mem (CPU total)=26108.76953125MB
INFO:root:[   18] Training loss: 0.47753046, Validation loss: 0.49043351, Gradient norm: 1.95892443
INFO:root:At the start of the epoch: mem (CPU python)=22328.4140625MB; mem (CPU total)=26129.92578125MB
INFO:root:[   19] Training loss: 0.47357844, Validation loss: 0.46430120, Gradient norm: 1.95022874
INFO:root:At the start of the epoch: mem (CPU python)=22349.58203125MB; mem (CPU total)=26150.96875MB
INFO:root:[   20] Training loss: 0.46897117, Validation loss: 0.46286146, Gradient norm: 2.29086295
INFO:root:At the start of the epoch: mem (CPU python)=22370.74609375MB; mem (CPU total)=26171.8515625MB
INFO:root:[   21] Training loss: 0.46708484, Validation loss: 0.46732484, Gradient norm: 2.42840885
INFO:root:At the start of the epoch: mem (CPU python)=22391.91015625MB; mem (CPU total)=26200.703125MB
INFO:root:[   22] Training loss: 0.46269729, Validation loss: 0.45616847, Gradient norm: 2.41093114
INFO:root:At the start of the epoch: mem (CPU python)=22413.07421875MB; mem (CPU total)=26267.84375MB
INFO:root:[   23] Training loss: 0.46612328, Validation loss: 0.46002148, Gradient norm: 2.48706471
INFO:root:At the start of the epoch: mem (CPU python)=22434.23046875MB; mem (CPU total)=26332.453125MB
INFO:root:[   24] Training loss: 0.46037992, Validation loss: 0.46780571, Gradient norm: 2.56767614
INFO:root:At the start of the epoch: mem (CPU python)=22455.39453125MB; mem (CPU total)=26392.01953125MB
INFO:root:[   25] Training loss: 0.45672815, Validation loss: 0.45889033, Gradient norm: 2.75487415
INFO:root:At the start of the epoch: mem (CPU python)=22476.5625MB; mem (CPU total)=26451.375MB
INFO:root:[   26] Training loss: 0.45675489, Validation loss: 0.52976028, Gradient norm: 2.62524693
INFO:root:At the start of the epoch: mem (CPU python)=22497.7265625MB; mem (CPU total)=26510.88671875MB
INFO:root:[   27] Training loss: 0.45479445, Validation loss: 0.46409693, Gradient norm: 2.85254155
INFO:root:At the start of the epoch: mem (CPU python)=22518.890625MB; mem (CPU total)=26563.7734375MB
INFO:root:[   28] Training loss: 0.45185658, Validation loss: 0.45974458, Gradient norm: 2.91758389
INFO:root:At the start of the epoch: mem (CPU python)=22540.0546875MB; mem (CPU total)=26614.9140625MB
INFO:root:[   29] Training loss: 0.45348453, Validation loss: 0.45531836, Gradient norm: 3.09559631
INFO:root:At the start of the epoch: mem (CPU python)=22561.21875MB; mem (CPU total)=26665.078125MB
INFO:root:[   30] Training loss: 0.45233002, Validation loss: 0.44722562, Gradient norm: 3.15155799
INFO:root:At the start of the epoch: mem (CPU python)=22582.38671875MB; mem (CPU total)=26713.16796875MB
INFO:root:[   31] Training loss: 0.45366674, Validation loss: 0.45189598, Gradient norm: 3.00812992
INFO:root:At the start of the epoch: mem (CPU python)=22603.55078125MB; mem (CPU total)=26759.46484375MB
INFO:root:[   32] Training loss: 0.45054289, Validation loss: 0.45701669, Gradient norm: 3.52943102
INFO:root:At the start of the epoch: mem (CPU python)=22624.7109375MB; mem (CPU total)=26804.5859375MB
INFO:root:[   33] Training loss: 0.44867498, Validation loss: 0.46218834, Gradient norm: 3.21235759
INFO:root:At the start of the epoch: mem (CPU python)=22645.875MB; mem (CPU total)=26848.3046875MB
INFO:root:[   34] Training loss: 0.45005987, Validation loss: 0.45345068, Gradient norm: 3.37567063
INFO:root:At the start of the epoch: mem (CPU python)=22667.0390625MB; mem (CPU total)=26891.953125MB
INFO:root:[   35] Training loss: 0.45248813, Validation loss: 0.48425185, Gradient norm: 3.24897759
INFO:root:At the start of the epoch: mem (CPU python)=22688.20703125MB; mem (CPU total)=26934.48828125MB
INFO:root:[   36] Training loss: 0.44990404, Validation loss: 0.46259323, Gradient norm: 3.34100858
INFO:root:At the start of the epoch: mem (CPU python)=22709.37109375MB; mem (CPU total)=26975.5078125MB
INFO:root:[   37] Training loss: 0.45208005, Validation loss: 0.45522088, Gradient norm: 3.18622620
INFO:root:At the start of the epoch: mem (CPU python)=22730.53515625MB; mem (CPU total)=27015.82421875MB
INFO:root:[   38] Training loss: 0.44138472, Validation loss: 0.47359840, Gradient norm: 3.68020402
INFO:root:At the start of the epoch: mem (CPU python)=22751.69921875MB; mem (CPU total)=27056.33984375MB
INFO:root:[   39] Training loss: 0.45059468, Validation loss: 0.46146086, Gradient norm: 3.54729601
INFO:root:At the start of the epoch: mem (CPU python)=22772.859375MB; mem (CPU total)=27094.9765625MB
INFO:root:[   40] Training loss: 0.44470345, Validation loss: 0.44806387, Gradient norm: 3.57983824
INFO:root:At the start of the epoch: mem (CPU python)=22794.02734375MB; mem (CPU total)=27133.61328125MB
INFO:root:[   41] Training loss: 0.44613776, Validation loss: 0.45493524, Gradient norm: 3.70051559
INFO:root:At the start of the epoch: mem (CPU python)=22815.19140625MB; mem (CPU total)=27172.28125MB
INFO:root:[   42] Training loss: 0.44309502, Validation loss: 0.45051540, Gradient norm: 3.57700471
INFO:root:At the start of the epoch: mem (CPU python)=22836.3515625MB; mem (CPU total)=27209.4765625MB
INFO:root:[   43] Training loss: 0.44733320, Validation loss: 0.48293344, Gradient norm: 4.11547282
INFO:root:At the start of the epoch: mem (CPU python)=22857.515625MB; mem (CPU total)=27246.65625MB
INFO:root:[   44] Training loss: 0.44796722, Validation loss: 0.45144484, Gradient norm: 3.78005144
INFO:root:At the start of the epoch: mem (CPU python)=22878.6796875MB; mem (CPU total)=27283.3828125MB
INFO:root:[   45] Training loss: 0.44103214, Validation loss: 0.44339637, Gradient norm: 3.62943973
INFO:root:At the start of the epoch: mem (CPU python)=22899.84375MB; mem (CPU total)=27319.94921875MB
INFO:root:[   46] Training loss: 0.44304662, Validation loss: 0.46446200, Gradient norm: 3.96024403
INFO:root:At the start of the epoch: mem (CPU python)=22921.0078125MB; mem (CPU total)=27355.46484375MB
INFO:root:[   47] Training loss: 0.43292834, Validation loss: 0.43704421, Gradient norm: 3.81733187
INFO:root:At the start of the epoch: mem (CPU python)=22942.17578125MB; mem (CPU total)=27391.25390625MB
INFO:root:[   48] Training loss: 0.44502576, Validation loss: 0.44072060, Gradient norm: 4.23588784
INFO:root:At the start of the epoch: mem (CPU python)=22963.33984375MB; mem (CPU total)=27426.80859375MB
INFO:root:[   49] Training loss: 0.44314868, Validation loss: 0.43829119, Gradient norm: 4.42712731
INFO:root:At the start of the epoch: mem (CPU python)=22984.50390625MB; mem (CPU total)=27461.8828125MB
INFO:root:[   50] Training loss: 0.43692940, Validation loss: 0.44410432, Gradient norm: 4.10719784
INFO:root:At the start of the epoch: mem (CPU python)=23005.66796875MB; mem (CPU total)=27496.6953125MB
INFO:root:[   51] Training loss: 0.43938527, Validation loss: 0.48100391, Gradient norm: 4.58367692
INFO:root:At the start of the epoch: mem (CPU python)=23026.828125MB; mem (CPU total)=27530.81640625MB
INFO:root:[   52] Training loss: 0.44285549, Validation loss: 0.43898876, Gradient norm: 3.85711707
INFO:root:At the start of the epoch: mem (CPU python)=23047.99609375MB; mem (CPU total)=27565.62109375MB
INFO:root:[   53] Training loss: 0.44270120, Validation loss: 0.45202209, Gradient norm: 4.97793618
INFO:root:At the start of the epoch: mem (CPU python)=23069.16015625MB; mem (CPU total)=27599.21875MB
INFO:root:[   54] Training loss: 0.44246823, Validation loss: 0.46826431, Gradient norm: 4.40976003
INFO:root:At the start of the epoch: mem (CPU python)=23090.32421875MB; mem (CPU total)=27633.1015625MB
INFO:root:[   55] Training loss: 0.43843744, Validation loss: 0.44345510, Gradient norm: 4.11923679
INFO:root:At the start of the epoch: mem (CPU python)=23111.48828125MB; mem (CPU total)=27666.234375MB
INFO:root:[   56] Training loss: 0.43934279, Validation loss: 0.43781265, Gradient norm: 4.64918062
INFO:root:At the start of the epoch: mem (CPU python)=23132.6484375MB; mem (CPU total)=27699.640625MB
INFO:root:[   57] Training loss: 0.43737026, Validation loss: 0.44439230, Gradient norm: 4.80887379
INFO:root:At the start of the epoch: mem (CPU python)=23153.8125MB; mem (CPU total)=27733.26171875MB
INFO:root:[   58] Training loss: 0.44159175, Validation loss: 0.46755557, Gradient norm: 4.53016154
INFO:root:At the start of the epoch: mem (CPU python)=23174.98046875MB; mem (CPU total)=27766.15234375MB
INFO:root:[   59] Training loss: 0.44251319, Validation loss: 0.45217927, Gradient norm: 4.18848707
INFO:root:At the start of the epoch: mem (CPU python)=23196.14453125MB; mem (CPU total)=27798.80859375MB
INFO:root:[   60] Training loss: 0.43856237, Validation loss: 0.44558831, Gradient norm: 4.84379007
INFO:root:At the start of the epoch: mem (CPU python)=23217.30859375MB; mem (CPU total)=27831.23046875MB
INFO:root:[   61] Training loss: 0.44093397, Validation loss: 0.46016282, Gradient norm: 4.44279255
INFO:root:At the start of the epoch: mem (CPU python)=23238.46875MB; mem (CPU total)=27864.359375MB
INFO:root:[   62] Training loss: 0.43452178, Validation loss: 0.45555869, Gradient norm: 4.77333690
INFO:root:At the start of the epoch: mem (CPU python)=23259.6328125MB; mem (CPU total)=27896.12109375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.43773798, Validation loss: 0.45152043, Gradient norm: 4.87200970
INFO:root:At the start of the epoch: mem (CPU python)=23280.796875MB; mem (CPU total)=27928.5546875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.40608363, Validation loss: 0.41687926, Gradient norm: 3.55727688
INFO:root:At the start of the epoch: mem (CPU python)=23301.96484375MB; mem (CPU total)=27960.8515625MB
INFO:root:[   65] Training loss: 0.39504488, Validation loss: 0.41061898, Gradient norm: 2.32842283
INFO:root:At the start of the epoch: mem (CPU python)=23323.12890625MB; mem (CPU total)=27992.62109375MB
INFO:root:[   66] Training loss: 0.39400652, Validation loss: 0.41231415, Gradient norm: 3.12631119
INFO:root:At the start of the epoch: mem (CPU python)=23344.29296875MB; mem (CPU total)=28024.58984375MB
INFO:root:[   67] Training loss: 0.39442790, Validation loss: 0.40774752, Gradient norm: 3.73028232
INFO:root:At the start of the epoch: mem (CPU python)=23365.45703125MB; mem (CPU total)=28056.47265625MB
INFO:root:[   68] Training loss: 0.39309620, Validation loss: 0.41090655, Gradient norm: 3.96783713
INFO:root:At the start of the epoch: mem (CPU python)=23386.62109375MB; mem (CPU total)=28096.546875MB
INFO:root:[   69] Training loss: 0.39251228, Validation loss: 0.41459015, Gradient norm: 4.35530178
INFO:root:At the start of the epoch: mem (CPU python)=23407.78515625MB; mem (CPU total)=28126.2578125MB
INFO:root:[   70] Training loss: 0.39255257, Validation loss: 0.40980442, Gradient norm: 4.72486744
INFO:root:At the start of the epoch: mem (CPU python)=23428.94921875MB; mem (CPU total)=28157.78125MB
INFO:root:[   71] Training loss: 0.39301019, Validation loss: 0.40931564, Gradient norm: 4.89062206
INFO:root:At the start of the epoch: mem (CPU python)=23450.11328125MB; mem (CPU total)=28188.796875MB
INFO:root:[   72] Training loss: 0.39341649, Validation loss: 0.41050872, Gradient norm: 5.68463350
INFO:root:At the start of the epoch: mem (CPU python)=23471.27734375MB; mem (CPU total)=28220.05078125MB
INFO:root:[   73] Training loss: 0.39935336, Validation loss: 0.43327475, Gradient norm: 6.86156790
INFO:root:At the start of the epoch: mem (CPU python)=23492.4375MB; mem (CPU total)=28250.296875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   74] Training loss: 0.39997871, Validation loss: 0.40970293, Gradient norm: 6.43738132
INFO:root:At the start of the epoch: mem (CPU python)=23513.6015625MB; mem (CPU total)=28281.3203125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   75] Training loss: 0.38848404, Validation loss: 0.40371599, Gradient norm: 3.78420527
INFO:root:At the start of the epoch: mem (CPU python)=23534.76953125MB; mem (CPU total)=28312.7890625MB
INFO:root:[   76] Training loss: 0.38521266, Validation loss: 0.40383839, Gradient norm: 2.36485612
INFO:root:At the start of the epoch: mem (CPU python)=23555.93359375MB; mem (CPU total)=28343.046875MB
INFO:root:[   77] Training loss: 0.38575803, Validation loss: 0.40564246, Gradient norm: 2.87526093
INFO:root:At the start of the epoch: mem (CPU python)=23577.09765625MB; mem (CPU total)=28373.80078125MB
INFO:root:[   78] Training loss: 0.38641581, Validation loss: 0.40404311, Gradient norm: 3.84217599
INFO:root:At the start of the epoch: mem (CPU python)=23598.26171875MB; mem (CPU total)=28404.34375MB
INFO:root:[   79] Training loss: 0.38627165, Validation loss: 0.40320174, Gradient norm: 3.79571516
INFO:root:At the start of the epoch: mem (CPU python)=23619.421875MB; mem (CPU total)=28434.6640625MB
INFO:root:[   80] Training loss: 0.38592885, Validation loss: 0.40290796, Gradient norm: 3.39856733
INFO:root:At the start of the epoch: mem (CPU python)=23640.58984375MB; mem (CPU total)=28465.21875MB
INFO:root:[   81] Training loss: 0.38584857, Validation loss: 0.40209511, Gradient norm: 3.73466829
INFO:root:At the start of the epoch: mem (CPU python)=23661.75390625MB; mem (CPU total)=28495.02734375MB
INFO:root:[   82] Training loss: 0.38497726, Validation loss: 0.40558277, Gradient norm: 3.59685313
INFO:root:At the start of the epoch: mem (CPU python)=23682.91796875MB; mem (CPU total)=28525.26171875MB
INFO:root:[   83] Training loss: 0.38565419, Validation loss: 0.40432559, Gradient norm: 3.97881401
INFO:root:At the start of the epoch: mem (CPU python)=23704.08203125MB; mem (CPU total)=28555.04296875MB
INFO:root:[   84] Training loss: 0.38535719, Validation loss: 0.40262865, Gradient norm: 4.38976486
INFO:root:At the start of the epoch: mem (CPU python)=23725.24609375MB; mem (CPU total)=28585.37890625MB
INFO:root:[   85] Training loss: 0.38618963, Validation loss: 0.40400849, Gradient norm: 4.52248503
INFO:root:At the start of the epoch: mem (CPU python)=23746.41015625MB; mem (CPU total)=28615.62890625MB
INFO:root:[   86] Training loss: 0.38622055, Validation loss: 0.40501880, Gradient norm: 4.82197570
INFO:root:At the start of the epoch: mem (CPU python)=23767.578125MB; mem (CPU total)=28645.4453125MB
INFO:root:[   87] Training loss: 0.38552587, Validation loss: 0.40356300, Gradient norm: 4.92837256
INFO:root:At the start of the epoch: mem (CPU python)=23788.7421875MB; mem (CPU total)=28675.28515625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   88] Training loss: 0.38582688, Validation loss: 0.40471298, Gradient norm: 5.15401167
INFO:root:At the start of the epoch: mem (CPU python)=23809.90625MB; mem (CPU total)=28705.359375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   89] Training loss: 0.38493021, Validation loss: 0.40448748, Gradient norm: 3.41972193
INFO:root:At the start of the epoch: mem (CPU python)=23831.06640625MB; mem (CPU total)=28734.9609375MB
INFO:root:[   90] Training loss: 0.38499408, Validation loss: 0.40130336, Gradient norm: 2.67585456
INFO:root:At the start of the epoch: mem (CPU python)=23852.234375MB; mem (CPU total)=28764.79296875MB
INFO:root:[   91] Training loss: 0.38429268, Validation loss: 0.40114785, Gradient norm: 3.15052835
INFO:root:At the start of the epoch: mem (CPU python)=23873.39453125MB; mem (CPU total)=28794.640625MB
INFO:root:[   92] Training loss: 0.38433679, Validation loss: 0.40369630, Gradient norm: 2.92590175
INFO:root:At the start of the epoch: mem (CPU python)=23894.55859375MB; mem (CPU total)=28824.45703125MB
INFO:root:[   93] Training loss: 0.38475966, Validation loss: 0.40349647, Gradient norm: 3.30821394
INFO:root:At the start of the epoch: mem (CPU python)=23915.72265625MB; mem (CPU total)=28853.5546875MB
INFO:root:[   94] Training loss: 0.38488500, Validation loss: 0.40123783, Gradient norm: 3.24453252
INFO:root:At the start of the epoch: mem (CPU python)=23936.88671875MB; mem (CPU total)=28882.71875MB
INFO:root:[   95] Training loss: 0.38456113, Validation loss: 0.40195257, Gradient norm: 3.29341517
INFO:root:At the start of the epoch: mem (CPU python)=23958.05078125MB; mem (CPU total)=28912.5703125MB
INFO:root:[   96] Training loss: 0.38482877, Validation loss: 0.40472719, Gradient norm: 3.49136664
INFO:root:At the start of the epoch: mem (CPU python)=23979.21875MB; mem (CPU total)=28942.1640625MB
INFO:root:[   97] Training loss: 0.38429271, Validation loss: 0.40278751, Gradient norm: 3.47863279
INFO:root:At the start of the epoch: mem (CPU python)=24000.3828125MB; mem (CPU total)=28970.9921875MB
INFO:root:[   98] Training loss: 0.38468698, Validation loss: 0.40165282, Gradient norm: 3.51406725
INFO:root:At the start of the epoch: mem (CPU python)=24021.54296875MB; mem (CPU total)=29000.265625MB
INFO:root:[   99] Training loss: 0.38396124, Validation loss: 0.40161037, Gradient norm: 3.50644381
INFO:root:At the start of the epoch: mem (CPU python)=24042.70703125MB; mem (CPU total)=29031.58984375MB
INFO:root:[  100] Training loss: 0.38491622, Validation loss: 0.40384909, Gradient norm: 3.48630151
INFO:root:At the start of the epoch: mem (CPU python)=24063.87109375MB; mem (CPU total)=29058.72265625MB
INFO:root:EP 100: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=24085.03515625MB; mem (CPU total)=29084.25MB
INFO:root:Training the model took 4013.845s.
INFO:root:Emptying the cuda cache took 0.036s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.35568
INFO:root:EnergyScoreValidation: 0.27054
INFO:root:CRPSValidation: 0.10594
INFO:root:Gaussian NLLValidation: -0.03417
INFO:root:CoverageValidation: 0.76534
INFO:root:IntervalWidthValidation: 0.38912
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.37999
INFO:root:EnergyScoreTest: 0.29244
INFO:root:CRPSTest: 0.11655
INFO:root:Gaussian NLLTest: 0.27136
INFO:root:CoverageTest: 0.72296
INFO:root:IntervalWidthTest: 0.38602
INFO:root:After validation: mem (CPU python)=24391.64453125MB; mem (CPU total)=29142.84375MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=24391.64453125MB; mem (CPU total)=29147.01953125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=24391.64453125MB; mem (CPU total)=29147.01953125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29150.984375MB
INFO:root:[    1] Training loss: 0.84212006, Validation loss: 0.74339997, Gradient norm: 0.49123327
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29179.90625MB
INFO:root:[    2] Training loss: 0.73973881, Validation loss: 0.74165265, Gradient norm: 0.30469613
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29208.015625MB
INFO:root:[    3] Training loss: 0.72922676, Validation loss: 0.71878196, Gradient norm: 0.41354231
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29236.90234375MB
INFO:root:[    4] Training loss: 0.71333249, Validation loss: 0.69795947, Gradient norm: 0.55334611
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29265.48046875MB
INFO:root:[    5] Training loss: 0.66673839, Validation loss: 0.63198723, Gradient norm: 0.85782050
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29294.32421875MB
INFO:root:[    6] Training loss: 0.60232083, Validation loss: 0.58525206, Gradient norm: 0.99925163
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29323.43359375MB
INFO:root:[    7] Training loss: 0.57687759, Validation loss: 0.56779657, Gradient norm: 1.13387555
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29352.53515625MB
INFO:root:[    8] Training loss: 0.55343868, Validation loss: 0.54596534, Gradient norm: 1.03862273
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29380.8984375MB
INFO:root:[    9] Training loss: 0.55772408, Validation loss: 0.55000044, Gradient norm: 1.45419988
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29409.46875MB
INFO:root:[   10] Training loss: 0.54095086, Validation loss: 0.56220762, Gradient norm: 1.48647305
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29438.11328125MB
INFO:root:[   11] Training loss: 0.53752948, Validation loss: 0.54867832, Gradient norm: 1.59333984
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29471.16796875MB
INFO:root:[   12] Training loss: 0.53126527, Validation loss: 0.53096297, Gradient norm: 1.38180077
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29495.58203125MB
INFO:root:[   13] Training loss: 0.52447628, Validation loss: 0.52581770, Gradient norm: 1.91390710
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29523.7734375MB
INFO:root:[   14] Training loss: 0.52417098, Validation loss: 0.53400530, Gradient norm: 1.94258784
INFO:root:At the start of the epoch: mem (CPU python)=24391.64453125MB; mem (CPU total)=29552.6328125MB
INFO:root:[   15] Training loss: 0.52030892, Validation loss: 0.50843913, Gradient norm: 1.87684158
INFO:root:At the start of the epoch: mem (CPU python)=24409.234375MB; mem (CPU total)=29581.5MB
INFO:root:[   16] Training loss: 0.51296197, Validation loss: 0.51362125, Gradient norm: 2.00695011
INFO:root:At the start of the epoch: mem (CPU python)=24430.39453125MB; mem (CPU total)=29609.89453125MB
INFO:root:[   17] Training loss: 0.50154292, Validation loss: 0.50951814, Gradient norm: 1.97818049
INFO:root:At the start of the epoch: mem (CPU python)=24451.55859375MB; mem (CPU total)=29638.27734375MB
INFO:root:[   18] Training loss: 0.49906817, Validation loss: 0.51261722, Gradient norm: 2.30440313
INFO:root:At the start of the epoch: mem (CPU python)=24472.7265625MB; mem (CPU total)=29666.390625MB
INFO:root:[   19] Training loss: 0.49485494, Validation loss: 0.49015356, Gradient norm: 2.27357795
INFO:root:At the start of the epoch: mem (CPU python)=24493.890625MB; mem (CPU total)=29694.71875MB
INFO:root:[   20] Training loss: 0.49286853, Validation loss: 0.48507891, Gradient norm: 2.69693724
INFO:root:At the start of the epoch: mem (CPU python)=24515.0546875MB; mem (CPU total)=29723.38671875MB
INFO:root:[   21] Training loss: 0.48765260, Validation loss: 0.49937896, Gradient norm: 2.34915701
INFO:root:At the start of the epoch: mem (CPU python)=24536.21875MB; mem (CPU total)=29751.0234375MB
INFO:root:[   22] Training loss: 0.48295676, Validation loss: 0.49208507, Gradient norm: 2.97124806
INFO:root:At the start of the epoch: mem (CPU python)=24557.3828125MB; mem (CPU total)=29779.12109375MB
INFO:root:[   23] Training loss: 0.48673185, Validation loss: 0.49258403, Gradient norm: 2.62964160
INFO:root:At the start of the epoch: mem (CPU python)=24578.546875MB; mem (CPU total)=29807.51953125MB
INFO:root:[   24] Training loss: 0.47924439, Validation loss: 0.48722429, Gradient norm: 3.01421655
INFO:root:At the start of the epoch: mem (CPU python)=24599.70703125MB; mem (CPU total)=29835.66015625MB
INFO:root:[   25] Training loss: 0.48232457, Validation loss: 0.48435080, Gradient norm: 3.15035006
INFO:root:At the start of the epoch: mem (CPU python)=24620.87109375MB; mem (CPU total)=29863.8203125MB
INFO:root:[   26] Training loss: 0.47897431, Validation loss: 0.49347989, Gradient norm: 3.27494782
INFO:root:At the start of the epoch: mem (CPU python)=24642.03515625MB; mem (CPU total)=29891.7109375MB
INFO:root:[   27] Training loss: 0.47672651, Validation loss: 0.47816739, Gradient norm: 3.03566858
INFO:root:At the start of the epoch: mem (CPU python)=24663.19921875MB; mem (CPU total)=29919.58203125MB
INFO:root:[   28] Training loss: 0.47555706, Validation loss: 0.46961454, Gradient norm: 3.21481600
INFO:root:At the start of the epoch: mem (CPU python)=24684.36328125MB; mem (CPU total)=29947.90234375MB
INFO:root:[   29] Training loss: 0.47214314, Validation loss: 0.47386366, Gradient norm: 3.23090661
INFO:root:At the start of the epoch: mem (CPU python)=24705.52734375MB; mem (CPU total)=29975.34765625MB
INFO:root:[   30] Training loss: 0.47105692, Validation loss: 0.46741804, Gradient norm: 3.19323344
INFO:root:At the start of the epoch: mem (CPU python)=24726.6953125MB; mem (CPU total)=30003.546875MB
INFO:root:[   31] Training loss: 0.46781034, Validation loss: 0.46055937, Gradient norm: 3.43271662
INFO:root:At the start of the epoch: mem (CPU python)=24747.859375MB; mem (CPU total)=30031.453125MB
INFO:root:[   32] Training loss: 0.46648591, Validation loss: 0.46851049, Gradient norm: 3.18174052
INFO:root:At the start of the epoch: mem (CPU python)=24769.0234375MB; mem (CPU total)=30059.3671875MB
INFO:root:[   33] Training loss: 0.46324171, Validation loss: 0.49809816, Gradient norm: 3.58318427
INFO:root:At the start of the epoch: mem (CPU python)=24790.1875MB; mem (CPU total)=30087.52734375MB
INFO:root:[   34] Training loss: 0.46515769, Validation loss: 0.46417714, Gradient norm: 3.37875197
INFO:root:At the start of the epoch: mem (CPU python)=24811.34765625MB; mem (CPU total)=30115.9140625MB
INFO:root:[   35] Training loss: 0.46308304, Validation loss: 0.47914377, Gradient norm: 3.91601823
INFO:root:At the start of the epoch: mem (CPU python)=24832.515625MB; mem (CPU total)=30143.265625MB
INFO:root:[   36] Training loss: 0.45757688, Validation loss: 0.46832345, Gradient norm: 3.42122536
INFO:root:At the start of the epoch: mem (CPU python)=24853.6796875MB; mem (CPU total)=30176.3828125MB
INFO:root:[   37] Training loss: 0.46133710, Validation loss: 0.46365624, Gradient norm: 4.26815717
INFO:root:At the start of the epoch: mem (CPU python)=24874.8515625MB; mem (CPU total)=30198.6328125MB
INFO:root:[   38] Training loss: 0.45980314, Validation loss: 0.46363006, Gradient norm: 4.16164602
INFO:root:At the start of the epoch: mem (CPU python)=24896.03125MB; mem (CPU total)=30226.50390625MB
INFO:root:[   39] Training loss: 0.46010891, Validation loss: 0.46527083, Gradient norm: 3.98503131
INFO:root:At the start of the epoch: mem (CPU python)=24917.1953125MB; mem (CPU total)=30253.92578125MB
INFO:root:[   40] Training loss: 0.46648884, Validation loss: 0.47601108, Gradient norm: 4.16792164
INFO:root:At the start of the epoch: mem (CPU python)=24938.3671875MB; mem (CPU total)=30281.60546875MB
INFO:root:[   41] Training loss: 0.45798164, Validation loss: 0.47268592, Gradient norm: 4.15991406
INFO:root:At the start of the epoch: mem (CPU python)=24959.54296875MB; mem (CPU total)=30309.0234375MB
INFO:root:[   42] Training loss: 0.45563995, Validation loss: 0.46588759, Gradient norm: 3.98372795
INFO:root:At the start of the epoch: mem (CPU python)=24980.71484375MB; mem (CPU total)=30336.97265625MB
INFO:root:[   43] Training loss: 0.45729681, Validation loss: 0.53796891, Gradient norm: 3.98046842
INFO:root:At the start of the epoch: mem (CPU python)=25001.8828125MB; mem (CPU total)=30364.3984375MB
INFO:root:[   44] Training loss: 0.45570583, Validation loss: 0.45901116, Gradient norm: 4.39437233
INFO:root:At the start of the epoch: mem (CPU python)=25023.05078125MB; mem (CPU total)=30392.0859375MB
INFO:root:[   45] Training loss: 0.45003489, Validation loss: 0.44839614, Gradient norm: 4.02295686
INFO:root:At the start of the epoch: mem (CPU python)=25044.2265625MB; mem (CPU total)=30419.48046875MB
INFO:root:[   46] Training loss: 0.45250627, Validation loss: 0.44492396, Gradient norm: 3.77772479
INFO:root:At the start of the epoch: mem (CPU python)=25065.39453125MB; mem (CPU total)=30447.14453125MB
INFO:root:[   47] Training loss: 0.45350192, Validation loss: 0.44455035, Gradient norm: 4.49337812
INFO:root:At the start of the epoch: mem (CPU python)=25086.57421875MB; mem (CPU total)=30474.5703125MB
INFO:root:[   48] Training loss: 0.45326161, Validation loss: 0.45386943, Gradient norm: 4.85490552
INFO:root:At the start of the epoch: mem (CPU python)=25107.8046875MB; mem (CPU total)=30501.96875MB
INFO:root:[   49] Training loss: 0.45477140, Validation loss: 0.46661573, Gradient norm: 4.77407438
INFO:root:At the start of the epoch: mem (CPU python)=25128.96875MB; mem (CPU total)=30529.4140625MB
INFO:root:[   50] Training loss: 0.45226807, Validation loss: 0.46001326, Gradient norm: 4.57060798
INFO:root:At the start of the epoch: mem (CPU python)=25150.140625MB; mem (CPU total)=30557.34375MB
INFO:root:[   51] Training loss: 0.45071655, Validation loss: 0.46862235, Gradient norm: 4.59062625
INFO:root:At the start of the epoch: mem (CPU python)=25172.1015625MB; mem (CPU total)=30585.9765625MB
INFO:root:[   52] Training loss: 0.45257964, Validation loss: 0.45907367, Gradient norm: 4.55554960
INFO:root:At the start of the epoch: mem (CPU python)=25193.265625MB; mem (CPU total)=30614.9609375MB
INFO:root:[   53] Training loss: 0.45072070, Validation loss: 0.46812955, Gradient norm: 4.73679468
INFO:root:At the start of the epoch: mem (CPU python)=25214.67578125MB; mem (CPU total)=30642.38671875MB
INFO:root:[   54] Training loss: 0.44701663, Validation loss: 0.43936319, Gradient norm: 4.53313555
INFO:root:At the start of the epoch: mem (CPU python)=25235.95703125MB; mem (CPU total)=30669.62890625MB
INFO:root:[   55] Training loss: 0.45539281, Validation loss: 0.46123667, Gradient norm: 5.03865779
INFO:root:At the start of the epoch: mem (CPU python)=25257.9765625MB; mem (CPU total)=30697.63671875MB
INFO:root:[   56] Training loss: 0.44380291, Validation loss: 0.44523353, Gradient norm: 4.01210405
INFO:root:At the start of the epoch: mem (CPU python)=25279.421875MB; mem (CPU total)=30725.109375MB
INFO:root:[   57] Training loss: 0.44859947, Validation loss: 0.46347363, Gradient norm: 5.21064233
INFO:root:At the start of the epoch: mem (CPU python)=25300.59375MB; mem (CPU total)=30752.703125MB
INFO:root:[   58] Training loss: 0.44662091, Validation loss: 0.49362114, Gradient norm: 4.50519846
INFO:root:At the start of the epoch: mem (CPU python)=25321.7734375MB; mem (CPU total)=30779.50390625MB
INFO:root:[   59] Training loss: 0.45259678, Validation loss: 0.47230003, Gradient norm: 5.27196608
INFO:root:At the start of the epoch: mem (CPU python)=25342.9375MB; mem (CPU total)=30811.453125MB
INFO:root:[   60] Training loss: 0.45125399, Validation loss: 0.46809166, Gradient norm: 4.90202706
INFO:root:At the start of the epoch: mem (CPU python)=25364.109375MB; mem (CPU total)=30838.5859375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.44527904, Validation loss: 0.44408782, Gradient norm: 4.64499259
INFO:root:At the start of the epoch: mem (CPU python)=25385.28515625MB; mem (CPU total)=30865.75MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 0.41255575, Validation loss: 0.42545984, Gradient norm: 3.76896045
INFO:root:At the start of the epoch: mem (CPU python)=25406.44921875MB; mem (CPU total)=30892.99609375MB
INFO:root:[   63] Training loss: 0.40450729, Validation loss: 0.41423401, Gradient norm: 3.45740501
INFO:root:At the start of the epoch: mem (CPU python)=25427.625MB; mem (CPU total)=30920.2265625MB
INFO:root:[   64] Training loss: 0.40108345, Validation loss: 0.41759062, Gradient norm: 3.31919469
INFO:root:At the start of the epoch: mem (CPU python)=25448.80078125MB; mem (CPU total)=30947.21875MB
INFO:root:[   65] Training loss: 0.40036700, Validation loss: 0.41565666, Gradient norm: 3.80629464
INFO:root:At the start of the epoch: mem (CPU python)=25469.98046875MB; mem (CPU total)=30974.68359375MB
INFO:root:[   66] Training loss: 0.40003906, Validation loss: 0.41266349, Gradient norm: 4.60280319
INFO:root:At the start of the epoch: mem (CPU python)=25491.14453125MB; mem (CPU total)=31001.6640625MB
INFO:root:[   67] Training loss: 0.39903507, Validation loss: 0.41530999, Gradient norm: 4.82596420
INFO:root:At the start of the epoch: mem (CPU python)=25512.31640625MB; mem (CPU total)=31028.640625MB
INFO:root:[   68] Training loss: 0.40074710, Validation loss: 0.41737838, Gradient norm: 5.35292057
INFO:root:At the start of the epoch: mem (CPU python)=25533.4921875MB; mem (CPU total)=31061.828125MB
INFO:root:[   69] Training loss: 0.40011326, Validation loss: 0.42263250, Gradient norm: 5.53898022
INFO:root:At the start of the epoch: mem (CPU python)=25554.66015625MB; mem (CPU total)=31083.60546875MB
INFO:root:[   70] Training loss: 0.40116244, Validation loss: 0.41170858, Gradient norm: 5.89497395
INFO:root:At the start of the epoch: mem (CPU python)=25575.95703125MB; mem (CPU total)=31109.87890625MB
INFO:root:[   71] Training loss: 0.39978509, Validation loss: 0.41495578, Gradient norm: 6.03327568
INFO:root:At the start of the epoch: mem (CPU python)=25597.3828125MB; mem (CPU total)=31136.828125MB
INFO:root:[   72] Training loss: 0.40111554, Validation loss: 0.41716331, Gradient norm: 6.92969293
INFO:root:At the start of the epoch: mem (CPU python)=25618.54296875MB; mem (CPU total)=31163.5546875MB
INFO:root:[   73] Training loss: 0.40111563, Validation loss: 0.42543095, Gradient norm: 7.08570238
INFO:root:At the start of the epoch: mem (CPU python)=25640.13671875MB; mem (CPU total)=31191.05078125MB
INFO:root:[   74] Training loss: 0.40163444, Validation loss: 0.41317040, Gradient norm: 7.37414750
INFO:root:At the start of the epoch: mem (CPU python)=25661.64453125MB; mem (CPU total)=31218.2578125MB
INFO:root:[   75] Training loss: 0.40110649, Validation loss: 0.43255470, Gradient norm: 6.87508580
INFO:root:At the start of the epoch: mem (CPU python)=25682.8203125MB; mem (CPU total)=31245.23828125MB
INFO:root:[   76] Training loss: 0.40284191, Validation loss: 0.42021452, Gradient norm: 7.90970348
INFO:root:At the start of the epoch: mem (CPU python)=25703.9921875MB; mem (CPU total)=31272.453125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 0.40295947, Validation loss: 0.41413321, Gradient norm: 8.59975710
INFO:root:At the start of the epoch: mem (CPU python)=25725.15625MB; mem (CPU total)=31299.15234375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 0.39494361, Validation loss: 0.41251237, Gradient norm: 4.88110060
INFO:root:At the start of the epoch: mem (CPU python)=25747.42578125MB; mem (CPU total)=31326.390625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   79] Training loss: 0.39259621, Validation loss: 0.40609217, Gradient norm: 3.66651587
INFO:root:At the start of the epoch: mem (CPU python)=25768.58984375MB; mem (CPU total)=31353.15234375MB
INFO:root:[   80] Training loss: 0.39080535, Validation loss: 0.40642678, Gradient norm: 2.65790714
INFO:root:At the start of the epoch: mem (CPU python)=25789.80078125MB; mem (CPU total)=31379.875MB
INFO:root:[   81] Training loss: 0.38972594, Validation loss: 0.40419274, Gradient norm: 2.63024916
INFO:root:At the start of the epoch: mem (CPU python)=25811.2265625MB; mem (CPU total)=31407.3515625MB
INFO:root:[   82] Training loss: 0.39017275, Validation loss: 0.40558949, Gradient norm: 3.13265205
INFO:root:At the start of the epoch: mem (CPU python)=25832.40234375MB; mem (CPU total)=31434.0625MB
INFO:root:[   83] Training loss: 0.39045975, Validation loss: 0.40628766, Gradient norm: 3.45466341
INFO:root:At the start of the epoch: mem (CPU python)=25853.9140625MB; mem (CPU total)=31461.69921875MB
INFO:root:[   84] Training loss: 0.39043194, Validation loss: 0.40554711, Gradient norm: 3.18182406
INFO:root:At the start of the epoch: mem (CPU python)=25875.23828125MB; mem (CPU total)=31487.58984375MB
INFO:root:[   85] Training loss: 0.38989679, Validation loss: 0.40584672, Gradient norm: 3.22289190
INFO:root:At the start of the epoch: mem (CPU python)=25896.41796875MB; mem (CPU total)=31514.5703125MB
INFO:root:[   86] Training loss: 0.38978918, Validation loss: 0.40647811, Gradient norm: 3.44806909
INFO:root:At the start of the epoch: mem (CPU python)=25917.58203125MB; mem (CPU total)=31541.2890625MB
INFO:root:[   87] Training loss: 0.39042071, Validation loss: 0.40644164, Gradient norm: 3.78336433
INFO:root:At the start of the epoch: mem (CPU python)=25939.2265625MB; mem (CPU total)=31568.76953125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   88] Training loss: 0.39026121, Validation loss: 0.40766125, Gradient norm: 4.26422745
INFO:root:At the start of the epoch: mem (CPU python)=25960.6796875MB; mem (CPU total)=31595.2578125MB
INFO:root:[   89] Training loss: 0.38998518, Validation loss: 0.40449756, Gradient norm: 3.12899297
INFO:root:At the start of the epoch: mem (CPU python)=25981.859375MB; mem (CPU total)=31621.7421875MB
INFO:root:[   90] Training loss: 0.38985041, Validation loss: 0.40603360, Gradient norm: 3.12404301
INFO:root:At the start of the epoch: mem (CPU python)=26003.15234375MB; mem (CPU total)=31648.73828125MB
INFO:root:EP 90: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=26030.125MB; mem (CPU total)=31677.9296875MB
INFO:root:Training the model took 3826.025s.
INFO:root:Emptying the cuda cache took 0.036s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.358
INFO:root:EnergyScoreValidation: 0.27159
INFO:root:CRPSValidation: 0.10669
INFO:root:Gaussian NLLValidation: -0.04347
INFO:root:CoverageValidation: 0.76946
INFO:root:IntervalWidthValidation: 0.39829
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.38288
INFO:root:EnergyScoreTest: 0.29359
INFO:root:CRPSTest: 0.11623
INFO:root:Gaussian NLLTest: 0.1978
INFO:root:CoverageTest: 0.73768
INFO:root:IntervalWidthTest: 0.39769
INFO:root:After validation: mem (CPU python)=26337.015625MB; mem (CPU total)=31716.7265625MB
