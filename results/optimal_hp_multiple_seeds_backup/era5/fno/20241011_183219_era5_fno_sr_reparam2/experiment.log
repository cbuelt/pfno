INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=580.96484375MB; mem (CPU total)=9784.30078125MB
INFO:root:############### Starting experiment with config file era5/fno_sr_reparam2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'era5', 'max_training_set_size': 20000, 'init_steps': 10, 'pred_horizon': 10}
INFO:root:After loading the datasets: mem (CPU python)=5500.45703125MB; mem (CPU total)=9793.20703125MB
INFO:root:###1 out of 2 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 16, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=5500.45703125MB; mem (CPU total)=9793.20703125MB
INFO:root:NumberParameters: 2698534
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=5500.45703125MB; mem (CPU total)=11137.0390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=11146.44140625MB
INFO:root:[    1] Training loss: 0.02438607, Validation loss: 0.01859762, Gradient norm: 0.13338739
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=12544.46875MB
INFO:root:[    2] Training loss: 0.01903994, Validation loss: 0.01807328, Gradient norm: 0.09981035
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=12622.79296875MB
INFO:root:[    3] Training loss: 0.01835447, Validation loss: 0.01717617, Gradient norm: 0.09560495
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=12733.5390625MB
INFO:root:[    4] Training loss: 0.01784430, Validation loss: 0.01669453, Gradient norm: 0.08961272
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=12822.29296875MB
INFO:root:[    5] Training loss: 0.01765032, Validation loss: 0.01646442, Gradient norm: 0.10001606
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=12914.66015625MB
INFO:root:[    6] Training loss: 0.01707553, Validation loss: 0.01702774, Gradient norm: 0.07965468
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13001.01171875MB
INFO:root:[    7] Training loss: 0.01686466, Validation loss: 0.01624165, Gradient norm: 0.09246907
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13092.88671875MB
INFO:root:[    8] Training loss: 0.01648005, Validation loss: 0.01600720, Gradient norm: 0.08481802
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13180.66796875MB
INFO:root:[    9] Training loss: 0.01622589, Validation loss: 0.01628239, Gradient norm: 0.08913543
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13275.0078125MB
INFO:root:[   10] Training loss: 0.01591466, Validation loss: 0.01684455, Gradient norm: 0.08161691
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13360.390625MB
INFO:root:[   11] Training loss: 0.01564848, Validation loss: 0.01637509, Gradient norm: 0.07741982
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13410.0MB
INFO:root:[   12] Training loss: 0.01549081, Validation loss: 0.01572941, Gradient norm: 0.08364175
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13540.3515625MB
INFO:root:[   13] Training loss: 0.01539537, Validation loss: 0.01484768, Gradient norm: 0.08805389
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13617.8828125MB
INFO:root:[   14] Training loss: 0.01512322, Validation loss: 0.01606777, Gradient norm: 0.08234717
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13721.66015625MB
INFO:root:[   15] Training loss: 0.01504683, Validation loss: 0.01443571, Gradient norm: 0.08363100
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13807.9375MB
INFO:root:[   16] Training loss: 0.01491517, Validation loss: 0.01455198, Gradient norm: 0.08449967
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13903.87890625MB
INFO:root:[   17] Training loss: 0.01475668, Validation loss: 0.01498086, Gradient norm: 0.07871610
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=13948.07421875MB
INFO:root:[   18] Training loss: 0.01466157, Validation loss: 0.01433178, Gradient norm: 0.08091790
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=14081.21875MB
INFO:root:[   19] Training loss: 0.01453134, Validation loss: 0.01436706, Gradient norm: 0.07710113
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=14168.5234375MB
INFO:root:[   20] Training loss: 0.01457060, Validation loss: 0.01435162, Gradient norm: 0.08758514
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=14258.23828125MB
INFO:root:[   21] Training loss: 0.01438523, Validation loss: 0.01396324, Gradient norm: 0.07626104
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=14346.8671875MB
INFO:root:[   22] Training loss: 0.01431000, Validation loss: 0.01474550, Gradient norm: 0.07680934
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=14433.31640625MB
INFO:root:[   23] Training loss: 0.01433427, Validation loss: 0.01461579, Gradient norm: 0.08188390
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=14526.87109375MB
INFO:root:[   24] Training loss: 0.01414459, Validation loss: 0.01460682, Gradient norm: 0.07455195
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=14612.60546875MB
INFO:root:[   25] Training loss: 0.01409969, Validation loss: 0.01394518, Gradient norm: 0.07395868
INFO:root:At the start of the epoch: mem (CPU python)=5500.45703125MB; mem (CPU total)=14706.32421875MB
INFO:root:[   26] Training loss: 0.01413527, Validation loss: 0.01415992, Gradient norm: 0.08184056
INFO:root:At the start of the epoch: mem (CPU python)=5543.33203125MB; mem (CPU total)=14793.33203125MB
INFO:root:[   27] Training loss: 0.01401074, Validation loss: 0.01385647, Gradient norm: 0.07414886
INFO:root:At the start of the epoch: mem (CPU python)=5603.3046875MB; mem (CPU total)=14885.9375MB
INFO:root:[   28] Training loss: 0.01395903, Validation loss: 0.01380495, Gradient norm: 0.07644447
INFO:root:At the start of the epoch: mem (CPU python)=5676.6953125MB; mem (CPU total)=14972.74609375MB
INFO:root:[   29] Training loss: 0.01388655, Validation loss: 0.01401118, Gradient norm: 0.07036826
INFO:root:At the start of the epoch: mem (CPU python)=5727.7421875MB; mem (CPU total)=15065.15625MB
INFO:root:[   30] Training loss: 0.01391751, Validation loss: 0.01358019, Gradient norm: 0.07849993
INFO:root:At the start of the epoch: mem (CPU python)=5792.52734375MB; mem (CPU total)=15152.45703125MB
INFO:root:[   31] Training loss: 0.01382966, Validation loss: 0.01403713, Gradient norm: 0.07397930
INFO:root:At the start of the epoch: mem (CPU python)=5850.4296875MB; mem (CPU total)=15241.12890625MB
INFO:root:[   32] Training loss: 0.01379505, Validation loss: 0.01379311, Gradient norm: 0.07411112
INFO:root:At the start of the epoch: mem (CPU python)=5921.78125MB; mem (CPU total)=15335.37890625MB
INFO:root:[   33] Training loss: 0.01371507, Validation loss: 0.01448233, Gradient norm: 0.07178318
INFO:root:At the start of the epoch: mem (CPU python)=5975.98046875MB; mem (CPU total)=15380.6953125MB
INFO:root:[   34] Training loss: 0.01369509, Validation loss: 0.01383160, Gradient norm: 0.07146962
INFO:root:At the start of the epoch: mem (CPU python)=6039.31640625MB; mem (CPU total)=15515.1484375MB
INFO:root:[   35] Training loss: 0.01372042, Validation loss: 0.01340602, Gradient norm: 0.07739686
INFO:root:At the start of the epoch: mem (CPU python)=6097.37890625MB; mem (CPU total)=15600.19921875MB
INFO:root:[   36] Training loss: 0.01362600, Validation loss: 0.01538611, Gradient norm: 0.07007040
INFO:root:At the start of the epoch: mem (CPU python)=6163.76953125MB; mem (CPU total)=15696.38671875MB
INFO:root:[   37] Training loss: 0.01362313, Validation loss: 0.01470492, Gradient norm: 0.07484380
INFO:root:At the start of the epoch: mem (CPU python)=6222.19140625MB; mem (CPU total)=15780.40234375MB
INFO:root:[   38] Training loss: 0.01354674, Validation loss: 0.01355392, Gradient norm: 0.06859728
INFO:root:At the start of the epoch: mem (CPU python)=6286.8203125MB; mem (CPU total)=15873.9375MB
INFO:root:[   39] Training loss: 0.01352930, Validation loss: 0.01360717, Gradient norm: 0.06864847
INFO:root:At the start of the epoch: mem (CPU python)=6354.453125MB; mem (CPU total)=15960.71875MB
INFO:root:[   40] Training loss: 0.01355839, Validation loss: 0.01333497, Gradient norm: 0.07187396
INFO:root:At the start of the epoch: mem (CPU python)=6407.8515625MB; mem (CPU total)=16046.1796875MB
INFO:root:[   41] Training loss: 0.01349042, Validation loss: 0.01509175, Gradient norm: 0.07029790
INFO:root:At the start of the epoch: mem (CPU python)=6474.7578125MB; mem (CPU total)=16132.5234375MB
INFO:root:[   42] Training loss: 0.01353022, Validation loss: 0.01315742, Gradient norm: 0.07587878
INFO:root:At the start of the epoch: mem (CPU python)=6540.01171875MB; mem (CPU total)=16185.359375MB
INFO:root:[   43] Training loss: 0.01350150, Validation loss: 0.01314588, Gradient norm: 0.07523577
INFO:root:At the start of the epoch: mem (CPU python)=6597.23046875MB; mem (CPU total)=16319.69140625MB
INFO:root:[   44] Training loss: 0.01343934, Validation loss: 0.01362326, Gradient norm: 0.07439181
INFO:root:At the start of the epoch: mem (CPU python)=6658.23046875MB; mem (CPU total)=16406.9375MB
INFO:root:[   45] Training loss: 0.01336537, Validation loss: 0.01323129, Gradient norm: 0.06871641
INFO:root:At the start of the epoch: mem (CPU python)=6720.40625MB; mem (CPU total)=16501.9375MB
INFO:root:[   46] Training loss: 0.01340174, Validation loss: 0.01353336, Gradient norm: 0.07360792
INFO:root:At the start of the epoch: mem (CPU python)=6781.3984375MB; mem (CPU total)=16586.90234375MB
INFO:root:[   47] Training loss: 0.01335444, Validation loss: 0.01354780, Gradient norm: 0.06983199
INFO:root:At the start of the epoch: mem (CPU python)=6838.34765625MB; mem (CPU total)=16678.984375MB
INFO:root:[   48] Training loss: 0.01330700, Validation loss: 0.01315562, Gradient norm: 0.06777435
INFO:root:At the start of the epoch: mem (CPU python)=6901.40625MB; mem (CPU total)=16767.73046875MB
INFO:root:[   49] Training loss: 0.01334482, Validation loss: 0.01329969, Gradient norm: 0.07488674
INFO:root:At the start of the epoch: mem (CPU python)=6963.5703125MB; mem (CPU total)=16841.77734375MB
INFO:root:[   50] Training loss: 0.01329559, Validation loss: 0.01345321, Gradient norm: 0.07311971
INFO:root:At the start of the epoch: mem (CPU python)=7023.45703125MB; mem (CPU total)=16945.78515625MB
INFO:root:[   51] Training loss: 0.01328459, Validation loss: 0.01390340, Gradient norm: 0.07339572
INFO:root:At the start of the epoch: mem (CPU python)=7087.92578125MB; mem (CPU total)=17024.45703125MB
INFO:root:[   52] Training loss: 0.01320931, Validation loss: 0.01366938, Gradient norm: 0.06916521
INFO:root:At the start of the epoch: mem (CPU python)=7148.67578125MB; mem (CPU total)=17126.90234375MB
INFO:root:[   53] Training loss: 0.01326316, Validation loss: 0.01329422, Gradient norm: 0.07463453
INFO:root:At the start of the epoch: mem (CPU python)=7209.4609375MB; mem (CPU total)=17213.1953125MB
INFO:root:[   54] Training loss: 0.01321768, Validation loss: 0.01304412, Gradient norm: 0.06948450
INFO:root:At the start of the epoch: mem (CPU python)=7272.078125MB; mem (CPU total)=17307.1875MB
INFO:root:[   55] Training loss: 0.01319082, Validation loss: 0.01301549, Gradient norm: 0.07185584
INFO:root:At the start of the epoch: mem (CPU python)=7338.828125MB; mem (CPU total)=17390.04296875MB
INFO:root:[   56] Training loss: 0.01319233, Validation loss: 0.01386637, Gradient norm: 0.07163331
INFO:root:At the start of the epoch: mem (CPU python)=7401.86328125MB; mem (CPU total)=17484.99609375MB
INFO:root:[   57] Training loss: 0.01314315, Validation loss: 0.01279687, Gradient norm: 0.06828743
INFO:root:At the start of the epoch: mem (CPU python)=7456.16015625MB; mem (CPU total)=17570.68359375MB
INFO:root:[   58] Training loss: 0.01311646, Validation loss: 0.01286996, Gradient norm: 0.06913818
INFO:root:At the start of the epoch: mem (CPU python)=7517.453125MB; mem (CPU total)=17656.3359375MB
INFO:root:[   59] Training loss: 0.01313350, Validation loss: 0.01286040, Gradient norm: 0.07286365
INFO:root:At the start of the epoch: mem (CPU python)=7582.484375MB; mem (CPU total)=17753.109375MB
INFO:root:[   60] Training loss: 0.01317153, Validation loss: 0.01335844, Gradient norm: 0.07523316
INFO:root:At the start of the epoch: mem (CPU python)=7641.3828125MB; mem (CPU total)=17836.76171875MB
INFO:root:[   61] Training loss: 0.01313928, Validation loss: 0.01281692, Gradient norm: 0.07271465
INFO:root:At the start of the epoch: mem (CPU python)=7709.87109375MB; mem (CPU total)=17930.921875MB
INFO:root:[   62] Training loss: 0.01311373, Validation loss: 0.01276697, Gradient norm: 0.07317448
INFO:root:At the start of the epoch: mem (CPU python)=7772.203125MB; mem (CPU total)=17975.0234375MB
INFO:root:[   63] Training loss: 0.01308769, Validation loss: 0.01329939, Gradient norm: 0.06990829
INFO:root:At the start of the epoch: mem (CPU python)=7835.23046875MB; mem (CPU total)=18111.18359375MB
INFO:root:[   64] Training loss: 0.01308652, Validation loss: 0.01318998, Gradient norm: 0.07661870
INFO:root:At the start of the epoch: mem (CPU python)=7893.03515625MB; mem (CPU total)=18196.02734375MB
INFO:root:[   65] Training loss: 0.01302108, Validation loss: 0.01285519, Gradient norm: 0.06972228
INFO:root:At the start of the epoch: mem (CPU python)=7951.08984375MB; mem (CPU total)=18287.94921875MB
INFO:root:[   66] Training loss: 0.01298617, Validation loss: 0.01314907, Gradient norm: 0.06949059
INFO:root:At the start of the epoch: mem (CPU python)=8013.328125MB; mem (CPU total)=18372.70703125MB
INFO:root:[   67] Training loss: 0.01301685, Validation loss: 0.01313464, Gradient norm: 0.06978143
INFO:root:At the start of the epoch: mem (CPU python)=8074.703125MB; mem (CPU total)=18463.875MB
INFO:root:[   68] Training loss: 0.01298799, Validation loss: 0.01380999, Gradient norm: 0.06918032
INFO:root:At the start of the epoch: mem (CPU python)=8140.72265625MB; mem (CPU total)=18553.66015625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   69] Training loss: 0.01300212, Validation loss: 0.01326231, Gradient norm: 0.06895544
INFO:root:At the start of the epoch: mem (CPU python)=8196.9375MB; mem (CPU total)=18640.26953125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   70] Training loss: 0.01255527, Validation loss: 0.01272816, Gradient norm: 0.04380933
INFO:root:At the start of the epoch: mem (CPU python)=8258.6640625MB; mem (CPU total)=18733.0MB
INFO:root:[   71] Training loss: 0.01234452, Validation loss: 0.01259934, Gradient norm: 0.03586145
INFO:root:At the start of the epoch: mem (CPU python)=8329.74609375MB; mem (CPU total)=18819.13671875MB
INFO:root:[   72] Training loss: 0.01229815, Validation loss: 0.01229161, Gradient norm: 0.03689053
INFO:root:At the start of the epoch: mem (CPU python)=8382.64453125MB; mem (CPU total)=18912.00390625MB
INFO:root:[   73] Training loss: 0.01228316, Validation loss: 0.01272644, Gradient norm: 0.03727337
INFO:root:At the start of the epoch: mem (CPU python)=8450.54296875MB; mem (CPU total)=19002.22265625MB
INFO:root:[   74] Training loss: 0.01226851, Validation loss: 0.01255346, Gradient norm: 0.03800888
INFO:root:At the start of the epoch: mem (CPU python)=8507.6875MB; mem (CPU total)=19134.953125MB
INFO:root:[   75] Training loss: 0.01226563, Validation loss: 0.01265583, Gradient norm: 0.04181652
INFO:root:At the start of the epoch: mem (CPU python)=8568.7578125MB; mem (CPU total)=19182.49609375MB
INFO:root:[   76] Training loss: 0.01224937, Validation loss: 0.01237360, Gradient norm: 0.04115848
INFO:root:At the start of the epoch: mem (CPU python)=8639.37890625MB; mem (CPU total)=19268.89453125MB
INFO:root:[   77] Training loss: 0.01224438, Validation loss: 0.01248215, Gradient norm: 0.04100299
INFO:root:At the start of the epoch: mem (CPU python)=8694.75390625MB; mem (CPU total)=19359.5234375MB
INFO:root:[   78] Training loss: 0.01222765, Validation loss: 0.01219486, Gradient norm: 0.04051589
INFO:root:At the start of the epoch: mem (CPU python)=8764.49609375MB; mem (CPU total)=19445.63671875MB
INFO:root:[   79] Training loss: 0.01222261, Validation loss: 0.01240641, Gradient norm: 0.04169581
INFO:root:At the start of the epoch: mem (CPU python)=8816.3984375MB; mem (CPU total)=19539.578125MB
INFO:root:[   80] Training loss: 0.01220282, Validation loss: 0.01235094, Gradient norm: 0.03913649
INFO:root:At the start of the epoch: mem (CPU python)=8885.53125MB; mem (CPU total)=19625.8671875MB
INFO:root:[   81] Training loss: 0.01219560, Validation loss: 0.01220678, Gradient norm: 0.03957009
INFO:root:At the start of the epoch: mem (CPU python)=8939.48828125MB; mem (CPU total)=19721.68359375MB
INFO:root:[   82] Training loss: 0.01218389, Validation loss: 0.01241646, Gradient norm: 0.03588184
INFO:root:At the start of the epoch: mem (CPU python)=9006.29296875MB; mem (CPU total)=19808.625MB
INFO:root:[   83] Training loss: 0.01217693, Validation loss: 0.01247149, Gradient norm: 0.03847863
INFO:root:At the start of the epoch: mem (CPU python)=9063.68359375MB; mem (CPU total)=19900.31640625MB
INFO:root:[   84] Training loss: 0.01219355, Validation loss: 0.01249637, Gradient norm: 0.04310810
INFO:root:At the start of the epoch: mem (CPU python)=9124.6953125MB; mem (CPU total)=19989.1640625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   85] Training loss: 0.01217613, Validation loss: 0.01245245, Gradient norm: 0.04069281
INFO:root:At the start of the epoch: mem (CPU python)=9186.9375MB; mem (CPU total)=20059.71875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   86] Training loss: 0.01207941, Validation loss: 0.01230340, Gradient norm: 0.02965391
INFO:root:At the start of the epoch: mem (CPU python)=9246.93359375MB; mem (CPU total)=20165.359375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   87] Training loss: 0.01202719, Validation loss: 0.01222992, Gradient norm: 0.02277247
INFO:root:At the start of the epoch: mem (CPU python)=9320.43359375MB; mem (CPU total)=20259.359375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:EP 87: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=9373.0859375MB; mem (CPU total)=20345.77734375MB
INFO:root:Training the model took 48216.59s.
INFO:root:Emptying the cuda cache took 0.055s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.0168
INFO:root:EnergyScoreValidation: 0.01218
INFO:root:CRPSValidation: 0.01354
INFO:root:Gaussian NLLValidation: -1.90415
INFO:root:CoverageValidation: 0.80504
INFO:root:IntervalWidthValidation: 0.06129
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.02417
INFO:root:EnergyScoreTest: 0.01865
INFO:root:CRPSTest: 0.02027
INFO:root:Gaussian NLLTest: -0.3928
INFO:root:CoverageTest: 0.67804
INFO:root:IntervalWidthTest: 0.06068
INFO:root:After validation: mem (CPU python)=9849.04296875MB; mem (CPU total)=20427.2734375MB
INFO:root:###2 out of 2 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 16, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=9849.04296875MB; mem (CPU total)=20427.73046875MB
INFO:root:NumberParameters: 2698534
INFO:root:GPU memory allocated: 587202560
INFO:root:After setting up the model: mem (CPU python)=9849.04296875MB; mem (CPU total)=20428.75390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=9849.04296875MB; mem (CPU total)=20429.6953125MB
INFO:root:[    1] Training loss: 0.02414819, Validation loss: 0.01938068, Gradient norm: 0.12738959
INFO:root:At the start of the epoch: mem (CPU python)=9849.04296875MB; mem (CPU total)=20512.18359375MB
INFO:root:[    2] Training loss: 0.01896182, Validation loss: 0.01812908, Gradient norm: 0.09683537
INFO:root:At the start of the epoch: mem (CPU python)=9849.04296875MB; mem (CPU total)=20603.97265625MB
INFO:root:[    3] Training loss: 0.01837500, Validation loss: 0.01822941, Gradient norm: 0.10094127
INFO:root:At the start of the epoch: mem (CPU python)=9849.04296875MB; mem (CPU total)=20701.6328125MB
INFO:root:[    4] Training loss: 0.01789081, Validation loss: 0.01803780, Gradient norm: 0.09434988
INFO:root:At the start of the epoch: mem (CPU python)=9849.04296875MB; mem (CPU total)=20785.87890625MB
INFO:root:[    5] Training loss: 0.01750142, Validation loss: 0.01907492, Gradient norm: 0.09315994
INFO:root:At the start of the epoch: mem (CPU python)=9849.04296875MB; mem (CPU total)=20840.125MB
INFO:root:[    6] Training loss: 0.01716812, Validation loss: 0.01632527, Gradient norm: 0.09239866
INFO:root:At the start of the epoch: mem (CPU python)=9849.04296875MB; mem (CPU total)=20963.66015625MB
INFO:root:[    7] Training loss: 0.01672048, Validation loss: 0.01708651, Gradient norm: 0.08495213
INFO:root:At the start of the epoch: mem (CPU python)=9849.04296875MB; mem (CPU total)=21051.78125MB
INFO:root:[    8] Training loss: 0.01648458, Validation loss: 0.01621472, Gradient norm: 0.08710959
INFO:root:At the start of the epoch: mem (CPU python)=9891.84375MB; mem (CPU total)=21140.14453125MB
INFO:root:[    9] Training loss: 0.01614748, Validation loss: 0.01620971, Gradient norm: 0.08139939
INFO:root:At the start of the epoch: mem (CPU python)=9957.4765625MB; mem (CPU total)=21233.44921875MB
INFO:root:[   10] Training loss: 0.01587077, Validation loss: 0.01594180, Gradient norm: 0.08147722
INFO:root:At the start of the epoch: mem (CPU python)=10024.01953125MB; mem (CPU total)=21277.7890625MB
INFO:root:[   11] Training loss: 0.01562294, Validation loss: 0.01518317, Gradient norm: 0.08010026
INFO:root:At the start of the epoch: mem (CPU python)=10092.3359375MB; mem (CPU total)=21411.29296875MB
INFO:root:[   12] Training loss: 0.01546307, Validation loss: 0.01533204, Gradient norm: 0.08234636
INFO:root:At the start of the epoch: mem (CPU python)=10140.08203125MB; mem (CPU total)=21500.98046875MB
INFO:root:[   13] Training loss: 0.01537063, Validation loss: 0.01508639, Gradient norm: 0.08933742
INFO:root:At the start of the epoch: mem (CPU python)=10222.55078125MB; mem (CPU total)=21599.984375MB
INFO:root:[   14] Training loss: 0.01511888, Validation loss: 0.01477149, Gradient norm: 0.08077402
INFO:root:At the start of the epoch: mem (CPU python)=10276.71484375MB; mem (CPU total)=21682.3671875MB
INFO:root:[   15] Training loss: 0.01487645, Validation loss: 0.01457554, Gradient norm: 0.07539618
INFO:root:At the start of the epoch: mem (CPU python)=10338.1171875MB; mem (CPU total)=21741.28125MB
INFO:root:[   16] Training loss: 0.01477288, Validation loss: 0.01447455, Gradient norm: 0.07533409
INFO:root:At the start of the epoch: mem (CPU python)=10385.77734375MB; mem (CPU total)=21859.00390625MB
INFO:root:[   17] Training loss: 0.01475392, Validation loss: 0.01570782, Gradient norm: 0.08257631
INFO:root:At the start of the epoch: mem (CPU python)=10458.94140625MB; mem (CPU total)=21956.43359375MB
INFO:root:[   18] Training loss: 0.01469000, Validation loss: 0.01475726, Gradient norm: 0.08279766
INFO:root:At the start of the epoch: mem (CPU python)=10517.76171875MB; mem (CPU total)=22039.63671875MB
INFO:root:[   19] Training loss: 0.01443717, Validation loss: 0.01512586, Gradient norm: 0.07435460
INFO:root:At the start of the epoch: mem (CPU python)=10584.234375MB; mem (CPU total)=22084.9375MB
INFO:root:[   20] Training loss: 0.01442328, Validation loss: 0.01528823, Gradient norm: 0.07523169
INFO:root:At the start of the epoch: mem (CPU python)=10642.51953125MB; mem (CPU total)=22219.7890625MB
INFO:root:[   21] Training loss: 0.01429444, Validation loss: 0.01425426, Gradient norm: 0.07646384
INFO:root:At the start of the epoch: mem (CPU python)=10711.4140625MB; mem (CPU total)=22319.96484375MB
INFO:root:[   22] Training loss: 0.01420250, Validation loss: 0.01416872, Gradient norm: 0.07479839
INFO:root:At the start of the epoch: mem (CPU python)=10766.0703125MB; mem (CPU total)=22358.84375MB
INFO:root:[   23] Training loss: 0.01414014, Validation loss: 0.01393257, Gradient norm: 0.07333991
INFO:root:At the start of the epoch: mem (CPU python)=10827.7421875MB; mem (CPU total)=22484.6953125MB
INFO:root:[   24] Training loss: 0.01404227, Validation loss: 0.01416288, Gradient norm: 0.07191668
INFO:root:At the start of the epoch: mem (CPU python)=10890.41015625MB; mem (CPU total)=22578.53515625MB
INFO:root:[   25] Training loss: 0.01400169, Validation loss: 0.01384303, Gradient norm: 0.07153206
INFO:root:At the start of the epoch: mem (CPU python)=10953.9375MB; mem (CPU total)=22665.89453125MB
INFO:root:[   26] Training loss: 0.01400481, Validation loss: 0.01396114, Gradient norm: 0.07863555
INFO:root:At the start of the epoch: mem (CPU python)=11014.0078125MB; mem (CPU total)=22755.9765625MB
INFO:root:[   27] Training loss: 0.01395605, Validation loss: 0.01379477, Gradient norm: 0.07689715
INFO:root:At the start of the epoch: mem (CPU python)=11073.625MB; mem (CPU total)=22845.546875MB
INFO:root:[   28] Training loss: 0.01388025, Validation loss: 0.01388375, Gradient norm: 0.07380382
INFO:root:At the start of the epoch: mem (CPU python)=11136.76171875MB; mem (CPU total)=22932.56640625MB
INFO:root:[   29] Training loss: 0.01388270, Validation loss: 0.01403686, Gradient norm: 0.07806393
INFO:root:At the start of the epoch: mem (CPU python)=11199.8828125MB; mem (CPU total)=23033.2265625MB
INFO:root:[   30] Training loss: 0.01375505, Validation loss: 0.01351888, Gradient norm: 0.07045148
INFO:root:At the start of the epoch: mem (CPU python)=11259.76953125MB; mem (CPU total)=23111.74609375MB
INFO:root:[   31] Training loss: 0.01363289, Validation loss: 0.01344561, Gradient norm: 0.06433510
INFO:root:At the start of the epoch: mem (CPU python)=11321.7421875MB; mem (CPU total)=23210.78125MB
INFO:root:[   32] Training loss: 0.01372049, Validation loss: 0.01416234, Gradient norm: 0.07242407
INFO:root:At the start of the epoch: mem (CPU python)=11383.734375MB; mem (CPU total)=23255.13671875MB
INFO:root:[   33] Training loss: 0.01362561, Validation loss: 0.01395468, Gradient norm: 0.06917139
INFO:root:At the start of the epoch: mem (CPU python)=11443.58203125MB; mem (CPU total)=23368.33984375MB
INFO:root:[   34] Training loss: 0.01362080, Validation loss: 0.01355886, Gradient norm: 0.07383593
INFO:root:At the start of the epoch: mem (CPU python)=11506.80078125MB; mem (CPU total)=23473.8359375MB
INFO:root:[   35] Training loss: 0.01358737, Validation loss: 0.01334860, Gradient norm: 0.06962631
INFO:root:At the start of the epoch: mem (CPU python)=11576.27734375MB; mem (CPU total)=23568.21875MB
INFO:root:[   36] Training loss: 0.01354808, Validation loss: 0.01366649, Gradient norm: 0.07452582
INFO:root:At the start of the epoch: mem (CPU python)=11629.46875MB; mem (CPU total)=23654.75390625MB
INFO:root:[   37] Training loss: 0.01350552, Validation loss: 0.01460839, Gradient norm: 0.07235706
INFO:root:At the start of the epoch: mem (CPU python)=11701.73828125MB; mem (CPU total)=23745.78125MB
INFO:root:[   38] Training loss: 0.01350085, Validation loss: 0.01497994, Gradient norm: 0.07255971
INFO:root:At the start of the epoch: mem (CPU python)=11751.8828125MB; mem (CPU total)=23835.00390625MB
INFO:root:[   39] Training loss: 0.01346420, Validation loss: 0.01445036, Gradient norm: 0.07364509
INFO:root:At the start of the epoch: mem (CPU python)=11819.80078125MB; mem (CPU total)=23930.80078125MB
INFO:root:[   40] Training loss: 0.01343273, Validation loss: 0.01399372, Gradient norm: 0.07409897
INFO:root:At the start of the epoch: mem (CPU python)=11877.125MB; mem (CPU total)=24014.5859375MB
INFO:root:[   41] Training loss: 0.01338647, Validation loss: 0.01353065, Gradient norm: 0.07077984
INFO:root:At the start of the epoch: mem (CPU python)=11943.44140625MB; mem (CPU total)=24109.359375MB
INFO:root:[   42] Training loss: 0.01334286, Validation loss: 0.01367652, Gradient norm: 0.06874809
INFO:root:At the start of the epoch: mem (CPU python)=12001.58984375MB; mem (CPU total)=24155.06640625MB
INFO:root:[   43] Training loss: 0.01339916, Validation loss: 0.01398835, Gradient norm: 0.07650263
INFO:root:At the start of the epoch: mem (CPU python)=12065.87109375MB; mem (CPU total)=24248.80078125MB
INFO:root:[   44] Training loss: 0.01336719, Validation loss: 0.01373907, Gradient norm: 0.07644860
INFO:root:At the start of the epoch: mem (CPU python)=12127.4140625MB; mem (CPU total)=24374.5078125MB
INFO:root:[   45] Training loss: 0.01325294, Validation loss: 0.01406988, Gradient norm: 0.06806703
INFO:root:At the start of the epoch: mem (CPU python)=12191.5703125MB; mem (CPU total)=24427.7109375MB
INFO:root:[   46] Training loss: 0.01330600, Validation loss: 0.01360115, Gradient norm: 0.07312762
INFO:root:At the start of the epoch: mem (CPU python)=12249.75MB; mem (CPU total)=24510.765625MB
INFO:root:[   47] Training loss: 0.01326168, Validation loss: 0.01362773, Gradient norm: 0.07145912
INFO:root:At the start of the epoch: mem (CPU python)=12316.9296875MB; mem (CPU total)=24653.1015625MB
INFO:root:[   48] Training loss: 0.01322050, Validation loss: 0.01452515, Gradient norm: 0.07113524
INFO:root:At the start of the epoch: mem (CPU python)=12371.51171875MB; mem (CPU total)=24763.37109375MB
INFO:root:[   49] Training loss: 0.01320857, Validation loss: 0.01306889, Gradient norm: 0.07080570
INFO:root:At the start of the epoch: mem (CPU python)=12436.04296875MB; mem (CPU total)=24817.41796875MB
INFO:root:[   50] Training loss: 0.01316782, Validation loss: 0.01338054, Gradient norm: 0.06743058
INFO:root:At the start of the epoch: mem (CPU python)=12492.75MB; mem (CPU total)=24908.0859375MB
INFO:root:[   51] Training loss: 0.01320775, Validation loss: 0.01304850, Gradient norm: 0.07551899
INFO:root:At the start of the epoch: mem (CPU python)=12556.3046875MB; mem (CPU total)=25000.19140625MB
INFO:root:[   52] Training loss: 0.01318484, Validation loss: 0.01311440, Gradient norm: 0.07485778
INFO:root:At the start of the epoch: mem (CPU python)=12621.02734375MB; mem (CPU total)=25087.1328125MB
INFO:root:[   53] Training loss: 0.01317216, Validation loss: 0.01369053, Gradient norm: 0.07424413
INFO:root:At the start of the epoch: mem (CPU python)=12691.296875MB; mem (CPU total)=25188.66015625MB
INFO:root:[   54] Training loss: 0.01307228, Validation loss: 0.01399107, Gradient norm: 0.07013396
INFO:root:At the start of the epoch: mem (CPU python)=12741.4765625MB; mem (CPU total)=25269.40234375MB
INFO:root:[   55] Training loss: 0.01308540, Validation loss: 0.01352417, Gradient norm: 0.07048234
INFO:root:At the start of the epoch: mem (CPU python)=12807.4921875MB; mem (CPU total)=25363.1875MB
INFO:root:[   56] Training loss: 0.01308251, Validation loss: 0.01317874, Gradient norm: 0.07691241
INFO:root:At the start of the epoch: mem (CPU python)=12873.5234375MB; mem (CPU total)=25449.109375MB
INFO:root:[   57] Training loss: 0.01302585, Validation loss: 0.01310364, Gradient norm: 0.06610728
INFO:root:At the start of the epoch: mem (CPU python)=12927.49609375MB; mem (CPU total)=25540.30859375MB
INFO:root:[   58] Training loss: 0.01305884, Validation loss: 0.01497456, Gradient norm: 0.07157985
INFO:root:At the start of the epoch: mem (CPU python)=12984.51171875MB; mem (CPU total)=25627.6015625MB
INFO:root:[   59] Training loss: 0.01307307, Validation loss: 0.01343660, Gradient norm: 0.07515770
INFO:root:At the start of the epoch: mem (CPU python)=13059.23828125MB; mem (CPU total)=25682.1875MB
INFO:root:[   60] Training loss: 0.01300611, Validation loss: 0.01291632, Gradient norm: 0.07095395
INFO:root:At the start of the epoch: mem (CPU python)=13113.1015625MB; mem (CPU total)=25808.12109375MB
INFO:root:[   61] Training loss: 0.01300401, Validation loss: 0.01274463, Gradient norm: 0.06859225
INFO:root:At the start of the epoch: mem (CPU python)=13177.671875MB; mem (CPU total)=25893.51171875MB
INFO:root:[   62] Training loss: 0.01299939, Validation loss: 0.01415735, Gradient norm: 0.07188419
INFO:root:At the start of the epoch: mem (CPU python)=13233.68359375MB; mem (CPU total)=25991.8671875MB
INFO:root:[   63] Training loss: 0.01296295, Validation loss: 0.01297337, Gradient norm: 0.07215445
INFO:root:At the start of the epoch: mem (CPU python)=13301.44140625MB; mem (CPU total)=26079.65234375MB
INFO:root:[   64] Training loss: 0.01293683, Validation loss: 0.01283019, Gradient norm: 0.07023880
INFO:root:At the start of the epoch: mem (CPU python)=13359.80078125MB; mem (CPU total)=26169.91015625MB
INFO:root:[   65] Training loss: 0.01293185, Validation loss: 0.01283688, Gradient norm: 0.07424866
INFO:root:At the start of the epoch: mem (CPU python)=13420.31640625MB; mem (CPU total)=26257.44140625MB
INFO:root:[   66] Training loss: 0.01294903, Validation loss: 0.01297908, Gradient norm: 0.07341925
INFO:root:At the start of the epoch: mem (CPU python)=13474.50390625MB; mem (CPU total)=26348.1484375MB
INFO:root:[   67] Training loss: 0.01295665, Validation loss: 0.01275651, Gradient norm: 0.07378185
INFO:root:At the start of the epoch: mem (CPU python)=13547.38671875MB; mem (CPU total)=26403.65625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   68] Training loss: 0.01286875, Validation loss: 0.01305218, Gradient norm: 0.06968162
INFO:root:At the start of the epoch: mem (CPU python)=13608.48046875MB; mem (CPU total)=26523.40234375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   69] Training loss: 0.01246103, Validation loss: 0.01281167, Gradient norm: 0.04441298
INFO:root:At the start of the epoch: mem (CPU python)=13671.8125MB; mem (CPU total)=26582.9609375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   70] Training loss: 0.01224984, Validation loss: 0.01268966, Gradient norm: 0.03205226
INFO:root:At the start of the epoch: mem (CPU python)=13721.7890625MB; mem (CPU total)=26703.74609375MB
INFO:root:[   71] Training loss: 0.01213750, Validation loss: 0.01264064, Gradient norm: 0.02713041
INFO:root:At the start of the epoch: mem (CPU python)=13789.12109375MB; mem (CPU total)=26796.7421875MB
INFO:root:[   72] Training loss: 0.01211523, Validation loss: 0.01239956, Gradient norm: 0.02886850
INFO:root:At the start of the epoch: mem (CPU python)=13850.66796875MB; mem (CPU total)=26882.921875MB
INFO:root:[   73] Training loss: 0.01211075, Validation loss: 0.01268239, Gradient norm: 0.02962108
INFO:root:At the start of the epoch: mem (CPU python)=13913.71484375MB; mem (CPU total)=26979.65234375MB
INFO:root:[   74] Training loss: 0.01209150, Validation loss: 0.01238451, Gradient norm: 0.02994364
INFO:root:At the start of the epoch: mem (CPU python)=13977.6484375MB; mem (CPU total)=27021.9921875MB
INFO:root:[   75] Training loss: 0.01209565, Validation loss: 0.01263216, Gradient norm: 0.03216586
INFO:root:At the start of the epoch: mem (CPU python)=14051.03125MB; mem (CPU total)=27124.14453125MB
INFO:root:[   76] Training loss: 0.01208343, Validation loss: 0.01259557, Gradient norm: 0.03232628
INFO:root:At the start of the epoch: mem (CPU python)=14100.5MB; mem (CPU total)=27242.93359375MB
INFO:root:[   77] Training loss: 0.01206936, Validation loss: 0.01236719, Gradient norm: 0.03072259
INFO:root:At the start of the epoch: mem (CPU python)=14165.60546875MB; mem (CPU total)=27344.7421875MB
INFO:root:[   78] Training loss: 0.01206936, Validation loss: 0.01252678, Gradient norm: 0.03155630
INFO:root:At the start of the epoch: mem (CPU python)=14224.4765625MB; mem (CPU total)=27385.34375MB
INFO:root:[   79] Training loss: 0.01206260, Validation loss: 0.01271561, Gradient norm: 0.03244104
INFO:root:At the start of the epoch: mem (CPU python)=14288.96875MB; mem (CPU total)=27520.80859375MB
INFO:root:[   80] Training loss: 0.01205047, Validation loss: 0.01235308, Gradient norm: 0.03045976
INFO:root:At the start of the epoch: mem (CPU python)=14348.3515625MB; mem (CPU total)=27564.30078125MB
INFO:root:[   81] Training loss: 0.01204397, Validation loss: 0.01240120, Gradient norm: 0.03027760
INFO:root:At the start of the epoch: mem (CPU python)=14419.3125MB; mem (CPU total)=27691.7421875MB
INFO:root:[   82] Training loss: 0.01204808, Validation loss: 0.01245462, Gradient norm: 0.03222050
INFO:root:At the start of the epoch: mem (CPU python)=14463.29296875MB; mem (CPU total)=27784.7421875MB
INFO:root:[   83] Training loss: 0.01203666, Validation loss: 0.01238710, Gradient norm: 0.03019017
INFO:root:At the start of the epoch: mem (CPU python)=14536.09765625MB; mem (CPU total)=27873.31640625MB
INFO:root:[   84] Training loss: 0.01203172, Validation loss: 0.01251542, Gradient norm: 0.03176240
INFO:root:At the start of the epoch: mem (CPU python)=14592.859375MB; mem (CPU total)=27926.39453125MB
INFO:root:[   85] Training loss: 0.01201986, Validation loss: 0.01238121, Gradient norm: 0.03024300
INFO:root:At the start of the epoch: mem (CPU python)=14661.5390625MB; mem (CPU total)=28058.90625MB
INFO:root:[   86] Training loss: 0.01201208, Validation loss: 0.01249878, Gradient norm: 0.02904933
INFO:root:At the start of the epoch: mem (CPU python)=14716.3046875MB; mem (CPU total)=28147.75390625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   87] Training loss: 0.01201143, Validation loss: 0.01221822, Gradient norm: 0.03015098
INFO:root:At the start of the epoch: mem (CPU python)=14781.9453125MB; mem (CPU total)=28193.12890625MB
INFO:root:[   88] Training loss: 0.01197141, Validation loss: 0.01226732, Gradient norm: 0.02404898
INFO:root:At the start of the epoch: mem (CPU python)=14840.1484375MB; mem (CPU total)=28280.8046875MB
INFO:root:[   89] Training loss: 0.01195700, Validation loss: 0.01237383, Gradient norm: 0.02465027
INFO:root:At the start of the epoch: mem (CPU python)=14901.671875MB; mem (CPU total)=28414.9765625MB
INFO:root:[   90] Training loss: 0.01195971, Validation loss: 0.01229745, Gradient norm: 0.02536518
INFO:root:At the start of the epoch: mem (CPU python)=14960.71875MB; mem (CPU total)=28501.58984375MB
INFO:root:[   91] Training loss: 0.01195335, Validation loss: 0.01234796, Gradient norm: 0.02438939
INFO:root:At the start of the epoch: mem (CPU python)=15037.4296875MB; mem (CPU total)=28602.03125MB
INFO:root:[   92] Training loss: 0.01195120, Validation loss: 0.01246823, Gradient norm: 0.02442954
INFO:root:At the start of the epoch: mem (CPU python)=15090.60546875MB; mem (CPU total)=28682.375MB
INFO:root:[   93] Training loss: 0.01194854, Validation loss: 0.01222649, Gradient norm: 0.02393618
INFO:root:At the start of the epoch: mem (CPU python)=15153.91796875MB; mem (CPU total)=28783.3671875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   94] Training loss: 0.01194946, Validation loss: 0.01236127, Gradient norm: 0.02568789
INFO:root:At the start of the epoch: mem (CPU python)=15207.0859375MB; mem (CPU total)=28861.71484375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   95] Training loss: 0.01192645, Validation loss: 0.01236479, Gradient norm: 0.02068858
INFO:root:At the start of the epoch: mem (CPU python)=15276.8125MB; mem (CPU total)=28962.20703125MB
INFO:root:[   96] Training loss: 0.01191489, Validation loss: 0.01232222, Gradient norm: 0.01889388
INFO:root:At the start of the epoch: mem (CPU python)=15337.8984375MB; mem (CPU total)=29041.1015625MB
INFO:root:[   97] Training loss: 0.01190585, Validation loss: 0.01220923, Gradient norm: 0.01896754
INFO:root:At the start of the epoch: mem (CPU python)=15397.47265625MB; mem (CPU total)=29130.94921875MB
INFO:root:[   98] Training loss: 0.01190304, Validation loss: 0.01225961, Gradient norm: 0.01865850
INFO:root:At the start of the epoch: mem (CPU python)=15451.7109375MB; mem (CPU total)=29220.42578125MB
INFO:root:[   99] Training loss: 0.01190481, Validation loss: 0.01226905, Gradient norm: 0.01905642
INFO:root:At the start of the epoch: mem (CPU python)=15520.46484375MB; mem (CPU total)=29308.53515625MB
INFO:root:[  100] Training loss: 0.01190699, Validation loss: 0.01227245, Gradient norm: 0.01865673
INFO:root:At the start of the epoch: mem (CPU python)=15582.85546875MB; mem (CPU total)=29401.5MB
INFO:root:[  101] Training loss: 0.01190325, Validation loss: 0.01225314, Gradient norm: 0.01883854
INFO:root:At the start of the epoch: mem (CPU python)=15654.43359375MB; mem (CPU total)=29455.67578125MB
INFO:root:[  102] Training loss: 0.01189614, Validation loss: 0.01228104, Gradient norm: 0.01894374
INFO:root:At the start of the epoch: mem (CPU python)=15707.09375MB; mem (CPU total)=29541.80859375MB
INFO:root:[  103] Training loss: 0.01189999, Validation loss: 0.01231228, Gradient norm: 0.01882377
INFO:root:At the start of the epoch: mem (CPU python)=15773.09765625MB; mem (CPU total)=29677.296875MB
INFO:root:[  104] Training loss: 0.01190932, Validation loss: 0.01227732, Gradient norm: 0.01966473
INFO:root:At the start of the epoch: mem (CPU python)=15830.94140625MB; mem (CPU total)=29761.33984375MB
INFO:root:[  105] Training loss: 0.01190052, Validation loss: 0.01221303, Gradient norm: 0.01824073
INFO:root:At the start of the epoch: mem (CPU python)=15899.23828125MB; mem (CPU total)=29849.37890625MB
INFO:root:[  106] Training loss: 0.01189717, Validation loss: 0.01227690, Gradient norm: 0.01860684
INFO:root:At the start of the epoch: mem (CPU python)=15956.3203125MB; mem (CPU total)=29903.1171875MB
INFO:root:EP 106: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16021.5078125MB; mem (CPU total)=30042.73046875MB
INFO:root:Training the model took 59329.402s.
INFO:root:Emptying the cuda cache took 0.056s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.01669
INFO:root:EnergyScoreValidation: 0.0122
INFO:root:CRPSValidation: 0.01354
INFO:root:Gaussian NLLValidation: -1.61087
INFO:root:CoverageValidation: 0.78265
INFO:root:IntervalWidthValidation: 0.05739
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.02412
INFO:root:EnergyScoreTest: 0.0188
INFO:root:CRPSTest: 0.02033
INFO:root:Gaussian NLLTest: 0.00382
INFO:root:CoverageTest: 0.64989
INFO:root:IntervalWidthTest: 0.0568
INFO:root:After validation: mem (CPU python)=16477.55078125MB; mem (CPU total)=30086.3125MB
