INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=574.8359375MB; mem (CPU total)=55405.22265625MB
INFO:root:############### Starting experiment with config file ks/uno_sr_dropout.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12454.390625MB; mem (CPU total)=55436.953125MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.390625MB; mem (CPU total)=55436.953125MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=12454.390625MB; mem (CPU total)=56619.00390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=56628.84765625MB
INFO:root:[    1] Training loss: 0.74930245, Validation loss: 0.71977981, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=57818.640625MB
INFO:root:[    2] Training loss: 0.71609041, Validation loss: 0.71054821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=57895.68359375MB
INFO:root:[    3] Training loss: 0.70966364, Validation loss: 0.70749395, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=57960.66796875MB
INFO:root:[    4] Training loss: 0.70803230, Validation loss: 0.70515233, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58009.86328125MB
INFO:root:[    5] Training loss: 0.70218989, Validation loss: 0.69937973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58086.6015625MB
INFO:root:[    6] Training loss: 0.69760624, Validation loss: 0.69624836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58155.52734375MB
INFO:root:[    7] Training loss: 0.69488700, Validation loss: 0.69442895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58201.203125MB
INFO:root:[    8] Training loss: 0.69307498, Validation loss: 0.69392871, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58277.22265625MB
INFO:root:[    9] Training loss: 0.69141030, Validation loss: 0.69177224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58351.9140625MB
INFO:root:[   10] Training loss: 0.68988178, Validation loss: 0.69032304, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58397.6796875MB
INFO:root:[   11] Training loss: 0.68857175, Validation loss: 0.68952556, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58468.6640625MB
INFO:root:[   12] Training loss: 0.68731596, Validation loss: 0.68748147, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58545.77734375MB
INFO:root:[   13] Training loss: 0.68623058, Validation loss: 0.68728668, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58592.34765625MB
INFO:root:[   14] Training loss: 0.68501048, Validation loss: 0.68533998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58658.69140625MB
INFO:root:[   15] Training loss: 0.68415460, Validation loss: 0.68481286, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58735.17578125MB
INFO:root:[   16] Training loss: 0.68304632, Validation loss: 0.68381821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58790.34375MB
INFO:root:[   17] Training loss: 0.68217575, Validation loss: 0.68320168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58850.91796875MB
INFO:root:[   18] Training loss: 0.68167793, Validation loss: 0.68270320, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58927.28125MB
INFO:root:[   19] Training loss: 0.68057068, Validation loss: 0.68154143, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=58987.7265625MB
INFO:root:[   20] Training loss: 0.67966766, Validation loss: 0.68047271, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59041.71875MB
INFO:root:[   21] Training loss: 0.67921717, Validation loss: 0.67943836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59117.1953125MB
INFO:root:[   22] Training loss: 0.67856703, Validation loss: 0.67919409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59183.95703125MB
INFO:root:[   23] Training loss: 0.67768095, Validation loss: 0.67826748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59231.29296875MB
INFO:root:[   24] Training loss: 0.67676446, Validation loss: 0.67683940, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59308.68359375MB
INFO:root:[   25] Training loss: 0.67631181, Validation loss: 0.67758100, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59383.26171875MB
INFO:root:[   26] Training loss: 0.67586773, Validation loss: 0.67742904, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59429.4140625MB
INFO:root:[   27] Training loss: 0.67564026, Validation loss: 0.67614725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59500.3515625MB
INFO:root:[   28] Training loss: 0.67503403, Validation loss: 0.67563728, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59579.16015625MB
INFO:root:[   29] Training loss: 0.67437926, Validation loss: 0.67508833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59629.61328125MB
INFO:root:[   30] Training loss: 0.67405502, Validation loss: 0.67438528, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59680.45703125MB
INFO:root:[   31] Training loss: 0.67374566, Validation loss: 0.67516636, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59730.46875MB
INFO:root:[   32] Training loss: 0.67340007, Validation loss: 0.67356649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59775.05859375MB
INFO:root:[   33] Training loss: 0.67312999, Validation loss: 0.67348773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59813.19140625MB
INFO:root:[   34] Training loss: 0.67299596, Validation loss: 0.67300266, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59847.8515625MB
INFO:root:[   35] Training loss: 0.67237695, Validation loss: 0.67307693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59886.19140625MB
INFO:root:[   36] Training loss: 0.67190795, Validation loss: 0.67264027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=59923.390625MB
INFO:root:[   37] Training loss: 0.67173775, Validation loss: 0.67291848, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=4713.171875MB
INFO:root:[   38] Training loss: 0.67111545, Validation loss: 0.67370719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=4751.67578125MB
INFO:root:[   39] Training loss: 0.67112895, Validation loss: 0.67188561, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=4790.02734375MB
INFO:root:[   40] Training loss: 0.67077949, Validation loss: 0.67201607, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=4828.3671875MB
INFO:root:[   41] Training loss: 0.67064566, Validation loss: 0.67107002, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=4866.37890625MB
INFO:root:[   42] Training loss: 0.67010671, Validation loss: 0.67186642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=4904.98828125MB
INFO:root:[   43] Training loss: 0.66977451, Validation loss: 0.67131693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=4943.2890625MB
INFO:root:[   44] Training loss: 0.66952274, Validation loss: 0.67129792, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=4980.69140625MB
INFO:root:[   45] Training loss: 0.66930571, Validation loss: 0.66969777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5018.71484375MB
INFO:root:[   46] Training loss: 0.66872587, Validation loss: 0.67105862, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5057.2734375MB
INFO:root:[   47] Training loss: 0.66855453, Validation loss: 0.67125295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5095.3125MB
INFO:root:[   48] Training loss: 0.66825360, Validation loss: 0.66905433, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5133.52734375MB
INFO:root:[   49] Training loss: 0.66777227, Validation loss: 0.66828520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5170.81640625MB
INFO:root:[   50] Training loss: 0.66729941, Validation loss: 0.66829388, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5209.28125MB
INFO:root:[   51] Training loss: 0.66672531, Validation loss: 0.66676799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5247.5078125MB
INFO:root:[   52] Training loss: 0.66590280, Validation loss: 0.66664266, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5285.71484375MB
INFO:root:[   53] Training loss: 0.66550590, Validation loss: 0.66731174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5323.921875MB
INFO:root:[   54] Training loss: 0.66540746, Validation loss: 0.66521667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5362.578125MB
INFO:root:[   55] Training loss: 0.66487197, Validation loss: 0.66563603, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5400.59375MB
INFO:root:[   56] Training loss: 0.66400509, Validation loss: 0.66567575, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5438.7109375MB
INFO:root:[   57] Training loss: 0.66367093, Validation loss: 0.66530010, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5476.546875MB
INFO:root:[   58] Training loss: 0.66313316, Validation loss: 0.66511437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5514.8359375MB
INFO:root:[   59] Training loss: 0.66335466, Validation loss: 0.66354814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5552.375MB
INFO:root:[   60] Training loss: 0.66237370, Validation loss: 0.66359890, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5590.52734375MB
INFO:root:[   61] Training loss: 0.66232293, Validation loss: 0.66303678, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5628.69140625MB
INFO:root:[   62] Training loss: 0.66136694, Validation loss: 0.66282590, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5666.69140625MB
INFO:root:[   63] Training loss: 0.66124500, Validation loss: 0.66118332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5704.4140625MB
INFO:root:[   64] Training loss: 0.66117799, Validation loss: 0.66159451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5742.86328125MB
INFO:root:[   65] Training loss: 0.66059171, Validation loss: 0.66119158, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5780.98828125MB
INFO:root:[   66] Training loss: 0.66040929, Validation loss: 0.66189826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5819.53515625MB
INFO:root:[   67] Training loss: 0.66024915, Validation loss: 0.66062544, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5857.75390625MB
INFO:root:[   68] Training loss: 0.66000369, Validation loss: 0.66120705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5895.2578125MB
INFO:root:[   69] Training loss: 0.65973053, Validation loss: 0.66057719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5933.7109375MB
INFO:root:[   70] Training loss: 0.65974309, Validation loss: 0.65994560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=5971.875MB
INFO:root:[   71] Training loss: 0.65921630, Validation loss: 0.65922769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6010.21484375MB
INFO:root:[   72] Training loss: 0.65892939, Validation loss: 0.65962884, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6048.62109375MB
INFO:root:[   73] Training loss: 0.65886561, Validation loss: 0.65941961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6086.27734375MB
INFO:root:[   74] Training loss: 0.65888223, Validation loss: 0.66123045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6124.44921875MB
INFO:root:[   75] Training loss: 0.65846212, Validation loss: 0.65942815, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6162.546875MB
INFO:root:[   76] Training loss: 0.65808072, Validation loss: 0.65901493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6201.18359375MB
INFO:root:[   77] Training loss: 0.65819400, Validation loss: 0.66021382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6240.1640625MB
INFO:root:[   78] Training loss: 0.65784638, Validation loss: 0.65901974, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6279.02734375MB
INFO:root:[   79] Training loss: 0.65789678, Validation loss: 0.65918751, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6317.53125MB
INFO:root:[   80] Training loss: 0.65782169, Validation loss: 0.65927856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6355.67578125MB
INFO:root:[   81] Training loss: 0.65767608, Validation loss: 0.65939797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6393.7421875MB
INFO:root:[   82] Training loss: 0.65756607, Validation loss: 0.65881096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6432.1875MB
INFO:root:[   83] Training loss: 0.65774871, Validation loss: 0.65803134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6470.45703125MB
INFO:root:[   84] Training loss: 0.65723676, Validation loss: 0.65794516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6508.7890625MB
INFO:root:[   85] Training loss: 0.65763673, Validation loss: 0.65824435, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6547.15234375MB
INFO:root:[   86] Training loss: 0.65721438, Validation loss: 0.65833314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6585.51171875MB
INFO:root:[   87] Training loss: 0.65685611, Validation loss: 0.65883486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6623.6328125MB
INFO:root:[   88] Training loss: 0.65683791, Validation loss: 0.65806027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6661.73828125MB
INFO:root:[   89] Training loss: 0.65678731, Validation loss: 0.65900560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6699.60546875MB
INFO:root:[   90] Training loss: 0.65639583, Validation loss: 0.65774240, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6737.85546875MB
INFO:root:[   91] Training loss: 0.65654862, Validation loss: 0.65820781, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6776.24609375MB
INFO:root:[   92] Training loss: 0.65634790, Validation loss: 0.65704377, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6813.91796875MB
INFO:root:[   93] Training loss: 0.65652293, Validation loss: 0.65815618, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6852.27734375MB
INFO:root:[   94] Training loss: 0.65576488, Validation loss: 0.65799896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6890.41015625MB
INFO:root:[   95] Training loss: 0.65549138, Validation loss: 0.65786175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6928.703125MB
INFO:root:[   96] Training loss: 0.65640957, Validation loss: 0.65758128, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=6967.078125MB
INFO:root:[   97] Training loss: 0.65568822, Validation loss: 0.65638802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7004.97265625MB
INFO:root:[   98] Training loss: 0.65577009, Validation loss: 0.65718763, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7043.37890625MB
INFO:root:[   99] Training loss: 0.65567564, Validation loss: 0.65812074, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7081.5234375MB
INFO:root:[  100] Training loss: 0.65536322, Validation loss: 0.65763237, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7119.40234375MB
INFO:root:[  101] Training loss: 0.65545342, Validation loss: 0.65628215, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7157.90234375MB
INFO:root:[  102] Training loss: 0.65543685, Validation loss: 0.65752962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7195.79296875MB
INFO:root:[  103] Training loss: 0.65577825, Validation loss: 0.65679402, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7234.15625MB
INFO:root:[  104] Training loss: 0.65530844, Validation loss: 0.65715176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7272.296875MB
INFO:root:[  105] Training loss: 0.65495827, Validation loss: 0.65616453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7310.6484375MB
INFO:root:[  106] Training loss: 0.65506234, Validation loss: 0.65789650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7349.02734375MB
INFO:root:[  107] Training loss: 0.65538757, Validation loss: 0.65604066, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7387.38671875MB
INFO:root:[  108] Training loss: 0.65468969, Validation loss: 0.65636313, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7425.55859375MB
INFO:root:[  109] Training loss: 0.65543704, Validation loss: 0.65679884, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7463.72265625MB
INFO:root:[  110] Training loss: 0.65511664, Validation loss: 0.65671006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7501.6171875MB
INFO:root:[  111] Training loss: 0.65496601, Validation loss: 0.65525662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7538.8203125MB
INFO:root:[  112] Training loss: 0.65469857, Validation loss: 0.65684168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7576.63671875MB
INFO:root:[  113] Training loss: 0.65484980, Validation loss: 0.65581066, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7614.30078125MB
INFO:root:[  114] Training loss: 0.65479418, Validation loss: 0.65645463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7652.46875MB
INFO:root:[  115] Training loss: 0.65461961, Validation loss: 0.65519701, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7690.15625MB
INFO:root:[  116] Training loss: 0.65472056, Validation loss: 0.65666658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7728.578125MB
INFO:root:[  117] Training loss: 0.65467629, Validation loss: 0.65571513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7766.9609375MB
INFO:root:[  118] Training loss: 0.65458294, Validation loss: 0.65663283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7805.0859375MB
INFO:root:[  119] Training loss: 0.65469407, Validation loss: 0.65570400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7843.13671875MB
INFO:root:[  120] Training loss: 0.65434330, Validation loss: 0.65588775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7880.9140625MB
INFO:root:[  121] Training loss: 0.65426550, Validation loss: 0.65530778, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7919.98046875MB
INFO:root:[  122] Training loss: 0.65428084, Validation loss: 0.65562228, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7957.90625MB
INFO:root:[  123] Training loss: 0.65388129, Validation loss: 0.65657179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=7996.2890625MB
INFO:root:[  124] Training loss: 0.65392071, Validation loss: 0.65539622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8034.41796875MB
INFO:root:[  125] Training loss: 0.65381258, Validation loss: 0.65460616, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8072.94921875MB
INFO:root:[  126] Training loss: 0.65363950, Validation loss: 0.65583568, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8111.09765625MB
INFO:root:[  127] Training loss: 0.65391262, Validation loss: 0.65452135, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8149.50390625MB
INFO:root:[  128] Training loss: 0.65381805, Validation loss: 0.65498332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8187.390625MB
INFO:root:[  129] Training loss: 0.65354085, Validation loss: 0.65642291, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8225.26171875MB
INFO:root:[  130] Training loss: 0.65351640, Validation loss: 0.65482432, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8263.375MB
INFO:root:[  131] Training loss: 0.65381926, Validation loss: 0.65458676, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8301.75MB
INFO:root:[  132] Training loss: 0.65414776, Validation loss: 0.65587933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8339.97265625MB
INFO:root:[  133] Training loss: 0.65373640, Validation loss: 0.65557582, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8377.87109375MB
INFO:root:[  134] Training loss: 0.65374161, Validation loss: 0.65638535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8416.28515625MB
INFO:root:[  135] Training loss: 0.65338429, Validation loss: 0.65649130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8454.42578125MB
INFO:root:[  136] Training loss: 0.65354222, Validation loss: 0.65421008, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8492.265625MB
INFO:root:[  137] Training loss: 0.65327824, Validation loss: 0.65440896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8530.140625MB
INFO:root:[  138] Training loss: 0.65309686, Validation loss: 0.65538991, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8568.265625MB
INFO:root:[  139] Training loss: 0.65333960, Validation loss: 0.65458978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8606.41015625MB
INFO:root:[  140] Training loss: 0.65301257, Validation loss: 0.65536185, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8644.29296875MB
INFO:root:[  141] Training loss: 0.65331635, Validation loss: 0.65565689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8682.65234375MB
INFO:root:[  142] Training loss: 0.65324789, Validation loss: 0.65540402, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8720.64453125MB
INFO:root:[  143] Training loss: 0.65307118, Validation loss: 0.65512261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8758.77734375MB
INFO:root:[  144] Training loss: 0.65286577, Validation loss: 0.65455823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8796.85546875MB
INFO:root:[  145] Training loss: 0.65265840, Validation loss: 0.65409243, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8835.1171875MB
INFO:root:[  146] Training loss: 0.65310704, Validation loss: 0.65462025, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8873.5390625MB
INFO:root:[  147] Training loss: 0.65321894, Validation loss: 0.65500401, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8911.4375MB
INFO:root:[  148] Training loss: 0.65272469, Validation loss: 0.65476209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8949.59765625MB
INFO:root:[  149] Training loss: 0.65297442, Validation loss: 0.65531240, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=8987.49609375MB
INFO:root:[  150] Training loss: 0.65290657, Validation loss: 0.65481020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9026.03125MB
INFO:root:[  151] Training loss: 0.65254642, Validation loss: 0.65535998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9064.13671875MB
INFO:root:[  152] Training loss: 0.65305056, Validation loss: 0.65552137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9102.02734375MB
INFO:root:[  153] Training loss: 0.65266934, Validation loss: 0.65505812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9140.39453125MB
INFO:root:[  154] Training loss: 0.65254588, Validation loss: 0.65455380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9178.53515625MB
INFO:root:EP 154: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12454.390625MB; mem (CPU total)=9216.1875MB
INFO:root:Training the model took 11089.815s.
INFO:root:Emptying the cuda cache took 0.006s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92626
INFO:root:EnergyScoreTrain: 0.65226
INFO:root:CRPSTrain: 0.58659
INFO:root:Gaussian NLLTrain: 1.83848
INFO:root:CoverageTrain: 0.81112
INFO:root:IntervalWidthTrain: 3.49246
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.92893
INFO:root:EnergyScoreValidation: 0.65414
INFO:root:CRPSValidation: 0.58852
INFO:root:Gaussian NLLValidation: 1.84536
INFO:root:CoverageValidation: 0.8103
INFO:root:IntervalWidthValidation: 3.49208
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.92937
INFO:root:EnergyScoreTest: 0.65444
INFO:root:CRPSTest: 0.58863
INFO:root:Gaussian NLLTest: 1.84255
INFO:root:CoverageTest: 0.8107
INFO:root:IntervalWidthTest: 3.49355
INFO:root:After validation: mem (CPU python)=12454.390625MB; mem (CPU total)=9262.62890625MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.390625MB; mem (CPU total)=9262.23828125MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 176160768
INFO:root:After setting up the model: mem (CPU python)=12454.390625MB; mem (CPU total)=9264.69921875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9264.94921875MB
INFO:root:[    1] Training loss: 0.76505569, Validation loss: 0.72517532, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9303.51953125MB
INFO:root:[    2] Training loss: 0.72707051, Validation loss: 0.71652392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9341.4296875MB
INFO:root:[    3] Training loss: 0.72120092, Validation loss: 0.71493447, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9380.01171875MB
INFO:root:[    4] Training loss: 0.71325992, Validation loss: 0.70452157, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9417.546875MB
INFO:root:[    5] Training loss: 0.70358910, Validation loss: 0.70076727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9455.74609375MB
INFO:root:[    6] Training loss: 0.69865475, Validation loss: 0.69821547, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9494.1640625MB
INFO:root:[    7] Training loss: 0.69855924, Validation loss: 0.69849777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9531.73046875MB
INFO:root:[    8] Training loss: 0.69479413, Validation loss: 0.69475190, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9569.40625MB
INFO:root:[    9] Training loss: 0.69365463, Validation loss: 0.69622279, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9607.328125MB
INFO:root:[   10] Training loss: 0.69225535, Validation loss: 0.69255820, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9645.6328125MB
INFO:root:[   11] Training loss: 0.69087782, Validation loss: 0.69218538, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9683.85546875MB
INFO:root:[   12] Training loss: 0.69097528, Validation loss: 0.69134368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9722.44140625MB
INFO:root:[   13] Training loss: 0.68903677, Validation loss: 0.68781484, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9760.92578125MB
INFO:root:[   14] Training loss: 0.68810491, Validation loss: 0.68704908, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9799.1328125MB
INFO:root:[   15] Training loss: 0.68721093, Validation loss: 0.68722204, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9837.546875MB
INFO:root:[   16] Training loss: 0.68595744, Validation loss: 0.68644798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9876.31640625MB
INFO:root:[   17] Training loss: 0.68512362, Validation loss: 0.68539731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9914.00390625MB
INFO:root:[   18] Training loss: 0.68396008, Validation loss: 0.68499443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9951.80078125MB
INFO:root:[   19] Training loss: 0.68305663, Validation loss: 0.68426061, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=9990.5234375MB
INFO:root:[   20] Training loss: 0.68239993, Validation loss: 0.68295211, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10028.09375MB
INFO:root:[   21] Training loss: 0.68192894, Validation loss: 0.68241019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10066.5703125MB
INFO:root:[   22] Training loss: 0.68117599, Validation loss: 0.68173368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10104.515625MB
INFO:root:[   23] Training loss: 0.68056388, Validation loss: 0.68064569, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10142.56640625MB
INFO:root:[   24] Training loss: 0.68003805, Validation loss: 0.68047400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10180.6328125MB
INFO:root:[   25] Training loss: 0.67962480, Validation loss: 0.68023982, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10219.03515625MB
INFO:root:[   26] Training loss: 0.67928041, Validation loss: 0.67942890, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10257.1640625MB
INFO:root:[   27] Training loss: 0.67839062, Validation loss: 0.67882821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10295.62109375MB
INFO:root:[   28] Training loss: 0.67780541, Validation loss: 0.67908803, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10333.98828125MB
INFO:root:[   29] Training loss: 0.67705536, Validation loss: 0.67744267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10372.23046875MB
INFO:root:[   30] Training loss: 0.67650459, Validation loss: 0.67664721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10410.71484375MB
INFO:root:[   31] Training loss: 0.67566105, Validation loss: 0.67664368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10448.96484375MB
INFO:root:[   32] Training loss: 0.67495741, Validation loss: 0.67569251, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10486.890625MB
INFO:root:[   33] Training loss: 0.67438337, Validation loss: 0.67579330, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10525.02734375MB
INFO:root:[   34] Training loss: 0.67381755, Validation loss: 0.67500714, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10562.984375MB
INFO:root:[   35] Training loss: 0.67331576, Validation loss: 0.67407606, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10601.74609375MB
INFO:root:[   36] Training loss: 0.67283441, Validation loss: 0.67413897, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10639.828125MB
INFO:root:[   37] Training loss: 0.67221146, Validation loss: 0.67327940, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10677.89453125MB
INFO:root:[   38] Training loss: 0.67189290, Validation loss: 0.67306003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10715.640625MB
INFO:root:[   39] Training loss: 0.67171120, Validation loss: 0.67252720, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10753.72265625MB
INFO:root:[   40] Training loss: 0.67136532, Validation loss: 0.67203804, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10792.1015625MB
INFO:root:[   41] Training loss: 0.67077821, Validation loss: 0.67289410, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10830.4609375MB
INFO:root:[   42] Training loss: 0.67070025, Validation loss: 0.67165822, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10868.6875MB
INFO:root:[   43] Training loss: 0.67044413, Validation loss: 0.67167424, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10907.0859375MB
INFO:root:[   44] Training loss: 0.66987099, Validation loss: 0.67148139, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10945.31640625MB
INFO:root:[   45] Training loss: 0.66972576, Validation loss: 0.67143473, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=10983.58203125MB
INFO:root:[   46] Training loss: 0.66941773, Validation loss: 0.67045015, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11023.5546875MB
INFO:root:[   47] Training loss: 0.66925829, Validation loss: 0.67024826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11062.203125MB
INFO:root:[   48] Training loss: 0.66890345, Validation loss: 0.67055620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11100.625MB
INFO:root:[   49] Training loss: 0.66876539, Validation loss: 0.67119465, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11138.75390625MB
INFO:root:[   50] Training loss: 0.66856083, Validation loss: 0.67091360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11177.05078125MB
INFO:root:[   51] Training loss: 0.66807260, Validation loss: 0.66990430, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11214.5546875MB
INFO:root:[   52] Training loss: 0.66798053, Validation loss: 0.66994508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11252.9453125MB
INFO:root:[   53] Training loss: 0.66755640, Validation loss: 0.66887292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11291.21875MB
INFO:root:[   54] Training loss: 0.66704635, Validation loss: 0.66830725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11329.38671875MB
INFO:root:[   55] Training loss: 0.66684720, Validation loss: 0.66824652, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11367.5625MB
INFO:root:[   56] Training loss: 0.66657879, Validation loss: 0.66837245, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11405.984375MB
INFO:root:[   57] Training loss: 0.66615649, Validation loss: 0.66685656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11443.93359375MB
INFO:root:[   58] Training loss: 0.66593624, Validation loss: 0.66901332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11482.3203125MB
INFO:root:[   59] Training loss: 0.66581272, Validation loss: 0.66667096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11519.7890625MB
INFO:root:[   60] Training loss: 0.66523022, Validation loss: 0.66730392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11558.20703125MB
INFO:root:[   61] Training loss: 0.66514075, Validation loss: 0.66656430, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11596.2109375MB
INFO:root:[   62] Training loss: 0.66517094, Validation loss: 0.66783980, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11634.35546875MB
INFO:root:[   63] Training loss: 0.66495854, Validation loss: 0.66660243, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11672.48046875MB
INFO:root:[   64] Training loss: 0.66441899, Validation loss: 0.66585881, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11710.54296875MB
INFO:root:[   65] Training loss: 0.66428334, Validation loss: 0.66596191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11749.16796875MB
INFO:root:[   66] Training loss: 0.66398575, Validation loss: 0.66507544, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11787.2890625MB
INFO:root:[   67] Training loss: 0.66418170, Validation loss: 0.66522297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11825.5390625MB
INFO:root:[   68] Training loss: 0.66398136, Validation loss: 0.66592267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11863.43359375MB
INFO:root:[   69] Training loss: 0.66359466, Validation loss: 0.66554786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11901.359375MB
INFO:root:[   70] Training loss: 0.66345233, Validation loss: 0.66495442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11938.78125MB
INFO:root:[   71] Training loss: 0.66308829, Validation loss: 0.66388581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=11976.921875MB
INFO:root:[   72] Training loss: 0.66321497, Validation loss: 0.66610799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=12015.328125MB
INFO:root:[   73] Training loss: 0.66301534, Validation loss: 0.66382119, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=12053.76171875MB
INFO:root:[   74] Training loss: 0.66281771, Validation loss: 0.66522814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=12091.87109375MB
INFO:root:[   75] Training loss: 0.66253110, Validation loss: 0.66382876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=12130.26953125MB
INFO:root:[   76] Training loss: 0.66250951, Validation loss: 0.66465223, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.390625MB; mem (CPU total)=12168.1953125MB
INFO:root:[   77] Training loss: 0.66251595, Validation loss: 0.66432283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12462.890625MB; mem (CPU total)=12205.9296875MB
INFO:root:[   78] Training loss: 0.66243408, Validation loss: 0.66343087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12500.98828125MB; mem (CPU total)=12244.45703125MB
INFO:root:[   79] Training loss: 0.66234613, Validation loss: 0.66329045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12539.08203125MB; mem (CPU total)=12281.7421875MB
INFO:root:[   80] Training loss: 0.66154468, Validation loss: 0.66340598, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12577.1796875MB; mem (CPU total)=12320.1484375MB
INFO:root:[   81] Training loss: 0.66166776, Validation loss: 0.66243765, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12615.2734375MB; mem (CPU total)=12358.2265625MB
INFO:root:[   82] Training loss: 0.66168532, Validation loss: 0.66315607, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12653.3671875MB; mem (CPU total)=12397.484375MB
INFO:root:[   83] Training loss: 0.66146393, Validation loss: 0.66332977, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12691.4609375MB; mem (CPU total)=12435.22265625MB
INFO:root:[   84] Training loss: 0.66152728, Validation loss: 0.66267886, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12729.55859375MB; mem (CPU total)=12473.3984375MB
INFO:root:[   85] Training loss: 0.66115508, Validation loss: 0.66307311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12767.65234375MB; mem (CPU total)=12511.1796875MB
INFO:root:[   86] Training loss: 0.66109998, Validation loss: 0.66309581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12805.7578125MB; mem (CPU total)=12549.328125MB
INFO:root:[   87] Training loss: 0.66097007, Validation loss: 0.66270937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12843.85546875MB; mem (CPU total)=12587.47265625MB
INFO:root:[   88] Training loss: 0.66098633, Validation loss: 0.66334532, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12881.953125MB; mem (CPU total)=12625.62109375MB
INFO:root:[   89] Training loss: 0.66064771, Validation loss: 0.66243222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12920.046875MB; mem (CPU total)=12663.5859375MB
INFO:root:[   90] Training loss: 0.66057137, Validation loss: 0.66276281, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12958.14453125MB; mem (CPU total)=12701.71484375MB
INFO:root:[   91] Training loss: 0.66066676, Validation loss: 0.66243594, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12996.23828125MB; mem (CPU total)=12739.921875MB
INFO:root:[   92] Training loss: 0.66043921, Validation loss: 0.66209428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13034.33203125MB; mem (CPU total)=12777.74609375MB
INFO:root:[   93] Training loss: 0.66017932, Validation loss: 0.66212390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13072.42578125MB; mem (CPU total)=12815.828125MB
INFO:root:[   94] Training loss: 0.65989380, Validation loss: 0.66117915, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13110.5234375MB; mem (CPU total)=12853.9609375MB
INFO:root:[   95] Training loss: 0.66018518, Validation loss: 0.66129417, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13148.62109375MB; mem (CPU total)=12892.61328125MB
INFO:root:[   96] Training loss: 0.65985698, Validation loss: 0.66147649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13186.71484375MB; mem (CPU total)=12930.75MB
INFO:root:[   97] Training loss: 0.65994564, Validation loss: 0.66271368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13224.8125MB; mem (CPU total)=12969.43359375MB
INFO:root:[   98] Training loss: 0.65936708, Validation loss: 0.66266700, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13262.90625MB; mem (CPU total)=13006.8671875MB
INFO:root:[   99] Training loss: 0.65947540, Validation loss: 0.66161359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13301.0MB; mem (CPU total)=13045.20703125MB
INFO:root:[  100] Training loss: 0.65921108, Validation loss: 0.66111356, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13339.09375MB; mem (CPU total)=13082.484375MB
INFO:root:[  101] Training loss: 0.65935344, Validation loss: 0.66133416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13377.19140625MB; mem (CPU total)=13121.15234375MB
INFO:root:[  102] Training loss: 0.65942673, Validation loss: 0.65983132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13415.2890625MB; mem (CPU total)=13159.46875MB
INFO:root:[  103] Training loss: 0.65869255, Validation loss: 0.66084174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13453.3828125MB; mem (CPU total)=13197.84765625MB
INFO:root:[  104] Training loss: 0.65899533, Validation loss: 0.66066722, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13491.484375MB; mem (CPU total)=13235.9921875MB
INFO:root:[  105] Training loss: 0.65853928, Validation loss: 0.66040552, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13529.578125MB; mem (CPU total)=13274.08203125MB
INFO:root:[  106] Training loss: 0.65884379, Validation loss: 0.65951090, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13567.671875MB; mem (CPU total)=13312.453125MB
INFO:root:[  107] Training loss: 0.65846843, Validation loss: 0.66079444, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13605.76953125MB; mem (CPU total)=13350.4140625MB
INFO:root:[  108] Training loss: 0.65835800, Validation loss: 0.65948360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13643.8671875MB; mem (CPU total)=13388.57421875MB
INFO:root:[  109] Training loss: 0.65816618, Validation loss: 0.65914439, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13681.9609375MB; mem (CPU total)=13427.3515625MB
INFO:root:[  110] Training loss: 0.65812620, Validation loss: 0.65922774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13720.0546875MB; mem (CPU total)=13465.48828125MB
INFO:root:[  111] Training loss: 0.65815402, Validation loss: 0.65916108, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13758.15234375MB; mem (CPU total)=13503.40625MB
INFO:root:[  112] Training loss: 0.65779297, Validation loss: 0.66144151, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13796.24609375MB; mem (CPU total)=13541.55078125MB
INFO:root:[  113] Training loss: 0.65746326, Validation loss: 0.66029856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13834.34375MB; mem (CPU total)=13579.7578125MB
INFO:root:[  114] Training loss: 0.65749617, Validation loss: 0.65851817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13872.44140625MB; mem (CPU total)=13617.7109375MB
INFO:root:[  115] Training loss: 0.65726702, Validation loss: 0.65847884, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13910.53515625MB; mem (CPU total)=13656.1796875MB
INFO:root:[  116] Training loss: 0.65726792, Validation loss: 0.65857624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13948.62890625MB; mem (CPU total)=13694.6015625MB
INFO:root:[  117] Training loss: 0.65695098, Validation loss: 0.65746379, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13986.72265625MB; mem (CPU total)=13732.5625MB
INFO:root:[  118] Training loss: 0.65642627, Validation loss: 0.65898612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14024.82421875MB; mem (CPU total)=13770.9375MB
INFO:root:[  119] Training loss: 0.65705691, Validation loss: 0.65751283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14062.91796875MB; mem (CPU total)=13808.83203125MB
INFO:root:[  120] Training loss: 0.65709755, Validation loss: 0.65799443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14101.01171875MB; mem (CPU total)=13847.19921875MB
INFO:root:[  121] Training loss: 0.65627566, Validation loss: 0.65977805, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14139.109375MB; mem (CPU total)=13885.171875MB
INFO:root:[  122] Training loss: 0.65633552, Validation loss: 0.65755836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14177.203125MB; mem (CPU total)=13923.31640625MB
INFO:root:[  123] Training loss: 0.65614677, Validation loss: 0.65692623, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14215.296875MB; mem (CPU total)=13961.66015625MB
INFO:root:[  124] Training loss: 0.65599300, Validation loss: 0.65909501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14253.39453125MB; mem (CPU total)=14000.08203125MB
INFO:root:[  125] Training loss: 0.65545530, Validation loss: 0.65813628, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14291.48828125MB; mem (CPU total)=14038.2265625MB
INFO:root:[  126] Training loss: 0.65615338, Validation loss: 0.65750093, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14329.5859375MB; mem (CPU total)=14076.390625MB
INFO:root:[  127] Training loss: 0.65582066, Validation loss: 0.65900021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14367.6796875MB; mem (CPU total)=14114.2265625MB
INFO:root:[  128] Training loss: 0.65615865, Validation loss: 0.65721467, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14405.77734375MB; mem (CPU total)=14152.8125MB
INFO:root:[  129] Training loss: 0.65546242, Validation loss: 0.65729874, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14443.87109375MB; mem (CPU total)=14190.9453125MB
INFO:root:[  130] Training loss: 0.65581555, Validation loss: 0.65634632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14481.96484375MB; mem (CPU total)=14228.703125MB
INFO:root:[  131] Training loss: 0.65557615, Validation loss: 0.65805378, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14520.0625MB; mem (CPU total)=14269.90234375MB
INFO:root:[  132] Training loss: 0.65572064, Validation loss: 0.65674248, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14558.15625MB; mem (CPU total)=14308.02734375MB
INFO:root:[  133] Training loss: 0.65559536, Validation loss: 0.65798941, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14596.25390625MB; mem (CPU total)=14345.09765625MB
INFO:root:[  134] Training loss: 0.65490350, Validation loss: 0.65878631, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14634.34765625MB; mem (CPU total)=14383.58203125MB
INFO:root:[  135] Training loss: 0.65508516, Validation loss: 0.66039175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14672.4453125MB; mem (CPU total)=14422.22265625MB
INFO:root:[  136] Training loss: 0.65581080, Validation loss: 0.65689062, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14710.5390625MB; mem (CPU total)=14459.828125MB
INFO:root:[  137] Training loss: 0.65518537, Validation loss: 0.65756474, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14748.6328125MB; mem (CPU total)=14497.72265625MB
INFO:root:[  138] Training loss: 0.65515033, Validation loss: 0.65715370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14786.73046875MB; mem (CPU total)=14536.11328125MB
INFO:root:[  139] Training loss: 0.65536066, Validation loss: 0.65550747, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14824.82421875MB; mem (CPU total)=14574.08984375MB
INFO:root:[  140] Training loss: 0.65445308, Validation loss: 0.65572382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14862.91796875MB; mem (CPU total)=14612.4765625MB
INFO:root:[  141] Training loss: 0.65517482, Validation loss: 0.65708903, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14901.015625MB; mem (CPU total)=14650.60546875MB
INFO:root:[  142] Training loss: 0.65560253, Validation loss: 0.65693463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14939.11328125MB; mem (CPU total)=14688.76953125MB
INFO:root:[  143] Training loss: 0.65481961, Validation loss: 0.65631633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14977.203125MB; mem (CPU total)=14726.83203125MB
INFO:root:[  144] Training loss: 0.65441356, Validation loss: 0.65443691, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15015.30078125MB; mem (CPU total)=14765.109375MB
INFO:root:[  145] Training loss: 0.65441349, Validation loss: 0.65632897, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15053.40234375MB; mem (CPU total)=14803.2578125MB
INFO:root:[  146] Training loss: 0.65445776, Validation loss: 0.65556037, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15091.49609375MB; mem (CPU total)=14841.15625MB
INFO:root:[  147] Training loss: 0.65413259, Validation loss: 0.65556310, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15129.58984375MB; mem (CPU total)=14879.2890625MB
INFO:root:[  148] Training loss: 0.65415704, Validation loss: 0.65575262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15167.6875MB; mem (CPU total)=14917.328125MB
INFO:root:[  149] Training loss: 0.65395196, Validation loss: 0.65555264, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15205.78125MB; mem (CPU total)=14954.9921875MB
INFO:root:[  150] Training loss: 0.65397216, Validation loss: 0.65534391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15243.875MB; mem (CPU total)=14993.54296875MB
INFO:root:[  151] Training loss: 0.65361935, Validation loss: 0.65442883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15281.96875MB; mem (CPU total)=15031.78125MB
INFO:root:[  152] Training loss: 0.65346637, Validation loss: 0.65505058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15320.0703125MB; mem (CPU total)=15069.98828125MB
INFO:root:[  153] Training loss: 0.65455047, Validation loss: 0.65548671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15358.1640625MB; mem (CPU total)=15108.1328125MB
INFO:root:[  154] Training loss: 0.65387898, Validation loss: 0.65456783, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15396.2578125MB; mem (CPU total)=15146.27734375MB
INFO:root:[  155] Training loss: 0.65338289, Validation loss: 0.65542184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15434.35546875MB; mem (CPU total)=15183.85546875MB
INFO:root:[  156] Training loss: 0.65383496, Validation loss: 0.65626101, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15472.44921875MB; mem (CPU total)=15222.48046875MB
INFO:root:[  157] Training loss: 0.65386976, Validation loss: 0.65464376, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15510.54296875MB; mem (CPU total)=15260.61328125MB
INFO:root:[  158] Training loss: 0.65341166, Validation loss: 0.65553580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15548.640625MB; mem (CPU total)=15298.19140625MB
INFO:root:[  159] Training loss: 0.65355309, Validation loss: 0.65538750, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15586.734375MB; mem (CPU total)=15336.3359375MB
INFO:root:[  160] Training loss: 0.65328276, Validation loss: 0.65377189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15624.828125MB; mem (CPU total)=15375.640625MB
INFO:root:[  161] Training loss: 0.65331294, Validation loss: 0.65489409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15662.921875MB; mem (CPU total)=15414.125MB
INFO:root:[  162] Training loss: 0.65389202, Validation loss: 0.65514312, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15701.0234375MB; mem (CPU total)=15452.046875MB
INFO:root:[  163] Training loss: 0.65388201, Validation loss: 0.65632183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15739.1171875MB; mem (CPU total)=15490.45703125MB
INFO:root:[  164] Training loss: 0.65327956, Validation loss: 0.65536977, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15777.2109375MB; mem (CPU total)=15528.78125MB
INFO:root:[  165] Training loss: 0.65345494, Validation loss: 0.65500520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15815.30859375MB; mem (CPU total)=15567.22265625MB
INFO:root:[  166] Training loss: 0.65314906, Validation loss: 0.65599510, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15853.40625MB; mem (CPU total)=15605.1328125MB
INFO:root:[  167] Training loss: 0.65293041, Validation loss: 0.65411503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15891.5MB; mem (CPU total)=15643.0625MB
INFO:root:[  168] Training loss: 0.65363289, Validation loss: 0.65562336, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15929.59375MB; mem (CPU total)=15680.9921875MB
INFO:root:[  169] Training loss: 0.65252192, Validation loss: 0.65598992, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15967.69140625MB; mem (CPU total)=15719.16796875MB
INFO:root:EP 169: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16005.78515625MB; mem (CPU total)=15757.32421875MB
INFO:root:Training the model took 13250.749s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92629
INFO:root:EnergyScoreTrain: 0.65235
INFO:root:CRPSTrain: 0.59568
INFO:root:Gaussian NLLTrain: 1.90236
INFO:root:CoverageTrain: 0.81197
INFO:root:IntervalWidthTrain: 3.50021
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9291
INFO:root:EnergyScoreValidation: 0.65432
INFO:root:CRPSValidation: 0.59763
INFO:root:Gaussian NLLValidation: 1.90991
INFO:root:CoverageValidation: 0.81117
INFO:root:IntervalWidthValidation: 3.49895
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.92853
INFO:root:EnergyScoreTest: 0.65393
INFO:root:CRPSTest: 0.59726
INFO:root:Gaussian NLLTest: 1.90571
INFO:root:CoverageTest: 0.81167
INFO:root:IntervalWidthTest: 3.50344
INFO:root:After validation: mem (CPU python)=16048.73046875MB; mem (CPU total)=15800.62890625MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=16048.73046875MB; mem (CPU total)=15800.6328125MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 188743680
INFO:root:After setting up the model: mem (CPU python)=16049.59375MB; mem (CPU total)=15801.6171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=16049.7890625MB; mem (CPU total)=15801.625MB
INFO:root:[    1] Training loss: 0.74763289, Validation loss: 0.72184757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16087.7421875MB; mem (CPU total)=15839.9140625MB
INFO:root:[    2] Training loss: 0.71997912, Validation loss: 0.71822621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16125.8359375MB; mem (CPU total)=15877.81640625MB
INFO:root:[    3] Training loss: 0.70779693, Validation loss: 0.70562930, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16163.9453125MB; mem (CPU total)=15916.72265625MB
INFO:root:[    4] Training loss: 0.70034024, Validation loss: 0.69833872, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16202.05859375MB; mem (CPU total)=15953.5546875MB
INFO:root:[    5] Training loss: 0.69922628, Validation loss: 0.70023575, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16240.171875MB; mem (CPU total)=15992.22265625MB
INFO:root:[    6] Training loss: 0.69706075, Validation loss: 0.69595923, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16278.28125MB; mem (CPU total)=16030.54296875MB
INFO:root:[    7] Training loss: 0.69371957, Validation loss: 0.69262850, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16316.39453125MB; mem (CPU total)=16068.3046875MB
INFO:root:[    8] Training loss: 0.69027680, Validation loss: 0.69007520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16354.48828125MB; mem (CPU total)=16106.98828125MB
INFO:root:[    9] Training loss: 0.68860200, Validation loss: 0.68784689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16392.5859375MB; mem (CPU total)=16145.26953125MB
INFO:root:[   10] Training loss: 0.68723670, Validation loss: 0.68763154, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16430.6796875MB; mem (CPU total)=16183.01953125MB
INFO:root:[   11] Training loss: 0.68648835, Validation loss: 0.68742195, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16468.77734375MB; mem (CPU total)=16221.3359375MB
INFO:root:[   12] Training loss: 0.68562783, Validation loss: 0.68635530, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16506.875MB; mem (CPU total)=16258.54296875MB
INFO:root:[   13] Training loss: 0.68475087, Validation loss: 0.68584712, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16544.96875MB; mem (CPU total)=16295.90234375MB
INFO:root:[   14] Training loss: 0.68427128, Validation loss: 0.68469040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16583.06640625MB; mem (CPU total)=16334.5234375MB
INFO:root:[   15] Training loss: 0.68381754, Validation loss: 0.68465143, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16621.16015625MB; mem (CPU total)=16373.1015625MB
INFO:root:[   16] Training loss: 0.68300905, Validation loss: 0.68397339, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16659.25390625MB; mem (CPU total)=16411.9765625MB
INFO:root:[   17] Training loss: 0.68281604, Validation loss: 0.68429036, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16697.3515625MB; mem (CPU total)=16450.3828125MB
INFO:root:[   18] Training loss: 0.68199598, Validation loss: 0.68314991, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16735.4453125MB; mem (CPU total)=16488.5078125MB
INFO:root:[   19] Training loss: 0.68174111, Validation loss: 0.68255748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16773.5390625MB; mem (CPU total)=16526.68359375MB
INFO:root:[   20] Training loss: 0.68106891, Validation loss: 0.68153706, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16811.6328125MB; mem (CPU total)=16564.90625MB
INFO:root:[   21] Training loss: 0.68056537, Validation loss: 0.68103291, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16849.73046875MB; mem (CPU total)=16603.41015625MB
INFO:root:[   22] Training loss: 0.68023834, Validation loss: 0.68032577, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16887.828125MB; mem (CPU total)=16640.3828125MB
INFO:root:[   23] Training loss: 0.67936959, Validation loss: 0.67994142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16925.921875MB; mem (CPU total)=16678.421875MB
INFO:root:[   24] Training loss: 0.67912043, Validation loss: 0.67957692, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16964.01953125MB; mem (CPU total)=16717.19140625MB
INFO:root:[   25] Training loss: 0.67839611, Validation loss: 0.67893235, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17002.11328125MB; mem (CPU total)=16755.4140625MB
INFO:root:[   26] Training loss: 0.67800960, Validation loss: 0.67862014, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17040.20703125MB; mem (CPU total)=16793.6796875MB
INFO:root:[   27] Training loss: 0.67713325, Validation loss: 0.67765330, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17078.30078125MB; mem (CPU total)=16831.91796875MB
INFO:root:[   28] Training loss: 0.67627735, Validation loss: 0.67699494, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17116.3984375MB; mem (CPU total)=16869.0859375MB
INFO:root:[   29] Training loss: 0.67593727, Validation loss: 0.67749683, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17154.49609375MB; mem (CPU total)=16908.4140625MB
INFO:root:[   30] Training loss: 0.67512397, Validation loss: 0.67542787, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17192.58984375MB; mem (CPU total)=16946.69140625MB
INFO:root:[   31] Training loss: 0.67424409, Validation loss: 0.67496925, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17230.6875MB; mem (CPU total)=16984.33203125MB
INFO:root:[   32] Training loss: 0.67394737, Validation loss: 0.67466529, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17268.78125MB; mem (CPU total)=17022.328125MB
INFO:root:[   33] Training loss: 0.67399289, Validation loss: 0.67512203, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17306.875MB; mem (CPU total)=17060.71484375MB
INFO:root:[   34] Training loss: 0.67317254, Validation loss: 0.67408317, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17344.9765625MB; mem (CPU total)=17098.76953125MB
INFO:root:[   35] Training loss: 0.67255983, Validation loss: 0.67361852, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17383.07421875MB; mem (CPU total)=17136.9765625MB
INFO:root:[   36] Training loss: 0.67226152, Validation loss: 0.67415498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17421.16796875MB; mem (CPU total)=17175.35546875MB
INFO:root:[   37] Training loss: 0.67178115, Validation loss: 0.67367884, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17459.26171875MB; mem (CPU total)=17213.7890625MB
INFO:root:[   38] Training loss: 0.67172404, Validation loss: 0.67295856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17497.359375MB; mem (CPU total)=17251.3359375MB
INFO:root:[   39] Training loss: 0.67139498, Validation loss: 0.67250470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17535.453125MB; mem (CPU total)=17288.7421875MB
INFO:root:[   40] Training loss: 0.67109710, Validation loss: 0.67332498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17573.55078125MB; mem (CPU total)=17326.62890625MB
INFO:root:[   41] Training loss: 0.67076805, Validation loss: 0.67116663, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17611.6484375MB; mem (CPU total)=17364.58984375MB
INFO:root:[   42] Training loss: 0.67073193, Validation loss: 0.67192472, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17649.7421875MB; mem (CPU total)=17402.71875MB
INFO:root:[   43] Training loss: 0.67038981, Validation loss: 0.67127180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17687.8359375MB; mem (CPU total)=17440.81640625MB
INFO:root:[   44] Training loss: 0.67000080, Validation loss: 0.67102620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17725.9296875MB; mem (CPU total)=17479.07421875MB
INFO:root:[   45] Training loss: 0.66967029, Validation loss: 0.67114657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17764.02734375MB; mem (CPU total)=17518.13671875MB
INFO:root:[   46] Training loss: 0.66867762, Validation loss: 0.67087022, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17802.12109375MB; mem (CPU total)=17556.265625MB
INFO:root:[   47] Training loss: 0.66832684, Validation loss: 0.66922345, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17840.21875MB; mem (CPU total)=17594.4453125MB
INFO:root:[   48] Training loss: 0.66776968, Validation loss: 0.66853754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17878.31640625MB; mem (CPU total)=17632.078125MB
INFO:root:[   49] Training loss: 0.66671331, Validation loss: 0.66702774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17916.41015625MB; mem (CPU total)=17670.4140625MB
INFO:root:[   50] Training loss: 0.66649181, Validation loss: 0.66756580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17954.50390625MB; mem (CPU total)=17709.0703125MB
INFO:root:[   51] Training loss: 0.66554033, Validation loss: 0.66656005, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17992.6015625MB; mem (CPU total)=17747.16015625MB
INFO:root:[   52] Training loss: 0.66506874, Validation loss: 0.66563569, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18030.6953125MB; mem (CPU total)=17785.52734375MB
INFO:root:[   53] Training loss: 0.66450403, Validation loss: 0.66499045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18068.7890625MB; mem (CPU total)=17824.08984375MB
INFO:root:[   54] Training loss: 0.66359284, Validation loss: 0.66584813, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18106.8828125MB; mem (CPU total)=17861.9609375MB
INFO:root:[   55] Training loss: 0.66375716, Validation loss: 0.66494106, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18144.984375MB; mem (CPU total)=17899.6328125MB
INFO:root:[   56] Training loss: 0.66339033, Validation loss: 0.66437937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18183.078125MB; mem (CPU total)=17937.65234375MB
INFO:root:[   57] Training loss: 0.66291974, Validation loss: 0.66506564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18221.171875MB; mem (CPU total)=17976.03515625MB
INFO:root:[   58] Training loss: 0.66233014, Validation loss: 0.66308611, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18259.26953125MB; mem (CPU total)=18013.86328125MB
INFO:root:[   59] Training loss: 0.66198987, Validation loss: 0.66233229, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18297.36328125MB; mem (CPU total)=18051.98828125MB
INFO:root:[   60] Training loss: 0.66165860, Validation loss: 0.66356594, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18335.45703125MB; mem (CPU total)=18090.37890625MB
INFO:root:[   61] Training loss: 0.66179108, Validation loss: 0.66238303, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18373.55078125MB; mem (CPU total)=18128.25390625MB
INFO:root:[   62] Training loss: 0.66135469, Validation loss: 0.66220550, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18411.6484375MB; mem (CPU total)=18166.66015625MB
INFO:root:[   63] Training loss: 0.66098647, Validation loss: 0.66243885, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18449.7421875MB; mem (CPU total)=18204.7421875MB
INFO:root:[   64] Training loss: 0.66064273, Validation loss: 0.66215797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18487.83984375MB; mem (CPU total)=18242.6953125MB
INFO:root:[   65] Training loss: 0.66057047, Validation loss: 0.66252456, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18525.9375MB; mem (CPU total)=18281.11328125MB
INFO:root:[   66] Training loss: 0.66039829, Validation loss: 0.66208195, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18564.03125MB; mem (CPU total)=18320.23046875MB
INFO:root:[   67] Training loss: 0.66073220, Validation loss: 0.66159942, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18602.125MB; mem (CPU total)=18358.63671875MB
INFO:root:[   68] Training loss: 0.66056400, Validation loss: 0.66091051, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18640.22265625MB; mem (CPU total)=18396.56640625MB
INFO:root:[   69] Training loss: 0.66032839, Validation loss: 0.66270385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18678.31640625MB; mem (CPU total)=18434.7421875MB
INFO:root:[   70] Training loss: 0.66024566, Validation loss: 0.66192613, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18716.41015625MB; mem (CPU total)=18472.8359375MB
INFO:root:[   71] Training loss: 0.66030861, Validation loss: 0.66138000, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18754.50390625MB; mem (CPU total)=18510.96875MB
INFO:root:[   72] Training loss: 0.66025241, Validation loss: 0.66150789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18792.6015625MB; mem (CPU total)=18548.7109375MB
INFO:root:[   73] Training loss: 0.65963183, Validation loss: 0.66042486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18830.703125MB; mem (CPU total)=18587.34765625MB
INFO:root:[   74] Training loss: 0.65955978, Validation loss: 0.66060783, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18868.796875MB; mem (CPU total)=18625.5859375MB
INFO:root:[   75] Training loss: 0.65959138, Validation loss: 0.66021098, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18906.8984375MB; mem (CPU total)=18662.4453125MB
INFO:root:[   76] Training loss: 0.65903758, Validation loss: 0.66018711, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18944.99609375MB; mem (CPU total)=18700.9609375MB
INFO:root:[   77] Training loss: 0.65909193, Validation loss: 0.66063120, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18983.08984375MB; mem (CPU total)=18739.3515625MB
INFO:root:[   78] Training loss: 0.65949703, Validation loss: 0.66018369, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19021.18359375MB; mem (CPU total)=18777.58984375MB
INFO:root:[   79] Training loss: 0.65868471, Validation loss: 0.66004686, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19059.28125MB; mem (CPU total)=18815.75390625MB
INFO:root:[   80] Training loss: 0.65898991, Validation loss: 0.66117498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19097.375MB; mem (CPU total)=18854.68359375MB
INFO:root:[   81] Training loss: 0.65921898, Validation loss: 0.66085486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19135.46875MB; mem (CPU total)=18892.5546875MB
INFO:root:[   82] Training loss: 0.65855934, Validation loss: 0.66023024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19173.5703125MB; mem (CPU total)=18930.171875MB
INFO:root:[   83] Training loss: 0.65863168, Validation loss: 0.65910785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19211.6640625MB; mem (CPU total)=18968.390625MB
INFO:root:[   84] Training loss: 0.65849251, Validation loss: 0.66010256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19249.7578125MB; mem (CPU total)=19006.8359375MB
INFO:root:[   85] Training loss: 0.65895952, Validation loss: 0.66001038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19287.85546875MB; mem (CPU total)=19044.97265625MB
INFO:root:[   86] Training loss: 0.65839139, Validation loss: 0.66061800, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19325.94921875MB; mem (CPU total)=19083.3515625MB
INFO:root:[   87] Training loss: 0.65851412, Validation loss: 0.65964803, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19364.04296875MB; mem (CPU total)=19120.88671875MB
INFO:root:[   88] Training loss: 0.65830838, Validation loss: 0.66041070, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19402.13671875MB; mem (CPU total)=19159.234375MB
INFO:root:[   89] Training loss: 0.65819413, Validation loss: 0.65983487, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19440.23828125MB; mem (CPU total)=19202.35546875MB
INFO:root:[   90] Training loss: 0.65798838, Validation loss: 0.65980606, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19478.33203125MB; mem (CPU total)=19240.37109375MB
INFO:root:[   91] Training loss: 0.65829278, Validation loss: 0.65896120, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19516.42578125MB; mem (CPU total)=19278.1484375MB
INFO:root:[   92] Training loss: 0.65849871, Validation loss: 0.65777288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19554.5234375MB; mem (CPU total)=19316.80859375MB
INFO:root:[   93] Training loss: 0.65770152, Validation loss: 0.65903967, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19592.6171875MB; mem (CPU total)=19354.6796875MB
INFO:root:[   94] Training loss: 0.65827095, Validation loss: 0.65969997, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19630.7109375MB; mem (CPU total)=19392.83984375MB
INFO:root:[   95] Training loss: 0.65769423, Validation loss: 0.65915449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19668.8046875MB; mem (CPU total)=19430.75390625MB
INFO:root:[   96] Training loss: 0.65753421, Validation loss: 0.66027117, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19706.90234375MB; mem (CPU total)=19468.83203125MB
INFO:root:[   97] Training loss: 0.65779986, Validation loss: 0.66007302, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19744.99609375MB; mem (CPU total)=19507.24609375MB
INFO:root:[   98] Training loss: 0.65721123, Validation loss: 0.65869019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19783.08984375MB; mem (CPU total)=19545.1796875MB
INFO:root:[   99] Training loss: 0.65752641, Validation loss: 0.65882885, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19821.19140625MB; mem (CPU total)=19583.35546875MB
INFO:root:[  100] Training loss: 0.65762550, Validation loss: 0.65882186, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19859.28515625MB; mem (CPU total)=19621.625MB
INFO:root:[  101] Training loss: 0.65740008, Validation loss: 0.65781609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19897.37890625MB; mem (CPU total)=19660.328125MB
INFO:root:EP 101: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19935.4765625MB; mem (CPU total)=19698.2265625MB
INFO:root:Training the model took 8530.599s.
INFO:root:Emptying the cuda cache took 0.003s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93288
INFO:root:EnergyScoreTrain: 0.65709
INFO:root:CRPSTrain: 0.60249
INFO:root:Gaussian NLLTrain: 2.0971
INFO:root:CoverageTrain: 0.78036
INFO:root:IntervalWidthTrain: 3.37
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93516
INFO:root:EnergyScoreValidation: 0.65874
INFO:root:CRPSValidation: 0.60412
INFO:root:Gaussian NLLValidation: 2.10474
INFO:root:CoverageValidation: 0.77953
INFO:root:IntervalWidthValidation: 3.36863
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93577
INFO:root:EnergyScoreTest: 0.65914
INFO:root:CRPSTest: 0.60433
INFO:root:Gaussian NLLTest: 2.10141
INFO:root:CoverageTest: 0.77993
INFO:root:IntervalWidthTest: 3.37124
INFO:root:After validation: mem (CPU python)=19978.21875MB; mem (CPU total)=19741.38671875MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=19978.21875MB; mem (CPU total)=19741.390625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 434110464
INFO:root:After setting up the model: mem (CPU python)=19979.39453125MB; mem (CPU total)=19742.375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=19979.515625MB; mem (CPU total)=19742.625MB
INFO:root:[    1] Training loss: 0.77638557, Validation loss: 0.72359520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20017.5625MB; mem (CPU total)=19780.14453125MB
INFO:root:[    2] Training loss: 0.72326289, Validation loss: 0.71985355, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20055.671875MB; mem (CPU total)=19818.609375MB
INFO:root:[    3] Training loss: 0.71113342, Validation loss: 0.70387207, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20093.78515625MB; mem (CPU total)=19857.0625MB
INFO:root:[    4] Training loss: 0.70241760, Validation loss: 0.70021759, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20131.8984375MB; mem (CPU total)=19895.01171875MB
INFO:root:[    5] Training loss: 0.69921306, Validation loss: 0.69777039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20169.9921875MB; mem (CPU total)=19932.96875MB
INFO:root:[    6] Training loss: 0.69822429, Validation loss: 0.69768827, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20208.08984375MB; mem (CPU total)=19971.20703125MB
INFO:root:[    7] Training loss: 0.69634755, Validation loss: 0.69804849, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20246.18359375MB; mem (CPU total)=20009.6328125MB
INFO:root:[    8] Training loss: 0.69490012, Validation loss: 0.69458067, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20284.28125MB; mem (CPU total)=20047.43359375MB
INFO:root:[    9] Training loss: 0.69340120, Validation loss: 0.69424238, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20322.375MB; mem (CPU total)=20085.890625MB
INFO:root:[   10] Training loss: 0.69257002, Validation loss: 0.69341864, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20360.47265625MB; mem (CPU total)=20124.70703125MB
INFO:root:[   11] Training loss: 0.69080481, Validation loss: 0.69342803, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20398.5703125MB; mem (CPU total)=20163.12109375MB
INFO:root:[   12] Training loss: 0.68922643, Validation loss: 0.68990959, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20436.66796875MB; mem (CPU total)=20201.21484375MB
INFO:root:[   13] Training loss: 0.68866112, Validation loss: 0.68859169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20474.765625MB; mem (CPU total)=20239.40234375MB
INFO:root:[   14] Training loss: 0.68766832, Validation loss: 0.68832840, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20512.859375MB; mem (CPU total)=20277.79296875MB
INFO:root:[   15] Training loss: 0.68715514, Validation loss: 0.68996815, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20550.953125MB; mem (CPU total)=20318.73828125MB
INFO:root:[   16] Training loss: 0.68619735, Validation loss: 0.68667774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20589.046875MB; mem (CPU total)=20353.8828125MB
INFO:root:[   17] Training loss: 0.68541613, Validation loss: 0.68597045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20627.14453125MB; mem (CPU total)=20391.95703125MB
INFO:root:[   18] Training loss: 0.68492549, Validation loss: 0.68507253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20665.2421875MB; mem (CPU total)=20429.94921875MB
INFO:root:[   19] Training loss: 0.68387987, Validation loss: 0.68455976, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20703.3359375MB; mem (CPU total)=20468.35546875MB
INFO:root:[   20] Training loss: 0.68293210, Validation loss: 0.68398940, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20741.43359375MB; mem (CPU total)=20506.296875MB
INFO:root:[   21] Training loss: 0.68249914, Validation loss: 0.68315252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20779.52734375MB; mem (CPU total)=20544.1171875MB
INFO:root:[   22] Training loss: 0.68195923, Validation loss: 0.68222861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20817.62109375MB; mem (CPU total)=20582.73046875MB
INFO:root:[   23] Training loss: 0.68090903, Validation loss: 0.68102222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20855.71875MB; mem (CPU total)=20621.015625MB
INFO:root:[   24] Training loss: 0.68041704, Validation loss: 0.68011767, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20893.8125MB; mem (CPU total)=20659.44140625MB
INFO:root:[   25] Training loss: 0.67965824, Validation loss: 0.68008745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20931.90625MB; mem (CPU total)=20697.83203125MB
INFO:root:[   26] Training loss: 0.67859348, Validation loss: 0.67861278, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20970.0MB; mem (CPU total)=20736.41796875MB
INFO:root:[   27] Training loss: 0.67812034, Validation loss: 0.67876527, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21008.1015625MB; mem (CPU total)=20774.765625MB
INFO:root:[   28] Training loss: 0.67756957, Validation loss: 0.67782778, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21046.1953125MB; mem (CPU total)=20812.49609375MB
INFO:root:[   29] Training loss: 0.67695839, Validation loss: 0.67827274, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21084.30078125MB; mem (CPU total)=20850.81640625MB
INFO:root:[   30] Training loss: 0.67643635, Validation loss: 0.67695614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21122.38671875MB; mem (CPU total)=20888.671875MB
INFO:root:[   31] Training loss: 0.67603448, Validation loss: 0.67695951, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21160.48046875MB; mem (CPU total)=20926.8359375MB
INFO:root:[   32] Training loss: 0.67564906, Validation loss: 0.67654509, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21198.57421875MB; mem (CPU total)=20965.5390625MB
INFO:root:[   33] Training loss: 0.67512827, Validation loss: 0.67523014, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21236.66796875MB; mem (CPU total)=21003.66796875MB
INFO:root:[   34] Training loss: 0.67458779, Validation loss: 0.67536565, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21274.765625MB; mem (CPU total)=21041.8125MB
INFO:root:[   35] Training loss: 0.67434629, Validation loss: 0.67612422, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21312.859375MB; mem (CPU total)=21079.74609375MB
INFO:root:[   36] Training loss: 0.67416144, Validation loss: 0.67598026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21350.953125MB; mem (CPU total)=21117.921875MB
INFO:root:[   37] Training loss: 0.67358859, Validation loss: 0.67465834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21389.0546875MB; mem (CPU total)=21155.58203125MB
INFO:root:[   38] Training loss: 0.67374060, Validation loss: 0.67506130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21427.1484375MB; mem (CPU total)=21193.74609375MB
INFO:root:[   39] Training loss: 0.67315075, Validation loss: 0.67410005, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21465.2421875MB; mem (CPU total)=21232.125MB
INFO:root:[   40] Training loss: 0.67250508, Validation loss: 0.67294492, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21503.33984375MB; mem (CPU total)=21270.3203125MB
INFO:root:[   41] Training loss: 0.67251106, Validation loss: 0.67235549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21541.43359375MB; mem (CPU total)=21308.4296875MB
INFO:root:[   42] Training loss: 0.67199679, Validation loss: 0.67309781, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21579.52734375MB; mem (CPU total)=21346.57421875MB
INFO:root:[   43] Training loss: 0.67185832, Validation loss: 0.67266202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21617.62109375MB; mem (CPU total)=21384.71875MB
INFO:root:[   44] Training loss: 0.67159338, Validation loss: 0.67311428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21655.72265625MB; mem (CPU total)=21422.85546875MB
INFO:root:[   45] Training loss: 0.67146775, Validation loss: 0.67257095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21693.81640625MB; mem (CPU total)=21461.0859375MB
INFO:root:[   46] Training loss: 0.67106905, Validation loss: 0.67192564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21731.91015625MB; mem (CPU total)=21499.16796875MB
INFO:root:[   47] Training loss: 0.67091796, Validation loss: 0.67148099, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21770.0078125MB; mem (CPU total)=21537.22265625MB
INFO:root:[   48] Training loss: 0.67052419, Validation loss: 0.67185126, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21808.1015625MB; mem (CPU total)=21575.15234375MB
INFO:root:[   49] Training loss: 0.67071194, Validation loss: 0.67205394, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21846.1953125MB; mem (CPU total)=21613.296875MB
INFO:root:[   50] Training loss: 0.67027009, Validation loss: 0.67087967, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21884.2890625MB; mem (CPU total)=21651.75MB
INFO:root:[   51] Training loss: 0.67002001, Validation loss: 0.67116084, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21922.38671875MB; mem (CPU total)=21690.125MB
INFO:root:[   52] Training loss: 0.67000429, Validation loss: 0.67101337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21960.484375MB; mem (CPU total)=21728.265625MB
INFO:root:[   53] Training loss: 0.66962639, Validation loss: 0.67073801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21998.578125MB; mem (CPU total)=21766.61328125MB
INFO:root:[   54] Training loss: 0.66940108, Validation loss: 0.67119249, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22036.6796875MB; mem (CPU total)=21805.0MB
INFO:root:[   55] Training loss: 0.66924076, Validation loss: 0.67038195, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22074.7734375MB; mem (CPU total)=21842.9765625MB
INFO:root:[   56] Training loss: 0.66925752, Validation loss: 0.67039956, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22112.8671875MB; mem (CPU total)=21881.3984375MB
INFO:root:[   57] Training loss: 0.66856191, Validation loss: 0.67000144, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22150.96484375MB; mem (CPU total)=21919.078125MB
INFO:root:[   58] Training loss: 0.66788832, Validation loss: 0.66880718, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22189.05859375MB; mem (CPU total)=21956.765625MB
INFO:root:[   59] Training loss: 0.66754456, Validation loss: 0.66791469, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22227.15234375MB; mem (CPU total)=21994.62890625MB
INFO:root:[   60] Training loss: 0.66648449, Validation loss: 0.66831675, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22265.24609375MB; mem (CPU total)=22032.734375MB
INFO:root:[   61] Training loss: 0.66623458, Validation loss: 0.66677334, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22303.34765625MB; mem (CPU total)=22071.07421875MB
INFO:root:[   62] Training loss: 0.66570456, Validation loss: 0.66586902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22341.44140625MB; mem (CPU total)=22109.421875MB
INFO:root:[   63] Training loss: 0.66511663, Validation loss: 0.66555212, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22379.53515625MB; mem (CPU total)=22147.88671875MB
INFO:root:[   64] Training loss: 0.66430079, Validation loss: 0.66477985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22417.6328125MB; mem (CPU total)=22185.9609375MB
INFO:root:[   65] Training loss: 0.66457522, Validation loss: 0.66554649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22455.7265625MB; mem (CPU total)=22224.4453125MB
INFO:root:[   66] Training loss: 0.66336365, Validation loss: 0.66540775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22493.8203125MB; mem (CPU total)=22262.5859375MB
INFO:root:[   67] Training loss: 0.66340659, Validation loss: 0.66433069, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22531.9140625MB; mem (CPU total)=22300.6640625MB
INFO:root:[   68] Training loss: 0.66294855, Validation loss: 0.66298568, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22570.01171875MB; mem (CPU total)=22338.70703125MB
INFO:root:[   69] Training loss: 0.66242654, Validation loss: 0.66320470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22608.10546875MB; mem (CPU total)=22376.8828125MB
INFO:root:[   70] Training loss: 0.66210703, Validation loss: 0.66300374, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22646.203125MB; mem (CPU total)=22415.2734375MB
INFO:root:[   71] Training loss: 0.66135533, Validation loss: 0.66221851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22684.30078125MB; mem (CPU total)=22453.1875MB
INFO:root:[   72] Training loss: 0.66140808, Validation loss: 0.66126152, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22722.39453125MB; mem (CPU total)=22491.5703125MB
INFO:root:[   73] Training loss: 0.66070950, Validation loss: 0.66130650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22760.48828125MB; mem (CPU total)=22529.9765625MB
INFO:root:[   74] Training loss: 0.66042925, Validation loss: 0.66174196, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22798.5859375MB; mem (CPU total)=22568.32421875MB
INFO:root:[   75] Training loss: 0.66019007, Validation loss: 0.66105606, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22836.6796875MB; mem (CPU total)=22606.1015625MB
INFO:root:[   76] Training loss: 0.66019541, Validation loss: 0.66005805, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22874.7734375MB; mem (CPU total)=22644.63671875MB
INFO:root:[   77] Training loss: 0.65981390, Validation loss: 0.66073686, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22912.8671875MB; mem (CPU total)=22683.0234375MB
INFO:root:[   78] Training loss: 0.65937550, Validation loss: 0.66042488, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22950.96875MB; mem (CPU total)=22721.16015625MB
INFO:root:[   79] Training loss: 0.65947857, Validation loss: 0.66068152, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22989.05859375MB; mem (CPU total)=22759.2578125MB
INFO:root:[   80] Training loss: 0.65906019, Validation loss: 0.66068337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23027.15625MB; mem (CPU total)=22797.07421875MB
INFO:root:[   81] Training loss: 0.65899573, Validation loss: 0.65923786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23065.25390625MB; mem (CPU total)=22835.25MB
INFO:root:[   82] Training loss: 0.65823691, Validation loss: 0.65928665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23103.34765625MB; mem (CPU total)=22873.640625MB
INFO:root:[   83] Training loss: 0.65848878, Validation loss: 0.65943223, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23141.44140625MB; mem (CPU total)=22911.78515625MB
INFO:root:[   84] Training loss: 0.65803555, Validation loss: 0.65919609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23179.53515625MB; mem (CPU total)=22949.8984375MB
INFO:root:[   85] Training loss: 0.65795605, Validation loss: 0.65980789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23217.6328125MB; mem (CPU total)=22988.03125MB
INFO:root:[   86] Training loss: 0.65762619, Validation loss: 0.65889229, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23255.7265625MB; mem (CPU total)=23026.33984375MB
INFO:root:[   87] Training loss: 0.65759224, Validation loss: 0.65871543, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23293.82421875MB; mem (CPU total)=23064.5390625MB
INFO:root:[   88] Training loss: 0.65782023, Validation loss: 0.65831227, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23331.921875MB; mem (CPU total)=23102.73046875MB
INFO:root:[   89] Training loss: 0.65733521, Validation loss: 0.65758788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23370.015625MB; mem (CPU total)=23141.26171875MB
INFO:root:[   90] Training loss: 0.65751309, Validation loss: 0.65754729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23408.109375MB; mem (CPU total)=23179.05078125MB
INFO:root:[   91] Training loss: 0.65735912, Validation loss: 0.65820549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23446.20703125MB; mem (CPU total)=23217.44140625MB
INFO:root:[   92] Training loss: 0.65707874, Validation loss: 0.65841696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23484.30078125MB; mem (CPU total)=23255.57421875MB
INFO:root:[   93] Training loss: 0.65706184, Validation loss: 0.65721880, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23522.39453125MB; mem (CPU total)=23293.68359375MB
INFO:root:[   94] Training loss: 0.65658276, Validation loss: 0.65691554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23560.4921875MB; mem (CPU total)=23331.6328125MB
INFO:root:[   95] Training loss: 0.65656967, Validation loss: 0.65815318, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23598.58984375MB; mem (CPU total)=23370.01953125MB
INFO:root:[   96] Training loss: 0.65640216, Validation loss: 0.65684184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23636.6875MB; mem (CPU total)=23407.90234375MB
INFO:root:[   97] Training loss: 0.65585570, Validation loss: 0.65701859, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23674.78125MB; mem (CPU total)=23446.26953125MB
INFO:root:[   98] Training loss: 0.65648351, Validation loss: 0.65741373, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23712.87890625MB; mem (CPU total)=23484.359375MB
INFO:root:[   99] Training loss: 0.65579212, Validation loss: 0.65672564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23750.97265625MB; mem (CPU total)=23522.4140625MB
INFO:root:[  100] Training loss: 0.65573445, Validation loss: 0.65671621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23789.06640625MB; mem (CPU total)=23561.53515625MB
INFO:root:[  101] Training loss: 0.65555150, Validation loss: 0.65768709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23827.16015625MB; mem (CPU total)=23601.72265625MB
INFO:root:[  102] Training loss: 0.65606013, Validation loss: 0.65704109, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23865.26171875MB; mem (CPU total)=23639.8671875MB
INFO:root:[  103] Training loss: 0.65550938, Validation loss: 0.65717233, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23903.35546875MB; mem (CPU total)=23677.85546875MB
INFO:root:[  104] Training loss: 0.65510593, Validation loss: 0.65789737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23941.44921875MB; mem (CPU total)=23715.94140625MB
INFO:root:[  105] Training loss: 0.65546359, Validation loss: 0.65650176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23979.546875MB; mem (CPU total)=23753.57421875MB
INFO:root:[  106] Training loss: 0.65525885, Validation loss: 0.65607818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24017.6484375MB; mem (CPU total)=23791.14453125MB
INFO:root:[  107] Training loss: 0.65507958, Validation loss: 0.65666843, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24055.7421875MB; mem (CPU total)=23829.57421875MB
INFO:root:[  108] Training loss: 0.65506993, Validation loss: 0.65644253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24093.83984375MB; mem (CPU total)=23867.69921875MB
INFO:root:[  109] Training loss: 0.65479516, Validation loss: 0.65655215, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24131.93359375MB; mem (CPU total)=23905.8125MB
INFO:root:[  110] Training loss: 0.65480565, Validation loss: 0.65594069, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24170.03125MB; mem (CPU total)=23943.83984375MB
INFO:root:[  111] Training loss: 0.65459037, Validation loss: 0.65639253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24208.125MB; mem (CPU total)=23981.984375MB
INFO:root:[  112] Training loss: 0.65477735, Validation loss: 0.65772163, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24246.22265625MB; mem (CPU total)=24020.36328125MB
INFO:root:[  113] Training loss: 0.65462395, Validation loss: 0.65605388, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24284.31640625MB; mem (CPU total)=24058.3828125MB
INFO:root:[  114] Training loss: 0.65392983, Validation loss: 0.65489529, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24322.41015625MB; mem (CPU total)=24096.15234375MB
INFO:root:[  115] Training loss: 0.65493674, Validation loss: 0.65605541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24360.5078125MB; mem (CPU total)=24134.328125MB
INFO:root:[  116] Training loss: 0.65421909, Validation loss: 0.65566868, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24398.6015625MB; mem (CPU total)=24172.47265625MB
INFO:root:[  117] Training loss: 0.65400117, Validation loss: 0.65569947, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24436.6953125MB; mem (CPU total)=24210.6484375MB
INFO:root:[  118] Training loss: 0.65403710, Validation loss: 0.65549759, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24474.79296875MB; mem (CPU total)=24248.9296875MB
INFO:root:[  119] Training loss: 0.65388218, Validation loss: 0.65541738, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24512.890625MB; mem (CPU total)=24287.06640625MB
INFO:root:[  120] Training loss: 0.65358054, Validation loss: 0.65512116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24550.984375MB; mem (CPU total)=24325.4375MB
INFO:root:[  121] Training loss: 0.65390544, Validation loss: 0.65558905, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24589.08203125MB; mem (CPU total)=24363.30859375MB
INFO:root:[  122] Training loss: 0.65345956, Validation loss: 0.65564456, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24627.1796875MB; mem (CPU total)=24401.69921875MB
INFO:root:[  123] Training loss: 0.65352938, Validation loss: 0.65577437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24665.2734375MB; mem (CPU total)=24439.84375MB
INFO:root:[  124] Training loss: 0.65386567, Validation loss: 0.65391256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24703.3671875MB; mem (CPU total)=24477.21875MB
INFO:root:[  125] Training loss: 0.65372824, Validation loss: 0.65556091, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24741.46484375MB; mem (CPU total)=24515.59375MB
INFO:root:[  126] Training loss: 0.65301576, Validation loss: 0.65472437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24779.55859375MB; mem (CPU total)=24553.5390625MB
INFO:root:[  127] Training loss: 0.65356950, Validation loss: 0.65402191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24817.65625MB; mem (CPU total)=24591.51953125MB
INFO:root:[  128] Training loss: 0.65313585, Validation loss: 0.65471110, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24855.75MB; mem (CPU total)=24629.84765625MB
INFO:root:[  129] Training loss: 0.65318439, Validation loss: 0.65479324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24893.84765625MB; mem (CPU total)=24667.74609375MB
INFO:root:[  130] Training loss: 0.65281224, Validation loss: 0.65430242, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24931.94140625MB; mem (CPU total)=24706.13671875MB
INFO:root:[  131] Training loss: 0.65278278, Validation loss: 0.65416669, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24970.03515625MB; mem (CPU total)=24744.265625MB
INFO:root:[  132] Training loss: 0.65270938, Validation loss: 0.65391725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25008.12890625MB; mem (CPU total)=24782.40625MB
INFO:root:[  133] Training loss: 0.65229681, Validation loss: 0.65389309, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25046.2265625MB; mem (CPU total)=24820.4140625MB
INFO:root:[  134] Training loss: 0.65282497, Validation loss: 0.65529991, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25084.3203125MB; mem (CPU total)=24858.8203125MB
INFO:root:[  135] Training loss: 0.65246938, Validation loss: 0.65407838, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25122.41796875MB; mem (CPU total)=24896.96484375MB
INFO:root:[  136] Training loss: 0.65261259, Validation loss: 0.65417828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25160.515625MB; mem (CPU total)=24935.35546875MB
INFO:root:[  137] Training loss: 0.65249303, Validation loss: 0.65323226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25198.609375MB; mem (CPU total)=24973.5625MB
INFO:root:[  138] Training loss: 0.65230170, Validation loss: 0.65307002, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25236.70703125MB; mem (CPU total)=25011.8203125MB
INFO:root:[  139] Training loss: 0.65199807, Validation loss: 0.65507483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25274.8046875MB; mem (CPU total)=25050.44140625MB
INFO:root:[  140] Training loss: 0.65251814, Validation loss: 0.65375802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25312.8984375MB; mem (CPU total)=25088.3359375MB
INFO:root:[  141] Training loss: 0.65239300, Validation loss: 0.65295642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25350.9921875MB; mem (CPU total)=25125.7890625MB
INFO:root:[  142] Training loss: 0.65212599, Validation loss: 0.65327328, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25389.08984375MB; mem (CPU total)=25164.45703125MB
INFO:root:[  143] Training loss: 0.65185653, Validation loss: 0.65389386, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25427.1875MB; mem (CPU total)=25202.6328125MB
INFO:root:[  144] Training loss: 0.65180659, Validation loss: 0.65317380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25465.28125MB; mem (CPU total)=25240.62890625MB
INFO:root:[  145] Training loss: 0.65202054, Validation loss: 0.65297446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25503.37109375MB; mem (CPU total)=25278.76171875MB
INFO:root:[  146] Training loss: 0.65190932, Validation loss: 0.65298913, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25541.47265625MB; mem (CPU total)=25316.59765625MB
INFO:root:[  147] Training loss: 0.65158997, Validation loss: 0.65418349, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25579.56640625MB; mem (CPU total)=25354.671875MB
INFO:root:[  148] Training loss: 0.65166424, Validation loss: 0.65373251, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25617.66015625MB; mem (CPU total)=25392.81640625MB
INFO:root:[  149] Training loss: 0.65177833, Validation loss: 0.65322916, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25655.7578125MB; mem (CPU total)=25431.16796875MB
INFO:root:[  150] Training loss: 0.65192898, Validation loss: 0.65352799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25693.8515625MB; mem (CPU total)=25469.3046875MB
INFO:root:EP 150: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=25731.94921875MB; mem (CPU total)=25507.19921875MB
INFO:root:Training the model took 13496.521s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92488
INFO:root:EnergyScoreTrain: 0.65134
INFO:root:CRPSTrain: 0.59865
INFO:root:Gaussian NLLTrain: 2.16727
INFO:root:CoverageTrain: 0.77017
INFO:root:IntervalWidthTrain: 3.28078
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.92743
INFO:root:EnergyScoreValidation: 0.65318
INFO:root:CRPSValidation: 0.60045
INFO:root:Gaussian NLLValidation: 2.1759
INFO:root:CoverageValidation: 0.76931
INFO:root:IntervalWidthValidation: 3.27908
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.92767
INFO:root:EnergyScoreTest: 0.65331
INFO:root:CRPSTest: 0.60052
INFO:root:Gaussian NLLTest: 2.1727
INFO:root:CoverageTest: 0.76946
INFO:root:IntervalWidthTest: 3.28202
INFO:root:After validation: mem (CPU python)=25774.83984375MB; mem (CPU total)=25550.55078125MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=25774.83984375MB; mem (CPU total)=25550.55078125MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 299892736
INFO:root:After setting up the model: mem (CPU python)=25774.90234375MB; mem (CPU total)=25550.55078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=25774.90625MB; mem (CPU total)=25550.54296875MB
INFO:root:[    1] Training loss: 0.76464156, Validation loss: 0.72311605, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25812.921875MB; mem (CPU total)=25589.6015625MB
INFO:root:[    2] Training loss: 0.71886527, Validation loss: 0.71346826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25851.015625MB; mem (CPU total)=25625.22265625MB
INFO:root:[    3] Training loss: 0.71323560, Validation loss: 0.71013666, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25889.10546875MB; mem (CPU total)=25663.67578125MB
INFO:root:[    4] Training loss: 0.70883322, Validation loss: 0.70290929, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25927.20703125MB; mem (CPU total)=25701.359375MB
INFO:root:[    5] Training loss: 0.70277063, Validation loss: 0.69984393, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25965.30078125MB; mem (CPU total)=25739.4453125MB
INFO:root:[    6] Training loss: 0.69923864, Validation loss: 0.69822010, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26003.39453125MB; mem (CPU total)=25777.69140625MB
INFO:root:[    7] Training loss: 0.69642953, Validation loss: 0.70320471, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26041.4921875MB; mem (CPU total)=25816.05078125MB
INFO:root:[    8] Training loss: 0.69531395, Validation loss: 0.69484492, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26079.5859375MB; mem (CPU total)=25854.2734375MB
INFO:root:[    9] Training loss: 0.69289945, Validation loss: 0.69237916, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26117.68359375MB; mem (CPU total)=25892.26171875MB
INFO:root:[   10] Training loss: 0.69040632, Validation loss: 0.68983670, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26155.78125MB; mem (CPU total)=25930.453125MB
INFO:root:[   11] Training loss: 0.68938653, Validation loss: 0.68961925, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26193.87890625MB; mem (CPU total)=25968.9140625MB
INFO:root:[   12] Training loss: 0.68876907, Validation loss: 0.68845288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26231.99609375MB; mem (CPU total)=26007.01171875MB
INFO:root:[   13] Training loss: 0.68825197, Validation loss: 0.68887586, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26270.0625MB; mem (CPU total)=26045.4140625MB
INFO:root:[   14] Training loss: 0.68762042, Validation loss: 0.68913423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26308.16015625MB; mem (CPU total)=26083.34765625MB
INFO:root:[   15] Training loss: 0.68711628, Validation loss: 0.68737587, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26346.25390625MB; mem (CPU total)=26121.6484375MB
INFO:root:[   16] Training loss: 0.68667400, Validation loss: 0.68684381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26384.34765625MB; mem (CPU total)=26159.68359375MB
INFO:root:[   17] Training loss: 0.68620108, Validation loss: 0.68857554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26422.4453125MB; mem (CPU total)=26197.88671875MB
INFO:root:[   18] Training loss: 0.68609254, Validation loss: 0.68676064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26460.5390625MB; mem (CPU total)=26236.12890625MB
INFO:root:[   19] Training loss: 0.68561415, Validation loss: 0.68640774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26498.63671875MB; mem (CPU total)=26274.41796875MB
INFO:root:[   20] Training loss: 0.68507349, Validation loss: 0.68577024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26536.73046875MB; mem (CPU total)=26312.25MB
INFO:root:[   21] Training loss: 0.68487130, Validation loss: 0.68588712, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26574.828125MB; mem (CPU total)=26350.67578125MB
INFO:root:[   22] Training loss: 0.68446601, Validation loss: 0.68496891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26612.921875MB; mem (CPU total)=26388.93359375MB
INFO:root:[   23] Training loss: 0.68391266, Validation loss: 0.68427178, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26651.015625MB; mem (CPU total)=26427.76171875MB
INFO:root:[   24] Training loss: 0.68356697, Validation loss: 0.68410276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26689.11328125MB; mem (CPU total)=26465.48828125MB
INFO:root:[   25] Training loss: 0.68316079, Validation loss: 0.68436367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26727.2109375MB; mem (CPU total)=26503.9296875MB
INFO:root:[   26] Training loss: 0.68257953, Validation loss: 0.68298641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26765.30859375MB; mem (CPU total)=26542.21875MB
INFO:root:[   27] Training loss: 0.68161485, Validation loss: 0.68212757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26803.3984375MB; mem (CPU total)=26580.44140625MB
INFO:root:[   28] Training loss: 0.68113645, Validation loss: 0.68135706, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26841.5MB; mem (CPU total)=26618.8671875MB
INFO:root:[   29] Training loss: 0.68027161, Validation loss: 0.68009999, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26879.59375MB; mem (CPU total)=26656.43359375MB
INFO:root:[   30] Training loss: 0.67915279, Validation loss: 0.68090132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26917.6875MB; mem (CPU total)=26695.73046875MB
INFO:root:[   31] Training loss: 0.67843751, Validation loss: 0.67949194, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26955.78515625MB; mem (CPU total)=26732.94140625MB
INFO:root:[   32] Training loss: 0.67726509, Validation loss: 0.67928561, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26993.87890625MB; mem (CPU total)=26770.3046875MB
INFO:root:[   33] Training loss: 0.67690102, Validation loss: 0.67830520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27031.9765625MB; mem (CPU total)=26808.66796875MB
INFO:root:[   34] Training loss: 0.67612273, Validation loss: 0.67844306, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27070.07421875MB; mem (CPU total)=26847.09375MB
INFO:root:[   35] Training loss: 0.67555190, Validation loss: 0.67585220, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27108.16796875MB; mem (CPU total)=26884.9296875MB
INFO:root:[   36] Training loss: 0.67499832, Validation loss: 0.67556400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27146.26171875MB; mem (CPU total)=26922.9296875MB
INFO:root:[   37] Training loss: 0.67435400, Validation loss: 0.67545324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27184.35546875MB; mem (CPU total)=26961.2109375MB
INFO:root:[   38] Training loss: 0.67405577, Validation loss: 0.67463876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27222.453125MB; mem (CPU total)=26999.06640625MB
INFO:root:[   39] Training loss: 0.67334992, Validation loss: 0.67398242, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27260.546875MB; mem (CPU total)=27037.16796875MB
INFO:root:[   40] Training loss: 0.67347216, Validation loss: 0.67427238, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27298.640625MB; mem (CPU total)=27075.48046875MB
INFO:root:[   41] Training loss: 0.67289476, Validation loss: 0.67317941, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27336.7421875MB; mem (CPU total)=27113.73828125MB
INFO:root:[   42] Training loss: 0.67249679, Validation loss: 0.67367671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27374.8359375MB; mem (CPU total)=27152.65625MB
INFO:root:[   43] Training loss: 0.67251827, Validation loss: 0.67348087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27412.9296875MB; mem (CPU total)=27190.3203125MB
INFO:root:[   44] Training loss: 0.67183380, Validation loss: 0.67364801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27451.0234375MB; mem (CPU total)=27228.22265625MB
INFO:root:[   45] Training loss: 0.67182319, Validation loss: 0.67281436, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27489.12109375MB; mem (CPU total)=27266.375MB
INFO:root:[   46] Training loss: 0.67128588, Validation loss: 0.67230681, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27527.21484375MB; mem (CPU total)=27304.921875MB
INFO:root:[   47] Training loss: 0.67129215, Validation loss: 0.67250027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27565.30859375MB; mem (CPU total)=27343.34375MB
INFO:root:[   48] Training loss: 0.67066561, Validation loss: 0.67191539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27603.40625MB; mem (CPU total)=27381.9296875MB
INFO:root:[   49] Training loss: 0.67038007, Validation loss: 0.67165064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27641.5MB; mem (CPU total)=27419.8984375MB
INFO:root:[   50] Training loss: 0.66993817, Validation loss: 0.67112746, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27679.59765625MB; mem (CPU total)=27457.6796875MB
INFO:root:[   51] Training loss: 0.66968179, Validation loss: 0.67086334, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27717.6953125MB; mem (CPU total)=27495.47265625MB
INFO:root:[   52] Training loss: 0.66952388, Validation loss: 0.67153218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27755.7890625MB; mem (CPU total)=27533.33984375MB
INFO:root:[   53] Training loss: 0.66937646, Validation loss: 0.66997852, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27793.8828125MB; mem (CPU total)=27570.40625MB
INFO:root:[   54] Training loss: 0.66890104, Validation loss: 0.66938512, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27831.9765625MB; mem (CPU total)=27608.796875MB
INFO:root:[   55] Training loss: 0.66852895, Validation loss: 0.66934308, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27870.07421875MB; mem (CPU total)=27647.453125MB
INFO:root:[   56] Training loss: 0.66831433, Validation loss: 0.66982660, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27908.16796875MB; mem (CPU total)=27685.36328125MB
INFO:root:[   57] Training loss: 0.66808294, Validation loss: 0.67017629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27946.26171875MB; mem (CPU total)=27723.46484375MB
INFO:root:[   58] Training loss: 0.66777732, Validation loss: 0.66991982, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27984.359375MB; mem (CPU total)=27761.42578125MB
INFO:root:[   59] Training loss: 0.66766423, Validation loss: 0.66904773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28022.453125MB; mem (CPU total)=27800.109375MB
INFO:root:[   60] Training loss: 0.66749168, Validation loss: 0.66872818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28060.546875MB; mem (CPU total)=27837.9140625MB
INFO:root:[   61] Training loss: 0.66708377, Validation loss: 0.66834187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28098.64453125MB; mem (CPU total)=27874.86328125MB
INFO:root:[   62] Training loss: 0.66701963, Validation loss: 0.66796377, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28136.7421875MB; mem (CPU total)=27912.60546875MB
INFO:root:[   63] Training loss: 0.66660574, Validation loss: 0.66758861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28174.8359375MB; mem (CPU total)=27950.47265625MB
INFO:root:[   64] Training loss: 0.66638089, Validation loss: 0.66777445, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28212.9296875MB; mem (CPU total)=27988.76953125MB
INFO:root:[   65] Training loss: 0.66626520, Validation loss: 0.66828834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28251.02734375MB; mem (CPU total)=28027.15625MB
INFO:root:[   66] Training loss: 0.66570315, Validation loss: 0.66653095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28289.125MB; mem (CPU total)=28065.14453125MB
INFO:root:[   67] Training loss: 0.66540330, Validation loss: 0.66626399, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28327.21875MB; mem (CPU total)=28103.3828125MB
INFO:root:[   68] Training loss: 0.66459107, Validation loss: 0.66551803, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28365.31640625MB; mem (CPU total)=28140.33984375MB
INFO:root:[   69] Training loss: 0.66388193, Validation loss: 0.66524168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28403.4140625MB; mem (CPU total)=28178.81640625MB
INFO:root:[   70] Training loss: 0.66388168, Validation loss: 0.66521620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28441.5078125MB; mem (CPU total)=28216.73046875MB
INFO:root:[   71] Training loss: 0.66257216, Validation loss: 0.66432483, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28479.6015625MB; mem (CPU total)=28254.90234375MB
INFO:root:[   72] Training loss: 0.66268050, Validation loss: 0.66367536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28517.69921875MB; mem (CPU total)=28292.78515625MB
INFO:root:[   73] Training loss: 0.66214016, Validation loss: 0.66304539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28555.79296875MB; mem (CPU total)=28331.17578125MB
INFO:root:[   74] Training loss: 0.66162375, Validation loss: 0.66296828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28593.88671875MB; mem (CPU total)=28368.42578125MB
INFO:root:[   75] Training loss: 0.66125137, Validation loss: 0.66191718, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28631.984375MB; mem (CPU total)=28406.59375MB
INFO:root:[   76] Training loss: 0.66109853, Validation loss: 0.66211696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28670.078125MB; mem (CPU total)=28445.36328125MB
INFO:root:[   77] Training loss: 0.66071897, Validation loss: 0.66132763, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28708.17578125MB; mem (CPU total)=28483.5625MB
INFO:root:[   78] Training loss: 0.65998375, Validation loss: 0.66180112, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28746.26953125MB; mem (CPU total)=28521.75MB
INFO:root:[   79] Training loss: 0.66039122, Validation loss: 0.66052712, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28784.3671875MB; mem (CPU total)=28559.36328125MB
INFO:root:[   80] Training loss: 0.65964832, Validation loss: 0.66188124, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28822.4609375MB; mem (CPU total)=28597.74609375MB
INFO:root:[   81] Training loss: 0.65967352, Validation loss: 0.66061181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28860.5546875MB; mem (CPU total)=28635.8828125MB
INFO:root:[   82] Training loss: 0.65936272, Validation loss: 0.65986015, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28898.65234375MB; mem (CPU total)=28674.05859375MB
INFO:root:[   83] Training loss: 0.65893334, Validation loss: 0.66085818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28936.74609375MB; mem (CPU total)=28712.203125MB
INFO:root:[   84] Training loss: 0.65846478, Validation loss: 0.66035009, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28974.84375MB; mem (CPU total)=28750.3359375MB
INFO:root:[   85] Training loss: 0.65843399, Validation loss: 0.66017557, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29012.94140625MB; mem (CPU total)=28788.38671875MB
INFO:root:[   86] Training loss: 0.65831138, Validation loss: 0.66001324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29051.03515625MB; mem (CPU total)=28826.53125MB
INFO:root:[   87] Training loss: 0.65783929, Validation loss: 0.66076949, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29089.12890625MB; mem (CPU total)=28864.91015625MB
INFO:root:[   88] Training loss: 0.65765634, Validation loss: 0.66020377, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29127.22265625MB; mem (CPU total)=28902.5390625MB
INFO:root:[   89] Training loss: 0.65786646, Validation loss: 0.65893367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29165.3203125MB; mem (CPU total)=28940.9765625MB
INFO:root:[   90] Training loss: 0.65772229, Validation loss: 0.65889490, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29203.4140625MB; mem (CPU total)=28979.6015625MB
INFO:root:[   91] Training loss: 0.65719938, Validation loss: 0.65860163, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29241.5078125MB; mem (CPU total)=29018.15625MB
INFO:root:[   92] Training loss: 0.65703424, Validation loss: 0.65867460, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29279.609375MB; mem (CPU total)=29056.0546875MB
INFO:root:[   93] Training loss: 0.65671794, Validation loss: 0.65847817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29317.703125MB; mem (CPU total)=29094.31640625MB
INFO:root:[   94] Training loss: 0.65686074, Validation loss: 0.65743044, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29355.796875MB; mem (CPU total)=29132.9921875MB
INFO:root:[   95] Training loss: 0.65648691, Validation loss: 0.65752271, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29393.890625MB; mem (CPU total)=29171.1484375MB
INFO:root:[   96] Training loss: 0.65676542, Validation loss: 0.65707204, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29431.98828125MB; mem (CPU total)=29209.6171875MB
INFO:root:[   97] Training loss: 0.65622958, Validation loss: 0.65787427, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29470.08203125MB; mem (CPU total)=29247.72265625MB
INFO:root:[   98] Training loss: 0.65616653, Validation loss: 0.65751998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29508.17578125MB; mem (CPU total)=29285.609375MB
INFO:root:[   99] Training loss: 0.65653075, Validation loss: 0.65667868, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29546.2734375MB; mem (CPU total)=29323.96875MB
INFO:root:[  100] Training loss: 0.65602011, Validation loss: 0.65791246, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29584.3671875MB; mem (CPU total)=29362.92578125MB
INFO:root:[  101] Training loss: 0.65593744, Validation loss: 0.65687231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29622.4609375MB; mem (CPU total)=29400.45703125MB
INFO:root:[  102] Training loss: 0.65558851, Validation loss: 0.65678873, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29660.5625MB; mem (CPU total)=29438.44140625MB
INFO:root:[  103] Training loss: 0.65569203, Validation loss: 0.65642614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29698.65234375MB; mem (CPU total)=29476.63671875MB
INFO:root:[  104] Training loss: 0.65543638, Validation loss: 0.65768566, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29736.75MB; mem (CPU total)=29515.05859375MB
INFO:root:[  105] Training loss: 0.65580402, Validation loss: 0.65690116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29774.84375MB; mem (CPU total)=29553.4375MB
INFO:root:[  106] Training loss: 0.65543068, Validation loss: 0.65825233, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29812.94140625MB; mem (CPU total)=29591.25390625MB
INFO:root:[  107] Training loss: 0.65538011, Validation loss: 0.65635247, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29851.03515625MB; mem (CPU total)=29629.0703125MB
INFO:root:[  108] Training loss: 0.65539789, Validation loss: 0.65615356, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29889.1328125MB; mem (CPU total)=29666.9453125MB
INFO:root:[  109] Training loss: 0.65488385, Validation loss: 0.65657846, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29927.23046875MB; mem (CPU total)=29705.3359375MB
INFO:root:[  110] Training loss: 0.65518046, Validation loss: 0.65652677, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29965.328125MB; mem (CPU total)=29743.44921875MB
INFO:root:[  111] Training loss: 0.65480473, Validation loss: 0.65633450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30003.42578125MB; mem (CPU total)=29781.27734375MB
INFO:root:[  112] Training loss: 0.65516605, Validation loss: 0.65696619, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30041.51953125MB; mem (CPU total)=29819.8984375MB
INFO:root:[  113] Training loss: 0.65466561, Validation loss: 0.65609069, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30079.6171875MB; mem (CPU total)=29858.05078125MB
INFO:root:[  114] Training loss: 0.65436358, Validation loss: 0.65594095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30117.7109375MB; mem (CPU total)=29896.53515625MB
INFO:root:[  115] Training loss: 0.65421504, Validation loss: 0.65773511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30155.8046875MB; mem (CPU total)=29935.5MB
INFO:root:[  116] Training loss: 0.65464449, Validation loss: 0.65660072, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30193.90234375MB; mem (CPU total)=29973.12109375MB
INFO:root:[  117] Training loss: 0.65454551, Validation loss: 0.65565919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30231.99609375MB; mem (CPU total)=30011.421875MB
INFO:root:[  118] Training loss: 0.65425636, Validation loss: 0.65662448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30270.09765625MB; mem (CPU total)=30049.7890625MB
INFO:root:[  119] Training loss: 0.65402855, Validation loss: 0.65602103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30308.1953125MB; mem (CPU total)=30088.11328125MB
INFO:root:[  120] Training loss: 0.65427457, Validation loss: 0.65563896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30346.2890625MB; mem (CPU total)=30126.39453125MB
INFO:root:[  121] Training loss: 0.65396938, Validation loss: 0.65612044, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30384.3828125MB; mem (CPU total)=30164.81640625MB
INFO:root:[  122] Training loss: 0.65388828, Validation loss: 0.65540532, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30422.4765625MB; mem (CPU total)=30202.83984375MB
INFO:root:[  123] Training loss: 0.65413620, Validation loss: 0.65591265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30460.57421875MB; mem (CPU total)=30241.1875MB
INFO:root:[  124] Training loss: 0.65404534, Validation loss: 0.65616631, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30498.66796875MB; mem (CPU total)=30279.328125MB
INFO:root:[  125] Training loss: 0.65394373, Validation loss: 0.65466346, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30536.76171875MB; mem (CPU total)=30316.55078125MB
INFO:root:[  126] Training loss: 0.65402156, Validation loss: 0.65472863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30574.86328125MB; mem (CPU total)=30354.5625MB
INFO:root:[  127] Training loss: 0.65357182, Validation loss: 0.65562054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30612.95703125MB; mem (CPU total)=30392.70703125MB
INFO:root:[  128] Training loss: 0.65359618, Validation loss: 0.65439535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30651.05078125MB; mem (CPU total)=30430.84375MB
INFO:root:[  129] Training loss: 0.65359292, Validation loss: 0.65596908, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30689.14453125MB; mem (CPU total)=30469.23046875MB
INFO:root:[  130] Training loss: 0.65351368, Validation loss: 0.65465081, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30727.2421875MB; mem (CPU total)=30507.36328125MB
INFO:root:[  131] Training loss: 0.65314033, Validation loss: 0.65547127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30765.3359375MB; mem (CPU total)=30545.33984375MB
INFO:root:[  132] Training loss: 0.65363077, Validation loss: 0.65518636, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30803.4296875MB; mem (CPU total)=30583.46484375MB
INFO:root:[  133] Training loss: 0.65350188, Validation loss: 0.65387614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30841.52734375MB; mem (CPU total)=30622.2265625MB
INFO:root:[  134] Training loss: 0.65282642, Validation loss: 0.65489987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30879.62109375MB; mem (CPU total)=30660.0625MB
INFO:root:[  135] Training loss: 0.65317452, Validation loss: 0.65429934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30917.71484375MB; mem (CPU total)=30698.20703125MB
INFO:root:[  136] Training loss: 0.65288711, Validation loss: 0.65483735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30955.81640625MB; mem (CPU total)=30736.0MB
INFO:root:[  137] Training loss: 0.65226465, Validation loss: 0.65528063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30993.91015625MB; mem (CPU total)=30774.67578125MB
INFO:root:[  138] Training loss: 0.65287562, Validation loss: 0.65508422, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31032.00390625MB; mem (CPU total)=30813.0703125MB
INFO:root:[  139] Training loss: 0.65306946, Validation loss: 0.65458098, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31070.09765625MB; mem (CPU total)=30850.9453125MB
INFO:root:[  140] Training loss: 0.65298407, Validation loss: 0.65482611, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31108.1953125MB; mem (CPU total)=30888.77734375MB
INFO:root:[  141] Training loss: 0.65280498, Validation loss: 0.65424207, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31146.2890625MB; mem (CPU total)=30927.16796875MB
INFO:root:[  142] Training loss: 0.65270242, Validation loss: 0.65318796, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31184.3828125MB; mem (CPU total)=30965.42578125MB
INFO:root:[  143] Training loss: 0.65255088, Validation loss: 0.65440261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31222.484375MB; mem (CPU total)=31003.8828125MB
INFO:root:[  144] Training loss: 0.65267219, Validation loss: 0.65408879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31260.578125MB; mem (CPU total)=31042.04296875MB
INFO:root:[  145] Training loss: 0.65278498, Validation loss: 0.65443333, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31298.671875MB; mem (CPU total)=31080.125MB
INFO:root:[  146] Training loss: 0.65261900, Validation loss: 0.65399342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31336.765625MB; mem (CPU total)=31117.89453125MB
INFO:root:[  147] Training loss: 0.65283785, Validation loss: 0.65471186, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31374.8671875MB; mem (CPU total)=31155.80859375MB
INFO:root:[  148] Training loss: 0.65249592, Validation loss: 0.65337721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31412.9609375MB; mem (CPU total)=31193.93359375MB
INFO:root:[  149] Training loss: 0.65229386, Validation loss: 0.65565101, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31451.0546875MB; mem (CPU total)=31232.5234375MB
INFO:root:[  150] Training loss: 0.65211159, Validation loss: 0.65431307, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31489.15234375MB; mem (CPU total)=31270.91015625MB
INFO:root:[  151] Training loss: 0.65230010, Validation loss: 0.65377881, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31527.24609375MB; mem (CPU total)=31309.0546875MB
INFO:root:EP 151: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=31565.33984375MB; mem (CPU total)=31346.94140625MB
INFO:root:Training the model took 14621.21s.
INFO:root:Emptying the cuda cache took 0.003s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92588
INFO:root:EnergyScoreTrain: 0.65197
INFO:root:CRPSTrain: 0.59917
INFO:root:Gaussian NLLTrain: 2.16605
INFO:root:CoverageTrain: 0.76806
INFO:root:IntervalWidthTrain: 3.28666
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.92871
INFO:root:EnergyScoreValidation: 0.65399
INFO:root:CRPSValidation: 0.60108
INFO:root:Gaussian NLLValidation: 2.17413
INFO:root:CoverageValidation: 0.76709
INFO:root:IntervalWidthValidation: 3.28441
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.92852
INFO:root:EnergyScoreTest: 0.65382
INFO:root:CRPSTest: 0.60095
INFO:root:Gaussian NLLTest: 2.17087
INFO:root:CoverageTest: 0.76755
INFO:root:IntervalWidthTest: 3.28758
INFO:root:After validation: mem (CPU python)=31608.05078125MB; mem (CPU total)=31389.73046875MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=31608.05078125MB; mem (CPU total)=31389.71875MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 165675008
INFO:root:After setting up the model: mem (CPU python)=31608.1796875MB; mem (CPU total)=31389.71875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=31608.2109375MB; mem (CPU total)=31389.953125MB
INFO:root:[    1] Training loss: 0.76196004, Validation loss: 0.72943600, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31646.23828125MB; mem (CPU total)=31428.546875MB
INFO:root:[    2] Training loss: 0.72657518, Validation loss: 0.71940386, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31684.3359375MB; mem (CPU total)=31466.05078125MB
INFO:root:[    3] Training loss: 0.71841061, Validation loss: 0.71508920, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31722.42578125MB; mem (CPU total)=31504.1015625MB
INFO:root:[    4] Training loss: 0.71457761, Validation loss: 0.71517813, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31760.52734375MB; mem (CPU total)=31542.4921875MB
INFO:root:[    5] Training loss: 0.71307998, Validation loss: 0.71782640, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31798.62109375MB; mem (CPU total)=31580.3671875MB
INFO:root:[    6] Training loss: 0.71005419, Validation loss: 0.71254843, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31836.71484375MB; mem (CPU total)=31621.9140625MB
INFO:root:[    7] Training loss: 0.70818883, Validation loss: 0.70794268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31874.8125MB; mem (CPU total)=31660.38671875MB
INFO:root:[    8] Training loss: 0.70743122, Validation loss: 0.70621589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31912.90625MB; mem (CPU total)=31699.01171875MB
INFO:root:[    9] Training loss: 0.70684810, Validation loss: 0.70569264, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31951.00390625MB; mem (CPU total)=31737.54296875MB
INFO:root:[   10] Training loss: 0.70596188, Validation loss: 0.70534981, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31989.09765625MB; mem (CPU total)=31775.58203125MB
INFO:root:[   11] Training loss: 0.70611400, Validation loss: 0.70880748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32027.1953125MB; mem (CPU total)=31813.96484375MB
INFO:root:[   12] Training loss: 0.70547616, Validation loss: 0.70405753, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32065.29296875MB; mem (CPU total)=31851.8125MB
INFO:root:[   13] Training loss: 0.70530853, Validation loss: 0.70446104, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32103.38671875MB; mem (CPU total)=31890.4375MB
INFO:root:[   14] Training loss: 0.70413306, Validation loss: 0.70517910, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32141.484375MB; mem (CPU total)=31928.55078125MB
INFO:root:[   15] Training loss: 0.70283180, Validation loss: 0.70231276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32179.578125MB; mem (CPU total)=31966.12890625MB
INFO:root:[   16] Training loss: 0.69965348, Validation loss: 0.69692521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32217.671875MB; mem (CPU total)=32004.203125MB
INFO:root:[   17] Training loss: 0.69517993, Validation loss: 0.69407182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32255.76953125MB; mem (CPU total)=32042.21875MB
INFO:root:[   18] Training loss: 0.69184273, Validation loss: 0.69201742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32293.86328125MB; mem (CPU total)=32080.71484375MB
INFO:root:[   19] Training loss: 0.69007846, Validation loss: 0.68995935, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32331.95703125MB; mem (CPU total)=32119.83203125MB
INFO:root:[   20] Training loss: 0.68835437, Validation loss: 0.68830244, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32370.05078125MB; mem (CPU total)=32157.66015625MB
INFO:root:[   21] Training loss: 0.68724359, Validation loss: 0.68695683, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32408.15234375MB; mem (CPU total)=32196.02734375MB
INFO:root:[   22] Training loss: 0.68555180, Validation loss: 0.68577189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32446.24609375MB; mem (CPU total)=32233.53515625MB
INFO:root:[   23] Training loss: 0.68402312, Validation loss: 0.68429553, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32484.33984375MB; mem (CPU total)=32272.296875MB
INFO:root:[   24] Training loss: 0.68300574, Validation loss: 0.68354758, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32522.4375MB; mem (CPU total)=32310.29296875MB
INFO:root:[   25] Training loss: 0.68197920, Validation loss: 0.68259614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32560.53125MB; mem (CPU total)=32348.296875MB
INFO:root:[   26] Training loss: 0.68098853, Validation loss: 0.68209167, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32598.625MB; mem (CPU total)=32385.953125MB
INFO:root:[   27] Training loss: 0.68022032, Validation loss: 0.68024583, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32636.71875MB; mem (CPU total)=32424.18359375MB
INFO:root:[   28] Training loss: 0.67971885, Validation loss: 0.68030304, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32674.81640625MB; mem (CPU total)=32462.5703125MB
INFO:root:[   29] Training loss: 0.67895111, Validation loss: 0.67999960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32712.9140625MB; mem (CPU total)=32500.64453125MB
INFO:root:[   30] Training loss: 0.67835804, Validation loss: 0.67944173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32751.0078125MB; mem (CPU total)=32539.29296875MB
INFO:root:[   31] Training loss: 0.67782175, Validation loss: 0.67958172, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32789.10546875MB; mem (CPU total)=32577.64453125MB
INFO:root:[   32] Training loss: 0.67750319, Validation loss: 0.67801361, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32827.19921875MB; mem (CPU total)=32615.4375MB
INFO:root:[   33] Training loss: 0.67666399, Validation loss: 0.67782170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32865.29296875MB; mem (CPU total)=32653.71484375MB
INFO:root:[   34] Training loss: 0.67636885, Validation loss: 0.67748255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32903.390625MB; mem (CPU total)=32691.984375MB
INFO:root:[   35] Training loss: 0.67613005, Validation loss: 0.67627865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32941.484375MB; mem (CPU total)=32729.83984375MB
INFO:root:[   36] Training loss: 0.67576628, Validation loss: 0.67767764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32979.578125MB; mem (CPU total)=32768.01171875MB
INFO:root:[   37] Training loss: 0.67545328, Validation loss: 0.67632571, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33017.67578125MB; mem (CPU total)=32806.03125MB
INFO:root:[   38] Training loss: 0.67527463, Validation loss: 0.67578043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33055.7734375MB; mem (CPU total)=32844.12890625MB
INFO:root:[   39] Training loss: 0.67483208, Validation loss: 0.67677234, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33093.8671875MB; mem (CPU total)=32882.55859375MB
INFO:root:[   40] Training loss: 0.67493108, Validation loss: 0.67636496, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33131.9609375MB; mem (CPU total)=32920.98828125MB
INFO:root:[   41] Training loss: 0.67453662, Validation loss: 0.67553284, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33170.05859375MB; mem (CPU total)=32958.89453125MB
INFO:root:[   42] Training loss: 0.67416210, Validation loss: 0.67534355, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33208.15234375MB; mem (CPU total)=32996.76171875MB
INFO:root:[   43] Training loss: 0.67387384, Validation loss: 0.67525897, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33246.24609375MB; mem (CPU total)=33035.15234375MB
INFO:root:[   44] Training loss: 0.67364113, Validation loss: 0.67478148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33284.33984375MB; mem (CPU total)=33072.8984375MB
INFO:root:[   45] Training loss: 0.67352910, Validation loss: 0.67450576, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33322.44140625MB; mem (CPU total)=33111.98046875MB
INFO:root:[   46] Training loss: 0.67321880, Validation loss: 0.67375561, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33360.53515625MB; mem (CPU total)=33150.234375MB
INFO:root:[   47] Training loss: 0.67309184, Validation loss: 0.67435824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33398.62890625MB; mem (CPU total)=33188.171875MB
INFO:root:[   48] Training loss: 0.67284554, Validation loss: 0.67448085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33436.7265625MB; mem (CPU total)=33226.3671875MB
INFO:root:[   49] Training loss: 0.67263956, Validation loss: 0.67448173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33474.8203125MB; mem (CPU total)=33264.44921875MB
INFO:root:[   50] Training loss: 0.67248053, Validation loss: 0.67310125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33512.9140625MB; mem (CPU total)=33302.8984375MB
INFO:root:[   51] Training loss: 0.67233499, Validation loss: 0.67369442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33551.01171875MB; mem (CPU total)=33341.00390625MB
INFO:root:[   52] Training loss: 0.67226457, Validation loss: 0.67302846, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33589.10546875MB; mem (CPU total)=33379.50390625MB
INFO:root:[   53] Training loss: 0.67181067, Validation loss: 0.67332664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33627.19921875MB; mem (CPU total)=33416.82421875MB
INFO:root:[   54] Training loss: 0.67200036, Validation loss: 0.67330659, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33665.296875MB; mem (CPU total)=33454.359375MB
INFO:root:[   55] Training loss: 0.67151071, Validation loss: 0.67289653, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33703.39453125MB; mem (CPU total)=33493.42578125MB
INFO:root:[   56] Training loss: 0.67129881, Validation loss: 0.67259416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33741.48828125MB; mem (CPU total)=33531.4765625MB
INFO:root:[   57] Training loss: 0.67120684, Validation loss: 0.67246797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33779.58203125MB; mem (CPU total)=33569.9765625MB
INFO:root:[   58] Training loss: 0.67083467, Validation loss: 0.67146741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33817.6796875MB; mem (CPU total)=33608.12109375MB
INFO:root:[   59] Training loss: 0.67074085, Validation loss: 0.67191002, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33855.7734375MB; mem (CPU total)=33645.98046875MB
INFO:root:[   60] Training loss: 0.67065298, Validation loss: 0.67177368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33893.8671875MB; mem (CPU total)=33684.08203125MB
INFO:root:[   61] Training loss: 0.67042080, Validation loss: 0.67109807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33931.9609375MB; mem (CPU total)=33721.328125MB
INFO:root:[   62] Training loss: 0.67039592, Validation loss: 0.67247906, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33970.05859375MB; mem (CPU total)=33759.48828125MB
INFO:root:[   63] Training loss: 0.67018321, Validation loss: 0.67124607, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34008.15625MB; mem (CPU total)=33797.38671875MB
INFO:root:[   64] Training loss: 0.67011110, Validation loss: 0.67093376, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34046.24609375MB; mem (CPU total)=33836.10546875MB
INFO:root:[   65] Training loss: 0.66978770, Validation loss: 0.67097565, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34084.34765625MB; mem (CPU total)=33874.47265625MB
INFO:root:[   66] Training loss: 0.66950129, Validation loss: 0.67027316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34122.44140625MB; mem (CPU total)=33912.26171875MB
INFO:root:[   67] Training loss: 0.66934081, Validation loss: 0.67094494, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34160.53515625MB; mem (CPU total)=33950.33984375MB
INFO:root:[   68] Training loss: 0.66965182, Validation loss: 0.67115523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34198.6328125MB; mem (CPU total)=33987.9921875MB
INFO:root:[   69] Training loss: 0.66912834, Validation loss: 0.67064873, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34236.7265625MB; mem (CPU total)=34026.03515625MB
INFO:root:[   70] Training loss: 0.66888858, Validation loss: 0.67051394, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34274.82421875MB; mem (CPU total)=34064.1796875MB
INFO:root:[   71] Training loss: 0.66885429, Validation loss: 0.66976008, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34312.91796875MB; mem (CPU total)=34102.10546875MB
INFO:root:[   72] Training loss: 0.66864863, Validation loss: 0.67147237, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34351.015625MB; mem (CPU total)=34140.5078125MB
INFO:root:[   73] Training loss: 0.66880115, Validation loss: 0.66949644, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34389.109375MB; mem (CPU total)=34179.47265625MB
INFO:root:[   74] Training loss: 0.66834567, Validation loss: 0.67003717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34427.203125MB; mem (CPU total)=34216.84375MB
INFO:root:[   75] Training loss: 0.66822614, Validation loss: 0.66936577, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34465.30078125MB; mem (CPU total)=34254.3515625MB
INFO:root:[   76] Training loss: 0.66837470, Validation loss: 0.66908550, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34503.39453125MB; mem (CPU total)=34292.03515625MB
INFO:root:[   77] Training loss: 0.66830150, Validation loss: 0.66932863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34541.4921875MB; mem (CPU total)=34330.40234375MB
INFO:root:[   78] Training loss: 0.66817297, Validation loss: 0.66888003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34579.5859375MB; mem (CPU total)=34368.640625MB
INFO:root:[   79] Training loss: 0.66796769, Validation loss: 0.66937398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34617.68359375MB; mem (CPU total)=34406.8203125MB
INFO:root:[   80] Training loss: 0.66769249, Validation loss: 0.66921407, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34655.77734375MB; mem (CPU total)=34444.7109375MB
INFO:root:[   81] Training loss: 0.66781003, Validation loss: 0.66942295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34693.87109375MB; mem (CPU total)=34482.6328125MB
INFO:root:[   82] Training loss: 0.66755033, Validation loss: 0.66929831, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34731.96875MB; mem (CPU total)=34520.77734375MB
INFO:root:[   83] Training loss: 0.66738633, Validation loss: 0.66842813, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34770.0625MB; mem (CPU total)=34559.875MB
INFO:root:[   84] Training loss: 0.66735297, Validation loss: 0.66888383, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34808.15625MB; mem (CPU total)=34598.2578125MB
INFO:root:[   85] Training loss: 0.66716885, Validation loss: 0.66761355, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34846.25390625MB; mem (CPU total)=34636.20703125MB
INFO:root:[   86] Training loss: 0.66682707, Validation loss: 0.66810753, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34884.3515625MB; mem (CPU total)=34674.578125MB
INFO:root:[   87] Training loss: 0.66690426, Validation loss: 0.66791022, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34922.4453125MB; mem (CPU total)=34712.703125MB
INFO:root:[   88] Training loss: 0.66686775, Validation loss: 0.66806649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34960.5390625MB; mem (CPU total)=34750.5078125MB
INFO:root:[   89] Training loss: 0.66666114, Validation loss: 0.66811016, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34998.63671875MB; mem (CPU total)=34788.88671875MB
INFO:root:[   90] Training loss: 0.66605974, Validation loss: 0.66784628, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35036.73046875MB; mem (CPU total)=34827.55859375MB
INFO:root:[   91] Training loss: 0.66633980, Validation loss: 0.66748800, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35074.82421875MB; mem (CPU total)=34865.10546875MB
INFO:root:[   92] Training loss: 0.66600915, Validation loss: 0.66706212, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35112.921875MB; mem (CPU total)=34903.3515625MB
INFO:root:[   93] Training loss: 0.66579682, Validation loss: 0.66732768, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35151.015625MB; mem (CPU total)=34942.91015625MB
INFO:root:[   94] Training loss: 0.66563595, Validation loss: 0.66745534, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35189.11328125MB; mem (CPU total)=34980.78515625MB
INFO:root:[   95] Training loss: 0.66567137, Validation loss: 0.66704891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35227.20703125MB; mem (CPU total)=35018.08203125MB
INFO:root:[   96] Training loss: 0.66533606, Validation loss: 0.66628358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35265.3046875MB; mem (CPU total)=35056.58203125MB
INFO:root:[   97] Training loss: 0.66530822, Validation loss: 0.66713943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35303.3984375MB; mem (CPU total)=35094.6953125MB
INFO:root:[   98] Training loss: 0.66512868, Validation loss: 0.66712572, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35341.49609375MB; mem (CPU total)=35132.70703125MB
INFO:root:[   99] Training loss: 0.66494507, Validation loss: 0.66661981, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35379.59375MB; mem (CPU total)=35171.03125MB
INFO:root:[  100] Training loss: 0.66501767, Validation loss: 0.66666702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35417.6875MB; mem (CPU total)=35208.9296875MB
INFO:root:[  101] Training loss: 0.66492756, Validation loss: 0.66616322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35455.78515625MB; mem (CPU total)=35247.31640625MB
INFO:root:[  102] Training loss: 0.66484137, Validation loss: 0.66702913, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35493.87890625MB; mem (CPU total)=35285.51171875MB
INFO:root:[  103] Training loss: 0.66447316, Validation loss: 0.66543113, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35531.9765625MB; mem (CPU total)=35323.80078125MB
INFO:root:[  104] Training loss: 0.66424219, Validation loss: 0.66560814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35570.0703125MB; mem (CPU total)=35362.21484375MB
INFO:root:[  105] Training loss: 0.66417714, Validation loss: 0.66590542, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35608.1640625MB; mem (CPU total)=35400.35546875MB
INFO:root:[  106] Training loss: 0.66395185, Validation loss: 0.66494394, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35646.26171875MB; mem (CPU total)=35438.4609375MB
INFO:root:[  107] Training loss: 0.66389602, Validation loss: 0.66497012, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35684.35546875MB; mem (CPU total)=35476.6015625MB
INFO:root:[  108] Training loss: 0.66393929, Validation loss: 0.66473117, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35722.44921875MB; mem (CPU total)=35514.125MB
INFO:root:[  109] Training loss: 0.66360377, Validation loss: 0.66543684, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35760.546875MB; mem (CPU total)=35552.26171875MB
INFO:root:[  110] Training loss: 0.66363626, Validation loss: 0.66482063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35798.640625MB; mem (CPU total)=35590.63671875MB
INFO:root:[  111] Training loss: 0.66355430, Validation loss: 0.66504507, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35836.734375MB; mem (CPU total)=35628.37890625MB
INFO:root:[  112] Training loss: 0.66321163, Validation loss: 0.66511893, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35874.83203125MB; mem (CPU total)=35666.2578125MB
INFO:root:[  113] Training loss: 0.66344832, Validation loss: 0.66557563, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35912.9296875MB; mem (CPU total)=35704.6328125MB
INFO:root:[  114] Training loss: 0.66310189, Validation loss: 0.66486076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35951.0234375MB; mem (CPU total)=35742.79296875MB
INFO:root:[  115] Training loss: 0.66276054, Validation loss: 0.66479183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35989.1171875MB; mem (CPU total)=35780.6875MB
INFO:root:[  116] Training loss: 0.66286163, Validation loss: 0.66553446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36027.21484375MB; mem (CPU total)=35819.078125MB
INFO:root:[  117] Training loss: 0.66261364, Validation loss: 0.66359141, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36065.30859375MB; mem (CPU total)=35857.1328125MB
INFO:root:[  118] Training loss: 0.66254652, Validation loss: 0.66475882, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36103.40234375MB; mem (CPU total)=35895.5390625MB
INFO:root:[  119] Training loss: 0.66235558, Validation loss: 0.66483236, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36141.5MB; mem (CPU total)=35933.88671875MB
INFO:root:[  120] Training loss: 0.66214395, Validation loss: 0.66464209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36179.59765625MB; mem (CPU total)=35971.80078125MB
INFO:root:[  121] Training loss: 0.66219268, Validation loss: 0.66427509, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36217.69140625MB; mem (CPU total)=36010.1953125MB
INFO:root:[  122] Training loss: 0.66163975, Validation loss: 0.66430785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36255.78515625MB; mem (CPU total)=36048.3359375MB
INFO:root:[  123] Training loss: 0.66176519, Validation loss: 0.66418015, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36293.8828125MB; mem (CPU total)=36086.48046875MB
INFO:root:[  124] Training loss: 0.66176760, Validation loss: 0.66423769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36331.9765625MB; mem (CPU total)=36124.60546875MB
INFO:root:[  125] Training loss: 0.66161067, Validation loss: 0.66410572, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36370.0703125MB; mem (CPU total)=36163.0MB
INFO:root:[  126] Training loss: 0.66153371, Validation loss: 0.66355736, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36408.16796875MB; mem (CPU total)=36201.06640625MB
INFO:root:[  127] Training loss: 0.66137210, Validation loss: 0.66398139, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36446.26171875MB; mem (CPU total)=36239.45703125MB
INFO:root:[  128] Training loss: 0.66120346, Validation loss: 0.66325211, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36484.35546875MB; mem (CPU total)=36277.36328125MB
INFO:root:[  129] Training loss: 0.66094578, Validation loss: 0.66359253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36522.44921875MB; mem (CPU total)=36315.8125MB
INFO:root:[  130] Training loss: 0.66099258, Validation loss: 0.66383845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36560.55078125MB; mem (CPU total)=36353.9453125MB
INFO:root:[  131] Training loss: 0.66090284, Validation loss: 0.66288113, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36598.64453125MB; mem (CPU total)=36392.12890625MB
INFO:root:[  132] Training loss: 0.66066012, Validation loss: 0.66294497, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36636.73828125MB; mem (CPU total)=36430.48046875MB
INFO:root:[  133] Training loss: 0.66069364, Validation loss: 0.66253099, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36674.8359375MB; mem (CPU total)=36468.06640625MB
INFO:root:[  134] Training loss: 0.66016759, Validation loss: 0.66126165, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36712.9296875MB; mem (CPU total)=36506.44921875MB
INFO:root:[  135] Training loss: 0.65978029, Validation loss: 0.66266116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36751.0234375MB; mem (CPU total)=36544.82421875MB
INFO:root:[  136] Training loss: 0.65969834, Validation loss: 0.66160891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36789.12109375MB; mem (CPU total)=36583.23046875MB
INFO:root:[  137] Training loss: 0.65935119, Validation loss: 0.66181254, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36827.21875MB; mem (CPU total)=36620.94140625MB
INFO:root:[  138] Training loss: 0.65957581, Validation loss: 0.66207703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36865.3125MB; mem (CPU total)=36659.11328125MB
INFO:root:[  139] Training loss: 0.65930644, Validation loss: 0.66124224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36903.40625MB; mem (CPU total)=36697.59765625MB
INFO:root:[  140] Training loss: 0.65903412, Validation loss: 0.66332994, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36941.50390625MB; mem (CPU total)=36736.01953125MB
INFO:root:[  141] Training loss: 0.65898060, Validation loss: 0.66112733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36979.59765625MB; mem (CPU total)=36774.0546875MB
INFO:root:[  142] Training loss: 0.65853595, Validation loss: 0.65983454, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37017.69140625MB; mem (CPU total)=36812.31640625MB
INFO:root:[  143] Training loss: 0.65856782, Validation loss: 0.65956514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37055.7890625MB; mem (CPU total)=36850.58203125MB
INFO:root:[  144] Training loss: 0.65821162, Validation loss: 0.65968006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37093.88671875MB; mem (CPU total)=36888.9609375MB
INFO:root:[  145] Training loss: 0.65813830, Validation loss: 0.65833390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37131.984375MB; mem (CPU total)=36927.13671875MB
INFO:root:[  146] Training loss: 0.65739778, Validation loss: 0.66066901, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37170.07421875MB; mem (CPU total)=36965.51953125MB
INFO:root:[  147] Training loss: 0.65736398, Validation loss: 0.66029809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37208.17578125MB; mem (CPU total)=37003.6484375MB
INFO:root:[  148] Training loss: 0.65743043, Validation loss: 0.65904605, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37246.26953125MB; mem (CPU total)=37040.96484375MB
INFO:root:[  149] Training loss: 0.65720743, Validation loss: 0.65834128, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37284.36328125MB; mem (CPU total)=37079.109375MB
INFO:root:[  150] Training loss: 0.65695467, Validation loss: 0.65938202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37322.4609375MB; mem (CPU total)=37117.5MB
INFO:root:[  151] Training loss: 0.65663725, Validation loss: 0.65807805, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37360.5546875MB; mem (CPU total)=37155.52734375MB
INFO:root:[  152] Training loss: 0.65714234, Validation loss: 0.65854017, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37398.6484375MB; mem (CPU total)=37194.15234375MB
INFO:root:[  153] Training loss: 0.65647557, Validation loss: 0.65885581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37436.75MB; mem (CPU total)=37233.10546875MB
INFO:root:[  154] Training loss: 0.65703877, Validation loss: 0.65865836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37474.84765625MB; mem (CPU total)=37270.80859375MB
INFO:root:[  155] Training loss: 0.65676856, Validation loss: 0.65772557, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37512.94140625MB; mem (CPU total)=37309.328125MB
INFO:root:[  156] Training loss: 0.65658420, Validation loss: 0.65814472, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37551.03515625MB; mem (CPU total)=37347.47265625MB
INFO:root:[  157] Training loss: 0.65636575, Validation loss: 0.65846813, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37589.1328125MB; mem (CPU total)=37385.89453125MB
INFO:root:[  158] Training loss: 0.65656902, Validation loss: 0.65836682, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37627.2265625MB; mem (CPU total)=37424.8671875MB
INFO:root:[  159] Training loss: 0.65577876, Validation loss: 0.65700185, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37665.3203125MB; mem (CPU total)=37463.37109375MB
INFO:root:[  160] Training loss: 0.65571734, Validation loss: 0.65790693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37703.41796875MB; mem (CPU total)=37501.42578125MB
INFO:root:[  161] Training loss: 0.65579849, Validation loss: 0.65760490, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37741.51171875MB; mem (CPU total)=37539.38671875MB
INFO:root:[  162] Training loss: 0.65567719, Validation loss: 0.65758504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37779.60546875MB; mem (CPU total)=37577.62890625MB
INFO:root:[  163] Training loss: 0.65546200, Validation loss: 0.65824835, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37817.703125MB; mem (CPU total)=37615.7578125MB
INFO:root:[  164] Training loss: 0.65554624, Validation loss: 0.65604646, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37855.80078125MB; mem (CPU total)=37654.26953125MB
INFO:root:[  165] Training loss: 0.65531495, Validation loss: 0.65768134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37893.89453125MB; mem (CPU total)=37692.890625MB
INFO:root:[  166] Training loss: 0.65561650, Validation loss: 0.65711020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37931.98828125MB; mem (CPU total)=37730.7890625MB
INFO:root:[  167] Training loss: 0.65542560, Validation loss: 0.65656206, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37970.0859375MB; mem (CPU total)=37768.90234375MB
INFO:root:[  168] Training loss: 0.65499014, Validation loss: 0.65720498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38008.1796875MB; mem (CPU total)=37807.046875MB
INFO:root:[  169] Training loss: 0.65492298, Validation loss: 0.65629343, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38046.2734375MB; mem (CPU total)=37844.8203125MB
INFO:root:[  170] Training loss: 0.65496608, Validation loss: 0.65689029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38084.37109375MB; mem (CPU total)=37883.24609375MB
INFO:root:[  171] Training loss: 0.65488782, Validation loss: 0.65633778, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38122.46875MB; mem (CPU total)=37920.8671875MB
INFO:root:[  172] Training loss: 0.65471789, Validation loss: 0.65720789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38160.5625MB; mem (CPU total)=37959.00390625MB
INFO:root:[  173] Training loss: 0.65479805, Validation loss: 0.65589283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38198.65625MB; mem (CPU total)=37997.45703125MB
INFO:root:[  174] Training loss: 0.65468224, Validation loss: 0.65725393, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38236.75390625MB; mem (CPU total)=38035.87890625MB
INFO:root:[  175] Training loss: 0.65472542, Validation loss: 0.65506089, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38274.84765625MB; mem (CPU total)=38073.59375MB
INFO:root:[  176] Training loss: 0.65431266, Validation loss: 0.65464402, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38312.94140625MB; mem (CPU total)=38112.30859375MB
INFO:root:[  177] Training loss: 0.65439131, Validation loss: 0.65889345, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38351.0390625MB; mem (CPU total)=38150.1953125MB
INFO:root:[  178] Training loss: 0.65429826, Validation loss: 0.65525620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38389.13671875MB; mem (CPU total)=38188.328125MB
INFO:root:[  179] Training loss: 0.65421421, Validation loss: 0.65527222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38427.23046875MB; mem (CPU total)=38226.33984375MB
INFO:root:[  180] Training loss: 0.65445194, Validation loss: 0.65729949, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38465.32421875MB; mem (CPU total)=38264.71875MB
INFO:root:[  181] Training loss: 0.65423809, Validation loss: 0.65550244, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38503.421875MB; mem (CPU total)=38302.8515625MB
INFO:root:[  182] Training loss: 0.65414887, Validation loss: 0.65588639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38541.515625MB; mem (CPU total)=38340.66796875MB
INFO:root:[  183] Training loss: 0.65364773, Validation loss: 0.65664071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38579.609375MB; mem (CPU total)=38378.80859375MB
INFO:root:[  184] Training loss: 0.65418154, Validation loss: 0.65520380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38617.70703125MB; mem (CPU total)=38417.19921875MB
INFO:root:[  185] Training loss: 0.65374782, Validation loss: 0.65587803, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38655.80078125MB; mem (CPU total)=38455.34375MB
INFO:root:EP 185: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=38693.8984375MB; mem (CPU total)=38493.71875MB
INFO:root:Training the model took 19245.091s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92802
INFO:root:EnergyScoreTrain: 0.65353
INFO:root:CRPSTrain: 0.59996
INFO:root:Gaussian NLLTrain: 1.94103
INFO:root:CoverageTrain: 0.80003
INFO:root:IntervalWidthTrain: 3.41421
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93122
INFO:root:EnergyScoreValidation: 0.65579
INFO:root:CRPSValidation: 0.60223
INFO:root:Gaussian NLLValidation: 1.94911
INFO:root:CoverageValidation: 0.79882
INFO:root:IntervalWidthValidation: 3.41375
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93026
INFO:root:EnergyScoreTest: 0.65513
INFO:root:CRPSTest: 0.60167
INFO:root:Gaussian NLLTest: 1.94704
INFO:root:CoverageTest: 0.79916
INFO:root:IntervalWidthTest: 3.41675
INFO:root:After validation: mem (CPU python)=38736.765625MB; mem (CPU total)=38536.6953125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=38736.765625MB; mem (CPU total)=38536.4140625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 165675008
INFO:root:After setting up the model: mem (CPU python)=38738.16015625MB; mem (CPU total)=38537.890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=38738.359375MB; mem (CPU total)=38537.61328125MB
INFO:root:[    1] Training loss: 0.78332356, Validation loss: 0.74787318, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38776.33984375MB; mem (CPU total)=38575.6875MB
INFO:root:[    2] Training loss: 0.72977818, Validation loss: 0.71908195, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38814.4375MB; mem (CPU total)=38612.84765625MB
INFO:root:[    3] Training loss: 0.71692075, Validation loss: 0.71141064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38852.53515625MB; mem (CPU total)=38651.0859375MB
INFO:root:[    4] Training loss: 0.71093783, Validation loss: 0.70390300, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38890.62890625MB; mem (CPU total)=38689.1484375MB
INFO:root:[    5] Training loss: 0.70533190, Validation loss: 0.70295693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38928.72265625MB; mem (CPU total)=38727.89453125MB
INFO:root:[    6] Training loss: 0.70407092, Validation loss: 0.70994314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38966.81640625MB; mem (CPU total)=38766.05859375MB
INFO:root:[    7] Training loss: 0.70266932, Validation loss: 0.70030085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39004.9140625MB; mem (CPU total)=38804.15625MB
INFO:root:[    8] Training loss: 0.70002817, Validation loss: 0.69947112, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39043.01171875MB; mem (CPU total)=38841.8671875MB
INFO:root:[    9] Training loss: 0.69836777, Validation loss: 0.69820276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39081.10546875MB; mem (CPU total)=38880.29296875MB
INFO:root:[   10] Training loss: 0.69723927, Validation loss: 0.69661955, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39119.203125MB; mem (CPU total)=38918.6328125MB
INFO:root:[   11] Training loss: 0.69616083, Validation loss: 0.69532321, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39157.296875MB; mem (CPU total)=38956.6875MB
INFO:root:[   12] Training loss: 0.69545413, Validation loss: 0.69617306, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39195.390625MB; mem (CPU total)=38995.109375MB
INFO:root:[   13] Training loss: 0.69402303, Validation loss: 0.69493174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39233.484375MB; mem (CPU total)=39033.19921875MB
INFO:root:[   14] Training loss: 0.69315385, Validation loss: 0.69335276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39271.58203125MB; mem (CPU total)=39071.63671875MB
INFO:root:[   15] Training loss: 0.69225673, Validation loss: 0.69232017, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39309.67578125MB; mem (CPU total)=39110.203125MB
INFO:root:[   16] Training loss: 0.69131192, Validation loss: 0.69110562, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39347.76953125MB; mem (CPU total)=39148.77734375MB
INFO:root:[   17] Training loss: 0.69053575, Validation loss: 0.69615819, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39385.87109375MB; mem (CPU total)=39186.65625MB
INFO:root:[   18] Training loss: 0.68991953, Validation loss: 0.69148438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39423.96484375MB; mem (CPU total)=39224.75390625MB
INFO:root:[   19] Training loss: 0.68926028, Validation loss: 0.68984682, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39462.05859375MB; mem (CPU total)=39263.23046875MB
INFO:root:[   20] Training loss: 0.68841611, Validation loss: 0.68887332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39500.15625MB; mem (CPU total)=39300.3359375MB
INFO:root:[   21] Training loss: 0.68783904, Validation loss: 0.68804621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39538.25MB; mem (CPU total)=39338.546875MB
INFO:root:[   22] Training loss: 0.68726884, Validation loss: 0.68813344, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39576.34375MB; mem (CPU total)=39376.3515625MB
INFO:root:[   23] Training loss: 0.68658439, Validation loss: 0.68754712, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39614.4375MB; mem (CPU total)=39414.515625MB
INFO:root:[   24] Training loss: 0.68579166, Validation loss: 0.68636131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39652.53515625MB; mem (CPU total)=39451.39453125MB
INFO:root:[   25] Training loss: 0.68471768, Validation loss: 0.68509071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39690.62890625MB; mem (CPU total)=39489.66796875MB
INFO:root:[   26] Training loss: 0.68386898, Validation loss: 0.68454810, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39728.7265625MB; mem (CPU total)=39528.01953125MB
INFO:root:[   27] Training loss: 0.68317179, Validation loss: 0.68399054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39766.82421875MB; mem (CPU total)=39565.84765625MB
INFO:root:[   28] Training loss: 0.68253627, Validation loss: 0.68332785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39804.91796875MB; mem (CPU total)=39603.0859375MB
INFO:root:[   29] Training loss: 0.68197952, Validation loss: 0.68309354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39843.01171875MB; mem (CPU total)=39641.6875MB
INFO:root:[   30] Training loss: 0.68128297, Validation loss: 0.68218624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39881.10546875MB; mem (CPU total)=39680.0234375MB
INFO:root:[   31] Training loss: 0.68094860, Validation loss: 0.68140276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39919.203125MB; mem (CPU total)=39717.54296875MB
INFO:root:[   32] Training loss: 0.68029632, Validation loss: 0.68055170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39957.296875MB; mem (CPU total)=39756.546875MB
INFO:root:[   33] Training loss: 0.67937962, Validation loss: 0.68053909, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39995.390625MB; mem (CPU total)=39794.7578125MB
INFO:root:[   34] Training loss: 0.67837567, Validation loss: 0.67918368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40033.4921875MB; mem (CPU total)=39833.0234375MB
INFO:root:[   35] Training loss: 0.67747571, Validation loss: 0.67707970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40071.5859375MB; mem (CPU total)=39872.0703125MB
INFO:root:[   36] Training loss: 0.67592211, Validation loss: 0.67493493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40109.6796875MB; mem (CPU total)=39910.17578125MB
INFO:root:[   37] Training loss: 0.67431197, Validation loss: 0.67373916, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40147.77734375MB; mem (CPU total)=39948.18359375MB
INFO:root:[   38] Training loss: 0.67254065, Validation loss: 0.67350192, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40185.87109375MB; mem (CPU total)=39986.109375MB
INFO:root:[   39] Training loss: 0.67197441, Validation loss: 0.67103125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40223.96484375MB; mem (CPU total)=40024.60546875MB
INFO:root:[   40] Training loss: 0.67059927, Validation loss: 0.67089357, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40262.05859375MB; mem (CPU total)=40063.0390625MB
INFO:root:[   41] Training loss: 0.66983160, Validation loss: 0.67031893, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40300.15625MB; mem (CPU total)=40101.33203125MB
INFO:root:[   42] Training loss: 0.66843382, Validation loss: 0.66872702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40338.25MB; mem (CPU total)=40139.75MB
INFO:root:[   43] Training loss: 0.66796437, Validation loss: 0.66867526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40376.34765625MB; mem (CPU total)=40177.4765625MB
INFO:root:[   44] Training loss: 0.66766096, Validation loss: 0.66855988, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40414.4453125MB; mem (CPU total)=40215.43359375MB
INFO:root:[   45] Training loss: 0.66713716, Validation loss: 0.66824454, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40452.5390625MB; mem (CPU total)=40253.83984375MB
INFO:root:[   46] Training loss: 0.66605617, Validation loss: 0.66694164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40490.6328125MB; mem (CPU total)=40292.05859375MB
INFO:root:[   47] Training loss: 0.66615984, Validation loss: 0.66596919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40528.7265625MB; mem (CPU total)=40330.23046875MB
INFO:root:[   48] Training loss: 0.66581766, Validation loss: 0.66656690, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40566.82421875MB; mem (CPU total)=40368.65234375MB
INFO:root:[   49] Training loss: 0.66525859, Validation loss: 0.66629986, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40604.921875MB; mem (CPU total)=40406.7421875MB
INFO:root:[   50] Training loss: 0.66528538, Validation loss: 0.66795932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40643.015625MB; mem (CPU total)=40444.62890625MB
INFO:root:[   51] Training loss: 0.66433098, Validation loss: 0.66524010, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40681.11328125MB; mem (CPU total)=40483.08203125MB
INFO:root:[   52] Training loss: 0.66438936, Validation loss: 0.66680708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40719.2109375MB; mem (CPU total)=40521.30078125MB
INFO:root:[   53] Training loss: 0.66378307, Validation loss: 0.66594771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40757.3046875MB; mem (CPU total)=40559.015625MB
INFO:root:[   54] Training loss: 0.66364775, Validation loss: 0.66434680, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40795.40234375MB; mem (CPU total)=40597.28125MB
INFO:root:[   55] Training loss: 0.66343812, Validation loss: 0.66348665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40833.4921875MB; mem (CPU total)=40636.28125MB
INFO:root:[   56] Training loss: 0.66341289, Validation loss: 0.66407699, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40871.58984375MB; mem (CPU total)=40674.21484375MB
INFO:root:[   57] Training loss: 0.66334397, Validation loss: 0.66387679, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40909.68359375MB; mem (CPU total)=40712.5859375MB
INFO:root:[   58] Training loss: 0.66284556, Validation loss: 0.66318602, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40947.78125MB; mem (CPU total)=40750.859375MB
INFO:root:[   59] Training loss: 0.66207327, Validation loss: 0.66278836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40985.87890625MB; mem (CPU total)=40788.9765625MB
INFO:root:[   60] Training loss: 0.66210891, Validation loss: 0.66300594, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41023.97265625MB; mem (CPU total)=40826.96484375MB
INFO:root:[   61] Training loss: 0.66258245, Validation loss: 0.66248171, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41062.0703125MB; mem (CPU total)=40865.2890625MB
INFO:root:[   62] Training loss: 0.66225896, Validation loss: 0.66317905, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41100.1640625MB; mem (CPU total)=40903.12890625MB
INFO:root:[   63] Training loss: 0.66225527, Validation loss: 0.66330325, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41138.2578125MB; mem (CPU total)=40941.2734375MB
INFO:root:[   64] Training loss: 0.66181132, Validation loss: 0.66305612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41176.3515625MB; mem (CPU total)=40978.8203125MB
INFO:root:[   65] Training loss: 0.66179775, Validation loss: 0.66240984, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41214.44921875MB; mem (CPU total)=41016.57421875MB
INFO:root:[   66] Training loss: 0.66164911, Validation loss: 0.66121409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41252.54296875MB; mem (CPU total)=41054.453125MB
INFO:root:[   67] Training loss: 0.66124119, Validation loss: 0.66161945, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41290.63671875MB; mem (CPU total)=41092.875MB
INFO:root:[   68] Training loss: 0.66126469, Validation loss: 0.66189946, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41328.734375MB; mem (CPU total)=41130.80078125MB
INFO:root:[   69] Training loss: 0.66088214, Validation loss: 0.66159662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41366.83203125MB; mem (CPU total)=41169.08984375MB
INFO:root:[   70] Training loss: 0.66064875, Validation loss: 0.66112786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41404.92578125MB; mem (CPU total)=41207.34375MB
INFO:root:[   71] Training loss: 0.66056380, Validation loss: 0.66200496, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41443.0234375MB; mem (CPU total)=41245.7421875MB
INFO:root:[   72] Training loss: 0.66070118, Validation loss: 0.66202788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41481.1171875MB; mem (CPU total)=41284.125MB
INFO:root:[   73] Training loss: 0.66021974, Validation loss: 0.66199735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41519.2109375MB; mem (CPU total)=41322.18359375MB
INFO:root:[   74] Training loss: 0.66054166, Validation loss: 0.66164074, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41557.3046875MB; mem (CPU total)=41360.08203125MB
INFO:root:[   75] Training loss: 0.66057727, Validation loss: 0.66089526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41595.40625MB; mem (CPU total)=41398.609375MB
INFO:root:[   76] Training loss: 0.65991114, Validation loss: 0.66140270, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41633.5MB; mem (CPU total)=41436.84375MB
INFO:root:[   77] Training loss: 0.66004822, Validation loss: 0.65999086, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41671.59375MB; mem (CPU total)=41474.3046875MB
INFO:root:[   78] Training loss: 0.65978335, Validation loss: 0.66000716, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41709.69140625MB; mem (CPU total)=41512.44921875MB
INFO:root:[   79] Training loss: 0.65957859, Validation loss: 0.66090465, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41747.78515625MB; mem (CPU total)=41550.58984375MB
INFO:root:[   80] Training loss: 0.65932602, Validation loss: 0.66089900, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41785.87890625MB; mem (CPU total)=41588.59375MB
INFO:root:[   81] Training loss: 0.66004420, Validation loss: 0.65994403, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41823.97265625MB; mem (CPU total)=41626.796875MB
INFO:root:[   82] Training loss: 0.65949366, Validation loss: 0.66049282, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41862.07421875MB; mem (CPU total)=41665.23828125MB
INFO:root:[   83] Training loss: 0.65974359, Validation loss: 0.66235195, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41900.16796875MB; mem (CPU total)=41703.3828125MB
INFO:root:[   84] Training loss: 0.65918703, Validation loss: 0.66015410, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41938.26171875MB; mem (CPU total)=41741.63671875MB
INFO:root:[   85] Training loss: 0.65918433, Validation loss: 0.65963680, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41976.359375MB; mem (CPU total)=41779.56640625MB
INFO:root:[   86] Training loss: 0.65939337, Validation loss: 0.66052837, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42014.453125MB; mem (CPU total)=41816.94140625MB
INFO:root:[   87] Training loss: 0.65853595, Validation loss: 0.65984315, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42052.546875MB; mem (CPU total)=41855.03515625MB
INFO:root:[   88] Training loss: 0.65878747, Validation loss: 0.65954404, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42090.64453125MB; mem (CPU total)=41893.37890625MB
INFO:root:[   89] Training loss: 0.65885745, Validation loss: 0.66195970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42128.73828125MB; mem (CPU total)=41931.5546875MB
INFO:root:[   90] Training loss: 0.65928835, Validation loss: 0.65890804, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42166.83203125MB; mem (CPU total)=41969.8671875MB
INFO:root:[   91] Training loss: 0.65893637, Validation loss: 0.66090028, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42204.92578125MB; mem (CPU total)=42007.921875MB
INFO:root:[   92] Training loss: 0.65824687, Validation loss: 0.66082147, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42243.02734375MB; mem (CPU total)=42046.6328125MB
INFO:root:[   93] Training loss: 0.65851246, Validation loss: 0.65984111, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42281.12109375MB; mem (CPU total)=42084.359375MB
INFO:root:[   94] Training loss: 0.65912002, Validation loss: 0.65972906, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42319.21484375MB; mem (CPU total)=42122.390625MB
INFO:root:[   95] Training loss: 0.65843841, Validation loss: 0.66031585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42357.3125MB; mem (CPU total)=42160.53515625MB
INFO:root:[   96] Training loss: 0.65790695, Validation loss: 0.66009841, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42395.40625MB; mem (CPU total)=42198.9140625MB
INFO:root:[   97] Training loss: 0.65828675, Validation loss: 0.65974642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42433.5MB; mem (CPU total)=42237.27734375MB
INFO:root:[   98] Training loss: 0.65793157, Validation loss: 0.65915401, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42471.59375MB; mem (CPU total)=42276.07421875MB
INFO:root:[   99] Training loss: 0.65777065, Validation loss: 0.65899987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42509.69140625MB; mem (CPU total)=42314.19921875MB
INFO:root:[  100] Training loss: 0.65762488, Validation loss: 0.65871908, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42547.78515625MB; mem (CPU total)=42351.7890625MB
INFO:root:[  101] Training loss: 0.65731618, Validation loss: 0.65911303, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42585.8828125MB; mem (CPU total)=42390.37890625MB
INFO:root:[  102] Training loss: 0.65756224, Validation loss: 0.66020796, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42623.98046875MB; mem (CPU total)=42428.51953125MB
INFO:root:[  103] Training loss: 0.65763236, Validation loss: 0.65785075, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42662.07421875MB; mem (CPU total)=42466.76953125MB
INFO:root:[  104] Training loss: 0.65728924, Validation loss: 0.65848843, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42700.16796875MB; mem (CPU total)=42504.9140625MB
INFO:root:[  105] Training loss: 0.65748525, Validation loss: 0.65944663, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42738.265625MB; mem (CPU total)=42542.82421875MB
INFO:root:[  106] Training loss: 0.65682457, Validation loss: 0.65800752, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42776.359375MB; mem (CPU total)=42580.859375MB
INFO:root:[  107] Training loss: 0.65676294, Validation loss: 0.65902796, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42814.453125MB; mem (CPU total)=42618.98828125MB
INFO:root:[  108] Training loss: 0.65769403, Validation loss: 0.65945094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42852.546875MB; mem (CPU total)=42657.66015625MB
INFO:root:[  109] Training loss: 0.65694515, Validation loss: 0.65719987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42890.6484375MB; mem (CPU total)=42695.83203125MB
INFO:root:[  110] Training loss: 0.65701066, Validation loss: 0.65900983, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42928.7421875MB; mem (CPU total)=42734.24609375MB
INFO:root:[  111] Training loss: 0.65729013, Validation loss: 0.65832197, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42966.8359375MB; mem (CPU total)=42772.3828125MB
INFO:root:[  112] Training loss: 0.65694557, Validation loss: 0.65805664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43004.93359375MB; mem (CPU total)=42810.1796875MB
INFO:root:[  113] Training loss: 0.65694196, Validation loss: 0.65713448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43043.02734375MB; mem (CPU total)=42848.2421875MB
INFO:root:[  114] Training loss: 0.65691195, Validation loss: 0.65896094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43081.12109375MB; mem (CPU total)=42886.59765625MB
INFO:root:[  115] Training loss: 0.65727250, Validation loss: 0.65768638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43119.21484375MB; mem (CPU total)=42924.71875MB
INFO:root:[  116] Training loss: 0.65714319, Validation loss: 0.65806078, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43157.3125MB; mem (CPU total)=42962.80078125MB
INFO:root:[  117] Training loss: 0.65622017, Validation loss: 0.65876074, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43195.40625MB; mem (CPU total)=43000.67578125MB
INFO:root:[  118] Training loss: 0.65663324, Validation loss: 0.65776330, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43233.50390625MB; mem (CPU total)=43038.8125MB
INFO:root:[  119] Training loss: 0.65649241, Validation loss: 0.65727507, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43271.6015625MB; mem (CPU total)=43077.1484375MB
INFO:root:[  120] Training loss: 0.65630489, Validation loss: 0.65665141, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43309.6953125MB; mem (CPU total)=43114.83984375MB
INFO:root:[  121] Training loss: 0.65646611, Validation loss: 0.65801798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43347.7890625MB; mem (CPU total)=43152.984375MB
INFO:root:[  122] Training loss: 0.65613125, Validation loss: 0.65756225, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43385.88671875MB; mem (CPU total)=43191.15234375MB
INFO:root:[  123] Training loss: 0.65624637, Validation loss: 0.65802325, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43423.98046875MB; mem (CPU total)=43229.50390625MB
INFO:root:[  124] Training loss: 0.65583848, Validation loss: 0.65827761, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43462.07421875MB; mem (CPU total)=43268.1171875MB
INFO:root:[  125] Training loss: 0.65606649, Validation loss: 0.65745670, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43500.16796875MB; mem (CPU total)=43306.4453125MB
INFO:root:[  126] Training loss: 0.65543683, Validation loss: 0.65663218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43538.265625MB; mem (CPU total)=43344.859375MB
INFO:root:[  127] Training loss: 0.65614915, Validation loss: 0.65649512, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43576.36328125MB; mem (CPU total)=43383.4609375MB
INFO:root:[  128] Training loss: 0.65598726, Validation loss: 0.65733564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43614.453125MB; mem (CPU total)=43421.58203125MB
INFO:root:[  129] Training loss: 0.65594929, Validation loss: 0.65727661, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43652.5546875MB; mem (CPU total)=43459.796875MB
INFO:root:[  130] Training loss: 0.65586245, Validation loss: 0.65732623, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43690.6484375MB; mem (CPU total)=43497.765625MB
INFO:root:[  131] Training loss: 0.65559250, Validation loss: 0.65678176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43728.7421875MB; mem (CPU total)=43535.6640625MB
INFO:root:[  132] Training loss: 0.65535192, Validation loss: 0.65688031, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43766.8359375MB; mem (CPU total)=43574.09375MB
INFO:root:[  133] Training loss: 0.65555634, Validation loss: 0.65652991, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43804.93359375MB; mem (CPU total)=43611.9609375MB
INFO:root:[  134] Training loss: 0.65523035, Validation loss: 0.65583937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43843.02734375MB; mem (CPU total)=43650.18359375MB
INFO:root:[  135] Training loss: 0.65535120, Validation loss: 0.65714941, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43881.12109375MB; mem (CPU total)=43687.5MB
INFO:root:[  136] Training loss: 0.65522984, Validation loss: 0.65615985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43919.22265625MB; mem (CPU total)=43725.3984375MB
INFO:root:[  137] Training loss: 0.65522322, Validation loss: 0.65717133, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43957.31640625MB; mem (CPU total)=43763.48046875MB
INFO:root:[  138] Training loss: 0.65550268, Validation loss: 0.65689395, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43995.41015625MB; mem (CPU total)=43801.37109375MB
INFO:root:[  139] Training loss: 0.65481591, Validation loss: 0.65695769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44033.5078125MB; mem (CPU total)=43839.25390625MB
INFO:root:[  140] Training loss: 0.65482802, Validation loss: 0.65741879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44071.6015625MB; mem (CPU total)=43878.078125MB
INFO:root:[  141] Training loss: 0.65497220, Validation loss: 0.65555055, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44109.69921875MB; mem (CPU total)=43915.77734375MB
INFO:root:[  142] Training loss: 0.65524013, Validation loss: 0.65565132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44147.7890625MB; mem (CPU total)=43953.67578125MB
INFO:root:[  143] Training loss: 0.65462812, Validation loss: 0.65695025, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44185.890625MB; mem (CPU total)=43991.8203125MB
INFO:root:[  144] Training loss: 0.65458982, Validation loss: 0.65713216, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44223.984375MB; mem (CPU total)=44029.88671875MB
INFO:root:[  145] Training loss: 0.65489212, Validation loss: 0.65642380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44262.078125MB; mem (CPU total)=44067.96875MB
INFO:root:[  146] Training loss: 0.65476803, Validation loss: 0.65548703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44300.17578125MB; mem (CPU total)=44106.390625MB
INFO:root:[  147] Training loss: 0.65429081, Validation loss: 0.65542707, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44338.26953125MB; mem (CPU total)=44144.3359375MB
INFO:root:[  148] Training loss: 0.65448006, Validation loss: 0.65655555, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44376.36328125MB; mem (CPU total)=44182.7265625MB
INFO:root:[  149] Training loss: 0.65460001, Validation loss: 0.65561609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44414.4609375MB; mem (CPU total)=44220.83203125MB
INFO:root:[  150] Training loss: 0.65445471, Validation loss: 0.65617990, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44452.55859375MB; mem (CPU total)=44258.8828125MB
INFO:root:[  151] Training loss: 0.65501968, Validation loss: 0.65533842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44490.65234375MB; mem (CPU total)=44297.0546875MB
INFO:root:[  152] Training loss: 0.65415923, Validation loss: 0.65674459, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44528.74609375MB; mem (CPU total)=44335.15234375MB
INFO:root:[  153] Training loss: 0.65434681, Validation loss: 0.65577531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44566.84375MB; mem (CPU total)=44373.2890625MB
INFO:root:[  154] Training loss: 0.65356638, Validation loss: 0.65551380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44604.9375MB; mem (CPU total)=44411.32421875MB
INFO:root:[  155] Training loss: 0.65395550, Validation loss: 0.65543870, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44643.03125MB; mem (CPU total)=44449.75390625MB
INFO:root:[  156] Training loss: 0.65380552, Validation loss: 0.65600388, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44681.12890625MB; mem (CPU total)=44487.78125MB
INFO:root:[  157] Training loss: 0.65404294, Validation loss: 0.65665507, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44719.22265625MB; mem (CPU total)=44525.8828125MB
INFO:root:[  158] Training loss: 0.65340559, Validation loss: 0.65555177, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44757.31640625MB; mem (CPU total)=44564.02734375MB
INFO:root:[  159] Training loss: 0.65362645, Validation loss: 0.65457094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44795.41015625MB; mem (CPU total)=44606.31640625MB
INFO:root:[  160] Training loss: 0.65409021, Validation loss: 0.65635407, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44833.51171875MB; mem (CPU total)=44644.73046875MB
INFO:root:[  161] Training loss: 0.65427655, Validation loss: 0.65432770, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44871.60546875MB; mem (CPU total)=44682.68359375MB
INFO:root:[  162] Training loss: 0.65362481, Validation loss: 0.65523714, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44909.69921875MB; mem (CPU total)=44721.06640625MB
INFO:root:[  163] Training loss: 0.65410160, Validation loss: 0.65498819, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44947.796875MB; mem (CPU total)=44759.2265625MB
INFO:root:[  164] Training loss: 0.65361783, Validation loss: 0.65528183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44985.890625MB; mem (CPU total)=44796.8125MB
INFO:root:[  165] Training loss: 0.65343280, Validation loss: 0.65502552, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45023.98828125MB; mem (CPU total)=44834.37109375MB
INFO:root:[  166] Training loss: 0.65309229, Validation loss: 0.65519288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45062.0859375MB; mem (CPU total)=44872.28515625MB
INFO:root:[  167] Training loss: 0.65310174, Validation loss: 0.65505143, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45100.18359375MB; mem (CPU total)=44910.17578125MB
INFO:root:[  168] Training loss: 0.65298066, Validation loss: 0.65432717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45138.27734375MB; mem (CPU total)=44948.92578125MB
INFO:root:[  169] Training loss: 0.65307485, Validation loss: 0.65524596, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45176.37109375MB; mem (CPU total)=44987.0703125MB
INFO:root:[  170] Training loss: 0.65283014, Validation loss: 0.65482540, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45214.46875MB; mem (CPU total)=45025.41015625MB
INFO:root:[  171] Training loss: 0.65286944, Validation loss: 0.65403601, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45252.5625MB; mem (CPU total)=45063.484375MB
INFO:root:[  172] Training loss: 0.65317747, Validation loss: 0.65467019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45290.65625MB; mem (CPU total)=45101.875MB
INFO:root:[  173] Training loss: 0.65275049, Validation loss: 0.65492092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45328.75390625MB; mem (CPU total)=45140.2578125MB
INFO:root:[  174] Training loss: 0.65266701, Validation loss: 0.65396921, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45366.84765625MB; mem (CPU total)=45178.109375MB
INFO:root:[  175] Training loss: 0.65276458, Validation loss: 0.65485294, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45404.94140625MB; mem (CPU total)=45215.75390625MB
INFO:root:[  176] Training loss: 0.65252214, Validation loss: 0.65451160, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45443.03515625MB; mem (CPU total)=45254.16796875MB
INFO:root:[  177] Training loss: 0.65265399, Validation loss: 0.65420275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45481.1328125MB; mem (CPU total)=45292.10546875MB
INFO:root:[  178] Training loss: 0.65267844, Validation loss: 0.65317096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45519.23046875MB; mem (CPU total)=45330.3125MB
INFO:root:[  179] Training loss: 0.65215312, Validation loss: 0.65460777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45557.32421875MB; mem (CPU total)=45368.453125MB
INFO:root:[  180] Training loss: 0.65240324, Validation loss: 0.65353493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45595.42578125MB; mem (CPU total)=45406.3515625MB
INFO:root:[  181] Training loss: 0.65228015, Validation loss: 0.65406049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45633.52734375MB; mem (CPU total)=45444.96484375MB
INFO:root:[  182] Training loss: 0.65229199, Validation loss: 0.65277786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45671.62109375MB; mem (CPU total)=45483.07421875MB
INFO:root:[  183] Training loss: 0.65203842, Validation loss: 0.65435772, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45709.71484375MB; mem (CPU total)=45521.46484375MB
INFO:root:[  184] Training loss: 0.65258306, Validation loss: 0.65599770, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45747.8125MB; mem (CPU total)=45559.59375MB
INFO:root:[  185] Training loss: 0.65184349, Validation loss: 0.65382395, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45785.90625MB; mem (CPU total)=45597.41796875MB
INFO:root:[  186] Training loss: 0.65245140, Validation loss: 0.65389445, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45824.0MB; mem (CPU total)=45635.5625MB
INFO:root:[  187] Training loss: 0.65206391, Validation loss: 0.65442535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45862.09765625MB; mem (CPU total)=45674.46875MB
INFO:root:[  188] Training loss: 0.65211669, Validation loss: 0.65335851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45900.19140625MB; mem (CPU total)=45712.390625MB
INFO:root:[  189] Training loss: 0.65182782, Validation loss: 0.65432528, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45938.28515625MB; mem (CPU total)=45750.2890625MB
INFO:root:[  190] Training loss: 0.65180162, Validation loss: 0.65253891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45976.3828125MB; mem (CPU total)=45788.03515625MB
INFO:root:[  191] Training loss: 0.65145238, Validation loss: 0.65334851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46014.48046875MB; mem (CPU total)=45826.51953125MB
INFO:root:[  192] Training loss: 0.65168150, Validation loss: 0.65337930, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46052.57421875MB; mem (CPU total)=45864.94921875MB
INFO:root:[  193] Training loss: 0.65218088, Validation loss: 0.65250645, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46090.66796875MB; mem (CPU total)=45903.37109375MB
INFO:root:[  194] Training loss: 0.65158248, Validation loss: 0.65355184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46128.765625MB; mem (CPU total)=45941.33203125MB
INFO:root:[  195] Training loss: 0.65164529, Validation loss: 0.65376811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46166.859375MB; mem (CPU total)=45979.46875MB
INFO:root:[  196] Training loss: 0.65179469, Validation loss: 0.65492776, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46204.953125MB; mem (CPU total)=46017.29296875MB
INFO:root:[  197] Training loss: 0.65182865, Validation loss: 0.65361372, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46243.05078125MB; mem (CPU total)=46055.74609375MB
INFO:root:[  198] Training loss: 0.65143710, Validation loss: 0.65383387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46281.14453125MB; mem (CPU total)=46093.8828125MB
INFO:root:[  199] Training loss: 0.65114629, Validation loss: 0.65346684, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46319.2421875MB; mem (CPU total)=46131.75MB
INFO:root:[  200] Training loss: 0.65127036, Validation loss: 0.65303758, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46357.3359375MB; mem (CPU total)=46169.890625MB
INFO:root:[  201] Training loss: 0.65136157, Validation loss: 0.65286809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46395.43359375MB; mem (CPU total)=46208.25390625MB
INFO:root:[  202] Training loss: 0.65136843, Validation loss: 0.65300518, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46433.52734375MB; mem (CPU total)=46246.59375MB
INFO:root:EP 202: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=46471.62109375MB; mem (CPU total)=46284.484375MB
INFO:root:Training the model took 22882.356s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92402
INFO:root:EnergyScoreTrain: 0.65088
INFO:root:CRPSTrain: 0.59722
INFO:root:Gaussian NLLTrain: 2.25388
INFO:root:CoverageTrain: 0.75082
INFO:root:IntervalWidthTrain: 3.30324
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.92694
INFO:root:EnergyScoreValidation: 0.65293
INFO:root:CRPSValidation: 0.59922
INFO:root:Gaussian NLLValidation: 2.26351
INFO:root:CoverageValidation: 0.74994
INFO:root:IntervalWidthValidation: 3.30239
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.92704
INFO:root:EnergyScoreTest: 0.65298
INFO:root:CRPSTest: 0.59927
INFO:root:Gaussian NLLTest: 2.26011
INFO:root:CoverageTest: 0.75032
INFO:root:IntervalWidthTest: 3.30334
INFO:root:After validation: mem (CPU python)=46514.48046875MB; mem (CPU total)=46328.140625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=46514.48046875MB; mem (CPU total)=46329.765625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 165675008
INFO:root:After setting up the model: mem (CPU python)=46514.55078125MB; mem (CPU total)=46329.765625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=46514.55078125MB; mem (CPU total)=46329.78125MB
INFO:root:[    1] Training loss: 0.77966369, Validation loss: 0.73957211, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46552.58203125MB; mem (CPU total)=46368.03515625MB
INFO:root:[    2] Training loss: 0.72722876, Validation loss: 0.71843620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46590.67578125MB; mem (CPU total)=46404.39453125MB
INFO:root:[    3] Training loss: 0.71505336, Validation loss: 0.71051005, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46628.7734375MB; mem (CPU total)=46441.48046875MB
INFO:root:[    4] Training loss: 0.71003892, Validation loss: 0.70297993, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46666.8671875MB; mem (CPU total)=46479.39453125MB
INFO:root:[    5] Training loss: 0.70328630, Validation loss: 0.70138111, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46704.96484375MB; mem (CPU total)=46517.6171875MB
INFO:root:[    6] Training loss: 0.69911615, Validation loss: 0.69897514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46743.05859375MB; mem (CPU total)=46555.97265625MB
INFO:root:[    7] Training loss: 0.69590300, Validation loss: 0.69747862, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46781.15625MB; mem (CPU total)=46594.41015625MB
INFO:root:[    8] Training loss: 0.69440485, Validation loss: 0.69194923, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46819.25MB; mem (CPU total)=46632.34765625MB
INFO:root:[    9] Training loss: 0.69137143, Validation loss: 0.69083560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46857.34375MB; mem (CPU total)=46670.51171875MB
INFO:root:[   10] Training loss: 0.69172225, Validation loss: 0.68973205, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46895.44140625MB; mem (CPU total)=46708.2734375MB
INFO:root:[   11] Training loss: 0.68887127, Validation loss: 0.69099172, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46933.53515625MB; mem (CPU total)=46746.65625MB
INFO:root:[   12] Training loss: 0.68781814, Validation loss: 0.68844740, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46971.62890625MB; mem (CPU total)=46784.3828125MB
INFO:root:[   13] Training loss: 0.68734705, Validation loss: 0.68742214, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47009.73046875MB; mem (CPU total)=46822.6953125MB
INFO:root:[   14] Training loss: 0.68638656, Validation loss: 0.68639934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47047.82421875MB; mem (CPU total)=46861.1953125MB
INFO:root:[   15] Training loss: 0.68560422, Validation loss: 0.68665510, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47085.9140625MB; mem (CPU total)=46899.69921875MB
INFO:root:[   16] Training loss: 0.68487774, Validation loss: 0.68587533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47124.01171875MB; mem (CPU total)=46937.96875MB
INFO:root:[   17] Training loss: 0.68407850, Validation loss: 0.68491832, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47162.109375MB; mem (CPU total)=46976.16015625MB
INFO:root:[   18] Training loss: 0.68356344, Validation loss: 0.68462199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47200.203125MB; mem (CPU total)=47014.15625MB
INFO:root:[   19] Training loss: 0.68281108, Validation loss: 0.68363432, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47238.296875MB; mem (CPU total)=47052.68359375MB
INFO:root:[   20] Training loss: 0.68213993, Validation loss: 0.68431216, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47276.39453125MB; mem (CPU total)=47091.3203125MB
INFO:root:[   21] Training loss: 0.68144840, Validation loss: 0.68214060, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47314.48828125MB; mem (CPU total)=47129.01953125MB
INFO:root:[   22] Training loss: 0.68104058, Validation loss: 0.68258630, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47352.58203125MB; mem (CPU total)=47167.40234375MB
INFO:root:[   23] Training loss: 0.68093090, Validation loss: 0.68118265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47390.6796875MB; mem (CPU total)=47205.3671875MB
INFO:root:[   24] Training loss: 0.68032189, Validation loss: 0.68143446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47428.77734375MB; mem (CPU total)=47244.06640625MB
INFO:root:[   25] Training loss: 0.67990606, Validation loss: 0.68087620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47466.87109375MB; mem (CPU total)=47282.08984375MB
INFO:root:[   26] Training loss: 0.67954678, Validation loss: 0.68094146, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47504.96484375MB; mem (CPU total)=47320.6953125MB
INFO:root:[   27] Training loss: 0.67903404, Validation loss: 0.67997992, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47543.0625MB; mem (CPU total)=47358.46875MB
INFO:root:[   28] Training loss: 0.67873484, Validation loss: 0.67980904, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47581.15625MB; mem (CPU total)=47395.84375MB
INFO:root:[   29] Training loss: 0.67829268, Validation loss: 0.68054513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47619.25MB; mem (CPU total)=47434.015625MB
INFO:root:[   30] Training loss: 0.67779590, Validation loss: 0.67934962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47657.34765625MB; mem (CPU total)=47472.62890625MB
INFO:root:[   31] Training loss: 0.67722211, Validation loss: 0.67884531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47695.44140625MB; mem (CPU total)=47510.00390625MB
INFO:root:[   32] Training loss: 0.67663775, Validation loss: 0.67822876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47733.5390625MB; mem (CPU total)=47547.5234375MB
INFO:root:[   33] Training loss: 0.67644298, Validation loss: 0.67679029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47771.6328125MB; mem (CPU total)=47585.8046875MB
INFO:root:[   34] Training loss: 0.67592361, Validation loss: 0.67676089, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47809.73046875MB; mem (CPU total)=47624.3828125MB
INFO:root:[   35] Training loss: 0.67560196, Validation loss: 0.67633987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47847.82421875MB; mem (CPU total)=47662.5234375MB
INFO:root:[   36] Training loss: 0.67530795, Validation loss: 0.67604702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47885.91796875MB; mem (CPU total)=47700.9140625MB
INFO:root:[   37] Training loss: 0.67517867, Validation loss: 0.67585180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47924.015625MB; mem (CPU total)=47738.828125MB
INFO:root:[   38] Training loss: 0.67467981, Validation loss: 0.67536915, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47962.109375MB; mem (CPU total)=47776.93359375MB
INFO:root:[   39] Training loss: 0.67435467, Validation loss: 0.67564780, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48000.203125MB; mem (CPU total)=47815.0546875MB
INFO:root:[   40] Training loss: 0.67409243, Validation loss: 0.67481330, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48038.30078125MB; mem (CPU total)=47853.4921875MB
INFO:root:[   41] Training loss: 0.67356011, Validation loss: 0.67391964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48076.3984375MB; mem (CPU total)=47892.5859375MB
INFO:root:[   42] Training loss: 0.67343692, Validation loss: 0.67422316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48114.4921875MB; mem (CPU total)=47930.5234375MB
INFO:root:[   43] Training loss: 0.67321925, Validation loss: 0.67353134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48152.5859375MB; mem (CPU total)=47969.203125MB
INFO:root:[   44] Training loss: 0.67288819, Validation loss: 0.67412004, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48190.68359375MB; mem (CPU total)=48007.63671875MB
INFO:root:[   45] Training loss: 0.67267562, Validation loss: 0.67367401, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48228.77734375MB; mem (CPU total)=48046.09375MB
INFO:root:[   46] Training loss: 0.67232629, Validation loss: 0.67348088, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48266.87109375MB; mem (CPU total)=48083.6328125MB
INFO:root:[   47] Training loss: 0.67181750, Validation loss: 0.67218604, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48304.96875MB; mem (CPU total)=48121.5234375MB
INFO:root:[   48] Training loss: 0.67124845, Validation loss: 0.67086862, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48343.06640625MB; mem (CPU total)=48160.0703125MB
INFO:root:[   49] Training loss: 0.67037904, Validation loss: 0.67090657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48381.16015625MB; mem (CPU total)=48198.55078125MB
INFO:root:[   50] Training loss: 0.66949398, Validation loss: 0.67053632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48419.25390625MB; mem (CPU total)=48235.57421875MB
INFO:root:[   51] Training loss: 0.66823936, Validation loss: 0.66993812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48457.3515625MB; mem (CPU total)=48273.421875MB
INFO:root:[   52] Training loss: 0.66704240, Validation loss: 0.66791817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48495.4453125MB; mem (CPU total)=48311.60546875MB
INFO:root:[   53] Training loss: 0.66683987, Validation loss: 0.66925637, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48533.5390625MB; mem (CPU total)=48350.18359375MB
INFO:root:[   54] Training loss: 0.66637875, Validation loss: 0.66659072, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48571.63671875MB; mem (CPU total)=48388.890625MB
INFO:root:[   55] Training loss: 0.66522422, Validation loss: 0.66588429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48609.73046875MB; mem (CPU total)=48426.98046875MB
INFO:root:[   56] Training loss: 0.66515116, Validation loss: 0.66524244, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48647.828125MB; mem (CPU total)=48465.21875MB
INFO:root:[   57] Training loss: 0.66421335, Validation loss: 0.66626119, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48685.921875MB; mem (CPU total)=48503.6640625MB
INFO:root:[   58] Training loss: 0.66390252, Validation loss: 0.66462650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48724.01953125MB; mem (CPU total)=48541.7890625MB
INFO:root:[   59] Training loss: 0.66357254, Validation loss: 0.66403388, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48762.11328125MB; mem (CPU total)=48580.3984375MB
INFO:root:[   60] Training loss: 0.66351103, Validation loss: 0.66414764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48800.2109375MB; mem (CPU total)=48618.8203125MB
INFO:root:[   61] Training loss: 0.66299191, Validation loss: 0.66418769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48838.30859375MB; mem (CPU total)=48656.5078125MB
INFO:root:[   62] Training loss: 0.66270783, Validation loss: 0.66351350, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48876.40234375MB; mem (CPU total)=48694.7265625MB
INFO:root:[   63] Training loss: 0.66241224, Validation loss: 0.66304710, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48914.49609375MB; mem (CPU total)=48732.828125MB
INFO:root:[   64] Training loss: 0.66215602, Validation loss: 0.66320859, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48952.59375MB; mem (CPU total)=48771.546875MB
INFO:root:[   65] Training loss: 0.66168839, Validation loss: 0.66341084, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48990.6875MB; mem (CPU total)=48809.48828125MB
INFO:root:[   66] Training loss: 0.66177591, Validation loss: 0.66260335, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49028.78125MB; mem (CPU total)=48847.66015625MB
INFO:root:[   67] Training loss: 0.66171842, Validation loss: 0.66326515, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49066.875MB; mem (CPU total)=48885.85546875MB
INFO:root:[   68] Training loss: 0.66163748, Validation loss: 0.66163460, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49104.97265625MB; mem (CPU total)=48924.1328125MB
INFO:root:[   69] Training loss: 0.66095122, Validation loss: 0.66158442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49143.06640625MB; mem (CPU total)=48962.3828125MB
INFO:root:[   70] Training loss: 0.66111068, Validation loss: 0.66266196, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49181.16015625MB; mem (CPU total)=49000.56640625MB
INFO:root:[   71] Training loss: 0.66059932, Validation loss: 0.66212454, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49219.2578125MB; mem (CPU total)=49038.98828125MB
INFO:root:[   72] Training loss: 0.66055179, Validation loss: 0.66121697, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49257.35546875MB; mem (CPU total)=49076.58984375MB
INFO:root:[   73] Training loss: 0.66098965, Validation loss: 0.66124030, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49295.44921875MB; mem (CPU total)=49114.9609375MB
INFO:root:[   74] Training loss: 0.66044299, Validation loss: 0.66096048, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49333.54296875MB; mem (CPU total)=49153.18359375MB
INFO:root:[   75] Training loss: 0.66066528, Validation loss: 0.66191788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49371.640625MB; mem (CPU total)=49192.03515625MB
INFO:root:[   76] Training loss: 0.66045313, Validation loss: 0.66213039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49409.734375MB; mem (CPU total)=49229.5546875MB
INFO:root:[   77] Training loss: 0.65981012, Validation loss: 0.66131369, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49447.828125MB; mem (CPU total)=49267.41015625MB
INFO:root:[   78] Training loss: 0.66027961, Validation loss: 0.65974394, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49485.92578125MB; mem (CPU total)=49306.046875MB
INFO:root:[   79] Training loss: 0.65945009, Validation loss: 0.66053392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49524.0234375MB; mem (CPU total)=49344.46484375MB
INFO:root:[   80] Training loss: 0.65963170, Validation loss: 0.66044027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49562.1171875MB; mem (CPU total)=49382.65625MB
INFO:root:[   81] Training loss: 0.65974045, Validation loss: 0.66032619, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49600.21484375MB; mem (CPU total)=49420.27734375MB
INFO:root:[   82] Training loss: 0.65933926, Validation loss: 0.66035766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49638.30859375MB; mem (CPU total)=49459.1171875MB
INFO:root:[   83] Training loss: 0.65965365, Validation loss: 0.65964284, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49676.40234375MB; mem (CPU total)=49497.78515625MB
INFO:root:[   84] Training loss: 0.65907017, Validation loss: 0.66018448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49714.49609375MB; mem (CPU total)=49536.203125MB
INFO:root:[   85] Training loss: 0.65921267, Validation loss: 0.66037721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49752.59375MB; mem (CPU total)=49574.33203125MB
INFO:root:[   86] Training loss: 0.65878890, Validation loss: 0.66048852, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49790.6875MB; mem (CPU total)=49612.1640625MB
INFO:root:[   87] Training loss: 0.65914566, Validation loss: 0.66036394, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49828.78515625MB; mem (CPU total)=49650.00390625MB
INFO:root:[   88] Training loss: 0.65886663, Validation loss: 0.65999773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49866.8828125MB; mem (CPU total)=49688.91015625MB
INFO:root:[   89] Training loss: 0.65888552, Validation loss: 0.65967441, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49904.9765625MB; mem (CPU total)=49727.03515625MB
INFO:root:[   90] Training loss: 0.65847608, Validation loss: 0.66074183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49943.0703125MB; mem (CPU total)=49765.1796875MB
INFO:root:[   91] Training loss: 0.65863202, Validation loss: 0.65980896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49981.1640625MB; mem (CPU total)=49803.5390625MB
INFO:root:[   92] Training loss: 0.65868789, Validation loss: 0.65993359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50019.26171875MB; mem (CPU total)=49841.390625MB
INFO:root:EP 92: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=50057.35546875MB; mem (CPU total)=49879.30859375MB
INFO:root:Training the model took 11109.875s.
INFO:root:Emptying the cuda cache took 0.006s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93557
INFO:root:EnergyScoreTrain: 0.65891
INFO:root:CRPSTrain: 0.62042
INFO:root:Gaussian NLLTrain: 2.60193
INFO:root:CoverageTrain: 0.73086
INFO:root:IntervalWidthTrain: 3.246
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93755
INFO:root:EnergyScoreValidation: 0.66031
INFO:root:CRPSValidation: 0.62191
INFO:root:Gaussian NLLValidation: 2.61274
INFO:root:CoverageValidation: 0.72977
INFO:root:IntervalWidthValidation: 3.24319
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93758
INFO:root:EnergyScoreTest: 0.66033
INFO:root:CRPSTest: 0.62181
INFO:root:Gaussian NLLTest: 2.60949
INFO:root:CoverageTest: 0.73055
INFO:root:IntervalWidthTest: 3.2472
INFO:root:After validation: mem (CPU python)=50100.1484375MB; mem (CPU total)=49922.93359375MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=50100.1484375MB; mem (CPU total)=49922.921875MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 165675008
INFO:root:After setting up the model: mem (CPU python)=50100.28515625MB; mem (CPU total)=49922.921875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=50100.2890625MB; mem (CPU total)=49922.921875MB
INFO:root:[    1] Training loss: 0.76257017, Validation loss: 0.72994654, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50138.33203125MB; mem (CPU total)=49961.61328125MB
INFO:root:[    2] Training loss: 0.73059336, Validation loss: 0.73711734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50176.42578125MB; mem (CPU total)=49999.7734375MB
INFO:root:[    3] Training loss: 0.71976325, Validation loss: 0.75335826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50214.5234375MB; mem (CPU total)=50037.93359375MB
INFO:root:[    4] Training loss: 0.71722392, Validation loss: 0.71231257, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50252.62109375MB; mem (CPU total)=50075.84765625MB
INFO:root:[    5] Training loss: 0.70783014, Validation loss: 0.70514814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50290.71484375MB; mem (CPU total)=50114.3984375MB
INFO:root:[    6] Training loss: 0.70498887, Validation loss: 0.70337912, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50328.80859375MB; mem (CPU total)=50152.453125MB
INFO:root:[    7] Training loss: 0.70304444, Validation loss: 0.70241699, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50366.90234375MB; mem (CPU total)=50190.8125MB
INFO:root:[    8] Training loss: 0.70213263, Validation loss: 0.70357777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50405.0MB; mem (CPU total)=50229.203125MB
INFO:root:[    9] Training loss: 0.70093032, Validation loss: 0.69844000, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50443.09765625MB; mem (CPU total)=50267.5078125MB
INFO:root:[   10] Training loss: 0.69826156, Validation loss: 0.69669649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50481.19140625MB; mem (CPU total)=50305.16015625MB
INFO:root:[   11] Training loss: 0.69612582, Validation loss: 0.69479875, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50519.29296875MB; mem (CPU total)=50343.3046875MB
INFO:root:[   12] Training loss: 0.69369050, Validation loss: 0.69268517, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50557.38671875MB; mem (CPU total)=50381.22265625MB
INFO:root:[   13] Training loss: 0.69206433, Validation loss: 0.69536606, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50595.48046875MB; mem (CPU total)=50420.140625MB
INFO:root:[   14] Training loss: 0.69110118, Validation loss: 0.69051092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50633.578125MB; mem (CPU total)=50457.625MB
INFO:root:[   15] Training loss: 0.68981801, Validation loss: 0.69108723, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50671.671875MB; mem (CPU total)=50496.00390625MB
INFO:root:[   16] Training loss: 0.68885939, Validation loss: 0.68888017, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50709.765625MB; mem (CPU total)=50534.1953125MB
INFO:root:[   17] Training loss: 0.68814664, Validation loss: 0.68782463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50747.86328125MB; mem (CPU total)=50572.66796875MB
INFO:root:[   18] Training loss: 0.68701596, Validation loss: 0.68734176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50785.9609375MB; mem (CPU total)=50610.9765625MB
INFO:root:[   19] Training loss: 0.68643268, Validation loss: 0.68655839, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50824.0546875MB; mem (CPU total)=50649.7265625MB
INFO:root:[   20] Training loss: 0.68543930, Validation loss: 0.68633825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50862.1484375MB; mem (CPU total)=50687.9375MB
INFO:root:[   21] Training loss: 0.68490904, Validation loss: 0.68461997, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50900.24609375MB; mem (CPU total)=50726.984375MB
INFO:root:[   22] Training loss: 0.68407413, Validation loss: 0.68404810, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50938.33984375MB; mem (CPU total)=50765.07421875MB
INFO:root:[   23] Training loss: 0.68323665, Validation loss: 0.68354701, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50976.43359375MB; mem (CPU total)=50803.265625MB
INFO:root:[   24] Training loss: 0.68273311, Validation loss: 0.68383689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51014.52734375MB; mem (CPU total)=50842.8203125MB
INFO:root:[   25] Training loss: 0.68219003, Validation loss: 0.68371797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51052.62890625MB; mem (CPU total)=50880.9296875MB
INFO:root:[   26] Training loss: 0.68142247, Validation loss: 0.68210824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51090.7265625MB; mem (CPU total)=50919.01953125MB
INFO:root:[   27] Training loss: 0.68056062, Validation loss: 0.68203114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51128.8203125MB; mem (CPU total)=50957.25390625MB
INFO:root:[   28] Training loss: 0.68025608, Validation loss: 0.68078707, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51166.91796875MB; mem (CPU total)=50995.59765625MB
INFO:root:[   29] Training loss: 0.67947468, Validation loss: 0.68011054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51205.01171875MB; mem (CPU total)=51034.2578125MB
INFO:root:[   30] Training loss: 0.67926234, Validation loss: 0.68084329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51243.10546875MB; mem (CPU total)=51072.6328125MB
INFO:root:[   31] Training loss: 0.67844888, Validation loss: 0.67964618, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51281.203125MB; mem (CPU total)=51110.94140625MB
INFO:root:[   32] Training loss: 0.67804617, Validation loss: 0.67897687, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51319.3046875MB; mem (CPU total)=51150.1484375MB
INFO:root:[   33] Training loss: 0.67769935, Validation loss: 0.67775770, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51357.3984375MB; mem (CPU total)=51188.5859375MB
INFO:root:[   34] Training loss: 0.67715878, Validation loss: 0.67719178, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51395.4921875MB; mem (CPU total)=51227.0MB
INFO:root:[   35] Training loss: 0.67710716, Validation loss: 0.67789670, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51433.58984375MB; mem (CPU total)=51265.14453125MB
INFO:root:[   36] Training loss: 0.67659589, Validation loss: 0.67784931, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51471.68359375MB; mem (CPU total)=51303.265625MB
INFO:root:[   37] Training loss: 0.67606221, Validation loss: 0.67800141, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51509.77734375MB; mem (CPU total)=51341.30859375MB
INFO:root:[   38] Training loss: 0.67582628, Validation loss: 0.67724704, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51547.875MB; mem (CPU total)=51379.41796875MB
INFO:root:[   39] Training loss: 0.67516908, Validation loss: 0.67597803, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51585.97265625MB; mem (CPU total)=51417.890625MB
INFO:root:[   40] Training loss: 0.67512948, Validation loss: 0.67559161, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51624.0625MB; mem (CPU total)=51456.203125MB
INFO:root:[   41] Training loss: 0.67447746, Validation loss: 0.67540798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51662.16015625MB; mem (CPU total)=51494.75MB
INFO:root:[   42] Training loss: 0.67412800, Validation loss: 0.67621161, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51700.2578125MB; mem (CPU total)=51532.859375MB
INFO:root:[   43] Training loss: 0.67384273, Validation loss: 0.67511040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51738.3515625MB; mem (CPU total)=51570.4765625MB
INFO:root:[   44] Training loss: 0.67359692, Validation loss: 0.67433460, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51776.4453125MB; mem (CPU total)=51607.96484375MB
INFO:root:[   45] Training loss: 0.67313611, Validation loss: 0.67392188, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51814.54296875MB; mem (CPU total)=51646.234375MB
INFO:root:[   46] Training loss: 0.67312437, Validation loss: 0.67416560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51852.640625MB; mem (CPU total)=51684.32421875MB
INFO:root:[   47] Training loss: 0.67271655, Validation loss: 0.67347476, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51890.73046875MB; mem (CPU total)=51722.4765625MB
INFO:root:[   48] Training loss: 0.67250473, Validation loss: 0.67309530, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51928.828125MB; mem (CPU total)=51759.21484375MB
INFO:root:[   49] Training loss: 0.67240555, Validation loss: 0.67369230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51966.92578125MB; mem (CPU total)=51797.8359375MB
INFO:root:[   50] Training loss: 0.67207390, Validation loss: 0.67366213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52005.01953125MB; mem (CPU total)=51835.828125MB
INFO:root:[   51] Training loss: 0.67166126, Validation loss: 0.67186895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52043.11328125MB; mem (CPU total)=51874.0234375MB
INFO:root:[   52] Training loss: 0.67082445, Validation loss: 0.67339747, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52081.2109375MB; mem (CPU total)=51912.38671875MB
INFO:root:[   53] Training loss: 0.67046173, Validation loss: 0.67188505, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52119.3046875MB; mem (CPU total)=51950.5546875MB
INFO:root:[   54] Training loss: 0.67038694, Validation loss: 0.67196248, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52157.3984375MB; mem (CPU total)=51988.56640625MB
INFO:root:[   55] Training loss: 0.66975078, Validation loss: 0.67050389, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52195.49609375MB; mem (CPU total)=52027.3203125MB
INFO:root:[   56] Training loss: 0.66915984, Validation loss: 0.66942953, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52233.59375MB; mem (CPU total)=52065.6640625MB
INFO:root:[   57] Training loss: 0.66803720, Validation loss: 0.66970337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52271.6875MB; mem (CPU total)=52104.0703125MB
INFO:root:[   58] Training loss: 0.66767047, Validation loss: 0.66917370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52309.78125MB; mem (CPU total)=52142.28125MB
INFO:root:[   59] Training loss: 0.66718461, Validation loss: 0.66845746, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52347.87890625MB; mem (CPU total)=52180.71875MB
INFO:root:[   60] Training loss: 0.66669751, Validation loss: 0.66803329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52385.97265625MB; mem (CPU total)=52218.51953125MB
INFO:root:[   61] Training loss: 0.66635354, Validation loss: 0.66709511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52424.06640625MB; mem (CPU total)=52256.48046875MB
INFO:root:[   62] Training loss: 0.66587219, Validation loss: 0.66674709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52462.1640625MB; mem (CPU total)=52294.99609375MB
INFO:root:[   63] Training loss: 0.66539745, Validation loss: 0.66794423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52500.2578125MB; mem (CPU total)=52333.3671875MB
INFO:root:[   64] Training loss: 0.66520455, Validation loss: 0.66611288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52538.3515625MB; mem (CPU total)=52371.203125MB
INFO:root:[   65] Training loss: 0.66498325, Validation loss: 0.66560601, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52576.453125MB; mem (CPU total)=52407.8046875MB
INFO:root:[   66] Training loss: 0.66447677, Validation loss: 0.66440074, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52614.546875MB; mem (CPU total)=52445.83203125MB
INFO:root:[   67] Training loss: 0.66455639, Validation loss: 0.66752379, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52652.640625MB; mem (CPU total)=52484.30078125MB
INFO:root:[   68] Training loss: 0.66411120, Validation loss: 0.66546840, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52690.734375MB; mem (CPU total)=52522.046875MB
INFO:root:[   69] Training loss: 0.66366473, Validation loss: 0.66473367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52728.83203125MB; mem (CPU total)=52559.9453125MB
INFO:root:[   70] Training loss: 0.66375525, Validation loss: 0.66387337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52766.92578125MB; mem (CPU total)=52597.93359375MB
INFO:root:[   71] Training loss: 0.66341500, Validation loss: 0.66515272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52805.01953125MB; mem (CPU total)=52636.046875MB
INFO:root:[   72] Training loss: 0.66330198, Validation loss: 0.66475977, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52843.1171875MB; mem (CPU total)=52674.20703125MB
INFO:root:[   73] Training loss: 0.66281493, Validation loss: 0.66334987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52881.21484375MB; mem (CPU total)=52712.2109375MB
INFO:root:[   74] Training loss: 0.66227667, Validation loss: 0.66340656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52919.30859375MB; mem (CPU total)=52750.35546875MB
INFO:root:[   75] Training loss: 0.66241678, Validation loss: 0.66372393, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52957.40234375MB; mem (CPU total)=52788.5MB
INFO:root:[   76] Training loss: 0.66266261, Validation loss: 0.66351163, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52995.5MB; mem (CPU total)=52826.29296875MB
INFO:root:[   77] Training loss: 0.66200941, Validation loss: 0.66372083, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53033.59375MB; mem (CPU total)=52864.69921875MB
INFO:root:[   78] Training loss: 0.66192289, Validation loss: 0.66363003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53071.6875MB; mem (CPU total)=52903.3203125MB
INFO:root:[   79] Training loss: 0.66181277, Validation loss: 0.66233630, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53109.78515625MB; mem (CPU total)=52941.54296875MB
INFO:root:[   80] Training loss: 0.66106593, Validation loss: 0.66452536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53147.87890625MB; mem (CPU total)=52978.99609375MB
INFO:root:[   81] Training loss: 0.66100188, Validation loss: 0.66266750, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53185.9765625MB; mem (CPU total)=53016.91796875MB
INFO:root:[   82] Training loss: 0.66147475, Validation loss: 0.66256811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53224.07421875MB; mem (CPU total)=53054.3046875MB
INFO:root:[   83] Training loss: 0.66070105, Validation loss: 0.66237909, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53262.16796875MB; mem (CPU total)=53092.69140625MB
INFO:root:[   84] Training loss: 0.66076551, Validation loss: 0.66150287, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53300.26171875MB; mem (CPU total)=53131.203125MB
INFO:root:[   85] Training loss: 0.66041926, Validation loss: 0.66183480, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53338.35546875MB; mem (CPU total)=53169.58203125MB
INFO:root:[   86] Training loss: 0.66127366, Validation loss: 0.66129937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53376.453125MB; mem (CPU total)=53207.8046875MB
INFO:root:[   87] Training loss: 0.66064597, Validation loss: 0.66149342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53414.546875MB; mem (CPU total)=53245.703125MB
INFO:root:[   88] Training loss: 0.66054176, Validation loss: 0.66144536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53452.640625MB; mem (CPU total)=53283.83984375MB
INFO:root:[   89] Training loss: 0.65994155, Validation loss: 0.65990027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53490.7421875MB; mem (CPU total)=53321.953125MB
INFO:root:[   90] Training loss: 0.66015671, Validation loss: 0.66102805, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53528.8359375MB; mem (CPU total)=53360.55859375MB
INFO:root:[   91] Training loss: 0.65961718, Validation loss: 0.66159054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53566.9296875MB; mem (CPU total)=53398.72265625MB
INFO:root:[   92] Training loss: 0.65959737, Validation loss: 0.66243324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53605.0234375MB; mem (CPU total)=53436.7578125MB
INFO:root:[   93] Training loss: 0.65977387, Validation loss: 0.66170561, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53643.12109375MB; mem (CPU total)=53474.89453125MB
INFO:root:[   94] Training loss: 0.65974001, Validation loss: 0.66167435, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53681.21484375MB; mem (CPU total)=53513.0234375MB
INFO:root:[   95] Training loss: 0.65914983, Validation loss: 0.66068580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53719.30859375MB; mem (CPU total)=53551.3828125MB
INFO:root:[   96] Training loss: 0.65915519, Validation loss: 0.66101317, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53757.40625MB; mem (CPU total)=53589.33984375MB
INFO:root:[   97] Training loss: 0.65917603, Validation loss: 0.66097742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53795.5MB; mem (CPU total)=53627.703125MB
INFO:root:[   98] Training loss: 0.65903550, Validation loss: 0.66101044, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53833.59765625MB; mem (CPU total)=53665.83203125MB
INFO:root:EP 98: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=53871.69140625MB; mem (CPU total)=53703.73046875MB
INFO:root:Training the model took 12209.199s.
INFO:root:Emptying the cuda cache took 0.003s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93613
INFO:root:EnergyScoreTrain: 0.65928
INFO:root:CRPSTrain: 0.59589
INFO:root:Gaussian NLLTrain: 1.77259
INFO:root:CoverageTrain: 0.82597
INFO:root:IntervalWidthTrain: 3.59257
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93854
INFO:root:EnergyScoreValidation: 0.66096
INFO:root:CRPSValidation: 0.59757
INFO:root:Gaussian NLLValidation: 1.77687
INFO:root:CoverageValidation: 0.82523
INFO:root:IntervalWidthValidation: 3.59342
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93893
INFO:root:EnergyScoreTest: 0.66121
INFO:root:CRPSTest: 0.59778
INFO:root:Gaussian NLLTest: 1.77721
INFO:root:CoverageTest: 0.8256
INFO:root:IntervalWidthTest: 3.59798
INFO:root:After validation: mem (CPU python)=53914.453125MB; mem (CPU total)=53749.08984375MB
