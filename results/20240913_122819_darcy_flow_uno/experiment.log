INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=576.43359375MB; mem (CPU total)=1024.15234375MB
INFO:root:############### Starting experiment with config file darcy_flow/uno.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'DarcyFlow', 'max_training_set_size': 10000, 'downscaling_factor': 2}
INFO:root:After loading the datasets: mem (CPU python)=1996.671875MB; mem (CPU total)=1036.02734375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=1996.671875MB; mem (CPU total)=1035.3984375MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 44040192
INFO:root:After setting up the model: mem (CPU python)=2214.74609375MB; mem (CPU total)=2426.6796875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2214.74609375MB; mem (CPU total)=2433.53125MB
INFO:root:[    1] Training loss: 0.31316601, Validation loss: 0.25004964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4450.69140625MB; mem (CPU total)=4216.64453125MB
INFO:root:[    2] Training loss: 0.18297245, Validation loss: 0.19880198, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4526.94140625MB; mem (CPU total)=4292.3984375MB
INFO:root:[    3] Training loss: 0.16872673, Validation loss: 0.20984227, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4603.17578125MB; mem (CPU total)=4368.1953125MB
INFO:root:[    4] Training loss: 0.15492320, Validation loss: 0.18779276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4679.3984375MB; mem (CPU total)=4444.47265625MB
INFO:root:[    5] Training loss: 0.14481584, Validation loss: 0.19566369, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4755.6171875MB; mem (CPU total)=4519.7890625MB
INFO:root:[    6] Training loss: 0.14098501, Validation loss: 0.18324928, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4831.83203125MB; mem (CPU total)=4595.68359375MB
INFO:root:[    7] Training loss: 0.13312711, Validation loss: 0.22092729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4908.04296875MB; mem (CPU total)=4671.91796875MB
INFO:root:[    8] Training loss: 0.13219314, Validation loss: 0.15946800, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4984.25390625MB; mem (CPU total)=4747.04296875MB
INFO:root:[    9] Training loss: 0.11968131, Validation loss: 0.17290071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5060.47265625MB; mem (CPU total)=4823.00390625MB
INFO:root:[   10] Training loss: 0.11935730, Validation loss: 0.17282331, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5136.7265625MB; mem (CPU total)=4899.66796875MB
INFO:root:[   11] Training loss: 0.12385866, Validation loss: 0.16850337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5212.93359375MB; mem (CPU total)=4977.015625MB
INFO:root:[   12] Training loss: 0.11568350, Validation loss: 0.18802644, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5289.15234375MB; mem (CPU total)=5052.7109375MB
INFO:root:[   13] Training loss: 0.11399179, Validation loss: 0.18729182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5365.3828125MB; mem (CPU total)=5128.4453125MB
INFO:root:[   14] Training loss: 0.11328152, Validation loss: 0.16720075, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5441.58984375MB; mem (CPU total)=5204.68359375MB
INFO:root:[   15] Training loss: 0.10766876, Validation loss: 0.18427492, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5517.80859375MB; mem (CPU total)=5281.5703125MB
INFO:root:[   16] Training loss: 0.11479811, Validation loss: 0.17652199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5594.01171875MB; mem (CPU total)=5358.80859375MB
INFO:root:[   17] Training loss: 0.10979214, Validation loss: 0.19010177, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5670.22265625MB; mem (CPU total)=5436.51953125MB
INFO:root:[   18] Training loss: 0.11487947, Validation loss: 0.17405910, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5746.44140625MB; mem (CPU total)=5512.44140625MB
INFO:root:[   19] Training loss: 0.10696327, Validation loss: 0.21983976, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5822.640625MB; mem (CPU total)=5587.859375MB
INFO:root:[   20] Training loss: 0.09978178, Validation loss: 0.17069965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5898.84765625MB; mem (CPU total)=5665.4921875MB
INFO:root:[   21] Training loss: 0.09577848, Validation loss: 0.20379206, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5975.046875MB; mem (CPU total)=5740.453125MB
INFO:root:[   22] Training loss: 0.09756727, Validation loss: 0.17344192, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6051.25390625MB; mem (CPU total)=5816.92578125MB
INFO:root:[   23] Training loss: 0.09574565, Validation loss: 0.18069962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6127.4453125MB; mem (CPU total)=5892.58203125MB
INFO:root:[   24] Training loss: 0.10215150, Validation loss: 0.18755708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6203.6328125MB; mem (CPU total)=5969.09375MB
INFO:root:[   25] Training loss: 0.09345624, Validation loss: 0.21077762, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6279.828125MB; mem (CPU total)=6045.34375MB
INFO:root:[   26] Training loss: 0.09236957, Validation loss: 0.18336128, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6356.015625MB; mem (CPU total)=6122.8359375MB
INFO:root:[   27] Training loss: 0.09338366, Validation loss: 0.18237854, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6432.20703125MB; mem (CPU total)=6199.05859375MB
INFO:root:[   28] Training loss: 0.09116242, Validation loss: 0.19621387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6508.40234375MB; mem (CPU total)=6275.07421875MB
INFO:root:[   29] Training loss: 0.08707924, Validation loss: 0.22277528, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6584.59375MB; mem (CPU total)=6351.4140625MB
INFO:root:[   30] Training loss: 0.08483613, Validation loss: 0.20068084, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6660.78515625MB; mem (CPU total)=6425.3984375MB
INFO:root:[   31] Training loss: 0.08737195, Validation loss: 0.20098194, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6736.97265625MB; mem (CPU total)=6501.5MB
INFO:root:[   32] Training loss: 0.08740102, Validation loss: 0.21828138, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6813.16796875MB; mem (CPU total)=6577.47265625MB
INFO:root:[   33] Training loss: 0.08708300, Validation loss: 0.20221877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6889.359375MB; mem (CPU total)=6653.72265625MB
INFO:root:[   34] Training loss: 0.08299060, Validation loss: 0.21144140, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6965.546875MB; mem (CPU total)=6729.65625MB
INFO:root:[   35] Training loss: 0.08047165, Validation loss: 0.19986718, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7041.73828125MB; mem (CPU total)=6805.9140625MB
INFO:root:[   36] Training loss: 0.08622190, Validation loss: 0.22683031, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7117.92578125MB; mem (CPU total)=6881.9140625MB
INFO:root:[   37] Training loss: 0.08759184, Validation loss: 0.20805785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7194.15625MB; mem (CPU total)=6958.140625MB
INFO:root:[   38] Training loss: 0.08036996, Validation loss: 0.24037886, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7270.81640625MB; mem (CPU total)=7034.91015625MB
INFO:root:[   39] Training loss: 0.07647105, Validation loss: 0.21059598, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7347.109375MB; mem (CPU total)=7109.796875MB
