INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=580.50390625MB; mem (CPU total)=4021.01171875MB
INFO:root:############### Starting experiment with config file sswe/sfno_timing.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=591.26953125MB; mem (CPU total)=4023.9296875MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 25, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=592.6953125MB; mem (CPU total)=4024.421875MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2324.71875MB; mem (CPU total)=5486.56640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2334.27734375MB; mem (CPU total)=5495.93359375MB
INFO:root:[    1] Training loss: 0.67120468, Validation loss: 0.52713072, Gradient norm: 0.27689772
INFO:root:At the start of the epoch: mem (CPU python)=4562.2109375MB; mem (CPU total)=7162.3125MB
INFO:root:[    2] Training loss: 0.53720434, Validation loss: 0.51964555, Gradient norm: 0.24210184
INFO:root:At the start of the epoch: mem (CPU python)=4593.859375MB; mem (CPU total)=7200.6328125MB
INFO:root:[    3] Training loss: 0.52914724, Validation loss: 0.51948241, Gradient norm: 0.16069638
INFO:root:At the start of the epoch: mem (CPU python)=4615.2890625MB; mem (CPU total)=7208.02734375MB
INFO:root:[    4] Training loss: 0.52650085, Validation loss: 0.51748364, Gradient norm: 0.17854914
INFO:root:At the start of the epoch: mem (CPU python)=4636.15625MB; mem (CPU total)=7245.64453125MB
INFO:root:[    5] Training loss: 0.52387167, Validation loss: 0.51093825, Gradient norm: 0.27262321
INFO:root:At the start of the epoch: mem (CPU python)=4657.51171875MB; mem (CPU total)=7268.41796875MB
INFO:root:[    6] Training loss: 0.51741790, Validation loss: 0.50318290, Gradient norm: 0.33050300
INFO:root:At the start of the epoch: mem (CPU python)=4678.6171875MB; mem (CPU total)=7310.1796875MB
INFO:root:[    7] Training loss: 0.51525702, Validation loss: 0.50011880, Gradient norm: 0.44468386
INFO:root:At the start of the epoch: mem (CPU python)=4699.8515625MB; mem (CPU total)=7297.6328125MB
INFO:root:[    8] Training loss: 0.50829892, Validation loss: 0.50690965, Gradient norm: 0.39085209
INFO:root:At the start of the epoch: mem (CPU python)=4721.1875MB; mem (CPU total)=7335.9140625MB
INFO:root:[    9] Training loss: 0.49557240, Validation loss: 0.46936368, Gradient norm: 0.50893490
INFO:root:At the start of the epoch: mem (CPU python)=4742.3671875MB; mem (CPU total)=7357.88671875MB
INFO:root:[   10] Training loss: 0.48384691, Validation loss: 0.44050026, Gradient norm: 0.76582869
INFO:root:At the start of the epoch: mem (CPU python)=4763.328125MB; mem (CPU total)=7380.48046875MB
INFO:root:[   11] Training loss: 0.47258598, Validation loss: 0.45200022, Gradient norm: 1.07895229
INFO:root:At the start of the epoch: mem (CPU python)=4784.55859375MB; mem (CPU total)=7403.65234375MB
INFO:root:[   12] Training loss: 0.46600917, Validation loss: 0.45293315, Gradient norm: 1.01784703
INFO:root:At the start of the epoch: mem (CPU python)=4805.48046875MB; mem (CPU total)=7426.30078125MB
INFO:root:[   13] Training loss: 0.45652952, Validation loss: 0.42494761, Gradient norm: 1.14247477
INFO:root:At the start of the epoch: mem (CPU python)=4826.89453125MB; mem (CPU total)=7432.58984375MB
INFO:root:[   14] Training loss: 0.45363867, Validation loss: 0.41017478, Gradient norm: 1.20108184
INFO:root:At the start of the epoch: mem (CPU python)=4848.1484375MB; mem (CPU total)=7458.1640625MB
INFO:root:[   15] Training loss: 0.45153498, Validation loss: 0.43027509, Gradient norm: 1.39449194
INFO:root:At the start of the epoch: mem (CPU python)=4869.20703125MB; mem (CPU total)=7478.51171875MB
INFO:root:[   16] Training loss: 0.44363307, Validation loss: 0.42316371, Gradient norm: 1.51688562
INFO:root:At the start of the epoch: mem (CPU python)=4890.33203125MB; mem (CPU total)=7515.04296875MB
INFO:root:[   17] Training loss: 0.44909242, Validation loss: 0.41514707, Gradient norm: 1.99227940
INFO:root:At the start of the epoch: mem (CPU python)=4911.35546875MB; mem (CPU total)=7537.76953125MB
INFO:root:[   18] Training loss: 0.43915173, Validation loss: 0.42294231, Gradient norm: 1.60185816
INFO:root:At the start of the epoch: mem (CPU python)=4932.6796875MB; mem (CPU total)=7560.57421875MB
INFO:root:[   19] Training loss: 0.44496809, Validation loss: 0.40099061, Gradient norm: 2.09393995
INFO:root:At the start of the epoch: mem (CPU python)=4953.65234375MB; mem (CPU total)=7582.08203125MB
INFO:root:[   20] Training loss: 0.43716442, Validation loss: 0.39520631, Gradient norm: 1.90508881
INFO:root:At the start of the epoch: mem (CPU python)=4974.91015625MB; mem (CPU total)=7605.84765625MB
INFO:root:[   21] Training loss: 0.43859293, Validation loss: 0.39584614, Gradient norm: 2.10979182
INFO:root:At the start of the epoch: mem (CPU python)=4996.12890625MB; mem (CPU total)=7614.1015625MB
INFO:root:[   22] Training loss: 0.43088046, Validation loss: 0.39754653, Gradient norm: 2.07900525
INFO:root:At the start of the epoch: mem (CPU python)=5017.05078125MB; mem (CPU total)=7636.4140625MB
INFO:root:[   23] Training loss: 0.43453479, Validation loss: 0.40829213, Gradient norm: 2.28170827
INFO:root:At the start of the epoch: mem (CPU python)=5038.61328125MB; mem (CPU total)=7672.96875MB
INFO:root:[   24] Training loss: 0.43348281, Validation loss: 0.38403509, Gradient norm: 2.36013282
INFO:root:At the start of the epoch: mem (CPU python)=5059.41796875MB; mem (CPU total)=7654.76953125MB
INFO:root:[   25] Training loss: 0.42870711, Validation loss: 0.38935934, Gradient norm: 2.23705911
INFO:root:After finishing all epochs: mem (CPU python)=5080.84765625MB; mem (CPU total)=7718.34375MB
INFO:root:Training the model took 798.095s.
INFO:root:Emptying the cuda cache took 0.046s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.54497
INFO:root:EnergyScoreValidation: 0.38394
INFO:root:CRPSValidation: 0.20586
INFO:root:Gaussian NLLValidation: 21041891742.62893
INFO:root:CoverageValidation: 0.34635
INFO:root:IntervalWidthValidation: 0.71182
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.55979
INFO:root:EnergyScoreTest: 0.39399
INFO:root:CRPSTest: 0.21128
INFO:root:Gaussian NLLTest: 22016435748.864
INFO:root:CoverageTest: 0.34364
INFO:root:IntervalWidthTest: 0.70939
INFO:root:After validation: mem (CPU python)=5591.67578125MB; mem (CPU total)=7733.38671875MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 25, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=5591.67578125MB; mem (CPU total)=7775.59765625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 616562688
INFO:root:After setting up the model: mem (CPU python)=5591.67578125MB; mem (CPU total)=7773.53515625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7773.53515625MB
INFO:root:[    1] Training loss: 0.95630147, Validation loss: 0.77293873, Gradient norm: 0.49298167
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7795.5546875MB
INFO:root:[    2] Training loss: 0.76175177, Validation loss: 0.73573867, Gradient norm: 0.22995547
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7807.6875MB
INFO:root:[    3] Training loss: 0.75173234, Validation loss: 0.73921026, Gradient norm: 0.34857714
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7822.03515625MB
INFO:root:[    4] Training loss: 0.74863972, Validation loss: 0.73647345, Gradient norm: 0.44208220
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7839.76171875MB
INFO:root:[    5] Training loss: 0.74710880, Validation loss: 0.73198787, Gradient norm: 0.58484345
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7885.26953125MB
INFO:root:[    6] Training loss: 0.74400860, Validation loss: 0.72139471, Gradient norm: 0.79122007
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7806.1484375MB
INFO:root:[    7] Training loss: 0.73911964, Validation loss: 0.71734369, Gradient norm: 0.87002296
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7924.30078125MB
INFO:root:[    8] Training loss: 0.72932052, Validation loss: 0.71663932, Gradient norm: 0.88263126
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7950.0625MB
INFO:root:[    9] Training loss: 0.72898561, Validation loss: 0.71424168, Gradient norm: 1.18181978
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7971.53125MB
INFO:root:[   10] Training loss: 0.72737065, Validation loss: 0.69158827, Gradient norm: 1.52530967
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=7994.21484375MB
INFO:root:[   11] Training loss: 0.70842014, Validation loss: 0.69389832, Gradient norm: 1.45178633
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8016.7421875MB
INFO:root:[   12] Training loss: 0.70265788, Validation loss: 0.66339860, Gradient norm: 1.96948788
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8038.3828125MB
INFO:root:[   13] Training loss: 0.68738241, Validation loss: 0.62825818, Gradient norm: 1.52395768
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8060.265625MB
INFO:root:[   14] Training loss: 0.67155085, Validation loss: 0.62913372, Gradient norm: 2.04573008
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8083.33203125MB
INFO:root:[   15] Training loss: 0.66334930, Validation loss: 0.61393403, Gradient norm: 1.93295223
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8104.0078125MB
INFO:root:[   16] Training loss: 0.65896061, Validation loss: 0.60779679, Gradient norm: 2.43514745
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8140.984375MB
INFO:root:[   17] Training loss: 0.65489726, Validation loss: 0.60267143, Gradient norm: 2.64021303
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8149.00390625MB
INFO:root:[   18] Training loss: 0.64738124, Validation loss: 0.61621785, Gradient norm: 2.51399993
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8185.765625MB
INFO:root:[   19] Training loss: 0.64136172, Validation loss: 0.58679593, Gradient norm: 2.44481378
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8194.1484375MB
INFO:root:[   20] Training loss: 0.63810422, Validation loss: 0.60822401, Gradient norm: 2.92124228
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8231.38671875MB
INFO:root:[   21] Training loss: 0.63782814, Validation loss: 0.59230114, Gradient norm: 3.17175512
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8253.640625MB
INFO:root:[   22] Training loss: 0.62690979, Validation loss: 0.59893089, Gradient norm: 2.92275355
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8261.9609375MB
INFO:root:[   23] Training loss: 0.63565403, Validation loss: 0.61301020, Gradient norm: 3.44439621
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8284.66015625MB
INFO:root:[   24] Training loss: 0.62237112, Validation loss: 0.56113231, Gradient norm: 3.06968463
INFO:root:At the start of the epoch: mem (CPU python)=5591.67578125MB; mem (CPU total)=8320.99609375MB
INFO:root:[   25] Training loss: 0.62613258, Validation loss: 0.57007267, Gradient norm: 3.36025083
INFO:root:After finishing all epochs: mem (CPU python)=5591.67578125MB; mem (CPU total)=8343.25MB
INFO:root:Training the model took 538.915s.
INFO:root:Emptying the cuda cache took 0.038s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.56192
INFO:root:EnergyScoreValidation: 0.43111
INFO:root:CRPSValidation: 0.1858
INFO:root:Gaussian NLLValidation: 2.07371
INFO:root:CoverageValidation: 0.68162
INFO:root:IntervalWidthValidation: 0.58274
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.56902
INFO:root:EnergyScoreTest: 0.43731
INFO:root:CRPSTest: 0.18714
INFO:root:Gaussian NLLTest: 2.18311
INFO:root:CoverageTest: 0.68234
INFO:root:IntervalWidthTest: 0.58302
INFO:root:After validation: mem (CPU python)=5925.4453125MB; mem (CPU total)=8611.04296875MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 25, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=5925.4453125MB; mem (CPU total)=8611.015625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 618659840
INFO:root:After setting up the model: mem (CPU python)=5949.125MB; mem (CPU total)=8634.83203125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=5949.125MB; mem (CPU total)=8635.32421875MB
INFO:root:[    1] Training loss: 0.95630147, Validation loss: 0.79370273, Gradient norm: 0.49298167
INFO:root:At the start of the epoch: mem (CPU python)=5993.83203125MB; mem (CPU total)=8631.9296875MB
INFO:root:[    2] Training loss: 0.76189251, Validation loss: 0.75507051, Gradient norm: 0.23118451
INFO:root:At the start of the epoch: mem (CPU python)=6015.01171875MB; mem (CPU total)=8657.5859375MB
INFO:root:[    3] Training loss: 0.75102830, Validation loss: 0.74883348, Gradient norm: 0.33090968
INFO:root:At the start of the epoch: mem (CPU python)=6036.046875MB; mem (CPU total)=8680.96875MB
INFO:root:[    4] Training loss: 0.75092442, Validation loss: 0.74624134, Gradient norm: 0.51651215
INFO:root:At the start of the epoch: mem (CPU python)=6057.28125MB; mem (CPU total)=8705.3515625MB
INFO:root:[    5] Training loss: 0.74585498, Validation loss: 0.74471752, Gradient norm: 0.48834879
INFO:root:At the start of the epoch: mem (CPU python)=6078.45703125MB; mem (CPU total)=8729.95703125MB
INFO:root:[    6] Training loss: 0.74445822, Validation loss: 0.73450796, Gradient norm: 0.81699694
INFO:root:At the start of the epoch: mem (CPU python)=6099.6484375MB; mem (CPU total)=8753.12109375MB
INFO:root:[    7] Training loss: 0.73362529, Validation loss: 0.72891181, Gradient norm: 0.82047204
INFO:root:At the start of the epoch: mem (CPU python)=6120.83203125MB; mem (CPU total)=8779.95703125MB
INFO:root:[    8] Training loss: 0.73765592, Validation loss: 0.73236372, Gradient norm: 1.18841287
INFO:root:At the start of the epoch: mem (CPU python)=6141.75MB; mem (CPU total)=8802.54296875MB
INFO:root:[    9] Training loss: 0.72946733, Validation loss: 0.74184325, Gradient norm: 1.17221614
INFO:root:At the start of the epoch: mem (CPU python)=6163.11328125MB; mem (CPU total)=8823.4453125MB
INFO:root:[   10] Training loss: 0.72652700, Validation loss: 0.70692854, Gradient norm: 1.35802563
INFO:root:At the start of the epoch: mem (CPU python)=6184.35546875MB; mem (CPU total)=8843.66796875MB
INFO:root:[   11] Training loss: 0.70838707, Validation loss: 0.69375709, Gradient norm: 1.56946361
INFO:root:At the start of the epoch: mem (CPU python)=6205.3125MB; mem (CPU total)=8865.0625MB
INFO:root:[   12] Training loss: 0.69528473, Validation loss: 0.69477647, Gradient norm: 1.42966814
INFO:root:At the start of the epoch: mem (CPU python)=6226.62890625MB; mem (CPU total)=8886.91015625MB
INFO:root:[   13] Training loss: 0.68391287, Validation loss: 0.68688446, Gradient norm: 1.80977977
INFO:root:At the start of the epoch: mem (CPU python)=6247.921875MB; mem (CPU total)=8907.07421875MB
INFO:root:[   14] Training loss: 0.66439056, Validation loss: 0.66591466, Gradient norm: 1.89201474
INFO:root:At the start of the epoch: mem (CPU python)=6269.078125MB; mem (CPU total)=8928.46875MB
INFO:root:[   15] Training loss: 0.65998931, Validation loss: 0.65720502, Gradient norm: 2.46907231
INFO:root:At the start of the epoch: mem (CPU python)=6290.01171875MB; mem (CPU total)=8949.95703125MB
INFO:root:[   16] Training loss: 0.65244239, Validation loss: 0.64677302, Gradient norm: 2.28385971
INFO:root:At the start of the epoch: mem (CPU python)=6311.2265625MB; mem (CPU total)=8972.734375MB
INFO:root:[   17] Training loss: 0.65015357, Validation loss: 0.63831782, Gradient norm: 2.34513693
INFO:root:At the start of the epoch: mem (CPU python)=6332.36328125MB; mem (CPU total)=8993.8828125MB
INFO:root:[   18] Training loss: 0.63722527, Validation loss: 0.65571598, Gradient norm: 2.58021157
INFO:root:At the start of the epoch: mem (CPU python)=6353.578125MB; mem (CPU total)=9016.109375MB
INFO:root:[   19] Training loss: 0.64083147, Validation loss: 0.62141559, Gradient norm: 2.59346358
INFO:root:At the start of the epoch: mem (CPU python)=6374.8984375MB; mem (CPU total)=9037.0390625MB
INFO:root:[   20] Training loss: 0.62177630, Validation loss: 0.63310202, Gradient norm: 2.18316657
INFO:root:At the start of the epoch: mem (CPU python)=6395.9140625MB; mem (CPU total)=9059.04296875MB
INFO:root:[   21] Training loss: 0.63028497, Validation loss: 0.62623247, Gradient norm: 3.35683949
INFO:root:At the start of the epoch: mem (CPU python)=6417.16796875MB; mem (CPU total)=9080.21875MB
INFO:root:[   22] Training loss: 0.62261862, Validation loss: 0.62150024, Gradient norm: 2.92298573
INFO:root:At the start of the epoch: mem (CPU python)=6438.35546875MB; mem (CPU total)=9100.6015625MB
INFO:root:[   23] Training loss: 0.63016598, Validation loss: 0.61383710, Gradient norm: 3.27507227
INFO:root:At the start of the epoch: mem (CPU python)=6459.3515625MB; mem (CPU total)=9121.5390625MB
INFO:root:[   24] Training loss: 0.61698414, Validation loss: 0.62237744, Gradient norm: 2.85394105
INFO:root:At the start of the epoch: mem (CPU python)=6480.5390625MB; mem (CPU total)=9143.27734375MB
INFO:root:[   25] Training loss: 0.61391740, Validation loss: 0.60927021, Gradient norm: 3.20456468
INFO:root:After finishing all epochs: mem (CPU python)=6501.75390625MB; mem (CPU total)=9163.3046875MB
INFO:root:Training the model took 559.007s.
INFO:root:Emptying the cuda cache took 0.035s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.56397
INFO:root:EnergyScoreValidation: 0.44596
INFO:root:CRPSValidation: 0.18901
INFO:root:Gaussian NLLValidation: 1.66783
INFO:root:CoverageValidation: 0.58794
INFO:root:IntervalWidthValidation: 0.47932
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.5703
INFO:root:EnergyScoreTest: 0.45198
INFO:root:CRPSTest: 0.19001
INFO:root:Gaussian NLLTest: 1.67416
INFO:root:CoverageTest: 0.59218
INFO:root:IntervalWidthTest: 0.47824
INFO:root:After validation: mem (CPU python)=7061.0859375MB; mem (CPU total)=9171.6484375MB
