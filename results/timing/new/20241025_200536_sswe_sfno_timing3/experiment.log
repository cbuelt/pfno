INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=577.42578125MB; mem (CPU total)=1042.65625MB
INFO:root:############### Starting experiment with config file sswe/sfno_timing3.ini ###############
INFO:root:###1 out of 2 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=588.47265625MB; mem (CPU total)=1045.4609375MB
INFO:root:###1 out of 1 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 25, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=590.09765625MB; mem (CPU total)=1045.9453125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2269.7109375MB; mem (CPU total)=2473.75MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2279.25MB; mem (CPU total)=2482.1796875MB
INFO:root:[    1] Training loss: 0.70267276, Validation loss: 0.55961026, Gradient norm: 3.00024700
INFO:root:At the start of the epoch: mem (CPU python)=4442.953125MB; mem (CPU total)=4186.640625MB
INFO:root:[    2] Training loss: 0.55121445, Validation loss: 0.53420702, Gradient norm: 1.31990504
INFO:root:At the start of the epoch: mem (CPU python)=4464.5546875MB; mem (CPU total)=4208.421875MB
INFO:root:[    3] Training loss: 0.53079319, Validation loss: 0.52975259, Gradient norm: 0.65624882
INFO:root:At the start of the epoch: mem (CPU python)=4486.71875MB; mem (CPU total)=4230.56640625MB
INFO:root:[    4] Training loss: 0.52792937, Validation loss: 0.52428666, Gradient norm: 0.57474583
INFO:root:At the start of the epoch: mem (CPU python)=4508.11328125MB; mem (CPU total)=4251.2734375MB
INFO:root:[    5] Training loss: 0.51587561, Validation loss: 0.51345284, Gradient norm: 0.54382576
INFO:root:At the start of the epoch: mem (CPU python)=4529.328125MB; mem (CPU total)=4272.71875MB
INFO:root:[    6] Training loss: 0.50457583, Validation loss: 0.49270654, Gradient norm: 0.57266100
INFO:root:At the start of the epoch: mem (CPU python)=4550.53515625MB; mem (CPU total)=4293.94921875MB
INFO:root:[    7] Training loss: 0.46922440, Validation loss: 0.43376833, Gradient norm: 0.66179036
INFO:root:At the start of the epoch: mem (CPU python)=4571.7265625MB; mem (CPU total)=4315.203125MB
INFO:root:[    8] Training loss: 0.40546791, Validation loss: 0.37661352, Gradient norm: 0.82037753
INFO:root:At the start of the epoch: mem (CPU python)=4592.9140625MB; mem (CPU total)=4336.3515625MB
INFO:root:[    9] Training loss: 0.37360789, Validation loss: 0.35873467, Gradient norm: 1.15685617
INFO:root:At the start of the epoch: mem (CPU python)=4614.08203125MB; mem (CPU total)=4357.61328125MB
INFO:root:[   10] Training loss: 0.34973123, Validation loss: 0.34824523, Gradient norm: 1.40698289
INFO:root:At the start of the epoch: mem (CPU python)=4635.25MB; mem (CPU total)=4378.94140625MB
INFO:root:[   11] Training loss: 0.33401778, Validation loss: 0.33880766, Gradient norm: 1.44588043
INFO:root:At the start of the epoch: mem (CPU python)=4656.4140625MB; mem (CPU total)=4399.953125MB
INFO:root:[   12] Training loss: 0.32388714, Validation loss: 0.31329433, Gradient norm: 1.67912706
INFO:root:At the start of the epoch: mem (CPU python)=4677.5859375MB; mem (CPU total)=4420.8671875MB
INFO:root:[   13] Training loss: 0.31607037, Validation loss: 0.32082021, Gradient norm: 1.89202824
INFO:root:At the start of the epoch: mem (CPU python)=4698.76171875MB; mem (CPU total)=4442.3515625MB
INFO:root:[   14] Training loss: 0.30953975, Validation loss: 0.30280584, Gradient norm: 1.77913903
INFO:root:At the start of the epoch: mem (CPU python)=4719.9296875MB; mem (CPU total)=4463.91015625MB
INFO:root:[   15] Training loss: 0.30466473, Validation loss: 0.30443139, Gradient norm: 1.99151865
INFO:root:At the start of the epoch: mem (CPU python)=4741.09765625MB; mem (CPU total)=4484.52734375MB
INFO:root:[   16] Training loss: 0.29835966, Validation loss: 0.28877619, Gradient norm: 1.96517241
INFO:root:At the start of the epoch: mem (CPU python)=4762.265625MB; mem (CPU total)=4505.4765625MB
INFO:root:[   17] Training loss: 0.29561443, Validation loss: 0.28603406, Gradient norm: 2.13236253
INFO:root:At the start of the epoch: mem (CPU python)=4783.43359375MB; mem (CPU total)=4526.79296875MB
INFO:root:[   18] Training loss: 0.29034172, Validation loss: 0.28585009, Gradient norm: 2.04274660
INFO:root:At the start of the epoch: mem (CPU python)=4804.609375MB; mem (CPU total)=4547.9453125MB
INFO:root:[   19] Training loss: 0.29258637, Validation loss: 0.28537556, Gradient norm: 2.61561435
INFO:root:At the start of the epoch: mem (CPU python)=4825.77734375MB; mem (CPU total)=4570.08203125MB
INFO:root:[   20] Training loss: 0.29074965, Validation loss: 0.28310252, Gradient norm: 2.69501366
INFO:root:At the start of the epoch: mem (CPU python)=4846.953125MB; mem (CPU total)=4590.8984375MB
INFO:root:[   21] Training loss: 0.28699384, Validation loss: 0.27946998, Gradient norm: 2.62216615
INFO:root:At the start of the epoch: mem (CPU python)=4868.125MB; mem (CPU total)=4611.55078125MB
INFO:root:[   22] Training loss: 0.28826437, Validation loss: 0.28516007, Gradient norm: 2.77998408
INFO:root:At the start of the epoch: mem (CPU python)=4889.296875MB; mem (CPU total)=4632.41015625MB
INFO:root:[   23] Training loss: 0.28589606, Validation loss: 0.28508041, Gradient norm: 2.68007296
INFO:root:At the start of the epoch: mem (CPU python)=4910.46484375MB; mem (CPU total)=4654.09375MB
INFO:root:[   24] Training loss: 0.28604014, Validation loss: 0.27943773, Gradient norm: 2.93681404
INFO:root:At the start of the epoch: mem (CPU python)=4931.640625MB; mem (CPU total)=4675.18359375MB
INFO:root:[   25] Training loss: 0.28327342, Validation loss: 0.28484801, Gradient norm: 2.72597763
INFO:root:After finishing all epochs: mem (CPU python)=4952.859375MB; mem (CPU total)=4696.25390625MB
INFO:root:Training the model took 1467.68s.
INFO:root:Emptying the cuda cache took 0.072s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.36968
INFO:root:EnergyScoreValidation: 0.27877
INFO:root:CRPSValidation: 0.11483
INFO:root:Gaussian NLLValidation: -0.16705
INFO:root:CoverageValidation: 0.99585
INFO:root:IntervalWidthValidation: 1.20781
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.39892
INFO:root:EnergyScoreTest: 0.29352
INFO:root:CRPSTest: 0.1216
INFO:root:Gaussian NLLTest: -0.13793
INFO:root:CoverageTest: 0.99224
INFO:root:IntervalWidthTest: 1.19125
INFO:root:After validation: mem (CPU python)=4967.90234375MB; mem (CPU total)=4707.65625MB
INFO:root:###2 out of 2 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=4967.91015625MB; mem (CPU total)=4707.65234375MB
INFO:root:###1 out of 1 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 25, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=4967.91015625MB; mem (CPU total)=4707.65234375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 176160768
INFO:root:After setting up the model: mem (CPU python)=5004.13671875MB; mem (CPU total)=4743.8359375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=5004.13671875MB; mem (CPU total)=4744.328125MB
INFO:root:[    1] Training loss: 0.70267276, Validation loss: 0.55961026, Gradient norm: 3.00024700
INFO:root:At the start of the epoch: mem (CPU python)=5038.2734375MB; mem (CPU total)=4778.41015625MB
INFO:root:[    2] Training loss: 0.55121445, Validation loss: 0.53420702, Gradient norm: 1.31990504
INFO:root:At the start of the epoch: mem (CPU python)=5059.48046875MB; mem (CPU total)=4799.92578125MB
INFO:root:[    3] Training loss: 0.53079319, Validation loss: 0.52975259, Gradient norm: 0.65624882
INFO:root:At the start of the epoch: mem (CPU python)=5080.6640625MB; mem (CPU total)=4820.81640625MB
INFO:root:[    4] Training loss: 0.52792937, Validation loss: 0.52428666, Gradient norm: 0.57474583
INFO:root:At the start of the epoch: mem (CPU python)=5101.83984375MB; mem (CPU total)=4842.4453125MB
INFO:root:[    5] Training loss: 0.51587561, Validation loss: 0.51345284, Gradient norm: 0.54382576
INFO:root:At the start of the epoch: mem (CPU python)=5123.01953125MB; mem (CPU total)=4863.796875MB
INFO:root:[    6] Training loss: 0.50457583, Validation loss: 0.49270654, Gradient norm: 0.57266100
INFO:root:At the start of the epoch: mem (CPU python)=5144.1953125MB; mem (CPU total)=4885.2109375MB
INFO:root:[    7] Training loss: 0.46922440, Validation loss: 0.43376833, Gradient norm: 0.66179036
INFO:root:At the start of the epoch: mem (CPU python)=5165.4375MB; mem (CPU total)=4906.59765625MB
INFO:root:[    8] Training loss: 0.40546791, Validation loss: 0.37661352, Gradient norm: 0.82037753
INFO:root:At the start of the epoch: mem (CPU python)=5186.609375MB; mem (CPU total)=4933.25MB
INFO:root:[    9] Training loss: 0.37360789, Validation loss: 0.35873467, Gradient norm: 1.15685617
INFO:root:At the start of the epoch: mem (CPU python)=5208.03515625MB; mem (CPU total)=4954.69140625MB
INFO:root:[   10] Training loss: 0.34973123, Validation loss: 0.34824523, Gradient norm: 1.40698289
INFO:root:At the start of the epoch: mem (CPU python)=5229.203125MB; mem (CPU total)=4975.83203125MB
INFO:root:[   11] Training loss: 0.33401778, Validation loss: 0.33880766, Gradient norm: 1.44588043
INFO:root:At the start of the epoch: mem (CPU python)=5250.59765625MB; mem (CPU total)=4997.75390625MB
INFO:root:[   12] Training loss: 0.32388714, Validation loss: 0.31329433, Gradient norm: 1.67912706
INFO:root:At the start of the epoch: mem (CPU python)=5272.453125MB; mem (CPU total)=5019.46875MB
INFO:root:[   13] Training loss: 0.31607037, Validation loss: 0.32082021, Gradient norm: 1.89202824
INFO:root:At the start of the epoch: mem (CPU python)=5294.09765625MB; mem (CPU total)=5041.26953125MB
INFO:root:[   14] Training loss: 0.30953975, Validation loss: 0.30280584, Gradient norm: 1.77913903
INFO:root:At the start of the epoch: mem (CPU python)=5315.875MB; mem (CPU total)=5063.015625MB
INFO:root:[   15] Training loss: 0.30466473, Validation loss: 0.30443139, Gradient norm: 1.99151865
INFO:root:At the start of the epoch: mem (CPU python)=5337.2578125MB; mem (CPU total)=5084.19140625MB
INFO:root:[   16] Training loss: 0.29835966, Validation loss: 0.28877619, Gradient norm: 1.96517241
INFO:root:At the start of the epoch: mem (CPU python)=5358.421875MB; mem (CPU total)=5105.30859375MB
INFO:root:[   17] Training loss: 0.29561443, Validation loss: 0.28603406, Gradient norm: 2.13236253
INFO:root:At the start of the epoch: mem (CPU python)=5379.5859375MB; mem (CPU total)=5126.66015625MB
INFO:root:[   18] Training loss: 0.29034172, Validation loss: 0.28585009, Gradient norm: 2.04274660
INFO:root:At the start of the epoch: mem (CPU python)=5400.75MB; mem (CPU total)=5147.71875MB
INFO:root:[   19] Training loss: 0.29258637, Validation loss: 0.28537556, Gradient norm: 2.61561435
INFO:root:At the start of the epoch: mem (CPU python)=5421.9140625MB; mem (CPU total)=5168.828125MB
INFO:root:[   20] Training loss: 0.29074965, Validation loss: 0.28310252, Gradient norm: 2.69501366
INFO:root:At the start of the epoch: mem (CPU python)=5443.078125MB; mem (CPU total)=5189.484375MB
INFO:root:[   21] Training loss: 0.28699384, Validation loss: 0.27946998, Gradient norm: 2.62216615
INFO:root:At the start of the epoch: mem (CPU python)=5464.23828125MB; mem (CPU total)=5210.87109375MB
INFO:root:[   22] Training loss: 0.28826437, Validation loss: 0.28516007, Gradient norm: 2.77998408
INFO:root:At the start of the epoch: mem (CPU python)=5485.40234375MB; mem (CPU total)=5231.56640625MB
INFO:root:[   23] Training loss: 0.28589606, Validation loss: 0.28508041, Gradient norm: 2.68007296
INFO:root:At the start of the epoch: mem (CPU python)=5506.56640625MB; mem (CPU total)=5252.91796875MB
INFO:root:[   24] Training loss: 0.28604014, Validation loss: 0.27943773, Gradient norm: 2.93681404
INFO:root:At the start of the epoch: mem (CPU python)=5527.73046875MB; mem (CPU total)=5274.03515625MB
INFO:root:[   25] Training loss: 0.28327342, Validation loss: 0.28484801, Gradient norm: 2.72597763
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [0.0025]
INFO:root:At the start of the epoch: mem (CPU python)=5548.8984375MB; mem (CPU total)=5295.16015625MB
INFO:root:[   26] Training loss: 0.35211925, Validation loss: 0.34567231, Gradient norm: 2.39017253
INFO:root:At the start of the epoch: mem (CPU python)=5570.0625MB; mem (CPU total)=5315.47265625MB
INFO:root:[   27] Training loss: 0.34456111, Validation loss: 0.34146563, Gradient norm: 2.33080663
INFO:root:At the start of the epoch: mem (CPU python)=5591.2265625MB; mem (CPU total)=5336.81640625MB
INFO:root:[   28] Training loss: 0.34207670, Validation loss: 0.33942022, Gradient norm: 2.61601137
INFO:root:At the start of the epoch: mem (CPU python)=5612.38671875MB; mem (CPU total)=5357.87109375MB
INFO:root:[   29] Training loss: 0.34162597, Validation loss: 0.34622402, Gradient norm: 3.04612097
INFO:root:At the start of the epoch: mem (CPU python)=5633.55078125MB; mem (CPU total)=5378.4453125MB
INFO:root:[   30] Training loss: 0.34060950, Validation loss: 0.34160147, Gradient norm: 3.04878608
INFO:root:At the start of the epoch: mem (CPU python)=5654.71875MB; mem (CPU total)=5399.77734375MB
INFO:root:[   31] Training loss: 0.33988255, Validation loss: 0.34062145, Gradient norm: 3.31581172
INFO:root:At the start of the epoch: mem (CPU python)=5675.8828125MB; mem (CPU total)=5420.63671875MB
INFO:root:[   32] Training loss: 0.34022117, Validation loss: 0.34005060, Gradient norm: 3.49352419
INFO:root:At the start of the epoch: mem (CPU python)=5697.046875MB; mem (CPU total)=5441.609375MB
INFO:root:[   33] Training loss: 0.33993546, Validation loss: 0.33982942, Gradient norm: 3.86874328
INFO:root:At the start of the epoch: mem (CPU python)=5718.2109375MB; mem (CPU total)=5462.93359375MB
INFO:root:[   34] Training loss: 0.33745332, Validation loss: 0.34185077, Gradient norm: 3.83214554
INFO:root:At the start of the epoch: mem (CPU python)=5739.37890625MB; mem (CPU total)=5484.125MB
INFO:root:[   35] Training loss: 0.33856409, Validation loss: 0.33790365, Gradient norm: 4.08531078
INFO:root:At the start of the epoch: mem (CPU python)=5760.54296875MB; mem (CPU total)=5504.734375MB
INFO:root:[   36] Training loss: 0.33794213, Validation loss: 0.33723509, Gradient norm: 4.12113917
INFO:root:At the start of the epoch: mem (CPU python)=5781.70703125MB; mem (CPU total)=5525.703125MB
INFO:root:[   37] Training loss: 0.33885520, Validation loss: 0.35055343, Gradient norm: 4.38032340
INFO:root:At the start of the epoch: mem (CPU python)=5802.8671875MB; mem (CPU total)=5546.796875MB
INFO:root:[   38] Training loss: 0.33683185, Validation loss: 0.33463285, Gradient norm: 4.25839766
INFO:root:At the start of the epoch: mem (CPU python)=5824.02734375MB; mem (CPU total)=5568.03515625MB
INFO:root:[   39] Training loss: 0.33564720, Validation loss: 0.34028696, Gradient norm: 4.50167029
INFO:root:At the start of the epoch: mem (CPU python)=5845.19140625MB; mem (CPU total)=5589.609375MB
INFO:root:[   40] Training loss: 0.33529315, Validation loss: 0.33674000, Gradient norm: 4.43064369
INFO:root:At the start of the epoch: mem (CPU python)=5866.35546875MB; mem (CPU total)=5609.98046875MB
INFO:root:[   41] Training loss: 0.33505237, Validation loss: 0.32990217, Gradient norm: 4.50829972
INFO:root:At the start of the epoch: mem (CPU python)=5887.5234375MB; mem (CPU total)=5631.09765625MB
INFO:root:[   42] Training loss: 0.33523633, Validation loss: 0.33638697, Gradient norm: 4.55325558
INFO:root:At the start of the epoch: mem (CPU python)=5908.6875MB; mem (CPU total)=5653.328125MB
INFO:root:[   43] Training loss: 0.33434909, Validation loss: 0.33076231, Gradient norm: 4.90256244
INFO:root:At the start of the epoch: mem (CPU python)=5929.8515625MB; mem (CPU total)=5674.39453125MB
INFO:root:[   44] Training loss: 0.33430313, Validation loss: 0.33385836, Gradient norm: 4.76024699
INFO:root:At the start of the epoch: mem (CPU python)=5951.015625MB; mem (CPU total)=5695.25MB
INFO:root:[   45] Training loss: 0.33410339, Validation loss: 0.32954499, Gradient norm: 4.97477089
INFO:root:At the start of the epoch: mem (CPU python)=5972.1796875MB; mem (CPU total)=5716.21875MB
INFO:root:[   46] Training loss: 0.33260502, Validation loss: 0.32655217, Gradient norm: 4.60810399
INFO:root:At the start of the epoch: mem (CPU python)=5993.34375MB; mem (CPU total)=5737.77734375MB
INFO:root:[   47] Training loss: 0.33240747, Validation loss: 0.33407001, Gradient norm: 5.22806115
INFO:root:At the start of the epoch: mem (CPU python)=6014.50390625MB; mem (CPU total)=5758.96484375MB
INFO:root:[   48] Training loss: 0.33057911, Validation loss: 0.33567328, Gradient norm: 4.96824194
INFO:root:At the start of the epoch: mem (CPU python)=6035.671875MB; mem (CPU total)=5780.578125MB
INFO:root:[   49] Training loss: 0.33168955, Validation loss: 0.33157465, Gradient norm: 5.55337289
INFO:root:At the start of the epoch: mem (CPU python)=6056.8359375MB; mem (CPU total)=5801.78125MB
INFO:root:[   50] Training loss: 0.33133969, Validation loss: 0.32563501, Gradient norm: 5.16918306
INFO:root:After finishing all epochs: mem (CPU python)=6078.0MB; mem (CPU total)=5822.859375MB
INFO:root:Training the model took 3952.575s.
INFO:root:Emptying the cuda cache took 0.137s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.54529
INFO:root:EnergyScoreValidation: 0.38725
INFO:root:CRPSValidation: 0.1648
INFO:root:Gaussian NLLValidation: 0.10983
INFO:root:CoverageValidation: 0.96322
INFO:root:IntervalWidthValidation: 1.30813
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.36759
INFO:root:EnergyScoreTest: 0.2738
INFO:root:CRPSTest: 0.11339
INFO:root:Gaussian NLLTest: -0.21067
INFO:root:CoverageTest: 0.99529
INFO:root:IntervalWidthTest: 1.14024
INFO:root:After validation: mem (CPU python)=6078.7109375MB; mem (CPU total)=5781.3203125MB
