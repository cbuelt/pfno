INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=581.57421875MB; mem (CPU total)=4166.9453125MB
INFO:root:############### Starting experiment with config file sswe/sfno_timing2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=592.5078125MB; mem (CPU total)=4170.2578125MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 25, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=593.90234375MB; mem (CPU total)=4170.7421875MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2373.27734375MB; mem (CPU total)=5631.83984375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2373.27734375MB; mem (CPU total)=5640.20703125MB
INFO:root:[    1] Training loss: 0.67120468, Validation loss: 0.52713072, Gradient norm: 0.27689772
INFO:root:At the start of the epoch: mem (CPU python)=4571.44140625MB; mem (CPU total)=7302.91796875MB
INFO:root:[    2] Training loss: 0.53720434, Validation loss: 0.51964555, Gradient norm: 0.24210184
INFO:root:At the start of the epoch: mem (CPU python)=4595.3125MB; mem (CPU total)=7367.26171875MB
INFO:root:[    3] Training loss: 0.52914724, Validation loss: 0.51948241, Gradient norm: 0.16069638
INFO:root:At the start of the epoch: mem (CPU python)=4617.3046875MB; mem (CPU total)=7388.89453125MB
INFO:root:[    4] Training loss: 0.52650085, Validation loss: 0.51748364, Gradient norm: 0.17854914
INFO:root:At the start of the epoch: mem (CPU python)=4638.484375MB; mem (CPU total)=7409.7890625MB
INFO:root:[    5] Training loss: 0.52387167, Validation loss: 0.51093825, Gradient norm: 0.27262321
INFO:root:At the start of the epoch: mem (CPU python)=4659.67578125MB; mem (CPU total)=7431.703125MB
INFO:root:[    6] Training loss: 0.51741790, Validation loss: 0.50318290, Gradient norm: 0.33050300
INFO:root:At the start of the epoch: mem (CPU python)=4680.859375MB; mem (CPU total)=7454.4453125MB
INFO:root:[    7] Training loss: 0.51525702, Validation loss: 0.50011880, Gradient norm: 0.44468386
INFO:root:At the start of the epoch: mem (CPU python)=4703.53515625MB; mem (CPU total)=7476.07421875MB
INFO:root:[    8] Training loss: 0.50829892, Validation loss: 0.50690965, Gradient norm: 0.39085209
INFO:root:At the start of the epoch: mem (CPU python)=4725.08984375MB; mem (CPU total)=7497.734375MB
INFO:root:[    9] Training loss: 0.49557240, Validation loss: 0.46936368, Gradient norm: 0.50893490
INFO:root:At the start of the epoch: mem (CPU python)=4746.26171875MB; mem (CPU total)=7519.16015625MB
INFO:root:[   10] Training loss: 0.48384691, Validation loss: 0.44050026, Gradient norm: 0.76582869
INFO:root:At the start of the epoch: mem (CPU python)=4767.421875MB; mem (CPU total)=7540.30078125MB
INFO:root:[   11] Training loss: 0.47258598, Validation loss: 0.45200022, Gradient norm: 1.07895229
INFO:root:At the start of the epoch: mem (CPU python)=4788.5859375MB; mem (CPU total)=7561.59375MB
INFO:root:[   12] Training loss: 0.46600917, Validation loss: 0.45293315, Gradient norm: 1.01784703
INFO:root:At the start of the epoch: mem (CPU python)=4809.11328125MB; mem (CPU total)=7583.22265625MB
INFO:root:[   13] Training loss: 0.45652952, Validation loss: 0.42494761, Gradient norm: 1.14247477
INFO:root:At the start of the epoch: mem (CPU python)=4830.91796875MB; mem (CPU total)=7603.64453125MB
INFO:root:[   14] Training loss: 0.45363867, Validation loss: 0.41017478, Gradient norm: 1.20108184
INFO:root:At the start of the epoch: mem (CPU python)=4851.43359375MB; mem (CPU total)=7625.015625MB
INFO:root:[   15] Training loss: 0.45153498, Validation loss: 0.43027509, Gradient norm: 1.39449194
INFO:root:At the start of the epoch: mem (CPU python)=4872.98046875MB; mem (CPU total)=7647.38671875MB
INFO:root:[   16] Training loss: 0.44363307, Validation loss: 0.42316371, Gradient norm: 1.51688562
INFO:root:At the start of the epoch: mem (CPU python)=4894.31640625MB; mem (CPU total)=7667.7890625MB
INFO:root:[   17] Training loss: 0.44909242, Validation loss: 0.41514707, Gradient norm: 1.99227940
INFO:root:At the start of the epoch: mem (CPU python)=4915.12109375MB; mem (CPU total)=7690.37109375MB
INFO:root:[   18] Training loss: 0.43915173, Validation loss: 0.42294231, Gradient norm: 1.60185816
INFO:root:At the start of the epoch: mem (CPU python)=4936.671875MB; mem (CPU total)=7711.4296875MB
INFO:root:[   19] Training loss: 0.44496809, Validation loss: 0.40099061, Gradient norm: 2.09393995
INFO:root:At the start of the epoch: mem (CPU python)=4957.43359375MB; mem (CPU total)=7732.32421875MB
INFO:root:[   20] Training loss: 0.43716442, Validation loss: 0.39520631, Gradient norm: 1.90508881
INFO:root:At the start of the epoch: mem (CPU python)=4979.0546875MB; mem (CPU total)=7754.0MB
INFO:root:[   21] Training loss: 0.43859293, Validation loss: 0.39584614, Gradient norm: 2.10979182
INFO:root:At the start of the epoch: mem (CPU python)=4999.91796875MB; mem (CPU total)=7776.2421875MB
INFO:root:[   22] Training loss: 0.43088046, Validation loss: 0.39754653, Gradient norm: 2.07900525
INFO:root:At the start of the epoch: mem (CPU python)=5021.80859375MB; mem (CPU total)=7798.43359375MB
INFO:root:[   23] Training loss: 0.43453479, Validation loss: 0.40829213, Gradient norm: 2.28170827
INFO:root:At the start of the epoch: mem (CPU python)=5043.13671875MB; mem (CPU total)=7819.26171875MB
INFO:root:[   24] Training loss: 0.43348281, Validation loss: 0.38403509, Gradient norm: 2.36013282
INFO:root:At the start of the epoch: mem (CPU python)=5063.7109375MB; mem (CPU total)=7839.83203125MB
INFO:root:[   25] Training loss: 0.42870711, Validation loss: 0.38935934, Gradient norm: 2.23705911
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [0.0025]
INFO:root:At the start of the epoch: mem (CPU python)=5085.63671875MB; mem (CPU total)=7861.796875MB
INFO:root:[   26] Training loss: 0.48828294, Validation loss: 0.44246545, Gradient norm: 2.01605195
INFO:root:At the start of the epoch: mem (CPU python)=5106.80078125MB; mem (CPU total)=7882.28125MB
INFO:root:[   27] Training loss: 0.47901409, Validation loss: 0.44161501, Gradient norm: 2.12272120
INFO:root:At the start of the epoch: mem (CPU python)=5127.69140625MB; mem (CPU total)=7903.4609375MB
INFO:root:[   28] Training loss: 0.47453288, Validation loss: 0.44913682, Gradient norm: 2.32851999
INFO:root:At the start of the epoch: mem (CPU python)=5148.546875MB; mem (CPU total)=7925.484375MB
INFO:root:[   29] Training loss: 0.47553433, Validation loss: 0.43201699, Gradient norm: 2.95910334
INFO:root:At the start of the epoch: mem (CPU python)=5169.75MB; mem (CPU total)=7946.5625MB
INFO:root:[   30] Training loss: 0.47490165, Validation loss: 0.43534891, Gradient norm: 2.78575343
INFO:root:At the start of the epoch: mem (CPU python)=5191.375MB; mem (CPU total)=7968.37890625MB
INFO:root:[   31] Training loss: 0.47526232, Validation loss: 0.44460952, Gradient norm: 3.22433397
INFO:root:At the start of the epoch: mem (CPU python)=5211.99609375MB; mem (CPU total)=7989.26953125MB
INFO:root:[   32] Training loss: 0.47284595, Validation loss: 0.44781959, Gradient norm: 3.34241341
INFO:root:At the start of the epoch: mem (CPU python)=5233.7421875MB; mem (CPU total)=8010.4375MB
INFO:root:[   33] Training loss: 0.47296921, Validation loss: 0.44396956, Gradient norm: 3.40877561
INFO:root:At the start of the epoch: mem (CPU python)=5254.73046875MB; mem (CPU total)=8032.20703125MB
INFO:root:[   34] Training loss: 0.47367712, Validation loss: 0.43490402, Gradient norm: 3.60756411
INFO:root:At the start of the epoch: mem (CPU python)=5275.7421875MB; mem (CPU total)=8053.25MB
INFO:root:[   35] Training loss: 0.47150655, Validation loss: 0.43086124, Gradient norm: 3.38835940
INFO:root:At the start of the epoch: mem (CPU python)=5297.15234375MB; mem (CPU total)=8074.21484375MB
INFO:root:[   36] Training loss: 0.47391524, Validation loss: 0.43089212, Gradient norm: 3.91640389
INFO:root:At the start of the epoch: mem (CPU python)=5317.57421875MB; mem (CPU total)=8096.5546875MB
INFO:root:[   37] Training loss: 0.47255950, Validation loss: 0.43115242, Gradient norm: 3.77789793
INFO:root:At the start of the epoch: mem (CPU python)=5339.56640625MB; mem (CPU total)=8116.48046875MB
INFO:root:[   38] Training loss: 0.47198571, Validation loss: 0.45353348, Gradient norm: 3.80787408
INFO:root:At the start of the epoch: mem (CPU python)=5360.02734375MB; mem (CPU total)=8138.9921875MB
INFO:root:[   39] Training loss: 0.47672511, Validation loss: 0.43298386, Gradient norm: 5.09601267
INFO:root:At the start of the epoch: mem (CPU python)=5381.546875MB; mem (CPU total)=8160.6796875MB
INFO:root:[   40] Training loss: 0.47143845, Validation loss: 0.43724766, Gradient norm: 3.96774157
INFO:root:At the start of the epoch: mem (CPU python)=5402.90234375MB; mem (CPU total)=8182.24609375MB
INFO:root:[   41] Training loss: 0.47297346, Validation loss: 0.43907534, Gradient norm: 4.39275554
INFO:root:At the start of the epoch: mem (CPU python)=5423.66796875MB; mem (CPU total)=8203.34765625MB
INFO:root:[   42] Training loss: 0.47417736, Validation loss: 0.42876329, Gradient norm: 5.01710232
INFO:root:At the start of the epoch: mem (CPU python)=5445.421875MB; mem (CPU total)=8223.8984375MB
INFO:root:[   43] Training loss: 0.47446851, Validation loss: 0.43733113, Gradient norm: 4.81352054
INFO:root:At the start of the epoch: mem (CPU python)=5465.90625MB; mem (CPU total)=8246.30859375MB
INFO:root:[   44] Training loss: 0.47076231, Validation loss: 0.44569839, Gradient norm: 4.59158140
INFO:root:At the start of the epoch: mem (CPU python)=5487.6484375MB; mem (CPU total)=8267.75MB
INFO:root:[   45] Training loss: 0.47517672, Validation loss: 0.43119393, Gradient norm: 5.52527765
INFO:root:At the start of the epoch: mem (CPU python)=5527.8671875MB; mem (CPU total)=8308.23828125MB
INFO:root:[   46] Training loss: 0.47406853, Validation loss: 0.44041160, Gradient norm: 5.32119441
INFO:root:At the start of the epoch: mem (CPU python)=5548.9453125MB; mem (CPU total)=8329.7890625MB
INFO:root:[   47] Training loss: 0.47361541, Validation loss: 0.43028650, Gradient norm: 4.61947144
INFO:root:At the start of the epoch: mem (CPU python)=5549.703125MB; mem (CPU total)=8329.98046875MB
INFO:root:[   48] Training loss: 0.47714680, Validation loss: 0.44341982, Gradient norm: 5.87738166
INFO:root:At the start of the epoch: mem (CPU python)=5569.1796875MB; mem (CPU total)=8351.5234375MB
INFO:root:[   49] Training loss: 0.47717427, Validation loss: 0.44195893, Gradient norm: 5.96933453
INFO:root:At the start of the epoch: mem (CPU python)=5590.953125MB; mem (CPU total)=8372.58203125MB
INFO:root:[   50] Training loss: 0.47205776, Validation loss: 0.42927989, Gradient norm: 5.02165023
INFO:root:After finishing all epochs: mem (CPU python)=5613.015625MB; mem (CPU total)=8395.16015625MB
INFO:root:Training the model took 2030.754s.
INFO:root:Emptying the cuda cache took 0.085s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.67725
INFO:root:EnergyScoreValidation: 0.47735
INFO:root:CRPSValidation: 0.27542
INFO:root:Gaussian NLLValidation: 67857691368.82278
INFO:root:CoverageValidation: 0.01527
INFO:root:IntervalWidthValidation: 0.15554
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.55542
INFO:root:EnergyScoreTest: 0.39122
INFO:root:CRPSTest: 0.22408
INFO:root:Gaussian NLLTest: 46245965987.84
INFO:root:CoverageTest: 0.01243
INFO:root:IntervalWidthTest: 0.11293
INFO:root:After validation: mem (CPU python)=6157.2890625MB; mem (CPU total)=8409.5MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 25, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=6157.2890625MB; mem (CPU total)=8409.37109375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 641728512
INFO:root:After setting up the model: mem (CPU python)=6157.2890625MB; mem (CPU total)=8421.05078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8422.0078125MB
INFO:root:[    1] Training loss: 0.95630147, Validation loss: 0.77293873, Gradient norm: 0.49298167
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8444.58984375MB
INFO:root:[    2] Training loss: 0.76175177, Validation loss: 0.73573867, Gradient norm: 0.22995547
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8464.5078125MB
INFO:root:[    3] Training loss: 0.75173234, Validation loss: 0.73921026, Gradient norm: 0.34857714
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8486.89453125MB
INFO:root:[    4] Training loss: 0.74863972, Validation loss: 0.73647345, Gradient norm: 0.44208220
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8508.546875MB
INFO:root:[    5] Training loss: 0.74710880, Validation loss: 0.73198787, Gradient norm: 0.58484345
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8529.203125MB
INFO:root:[    6] Training loss: 0.74400860, Validation loss: 0.72139471, Gradient norm: 0.79122007
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8550.60546875MB
INFO:root:[    7] Training loss: 0.73911964, Validation loss: 0.71734369, Gradient norm: 0.87002296
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8511.94140625MB
INFO:root:[    8] Training loss: 0.72932052, Validation loss: 0.71663932, Gradient norm: 0.88263126
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8591.88671875MB
INFO:root:[    9] Training loss: 0.72898561, Validation loss: 0.71424168, Gradient norm: 1.18181978
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8613.92578125MB
INFO:root:[   10] Training loss: 0.72737065, Validation loss: 0.69158827, Gradient norm: 1.52530967
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8634.984375MB
INFO:root:[   11] Training loss: 0.70842014, Validation loss: 0.69389832, Gradient norm: 1.45178633
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8657.109375MB
INFO:root:[   12] Training loss: 0.70265788, Validation loss: 0.66339860, Gradient norm: 1.96948788
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8678.50390625MB
INFO:root:[   13] Training loss: 0.68738241, Validation loss: 0.62825818, Gradient norm: 1.52395768
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8699.890625MB
INFO:root:[   14] Training loss: 0.67155085, Validation loss: 0.62913372, Gradient norm: 2.04573008
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8721.4609375MB
INFO:root:[   15] Training loss: 0.66334930, Validation loss: 0.61393403, Gradient norm: 1.93295223
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8741.37890625MB
INFO:root:[   16] Training loss: 0.65896061, Validation loss: 0.60779679, Gradient norm: 2.43514745
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8763.01171875MB
INFO:root:[   17] Training loss: 0.65489726, Validation loss: 0.60267143, Gradient norm: 2.64021303
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8783.90625MB
INFO:root:[   18] Training loss: 0.64738124, Validation loss: 0.61621785, Gradient norm: 2.51399993
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8805.296875MB
INFO:root:[   19] Training loss: 0.64136172, Validation loss: 0.58679593, Gradient norm: 2.44481378
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8826.34765625MB
INFO:root:[   20] Training loss: 0.63810422, Validation loss: 0.60822401, Gradient norm: 2.92124228
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8847.48046875MB
INFO:root:[   21] Training loss: 0.63782814, Validation loss: 0.59230114, Gradient norm: 3.17175512
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8869.38671875MB
INFO:root:[   22] Training loss: 0.62690979, Validation loss: 0.59893089, Gradient norm: 2.92275355
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8889.9140625MB
INFO:root:[   23] Training loss: 0.63565403, Validation loss: 0.61301020, Gradient norm: 3.44439621
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8911.80078125MB
INFO:root:[   24] Training loss: 0.62237112, Validation loss: 0.56113231, Gradient norm: 3.06968463
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8932.44921875MB
INFO:root:[   25] Training loss: 0.62613258, Validation loss: 0.57007267, Gradient norm: 3.36025083
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [0.0025]
INFO:root:At the start of the epoch: mem (CPU python)=6157.2890625MB; mem (CPU total)=8954.3359375MB
INFO:root:[   26] Training loss: 0.70104431, Validation loss: 0.63647713, Gradient norm: 3.14019522
INFO:root:At the start of the epoch: mem (CPU python)=6171.171875MB; mem (CPU total)=8975.34765625MB
INFO:root:[   27] Training loss: 0.68607518, Validation loss: 0.63032895, Gradient norm: 2.80556580
INFO:root:At the start of the epoch: mem (CPU python)=6193.125MB; mem (CPU total)=8996.4765625MB
INFO:root:[   28] Training loss: 0.68211999, Validation loss: 0.62969609, Gradient norm: 2.96149468
INFO:root:At the start of the epoch: mem (CPU python)=6213.7890625MB; mem (CPU total)=9017.84375MB
INFO:root:[   29] Training loss: 0.68123198, Validation loss: 0.62438858, Gradient norm: 3.09294922
INFO:root:At the start of the epoch: mem (CPU python)=6235.03125MB; mem (CPU total)=9039.23046875MB
INFO:root:[   30] Training loss: 0.68048087, Validation loss: 0.62181998, Gradient norm: 4.09150211
INFO:root:At the start of the epoch: mem (CPU python)=6256.62109375MB; mem (CPU total)=9060.36328125MB
INFO:root:[   31] Training loss: 0.68044451, Validation loss: 0.62407351, Gradient norm: 4.80632471
INFO:root:At the start of the epoch: mem (CPU python)=6277.78515625MB; mem (CPU total)=9082.71875MB
INFO:root:[   32] Training loss: 0.68212326, Validation loss: 0.61741617, Gradient norm: 4.74370769
INFO:root:At the start of the epoch: mem (CPU python)=6298.890625MB; mem (CPU total)=9103.109375MB
INFO:root:[   33] Training loss: 0.68076057, Validation loss: 0.62636486, Gradient norm: 5.08658090
INFO:root:At the start of the epoch: mem (CPU python)=6319.421875MB; mem (CPU total)=9125.21875MB
INFO:root:[   34] Training loss: 0.68018759, Validation loss: 0.61980283, Gradient norm: 4.98086966
INFO:root:At the start of the epoch: mem (CPU python)=6341.24609375MB; mem (CPU total)=9146.4140625MB
INFO:root:[   35] Training loss: 0.67896103, Validation loss: 0.62823732, Gradient norm: 5.66064019
INFO:root:At the start of the epoch: mem (CPU python)=6362.07421875MB; mem (CPU total)=9167.77734375MB
INFO:root:[   36] Training loss: 0.68081802, Validation loss: 0.62399035, Gradient norm: 5.35621645
INFO:root:At the start of the epoch: mem (CPU python)=6382.94140625MB; mem (CPU total)=9189.1640625MB
INFO:root:[   37] Training loss: 0.67765782, Validation loss: 0.62098937, Gradient norm: 5.87921901
INFO:root:At the start of the epoch: mem (CPU python)=6404.76953125MB; mem (CPU total)=9211.24609375MB
INFO:root:[   38] Training loss: 0.67803943, Validation loss: 0.64224387, Gradient norm: 6.15131967
INFO:root:At the start of the epoch: mem (CPU python)=6425.93359375MB; mem (CPU total)=9232.83203125MB
INFO:root:[   39] Training loss: 0.67940950, Validation loss: 0.63703868, Gradient norm: 6.14520919
INFO:root:At the start of the epoch: mem (CPU python)=6447.1015625MB; mem (CPU total)=9253.90625MB
INFO:root:[   40] Training loss: 0.67948453, Validation loss: 0.62035097, Gradient norm: 6.51932751
INFO:root:At the start of the epoch: mem (CPU python)=6467.5546875MB; mem (CPU total)=9275.27734375MB
INFO:root:[   41] Training loss: 0.67934193, Validation loss: 0.62187879, Gradient norm: 6.64076727
INFO:root:At the start of the epoch: mem (CPU python)=6489.15234375MB; mem (CPU total)=9296.375MB
INFO:root:[   42] Training loss: 0.67535480, Validation loss: 0.62268273, Gradient norm: 6.52511459
INFO:root:At the start of the epoch: mem (CPU python)=6510.34375MB; mem (CPU total)=9317.0625MB
INFO:root:[   43] Training loss: 0.67459433, Validation loss: 0.63084242, Gradient norm: 6.09642014
INFO:root:At the start of the epoch: mem (CPU python)=6531.21484375MB; mem (CPU total)=9337.88671875MB
INFO:root:[   44] Training loss: 0.67898363, Validation loss: 0.61781161, Gradient norm: 7.87447117
INFO:root:At the start of the epoch: mem (CPU python)=6552.84765625MB; mem (CPU total)=9359.01953125MB
INFO:root:[   45] Training loss: 0.67663963, Validation loss: 0.61320304, Gradient norm: 6.99447047
INFO:root:At the start of the epoch: mem (CPU python)=6573.23046875MB; mem (CPU total)=9380.38671875MB
INFO:root:[   46] Training loss: 0.68179292, Validation loss: 0.61855322, Gradient norm: 8.04057055
INFO:root:At the start of the epoch: mem (CPU python)=6595.25MB; mem (CPU total)=9401.515625MB
INFO:root:[   47] Training loss: 0.67859439, Validation loss: 0.61126832, Gradient norm: 7.39720881
INFO:root:At the start of the epoch: mem (CPU python)=6616.21484375MB; mem (CPU total)=9422.43359375MB
INFO:root:[   48] Training loss: 0.67549196, Validation loss: 0.61581365, Gradient norm: 7.77596953
INFO:root:At the start of the epoch: mem (CPU python)=6637.16015625MB; mem (CPU total)=9444.828125MB
INFO:root:[   49] Training loss: 0.67640720, Validation loss: 0.61460498, Gradient norm: 6.81151645
INFO:root:At the start of the epoch: mem (CPU python)=6658.484375MB; mem (CPU total)=9466.69140625MB
INFO:root:[   50] Training loss: 0.67431243, Validation loss: 0.62072179, Gradient norm: 7.60900789
INFO:root:After finishing all epochs: mem (CPU python)=6679.0390625MB; mem (CPU total)=9488.07421875MB
INFO:root:Training the model took 1531.036s.
INFO:root:Emptying the cuda cache took 0.069s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.68783
INFO:root:EnergyScoreValidation: 0.55531
INFO:root:CRPSValidation: 0.23424
INFO:root:Gaussian NLLValidation: 4.28721
INFO:root:CoverageValidation: 0.5821
INFO:root:IntervalWidthValidation: 0.52775
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.55117
INFO:root:EnergyScoreTest: 0.42341
INFO:root:CRPSTest: 0.1804
INFO:root:Gaussian NLLTest: 1.9742
INFO:root:CoverageTest: 0.68898
INFO:root:IntervalWidthTest: 0.56876
INFO:root:After validation: mem (CPU python)=7007.8984375MB; mem (CPU total)=9729.44140625MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 64, 'n_epochs': 25, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=7007.8984375MB; mem (CPU total)=9729.64453125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 593494016
INFO:root:After setting up the model: mem (CPU python)=7056.56640625MB; mem (CPU total)=9730.3828125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=7056.56640625MB; mem (CPU total)=9730.3828125MB
INFO:root:[    1] Training loss: 0.95630147, Validation loss: 0.79370273, Gradient norm: 0.49298167
INFO:root:At the start of the epoch: mem (CPU python)=7077.46484375MB; mem (CPU total)=9752.453125MB
INFO:root:[    2] Training loss: 0.76189251, Validation loss: 0.75507051, Gradient norm: 0.23118451
INFO:root:At the start of the epoch: mem (CPU python)=7098.51171875MB; mem (CPU total)=9773.1015625MB
INFO:root:[    3] Training loss: 0.75102830, Validation loss: 0.74883348, Gradient norm: 0.33090968
INFO:root:At the start of the epoch: mem (CPU python)=7119.80859375MB; mem (CPU total)=9794.76953125MB
INFO:root:[    4] Training loss: 0.75092442, Validation loss: 0.74624134, Gradient norm: 0.51651215
INFO:root:At the start of the epoch: mem (CPU python)=7140.97265625MB; mem (CPU total)=9815.91796875MB
INFO:root:[    5] Training loss: 0.74585498, Validation loss: 0.74471752, Gradient norm: 0.48834879
INFO:root:At the start of the epoch: mem (CPU python)=7161.51953125MB; mem (CPU total)=9837.12890625MB
INFO:root:[    6] Training loss: 0.74445822, Validation loss: 0.73450796, Gradient norm: 0.81699694
INFO:root:At the start of the epoch: mem (CPU python)=7183.15234375MB; mem (CPU total)=9857.80859375MB
INFO:root:[    7] Training loss: 0.73362529, Validation loss: 0.72891181, Gradient norm: 0.82047204
INFO:root:At the start of the epoch: mem (CPU python)=7203.984375MB; mem (CPU total)=9879.203125MB
INFO:root:[    8] Training loss: 0.73765592, Validation loss: 0.73236372, Gradient norm: 1.18841287
INFO:root:At the start of the epoch: mem (CPU python)=7225.19921875MB; mem (CPU total)=9901.3359375MB
INFO:root:[    9] Training loss: 0.72946733, Validation loss: 0.74184325, Gradient norm: 1.17221614
INFO:root:At the start of the epoch: mem (CPU python)=7246.42578125MB; mem (CPU total)=9922.72265625MB
INFO:root:[   10] Training loss: 0.72652700, Validation loss: 0.70692854, Gradient norm: 1.35802563
INFO:root:At the start of the epoch: mem (CPU python)=7267.4375MB; mem (CPU total)=9943.3671875MB
INFO:root:[   11] Training loss: 0.70838707, Validation loss: 0.69375709, Gradient norm: 1.56946361
INFO:root:At the start of the epoch: mem (CPU python)=7289.12109375MB; mem (CPU total)=9964.69921875MB
INFO:root:[   12] Training loss: 0.69528473, Validation loss: 0.69477647, Gradient norm: 1.42966814
INFO:root:At the start of the epoch: mem (CPU python)=7309.7578125MB; mem (CPU total)=9986.82421875MB
INFO:root:[   13] Training loss: 0.68391287, Validation loss: 0.68688446, Gradient norm: 1.80977977
INFO:root:At the start of the epoch: mem (CPU python)=7331.41796875MB; mem (CPU total)=10006.98828125MB
INFO:root:[   14] Training loss: 0.66439056, Validation loss: 0.66591466, Gradient norm: 1.89201474
INFO:root:At the start of the epoch: mem (CPU python)=7352.13671875MB; mem (CPU total)=10028.12890625MB
INFO:root:[   15] Training loss: 0.65998931, Validation loss: 0.65720502, Gradient norm: 2.46907231
INFO:root:At the start of the epoch: mem (CPU python)=7373.51171875MB; mem (CPU total)=10049.5234375MB
INFO:root:[   16] Training loss: 0.65244239, Validation loss: 0.64677302, Gradient norm: 2.28385971
INFO:root:At the start of the epoch: mem (CPU python)=7394.8671875MB; mem (CPU total)=10070.90625MB
INFO:root:[   17] Training loss: 0.65015357, Validation loss: 0.63831782, Gradient norm: 2.34513693
INFO:root:At the start of the epoch: mem (CPU python)=7415.51171875MB; mem (CPU total)=10092.046875MB
INFO:root:[   18] Training loss: 0.63722527, Validation loss: 0.65571598, Gradient norm: 2.58021157
INFO:root:At the start of the epoch: mem (CPU python)=7437.15234375MB; mem (CPU total)=10115.25390625MB
INFO:root:[   19] Training loss: 0.64083147, Validation loss: 0.62141559, Gradient norm: 2.59346358
INFO:root:At the start of the epoch: mem (CPU python)=7457.70703125MB; mem (CPU total)=10136.4921875MB
INFO:root:[   20] Training loss: 0.62177630, Validation loss: 0.63310202, Gradient norm: 2.18316657
INFO:root:At the start of the epoch: mem (CPU python)=7479.18359375MB; mem (CPU total)=10159.0625MB
INFO:root:[   21] Training loss: 0.63028497, Validation loss: 0.62623247, Gradient norm: 3.35683949
INFO:root:At the start of the epoch: mem (CPU python)=7500.54296875MB; mem (CPU total)=10192.41796875MB
INFO:root:[   22] Training loss: 0.62261862, Validation loss: 0.62150024, Gradient norm: 2.92298573
INFO:root:At the start of the epoch: mem (CPU python)=7532.7578125MB; mem (CPU total)=10213.1796875MB
INFO:root:[   23] Training loss: 0.63016598, Validation loss: 0.61383710, Gradient norm: 3.27507227
INFO:root:At the start of the epoch: mem (CPU python)=7554.2265625MB; mem (CPU total)=10233.48828125MB
INFO:root:[   24] Training loss: 0.61698414, Validation loss: 0.62237744, Gradient norm: 2.85394105
INFO:root:At the start of the epoch: mem (CPU python)=7574.85546875MB; mem (CPU total)=10255.85546875MB
INFO:root:[   25] Training loss: 0.61391740, Validation loss: 0.60927021, Gradient norm: 3.20456468
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [0.0025]
INFO:root:At the start of the epoch: mem (CPU python)=7596.76171875MB; mem (CPU total)=7153.14453125MB
INFO:root:[   26] Training loss: 0.68655449, Validation loss: 0.67787698, Gradient norm: 2.95441152
INFO:root:At the start of the epoch: mem (CPU python)=7617.15234375MB; mem (CPU total)=7174.29296875MB
INFO:root:[   27] Training loss: 0.67786401, Validation loss: 0.67410035, Gradient norm: 2.67300588
INFO:root:At the start of the epoch: mem (CPU python)=7638.703125MB; mem (CPU total)=7194.92578125MB
INFO:root:[   28] Training loss: 0.67829222, Validation loss: 0.67337240, Gradient norm: 2.95029357
INFO:root:At the start of the epoch: mem (CPU python)=7660.15234375MB; mem (CPU total)=7216.29296875MB
INFO:root:[   29] Training loss: 0.67517622, Validation loss: 0.66718769, Gradient norm: 4.17231702
INFO:root:At the start of the epoch: mem (CPU python)=7680.88671875MB; mem (CPU total)=7237.1796875MB
INFO:root:[   30] Training loss: 0.67466367, Validation loss: 0.67172179, Gradient norm: 4.38432447
INFO:root:At the start of the epoch: mem (CPU python)=7702.4609375MB; mem (CPU total)=7258.0546875MB
INFO:root:[   31] Training loss: 0.68313157, Validation loss: 0.67310132, Gradient norm: 5.04138619
INFO:root:At the start of the epoch: mem (CPU python)=7722.94140625MB; mem (CPU total)=7280.41796875MB
INFO:root:[   32] Training loss: 0.67413536, Validation loss: 0.68313179, Gradient norm: 4.35286509
INFO:root:At the start of the epoch: mem (CPU python)=7744.8359375MB; mem (CPU total)=7300.109375MB
INFO:root:[   33] Training loss: 0.67490649, Validation loss: 0.68393425, Gradient norm: 4.54462586
INFO:root:At the start of the epoch: mem (CPU python)=7765.69140625MB; mem (CPU total)=7321.98046875MB
INFO:root:[   34] Training loss: 0.67504202, Validation loss: 0.67692802, Gradient norm: 5.35773699
INFO:root:At the start of the epoch: mem (CPU python)=7786.703125MB; mem (CPU total)=7343.359375MB
INFO:root:[   35] Training loss: 0.67361963, Validation loss: 0.67638742, Gradient norm: 5.76300987
INFO:root:At the start of the epoch: mem (CPU python)=7808.23828125MB; mem (CPU total)=7363.9921875MB
INFO:root:[   36] Training loss: 0.67209723, Validation loss: 0.67324531, Gradient norm: 5.79657948
INFO:root:At the start of the epoch: mem (CPU python)=7828.8125MB; mem (CPU total)=7385.5859375MB
INFO:root:[   37] Training loss: 0.67418900, Validation loss: 0.67953547, Gradient norm: 6.09966195
INFO:root:At the start of the epoch: mem (CPU python)=7850.7421875MB; mem (CPU total)=7406.3984375MB
INFO:root:[   38] Training loss: 0.67266038, Validation loss: 0.66794845, Gradient norm: 5.93546166
INFO:root:At the start of the epoch: mem (CPU python)=7870.9140625MB; mem (CPU total)=7428.0234375MB
INFO:root:[   39] Training loss: 0.67224362, Validation loss: 0.67894225, Gradient norm: 5.88785462
INFO:root:At the start of the epoch: mem (CPU python)=7892.44140625MB; mem (CPU total)=7450.140625MB
INFO:root:[   40] Training loss: 0.67525051, Validation loss: 0.66532814, Gradient norm: 7.09538806
INFO:root:At the start of the epoch: mem (CPU python)=7913.3125MB; mem (CPU total)=7470.2890625MB
INFO:root:[   41] Training loss: 0.67185294, Validation loss: 0.67512547, Gradient norm: 6.39516803
INFO:root:At the start of the epoch: mem (CPU python)=7935.1015625MB; mem (CPU total)=7491.3359375MB
INFO:root:[   42] Training loss: 0.67112047, Validation loss: 0.67660815, Gradient norm: 6.71566673
INFO:root:At the start of the epoch: mem (CPU python)=7956.171875MB; mem (CPU total)=7512.71875MB
INFO:root:[   43] Training loss: 0.67406830, Validation loss: 0.68284418, Gradient norm: 7.71830450
INFO:root:At the start of the epoch: mem (CPU python)=7977.109375MB; mem (CPU total)=7533.97265625MB
INFO:root:[   44] Training loss: 0.67627311, Validation loss: 0.67690837, Gradient norm: 7.60996835
INFO:root:At the start of the epoch: mem (CPU python)=7998.18359375MB; mem (CPU total)=7557.69921875MB
INFO:root:[   45] Training loss: 0.67091241, Validation loss: 0.67902408, Gradient norm: 7.37725142
INFO:root:At the start of the epoch: mem (CPU python)=8019.609375MB; mem (CPU total)=7578.47265625MB
INFO:root:[   46] Training loss: 0.67391206, Validation loss: 0.68447911, Gradient norm: 7.54750036
INFO:root:At the start of the epoch: mem (CPU python)=8040.4765625MB; mem (CPU total)=7599.61328125MB
INFO:root:[   47] Training loss: 0.67205424, Validation loss: 0.65808059, Gradient norm: 7.58882964
INFO:root:At the start of the epoch: mem (CPU python)=8061.66796875MB; mem (CPU total)=7620.12890625MB
INFO:root:[   48] Training loss: 0.67425011, Validation loss: 0.67044843, Gradient norm: 8.26187558
INFO:root:At the start of the epoch: mem (CPU python)=8083.12109375MB; mem (CPU total)=7641.51953125MB
INFO:root:[   49] Training loss: 0.67099614, Validation loss: 0.66820071, Gradient norm: 7.48566741
INFO:root:At the start of the epoch: mem (CPU python)=8104.73046875MB; mem (CPU total)=7663.5234375MB
INFO:root:[   50] Training loss: 0.67009117, Validation loss: 0.68034198, Gradient norm: 7.58234481
INFO:root:After finishing all epochs: mem (CPU python)=8125.89453125MB; mem (CPU total)=7683.8984375MB
INFO:root:Training the model took 1593.994s.
INFO:root:Emptying the cuda cache took 0.064s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.67309
INFO:root:EnergyScoreValidation: 0.55419
INFO:root:CRPSValidation: 0.22986
INFO:root:Gaussian NLLValidation: 3.10467
INFO:root:CoverageValidation: 0.51663
INFO:root:IntervalWidthValidation: 0.4509
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.53921
INFO:root:EnergyScoreTest: 0.42069
INFO:root:CRPSTest: 0.17326
INFO:root:Gaussian NLLTest: 1.12719
INFO:root:CoverageTest: 0.66579
INFO:root:IntervalWidthTest: 0.4986
INFO:root:After validation: mem (CPU python)=8684.77734375MB; mem (CPU total)=7690.75390625MB
