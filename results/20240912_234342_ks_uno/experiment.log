INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=573.12890625MB; mem (CPU total)=1099.31640625MB
INFO:root:############### Starting experiment with config file ks/uno2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12452.31640625MB; mem (CPU total)=1121.1796875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12452.31640625MB; mem (CPU total)=1121.1796875MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=12452.31640625MB; mem (CPU total)=2482.265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=2491.140625MB
INFO:root:[    1] Training loss: 1.00800710, Validation loss: 0.99444890, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4210.45703125MB
INFO:root:[    2] Training loss: 0.98613820, Validation loss: 0.98339899, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4249.13671875MB
INFO:root:[    3] Training loss: 0.98006057, Validation loss: 0.97969251, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4287.67578125MB
INFO:root:[    4] Training loss: 0.97660448, Validation loss: 0.97684155, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4326.10546875MB
INFO:root:[    5] Training loss: 0.97371071, Validation loss: 0.97396675, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4364.04296875MB
INFO:root:[    6] Training loss: 0.97192743, Validation loss: 0.97321699, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4402.5078125MB
INFO:root:[    7] Training loss: 0.97062567, Validation loss: 0.97147880, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4440.890625MB
INFO:root:[    8] Training loss: 0.96953272, Validation loss: 0.97011752, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4478.3984375MB
INFO:root:[    9] Training loss: 0.96854275, Validation loss: 0.96938885, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4527.77734375MB
INFO:root:[   10] Training loss: 0.96770738, Validation loss: 0.96851482, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4566.34765625MB
INFO:root:[   11] Training loss: 0.96709442, Validation loss: 0.96753222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4604.27734375MB
INFO:root:[   12] Training loss: 0.96610536, Validation loss: 0.96685394, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4642.37109375MB
INFO:root:[   13] Training loss: 0.96581370, Validation loss: 0.96686942, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4680.6796875MB
INFO:root:[   14] Training loss: 0.96521193, Validation loss: 0.96776058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4718.89453125MB
INFO:root:[   15] Training loss: 0.96463456, Validation loss: 0.96686498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4756.7734375MB
INFO:root:[   16] Training loss: 0.96398986, Validation loss: 0.96680216, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4794.8515625MB
INFO:root:[   17] Training loss: 0.96426050, Validation loss: 0.96458322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4833.28515625MB
INFO:root:[   18] Training loss: 0.96334067, Validation loss: 0.96669076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4871.65234375MB
INFO:root:[   19] Training loss: 0.96318301, Validation loss: 0.96461702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4909.88671875MB
INFO:root:[   20] Training loss: 0.96260536, Validation loss: 0.96326085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4947.96875MB
INFO:root:[   21] Training loss: 0.96239518, Validation loss: 0.96391824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=4986.2265625MB
INFO:root:[   22] Training loss: 0.96248616, Validation loss: 0.96627951, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5024.3515625MB
INFO:root:[   23] Training loss: 0.96180450, Validation loss: 0.96404760, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5062.16796875MB
INFO:root:[   24] Training loss: 0.96139040, Validation loss: 0.96478166, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5100.125MB
INFO:root:[   25] Training loss: 0.96159993, Validation loss: 0.96472477, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5138.94921875MB
INFO:root:[   26] Training loss: 0.96164000, Validation loss: 0.96364150, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5176.35546875MB
INFO:root:[   27] Training loss: 0.96146762, Validation loss: 0.96174633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5214.0MB
INFO:root:[   28] Training loss: 0.96087160, Validation loss: 0.96314747, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5252.37109375MB
INFO:root:[   29] Training loss: 0.96036031, Validation loss: 0.96405250, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5290.5078125MB
INFO:root:[   30] Training loss: 0.96018041, Validation loss: 0.96342162, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5328.69140625MB
INFO:root:[   31] Training loss: 0.96042054, Validation loss: 0.96303134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5366.90625MB
INFO:root:[   32] Training loss: 0.96065070, Validation loss: 0.96244332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5404.703125MB
INFO:root:[   33] Training loss: 0.96021847, Validation loss: 0.96204485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5441.96484375MB
INFO:root:[   34] Training loss: 0.95972677, Validation loss: 0.95997573, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5480.796875MB
INFO:root:[   35] Training loss: 0.96068113, Validation loss: 0.95829319, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5518.71875MB
INFO:root:[   36] Training loss: 0.95893047, Validation loss: 0.96058585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5556.63671875MB
INFO:root:[   37] Training loss: 0.95952568, Validation loss: 0.96241261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5594.9375MB
INFO:root:[   38] Training loss: 0.95903474, Validation loss: 0.96091952, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5632.8671875MB
INFO:root:[   39] Training loss: 0.95872321, Validation loss: 0.96084757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5671.01171875MB
INFO:root:[   40] Training loss: 0.95866395, Validation loss: 0.95951437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5709.6484375MB
INFO:root:[   41] Training loss: 0.95806793, Validation loss: 0.95874003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5747.79296875MB
INFO:root:[   42] Training loss: 0.95782370, Validation loss: 0.96054823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5785.9375MB
INFO:root:[   43] Training loss: 0.95790301, Validation loss: 0.95856652, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5823.8203125MB
INFO:root:[   44] Training loss: 0.95746806, Validation loss: 0.96057346, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5862.0859375MB
INFO:root:[   45] Training loss: 0.95813024, Validation loss: 0.95855983, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5900.23046875MB
INFO:root:[   46] Training loss: 0.95743790, Validation loss: 0.95813023, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5938.69140625MB
INFO:root:[   47] Training loss: 0.95605176, Validation loss: 0.95658010, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=5976.86328125MB
INFO:root:[   48] Training loss: 0.95628402, Validation loss: 0.96054007, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6015.0234375MB
INFO:root:[   49] Training loss: 0.95632593, Validation loss: 0.95558015, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6053.09375MB
INFO:root:[   50] Training loss: 0.95727768, Validation loss: 0.96122798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6091.5625MB
INFO:root:[   51] Training loss: 0.95655952, Validation loss: 0.95903127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6129.4765625MB
INFO:root:[   52] Training loss: 0.95578800, Validation loss: 0.95847286, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6167.6171875MB
INFO:root:[   53] Training loss: 0.95535389, Validation loss: 0.95550092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6205.58203125MB
INFO:root:[   54] Training loss: 0.95501245, Validation loss: 0.95597255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6243.48046875MB
INFO:root:[   55] Training loss: 0.95453247, Validation loss: 0.95626113, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6281.61328125MB
INFO:root:[   56] Training loss: 0.95480402, Validation loss: 0.95676700, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6320.25MB
INFO:root:[   57] Training loss: 0.95449226, Validation loss: 0.95469028, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6358.41015625MB
INFO:root:[   58] Training loss: 0.95394183, Validation loss: 0.95624165, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6396.81640625MB
INFO:root:[   59] Training loss: 0.95410559, Validation loss: 0.95795089, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6434.9609375MB
INFO:root:[   60] Training loss: 0.95359832, Validation loss: 0.95614063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6473.08984375MB
INFO:root:[   61] Training loss: 0.95300676, Validation loss: 0.95335350, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6511.25MB
INFO:root:[   62] Training loss: 0.95280835, Validation loss: 0.95628695, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6549.66796875MB
INFO:root:[   63] Training loss: 0.95287158, Validation loss: 0.95462097, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6587.8125MB
INFO:root:[   64] Training loss: 0.95340787, Validation loss: 0.95533591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6625.95703125MB
INFO:root:[   65] Training loss: 0.95299698, Validation loss: 0.95610191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6664.1015625MB
INFO:root:[   66] Training loss: 0.95228512, Validation loss: 0.95636253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6702.5MB
INFO:root:[   67] Training loss: 0.95159172, Validation loss: 0.95171977, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6740.22265625MB
INFO:root:[   68] Training loss: 0.95246835, Validation loss: 0.95251423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6778.61328125MB
INFO:root:[   69] Training loss: 0.95199301, Validation loss: 0.95292224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6816.7578125MB
INFO:root:[   70] Training loss: 0.95108473, Validation loss: 0.95131221, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6854.73046875MB
INFO:root:[   71] Training loss: 0.95051455, Validation loss: 0.95114012, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6891.6875MB
INFO:root:[   72] Training loss: 0.95018772, Validation loss: 0.95653675, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6929.8203125MB
INFO:root:[   73] Training loss: 0.95080018, Validation loss: 0.95231361, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=6967.9609375MB
INFO:root:[   74] Training loss: 0.94990275, Validation loss: 0.95471711, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7006.3515625MB
INFO:root:[   75] Training loss: 0.94988001, Validation loss: 0.95043333, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7044.23828125MB
INFO:root:[   76] Training loss: 0.94906141, Validation loss: 0.95160533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7082.6171875MB
INFO:root:[   77] Training loss: 0.94987219, Validation loss: 0.95835049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7120.7578125MB
INFO:root:[   78] Training loss: 0.94897191, Validation loss: 0.95360837, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7158.90234375MB
INFO:root:[   79] Training loss: 0.95004023, Validation loss: 0.94942927, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7196.6796875MB
INFO:root:[   80] Training loss: 0.94846592, Validation loss: 0.94962282, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7235.0703125MB
INFO:root:[   81] Training loss: 0.94899421, Validation loss: 0.95003026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7273.2421875MB
INFO:root:[   82] Training loss: 0.94873511, Validation loss: 0.95188292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7311.37890625MB
INFO:root:[   83] Training loss: 0.94932470, Validation loss: 0.95211269, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7349.63671875MB
INFO:root:[   84] Training loss: 0.94887599, Validation loss: 0.94868335, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7387.92578125MB
INFO:root:[   85] Training loss: 0.94805475, Validation loss: 0.95005076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7426.0234375MB
INFO:root:[   86] Training loss: 0.94826823, Validation loss: 0.95059395, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7464.2109375MB
INFO:root:[   87] Training loss: 0.94786112, Validation loss: 0.95242368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7502.45703125MB
INFO:root:[   88] Training loss: 0.94854547, Validation loss: 0.95050752, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7540.58203125MB
INFO:root:[   89] Training loss: 0.94878843, Validation loss: 0.95076109, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7578.953125MB
INFO:root:[   90] Training loss: 0.94801513, Validation loss: 0.95009657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7616.859375MB
INFO:root:[   91] Training loss: 0.94769283, Validation loss: 0.94956173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7655.4609375MB
INFO:root:[   92] Training loss: 0.94798901, Validation loss: 0.94836990, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7693.625MB
INFO:root:[   93] Training loss: 0.94729110, Validation loss: 0.95091717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7731.71484375MB
INFO:root:[   94] Training loss: 0.94837674, Validation loss: 0.95009328, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7770.08984375MB
INFO:root:[   95] Training loss: 0.94681732, Validation loss: 0.94995931, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7808.08203125MB
INFO:root:[   96] Training loss: 0.94755489, Validation loss: 0.94962685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7845.9140625MB
INFO:root:[   97] Training loss: 0.94775299, Validation loss: 0.94827486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7884.3515625MB
INFO:root:[   98] Training loss: 0.94650626, Validation loss: 0.94900380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7922.53515625MB
INFO:root:[   99] Training loss: 0.94670231, Validation loss: 0.94829438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7960.6953125MB
INFO:root:[  100] Training loss: 0.94690854, Validation loss: 0.94986354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=7998.8515625MB
INFO:root:[  101] Training loss: 0.94747628, Validation loss: 0.94915241, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8037.01171875MB
INFO:root:[  102] Training loss: 0.94669036, Validation loss: 0.94924035, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8075.171875MB
INFO:root:[  103] Training loss: 0.94717556, Validation loss: 0.95037056, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8113.33203125MB
INFO:root:[  104] Training loss: 0.94681442, Validation loss: 0.95020741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8151.4921875MB
INFO:root:[  105] Training loss: 0.94601329, Validation loss: 0.95079267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8189.88671875MB
INFO:root:[  106] Training loss: 0.94700390, Validation loss: 0.94829048, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8227.9375MB
INFO:root:EP 106: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12452.31640625MB; mem (CPU total)=8266.08203125MB
INFO:root:Training the model took 4030.119s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.942
INFO:root:EnergyScoreTrain: 0.8971
INFO:root:CRPSTrain: 0.73993
INFO:root:Gaussian NLLTrain: 716.01459
INFO:root:CoverageTrain: 0.07336
INFO:root:IntervalWidthTrain: 0.14203
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94548
INFO:root:EnergyScoreValidation: 0.90064
INFO:root:CRPSValidation: 0.74333
INFO:root:Gaussian NLLValidation: 717.01203
INFO:root:CoverageValidation: 0.0726
INFO:root:IntervalWidthValidation: 0.14179
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94506
INFO:root:EnergyScoreTest: 0.90016
INFO:root:CRPSTest: 0.74297
INFO:root:Gaussian NLLTest: 715.76678
INFO:root:CoverageTest: 0.07258
INFO:root:IntervalWidthTest: 0.14183
INFO:root:After validation: mem (CPU python)=12452.31640625MB; mem (CPU total)=8345.2890625MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12452.31640625MB; mem (CPU total)=8345.2890625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 174063616
INFO:root:After setting up the model: mem (CPU python)=12452.31640625MB; mem (CPU total)=8345.2890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8345.28515625MB
INFO:root:[    1] Training loss: 1.00805590, Validation loss: 0.99457720, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8383.11328125MB
INFO:root:[    2] Training loss: 0.98718745, Validation loss: 0.98433724, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8421.609375MB
INFO:root:[    3] Training loss: 0.98084969, Validation loss: 0.98002049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8459.4140625MB
INFO:root:[    4] Training loss: 0.97698122, Validation loss: 0.97709321, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8497.42578125MB
INFO:root:[    5] Training loss: 0.97439074, Validation loss: 0.97476506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8535.67578125MB
INFO:root:[    6] Training loss: 0.97298108, Validation loss: 0.97388083, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8573.734375MB
INFO:root:[    7] Training loss: 0.97180186, Validation loss: 0.97381883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8611.58984375MB
INFO:root:[    8] Training loss: 0.97064077, Validation loss: 0.97213985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8649.7890625MB
INFO:root:[    9] Training loss: 0.96949865, Validation loss: 0.97022206, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8687.546875MB
INFO:root:[   10] Training loss: 0.96874904, Validation loss: 0.97044112, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8725.94140625MB
INFO:root:[   11] Training loss: 0.96792803, Validation loss: 0.96897502, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8764.171875MB
INFO:root:[   12] Training loss: 0.96733841, Validation loss: 0.96958564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8802.3203125MB
INFO:root:[   13] Training loss: 0.96671831, Validation loss: 0.96781639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8840.46484375MB
INFO:root:[   14] Training loss: 0.96621058, Validation loss: 0.96843265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8878.859375MB
INFO:root:[   15] Training loss: 0.96536759, Validation loss: 0.96681587, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8916.96875MB
INFO:root:[   16] Training loss: 0.96488906, Validation loss: 0.96677891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8954.91796875MB
INFO:root:[   17] Training loss: 0.96487774, Validation loss: 0.96600154, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=8993.57421875MB
INFO:root:[   18] Training loss: 0.96455358, Validation loss: 0.96707260, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9031.98046875MB
INFO:root:[   19] Training loss: 0.96401190, Validation loss: 0.96431834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9070.34375MB
INFO:root:[   20] Training loss: 0.96394344, Validation loss: 0.96563740, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9108.66796875MB
INFO:root:[   21] Training loss: 0.96323175, Validation loss: 0.96499717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9146.84375MB
INFO:root:[   22] Training loss: 0.96350986, Validation loss: 0.96414784, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9185.28125MB
INFO:root:[   23] Training loss: 0.96326977, Validation loss: 0.96477641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9222.94140625MB
INFO:root:[   24] Training loss: 0.96258436, Validation loss: 0.96368411, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9260.1015625MB
INFO:root:[   25] Training loss: 0.96233595, Validation loss: 0.96389218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9298.015625MB
INFO:root:[   26] Training loss: 0.96219778, Validation loss: 0.96223265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9336.09375MB
INFO:root:[   27] Training loss: 0.96187641, Validation loss: 0.96260246, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9374.44921875MB
INFO:root:[   28] Training loss: 0.96176101, Validation loss: 0.96242746, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9412.85546875MB
INFO:root:[   29] Training loss: 0.96127492, Validation loss: 0.96208247, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9450.90234375MB
INFO:root:[   30] Training loss: 0.96105633, Validation loss: 0.96466190, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9489.3046875MB
INFO:root:[   31] Training loss: 0.96068697, Validation loss: 0.96324447, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9528.1875MB
INFO:root:[   32] Training loss: 0.95990904, Validation loss: 0.96208539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9566.40234375MB
INFO:root:[   33] Training loss: 0.95941463, Validation loss: 0.96049016, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9605.015625MB
INFO:root:[   34] Training loss: 0.95922892, Validation loss: 0.95976447, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9642.890625MB
INFO:root:[   35] Training loss: 0.95888474, Validation loss: 0.95983642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9681.0703125MB
INFO:root:[   36] Training loss: 0.95840389, Validation loss: 0.95860180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9720.02734375MB
INFO:root:[   37] Training loss: 0.95882984, Validation loss: 0.95954582, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9758.640625MB
INFO:root:[   38] Training loss: 0.95830329, Validation loss: 0.95866332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9796.9140625MB
INFO:root:[   39] Training loss: 0.95760885, Validation loss: 0.95953028, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9835.05859375MB
INFO:root:[   40] Training loss: 0.95806899, Validation loss: 0.95866830, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9873.203125MB
INFO:root:[   41] Training loss: 0.95746000, Validation loss: 0.95831880, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9911.39453125MB
INFO:root:[   42] Training loss: 0.95724453, Validation loss: 0.95842297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9949.78515625MB
INFO:root:[   43] Training loss: 0.95704383, Validation loss: 0.95865186, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=9988.17578125MB
INFO:root:[   44] Training loss: 0.95634352, Validation loss: 0.95702468, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10025.71484375MB
INFO:root:[   45] Training loss: 0.95596416, Validation loss: 0.95741205, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10064.10546875MB
INFO:root:[   46] Training loss: 0.95545665, Validation loss: 0.95575321, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10102.20703125MB
INFO:root:[   47] Training loss: 0.95397985, Validation loss: 0.95532415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10140.2265625MB
INFO:root:[   48] Training loss: 0.95393266, Validation loss: 0.95445764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10177.953125MB
INFO:root:[   49] Training loss: 0.95355574, Validation loss: 0.95478920, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10216.07421875MB
INFO:root:[   50] Training loss: 0.95344302, Validation loss: 0.95597798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10254.203125MB
INFO:root:[   51] Training loss: 0.95327810, Validation loss: 0.95698874, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10292.12890625MB
INFO:root:[   52] Training loss: 0.95331774, Validation loss: 0.95603539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10330.51953125MB
INFO:root:[   53] Training loss: 0.95258403, Validation loss: 0.95490712, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10368.64453125MB
INFO:root:[   54] Training loss: 0.95250738, Validation loss: 0.95429060, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10406.7890625MB
INFO:root:[   55] Training loss: 0.95212984, Validation loss: 0.95234545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10445.01171875MB
INFO:root:[   56] Training loss: 0.95171294, Validation loss: 0.95173832, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10483.078125MB
INFO:root:[   57] Training loss: 0.95102156, Validation loss: 0.95264536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10521.44921875MB
INFO:root:[   58] Training loss: 0.95104127, Validation loss: 0.95458601, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10559.5859375MB
INFO:root:[   59] Training loss: 0.95071568, Validation loss: 0.95348894, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10597.73046875MB
INFO:root:[   60] Training loss: 0.95042261, Validation loss: 0.95282754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10635.875MB
INFO:root:[   61] Training loss: 0.95024094, Validation loss: 0.95134388, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10674.02734375MB
INFO:root:[   62] Training loss: 0.95000964, Validation loss: 0.95102508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10712.59765625MB
INFO:root:[   63] Training loss: 0.94980651, Validation loss: 0.95000733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10751.328125MB
INFO:root:[   64] Training loss: 0.94954090, Validation loss: 0.94952790, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10789.609375MB
INFO:root:[   65] Training loss: 0.94930167, Validation loss: 0.94993679, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10826.59765625MB
INFO:root:[   66] Training loss: 0.94910753, Validation loss: 0.95090849, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10864.515625MB
INFO:root:[   67] Training loss: 0.94863968, Validation loss: 0.95133727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10902.66015625MB
INFO:root:[   68] Training loss: 0.94824410, Validation loss: 0.95023335, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10940.8046875MB
INFO:root:[   69] Training loss: 0.94790047, Validation loss: 0.94950406, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=10979.2890625MB
INFO:root:[   70] Training loss: 0.94712798, Validation loss: 0.94889915, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11017.9140625MB
INFO:root:[   71] Training loss: 0.94720899, Validation loss: 0.94953060, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11056.01953125MB
INFO:root:[   72] Training loss: 0.94666263, Validation loss: 0.94824965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11093.6484375MB
INFO:root:[   73] Training loss: 0.94677690, Validation loss: 0.94728843, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11132.296875MB
INFO:root:[   74] Training loss: 0.94647119, Validation loss: 0.94997204, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11170.1953125MB
INFO:root:[   75] Training loss: 0.94623359, Validation loss: 0.94880114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11208.3359375MB
INFO:root:[   76] Training loss: 0.94621681, Validation loss: 0.94865108, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11246.48046875MB
INFO:root:[   77] Training loss: 0.94612307, Validation loss: 0.94750944, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11284.83984375MB
INFO:root:[   78] Training loss: 0.94586119, Validation loss: 0.94793802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11322.73828125MB
INFO:root:[   79] Training loss: 0.94576255, Validation loss: 0.94927304, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11360.8828125MB
INFO:root:[   80] Training loss: 0.94568987, Validation loss: 0.94664434, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11399.09765625MB
INFO:root:[   81] Training loss: 0.94549340, Validation loss: 0.94719117, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11437.2109375MB
INFO:root:[   82] Training loss: 0.94532943, Validation loss: 0.94656301, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11475.3671875MB
INFO:root:[   83] Training loss: 0.94514470, Validation loss: 0.94677296, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11513.7578125MB
INFO:root:[   84] Training loss: 0.94483588, Validation loss: 0.94668503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11551.90234375MB
INFO:root:[   85] Training loss: 0.94496562, Validation loss: 0.94677632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11589.80078125MB
INFO:root:[   86] Training loss: 0.94483302, Validation loss: 0.94662564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11627.9375MB
INFO:root:[   87] Training loss: 0.94474192, Validation loss: 0.94756239, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11666.58984375MB
INFO:root:[   88] Training loss: 0.94444136, Validation loss: 0.94626174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11704.3046875MB
INFO:root:[   89] Training loss: 0.94444653, Validation loss: 0.94710579, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11742.6796875MB
INFO:root:[   90] Training loss: 0.94439112, Validation loss: 0.94568050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11780.90625MB
INFO:root:[   91] Training loss: 0.94453553, Validation loss: 0.94588619, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11819.08203125MB
INFO:root:[   92] Training loss: 0.94419974, Validation loss: 0.94721029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11857.44140625MB
INFO:root:[   93] Training loss: 0.94428910, Validation loss: 0.94519773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11895.17578125MB
INFO:root:[   94] Training loss: 0.94400948, Validation loss: 0.94670407, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11933.59765625MB
INFO:root:[   95] Training loss: 0.94359565, Validation loss: 0.94446313, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=11971.4296875MB
INFO:root:[   96] Training loss: 0.94366184, Validation loss: 0.94591664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12009.8359375MB
INFO:root:[   97] Training loss: 0.94369900, Validation loss: 0.94544240, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12047.99609375MB
INFO:root:[   98] Training loss: 0.94335296, Validation loss: 0.94504885, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12086.15625MB
INFO:root:[   99] Training loss: 0.94344389, Validation loss: 0.94617306, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12123.82421875MB
INFO:root:[  100] Training loss: 0.94351703, Validation loss: 0.94470639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12162.23046875MB
INFO:root:[  101] Training loss: 0.94307880, Validation loss: 0.94585505, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12200.63671875MB
INFO:root:[  102] Training loss: 0.94305958, Validation loss: 0.94577479, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12238.87890625MB
INFO:root:[  103] Training loss: 0.94306430, Validation loss: 0.94507746, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12277.11328125MB
INFO:root:[  104] Training loss: 0.94305995, Validation loss: 0.94631217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12315.02734375MB
INFO:root:[  105] Training loss: 0.94299935, Validation loss: 0.94401900, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12452.31640625MB; mem (CPU total)=12353.48828125MB
INFO:root:[  106] Training loss: 0.94284102, Validation loss: 0.94517612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12468.51953125MB; mem (CPU total)=12391.890625MB
INFO:root:[  107] Training loss: 0.94259763, Validation loss: 0.94530437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12506.61328125MB; mem (CPU total)=12430.05078125MB
INFO:root:[  108] Training loss: 0.94267208, Validation loss: 0.94613678, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12544.7109375MB; mem (CPU total)=12467.71875MB
INFO:root:[  109] Training loss: 0.94279883, Validation loss: 0.94463408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12582.80859375MB; mem (CPU total)=12505.90234375MB
INFO:root:[  110] Training loss: 0.94239853, Validation loss: 0.94412907, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12620.90234375MB; mem (CPU total)=12544.3046875MB
INFO:root:[  111] Training loss: 0.94232010, Validation loss: 0.94402096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12659.0MB; mem (CPU total)=12582.49609375MB
INFO:root:[  112] Training loss: 0.94230653, Validation loss: 0.94403887, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12697.09375MB; mem (CPU total)=12620.6875MB
INFO:root:[  113] Training loss: 0.94224938, Validation loss: 0.94431975, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12735.1875MB; mem (CPU total)=12658.75390625MB
INFO:root:[  114] Training loss: 0.94205093, Validation loss: 0.94343639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12773.28125MB; mem (CPU total)=12697.05078125MB
INFO:root:[  115] Training loss: 0.94205256, Validation loss: 0.94373371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12811.37890625MB; mem (CPU total)=12735.23828125MB
INFO:root:[  116] Training loss: 0.94178268, Validation loss: 0.94464905, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12849.4765625MB; mem (CPU total)=12773.64453125MB
INFO:root:[  117] Training loss: 0.94195709, Validation loss: 0.94386094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12887.57421875MB; mem (CPU total)=12811.5546875MB
INFO:root:[  118] Training loss: 0.94169077, Validation loss: 0.94369840, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12925.671875MB; mem (CPU total)=12849.6875MB
INFO:root:[  119] Training loss: 0.94157698, Validation loss: 0.94418181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12963.765625MB; mem (CPU total)=12887.83203125MB
INFO:root:[  120] Training loss: 0.94161625, Validation loss: 0.94338007, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13001.859375MB; mem (CPU total)=12925.375MB
INFO:root:[  121] Training loss: 0.94137320, Validation loss: 0.94322703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13039.953125MB; mem (CPU total)=12963.83203125MB
INFO:root:[  122] Training loss: 0.94134728, Validation loss: 0.94316823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13078.0546875MB; mem (CPU total)=13002.09375MB
INFO:root:[  123] Training loss: 0.94130685, Validation loss: 0.94387916, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13116.14453125MB; mem (CPU total)=13040.01953125MB
INFO:root:[  124] Training loss: 0.94142845, Validation loss: 0.94398564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13154.23828125MB; mem (CPU total)=13078.2109375MB
INFO:root:[  125] Training loss: 0.94131736, Validation loss: 0.94442030, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13192.34375MB; mem (CPU total)=13116.125MB
INFO:root:[  126] Training loss: 0.94133228, Validation loss: 0.94480250, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13230.4375MB; mem (CPU total)=13154.5234375MB
INFO:root:[  127] Training loss: 0.94114215, Validation loss: 0.94145450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13268.53125MB; mem (CPU total)=13192.83203125MB
INFO:root:[  128] Training loss: 0.94098135, Validation loss: 0.94310979, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13306.62890625MB; mem (CPU total)=13230.9921875MB
INFO:root:[  129] Training loss: 0.94098440, Validation loss: 0.94209001, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13344.72265625MB; mem (CPU total)=13268.6328125MB
INFO:root:[  130] Training loss: 0.94088053, Validation loss: 0.94334209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13382.81640625MB; mem (CPU total)=13306.546875MB
INFO:root:[  131] Training loss: 0.94073817, Validation loss: 0.94266790, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13420.91015625MB; mem (CPU total)=13344.953125MB
INFO:root:[  132] Training loss: 0.94070277, Validation loss: 0.94344047, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13459.0078125MB; mem (CPU total)=13383.05859375MB
INFO:root:[  133] Training loss: 0.94038050, Validation loss: 0.94207832, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13497.10546875MB; mem (CPU total)=13421.30078125MB
INFO:root:[  134] Training loss: 0.94042692, Validation loss: 0.94331370, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13535.19921875MB; mem (CPU total)=13459.70703125MB
INFO:root:[  135] Training loss: 0.94030596, Validation loss: 0.94266811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13573.296875MB; mem (CPU total)=13497.48046875MB
INFO:root:[  136] Training loss: 0.94039645, Validation loss: 0.94396165, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13611.390625MB; mem (CPU total)=13535.6171875MB
INFO:root:EP 136: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=13649.484375MB; mem (CPU total)=13574.05078125MB
INFO:root:Training the model took 5628.657s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.935
INFO:root:EnergyScoreTrain: 0.88145
INFO:root:CRPSTrain: 0.72867
INFO:root:Gaussian NLLTrain: 28607603485.58225
INFO:root:CoverageTrain: 0.10332
INFO:root:IntervalWidthTrain: 0.18793
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93785
INFO:root:EnergyScoreValidation: 0.88448
INFO:root:CRPSValidation: 0.73147
INFO:root:Gaussian NLLValidation: 28900621403.02224
INFO:root:CoverageValidation: 0.10231
INFO:root:IntervalWidthValidation: 0.18733
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93707
INFO:root:EnergyScoreTest: 0.88359
INFO:root:CRPSTest: 0.73093
INFO:root:Gaussian NLLTest: 27949870219.26398
INFO:root:CoverageTest: 0.10233
INFO:root:IntervalWidthTest: 0.18774
INFO:root:After validation: mem (CPU python)=13692.47265625MB; mem (CPU total)=13618.40625MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=13692.47265625MB; mem (CPU total)=13618.40625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=13692.5390625MB; mem (CPU total)=13618.40625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=13692.58203125MB; mem (CPU total)=13618.65234375MB
INFO:root:[    1] Training loss: 1.00829535, Validation loss: 0.99473912, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13730.5234375MB; mem (CPU total)=13656.73828125MB
INFO:root:[    2] Training loss: 0.98747495, Validation loss: 0.98462337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13768.6328125MB; mem (CPU total)=13694.0078125MB
INFO:root:[    3] Training loss: 0.98028605, Validation loss: 0.97928286, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13806.75MB; mem (CPU total)=13732.4453125MB
INFO:root:[    4] Training loss: 0.97667167, Validation loss: 0.97696391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13844.84375MB; mem (CPU total)=13770.9140625MB
INFO:root:[    5] Training loss: 0.97443155, Validation loss: 0.97493219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13882.9375MB; mem (CPU total)=13809.3671875MB
INFO:root:[    6] Training loss: 0.97306306, Validation loss: 0.97371541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13921.03125MB; mem (CPU total)=13847.01953125MB
INFO:root:[    7] Training loss: 0.97199528, Validation loss: 0.97374923, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13959.12890625MB; mem (CPU total)=13885.41015625MB
INFO:root:[    8] Training loss: 0.97120311, Validation loss: 0.97147225, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13997.2265625MB; mem (CPU total)=13923.1484375MB
INFO:root:[    9] Training loss: 0.97016557, Validation loss: 0.97114702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14035.3203125MB; mem (CPU total)=13961.27734375MB
INFO:root:[   10] Training loss: 0.96936223, Validation loss: 0.97064348, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14073.41796875MB; mem (CPU total)=13998.6796875MB
INFO:root:[   11] Training loss: 0.96849859, Validation loss: 0.96926542, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14111.51171875MB; mem (CPU total)=14036.94140625MB
INFO:root:[   12] Training loss: 0.96795281, Validation loss: 0.96905504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14149.60546875MB; mem (CPU total)=14074.859375MB
INFO:root:[   13] Training loss: 0.96742105, Validation loss: 0.96819774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14187.70703125MB; mem (CPU total)=14113.3125MB
INFO:root:[   14] Training loss: 0.96666382, Validation loss: 0.96914003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14225.796875MB; mem (CPU total)=14150.98828125MB
INFO:root:[   15] Training loss: 0.96587155, Validation loss: 0.96654509, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14263.89453125MB; mem (CPU total)=14189.31640625MB
INFO:root:[   16] Training loss: 0.96525536, Validation loss: 0.96657881, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14301.98828125MB; mem (CPU total)=14227.4296875MB
INFO:root:[   17] Training loss: 0.96439791, Validation loss: 0.96545222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14340.0859375MB; mem (CPU total)=14265.62109375MB
INFO:root:[   18] Training loss: 0.96383966, Validation loss: 0.96516818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14378.1796875MB; mem (CPU total)=14303.94140625MB
INFO:root:[   19] Training loss: 0.96311982, Validation loss: 0.96460190, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14416.2734375MB; mem (CPU total)=14342.1015625MB
INFO:root:[   20] Training loss: 0.96265658, Validation loss: 0.96386068, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14454.37109375MB; mem (CPU total)=14380.35546875MB
INFO:root:[   21] Training loss: 0.96217810, Validation loss: 0.96304874, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14492.46875MB; mem (CPU total)=14418.1484375MB
INFO:root:[   22] Training loss: 0.96180971, Validation loss: 0.96426798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14530.5625MB; mem (CPU total)=14456.5703125MB
INFO:root:[   23] Training loss: 0.96161507, Validation loss: 0.96261257, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14568.65625MB; mem (CPU total)=14494.59765625MB
INFO:root:[   24] Training loss: 0.96137884, Validation loss: 0.96159698, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14606.75390625MB; mem (CPU total)=14533.078125MB
INFO:root:[   25] Training loss: 0.96097144, Validation loss: 0.96127491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14644.84765625MB; mem (CPU total)=14571.359375MB
INFO:root:[   26] Training loss: 0.96026278, Validation loss: 0.96056911, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14682.94140625MB; mem (CPU total)=14608.33203125MB
INFO:root:[   27] Training loss: 0.96012095, Validation loss: 0.96077696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14721.0390625MB; mem (CPU total)=14646.734375MB
INFO:root:[   28] Training loss: 0.95944254, Validation loss: 0.96039613, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14759.1328125MB; mem (CPU total)=14684.36328125MB
INFO:root:[   29] Training loss: 0.95904789, Validation loss: 0.96033385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14797.2265625MB; mem (CPU total)=14722.8203125MB
INFO:root:[   30] Training loss: 0.95875272, Validation loss: 0.96030494, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14835.328125MB; mem (CPU total)=14760.86328125MB
INFO:root:[   31] Training loss: 0.95863281, Validation loss: 0.96034376, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14873.421875MB; mem (CPU total)=14798.515625MB
INFO:root:[   32] Training loss: 0.95835358, Validation loss: 0.95882528, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14911.515625MB; mem (CPU total)=14837.08984375MB
INFO:root:[   33] Training loss: 0.95787729, Validation loss: 0.95890550, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14949.609375MB; mem (CPU total)=14874.8828125MB
INFO:root:[   34] Training loss: 0.95741982, Validation loss: 0.95844636, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14987.70703125MB; mem (CPU total)=14913.0703125MB
INFO:root:[   35] Training loss: 0.95727317, Validation loss: 0.95762359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15025.8046875MB; mem (CPU total)=14951.30859375MB
INFO:root:[   36] Training loss: 0.95696395, Validation loss: 0.95729678, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15063.8984375MB; mem (CPU total)=14989.8203125MB
INFO:root:[   37] Training loss: 0.95643694, Validation loss: 0.95802817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15101.9921875MB; mem (CPU total)=15028.1953125MB
INFO:root:[   38] Training loss: 0.95678136, Validation loss: 0.95763696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15140.08984375MB; mem (CPU total)=15066.34765625MB
INFO:root:[   39] Training loss: 0.95611476, Validation loss: 0.95841322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15178.18359375MB; mem (CPU total)=15104.51171875MB
INFO:root:[   40] Training loss: 0.95588911, Validation loss: 0.95683680, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15216.27734375MB; mem (CPU total)=15142.68359375MB
INFO:root:[   41] Training loss: 0.95573393, Validation loss: 0.95722619, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15254.375MB; mem (CPU total)=15181.16015625MB
INFO:root:[   42] Training loss: 0.95529116, Validation loss: 0.95664688, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15292.46875MB; mem (CPU total)=15219.41015625MB
INFO:root:[   43] Training loss: 0.95492299, Validation loss: 0.95586847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15330.56640625MB; mem (CPU total)=15257.69140625MB
INFO:root:[   44] Training loss: 0.95472899, Validation loss: 0.95632033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15368.6640625MB; mem (CPU total)=15295.3671875MB
INFO:root:[   45] Training loss: 0.95461615, Validation loss: 0.95593543, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15406.7578125MB; mem (CPU total)=15333.77734375MB
INFO:root:[   46] Training loss: 0.95427373, Validation loss: 0.95510214, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15444.85546875MB; mem (CPU total)=15372.078125MB
INFO:root:[   47] Training loss: 0.95397983, Validation loss: 0.95542180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15482.9765625MB; mem (CPU total)=15410.484375MB
INFO:root:[   48] Training loss: 0.95357712, Validation loss: 0.95365691, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15521.0703125MB; mem (CPU total)=15448.64453125MB
INFO:root:[   49] Training loss: 0.95352552, Validation loss: 0.95385201, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15559.1640625MB; mem (CPU total)=15486.7734375MB
INFO:root:[   50] Training loss: 0.95324916, Validation loss: 0.95535039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15597.2578125MB; mem (CPU total)=15524.90625MB
INFO:root:[   51] Training loss: 0.95287842, Validation loss: 0.95433235, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15635.35546875MB; mem (CPU total)=15563.06640625MB
INFO:root:[   52] Training loss: 0.95279399, Validation loss: 0.95402955, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15673.44921875MB; mem (CPU total)=15600.98046875MB
INFO:root:[   53] Training loss: 0.95253181, Validation loss: 0.95396329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15711.54296875MB; mem (CPU total)=15639.390625MB
INFO:root:[   54] Training loss: 0.95261076, Validation loss: 0.95391187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15749.64453125MB; mem (CPU total)=15677.30859375MB
INFO:root:[   55] Training loss: 0.95219593, Validation loss: 0.95297666, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15787.73828125MB; mem (CPU total)=15716.4375MB
INFO:root:[   56] Training loss: 0.95205429, Validation loss: 0.95221643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15825.83203125MB; mem (CPU total)=15755.9296875MB
INFO:root:[   57] Training loss: 0.95169964, Validation loss: 0.95346593, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15863.92578125MB; mem (CPU total)=15794.33203125MB
INFO:root:[   58] Training loss: 0.95159679, Validation loss: 0.95280727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15902.0234375MB; mem (CPU total)=15832.734375MB
INFO:root:[   59] Training loss: 0.95150177, Validation loss: 0.95319701, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15940.1171875MB; mem (CPU total)=15870.8828125MB
INFO:root:[   60] Training loss: 0.95126256, Validation loss: 0.95201745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15978.2109375MB; mem (CPU total)=15909.515625MB
INFO:root:[   61] Training loss: 0.95100303, Validation loss: 0.95160764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16016.30859375MB; mem (CPU total)=15947.61328125MB
INFO:root:[   62] Training loss: 0.95105734, Validation loss: 0.95235612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16054.40234375MB; mem (CPU total)=15985.765625MB
INFO:root:[   63] Training loss: 0.95071235, Validation loss: 0.95234701, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16092.49609375MB; mem (CPU total)=16023.703125MB
INFO:root:[   64] Training loss: 0.95062711, Validation loss: 0.95098513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16130.59765625MB; mem (CPU total)=16061.62109375MB
INFO:root:[   65] Training loss: 0.95042482, Validation loss: 0.95246825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16168.69140625MB; mem (CPU total)=16099.77734375MB
INFO:root:[   66] Training loss: 0.95030379, Validation loss: 0.95141265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16206.78515625MB; mem (CPU total)=16137.93359375MB
INFO:root:[   67] Training loss: 0.95003372, Validation loss: 0.95120433, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16244.87890625MB; mem (CPU total)=16176.0390625MB
INFO:root:[   68] Training loss: 0.94989585, Validation loss: 0.95049618, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16282.98046875MB; mem (CPU total)=16214.171875MB
INFO:root:[   69] Training loss: 0.94972192, Validation loss: 0.95164179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16321.0703125MB; mem (CPU total)=16252.58203125MB
INFO:root:[   70] Training loss: 0.94944042, Validation loss: 0.95153158, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16359.1640625MB; mem (CPU total)=16290.2421875MB
INFO:root:[   71] Training loss: 0.94953278, Validation loss: 0.95098540, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16397.265625MB; mem (CPU total)=16328.7421875MB
INFO:root:[   72] Training loss: 0.94934836, Validation loss: 0.95032817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16435.359375MB; mem (CPU total)=16367.1875MB
INFO:root:[   73] Training loss: 0.94920853, Validation loss: 0.95026733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16473.453125MB; mem (CPU total)=16405.71484375MB
INFO:root:[   74] Training loss: 0.94896508, Validation loss: 0.95184780, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16511.546875MB; mem (CPU total)=16444.10546875MB
INFO:root:[   75] Training loss: 0.94887395, Validation loss: 0.94954995, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16549.64453125MB; mem (CPU total)=16481.8515625MB
INFO:root:[   76] Training loss: 0.94896079, Validation loss: 0.95157919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16587.73828125MB; mem (CPU total)=16519.9921875MB
INFO:root:[   77] Training loss: 0.94870682, Validation loss: 0.95014683, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16625.83203125MB; mem (CPU total)=16557.890625MB
INFO:root:[   78] Training loss: 0.94852993, Validation loss: 0.95016258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16663.9296875MB; mem (CPU total)=16596.03125MB
INFO:root:[   79] Training loss: 0.94836824, Validation loss: 0.94995894, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16702.0234375MB; mem (CPU total)=16634.40625MB
INFO:root:[   80] Training loss: 0.94833340, Validation loss: 0.95043588, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16740.12109375MB; mem (CPU total)=16672.53515625MB
INFO:root:[   81] Training loss: 0.94808733, Validation loss: 0.94931065, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16778.21875MB; mem (CPU total)=16710.58203125MB
INFO:root:[   82] Training loss: 0.94790789, Validation loss: 0.94895959, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16816.3125MB; mem (CPU total)=16749.08203125MB
INFO:root:[   83] Training loss: 0.94787365, Validation loss: 0.94881571, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16854.40625MB; mem (CPU total)=16787.58203125MB
INFO:root:[   84] Training loss: 0.94754333, Validation loss: 0.94920828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16892.5MB; mem (CPU total)=16826.28125MB
INFO:root:[   85] Training loss: 0.94751739, Validation loss: 0.94872105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16930.6015625MB; mem (CPU total)=16864.61328125MB
INFO:root:[   86] Training loss: 0.94749485, Validation loss: 0.94879175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16968.69140625MB; mem (CPU total)=16902.2578125MB
INFO:root:[   87] Training loss: 0.94729765, Validation loss: 0.94861259, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17006.7890625MB; mem (CPU total)=16940.44140625MB
INFO:root:[   88] Training loss: 0.94722343, Validation loss: 0.94918807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17044.8828125MB; mem (CPU total)=16978.55859375MB
INFO:root:[   89] Training loss: 0.94705826, Validation loss: 0.94977051, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17082.98046875MB; mem (CPU total)=17016.66796875MB
INFO:root:[   90] Training loss: 0.94699499, Validation loss: 0.94834513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17121.078125MB; mem (CPU total)=17055.15234375MB
INFO:root:[   91] Training loss: 0.94686321, Validation loss: 0.94851316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17159.171875MB; mem (CPU total)=17092.8046875MB
INFO:root:[   92] Training loss: 0.94696308, Validation loss: 0.94872572, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17197.26953125MB; mem (CPU total)=17130.671875MB
INFO:root:[   93] Training loss: 0.94685077, Validation loss: 0.94815591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17235.36328125MB; mem (CPU total)=17168.6171875MB
INFO:root:[   94] Training loss: 0.94670360, Validation loss: 0.94785416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17273.45703125MB; mem (CPU total)=17207.25390625MB
INFO:root:[   95] Training loss: 0.94625361, Validation loss: 0.94859376, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17311.5546875MB; mem (CPU total)=17245.63671875MB
INFO:root:[   96] Training loss: 0.94635983, Validation loss: 0.94758039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17349.6484375MB; mem (CPU total)=17283.765625MB
INFO:root:[   97] Training loss: 0.94626659, Validation loss: 0.94761854, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17387.7421875MB; mem (CPU total)=17322.40234375MB
INFO:root:[   98] Training loss: 0.94612562, Validation loss: 0.94753720, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17425.84375MB; mem (CPU total)=17360.6875MB
INFO:root:[   99] Training loss: 0.94604675, Validation loss: 0.94766369, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17463.9375MB; mem (CPU total)=17398.83203125MB
INFO:root:[  100] Training loss: 0.94622464, Validation loss: 0.94742564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17502.03125MB; mem (CPU total)=17440.5546875MB
INFO:root:[  101] Training loss: 0.94579582, Validation loss: 0.94776369, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17540.125MB; mem (CPU total)=17478.453125MB
INFO:root:[  102] Training loss: 0.94598801, Validation loss: 0.94704464, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17578.22265625MB; mem (CPU total)=17514.39453125MB
INFO:root:[  103] Training loss: 0.94570132, Validation loss: 0.94819623, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17616.31640625MB; mem (CPU total)=17552.5390625MB
INFO:root:[  104] Training loss: 0.94585288, Validation loss: 0.94957940, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17654.41015625MB; mem (CPU total)=17590.4296875MB
INFO:root:[  105] Training loss: 0.94557671, Validation loss: 0.94847034, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17692.51171875MB; mem (CPU total)=17628.51171875MB
INFO:root:[  106] Training loss: 0.94537357, Validation loss: 0.94756642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17730.60546875MB; mem (CPU total)=17666.90234375MB
INFO:root:[  107] Training loss: 0.94534951, Validation loss: 0.94660517, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17768.69921875MB; mem (CPU total)=17704.97265625MB
INFO:root:[  108] Training loss: 0.94524249, Validation loss: 0.94728505, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17806.79296875MB; mem (CPU total)=17742.6171875MB
INFO:root:[  109] Training loss: 0.94502096, Validation loss: 0.94683010, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17844.890625MB; mem (CPU total)=17781.0078125MB
INFO:root:[  110] Training loss: 0.94511580, Validation loss: 0.94586992, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17882.984375MB; mem (CPU total)=17819.375MB
INFO:root:[  111] Training loss: 0.94479634, Validation loss: 0.94643928, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17921.078125MB; mem (CPU total)=17857.78125MB
INFO:root:[  112] Training loss: 0.94481764, Validation loss: 0.94733681, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17959.17578125MB; mem (CPU total)=17895.69921875MB
INFO:root:[  113] Training loss: 0.94448322, Validation loss: 0.94659551, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17997.2734375MB; mem (CPU total)=17933.8515625MB
INFO:root:[  114] Training loss: 0.94459823, Validation loss: 0.94592295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18035.3671875MB; mem (CPU total)=17971.70703125MB
INFO:root:[  115] Training loss: 0.94447239, Validation loss: 0.94666146, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18073.46484375MB; mem (CPU total)=18010.1796875MB
INFO:root:[  116] Training loss: 0.94431863, Validation loss: 0.94693479, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18111.55859375MB; mem (CPU total)=18048.18359375MB
INFO:root:[  117] Training loss: 0.94430441, Validation loss: 0.94545681, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18149.65625MB; mem (CPU total)=18086.546875MB
INFO:root:[  118] Training loss: 0.94426091, Validation loss: 0.94607876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18187.75MB; mem (CPU total)=18124.97265625MB
INFO:root:[  119] Training loss: 0.94442143, Validation loss: 0.94599277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18225.84765625MB; mem (CPU total)=18162.63671875MB
INFO:root:[  120] Training loss: 0.94424775, Validation loss: 0.94542147, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18263.953125MB; mem (CPU total)=18201.0703125MB
INFO:root:[  121] Training loss: 0.94400527, Validation loss: 0.94672866, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18302.109375MB; mem (CPU total)=18239.7265625MB
INFO:root:[  122] Training loss: 0.94389911, Validation loss: 0.94598624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18340.20703125MB; mem (CPU total)=18277.74609375MB
INFO:root:[  123] Training loss: 0.94382381, Validation loss: 0.94569166, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18378.3046875MB; mem (CPU total)=18315.81640625MB
INFO:root:[  124] Training loss: 0.94386676, Validation loss: 0.94524359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18416.3984375MB; mem (CPU total)=18353.99609375MB
INFO:root:[  125] Training loss: 0.94356715, Validation loss: 0.94612743, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18454.4921875MB; mem (CPU total)=18392.1328125MB
INFO:root:[  126] Training loss: 0.94354431, Validation loss: 0.94568354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18492.58984375MB; mem (CPU total)=18430.32421875MB
INFO:root:[  127] Training loss: 0.94357405, Validation loss: 0.94557927, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18530.68359375MB; mem (CPU total)=18468.23828125MB
INFO:root:[  128] Training loss: 0.94345581, Validation loss: 0.94484568, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18568.77734375MB; mem (CPU total)=18506.37109375MB
INFO:root:[  129] Training loss: 0.94344961, Validation loss: 0.94581515, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18606.875MB; mem (CPU total)=18543.98046875MB
INFO:root:[  130] Training loss: 0.94361558, Validation loss: 0.94485749, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18644.96875MB; mem (CPU total)=18582.35546875MB
INFO:root:[  131] Training loss: 0.94328972, Validation loss: 0.94516602, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18683.0625MB; mem (CPU total)=18620.49609375MB
INFO:root:[  132] Training loss: 0.94329102, Validation loss: 0.94523416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18721.1640625MB; mem (CPU total)=18658.42578125MB
INFO:root:[  133] Training loss: 0.94314133, Validation loss: 0.94501967, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18759.2578125MB; mem (CPU total)=18696.5625MB
INFO:root:[  134] Training loss: 0.94315298, Validation loss: 0.94581918, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18797.3515625MB; mem (CPU total)=18734.70703125MB
INFO:root:[  135] Training loss: 0.94314288, Validation loss: 0.94513609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18835.4453125MB; mem (CPU total)=18772.7890625MB
INFO:root:[  136] Training loss: 0.94304523, Validation loss: 0.94579795, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18873.54296875MB; mem (CPU total)=18810.93359375MB
INFO:root:[  137] Training loss: 0.94297947, Validation loss: 0.94459106, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18911.63671875MB; mem (CPU total)=18848.9140625MB
INFO:root:[  138] Training loss: 0.94286748, Validation loss: 0.94521647, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18949.73046875MB; mem (CPU total)=18886.79296875MB
INFO:root:[  139] Training loss: 0.94298563, Validation loss: 0.94397756, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18987.83203125MB; mem (CPU total)=18924.15234375MB
INFO:root:[  140] Training loss: 0.94268319, Validation loss: 0.94548206, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19025.92578125MB; mem (CPU total)=18962.29296875MB
INFO:root:[  141] Training loss: 0.94283615, Validation loss: 0.94440390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19064.01953125MB; mem (CPU total)=19000.4375MB
INFO:root:[  142] Training loss: 0.94273780, Validation loss: 0.94456549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19102.11328125MB; mem (CPU total)=19038.58203125MB
INFO:root:[  143] Training loss: 0.94280390, Validation loss: 0.94580658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19140.2109375MB; mem (CPU total)=19076.47265625MB
INFO:root:[  144] Training loss: 0.94282268, Validation loss: 0.94401523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19178.3046875MB; mem (CPU total)=19114.60546875MB
INFO:root:[  145] Training loss: 0.94260627, Validation loss: 0.94458061, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19216.3984375MB; mem (CPU total)=19153.03515625MB
INFO:root:[  146] Training loss: 0.94262069, Validation loss: 0.94427448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19254.49609375MB; mem (CPU total)=19190.6171875MB
INFO:root:[  147] Training loss: 0.94238928, Validation loss: 0.94483429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19292.58984375MB; mem (CPU total)=19228.06640625MB
INFO:root:[  148] Training loss: 0.94238795, Validation loss: 0.94476278, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19330.6875MB; mem (CPU total)=19266.2109375MB
INFO:root:EP 148: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19368.78515625MB; mem (CPU total)=19304.10546875MB
INFO:root:Training the model took 6798.727s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93582
INFO:root:EnergyScoreTrain: 0.87143
INFO:root:CRPSTrain: 0.72558
INFO:root:Gaussian NLLTrain: 9644595245.93778
INFO:root:CoverageTrain: 0.13024
INFO:root:IntervalWidthTrain: 0.24528
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93863
INFO:root:EnergyScoreValidation: 0.87446
INFO:root:CRPSValidation: 0.7284
INFO:root:Gaussian NLLValidation: 9664387797.90222
INFO:root:CoverageValidation: 0.1288
INFO:root:IntervalWidthValidation: 0.24426
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93797
INFO:root:EnergyScoreTest: 0.87376
INFO:root:CRPSTest: 0.72791
INFO:root:Gaussian NLLTest: 9453720599.552
INFO:root:CoverageTest: 0.12897
INFO:root:IntervalWidthTest: 0.2447
INFO:root:After validation: mem (CPU python)=19411.671875MB; mem (CPU total)=19348.0859375MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=19411.671875MB; mem (CPU total)=19348.0859375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=19411.671875MB; mem (CPU total)=19348.0859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=19411.70703125MB; mem (CPU total)=19348.0859375MB
INFO:root:[    1] Training loss: 1.00881472, Validation loss: 0.99524611, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19449.70703125MB; mem (CPU total)=19386.765625MB
INFO:root:[    2] Training loss: 0.98804633, Validation loss: 0.98512518, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19487.81640625MB; mem (CPU total)=19424.9375MB
INFO:root:[    3] Training loss: 0.98082242, Validation loss: 0.97975862, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19525.9140625MB; mem (CPU total)=19462.8125MB
INFO:root:[    4] Training loss: 0.97756472, Validation loss: 0.97813599, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19564.0078125MB; mem (CPU total)=19501.29296875MB
INFO:root:[    5] Training loss: 0.97548779, Validation loss: 0.97592347, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19602.1015625MB; mem (CPU total)=19539.8125MB
INFO:root:[    6] Training loss: 0.97422223, Validation loss: 0.97485367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19640.19921875MB; mem (CPU total)=19577.12109375MB
INFO:root:[    7] Training loss: 0.97303983, Validation loss: 0.97443277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19678.296875MB; mem (CPU total)=19614.890625MB
INFO:root:[    8] Training loss: 0.97208148, Validation loss: 0.97245807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19716.390625MB; mem (CPU total)=19653.12890625MB
INFO:root:[    9] Training loss: 0.97106534, Validation loss: 0.97170247, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19754.484375MB; mem (CPU total)=19691.75MB
INFO:root:[   10] Training loss: 0.97041272, Validation loss: 0.97210858, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19792.58203125MB; mem (CPU total)=19730.38671875MB
INFO:root:[   11] Training loss: 0.96991162, Validation loss: 0.97119109, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19830.67578125MB; mem (CPU total)=19767.70703125MB
INFO:root:[   12] Training loss: 0.96951319, Validation loss: 0.97058527, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19868.76953125MB; mem (CPU total)=19806.09765625MB
INFO:root:[   13] Training loss: 0.96900575, Validation loss: 0.97018972, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19906.8671875MB; mem (CPU total)=19843.71484375MB
INFO:root:[   14] Training loss: 0.96846340, Validation loss: 0.96957842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19944.9609375MB; mem (CPU total)=19881.8125MB
INFO:root:[   15] Training loss: 0.96805534, Validation loss: 0.96906619, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19983.05859375MB; mem (CPU total)=19920.11328125MB
INFO:root:[   16] Training loss: 0.96734244, Validation loss: 0.96916459, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20021.15234375MB; mem (CPU total)=19958.50390625MB
INFO:root:[   17] Training loss: 0.96679961, Validation loss: 0.96769649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20059.25390625MB; mem (CPU total)=19996.04296875MB
INFO:root:[   18] Training loss: 0.96593852, Validation loss: 0.96722470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20097.34765625MB; mem (CPU total)=20034.29296875MB
INFO:root:[   19] Training loss: 0.96520919, Validation loss: 0.96569027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20135.44140625MB; mem (CPU total)=20071.94140625MB
INFO:root:[   20] Training loss: 0.96462818, Validation loss: 0.96499308, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20173.5390625MB; mem (CPU total)=20110.421875MB
INFO:root:[   21] Training loss: 0.96430363, Validation loss: 0.96489295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20211.63671875MB; mem (CPU total)=20148.78515625MB
INFO:root:[   22] Training loss: 0.96361888, Validation loss: 0.96471266, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20249.73046875MB; mem (CPU total)=20187.19140625MB
INFO:root:[   23] Training loss: 0.96314534, Validation loss: 0.96358754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20287.828125MB; mem (CPU total)=20225.61328125MB
INFO:root:[   24] Training loss: 0.96289510, Validation loss: 0.96329538, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20325.921875MB; mem (CPU total)=20263.86328125MB
INFO:root:[   25] Training loss: 0.96247916, Validation loss: 0.96319666, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20364.015625MB; mem (CPU total)=20302.0390625MB
INFO:root:[   26] Training loss: 0.96208329, Validation loss: 0.96210451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20402.109375MB; mem (CPU total)=20340.23046875MB
INFO:root:[   27] Training loss: 0.96172011, Validation loss: 0.96224057, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20440.20703125MB; mem (CPU total)=20378.63671875MB
INFO:root:[   28] Training loss: 0.96114586, Validation loss: 0.96200574, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20478.30078125MB; mem (CPU total)=20416.84375MB
INFO:root:[   29] Training loss: 0.96102652, Validation loss: 0.96191917, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20516.39453125MB; mem (CPU total)=20455.4296875MB
INFO:root:[   30] Training loss: 0.96052879, Validation loss: 0.96118364, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20554.4921875MB; mem (CPU total)=20493.9296875MB
INFO:root:[   31] Training loss: 0.96012982, Validation loss: 0.96137927, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20592.5859375MB; mem (CPU total)=20532.30859375MB
INFO:root:[   32] Training loss: 0.95979574, Validation loss: 0.96053546, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20630.68359375MB; mem (CPU total)=20570.5625MB
INFO:root:[   33] Training loss: 0.95952110, Validation loss: 0.95994637, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20668.77734375MB; mem (CPU total)=20608.76171875MB
INFO:root:[   34] Training loss: 0.95918895, Validation loss: 0.96032332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20706.875MB; mem (CPU total)=20646.40625MB
INFO:root:[   35] Training loss: 0.95897522, Validation loss: 0.95983481, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20744.96875MB; mem (CPU total)=20683.78125MB
INFO:root:[   36] Training loss: 0.95856337, Validation loss: 0.95928843, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20783.0625MB; mem (CPU total)=20722.27734375MB
INFO:root:[   37] Training loss: 0.95837677, Validation loss: 0.95915713, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20821.16015625MB; mem (CPU total)=20760.5MB
INFO:root:[   38] Training loss: 0.95842184, Validation loss: 0.95872508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20859.2578125MB; mem (CPU total)=20798.09375MB
INFO:root:[   39] Training loss: 0.95809621, Validation loss: 0.95962761, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20897.34765625MB; mem (CPU total)=20836.1875MB
INFO:root:[   40] Training loss: 0.95795925, Validation loss: 0.95900332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20935.44921875MB; mem (CPU total)=20874.26953125MB
INFO:root:[   41] Training loss: 0.95772798, Validation loss: 0.95912589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20973.54296875MB; mem (CPU total)=20912.3828125MB
INFO:root:[   42] Training loss: 0.95754432, Validation loss: 0.95872497, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21011.640625MB; mem (CPU total)=20949.5546875MB
INFO:root:[   43] Training loss: 0.95707212, Validation loss: 0.95742413, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21049.734375MB; mem (CPU total)=20987.80859375MB
INFO:root:[   44] Training loss: 0.95678990, Validation loss: 0.95776816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21087.83203125MB; mem (CPU total)=21025.90625MB
INFO:root:[   45] Training loss: 0.95676138, Validation loss: 0.95741560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21125.92578125MB; mem (CPU total)=21064.546875MB
INFO:root:[   46] Training loss: 0.95670599, Validation loss: 0.95714692, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21164.01953125MB; mem (CPU total)=21102.5390625MB
INFO:root:[   47] Training loss: 0.95625392, Validation loss: 0.95761952, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21202.1171875MB; mem (CPU total)=21140.9140625MB
INFO:root:[   48] Training loss: 0.95618175, Validation loss: 0.95683366, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21240.21484375MB; mem (CPU total)=21179.0546875MB
INFO:root:[   49] Training loss: 0.95587088, Validation loss: 0.95767867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21278.30859375MB; mem (CPU total)=21217.3984375MB
INFO:root:[   50] Training loss: 0.95591034, Validation loss: 0.95812491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21316.40234375MB; mem (CPU total)=21255.2578125MB
INFO:root:[   51] Training loss: 0.95567949, Validation loss: 0.95704438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21354.5MB; mem (CPU total)=21293.38671875MB
INFO:root:[   52] Training loss: 0.95543995, Validation loss: 0.95687465, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21392.59375MB; mem (CPU total)=21331.7421875MB
INFO:root:[   53] Training loss: 0.95517694, Validation loss: 0.95655876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21430.69140625MB; mem (CPU total)=21369.75390625MB
INFO:root:[   54] Training loss: 0.95511980, Validation loss: 0.95773531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21468.78515625MB; mem (CPU total)=21408.1171875MB
INFO:root:[   55] Training loss: 0.95488554, Validation loss: 0.95606022, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21506.8828125MB; mem (CPU total)=21446.25390625MB
INFO:root:[   56] Training loss: 0.95469673, Validation loss: 0.95608700, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21544.9765625MB; mem (CPU total)=21483.359375MB
INFO:root:[   57] Training loss: 0.95441304, Validation loss: 0.95576952, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21583.07421875MB; mem (CPU total)=21521.79296875MB
INFO:root:[   58] Training loss: 0.95440796, Validation loss: 0.95587437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21621.16796875MB; mem (CPU total)=21559.89453125MB
INFO:root:[   59] Training loss: 0.95428841, Validation loss: 0.95508726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21659.26171875MB; mem (CPU total)=21598.08203125MB
INFO:root:[   60] Training loss: 0.95399561, Validation loss: 0.95532535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21697.359375MB; mem (CPU total)=21636.4375MB
INFO:root:[   61] Training loss: 0.95366717, Validation loss: 0.95564515, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21735.45703125MB; mem (CPU total)=21674.32421875MB
INFO:root:[   62] Training loss: 0.95368190, Validation loss: 0.95501823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21773.5546875MB; mem (CPU total)=21712.5390625MB
INFO:root:[   63] Training loss: 0.95342835, Validation loss: 0.95481320, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21811.6484375MB; mem (CPU total)=21750.94921875MB
INFO:root:[   64] Training loss: 0.95325377, Validation loss: 0.95357476, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21849.74609375MB; mem (CPU total)=21789.140625MB
INFO:root:[   65] Training loss: 0.95302935, Validation loss: 0.95552348, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21887.8359375MB; mem (CPU total)=21827.51171875MB
INFO:root:[   66] Training loss: 0.95299038, Validation loss: 0.95452910, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21925.93359375MB; mem (CPU total)=21866.9140625MB
INFO:root:[   67] Training loss: 0.95297746, Validation loss: 0.95382218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21964.02734375MB; mem (CPU total)=21905.05859375MB
INFO:root:[   68] Training loss: 0.95269717, Validation loss: 0.95362396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22002.125MB; mem (CPU total)=21942.94921875MB
INFO:root:[   69] Training loss: 0.95259341, Validation loss: 0.95343373, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22040.22265625MB; mem (CPU total)=21981.765625MB
INFO:root:[   70] Training loss: 0.95226913, Validation loss: 0.95515537, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22078.3125MB; mem (CPU total)=22020.140625MB
INFO:root:[   71] Training loss: 0.95222016, Validation loss: 0.95368172, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22116.4140625MB; mem (CPU total)=22057.80859375MB
INFO:root:[   72] Training loss: 0.95187510, Validation loss: 0.95434137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22154.5078125MB; mem (CPU total)=22095.9453125MB
INFO:root:[   73] Training loss: 0.95187476, Validation loss: 0.95280042, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22192.6015625MB; mem (CPU total)=22133.921875MB
INFO:root:[   74] Training loss: 0.95166285, Validation loss: 0.95361387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22230.69921875MB; mem (CPU total)=22172.54296875MB
INFO:root:[   75] Training loss: 0.95172413, Validation loss: 0.95299360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22268.79296875MB; mem (CPU total)=22210.66796875MB
INFO:root:[   76] Training loss: 0.95185653, Validation loss: 0.95331520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22306.88671875MB; mem (CPU total)=22248.2734375MB
INFO:root:[   77] Training loss: 0.95163976, Validation loss: 0.95337031, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22344.98046875MB; mem (CPU total)=22286.67578125MB
INFO:root:[   78] Training loss: 0.95121957, Validation loss: 0.95361630, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22383.078125MB; mem (CPU total)=22324.8125MB
INFO:root:[   79] Training loss: 0.95135361, Validation loss: 0.95235500, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22421.17578125MB; mem (CPU total)=22363.09375MB
INFO:root:[   80] Training loss: 0.95120383, Validation loss: 0.95242825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22459.265625MB; mem (CPU total)=22401.2421875MB
INFO:root:[   81] Training loss: 0.95098847, Validation loss: 0.95307892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22497.3671875MB; mem (CPU total)=22439.62890625MB
INFO:root:[   82] Training loss: 0.95087403, Validation loss: 0.95390916, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22535.4609375MB; mem (CPU total)=22477.7734375MB
INFO:root:[   83] Training loss: 0.95091512, Validation loss: 0.95425792, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22573.5546875MB; mem (CPU total)=22515.91796875MB
INFO:root:[   84] Training loss: 0.95063815, Validation loss: 0.95215092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22611.6484375MB; mem (CPU total)=22554.09765625MB
INFO:root:[   85] Training loss: 0.95066307, Validation loss: 0.95293189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22649.74609375MB; mem (CPU total)=22592.23828125MB
INFO:root:[   86] Training loss: 0.95052026, Validation loss: 0.95201667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22687.83984375MB; mem (CPU total)=22630.46875MB
INFO:root:[   87] Training loss: 0.95030097, Validation loss: 0.95205602, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22725.93359375MB; mem (CPU total)=22668.62109375MB
INFO:root:[   88] Training loss: 0.95035348, Validation loss: 0.95175948, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22764.03125MB; mem (CPU total)=22706.453125MB
INFO:root:[   89] Training loss: 0.95032706, Validation loss: 0.95207181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22802.125MB; mem (CPU total)=22744.625MB
INFO:root:[   90] Training loss: 0.95018336, Validation loss: 0.95193957, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22840.21875MB; mem (CPU total)=22782.75390625MB
INFO:root:[   91] Training loss: 0.95012190, Validation loss: 0.95251766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22878.3203125MB; mem (CPU total)=22820.87890625MB
INFO:root:[   92] Training loss: 0.95012345, Validation loss: 0.95309816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22916.4140625MB; mem (CPU total)=22859.20703125MB
INFO:root:[   93] Training loss: 0.95011734, Validation loss: 0.95079901, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22954.5078125MB; mem (CPU total)=22897.65234375MB
INFO:root:[   94] Training loss: 0.94996914, Validation loss: 0.95200270, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22992.6015625MB; mem (CPU total)=22936.0390625MB
INFO:root:[   95] Training loss: 0.94966668, Validation loss: 0.95139799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23030.69921875MB; mem (CPU total)=22974.16015625MB
INFO:root:[   96] Training loss: 0.94962156, Validation loss: 0.95144008, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23068.79296875MB; mem (CPU total)=23012.05859375MB
INFO:root:[   97] Training loss: 0.94975155, Validation loss: 0.95102663, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23106.88671875MB; mem (CPU total)=23050.2109375MB
INFO:root:[   98] Training loss: 0.94943951, Validation loss: 0.95116919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23144.984375MB; mem (CPU total)=23088.83203125MB
INFO:root:[   99] Training loss: 0.94946399, Validation loss: 0.95084468, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23183.08203125MB; mem (CPU total)=23126.46484375MB
INFO:root:[  100] Training loss: 0.94939488, Validation loss: 0.95113231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23221.17578125MB; mem (CPU total)=23164.8359375MB
INFO:root:[  101] Training loss: 0.94911248, Validation loss: 0.95182181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23259.26953125MB; mem (CPU total)=23202.97265625MB
INFO:root:[  102] Training loss: 0.94930679, Validation loss: 0.95111188, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23297.37109375MB; mem (CPU total)=23241.2109375MB
INFO:root:EP 102: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=23335.421875MB; mem (CPU total)=23279.02734375MB
INFO:root:Training the model took 5130.41s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94204
INFO:root:EnergyScoreTrain: 0.87164
INFO:root:CRPSTrain: 0.72929
INFO:root:Gaussian NLLTrain: 24220896825.45782
INFO:root:CoverageTrain: 0.14613
INFO:root:IntervalWidthTrain: 0.28848
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94467
INFO:root:EnergyScoreValidation: 0.87461
INFO:root:CRPSValidation: 0.73205
INFO:root:Gaussian NLLValidation: 24438639124.47999
INFO:root:CoverageValidation: 0.14406
INFO:root:IntervalWidthValidation: 0.28697
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.9436
INFO:root:EnergyScoreTest: 0.87345
INFO:root:CRPSTest: 0.73103
INFO:root:Gaussian NLLTest: 23086428012.544
INFO:root:CoverageTest: 0.14497
INFO:root:IntervalWidthTest: 0.28732
INFO:root:After validation: mem (CPU python)=23378.2734375MB; mem (CPU total)=23321.859375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=23378.2734375MB; mem (CPU total)=23321.87890625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=23378.27734375MB; mem (CPU total)=23321.875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=23378.39453125MB; mem (CPU total)=23322.12109375MB
INFO:root:[    1] Training loss: 1.00984693, Validation loss: 0.99664919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23416.4296875MB; mem (CPU total)=23360.84765625MB
INFO:root:[    2] Training loss: 0.98961826, Validation loss: 0.98687415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23454.53125MB; mem (CPU total)=23399.140625MB
INFO:root:[    3] Training loss: 0.98322371, Validation loss: 0.98224207, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23492.625MB; mem (CPU total)=23437.50390625MB
INFO:root:[    4] Training loss: 0.98036004, Validation loss: 0.98044554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23530.7265625MB; mem (CPU total)=23475.6015625MB
INFO:root:[    5] Training loss: 0.97848898, Validation loss: 0.97856078, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23568.81640625MB; mem (CPU total)=23513.90625MB
INFO:root:[    6] Training loss: 0.97741059, Validation loss: 0.97778809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23606.9140625MB; mem (CPU total)=23552.28515625MB
INFO:root:[    7] Training loss: 0.97639607, Validation loss: 0.97750925, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23645.0078125MB; mem (CPU total)=23590.484375MB
INFO:root:[    8] Training loss: 0.97556393, Validation loss: 0.97736230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23683.10546875MB; mem (CPU total)=23628.0703125MB
INFO:root:[    9] Training loss: 0.97500924, Validation loss: 0.97599403, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23721.19921875MB; mem (CPU total)=23666.3984375MB
INFO:root:[   10] Training loss: 0.97438538, Validation loss: 0.97521327, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23759.29296875MB; mem (CPU total)=23705.5234375MB
INFO:root:[   11] Training loss: 0.97382399, Validation loss: 0.97453179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23797.390625MB; mem (CPU total)=23743.6796875MB
INFO:root:[   12] Training loss: 0.97348161, Validation loss: 0.97472707, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23835.484375MB; mem (CPU total)=23781.81640625MB
INFO:root:[   13] Training loss: 0.97293041, Validation loss: 0.97393809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23873.58203125MB; mem (CPU total)=23820.015625MB
INFO:root:[   14] Training loss: 0.97246740, Validation loss: 0.97390683, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23911.6796875MB; mem (CPU total)=23858.45703125MB
INFO:root:[   15] Training loss: 0.97212671, Validation loss: 0.97499075, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23949.7734375MB; mem (CPU total)=23896.70703125MB
INFO:root:[   16] Training loss: 0.97163049, Validation loss: 0.97319295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23987.8671875MB; mem (CPU total)=23934.60546875MB
INFO:root:[   17] Training loss: 0.97107322, Validation loss: 0.97280984, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24025.9609375MB; mem (CPU total)=23972.8828125MB
INFO:root:[   18] Training loss: 0.97084724, Validation loss: 0.97212038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24064.05859375MB; mem (CPU total)=24011.1796875MB
INFO:root:[   19] Training loss: 0.97016635, Validation loss: 0.97124819, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24102.15625MB; mem (CPU total)=24049.51171875MB
INFO:root:[   20] Training loss: 0.96947382, Validation loss: 0.97014638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24140.25MB; mem (CPU total)=24088.23046875MB
INFO:root:[   21] Training loss: 0.96907879, Validation loss: 0.96974361, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24178.34765625MB; mem (CPU total)=24129.71484375MB
INFO:root:[   22] Training loss: 0.96842478, Validation loss: 0.96903145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24216.44140625MB; mem (CPU total)=24167.6796875MB
INFO:root:[   23] Training loss: 0.96793483, Validation loss: 0.96796526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24254.53515625MB; mem (CPU total)=24205.296875MB
INFO:root:[   24] Training loss: 0.96754566, Validation loss: 0.96766902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24292.62890625MB; mem (CPU total)=24243.73046875MB
INFO:root:[   25] Training loss: 0.96707366, Validation loss: 0.96743484, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24330.73046875MB; mem (CPU total)=24282.08203125MB
INFO:root:[   26] Training loss: 0.96658695, Validation loss: 0.96679219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24368.82421875MB; mem (CPU total)=24320.578125MB
INFO:root:[   27] Training loss: 0.96636094, Validation loss: 0.96767090, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24406.91796875MB; mem (CPU total)=24358.95703125MB
INFO:root:[   28] Training loss: 0.96590247, Validation loss: 0.96694640, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24445.015625MB; mem (CPU total)=24397.08203125MB
INFO:root:[   29] Training loss: 0.96550069, Validation loss: 0.96648344, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24483.109375MB; mem (CPU total)=24434.3828125MB
INFO:root:[   30] Training loss: 0.96526015, Validation loss: 0.96604382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24521.203125MB; mem (CPU total)=24472.76953125MB
INFO:root:[   31] Training loss: 0.96503753, Validation loss: 0.96642653, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24559.30078125MB; mem (CPU total)=24511.35546875MB
INFO:root:[   32] Training loss: 0.96502400, Validation loss: 0.96553107, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24597.39453125MB; mem (CPU total)=24549.45703125MB
INFO:root:[   33] Training loss: 0.96445906, Validation loss: 0.96595355, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24635.48828125MB; mem (CPU total)=24587.84375MB
INFO:root:[   34] Training loss: 0.96419037, Validation loss: 0.96582651, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24673.5859375MB; mem (CPU total)=24625.75390625MB
INFO:root:[   35] Training loss: 0.96398167, Validation loss: 0.96491904, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24711.6875MB; mem (CPU total)=24664.15625MB
INFO:root:[   36] Training loss: 0.96378469, Validation loss: 0.96396284, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24749.78125MB; mem (CPU total)=24700.6484375MB
INFO:root:[   37] Training loss: 0.96342919, Validation loss: 0.96445368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24787.875MB; mem (CPU total)=24738.8125MB
INFO:root:[   38] Training loss: 0.96337484, Validation loss: 0.96433418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24825.97265625MB; mem (CPU total)=24776.9375MB
INFO:root:[   39] Training loss: 0.96288880, Validation loss: 0.96393026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24864.06640625MB; mem (CPU total)=24814.91796875MB
INFO:root:[   40] Training loss: 0.96288760, Validation loss: 0.96366020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24902.16015625MB; mem (CPU total)=24853.39453125MB
INFO:root:[   41] Training loss: 0.96269400, Validation loss: 0.96401164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24940.25390625MB; mem (CPU total)=24891.77734375MB
INFO:root:[   42] Training loss: 0.96253194, Validation loss: 0.96363084, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24978.35546875MB; mem (CPU total)=24929.828125MB
INFO:root:[   43] Training loss: 0.96241367, Validation loss: 0.96293961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25016.44921875MB; mem (CPU total)=24967.9765625MB
INFO:root:[   44] Training loss: 0.96231551, Validation loss: 0.96318702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25054.5390625MB; mem (CPU total)=25006.33984375MB
INFO:root:[   45] Training loss: 0.96205559, Validation loss: 0.96378006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25092.640625MB; mem (CPU total)=25044.46484375MB
INFO:root:[   46] Training loss: 0.96207117, Validation loss: 0.96337891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25130.734375MB; mem (CPU total)=25082.3515625MB
INFO:root:[   47] Training loss: 0.96150728, Validation loss: 0.96313048, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25168.828125MB; mem (CPU total)=25121.91796875MB
INFO:root:[   48] Training loss: 0.96137580, Validation loss: 0.96264729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25206.92578125MB; mem (CPU total)=25160.76953125MB
INFO:root:[   49] Training loss: 0.96133927, Validation loss: 0.96193788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25245.01953125MB; mem (CPU total)=25198.515625MB
INFO:root:[   50] Training loss: 0.96130592, Validation loss: 0.96160362, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25283.11328125MB; mem (CPU total)=25233.8125MB
INFO:root:[   51] Training loss: 0.96120534, Validation loss: 0.96226949, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25321.20703125MB; mem (CPU total)=25271.92578125MB
INFO:root:[   52] Training loss: 0.96095874, Validation loss: 0.96242821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25359.30859375MB; mem (CPU total)=25310.52734375MB
INFO:root:[   53] Training loss: 0.96075648, Validation loss: 0.96129857, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25397.40234375MB; mem (CPU total)=25348.59375MB
INFO:root:[   54] Training loss: 0.96079138, Validation loss: 0.96213795, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25435.49609375MB; mem (CPU total)=25386.98046875MB
INFO:root:[   55] Training loss: 0.96046512, Validation loss: 0.96172584, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25473.59375MB; mem (CPU total)=25425.09375MB
INFO:root:[   56] Training loss: 0.96038765, Validation loss: 0.96115849, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25511.6875MB; mem (CPU total)=25463.328125MB
INFO:root:[   57] Training loss: 0.96032875, Validation loss: 0.96133761, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25549.78125MB; mem (CPU total)=25501.68359375MB
INFO:root:[   58] Training loss: 0.95992991, Validation loss: 0.96118261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25587.875MB; mem (CPU total)=25539.81640625MB
INFO:root:[   59] Training loss: 0.96018596, Validation loss: 0.96199598, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25625.97265625MB; mem (CPU total)=25578.4453125MB
INFO:root:[   60] Training loss: 0.96005570, Validation loss: 0.96107680, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25664.0703125MB; mem (CPU total)=25616.29296875MB
INFO:root:[   61] Training loss: 0.95981597, Validation loss: 0.96029184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25702.1640625MB; mem (CPU total)=25654.0078125MB
INFO:root:[   62] Training loss: 0.95959933, Validation loss: 0.96065902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25740.26171875MB; mem (CPU total)=25691.1953125MB
INFO:root:[   63] Training loss: 0.95950455, Validation loss: 0.96021342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25778.35546875MB; mem (CPU total)=25729.5234375MB
INFO:root:[   64] Training loss: 0.95939695, Validation loss: 0.96023760, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25816.44921875MB; mem (CPU total)=25767.9140625MB
INFO:root:[   65] Training loss: 0.95932371, Validation loss: 0.96117084, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25854.546875MB; mem (CPU total)=25806.05859375MB
INFO:root:[   66] Training loss: 0.95931984, Validation loss: 0.96066976, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25892.640625MB; mem (CPU total)=25844.1640625MB
INFO:root:[   67] Training loss: 0.95908109, Validation loss: 0.95998338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25930.73828125MB; mem (CPU total)=25881.98828125MB
INFO:root:[   68] Training loss: 0.95915836, Validation loss: 0.95965866, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25968.83203125MB; mem (CPU total)=25920.5390625MB
INFO:root:[   69] Training loss: 0.95882426, Validation loss: 0.95873303, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26006.9296875MB; mem (CPU total)=25958.859375MB
INFO:root:[   70] Training loss: 0.95867057, Validation loss: 0.96034213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26045.0234375MB; mem (CPU total)=25997.203125MB
INFO:root:[   71] Training loss: 0.95869220, Validation loss: 0.95920347, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26083.1171875MB; mem (CPU total)=26035.31640625MB
INFO:root:[   72] Training loss: 0.95856612, Validation loss: 0.96031307, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26121.21484375MB; mem (CPU total)=26073.44140625MB
INFO:root:[   73] Training loss: 0.95842171, Validation loss: 0.95945448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26159.30859375MB; mem (CPU total)=26111.1015625MB
INFO:root:[   74] Training loss: 0.95828970, Validation loss: 0.95993259, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26197.40234375MB; mem (CPU total)=26149.73046875MB
INFO:root:[   75] Training loss: 0.95826947, Validation loss: 0.95927300, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26235.49609375MB; mem (CPU total)=26187.484375MB
INFO:root:[   76] Training loss: 0.95824151, Validation loss: 0.95907086, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26273.59375MB; mem (CPU total)=26225.86328125MB
INFO:root:[   77] Training loss: 0.95815358, Validation loss: 0.95957861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26311.69140625MB; mem (CPU total)=26264.25390625MB
INFO:root:[   78] Training loss: 0.95820088, Validation loss: 0.96069430, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26349.78515625MB; mem (CPU total)=26302.12109375MB
INFO:root:EP 78: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=26387.88671875MB; mem (CPU total)=26340.01953125MB
INFO:root:Training the model took 4176.233s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94891
INFO:root:EnergyScoreTrain: 0.87116
INFO:root:CRPSTrain: 0.73419
INFO:root:Gaussian NLLTrain: 47611206997.33331
INFO:root:CoverageTrain: 0.15527
INFO:root:IntervalWidthTrain: 0.31537
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.95071
INFO:root:EnergyScoreValidation: 0.8734
INFO:root:CRPSValidation: 0.73622
INFO:root:Gaussian NLLValidation: 47565952086.47111
INFO:root:CoverageValidation: 0.15338
INFO:root:IntervalWidthValidation: 0.31351
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.95027
INFO:root:EnergyScoreTest: 0.87289
INFO:root:CRPSTest: 0.7359
INFO:root:Gaussian NLLTest: 48155729330.17601
INFO:root:CoverageTest: 0.15373
INFO:root:IntervalWidthTest: 0.31351
INFO:root:After validation: mem (CPU python)=26430.59375MB; mem (CPU total)=26385.84765625MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=26430.59375MB; mem (CPU total)=26385.84765625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=26430.609375MB; mem (CPU total)=26385.84765625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=26430.7421875MB; mem (CPU total)=26385.84375MB
INFO:root:[    1] Training loss: 1.01147708, Validation loss: 0.99859621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26468.78515625MB; mem (CPU total)=26424.3125MB
INFO:root:[    2] Training loss: 0.99230077, Validation loss: 0.98985290, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26506.8828125MB; mem (CPU total)=26458.34375MB
INFO:root:[    3] Training loss: 0.98696489, Validation loss: 0.98596190, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26544.9765625MB; mem (CPU total)=26496.38671875MB
INFO:root:[    4] Training loss: 0.98453979, Validation loss: 0.98492696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26583.07421875MB; mem (CPU total)=26534.8515625MB
INFO:root:[    5] Training loss: 0.98307268, Validation loss: 0.98374590, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26621.16796875MB; mem (CPU total)=26573.23828125MB
INFO:root:[    6] Training loss: 0.98207938, Validation loss: 0.98237204, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26659.265625MB; mem (CPU total)=26611.2734375MB
INFO:root:[    7] Training loss: 0.98139145, Validation loss: 0.98274971, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26697.359375MB; mem (CPU total)=26649.6484375MB
INFO:root:[    8] Training loss: 0.98076558, Validation loss: 0.98150768, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26735.453125MB; mem (CPU total)=26687.734375MB
INFO:root:[    9] Training loss: 0.98028825, Validation loss: 0.98036539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26773.55078125MB; mem (CPU total)=26725.66015625MB
INFO:root:[   10] Training loss: 0.97985881, Validation loss: 0.98110331, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26811.64453125MB; mem (CPU total)=26763.97265625MB
INFO:root:[   11] Training loss: 0.97945031, Validation loss: 0.97996703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26849.7421875MB; mem (CPU total)=26802.0703125MB
INFO:root:[   12] Training loss: 0.97949642, Validation loss: 0.97942652, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26887.8359375MB; mem (CPU total)=26839.5859375MB
INFO:root:[   13] Training loss: 0.97905034, Validation loss: 0.98002385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26925.93359375MB; mem (CPU total)=26877.61328125MB
INFO:root:[   14] Training loss: 0.97874964, Validation loss: 0.97997988, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26964.02734375MB; mem (CPU total)=26915.72265625MB
INFO:root:[   15] Training loss: 0.97822994, Validation loss: 0.97871122, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27002.12109375MB; mem (CPU total)=26954.1328125MB
INFO:root:[   16] Training loss: 0.97756870, Validation loss: 0.97952898, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27040.21875MB; mem (CPU total)=26992.00390625MB
INFO:root:[   17] Training loss: 0.97734125, Validation loss: 0.97836690, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27078.3125MB; mem (CPU total)=27029.140625MB
INFO:root:[   18] Training loss: 0.97707181, Validation loss: 0.97841075, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27116.40625MB; mem (CPU total)=27067.484375MB
INFO:root:[   19] Training loss: 0.97625519, Validation loss: 0.97854551, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27154.50390625MB; mem (CPU total)=27106.39453125MB
INFO:root:[   20] Training loss: 0.97596490, Validation loss: 0.97590173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27192.6015625MB; mem (CPU total)=27145.96484375MB
INFO:root:[   21] Training loss: 0.97539184, Validation loss: 0.97600799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27230.6953125MB; mem (CPU total)=27184.04296875MB
INFO:root:[   22] Training loss: 0.97477660, Validation loss: 0.97657030, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27268.78515625MB; mem (CPU total)=27222.18359375MB
INFO:root:[   23] Training loss: 0.97454275, Validation loss: 0.97492287, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27306.88671875MB; mem (CPU total)=27259.703125MB
INFO:root:[   24] Training loss: 0.97409335, Validation loss: 0.97481867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27344.98046875MB; mem (CPU total)=27297.359375MB
INFO:root:[   25] Training loss: 0.97378274, Validation loss: 0.97396336, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27383.078125MB; mem (CPU total)=27334.98828125MB
INFO:root:[   26] Training loss: 0.97327658, Validation loss: 0.97393962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27421.17578125MB; mem (CPU total)=27373.42578125MB
INFO:root:[   27] Training loss: 0.97296028, Validation loss: 0.97481533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27459.2734375MB; mem (CPU total)=27411.54296875MB
INFO:root:[   28] Training loss: 0.97245055, Validation loss: 0.97318215, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27497.37109375MB; mem (CPU total)=27449.4609375MB
INFO:root:[   29] Training loss: 0.97224687, Validation loss: 0.97355063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27535.46484375MB; mem (CPU total)=27487.78515625MB
INFO:root:[   30] Training loss: 0.97200923, Validation loss: 0.97229281, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27573.55859375MB; mem (CPU total)=27526.0546875MB
INFO:root:[   31] Training loss: 0.97167535, Validation loss: 0.97187701, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27611.65625MB; mem (CPU total)=27564.578125MB
INFO:root:[   32] Training loss: 0.97155752, Validation loss: 0.97215324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27649.75MB; mem (CPU total)=27602.9375MB
INFO:root:[   33] Training loss: 0.97112776, Validation loss: 0.97090029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27687.84765625MB; mem (CPU total)=27641.21875MB
INFO:root:[   34] Training loss: 0.97090052, Validation loss: 0.97217874, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27725.94140625MB; mem (CPU total)=27679.58203125MB
INFO:root:[   35] Training loss: 0.97069566, Validation loss: 0.97119557, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27764.03515625MB; mem (CPU total)=27717.6015625MB
INFO:root:[   36] Training loss: 0.97055963, Validation loss: 0.97019789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27802.13671875MB; mem (CPU total)=27755.9296875MB
INFO:root:[   37] Training loss: 0.97006985, Validation loss: 0.97194377, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27840.23046875MB; mem (CPU total)=27794.2890625MB
INFO:root:[   38] Training loss: 0.96982598, Validation loss: 0.97027733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27878.32421875MB; mem (CPU total)=27832.40234375MB
INFO:root:[   39] Training loss: 0.96965582, Validation loss: 0.97081876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27916.4140625MB; mem (CPU total)=27870.2265625MB
INFO:root:[   40] Training loss: 0.96980624, Validation loss: 0.96965231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27954.515625MB; mem (CPU total)=27908.21875MB
INFO:root:[   41] Training loss: 0.96955870, Validation loss: 0.96997400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27992.609375MB; mem (CPU total)=27946.58984375MB
INFO:root:[   42] Training loss: 0.96953104, Validation loss: 0.97043838, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28030.703125MB; mem (CPU total)=27984.94140625MB
INFO:root:[   43] Training loss: 0.96926489, Validation loss: 0.96949086, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28068.8046875MB; mem (CPU total)=28022.9296875MB
INFO:root:[   44] Training loss: 0.96909131, Validation loss: 0.96932851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28106.8984375MB; mem (CPU total)=28061.12109375MB
INFO:root:[   45] Training loss: 0.96903027, Validation loss: 0.96949210, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28144.98828125MB; mem (CPU total)=28098.7578125MB
INFO:root:[   46] Training loss: 0.96885423, Validation loss: 0.96910357, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28183.0859375MB; mem (CPU total)=28137.1328125MB
INFO:root:[   47] Training loss: 0.96855524, Validation loss: 0.96884601, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28221.18359375MB; mem (CPU total)=28175.36328125MB
INFO:root:[   48] Training loss: 0.96858261, Validation loss: 0.96986185, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28259.27734375MB; mem (CPU total)=28213.73828125MB
INFO:root:[   49] Training loss: 0.96868004, Validation loss: 0.96913676, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28297.37109375MB; mem (CPU total)=28251.85546875MB
INFO:root:[   50] Training loss: 0.96828186, Validation loss: 0.96890127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28335.46875MB; mem (CPU total)=28289.7421875MB
INFO:root:[   51] Training loss: 0.96836095, Validation loss: 0.96825045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28373.56640625MB; mem (CPU total)=28327.984375MB
INFO:root:[   52] Training loss: 0.96811459, Validation loss: 0.96919064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28411.65625MB; mem (CPU total)=28366.5703125MB
INFO:root:[   53] Training loss: 0.96782206, Validation loss: 0.96911194, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28449.7578125MB; mem (CPU total)=28404.66015625MB
INFO:root:[   54] Training loss: 0.96782877, Validation loss: 0.96905371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28487.84765625MB; mem (CPU total)=28442.7578125MB
INFO:root:[   55] Training loss: 0.96753481, Validation loss: 0.96875807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28525.9453125MB; mem (CPU total)=28480.625MB
INFO:root:[   56] Training loss: 0.96760267, Validation loss: 0.96855894, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28564.0390625MB; mem (CPU total)=28519.46484375MB
INFO:root:[   57] Training loss: 0.96749102, Validation loss: 0.96818813, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28602.13671875MB; mem (CPU total)=28558.13671875MB
INFO:root:[   58] Training loss: 0.96734397, Validation loss: 0.96833853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28640.23046875MB; mem (CPU total)=28596.2421875MB
INFO:root:[   59] Training loss: 0.96736335, Validation loss: 0.96778707, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28678.32421875MB; mem (CPU total)=28634.44921875MB
INFO:root:[   60] Training loss: 0.96734399, Validation loss: 0.96929398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28716.421875MB; mem (CPU total)=28672.546875MB
INFO:root:[   61] Training loss: 0.96704243, Validation loss: 0.96785473, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28754.51953125MB; mem (CPU total)=28710.66796875MB
INFO:root:[   62] Training loss: 0.96712304, Validation loss: 0.96829933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28792.609375MB; mem (CPU total)=28749.25390625MB
INFO:root:[   63] Training loss: 0.96712535, Validation loss: 0.96789596, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28830.70703125MB; mem (CPU total)=28787.60546875MB
INFO:root:[   64] Training loss: 0.96701289, Validation loss: 0.96807325, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28868.8046875MB; mem (CPU total)=30774.18359375MB
INFO:root:[   65] Training loss: 0.96671951, Validation loss: 0.96819923, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28906.8984375MB; mem (CPU total)=32339.99609375MB
INFO:root:[   66] Training loss: 0.96663514, Validation loss: 0.96870586, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28944.9921875MB; mem (CPU total)=32382.68359375MB
INFO:root:[   67] Training loss: 0.96675998, Validation loss: 0.96752581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28983.09765625MB; mem (CPU total)=32426.58203125MB
INFO:root:[   68] Training loss: 0.96653203, Validation loss: 0.96686292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29021.19140625MB; mem (CPU total)=32562.1640625MB
INFO:root:[   69] Training loss: 0.96626252, Validation loss: 0.96724876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29059.28125MB; mem (CPU total)=32507.98046875MB
INFO:root:[   70] Training loss: 0.96618519, Validation loss: 0.96725040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29097.3828125MB; mem (CPU total)=32543.16796875MB
INFO:root:[   71] Training loss: 0.96634258, Validation loss: 0.96761892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29135.4765625MB; mem (CPU total)=32587.40234375MB
INFO:root:[   72] Training loss: 0.96597819, Validation loss: 0.96685473, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29173.5703125MB; mem (CPU total)=32623.80859375MB
INFO:root:[   73] Training loss: 0.96622740, Validation loss: 0.96720323, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29211.6640625MB; mem (CPU total)=32664.078125MB
INFO:root:[   74] Training loss: 0.96610203, Validation loss: 0.96695475, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29249.76171875MB; mem (CPU total)=32706.17578125MB
INFO:root:[   75] Training loss: 0.96578425, Validation loss: 0.96680390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29287.85546875MB; mem (CPU total)=32742.25390625MB
INFO:root:[   76] Training loss: 0.96581394, Validation loss: 0.96639350, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29325.94921875MB; mem (CPU total)=32786.8515625MB
INFO:root:[   77] Training loss: 0.96583299, Validation loss: 0.96627318, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29364.05078125MB; mem (CPU total)=32827.74609375MB
INFO:root:[   78] Training loss: 0.96576696, Validation loss: 0.96652705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29402.140625MB; mem (CPU total)=33005.4296875MB
INFO:root:[   79] Training loss: 0.96548824, Validation loss: 0.96642164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29440.23828125MB; mem (CPU total)=32907.45703125MB
INFO:root:[   80] Training loss: 0.96539466, Validation loss: 0.96691348, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29478.33203125MB; mem (CPU total)=31925.1171875MB
INFO:root:[   81] Training loss: 0.96535081, Validation loss: 0.96656997, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29516.4296875MB; mem (CPU total)=31970.45703125MB
INFO:root:[   82] Training loss: 0.96537204, Validation loss: 0.96614280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29554.5234375MB; mem (CPU total)=32012.68359375MB
INFO:root:[   83] Training loss: 0.96532244, Validation loss: 0.96665719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29592.6171875MB; mem (CPU total)=32050.83984375MB
INFO:root:[   84] Training loss: 0.96517954, Validation loss: 0.96664766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29630.71484375MB; mem (CPU total)=32092.546875MB
INFO:root:[   85] Training loss: 0.96512830, Validation loss: 0.96600771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29668.8125MB; mem (CPU total)=32126.64453125MB
INFO:root:[   86] Training loss: 0.96503440, Validation loss: 0.96673422, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29706.90234375MB; mem (CPU total)=32164.41796875MB
INFO:root:[   87] Training loss: 0.96494553, Validation loss: 0.96575609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29745.00390625MB; mem (CPU total)=32199.7265625MB
INFO:root:[   88] Training loss: 0.96495327, Validation loss: 0.96486640, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29783.09765625MB; mem (CPU total)=32238.71484375MB
INFO:root:[   89] Training loss: 0.96492455, Validation loss: 0.96588036, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29821.19140625MB; mem (CPU total)=32277.6796875MB
INFO:root:[   90] Training loss: 0.96492028, Validation loss: 0.96572311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29859.28515625MB; mem (CPU total)=32317.921875MB
INFO:root:[   91] Training loss: 0.96475703, Validation loss: 0.96567222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29897.3828125MB; mem (CPU total)=32357.7734375MB
INFO:root:[   92] Training loss: 0.96467158, Validation loss: 0.96482979, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29935.48046875MB; mem (CPU total)=32395.00390625MB
INFO:root:[   93] Training loss: 0.96469980, Validation loss: 0.96451916, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29973.57421875MB; mem (CPU total)=32433.46875MB
INFO:root:[   94] Training loss: 0.96462169, Validation loss: 0.96627819, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30011.66796875MB; mem (CPU total)=32472.71484375MB
INFO:root:[   95] Training loss: 0.96439862, Validation loss: 0.96473512, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30049.76171875MB; mem (CPU total)=32511.64453125MB
INFO:root:[   96] Training loss: 0.96449870, Validation loss: 0.96584578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30087.859375MB; mem (CPU total)=32547.6953125MB
INFO:root:[   97] Training loss: 0.96436450, Validation loss: 0.96533392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30125.953125MB; mem (CPU total)=32589.30078125MB
INFO:root:[   98] Training loss: 0.96418328, Validation loss: 0.96569174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30164.05078125MB; mem (CPU total)=32628.9921875MB
INFO:root:[   99] Training loss: 0.96410102, Validation loss: 0.96485288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30202.14453125MB; mem (CPU total)=32669.0546875MB
INFO:root:[  100] Training loss: 0.96432010, Validation loss: 0.96528130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30240.23828125MB; mem (CPU total)=32705.1015625MB
INFO:root:[  101] Training loss: 0.96397598, Validation loss: 0.96571494, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30278.3359375MB; mem (CPU total)=33188.4453125MB
INFO:root:[  102] Training loss: 0.96397448, Validation loss: 0.96484405, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30316.4296875MB; mem (CPU total)=50949.3125MB
INFO:root:EP 102: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=30354.40625MB; mem (CPU total)=51004.92578125MB
INFO:root:Training the model took 5772.955s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.95306
INFO:root:EnergyScoreTrain: 0.86659
INFO:root:CRPSTrain: 0.73365
INFO:root:Gaussian NLLTrain: 17383385875.3422
INFO:root:CoverageTrain: 0.16404
INFO:root:IntervalWidthTrain: 0.34749
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9547
INFO:root:EnergyScoreValidation: 0.8687
INFO:root:CRPSValidation: 0.73551
INFO:root:Gaussian NLLValidation: 17482771665.35111
INFO:root:CoverageValidation: 0.16238
INFO:root:IntervalWidthValidation: 0.34564
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.95436
INFO:root:EnergyScoreTest: 0.86825
INFO:root:CRPSTest: 0.73525
INFO:root:Gaussian NLLTest: 17458997239.808
INFO:root:CoverageTest: 0.16248
INFO:root:IntervalWidthTest: 0.34563
INFO:root:After validation: mem (CPU python)=30397.29296875MB; mem (CPU total)=51082.14453125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=30397.29296875MB; mem (CPU total)=51082.18359375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=30397.453125MB; mem (CPU total)=51081.75390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=30397.453125MB; mem (CPU total)=51082.60546875MB
INFO:root:[    1] Training loss: 1.01280889, Validation loss: 1.00054344, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30435.5MB; mem (CPU total)=51123.58203125MB
INFO:root:[    2] Training loss: 0.99493964, Validation loss: 0.99284115, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30473.59375MB; mem (CPU total)=51162.40625MB
INFO:root:[    3] Training loss: 0.99004275, Validation loss: 0.98922201, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30511.69140625MB; mem (CPU total)=51201.7109375MB
INFO:root:[    4] Training loss: 0.98779901, Validation loss: 0.98798744, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30549.78515625MB; mem (CPU total)=51245.21484375MB
INFO:root:[    5] Training loss: 0.98653892, Validation loss: 0.98689392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30587.87890625MB; mem (CPU total)=51285.2890625MB
INFO:root:[    6] Training loss: 0.98545172, Validation loss: 0.98549337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30625.9765625MB; mem (CPU total)=51323.8828125MB
INFO:root:[    7] Training loss: 0.98476490, Validation loss: 0.98665965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30664.0703125MB; mem (CPU total)=51364.27734375MB
INFO:root:[    8] Training loss: 0.98432201, Validation loss: 0.98522158, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30702.16796875MB; mem (CPU total)=51406.953125MB
INFO:root:[    9] Training loss: 0.98378325, Validation loss: 0.98392906, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30740.26171875MB; mem (CPU total)=51443.828125MB
INFO:root:[   10] Training loss: 0.98351987, Validation loss: 0.98397588, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30778.359375MB; mem (CPU total)=51484.69140625MB
INFO:root:[   11] Training loss: 0.98321372, Validation loss: 0.98386019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30816.453125MB; mem (CPU total)=51528.04296875MB
INFO:root:[   12] Training loss: 0.98300951, Validation loss: 0.98332488, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30854.546875MB; mem (CPU total)=51571.015625MB
INFO:root:[   13] Training loss: 0.98286378, Validation loss: 0.98348169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30892.640625MB; mem (CPU total)=51610.0MB
INFO:root:[   14] Training loss: 0.98218646, Validation loss: 0.98365515, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30930.73828125MB; mem (CPU total)=51654.0234375MB
INFO:root:[   15] Training loss: 0.98190136, Validation loss: 0.98191649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30968.8359375MB; mem (CPU total)=51693.1875MB
INFO:root:[   16] Training loss: 0.98126406, Validation loss: 0.98267153, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31006.9296875MB; mem (CPU total)=51735.02734375MB
INFO:root:[   17] Training loss: 0.98100245, Validation loss: 0.98215311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31045.02734375MB; mem (CPU total)=51774.22265625MB
INFO:root:[   18] Training loss: 0.98074758, Validation loss: 0.98228948, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31083.12109375MB; mem (CPU total)=51813.4296875MB
INFO:root:[   19] Training loss: 0.98028106, Validation loss: 0.98069104, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31121.21484375MB; mem (CPU total)=51854.19140625MB
INFO:root:[   20] Training loss: 0.97986404, Validation loss: 0.98053131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31159.3125MB; mem (CPU total)=51851.375MB
INFO:root:[   21] Training loss: 0.97962117, Validation loss: 0.98051508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31197.41015625MB; mem (CPU total)=51898.0390625MB
INFO:root:[   22] Training loss: 0.97908445, Validation loss: 0.98035336, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31235.50390625MB; mem (CPU total)=51942.171875MB
INFO:root:[   23] Training loss: 0.97886250, Validation loss: 0.97898107, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31273.59765625MB; mem (CPU total)=51983.9921875MB
INFO:root:[   24] Training loss: 0.97842979, Validation loss: 0.97893596, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31311.6953125MB; mem (CPU total)=52021.078125MB
INFO:root:[   25] Training loss: 0.97793361, Validation loss: 0.97841710, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31349.7890625MB; mem (CPU total)=52089.6640625MB
INFO:root:[   26] Training loss: 0.97760163, Validation loss: 0.97734725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31387.8828125MB; mem (CPU total)=52140.2421875MB
INFO:root:[   27] Training loss: 0.97742102, Validation loss: 0.97804480, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31425.98046875MB; mem (CPU total)=52182.4765625MB
INFO:root:[   28] Training loss: 0.97677667, Validation loss: 0.97757279, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31464.07421875MB; mem (CPU total)=52225.5MB
INFO:root:[   29] Training loss: 0.97677551, Validation loss: 0.97776916, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31502.16796875MB; mem (CPU total)=52265.16015625MB
INFO:root:[   30] Training loss: 0.97655757, Validation loss: 0.97671216, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31540.265625MB; mem (CPU total)=52303.0MB
INFO:root:[   31] Training loss: 0.97617416, Validation loss: 0.97740449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31578.36328125MB; mem (CPU total)=52344.70703125MB
INFO:root:[   32] Training loss: 0.97611585, Validation loss: 0.97662440, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31616.45703125MB; mem (CPU total)=52385.578125MB
INFO:root:[   33] Training loss: 0.97555380, Validation loss: 0.97669983, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31654.55078125MB; mem (CPU total)=52425.37109375MB
INFO:root:[   34] Training loss: 0.97555786, Validation loss: 0.97693253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31692.6484375MB; mem (CPU total)=52465.82421875MB
INFO:root:[   35] Training loss: 0.97547179, Validation loss: 0.97613723, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31730.7421875MB; mem (CPU total)=52510.72265625MB
INFO:root:[   36] Training loss: 0.97529461, Validation loss: 0.97549849, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31768.8359375MB; mem (CPU total)=52547.80078125MB
INFO:root:[   37] Training loss: 0.97491265, Validation loss: 0.97650236, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31806.93359375MB; mem (CPU total)=52587.515625MB
INFO:root:[   38] Training loss: 0.97488000, Validation loss: 0.97532773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31845.03125MB; mem (CPU total)=52628.73828125MB
INFO:root:[   39] Training loss: 0.97474597, Validation loss: 0.97575909, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31883.12109375MB; mem (CPU total)=52667.37890625MB
INFO:root:[   40] Training loss: 0.97466892, Validation loss: 0.97555228, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31921.21875MB; mem (CPU total)=52703.97265625MB
INFO:root:[   41] Training loss: 0.97444026, Validation loss: 0.97525277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31959.31640625MB; mem (CPU total)=52744.75MB
INFO:root:[   42] Training loss: 0.97449132, Validation loss: 0.97484966, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31997.41015625MB; mem (CPU total)=52785.6171875MB
INFO:root:[   43] Training loss: 0.97426086, Validation loss: 0.97467598, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32035.50390625MB; mem (CPU total)=52825.171875MB
INFO:root:[   44] Training loss: 0.97432146, Validation loss: 0.97431690, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32073.60546875MB; mem (CPU total)=52863.53125MB
INFO:root:[   45] Training loss: 0.97425105, Validation loss: 0.97506025, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32111.6953125MB; mem (CPU total)=52907.12890625MB
INFO:root:[   46] Training loss: 0.97402553, Validation loss: 0.97450976, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32149.7890625MB; mem (CPU total)=52945.44921875MB
INFO:root:[   47] Training loss: 0.97374231, Validation loss: 0.97412008, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32187.88671875MB; mem (CPU total)=52987.91015625MB
INFO:root:[   48] Training loss: 0.97385660, Validation loss: 0.97455893, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32225.984375MB; mem (CPU total)=53025.890625MB
INFO:root:[   49] Training loss: 0.97349196, Validation loss: 0.97465278, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32264.078125MB; mem (CPU total)=53066.4140625MB
INFO:root:[   50] Training loss: 0.97333150, Validation loss: 0.97412906, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32302.171875MB; mem (CPU total)=53102.18359375MB
INFO:root:[   51] Training loss: 0.97326942, Validation loss: 0.97310165, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32340.26953125MB; mem (CPU total)=50601.75390625MB
INFO:root:[   52] Training loss: 0.97317005, Validation loss: 0.97531131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32378.36328125MB; mem (CPU total)=50639.6640625MB
INFO:root:[   53] Training loss: 0.97289369, Validation loss: 0.97321949, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32416.45703125MB; mem (CPU total)=50677.77734375MB
INFO:root:[   54] Training loss: 0.97285119, Validation loss: 0.97406243, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32454.5546875MB; mem (CPU total)=50716.10546875MB
INFO:root:[   55] Training loss: 0.97268219, Validation loss: 0.97360214, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32492.65234375MB; mem (CPU total)=54142.00390625MB
INFO:root:[   56] Training loss: 0.97262892, Validation loss: 0.97335242, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32530.74609375MB; mem (CPU total)=54197.60546875MB
INFO:root:[   57] Training loss: 0.97264672, Validation loss: 0.97369138, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32568.83984375MB; mem (CPU total)=54244.921875MB
INFO:root:[   58] Training loss: 0.97234098, Validation loss: 0.97298539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32606.9375MB; mem (CPU total)=36006.55859375MB
INFO:root:[   59] Training loss: 0.97243599, Validation loss: 0.97312237, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32645.03125MB; mem (CPU total)=36030.84375MB
INFO:root:[   60] Training loss: 0.97219119, Validation loss: 0.97268494, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32683.125MB; mem (CPU total)=36078.27734375MB
INFO:root:[   61] Training loss: 0.97214227, Validation loss: 0.97250522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32721.2265625MB; mem (CPU total)=36151.62109375MB
INFO:root:[   62] Training loss: 0.97188658, Validation loss: 0.97303536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32759.31640625MB; mem (CPU total)=32767.42578125MB
INFO:root:[   63] Training loss: 0.97184413, Validation loss: 0.97266006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32797.41015625MB; mem (CPU total)=35270.94921875MB
INFO:root:[   64] Training loss: 0.97185520, Validation loss: 0.97312275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32835.5078125MB; mem (CPU total)=35932.3984375MB
INFO:root:[   65] Training loss: 0.97167755, Validation loss: 0.97295214, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32873.609375MB; mem (CPU total)=35355.43359375MB
INFO:root:[   66] Training loss: 0.97160189, Validation loss: 0.97263201, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32911.703125MB; mem (CPU total)=35422.046875MB
INFO:root:[   67] Training loss: 0.97157756, Validation loss: 0.97258503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32949.796875MB; mem (CPU total)=34958.83984375MB
INFO:root:[   68] Training loss: 0.97142691, Validation loss: 0.97173274, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32987.89453125MB; mem (CPU total)=32980.76171875MB
INFO:root:[   69] Training loss: 0.97146099, Validation loss: 0.97177842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33025.98828125MB; mem (CPU total)=36139.9375MB
INFO:root:[   70] Training loss: 0.97100001, Validation loss: 0.97210285, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33064.08203125MB; mem (CPU total)=36454.0625MB
INFO:root:[   71] Training loss: 0.97107475, Validation loss: 0.97184065, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33102.1796875MB; mem (CPU total)=35048.49609375MB
INFO:root:[   72] Training loss: 0.97079981, Validation loss: 0.97174169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33140.27734375MB; mem (CPU total)=35093.42578125MB
INFO:root:[   73] Training loss: 0.97081910, Validation loss: 0.97225169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33178.37109375MB; mem (CPU total)=37613.0859375MB
INFO:root:[   74] Training loss: 0.97080366, Validation loss: 0.97272248, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33216.46484375MB; mem (CPU total)=37656.6328125MB
INFO:root:[   75] Training loss: 0.97076399, Validation loss: 0.97127825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33254.5625MB; mem (CPU total)=37624.05859375MB
INFO:root:[   76] Training loss: 0.97062662, Validation loss: 0.97167358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33292.65625MB; mem (CPU total)=35430.78515625MB
INFO:root:[   77] Training loss: 0.97071551, Validation loss: 0.97199356, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33330.75MB; mem (CPU total)=35243.203125MB
INFO:root:[   78] Training loss: 0.97035596, Validation loss: 0.97107756, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33368.84765625MB; mem (CPU total)=35298.328125MB
INFO:root:[   79] Training loss: 0.97026686, Validation loss: 0.97135322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33406.94140625MB; mem (CPU total)=35626.42578125MB
INFO:root:[   80] Training loss: 0.97013549, Validation loss: 0.97109650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33445.03515625MB; mem (CPU total)=38996.52734375MB
INFO:root:[   81] Training loss: 0.97012668, Validation loss: 0.97163846, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33483.1328125MB; mem (CPU total)=39044.81640625MB
INFO:root:[   82] Training loss: 0.97007189, Validation loss: 0.97028668, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33521.23046875MB; mem (CPU total)=39139.01171875MB
INFO:root:[   83] Training loss: 0.97005001, Validation loss: 0.97131998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33559.32421875MB; mem (CPU total)=39117.60546875MB
INFO:root:[   84] Training loss: 0.96993276, Validation loss: 0.97070224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33597.41796875MB; mem (CPU total)=35487.82421875MB
INFO:root:[   85] Training loss: 0.96978289, Validation loss: 0.97052936, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33635.515625MB; mem (CPU total)=35573.453125MB
INFO:root:[   86] Training loss: 0.96986262, Validation loss: 0.97023095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33673.61328125MB; mem (CPU total)=35620.05859375MB
INFO:root:[   87] Training loss: 0.96976771, Validation loss: 0.97129702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33711.70703125MB; mem (CPU total)=35655.84375MB
INFO:root:[   88] Training loss: 0.96980268, Validation loss: 0.96993659, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33749.80859375MB; mem (CPU total)=35704.015625MB
INFO:root:[   89] Training loss: 0.96973993, Validation loss: 0.97143319, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33787.8984375MB; mem (CPU total)=35672.76953125MB
INFO:root:[   90] Training loss: 0.96949379, Validation loss: 0.97028164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33825.99609375MB; mem (CPU total)=35767.84375MB
INFO:root:[   91] Training loss: 0.96928929, Validation loss: 0.97066365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33864.08984375MB; mem (CPU total)=35821.73828125MB
INFO:root:[   92] Training loss: 0.96936110, Validation loss: 0.96990870, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33902.1875MB; mem (CPU total)=35774.078125MB
INFO:root:[   93] Training loss: 0.96942854, Validation loss: 0.96941622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33940.28125MB; mem (CPU total)=35875.0390625MB
INFO:root:[   94] Training loss: 0.96925692, Validation loss: 0.97128660, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33978.375MB; mem (CPU total)=35927.0625MB
INFO:root:[   95] Training loss: 0.96915680, Validation loss: 0.96959127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34016.47265625MB; mem (CPU total)=35969.32421875MB
INFO:root:[   96] Training loss: 0.96895137, Validation loss: 0.97082397, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34054.56640625MB; mem (CPU total)=35946.78125MB
INFO:root:[   97] Training loss: 0.96887130, Validation loss: 0.97024350, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34092.6640625MB; mem (CPU total)=36006.5390625MB
INFO:root:[   98] Training loss: 0.96883230, Validation loss: 0.96966280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34130.7578125MB; mem (CPU total)=36076.9296875MB
INFO:root:[   99] Training loss: 0.96867483, Validation loss: 0.96934103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34168.85546875MB; mem (CPU total)=36122.53125MB
INFO:root:[  100] Training loss: 0.96887065, Validation loss: 0.96971458, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34206.9609375MB; mem (CPU total)=36097.2578125MB
INFO:root:[  101] Training loss: 0.96852262, Validation loss: 0.96980801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34245.0546875MB; mem (CPU total)=36162.0859375MB
INFO:root:[  102] Training loss: 0.96851446, Validation loss: 0.96931359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34283.15234375MB; mem (CPU total)=39596.01953125MB
INFO:root:[  103] Training loss: 0.96855280, Validation loss: 0.97020435, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34321.24609375MB; mem (CPU total)=39782.27734375MB
INFO:root:[  104] Training loss: 0.96830779, Validation loss: 0.96970267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34359.33984375MB; mem (CPU total)=39818.67578125MB
INFO:root:[  105] Training loss: 0.96836214, Validation loss: 0.96989900, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34397.4375MB; mem (CPU total)=39721.73828125MB
INFO:root:[  106] Training loss: 0.96828938, Validation loss: 0.97076156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34435.53515625MB; mem (CPU total)=39894.4765625MB
INFO:root:[  107] Training loss: 0.96829315, Validation loss: 0.96949844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34473.62890625MB; mem (CPU total)=40061.23046875MB
INFO:root:[  108] Training loss: 0.96817843, Validation loss: 0.96919279, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34511.72265625MB; mem (CPU total)=36479.09765625MB
INFO:root:[  109] Training loss: 0.96801776, Validation loss: 0.96893969, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34549.8203125MB; mem (CPU total)=36516.203125MB
INFO:root:[  110] Training loss: 0.96795683, Validation loss: 0.96891625, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34587.9140625MB; mem (CPU total)=36521.14453125MB
INFO:root:[  111] Training loss: 0.96777485, Validation loss: 0.96898159, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34626.0078125MB; mem (CPU total)=36580.40625MB
INFO:root:[  112] Training loss: 0.96773965, Validation loss: 0.96890822, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34664.10546875MB; mem (CPU total)=36573.59765625MB
INFO:root:[  113] Training loss: 0.96781175, Validation loss: 0.96947463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34702.19921875MB; mem (CPU total)=36650.27734375MB
INFO:root:[  114] Training loss: 0.96778724, Validation loss: 0.96788484, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34740.296875MB; mem (CPU total)=36697.7734375MB
INFO:root:[  115] Training loss: 0.96775514, Validation loss: 0.96922431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34778.390625MB; mem (CPU total)=36714.13671875MB
INFO:root:[  116] Training loss: 0.96755655, Validation loss: 0.96827855, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34816.48828125MB; mem (CPU total)=36759.4921875MB
INFO:root:[  117] Training loss: 0.96759981, Validation loss: 0.96904732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34854.58203125MB; mem (CPU total)=36726.6796875MB
INFO:root:[  118] Training loss: 0.96734506, Validation loss: 0.96846444, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34892.67578125MB; mem (CPU total)=36839.328125MB
INFO:root:[  119] Training loss: 0.96751277, Validation loss: 0.96812021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34930.7734375MB; mem (CPU total)=36881.640625MB
INFO:root:[  120] Training loss: 0.96724242, Validation loss: 0.96801907, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34968.8671875MB; mem (CPU total)=36903.91015625MB
INFO:root:[  121] Training loss: 0.96736112, Validation loss: 0.96877362, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35006.9609375MB; mem (CPU total)=36962.8046875MB
INFO:root:[  122] Training loss: 0.96733969, Validation loss: 0.96780405, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35045.0625MB; mem (CPU total)=36933.375MB
INFO:root:[  123] Training loss: 0.96725064, Validation loss: 0.96866540, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35083.15625MB; mem (CPU total)=37038.12890625MB
INFO:root:[  124] Training loss: 0.96711042, Validation loss: 0.96851439, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35121.25MB; mem (CPU total)=37002.328125MB
INFO:root:[  125] Training loss: 0.96695133, Validation loss: 0.96801945, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35159.34375MB; mem (CPU total)=37107.140625MB
INFO:root:[  126] Training loss: 0.96703863, Validation loss: 0.96790570, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35197.44140625MB; mem (CPU total)=37069.82421875MB
INFO:root:[  127] Training loss: 0.96686600, Validation loss: 0.96722393, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35235.53515625MB; mem (CPU total)=37170.73828125MB
INFO:root:[  128] Training loss: 0.96672986, Validation loss: 0.96755164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35273.62890625MB; mem (CPU total)=37233.99609375MB
INFO:root:[  129] Training loss: 0.96683960, Validation loss: 0.96702354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35311.7265625MB; mem (CPU total)=37253.640625MB
INFO:root:[  130] Training loss: 0.96672682, Validation loss: 0.96757253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35349.8203125MB; mem (CPU total)=37306.06640625MB
INFO:root:[  131] Training loss: 0.96652087, Validation loss: 0.96772655, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35387.9140625MB; mem (CPU total)=37329.05859375MB
INFO:root:[  132] Training loss: 0.96645894, Validation loss: 0.96788819, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35426.01171875MB; mem (CPU total)=37379.68359375MB
INFO:root:[  133] Training loss: 0.96645372, Validation loss: 0.96756867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35464.109375MB; mem (CPU total)=37409.24609375MB
INFO:root:[  134] Training loss: 0.96646845, Validation loss: 0.96794359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35502.203125MB; mem (CPU total)=37386.58203125MB
INFO:root:[  135] Training loss: 0.96641485, Validation loss: 0.96811006, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35540.296875MB; mem (CPU total)=37485.42578125MB
INFO:root:[  136] Training loss: 0.96636453, Validation loss: 0.96799381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35578.39453125MB; mem (CPU total)=37466.9375MB
INFO:root:[  137] Training loss: 0.96632043, Validation loss: 0.96716226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35616.48828125MB; mem (CPU total)=37564.5703125MB
INFO:root:[  138] Training loss: 0.96632744, Validation loss: 0.96727590, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35654.58203125MB; mem (CPU total)=37533.37109375MB
INFO:root:[  139] Training loss: 0.96633639, Validation loss: 0.96680286, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35692.68359375MB; mem (CPU total)=37645.01953125MB
INFO:root:[  140] Training loss: 0.96602687, Validation loss: 0.96748760, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35730.7734375MB; mem (CPU total)=37628.14453125MB
INFO:root:[  141] Training loss: 0.96618717, Validation loss: 0.96631671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35768.87109375MB; mem (CPU total)=37713.8515625MB
INFO:root:[  142] Training loss: 0.96612412, Validation loss: 0.96755785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35806.96484375MB; mem (CPU total)=37697.19140625MB
INFO:root:[  143] Training loss: 0.96605630, Validation loss: 0.96762068, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35845.0625MB; mem (CPU total)=37795.28515625MB
INFO:root:[  144] Training loss: 0.96601378, Validation loss: 0.96725039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35883.15625MB; mem (CPU total)=37750.24609375MB
INFO:root:[  145] Training loss: 0.96590035, Validation loss: 0.96642615, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35921.25MB; mem (CPU total)=37859.875MB
INFO:root:[  146] Training loss: 0.96580750, Validation loss: 0.96610537, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35959.3515625MB; mem (CPU total)=37917.48828125MB
INFO:root:[  147] Training loss: 0.96583888, Validation loss: 0.96727522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35997.44140625MB; mem (CPU total)=37932.70703125MB
INFO:root:[  148] Training loss: 0.96590663, Validation loss: 0.96681409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36035.5390625MB; mem (CPU total)=37999.44921875MB
INFO:root:[  149] Training loss: 0.96572109, Validation loss: 0.96658954, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36073.6328125MB; mem (CPU total)=38011.5MB
INFO:root:[  150] Training loss: 0.96559330, Validation loss: 0.96693454, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36111.73046875MB; mem (CPU total)=38072.2421875MB
INFO:root:[  151] Training loss: 0.96550103, Validation loss: 0.96656116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36149.82421875MB; mem (CPU total)=38049.31640625MB
INFO:root:[  152] Training loss: 0.96545339, Validation loss: 0.96680934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36187.91796875MB; mem (CPU total)=42131.6640625MB
INFO:root:[  153] Training loss: 0.96552293, Validation loss: 0.96635260, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36226.015625MB; mem (CPU total)=42343.76171875MB
INFO:root:[  154] Training loss: 0.96560214, Validation loss: 0.96633393, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36264.109375MB; mem (CPU total)=42099.56640625MB
INFO:root:[  155] Training loss: 0.96530841, Validation loss: 0.96629053, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36302.20703125MB; mem (CPU total)=41956.99609375MB
INFO:root:EP 155: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=36340.2734375MB; mem (CPU total)=41985.03125MB
INFO:root:Training the model took 9560.196s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.9531
INFO:root:EnergyScoreTrain: 0.86013
INFO:root:CRPSTrain: 0.73261
INFO:root:Gaussian NLLTrain: 18385968038.11557
INFO:root:CoverageTrain: 0.17045
INFO:root:IntervalWidthTrain: 0.36002
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9547
INFO:root:EnergyScoreValidation: 0.86218
INFO:root:CRPSValidation: 0.73438
INFO:root:Gaussian NLLValidation: 18512304132.5511
INFO:root:CoverageValidation: 0.16863
INFO:root:IntervalWidthValidation: 0.35825
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.95468
INFO:root:EnergyScoreTest: 0.86219
INFO:root:CRPSTest: 0.73455
INFO:root:Gaussian NLLTest: 18246813442.048
INFO:root:CoverageTest: 0.16863
INFO:root:IntervalWidthTest: 0.35745
INFO:root:After validation: mem (CPU python)=36383.015625MB; mem (CPU total)=41845.84765625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=36383.015625MB; mem (CPU total)=41959.41796875MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=36383.1640625MB; mem (CPU total)=41899.6328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=36383.1640625MB; mem (CPU total)=41891.31640625MB
INFO:root:[    1] Training loss: 1.01422860, Validation loss: 1.00282129, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36421.22265625MB; mem (CPU total)=40136.48046875MB
INFO:root:[    2] Training loss: 0.99704370, Validation loss: 0.99461193, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36459.31640625MB; mem (CPU total)=41963.0546875MB
INFO:root:[    3] Training loss: 0.99222488, Validation loss: 0.99145644, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36497.42578125MB; mem (CPU total)=42070.984375MB
INFO:root:[    4] Training loss: 0.99032762, Validation loss: 0.99011033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36535.51953125MB; mem (CPU total)=42191.05078125MB
INFO:root:[    5] Training loss: 0.98896177, Validation loss: 0.98868105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36573.61328125MB; mem (CPU total)=42184.18359375MB
INFO:root:[    6] Training loss: 0.98808506, Validation loss: 0.98797777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36611.7109375MB; mem (CPU total)=42295.73046875MB
INFO:root:[    7] Training loss: 0.98751331, Validation loss: 0.98769073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36649.8046875MB; mem (CPU total)=40987.1171875MB
INFO:root:[    8] Training loss: 0.98691133, Validation loss: 0.98790127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36687.8984375MB; mem (CPU total)=41026.3828125MB
INFO:root:[    9] Training loss: 0.98665405, Validation loss: 0.98678359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36725.99609375MB; mem (CPU total)=41043.71484375MB
INFO:root:[   10] Training loss: 0.98623929, Validation loss: 0.98721292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36764.08984375MB; mem (CPU total)=41095.39453125MB
INFO:root:[   11] Training loss: 0.98597650, Validation loss: 0.98591569, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36802.1875MB; mem (CPU total)=40265.9140625MB
INFO:root:[   12] Training loss: 0.98568399, Validation loss: 0.98602438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36840.28125MB; mem (CPU total)=42084.859375MB
INFO:root:[   13] Training loss: 0.98554663, Validation loss: 0.98663071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36878.37890625MB; mem (CPU total)=42151.6796875MB
INFO:root:[   14] Training loss: 0.98505850, Validation loss: 0.98579702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36916.47265625MB; mem (CPU total)=40361.67578125MB
INFO:root:[   15] Training loss: 0.98478130, Validation loss: 0.98477573, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36954.56640625MB; mem (CPU total)=40423.296875MB
INFO:root:[   16] Training loss: 0.98426301, Validation loss: 0.98613154, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36992.6640625MB; mem (CPU total)=40494.5390625MB
INFO:root:[   17] Training loss: 0.98427465, Validation loss: 0.98484899, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37030.7578125MB; mem (CPU total)=40654.328125MB
INFO:root:[   18] Training loss: 0.98387490, Validation loss: 0.98551271, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37068.85546875MB; mem (CPU total)=37066.265625MB
INFO:root:[   19] Training loss: 0.98364020, Validation loss: 0.98360617, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37106.94921875MB; mem (CPU total)=37102.08203125MB
INFO:root:[   20] Training loss: 0.98329901, Validation loss: 0.98374901, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37145.046875MB; mem (CPU total)=37139.578125MB
INFO:root:[   21] Training loss: 0.98309318, Validation loss: 0.98431638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37183.140625MB; mem (CPU total)=37175.2890625MB
INFO:root:[   22] Training loss: 0.98289030, Validation loss: 0.98339143, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37221.23828125MB; mem (CPU total)=39052.23828125MB
INFO:root:[   23] Training loss: 0.98261960, Validation loss: 0.98266049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37259.3359375MB; mem (CPU total)=37253.5625MB
INFO:root:[   24] Training loss: 0.98208550, Validation loss: 0.98295498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37297.42578125MB; mem (CPU total)=37291.0390625MB
INFO:root:[   25] Training loss: 0.98189000, Validation loss: 0.98189209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37335.5234375MB; mem (CPU total)=39164.08984375MB
INFO:root:[   26] Training loss: 0.98143316, Validation loss: 0.98128902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37373.62109375MB; mem (CPU total)=41672.3359375MB
INFO:root:[   27] Training loss: 0.98125139, Validation loss: 0.98150693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37411.71484375MB; mem (CPU total)=41728.640625MB
INFO:root:[   28] Training loss: 0.98077534, Validation loss: 0.98094773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37449.80859375MB; mem (CPU total)=41768.375MB
INFO:root:[   29] Training loss: 0.98084954, Validation loss: 0.98141770, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37487.90234375MB; mem (CPU total)=40921.0390625MB
INFO:root:[   30] Training loss: 0.98044649, Validation loss: 0.98059453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37526.0MB; mem (CPU total)=41852.28515625MB
INFO:root:[   31] Training loss: 0.98019225, Validation loss: 0.98146713, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37564.09375MB; mem (CPU total)=41891.4921875MB
INFO:root:[   32] Training loss: 0.98027454, Validation loss: 0.98112688, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37602.1875MB; mem (CPU total)=39441.75MB
INFO:root:[   33] Training loss: 0.97981040, Validation loss: 0.97993742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37640.2890625MB; mem (CPU total)=39480.48828125MB
INFO:root:[   34] Training loss: 0.97950493, Validation loss: 0.98012864, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37678.3828125MB; mem (CPU total)=39519.6953125MB
INFO:root:[   35] Training loss: 0.97943831, Validation loss: 0.98042649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37716.4765625MB; mem (CPU total)=39555.640625MB
INFO:root:[   36] Training loss: 0.97948444, Validation loss: 0.97938164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37754.5703125MB; mem (CPU total)=39593.2734375MB
INFO:root:[   37] Training loss: 0.97930620, Validation loss: 0.97979684, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37792.66796875MB; mem (CPU total)=39635.421875MB
INFO:root:[   38] Training loss: 0.97905073, Validation loss: 0.97938374, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37830.76171875MB; mem (CPU total)=39674.97265625MB
INFO:root:[   39] Training loss: 0.97894970, Validation loss: 0.98041635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37868.85546875MB; mem (CPU total)=39711.05078125MB
INFO:root:[   40] Training loss: 0.97899427, Validation loss: 0.97930234, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37906.95703125MB; mem (CPU total)=37906.39453125MB
INFO:root:[   41] Training loss: 0.97855325, Validation loss: 0.98056428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37945.046875MB; mem (CPU total)=40468.94921875MB
INFO:root:[   42] Training loss: 0.97855920, Validation loss: 0.97910399, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37983.14453125MB; mem (CPU total)=38131.88671875MB
INFO:root:[   43] Training loss: 0.97847810, Validation loss: 0.97867667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38021.2421875MB; mem (CPU total)=41411.5703125MB
INFO:root:[   44] Training loss: 0.97844692, Validation loss: 0.97918008, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38059.33984375MB; mem (CPU total)=41473.18359375MB
INFO:root:[   45] Training loss: 0.97834884, Validation loss: 0.97914101, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38097.43359375MB; mem (CPU total)=41532.4765625MB
INFO:root:[   46] Training loss: 0.97831509, Validation loss: 0.97837533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38135.53125MB; mem (CPU total)=41595.86328125MB
INFO:root:[   47] Training loss: 0.97792071, Validation loss: 0.97880602, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38173.62890625MB; mem (CPU total)=41737.9765625MB
INFO:root:[   48] Training loss: 0.97816923, Validation loss: 0.97912324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38211.71875MB; mem (CPU total)=41801.1015625MB
INFO:root:[   49] Training loss: 0.97793733, Validation loss: 0.97868657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38249.81640625MB; mem (CPU total)=41947.66796875MB
INFO:root:[   50] Training loss: 0.97792711, Validation loss: 0.97816015, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38287.9140625MB; mem (CPU total)=41993.8203125MB
INFO:root:[   51] Training loss: 0.97781674, Validation loss: 0.97857996, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38326.0078125MB; mem (CPU total)=41973.25390625MB
INFO:root:[   52] Training loss: 0.97764777, Validation loss: 0.97854638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38364.1015625MB; mem (CPU total)=42074.91015625MB
INFO:root:[   53] Training loss: 0.97738108, Validation loss: 0.97811600, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38402.1953125MB; mem (CPU total)=44024.56640625MB
INFO:root:[   54] Training loss: 0.97755714, Validation loss: 0.97823873, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38440.29296875MB; mem (CPU total)=44021.8984375MB
INFO:root:[   55] Training loss: 0.97722998, Validation loss: 0.97769778, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38478.390625MB; mem (CPU total)=44124.625MB
INFO:root:[   56] Training loss: 0.97725796, Validation loss: 0.97784863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38516.484375MB; mem (CPU total)=44316.3671875MB
