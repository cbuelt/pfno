INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.4453125MB; mem (CPU total)=11328.9453125MB
INFO:root:############### Starting experiment with config file sswe/sfno_dropout_1_2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=587.046875MB; mem (CPU total)=11333.9140625MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=588.59375MB; mem (CPU total)=11334.41015625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2233.28125MB; mem (CPU total)=12709.68359375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2242.91796875MB; mem (CPU total)=12718.3046875MB
INFO:root:[    1] Training loss: 0.76685815, Validation loss: 0.72166003, Gradient norm: 0.49899198
INFO:root:At the start of the epoch: mem (CPU python)=4403.375MB; mem (CPU total)=14393.74609375MB
INFO:root:[    2] Training loss: 0.66802422, Validation loss: 0.59348359, Gradient norm: 0.89987110
INFO:root:At the start of the epoch: mem (CPU python)=4424.47265625MB; mem (CPU total)=12234.93359375MB
INFO:root:[    3] Training loss: 0.57666397, Validation loss: 0.56489575, Gradient norm: 1.27661728
INFO:root:At the start of the epoch: mem (CPU python)=4445.91796875MB; mem (CPU total)=12273.0078125MB
INFO:root:[    4] Training loss: 0.53480851, Validation loss: 0.51377172, Gradient norm: 1.57492004
INFO:root:At the start of the epoch: mem (CPU python)=4469.6328125MB; mem (CPU total)=12316.26953125MB
INFO:root:[    5] Training loss: 0.50696549, Validation loss: 0.49945954, Gradient norm: 1.86737386
INFO:root:At the start of the epoch: mem (CPU python)=4491.1484375MB; mem (CPU total)=12356.43359375MB
INFO:root:[    6] Training loss: 0.49237930, Validation loss: 0.48016702, Gradient norm: 2.12906789
INFO:root:At the start of the epoch: mem (CPU python)=4512.33984375MB; mem (CPU total)=12396.55078125MB
INFO:root:[    7] Training loss: 0.48571601, Validation loss: 0.51157428, Gradient norm: 2.26102437
INFO:root:At the start of the epoch: mem (CPU python)=4542.64453125MB; mem (CPU total)=12447.35546875MB
