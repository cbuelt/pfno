INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=581.96875MB; mem (CPU total)=7941.5625MB
INFO:root:############### Starting experiment with config file sswe/sfno_dropout_1_3.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=593.11328125MB; mem (CPU total)=7893.03125MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=594.46484375MB; mem (CPU total)=7893.03125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2239.9609375MB; mem (CPU total)=9267.35546875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2249.54296875MB; mem (CPU total)=9075.2109375MB
INFO:root:[    1] Training loss: 0.76464710, Validation loss: 0.72179651, Gradient norm: 0.63200568
INFO:root:At the start of the epoch: mem (CPU python)=4409.19140625MB; mem (CPU total)=11104.62890625MB
INFO:root:[    2] Training loss: 0.68259164, Validation loss: 0.61683507, Gradient norm: 1.12500285
INFO:root:At the start of the epoch: mem (CPU python)=4430.3984375MB; mem (CPU total)=11103.73828125MB
INFO:root:[    3] Training loss: 0.57782592, Validation loss: 0.54127086, Gradient norm: 1.90511571
INFO:root:At the start of the epoch: mem (CPU python)=4452.52734375MB; mem (CPU total)=11055.359375MB
INFO:root:[    4] Training loss: 0.53503164, Validation loss: 0.51465331, Gradient norm: 2.29434769
INFO:root:At the start of the epoch: mem (CPU python)=4476.04296875MB; mem (CPU total)=11062.91796875MB
INFO:root:[    5] Training loss: 0.51898936, Validation loss: 0.51278968, Gradient norm: 2.65945232
INFO:root:At the start of the epoch: mem (CPU python)=4497.8359375MB; mem (CPU total)=11093.6171875MB
INFO:root:[    6] Training loss: 0.50990118, Validation loss: 0.49829429, Gradient norm: 2.90508647
INFO:root:At the start of the epoch: mem (CPU python)=4521.58984375MB; mem (CPU total)=11144.47265625MB
INFO:root:[    7] Training loss: 0.50500541, Validation loss: 0.51190656, Gradient norm: 3.02704024
INFO:root:At the start of the epoch: mem (CPU python)=4542.890625MB; mem (CPU total)=11138.38671875MB
INFO:root:[    8] Training loss: 0.49937854, Validation loss: 0.50858871, Gradient norm: 3.20942186
INFO:root:At the start of the epoch: mem (CPU python)=4564.07421875MB; mem (CPU total)=11148.23828125MB
INFO:root:[    9] Training loss: 0.49759642, Validation loss: 0.49367753, Gradient norm: 3.35624806
INFO:root:At the start of the epoch: mem (CPU python)=4585.63671875MB; mem (CPU total)=11203.97265625MB
INFO:root:[   10] Training loss: 0.49259304, Validation loss: 0.52299517, Gradient norm: 3.44070503
INFO:root:At the start of the epoch: mem (CPU python)=4609.68359375MB; mem (CPU total)=11217.74609375MB
INFO:root:[   11] Training loss: 0.49175030, Validation loss: 0.49841321, Gradient norm: 3.54703297
INFO:root:At the start of the epoch: mem (CPU python)=4630.98046875MB; mem (CPU total)=11275.55078125MB
INFO:root:[   12] Training loss: 0.48775604, Validation loss: 0.47555266, Gradient norm: 3.76286604
INFO:root:At the start of the epoch: mem (CPU python)=4658.3359375MB; mem (CPU total)=11250.9375MB
INFO:root:[   13] Training loss: 0.48545001, Validation loss: 0.48733240, Gradient norm: 3.73659143
INFO:root:At the start of the epoch: mem (CPU python)=4679.703125MB; mem (CPU total)=11267.3125MB
INFO:root:[   14] Training loss: 0.48311560, Validation loss: 0.47672883, Gradient norm: 4.07953625
INFO:root:At the start of the epoch: mem (CPU python)=4700.8671875MB; mem (CPU total)=11298.00390625MB
INFO:root:[   15] Training loss: 0.47936248, Validation loss: 0.47131295, Gradient norm: 4.35891272
INFO:root:At the start of the epoch: mem (CPU python)=4722.04296875MB; mem (CPU total)=11310.71484375MB
INFO:root:[   16] Training loss: 0.48057893, Validation loss: 0.46849916, Gradient norm: 4.50610216
INFO:root:At the start of the epoch: mem (CPU python)=4743.20703125MB; mem (CPU total)=11350.8515625MB
INFO:root:[   17] Training loss: 0.47560693, Validation loss: 0.49025470, Gradient norm: 4.76818116
INFO:root:At the start of the epoch: mem (CPU python)=4764.39453125MB; mem (CPU total)=11410.8984375MB
INFO:root:[   18] Training loss: 0.47466607, Validation loss: 0.47275077, Gradient norm: 4.98658669
INFO:root:At the start of the epoch: mem (CPU python)=4785.58203125MB; mem (CPU total)=11441.79296875MB
INFO:root:[   19] Training loss: 0.47411235, Validation loss: 0.47567979, Gradient norm: 5.22291742
INFO:root:At the start of the epoch: mem (CPU python)=4806.7421875MB; mem (CPU total)=11414.61328125MB
INFO:root:[   20] Training loss: 0.47315427, Validation loss: 0.47287425, Gradient norm: 5.60719025
INFO:root:At the start of the epoch: mem (CPU python)=4827.90625MB; mem (CPU total)=11423.75390625MB
INFO:root:[   21] Training loss: 0.47320939, Validation loss: 0.46646234, Gradient norm: 5.70941941
INFO:root:At the start of the epoch: mem (CPU python)=4849.0703125MB; mem (CPU total)=11477.296875MB
INFO:root:[   22] Training loss: 0.47155732, Validation loss: 0.46316765, Gradient norm: 5.72384445
INFO:root:At the start of the epoch: mem (CPU python)=4870.24609375MB; mem (CPU total)=11465.5390625MB
INFO:root:[   23] Training loss: 0.47071168, Validation loss: 0.47041112, Gradient norm: 5.96294269
INFO:root:At the start of the epoch: mem (CPU python)=4891.56640625MB; mem (CPU total)=11489.140625MB
INFO:root:[   24] Training loss: 0.47081728, Validation loss: 0.47618235, Gradient norm: 5.96336840
INFO:root:At the start of the epoch: mem (CPU python)=4917.92578125MB; mem (CPU total)=11525.1640625MB
INFO:root:[   25] Training loss: 0.47176940, Validation loss: 0.48496585, Gradient norm: 6.14300489
INFO:root:At the start of the epoch: mem (CPU python)=4939.40625MB; mem (CPU total)=11544.5390625MB
INFO:root:[   26] Training loss: 0.46942245, Validation loss: 0.46073378, Gradient norm: 6.24534525
INFO:root:At the start of the epoch: mem (CPU python)=4960.58203125MB; mem (CPU total)=11592.19140625MB
INFO:root:[   27] Training loss: 0.47214959, Validation loss: 0.46134003, Gradient norm: 6.41880336
INFO:root:At the start of the epoch: mem (CPU python)=4981.7578125MB; mem (CPU total)=11577.21875MB
INFO:root:[   28] Training loss: 0.46950683, Validation loss: 0.47800857, Gradient norm: 6.40301021
INFO:root:At the start of the epoch: mem (CPU python)=5002.921875MB; mem (CPU total)=11615.9453125MB
INFO:root:[   29] Training loss: 0.46713100, Validation loss: 0.46275980, Gradient norm: 6.49257848
INFO:root:At the start of the epoch: mem (CPU python)=5024.09375MB; mem (CPU total)=11625.4140625MB
INFO:root:[   30] Training loss: 0.46799411, Validation loss: 0.49067261, Gradient norm: 6.54707445
INFO:root:At the start of the epoch: mem (CPU python)=5045.26953125MB; mem (CPU total)=11636.8984375MB
INFO:root:[   31] Training loss: 0.47593136, Validation loss: 0.63879384, Gradient norm: 6.76729511
INFO:root:At the start of the epoch: mem (CPU python)=5066.43359375MB; mem (CPU total)=11686.6875MB
INFO:root:[   32] Training loss: 0.52209493, Validation loss: 0.48523287, Gradient norm: 8.69154450
INFO:root:At the start of the epoch: mem (CPU python)=5087.59765625MB; mem (CPU total)=11689.03515625MB
INFO:root:[   33] Training loss: 0.47553953, Validation loss: 0.48471313, Gradient norm: 6.75608308
INFO:root:At the start of the epoch: mem (CPU python)=5109.45703125MB; mem (CPU total)=11766.203125MB
INFO:root:[   34] Training loss: 0.46457875, Validation loss: 0.46470181, Gradient norm: 6.43351993
INFO:root:At the start of the epoch: mem (CPU python)=5130.98046875MB; mem (CPU total)=11788.19140625MB
INFO:root:[   35] Training loss: 0.46371503, Validation loss: 0.45010539, Gradient norm: 6.55884921
INFO:root:At the start of the epoch: mem (CPU python)=5152.14453125MB; mem (CPU total)=11759.25390625MB
INFO:root:[   36] Training loss: 0.46488889, Validation loss: 0.46793659, Gradient norm: 6.70366221
INFO:root:At the start of the epoch: mem (CPU python)=5173.375MB; mem (CPU total)=11776.625MB
INFO:root:[   37] Training loss: 0.46489382, Validation loss: 0.47452482, Gradient norm: 6.79710985
INFO:root:At the start of the epoch: mem (CPU python)=5194.55078125MB; mem (CPU total)=11796.609375MB
INFO:root:[   38] Training loss: 0.46334191, Validation loss: 0.49384614, Gradient norm: 6.84595859
INFO:root:At the start of the epoch: mem (CPU python)=5217.453125MB; mem (CPU total)=11811.58984375MB
INFO:root:[   39] Training loss: 0.46006802, Validation loss: 0.46660569, Gradient norm: 7.21026555
INFO:root:At the start of the epoch: mem (CPU python)=5239.1484375MB; mem (CPU total)=11834.265625MB
INFO:root:[   40] Training loss: 0.46372725, Validation loss: 0.45459235, Gradient norm: 7.27929032
INFO:root:At the start of the epoch: mem (CPU python)=5260.34375MB; mem (CPU total)=11879.28125MB
INFO:root:[   41] Training loss: 0.51642089, Validation loss: 0.52073141, Gradient norm: 8.89004271
INFO:root:At the start of the epoch: mem (CPU python)=5281.55859375MB; mem (CPU total)=11916.30859375MB
INFO:root:[   42] Training loss: 0.50789572, Validation loss: 0.45786013, Gradient norm: 9.37741433
INFO:root:At the start of the epoch: mem (CPU python)=5306.76171875MB; mem (CPU total)=11917.02734375MB
INFO:root:[   43] Training loss: 0.46342992, Validation loss: 0.45034740, Gradient norm: 7.33256737
INFO:root:At the start of the epoch: mem (CPU python)=5328.08203125MB; mem (CPU total)=11943.1640625MB
INFO:root:[   44] Training loss: 0.45522754, Validation loss: 0.47719675, Gradient norm: 7.24900498
INFO:root:At the start of the epoch: mem (CPU python)=5349.28125MB; mem (CPU total)=11943.17578125MB
INFO:root:[   45] Training loss: 0.46006015, Validation loss: 0.46414191, Gradient norm: 7.57648508
INFO:root:At the start of the epoch: mem (CPU python)=5370.46484375MB; mem (CPU total)=11877.8125MB
INFO:root:[   46] Training loss: 0.45511955, Validation loss: 0.44234460, Gradient norm: 7.51525714
INFO:root:At the start of the epoch: mem (CPU python)=5393.5859375MB; mem (CPU total)=12018.3125MB
INFO:root:[   47] Training loss: 0.45774899, Validation loss: 0.46774342, Gradient norm: 7.40511443
INFO:root:At the start of the epoch: mem (CPU python)=5415.12890625MB; mem (CPU total)=12003.390625MB
INFO:root:[   48] Training loss: 0.45672883, Validation loss: 0.44851309, Gradient norm: 7.45865084
INFO:root:At the start of the epoch: mem (CPU python)=5436.328125MB; mem (CPU total)=11935.90234375MB
INFO:root:[   49] Training loss: 0.45512182, Validation loss: 0.44727651, Gradient norm: 7.74033330
INFO:root:At the start of the epoch: mem (CPU python)=5460.03515625MB; mem (CPU total)=12103.71875MB
INFO:root:[   50] Training loss: 0.45165195, Validation loss: 0.45936641, Gradient norm: 7.50038504
INFO:root:At the start of the epoch: mem (CPU python)=5481.71875MB; mem (CPU total)=12136.04296875MB
INFO:root:[   51] Training loss: 0.45411928, Validation loss: 0.45401094, Gradient norm: 7.92529360
INFO:root:At the start of the epoch: mem (CPU python)=5502.91796875MB; mem (CPU total)=11943.88671875MB
INFO:root:[   52] Training loss: 0.45565450, Validation loss: 0.44215401, Gradient norm: 7.97283731
INFO:root:At the start of the epoch: mem (CPU python)=5524.10546875MB; mem (CPU total)=12086.04296875MB
INFO:root:[   53] Training loss: 0.45227312, Validation loss: 0.45674005, Gradient norm: 7.54552873
INFO:root:At the start of the epoch: mem (CPU python)=5545.2890625MB; mem (CPU total)=12110.0390625MB
INFO:root:[   54] Training loss: 0.58284627, Validation loss: 0.62131819, Gradient norm: 13.14988514
INFO:root:At the start of the epoch: mem (CPU python)=5566.4921875MB; mem (CPU total)=12152.1171875MB
INFO:root:[   55] Training loss: 0.52052378, Validation loss: 0.49113419, Gradient norm: 10.95627285
INFO:root:At the start of the epoch: mem (CPU python)=5587.69140625MB; mem (CPU total)=12167.48828125MB
INFO:root:[   56] Training loss: 0.47502720, Validation loss: 0.45921722, Gradient norm: 8.33128119
INFO:root:At the start of the epoch: mem (CPU python)=5608.76171875MB; mem (CPU total)=12192.66796875MB
INFO:root:[   57] Training loss: 0.45575775, Validation loss: 0.44963115, Gradient norm: 7.47674505
INFO:root:At the start of the epoch: mem (CPU python)=5630.109375MB; mem (CPU total)=12207.23828125MB
INFO:root:[   58] Training loss: 0.45302131, Validation loss: 0.46429613, Gradient norm: 7.69014437
INFO:root:At the start of the epoch: mem (CPU python)=5651.32421875MB; mem (CPU total)=12231.43359375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   59] Training loss: 0.45380315, Validation loss: 0.44697430, Gradient norm: 8.18166238
INFO:root:At the start of the epoch: mem (CPU python)=5672.51171875MB; mem (CPU total)=12266.76953125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   60] Training loss: 0.42473918, Validation loss: 0.43116990, Gradient norm: 7.11604550
INFO:root:At the start of the epoch: mem (CPU python)=5693.71484375MB; mem (CPU total)=12297.34765625MB
INFO:root:[   61] Training loss: 0.41300075, Validation loss: 0.42187742, Gradient norm: 7.01927136
INFO:root:At the start of the epoch: mem (CPU python)=5714.9296875MB; mem (CPU total)=12324.17578125MB
INFO:root:[   62] Training loss: 0.41421828, Validation loss: 0.41839283, Gradient norm: 9.97593539
INFO:root:At the start of the epoch: mem (CPU python)=5736.13671875MB; mem (CPU total)=12355.734375MB
INFO:root:[   63] Training loss: 0.41502963, Validation loss: 0.42747695, Gradient norm: 11.64733681
INFO:root:At the start of the epoch: mem (CPU python)=5758.8515625MB; mem (CPU total)=12805.62890625MB
INFO:root:[   64] Training loss: 0.41598401, Validation loss: 0.42000874, Gradient norm: 13.09131519
INFO:root:At the start of the epoch: mem (CPU python)=5780.03515625MB; mem (CPU total)=12562.6484375MB
INFO:root:[   65] Training loss: 0.41916673, Validation loss: 0.42800153, Gradient norm: 15.21856815
INFO:root:At the start of the epoch: mem (CPU python)=5802.2109375MB; mem (CPU total)=12394.15625MB
INFO:root:[   66] Training loss: 0.42011757, Validation loss: 0.43320855, Gradient norm: 16.85077085
INFO:root:At the start of the epoch: mem (CPU python)=5826.40625MB; mem (CPU total)=12998.625MB
INFO:root:[   67] Training loss: 0.43344682, Validation loss: 0.43895781, Gradient norm: 21.12748754
INFO:root:At the start of the epoch: mem (CPU python)=5849.921875MB; mem (CPU total)=12345.37890625MB
INFO:root:[   68] Training loss: 0.42510076, Validation loss: 0.44288598, Gradient norm: 21.20818654
INFO:root:At the start of the epoch: mem (CPU python)=5871.37890625MB; mem (CPU total)=12449.62109375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   69] Training loss: 0.42368694, Validation loss: 0.42459165, Gradient norm: 20.75482496
INFO:root:At the start of the epoch: mem (CPU python)=5892.5546875MB; mem (CPU total)=12465.75MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   70] Training loss: 0.41306513, Validation loss: 0.41665615, Gradient norm: 16.45669976
INFO:root:At the start of the epoch: mem (CPU python)=5915.53125MB; mem (CPU total)=13288.1796875MB
INFO:root:[   71] Training loss: 0.40679208, Validation loss: 0.41011772, Gradient norm: 13.08060439
INFO:root:At the start of the epoch: mem (CPU python)=5937.3828125MB; mem (CPU total)=12556.21484375MB
INFO:root:[   72] Training loss: 0.40605543, Validation loss: 0.41515736, Gradient norm: 14.80143165
INFO:root:At the start of the epoch: mem (CPU python)=5958.55859375MB; mem (CPU total)=13353.55078125MB
INFO:root:[   73] Training loss: 0.40633957, Validation loss: 0.41300958, Gradient norm: 14.97170278
INFO:root:At the start of the epoch: mem (CPU python)=5979.83984375MB; mem (CPU total)=13355.76171875MB
INFO:root:[   74] Training loss: 0.40690696, Validation loss: 0.41090844, Gradient norm: 17.99138179
INFO:root:At the start of the epoch: mem (CPU python)=6003.71875MB; mem (CPU total)=13385.546875MB
INFO:root:[   75] Training loss: 0.40685872, Validation loss: 0.41155307, Gradient norm: 18.72376962
INFO:root:At the start of the epoch: mem (CPU python)=6027.97265625MB; mem (CPU total)=13434.28125MB
INFO:root:[   76] Training loss: 0.40685810, Validation loss: 0.41803343, Gradient norm: 20.42173208
INFO:root:At the start of the epoch: mem (CPU python)=6049.12890625MB; mem (CPU total)=12668.15625MB
INFO:root:[   77] Training loss: 0.40727036, Validation loss: 0.41211411, Gradient norm: 21.13490205
INFO:root:At the start of the epoch: mem (CPU python)=6070.29296875MB; mem (CPU total)=12655.45703125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   78] Training loss: 0.40906142, Validation loss: 0.41384891, Gradient norm: 26.42479721
INFO:root:At the start of the epoch: mem (CPU python)=6093.703125MB; mem (CPU total)=12696.25390625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   79] Training loss: 0.40441739, Validation loss: 0.40840935, Gradient norm: 16.67600914
INFO:root:At the start of the epoch: mem (CPU python)=6114.86328125MB; mem (CPU total)=12705.54296875MB
INFO:root:[   80] Training loss: 0.40222927, Validation loss: 0.40655085, Gradient norm: 14.61915695
INFO:root:At the start of the epoch: mem (CPU python)=6136.140625MB; mem (CPU total)=12774.48046875MB
INFO:root:[   81] Training loss: 0.40261305, Validation loss: 0.40858306, Gradient norm: 14.42647809
INFO:root:At the start of the epoch: mem (CPU python)=6157.30859375MB; mem (CPU total)=12779.421875MB
INFO:root:[   82] Training loss: 0.40215958, Validation loss: 0.40749577, Gradient norm: 16.31116435
INFO:root:At the start of the epoch: mem (CPU python)=6178.47265625MB; mem (CPU total)=12790.3125MB
INFO:root:[   83] Training loss: 0.40207038, Validation loss: 0.40563643, Gradient norm: 15.89367486
INFO:root:At the start of the epoch: mem (CPU python)=6199.6796875MB; mem (CPU total)=12797.87109375MB
INFO:root:[   84] Training loss: 0.40255671, Validation loss: 0.40579638, Gradient norm: 17.98099909
INFO:root:At the start of the epoch: mem (CPU python)=6225.76171875MB; mem (CPU total)=12826.390625MB
INFO:root:[   85] Training loss: 0.40218025, Validation loss: 0.40592979, Gradient norm: 17.30570963
INFO:root:At the start of the epoch: mem (CPU python)=6246.9765625MB; mem (CPU total)=12844.30859375MB
INFO:root:[   86] Training loss: 0.40240938, Validation loss: 0.40781855, Gradient norm: 18.37281286
INFO:root:At the start of the epoch: mem (CPU python)=6268.55078125MB; mem (CPU total)=12890.7734375MB
INFO:root:[   87] Training loss: 0.40256427, Validation loss: 0.40652554, Gradient norm: 17.39963858
INFO:root:At the start of the epoch: mem (CPU python)=6289.75MB; mem (CPU total)=12898.75390625MB
INFO:root:[   88] Training loss: 0.40191541, Validation loss: 0.40896127, Gradient norm: 18.07908196
INFO:root:At the start of the epoch: mem (CPU python)=6310.9140625MB; mem (CPU total)=12905.12890625MB
INFO:root:[   89] Training loss: 0.40247982, Validation loss: 0.40816101, Gradient norm: 20.27395292
INFO:root:At the start of the epoch: mem (CPU python)=6332.12109375MB; mem (CPU total)=12900.9296875MB
INFO:root:[   90] Training loss: 0.40273998, Validation loss: 0.41137939, Gradient norm: 20.22039276
INFO:root:At the start of the epoch: mem (CPU python)=6353.3125MB; mem (CPU total)=12931.83203125MB
INFO:root:[   91] Training loss: 0.40229695, Validation loss: 0.40632253, Gradient norm: 20.71182761
INFO:root:At the start of the epoch: mem (CPU python)=6374.5078125MB; mem (CPU total)=12994.203125MB
INFO:root:[   92] Training loss: 0.40294604, Validation loss: 0.40745267, Gradient norm: 21.69424565
INFO:root:At the start of the epoch: mem (CPU python)=6396.12109375MB; mem (CPU total)=13000.36328125MB
INFO:root:EP 92: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=6417.609375MB; mem (CPU total)=13035.1328125MB
INFO:root:Training the model took 2271.115s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.35705
INFO:root:EnergyScoreValidation: 0.26931
INFO:root:CRPSValidation: 0.10806
INFO:root:Gaussian NLLValidation: 0.02083
INFO:root:CoverageValidation: 0.75963
INFO:root:IntervalWidthValidation: 0.41035
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.37762
INFO:root:EnergyScoreTest: 0.28815
INFO:root:CRPSTest: 0.11651
INFO:root:Gaussian NLLTest: 0.27297
INFO:root:CoverageTest: 0.72523
INFO:root:IntervalWidthTest: 0.40385
INFO:root:After validation: mem (CPU python)=6434.0MB; mem (CPU total)=13026.921875MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=6434.0MB; mem (CPU total)=13027.82421875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 60817408
INFO:root:After setting up the model: mem (CPU python)=6438.796875MB; mem (CPU total)=13032.25390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=6438.796875MB; mem (CPU total)=13033.1015625MB
INFO:root:[    1] Training loss: 0.76062651, Validation loss: 0.71691158, Gradient norm: 0.32772386
INFO:root:At the start of the epoch: mem (CPU python)=6463.18359375MB; mem (CPU total)=13069.12890625MB
INFO:root:[    2] Training loss: 0.66934029, Validation loss: 0.61698049, Gradient norm: 0.33264067
INFO:root:At the start of the epoch: mem (CPU python)=6484.35546875MB; mem (CPU total)=13052.90234375MB
INFO:root:[    3] Training loss: 0.57139807, Validation loss: 0.53878073, Gradient norm: 0.45366909
INFO:root:At the start of the epoch: mem (CPU python)=6505.59765625MB; mem (CPU total)=13127.30078125MB
INFO:root:[    4] Training loss: 0.52211166, Validation loss: 0.51725177, Gradient norm: 0.50159807
INFO:root:At the start of the epoch: mem (CPU python)=6526.93359375MB; mem (CPU total)=13117.20703125MB
INFO:root:[    5] Training loss: 0.50308320, Validation loss: 0.51292890, Gradient norm: 0.52958780
INFO:root:At the start of the epoch: mem (CPU python)=6548.09765625MB; mem (CPU total)=13135.7578125MB
INFO:root:[    6] Training loss: 0.49263863, Validation loss: 0.48323981, Gradient norm: 0.60524345
INFO:root:At the start of the epoch: mem (CPU python)=6569.265625MB; mem (CPU total)=13179.80078125MB
INFO:root:[    7] Training loss: 0.46941502, Validation loss: 0.46057063, Gradient norm: 0.71232506
INFO:root:At the start of the epoch: mem (CPU python)=6590.59765625MB; mem (CPU total)=13187.9296875MB
INFO:root:[    8] Training loss: 0.45232604, Validation loss: 0.45876121, Gradient norm: 0.92685999
INFO:root:At the start of the epoch: mem (CPU python)=6611.765625MB; mem (CPU total)=13193.98046875MB
INFO:root:[    9] Training loss: 0.44217965, Validation loss: 0.43842074, Gradient norm: 1.14909498
INFO:root:At the start of the epoch: mem (CPU python)=6632.9296875MB; mem (CPU total)=13209.39453125MB
INFO:root:[   10] Training loss: 0.43786486, Validation loss: 0.43782062, Gradient norm: 1.61634953
INFO:root:At the start of the epoch: mem (CPU python)=6654.1328125MB; mem (CPU total)=13232.55078125MB
INFO:root:[   11] Training loss: 0.43364719, Validation loss: 0.42915215, Gradient norm: 2.11176530
INFO:root:At the start of the epoch: mem (CPU python)=6675.42578125MB; mem (CPU total)=13277.453125MB
INFO:root:[   12] Training loss: 0.43238020, Validation loss: 0.45660060, Gradient norm: 2.66062550
INFO:root:At the start of the epoch: mem (CPU python)=6696.58984375MB; mem (CPU total)=13282.96484375MB
INFO:root:[   13] Training loss: 0.43457232, Validation loss: 0.43029880, Gradient norm: 3.08180238
INFO:root:At the start of the epoch: mem (CPU python)=6718.05859375MB; mem (CPU total)=13286.33203125MB
INFO:root:[   14] Training loss: 0.43593512, Validation loss: 0.44695074, Gradient norm: 3.62302073
INFO:root:At the start of the epoch: mem (CPU python)=6739.21875MB; mem (CPU total)=13417.828125MB
INFO:root:[   15] Training loss: 0.43713879, Validation loss: 0.44253840, Gradient norm: 3.96731435
INFO:root:At the start of the epoch: mem (CPU python)=6760.6875MB; mem (CPU total)=13329.890625MB
INFO:root:[   16] Training loss: 0.43622312, Validation loss: 0.43736681, Gradient norm: 4.18205472
INFO:root:At the start of the epoch: mem (CPU python)=6781.88671875MB; mem (CPU total)=13381.69921875MB
INFO:root:[   17] Training loss: 0.43656972, Validation loss: 0.43997483, Gradient norm: 4.62889407
INFO:root:At the start of the epoch: mem (CPU python)=6803.30078125MB; mem (CPU total)=13402.16015625MB
INFO:root:[   18] Training loss: 0.43856726, Validation loss: 0.42512386, Gradient norm: 4.83823803
INFO:root:At the start of the epoch: mem (CPU python)=6824.85546875MB; mem (CPU total)=13418.84375MB
INFO:root:[   19] Training loss: 0.43996265, Validation loss: 0.45574907, Gradient norm: 5.06564420
INFO:root:At the start of the epoch: mem (CPU python)=6846.01953125MB; mem (CPU total)=13453.72265625MB
INFO:root:[   20] Training loss: 0.43860153, Validation loss: 0.45335888, Gradient norm: 5.41531896
INFO:root:At the start of the epoch: mem (CPU python)=6867.37109375MB; mem (CPU total)=13489.88671875MB
INFO:root:[   21] Training loss: 0.43957008, Validation loss: 0.45209301, Gradient norm: 5.32242209
INFO:root:At the start of the epoch: mem (CPU python)=6888.71875MB; mem (CPU total)=13462.63671875MB
INFO:root:[   22] Training loss: 0.43949385, Validation loss: 0.44187567, Gradient norm: 5.55202371
INFO:root:At the start of the epoch: mem (CPU python)=6910.2421875MB; mem (CPU total)=13485.453125MB
INFO:root:[   23] Training loss: 0.43956414, Validation loss: 0.44205510, Gradient norm: 5.77110622
INFO:root:At the start of the epoch: mem (CPU python)=6931.40625MB; mem (CPU total)=13507.90234375MB
INFO:root:[   24] Training loss: 0.43982258, Validation loss: 0.45204620, Gradient norm: 5.88694566
INFO:root:At the start of the epoch: mem (CPU python)=6952.5703125MB; mem (CPU total)=13525.69921875MB
INFO:root:[   25] Training loss: 0.43785602, Validation loss: 0.44800267, Gradient norm: 6.24600659
INFO:root:At the start of the epoch: mem (CPU python)=6973.73828125MB; mem (CPU total)=13580.234375MB
INFO:root:[   26] Training loss: 0.43809060, Validation loss: 0.46015864, Gradient norm: 6.36517745
INFO:root:At the start of the epoch: mem (CPU python)=6994.90234375MB; mem (CPU total)=13584.5MB
INFO:root:[   27] Training loss: 0.43821728, Validation loss: 0.44430067, Gradient norm: 6.61727166
INFO:root:At the start of the epoch: mem (CPU python)=7016.06640625MB; mem (CPU total)=13608.5859375MB
INFO:root:[   28] Training loss: 0.44189573, Validation loss: 0.46104706, Gradient norm: 6.87867309
INFO:root:At the start of the epoch: mem (CPU python)=7037.2265625MB; mem (CPU total)=13607.10546875MB
INFO:root:[   29] Training loss: 0.43659263, Validation loss: 0.44837788, Gradient norm: 6.57110930
INFO:root:At the start of the epoch: mem (CPU python)=7058.390625MB; mem (CPU total)=13710.890625MB
INFO:root:[   30] Training loss: 0.43785332, Validation loss: 0.43307745, Gradient norm: 6.92916397
INFO:root:At the start of the epoch: mem (CPU python)=7079.5546875MB; mem (CPU total)=13672.3671875MB
INFO:root:[   31] Training loss: 0.43422953, Validation loss: 0.47504217, Gradient norm: 6.89716166
INFO:root:At the start of the epoch: mem (CPU python)=7100.71875MB; mem (CPU total)=13703.30078125MB
INFO:root:[   32] Training loss: 0.43816696, Validation loss: 0.56746255, Gradient norm: 7.03038561
INFO:root:At the start of the epoch: mem (CPU python)=7121.8828125MB; mem (CPU total)=13562.66796875MB
INFO:root:[   33] Training loss: 0.43692776, Validation loss: 0.45587045, Gradient norm: 7.30420390
INFO:root:At the start of the epoch: mem (CPU python)=7143.046875MB; mem (CPU total)=13714.203125MB
INFO:root:[   34] Training loss: 0.43640278, Validation loss: 0.44557675, Gradient norm: 7.39367688
INFO:root:At the start of the epoch: mem (CPU python)=7164.2109375MB; mem (CPU total)=13776.5703125MB
INFO:root:[   35] Training loss: 0.43619165, Validation loss: 0.44391691, Gradient norm: 7.20615253
INFO:root:At the start of the epoch: mem (CPU python)=7185.375MB; mem (CPU total)=13766.4453125MB
INFO:root:[   36] Training loss: 0.43557241, Validation loss: 0.47021701, Gradient norm: 7.45766731
INFO:root:At the start of the epoch: mem (CPU python)=7206.54296875MB; mem (CPU total)=13812.64453125MB
INFO:root:[   37] Training loss: 0.43531914, Validation loss: 0.46197585, Gradient norm: 7.39569956
INFO:root:At the start of the epoch: mem (CPU python)=7227.703125MB; mem (CPU total)=13837.08984375MB
INFO:root:[   38] Training loss: 0.43975291, Validation loss: 0.45613011, Gradient norm: 7.32754673
INFO:root:At the start of the epoch: mem (CPU python)=7248.8671875MB; mem (CPU total)=13863.5546875MB
INFO:root:[   39] Training loss: 0.43126698, Validation loss: 0.46324029, Gradient norm: 7.26699690
INFO:root:At the start of the epoch: mem (CPU python)=7270.03125MB; mem (CPU total)=13887.87109375MB
INFO:root:[   40] Training loss: 0.43982897, Validation loss: 0.44922255, Gradient norm: 7.67549892
INFO:root:At the start of the epoch: mem (CPU python)=7291.1953125MB; mem (CPU total)=13765.34375MB
INFO:root:[   41] Training loss: 0.43171683, Validation loss: 0.46248758, Gradient norm: 7.21254235
INFO:root:At the start of the epoch: mem (CPU python)=7312.359375MB; mem (CPU total)=13892.21875MB
INFO:root:[   42] Training loss: 0.42941244, Validation loss: 0.47407820, Gradient norm: 7.20632701
INFO:root:At the start of the epoch: mem (CPU python)=7333.52734375MB; mem (CPU total)=13907.26953125MB
INFO:root:[   43] Training loss: 0.43486212, Validation loss: 0.44049515, Gradient norm: 7.53569783
INFO:root:At the start of the epoch: mem (CPU python)=7354.69140625MB; mem (CPU total)=13924.4296875MB
INFO:root:[   44] Training loss: 0.43070458, Validation loss: 0.44766219, Gradient norm: 7.45918008
INFO:root:At the start of the epoch: mem (CPU python)=7375.85546875MB; mem (CPU total)=14054.08203125MB
INFO:root:[   45] Training loss: 0.42682396, Validation loss: 0.44182215, Gradient norm: 7.66844725
INFO:root:At the start of the epoch: mem (CPU python)=7397.01953125MB; mem (CPU total)=13987.44140625MB
INFO:root:[   46] Training loss: 0.61741800, Validation loss: 0.73802373, Gradient norm: 11.57653911
INFO:root:At the start of the epoch: mem (CPU python)=7418.18359375MB; mem (CPU total)=13887.91796875MB
INFO:root:[   47] Training loss: 0.65453357, Validation loss: 0.59461277, Gradient norm: 8.15038791
INFO:root:At the start of the epoch: mem (CPU python)=7439.34765625MB; mem (CPU total)=14051.8125MB
INFO:root:[   48] Training loss: 0.59363084, Validation loss: 0.59386124, Gradient norm: 6.21770526
INFO:root:At the start of the epoch: mem (CPU python)=7460.5078125MB; mem (CPU total)=14064.30859375MB
INFO:root:[   49] Training loss: 0.58948359, Validation loss: 0.59071651, Gradient norm: 7.32316226
INFO:root:At the start of the epoch: mem (CPU python)=7481.671875MB; mem (CPU total)=14058.36328125MB
INFO:root:[   50] Training loss: 0.58487495, Validation loss: 0.58169994, Gradient norm: 7.82031453
INFO:root:At the start of the epoch: mem (CPU python)=7502.8359375MB; mem (CPU total)=14099.92578125MB
INFO:root:[   51] Training loss: 0.57978021, Validation loss: 0.60120909, Gradient norm: 8.61500657
INFO:root:At the start of the epoch: mem (CPU python)=7524.0MB; mem (CPU total)=14107.953125MB
INFO:root:[   52] Training loss: 0.82448937, Validation loss: 0.62378201, Gradient norm: 26.50458349
INFO:root:At the start of the epoch: mem (CPU python)=7545.16796875MB; mem (CPU total)=14114.484375MB
INFO:root:[   53] Training loss: 0.75413392, Validation loss: 0.60831780, Gradient norm: 26.34516213
INFO:root:At the start of the epoch: mem (CPU python)=7566.33203125MB; mem (CPU total)=14170.28125MB
INFO:root:[   54] Training loss: 0.60316185, Validation loss: 0.59635207, Gradient norm: 10.53155152
INFO:root:At the start of the epoch: mem (CPU python)=7587.49609375MB; mem (CPU total)=14179.203125MB
INFO:root:[   55] Training loss: 0.59266989, Validation loss: 0.60092027, Gradient norm: 9.81185569
INFO:root:At the start of the epoch: mem (CPU python)=7608.66015625MB; mem (CPU total)=14227.87109375MB
INFO:root:[   56] Training loss: 0.59182384, Validation loss: 0.58559422, Gradient norm: 10.45725220
INFO:root:At the start of the epoch: mem (CPU python)=7629.8203125MB; mem (CPU total)=14258.5MB
INFO:root:[   57] Training loss: 0.59765831, Validation loss: 0.61569272, Gradient norm: 12.17942019
INFO:root:At the start of the epoch: mem (CPU python)=7650.984375MB; mem (CPU total)=14242.26171875MB
INFO:root:[   58] Training loss: 0.60764027, Validation loss: 0.59531027, Gradient norm: 15.91828528
INFO:root:At the start of the epoch: mem (CPU python)=7672.15234375MB; mem (CPU total)=14257.1796875MB
INFO:root:[   59] Training loss: 0.59030271, Validation loss: 0.59399777, Gradient norm: 12.42512728
INFO:root:At the start of the epoch: mem (CPU python)=7693.31640625MB; mem (CPU total)=14346.96484375MB
INFO:root:[   60] Training loss: 0.98761762, Validation loss: 0.79377153, Gradient norm: 31.62172326
INFO:root:At the start of the epoch: mem (CPU python)=7714.48046875MB; mem (CPU total)=14307.98046875MB
INFO:root:[   61] Training loss: 0.67144101, Validation loss: 0.60500142, Gradient norm: 17.41266522
INFO:root:At the start of the epoch: mem (CPU python)=7735.64453125MB; mem (CPU total)=14329.60546875MB
INFO:root:[   62] Training loss: 0.59133070, Validation loss: 0.58366494, Gradient norm: 8.05944250
INFO:root:At the start of the epoch: mem (CPU python)=7756.80859375MB; mem (CPU total)=14372.65625MB
INFO:root:[   63] Training loss: 1.15641490, Validation loss: 1.63678532, Gradient norm: 8.02750695
INFO:root:At the start of the epoch: mem (CPU python)=7777.97265625MB; mem (CPU total)=14372.2421875MB
INFO:root:[   64] Training loss: 1.63660789, Validation loss: 1.63677705, Gradient norm: 0.00635348
INFO:root:At the start of the epoch: mem (CPU python)=7799.140625MB; mem (CPU total)=14370.390625MB
INFO:root:[   65] Training loss: 1.63660870, Validation loss: 1.63678190, Gradient norm: 0.00637223
INFO:root:At the start of the epoch: mem (CPU python)=7820.30078125MB; mem (CPU total)=14395.71484375MB
INFO:root:[   66] Training loss: 1.63661042, Validation loss: 1.63677883, Gradient norm: 0.00651964
INFO:root:At the start of the epoch: mem (CPU python)=7841.4609375MB; mem (CPU total)=14437.56640625MB
INFO:root:[   67] Training loss: 1.63661014, Validation loss: 1.63678158, Gradient norm: 0.00649920
INFO:root:At the start of the epoch: mem (CPU python)=7862.625MB; mem (CPU total)=14456.59765625MB
INFO:root:[   68] Training loss: 1.63661179, Validation loss: 1.63678908, Gradient norm: 0.00658903
INFO:root:At the start of the epoch: mem (CPU python)=7883.7890625MB; mem (CPU total)=14460.46875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   69] Training loss: 1.63661253, Validation loss: 1.63679983, Gradient norm: 0.00683814
INFO:root:At the start of the epoch: mem (CPU python)=7904.95703125MB; mem (CPU total)=14465.71875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   70] Training loss: 1.63660692, Validation loss: 1.63678253, Gradient norm: 0.00612077
INFO:root:At the start of the epoch: mem (CPU python)=7926.12109375MB; mem (CPU total)=14511.41015625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   71] Training loss: 1.63660493, Validation loss: 1.63677961, Gradient norm: 0.00592440
INFO:root:At the start of the epoch: mem (CPU python)=7947.28515625MB; mem (CPU total)=14222.375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:EP 71: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=7968.234375MB; mem (CPU total)=14565.6640625MB
INFO:root:Training the model took 1763.335s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.38197
INFO:root:EnergyScoreValidation: 0.29439
INFO:root:CRPSValidation: 0.12115
INFO:root:Gaussian NLLValidation: 0.49376
INFO:root:CoverageValidation: 0.67691
INFO:root:IntervalWidthValidation: 0.38631
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.40749
INFO:root:EnergyScoreTest: 0.3175
INFO:root:CRPSTest: 0.13461
INFO:root:Gaussian NLLTest: 0.99652
INFO:root:CoverageTest: 0.61548
INFO:root:IntervalWidthTest: 0.38483
INFO:root:After validation: mem (CPU python)=7975.82421875MB; mem (CPU total)=14640.26171875MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=7975.82421875MB; mem (CPU total)=14451.20703125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 60817408
INFO:root:After setting up the model: mem (CPU python)=7975.82421875MB; mem (CPU total)=14472.45703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=7975.82421875MB; mem (CPU total)=14630.14453125MB
INFO:root:[    1] Training loss: 0.76254543, Validation loss: 0.71597296, Gradient norm: 0.42059732
INFO:root:At the start of the epoch: mem (CPU python)=7996.2421875MB; mem (CPU total)=14603.046875MB
INFO:root:[    2] Training loss: 0.64272660, Validation loss: 0.56204098, Gradient norm: 0.76607223
INFO:root:At the start of the epoch: mem (CPU python)=8017.421875MB; mem (CPU total)=14589.63671875MB
INFO:root:[    3] Training loss: 0.52723717, Validation loss: 0.50769375, Gradient norm: 1.10101453
INFO:root:At the start of the epoch: mem (CPU python)=8038.6015625MB; mem (CPU total)=14429.46875MB
INFO:root:[    4] Training loss: 0.49890512, Validation loss: 0.49733391, Gradient norm: 1.33783818
INFO:root:At the start of the epoch: mem (CPU python)=8059.765625MB; mem (CPU total)=14625.890625MB
INFO:root:[    5] Training loss: 0.48408707, Validation loss: 0.48242397, Gradient norm: 1.48963990
INFO:root:At the start of the epoch: mem (CPU python)=8080.9296875MB; mem (CPU total)=14678.97265625MB
INFO:root:[    6] Training loss: 0.47474174, Validation loss: 0.47693838, Gradient norm: 1.73883115
INFO:root:At the start of the epoch: mem (CPU python)=8102.09375MB; mem (CPU total)=14687.296875MB
INFO:root:[    7] Training loss: 0.46838504, Validation loss: 0.46623863, Gradient norm: 1.96371986
INFO:root:At the start of the epoch: mem (CPU python)=8123.25390625MB; mem (CPU total)=14707.43359375MB
INFO:root:[    8] Training loss: 0.46110935, Validation loss: 0.46778444, Gradient norm: 2.07411443
INFO:root:At the start of the epoch: mem (CPU python)=8144.41796875MB; mem (CPU total)=14758.20703125MB
INFO:root:[    9] Training loss: 0.45554206, Validation loss: 0.46038136, Gradient norm: 2.28549898
INFO:root:At the start of the epoch: mem (CPU python)=8165.5859375MB; mem (CPU total)=14610.3671875MB
INFO:root:[   10] Training loss: 0.44999723, Validation loss: 0.45981130, Gradient norm: 2.43501143
INFO:root:At the start of the epoch: mem (CPU python)=8186.75MB; mem (CPU total)=14821.84765625MB
INFO:root:[   11] Training loss: 0.44631692, Validation loss: 0.45658493, Gradient norm: 2.63016351
INFO:root:At the start of the epoch: mem (CPU python)=8207.9140625MB; mem (CPU total)=14812.4296875MB
INFO:root:[   12] Training loss: 0.44443730, Validation loss: 0.45939118, Gradient norm: 2.73798705
INFO:root:At the start of the epoch: mem (CPU python)=8229.078125MB; mem (CPU total)=14806.92578125MB
INFO:root:[   13] Training loss: 0.44126062, Validation loss: 0.43731956, Gradient norm: 2.97466572
INFO:root:At the start of the epoch: mem (CPU python)=8250.24609375MB; mem (CPU total)=14835.99609375MB
INFO:root:[   14] Training loss: 0.43881091, Validation loss: 0.44316370, Gradient norm: 2.96788083
INFO:root:At the start of the epoch: mem (CPU python)=8271.40625MB; mem (CPU total)=14892.9921875MB
INFO:root:[   15] Training loss: 0.43890461, Validation loss: 0.43406431, Gradient norm: 3.20658441
INFO:root:At the start of the epoch: mem (CPU python)=8292.57421875MB; mem (CPU total)=14799.91015625MB
INFO:root:[   16] Training loss: 0.43801514, Validation loss: 0.43603236, Gradient norm: 3.13702685
INFO:root:At the start of the epoch: mem (CPU python)=8313.73046875MB; mem (CPU total)=14891.37890625MB
INFO:root:[   17] Training loss: 0.43544750, Validation loss: 0.45139549, Gradient norm: 3.27773087
INFO:root:At the start of the epoch: mem (CPU python)=8337.7265625MB; mem (CPU total)=14928.28125MB
INFO:root:[   18] Training loss: 0.43380336, Validation loss: 0.43131473, Gradient norm: 3.28858275
INFO:root:At the start of the epoch: mem (CPU python)=8358.89453125MB; mem (CPU total)=14936.515625MB
INFO:root:[   19] Training loss: 0.43179822, Validation loss: 0.43706172, Gradient norm: 3.29642105
INFO:root:At the start of the epoch: mem (CPU python)=8385.88671875MB; mem (CPU total)=14980.41015625MB
INFO:root:[   20] Training loss: 0.43085527, Validation loss: 0.43284031, Gradient norm: 3.38825989
INFO:root:At the start of the epoch: mem (CPU python)=8407.05078125MB; mem (CPU total)=14964.6875MB
INFO:root:[   21] Training loss: 0.42912820, Validation loss: 0.42367612, Gradient norm: 3.52756585
INFO:root:At the start of the epoch: mem (CPU python)=8428.5546875MB; mem (CPU total)=15034.4609375MB
INFO:root:[   22] Training loss: 0.42612551, Validation loss: 0.42699517, Gradient norm: 3.63556740
INFO:root:At the start of the epoch: mem (CPU python)=8449.71875MB; mem (CPU total)=15045.55078125MB
INFO:root:[   23] Training loss: 0.42696708, Validation loss: 0.42430579, Gradient norm: 3.68779718
INFO:root:At the start of the epoch: mem (CPU python)=8473.5390625MB; mem (CPU total)=15053.23828125MB
INFO:root:[   24] Training loss: 0.42515607, Validation loss: 0.42235208, Gradient norm: 3.60598924
INFO:root:At the start of the epoch: mem (CPU python)=8494.70703125MB; mem (CPU total)=15078.17578125MB
INFO:root:[   25] Training loss: 0.42373242, Validation loss: 0.42955458, Gradient norm: 3.95395556
INFO:root:At the start of the epoch: mem (CPU python)=8516.21484375MB; mem (CPU total)=15111.87890625MB
INFO:root:[   26] Training loss: 0.42395378, Validation loss: 0.42728800, Gradient norm: 3.92830812
INFO:root:At the start of the epoch: mem (CPU python)=8537.375MB; mem (CPU total)=15147.82421875MB
INFO:root:[   27] Training loss: 0.42302680, Validation loss: 0.41773191, Gradient norm: 3.93812693
INFO:root:At the start of the epoch: mem (CPU python)=8558.5390625MB; mem (CPU total)=15179.45703125MB
INFO:root:[   28] Training loss: 0.42229844, Validation loss: 0.43586646, Gradient norm: 4.01848544
INFO:root:At the start of the epoch: mem (CPU python)=8579.703125MB; mem (CPU total)=15281.2109375MB
INFO:root:[   29] Training loss: 0.42023673, Validation loss: 0.42879741, Gradient norm: 4.11757742
INFO:root:At the start of the epoch: mem (CPU python)=8600.8671875MB; mem (CPU total)=15273.8671875MB
INFO:root:[   30] Training loss: 0.41890250, Validation loss: 0.43652830, Gradient norm: 4.15327218
INFO:root:At the start of the epoch: mem (CPU python)=8622.03515625MB; mem (CPU total)=15220.55859375MB
INFO:root:[   31] Training loss: 0.42017377, Validation loss: 0.42381579, Gradient norm: 4.23571805
INFO:root:At the start of the epoch: mem (CPU python)=8643.19921875MB; mem (CPU total)=15230.4921875MB
INFO:root:[   32] Training loss: 0.41877319, Validation loss: 0.42709490, Gradient norm: 4.34175966
INFO:root:At the start of the epoch: mem (CPU python)=8664.36328125MB; mem (CPU total)=17638.6640625MB
INFO:root:[   33] Training loss: 0.41842962, Validation loss: 0.42048659, Gradient norm: 4.30852535
INFO:root:At the start of the epoch: mem (CPU python)=8685.5234375MB; mem (CPU total)=12753.52734375MB
INFO:root:[   34] Training loss: 0.41783486, Validation loss: 0.43079756, Gradient norm: 4.49401808
INFO:root:At the start of the epoch: mem (CPU python)=8706.6875MB; mem (CPU total)=15316.359375MB
INFO:root:[   35] Training loss: 0.41765836, Validation loss: 0.42320073, Gradient norm: 4.42655436
INFO:root:At the start of the epoch: mem (CPU python)=8727.875MB; mem (CPU total)=15549.078125MB
INFO:root:[   36] Training loss: 0.41677857, Validation loss: 0.41238147, Gradient norm: 4.44282276
INFO:root:At the start of the epoch: mem (CPU python)=8749.0390625MB; mem (CPU total)=15569.625MB
INFO:root:[   37] Training loss: 0.41626028, Validation loss: 0.41464898, Gradient norm: 4.40792147
INFO:root:At the start of the epoch: mem (CPU python)=8770.203125MB; mem (CPU total)=15625.90625MB
INFO:root:[   38] Training loss: 0.41506338, Validation loss: 0.44694709, Gradient norm: 4.45647278
INFO:root:At the start of the epoch: mem (CPU python)=8791.45703125MB; mem (CPU total)=15668.6171875MB
INFO:root:[   39] Training loss: 0.41708952, Validation loss: 0.43387782, Gradient norm: 4.37960678
INFO:root:At the start of the epoch: mem (CPU python)=8813.96875MB; mem (CPU total)=15664.40625MB
INFO:root:[   40] Training loss: 0.41242532, Validation loss: 0.41426298, Gradient norm: 4.50991660
INFO:root:At the start of the epoch: mem (CPU python)=8835.20703125MB; mem (CPU total)=15804.6875MB
INFO:root:[   41] Training loss: 0.41293323, Validation loss: 0.41036895, Gradient norm: 4.53272494
INFO:root:At the start of the epoch: mem (CPU python)=8856.56640625MB; mem (CPU total)=15843.1875MB
INFO:root:[   42] Training loss: 0.41085705, Validation loss: 0.41527454, Gradient norm: 4.39896665
INFO:root:At the start of the epoch: mem (CPU python)=8877.73046875MB; mem (CPU total)=15772.375MB
INFO:root:[   43] Training loss: 0.41020372, Validation loss: 0.40638228, Gradient norm: 4.54032535
INFO:root:At the start of the epoch: mem (CPU python)=8898.9609375MB; mem (CPU total)=15790.73046875MB
INFO:root:[   44] Training loss: 0.40937794, Validation loss: 0.42174477, Gradient norm: 4.54563318
INFO:root:At the start of the epoch: mem (CPU python)=8920.171875MB; mem (CPU total)=15821.609375MB
INFO:root:[   45] Training loss: 0.41050133, Validation loss: 0.43166529, Gradient norm: 4.63706674
INFO:root:At the start of the epoch: mem (CPU python)=8941.36328125MB; mem (CPU total)=15856.5234375MB
INFO:root:[   46] Training loss: 0.40953479, Validation loss: 0.42117909, Gradient norm: 4.63146782
INFO:root:At the start of the epoch: mem (CPU python)=8962.52734375MB; mem (CPU total)=15881.31640625MB
INFO:root:[   47] Training loss: 0.40880040, Validation loss: 0.40418982, Gradient norm: 4.56593829
INFO:root:At the start of the epoch: mem (CPU python)=8986.40234375MB; mem (CPU total)=15909.12890625MB
INFO:root:[   48] Training loss: 0.40570751, Validation loss: 0.40663828, Gradient norm: 4.48853074
INFO:root:At the start of the epoch: mem (CPU python)=9016.73828125MB; mem (CPU total)=15950.30078125MB
INFO:root:[   49] Training loss: 0.40506263, Validation loss: 0.41471367, Gradient norm: 4.58820681
INFO:root:At the start of the epoch: mem (CPU python)=9037.96484375MB; mem (CPU total)=15994.265625MB
INFO:root:[   50] Training loss: 0.40503264, Validation loss: 0.40618810, Gradient norm: 4.64420506
INFO:root:At the start of the epoch: mem (CPU python)=9059.34765625MB; mem (CPU total)=16024.15625MB
INFO:root:[   51] Training loss: 0.40446743, Validation loss: 0.40786545, Gradient norm: 4.66529880
INFO:root:At the start of the epoch: mem (CPU python)=9080.515625MB; mem (CPU total)=16047.79296875MB
INFO:root:[   52] Training loss: 0.40497117, Validation loss: 0.41310081, Gradient norm: 4.73206324
INFO:root:At the start of the epoch: mem (CPU python)=9101.75MB; mem (CPU total)=16081.5078125MB
INFO:root:[   53] Training loss: 0.40377918, Validation loss: 0.42717531, Gradient norm: 4.79855465
INFO:root:At the start of the epoch: mem (CPU python)=9122.9140625MB; mem (CPU total)=16085.21484375MB
INFO:root:[   54] Training loss: 0.40289545, Validation loss: 0.40331424, Gradient norm: 4.57715507
INFO:root:At the start of the epoch: mem (CPU python)=9144.13671875MB; mem (CPU total)=16111.1640625MB
INFO:root:[   55] Training loss: 0.40212107, Validation loss: 0.45020965, Gradient norm: 4.71144999
INFO:root:At the start of the epoch: mem (CPU python)=9165.30078125MB; mem (CPU total)=16195.90234375MB
INFO:root:[   56] Training loss: 0.40213836, Validation loss: 0.41157317, Gradient norm: 4.81845740
INFO:root:At the start of the epoch: mem (CPU python)=9186.5234375MB; mem (CPU total)=16201.62109375MB
INFO:root:[   57] Training loss: 0.40036759, Validation loss: 0.41089480, Gradient norm: 4.76503285
INFO:root:At the start of the epoch: mem (CPU python)=9207.69140625MB; mem (CPU total)=16233.9453125MB
INFO:root:[   58] Training loss: 0.40068461, Validation loss: 0.42481656, Gradient norm: 4.73543030
INFO:root:At the start of the epoch: mem (CPU python)=9228.921875MB; mem (CPU total)=16265.15234375MB
INFO:root:[   59] Training loss: 0.40148664, Validation loss: 0.43470582, Gradient norm: 4.82265600
INFO:root:At the start of the epoch: mem (CPU python)=9250.0859375MB; mem (CPU total)=16290.95703125MB
INFO:root:[   60] Training loss: 0.40064633, Validation loss: 0.41639458, Gradient norm: 4.85625681
INFO:root:At the start of the epoch: mem (CPU python)=9271.30859375MB; mem (CPU total)=16327.1015625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.39748193, Validation loss: 0.40720203, Gradient norm: 4.63691936
INFO:root:At the start of the epoch: mem (CPU python)=9292.47265625MB; mem (CPU total)=16346.9296875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 0.37250190, Validation loss: 0.38644849, Gradient norm: 4.30120368
INFO:root:At the start of the epoch: mem (CPU python)=9313.7265625MB; mem (CPU total)=16375.7109375MB
INFO:root:[   63] Training loss: 0.36138410, Validation loss: 0.37930819, Gradient norm: 4.36319794
INFO:root:At the start of the epoch: mem (CPU python)=9334.890625MB; mem (CPU total)=16403.49609375MB
INFO:root:[   64] Training loss: 0.36140265, Validation loss: 0.38131228, Gradient norm: 5.65353935
INFO:root:At the start of the epoch: mem (CPU python)=9356.1015625MB; mem (CPU total)=16436.734375MB
INFO:root:[   65] Training loss: 0.36199422, Validation loss: 0.38171757, Gradient norm: 7.18744013
INFO:root:At the start of the epoch: mem (CPU python)=9377.265625MB; mem (CPU total)=16458.953125MB
INFO:root:[   66] Training loss: 0.36439378, Validation loss: 0.37939729, Gradient norm: 8.27430974
INFO:root:At the start of the epoch: mem (CPU python)=9398.49609375MB; mem (CPU total)=16512.34765625MB
INFO:root:[   67] Training loss: 0.36362120, Validation loss: 0.38091405, Gradient norm: 9.15616906
INFO:root:At the start of the epoch: mem (CPU python)=9419.65625MB; mem (CPU total)=16533.31640625MB
INFO:root:[   68] Training loss: 0.36570731, Validation loss: 0.38455327, Gradient norm: 10.00990643
INFO:root:At the start of the epoch: mem (CPU python)=9440.88671875MB; mem (CPU total)=16555.828125MB
INFO:root:[   69] Training loss: 0.36873401, Validation loss: 0.38508870, Gradient norm: 10.51284213
INFO:root:At the start of the epoch: mem (CPU python)=9462.07421875MB; mem (CPU total)=16667.90234375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   70] Training loss: 0.36895774, Validation loss: 0.38665690, Gradient norm: 11.85291690
INFO:root:At the start of the epoch: mem (CPU python)=9483.23828125MB; mem (CPU total)=16647.22265625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   71] Training loss: 0.35959151, Validation loss: 0.38495259, Gradient norm: 8.82039849
INFO:root:At the start of the epoch: mem (CPU python)=9510.2734375MB; mem (CPU total)=16669.3828125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   72] Training loss: 0.35616861, Validation loss: 0.37358212, Gradient norm: 8.42036188
INFO:root:At the start of the epoch: mem (CPU python)=9531.4375MB; mem (CPU total)=16700.77734375MB
INFO:root:[   73] Training loss: 0.35287467, Validation loss: 0.37197270, Gradient norm: 6.71671994
INFO:root:At the start of the epoch: mem (CPU python)=9557.296875MB; mem (CPU total)=16747.55078125MB
INFO:root:[   74] Training loss: 0.35265807, Validation loss: 0.37130949, Gradient norm: 7.59925678
INFO:root:At the start of the epoch: mem (CPU python)=9578.46484375MB; mem (CPU total)=16780.640625MB
INFO:root:[   75] Training loss: 0.35331859, Validation loss: 0.37405076, Gradient norm: 8.29027468
INFO:root:At the start of the epoch: mem (CPU python)=9599.62890625MB; mem (CPU total)=16810.24609375MB
INFO:root:[   76] Training loss: 0.35302305, Validation loss: 0.37187644, Gradient norm: 9.11418366
INFO:root:At the start of the epoch: mem (CPU python)=9620.79296875MB; mem (CPU total)=16844.3125MB
INFO:root:[   77] Training loss: 0.35426530, Validation loss: 0.37217935, Gradient norm: 9.85514468
INFO:root:At the start of the epoch: mem (CPU python)=9641.95703125MB; mem (CPU total)=16869.796875MB
INFO:root:[   78] Training loss: 0.35376406, Validation loss: 0.37161031, Gradient norm: 10.98925179
INFO:root:At the start of the epoch: mem (CPU python)=9669.87890625MB; mem (CPU total)=16895.6875MB
INFO:root:[   79] Training loss: 0.35446775, Validation loss: 0.37222731, Gradient norm: 11.66411841
INFO:root:At the start of the epoch: mem (CPU python)=9691.04296875MB; mem (CPU total)=16913.61328125MB
INFO:root:[   80] Training loss: 0.35491312, Validation loss: 0.37446173, Gradient norm: 12.44294572
INFO:root:At the start of the epoch: mem (CPU python)=9712.5859375MB; mem (CPU total)=16958.671875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   81] Training loss: 0.35477095, Validation loss: 0.37337076, Gradient norm: 12.71760028
INFO:root:At the start of the epoch: mem (CPU python)=9733.75MB; mem (CPU total)=16995.1328125MB
INFO:root:[   82] Training loss: 0.35315893, Validation loss: 0.37110683, Gradient norm: 10.60578238
INFO:root:At the start of the epoch: mem (CPU python)=9754.91015625MB; mem (CPU total)=16719.64453125MB
INFO:root:[   83] Training loss: 0.35264512, Validation loss: 0.37154240, Gradient norm: 10.60748659
INFO:root:At the start of the epoch: mem (CPU python)=9776.07421875MB; mem (CPU total)=17099.4765625MB
INFO:root:[   84] Training loss: 0.35322730, Validation loss: 0.37088199, Gradient norm: 11.80261467
INFO:root:At the start of the epoch: mem (CPU python)=9797.23828125MB; mem (CPU total)=17074.3828125MB
INFO:root:[   85] Training loss: 0.35349926, Validation loss: 0.37212800, Gradient norm: 12.18168590
INFO:root:At the start of the epoch: mem (CPU python)=9818.3984375MB; mem (CPU total)=17116.3828125MB
INFO:root:[   86] Training loss: 0.35299247, Validation loss: 0.37108142, Gradient norm: 12.10970768
INFO:root:At the start of the epoch: mem (CPU python)=9839.56640625MB; mem (CPU total)=17145.99609375MB
INFO:root:[   87] Training loss: 0.35339200, Validation loss: 0.37145101, Gradient norm: 12.82768503
INFO:root:At the start of the epoch: mem (CPU python)=9860.73046875MB; mem (CPU total)=17178.86328125MB
INFO:root:[   88] Training loss: 0.35377273, Validation loss: 0.37230421, Gradient norm: 14.19406087
INFO:root:At the start of the epoch: mem (CPU python)=9883.89453125MB; mem (CPU total)=17204.04296875MB
INFO:root:[   89] Training loss: 0.35371839, Validation loss: 0.37185444, Gradient norm: 14.20438358
INFO:root:At the start of the epoch: mem (CPU python)=9905.05859375MB; mem (CPU total)=17236.87109375MB
INFO:root:[   90] Training loss: 0.35380970, Validation loss: 0.37260732, Gradient norm: 14.23193985
INFO:root:At the start of the epoch: mem (CPU python)=9926.22265625MB; mem (CPU total)=17278.44140625MB
INFO:root:[   91] Training loss: 0.35381037, Validation loss: 0.37303553, Gradient norm: 14.25805189
INFO:root:At the start of the epoch: mem (CPU python)=9947.51953125MB; mem (CPU total)=17298.91015625MB
INFO:root:[   92] Training loss: 0.35411307, Validation loss: 0.37070091, Gradient norm: 15.34708842
INFO:root:At the start of the epoch: mem (CPU python)=9968.96484375MB; mem (CPU total)=17318.5MB
INFO:root:[   93] Training loss: 0.35507197, Validation loss: 0.37098928, Gradient norm: 15.75630366
INFO:root:At the start of the epoch: mem (CPU python)=9995.91015625MB; mem (CPU total)=17368.46484375MB
INFO:root:[   94] Training loss: 0.35457171, Validation loss: 0.37268300, Gradient norm: 15.96002770
INFO:root:At the start of the epoch: mem (CPU python)=10017.07421875MB; mem (CPU total)=17413.13671875MB
INFO:root:[   95] Training loss: 0.35450401, Validation loss: 0.37211380, Gradient norm: 17.11424501
INFO:root:At the start of the epoch: mem (CPU python)=10038.45703125MB; mem (CPU total)=17447.046875MB
INFO:root:[   96] Training loss: 0.35426841, Validation loss: 0.37255875, Gradient norm: 16.39670139
INFO:root:At the start of the epoch: mem (CPU python)=10059.62109375MB; mem (CPU total)=17526.40625MB
INFO:root:[   97] Training loss: 0.35552295, Validation loss: 0.37177117, Gradient norm: 18.23979294
INFO:root:At the start of the epoch: mem (CPU python)=10080.78515625MB; mem (CPU total)=17559.30859375MB
INFO:root:[   98] Training loss: 0.35447789, Validation loss: 0.37339018, Gradient norm: 17.40112868
INFO:root:At the start of the epoch: mem (CPU python)=10101.953125MB; mem (CPU total)=17545.45703125MB
INFO:root:[   99] Training loss: 0.35477788, Validation loss: 0.37569543, Gradient norm: 18.37177050
INFO:root:At the start of the epoch: mem (CPU python)=10126.8515625MB; mem (CPU total)=17591.87109375MB
INFO:root:[  100] Training loss: 0.35496511, Validation loss: 0.37293687, Gradient norm: 19.63950772
INFO:root:At the start of the epoch: mem (CPU python)=10148.015625MB; mem (CPU total)=17589.77734375MB
INFO:root:[  101] Training loss: 0.35515904, Validation loss: 0.37276153, Gradient norm: 19.84616025
INFO:root:At the start of the epoch: mem (CPU python)=10169.57421875MB; mem (CPU total)=17621.328125MB
INFO:root:EP 101: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=10190.73046875MB; mem (CPU total)=17651.25MB
INFO:root:Training the model took 2707.685s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.32563
INFO:root:EnergyScoreValidation: 0.24581
INFO:root:CRPSValidation: 0.0976
INFO:root:Gaussian NLLValidation: -0.13887
INFO:root:CoverageValidation: 0.77484
INFO:root:IntervalWidthValidation: 0.37746
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.35333
INFO:root:EnergyScoreTest: 0.2707
INFO:root:CRPSTest: 0.10838
INFO:root:Gaussian NLLTest: 0.16735
INFO:root:CoverageTest: 0.73432
INFO:root:IntervalWidthTest: 0.37519
INFO:root:After validation: mem (CPU python)=10197.578125MB; mem (CPU total)=17842.69921875MB
