INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=568.69921875MB; mem (CPU total)=1035.3828125MB
INFO:root:############### Starting experiment with config file ks/uno_dropout.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12447.37109375MB; mem (CPU total)=1050.421875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12447.37109375MB; mem (CPU total)=1050.421875MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=12447.37109375MB; mem (CPU total)=2256.96484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=2266.53125MB
INFO:root:[    1] Training loss: 1.01208228, Validation loss: 1.00145482, Gradient norm: 0.03126781
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3437.4765625MB
INFO:root:[    2] Training loss: 0.99426825, Validation loss: 0.99085534, Gradient norm: 0.05160855
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3476.3125MB
INFO:root:[    3] Training loss: 0.98776003, Validation loss: 0.98647040, Gradient norm: 0.05757205
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3515.7890625MB
INFO:root:[    4] Training loss: 0.98502323, Validation loss: 0.98452257, Gradient norm: 0.05966982
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3553.1640625MB
INFO:root:[    5] Training loss: 0.98347984, Validation loss: 0.98323910, Gradient norm: 0.06209258
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3591.33984375MB
INFO:root:[    6] Training loss: 0.98230557, Validation loss: 0.98219275, Gradient norm: 0.06408338
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3629.28515625MB
INFO:root:[    7] Training loss: 0.98123189, Validation loss: 0.98120590, Gradient norm: 0.06514442
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3667.84765625MB
INFO:root:[    8] Training loss: 0.98017201, Validation loss: 0.98151239, Gradient norm: 0.06293256
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3707.4375MB
INFO:root:[    9] Training loss: 0.97939158, Validation loss: 0.98045219, Gradient norm: 0.06812729
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3744.62109375MB
INFO:root:[   10] Training loss: 0.97875997, Validation loss: 0.98011231, Gradient norm: 0.07903647
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3783.05859375MB
INFO:root:[   11] Training loss: 0.97812594, Validation loss: 0.97958938, Gradient norm: 0.07571001
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3821.05078125MB
INFO:root:[   12] Training loss: 0.97746847, Validation loss: 0.97802357, Gradient norm: 0.08129082
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3860.453125MB
INFO:root:[   13] Training loss: 0.97673252, Validation loss: 0.97751203, Gradient norm: 0.07963763
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3898.44140625MB
INFO:root:[   14] Training loss: 0.97601048, Validation loss: 0.97687150, Gradient norm: 0.08501042
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3936.78125MB
INFO:root:[   15] Training loss: 0.97533935, Validation loss: 0.97661624, Gradient norm: 0.08718683
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=3975.25390625MB
INFO:root:[   16] Training loss: 0.97476421, Validation loss: 0.97524825, Gradient norm: 0.08773782
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4013.48046875MB
INFO:root:[   17] Training loss: 0.97420896, Validation loss: 0.97469752, Gradient norm: 0.09532328
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4051.82421875MB
INFO:root:[   18] Training loss: 0.97362459, Validation loss: 0.97437626, Gradient norm: 0.09515521
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4090.03515625MB
INFO:root:[   19] Training loss: 0.97286650, Validation loss: 0.97372231, Gradient norm: 0.09427228
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4128.41015625MB
INFO:root:[   20] Training loss: 0.97239947, Validation loss: 0.97303527, Gradient norm: 0.09941269
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4166.7265625MB
INFO:root:[   21] Training loss: 0.97198469, Validation loss: 0.97290342, Gradient norm: 0.09087458
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4204.5078125MB
INFO:root:[   22] Training loss: 0.97159584, Validation loss: 0.97353503, Gradient norm: 0.10138027
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4242.81640625MB
INFO:root:[   23] Training loss: 0.97110986, Validation loss: 0.97194495, Gradient norm: 0.09331138
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4280.9609375MB
INFO:root:[   24] Training loss: 0.97075450, Validation loss: 0.97139145, Gradient norm: 0.09469264
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4319.3359375MB
INFO:root:[   25] Training loss: 0.97037988, Validation loss: 0.97154431, Gradient norm: 0.09938617
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4357.60546875MB
INFO:root:[   26] Training loss: 0.97025793, Validation loss: 0.97134147, Gradient norm: 0.10105463
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4395.70703125MB
INFO:root:[   27] Training loss: 0.96980651, Validation loss: 0.97103753, Gradient norm: 0.09592234
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4434.3125MB
INFO:root:[   28] Training loss: 0.96957680, Validation loss: 0.97073531, Gradient norm: 0.10064298
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4472.40234375MB
INFO:root:[   29] Training loss: 0.96939816, Validation loss: 0.97055931, Gradient norm: 0.09346625
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4510.83984375MB
INFO:root:[   30] Training loss: 0.96919242, Validation loss: 0.96965226, Gradient norm: 0.09501694
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4549.109375MB
INFO:root:[   31] Training loss: 0.96911942, Validation loss: 0.96944938, Gradient norm: 0.10119612
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4587.37109375MB
INFO:root:[   32] Training loss: 0.96876622, Validation loss: 0.96965208, Gradient norm: 0.09539126
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4625.859375MB
INFO:root:[   33] Training loss: 0.96832776, Validation loss: 0.96975113, Gradient norm: 0.09682109
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4663.94921875MB
INFO:root:[   34] Training loss: 0.96833454, Validation loss: 0.96936305, Gradient norm: 0.09903111
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4701.68359375MB
INFO:root:[   35] Training loss: 0.96827250, Validation loss: 0.96883284, Gradient norm: 0.10543996
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4739.63671875MB
INFO:root:[   36] Training loss: 0.96794334, Validation loss: 0.96925631, Gradient norm: 0.09798038
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4778.09765625MB
INFO:root:[   37] Training loss: 0.96786394, Validation loss: 0.96942297, Gradient norm: 0.09813157
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4815.9765625MB
INFO:root:[   38] Training loss: 0.96755382, Validation loss: 0.96875003, Gradient norm: 0.09940940
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4854.25390625MB
INFO:root:[   39] Training loss: 0.96745858, Validation loss: 0.96830847, Gradient norm: 0.10264703
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4892.42578125MB
INFO:root:[   40] Training loss: 0.96718814, Validation loss: 0.96801668, Gradient norm: 0.09829648
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4930.73046875MB
INFO:root:[   41] Training loss: 0.96708234, Validation loss: 0.96783634, Gradient norm: 0.10354675
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=4968.8046875MB
INFO:root:[   42] Training loss: 0.96686033, Validation loss: 0.96762284, Gradient norm: 0.10022813
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5006.94921875MB
INFO:root:[   43] Training loss: 0.96666076, Validation loss: 0.96863647, Gradient norm: 0.09971648
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5045.37109375MB
INFO:root:[   44] Training loss: 0.96656592, Validation loss: 0.96755388, Gradient norm: 0.10568927
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5083.68359375MB
INFO:root:[   45] Training loss: 0.96637389, Validation loss: 0.96859008, Gradient norm: 0.10370171
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5121.83984375MB
INFO:root:[   46] Training loss: 0.96620920, Validation loss: 0.96718405, Gradient norm: 0.10331534
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5159.92578125MB
INFO:root:[   47] Training loss: 0.96603972, Validation loss: 0.96779189, Gradient norm: 0.10441297
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5198.28515625MB
INFO:root:[   48] Training loss: 0.96586055, Validation loss: 0.96679468, Gradient norm: 0.10141375
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5236.6015625MB
INFO:root:[   49] Training loss: 0.96564070, Validation loss: 0.96684373, Gradient norm: 0.10768494
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5274.02734375MB
INFO:root:[   50] Training loss: 0.96539931, Validation loss: 0.96647306, Gradient norm: 0.10321766
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5312.28125MB
INFO:root:[   51] Training loss: 0.96517868, Validation loss: 0.96589177, Gradient norm: 0.10146952
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5351.03125MB
INFO:root:[   52] Training loss: 0.96504615, Validation loss: 0.96591373, Gradient norm: 0.10610754
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5389.421875MB
INFO:root:[   53] Training loss: 0.96495669, Validation loss: 0.96594492, Gradient norm: 0.10741804
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5427.5859375MB
INFO:root:[   54] Training loss: 0.96492578, Validation loss: 0.96619788, Gradient norm: 0.11135823
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5465.74609375MB
INFO:root:[   55] Training loss: 0.96462989, Validation loss: 0.96570295, Gradient norm: 0.10297809
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5504.48828125MB
INFO:root:[   56] Training loss: 0.96438768, Validation loss: 0.96590463, Gradient norm: 0.10427226
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5542.765625MB
INFO:root:[   57] Training loss: 0.96437450, Validation loss: 0.96572084, Gradient norm: 0.10492567
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5580.671875MB
INFO:root:[   58] Training loss: 0.96411670, Validation loss: 0.96540374, Gradient norm: 0.10688717
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5619.54296875MB
INFO:root:[   59] Training loss: 0.96398861, Validation loss: 0.96583549, Gradient norm: 0.10782445
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5658.18359375MB
INFO:root:[   60] Training loss: 0.96381893, Validation loss: 0.96560196, Gradient norm: 0.10451880
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5696.57421875MB
INFO:root:[   61] Training loss: 0.96381969, Validation loss: 0.96453647, Gradient norm: 0.10513458
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5734.453125MB
INFO:root:[   62] Training loss: 0.96362115, Validation loss: 0.96461986, Gradient norm: 0.10526162
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5772.84375MB
INFO:root:[   63] Training loss: 0.96349431, Validation loss: 0.96477105, Gradient norm: 0.10541719
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5810.98046875MB
INFO:root:[   64] Training loss: 0.96341064, Validation loss: 0.96440347, Gradient norm: 0.10964999
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5849.32421875MB
INFO:root:[   65] Training loss: 0.96326503, Validation loss: 0.96426935, Gradient norm: 0.10478446
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5886.29296875MB
INFO:root:[   66] Training loss: 0.96306434, Validation loss: 0.96413099, Gradient norm: 0.10354778
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5923.50390625MB
INFO:root:[   67] Training loss: 0.96295170, Validation loss: 0.96397565, Gradient norm: 0.10108897
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=5962.05078125MB
INFO:root:[   68] Training loss: 0.96281536, Validation loss: 0.96415344, Gradient norm: 0.10065454
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6000.7109375MB
INFO:root:[   69] Training loss: 0.96282457, Validation loss: 0.96358219, Gradient norm: 0.11114018
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6038.2421875MB
INFO:root:[   70] Training loss: 0.96262563, Validation loss: 0.96452171, Gradient norm: 0.10549772
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6076.6640625MB
INFO:root:[   71] Training loss: 0.96250026, Validation loss: 0.96358087, Gradient norm: 0.10756645
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6114.62890625MB
INFO:root:[   72] Training loss: 0.96250594, Validation loss: 0.96402022, Gradient norm: 0.10574717
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6152.984375MB
INFO:root:[   73] Training loss: 0.96238486, Validation loss: 0.96382159, Gradient norm: 0.10760586
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6190.8828125MB
INFO:root:[   74] Training loss: 0.96204604, Validation loss: 0.96387385, Gradient norm: 0.10365997
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6229.02734375MB
INFO:root:[   75] Training loss: 0.96199844, Validation loss: 0.96253077, Gradient norm: 0.10521573
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6267.46484375MB
INFO:root:[   76] Training loss: 0.96175558, Validation loss: 0.96291370, Gradient norm: 0.10514156
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6305.82421875MB
INFO:root:[   77] Training loss: 0.96179701, Validation loss: 0.96333885, Gradient norm: 0.10435315
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6343.6953125MB
INFO:root:[   78] Training loss: 0.96172531, Validation loss: 0.96263702, Gradient norm: 0.10860606
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6381.83203125MB
INFO:root:[   79] Training loss: 0.96160249, Validation loss: 0.96242536, Gradient norm: 0.10792829
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6420.296875MB
INFO:root:[   80] Training loss: 0.96125278, Validation loss: 0.96272756, Gradient norm: 0.10164915
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6458.6875MB
INFO:root:[   81] Training loss: 0.96134453, Validation loss: 0.96349795, Gradient norm: 0.11540209
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6497.11328125MB
INFO:root:[   82] Training loss: 0.96103404, Validation loss: 0.96215830, Gradient norm: 0.10636242
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6534.78515625MB
INFO:root:[   83] Training loss: 0.96101754, Validation loss: 0.96214961, Gradient norm: 0.11448196
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6572.89453125MB
INFO:root:[   84] Training loss: 0.96092455, Validation loss: 0.96243108, Gradient norm: 0.11118941
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6611.2734375MB
INFO:root:[   85] Training loss: 0.96082958, Validation loss: 0.96230933, Gradient norm: 0.11006555
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6649.171875MB
INFO:root:[   86] Training loss: 0.96062066, Validation loss: 0.96168417, Gradient norm: 0.10624099
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6687.56640625MB
INFO:root:[   87] Training loss: 0.96053208, Validation loss: 0.96179588, Gradient norm: 0.11310218
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6725.69921875MB
INFO:root:[   88] Training loss: 0.96039791, Validation loss: 0.96115740, Gradient norm: 0.10475709
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6764.32421875MB
INFO:root:[   89] Training loss: 0.96027109, Validation loss: 0.96090453, Gradient norm: 0.11130463
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6802.89453125MB
INFO:root:[   90] Training loss: 0.96020832, Validation loss: 0.96183274, Gradient norm: 0.11252766
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6841.28515625MB
INFO:root:[   91] Training loss: 0.96028210, Validation loss: 0.96167967, Gradient norm: 0.11860671
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6879.18359375MB
INFO:root:[   92] Training loss: 0.96014266, Validation loss: 0.96183993, Gradient norm: 0.12047452
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6917.328125MB
INFO:root:[   93] Training loss: 0.95991871, Validation loss: 0.96110915, Gradient norm: 0.10971184
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6955.1796875MB
INFO:root:[   94] Training loss: 0.95987641, Validation loss: 0.96083898, Gradient norm: 0.11120314
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=6993.859375MB
INFO:root:[   95] Training loss: 0.95972611, Validation loss: 0.96209127, Gradient norm: 0.11232117
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7032.265625MB
INFO:root:[   96] Training loss: 0.95964505, Validation loss: 0.96107688, Gradient norm: 0.11394312
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7070.61328125MB
INFO:root:[   97] Training loss: 0.95955496, Validation loss: 0.96086308, Gradient norm: 0.11466281
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7108.52734375MB
INFO:root:[   98] Training loss: 0.95954950, Validation loss: 0.96075826, Gradient norm: 0.12068407
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7146.4296875MB
INFO:root:[   99] Training loss: 0.95937129, Validation loss: 0.96123495, Gradient norm: 0.11198660
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7184.59375MB
INFO:root:[  100] Training loss: 0.95930247, Validation loss: 0.96083119, Gradient norm: 0.11282802
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7223.0MB
INFO:root:[  101] Training loss: 0.95931658, Validation loss: 0.96049727, Gradient norm: 0.11339559
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7260.7890625MB
INFO:root:[  102] Training loss: 0.95926986, Validation loss: 0.96062213, Gradient norm: 0.12306390
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7299.19921875MB
INFO:root:[  103] Training loss: 0.95908346, Validation loss: 0.96076856, Gradient norm: 0.11280182
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7337.36328125MB
INFO:root:[  104] Training loss: 0.95905119, Validation loss: 0.96024613, Gradient norm: 0.11535412
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7375.33984375MB
INFO:root:[  105] Training loss: 0.95906199, Validation loss: 0.96058035, Gradient norm: 0.12179568
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7413.75MB
INFO:root:[  106] Training loss: 0.95893487, Validation loss: 0.96017987, Gradient norm: 0.11488429
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7451.671875MB
INFO:root:[  107] Training loss: 0.95880409, Validation loss: 0.95970073, Gradient norm: 0.11695328
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7489.9921875MB
INFO:root:[  108] Training loss: 0.95871546, Validation loss: 0.96017389, Gradient norm: 0.11575742
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7528.2734375MB
INFO:root:[  109] Training loss: 0.95858437, Validation loss: 0.95987484, Gradient norm: 0.11059687
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7566.00390625MB
INFO:root:[  110] Training loss: 0.95859676, Validation loss: 0.96069989, Gradient norm: 0.11530753
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7604.16796875MB
INFO:root:[  111] Training loss: 0.95855352, Validation loss: 0.95980366, Gradient norm: 0.11493687
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7642.72265625MB
INFO:root:[  112] Training loss: 0.95855167, Validation loss: 0.95926930, Gradient norm: 0.11793536
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7680.86328125MB
INFO:root:[  113] Training loss: 0.95849612, Validation loss: 0.96010395, Gradient norm: 0.11230863
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7719.20703125MB
INFO:root:[  114] Training loss: 0.95841267, Validation loss: 0.96006750, Gradient norm: 0.11907232
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7757.125MB
INFO:root:[  115] Training loss: 0.95833937, Validation loss: 0.95978208, Gradient norm: 0.12041189
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7795.6796875MB
INFO:root:[  116] Training loss: 0.95819747, Validation loss: 0.96021210, Gradient norm: 0.11563586
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7833.6953125MB
INFO:root:[  117] Training loss: 0.95820756, Validation loss: 0.96011183, Gradient norm: 0.11274532
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7871.859375MB
INFO:root:[  118] Training loss: 0.95809653, Validation loss: 0.95954788, Gradient norm: 0.12039058
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7910.20703125MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  119] Training loss: 0.95806709, Validation loss: 0.95921091, Gradient norm: 0.12131487
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7948.0546875MB
INFO:root:[  120] Training loss: 0.95704036, Validation loss: 0.95861436, Gradient norm: 0.09988185
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=7986.15234375MB
INFO:root:[  121] Training loss: 0.95699951, Validation loss: 0.95820497, Gradient norm: 0.10615793
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8024.640625MB
INFO:root:[  122] Training loss: 0.95685832, Validation loss: 0.95863176, Gradient norm: 0.11101608
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8063.28515625MB
INFO:root:[  123] Training loss: 0.95664167, Validation loss: 0.95860627, Gradient norm: 0.11226749
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8101.4296875MB
INFO:root:[  124] Training loss: 0.95664958, Validation loss: 0.95833042, Gradient norm: 0.11055262
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8139.60546875MB
INFO:root:[  125] Training loss: 0.95667726, Validation loss: 0.95844479, Gradient norm: 0.11020206
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8177.48828125MB
INFO:root:[  126] Training loss: 0.95663302, Validation loss: 0.95808338, Gradient norm: 0.11773260
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8216.125MB
INFO:root:[  127] Training loss: 0.95649099, Validation loss: 0.95851690, Gradient norm: 0.11157042
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8254.515625MB
INFO:root:[  128] Training loss: 0.95656251, Validation loss: 0.95860192, Gradient norm: 0.11336294
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8292.62890625MB
INFO:root:[  129] Training loss: 0.95630462, Validation loss: 0.95784768, Gradient norm: 0.11193650
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8330.55078125MB
INFO:root:[  130] Training loss: 0.95642221, Validation loss: 0.95800816, Gradient norm: 0.11781071
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8368.2265625MB
INFO:root:[  131] Training loss: 0.95643710, Validation loss: 0.95822883, Gradient norm: 0.11782074
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8406.49609375MB
INFO:root:[  132] Training loss: 0.95636176, Validation loss: 0.95836963, Gradient norm: 0.11113433
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8444.6328125MB
INFO:root:[  133] Training loss: 0.95640131, Validation loss: 0.95813039, Gradient norm: 0.11553027
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8483.01953125MB
INFO:root:[  134] Training loss: 0.95631817, Validation loss: 0.95826317, Gradient norm: 0.11972266
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8521.41015625MB
INFO:root:[  135] Training loss: 0.95638104, Validation loss: 0.95789155, Gradient norm: 0.12383246
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8559.30859375MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  136] Training loss: 0.95624694, Validation loss: 0.95808668, Gradient norm: 0.11490287
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8597.390625MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  137] Training loss: 0.95572706, Validation loss: 0.95731509, Gradient norm: 0.10901796
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8635.90234375MB
INFO:root:[  138] Training loss: 0.95523703, Validation loss: 0.95718818, Gradient norm: 0.10103812
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8674.25MB
INFO:root:[  139] Training loss: 0.95516619, Validation loss: 0.95736705, Gradient norm: 0.10430689
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8712.671875MB
INFO:root:[  140] Training loss: 0.95521392, Validation loss: 0.95704435, Gradient norm: 0.10739474
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8750.94140625MB
INFO:root:[  141] Training loss: 0.95512144, Validation loss: 0.95735038, Gradient norm: 0.10459244
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8789.33203125MB
INFO:root:[  142] Training loss: 0.95521230, Validation loss: 0.95727029, Gradient norm: 0.10953395
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8827.74609375MB
INFO:root:[  143] Training loss: 0.95514755, Validation loss: 0.95762485, Gradient norm: 0.10839906
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8865.54296875MB
INFO:root:[  144] Training loss: 0.95506308, Validation loss: 0.95710040, Gradient norm: 0.10898219
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8903.92578125MB
INFO:root:[  145] Training loss: 0.95511327, Validation loss: 0.95735227, Gradient norm: 0.10836572
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8942.0703125MB
INFO:root:[  146] Training loss: 0.95506350, Validation loss: 0.95730516, Gradient norm: 0.10800979
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=8980.21484375MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  147] Training loss: 0.95509604, Validation loss: 0.95727342, Gradient norm: 0.10977110
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9017.98828125MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  148] Training loss: 0.95498310, Validation loss: 0.95682288, Gradient norm: 0.10855958
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9056.8046875MB
INFO:root:[  149] Training loss: 0.95485954, Validation loss: 0.95677401, Gradient norm: 0.10417984
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9095.28125MB
INFO:root:[  150] Training loss: 0.95477827, Validation loss: 0.95682792, Gradient norm: 0.10398041
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9133.45703125MB
INFO:root:[  151] Training loss: 0.95477344, Validation loss: 0.95695259, Gradient norm: 0.10161433
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9171.34765625MB
INFO:root:[  152] Training loss: 0.95474331, Validation loss: 0.95677077, Gradient norm: 0.10265695
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9209.59375MB
INFO:root:[  153] Training loss: 0.95474297, Validation loss: 0.95659779, Gradient norm: 0.10512387
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9247.80078125MB
INFO:root:[  154] Training loss: 0.95474692, Validation loss: 0.95700746, Gradient norm: 0.10744761
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9286.40625MB
INFO:root:[  155] Training loss: 0.95483581, Validation loss: 0.95686634, Gradient norm: 0.10625375
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9324.3984375MB
INFO:root:[  156] Training loss: 0.95476480, Validation loss: 0.95703847, Gradient norm: 0.10516002
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9362.53125MB
INFO:root:[  157] Training loss: 0.95470829, Validation loss: 0.95665168, Gradient norm: 0.10397416
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9400.67578125MB
INFO:root:[  158] Training loss: 0.95469256, Validation loss: 0.95703861, Gradient norm: 0.10795804
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9438.8203125MB
INFO:root:[  159] Training loss: 0.95474070, Validation loss: 0.95670587, Gradient norm: 0.10601792
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9476.96484375MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  160] Training loss: 0.95473631, Validation loss: 0.95695726, Gradient norm: 0.10597258
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9515.03515625MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  161] Training loss: 0.95465161, Validation loss: 0.95628106, Gradient norm: 0.10534324
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9553.57421875MB
INFO:root:[  162] Training loss: 0.95470642, Validation loss: 0.95700845, Gradient norm: 0.10558675
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9591.99609375MB
INFO:root:[  163] Training loss: 0.95457685, Validation loss: 0.95672629, Gradient norm: 0.10398874
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9630.41796875MB
INFO:root:[  164] Training loss: 0.95463416, Validation loss: 0.95663011, Gradient norm: 0.10572209
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9668.0703125MB
INFO:root:[  165] Training loss: 0.95452708, Validation loss: 0.95698644, Gradient norm: 0.10435340
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9706.21484375MB
INFO:root:[  166] Training loss: 0.95464376, Validation loss: 0.95697855, Gradient norm: 0.10871627
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9744.02734375MB
INFO:root:[  167] Training loss: 0.95462899, Validation loss: 0.95656794, Gradient norm: 0.10507093
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9782.078125MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  168] Training loss: 0.95459128, Validation loss: 0.95703301, Gradient norm: 0.10239348
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9820.21484375MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  169] Training loss: 0.95468966, Validation loss: 0.95694122, Gradient norm: 0.10502036
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9858.359375MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:[  170] Training loss: 0.95451208, Validation loss: 0.95677573, Gradient norm: 0.10418690
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=9896.50390625MB
INFO:root:Learning rate reduced to: [4.8828125e-07]
INFO:root:EP 170: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12447.37109375MB; mem (CPU total)=9934.64453125MB
INFO:root:Training the model took 8131.183s.
INFO:root:Emptying the cuda cache took 0.013s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94195
INFO:root:EnergyScoreTrain: 0.84577
INFO:root:CRPSTrain: 0.71344
INFO:root:Gaussian NLLTrain: 605.18461
INFO:root:CoverageTrain: 0.2008
INFO:root:IntervalWidthTrain: 0.41198
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94432
INFO:root:EnergyScoreValidation: 0.84859
INFO:root:CRPSValidation: 0.71592
INFO:root:Gaussian NLLValidation: 603.40753
INFO:root:CoverageValidation: 0.19875
INFO:root:IntervalWidthValidation: 0.41029
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94399
INFO:root:EnergyScoreTest: 0.84816
INFO:root:CRPSTest: 0.71581
INFO:root:Gaussian NLLTest: 608.48186
INFO:root:CoverageTest: 0.19871
INFO:root:IntervalWidthTest: 0.41027
INFO:root:After validation: mem (CPU python)=12447.37109375MB; mem (CPU total)=10007.99609375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12447.37109375MB; mem (CPU total)=10007.65234375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 174063616
INFO:root:After setting up the model: mem (CPU python)=12447.37109375MB; mem (CPU total)=10007.65234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10007.90234375MB
INFO:root:[    1] Training loss: 1.01089438, Validation loss: 0.99980682, Gradient norm: 0.03110910
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10045.1015625MB
INFO:root:[    2] Training loss: 0.99380165, Validation loss: 0.99023736, Gradient norm: 0.04446518
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10084.36328125MB
INFO:root:[    3] Training loss: 0.98731169, Validation loss: 0.98654282, Gradient norm: 0.05002952
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10121.921875MB
INFO:root:[    4] Training loss: 0.98432640, Validation loss: 0.98377677, Gradient norm: 0.05750108
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10159.8671875MB
INFO:root:[    5] Training loss: 0.98244262, Validation loss: 0.98280825, Gradient norm: 0.06153767
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10198.671875MB
INFO:root:[    6] Training loss: 0.98118963, Validation loss: 0.98209829, Gradient norm: 0.06017099
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10236.82421875MB
INFO:root:[    7] Training loss: 0.98004415, Validation loss: 0.98040967, Gradient norm: 0.06291253
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10275.53125MB
INFO:root:[    8] Training loss: 0.97935896, Validation loss: 0.97976644, Gradient norm: 0.06994337
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10313.94140625MB
INFO:root:[    9] Training loss: 0.97812791, Validation loss: 0.97864788, Gradient norm: 0.06833430
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10352.1015625MB
INFO:root:[   10] Training loss: 0.97719375, Validation loss: 0.97769048, Gradient norm: 0.07268128
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10390.29296875MB
INFO:root:[   11] Training loss: 0.97618051, Validation loss: 0.97659124, Gradient norm: 0.07367233
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10428.0MB
INFO:root:[   12] Training loss: 0.97561700, Validation loss: 0.97588064, Gradient norm: 0.08854316
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10465.52734375MB
INFO:root:[   13] Training loss: 0.97459678, Validation loss: 0.97543173, Gradient norm: 0.08577665
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10503.59765625MB
INFO:root:[   14] Training loss: 0.97415091, Validation loss: 0.97432064, Gradient norm: 0.09245532
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10541.73828125MB
INFO:root:[   15] Training loss: 0.97334396, Validation loss: 0.97401831, Gradient norm: 0.09056418
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10579.45703125MB
INFO:root:[   16] Training loss: 0.97294623, Validation loss: 0.97347097, Gradient norm: 0.09560952
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10617.51171875MB
INFO:root:[   17] Training loss: 0.97222546, Validation loss: 0.97273544, Gradient norm: 0.09430197
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10655.65234375MB
INFO:root:[   18] Training loss: 0.97192682, Validation loss: 0.97288109, Gradient norm: 0.10067797
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10694.05859375MB
INFO:root:[   19] Training loss: 0.97131008, Validation loss: 0.97288575, Gradient norm: 0.09970441
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10732.21484375MB
INFO:root:[   20] Training loss: 0.97093916, Validation loss: 0.97179120, Gradient norm: 0.09738244
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10770.47265625MB
INFO:root:[   21] Training loss: 0.97053293, Validation loss: 0.97115380, Gradient norm: 0.10231144
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10808.8671875MB
INFO:root:[   22] Training loss: 0.97015811, Validation loss: 0.97166413, Gradient norm: 0.10150302
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10847.27734375MB
INFO:root:[   23] Training loss: 0.96991769, Validation loss: 0.97066437, Gradient norm: 0.10417709
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10885.62890625MB
INFO:root:[   24] Training loss: 0.96957229, Validation loss: 0.97006313, Gradient norm: 0.10127045
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10922.48046875MB
INFO:root:[   25] Training loss: 0.96907855, Validation loss: 0.96991726, Gradient norm: 0.09946657
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10960.87109375MB
INFO:root:[   26] Training loss: 0.96902987, Validation loss: 0.97014819, Gradient norm: 0.10354828
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=10998.18359375MB
INFO:root:[   27] Training loss: 0.96861484, Validation loss: 0.96948983, Gradient norm: 0.10149397
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11036.27734375MB
INFO:root:[   28] Training loss: 0.96841442, Validation loss: 0.96955066, Gradient norm: 0.11094065
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11074.421875MB
INFO:root:[   29] Training loss: 0.96798270, Validation loss: 0.96850511, Gradient norm: 0.10292495
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11112.30078125MB
INFO:root:[   30] Training loss: 0.96795049, Validation loss: 0.96851605, Gradient norm: 0.10351138
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11150.4765625MB
INFO:root:[   31] Training loss: 0.96752105, Validation loss: 0.96851879, Gradient norm: 0.10631020
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11188.8671875MB
INFO:root:[   32] Training loss: 0.96734356, Validation loss: 0.96850207, Gradient norm: 0.10940530
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11226.9609375MB
INFO:root:[   33] Training loss: 0.96711511, Validation loss: 0.96927964, Gradient norm: 0.10983437
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11265.3203125MB
INFO:root:[   34] Training loss: 0.96670378, Validation loss: 0.96775047, Gradient norm: 0.10738000
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11302.8671875MB
INFO:root:[   35] Training loss: 0.96644639, Validation loss: 0.96751188, Gradient norm: 0.10568296
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11340.85546875MB
INFO:root:[   36] Training loss: 0.96623866, Validation loss: 0.96750935, Gradient norm: 0.10297460
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11379.0625MB
INFO:root:[   37] Training loss: 0.96603424, Validation loss: 0.96694987, Gradient norm: 0.11246896
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11416.94921875MB
INFO:root:[   38] Training loss: 0.96576339, Validation loss: 0.96661304, Gradient norm: 0.10760410
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11455.02734375MB
INFO:root:[   39] Training loss: 0.96548533, Validation loss: 0.96651232, Gradient norm: 0.10624061
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11492.9921875MB
INFO:root:[   40] Training loss: 0.96545182, Validation loss: 0.96641729, Gradient norm: 0.11063329
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11531.3125MB
INFO:root:[   41] Training loss: 0.96500214, Validation loss: 0.96642846, Gradient norm: 0.10780381
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11569.703125MB
INFO:root:[   42] Training loss: 0.96492850, Validation loss: 0.96581408, Gradient norm: 0.11160602
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11607.95703125MB
INFO:root:[   43] Training loss: 0.96458041, Validation loss: 0.96560270, Gradient norm: 0.10514165
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11646.43359375MB
INFO:root:[   44] Training loss: 0.96466925, Validation loss: 0.96562530, Gradient norm: 0.11363504
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11684.9296875MB
INFO:root:[   45] Training loss: 0.96420723, Validation loss: 0.96550534, Gradient norm: 0.10887668
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11722.8125MB
INFO:root:[   46] Training loss: 0.96422483, Validation loss: 0.96507514, Gradient norm: 0.11343374
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11761.00390625MB
INFO:root:[   47] Training loss: 0.96396051, Validation loss: 0.96547495, Gradient norm: 0.11196574
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11799.1484375MB
INFO:root:[   48] Training loss: 0.96380511, Validation loss: 0.96420504, Gradient norm: 0.10080645
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11838.6640625MB
INFO:root:[   49] Training loss: 0.96378767, Validation loss: 0.96551906, Gradient norm: 0.11171917
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11876.796875MB
INFO:root:[   50] Training loss: 0.96354302, Validation loss: 0.96454834, Gradient norm: 0.11175802
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11914.94140625MB
INFO:root:[   51] Training loss: 0.96334134, Validation loss: 0.96430250, Gradient norm: 0.10731096
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11953.0859375MB
INFO:root:[   52] Training loss: 0.96306401, Validation loss: 0.96429744, Gradient norm: 0.10740546
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=11991.05078125MB
INFO:root:[   53] Training loss: 0.96314605, Validation loss: 0.96468539, Gradient norm: 0.11870220
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=12029.44140625MB
INFO:root:[   54] Training loss: 0.96276398, Validation loss: 0.96410935, Gradient norm: 0.10361843
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=12067.46484375MB
INFO:root:[   55] Training loss: 0.96250840, Validation loss: 0.96376905, Gradient norm: 0.10788747
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=12106.10546875MB
INFO:root:[   56] Training loss: 0.96243374, Validation loss: 0.96338960, Gradient norm: 0.10166571
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=12144.65234375MB
INFO:root:[   57] Training loss: 0.96239735, Validation loss: 0.96297544, Gradient norm: 0.10817737
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=12182.625MB
INFO:root:[   58] Training loss: 0.96219267, Validation loss: 0.96330252, Gradient norm: 0.11456934
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=12220.5234375MB
INFO:root:[   59] Training loss: 0.96198432, Validation loss: 0.96280822, Gradient norm: 0.10664837
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=12258.9453125MB
INFO:root:[   60] Training loss: 0.96191373, Validation loss: 0.96295406, Gradient norm: 0.11026748
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=12295.86328125MB
INFO:root:[   61] Training loss: 0.96183681, Validation loss: 0.96301825, Gradient norm: 0.10968006
INFO:root:At the start of the epoch: mem (CPU python)=12447.37109375MB; mem (CPU total)=12334.3984375MB
INFO:root:[   62] Training loss: 0.96147233, Validation loss: 0.96282825, Gradient norm: 0.10851469
INFO:root:At the start of the epoch: mem (CPU python)=12461.44921875MB; mem (CPU total)=12371.92578125MB
INFO:root:[   63] Training loss: 0.96149627, Validation loss: 0.96255399, Gradient norm: 0.10562147
INFO:root:At the start of the epoch: mem (CPU python)=12499.546875MB; mem (CPU total)=12410.30078125MB
INFO:root:[   64] Training loss: 0.96142850, Validation loss: 0.96234231, Gradient norm: 0.11234370
INFO:root:At the start of the epoch: mem (CPU python)=12537.64453125MB; mem (CPU total)=12448.83203125MB
INFO:root:[   65] Training loss: 0.96127365, Validation loss: 0.96265571, Gradient norm: 0.11439510
INFO:root:At the start of the epoch: mem (CPU python)=12575.73828125MB; mem (CPU total)=12486.828125MB
INFO:root:[   66] Training loss: 0.96111672, Validation loss: 0.96204246, Gradient norm: 0.11170036
INFO:root:At the start of the epoch: mem (CPU python)=12613.8359375MB; mem (CPU total)=12525.3125MB
INFO:root:[   67] Training loss: 0.96100529, Validation loss: 0.96233695, Gradient norm: 0.11266348
INFO:root:At the start of the epoch: mem (CPU python)=12651.9296875MB; mem (CPU total)=12563.45703125MB
INFO:root:[   68] Training loss: 0.96078699, Validation loss: 0.96260870, Gradient norm: 0.11146621
INFO:root:At the start of the epoch: mem (CPU python)=12690.6171875MB; mem (CPU total)=12602.1953125MB
INFO:root:[   69] Training loss: 0.96084848, Validation loss: 0.96182382, Gradient norm: 0.10862203
INFO:root:At the start of the epoch: mem (CPU python)=12729.51171875MB; mem (CPU total)=12641.546875MB
INFO:root:[   70] Training loss: 0.96066671, Validation loss: 0.96158533, Gradient norm: 0.10718938
INFO:root:At the start of the epoch: mem (CPU python)=12767.60546875MB; mem (CPU total)=12679.875MB
INFO:root:[   71] Training loss: 0.96063905, Validation loss: 0.96169627, Gradient norm: 0.11220471
INFO:root:At the start of the epoch: mem (CPU python)=12805.69921875MB; mem (CPU total)=12717.56640625MB
INFO:root:[   72] Training loss: 0.96037649, Validation loss: 0.96175317, Gradient norm: 0.11076746
INFO:root:At the start of the epoch: mem (CPU python)=12843.796875MB; mem (CPU total)=12755.703125MB
INFO:root:[   73] Training loss: 0.96036170, Validation loss: 0.96129394, Gradient norm: 0.11118080
INFO:root:At the start of the epoch: mem (CPU python)=12881.890625MB; mem (CPU total)=12794.11328125MB
INFO:root:[   74] Training loss: 0.96024474, Validation loss: 0.96141834, Gradient norm: 0.11053066
INFO:root:At the start of the epoch: mem (CPU python)=12919.98828125MB; mem (CPU total)=12832.50390625MB
INFO:root:[   75] Training loss: 0.96010274, Validation loss: 0.96142964, Gradient norm: 0.10827934
INFO:root:At the start of the epoch: mem (CPU python)=12958.08203125MB; mem (CPU total)=12870.3046875MB
INFO:root:[   76] Training loss: 0.95998285, Validation loss: 0.96111653, Gradient norm: 0.11267617
INFO:root:At the start of the epoch: mem (CPU python)=12996.1796875MB; mem (CPU total)=12908.4765625MB
INFO:root:[   77] Training loss: 0.95991118, Validation loss: 0.96121145, Gradient norm: 0.10796369
INFO:root:At the start of the epoch: mem (CPU python)=13034.26953125MB; mem (CPU total)=12947.08984375MB
INFO:root:[   78] Training loss: 0.95973566, Validation loss: 0.96074380, Gradient norm: 0.10679866
INFO:root:At the start of the epoch: mem (CPU python)=13072.37109375MB; mem (CPU total)=12984.51171875MB
INFO:root:[   79] Training loss: 0.95987581, Validation loss: 0.96114980, Gradient norm: 0.11740867
INFO:root:At the start of the epoch: mem (CPU python)=13110.4609375MB; mem (CPU total)=13022.90234375MB
INFO:root:[   80] Training loss: 0.95975665, Validation loss: 0.96051594, Gradient norm: 0.11178924
INFO:root:At the start of the epoch: mem (CPU python)=13148.55859375MB; mem (CPU total)=13060.72265625MB
INFO:root:[   81] Training loss: 0.95965982, Validation loss: 0.96045508, Gradient norm: 0.10797847
INFO:root:At the start of the epoch: mem (CPU python)=13186.65625MB; mem (CPU total)=13099.09765625MB
INFO:root:[   82] Training loss: 0.95938148, Validation loss: 0.96162720, Gradient norm: 0.10645317
INFO:root:At the start of the epoch: mem (CPU python)=13224.75MB; mem (CPU total)=13137.0625MB
INFO:root:[   83] Training loss: 0.95937579, Validation loss: 0.96074325, Gradient norm: 0.11174039
INFO:root:At the start of the epoch: mem (CPU python)=13262.84375MB; mem (CPU total)=13175.19921875MB
INFO:root:[   84] Training loss: 0.95931407, Validation loss: 0.96078637, Gradient norm: 0.11039030
INFO:root:At the start of the epoch: mem (CPU python)=13300.94140625MB; mem (CPU total)=13213.34375MB
INFO:root:[   85] Training loss: 0.95912956, Validation loss: 0.96064640, Gradient norm: 0.10683275
INFO:root:At the start of the epoch: mem (CPU python)=13339.0390625MB; mem (CPU total)=13251.48828125MB
INFO:root:[   86] Training loss: 0.95929133, Validation loss: 0.96088074, Gradient norm: 0.11575691
INFO:root:At the start of the epoch: mem (CPU python)=13377.1328125MB; mem (CPU total)=13290.09375MB
INFO:root:[   87] Training loss: 0.95906403, Validation loss: 0.96043459, Gradient norm: 0.11147426
INFO:root:At the start of the epoch: mem (CPU python)=13415.23046875MB; mem (CPU total)=13328.3125MB
INFO:root:[   88] Training loss: 0.95898758, Validation loss: 0.96032701, Gradient norm: 0.10903012
INFO:root:At the start of the epoch: mem (CPU python)=13453.328125MB; mem (CPU total)=13366.2421875MB
INFO:root:[   89] Training loss: 0.95886129, Validation loss: 0.95987283, Gradient norm: 0.10602663
INFO:root:At the start of the epoch: mem (CPU python)=13491.421875MB; mem (CPU total)=13404.69140625MB
INFO:root:[   90] Training loss: 0.95885705, Validation loss: 0.96027062, Gradient norm: 0.11106967
INFO:root:At the start of the epoch: mem (CPU python)=13529.515625MB; mem (CPU total)=13443.10546875MB
INFO:root:[   91] Training loss: 0.95882930, Validation loss: 0.96057457, Gradient norm: 0.11212286
INFO:root:At the start of the epoch: mem (CPU python)=13567.61328125MB; mem (CPU total)=13481.00390625MB
INFO:root:[   92] Training loss: 0.95880880, Validation loss: 0.95971688, Gradient norm: 0.11718933
INFO:root:At the start of the epoch: mem (CPU python)=13605.7109375MB; mem (CPU total)=13519.64453125MB
INFO:root:[   93] Training loss: 0.95861010, Validation loss: 0.95994067, Gradient norm: 0.10719020
INFO:root:At the start of the epoch: mem (CPU python)=13643.8046875MB; mem (CPU total)=13557.72265625MB
INFO:root:[   94] Training loss: 0.95861985, Validation loss: 0.95975892, Gradient norm: 0.10876690
INFO:root:At the start of the epoch: mem (CPU python)=13681.8984375MB; mem (CPU total)=13595.62109375MB
INFO:root:[   95] Training loss: 0.95859423, Validation loss: 0.95981993, Gradient norm: 0.11461760
INFO:root:At the start of the epoch: mem (CPU python)=13720.0MB; mem (CPU total)=13633.7578125MB
INFO:root:[   96] Training loss: 0.95867028, Validation loss: 0.96009680, Gradient norm: 0.11614627
INFO:root:At the start of the epoch: mem (CPU python)=13758.09375MB; mem (CPU total)=13671.90234375MB
INFO:root:[   97] Training loss: 0.95827916, Validation loss: 0.95949927, Gradient norm: 0.11102073
INFO:root:At the start of the epoch: mem (CPU python)=13796.1875MB; mem (CPU total)=13709.859375MB
INFO:root:[   98] Training loss: 0.95838904, Validation loss: 0.95995649, Gradient norm: 0.11238825
INFO:root:At the start of the epoch: mem (CPU python)=13834.28515625MB; mem (CPU total)=13748.25MB
INFO:root:[   99] Training loss: 0.95834672, Validation loss: 0.95999427, Gradient norm: 0.10894602
INFO:root:At the start of the epoch: mem (CPU python)=13872.37890625MB; mem (CPU total)=13786.39453125MB
INFO:root:[  100] Training loss: 0.95816445, Validation loss: 0.95953771, Gradient norm: 0.10605428
INFO:root:At the start of the epoch: mem (CPU python)=13910.47265625MB; mem (CPU total)=13824.51171875MB
INFO:root:[  101] Training loss: 0.95809943, Validation loss: 0.95966882, Gradient norm: 0.10941420
INFO:root:At the start of the epoch: mem (CPU python)=13948.5703125MB; mem (CPU total)=13862.671875MB
INFO:root:[  102] Training loss: 0.95804387, Validation loss: 0.95982889, Gradient norm: 0.10752479
INFO:root:At the start of the epoch: mem (CPU python)=13986.6640625MB; mem (CPU total)=13900.58984375MB
INFO:root:[  103] Training loss: 0.95811773, Validation loss: 0.95967878, Gradient norm: 0.11415497
INFO:root:At the start of the epoch: mem (CPU python)=14024.76171875MB; mem (CPU total)=13938.48828125MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  104] Training loss: 0.95793896, Validation loss: 0.95942518, Gradient norm: 0.10674794
INFO:root:At the start of the epoch: mem (CPU python)=14062.85546875MB; mem (CPU total)=13977.22265625MB
INFO:root:[  105] Training loss: 0.95691682, Validation loss: 0.95869148, Gradient norm: 0.10000408
INFO:root:At the start of the epoch: mem (CPU python)=14100.953125MB; mem (CPU total)=14014.91796875MB
INFO:root:[  106] Training loss: 0.95688163, Validation loss: 0.95863590, Gradient norm: 0.10507086
INFO:root:At the start of the epoch: mem (CPU python)=14139.046875MB; mem (CPU total)=14053.3046875MB
INFO:root:[  107] Training loss: 0.95660030, Validation loss: 0.95866184, Gradient norm: 0.10276941
INFO:root:At the start of the epoch: mem (CPU python)=14177.140625MB; mem (CPU total)=14091.47265625MB
INFO:root:[  108] Training loss: 0.95672943, Validation loss: 0.95857458, Gradient norm: 0.10439287
INFO:root:At the start of the epoch: mem (CPU python)=14215.2421875MB; mem (CPU total)=14129.83984375MB
INFO:root:[  109] Training loss: 0.95656811, Validation loss: 0.95832659, Gradient norm: 0.10154027
INFO:root:At the start of the epoch: mem (CPU python)=14253.3359375MB; mem (CPU total)=14168.10546875MB
INFO:root:[  110] Training loss: 0.95667665, Validation loss: 0.95830481, Gradient norm: 0.10560552
INFO:root:At the start of the epoch: mem (CPU python)=14291.4296875MB; mem (CPU total)=14207.03125MB
INFO:root:[  111] Training loss: 0.95667361, Validation loss: 0.95870671, Gradient norm: 0.10541929
INFO:root:At the start of the epoch: mem (CPU python)=14329.51953125MB; mem (CPU total)=14245.4453125MB
INFO:root:[  112] Training loss: 0.95656532, Validation loss: 0.95857174, Gradient norm: 0.11130679
INFO:root:At the start of the epoch: mem (CPU python)=14367.6171875MB; mem (CPU total)=14283.36328125MB
INFO:root:[  113] Training loss: 0.95659537, Validation loss: 0.95828440, Gradient norm: 0.10907390
INFO:root:At the start of the epoch: mem (CPU python)=14405.71484375MB; mem (CPU total)=14321.609375MB
INFO:root:[  114] Training loss: 0.95648504, Validation loss: 0.95823664, Gradient norm: 0.11035511
INFO:root:At the start of the epoch: mem (CPU python)=14443.80859375MB; mem (CPU total)=14359.21875MB
INFO:root:[  115] Training loss: 0.95631924, Validation loss: 0.95827639, Gradient norm: 0.10317559
INFO:root:At the start of the epoch: mem (CPU python)=14481.90625MB; mem (CPU total)=14397.39453125MB
INFO:root:[  116] Training loss: 0.95633167, Validation loss: 0.95808004, Gradient norm: 0.11191176
INFO:root:At the start of the epoch: mem (CPU python)=14520.0MB; mem (CPU total)=14435.24609375MB
INFO:root:[  117] Training loss: 0.95637057, Validation loss: 0.95775394, Gradient norm: 0.10730081
INFO:root:At the start of the epoch: mem (CPU python)=14558.09375MB; mem (CPU total)=14474.078125MB
INFO:root:[  118] Training loss: 0.95631735, Validation loss: 0.95787303, Gradient norm: 0.10524411
INFO:root:At the start of the epoch: mem (CPU python)=14596.19140625MB; mem (CPU total)=14512.48828125MB
INFO:root:[  119] Training loss: 0.95626362, Validation loss: 0.95780098, Gradient norm: 0.10368044
INFO:root:At the start of the epoch: mem (CPU python)=14634.28515625MB; mem (CPU total)=14550.65625MB
INFO:root:[  120] Training loss: 0.95635423, Validation loss: 0.95848745, Gradient norm: 0.11018017
INFO:root:At the start of the epoch: mem (CPU python)=14672.38671875MB; mem (CPU total)=14588.82421875MB
INFO:root:[  121] Training loss: 0.95612762, Validation loss: 0.95809420, Gradient norm: 0.11007502
INFO:root:At the start of the epoch: mem (CPU python)=14710.48046875MB; mem (CPU total)=14626.734375MB
INFO:root:[  122] Training loss: 0.95603735, Validation loss: 0.95790720, Gradient norm: 0.10758323
INFO:root:At the start of the epoch: mem (CPU python)=14748.58203125MB; mem (CPU total)=14664.87109375MB
INFO:root:[  123] Training loss: 0.95624161, Validation loss: 0.95793908, Gradient norm: 0.11365492
INFO:root:At the start of the epoch: mem (CPU python)=14786.67578125MB; mem (CPU total)=14703.15625MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  124] Training loss: 0.95598302, Validation loss: 0.95858939, Gradient norm: 0.10675406
INFO:root:At the start of the epoch: mem (CPU python)=14824.76953125MB; mem (CPU total)=14741.5859375MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  125] Training loss: 0.95568562, Validation loss: 0.95754803, Gradient norm: 0.10297217
INFO:root:At the start of the epoch: mem (CPU python)=14862.87109375MB; mem (CPU total)=14779.95703125MB
INFO:root:[  126] Training loss: 0.95518456, Validation loss: 0.95724478, Gradient norm: 0.09464118
INFO:root:At the start of the epoch: mem (CPU python)=14900.96484375MB; mem (CPU total)=14818.23828125MB
INFO:root:[  127] Training loss: 0.95510153, Validation loss: 0.95734760, Gradient norm: 0.09418217
INFO:root:At the start of the epoch: mem (CPU python)=14939.0546875MB; mem (CPU total)=14856.0234375MB
INFO:root:[  128] Training loss: 0.95510088, Validation loss: 0.95715145, Gradient norm: 0.09363844
INFO:root:At the start of the epoch: mem (CPU python)=14977.15234375MB; mem (CPU total)=14894.0546875MB
INFO:root:[  129] Training loss: 0.95503147, Validation loss: 0.95709248, Gradient norm: 0.09515296
INFO:root:At the start of the epoch: mem (CPU python)=15015.25MB; mem (CPU total)=14931.78515625MB
INFO:root:[  130] Training loss: 0.95501609, Validation loss: 0.95705707, Gradient norm: 0.09724902
INFO:root:At the start of the epoch: mem (CPU python)=15053.34375MB; mem (CPU total)=14970.27734375MB
INFO:root:[  131] Training loss: 0.95503760, Validation loss: 0.95699213, Gradient norm: 0.10255729
INFO:root:At the start of the epoch: mem (CPU python)=15091.4375MB; mem (CPU total)=15008.66015625MB
INFO:root:[  132] Training loss: 0.95491351, Validation loss: 0.95697463, Gradient norm: 0.10060108
INFO:root:At the start of the epoch: mem (CPU python)=15129.53515625MB; mem (CPU total)=15046.8359375MB
INFO:root:[  133] Training loss: 0.95486564, Validation loss: 0.95717491, Gradient norm: 0.10280028
INFO:root:At the start of the epoch: mem (CPU python)=15167.62890625MB; mem (CPU total)=15085.25MB
INFO:root:[  134] Training loss: 0.95495580, Validation loss: 0.95696336, Gradient norm: 0.10442056
INFO:root:At the start of the epoch: mem (CPU python)=15205.7265625MB; mem (CPU total)=15123.23046875MB
INFO:root:[  135] Training loss: 0.95494325, Validation loss: 0.95672941, Gradient norm: 0.10015639
INFO:root:At the start of the epoch: mem (CPU python)=15243.82421875MB; mem (CPU total)=15162.23828125MB
INFO:root:[  136] Training loss: 0.95494373, Validation loss: 0.95716281, Gradient norm: 0.10724714
INFO:root:At the start of the epoch: mem (CPU python)=15281.9140625MB; mem (CPU total)=15200.89453125MB
INFO:root:[  137] Training loss: 0.95486946, Validation loss: 0.95720610, Gradient norm: 0.10053924
INFO:root:At the start of the epoch: mem (CPU python)=15320.0078125MB; mem (CPU total)=15238.5078125MB
INFO:root:[  138] Training loss: 0.95473799, Validation loss: 0.95709628, Gradient norm: 0.10214312
INFO:root:At the start of the epoch: mem (CPU python)=15358.10546875MB; mem (CPU total)=15276.64453125MB
INFO:root:[  139] Training loss: 0.95482120, Validation loss: 0.95688203, Gradient norm: 0.10137836
INFO:root:At the start of the epoch: mem (CPU python)=15396.203125MB; mem (CPU total)=15314.5625MB
INFO:root:[  140] Training loss: 0.95475570, Validation loss: 0.95667549, Gradient norm: 0.10278748
INFO:root:At the start of the epoch: mem (CPU python)=15434.296875MB; mem (CPU total)=15352.90234375MB
INFO:root:[  141] Training loss: 0.95487034, Validation loss: 0.95705356, Gradient norm: 0.10507879
INFO:root:At the start of the epoch: mem (CPU python)=15472.390625MB; mem (CPU total)=15391.82421875MB
INFO:root:[  142] Training loss: 0.95488979, Validation loss: 0.95712796, Gradient norm: 0.10122697
INFO:root:At the start of the epoch: mem (CPU python)=15510.48828125MB; mem (CPU total)=15429.94140625MB
INFO:root:[  143] Training loss: 0.95491541, Validation loss: 0.95686074, Gradient norm: 0.10373619
INFO:root:At the start of the epoch: mem (CPU python)=15548.58203125MB; mem (CPU total)=15468.0859375MB
INFO:root:[  144] Training loss: 0.95480611, Validation loss: 0.95660173, Gradient norm: 0.10341385
INFO:root:At the start of the epoch: mem (CPU python)=15586.6796875MB; mem (CPU total)=15506.26171875MB
INFO:root:[  145] Training loss: 0.95475137, Validation loss: 0.95711167, Gradient norm: 0.10591432
INFO:root:At the start of the epoch: mem (CPU python)=15624.76953125MB; mem (CPU total)=15544.4765625MB
INFO:root:[  146] Training loss: 0.95476876, Validation loss: 0.95711751, Gradient norm: 0.10395236
INFO:root:At the start of the epoch: mem (CPU python)=15662.8671875MB; mem (CPU total)=15582.23828125MB
INFO:root:[  147] Training loss: 0.95471691, Validation loss: 0.95702704, Gradient norm: 0.10535388
INFO:root:At the start of the epoch: mem (CPU python)=15700.96484375MB; mem (CPU total)=15620.13671875MB
INFO:root:[  148] Training loss: 0.95468332, Validation loss: 0.95695958, Gradient norm: 0.10758516
INFO:root:At the start of the epoch: mem (CPU python)=15739.05859375MB; mem (CPU total)=15658.2734375MB
INFO:root:[  149] Training loss: 0.95475849, Validation loss: 0.95649525, Gradient norm: 0.10369096
INFO:root:At the start of the epoch: mem (CPU python)=15777.16015625MB; mem (CPU total)=15696.828125MB
INFO:root:[  150] Training loss: 0.95467949, Validation loss: 0.95692880, Gradient norm: 0.10762189
INFO:root:At the start of the epoch: mem (CPU python)=15815.25MB; mem (CPU total)=15734.97265625MB
INFO:root:[  151] Training loss: 0.95479175, Validation loss: 0.95652340, Gradient norm: 0.10686401
INFO:root:At the start of the epoch: mem (CPU python)=15853.34375MB; mem (CPU total)=15772.87109375MB
INFO:root:[  152] Training loss: 0.95460500, Validation loss: 0.95667382, Gradient norm: 0.10629084
INFO:root:At the start of the epoch: mem (CPU python)=15891.44140625MB; mem (CPU total)=15811.015625MB
INFO:root:[  153] Training loss: 0.95466300, Validation loss: 0.95650380, Gradient norm: 0.10410691
INFO:root:At the start of the epoch: mem (CPU python)=15929.53515625MB; mem (CPU total)=15856.796875MB
INFO:root:[  154] Training loss: 0.95469661, Validation loss: 0.95690509, Gradient norm: 0.10715154
INFO:root:At the start of the epoch: mem (CPU python)=15967.6328125MB; mem (CPU total)=15895.109375MB
INFO:root:[  155] Training loss: 0.95471930, Validation loss: 0.95691980, Gradient norm: 0.10740553
INFO:root:At the start of the epoch: mem (CPU python)=16005.7265625MB; mem (CPU total)=15932.57421875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  156] Training loss: 0.95461810, Validation loss: 0.95647214, Gradient norm: 0.10626729
INFO:root:At the start of the epoch: mem (CPU python)=16043.82421875MB; mem (CPU total)=15971.17578125MB
INFO:root:[  157] Training loss: 0.95451000, Validation loss: 0.95629054, Gradient norm: 0.10510295
INFO:root:At the start of the epoch: mem (CPU python)=16081.91796875MB; mem (CPU total)=16009.66015625MB
INFO:root:[  158] Training loss: 0.95434862, Validation loss: 0.95668118, Gradient norm: 0.10240554
INFO:root:At the start of the epoch: mem (CPU python)=16120.01171875MB; mem (CPU total)=16048.05078125MB
INFO:root:[  159] Training loss: 0.95448422, Validation loss: 0.95669157, Gradient norm: 0.10242573
INFO:root:At the start of the epoch: mem (CPU python)=16158.109375MB; mem (CPU total)=16086.1953125MB
INFO:root:[  160] Training loss: 0.95439864, Validation loss: 0.95691718, Gradient norm: 0.10296864
INFO:root:At the start of the epoch: mem (CPU python)=16196.203125MB; mem (CPU total)=16124.09375MB
INFO:root:[  161] Training loss: 0.95444239, Validation loss: 0.95694032, Gradient norm: 0.10126844
INFO:root:At the start of the epoch: mem (CPU python)=16234.296875MB; mem (CPU total)=16162.23828125MB
INFO:root:[  162] Training loss: 0.95436951, Validation loss: 0.95704214, Gradient norm: 0.10567488
INFO:root:At the start of the epoch: mem (CPU python)=16272.39453125MB; mem (CPU total)=16200.53515625MB
INFO:root:[  163] Training loss: 0.95437291, Validation loss: 0.95664134, Gradient norm: 0.10377656
INFO:root:At the start of the epoch: mem (CPU python)=16310.4921875MB; mem (CPU total)=16238.6796875MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  164] Training loss: 0.95438460, Validation loss: 0.95707329, Gradient norm: 0.10378647
INFO:root:At the start of the epoch: mem (CPU python)=16348.5859375MB; mem (CPU total)=16276.5703125MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  165] Training loss: 0.95433736, Validation loss: 0.95683712, Gradient norm: 0.10166397
INFO:root:At the start of the epoch: mem (CPU python)=16386.6796875MB; mem (CPU total)=16314.9609375MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  166] Training loss: 0.95420551, Validation loss: 0.95624477, Gradient norm: 0.10244804
INFO:root:At the start of the epoch: mem (CPU python)=16424.77734375MB; mem (CPU total)=16352.01953125MB
INFO:root:[  167] Training loss: 0.95407386, Validation loss: 0.95641141, Gradient norm: 0.09729165
INFO:root:At the start of the epoch: mem (CPU python)=16462.87109375MB; mem (CPU total)=16390.39453125MB
INFO:root:[  168] Training loss: 0.95430029, Validation loss: 0.95663303, Gradient norm: 0.10117096
INFO:root:At the start of the epoch: mem (CPU python)=16500.96484375MB; mem (CPU total)=16428.44921875MB
INFO:root:[  169] Training loss: 0.95414269, Validation loss: 0.95658783, Gradient norm: 0.10231167
INFO:root:At the start of the epoch: mem (CPU python)=16539.0625MB; mem (CPU total)=16466.58984375MB
INFO:root:[  170] Training loss: 0.95419778, Validation loss: 0.95665476, Gradient norm: 0.09993110
INFO:root:At the start of the epoch: mem (CPU python)=16577.15625MB; mem (CPU total)=16504.48828125MB
INFO:root:[  171] Training loss: 0.95421003, Validation loss: 0.95656333, Gradient norm: 0.09982144
INFO:root:At the start of the epoch: mem (CPU python)=16615.25MB; mem (CPU total)=16542.6015625MB
INFO:root:[  172] Training loss: 0.95426397, Validation loss: 0.95659513, Gradient norm: 0.10316806
INFO:root:At the start of the epoch: mem (CPU python)=16653.34375MB; mem (CPU total)=16580.60546875MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  173] Training loss: 0.95416411, Validation loss: 0.95669388, Gradient norm: 0.10384275
INFO:root:At the start of the epoch: mem (CPU python)=16691.4453125MB; mem (CPU total)=16618.7421875MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:[  174] Training loss: 0.95416935, Validation loss: 0.95657919, Gradient norm: 0.10107728
INFO:root:At the start of the epoch: mem (CPU python)=16729.5390625MB; mem (CPU total)=16657.1328125MB
INFO:root:Learning rate reduced to: [9.765625e-07]
INFO:root:[  175] Training loss: 0.95421438, Validation loss: 0.95628140, Gradient norm: 0.10009320
INFO:root:At the start of the epoch: mem (CPU python)=16767.6328125MB; mem (CPU total)=16695.03125MB
INFO:root:Learning rate reduced to: [4.8828125e-07]
INFO:root:[  176] Training loss: 0.95410661, Validation loss: 0.95610491, Gradient norm: 0.10087696
INFO:root:At the start of the epoch: mem (CPU python)=16805.73046875MB; mem (CPU total)=16732.6875MB
INFO:root:[  177] Training loss: 0.95424426, Validation loss: 0.95627283, Gradient norm: 0.10115972
INFO:root:At the start of the epoch: mem (CPU python)=16843.82421875MB; mem (CPU total)=16770.421875MB
INFO:root:[  178] Training loss: 0.95421629, Validation loss: 0.95661997, Gradient norm: 0.10225464
INFO:root:At the start of the epoch: mem (CPU python)=16881.91796875MB; mem (CPU total)=16808.5390625MB
INFO:root:[  179] Training loss: 0.95407663, Validation loss: 0.95673997, Gradient norm: 0.09954915
INFO:root:At the start of the epoch: mem (CPU python)=16920.01171875MB; mem (CPU total)=16846.9296875MB
INFO:root:[  180] Training loss: 0.95417529, Validation loss: 0.95696163, Gradient norm: 0.10196237
INFO:root:At the start of the epoch: mem (CPU python)=16958.109375MB; mem (CPU total)=16885.07421875MB
INFO:root:[  181] Training loss: 0.95412102, Validation loss: 0.95640664, Gradient norm: 0.10060717
INFO:root:At the start of the epoch: mem (CPU python)=16996.20703125MB; mem (CPU total)=16922.7265625MB
INFO:root:[  182] Training loss: 0.95430988, Validation loss: 0.95611853, Gradient norm: 0.10082364
INFO:root:At the start of the epoch: mem (CPU python)=17034.30078125MB; mem (CPU total)=16961.23828125MB
INFO:root:Learning rate reduced to: [2.44140625e-07]
INFO:root:[  183] Training loss: 0.95407448, Validation loss: 0.95679524, Gradient norm: 0.10065773
INFO:root:At the start of the epoch: mem (CPU python)=17072.3984375MB; mem (CPU total)=16999.3828125MB
INFO:root:Learning rate reduced to: [1.220703125e-07]
INFO:root:[  184] Training loss: 0.95414852, Validation loss: 0.95673650, Gradient norm: 0.10046642
INFO:root:At the start of the epoch: mem (CPU python)=17110.4921875MB; mem (CPU total)=17037.52734375MB
INFO:root:Learning rate reduced to: [6.103515625e-08]
INFO:root:[  185] Training loss: 0.95424004, Validation loss: 0.95635729, Gradient norm: 0.10070310
INFO:root:At the start of the epoch: mem (CPU python)=17148.5859375MB; mem (CPU total)=17075.671875MB
INFO:root:Learning rate reduced to: [3.0517578125e-08]
INFO:root:EP 185: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=17186.68359375MB; mem (CPU total)=17113.5625MB
INFO:root:Training the model took 10305.265s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94153
INFO:root:EnergyScoreTrain: 0.84555
INFO:root:CRPSTrain: 0.71266
INFO:root:Gaussian NLLTrain: 432.43654
INFO:root:CoverageTrain: 0.20125
INFO:root:IntervalWidthTrain: 0.41259
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94408
INFO:root:EnergyScoreValidation: 0.84851
INFO:root:CRPSValidation: 0.71534
INFO:root:Gaussian NLLValidation: 433.0139
INFO:root:CoverageValidation: 0.19906
INFO:root:IntervalWidthValidation: 0.41088
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94358
INFO:root:EnergyScoreTest: 0.84787
INFO:root:CRPSTest: 0.71494
INFO:root:Gaussian NLLTest: 435.50593
INFO:root:CoverageTest: 0.19936
INFO:root:IntervalWidthTest: 0.41107
INFO:root:After validation: mem (CPU python)=17229.8046875MB; mem (CPU total)=17158.02734375MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=17229.8046875MB; mem (CPU total)=17158.02734375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=17229.8046875MB; mem (CPU total)=17158.02734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=17229.8359375MB; mem (CPU total)=17158.02734375MB
INFO:root:[    1] Training loss: 1.01053224, Validation loss: 0.99786991, Gradient norm: 0.03105646
INFO:root:At the start of the epoch: mem (CPU python)=17267.65625MB; mem (CPU total)=17195.90234375MB
INFO:root:[    2] Training loss: 0.99212109, Validation loss: 0.98941446, Gradient norm: 0.05086574
INFO:root:At the start of the epoch: mem (CPU python)=17305.76953125MB; mem (CPU total)=17233.03515625MB
INFO:root:[    3] Training loss: 0.98681047, Validation loss: 0.98690038, Gradient norm: 0.05419959
INFO:root:At the start of the epoch: mem (CPU python)=17343.87890625MB; mem (CPU total)=17271.58984375MB
INFO:root:[    4] Training loss: 0.98458795, Validation loss: 0.98498798, Gradient norm: 0.05705690
INFO:root:At the start of the epoch: mem (CPU python)=17381.9765625MB; mem (CPU total)=17309.484375MB
INFO:root:[    5] Training loss: 0.98313202, Validation loss: 0.98359735, Gradient norm: 0.06050735
INFO:root:At the start of the epoch: mem (CPU python)=17420.08984375MB; mem (CPU total)=17347.31640625MB
INFO:root:[    6] Training loss: 0.98191498, Validation loss: 0.98217432, Gradient norm: 0.06302787
INFO:root:At the start of the epoch: mem (CPU python)=17458.19921875MB; mem (CPU total)=17385.50390625MB
INFO:root:[    7] Training loss: 0.98099191, Validation loss: 0.98153852, Gradient norm: 0.06355201
INFO:root:At the start of the epoch: mem (CPU python)=17496.30859375MB; mem (CPU total)=17423.6640625MB
INFO:root:[    8] Training loss: 0.98011376, Validation loss: 0.98116061, Gradient norm: 0.06552627
INFO:root:At the start of the epoch: mem (CPU python)=17534.40234375MB; mem (CPU total)=17461.9765625MB
INFO:root:[    9] Training loss: 0.97942149, Validation loss: 0.97976516, Gradient norm: 0.06753536
INFO:root:At the start of the epoch: mem (CPU python)=17572.5MB; mem (CPU total)=17500.09765625MB
INFO:root:[   10] Training loss: 0.97868202, Validation loss: 0.97959619, Gradient norm: 0.06630076
INFO:root:At the start of the epoch: mem (CPU python)=17610.59375MB; mem (CPU total)=17537.859375MB
INFO:root:[   11] Training loss: 0.97828328, Validation loss: 0.97943078, Gradient norm: 0.07230662
INFO:root:At the start of the epoch: mem (CPU python)=17648.69140625MB; mem (CPU total)=17576.71484375MB
INFO:root:[   12] Training loss: 0.97761464, Validation loss: 0.97878566, Gradient norm: 0.07895353
INFO:root:At the start of the epoch: mem (CPU python)=17686.78515625MB; mem (CPU total)=17615.18359375MB
INFO:root:[   13] Training loss: 0.97687341, Validation loss: 0.97784587, Gradient norm: 0.07764960
INFO:root:At the start of the epoch: mem (CPU python)=17724.8828125MB; mem (CPU total)=17653.28125MB
INFO:root:[   14] Training loss: 0.97637529, Validation loss: 0.97734911, Gradient norm: 0.08070143
INFO:root:At the start of the epoch: mem (CPU python)=17762.9765625MB; mem (CPU total)=17690.4609375MB
INFO:root:[   15] Training loss: 0.97595071, Validation loss: 0.97671069, Gradient norm: 0.08699929
INFO:root:At the start of the epoch: mem (CPU python)=17801.0703125MB; mem (CPU total)=17728.66796875MB
INFO:root:[   16] Training loss: 0.97531791, Validation loss: 0.97605851, Gradient norm: 0.08864984
INFO:root:At the start of the epoch: mem (CPU python)=17839.171875MB; mem (CPU total)=17766.8046875MB
INFO:root:[   17] Training loss: 0.97474169, Validation loss: 0.97557002, Gradient norm: 0.09276147
INFO:root:At the start of the epoch: mem (CPU python)=17877.265625MB; mem (CPU total)=17804.96875MB
INFO:root:[   18] Training loss: 0.97412694, Validation loss: 0.97487155, Gradient norm: 0.09446595
INFO:root:At the start of the epoch: mem (CPU python)=17915.359375MB; mem (CPU total)=17843.25MB
INFO:root:[   19] Training loss: 0.97354555, Validation loss: 0.97455566, Gradient norm: 0.09701360
INFO:root:At the start of the epoch: mem (CPU python)=17953.45703125MB; mem (CPU total)=17881.31640625MB
INFO:root:[   20] Training loss: 0.97283017, Validation loss: 0.97324821, Gradient norm: 0.09682608
INFO:root:At the start of the epoch: mem (CPU python)=17991.55078125MB; mem (CPU total)=17919.99609375MB
INFO:root:[   21] Training loss: 0.97240908, Validation loss: 0.97310889, Gradient norm: 0.09798298
INFO:root:At the start of the epoch: mem (CPU python)=18029.6484375MB; mem (CPU total)=17957.69140625MB
INFO:root:[   22] Training loss: 0.97194976, Validation loss: 0.97322754, Gradient norm: 0.10060370
INFO:root:At the start of the epoch: mem (CPU python)=18067.7421875MB; mem (CPU total)=17995.8046875MB
INFO:root:[   23] Training loss: 0.97170178, Validation loss: 0.97281329, Gradient norm: 0.10328566
INFO:root:At the start of the epoch: mem (CPU python)=18105.83984375MB; mem (CPU total)=18034.2734375MB
INFO:root:[   24] Training loss: 0.97128929, Validation loss: 0.97178918, Gradient norm: 0.10207210
INFO:root:At the start of the epoch: mem (CPU python)=18143.93359375MB; mem (CPU total)=18072.21484375MB
INFO:root:[   25] Training loss: 0.97080871, Validation loss: 0.97106082, Gradient norm: 0.10749968
INFO:root:At the start of the epoch: mem (CPU python)=18182.02734375MB; mem (CPU total)=18109.796875MB
INFO:root:[   26] Training loss: 0.97045572, Validation loss: 0.97081107, Gradient norm: 0.10456703
INFO:root:At the start of the epoch: mem (CPU python)=18220.125MB; mem (CPU total)=18147.890625MB
INFO:root:[   27] Training loss: 0.97004644, Validation loss: 0.97076555, Gradient norm: 0.10560741
INFO:root:At the start of the epoch: mem (CPU python)=18258.21875MB; mem (CPU total)=18186.19140625MB
INFO:root:[   28] Training loss: 0.96979996, Validation loss: 0.97119793, Gradient norm: 0.11247065
INFO:root:At the start of the epoch: mem (CPU python)=18296.3125MB; mem (CPU total)=18224.82421875MB
INFO:root:[   29] Training loss: 0.96955258, Validation loss: 0.97059112, Gradient norm: 0.11393651
INFO:root:At the start of the epoch: mem (CPU python)=18334.41015625MB; mem (CPU total)=18263.06640625MB
INFO:root:[   30] Training loss: 0.96915724, Validation loss: 0.97044584, Gradient norm: 0.11160199
INFO:root:At the start of the epoch: mem (CPU python)=18372.5078125MB; mem (CPU total)=18300.58984375MB
INFO:root:[   31] Training loss: 0.96884965, Validation loss: 0.96969779, Gradient norm: 0.10711086
INFO:root:At the start of the epoch: mem (CPU python)=18410.6015625MB; mem (CPU total)=18338.87890625MB
INFO:root:[   32] Training loss: 0.96860333, Validation loss: 0.96980210, Gradient norm: 0.11338250
INFO:root:At the start of the epoch: mem (CPU python)=18448.6953125MB; mem (CPU total)=18377.26953125MB
INFO:root:[   33] Training loss: 0.96839086, Validation loss: 0.96919129, Gradient norm: 0.11078076
INFO:root:At the start of the epoch: mem (CPU python)=18486.796875MB; mem (CPU total)=18415.83984375MB
INFO:root:[   34] Training loss: 0.96813613, Validation loss: 0.96846658, Gradient norm: 0.11504655
INFO:root:At the start of the epoch: mem (CPU python)=18524.890625MB; mem (CPU total)=18454.35546875MB
INFO:root:[   35] Training loss: 0.96776219, Validation loss: 0.96857034, Gradient norm: 0.11015918
INFO:root:At the start of the epoch: mem (CPU python)=18562.98046875MB; mem (CPU total)=18492.5MB
INFO:root:[   36] Training loss: 0.96767346, Validation loss: 0.96868761, Gradient norm: 0.11340537
INFO:root:At the start of the epoch: mem (CPU python)=18601.078125MB; mem (CPU total)=18530.859375MB
INFO:root:[   37] Training loss: 0.96726913, Validation loss: 0.96815140, Gradient norm: 0.10565484
INFO:root:At the start of the epoch: mem (CPU python)=18639.17578125MB; mem (CPU total)=18568.58203125MB
INFO:root:[   38] Training loss: 0.96708227, Validation loss: 0.96816549, Gradient norm: 0.11813543
INFO:root:At the start of the epoch: mem (CPU python)=18677.265625MB; mem (CPU total)=18606.6953125MB
INFO:root:[   39] Training loss: 0.96679681, Validation loss: 0.96764643, Gradient norm: 0.11177893
INFO:root:At the start of the epoch: mem (CPU python)=18715.35546875MB; mem (CPU total)=18644.9765625MB
INFO:root:[   40] Training loss: 0.96655761, Validation loss: 0.96739770, Gradient norm: 0.10719697
INFO:root:At the start of the epoch: mem (CPU python)=18753.44921875MB; mem (CPU total)=18682.99609375MB
INFO:root:[   41] Training loss: 0.96643916, Validation loss: 0.96691135, Gradient norm: 0.11742799
INFO:root:At the start of the epoch: mem (CPU python)=18791.54296875MB; mem (CPU total)=18720.6015625MB
INFO:root:[   42] Training loss: 0.96614141, Validation loss: 0.96691744, Gradient norm: 0.11583763
INFO:root:At the start of the epoch: mem (CPU python)=18829.63671875MB; mem (CPU total)=18758.9921875MB
INFO:root:[   43] Training loss: 0.96604120, Validation loss: 0.96681046, Gradient norm: 0.11481727
INFO:root:At the start of the epoch: mem (CPU python)=18867.73828125MB; mem (CPU total)=18797.125MB
INFO:root:[   44] Training loss: 0.96577215, Validation loss: 0.96647026, Gradient norm: 0.10945048
INFO:root:At the start of the epoch: mem (CPU python)=18905.83203125MB; mem (CPU total)=18835.50390625MB
INFO:root:[   45] Training loss: 0.96562855, Validation loss: 0.96659669, Gradient norm: 0.11510509
INFO:root:At the start of the epoch: mem (CPU python)=18943.921875MB; mem (CPU total)=18873.671875MB
INFO:root:[   46] Training loss: 0.96535680, Validation loss: 0.96658769, Gradient norm: 0.11645497
INFO:root:At the start of the epoch: mem (CPU python)=18982.015625MB; mem (CPU total)=18911.5859375MB
INFO:root:[   47] Training loss: 0.96512468, Validation loss: 0.96603285, Gradient norm: 0.11525746
INFO:root:At the start of the epoch: mem (CPU python)=19020.1171875MB; mem (CPU total)=18949.94140625MB
INFO:root:[   48] Training loss: 0.96516143, Validation loss: 0.96623724, Gradient norm: 0.12270928
INFO:root:At the start of the epoch: mem (CPU python)=19058.2109375MB; mem (CPU total)=18987.76953125MB
INFO:root:[   49] Training loss: 0.96478741, Validation loss: 0.96568231, Gradient norm: 0.11303396
INFO:root:At the start of the epoch: mem (CPU python)=19096.3046875MB; mem (CPU total)=19025.984375MB
INFO:root:[   50] Training loss: 0.96448783, Validation loss: 0.96615923, Gradient norm: 0.11232276
INFO:root:At the start of the epoch: mem (CPU python)=19134.4140625MB; mem (CPU total)=19064.42578125MB
INFO:root:[   51] Training loss: 0.96462012, Validation loss: 0.96645616, Gradient norm: 0.11439974
INFO:root:At the start of the epoch: mem (CPU python)=19172.5078125MB; mem (CPU total)=19102.3671875MB
INFO:root:[   52] Training loss: 0.96423547, Validation loss: 0.96515773, Gradient norm: 0.11321168
INFO:root:At the start of the epoch: mem (CPU python)=19210.60546875MB; mem (CPU total)=19140.67578125MB
INFO:root:[   53] Training loss: 0.96425857, Validation loss: 0.96608721, Gradient norm: 0.11582099
INFO:root:At the start of the epoch: mem (CPU python)=19248.69921875MB; mem (CPU total)=19179.08984375MB
INFO:root:[   54] Training loss: 0.96398812, Validation loss: 0.96550845, Gradient norm: 0.11073890
INFO:root:At the start of the epoch: mem (CPU python)=19286.796875MB; mem (CPU total)=19216.97265625MB
INFO:root:[   55] Training loss: 0.96396681, Validation loss: 0.96549726, Gradient norm: 0.11812297
INFO:root:At the start of the epoch: mem (CPU python)=19324.890625MB; mem (CPU total)=19255.109375MB
INFO:root:[   56] Training loss: 0.96377586, Validation loss: 0.96463948, Gradient norm: 0.11910819
INFO:root:At the start of the epoch: mem (CPU python)=19362.98828125MB; mem (CPU total)=19293.3203125MB
INFO:root:[   57] Training loss: 0.96354152, Validation loss: 0.96477940, Gradient norm: 0.11139348
INFO:root:At the start of the epoch: mem (CPU python)=19401.08203125MB; mem (CPU total)=19331.45703125MB
INFO:root:[   58] Training loss: 0.96331481, Validation loss: 0.96480456, Gradient norm: 0.10784018
INFO:root:At the start of the epoch: mem (CPU python)=19439.17578125MB; mem (CPU total)=19369.65625MB
INFO:root:[   59] Training loss: 0.96322798, Validation loss: 0.96432112, Gradient norm: 0.11526286
INFO:root:At the start of the epoch: mem (CPU python)=19477.2734375MB; mem (CPU total)=19408.16015625MB
INFO:root:[   60] Training loss: 0.96307689, Validation loss: 0.96405828, Gradient norm: 0.11688426
INFO:root:At the start of the epoch: mem (CPU python)=19515.37109375MB; mem (CPU total)=19446.31640625MB
INFO:root:[   61] Training loss: 0.96309417, Validation loss: 0.96455024, Gradient norm: 0.11734203
INFO:root:At the start of the epoch: mem (CPU python)=19553.4609375MB; mem (CPU total)=19484.0234375MB
INFO:root:[   62] Training loss: 0.96297129, Validation loss: 0.96390739, Gradient norm: 0.11781124
INFO:root:At the start of the epoch: mem (CPU python)=19591.55859375MB; mem (CPU total)=19522.5MB
INFO:root:[   63] Training loss: 0.96291216, Validation loss: 0.96352919, Gradient norm: 0.12232788
INFO:root:At the start of the epoch: mem (CPU python)=19629.65234375MB; mem (CPU total)=19561.07421875MB
INFO:root:[   64] Training loss: 0.96265863, Validation loss: 0.96440802, Gradient norm: 0.11271244
INFO:root:At the start of the epoch: mem (CPU python)=19667.75MB; mem (CPU total)=19599.44921875MB
INFO:root:[   65] Training loss: 0.96256045, Validation loss: 0.96375642, Gradient norm: 0.11545341
INFO:root:At the start of the epoch: mem (CPU python)=19705.84375MB; mem (CPU total)=19637.6171875MB
INFO:root:[   66] Training loss: 0.96259373, Validation loss: 0.96406752, Gradient norm: 0.11723336
INFO:root:At the start of the epoch: mem (CPU python)=19743.9375MB; mem (CPU total)=19674.42578125MB
INFO:root:[   67] Training loss: 0.96235648, Validation loss: 0.96401156, Gradient norm: 0.11991491
INFO:root:At the start of the epoch: mem (CPU python)=19782.03515625MB; mem (CPU total)=19712.55078125MB
INFO:root:[   68] Training loss: 0.96229202, Validation loss: 0.96344617, Gradient norm: 0.12067446
INFO:root:At the start of the epoch: mem (CPU python)=19820.1328125MB; mem (CPU total)=19750.93359375MB
INFO:root:[   69] Training loss: 0.96220672, Validation loss: 0.96395132, Gradient norm: 0.11343926
INFO:root:At the start of the epoch: mem (CPU python)=19858.22265625MB; mem (CPU total)=19789.33984375MB
INFO:root:[   70] Training loss: 0.96215813, Validation loss: 0.96358301, Gradient norm: 0.12000135
INFO:root:At the start of the epoch: mem (CPU python)=19896.3203125MB; mem (CPU total)=19827.27734375MB
INFO:root:[   71] Training loss: 0.96199150, Validation loss: 0.96307804, Gradient norm: 0.11757439
INFO:root:At the start of the epoch: mem (CPU python)=19934.41796875MB; mem (CPU total)=19865.578125MB
INFO:root:[   72] Training loss: 0.96186406, Validation loss: 0.96336085, Gradient norm: 0.12176281
INFO:root:At the start of the epoch: mem (CPU python)=19972.51171875MB; mem (CPU total)=19903.9921875MB
INFO:root:[   73] Training loss: 0.96159797, Validation loss: 0.96354676, Gradient norm: 0.11789523
INFO:root:At the start of the epoch: mem (CPU python)=20010.609375MB; mem (CPU total)=19942.24609375MB
INFO:root:[   74] Training loss: 0.96164953, Validation loss: 0.96375197, Gradient norm: 0.12035005
INFO:root:At the start of the epoch: mem (CPU python)=20048.703125MB; mem (CPU total)=19980.0546875MB
INFO:root:[   75] Training loss: 0.96142645, Validation loss: 0.96233389, Gradient norm: 0.11704547
INFO:root:At the start of the epoch: mem (CPU python)=20086.796875MB; mem (CPU total)=20018.3359375MB
INFO:root:[   76] Training loss: 0.96136033, Validation loss: 0.96246944, Gradient norm: 0.11826609
INFO:root:At the start of the epoch: mem (CPU python)=20124.890625MB; mem (CPU total)=20056.5MB
INFO:root:[   77] Training loss: 0.96134495, Validation loss: 0.96280326, Gradient norm: 0.11962805
INFO:root:At the start of the epoch: mem (CPU python)=20162.98828125MB; mem (CPU total)=20094.65625MB
INFO:root:[   78] Training loss: 0.96104317, Validation loss: 0.96288246, Gradient norm: 0.11965003
INFO:root:At the start of the epoch: mem (CPU python)=20201.08203125MB; mem (CPU total)=20132.578125MB
INFO:root:[   79] Training loss: 0.96107033, Validation loss: 0.96253897, Gradient norm: 0.11631091
INFO:root:At the start of the epoch: mem (CPU python)=20239.1796875MB; mem (CPU total)=20170.9765625MB
INFO:root:[   80] Training loss: 0.96096745, Validation loss: 0.96194662, Gradient norm: 0.12213467
INFO:root:At the start of the epoch: mem (CPU python)=20277.27734375MB; mem (CPU total)=20208.71875MB
INFO:root:[   81] Training loss: 0.96081496, Validation loss: 0.96158396, Gradient norm: 0.11902948
INFO:root:At the start of the epoch: mem (CPU python)=20315.37109375MB; mem (CPU total)=20247.3203125MB
INFO:root:[   82] Training loss: 0.96075249, Validation loss: 0.96202387, Gradient norm: 0.12159606
INFO:root:At the start of the epoch: mem (CPU python)=20353.46484375MB; mem (CPU total)=20285.51953125MB
INFO:root:[   83] Training loss: 0.96071302, Validation loss: 0.96181585, Gradient norm: 0.12418954
INFO:root:At the start of the epoch: mem (CPU python)=20391.55859375MB; mem (CPU total)=20323.6875MB
INFO:root:[   84] Training loss: 0.96064038, Validation loss: 0.96183170, Gradient norm: 0.11768463
INFO:root:At the start of the epoch: mem (CPU python)=20429.65625MB; mem (CPU total)=20361.85546875MB
INFO:root:[   85] Training loss: 0.96056243, Validation loss: 0.96172557, Gradient norm: 0.12010382
INFO:root:At the start of the epoch: mem (CPU python)=20467.75MB; mem (CPU total)=20400.140625MB
INFO:root:[   86] Training loss: 0.96022217, Validation loss: 0.96133767, Gradient norm: 0.12384835
INFO:root:At the start of the epoch: mem (CPU python)=20505.84765625MB; mem (CPU total)=20438.39453125MB
INFO:root:[   87] Training loss: 0.96037084, Validation loss: 0.96137647, Gradient norm: 0.12295074
INFO:root:At the start of the epoch: mem (CPU python)=20543.94140625MB; mem (CPU total)=20476.8359375MB
INFO:root:[   88] Training loss: 0.96011921, Validation loss: 0.96074288, Gradient norm: 0.11815017
INFO:root:At the start of the epoch: mem (CPU python)=20582.0390625MB; mem (CPU total)=20514.76953125MB
INFO:root:[   89] Training loss: 0.96004795, Validation loss: 0.96186123, Gradient norm: 0.11966049
INFO:root:At the start of the epoch: mem (CPU python)=20620.1328125MB; mem (CPU total)=20552.9375MB
INFO:root:[   90] Training loss: 0.95995556, Validation loss: 0.96160025, Gradient norm: 0.12558031
INFO:root:At the start of the epoch: mem (CPU python)=20658.23046875MB; mem (CPU total)=20591.32421875MB
INFO:root:[   91] Training loss: 0.96000028, Validation loss: 0.96055197, Gradient norm: 0.12548218
INFO:root:At the start of the epoch: mem (CPU python)=20696.32421875MB; mem (CPU total)=20629.54296875MB
INFO:root:[   92] Training loss: 0.95972916, Validation loss: 0.96090597, Gradient norm: 0.12018467
INFO:root:At the start of the epoch: mem (CPU python)=20734.41796875MB; mem (CPU total)=20667.6875MB
INFO:root:[   93] Training loss: 0.95969984, Validation loss: 0.96139104, Gradient norm: 0.12157710
INFO:root:At the start of the epoch: mem (CPU python)=20772.51171875MB; mem (CPU total)=20706.03125MB
INFO:root:[   94] Training loss: 0.95957027, Validation loss: 0.96099601, Gradient norm: 0.12558560
INFO:root:At the start of the epoch: mem (CPU python)=20810.609375MB; mem (CPU total)=20743.8046875MB
INFO:root:[   95] Training loss: 0.95957291, Validation loss: 0.96094394, Gradient norm: 0.12364037
INFO:root:At the start of the epoch: mem (CPU python)=20848.703125MB; mem (CPU total)=20781.91796875MB
INFO:root:[   96] Training loss: 0.95938081, Validation loss: 0.96064322, Gradient norm: 0.12058286
INFO:root:At the start of the epoch: mem (CPU python)=20886.80078125MB; mem (CPU total)=20820.20703125MB
INFO:root:[   97] Training loss: 0.95932809, Validation loss: 0.96030503, Gradient norm: 0.11906825
INFO:root:At the start of the epoch: mem (CPU python)=20924.8984375MB; mem (CPU total)=20858.2578125MB
INFO:root:[   98] Training loss: 0.95917459, Validation loss: 0.95995367, Gradient norm: 0.11966714
INFO:root:At the start of the epoch: mem (CPU python)=20962.9921875MB; mem (CPU total)=20896.51171875MB
INFO:root:[   99] Training loss: 0.95916255, Validation loss: 0.96046492, Gradient norm: 0.12302767
INFO:root:At the start of the epoch: mem (CPU python)=21001.0859375MB; mem (CPU total)=20934.90234375MB
INFO:root:[  100] Training loss: 0.95900735, Validation loss: 0.95991038, Gradient norm: 0.12288348
INFO:root:At the start of the epoch: mem (CPU python)=21039.1796875MB; mem (CPU total)=20973.125MB
INFO:root:[  101] Training loss: 0.95904584, Validation loss: 0.96043311, Gradient norm: 0.12698139
INFO:root:At the start of the epoch: mem (CPU python)=21077.27734375MB; mem (CPU total)=21011.76171875MB
INFO:root:[  102] Training loss: 0.95869522, Validation loss: 0.96014858, Gradient norm: 0.12188713
INFO:root:At the start of the epoch: mem (CPU python)=21115.37109375MB; mem (CPU total)=21049.66015625MB
INFO:root:[  103] Training loss: 0.95875954, Validation loss: 0.96043107, Gradient norm: 0.12253495
INFO:root:At the start of the epoch: mem (CPU python)=21153.46484375MB; mem (CPU total)=21088.09765625MB
INFO:root:[  104] Training loss: 0.95876682, Validation loss: 0.95961411, Gradient norm: 0.12600146
INFO:root:At the start of the epoch: mem (CPU python)=21191.56640625MB; mem (CPU total)=21126.31640625MB
INFO:root:[  105] Training loss: 0.95860344, Validation loss: 0.95996972, Gradient norm: 0.12850565
INFO:root:At the start of the epoch: mem (CPU python)=21229.65625MB; mem (CPU total)=21164.74609375MB
INFO:root:[  106] Training loss: 0.95866924, Validation loss: 0.95956944, Gradient norm: 0.12824624
INFO:root:At the start of the epoch: mem (CPU python)=21267.75390625MB; mem (CPU total)=21202.23828125MB
INFO:root:[  107] Training loss: 0.95854082, Validation loss: 0.95962245, Gradient norm: 0.12803779
INFO:root:At the start of the epoch: mem (CPU python)=21305.8515625MB; mem (CPU total)=21240.62890625MB
INFO:root:[  108] Training loss: 0.95832938, Validation loss: 0.95974720, Gradient norm: 0.12589894
INFO:root:At the start of the epoch: mem (CPU python)=21343.9453125MB; mem (CPU total)=21278.7734375MB
INFO:root:[  109] Training loss: 0.95833252, Validation loss: 0.95984633, Gradient norm: 0.13093677
INFO:root:At the start of the epoch: mem (CPU python)=21382.0390625MB; mem (CPU total)=21316.88671875MB
INFO:root:[  110] Training loss: 0.95829131, Validation loss: 0.95966744, Gradient norm: 0.12119941
INFO:root:At the start of the epoch: mem (CPU python)=21420.1328125MB; mem (CPU total)=21355.02734375MB
INFO:root:[  111] Training loss: 0.95803679, Validation loss: 0.95979696, Gradient norm: 0.12483908
INFO:root:At the start of the epoch: mem (CPU python)=21458.23046875MB; mem (CPU total)=21393.078125MB
INFO:root:[  112] Training loss: 0.95813708, Validation loss: 0.95983739, Gradient norm: 0.12894713
INFO:root:At the start of the epoch: mem (CPU python)=21496.32421875MB; mem (CPU total)=21431.22265625MB
INFO:root:Learning rate reduced to: [0.0005]
INFO:root:[  113] Training loss: 0.95790598, Validation loss: 0.95956429, Gradient norm: 0.12861341
INFO:root:At the start of the epoch: mem (CPU python)=21534.421875MB; mem (CPU total)=21469.12890625MB
INFO:root:[  114] Training loss: 0.95700857, Validation loss: 0.95847616, Gradient norm: 0.11574968
INFO:root:At the start of the epoch: mem (CPU python)=21572.515625MB; mem (CPU total)=21507.2890625MB
INFO:root:[  115] Training loss: 0.95687497, Validation loss: 0.95857709, Gradient norm: 0.11747690
INFO:root:At the start of the epoch: mem (CPU python)=21610.61328125MB; mem (CPU total)=21545.671875MB
INFO:root:[  116] Training loss: 0.95663671, Validation loss: 0.95872820, Gradient norm: 0.11763478
INFO:root:At the start of the epoch: mem (CPU python)=21648.70703125MB; mem (CPU total)=21583.84375MB
INFO:root:[  117] Training loss: 0.95674088, Validation loss: 0.95855056, Gradient norm: 0.12276041
INFO:root:At the start of the epoch: mem (CPU python)=21686.80078125MB; mem (CPU total)=21622.41015625MB
INFO:root:[  118] Training loss: 0.95666002, Validation loss: 0.95816875, Gradient norm: 0.11855959
INFO:root:At the start of the epoch: mem (CPU python)=21724.8984375MB; mem (CPU total)=21660.828125MB
INFO:root:[  119] Training loss: 0.95652735, Validation loss: 0.95825846, Gradient norm: 0.12345227
INFO:root:At the start of the epoch: mem (CPU python)=21762.9921875MB; mem (CPU total)=21699.0078125MB
INFO:root:[  120] Training loss: 0.95670083, Validation loss: 0.95798869, Gradient norm: 0.12918084
INFO:root:At the start of the epoch: mem (CPU python)=21801.08984375MB; mem (CPU total)=21737.0234375MB
INFO:root:[  121] Training loss: 0.95661241, Validation loss: 0.95835252, Gradient norm: 0.12782731
INFO:root:At the start of the epoch: mem (CPU python)=21839.18359375MB; mem (CPU total)=21775.4140625MB
INFO:root:[  122] Training loss: 0.95639758, Validation loss: 0.95821454, Gradient norm: 0.12603071
INFO:root:At the start of the epoch: mem (CPU python)=21877.27734375MB; mem (CPU total)=21813.265625MB
INFO:root:[  123] Training loss: 0.95638718, Validation loss: 0.95853444, Gradient norm: 0.12206450
INFO:root:At the start of the epoch: mem (CPU python)=21915.375MB; mem (CPU total)=21851.38671875MB
INFO:root:[  124] Training loss: 0.95641197, Validation loss: 0.95857522, Gradient norm: 0.13076205
INFO:root:At the start of the epoch: mem (CPU python)=21953.47265625MB; mem (CPU total)=21889.77734375MB
INFO:root:[  125] Training loss: 0.95626538, Validation loss: 0.95814020, Gradient norm: 0.12527702
INFO:root:At the start of the epoch: mem (CPU python)=21991.56640625MB; mem (CPU total)=21927.8203125MB
INFO:root:[  126] Training loss: 0.95625828, Validation loss: 0.95758530, Gradient norm: 0.12373031
INFO:root:At the start of the epoch: mem (CPU python)=22029.66015625MB; mem (CPU total)=21966.14453125MB
INFO:root:[  127] Training loss: 0.95637473, Validation loss: 0.95838573, Gradient norm: 0.12731726
INFO:root:At the start of the epoch: mem (CPU python)=22067.75390625MB; mem (CPU total)=22004.453125MB
INFO:root:[  128] Training loss: 0.95622992, Validation loss: 0.95740643, Gradient norm: 0.12730062
INFO:root:At the start of the epoch: mem (CPU python)=22105.86328125MB; mem (CPU total)=22042.73828125MB
INFO:root:[  129] Training loss: 0.95625194, Validation loss: 0.95788043, Gradient norm: 0.12885685
INFO:root:At the start of the epoch: mem (CPU python)=22143.953125MB; mem (CPU total)=22080.515625MB
INFO:root:[  130] Training loss: 0.95614190, Validation loss: 0.95776847, Gradient norm: 0.12806390
INFO:root:At the start of the epoch: mem (CPU python)=22182.05078125MB; mem (CPU total)=22118.7265625MB
INFO:root:[  131] Training loss: 0.95618280, Validation loss: 0.95747943, Gradient norm: 0.12433888
INFO:root:At the start of the epoch: mem (CPU python)=22220.1484375MB; mem (CPU total)=22156.76953125MB
INFO:root:[  132] Training loss: 0.95603774, Validation loss: 0.95798890, Gradient norm: 0.13409988
INFO:root:At the start of the epoch: mem (CPU python)=22258.2421875MB; mem (CPU total)=22194.9140625MB
INFO:root:[  133] Training loss: 0.95612050, Validation loss: 0.95758049, Gradient norm: 0.12691830
INFO:root:At the start of the epoch: mem (CPU python)=22296.3359375MB; mem (CPU total)=22233.2421875MB
INFO:root:[  134] Training loss: 0.95597061, Validation loss: 0.95782586, Gradient norm: 0.13050308
INFO:root:At the start of the epoch: mem (CPU python)=22334.4296875MB; mem (CPU total)=22271.140625MB
INFO:root:Learning rate reduced to: [0.00025]
INFO:root:[  135] Training loss: 0.95607576, Validation loss: 0.95779092, Gradient norm: 0.12512299
INFO:root:At the start of the epoch: mem (CPU python)=22372.52734375MB; mem (CPU total)=22309.0390625MB
INFO:root:Learning rate reduced to: [0.000125]
INFO:root:[  136] Training loss: 0.95539356, Validation loss: 0.95699358, Gradient norm: 0.11715379
INFO:root:At the start of the epoch: mem (CPU python)=22410.625MB; mem (CPU total)=22347.5234375MB
INFO:root:[  137] Training loss: 0.95497543, Validation loss: 0.95727433, Gradient norm: 0.11331032
INFO:root:At the start of the epoch: mem (CPU python)=22448.71484375MB; mem (CPU total)=22385.9453125MB
INFO:root:[  138] Training loss: 0.95485410, Validation loss: 0.95720987, Gradient norm: 0.11207638
INFO:root:At the start of the epoch: mem (CPU python)=22486.8125MB; mem (CPU total)=22424.08984375MB
INFO:root:[  139] Training loss: 0.95488682, Validation loss: 0.95683909, Gradient norm: 0.11568086
INFO:root:At the start of the epoch: mem (CPU python)=22524.91015625MB; mem (CPU total)=22462.06640625MB
INFO:root:[  140] Training loss: 0.95480738, Validation loss: 0.95671668, Gradient norm: 0.11488678
INFO:root:At the start of the epoch: mem (CPU python)=22563.00390625MB; mem (CPU total)=22500.875MB
INFO:root:[  141] Training loss: 0.95494705, Validation loss: 0.95694153, Gradient norm: 0.11802446
INFO:root:At the start of the epoch: mem (CPU python)=22601.1015625MB; mem (CPU total)=22539.04296875MB
INFO:root:[  142] Training loss: 0.95483031, Validation loss: 0.95713726, Gradient norm: 0.12002662
INFO:root:At the start of the epoch: mem (CPU python)=22639.1953125MB; mem (CPU total)=22577.1875MB
INFO:root:[  143] Training loss: 0.95479122, Validation loss: 0.95688207, Gradient norm: 0.11776325
INFO:root:At the start of the epoch: mem (CPU python)=22677.2890625MB; mem (CPU total)=22615.33203125MB
INFO:root:[  144] Training loss: 0.95485493, Validation loss: 0.95702587, Gradient norm: 0.11972697
INFO:root:At the start of the epoch: mem (CPU python)=22715.3828125MB; mem (CPU total)=22653.23046875MB
INFO:root:[  145] Training loss: 0.95473445, Validation loss: 0.95672404, Gradient norm: 0.11406119
INFO:root:At the start of the epoch: mem (CPU python)=22753.48046875MB; mem (CPU total)=22691.52734375MB
INFO:root:[  146] Training loss: 0.95471035, Validation loss: 0.95678840, Gradient norm: 0.11733033
INFO:root:At the start of the epoch: mem (CPU python)=22791.578125MB; mem (CPU total)=22729.88671875MB
INFO:root:Learning rate reduced to: [6.25e-05]
INFO:root:[  147] Training loss: 0.95476096, Validation loss: 0.95674266, Gradient norm: 0.11717494
INFO:root:At the start of the epoch: mem (CPU python)=22829.66796875MB; mem (CPU total)=22768.03125MB
INFO:root:Learning rate reduced to: [3.125e-05]
INFO:root:[  148] Training loss: 0.95456458, Validation loss: 0.95639719, Gradient norm: 0.11521808
INFO:root:At the start of the epoch: mem (CPU python)=22867.76953125MB; mem (CPU total)=22806.25390625MB
INFO:root:[  149] Training loss: 0.95441591, Validation loss: 0.95660628, Gradient norm: 0.10963224
INFO:root:At the start of the epoch: mem (CPU python)=22905.86328125MB; mem (CPU total)=22844.00390625MB
INFO:root:[  150] Training loss: 0.95448809, Validation loss: 0.95639068, Gradient norm: 0.11350336
INFO:root:At the start of the epoch: mem (CPU python)=22943.95703125MB; mem (CPU total)=22882.08203125MB
INFO:root:[  151] Training loss: 0.95453980, Validation loss: 0.95674178, Gradient norm: 0.11016528
INFO:root:At the start of the epoch: mem (CPU python)=22982.05078125MB; mem (CPU total)=22920.2265625MB
INFO:root:[  152] Training loss: 0.95445678, Validation loss: 0.95723299, Gradient norm: 0.11712028
INFO:root:At the start of the epoch: mem (CPU python)=23020.15234375MB; mem (CPU total)=22958.37109375MB
INFO:root:[  153] Training loss: 0.95445709, Validation loss: 0.95634108, Gradient norm: 0.11184955
INFO:root:At the start of the epoch: mem (CPU python)=23058.25MB; mem (CPU total)=22997.0MB
INFO:root:[  154] Training loss: 0.95436626, Validation loss: 0.95694654, Gradient norm: 0.11530572
INFO:root:At the start of the epoch: mem (CPU python)=23096.33984375MB; mem (CPU total)=23035.14453125MB
INFO:root:[  155] Training loss: 0.95456717, Validation loss: 0.95643874, Gradient norm: 0.11466293
INFO:root:At the start of the epoch: mem (CPU python)=23134.4375MB; mem (CPU total)=23073.2890625MB
INFO:root:[  156] Training loss: 0.95439812, Validation loss: 0.95674242, Gradient norm: 0.11078554
INFO:root:At the start of the epoch: mem (CPU python)=23172.53515625MB; mem (CPU total)=23111.43359375MB
INFO:root:[  157] Training loss: 0.95441546, Validation loss: 0.95691535, Gradient norm: 0.11481991
INFO:root:At the start of the epoch: mem (CPU python)=23210.62890625MB; mem (CPU total)=23149.578125MB
INFO:root:[  158] Training loss: 0.95432558, Validation loss: 0.95609710, Gradient norm: 0.11549138
INFO:root:At the start of the epoch: mem (CPU python)=23248.7265625MB; mem (CPU total)=23187.77734375MB
INFO:root:[  159] Training loss: 0.95429976, Validation loss: 0.95654943, Gradient norm: 0.11671730
INFO:root:At the start of the epoch: mem (CPU python)=23286.81640625MB; mem (CPU total)=23225.4609375MB
INFO:root:[  160] Training loss: 0.95448092, Validation loss: 0.95658956, Gradient norm: 0.11629621
INFO:root:At the start of the epoch: mem (CPU python)=23324.9140625MB; mem (CPU total)=23263.66015625MB
INFO:root:[  161] Training loss: 0.95443893, Validation loss: 0.95636793, Gradient norm: 0.11600431
INFO:root:At the start of the epoch: mem (CPU python)=23363.0078125MB; mem (CPU total)=23301.3125MB
INFO:root:[  162] Training loss: 0.95445170, Validation loss: 0.95659307, Gradient norm: 0.11045588
INFO:root:At the start of the epoch: mem (CPU python)=23401.10546875MB; mem (CPU total)=23339.703125MB
INFO:root:[  163] Training loss: 0.95435275, Validation loss: 0.95673959, Gradient norm: 0.11536549
INFO:root:At the start of the epoch: mem (CPU python)=23439.203125MB; mem (CPU total)=23377.78515625MB
INFO:root:[  164] Training loss: 0.95435638, Validation loss: 0.95659497, Gradient norm: 0.11955360
INFO:root:At the start of the epoch: mem (CPU python)=23477.29296875MB; mem (CPU total)=23415.9296875MB
INFO:root:Learning rate reduced to: [1.5625e-05]
INFO:root:[  165] Training loss: 0.95431322, Validation loss: 0.95672202, Gradient norm: 0.11881633
INFO:root:At the start of the epoch: mem (CPU python)=23515.39453125MB; mem (CPU total)=23454.3203125MB
INFO:root:Learning rate reduced to: [7.8125e-06]
INFO:root:[  166] Training loss: 0.95430343, Validation loss: 0.95671851, Gradient norm: 0.11698593
INFO:root:At the start of the epoch: mem (CPU python)=23553.48828125MB; mem (CPU total)=23492.46484375MB
INFO:root:Learning rate reduced to: [3.90625e-06]
INFO:root:[  167] Training loss: 0.95425072, Validation loss: 0.95656985, Gradient norm: 0.11441053
INFO:root:At the start of the epoch: mem (CPU python)=23591.58203125MB; mem (CPU total)=23531.12890625MB
INFO:root:Learning rate reduced to: [1.953125e-06]
INFO:root:EP 167: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=23629.67578125MB; mem (CPU total)=23568.90234375MB
INFO:root:Training the model took 10671.765s.
INFO:root:Emptying the cuda cache took 0.009s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94172
INFO:root:EnergyScoreTrain: 0.84569
INFO:root:CRPSTrain: 0.7129
INFO:root:Gaussian NLLTrain: 536.0314
INFO:root:CoverageTrain: 0.20131
INFO:root:IntervalWidthTrain: 0.41281
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94411
INFO:root:EnergyScoreValidation: 0.84842
INFO:root:CRPSValidation: 0.71539
INFO:root:Gaussian NLLValidation: 535.56308
INFO:root:CoverageValidation: 0.19935
INFO:root:IntervalWidthValidation: 0.4115
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94375
INFO:root:EnergyScoreTest: 0.84807
INFO:root:CRPSTest: 0.71524
INFO:root:Gaussian NLLTest: 540.09484
INFO:root:CoverageTest: 0.19914
INFO:root:IntervalWidthTest: 0.41112
INFO:root:After validation: mem (CPU python)=23688.234375MB; mem (CPU total)=23627.41015625MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=23688.234375MB; mem (CPU total)=23627.40234375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=23688.265625MB; mem (CPU total)=23627.40234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=23688.265625MB; mem (CPU total)=23627.39453125MB
INFO:root:[    1] Training loss: 1.01167432, Validation loss: 0.99891416, Gradient norm: 0.03382822
INFO:root:At the start of the epoch: mem (CPU python)=23726.20703125MB; mem (CPU total)=23665.3984375MB
INFO:root:[    2] Training loss: 0.99325558, Validation loss: 0.99017637, Gradient norm: 0.05563148
INFO:root:At the start of the epoch: mem (CPU python)=23764.31640625MB; mem (CPU total)=23703.62109375MB
INFO:root:[    3] Training loss: 0.98739978, Validation loss: 0.98671795, Gradient norm: 0.05762361
INFO:root:At the start of the epoch: mem (CPU python)=23802.43359375MB; mem (CPU total)=23741.84375MB
INFO:root:[    4] Training loss: 0.98475238, Validation loss: 0.98502403, Gradient norm: 0.06383246
INFO:root:At the start of the epoch: mem (CPU python)=23840.53125MB; mem (CPU total)=23779.87109375MB
INFO:root:[    5] Training loss: 0.98299962, Validation loss: 0.98324816, Gradient norm: 0.06426415
INFO:root:At the start of the epoch: mem (CPU python)=23878.625MB; mem (CPU total)=23818.234375MB
INFO:root:[    6] Training loss: 0.98188233, Validation loss: 0.98211702, Gradient norm: 0.06440226
INFO:root:At the start of the epoch: mem (CPU python)=23916.71875MB; mem (CPU total)=23856.17578125MB
INFO:root:[    7] Training loss: 0.98099253, Validation loss: 0.98227489, Gradient norm: 0.06862895
INFO:root:At the start of the epoch: mem (CPU python)=23954.81640625MB; mem (CPU total)=23894.5546875MB
INFO:root:[    8] Training loss: 0.98019377, Validation loss: 0.98056620, Gradient norm: 0.06794119
INFO:root:At the start of the epoch: mem (CPU python)=23992.91015625MB; mem (CPU total)=23932.609375MB
INFO:root:[    9] Training loss: 0.97963607, Validation loss: 0.97968136, Gradient norm: 0.07559514
INFO:root:At the start of the epoch: mem (CPU python)=24031.00390625MB; mem (CPU total)=23970.75MB
INFO:root:[   10] Training loss: 0.97887878, Validation loss: 0.97965274, Gradient norm: 0.07048021
INFO:root:At the start of the epoch: mem (CPU python)=24069.10546875MB; mem (CPU total)=24009.390625MB
INFO:root:[   11] Training loss: 0.97817555, Validation loss: 0.97887833, Gradient norm: 0.07396479
INFO:root:At the start of the epoch: mem (CPU python)=24107.19921875MB; mem (CPU total)=24047.66015625MB
INFO:root:[   12] Training loss: 0.97747445, Validation loss: 0.97847553, Gradient norm: 0.07777380
INFO:root:At the start of the epoch: mem (CPU python)=24145.29296875MB; mem (CPU total)=24086.12890625MB
INFO:root:[   13] Training loss: 0.97687056, Validation loss: 0.97808356, Gradient norm: 0.08381570
INFO:root:At the start of the epoch: mem (CPU python)=24183.390625MB; mem (CPU total)=24124.30078125MB
INFO:root:[   14] Training loss: 0.97622209, Validation loss: 0.97733121, Gradient norm: 0.08987309
INFO:root:At the start of the epoch: mem (CPU python)=24221.484375MB; mem (CPU total)=24162.26171875MB
INFO:root:[   15] Training loss: 0.97538767, Validation loss: 0.97580767, Gradient norm: 0.08718181
INFO:root:At the start of the epoch: mem (CPU python)=24259.578125MB; mem (CPU total)=24200.40625MB
INFO:root:[   16] Training loss: 0.97456787, Validation loss: 0.97597272, Gradient norm: 0.09429086
INFO:root:At the start of the epoch: mem (CPU python)=24297.671875MB; mem (CPU total)=24238.5390625MB
INFO:root:[   17] Training loss: 0.97396803, Validation loss: 0.97452221, Gradient norm: 0.09179013
INFO:root:At the start of the epoch: mem (CPU python)=24335.7734375MB; mem (CPU total)=24276.74609375MB
INFO:root:[   18] Training loss: 0.97360379, Validation loss: 0.97423199, Gradient norm: 0.10497718
INFO:root:At the start of the epoch: mem (CPU python)=24373.8671875MB; mem (CPU total)=24315.35546875MB
INFO:root:[   19] Training loss: 0.97301054, Validation loss: 0.97380403, Gradient norm: 0.09918949
INFO:root:At the start of the epoch: mem (CPU python)=24411.96484375MB; mem (CPU total)=24353.8671875MB
INFO:root:[   20] Training loss: 0.97253593, Validation loss: 0.97324369, Gradient norm: 0.10329940
INFO:root:At the start of the epoch: mem (CPU python)=24450.0625MB; mem (CPU total)=24391.9296875MB
INFO:root:[   21] Training loss: 0.97198238, Validation loss: 0.97283183, Gradient norm: 0.10389405
INFO:root:At the start of the epoch: mem (CPU python)=24488.15625MB; mem (CPU total)=24429.8984375MB
INFO:root:[   22] Training loss: 0.97143596, Validation loss: 0.97249587, Gradient norm: 0.10233164
INFO:root:At the start of the epoch: mem (CPU python)=24526.25390625MB; mem (CPU total)=24472.15234375MB
INFO:root:[   23] Training loss: 0.97129311, Validation loss: 0.97175497, Gradient norm: 0.10586555
INFO:root:At the start of the epoch: mem (CPU python)=24564.34765625MB; mem (CPU total)=24509.87890625MB
INFO:root:[   24] Training loss: 0.97062227, Validation loss: 0.97159004, Gradient norm: 0.10303359
INFO:root:At the start of the epoch: mem (CPU python)=24602.4453125MB; mem (CPU total)=24548.69140625MB
INFO:root:[   25] Training loss: 0.97029407, Validation loss: 0.97083566, Gradient norm: 0.10275049
INFO:root:At the start of the epoch: mem (CPU python)=24640.5390625MB; mem (CPU total)=24586.76171875MB
INFO:root:[   26] Training loss: 0.97000525, Validation loss: 0.97030294, Gradient norm: 0.10466341
INFO:root:At the start of the epoch: mem (CPU python)=24678.6328125MB; mem (CPU total)=24624.890625MB
INFO:root:[   27] Training loss: 0.96958789, Validation loss: 0.96975124, Gradient norm: 0.10311670
INFO:root:At the start of the epoch: mem (CPU python)=24716.73046875MB; mem (CPU total)=24663.328125MB
INFO:root:[   28] Training loss: 0.96948800, Validation loss: 0.96964321, Gradient norm: 0.11157416
INFO:root:At the start of the epoch: mem (CPU python)=24754.82421875MB; mem (CPU total)=24701.765625MB
INFO:root:[   29] Training loss: 0.96898009, Validation loss: 0.97025218, Gradient norm: 0.10206912
INFO:root:At the start of the epoch: mem (CPU python)=24792.91796875MB; mem (CPU total)=24740.15625MB
INFO:root:[   30] Training loss: 0.96877394, Validation loss: 0.96930967, Gradient norm: 0.10180195
INFO:root:At the start of the epoch: mem (CPU python)=24831.0234375MB; mem (CPU total)=24777.421875MB
INFO:root:[   31] Training loss: 0.96846599, Validation loss: 0.96949923, Gradient norm: 0.10841561
INFO:root:At the start of the epoch: mem (CPU python)=24869.11328125MB; mem (CPU total)=24815.74609375MB
INFO:root:[   32] Training loss: 0.96828609, Validation loss: 0.96907778, Gradient norm: 0.10365316
INFO:root:At the start of the epoch: mem (CPU python)=24907.2109375MB; mem (CPU total)=24853.88671875MB
INFO:root:[   33] Training loss: 0.96795809, Validation loss: 0.96888272, Gradient norm: 0.10445117
INFO:root:At the start of the epoch: mem (CPU python)=24945.3046875MB; mem (CPU total)=24891.79296875MB
INFO:root:[   34] Training loss: 0.96778382, Validation loss: 0.96832588, Gradient norm: 0.10556246
INFO:root:At the start of the epoch: mem (CPU python)=24983.40234375MB; mem (CPU total)=24929.95703125MB
INFO:root:[   35] Training loss: 0.96751806, Validation loss: 0.96843934, Gradient norm: 0.10473067
INFO:root:At the start of the epoch: mem (CPU python)=25021.49609375MB; mem (CPU total)=24968.34765625MB
INFO:root:[   36] Training loss: 0.96747147, Validation loss: 0.96827371, Gradient norm: 0.10918053
INFO:root:At the start of the epoch: mem (CPU python)=25059.58984375MB; mem (CPU total)=25006.125MB
INFO:root:[   37] Training loss: 0.96717740, Validation loss: 0.96773389, Gradient norm: 0.11159765
INFO:root:At the start of the epoch: mem (CPU python)=25097.6875MB; mem (CPU total)=25044.37890625MB
INFO:root:[   38] Training loss: 0.96687654, Validation loss: 0.96783867, Gradient norm: 0.10631721
INFO:root:At the start of the epoch: mem (CPU python)=25135.78125MB; mem (CPU total)=25083.015625MB
INFO:root:[   39] Training loss: 0.96679780, Validation loss: 0.96791110, Gradient norm: 0.10874124
INFO:root:At the start of the epoch: mem (CPU python)=25173.875MB; mem (CPU total)=25121.04296875MB
INFO:root:[   40] Training loss: 0.96662360, Validation loss: 0.96706162, Gradient norm: 0.11259556
INFO:root:At the start of the epoch: mem (CPU python)=25211.97265625MB; mem (CPU total)=25159.7109375MB
INFO:root:[   41] Training loss: 0.96627121, Validation loss: 0.96696859, Gradient norm: 0.10415680
INFO:root:At the start of the epoch: mem (CPU python)=25250.0703125MB; mem (CPU total)=25197.16015625MB
INFO:root:[   42] Training loss: 0.96625578, Validation loss: 0.96746661, Gradient norm: 0.10604459
INFO:root:At the start of the epoch: mem (CPU python)=25288.1640625MB; mem (CPU total)=25235.33203125MB
INFO:root:[   43] Training loss: 0.96605866, Validation loss: 0.96670648, Gradient norm: 0.10701795
INFO:root:At the start of the epoch: mem (CPU python)=25326.2578125MB; mem (CPU total)=25273.578125MB
INFO:root:[   44] Training loss: 0.96568886, Validation loss: 0.96671409, Gradient norm: 0.10819970
INFO:root:At the start of the epoch: mem (CPU python)=25364.35546875MB; mem (CPU total)=25311.7890625MB
INFO:root:[   45] Training loss: 0.96588732, Validation loss: 0.96649388, Gradient norm: 0.11259249
INFO:root:At the start of the epoch: mem (CPU python)=25402.453125MB; mem (CPU total)=25350.87109375MB
INFO:root:[   46] Training loss: 0.96556916, Validation loss: 0.96601290, Gradient norm: 0.10962686
INFO:root:At the start of the epoch: mem (CPU python)=25440.546875MB; mem (CPU total)=25388.6484375MB
INFO:root:[   47] Training loss: 0.96530515, Validation loss: 0.96624194, Gradient norm: 0.10537511
INFO:root:At the start of the epoch: mem (CPU python)=25478.640625MB; mem (CPU total)=25426.55078125MB
INFO:root:[   48] Training loss: 0.96511103, Validation loss: 0.96624797, Gradient norm: 0.11064769
INFO:root:At the start of the epoch: mem (CPU python)=25516.734375MB; mem (CPU total)=25464.484375MB
INFO:root:[   49] Training loss: 0.96494785, Validation loss: 0.96583111, Gradient norm: 0.10365607
INFO:root:At the start of the epoch: mem (CPU python)=25554.83203125MB; mem (CPU total)=25502.04296875MB
INFO:root:[   50] Training loss: 0.96488811, Validation loss: 0.96599304, Gradient norm: 0.11594070
INFO:root:At the start of the epoch: mem (CPU python)=25592.92578125MB; mem (CPU total)=25539.6796875MB
INFO:root:[   51] Training loss: 0.96474878, Validation loss: 0.96529483, Gradient norm: 0.10290510
INFO:root:At the start of the epoch: mem (CPU python)=25631.0234375MB; mem (CPU total)=25577.71875MB
INFO:root:[   52] Training loss: 0.96452618, Validation loss: 0.96580462, Gradient norm: 0.11004256
INFO:root:At the start of the epoch: mem (CPU python)=25669.1171875MB; mem (CPU total)=25616.375MB
INFO:root:[   53] Training loss: 0.96423534, Validation loss: 0.96573706, Gradient norm: 0.10273703
INFO:root:At the start of the epoch: mem (CPU python)=25707.2109375MB; mem (CPU total)=25654.546875MB
INFO:root:[   54] Training loss: 0.96441604, Validation loss: 0.96543413, Gradient norm: 0.12170028
INFO:root:At the start of the epoch: mem (CPU python)=25745.30859375MB; mem (CPU total)=25692.47265625MB
INFO:root:[   55] Training loss: 0.96398858, Validation loss: 0.96547069, Gradient norm: 0.10816936
INFO:root:At the start of the epoch: mem (CPU python)=25783.40234375MB; mem (CPU total)=25730.890625MB
INFO:root:[   56] Training loss: 0.96391142, Validation loss: 0.96512018, Gradient norm: 0.11340752
INFO:root:At the start of the epoch: mem (CPU python)=25821.5MB; mem (CPU total)=25768.4609375MB
INFO:root:[   57] Training loss: 0.96379211, Validation loss: 0.96485378, Gradient norm: 0.10903642
INFO:root:At the start of the epoch: mem (CPU python)=25859.59375MB; mem (CPU total)=25806.96484375MB
INFO:root:[   58] Training loss: 0.96360892, Validation loss: 0.96478806, Gradient norm: 0.10834112
INFO:root:At the start of the epoch: mem (CPU python)=25897.69140625MB; mem (CPU total)=25845.04296875MB
INFO:root:[   59] Training loss: 0.96366510, Validation loss: 0.96447265, Gradient norm: 0.10946603
INFO:root:At the start of the epoch: mem (CPU python)=25935.78515625MB; mem (CPU total)=25883.15234375MB
INFO:root:[   60] Training loss: 0.96340869, Validation loss: 0.96545578, Gradient norm: 0.10938579
INFO:root:At the start of the epoch: mem (CPU python)=25973.87890625MB; mem (CPU total)=25921.81640625MB
INFO:root:[   61] Training loss: 0.96335589, Validation loss: 0.96383668, Gradient norm: 0.11383998
INFO:root:At the start of the epoch: mem (CPU python)=26011.98046875MB; mem (CPU total)=25959.92578125MB
INFO:root:[   62] Training loss: 0.96320375, Validation loss: 0.96506105, Gradient norm: 0.10608700
INFO:root:At the start of the epoch: mem (CPU python)=26050.0703125MB; mem (CPU total)=25998.12890625MB
INFO:root:[   63] Training loss: 0.96304825, Validation loss: 0.96408660, Gradient norm: 0.11662740
INFO:root:At the start of the epoch: mem (CPU python)=26088.1640625MB; mem (CPU total)=26036.0546875MB
INFO:root:[   64] Training loss: 0.96308004, Validation loss: 0.96403505, Gradient norm: 0.11518245
INFO:root:At the start of the epoch: mem (CPU python)=26126.26171875MB; mem (CPU total)=26074.2265625MB
INFO:root:[   65] Training loss: 0.96288045, Validation loss: 0.96407055, Gradient norm: 0.10692313
INFO:root:At the start of the epoch: mem (CPU python)=26164.359375MB; mem (CPU total)=26111.16796875MB
INFO:root:[   66] Training loss: 0.96285487, Validation loss: 0.96353885, Gradient norm: 0.10739692
INFO:root:At the start of the epoch: mem (CPU python)=26202.453125MB; mem (CPU total)=26150.1953125MB
INFO:root:[   67] Training loss: 0.96265364, Validation loss: 0.96345037, Gradient norm: 0.10975385
INFO:root:At the start of the epoch: mem (CPU python)=26240.546875MB; mem (CPU total)=26187.875MB
INFO:root:[   68] Training loss: 0.96267876, Validation loss: 0.96341964, Gradient norm: 0.11500438
INFO:root:At the start of the epoch: mem (CPU python)=26278.64453125MB; mem (CPU total)=26226.046875MB
INFO:root:[   69] Training loss: 0.96257625, Validation loss: 0.96309704, Gradient norm: 0.11036584
INFO:root:At the start of the epoch: mem (CPU python)=26316.73828125MB; mem (CPU total)=26264.48046875MB
INFO:root:[   70] Training loss: 0.96233283, Validation loss: 0.96360441, Gradient norm: 0.10956068
INFO:root:At the start of the epoch: mem (CPU python)=26354.83203125MB; mem (CPU total)=26302.8125MB
INFO:root:[   71] Training loss: 0.96211896, Validation loss: 0.96378796, Gradient norm: 0.10973272
INFO:root:At the start of the epoch: mem (CPU python)=26392.9296875MB; mem (CPU total)=26340.95703125MB
INFO:root:[   72] Training loss: 0.96226370, Validation loss: 0.96294093, Gradient norm: 0.11357193
INFO:root:At the start of the epoch: mem (CPU python)=26431.02734375MB; mem (CPU total)=26378.68359375MB
INFO:root:[   73] Training loss: 0.96196311, Validation loss: 0.96335560, Gradient norm: 0.10854601
INFO:root:At the start of the epoch: mem (CPU python)=26469.12109375MB; mem (CPU total)=26416.8515625MB
INFO:root:[   74] Training loss: 0.96189352, Validation loss: 0.96311235, Gradient norm: 0.11201863
INFO:root:At the start of the epoch: mem (CPU python)=26507.21875MB; mem (CPU total)=26455.1328125MB
INFO:root:[   75] Training loss: 0.96173299, Validation loss: 0.96295179, Gradient norm: 0.10977481
INFO:root:At the start of the epoch: mem (CPU python)=26545.31640625MB; mem (CPU total)=26493.0078125MB
INFO:root:[   76] Training loss: 0.96196067, Validation loss: 0.96273275, Gradient norm: 0.11589736
INFO:root:At the start of the epoch: mem (CPU python)=26583.41015625MB; mem (CPU total)=26531.21484375MB
INFO:root:[   77] Training loss: 0.96160832, Validation loss: 0.96275601, Gradient norm: 0.10588658
INFO:root:At the start of the epoch: mem (CPU python)=26621.50390625MB; mem (CPU total)=26569.63671875MB
INFO:root:[   78] Training loss: 0.96151728, Validation loss: 0.96313640, Gradient norm: 0.11343586
INFO:root:At the start of the epoch: mem (CPU python)=26659.6015625MB; mem (CPU total)=26607.78125MB
INFO:root:[   79] Training loss: 0.96148770, Validation loss: 0.96298967, Gradient norm: 0.11787822
INFO:root:At the start of the epoch: mem (CPU python)=26697.6953125MB; mem (CPU total)=26645.92578125MB
INFO:root:[   80] Training loss: 0.96139108, Validation loss: 0.96301540, Gradient norm: 0.11306585
INFO:root:At the start of the epoch: mem (CPU python)=26735.7890625MB; mem (CPU total)=26683.9765625MB
INFO:root:[   81] Training loss: 0.96125927, Validation loss: 0.96294278, Gradient norm: 0.11359146
INFO:root:At the start of the epoch: mem (CPU python)=26773.88671875MB; mem (CPU total)=26722.3671875MB
INFO:root:[   82] Training loss: 0.96117450, Validation loss: 0.96235377, Gradient norm: 0.10838665
INFO:root:At the start of the epoch: mem (CPU python)=26811.984375MB; mem (CPU total)=26760.56640625MB
INFO:root:[   83] Training loss: 0.96106497, Validation loss: 0.96259498, Gradient norm: 0.10701687
INFO:root:At the start of the epoch: mem (CPU python)=26850.078125MB; mem (CPU total)=26798.97265625MB
INFO:root:[   84] Training loss: 0.96108685, Validation loss: 0.96225129, Gradient norm: 0.11084536
INFO:root:At the start of the epoch: mem (CPU python)=26888.171875MB; mem (CPU total)=26836.37890625MB
INFO:root:[   85] Training loss: 0.96095297, Validation loss: 0.96213126, Gradient norm: 0.11789750
INFO:root:At the start of the epoch: mem (CPU python)=26926.26953125MB; mem (CPU total)=26873.30859375MB
INFO:root:[   86] Training loss: 0.96092492, Validation loss: 0.96222684, Gradient norm: 0.11056952
INFO:root:At the start of the epoch: mem (CPU python)=26964.36328125MB; mem (CPU total)=26911.20703125MB
INFO:root:[   87] Training loss: 0.96077075, Validation loss: 0.96169990, Gradient norm: 0.11122862
INFO:root:At the start of the epoch: mem (CPU python)=27002.4609375MB; mem (CPU total)=26949.68359375MB
INFO:root:[   88] Training loss: 0.96056768, Validation loss: 0.96134892, Gradient norm: 0.11472295
INFO:root:At the start of the epoch: mem (CPU python)=27040.55859375MB; mem (CPU total)=26987.17578125MB
INFO:root:[   89] Training loss: 0.96055420, Validation loss: 0.96122211, Gradient norm: 0.11213008
INFO:root:At the start of the epoch: mem (CPU python)=27078.65234375MB; mem (CPU total)=27025.2734375MB
INFO:root:[   90] Training loss: 0.96047432, Validation loss: 0.96208550, Gradient norm: 0.10974720
INFO:root:At the start of the epoch: mem (CPU python)=27116.7421875MB; mem (CPU total)=27063.78515625MB
INFO:root:[   91] Training loss: 0.96028201, Validation loss: 0.96144826, Gradient norm: 0.11263686
INFO:root:At the start of the epoch: mem (CPU python)=27154.83984375MB; mem (CPU total)=27101.85546875MB
INFO:root:[   92] Training loss: 0.96024403, Validation loss: 0.96163946, Gradient norm: 0.11055436
INFO:root:At the start of the epoch: mem (CPU python)=27192.9375MB; mem (CPU total)=27140.10546875MB
INFO:root:[   93] Training loss: 0.96022132, Validation loss: 0.96066245, Gradient norm: 0.12154843
INFO:root:At the start of the epoch: mem (CPU python)=27231.03125MB; mem (CPU total)=27178.08984375MB
INFO:root:[   94] Training loss: 0.96015492, Validation loss: 0.96074947, Gradient norm: 0.11460481
INFO:root:At the start of the epoch: mem (CPU python)=27269.125MB; mem (CPU total)=27216.30859375MB
INFO:root:[   95] Training loss: 0.96004674, Validation loss: 0.96099459, Gradient norm: 0.11113440
INFO:root:At the start of the epoch: mem (CPU python)=27307.22265625MB; mem (CPU total)=27254.73828125MB
INFO:root:[   96] Training loss: 0.96003626, Validation loss: 0.96172456, Gradient norm: 0.11412968
INFO:root:At the start of the epoch: mem (CPU python)=27345.31640625MB; mem (CPU total)=27292.38671875MB
INFO:root:[   97] Training loss: 0.95993052, Validation loss: 0.96086009, Gradient norm: 0.11724581
INFO:root:At the start of the epoch: mem (CPU python)=27383.4140625MB; mem (CPU total)=27330.3828125MB
INFO:root:[   98] Training loss: 0.95975026, Validation loss: 0.96102759, Gradient norm: 0.11329593
INFO:root:At the start of the epoch: mem (CPU python)=27421.51171875MB; mem (CPU total)=27368.1484375MB
INFO:root:[   99] Training loss: 0.95976592, Validation loss: 0.96062353, Gradient norm: 0.10957329
INFO:root:At the start of the epoch: mem (CPU python)=27459.60546875MB; mem (CPU total)=27406.890625MB
INFO:root:[  100] Training loss: 0.95977915, Validation loss: 0.96059173, Gradient norm: 0.12091777
INFO:root:At the start of the epoch: mem (CPU python)=27497.69921875MB; mem (CPU total)=27445.15625MB
INFO:root:[  101] Training loss: 0.95957376, Validation loss: 0.96090175, Gradient norm: 0.11580488
INFO:root:At the start of the epoch: mem (CPU python)=27535.79296875MB; mem (CPU total)=27483.57421875MB
INFO:root:[  102] Training loss: 0.95948199, Validation loss: 0.96104156, Gradient norm: 0.11467408
INFO:root:At the start of the epoch: mem (CPU python)=27573.890625MB; mem (CPU total)=27521.73046875MB
INFO:root:[  103] Training loss: 0.95945198, Validation loss: 0.96126622, Gradient norm: 0.11242972
INFO:root:At the start of the epoch: mem (CPU python)=27611.984375MB; mem (CPU total)=27559.90234375MB
INFO:root:[  104] Training loss: 0.95937139, Validation loss: 0.96110928, Gradient norm: 0.11839254
INFO:root:At the start of the epoch: mem (CPU python)=27650.078125MB; mem (CPU total)=27597.76953125MB
INFO:root:[  105] Training loss: 0.95919199, Validation loss: 0.96005321, Gradient norm: 0.11699323
INFO:root:At the start of the epoch: mem (CPU python)=27688.1796875MB; mem (CPU total)=27636.12890625MB
INFO:root:[  106] Training loss: 0.95903914, Validation loss: 0.96049895, Gradient norm: 0.11177714
INFO:root:At the start of the epoch: mem (CPU python)=27726.26953125MB; mem (CPU total)=27674.37890625MB
INFO:root:[  107] Training loss: 0.95897432, Validation loss: 0.96060756, Gradient norm: 0.11802095
INFO:root:At the start of the epoch: mem (CPU python)=27764.3671875MB; mem (CPU total)=27712.51953125MB
INFO:root:[  108] Training loss: 0.95883920, Validation loss: 0.96024823, Gradient norm: 0.11162102
INFO:root:At the start of the epoch: mem (CPU python)=27802.4609375MB; mem (CPU total)=27750.6796875MB
