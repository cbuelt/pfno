INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=574.9921875MB; mem (CPU total)=33605.46875MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples3.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12453.96875MB; mem (CPU total)=33679.9609375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=12453.96875MB; mem (CPU total)=33679.9609375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12453.96875MB; mem (CPU total)=35021.0703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=35029.30078125MB
INFO:root:[    1] Training loss: 0.77904213, Validation loss: 0.72697477, Gradient norm: 0.43296064
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=36791.99609375MB
INFO:root:[    2] Training loss: 0.72355524, Validation loss: 0.72218628, Gradient norm: 0.26672614
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=36863.2109375MB
INFO:root:[    3] Training loss: 0.72125144, Validation loss: 0.72212162, Gradient norm: 0.26849184
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=36937.5625MB
INFO:root:[    4] Training loss: 0.72048594, Validation loss: 0.72095890, Gradient norm: 0.25335754
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37012.7109375MB
INFO:root:[    5] Training loss: 0.72005048, Validation loss: 0.72070569, Gradient norm: 0.23187863
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37086.02734375MB
INFO:root:[    6] Training loss: 0.71969245, Validation loss: 0.72014746, Gradient norm: 0.16821984
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37164.55859375MB
INFO:root:[    7] Training loss: 0.71946477, Validation loss: 0.71979462, Gradient norm: 0.20656164
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37244.41015625MB
INFO:root:[    8] Training loss: 0.71900989, Validation loss: 0.71948909, Gradient norm: 0.20779702
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37325.65625MB
INFO:root:[    9] Training loss: 0.71830367, Validation loss: 0.71848999, Gradient norm: 0.17681102
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37405.76171875MB
INFO:root:[   10] Training loss: 0.71636080, Validation loss: 0.71321217, Gradient norm: 0.15233950
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37487.265625MB
INFO:root:[   11] Training loss: 0.70795124, Validation loss: 0.70295406, Gradient norm: 0.19512664
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37567.7421875MB
INFO:root:[   12] Training loss: 0.69823269, Validation loss: 0.69412036, Gradient norm: 0.12937699
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37647.91015625MB
INFO:root:[   13] Training loss: 0.69012827, Validation loss: 0.68702360, Gradient norm: 0.11938835
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37706.94140625MB
INFO:root:[   14] Training loss: 0.68364071, Validation loss: 0.68185974, Gradient norm: 0.11743224
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37759.96875MB
INFO:root:[   15] Training loss: 0.67817610, Validation loss: 0.67683606, Gradient norm: 0.08875690
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37810.4296875MB
INFO:root:[   16] Training loss: 0.67383133, Validation loss: 0.67303717, Gradient norm: 0.10692968
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37849.8984375MB
INFO:root:[   17] Training loss: 0.67014615, Validation loss: 0.66886971, Gradient norm: 0.09532268
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37926.7890625MB
INFO:root:[   18] Training loss: 0.66690528, Validation loss: 0.66633258, Gradient norm: 0.10873327
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38002.15234375MB
INFO:root:[   19] Training loss: 0.66410279, Validation loss: 0.66442618, Gradient norm: 0.11125379
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38077.6796875MB
INFO:root:[   20] Training loss: 0.66160383, Validation loss: 0.66247539, Gradient norm: 0.13315306
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38155.8984375MB
INFO:root:[   21] Training loss: 0.65935955, Validation loss: 0.65962366, Gradient norm: 0.10824772
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38237.64453125MB
INFO:root:[   22] Training loss: 0.65737463, Validation loss: 0.65853146, Gradient norm: 0.11423776
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38321.60546875MB
INFO:root:[   23] Training loss: 0.65556000, Validation loss: 0.65648234, Gradient norm: 0.08534660
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38404.17578125MB
INFO:root:[   24] Training loss: 0.65377905, Validation loss: 0.65499223, Gradient norm: 0.08677576
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38485.1796875MB
INFO:root:[   25] Training loss: 0.65215435, Validation loss: 0.65351449, Gradient norm: 0.09825167
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38566.11328125MB
INFO:root:[   26] Training loss: 0.65076129, Validation loss: 0.65271703, Gradient norm: 0.08733948
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38649.34375MB
INFO:root:[   27] Training loss: 0.64926581, Validation loss: 0.65099389, Gradient norm: 0.09212679
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38727.09765625MB
INFO:root:[   28] Training loss: 0.64802463, Validation loss: 0.64947851, Gradient norm: 0.10074984
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38803.515625MB
INFO:root:[   29] Training loss: 0.64685828, Validation loss: 0.64864219, Gradient norm: 0.09748635
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38879.953125MB
INFO:root:[   30] Training loss: 0.64550653, Validation loss: 0.64767784, Gradient norm: 0.09850532
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38956.0MB
INFO:root:[   31] Training loss: 0.64442158, Validation loss: 0.64693748, Gradient norm: 0.13919372
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39032.4453125MB
INFO:root:[   32] Training loss: 0.64339046, Validation loss: 0.64623055, Gradient norm: 0.11444790
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39108.90234375MB
INFO:root:[   33] Training loss: 0.64230577, Validation loss: 0.64516032, Gradient norm: 0.09124596
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39184.91015625MB
INFO:root:[   34] Training loss: 0.64121729, Validation loss: 0.64373209, Gradient norm: 0.12184318
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39263.2890625MB
INFO:root:[   35] Training loss: 0.64017348, Validation loss: 0.64325689, Gradient norm: 0.11247959
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39344.8046875MB
INFO:root:[   36] Training loss: 0.63928760, Validation loss: 0.64291040, Gradient norm: 0.11432389
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39424.90625MB
INFO:root:[   37] Training loss: 0.63841228, Validation loss: 0.64201845, Gradient norm: 0.10478893
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39506.8125MB
INFO:root:[   38] Training loss: 0.63736818, Validation loss: 0.64051187, Gradient norm: 0.11578901
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39588.515625MB
INFO:root:[   39] Training loss: 0.63639990, Validation loss: 0.63985637, Gradient norm: 0.08849559
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39670.625MB
INFO:root:[   40] Training loss: 0.63573455, Validation loss: 0.63933808, Gradient norm: 0.11874409
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39751.6796875MB
INFO:root:[   41] Training loss: 0.63485810, Validation loss: 0.63893947, Gradient norm: 0.13260681
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39832.60546875MB
INFO:root:[   42] Training loss: 0.63404005, Validation loss: 0.63820514, Gradient norm: 0.11577938
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39909.1953125MB
INFO:root:[   43] Training loss: 0.63327349, Validation loss: 0.63750814, Gradient norm: 0.10419973
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39985.45703125MB
INFO:root:[   44] Training loss: 0.63264940, Validation loss: 0.63686684, Gradient norm: 0.15871599
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40061.80078125MB
INFO:root:[   45] Training loss: 0.63186891, Validation loss: 0.63616990, Gradient norm: 0.10875396
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40138.5546875MB
INFO:root:[   46] Training loss: 0.63143718, Validation loss: 0.63537375, Gradient norm: 0.11831440
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40216.75390625MB
INFO:root:[   47] Training loss: 0.63042226, Validation loss: 0.63505966, Gradient norm: 0.12669986
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40292.76171875MB
INFO:root:[   48] Training loss: 0.62998221, Validation loss: 0.63445713, Gradient norm: 0.10287160
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40369.27734375MB
INFO:root:[   49] Training loss: 0.62941074, Validation loss: 0.63474872, Gradient norm: 0.13868485
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40446.64453125MB
INFO:root:[   50] Training loss: 0.62878012, Validation loss: 0.63325255, Gradient norm: 0.11799104
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40526.38671875MB
INFO:root:[   51] Training loss: 0.62806998, Validation loss: 0.63291996, Gradient norm: 0.09653657
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40607.85546875MB
INFO:root:[   52] Training loss: 0.62752010, Validation loss: 0.63294573, Gradient norm: 0.11640761
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40689.57421875MB
