INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=580.5859375MB; mem (CPU total)=973.0MB
INFO:root:############### Starting experiment with config file darcy_flow/uno_laplace.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'DarcyFlow', 'max_training_set_size': 10000, 'downscaling_factor': 2}
INFO:root:After loading the datasets: mem (CPU python)=2000.69140625MB; mem (CPU total)=981.109375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=2000.69140625MB; mem (CPU total)=980.75MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 44040192
INFO:root:After setting up the model: mem (CPU python)=2026.09375MB; mem (CPU total)=2185.78515625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2026.09375MB; mem (CPU total)=2192.92578125MB
INFO:root:[    1] Training loss: 0.33882594, Validation loss: 0.23052040, Gradient norm: 2.77009237
INFO:root:At the start of the epoch: mem (CPU python)=3658.96875MB; mem (CPU total)=3441.10546875MB
INFO:root:[    2] Training loss: 0.22615745, Validation loss: 0.20784566, Gradient norm: 2.95335202
INFO:root:At the start of the epoch: mem (CPU python)=3735.5546875MB; mem (CPU total)=3517.65625MB
INFO:root:[    3] Training loss: 0.20284573, Validation loss: 0.18047519, Gradient norm: 3.02728979
INFO:root:At the start of the epoch: mem (CPU python)=3811.7578125MB; mem (CPU total)=3593.859375MB
INFO:root:[    4] Training loss: 0.18291308, Validation loss: 0.19845345, Gradient norm: 3.03446009
INFO:root:At the start of the epoch: mem (CPU python)=3887.98046875MB; mem (CPU total)=3670.70703125MB
INFO:root:[    5] Training loss: 0.17591159, Validation loss: 0.22060398, Gradient norm: 2.79211646
INFO:root:At the start of the epoch: mem (CPU python)=3964.1875MB; mem (CPU total)=3747.03515625MB
INFO:root:[    6] Training loss: 0.16355280, Validation loss: 0.17364693, Gradient norm: 2.16809401
INFO:root:At the start of the epoch: mem (CPU python)=4040.3984375MB; mem (CPU total)=3823.76171875MB
INFO:root:[    7] Training loss: 0.15783832, Validation loss: 0.16401745, Gradient norm: 2.04753503
INFO:root:At the start of the epoch: mem (CPU python)=4116.61328125MB; mem (CPU total)=3900.8125MB
INFO:root:[    8] Training loss: 0.15109539, Validation loss: 0.16111393, Gradient norm: 2.48824681
INFO:root:At the start of the epoch: mem (CPU python)=4192.828125MB; mem (CPU total)=3976.85546875MB
INFO:root:[    9] Training loss: 0.14509222, Validation loss: 0.19103670, Gradient norm: 2.01784994
INFO:root:At the start of the epoch: mem (CPU python)=4269.04296875MB; mem (CPU total)=4053.4296875MB
INFO:root:[   10] Training loss: 0.14893102, Validation loss: 0.15600201, Gradient norm: 2.21946965
INFO:root:At the start of the epoch: mem (CPU python)=4345.265625MB; mem (CPU total)=4129.07421875MB
INFO:root:[   11] Training loss: 0.13595360, Validation loss: 0.17367038, Gradient norm: 1.98390562
INFO:root:At the start of the epoch: mem (CPU python)=4421.48046875MB; mem (CPU total)=4205.6484375MB
INFO:root:[   12] Training loss: 0.13547436, Validation loss: 0.15784232, Gradient norm: 2.08847578
INFO:root:At the start of the epoch: mem (CPU python)=4497.71484375MB; mem (CPU total)=4281.91796875MB
INFO:root:[   13] Training loss: 0.13194883, Validation loss: 0.16105020, Gradient norm: 2.01132238
INFO:root:At the start of the epoch: mem (CPU python)=4573.94140625MB; mem (CPU total)=4358.37109375MB
INFO:root:[   14] Training loss: 0.13387129, Validation loss: 0.17145932, Gradient norm: 2.26631217
INFO:root:At the start of the epoch: mem (CPU python)=4650.15625MB; mem (CPU total)=4434.546875MB
INFO:root:[   15] Training loss: 0.12991442, Validation loss: 0.16530404, Gradient norm: 1.67492484
INFO:root:At the start of the epoch: mem (CPU python)=4726.37109375MB; mem (CPU total)=4511.1171875MB
INFO:root:[   16] Training loss: 0.13328569, Validation loss: 0.16533088, Gradient norm: 2.23428903
INFO:root:At the start of the epoch: mem (CPU python)=4802.5703125MB; mem (CPU total)=4587.265625MB
INFO:root:[   17] Training loss: 0.12187995, Validation loss: 0.15284343, Gradient norm: 1.98064743
INFO:root:At the start of the epoch: mem (CPU python)=4878.76953125MB; mem (CPU total)=4667.52734375MB
INFO:root:[   18] Training loss: 0.12586350, Validation loss: 0.14478608, Gradient norm: 2.13866514
INFO:root:At the start of the epoch: mem (CPU python)=4954.96484375MB; mem (CPU total)=4742.5546875MB
INFO:root:[   19] Training loss: 0.11985886, Validation loss: 0.17127952, Gradient norm: 2.18955913
INFO:root:At the start of the epoch: mem (CPU python)=5039.03515625MB; mem (CPU total)=4826.9296875MB
INFO:root:[   20] Training loss: 0.11769724, Validation loss: 0.17765604, Gradient norm: 1.84574165
INFO:root:At the start of the epoch: mem (CPU python)=5115.36328125MB; mem (CPU total)=4903.0703125MB
INFO:root:[   21] Training loss: 0.11375234, Validation loss: 0.16703817, Gradient norm: 1.91995316
INFO:root:At the start of the epoch: mem (CPU python)=5191.5703125MB; mem (CPU total)=4979.9375MB
INFO:root:[   22] Training loss: 0.11845561, Validation loss: 0.18309039, Gradient norm: 2.06857279
INFO:root:At the start of the epoch: mem (CPU python)=5267.765625MB; mem (CPU total)=5055.96875MB
INFO:root:[   23] Training loss: 0.11838878, Validation loss: 0.20429062, Gradient norm: 2.10067735
INFO:root:At the start of the epoch: mem (CPU python)=5344.0MB; mem (CPU total)=5132.1484375MB
INFO:root:[   24] Training loss: 0.10754828, Validation loss: 0.15653990, Gradient norm: 1.86893985
INFO:root:At the start of the epoch: mem (CPU python)=5420.22265625MB; mem (CPU total)=5208.90625MB
INFO:root:[   25] Training loss: 0.10896555, Validation loss: 0.23958240, Gradient norm: 2.00517996
INFO:root:At the start of the epoch: mem (CPU python)=5496.4296875MB; mem (CPU total)=5284.94140625MB
INFO:root:[   26] Training loss: 0.11159446, Validation loss: 0.20583794, Gradient norm: 2.23967203
INFO:root:At the start of the epoch: mem (CPU python)=5572.62890625MB; mem (CPU total)=5361.421875MB
INFO:root:[   27] Training loss: 0.11015598, Validation loss: 0.24825339, Gradient norm: 2.30724114
INFO:root:At the start of the epoch: mem (CPU python)=5648.81640625MB; mem (CPU total)=5437.78125MB
INFO:root:[   28] Training loss: 0.10913894, Validation loss: 0.18591146, Gradient norm: 2.01369947
INFO:root:At the start of the epoch: mem (CPU python)=5725.0234375MB; mem (CPU total)=5513.78125MB
INFO:root:[   29] Training loss: 0.11136862, Validation loss: 0.19902335, Gradient norm: 2.56784513
INFO:root:At the start of the epoch: mem (CPU python)=5801.21484375MB; mem (CPU total)=5590.1953125MB
INFO:root:[   30] Training loss: 0.10522437, Validation loss: 0.16838894, Gradient norm: 2.13780648
INFO:root:At the start of the epoch: mem (CPU python)=5877.40625MB; mem (CPU total)=5665.953125MB
INFO:root:[   31] Training loss: 0.10416664, Validation loss: 0.20141484, Gradient norm: 2.03756807
INFO:root:At the start of the epoch: mem (CPU python)=5953.6015625MB; mem (CPU total)=5741.4921875MB
INFO:root:[   32] Training loss: 0.10015429, Validation loss: 0.17305056, Gradient norm: 1.71857471
INFO:root:At the start of the epoch: mem (CPU python)=6029.7890625MB; mem (CPU total)=5817.5MB
INFO:root:[   33] Training loss: 0.10135363, Validation loss: 0.17373979, Gradient norm: 1.78045745
INFO:root:At the start of the epoch: mem (CPU python)=6105.98046875MB; mem (CPU total)=5893.53125MB
