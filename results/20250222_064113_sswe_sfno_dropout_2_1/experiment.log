INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=582.4453125MB; mem (CPU total)=8949.796875MB
INFO:root:############### Starting experiment with config file sswe/sfno_dropout_2_1.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=593.1796875MB; mem (CPU total)=8957.0703125MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=594.625MB; mem (CPU total)=8956.4609375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2246.9921875MB; mem (CPU total)=10339.046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2256.703125MB; mem (CPU total)=10348.078125MB
INFO:root:[    1] Training loss: 0.75934527, Validation loss: 0.71457591, Gradient norm: 0.39811017
INFO:root:At the start of the epoch: mem (CPU python)=4412.734375MB; mem (CPU total)=12106.80078125MB
INFO:root:[    2] Training loss: 0.65687639, Validation loss: 0.60467522, Gradient norm: 0.61580318
INFO:root:At the start of the epoch: mem (CPU python)=4434.98046875MB; mem (CPU total)=12138.07421875MB
INFO:root:[    3] Training loss: 0.57591440, Validation loss: 0.55132942, Gradient norm: 1.06458570
INFO:root:At the start of the epoch: mem (CPU python)=4457.95703125MB; mem (CPU total)=12167.625MB
INFO:root:[    4] Training loss: 0.53839735, Validation loss: 0.52585903, Gradient norm: 1.48044283
INFO:root:At the start of the epoch: mem (CPU python)=4479.8671875MB; mem (CPU total)=12168.3984375MB
INFO:root:[    5] Training loss: 0.52356487, Validation loss: 0.51806507, Gradient norm: 1.78877726
INFO:root:At the start of the epoch: mem (CPU python)=4501.078125MB; mem (CPU total)=12201.93359375MB
INFO:root:[    6] Training loss: 0.51620414, Validation loss: 0.51198769, Gradient norm: 2.13892501
INFO:root:At the start of the epoch: mem (CPU python)=4522.26953125MB; mem (CPU total)=12238.140625MB
INFO:root:[    7] Training loss: 0.51336870, Validation loss: 0.51182777, Gradient norm: 2.40204817
INFO:root:At the start of the epoch: mem (CPU python)=4544.3671875MB; mem (CPU total)=12249.3203125MB
INFO:root:[    8] Training loss: 0.50929323, Validation loss: 0.51632830, Gradient norm: 2.63296125
INFO:root:At the start of the epoch: mem (CPU python)=4570.6015625MB; mem (CPU total)=12287.3125MB
INFO:root:[    9] Training loss: 0.50945075, Validation loss: 0.52359132, Gradient norm: 2.83357671
INFO:root:At the start of the epoch: mem (CPU python)=4592.5546875MB; mem (CPU total)=12323.36328125MB
INFO:root:[   10] Training loss: 0.50578219, Validation loss: 0.49508418, Gradient norm: 3.05617915
INFO:root:At the start of the epoch: mem (CPU python)=4614.3125MB; mem (CPU total)=12058.33984375MB
INFO:root:[   11] Training loss: 0.50078365, Validation loss: 0.49998486, Gradient norm: 3.33005352
INFO:root:At the start of the epoch: mem (CPU python)=4636.25MB; mem (CPU total)=12382.734375MB
INFO:root:[   12] Training loss: 0.50066785, Validation loss: 0.49355786, Gradient norm: 3.54353245
INFO:root:At the start of the epoch: mem (CPU python)=4658.17578125MB; mem (CPU total)=12399.66796875MB
INFO:root:[   13] Training loss: 0.49839609, Validation loss: 0.49861274, Gradient norm: 3.68465432
INFO:root:At the start of the epoch: mem (CPU python)=4679.35546875MB; mem (CPU total)=12430.5MB
INFO:root:[   14] Training loss: 0.49556788, Validation loss: 0.49337521, Gradient norm: 3.87900007
INFO:root:At the start of the epoch: mem (CPU python)=4700.515625MB; mem (CPU total)=12483.95703125MB
INFO:root:[   15] Training loss: 0.48390478, Validation loss: 0.46033958, Gradient norm: 4.14395305
INFO:root:At the start of the epoch: mem (CPU python)=4721.6796875MB; mem (CPU total)=12500.65234375MB
INFO:root:[   16] Training loss: 0.47114064, Validation loss: 0.47116305, Gradient norm: 4.49833920
INFO:root:At the start of the epoch: mem (CPU python)=4742.84375MB; mem (CPU total)=12541.859375MB
INFO:root:[   17] Training loss: 0.46581708, Validation loss: 0.45979840, Gradient norm: 4.52601194
INFO:root:At the start of the epoch: mem (CPU python)=4764.015625MB; mem (CPU total)=12593.484375MB
INFO:root:[   18] Training loss: 0.46591496, Validation loss: 0.46300357, Gradient norm: 4.51775709
INFO:root:At the start of the epoch: mem (CPU python)=4785.1875MB; mem (CPU total)=12624.3984375MB
INFO:root:[   19] Training loss: 0.46273208, Validation loss: 0.47273131, Gradient norm: 4.73386501
INFO:root:At the start of the epoch: mem (CPU python)=4806.34765625MB; mem (CPU total)=12625.03125MB
INFO:root:[   20] Training loss: 0.46140204, Validation loss: 0.44896962, Gradient norm: 4.81593210
INFO:root:At the start of the epoch: mem (CPU python)=4829.8125MB; mem (CPU total)=12652.49609375MB
INFO:root:[   21] Training loss: 0.45893038, Validation loss: 0.45573298, Gradient norm: 4.98182905
INFO:root:At the start of the epoch: mem (CPU python)=4851.640625MB; mem (CPU total)=12681.3515625MB
INFO:root:[   22] Training loss: 0.45840782, Validation loss: 0.46425930, Gradient norm: 4.96991998
INFO:root:At the start of the epoch: mem (CPU python)=4873.23828125MB; mem (CPU total)=12729.54296875MB
INFO:root:[   23] Training loss: 0.45638075, Validation loss: 0.45005803, Gradient norm: 4.95684004
INFO:root:At the start of the epoch: mem (CPU python)=4896.9453125MB; mem (CPU total)=12756.24609375MB
INFO:root:[   24] Training loss: 0.45491009, Validation loss: 0.44642810, Gradient norm: 4.98782791
INFO:root:At the start of the epoch: mem (CPU python)=4918.890625MB; mem (CPU total)=12785.0390625MB
INFO:root:[   25] Training loss: 0.45309537, Validation loss: 0.46203544, Gradient norm: 4.92653169
INFO:root:At the start of the epoch: mem (CPU python)=4940.0546875MB; mem (CPU total)=12818.67578125MB
INFO:root:[   26] Training loss: 0.45076672, Validation loss: 0.47292301, Gradient norm: 4.96594484
INFO:root:At the start of the epoch: mem (CPU python)=4961.2265625MB; mem (CPU total)=12836.4140625MB
INFO:root:[   27] Training loss: 0.45034904, Validation loss: 0.45762014, Gradient norm: 5.05768718
INFO:root:At the start of the epoch: mem (CPU python)=4990.18359375MB; mem (CPU total)=12874.71875MB
INFO:root:[   28] Training loss: 0.44787929, Validation loss: 0.45459772, Gradient norm: 5.06629792
INFO:root:At the start of the epoch: mem (CPU python)=5011.734375MB; mem (CPU total)=12903.2890625MB
INFO:root:[   29] Training loss: 0.44640071, Validation loss: 0.46566404, Gradient norm: 5.12356863
INFO:root:At the start of the epoch: mem (CPU python)=5032.91015625MB; mem (CPU total)=12932.12890625MB
INFO:root:[   30] Training loss: 0.44632667, Validation loss: 0.43280491, Gradient norm: 5.19209740
INFO:root:At the start of the epoch: mem (CPU python)=5054.07421875MB; mem (CPU total)=12964.73828125MB
INFO:root:[   31] Training loss: 0.44574604, Validation loss: 0.44583174, Gradient norm: 5.16684439
INFO:root:At the start of the epoch: mem (CPU python)=5075.2421875MB; mem (CPU total)=12992.42578125MB
INFO:root:[   32] Training loss: 0.44408359, Validation loss: 0.44789771, Gradient norm: 5.21805956
INFO:root:At the start of the epoch: mem (CPU python)=5096.421875MB; mem (CPU total)=13020.17578125MB
INFO:root:[   33] Training loss: 0.44313034, Validation loss: 0.44420328, Gradient norm: 5.09122741
INFO:root:At the start of the epoch: mem (CPU python)=5118.56640625MB; mem (CPU total)=13129.171875MB
INFO:root:[   34] Training loss: 0.43980857, Validation loss: 0.43658357, Gradient norm: 5.41644253
INFO:root:At the start of the epoch: mem (CPU python)=5139.75MB; mem (CPU total)=13096.625MB
INFO:root:[   35] Training loss: 0.44165205, Validation loss: 0.46076054, Gradient norm: 5.17847948
INFO:root:At the start of the epoch: mem (CPU python)=5160.96875MB; mem (CPU total)=13126.36328125MB
INFO:root:[   36] Training loss: 0.43915953, Validation loss: 0.46274981, Gradient norm: 5.25207239
INFO:root:At the start of the epoch: mem (CPU python)=5182.17578125MB; mem (CPU total)=13156.1875MB
INFO:root:[   37] Training loss: 0.43732053, Validation loss: 0.43730267, Gradient norm: 5.36836351
INFO:root:At the start of the epoch: mem (CPU python)=5203.37109375MB; mem (CPU total)=13175.21484375MB
INFO:root:[   38] Training loss: 0.44032194, Validation loss: 0.43548888, Gradient norm: 5.50091101
INFO:root:At the start of the epoch: mem (CPU python)=5224.578125MB; mem (CPU total)=13559.12109375MB
INFO:root:[   39] Training loss: 0.43625893, Validation loss: 0.45175429, Gradient norm: 5.37884803
INFO:root:At the start of the epoch: mem (CPU python)=5245.796875MB; mem (CPU total)=13235.765625MB
INFO:root:[   40] Training loss: 0.43651602, Validation loss: 0.44415333, Gradient norm: 5.63767189
INFO:root:At the start of the epoch: mem (CPU python)=5266.984375MB; mem (CPU total)=13262.62109375MB
INFO:root:[   41] Training loss: 0.43500699, Validation loss: 0.44127593, Gradient norm: 5.27894076
INFO:root:At the start of the epoch: mem (CPU python)=5292.1796875MB; mem (CPU total)=13644.9140625MB
INFO:root:[   42] Training loss: 0.43254400, Validation loss: 0.44187252, Gradient norm: 5.36816025
INFO:root:At the start of the epoch: mem (CPU python)=5313.90625MB; mem (CPU total)=13340.42578125MB
INFO:root:[   43] Training loss: 0.43300395, Validation loss: 0.44271786, Gradient norm: 5.41459311
INFO:root:At the start of the epoch: mem (CPU python)=5335.09765625MB; mem (CPU total)=13346.7109375MB
INFO:root:[   44] Training loss: 0.43539257, Validation loss: 0.44447473, Gradient norm: 5.54836039
INFO:root:At the start of the epoch: mem (CPU python)=5356.29296875MB; mem (CPU total)=13838.8203125MB
INFO:root:[   45] Training loss: 0.43050140, Validation loss: 0.42169557, Gradient norm: 5.32237580
INFO:root:At the start of the epoch: mem (CPU python)=5377.49609375MB; mem (CPU total)=13545.02734375MB
INFO:root:[   46] Training loss: 0.43085550, Validation loss: 0.42626448, Gradient norm: 5.43805904
INFO:root:At the start of the epoch: mem (CPU python)=5398.69921875MB; mem (CPU total)=13450.84765625MB
INFO:root:[   47] Training loss: 0.43131171, Validation loss: 0.44649836, Gradient norm: 5.48791526
INFO:root:At the start of the epoch: mem (CPU python)=5419.8984375MB; mem (CPU total)=14268.4375MB
INFO:root:[   48] Training loss: 0.43127823, Validation loss: 0.43508429, Gradient norm: 5.55298473
INFO:root:At the start of the epoch: mem (CPU python)=5441.09375MB; mem (CPU total)=13540.05078125MB
INFO:root:[   49] Training loss: 0.43131386, Validation loss: 0.44160689, Gradient norm: 5.66430895
INFO:root:At the start of the epoch: mem (CPU python)=5462.29296875MB; mem (CPU total)=13925.8828125MB
INFO:root:[   50] Training loss: 0.42897509, Validation loss: 0.43007580, Gradient norm: 5.70425153
INFO:root:At the start of the epoch: mem (CPU python)=5483.3984375MB; mem (CPU total)=13806.0234375MB
INFO:root:[   51] Training loss: 0.43120307, Validation loss: 0.42604286, Gradient norm: 5.67417414
INFO:root:At the start of the epoch: mem (CPU python)=5504.6953125MB; mem (CPU total)=14088.078125MB
INFO:root:[   52] Training loss: 0.42932644, Validation loss: 0.44737893, Gradient norm: 5.85042828
INFO:root:At the start of the epoch: mem (CPU python)=5525.8125MB; mem (CPU total)=14350.82421875MB
INFO:root:[   53] Training loss: 0.45037757, Validation loss: 0.52759215, Gradient norm: 6.31691859
INFO:root:At the start of the epoch: mem (CPU python)=5547.09375MB; mem (CPU total)=14228.296875MB
INFO:root:[   54] Training loss: 0.45948296, Validation loss: 0.46346899, Gradient norm: 7.46873570
INFO:root:At the start of the epoch: mem (CPU python)=5573.2421875MB; mem (CPU total)=14168.08203125MB
INFO:root:[   55] Training loss: 0.43103659, Validation loss: 0.43778495, Gradient norm: 5.60661578
INFO:root:At the start of the epoch: mem (CPU python)=5595.10546875MB; mem (CPU total)=14317.09375MB
INFO:root:[   56] Training loss: 0.42806617, Validation loss: 0.43562024, Gradient norm: 5.35814009
INFO:root:At the start of the epoch: mem (CPU python)=5616.41796875MB; mem (CPU total)=14544.5859375MB
INFO:root:[   57] Training loss: 0.42638251, Validation loss: 0.42735990, Gradient norm: 5.51421459
INFO:root:At the start of the epoch: mem (CPU python)=5637.8828125MB; mem (CPU total)=13785.16015625MB
INFO:root:[   58] Training loss: 0.42648572, Validation loss: 0.42604307, Gradient norm: 5.66352416
INFO:root:At the start of the epoch: mem (CPU python)=5659.08984375MB; mem (CPU total)=14614.625MB
INFO:root:[   59] Training loss: 0.42500541, Validation loss: 0.42502461, Gradient norm: 5.71989154
INFO:root:At the start of the epoch: mem (CPU python)=5680.2890625MB; mem (CPU total)=14668.5546875MB
INFO:root:[   60] Training loss: 0.42612599, Validation loss: 0.43819999, Gradient norm: 5.89325364
INFO:root:At the start of the epoch: mem (CPU python)=5701.48046875MB; mem (CPU total)=13996.42578125MB
INFO:root:[   61] Training loss: 0.42789543, Validation loss: 0.44127595, Gradient norm: 5.89303359
INFO:root:At the start of the epoch: mem (CPU python)=5722.64453125MB; mem (CPU total)=14704.43359375MB
INFO:root:[   62] Training loss: 0.42580079, Validation loss: 0.42459150, Gradient norm: 5.98848764
INFO:root:At the start of the epoch: mem (CPU python)=5743.8984375MB; mem (CPU total)=14746.140625MB
INFO:root:[   63] Training loss: 0.42781023, Validation loss: 0.42746961, Gradient norm: 5.99062379
INFO:root:At the start of the epoch: mem (CPU python)=5769.01953125MB; mem (CPU total)=14036.17578125MB
INFO:root:[   64] Training loss: 0.42620476, Validation loss: 0.43079977, Gradient norm: 5.87562820
INFO:root:At the start of the epoch: mem (CPU python)=5790.79296875MB; mem (CPU total)=14853.2109375MB
INFO:root:[   65] Training loss: 0.42574881, Validation loss: 0.44640652, Gradient norm: 5.95623768
INFO:root:At the start of the epoch: mem (CPU python)=5811.984375MB; mem (CPU total)=14879.6796875MB
INFO:root:[   66] Training loss: 0.42531436, Validation loss: 0.41857125, Gradient norm: 5.85496047
INFO:root:At the start of the epoch: mem (CPU python)=5836.76171875MB; mem (CPU total)=14545.41796875MB
INFO:root:[   67] Training loss: 0.42487187, Validation loss: 0.42997250, Gradient norm: 5.98160316
INFO:root:At the start of the epoch: mem (CPU python)=5857.93359375MB; mem (CPU total)=14900.8203125MB
INFO:root:[   68] Training loss: 0.72566925, Validation loss: 0.51321902, Gradient norm: 11.97783804
INFO:root:At the start of the epoch: mem (CPU python)=5879.1328125MB; mem (CPU total)=14950.3828125MB
INFO:root:[   69] Training loss: 0.47785881, Validation loss: 0.44888223, Gradient norm: 7.19532105
INFO:root:At the start of the epoch: mem (CPU python)=5900.3203125MB; mem (CPU total)=14947.53515625MB
INFO:root:[   70] Training loss: 0.44370794, Validation loss: 0.45508438, Gradient norm: 6.36453711
INFO:root:At the start of the epoch: mem (CPU python)=5921.46484375MB; mem (CPU total)=14975.28515625MB
INFO:root:[   71] Training loss: 0.43673574, Validation loss: 0.43682176, Gradient norm: 6.39055178
INFO:root:At the start of the epoch: mem (CPU python)=5945.4921875MB; mem (CPU total)=15036.0234375MB
INFO:root:[   72] Training loss: 0.43226631, Validation loss: 0.44368712, Gradient norm: 6.39129934
INFO:root:At the start of the epoch: mem (CPU python)=5966.6640625MB; mem (CPU total)=15076.03125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   73] Training loss: 0.42998953, Validation loss: 0.46580656, Gradient norm: 6.54797594
INFO:root:At the start of the epoch: mem (CPU python)=5988.75MB; mem (CPU total)=15103.12890625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   74] Training loss: 0.40474193, Validation loss: 0.41738404, Gradient norm: 5.87220103
INFO:root:At the start of the epoch: mem (CPU python)=6009.921875MB; mem (CPU total)=15104.1484375MB
INFO:root:[   75] Training loss: 0.39616575, Validation loss: 0.40557991, Gradient norm: 6.48327755
INFO:root:At the start of the epoch: mem (CPU python)=6031.09375MB; mem (CPU total)=15171.91796875MB
INFO:root:[   76] Training loss: 0.39317950, Validation loss: 0.40380032, Gradient norm: 6.96956838
INFO:root:At the start of the epoch: mem (CPU python)=6052.2578125MB; mem (CPU total)=15201.734375MB
INFO:root:[   77] Training loss: 0.39366431, Validation loss: 0.40198066, Gradient norm: 8.73266418
INFO:root:At the start of the epoch: mem (CPU python)=6073.42578125MB; mem (CPU total)=15213.3046875MB
INFO:root:[   78] Training loss: 0.39490471, Validation loss: 0.40408398, Gradient norm: 10.25487988
INFO:root:At the start of the epoch: mem (CPU python)=6094.78125MB; mem (CPU total)=15237.94921875MB
INFO:root:[   79] Training loss: 0.39531149, Validation loss: 0.42546453, Gradient norm: 11.44388946
INFO:root:At the start of the epoch: mem (CPU python)=6115.75390625MB; mem (CPU total)=14534.15625MB
INFO:root:[   80] Training loss: 0.39887834, Validation loss: 0.40661611, Gradient norm: 12.84404962
INFO:root:At the start of the epoch: mem (CPU python)=6137.45703125MB; mem (CPU total)=14530.30078125MB
INFO:root:[   81] Training loss: 0.39869557, Validation loss: 0.40294653, Gradient norm: 13.75108284
INFO:root:At the start of the epoch: mem (CPU python)=6158.625MB; mem (CPU total)=14558.12109375MB
INFO:root:[   82] Training loss: 0.39943564, Validation loss: 0.41131331, Gradient norm: 14.44740364
INFO:root:At the start of the epoch: mem (CPU python)=6182.51171875MB; mem (CPU total)=14588.6953125MB
INFO:root:[   83] Training loss: 0.40250587, Validation loss: 0.40420359, Gradient norm: 16.51467008
INFO:root:At the start of the epoch: mem (CPU python)=6203.8125MB; mem (CPU total)=14592.5078125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   84] Training loss: 0.40072681, Validation loss: 0.41590171, Gradient norm: 16.47170073
INFO:root:At the start of the epoch: mem (CPU python)=6225.39453125MB; mem (CPU total)=14625.7734375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   85] Training loss: 0.38961700, Validation loss: 0.40341684, Gradient norm: 12.21623836
INFO:root:At the start of the epoch: mem (CPU python)=6246.5703125MB; mem (CPU total)=14691.078125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   86] Training loss: 0.38566675, Validation loss: 0.39425033, Gradient norm: 11.55480658
INFO:root:At the start of the epoch: mem (CPU python)=6268.26171875MB; mem (CPU total)=14697.8984375MB
INFO:root:[   87] Training loss: 0.38300107, Validation loss: 0.39400187, Gradient norm: 9.33538581
INFO:root:At the start of the epoch: mem (CPU python)=6289.42578125MB; mem (CPU total)=14723.91796875MB
INFO:root:[   88] Training loss: 0.38302657, Validation loss: 0.39312165, Gradient norm: 9.96066879
INFO:root:At the start of the epoch: mem (CPU python)=6310.5859375MB; mem (CPU total)=14756.90625MB
INFO:root:[   89] Training loss: 0.38297506, Validation loss: 0.39187137, Gradient norm: 11.34356866
INFO:root:At the start of the epoch: mem (CPU python)=6334.87890625MB; mem (CPU total)=14793.58984375MB
INFO:root:[   90] Training loss: 0.38313202, Validation loss: 0.39493145, Gradient norm: 11.28935749
INFO:root:At the start of the epoch: mem (CPU python)=6356.1640625MB; mem (CPU total)=14821.50390625MB
INFO:root:[   91] Training loss: 0.38291745, Validation loss: 0.39251039, Gradient norm: 11.73464498
INFO:root:At the start of the epoch: mem (CPU python)=6377.671875MB; mem (CPU total)=14853.95703125MB
INFO:root:[   92] Training loss: 0.38344495, Validation loss: 0.39033752, Gradient norm: 13.51219912
INFO:root:At the start of the epoch: mem (CPU python)=6398.83984375MB; mem (CPU total)=14878.95703125MB
INFO:root:[   93] Training loss: 0.38348954, Validation loss: 0.39126885, Gradient norm: 13.90638373
INFO:root:At the start of the epoch: mem (CPU python)=6420.00390625MB; mem (CPU total)=14894.62890625MB
INFO:root:[   94] Training loss: 0.38374708, Validation loss: 0.39243595, Gradient norm: 15.03309252
INFO:root:At the start of the epoch: mem (CPU python)=6441.16796875MB; mem (CPU total)=14962.9453125MB
INFO:root:[   95] Training loss: 0.38340179, Validation loss: 0.39024106, Gradient norm: 16.08067325
INFO:root:At the start of the epoch: mem (CPU python)=6464.109375MB; mem (CPU total)=14976.52734375MB
INFO:root:[   96] Training loss: 0.38421994, Validation loss: 0.39104363, Gradient norm: 16.01346670
INFO:root:At the start of the epoch: mem (CPU python)=6485.2734375MB; mem (CPU total)=15008.40625MB
INFO:root:[   97] Training loss: 0.38428201, Validation loss: 0.39340196, Gradient norm: 17.16742220
INFO:root:At the start of the epoch: mem (CPU python)=6506.9296875MB; mem (CPU total)=15035.41796875MB
INFO:root:[   98] Training loss: 0.38401605, Validation loss: 0.39142350, Gradient norm: 17.61430650
INFO:root:At the start of the epoch: mem (CPU python)=6528.09375MB; mem (CPU total)=15065.27734375MB
INFO:root:[   99] Training loss: 0.38461336, Validation loss: 0.39234798, Gradient norm: 20.25539940
INFO:root:At the start of the epoch: mem (CPU python)=6549.25390625MB; mem (CPU total)=14883.78125MB
INFO:root:[  100] Training loss: 0.38391818, Validation loss: 0.39146890, Gradient norm: 18.83280819
INFO:root:At the start of the epoch: mem (CPU python)=6570.41796875MB; mem (CPU total)=15138.5MB
INFO:root:[  101] Training loss: 0.38459424, Validation loss: 0.39547370, Gradient norm: 19.47219327
INFO:root:At the start of the epoch: mem (CPU python)=6591.76171875MB; mem (CPU total)=15156.22265625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  102] Training loss: 0.38473925, Validation loss: 0.39127822, Gradient norm: 20.43603217
INFO:root:At the start of the epoch: mem (CPU python)=6613.55859375MB; mem (CPU total)=15204.890625MB
INFO:root:[  103] Training loss: 0.38251258, Validation loss: 0.39029793, Gradient norm: 16.72391007
INFO:root:At the start of the epoch: mem (CPU python)=6634.7578125MB; mem (CPU total)=15236.140625MB
INFO:root:[  104] Training loss: 0.38237098, Validation loss: 0.39139174, Gradient norm: 16.97847553
INFO:root:At the start of the epoch: mem (CPU python)=6656.87109375MB; mem (CPU total)=15249.76953125MB
INFO:root:EP 104: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=6678.515625MB; mem (CPU total)=15274.49609375MB
INFO:root:[  106] Training loss: 0.46819157, Validation loss: 0.47189948, Gradient norm: 26.75847511
INFO:root:At the start of the epoch: mem (CPU python)=6700.13671875MB; mem (CPU total)=15305.73828125MB
INFO:root:[  107] Training loss: 0.46471460, Validation loss: 0.47120735, Gradient norm: 25.05819634
INFO:root:At the start of the epoch: mem (CPU python)=6721.3046875MB; mem (CPU total)=15360.1328125MB
INFO:root:[  108] Training loss: 0.46414345, Validation loss: 0.46960746, Gradient norm: 24.67952361
INFO:root:At the start of the epoch: mem (CPU python)=6742.46484375MB; mem (CPU total)=15375.47265625MB
INFO:root:[  109] Training loss: 0.46425736, Validation loss: 0.46903610, Gradient norm: 26.03995141
INFO:root:At the start of the epoch: mem (CPU python)=6763.6328125MB; mem (CPU total)=15362.37890625MB
INFO:root:[  110] Training loss: 0.46412069, Validation loss: 0.47202515, Gradient norm: 25.74935124
INFO:root:At the start of the epoch: mem (CPU python)=6784.796875MB; mem (CPU total)=15409.50390625MB
INFO:root:[  111] Training loss: 0.46333945, Validation loss: 0.46982128, Gradient norm: 26.56043198
INFO:root:At the start of the epoch: mem (CPU python)=6805.9609375MB; mem (CPU total)=15432.390625MB
INFO:root:[  112] Training loss: 0.46364872, Validation loss: 0.46898373, Gradient norm: 26.83730813
INFO:root:At the start of the epoch: mem (CPU python)=6827.12890625MB; mem (CPU total)=15463.24609375MB
INFO:root:[  113] Training loss: 0.46327189, Validation loss: 0.47035285, Gradient norm: 26.57092859
INFO:root:At the start of the epoch: mem (CPU python)=6848.29296875MB; mem (CPU total)=15458.55859375MB
INFO:root:[  114] Training loss: 0.46268763, Validation loss: 0.46821331, Gradient norm: 27.17694986
INFO:root:At the start of the epoch: mem (CPU python)=6869.51953125MB; mem (CPU total)=15491.171875MB
INFO:root:[  115] Training loss: 0.46304491, Validation loss: 0.46766946, Gradient norm: 28.35243801
INFO:root:At the start of the epoch: mem (CPU python)=6890.9375MB; mem (CPU total)=15537.1015625MB
INFO:root:[  116] Training loss: 0.46270100, Validation loss: 0.47016727, Gradient norm: 27.13699931
INFO:root:At the start of the epoch: mem (CPU python)=6912.99609375MB; mem (CPU total)=15578.77734375MB
INFO:root:[  117] Training loss: 0.46334488, Validation loss: 0.46954437, Gradient norm: 29.26400992
INFO:root:At the start of the epoch: mem (CPU python)=6934.625MB; mem (CPU total)=15613.37890625MB
INFO:root:[  118] Training loss: 0.46244439, Validation loss: 0.46959749, Gradient norm: 28.07578953
INFO:root:At the start of the epoch: mem (CPU python)=6956.23828125MB; mem (CPU total)=15638.11328125MB
INFO:root:[  119] Training loss: 0.46284043, Validation loss: 0.46916136, Gradient norm: 29.86673125
INFO:root:At the start of the epoch: mem (CPU python)=6977.75MB; mem (CPU total)=15678.14453125MB
INFO:root:[  120] Training loss: 0.46193411, Validation loss: 0.46878082, Gradient norm: 28.75777422
INFO:root:At the start of the epoch: mem (CPU python)=6999.23046875MB; mem (CPU total)=15721.421875MB
INFO:root:[  121] Training loss: 0.46184754, Validation loss: 0.46953312, Gradient norm: 30.41978507
INFO:root:At the start of the epoch: mem (CPU python)=7021.0546875MB; mem (CPU total)=15755.35546875MB
INFO:root:[  122] Training loss: 0.46254031, Validation loss: 0.46906461, Gradient norm: 29.22682045
INFO:root:At the start of the epoch: mem (CPU python)=7042.53515625MB; mem (CPU total)=15784.578125MB
INFO:root:[  123] Training loss: 0.46200097, Validation loss: 0.46844133, Gradient norm: 29.73888853
INFO:root:At the start of the epoch: mem (CPU python)=7063.95703125MB; mem (CPU total)=15818.5234375MB
INFO:root:[  124] Training loss: 0.46193092, Validation loss: 0.46716598, Gradient norm: 29.74160668
INFO:root:At the start of the epoch: mem (CPU python)=7086.015625MB; mem (CPU total)=15843.328125MB
INFO:root:[  125] Training loss: 0.46189437, Validation loss: 0.46861945, Gradient norm: 31.46169606
INFO:root:At the start of the epoch: mem (CPU python)=7108.76953125MB; mem (CPU total)=15924.4140625MB
INFO:root:[  126] Training loss: 0.46215583, Validation loss: 0.46745186, Gradient norm: 31.94532320
INFO:root:At the start of the epoch: mem (CPU python)=7130.08203125MB; mem (CPU total)=15943.4375MB
INFO:root:[  127] Training loss: 0.46207596, Validation loss: 0.46745115, Gradient norm: 31.10952382
INFO:root:At the start of the epoch: mem (CPU python)=7151.65625MB; mem (CPU total)=15963.3125MB
INFO:root:[  128] Training loss: 0.46180241, Validation loss: 0.46676753, Gradient norm: 31.78178436
INFO:root:At the start of the epoch: mem (CPU python)=7173.15625MB; mem (CPU total)=15999.30859375MB
INFO:root:[  129] Training loss: 0.46161935, Validation loss: 0.46901221, Gradient norm: 32.92331697
INFO:root:At the start of the epoch: mem (CPU python)=7194.34765625MB; mem (CPU total)=16031.0625MB
INFO:root:[  130] Training loss: 0.46114988, Validation loss: 0.47036552, Gradient norm: 32.82897401
INFO:root:At the start of the epoch: mem (CPU python)=7215.78125MB; mem (CPU total)=16074.7421875MB
INFO:root:[  131] Training loss: 0.46203954, Validation loss: 0.46756501, Gradient norm: 33.30584312
INFO:root:At the start of the epoch: mem (CPU python)=7238.4375MB; mem (CPU total)=16090.52734375MB
INFO:root:[  132] Training loss: 0.46289860, Validation loss: 0.46973891, Gradient norm: 37.07011957
INFO:root:At the start of the epoch: mem (CPU python)=7265.82421875MB; mem (CPU total)=16150.38671875MB
INFO:root:[  133] Training loss: 0.46180918, Validation loss: 0.46820279, Gradient norm: 33.61472244
INFO:root:At the start of the epoch: mem (CPU python)=7288.11328125MB; mem (CPU total)=16153.02734375MB
INFO:root:[  134] Training loss: 0.46127450, Validation loss: 0.46756619, Gradient norm: 34.07038835
INFO:root:At the start of the epoch: mem (CPU python)=7309.27734375MB; mem (CPU total)=16251.5859375MB
INFO:root:[  135] Training loss: 0.46080752, Validation loss: 0.46874054, Gradient norm: 34.05973842
INFO:root:At the start of the epoch: mem (CPU python)=7330.4453125MB; mem (CPU total)=16267.31640625MB
INFO:root:[  136] Training loss: 0.46159066, Validation loss: 0.46861048, Gradient norm: 33.82469005
INFO:root:At the start of the epoch: mem (CPU python)=7352.734375MB; mem (CPU total)=16317.640625MB
INFO:root:[  137] Training loss: 0.46148048, Validation loss: 0.46736728, Gradient norm: 35.20308401
INFO:root:At the start of the epoch: mem (CPU python)=7375.3359375MB; mem (CPU total)=16327.56640625MB
INFO:root:EP 137: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=7396.94140625MB; mem (CPU total)=16358.94921875MB
INFO:root:Training the model took 3939.338s.
INFO:root:Emptying the cuda cache took 0.038s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.47139
INFO:root:EnergyScoreValidation: 0.35637
INFO:root:CRPSValidation: 0.14731
INFO:root:Gaussian NLLValidation: 0.42442
INFO:root:CoverageValidation: 0.73067
INFO:root:IntervalWidthValidation: 0.53802
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.38006
INFO:root:EnergyScoreTest: 0.29328
INFO:root:CRPSTest: 0.11929
INFO:root:Gaussian NLLTest: 0.49923
INFO:root:CoverageTest: 0.67774
INFO:root:IntervalWidthTest: 0.37841
INFO:root:After validation: mem (CPU python)=7422.88671875MB; mem (CPU total)=16617.203125MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=7422.88671875MB; mem (CPU total)=16619.22265625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 48234496
INFO:root:After setting up the model: mem (CPU python)=7430.78515625MB; mem (CPU total)=16627.1640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=7430.78515625MB; mem (CPU total)=16628.015625MB
INFO:root:[    1] Training loss: 0.76417378, Validation loss: 0.71675641, Gradient norm: 0.41534535
INFO:root:At the start of the epoch: mem (CPU python)=7455.80078125MB; mem (CPU total)=16649.21484375MB
INFO:root:[    2] Training loss: 0.66164627, Validation loss: 0.61424280, Gradient norm: 0.80360545
INFO:root:At the start of the epoch: mem (CPU python)=7476.96875MB; mem (CPU total)=16691.359375MB
INFO:root:[    3] Training loss: 0.59344618, Validation loss: 0.56514622, Gradient norm: 1.30334063
INFO:root:At the start of the epoch: mem (CPU python)=7498.14453125MB; mem (CPU total)=16720.57421875MB
INFO:root:[    4] Training loss: 0.54769104, Validation loss: 0.52620559, Gradient norm: 1.57848719
INFO:root:At the start of the epoch: mem (CPU python)=7519.3046875MB; mem (CPU total)=16761.80859375MB
INFO:root:[    5] Training loss: 0.51237017, Validation loss: 0.50096721, Gradient norm: 1.85631907
INFO:root:At the start of the epoch: mem (CPU python)=7540.46875MB; mem (CPU total)=16777.421875MB
INFO:root:[    6] Training loss: 0.49989705, Validation loss: 0.49954963, Gradient norm: 2.06597012
INFO:root:At the start of the epoch: mem (CPU python)=7561.6328125MB; mem (CPU total)=16814.1015625MB
INFO:root:[    7] Training loss: 0.49284612, Validation loss: 0.48902288, Gradient norm: 2.27078788
INFO:root:At the start of the epoch: mem (CPU python)=7582.80078125MB; mem (CPU total)=16843.44921875MB
INFO:root:[    8] Training loss: 0.48697986, Validation loss: 0.48340648, Gradient norm: 2.47934492
INFO:root:At the start of the epoch: mem (CPU python)=7603.96484375MB; mem (CPU total)=16852.44140625MB
INFO:root:[    9] Training loss: 0.48341415, Validation loss: 0.48005244, Gradient norm: 2.68872553
INFO:root:At the start of the epoch: mem (CPU python)=7625.12890625MB; mem (CPU total)=16896.21875MB
INFO:root:[   10] Training loss: 0.48143649, Validation loss: 0.48230162, Gradient norm: 2.76260752
INFO:root:At the start of the epoch: mem (CPU python)=7646.29296875MB; mem (CPU total)=16929.69921875MB
INFO:root:[   11] Training loss: 0.47745048, Validation loss: 0.47595156, Gradient norm: 2.96790878
INFO:root:At the start of the epoch: mem (CPU python)=7667.453125MB; mem (CPU total)=16968.734375MB
INFO:root:[   12] Training loss: 0.47799657, Validation loss: 0.48735499, Gradient norm: 3.20650062
INFO:root:At the start of the epoch: mem (CPU python)=7688.6171875MB; mem (CPU total)=17022.9921875MB
INFO:root:[   13] Training loss: 0.47477502, Validation loss: 0.47920684, Gradient norm: 3.24552034
INFO:root:At the start of the epoch: mem (CPU python)=7709.78515625MB; mem (CPU total)=17023.59375MB
INFO:root:[   14] Training loss: 0.47258469, Validation loss: 0.45477782, Gradient norm: 3.37867012
INFO:root:At the start of the epoch: mem (CPU python)=7730.94921875MB; mem (CPU total)=17052.58984375MB
INFO:root:[   15] Training loss: 0.46966771, Validation loss: 0.48778492, Gradient norm: 3.39819597
INFO:root:At the start of the epoch: mem (CPU python)=7752.11328125MB; mem (CPU total)=17084.8203125MB
INFO:root:[   16] Training loss: 0.46757133, Validation loss: 0.47658577, Gradient norm: 3.51902085
INFO:root:At the start of the epoch: mem (CPU python)=7773.27734375MB; mem (CPU total)=17107.671875MB
INFO:root:[   17] Training loss: 0.46664399, Validation loss: 0.46721679, Gradient norm: 3.72527228
INFO:root:At the start of the epoch: mem (CPU python)=7794.44140625MB; mem (CPU total)=17152.046875MB
INFO:root:[   18] Training loss: 0.46485005, Validation loss: 0.46968487, Gradient norm: 3.69684889
INFO:root:At the start of the epoch: mem (CPU python)=7815.609375MB; mem (CPU total)=17193.1875MB
INFO:root:[   19] Training loss: 0.46451152, Validation loss: 0.46185506, Gradient norm: 3.85804738
INFO:root:At the start of the epoch: mem (CPU python)=7836.7734375MB; mem (CPU total)=17198.5625MB
INFO:root:[   20] Training loss: 0.46224013, Validation loss: 0.46567851, Gradient norm: 3.99384595
INFO:root:At the start of the epoch: mem (CPU python)=7857.93359375MB; mem (CPU total)=17225.85546875MB
INFO:root:[   21] Training loss: 0.46156466, Validation loss: 0.45676389, Gradient norm: 4.00314893
INFO:root:At the start of the epoch: mem (CPU python)=7879.09375MB; mem (CPU total)=17258.7421875MB
INFO:root:[   22] Training loss: 0.45344959, Validation loss: 0.45224476, Gradient norm: 4.21883251
INFO:root:At the start of the epoch: mem (CPU python)=7900.26171875MB; mem (CPU total)=17293.14453125MB
INFO:root:[   23] Training loss: 0.43391710, Validation loss: 0.42902907, Gradient norm: 4.68563354
INFO:root:At the start of the epoch: mem (CPU python)=7921.4296875MB; mem (CPU total)=17331.91015625MB
INFO:root:[   24] Training loss: 0.43189840, Validation loss: 0.41970496, Gradient norm: 4.74642826
INFO:root:At the start of the epoch: mem (CPU python)=7942.59375MB; mem (CPU total)=17350.66015625MB
INFO:root:[   25] Training loss: 0.43115945, Validation loss: 0.43185396, Gradient norm: 4.94473470
INFO:root:At the start of the epoch: mem (CPU python)=7963.7578125MB; mem (CPU total)=17390.14453125MB
INFO:root:[   26] Training loss: 0.42899449, Validation loss: 0.42544566, Gradient norm: 4.99795683
INFO:root:At the start of the epoch: mem (CPU python)=7984.921875MB; mem (CPU total)=17449.03125MB
INFO:root:[   27] Training loss: 0.42785168, Validation loss: 0.43127421, Gradient norm: 5.13766014
INFO:root:At the start of the epoch: mem (CPU python)=8006.0859375MB; mem (CPU total)=17451.73828125MB
INFO:root:[   28] Training loss: 0.42770904, Validation loss: 0.43415990, Gradient norm: 5.10238914
INFO:root:At the start of the epoch: mem (CPU python)=8027.25MB; mem (CPU total)=17497.76171875MB
INFO:root:[   29] Training loss: 0.42652249, Validation loss: 0.42292805, Gradient norm: 5.13036394
INFO:root:At the start of the epoch: mem (CPU python)=8048.41796875MB; mem (CPU total)=17496.0390625MB
INFO:root:[   30] Training loss: 0.42841938, Validation loss: 0.42781146, Gradient norm: 5.38044870
INFO:root:At the start of the epoch: mem (CPU python)=8069.578125MB; mem (CPU total)=17558.41015625MB
INFO:root:[   31] Training loss: 0.42544654, Validation loss: 0.42467045, Gradient norm: 5.20484105
INFO:root:At the start of the epoch: mem (CPU python)=8090.7421875MB; mem (CPU total)=17588.39453125MB
INFO:root:[   32] Training loss: 0.42242967, Validation loss: 0.44675271, Gradient norm: 5.39820322
INFO:root:At the start of the epoch: mem (CPU python)=8111.90625MB; mem (CPU total)=17620.30859375MB
INFO:root:[   33] Training loss: 0.42322898, Validation loss: 0.42438384, Gradient norm: 5.47739767
INFO:root:At the start of the epoch: mem (CPU python)=8133.0703125MB; mem (CPU total)=17652.1484375MB
INFO:root:[   34] Training loss: 0.42530048, Validation loss: 0.43248484, Gradient norm: 5.68894238
INFO:root:At the start of the epoch: mem (CPU python)=8154.23828125MB; mem (CPU total)=17665.3515625MB
INFO:root:[   35] Training loss: 0.42247809, Validation loss: 0.44115146, Gradient norm: 5.48397191
INFO:root:At the start of the epoch: mem (CPU python)=8175.40234375MB; mem (CPU total)=17695.203125MB
INFO:root:[   36] Training loss: 0.42475659, Validation loss: 0.42695983, Gradient norm: 5.72303352
INFO:root:At the start of the epoch: mem (CPU python)=8196.56640625MB; mem (CPU total)=17729.296875MB
INFO:root:[   37] Training loss: 0.42234080, Validation loss: 0.44737293, Gradient norm: 5.85594930
INFO:root:At the start of the epoch: mem (CPU python)=8217.7265625MB; mem (CPU total)=17745.6875MB
INFO:root:[   38] Training loss: 0.42429059, Validation loss: 0.44175864, Gradient norm: 5.92432393
INFO:root:At the start of the epoch: mem (CPU python)=8238.890625MB; mem (CPU total)=17657.6171875MB
INFO:root:[   39] Training loss: 0.42372826, Validation loss: 0.45221203, Gradient norm: 6.10683669
INFO:root:At the start of the epoch: mem (CPU python)=8260.0546875MB; mem (CPU total)=17825.34375MB
INFO:root:[   40] Training loss: 0.42338575, Validation loss: 0.43018196, Gradient norm: 6.04131300
INFO:root:At the start of the epoch: mem (CPU python)=8281.21875MB; mem (CPU total)=17885.9921875MB
INFO:root:[   41] Training loss: 0.42156178, Validation loss: 0.42950424, Gradient norm: 6.04140176
INFO:root:At the start of the epoch: mem (CPU python)=8302.3828125MB; mem (CPU total)=17926.43359375MB
INFO:root:[   42] Training loss: 0.42146719, Validation loss: 0.44822806, Gradient norm: 6.16755531
INFO:root:At the start of the epoch: mem (CPU python)=8323.546875MB; mem (CPU total)=17908.4140625MB
INFO:root:[   43] Training loss: 0.42269208, Validation loss: 0.43519472, Gradient norm: 6.37207929
INFO:root:At the start of the epoch: mem (CPU python)=8344.7109375MB; mem (CPU total)=17958.57421875MB
INFO:root:[   44] Training loss: 0.42023071, Validation loss: 0.45347857, Gradient norm: 6.40756440
INFO:root:At the start of the epoch: mem (CPU python)=8365.87890625MB; mem (CPU total)=17954.58203125MB
INFO:root:[   45] Training loss: 0.42242705, Validation loss: 0.41465775, Gradient norm: 6.54171899
INFO:root:At the start of the epoch: mem (CPU python)=8387.04296875MB; mem (CPU total)=17992.5078125MB
INFO:root:[   46] Training loss: 0.42118883, Validation loss: 0.42787918, Gradient norm: 6.60118433
INFO:root:At the start of the epoch: mem (CPU python)=8408.20703125MB; mem (CPU total)=18050.8046875MB
INFO:root:[   47] Training loss: 0.42271270, Validation loss: 0.44518945, Gradient norm: 6.75816619
INFO:root:At the start of the epoch: mem (CPU python)=8429.37109375MB; mem (CPU total)=18065.10546875MB
INFO:root:[   48] Training loss: 0.46416046, Validation loss: 0.44089326, Gradient norm: 8.47693013
INFO:root:At the start of the epoch: mem (CPU python)=8450.53515625MB; mem (CPU total)=18096.9921875MB
INFO:root:[   49] Training loss: 0.41921128, Validation loss: 0.42627633, Gradient norm: 6.45945289
INFO:root:At the start of the epoch: mem (CPU python)=8471.6953125MB; mem (CPU total)=18132.10546875MB
INFO:root:[   50] Training loss: 0.43582931, Validation loss: 0.43623050, Gradient norm: 7.48059123
INFO:root:At the start of the epoch: mem (CPU python)=8492.86328125MB; mem (CPU total)=18152.1171875MB
INFO:root:[   51] Training loss: 0.41759183, Validation loss: 0.41959680, Gradient norm: 6.24427374
INFO:root:At the start of the epoch: mem (CPU python)=8514.02734375MB; mem (CPU total)=18177.8515625MB
INFO:root:[   52] Training loss: 0.41615710, Validation loss: 0.46076942, Gradient norm: 6.35790572
INFO:root:At the start of the epoch: mem (CPU python)=8535.19140625MB; mem (CPU total)=18223.921875MB
INFO:root:[   53] Training loss: 0.41634602, Validation loss: 0.44597618, Gradient norm: 6.53323920
INFO:root:At the start of the epoch: mem (CPU python)=8556.35546875MB; mem (CPU total)=18246.0MB
INFO:root:[   54] Training loss: 0.41584321, Validation loss: 0.45642604, Gradient norm: 6.66090521
INFO:root:At the start of the epoch: mem (CPU python)=8577.515625MB; mem (CPU total)=18265.359375MB
INFO:root:[   55] Training loss: 0.65173426, Validation loss: 0.52820041, Gradient norm: 12.23496461
INFO:root:At the start of the epoch: mem (CPU python)=8598.68359375MB; mem (CPU total)=18338.33984375MB
INFO:root:[   56] Training loss: 0.46368895, Validation loss: 0.48225012, Gradient norm: 8.38775184
INFO:root:At the start of the epoch: mem (CPU python)=8619.84765625MB; mem (CPU total)=18363.19140625MB
INFO:root:[   57] Training loss: 0.42907754, Validation loss: 0.44800165, Gradient norm: 7.04345664
INFO:root:At the start of the epoch: mem (CPU python)=8641.01171875MB; mem (CPU total)=18358.984375MB
INFO:root:[   58] Training loss: 0.42206328, Validation loss: 0.42269570, Gradient norm: 6.89113514
INFO:root:At the start of the epoch: mem (CPU python)=8662.171875MB; mem (CPU total)=18398.76953125MB
INFO:root:[   59] Training loss: 0.42018820, Validation loss: 0.44831780, Gradient norm: 6.84275215
INFO:root:At the start of the epoch: mem (CPU python)=8683.3359375MB; mem (CPU total)=18438.3984375MB
INFO:root:[   60] Training loss: 0.41958548, Validation loss: 0.43086847, Gradient norm: 7.10198653
INFO:root:At the start of the epoch: mem (CPU python)=8704.5MB; mem (CPU total)=18454.453125MB
INFO:root:[   61] Training loss: 0.41834126, Validation loss: 0.42383745, Gradient norm: 7.15832855
INFO:root:At the start of the epoch: mem (CPU python)=8725.6640625MB; mem (CPU total)=18486.07421875MB
INFO:root:[   62] Training loss: 0.41605274, Validation loss: 0.42916727, Gradient norm: 7.33609589
INFO:root:At the start of the epoch: mem (CPU python)=8746.83203125MB; mem (CPU total)=18516.0078125MB
INFO:root:[   63] Training loss: 0.41778166, Validation loss: 0.45445890, Gradient norm: 7.50975771
INFO:root:At the start of the epoch: mem (CPU python)=8767.99609375MB; mem (CPU total)=18548.58984375MB
INFO:root:[   64] Training loss: 0.41819686, Validation loss: 0.43178493, Gradient norm: 7.63079988
INFO:root:At the start of the epoch: mem (CPU python)=8789.16015625MB; mem (CPU total)=18600.9921875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   65] Training loss: 0.41614221, Validation loss: 0.43507333, Gradient norm: 7.58850034
INFO:root:At the start of the epoch: mem (CPU python)=8810.328125MB; mem (CPU total)=18456.8203125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   66] Training loss: 0.38852979, Validation loss: 0.40143241, Gradient norm: 7.09175497
INFO:root:At the start of the epoch: mem (CPU python)=8831.49609375MB; mem (CPU total)=18641.2421875MB
INFO:root:[   67] Training loss: 0.37789998, Validation loss: 0.40303375, Gradient norm: 7.28329364
INFO:root:At the start of the epoch: mem (CPU python)=8852.65625MB; mem (CPU total)=18654.21484375MB
INFO:root:[   68] Training loss: 0.37627117, Validation loss: 0.39351221, Gradient norm: 9.12706906
INFO:root:At the start of the epoch: mem (CPU python)=8873.8203125MB; mem (CPU total)=18692.9140625MB
INFO:root:[   69] Training loss: 0.38009012, Validation loss: 0.39660285, Gradient norm: 11.39807941
INFO:root:At the start of the epoch: mem (CPU python)=8894.984375MB; mem (CPU total)=18773.1796875MB
INFO:root:[   70] Training loss: 0.38037339, Validation loss: 0.39701801, Gradient norm: 12.38485160
INFO:root:At the start of the epoch: mem (CPU python)=8916.1484375MB; mem (CPU total)=18777.87109375MB
INFO:root:[   71] Training loss: 0.38177051, Validation loss: 0.39884052, Gradient norm: 14.28506780
INFO:root:At the start of the epoch: mem (CPU python)=8937.30859375MB; mem (CPU total)=18792.76953125MB
INFO:root:[   72] Training loss: 0.38000667, Validation loss: 0.39681635, Gradient norm: 14.49301131
INFO:root:At the start of the epoch: mem (CPU python)=8958.47265625MB; mem (CPU total)=18825.79296875MB
INFO:root:[   73] Training loss: 0.38609426, Validation loss: 0.40075456, Gradient norm: 16.58962382
INFO:root:At the start of the epoch: mem (CPU python)=8979.640625MB; mem (CPU total)=18858.1171875MB
INFO:root:[   74] Training loss: 0.38251468, Validation loss: 0.40011157, Gradient norm: 16.63652267
INFO:root:At the start of the epoch: mem (CPU python)=9000.8046875MB; mem (CPU total)=18889.21875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   75] Training loss: 0.38454117, Validation loss: 0.42161420, Gradient norm: 17.56060863
INFO:root:At the start of the epoch: mem (CPU python)=9021.96875MB; mem (CPU total)=18920.83984375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   76] Training loss: 0.37669356, Validation loss: 0.38878447, Gradient norm: 17.08345976
INFO:root:At the start of the epoch: mem (CPU python)=9043.1328125MB; mem (CPU total)=18964.59375MB
INFO:root:[   77] Training loss: 0.36858739, Validation loss: 0.38647449, Gradient norm: 11.75284467
INFO:root:At the start of the epoch: mem (CPU python)=9064.29296875MB; mem (CPU total)=18996.49609375MB
INFO:root:[   78] Training loss: 0.36762354, Validation loss: 0.38515595, Gradient norm: 13.44170547
INFO:root:At the start of the epoch: mem (CPU python)=9085.4609375MB; mem (CPU total)=18996.92578125MB
INFO:root:[   79] Training loss: 0.36801771, Validation loss: 0.38416756, Gradient norm: 14.90937690
INFO:root:At the start of the epoch: mem (CPU python)=9106.625MB; mem (CPU total)=18970.1328125MB
INFO:root:[   80] Training loss: 0.36853558, Validation loss: 0.38598626, Gradient norm: 17.18897821
INFO:root:At the start of the epoch: mem (CPU python)=9127.7890625MB; mem (CPU total)=19042.92578125MB
INFO:root:[   81] Training loss: 0.36899881, Validation loss: 0.38511872, Gradient norm: 17.91478998
INFO:root:At the start of the epoch: mem (CPU python)=9148.953125MB; mem (CPU total)=19109.109375MB
INFO:root:[   82] Training loss: 0.37033882, Validation loss: 0.38538277, Gradient norm: 21.09718736
INFO:root:At the start of the epoch: mem (CPU python)=9170.1171875MB; mem (CPU total)=19085.8515625MB
INFO:root:[   83] Training loss: 0.36880934, Validation loss: 0.38666192, Gradient norm: 18.39634148
INFO:root:At the start of the epoch: mem (CPU python)=9191.28125MB; mem (CPU total)=19198.88671875MB
INFO:root:[   84] Training loss: 0.36921559, Validation loss: 0.38566581, Gradient norm: 19.57113964
INFO:root:At the start of the epoch: mem (CPU python)=9212.44921875MB; mem (CPU total)=19195.86328125MB
INFO:root:[   85] Training loss: 0.36878604, Validation loss: 0.39204332, Gradient norm: 21.50713274
INFO:root:At the start of the epoch: mem (CPU python)=9233.61328125MB; mem (CPU total)=19241.53125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   86] Training loss: 0.37137858, Validation loss: 0.38855963, Gradient norm: 24.88169781
INFO:root:At the start of the epoch: mem (CPU python)=9254.7734375MB; mem (CPU total)=19286.9296875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   87] Training loss: 0.36658288, Validation loss: 0.38399534, Gradient norm: 16.94855359
INFO:root:At the start of the epoch: mem (CPU python)=9275.9375MB; mem (CPU total)=19303.5234375MB
INFO:root:[   88] Training loss: 0.36414654, Validation loss: 0.38364841, Gradient norm: 13.78845988
INFO:root:At the start of the epoch: mem (CPU python)=9297.1015625MB; mem (CPU total)=19334.0703125MB
INFO:root:[   89] Training loss: 0.36384995, Validation loss: 0.38311678, Gradient norm: 14.06397143
INFO:root:At the start of the epoch: mem (CPU python)=9318.265625MB; mem (CPU total)=19356.44140625MB
INFO:root:[   90] Training loss: 0.36382652, Validation loss: 0.38098551, Gradient norm: 14.85344666
INFO:root:At the start of the epoch: mem (CPU python)=9339.4296875MB; mem (CPU total)=19395.6796875MB
INFO:root:[   91] Training loss: 0.36444570, Validation loss: 0.38121020, Gradient norm: 15.10732097
INFO:root:At the start of the epoch: mem (CPU python)=9360.59375MB; mem (CPU total)=19409.9140625MB
INFO:root:[   92] Training loss: 0.36364561, Validation loss: 0.38156124, Gradient norm: 15.47433592
INFO:root:At the start of the epoch: mem (CPU python)=9381.7578125MB; mem (CPU total)=19428.23046875MB
INFO:root:[   93] Training loss: 0.36438640, Validation loss: 0.38352658, Gradient norm: 18.09831324
INFO:root:At the start of the epoch: mem (CPU python)=9402.921875MB; mem (CPU total)=19478.125MB
INFO:root:[   94] Training loss: 0.36479021, Validation loss: 0.38385077, Gradient norm: 16.89628381
INFO:root:At the start of the epoch: mem (CPU python)=9424.08984375MB; mem (CPU total)=19521.17578125MB
INFO:root:[   95] Training loss: 0.36476436, Validation loss: 0.38105583, Gradient norm: 17.54904616
INFO:root:At the start of the epoch: mem (CPU python)=9445.25390625MB; mem (CPU total)=19522.2578125MB
INFO:root:[   96] Training loss: 0.36428038, Validation loss: 0.38400656, Gradient norm: 17.89591250
INFO:root:At the start of the epoch: mem (CPU python)=9466.4140625MB; mem (CPU total)=19578.0078125MB
INFO:root:[   97] Training loss: 0.36434523, Validation loss: 0.38189280, Gradient norm: 18.70172104
INFO:root:At the start of the epoch: mem (CPU python)=9487.578125MB; mem (CPU total)=19625.19921875MB
INFO:root:[   98] Training loss: 0.36454654, Validation loss: 0.38226913, Gradient norm: 18.89878483
INFO:root:At the start of the epoch: mem (CPU python)=9508.7421875MB; mem (CPU total)=19641.8828125MB
INFO:root:[   99] Training loss: 0.36496231, Validation loss: 0.38281279, Gradient norm: 19.88442617
INFO:root:At the start of the epoch: mem (CPU python)=9529.90625MB; mem (CPU total)=19661.5078125MB
INFO:root:EP 99: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=9551.07421875MB; mem (CPU total)=19671.4609375MB
INFO:root:[  101] Training loss: 0.45540778, Validation loss: 0.46969691, Gradient norm: 25.67497861
INFO:root:At the start of the epoch: mem (CPU python)=9572.23828125MB; mem (CPU total)=19702.75390625MB
INFO:root:[  102] Training loss: 0.45397094, Validation loss: 0.46495483, Gradient norm: 25.85312368
INFO:root:At the start of the epoch: mem (CPU python)=9593.40234375MB; mem (CPU total)=19755.8515625MB
INFO:root:[  103] Training loss: 0.45283636, Validation loss: 0.46609194, Gradient norm: 24.40630766
INFO:root:At the start of the epoch: mem (CPU python)=9614.56640625MB; mem (CPU total)=19805.265625MB
INFO:root:[  104] Training loss: 0.45243149, Validation loss: 0.46485729, Gradient norm: 25.95388858
INFO:root:At the start of the epoch: mem (CPU python)=9635.73046875MB; mem (CPU total)=19829.875MB
INFO:root:[  105] Training loss: 0.45203012, Validation loss: 0.46274199, Gradient norm: 25.74719960
INFO:root:At the start of the epoch: mem (CPU python)=9656.890625MB; mem (CPU total)=19879.6484375MB
INFO:root:[  106] Training loss: 0.45251269, Validation loss: 0.46350968, Gradient norm: 32.90762326
INFO:root:At the start of the epoch: mem (CPU python)=9678.05078125MB; mem (CPU total)=19894.578125MB
INFO:root:[  107] Training loss: 0.45230124, Validation loss: 0.46387979, Gradient norm: 26.89529365
INFO:root:At the start of the epoch: mem (CPU python)=9699.21875MB; mem (CPU total)=19945.953125MB
INFO:root:[  108] Training loss: 0.45131654, Validation loss: 0.46333356, Gradient norm: 26.20251703
INFO:root:At the start of the epoch: mem (CPU python)=9720.3828125MB; mem (CPU total)=19994.64453125MB
INFO:root:[  109] Training loss: 0.45167470, Validation loss: 0.46347018, Gradient norm: 26.73147160
INFO:root:At the start of the epoch: mem (CPU python)=9741.546875MB; mem (CPU total)=20013.5546875MB
INFO:root:[  110] Training loss: 0.45206988, Validation loss: 0.46336584, Gradient norm: 33.55891853
INFO:root:At the start of the epoch: mem (CPU python)=9762.7109375MB; mem (CPU total)=20050.78125MB
INFO:root:[  111] Training loss: 0.45144167, Validation loss: 0.46373174, Gradient norm: 27.01446507
INFO:root:At the start of the epoch: mem (CPU python)=9783.875MB; mem (CPU total)=20105.94140625MB
INFO:root:[  112] Training loss: 0.45058165, Validation loss: 0.46144973, Gradient norm: 25.78448864
INFO:root:At the start of the epoch: mem (CPU python)=9805.04296875MB; mem (CPU total)=20101.0546875MB
INFO:root:[  113] Training loss: 0.45034027, Validation loss: 0.46342743, Gradient norm: 27.57783045
INFO:root:At the start of the epoch: mem (CPU python)=9826.20703125MB; mem (CPU total)=20156.984375MB
INFO:root:[  114] Training loss: 0.44997831, Validation loss: 0.46289704, Gradient norm: 28.75492074
INFO:root:At the start of the epoch: mem (CPU python)=9847.375MB; mem (CPU total)=20185.20703125MB
INFO:root:[  115] Training loss: 0.45051362, Validation loss: 0.46168003, Gradient norm: 28.06624296
INFO:root:At the start of the epoch: mem (CPU python)=9868.53515625MB; mem (CPU total)=20257.8984375MB
INFO:root:[  116] Training loss: 0.45062199, Validation loss: 0.46402472, Gradient norm: 30.29306776
INFO:root:At the start of the epoch: mem (CPU python)=9889.69921875MB; mem (CPU total)=20262.93359375MB
INFO:root:[  117] Training loss: 0.45074865, Validation loss: 0.46368521, Gradient norm: 30.45166489
INFO:root:At the start of the epoch: mem (CPU python)=9910.86328125MB; mem (CPU total)=20308.81640625MB
INFO:root:[  118] Training loss: 0.45015333, Validation loss: 0.46228042, Gradient norm: 29.88096533
INFO:root:At the start of the epoch: mem (CPU python)=9932.03125MB; mem (CPU total)=20336.67578125MB
INFO:root:[  119] Training loss: 0.44966941, Validation loss: 0.46216611, Gradient norm: 30.03831718
INFO:root:At the start of the epoch: mem (CPU python)=9953.1953125MB; mem (CPU total)=20349.02734375MB
INFO:root:[  120] Training loss: 0.44989917, Validation loss: 0.46028733, Gradient norm: 29.97579393
INFO:root:At the start of the epoch: mem (CPU python)=9974.359375MB; mem (CPU total)=20411.40234375MB
INFO:root:[  121] Training loss: 0.44959450, Validation loss: 0.46177749, Gradient norm: 30.55163450
INFO:root:At the start of the epoch: mem (CPU python)=9995.5234375MB; mem (CPU total)=20432.80078125MB
INFO:root:[  122] Training loss: 0.44949467, Validation loss: 0.46324877, Gradient norm: 32.66749300
INFO:root:At the start of the epoch: mem (CPU python)=10016.68359375MB; mem (CPU total)=20486.17578125MB
INFO:root:[  123] Training loss: 0.44975458, Validation loss: 0.46054637, Gradient norm: 31.34532139
INFO:root:At the start of the epoch: mem (CPU python)=10037.84765625MB; mem (CPU total)=20500.1328125MB
INFO:root:[  124] Training loss: 0.44986447, Validation loss: 0.46119451, Gradient norm: 31.33385604
INFO:root:At the start of the epoch: mem (CPU python)=10059.01171875MB; mem (CPU total)=20549.46484375MB
INFO:root:[  125] Training loss: 0.44968209, Validation loss: 0.46043763, Gradient norm: 30.16902138
INFO:root:At the start of the epoch: mem (CPU python)=10080.17578125MB; mem (CPU total)=20594.4609375MB
INFO:root:[  126] Training loss: 0.44961971, Validation loss: 0.46211505, Gradient norm: 31.69543438
INFO:root:At the start of the epoch: mem (CPU python)=10101.33984375MB; mem (CPU total)=20618.8828125MB
INFO:root:[  127] Training loss: 0.44985128, Validation loss: 0.46146424, Gradient norm: 31.19309026
INFO:root:At the start of the epoch: mem (CPU python)=10122.50390625MB; mem (CPU total)=20680.1015625MB
INFO:root:[  128] Training loss: 0.44918932, Validation loss: 0.46103172, Gradient norm: 32.14763931
INFO:root:At the start of the epoch: mem (CPU python)=10143.66796875MB; mem (CPU total)=20674.19140625MB
INFO:root:[  129] Training loss: 0.44944931, Validation loss: 0.46294749, Gradient norm: 31.34263858
INFO:root:At the start of the epoch: mem (CPU python)=10164.8359375MB; mem (CPU total)=20691.2578125MB
INFO:root:EP 129: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=10185.875MB; mem (CPU total)=20769.73828125MB
INFO:root:Training the model took 3886.931s.
INFO:root:Emptying the cuda cache took 0.039s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.4683
INFO:root:EnergyScoreValidation: 0.35149
INFO:root:CRPSValidation: 0.1445
INFO:root:Gaussian NLLValidation: 0.30832
INFO:root:CoverageValidation: 0.75462
INFO:root:IntervalWidthValidation: 0.55744
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.36634
INFO:root:EnergyScoreTest: 0.28127
INFO:root:CRPSTest: 0.11478
INFO:root:Gaussian NLLTest: 0.37471
INFO:root:CoverageTest: 0.68803
INFO:root:IntervalWidthTest: 0.37741
INFO:root:After validation: mem (CPU python)=10192.9765625MB; mem (CPU total)=20872.8203125MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=10192.9765625MB; mem (CPU total)=20874.1171875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 48234496
INFO:root:After setting up the model: mem (CPU python)=10192.98828125MB; mem (CPU total)=20874.1171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=10192.98828125MB; mem (CPU total)=20866.234375MB
INFO:root:[    1] Training loss: 0.76432685, Validation loss: 0.71948570, Gradient norm: 0.42502844
INFO:root:At the start of the epoch: mem (CPU python)=10213.7109375MB; mem (CPU total)=20914.99609375MB
INFO:root:[    2] Training loss: 0.68072581, Validation loss: 0.59985288, Gradient norm: 0.63698640
INFO:root:At the start of the epoch: mem (CPU python)=10234.875MB; mem (CPU total)=20945.30078125MB
INFO:root:[    3] Training loss: 0.56352278, Validation loss: 0.54341027, Gradient norm: 1.18544974
INFO:root:At the start of the epoch: mem (CPU python)=10256.04296875MB; mem (CPU total)=20989.55859375MB
INFO:root:[    4] Training loss: 0.53349307, Validation loss: 0.51916287, Gradient norm: 1.59001496
INFO:root:At the start of the epoch: mem (CPU python)=10277.20703125MB; mem (CPU total)=21018.91015625MB
INFO:root:[    5] Training loss: 0.51755151, Validation loss: 0.50872736, Gradient norm: 1.86315372
INFO:root:At the start of the epoch: mem (CPU python)=10298.37109375MB; mem (CPU total)=21052.83203125MB
INFO:root:[    6] Training loss: 0.50765154, Validation loss: 0.50754579, Gradient norm: 2.16215929
INFO:root:At the start of the epoch: mem (CPU python)=10319.53515625MB; mem (CPU total)=21093.63671875MB
INFO:root:[    7] Training loss: 0.50277494, Validation loss: 0.50857584, Gradient norm: 2.54321990
INFO:root:At the start of the epoch: mem (CPU python)=10340.69921875MB; mem (CPU total)=21086.26171875MB
INFO:root:[    8] Training loss: 0.49915670, Validation loss: 0.49876958, Gradient norm: 2.70764162
INFO:root:At the start of the epoch: mem (CPU python)=10361.859375MB; mem (CPU total)=21121.6953125MB
INFO:root:[    9] Training loss: 0.49588850, Validation loss: 0.49963564, Gradient norm: 2.91408392
INFO:root:At the start of the epoch: mem (CPU python)=10383.02734375MB; mem (CPU total)=21165.609375MB
INFO:root:[   10] Training loss: 0.49394998, Validation loss: 0.48835847, Gradient norm: 3.00636521
INFO:root:At the start of the epoch: mem (CPU python)=10404.19140625MB; mem (CPU total)=21193.5859375MB
INFO:root:[   11] Training loss: 0.49060960, Validation loss: 0.49252613, Gradient norm: 3.27958346
INFO:root:At the start of the epoch: mem (CPU python)=10425.35546875MB; mem (CPU total)=21214.17578125MB
INFO:root:[   12] Training loss: 0.48771817, Validation loss: 0.47955274, Gradient norm: 3.49406480
INFO:root:At the start of the epoch: mem (CPU python)=10446.51953125MB; mem (CPU total)=21242.47265625MB
INFO:root:[   13] Training loss: 0.48446628, Validation loss: 0.48030851, Gradient norm: 3.65909916
INFO:root:At the start of the epoch: mem (CPU python)=10467.68359375MB; mem (CPU total)=21273.8203125MB
INFO:root:[   14] Training loss: 0.48187710, Validation loss: 0.49219153, Gradient norm: 3.86155514
INFO:root:At the start of the epoch: mem (CPU python)=10488.8515625MB; mem (CPU total)=21319.875MB
INFO:root:[   15] Training loss: 0.48072191, Validation loss: 0.48764459, Gradient norm: 3.93013607
INFO:root:At the start of the epoch: mem (CPU python)=10510.01171875MB; mem (CPU total)=21358.78125MB
INFO:root:[   16] Training loss: 0.47876479, Validation loss: 0.47120920, Gradient norm: 4.09158864
INFO:root:At the start of the epoch: mem (CPU python)=10531.17578125MB; mem (CPU total)=21377.50390625MB
INFO:root:[   17] Training loss: 0.47689879, Validation loss: 0.47041879, Gradient norm: 4.29839648
INFO:root:At the start of the epoch: mem (CPU python)=10552.3359375MB; mem (CPU total)=21422.24609375MB
INFO:root:[   18] Training loss: 0.47619680, Validation loss: 0.46677901, Gradient norm: 4.32859788
INFO:root:At the start of the epoch: mem (CPU python)=10573.5MB; mem (CPU total)=21454.96484375MB
INFO:root:[   19] Training loss: 0.47629833, Validation loss: 0.47595225, Gradient norm: 4.50436328
INFO:root:At the start of the epoch: mem (CPU python)=10594.6640625MB; mem (CPU total)=21491.77734375MB
INFO:root:[   20] Training loss: 0.47156566, Validation loss: 0.46450842, Gradient norm: 4.56332501
INFO:root:At the start of the epoch: mem (CPU python)=10615.83203125MB; mem (CPU total)=21532.0625MB
INFO:root:[   21] Training loss: 0.47329902, Validation loss: 0.47632816, Gradient norm: 4.57571505
INFO:root:At the start of the epoch: mem (CPU python)=10636.99609375MB; mem (CPU total)=21555.82421875MB
INFO:root:[   22] Training loss: 0.47174430, Validation loss: 0.45499060, Gradient norm: 4.63081130
INFO:root:At the start of the epoch: mem (CPU python)=10664.6640625MB; mem (CPU total)=21566.8515625MB
INFO:root:[   23] Training loss: 0.44912020, Validation loss: 0.45815730, Gradient norm: 5.27016160
INFO:root:At the start of the epoch: mem (CPU python)=10685.828125MB; mem (CPU total)=21587.76171875MB
INFO:root:[   24] Training loss: 0.44471563, Validation loss: 0.44005770, Gradient norm: 5.43323120
INFO:root:At the start of the epoch: mem (CPU python)=10713.00390625MB; mem (CPU total)=21631.33984375MB
INFO:root:[   25] Training loss: 0.44493616, Validation loss: 0.45928965, Gradient norm: 5.54239683
INFO:root:At the start of the epoch: mem (CPU python)=10734.1640625MB; mem (CPU total)=21673.78125MB
INFO:root:[   26] Training loss: 0.44499744, Validation loss: 0.44318389, Gradient norm: 5.60421521
INFO:root:At the start of the epoch: mem (CPU python)=10755.94140625MB; mem (CPU total)=21690.46875MB
INFO:root:[   27] Training loss: 0.44387076, Validation loss: 0.46437351, Gradient norm: 5.76804896
INFO:root:At the start of the epoch: mem (CPU python)=10777.10546875MB; mem (CPU total)=21724.4375MB
INFO:root:[   28] Training loss: 0.43890753, Validation loss: 0.48246208, Gradient norm: 5.47698320
INFO:root:At the start of the epoch: mem (CPU python)=10798.26953125MB; mem (CPU total)=21742.71875MB
INFO:root:[   29] Training loss: 0.44405443, Validation loss: 0.44991847, Gradient norm: 5.82602036
INFO:root:At the start of the epoch: mem (CPU python)=10819.43359375MB; mem (CPU total)=21776.6171875MB
INFO:root:[   30] Training loss: 0.43903197, Validation loss: 0.47738177, Gradient norm: 5.54391726
INFO:root:At the start of the epoch: mem (CPU python)=10840.59765625MB; mem (CPU total)=21854.17578125MB
INFO:root:[   31] Training loss: 0.43684716, Validation loss: 0.45183139, Gradient norm: 5.36479635
INFO:root:At the start of the epoch: mem (CPU python)=10861.765625MB; mem (CPU total)=21869.515625MB
INFO:root:[   32] Training loss: 0.43807922, Validation loss: 0.70472664, Gradient norm: 5.65813277
INFO:root:At the start of the epoch: mem (CPU python)=10882.92578125MB; mem (CPU total)=21889.05859375MB
INFO:root:[   33] Training loss: 0.46383698, Validation loss: 0.43052283, Gradient norm: 6.77025769
INFO:root:At the start of the epoch: mem (CPU python)=10908.01953125MB; mem (CPU total)=21963.89453125MB
INFO:root:[   34] Training loss: 0.43288095, Validation loss: 0.43049366, Gradient norm: 5.57730434
INFO:root:At the start of the epoch: mem (CPU python)=10929.77734375MB; mem (CPU total)=21958.95703125MB
INFO:root:[   35] Training loss: 0.42813591, Validation loss: 0.42349385, Gradient norm: 5.36545501
INFO:root:At the start of the epoch: mem (CPU python)=10950.9453125MB; mem (CPU total)=22007.0MB
INFO:root:[   36] Training loss: 0.42948328, Validation loss: 0.43332319, Gradient norm: 5.40570079
INFO:root:At the start of the epoch: mem (CPU python)=10972.10546875MB; mem (CPU total)=22042.51953125MB
INFO:root:[   37] Training loss: 0.42909875, Validation loss: 0.43801570, Gradient norm: 5.39928927
INFO:root:At the start of the epoch: mem (CPU python)=10993.26953125MB; mem (CPU total)=22052.08203125MB
INFO:root:[   38] Training loss: 0.47768057, Validation loss: 0.44042662, Gradient norm: 6.94947970
INFO:root:At the start of the epoch: mem (CPU python)=11022.98828125MB; mem (CPU total)=22099.00390625MB
INFO:root:[   39] Training loss: 0.43053246, Validation loss: 0.43699935, Gradient norm: 5.32386132
INFO:root:At the start of the epoch: mem (CPU python)=11044.15234375MB; mem (CPU total)=22135.4140625MB
INFO:root:[   40] Training loss: 0.42472384, Validation loss: 0.42857848, Gradient norm: 5.06517455
INFO:root:At the start of the epoch: mem (CPU python)=11066.13671875MB; mem (CPU total)=22162.421875MB
INFO:root:[   41] Training loss: 0.42504273, Validation loss: 0.43350302, Gradient norm: 5.15167428
INFO:root:At the start of the epoch: mem (CPU python)=11087.30078125MB; mem (CPU total)=22203.31640625MB
INFO:root:[   42] Training loss: 0.42248645, Validation loss: 0.42094906, Gradient norm: 5.46218751
INFO:root:At the start of the epoch: mem (CPU python)=11108.46875MB; mem (CPU total)=22219.08203125MB
INFO:root:[   43] Training loss: 0.42296023, Validation loss: 0.42998433, Gradient norm: 5.30863742
INFO:root:At the start of the epoch: mem (CPU python)=11129.6328125MB; mem (CPU total)=22241.9296875MB
INFO:root:[   44] Training loss: 0.42560034, Validation loss: 0.42286847, Gradient norm: 5.62423180
INFO:root:At the start of the epoch: mem (CPU python)=11150.796875MB; mem (CPU total)=22258.41015625MB
INFO:root:[   45] Training loss: 0.41961535, Validation loss: 0.42381319, Gradient norm: 5.40721674
INFO:root:At the start of the epoch: mem (CPU python)=11171.95703125MB; mem (CPU total)=22283.87109375MB
INFO:root:[   46] Training loss: 0.41855007, Validation loss: 0.42380119, Gradient norm: 5.30594770
INFO:root:At the start of the epoch: mem (CPU python)=11193.12109375MB; mem (CPU total)=22360.3671875MB
INFO:root:[   47] Training loss: 0.42112312, Validation loss: 0.42468485, Gradient norm: 5.36167068
INFO:root:At the start of the epoch: mem (CPU python)=11214.2890625MB; mem (CPU total)=22390.3203125MB
INFO:root:[   48] Training loss: 0.41744320, Validation loss: 0.44645923, Gradient norm: 5.60818868
INFO:root:At the start of the epoch: mem (CPU python)=11235.453125MB; mem (CPU total)=22391.6875MB
INFO:root:[   49] Training loss: 0.41800365, Validation loss: 0.42094265, Gradient norm: 5.52902934
INFO:root:At the start of the epoch: mem (CPU python)=11256.6171875MB; mem (CPU total)=22427.99609375MB
INFO:root:[   50] Training loss: 0.41564535, Validation loss: 0.40993280, Gradient norm: 5.81712248
INFO:root:At the start of the epoch: mem (CPU python)=11277.77734375MB; mem (CPU total)=22464.51953125MB
INFO:root:[   51] Training loss: 0.42315832, Validation loss: 0.43800263, Gradient norm: 5.63289125
INFO:root:At the start of the epoch: mem (CPU python)=11298.94140625MB; mem (CPU total)=22489.37109375MB
INFO:root:[   52] Training loss: 0.41588064, Validation loss: 0.41906665, Gradient norm: 5.69112968
INFO:root:At the start of the epoch: mem (CPU python)=11320.109375MB; mem (CPU total)=22544.45703125MB
INFO:root:[   53] Training loss: 0.41399111, Validation loss: 0.41740444, Gradient norm: 5.31030406
INFO:root:At the start of the epoch: mem (CPU python)=11341.2734375MB; mem (CPU total)=22508.5703125MB
INFO:root:[   54] Training loss: 0.41497053, Validation loss: 0.40897132, Gradient norm: 5.32838985
INFO:root:At the start of the epoch: mem (CPU python)=11364.4375MB; mem (CPU total)=22566.80078125MB
INFO:root:[   55] Training loss: 0.43397158, Validation loss: 0.41540126, Gradient norm: 6.41747950
INFO:root:At the start of the epoch: mem (CPU python)=11385.59765625MB; mem (CPU total)=22603.828125MB
INFO:root:[   56] Training loss: 0.42358020, Validation loss: 0.42901485, Gradient norm: 6.05485148
INFO:root:At the start of the epoch: mem (CPU python)=11406.76171875MB; mem (CPU total)=22635.359375MB
INFO:root:[   57] Training loss: 0.41117622, Validation loss: 0.42388297, Gradient norm: 5.29425453
INFO:root:At the start of the epoch: mem (CPU python)=11427.92578125MB; mem (CPU total)=22691.3515625MB
INFO:root:[   58] Training loss: 0.40998382, Validation loss: 0.41894360, Gradient norm: 5.07043052
INFO:root:At the start of the epoch: mem (CPU python)=11449.09375MB; mem (CPU total)=22724.09375MB
INFO:root:[   59] Training loss: 0.41042930, Validation loss: 0.43837310, Gradient norm: 5.11242050
INFO:root:At the start of the epoch: mem (CPU python)=11470.26171875MB; mem (CPU total)=22814.58203125MB
INFO:root:[   60] Training loss: 0.40733376, Validation loss: 0.43215678, Gradient norm: 5.16739498
INFO:root:At the start of the epoch: mem (CPU python)=11491.44921875MB; mem (CPU total)=22803.53515625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.40715670, Validation loss: 0.41353662, Gradient norm: 5.17141357
INFO:root:At the start of the epoch: mem (CPU python)=11512.6171875MB; mem (CPU total)=22844.0MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 0.38211393, Validation loss: 0.39321027, Gradient norm: 4.48681212
INFO:root:At the start of the epoch: mem (CPU python)=11542.13671875MB; mem (CPU total)=22892.6328125MB
INFO:root:[   63] Training loss: 0.37168257, Validation loss: 0.38639810, Gradient norm: 4.38933733
INFO:root:At the start of the epoch: mem (CPU python)=11563.94921875MB; mem (CPU total)=22876.17578125MB
INFO:root:[   64] Training loss: 0.37164465, Validation loss: 0.38466565, Gradient norm: 6.26270654
INFO:root:At the start of the epoch: mem (CPU python)=11585.11328125MB; mem (CPU total)=22925.0078125MB
INFO:root:[   65] Training loss: 0.37098120, Validation loss: 0.38223122, Gradient norm: 6.66929087
INFO:root:At the start of the epoch: mem (CPU python)=11606.27734375MB; mem (CPU total)=22928.8828125MB
INFO:root:[   66] Training loss: 0.37201976, Validation loss: 0.39013652, Gradient norm: 7.75373292
INFO:root:At the start of the epoch: mem (CPU python)=11627.4375MB; mem (CPU total)=22959.3125MB
INFO:root:[   67] Training loss: 0.37373211, Validation loss: 0.38578446, Gradient norm: 9.11104543
INFO:root:At the start of the epoch: mem (CPU python)=11648.6015625MB; mem (CPU total)=23011.9921875MB
INFO:root:[   68] Training loss: 0.37411445, Validation loss: 0.38700470, Gradient norm: 9.83032995
INFO:root:At the start of the epoch: mem (CPU python)=11669.765625MB; mem (CPU total)=23030.45703125MB
INFO:root:[   69] Training loss: 0.37563012, Validation loss: 0.38860195, Gradient norm: 10.58350636
INFO:root:At the start of the epoch: mem (CPU python)=11690.9296875MB; mem (CPU total)=23066.76171875MB
INFO:root:[   70] Training loss: 0.37721140, Validation loss: 0.39920631, Gradient norm: 11.38549529
INFO:root:At the start of the epoch: mem (CPU python)=11712.09765625MB; mem (CPU total)=23089.59375MB
INFO:root:[   71] Training loss: 0.37728270, Validation loss: 0.39326885, Gradient norm: 12.39350508
INFO:root:At the start of the epoch: mem (CPU python)=11733.26171875MB; mem (CPU total)=23144.55859375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   72] Training loss: 0.37802835, Validation loss: 0.39582808, Gradient norm: 12.84217716
INFO:root:At the start of the epoch: mem (CPU python)=11754.42578125MB; mem (CPU total)=23210.53515625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   73] Training loss: 0.36895606, Validation loss: 0.38551025, Gradient norm: 9.19478042
INFO:root:At the start of the epoch: mem (CPU python)=11775.58984375MB; mem (CPU total)=23218.37890625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   74] Training loss: 0.36425669, Validation loss: 0.37897713, Gradient norm: 7.77709486
INFO:root:At the start of the epoch: mem (CPU python)=11796.75390625MB; mem (CPU total)=23249.19921875MB
INFO:root:[   75] Training loss: 0.36206370, Validation loss: 0.37625326, Gradient norm: 6.65586158
INFO:root:At the start of the epoch: mem (CPU python)=11817.91796875MB; mem (CPU total)=23250.2421875MB
INFO:root:[   76] Training loss: 0.36204764, Validation loss: 0.37623712, Gradient norm: 7.51136603
INFO:root:At the start of the epoch: mem (CPU python)=11839.08203125MB; mem (CPU total)=23283.99609375MB
INFO:root:[   77] Training loss: 0.36192261, Validation loss: 0.37772418, Gradient norm: 7.78017686
INFO:root:At the start of the epoch: mem (CPU python)=11860.24609375MB; mem (CPU total)=23314.79296875MB
INFO:root:[   78] Training loss: 0.36213762, Validation loss: 0.37877393, Gradient norm: 8.29042701
INFO:root:At the start of the epoch: mem (CPU python)=11881.41015625MB; mem (CPU total)=23357.29296875MB
INFO:root:[   79] Training loss: 0.36233249, Validation loss: 0.37781492, Gradient norm: 8.75339652
INFO:root:At the start of the epoch: mem (CPU python)=11902.57421875MB; mem (CPU total)=23400.7421875MB
INFO:root:[   80] Training loss: 0.36241714, Validation loss: 0.37833458, Gradient norm: 9.34127789
INFO:root:At the start of the epoch: mem (CPU python)=11923.73828125MB; mem (CPU total)=23423.08203125MB
INFO:root:[   81] Training loss: 0.36254853, Validation loss: 0.37539962, Gradient norm: 10.12920132
INFO:root:At the start of the epoch: mem (CPU python)=11944.90625MB; mem (CPU total)=23456.19140625MB
INFO:root:[   82] Training loss: 0.36330191, Validation loss: 0.37672141, Gradient norm: 10.78161865
INFO:root:At the start of the epoch: mem (CPU python)=11966.66015625MB; mem (CPU total)=23469.75390625MB
INFO:root:[   83] Training loss: 0.36335075, Validation loss: 0.37644380, Gradient norm: 11.12075253
INFO:root:At the start of the epoch: mem (CPU python)=11989.6875MB; mem (CPU total)=23509.421875MB
INFO:root:[   84] Training loss: 0.36387621, Validation loss: 0.37866520, Gradient norm: 11.70702754
INFO:root:At the start of the epoch: mem (CPU python)=12011.078125MB; mem (CPU total)=23553.0390625MB
INFO:root:[   85] Training loss: 0.36372452, Validation loss: 0.37913318, Gradient norm: 12.15625022
INFO:root:At the start of the epoch: mem (CPU python)=12032.75390625MB; mem (CPU total)=23612.83984375MB
INFO:root:[   86] Training loss: 0.36446885, Validation loss: 0.37618827, Gradient norm: 13.56971113
INFO:root:At the start of the epoch: mem (CPU python)=12055.171875MB; mem (CPU total)=23623.85546875MB
INFO:root:[   87] Training loss: 0.36365325, Validation loss: 0.37870604, Gradient norm: 13.39554568
INFO:root:At the start of the epoch: mem (CPU python)=12077.0MB; mem (CPU total)=23655.0390625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   88] Training loss: 0.36406450, Validation loss: 0.37926707, Gradient norm: 14.39522149
INFO:root:At the start of the epoch: mem (CPU python)=12098.1640625MB; mem (CPU total)=23686.41015625MB
INFO:root:[   89] Training loss: 0.36345327, Validation loss: 0.37638337, Gradient norm: 11.62111905
INFO:root:At the start of the epoch: mem (CPU python)=12119.328125MB; mem (CPU total)=23680.8046875MB
INFO:root:[   90] Training loss: 0.36308587, Validation loss: 0.37555299, Gradient norm: 11.46563637
INFO:root:At the start of the epoch: mem (CPU python)=12140.49609375MB; mem (CPU total)=23731.9765625MB
INFO:root:EP 90: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=12161.66015625MB; mem (CPU total)=23745.64453125MB
INFO:root:[   92] Training loss: 0.45070658, Validation loss: 0.45975625, Gradient norm: 23.58615548
INFO:root:At the start of the epoch: mem (CPU python)=12182.82421875MB; mem (CPU total)=23784.05078125MB
INFO:root:[   93] Training loss: 0.44810481, Validation loss: 0.45860086, Gradient norm: 23.47103470
INFO:root:At the start of the epoch: mem (CPU python)=12203.98828125MB; mem (CPU total)=23831.625MB
INFO:root:[   94] Training loss: 0.44758494, Validation loss: 0.45666627, Gradient norm: 23.43657477
INFO:root:At the start of the epoch: mem (CPU python)=12225.15234375MB; mem (CPU total)=23842.35546875MB
INFO:root:[   95] Training loss: 0.44657625, Validation loss: 0.45803671, Gradient norm: 22.87014844
INFO:root:At the start of the epoch: mem (CPU python)=12246.31640625MB; mem (CPU total)=23532.703125MB
INFO:root:[   96] Training loss: 0.44615748, Validation loss: 0.45780169, Gradient norm: 23.82395436
INFO:root:At the start of the epoch: mem (CPU python)=12267.48046875MB; mem (CPU total)=23981.50390625MB
INFO:root:[   97] Training loss: 0.44525332, Validation loss: 0.45804166, Gradient norm: 21.94473958
INFO:root:At the start of the epoch: mem (CPU python)=12288.64453125MB; mem (CPU total)=24021.80078125MB
INFO:root:[   98] Training loss: 0.44545304, Validation loss: 0.45750826, Gradient norm: 22.74914480
INFO:root:At the start of the epoch: mem (CPU python)=12309.9140625MB; mem (CPU total)=24039.0234375MB
INFO:root:[   99] Training loss: 0.44596608, Validation loss: 0.45636133, Gradient norm: 25.24837980
INFO:root:At the start of the epoch: mem (CPU python)=12331.81640625MB; mem (CPU total)=24095.67578125MB
INFO:root:[  100] Training loss: 0.44551855, Validation loss: 0.45614817, Gradient norm: 21.94630013
INFO:root:At the start of the epoch: mem (CPU python)=12352.98046875MB; mem (CPU total)=24109.1171875MB
INFO:root:[  101] Training loss: 0.44490840, Validation loss: 0.45667888, Gradient norm: 22.51802686
INFO:root:At the start of the epoch: mem (CPU python)=12374.515625MB; mem (CPU total)=24141.87109375MB
INFO:root:[  102] Training loss: 0.44530027, Validation loss: 0.45467708, Gradient norm: 22.26502926
INFO:root:At the start of the epoch: mem (CPU python)=12396.16015625MB; mem (CPU total)=24166.6015625MB
INFO:root:[  103] Training loss: 0.44483026, Validation loss: 0.45789161, Gradient norm: 23.29710418
INFO:root:At the start of the epoch: mem (CPU python)=12417.9921875MB; mem (CPU total)=24199.4609375MB
INFO:root:[  104] Training loss: 0.44499982, Validation loss: 0.45485356, Gradient norm: 23.87507151
INFO:root:At the start of the epoch: mem (CPU python)=12440.26953125MB; mem (CPU total)=24253.109375MB
INFO:root:[  105] Training loss: 0.44480790, Validation loss: 0.45603901, Gradient norm: 23.15344779
INFO:root:At the start of the epoch: mem (CPU python)=12461.4375MB; mem (CPU total)=24303.125MB
INFO:root:[  106] Training loss: 0.44459548, Validation loss: 0.45924595, Gradient norm: 24.83611814
INFO:root:At the start of the epoch: mem (CPU python)=12483.3515625MB; mem (CPU total)=24331.4609375MB
INFO:root:[  107] Training loss: 0.44384156, Validation loss: 0.45604456, Gradient norm: 22.56581357
INFO:root:At the start of the epoch: mem (CPU python)=12504.6953125MB; mem (CPU total)=24356.19921875MB
INFO:root:[  108] Training loss: 0.44433790, Validation loss: 0.45614330, Gradient norm: 24.53386930
INFO:root:At the start of the epoch: mem (CPU python)=12526.0546875MB; mem (CPU total)=24385.91015625MB
INFO:root:[  109] Training loss: 0.44369512, Validation loss: 0.45382042, Gradient norm: 23.81862369
INFO:root:At the start of the epoch: mem (CPU python)=12548.71875MB; mem (CPU total)=24431.265625MB
INFO:root:[  110] Training loss: 0.44371077, Validation loss: 0.45537737, Gradient norm: 23.71978070
INFO:root:At the start of the epoch: mem (CPU python)=12569.8828125MB; mem (CPU total)=24475.6328125MB
INFO:root:[  111] Training loss: 0.44431946, Validation loss: 0.45475134, Gradient norm: 24.35724622
INFO:root:At the start of the epoch: mem (CPU python)=12591.4921875MB; mem (CPU total)=24506.62890625MB
INFO:root:[  112] Training loss: 0.44623438, Validation loss: 0.45473005, Gradient norm: 30.89107415
INFO:root:At the start of the epoch: mem (CPU python)=12613.4296875MB; mem (CPU total)=24622.734375MB
INFO:root:[  113] Training loss: 0.44437459, Validation loss: 0.45410467, Gradient norm: 25.98481949
INFO:root:At the start of the epoch: mem (CPU python)=12634.875MB; mem (CPU total)=24585.828125MB
INFO:root:[  114] Training loss: 0.44348021, Validation loss: 0.45450586, Gradient norm: 24.64336341
INFO:root:At the start of the epoch: mem (CPU python)=12657.1640625MB; mem (CPU total)=24629.30859375MB
INFO:root:[  115] Training loss: 0.44387552, Validation loss: 0.45541533, Gradient norm: 26.73984117
INFO:root:At the start of the epoch: mem (CPU python)=12678.33203125MB; mem (CPU total)=24670.35546875MB
INFO:root:[  116] Training loss: 0.44396038, Validation loss: 0.45524290, Gradient norm: 25.95228764
INFO:root:At the start of the epoch: mem (CPU python)=12699.63671875MB; mem (CPU total)=24676.52734375MB
INFO:root:[  117] Training loss: 0.44455408, Validation loss: 0.45412468, Gradient norm: 25.96003918
INFO:root:At the start of the epoch: mem (CPU python)=12721.3515625MB; mem (CPU total)=24728.4140625MB
INFO:root:[  118] Training loss: 0.44422080, Validation loss: 0.45569293, Gradient norm: 26.58615521
INFO:root:At the start of the epoch: mem (CPU python)=12742.94921875MB; mem (CPU total)=24781.9296875MB
INFO:root:EP 118: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12764.11328125MB; mem (CPU total)=24782.015625MB
INFO:root:Training the model took 3821.268s.
INFO:root:Emptying the cuda cache took 0.04s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.46493
INFO:root:EnergyScoreValidation: 0.35232
INFO:root:CRPSValidation: 0.14589
INFO:root:Gaussian NLLValidation: 0.44044
INFO:root:CoverageValidation: 0.73156
INFO:root:IntervalWidthValidation: 0.52347
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.36735
INFO:root:EnergyScoreTest: 0.2846
INFO:root:CRPSTest: 0.11485
INFO:root:Gaussian NLLTest: 0.47761
INFO:root:CoverageTest: 0.6832
INFO:root:IntervalWidthTest: 0.35908
INFO:root:After validation: mem (CPU python)=12770.9921875MB; mem (CPU total)=25011.8125MB
