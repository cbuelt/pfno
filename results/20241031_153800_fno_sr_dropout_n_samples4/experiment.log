INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.87890625MB; mem (CPU total)=21601.54296875MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples4.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12454.76171875MB; mem (CPU total)=21649.2421875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.76171875MB; mem (CPU total)=21649.2421875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12454.76171875MB; mem (CPU total)=22994.45703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=23004.8359375MB
INFO:root:[    1] Training loss: 0.75900980, Validation loss: 0.72293694, Gradient norm: 0.63306309
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=24861.640625MB
INFO:root:[    2] Training loss: 0.72201542, Validation loss: 0.72057892, Gradient norm: 0.67691237
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25042.44921875MB
INFO:root:[    3] Training loss: 0.72038754, Validation loss: 0.72051996, Gradient norm: 0.48096805
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25216.90234375MB
INFO:root:[    4] Training loss: 0.71983677, Validation loss: 0.71972629, Gradient norm: 0.41009852
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25389.36328125MB
INFO:root:[    5] Training loss: 0.71931349, Validation loss: 0.71923209, Gradient norm: 0.27213561
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25577.37109375MB
INFO:root:[    6] Training loss: 0.71874922, Validation loss: 0.71948333, Gradient norm: 0.26568882
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25751.08203125MB
INFO:root:[    7] Training loss: 0.71815128, Validation loss: 0.71794273, Gradient norm: 0.30479386
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25926.12890625MB
INFO:root:[    8] Training loss: 0.71330246, Validation loss: 0.70534636, Gradient norm: 0.34756173
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26110.8203125MB
INFO:root:[    9] Training loss: 0.69588645, Validation loss: 0.68840689, Gradient norm: 0.37925225
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26290.19921875MB
INFO:root:[   10] Training loss: 0.68117755, Validation loss: 0.67654338, Gradient norm: 0.25191881
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26456.55859375MB
INFO:root:[   11] Training loss: 0.67129757, Validation loss: 0.66873846, Gradient norm: 0.29056283
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26643.9296875MB
INFO:root:[   12] Training loss: 0.66481669, Validation loss: 0.66383467, Gradient norm: 0.23602432
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26816.00390625MB
INFO:root:[   13] Training loss: 0.66046079, Validation loss: 0.66002322, Gradient norm: 0.21765924
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26985.8046875MB
INFO:root:[   14] Training loss: 0.65707729, Validation loss: 0.65726145, Gradient norm: 0.21217730
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=27173.4765625MB
INFO:root:[   15] Training loss: 0.65420795, Validation loss: 0.65473152, Gradient norm: 0.26039722
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=27340.390625MB
INFO:root:[   16] Training loss: 0.65190709, Validation loss: 0.65312293, Gradient norm: 0.22385801
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=27516.59765625MB
