INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=579.5625MB; mem (CPU total)=12732.0MB
INFO:root:############### Starting experiment with config file sswe/sfno_sr_dropout_1_3.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=590.71484375MB; mem (CPU total)=12736.18359375MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=592.0625MB; mem (CPU total)=12736.6796875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2233.09375MB; mem (CPU total)=14113.7890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2242.78515625MB; mem (CPU total)=14123.359375MB
INFO:root:[    1] Training loss: 0.76485368, Validation loss: 0.65347280, Gradient norm: 0.64152676
INFO:root:At the start of the epoch: mem (CPU python)=4406.89453125MB; mem (CPU total)=15853.38671875MB
INFO:root:[    2] Training loss: 0.68206079, Validation loss: 0.51859839, Gradient norm: 1.20943197
INFO:root:At the start of the epoch: mem (CPU python)=4429.11328125MB; mem (CPU total)=15908.7421875MB
INFO:root:[    3] Training loss: 0.57916198, Validation loss: 0.42962943, Gradient norm: 1.86136359
INFO:root:At the start of the epoch: mem (CPU python)=4450.625MB; mem (CPU total)=15968.8828125MB
INFO:root:[    4] Training loss: 0.53292860, Validation loss: 0.39509856, Gradient norm: 2.19585508
INFO:root:At the start of the epoch: mem (CPU python)=4471.83984375MB; mem (CPU total)=16075.078125MB
INFO:root:[    5] Training loss: 0.51526464, Validation loss: 0.39291254, Gradient norm: 2.45138503
INFO:root:At the start of the epoch: mem (CPU python)=4493.02734375MB; mem (CPU total)=16083.5234375MB
INFO:root:[    6] Training loss: 0.50491995, Validation loss: 0.38778106, Gradient norm: 2.80699701
INFO:root:At the start of the epoch: mem (CPU python)=4514.21875MB; mem (CPU total)=16166.64453125MB
INFO:root:[    7] Training loss: 0.49793352, Validation loss: 0.38721303, Gradient norm: 3.08852693
INFO:root:At the start of the epoch: mem (CPU python)=4535.66015625MB; mem (CPU total)=16255.796875MB
INFO:root:[    8] Training loss: 0.49330429, Validation loss: 0.36271589, Gradient norm: 3.42873699
INFO:root:At the start of the epoch: mem (CPU python)=4556.97265625MB; mem (CPU total)=16308.32421875MB
INFO:root:[    9] Training loss: 0.48967697, Validation loss: 0.37267468, Gradient norm: 3.67089525
INFO:root:At the start of the epoch: mem (CPU python)=4578.16796875MB; mem (CPU total)=16351.265625MB
INFO:root:[   10] Training loss: 0.48764261, Validation loss: 0.38703577, Gradient norm: 3.83236921
INFO:root:At the start of the epoch: mem (CPU python)=4599.33203125MB; mem (CPU total)=16463.68359375MB
INFO:root:[   11] Training loss: 0.48328143, Validation loss: 0.35733579, Gradient norm: 4.03852239
INFO:root:At the start of the epoch: mem (CPU python)=4622.94140625MB; mem (CPU total)=16489.77734375MB
INFO:root:[   12] Training loss: 0.48106933, Validation loss: 0.35043511, Gradient norm: 4.26314823
INFO:root:At the start of the epoch: mem (CPU python)=4644.3125MB; mem (CPU total)=16673.9296875MB
INFO:root:[   13] Training loss: 0.47636409, Validation loss: 0.35870029, Gradient norm: 4.52015099
INFO:root:At the start of the epoch: mem (CPU python)=4665.48046875MB; mem (CPU total)=16666.08984375MB
INFO:root:[   14] Training loss: 0.47677418, Validation loss: 0.34057914, Gradient norm: 4.77416446
INFO:root:At the start of the epoch: mem (CPU python)=4686.64453125MB; mem (CPU total)=16713.45703125MB
INFO:root:[   15] Training loss: 0.47614376, Validation loss: 0.35327255, Gradient norm: 4.86515205
INFO:root:At the start of the epoch: mem (CPU python)=4707.8125MB; mem (CPU total)=16780.3515625MB
INFO:root:[   16] Training loss: 0.47161078, Validation loss: 0.33547976, Gradient norm: 4.96862709
INFO:root:At the start of the epoch: mem (CPU python)=4728.98046875MB; mem (CPU total)=16856.9453125MB
INFO:root:[   17] Training loss: 0.47004536, Validation loss: 0.36666012, Gradient norm: 5.14488129
INFO:root:At the start of the epoch: mem (CPU python)=4750.1484375MB; mem (CPU total)=16901.96875MB
INFO:root:[   18] Training loss: 0.46955471, Validation loss: 0.35200485, Gradient norm: 5.34415289
INFO:root:At the start of the epoch: mem (CPU python)=4771.32421875MB; mem (CPU total)=17085.23828125MB
INFO:root:[   19] Training loss: 0.46833005, Validation loss: 0.32823083, Gradient norm: 5.38142722
INFO:root:At the start of the epoch: mem (CPU python)=4792.4921875MB; mem (CPU total)=17041.1953125MB
INFO:root:[   20] Training loss: 0.46637941, Validation loss: 0.31720120, Gradient norm: 5.38063871
INFO:root:At the start of the epoch: mem (CPU python)=4813.66796875MB; mem (CPU total)=17123.86328125MB
INFO:root:[   21] Training loss: 0.46495819, Validation loss: 0.35855592, Gradient norm: 5.51825823
INFO:root:At the start of the epoch: mem (CPU python)=4834.8359375MB; mem (CPU total)=17174.94140625MB
INFO:root:[   22] Training loss: 0.46304214, Validation loss: 0.34155501, Gradient norm: 5.52812794
INFO:root:At the start of the epoch: mem (CPU python)=4856.0MB; mem (CPU total)=17204.95703125MB
INFO:root:[   23] Training loss: 0.49907487, Validation loss: 0.32978938, Gradient norm: 7.43247290
INFO:root:At the start of the epoch: mem (CPU python)=4877.171875MB; mem (CPU total)=17238.9765625MB
INFO:root:[   24] Training loss: 0.46680941, Validation loss: 0.33365554, Gradient norm: 5.88698000
INFO:root:At the start of the epoch: mem (CPU python)=4898.33984375MB; mem (CPU total)=17322.734375MB
INFO:root:[   25] Training loss: 0.46647563, Validation loss: 0.34080982, Gradient norm: 6.02539877
INFO:root:At the start of the epoch: mem (CPU python)=4919.546875MB; mem (CPU total)=17450.19140625MB
INFO:root:[   26] Training loss: 0.45958358, Validation loss: 0.33733926, Gradient norm: 5.82558600
INFO:root:At the start of the epoch: mem (CPU python)=4940.73828125MB; mem (CPU total)=17389.515625MB
INFO:root:[   27] Training loss: 0.45834909, Validation loss: 0.35874206, Gradient norm: 6.02171772
INFO:root:At the start of the epoch: mem (CPU python)=4961.92578125MB; mem (CPU total)=17461.34765625MB
INFO:root:[   28] Training loss: 0.45616749, Validation loss: 0.31697261, Gradient norm: 6.04233373
INFO:root:At the start of the epoch: mem (CPU python)=4983.109375MB; mem (CPU total)=17506.32421875MB
INFO:root:[   29] Training loss: 0.45789958, Validation loss: 0.34267407, Gradient norm: 6.32075611
INFO:root:At the start of the epoch: mem (CPU python)=5004.29296875MB; mem (CPU total)=17549.6171875MB
INFO:root:[   30] Training loss: 0.45812971, Validation loss: 0.31010164, Gradient norm: 6.39685303
INFO:root:At the start of the epoch: mem (CPU python)=5025.46484375MB; mem (CPU total)=17619.7578125MB
INFO:root:[   31] Training loss: 0.45492203, Validation loss: 0.32531769, Gradient norm: 6.38938694
INFO:root:At the start of the epoch: mem (CPU python)=5046.62890625MB; mem (CPU total)=17755.6484375MB
INFO:root:[   32] Training loss: 0.45378954, Validation loss: 0.31336332, Gradient norm: 6.66858865
INFO:root:At the start of the epoch: mem (CPU python)=5067.79296875MB; mem (CPU total)=17728.85546875MB
INFO:root:[   33] Training loss: 0.45268687, Validation loss: 0.32696136, Gradient norm: 6.52857481
INFO:root:At the start of the epoch: mem (CPU python)=5088.953125MB; mem (CPU total)=17757.34765625MB
INFO:root:[   34] Training loss: 0.45339862, Validation loss: 0.31309874, Gradient norm: 6.85185541
INFO:root:At the start of the epoch: mem (CPU python)=5110.12109375MB; mem (CPU total)=17603.8359375MB
INFO:root:[   35] Training loss: 0.45315676, Validation loss: 0.35274899, Gradient norm: 6.93680314
INFO:root:At the start of the epoch: mem (CPU python)=5131.28125MB; mem (CPU total)=17842.13671875MB
INFO:root:[   36] Training loss: 0.45534384, Validation loss: 0.32598739, Gradient norm: 7.01350982
INFO:root:At the start of the epoch: mem (CPU python)=5152.4453125MB; mem (CPU total)=17921.0234375MB
INFO:root:[   37] Training loss: 0.44960024, Validation loss: 0.31851455, Gradient norm: 6.63263181
INFO:root:At the start of the epoch: mem (CPU python)=5173.63671875MB; mem (CPU total)=17938.1484375MB
INFO:root:[   38] Training loss: 0.44981192, Validation loss: 0.31656241, Gradient norm: 6.88855414
INFO:root:At the start of the epoch: mem (CPU python)=5194.81640625MB; mem (CPU total)=18008.4921875MB
INFO:root:[   39] Training loss: 0.44808654, Validation loss: 0.30334904, Gradient norm: 6.87684830
INFO:root:At the start of the epoch: mem (CPU python)=5216.23046875MB; mem (CPU total)=18010.86328125MB
INFO:root:[   40] Training loss: 0.44664111, Validation loss: 0.34951083, Gradient norm: 6.64148049
INFO:root:At the start of the epoch: mem (CPU python)=5237.76953125MB; mem (CPU total)=18031.86328125MB
INFO:root:[   41] Training loss: 0.44597637, Validation loss: 0.34752399, Gradient norm: 6.65807973
INFO:root:At the start of the epoch: mem (CPU python)=5259.17578125MB; mem (CPU total)=18061.44140625MB
INFO:root:[   42] Training loss: 0.77431842, Validation loss: 0.61128134, Gradient norm: 12.83590699
INFO:root:At the start of the epoch: mem (CPU python)=5280.4765625MB; mem (CPU total)=18088.62890625MB
INFO:root:[   43] Training loss: 0.65824175, Validation loss: 0.48961980, Gradient norm: 5.83272908
INFO:root:At the start of the epoch: mem (CPU python)=5302.23828125MB; mem (CPU total)=18108.70703125MB
INFO:root:[   44] Training loss: 0.62869123, Validation loss: 0.46784916, Gradient norm: 9.75403503
INFO:root:At the start of the epoch: mem (CPU python)=5323.7734375MB; mem (CPU total)=18206.96484375MB
INFO:root:[   45] Training loss: 0.60184354, Validation loss: 0.46996755, Gradient norm: 8.14910380
INFO:root:At the start of the epoch: mem (CPU python)=5344.9375MB; mem (CPU total)=18174.27734375MB
INFO:root:[   46] Training loss: 0.58927246, Validation loss: 0.44881793, Gradient norm: 7.68920263
INFO:root:At the start of the epoch: mem (CPU python)=5366.1015625MB; mem (CPU total)=18168.68359375MB
INFO:root:[   47] Training loss: 0.58280757, Validation loss: 0.45006205, Gradient norm: 7.56101320
INFO:root:At the start of the epoch: mem (CPU python)=5387.265625MB; mem (CPU total)=18206.3046875MB
INFO:root:[   48] Training loss: 0.59515297, Validation loss: 0.45630889, Gradient norm: 9.82173581
INFO:root:At the start of the epoch: mem (CPU python)=5408.4296875MB; mem (CPU total)=18222.734375MB
INFO:root:[   49] Training loss: 0.59147956, Validation loss: 0.46019786, Gradient norm: 10.09184671
INFO:root:At the start of the epoch: mem (CPU python)=5429.59375MB; mem (CPU total)=18238.28125MB
INFO:root:[   50] Training loss: 0.79707560, Validation loss: 0.72284166, Gradient norm: 36.25892520
INFO:root:At the start of the epoch: mem (CPU python)=5450.76171875MB; mem (CPU total)=18253.3046875MB
INFO:root:[   51] Training loss: 0.65227011, Validation loss: 0.48757379, Gradient norm: 11.65389359
INFO:root:At the start of the epoch: mem (CPU python)=5471.92578125MB; mem (CPU total)=18341.21484375MB
INFO:root:[   52] Training loss: 0.62630547, Validation loss: 0.47193267, Gradient norm: 11.87455155
INFO:root:At the start of the epoch: mem (CPU python)=5493.08203125MB; mem (CPU total)=18390.265625MB
INFO:root:[   53] Training loss: 0.61008751, Validation loss: 0.46511097, Gradient norm: 10.73347578
INFO:root:At the start of the epoch: mem (CPU python)=5514.24609375MB; mem (CPU total)=18461.25390625MB
INFO:root:[   54] Training loss: 0.62403654, Validation loss: 0.47445480, Gradient norm: 14.92252478
INFO:root:At the start of the epoch: mem (CPU python)=5535.41015625MB; mem (CPU total)=18501.06640625MB
INFO:root:[   55] Training loss: 0.60486342, Validation loss: 0.46158438, Gradient norm: 11.57596705
INFO:root:At the start of the epoch: mem (CPU python)=5556.578125MB; mem (CPU total)=18574.59765625MB
INFO:root:[   56] Training loss: 0.61013636, Validation loss: 0.47654523, Gradient norm: 12.45588066
INFO:root:At the start of the epoch: mem (CPU python)=5577.7421875MB; mem (CPU total)=18660.71484375MB
INFO:root:[   57] Training loss: 0.60483035, Validation loss: 0.45141067, Gradient norm: 12.94302712
INFO:root:At the start of the epoch: mem (CPU python)=5598.90625MB; mem (CPU total)=18813.08203125MB
INFO:root:[   58] Training loss: 0.96613902, Validation loss: 0.57236310, Gradient norm: 33.49282483
INFO:root:At the start of the epoch: mem (CPU python)=5620.0703125MB; mem (CPU total)=18791.53515625MB
INFO:root:[   59] Training loss: 0.61856259, Validation loss: 0.45194686, Gradient norm: 11.26155678
INFO:root:At the start of the epoch: mem (CPU python)=5641.234375MB; mem (CPU total)=18858.328125MB
INFO:root:[   60] Training loss: 0.59505383, Validation loss: 0.45469523, Gradient norm: 9.44624062
INFO:root:At the start of the epoch: mem (CPU python)=5662.3984375MB; mem (CPU total)=18923.90234375MB
INFO:root:[   61] Training loss: 0.59458402, Validation loss: 0.45471441, Gradient norm: 10.65673534
INFO:root:At the start of the epoch: mem (CPU python)=5683.5625MB; mem (CPU total)=18964.578125MB
INFO:root:[   62] Training loss: 0.60809920, Validation loss: 0.45521757, Gradient norm: 14.26365325
INFO:root:At the start of the epoch: mem (CPU python)=5704.7265625MB; mem (CPU total)=19037.52734375MB
INFO:root:[   63] Training loss: 0.60992910, Validation loss: 0.45538667, Gradient norm: 14.91205109
INFO:root:At the start of the epoch: mem (CPU python)=5725.890625MB; mem (CPU total)=18664.10546875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   64] Training loss: 0.58954446, Validation loss: 0.44745293, Gradient norm: 11.17069176
INFO:root:At the start of the epoch: mem (CPU python)=5747.0546875MB; mem (CPU total)=19187.98046875MB
INFO:root:[   65] Training loss: 0.57305088, Validation loss: 0.44197479, Gradient norm: 8.32856360
INFO:root:At the start of the epoch: mem (CPU python)=5768.21875MB; mem (CPU total)=19242.4453125MB
INFO:root:[   66] Training loss: 0.57159123, Validation loss: 0.43604752, Gradient norm: 10.78409509
INFO:root:At the start of the epoch: mem (CPU python)=5789.38671875MB; mem (CPU total)=19287.94921875MB
INFO:root:[   67] Training loss: 0.57879442, Validation loss: 0.59822976, Gradient norm: 15.30571995
INFO:root:At the start of the epoch: mem (CPU python)=5810.55078125MB; mem (CPU total)=19364.16015625MB
INFO:root:[   68] Training loss: 0.60012530, Validation loss: 0.45280318, Gradient norm: 24.76279874
INFO:root:At the start of the epoch: mem (CPU python)=5831.71484375MB; mem (CPU total)=19407.96875MB
INFO:root:[   69] Training loss: 0.58739041, Validation loss: 0.44234262, Gradient norm: 20.95162763
INFO:root:At the start of the epoch: mem (CPU python)=5852.875MB; mem (CPU total)=19506.23046875MB
INFO:root:[   70] Training loss: 0.58019500, Validation loss: 0.44876187, Gradient norm: 20.27257267
INFO:root:At the start of the epoch: mem (CPU python)=5874.0390625MB; mem (CPU total)=19669.71484375MB
INFO:root:[   71] Training loss: 0.57805485, Validation loss: 0.43828319, Gradient norm: 19.37095720
INFO:root:At the start of the epoch: mem (CPU python)=5895.203125MB; mem (CPU total)=19622.80078125MB
INFO:root:[   72] Training loss: 0.57691198, Validation loss: 0.43465611, Gradient norm: 20.52191933
INFO:root:At the start of the epoch: mem (CPU python)=5916.3671875MB; mem (CPU total)=19684.92578125MB
INFO:root:[   73] Training loss: 0.58287521, Validation loss: 0.44263918, Gradient norm: 23.79700865
INFO:root:At the start of the epoch: mem (CPU python)=5937.53125MB; mem (CPU total)=19753.33203125MB
INFO:root:[   74] Training loss: 0.57314867, Validation loss: 0.43345473, Gradient norm: 20.56205562
INFO:root:At the start of the epoch: mem (CPU python)=5958.6953125MB; mem (CPU total)=19787.37890625MB
INFO:root:[   75] Training loss: 0.57480063, Validation loss: 0.43233136, Gradient norm: 22.65515520
INFO:root:At the start of the epoch: mem (CPU python)=5979.859375MB; mem (CPU total)=19852.97265625MB
INFO:root:[   76] Training loss: 0.56645054, Validation loss: 0.41387762, Gradient norm: 20.82313377
INFO:root:At the start of the epoch: mem (CPU python)=6001.0234375MB; mem (CPU total)=20049.61328125MB
INFO:root:[   77] Training loss: 0.58842969, Validation loss: 0.42593034, Gradient norm: 29.27510826
INFO:root:At the start of the epoch: mem (CPU python)=6022.4296875MB; mem (CPU total)=20026.69140625MB
INFO:root:[   78] Training loss: 0.56625868, Validation loss: 0.42935736, Gradient norm: 25.70411409
INFO:root:At the start of the epoch: mem (CPU python)=6043.59765625MB; mem (CPU total)=20068.04296875MB
INFO:root:[   79] Training loss: 0.56211499, Validation loss: 0.42026385, Gradient norm: 23.68634541
INFO:root:At the start of the epoch: mem (CPU python)=6064.76171875MB; mem (CPU total)=20101.2109375MB
INFO:root:[   80] Training loss: 0.57969796, Validation loss: 0.41350331, Gradient norm: 29.22993271
INFO:root:At the start of the epoch: mem (CPU python)=6086.046875MB; mem (CPU total)=20187.109375MB
INFO:root:[   81] Training loss: 0.56955509, Validation loss: 0.41802170, Gradient norm: 28.51721302
INFO:root:At the start of the epoch: mem (CPU python)=6107.2109375MB; mem (CPU total)=20270.37109375MB
INFO:root:[   82] Training loss: 0.55857804, Validation loss: 0.40485165, Gradient norm: 23.83479804
INFO:root:At the start of the epoch: mem (CPU python)=6128.375MB; mem (CPU total)=20309.75MB
INFO:root:[   83] Training loss: 0.55620727, Validation loss: 0.41683120, Gradient norm: 22.43668550
INFO:root:At the start of the epoch: mem (CPU python)=6149.5390625MB; mem (CPU total)=20437.08984375MB
INFO:root:[   84] Training loss: 0.56741860, Validation loss: 0.42078205, Gradient norm: 26.30272127
INFO:root:At the start of the epoch: mem (CPU python)=6170.71484375MB; mem (CPU total)=20445.80859375MB
INFO:root:[   85] Training loss: 0.57327045, Validation loss: 0.42801216, Gradient norm: 27.86526558
INFO:root:At the start of the epoch: mem (CPU python)=6191.87890625MB; mem (CPU total)=20509.45703125MB
INFO:root:[   86] Training loss: 0.56864861, Validation loss: 0.40715143, Gradient norm: 28.98674856
INFO:root:At the start of the epoch: mem (CPU python)=6213.0390625MB; mem (CPU total)=20572.734375MB
INFO:root:[   87] Training loss: 0.55701400, Validation loss: 0.40836224, Gradient norm: 25.55901976
INFO:root:At the start of the epoch: mem (CPU python)=6234.203125MB; mem (CPU total)=20658.8203125MB
INFO:root:[   88] Training loss: 0.55411965, Validation loss: 0.40477846, Gradient norm: 24.08994076
INFO:root:At the start of the epoch: mem (CPU python)=6255.3671875MB; mem (CPU total)=20743.80078125MB
INFO:root:[   89] Training loss: 0.60360263, Validation loss: 0.40909635, Gradient norm: 33.73546573
INFO:root:At the start of the epoch: mem (CPU python)=6276.53515625MB; mem (CPU total)=20832.5703125MB
INFO:root:[   90] Training loss: 0.59770267, Validation loss: 0.43305895, Gradient norm: 36.84674004
INFO:root:At the start of the epoch: mem (CPU python)=6297.6953125MB; mem (CPU total)=20833.9609375MB
INFO:root:[   91] Training loss: 0.63766833, Validation loss: 0.46337443, Gradient norm: 48.02372475
INFO:root:At the start of the epoch: mem (CPU python)=6318.859375MB; mem (CPU total)=20916.63671875MB
INFO:root:[   92] Training loss: 0.62560098, Validation loss: 0.43083421, Gradient norm: 50.83508537
INFO:root:At the start of the epoch: mem (CPU python)=6340.0234375MB; mem (CPU total)=20942.4453125MB
INFO:root:[   93] Training loss: 0.57042130, Validation loss: 0.41438070, Gradient norm: 34.63795603
INFO:root:At the start of the epoch: mem (CPU python)=6361.1875MB; mem (CPU total)=21006.70703125MB
INFO:root:[   94] Training loss: 0.60103247, Validation loss: 0.43479200, Gradient norm: 38.85645174
INFO:root:At the start of the epoch: mem (CPU python)=6382.3515625MB; mem (CPU total)=21078.37890625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   95] Training loss: 0.57358343, Validation loss: 0.40290972, Gradient norm: 35.37743010
INFO:root:At the start of the epoch: mem (CPU python)=6403.51953125MB; mem (CPU total)=21219.16796875MB
INFO:root:[   96] Training loss: 0.54850098, Validation loss: 0.39691065, Gradient norm: 19.32744246
INFO:root:At the start of the epoch: mem (CPU python)=6424.68359375MB; mem (CPU total)=21178.515625MB
INFO:root:[   97] Training loss: 0.54555669, Validation loss: 0.40023261, Gradient norm: 21.11433547
INFO:root:At the start of the epoch: mem (CPU python)=6445.84765625MB; mem (CPU total)=21222.96875MB
INFO:root:[   98] Training loss: 0.55087952, Validation loss: 0.40355060, Gradient norm: 26.48202061
INFO:root:At the start of the epoch: mem (CPU python)=6467.01171875MB; mem (CPU total)=21247.76171875MB
INFO:root:[   99] Training loss: 0.54492594, Validation loss: 0.39964111, Gradient norm: 25.73092910
INFO:root:At the start of the epoch: mem (CPU python)=6488.171875MB; mem (CPU total)=21335.26171875MB
INFO:root:[  100] Training loss: 0.54324058, Validation loss: 0.39303438, Gradient norm: 25.26617056
INFO:root:At the start of the epoch: mem (CPU python)=6509.33984375MB; mem (CPU total)=21370.5234375MB
INFO:root:[  101] Training loss: 0.54239271, Validation loss: 0.40269932, Gradient norm: 26.51235309
INFO:root:At the start of the epoch: mem (CPU python)=6530.50390625MB; mem (CPU total)=21409.66796875MB
INFO:root:[  102] Training loss: 0.54819836, Validation loss: 0.39100731, Gradient norm: 31.92489079
INFO:root:At the start of the epoch: mem (CPU python)=6551.66796875MB; mem (CPU total)=21474.765625MB
INFO:root:[  103] Training loss: 0.54217910, Validation loss: 0.39159084, Gradient norm: 29.64275389
INFO:root:At the start of the epoch: mem (CPU python)=6572.828125MB; mem (CPU total)=21501.13671875MB
INFO:root:[  104] Training loss: 0.58351377, Validation loss: 0.40323836, Gradient norm: 58.46516689
INFO:root:At the start of the epoch: mem (CPU python)=6593.9921875MB; mem (CPU total)=21565.40625MB
INFO:root:[  105] Training loss: 0.54788856, Validation loss: 0.39883639, Gradient norm: 38.94484170
INFO:root:At the start of the epoch: mem (CPU python)=6615.16015625MB; mem (CPU total)=21577.84765625MB
INFO:root:[  106] Training loss: 0.54364320, Validation loss: 0.39104094, Gradient norm: 34.43597415
INFO:root:At the start of the epoch: mem (CPU python)=6636.32421875MB; mem (CPU total)=21491.7734375MB
INFO:root:[  107] Training loss: 0.54851949, Validation loss: 0.40007488, Gradient norm: 36.98400363
INFO:root:At the start of the epoch: mem (CPU python)=6657.4921875MB; mem (CPU total)=21699.6328125MB
INFO:root:[  108] Training loss: 0.54238428, Validation loss: 0.39813805, Gradient norm: 35.44301221
INFO:root:At the start of the epoch: mem (CPU python)=6678.65234375MB; mem (CPU total)=21738.65625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[  109] Training loss: 0.56342201, Validation loss: 0.40039791, Gradient norm: 48.04322685
INFO:root:At the start of the epoch: mem (CPU python)=6699.81640625MB; mem (CPU total)=21788.203125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[  110] Training loss: 0.54046707, Validation loss: 0.39161359, Gradient norm: 27.53893287
INFO:root:At the start of the epoch: mem (CPU python)=6720.98046875MB; mem (CPU total)=21831.48828125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  111] Training loss: 0.53514260, Validation loss: 0.38836841, Gradient norm: 17.30620760
INFO:root:At the start of the epoch: mem (CPU python)=6742.14453125MB; mem (CPU total)=21920.7109375MB
INFO:root:[  112] Training loss: 0.53358792, Validation loss: 0.38791625, Gradient norm: 13.57420849
INFO:root:At the start of the epoch: mem (CPU python)=6763.3125MB; mem (CPU total)=21569.01171875MB
INFO:root:[  113] Training loss: 0.53273312, Validation loss: 0.38841493, Gradient norm: 13.51881197
INFO:root:At the start of the epoch: mem (CPU python)=6784.4765625MB; mem (CPU total)=21972.70703125MB
INFO:root:[  114] Training loss: 0.53214570, Validation loss: 0.38950872, Gradient norm: 13.90309517
INFO:root:At the start of the epoch: mem (CPU python)=6805.640625MB; mem (CPU total)=22004.35546875MB
INFO:root:[  115] Training loss: 0.53187443, Validation loss: 0.38594555, Gradient norm: 14.04853650
INFO:root:At the start of the epoch: mem (CPU python)=6826.8046875MB; mem (CPU total)=22860.3828125MB
INFO:root:[  116] Training loss: 0.53162160, Validation loss: 0.38683018, Gradient norm: 15.21215693
INFO:root:At the start of the epoch: mem (CPU python)=6847.96875MB; mem (CPU total)=22142.80078125MB
INFO:root:[  117] Training loss: 0.53136301, Validation loss: 0.38539758, Gradient norm: 15.49921141
INFO:root:At the start of the epoch: mem (CPU python)=6869.13671875MB; mem (CPU total)=22182.03125MB
INFO:root:[  118] Training loss: 0.53079433, Validation loss: 0.38663295, Gradient norm: 14.96661348
INFO:root:At the start of the epoch: mem (CPU python)=6890.296875MB; mem (CPU total)=22263.94140625MB
INFO:root:[  119] Training loss: 0.53070077, Validation loss: 0.38453735, Gradient norm: 16.42890547
INFO:root:At the start of the epoch: mem (CPU python)=6911.4609375MB; mem (CPU total)=22296.5MB
INFO:root:[  120] Training loss: 0.53061009, Validation loss: 0.38601189, Gradient norm: 18.40314457
INFO:root:At the start of the epoch: mem (CPU python)=6932.62109375MB; mem (CPU total)=21969.640625MB
INFO:root:[  121] Training loss: 0.53037984, Validation loss: 0.38661416, Gradient norm: 16.52045453
INFO:root:At the start of the epoch: mem (CPU python)=6953.78515625MB; mem (CPU total)=22148.75390625MB
INFO:root:[  122] Training loss: 0.53011024, Validation loss: 0.38481834, Gradient norm: 17.33750397
INFO:root:At the start of the epoch: mem (CPU python)=6974.94921875MB; mem (CPU total)=22399.21484375MB
INFO:root:[  123] Training loss: 0.52980150, Validation loss: 0.38529318, Gradient norm: 18.23606215
INFO:root:At the start of the epoch: mem (CPU python)=6996.1171875MB; mem (CPU total)=22490.02734375MB
INFO:root:[  124] Training loss: 0.52955825, Validation loss: 0.38541715, Gradient norm: 18.23868975
INFO:root:At the start of the epoch: mem (CPU python)=7017.28125MB; mem (CPU total)=22506.86328125MB
INFO:root:[  125] Training loss: 0.53026371, Validation loss: 0.38623507, Gradient norm: 20.23071227
INFO:root:At the start of the epoch: mem (CPU python)=7038.4453125MB; mem (CPU total)=22282.33203125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  126] Training loss: 0.52977127, Validation loss: 0.38500719, Gradient norm: 20.08190158
INFO:root:At the start of the epoch: mem (CPU python)=7059.609375MB; mem (CPU total)=22554.875MB
INFO:root:[  127] Training loss: 0.52888308, Validation loss: 0.38387264, Gradient norm: 15.03342457
INFO:root:At the start of the epoch: mem (CPU python)=7080.76953125MB; mem (CPU total)=22575.41796875MB
INFO:root:[  128] Training loss: 0.52892513, Validation loss: 0.38357591, Gradient norm: 15.39947749
INFO:root:At the start of the epoch: mem (CPU python)=7101.9375MB; mem (CPU total)=22590.41796875MB
INFO:root:[  129] Training loss: 0.52861949, Validation loss: 0.38471565, Gradient norm: 15.18052588
INFO:root:At the start of the epoch: mem (CPU python)=7123.1015625MB; mem (CPU total)=22650.27734375MB
INFO:root:[  130] Training loss: 0.52869599, Validation loss: 0.38360867, Gradient norm: 15.01820636
INFO:root:At the start of the epoch: mem (CPU python)=7144.265625MB; mem (CPU total)=22456.015625MB
INFO:root:[  131] Training loss: 0.52891105, Validation loss: 0.38558512, Gradient norm: 15.43623526
INFO:root:At the start of the epoch: mem (CPU python)=7165.4296875MB; mem (CPU total)=22650.75390625MB
INFO:root:[  132] Training loss: 0.52879164, Validation loss: 0.38321569, Gradient norm: 15.70227870
INFO:root:At the start of the epoch: mem (CPU python)=7186.59375MB; mem (CPU total)=22413.9609375MB
INFO:root:[  133] Training loss: 0.52871807, Validation loss: 0.38445140, Gradient norm: 15.74716923
INFO:root:At the start of the epoch: mem (CPU python)=7207.7578125MB; mem (CPU total)=22698.1171875MB
INFO:root:[  134] Training loss: 0.52831230, Validation loss: 0.38378536, Gradient norm: 15.72736128
INFO:root:At the start of the epoch: mem (CPU python)=7228.92578125MB; mem (CPU total)=22495.6953125MB
INFO:root:[  135] Training loss: 0.52848640, Validation loss: 0.38376205, Gradient norm: 16.13941434
INFO:root:At the start of the epoch: mem (CPU python)=7250.08984375MB; mem (CPU total)=22729.9765625MB
INFO:root:[  136] Training loss: 0.52825748, Validation loss: 0.38316368, Gradient norm: 16.86200754
INFO:root:At the start of the epoch: mem (CPU python)=7271.25390625MB; mem (CPU total)=10598.015625MB
INFO:root:[  137] Training loss: 0.52822970, Validation loss: 0.38431049, Gradient norm: 17.65299008
INFO:root:At the start of the epoch: mem (CPU python)=7292.41015625MB; mem (CPU total)=10611.20703125MB
INFO:root:[  138] Training loss: 0.52817201, Validation loss: 0.38325786, Gradient norm: 17.43681259
INFO:root:At the start of the epoch: mem (CPU python)=7313.578125MB; mem (CPU total)=10231.59765625MB
INFO:root:[  139] Training loss: 0.52797236, Validation loss: 0.38447527, Gradient norm: 16.73117275
INFO:root:At the start of the epoch: mem (CPU python)=7334.7421875MB; mem (CPU total)=10656.9609375MB
INFO:root:[  140] Training loss: 0.52830197, Validation loss: 0.38439097, Gradient norm: 17.41710322
INFO:root:At the start of the epoch: mem (CPU python)=7356.03125MB; mem (CPU total)=10676.421875MB
INFO:root:[  141] Training loss: 0.52792510, Validation loss: 0.38291278, Gradient norm: 18.17422997
INFO:root:At the start of the epoch: mem (CPU python)=7377.3203125MB; mem (CPU total)=10875.73828125MB
INFO:root:[  142] Training loss: 0.52819107, Validation loss: 0.38391628, Gradient norm: 18.03517053
INFO:root:At the start of the epoch: mem (CPU python)=7398.484375MB; mem (CPU total)=10728.53515625MB
INFO:root:[  143] Training loss: 0.52784640, Validation loss: 0.38381617, Gradient norm: 18.25319977
INFO:root:At the start of the epoch: mem (CPU python)=7419.65234375MB; mem (CPU total)=10507.82421875MB
INFO:root:[  144] Training loss: 0.52793226, Validation loss: 0.38303656, Gradient norm: 19.77108462
INFO:root:At the start of the epoch: mem (CPU python)=7440.94140625MB; mem (CPU total)=10777.4140625MB
INFO:root:[  145] Training loss: 0.52788387, Validation loss: 0.38307991, Gradient norm: 19.33180164
INFO:root:At the start of the epoch: mem (CPU python)=7462.109375MB; mem (CPU total)=10799.28515625MB
INFO:root:[  146] Training loss: 0.52787214, Validation loss: 0.38487096, Gradient norm: 20.77069923
INFO:root:At the start of the epoch: mem (CPU python)=7483.26953125MB; mem (CPU total)=10802.88671875MB
INFO:root:[  147] Training loss: 0.52763398, Validation loss: 0.38400556, Gradient norm: 19.91741009
INFO:root:At the start of the epoch: mem (CPU python)=7504.43359375MB; mem (CPU total)=10835.10546875MB
INFO:root:[  148] Training loss: 0.52777591, Validation loss: 0.38302575, Gradient norm: 20.61483705
INFO:root:At the start of the epoch: mem (CPU python)=7525.59765625MB; mem (CPU total)=10847.75390625MB
INFO:root:[  149] Training loss: 0.52745218, Validation loss: 0.38219080, Gradient norm: 20.16670663
INFO:root:At the start of the epoch: mem (CPU python)=7546.76171875MB; mem (CPU total)=10861.4609375MB
INFO:root:[  150] Training loss: 0.52763639, Validation loss: 0.38244211, Gradient norm: 21.66400897
INFO:root:At the start of the epoch: mem (CPU python)=7567.92578125MB; mem (CPU total)=10737.92578125MB
INFO:root:[  151] Training loss: 0.52750884, Validation loss: 0.38275654, Gradient norm: 21.20635245
INFO:root:At the start of the epoch: mem (CPU python)=7589.08984375MB; mem (CPU total)=10898.49609375MB
INFO:root:[  152] Training loss: 0.52728864, Validation loss: 0.38293100, Gradient norm: 20.25720111
INFO:root:At the start of the epoch: mem (CPU python)=7610.2578125MB; mem (CPU total)=10935.140625MB
INFO:root:[  153] Training loss: 0.52721925, Validation loss: 0.38399055, Gradient norm: 20.55958122
INFO:root:At the start of the epoch: mem (CPU python)=7631.421875MB; mem (CPU total)=10940.8671875MB
INFO:root:[  154] Training loss: 0.52729091, Validation loss: 0.38216302, Gradient norm: 21.21010306
INFO:root:At the start of the epoch: mem (CPU python)=7652.58203125MB; mem (CPU total)=10977.9921875MB
INFO:root:[  155] Training loss: 0.52693363, Validation loss: 0.38132415, Gradient norm: 22.32698336
INFO:root:At the start of the epoch: mem (CPU python)=7673.7421875MB; mem (CPU total)=10998.68359375MB
INFO:root:[  156] Training loss: 0.52698510, Validation loss: 0.38181073, Gradient norm: 21.19550831
INFO:root:At the start of the epoch: mem (CPU python)=7694.90625MB; mem (CPU total)=11005.3984375MB
INFO:root:[  157] Training loss: 0.52704750, Validation loss: 0.38141962, Gradient norm: 21.83534935
INFO:root:At the start of the epoch: mem (CPU python)=7716.07421875MB; mem (CPU total)=10677.99609375MB
INFO:root:[  158] Training loss: 0.52702646, Validation loss: 0.38350558, Gradient norm: 21.39975000
INFO:root:At the start of the epoch: mem (CPU python)=7737.23828125MB; mem (CPU total)=11059.53125MB
INFO:root:[  159] Training loss: 0.52658956, Validation loss: 0.38101867, Gradient norm: 21.78999511
INFO:root:At the start of the epoch: mem (CPU python)=7758.40234375MB; mem (CPU total)=11067.640625MB
INFO:root:[  160] Training loss: 0.52685406, Validation loss: 0.38317812, Gradient norm: 22.69205220
INFO:root:At the start of the epoch: mem (CPU python)=7779.56640625MB; mem (CPU total)=10860.11328125MB
INFO:root:[  161] Training loss: 0.52658091, Validation loss: 0.38199757, Gradient norm: 23.42267007
INFO:root:At the start of the epoch: mem (CPU python)=7800.73046875MB; mem (CPU total)=11109.40625MB
INFO:root:[  162] Training loss: 0.52668576, Validation loss: 0.38217818, Gradient norm: 22.76013052
INFO:root:At the start of the epoch: mem (CPU python)=7821.89453125MB; mem (CPU total)=11121.69140625MB
INFO:root:[  163] Training loss: 0.52699313, Validation loss: 0.38303229, Gradient norm: 24.69017813
INFO:root:At the start of the epoch: mem (CPU python)=7843.0625MB; mem (CPU total)=11149.46875MB
INFO:root:[  164] Training loss: 0.52657290, Validation loss: 0.38300462, Gradient norm: 23.35799303
INFO:root:At the start of the epoch: mem (CPU python)=7864.2265625MB; mem (CPU total)=11187.390625MB
INFO:root:[  165] Training loss: 0.52650833, Validation loss: 0.38067621, Gradient norm: 24.21127734
INFO:root:At the start of the epoch: mem (CPU python)=7885.38671875MB; mem (CPU total)=11227.00390625MB
INFO:root:[  166] Training loss: 0.52658117, Validation loss: 0.38121868, Gradient norm: 23.17034924
INFO:root:At the start of the epoch: mem (CPU python)=7906.55078125MB; mem (CPU total)=11215.859375MB
INFO:root:[  167] Training loss: 0.52677095, Validation loss: 0.38302542, Gradient norm: 24.54908602
INFO:root:At the start of the epoch: mem (CPU python)=7927.71484375MB; mem (CPU total)=11242.71875MB
INFO:root:[  168] Training loss: 0.52635425, Validation loss: 0.38201933, Gradient norm: 26.26187734
INFO:root:At the start of the epoch: mem (CPU python)=7948.87890625MB; mem (CPU total)=11268.57421875MB
INFO:root:[  169] Training loss: 0.52634485, Validation loss: 0.38225195, Gradient norm: 23.98859039
INFO:root:At the start of the epoch: mem (CPU python)=7970.046875MB; mem (CPU total)=11301.9296875MB
INFO:root:[  170] Training loss: 0.52642164, Validation loss: 0.38155192, Gradient norm: 25.11737828
INFO:root:At the start of the epoch: mem (CPU python)=7991.2109375MB; mem (CPU total)=11301.0390625MB
INFO:root:[  171] Training loss: 0.52626501, Validation loss: 0.38191469, Gradient norm: 26.21297208
INFO:root:At the start of the epoch: mem (CPU python)=8012.37109375MB; mem (CPU total)=11331.953125MB
INFO:root:[  172] Training loss: 0.52606184, Validation loss: 0.38065597, Gradient norm: 26.06198313
INFO:root:At the start of the epoch: mem (CPU python)=8033.53515625MB; mem (CPU total)=11364.10546875MB
INFO:root:[  173] Training loss: 0.52614111, Validation loss: 0.38109104, Gradient norm: 25.76717207
INFO:root:At the start of the epoch: mem (CPU python)=8054.69921875MB; mem (CPU total)=11366.171875MB
INFO:root:[  174] Training loss: 0.52616363, Validation loss: 0.38359409, Gradient norm: 26.57397867
INFO:root:At the start of the epoch: mem (CPU python)=8075.86328125MB; mem (CPU total)=11415.953125MB
INFO:root:[  175] Training loss: 0.52603433, Validation loss: 0.38319232, Gradient norm: 25.55942645
INFO:root:At the start of the epoch: mem (CPU python)=8097.02734375MB; mem (CPU total)=11418.7734375MB
INFO:root:[  176] Training loss: 0.52570681, Validation loss: 0.38228365, Gradient norm: 26.37731223
INFO:root:At the start of the epoch: mem (CPU python)=8118.19140625MB; mem (CPU total)=11441.36328125MB
INFO:root:[  177] Training loss: 0.52635483, Validation loss: 0.38140360, Gradient norm: 27.51096187
INFO:root:At the start of the epoch: mem (CPU python)=8139.35546875MB; mem (CPU total)=11460.15234375MB
INFO:root:[  178] Training loss: 0.52606337, Validation loss: 0.38078650, Gradient norm: 26.89191402
INFO:root:At the start of the epoch: mem (CPU python)=8160.51953125MB; mem (CPU total)=11478.703125MB
INFO:root:[  179] Training loss: 0.52575705, Validation loss: 0.38133070, Gradient norm: 25.73561699
INFO:root:At the start of the epoch: mem (CPU python)=8181.68359375MB; mem (CPU total)=11512.7578125MB
INFO:root:[  180] Training loss: 0.52585609, Validation loss: 0.38210625, Gradient norm: 28.62601249
INFO:root:At the start of the epoch: mem (CPU python)=8202.8515625MB; mem (CPU total)=11522.5703125MB
INFO:root:[  181] Training loss: 0.52572859, Validation loss: 0.38195397, Gradient norm: 27.03526669
INFO:root:At the start of the epoch: mem (CPU python)=8224.015625MB; mem (CPU total)=11544.4609375MB
INFO:root:[  182] Training loss: 0.52563878, Validation loss: 0.38048357, Gradient norm: 27.51319263
INFO:root:At the start of the epoch: mem (CPU python)=8245.1796875MB; mem (CPU total)=11558.9375MB
INFO:root:[  183] Training loss: 0.52544302, Validation loss: 0.38023988, Gradient norm: 27.14939077
INFO:root:At the start of the epoch: mem (CPU python)=8266.34375MB; mem (CPU total)=11252.45703125MB
INFO:root:[  184] Training loss: 0.52540649, Validation loss: 0.38193525, Gradient norm: 25.99680660
INFO:root:At the start of the epoch: mem (CPU python)=8287.50390625MB; mem (CPU total)=11613.1796875MB
INFO:root:[  185] Training loss: 0.52554049, Validation loss: 0.38248918, Gradient norm: 28.14447705
INFO:root:At the start of the epoch: mem (CPU python)=8308.671875MB; mem (CPU total)=11630.42578125MB
INFO:root:[  186] Training loss: 0.52546458, Validation loss: 0.37968093, Gradient norm: 29.77403858
INFO:root:At the start of the epoch: mem (CPU python)=8329.83984375MB; mem (CPU total)=11669.875MB
INFO:root:[  187] Training loss: 0.52528846, Validation loss: 0.38039115, Gradient norm: 28.11658255
INFO:root:At the start of the epoch: mem (CPU python)=8351.00390625MB; mem (CPU total)=11666.91796875MB
INFO:root:[  188] Training loss: 0.52518506, Validation loss: 0.38241261, Gradient norm: 26.80804959
INFO:root:At the start of the epoch: mem (CPU python)=8372.1640625MB; mem (CPU total)=11706.8203125MB
INFO:root:[  189] Training loss: 0.52545709, Validation loss: 0.38089836, Gradient norm: 29.81042946
INFO:root:At the start of the epoch: mem (CPU python)=8393.328125MB; mem (CPU total)=11716.35546875MB
INFO:root:[  190] Training loss: 0.52548148, Validation loss: 0.38096244, Gradient norm: 30.82155757
INFO:root:At the start of the epoch: mem (CPU python)=8414.49609375MB; mem (CPU total)=11749.15234375MB
INFO:root:[  191] Training loss: 0.52502114, Validation loss: 0.38069053, Gradient norm: 30.14107621
INFO:root:At the start of the epoch: mem (CPU python)=8435.66015625MB; mem (CPU total)=11751.125MB
INFO:root:[  192] Training loss: 0.52489700, Validation loss: 0.37989709, Gradient norm: 28.30833619
INFO:root:At the start of the epoch: mem (CPU python)=8456.82421875MB; mem (CPU total)=11767.38671875MB
INFO:root:[  193] Training loss: 0.52502708, Validation loss: 0.38175587, Gradient norm: 29.65487898
INFO:root:At the start of the epoch: mem (CPU python)=8477.984375MB; mem (CPU total)=11802.890625MB
INFO:root:[  194] Training loss: 0.52507369, Validation loss: 0.38037773, Gradient norm: 30.38243255
INFO:root:At the start of the epoch: mem (CPU python)=8499.1484375MB; mem (CPU total)=11822.79296875MB
INFO:root:[  195] Training loss: 0.52501160, Validation loss: 0.38067834, Gradient norm: 31.57896532
INFO:root:At the start of the epoch: mem (CPU python)=8520.3125MB; mem (CPU total)=11835.63671875MB
INFO:root:EP 195: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=8541.48046875MB; mem (CPU total)=11855.66796875MB
INFO:root:Training the model took 11478.586s.
INFO:root:Emptying the cuda cache took 0.05s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.39222
INFO:root:EnergyScoreValidation: 0.30367
INFO:root:CRPSValidation: 0.12422
INFO:root:Gaussian NLLValidation: 0.55357
INFO:root:CoverageValidation: 0.69993
INFO:root:IntervalWidthValidation: 0.39575
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.41597
INFO:root:EnergyScoreTest: 0.32634
INFO:root:CRPSTest: 0.13274
INFO:root:Gaussian NLLTest: 0.87967
INFO:root:CoverageTest: 0.67282
INFO:root:IntervalWidthTest: 0.38818
INFO:root:After validation: mem (CPU python)=8561.71484375MB; mem (CPU total)=11878.09375MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=8561.71484375MB; mem (CPU total)=11878.5703125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 62914560
INFO:root:After setting up the model: mem (CPU python)=8567.39453125MB; mem (CPU total)=11884.26171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=8567.48046875MB; mem (CPU total)=11885.578125MB
INFO:root:[    1] Training loss: 0.76076197, Validation loss: 0.66055122, Gradient norm: 0.33022061
INFO:root:At the start of the epoch: mem (CPU python)=8588.46484375MB; mem (CPU total)=11896.09375MB
INFO:root:[    2] Training loss: 0.66951784, Validation loss: 0.53270298, Gradient norm: 0.34325234
INFO:root:At the start of the epoch: mem (CPU python)=8609.64453125MB; mem (CPU total)=11919.3984375MB
INFO:root:[    3] Training loss: 0.56997769, Validation loss: 0.43589462, Gradient norm: 0.45009438
INFO:root:At the start of the epoch: mem (CPU python)=8630.83203125MB; mem (CPU total)=11950.9765625MB
INFO:root:[    4] Training loss: 0.52154006, Validation loss: 0.41167378, Gradient norm: 0.49537264
INFO:root:At the start of the epoch: mem (CPU python)=8652.00390625MB; mem (CPU total)=11984.84765625MB
INFO:root:[    5] Training loss: 0.49329723, Validation loss: 0.37319545, Gradient norm: 0.56177000
INFO:root:At the start of the epoch: mem (CPU python)=8673.16796875MB; mem (CPU total)=11980.765625MB
INFO:root:[    6] Training loss: 0.46622353, Validation loss: 0.35356127, Gradient norm: 0.62947859
INFO:root:At the start of the epoch: mem (CPU python)=8694.33203125MB; mem (CPU total)=12015.44140625MB
INFO:root:[    7] Training loss: 0.44828954, Validation loss: 0.33243810, Gradient norm: 0.69434958
INFO:root:At the start of the epoch: mem (CPU python)=8715.49609375MB; mem (CPU total)=12024.65625MB
INFO:root:[    8] Training loss: 0.43732144, Validation loss: 0.32748062, Gradient norm: 0.76465891
INFO:root:At the start of the epoch: mem (CPU python)=8736.6640625MB; mem (CPU total)=12047.89453125MB
INFO:root:[    9] Training loss: 0.42974449, Validation loss: 0.31891880, Gradient norm: 0.86397854
INFO:root:At the start of the epoch: mem (CPU python)=8757.828125MB; mem (CPU total)=12067.01953125MB
INFO:root:[   10] Training loss: 0.42709041, Validation loss: 0.31381096, Gradient norm: 1.04026270
INFO:root:At the start of the epoch: mem (CPU python)=8778.98828125MB; mem (CPU total)=12078.640625MB
INFO:root:[   11] Training loss: 0.42609976, Validation loss: 0.31671062, Gradient norm: 1.34120750
INFO:root:At the start of the epoch: mem (CPU python)=8800.15234375MB; mem (CPU total)=12120.98828125MB
INFO:root:[   12] Training loss: 0.42463235, Validation loss: 0.30481877, Gradient norm: 1.70024670
INFO:root:At the start of the epoch: mem (CPU python)=8821.31640625MB; mem (CPU total)=11939.6640625MB
INFO:root:[   13] Training loss: 0.42434109, Validation loss: 0.31338404, Gradient norm: 2.16164683
INFO:root:At the start of the epoch: mem (CPU python)=8842.48046875MB; mem (CPU total)=12129.6953125MB
INFO:root:[   14] Training loss: 0.42473155, Validation loss: 0.29992023, Gradient norm: 2.67954320
INFO:root:At the start of the epoch: mem (CPU python)=8863.64453125MB; mem (CPU total)=12176.1640625MB
INFO:root:[   15] Training loss: 0.42441161, Validation loss: 0.35011594, Gradient norm: 3.17439906
INFO:root:At the start of the epoch: mem (CPU python)=8884.80859375MB; mem (CPU total)=12208.44140625MB
INFO:root:[   16] Training loss: 0.42706298, Validation loss: 0.32827106, Gradient norm: 3.51984002
INFO:root:At the start of the epoch: mem (CPU python)=8905.97265625MB; mem (CPU total)=12212.2109375MB
INFO:root:[   17] Training loss: 0.42790890, Validation loss: 0.31929906, Gradient norm: 3.88432400
INFO:root:At the start of the epoch: mem (CPU python)=8927.13671875MB; mem (CPU total)=12239.1171875MB
INFO:root:[   18] Training loss: 0.42804115, Validation loss: 0.31496747, Gradient norm: 4.12541304
INFO:root:At the start of the epoch: mem (CPU python)=8948.3046875MB; mem (CPU total)=12288.5703125MB
INFO:root:[   19] Training loss: 0.43146520, Validation loss: 0.32021204, Gradient norm: 4.39769943
INFO:root:At the start of the epoch: mem (CPU python)=8969.46484375MB; mem (CPU total)=12283.2265625MB
INFO:root:[   20] Training loss: 0.42861534, Validation loss: 0.33011988, Gradient norm: 4.61657168
INFO:root:At the start of the epoch: mem (CPU python)=8990.62890625MB; mem (CPU total)=12291.40625MB
INFO:root:[   21] Training loss: 0.43149817, Validation loss: 0.31269982, Gradient norm: 4.89746659
INFO:root:At the start of the epoch: mem (CPU python)=9011.79296875MB; mem (CPU total)=12315.01953125MB
INFO:root:[   22] Training loss: 0.43193501, Validation loss: 0.31296237, Gradient norm: 4.97668049
INFO:root:At the start of the epoch: mem (CPU python)=9032.9609375MB; mem (CPU total)=12338.08203125MB
INFO:root:[   23] Training loss: 0.43078016, Validation loss: 0.32756508, Gradient norm: 5.23644191
INFO:root:At the start of the epoch: mem (CPU python)=9054.12890625MB; mem (CPU total)=12376.71875MB
INFO:root:[   24] Training loss: 0.43189497, Validation loss: 0.32709722, Gradient norm: 5.10002193
INFO:root:At the start of the epoch: mem (CPU python)=9075.29296875MB; mem (CPU total)=12382.08984375MB
INFO:root:[   25] Training loss: 0.43126100, Validation loss: 0.30577289, Gradient norm: 5.44025069
INFO:root:At the start of the epoch: mem (CPU python)=9096.45703125MB; mem (CPU total)=12407.19921875MB
INFO:root:[   26] Training loss: 0.43047931, Validation loss: 0.34664040, Gradient norm: 5.51783607
INFO:root:At the start of the epoch: mem (CPU python)=9117.62109375MB; mem (CPU total)=12434.42578125MB
INFO:root:[   27] Training loss: 0.42926025, Validation loss: 0.32333312, Gradient norm: 5.66204025
INFO:root:At the start of the epoch: mem (CPU python)=9138.78515625MB; mem (CPU total)=12476.90625MB
INFO:root:[   28] Training loss: 0.43031506, Validation loss: 0.31046368, Gradient norm: 5.93012177
INFO:root:At the start of the epoch: mem (CPU python)=9159.9453125MB; mem (CPU total)=12476.8828125MB
INFO:root:[   29] Training loss: 0.43049248, Validation loss: 0.31091490, Gradient norm: 5.92676743
INFO:root:At the start of the epoch: mem (CPU python)=9181.109375MB; mem (CPU total)=12490.27734375MB
INFO:root:[   30] Training loss: 0.42931078, Validation loss: 0.30705852, Gradient norm: 6.09241403
INFO:root:At the start of the epoch: mem (CPU python)=9202.2734375MB; mem (CPU total)=12519.234375MB
INFO:root:[   31] Training loss: 0.43118997, Validation loss: 0.33543427, Gradient norm: 6.11777858
INFO:root:At the start of the epoch: mem (CPU python)=9223.4375MB; mem (CPU total)=12507.0625MB
INFO:root:[   32] Training loss: 0.43046705, Validation loss: 0.32112473, Gradient norm: 6.26445561
INFO:root:At the start of the epoch: mem (CPU python)=9244.6015625MB; mem (CPU total)=12563.29296875MB
INFO:root:[   33] Training loss: 0.42716903, Validation loss: 0.32995101, Gradient norm: 6.37416022
INFO:root:At the start of the epoch: mem (CPU python)=9265.76953125MB; mem (CPU total)=12595.578125MB
INFO:root:[   34] Training loss: 0.42838909, Validation loss: 0.29722354, Gradient norm: 6.26853599
INFO:root:At the start of the epoch: mem (CPU python)=9286.93359375MB; mem (CPU total)=12615.171875MB
INFO:root:[   35] Training loss: 0.42805574, Validation loss: 0.32377432, Gradient norm: 6.31873657
INFO:root:At the start of the epoch: mem (CPU python)=9308.09765625MB; mem (CPU total)=12643.1015625MB
INFO:root:[   36] Training loss: 0.42653388, Validation loss: 0.33066747, Gradient norm: 6.28472786
INFO:root:At the start of the epoch: mem (CPU python)=9329.26171875MB; mem (CPU total)=12661.2421875MB
INFO:root:[   37] Training loss: 0.42401965, Validation loss: 0.30745776, Gradient norm: 6.47370850
INFO:root:At the start of the epoch: mem (CPU python)=9350.42578125MB; mem (CPU total)=12666.73046875MB
INFO:root:[   38] Training loss: 0.51700646, Validation loss: 0.34134201, Gradient norm: 9.67824546
INFO:root:At the start of the epoch: mem (CPU python)=9371.5859375MB; mem (CPU total)=12699.58203125MB
INFO:root:[   39] Training loss: 0.43741631, Validation loss: 0.32282737, Gradient norm: 6.92005706
INFO:root:At the start of the epoch: mem (CPU python)=9392.75MB; mem (CPU total)=12705.5703125MB
INFO:root:[   40] Training loss: 0.42413648, Validation loss: 0.29465379, Gradient norm: 6.05808229
INFO:root:At the start of the epoch: mem (CPU python)=9413.91796875MB; mem (CPU total)=12729.625MB
INFO:root:[   41] Training loss: 0.42217291, Validation loss: 0.31446444, Gradient norm: 6.07656118
INFO:root:At the start of the epoch: mem (CPU python)=9435.0859375MB; mem (CPU total)=12764.6953125MB
INFO:root:[   42] Training loss: 0.42011001, Validation loss: 0.32699072, Gradient norm: 6.25934547
INFO:root:At the start of the epoch: mem (CPU python)=9456.25MB; mem (CPU total)=12772.65625MB
INFO:root:[   43] Training loss: 0.41968953, Validation loss: 0.30352656, Gradient norm: 6.20086481
INFO:root:At the start of the epoch: mem (CPU python)=9477.4140625MB; mem (CPU total)=12778.15625MB
INFO:root:[   44] Training loss: 0.41667453, Validation loss: 0.29435609, Gradient norm: 6.34185442
INFO:root:At the start of the epoch: mem (CPU python)=9498.578125MB; mem (CPU total)=12798.46875MB
INFO:root:[   45] Training loss: 0.42000944, Validation loss: 0.32990142, Gradient norm: 6.63297162
INFO:root:At the start of the epoch: mem (CPU python)=9519.74609375MB; mem (CPU total)=12896.2890625MB
INFO:root:[   46] Training loss: 0.41792135, Validation loss: 0.31539914, Gradient norm: 6.40222510
INFO:root:At the start of the epoch: mem (CPU python)=9540.90625MB; mem (CPU total)=12844.87890625MB
INFO:root:[   47] Training loss: 0.41646492, Validation loss: 0.29666117, Gradient norm: 6.74272059
INFO:root:At the start of the epoch: mem (CPU python)=9562.06640625MB; mem (CPU total)=12885.953125MB
INFO:root:[   48] Training loss: 0.41789879, Validation loss: 0.31701296, Gradient norm: 6.71266821
INFO:root:At the start of the epoch: mem (CPU python)=9583.23046875MB; mem (CPU total)=13484.765625MB
INFO:root:[   49] Training loss: 0.41838880, Validation loss: 0.31260041, Gradient norm: 6.69846199
INFO:root:At the start of the epoch: mem (CPU python)=9604.39453125MB; mem (CPU total)=12664.44140625MB
INFO:root:[   50] Training loss: 0.41737538, Validation loss: 0.32413908, Gradient norm: 6.81889287
INFO:root:At the start of the epoch: mem (CPU python)=9625.55859375MB; mem (CPU total)=13754.26953125MB
INFO:root:[   51] Training loss: 0.41422426, Validation loss: 0.32468976, Gradient norm: 6.82659204
INFO:root:At the start of the epoch: mem (CPU python)=9646.72265625MB; mem (CPU total)=13422.703125MB
INFO:root:[   52] Training loss: 0.42052492, Validation loss: 0.32075420, Gradient norm: 7.00872488
INFO:root:At the start of the epoch: mem (CPU python)=9667.890625MB; mem (CPU total)=13466.85546875MB
INFO:root:[   53] Training loss: 0.41697365, Validation loss: 0.30767028, Gradient norm: 6.83281455
INFO:root:At the start of the epoch: mem (CPU python)=9689.0546875MB; mem (CPU total)=13812.17578125MB
INFO:root:[   54] Training loss: 0.41476326, Validation loss: 0.30935512, Gradient norm: 6.68913153
INFO:root:At the start of the epoch: mem (CPU python)=9710.21875MB; mem (CPU total)=13865.62890625MB
INFO:root:[   55] Training loss: 0.41480256, Validation loss: 0.32748174, Gradient norm: 6.92435792
INFO:root:At the start of the epoch: mem (CPU python)=9734.12890625MB; mem (CPU total)=13056.76171875MB
INFO:root:[   56] Training loss: 0.41349226, Validation loss: 0.31813927, Gradient norm: 6.87271131
INFO:root:At the start of the epoch: mem (CPU python)=9755.546875MB; mem (CPU total)=13880.79296875MB
INFO:root:[   57] Training loss: 0.41657888, Validation loss: 0.33112219, Gradient norm: 7.01040064
INFO:root:At the start of the epoch: mem (CPU python)=9776.7109375MB; mem (CPU total)=13925.1015625MB
INFO:root:[   58] Training loss: 0.41355208, Validation loss: 0.34323366, Gradient norm: 6.93006736
INFO:root:At the start of the epoch: mem (CPU python)=9797.875MB; mem (CPU total)=13703.671875MB
INFO:root:[   59] Training loss: 0.41379399, Validation loss: 0.29605827, Gradient norm: 6.83395897
INFO:root:At the start of the epoch: mem (CPU python)=9819.0390625MB; mem (CPU total)=13920.3515625MB
INFO:root:[   60] Training loss: 0.41688363, Validation loss: 0.31725433, Gradient norm: 7.05483329
INFO:root:At the start of the epoch: mem (CPU python)=9840.203125MB; mem (CPU total)=13190.95703125MB
INFO:root:[   61] Training loss: 0.41087761, Validation loss: 0.30145906, Gradient norm: 6.84077969
INFO:root:At the start of the epoch: mem (CPU python)=9861.3671875MB; mem (CPU total)=13203.3203125MB
INFO:root:[   62] Training loss: 0.40898031, Validation loss: 0.29065800, Gradient norm: 6.83340963
INFO:root:At the start of the epoch: mem (CPU python)=9882.53515625MB; mem (CPU total)=13251.25390625MB
INFO:root:[   63] Training loss: 0.41156682, Validation loss: 0.31834942, Gradient norm: 6.94431928
INFO:root:At the start of the epoch: mem (CPU python)=9903.6953125MB; mem (CPU total)=13323.3515625MB
INFO:root:[   64] Training loss: 0.41019501, Validation loss: 0.31795813, Gradient norm: 6.92402303
INFO:root:At the start of the epoch: mem (CPU python)=9924.859375MB; mem (CPU total)=13291.45703125MB
INFO:root:[   65] Training loss: 0.58694220, Validation loss: 0.34462749, Gradient norm: 10.78969336
INFO:root:At the start of the epoch: mem (CPU python)=9946.02734375MB; mem (CPU total)=13291.8515625MB
INFO:root:[   66] Training loss: 0.48400159, Validation loss: 0.36506282, Gradient norm: 8.27903631
INFO:root:At the start of the epoch: mem (CPU python)=9967.1875MB; mem (CPU total)=13323.78125MB
INFO:root:[   67] Training loss: 0.43125662, Validation loss: 0.30934172, Gradient norm: 6.94973287
INFO:root:At the start of the epoch: mem (CPU python)=9988.3515625MB; mem (CPU total)=13335.12109375MB
INFO:root:[   68] Training loss: 0.41336680, Validation loss: 0.30014344, Gradient norm: 6.37439681
INFO:root:At the start of the epoch: mem (CPU python)=10009.51953125MB; mem (CPU total)=13365.72265625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   69] Training loss: 0.40749602, Validation loss: 0.28848595, Gradient norm: 6.45712008
INFO:root:At the start of the epoch: mem (CPU python)=10030.68359375MB; mem (CPU total)=13390.14453125MB
INFO:root:[   70] Training loss: 0.37945900, Validation loss: 0.28704595, Gradient norm: 5.57628034
INFO:root:At the start of the epoch: mem (CPU python)=10051.87109375MB; mem (CPU total)=13432.27734375MB
INFO:root:[   71] Training loss: 0.37821240, Validation loss: 0.28164192, Gradient norm: 7.50466981
INFO:root:At the start of the epoch: mem (CPU python)=10073.03515625MB; mem (CPU total)=13419.15625MB
INFO:root:[   72] Training loss: 0.38160349, Validation loss: 0.29433946, Gradient norm: 8.63071470
INFO:root:At the start of the epoch: mem (CPU python)=10094.19921875MB; mem (CPU total)=13433.21484375MB
INFO:root:[   73] Training loss: 0.39536861, Validation loss: 0.30979646, Gradient norm: 10.54443105
INFO:root:At the start of the epoch: mem (CPU python)=10115.36328125MB; mem (CPU total)=13463.8359375MB
INFO:root:[   74] Training loss: 0.38699407, Validation loss: 0.28190404, Gradient norm: 10.93949822
INFO:root:At the start of the epoch: mem (CPU python)=10136.53125MB; mem (CPU total)=13481.90625MB
INFO:root:[   75] Training loss: 0.38596147, Validation loss: 0.29811178, Gradient norm: 11.14149995
INFO:root:At the start of the epoch: mem (CPU python)=10157.6953125MB; mem (CPU total)=13194.55078125MB
INFO:root:[   76] Training loss: 0.38583661, Validation loss: 0.29947921, Gradient norm: 11.51966024
INFO:root:At the start of the epoch: mem (CPU python)=10178.85546875MB; mem (CPU total)=13512.66015625MB
INFO:root:[   77] Training loss: 0.39036707, Validation loss: 0.34331727, Gradient norm: 12.26621320
INFO:root:At the start of the epoch: mem (CPU python)=10200.01953125MB; mem (CPU total)=13550.32421875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   78] Training loss: 0.40834603, Validation loss: 0.35704373, Gradient norm: 14.49355555
INFO:root:At the start of the epoch: mem (CPU python)=10221.1875MB; mem (CPU total)=13583.03125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   79] Training loss: 0.39668778, Validation loss: 0.29302976, Gradient norm: 13.39964729
INFO:root:At the start of the epoch: mem (CPU python)=10242.3515625MB; mem (CPU total)=13590.3828125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   80] Training loss: 0.37090147, Validation loss: 0.27090638, Gradient norm: 9.28805628
INFO:root:At the start of the epoch: mem (CPU python)=10263.515625MB; mem (CPU total)=13609.9296875MB
INFO:root:[   81] Training loss: 0.36506682, Validation loss: 0.26699432, Gradient norm: 8.21947227
INFO:root:At the start of the epoch: mem (CPU python)=10284.67578125MB; mem (CPU total)=13637.06640625MB
INFO:root:[   82] Training loss: 0.36458308, Validation loss: 0.26352318, Gradient norm: 9.54849105
INFO:root:At the start of the epoch: mem (CPU python)=10305.83984375MB; mem (CPU total)=13656.22265625MB
INFO:root:[   83] Training loss: 0.36511175, Validation loss: 0.26826883, Gradient norm: 12.67180704
INFO:root:At the start of the epoch: mem (CPU python)=10327.00390625MB; mem (CPU total)=13666.51171875MB
INFO:root:[   84] Training loss: 0.36498504, Validation loss: 0.26632548, Gradient norm: 13.01785269
INFO:root:At the start of the epoch: mem (CPU python)=10348.171875MB; mem (CPU total)=13695.8515625MB
INFO:root:[   85] Training loss: 0.36292374, Validation loss: 0.26920867, Gradient norm: 12.95229726
INFO:root:At the start of the epoch: mem (CPU python)=10369.33203125MB; mem (CPU total)=13760.94921875MB
INFO:root:[   86] Training loss: 0.36425854, Validation loss: 0.27790886, Gradient norm: 13.89621887
INFO:root:At the start of the epoch: mem (CPU python)=10390.49609375MB; mem (CPU total)=13753.3828125MB
INFO:root:[   87] Training loss: 0.36450594, Validation loss: 0.26686075, Gradient norm: 16.66731050
INFO:root:At the start of the epoch: mem (CPU python)=10411.66015625MB; mem (CPU total)=13782.83984375MB
INFO:root:[   88] Training loss: 0.36427785, Validation loss: 0.26724250, Gradient norm: 16.48442900
INFO:root:At the start of the epoch: mem (CPU python)=10432.82421875MB; mem (CPU total)=13769.2109375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   89] Training loss: 0.36401403, Validation loss: 0.26510343, Gradient norm: 15.34440682
INFO:root:At the start of the epoch: mem (CPU python)=10453.98828125MB; mem (CPU total)=13811.38671875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   90] Training loss: 0.36072299, Validation loss: 0.26231989, Gradient norm: 12.04932740
INFO:root:At the start of the epoch: mem (CPU python)=10475.15625MB; mem (CPU total)=13828.1640625MB
INFO:root:[   91] Training loss: 0.36040498, Validation loss: 0.26233909, Gradient norm: 10.48413635
INFO:root:At the start of the epoch: mem (CPU python)=10496.3203125MB; mem (CPU total)=13849.390625MB
INFO:root:[   92] Training loss: 0.36060139, Validation loss: 0.26287405, Gradient norm: 10.61150015
INFO:root:At the start of the epoch: mem (CPU python)=10517.484375MB; mem (CPU total)=13880.8125MB
INFO:root:[   93] Training loss: 0.36078213, Validation loss: 0.26083090, Gradient norm: 10.55220096
INFO:root:At the start of the epoch: mem (CPU python)=10538.6484375MB; mem (CPU total)=13882.9921875MB
INFO:root:[   94] Training loss: 0.35977284, Validation loss: 0.26528455, Gradient norm: 11.94861802
INFO:root:At the start of the epoch: mem (CPU python)=10559.80859375MB; mem (CPU total)=13958.8203125MB
INFO:root:[   95] Training loss: 0.36050411, Validation loss: 0.26385335, Gradient norm: 11.54997358
INFO:root:At the start of the epoch: mem (CPU python)=10580.97265625MB; mem (CPU total)=13947.5703125MB
INFO:root:[   96] Training loss: 0.36029532, Validation loss: 0.26350090, Gradient norm: 12.51744576
INFO:root:At the start of the epoch: mem (CPU python)=10602.140625MB; mem (CPU total)=13979.1640625MB
INFO:root:[   97] Training loss: 0.36126535, Validation loss: 0.26178886, Gradient norm: 12.85698628
INFO:root:At the start of the epoch: mem (CPU python)=10623.30078125MB; mem (CPU total)=13976.90625MB
INFO:root:[   98] Training loss: 0.36040895, Validation loss: 0.26129400, Gradient norm: 13.80012752
INFO:root:At the start of the epoch: mem (CPU python)=10644.46484375MB; mem (CPU total)=13999.8671875MB
INFO:root:[   99] Training loss: 0.36096924, Validation loss: 0.26256278, Gradient norm: 14.05827091
INFO:root:At the start of the epoch: mem (CPU python)=10665.62890625MB; mem (CPU total)=14004.9921875MB
INFO:root:[  100] Training loss: 0.36119508, Validation loss: 0.26160792, Gradient norm: 13.72279284
INFO:root:At the start of the epoch: mem (CPU python)=10686.79296875MB; mem (CPU total)=14045.08203125MB
INFO:root:[  101] Training loss: 0.36112653, Validation loss: 0.26147830, Gradient norm: 15.03223546
INFO:root:At the start of the epoch: mem (CPU python)=10707.95703125MB; mem (CPU total)=14051.4453125MB
INFO:root:[  102] Training loss: 0.36045492, Validation loss: 0.25967130, Gradient norm: 14.55465484
INFO:root:At the start of the epoch: mem (CPU python)=10729.125MB; mem (CPU total)=14073.11328125MB
INFO:root:[  103] Training loss: 0.36114976, Validation loss: 0.26359300, Gradient norm: 15.39785436
INFO:root:At the start of the epoch: mem (CPU python)=10750.2890625MB; mem (CPU total)=14173.39453125MB
INFO:root:[  104] Training loss: 0.36142966, Validation loss: 0.26040440, Gradient norm: 15.07819277
INFO:root:At the start of the epoch: mem (CPU python)=10771.44921875MB; mem (CPU total)=14136.4609375MB
INFO:root:[  105] Training loss: 0.36211422, Validation loss: 0.26198928, Gradient norm: 16.60799168
INFO:root:At the start of the epoch: mem (CPU python)=10792.61328125MB; mem (CPU total)=13977.23828125MB
INFO:root:[  106] Training loss: 0.36118700, Validation loss: 0.26180439, Gradient norm: 16.63959687
INFO:root:At the start of the epoch: mem (CPU python)=10813.77734375MB; mem (CPU total)=14147.12890625MB
INFO:root:[  107] Training loss: 0.36151215, Validation loss: 0.26105374, Gradient norm: 15.81387542
INFO:root:At the start of the epoch: mem (CPU python)=10834.9453125MB; mem (CPU total)=14190.58203125MB
INFO:root:[  108] Training loss: 0.36212435, Validation loss: 0.26041242, Gradient norm: 17.70389403
INFO:root:At the start of the epoch: mem (CPU python)=10856.109375MB; mem (CPU total)=14221.34765625MB
INFO:root:[  109] Training loss: 0.36139498, Validation loss: 0.26197892, Gradient norm: 17.37462734
INFO:root:At the start of the epoch: mem (CPU python)=10877.2734375MB; mem (CPU total)=14233.64453125MB
INFO:root:[  110] Training loss: 0.36197520, Validation loss: 0.25998432, Gradient norm: 18.64936281
INFO:root:At the start of the epoch: mem (CPU python)=10898.4375MB; mem (CPU total)=14252.8984375MB
INFO:root:[  111] Training loss: 0.36188560, Validation loss: 0.25959546, Gradient norm: 19.05997337
INFO:root:At the start of the epoch: mem (CPU python)=10919.6015625MB; mem (CPU total)=14279.03515625MB
INFO:root:[  112] Training loss: 0.36158003, Validation loss: 0.26005119, Gradient norm: 18.87175127
INFO:root:At the start of the epoch: mem (CPU python)=10940.76953125MB; mem (CPU total)=14331.96484375MB
INFO:root:[  113] Training loss: 0.36225785, Validation loss: 0.25927737, Gradient norm: 20.64398028
INFO:root:At the start of the epoch: mem (CPU python)=10961.93359375MB; mem (CPU total)=14316.06640625MB
INFO:root:[  114] Training loss: 0.36160234, Validation loss: 0.25891847, Gradient norm: 19.87475089
INFO:root:At the start of the epoch: mem (CPU python)=10983.09765625MB; mem (CPU total)=14347.6484375MB
INFO:root:[  115] Training loss: 0.36167588, Validation loss: 0.26091580, Gradient norm: 20.49494694
INFO:root:At the start of the epoch: mem (CPU python)=11004.3046875MB; mem (CPU total)=14336.41015625MB
INFO:root:[  116] Training loss: 0.36199449, Validation loss: 0.25869266, Gradient norm: 21.20076941
INFO:root:At the start of the epoch: mem (CPU python)=11025.46875MB; mem (CPU total)=14356.37109375MB
INFO:root:[  117] Training loss: 0.36228732, Validation loss: 0.25901163, Gradient norm: 20.54536381
INFO:root:At the start of the epoch: mem (CPU python)=11046.6328125MB; mem (CPU total)=14388.1328125MB
INFO:root:[  118] Training loss: 0.36217823, Validation loss: 0.26414822, Gradient norm: 21.37733321
INFO:root:At the start of the epoch: mem (CPU python)=11067.796875MB; mem (CPU total)=14409.4375MB
INFO:root:[  119] Training loss: 0.36219342, Validation loss: 0.26141574, Gradient norm: 24.09965168
INFO:root:At the start of the epoch: mem (CPU python)=11088.96484375MB; mem (CPU total)=14433.47265625MB
INFO:root:[  120] Training loss: 0.36225336, Validation loss: 0.25990043, Gradient norm: 22.88203912
INFO:root:At the start of the epoch: mem (CPU python)=11110.15234375MB; mem (CPU total)=14457.12109375MB
INFO:root:[  121] Training loss: 0.36241902, Validation loss: 0.26043382, Gradient norm: 23.00557071
INFO:root:At the start of the epoch: mem (CPU python)=11131.31640625MB; mem (CPU total)=14521.44921875MB
INFO:root:[  122] Training loss: 0.36311638, Validation loss: 0.25779867, Gradient norm: 24.04697929
INFO:root:At the start of the epoch: mem (CPU python)=11152.48046875MB; mem (CPU total)=14516.51953125MB
INFO:root:[  123] Training loss: 0.36236453, Validation loss: 0.25956202, Gradient norm: 23.85199173
INFO:root:At the start of the epoch: mem (CPU python)=11173.640625MB; mem (CPU total)=14508.11328125MB
INFO:root:[  124] Training loss: 0.36218749, Validation loss: 0.25950044, Gradient norm: 25.09425364
INFO:root:At the start of the epoch: mem (CPU python)=11194.80859375MB; mem (CPU total)=14552.9140625MB
INFO:root:[  125] Training loss: 0.36229897, Validation loss: 0.25928069, Gradient norm: 27.03930527
INFO:root:At the start of the epoch: mem (CPU python)=11215.97265625MB; mem (CPU total)=14562.875MB
INFO:root:[  126] Training loss: 0.36166696, Validation loss: 0.25979804, Gradient norm: 25.11159475
INFO:root:At the start of the epoch: mem (CPU python)=11237.13671875MB; mem (CPU total)=14592.30078125MB
INFO:root:[  127] Training loss: 0.36283618, Validation loss: 0.25682005, Gradient norm: 26.13711945
INFO:root:At the start of the epoch: mem (CPU python)=11258.30078125MB; mem (CPU total)=14594.3359375MB
INFO:root:[  128] Training loss: 0.36245173, Validation loss: 0.26217020, Gradient norm: 25.19396822
INFO:root:At the start of the epoch: mem (CPU python)=11279.46484375MB; mem (CPU total)=14627.56640625MB
INFO:root:[  129] Training loss: 0.36271982, Validation loss: 0.26330204, Gradient norm: 26.23939723
INFO:root:At the start of the epoch: mem (CPU python)=11300.62890625MB; mem (CPU total)=14646.70703125MB
INFO:root:[  130] Training loss: 0.36338193, Validation loss: 0.25771575, Gradient norm: 28.71522300
INFO:root:At the start of the epoch: mem (CPU python)=11321.796875MB; mem (CPU total)=14611.16015625MB
INFO:root:[  131] Training loss: 0.36225798, Validation loss: 0.26438378, Gradient norm: 29.20774368
INFO:root:At the start of the epoch: mem (CPU python)=11342.95703125MB; mem (CPU total)=14689.09375MB
INFO:root:[  132] Training loss: 0.36341047, Validation loss: 0.25864131, Gradient norm: 27.57055522
INFO:root:At the start of the epoch: mem (CPU python)=11364.1171875MB; mem (CPU total)=14711.69140625MB
INFO:root:[  133] Training loss: 0.36268261, Validation loss: 0.25765292, Gradient norm: 29.16278073
INFO:root:At the start of the epoch: mem (CPU python)=11385.28125MB; mem (CPU total)=14732.08984375MB
INFO:root:[  134] Training loss: 0.36319983, Validation loss: 0.25867714, Gradient norm: 29.76146910
INFO:root:At the start of the epoch: mem (CPU python)=11406.4453125MB; mem (CPU total)=14324.625MB
INFO:root:[  135] Training loss: 0.36277356, Validation loss: 0.25822449, Gradient norm: 29.67281191
INFO:root:At the start of the epoch: mem (CPU python)=11427.61328125MB; mem (CPU total)=14775.3984375MB
INFO:root:[  136] Training loss: 0.36280535, Validation loss: 0.26081735, Gradient norm: 30.70060245
INFO:root:At the start of the epoch: mem (CPU python)=11448.77734375MB; mem (CPU total)=14786.1796875MB
INFO:root:EP 136: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=11469.94140625MB; mem (CPU total)=14831.9609375MB
INFO:root:Training the model took 8364.703s.
INFO:root:Emptying the cuda cache took 0.052s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.34087
INFO:root:EnergyScoreValidation: 0.25674
INFO:root:CRPSValidation: 0.10344
INFO:root:Gaussian NLLValidation: -0.05167
INFO:root:CoverageValidation: 0.75787
INFO:root:IntervalWidthValidation: 0.40151
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.36052
INFO:root:EnergyScoreTest: 0.27411
INFO:root:CRPSTest: 0.11103
INFO:root:Gaussian NLLTest: 0.15508
INFO:root:CoverageTest: 0.73566
INFO:root:IntervalWidthTest: 0.40041
INFO:root:After validation: mem (CPU python)=11476.73828125MB; mem (CPU total)=14807.43359375MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=11476.73828125MB; mem (CPU total)=14807.75MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 62914560
INFO:root:After setting up the model: mem (CPU python)=11476.73828125MB; mem (CPU total)=14807.75MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=11476.75MB; mem (CPU total)=14885.33203125MB
INFO:root:[    1] Training loss: 0.76259287, Validation loss: 0.65325132, Gradient norm: 0.42009029
INFO:root:At the start of the epoch: mem (CPU python)=11497.6015625MB; mem (CPU total)=14865.67578125MB
INFO:root:[    2] Training loss: 0.64729285, Validation loss: 0.46223855, Gradient norm: 0.71492136
INFO:root:At the start of the epoch: mem (CPU python)=11518.77734375MB; mem (CPU total)=14870.5MB
INFO:root:[    3] Training loss: 0.53893731, Validation loss: 0.41344246, Gradient norm: 1.10758687
INFO:root:At the start of the epoch: mem (CPU python)=11539.94140625MB; mem (CPU total)=14878.06640625MB
INFO:root:[    4] Training loss: 0.50886965, Validation loss: 0.39081101, Gradient norm: 1.24332984
INFO:root:At the start of the epoch: mem (CPU python)=11561.10546875MB; mem (CPU total)=14895.98828125MB
INFO:root:[    5] Training loss: 0.49169420, Validation loss: 0.37738089, Gradient norm: 1.38058074
INFO:root:At the start of the epoch: mem (CPU python)=11582.26953125MB; mem (CPU total)=14956.98828125MB
INFO:root:[    6] Training loss: 0.48246326, Validation loss: 0.36455335, Gradient norm: 1.55061276
INFO:root:At the start of the epoch: mem (CPU python)=11603.4375MB; mem (CPU total)=14963.48046875MB
INFO:root:[    7] Training loss: 0.47313462, Validation loss: 0.35286059, Gradient norm: 1.64839944
INFO:root:At the start of the epoch: mem (CPU python)=11624.6015625MB; mem (CPU total)=14965.19140625MB
INFO:root:[    8] Training loss: 0.46662897, Validation loss: 0.34731018, Gradient norm: 1.85485457
INFO:root:At the start of the epoch: mem (CPU python)=11648.38671875MB; mem (CPU total)=15001.92578125MB
INFO:root:[    9] Training loss: 0.46000489, Validation loss: 0.33281592, Gradient norm: 2.00911984
INFO:root:At the start of the epoch: mem (CPU python)=11669.92578125MB; mem (CPU total)=15025.73828125MB
INFO:root:[   10] Training loss: 0.45691437, Validation loss: 0.33808588, Gradient norm: 2.17056622
INFO:root:At the start of the epoch: mem (CPU python)=11691.08984375MB; mem (CPU total)=15049.10546875MB
INFO:root:[   11] Training loss: 0.45305291, Validation loss: 0.34753844, Gradient norm: 2.33902125
INFO:root:At the start of the epoch: mem (CPU python)=11712.2578125MB; mem (CPU total)=15058.04296875MB
INFO:root:[   12] Training loss: 0.44986025, Validation loss: 0.35018594, Gradient norm: 2.44787565
INFO:root:At the start of the epoch: mem (CPU python)=11733.421875MB; mem (CPU total)=15061.8515625MB
INFO:root:[   13] Training loss: 0.44857500, Validation loss: 0.32917090, Gradient norm: 2.42389995
INFO:root:At the start of the epoch: mem (CPU python)=11754.5859375MB; mem (CPU total)=15099.48046875MB
INFO:root:[   14] Training loss: 0.44587340, Validation loss: 0.31678420, Gradient norm: 2.62698417
INFO:root:At the start of the epoch: mem (CPU python)=11775.75MB; mem (CPU total)=15134.68359375MB
INFO:root:[   15] Training loss: 0.44276013, Validation loss: 0.34151743, Gradient norm: 2.63653388
INFO:root:At the start of the epoch: mem (CPU python)=11796.9140625MB; mem (CPU total)=15147.35546875MB
INFO:root:[   16] Training loss: 0.44206522, Validation loss: 0.33994130, Gradient norm: 2.75085705
INFO:root:At the start of the epoch: mem (CPU python)=11818.07421875MB; mem (CPU total)=15148.50390625MB
INFO:root:[   17] Training loss: 0.44056929, Validation loss: 0.31812760, Gradient norm: 2.77011864
INFO:root:At the start of the epoch: mem (CPU python)=11839.2421875MB; mem (CPU total)=14999.82421875MB
INFO:root:[   18] Training loss: 0.43930352, Validation loss: 0.33028081, Gradient norm: 2.85019423
INFO:root:At the start of the epoch: mem (CPU python)=11860.40234375MB; mem (CPU total)=14870.9765625MB
INFO:root:[   19] Training loss: 0.43630547, Validation loss: 0.31814085, Gradient norm: 2.87828892
INFO:root:At the start of the epoch: mem (CPU python)=11881.56640625MB; mem (CPU total)=15234.625MB
INFO:root:[   20] Training loss: 0.43465156, Validation loss: 0.31111739, Gradient norm: 3.10882897
INFO:root:At the start of the epoch: mem (CPU python)=11902.73046875MB; mem (CPU total)=15261.9375MB
INFO:root:[   21] Training loss: 0.43564610, Validation loss: 0.32145017, Gradient norm: 3.08345301
INFO:root:At the start of the epoch: mem (CPU python)=11923.89453125MB; mem (CPU total)=15263.94921875MB
INFO:root:[   22] Training loss: 0.43333516, Validation loss: 0.31460206, Gradient norm: 3.31910099
INFO:root:At the start of the epoch: mem (CPU python)=11945.0625MB; mem (CPU total)=15356.62890625MB
INFO:root:[   23] Training loss: 0.43293713, Validation loss: 0.31503787, Gradient norm: 3.39724833
INFO:root:At the start of the epoch: mem (CPU python)=11966.2265625MB; mem (CPU total)=15294.921875MB
INFO:root:[   24] Training loss: 0.43155345, Validation loss: 0.31452482, Gradient norm: 3.43091026
INFO:root:At the start of the epoch: mem (CPU python)=11987.390625MB; mem (CPU total)=15329.0546875MB
INFO:root:[   25] Training loss: 0.43069045, Validation loss: 0.31869507, Gradient norm: 3.55646464
INFO:root:At the start of the epoch: mem (CPU python)=12008.5546875MB; mem (CPU total)=15337.25390625MB
INFO:root:[   26] Training loss: 0.42872677, Validation loss: 0.31965202, Gradient norm: 3.72651032
INFO:root:At the start of the epoch: mem (CPU python)=12029.71875MB; mem (CPU total)=15350.8125MB
INFO:root:[   27] Training loss: 0.43125884, Validation loss: 0.30019937, Gradient norm: 3.81577031
INFO:root:At the start of the epoch: mem (CPU python)=12050.8828125MB; mem (CPU total)=15406.640625MB
INFO:root:[   28] Training loss: 0.42981943, Validation loss: 0.31240310, Gradient norm: 3.90475565
INFO:root:At the start of the epoch: mem (CPU python)=12072.046875MB; mem (CPU total)=15423.87890625MB
INFO:root:[   29] Training loss: 0.43075943, Validation loss: 0.32450180, Gradient norm: 4.15251659
INFO:root:At the start of the epoch: mem (CPU python)=12093.2109375MB; mem (CPU total)=15420.51171875MB
INFO:root:[   30] Training loss: 0.42957593, Validation loss: 0.30125024, Gradient norm: 4.18238006
INFO:root:At the start of the epoch: mem (CPU python)=12114.375MB; mem (CPU total)=15457.4765625MB
INFO:root:[   31] Training loss: 0.42941748, Validation loss: 0.32777425, Gradient norm: 4.26056589
INFO:root:At the start of the epoch: mem (CPU python)=12135.5390625MB; mem (CPU total)=15521.09375MB
INFO:root:[   32] Training loss: 0.43047198, Validation loss: 0.30808678, Gradient norm: 4.42399060
INFO:root:At the start of the epoch: mem (CPU python)=12156.703125MB; mem (CPU total)=15463.26171875MB
INFO:root:[   33] Training loss: 0.43046353, Validation loss: 0.33040648, Gradient norm: 4.53557253
INFO:root:At the start of the epoch: mem (CPU python)=12177.86328125MB; mem (CPU total)=15509.53125MB
INFO:root:[   34] Training loss: 0.43026141, Validation loss: 0.30756206, Gradient norm: 4.55258729
INFO:root:At the start of the epoch: mem (CPU python)=12199.03125MB; mem (CPU total)=15541.8125MB
INFO:root:[   35] Training loss: 0.43075351, Validation loss: 0.32125672, Gradient norm: 4.59532486
INFO:root:At the start of the epoch: mem (CPU python)=12220.1953125MB; mem (CPU total)=15541.46875MB
INFO:root:[   36] Training loss: 0.42895928, Validation loss: 0.32941194, Gradient norm: 4.86602241
INFO:root:At the start of the epoch: mem (CPU python)=12241.359375MB; mem (CPU total)=15584.3359375MB
INFO:root:[   37] Training loss: 0.43033400, Validation loss: 0.30459473, Gradient norm: 4.78891027
INFO:root:At the start of the epoch: mem (CPU python)=12262.51953125MB; mem (CPU total)=15597.2578125MB
INFO:root:[   38] Training loss: 0.43068738, Validation loss: 0.32097618, Gradient norm: 5.13315263
INFO:root:At the start of the epoch: mem (CPU python)=12283.68359375MB; mem (CPU total)=15642.8125MB
INFO:root:[   39] Training loss: 0.43195025, Validation loss: 0.32217546, Gradient norm: 5.15864750
INFO:root:At the start of the epoch: mem (CPU python)=12304.8515625MB; mem (CPU total)=15652.4375MB
INFO:root:[   40] Training loss: 0.43166071, Validation loss: 0.32816422, Gradient norm: 5.45321759
INFO:root:At the start of the epoch: mem (CPU python)=12326.01953125MB; mem (CPU total)=15681.97265625MB
INFO:root:[   41] Training loss: 0.43004172, Validation loss: 0.32619528, Gradient norm: 5.25965981
INFO:root:At the start of the epoch: mem (CPU python)=12347.18359375MB; mem (CPU total)=15701.96484375MB
INFO:root:[   42] Training loss: 0.43001568, Validation loss: 0.33447374, Gradient norm: 5.56910559
INFO:root:At the start of the epoch: mem (CPU python)=12368.34765625MB; mem (CPU total)=15690.7578125MB
INFO:root:[   43] Training loss: 0.43416294, Validation loss: 0.31376620, Gradient norm: 5.60268114
INFO:root:At the start of the epoch: mem (CPU python)=12389.51171875MB; mem (CPU total)=15736.43359375MB
INFO:root:[   44] Training loss: 0.42942762, Validation loss: 0.31344067, Gradient norm: 5.65152235
INFO:root:At the start of the epoch: mem (CPU python)=12410.67578125MB; mem (CPU total)=15826.08984375MB
INFO:root:[   45] Training loss: 0.43406707, Validation loss: 0.33218022, Gradient norm: 5.84062310
INFO:root:At the start of the epoch: mem (CPU python)=12431.84375MB; mem (CPU total)=15773.5625MB
INFO:root:[   46] Training loss: 0.43209121, Validation loss: 0.31310777, Gradient norm: 5.94806141
INFO:root:At the start of the epoch: mem (CPU python)=12453.00390625MB; mem (CPU total)=15790.74609375MB
INFO:root:[   47] Training loss: 0.43400712, Validation loss: 0.32258984, Gradient norm: 6.10947828
INFO:root:At the start of the epoch: mem (CPU python)=12474.16796875MB; mem (CPU total)=15825.3828125MB
INFO:root:[   48] Training loss: 0.43250356, Validation loss: 0.32420503, Gradient norm: 6.14806405
INFO:root:At the start of the epoch: mem (CPU python)=12495.33203125MB; mem (CPU total)=15865.58203125MB
INFO:root:[   49] Training loss: 0.43301911, Validation loss: 0.33399335, Gradient norm: 6.15338719
INFO:root:At the start of the epoch: mem (CPU python)=12516.49609375MB; mem (CPU total)=15894.7421875MB
INFO:root:[   50] Training loss: 0.43293979, Validation loss: 0.32215234, Gradient norm: 6.31848239
INFO:root:At the start of the epoch: mem (CPU python)=12537.66015625MB; mem (CPU total)=15874.27734375MB
INFO:root:[   51] Training loss: 0.43290426, Validation loss: 0.35284103, Gradient norm: 6.28961692
INFO:root:At the start of the epoch: mem (CPU python)=12558.82421875MB; mem (CPU total)=15911.421875MB
INFO:root:[   52] Training loss: 0.43258549, Validation loss: 0.33531545, Gradient norm: 6.69266867
INFO:root:At the start of the epoch: mem (CPU python)=12579.98828125MB; mem (CPU total)=15911.734375MB
INFO:root:[   53] Training loss: 0.43317088, Validation loss: 0.33933417, Gradient norm: 6.61073450
INFO:root:At the start of the epoch: mem (CPU python)=12601.15234375MB; mem (CPU total)=15991.015625MB
INFO:root:[   54] Training loss: 0.43161243, Validation loss: 0.32139989, Gradient norm: 6.47550122
INFO:root:At the start of the epoch: mem (CPU python)=12622.31640625MB; mem (CPU total)=15972.02734375MB
INFO:root:[   55] Training loss: 0.43208256, Validation loss: 0.36038190, Gradient norm: 6.57961445
INFO:root:At the start of the epoch: mem (CPU python)=12643.48046875MB; mem (CPU total)=15995.30078125MB
INFO:root:[   56] Training loss: 0.43048511, Validation loss: 0.33930199, Gradient norm: 6.64569539
INFO:root:At the start of the epoch: mem (CPU python)=12664.640625MB; mem (CPU total)=16006.6640625MB
INFO:root:[   57] Training loss: 0.43154856, Validation loss: 0.29952756, Gradient norm: 6.84367070
INFO:root:At the start of the epoch: mem (CPU python)=12685.80859375MB; mem (CPU total)=16086.5625MB
INFO:root:[   58] Training loss: 0.43122227, Validation loss: 0.30046368, Gradient norm: 6.56709103
INFO:root:At the start of the epoch: mem (CPU python)=12706.97265625MB; mem (CPU total)=16042.83203125MB
INFO:root:[   59] Training loss: 0.42835882, Validation loss: 0.30912416, Gradient norm: 6.57910711
INFO:root:At the start of the epoch: mem (CPU python)=12728.13671875MB; mem (CPU total)=16078.27734375MB
INFO:root:[   60] Training loss: 0.43191994, Validation loss: 0.32505205, Gradient norm: 6.57270455
INFO:root:At the start of the epoch: mem (CPU python)=12749.30078125MB; mem (CPU total)=16091.2734375MB
INFO:root:[   61] Training loss: 0.42767374, Validation loss: 0.34727591, Gradient norm: 6.59987173
INFO:root:At the start of the epoch: mem (CPU python)=12770.46484375MB; mem (CPU total)=16102.7421875MB
INFO:root:[   62] Training loss: 0.42953596, Validation loss: 0.32325132, Gradient norm: 6.75584472
INFO:root:At the start of the epoch: mem (CPU python)=12791.6328125MB; mem (CPU total)=16136.81640625MB
INFO:root:[   63] Training loss: 0.43368355, Validation loss: 0.31313270, Gradient norm: 6.79999326
INFO:root:At the start of the epoch: mem (CPU python)=12812.796875MB; mem (CPU total)=16054.5234375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   64] Training loss: 0.42698891, Validation loss: 0.33708807, Gradient norm: 6.47846717
INFO:root:At the start of the epoch: mem (CPU python)=12833.9609375MB; mem (CPU total)=16165.9453125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   65] Training loss: 0.39770222, Validation loss: 0.27567592, Gradient norm: 5.98034734
INFO:root:At the start of the epoch: mem (CPU python)=12855.12109375MB; mem (CPU total)=16222.83984375MB
INFO:root:[   66] Training loss: 0.38436788, Validation loss: 0.27618020, Gradient norm: 5.81666505
INFO:root:At the start of the epoch: mem (CPU python)=12876.28515625MB; mem (CPU total)=16273.85546875MB
INFO:root:[   67] Training loss: 0.38683347, Validation loss: 0.26763435, Gradient norm: 8.23650881
INFO:root:At the start of the epoch: mem (CPU python)=12897.453125MB; mem (CPU total)=16225.7578125MB
INFO:root:[   68] Training loss: 0.38451977, Validation loss: 0.27617599, Gradient norm: 8.93966456
INFO:root:At the start of the epoch: mem (CPU python)=12918.61328125MB; mem (CPU total)=16260.9765625MB
INFO:root:[   69] Training loss: 0.39038304, Validation loss: 0.27327708, Gradient norm: 10.60919940
INFO:root:At the start of the epoch: mem (CPU python)=12939.77734375MB; mem (CPU total)=16304.45703125MB
INFO:root:[   70] Training loss: 0.38818349, Validation loss: 0.27763847, Gradient norm: 11.64786534
INFO:root:At the start of the epoch: mem (CPU python)=12960.94140625MB; mem (CPU total)=16292.2109375MB
INFO:root:[   71] Training loss: 0.39041157, Validation loss: 0.27360499, Gradient norm: 12.55433519
INFO:root:At the start of the epoch: mem (CPU python)=12982.10546875MB; mem (CPU total)=16320.6953125MB
INFO:root:[   72] Training loss: 0.39050298, Validation loss: 0.26986763, Gradient norm: 13.43273442
INFO:root:At the start of the epoch: mem (CPU python)=13003.26953125MB; mem (CPU total)=16346.2734375MB
INFO:root:[   73] Training loss: 0.39227322, Validation loss: 0.28033979, Gradient norm: 13.91610196
INFO:root:At the start of the epoch: mem (CPU python)=13024.43359375MB; mem (CPU total)=16347.796875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   74] Training loss: 0.39270819, Validation loss: 0.27781786, Gradient norm: 15.16445789
INFO:root:At the start of the epoch: mem (CPU python)=13045.59765625MB; mem (CPU total)=16413.69140625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   75] Training loss: 0.38280776, Validation loss: 0.26581715, Gradient norm: 11.15886310
INFO:root:At the start of the epoch: mem (CPU python)=13066.76171875MB; mem (CPU total)=16423.66796875MB
INFO:root:[   76] Training loss: 0.37698803, Validation loss: 0.26292510, Gradient norm: 10.27568950
INFO:root:At the start of the epoch: mem (CPU python)=13087.92578125MB; mem (CPU total)=16441.69140625MB
INFO:root:[   77] Training loss: 0.37737011, Validation loss: 0.26312113, Gradient norm: 12.42524174
INFO:root:At the start of the epoch: mem (CPU python)=13109.08984375MB; mem (CPU total)=16451.75MB
INFO:root:[   78] Training loss: 0.37847531, Validation loss: 0.26305988, Gradient norm: 12.51968372
INFO:root:At the start of the epoch: mem (CPU python)=13130.25390625MB; mem (CPU total)=16476.37109375MB
INFO:root:[   79] Training loss: 0.37710603, Validation loss: 0.26687603, Gradient norm: 13.30624354
INFO:root:At the start of the epoch: mem (CPU python)=13151.41796875MB; mem (CPU total)=16569.28515625MB
INFO:root:[   80] Training loss: 0.37847618, Validation loss: 0.26662932, Gradient norm: 16.07181344
INFO:root:At the start of the epoch: mem (CPU python)=13172.5859375MB; mem (CPU total)=16527.0703125MB
INFO:root:[   81] Training loss: 0.37808605, Validation loss: 0.26470631, Gradient norm: 15.59122143
INFO:root:At the start of the epoch: mem (CPU python)=13193.75MB; mem (CPU total)=16525.25MB
INFO:root:[   82] Training loss: 0.38033820, Validation loss: 0.26454411, Gradient norm: 19.52750961
INFO:root:At the start of the epoch: mem (CPU python)=13214.9140625MB; mem (CPU total)=16527.1484375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   83] Training loss: 0.37977282, Validation loss: 0.26508312, Gradient norm: 19.32480966
INFO:root:At the start of the epoch: mem (CPU python)=13236.078125MB; mem (CPU total)=16630.171875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   84] Training loss: 0.37592740, Validation loss: 0.26278256, Gradient norm: 13.44585698
INFO:root:At the start of the epoch: mem (CPU python)=13257.2421875MB; mem (CPU total)=16592.86328125MB
INFO:root:[   85] Training loss: 0.37442278, Validation loss: 0.26023990, Gradient norm: 11.38974702
INFO:root:At the start of the epoch: mem (CPU python)=13278.40625MB; mem (CPU total)=16603.6640625MB
INFO:root:[   86] Training loss: 0.37342835, Validation loss: 0.26098027, Gradient norm: 11.90945279
INFO:root:At the start of the epoch: mem (CPU python)=13299.56640625MB; mem (CPU total)=16645.86328125MB
INFO:root:[   87] Training loss: 0.37357265, Validation loss: 0.25898111, Gradient norm: 12.80306466
INFO:root:At the start of the epoch: mem (CPU python)=13320.73046875MB; mem (CPU total)=16683.05078125MB
INFO:root:[   88] Training loss: 0.37438609, Validation loss: 0.26030899, Gradient norm: 12.66496483
INFO:root:At the start of the epoch: mem (CPU python)=13341.89453125MB; mem (CPU total)=16712.4453125MB
INFO:root:[   89] Training loss: 0.37469007, Validation loss: 0.26068434, Gradient norm: 13.35928978
INFO:root:At the start of the epoch: mem (CPU python)=13363.0625MB; mem (CPU total)=16709.55859375MB
INFO:root:[   90] Training loss: 0.37469969, Validation loss: 0.26130577, Gradient norm: 14.78754589
INFO:root:At the start of the epoch: mem (CPU python)=13384.2265625MB; mem (CPU total)=16716.48828125MB
INFO:root:[   91] Training loss: 0.37410340, Validation loss: 0.26008022, Gradient norm: 15.01979268
INFO:root:At the start of the epoch: mem (CPU python)=13405.39453125MB; mem (CPU total)=16766.0625MB
INFO:root:[   92] Training loss: 0.37424614, Validation loss: 0.25925207, Gradient norm: 15.31135809
INFO:root:At the start of the epoch: mem (CPU python)=13426.5703125MB; mem (CPU total)=16795.234375MB
INFO:root:[   93] Training loss: 0.37457888, Validation loss: 0.25966263, Gradient norm: 15.65674651
INFO:root:At the start of the epoch: mem (CPU python)=13447.71875MB; mem (CPU total)=16798.80859375MB
INFO:root:[   94] Training loss: 0.37537560, Validation loss: 0.25912973, Gradient norm: 15.94726838
INFO:root:At the start of the epoch: mem (CPU python)=13468.8828125MB; mem (CPU total)=16821.515625MB
INFO:root:[   95] Training loss: 0.37507837, Validation loss: 0.25994399, Gradient norm: 16.48976722
INFO:root:At the start of the epoch: mem (CPU python)=13490.046875MB; mem (CPU total)=16839.91796875MB
INFO:root:[   96] Training loss: 0.37451154, Validation loss: 0.26087926, Gradient norm: 15.69889927
INFO:root:At the start of the epoch: mem (CPU python)=13511.21484375MB; mem (CPU total)=16926.234375MB
INFO:root:EP 96: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=13532.37890625MB; mem (CPU total)=16873.921875MB
INFO:root:Training the model took 6088.265s.
INFO:root:Emptying the cuda cache took 0.053s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.34339
INFO:root:EnergyScoreValidation: 0.25916
INFO:root:CRPSValidation: 0.10291
INFO:root:Gaussian NLLValidation: -0.07557
INFO:root:CoverageValidation: 0.77072
INFO:root:IntervalWidthValidation: 0.39493
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.36648
INFO:root:EnergyScoreTest: 0.28002
INFO:root:CRPSTest: 0.11197
INFO:root:Gaussian NLLTest: 0.18169
INFO:root:CoverageTest: 0.73613
INFO:root:IntervalWidthTest: 0.39038
INFO:root:After validation: mem (CPU python)=13539.140625MB; mem (CPU total)=16891.73046875MB
