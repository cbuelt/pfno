INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=580.20703125MB; mem (CPU total)=4447.24609375MB
INFO:root:############### Starting experiment with config file sswe/sfno_deterministic_2_2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=591.421875MB; mem (CPU total)=4449.54296875MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'deterministic', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=592.671875MB; mem (CPU total)=4449.54296875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2303.7421875MB; mem (CPU total)=5883.5078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2313.29296875MB; mem (CPU total)=5891.625MB
INFO:root:[    1] Training loss: 0.83256811, Validation loss: 0.73565260, Gradient norm: 0.59948635
INFO:root:At the start of the epoch: mem (CPU python)=4468.06640625MB; mem (CPU total)=7609.6953125MB
INFO:root:[    2] Training loss: 0.73499616, Validation loss: 0.73420591, Gradient norm: 0.38054094
INFO:root:At the start of the epoch: mem (CPU python)=4492.73046875MB; mem (CPU total)=7612.9140625MB
INFO:root:[    3] Training loss: 0.73309186, Validation loss: 0.73198458, Gradient norm: 0.32901365
INFO:root:At the start of the epoch: mem (CPU python)=4514.0234375MB; mem (CPU total)=7597.703125MB
INFO:root:[    4] Training loss: 0.72551620, Validation loss: 0.71307312, Gradient norm: 0.41063192
INFO:root:At the start of the epoch: mem (CPU python)=4534.0625MB; mem (CPU total)=7665.90625MB
INFO:root:[    5] Training loss: 0.68292151, Validation loss: 0.64742793, Gradient norm: 0.54295183
INFO:root:At the start of the epoch: mem (CPU python)=4555.953125MB; mem (CPU total)=7683.15625MB
INFO:root:[    6] Training loss: 0.62078669, Validation loss: 0.59301823, Gradient norm: 0.76288777
INFO:root:At the start of the epoch: mem (CPU python)=4577.1328125MB; mem (CPU total)=7706.7421875MB
INFO:root:[    7] Training loss: 0.56751988, Validation loss: 0.53625134, Gradient norm: 0.93894481
INFO:root:At the start of the epoch: mem (CPU python)=4597.78515625MB; mem (CPU total)=7715.05859375MB
INFO:root:[    8] Training loss: 0.52914625, Validation loss: 0.51308222, Gradient norm: 0.99676044
INFO:root:At the start of the epoch: mem (CPU python)=4619.78515625MB; mem (CPU total)=7739.109375MB
INFO:root:[    9] Training loss: 0.51255845, Validation loss: 0.49144677, Gradient norm: 1.18015394
INFO:root:At the start of the epoch: mem (CPU python)=4641.03515625MB; mem (CPU total)=7756.7734375MB
INFO:root:[   10] Training loss: 0.49195419, Validation loss: 0.49287842, Gradient norm: 1.11072870
INFO:root:At the start of the epoch: mem (CPU python)=4661.6171875MB; mem (CPU total)=7808.76171875MB
INFO:root:[   11] Training loss: 0.48684310, Validation loss: 0.47711204, Gradient norm: 1.30866645
INFO:root:At the start of the epoch: mem (CPU python)=4682.62109375MB; mem (CPU total)=7813.03515625MB
INFO:root:[   12] Training loss: 0.47600222, Validation loss: 0.48062915, Gradient norm: 1.28412048
INFO:root:At the start of the epoch: mem (CPU python)=4704.08984375MB; mem (CPU total)=7832.7265625MB
INFO:root:[   13] Training loss: 0.46842521, Validation loss: 0.45576750, Gradient norm: 1.14940452
INFO:root:At the start of the epoch: mem (CPU python)=4726.58203125MB; mem (CPU total)=7854.8203125MB
INFO:root:[   14] Training loss: 0.46427131, Validation loss: 0.44936889, Gradient norm: 1.37038493
INFO:root:At the start of the epoch: mem (CPU python)=4746.8046875MB; mem (CPU total)=7877.34375MB
INFO:root:[   15] Training loss: 0.46082449, Validation loss: 0.44845971, Gradient norm: 1.46394930
INFO:root:At the start of the epoch: mem (CPU python)=4767.69921875MB; mem (CPU total)=7899.96875MB
INFO:root:[   16] Training loss: 0.45466471, Validation loss: 0.44168757, Gradient norm: 1.36181495
INFO:root:At the start of the epoch: mem (CPU python)=4789.95703125MB; mem (CPU total)=7908.4765625MB
INFO:root:[   17] Training loss: 0.44723147, Validation loss: 0.44069076, Gradient norm: 1.28056293
INFO:root:At the start of the epoch: mem (CPU python)=4809.7578125MB; mem (CPU total)=7915.46484375MB
INFO:root:[   18] Training loss: 0.44498884, Validation loss: 0.43798790, Gradient norm: 1.28108839
INFO:root:At the start of the epoch: mem (CPU python)=4833.90234375MB; mem (CPU total)=7961.5MB
INFO:root:[   19] Training loss: 0.44415599, Validation loss: 0.43214634, Gradient norm: 1.48568519
INFO:root:At the start of the epoch: mem (CPU python)=4852.59765625MB; mem (CPU total)=7983.046875MB
INFO:root:[   20] Training loss: 0.44113815, Validation loss: 0.43687516, Gradient norm: 1.49326224
INFO:root:At the start of the epoch: mem (CPU python)=4874.53515625MB; mem (CPU total)=7953.88671875MB
INFO:root:[   21] Training loss: 0.43755038, Validation loss: 0.42667591, Gradient norm: 1.56755982
INFO:root:At the start of the epoch: mem (CPU python)=4895.6640625MB; mem (CPU total)=8030.671875MB
INFO:root:[   22] Training loss: 0.43371885, Validation loss: 0.42965078, Gradient norm: 1.39343834
INFO:root:At the start of the epoch: mem (CPU python)=4915.9609375MB; mem (CPU total)=8041.703125MB
INFO:root:[   23] Training loss: 0.43318010, Validation loss: 0.42118210, Gradient norm: 1.48731415
INFO:root:At the start of the epoch: mem (CPU python)=4937.796875MB; mem (CPU total)=8065.171875MB
INFO:root:[   24] Training loss: 0.43203043, Validation loss: 0.41830138, Gradient norm: 1.85352650
INFO:root:At the start of the epoch: mem (CPU python)=4959.8671875MB; mem (CPU total)=8091.78515625MB
INFO:root:[   25] Training loss: 0.43182539, Validation loss: 0.43231732, Gradient norm: 1.79111307
INFO:root:At the start of the epoch: mem (CPU python)=4981.50390625MB; mem (CPU total)=8117.65234375MB
INFO:root:[   26] Training loss: 0.43175185, Validation loss: 0.42463169, Gradient norm: 1.44776782
INFO:root:At the start of the epoch: mem (CPU python)=5004.5625MB; mem (CPU total)=8129.66015625MB
INFO:root:[   27] Training loss: 0.42376944, Validation loss: 0.41658723, Gradient norm: 1.81457102
INFO:root:At the start of the epoch: mem (CPU python)=5024.02734375MB; mem (CPU total)=8163.2578125MB
INFO:root:[   28] Training loss: 0.42727617, Validation loss: 0.41074892, Gradient norm: 1.86353604
INFO:root:At the start of the epoch: mem (CPU python)=5048.51953125MB; mem (CPU total)=8174.06640625MB
INFO:root:[   29] Training loss: 0.42184684, Validation loss: 0.41809942, Gradient norm: 1.60258975
INFO:root:At the start of the epoch: mem (CPU python)=5069.140625MB; mem (CPU total)=8197.703125MB
INFO:root:[   30] Training loss: 0.42270099, Validation loss: 0.40415107, Gradient norm: 2.04722757
INFO:root:At the start of the epoch: mem (CPU python)=5089.34375MB; mem (CPU total)=8206.74609375MB
INFO:root:[   31] Training loss: 0.42305058, Validation loss: 0.41876578, Gradient norm: 1.61375566
INFO:root:At the start of the epoch: mem (CPU python)=5111.890625MB; mem (CPU total)=8245.453125MB
INFO:root:[   32] Training loss: 0.42155520, Validation loss: 0.40481892, Gradient norm: 2.15259976
INFO:root:At the start of the epoch: mem (CPU python)=5131.74609375MB; mem (CPU total)=8253.4765625MB
INFO:root:[   33] Training loss: 0.42076900, Validation loss: 0.41969608, Gradient norm: 2.16318035
INFO:root:At the start of the epoch: mem (CPU python)=5155.3671875MB; mem (CPU total)=8266.3203125MB
INFO:root:[   34] Training loss: 0.42043607, Validation loss: 0.42022994, Gradient norm: 2.01109290
INFO:root:At the start of the epoch: mem (CPU python)=5175.26171875MB; mem (CPU total)=8290.9609375MB
INFO:root:[   35] Training loss: 0.41976399, Validation loss: 0.42880453, Gradient norm: 2.26504826
INFO:root:At the start of the epoch: mem (CPU python)=5196.0625MB; mem (CPU total)=8323.87890625MB
INFO:root:[   36] Training loss: 0.41758257, Validation loss: 0.44044552, Gradient norm: 2.27559417
INFO:root:At the start of the epoch: mem (CPU python)=5219.109375MB; mem (CPU total)=8358.0703125MB
INFO:root:[   37] Training loss: 0.41844530, Validation loss: 0.40995998, Gradient norm: 2.08152015
INFO:root:At the start of the epoch: mem (CPU python)=5237.62109375MB; mem (CPU total)=8321.65234375MB
INFO:root:[   38] Training loss: 0.41734923, Validation loss: 0.41672577, Gradient norm: 2.22449257
INFO:root:At the start of the epoch: mem (CPU python)=5258.82421875MB; mem (CPU total)=8375.88671875MB
INFO:root:[   39] Training loss: 0.41544325, Validation loss: 0.40971909, Gradient norm: 2.15779312
INFO:root:At the start of the epoch: mem (CPU python)=5280.69140625MB; mem (CPU total)=8410.53515625MB
INFO:root:[   40] Training loss: 0.41724700, Validation loss: 0.39887609, Gradient norm: 2.18705175
INFO:root:At the start of the epoch: mem (CPU python)=5302.0703125MB; mem (CPU total)=8397.796875MB
INFO:root:[   41] Training loss: 0.41326092, Validation loss: 0.40109825, Gradient norm: 2.74508121
INFO:root:At the start of the epoch: mem (CPU python)=5323.1640625MB; mem (CPU total)=8463.59765625MB
INFO:root:[   42] Training loss: 0.41675123, Validation loss: 0.41893697, Gradient norm: 2.49317622
INFO:root:At the start of the epoch: mem (CPU python)=5343.69140625MB; mem (CPU total)=8456.36328125MB
INFO:root:[   43] Training loss: 0.41290499, Validation loss: 0.40337857, Gradient norm: 2.56348714
INFO:root:At the start of the epoch: mem (CPU python)=5367.640625MB; mem (CPU total)=8485.2109375MB
INFO:root:[   44] Training loss: 0.41559464, Validation loss: 0.40988211, Gradient norm: 2.27508328
INFO:root:At the start of the epoch: mem (CPU python)=5391.96875MB; mem (CPU total)=8510.35546875MB
INFO:root:[   45] Training loss: 0.41140650, Validation loss: 0.40788232, Gradient norm: 2.65500725
INFO:root:At the start of the epoch: mem (CPU python)=5412.78125MB; mem (CPU total)=8527.90234375MB
INFO:root:[   46] Training loss: 0.41001241, Validation loss: 0.41193253, Gradient norm: 2.63953284
INFO:root:At the start of the epoch: mem (CPU python)=5434.7578125MB; mem (CPU total)=8559.0859375MB
INFO:root:[   47] Training loss: 0.40962461, Validation loss: 0.41543958, Gradient norm: 2.82368150
INFO:root:At the start of the epoch: mem (CPU python)=5455.0078125MB; mem (CPU total)=8514.54296875MB
INFO:root:[   48] Training loss: 0.41029382, Validation loss: 0.40902303, Gradient norm: 2.89162618
INFO:root:At the start of the epoch: mem (CPU python)=5474.484375MB; mem (CPU total)=8599.203125MB
INFO:root:[   49] Training loss: 0.40886519, Validation loss: 0.39390784, Gradient norm: 2.68390896
INFO:root:At the start of the epoch: mem (CPU python)=5495.734375MB; mem (CPU total)=8615.70703125MB
INFO:root:[   50] Training loss: 0.40815689, Validation loss: 0.41556331, Gradient norm: 2.37054686
INFO:root:At the start of the epoch: mem (CPU python)=5521.171875MB; mem (CPU total)=8652.39453125MB
INFO:root:[   51] Training loss: 0.40874344, Validation loss: 0.39859046, Gradient norm: 3.12368856
INFO:root:At the start of the epoch: mem (CPU python)=5542.98046875MB; mem (CPU total)=8681.49609375MB
INFO:root:[   52] Training loss: 0.40709264, Validation loss: 0.39571351, Gradient norm: 2.97426581
INFO:root:At the start of the epoch: mem (CPU python)=5564.14453125MB; mem (CPU total)=8689.28515625MB
INFO:root:[   53] Training loss: 0.40929212, Validation loss: 0.40292914, Gradient norm: 3.44899669
INFO:root:At the start of the epoch: mem (CPU python)=5585.3046875MB; mem (CPU total)=8695.7734375MB
INFO:root:[   54] Training loss: 0.41009853, Validation loss: 0.39729022, Gradient norm: 2.94819316
INFO:root:At the start of the epoch: mem (CPU python)=5606.46875MB; mem (CPU total)=8739.48828125MB
INFO:root:[   55] Training loss: 0.40986632, Validation loss: 0.40766429, Gradient norm: 3.14868620
INFO:root:At the start of the epoch: mem (CPU python)=5627.63671875MB; mem (CPU total)=8771.7734375MB
INFO:root:[   56] Training loss: 0.40850527, Validation loss: 0.39786520, Gradient norm: 3.09527446
INFO:root:At the start of the epoch: mem (CPU python)=5648.921875MB; mem (CPU total)=8771.19140625MB
INFO:root:[   57] Training loss: 0.40510337, Validation loss: 0.43014655, Gradient norm: 3.35304172
INFO:root:At the start of the epoch: mem (CPU python)=5670.2109375MB; mem (CPU total)=8801.59765625MB
INFO:root:[   58] Training loss: 0.40941102, Validation loss: 0.41733249, Gradient norm: 3.76389075
INFO:root:At the start of the epoch: mem (CPU python)=5691.5MB; mem (CPU total)=8825.125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   59] Training loss: 0.40760538, Validation loss: 0.39052793, Gradient norm: 3.52654178
INFO:root:At the start of the epoch: mem (CPU python)=5712.671875MB; mem (CPU total)=8842.5859375MB
INFO:root:[   60] Training loss: 0.38732105, Validation loss: 0.37683368, Gradient norm: 2.58247312
INFO:root:At the start of the epoch: mem (CPU python)=5733.875MB; mem (CPU total)=8866.890625MB
INFO:root:[   61] Training loss: 0.38570963, Validation loss: 0.37430100, Gradient norm: 2.74543711
INFO:root:At the start of the epoch: mem (CPU python)=5756.28515625MB; mem (CPU total)=8890.109375MB
INFO:root:[   62] Training loss: 0.38446980, Validation loss: 0.38400284, Gradient norm: 3.02748163
INFO:root:At the start of the epoch: mem (CPU python)=5777.44921875MB; mem (CPU total)=8912.56640625MB
INFO:root:[   63] Training loss: 0.38345641, Validation loss: 0.38049260, Gradient norm: 3.16090862
INFO:root:At the start of the epoch: mem (CPU python)=5799.19921875MB; mem (CPU total)=8907.99609375MB
INFO:root:[   64] Training loss: 0.38600727, Validation loss: 0.37337458, Gradient norm: 3.80255224
INFO:root:At the start of the epoch: mem (CPU python)=5820.3671875MB; mem (CPU total)=8945.72265625MB
INFO:root:[   65] Training loss: 0.38200158, Validation loss: 0.38162819, Gradient norm: 3.60123035
INFO:root:At the start of the epoch: mem (CPU python)=5841.52734375MB; mem (CPU total)=8969.765625MB
INFO:root:[   66] Training loss: 0.38460970, Validation loss: 0.37564001, Gradient norm: 3.78753094
INFO:root:At the start of the epoch: mem (CPU python)=5862.6953125MB; mem (CPU total)=8963.82421875MB
INFO:root:[   67] Training loss: 0.38193164, Validation loss: 0.37227265, Gradient norm: 4.06719447
INFO:root:At the start of the epoch: mem (CPU python)=5883.859375MB; mem (CPU total)=9023.19140625MB
INFO:root:[   68] Training loss: 0.38376864, Validation loss: 0.38328021, Gradient norm: 4.35264671
INFO:root:At the start of the epoch: mem (CPU python)=5905.0234375MB; mem (CPU total)=9031.58203125MB
INFO:root:[   69] Training loss: 0.38452502, Validation loss: 0.37671351, Gradient norm: 4.47665607
INFO:root:At the start of the epoch: mem (CPU python)=5926.18359375MB; mem (CPU total)=9057.765625MB
INFO:root:[   70] Training loss: 0.38355816, Validation loss: 0.38875424, Gradient norm: 4.60038205
INFO:root:At the start of the epoch: mem (CPU python)=5947.4765625MB; mem (CPU total)=8924.16015625MB
INFO:root:[   71] Training loss: 0.38144147, Validation loss: 0.37219223, Gradient norm: 4.48037338
INFO:root:At the start of the epoch: mem (CPU python)=5968.65234375MB; mem (CPU total)=9055.99609375MB
INFO:root:[   72] Training loss: 0.38836483, Validation loss: 0.37547148, Gradient norm: 4.73771655
INFO:root:At the start of the epoch: mem (CPU python)=5990.05078125MB; mem (CPU total)=9121.17578125MB
INFO:root:[   73] Training loss: 0.38479922, Validation loss: 0.38123809, Gradient norm: 4.24848369
INFO:root:At the start of the epoch: mem (CPU python)=6011.21875MB; mem (CPU total)=9140.55859375MB
INFO:root:[   74] Training loss: 0.38272076, Validation loss: 0.37711584, Gradient norm: 5.51050896
INFO:root:At the start of the epoch: mem (CPU python)=6032.4765625MB; mem (CPU total)=9161.390625MB
INFO:root:[   75] Training loss: 0.38633448, Validation loss: 0.38119669, Gradient norm: 5.16624203
INFO:root:At the start of the epoch: mem (CPU python)=6053.921875MB; mem (CPU total)=9183.328125MB
INFO:root:[   76] Training loss: 0.38086027, Validation loss: 0.37885848, Gradient norm: 5.15520303
INFO:root:At the start of the epoch: mem (CPU python)=6075.0859375MB; mem (CPU total)=9203.359375MB
INFO:root:[   77] Training loss: 0.38787594, Validation loss: 0.38025742, Gradient norm: 5.39411368
INFO:root:At the start of the epoch: mem (CPU python)=6096.25390625MB; mem (CPU total)=9220.62109375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   78] Training loss: 0.38360376, Validation loss: 0.39270415, Gradient norm: 5.72897938
INFO:root:At the start of the epoch: mem (CPU python)=6117.41796875MB; mem (CPU total)=9248.55859375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   79] Training loss: 0.37756352, Validation loss: 0.37378724, Gradient norm: 3.84030357
INFO:root:At the start of the epoch: mem (CPU python)=6138.578125MB; mem (CPU total)=9272.31640625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   80] Training loss: 0.36761945, Validation loss: 0.36083921, Gradient norm: 2.38819455
INFO:root:At the start of the epoch: mem (CPU python)=6159.7421875MB; mem (CPU total)=9282.1640625MB
INFO:root:[   81] Training loss: 0.36490612, Validation loss: 0.35967347, Gradient norm: 1.91603409
INFO:root:At the start of the epoch: mem (CPU python)=6180.91015625MB; mem (CPU total)=9300.390625MB
INFO:root:[   82] Training loss: 0.36511900, Validation loss: 0.35897046, Gradient norm: 1.82515414
INFO:root:At the start of the epoch: mem (CPU python)=6202.4453125MB; mem (CPU total)=9326.81640625MB
INFO:root:[   83] Training loss: 0.36546516, Validation loss: 0.35909868, Gradient norm: 1.70748852
INFO:root:At the start of the epoch: mem (CPU python)=6223.61328125MB; mem (CPU total)=9353.48046875MB
INFO:root:[   84] Training loss: 0.36544472, Validation loss: 0.36026405, Gradient norm: 1.82048589
INFO:root:At the start of the epoch: mem (CPU python)=6244.77734375MB; mem (CPU total)=9376.6171875MB
INFO:root:[   85] Training loss: 0.36451549, Validation loss: 0.35954159, Gradient norm: 1.90797861
INFO:root:At the start of the epoch: mem (CPU python)=6266.3125MB; mem (CPU total)=9398.21484375MB
INFO:root:[   86] Training loss: 0.36381844, Validation loss: 0.35839456, Gradient norm: 2.09970716
INFO:root:At the start of the epoch: mem (CPU python)=6287.9921875MB; mem (CPU total)=9408.5234375MB
INFO:root:[   87] Training loss: 0.36377588, Validation loss: 0.35814644, Gradient norm: 2.38561041
INFO:root:At the start of the epoch: mem (CPU python)=6307.91796875MB; mem (CPU total)=9446.62890625MB
INFO:root:[   88] Training loss: 0.36355805, Validation loss: 0.35776747, Gradient norm: 2.33572803
INFO:root:At the start of the epoch: mem (CPU python)=6329.0234375MB; mem (CPU total)=9464.42578125MB
INFO:root:[   89] Training loss: 0.36322951, Validation loss: 0.36028039, Gradient norm: 2.64653970
INFO:root:At the start of the epoch: mem (CPU python)=6352.21875MB; mem (CPU total)=9476.5MB
INFO:root:[   90] Training loss: 0.36422342, Validation loss: 0.35888760, Gradient norm: 3.52529976
INFO:root:At the start of the epoch: mem (CPU python)=6372.7734375MB; mem (CPU total)=9497.76953125MB
INFO:root:[   91] Training loss: 0.36412194, Validation loss: 0.35844054, Gradient norm: 2.74651284
INFO:root:At the start of the epoch: mem (CPU python)=6393.359375MB; mem (CPU total)=9530.48828125MB
INFO:root:[   92] Training loss: 0.36432664, Validation loss: 0.35833817, Gradient norm: 2.89977594
INFO:root:At the start of the epoch: mem (CPU python)=6413.80859375MB; mem (CPU total)=9538.34375MB
INFO:root:[   93] Training loss: 0.36376817, Validation loss: 0.35841929, Gradient norm: 3.28860862
INFO:root:At the start of the epoch: mem (CPU python)=6436.296875MB; mem (CPU total)=9570.37109375MB
INFO:root:[   94] Training loss: 0.36262656, Validation loss: 0.35738731, Gradient norm: 2.99589184
INFO:root:At the start of the epoch: mem (CPU python)=6456.98828125MB; mem (CPU total)=9590.92578125MB
INFO:root:[   95] Training loss: 0.36399951, Validation loss: 0.35819787, Gradient norm: 3.30514038
INFO:root:At the start of the epoch: mem (CPU python)=6478.984375MB; mem (CPU total)=9611.19140625MB
INFO:root:[   96] Training loss: 0.36308502, Validation loss: 0.35791994, Gradient norm: 3.23149959
INFO:root:At the start of the epoch: mem (CPU python)=6499.84375MB; mem (CPU total)=9629.37109375MB
INFO:root:[   97] Training loss: 0.36258715, Validation loss: 0.35765949, Gradient norm: 3.44982550
INFO:root:At the start of the epoch: mem (CPU python)=6522.296875MB; mem (CPU total)=9658.9609375MB
INFO:root:[   98] Training loss: 0.36293530, Validation loss: 0.35800996, Gradient norm: 3.35365759
INFO:root:At the start of the epoch: mem (CPU python)=6544.0MB; mem (CPU total)=9668.15625MB
INFO:root:[   99] Training loss: 0.36353370, Validation loss: 0.35783450, Gradient norm: 3.90127932
INFO:root:At the start of the epoch: mem (CPU python)=6564.046875MB; mem (CPU total)=9702.1953125MB
INFO:root:[  100] Training loss: 0.36355749, Validation loss: 0.35885133, Gradient norm: 3.86672427
INFO:root:At the start of the epoch: mem (CPU python)=6585.74609375MB; mem (CPU total)=9554.03515625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  101] Training loss: 0.36354764, Validation loss: 0.35839183, Gradient norm: 4.02262705
INFO:root:At the start of the epoch: mem (CPU python)=6607.515625MB; mem (CPU total)=9698.10546875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  102] Training loss: 0.36296517, Validation loss: 0.35732195, Gradient norm: 2.93449825
INFO:root:At the start of the epoch: mem (CPU python)=6628.5234375MB; mem (CPU total)=9762.44140625MB
INFO:root:[  103] Training loss: 0.36092962, Validation loss: 0.35593159, Gradient norm: 1.89995492
INFO:root:At the start of the epoch: mem (CPU python)=6649.21875MB; mem (CPU total)=9772.49609375MB
INFO:root:[  104] Training loss: 0.36077242, Validation loss: 0.35638280, Gradient norm: 2.14854345
INFO:root:At the start of the epoch: mem (CPU python)=6671.62109375MB; mem (CPU total)=9777.3125MB
INFO:root:[  105] Training loss: 0.36124434, Validation loss: 0.35645295, Gradient norm: 2.47502205
INFO:root:At the start of the epoch: mem (CPU python)=6691.73828125MB; mem (CPU total)=9810.2734375MB
INFO:root:[  106] Training loss: 0.36082143, Validation loss: 0.35650873, Gradient norm: 2.22522311
INFO:root:At the start of the epoch: mem (CPU python)=6712.0546875MB; mem (CPU total)=9785.87109375MB
INFO:root:[  107] Training loss: 0.36145684, Validation loss: 0.35655445, Gradient norm: 2.20286573
INFO:root:At the start of the epoch: mem (CPU python)=6734.875MB; mem (CPU total)=9845.7890625MB
INFO:root:[  108] Training loss: 0.36034115, Validation loss: 0.35548338, Gradient norm: 2.29032494
INFO:root:At the start of the epoch: mem (CPU python)=6755.7578125MB; mem (CPU total)=9873.12890625MB
INFO:root:[  109] Training loss: 0.36148194, Validation loss: 0.35571528, Gradient norm: 2.41848960
INFO:root:At the start of the epoch: mem (CPU python)=6776.92578125MB; mem (CPU total)=9895.4375MB
INFO:root:[  110] Training loss: 0.36134614, Validation loss: 0.35588274, Gradient norm: 2.27923990
INFO:root:At the start of the epoch: mem (CPU python)=6799.3515625MB; mem (CPU total)=9930.41796875MB
INFO:root:[  111] Training loss: 0.36193253, Validation loss: 0.35589247, Gradient norm: 2.17452861
INFO:root:At the start of the epoch: mem (CPU python)=6821.1796875MB; mem (CPU total)=9965.52734375MB
INFO:root:[  112] Training loss: 0.36071773, Validation loss: 0.35624348, Gradient norm: 2.17551172
INFO:root:At the start of the epoch: mem (CPU python)=6843.09765625MB; mem (CPU total)=9970.7890625MB
INFO:root:[  113] Training loss: 0.36182912, Validation loss: 0.35584214, Gradient norm: 2.51960924
INFO:root:At the start of the epoch: mem (CPU python)=6864.64453125MB; mem (CPU total)=9992.234375MB
INFO:root:[  114] Training loss: 0.36162504, Validation loss: 0.35594079, Gradient norm: 2.61700179
INFO:root:At the start of the epoch: mem (CPU python)=6885.80859375MB; mem (CPU total)=10003.12109375MB
INFO:root:[  115] Training loss: 0.36048980, Validation loss: 0.35593806, Gradient norm: 2.44459492
INFO:root:At the start of the epoch: mem (CPU python)=6906.9765625MB; mem (CPU total)=10038.44140625MB
INFO:root:[  116] Training loss: 0.36109857, Validation loss: 0.35612168, Gradient norm: 2.54626069
INFO:root:At the start of the epoch: mem (CPU python)=6928.14453125MB; mem (CPU total)=10065.48828125MB
INFO:root:[  117] Training loss: 0.36092738, Validation loss: 0.35558218, Gradient norm: 2.86407394
INFO:root:At the start of the epoch: mem (CPU python)=6949.3125MB; mem (CPU total)=10080.95703125MB
INFO:root:EP 117: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=6970.48828125MB; mem (CPU total)=10087.296875MB
INFO:root:[  119] Training loss: 0.44463298, Validation loss: 0.43516582, Gradient norm: 4.71715561
INFO:root:At the start of the epoch: mem (CPU python)=6991.65234375MB; mem (CPU total)=10072.546875MB
INFO:root:[  120] Training loss: 0.44306937, Validation loss: 0.43391812, Gradient norm: 4.56792480
INFO:root:At the start of the epoch: mem (CPU python)=7012.81640625MB; mem (CPU total)=10123.1953125MB
INFO:root:[  121] Training loss: 0.44290283, Validation loss: 0.43328814, Gradient norm: 4.60887490
INFO:root:At the start of the epoch: mem (CPU python)=7033.9921875MB; mem (CPU total)=10153.19140625MB
INFO:root:[  122] Training loss: 0.44195174, Validation loss: 0.43347741, Gradient norm: 5.15069632
INFO:root:At the start of the epoch: mem (CPU python)=7055.16015625MB; mem (CPU total)=10189.3125MB
INFO:root:[  123] Training loss: 0.44236729, Validation loss: 0.43349889, Gradient norm: 4.67579593
INFO:root:At the start of the epoch: mem (CPU python)=7076.32421875MB; mem (CPU total)=10202.96484375MB
INFO:root:[  124] Training loss: 0.44171094, Validation loss: 0.43309517, Gradient norm: 4.76065997
INFO:root:At the start of the epoch: mem (CPU python)=7097.49609375MB; mem (CPU total)=10221.53515625MB
INFO:root:[  125] Training loss: 0.44128261, Validation loss: 0.43294101, Gradient norm: 4.74094322
INFO:root:At the start of the epoch: mem (CPU python)=7118.6640625MB; mem (CPU total)=10256.19921875MB
INFO:root:[  126] Training loss: 0.44173269, Validation loss: 0.43213681, Gradient norm: 4.77176967
INFO:root:At the start of the epoch: mem (CPU python)=7139.83203125MB; mem (CPU total)=10278.56640625MB
INFO:root:[  127] Training loss: 0.44149106, Validation loss: 0.43355138, Gradient norm: 4.66910168
INFO:root:At the start of the epoch: mem (CPU python)=7160.99609375MB; mem (CPU total)=10283.43359375MB
INFO:root:[  128] Training loss: 0.44091160, Validation loss: 0.43204665, Gradient norm: 4.68396904
INFO:root:At the start of the epoch: mem (CPU python)=7182.1640625MB; mem (CPU total)=10299.37109375MB
INFO:root:[  129] Training loss: 0.44014393, Validation loss: 0.43209294, Gradient norm: 4.72812443
INFO:root:At the start of the epoch: mem (CPU python)=7203.64453125MB; mem (CPU total)=10341.58984375MB
INFO:root:[  130] Training loss: 0.44092068, Validation loss: 0.43196200, Gradient norm: 4.79670519
INFO:root:At the start of the epoch: mem (CPU python)=7224.8203125MB; mem (CPU total)=10341.80859375MB
INFO:root:[  131] Training loss: 0.44034154, Validation loss: 0.43213394, Gradient norm: 5.01712470
INFO:root:At the start of the epoch: mem (CPU python)=7246.42578125MB; mem (CPU total)=10379.90625MB
INFO:root:[  132] Training loss: 0.44007606, Validation loss: 0.43192060, Gradient norm: 4.70601063
INFO:root:At the start of the epoch: mem (CPU python)=7268.578125MB; mem (CPU total)=10403.5234375MB
INFO:root:[  133] Training loss: 0.43997481, Validation loss: 0.43214639, Gradient norm: 4.88987370
INFO:root:At the start of the epoch: mem (CPU python)=7289.7578125MB; mem (CPU total)=10417.2265625MB
INFO:root:[  134] Training loss: 0.44018261, Validation loss: 0.43137275, Gradient norm: 4.89379691
INFO:root:At the start of the epoch: mem (CPU python)=7310.9453125MB; mem (CPU total)=10435.9921875MB
INFO:root:[  135] Training loss: 0.44032857, Validation loss: 0.43190795, Gradient norm: 4.89181727
INFO:root:At the start of the epoch: mem (CPU python)=7332.11328125MB; mem (CPU total)=10447.109375MB
INFO:root:[  136] Training loss: 0.43970321, Validation loss: 0.43054940, Gradient norm: 4.82159537
INFO:root:At the start of the epoch: mem (CPU python)=7353.29296875MB; mem (CPU total)=10481.25MB
INFO:root:[  137] Training loss: 0.43988882, Validation loss: 0.43137226, Gradient norm: 4.67919137
INFO:root:At the start of the epoch: mem (CPU python)=7374.58203125MB; mem (CPU total)=10502.45703125MB
INFO:root:[  138] Training loss: 0.44020031, Validation loss: 0.43099992, Gradient norm: 5.14221480
INFO:root:At the start of the epoch: mem (CPU python)=7396.453125MB; mem (CPU total)=10514.84375MB
INFO:root:[  139] Training loss: 0.43983913, Validation loss: 0.43141159, Gradient norm: 4.99641699
INFO:root:At the start of the epoch: mem (CPU python)=7417.94921875MB; mem (CPU total)=10462.9609375MB
INFO:root:[  140] Training loss: 0.43973226, Validation loss: 0.43065657, Gradient norm: 5.00012762
INFO:root:At the start of the epoch: mem (CPU python)=7439.12109375MB; mem (CPU total)=10543.40625MB
INFO:root:[  141] Training loss: 0.43979649, Validation loss: 0.43142057, Gradient norm: 5.10585510
INFO:root:At the start of the epoch: mem (CPU python)=7460.30078125MB; mem (CPU total)=10593.4140625MB
INFO:root:[  142] Training loss: 0.44050636, Validation loss: 0.43078959, Gradient norm: 4.87425145
INFO:root:At the start of the epoch: mem (CPU python)=7481.4765625MB; mem (CPU total)=10614.22265625MB
INFO:root:[  143] Training loss: 0.43900301, Validation loss: 0.43016715, Gradient norm: 4.80414155
INFO:root:At the start of the epoch: mem (CPU python)=7502.66796875MB; mem (CPU total)=10635.21484375MB
INFO:root:[  144] Training loss: 0.43925468, Validation loss: 0.43075303, Gradient norm: 5.00662224
INFO:root:At the start of the epoch: mem (CPU python)=7523.83984375MB; mem (CPU total)=10661.71484375MB
INFO:root:[  145] Training loss: 0.43883030, Validation loss: 0.43098255, Gradient norm: 4.62003134
INFO:root:At the start of the epoch: mem (CPU python)=7545.0078125MB; mem (CPU total)=10661.4375MB
INFO:root:[  146] Training loss: 0.43924940, Validation loss: 0.43021972, Gradient norm: 5.45457001
INFO:root:At the start of the epoch: mem (CPU python)=7566.1875MB; mem (CPU total)=10689.6015625MB
INFO:root:[  147] Training loss: 0.43968751, Validation loss: 0.43061325, Gradient norm: 4.88034455
INFO:root:At the start of the epoch: mem (CPU python)=7587.9765625MB; mem (CPU total)=10727.0MB
INFO:root:[  148] Training loss: 0.43922614, Validation loss: 0.43023110, Gradient norm: 5.01402658
INFO:root:At the start of the epoch: mem (CPU python)=7609.65625MB; mem (CPU total)=10735.16015625MB
INFO:root:[  149] Training loss: 0.43899476, Validation loss: 0.43088845, Gradient norm: 4.86535245
INFO:root:At the start of the epoch: mem (CPU python)=7630.828125MB; mem (CPU total)=10642.18359375MB
INFO:root:[  150] Training loss: 0.43830378, Validation loss: 0.43033120, Gradient norm: 5.30531501
INFO:root:At the start of the epoch: mem (CPU python)=7652.0MB; mem (CPU total)=10788.61328125MB
INFO:root:[  151] Training loss: 0.43940752, Validation loss: 0.43043106, Gradient norm: 5.32035829
INFO:root:At the start of the epoch: mem (CPU python)=7673.171875MB; mem (CPU total)=10691.68359375MB
INFO:root:[  152] Training loss: 0.43923502, Validation loss: 0.42991918, Gradient norm: 5.75934635
INFO:root:At the start of the epoch: mem (CPU python)=7694.3359375MB; mem (CPU total)=10840.31640625MB
INFO:root:[  153] Training loss: 0.43857004, Validation loss: 0.43018769, Gradient norm: 5.68311957
INFO:root:At the start of the epoch: mem (CPU python)=7714.05859375MB; mem (CPU total)=10851.1171875MB
INFO:root:[  154] Training loss: 0.43860293, Validation loss: 0.43038944, Gradient norm: 5.77670472
INFO:root:At the start of the epoch: mem (CPU python)=7735.8515625MB; mem (CPU total)=10856.1875MB
INFO:root:[  155] Training loss: 0.43972405, Validation loss: 0.43022926, Gradient norm: 5.76353781
INFO:root:At the start of the epoch: mem (CPU python)=7756.66796875MB; mem (CPU total)=10900.44921875MB
INFO:root:[  156] Training loss: 0.43862902, Validation loss: 0.42980465, Gradient norm: 5.98200838
INFO:root:At the start of the epoch: mem (CPU python)=7778.3984375MB; mem (CPU total)=10893.87109375MB
INFO:root:[  157] Training loss: 0.43827735, Validation loss: 0.43016336, Gradient norm: 5.15212898
INFO:root:At the start of the epoch: mem (CPU python)=7799.53515625MB; mem (CPU total)=10917.81640625MB
INFO:root:[  158] Training loss: 0.43914931, Validation loss: 0.42953635, Gradient norm: 5.44693550
INFO:root:At the start of the epoch: mem (CPU python)=7821.83984375MB; mem (CPU total)=10959.5078125MB
INFO:root:[  159] Training loss: 0.43868968, Validation loss: 0.43036957, Gradient norm: 5.53734024
INFO:root:At the start of the epoch: mem (CPU python)=7844.33984375MB; mem (CPU total)=10973.94921875MB
INFO:root:[  160] Training loss: 0.43837754, Validation loss: 0.42958701, Gradient norm: 5.66337672
INFO:root:At the start of the epoch: mem (CPU python)=7863.71875MB; mem (CPU total)=10997.22265625MB
INFO:root:[  161] Training loss: 0.43907811, Validation loss: 0.43003771, Gradient norm: 5.53388640
INFO:root:At the start of the epoch: mem (CPU python)=7884.8984375MB; mem (CPU total)=11012.0078125MB
INFO:root:[  162] Training loss: 0.43766277, Validation loss: 0.42930392, Gradient norm: 5.47041414
INFO:root:At the start of the epoch: mem (CPU python)=7905.35546875MB; mem (CPU total)=11027.2421875MB
INFO:root:[  163] Training loss: 0.43868636, Validation loss: 0.42938358, Gradient norm: 6.08208294
INFO:root:At the start of the epoch: mem (CPU python)=7927.29296875MB; mem (CPU total)=11049.6953125MB
INFO:root:[  164] Training loss: 0.43782261, Validation loss: 0.42976253, Gradient norm: 5.70539122
INFO:root:At the start of the epoch: mem (CPU python)=7947.90625MB; mem (CPU total)=11086.48046875MB
INFO:root:[  165] Training loss: 0.43805379, Validation loss: 0.42913095, Gradient norm: 6.08821473
INFO:root:At the start of the epoch: mem (CPU python)=7968.3984375MB; mem (CPU total)=11094.0546875MB
INFO:root:[  166] Training loss: 0.43793198, Validation loss: 0.42965866, Gradient norm: 5.67665132
INFO:root:At the start of the epoch: mem (CPU python)=7990.23828125MB; mem (CPU total)=11125.3671875MB
INFO:root:[  167] Training loss: 0.43848089, Validation loss: 0.42948915, Gradient norm: 5.96625147
INFO:root:At the start of the epoch: mem (CPU python)=8013.80078125MB; mem (CPU total)=11143.4375MB
INFO:root:[  168] Training loss: 0.43815638, Validation loss: 0.42933139, Gradient norm: 5.99230569
INFO:root:At the start of the epoch: mem (CPU python)=8033.80078125MB; mem (CPU total)=11158.203125MB
INFO:root:[  169] Training loss: 0.43848241, Validation loss: 0.42923099, Gradient norm: 5.45563211
INFO:root:At the start of the epoch: mem (CPU python)=8055.078125MB; mem (CPU total)=11156.7421875MB
INFO:root:[  170] Training loss: 0.43832535, Validation loss: 0.42899241, Gradient norm: 6.13985535
INFO:root:At the start of the epoch: mem (CPU python)=8075.9765625MB; mem (CPU total)=11211.1875MB
INFO:root:[  171] Training loss: 0.43848508, Validation loss: 0.42980206, Gradient norm: 5.78285775
INFO:root:At the start of the epoch: mem (CPU python)=8098.56640625MB; mem (CPU total)=11337.6015625MB
INFO:root:[  172] Training loss: 0.43794230, Validation loss: 0.42951059, Gradient norm: 6.21077005
INFO:root:At the start of the epoch: mem (CPU python)=8120.58203125MB; mem (CPU total)=11232.88671875MB
INFO:root:[  173] Training loss: 0.43829463, Validation loss: 0.42962179, Gradient norm: 5.94680241
INFO:root:At the start of the epoch: mem (CPU python)=8141.00390625MB; mem (CPU total)=11282.359375MB
INFO:root:[  174] Training loss: 0.43785065, Validation loss: 0.42884229, Gradient norm: 6.10319027
INFO:root:At the start of the epoch: mem (CPU python)=8162.59375MB; mem (CPU total)=11283.14453125MB
INFO:root:[  175] Training loss: 0.43775867, Validation loss: 0.42907582, Gradient norm: 5.98058757
INFO:root:At the start of the epoch: mem (CPU python)=8182.6875MB; mem (CPU total)=12103.421875MB
INFO:root:[  176] Training loss: 0.43767458, Validation loss: 0.42881979, Gradient norm: 5.93804950
INFO:root:At the start of the epoch: mem (CPU python)=8204.12890625MB; mem (CPU total)=11347.34765625MB
INFO:root:[  177] Training loss: 0.43915739, Validation loss: 0.42891493, Gradient norm: 6.45497702
INFO:root:At the start of the epoch: mem (CPU python)=8225.078125MB; mem (CPU total)=11356.984375MB
INFO:root:[  178] Training loss: 0.43832044, Validation loss: 0.42880977, Gradient norm: 6.09447473
INFO:root:At the start of the epoch: mem (CPU python)=8247.4375MB; mem (CPU total)=11360.59765625MB
INFO:root:[  179] Training loss: 0.43758126, Validation loss: 0.42884021, Gradient norm: 6.46589393
INFO:root:At the start of the epoch: mem (CPU python)=8269.01953125MB; mem (CPU total)=11416.59765625MB
INFO:root:[  180] Training loss: 0.43778470, Validation loss: 0.42878280, Gradient norm: 6.41715619
INFO:root:At the start of the epoch: mem (CPU python)=8288.7265625MB; mem (CPU total)=11427.09375MB
INFO:root:[  181] Training loss: 0.43744596, Validation loss: 0.42858334, Gradient norm: 6.45245217
INFO:root:At the start of the epoch: mem (CPU python)=8309.984375MB; mem (CPU total)=11480.35546875MB
INFO:root:[  182] Training loss: 0.43751623, Validation loss: 0.42966990, Gradient norm: 6.14239404
INFO:root:At the start of the epoch: mem (CPU python)=8331.26171875MB; mem (CPU total)=11498.15625MB
INFO:root:[  183] Training loss: 0.43756798, Validation loss: 0.42863155, Gradient norm: 6.29877654
INFO:root:At the start of the epoch: mem (CPU python)=8355.04296875MB; mem (CPU total)=11510.53515625MB
INFO:root:[  184] Training loss: 0.43752028, Validation loss: 0.42867478, Gradient norm: 6.40677502
INFO:root:At the start of the epoch: mem (CPU python)=8376.72265625MB; mem (CPU total)=11544.6796875MB
INFO:root:[  185] Training loss: 0.43817252, Validation loss: 0.42915254, Gradient norm: 6.71507857
INFO:root:At the start of the epoch: mem (CPU python)=8397.890625MB; mem (CPU total)=11544.59765625MB
INFO:root:[  186] Training loss: 0.43752841, Validation loss: 0.42876629, Gradient norm: 6.58330722
INFO:root:At the start of the epoch: mem (CPU python)=8419.0625MB; mem (CPU total)=11566.92578125MB
INFO:root:[  187] Training loss: 0.43744945, Validation loss: 0.42862340, Gradient norm: 6.17311126
INFO:root:At the start of the epoch: mem (CPU python)=8440.23046875MB; mem (CPU total)=11618.75MB
INFO:root:[  188] Training loss: 0.43777597, Validation loss: 0.42870207, Gradient norm: 6.84037168
INFO:root:At the start of the epoch: mem (CPU python)=8461.40625MB; mem (CPU total)=11605.28125MB
INFO:root:[  189] Training loss: 0.43724378, Validation loss: 0.42854053, Gradient norm: 6.64917418
INFO:root:At the start of the epoch: mem (CPU python)=8482.58984375MB; mem (CPU total)=11543.33203125MB
INFO:root:[  190] Training loss: 0.43704633, Validation loss: 0.42872446, Gradient norm: 6.44732543
INFO:root:At the start of the epoch: mem (CPU python)=8503.75MB; mem (CPU total)=11652.71484375MB
INFO:root:[  191] Training loss: 0.43788197, Validation loss: 0.42848459, Gradient norm: 6.27661555
INFO:root:At the start of the epoch: mem (CPU python)=8524.92578125MB; mem (CPU total)=11657.80078125MB
INFO:root:[  192] Training loss: 0.43714443, Validation loss: 0.42871618, Gradient norm: 6.98977296
INFO:root:At the start of the epoch: mem (CPU python)=8546.359375MB; mem (CPU total)=11669.07421875MB
INFO:root:[  193] Training loss: 0.43671419, Validation loss: 0.42864803, Gradient norm: 6.74647033
INFO:root:At the start of the epoch: mem (CPU python)=8567.640625MB; mem (CPU total)=11710.1171875MB
INFO:root:[  194] Training loss: 0.43726850, Validation loss: 0.42809800, Gradient norm: 6.92011042
INFO:root:At the start of the epoch: mem (CPU python)=8588.87109375MB; mem (CPU total)=11716.1875MB
INFO:root:[  195] Training loss: 0.43697454, Validation loss: 0.42824753, Gradient norm: 7.08368732
INFO:root:At the start of the epoch: mem (CPU python)=8610.27734375MB; mem (CPU total)=11763.48046875MB
INFO:root:[  196] Training loss: 0.43712378, Validation loss: 0.42874628, Gradient norm: 6.74844542
INFO:root:At the start of the epoch: mem (CPU python)=8631.7421875MB; mem (CPU total)=11647.2265625MB
INFO:root:[  197] Training loss: 0.43702121, Validation loss: 0.42825224, Gradient norm: 6.85072340
INFO:root:At the start of the epoch: mem (CPU python)=8653.01171875MB; mem (CPU total)=11810.52734375MB
INFO:root:[  198] Training loss: 0.43666284, Validation loss: 0.42819322, Gradient norm: 6.80139462
INFO:root:At the start of the epoch: mem (CPU python)=8674.453125MB; mem (CPU total)=11801.515625MB
INFO:root:[  199] Training loss: 0.43695671, Validation loss: 0.42808965, Gradient norm: 7.42533308
INFO:root:At the start of the epoch: mem (CPU python)=8696.54296875MB; mem (CPU total)=11831.234375MB
INFO:root:[  200] Training loss: 0.43662492, Validation loss: 0.42799916, Gradient norm: 7.41385090
INFO:root:At the start of the epoch: mem (CPU python)=8717.70703125MB; mem (CPU total)=11846.78515625MB
INFO:root:[  201] Training loss: 0.43681933, Validation loss: 0.42838540, Gradient norm: 7.47714916
INFO:root:At the start of the epoch: mem (CPU python)=8739.2578125MB; mem (CPU total)=11866.98828125MB
INFO:root:[  202] Training loss: 0.43740089, Validation loss: 0.42815896, Gradient norm: 7.07310261
INFO:root:At the start of the epoch: mem (CPU python)=8760.4296875MB; mem (CPU total)=11927.69921875MB
INFO:root:[  203] Training loss: 0.43751250, Validation loss: 0.42839097, Gradient norm: 7.43972348
INFO:root:At the start of the epoch: mem (CPU python)=8781.59375MB; mem (CPU total)=11923.359375MB
INFO:root:[  204] Training loss: 0.43652716, Validation loss: 0.42832617, Gradient norm: 7.34578409
INFO:root:At the start of the epoch: mem (CPU python)=8803.14453125MB; mem (CPU total)=11904.84765625MB
INFO:root:[  205] Training loss: 0.43672589, Validation loss: 0.42840947, Gradient norm: 7.44599508
INFO:root:At the start of the epoch: mem (CPU python)=8824.32421875MB; mem (CPU total)=11960.28515625MB
INFO:root:[  206] Training loss: 0.43751527, Validation loss: 0.42781536, Gradient norm: 7.32220644
INFO:root:At the start of the epoch: mem (CPU python)=8845.99609375MB; mem (CPU total)=11975.859375MB
INFO:root:[  207] Training loss: 0.43754693, Validation loss: 0.42816314, Gradient norm: 7.28271991
INFO:root:At the start of the epoch: mem (CPU python)=8867.40625MB; mem (CPU total)=12028.25390625MB
INFO:root:[  208] Training loss: 0.43733907, Validation loss: 0.42810665, Gradient norm: 6.85956810
INFO:root:At the start of the epoch: mem (CPU python)=8888.5859375MB; mem (CPU total)=12038.63671875MB
INFO:root:[  209] Training loss: 0.43734048, Validation loss: 0.42845227, Gradient norm: 7.17067024
INFO:root:At the start of the epoch: mem (CPU python)=8909.75MB; mem (CPU total)=12062.08984375MB
INFO:root:[  210] Training loss: 0.43691089, Validation loss: 0.42804337, Gradient norm: 7.34080713
INFO:root:At the start of the epoch: mem (CPU python)=8930.91796875MB; mem (CPU total)=12106.046875MB
INFO:root:[  211] Training loss: 0.43676732, Validation loss: 0.42813819, Gradient norm: 7.39499126
INFO:root:At the start of the epoch: mem (CPU python)=8952.1015625MB; mem (CPU total)=12091.953125MB
INFO:root:[  212] Training loss: 0.43706415, Validation loss: 0.42836663, Gradient norm: 7.44119153
INFO:root:At the start of the epoch: mem (CPU python)=8973.69921875MB; mem (CPU total)=12119.7578125MB
INFO:root:[  213] Training loss: 0.43698308, Validation loss: 0.42905683, Gradient norm: 7.69055557
INFO:root:At the start of the epoch: mem (CPU python)=8995.5625MB; mem (CPU total)=12145.2578125MB
INFO:root:[  214] Training loss: 0.43629908, Validation loss: 0.42743350, Gradient norm: 7.84047233
INFO:root:At the start of the epoch: mem (CPU python)=9016.734375MB; mem (CPU total)=12162.546875MB
INFO:root:[  215] Training loss: 0.43670229, Validation loss: 0.42857657, Gradient norm: 8.43622474
INFO:root:At the start of the epoch: mem (CPU python)=9037.90625MB; mem (CPU total)=12182.6171875MB
INFO:root:[  216] Training loss: 0.43698390, Validation loss: 0.42795017, Gradient norm: 7.63987239
INFO:root:At the start of the epoch: mem (CPU python)=9059.078125MB; mem (CPU total)=12206.47265625MB
INFO:root:[  217] Training loss: 0.43732634, Validation loss: 0.42744774, Gradient norm: 7.34001911
INFO:root:At the start of the epoch: mem (CPU python)=9081.0078125MB; mem (CPU total)=12222.515625MB
INFO:root:[  218] Training loss: 0.43793553, Validation loss: 0.42828852, Gradient norm: 7.36151671
INFO:root:At the start of the epoch: mem (CPU python)=9102.1796875MB; mem (CPU total)=12231.33984375MB
INFO:root:[  219] Training loss: 0.43658752, Validation loss: 0.42797572, Gradient norm: 8.21556970
INFO:root:At the start of the epoch: mem (CPU python)=9123.34765625MB; mem (CPU total)=12268.234375MB
INFO:root:[  220] Training loss: 0.43689261, Validation loss: 0.42893296, Gradient norm: 8.14107417
INFO:root:At the start of the epoch: mem (CPU python)=9144.515625MB; mem (CPU total)=12286.80859375MB
INFO:root:[  221] Training loss: 0.43661620, Validation loss: 0.42759924, Gradient norm: 8.00282793
INFO:root:At the start of the epoch: mem (CPU python)=9165.68359375MB; mem (CPU total)=12300.76171875MB
INFO:root:[  222] Training loss: 0.43615853, Validation loss: 0.42754961, Gradient norm: 8.06039806
INFO:root:At the start of the epoch: mem (CPU python)=9187.76953125MB; mem (CPU total)=12316.78125MB
INFO:root:[  223] Training loss: 0.43676763, Validation loss: 0.42746816, Gradient norm: 8.07887536
INFO:root:At the start of the epoch: mem (CPU python)=9209.15234375MB; mem (CPU total)=12355.96875MB
INFO:root:EP 223: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=9230.12109375MB; mem (CPU total)=12383.26953125MB
INFO:root:Training the model took 6986.689s.
INFO:root:Emptying the cuda cache took 0.049s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification deterministic
INFO:root:Evaluating the model on Validation data.
