INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=576.9296875MB; mem (CPU total)=1007.21484375MB
INFO:root:############### Starting experiment with config file darcy_flow/fno1.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'DarcyFlow', 'max_training_set_size': 10000, 'downscaling_factor': 2}
INFO:root:After loading the datasets: mem (CPU python)=1996.7578125MB; mem (CPU total)=1019.5859375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=1996.7578125MB; mem (CPU total)=1019.5859375MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 4194304
INFO:root:After setting up the model: mem (CPU python)=2203.68359375MB; mem (CPU total)=2392.234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2215.26953125MB; mem (CPU total)=2403.0625MB
INFO:root:[    1] Training loss: 0.38137492, Validation loss: 0.46872585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4462.3515625MB; mem (CPU total)=4193.37109375MB
INFO:root:[    2] Training loss: 0.16194141, Validation loss: 0.38276206, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4538.6640625MB; mem (CPU total)=4269.41796875MB
INFO:root:[    3] Training loss: 0.12753762, Validation loss: 0.33397896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4614.859375MB; mem (CPU total)=4345.953125MB
INFO:root:[    4] Training loss: 0.10977971, Validation loss: 0.30974328, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4695.0625MB; mem (CPU total)=4426.4140625MB
INFO:root:[    5] Training loss: 0.10447406, Validation loss: 0.28438453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4771.2734375MB; mem (CPU total)=4502.6875MB
INFO:root:[    6] Training loss: 0.09573652, Validation loss: 0.28320293, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4847.91796875MB; mem (CPU total)=4579.8359375MB
INFO:root:[    7] Training loss: 0.09596925, Validation loss: 0.25753953, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=4924.421875MB; mem (CPU total)=4656.65625MB
INFO:root:[    8] Training loss: 0.09064074, Validation loss: 0.26097614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5000.65625MB; mem (CPU total)=4732.9296875MB
INFO:root:[    9] Training loss: 0.08336603, Validation loss: 0.24872438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5077.5390625MB; mem (CPU total)=4810.12109375MB
INFO:root:[   10] Training loss: 0.08650271, Validation loss: 0.23237160, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5153.765625MB; mem (CPU total)=4886.65625MB
INFO:root:[   11] Training loss: 0.07823470, Validation loss: 0.23839665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5229.9765625MB; mem (CPU total)=4962.91015625MB
INFO:root:[   12] Training loss: 0.07836150, Validation loss: 0.22282679, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5306.1875MB; mem (CPU total)=5039.41796875MB
INFO:root:[   13] Training loss: 0.08011560, Validation loss: 0.22279645, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5382.421875MB; mem (CPU total)=5115.9140625MB
INFO:root:[   14] Training loss: 0.07351429, Validation loss: 0.21210300, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5458.6328125MB; mem (CPU total)=5192.19921875MB
INFO:root:[   15] Training loss: 0.07658992, Validation loss: 0.21331614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5534.8515625MB; mem (CPU total)=5268.97265625MB
INFO:root:[   16] Training loss: 0.07153569, Validation loss: 0.20771629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5611.05078125MB; mem (CPU total)=5345.1640625MB
INFO:root:[   17] Training loss: 0.06989030, Validation loss: 0.20967427, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5687.24609375MB; mem (CPU total)=5421.3359375MB
INFO:root:[   18] Training loss: 0.07100730, Validation loss: 0.21011658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5763.44921875MB; mem (CPU total)=5497.921875MB
INFO:root:[   19] Training loss: 0.06597299, Validation loss: 0.21277973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5839.64453125MB; mem (CPU total)=5574.1875MB
INFO:root:[   20] Training loss: 0.06577304, Validation loss: 0.20259705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5915.859375MB; mem (CPU total)=5650.39453125MB
INFO:root:[   21] Training loss: 0.06307199, Validation loss: 0.20984592, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=5992.0546875MB; mem (CPU total)=5726.75390625MB
INFO:root:[   22] Training loss: 0.06520480, Validation loss: 0.20137691, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6068.2578125MB; mem (CPU total)=5803.2421875MB
INFO:root:[   23] Training loss: 0.06042291, Validation loss: 0.19870414, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6144.46875MB; mem (CPU total)=5880.15625MB
INFO:root:[   24] Training loss: 0.06122610, Validation loss: 0.19820041, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6220.671875MB; mem (CPU total)=5956.39453125MB
INFO:root:[   25] Training loss: 0.05967893, Validation loss: 0.19641026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6296.87109375MB; mem (CPU total)=6033.03125MB
INFO:root:[   26] Training loss: 0.05806531, Validation loss: 0.19501806, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6373.06640625MB; mem (CPU total)=6109.015625MB
INFO:root:[   27] Training loss: 0.05712948, Validation loss: 0.19583923, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6449.26171875MB; mem (CPU total)=6185.27734375MB
INFO:root:[   28] Training loss: 0.05526781, Validation loss: 0.19613695, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6525.44921875MB; mem (CPU total)=6261.7890625MB
INFO:root:[   29] Training loss: 0.05727053, Validation loss: 0.19258617, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6601.64453125MB; mem (CPU total)=6337.80078125MB
INFO:root:[   30] Training loss: 0.05199134, Validation loss: 0.20167454, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6677.8359375MB; mem (CPU total)=6414.06640625MB
INFO:root:[   31] Training loss: 0.05447195, Validation loss: 0.19533514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6754.0234375MB; mem (CPU total)=6490.32421875MB
INFO:root:[   32] Training loss: 0.05408107, Validation loss: 0.19461028, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6830.21484375MB; mem (CPU total)=6566.81640625MB
INFO:root:[   33] Training loss: 0.05066013, Validation loss: 0.19602300, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6906.40234375MB; mem (CPU total)=6643.04296875MB
INFO:root:[   34] Training loss: 0.04825159, Validation loss: 0.19790261, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=6982.59765625MB; mem (CPU total)=6719.3046875MB
INFO:root:[   35] Training loss: 0.05011134, Validation loss: 0.19699924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7058.79296875MB; mem (CPU total)=6795.5625MB
INFO:root:[   36] Training loss: 0.04752521, Validation loss: 0.19256985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7134.98046875MB; mem (CPU total)=6877.609375MB
INFO:root:[   37] Training loss: 0.04796854, Validation loss: 0.19061823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7211.171875MB; mem (CPU total)=6953.8671875MB
INFO:root:[   38] Training loss: 0.04537207, Validation loss: 0.19458032, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7287.36328125MB; mem (CPU total)=7030.328125MB
INFO:root:[   39] Training loss: 0.04474030, Validation loss: 0.19071210, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7363.5546875MB; mem (CPU total)=7103.359375MB
INFO:root:[   40] Training loss: 0.04477153, Validation loss: 0.19055419, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7439.74609375MB; mem (CPU total)=7178.30859375MB
INFO:root:[   41] Training loss: 0.04230164, Validation loss: 0.19447170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7515.9375MB; mem (CPU total)=7254.34765625MB
INFO:root:[   42] Training loss: 0.04338079, Validation loss: 0.18830957, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7592.12890625MB; mem (CPU total)=7330.8515625MB
INFO:root:[   43] Training loss: 0.04392302, Validation loss: 0.19033145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7668.31640625MB; mem (CPU total)=7406.87109375MB
INFO:root:[   44] Training loss: 0.04352758, Validation loss: 0.18641840, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7744.51171875MB; mem (CPU total)=7483.21484375MB
INFO:root:[   45] Training loss: 0.04114591, Validation loss: 0.19173254, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7820.69921875MB; mem (CPU total)=7558.47265625MB
INFO:root:[   46] Training loss: 0.04448806, Validation loss: 0.18421520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7896.890625MB; mem (CPU total)=7635.25390625MB
INFO:root:[   47] Training loss: 0.04456339, Validation loss: 0.18559443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=7973.0859375MB; mem (CPU total)=7712.04296875MB
INFO:root:[   48] Training loss: 0.04206888, Validation loss: 0.18459628, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8049.27734375MB; mem (CPU total)=7788.546875MB
INFO:root:[   49] Training loss: 0.04174445, Validation loss: 0.18604595, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8125.46875MB; mem (CPU total)=7864.8046875MB
INFO:root:[   50] Training loss: 0.03866898, Validation loss: 0.18225262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8201.65625MB; mem (CPU total)=7941.09375MB
INFO:root:[   51] Training loss: 0.03937295, Validation loss: 0.18182693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8277.8515625MB; mem (CPU total)=8017.42578125MB
INFO:root:[   52] Training loss: 0.03955234, Validation loss: 0.18593350, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8354.04296875MB; mem (CPU total)=8093.62890625MB
INFO:root:[   53] Training loss: 0.03945249, Validation loss: 0.18470140, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8430.23828125MB; mem (CPU total)=8169.58203125MB
INFO:root:[   54] Training loss: 0.03736826, Validation loss: 0.17721656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8506.43359375MB; mem (CPU total)=8246.82421875MB
INFO:root:[   55] Training loss: 0.03588124, Validation loss: 0.17904662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8582.62890625MB; mem (CPU total)=8322.56640625MB
INFO:root:[   56] Training loss: 0.03640542, Validation loss: 0.17683974, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8658.828125MB; mem (CPU total)=8399.15625MB
INFO:root:[   57] Training loss: 0.03764229, Validation loss: 0.17765755, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8735.03515625MB; mem (CPU total)=8475.12109375MB
INFO:root:[   58] Training loss: 0.03669888, Validation loss: 0.17701331, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8811.23046875MB; mem (CPU total)=8551.8515625MB
INFO:root:[   59] Training loss: 0.03752722, Validation loss: 0.17395414, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8887.4296875MB; mem (CPU total)=8627.96484375MB
INFO:root:[   60] Training loss: 0.03578706, Validation loss: 0.17388401, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=8963.6171875MB; mem (CPU total)=8704.296875MB
INFO:root:[   61] Training loss: 0.03612694, Validation loss: 0.17859882, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9039.81640625MB; mem (CPU total)=8780.7265625MB
INFO:root:[   62] Training loss: 0.03847718, Validation loss: 0.17432045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9116.015625MB; mem (CPU total)=8857.28125MB
INFO:root:[   63] Training loss: 0.03452296, Validation loss: 0.17466770, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9192.21875MB; mem (CPU total)=8933.43359375MB
INFO:root:[   64] Training loss: 0.03383456, Validation loss: 0.17152396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9268.41015625MB; mem (CPU total)=9009.53515625MB
INFO:root:[   65] Training loss: 0.03416017, Validation loss: 0.17802245, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9344.6015625MB; mem (CPU total)=9085.9765625MB
INFO:root:[   66] Training loss: 0.03321966, Validation loss: 0.17388508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9420.796875MB; mem (CPU total)=9162.12890625MB
INFO:root:[   67] Training loss: 0.03446217, Validation loss: 0.17679554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9496.984375MB; mem (CPU total)=9238.3046875MB
INFO:root:[   68] Training loss: 0.03426944, Validation loss: 0.17249039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9573.18359375MB; mem (CPU total)=9314.48046875MB
INFO:root:[   69] Training loss: 0.03692849, Validation loss: 0.17380423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9649.3828125MB; mem (CPU total)=9391.02734375MB
INFO:root:[   70] Training loss: 0.03294954, Validation loss: 0.17042140, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9725.578125MB; mem (CPU total)=9467.4765625MB
INFO:root:[   71] Training loss: 0.03568779, Validation loss: 0.16392704, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9801.796875MB; mem (CPU total)=9543.73046875MB
INFO:root:[   72] Training loss: 0.03391881, Validation loss: 0.17013227, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9878.015625MB; mem (CPU total)=9620.02734375MB
INFO:root:[   73] Training loss: 0.03453702, Validation loss: 0.16860088, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=9954.22265625MB; mem (CPU total)=9696.421875MB
INFO:root:[   74] Training loss: 0.03342794, Validation loss: 0.17101611, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10030.4296875MB; mem (CPU total)=9772.4765625MB
INFO:root:[   75] Training loss: 0.03434718, Validation loss: 0.16668453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10106.62890625MB; mem (CPU total)=9848.734375MB
INFO:root:[   76] Training loss: 0.03352187, Validation loss: 0.16414587, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10182.8359375MB; mem (CPU total)=9925.06640625MB
INFO:root:[   77] Training loss: 0.03251694, Validation loss: 0.16527631, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10259.03125MB; mem (CPU total)=10001.671875MB
INFO:root:[   78] Training loss: 0.03087508, Validation loss: 0.16528168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10335.234375MB; mem (CPU total)=10078.09375MB
INFO:root:[   79] Training loss: 0.03187452, Validation loss: 0.16401960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10411.4296875MB; mem (CPU total)=10154.56640625MB
INFO:root:[   80] Training loss: 0.03267011, Validation loss: 0.16610390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=10487.62890625MB; mem (CPU total)=10230.69140625MB
INFO:root:EP 80: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=10563.8203125MB; mem (CPU total)=10307.08984375MB
INFO:root:Training the model took 3086.74s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.10092
INFO:root:EnergyScoreTrain: 0.05221
INFO:root:CRPSTrain: 0.04228
INFO:root:Gaussian NLLTrain: 1.60606
INFO:root:CoverageTrain: 0.71126
INFO:root:IntervalWidthTrain: 0.25971
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.18839
INFO:root:EnergyScoreValidation: 0.11703
INFO:root:CRPSValidation: 0.09586
INFO:root:Gaussian NLLValidation: 11.8516
INFO:root:CoverageValidation: 0.48091
INFO:root:IntervalWidthValidation: 0.26836
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.19233
INFO:root:EnergyScoreTest: 0.12076
INFO:root:CRPSTest: 0.0991
INFO:root:Gaussian NLLTest: 13.38153
INFO:root:CoverageTest: 0.44968
INFO:root:IntervalWidthTest: 0.2549
INFO:root:After validation: mem (CPU python)=11035.6953125MB; mem (CPU total)=10645.3046875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=11035.6953125MB; mem (CPU total)=10645.1875MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 308281344
INFO:root:After setting up the model: mem (CPU python)=11036.93359375MB; mem (CPU total)=10646.41796875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=11036.94140625MB; mem (CPU total)=10646.4140625MB
INFO:root:[    1] Training loss: 0.38585340, Validation loss: 0.42729493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11132.76171875MB; mem (CPU total)=10742.24609375MB
INFO:root:[    2] Training loss: 0.16081844, Validation loss: 0.33282900, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11208.95703125MB; mem (CPU total)=10817.58203125MB
INFO:root:[    3] Training loss: 0.12272123, Validation loss: 0.28011845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11285.1640625MB; mem (CPU total)=10894.42578125MB
INFO:root:[    4] Training loss: 0.11987254, Validation loss: 0.27794937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11361.3671875MB; mem (CPU total)=10970.7109375MB
INFO:root:[    5] Training loss: 0.10850818, Validation loss: 0.23667174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11437.57421875MB; mem (CPU total)=11047.16015625MB
INFO:root:[    6] Training loss: 0.10035029, Validation loss: 0.22877381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11513.78515625MB; mem (CPU total)=11122.9765625MB
INFO:root:[    7] Training loss: 0.09363024, Validation loss: 0.21750886, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11589.9921875MB; mem (CPU total)=11199.25MB
INFO:root:[    8] Training loss: 0.09239118, Validation loss: 0.19826816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11666.19921875MB; mem (CPU total)=11275.546875MB
INFO:root:[    9] Training loss: 0.08613263, Validation loss: 0.19903170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11742.40625MB; mem (CPU total)=11351.8125MB
INFO:root:[   10] Training loss: 0.08403131, Validation loss: 0.18718524, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11818.61328125MB; mem (CPU total)=11428.078125MB
INFO:root:[   11] Training loss: 0.08305466, Validation loss: 0.18792116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11894.83203125MB; mem (CPU total)=11504.09765625MB
INFO:root:[   12] Training loss: 0.08135861, Validation loss: 0.18164259, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=11971.0234375MB; mem (CPU total)=11580.6171875MB
INFO:root:[   13] Training loss: 0.07898132, Validation loss: 0.18284683, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12047.21484375MB; mem (CPU total)=11656.8125MB
INFO:root:[   14] Training loss: 0.07639007, Validation loss: 0.17367215, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12123.40234375MB; mem (CPU total)=11733.3515625MB
INFO:root:[   15] Training loss: 0.07803158, Validation loss: 0.17113943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12199.59375MB; mem (CPU total)=11809.6875MB
INFO:root:[   16] Training loss: 0.07105460, Validation loss: 0.16476757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12275.79296875MB; mem (CPU total)=11886.29296875MB
INFO:root:[   17] Training loss: 0.07738441, Validation loss: 0.16373849, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12351.98046875MB; mem (CPU total)=11962.56640625MB
INFO:root:[   18] Training loss: 0.07414930, Validation loss: 0.16017194, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12428.171875MB; mem (CPU total)=12039.40625MB
INFO:root:[   19] Training loss: 0.06969463, Validation loss: 0.17199315, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12504.36328125MB; mem (CPU total)=12115.41796875MB
INFO:root:[   20] Training loss: 0.07104872, Validation loss: 0.16090961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12580.5546875MB; mem (CPU total)=12191.9375MB
INFO:root:[   21] Training loss: 0.06850194, Validation loss: 0.16916573, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12656.7421875MB; mem (CPU total)=12268.453125MB
INFO:root:[   22] Training loss: 0.06747644, Validation loss: 0.15958539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12732.93359375MB; mem (CPU total)=12344.74609375MB
INFO:root:[   23] Training loss: 0.06387711, Validation loss: 0.15279730, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12809.125MB; mem (CPU total)=12421.01953125MB
INFO:root:[   24] Training loss: 0.06216663, Validation loss: 0.15933023, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12885.3125MB; mem (CPU total)=12497.2421875MB
INFO:root:[   25] Training loss: 0.06238430, Validation loss: 0.15391206, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12961.5078125MB; mem (CPU total)=12574.0078125MB
INFO:root:[   26] Training loss: 0.06027444, Validation loss: 0.14895085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13037.6953125MB; mem (CPU total)=12649.97265625MB
INFO:root:[   27] Training loss: 0.06141424, Validation loss: 0.15073809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13113.890625MB; mem (CPU total)=12726.234375MB
INFO:root:[   28] Training loss: 0.05814229, Validation loss: 0.15222382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13190.08203125MB; mem (CPU total)=12802.50390625MB
INFO:root:[   29] Training loss: 0.05991960, Validation loss: 0.14988503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13266.26953125MB; mem (CPU total)=12878.73828125MB
INFO:root:[   30] Training loss: 0.05804601, Validation loss: 0.15098738, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13342.46484375MB; mem (CPU total)=12955.01171875MB
INFO:root:[   31] Training loss: 0.05594788, Validation loss: 0.14924559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13418.65234375MB; mem (CPU total)=13031.2734375MB
INFO:root:[   32] Training loss: 0.05534992, Validation loss: 0.14755314, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13494.84765625MB; mem (CPU total)=13108.09375MB
INFO:root:[   33] Training loss: 0.05360165, Validation loss: 0.14299118, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13571.03515625MB; mem (CPU total)=13184.47265625MB
INFO:root:[   34] Training loss: 0.05191191, Validation loss: 0.14963027, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13647.2265625MB; mem (CPU total)=13260.35546875MB
INFO:root:[   35] Training loss: 0.05372496, Validation loss: 0.15531564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13723.41796875MB; mem (CPU total)=13336.86328125MB
INFO:root:[   36] Training loss: 0.05524372, Validation loss: 0.14430526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13799.60546875MB; mem (CPU total)=13412.8828125MB
INFO:root:[   37] Training loss: 0.05326210, Validation loss: 0.13845815, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13875.80078125MB; mem (CPU total)=13489.02734375MB
INFO:root:[   38] Training loss: 0.04964459, Validation loss: 0.14270150, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13951.98828125MB; mem (CPU total)=13565.08203125MB
INFO:root:[   39] Training loss: 0.05185060, Validation loss: 0.14097895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14028.1796875MB; mem (CPU total)=13641.84375MB
INFO:root:[   40] Training loss: 0.05221421, Validation loss: 0.14518338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14104.37109375MB; mem (CPU total)=13718.1171875MB
INFO:root:[   41] Training loss: 0.04738865, Validation loss: 0.14460445, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14180.5625MB; mem (CPU total)=13794.3828125MB
INFO:root:[   42] Training loss: 0.05100848, Validation loss: 0.13605452, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14256.75390625MB; mem (CPU total)=13870.64453125MB
INFO:root:[   43] Training loss: 0.04828357, Validation loss: 0.14360410, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14332.94140625MB; mem (CPU total)=13946.17578125MB
INFO:root:[   44] Training loss: 0.04750089, Validation loss: 0.13994327, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14409.1328125MB; mem (CPU total)=14022.58203125MB
INFO:root:[   45] Training loss: 0.04612988, Validation loss: 0.14071792, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14485.328125MB; mem (CPU total)=14099.34375MB
INFO:root:[   46] Training loss: 0.04558999, Validation loss: 0.13859433, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14561.51953125MB; mem (CPU total)=14175.38671875MB
INFO:root:[   47] Training loss: 0.04671093, Validation loss: 0.13783623, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14637.7109375MB; mem (CPU total)=14251.90234375MB
INFO:root:[   48] Training loss: 0.04703685, Validation loss: 0.13714096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14713.8984375MB; mem (CPU total)=14327.92578125MB
INFO:root:[   49] Training loss: 0.04512355, Validation loss: 0.13917517, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14790.09375MB; mem (CPU total)=14404.375MB
INFO:root:[   50] Training loss: 0.04586034, Validation loss: 0.13634798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14866.28515625MB; mem (CPU total)=14480.89453125MB
INFO:root:[   51] Training loss: 0.04482545, Validation loss: 0.13838685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14942.47265625MB; mem (CPU total)=14556.91796875MB
INFO:root:[   52] Training loss: 0.04350220, Validation loss: 0.13698906, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15018.6640625MB; mem (CPU total)=14633.6796875MB
INFO:root:[   53] Training loss: 0.04369395, Validation loss: 0.13494969, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15094.85546875MB; mem (CPU total)=14710.0390625MB
INFO:root:[   54] Training loss: 0.04412965, Validation loss: 0.13219613, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15171.05078125MB; mem (CPU total)=14786.5546875MB
INFO:root:[   55] Training loss: 0.04194577, Validation loss: 0.13505720, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15247.23828125MB; mem (CPU total)=14862.57421875MB
INFO:root:[   56] Training loss: 0.04340145, Validation loss: 0.13324102, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15323.4296875MB; mem (CPU total)=14939.12109375MB
INFO:root:[   57] Training loss: 0.04077481, Validation loss: 0.13219598, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15399.625MB; mem (CPU total)=15015.484375MB
INFO:root:[   58] Training loss: 0.04097632, Validation loss: 0.13212484, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15475.8125MB; mem (CPU total)=15091.9140625MB
INFO:root:[   59] Training loss: 0.04161858, Validation loss: 0.13349038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15552.0078125MB; mem (CPU total)=15168.2578125MB
INFO:root:[   60] Training loss: 0.04143907, Validation loss: 0.12900075, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15628.1953125MB; mem (CPU total)=15244.73046875MB
INFO:root:[   61] Training loss: 0.04271977, Validation loss: 0.13416467, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15704.38671875MB; mem (CPU total)=15320.56640625MB
INFO:root:[   62] Training loss: 0.04090434, Validation loss: 0.12976093, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15780.58203125MB; mem (CPU total)=15397.0859375MB
INFO:root:[   63] Training loss: 0.04030366, Validation loss: 0.12895749, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15856.76953125MB; mem (CPU total)=15473.61328125MB
INFO:root:[   64] Training loss: 0.04133613, Validation loss: 0.12714919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15932.96484375MB; mem (CPU total)=15549.609375MB
INFO:root:[   65] Training loss: 0.04074034, Validation loss: 0.13222300, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16009.1484375MB; mem (CPU total)=15626.01171875MB
INFO:root:[   66] Training loss: 0.03924802, Validation loss: 0.12717719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16085.33984375MB; mem (CPU total)=15702.26953125MB
INFO:root:[   67] Training loss: 0.04155322, Validation loss: 0.13021985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16161.53125MB; mem (CPU total)=15778.7578125MB
INFO:root:[   68] Training loss: 0.04036757, Validation loss: 0.12614609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16237.71875MB; mem (CPU total)=15854.8515625MB
INFO:root:[   69] Training loss: 0.03918471, Validation loss: 0.13037346, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16313.91015625MB; mem (CPU total)=15931.109375MB
INFO:root:[   70] Training loss: 0.03926293, Validation loss: 0.12492965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16390.1015625MB; mem (CPU total)=16007.73046875MB
INFO:root:[   71] Training loss: 0.03907197, Validation loss: 0.12164323, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16466.29296875MB; mem (CPU total)=16084.08203125MB
INFO:root:[   72] Training loss: 0.03833555, Validation loss: 0.12816582, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16542.48046875MB; mem (CPU total)=16160.3515625MB
INFO:root:[   73] Training loss: 0.03977760, Validation loss: 0.12721857, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16618.671875MB; mem (CPU total)=16236.83984375MB
INFO:root:[   74] Training loss: 0.03813264, Validation loss: 0.12857677, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16694.8671875MB; mem (CPU total)=16313.09765625MB
INFO:root:[   75] Training loss: 0.03742560, Validation loss: 0.12757737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16771.0546875MB; mem (CPU total)=16389.34765625MB
INFO:root:[   76] Training loss: 0.03801164, Validation loss: 0.12550510, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16847.24609375MB; mem (CPU total)=16465.59375MB
INFO:root:[   77] Training loss: 0.03711085, Validation loss: 0.12465445, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16923.43359375MB; mem (CPU total)=16541.7578125MB
INFO:root:[   78] Training loss: 0.03722991, Validation loss: 0.12390193, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16999.62890625MB; mem (CPU total)=16618.40625MB
INFO:root:[   79] Training loss: 0.03758305, Validation loss: 0.12411682, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17075.8203125MB; mem (CPU total)=16694.65625MB
INFO:root:[   80] Training loss: 0.03778227, Validation loss: 0.12292011, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17152.0078125MB; mem (CPU total)=16770.91015625MB
INFO:root:EP 80: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=17228.12890625MB; mem (CPU total)=16846.67578125MB
INFO:root:Training the model took 3535.923s.
INFO:root:Emptying the cuda cache took 0.024s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09492
INFO:root:EnergyScoreTrain: 0.04926
INFO:root:CRPSTrain: 0.04002
INFO:root:Gaussian NLLTrain: 1.71946
INFO:root:CoverageTrain: 0.70502
INFO:root:IntervalWidthTrain: 0.24877
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.149
INFO:root:EnergyScoreValidation: 0.08788
INFO:root:CRPSValidation: 0.07233
INFO:root:Gaussian NLLValidation: 8.00389
INFO:root:CoverageValidation: 0.54918
INFO:root:IntervalWidthValidation: 0.25313
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.15469
INFO:root:EnergyScoreTest: 0.09367
INFO:root:CRPSTest: 0.07736
INFO:root:Gaussian NLLTest: 7.91811
INFO:root:CoverageTest: 0.50846
INFO:root:IntervalWidthTest: 0.23778
INFO:root:After validation: mem (CPU python)=17374.74609375MB; mem (CPU total)=16993.234375MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=17374.74609375MB; mem (CPU total)=16993.6953125MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 304087040
INFO:root:After setting up the model: mem (CPU python)=17376.16015625MB; mem (CPU total)=16995.171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=17376.16015625MB; mem (CPU total)=16995.1640625MB
INFO:root:[    1] Training loss: 0.38692180, Validation loss: 0.37560100, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17452.61328125MB; mem (CPU total)=17071.28125MB
INFO:root:[    2] Training loss: 0.16600751, Validation loss: 0.28864608, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17528.8046875MB; mem (CPU total)=17147.1015625MB
INFO:root:[    3] Training loss: 0.13793460, Validation loss: 0.25123933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17605.01171875MB; mem (CPU total)=17223.37890625MB
INFO:root:[    4] Training loss: 0.11688270, Validation loss: 0.23768190, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17681.22265625MB; mem (CPU total)=17299.44140625MB
INFO:root:[    5] Training loss: 0.11057443, Validation loss: 0.20541154, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17757.42578125MB; mem (CPU total)=17375.96875MB
INFO:root:[    6] Training loss: 0.10091335, Validation loss: 0.20440334, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17833.6328125MB; mem (CPU total)=17452.50390625MB
INFO:root:[    7] Training loss: 0.09579383, Validation loss: 0.19091248, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17909.8359375MB; mem (CPU total)=17529.02734375MB
INFO:root:[    8] Training loss: 0.09750072, Validation loss: 0.17792579, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17986.046875MB; mem (CPU total)=17605.03125MB
INFO:root:[    9] Training loss: 0.09502279, Validation loss: 0.17170543, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18062.25MB; mem (CPU total)=17681.21875MB
INFO:root:[   10] Training loss: 0.09013180, Validation loss: 0.16382676, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18138.45703125MB; mem (CPU total)=17757.5MB
INFO:root:[   11] Training loss: 0.08608877, Validation loss: 0.16315892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18214.6484375MB; mem (CPU total)=17833.77734375MB
INFO:root:[   12] Training loss: 0.08198382, Validation loss: 0.15701883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18290.8359375MB; mem (CPU total)=17910.08984375MB
INFO:root:[   13] Training loss: 0.08131693, Validation loss: 0.15594339, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18367.02734375MB; mem (CPU total)=17986.8203125MB
INFO:root:[   14] Training loss: 0.07971849, Validation loss: 0.14995905, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18443.21875MB; mem (CPU total)=18063.3359375MB
INFO:root:[   15] Training loss: 0.07865731, Validation loss: 0.15490037, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18519.41015625MB; mem (CPU total)=18139.34375MB
INFO:root:[   16] Training loss: 0.07541279, Validation loss: 0.14204799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18595.6015625MB; mem (CPU total)=18215.90234375MB
INFO:root:[   17] Training loss: 0.07614867, Validation loss: 0.14359717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18671.79296875MB; mem (CPU total)=18292.15234375MB
INFO:root:[   18] Training loss: 0.07446951, Validation loss: 0.13991425, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18747.984375MB; mem (CPU total)=18368.7421875MB
INFO:root:[   19] Training loss: 0.07217568, Validation loss: 0.15308868, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18824.18359375MB; mem (CPU total)=18445.05859375MB
INFO:root:[   20] Training loss: 0.07728860, Validation loss: 0.13972113, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18900.3828125MB; mem (CPU total)=18521.41796875MB
INFO:root:[   21] Training loss: 0.07014650, Validation loss: 0.13870857, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18976.578125MB; mem (CPU total)=18597.703125MB
INFO:root:[   22] Training loss: 0.07384488, Validation loss: 0.13935862, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19052.765625MB; mem (CPU total)=18673.8984375MB
INFO:root:[   23] Training loss: 0.06844513, Validation loss: 0.13334321, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19128.95703125MB; mem (CPU total)=18750.890625MB
INFO:root:[   24] Training loss: 0.06616395, Validation loss: 0.13341924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19205.14453125MB; mem (CPU total)=18826.92578125MB
INFO:root:[   25] Training loss: 0.06426834, Validation loss: 0.12932024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19281.33984375MB; mem (CPU total)=18902.94921875MB
INFO:root:[   26] Training loss: 0.06527207, Validation loss: 0.13251704, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19357.52734375MB; mem (CPU total)=18978.63671875MB
INFO:root:[   27] Training loss: 0.06258189, Validation loss: 0.12949964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19433.71875MB; mem (CPU total)=19054.88671875MB
INFO:root:[   28] Training loss: 0.06122949, Validation loss: 0.13829654, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19509.91015625MB; mem (CPU total)=19131.125MB
INFO:root:[   29] Training loss: 0.06233910, Validation loss: 0.12127395, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19586.09765625MB; mem (CPU total)=19207.234375MB
INFO:root:[   30] Training loss: 0.06349379, Validation loss: 0.13160671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19662.29296875MB; mem (CPU total)=19283.484375MB
INFO:root:[   31] Training loss: 0.06175410, Validation loss: 0.13377456, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19738.48046875MB; mem (CPU total)=19359.94140625MB
INFO:root:[   32] Training loss: 0.06021080, Validation loss: 0.12951058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19814.671875MB; mem (CPU total)=19436.1796875MB
INFO:root:[   33] Training loss: 0.05724008, Validation loss: 0.12505149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19890.86328125MB; mem (CPU total)=19512.4296875MB
INFO:root:[   34] Training loss: 0.05564133, Validation loss: 0.12544860, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19967.0546875MB; mem (CPU total)=19588.9140625MB
INFO:root:[   35] Training loss: 0.05946239, Validation loss: 0.12755871, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20043.24609375MB; mem (CPU total)=19665.08984375MB
INFO:root:[   36] Training loss: 0.05554095, Validation loss: 0.12558731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20119.4375MB; mem (CPU total)=19741.60546875MB
INFO:root:[   37] Training loss: 0.05617786, Validation loss: 0.12110366, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20195.62890625MB; mem (CPU total)=19817.4140625MB
INFO:root:[   38] Training loss: 0.05407518, Validation loss: 0.12175174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20271.82421875MB; mem (CPU total)=19893.65234375MB
INFO:root:[   39] Training loss: 0.05344968, Validation loss: 0.12296554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20348.01171875MB; mem (CPU total)=19970.171875MB
INFO:root:[   40] Training loss: 0.05508249, Validation loss: 0.12251160, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20424.203125MB; mem (CPU total)=20046.4140625MB
INFO:root:[   41] Training loss: 0.05330187, Validation loss: 0.12982252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20500.390625MB; mem (CPU total)=20122.6953125MB
INFO:root:[   42] Training loss: 0.05125526, Validation loss: 0.11949317, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20576.5859375MB; mem (CPU total)=20199.1796875MB
INFO:root:[   43] Training loss: 0.05162650, Validation loss: 0.12746030, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20652.7734375MB; mem (CPU total)=20275.16796875MB
INFO:root:[   44] Training loss: 0.05065096, Validation loss: 0.12355703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20728.96484375MB; mem (CPU total)=20351.65234375MB
INFO:root:[   45] Training loss: 0.05129875, Validation loss: 0.12176003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20805.15625MB; mem (CPU total)=20428.16796875MB
INFO:root:[   46] Training loss: 0.05041968, Validation loss: 0.12362858, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20881.34765625MB; mem (CPU total)=20504.6640625MB
INFO:root:[   47] Training loss: 0.05173569, Validation loss: 0.12579521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20957.54296875MB; mem (CPU total)=20581.15234375MB
INFO:root:[   48] Training loss: 0.04938232, Validation loss: 0.12031278, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21033.73046875MB; mem (CPU total)=20657.3125MB
INFO:root:[   49] Training loss: 0.04892466, Validation loss: 0.12121842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21109.921875MB; mem (CPU total)=20733.80078125MB
INFO:root:[   50] Training loss: 0.04796731, Validation loss: 0.12289437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21186.1171875MB; mem (CPU total)=20810.06640625MB
INFO:root:[   51] Training loss: 0.04718314, Validation loss: 0.11743433, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21262.3046875MB; mem (CPU total)=20886.671875MB
INFO:root:[   52] Training loss: 0.04691542, Validation loss: 0.11983615, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21338.49609375MB; mem (CPU total)=20962.69921875MB
INFO:root:[   53] Training loss: 0.04759545, Validation loss: 0.11632020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21414.68359375MB; mem (CPU total)=21039.1875MB
INFO:root:[   54] Training loss: 0.04605176, Validation loss: 0.11471646, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21490.87890625MB; mem (CPU total)=21115.4296875MB
INFO:root:[   55] Training loss: 0.04744137, Validation loss: 0.11966610, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21567.07421875MB; mem (CPU total)=21191.6640625MB
INFO:root:[   56] Training loss: 0.04643690, Validation loss: 0.11461079, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21643.26171875MB; mem (CPU total)=21267.9140625MB
INFO:root:[   57] Training loss: 0.04445644, Validation loss: 0.11815060, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21719.453125MB; mem (CPU total)=21343.875MB
INFO:root:[   58] Training loss: 0.04588682, Validation loss: 0.11519577, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21795.640625MB; mem (CPU total)=21420.36328125MB
INFO:root:[   59] Training loss: 0.04421270, Validation loss: 0.11752518, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21871.8359375MB; mem (CPU total)=21496.83984375MB
INFO:root:[   60] Training loss: 0.04503973, Validation loss: 0.11533860, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21948.0234375MB; mem (CPU total)=21572.8359375MB
INFO:root:[   61] Training loss: 0.04503843, Validation loss: 0.11964173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22024.21484375MB; mem (CPU total)=21649.55859375MB
INFO:root:[   62] Training loss: 0.04440283, Validation loss: 0.11449818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22100.40234375MB; mem (CPU total)=21725.77734375MB
INFO:root:[   63] Training loss: 0.04377575, Validation loss: 0.11285243, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22176.59375MB; mem (CPU total)=21802.3046875MB
INFO:root:[   64] Training loss: 0.04429481, Validation loss: 0.11283256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22252.7890625MB; mem (CPU total)=21878.60546875MB
INFO:root:[   65] Training loss: 0.04286929, Validation loss: 0.11940275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22328.97265625MB; mem (CPU total)=21954.87890625MB
INFO:root:[   66] Training loss: 0.04231407, Validation loss: 0.11277973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22405.91015625MB; mem (CPU total)=22032.765625MB
INFO:root:[   67] Training loss: 0.04376475, Validation loss: 0.11730853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22481.35546875MB; mem (CPU total)=22107.6484375MB
INFO:root:[   68] Training loss: 0.04259816, Validation loss: 0.11310403, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22557.546875MB; mem (CPU total)=22183.92578125MB
INFO:root:[   69] Training loss: 0.04260468, Validation loss: 0.11645461, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22633.73828125MB; mem (CPU total)=22260.43359375MB
INFO:root:[   70] Training loss: 0.04226002, Validation loss: 0.11307353, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22709.92578125MB; mem (CPU total)=22336.72265625MB
INFO:root:[   71] Training loss: 0.04150918, Validation loss: 0.10722580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22786.12109375MB; mem (CPU total)=22413.03515625MB
INFO:root:[   72] Training loss: 0.04207211, Validation loss: 0.11507711, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22862.3125MB; mem (CPU total)=22489.26953125MB
INFO:root:[   73] Training loss: 0.04273530, Validation loss: 0.11412589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22938.5MB; mem (CPU total)=22565.5390625MB
INFO:root:[   74] Training loss: 0.04088707, Validation loss: 0.11701226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23014.69140625MB; mem (CPU total)=22642.03125MB
INFO:root:[   75] Training loss: 0.04189733, Validation loss: 0.11205737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23090.8828125MB; mem (CPU total)=22721.08984375MB
INFO:root:[   76] Training loss: 0.04313548, Validation loss: 0.11031556, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23167.07421875MB; mem (CPU total)=22797.359375MB
INFO:root:[   77] Training loss: 0.04158424, Validation loss: 0.11291956, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23243.26171875MB; mem (CPU total)=22872.80859375MB
INFO:root:[   78] Training loss: 0.03989056, Validation loss: 0.11096942, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23319.453125MB; mem (CPU total)=22949.3203125MB
INFO:root:[   79] Training loss: 0.04207150, Validation loss: 0.11824670, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23395.6484375MB; mem (CPU total)=23025.58203125MB
INFO:root:[   80] Training loss: 0.04249968, Validation loss: 0.10991672, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23471.8359375MB; mem (CPU total)=23101.453125MB
INFO:root:EP 80: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=23548.02734375MB; mem (CPU total)=23178.23828125MB
INFO:root:Training the model took 4195.548s.
INFO:root:Emptying the cuda cache took 0.026s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09433
INFO:root:EnergyScoreTrain: 0.04877
INFO:root:CRPSTrain: 0.03956
INFO:root:Gaussian NLLTrain: 2.10853
INFO:root:CoverageTrain: 0.70329
INFO:root:IntervalWidthTrain: 0.24501
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.13786
INFO:root:EnergyScoreValidation: 0.07877
INFO:root:CRPSValidation: 0.06449
INFO:root:Gaussian NLLValidation: 5.8294
INFO:root:CoverageValidation: 0.56946
INFO:root:IntervalWidthValidation: 0.25085
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.14069
INFO:root:EnergyScoreTest: 0.08249
INFO:root:CRPSTest: 0.06783
INFO:root:Gaussian NLLTest: 7.86529
INFO:root:CoverageTest: 0.53988
INFO:root:IntervalWidthTest: 0.2331
INFO:root:After validation: mem (CPU python)=23694.4765625MB; mem (CPU total)=23323.578125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=23694.4765625MB; mem (CPU total)=23323.5625MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 304087040
INFO:root:After setting up the model: mem (CPU python)=23695.87109375MB; mem (CPU total)=23324.79296875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=23695.87109375MB; mem (CPU total)=23325.015625MB
INFO:root:[    1] Training loss: 0.38424999, Validation loss: 0.33226590, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23772.41796875MB; mem (CPU total)=23401.77734375MB
INFO:root:[    2] Training loss: 0.17087661, Validation loss: 0.25712053, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23848.60546875MB; mem (CPU total)=23478.296875MB
INFO:root:[    3] Training loss: 0.13526164, Validation loss: 0.21939362, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23924.8125MB; mem (CPU total)=23554.32421875MB
INFO:root:[    4] Training loss: 0.12185373, Validation loss: 0.20076719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24001.01953125MB; mem (CPU total)=23630.58984375MB
INFO:root:[    5] Training loss: 0.11299762, Validation loss: 0.17989020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24077.2265625MB; mem (CPU total)=23706.87109375MB
INFO:root:[    6] Training loss: 0.10680905, Validation loss: 0.17717461, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24153.43359375MB; mem (CPU total)=23783.1875MB
INFO:root:[    7] Training loss: 0.10139565, Validation loss: 0.17033544, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24229.640625MB; mem (CPU total)=23859.9921875MB
INFO:root:[    8] Training loss: 0.10160658, Validation loss: 0.15368334, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24305.84765625MB; mem (CPU total)=23936.2734375MB
INFO:root:[    9] Training loss: 0.09482025, Validation loss: 0.15529156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24382.0390625MB; mem (CPU total)=24012.26953125MB
INFO:root:[   10] Training loss: 0.09174772, Validation loss: 0.14944310, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24458.234375MB; mem (CPU total)=24088.4453125MB
INFO:root:[   11] Training loss: 0.08870599, Validation loss: 0.15894836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24534.421875MB; mem (CPU total)=24164.6953125MB
INFO:root:[   12] Training loss: 0.08835739, Validation loss: 0.15421294, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24610.61328125MB; mem (CPU total)=24240.875MB
INFO:root:[   13] Training loss: 0.08995805, Validation loss: 0.14054629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24686.8046875MB; mem (CPU total)=24317.8828125MB
INFO:root:[   14] Training loss: 0.08512615, Validation loss: 0.13703751, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24762.99609375MB; mem (CPU total)=24393.76171875MB
INFO:root:[   15] Training loss: 0.08491045, Validation loss: 0.13391511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24839.1875MB; mem (CPU total)=24470.0MB
INFO:root:[   16] Training loss: 0.08141082, Validation loss: 0.12962300, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24915.375MB; mem (CPU total)=24546.1796875MB
INFO:root:[   17] Training loss: 0.08156577, Validation loss: 0.12933681, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24991.56640625MB; mem (CPU total)=24622.0234375MB
INFO:root:[   18] Training loss: 0.07845929, Validation loss: 0.12635147, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25067.7578125MB; mem (CPU total)=24698.51171875MB
INFO:root:[   19] Training loss: 0.07769815, Validation loss: 0.12761323, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25143.94921875MB; mem (CPU total)=24774.515625MB
INFO:root:[   20] Training loss: 0.07578244, Validation loss: 0.12425990, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25220.140625MB; mem (CPU total)=24851.27734375MB
INFO:root:[   21] Training loss: 0.07471096, Validation loss: 0.12478254, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25296.328125MB; mem (CPU total)=24927.48828125MB
INFO:root:[   22] Training loss: 0.07561384, Validation loss: 0.12597789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25372.5234375MB; mem (CPU total)=25003.73828125MB
INFO:root:[   23] Training loss: 0.07310776, Validation loss: 0.11924095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25448.7109375MB; mem (CPU total)=25080.59375MB
INFO:root:[   24] Training loss: 0.07454526, Validation loss: 0.12258024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25524.90234375MB; mem (CPU total)=25156.6328125MB
INFO:root:[   25] Training loss: 0.06830094, Validation loss: 0.11564880, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25601.09375MB; mem (CPU total)=25233.4765625MB
INFO:root:[   26] Training loss: 0.06951896, Validation loss: 0.11866710, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25677.28515625MB; mem (CPU total)=25309.47265625MB
INFO:root:[   27] Training loss: 0.06975476, Validation loss: 0.11941645, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25753.4765625MB; mem (CPU total)=25385.95703125MB
INFO:root:[   28] Training loss: 0.06860099, Validation loss: 0.12539526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25829.6640625MB; mem (CPU total)=25461.95703125MB
INFO:root:[   29] Training loss: 0.06744780, Validation loss: 0.11245964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25905.859375MB; mem (CPU total)=25538.23828125MB
INFO:root:[   30] Training loss: 0.06722556, Validation loss: 0.12314338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25982.05078125MB; mem (CPU total)=25614.16796875MB
INFO:root:[   31] Training loss: 0.06704907, Validation loss: 0.11589514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26058.23828125MB; mem (CPU total)=25690.39453125MB
INFO:root:[   32] Training loss: 0.06377736, Validation loss: 0.11845182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26134.4296875MB; mem (CPU total)=25766.8828125MB
INFO:root:[   33] Training loss: 0.06223444, Validation loss: 0.11428616, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26210.62109375MB; mem (CPU total)=25843.359375MB
INFO:root:[   34] Training loss: 0.06010270, Validation loss: 0.11935811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26286.8125MB; mem (CPU total)=25919.75390625MB
INFO:root:[   35] Training loss: 0.06440499, Validation loss: 0.11890291, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26363.0MB; mem (CPU total)=25996.1328125MB
INFO:root:[   36] Training loss: 0.05961216, Validation loss: 0.11429112, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26439.19140625MB; mem (CPU total)=26072.38671875MB
INFO:root:[   37] Training loss: 0.06061306, Validation loss: 0.11633685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26515.38671875MB; mem (CPU total)=26148.65625MB
INFO:root:[   38] Training loss: 0.05854554, Validation loss: 0.11359583, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26591.57421875MB; mem (CPU total)=26224.9375MB
INFO:root:[   39] Training loss: 0.05706459, Validation loss: 0.11288805, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26667.765625MB; mem (CPU total)=26301.703125MB
INFO:root:[   40] Training loss: 0.05845994, Validation loss: 0.11425581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26743.95703125MB; mem (CPU total)=26378.296875MB
INFO:root:[   41] Training loss: 0.05714112, Validation loss: 0.11819048, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26820.1484375MB; mem (CPU total)=26454.8046875MB
INFO:root:[   42] Training loss: 0.05704853, Validation loss: 0.11408121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26896.34765625MB; mem (CPU total)=26531.3125MB
INFO:root:[   43] Training loss: 0.05666576, Validation loss: 0.11460977, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26972.53515625MB; mem (CPU total)=26607.8359375MB
INFO:root:[   44] Training loss: 0.05691762, Validation loss: 0.11893753, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27048.73046875MB; mem (CPU total)=26684.375MB
INFO:root:[   45] Training loss: 0.05594335, Validation loss: 0.12022631, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27124.91796875MB; mem (CPU total)=26760.37109375MB
INFO:root:[   46] Training loss: 0.05663470, Validation loss: 0.11279558, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27201.109375MB; mem (CPU total)=26836.61328125MB
INFO:root:[   47] Training loss: 0.05424475, Validation loss: 0.11865475, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27277.3046875MB; mem (CPU total)=26912.85546875MB
INFO:root:[   48] Training loss: 0.05401371, Validation loss: 0.11146154, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27353.4921875MB; mem (CPU total)=26988.97265625MB
INFO:root:[   49] Training loss: 0.05403729, Validation loss: 0.11110969, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27429.6796875MB; mem (CPU total)=27065.30859375MB
INFO:root:[   50] Training loss: 0.05234128, Validation loss: 0.11020789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27505.87109375MB; mem (CPU total)=27141.59765625MB
INFO:root:[   51] Training loss: 0.05276552, Validation loss: 0.11215812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27582.0625MB; mem (CPU total)=27217.83984375MB
INFO:root:[   52] Training loss: 0.05244646, Validation loss: 0.11259156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27658.25MB; mem (CPU total)=27294.07421875MB
INFO:root:[   53] Training loss: 0.05296104, Validation loss: 0.10767295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27734.44140625MB; mem (CPU total)=27373.7421875MB
INFO:root:[   54] Training loss: 0.05057590, Validation loss: 0.10779170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27810.640625MB; mem (CPU total)=27449.72265625MB
INFO:root:[   55] Training loss: 0.05122398, Validation loss: 0.11131933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27886.828125MB; mem (CPU total)=27525.671875MB
INFO:root:[   56] Training loss: 0.05096836, Validation loss: 0.10607434, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27963.0234375MB; mem (CPU total)=27601.42578125MB
INFO:root:[   57] Training loss: 0.05338991, Validation loss: 0.11183943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28039.2109375MB; mem (CPU total)=27677.4140625MB
INFO:root:[   58] Training loss: 0.05175158, Validation loss: 0.10724134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28115.40625MB; mem (CPU total)=27753.87109375MB
INFO:root:[   59] Training loss: 0.04974218, Validation loss: 0.10903632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28191.59765625MB; mem (CPU total)=27830.34765625MB
INFO:root:[   60] Training loss: 0.04871503, Validation loss: 0.10733739, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28267.78515625MB; mem (CPU total)=27906.58203125MB
INFO:root:[   61] Training loss: 0.04936938, Validation loss: 0.11698379, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28343.98046875MB; mem (CPU total)=27983.0MB
INFO:root:[   62] Training loss: 0.04916014, Validation loss: 0.11123455, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28420.16796875MB; mem (CPU total)=28058.9765625MB
INFO:root:[   63] Training loss: 0.04805712, Validation loss: 0.10486643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28496.359375MB; mem (CPU total)=28136.01953125MB
INFO:root:[   64] Training loss: 0.04904405, Validation loss: 0.10579252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28572.55078125MB; mem (CPU total)=28212.03515625MB
INFO:root:[   65] Training loss: 0.04710496, Validation loss: 0.11432276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28648.734375MB; mem (CPU total)=28288.51171875MB
INFO:root:[   66] Training loss: 0.04847792, Validation loss: 0.11108745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28724.9296875MB; mem (CPU total)=28364.74609375MB
INFO:root:[   67] Training loss: 0.04883907, Validation loss: 0.11088709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28801.12109375MB; mem (CPU total)=28440.7421875MB
INFO:root:[   68] Training loss: 0.04857934, Validation loss: 0.11154365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28877.3125MB; mem (CPU total)=28517.40625MB
INFO:root:[   69] Training loss: 0.04892939, Validation loss: 0.11267993, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28953.5MB; mem (CPU total)=28593.39453125MB
INFO:root:[   70] Training loss: 0.04643619, Validation loss: 0.10722889, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29029.6953125MB; mem (CPU total)=28669.875MB
INFO:root:[   71] Training loss: 0.04641181, Validation loss: 0.10127704, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29105.88671875MB; mem (CPU total)=28746.83203125MB
INFO:root:[   72] Training loss: 0.04592046, Validation loss: 0.10860932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29182.07421875MB; mem (CPU total)=28822.82421875MB
INFO:root:[   73] Training loss: 0.04640573, Validation loss: 0.10711526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29258.26953125MB; mem (CPU total)=28899.296875MB
INFO:root:[   74] Training loss: 0.04551301, Validation loss: 0.10762499, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29334.45703125MB; mem (CPU total)=28975.5703125MB
INFO:root:[   75] Training loss: 0.04635247, Validation loss: 0.10368870, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29410.6484375MB; mem (CPU total)=29051.5625MB
INFO:root:[   76] Training loss: 0.04694216, Validation loss: 0.10400111, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29486.83984375MB; mem (CPU total)=29128.0MB
INFO:root:[   77] Training loss: 0.04589766, Validation loss: 0.10411638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29563.02734375MB; mem (CPU total)=29204.01953125MB
INFO:root:[   78] Training loss: 0.04407676, Validation loss: 0.10904722, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29639.22265625MB; mem (CPU total)=29280.5078125MB
INFO:root:[   79] Training loss: 0.04519197, Validation loss: 0.10632148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29715.41015625MB; mem (CPU total)=29356.7421875MB
INFO:root:[   80] Training loss: 0.04571774, Validation loss: 0.10274522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29791.6015625MB; mem (CPU total)=29433.21875MB
INFO:root:EP 80: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=29867.79296875MB; mem (CPU total)=29509.4609375MB
INFO:root:Training the model took 4805.233s.
INFO:root:Emptying the cuda cache took 0.025s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09827
INFO:root:EnergyScoreTrain: 0.05144
INFO:root:CRPSTrain: 0.04164
INFO:root:Gaussian NLLTrain: 13.43193
INFO:root:CoverageTrain: 0.69753
INFO:root:IntervalWidthTrain: 0.24235
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.13359
INFO:root:EnergyScoreValidation: 0.07593
INFO:root:CRPSValidation: 0.06214
INFO:root:Gaussian NLLValidation: 10.4026
INFO:root:CoverageValidation: 0.56783
INFO:root:IntervalWidthValidation: 0.24481
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.13779
INFO:root:EnergyScoreTest: 0.08089
INFO:root:CRPSTest: 0.06638
INFO:root:Gaussian NLLTest: 5.80317
INFO:root:CoverageTest: 0.53998
INFO:root:IntervalWidthTest: 0.22801
INFO:root:After validation: mem (CPU python)=30014.26953125MB; mem (CPU total)=29656.68359375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=30014.26953125MB; mem (CPU total)=29656.28125MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 304087040
INFO:root:After setting up the model: mem (CPU python)=30015.640625MB; mem (CPU total)=29657.51171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=30015.640625MB; mem (CPU total)=29657.7421875MB
INFO:root:[    1] Training loss: 0.39068816, Validation loss: 0.28087764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30091.8984375MB; mem (CPU total)=29734.12109375MB
INFO:root:[    2] Training loss: 0.17924333, Validation loss: 0.23168466, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30168.08984375MB; mem (CPU total)=29810.5703125MB
INFO:root:[    3] Training loss: 0.14883160, Validation loss: 0.18508559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30244.296875MB; mem (CPU total)=29886.359375MB
INFO:root:[    4] Training loss: 0.13154561, Validation loss: 0.18842818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30320.50390625MB; mem (CPU total)=29962.4453125MB
INFO:root:[    5] Training loss: 0.12648220, Validation loss: 0.15528823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30396.71484375MB; mem (CPU total)=30038.21875MB
INFO:root:[    6] Training loss: 0.11813556, Validation loss: 0.15403547, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30472.91796875MB; mem (CPU total)=30115.03515625MB
INFO:root:[    7] Training loss: 0.11375223, Validation loss: 0.14767797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30549.125MB; mem (CPU total)=30191.07421875MB
INFO:root:[    8] Training loss: 0.10996666, Validation loss: 0.13952238, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30625.31640625MB; mem (CPU total)=30267.609375MB
INFO:root:[    9] Training loss: 0.10702500, Validation loss: 0.13758682, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30701.5078125MB; mem (CPU total)=30343.65234375MB
INFO:root:[   10] Training loss: 0.10241009, Validation loss: 0.14227739, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30777.69921875MB; mem (CPU total)=30419.94921875MB
INFO:root:[   11] Training loss: 0.10009702, Validation loss: 0.13467716, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30853.890625MB; mem (CPU total)=30496.5MB
INFO:root:[   12] Training loss: 0.09891094, Validation loss: 0.13123964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30930.08203125MB; mem (CPU total)=30572.77734375MB
INFO:root:[   13] Training loss: 0.09535961, Validation loss: 0.12773125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31006.26953125MB; mem (CPU total)=30649.046875MB
INFO:root:[   14] Training loss: 0.09616738, Validation loss: 0.12320542, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31082.4609375MB; mem (CPU total)=30725.08984375MB
INFO:root:[   15] Training loss: 0.09496324, Validation loss: 0.12545852, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31158.65625MB; mem (CPU total)=30801.33203125MB
INFO:root:[   16] Training loss: 0.09105345, Validation loss: 0.12299438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31234.84375MB; mem (CPU total)=30877.5625MB
INFO:root:[   17] Training loss: 0.08940050, Validation loss: 0.12460728, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31311.0390625MB; mem (CPU total)=30953.8828125MB
INFO:root:[   18] Training loss: 0.08788457, Validation loss: 0.12219355, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31387.2265625MB; mem (CPU total)=31030.37109375MB
INFO:root:[   19] Training loss: 0.08647177, Validation loss: 0.12113884, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31463.41796875MB; mem (CPU total)=31106.81640625MB
INFO:root:[   20] Training loss: 0.08604832, Validation loss: 0.11853970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31539.609375MB; mem (CPU total)=31182.984375MB
INFO:root:[   21] Training loss: 0.08465289, Validation loss: 0.12231268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31615.80078125MB; mem (CPU total)=31258.98046875MB
INFO:root:[   22] Training loss: 0.08585912, Validation loss: 0.12025832, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31691.9921875MB; mem (CPU total)=31335.21875MB
INFO:root:[   23] Training loss: 0.08225871, Validation loss: 0.11537168, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31768.1796875MB; mem (CPU total)=31411.96875MB
INFO:root:[   24] Training loss: 0.08220865, Validation loss: 0.12179233, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31844.375MB; mem (CPU total)=31488.26171875MB
INFO:root:[   25] Training loss: 0.08076559, Validation loss: 0.11372968, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31920.5625MB; mem (CPU total)=31565.04296875MB
INFO:root:[   26] Training loss: 0.08072592, Validation loss: 0.11451157, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31996.75390625MB; mem (CPU total)=31641.0546875MB
INFO:root:[   27] Training loss: 0.07738996, Validation loss: 0.11566257, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32072.9453125MB; mem (CPU total)=31717.53125MB
INFO:root:[   28] Training loss: 0.07687789, Validation loss: 0.12334159, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32149.1328125MB; mem (CPU total)=31793.71875MB
INFO:root:[   29] Training loss: 0.07687346, Validation loss: 0.11148280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32225.328125MB; mem (CPU total)=31870.47265625MB
INFO:root:[   30] Training loss: 0.07499197, Validation loss: 0.11604073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32301.515625MB; mem (CPU total)=31946.515625MB
INFO:root:[   31] Training loss: 0.07503655, Validation loss: 0.11944734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32377.70703125MB; mem (CPU total)=32022.484375MB
INFO:root:[   32] Training loss: 0.07424667, Validation loss: 0.11630833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32453.90234375MB; mem (CPU total)=32098.953125MB
INFO:root:[   33] Training loss: 0.07352101, Validation loss: 0.11171578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32530.08984375MB; mem (CPU total)=32175.16796875MB
INFO:root:[   34] Training loss: 0.07209977, Validation loss: 0.11680585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32606.28125MB; mem (CPU total)=32251.58203125MB
INFO:root:[   35] Training loss: 0.07287697, Validation loss: 0.11936076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32682.46875MB; mem (CPU total)=32327.578125MB
INFO:root:[   36] Training loss: 0.07088799, Validation loss: 0.11234723, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32758.6640625MB; mem (CPU total)=32404.05078125MB
INFO:root:[   37] Training loss: 0.06979074, Validation loss: 0.11510655, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32834.85546875MB; mem (CPU total)=32480.765625MB
INFO:root:[   38] Training loss: 0.06846717, Validation loss: 0.11680734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32911.04296875MB; mem (CPU total)=32556.76171875MB
INFO:root:[   39] Training loss: 0.06838131, Validation loss: 0.11120225, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32987.234375MB; mem (CPU total)=32633.12109375MB
INFO:root:[   40] Training loss: 0.06812417, Validation loss: 0.11137761, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33063.42578125MB; mem (CPU total)=32709.07421875MB
INFO:root:[   41] Training loss: 0.06672992, Validation loss: 0.11249050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33139.6171875MB; mem (CPU total)=32785.5546875MB
INFO:root:[   42] Training loss: 0.06612831, Validation loss: 0.10978727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33215.8046875MB; mem (CPU total)=32862.1015625MB
INFO:root:[   43] Training loss: 0.06548805, Validation loss: 0.11312697, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33291.99609375MB; mem (CPU total)=32938.08203125MB
INFO:root:[   44] Training loss: 0.06538977, Validation loss: 0.11191662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33368.19140625MB; mem (CPU total)=33014.2265625MB
INFO:root:[   45] Training loss: 0.06407082, Validation loss: 0.11189464, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33444.3828125MB; mem (CPU total)=33090.7265625MB
INFO:root:[   46] Training loss: 0.06595637, Validation loss: 0.10978380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33520.57421875MB; mem (CPU total)=33167.296875MB
INFO:root:[   47] Training loss: 0.06688240, Validation loss: 0.11166900, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33596.76171875MB; mem (CPU total)=33243.52734375MB
INFO:root:[   48] Training loss: 0.06333356, Validation loss: 0.11230198, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33672.953125MB; mem (CPU total)=33319.796875MB
INFO:root:[   49] Training loss: 0.06280461, Validation loss: 0.11235882, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33749.1484375MB; mem (CPU total)=33396.08984375MB
INFO:root:[   50] Training loss: 0.06189712, Validation loss: 0.10902384, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33825.3359375MB; mem (CPU total)=33472.625MB
INFO:root:[   51] Training loss: 0.06112685, Validation loss: 0.11059504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33901.52734375MB; mem (CPU total)=33548.8515625MB
INFO:root:[   52] Training loss: 0.06202481, Validation loss: 0.11536705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33977.71484375MB; mem (CPU total)=33625.11328125MB
INFO:root:[   53] Training loss: 0.06102928, Validation loss: 0.11333732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34053.91015625MB; mem (CPU total)=33701.359375MB
INFO:root:[   54] Training loss: 0.06219004, Validation loss: 0.10954331, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34130.10546875MB; mem (CPU total)=33777.5546875MB
INFO:root:[   55] Training loss: 0.05996007, Validation loss: 0.11404727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34206.29296875MB; mem (CPU total)=33854.05859375MB
INFO:root:[   56] Training loss: 0.05934430, Validation loss: 0.11002073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34282.48828125MB; mem (CPU total)=33930.31640625MB
INFO:root:[   57] Training loss: 0.06141168, Validation loss: 0.11375284, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34358.67578125MB; mem (CPU total)=34006.58203125MB
INFO:root:[   58] Training loss: 0.06028387, Validation loss: 0.11124061, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34434.8671875MB; mem (CPU total)=34083.05859375MB
INFO:root:[   59] Training loss: 0.05902087, Validation loss: 0.11138973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34511.0546875MB; mem (CPU total)=34159.30859375MB
INFO:root:[   60] Training loss: 0.05923236, Validation loss: 0.11001959, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34587.24609375MB; mem (CPU total)=34235.7890625MB
INFO:root:[   61] Training loss: 0.05926196, Validation loss: 0.11843498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34663.44140625MB; mem (CPU total)=34312.2578125MB
INFO:root:[   62] Training loss: 0.05799610, Validation loss: 0.11402470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34739.6328125MB; mem (CPU total)=34388.24609375MB
INFO:root:[   63] Training loss: 0.05761554, Validation loss: 0.10927534, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34815.8203125MB; mem (CPU total)=34464.96875MB
INFO:root:[   64] Training loss: 0.05753914, Validation loss: 0.10957112, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34892.01171875MB; mem (CPU total)=34540.95703125MB
INFO:root:[   65] Training loss: 0.05726227, Validation loss: 0.11656464, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34968.203125MB; mem (CPU total)=34617.18359375MB
INFO:root:[   66] Training loss: 0.05727609, Validation loss: 0.10965956, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35044.39453125MB; mem (CPU total)=34693.69140625MB
INFO:root:[   67] Training loss: 0.05651658, Validation loss: 0.11289087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35120.58203125MB; mem (CPU total)=34769.92578125MB
INFO:root:[   68] Training loss: 0.05693666, Validation loss: 0.11384779, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35196.7734375MB; mem (CPU total)=34846.3984375MB
INFO:root:[   69] Training loss: 0.05588438, Validation loss: 0.12562807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35272.9609375MB; mem (CPU total)=34922.3828125MB
INFO:root:[   70] Training loss: 0.05514091, Validation loss: 0.11133849, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35349.15625MB; mem (CPU total)=34999.39453125MB
INFO:root:[   71] Training loss: 0.05658243, Validation loss: 0.11389667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35425.34765625MB; mem (CPU total)=35075.86328125MB
INFO:root:[   72] Training loss: 0.05474322, Validation loss: 0.11512687, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35501.53515625MB; mem (CPU total)=35151.84375MB
INFO:root:EP 72: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=35577.56640625MB; mem (CPU total)=35228.35546875MB
INFO:root:Training the model took 4874.6s.
INFO:root:Emptying the cuda cache took 0.024s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.09852
INFO:root:EnergyScoreTrain: 0.05151
INFO:root:CRPSTrain: 0.04174
INFO:root:Gaussian NLLTrain: 2.09391
INFO:root:CoverageTrain: 0.68872
INFO:root:IntervalWidthTrain: 0.2433
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.13917
INFO:root:EnergyScoreValidation: 0.08158
INFO:root:CRPSValidation: 0.06706
INFO:root:Gaussian NLLValidation: 10.0809
INFO:root:CoverageValidation: 0.55119
INFO:root:IntervalWidthValidation: 0.24513
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.14031
INFO:root:EnergyScoreTest: 0.08174
INFO:root:CRPSTest: 0.06667
INFO:root:Gaussian NLLTest: 7.69161
INFO:root:CoverageTest: 0.53956
INFO:root:IntervalWidthTest: 0.24793
INFO:root:After validation: mem (CPU python)=35724.765625MB; mem (CPU total)=35373.9296875MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=35724.765625MB; mem (CPU total)=35373.8984375MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 306184192
INFO:root:After setting up the model: mem (CPU python)=35725.5546875MB; mem (CPU total)=35374.8828125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=35725.74609375MB; mem (CPU total)=35374.859375MB
INFO:root:[    1] Training loss: 0.40591677, Validation loss: 0.26654920, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35802.2734375MB; mem (CPU total)=35451.6015625MB
INFO:root:[    2] Training loss: 0.19959959, Validation loss: 0.20932631, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35878.4609375MB; mem (CPU total)=35527.890625MB
INFO:root:[    3] Training loss: 0.16425410, Validation loss: 0.17801013, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35954.66796875MB; mem (CPU total)=35604.08203125MB
INFO:root:[    4] Training loss: 0.14806945, Validation loss: 0.19626004, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36030.87109375MB; mem (CPU total)=35680.5625MB
INFO:root:[    5] Training loss: 0.14102783, Validation loss: 0.16212756, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36107.08203125MB; mem (CPU total)=35757.07421875MB
INFO:root:[    6] Training loss: 0.13246445, Validation loss: 0.15374867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36183.28515625MB; mem (CPU total)=35833.51953125MB
INFO:root:[    7] Training loss: 0.12583562, Validation loss: 0.15108656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36259.48046875MB; mem (CPU total)=35909.5390625MB
INFO:root:[    8] Training loss: 0.12334768, Validation loss: 0.14346304, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36335.671875MB; mem (CPU total)=35985.91015625MB
INFO:root:[    9] Training loss: 0.11960008, Validation loss: 0.15175770, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36411.859375MB; mem (CPU total)=36061.8671875MB
INFO:root:[   10] Training loss: 0.11536127, Validation loss: 0.13891642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36488.0546875MB; mem (CPU total)=36138.33984375MB
INFO:root:[   11] Training loss: 0.11154676, Validation loss: 0.13862597, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36564.2421875MB; mem (CPU total)=36214.3203125MB
INFO:root:[   12] Training loss: 0.10906761, Validation loss: 0.14124777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36640.43359375MB; mem (CPU total)=36290.578125MB
INFO:root:[   13] Training loss: 0.10537365, Validation loss: 0.13397821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36716.625MB; mem (CPU total)=36367.0859375MB
INFO:root:[   14] Training loss: 0.10513908, Validation loss: 0.13567315, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36792.8125MB; mem (CPU total)=36443.09765625MB
INFO:root:[   15] Training loss: 0.10953801, Validation loss: 0.14370418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36869.0078125MB; mem (CPU total)=36519.59765625MB
INFO:root:[   16] Training loss: 0.10196760, Validation loss: 0.13555955, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36945.1953125MB; mem (CPU total)=36595.859375MB
INFO:root:[   17] Training loss: 0.09932662, Validation loss: 0.13490546, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37021.38671875MB; mem (CPU total)=36672.30078125MB
INFO:root:[   18] Training loss: 0.09840786, Validation loss: 0.13441624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37097.578125MB; mem (CPU total)=36748.80859375MB
INFO:root:[   19] Training loss: 0.09678014, Validation loss: 0.13441689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37173.7734375MB; mem (CPU total)=36824.8125MB
INFO:root:[   20] Training loss: 0.09740834, Validation loss: 0.13630509, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37249.96484375MB; mem (CPU total)=36901.69921875MB
INFO:root:[   21] Training loss: 0.09458944, Validation loss: 0.13666288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37326.15234375MB; mem (CPU total)=36978.19921875MB
INFO:root:[   22] Training loss: 0.09525438, Validation loss: 0.13703371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37402.34765625MB; mem (CPU total)=37053.8125MB
INFO:root:[   23] Training loss: 0.09369789, Validation loss: 0.13379920, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37478.53515625MB; mem (CPU total)=37130.3984375MB
INFO:root:[   24] Training loss: 0.09183483, Validation loss: 0.13337056, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37554.7265625MB; mem (CPU total)=37206.45703125MB
INFO:root:[   25] Training loss: 0.09054750, Validation loss: 0.13418249, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37630.91796875MB; mem (CPU total)=37283.203125MB
INFO:root:[   26] Training loss: 0.09072819, Validation loss: 0.13604426, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37707.10546875MB; mem (CPU total)=37359.453125MB
INFO:root:[   27] Training loss: 0.08843349, Validation loss: 0.14527442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37783.296875MB; mem (CPU total)=37435.90625MB
INFO:root:[   28] Training loss: 0.08986926, Validation loss: 0.14910252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37859.48828125MB; mem (CPU total)=37512.37890625MB
INFO:root:[   29] Training loss: 0.08771620, Validation loss: 0.15489275, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37935.6796875MB; mem (CPU total)=37588.62890625MB
INFO:root:[   30] Training loss: 0.08686185, Validation loss: 0.14304929, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38011.87109375MB; mem (CPU total)=37664.8828125MB
INFO:root:[   31] Training loss: 0.08535093, Validation loss: 0.13885456, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38088.0625MB; mem (CPU total)=37740.984375MB
INFO:root:[   32] Training loss: 0.08283984, Validation loss: 0.14895841, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38164.25390625MB; mem (CPU total)=37817.20703125MB
INFO:root:[   33] Training loss: 0.08408391, Validation loss: 0.13726702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38240.44140625MB; mem (CPU total)=37893.69140625MB
INFO:root:[   34] Training loss: 0.08316265, Validation loss: 0.14262948, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38316.6328125MB; mem (CPU total)=37969.65625MB
INFO:root:[   35] Training loss: 0.08206350, Validation loss: 0.14551076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38392.828125MB; mem (CPU total)=38046.13671875MB
INFO:root:[   36] Training loss: 0.08143693, Validation loss: 0.14255845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38469.01953125MB; mem (CPU total)=38122.3515625MB
INFO:root:[   37] Training loss: 0.08105857, Validation loss: 0.14188660, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38545.2109375MB; mem (CPU total)=38198.83203125MB
INFO:root:[   38] Training loss: 0.07935124, Validation loss: 0.14519380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38621.40234375MB; mem (CPU total)=38275.046875MB
INFO:root:[   39] Training loss: 0.08142389, Validation loss: 0.14018167, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38697.59375MB; mem (CPU total)=38351.04296875MB
INFO:root:[   40] Training loss: 0.07839433, Validation loss: 0.14466634, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38773.78125MB; mem (CPU total)=38427.50390625MB
INFO:root:[   41] Training loss: 0.07739022, Validation loss: 0.14387650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38849.9765625MB; mem (CPU total)=38504.1953125MB
INFO:root:[   42] Training loss: 0.07619119, Validation loss: 0.14676420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38926.16796875MB; mem (CPU total)=38580.44140625MB
INFO:root:[   43] Training loss: 0.07672969, Validation loss: 0.16287908, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39002.35546875MB; mem (CPU total)=38657.48046875MB
INFO:root:[   44] Training loss: 0.07656005, Validation loss: 0.14733771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39078.546875MB; mem (CPU total)=38733.109375MB
INFO:root:[   45] Training loss: 0.07440145, Validation loss: 0.15749270, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39154.734375MB; mem (CPU total)=38809.359375MB
INFO:root:[   46] Training loss: 0.07581425, Validation loss: 0.15305064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39230.92578125MB; mem (CPU total)=38885.6171875MB
INFO:root:[   47] Training loss: 0.07538753, Validation loss: 0.15616503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39307.12109375MB; mem (CPU total)=38962.61328125MB
INFO:root:[   48] Training loss: 0.07377215, Validation loss: 0.16563291, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39383.30859375MB; mem (CPU total)=39038.82421875MB
INFO:root:[   49] Training loss: 0.07285331, Validation loss: 0.15853228, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39459.50390625MB; mem (CPU total)=39115.06640625MB
INFO:root:[   50] Training loss: 0.07211039, Validation loss: 0.15739092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39535.69140625MB; mem (CPU total)=39191.3203125MB
INFO:root:[   51] Training loss: 0.07089096, Validation loss: 0.16160833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39611.8828125MB; mem (CPU total)=39268.07421875MB
INFO:root:[   52] Training loss: 0.07165699, Validation loss: 0.16692071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39688.07421875MB; mem (CPU total)=39344.28515625MB
INFO:root:[   53] Training loss: 0.07005991, Validation loss: 0.16177392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39764.265625MB; mem (CPU total)=39420.3359375MB
INFO:root:[   54] Training loss: 0.06978033, Validation loss: 0.16532379, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39840.4609375MB; mem (CPU total)=39496.5859375MB
INFO:root:[   55] Training loss: 0.06880639, Validation loss: 0.17596826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39916.6484375MB; mem (CPU total)=39573.3671875MB
INFO:root:[   56] Training loss: 0.06884132, Validation loss: 0.17097809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39992.83984375MB; mem (CPU total)=39650.5625MB
INFO:root:[   57] Training loss: 0.06963594, Validation loss: 0.17565826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40069.02734375MB; mem (CPU total)=39727.06640625MB
INFO:root:[   58] Training loss: 0.06704712, Validation loss: 0.18034588, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40145.22265625MB; mem (CPU total)=39803.07421875MB
INFO:root:[   59] Training loss: 0.06509415, Validation loss: 0.17722089, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40221.4140625MB; mem (CPU total)=39879.328125MB
INFO:root:[   60] Training loss: 0.06563093, Validation loss: 0.18100727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40297.6015625MB; mem (CPU total)=39955.58203125MB
INFO:root:[   61] Training loss: 0.06602372, Validation loss: 0.18373305, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40373.79296875MB; mem (CPU total)=40032.09765625MB
INFO:root:[   62] Training loss: 0.06469901, Validation loss: 0.18889877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40449.984375MB; mem (CPU total)=40108.3203125MB
INFO:root:EP 62: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=40526.17578125MB; mem (CPU total)=40184.85546875MB
INFO:root:Training the model took 4664.057s.
INFO:root:Emptying the cuda cache took 0.026s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.12149
INFO:root:EnergyScoreTrain: 0.066
INFO:root:CRPSTrain: 0.05347
INFO:root:Gaussian NLLTrain: 4.50401
INFO:root:CoverageTrain: 0.64653
INFO:root:IntervalWidthTrain: 0.25933
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.16418
INFO:root:EnergyScoreValidation: 0.09926
INFO:root:CRPSValidation: 0.08202
INFO:root:Gaussian NLLValidation: 19.26437
INFO:root:CoverageValidation: 0.46173
INFO:root:IntervalWidthValidation: 0.25519
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.16071
INFO:root:EnergyScoreTest: 0.09297
INFO:root:CRPSTest: 0.07691
INFO:root:Gaussian NLLTest: 24.23737
INFO:root:CoverageTest: 0.47181
INFO:root:IntervalWidthTest: 0.26191
INFO:root:After validation: mem (CPU python)=40673.0625MB; mem (CPU total)=40333.36328125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=40673.0625MB; mem (CPU total)=40333.33203125MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 306184192
INFO:root:After setting up the model: mem (CPU python)=40673.9375MB; mem (CPU total)=40334.3125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=40674.01953125MB; mem (CPU total)=40334.5234375MB
INFO:root:[    1] Training loss: 0.41502286, Validation loss: 0.26313910, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40751.703125MB; mem (CPU total)=40412.5546875MB
INFO:root:[    2] Training loss: 0.21363775, Validation loss: 0.21539334, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40827.890625MB; mem (CPU total)=40488.56640625MB
INFO:root:[    3] Training loss: 0.17636383, Validation loss: 0.17949855, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40904.09765625MB; mem (CPU total)=40564.828125MB
INFO:root:[    4] Training loss: 0.16072902, Validation loss: 0.18133697, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40980.3046875MB; mem (CPU total)=40641.30078125MB
INFO:root:[    5] Training loss: 0.14828612, Validation loss: 0.16063886, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41056.4921875MB; mem (CPU total)=40717.84375MB
INFO:root:[    6] Training loss: 0.14477911, Validation loss: 0.16703526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41132.68359375MB; mem (CPU total)=40794.2421875MB
INFO:root:[    7] Training loss: 0.13450696, Validation loss: 0.15002117, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41208.875MB; mem (CPU total)=40871.0234375MB
INFO:root:[    8] Training loss: 0.13160111, Validation loss: 0.15127822, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41285.06640625MB; mem (CPU total)=40947.3046875MB
INFO:root:[    9] Training loss: 0.12937965, Validation loss: 0.14935094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41361.2578125MB; mem (CPU total)=41023.35546875MB
INFO:root:[   10] Training loss: 0.12452995, Validation loss: 0.14337596, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41437.453125MB; mem (CPU total)=41100.27734375MB
INFO:root:[   11] Training loss: 0.12331366, Validation loss: 0.15195251, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41513.64453125MB; mem (CPU total)=41175.86328125MB
INFO:root:[   12] Training loss: 0.12134914, Validation loss: 0.15750439, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41589.83203125MB; mem (CPU total)=41252.390625MB
INFO:root:[   13] Training loss: 0.11405286, Validation loss: 0.15183741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41666.0234375MB; mem (CPU total)=41328.890625MB
INFO:root:[   14] Training loss: 0.11325608, Validation loss: 0.14340636, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41742.21484375MB; mem (CPU total)=41405.11328125MB
INFO:root:[   15] Training loss: 0.11648657, Validation loss: 0.14892846, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41818.40625MB; mem (CPU total)=41481.61328125MB
INFO:root:[   16] Training loss: 0.11033941, Validation loss: 0.14306691, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41894.59765625MB; mem (CPU total)=41557.93359375MB
INFO:root:[   17] Training loss: 0.10832219, Validation loss: 0.13962713, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41970.78515625MB; mem (CPU total)=41633.90625MB
INFO:root:[   18] Training loss: 0.10641520, Validation loss: 0.14270425, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42046.98046875MB; mem (CPU total)=41709.92578125MB
INFO:root:[   19] Training loss: 0.10527599, Validation loss: 0.14347356, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42123.16796875MB; mem (CPU total)=41786.421875MB
INFO:root:[   20] Training loss: 0.10606737, Validation loss: 0.15346372, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42199.359375MB; mem (CPU total)=41863.328125MB
INFO:root:[   21] Training loss: 0.10401931, Validation loss: 0.14203843, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42275.55078125MB; mem (CPU total)=41939.23828125MB
INFO:root:[   22] Training loss: 0.10318546, Validation loss: 0.14594467, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42351.7421875MB; mem (CPU total)=42015.73046875MB
INFO:root:[   23] Training loss: 0.10113979, Validation loss: 0.14533170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42427.93359375MB; mem (CPU total)=42096.47265625MB
INFO:root:[   24] Training loss: 0.10129931, Validation loss: 0.14798695, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42504.12109375MB; mem (CPU total)=42172.203125MB
INFO:root:[   25] Training loss: 0.09972280, Validation loss: 0.14493398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42580.3125MB; mem (CPU total)=42248.66015625MB
INFO:root:[   26] Training loss: 0.09827550, Validation loss: 0.14571616, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42656.5078125MB; mem (CPU total)=42324.62890625MB
INFO:root:[   27] Training loss: 0.09650612, Validation loss: 0.15242407, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42732.6953125MB; mem (CPU total)=42401.37109375MB
INFO:root:[   28] Training loss: 0.09802601, Validation loss: 0.15863558, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42808.88671875MB; mem (CPU total)=42477.09375MB
INFO:root:[   29] Training loss: 0.09659921, Validation loss: 0.16790127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42885.07421875MB; mem (CPU total)=42553.625MB
INFO:root:[   30] Training loss: 0.09558159, Validation loss: 0.15015914, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42961.26953125MB; mem (CPU total)=42629.8828125MB
INFO:root:[   31] Training loss: 0.09287093, Validation loss: 0.14563175, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43037.45703125MB; mem (CPU total)=42705.8828125MB
INFO:root:[   32] Training loss: 0.09117399, Validation loss: 0.15772737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43113.6484375MB; mem (CPU total)=42782.12890625MB
INFO:root:[   33] Training loss: 0.09126874, Validation loss: 0.14613506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43189.84375MB; mem (CPU total)=42858.13671875MB
INFO:root:[   34] Training loss: 0.09028355, Validation loss: 0.15328208, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43266.03125MB; mem (CPU total)=42934.87109375MB
INFO:root:[   35] Training loss: 0.08948808, Validation loss: 0.15160911, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43342.22265625MB; mem (CPU total)=43011.39453125MB
INFO:root:[   36] Training loss: 0.08890001, Validation loss: 0.15165294, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43418.41015625MB; mem (CPU total)=43087.3984375MB
INFO:root:[   37] Training loss: 0.08824922, Validation loss: 0.15050479, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43494.6015625MB; mem (CPU total)=43163.94140625MB
INFO:root:[   38] Training loss: 0.08703847, Validation loss: 0.15516167, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43570.796875MB; mem (CPU total)=43239.91796875MB
INFO:root:[   39] Training loss: 0.08832277, Validation loss: 0.14657833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43646.984375MB; mem (CPU total)=43316.55859375MB
INFO:root:[   40] Training loss: 0.08472768, Validation loss: 0.15198049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43723.17578125MB; mem (CPU total)=43393.0546875MB
INFO:root:[   41] Training loss: 0.08423125, Validation loss: 0.15332392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43799.3671875MB; mem (CPU total)=43469.06640625MB
INFO:root:[   42] Training loss: 0.08379206, Validation loss: 0.15936464, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43875.56640625MB; mem (CPU total)=43545.37109375MB
INFO:root:[   43] Training loss: 0.08354483, Validation loss: 0.16754241, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43951.7578125MB; mem (CPU total)=43621.375MB
INFO:root:[   44] Training loss: 0.08353697, Validation loss: 0.15314215, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44027.9453125MB; mem (CPU total)=43697.625MB
INFO:root:[   45] Training loss: 0.08113354, Validation loss: 0.15836568, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44104.140625MB; mem (CPU total)=43774.48046875MB
INFO:root:[   46] Training loss: 0.08131905, Validation loss: 0.16544420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44180.328125MB; mem (CPU total)=43850.4765625MB
INFO:root:[   47] Training loss: 0.08197747, Validation loss: 0.15923292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44256.51953125MB; mem (CPU total)=43926.88671875MB
INFO:root:[   48] Training loss: 0.08078526, Validation loss: 0.16566183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44332.70703125MB; mem (CPU total)=44003.33984375MB
INFO:root:[   49] Training loss: 0.07916551, Validation loss: 0.16264610, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44408.8984375MB; mem (CPU total)=44079.56640625MB
INFO:root:[   50] Training loss: 0.08002918, Validation loss: 0.15954248, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44485.09375MB; mem (CPU total)=44155.78515625MB
INFO:root:[   51] Training loss: 0.07768769, Validation loss: 0.16249397, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44561.28125MB; mem (CPU total)=44231.76171875MB
INFO:root:[   52] Training loss: 0.07825398, Validation loss: 0.16660145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44637.47265625MB; mem (CPU total)=44308.7265625MB
INFO:root:[   53] Training loss: 0.07596366, Validation loss: 0.16220172, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44713.66015625MB; mem (CPU total)=44384.94140625MB
INFO:root:[   54] Training loss: 0.07647345, Validation loss: 0.16052841, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44789.859375MB; mem (CPU total)=44461.16015625MB
INFO:root:[   55] Training loss: 0.07469592, Validation loss: 0.16747217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44866.05078125MB; mem (CPU total)=44537.62890625MB
INFO:root:[   56] Training loss: 0.07506341, Validation loss: 0.16181016, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44942.23828125MB; mem (CPU total)=44613.96875MB
INFO:root:[   57] Training loss: 0.07595846, Validation loss: 0.16502648, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45018.43359375MB; mem (CPU total)=44690.28125MB
INFO:root:[   58] Training loss: 0.07312520, Validation loss: 0.16712114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45094.62109375MB; mem (CPU total)=44766.2890625MB
INFO:root:[   59] Training loss: 0.07206909, Validation loss: 0.16575802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45170.8125MB; mem (CPU total)=44843.0390625MB
INFO:root:[   60] Training loss: 0.07151594, Validation loss: 0.16647640, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45247.00390625MB; mem (CPU total)=44919.28515625MB
INFO:root:[   61] Training loss: 0.07188354, Validation loss: 0.16670418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45323.1953125MB; mem (CPU total)=44995.296875MB
INFO:root:[   62] Training loss: 0.07142646, Validation loss: 0.16540076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45399.38671875MB; mem (CPU total)=45072.19140625MB
INFO:root:[   63] Training loss: 0.07199422, Validation loss: 0.17032982, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45475.57421875MB; mem (CPU total)=45148.30078125MB
INFO:root:EP 63: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=45551.765625MB; mem (CPU total)=45224.57421875MB
INFO:root:Training the model took 5113.185s.
INFO:root:Emptying the cuda cache took 0.026s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.12119
INFO:root:EnergyScoreTrain: 0.06611
INFO:root:CRPSTrain: 0.05444
INFO:root:Gaussian NLLTrain: 5.57725
INFO:root:CoverageTrain: 0.63271
INFO:root:IntervalWidthTrain: 0.26348
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.17271
INFO:root:EnergyScoreValidation: 0.1062
INFO:root:CRPSValidation: 0.08859
INFO:root:Gaussian NLLValidation: 18.24617
INFO:root:CoverageValidation: 0.44476
INFO:root:IntervalWidthValidation: 0.25911
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.17242
INFO:root:EnergyScoreTest: 0.10616
INFO:root:CRPSTest: 0.08841
INFO:root:Gaussian NLLTest: 16.85331
INFO:root:CoverageTest: 0.45676
INFO:root:IntervalWidthTest: 0.26171
INFO:root:After validation: mem (CPU python)=45698.2578125MB; mem (CPU total)=45368.48046875MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=45698.2578125MB; mem (CPU total)=45368.703125MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 301989888
INFO:root:After setting up the model: mem (CPU python)=45699.57421875MB; mem (CPU total)=45369.6875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=45699.57421875MB; mem (CPU total)=45369.921875MB
INFO:root:[    1] Training loss: 0.42510015, Validation loss: 0.25747881, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45776.35546875MB; mem (CPU total)=45446.92578125MB
INFO:root:[    2] Training loss: 0.22707925, Validation loss: 0.19754672, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45852.54296875MB; mem (CPU total)=45523.12890625MB
INFO:root:[    3] Training loss: 0.18750592, Validation loss: 0.17400417, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45928.734375MB; mem (CPU total)=45599.53515625MB
INFO:root:[    4] Training loss: 0.17046168, Validation loss: 0.17641516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46004.92578125MB; mem (CPU total)=45675.53515625MB
INFO:root:[    5] Training loss: 0.16084457, Validation loss: 0.16086719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46081.12109375MB; mem (CPU total)=45752.421875MB
INFO:root:[    6] Training loss: 0.15150962, Validation loss: 0.15515137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46157.3125MB; mem (CPU total)=45829.0703125MB
INFO:root:[    7] Training loss: 0.14191093, Validation loss: 0.15053883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46233.5MB; mem (CPU total)=45905.15234375MB
INFO:root:[    8] Training loss: 0.13943413, Validation loss: 0.15048816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46309.69140625MB; mem (CPU total)=45981.375MB
INFO:root:[    9] Training loss: 0.13782416, Validation loss: 0.15220930, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46385.87890625MB; mem (CPU total)=46057.98828125MB
INFO:root:[   10] Training loss: 0.13073221, Validation loss: 0.14991221, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46462.07421875MB; mem (CPU total)=46133.8828125MB
INFO:root:[   11] Training loss: 0.12990833, Validation loss: 0.15141135, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46538.26953125MB; mem (CPU total)=46210.13671875MB
INFO:root:[   12] Training loss: 0.12898466, Validation loss: 0.16049238, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46614.45703125MB; mem (CPU total)=46286.6484375MB
INFO:root:[   13] Training loss: 0.12139031, Validation loss: 0.14902320, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46690.6484375MB; mem (CPU total)=46363.421875MB
INFO:root:[   14] Training loss: 0.12143582, Validation loss: 0.14247589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46766.8359375MB; mem (CPU total)=46439.41796875MB
INFO:root:[   15] Training loss: 0.12332031, Validation loss: 0.15304096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46843.02734375MB; mem (CPU total)=46515.9140625MB
INFO:root:[   16] Training loss: 0.11787303, Validation loss: 0.14369386, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46919.22265625MB; mem (CPU total)=46592.16015625MB
INFO:root:[   17] Training loss: 0.11601286, Validation loss: 0.14326597, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46995.4140625MB; mem (CPU total)=46668.40234375MB
INFO:root:[   18] Training loss: 0.11451421, Validation loss: 0.15066536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47071.60546875MB; mem (CPU total)=46744.79296875MB
INFO:root:[   19] Training loss: 0.11286056, Validation loss: 0.14291071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47147.796875MB; mem (CPU total)=46821.56640625MB
INFO:root:[   20] Training loss: 0.11193086, Validation loss: 0.15279059, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47223.98828125MB; mem (CPU total)=46897.796875MB
INFO:root:[   21] Training loss: 0.11016042, Validation loss: 0.14636850, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47300.17578125MB; mem (CPU total)=46974.046875MB
INFO:root:[   22] Training loss: 0.10998185, Validation loss: 0.14693237, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47376.3671875MB; mem (CPU total)=47050.53125MB
INFO:root:[   23] Training loss: 0.10778765, Validation loss: 0.14908421, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47452.5625MB; mem (CPU total)=47126.78125MB
INFO:root:[   24] Training loss: 0.10785759, Validation loss: 0.14790398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47528.75MB; mem (CPU total)=47203.03125MB
INFO:root:[   25] Training loss: 0.10614061, Validation loss: 0.14965215, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47604.94140625MB; mem (CPU total)=47279.27734375MB
INFO:root:[   26] Training loss: 0.10657413, Validation loss: 0.15105218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47681.12890625MB; mem (CPU total)=47355.5234375MB
INFO:root:[   27] Training loss: 0.10268976, Validation loss: 0.14959399, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47757.32421875MB; mem (CPU total)=47431.99609375MB
INFO:root:[   28] Training loss: 0.10442156, Validation loss: 0.15567131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47833.515625MB; mem (CPU total)=47507.00390625MB
INFO:root:[   29] Training loss: 0.10136630, Validation loss: 0.15758662, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47909.703125MB; mem (CPU total)=47583.4375MB
INFO:root:[   30] Training loss: 0.10072046, Validation loss: 0.15153152, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47985.89453125MB; mem (CPU total)=47659.6875MB
INFO:root:[   31] Training loss: 0.09957306, Validation loss: 0.14878474, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48062.0859375MB; mem (CPU total)=47735.9296875MB
INFO:root:[   32] Training loss: 0.09749630, Validation loss: 0.15769807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48138.27734375MB; mem (CPU total)=47812.43359375MB
INFO:root:[   33] Training loss: 0.09747847, Validation loss: 0.14793718, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48214.46875MB; mem (CPU total)=47888.42578125MB
INFO:root:[   34] Training loss: 0.09710388, Validation loss: 0.15627954, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48290.65625MB; mem (CPU total)=47964.70703125MB
INFO:root:[   35] Training loss: 0.09489899, Validation loss: 0.15552258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48366.8515625MB; mem (CPU total)=48040.4765625MB
INFO:root:[   36] Training loss: 0.09393080, Validation loss: 0.15486699, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48443.0390625MB; mem (CPU total)=48117.3515625MB
INFO:root:[   37] Training loss: 0.09479826, Validation loss: 0.15694368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48519.23046875MB; mem (CPU total)=48193.44921875MB
INFO:root:[   38] Training loss: 0.09279996, Validation loss: 0.15476575, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48595.41796875MB; mem (CPU total)=48269.46484375MB
INFO:root:[   39] Training loss: 0.09330913, Validation loss: 0.15314414, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48671.61328125MB; mem (CPU total)=48345.7109375MB
INFO:root:[   40] Training loss: 0.09041468, Validation loss: 0.15702057, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48747.8046875MB; mem (CPU total)=48421.9609375MB
INFO:root:[   41] Training loss: 0.08955866, Validation loss: 0.15186180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48823.9921875MB; mem (CPU total)=48498.4765625MB
INFO:root:[   42] Training loss: 0.08967545, Validation loss: 0.16073209, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48900.18359375MB; mem (CPU total)=48574.984375MB
INFO:root:[   43] Training loss: 0.08923178, Validation loss: 0.16905167, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=48976.375MB; mem (CPU total)=48651.22265625MB
INFO:root:[   44] Training loss: 0.08936898, Validation loss: 0.15311722, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49052.56640625MB; mem (CPU total)=48727.47265625MB
INFO:root:[   45] Training loss: 0.08653766, Validation loss: 0.15961643, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49128.7578125MB; mem (CPU total)=48803.44921875MB
INFO:root:[   46] Training loss: 0.08885531, Validation loss: 0.16481763, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49204.9453125MB; mem (CPU total)=48879.83984375MB
INFO:root:[   47] Training loss: 0.08700680, Validation loss: 0.15928542, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49281.140625MB; mem (CPU total)=48955.953125MB
INFO:root:[   48] Training loss: 0.08641186, Validation loss: 0.16227354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49357.328125MB; mem (CPU total)=49032.46484375MB
INFO:root:[   49] Training loss: 0.08487569, Validation loss: 0.16302557, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49433.51953125MB; mem (CPU total)=49108.71484375MB
INFO:root:[   50] Training loss: 0.08566877, Validation loss: 0.16483850, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49509.7109375MB; mem (CPU total)=49185.609375MB
INFO:root:[   51] Training loss: 0.08370661, Validation loss: 0.16070282, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49585.8984375MB; mem (CPU total)=49261.4609375MB
INFO:root:[   52] Training loss: 0.08480061, Validation loss: 0.16430309, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49662.09375MB; mem (CPU total)=49337.70703125MB
INFO:root:[   53] Training loss: 0.08329097, Validation loss: 0.15786082, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49738.28125MB; mem (CPU total)=49413.95703125MB
INFO:root:[   54] Training loss: 0.08323687, Validation loss: 0.15609046, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49814.4765625MB; mem (CPU total)=49490.20703125MB
INFO:root:[   55] Training loss: 0.08137572, Validation loss: 0.16465161, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49890.66796875MB; mem (CPU total)=49567.55078125MB
INFO:root:[   56] Training loss: 0.08165707, Validation loss: 0.15800937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=49966.859375MB; mem (CPU total)=49643.54296875MB
INFO:root:[   57] Training loss: 0.08084456, Validation loss: 0.16200882, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50043.05078125MB; mem (CPU total)=49720.04296875MB
INFO:root:[   58] Training loss: 0.08001860, Validation loss: 0.15941536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50119.23828125MB; mem (CPU total)=49796.30078125MB
INFO:root:[   59] Training loss: 0.07801129, Validation loss: 0.16192138, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50195.43359375MB; mem (CPU total)=49872.29296875MB
INFO:root:[   60] Training loss: 0.07858532, Validation loss: 0.15931709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50271.62109375MB; mem (CPU total)=49949.19140625MB
INFO:root:[   61] Training loss: 0.07867301, Validation loss: 0.16853784, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50347.8203125MB; mem (CPU total)=50024.80078125MB
INFO:root:[   62] Training loss: 0.07765533, Validation loss: 0.16431959, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50424.0078125MB; mem (CPU total)=50101.4296875MB
INFO:root:[   63] Training loss: 0.07852927, Validation loss: 0.16260420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50500.203125MB; mem (CPU total)=50177.68359375MB
INFO:root:EP 63: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=50576.390625MB; mem (CPU total)=50253.96484375MB
INFO:root:Training the model took 5342.254s.
INFO:root:Emptying the cuda cache took 0.027s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.13466
INFO:root:EnergyScoreTrain: 0.0749
INFO:root:CRPSTrain: 0.06202
INFO:root:Gaussian NLLTrain: 6.32332
INFO:root:CoverageTrain: 0.58762
INFO:root:IntervalWidthTrain: 0.26964
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.17892
INFO:root:EnergyScoreValidation: 0.10919
INFO:root:CRPSValidation: 0.09009
INFO:root:Gaussian NLLValidation: 17.50136
INFO:root:CoverageValidation: 0.46595
INFO:root:IntervalWidthValidation: 0.27307
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.18089
INFO:root:EnergyScoreTest: 0.11155
INFO:root:CRPSTest: 0.0919
INFO:root:Gaussian NLLTest: 13.20359
INFO:root:CoverageTest: 0.46957
INFO:root:IntervalWidthTest: 0.27427
INFO:root:After validation: mem (CPU python)=50722.91015625MB; mem (CPU total)=50401.7890625MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.3, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (12, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=50722.91015625MB; mem (CPU total)=50401.765625MB
INFO:root:NumberParameters: 710305
INFO:root:GPU memory allocated: 301989888
INFO:root:After setting up the model: mem (CPU python)=50724.125MB; mem (CPU total)=50402.75MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=50724.20703125MB; mem (CPU total)=50402.78125MB
INFO:root:[    1] Training loss: 0.44668367, Validation loss: 0.26522663, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50800.55078125MB; mem (CPU total)=50479.2734375MB
INFO:root:[    2] Training loss: 0.25902696, Validation loss: 0.20905897, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50876.74609375MB; mem (CPU total)=50556.37109375MB
INFO:root:[    3] Training loss: 0.21049717, Validation loss: 0.17741183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=50952.9375MB; mem (CPU total)=50632.24609375MB
INFO:root:[    4] Training loss: 0.19254483, Validation loss: 0.20129634, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51029.125MB; mem (CPU total)=50707.5234375MB
INFO:root:[    5] Training loss: 0.18184553, Validation loss: 0.16484694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51105.3203125MB; mem (CPU total)=50784.39453125MB
INFO:root:[    6] Training loss: 0.17067442, Validation loss: 0.16109733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51181.5234375MB; mem (CPU total)=50861.1484375MB
INFO:root:[    7] Training loss: 0.15902471, Validation loss: 0.16276731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51257.7109375MB; mem (CPU total)=50937.09375MB
INFO:root:[    8] Training loss: 0.15543944, Validation loss: 0.15271541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51333.91015625MB; mem (CPU total)=51013.52734375MB
INFO:root:[    9] Training loss: 0.15206129, Validation loss: 0.15284035, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51410.09765625MB; mem (CPU total)=51089.7109375MB
INFO:root:[   10] Training loss: 0.14776500, Validation loss: 0.15384563, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51486.2890625MB; mem (CPU total)=51165.921875MB
INFO:root:[   11] Training loss: 0.14535172, Validation loss: 0.15763229, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51562.4765625MB; mem (CPU total)=51242.25390625MB
INFO:root:[   12] Training loss: 0.14238310, Validation loss: 0.14883238, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51638.671875MB; mem (CPU total)=51319.02734375MB
INFO:root:[   13] Training loss: 0.13635869, Validation loss: 0.15526459, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51714.86328125MB; mem (CPU total)=51395.02734375MB
INFO:root:[   14] Training loss: 0.13530105, Validation loss: 0.14663665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51791.05078125MB; mem (CPU total)=51471.515625MB
INFO:root:[   15] Training loss: 0.13470624, Validation loss: 0.15657149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51867.24609375MB; mem (CPU total)=51547.73046875MB
INFO:root:[   16] Training loss: 0.12979924, Validation loss: 0.15092379, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=51943.43359375MB; mem (CPU total)=51624.1953125MB
INFO:root:[   17] Training loss: 0.12893605, Validation loss: 0.15087731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52019.62890625MB; mem (CPU total)=51700.35546875MB
INFO:root:[   18] Training loss: 0.12729603, Validation loss: 0.15399944, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52095.8203125MB; mem (CPU total)=51776.796875MB
INFO:root:[   19] Training loss: 0.12571525, Validation loss: 0.15673080, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52172.0078125MB; mem (CPU total)=51853.2890625MB
INFO:root:[   20] Training loss: 0.12703491, Validation loss: 0.16935866, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52248.19921875MB; mem (CPU total)=51929.25390625MB
INFO:root:[   21] Training loss: 0.12085238, Validation loss: 0.15997064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52324.38671875MB; mem (CPU total)=52005.6953125MB
INFO:root:[   22] Training loss: 0.12211187, Validation loss: 0.15925413, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52400.58203125MB; mem (CPU total)=52081.8984375MB
INFO:root:[   23] Training loss: 0.11902485, Validation loss: 0.16060639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52476.7734375MB; mem (CPU total)=52157.90625MB
INFO:root:[   24] Training loss: 0.11842935, Validation loss: 0.15652953, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52552.9609375MB; mem (CPU total)=52234.61328125MB
INFO:root:[   25] Training loss: 0.11894612, Validation loss: 0.16441932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52629.15625MB; mem (CPU total)=52310.5703125MB
INFO:root:[   26] Training loss: 0.11809958, Validation loss: 0.16176770, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52705.34375MB; mem (CPU total)=52387.0546875MB
INFO:root:[   27] Training loss: 0.11450276, Validation loss: 0.16835626, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52781.53515625MB; mem (CPU total)=52463.48046875MB
INFO:root:[   28] Training loss: 0.11352114, Validation loss: 0.17323943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52857.72265625MB; mem (CPU total)=52539.45703125MB
INFO:root:[   29] Training loss: 0.11255215, Validation loss: 0.17169085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=52933.921875MB; mem (CPU total)=52615.9140625MB
INFO:root:[   30] Training loss: 0.11095606, Validation loss: 0.16920793, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53010.11328125MB; mem (CPU total)=52691.890625MB
INFO:root:[   31] Training loss: 0.11034896, Validation loss: 0.17706521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53086.30078125MB; mem (CPU total)=52768.328125MB
INFO:root:[   32] Training loss: 0.10784241, Validation loss: 0.18677481, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53162.4921875MB; mem (CPU total)=52844.52734375MB
INFO:root:[   33] Training loss: 0.10773824, Validation loss: 0.17985798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53238.68359375MB; mem (CPU total)=52920.96875MB
INFO:root:[   34] Training loss: 0.10749167, Validation loss: 0.18121334, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53314.875MB; mem (CPU total)=52997.4140625MB
INFO:root:[   35] Training loss: 0.10593495, Validation loss: 0.17611485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53391.06640625MB; mem (CPU total)=53073.359375MB
INFO:root:[   36] Training loss: 0.10456766, Validation loss: 0.19047666, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53467.25390625MB; mem (CPU total)=53149.95703125MB
INFO:root:[   37] Training loss: 0.10472701, Validation loss: 0.17934533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53543.44921875MB; mem (CPU total)=53226.19921875MB
INFO:root:[   38] Training loss: 0.10361006, Validation loss: 0.19725017, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53619.63671875MB; mem (CPU total)=53303.67578125MB
INFO:root:[   39] Training loss: 0.10430062, Validation loss: 0.18479655, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53695.828125MB; mem (CPU total)=53380.39453125MB
INFO:root:[   40] Training loss: 0.10085355, Validation loss: 0.18300345, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53772.0234375MB; mem (CPU total)=53456.6328125MB
INFO:root:[   41] Training loss: 0.10007945, Validation loss: 0.18878282, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53848.2109375MB; mem (CPU total)=53532.609375MB
INFO:root:[   42] Training loss: 0.10059800, Validation loss: 0.19386733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=53924.40234375MB; mem (CPU total)=53609.09375MB
INFO:root:[   43] Training loss: 0.09822372, Validation loss: 0.19570913, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54000.58984375MB; mem (CPU total)=53685.34375MB
INFO:root:[   44] Training loss: 0.10001047, Validation loss: 0.17956927, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54076.78125MB; mem (CPU total)=53761.8203125MB
INFO:root:[   45] Training loss: 0.09733911, Validation loss: 0.19210260, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54152.96875MB; mem (CPU total)=53838.05859375MB
INFO:root:[   46] Training loss: 0.10017261, Validation loss: 0.19430354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54229.1640625MB; mem (CPU total)=53914.5390625MB
INFO:root:[   47] Training loss: 0.09820005, Validation loss: 0.18838712, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54305.35546875MB; mem (CPU total)=53990.5234375MB
INFO:root:[   48] Training loss: 0.09770983, Validation loss: 0.19300131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54381.54296875MB; mem (CPU total)=54066.99609375MB
INFO:root:[   49] Training loss: 0.09595962, Validation loss: 0.19542708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54457.73828125MB; mem (CPU total)=54143.74609375MB
INFO:root:[   50] Training loss: 0.09716888, Validation loss: 0.19008015, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54533.92578125MB; mem (CPU total)=54220.26171875MB
INFO:root:[   51] Training loss: 0.09460899, Validation loss: 0.19598188, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54610.1171875MB; mem (CPU total)=54296.515625MB
INFO:root:[   52] Training loss: 0.09548792, Validation loss: 0.20429150, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54686.3125MB; mem (CPU total)=54372.26171875MB
INFO:root:[   53] Training loss: 0.09540471, Validation loss: 0.19890020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54762.5MB; mem (CPU total)=54448.50390625MB
INFO:root:[   54] Training loss: 0.09452370, Validation loss: 0.19725224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54838.6953125MB; mem (CPU total)=54525.00390625MB
INFO:root:[   55] Training loss: 0.09268832, Validation loss: 0.20870608, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54914.8828125MB; mem (CPU total)=54601.74609375MB
INFO:root:[   56] Training loss: 0.09313962, Validation loss: 0.20166221, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=54991.07421875MB; mem (CPU total)=54678.0390625MB
INFO:root:[   57] Training loss: 0.09121160, Validation loss: 0.20986442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55067.26953125MB; mem (CPU total)=54754.2890625MB
INFO:root:[   58] Training loss: 0.09082763, Validation loss: 0.21215732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55143.45703125MB; mem (CPU total)=54830.296875MB
INFO:root:[   59] Training loss: 0.09134715, Validation loss: 0.21358828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55219.6484375MB; mem (CPU total)=54906.78515625MB
INFO:root:[   60] Training loss: 0.09018868, Validation loss: 0.19856999, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55295.8359375MB; mem (CPU total)=54983.0390625MB
INFO:root:[   61] Training loss: 0.09149583, Validation loss: 0.20198857, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55372.03125MB; mem (CPU total)=55059.43359375MB
INFO:root:[   62] Training loss: 0.09024267, Validation loss: 0.20359418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55448.2265625MB; mem (CPU total)=55136.1953125MB
INFO:root:[   63] Training loss: 0.08993713, Validation loss: 0.20308996, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=55524.43359375MB; mem (CPU total)=55212.4375MB
INFO:root:EP 63: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=55600.625MB; mem (CPU total)=55288.953125MB
INFO:root:Training the model took 5747.858s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.15175
INFO:root:EnergyScoreTrain: 0.08714
INFO:root:CRPSTrain: 0.07235
INFO:root:Gaussian NLLTrain: 13.37616
INFO:root:CoverageTrain: 0.55563
INFO:root:IntervalWidthTrain: 0.28122
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.1887
INFO:root:EnergyScoreValidation: 0.11645
INFO:root:CRPSValidation: 0.09628
INFO:root:Gaussian NLLValidation: 15.85372
INFO:root:CoverageValidation: 0.46944
INFO:root:IntervalWidthValidation: 0.28125
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.19121
INFO:root:EnergyScoreTest: 0.11769
INFO:root:CRPSTest: 0.0971
INFO:root:Gaussian NLLTest: 18.796
INFO:root:CoverageTest: 0.48907
INFO:root:IntervalWidthTest: 0.29197
INFO:root:After validation: mem (CPU python)=55747.16015625MB; mem (CPU total)=55435.98828125MB
