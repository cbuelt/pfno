INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=576.07421875MB; mem (CPU total)=1121.296875MB
INFO:root:############### Starting experiment with config file ks/uno.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12454.79296875MB; mem (CPU total)=1127.5078125MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.79296875MB; mem (CPU total)=1126.4921875MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=12454.79296875MB; mem (CPU total)=2493.02734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=2502.22265625MB
INFO:root:[    1] Training loss: 0.71393730, Validation loss: 0.70322842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=6662.40625MB
INFO:root:[    2] Training loss: 0.69837920, Validation loss: 0.69607522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=6709.8515625MB
INFO:root:[    3] Training loss: 0.69375324, Validation loss: 0.69175213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=6748.32421875MB
INFO:root:[    4] Training loss: 0.69097854, Validation loss: 0.69050482, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=6788.74609375MB
INFO:root:[    5] Training loss: 0.68929476, Validation loss: 0.68887451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=6828.5234375MB
INFO:root:[    6] Training loss: 0.68805358, Validation loss: 0.68754543, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=6870.37109375MB
INFO:root:[    7] Training loss: 0.68714453, Validation loss: 0.68714248, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=6910.73828125MB
INFO:root:[    8] Training loss: 0.68625781, Validation loss: 0.68672857, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=6950.25390625MB
INFO:root:[    9] Training loss: 0.68574532, Validation loss: 0.68575844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=6992.32421875MB
INFO:root:[   10] Training loss: 0.68496572, Validation loss: 0.68571420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7033.4140625MB
INFO:root:[   11] Training loss: 0.68448614, Validation loss: 0.68393272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7071.5390625MB
INFO:root:[   12] Training loss: 0.68429122, Validation loss: 0.68439754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7111.0625MB
INFO:root:[   13] Training loss: 0.68370246, Validation loss: 0.68342992, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7151.8046875MB
INFO:root:[   14] Training loss: 0.68339349, Validation loss: 0.68364191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7192.484375MB
INFO:root:[   15] Training loss: 0.68288428, Validation loss: 0.68268761, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7233.3515625MB
INFO:root:[   16] Training loss: 0.68242709, Validation loss: 0.68242033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7276.2890625MB
INFO:root:[   17] Training loss: 0.68211938, Validation loss: 0.68147089, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7433.52734375MB
INFO:root:[   18] Training loss: 0.68162336, Validation loss: 0.68159249, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7606.34765625MB
INFO:root:[   19] Training loss: 0.68135011, Validation loss: 0.68157365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7786.12890625MB
INFO:root:[   20] Training loss: 0.68108350, Validation loss: 0.68068694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9829.70703125MB
INFO:root:[   21] Training loss: 0.68081708, Validation loss: 0.68041139, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10385.94140625MB
INFO:root:[   22] Training loss: 0.68058655, Validation loss: 0.68087598, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10425.92578125MB
INFO:root:[   23] Training loss: 0.68048002, Validation loss: 0.67953316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10466.8984375MB
INFO:root:[   24] Training loss: 0.67987749, Validation loss: 0.67994152, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10604.0859375MB
INFO:root:[   25] Training loss: 0.68003375, Validation loss: 0.67985199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10643.34765625MB
INFO:root:[   26] Training loss: 0.67974977, Validation loss: 0.67962865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10681.62890625MB
INFO:root:[   27] Training loss: 0.67917834, Validation loss: 0.67868295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10744.18359375MB
INFO:root:[   28] Training loss: 0.67903598, Validation loss: 0.67904439, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=5888.875MB
INFO:root:[   29] Training loss: 0.67922649, Validation loss: 0.67964087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7756.29296875MB
INFO:root:[   30] Training loss: 0.67915102, Validation loss: 0.67967581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7796.33203125MB
INFO:root:[   31] Training loss: 0.67848406, Validation loss: 0.67998066, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7835.70703125MB
INFO:root:[   32] Training loss: 0.67868499, Validation loss: 0.67878549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7877.765625MB
INFO:root:[   33] Training loss: 0.67870115, Validation loss: 0.67844567, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7916.32421875MB
INFO:root:[   34] Training loss: 0.67881371, Validation loss: 0.67962337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7957.1640625MB
INFO:root:[   35] Training loss: 0.67805284, Validation loss: 0.67762714, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=7996.703125MB
INFO:root:[   36] Training loss: 0.67824239, Validation loss: 0.67962403, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8034.68359375MB
INFO:root:[   37] Training loss: 0.67830786, Validation loss: 0.67689047, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8074.203125MB
INFO:root:[   38] Training loss: 0.67760988, Validation loss: 0.67788535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8114.77734375MB
INFO:root:[   39] Training loss: 0.67731097, Validation loss: 0.67734647, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8154.4296875MB
INFO:root:[   40] Training loss: 0.67686121, Validation loss: 0.67893612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8193.984375MB
INFO:root:[   41] Training loss: 0.67738490, Validation loss: 0.67656854, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8234.265625MB
INFO:root:[   42] Training loss: 0.67693110, Validation loss: 0.67629879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8273.453125MB
INFO:root:[   43] Training loss: 0.67650055, Validation loss: 0.67553723, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8312.796875MB
INFO:root:[   44] Training loss: 0.67650323, Validation loss: 0.67732708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8353.1640625MB
INFO:root:[   45] Training loss: 0.67595697, Validation loss: 0.67623530, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8393.17578125MB
INFO:root:[   46] Training loss: 0.67619015, Validation loss: 0.67572489, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8432.55078125MB
INFO:root:[   47] Training loss: 0.67572441, Validation loss: 0.67670791, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8473.4765625MB
INFO:root:[   48] Training loss: 0.67571768, Validation loss: 0.67588024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8513.2890625MB
INFO:root:[   49] Training loss: 0.67516076, Validation loss: 0.67762566, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8554.5625MB
INFO:root:[   50] Training loss: 0.67543342, Validation loss: 0.67525225, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8594.54296875MB
INFO:root:[   51] Training loss: 0.67543543, Validation loss: 0.67512726, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8634.578125MB
INFO:root:[   52] Training loss: 0.67497402, Validation loss: 0.67489651, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8673.6171875MB
INFO:root:[   53] Training loss: 0.67465540, Validation loss: 0.67394566, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8713.51171875MB
INFO:root:[   54] Training loss: 0.67453748, Validation loss: 0.67387326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8779.04296875MB
INFO:root:[   55] Training loss: 0.67405027, Validation loss: 0.67469311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8817.84765625MB
INFO:root:[   56] Training loss: 0.67455393, Validation loss: 0.67388428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8856.953125MB
INFO:root:[   57] Training loss: 0.67429782, Validation loss: 0.67442724, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=8895.34765625MB
INFO:root:[   58] Training loss: 0.67424134, Validation loss: 0.67386402, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9059.87890625MB
INFO:root:[   59] Training loss: 0.67419685, Validation loss: 0.67422978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9133.84765625MB
INFO:root:[   60] Training loss: 0.67412540, Validation loss: 0.67421400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9183.81640625MB
INFO:root:[   61] Training loss: 0.67379212, Validation loss: 0.67294028, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9049.6484375MB
INFO:root:[   62] Training loss: 0.67333634, Validation loss: 0.67226571, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9088.171875MB
INFO:root:[   63] Training loss: 0.67283304, Validation loss: 0.67336521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9125.99609375MB
INFO:root:[   64] Training loss: 0.67315364, Validation loss: 0.67301065, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9164.22265625MB
INFO:root:[   65] Training loss: 0.67300064, Validation loss: 0.67271308, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9202.57421875MB
INFO:root:[   66] Training loss: 0.67256335, Validation loss: 0.67342171, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9367.9765625MB
INFO:root:[   67] Training loss: 0.67228039, Validation loss: 0.67195491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9278.29296875MB
INFO:root:[   68] Training loss: 0.67199388, Validation loss: 0.67328062, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9316.12890625MB
INFO:root:[   69] Training loss: 0.67219250, Validation loss: 0.67275995, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9354.2109375MB
INFO:root:[   70] Training loss: 0.67181637, Validation loss: 0.67179976, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9393.7890625MB
INFO:root:[   71] Training loss: 0.67163321, Validation loss: 0.67148396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9434.91796875MB
INFO:root:[   72] Training loss: 0.67144560, Validation loss: 0.67154865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9474.83203125MB
INFO:root:[   73] Training loss: 0.67111004, Validation loss: 0.67204913, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9513.60546875MB
INFO:root:[   74] Training loss: 0.67106819, Validation loss: 0.67254189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9557.19921875MB
INFO:root:[   75] Training loss: 0.67123579, Validation loss: 0.67114111, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9822.26953125MB
INFO:root:[   76] Training loss: 0.67126868, Validation loss: 0.66977695, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9633.91796875MB
INFO:root:[   77] Training loss: 0.67043816, Validation loss: 0.67024586, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9673.59375MB
INFO:root:[   78] Training loss: 0.67078905, Validation loss: 0.67245484, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9713.89453125MB
INFO:root:[   79] Training loss: 0.67054539, Validation loss: 0.67180169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9753.94140625MB
INFO:root:[   80] Training loss: 0.67034429, Validation loss: 0.67038665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9819.93359375MB
INFO:root:[   81] Training loss: 0.67036890, Validation loss: 0.67104819, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10085.15234375MB
INFO:root:[   82] Training loss: 0.67013553, Validation loss: 0.67055501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9945.5MB
INFO:root:[   83] Training loss: 0.67019500, Validation loss: 0.67055840, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9935.76171875MB
INFO:root:[   84] Training loss: 0.67034783, Validation loss: 0.66952551, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=9973.84375MB
INFO:root:[   85] Training loss: 0.67023480, Validation loss: 0.66918443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10011.85546875MB
INFO:root:[   86] Training loss: 0.66977141, Validation loss: 0.67010973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10049.953125MB
INFO:root:[   87] Training loss: 0.66983013, Validation loss: 0.66984544, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10274.94140625MB
INFO:root:[   88] Training loss: 0.66934224, Validation loss: 0.66945387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10126.01171875MB
INFO:root:[   89] Training loss: 0.66943587, Validation loss: 0.66912651, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10316.80859375MB
INFO:root:[   90] Training loss: 0.66977346, Validation loss: 0.67176463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10203.41796875MB
INFO:root:[   91] Training loss: 0.66951665, Validation loss: 0.66887166, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10241.87109375MB
INFO:root:[   92] Training loss: 0.66935001, Validation loss: 0.66905839, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10279.1640625MB
INFO:root:[   93] Training loss: 0.66940437, Validation loss: 0.66940401, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10317.02734375MB
INFO:root:[   94] Training loss: 0.66918592, Validation loss: 0.66834308, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10354.55078125MB
INFO:root:[   95] Training loss: 0.66902676, Validation loss: 0.66877640, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10394.38671875MB
INFO:root:[   96] Training loss: 0.66955692, Validation loss: 0.66972238, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10435.21875MB
INFO:root:[   97] Training loss: 0.66877149, Validation loss: 0.66880604, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10474.1015625MB
INFO:root:[   98] Training loss: 0.66931672, Validation loss: 0.66899407, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10513.21875MB
INFO:root:[   99] Training loss: 0.66915025, Validation loss: 0.66825964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10552.9609375MB
INFO:root:[  100] Training loss: 0.66861268, Validation loss: 0.66807148, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10594.82421875MB
INFO:root:[  101] Training loss: 0.66858661, Validation loss: 0.66809965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10635.8671875MB
INFO:root:[  102] Training loss: 0.66867685, Validation loss: 0.66849717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10675.46875MB
INFO:root:[  103] Training loss: 0.66884732, Validation loss: 0.66838816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10716.08984375MB
INFO:root:[  104] Training loss: 0.66863906, Validation loss: 0.66815407, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10755.9453125MB
INFO:root:[  105] Training loss: 0.66814742, Validation loss: 0.66855059, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10820.9921875MB
INFO:root:[  106] Training loss: 0.66892809, Validation loss: 0.66794506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10858.69140625MB
INFO:root:[  107] Training loss: 0.66853005, Validation loss: 0.66964322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10897.078125MB
INFO:root:[  108] Training loss: 0.66848415, Validation loss: 0.66897385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10935.45703125MB
INFO:root:[  109] Training loss: 0.66859516, Validation loss: 0.66877171, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=10974.07421875MB
INFO:root:[  110] Training loss: 0.66813435, Validation loss: 0.66877869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11012.21484375MB
INFO:root:[  111] Training loss: 0.66805100, Validation loss: 0.66843579, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11050.59375MB
INFO:root:[  112] Training loss: 0.66820507, Validation loss: 0.66824303, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11088.53515625MB
INFO:root:[  113] Training loss: 0.66807127, Validation loss: 0.66824038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11164.82421875MB
INFO:root:[  114] Training loss: 0.66779812, Validation loss: 0.66830969, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11168.64453125MB
INFO:root:[  115] Training loss: 0.66811291, Validation loss: 0.66775492, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11206.83984375MB
INFO:root:[  116] Training loss: 0.66751372, Validation loss: 0.66743320, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11244.859375MB
INFO:root:[  117] Training loss: 0.66745085, Validation loss: 0.66715739, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11283.0625MB
INFO:root:[  118] Training loss: 0.66753662, Validation loss: 0.66797504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11488.48828125MB
INFO:root:[  119] Training loss: 0.66752655, Validation loss: 0.66865468, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11359.31640625MB
INFO:root:[  120] Training loss: 0.66748112, Validation loss: 0.66724325, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11400.1875MB
INFO:root:[  121] Training loss: 0.66743637, Validation loss: 0.66687331, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11440.3984375MB
INFO:root:[  122] Training loss: 0.66729024, Validation loss: 0.66783991, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11480.27734375MB
INFO:root:[  123] Training loss: 0.66680095, Validation loss: 0.66780742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11521.375MB
INFO:root:[  124] Training loss: 0.66732924, Validation loss: 0.66631127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11560.90625MB
INFO:root:[  125] Training loss: 0.66713882, Validation loss: 0.66765364, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11600.9921875MB
INFO:root:[  126] Training loss: 0.66720392, Validation loss: 0.66955300, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11642.16015625MB
INFO:root:[  127] Training loss: 0.66653018, Validation loss: 0.66724853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11681.84375MB
INFO:root:[  128] Training loss: 0.66668382, Validation loss: 0.66706137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11746.3828125MB
INFO:root:[  129] Training loss: 0.66684873, Validation loss: 0.66654187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11784.5234375MB
INFO:root:[  130] Training loss: 0.66668863, Validation loss: 0.66681346, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11823.88671875MB
INFO:root:[  131] Training loss: 0.66653415, Validation loss: 0.66548771, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11861.59375MB
INFO:root:[  132] Training loss: 0.66658055, Validation loss: 0.66642691, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11899.97265625MB
INFO:root:[  133] Training loss: 0.66624177, Validation loss: 0.66648883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11938.11328125MB
INFO:root:[  134] Training loss: 0.66646796, Validation loss: 0.66636450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11976.48046875MB
INFO:root:[  135] Training loss: 0.66589344, Validation loss: 0.66623587, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12014.359375MB
INFO:root:[  136] Training loss: 0.66624813, Validation loss: 0.66963116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12052.49609375MB
INFO:root:[  137] Training loss: 0.66610030, Validation loss: 0.66476938, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12316.26953125MB
INFO:root:[  138] Training loss: 0.66582355, Validation loss: 0.66566458, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12128.76171875MB
INFO:root:[  139] Training loss: 0.66585432, Validation loss: 0.66553773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12166.9140625MB
INFO:root:[  140] Training loss: 0.66630330, Validation loss: 0.66578717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12206.5234375MB
INFO:root:[  141] Training loss: 0.66614238, Validation loss: 0.66536454, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12247.09765625MB
INFO:root:[  142] Training loss: 0.66583939, Validation loss: 0.66664161, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12288.1796875MB
INFO:root:[  143] Training loss: 0.66578263, Validation loss: 0.66664088, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12327.30859375MB
INFO:root:[  144] Training loss: 0.66685651, Validation loss: 0.66625626, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12367.6953125MB
INFO:root:[  145] Training loss: 0.66575005, Validation loss: 0.66572058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12408.61328125MB
INFO:root:[  146] Training loss: 0.66552257, Validation loss: 0.66674205, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12446.98828125MB
INFO:root:EP 146: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12454.79296875MB; mem (CPU total)=12487.58984375MB
INFO:root:Training the model took 5700.161s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94087
INFO:root:EnergyScoreTrain: 0.6622
INFO:root:CRPSTrain: 0.59493
INFO:root:Gaussian NLLTrain: 42206463608.60446
INFO:root:CoverageTrain: 0.62067
INFO:root:IntervalWidthTrain: 2.77956
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94466
INFO:root:EnergyScoreValidation: 0.6649
INFO:root:CRPSValidation: 0.59775
INFO:root:Gaussian NLLValidation: 42862322592.42666
INFO:root:CoverageValidation: 0.6216
INFO:root:IntervalWidthValidation: 2.78535
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94384
INFO:root:EnergyScoreTest: 0.66431
INFO:root:CRPSTest: 0.59748
INFO:root:Gaussian NLLTest: 42643405258.75202
INFO:root:CoverageTest: 0.62016
INFO:root:IntervalWidthTest: 2.78028
INFO:root:After validation: mem (CPU python)=12454.79296875MB; mem (CPU total)=12727.78125MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.79296875MB; mem (CPU total)=12553.56640625MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 195035136
INFO:root:After setting up the model: mem (CPU python)=12454.79296875MB; mem (CPU total)=12553.40625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12554.60546875MB
INFO:root:[    1] Training loss: 0.71412177, Validation loss: 0.70297717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12786.24609375MB
INFO:root:[    2] Training loss: 0.69888576, Validation loss: 0.69557480, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12660.5703125MB
INFO:root:[    3] Training loss: 0.69452382, Validation loss: 0.69220292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12963.2734375MB
INFO:root:[    4] Training loss: 0.69191717, Validation loss: 0.69067633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12736.296875MB
INFO:root:[    5] Training loss: 0.69021791, Validation loss: 0.68871850, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12774.70703125MB
INFO:root:[    6] Training loss: 0.68911662, Validation loss: 0.68798217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12812.05859375MB
INFO:root:[    7] Training loss: 0.68822537, Validation loss: 0.68744994, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12850.25MB
INFO:root:[    8] Training loss: 0.68750796, Validation loss: 0.68675043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12887.7421875MB
INFO:root:[    9] Training loss: 0.68698997, Validation loss: 0.68611198, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12925.7578125MB
INFO:root:[   10] Training loss: 0.68625352, Validation loss: 0.68656032, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12965.2734375MB
INFO:root:[   11] Training loss: 0.68604422, Validation loss: 0.68512769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13002.73046875MB
INFO:root:[   12] Training loss: 0.68560056, Validation loss: 0.68558633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13187.5703125MB
INFO:root:[   13] Training loss: 0.68498645, Validation loss: 0.68446618, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13080.36328125MB
INFO:root:[   14] Training loss: 0.68474680, Validation loss: 0.68373918, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13118.625MB
INFO:root:[   15] Training loss: 0.68432649, Validation loss: 0.68438909, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13156.6875MB
INFO:root:[   16] Training loss: 0.68386483, Validation loss: 0.68401141, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13197.03515625MB
INFO:root:[   17] Training loss: 0.68336776, Validation loss: 0.68311932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13237.91015625MB
INFO:root:[   18] Training loss: 0.68307943, Validation loss: 0.68208449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13278.36328125MB
INFO:root:[   19] Training loss: 0.68305199, Validation loss: 0.68324751, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13476.98828125MB
INFO:root:[   20] Training loss: 0.68285709, Validation loss: 0.68251786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14984.45703125MB
INFO:root:[   21] Training loss: 0.68204047, Validation loss: 0.68075744, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13397.984375MB
INFO:root:[   22] Training loss: 0.68193856, Validation loss: 0.68181612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13437.09375MB
INFO:root:[   23] Training loss: 0.68138611, Validation loss: 0.68026433, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13503.8203125MB
INFO:root:[   24] Training loss: 0.68106697, Validation loss: 0.68087872, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13520.38671875MB
INFO:root:[   25] Training loss: 0.68082766, Validation loss: 0.68025274, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13584.47265625MB
INFO:root:[   26] Training loss: 0.68029316, Validation loss: 0.67920553, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13623.046875MB
INFO:root:[   27] Training loss: 0.67989581, Validation loss: 0.67848587, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13661.3203125MB
INFO:root:[   28] Training loss: 0.67948867, Validation loss: 0.67840039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13945.12890625MB
INFO:root:[   29] Training loss: 0.67919758, Validation loss: 0.67834362, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13737.484375MB
INFO:root:[   30] Training loss: 0.67866746, Validation loss: 0.67912462, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=15391.79296875MB
INFO:root:[   31] Training loss: 0.67850276, Validation loss: 0.67808499, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13813.9921875MB
INFO:root:[   32] Training loss: 0.67833279, Validation loss: 0.67800623, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13852.8046875MB
INFO:root:[   33] Training loss: 0.67809000, Validation loss: 0.67709847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=15514.0625MB
INFO:root:[   34] Training loss: 0.67804893, Validation loss: 0.67637892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13928.625MB
INFO:root:[   35] Training loss: 0.67778272, Validation loss: 0.67604612, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=13966.90234375MB
INFO:root:[   36] Training loss: 0.67765737, Validation loss: 0.67743427, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14005.03515625MB
INFO:root:[   37] Training loss: 0.67725121, Validation loss: 0.67575748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14316.76171875MB
INFO:root:[   38] Training loss: 0.67701160, Validation loss: 0.67546124, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14085.640625MB
INFO:root:[   39] Training loss: 0.67667163, Validation loss: 0.67575927, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14125.71875MB
INFO:root:[   40] Training loss: 0.67669413, Validation loss: 0.67493112, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=18725.80078125MB
INFO:root:[   41] Training loss: 0.67644651, Validation loss: 0.67599285, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14332.3671875MB
INFO:root:[   42] Training loss: 0.67626823, Validation loss: 0.67431745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=18336.2890625MB
INFO:root:[   43] Training loss: 0.67591537, Validation loss: 0.67443387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=18389.234375MB
INFO:root:[   44] Training loss: 0.67563602, Validation loss: 0.67493859, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=18432.07421875MB
INFO:root:[   45] Training loss: 0.67562712, Validation loss: 0.67429506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=18471.96484375MB
INFO:root:[   46] Training loss: 0.67544850, Validation loss: 0.67412993, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=18511.4296875MB
INFO:root:[   47] Training loss: 0.67518141, Validation loss: 0.67436102, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=18577.6875MB
INFO:root:[   48] Training loss: 0.67489176, Validation loss: 0.67442743, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14519.72265625MB
INFO:root:[   49] Training loss: 0.67485315, Validation loss: 0.67342182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14557.65625MB
INFO:root:[   50] Training loss: 0.67458238, Validation loss: 0.67380564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11929.44140625MB
INFO:root:[   51] Training loss: 0.67452598, Validation loss: 0.67220105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11809.66015625MB
INFO:root:[   52] Training loss: 0.67444850, Validation loss: 0.67258501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12088.5MB
INFO:root:[   53] Training loss: 0.67410125, Validation loss: 0.67238715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=12185.19921875MB
INFO:root:[   54] Training loss: 0.67409939, Validation loss: 0.67241578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=11925.17578125MB
INFO:root:[   55] Training loss: 0.67381555, Validation loss: 0.67253811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14434.3125MB
INFO:root:[   56] Training loss: 0.67402066, Validation loss: 0.67295091, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14477.87109375MB
INFO:root:[   57] Training loss: 0.67386805, Validation loss: 0.67157774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=16138.9765625MB
INFO:root:[   58] Training loss: 0.67355236, Validation loss: 0.67172577, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14561.3515625MB
INFO:root:[   59] Training loss: 0.67333605, Validation loss: 0.67235499, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=16205.48046875MB
INFO:root:[   60] Training loss: 0.67335522, Validation loss: 0.67232725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14640.51171875MB
INFO:root:[   61] Training loss: 0.67334509, Validation loss: 0.67164126, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14859.8125MB
INFO:root:[   62] Training loss: 0.67316211, Validation loss: 0.67141310, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14721.31640625MB
INFO:root:[   63] Training loss: 0.67283540, Validation loss: 0.67217832, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14762.12890625MB
INFO:root:[   64] Training loss: 0.67281747, Validation loss: 0.67124453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.79296875MB; mem (CPU total)=14836.203125MB
INFO:root:[   65] Training loss: 0.67255866, Validation loss: 0.67163065, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12484.31640625MB; mem (CPU total)=14948.71875MB
INFO:root:[   66] Training loss: 0.67234062, Validation loss: 0.67045267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12522.4296875MB; mem (CPU total)=15082.53125MB
INFO:root:[   67] Training loss: 0.67210291, Validation loss: 0.67133363, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12560.5234375MB; mem (CPU total)=14924.92578125MB
INFO:root:[   68] Training loss: 0.67216288, Validation loss: 0.67107355, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12598.62890625MB; mem (CPU total)=14964.88671875MB
INFO:root:[   69] Training loss: 0.67217255, Validation loss: 0.67060247, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12636.7265625MB; mem (CPU total)=15005.29296875MB
INFO:root:[   70] Training loss: 0.67188731, Validation loss: 0.66998113, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12674.83203125MB; mem (CPU total)=15046.0234375MB
INFO:root:[   71] Training loss: 0.67177027, Validation loss: 0.67043313, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12712.9296875MB; mem (CPU total)=15251.3828125MB
INFO:root:[   72] Training loss: 0.67173932, Validation loss: 0.66998519, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12751.01171875MB; mem (CPU total)=15129.609375MB
INFO:root:[   73] Training loss: 0.67138883, Validation loss: 0.67066957, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12789.10546875MB; mem (CPU total)=15170.015625MB
INFO:root:[   74] Training loss: 0.67108293, Validation loss: 0.66939105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12827.20703125MB; mem (CPU total)=16770.12109375MB
INFO:root:[   75] Training loss: 0.67124997, Validation loss: 0.67031157, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12865.296875MB; mem (CPU total)=19481.62890625MB
INFO:root:[   76] Training loss: 0.67087384, Validation loss: 0.66984939, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12903.390625MB; mem (CPU total)=15289.32421875MB
INFO:root:[   77] Training loss: 0.67090260, Validation loss: 0.66965448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12941.484375MB; mem (CPU total)=15353.3828125MB
INFO:root:[   78] Training loss: 0.67072899, Validation loss: 0.66964977, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12979.58203125MB; mem (CPU total)=15391.875MB
INFO:root:[   79] Training loss: 0.67075840, Validation loss: 0.66957828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13017.67578125MB; mem (CPU total)=15431.23828125MB
INFO:root:[   80] Training loss: 0.67055437, Validation loss: 0.66860867, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13055.7734375MB; mem (CPU total)=15469.828125MB
INFO:root:[   81] Training loss: 0.67022340, Validation loss: 0.66896757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13093.87109375MB; mem (CPU total)=15746.9140625MB
INFO:root:[   82] Training loss: 0.67000663, Validation loss: 0.66851839, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13131.96875MB; mem (CPU total)=19680.640625MB
INFO:root:[   83] Training loss: 0.67005311, Validation loss: 0.66829647, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13170.0625MB; mem (CPU total)=15584.3515625MB
INFO:root:[   84] Training loss: 0.66999651, Validation loss: 0.66833187, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13208.15234375MB; mem (CPU total)=19781.734375MB
INFO:root:[   85] Training loss: 0.67001007, Validation loss: 0.66860013, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13246.25MB; mem (CPU total)=15864.81640625MB
INFO:root:[   86] Training loss: 0.66958719, Validation loss: 0.66883821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13284.34375MB; mem (CPU total)=15699.3359375MB
INFO:root:[   87] Training loss: 0.66967059, Validation loss: 0.66887607, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13322.44140625MB; mem (CPU total)=15737.3984375MB
INFO:root:[   88] Training loss: 0.66949528, Validation loss: 0.66834283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13360.5390625MB; mem (CPU total)=15775.60546875MB
INFO:root:[   89] Training loss: 0.66939919, Validation loss: 0.66774308, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13398.63671875MB; mem (CPU total)=16057.26953125MB
INFO:root:[   90] Training loss: 0.66926462, Validation loss: 0.66800407, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13436.7265625MB; mem (CPU total)=13549.20703125MB
INFO:root:[   91] Training loss: 0.66935042, Validation loss: 0.66733639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13474.828125MB; mem (CPU total)=13337.734375MB
INFO:root:[   92] Training loss: 0.66925587, Validation loss: 0.66854463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13512.91796875MB; mem (CPU total)=13375.7890625MB
INFO:root:[   93] Training loss: 0.66908647, Validation loss: 0.66694342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13551.015625MB; mem (CPU total)=13413.65234375MB
INFO:root:[   94] Training loss: 0.66906162, Validation loss: 0.66706905, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13589.109375MB; mem (CPU total)=13451.53125MB
INFO:root:[   95] Training loss: 0.66891158, Validation loss: 0.66712511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13627.203125MB; mem (CPU total)=13489.23828125MB
INFO:root:[   96] Training loss: 0.66889530, Validation loss: 0.66725609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13665.30078125MB; mem (CPU total)=13527.59375MB
INFO:root:[   97] Training loss: 0.66858171, Validation loss: 0.66756656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13703.39453125MB; mem (CPU total)=13565.4453125MB
INFO:root:[   98] Training loss: 0.66881335, Validation loss: 0.66770228, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13741.4921875MB; mem (CPU total)=13603.5859375MB
INFO:root:[   99] Training loss: 0.66858965, Validation loss: 0.66691960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13779.58984375MB; mem (CPU total)=13641.80859375MB
INFO:root:[  100] Training loss: 0.66845832, Validation loss: 0.66719299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13817.6796875MB; mem (CPU total)=13679.953125MB
INFO:root:[  101] Training loss: 0.66844706, Validation loss: 0.66704861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13855.7734375MB; mem (CPU total)=13718.08984375MB
INFO:root:[  102] Training loss: 0.66807824, Validation loss: 0.66717408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13893.87109375MB; mem (CPU total)=13755.96875MB
INFO:root:[  103] Training loss: 0.66821859, Validation loss: 0.66742808, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13931.96484375MB; mem (CPU total)=13849.28125MB
INFO:root:[  104] Training loss: 0.66834317, Validation loss: 0.66665067, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13970.0625MB; mem (CPU total)=17988.921875MB
INFO:root:[  105] Training loss: 0.66788217, Validation loss: 0.66650535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14008.16015625MB; mem (CPU total)=14069.2109375MB
INFO:root:[  106] Training loss: 0.66796427, Validation loss: 0.66711293, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14046.25390625MB; mem (CPU total)=14037.27734375MB
INFO:root:[  107] Training loss: 0.66815283, Validation loss: 0.66645937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14084.3515625MB; mem (CPU total)=14050.57421875MB
INFO:root:[  108] Training loss: 0.66807532, Validation loss: 0.66696701, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14122.4453125MB; mem (CPU total)=13984.35546875MB
INFO:root:[  109] Training loss: 0.66827810, Validation loss: 0.66651163, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14160.54296875MB; mem (CPU total)=14281.40234375MB
INFO:root:[  110] Training loss: 0.66786461, Validation loss: 0.66739202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14198.640625MB; mem (CPU total)=16570.38671875MB
INFO:root:[  111] Training loss: 0.66757735, Validation loss: 0.66667322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14236.73046875MB; mem (CPU total)=14097.96484375MB
INFO:root:[  112] Training loss: 0.66754773, Validation loss: 0.66647153, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14274.83203125MB; mem (CPU total)=14135.94921875MB
INFO:root:[  113] Training loss: 0.66756622, Validation loss: 0.66655846, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14312.92578125MB; mem (CPU total)=14174.2890625MB
INFO:root:[  114] Training loss: 0.66756212, Validation loss: 0.66616136, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14351.01953125MB; mem (CPU total)=14213.078125MB
INFO:root:[  115] Training loss: 0.66744136, Validation loss: 0.66681879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14389.1171875MB; mem (CPU total)=14250.84375MB
INFO:root:[  116] Training loss: 0.66730746, Validation loss: 0.66593150, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14427.21484375MB; mem (CPU total)=14429.171875MB
INFO:root:[  117] Training loss: 0.66722409, Validation loss: 0.66561169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14465.30859375MB; mem (CPU total)=14327.55078125MB
INFO:root:[  118] Training loss: 0.66714774, Validation loss: 0.66638570, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14503.3984375MB; mem (CPU total)=14523.359375MB
INFO:root:[  119] Training loss: 0.66722829, Validation loss: 0.66621535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14541.49609375MB; mem (CPU total)=14561.50390625MB
INFO:root:[  120] Training loss: 0.66691880, Validation loss: 0.66630506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14579.58984375MB; mem (CPU total)=14442.2890625MB
INFO:root:[  121] Training loss: 0.66694830, Validation loss: 0.66520924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14617.69140625MB; mem (CPU total)=14480.234375MB
INFO:root:[  122] Training loss: 0.66689980, Validation loss: 0.66619624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14655.7890625MB; mem (CPU total)=14696.00390625MB
INFO:root:[  123] Training loss: 0.66677807, Validation loss: 0.66590962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14693.8828125MB; mem (CPU total)=16770.4375MB
INFO:root:[  124] Training loss: 0.66682235, Validation loss: 0.66559199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14731.9765625MB; mem (CPU total)=14598.61328125MB
INFO:root:[  125] Training loss: 0.66652467, Validation loss: 0.66597129, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14770.07421875MB; mem (CPU total)=16847.1640625MB
INFO:root:[  126] Training loss: 0.66664121, Validation loss: 0.66494761, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14808.171875MB; mem (CPU total)=16884.328125MB
INFO:root:[  127] Training loss: 0.66648381, Validation loss: 0.66496308, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14846.26171875MB; mem (CPU total)=16933.39453125MB
INFO:root:[  128] Training loss: 0.66645321, Validation loss: 0.66523456, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14884.35546875MB; mem (CPU total)=16971.2265625MB
INFO:root:[  129] Training loss: 0.66655521, Validation loss: 0.66556256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14922.45703125MB; mem (CPU total)=17008.7265625MB
INFO:root:[  130] Training loss: 0.66644133, Validation loss: 0.66479121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14960.55078125MB; mem (CPU total)=17080.859375MB
INFO:root:[  131] Training loss: 0.66618909, Validation loss: 0.66545690, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14998.64453125MB; mem (CPU total)=17093.109375MB
INFO:root:[  132] Training loss: 0.66619605, Validation loss: 0.66534044, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15036.7421875MB; mem (CPU total)=17139.77734375MB
INFO:root:[  133] Training loss: 0.66615605, Validation loss: 0.66508584, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15074.8359375MB; mem (CPU total)=17169.6015625MB
INFO:root:[  134] Training loss: 0.66606571, Validation loss: 0.66477829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15112.93359375MB; mem (CPU total)=17204.98046875MB
INFO:root:[  135] Training loss: 0.66594309, Validation loss: 0.66513363, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15151.0234375MB; mem (CPU total)=17246.13671875MB
INFO:root:[  136] Training loss: 0.66601202, Validation loss: 0.66494870, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15189.12109375MB; mem (CPU total)=21947.3203125MB
INFO:root:[  137] Training loss: 0.66615708, Validation loss: 0.66446735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15227.21875MB; mem (CPU total)=19252.31640625MB
INFO:root:[  138] Training loss: 0.66582290, Validation loss: 0.66449754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15265.3125MB; mem (CPU total)=15271.80859375MB
INFO:root:[  139] Training loss: 0.66589432, Validation loss: 0.66484088, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15303.41015625MB; mem (CPU total)=17387.73046875MB
INFO:root:[  140] Training loss: 0.66560866, Validation loss: 0.66503023, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15341.50390625MB; mem (CPU total)=17427.2109375MB
INFO:root:[  141] Training loss: 0.66588214, Validation loss: 0.66379190, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15379.6015625MB; mem (CPU total)=17465.96875MB
INFO:root:[  142] Training loss: 0.66570699, Validation loss: 0.66399708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15417.6953125MB; mem (CPU total)=17503.6640625MB
INFO:root:[  143] Training loss: 0.66579270, Validation loss: 0.66425182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15455.7890625MB; mem (CPU total)=17547.8203125MB
INFO:root:[  144] Training loss: 0.66548151, Validation loss: 0.66419972, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15493.8828125MB; mem (CPU total)=17587.27734375MB
INFO:root:[  145] Training loss: 0.66557700, Validation loss: 0.66385451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15531.98046875MB; mem (CPU total)=17624.8671875MB
INFO:root:[  146] Training loss: 0.66545926, Validation loss: 0.66356197, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15570.078125MB; mem (CPU total)=17649.86328125MB
INFO:root:[  147] Training loss: 0.66538533, Validation loss: 0.66427547, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15608.171875MB; mem (CPU total)=17687.08203125MB
INFO:root:[  148] Training loss: 0.66532770, Validation loss: 0.66419280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15646.26171875MB; mem (CPU total)=17726.15625MB
INFO:root:[  149] Training loss: 0.66529079, Validation loss: 0.66419690, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15684.36328125MB; mem (CPU total)=17764.01171875MB
INFO:root:[  150] Training loss: 0.66522819, Validation loss: 0.66377007, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15722.45703125MB; mem (CPU total)=15596.00390625MB
INFO:root:[  151] Training loss: 0.66515294, Validation loss: 0.66424523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15760.55078125MB; mem (CPU total)=15633.90234375MB
INFO:root:[  152] Training loss: 0.66512613, Validation loss: 0.66429351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15798.6484375MB; mem (CPU total)=15671.05859375MB
INFO:root:[  153] Training loss: 0.66507772, Validation loss: 0.66462757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15836.75MB; mem (CPU total)=15708.76171875MB
INFO:root:[  154] Training loss: 0.66493130, Validation loss: 0.66344572, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15874.84375MB; mem (CPU total)=17972.21875MB
INFO:root:[  155] Training loss: 0.66489145, Validation loss: 0.66396478, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15912.9375MB; mem (CPU total)=18010.33984375MB
INFO:root:[  156] Training loss: 0.66495272, Validation loss: 0.66312079, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15951.0390625MB; mem (CPU total)=18054.78515625MB
INFO:root:[  157] Training loss: 0.66493667, Validation loss: 0.66376163, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15989.12890625MB; mem (CPU total)=18093.9296875MB
INFO:root:[  158] Training loss: 0.66485504, Validation loss: 0.66329412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16027.22265625MB; mem (CPU total)=18144.39453125MB
INFO:root:[  159] Training loss: 0.66465624, Validation loss: 0.66343390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16065.3203125MB; mem (CPU total)=18166.1015625MB
INFO:root:[  160] Training loss: 0.66476571, Validation loss: 0.66313204, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16103.4140625MB; mem (CPU total)=18202.26953125MB
INFO:root:[  161] Training loss: 0.66456684, Validation loss: 0.66338638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16141.51171875MB; mem (CPU total)=18239.921875MB
INFO:root:[  162] Training loss: 0.66457892, Validation loss: 0.66323138, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16179.60546875MB; mem (CPU total)=18277.8984375MB
INFO:root:[  163] Training loss: 0.66452574, Validation loss: 0.66322029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16217.703125MB; mem (CPU total)=18315.93359375MB
INFO:root:[  164] Training loss: 0.66443561, Validation loss: 0.66347895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16255.796875MB; mem (CPU total)=18353.60546875MB
INFO:root:[  165] Training loss: 0.66443735, Validation loss: 0.66297279, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16293.89453125MB; mem (CPU total)=18390.2109375MB
INFO:root:[  166] Training loss: 0.66450120, Validation loss: 0.66285727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16331.9921875MB; mem (CPU total)=18427.87890625MB
INFO:root:[  167] Training loss: 0.66433473, Validation loss: 0.66366677, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16370.08203125MB; mem (CPU total)=18466.01171875MB
INFO:root:[  168] Training loss: 0.66423068, Validation loss: 0.66309240, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16408.17578125MB; mem (CPU total)=18504.140625MB
INFO:root:[  169] Training loss: 0.66416872, Validation loss: 0.66307826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16446.26953125MB; mem (CPU total)=18541.9921875MB
INFO:root:[  170] Training loss: 0.66415265, Validation loss: 0.66352276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16484.3671875MB; mem (CPU total)=18580.13671875MB
INFO:root:[  171] Training loss: 0.66402939, Validation loss: 0.66319279, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16522.46484375MB; mem (CPU total)=18618.52734375MB
INFO:root:[  172] Training loss: 0.66386021, Validation loss: 0.66307605, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16560.55859375MB; mem (CPU total)=18656.42578125MB
INFO:root:[  173] Training loss: 0.66395142, Validation loss: 0.66281334, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16598.65625MB; mem (CPU total)=18694.19921875MB
INFO:root:[  174] Training loss: 0.66395050, Validation loss: 0.66284425, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16636.75MB; mem (CPU total)=18731.8828125MB
INFO:root:[  175] Training loss: 0.66404188, Validation loss: 0.66312277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16674.84375MB; mem (CPU total)=18769.4609375MB
INFO:root:[  176] Training loss: 0.66395083, Validation loss: 0.66380799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16712.94140625MB; mem (CPU total)=18807.59375MB
INFO:root:[  177] Training loss: 0.66379004, Validation loss: 0.66307297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16751.03515625MB; mem (CPU total)=18845.4765625MB
INFO:root:[  178] Training loss: 0.66370493, Validation loss: 0.66272781, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16789.1328125MB; mem (CPU total)=18884.0390625MB
INFO:root:[  179] Training loss: 0.66378505, Validation loss: 0.66293180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16827.22265625MB; mem (CPU total)=18922.42578125MB
INFO:root:[  180] Training loss: 0.66367994, Validation loss: 0.66243986, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16865.32421875MB; mem (CPU total)=18960.19921875MB
INFO:root:[  181] Training loss: 0.66382783, Validation loss: 0.66246808, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16903.41796875MB; mem (CPU total)=18998.34375MB
INFO:root:[  182] Training loss: 0.66362801, Validation loss: 0.66230629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16941.51171875MB; mem (CPU total)=19035.41015625MB
INFO:root:[  183] Training loss: 0.66372760, Validation loss: 0.66228054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16979.61328125MB; mem (CPU total)=19073.578125MB
INFO:root:[  184] Training loss: 0.66344521, Validation loss: 0.66185938, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17017.70703125MB; mem (CPU total)=19110.98046875MB
INFO:root:[  185] Training loss: 0.66340021, Validation loss: 0.66230206, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17055.796875MB; mem (CPU total)=19149.12890625MB
INFO:root:[  186] Training loss: 0.66335734, Validation loss: 0.66266576, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17093.890625MB; mem (CPU total)=19187.14453125MB
INFO:root:[  187] Training loss: 0.66345885, Validation loss: 0.66228521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17131.98828125MB; mem (CPU total)=19225.26171875MB
INFO:root:[  188] Training loss: 0.66364982, Validation loss: 0.66278398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17170.0859375MB; mem (CPU total)=19263.3984375MB
INFO:root:[  189] Training loss: 0.66329253, Validation loss: 0.66246085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17208.1796875MB; mem (CPU total)=19301.7265625MB
INFO:root:[  190] Training loss: 0.66330731, Validation loss: 0.66227545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17246.27734375MB; mem (CPU total)=19339.87109375MB
INFO:root:[  191] Training loss: 0.66322002, Validation loss: 0.66193949, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17284.37109375MB; mem (CPU total)=19377.67578125MB
INFO:root:[  192] Training loss: 0.66332057, Validation loss: 0.66154909, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17322.46875MB; mem (CPU total)=19497.71484375MB
INFO:root:[  193] Training loss: 0.66317526, Validation loss: 0.66235292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17360.5625MB; mem (CPU total)=19535.67578125MB
INFO:root:[  194] Training loss: 0.66312618, Validation loss: 0.66210161, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17398.65625MB; mem (CPU total)=19574.06640625MB
INFO:root:[  195] Training loss: 0.66313431, Validation loss: 0.66234704, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17436.75390625MB; mem (CPU total)=19612.12890625MB
INFO:root:[  196] Training loss: 0.66289624, Validation loss: 0.66235359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17474.84765625MB; mem (CPU total)=19650.96484375MB
INFO:root:[  197] Training loss: 0.66311381, Validation loss: 0.66207821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17512.9453125MB; mem (CPU total)=19689.12890625MB
INFO:root:[  198] Training loss: 0.66301858, Validation loss: 0.66171088, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17551.0390625MB; mem (CPU total)=19727.99609375MB
INFO:root:[  199] Training loss: 0.66315673, Validation loss: 0.66241405, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17589.1328125MB; mem (CPU total)=19765.78515625MB
INFO:root:[  200] Training loss: 0.66302794, Validation loss: 0.66258753, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17627.23046875MB; mem (CPU total)=19802.22265625MB
INFO:root:[  201] Training loss: 0.66299364, Validation loss: 0.66332311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17665.32421875MB; mem (CPU total)=19856.3125MB
INFO:root:EP 201: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=17703.41796875MB; mem (CPU total)=19894.2890625MB
INFO:root:Training the model took 8970.519s.
INFO:root:Emptying the cuda cache took 0.007s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93619
INFO:root:EnergyScoreTrain: 0.65887
INFO:root:CRPSTrain: 0.569
INFO:root:Gaussian NLLTrain: 36685937889.28005
INFO:root:CoverageTrain: 0.72127
INFO:root:IntervalWidthTrain: 3.05816
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93983
INFO:root:EnergyScoreValidation: 0.66145
INFO:root:CRPSValidation: 0.57152
INFO:root:Gaussian NLLValidation: 37141221248.5689
INFO:root:CoverageValidation: 0.7225
INFO:root:IntervalWidthValidation: 3.06452
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93891
INFO:root:EnergyScoreTest: 0.66078
INFO:root:CRPSTest: 0.57132
INFO:root:Gaussian NLLTest: 37228039700.48
INFO:root:CoverageTest: 0.72134
INFO:root:IntervalWidthTest: 3.05993
INFO:root:After validation: mem (CPU python)=17793.3046875MB; mem (CPU total)=19973.76171875MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=17793.3046875MB; mem (CPU total)=19928.37890625MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 174063616
INFO:root:After setting up the model: mem (CPU python)=17793.3046875MB; mem (CPU total)=19931.02734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=17793.3046875MB; mem (CPU total)=19931.27734375MB
INFO:root:[    1] Training loss: 0.71439335, Validation loss: 0.70306335, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17793.3046875MB; mem (CPU total)=19972.76171875MB
INFO:root:[    2] Training loss: 0.69918742, Validation loss: 0.69511580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17815.30078125MB; mem (CPU total)=20010.453125MB
INFO:root:[    3] Training loss: 0.69433067, Validation loss: 0.69121181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17853.41015625MB; mem (CPU total)=20048.53515625MB
INFO:root:[    4] Training loss: 0.69172953, Validation loss: 0.68991686, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17891.52734375MB; mem (CPU total)=20085.203125MB
INFO:root:[    5] Training loss: 0.69016144, Validation loss: 0.68833353, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17929.63671875MB; mem (CPU total)=20121.16015625MB
INFO:root:[    6] Training loss: 0.68925966, Validation loss: 0.68825131, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17967.74609375MB; mem (CPU total)=20158.01953125MB
INFO:root:[    7] Training loss: 0.68837044, Validation loss: 0.68711400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18005.859375MB; mem (CPU total)=20183.28125MB
INFO:root:[    8] Training loss: 0.68767636, Validation loss: 0.68641138, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18043.953125MB; mem (CPU total)=20220.46484375MB
INFO:root:[    9] Training loss: 0.68736539, Validation loss: 0.68577531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18082.0546875MB; mem (CPU total)=20265.375MB
INFO:root:[   10] Training loss: 0.68677889, Validation loss: 0.68658460, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18120.1484375MB; mem (CPU total)=20306.00390625MB
INFO:root:[   11] Training loss: 0.68618283, Validation loss: 0.68577221, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18158.24609375MB; mem (CPU total)=20342.046875MB
INFO:root:[   12] Training loss: 0.68591370, Validation loss: 0.68538693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18196.33984375MB; mem (CPU total)=20376.35546875MB
INFO:root:[   13] Training loss: 0.68548998, Validation loss: 0.68480235, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18234.43359375MB; mem (CPU total)=20410.55078125MB
INFO:root:[   14] Training loss: 0.68495316, Validation loss: 0.68352558, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18272.53125MB; mem (CPU total)=20470.5625MB
INFO:root:[   15] Training loss: 0.68441258, Validation loss: 0.68465331, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18310.625MB; mem (CPU total)=20508.46875MB
INFO:root:[   16] Training loss: 0.68419832, Validation loss: 0.68281836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18348.71875MB; mem (CPU total)=20545.9609375MB
INFO:root:[   17] Training loss: 0.68371868, Validation loss: 0.68268427, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18386.8203125MB; mem (CPU total)=20583.83203125MB
INFO:root:[   18] Training loss: 0.68346266, Validation loss: 0.68211347, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18424.9140625MB; mem (CPU total)=20621.17578125MB
INFO:root:[   19] Training loss: 0.68313729, Validation loss: 0.68193085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18463.0078125MB; mem (CPU total)=20658.6171875MB
INFO:root:[   20] Training loss: 0.68274951, Validation loss: 0.68076521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18501.1015625MB; mem (CPU total)=20695.91796875MB
INFO:root:[   21] Training loss: 0.68197328, Validation loss: 0.67975809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18539.19921875MB; mem (CPU total)=20732.74609375MB
INFO:root:[   22] Training loss: 0.68162343, Validation loss: 0.68075253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18577.29296875MB; mem (CPU total)=20769.16796875MB
INFO:root:[   23] Training loss: 0.68104711, Validation loss: 0.67941545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18615.38671875MB; mem (CPU total)=20805.3359375MB
INFO:root:[   24] Training loss: 0.68122543, Validation loss: 0.68005146, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18653.484375MB; mem (CPU total)=18527.12109375MB
INFO:root:[   25] Training loss: 0.68088496, Validation loss: 0.67882472, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18691.58203125MB; mem (CPU total)=18565.6796875MB
INFO:root:[   26] Training loss: 0.68065443, Validation loss: 0.67837993, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18729.67578125MB; mem (CPU total)=18603.65234375MB
INFO:root:[   27] Training loss: 0.68025652, Validation loss: 0.67860252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18767.76953125MB; mem (CPU total)=18641.75390625MB
INFO:root:[   28] Training loss: 0.67962233, Validation loss: 0.67866976, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18805.86328125MB; mem (CPU total)=18679.8984375MB
INFO:root:[   29] Training loss: 0.67949083, Validation loss: 0.67810233, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18843.9609375MB; mem (CPU total)=18718.54296875MB
INFO:root:[   30] Training loss: 0.67913499, Validation loss: 0.67732306, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18882.0546875MB; mem (CPU total)=18756.18359375MB
INFO:root:[   31] Training loss: 0.67910721, Validation loss: 0.67841564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18920.15234375MB; mem (CPU total)=18794.37890625MB
INFO:root:[   32] Training loss: 0.67881156, Validation loss: 0.67753401, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18958.24609375MB; mem (CPU total)=18832.76953125MB
INFO:root:[   33] Training loss: 0.67822575, Validation loss: 0.67744167, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18996.33984375MB; mem (CPU total)=18871.16796875MB
INFO:root:[   34] Training loss: 0.67838309, Validation loss: 0.67723471, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19034.44140625MB; mem (CPU total)=18908.9765625MB
INFO:root:[   35] Training loss: 0.67802382, Validation loss: 0.67598385, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19072.53515625MB; mem (CPU total)=18947.4609375MB
INFO:root:[   36] Training loss: 0.67796564, Validation loss: 0.67683252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19110.625MB; mem (CPU total)=18985.63671875MB
INFO:root:[   37] Training loss: 0.67727116, Validation loss: 0.67532959, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19148.72265625MB; mem (CPU total)=19023.671875MB
INFO:root:[   38] Training loss: 0.67728977, Validation loss: 0.67571413, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19186.81640625MB; mem (CPU total)=19062.078125MB
INFO:root:[   39] Training loss: 0.67703018, Validation loss: 0.67549140, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19224.91796875MB; mem (CPU total)=19099.99609375MB
INFO:root:[   40] Training loss: 0.67669496, Validation loss: 0.67405607, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19263.01171875MB; mem (CPU total)=19138.0546875MB
INFO:root:[   41] Training loss: 0.67670555, Validation loss: 0.67562735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19301.109375MB; mem (CPU total)=19176.4296875MB
INFO:root:[   42] Training loss: 0.67652742, Validation loss: 0.67516156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19339.203125MB; mem (CPU total)=19214.34765625MB
INFO:root:[   43] Training loss: 0.67639608, Validation loss: 0.67440147, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19377.296875MB; mem (CPU total)=19252.50390625MB
INFO:root:[   44] Training loss: 0.67606432, Validation loss: 0.67418351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19415.39453125MB; mem (CPU total)=19290.9609375MB
INFO:root:[   45] Training loss: 0.67585017, Validation loss: 0.67371754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19453.4921875MB; mem (CPU total)=19329.3984375MB
INFO:root:[   46] Training loss: 0.67569260, Validation loss: 0.67324227, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19491.5859375MB; mem (CPU total)=19366.265625MB
INFO:root:[   47] Training loss: 0.67560726, Validation loss: 0.67411170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19529.67578125MB; mem (CPU total)=19403.69140625MB
INFO:root:[   48] Training loss: 0.67535623, Validation loss: 0.67349039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19567.77734375MB; mem (CPU total)=19441.91015625MB
INFO:root:[   49] Training loss: 0.67512597, Validation loss: 0.67391058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19605.87109375MB; mem (CPU total)=19479.9921875MB
INFO:root:[   50] Training loss: 0.67501148, Validation loss: 0.67307790, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19643.96875MB; mem (CPU total)=19517.46484375MB
INFO:root:[   51] Training loss: 0.67487969, Validation loss: 0.67219486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19682.0703125MB; mem (CPU total)=19556.015625MB
INFO:root:[   52] Training loss: 0.67465197, Validation loss: 0.67229765, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19720.16015625MB; mem (CPU total)=19594.1796875MB
INFO:root:[   53] Training loss: 0.67444932, Validation loss: 0.67210365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19758.2578125MB; mem (CPU total)=19630.96484375MB
INFO:root:[   54] Training loss: 0.67432803, Validation loss: 0.67259216, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19796.34765625MB; mem (CPU total)=19669.10546875MB
INFO:root:[   55] Training loss: 0.67394222, Validation loss: 0.67149113, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19834.44921875MB; mem (CPU total)=19706.31640625MB
INFO:root:[   56] Training loss: 0.67416987, Validation loss: 0.67201875, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19872.54296875MB; mem (CPU total)=19744.7265625MB
INFO:root:[   57] Training loss: 0.67396629, Validation loss: 0.67164322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19910.63671875MB; mem (CPU total)=19782.86328125MB
INFO:root:[   58] Training loss: 0.67366684, Validation loss: 0.67162307, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19948.734375MB; mem (CPU total)=19821.25390625MB
INFO:root:[   59] Training loss: 0.67348160, Validation loss: 0.67165400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19986.828125MB; mem (CPU total)=19859.08984375MB
INFO:root:[   60] Training loss: 0.67342620, Validation loss: 0.67077980, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20024.92578125MB; mem (CPU total)=19897.05078125MB
INFO:root:[   61] Training loss: 0.67347753, Validation loss: 0.67127565, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20063.01953125MB; mem (CPU total)=19935.2109375MB
INFO:root:[   62] Training loss: 0.67342887, Validation loss: 0.67065360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20101.1171875MB; mem (CPU total)=19973.6171875MB
INFO:root:[   63] Training loss: 0.67284220, Validation loss: 0.67117124, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20139.2109375MB; mem (CPU total)=20011.51171875MB
INFO:root:[   64] Training loss: 0.67308087, Validation loss: 0.67010105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20177.30859375MB; mem (CPU total)=20049.59375MB
INFO:root:[   65] Training loss: 0.67258836, Validation loss: 0.67026555, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20215.40234375MB; mem (CPU total)=20087.625MB
INFO:root:[   66] Training loss: 0.67256400, Validation loss: 0.67041283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20253.49609375MB; mem (CPU total)=20125.546875MB
INFO:root:[   67] Training loss: 0.67229967, Validation loss: 0.67124659, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20291.58984375MB; mem (CPU total)=20163.7109375MB
INFO:root:[   68] Training loss: 0.67230070, Validation loss: 0.67117239, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20329.6875MB; mem (CPU total)=20201.875MB
INFO:root:[   69] Training loss: 0.67234471, Validation loss: 0.67009123, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20367.78515625MB; mem (CPU total)=20240.328125MB
INFO:root:[   70] Training loss: 0.67206342, Validation loss: 0.66994928, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20405.87890625MB; mem (CPU total)=20278.67578125MB
INFO:root:[   71] Training loss: 0.67202592, Validation loss: 0.66965848, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20443.97265625MB; mem (CPU total)=20316.890625MB
INFO:root:[   72] Training loss: 0.67172219, Validation loss: 0.66982748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20482.0703125MB; mem (CPU total)=20355.31640625MB
INFO:root:[   73] Training loss: 0.67143658, Validation loss: 0.66898322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20520.16796875MB; mem (CPU total)=20393.5703125MB
INFO:root:[   74] Training loss: 0.67127792, Validation loss: 0.66925606, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20558.2578125MB; mem (CPU total)=20431.96875MB
INFO:root:[   75] Training loss: 0.67121590, Validation loss: 0.66925376, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20596.35546875MB; mem (CPU total)=20469.88671875MB
INFO:root:[   76] Training loss: 0.67136410, Validation loss: 0.66852199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20635.203125MB; mem (CPU total)=20508.42578125MB
INFO:root:[   77] Training loss: 0.67178477, Validation loss: 0.66986621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20673.29296875MB; mem (CPU total)=20546.55078125MB
INFO:root:[   78] Training loss: 0.67168072, Validation loss: 0.66893742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20711.390625MB; mem (CPU total)=20584.71484375MB
INFO:root:[   79] Training loss: 0.67089555, Validation loss: 0.66897218, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20749.484375MB; mem (CPU total)=20621.85546875MB
INFO:root:[   80] Training loss: 0.67082482, Validation loss: 0.66817124, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20787.58203125MB; mem (CPU total)=20661.0390625MB
INFO:root:[   81] Training loss: 0.67053221, Validation loss: 0.66813520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20825.67578125MB; mem (CPU total)=20699.34375MB
INFO:root:[   82] Training loss: 0.67040557, Validation loss: 0.66800437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20863.77734375MB; mem (CPU total)=20737.4765625MB
INFO:root:[   83] Training loss: 0.67040050, Validation loss: 0.66793189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20901.875MB; mem (CPU total)=20775.7578125MB
INFO:root:[   84] Training loss: 0.67040673, Validation loss: 0.66710448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20939.96875MB; mem (CPU total)=20814.171875MB
INFO:root:[   85] Training loss: 0.67026755, Validation loss: 0.66841387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20978.06640625MB; mem (CPU total)=20852.3359375MB
INFO:root:[   86] Training loss: 0.67017651, Validation loss: 0.66764856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21016.203125MB; mem (CPU total)=20890.74609375MB
INFO:root:[   87] Training loss: 0.67005510, Validation loss: 0.66779900, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21054.30078125MB; mem (CPU total)=20928.91015625MB
INFO:root:[   88] Training loss: 0.66998086, Validation loss: 0.66748007, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21092.39453125MB; mem (CPU total)=20967.07421875MB
INFO:root:[   89] Training loss: 0.66983740, Validation loss: 0.66745540, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21130.4921875MB; mem (CPU total)=21005.453125MB
INFO:root:[   90] Training loss: 0.66995928, Validation loss: 0.66682449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21168.5859375MB; mem (CPU total)=21043.86328125MB
INFO:root:[   91] Training loss: 0.66987697, Validation loss: 0.66776604, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21206.6796875MB; mem (CPU total)=21081.78125MB
INFO:root:[   92] Training loss: 0.66986299, Validation loss: 0.66761786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21244.77734375MB; mem (CPU total)=21119.7265625MB
INFO:root:[   93] Training loss: 0.66975741, Validation loss: 0.66679794, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21282.875MB; mem (CPU total)=21157.5546875MB
INFO:root:[   94] Training loss: 0.66957804, Validation loss: 0.66721023, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21320.96484375MB; mem (CPU total)=21195.91796875MB
INFO:root:[   95] Training loss: 0.66936868, Validation loss: 0.66728189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21359.0625MB; mem (CPU total)=21234.04296875MB
INFO:root:[   96] Training loss: 0.66935571, Validation loss: 0.66660895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21397.16015625MB; mem (CPU total)=21272.21875MB
INFO:root:[   97] Training loss: 0.66914501, Validation loss: 0.66763041, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21435.25390625MB; mem (CPU total)=21310.58984375MB
INFO:root:[   98] Training loss: 0.66934974, Validation loss: 0.66739011, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21473.34765625MB; mem (CPU total)=21348.71484375MB
INFO:root:[   99] Training loss: 0.66919202, Validation loss: 0.66623200, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21511.4453125MB; mem (CPU total)=21387.046875MB
INFO:root:[  100] Training loss: 0.66903438, Validation loss: 0.66622647, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21549.54296875MB; mem (CPU total)=21425.59765625MB
INFO:root:[  101] Training loss: 0.66935370, Validation loss: 0.66710845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21587.6328125MB; mem (CPU total)=21463.48828125MB
INFO:root:[  102] Training loss: 0.66884383, Validation loss: 0.66648877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21625.73046875MB; mem (CPU total)=21501.62890625MB
INFO:root:[  103] Training loss: 0.66895628, Validation loss: 0.66657120, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21663.82421875MB; mem (CPU total)=21539.51171875MB
INFO:root:[  104] Training loss: 0.66925512, Validation loss: 0.66649292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21701.921875MB; mem (CPU total)=21578.3984375MB
INFO:root:[  105] Training loss: 0.66891159, Validation loss: 0.66609242, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21740.015625MB; mem (CPU total)=21616.03125MB
INFO:root:[  106] Training loss: 0.66895471, Validation loss: 0.66704759, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21778.11328125MB; mem (CPU total)=21654.14453125MB
INFO:root:[  107] Training loss: 0.66892544, Validation loss: 0.66639449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21816.20703125MB; mem (CPU total)=21692.53515625MB
INFO:root:[  108] Training loss: 0.66900482, Validation loss: 0.66638786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21854.30078125MB; mem (CPU total)=21730.671875MB
INFO:root:[  109] Training loss: 0.66918072, Validation loss: 0.66617990, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21892.3984375MB; mem (CPU total)=21768.546875MB
INFO:root:[  110] Training loss: 0.66896989, Validation loss: 0.66744381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21930.4921875MB; mem (CPU total)=21806.91015625MB
INFO:root:[  111] Training loss: 0.66875299, Validation loss: 0.66679683, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21968.5859375MB; mem (CPU total)=21844.953125MB
INFO:root:[  112] Training loss: 0.66848675, Validation loss: 0.66639508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22006.68359375MB; mem (CPU total)=21882.8515625MB
INFO:root:[  113] Training loss: 0.66872218, Validation loss: 0.66677108, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22044.78125MB; mem (CPU total)=21921.2421875MB
INFO:root:[  114] Training loss: 0.66868234, Validation loss: 0.66626808, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22082.875MB; mem (CPU total)=21959.12890625MB
INFO:root:EP 114: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=22120.96875MB; mem (CPU total)=21997.2578125MB
INFO:root:Training the model took 5716.779s.
INFO:root:Emptying the cuda cache took 0.007s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94364
INFO:root:EnergyScoreTrain: 0.66412
INFO:root:CRPSTrain: 0.58851
INFO:root:Gaussian NLLTrain: 57362183682.27558
INFO:root:CoverageTrain: 0.65369
INFO:root:IntervalWidthTrain: 2.89447
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94614
INFO:root:EnergyScoreValidation: 0.6659
INFO:root:CRPSValidation: 0.59049
INFO:root:Gaussian NLLValidation: 57774842365.72446
INFO:root:CoverageValidation: 0.65442
INFO:root:IntervalWidthValidation: 2.89807
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94541
INFO:root:EnergyScoreTest: 0.66538
INFO:root:CRPSTest: 0.59004
INFO:root:Gaussian NLLTest: 57815172153.34401
INFO:root:CoverageTest: 0.65453
INFO:root:IntervalWidthTest: 2.89761
INFO:root:After validation: mem (CPU python)=22187.87109375MB; mem (CPU total)=22065.4375MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=22187.87109375MB; mem (CPU total)=22065.4375MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 297795584
INFO:root:After setting up the model: mem (CPU python)=22187.96875MB; mem (CPU total)=22065.4375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=22187.96875MB; mem (CPU total)=22065.43359375MB
INFO:root:[    1] Training loss: 0.71487094, Validation loss: 0.70366521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22226.046875MB; mem (CPU total)=22103.92578125MB
INFO:root:[    2] Training loss: 0.69989872, Validation loss: 0.69601418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22264.15625MB; mem (CPU total)=22141.90625MB
INFO:root:[    3] Training loss: 0.69465251, Validation loss: 0.69059199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22302.2734375MB; mem (CPU total)=22179.98828125MB
INFO:root:[    4] Training loss: 0.69190931, Validation loss: 0.68894262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22340.37109375MB; mem (CPU total)=22218.65625MB
INFO:root:[    5] Training loss: 0.69088551, Validation loss: 0.68869431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22378.46484375MB; mem (CPU total)=22257.16796875MB
INFO:root:[    6] Training loss: 0.69016364, Validation loss: 0.68751022, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22416.55859375MB; mem (CPU total)=22295.0546875MB
INFO:root:[    7] Training loss: 0.68921356, Validation loss: 0.68705369, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22454.65625MB; mem (CPU total)=22333.5078125MB
INFO:root:[    8] Training loss: 0.68888454, Validation loss: 0.68781083, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22492.75MB; mem (CPU total)=22371.8984375MB
INFO:root:[    9] Training loss: 0.68829646, Validation loss: 0.68715423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22530.84375MB; mem (CPU total)=22410.04296875MB
INFO:root:[   10] Training loss: 0.68766182, Validation loss: 0.68727713, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22568.94140625MB; mem (CPU total)=22447.97265625MB
INFO:root:[   11] Training loss: 0.68694204, Validation loss: 0.68425303, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22607.0390625MB; mem (CPU total)=22486.234375MB
INFO:root:[   12] Training loss: 0.68709169, Validation loss: 0.68537764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22645.12890625MB; mem (CPU total)=22524.59375MB
INFO:root:[   13] Training loss: 0.68628952, Validation loss: 0.68416625, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22683.23046875MB; mem (CPU total)=22562.59765625MB
INFO:root:[   14] Training loss: 0.68583582, Validation loss: 0.68456901, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22721.32421875MB; mem (CPU total)=22600.984375MB
INFO:root:[   15] Training loss: 0.68539710, Validation loss: 0.68355450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22759.41796875MB; mem (CPU total)=22639.23828125MB
INFO:root:[   16] Training loss: 0.68511427, Validation loss: 0.68257498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22797.515625MB; mem (CPU total)=22677.8671875MB
INFO:root:[   17] Training loss: 0.68445403, Validation loss: 0.68177230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22835.6171875MB; mem (CPU total)=22715.34765625MB
INFO:root:[   18] Training loss: 0.68418265, Validation loss: 0.68270401, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22873.71875MB; mem (CPU total)=22753.515625MB
INFO:root:[   19] Training loss: 0.68384441, Validation loss: 0.68090378, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22911.81640625MB; mem (CPU total)=22792.02734375MB
INFO:root:[   20] Training loss: 0.68378070, Validation loss: 0.68156659, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22949.91015625MB; mem (CPU total)=22830.171875MB
INFO:root:[   21] Training loss: 0.68293538, Validation loss: 0.68038299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22988.0078125MB; mem (CPU total)=22867.14453125MB
INFO:root:[   22] Training loss: 0.68240432, Validation loss: 0.67991418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23026.08984375MB; mem (CPU total)=22905.21484375MB
INFO:root:[   23] Training loss: 0.68218410, Validation loss: 0.67803687, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23064.18359375MB; mem (CPU total)=22942.88671875MB
INFO:root:[   24] Training loss: 0.68173465, Validation loss: 0.67962437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23102.28125MB; mem (CPU total)=22981.08203125MB
INFO:root:[   25] Training loss: 0.68149089, Validation loss: 0.67882987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23140.375MB; mem (CPU total)=23019.4609375MB
INFO:root:[   26] Training loss: 0.68131026, Validation loss: 0.67831277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23178.46875MB; mem (CPU total)=23057.375MB
INFO:root:[   27] Training loss: 0.68088778, Validation loss: 0.67840515, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23216.56640625MB; mem (CPU total)=23095.22265625MB
INFO:root:[   28] Training loss: 0.68037093, Validation loss: 0.67707126, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23254.6640625MB; mem (CPU total)=23133.49609375MB
INFO:root:[   29] Training loss: 0.68030466, Validation loss: 0.67648511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23292.7578125MB; mem (CPU total)=23171.26171875MB
INFO:root:[   30] Training loss: 0.68008694, Validation loss: 0.67715116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23330.85546875MB; mem (CPU total)=23209.671875MB
INFO:root:[   31] Training loss: 0.67995764, Validation loss: 0.67664141, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23368.94921875MB; mem (CPU total)=23247.83203125MB
INFO:root:[   32] Training loss: 0.67938357, Validation loss: 0.67637815, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23407.046875MB; mem (CPU total)=23285.83203125MB
INFO:root:[   33] Training loss: 0.67922038, Validation loss: 0.67568141, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23445.140625MB; mem (CPU total)=23324.78515625MB
INFO:root:[   34] Training loss: 0.67906709, Validation loss: 0.67548733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23483.23828125MB; mem (CPU total)=23362.921875MB
INFO:root:[   35] Training loss: 0.67875330, Validation loss: 0.67613801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23521.328125MB; mem (CPU total)=23401.33203125MB
INFO:root:[   36] Training loss: 0.67877081, Validation loss: 0.67537952, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23559.42578125MB; mem (CPU total)=23439.57421875MB
INFO:root:[   37] Training loss: 0.67848848, Validation loss: 0.67441247, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23597.5234375MB; mem (CPU total)=23478.3203125MB
INFO:root:[   38] Training loss: 0.67843381, Validation loss: 0.67445727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23635.6171875MB; mem (CPU total)=23516.7109375MB
INFO:root:[   39] Training loss: 0.67786118, Validation loss: 0.67495546, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23673.7109375MB; mem (CPU total)=23554.8359375MB
INFO:root:[   40] Training loss: 0.67775312, Validation loss: 0.67301054, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23711.80859375MB; mem (CPU total)=23593.015625MB
INFO:root:[   41] Training loss: 0.67763151, Validation loss: 0.67481174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23749.90234375MB; mem (CPU total)=23631.1796875MB
INFO:root:[   42] Training loss: 0.67734465, Validation loss: 0.67432184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23787.99609375MB; mem (CPU total)=23669.34375MB
INFO:root:[   43] Training loss: 0.67715767, Validation loss: 0.67331856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23826.08984375MB; mem (CPU total)=23707.7109375MB
INFO:root:[   44] Training loss: 0.67681775, Validation loss: 0.67406121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23864.1875MB; mem (CPU total)=23745.3828125MB
INFO:root:[   45] Training loss: 0.67684630, Validation loss: 0.67350778, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23902.28125MB; mem (CPU total)=23783.078125MB
INFO:root:[   46] Training loss: 0.67664814, Validation loss: 0.67317415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23940.37890625MB; mem (CPU total)=23821.39453125MB
INFO:root:[   47] Training loss: 0.67660223, Validation loss: 0.67330736, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23978.4765625MB; mem (CPU total)=23859.63671875MB
INFO:root:[   48] Training loss: 0.67629155, Validation loss: 0.67392353, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24016.5703125MB; mem (CPU total)=23897.72265625MB
INFO:root:[   49] Training loss: 0.67616918, Validation loss: 0.67385229, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24054.6640625MB; mem (CPU total)=23935.88671875MB
INFO:root:[   50] Training loss: 0.67595170, Validation loss: 0.67347539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24092.7578125MB; mem (CPU total)=23974.27734375MB
INFO:root:[   51] Training loss: 0.67612009, Validation loss: 0.67152522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24130.859375MB; mem (CPU total)=24012.73046875MB
INFO:root:[   52] Training loss: 0.67582037, Validation loss: 0.67206244, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24168.94921875MB; mem (CPU total)=24050.65625MB
INFO:root:[   53] Training loss: 0.67561213, Validation loss: 0.67184108, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24207.04296875MB; mem (CPU total)=24088.80859375MB
INFO:root:[   54] Training loss: 0.67553222, Validation loss: 0.67171106, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24245.140625MB; mem (CPU total)=24127.2109375MB
INFO:root:[   55] Training loss: 0.67517113, Validation loss: 0.67111865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24283.23828125MB; mem (CPU total)=24165.4375MB
INFO:root:[   56] Training loss: 0.67517636, Validation loss: 0.67213220, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24321.33203125MB; mem (CPU total)=24203.1796875MB
INFO:root:[   57] Training loss: 0.67523486, Validation loss: 0.67170596, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24359.42578125MB; mem (CPU total)=24241.2890625MB
INFO:root:[   58] Training loss: 0.67506668, Validation loss: 0.67135367, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24397.5234375MB; mem (CPU total)=24279.4453125MB
INFO:root:[   59] Training loss: 0.67482507, Validation loss: 0.67140132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24435.62109375MB; mem (CPU total)=24317.6640625MB
INFO:root:[   60] Training loss: 0.67478056, Validation loss: 0.67131751, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24473.71484375MB; mem (CPU total)=24355.80859375MB
INFO:root:[   61] Training loss: 0.67471495, Validation loss: 0.67097748, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24511.8125MB; mem (CPU total)=24394.1171875MB
INFO:root:[   62] Training loss: 0.67463262, Validation loss: 0.67060264, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24549.91015625MB; mem (CPU total)=24432.78515625MB
INFO:root:[   63] Training loss: 0.67432209, Validation loss: 0.67160408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24588.00390625MB; mem (CPU total)=24471.17578125MB
INFO:root:[   64] Training loss: 0.67461344, Validation loss: 0.67075941, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24626.1015625MB; mem (CPU total)=24508.8125MB
INFO:root:[   65] Training loss: 0.67422950, Validation loss: 0.67105817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24664.1953125MB; mem (CPU total)=24546.93359375MB
INFO:root:[   66] Training loss: 0.67390576, Validation loss: 0.67028298, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24702.29296875MB; mem (CPU total)=24585.15625MB
INFO:root:[   67] Training loss: 0.67385733, Validation loss: 0.67031418, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24740.3828125MB; mem (CPU total)=24622.890625MB
INFO:root:[   68] Training loss: 0.67379024, Validation loss: 0.67061193, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24778.48046875MB; mem (CPU total)=24660.76953125MB
INFO:root:[   69] Training loss: 0.67371890, Validation loss: 0.67015255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24816.578125MB; mem (CPU total)=24698.72265625MB
INFO:root:[   70] Training loss: 0.67353829, Validation loss: 0.67011878, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24854.671875MB; mem (CPU total)=24735.8828125MB
INFO:root:[   71] Training loss: 0.67370630, Validation loss: 0.67042817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24892.76953125MB; mem (CPU total)=24774.0234375MB
INFO:root:[   72] Training loss: 0.67342313, Validation loss: 0.67113451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24930.86328125MB; mem (CPU total)=24812.3203125MB
INFO:root:[   73] Training loss: 0.67300916, Validation loss: 0.66927124, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24968.95703125MB; mem (CPU total)=24850.4609375MB
INFO:root:[   74] Training loss: 0.67295045, Validation loss: 0.66992429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25007.05078125MB; mem (CPU total)=24888.60546875MB
INFO:root:[   75] Training loss: 0.67288254, Validation loss: 0.66952660, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25045.1484375MB; mem (CPU total)=24926.74609375MB
INFO:root:[   76] Training loss: 0.67269717, Validation loss: 0.66879929, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25083.24609375MB; mem (CPU total)=24965.0234375MB
INFO:root:[   77] Training loss: 0.67273139, Validation loss: 0.66909575, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25121.33984375MB; mem (CPU total)=25002.421875MB
INFO:root:[   78] Training loss: 0.67265032, Validation loss: 0.66935379, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25159.4375MB; mem (CPU total)=25041.3359375MB
INFO:root:[   79] Training loss: 0.67250174, Validation loss: 0.66978602, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25197.53125MB; mem (CPU total)=25079.48046875MB
INFO:root:[   80] Training loss: 0.67222526, Validation loss: 0.66829682, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25235.625MB; mem (CPU total)=25117.77734375MB
INFO:root:[   81] Training loss: 0.67211797, Validation loss: 0.66816648, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25273.7265625MB; mem (CPU total)=25155.94140625MB
INFO:root:[   82] Training loss: 0.67198425, Validation loss: 0.66824971, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25311.81640625MB; mem (CPU total)=25194.0234375MB
INFO:root:[   83] Training loss: 0.67208640, Validation loss: 0.66832144, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25349.91015625MB; mem (CPU total)=25231.921875MB
INFO:root:[   84] Training loss: 0.67194751, Validation loss: 0.66752646, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25388.01171875MB; mem (CPU total)=25270.66015625MB
INFO:root:[   85] Training loss: 0.67195696, Validation loss: 0.66948766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25426.10546875MB; mem (CPU total)=25309.0390625MB
INFO:root:[   86] Training loss: 0.67183962, Validation loss: 0.66858913, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25464.19921875MB; mem (CPU total)=25346.921875MB
INFO:root:[   87] Training loss: 0.67170081, Validation loss: 0.66788678, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25502.296875MB; mem (CPU total)=25385.06640625MB
INFO:root:[   88] Training loss: 0.67156877, Validation loss: 0.66783412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25540.39453125MB; mem (CPU total)=25423.5MB
INFO:root:[   89] Training loss: 0.67158505, Validation loss: 0.66821407, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25578.48828125MB; mem (CPU total)=25461.9140625MB
INFO:root:[   90] Training loss: 0.67152272, Validation loss: 0.66802258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25616.58203125MB; mem (CPU total)=25499.96484375MB
INFO:root:[   91] Training loss: 0.67163374, Validation loss: 0.66818050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25654.67578125MB; mem (CPU total)=25537.7265625MB
INFO:root:[   92] Training loss: 0.67159392, Validation loss: 0.66898965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25692.7734375MB; mem (CPU total)=25576.1171875MB
INFO:root:[   93] Training loss: 0.67141373, Validation loss: 0.66774865, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25730.8671875MB; mem (CPU total)=25614.2578125MB
INFO:root:[   94] Training loss: 0.67141806, Validation loss: 0.66738689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25768.96484375MB; mem (CPU total)=25652.79296875MB
INFO:root:[   95] Training loss: 0.67105140, Validation loss: 0.66798471, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25807.0546875MB; mem (CPU total)=25690.9765625MB
INFO:root:[   96] Training loss: 0.67124231, Validation loss: 0.66756732, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25845.15625MB; mem (CPU total)=25728.875MB
INFO:root:[   97] Training loss: 0.67106043, Validation loss: 0.66871096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25883.25MB; mem (CPU total)=25767.01171875MB
INFO:root:[   98] Training loss: 0.67114018, Validation loss: 0.66840965, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25921.34765625MB; mem (CPU total)=25805.3984375MB
INFO:root:[   99] Training loss: 0.67114353, Validation loss: 0.66720869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25959.44140625MB; mem (CPU total)=25843.53515625MB
INFO:root:[  100] Training loss: 0.67087381, Validation loss: 0.66709760, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25997.55078125MB; mem (CPU total)=25881.6875MB
INFO:root:[  101] Training loss: 0.67110934, Validation loss: 0.66782693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26035.640625MB; mem (CPU total)=25919.83984375MB
INFO:root:[  102] Training loss: 0.67065879, Validation loss: 0.66786989, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26073.73046875MB; mem (CPU total)=25958.04296875MB
INFO:root:[  103] Training loss: 0.67070213, Validation loss: 0.66715170, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26111.82421875MB; mem (CPU total)=25996.20703125MB
INFO:root:[  104] Training loss: 0.67094707, Validation loss: 0.66671258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26149.921875MB; mem (CPU total)=26034.15625MB
INFO:root:[  105] Training loss: 0.67073763, Validation loss: 0.66727799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26188.015625MB; mem (CPU total)=26071.79296875MB
INFO:root:[  106] Training loss: 0.67056663, Validation loss: 0.66712029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26226.11328125MB; mem (CPU total)=26109.95703125MB
INFO:root:[  107] Training loss: 0.67073463, Validation loss: 0.66736607, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26264.20703125MB; mem (CPU total)=26148.125MB
INFO:root:[  108] Training loss: 0.67067959, Validation loss: 0.66639836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26302.3046875MB; mem (CPU total)=26185.9765625MB
INFO:root:[  109] Training loss: 0.67084416, Validation loss: 0.66744810, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26340.3984375MB; mem (CPU total)=26224.14453125MB
INFO:root:[  110] Training loss: 0.67055476, Validation loss: 0.66791823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26378.4921875MB; mem (CPU total)=26262.51171875MB
INFO:root:[  111] Training loss: 0.67044803, Validation loss: 0.66729899, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26416.58984375MB; mem (CPU total)=26300.65625MB
INFO:root:[  112] Training loss: 0.67039527, Validation loss: 0.66671467, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26454.6875MB; mem (CPU total)=26338.56640625MB
INFO:root:[  113] Training loss: 0.67058400, Validation loss: 0.66737811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26492.78125MB; mem (CPU total)=26376.71484375MB
INFO:root:[  114] Training loss: 0.67047188, Validation loss: 0.66678226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26530.875MB; mem (CPU total)=26415.14453125MB
INFO:root:[  115] Training loss: 0.67061843, Validation loss: 0.66664504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26568.97265625MB; mem (CPU total)=26453.2109375MB
INFO:root:[  116] Training loss: 0.67018701, Validation loss: 0.66585214, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26607.0703125MB; mem (CPU total)=26491.55859375MB
INFO:root:[  117] Training loss: 0.67016658, Validation loss: 0.66641598, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26645.16015625MB; mem (CPU total)=26529.50390625MB
INFO:root:[  118] Training loss: 0.67024401, Validation loss: 0.66762137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26683.25390625MB; mem (CPU total)=26567.6328125MB
INFO:root:[  119] Training loss: 0.67027936, Validation loss: 0.66735443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26721.3515625MB; mem (CPU total)=26605.796875MB
INFO:root:[  120] Training loss: 0.66991463, Validation loss: 0.66722481, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26759.4453125MB; mem (CPU total)=26643.9453125MB
INFO:root:[  121] Training loss: 0.67007288, Validation loss: 0.66583822, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26797.54296875MB; mem (CPU total)=26681.78515625MB
INFO:root:[  122] Training loss: 0.67006446, Validation loss: 0.66681001, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26835.63671875MB; mem (CPU total)=26719.98046875MB
INFO:root:[  123] Training loss: 0.66994023, Validation loss: 0.66727716, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26873.734375MB; mem (CPU total)=26757.734375MB
INFO:root:[  124] Training loss: 0.66998421, Validation loss: 0.66583539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26911.83203125MB; mem (CPU total)=26795.765625MB
INFO:root:[  125] Training loss: 0.66978883, Validation loss: 0.66630133, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26949.921875MB; mem (CPU total)=26834.4140625MB
INFO:root:[  126] Training loss: 0.66988034, Validation loss: 0.66591935, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26988.01953125MB; mem (CPU total)=26872.328125MB
INFO:root:[  127] Training loss: 0.66974398, Validation loss: 0.66595739, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27026.11328125MB; mem (CPU total)=26910.19921875MB
INFO:root:[  128] Training loss: 0.66969155, Validation loss: 0.66670463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27064.20703125MB; mem (CPU total)=26948.3515625MB
INFO:root:[  129] Training loss: 0.66984656, Validation loss: 0.66617597, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27102.3046875MB; mem (CPU total)=26986.75390625MB
INFO:root:[  130] Training loss: 0.66970904, Validation loss: 0.66598861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27140.40234375MB; mem (CPU total)=27024.8515625MB
INFO:root:[  131] Training loss: 0.66957819, Validation loss: 0.66685944, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27178.49609375MB; mem (CPU total)=27063.09765625MB
INFO:root:[  132] Training loss: 0.66952067, Validation loss: 0.66662297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27216.59375MB; mem (CPU total)=27101.10546875MB
INFO:root:[  133] Training loss: 0.66945956, Validation loss: 0.66611142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27254.6875MB; mem (CPU total)=27139.26171875MB
INFO:root:EP 133: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=27292.78125MB; mem (CPU total)=27177.40625MB
INFO:root:Training the model took 7223.696s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94354
INFO:root:EnergyScoreTrain: 0.66404
INFO:root:CRPSTrain: 0.57067
INFO:root:Gaussian NLLTrain: 32880395018.24
INFO:root:CoverageTrain: 0.7413
INFO:root:IntervalWidthTrain: 3.12588
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9462
INFO:root:EnergyScoreValidation: 0.66592
INFO:root:CRPSValidation: 0.57264
INFO:root:Gaussian NLLValidation: 33439912746.09778
INFO:root:CoverageValidation: 0.74196
INFO:root:IntervalWidthValidation: 3.12988
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.9454
INFO:root:EnergyScoreTest: 0.66535
INFO:root:CRPSTest: 0.57215
INFO:root:Gaussian NLLTest: 33279468568.576
INFO:root:CoverageTest: 0.74181
INFO:root:IntervalWidthTest: 3.12881
INFO:root:After validation: mem (CPU python)=27350.7265625MB; mem (CPU total)=27237.8359375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=27350.7265625MB; mem (CPU total)=27237.8203125MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=27350.8671875MB; mem (CPU total)=27237.8203125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=27350.8671875MB; mem (CPU total)=27238.06640625MB
INFO:root:[    1] Training loss: 0.71594342, Validation loss: 0.70398236, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27388.8515625MB; mem (CPU total)=27275.84765625MB
INFO:root:[    2] Training loss: 0.70108388, Validation loss: 0.69584468, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27426.9453125MB; mem (CPU total)=27313.953125MB
INFO:root:[    3] Training loss: 0.69635320, Validation loss: 0.69132412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27465.0546875MB; mem (CPU total)=27352.125MB
INFO:root:[    4] Training loss: 0.69407674, Validation loss: 0.68995866, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27503.16015625MB; mem (CPU total)=27390.234375MB
INFO:root:[    5] Training loss: 0.69289029, Validation loss: 0.69110137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27541.25390625MB; mem (CPU total)=27428.37890625MB
INFO:root:[    6] Training loss: 0.69203214, Validation loss: 0.69751181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27579.34765625MB; mem (CPU total)=27466.5234375MB
INFO:root:[    7] Training loss: 0.69178889, Validation loss: 0.69675898, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27617.4453125MB; mem (CPU total)=27504.6328125MB
INFO:root:[    8] Training loss: 0.69127362, Validation loss: 0.70396180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27655.54296875MB; mem (CPU total)=27542.7890625MB
INFO:root:[    9] Training loss: 0.69076954, Validation loss: 0.70121132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27693.63671875MB; mem (CPU total)=27581.17578125MB
INFO:root:[   10] Training loss: 0.69004641, Validation loss: 0.69910296, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27731.73046875MB; mem (CPU total)=27618.9765625MB
INFO:root:[   11] Training loss: 0.68950255, Validation loss: 0.68989409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27769.83203125MB; mem (CPU total)=27657.7265625MB
INFO:root:[   12] Training loss: 0.68912500, Validation loss: 0.70011514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27807.921875MB; mem (CPU total)=27696.09765625MB
INFO:root:[   13] Training loss: 0.68884354, Validation loss: 0.69582047, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27846.015625MB; mem (CPU total)=27734.05859375MB
INFO:root:[   14] Training loss: 0.68878958, Validation loss: 0.69569895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27884.11328125MB; mem (CPU total)=27771.95703125MB
INFO:root:[   15] Training loss: 0.68841242, Validation loss: 0.69471066, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27922.2109375MB; mem (CPU total)=27810.08984375MB
INFO:root:[   16] Training loss: 0.68780222, Validation loss: 0.68873629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27960.30859375MB; mem (CPU total)=27848.32421875MB
INFO:root:[   17] Training loss: 0.68736562, Validation loss: 0.68658571, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27998.40234375MB; mem (CPU total)=27885.93359375MB
INFO:root:[   18] Training loss: 0.68707985, Validation loss: 0.68960428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28036.49609375MB; mem (CPU total)=27924.2109375MB
INFO:root:[   19] Training loss: 0.68674426, Validation loss: 0.68768503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28074.58984375MB; mem (CPU total)=27962.3828125MB
INFO:root:[   20] Training loss: 0.68638644, Validation loss: 0.69025951, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28112.68359375MB; mem (CPU total)=28003.46484375MB
INFO:root:[   21] Training loss: 0.68592526, Validation loss: 0.68744922, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28150.78125MB; mem (CPU total)=28041.32421875MB
INFO:root:[   22] Training loss: 0.68553862, Validation loss: 0.68934292, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28188.87890625MB; mem (CPU total)=28079.69921875MB
INFO:root:[   23] Training loss: 0.68523341, Validation loss: 0.68558614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28226.97265625MB; mem (CPU total)=28118.13671875MB
INFO:root:[   24] Training loss: 0.68497703, Validation loss: 0.68344255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28265.0703125MB; mem (CPU total)=28156.3984375MB
INFO:root:[   25] Training loss: 0.68453648, Validation loss: 0.68626179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28303.1640625MB; mem (CPU total)=28194.08203125MB
INFO:root:[   26] Training loss: 0.68468289, Validation loss: 0.68398731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28341.2578125MB; mem (CPU total)=28231.96484375MB
INFO:root:[   27] Training loss: 0.68427161, Validation loss: 0.68309870, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28379.35546875MB; mem (CPU total)=28269.46484375MB
INFO:root:[   28] Training loss: 0.68395771, Validation loss: 0.68384673, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28417.44921875MB; mem (CPU total)=28307.60546875MB
INFO:root:[   29] Training loss: 0.68390117, Validation loss: 0.68244431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28455.546875MB; mem (CPU total)=28345.75390625MB
INFO:root:[   30] Training loss: 0.68355208, Validation loss: 0.68206519, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28493.640625MB; mem (CPU total)=28383.32421875MB
INFO:root:[   31] Training loss: 0.68348728, Validation loss: 0.67929616, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28531.73828125MB; mem (CPU total)=28421.71484375MB
INFO:root:[   32] Training loss: 0.68318019, Validation loss: 0.67894519, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28569.83203125MB; mem (CPU total)=28459.61328125MB
INFO:root:[   33] Training loss: 0.68296437, Validation loss: 0.67941434, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28607.92578125MB; mem (CPU total)=28498.2421875MB
INFO:root:[   34] Training loss: 0.68305019, Validation loss: 0.67913763, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28646.0234375MB; mem (CPU total)=28536.38671875MB
INFO:root:[   35] Training loss: 0.68261600, Validation loss: 0.67679322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28684.88671875MB; mem (CPU total)=28575.765625MB
INFO:root:[   36] Training loss: 0.68259345, Validation loss: 0.67795405, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28722.21484375MB; mem (CPU total)=28612.92578125MB
INFO:root:[   37] Training loss: 0.68208552, Validation loss: 0.67726443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28760.3203125MB; mem (CPU total)=28651.0703125MB
INFO:root:[   38] Training loss: 0.68207228, Validation loss: 0.67697012, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28798.41796875MB; mem (CPU total)=28689.23046875MB
INFO:root:[   39] Training loss: 0.68172979, Validation loss: 0.67663964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28836.50390625MB; mem (CPU total)=28727.2109375MB
INFO:root:[   40] Training loss: 0.68154107, Validation loss: 0.67548776, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28874.59765625MB; mem (CPU total)=28765.1328125MB
INFO:root:[   41] Training loss: 0.68152308, Validation loss: 0.67816894, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28912.6953125MB; mem (CPU total)=28803.515625MB
INFO:root:[   42] Training loss: 0.68160445, Validation loss: 0.67724177, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28950.7890625MB; mem (CPU total)=28841.43359375MB
INFO:root:[   43] Training loss: 0.68132384, Validation loss: 0.67547338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28988.88671875MB; mem (CPU total)=28879.6328125MB
INFO:root:[   44] Training loss: 0.68112127, Validation loss: 0.67644423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29026.9765625MB; mem (CPU total)=28918.16796875MB
INFO:root:[   45] Training loss: 0.68104614, Validation loss: 0.67602063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29065.07421875MB; mem (CPU total)=28956.296875MB
INFO:root:[   46] Training loss: 0.68072452, Validation loss: 0.67561324, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29103.171875MB; mem (CPU total)=28994.1953125MB
INFO:root:[   47] Training loss: 0.68067238, Validation loss: 0.67458156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29141.265625MB; mem (CPU total)=29032.37890625MB
INFO:root:[   48] Training loss: 0.68044675, Validation loss: 0.67498097, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29179.36328125MB; mem (CPU total)=29070.7578125MB
INFO:root:[   49] Training loss: 0.68045848, Validation loss: 0.67590578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29217.45703125MB; mem (CPU total)=29108.87109375MB
INFO:root:[   50] Training loss: 0.68014041, Validation loss: 0.67463844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29255.55078125MB; mem (CPU total)=29146.53515625MB
INFO:root:[   51] Training loss: 0.68021716, Validation loss: 0.67424981, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29293.64453125MB; mem (CPU total)=29182.9765625MB
INFO:root:[   52] Training loss: 0.68004045, Validation loss: 0.67432486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29331.7421875MB; mem (CPU total)=29221.58984375MB
INFO:root:[   53] Training loss: 0.67972664, Validation loss: 0.67421931, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29369.83984375MB; mem (CPU total)=29259.6640625MB
INFO:root:[   54] Training loss: 0.67981763, Validation loss: 0.67386624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29407.93359375MB; mem (CPU total)=29297.8359375MB
INFO:root:[   55] Training loss: 0.67958984, Validation loss: 0.67331189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29446.03125MB; mem (CPU total)=29335.46875MB
INFO:root:[   56] Training loss: 0.67959553, Validation loss: 0.67434222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29484.12109375MB; mem (CPU total)=29373.3671875MB
INFO:root:[   57] Training loss: 0.67954131, Validation loss: 0.67398204, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29522.21875MB; mem (CPU total)=29411.51171875MB
INFO:root:[   58] Training loss: 0.67932292, Validation loss: 0.67397591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29560.31640625MB; mem (CPU total)=29449.90234375MB
INFO:root:[   59] Training loss: 0.67933735, Validation loss: 0.67339133, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29598.41015625MB; mem (CPU total)=29689.87890625MB
INFO:root:[   60] Training loss: 0.67917266, Validation loss: 0.67403080, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29636.50390625MB; mem (CPU total)=32047.36328125MB
INFO:root:[   61] Training loss: 0.67918633, Validation loss: 0.67299125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29674.6015625MB; mem (CPU total)=32087.578125MB
INFO:root:[   62] Training loss: 0.67898045, Validation loss: 0.67264882, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29712.69921875MB; mem (CPU total)=32119.93359375MB
INFO:root:[   63] Training loss: 0.67865685, Validation loss: 0.67385354, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29750.7890625MB; mem (CPU total)=32157.27734375MB
INFO:root:[   64] Training loss: 0.67897788, Validation loss: 0.67295345, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29788.8828125MB; mem (CPU total)=32194.71875MB
INFO:root:[   65] Training loss: 0.67874388, Validation loss: 0.67351988, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29826.984375MB; mem (CPU total)=32237.78515625MB
INFO:root:[   66] Training loss: 0.67839233, Validation loss: 0.67269351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29865.078125MB; mem (CPU total)=32272.90625MB
INFO:root:[   67] Training loss: 0.67837907, Validation loss: 0.67279963, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29903.171875MB; mem (CPU total)=32307.66796875MB
INFO:root:[   68] Training loss: 0.67839869, Validation loss: 0.67318590, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29941.265625MB; mem (CPU total)=32342.23046875MB
INFO:root:[   69] Training loss: 0.67836508, Validation loss: 0.67310954, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29979.36328125MB; mem (CPU total)=32381.94140625MB
INFO:root:[   70] Training loss: 0.67804651, Validation loss: 0.67258348, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30017.4609375MB; mem (CPU total)=32423.6171875MB
INFO:root:[   71] Training loss: 0.67813252, Validation loss: 0.67324955, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30055.5546875MB; mem (CPU total)=32461.05078125MB
INFO:root:[   72] Training loss: 0.67800919, Validation loss: 0.67288475, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30093.6484375MB; mem (CPU total)=32496.49609375MB
INFO:root:[   73] Training loss: 0.67767663, Validation loss: 0.67257657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30131.75MB; mem (CPU total)=32532.73046875MB
INFO:root:[   74] Training loss: 0.67762696, Validation loss: 0.67182925, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30169.84375MB; mem (CPU total)=32570.7578125MB
INFO:root:[   75] Training loss: 0.67768910, Validation loss: 0.67259947, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30207.9375MB; mem (CPU total)=32617.05859375MB
INFO:root:[   76] Training loss: 0.67742646, Validation loss: 0.67208047, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30246.03125MB; mem (CPU total)=32655.8671875MB
INFO:root:[   77] Training loss: 0.67762652, Validation loss: 0.67200716, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30284.12890625MB; mem (CPU total)=32693.84765625MB
INFO:root:[   78] Training loss: 0.67754519, Validation loss: 0.67271361, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30322.22265625MB; mem (CPU total)=32729.58203125MB
INFO:root:[   79] Training loss: 0.67728448, Validation loss: 0.67228863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30360.3203125MB; mem (CPU total)=32765.84375MB
INFO:root:[   80] Training loss: 0.67735054, Validation loss: 0.67158272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30398.41796875MB; mem (CPU total)=32802.3359375MB
INFO:root:[   81] Training loss: 0.67723416, Validation loss: 0.67180556, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30436.5078125MB; mem (CPU total)=32849.76171875MB
INFO:root:[   82] Training loss: 0.67697660, Validation loss: 0.67172272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30474.609375MB; mem (CPU total)=32884.6015625MB
INFO:root:[   83] Training loss: 0.67704766, Validation loss: 0.67122775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30512.70703125MB; mem (CPU total)=32920.03515625MB
INFO:root:[   84] Training loss: 0.67700664, Validation loss: 0.67087890, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30550.80078125MB; mem (CPU total)=32957.3671875MB
INFO:root:[   85] Training loss: 0.67695890, Validation loss: 0.67240058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30588.890625MB; mem (CPU total)=33004.93359375MB
INFO:root:[   86] Training loss: 0.67683325, Validation loss: 0.67169546, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30626.98828125MB; mem (CPU total)=33035.0703125MB
INFO:root:[   87] Training loss: 0.67689567, Validation loss: 0.67101043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30665.08203125MB; mem (CPU total)=33080.30078125MB
INFO:root:[   88] Training loss: 0.67679473, Validation loss: 0.67164430, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30703.17578125MB; mem (CPU total)=33116.01171875MB
INFO:root:[   89] Training loss: 0.67667104, Validation loss: 0.67080915, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30741.27734375MB; mem (CPU total)=33150.765625MB
INFO:root:[   90] Training loss: 0.67685771, Validation loss: 0.67099497, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30779.37109375MB; mem (CPU total)=33189.9921875MB
INFO:root:[   91] Training loss: 0.67679324, Validation loss: 0.67140196, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30817.46875MB; mem (CPU total)=33234.56640625MB
INFO:root:[   92] Training loss: 0.67673855, Validation loss: 0.67239059, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30855.56640625MB; mem (CPU total)=33271.91015625MB
INFO:root:[   93] Training loss: 0.67671674, Validation loss: 0.67101828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30893.66015625MB; mem (CPU total)=33305.67578125MB
INFO:root:[   94] Training loss: 0.67668721, Validation loss: 0.67118141, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30931.75390625MB; mem (CPU total)=33342.765625MB
INFO:root:[   95] Training loss: 0.67636926, Validation loss: 0.67085356, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30969.84765625MB; mem (CPU total)=33390.79296875MB
INFO:root:[   96] Training loss: 0.67662629, Validation loss: 0.67103964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31007.9453125MB; mem (CPU total)=33429.484375MB
INFO:root:[   97] Training loss: 0.67633914, Validation loss: 0.67131063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31046.0390625MB; mem (CPU total)=33464.05078125MB
INFO:root:[   98] Training loss: 0.67635567, Validation loss: 0.67116876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31084.1328125MB; mem (CPU total)=33498.47265625MB
INFO:root:[   99] Training loss: 0.67618169, Validation loss: 0.67073427, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31122.234375MB; mem (CPU total)=33537.640625MB
INFO:root:[  100] Training loss: 0.67601236, Validation loss: 0.67076738, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31160.328125MB; mem (CPU total)=33582.328125MB
INFO:root:[  101] Training loss: 0.67612303, Validation loss: 0.67036126, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31198.421875MB; mem (CPU total)=33618.08984375MB
INFO:root:[  102] Training loss: 0.67570583, Validation loss: 0.67068391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31236.515625MB; mem (CPU total)=33656.3203125MB
INFO:root:[  103] Training loss: 0.67582030, Validation loss: 0.67020285, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31274.6171875MB; mem (CPU total)=33691.34375MB
INFO:root:[  104] Training loss: 0.67598758, Validation loss: 0.66990909, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31312.7109375MB; mem (CPU total)=33728.61328125MB
INFO:root:[  105] Training loss: 0.67583116, Validation loss: 0.66987695, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31350.8046875MB; mem (CPU total)=33774.9609375MB
INFO:root:[  106] Training loss: 0.67555758, Validation loss: 0.67014269, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31388.90234375MB; mem (CPU total)=33814.19921875MB
INFO:root:[  107] Training loss: 0.67585726, Validation loss: 0.67047851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31426.99609375MB; mem (CPU total)=33854.296875MB
INFO:root:[  108] Training loss: 0.67591729, Validation loss: 0.67028214, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31465.08984375MB; mem (CPU total)=33890.671875MB
INFO:root:[  109] Training loss: 0.67601092, Validation loss: 0.67010770, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31503.1875MB; mem (CPU total)=33925.94921875MB
INFO:root:[  110] Training loss: 0.67570055, Validation loss: 0.67154736, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31541.28125MB; mem (CPU total)=33961.30078125MB
INFO:root:[  111] Training loss: 0.67561552, Validation loss: 0.67038386, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31579.375MB; mem (CPU total)=34006.5078125MB
INFO:root:[  112] Training loss: 0.67548927, Validation loss: 0.66945116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31617.47265625MB; mem (CPU total)=34044.88671875MB
INFO:root:[  113] Training loss: 0.67562697, Validation loss: 0.67072023, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31655.56640625MB; mem (CPU total)=34081.5703125MB
INFO:root:[  114] Training loss: 0.67545970, Validation loss: 0.66943513, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31693.6640625MB; mem (CPU total)=34117.15625MB
INFO:root:[  115] Training loss: 0.67534908, Validation loss: 0.66979058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31731.7578125MB; mem (CPU total)=34154.14453125MB
INFO:root:[  116] Training loss: 0.67514126, Validation loss: 0.66883474, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31769.85546875MB; mem (CPU total)=34200.40625MB
INFO:root:[  117] Training loss: 0.67502224, Validation loss: 0.66910943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31807.94921875MB; mem (CPU total)=34237.81640625MB
INFO:root:[  118] Training loss: 0.67516787, Validation loss: 0.67034480, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31846.04296875MB; mem (CPU total)=34273.7421875MB
INFO:root:[  119] Training loss: 0.67521624, Validation loss: 0.66934898, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31884.13671875MB; mem (CPU total)=34311.19140625MB
INFO:root:[  120] Training loss: 0.67491682, Validation loss: 0.67069774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31922.234375MB; mem (CPU total)=34357.01953125MB
INFO:root:[  121] Training loss: 0.67509304, Validation loss: 0.66933012, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31960.328125MB; mem (CPU total)=34482.3515625MB
INFO:root:[  122] Training loss: 0.67492527, Validation loss: 0.67017090, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31998.421875MB; mem (CPU total)=34516.83203125MB
INFO:root:[  123] Training loss: 0.67483452, Validation loss: 0.66978268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32036.5234375MB; mem (CPU total)=34544.31640625MB
INFO:root:[  124] Training loss: 0.67482531, Validation loss: 0.66892795, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32074.6171875MB; mem (CPU total)=34604.01171875MB
INFO:root:[  125] Training loss: 0.67470407, Validation loss: 0.66916523, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32112.7109375MB; mem (CPU total)=34636.1171875MB
INFO:root:[  126] Training loss: 0.67475867, Validation loss: 0.66873462, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32150.8125MB; mem (CPU total)=34672.7734375MB
INFO:root:[  127] Training loss: 0.67460607, Validation loss: 0.66882983, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32188.90234375MB; mem (CPU total)=34704.88671875MB
INFO:root:[  128] Training loss: 0.67451324, Validation loss: 0.66933455, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32226.99609375MB; mem (CPU total)=34726.49609375MB
INFO:root:[  129] Training loss: 0.67468616, Validation loss: 0.66873933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32265.08984375MB; mem (CPU total)=34783.39453125MB
INFO:root:[  130] Training loss: 0.67453344, Validation loss: 0.66909475, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32303.1875MB; mem (CPU total)=34816.5859375MB
INFO:root:[  131] Training loss: 0.67448754, Validation loss: 0.66972036, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32341.28515625MB; mem (CPU total)=34843.23046875MB
INFO:root:[  132] Training loss: 0.67437221, Validation loss: 0.66896380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32379.3828125MB; mem (CPU total)=34876.78515625MB
INFO:root:[  133] Training loss: 0.67424199, Validation loss: 0.66904156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32417.48046875MB; mem (CPU total)=34933.95703125MB
INFO:root:[  134] Training loss: 0.67440278, Validation loss: 0.66936661, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32455.57421875MB; mem (CPU total)=34971.0MB
INFO:root:[  135] Training loss: 0.67416611, Validation loss: 0.66874617, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32493.66796875MB; mem (CPU total)=34999.87890625MB
INFO:root:EP 135: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=32531.62890625MB; mem (CPU total)=35040.59375MB
INFO:root:Training the model took 8012.802s.
INFO:root:Emptying the cuda cache took 0.009s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94754
INFO:root:EnergyScoreTrain: 0.66689
INFO:root:CRPSTrain: 0.5894
INFO:root:Gaussian NLLTrain: 50043920324.83559
INFO:root:CoverageTrain: 0.66103
INFO:root:IntervalWidthTrain: 2.9131
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.95017
INFO:root:EnergyScoreValidation: 0.66876
INFO:root:CRPSValidation: 0.59149
INFO:root:Gaussian NLLValidation: 50574874451.05782
INFO:root:CoverageValidation: 0.66185
INFO:root:IntervalWidthValidation: 2.91747
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94952
INFO:root:EnergyScoreTest: 0.66831
INFO:root:CRPSTest: 0.591
INFO:root:Gaussian NLLTest: 50049828519.93603
INFO:root:CoverageTest: 0.66181
INFO:root:IntervalWidthTest: 2.91685
INFO:root:After validation: mem (CPU python)=32574.51953125MB; mem (CPU total)=35076.08203125MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=32574.51953125MB; mem (CPU total)=35079.0390625MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=32574.6328125MB; mem (CPU total)=35076.734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=32574.6328125MB; mem (CPU total)=35091.48046875MB
INFO:root:[    1] Training loss: 0.71719174, Validation loss: 0.70494207, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32612.69921875MB; mem (CPU total)=35119.609375MB
INFO:root:[    2] Training loss: 0.70317971, Validation loss: 0.69717231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32650.8046875MB; mem (CPU total)=35146.953125MB
INFO:root:[    3] Training loss: 0.69886978, Validation loss: 0.69437398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32688.890625MB; mem (CPU total)=35208.5546875MB
INFO:root:[    4] Training loss: 0.69693690, Validation loss: 0.69910134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32726.98046875MB; mem (CPU total)=35238.55078125MB
INFO:root:[    5] Training loss: 0.69623280, Validation loss: 0.71407171, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32764.83203125MB; mem (CPU total)=35287.9921875MB
INFO:root:[    6] Training loss: 0.69565577, Validation loss: 0.72325709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32802.92578125MB; mem (CPU total)=35324.04296875MB
INFO:root:[    7] Training loss: 0.69534575, Validation loss: 0.73708530, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32841.02734375MB; mem (CPU total)=35363.91796875MB
INFO:root:[    8] Training loss: 0.69475087, Validation loss: 0.71895332, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32879.09375MB; mem (CPU total)=35402.40234375MB
INFO:root:[    9] Training loss: 0.69441715, Validation loss: 0.71199768, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32917.1875MB; mem (CPU total)=35442.93359375MB
INFO:root:[   10] Training loss: 0.69380044, Validation loss: 0.72303973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32955.28515625MB; mem (CPU total)=35484.23046875MB
INFO:root:[   11] Training loss: 0.69349282, Validation loss: 0.70215895, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32993.37890625MB; mem (CPU total)=35513.875MB
INFO:root:[   12] Training loss: 0.69326365, Validation loss: 0.71863851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33031.47265625MB; mem (CPU total)=32941.40625MB
INFO:root:[   13] Training loss: 0.69309520, Validation loss: 0.72304003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33069.5703125MB; mem (CPU total)=32978.31640625MB
INFO:root:[   14] Training loss: 0.69268317, Validation loss: 0.71330382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33107.6640625MB; mem (CPU total)=33016.05859375MB
INFO:root:[   15] Training loss: 0.69246939, Validation loss: 0.69797531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33145.7578125MB; mem (CPU total)=33053.98046875MB
INFO:root:[   16] Training loss: 0.69207904, Validation loss: 0.70063617, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33183.8515625MB; mem (CPU total)=33091.6015625MB
INFO:root:[   17] Training loss: 0.69202006, Validation loss: 0.69296651, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33221.953125MB; mem (CPU total)=33126.1875MB
INFO:root:[   18] Training loss: 0.69173269, Validation loss: 0.69307044, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33260.046875MB; mem (CPU total)=33164.0859375MB
INFO:root:[   19] Training loss: 0.69110799, Validation loss: 0.68920130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33298.140625MB; mem (CPU total)=33201.6484375MB
INFO:root:[   20] Training loss: 0.69098115, Validation loss: 0.69223078, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33336.23828125MB; mem (CPU total)=33238.89453125MB
INFO:root:[   21] Training loss: 0.69075751, Validation loss: 0.68672251, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33374.3359375MB; mem (CPU total)=33235.64453125MB
INFO:root:[   22] Training loss: 0.69038474, Validation loss: 0.69113271, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33412.42578125MB; mem (CPU total)=33274.7578125MB
INFO:root:[   23] Training loss: 0.69022518, Validation loss: 0.68536585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33450.5234375MB; mem (CPU total)=33312.79296875MB
INFO:root:[   24] Training loss: 0.68988535, Validation loss: 0.68428637, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33488.62109375MB; mem (CPU total)=33351.5703125MB
INFO:root:[   25] Training loss: 0.68955392, Validation loss: 0.68453927, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33526.71484375MB; mem (CPU total)=33389.93359375MB
INFO:root:[   26] Training loss: 0.68923096, Validation loss: 0.68358668, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33564.8125MB; mem (CPU total)=33428.70703125MB
INFO:root:[   27] Training loss: 0.68908033, Validation loss: 0.68246924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33602.9140625MB; mem (CPU total)=33467.76953125MB
INFO:root:[   28] Training loss: 0.68856961, Validation loss: 0.68326769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33641.00390625MB; mem (CPU total)=33505.9140625MB
INFO:root:[   29] Training loss: 0.68827829, Validation loss: 0.68120386, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33679.1015625MB; mem (CPU total)=33544.5390625MB
INFO:root:[   30] Training loss: 0.68808538, Validation loss: 0.68189449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33717.1953125MB; mem (CPU total)=33583.17578125MB
INFO:root:[   31] Training loss: 0.68799464, Validation loss: 0.68145485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33755.2890625MB; mem (CPU total)=33623.078125MB
INFO:root:[   32] Training loss: 0.68747082, Validation loss: 0.68053299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33793.38671875MB; mem (CPU total)=33660.85546875MB
INFO:root:[   33] Training loss: 0.68745546, Validation loss: 0.68015355, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33831.48046875MB; mem (CPU total)=33699.265625MB
INFO:root:[   34] Training loss: 0.68723928, Validation loss: 0.68095040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33869.578125MB; mem (CPU total)=33737.41015625MB
INFO:root:[   35] Training loss: 0.68711829, Validation loss: 0.67937716, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33907.67578125MB; mem (CPU total)=33775.98046875MB
INFO:root:[   36] Training loss: 0.68703876, Validation loss: 0.68074486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33945.765625MB; mem (CPU total)=33814.36328125MB
INFO:root:[   37] Training loss: 0.68682965, Validation loss: 0.68009553, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33983.86328125MB; mem (CPU total)=33852.45703125MB
INFO:root:[   38] Training loss: 0.68663336, Validation loss: 0.68081879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34021.95703125MB; mem (CPU total)=33890.3203125MB
INFO:root:[   39] Training loss: 0.68627989, Validation loss: 0.67963665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34060.0546875MB; mem (CPU total)=33928.6875MB
INFO:root:[   40] Training loss: 0.68644380, Validation loss: 0.67894350, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34098.1484375MB; mem (CPU total)=33967.1015625MB
INFO:root:[   41] Training loss: 0.68637333, Validation loss: 0.67953039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34136.2421875MB; mem (CPU total)=34005.9765625MB
INFO:root:[   42] Training loss: 0.68621825, Validation loss: 0.67942933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34174.33984375MB; mem (CPU total)=34044.890625MB
INFO:root:[   43] Training loss: 0.68594729, Validation loss: 0.67860487, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34212.4375MB; mem (CPU total)=34083.20703125MB
INFO:root:[   44] Training loss: 0.68584438, Validation loss: 0.68108677, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34250.53125MB; mem (CPU total)=34121.3515625MB
INFO:root:[   45] Training loss: 0.68577175, Validation loss: 0.67862656, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34288.625MB; mem (CPU total)=34159.49609375MB
INFO:root:[   46] Training loss: 0.68549673, Validation loss: 0.67970655, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34326.71875MB; mem (CPU total)=34197.640625MB
INFO:root:[   47] Training loss: 0.68555318, Validation loss: 0.67877509, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34364.81640625MB; mem (CPU total)=34235.78125MB
INFO:root:[   48] Training loss: 0.68548870, Validation loss: 0.67854814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34402.9140625MB; mem (CPU total)=34273.0859375MB
INFO:root:[   49] Training loss: 0.68539233, Validation loss: 0.68034250, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34441.00390625MB; mem (CPU total)=34311.46875MB
INFO:root:[   50] Training loss: 0.68502581, Validation loss: 0.67751933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34479.1015625MB; mem (CPU total)=34350.10546875MB
INFO:root:[   51] Training loss: 0.68513215, Validation loss: 0.67779917, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34517.19921875MB; mem (CPU total)=34387.7109375MB
INFO:root:[   52] Training loss: 0.68519051, Validation loss: 0.67847198, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34555.29296875MB; mem (CPU total)=34425.84765625MB
INFO:root:[   53] Training loss: 0.68472937, Validation loss: 0.67787863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34593.38671875MB; mem (CPU total)=34463.73046875MB
INFO:root:[   54] Training loss: 0.68482926, Validation loss: 0.67790578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34631.484375MB; mem (CPU total)=34501.8671875MB
INFO:root:[   55] Training loss: 0.68450557, Validation loss: 0.67714140, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34669.58203125MB; mem (CPU total)=34540.08203125MB
INFO:root:[   56] Training loss: 0.68460961, Validation loss: 0.67762825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34707.67578125MB; mem (CPU total)=34577.6484375MB
INFO:root:[   57] Training loss: 0.68475417, Validation loss: 0.67700311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34745.76953125MB; mem (CPU total)=34616.71875MB
INFO:root:[   58] Training loss: 0.68437913, Validation loss: 0.67774086, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34783.8671875MB; mem (CPU total)=34654.0MB
INFO:root:[   59] Training loss: 0.68429790, Validation loss: 0.67638391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34821.9609375MB; mem (CPU total)=34692.984375MB
INFO:root:[   60] Training loss: 0.68435839, Validation loss: 0.67791199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34860.0546875MB; mem (CPU total)=34731.359375MB
INFO:root:[   61] Training loss: 0.68421348, Validation loss: 0.67629091, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34898.15625MB; mem (CPU total)=34769.1953125MB
INFO:root:[   62] Training loss: 0.68427255, Validation loss: 0.67596180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34936.25MB; mem (CPU total)=34794.578125MB
INFO:root:[   63] Training loss: 0.68393686, Validation loss: 0.67729446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34974.33984375MB; mem (CPU total)=34835.35546875MB
INFO:root:[   64] Training loss: 0.68417163, Validation loss: 0.67727258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35012.44140625MB; mem (CPU total)=34872.0390625MB
INFO:root:[   65] Training loss: 0.68387941, Validation loss: 0.67769337, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35050.53515625MB; mem (CPU total)=34911.58203125MB
INFO:root:[   66] Training loss: 0.68369174, Validation loss: 0.67570041, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35088.6328125MB; mem (CPU total)=34949.9921875MB
INFO:root:[   67] Training loss: 0.68364322, Validation loss: 0.67611567, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35126.72265625MB; mem (CPU total)=34987.1015625MB
INFO:root:[   68] Training loss: 0.68356909, Validation loss: 0.67758062, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35164.8203125MB; mem (CPU total)=35025.75MB
INFO:root:[   69] Training loss: 0.68367110, Validation loss: 0.67652671, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35202.91796875MB; mem (CPU total)=35066.9921875MB
INFO:root:[   70] Training loss: 0.68350681, Validation loss: 0.67622412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35241.01171875MB; mem (CPU total)=35106.6328125MB
INFO:root:[   71] Training loss: 0.68357788, Validation loss: 0.67560583, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35279.11328125MB; mem (CPU total)=35140.6875MB
INFO:root:[   72] Training loss: 0.68337762, Validation loss: 0.67786734, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35317.203125MB; mem (CPU total)=35178.70703125MB
INFO:root:[   73] Training loss: 0.68335461, Validation loss: 0.67617735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35355.296875MB; mem (CPU total)=35216.890625MB
INFO:root:[   74] Training loss: 0.68336899, Validation loss: 0.67586614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35393.39453125MB; mem (CPU total)=35255.1328125MB
INFO:root:[   75] Training loss: 0.68333172, Validation loss: 0.67746198, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35431.4921875MB; mem (CPU total)=35293.5078125MB
INFO:root:[   76] Training loss: 0.68321848, Validation loss: 0.67553619, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35469.5859375MB; mem (CPU total)=35330.2421875MB
INFO:root:[   77] Training loss: 0.68335166, Validation loss: 0.67627626, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35507.6796875MB; mem (CPU total)=35368.45703125MB
INFO:root:[   78] Training loss: 0.68337992, Validation loss: 0.67642243, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35545.77734375MB; mem (CPU total)=35410.1171875MB
INFO:root:[   79] Training loss: 0.68309453, Validation loss: 0.67637217, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35583.87109375MB; mem (CPU total)=35448.51953125MB
INFO:root:[   80] Training loss: 0.68323718, Validation loss: 0.67600019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35621.96484375MB; mem (CPU total)=35486.65234375MB
INFO:root:[   81] Training loss: 0.68317565, Validation loss: 0.67671033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35660.06640625MB; mem (CPU total)=35525.921875MB
INFO:root:[   82] Training loss: 0.68287939, Validation loss: 0.67584592, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35698.16015625MB; mem (CPU total)=35564.28515625MB
INFO:root:[   83] Training loss: 0.68305790, Validation loss: 0.67532487, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35736.2578125MB; mem (CPU total)=35602.78515625MB
INFO:root:[   84] Training loss: 0.68285574, Validation loss: 0.67514757, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35774.3515625MB; mem (CPU total)=35640.55859375MB
INFO:root:[   85] Training loss: 0.68284969, Validation loss: 0.67659547, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35812.4453125MB; mem (CPU total)=35679.18359375MB
INFO:root:[   86] Training loss: 0.68295882, Validation loss: 0.67546729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35850.5390625MB; mem (CPU total)=35717.5703125MB
INFO:root:[   87] Training loss: 0.68321278, Validation loss: 0.67543631, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35888.6328125MB; mem (CPU total)=35757.45703125MB
INFO:root:[   88] Training loss: 0.68334044, Validation loss: 0.67758392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35926.73046875MB; mem (CPU total)=35795.83203125MB
INFO:root:[   89] Training loss: 0.68347735, Validation loss: 0.67636236, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35964.82421875MB; mem (CPU total)=35833.83203125MB
INFO:root:[   90] Training loss: 0.68303275, Validation loss: 0.67530271, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36002.92578125MB; mem (CPU total)=35872.21484375MB
INFO:root:[   91] Training loss: 0.68308238, Validation loss: 0.67562525, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36041.01953125MB; mem (CPU total)=35910.16015625MB
INFO:root:[   92] Training loss: 0.68283243, Validation loss: 0.67475954, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36079.1171875MB; mem (CPU total)=35947.890625MB
INFO:root:[   93] Training loss: 0.68295361, Validation loss: 0.67631319, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36117.2109375MB; mem (CPU total)=35985.80859375MB
INFO:root:[   94] Training loss: 0.68285414, Validation loss: 0.67617856, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36155.3046875MB; mem (CPU total)=36024.18359375MB
INFO:root:[   95] Training loss: 0.68258566, Validation loss: 0.67540055, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36193.40234375MB; mem (CPU total)=36062.57421875MB
INFO:root:[   96] Training loss: 0.68259187, Validation loss: 0.67573178, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36231.49609375MB; mem (CPU total)=36100.96484375MB
INFO:root:[   97] Training loss: 0.68246747, Validation loss: 0.67482174, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36269.58984375MB; mem (CPU total)=36140.00390625MB
INFO:root:[   98] Training loss: 0.68276047, Validation loss: 0.67574779, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36307.6875MB; mem (CPU total)=36178.14453125MB
INFO:root:[   99] Training loss: 0.68277317, Validation loss: 0.67481529, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36345.78515625MB; mem (CPU total)=36216.5078125MB
INFO:root:[  100] Training loss: 0.68225066, Validation loss: 0.67475317, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36383.87890625MB; mem (CPU total)=36253.46484375MB
INFO:root:[  101] Training loss: 0.68236475, Validation loss: 0.67515775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36421.97265625MB; mem (CPU total)=36292.1015625MB
INFO:root:[  102] Training loss: 0.68192030, Validation loss: 0.67562801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36460.0703125MB; mem (CPU total)=36330.23828125MB
INFO:root:[  103] Training loss: 0.68241602, Validation loss: 0.67481584, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36498.1640625MB; mem (CPU total)=36368.66015625MB
INFO:root:[  104] Training loss: 0.68224684, Validation loss: 0.67418580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36536.26171875MB; mem (CPU total)=36407.3125MB
INFO:root:[  105] Training loss: 0.68191707, Validation loss: 0.67405794, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36574.359375MB; mem (CPU total)=36445.6015625MB
INFO:root:[  106] Training loss: 0.68188798, Validation loss: 0.67460639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36612.44921875MB; mem (CPU total)=36485.4375MB
INFO:root:[  107] Training loss: 0.68212612, Validation loss: 0.67587081, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36650.54296875MB; mem (CPU total)=36523.578125MB
INFO:root:[  108] Training loss: 0.68258550, Validation loss: 0.67554166, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36688.640625MB; mem (CPU total)=36561.7109375MB
INFO:root:[  109] Training loss: 0.68257964, Validation loss: 0.67438198, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36726.73828125MB; mem (CPU total)=36600.08984375MB
INFO:root:[  110] Training loss: 0.68208025, Validation loss: 0.67492919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36764.83203125MB; mem (CPU total)=36640.57421875MB
INFO:root:[  111] Training loss: 0.68190079, Validation loss: 0.67541241, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36802.92578125MB; mem (CPU total)=36677.30859375MB
INFO:root:[  112] Training loss: 0.68174939, Validation loss: 0.67399402, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36841.02734375MB; mem (CPU total)=36716.296875MB
INFO:root:[  113] Training loss: 0.68172002, Validation loss: 0.67420829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36879.1171875MB; mem (CPU total)=36754.4375MB
INFO:root:[  114] Training loss: 0.68161820, Validation loss: 0.67399243, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36917.21484375MB; mem (CPU total)=36792.59765625MB
INFO:root:[  115] Training loss: 0.68175704, Validation loss: 0.67451391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36955.30859375MB; mem (CPU total)=36831.44921875MB
INFO:root:[  116] Training loss: 0.68169698, Validation loss: 0.67406475, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36993.40234375MB; mem (CPU total)=36867.65234375MB
INFO:root:[  117] Training loss: 0.68171159, Validation loss: 0.67465530, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37031.5MB; mem (CPU total)=36905.97265625MB
INFO:root:[  118] Training loss: 0.68168515, Validation loss: 0.67497684, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37069.59375MB; mem (CPU total)=36944.08203125MB
INFO:root:[  119] Training loss: 0.68143697, Validation loss: 0.67385571, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37107.6953125MB; mem (CPU total)=36982.21875MB
INFO:root:[  120] Training loss: 0.68125852, Validation loss: 0.67405356, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37145.78515625MB; mem (CPU total)=37021.40625MB
INFO:root:[  121] Training loss: 0.68137505, Validation loss: 0.67369866, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37183.8828125MB; mem (CPU total)=37058.1171875MB
INFO:root:[  122] Training loss: 0.68122182, Validation loss: 0.67400711, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37221.9765625MB; mem (CPU total)=37097.13671875MB
INFO:root:[  123] Training loss: 0.68106919, Validation loss: 0.67436146, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37260.0703125MB; mem (CPU total)=37135.5234375MB
INFO:root:[  124] Training loss: 0.68137125, Validation loss: 0.67434936, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37298.16796875MB; mem (CPU total)=37174.62890625MB
INFO:root:[  125] Training loss: 0.68117203, Validation loss: 0.67426450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37336.26171875MB; mem (CPU total)=37212.46484375MB
INFO:root:[  126] Training loss: 0.68106614, Validation loss: 0.67391828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37374.36328125MB; mem (CPU total)=37250.0078125MB
INFO:root:[  127] Training loss: 0.68101546, Validation loss: 0.67297571, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37412.45703125MB; mem (CPU total)=37289.3203125MB
INFO:root:[  128] Training loss: 0.68082633, Validation loss: 0.67404021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37450.55078125MB; mem (CPU total)=37327.44921875MB
INFO:root:[  129] Training loss: 0.68110124, Validation loss: 0.67341951, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37488.6484375MB; mem (CPU total)=37365.59375MB
INFO:root:[  130] Training loss: 0.68098743, Validation loss: 0.67336044, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37526.7421875MB; mem (CPU total)=37402.890625MB
INFO:root:[  131] Training loss: 0.68083751, Validation loss: 0.67362262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37564.8359375MB; mem (CPU total)=37441.0MB
INFO:root:[  132] Training loss: 0.68060922, Validation loss: 0.67365843, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37602.93359375MB; mem (CPU total)=37480.078125MB
INFO:root:[  133] Training loss: 0.68075227, Validation loss: 0.67369672, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37641.03125MB; mem (CPU total)=37519.22265625MB
INFO:root:[  134] Training loss: 0.68079370, Validation loss: 0.67456171, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37679.125MB; mem (CPU total)=37558.18359375MB
INFO:root:[  135] Training loss: 0.68054931, Validation loss: 0.67303201, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37717.21875MB; mem (CPU total)=37594.671875MB
INFO:root:[  136] Training loss: 0.68068245, Validation loss: 0.67324020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37755.31640625MB; mem (CPU total)=37633.79296875MB
INFO:root:EP 136: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=37793.41015625MB; mem (CPU total)=37671.9375MB
INFO:root:Training the model took 8787.833s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.95417
INFO:root:EnergyScoreTrain: 0.67161
INFO:root:CRPSTrain: 0.59229
INFO:root:Gaussian NLLTrain: 71764745225.10225
INFO:root:CoverageTrain: 0.68282
INFO:root:IntervalWidthTrain: 2.96692
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.95612
INFO:root:EnergyScoreValidation: 0.673
INFO:root:CRPSValidation: 0.59383
INFO:root:Gaussian NLLValidation: 72613031662.93338
INFO:root:CoverageValidation: 0.68357
INFO:root:IntervalWidthValidation: 2.9708
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.95543
INFO:root:EnergyScoreTest: 0.67251
INFO:root:CRPSTest: 0.59347
INFO:root:Gaussian NLLTest: 72392905523.2
INFO:root:CoverageTest: 0.68328
INFO:root:IntervalWidthTest: 2.96898
INFO:root:After validation: mem (CPU python)=37837.859375MB; mem (CPU total)=37718.83984375MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=37837.859375MB; mem (CPU total)=37718.83203125MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=37837.90625MB; mem (CPU total)=37718.83203125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=37837.90625MB; mem (CPU total)=37718.81640625MB
INFO:root:[    1] Training loss: 0.71841336, Validation loss: 0.70622952, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37875.89453125MB; mem (CPU total)=37756.21875MB
INFO:root:[    2] Training loss: 0.70513496, Validation loss: 0.70040665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37913.98828125MB; mem (CPU total)=37793.91796875MB
INFO:root:[    3] Training loss: 0.70149038, Validation loss: 0.71035615, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37952.08203125MB; mem (CPU total)=37833.34375MB
INFO:root:[    4] Training loss: 0.70019356, Validation loss: 0.75523729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37990.1796875MB; mem (CPU total)=37872.2109375MB
INFO:root:[    5] Training loss: 0.69949561, Validation loss: 0.78996181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38028.2734375MB; mem (CPU total)=37910.33984375MB
INFO:root:[    6] Training loss: 0.69869216, Validation loss: 0.75382288, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38066.3671875MB; mem (CPU total)=37947.76953125MB
INFO:root:[    7] Training loss: 0.69800992, Validation loss: 0.76814958, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38104.46484375MB; mem (CPU total)=37985.5MB
INFO:root:[    8] Training loss: 0.69744919, Validation loss: 0.73525874, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38142.55859375MB; mem (CPU total)=38024.1328125MB
INFO:root:[    9] Training loss: 0.69726190, Validation loss: 0.84010808, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38180.65625MB; mem (CPU total)=38062.12109375MB
INFO:root:[   10] Training loss: 0.69686100, Validation loss: 0.78136986, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38218.75MB; mem (CPU total)=38084.3125MB
INFO:root:[   11] Training loss: 0.69660699, Validation loss: 0.77668541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38256.84765625MB; mem (CPU total)=38124.47265625MB
INFO:root:[   12] Training loss: 0.69625420, Validation loss: 0.75098847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38294.94140625MB; mem (CPU total)=38165.484375MB
INFO:root:[   13] Training loss: 0.69600862, Validation loss: 0.80370094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38333.03515625MB; mem (CPU total)=38199.984375MB
INFO:root:[   14] Training loss: 0.69595958, Validation loss: 0.75177293, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38371.1328125MB; mem (CPU total)=38238.03125MB
INFO:root:[   15] Training loss: 0.69566938, Validation loss: 0.70629737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38409.2265625MB; mem (CPU total)=38275.9296875MB
INFO:root:[   16] Training loss: 0.69540428, Validation loss: 0.71394724, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38447.32421875MB; mem (CPU total)=38314.8125MB
INFO:root:[   17] Training loss: 0.69536235, Validation loss: 0.69892667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38485.41796875MB; mem (CPU total)=38353.296875MB
INFO:root:[   18] Training loss: 0.69503017, Validation loss: 0.69841741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38523.515625MB; mem (CPU total)=38393.55078125MB
INFO:root:[   19] Training loss: 0.69448850, Validation loss: 0.69240860, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38561.61328125MB; mem (CPU total)=38431.9765625MB
INFO:root:[   20] Training loss: 0.69435741, Validation loss: 0.69125492, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38599.70703125MB; mem (CPU total)=38471.265625MB
INFO:root:[   21] Training loss: 0.69395006, Validation loss: 0.68949245, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38637.80078125MB; mem (CPU total)=38507.18359375MB
INFO:root:[   22] Training loss: 0.69382781, Validation loss: 0.68931361, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38675.8984375MB; mem (CPU total)=38542.0MB
INFO:root:[   23] Training loss: 0.69359878, Validation loss: 0.68812321, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38713.9921875MB; mem (CPU total)=38580.25390625MB
INFO:root:[   24] Training loss: 0.69336578, Validation loss: 0.68761463, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38752.08984375MB; mem (CPU total)=38618.98828125MB
INFO:root:[   25] Training loss: 0.69321216, Validation loss: 0.68704045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38790.18359375MB; mem (CPU total)=38655.94140625MB
INFO:root:[   26] Training loss: 0.69291886, Validation loss: 0.68768624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38828.27734375MB; mem (CPU total)=38695.0625MB
INFO:root:[   27] Training loss: 0.69316799, Validation loss: 0.68707532, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38866.37109375MB; mem (CPU total)=38733.1796875MB
INFO:root:[   28] Training loss: 0.69266503, Validation loss: 0.68977718, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38904.46875MB; mem (CPU total)=38771.45703125MB
INFO:root:[   29] Training loss: 0.69276288, Validation loss: 0.68560183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38942.56640625MB; mem (CPU total)=38808.21875MB
INFO:root:[   30] Training loss: 0.69217976, Validation loss: 0.68663412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38980.65625MB; mem (CPU total)=38847.37109375MB
INFO:root:[   31] Training loss: 0.69223063, Validation loss: 0.68531211, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39018.7578125MB; mem (CPU total)=38887.19140625MB
INFO:root:[   32] Training loss: 0.69170903, Validation loss: 0.68485563, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39056.8515625MB; mem (CPU total)=38922.72265625MB
INFO:root:[   33] Training loss: 0.69158363, Validation loss: 0.68556349, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39094.9453125MB; mem (CPU total)=38961.890625MB
INFO:root:[   34] Training loss: 0.69141402, Validation loss: 0.68567700, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39133.0390625MB; mem (CPU total)=38998.03515625MB
INFO:root:[   35] Training loss: 0.69166038, Validation loss: 0.69099912, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39171.13671875MB; mem (CPU total)=39038.08984375MB
INFO:root:[   36] Training loss: 0.69177338, Validation loss: 0.68928504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39209.23046875MB; mem (CPU total)=39075.61328125MB
INFO:root:[   37] Training loss: 0.69161169, Validation loss: 0.68565691, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39247.32421875MB; mem (CPU total)=39114.60546875MB
INFO:root:[   38] Training loss: 0.69124075, Validation loss: 0.68941341, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39285.421875MB; mem (CPU total)=39155.02734375MB
INFO:root:[   39] Training loss: 0.69222687, Validation loss: 0.71376716, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39323.515625MB; mem (CPU total)=39193.65234375MB
INFO:root:[   40] Training loss: 0.69236021, Validation loss: 0.75943001, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39361.609375MB; mem (CPU total)=39227.6484375MB
INFO:root:[   41] Training loss: 0.69138143, Validation loss: 0.81785719, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39399.7109375MB; mem (CPU total)=39267.26953125MB
INFO:root:[   42] Training loss: 0.69118981, Validation loss: 0.84031323, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39437.8046875MB; mem (CPU total)=39304.37109375MB
INFO:root:[   43] Training loss: 0.69126510, Validation loss: 0.83306126, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39475.8984375MB; mem (CPU total)=39342.90625MB
INFO:root:[   44] Training loss: 0.69116147, Validation loss: 0.81324754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39513.9921875MB; mem (CPU total)=39381.640625MB
INFO:root:[   45] Training loss: 0.69109135, Validation loss: 0.83757128, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39552.08984375MB; mem (CPU total)=39420.42578125MB
INFO:root:[   46] Training loss: 0.69114404, Validation loss: 0.89649686, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39590.18359375MB; mem (CPU total)=39456.96484375MB
INFO:root:[   47] Training loss: 0.69076931, Validation loss: 0.87674034, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39628.27734375MB; mem (CPU total)=39495.84765625MB
INFO:root:[   48] Training loss: 0.69040511, Validation loss: 0.87978415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39666.37890625MB; mem (CPU total)=39535.3359375MB
INFO:root:[   49] Training loss: 0.69021637, Validation loss: 0.95337536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39704.47265625MB; mem (CPU total)=39572.796875MB
INFO:root:[   50] Training loss: 0.69009042, Validation loss: 0.94884152, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39742.56640625MB; mem (CPU total)=39610.84765625MB
INFO:root:[   51] Training loss: 0.68985037, Validation loss: 0.93856146, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39780.66015625MB; mem (CPU total)=39659.37890625MB
INFO:root:[   52] Training loss: 0.69002513, Validation loss: 0.91537310, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39818.7578125MB; mem (CPU total)=39697.62890625MB
INFO:root:[   53] Training loss: 0.69026743, Validation loss: 0.92295405, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39856.8515625MB; mem (CPU total)=39726.70703125MB
INFO:root:[   54] Training loss: 0.69015205, Validation loss: 0.91370037, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39894.9453125MB; mem (CPU total)=39763.15234375MB
INFO:root:[   55] Training loss: 0.68960830, Validation loss: 0.93633096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39933.046875MB; mem (CPU total)=39800.8984375MB
INFO:root:[   56] Training loss: 0.68972744, Validation loss: 0.96033589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39971.13671875MB; mem (CPU total)=39842.94140625MB
INFO:root:[   57] Training loss: 0.68967811, Validation loss: 0.95944254, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40009.234375MB; mem (CPU total)=39877.5703125MB
INFO:root:[   58] Training loss: 0.68981766, Validation loss: 0.94448642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40047.33203125MB; mem (CPU total)=39917.0390625MB
INFO:root:[   59] Training loss: 0.68956434, Validation loss: 0.91667498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40085.42578125MB; mem (CPU total)=39952.1640625MB
INFO:root:[   60] Training loss: 0.68928284, Validation loss: 0.92941887, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40123.51953125MB; mem (CPU total)=39992.81640625MB
INFO:root:[   61] Training loss: 0.68993824, Validation loss: 0.79366853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40161.61328125MB; mem (CPU total)=40029.421875MB
INFO:root:[   62] Training loss: 0.69145145, Validation loss: 0.83224816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40199.7109375MB; mem (CPU total)=40068.39453125MB
INFO:root:[   63] Training loss: 0.69024571, Validation loss: 0.87674411, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40237.8046875MB; mem (CPU total)=40104.83984375MB
INFO:root:[   64] Training loss: 0.68978854, Validation loss: 0.83202348, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40275.8984375MB; mem (CPU total)=40145.26171875MB
INFO:root:[   65] Training loss: 0.68967232, Validation loss: 0.81589084, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40314.0MB; mem (CPU total)=40182.234375MB
INFO:root:[   66] Training loss: 0.68947021, Validation loss: 0.85131457, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40352.09375MB; mem (CPU total)=40221.41796875MB
INFO:root:[   67] Training loss: 0.68952347, Validation loss: 0.88406047, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40390.1875MB; mem (CPU total)=40259.33984375MB
INFO:root:[   68] Training loss: 0.68919991, Validation loss: 0.87248514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40428.28125MB; mem (CPU total)=40295.5078125MB
INFO:root:[   69] Training loss: 0.68902638, Validation loss: 0.81661978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40466.37890625MB; mem (CPU total)=40334.984375MB
INFO:root:[   70] Training loss: 0.68928507, Validation loss: 0.87791815, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40504.47265625MB; mem (CPU total)=40372.17578125MB
INFO:root:[   71] Training loss: 0.68917133, Validation loss: 0.78909384, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40542.56640625MB; mem (CPU total)=40410.625MB
INFO:root:[   72] Training loss: 0.68895224, Validation loss: 0.88421883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40580.6640625MB; mem (CPU total)=40449.90625MB
INFO:root:[   73] Training loss: 0.68880622, Validation loss: 0.88095258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40618.76171875MB; mem (CPU total)=40486.38671875MB
INFO:root:[   74] Training loss: 0.68873439, Validation loss: 0.91844226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40656.85546875MB; mem (CPU total)=40527.1328125MB
INFO:root:[   75] Training loss: 0.68864413, Validation loss: 0.84160398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40694.953125MB; mem (CPU total)=40563.32421875MB
INFO:root:[   76] Training loss: 0.68899181, Validation loss: 0.87908458, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40733.046875MB; mem (CPU total)=40602.84765625MB
INFO:root:[   77] Training loss: 0.68904075, Validation loss: 0.89121717, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40771.140625MB; mem (CPU total)=40641.49609375MB
INFO:root:[   78] Training loss: 0.68908661, Validation loss: 0.88265657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40809.234375MB; mem (CPU total)=40677.23046875MB
INFO:root:[   79] Training loss: 0.68865731, Validation loss: 0.86322682, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40847.33203125MB; mem (CPU total)=40718.03515625MB
INFO:root:[   80] Training loss: 0.68920543, Validation loss: 0.74114228, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40885.42578125MB; mem (CPU total)=40754.46875MB
INFO:root:[   81] Training loss: 0.68949916, Validation loss: 0.75971825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40923.51953125MB; mem (CPU total)=40796.83984375MB
INFO:root:[   82] Training loss: 0.68893010, Validation loss: 0.73133682, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40961.62109375MB; mem (CPU total)=40830.62890625MB
INFO:root:[   83] Training loss: 0.68915191, Validation loss: 0.71777373, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40999.71484375MB; mem (CPU total)=40868.88671875MB
INFO:root:[   84] Training loss: 0.68878348, Validation loss: 0.73826850, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41037.80859375MB; mem (CPU total)=40908.2890625MB
INFO:root:[   85] Training loss: 0.68882970, Validation loss: 0.75339956, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41075.90234375MB; mem (CPU total)=40945.875MB
INFO:root:[   86] Training loss: 0.68891397, Validation loss: 0.68448764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41114.00390625MB; mem (CPU total)=40984.74609375MB
INFO:root:[   87] Training loss: 0.68883491, Validation loss: 0.68273568, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41152.09765625MB; mem (CPU total)=41022.39453125MB
INFO:root:[   88] Training loss: 0.68821405, Validation loss: 0.68177034, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41190.19140625MB; mem (CPU total)=41062.1640625MB
INFO:root:[   89] Training loss: 0.68805509, Validation loss: 0.68106962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41228.28515625MB; mem (CPU total)=41098.8828125MB
INFO:root:[   90] Training loss: 0.68821175, Validation loss: 0.68140811, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41266.37890625MB; mem (CPU total)=41136.84375MB
INFO:root:[   91] Training loss: 0.68826593, Validation loss: 0.68104609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41304.4765625MB; mem (CPU total)=41175.4375MB
INFO:root:[   92] Training loss: 0.68793336, Validation loss: 0.67949025, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41342.57421875MB; mem (CPU total)=41214.25390625MB
INFO:root:[   93] Training loss: 0.68797191, Validation loss: 0.68067809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41380.66796875MB; mem (CPU total)=41251.15234375MB
INFO:root:[   94] Training loss: 0.68767600, Validation loss: 0.68062562, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41418.76171875MB; mem (CPU total)=41289.76171875MB
INFO:root:[   95] Training loss: 0.68724444, Validation loss: 0.67982569, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41456.85546875MB; mem (CPU total)=41327.93359375MB
INFO:root:[   96] Training loss: 0.68753873, Validation loss: 0.68106678, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41494.95703125MB; mem (CPU total)=41366.70703125MB
INFO:root:[   97] Training loss: 0.68738112, Validation loss: 0.67971729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41533.0546875MB; mem (CPU total)=41404.60546875MB
INFO:root:[   98] Training loss: 0.68738684, Validation loss: 0.68010189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41571.1484375MB; mem (CPU total)=41442.1015625MB
INFO:root:[   99] Training loss: 0.68729791, Validation loss: 0.68178812, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41609.25MB; mem (CPU total)=41481.58203125MB
INFO:root:[  100] Training loss: 0.68708202, Validation loss: 0.67867739, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41647.33984375MB; mem (CPU total)=41517.953125MB
INFO:root:[  101] Training loss: 0.68745446, Validation loss: 0.68128462, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41685.4375MB; mem (CPU total)=41555.6328125MB
INFO:root:[  102] Training loss: 0.68751694, Validation loss: 0.68126831, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41723.53125MB; mem (CPU total)=41595.5703125MB
INFO:root:[  103] Training loss: 0.68798965, Validation loss: 0.68452108, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41761.62890625MB; mem (CPU total)=41634.03515625MB
INFO:root:[  104] Training loss: 0.68805737, Validation loss: 0.67960231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41799.72265625MB; mem (CPU total)=41671.75390625MB
INFO:root:[  105] Training loss: 0.68767886, Validation loss: 0.68085933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41837.81640625MB; mem (CPU total)=41709.94140625MB
INFO:root:[  106] Training loss: 0.68750495, Validation loss: 0.68401080, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41875.9140625MB; mem (CPU total)=41746.40234375MB
INFO:root:[  107] Training loss: 0.68745271, Validation loss: 0.68155874, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41914.0078125MB; mem (CPU total)=41789.3828125MB
INFO:root:[  108] Training loss: 0.68733320, Validation loss: 0.68164415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41952.10546875MB; mem (CPU total)=41823.40234375MB
INFO:root:[  109] Training loss: 0.68731978, Validation loss: 0.67937274, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41990.203125MB; mem (CPU total)=41862.30859375MB
INFO:root:EP 109: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=42028.25MB; mem (CPU total)=41900.53515625MB
INFO:root:Training the model took 7658.618s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.96204
INFO:root:EnergyScoreTrain: 0.67751
INFO:root:CRPSTrain: 0.58988
INFO:root:Gaussian NLLTrain: 56950029393.92001
INFO:root:CoverageTrain: 0.73556
INFO:root:IntervalWidthTrain: 3.03372
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.96357
INFO:root:EnergyScoreValidation: 0.67861
INFO:root:CRPSValidation: 0.59092
INFO:root:Gaussian NLLValidation: 57072708030.00888
INFO:root:CoverageValidation: 0.73665
INFO:root:IntervalWidthValidation: 3.03821
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.9632
INFO:root:EnergyScoreTest: 0.67833
INFO:root:CRPSTest: 0.59074
INFO:root:Gaussian NLLTest: 56882361466.88
INFO:root:CoverageTest: 0.7366
INFO:root:IntervalWidthTest: 3.0376
INFO:root:After validation: mem (CPU python)=42056.375MB; mem (CPU total)=41929.81640625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=42056.37890625MB; mem (CPU total)=41929.80078125MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=42056.4375MB; mem (CPU total)=41929.796875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=42056.5234375MB; mem (CPU total)=41930.515625MB
INFO:root:[    1] Training loss: 0.71949509, Validation loss: 0.70816004, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42094.5859375MB; mem (CPU total)=41969.93359375MB
INFO:root:[    2] Training loss: 0.70681226, Validation loss: 0.70304363, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42132.68359375MB; mem (CPU total)=42007.04296875MB
INFO:root:[    3] Training loss: 0.70329726, Validation loss: 0.71822964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42170.7734375MB; mem (CPU total)=42044.2265625MB
INFO:root:[    4] Training loss: 0.70193140, Validation loss: 0.80830122, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42208.8671875MB; mem (CPU total)=42083.41015625MB
INFO:root:[    5] Training loss: 0.70178344, Validation loss: 0.76773972, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42246.96875MB; mem (CPU total)=42122.9375MB
INFO:root:[    6] Training loss: 0.70080964, Validation loss: 0.82127076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42285.06640625MB; mem (CPU total)=42163.09765625MB
INFO:root:[    7] Training loss: 0.70060765, Validation loss: 0.79350583, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42323.16015625MB; mem (CPU total)=42197.3828125MB
INFO:root:[    8] Training loss: 0.70018652, Validation loss: 0.75541231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42361.25390625MB; mem (CPU total)=42236.37109375MB
INFO:root:[    9] Training loss: 0.69994804, Validation loss: 0.72535358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42399.3515625MB; mem (CPU total)=42272.515625MB
INFO:root:[   10] Training loss: 0.69950796, Validation loss: 0.72642183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42437.4453125MB; mem (CPU total)=42310.6875MB
INFO:root:[   11] Training loss: 0.69916454, Validation loss: 0.73882663, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42475.5390625MB; mem (CPU total)=42351.22265625MB
INFO:root:[   12] Training loss: 0.69867869, Validation loss: 0.73794486, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42513.640625MB; mem (CPU total)=42391.0625MB
INFO:root:[   13] Training loss: 0.69860701, Validation loss: 0.70347415, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42551.73046875MB; mem (CPU total)=42427.88671875MB
INFO:root:[   14] Training loss: 0.69797708, Validation loss: 0.70423344, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42589.828125MB; mem (CPU total)=42465.140625MB
INFO:root:[   15] Training loss: 0.69770309, Validation loss: 0.69993382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42627.92578125MB; mem (CPU total)=42501.40625MB
INFO:root:[   16] Training loss: 0.69790832, Validation loss: 0.69897853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42666.01953125MB; mem (CPU total)=42541.82421875MB
INFO:root:[   17] Training loss: 0.69779200, Validation loss: 0.69633807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42704.1171875MB; mem (CPU total)=42579.26171875MB
INFO:root:[   18] Training loss: 0.69785412, Validation loss: 0.70307626, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42742.20703125MB; mem (CPU total)=42617.109375MB
INFO:root:[   19] Training loss: 0.69742084, Validation loss: 0.69642470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42780.3046875MB; mem (CPU total)=42656.23828125MB
INFO:root:[   20] Training loss: 0.69717404, Validation loss: 0.69980119, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42818.40234375MB; mem (CPU total)=42697.4453125MB
INFO:root:[   21] Training loss: 0.69727528, Validation loss: 0.69493588, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42856.49609375MB; mem (CPU total)=42736.5MB
INFO:root:[   22] Training loss: 0.69713013, Validation loss: 0.69592121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42894.59375MB; mem (CPU total)=42770.71484375MB
INFO:root:[   23] Training loss: 0.69747697, Validation loss: 0.69693885, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42932.6875MB; mem (CPU total)=42808.546875MB
INFO:root:[   24] Training loss: 0.69690266, Validation loss: 0.69223629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42970.78515625MB; mem (CPU total)=42846.6796875MB
INFO:root:[   25] Training loss: 0.69649159, Validation loss: 0.69050618, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43008.87890625MB; mem (CPU total)=42885.40234375MB
INFO:root:[   26] Training loss: 0.69636794, Validation loss: 0.69113870, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43046.97265625MB; mem (CPU total)=42923.0390625MB
INFO:root:[   27] Training loss: 0.69638531, Validation loss: 0.69299731, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43085.0703125MB; mem (CPU total)=42962.65234375MB
INFO:root:[   28] Training loss: 0.69585307, Validation loss: 0.69217549, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43123.1640625MB; mem (CPU total)=43001.13671875MB
INFO:root:[   29] Training loss: 0.69587193, Validation loss: 0.68891001, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43161.26171875MB; mem (CPU total)=43038.16015625MB
INFO:root:[   30] Training loss: 0.69552621, Validation loss: 0.69009788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43199.35546875MB; mem (CPU total)=43074.01953125MB
INFO:root:[   31] Training loss: 0.69562084, Validation loss: 0.69017037, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43237.44921875MB; mem (CPU total)=43112.19140625MB
INFO:root:[   32] Training loss: 0.69542615, Validation loss: 0.68827827, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43275.55078125MB; mem (CPU total)=43152.07421875MB
INFO:root:[   33] Training loss: 0.69509263, Validation loss: 0.68747541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43313.64453125MB; mem (CPU total)=43190.109375MB
INFO:root:[   34] Training loss: 0.69506416, Validation loss: 0.68829639, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43351.734375MB; mem (CPU total)=43227.9765625MB
INFO:root:[   35] Training loss: 0.69482813, Validation loss: 0.68813933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43389.83203125MB; mem (CPU total)=43266.37890625MB
INFO:root:[   36] Training loss: 0.69474411, Validation loss: 0.68837520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43427.9296875MB; mem (CPU total)=43304.66796875MB
INFO:root:[   37] Training loss: 0.69441038, Validation loss: 0.68905922, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43466.0234375MB; mem (CPU total)=43342.828125MB
INFO:root:[   38] Training loss: 0.69438151, Validation loss: 0.68856989, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43504.12109375MB; mem (CPU total)=43380.44140625MB
INFO:root:[   39] Training loss: 0.69438432, Validation loss: 0.69101803, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43542.22265625MB; mem (CPU total)=43419.18359375MB
INFO:root:[   40] Training loss: 0.69424516, Validation loss: 0.68704868, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43580.3203125MB; mem (CPU total)=43457.26171875MB
INFO:root:[   41] Training loss: 0.69434487, Validation loss: 0.68659067, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43618.41796875MB; mem (CPU total)=43495.48046875MB
INFO:root:[   42] Training loss: 0.69413421, Validation loss: 0.68680453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43656.5078125MB; mem (CPU total)=43533.90625MB
INFO:root:[   43] Training loss: 0.69376639, Validation loss: 0.68756569, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43694.60546875MB; mem (CPU total)=43571.99609375MB
INFO:root:[   44] Training loss: 0.69345651, Validation loss: 0.68904476, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43732.69921875MB; mem (CPU total)=43609.3671875MB
INFO:root:[   45] Training loss: 0.69372229, Validation loss: 0.68603102, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43770.796875MB; mem (CPU total)=43650.16796875MB
INFO:root:[   46] Training loss: 0.69338483, Validation loss: 0.68787992, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43808.89453125MB; mem (CPU total)=43686.74609375MB
INFO:root:[   47] Training loss: 0.69361773, Validation loss: 0.68829390, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43846.98828125MB; mem (CPU total)=43722.94140625MB
INFO:root:[   48] Training loss: 0.69367060, Validation loss: 0.68574380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43885.17578125MB; mem (CPU total)=43763.30078125MB
INFO:root:[   49] Training loss: 0.69380474, Validation loss: 0.69063873, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43923.2734375MB; mem (CPU total)=43800.76171875MB
INFO:root:[   50] Training loss: 0.69386248, Validation loss: 0.68964285, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43962.0234375MB; mem (CPU total)=43839.95703125MB
INFO:root:[   51] Training loss: 0.69396273, Validation loss: 0.68803756, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44000.375MB; mem (CPU total)=43878.0546875MB
INFO:root:[   52] Training loss: 0.69396301, Validation loss: 0.68644318, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44038.46875MB; mem (CPU total)=43917.06640625MB
INFO:root:[   53] Training loss: 0.69367634, Validation loss: 0.68836960, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44076.5703125MB; mem (CPU total)=43955.94921875MB
INFO:root:[   54] Training loss: 0.69331027, Validation loss: 0.68975601, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44114.66015625MB; mem (CPU total)=43996.5625MB
INFO:root:[   55] Training loss: 0.69291607, Validation loss: 0.68647605, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44152.7578125MB; mem (CPU total)=44035.96484375MB
INFO:root:[   56] Training loss: 0.69279705, Validation loss: 0.68615931, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44190.85546875MB; mem (CPU total)=44074.328125MB
INFO:root:[   57] Training loss: 0.69282269, Validation loss: 0.68598839, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44228.94921875MB; mem (CPU total)=44112.47265625MB
INFO:root:[   58] Training loss: 0.69237615, Validation loss: 0.68692900, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44267.04296875MB; mem (CPU total)=44150.6171875MB
INFO:root:[   59] Training loss: 0.69231296, Validation loss: 0.68371827, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44305.140625MB; mem (CPU total)=44188.46484375MB
INFO:root:[   60] Training loss: 0.69245800, Validation loss: 0.68488813, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44343.234375MB; mem (CPU total)=44226.640625MB
INFO:root:[   61] Training loss: 0.69235591, Validation loss: 0.68669053, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44381.328125MB; mem (CPU total)=44264.77734375MB
INFO:root:[   62] Training loss: 0.69230928, Validation loss: 0.68712877, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44419.42578125MB; mem (CPU total)=44303.96875MB
INFO:root:[   63] Training loss: 0.69214396, Validation loss: 0.69114742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44457.5234375MB; mem (CPU total)=44341.99609375MB
INFO:root:[   64] Training loss: 0.69257636, Validation loss: 0.68639616, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44495.6171875MB; mem (CPU total)=44380.62109375MB
INFO:root:[   65] Training loss: 0.69195337, Validation loss: 0.69017204, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44533.7109375MB; mem (CPU total)=44422.07421875MB
INFO:root:[   66] Training loss: 0.69193722, Validation loss: 0.68461255, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44571.80859375MB; mem (CPU total)=44458.80078125MB
INFO:root:[   67] Training loss: 0.69190806, Validation loss: 0.68555522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44609.90234375MB; mem (CPU total)=44497.9609375MB
INFO:root:[   68] Training loss: 0.69193988, Validation loss: 0.69035381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44647.99609375MB; mem (CPU total)=44536.3515625MB
INFO:root:EP 68: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=44686.08984375MB; mem (CPU total)=44574.2421875MB
INFO:root:Training the model took 4967.912s.
INFO:root:Emptying the cuda cache took 0.007s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.96949
INFO:root:EnergyScoreTrain: 0.68249
INFO:root:CRPSTrain: 0.5762
INFO:root:Gaussian NLLTrain: 29562413907.05778
INFO:root:CoverageTrain: 0.82683
INFO:root:IntervalWidthTrain: 3.31828
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.97073
INFO:root:EnergyScoreValidation: 0.68337
INFO:root:CRPSValidation: 0.577
INFO:root:Gaussian NLLValidation: 29560918789.6889
INFO:root:CoverageValidation: 0.82811
INFO:root:IntervalWidthValidation: 3.32349
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.97013
INFO:root:EnergyScoreTest: 0.68294
INFO:root:CRPSTest: 0.5766
INFO:root:Gaussian NLLTest: 29718867427.328
INFO:root:CoverageTest: 0.82772
INFO:root:IntervalWidthTest: 3.32149
INFO:root:After validation: mem (CPU python)=44743.484375MB; mem (CPU total)=44637.0234375MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.3, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=44743.484375MB; mem (CPU total)=44637.05078125MB
INFO:root:NumberParameters: 1688178
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=44743.65234375MB; mem (CPU total)=44637.05078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=44743.65234375MB; mem (CPU total)=44637.0390625MB
INFO:root:[    1] Training loss: 0.72150326, Validation loss: 0.71109689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44781.7265625MB; mem (CPU total)=44674.2109375MB
INFO:root:[    2] Training loss: 0.70955262, Validation loss: 0.71129788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44819.81640625MB; mem (CPU total)=44710.7890625MB
INFO:root:[    3] Training loss: 0.70643797, Validation loss: 0.73685929, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44857.9140625MB; mem (CPU total)=44750.12109375MB
INFO:root:[    4] Training loss: 0.70517480, Validation loss: 0.76757338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44896.0078125MB; mem (CPU total)=44788.26171875MB
INFO:root:[    5] Training loss: 0.70482108, Validation loss: 0.81266860, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44934.10546875MB; mem (CPU total)=44826.5546875MB
INFO:root:[    6] Training loss: 0.70455623, Validation loss: 0.82029984, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44972.203125MB; mem (CPU total)=44864.69921875MB
INFO:root:[    7] Training loss: 0.70407528, Validation loss: 0.86382794, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45010.296875MB; mem (CPU total)=44901.5703125MB
INFO:root:[    8] Training loss: 0.70339179, Validation loss: 0.78176002, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45048.390625MB; mem (CPU total)=44941.1796875MB
INFO:root:[    9] Training loss: 0.70290486, Validation loss: 0.85141946, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45086.484375MB; mem (CPU total)=44979.27734375MB
INFO:root:[   10] Training loss: 0.70270375, Validation loss: 0.78303358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45124.58203125MB; mem (CPU total)=45017.40625MB
INFO:root:[   11] Training loss: 0.70223632, Validation loss: 0.76075709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45162.67578125MB; mem (CPU total)=45055.3046875MB
INFO:root:[   12] Training loss: 0.70225962, Validation loss: 0.81083120, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45201.14453125MB; mem (CPU total)=45096.90234375MB
INFO:root:[   13] Training loss: 0.70190372, Validation loss: 0.85005788, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45238.87109375MB; mem (CPU total)=45117.7734375MB
INFO:root:[   14] Training loss: 0.70171505, Validation loss: 0.76194339, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45276.96484375MB; mem (CPU total)=45156.4140625MB
INFO:root:[   15] Training loss: 0.70164237, Validation loss: 0.79878600, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45315.05859375MB; mem (CPU total)=45194.12109375MB
INFO:root:[   16] Training loss: 0.70141530, Validation loss: 0.77177226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45353.15234375MB; mem (CPU total)=45235.0MB
INFO:root:[   17] Training loss: 0.70137362, Validation loss: 0.76458450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45391.25MB; mem (CPU total)=45270.26171875MB
INFO:root:[   18] Training loss: 0.70123910, Validation loss: 0.80934727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45429.34375MB; mem (CPU total)=45307.69140625MB
INFO:root:[   19] Training loss: 0.70103249, Validation loss: 0.85261664, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45467.44140625MB; mem (CPU total)=45345.86328125MB
INFO:root:[   20] Training loss: 0.70091970, Validation loss: 0.72922695, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45505.53515625MB; mem (CPU total)=45384.2734375MB
INFO:root:[   21] Training loss: 0.70062515, Validation loss: 0.81041360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45543.6328125MB; mem (CPU total)=45422.203125MB
INFO:root:[   22] Training loss: 0.70048240, Validation loss: 0.82292100, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45581.7265625MB; mem (CPU total)=45461.10546875MB
INFO:root:[   23] Training loss: 0.70034854, Validation loss: 0.86693333, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45619.82421875MB; mem (CPU total)=45498.5390625MB
INFO:root:[   24] Training loss: 0.70060414, Validation loss: 0.84710763, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45657.91796875MB; mem (CPU total)=45539.453125MB
INFO:root:[   25] Training loss: 0.70014997, Validation loss: 0.88327999, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45696.01171875MB; mem (CPU total)=45575.13671875MB
INFO:root:[   26] Training loss: 0.70035156, Validation loss: 0.85438442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45734.10546875MB; mem (CPU total)=45613.546875MB
INFO:root:[   27] Training loss: 0.70028595, Validation loss: 0.74673503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45772.20703125MB; mem (CPU total)=45651.6953125MB
INFO:root:[   28] Training loss: 0.70067599, Validation loss: 0.73110114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45810.30078125MB; mem (CPU total)=45690.1015625MB
INFO:root:[   29] Training loss: 0.70052100, Validation loss: 0.76086256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45848.39453125MB; mem (CPU total)=45728.2734375MB
INFO:root:[   30] Training loss: 0.70076202, Validation loss: 0.87979758, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45886.4921875MB; mem (CPU total)=45766.62109375MB
INFO:root:[   31] Training loss: 0.70084976, Validation loss: 0.95697343, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45924.5859375MB; mem (CPU total)=45804.671875MB
INFO:root:[   32] Training loss: 0.70070637, Validation loss: 0.96344048, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=45962.6796875MB; mem (CPU total)=45845.60546875MB
INFO:root:[   33] Training loss: 0.70009995, Validation loss: 0.94763311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46000.7734375MB; mem (CPU total)=45881.8125MB
INFO:root:[   34] Training loss: 0.69989231, Validation loss: 0.90678844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46038.87109375MB; mem (CPU total)=45921.98046875MB
INFO:root:[   35] Training loss: 0.69977786, Validation loss: 0.71528554, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46076.96484375MB; mem (CPU total)=45956.6796875MB
INFO:root:[   36] Training loss: 0.69965873, Validation loss: 0.69750896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46115.0625MB; mem (CPU total)=45994.9921875MB
INFO:root:[   37] Training loss: 0.69944128, Validation loss: 0.69568685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46153.16015625MB; mem (CPU total)=46033.73828125MB
INFO:root:[   38] Training loss: 0.69925493, Validation loss: 0.69697264, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46191.25390625MB; mem (CPU total)=46071.66796875MB
INFO:root:[   39] Training loss: 0.69893420, Validation loss: 0.69607443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46229.34765625MB; mem (CPU total)=46108.95703125MB
INFO:root:[   40] Training loss: 0.69938983, Validation loss: 0.69886340, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46267.4453125MB; mem (CPU total)=46148.203125MB
INFO:root:[   41] Training loss: 0.69915023, Validation loss: 0.69396015, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46305.54296875MB; mem (CPU total)=46188.46484375MB
INFO:root:[   42] Training loss: 0.69899931, Validation loss: 0.69226437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46343.63671875MB; mem (CPU total)=46225.01953125MB
INFO:root:[   43] Training loss: 0.69868674, Validation loss: 0.69408803, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46381.7265625MB; mem (CPU total)=46263.62109375MB
INFO:root:[   44] Training loss: 0.69842702, Validation loss: 0.69594451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46419.8359375MB; mem (CPU total)=46303.21875MB
INFO:root:[   45] Training loss: 0.69827379, Validation loss: 0.69585809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46457.9296875MB; mem (CPU total)=46345.33203125MB
INFO:root:[   46] Training loss: 0.69823410, Validation loss: 0.69578892, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46496.02734375MB; mem (CPU total)=46384.421875MB
INFO:root:[   47] Training loss: 0.69821204, Validation loss: 0.69608750, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46534.125MB; mem (CPU total)=46422.46875MB
INFO:root:[   48] Training loss: 0.69804130, Validation loss: 0.69686906, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46572.21875MB; mem (CPU total)=46463.59765625MB
INFO:root:[   49] Training loss: 0.69814997, Validation loss: 0.69705470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46610.3125MB; mem (CPU total)=46519.9609375MB
INFO:root:[   50] Training loss: 0.69773152, Validation loss: 0.69857052, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46648.40625MB; mem (CPU total)=46535.40625MB
INFO:root:[   51] Training loss: 0.69795786, Validation loss: 0.69713215, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46686.50390625MB; mem (CPU total)=46574.8125MB
INFO:root:[   52] Training loss: 0.69799546, Validation loss: 0.69790932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46724.59765625MB; mem (CPU total)=46613.50390625MB
INFO:root:[   53] Training loss: 0.69778502, Validation loss: 0.70002267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46762.6953125MB; mem (CPU total)=46652.09765625MB
INFO:root:[   54] Training loss: 0.69848069, Validation loss: 0.69587519, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46800.79296875MB; mem (CPU total)=46688.38671875MB
INFO:root:[   55] Training loss: 0.69798251, Validation loss: 0.69755511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46838.88671875MB; mem (CPU total)=46727.69921875MB
INFO:root:[   56] Training loss: 0.69822431, Validation loss: 0.69734409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46876.98046875MB; mem (CPU total)=46763.87109375MB
INFO:root:[   57] Training loss: 0.69878174, Validation loss: 0.70186679, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46915.078125MB; mem (CPU total)=46796.56640625MB
INFO:root:[   58] Training loss: 0.69841718, Validation loss: 0.69563708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46953.171875MB; mem (CPU total)=46837.03125MB
INFO:root:[   59] Training loss: 0.69793404, Validation loss: 0.70183607, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=46991.265625MB; mem (CPU total)=46876.87890625MB
INFO:root:[   60] Training loss: 0.69866036, Validation loss: 0.70600495, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47029.359375MB; mem (CPU total)=46913.1484375MB
INFO:root:[   61] Training loss: 0.69843833, Validation loss: 0.70701408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47067.45703125MB; mem (CPU total)=46951.3046875MB
INFO:root:[   62] Training loss: 0.69841567, Validation loss: 0.70481479, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47105.5546875MB; mem (CPU total)=46988.78515625MB
INFO:root:[   63] Training loss: 0.69836598, Validation loss: 0.70071711, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47143.6484375MB; mem (CPU total)=47027.32421875MB
INFO:root:[   64] Training loss: 0.69916477, Validation loss: 0.70271987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47181.74609375MB; mem (CPU total)=47065.2734375MB
INFO:root:[   65] Training loss: 0.69946405, Validation loss: 0.69903823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47219.83984375MB; mem (CPU total)=47103.50390625MB
INFO:root:[   66] Training loss: 0.69924918, Validation loss: 0.69676520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47257.93359375MB; mem (CPU total)=47141.78125MB
INFO:root:[   67] Training loss: 0.69874007, Validation loss: 0.70193256, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=47296.02734375MB; mem (CPU total)=47179.265625MB
INFO:root:EP 67: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=47334.125MB; mem (CPU total)=47216.875MB
INFO:root:Training the model took 5135.537s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.98027
INFO:root:EnergyScoreTrain: 0.69101
INFO:root:CRPSTrain: 0.5953
INFO:root:Gaussian NLLTrain: 36194525711.9289
INFO:root:CoverageTrain: 0.7725
INFO:root:IntervalWidthTrain: 3.09467
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9814
INFO:root:EnergyScoreValidation: 0.69181
INFO:root:CRPSValidation: 0.59609
INFO:root:Gaussian NLLValidation: 36509632466.48884
INFO:root:CoverageValidation: 0.77346
INFO:root:IntervalWidthValidation: 3.09937
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.9805
INFO:root:EnergyScoreTest: 0.69117
INFO:root:CRPSTest: 0.59559
INFO:root:Gaussian NLLTest: 36096772046.84798
INFO:root:CoverageTest: 0.77294
INFO:root:IntervalWidthTest: 3.09632
INFO:root:After validation: mem (CPU python)=47376.875MB; mem (CPU total)=47260.05078125MB
