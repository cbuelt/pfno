INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=577.46484375MB; mem (CPU total)=1056.890625MB
INFO:root:############### Starting experiment with config file sswe/sfno.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=588.5MB; mem (CPU total)=1060.28515625MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=589.91796875MB; mem (CPU total)=1061.21484375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2260.76171875MB; mem (CPU total)=2502.5MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2270.34765625MB; mem (CPU total)=2511.80078125MB
INFO:root:[    1] Training loss: 0.83318730, Validation loss: 0.73816248, Gradient norm: 0.60771032
INFO:root:At the start of the epoch: mem (CPU python)=4418.62890625MB; mem (CPU total)=4215.546875MB
INFO:root:[    2] Training loss: 0.73496889, Validation loss: 0.73539113, Gradient norm: 0.38440849
INFO:root:At the start of the epoch: mem (CPU python)=4441.14453125MB; mem (CPU total)=4237.59375MB
INFO:root:[    3] Training loss: 0.73267302, Validation loss: 0.73223844, Gradient norm: 0.31569036
INFO:root:At the start of the epoch: mem (CPU python)=4462.3984375MB; mem (CPU total)=4258.671875MB
INFO:root:[    4] Training loss: 0.72568760, Validation loss: 0.71224797, Gradient norm: 0.42025110
INFO:root:At the start of the epoch: mem (CPU python)=4483.765625MB; mem (CPU total)=4280.19921875MB
INFO:root:[    5] Training loss: 0.68414872, Validation loss: 0.64939303, Gradient norm: 0.52165202
INFO:root:At the start of the epoch: mem (CPU python)=4504.98828125MB; mem (CPU total)=4302.1171875MB
INFO:root:[    6] Training loss: 0.62124004, Validation loss: 0.59139576, Gradient norm: 0.75453584
INFO:root:At the start of the epoch: mem (CPU python)=4526.171875MB; mem (CPU total)=4323.1953125MB
INFO:root:[    7] Training loss: 0.57106045, Validation loss: 0.54178082, Gradient norm: 0.90172416
INFO:root:At the start of the epoch: mem (CPU python)=4547.59765625MB; mem (CPU total)=4343.89453125MB
INFO:root:[    8] Training loss: 0.53751086, Validation loss: 0.51217314, Gradient norm: 1.01741338
INFO:root:At the start of the epoch: mem (CPU python)=4568.76953125MB; mem (CPU total)=4365.16796875MB
INFO:root:[    9] Training loss: 0.50987227, Validation loss: 0.49719173, Gradient norm: 0.99920223
INFO:root:At the start of the epoch: mem (CPU python)=4589.93359375MB; mem (CPU total)=4386.5546875MB
INFO:root:[   10] Training loss: 0.50150972, Validation loss: 0.48877192, Gradient norm: 1.20166091
INFO:root:At the start of the epoch: mem (CPU python)=4611.8359375MB; mem (CPU total)=4408.078125MB
INFO:root:[   11] Training loss: 0.49384541, Validation loss: 0.47507316, Gradient norm: 1.26835294
INFO:root:At the start of the epoch: mem (CPU python)=4633.01171875MB; mem (CPU total)=4429.75390625MB
INFO:root:[   12] Training loss: 0.47650067, Validation loss: 0.47446665, Gradient norm: 1.02930204
INFO:root:At the start of the epoch: mem (CPU python)=4654.3359375MB; mem (CPU total)=4451.0234375MB
INFO:root:[   13] Training loss: 0.46808503, Validation loss: 0.45858569, Gradient norm: 1.08378690
INFO:root:At the start of the epoch: mem (CPU python)=4675.51171875MB; mem (CPU total)=4471.84765625MB
INFO:root:[   14] Training loss: 0.46326821, Validation loss: 0.45104820, Gradient norm: 1.13768729
INFO:root:At the start of the epoch: mem (CPU python)=4696.67578125MB; mem (CPU total)=4493.0MB
INFO:root:[   15] Training loss: 0.45826861, Validation loss: 0.44458385, Gradient norm: 1.33531932
INFO:root:At the start of the epoch: mem (CPU python)=4717.8671875MB; mem (CPU total)=4514.09375MB
INFO:root:[   16] Training loss: 0.45516453, Validation loss: 0.44182311, Gradient norm: 1.45939196
INFO:root:At the start of the epoch: mem (CPU python)=4739.0390625MB; mem (CPU total)=4535.3125MB
INFO:root:[   17] Training loss: 0.45000139, Validation loss: 0.43573368, Gradient norm: 1.16976679
INFO:root:At the start of the epoch: mem (CPU python)=4760.21484375MB; mem (CPU total)=4556.52734375MB
INFO:root:[   18] Training loss: 0.44554790, Validation loss: 0.43830644, Gradient norm: 1.28136756
INFO:root:At the start of the epoch: mem (CPU python)=4781.3828125MB; mem (CPU total)=4577.62109375MB
INFO:root:[   19] Training loss: 0.44378450, Validation loss: 0.44125350, Gradient norm: 1.43930871
INFO:root:At the start of the epoch: mem (CPU python)=4802.54296875MB; mem (CPU total)=4598.9140625MB
INFO:root:[   20] Training loss: 0.43800659, Validation loss: 0.43361779, Gradient norm: 1.45647656
INFO:root:At the start of the epoch: mem (CPU python)=4823.71875MB; mem (CPU total)=4619.66796875MB
INFO:root:[   21] Training loss: 0.44041776, Validation loss: 0.43354037, Gradient norm: 1.49830238
INFO:root:At the start of the epoch: mem (CPU python)=4844.8828125MB; mem (CPU total)=4640.9921875MB
INFO:root:[   22] Training loss: 0.43436332, Validation loss: 0.42565520, Gradient norm: 1.35539689
INFO:root:At the start of the epoch: mem (CPU python)=4866.046875MB; mem (CPU total)=4662.09765625MB
INFO:root:[   23] Training loss: 0.43454510, Validation loss: 0.43316446, Gradient norm: 1.76209396
INFO:root:At the start of the epoch: mem (CPU python)=4887.2109375MB; mem (CPU total)=4683.3125MB
INFO:root:[   24] Training loss: 0.43020171, Validation loss: 0.42810629, Gradient norm: 1.43537149
INFO:root:At the start of the epoch: mem (CPU python)=4908.546875MB; mem (CPU total)=4705.00390625MB
INFO:root:[   25] Training loss: 0.43402986, Validation loss: 0.42566085, Gradient norm: 1.43648949
INFO:root:At the start of the epoch: mem (CPU python)=4930.765625MB; mem (CPU total)=4726.6328125MB
INFO:root:[   26] Training loss: 0.42625269, Validation loss: 0.43172911, Gradient norm: 1.63442358
INFO:root:At the start of the epoch: mem (CPU python)=4952.20703125MB; mem (CPU total)=4748.2578125MB
INFO:root:[   27] Training loss: 0.42645271, Validation loss: 0.41787924, Gradient norm: 1.60862020
INFO:root:At the start of the epoch: mem (CPU python)=4973.390625MB; mem (CPU total)=4769.66796875MB
INFO:root:[   28] Training loss: 0.42543208, Validation loss: 0.42347930, Gradient norm: 1.61483484
INFO:root:At the start of the epoch: mem (CPU python)=4994.55078125MB; mem (CPU total)=4791.62109375MB
INFO:root:[   29] Training loss: 0.42353148, Validation loss: 0.41373675, Gradient norm: 1.83403653
INFO:root:At the start of the epoch: mem (CPU python)=5015.72265625MB; mem (CPU total)=4812.515625MB
INFO:root:[   30] Training loss: 0.42205774, Validation loss: 0.41568484, Gradient norm: 1.64070107
INFO:root:At the start of the epoch: mem (CPU python)=5036.8828125MB; mem (CPU total)=4833.59375MB
INFO:root:[   31] Training loss: 0.42226594, Validation loss: 0.41306641, Gradient norm: 1.78257508
INFO:root:At the start of the epoch: mem (CPU python)=5058.0546875MB; mem (CPU total)=4854.94921875MB
INFO:root:[   32] Training loss: 0.42148905, Validation loss: 0.40873200, Gradient norm: 2.00677704
INFO:root:At the start of the epoch: mem (CPU python)=5079.22265625MB; mem (CPU total)=4876.62890625MB
INFO:root:[   33] Training loss: 0.41952337, Validation loss: 0.41378541, Gradient norm: 1.66525238
INFO:root:At the start of the epoch: mem (CPU python)=5100.39453125MB; mem (CPU total)=4897.53125MB
INFO:root:[   34] Training loss: 0.41715459, Validation loss: 0.40809867, Gradient norm: 1.66739843
INFO:root:At the start of the epoch: mem (CPU python)=5121.56640625MB; mem (CPU total)=4918.50390625MB
INFO:root:[   35] Training loss: 0.41639789, Validation loss: 0.42005307, Gradient norm: 1.82860906
INFO:root:At the start of the epoch: mem (CPU python)=5142.8203125MB; mem (CPU total)=4940.53125MB
INFO:root:[   36] Training loss: 0.41456019, Validation loss: 0.39884029, Gradient norm: 2.08541572
INFO:root:At the start of the epoch: mem (CPU python)=5164.28125MB; mem (CPU total)=4961.88671875MB
INFO:root:[   37] Training loss: 0.41354957, Validation loss: 0.40798843, Gradient norm: 1.85086374
INFO:root:At the start of the epoch: mem (CPU python)=5185.6640625MB; mem (CPU total)=4983.1796875MB
INFO:root:[   38] Training loss: 0.41330986, Validation loss: 0.40170973, Gradient norm: 2.06043034
INFO:root:At the start of the epoch: mem (CPU python)=5206.99609375MB; mem (CPU total)=5004.2265625MB
INFO:root:[   39] Training loss: 0.40814351, Validation loss: 0.39952980, Gradient norm: 2.07465404
INFO:root:At the start of the epoch: mem (CPU python)=5228.16015625MB; mem (CPU total)=5025.42578125MB
INFO:root:[   40] Training loss: 0.41538165, Validation loss: 0.40905295, Gradient norm: 1.76258416
INFO:root:At the start of the epoch: mem (CPU python)=5249.2421875MB; mem (CPU total)=5046.55859375MB
INFO:root:[   41] Training loss: 0.40918674, Validation loss: 0.39519090, Gradient norm: 2.33313930
INFO:root:At the start of the epoch: mem (CPU python)=5270.62890625MB; mem (CPU total)=5068.49609375MB
INFO:root:[   42] Training loss: 0.40466858, Validation loss: 0.39800866, Gradient norm: 2.28905325
INFO:root:At the start of the epoch: mem (CPU python)=5291.80078125MB; mem (CPU total)=5090.06640625MB
INFO:root:[   43] Training loss: 0.41000274, Validation loss: 0.40988511, Gradient norm: 1.93796656
INFO:root:At the start of the epoch: mem (CPU python)=5313.21875MB; mem (CPU total)=5111.0859375MB
INFO:root:[   44] Training loss: 0.40792951, Validation loss: 0.39711188, Gradient norm: 2.22878128
INFO:root:At the start of the epoch: mem (CPU python)=5335.28125MB; mem (CPU total)=5133.0859375MB
INFO:root:[   45] Training loss: 0.40577027, Validation loss: 0.40066659, Gradient norm: 2.28410722
INFO:root:At the start of the epoch: mem (CPU python)=5356.6796875MB; mem (CPU total)=5154.0078125MB
INFO:root:[   46] Training loss: 0.40368891, Validation loss: 0.38911475, Gradient norm: 2.49171920
INFO:root:At the start of the epoch: mem (CPU python)=5378.046875MB; mem (CPU total)=5175.79296875MB
INFO:root:[   47] Training loss: 0.40114716, Validation loss: 0.38862814, Gradient norm: 2.54660404
INFO:root:At the start of the epoch: mem (CPU python)=5400.25390625MB; mem (CPU total)=5198.0703125MB
INFO:root:[   48] Training loss: 0.40491780, Validation loss: 0.39603734, Gradient norm: 2.72513426
INFO:root:At the start of the epoch: mem (CPU python)=5421.67578125MB; mem (CPU total)=5219.0546875MB
INFO:root:[   49] Training loss: 0.40487997, Validation loss: 0.38831538, Gradient norm: 2.05550861
INFO:root:At the start of the epoch: mem (CPU python)=5442.84765625MB; mem (CPU total)=5240.2890625MB
INFO:root:[   50] Training loss: 0.40334016, Validation loss: 0.40150318, Gradient norm: 2.71488608
INFO:root:At the start of the epoch: mem (CPU python)=5464.8828125MB; mem (CPU total)=5262.59765625MB
INFO:root:[   51] Training loss: 0.40169717, Validation loss: 0.38978574, Gradient norm: 2.86652641
INFO:root:At the start of the epoch: mem (CPU python)=5486.06640625MB; mem (CPU total)=5283.828125MB
INFO:root:[   52] Training loss: 0.40375267, Validation loss: 0.38601641, Gradient norm: 2.70552859
INFO:root:At the start of the epoch: mem (CPU python)=5507.11328125MB; mem (CPU total)=5304.99609375MB
INFO:root:[   53] Training loss: 0.40115244, Validation loss: 0.38924889, Gradient norm: 2.81147154
INFO:root:At the start of the epoch: mem (CPU python)=5530.6953125MB; mem (CPU total)=5328.47265625MB
INFO:root:[   54] Training loss: 0.40758363, Validation loss: 0.39695218, Gradient norm: 3.06516021
INFO:root:At the start of the epoch: mem (CPU python)=5551.86328125MB; mem (CPU total)=5350.0MB
INFO:root:[   55] Training loss: 0.40004415, Validation loss: 0.38310140, Gradient norm: 3.14112446
INFO:root:At the start of the epoch: mem (CPU python)=5573.2421875MB; mem (CPU total)=5372.125MB
INFO:root:[   56] Training loss: 0.40070700, Validation loss: 0.39107734, Gradient norm: 3.25494283
INFO:root:At the start of the epoch: mem (CPU python)=5594.40234375MB; mem (CPU total)=5393.41015625MB
INFO:root:[   57] Training loss: 0.40308933, Validation loss: 0.38574353, Gradient norm: 3.26496250
INFO:root:At the start of the epoch: mem (CPU python)=5615.5703125MB; mem (CPU total)=5414.6875MB
INFO:root:[   58] Training loss: 0.40384012, Validation loss: 0.39098429, Gradient norm: 2.96674402
INFO:root:At the start of the epoch: mem (CPU python)=5636.75MB; mem (CPU total)=5435.671875MB
INFO:root:[   59] Training loss: 0.40272938, Validation loss: 0.39135486, Gradient norm: 2.90915823
INFO:root:At the start of the epoch: mem (CPU python)=5659.15625MB; mem (CPU total)=5458.59375MB
INFO:root:[   60] Training loss: 0.40601963, Validation loss: 0.41137379, Gradient norm: 3.56249456
INFO:root:At the start of the epoch: mem (CPU python)=5680.60546875MB; mem (CPU total)=5479.640625MB
INFO:root:[   61] Training loss: 0.40008964, Validation loss: 0.40619075, Gradient norm: 2.88336921
INFO:root:At the start of the epoch: mem (CPU python)=5701.7734375MB; mem (CPU total)=5500.828125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   62] Training loss: 0.40180199, Validation loss: 0.39110809, Gradient norm: 2.98895058
INFO:root:At the start of the epoch: mem (CPU python)=5722.9375MB; mem (CPU total)=5521.98828125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   63] Training loss: 0.37691954, Validation loss: 0.36607676, Gradient norm: 2.52510380
INFO:root:At the start of the epoch: mem (CPU python)=5744.1015625MB; mem (CPU total)=5543.09375MB
INFO:root:[   64] Training loss: 0.36726428, Validation loss: 0.36091215, Gradient norm: 1.82973803
INFO:root:At the start of the epoch: mem (CPU python)=5765.265625MB; mem (CPU total)=5564.44921875MB
INFO:root:[   65] Training loss: 0.36607278, Validation loss: 0.35634509, Gradient norm: 2.06208431
INFO:root:At the start of the epoch: mem (CPU python)=5786.43359375MB; mem (CPU total)=5585.59375MB
INFO:root:[   66] Training loss: 0.36816552, Validation loss: 0.35727001, Gradient norm: 2.94811536
INFO:root:At the start of the epoch: mem (CPU python)=5807.60546875MB; mem (CPU total)=5606.7578125MB
INFO:root:[   67] Training loss: 0.36553475, Validation loss: 0.35708296, Gradient norm: 2.44849352
INFO:root:At the start of the epoch: mem (CPU python)=5828.7734375MB; mem (CPU total)=5627.89453125MB
INFO:root:[   68] Training loss: 0.36503705, Validation loss: 0.35742024, Gradient norm: 2.64166752
INFO:root:At the start of the epoch: mem (CPU python)=5850.40234375MB; mem (CPU total)=5650.171875MB
INFO:root:[   69] Training loss: 0.36431525, Validation loss: 0.35521233, Gradient norm: 2.98584293
INFO:root:At the start of the epoch: mem (CPU python)=5871.86328125MB; mem (CPU total)=5671.703125MB
INFO:root:[   70] Training loss: 0.36382624, Validation loss: 0.35590986, Gradient norm: 3.20788633
INFO:root:At the start of the epoch: mem (CPU python)=5893.02734375MB; mem (CPU total)=5692.4765625MB
INFO:root:[   71] Training loss: 0.36427655, Validation loss: 0.35607431, Gradient norm: 3.19115114
INFO:root:At the start of the epoch: mem (CPU python)=5915.0625MB; mem (CPU total)=5714.9296875MB
INFO:root:[   72] Training loss: 0.36288247, Validation loss: 0.35359108, Gradient norm: 3.28309226
INFO:root:At the start of the epoch: mem (CPU python)=5936.49609375MB; mem (CPU total)=5736.30859375MB
INFO:root:[   73] Training loss: 0.36521907, Validation loss: 0.35637458, Gradient norm: 3.91361475
INFO:root:At the start of the epoch: mem (CPU python)=5957.66015625MB; mem (CPU total)=5757.4375MB
INFO:root:[   74] Training loss: 0.36267263, Validation loss: 0.35574383, Gradient norm: 3.74186286
INFO:root:At the start of the epoch: mem (CPU python)=5980.16796875MB; mem (CPU total)=5780.4140625MB
INFO:root:[   75] Training loss: 0.36291746, Validation loss: 0.35586315, Gradient norm: 4.43834230
INFO:root:At the start of the epoch: mem (CPU python)=6001.45703125MB; mem (CPU total)=5801.54296875MB
INFO:root:[   76] Training loss: 0.36250979, Validation loss: 0.35344910, Gradient norm: 4.54347618
INFO:root:At the start of the epoch: mem (CPU python)=6023.0390625MB; mem (CPU total)=5822.6796875MB
INFO:root:[   77] Training loss: 0.36233670, Validation loss: 0.35586596, Gradient norm: 4.60669843
INFO:root:At the start of the epoch: mem (CPU python)=6044.203125MB; mem (CPU total)=5843.80859375MB
INFO:root:[   78] Training loss: 0.36735694, Validation loss: 0.38830556, Gradient norm: 6.19012696
INFO:root:At the start of the epoch: mem (CPU python)=6065.3671875MB; mem (CPU total)=5864.97265625MB
INFO:root:[   79] Training loss: 0.36437819, Validation loss: 0.35440549, Gradient norm: 4.75015688
INFO:root:At the start of the epoch: mem (CPU python)=6086.53125MB; mem (CPU total)=5886.14453125MB
INFO:root:[   80] Training loss: 0.36337087, Validation loss: 0.35704095, Gradient norm: 4.89514350
INFO:root:At the start of the epoch: mem (CPU python)=6107.6953125MB; mem (CPU total)=5907.31640625MB
INFO:root:[   81] Training loss: 0.36246818, Validation loss: 0.35406583, Gradient norm: 5.01502480
INFO:root:At the start of the epoch: mem (CPU python)=6128.86328125MB; mem (CPU total)=5928.48828125MB
INFO:root:[   82] Training loss: 0.36297664, Validation loss: 0.35370551, Gradient norm: 5.23697626
INFO:root:At the start of the epoch: mem (CPU python)=6150.02734375MB; mem (CPU total)=5949.43359375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   83] Training loss: 0.36247282, Validation loss: 0.35524383, Gradient norm: 5.42042487
INFO:root:At the start of the epoch: mem (CPU python)=6171.17578125MB; mem (CPU total)=5979.34765625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   84] Training loss: 0.35899787, Validation loss: 0.35009939, Gradient norm: 3.54719367
INFO:root:At the start of the epoch: mem (CPU python)=6192.359375MB; mem (CPU total)=6000.2734375MB
INFO:root:[   85] Training loss: 0.35555540, Validation loss: 0.34699013, Gradient norm: 2.25316041
INFO:root:At the start of the epoch: mem (CPU python)=6214.21875MB; mem (CPU total)=6119.0078125MB
INFO:root:[   86] Training loss: 0.35541754, Validation loss: 0.34736699, Gradient norm: 2.31065707
INFO:root:At the start of the epoch: mem (CPU python)=6235.3828125MB; mem (CPU total)=6049.29296875MB
INFO:root:[   87] Training loss: 0.35543328, Validation loss: 0.34694930, Gradient norm: 3.14961331
INFO:root:At the start of the epoch: mem (CPU python)=6256.97265625MB; mem (CPU total)=6069.078125MB
INFO:root:[   88] Training loss: 0.35513778, Validation loss: 0.34603643, Gradient norm: 2.49633419
INFO:root:At the start of the epoch: mem (CPU python)=6278.13671875MB; mem (CPU total)=6090.4453125MB
INFO:root:[   89] Training loss: 0.35517636, Validation loss: 0.34567379, Gradient norm: 2.99463619
INFO:root:At the start of the epoch: mem (CPU python)=6299.296875MB; mem (CPU total)=6111.36328125MB
INFO:root:[   90] Training loss: 0.35546169, Validation loss: 0.34756263, Gradient norm: 3.35582847
INFO:root:At the start of the epoch: mem (CPU python)=6320.45703125MB; mem (CPU total)=6132.28125MB
INFO:root:[   91] Training loss: 0.35466621, Validation loss: 0.34622472, Gradient norm: 3.17193197
INFO:root:At the start of the epoch: mem (CPU python)=6341.62109375MB; mem (CPU total)=6153.6640625MB
INFO:root:[   92] Training loss: 0.35469653, Validation loss: 0.34558454, Gradient norm: 3.24258535
INFO:root:At the start of the epoch: mem (CPU python)=6362.79296875MB; mem (CPU total)=6174.08984375MB
INFO:root:[   93] Training loss: 0.35474828, Validation loss: 0.34707471, Gradient norm: 3.39918662
INFO:root:At the start of the epoch: mem (CPU python)=6383.953125MB; mem (CPU total)=6195.6875MB
INFO:root:[   94] Training loss: 0.35477567, Validation loss: 0.34650319, Gradient norm: 3.43256487
INFO:root:At the start of the epoch: mem (CPU python)=6405.125MB; mem (CPU total)=6216.609375MB
INFO:root:[   95] Training loss: 0.35532015, Validation loss: 0.34588062, Gradient norm: 3.69149508
INFO:root:At the start of the epoch: mem (CPU python)=6426.28515625MB; mem (CPU total)=6237.34765625MB
INFO:root:[   96] Training loss: 0.35473527, Validation loss: 0.34581704, Gradient norm: 4.85894863
INFO:root:At the start of the epoch: mem (CPU python)=6447.44921875MB; mem (CPU total)=6353.859375MB
INFO:root:[   97] Training loss: 0.35610527, Validation loss: 0.35066036, Gradient norm: 6.59118025
INFO:root:At the start of the epoch: mem (CPU python)=6468.98046875MB; mem (CPU total)=6279.828125MB
INFO:root:[   98] Training loss: 0.35522384, Validation loss: 0.34508139, Gradient norm: 5.12229982
INFO:root:At the start of the epoch: mem (CPU python)=6491.41015625MB; mem (CPU total)=6301.84765625MB
INFO:root:[   99] Training loss: 0.35470647, Validation loss: 0.34541274, Gradient norm: 4.45469741
INFO:root:At the start of the epoch: mem (CPU python)=6513.64453125MB; mem (CPU total)=6324.08984375MB
INFO:root:[  100] Training loss: 0.35437640, Validation loss: 0.34631207, Gradient norm: 4.60791585
INFO:root:At the start of the epoch: mem (CPU python)=6535.10546875MB; mem (CPU total)=6345.25390625MB
INFO:root:[  101] Training loss: 0.35543076, Validation loss: 0.34665198, Gradient norm: 6.63634640
INFO:root:At the start of the epoch: mem (CPU python)=6556.27734375MB; mem (CPU total)=6366.8203125MB
INFO:root:[  102] Training loss: 0.35414903, Validation loss: 0.34597049, Gradient norm: 4.68947003
INFO:root:At the start of the epoch: mem (CPU python)=6577.34765625MB; mem (CPU total)=6387.3984375MB
INFO:root:[  103] Training loss: 0.35488191, Validation loss: 0.34610928, Gradient norm: 4.97020506
INFO:root:At the start of the epoch: mem (CPU python)=6598.609375MB; mem (CPU total)=6408.7734375MB
INFO:root:[  104] Training loss: 0.35455709, Validation loss: 0.34596449, Gradient norm: 5.22285598
INFO:root:At the start of the epoch: mem (CPU python)=6619.76953125MB; mem (CPU total)=6430.7421875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  105] Training loss: 0.35417515, Validation loss: 0.34565687, Gradient norm: 5.30113811
INFO:root:At the start of the epoch: mem (CPU python)=6640.93359375MB; mem (CPU total)=6451.91796875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  106] Training loss: 0.35330058, Validation loss: 0.34541428, Gradient norm: 3.49228294
INFO:root:At the start of the epoch: mem (CPU python)=6662.1015625MB; mem (CPU total)=6473.08984375MB
INFO:root:[  107] Training loss: 0.35230116, Validation loss: 0.34449936, Gradient norm: 2.47384691
INFO:root:At the start of the epoch: mem (CPU python)=6683.26953125MB; mem (CPU total)=6494.5078125MB
INFO:root:[  108] Training loss: 0.35253498, Validation loss: 0.34352193, Gradient norm: 2.46571413
INFO:root:At the start of the epoch: mem (CPU python)=6704.421875MB; mem (CPU total)=6515.3359375MB
INFO:root:[  109] Training loss: 0.35240726, Validation loss: 0.34382797, Gradient norm: 2.60053160
INFO:root:At the start of the epoch: mem (CPU python)=6725.5859375MB; mem (CPU total)=6536.5078125MB
INFO:root:[  110] Training loss: 0.35280633, Validation loss: 0.34391241, Gradient norm: 2.87008074
INFO:root:At the start of the epoch: mem (CPU python)=6746.7578125MB; mem (CPU total)=6557.92578125MB
INFO:root:[  111] Training loss: 0.35276540, Validation loss: 0.34374266, Gradient norm: 2.86536618
INFO:root:At the start of the epoch: mem (CPU python)=6767.921875MB; mem (CPU total)=6579.06640625MB
INFO:root:[  112] Training loss: 0.35186549, Validation loss: 0.34416267, Gradient norm: 2.66693924
INFO:root:At the start of the epoch: mem (CPU python)=6789.0859375MB; mem (CPU total)=6600.234375MB
INFO:root:[  113] Training loss: 0.35228715, Validation loss: 0.34367282, Gradient norm: 3.10551907
INFO:root:At the start of the epoch: mem (CPU python)=6810.25MB; mem (CPU total)=6621.40625MB
INFO:root:[  114] Training loss: 0.35243791, Validation loss: 0.34350981, Gradient norm: 3.13927532
INFO:root:At the start of the epoch: mem (CPU python)=6831.421875MB; mem (CPU total)=6642.5703125MB
INFO:root:[  115] Training loss: 0.35237863, Validation loss: 0.34358814, Gradient norm: 3.09204323
INFO:root:At the start of the epoch: mem (CPU python)=6852.578125MB; mem (CPU total)=6664.3828125MB
INFO:root:[  116] Training loss: 0.35207334, Validation loss: 0.34364651, Gradient norm: 3.07451573
INFO:root:At the start of the epoch: mem (CPU python)=6875.0546875MB; mem (CPU total)=6686.640625MB
INFO:root:[  117] Training loss: 0.35216687, Validation loss: 0.34345431, Gradient norm: 3.29022083
INFO:root:At the start of the epoch: mem (CPU python)=6896.4140625MB; mem (CPU total)=6707.8046875MB
INFO:root:[  118] Training loss: 0.35264881, Validation loss: 0.34368058, Gradient norm: 3.17010360
INFO:root:At the start of the epoch: mem (CPU python)=6917.5703125MB; mem (CPU total)=6729.0078125MB
INFO:root:[  119] Training loss: 0.35271655, Validation loss: 0.34434733, Gradient norm: 3.35256174
INFO:root:At the start of the epoch: mem (CPU python)=6938.76171875MB; mem (CPU total)=6749.9375MB
INFO:root:[  120] Training loss: 0.35225688, Validation loss: 0.34346008, Gradient norm: 3.27151708
INFO:root:At the start of the epoch: mem (CPU python)=6959.92578125MB; mem (CPU total)=6771.35546875MB
INFO:root:[  121] Training loss: 0.35218401, Validation loss: 0.34376807, Gradient norm: 3.49171447
INFO:root:At the start of the epoch: mem (CPU python)=6981.08984375MB; mem (CPU total)=6792.37109375MB
INFO:root:[  122] Training loss: 0.35180654, Validation loss: 0.34374285, Gradient norm: 3.68067211
INFO:root:At the start of the epoch: mem (CPU python)=7002.4453125MB; mem (CPU total)=6813.76171875MB
INFO:root:[  123] Training loss: 0.35248417, Validation loss: 0.34328649, Gradient norm: 3.45627358
INFO:root:At the start of the epoch: mem (CPU python)=7023.6484375MB; mem (CPU total)=6835.08203125MB
INFO:root:[  124] Training loss: 0.35204660, Validation loss: 0.34405508, Gradient norm: 3.34620910
INFO:root:At the start of the epoch: mem (CPU python)=7044.96875MB; mem (CPU total)=6856.21875MB
INFO:root:[  125] Training loss: 0.35266281, Validation loss: 0.34318206, Gradient norm: 3.56348471
INFO:root:At the start of the epoch: mem (CPU python)=7066.13671875MB; mem (CPU total)=6877.62890625MB
INFO:root:[  126] Training loss: 0.35184097, Validation loss: 0.34304132, Gradient norm: 4.15241946
INFO:root:At the start of the epoch: mem (CPU python)=7087.3046875MB; mem (CPU total)=6898.71875MB
INFO:root:[  127] Training loss: 0.35130515, Validation loss: 0.34352110, Gradient norm: 3.91884011
INFO:root:At the start of the epoch: mem (CPU python)=7108.46484375MB; mem (CPU total)=6919.94140625MB
INFO:root:[  128] Training loss: 0.35143482, Validation loss: 0.34338344, Gradient norm: 3.90238741
INFO:root:At the start of the epoch: mem (CPU python)=7131.34765625MB; mem (CPU total)=6943.16015625MB
INFO:root:[  129] Training loss: 0.35224897, Validation loss: 0.34355236, Gradient norm: 3.68289824
INFO:root:At the start of the epoch: mem (CPU python)=7153.62890625MB; mem (CPU total)=6965.34375MB
INFO:root:[  130] Training loss: 0.35190980, Validation loss: 0.34329643, Gradient norm: 3.98822873
INFO:root:At the start of the epoch: mem (CPU python)=7175.140625MB; mem (CPU total)=6987.16015625MB
INFO:root:[  131] Training loss: 0.35260344, Validation loss: 0.34387789, Gradient norm: 3.86512571
INFO:root:At the start of the epoch: mem (CPU python)=7196.30859375MB; mem (CPU total)=7008.32421875MB
INFO:root:[  132] Training loss: 0.35232776, Validation loss: 0.34414611, Gradient norm: 3.87579707
INFO:root:At the start of the epoch: mem (CPU python)=7218.73828125MB; mem (CPU total)=7030.75390625MB
INFO:root:[  133] Training loss: 0.35220747, Validation loss: 0.34334541, Gradient norm: 4.26970770
INFO:root:At the start of the epoch: mem (CPU python)=7239.99609375MB; mem (CPU total)=7052.2734375MB
INFO:root:[  134] Training loss: 0.35231532, Validation loss: 0.34355656, Gradient norm: 4.19607488
INFO:root:At the start of the epoch: mem (CPU python)=7261.16015625MB; mem (CPU total)=7073.43359375MB
INFO:root:[  135] Training loss: 0.35262679, Validation loss: 0.34313271, Gradient norm: 3.74877489
INFO:root:At the start of the epoch: mem (CPU python)=7282.34375MB; mem (CPU total)=7094.59765625MB
INFO:root:[  136] Training loss: 0.35236503, Validation loss: 0.34283419, Gradient norm: 3.96295578
INFO:root:At the start of the epoch: mem (CPU python)=7303.5078125MB; mem (CPU total)=7116.0390625MB
INFO:root:[  137] Training loss: 0.35230748, Validation loss: 0.34361993, Gradient norm: 4.07227461
INFO:root:At the start of the epoch: mem (CPU python)=7324.68359375MB; mem (CPU total)=7137.328125MB
INFO:root:[  138] Training loss: 0.35165944, Validation loss: 0.34297515, Gradient norm: 4.16206425
INFO:root:At the start of the epoch: mem (CPU python)=7345.8515625MB; mem (CPU total)=7158.23828125MB
INFO:root:[  139] Training loss: 0.35203374, Validation loss: 0.34386009, Gradient norm: 4.16459632
INFO:root:At the start of the epoch: mem (CPU python)=7367.03125MB; mem (CPU total)=7179.3984375MB
INFO:root:[  140] Training loss: 0.35157145, Validation loss: 0.34426323, Gradient norm: 4.88082964
INFO:root:At the start of the epoch: mem (CPU python)=7388.9453125MB; mem (CPU total)=7201.26953125MB
INFO:root:[  141] Training loss: 0.35269217, Validation loss: 0.34348615, Gradient norm: 4.98358170
INFO:root:At the start of the epoch: mem (CPU python)=7410.109375MB; mem (CPU total)=7222.92578125MB
INFO:root:[  142] Training loss: 0.35201876, Validation loss: 0.34349672, Gradient norm: 4.80136000
INFO:root:At the start of the epoch: mem (CPU python)=7431.30078125MB; mem (CPU total)=7244.08984375MB
INFO:root:[  143] Training loss: 0.35173151, Validation loss: 0.34256144, Gradient norm: 4.96178713
INFO:root:At the start of the epoch: mem (CPU python)=7452.46875MB; mem (CPU total)=7265.0078125MB
INFO:root:[  144] Training loss: 0.35205552, Validation loss: 0.34326197, Gradient norm: 4.44346508
INFO:root:At the start of the epoch: mem (CPU python)=7473.64453125MB; mem (CPU total)=7286.16796875MB
INFO:root:[  145] Training loss: 0.35171584, Validation loss: 0.34330078, Gradient norm: 4.69697518
INFO:root:At the start of the epoch: mem (CPU python)=7494.80859375MB; mem (CPU total)=7307.29296875MB
INFO:root:[  146] Training loss: 0.35194065, Validation loss: 0.34328997, Gradient norm: 4.96099056
INFO:root:At the start of the epoch: mem (CPU python)=7515.98828125MB; mem (CPU total)=7328.45703125MB
INFO:root:[  147] Training loss: 0.35172380, Validation loss: 0.34360276, Gradient norm: 5.02235177
INFO:root:At the start of the epoch: mem (CPU python)=7537.15234375MB; mem (CPU total)=7349.8671875MB
INFO:root:[  148] Training loss: 0.35143284, Validation loss: 0.34325662, Gradient norm: 4.99552458
INFO:root:At the start of the epoch: mem (CPU python)=7558.32421875MB; mem (CPU total)=7371.03125MB
INFO:root:[  149] Training loss: 0.35167729, Validation loss: 0.34270199, Gradient norm: 4.61070095
INFO:root:At the start of the epoch: mem (CPU python)=7579.51171875MB; mem (CPU total)=7392.1640625MB
INFO:root:[  150] Training loss: 0.35220666, Validation loss: 0.34307500, Gradient norm: 4.77144743
INFO:root:At the start of the epoch: mem (CPU python)=7600.67578125MB; mem (CPU total)=7413.328125MB
INFO:root:[  151] Training loss: 0.35293436, Validation loss: 0.34375267, Gradient norm: 5.47024358
INFO:root:At the start of the epoch: mem (CPU python)=7622.01171875MB; mem (CPU total)=7434.48828125MB
INFO:root:[  152] Training loss: 0.35249615, Validation loss: 0.34294332, Gradient norm: 5.03510118
INFO:root:At the start of the epoch: mem (CPU python)=7643.390625MB; mem (CPU total)=7455.65234375MB
INFO:root:EP 152: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=7664.57421875MB; mem (CPU total)=7476.81640625MB
INFO:root:Training the model took 3653.231s.
INFO:root:Emptying the cuda cache took 0.033s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.39395
INFO:root:EnergyScoreValidation: 0.24407
INFO:root:CRPSValidation: 0.10534
INFO:root:Gaussian NLLValidation: 12.48677
INFO:root:CoverageValidation: 0.53423
INFO:root:IntervalWidthValidation: 0.30915
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.42313
INFO:root:EnergyScoreTest: 0.2711
INFO:root:CRPSTest: 0.11605
INFO:root:Gaussian NLLTest: 25.15149
INFO:root:CoverageTest: 0.50528
INFO:root:IntervalWidthTest: 0.29964
INFO:root:After validation: mem (CPU python)=8024.0078125MB; mem (CPU total)=7700.2421875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=8024.0078125MB; mem (CPU total)=7700.73046875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 367001600
INFO:root:After setting up the model: mem (CPU python)=8036.39453125MB; mem (CPU total)=7713.46875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=8036.39453125MB; mem (CPU total)=7713.16015625MB
INFO:root:[    1] Training loss: 0.83787462, Validation loss: 0.73605332, Gradient norm: 0.51659137
INFO:root:At the start of the epoch: mem (CPU python)=8070.26953125MB; mem (CPU total)=7746.2421875MB
INFO:root:[    2] Training loss: 0.73831083, Validation loss: 0.73343866, Gradient norm: 0.35461291
INFO:root:At the start of the epoch: mem (CPU python)=8091.45703125MB; mem (CPU total)=7767.40234375MB
INFO:root:[    3] Training loss: 0.73502300, Validation loss: 0.73000225, Gradient norm: 0.35775215
INFO:root:At the start of the epoch: mem (CPU python)=8112.63671875MB; mem (CPU total)=7788.56640625MB
INFO:root:[    4] Training loss: 0.71570278, Validation loss: 0.69910774, Gradient norm: 0.52419393
INFO:root:At the start of the epoch: mem (CPU python)=8133.80078125MB; mem (CPU total)=7809.73046875MB
INFO:root:[    5] Training loss: 0.66997410, Validation loss: 0.63783371, Gradient norm: 0.65476247
INFO:root:At the start of the epoch: mem (CPU python)=8154.96875MB; mem (CPU total)=7830.89453125MB
INFO:root:[    6] Training loss: 0.62633287, Validation loss: 0.61637208, Gradient norm: 0.98089390
INFO:root:At the start of the epoch: mem (CPU python)=8176.1328125MB; mem (CPU total)=7852.046875MB
INFO:root:[    7] Training loss: 0.59531154, Validation loss: 0.58956879, Gradient norm: 0.93730274
INFO:root:At the start of the epoch: mem (CPU python)=8197.296875MB; mem (CPU total)=7873.2109375MB
INFO:root:[    8] Training loss: 0.57650475, Validation loss: 0.54643295, Gradient norm: 1.40159100
INFO:root:At the start of the epoch: mem (CPU python)=8218.4609375MB; mem (CPU total)=7894.375MB
INFO:root:[    9] Training loss: 0.54850952, Validation loss: 0.54106330, Gradient norm: 1.17322369
INFO:root:At the start of the epoch: mem (CPU python)=8239.625MB; mem (CPU total)=7915.5390625MB
INFO:root:[   10] Training loss: 0.53251108, Validation loss: 0.51285840, Gradient norm: 1.40860771
INFO:root:At the start of the epoch: mem (CPU python)=8260.79296875MB; mem (CPU total)=7936.94921875MB
INFO:root:[   11] Training loss: 0.52280939, Validation loss: 0.49091619, Gradient norm: 1.56071152
INFO:root:At the start of the epoch: mem (CPU python)=8281.9609375MB; mem (CPU total)=7958.046875MB
INFO:root:[   12] Training loss: 0.50573743, Validation loss: 0.47702580, Gradient norm: 1.74450007
INFO:root:At the start of the epoch: mem (CPU python)=8303.125MB; mem (CPU total)=7978.1875MB
INFO:root:[   13] Training loss: 0.49960472, Validation loss: 0.48415421, Gradient norm: 1.54716676
INFO:root:At the start of the epoch: mem (CPU python)=8324.28515625MB; mem (CPU total)=7999.31640625MB
INFO:root:[   14] Training loss: 0.49403792, Validation loss: 0.47817862, Gradient norm: 1.97621297
INFO:root:At the start of the epoch: mem (CPU python)=8345.453125MB; mem (CPU total)=8020.703125MB
INFO:root:[   15] Training loss: 0.48879829, Validation loss: 0.47175877, Gradient norm: 1.81110307
INFO:root:At the start of the epoch: mem (CPU python)=8366.61328125MB; mem (CPU total)=8041.859375MB
INFO:root:[   16] Training loss: 0.48485375, Validation loss: 0.46768987, Gradient norm: 2.04812920
INFO:root:At the start of the epoch: mem (CPU python)=8387.78125MB; mem (CPU total)=8063.05078125MB
INFO:root:[   17] Training loss: 0.48280696, Validation loss: 0.46715702, Gradient norm: 1.88707004
INFO:root:At the start of the epoch: mem (CPU python)=8408.9453125MB; mem (CPU total)=8084.21484375MB
INFO:root:[   18] Training loss: 0.47560708, Validation loss: 0.46876911, Gradient norm: 1.90344219
INFO:root:At the start of the epoch: mem (CPU python)=8430.109375MB; mem (CPU total)=8105.625MB
INFO:root:[   19] Training loss: 0.47300356, Validation loss: 0.44848245, Gradient norm: 1.77479487
INFO:root:At the start of the epoch: mem (CPU python)=8451.2734375MB; mem (CPU total)=8126.7890625MB
INFO:root:[   20] Training loss: 0.47050994, Validation loss: 0.44090580, Gradient norm: 2.06260154
INFO:root:At the start of the epoch: mem (CPU python)=8472.4375MB; mem (CPU total)=8147.953125MB
INFO:root:[   21] Training loss: 0.47023347, Validation loss: 0.44795831, Gradient norm: 2.05349437
INFO:root:At the start of the epoch: mem (CPU python)=8493.6015625MB; mem (CPU total)=8169.1171875MB
INFO:root:[   22] Training loss: 0.46717524, Validation loss: 0.45884926, Gradient norm: 2.11698456
INFO:root:At the start of the epoch: mem (CPU python)=8514.76953125MB; mem (CPU total)=8190.2734375MB
INFO:root:[   23] Training loss: 0.46275109, Validation loss: 0.45347422, Gradient norm: 1.85266550
INFO:root:At the start of the epoch: mem (CPU python)=8535.93359375MB; mem (CPU total)=8211.6796875MB
INFO:root:[   24] Training loss: 0.46387357, Validation loss: 0.44817149, Gradient norm: 2.18157716
INFO:root:At the start of the epoch: mem (CPU python)=8557.09765625MB; mem (CPU total)=8232.84375MB
INFO:root:[   25] Training loss: 0.46406882, Validation loss: 0.43910600, Gradient norm: 2.24106194
INFO:root:At the start of the epoch: mem (CPU python)=8578.26171875MB; mem (CPU total)=8254.0078125MB
INFO:root:[   26] Training loss: 0.45991688, Validation loss: 0.43491108, Gradient norm: 2.28590275
INFO:root:At the start of the epoch: mem (CPU python)=8599.42578125MB; mem (CPU total)=8275.203125MB
INFO:root:[   27] Training loss: 0.46241462, Validation loss: 0.47394087, Gradient norm: 2.09261396
INFO:root:At the start of the epoch: mem (CPU python)=8620.58984375MB; mem (CPU total)=8296.61328125MB
INFO:root:[   28] Training loss: 0.46187485, Validation loss: 0.44051649, Gradient norm: 2.49604601
INFO:root:At the start of the epoch: mem (CPU python)=8641.75390625MB; mem (CPU total)=8317.74609375MB
INFO:root:[   29] Training loss: 0.45855520, Validation loss: 0.44080773, Gradient norm: 2.15041508
INFO:root:At the start of the epoch: mem (CPU python)=8662.9140625MB; mem (CPU total)=8338.91015625MB
INFO:root:[   30] Training loss: 0.45709037, Validation loss: 0.44432692, Gradient norm: 2.22727742
INFO:root:At the start of the epoch: mem (CPU python)=8684.078125MB; mem (CPU total)=8360.0859375MB
INFO:root:[   31] Training loss: 0.45739933, Validation loss: 0.43324187, Gradient norm: 2.48321804
INFO:root:At the start of the epoch: mem (CPU python)=8705.24609375MB; mem (CPU total)=8381.27734375MB
INFO:root:[   32] Training loss: 0.45433350, Validation loss: 0.43389466, Gradient norm: 2.27795963
INFO:root:At the start of the epoch: mem (CPU python)=8726.41015625MB; mem (CPU total)=8402.43359375MB
INFO:root:[   33] Training loss: 0.45849988, Validation loss: 0.44591253, Gradient norm: 2.24312721
INFO:root:At the start of the epoch: mem (CPU python)=8747.57421875MB; mem (CPU total)=8423.859375MB
INFO:root:[   34] Training loss: 0.45398758, Validation loss: 0.47529668, Gradient norm: 2.31649205
INFO:root:At the start of the epoch: mem (CPU python)=8768.73828125MB; mem (CPU total)=8445.234375MB
INFO:root:[   35] Training loss: 0.45752867, Validation loss: 0.42940843, Gradient norm: 2.62078044
INFO:root:At the start of the epoch: mem (CPU python)=8789.90234375MB; mem (CPU total)=8466.40625MB
INFO:root:[   36] Training loss: 0.45434844, Validation loss: 0.47422387, Gradient norm: 2.47354803
INFO:root:At the start of the epoch: mem (CPU python)=8811.0703125MB; mem (CPU total)=8487.5625MB
INFO:root:[   37] Training loss: 0.45692048, Validation loss: 0.42304272, Gradient norm: 2.33922900
INFO:root:At the start of the epoch: mem (CPU python)=8832.23828125MB; mem (CPU total)=8508.72265625MB
INFO:root:[   38] Training loss: 0.45211563, Validation loss: 0.42126935, Gradient norm: 2.47828819
INFO:root:At the start of the epoch: mem (CPU python)=8853.40234375MB; mem (CPU total)=8529.88671875MB
INFO:root:[   39] Training loss: 0.45236853, Validation loss: 0.43865917, Gradient norm: 2.27209481
INFO:root:At the start of the epoch: mem (CPU python)=8874.5703125MB; mem (CPU total)=8551.265625MB
INFO:root:[   40] Training loss: 0.45256867, Validation loss: 0.42890330, Gradient norm: 2.73072604
INFO:root:At the start of the epoch: mem (CPU python)=8895.734375MB; mem (CPU total)=8572.4296875MB
INFO:root:[   41] Training loss: 0.45504141, Validation loss: 0.42893307, Gradient norm: 2.69944467
INFO:root:At the start of the epoch: mem (CPU python)=8916.8984375MB; mem (CPU total)=8593.59375MB
INFO:root:[   42] Training loss: 0.44692364, Validation loss: 0.42198188, Gradient norm: 2.84340357
INFO:root:At the start of the epoch: mem (CPU python)=8938.06640625MB; mem (CPU total)=8614.7578125MB
INFO:root:[   43] Training loss: 0.45527235, Validation loss: 0.42031566, Gradient norm: 2.72417050
INFO:root:At the start of the epoch: mem (CPU python)=8959.23046875MB; mem (CPU total)=8636.13671875MB
INFO:root:[   44] Training loss: 0.45107373, Validation loss: 0.42958267, Gradient norm: 2.88504731
INFO:root:At the start of the epoch: mem (CPU python)=8980.390625MB; mem (CPU total)=8657.546875MB
INFO:root:[   45] Training loss: 0.45137995, Validation loss: 0.42877727, Gradient norm: 2.97226767
INFO:root:At the start of the epoch: mem (CPU python)=9001.5546875MB; mem (CPU total)=8678.703125MB
INFO:root:[   46] Training loss: 0.45388230, Validation loss: 0.42268095, Gradient norm: 2.76448354
INFO:root:At the start of the epoch: mem (CPU python)=9022.71484375MB; mem (CPU total)=8700.1015625MB
INFO:root:[   47] Training loss: 0.44451548, Validation loss: 0.45089589, Gradient norm: 3.01971776
INFO:root:At the start of the epoch: mem (CPU python)=9043.8828125MB; mem (CPU total)=8721.48046875MB
INFO:root:[   48] Training loss: 0.44918192, Validation loss: 0.42656372, Gradient norm: 3.09994217
INFO:root:At the start of the epoch: mem (CPU python)=9065.05078125MB; mem (CPU total)=8742.390625MB
INFO:root:[   49] Training loss: 0.44912571, Validation loss: 0.43853431, Gradient norm: 3.16493329
INFO:root:At the start of the epoch: mem (CPU python)=9086.21484375MB; mem (CPU total)=8763.4375MB
INFO:root:[   50] Training loss: 0.44694064, Validation loss: 0.42855482, Gradient norm: 2.88485291
INFO:root:At the start of the epoch: mem (CPU python)=9107.3828125MB; mem (CPU total)=8784.8828125MB
INFO:root:[   51] Training loss: 0.43534027, Validation loss: 0.40891308, Gradient norm: 2.98150744
INFO:root:At the start of the epoch: mem (CPU python)=9128.5625MB; mem (CPU total)=8805.95703125MB
INFO:root:[   52] Training loss: 0.44358539, Validation loss: 0.42386966, Gradient norm: 2.82017389
INFO:root:At the start of the epoch: mem (CPU python)=9149.7265625MB; mem (CPU total)=8827.1328125MB
INFO:root:[   53] Training loss: 0.44508229, Validation loss: 0.43474326, Gradient norm: 3.16988291
INFO:root:At the start of the epoch: mem (CPU python)=9170.89453125MB; mem (CPU total)=8848.3046875MB
INFO:root:[   54] Training loss: 0.44161405, Validation loss: 0.40963371, Gradient norm: 3.27776784
INFO:root:At the start of the epoch: mem (CPU python)=9192.05859375MB; mem (CPU total)=8869.5MB
INFO:root:[   55] Training loss: 0.44052403, Validation loss: 0.44375505, Gradient norm: 3.25231027
INFO:root:At the start of the epoch: mem (CPU python)=9213.22265625MB; mem (CPU total)=8890.91796875MB
INFO:root:[   56] Training loss: 0.44705868, Validation loss: 0.41135008, Gradient norm: 3.36546016
INFO:root:At the start of the epoch: mem (CPU python)=9234.38671875MB; mem (CPU total)=8911.83984375MB
INFO:root:[   57] Training loss: 0.44204924, Validation loss: 0.41207587, Gradient norm: 3.14339204
INFO:root:At the start of the epoch: mem (CPU python)=9255.55078125MB; mem (CPU total)=8933.00390625MB
INFO:root:[   58] Training loss: 0.43759744, Validation loss: 0.41356060, Gradient norm: 2.90771156
INFO:root:At the start of the epoch: mem (CPU python)=9276.71875MB; mem (CPU total)=8954.1640625MB
INFO:root:[   59] Training loss: 0.44325707, Validation loss: 0.42875126, Gradient norm: 3.55471681
INFO:root:At the start of the epoch: mem (CPU python)=9297.87890625MB; mem (CPU total)=8975.3359375MB
INFO:root:[   60] Training loss: 0.43547080, Validation loss: 0.42213018, Gradient norm: 3.34824934
INFO:root:At the start of the epoch: mem (CPU python)=9319.04296875MB; mem (CPU total)=8996.50390625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.44109350, Validation loss: 0.41619752, Gradient norm: 3.79157954
INFO:root:At the start of the epoch: mem (CPU python)=9340.20703125MB; mem (CPU total)=9017.9140625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 0.41354642, Validation loss: 0.38570318, Gradient norm: 2.52778457
INFO:root:At the start of the epoch: mem (CPU python)=9361.37109375MB; mem (CPU total)=9039.0859375MB
INFO:root:[   63] Training loss: 0.40479633, Validation loss: 0.38411555, Gradient norm: 1.75414193
INFO:root:At the start of the epoch: mem (CPU python)=9382.5390625MB; mem (CPU total)=9060.2890625MB
INFO:root:[   64] Training loss: 0.40330587, Validation loss: 0.38218315, Gradient norm: 2.26419956
INFO:root:At the start of the epoch: mem (CPU python)=9403.69921875MB; mem (CPU total)=9081.46484375MB
INFO:root:[   65] Training loss: 0.40333501, Validation loss: 0.37960708, Gradient norm: 2.48941875
INFO:root:At the start of the epoch: mem (CPU python)=9424.86328125MB; mem (CPU total)=9102.90234375MB
INFO:root:[   66] Training loss: 0.40340947, Validation loss: 0.38316325, Gradient norm: 2.87551380
INFO:root:At the start of the epoch: mem (CPU python)=9446.02734375MB; mem (CPU total)=9124.078125MB
INFO:root:[   67] Training loss: 0.40732381, Validation loss: 0.38796035, Gradient norm: 4.35912766
INFO:root:At the start of the epoch: mem (CPU python)=9467.19140625MB; mem (CPU total)=9145.25390625MB
INFO:root:[   68] Training loss: 0.40488286, Validation loss: 0.38125045, Gradient norm: 3.40278855
INFO:root:At the start of the epoch: mem (CPU python)=9488.35546875MB; mem (CPU total)=9166.42578125MB
INFO:root:[   69] Training loss: 0.40357569, Validation loss: 0.38359573, Gradient norm: 3.73779398
INFO:root:At the start of the epoch: mem (CPU python)=9509.5234375MB; mem (CPU total)=9187.9921875MB
INFO:root:[   70] Training loss: 0.40349016, Validation loss: 0.38191494, Gradient norm: 3.88559886
INFO:root:At the start of the epoch: mem (CPU python)=9530.6875MB; mem (CPU total)=9208.05078125MB
INFO:root:[   71] Training loss: 0.40330072, Validation loss: 0.38203746, Gradient norm: 4.33929749
INFO:root:At the start of the epoch: mem (CPU python)=9551.8515625MB; mem (CPU total)=9229.2109375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   72] Training loss: 0.40237057, Validation loss: 0.37965272, Gradient norm: 4.37317114
INFO:root:At the start of the epoch: mem (CPU python)=9573.01171875MB; mem (CPU total)=9250.36328125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   73] Training loss: 0.39911197, Validation loss: 0.37745113, Gradient norm: 2.86618153
INFO:root:At the start of the epoch: mem (CPU python)=9594.17578125MB; mem (CPU total)=9271.7578125MB
INFO:root:[   74] Training loss: 0.39721106, Validation loss: 0.37445233, Gradient norm: 2.55134276
INFO:root:At the start of the epoch: mem (CPU python)=9615.34375MB; mem (CPU total)=9292.88671875MB
INFO:root:[   75] Training loss: 0.39649995, Validation loss: 0.37428709, Gradient norm: 2.75653345
INFO:root:At the start of the epoch: mem (CPU python)=9636.5078125MB; mem (CPU total)=9314.36328125MB
INFO:root:[   76] Training loss: 0.39699292, Validation loss: 0.37422409, Gradient norm: 2.68678781
INFO:root:At the start of the epoch: mem (CPU python)=9657.671875MB; mem (CPU total)=9335.5234375MB
INFO:root:[   77] Training loss: 0.39734298, Validation loss: 0.37376907, Gradient norm: 2.96927286
INFO:root:At the start of the epoch: mem (CPU python)=9678.8359375MB; mem (CPU total)=9356.046875MB
INFO:root:[   78] Training loss: 0.39622051, Validation loss: 0.37347840, Gradient norm: 3.12674959
INFO:root:At the start of the epoch: mem (CPU python)=9700.0MB; mem (CPU total)=9376.9609375MB
INFO:root:[   79] Training loss: 0.39637752, Validation loss: 0.37357028, Gradient norm: 3.16977743
INFO:root:At the start of the epoch: mem (CPU python)=9721.1640625MB; mem (CPU total)=9398.3828125MB
INFO:root:[   80] Training loss: 0.39566426, Validation loss: 0.37315642, Gradient norm: 2.69920217
INFO:root:At the start of the epoch: mem (CPU python)=9742.33203125MB; mem (CPU total)=9419.55078125MB
INFO:root:[   81] Training loss: 0.39603760, Validation loss: 0.37482148, Gradient norm: 2.93128159
INFO:root:At the start of the epoch: mem (CPU python)=9763.48828125MB; mem (CPU total)=9440.71484375MB
INFO:root:[   82] Training loss: 0.39739053, Validation loss: 0.37489318, Gradient norm: 5.05499273
INFO:root:At the start of the epoch: mem (CPU python)=9784.65234375MB; mem (CPU total)=9461.88671875MB
INFO:root:[   83] Training loss: 0.39733058, Validation loss: 0.37678085, Gradient norm: 4.93589470
INFO:root:At the start of the epoch: mem (CPU python)=9805.81640625MB; mem (CPU total)=9483.0625MB
INFO:root:[   84] Training loss: 0.39654836, Validation loss: 0.37272496, Gradient norm: 4.07477010
INFO:root:At the start of the epoch: mem (CPU python)=9826.984375MB; mem (CPU total)=9504.62890625MB
INFO:root:[   85] Training loss: 0.39649793, Validation loss: 0.37426219, Gradient norm: 3.99411968
INFO:root:At the start of the epoch: mem (CPU python)=9848.14453125MB; mem (CPU total)=9525.41015625MB
INFO:root:[   86] Training loss: 0.39620167, Validation loss: 0.37388174, Gradient norm: 4.30537588
INFO:root:At the start of the epoch: mem (CPU python)=9869.3125MB; mem (CPU total)=9546.5859375MB
INFO:root:[   87] Training loss: 0.39630551, Validation loss: 0.37345945, Gradient norm: 3.93710928
INFO:root:At the start of the epoch: mem (CPU python)=9890.4765625MB; mem (CPU total)=9567.7578125MB
INFO:root:[   88] Training loss: 0.39696187, Validation loss: 0.37676875, Gradient norm: 4.89193131
INFO:root:At the start of the epoch: mem (CPU python)=9911.640625MB; mem (CPU total)=9588.90234375MB
INFO:root:[   89] Training loss: 0.39670729, Validation loss: 0.37815323, Gradient norm: 5.09505264
INFO:root:At the start of the epoch: mem (CPU python)=9932.8046875MB; mem (CPU total)=9610.3203125MB
INFO:root:[   90] Training loss: 0.39824281, Validation loss: 0.37549860, Gradient norm: 7.15978150
INFO:root:At the start of the epoch: mem (CPU python)=9953.96875MB; mem (CPU total)=9631.49609375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   91] Training loss: 0.39606198, Validation loss: 0.37341091, Gradient norm: 4.48845176
INFO:root:At the start of the epoch: mem (CPU python)=9975.1328125MB; mem (CPU total)=9652.60546875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   92] Training loss: 0.39434478, Validation loss: 0.37276116, Gradient norm: 3.46354492
INFO:root:At the start of the epoch: mem (CPU python)=9996.296875MB; mem (CPU total)=9673.73828125MB
INFO:root:[   93] Training loss: 0.39461644, Validation loss: 0.37204851, Gradient norm: 2.61713205
INFO:root:At the start of the epoch: mem (CPU python)=10017.4609375MB; mem (CPU total)=9695.14453125MB
INFO:root:[   94] Training loss: 0.39409480, Validation loss: 0.37229881, Gradient norm: 2.53219779
INFO:root:At the start of the epoch: mem (CPU python)=10038.625MB; mem (CPU total)=9716.30859375MB
INFO:root:[   95] Training loss: 0.39428240, Validation loss: 0.37145080, Gradient norm: 2.51362934
INFO:root:At the start of the epoch: mem (CPU python)=10059.7890625MB; mem (CPU total)=9737.75MB
INFO:root:[   96] Training loss: 0.39455569, Validation loss: 0.37159259, Gradient norm: 2.80056578
INFO:root:At the start of the epoch: mem (CPU python)=10080.953125MB; mem (CPU total)=9758.8828125MB
INFO:root:[   97] Training loss: 0.39430780, Validation loss: 0.37138660, Gradient norm: 2.75534162
INFO:root:At the start of the epoch: mem (CPU python)=10102.12109375MB; mem (CPU total)=9780.046875MB
INFO:root:[   98] Training loss: 0.39459521, Validation loss: 0.37186191, Gradient norm: 2.79010500
INFO:root:At the start of the epoch: mem (CPU python)=10123.28125MB; mem (CPU total)=9801.2109375MB
INFO:root:[   99] Training loss: 0.39397710, Validation loss: 0.37145040, Gradient norm: 2.92195134
INFO:root:At the start of the epoch: mem (CPU python)=10144.4453125MB; mem (CPU total)=9822.12890625MB
INFO:root:[  100] Training loss: 0.39390758, Validation loss: 0.37122379, Gradient norm: 3.09513728
INFO:root:At the start of the epoch: mem (CPU python)=10165.60546875MB; mem (CPU total)=9843.54296875MB
INFO:root:[  101] Training loss: 0.39419741, Validation loss: 0.37177454, Gradient norm: 3.02893964
INFO:root:At the start of the epoch: mem (CPU python)=10186.7734375MB; mem (CPU total)=9864.453125MB
INFO:root:[  102] Training loss: 0.39454927, Validation loss: 0.37242499, Gradient norm: 3.09449304
INFO:root:At the start of the epoch: mem (CPU python)=10207.9375MB; mem (CPU total)=9885.6484375MB
INFO:root:[  103] Training loss: 0.39406845, Validation loss: 0.37202112, Gradient norm: 2.90560888
INFO:root:At the start of the epoch: mem (CPU python)=10229.10546875MB; mem (CPU total)=9906.8125MB
INFO:root:[  104] Training loss: 0.39399212, Validation loss: 0.37146465, Gradient norm: 3.08957378
INFO:root:At the start of the epoch: mem (CPU python)=10250.26953125MB; mem (CPU total)=9927.9765625MB
INFO:root:[  105] Training loss: 0.39474159, Validation loss: 0.37124304, Gradient norm: 3.52675249
INFO:root:At the start of the epoch: mem (CPU python)=10271.43359375MB; mem (CPU total)=9949.38671875MB
INFO:root:[  106] Training loss: 0.39447300, Validation loss: 0.37188595, Gradient norm: 3.53193949
INFO:root:At the start of the epoch: mem (CPU python)=10292.59765625MB; mem (CPU total)=9970.55078125MB
INFO:root:[  107] Training loss: 0.39454747, Validation loss: 0.37269299, Gradient norm: 3.29618907
INFO:root:At the start of the epoch: mem (CPU python)=10313.76171875MB; mem (CPU total)=9991.59765625MB
INFO:root:[  108] Training loss: 0.39466111, Validation loss: 0.37183087, Gradient norm: 3.72905115
INFO:root:At the start of the epoch: mem (CPU python)=10334.9296875MB; mem (CPU total)=10012.7421875MB
INFO:root:[  109] Training loss: 0.39423929, Validation loss: 0.37112620, Gradient norm: 3.84870804
INFO:root:At the start of the epoch: mem (CPU python)=10356.09375MB; mem (CPU total)=10033.90625MB
INFO:root:[  110] Training loss: 0.39405567, Validation loss: 0.37242126, Gradient norm: 3.76917465
INFO:root:At the start of the epoch: mem (CPU python)=10377.25390625MB; mem (CPU total)=10055.31640625MB
INFO:root:[  111] Training loss: 0.39462073, Validation loss: 0.37174858, Gradient norm: 3.84231689
INFO:root:At the start of the epoch: mem (CPU python)=10398.41796875MB; mem (CPU total)=10076.48046875MB
INFO:root:[  112] Training loss: 0.39451706, Validation loss: 0.37252109, Gradient norm: 3.92255306
INFO:root:At the start of the epoch: mem (CPU python)=10419.58203125MB; mem (CPU total)=10097.3359375MB
INFO:root:[  113] Training loss: 0.39424635, Validation loss: 0.37131616, Gradient norm: 4.33026937
INFO:root:At the start of the epoch: mem (CPU python)=10440.74609375MB; mem (CPU total)=10118.48828125MB
INFO:root:[  114] Training loss: 0.39439189, Validation loss: 0.37140635, Gradient norm: 4.25467866
INFO:root:At the start of the epoch: mem (CPU python)=10461.91015625MB; mem (CPU total)=10139.63671875MB
INFO:root:[  115] Training loss: 0.39400359, Validation loss: 0.37121674, Gradient norm: 4.26684499
INFO:root:At the start of the epoch: mem (CPU python)=10483.07421875MB; mem (CPU total)=10160.78515625MB
INFO:root:[  116] Training loss: 0.39406863, Validation loss: 0.37140229, Gradient norm: 3.92007541
INFO:root:At the start of the epoch: mem (CPU python)=10504.23828125MB; mem (CPU total)=10182.19140625MB
INFO:root:[  117] Training loss: 0.39379698, Validation loss: 0.37156203, Gradient norm: 4.39897941
INFO:root:At the start of the epoch: mem (CPU python)=10525.40234375MB; mem (CPU total)=10203.34375MB
INFO:root:[  118] Training loss: 0.39491266, Validation loss: 0.37137768, Gradient norm: 4.26340099
INFO:root:At the start of the epoch: mem (CPU python)=10546.5703125MB; mem (CPU total)=10224.49609375MB
INFO:root:EP 118: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=10567.73046875MB; mem (CPU total)=10245.41015625MB
INFO:root:Training the model took 3045.869s.
INFO:root:Emptying the cuda cache took 0.035s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.45372
INFO:root:EnergyScoreValidation: 0.26634
INFO:root:CRPSValidation: 0.11731
INFO:root:Gaussian NLLValidation: 9.526
INFO:root:CoverageValidation: 0.57609
INFO:root:IntervalWidthValidation: 0.41742
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.47371
INFO:root:EnergyScoreTest: 0.28288
INFO:root:CRPSTest: 0.12421
INFO:root:Gaussian NLLTest: 8.86374
INFO:root:CoverageTest: 0.5535
INFO:root:IntervalWidthTest: 0.41446
INFO:root:After validation: mem (CPU python)=10691.15234375MB; mem (CPU total)=10368.60546875MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=10691.15234375MB; mem (CPU total)=10250.58203125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 367001600
INFO:root:After setting up the model: mem (CPU python)=10691.15234375MB; mem (CPU total)=10263.8125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=10691.15234375MB; mem (CPU total)=10264.05859375MB
INFO:root:[    1] Training loss: 0.84074616, Validation loss: 0.73742301, Gradient norm: 0.48069239
INFO:root:At the start of the epoch: mem (CPU python)=10691.15234375MB; mem (CPU total)=10297.41796875MB
INFO:root:[    2] Training loss: 0.74151034, Validation loss: 0.73201175, Gradient norm: 0.39597610
INFO:root:At the start of the epoch: mem (CPU python)=10691.15234375MB; mem (CPU total)=10318.09375MB
INFO:root:[    3] Training loss: 0.73931278, Validation loss: 0.73269488, Gradient norm: 0.49077016
INFO:root:At the start of the epoch: mem (CPU python)=10691.15234375MB; mem (CPU total)=10339.26171875MB
INFO:root:[    4] Training loss: 0.72046235, Validation loss: 0.70781208, Gradient norm: 0.54003942
INFO:root:At the start of the epoch: mem (CPU python)=10691.15234375MB; mem (CPU total)=10360.43359375MB
INFO:root:[    5] Training loss: 0.68632441, Validation loss: 0.65415972, Gradient norm: 0.83873132
INFO:root:At the start of the epoch: mem (CPU python)=10701.92578125MB; mem (CPU total)=10381.62890625MB
INFO:root:[    6] Training loss: 0.63252488, Validation loss: 0.58783209, Gradient norm: 1.18403594
INFO:root:At the start of the epoch: mem (CPU python)=10723.08984375MB; mem (CPU total)=10402.80078125MB
INFO:root:[    7] Training loss: 0.59489666, Validation loss: 0.56840416, Gradient norm: 1.33496077
INFO:root:At the start of the epoch: mem (CPU python)=10744.2578125MB; mem (CPU total)=10423.96875MB
INFO:root:[    8] Training loss: 0.58665431, Validation loss: 0.55095091, Gradient norm: 1.94981021
INFO:root:At the start of the epoch: mem (CPU python)=10765.42578125MB; mem (CPU total)=10445.1328125MB
INFO:root:[    9] Training loss: 0.57319450, Validation loss: 0.54048330, Gradient norm: 1.57991173
INFO:root:At the start of the epoch: mem (CPU python)=10786.58984375MB; mem (CPU total)=10466.546875MB
INFO:root:[   10] Training loss: 0.55907366, Validation loss: 0.52055852, Gradient norm: 1.90865795
INFO:root:At the start of the epoch: mem (CPU python)=10807.75390625MB; mem (CPU total)=10487.85546875MB
INFO:root:[   11] Training loss: 0.55596529, Validation loss: 0.51826512, Gradient norm: 2.20706195
INFO:root:At the start of the epoch: mem (CPU python)=10828.921875MB; mem (CPU total)=10508.48828125MB
INFO:root:[   12] Training loss: 0.54166716, Validation loss: 0.50712612, Gradient norm: 2.09849273
INFO:root:At the start of the epoch: mem (CPU python)=10850.08203125MB; mem (CPU total)=10529.6796875MB
INFO:root:[   13] Training loss: 0.53255698, Validation loss: 0.49970244, Gradient norm: 2.28559804
INFO:root:At the start of the epoch: mem (CPU python)=10871.25MB; mem (CPU total)=10551.0546875MB
INFO:root:[   14] Training loss: 0.52729289, Validation loss: 0.49450529, Gradient norm: 2.36974352
INFO:root:At the start of the epoch: mem (CPU python)=10892.4140625MB; mem (CPU total)=10571.96875MB
INFO:root:[   15] Training loss: 0.51519309, Validation loss: 0.48091615, Gradient norm: 2.52929046
INFO:root:At the start of the epoch: mem (CPU python)=10913.578125MB; mem (CPU total)=10593.1640625MB
INFO:root:[   16] Training loss: 0.51243165, Validation loss: 0.47255209, Gradient norm: 2.73332518
INFO:root:At the start of the epoch: mem (CPU python)=10934.7421875MB; mem (CPU total)=10614.48828125MB
INFO:root:[   17] Training loss: 0.50604935, Validation loss: 0.48937049, Gradient norm: 2.41389482
INFO:root:At the start of the epoch: mem (CPU python)=10955.90234375MB; mem (CPU total)=10635.6640625MB
INFO:root:[   18] Training loss: 0.50044287, Validation loss: 0.48197678, Gradient norm: 2.89369358
INFO:root:At the start of the epoch: mem (CPU python)=10977.06640625MB; mem (CPU total)=10656.828125MB
INFO:root:[   19] Training loss: 0.51065832, Validation loss: 0.46138703, Gradient norm: 2.89111443
INFO:root:At the start of the epoch: mem (CPU python)=10998.234375MB; mem (CPU total)=10677.98828125MB
INFO:root:[   20] Training loss: 0.49833997, Validation loss: 0.46505513, Gradient norm: 2.67570682
INFO:root:At the start of the epoch: mem (CPU python)=11019.3984375MB; mem (CPU total)=10699.15234375MB
INFO:root:[   21] Training loss: 0.49435765, Validation loss: 0.48170489, Gradient norm: 2.80235486
INFO:root:At the start of the epoch: mem (CPU python)=11040.5625MB; mem (CPU total)=10720.32421875MB
INFO:root:[   22] Training loss: 0.49293507, Validation loss: 0.44757308, Gradient norm: 2.84230961
INFO:root:At the start of the epoch: mem (CPU python)=11061.7265625MB; mem (CPU total)=10741.7109375MB
INFO:root:[   23] Training loss: 0.49524933, Validation loss: 0.46136859, Gradient norm: 3.05686809
INFO:root:At the start of the epoch: mem (CPU python)=11082.890625MB; mem (CPU total)=10762.85546875MB
INFO:root:[   24] Training loss: 0.49201863, Validation loss: 0.47247427, Gradient norm: 2.84043623
INFO:root:At the start of the epoch: mem (CPU python)=11104.0546875MB; mem (CPU total)=10784.03125MB
INFO:root:[   25] Training loss: 0.49376545, Validation loss: 0.46470708, Gradient norm: 2.94651878
INFO:root:At the start of the epoch: mem (CPU python)=11125.21875MB; mem (CPU total)=10805.203125MB
INFO:root:[   26] Training loss: 0.48586064, Validation loss: 0.45711759, Gradient norm: 2.89426088
INFO:root:At the start of the epoch: mem (CPU python)=11146.3828125MB; mem (CPU total)=10826.34375MB
INFO:root:[   27] Training loss: 0.49215465, Validation loss: 0.47108773, Gradient norm: 2.70286470
INFO:root:At the start of the epoch: mem (CPU python)=11167.890625MB; mem (CPU total)=10848.25390625MB
INFO:root:[   28] Training loss: 0.48336535, Validation loss: 0.45383529, Gradient norm: 3.32480407
INFO:root:At the start of the epoch: mem (CPU python)=11189.5546875MB; mem (CPU total)=10870.015625MB
INFO:root:[   29] Training loss: 0.48596263, Validation loss: 0.44300569, Gradient norm: 2.96041899
INFO:root:At the start of the epoch: mem (CPU python)=11211.47265625MB; mem (CPU total)=10891.94921875MB
INFO:root:[   30] Training loss: 0.48148246, Validation loss: 0.48065081, Gradient norm: 3.07803495
INFO:root:At the start of the epoch: mem (CPU python)=11233.38671875MB; mem (CPU total)=10913.86328125MB
INFO:root:[   31] Training loss: 0.48655759, Validation loss: 0.45665826, Gradient norm: 3.14451874
INFO:root:At the start of the epoch: mem (CPU python)=11255.046875MB; mem (CPU total)=10935.52734375MB
INFO:root:[   32] Training loss: 0.48080619, Validation loss: 0.47906421, Gradient norm: 3.26718405
INFO:root:At the start of the epoch: mem (CPU python)=11276.9609375MB; mem (CPU total)=10957.44921875MB
INFO:root:[   33] Training loss: 0.48494870, Validation loss: 0.46013767, Gradient norm: 3.16723911
INFO:root:At the start of the epoch: mem (CPU python)=11298.53125MB; mem (CPU total)=10978.765625MB
INFO:root:[   34] Training loss: 0.47715983, Validation loss: 0.44686531, Gradient norm: 2.76996125
INFO:root:At the start of the epoch: mem (CPU python)=11319.6875MB; mem (CPU total)=10999.9296875MB
INFO:root:[   35] Training loss: 0.47982417, Validation loss: 0.44561241, Gradient norm: 3.44669562
INFO:root:At the start of the epoch: mem (CPU python)=11340.859375MB; mem (CPU total)=11021.31640625MB
INFO:root:[   36] Training loss: 0.48017239, Validation loss: 0.46285452, Gradient norm: 3.28862694
INFO:root:At the start of the epoch: mem (CPU python)=11362.0234375MB; mem (CPU total)=11042.4921875MB
INFO:root:[   37] Training loss: 0.47702638, Validation loss: 0.44596424, Gradient norm: 2.93396561
INFO:root:At the start of the epoch: mem (CPU python)=11383.18359375MB; mem (CPU total)=11063.6640625MB
INFO:root:[   38] Training loss: 0.47731192, Validation loss: 0.44457146, Gradient norm: 3.71602366
INFO:root:At the start of the epoch: mem (CPU python)=11404.34765625MB; mem (CPU total)=11084.83984375MB
INFO:root:[   39] Training loss: 0.47723774, Validation loss: 0.44861292, Gradient norm: 3.49188900
INFO:root:At the start of the epoch: mem (CPU python)=11425.51171875MB; mem (CPU total)=11106.015625MB
INFO:root:[   40] Training loss: 0.47927062, Validation loss: 0.46018463, Gradient norm: 3.21414521
INFO:root:At the start of the epoch: mem (CPU python)=11446.67578125MB; mem (CPU total)=11127.43359375MB
INFO:root:[   41] Training loss: 0.47583273, Validation loss: 0.45446759, Gradient norm: 3.43046782
INFO:root:At the start of the epoch: mem (CPU python)=11467.84375MB; mem (CPU total)=11148.546875MB
INFO:root:[   42] Training loss: 0.47982166, Validation loss: 0.45290050, Gradient norm: 3.40791316
INFO:root:At the start of the epoch: mem (CPU python)=11489.0078125MB; mem (CPU total)=11169.72265625MB
INFO:root:[   43] Training loss: 0.46910075, Validation loss: 0.43782207, Gradient norm: 3.93191516
INFO:root:At the start of the epoch: mem (CPU python)=11510.171875MB; mem (CPU total)=11191.140625MB
INFO:root:[   44] Training loss: 0.47236201, Validation loss: 0.43241439, Gradient norm: 3.48653280
INFO:root:At the start of the epoch: mem (CPU python)=11531.3359375MB; mem (CPU total)=11212.34765625MB
INFO:root:[   45] Training loss: 0.47629110, Validation loss: 0.44300306, Gradient norm: 4.18540763
INFO:root:At the start of the epoch: mem (CPU python)=11552.5MB; mem (CPU total)=11233.5234375MB
INFO:root:[   46] Training loss: 0.47332401, Validation loss: 0.44411006, Gradient norm: 3.60912710
INFO:root:At the start of the epoch: mem (CPU python)=11573.66796875MB; mem (CPU total)=11254.72265625MB
INFO:root:[   47] Training loss: 0.47158440, Validation loss: 0.45432105, Gradient norm: 3.83049782
INFO:root:At the start of the epoch: mem (CPU python)=11594.83203125MB; mem (CPU total)=11275.89453125MB
INFO:root:[   48] Training loss: 0.46757174, Validation loss: 0.43627526, Gradient norm: 3.78696595
INFO:root:At the start of the epoch: mem (CPU python)=11615.99609375MB; mem (CPU total)=11297.30859375MB
INFO:root:[   49] Training loss: 0.47014146, Validation loss: 0.43670414, Gradient norm: 3.48482944
INFO:root:At the start of the epoch: mem (CPU python)=11637.16015625MB; mem (CPU total)=11318.625MB
INFO:root:[   50] Training loss: 0.46779428, Validation loss: 0.43622351, Gradient norm: 4.01986235
INFO:root:At the start of the epoch: mem (CPU python)=11658.32421875MB; mem (CPU total)=11339.40234375MB
INFO:root:[   51] Training loss: 0.46624732, Validation loss: 0.43499379, Gradient norm: 3.59468882
INFO:root:At the start of the epoch: mem (CPU python)=11679.484375MB; mem (CPU total)=11360.33203125MB
INFO:root:[   52] Training loss: 0.46586160, Validation loss: 0.45849848, Gradient norm: 4.05924193
INFO:root:At the start of the epoch: mem (CPU python)=11701.1484375MB; mem (CPU total)=11382.0MB
INFO:root:[   53] Training loss: 0.46970357, Validation loss: 0.43305267, Gradient norm: 3.78604791
INFO:root:At the start of the epoch: mem (CPU python)=11722.4375MB; mem (CPU total)=11403.41796875MB
INFO:root:[   54] Training loss: 0.46323983, Validation loss: 0.43488876, Gradient norm: 3.45484904
INFO:root:At the start of the epoch: mem (CPU python)=11743.6015625MB; mem (CPU total)=11424.80859375MB
INFO:root:[   55] Training loss: 0.46785945, Validation loss: 0.43242223, Gradient norm: 4.06836315
INFO:root:At the start of the epoch: mem (CPU python)=11764.765625MB; mem (CPU total)=11445.94140625MB
INFO:root:[   56] Training loss: 0.47196456, Validation loss: 0.43969072, Gradient norm: 3.56461604
INFO:root:At the start of the epoch: mem (CPU python)=11785.93359375MB; mem (CPU total)=11467.11328125MB
INFO:root:[   57] Training loss: 0.46183864, Validation loss: 0.47151862, Gradient norm: 3.94547796
INFO:root:At the start of the epoch: mem (CPU python)=11807.31640625MB; mem (CPU total)=11488.53515625MB
INFO:root:[   58] Training loss: 0.47085555, Validation loss: 0.44636291, Gradient norm: 3.96397488
INFO:root:At the start of the epoch: mem (CPU python)=11829.07421875MB; mem (CPU total)=11510.29296875MB
INFO:root:[   59] Training loss: 0.46347700, Validation loss: 0.42969294, Gradient norm: 3.56105399
INFO:root:At the start of the epoch: mem (CPU python)=11850.234375MB; mem (CPU total)=11531.453125MB
INFO:root:[   60] Training loss: 0.46096191, Validation loss: 0.42503101, Gradient norm: 3.29559090
INFO:root:At the start of the epoch: mem (CPU python)=11871.3984375MB; mem (CPU total)=11552.9296875MB
INFO:root:[   61] Training loss: 0.46151452, Validation loss: 0.46225602, Gradient norm: 4.24935399
INFO:root:At the start of the epoch: mem (CPU python)=11892.5625MB; mem (CPU total)=11574.09375MB
INFO:root:[   62] Training loss: 0.46018922, Validation loss: 0.43005589, Gradient norm: 3.93993429
INFO:root:At the start of the epoch: mem (CPU python)=11913.73046875MB; mem (CPU total)=11595.50390625MB
INFO:root:[   63] Training loss: 0.46163088, Validation loss: 0.42549482, Gradient norm: 3.86835311
INFO:root:At the start of the epoch: mem (CPU python)=11934.89453125MB; mem (CPU total)=11616.66796875MB
INFO:root:[   64] Training loss: 0.45776591, Validation loss: 0.42332473, Gradient norm: 3.90453467
INFO:root:At the start of the epoch: mem (CPU python)=11956.05859375MB; mem (CPU total)=11637.83203125MB
INFO:root:[   65] Training loss: 0.46450757, Validation loss: 0.43486883, Gradient norm: 3.62895740
INFO:root:At the start of the epoch: mem (CPU python)=11977.22265625MB; mem (CPU total)=11659.2734375MB
INFO:root:[   66] Training loss: 0.45484235, Validation loss: 0.41387824, Gradient norm: 3.71815089
INFO:root:At the start of the epoch: mem (CPU python)=11998.38671875MB; mem (CPU total)=11680.43359375MB
INFO:root:[   67] Training loss: 0.45658987, Validation loss: 0.44105647, Gradient norm: 4.02250338
INFO:root:At the start of the epoch: mem (CPU python)=12019.55078125MB; mem (CPU total)=11701.3515625MB
INFO:root:[   68] Training loss: 0.46392612, Validation loss: 0.42856170, Gradient norm: 4.18784901
INFO:root:At the start of the epoch: mem (CPU python)=12040.71484375MB; mem (CPU total)=11722.26171875MB
INFO:root:[   69] Training loss: 0.45622133, Validation loss: 0.41754389, Gradient norm: 3.58870552
INFO:root:At the start of the epoch: mem (CPU python)=12061.875MB; mem (CPU total)=11743.41796875MB
INFO:root:[   70] Training loss: 0.45660922, Validation loss: 0.42107470, Gradient norm: 4.07123843
INFO:root:At the start of the epoch: mem (CPU python)=12083.0390625MB; mem (CPU total)=11764.796875MB
INFO:root:[   71] Training loss: 0.45754883, Validation loss: 0.42867384, Gradient norm: 4.03544567
INFO:root:At the start of the epoch: mem (CPU python)=12104.203125MB; mem (CPU total)=11786.23046875MB
INFO:root:[   72] Training loss: 0.45556256, Validation loss: 0.42141068, Gradient norm: 4.10531107
INFO:root:At the start of the epoch: mem (CPU python)=12125.3671875MB; mem (CPU total)=11807.38671875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   73] Training loss: 0.45330975, Validation loss: 0.42221671, Gradient norm: 3.97495319
INFO:root:At the start of the epoch: mem (CPU python)=12146.53515625MB; mem (CPU total)=11828.55078125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   74] Training loss: 0.42789328, Validation loss: 0.39055470, Gradient norm: 3.06459875
INFO:root:At the start of the epoch: mem (CPU python)=12167.69921875MB; mem (CPU total)=11849.71484375MB
INFO:root:[   75] Training loss: 0.41726934, Validation loss: 0.38296933, Gradient norm: 2.06592535
INFO:root:At the start of the epoch: mem (CPU python)=12188.86328125MB; mem (CPU total)=11871.15625MB
INFO:root:[   76] Training loss: 0.41707450, Validation loss: 0.38587547, Gradient norm: 2.48681370
INFO:root:At the start of the epoch: mem (CPU python)=12210.02734375MB; mem (CPU total)=11892.3203125MB
INFO:root:[   77] Training loss: 0.41598330, Validation loss: 0.37936469, Gradient norm: 3.04202536
INFO:root:At the start of the epoch: mem (CPU python)=12231.1953125MB; mem (CPU total)=11913.20703125MB
INFO:root:[   78] Training loss: 0.41533907, Validation loss: 0.38647107, Gradient norm: 3.40406975
INFO:root:At the start of the epoch: mem (CPU python)=12252.35546875MB; mem (CPU total)=11934.37109375MB
INFO:root:[   79] Training loss: 0.41564535, Validation loss: 0.38394360, Gradient norm: 3.92673231
INFO:root:At the start of the epoch: mem (CPU python)=12273.5234375MB; mem (CPU total)=11955.53515625MB
INFO:root:[   80] Training loss: 0.41544103, Validation loss: 0.38272474, Gradient norm: 4.40165941
INFO:root:At the start of the epoch: mem (CPU python)=12294.6875MB; mem (CPU total)=11976.9453125MB
INFO:root:[   81] Training loss: 0.41563984, Validation loss: 0.38662385, Gradient norm: 4.71426720
INFO:root:At the start of the epoch: mem (CPU python)=12315.8515625MB; mem (CPU total)=11998.109375MB
INFO:root:[   82] Training loss: 0.41643538, Validation loss: 0.38335936, Gradient norm: 5.06127772
INFO:root:At the start of the epoch: mem (CPU python)=12337.015625MB; mem (CPU total)=12019.2734375MB
INFO:root:[   83] Training loss: 0.41539328, Validation loss: 0.38327214, Gradient norm: 5.50293185
INFO:root:At the start of the epoch: mem (CPU python)=12358.1796875MB; mem (CPU total)=12040.43359375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   84] Training loss: 0.41570884, Validation loss: 0.37888409, Gradient norm: 5.77715838
INFO:root:At the start of the epoch: mem (CPU python)=12379.34765625MB; mem (CPU total)=12061.5859375MB
INFO:root:[   85] Training loss: 0.41099769, Validation loss: 0.37632425, Gradient norm: 3.60300429
INFO:root:At the start of the epoch: mem (CPU python)=12400.51171875MB; mem (CPU total)=12082.80078125MB
INFO:root:[   86] Training loss: 0.41049813, Validation loss: 0.37536021, Gradient norm: 4.05399882
INFO:root:At the start of the epoch: mem (CPU python)=12421.671875MB; mem (CPU total)=12104.1953125MB
INFO:root:[   87] Training loss: 0.41089349, Validation loss: 0.37510849, Gradient norm: 4.47652944
INFO:root:At the start of the epoch: mem (CPU python)=12442.8359375MB; mem (CPU total)=12125.359375MB
INFO:root:[   88] Training loss: 0.41131451, Validation loss: 0.37680569, Gradient norm: 4.57597655
INFO:root:At the start of the epoch: mem (CPU python)=12463.99609375MB; mem (CPU total)=12146.5234375MB
INFO:root:[   89] Training loss: 0.41098136, Validation loss: 0.37680778, Gradient norm: 5.39836081
INFO:root:At the start of the epoch: mem (CPU python)=12485.16015625MB; mem (CPU total)=12167.6875MB
INFO:root:[   90] Training loss: 0.41126935, Validation loss: 0.37526881, Gradient norm: 5.50213470
INFO:root:At the start of the epoch: mem (CPU python)=12506.328125MB; mem (CPU total)=12189.09765625MB
INFO:root:[   91] Training loss: 0.41069706, Validation loss: 0.37633146, Gradient norm: 5.95583007
INFO:root:At the start of the epoch: mem (CPU python)=12527.4921875MB; mem (CPU total)=12210.26171875MB
INFO:root:[   92] Training loss: 0.41123601, Validation loss: 0.37442098, Gradient norm: 6.22389506
INFO:root:At the start of the epoch: mem (CPU python)=12548.65625MB; mem (CPU total)=12231.44140625MB
INFO:root:[   93] Training loss: 0.41175380, Validation loss: 0.38049970, Gradient norm: 6.72713091
INFO:root:At the start of the epoch: mem (CPU python)=12569.8203125MB; mem (CPU total)=12252.6015625MB
INFO:root:[   94] Training loss: 0.41153799, Validation loss: 0.37556281, Gradient norm: 6.85049627
INFO:root:At the start of the epoch: mem (CPU python)=12590.984375MB; mem (CPU total)=12273.765625MB
INFO:root:[   95] Training loss: 0.41199343, Validation loss: 0.37761708, Gradient norm: 7.29177133
INFO:root:At the start of the epoch: mem (CPU python)=12612.1484375MB; mem (CPU total)=12295.17578125MB
INFO:root:[   96] Training loss: 0.41222135, Validation loss: 0.37734152, Gradient norm: 7.49491368
INFO:root:At the start of the epoch: mem (CPU python)=12633.31640625MB; mem (CPU total)=12316.33984375MB
INFO:root:[   97] Training loss: 0.41209333, Validation loss: 0.37518452, Gradient norm: 7.79229839
INFO:root:At the start of the epoch: mem (CPU python)=12654.4765625MB; mem (CPU total)=12337.47265625MB
INFO:root:[   98] Training loss: 0.41234020, Validation loss: 0.38032511, Gradient norm: 8.19408020
INFO:root:At the start of the epoch: mem (CPU python)=12675.640625MB; mem (CPU total)=12357.8671875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   99] Training loss: 0.41250745, Validation loss: 0.37565060, Gradient norm: 8.62603766
INFO:root:At the start of the epoch: mem (CPU python)=12696.8046875MB; mem (CPU total)=12379.01953125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  100] Training loss: 0.40868656, Validation loss: 0.37430736, Gradient norm: 5.43250949
INFO:root:At the start of the epoch: mem (CPU python)=12717.97265625MB; mem (CPU total)=12400.65625MB
INFO:root:[  101] Training loss: 0.40775319, Validation loss: 0.37359583, Gradient norm: 4.28915936
INFO:root:At the start of the epoch: mem (CPU python)=12739.13671875MB; mem (CPU total)=12421.83984375MB
INFO:root:[  102] Training loss: 0.40748492, Validation loss: 0.37304267, Gradient norm: 4.26867871
INFO:root:At the start of the epoch: mem (CPU python)=12760.30078125MB; mem (CPU total)=12442.7421875MB
INFO:root:[  103] Training loss: 0.40792799, Validation loss: 0.37320748, Gradient norm: 4.59663526
INFO:root:At the start of the epoch: mem (CPU python)=12781.4609375MB; mem (CPU total)=12463.89453125MB
INFO:root:[  104] Training loss: 0.40756829, Validation loss: 0.37329888, Gradient norm: 5.00379676
INFO:root:At the start of the epoch: mem (CPU python)=12802.625MB; mem (CPU total)=12485.296875MB
INFO:root:[  105] Training loss: 0.40822368, Validation loss: 0.37512287, Gradient norm: 5.75772771
INFO:root:At the start of the epoch: mem (CPU python)=12823.7890625MB; mem (CPU total)=12506.22265625MB
INFO:root:[  106] Training loss: 0.40779694, Validation loss: 0.37425456, Gradient norm: 6.63439565
INFO:root:At the start of the epoch: mem (CPU python)=12844.94921875MB; mem (CPU total)=12528.34765625MB
INFO:root:[  107] Training loss: 0.40784502, Validation loss: 0.37357825, Gradient norm: 5.85894688
INFO:root:At the start of the epoch: mem (CPU python)=12866.1171875MB; mem (CPU total)=12549.75MB
INFO:root:[  108] Training loss: 0.40809653, Validation loss: 0.37228786, Gradient norm: 4.84021100
INFO:root:At the start of the epoch: mem (CPU python)=12887.28125MB; mem (CPU total)=12570.89453125MB
INFO:root:[  109] Training loss: 0.40773951, Validation loss: 0.37342043, Gradient norm: 5.61579155
INFO:root:At the start of the epoch: mem (CPU python)=12908.4453125MB; mem (CPU total)=12592.296875MB
INFO:root:[  110] Training loss: 0.40745138, Validation loss: 0.37435657, Gradient norm: 6.03522217
INFO:root:At the start of the epoch: mem (CPU python)=12929.609375MB; mem (CPU total)=12613.4609375MB
INFO:root:[  111] Training loss: 0.40790015, Validation loss: 0.37277486, Gradient norm: 6.73211626
INFO:root:At the start of the epoch: mem (CPU python)=12950.7734375MB; mem (CPU total)=12634.65625MB
INFO:root:[  112] Training loss: 0.40749338, Validation loss: 0.37322860, Gradient norm: 6.27505065
INFO:root:At the start of the epoch: mem (CPU python)=12971.9375MB; mem (CPU total)=12655.8203125MB
INFO:root:[  113] Training loss: 0.40816136, Validation loss: 0.37273674, Gradient norm: 7.45882919
INFO:root:At the start of the epoch: mem (CPU python)=12993.10546875MB; mem (CPU total)=13921.2734375MB
INFO:root:[  114] Training loss: 0.40797775, Validation loss: 0.37646684, Gradient norm: 6.49726877
INFO:root:At the start of the epoch: mem (CPU python)=13014.2734375MB; mem (CPU total)=12712.2578125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  115] Training loss: 0.40773859, Validation loss: 0.37273366, Gradient norm: 7.03466172
INFO:root:At the start of the epoch: mem (CPU python)=13035.4375MB; mem (CPU total)=12732.21875MB
INFO:root:[  116] Training loss: 0.40766621, Validation loss: 0.37145970, Gradient norm: 5.20127398
INFO:root:At the start of the epoch: mem (CPU python)=13056.59765625MB; mem (CPU total)=12751.6796875MB
INFO:root:[  117] Training loss: 0.40650113, Validation loss: 0.37200563, Gradient norm: 5.18237713
INFO:root:At the start of the epoch: mem (CPU python)=13077.76171875MB; mem (CPU total)=12771.59765625MB
INFO:root:[  118] Training loss: 0.40766450, Validation loss: 0.37145499, Gradient norm: 5.63631394
INFO:root:At the start of the epoch: mem (CPU python)=13098.9296875MB; mem (CPU total)=12792.875MB
INFO:root:[  119] Training loss: 0.40787312, Validation loss: 0.37311179, Gradient norm: 6.22847360
INFO:root:At the start of the epoch: mem (CPU python)=13120.08984375MB; mem (CPU total)=12816.3984375MB
INFO:root:[  120] Training loss: 0.40687815, Validation loss: 0.37223238, Gradient norm: 4.96693411
INFO:root:At the start of the epoch: mem (CPU python)=13141.25390625MB; mem (CPU total)=12836.48046875MB
INFO:root:[  121] Training loss: 0.40727141, Validation loss: 0.37241878, Gradient norm: 6.69630026
INFO:root:At the start of the epoch: mem (CPU python)=13162.41796875MB; mem (CPU total)=12860.01953125MB
INFO:root:[  122] Training loss: 0.40820060, Validation loss: 0.37348098, Gradient norm: 6.44073191
INFO:root:At the start of the epoch: mem (CPU python)=13183.58203125MB; mem (CPU total)=12879.62890625MB
INFO:root:[  123] Training loss: 0.40729744, Validation loss: 0.37186230, Gradient norm: 6.61976079
INFO:root:At the start of the epoch: mem (CPU python)=13204.74609375MB; mem (CPU total)=14751.76171875MB
INFO:root:[  124] Training loss: 0.40747252, Validation loss: 0.37245388, Gradient norm: 6.47738994
INFO:root:At the start of the epoch: mem (CPU python)=13225.91015625MB; mem (CPU total)=12927.828125MB
INFO:root:[  125] Training loss: 0.40737860, Validation loss: 0.37176910, Gradient norm: 6.36727751
INFO:root:At the start of the epoch: mem (CPU python)=13247.07421875MB; mem (CPU total)=12947.296875MB
INFO:root:[  126] Training loss: 0.40766034, Validation loss: 0.37182065, Gradient norm: 6.43291982
INFO:root:At the start of the epoch: mem (CPU python)=13268.23828125MB; mem (CPU total)=12968.12109375MB
INFO:root:[  127] Training loss: 0.40716361, Validation loss: 0.37193468, Gradient norm: 6.06137585
INFO:root:At the start of the epoch: mem (CPU python)=13289.40234375MB; mem (CPU total)=12992.94140625MB
INFO:root:EP 127: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=13310.421875MB; mem (CPU total)=13012.13671875MB
INFO:root:Training the model took 3582.229s.
INFO:root:Emptying the cuda cache took 0.037s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.62148
INFO:root:EnergyScoreValidation: 0.33172
INFO:root:CRPSValidation: 0.15134
INFO:root:Gaussian NLLValidation: 4.88516
INFO:root:CoverageValidation: 0.65248
INFO:root:IntervalWidthValidation: 0.76983
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.62526
INFO:root:EnergyScoreTest: 0.33309
INFO:root:CRPSTest: 0.15217
INFO:root:Gaussian NLLTest: 23.0269
INFO:root:CoverageTest: 0.64479
INFO:root:IntervalWidthTest: 0.77203
INFO:root:After validation: mem (CPU python)=13398.31640625MB; mem (CPU total)=13098.04296875MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=13398.31640625MB; mem (CPU total)=13004.44921875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 367001600
INFO:root:After setting up the model: mem (CPU python)=13398.31640625MB; mem (CPU total)=13027.6796875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=13398.31640625MB; mem (CPU total)=13027.40625MB
INFO:root:[    1] Training loss: 0.84672186, Validation loss: 0.73706373, Gradient norm: 0.42380271
INFO:root:At the start of the epoch: mem (CPU python)=13398.31640625MB; mem (CPU total)=13045.83984375MB
INFO:root:[    2] Training loss: 0.74547741, Validation loss: 0.73748162, Gradient norm: 0.43665544
INFO:root:At the start of the epoch: mem (CPU python)=13398.31640625MB; mem (CPU total)=13066.7734375MB
INFO:root:[    3] Training loss: 0.73876069, Validation loss: 0.72074134, Gradient norm: 0.52610141
INFO:root:At the start of the epoch: mem (CPU python)=13398.31640625MB; mem (CPU total)=13086.50390625MB
INFO:root:[    4] Training loss: 0.72428624, Validation loss: 0.70732441, Gradient norm: 0.75740335
INFO:root:At the start of the epoch: mem (CPU python)=13411.45703125MB; mem (CPU total)=13106.68359375MB
INFO:root:[    5] Training loss: 0.69221966, Validation loss: 0.67164614, Gradient norm: 0.96301877
INFO:root:At the start of the epoch: mem (CPU python)=13432.62109375MB; mem (CPU total)=13127.34765625MB
INFO:root:[    6] Training loss: 0.65961597, Validation loss: 0.62850475, Gradient norm: 1.39481851
INFO:root:At the start of the epoch: mem (CPU python)=13453.7890625MB; mem (CPU total)=13148.078125MB
INFO:root:[    7] Training loss: 0.62943557, Validation loss: 0.58558475, Gradient norm: 1.43705551
INFO:root:At the start of the epoch: mem (CPU python)=13474.953125MB; mem (CPU total)=13169.2421875MB
INFO:root:[    8] Training loss: 0.61545037, Validation loss: 0.57410335, Gradient norm: 1.68459488
INFO:root:At the start of the epoch: mem (CPU python)=13496.11328125MB; mem (CPU total)=13189.890625MB
INFO:root:[    9] Training loss: 0.60155112, Validation loss: 0.56379669, Gradient norm: 1.59747321
INFO:root:At the start of the epoch: mem (CPU python)=13517.27734375MB; mem (CPU total)=13210.12109375MB
INFO:root:[   10] Training loss: 0.59499336, Validation loss: 0.56005715, Gradient norm: 2.14652428
INFO:root:At the start of the epoch: mem (CPU python)=13538.44140625MB; mem (CPU total)=13231.46484375MB
INFO:root:[   11] Training loss: 0.58843904, Validation loss: 0.54357372, Gradient norm: 2.22198784
INFO:root:At the start of the epoch: mem (CPU python)=13559.60546875MB; mem (CPU total)=13251.890625MB
INFO:root:[   12] Training loss: 0.58192297, Validation loss: 0.54703340, Gradient norm: 2.57941102
INFO:root:At the start of the epoch: mem (CPU python)=13580.76953125MB; mem (CPU total)=13272.8125MB
INFO:root:[   13] Training loss: 0.56772168, Validation loss: 0.52173292, Gradient norm: 2.43680172
INFO:root:At the start of the epoch: mem (CPU python)=13601.9375MB; mem (CPU total)=13294.234375MB
INFO:root:[   14] Training loss: 0.56669420, Validation loss: 0.53150971, Gradient norm: 2.61413460
INFO:root:At the start of the epoch: mem (CPU python)=13623.1015625MB; mem (CPU total)=13315.1640625MB
INFO:root:[   15] Training loss: 0.56035187, Validation loss: 0.50673891, Gradient norm: 3.04304955
INFO:root:At the start of the epoch: mem (CPU python)=13644.265625MB; mem (CPU total)=13336.33984375MB
INFO:root:[   16] Training loss: 0.55819870, Validation loss: 0.50955887, Gradient norm: 3.41246771
INFO:root:At the start of the epoch: mem (CPU python)=13665.4296875MB; mem (CPU total)=13357.51171875MB
INFO:root:[   17] Training loss: 0.55587443, Validation loss: 0.51874812, Gradient norm: 3.46568814
INFO:root:At the start of the epoch: mem (CPU python)=13686.59765625MB; mem (CPU total)=13378.93359375MB
INFO:root:[   18] Training loss: 0.55099042, Validation loss: 0.50973471, Gradient norm: 3.84636951
INFO:root:At the start of the epoch: mem (CPU python)=13707.7578125MB; mem (CPU total)=13400.25390625MB
INFO:root:[   19] Training loss: 0.55472864, Validation loss: 0.52234110, Gradient norm: 3.85123347
INFO:root:At the start of the epoch: mem (CPU python)=13728.921875MB; mem (CPU total)=13537.34765625MB
INFO:root:[   20] Training loss: 0.55281106, Validation loss: 0.49673856, Gradient norm: 3.67163952
INFO:root:At the start of the epoch: mem (CPU python)=13750.0859375MB; mem (CPU total)=15313.8671875MB
INFO:root:[   21] Training loss: 0.55715829, Validation loss: 0.51709452, Gradient norm: 4.15768929
INFO:root:At the start of the epoch: mem (CPU python)=13771.25MB; mem (CPU total)=15334.96875MB
INFO:root:[   22] Training loss: 0.54821804, Validation loss: 0.49881462, Gradient norm: 3.98242881
INFO:root:At the start of the epoch: mem (CPU python)=13792.4140625MB; mem (CPU total)=15356.65234375MB
INFO:root:[   23] Training loss: 0.55290338, Validation loss: 0.52003385, Gradient norm: 4.26691524
INFO:root:At the start of the epoch: mem (CPU python)=13813.58203125MB; mem (CPU total)=15381.20703125MB
INFO:root:[   24] Training loss: 0.55316595, Validation loss: 0.51598589, Gradient norm: 4.30939523
INFO:root:At the start of the epoch: mem (CPU python)=13834.74609375MB; mem (CPU total)=15401.20703125MB
INFO:root:[   25] Training loss: 0.54647649, Validation loss: 0.49384235, Gradient norm: 4.75720260
INFO:root:At the start of the epoch: mem (CPU python)=13855.91015625MB; mem (CPU total)=15420.81640625MB
INFO:root:[   26] Training loss: 0.54524953, Validation loss: 0.51777815, Gradient norm: 4.73827705
INFO:root:At the start of the epoch: mem (CPU python)=13877.07421875MB; mem (CPU total)=15444.07421875MB
INFO:root:[   27] Training loss: 0.54976382, Validation loss: 0.52456069, Gradient norm: 5.12780088
INFO:root:At the start of the epoch: mem (CPU python)=13898.23828125MB; mem (CPU total)=15462.36328125MB
INFO:root:[   28] Training loss: 0.55302677, Validation loss: 0.50289834, Gradient norm: 4.76354690
INFO:root:At the start of the epoch: mem (CPU python)=13919.40234375MB; mem (CPU total)=15483.3359375MB
INFO:root:[   29] Training loss: 0.54716191, Validation loss: 0.51038893, Gradient norm: 5.25580965
INFO:root:At the start of the epoch: mem (CPU python)=13941.2578125MB; mem (CPU total)=15504.65234375MB
INFO:root:[   30] Training loss: 0.54178518, Validation loss: 0.52153908, Gradient norm: 4.68747115
INFO:root:At the start of the epoch: mem (CPU python)=13962.77734375MB; mem (CPU total)=13671.3828125MB
INFO:root:[   31] Training loss: 0.54340863, Validation loss: 0.52479631, Gradient norm: 5.20114010
INFO:root:At the start of the epoch: mem (CPU python)=13983.94140625MB; mem (CPU total)=13690.1171875MB
INFO:root:[   32] Training loss: 0.54445164, Validation loss: 0.50390271, Gradient norm: 4.93094868
INFO:root:At the start of the epoch: mem (CPU python)=14005.10546875MB; mem (CPU total)=13709.23046875MB
INFO:root:[   33] Training loss: 0.53918896, Validation loss: 0.51091406, Gradient norm: 4.83947033
INFO:root:At the start of the epoch: mem (CPU python)=14026.2734375MB; mem (CPU total)=15577.88671875MB
INFO:root:[   34] Training loss: 0.53447984, Validation loss: 0.48159716, Gradient norm: 4.74073090
INFO:root:At the start of the epoch: mem (CPU python)=14047.4375MB; mem (CPU total)=15613.62109375MB
INFO:root:[   35] Training loss: 0.53647980, Validation loss: 0.50303637, Gradient norm: 5.01359319
INFO:root:At the start of the epoch: mem (CPU python)=14068.6015625MB; mem (CPU total)=15634.046875MB
INFO:root:[   36] Training loss: 0.53993294, Validation loss: 0.48958671, Gradient norm: 5.23933865
INFO:root:At the start of the epoch: mem (CPU python)=14089.765625MB; mem (CPU total)=15653.2265625MB
INFO:root:[   37] Training loss: 0.53589000, Validation loss: 0.50393099, Gradient norm: 4.70764701
INFO:root:At the start of the epoch: mem (CPU python)=14110.92578125MB; mem (CPU total)=15673.09375MB
INFO:root:[   38] Training loss: 0.53508501, Validation loss: 0.51355223, Gradient norm: 4.96125305
INFO:root:At the start of the epoch: mem (CPU python)=14132.08984375MB; mem (CPU total)=15692.54296875MB
INFO:root:[   39] Training loss: 0.53208613, Validation loss: 0.49195930, Gradient norm: 5.36644940
INFO:root:At the start of the epoch: mem (CPU python)=14153.2578125MB; mem (CPU total)=15712.484375MB
INFO:root:[   40] Training loss: 0.53723432, Validation loss: 0.51318648, Gradient norm: 4.96836622
INFO:root:At the start of the epoch: mem (CPU python)=14174.421875MB; mem (CPU total)=15732.18359375MB
INFO:root:[   41] Training loss: 0.53495390, Validation loss: 0.50617347, Gradient norm: 5.32827498
INFO:root:At the start of the epoch: mem (CPU python)=14195.5859375MB; mem (CPU total)=13892.7421875MB
INFO:root:[   42] Training loss: 0.53211676, Validation loss: 0.49577569, Gradient norm: 5.07630736
INFO:root:At the start of the epoch: mem (CPU python)=14216.75MB; mem (CPU total)=13913.91796875MB
INFO:root:[   43] Training loss: 0.53073920, Validation loss: 0.48522128, Gradient norm: 4.82570029
INFO:root:At the start of the epoch: mem (CPU python)=14237.9140625MB; mem (CPU total)=13935.01171875MB
INFO:root:[   44] Training loss: 0.53224214, Validation loss: 0.48799163, Gradient norm: 5.52170498
INFO:root:At the start of the epoch: mem (CPU python)=14259.08203125MB; mem (CPU total)=13955.12890625MB
INFO:root:[   45] Training loss: 0.53060271, Validation loss: 0.50992373, Gradient norm: 5.45505474
INFO:root:At the start of the epoch: mem (CPU python)=14280.24609375MB; mem (CPU total)=13975.98828125MB
INFO:root:[   46] Training loss: 0.53882115, Validation loss: 0.50291959, Gradient norm: 5.41997088
INFO:root:At the start of the epoch: mem (CPU python)=14301.40625MB; mem (CPU total)=13996.6328125MB
INFO:root:[   47] Training loss: 0.53185800, Validation loss: 0.47600089, Gradient norm: 5.43388155
INFO:root:At the start of the epoch: mem (CPU python)=14322.5703125MB; mem (CPU total)=14017.1875MB
INFO:root:[   48] Training loss: 0.53216042, Validation loss: 0.48279194, Gradient norm: 5.15410958
INFO:root:At the start of the epoch: mem (CPU python)=14343.73046875MB; mem (CPU total)=14038.0546875MB
INFO:root:[   49] Training loss: 0.53025926, Validation loss: 0.49161365, Gradient norm: 5.31726438
INFO:root:At the start of the epoch: mem (CPU python)=14364.89453125MB; mem (CPU total)=14058.734375MB
INFO:root:[   50] Training loss: 0.52458378, Validation loss: 0.50351782, Gradient norm: 4.85801174
INFO:root:At the start of the epoch: mem (CPU python)=14386.0625MB; mem (CPU total)=14079.91015625MB
INFO:root:[   51] Training loss: 0.52806944, Validation loss: 0.50061776, Gradient norm: 5.56637438
INFO:root:At the start of the epoch: mem (CPU python)=14407.2265625MB; mem (CPU total)=14101.08203125MB
INFO:root:[   52] Training loss: 0.52867373, Validation loss: 0.50915010, Gradient norm: 5.15442608
INFO:root:At the start of the epoch: mem (CPU python)=14428.39453125MB; mem (CPU total)=14122.50390625MB
INFO:root:[   53] Training loss: 0.53009024, Validation loss: 0.48782014, Gradient norm: 6.15469693
INFO:root:At the start of the epoch: mem (CPU python)=14449.55859375MB; mem (CPU total)=14143.67578125MB
INFO:root:[   54] Training loss: 0.53140160, Validation loss: 0.47997671, Gradient norm: 5.53343500
INFO:root:At the start of the epoch: mem (CPU python)=14470.7265625MB; mem (CPU total)=14164.8359375MB
INFO:root:[   55] Training loss: 0.52659064, Validation loss: 0.48548631, Gradient norm: 5.52098912
INFO:root:At the start of the epoch: mem (CPU python)=14491.88671875MB; mem (CPU total)=14186.0078125MB
INFO:root:[   56] Training loss: 0.53395206, Validation loss: 0.47512918, Gradient norm: 5.94151422
INFO:root:At the start of the epoch: mem (CPU python)=14513.05078125MB; mem (CPU total)=16074.36328125MB
INFO:root:[   57] Training loss: 0.52392335, Validation loss: 0.46433870, Gradient norm: 5.26944607
INFO:root:At the start of the epoch: mem (CPU python)=14534.21484375MB; mem (CPU total)=14237.3125MB
INFO:root:[   58] Training loss: 0.52685682, Validation loss: 0.50944581, Gradient norm: 5.69692862
INFO:root:At the start of the epoch: mem (CPU python)=14555.37890625MB; mem (CPU total)=14436.12109375MB
INFO:root:[   59] Training loss: 0.53615548, Validation loss: 0.50981256, Gradient norm: 6.42236467
INFO:root:At the start of the epoch: mem (CPU python)=14576.54296875MB; mem (CPU total)=16163.18359375MB
INFO:root:[   60] Training loss: 0.52637846, Validation loss: 0.48432740, Gradient norm: 5.08201264
INFO:root:At the start of the epoch: mem (CPU python)=14597.70703125MB; mem (CPU total)=16182.3671875MB
INFO:root:[   61] Training loss: 0.52687792, Validation loss: 0.50537797, Gradient norm: 6.36366511
INFO:root:At the start of the epoch: mem (CPU python)=14618.875MB; mem (CPU total)=16202.8671875MB
INFO:root:[   62] Training loss: 0.52558190, Validation loss: 0.50017556, Gradient norm: 5.75200719
INFO:root:At the start of the epoch: mem (CPU python)=14640.0390625MB; mem (CPU total)=16223.6796875MB
INFO:root:[   63] Training loss: 0.53099868, Validation loss: 0.49701632, Gradient norm: 6.08823015
INFO:root:At the start of the epoch: mem (CPU python)=14661.203125MB; mem (CPU total)=16244.84375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   64] Training loss: 0.52966835, Validation loss: 0.48338888, Gradient norm: 5.75562479
INFO:root:At the start of the epoch: mem (CPU python)=14682.36328125MB; mem (CPU total)=16266.0078125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   65] Training loss: 0.50115216, Validation loss: 0.44702959, Gradient norm: 4.10310848
INFO:root:At the start of the epoch: mem (CPU python)=14703.52734375MB; mem (CPU total)=16286.43359375MB
INFO:root:[   66] Training loss: 0.48378951, Validation loss: 0.44259867, Gradient norm: 3.61414142
INFO:root:At the start of the epoch: mem (CPU python)=14724.69140625MB; mem (CPU total)=16306.61328125MB
INFO:root:[   67] Training loss: 0.48395874, Validation loss: 0.44185478, Gradient norm: 4.38795678
INFO:root:At the start of the epoch: mem (CPU python)=14745.85546875MB; mem (CPU total)=16327.48828125MB
INFO:root:[   68] Training loss: 0.48476923, Validation loss: 0.44392168, Gradient norm: 5.21528896
INFO:root:At the start of the epoch: mem (CPU python)=14767.01953125MB; mem (CPU total)=16348.65234375MB
INFO:root:[   69] Training loss: 0.48434684, Validation loss: 0.44065873, Gradient norm: 5.77221472
INFO:root:At the start of the epoch: mem (CPU python)=14788.18359375MB; mem (CPU total)=16369.2890625MB
INFO:root:[   70] Training loss: 0.48835346, Validation loss: 0.46034140, Gradient norm: 7.00560259
INFO:root:At the start of the epoch: mem (CPU python)=14809.34765625MB; mem (CPU total)=16389.76171875MB
INFO:root:[   71] Training loss: 0.49283046, Validation loss: 0.44402386, Gradient norm: 8.48340411
INFO:root:At the start of the epoch: mem (CPU python)=14830.51171875MB; mem (CPU total)=16410.9453125MB
INFO:root:[   72] Training loss: 0.48725137, Validation loss: 0.44254495, Gradient norm: 6.82678786
INFO:root:At the start of the epoch: mem (CPU python)=14851.6796875MB; mem (CPU total)=16432.09765625MB
INFO:root:[   73] Training loss: 0.48600178, Validation loss: 0.44329517, Gradient norm: 7.48002274
INFO:root:At the start of the epoch: mem (CPU python)=14872.84375MB; mem (CPU total)=16453.49609375MB
INFO:root:[   74] Training loss: 0.48614978, Validation loss: 0.44236888, Gradient norm: 7.76462086
INFO:root:At the start of the epoch: mem (CPU python)=14894.00390625MB; mem (CPU total)=16474.6484375MB
INFO:root:[   75] Training loss: 0.48668911, Validation loss: 0.44053468, Gradient norm: 8.42335472
INFO:root:At the start of the epoch: mem (CPU python)=14915.16796875MB; mem (CPU total)=16500.9921875MB
INFO:root:[   76] Training loss: 0.48644099, Validation loss: 0.44711373, Gradient norm: 8.41818434
INFO:root:At the start of the epoch: mem (CPU python)=14936.33203125MB; mem (CPU total)=16521.80859375MB
INFO:root:[   77] Training loss: 0.48827466, Validation loss: 0.44578451, Gradient norm: 8.74310661
INFO:root:At the start of the epoch: mem (CPU python)=14957.5MB; mem (CPU total)=16542.12109375MB
INFO:root:[   78] Training loss: 0.48752784, Validation loss: 0.44272130, Gradient norm: 9.77728121
INFO:root:At the start of the epoch: mem (CPU python)=14978.6640625MB; mem (CPU total)=16563.01953125MB
INFO:root:[   79] Training loss: 0.48875373, Validation loss: 0.46017230, Gradient norm: 9.45494478
INFO:root:At the start of the epoch: mem (CPU python)=14999.828125MB; mem (CPU total)=16583.75MB
INFO:root:[   80] Training loss: 0.48945482, Validation loss: 0.43761643, Gradient norm: 10.74218250
INFO:root:At the start of the epoch: mem (CPU python)=15020.9921875MB; mem (CPU total)=16604.57421875MB
INFO:root:[   81] Training loss: 0.49043758, Validation loss: 0.44686674, Gradient norm: 11.20033940
INFO:root:At the start of the epoch: mem (CPU python)=15042.15234375MB; mem (CPU total)=16625.734375MB
INFO:root:[   82] Training loss: 0.49204649, Validation loss: 0.44586894, Gradient norm: 10.99766690
INFO:root:At the start of the epoch: mem (CPU python)=15063.3203125MB; mem (CPU total)=16646.88671875MB
INFO:root:[   83] Training loss: 0.48994367, Validation loss: 0.44498314, Gradient norm: 11.84554460
INFO:root:At the start of the epoch: mem (CPU python)=15084.484375MB; mem (CPU total)=16668.046875MB
INFO:root:[   84] Training loss: 0.49289903, Validation loss: 0.44754700, Gradient norm: 12.39791751
INFO:root:At the start of the epoch: mem (CPU python)=15105.64453125MB; mem (CPU total)=16689.1484375MB
INFO:root:[   85] Training loss: 0.48857457, Validation loss: 0.45000253, Gradient norm: 11.89578973
INFO:root:At the start of the epoch: mem (CPU python)=15126.80859375MB; mem (CPU total)=16709.69921875MB
INFO:root:[   86] Training loss: 0.49165615, Validation loss: 0.44682480, Gradient norm: 12.84170973
INFO:root:At the start of the epoch: mem (CPU python)=15147.97265625MB; mem (CPU total)=16730.88671875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   87] Training loss: 0.49543032, Validation loss: 0.44711904, Gradient norm: 13.28265292
INFO:root:At the start of the epoch: mem (CPU python)=15169.140625MB; mem (CPU total)=16751.8046875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   88] Training loss: 0.48168991, Validation loss: 0.43532039, Gradient norm: 8.69424459
INFO:root:At the start of the epoch: mem (CPU python)=15190.3046875MB; mem (CPU total)=16773.2421875MB
INFO:root:[   89] Training loss: 0.47649946, Validation loss: 0.43022047, Gradient norm: 6.11138284
INFO:root:At the start of the epoch: mem (CPU python)=15211.46875MB; mem (CPU total)=16794.44921875MB
INFO:root:[   90] Training loss: 0.47663207, Validation loss: 0.43008023, Gradient norm: 7.65002894
INFO:root:At the start of the epoch: mem (CPU python)=15232.63671875MB; mem (CPU total)=14933.52734375MB
INFO:root:[   91] Training loss: 0.47575428, Validation loss: 0.42952956, Gradient norm: 7.91872425
INFO:root:At the start of the epoch: mem (CPU python)=15253.80078125MB; mem (CPU total)=14953.953125MB
INFO:root:[   92] Training loss: 0.47607611, Validation loss: 0.42963688, Gradient norm: 8.35660535
INFO:root:At the start of the epoch: mem (CPU python)=15274.96484375MB; mem (CPU total)=14974.12890625MB
INFO:root:[   93] Training loss: 0.47616057, Validation loss: 0.43173528, Gradient norm: 9.09350197
INFO:root:At the start of the epoch: mem (CPU python)=15296.125MB; mem (CPU total)=14995.28125MB
INFO:root:[   94] Training loss: 0.47987040, Validation loss: 0.43053337, Gradient norm: 14.56570442
INFO:root:At the start of the epoch: mem (CPU python)=15317.29296875MB; mem (CPU total)=15016.19921875MB
INFO:root:[   95] Training loss: 0.47726740, Validation loss: 0.42892922, Gradient norm: 10.43956769
INFO:root:At the start of the epoch: mem (CPU python)=15340.1171875MB; mem (CPU total)=15927.04296875MB
INFO:root:[   96] Training loss: 0.47686856, Validation loss: 0.43072324, Gradient norm: 10.39955376
INFO:root:At the start of the epoch: mem (CPU python)=15361.28125MB; mem (CPU total)=16930.9921875MB
INFO:root:[   97] Training loss: 0.48030444, Validation loss: 0.43315443, Gradient norm: 15.65403731
INFO:root:At the start of the epoch: mem (CPU python)=15382.6640625MB; mem (CPU total)=16950.55859375MB
INFO:root:[   98] Training loss: 0.47874214, Validation loss: 0.43030706, Gradient norm: 13.44180103
INFO:root:At the start of the epoch: mem (CPU python)=15403.828125MB; mem (CPU total)=16972.00390625MB
INFO:root:[   99] Training loss: 0.47691476, Validation loss: 0.43130131, Gradient norm: 11.28018943
INFO:root:At the start of the epoch: mem (CPU python)=15424.98828125MB; mem (CPU total)=16991.1875MB
INFO:root:[  100] Training loss: 0.47743554, Validation loss: 0.43092758, Gradient norm: 13.28341310
INFO:root:At the start of the epoch: mem (CPU python)=15446.15625MB; mem (CPU total)=17011.30859375MB
INFO:root:[  101] Training loss: 0.47689364, Validation loss: 0.43028115, Gradient norm: 12.79974280
INFO:root:At the start of the epoch: mem (CPU python)=15467.3203125MB; mem (CPU total)=17031.484375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  102] Training loss: 0.47707327, Validation loss: 0.42940285, Gradient norm: 13.64238053
INFO:root:At the start of the epoch: mem (CPU python)=15488.48046875MB; mem (CPU total)=17050.92578125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  103] Training loss: 0.47463300, Validation loss: 0.42770537, Gradient norm: 8.57321589
INFO:root:At the start of the epoch: mem (CPU python)=15509.6484375MB; mem (CPU total)=17074.73046875MB
INFO:root:[  104] Training loss: 0.47338829, Validation loss: 0.42609428, Gradient norm: 6.42187276
INFO:root:At the start of the epoch: mem (CPU python)=15532.1953125MB; mem (CPU total)=17103.87890625MB
INFO:root:[  105] Training loss: 0.47342301, Validation loss: 0.42612982, Gradient norm: 7.52419364
INFO:root:At the start of the epoch: mem (CPU python)=15553.36328125MB; mem (CPU total)=17123.98046875MB
INFO:root:[  106] Training loss: 0.47277104, Validation loss: 0.42649421, Gradient norm: 6.93566511
INFO:root:At the start of the epoch: mem (CPU python)=15574.63671875MB; mem (CPU total)=17145.63671875MB
INFO:root:[  107] Training loss: 0.47285918, Validation loss: 0.42665192, Gradient norm: 8.18740804
INFO:root:At the start of the epoch: mem (CPU python)=15595.80078125MB; mem (CPU total)=17163.83984375MB
INFO:root:[  108] Training loss: 0.47328910, Validation loss: 0.42590594, Gradient norm: 7.09757012
INFO:root:At the start of the epoch: mem (CPU python)=15616.96484375MB; mem (CPU total)=17183.7109375MB
INFO:root:[  109] Training loss: 0.47327906, Validation loss: 0.42609023, Gradient norm: 8.22569146
INFO:root:At the start of the epoch: mem (CPU python)=15638.12890625MB; mem (CPU total)=17204.52734375MB
INFO:root:[  110] Training loss: 0.47283936, Validation loss: 0.42696531, Gradient norm: 9.69898205
INFO:root:At the start of the epoch: mem (CPU python)=15659.29296875MB; mem (CPU total)=15368.38671875MB
INFO:root:[  111] Training loss: 0.47277240, Validation loss: 0.42660189, Gradient norm: 8.89276351
INFO:root:At the start of the epoch: mem (CPU python)=15680.4609375MB; mem (CPU total)=15388.23828125MB
INFO:root:[  112] Training loss: 0.47274224, Validation loss: 0.42731659, Gradient norm: 8.41277966
INFO:root:At the start of the epoch: mem (CPU python)=15701.62109375MB; mem (CPU total)=15408.37890625MB
INFO:root:[  113] Training loss: 0.47261358, Validation loss: 0.42643098, Gradient norm: 9.61769946
INFO:root:At the start of the epoch: mem (CPU python)=15722.78515625MB; mem (CPU total)=15429.05078125MB
INFO:root:[  114] Training loss: 0.47270575, Validation loss: 0.42643640, Gradient norm: 9.73222887
INFO:root:At the start of the epoch: mem (CPU python)=15744.203125MB; mem (CPU total)=15885.77734375MB
INFO:root:[  115] Training loss: 0.47287971, Validation loss: 0.42582058, Gradient norm: 9.13224978
INFO:root:At the start of the epoch: mem (CPU python)=15765.49609375MB; mem (CPU total)=17336.9453125MB
INFO:root:[  116] Training loss: 0.47340657, Validation loss: 0.42651051, Gradient norm: 9.23038724
INFO:root:At the start of the epoch: mem (CPU python)=15786.859375MB; mem (CPU total)=17357.68359375MB
INFO:root:[  117] Training loss: 0.47307218, Validation loss: 0.42648852, Gradient norm: 11.59749772
INFO:root:At the start of the epoch: mem (CPU python)=15808.1953125MB; mem (CPU total)=17379.3515625MB
INFO:root:[  118] Training loss: 0.47312023, Validation loss: 0.42621563, Gradient norm: 13.23858458
INFO:root:At the start of the epoch: mem (CPU python)=15829.359375MB; mem (CPU total)=17398.76171875MB
INFO:root:[  119] Training loss: 0.47379819, Validation loss: 0.42940537, Gradient norm: 12.94988719
INFO:root:At the start of the epoch: mem (CPU python)=15850.76171875MB; mem (CPU total)=17419.67578125MB
INFO:root:[  120] Training loss: 0.47286353, Validation loss: 0.42623889, Gradient norm: 11.36510433
INFO:root:At the start of the epoch: mem (CPU python)=15872.05859375MB; mem (CPU total)=17439.32421875MB
INFO:root:[  121] Training loss: 0.47370748, Validation loss: 0.42785691, Gradient norm: 12.78932021
INFO:root:At the start of the epoch: mem (CPU python)=15893.44140625MB; mem (CPU total)=17534.41015625MB
INFO:root:[  122] Training loss: 0.47356684, Validation loss: 0.42713572, Gradient norm: 10.84656735
INFO:root:At the start of the epoch: mem (CPU python)=15915.1953125MB; mem (CPU total)=15622.93359375MB
INFO:root:[  123] Training loss: 0.47304230, Validation loss: 0.42634784, Gradient norm: 11.97850164
INFO:root:At the start of the epoch: mem (CPU python)=15936.359375MB; mem (CPU total)=15644.125MB
INFO:root:[  124] Training loss: 0.47371066, Validation loss: 0.42675710, Gradient norm: 12.97704387
INFO:root:At the start of the epoch: mem (CPU python)=15958.69921875MB; mem (CPU total)=15665.65234375MB
INFO:root:EP 124: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=15980.08984375MB; mem (CPU total)=15686.0078125MB
INFO:root:Training the model took 3853.839s.
INFO:root:Emptying the cuda cache took 0.037s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.62075
INFO:root:EnergyScoreValidation: 0.33626
INFO:root:CRPSValidation: 0.15314
INFO:root:Gaussian NLLValidation: 6.37723
INFO:root:CoverageValidation: 0.62144
INFO:root:IntervalWidthValidation: 0.71017
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.64829
INFO:root:EnergyScoreTest: 0.3551
INFO:root:CRPSTest: 0.16156
INFO:root:Gaussian NLLTest: 8.92612
INFO:root:CoverageTest: 0.61265
INFO:root:IntervalWidthTest: 0.72041
INFO:root:After validation: mem (CPU python)=16047.48828125MB; mem (CPU total)=15711.7734375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=16047.48828125MB; mem (CPU total)=15712.1171875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 367001600
INFO:root:After setting up the model: mem (CPU python)=16047.48828125MB; mem (CPU total)=15712.1171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=16047.48828125MB; mem (CPU total)=15712.109375MB
INFO:root:[    1] Training loss: 0.85787321, Validation loss: 0.73906795, Gradient norm: 0.37741049
INFO:root:At the start of the epoch: mem (CPU python)=16047.48828125MB; mem (CPU total)=15733.12890625MB
INFO:root:[    2] Training loss: 0.75255034, Validation loss: 0.73881387, Gradient norm: 0.48656446
INFO:root:At the start of the epoch: mem (CPU python)=16057.0625MB; mem (CPU total)=15753.5546875MB
INFO:root:[    3] Training loss: 0.74698376, Validation loss: 0.72509002, Gradient norm: 0.68399091
INFO:root:At the start of the epoch: mem (CPU python)=16078.23046875MB; mem (CPU total)=15774.6875MB
INFO:root:[    4] Training loss: 0.73889185, Validation loss: 0.70862480, Gradient norm: 1.04059502
INFO:root:At the start of the epoch: mem (CPU python)=16099.39453125MB; mem (CPU total)=15795.63671875MB
INFO:root:[    5] Training loss: 0.72985313, Validation loss: 0.71023513, Gradient norm: 1.23106505
INFO:root:At the start of the epoch: mem (CPU python)=16120.55859375MB; mem (CPU total)=15816.80078125MB
INFO:root:[    6] Training loss: 0.71989520, Validation loss: 0.67299921, Gradient norm: 1.54770988
INFO:root:At the start of the epoch: mem (CPU python)=16141.7265625MB; mem (CPU total)=15839.015625MB
INFO:root:[    7] Training loss: 0.69143429, Validation loss: 0.65481861, Gradient norm: 1.75654711
INFO:root:At the start of the epoch: mem (CPU python)=16162.890625MB; mem (CPU total)=15859.30859375MB
INFO:root:[    8] Training loss: 0.66800282, Validation loss: 0.65831340, Gradient norm: 2.24657734
INFO:root:At the start of the epoch: mem (CPU python)=16184.05078125MB; mem (CPU total)=15880.48828125MB
INFO:root:[    9] Training loss: 0.65799412, Validation loss: 0.60392003, Gradient norm: 2.67542691
INFO:root:At the start of the epoch: mem (CPU python)=16205.21484375MB; mem (CPU total)=15901.84765625MB
INFO:root:[   10] Training loss: 0.64266354, Validation loss: 0.58783092, Gradient norm: 2.57021992
INFO:root:At the start of the epoch: mem (CPU python)=16226.37890625MB; mem (CPU total)=15925.1796875MB
INFO:root:[   11] Training loss: 0.63070131, Validation loss: 0.58104216, Gradient norm: 2.73423527
INFO:root:At the start of the epoch: mem (CPU python)=16247.546875MB; mem (CPU total)=15946.28125MB
INFO:root:[   12] Training loss: 0.62841626, Validation loss: 0.58669125, Gradient norm: 3.25090914
INFO:root:At the start of the epoch: mem (CPU python)=16268.7109375MB; mem (CPU total)=15967.46875MB
INFO:root:[   13] Training loss: 0.61803864, Validation loss: 0.57305955, Gradient norm: 3.03640244
INFO:root:At the start of the epoch: mem (CPU python)=16289.875MB; mem (CPU total)=15988.47265625MB
INFO:root:[   14] Training loss: 0.61379403, Validation loss: 0.54946373, Gradient norm: 3.46021054
INFO:root:At the start of the epoch: mem (CPU python)=16311.0390625MB; mem (CPU total)=17211.73828125MB
INFO:root:[   15] Training loss: 0.60131624, Validation loss: 0.54050761, Gradient norm: 3.42522090
INFO:root:At the start of the epoch: mem (CPU python)=16332.203125MB; mem (CPU total)=17887.3984375MB
INFO:root:[   16] Training loss: 0.60474032, Validation loss: 0.54930643, Gradient norm: 3.73067684
INFO:root:At the start of the epoch: mem (CPU python)=16353.3671875MB; mem (CPU total)=17910.94921875MB
INFO:root:[   17] Training loss: 0.60525961, Validation loss: 0.54189421, Gradient norm: 3.82702783
INFO:root:At the start of the epoch: mem (CPU python)=16374.52734375MB; mem (CPU total)=17930.96875MB
INFO:root:[   18] Training loss: 0.60027087, Validation loss: 0.53937467, Gradient norm: 4.48319062
INFO:root:At the start of the epoch: mem (CPU python)=16395.69140625MB; mem (CPU total)=17974.03125MB
INFO:root:[   19] Training loss: 0.60619126, Validation loss: 0.54614465, Gradient norm: 4.16751319
INFO:root:At the start of the epoch: mem (CPU python)=16416.85546875MB; mem (CPU total)=16122.05859375MB
INFO:root:[   20] Training loss: 0.60061284, Validation loss: 0.55579689, Gradient norm: 4.47272500
INFO:root:At the start of the epoch: mem (CPU python)=16438.0234375MB; mem (CPU total)=16141.62109375MB
INFO:root:[   21] Training loss: 0.59904244, Validation loss: 0.53613178, Gradient norm: 4.64811875
INFO:root:At the start of the epoch: mem (CPU python)=16459.1875MB; mem (CPU total)=16162.03515625MB
INFO:root:[   22] Training loss: 0.60087525, Validation loss: 0.54671729, Gradient norm: 4.44252061
INFO:root:At the start of the epoch: mem (CPU python)=16480.3515625MB; mem (CPU total)=16182.94921875MB
INFO:root:[   23] Training loss: 0.58878951, Validation loss: 0.52996268, Gradient norm: 4.50926910
INFO:root:At the start of the epoch: mem (CPU python)=16501.515625MB; mem (CPU total)=16203.1171875MB
INFO:root:[   24] Training loss: 0.59423632, Validation loss: 0.54773019, Gradient norm: 4.72934551
INFO:root:At the start of the epoch: mem (CPU python)=16522.6796875MB; mem (CPU total)=16223.9921875MB
INFO:root:[   25] Training loss: 0.58940934, Validation loss: 0.53643584, Gradient norm: 4.74223034
INFO:root:At the start of the epoch: mem (CPU python)=16543.84765625MB; mem (CPU total)=16244.671875MB
INFO:root:[   26] Training loss: 0.58983573, Validation loss: 0.54073128, Gradient norm: 4.97961273
INFO:root:At the start of the epoch: mem (CPU python)=16565.01171875MB; mem (CPU total)=16265.5859375MB
INFO:root:[   27] Training loss: 0.59534342, Validation loss: 0.52522971, Gradient norm: 5.52400299
INFO:root:At the start of the epoch: mem (CPU python)=16586.171875MB; mem (CPU total)=16286.39453125MB
INFO:root:[   28] Training loss: 0.60013744, Validation loss: 0.52218009, Gradient norm: 5.45024061
INFO:root:At the start of the epoch: mem (CPU python)=16607.3359375MB; mem (CPU total)=16306.82421875MB
INFO:root:[   29] Training loss: 0.58699475, Validation loss: 0.51368715, Gradient norm: 5.16007008
INFO:root:At the start of the epoch: mem (CPU python)=16628.50390625MB; mem (CPU total)=16328.26171875MB
INFO:root:[   30] Training loss: 0.58998676, Validation loss: 0.54621524, Gradient norm: 5.63871908
INFO:root:At the start of the epoch: mem (CPU python)=16649.6640625MB; mem (CPU total)=16349.17578125MB
INFO:root:[   31] Training loss: 0.59366888, Validation loss: 0.54012480, Gradient norm: 6.00130614
INFO:root:At the start of the epoch: mem (CPU python)=16670.828125MB; mem (CPU total)=16370.32421875MB
INFO:root:[   32] Training loss: 0.59293302, Validation loss: 0.53340828, Gradient norm: 5.72519208
INFO:root:At the start of the epoch: mem (CPU python)=16691.9921875MB; mem (CPU total)=16391.484375MB
INFO:root:[   33] Training loss: 0.59391296, Validation loss: 0.53030768, Gradient norm: 6.04820440
INFO:root:At the start of the epoch: mem (CPU python)=16713.15625MB; mem (CPU total)=16412.6484375MB
INFO:root:[   34] Training loss: 0.58812143, Validation loss: 0.52070359, Gradient norm: 5.78477470
INFO:root:At the start of the epoch: mem (CPU python)=16734.3203125MB; mem (CPU total)=16433.80859375MB
INFO:root:[   35] Training loss: 0.58760626, Validation loss: 0.53687148, Gradient norm: 5.68453457
INFO:root:At the start of the epoch: mem (CPU python)=16755.484375MB; mem (CPU total)=16455.20703125MB
INFO:root:[   36] Training loss: 0.59080440, Validation loss: 0.50987671, Gradient norm: 6.27920216
INFO:root:At the start of the epoch: mem (CPU python)=16776.6484375MB; mem (CPU total)=16476.35546875MB
INFO:root:[   37] Training loss: 0.58817571, Validation loss: 0.52176893, Gradient norm: 6.37049800
INFO:root:At the start of the epoch: mem (CPU python)=16797.8125MB; mem (CPU total)=16497.3828125MB
INFO:root:[   38] Training loss: 0.59407330, Validation loss: 0.55307390, Gradient norm: 6.30561881
INFO:root:At the start of the epoch: mem (CPU python)=16818.9765625MB; mem (CPU total)=16518.23828125MB
INFO:root:[   39] Training loss: 0.59134718, Validation loss: 0.53520238, Gradient norm: 6.07977877
INFO:root:At the start of the epoch: mem (CPU python)=16840.140625MB; mem (CPU total)=16539.3984375MB
INFO:root:[   40] Training loss: 0.59041440, Validation loss: 0.53159658, Gradient norm: 6.43583615
INFO:root:At the start of the epoch: mem (CPU python)=16861.30859375MB; mem (CPU total)=16561.0390625MB
INFO:root:[   41] Training loss: 0.58902716, Validation loss: 0.55424694, Gradient norm: 6.37526424
INFO:root:At the start of the epoch: mem (CPU python)=16882.47265625MB; mem (CPU total)=16612.35546875MB
INFO:root:[   42] Training loss: 0.58910218, Validation loss: 0.53891234, Gradient norm: 6.57890331
INFO:root:At the start of the epoch: mem (CPU python)=16903.63671875MB; mem (CPU total)=18457.40625MB
INFO:root:[   43] Training loss: 0.58300449, Validation loss: 0.55913337, Gradient norm: 6.20081770
INFO:root:At the start of the epoch: mem (CPU python)=16924.80078125MB; mem (CPU total)=18476.8203125MB
INFO:root:[   44] Training loss: 0.58119085, Validation loss: 0.55809711, Gradient norm: 7.01387273
INFO:root:At the start of the epoch: mem (CPU python)=16945.96484375MB; mem (CPU total)=18496.3984375MB
INFO:root:[   45] Training loss: 0.60236276, Validation loss: 0.53227630, Gradient norm: 8.72965061
INFO:root:At the start of the epoch: mem (CPU python)=16967.1328125MB; mem (CPU total)=16670.09765625MB
INFO:root:[   46] Training loss: 0.59747079, Validation loss: 0.52839751, Gradient norm: 7.55315335
INFO:root:At the start of the epoch: mem (CPU python)=16988.29296875MB; mem (CPU total)=16690.78515625MB
INFO:root:[   47] Training loss: 0.59294628, Validation loss: 0.52775472, Gradient norm: 7.07867353
INFO:root:At the start of the epoch: mem (CPU python)=17009.45703125MB; mem (CPU total)=16711.9609375MB
INFO:root:[   48] Training loss: 0.58634738, Validation loss: 0.54567353, Gradient norm: 7.27275031
INFO:root:At the start of the epoch: mem (CPU python)=17030.6171875MB; mem (CPU total)=16731.90625MB
INFO:root:[   49] Training loss: 0.59330020, Validation loss: 0.60712566, Gradient norm: 7.84605373
INFO:root:At the start of the epoch: mem (CPU python)=17051.78125MB; mem (CPU total)=16753.03515625MB
INFO:root:[   50] Training loss: 0.60240815, Validation loss: 0.56194566, Gradient norm: 7.64363297
INFO:root:At the start of the epoch: mem (CPU python)=17072.94921875MB; mem (CPU total)=16773.65625MB
INFO:root:[   51] Training loss: 0.58726204, Validation loss: 0.53058443, Gradient norm: 7.32332703
INFO:root:At the start of the epoch: mem (CPU python)=17094.11328125MB; mem (CPU total)=16794.59375MB
INFO:root:[   52] Training loss: 0.58240652, Validation loss: 0.57447850, Gradient norm: 7.52906403
INFO:root:At the start of the epoch: mem (CPU python)=17115.27734375MB; mem (CPU total)=16815.6640625MB
INFO:root:[   53] Training loss: 0.60162462, Validation loss: 0.54681031, Gradient norm: 8.52792552
INFO:root:At the start of the epoch: mem (CPU python)=17136.44140625MB; mem (CPU total)=16836.828125MB
INFO:root:[   54] Training loss: 0.59831383, Validation loss: 0.52712011, Gradient norm: 8.14992882
INFO:root:At the start of the epoch: mem (CPU python)=17157.60546875MB; mem (CPU total)=16857.6015625MB
INFO:root:[   55] Training loss: 0.58923045, Validation loss: 0.52036412, Gradient norm: 7.46569505
INFO:root:At the start of the epoch: mem (CPU python)=17178.76953125MB; mem (CPU total)=16878.54296875MB
INFO:root:[   56] Training loss: 0.59143722, Validation loss: 0.50261057, Gradient norm: 8.25136001
INFO:root:At the start of the epoch: mem (CPU python)=17199.93359375MB; mem (CPU total)=16899.71875MB
INFO:root:[   57] Training loss: 0.59162561, Validation loss: 0.52170732, Gradient norm: 7.94469025
INFO:root:At the start of the epoch: mem (CPU python)=17221.09765625MB; mem (CPU total)=16920.77734375MB
INFO:root:[   58] Training loss: 0.58277964, Validation loss: 0.51695339, Gradient norm: 7.37125924
INFO:root:At the start of the epoch: mem (CPU python)=17242.26171875MB; mem (CPU total)=16941.67578125MB
INFO:root:[   59] Training loss: 0.58426947, Validation loss: 0.52378129, Gradient norm: 8.48143581
INFO:root:At the start of the epoch: mem (CPU python)=17263.42578125MB; mem (CPU total)=16962.80859375MB
INFO:root:[   60] Training loss: 0.58611549, Validation loss: 0.53328103, Gradient norm: 8.29455649
INFO:root:At the start of the epoch: mem (CPU python)=17284.58984375MB; mem (CPU total)=16983.953125MB
INFO:root:[   61] Training loss: 0.59009107, Validation loss: 0.52985582, Gradient norm: 8.95832030
INFO:root:At the start of the epoch: mem (CPU python)=17305.7578125MB; mem (CPU total)=17005.09765625MB
INFO:root:[   62] Training loss: 0.59589705, Validation loss: 0.50730153, Gradient norm: 9.34564394
INFO:root:At the start of the epoch: mem (CPU python)=17326.921875MB; mem (CPU total)=17026.25MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.58923556, Validation loss: 0.53324157, Gradient norm: 8.73577863
INFO:root:At the start of the epoch: mem (CPU python)=17348.0859375MB; mem (CPU total)=17047.48828125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.55279458, Validation loss: 0.49156188, Gradient norm: 7.33883156
INFO:root:At the start of the epoch: mem (CPU python)=17369.24609375MB; mem (CPU total)=17068.65234375MB
INFO:root:[   65] Training loss: 0.53905622, Validation loss: 0.47161461, Gradient norm: 5.71510707
INFO:root:At the start of the epoch: mem (CPU python)=17390.41015625MB; mem (CPU total)=17089.87890625MB
INFO:root:[   66] Training loss: 0.53912166, Validation loss: 0.46909964, Gradient norm: 6.65141630
INFO:root:At the start of the epoch: mem (CPU python)=17411.5703125MB; mem (CPU total)=17111.04296875MB
INFO:root:[   67] Training loss: 0.54021112, Validation loss: 0.47279343, Gradient norm: 8.39043199
INFO:root:At the start of the epoch: mem (CPU python)=17432.734375MB; mem (CPU total)=17132.453125MB
INFO:root:[   68] Training loss: 0.54080848, Validation loss: 0.47363977, Gradient norm: 8.79640128
INFO:root:At the start of the epoch: mem (CPU python)=17453.90234375MB; mem (CPU total)=17153.6171875MB
INFO:root:[   69] Training loss: 0.54083877, Validation loss: 0.47769806, Gradient norm: 9.18321200
INFO:root:At the start of the epoch: mem (CPU python)=17475.06640625MB; mem (CPU total)=17174.78125MB
INFO:root:[   70] Training loss: 0.54301959, Validation loss: 0.47139466, Gradient norm: 10.37450308
INFO:root:At the start of the epoch: mem (CPU python)=17496.23046875MB; mem (CPU total)=17195.9453125MB
INFO:root:[   71] Training loss: 0.54279401, Validation loss: 0.47448832, Gradient norm: 11.58346589
INFO:root:At the start of the epoch: mem (CPU python)=17517.39453125MB; mem (CPU total)=17217.09765625MB
INFO:root:[   72] Training loss: 0.54473063, Validation loss: 0.47306194, Gradient norm: 11.11969463
INFO:root:At the start of the epoch: mem (CPU python)=17538.55859375MB; mem (CPU total)=17238.25390625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   73] Training loss: 0.54275086, Validation loss: 0.48102520, Gradient norm: 12.19564770
INFO:root:At the start of the epoch: mem (CPU python)=17559.7265625MB; mem (CPU total)=17259.1875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   74] Training loss: 0.53464222, Validation loss: 0.46676700, Gradient norm: 8.67739594
INFO:root:At the start of the epoch: mem (CPU python)=17580.88671875MB; mem (CPU total)=17280.09375MB
INFO:root:[   75] Training loss: 0.52952582, Validation loss: 0.46484163, Gradient norm: 5.92686210
INFO:root:At the start of the epoch: mem (CPU python)=17602.05078125MB; mem (CPU total)=17300.9921875MB
INFO:root:[   76] Training loss: 0.53000042, Validation loss: 0.46278057, Gradient norm: 7.72325664
INFO:root:At the start of the epoch: mem (CPU python)=17623.21484375MB; mem (CPU total)=17322.15625MB
INFO:root:[   77] Training loss: 0.52935937, Validation loss: 0.46388690, Gradient norm: 7.48055106
INFO:root:At the start of the epoch: mem (CPU python)=17644.37890625MB; mem (CPU total)=17343.56640625MB
INFO:root:[   78] Training loss: 0.52912273, Validation loss: 0.46368480, Gradient norm: 7.92924946
INFO:root:At the start of the epoch: mem (CPU python)=17665.54296875MB; mem (CPU total)=17364.72265625MB
INFO:root:[   79] Training loss: 0.52965616, Validation loss: 0.46814205, Gradient norm: 9.06783046
INFO:root:At the start of the epoch: mem (CPU python)=17686.7109375MB; mem (CPU total)=17385.875MB
INFO:root:[   80] Training loss: 0.53020923, Validation loss: 0.46252351, Gradient norm: 10.83540898
INFO:root:At the start of the epoch: mem (CPU python)=17707.875MB; mem (CPU total)=17407.01953125MB
INFO:root:[   81] Training loss: 0.52868089, Validation loss: 0.46462019, Gradient norm: 9.62539018
INFO:root:At the start of the epoch: mem (CPU python)=17729.0390625MB; mem (CPU total)=17427.921875MB
INFO:root:[   82] Training loss: 0.52890459, Validation loss: 0.46826962, Gradient norm: 9.64436991
INFO:root:At the start of the epoch: mem (CPU python)=17750.19921875MB; mem (CPU total)=17449.0703125MB
INFO:root:[   83] Training loss: 0.52981789, Validation loss: 0.46395536, Gradient norm: 10.95659203
INFO:root:At the start of the epoch: mem (CPU python)=17771.359375MB; mem (CPU total)=17470.40234375MB
INFO:root:[   84] Training loss: 0.52897872, Validation loss: 0.46573431, Gradient norm: 10.98867574
INFO:root:At the start of the epoch: mem (CPU python)=17792.52734375MB; mem (CPU total)=17491.5625MB
INFO:root:[   85] Training loss: 0.52805950, Validation loss: 0.46376233, Gradient norm: 11.28932980
INFO:root:At the start of the epoch: mem (CPU python)=17813.69140625MB; mem (CPU total)=17512.640625MB
INFO:root:[   86] Training loss: 0.52832788, Validation loss: 0.46419828, Gradient norm: 11.83502263
INFO:root:At the start of the epoch: mem (CPU python)=17834.85546875MB; mem (CPU total)=17533.79296875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   87] Training loss: 0.52867305, Validation loss: 0.46831094, Gradient norm: 11.72744216
INFO:root:At the start of the epoch: mem (CPU python)=17856.01953125MB; mem (CPU total)=17554.9453125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   88] Training loss: 0.52683512, Validation loss: 0.46241032, Gradient norm: 8.34484526
INFO:root:At the start of the epoch: mem (CPU python)=17877.18359375MB; mem (CPU total)=17576.0390625MB
INFO:root:[   89] Training loss: 0.52528521, Validation loss: 0.46237059, Gradient norm: 6.61151208
INFO:root:At the start of the epoch: mem (CPU python)=17898.3515625MB; mem (CPU total)=17597.171875MB
INFO:root:[   90] Training loss: 0.52528502, Validation loss: 0.46157014, Gradient norm: 7.15045004
INFO:root:At the start of the epoch: mem (CPU python)=17919.515625MB; mem (CPU total)=17618.328125MB
INFO:root:[   91] Training loss: 0.52498570, Validation loss: 0.46180559, Gradient norm: 6.68143527
INFO:root:At the start of the epoch: mem (CPU python)=17940.6796875MB; mem (CPU total)=17639.4765625MB
INFO:root:[   92] Training loss: 0.52464003, Validation loss: 0.46168020, Gradient norm: 6.57221483
INFO:root:At the start of the epoch: mem (CPU python)=17961.84375MB; mem (CPU total)=17660.63671875MB
INFO:root:[   93] Training loss: 0.52476279, Validation loss: 0.46185928, Gradient norm: 8.53395425
INFO:root:At the start of the epoch: mem (CPU python)=17983.00390625MB; mem (CPU total)=17681.79296875MB
INFO:root:[   94] Training loss: 0.52460980, Validation loss: 0.46133630, Gradient norm: 6.88679845
INFO:root:At the start of the epoch: mem (CPU python)=18004.171875MB; mem (CPU total)=17702.9375MB
INFO:root:[   95] Training loss: 0.52478729, Validation loss: 0.46123882, Gradient norm: 8.99053077
INFO:root:At the start of the epoch: mem (CPU python)=18025.3359375MB; mem (CPU total)=17724.32421875MB
INFO:root:[   96] Training loss: 0.52460777, Validation loss: 0.46176665, Gradient norm: 9.28773175
INFO:root:At the start of the epoch: mem (CPU python)=18046.5MB; mem (CPU total)=17745.4765625MB
INFO:root:[   97] Training loss: 0.52448346, Validation loss: 0.46201042, Gradient norm: 9.82659275
INFO:root:At the start of the epoch: mem (CPU python)=18067.6640625MB; mem (CPU total)=17766.88671875MB
INFO:root:[   98] Training loss: 0.52530161, Validation loss: 0.46228259, Gradient norm: 11.15360027
INFO:root:At the start of the epoch: mem (CPU python)=18088.828125MB; mem (CPU total)=17788.05078125MB
INFO:root:[   99] Training loss: 0.52470742, Validation loss: 0.46228383, Gradient norm: 9.36531677
INFO:root:At the start of the epoch: mem (CPU python)=18109.98828125MB; mem (CPU total)=17809.18359375MB
INFO:root:[  100] Training loss: 0.52441362, Validation loss: 0.46229435, Gradient norm: 8.79211707
INFO:root:At the start of the epoch: mem (CPU python)=18131.15234375MB; mem (CPU total)=17830.34765625MB
INFO:root:[  101] Training loss: 0.52470266, Validation loss: 0.46266971, Gradient norm: 12.03077160
INFO:root:At the start of the epoch: mem (CPU python)=18152.3203125MB; mem (CPU total)=17851.5078125MB
INFO:root:[  102] Training loss: 0.52400441, Validation loss: 0.46166373, Gradient norm: 9.22729478
INFO:root:At the start of the epoch: mem (CPU python)=18173.48046875MB; mem (CPU total)=17872.671875MB
INFO:root:[  103] Training loss: 0.52450890, Validation loss: 0.46236724, Gradient norm: 10.60048502
INFO:root:At the start of the epoch: mem (CPU python)=18194.64453125MB; mem (CPU total)=17894.08203125MB
INFO:root:[  104] Training loss: 0.52410812, Validation loss: 0.46228772, Gradient norm: 10.74278163
INFO:root:At the start of the epoch: mem (CPU python)=18215.80859375MB; mem (CPU total)=17915.4296875MB
INFO:root:EP 104: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=18236.87109375MB; mem (CPU total)=17936.1015625MB
INFO:root:Training the model took 3478.844s.
INFO:root:Emptying the cuda cache took 0.036s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.61434
INFO:root:EnergyScoreValidation: 0.34921
INFO:root:CRPSValidation: 0.15774
INFO:root:Gaussian NLLValidation: 9.24185
INFO:root:CoverageValidation: 0.56463
INFO:root:IntervalWidthValidation: 0.59818
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.61553
INFO:root:EnergyScoreTest: 0.35392
INFO:root:CRPSTest: 0.16125
INFO:root:Gaussian NLLTest: 13.38866
INFO:root:CoverageTest: 0.55265
INFO:root:IntervalWidthTest: 0.57906
INFO:root:After validation: mem (CPU python)=18294.875MB; mem (CPU total)=17953.1875MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=18294.875MB; mem (CPU total)=17953.0234375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 367001600
INFO:root:After setting up the model: mem (CPU python)=18294.875MB; mem (CPU total)=17953.0234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=18294.875MB; mem (CPU total)=17953.265625MB
INFO:root:[    1] Training loss: 0.86891167, Validation loss: 0.73662448, Gradient norm: 0.34637988
INFO:root:At the start of the epoch: mem (CPU python)=18294.875MB; mem (CPU total)=17973.74609375MB
INFO:root:[    2] Training loss: 0.75571312, Validation loss: 0.73410792, Gradient norm: 0.32610048
INFO:root:At the start of the epoch: mem (CPU python)=18299.64453125MB; mem (CPU total)=17994.91015625MB
INFO:root:[    3] Training loss: 0.74939258, Validation loss: 0.72675532, Gradient norm: 0.52415214
INFO:root:At the start of the epoch: mem (CPU python)=18320.8125MB; mem (CPU total)=18016.07421875MB
INFO:root:[    4] Training loss: 0.74053824, Validation loss: 0.71368402, Gradient norm: 0.70537682
INFO:root:At the start of the epoch: mem (CPU python)=18341.9765625MB; mem (CPU total)=18037.26953125MB
INFO:root:[    5] Training loss: 0.72969490, Validation loss: 0.69924890, Gradient norm: 0.86549241
INFO:root:At the start of the epoch: mem (CPU python)=18363.140625MB; mem (CPU total)=18058.359375MB
INFO:root:[    6] Training loss: 0.71919843, Validation loss: 0.68976263, Gradient norm: 1.51888805
INFO:root:At the start of the epoch: mem (CPU python)=18384.3046875MB; mem (CPU total)=18079.76953125MB
INFO:root:[    7] Training loss: 0.70853184, Validation loss: 0.64935983, Gradient norm: 1.57459738
INFO:root:At the start of the epoch: mem (CPU python)=18405.46875MB; mem (CPU total)=18100.93359375MB
INFO:root:[    8] Training loss: 0.69905173, Validation loss: 0.65398248, Gradient norm: 2.12484221
INFO:root:At the start of the epoch: mem (CPU python)=18426.6328125MB; mem (CPU total)=18122.0625MB
INFO:root:[    9] Training loss: 0.69414074, Validation loss: 0.64841136, Gradient norm: 2.35032966
INFO:root:At the start of the epoch: mem (CPU python)=18447.796875MB; mem (CPU total)=18143.26171875MB
INFO:root:[   10] Training loss: 0.68676485, Validation loss: 0.64829049, Gradient norm: 2.57629907
INFO:root:At the start of the epoch: mem (CPU python)=18468.9609375MB; mem (CPU total)=18164.72265625MB
INFO:root:[   11] Training loss: 0.68143960, Validation loss: 0.63226370, Gradient norm: 2.90381105
INFO:root:At the start of the epoch: mem (CPU python)=18490.125MB; mem (CPU total)=18185.640625MB
INFO:root:[   12] Training loss: 0.67923728, Validation loss: 0.61545028, Gradient norm: 3.37843500
INFO:root:At the start of the epoch: mem (CPU python)=18511.2890625MB; mem (CPU total)=18206.80078125MB
INFO:root:[   13] Training loss: 0.67706459, Validation loss: 0.61090489, Gradient norm: 3.46586796
INFO:root:At the start of the epoch: mem (CPU python)=18532.45703125MB; mem (CPU total)=18228.1796875MB
INFO:root:[   14] Training loss: 0.67185187, Validation loss: 0.60179353, Gradient norm: 3.79241437
INFO:root:At the start of the epoch: mem (CPU python)=18553.62109375MB; mem (CPU total)=18249.37890625MB
INFO:root:[   15] Training loss: 0.67257773, Validation loss: 0.61252739, Gradient norm: 4.23996567
INFO:root:At the start of the epoch: mem (CPU python)=18574.78515625MB; mem (CPU total)=18270.80078125MB
INFO:root:[   16] Training loss: 0.66497122, Validation loss: 0.59174561, Gradient norm: 4.03183947
INFO:root:At the start of the epoch: mem (CPU python)=18595.94921875MB; mem (CPU total)=18291.6953125MB
INFO:root:[   17] Training loss: 0.66912274, Validation loss: 0.60625866, Gradient norm: 4.57654986
INFO:root:At the start of the epoch: mem (CPU python)=18617.109375MB; mem (CPU total)=18313.10546875MB
INFO:root:[   18] Training loss: 0.66204646, Validation loss: 0.59184636, Gradient norm: 4.42516704
INFO:root:At the start of the epoch: mem (CPU python)=18638.26953125MB; mem (CPU total)=18334.28515625MB
INFO:root:[   19] Training loss: 0.65550009, Validation loss: 0.63768237, Gradient norm: 4.49815851
INFO:root:At the start of the epoch: mem (CPU python)=18659.4375MB; mem (CPU total)=18355.4609375MB
INFO:root:[   20] Training loss: 0.66201545, Validation loss: 0.59256663, Gradient norm: 5.07782601
INFO:root:At the start of the epoch: mem (CPU python)=18680.6015625MB; mem (CPU total)=18376.6328125MB
INFO:root:[   21] Training loss: 0.66151081, Validation loss: 0.59158424, Gradient norm: 5.37756559
INFO:root:At the start of the epoch: mem (CPU python)=18701.765625MB; mem (CPU total)=18397.80859375MB
INFO:root:[   22] Training loss: 0.65633149, Validation loss: 0.58468161, Gradient norm: 5.23159968
INFO:root:At the start of the epoch: mem (CPU python)=18722.9296875MB; mem (CPU total)=18419.015625MB
INFO:root:[   23] Training loss: 0.65888344, Validation loss: 0.60553718, Gradient norm: 5.54223361
INFO:root:At the start of the epoch: mem (CPU python)=18744.09375MB; mem (CPU total)=18440.13671875MB
INFO:root:[   24] Training loss: 0.65154090, Validation loss: 0.58799368, Gradient norm: 5.05267884
INFO:root:At the start of the epoch: mem (CPU python)=18765.2578125MB; mem (CPU total)=18461.296875MB
INFO:root:[   25] Training loss: 0.65264794, Validation loss: 0.59046070, Gradient norm: 5.96347363
INFO:root:At the start of the epoch: mem (CPU python)=18786.42578125MB; mem (CPU total)=18482.83203125MB
INFO:root:[   26] Training loss: 0.65053667, Validation loss: 0.58712619, Gradient norm: 5.83946778
INFO:root:At the start of the epoch: mem (CPU python)=18807.58984375MB; mem (CPU total)=18503.6171875MB
INFO:root:[   27] Training loss: 0.65962437, Validation loss: 0.58856984, Gradient norm: 6.50155336
INFO:root:At the start of the epoch: mem (CPU python)=18828.75390625MB; mem (CPU total)=18524.79296875MB
INFO:root:[   28] Training loss: 0.65228646, Validation loss: 0.61745975, Gradient norm: 6.05504444
INFO:root:At the start of the epoch: mem (CPU python)=18849.9140625MB; mem (CPU total)=18546.21875MB
INFO:root:[   29] Training loss: 0.65789854, Validation loss: 0.56758528, Gradient norm: 6.76314688
INFO:root:At the start of the epoch: mem (CPU python)=18871.08203125MB; mem (CPU total)=18567.375MB
INFO:root:[   30] Training loss: 0.65206177, Validation loss: 0.57607624, Gradient norm: 6.77747023
INFO:root:At the start of the epoch: mem (CPU python)=18892.24609375MB; mem (CPU total)=18588.53515625MB
INFO:root:[   31] Training loss: 0.65387719, Validation loss: 0.60643207, Gradient norm: 6.95272364
INFO:root:At the start of the epoch: mem (CPU python)=18913.41015625MB; mem (CPU total)=18609.734375MB
INFO:root:[   32] Training loss: 0.64645680, Validation loss: 0.57353484, Gradient norm: 6.76727229
INFO:root:At the start of the epoch: mem (CPU python)=18934.57421875MB; mem (CPU total)=18631.29296875MB
INFO:root:[   33] Training loss: 0.62594012, Validation loss: 0.53711656, Gradient norm: 6.67180352
INFO:root:At the start of the epoch: mem (CPU python)=18955.7421875MB; mem (CPU total)=18652.34375MB
INFO:root:[   34] Training loss: 0.64398035, Validation loss: 0.61913161, Gradient norm: 9.30908584
INFO:root:At the start of the epoch: mem (CPU python)=18976.8984375MB; mem (CPU total)=18673.2734375MB
INFO:root:[   35] Training loss: 0.64461346, Validation loss: 0.57223073, Gradient norm: 8.75274815
INFO:root:At the start of the epoch: mem (CPU python)=18998.06640625MB; mem (CPU total)=18694.453125MB
INFO:root:[   36] Training loss: 0.63555336, Validation loss: 0.51997453, Gradient norm: 8.35154598
INFO:root:At the start of the epoch: mem (CPU python)=19019.23046875MB; mem (CPU total)=18715.62890625MB
INFO:root:[   37] Training loss: 0.63049271, Validation loss: 0.56102227, Gradient norm: 8.48101254
INFO:root:At the start of the epoch: mem (CPU python)=19040.390625MB; mem (CPU total)=18736.796875MB
INFO:root:[   38] Training loss: 0.63734649, Validation loss: 0.56802719, Gradient norm: 9.49752101
INFO:root:At the start of the epoch: mem (CPU python)=19061.5546875MB; mem (CPU total)=18758.15625MB
INFO:root:[   39] Training loss: 0.63589545, Validation loss: 0.52811974, Gradient norm: 9.16012890
INFO:root:At the start of the epoch: mem (CPU python)=19082.72265625MB; mem (CPU total)=18779.1640625MB
INFO:root:[   40] Training loss: 0.63075094, Validation loss: 0.52610087, Gradient norm: 8.94072420
INFO:root:At the start of the epoch: mem (CPU python)=19103.88671875MB; mem (CPU total)=18800.328125MB
INFO:root:[   41] Training loss: 0.64413438, Validation loss: 0.54253333, Gradient norm: 9.84692725
INFO:root:At the start of the epoch: mem (CPU python)=19125.05078125MB; mem (CPU total)=18821.50390625MB
INFO:root:[   42] Training loss: 0.63430914, Validation loss: 0.54055125, Gradient norm: 9.55424132
INFO:root:At the start of the epoch: mem (CPU python)=19146.21484375MB; mem (CPU total)=18842.92578125MB
INFO:root:[   43] Training loss: 0.63545440, Validation loss: 0.52709253, Gradient norm: 9.65254415
INFO:root:At the start of the epoch: mem (CPU python)=19167.3828125MB; mem (CPU total)=18864.0859375MB
INFO:root:[   44] Training loss: 0.63494490, Validation loss: 0.53384909, Gradient norm: 10.19751990
INFO:root:At the start of the epoch: mem (CPU python)=19188.546875MB; mem (CPU total)=18885.51171875MB
INFO:root:[   45] Training loss: 0.63026238, Validation loss: 0.55362712, Gradient norm: 10.13584425
INFO:root:At the start of the epoch: mem (CPU python)=19209.7109375MB; mem (CPU total)=18906.37890625MB
INFO:root:[   46] Training loss: 0.63488293, Validation loss: 0.52873915, Gradient norm: 10.62180683
INFO:root:At the start of the epoch: mem (CPU python)=19230.87109375MB; mem (CPU total)=18927.5546875MB
INFO:root:[   47] Training loss: 0.64630581, Validation loss: 0.54414337, Gradient norm: 11.27664321
INFO:root:At the start of the epoch: mem (CPU python)=19252.03515625MB; mem (CPU total)=18948.73046875MB
INFO:root:[   48] Training loss: 0.63909371, Validation loss: 0.56299221, Gradient norm: 11.21094521
INFO:root:At the start of the epoch: mem (CPU python)=19273.19921875MB; mem (CPU total)=18969.90625MB
INFO:root:[   49] Training loss: 0.63425606, Validation loss: 0.58138454, Gradient norm: 10.88145346
INFO:root:At the start of the epoch: mem (CPU python)=19294.3671875MB; mem (CPU total)=18991.08203125MB
INFO:root:[   50] Training loss: 0.65057306, Validation loss: 0.55123643, Gradient norm: 12.44447298
INFO:root:At the start of the epoch: mem (CPU python)=19315.53125MB; mem (CPU total)=19012.8984375MB
INFO:root:[   51] Training loss: 0.63707970, Validation loss: 0.59188794, Gradient norm: 10.97426453
INFO:root:At the start of the epoch: mem (CPU python)=19336.69140625MB; mem (CPU total)=19033.671875MB
INFO:root:[   52] Training loss: 0.63747015, Validation loss: 0.53945063, Gradient norm: 11.26179420
INFO:root:At the start of the epoch: mem (CPU python)=19357.85546875MB; mem (CPU total)=19054.58984375MB
INFO:root:[   53] Training loss: 0.63234937, Validation loss: 0.54369707, Gradient norm: 11.42373176
INFO:root:At the start of the epoch: mem (CPU python)=19379.01953125MB; mem (CPU total)=19075.35546875MB
INFO:root:[   54] Training loss: 0.63716010, Validation loss: 0.51602232, Gradient norm: 11.90974137
INFO:root:At the start of the epoch: mem (CPU python)=19400.1875MB; mem (CPU total)=19096.79296875MB
INFO:root:[   55] Training loss: 0.64469886, Validation loss: 0.60480271, Gradient norm: 12.66644194
INFO:root:At the start of the epoch: mem (CPU python)=19421.34765625MB; mem (CPU total)=19118.4609375MB
INFO:root:[   56] Training loss: 0.64072719, Validation loss: 0.52515472, Gradient norm: 12.53766141
INFO:root:At the start of the epoch: mem (CPU python)=19442.51171875MB; mem (CPU total)=19139.79296875MB
INFO:root:[   57] Training loss: 0.64256510, Validation loss: 0.51612946, Gradient norm: 12.89754720
INFO:root:At the start of the epoch: mem (CPU python)=19463.67578125MB; mem (CPU total)=19160.9453125MB
INFO:root:[   58] Training loss: 0.63266258, Validation loss: 0.54320869, Gradient norm: 12.40505082
INFO:root:At the start of the epoch: mem (CPU python)=19484.83984375MB; mem (CPU total)=19181.8515625MB
INFO:root:[   59] Training loss: 0.64276892, Validation loss: 0.55435025, Gradient norm: 13.47350360
INFO:root:At the start of the epoch: mem (CPU python)=19506.0078125MB; mem (CPU total)=19203.015625MB
INFO:root:[   60] Training loss: 0.64534053, Validation loss: 0.56541313, Gradient norm: 13.59088187
INFO:root:At the start of the epoch: mem (CPU python)=19527.171875MB; mem (CPU total)=19224.17578125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.64473461, Validation loss: 0.56370184, Gradient norm: 13.26918780
INFO:root:At the start of the epoch: mem (CPU python)=19548.3359375MB; mem (CPU total)=19245.0859375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 0.60107800, Validation loss: 0.49774831, Gradient norm: 10.19812709
INFO:root:At the start of the epoch: mem (CPU python)=19569.5MB; mem (CPU total)=19266.28125MB
INFO:root:[   63] Training loss: 0.57857341, Validation loss: 0.49069709, Gradient norm: 8.30788153
INFO:root:At the start of the epoch: mem (CPU python)=19590.6640625MB; mem (CPU total)=19288.23828125MB
INFO:root:[   64] Training loss: 0.58005758, Validation loss: 0.49795925, Gradient norm: 10.77227928
INFO:root:At the start of the epoch: mem (CPU python)=19611.828125MB; mem (CPU total)=19309.3671875MB
INFO:root:[   65] Training loss: 0.57982792, Validation loss: 0.48759673, Gradient norm: 11.87809008
INFO:root:At the start of the epoch: mem (CPU python)=19632.98828125MB; mem (CPU total)=19330.53125MB
INFO:root:[   66] Training loss: 0.58248381, Validation loss: 0.48649196, Gradient norm: 14.20308138
INFO:root:At the start of the epoch: mem (CPU python)=19654.15625MB; mem (CPU total)=19351.9453125MB
INFO:root:[   67] Training loss: 0.58220074, Validation loss: 0.50341520, Gradient norm: 14.55098527
INFO:root:At the start of the epoch: mem (CPU python)=19675.31640625MB; mem (CPU total)=19373.109375MB
INFO:root:[   68] Training loss: 0.58469822, Validation loss: 0.50673028, Gradient norm: 15.98930393
INFO:root:At the start of the epoch: mem (CPU python)=19696.48046875MB; mem (CPU total)=19394.2734375MB
INFO:root:[   69] Training loss: 0.58449456, Validation loss: 0.50862281, Gradient norm: 17.15872220
INFO:root:At the start of the epoch: mem (CPU python)=19717.64453125MB; mem (CPU total)=19415.4375MB
INFO:root:[   70] Training loss: 0.58641180, Validation loss: 0.49413345, Gradient norm: 18.39848498
INFO:root:At the start of the epoch: mem (CPU python)=19738.80859375MB; mem (CPU total)=19436.6015625MB
INFO:root:[   71] Training loss: 0.58567975, Validation loss: 0.49549717, Gradient norm: 18.93071645
INFO:root:At the start of the epoch: mem (CPU python)=19759.9765625MB; mem (CPU total)=19458.625MB
INFO:root:[   72] Training loss: 0.58714602, Validation loss: 0.48724769, Gradient norm: 19.73293300
INFO:root:At the start of the epoch: mem (CPU python)=19781.140625MB; mem (CPU total)=19479.1640625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   73] Training loss: 0.58911469, Validation loss: 0.50434045, Gradient norm: 20.88925062
INFO:root:At the start of the epoch: mem (CPU python)=19802.3046875MB; mem (CPU total)=19500.59765625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   74] Training loss: 0.57289896, Validation loss: 0.48239883, Gradient norm: 14.46262280
INFO:root:At the start of the epoch: mem (CPU python)=19823.46875MB; mem (CPU total)=19521.5546875MB
INFO:root:[   75] Training loss: 0.56697507, Validation loss: 0.47846018, Gradient norm: 10.40940917
INFO:root:At the start of the epoch: mem (CPU python)=19844.62890625MB; mem (CPU total)=19542.734375MB
INFO:root:[   76] Training loss: 0.56617466, Validation loss: 0.48072832, Gradient norm: 12.12533616
INFO:root:At the start of the epoch: mem (CPU python)=19865.79296875MB; mem (CPU total)=19564.1953125MB
INFO:root:[   77] Training loss: 0.56530679, Validation loss: 0.48244364, Gradient norm: 13.39692105
INFO:root:At the start of the epoch: mem (CPU python)=19886.95703125MB; mem (CPU total)=19585.359375MB
INFO:root:[   78] Training loss: 0.56536747, Validation loss: 0.48054388, Gradient norm: 14.92055218
INFO:root:At the start of the epoch: mem (CPU python)=19908.125MB; mem (CPU total)=19606.51953125MB
INFO:root:[   79] Training loss: 0.56470631, Validation loss: 0.48190939, Gradient norm: 15.11904035
INFO:root:At the start of the epoch: mem (CPU python)=19929.2890625MB; mem (CPU total)=19627.6953125MB
INFO:root:[   80] Training loss: 0.56490115, Validation loss: 0.48005988, Gradient norm: 15.71728304
INFO:root:At the start of the epoch: mem (CPU python)=19950.453125MB; mem (CPU total)=19648.8671875MB
INFO:root:[   81] Training loss: 0.56410453, Validation loss: 0.48183675, Gradient norm: 16.66941417
INFO:root:At the start of the epoch: mem (CPU python)=19971.6171875MB; mem (CPU total)=19670.046875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   82] Training loss: 0.56392337, Validation loss: 0.48068328, Gradient norm: 17.69395091
INFO:root:At the start of the epoch: mem (CPU python)=19992.78515625MB; mem (CPU total)=19691.46875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   83] Training loss: 0.56098884, Validation loss: 0.47673112, Gradient norm: 10.91213111
INFO:root:At the start of the epoch: mem (CPU python)=20013.94921875MB; mem (CPU total)=19712.57421875MB
INFO:root:[   84] Training loss: 0.55919566, Validation loss: 0.47614586, Gradient norm: 8.80636776
INFO:root:At the start of the epoch: mem (CPU python)=20035.109375MB; mem (CPU total)=19733.78125MB
INFO:root:[   85] Training loss: 0.55869016, Validation loss: 0.47543414, Gradient norm: 8.96039268
INFO:root:At the start of the epoch: mem (CPU python)=20056.2734375MB; mem (CPU total)=19755.20703125MB
INFO:root:[   86] Training loss: 0.55858811, Validation loss: 0.47658859, Gradient norm: 10.79801956
INFO:root:At the start of the epoch: mem (CPU python)=20077.43359375MB; mem (CPU total)=19776.62890625MB
INFO:root:[   87] Training loss: 0.55802053, Validation loss: 0.47583226, Gradient norm: 11.38611382
INFO:root:At the start of the epoch: mem (CPU python)=20098.59765625MB; mem (CPU total)=19797.80859375MB
INFO:root:[   88] Training loss: 0.55815687, Validation loss: 0.47494049, Gradient norm: 12.45804904
INFO:root:At the start of the epoch: mem (CPU python)=20119.765625MB; mem (CPU total)=19818.9765625MB
INFO:root:[   89] Training loss: 0.55775042, Validation loss: 0.47762508, Gradient norm: 12.21391221
INFO:root:At the start of the epoch: mem (CPU python)=20140.9296875MB; mem (CPU total)=19840.171875MB
INFO:root:[   90] Training loss: 0.55748982, Validation loss: 0.47524904, Gradient norm: 12.72588593
INFO:root:At the start of the epoch: mem (CPU python)=20162.09375MB; mem (CPU total)=19861.1171875MB
INFO:root:[   91] Training loss: 0.55691083, Validation loss: 0.47634821, Gradient norm: 12.08559968
INFO:root:At the start of the epoch: mem (CPU python)=20183.2578125MB; mem (CPU total)=19882.52734375MB
INFO:root:[   92] Training loss: 0.55670520, Validation loss: 0.47680252, Gradient norm: 13.89984828
INFO:root:At the start of the epoch: mem (CPU python)=20204.421875MB; mem (CPU total)=19903.1796875MB
INFO:root:[   93] Training loss: 0.55673467, Validation loss: 0.47591573, Gradient norm: 13.90572380
INFO:root:At the start of the epoch: mem (CPU python)=20225.5859375MB; mem (CPU total)=19924.328125MB
INFO:root:[   94] Training loss: 0.55626152, Validation loss: 0.47624209, Gradient norm: 12.69292800
INFO:root:At the start of the epoch: mem (CPU python)=20246.74609375MB; mem (CPU total)=19945.8984375MB
INFO:root:[   95] Training loss: 0.55684091, Validation loss: 0.47604882, Gradient norm: 16.89781047
INFO:root:At the start of the epoch: mem (CPU python)=20267.9140625MB; mem (CPU total)=19966.68359375MB
INFO:root:[   96] Training loss: 0.55621269, Validation loss: 0.47466622, Gradient norm: 15.56628216
INFO:root:At the start of the epoch: mem (CPU python)=20289.078125MB; mem (CPU total)=19988.48828125MB
INFO:root:[   97] Training loss: 0.55610841, Validation loss: 0.47537759, Gradient norm: 19.37880013
INFO:root:At the start of the epoch: mem (CPU python)=20310.2421875MB; mem (CPU total)=20009.30078125MB
INFO:root:[   98] Training loss: 0.55649987, Validation loss: 0.47539169, Gradient norm: 20.64289446
INFO:root:At the start of the epoch: mem (CPU python)=20331.40625MB; mem (CPU total)=20030.734375MB
INFO:root:[   99] Training loss: 0.55605728, Validation loss: 0.47464952, Gradient norm: 19.13800438
INFO:root:At the start of the epoch: mem (CPU python)=20352.57421875MB; mem (CPU total)=20051.8046875MB
INFO:root:[  100] Training loss: 0.55626637, Validation loss: 0.47553649, Gradient norm: 20.47894645
INFO:root:At the start of the epoch: mem (CPU python)=20373.73828125MB; mem (CPU total)=20072.96875MB
INFO:root:[  101] Training loss: 0.55545349, Validation loss: 0.47775083, Gradient norm: 16.60259801
INFO:root:At the start of the epoch: mem (CPU python)=20394.90234375MB; mem (CPU total)=20094.375MB
INFO:root:[  102] Training loss: 0.55567755, Validation loss: 0.47531682, Gradient norm: 21.58394845
INFO:root:At the start of the epoch: mem (CPU python)=20416.0625MB; mem (CPU total)=20115.5390625MB
INFO:root:[  103] Training loss: 0.55595200, Validation loss: 0.47602977, Gradient norm: 20.21339641
INFO:root:At the start of the epoch: mem (CPU python)=20437.2265625MB; mem (CPU total)=20136.7109375MB
INFO:root:[  104] Training loss: 0.55486709, Validation loss: 0.47439468, Gradient norm: 17.45443520
INFO:root:At the start of the epoch: mem (CPU python)=20458.390625MB; mem (CPU total)=20157.45703125MB
INFO:root:[  105] Training loss: 0.55552554, Validation loss: 0.47840229, Gradient norm: 22.03752470
INFO:root:At the start of the epoch: mem (CPU python)=20479.5546875MB; mem (CPU total)=20178.6171875MB
INFO:root:[  106] Training loss: 0.55563529, Validation loss: 0.47577516, Gradient norm: 24.98744184
INFO:root:At the start of the epoch: mem (CPU python)=20500.71875MB; mem (CPU total)=20199.8125MB
INFO:root:[  107] Training loss: 0.55470837, Validation loss: 0.47365218, Gradient norm: 20.37982804
INFO:root:At the start of the epoch: mem (CPU python)=20521.8828125MB; mem (CPU total)=20221.19921875MB
INFO:root:[  108] Training loss: 0.55452994, Validation loss: 0.47621870, Gradient norm: 19.76408043
INFO:root:At the start of the epoch: mem (CPU python)=20543.046875MB; mem (CPU total)=20241.8671875MB
INFO:root:[  109] Training loss: 0.55475063, Validation loss: 0.47557992, Gradient norm: 20.91221535
INFO:root:At the start of the epoch: mem (CPU python)=20564.21484375MB; mem (CPU total)=20263.015625MB
INFO:root:[  110] Training loss: 0.55574111, Validation loss: 0.47865653, Gradient norm: 29.90801515
INFO:root:At the start of the epoch: mem (CPU python)=20585.37890625MB; mem (CPU total)=20284.16796875MB
INFO:root:[  111] Training loss: 0.55467828, Validation loss: 0.47465659, Gradient norm: 23.72696862
INFO:root:At the start of the epoch: mem (CPU python)=20606.54296875MB; mem (CPU total)=20305.56640625MB
INFO:root:[  112] Training loss: 0.55501051, Validation loss: 0.47591651, Gradient norm: 20.89138341
INFO:root:At the start of the epoch: mem (CPU python)=20627.703125MB; mem (CPU total)=20326.44140625MB
INFO:root:[  113] Training loss: 0.55580157, Validation loss: 0.47989964, Gradient norm: 31.26146812
INFO:root:At the start of the epoch: mem (CPU python)=20648.8671875MB; mem (CPU total)=20347.58984375MB
INFO:root:[  114] Training loss: 0.55496283, Validation loss: 0.47592669, Gradient norm: 27.48094771
INFO:root:At the start of the epoch: mem (CPU python)=20670.03125MB; mem (CPU total)=20368.984375MB
INFO:root:[  115] Training loss: 0.55437259, Validation loss: 0.47680484, Gradient norm: 25.99898301
INFO:root:At the start of the epoch: mem (CPU python)=20691.1953125MB; mem (CPU total)=20390.1015625MB
INFO:root:[  116] Training loss: 0.55485648, Validation loss: 0.47534474, Gradient norm: 24.35671816
INFO:root:At the start of the epoch: mem (CPU python)=20712.73828125MB; mem (CPU total)=20411.46484375MB
INFO:root:EP 116: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=20735.04296875MB; mem (CPU total)=20434.09765625MB
INFO:root:Training the model took 4163.224s.
INFO:root:Emptying the cuda cache took 0.038s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.66209
INFO:root:EnergyScoreValidation: 0.3637
INFO:root:CRPSValidation: 0.16428
INFO:root:Gaussian NLLValidation: 16.4558
INFO:root:CoverageValidation: 0.60301
INFO:root:IntervalWidthValidation: 0.71056
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.68714
INFO:root:EnergyScoreTest: 0.3804
INFO:root:CRPSTest: 0.17115
INFO:root:Gaussian NLLTest: 19.95178
INFO:root:CoverageTest: 0.59581
INFO:root:IntervalWidthTest: 0.71951
INFO:root:After validation: mem (CPU python)=20811.32421875MB; mem (CPU total)=20511.640625MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=20811.32421875MB; mem (CPU total)=20432.87890625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 367001600
INFO:root:After setting up the model: mem (CPU python)=20811.32421875MB; mem (CPU total)=20456.84765625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=20811.32421875MB; mem (CPU total)=20456.85546875MB
INFO:root:[    1] Training loss: 0.88003774, Validation loss: 0.73872342, Gradient norm: 0.32130336
INFO:root:At the start of the epoch: mem (CPU python)=20811.32421875MB; mem (CPU total)=20477.703125MB
INFO:root:[    2] Training loss: 0.76282338, Validation loss: 0.73333967, Gradient norm: 0.35148656
INFO:root:At the start of the epoch: mem (CPU python)=20811.32421875MB; mem (CPU total)=20498.8984375MB
INFO:root:[    3] Training loss: 0.75759491, Validation loss: 0.72835106, Gradient norm: 0.55893525
INFO:root:At the start of the epoch: mem (CPU python)=20818.90625MB; mem (CPU total)=20520.09375MB
INFO:root:[    4] Training loss: 0.75028747, Validation loss: 0.71601044, Gradient norm: 0.87970244
INFO:root:At the start of the epoch: mem (CPU python)=20840.07421875MB; mem (CPU total)=20541.25MB
INFO:root:[    5] Training loss: 0.74240579, Validation loss: 0.68890852, Gradient norm: 1.23131374
INFO:root:At the start of the epoch: mem (CPU python)=20862.02734375MB; mem (CPU total)=20563.88671875MB
INFO:root:[    6] Training loss: 0.73477056, Validation loss: 0.67547524, Gradient norm: 1.70365076
INFO:root:At the start of the epoch: mem (CPU python)=20883.453125MB; mem (CPU total)=20585.0390625MB
INFO:root:[    7] Training loss: 0.72705526, Validation loss: 0.67909777, Gradient norm: 2.00227418
INFO:root:At the start of the epoch: mem (CPU python)=20904.61328125MB; mem (CPU total)=20605.9765625MB
INFO:root:[    8] Training loss: 0.72210489, Validation loss: 0.67070965, Gradient norm: 2.16114185
INFO:root:At the start of the epoch: mem (CPU python)=20925.78125MB; mem (CPU total)=20627.3515625MB
INFO:root:[    9] Training loss: 0.71241981, Validation loss: 0.67816943, Gradient norm: 2.11136255
INFO:root:At the start of the epoch: mem (CPU python)=20946.94140625MB; mem (CPU total)=20648.2265625MB
INFO:root:[   10] Training loss: 0.71174938, Validation loss: 0.67632088, Gradient norm: 2.53630135
INFO:root:At the start of the epoch: mem (CPU python)=20968.10546875MB; mem (CPU total)=20669.37890625MB
INFO:root:[   11] Training loss: 0.70905994, Validation loss: 0.64146164, Gradient norm: 2.87680533
INFO:root:At the start of the epoch: mem (CPU python)=20989.26953125MB; mem (CPU total)=20690.5625MB
INFO:root:[   12] Training loss: 0.70414117, Validation loss: 0.65604705, Gradient norm: 2.87492695
INFO:root:At the start of the epoch: mem (CPU python)=21010.43359375MB; mem (CPU total)=20711.9453125MB
INFO:root:[   13] Training loss: 0.70180291, Validation loss: 0.63511951, Gradient norm: 3.29457815
INFO:root:At the start of the epoch: mem (CPU python)=21031.59765625MB; mem (CPU total)=20733.09765625MB
INFO:root:[   14] Training loss: 0.69856569, Validation loss: 0.64975358, Gradient norm: 3.45572793
INFO:root:At the start of the epoch: mem (CPU python)=21053.7734375MB; mem (CPU total)=20755.71484375MB
INFO:root:[   15] Training loss: 0.69790953, Validation loss: 0.65762028, Gradient norm: 3.37022745
INFO:root:At the start of the epoch: mem (CPU python)=21075.0546875MB; mem (CPU total)=20776.86328125MB
INFO:root:[   16] Training loss: 0.69789481, Validation loss: 0.63417007, Gradient norm: 3.54023750
INFO:root:At the start of the epoch: mem (CPU python)=21096.21484375MB; mem (CPU total)=20797.734375MB
INFO:root:[   17] Training loss: 0.69398754, Validation loss: 0.62086864, Gradient norm: 3.67568057
INFO:root:At the start of the epoch: mem (CPU python)=21117.37890625MB; mem (CPU total)=20819.16796875MB
INFO:root:[   18] Training loss: 0.68695392, Validation loss: 0.62328584, Gradient norm: 3.49194970
INFO:root:At the start of the epoch: mem (CPU python)=21138.54296875MB; mem (CPU total)=20840.32421875MB
INFO:root:[   19] Training loss: 0.69430890, Validation loss: 0.62805767, Gradient norm: 4.35181724
INFO:root:At the start of the epoch: mem (CPU python)=21159.70703125MB; mem (CPU total)=20861.4765625MB
INFO:root:[   20] Training loss: 0.68792523, Validation loss: 0.63063116, Gradient norm: 3.96912497
INFO:root:At the start of the epoch: mem (CPU python)=21180.875MB; mem (CPU total)=20882.640625MB
INFO:root:[   21] Training loss: 0.69234358, Validation loss: 0.62411704, Gradient norm: 4.54449015
INFO:root:At the start of the epoch: mem (CPU python)=21202.0390625MB; mem (CPU total)=20903.7734375MB
INFO:root:[   22] Training loss: 0.68706391, Validation loss: 0.62685540, Gradient norm: 4.43709180
INFO:root:At the start of the epoch: mem (CPU python)=21223.203125MB; mem (CPU total)=20925.18359375MB
INFO:root:[   23] Training loss: 0.69044266, Validation loss: 0.60797427, Gradient norm: 4.69298664
INFO:root:At the start of the epoch: mem (CPU python)=21244.3671875MB; mem (CPU total)=20946.609375MB
INFO:root:[   24] Training loss: 0.68349179, Validation loss: 0.65866167, Gradient norm: 4.64471420
INFO:root:At the start of the epoch: mem (CPU python)=21265.53125MB; mem (CPU total)=20967.5234375MB
INFO:root:[   25] Training loss: 0.68999777, Validation loss: 0.62824130, Gradient norm: 5.28015869
INFO:root:At the start of the epoch: mem (CPU python)=21286.6953125MB; mem (CPU total)=20988.67578125MB
INFO:root:[   26] Training loss: 0.68654350, Validation loss: 0.61575397, Gradient norm: 5.02018045
INFO:root:At the start of the epoch: mem (CPU python)=21307.85546875MB; mem (CPU total)=21009.83203125MB
INFO:root:[   27] Training loss: 0.68566350, Validation loss: 0.61414184, Gradient norm: 5.00346102
INFO:root:At the start of the epoch: mem (CPU python)=21329.01953125MB; mem (CPU total)=21031.23828125MB
INFO:root:[   28] Training loss: 0.68248350, Validation loss: 0.61116060, Gradient norm: 4.80325589
INFO:root:At the start of the epoch: mem (CPU python)=21350.18359375MB; mem (CPU total)=21052.40234375MB
INFO:root:[   29] Training loss: 0.67587059, Validation loss: 0.60202044, Gradient norm: 4.45201046
INFO:root:At the start of the epoch: mem (CPU python)=21371.3515625MB; mem (CPU total)=21073.578125MB
INFO:root:[   30] Training loss: 0.68466275, Validation loss: 0.60537539, Gradient norm: 5.71937370
INFO:root:At the start of the epoch: mem (CPU python)=21392.515625MB; mem (CPU total)=21094.9765625MB
INFO:root:[   31] Training loss: 0.68103771, Validation loss: 0.63424171, Gradient norm: 5.45022063
INFO:root:At the start of the epoch: mem (CPU python)=21413.6796875MB; mem (CPU total)=21116.1015625MB
INFO:root:[   32] Training loss: 0.68723377, Validation loss: 0.61276954, Gradient norm: 6.12669171
INFO:root:At the start of the epoch: mem (CPU python)=21434.84375MB; mem (CPU total)=21137.265625MB
INFO:root:[   33] Training loss: 0.67910917, Validation loss: 0.61270074, Gradient norm: 5.34830602
INFO:root:At the start of the epoch: mem (CPU python)=21456.0078125MB; mem (CPU total)=21158.67578125MB
INFO:root:[   34] Training loss: 0.68785939, Validation loss: 0.61499461, Gradient norm: 6.56790098
INFO:root:At the start of the epoch: mem (CPU python)=21477.171875MB; mem (CPU total)=21179.8203125MB
INFO:root:[   35] Training loss: 0.67912932, Validation loss: 0.60215587, Gradient norm: 5.50889284
INFO:root:At the start of the epoch: mem (CPU python)=21498.33203125MB; mem (CPU total)=21200.984375MB
INFO:root:[   36] Training loss: 0.67670711, Validation loss: 0.61085364, Gradient norm: 6.49719692
INFO:root:At the start of the epoch: mem (CPU python)=21519.5MB; mem (CPU total)=21222.1484375MB
INFO:root:[   37] Training loss: 0.67662595, Validation loss: 0.60265287, Gradient norm: 6.39762672
INFO:root:At the start of the epoch: mem (CPU python)=21540.6640625MB; mem (CPU total)=21243.25MB
INFO:root:[   38] Training loss: 0.67223365, Validation loss: 0.63105525, Gradient norm: 6.51579894
INFO:root:At the start of the epoch: mem (CPU python)=21561.828125MB; mem (CPU total)=21264.16796875MB
INFO:root:[   39] Training loss: 0.66699499, Validation loss: 0.58837366, Gradient norm: 6.13818562
INFO:root:At the start of the epoch: mem (CPU python)=21582.9921875MB; mem (CPU total)=21285.578125MB
INFO:root:[   40] Training loss: 0.66925611, Validation loss: 0.59074317, Gradient norm: 7.00506343
INFO:root:At the start of the epoch: mem (CPU python)=21604.15625MB; mem (CPU total)=21306.73046875MB
INFO:root:[   41] Training loss: 0.67006388, Validation loss: 0.61756824, Gradient norm: 6.94991728
INFO:root:At the start of the epoch: mem (CPU python)=21625.32421875MB; mem (CPU total)=21327.89453125MB
INFO:root:[   42] Training loss: 0.68032644, Validation loss: 0.59724588, Gradient norm: 8.12124218
INFO:root:At the start of the epoch: mem (CPU python)=21646.484375MB; mem (CPU total)=21349.08203125MB
INFO:root:[   43] Training loss: 0.67040962, Validation loss: 0.58653070, Gradient norm: 7.08390441
INFO:root:At the start of the epoch: mem (CPU python)=21668.45703125MB; mem (CPU total)=21371.49609375MB
INFO:root:[   44] Training loss: 0.67253943, Validation loss: 0.60126413, Gradient norm: 7.24358060
INFO:root:At the start of the epoch: mem (CPU python)=21689.9375MB; mem (CPU total)=21392.890625MB
INFO:root:[   45] Training loss: 0.66186302, Validation loss: 0.58886829, Gradient norm: 7.02359559
INFO:root:At the start of the epoch: mem (CPU python)=21711.1015625MB; mem (CPU total)=21414.05078125MB
INFO:root:[   46] Training loss: 0.66856201, Validation loss: 0.57624871, Gradient norm: 7.64560675
INFO:root:At the start of the epoch: mem (CPU python)=21732.265625MB; mem (CPU total)=21435.27734375MB
INFO:root:[   47] Training loss: 0.67908429, Validation loss: 0.59063963, Gradient norm: 8.65473242
INFO:root:At the start of the epoch: mem (CPU python)=21753.4296875MB; mem (CPU total)=21456.4375MB
INFO:root:[   48] Training loss: 0.66806153, Validation loss: 0.56655576, Gradient norm: 7.37923154
INFO:root:At the start of the epoch: mem (CPU python)=21774.59375MB; mem (CPU total)=21477.5859375MB
INFO:root:[   49] Training loss: 0.66648677, Validation loss: 0.58721039, Gradient norm: 7.61965606
INFO:root:At the start of the epoch: mem (CPU python)=21795.7578125MB; mem (CPU total)=21498.984375MB
INFO:root:[   50] Training loss: 0.67053352, Validation loss: 0.58332917, Gradient norm: 8.22009043
INFO:root:At the start of the epoch: mem (CPU python)=21816.921875MB; mem (CPU total)=21520.12109375MB
INFO:root:[   51] Training loss: 0.66876191, Validation loss: 0.59960870, Gradient norm: 7.90547028
INFO:root:At the start of the epoch: mem (CPU python)=21838.0859375MB; mem (CPU total)=21541.234375MB
INFO:root:[   52] Training loss: 0.67041655, Validation loss: 0.63253737, Gradient norm: 7.87486162
INFO:root:At the start of the epoch: mem (CPU python)=21859.25390625MB; mem (CPU total)=21562.3828125MB
INFO:root:[   53] Training loss: 0.67289745, Validation loss: 0.62838466, Gradient norm: 8.09086211
INFO:root:At the start of the epoch: mem (CPU python)=21880.41796875MB; mem (CPU total)=21583.53125MB
INFO:root:[   54] Training loss: 0.65909207, Validation loss: 0.61120804, Gradient norm: 7.16304141
INFO:root:At the start of the epoch: mem (CPU python)=21901.578125MB; mem (CPU total)=21604.9375MB
INFO:root:[   55] Training loss: 0.67617742, Validation loss: 0.57623233, Gradient norm: 8.64757758
INFO:root:At the start of the epoch: mem (CPU python)=21922.7421875MB; mem (CPU total)=21626.0703125MB
INFO:root:[   56] Training loss: 0.66652057, Validation loss: 0.59732371, Gradient norm: 7.72494040
INFO:root:At the start of the epoch: mem (CPU python)=21943.91015625MB; mem (CPU total)=21647.19921875MB
INFO:root:[   57] Training loss: 0.66436020, Validation loss: 0.56488221, Gradient norm: 7.70059010
INFO:root:At the start of the epoch: mem (CPU python)=21965.07421875MB; mem (CPU total)=21668.63671875MB
INFO:root:[   58] Training loss: 0.66035911, Validation loss: 0.56717859, Gradient norm: 7.79117427
INFO:root:At the start of the epoch: mem (CPU python)=21986.23828125MB; mem (CPU total)=21689.80078125MB
INFO:root:[   59] Training loss: 0.66319568, Validation loss: 0.57512434, Gradient norm: 8.68068316
INFO:root:At the start of the epoch: mem (CPU python)=22007.3984375MB; mem (CPU total)=21710.96484375MB
INFO:root:[   60] Training loss: 0.66708042, Validation loss: 0.58101423, Gradient norm: 8.51750470
INFO:root:At the start of the epoch: mem (CPU python)=22028.5625MB; mem (CPU total)=21737.05859375MB
INFO:root:[   61] Training loss: 0.66648529, Validation loss: 0.59156156, Gradient norm: 8.05634748
INFO:root:At the start of the epoch: mem (CPU python)=22049.7265625MB; mem (CPU total)=21757.265625MB
INFO:root:[   62] Training loss: 0.66740666, Validation loss: 0.58316173, Gradient norm: 8.31781313
INFO:root:At the start of the epoch: mem (CPU python)=22070.89453125MB; mem (CPU total)=21778.390625MB
INFO:root:[   63] Training loss: 0.65949945, Validation loss: 0.59614645, Gradient norm: 7.95451872
INFO:root:At the start of the epoch: mem (CPU python)=22092.05859375MB; mem (CPU total)=21799.546875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   64] Training loss: 0.65435894, Validation loss: 0.62173040, Gradient norm: 7.94230971
INFO:root:At the start of the epoch: mem (CPU python)=22113.21875MB; mem (CPU total)=21820.46484375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   65] Training loss: 0.62689326, Validation loss: 0.54435397, Gradient norm: 6.54078572
INFO:root:At the start of the epoch: mem (CPU python)=22134.3828125MB; mem (CPU total)=21841.4375MB
INFO:root:[   66] Training loss: 0.61278080, Validation loss: 0.53662712, Gradient norm: 5.22587411
INFO:root:At the start of the epoch: mem (CPU python)=22155.546875MB; mem (CPU total)=21862.6328125MB
INFO:root:[   67] Training loss: 0.61070477, Validation loss: 0.54105170, Gradient norm: 6.22056534
INFO:root:At the start of the epoch: mem (CPU python)=22176.7109375MB; mem (CPU total)=21884.2734375MB
INFO:root:[   68] Training loss: 0.61024724, Validation loss: 0.54174905, Gradient norm: 6.82512560
INFO:root:At the start of the epoch: mem (CPU python)=22197.87890625MB; mem (CPU total)=21905.421875MB
INFO:root:[   69] Training loss: 0.61120055, Validation loss: 0.53736108, Gradient norm: 7.81205600
INFO:root:At the start of the epoch: mem (CPU python)=22219.04296875MB; mem (CPU total)=21926.6171875MB
INFO:root:[   70] Training loss: 0.61788867, Validation loss: 0.53598833, Gradient norm: 9.63770755
INFO:root:At the start of the epoch: mem (CPU python)=22240.20703125MB; mem (CPU total)=21948.05078125MB
INFO:root:[   71] Training loss: 0.61294434, Validation loss: 0.53848005, Gradient norm: 8.49403422
INFO:root:At the start of the epoch: mem (CPU python)=22261.37109375MB; mem (CPU total)=21969.1953125MB
INFO:root:[   72] Training loss: 0.61377494, Validation loss: 0.54215608, Gradient norm: 9.31201446
INFO:root:At the start of the epoch: mem (CPU python)=22282.53515625MB; mem (CPU total)=21990.60546875MB
INFO:root:[   73] Training loss: 0.61348032, Validation loss: 0.54274710, Gradient norm: 9.76537497
INFO:root:At the start of the epoch: mem (CPU python)=22303.82421875MB; mem (CPU total)=22012.015625MB
INFO:root:[   74] Training loss: 0.61441011, Validation loss: 0.53820553, Gradient norm: 10.68309904
INFO:root:At the start of the epoch: mem (CPU python)=22324.98828125MB; mem (CPU total)=22033.390625MB
INFO:root:[   75] Training loss: 0.61464657, Validation loss: 0.54037466, Gradient norm: 11.04025097
INFO:root:At the start of the epoch: mem (CPU python)=22346.40625MB; mem (CPU total)=22054.546875MB
INFO:root:[   76] Training loss: 0.61545658, Validation loss: 0.54605474, Gradient norm: 11.89878751
INFO:root:At the start of the epoch: mem (CPU python)=22367.56640625MB; mem (CPU total)=22075.703125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 0.62038204, Validation loss: 0.54340671, Gradient norm: 12.29885196
INFO:root:At the start of the epoch: mem (CPU python)=22388.73046875MB; mem (CPU total)=22096.859375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 0.60596793, Validation loss: 0.53432113, Gradient norm: 8.03282388
INFO:root:At the start of the epoch: mem (CPU python)=22410.06640625MB; mem (CPU total)=22118.50390625MB
INFO:root:[   79] Training loss: 0.60215242, Validation loss: 0.53278368, Gradient norm: 5.62686747
INFO:root:At the start of the epoch: mem (CPU python)=22431.43359375MB; mem (CPU total)=22139.73046875MB
INFO:root:[   80] Training loss: 0.60082758, Validation loss: 0.53432240, Gradient norm: 6.79114359
INFO:root:At the start of the epoch: mem (CPU python)=22452.84765625MB; mem (CPU total)=22161.140625MB
INFO:root:[   81] Training loss: 0.60062204, Validation loss: 0.53503864, Gradient norm: 7.14034850
INFO:root:At the start of the epoch: mem (CPU python)=22474.140625MB; mem (CPU total)=22182.3046875MB
INFO:root:[   82] Training loss: 0.60077313, Validation loss: 0.53417376, Gradient norm: 7.70782052
INFO:root:At the start of the epoch: mem (CPU python)=22495.30078125MB; mem (CPU total)=22203.71484375MB
INFO:root:[   83] Training loss: 0.60070720, Validation loss: 0.53322990, Gradient norm: 8.52495237
INFO:root:At the start of the epoch: mem (CPU python)=22516.68359375MB; mem (CPU total)=22225.125MB
INFO:root:[   84] Training loss: 0.60063809, Validation loss: 0.53344335, Gradient norm: 8.99612174
INFO:root:At the start of the epoch: mem (CPU python)=22538.0078125MB; mem (CPU total)=22246.2890625MB
INFO:root:[   85] Training loss: 0.60039261, Validation loss: 0.53410414, Gradient norm: 8.93353391
INFO:root:At the start of the epoch: mem (CPU python)=22559.171875MB; mem (CPU total)=22267.44921875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   86] Training loss: 0.60060271, Validation loss: 0.53115315, Gradient norm: 9.46706265
INFO:root:At the start of the epoch: mem (CPU python)=22580.3359375MB; mem (CPU total)=22288.58984375MB
INFO:root:[   87] Training loss: 0.59885474, Validation loss: 0.53303004, Gradient norm: 5.73317405
INFO:root:At the start of the epoch: mem (CPU python)=22601.5MB; mem (CPU total)=22309.72265625MB
INFO:root:[   88] Training loss: 0.59834003, Validation loss: 0.53113034, Gradient norm: 6.47507023
INFO:root:At the start of the epoch: mem (CPU python)=22622.6640625MB; mem (CPU total)=22331.1640625MB
INFO:root:[   89] Training loss: 0.59871221, Validation loss: 0.53390771, Gradient norm: 8.61215745
INFO:root:At the start of the epoch: mem (CPU python)=22643.828125MB; mem (CPU total)=22351.95703125MB
INFO:root:[   90] Training loss: 0.59828194, Validation loss: 0.53096016, Gradient norm: 8.81197533
INFO:root:At the start of the epoch: mem (CPU python)=22664.99609375MB; mem (CPU total)=22373.14453125MB
INFO:root:[   91] Training loss: 0.59825514, Validation loss: 0.53235828, Gradient norm: 8.11106134
INFO:root:At the start of the epoch: mem (CPU python)=22686.16015625MB; mem (CPU total)=22394.65625MB
INFO:root:[   92] Training loss: 0.59878228, Validation loss: 0.53204395, Gradient norm: 11.51669491
INFO:root:At the start of the epoch: mem (CPU python)=22707.3203125MB; mem (CPU total)=22415.36328125MB
INFO:root:[   93] Training loss: 0.59820842, Validation loss: 0.53163131, Gradient norm: 9.65300134
INFO:root:At the start of the epoch: mem (CPU python)=22728.48046875MB; mem (CPU total)=22436.6796875MB
INFO:root:[   94] Training loss: 0.59775480, Validation loss: 0.53271185, Gradient norm: 8.67383684
INFO:root:At the start of the epoch: mem (CPU python)=22749.64453125MB; mem (CPU total)=22457.859375MB
INFO:root:[   95] Training loss: 0.59771153, Validation loss: 0.53345603, Gradient norm: 8.88510550
INFO:root:At the start of the epoch: mem (CPU python)=22770.8125MB; mem (CPU total)=22478.7890625MB
INFO:root:[   96] Training loss: 0.59742811, Validation loss: 0.53243338, Gradient norm: 9.18464939
INFO:root:At the start of the epoch: mem (CPU python)=22791.9765625MB; mem (CPU total)=22499.68359375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   97] Training loss: 0.59739199, Validation loss: 0.53145768, Gradient norm: 9.61539056
INFO:root:At the start of the epoch: mem (CPU python)=22813.140625MB; mem (CPU total)=22520.859375MB
INFO:root:[   98] Training loss: 0.59650501, Validation loss: 0.53171302, Gradient norm: 7.49585301
INFO:root:At the start of the epoch: mem (CPU python)=22834.3046875MB; mem (CPU total)=22542.12890625MB
INFO:root:[   99] Training loss: 0.59666139, Validation loss: 0.53110702, Gradient norm: 7.65414547
INFO:root:At the start of the epoch: mem (CPU python)=22855.46875MB; mem (CPU total)=22563.29296875MB
INFO:root:[  100] Training loss: 0.59661496, Validation loss: 0.53076723, Gradient norm: 7.89950826
INFO:root:At the start of the epoch: mem (CPU python)=22876.63671875MB; mem (CPU total)=22584.44140625MB
INFO:root:[  101] Training loss: 0.59623066, Validation loss: 0.53115318, Gradient norm: 7.97591963
INFO:root:At the start of the epoch: mem (CPU python)=22898.20703125MB; mem (CPU total)=22606.60546875MB
INFO:root:[  102] Training loss: 0.59621910, Validation loss: 0.53186063, Gradient norm: 7.27455806
INFO:root:At the start of the epoch: mem (CPU python)=22919.7109375MB; mem (CPU total)=22627.75390625MB
INFO:root:[  103] Training loss: 0.59613468, Validation loss: 0.53027267, Gradient norm: 8.58401341
INFO:root:At the start of the epoch: mem (CPU python)=22940.875MB; mem (CPU total)=22649.19140625MB
INFO:root:[  104] Training loss: 0.59589243, Validation loss: 0.53176695, Gradient norm: 9.54575403
INFO:root:At the start of the epoch: mem (CPU python)=22962.0390625MB; mem (CPU total)=22670.33984375MB
INFO:root:[  105] Training loss: 0.59580338, Validation loss: 0.53164801, Gradient norm: 8.69464978
INFO:root:At the start of the epoch: mem (CPU python)=22983.203125MB; mem (CPU total)=22691.49609375MB
INFO:root:[  106] Training loss: 0.59631608, Validation loss: 0.53026244, Gradient norm: 10.57661432
INFO:root:At the start of the epoch: mem (CPU python)=23004.37109375MB; mem (CPU total)=22712.66015625MB
INFO:root:[  107] Training loss: 0.59568456, Validation loss: 0.53036171, Gradient norm: 8.83966112
INFO:root:At the start of the epoch: mem (CPU python)=23025.734375MB; mem (CPU total)=22734.1015625MB
INFO:root:[  108] Training loss: 0.59559708, Validation loss: 0.53134173, Gradient norm: 9.68857454
INFO:root:At the start of the epoch: mem (CPU python)=23047.07421875MB; mem (CPU total)=22755.4765625MB
INFO:root:[  109] Training loss: 0.59625730, Validation loss: 0.53143383, Gradient norm: 13.35639756
INFO:root:At the start of the epoch: mem (CPU python)=23068.23828125MB; mem (CPU total)=22776.640625MB
INFO:root:[  110] Training loss: 0.59590808, Validation loss: 0.53120787, Gradient norm: 10.36951681
INFO:root:At the start of the epoch: mem (CPU python)=23089.3984375MB; mem (CPU total)=22797.8046875MB
INFO:root:[  111] Training loss: 0.59605131, Validation loss: 0.53115756, Gradient norm: 14.01707754
INFO:root:At the start of the epoch: mem (CPU python)=23110.55859375MB; mem (CPU total)=22818.96875MB
INFO:root:[  112] Training loss: 0.59562189, Validation loss: 0.53177122, Gradient norm: 10.61026042
INFO:root:At the start of the epoch: mem (CPU python)=23131.7265625MB; mem (CPU total)=22840.12109375MB
INFO:root:[  113] Training loss: 0.59574445, Validation loss: 0.53112305, Gradient norm: 14.23983186
INFO:root:At the start of the epoch: mem (CPU python)=23152.890625MB; mem (CPU total)=22861.26953125MB
INFO:root:[  114] Training loss: 0.59585279, Validation loss: 0.53119950, Gradient norm: 13.71059913
INFO:root:At the start of the epoch: mem (CPU python)=23174.0546875MB; mem (CPU total)=22882.64453125MB
INFO:root:[  115] Training loss: 0.59513562, Validation loss: 0.53149652, Gradient norm: 11.58267549
INFO:root:At the start of the epoch: mem (CPU python)=23195.75MB; mem (CPU total)=22904.53125MB
INFO:root:EP 115: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=23217.16015625MB; mem (CPU total)=22925.93359375MB
INFO:root:Training the model took 4424.961s.
INFO:root:Emptying the cuda cache took 0.037s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.72287
INFO:root:EnergyScoreValidation: 0.40007
INFO:root:CRPSValidation: 0.17989
INFO:root:Gaussian NLLValidation: 14.21826
INFO:root:CoverageValidation: 0.60645
INFO:root:IntervalWidthValidation: 0.76185
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.73013
INFO:root:EnergyScoreTest: 0.40515
INFO:root:CRPSTest: 0.18266
INFO:root:Gaussian NLLTest: 10.78851
INFO:root:CoverageTest: 0.59918
INFO:root:IntervalWidthTest: 0.76045
INFO:root:After validation: mem (CPU python)=23322.76171875MB; mem (CPU total)=23026.40234375MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=23322.765625MB; mem (CPU total)=22933.47265625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 367001600
INFO:root:After setting up the model: mem (CPU python)=23322.765625MB; mem (CPU total)=22956.94921875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=23322.765625MB; mem (CPU total)=22956.9140625MB
INFO:root:[    1] Training loss: 0.89065444, Validation loss: 0.73907437, Gradient norm: 0.32276806
INFO:root:At the start of the epoch: mem (CPU python)=23322.765625MB; mem (CPU total)=22989.52734375MB
INFO:root:[    2] Training loss: 0.76919994, Validation loss: 0.73546534, Gradient norm: 0.34410750
INFO:root:At the start of the epoch: mem (CPU python)=23322.765625MB; mem (CPU total)=23010.1171875MB
INFO:root:[    3] Training loss: 0.76278654, Validation loss: 0.74772408, Gradient norm: 0.46887921
INFO:root:At the start of the epoch: mem (CPU python)=23326.1484375MB; mem (CPU total)=23031.21875MB
INFO:root:[    4] Training loss: 0.75692556, Validation loss: 0.72046959, Gradient norm: 0.77012648
INFO:root:At the start of the epoch: mem (CPU python)=23347.3125MB; mem (CPU total)=23052.62890625MB
INFO:root:[    5] Training loss: 0.75037652, Validation loss: 0.69914053, Gradient norm: 1.16434278
INFO:root:At the start of the epoch: mem (CPU python)=23368.4765625MB; mem (CPU total)=23073.54296875MB
INFO:root:[    6] Training loss: 0.74374110, Validation loss: 0.71465143, Gradient norm: 1.72955408
INFO:root:At the start of the epoch: mem (CPU python)=23389.640625MB; mem (CPU total)=23094.70703125MB
INFO:root:[    7] Training loss: 0.73738302, Validation loss: 0.70345526, Gradient norm: 2.05835459
INFO:root:At the start of the epoch: mem (CPU python)=23410.80078125MB; mem (CPU total)=23115.80859375MB
INFO:root:[    8] Training loss: 0.73579925, Validation loss: 0.67585400, Gradient norm: 2.19310712
INFO:root:At the start of the epoch: mem (CPU python)=23431.96484375MB; mem (CPU total)=23136.97265625MB
INFO:root:[    9] Training loss: 0.72991207, Validation loss: 0.67745604, Gradient norm: 2.28451903
INFO:root:At the start of the epoch: mem (CPU python)=23453.1328125MB; mem (CPU total)=23158.34765625MB
INFO:root:[   10] Training loss: 0.72154543, Validation loss: 0.65362869, Gradient norm: 2.64923987
INFO:root:At the start of the epoch: mem (CPU python)=23474.296875MB; mem (CPU total)=23179.51171875MB
INFO:root:[   11] Training loss: 0.72239453, Validation loss: 0.66144633, Gradient norm: 2.91894973
INFO:root:At the start of the epoch: mem (CPU python)=23495.4609375MB; mem (CPU total)=23200.67578125MB
INFO:root:[   12] Training loss: 0.72819738, Validation loss: 0.65949474, Gradient norm: 3.25707653
INFO:root:At the start of the epoch: mem (CPU python)=23516.625MB; mem (CPU total)=23222.0546875MB
INFO:root:[   13] Training loss: 0.72061870, Validation loss: 0.66430212, Gradient norm: 3.08501637
INFO:root:At the start of the epoch: mem (CPU python)=23537.7890625MB; mem (CPU total)=23243.19921875MB
INFO:root:[   14] Training loss: 0.71620319, Validation loss: 0.66199127, Gradient norm: 3.42960490
INFO:root:At the start of the epoch: mem (CPU python)=23558.95703125MB; mem (CPU total)=23264.34765625MB
INFO:root:[   15] Training loss: 0.71813998, Validation loss: 0.66990904, Gradient norm: 3.77518176
INFO:root:At the start of the epoch: mem (CPU python)=23580.12109375MB; mem (CPU total)=23285.51171875MB
INFO:root:[   16] Training loss: 0.72092022, Validation loss: 0.65893861, Gradient norm: 3.87308775
INFO:root:At the start of the epoch: mem (CPU python)=23601.28125MB; mem (CPU total)=23306.640625MB
INFO:root:[   17] Training loss: 0.71387424, Validation loss: 0.64379235, Gradient norm: 3.49784135
INFO:root:At the start of the epoch: mem (CPU python)=23622.4453125MB; mem (CPU total)=23327.8203125MB
INFO:root:[   18] Training loss: 0.71524079, Validation loss: 0.65575822, Gradient norm: 4.05649810
INFO:root:At the start of the epoch: mem (CPU python)=23643.60546875MB; mem (CPU total)=23349.203125MB
INFO:root:[   19] Training loss: 0.71259595, Validation loss: 0.63730244, Gradient norm: 4.27403704
INFO:root:At the start of the epoch: mem (CPU python)=23664.7734375MB; mem (CPU total)=23370.3671875MB
INFO:root:[   20] Training loss: 0.70770199, Validation loss: 0.63757344, Gradient norm: 4.31613661
INFO:root:At the start of the epoch: mem (CPU python)=23685.9375MB; mem (CPU total)=23391.3046875MB
INFO:root:[   21] Training loss: 0.70706596, Validation loss: 0.64917042, Gradient norm: 4.48707625
INFO:root:At the start of the epoch: mem (CPU python)=23707.1015625MB; mem (CPU total)=23412.45703125MB
INFO:root:[   22] Training loss: 0.70946649, Validation loss: 0.66350101, Gradient norm: 4.85535916
INFO:root:At the start of the epoch: mem (CPU python)=23728.265625MB; mem (CPU total)=23433.59765625MB
INFO:root:[   23] Training loss: 0.70315470, Validation loss: 0.65461837, Gradient norm: 4.58844308
INFO:root:At the start of the epoch: mem (CPU python)=23749.4296875MB; mem (CPU total)=23455.0078125MB
INFO:root:[   24] Training loss: 0.70909480, Validation loss: 0.61713696, Gradient norm: 5.19800917
INFO:root:At the start of the epoch: mem (CPU python)=23770.59765625MB; mem (CPU total)=23476.40234375MB
INFO:root:[   25] Training loss: 0.70485920, Validation loss: 0.63133220, Gradient norm: 4.91849348
INFO:root:At the start of the epoch: mem (CPU python)=23791.7578125MB; mem (CPU total)=23497.28515625MB
INFO:root:[   26] Training loss: 0.69933931, Validation loss: 0.61997296, Gradient norm: 4.91758076
INFO:root:At the start of the epoch: mem (CPU python)=23812.921875MB; mem (CPU total)=23518.19140625MB
INFO:root:[   27] Training loss: 0.71292747, Validation loss: 0.63301765, Gradient norm: 5.87742329
INFO:root:At the start of the epoch: mem (CPU python)=23834.0859375MB; mem (CPU total)=23539.34375MB
INFO:root:[   28] Training loss: 0.70794316, Validation loss: 0.65181348, Gradient norm: 5.96611505
INFO:root:At the start of the epoch: mem (CPU python)=23855.25MB; mem (CPU total)=23560.50390625MB
INFO:root:[   29] Training loss: 0.71044931, Validation loss: 0.62182458, Gradient norm: 6.00134377
INFO:root:At the start of the epoch: mem (CPU python)=23876.41796875MB; mem (CPU total)=23581.890625MB
INFO:root:[   30] Training loss: 0.70865983, Validation loss: 0.63264713, Gradient norm: 5.86330337
INFO:root:At the start of the epoch: mem (CPU python)=23897.58203125MB; mem (CPU total)=23603.0546875MB
INFO:root:[   31] Training loss: 0.70840332, Validation loss: 0.63945523, Gradient norm: 6.12538590
INFO:root:At the start of the epoch: mem (CPU python)=23918.74609375MB; mem (CPU total)=23623.96875MB
INFO:root:[   32] Training loss: 0.69738759, Validation loss: 0.62114947, Gradient norm: 5.40883960
INFO:root:At the start of the epoch: mem (CPU python)=23939.91015625MB; mem (CPU total)=23645.33984375MB
INFO:root:[   33] Training loss: 0.70642869, Validation loss: 0.64246201, Gradient norm: 6.39177701
INFO:root:At the start of the epoch: mem (CPU python)=23961.07421875MB; mem (CPU total)=23666.49609375MB
INFO:root:[   34] Training loss: 0.71006394, Validation loss: 0.65878859, Gradient norm: 6.85693835
INFO:root:At the start of the epoch: mem (CPU python)=23982.234375MB; mem (CPU total)=23687.90234375MB
INFO:root:[   35] Training loss: 0.70820759, Validation loss: 0.66847271, Gradient norm: 6.84747478
INFO:root:At the start of the epoch: mem (CPU python)=24003.3984375MB; mem (CPU total)=23709.05078125MB
INFO:root:[   36] Training loss: 0.70196821, Validation loss: 0.63116753, Gradient norm: 6.29423096
INFO:root:At the start of the epoch: mem (CPU python)=24024.5625MB; mem (CPU total)=23730.21484375MB
INFO:root:[   37] Training loss: 0.70587603, Validation loss: 0.62009623, Gradient norm: 6.94141965
INFO:root:At the start of the epoch: mem (CPU python)=24045.7265625MB; mem (CPU total)=23751.37890625MB
INFO:root:[   38] Training loss: 0.71325407, Validation loss: 0.68270383, Gradient norm: 7.44484890
INFO:root:At the start of the epoch: mem (CPU python)=24066.890625MB; mem (CPU total)=23772.54296875MB
INFO:root:[   39] Training loss: 0.70721245, Validation loss: 0.62562725, Gradient norm: 7.21733587
INFO:root:At the start of the epoch: mem (CPU python)=24088.0546875MB; mem (CPU total)=23793.70703125MB
INFO:root:[   40] Training loss: 0.70538920, Validation loss: 0.62259920, Gradient norm: 7.04849715
INFO:root:At the start of the epoch: mem (CPU python)=24109.22265625MB; mem (CPU total)=23815.09765625MB
INFO:root:[   41] Training loss: 0.70814982, Validation loss: 0.60949379, Gradient norm: 7.70567104
INFO:root:At the start of the epoch: mem (CPU python)=24130.38671875MB; mem (CPU total)=23836.25390625MB
INFO:root:[   42] Training loss: 0.71290360, Validation loss: 0.66841678, Gradient norm: 8.09537831
INFO:root:At the start of the epoch: mem (CPU python)=24151.55078125MB; mem (CPU total)=23857.44921875MB
INFO:root:[   43] Training loss: 0.70799812, Validation loss: 0.62440112, Gradient norm: 7.65775277
INFO:root:At the start of the epoch: mem (CPU python)=24172.71484375MB; mem (CPU total)=23878.61328125MB
INFO:root:[   44] Training loss: 0.70892216, Validation loss: 0.64212669, Gradient norm: 8.13573854
INFO:root:At the start of the epoch: mem (CPU python)=24193.87890625MB; mem (CPU total)=23899.77734375MB
INFO:root:[   45] Training loss: 0.70592133, Validation loss: 0.64657425, Gradient norm: 7.96702394
INFO:root:At the start of the epoch: mem (CPU python)=24215.0390625MB; mem (CPU total)=23920.94140625MB
INFO:root:[   46] Training loss: 0.71061800, Validation loss: 0.61487607, Gradient norm: 7.84831047
INFO:root:At the start of the epoch: mem (CPU python)=24236.20703125MB; mem (CPU total)=23942.3515625MB
INFO:root:[   47] Training loss: 0.69913314, Validation loss: 0.60262962, Gradient norm: 7.71336854
INFO:root:At the start of the epoch: mem (CPU python)=24257.37109375MB; mem (CPU total)=23963.55859375MB
INFO:root:[   48] Training loss: 0.70816240, Validation loss: 0.59598313, Gradient norm: 8.66487564
INFO:root:At the start of the epoch: mem (CPU python)=24278.53515625MB; mem (CPU total)=23984.73828125MB
INFO:root:[   49] Training loss: 0.71216909, Validation loss: 0.61155293, Gradient norm: 8.86626941
INFO:root:At the start of the epoch: mem (CPU python)=24299.69921875MB; mem (CPU total)=24005.85546875MB
INFO:root:[   50] Training loss: 0.70172491, Validation loss: 0.64476333, Gradient norm: 8.11416528
INFO:root:At the start of the epoch: mem (CPU python)=24320.8671875MB; mem (CPU total)=24027.015625MB
INFO:root:[   51] Training loss: 0.69808987, Validation loss: 0.59995575, Gradient norm: 8.18752320
INFO:root:At the start of the epoch: mem (CPU python)=24342.02734375MB; mem (CPU total)=24048.4140625MB
INFO:root:[   52] Training loss: 0.70443167, Validation loss: 0.60983149, Gradient norm: 8.74232643
INFO:root:At the start of the epoch: mem (CPU python)=24363.19140625MB; mem (CPU total)=24069.578125MB
INFO:root:[   53] Training loss: 0.71053138, Validation loss: 0.63047498, Gradient norm: 9.52464061
INFO:root:At the start of the epoch: mem (CPU python)=24384.35546875MB; mem (CPU total)=24090.7421875MB
INFO:root:[   54] Training loss: 0.72535379, Validation loss: 0.76602446, Gradient norm: 10.11947066
INFO:root:At the start of the epoch: mem (CPU python)=24405.515625MB; mem (CPU total)=24111.65234375MB
INFO:root:[   55] Training loss: 0.71925021, Validation loss: 0.61383442, Gradient norm: 9.03497334
INFO:root:At the start of the epoch: mem (CPU python)=24426.68359375MB; mem (CPU total)=24132.81640625MB
INFO:root:[   56] Training loss: 0.69662105, Validation loss: 0.59462108, Gradient norm: 7.45585580
INFO:root:At the start of the epoch: mem (CPU python)=24447.84765625MB; mem (CPU total)=24154.2265625MB
INFO:root:[   57] Training loss: 0.71517215, Validation loss: 0.61260689, Gradient norm: 9.11333160
INFO:root:At the start of the epoch: mem (CPU python)=24469.01171875MB; mem (CPU total)=24175.63671875MB
INFO:root:[   58] Training loss: 0.70023130, Validation loss: 0.64871337, Gradient norm: 7.68809364
INFO:root:At the start of the epoch: mem (CPU python)=24490.17578125MB; mem (CPU total)=24196.80078125MB
INFO:root:[   59] Training loss: 0.70081007, Validation loss: 0.60604149, Gradient norm: 8.60885243
INFO:root:At the start of the epoch: mem (CPU python)=24511.33984375MB; mem (CPU total)=24217.96484375MB
INFO:root:[   60] Training loss: 0.70513374, Validation loss: 0.62483533, Gradient norm: 8.92049001
INFO:root:At the start of the epoch: mem (CPU python)=24532.50390625MB; mem (CPU total)=24239.12890625MB
INFO:root:[   61] Training loss: 0.70538242, Validation loss: 0.61809044, Gradient norm: 9.34592053
INFO:root:At the start of the epoch: mem (CPU python)=24553.671875MB; mem (CPU total)=24260.046875MB
INFO:root:[   62] Training loss: 0.71068832, Validation loss: 0.59984599, Gradient norm: 9.75532719
INFO:root:At the start of the epoch: mem (CPU python)=24574.8359375MB; mem (CPU total)=24281.48046875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.70233508, Validation loss: 0.64007550, Gradient norm: 8.84560489
INFO:root:At the start of the epoch: mem (CPU python)=24595.99609375MB; mem (CPU total)=24302.890625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.66732583, Validation loss: 0.58589963, Gradient norm: 7.61279284
INFO:root:At the start of the epoch: mem (CPU python)=24617.16015625MB; mem (CPU total)=24323.9921875MB
INFO:root:[   65] Training loss: 0.65254138, Validation loss: 0.57660818, Gradient norm: 6.41427699
INFO:root:At the start of the epoch: mem (CPU python)=24638.32421875MB; mem (CPU total)=24345.3828125MB
INFO:root:[   66] Training loss: 0.65195114, Validation loss: 0.57523866, Gradient norm: 8.37870559
INFO:root:At the start of the epoch: mem (CPU python)=24659.48828125MB; mem (CPU total)=24366.5703125MB
INFO:root:[   67] Training loss: 0.65385591, Validation loss: 0.57954701, Gradient norm: 8.93557367
INFO:root:At the start of the epoch: mem (CPU python)=24680.65234375MB; mem (CPU total)=24387.98046875MB
INFO:root:[   68] Training loss: 0.65366811, Validation loss: 0.57817759, Gradient norm: 10.04226929
INFO:root:At the start of the epoch: mem (CPU python)=24701.81640625MB; mem (CPU total)=24410.125MB
INFO:root:[   69] Training loss: 0.65577487, Validation loss: 0.57904570, Gradient norm: 10.48610065
INFO:root:At the start of the epoch: mem (CPU python)=24722.98046875MB; mem (CPU total)=24431.2890625MB
INFO:root:[   70] Training loss: 0.65761695, Validation loss: 0.57587035, Gradient norm: 11.06549311
INFO:root:At the start of the epoch: mem (CPU python)=24744.14453125MB; mem (CPU total)=24452.45703125MB
INFO:root:[   71] Training loss: 0.65947248, Validation loss: 0.57391736, Gradient norm: 13.30958291
INFO:root:At the start of the epoch: mem (CPU python)=24765.30859375MB; mem (CPU total)=24473.63671875MB
INFO:root:[   72] Training loss: 0.66256847, Validation loss: 0.57950585, Gradient norm: 13.75143507
INFO:root:At the start of the epoch: mem (CPU python)=24786.4765625MB; mem (CPU total)=24494.81640625MB
INFO:root:[   73] Training loss: 0.66144146, Validation loss: 0.57616243, Gradient norm: 14.00110727
INFO:root:At the start of the epoch: mem (CPU python)=24807.63671875MB; mem (CPU total)=24516.1796875MB
INFO:root:[   74] Training loss: 0.66401657, Validation loss: 0.58308656, Gradient norm: 15.61579753
INFO:root:At the start of the epoch: mem (CPU python)=24828.80078125MB; mem (CPU total)=24537.34375MB
INFO:root:[   75] Training loss: 0.66332409, Validation loss: 0.58667496, Gradient norm: 15.64566676
INFO:root:At the start of the epoch: mem (CPU python)=24849.96484375MB; mem (CPU total)=24558.4765625MB
INFO:root:[   76] Training loss: 0.66767919, Validation loss: 0.58971803, Gradient norm: 17.39497017
INFO:root:At the start of the epoch: mem (CPU python)=24871.12890625MB; mem (CPU total)=24579.640625MB
INFO:root:[   77] Training loss: 0.66553775, Validation loss: 0.58403884, Gradient norm: 17.28458020
INFO:root:At the start of the epoch: mem (CPU python)=24892.29296875MB; mem (CPU total)=24600.890625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   78] Training loss: 0.66883565, Validation loss: 0.59115298, Gradient norm: 18.91571937
INFO:root:At the start of the epoch: mem (CPU python)=24913.45703125MB; mem (CPU total)=24622.30078125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   79] Training loss: 0.65240934, Validation loss: 0.57070701, Gradient norm: 12.75932513
INFO:root:At the start of the epoch: mem (CPU python)=24934.625MB; mem (CPU total)=24643.7265625MB
INFO:root:[   80] Training loss: 0.64438743, Validation loss: 0.56947506, Gradient norm: 8.03355379
INFO:root:At the start of the epoch: mem (CPU python)=24955.7890625MB; mem (CPU total)=24664.87109375MB
INFO:root:[   81] Training loss: 0.64374270, Validation loss: 0.56879615, Gradient norm: 10.94716685
INFO:root:At the start of the epoch: mem (CPU python)=24976.953125MB; mem (CPU total)=24686.06640625MB
INFO:root:[   82] Training loss: 0.64338903, Validation loss: 0.56804783, Gradient norm: 11.10663807
INFO:root:At the start of the epoch: mem (CPU python)=24998.11328125MB; mem (CPU total)=24707.26171875MB
INFO:root:[   83] Training loss: 0.64354943, Validation loss: 0.56689808, Gradient norm: 12.36838528
INFO:root:At the start of the epoch: mem (CPU python)=25019.28125MB; mem (CPU total)=24728.42578125MB
INFO:root:[   84] Training loss: 0.64315962, Validation loss: 0.56598619, Gradient norm: 12.23649267
INFO:root:At the start of the epoch: mem (CPU python)=25040.4453125MB; mem (CPU total)=24749.09765625MB
INFO:root:[   85] Training loss: 0.64350794, Validation loss: 0.56744159, Gradient norm: 12.85715275
INFO:root:At the start of the epoch: mem (CPU python)=25061.60546875MB; mem (CPU total)=24770.26171875MB
INFO:root:[   86] Training loss: 0.64351951, Validation loss: 0.57295370, Gradient norm: 13.49082115
INFO:root:At the start of the epoch: mem (CPU python)=25082.76953125MB; mem (CPU total)=24791.421875MB
INFO:root:[   87] Training loss: 0.64522690, Validation loss: 0.56635777, Gradient norm: 15.86392153
INFO:root:At the start of the epoch: mem (CPU python)=25103.93359375MB; mem (CPU total)=24812.81640625MB
INFO:root:[   88] Training loss: 0.64350081, Validation loss: 0.56571729, Gradient norm: 14.30149165
INFO:root:At the start of the epoch: mem (CPU python)=25125.09765625MB; mem (CPU total)=24833.9375MB
INFO:root:[   89] Training loss: 0.64312019, Validation loss: 0.56425583, Gradient norm: 15.03702102
INFO:root:At the start of the epoch: mem (CPU python)=25146.26171875MB; mem (CPU total)=24855.0703125MB
INFO:root:[   90] Training loss: 0.64329633, Validation loss: 0.56427336, Gradient norm: 16.15208915
INFO:root:At the start of the epoch: mem (CPU python)=25167.42578125MB; mem (CPU total)=24876.234375MB
INFO:root:[   91] Training loss: 0.64248393, Validation loss: 0.56329118, Gradient norm: 16.04488291
INFO:root:At the start of the epoch: mem (CPU python)=25188.59375MB; mem (CPU total)=24897.6640625MB
INFO:root:[   92] Training loss: 0.64259319, Validation loss: 0.56640868, Gradient norm: 16.36195768
INFO:root:At the start of the epoch: mem (CPU python)=25209.75390625MB; mem (CPU total)=24919.09765625MB
INFO:root:[   93] Training loss: 0.64247002, Validation loss: 0.56104023, Gradient norm: 16.51814884
INFO:root:At the start of the epoch: mem (CPU python)=25230.91796875MB; mem (CPU total)=24940.26171875MB
INFO:root:[   94] Training loss: 0.64195214, Validation loss: 0.56205254, Gradient norm: 19.09194265
INFO:root:At the start of the epoch: mem (CPU python)=25252.08203125MB; mem (CPU total)=24961.44921875MB
INFO:root:[   95] Training loss: 0.64121852, Validation loss: 0.56744510, Gradient norm: 18.13945849
INFO:root:At the start of the epoch: mem (CPU python)=25273.24609375MB; mem (CPU total)=24982.61328125MB
INFO:root:[   96] Training loss: 0.64185782, Validation loss: 0.56316766, Gradient norm: 18.99192612
INFO:root:At the start of the epoch: mem (CPU python)=25294.4140625MB; mem (CPU total)=25003.77734375MB
INFO:root:[   97] Training loss: 0.64131762, Validation loss: 0.56326583, Gradient norm: 19.67107343
INFO:root:At the start of the epoch: mem (CPU python)=25315.578125MB; mem (CPU total)=25025.1875MB
INFO:root:[   98] Training loss: 0.64032173, Validation loss: 0.56042431, Gradient norm: 18.71604954
INFO:root:At the start of the epoch: mem (CPU python)=25336.7421875MB; mem (CPU total)=25046.62890625MB
INFO:root:[   99] Training loss: 0.64214353, Validation loss: 0.55687353, Gradient norm: 21.80749941
INFO:root:At the start of the epoch: mem (CPU python)=25357.90625MB; mem (CPU total)=25067.82421875MB
INFO:root:[  100] Training loss: 0.64143887, Validation loss: 0.55869168, Gradient norm: 21.76359889
INFO:root:At the start of the epoch: mem (CPU python)=25379.0703125MB; mem (CPU total)=25088.98828125MB
INFO:root:[  101] Training loss: 0.64013937, Validation loss: 0.55792243, Gradient norm: 20.75433889
INFO:root:At the start of the epoch: mem (CPU python)=25400.23046875MB; mem (CPU total)=25110.3984375MB
INFO:root:[  102] Training loss: 0.64070971, Validation loss: 0.55744783, Gradient norm: 21.58504073
INFO:root:At the start of the epoch: mem (CPU python)=25421.39453125MB; mem (CPU total)=25131.30859375MB
INFO:root:[  103] Training loss: 0.64095324, Validation loss: 0.55734623, Gradient norm: 23.37117234
INFO:root:At the start of the epoch: mem (CPU python)=25442.55859375MB; mem (CPU total)=25152.2109375MB
INFO:root:[  104] Training loss: 0.64252504, Validation loss: 0.55724457, Gradient norm: 23.36062674
INFO:root:At the start of the epoch: mem (CPU python)=25463.72265625MB; mem (CPU total)=25173.359375MB
INFO:root:[  105] Training loss: 0.64153434, Validation loss: 0.55988670, Gradient norm: 23.59129659
INFO:root:At the start of the epoch: mem (CPU python)=25484.88671875MB; mem (CPU total)=25194.44921875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  106] Training loss: 0.64113702, Validation loss: 0.55654815, Gradient norm: 24.30080915
INFO:root:At the start of the epoch: mem (CPU python)=25506.0546875MB; mem (CPU total)=25215.6171875MB
INFO:root:[  107] Training loss: 0.63642864, Validation loss: 0.55588915, Gradient norm: 14.48432225
INFO:root:At the start of the epoch: mem (CPU python)=25527.21875MB; mem (CPU total)=25236.8125MB
INFO:root:[  108] Training loss: 0.63596942, Validation loss: 0.55456513, Gradient norm: 17.12652412
INFO:root:At the start of the epoch: mem (CPU python)=25548.3828125MB; mem (CPU total)=25257.96484375MB
INFO:root:[  109] Training loss: 0.63513150, Validation loss: 0.55547775, Gradient norm: 19.36821268
INFO:root:At the start of the epoch: mem (CPU python)=25569.546875MB; mem (CPU total)=25279.375MB
INFO:root:[  110] Training loss: 0.63490435, Validation loss: 0.55339245, Gradient norm: 19.13621410
INFO:root:At the start of the epoch: mem (CPU python)=25590.7109375MB; mem (CPU total)=25300.28515625MB
INFO:root:[  111] Training loss: 0.63481794, Validation loss: 0.55385899, Gradient norm: 20.04609472
INFO:root:At the start of the epoch: mem (CPU python)=25611.87109375MB; mem (CPU total)=25321.44921875MB
INFO:root:[  112] Training loss: 0.63535660, Validation loss: 0.55303786, Gradient norm: 20.56942424
INFO:root:At the start of the epoch: mem (CPU python)=25633.0390625MB; mem (CPU total)=25342.8984375MB
INFO:root:[  113] Training loss: 0.63527403, Validation loss: 0.55211370, Gradient norm: 20.68254894
INFO:root:At the start of the epoch: mem (CPU python)=25654.203125MB; mem (CPU total)=25364.0859375MB
INFO:root:[  114] Training loss: 0.63568845, Validation loss: 0.55368074, Gradient norm: 21.89085145
INFO:root:At the start of the epoch: mem (CPU python)=25675.3671875MB; mem (CPU total)=25385.2109375MB
INFO:root:[  115] Training loss: 0.63521064, Validation loss: 0.55448479, Gradient norm: 21.57400042
INFO:root:At the start of the epoch: mem (CPU python)=25696.53125MB; mem (CPU total)=25406.34375MB
INFO:root:[  116] Training loss: 0.63506539, Validation loss: 0.55313395, Gradient norm: 22.33242694
INFO:root:At the start of the epoch: mem (CPU python)=25717.6953125MB; mem (CPU total)=25427.5078125MB
INFO:root:[  117] Training loss: 0.63506708, Validation loss: 0.55242067, Gradient norm: 23.29881929
INFO:root:At the start of the epoch: mem (CPU python)=25738.86328125MB; mem (CPU total)=25448.91796875MB
INFO:root:[  118] Training loss: 0.63491866, Validation loss: 0.55457136, Gradient norm: 22.88979289
INFO:root:At the start of the epoch: mem (CPU python)=25760.02734375MB; mem (CPU total)=25469.8359375MB
INFO:root:[  119] Training loss: 0.63496652, Validation loss: 0.55504417, Gradient norm: 24.23384842
INFO:root:At the start of the epoch: mem (CPU python)=25781.1875MB; mem (CPU total)=25490.9921875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  120] Training loss: 0.63496199, Validation loss: 0.55117369, Gradient norm: 24.03090432
INFO:root:At the start of the epoch: mem (CPU python)=25802.34765625MB; mem (CPU total)=25512.46875MB
INFO:root:[  121] Training loss: 0.63298932, Validation loss: 0.55354411, Gradient norm: 14.86162804
INFO:root:At the start of the epoch: mem (CPU python)=25823.51171875MB; mem (CPU total)=25533.60546875MB
INFO:root:[  122] Training loss: 0.63202149, Validation loss: 0.55301126, Gradient norm: 15.92694346
INFO:root:At the start of the epoch: mem (CPU python)=25844.6796875MB; mem (CPU total)=25554.75390625MB
INFO:root:[  123] Training loss: 0.63183283, Validation loss: 0.55234136, Gradient norm: 16.27480514
INFO:root:At the start of the epoch: mem (CPU python)=25865.83984375MB; mem (CPU total)=25576.15234375MB
INFO:root:[  124] Training loss: 0.63226235, Validation loss: 0.55062127, Gradient norm: 21.58085059
INFO:root:At the start of the epoch: mem (CPU python)=25887.0078125MB; mem (CPU total)=25597.0859375MB
INFO:root:[  125] Training loss: 0.63251862, Validation loss: 0.55109820, Gradient norm: 21.88595023
INFO:root:At the start of the epoch: mem (CPU python)=25908.171875MB; mem (CPU total)=25618.23828125MB
INFO:root:[  126] Training loss: 0.63205282, Validation loss: 0.55128245, Gradient norm: 17.31276780
INFO:root:At the start of the epoch: mem (CPU python)=25929.3359375MB; mem (CPU total)=25639.3984375MB
INFO:root:[  127] Training loss: 0.63170914, Validation loss: 0.55063997, Gradient norm: 17.86047223
INFO:root:At the start of the epoch: mem (CPU python)=25950.50390625MB; mem (CPU total)=25660.25390625MB
INFO:root:[  128] Training loss: 0.63182239, Validation loss: 0.55152890, Gradient norm: 19.11162987
INFO:root:At the start of the epoch: mem (CPU python)=25971.6640625MB; mem (CPU total)=25681.66015625MB
INFO:root:[  129] Training loss: 0.63170421, Validation loss: 0.55008811, Gradient norm: 20.70459694
INFO:root:At the start of the epoch: mem (CPU python)=25992.828125MB; mem (CPU total)=25702.85546875MB
INFO:root:[  130] Training loss: 0.63154324, Validation loss: 0.55075180, Gradient norm: 19.84698645
INFO:root:At the start of the epoch: mem (CPU python)=26013.9921875MB; mem (CPU total)=25724.01953125MB
INFO:root:[  131] Training loss: 0.63126554, Validation loss: 0.55074216, Gradient norm: 20.44622169
INFO:root:At the start of the epoch: mem (CPU python)=26035.15625MB; mem (CPU total)=25745.4296875MB
INFO:root:[  132] Training loss: 0.63145401, Validation loss: 0.55240399, Gradient norm: 20.80760100
INFO:root:At the start of the epoch: mem (CPU python)=26056.3203125MB; mem (CPU total)=25766.34765625MB
INFO:root:[  133] Training loss: 0.63081737, Validation loss: 0.55338867, Gradient norm: 21.74693803
INFO:root:At the start of the epoch: mem (CPU python)=26077.484375MB; mem (CPU total)=25787.70703125MB
INFO:root:[  134] Training loss: 0.63099762, Validation loss: 0.55182641, Gradient norm: 22.56128519
INFO:root:At the start of the epoch: mem (CPU python)=26098.65234375MB; mem (CPU total)=25809.125MB
INFO:root:[  135] Training loss: 0.63059681, Validation loss: 0.55153814, Gradient norm: 21.04265420
INFO:root:At the start of the epoch: mem (CPU python)=26119.81640625MB; mem (CPU total)=25830.71484375MB
INFO:root:[  136] Training loss: 0.63033738, Validation loss: 0.55145979, Gradient norm: 22.05104899
INFO:root:At the start of the epoch: mem (CPU python)=26140.9765625MB; mem (CPU total)=25851.44140625MB
INFO:root:[  137] Training loss: 0.63003406, Validation loss: 0.55108850, Gradient norm: 23.57822989
INFO:root:At the start of the epoch: mem (CPU python)=26162.140625MB; mem (CPU total)=25872.36328125MB
INFO:root:[  138] Training loss: 0.63005247, Validation loss: 0.55046028, Gradient norm: 23.49426740
INFO:root:At the start of the epoch: mem (CPU python)=26183.3046875MB; mem (CPU total)=25893.76171875MB
INFO:root:EP 138: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=26204.46875MB; mem (CPU total)=25914.91796875MB
INFO:root:Training the model took 5642.309s.
INFO:root:Emptying the cuda cache took 0.037s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 1.26627
INFO:root:EnergyScoreValidation: 0.65393
INFO:root:CRPSValidation: 0.29131
INFO:root:Gaussian NLLValidation: 4.95312
INFO:root:CoverageValidation: 0.6887
INFO:root:IntervalWidthValidation: 1.73908
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 1.336
INFO:root:EnergyScoreTest: 0.7001
INFO:root:CRPSTest: 0.31196
INFO:root:Gaussian NLLTest: 5.89727
INFO:root:CoverageTest: 0.6704
INFO:root:IntervalWidthTest: 1.75984
INFO:root:After validation: mem (CPU python)=26292.86328125MB; mem (CPU total)=26003.82421875MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.3, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=26292.86328125MB; mem (CPU total)=25909.0859375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 367001600
INFO:root:After setting up the model: mem (CPU python)=26292.86328125MB; mem (CPU total)=25932.5625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=26292.86328125MB; mem (CPU total)=25932.55859375MB
INFO:root:[    1] Training loss: 0.91148850, Validation loss: 0.73473286, Gradient norm: 0.34498457
INFO:root:At the start of the epoch: mem (CPU python)=26292.86328125MB; mem (CPU total)=25964.890625MB
INFO:root:[    2] Training loss: 0.77815914, Validation loss: 0.73239211, Gradient norm: 0.24230703
INFO:root:At the start of the epoch: mem (CPU python)=26292.86328125MB; mem (CPU total)=25985.09765625MB
INFO:root:[    3] Training loss: 0.77082927, Validation loss: 0.72547150, Gradient norm: 0.34371216
INFO:root:At the start of the epoch: mem (CPU python)=26296.19140625MB; mem (CPU total)=26006.00390625MB
INFO:root:[    4] Training loss: 0.76671198, Validation loss: 0.72459923, Gradient norm: 0.64858570
INFO:root:At the start of the epoch: mem (CPU python)=26317.35546875MB; mem (CPU total)=26027.43359375MB
INFO:root:[    5] Training loss: 0.76850106, Validation loss: 0.74010040, Gradient norm: 1.12769630
INFO:root:At the start of the epoch: mem (CPU python)=26338.51953125MB; mem (CPU total)=26048.90234375MB
INFO:root:[    6] Training loss: 0.76668486, Validation loss: 0.71786736, Gradient norm: 1.62925138
INFO:root:At the start of the epoch: mem (CPU python)=26359.68359375MB; mem (CPU total)=26070.05859375MB
INFO:root:[    7] Training loss: 0.76338298, Validation loss: 0.69650025, Gradient norm: 1.79745885
INFO:root:At the start of the epoch: mem (CPU python)=26380.84765625MB; mem (CPU total)=26090.94140625MB
INFO:root:[    8] Training loss: 0.75991610, Validation loss: 0.69083948, Gradient norm: 2.33217916
INFO:root:At the start of the epoch: mem (CPU python)=26402.01171875MB; mem (CPU total)=26111.625MB
INFO:root:[    9] Training loss: 0.75151576, Validation loss: 0.68139655, Gradient norm: 2.45351194
INFO:root:At the start of the epoch: mem (CPU python)=26423.1796875MB; mem (CPU total)=26133.04296875MB
INFO:root:[   10] Training loss: 0.75593614, Validation loss: 0.69390128, Gradient norm: 2.97025219
INFO:root:At the start of the epoch: mem (CPU python)=26444.34375MB; mem (CPU total)=26154.21484375MB
INFO:root:[   11] Training loss: 0.75220152, Validation loss: 0.67736697, Gradient norm: 3.09192230
INFO:root:At the start of the epoch: mem (CPU python)=26465.50390625MB; mem (CPU total)=26175.59375MB
INFO:root:[   12] Training loss: 0.74829983, Validation loss: 0.67253632, Gradient norm: 3.26412043
INFO:root:At the start of the epoch: mem (CPU python)=26486.671875MB; mem (CPU total)=26196.7734375MB
INFO:root:[   13] Training loss: 0.75331531, Validation loss: 0.69165129, Gradient norm: 3.82214985
INFO:root:At the start of the epoch: mem (CPU python)=26507.83203125MB; mem (CPU total)=26217.9453125MB
INFO:root:[   14] Training loss: 0.75315368, Validation loss: 0.66341185, Gradient norm: 3.73650074
INFO:root:At the start of the epoch: mem (CPU python)=26529.0078125MB; mem (CPU total)=26239.09375MB
INFO:root:[   15] Training loss: 0.75507281, Validation loss: 0.67780988, Gradient norm: 4.36686536
INFO:root:At the start of the epoch: mem (CPU python)=26550.171875MB; mem (CPU total)=26260.30859375MB
INFO:root:[   16] Training loss: 0.74704015, Validation loss: 0.70877639, Gradient norm: 4.15609678
INFO:root:At the start of the epoch: mem (CPU python)=26571.3359375MB; mem (CPU total)=26281.48828125MB
INFO:root:[   17] Training loss: 0.75090858, Validation loss: 0.67922622, Gradient norm: 4.66463144
INFO:root:At the start of the epoch: mem (CPU python)=26592.5MB; mem (CPU total)=26302.66796875MB
INFO:root:[   18] Training loss: 0.74272896, Validation loss: 0.63723362, Gradient norm: 4.27487344
INFO:root:At the start of the epoch: mem (CPU python)=26613.66796875MB; mem (CPU total)=26324.09375MB
INFO:root:[   19] Training loss: 0.74778423, Validation loss: 0.64322915, Gradient norm: 4.72168252
INFO:root:At the start of the epoch: mem (CPU python)=26634.83203125MB; mem (CPU total)=26345.2734375MB
INFO:root:[   20] Training loss: 0.74758791, Validation loss: 0.67257425, Gradient norm: 5.08829923
INFO:root:At the start of the epoch: mem (CPU python)=26655.9921875MB; mem (CPU total)=26366.8359375MB
INFO:root:[   21] Training loss: 0.74697577, Validation loss: 0.65304911, Gradient norm: 5.10446186
INFO:root:At the start of the epoch: mem (CPU python)=26677.15234375MB; mem (CPU total)=26387.625MB
INFO:root:[   22] Training loss: 0.73764408, Validation loss: 0.66428256, Gradient norm: 4.50855351
INFO:root:At the start of the epoch: mem (CPU python)=26698.31640625MB; mem (CPU total)=26409.0390625MB
INFO:root:[   23] Training loss: 0.73456356, Validation loss: 0.64637489, Gradient norm: 4.85278000
INFO:root:At the start of the epoch: mem (CPU python)=26719.484375MB; mem (CPU total)=26429.95703125MB
INFO:root:[   24] Training loss: 0.74849005, Validation loss: 0.72589003, Gradient norm: 6.04686321
INFO:root:At the start of the epoch: mem (CPU python)=26740.6484375MB; mem (CPU total)=26451.37890625MB
INFO:root:[   25] Training loss: 0.74410365, Validation loss: 0.63312023, Gradient norm: 5.47359103
INFO:root:At the start of the epoch: mem (CPU python)=26761.8125MB; mem (CPU total)=26472.515625MB
INFO:root:[   26] Training loss: 0.73074679, Validation loss: 0.64052357, Gradient norm: 5.20179481
INFO:root:At the start of the epoch: mem (CPU python)=26782.9765625MB; mem (CPU total)=26493.4453125MB
INFO:root:[   27] Training loss: 0.73373735, Validation loss: 0.64109674, Gradient norm: 5.92229216
INFO:root:At the start of the epoch: mem (CPU python)=26804.140625MB; mem (CPU total)=26514.84765625MB
INFO:root:[   28] Training loss: 0.75781564, Validation loss: 0.68251212, Gradient norm: 7.43091949
INFO:root:At the start of the epoch: mem (CPU python)=26825.30859375MB; mem (CPU total)=26535.8046875MB
INFO:root:[   29] Training loss: 0.75084989, Validation loss: 0.66690281, Gradient norm: 6.52659570
INFO:root:At the start of the epoch: mem (CPU python)=26846.47265625MB; mem (CPU total)=26557.46875MB
INFO:root:[   30] Training loss: 0.75059597, Validation loss: 0.65947765, Gradient norm: 6.49056266
INFO:root:At the start of the epoch: mem (CPU python)=26867.6328125MB; mem (CPU total)=26578.640625MB
INFO:root:[   31] Training loss: 0.73785268, Validation loss: 0.68725109, Gradient norm: 5.82170964
INFO:root:At the start of the epoch: mem (CPU python)=26888.796875MB; mem (CPU total)=26599.76171875MB
INFO:root:[   32] Training loss: 0.74077452, Validation loss: 0.65042101, Gradient norm: 6.25577027
INFO:root:At the start of the epoch: mem (CPU python)=26909.9609375MB; mem (CPU total)=26620.625MB
INFO:root:[   33] Training loss: 0.74340401, Validation loss: 0.63387565, Gradient norm: 6.41415731
INFO:root:At the start of the epoch: mem (CPU python)=26931.125MB; mem (CPU total)=26641.76171875MB
INFO:root:[   34] Training loss: 0.73456092, Validation loss: 0.62319334, Gradient norm: 6.03246941
INFO:root:At the start of the epoch: mem (CPU python)=26952.29296875MB; mem (CPU total)=26663.42578125MB
INFO:root:[   35] Training loss: 0.74138759, Validation loss: 0.64559366, Gradient norm: 7.12502057
INFO:root:At the start of the epoch: mem (CPU python)=26973.45703125MB; mem (CPU total)=26685.11328125MB
INFO:root:[   36] Training loss: 0.75545634, Validation loss: 0.62813429, Gradient norm: 7.88979650
INFO:root:At the start of the epoch: mem (CPU python)=26994.62109375MB; mem (CPU total)=26705.8125MB
INFO:root:[   37] Training loss: 0.74124387, Validation loss: 0.65243206, Gradient norm: 7.15663785
INFO:root:At the start of the epoch: mem (CPU python)=27015.78125MB; mem (CPU total)=26726.98828125MB
INFO:root:[   38] Training loss: 0.76013094, Validation loss: 0.69335768, Gradient norm: 8.00812062
INFO:root:At the start of the epoch: mem (CPU python)=27036.9453125MB; mem (CPU total)=26748.16015625MB
INFO:root:[   39] Training loss: 0.75326395, Validation loss: 0.64700429, Gradient norm: 7.45825490
INFO:root:At the start of the epoch: mem (CPU python)=27058.10546875MB; mem (CPU total)=26769.07421875MB
INFO:root:[   40] Training loss: 0.74463423, Validation loss: 0.64104271, Gradient norm: 6.92029945
INFO:root:At the start of the epoch: mem (CPU python)=27079.26953125MB; mem (CPU total)=26790.86328125MB
INFO:root:[   41] Training loss: 0.75201775, Validation loss: 0.63872123, Gradient norm: 7.41105698
INFO:root:At the start of the epoch: mem (CPU python)=27100.4375MB; mem (CPU total)=26811.578125MB
INFO:root:[   42] Training loss: 0.75233032, Validation loss: 0.66022016, Gradient norm: 7.64143747
INFO:root:At the start of the epoch: mem (CPU python)=27121.6015625MB; mem (CPU total)=26832.7578125MB
INFO:root:[   43] Training loss: 0.74316294, Validation loss: 0.63478926, Gradient norm: 7.52296106
INFO:root:At the start of the epoch: mem (CPU python)=27142.765625MB; mem (CPU total)=26853.6796875MB
INFO:root:[   44] Training loss: 0.74066082, Validation loss: 0.70371163, Gradient norm: 8.21705659
INFO:root:At the start of the epoch: mem (CPU python)=27163.9296875MB; mem (CPU total)=26874.85546875MB
INFO:root:[   45] Training loss: 0.76259123, Validation loss: 0.66926990, Gradient norm: 9.38289124
INFO:root:At the start of the epoch: mem (CPU python)=27185.09375MB; mem (CPU total)=26895.421875MB
INFO:root:[   46] Training loss: 0.76792142, Validation loss: 0.66516426, Gradient norm: 9.38528148
INFO:root:At the start of the epoch: mem (CPU python)=27206.26171875MB; mem (CPU total)=26916.83984375MB
INFO:root:[   47] Training loss: 0.75935429, Validation loss: 0.63247041, Gradient norm: 8.32421852
INFO:root:At the start of the epoch: mem (CPU python)=27227.42578125MB; mem (CPU total)=26938.0MB
INFO:root:[   48] Training loss: 0.75848905, Validation loss: 0.69143658, Gradient norm: 9.33872752
INFO:root:At the start of the epoch: mem (CPU python)=27248.58984375MB; mem (CPU total)=26959.16015625MB
INFO:root:[   49] Training loss: 0.76932179, Validation loss: 0.69181667, Gradient norm: 10.03610838
INFO:root:At the start of the epoch: mem (CPU python)=27269.75MB; mem (CPU total)=26980.3359375MB
INFO:root:[   50] Training loss: 0.76344130, Validation loss: 0.65024609, Gradient norm: 9.63572856
INFO:root:At the start of the epoch: mem (CPU python)=27290.9140625MB; mem (CPU total)=27001.49609375MB
INFO:root:[   51] Training loss: 0.78042457, Validation loss: 0.66145934, Gradient norm: 9.97954731
INFO:root:At the start of the epoch: mem (CPU python)=27312.078125MB; mem (CPU total)=27022.6640625MB
INFO:root:[   52] Training loss: 0.75973184, Validation loss: 0.62852535, Gradient norm: 8.92122345
INFO:root:At the start of the epoch: mem (CPU python)=27333.24609375MB; mem (CPU total)=27044.08984375MB
INFO:root:[   53] Training loss: 0.76285753, Validation loss: 0.66360564, Gradient norm: 9.27756737
INFO:root:At the start of the epoch: mem (CPU python)=27354.41015625MB; mem (CPU total)=27065.5078125MB
INFO:root:[   54] Training loss: 0.77977276, Validation loss: 0.68125019, Gradient norm: 10.69153570
INFO:root:At the start of the epoch: mem (CPU python)=27375.5703125MB; mem (CPU total)=27086.8125MB
INFO:root:[   55] Training loss: 0.76608387, Validation loss: 0.68871323, Gradient norm: 9.42924521
INFO:root:At the start of the epoch: mem (CPU python)=27396.734375MB; mem (CPU total)=27107.58984375MB
INFO:root:[   56] Training loss: 0.76707048, Validation loss: 0.62270690, Gradient norm: 9.53816323
INFO:root:At the start of the epoch: mem (CPU python)=27417.8984375MB; mem (CPU total)=27128.80859375MB
INFO:root:[   57] Training loss: 0.78210426, Validation loss: 0.65288147, Gradient norm: 11.22020365
INFO:root:At the start of the epoch: mem (CPU python)=27439.0625MB; mem (CPU total)=27150.2109375MB
INFO:root:[   58] Training loss: 0.78099681, Validation loss: 0.68085645, Gradient norm: 11.31887097
INFO:root:At the start of the epoch: mem (CPU python)=27460.2265625MB; mem (CPU total)=27171.11328125MB
INFO:root:[   59] Training loss: 0.76857218, Validation loss: 0.65496276, Gradient norm: 11.34376065
INFO:root:At the start of the epoch: mem (CPU python)=27481.390625MB; mem (CPU total)=27192.27734375MB
INFO:root:[   60] Training loss: 0.77795575, Validation loss: 0.70757011, Gradient norm: 12.08286083
INFO:root:At the start of the epoch: mem (CPU python)=27502.5546875MB; mem (CPU total)=27213.6875MB
INFO:root:[   61] Training loss: 0.79005164, Validation loss: 0.70421045, Gradient norm: 13.28928741
INFO:root:At the start of the epoch: mem (CPU python)=27523.71875MB; mem (CPU total)=27234.86328125MB
INFO:root:[   62] Training loss: 0.79723733, Validation loss: 0.71056243, Gradient norm: 13.65221647
INFO:root:At the start of the epoch: mem (CPU python)=27544.88671875MB; mem (CPU total)=27256.04296875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.78632173, Validation loss: 0.74270381, Gradient norm: 13.12052029
INFO:root:At the start of the epoch: mem (CPU python)=27566.05078125MB; mem (CPU total)=27277.41015625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.73397934, Validation loss: 0.62528948, Gradient norm: 11.80960075
INFO:root:At the start of the epoch: mem (CPU python)=27587.21484375MB; mem (CPU total)=27298.76171875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   65] Training loss: 0.72084791, Validation loss: 0.60271163, Gradient norm: 12.20517772
INFO:root:At the start of the epoch: mem (CPU python)=27608.37890625MB; mem (CPU total)=27319.984375MB
INFO:root:[   66] Training loss: 0.69589502, Validation loss: 0.60730552, Gradient norm: 6.96025984
INFO:root:At the start of the epoch: mem (CPU python)=27629.54296875MB; mem (CPU total)=27340.93359375MB
INFO:root:[   67] Training loss: 0.69397064, Validation loss: 0.59790730, Gradient norm: 10.44946284
INFO:root:At the start of the epoch: mem (CPU python)=27650.7109375MB; mem (CPU total)=27362.1171875MB
INFO:root:[   68] Training loss: 0.69441394, Validation loss: 0.60070043, Gradient norm: 11.05989618
INFO:root:At the start of the epoch: mem (CPU python)=27671.8671875MB; mem (CPU total)=27383.44921875MB
INFO:root:[   69] Training loss: 0.69448044, Validation loss: 0.60099700, Gradient norm: 12.49272707
INFO:root:At the start of the epoch: mem (CPU python)=27693.03515625MB; mem (CPU total)=27404.39453125MB
INFO:root:[   70] Training loss: 0.69562761, Validation loss: 0.60051610, Gradient norm: 13.41202256
INFO:root:At the start of the epoch: mem (CPU python)=27714.19921875MB; mem (CPU total)=27425.53125MB
INFO:root:[   71] Training loss: 0.69684612, Validation loss: 0.60094117, Gradient norm: 13.43525996
INFO:root:At the start of the epoch: mem (CPU python)=27735.359375MB; mem (CPU total)=27446.67578125MB
INFO:root:[   72] Training loss: 0.69675465, Validation loss: 0.60102706, Gradient norm: 15.33212278
INFO:root:At the start of the epoch: mem (CPU python)=27756.52734375MB; mem (CPU total)=27467.78515625MB
INFO:root:[   73] Training loss: 0.69738410, Validation loss: 0.60943911, Gradient norm: 14.61030576
INFO:root:At the start of the epoch: mem (CPU python)=27777.69140625MB; mem (CPU total)=27488.921875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   74] Training loss: 0.69788048, Validation loss: 0.60577333, Gradient norm: 15.48491374
INFO:root:At the start of the epoch: mem (CPU python)=27798.85546875MB; mem (CPU total)=27510.2578125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   75] Training loss: 0.69072857, Validation loss: 0.60183436, Gradient norm: 10.44329430
INFO:root:At the start of the epoch: mem (CPU python)=27820.01953125MB; mem (CPU total)=27531.6640625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   76] Training loss: 0.68716874, Validation loss: 0.59813015, Gradient norm: 7.36762453
INFO:root:At the start of the epoch: mem (CPU python)=27841.18359375MB; mem (CPU total)=27553.05078125MB
INFO:root:[   77] Training loss: 0.68550024, Validation loss: 0.59582840, Gradient norm: 6.18616259
INFO:root:At the start of the epoch: mem (CPU python)=27862.34375MB; mem (CPU total)=27574.72265625MB
INFO:root:[   78] Training loss: 0.68583336, Validation loss: 0.59555651, Gradient norm: 5.99708586
INFO:root:At the start of the epoch: mem (CPU python)=27883.51171875MB; mem (CPU total)=27595.88671875MB
INFO:root:[   79] Training loss: 0.68596333, Validation loss: 0.59426076, Gradient norm: 7.88996773
INFO:root:At the start of the epoch: mem (CPU python)=27904.67578125MB; mem (CPU total)=27617.33984375MB
INFO:root:[   80] Training loss: 0.68561237, Validation loss: 0.59643631, Gradient norm: 7.45489850
INFO:root:At the start of the epoch: mem (CPU python)=27925.83984375MB; mem (CPU total)=27638.28515625MB
INFO:root:[   81] Training loss: 0.68515001, Validation loss: 0.59525613, Gradient norm: 7.81465571
INFO:root:At the start of the epoch: mem (CPU python)=27947.00390625MB; mem (CPU total)=27659.41796875MB
INFO:root:[   82] Training loss: 0.68495454, Validation loss: 0.59445880, Gradient norm: 7.82695483
INFO:root:At the start of the epoch: mem (CPU python)=27968.16796875MB; mem (CPU total)=27680.578125MB
INFO:root:[   83] Training loss: 0.68471869, Validation loss: 0.59601261, Gradient norm: 7.44445809
INFO:root:At the start of the epoch: mem (CPU python)=27989.3359375MB; mem (CPU total)=27701.7421875MB
INFO:root:[   84] Training loss: 0.68476567, Validation loss: 0.59480504, Gradient norm: 8.18422879
INFO:root:At the start of the epoch: mem (CPU python)=28010.5MB; mem (CPU total)=27722.90625MB
INFO:root:[   85] Training loss: 0.68453555, Validation loss: 0.59531860, Gradient norm: 10.24265198
INFO:root:At the start of the epoch: mem (CPU python)=28031.6640625MB; mem (CPU total)=27744.5MB
INFO:root:[   86] Training loss: 0.68456981, Validation loss: 0.59470254, Gradient norm: 9.90143321
INFO:root:At the start of the epoch: mem (CPU python)=28052.82421875MB; mem (CPU total)=27765.6171875MB
INFO:root:[   87] Training loss: 0.68458415, Validation loss: 0.59646342, Gradient norm: 9.57320705
INFO:root:At the start of the epoch: mem (CPU python)=28073.98828125MB; mem (CPU total)=27786.76953125MB
INFO:root:[   88] Training loss: 0.68451382, Validation loss: 0.59560232, Gradient norm: 10.87970652
INFO:root:At the start of the epoch: mem (CPU python)=28095.1484375MB; mem (CPU total)=27807.921875MB
INFO:root:EP 88: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=28116.31640625MB; mem (CPU total)=27828.828125MB
INFO:root:Training the model took 3842.335s.
INFO:root:Emptying the cuda cache took 0.038s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9665
INFO:root:EnergyScoreValidation: 0.51644
INFO:root:CRPSValidation: 0.23431
INFO:root:Gaussian NLLValidation: 8.29824
INFO:root:CoverageValidation: 0.62737
INFO:root:IntervalWidthValidation: 1.14835
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.98804
INFO:root:EnergyScoreTest: 0.52769
INFO:root:CRPSTest: 0.2402
INFO:root:Gaussian NLLTest: 5.48539
INFO:root:CoverageTest: 0.62081
INFO:root:IntervalWidthTest: 1.15597
INFO:root:After validation: mem (CPU python)=28204.60546875MB; mem (CPU total)=27917.6171875MB
