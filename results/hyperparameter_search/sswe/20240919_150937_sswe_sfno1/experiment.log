INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=581.8515625MB; mem (CPU total)=9009.22265625MB
INFO:root:############### Starting experiment with config file sswe/sfno1.ini ###############
INFO:root:###1 out of 2 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 1, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=592.98046875MB; mem (CPU total)=9048.84765625MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=594.375MB; mem (CPU total)=9048.796875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2277.0859375MB; mem (CPU total)=10768.30859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2286.62890625MB; mem (CPU total)=10789.92578125MB
INFO:root:[    1] Training loss: 0.83318730, Validation loss: 0.73970448, Gradient norm: 0.60771032
INFO:root:At the start of the epoch: mem (CPU python)=4447.21875MB; mem (CPU total)=8654.5859375MB
INFO:root:[    2] Training loss: 0.73502503, Validation loss: 0.73325702, Gradient norm: 0.38430298
INFO:root:At the start of the epoch: mem (CPU python)=4469.3828125MB; mem (CPU total)=8684.91796875MB
INFO:root:[    3] Training loss: 0.73252594, Validation loss: 0.73248225, Gradient norm: 0.30895425
INFO:root:At the start of the epoch: mem (CPU python)=4490.8046875MB; mem (CPU total)=9606.46484375MB
INFO:root:[    4] Training loss: 0.72723118, Validation loss: 0.71408572, Gradient norm: 0.44993609
INFO:root:At the start of the epoch: mem (CPU python)=4511.984375MB; mem (CPU total)=10532.16796875MB
INFO:root:[    5] Training loss: 0.68626477, Validation loss: 0.65804589, Gradient norm: 0.50662932
INFO:root:At the start of the epoch: mem (CPU python)=4533.16796875MB; mem (CPU total)=11358.0859375MB
INFO:root:[    6] Training loss: 0.62583091, Validation loss: 0.60076104, Gradient norm: 0.70316403
INFO:root:At the start of the epoch: mem (CPU python)=4554.3515625MB; mem (CPU total)=11939.67578125MB
INFO:root:[    7] Training loss: 0.56703553, Validation loss: 0.55090530, Gradient norm: 0.87436516
INFO:root:At the start of the epoch: mem (CPU python)=4575.53515625MB; mem (CPU total)=12399.46484375MB
INFO:root:[    8] Training loss: 0.53326708, Validation loss: 0.52463143, Gradient norm: 0.93635610
INFO:root:At the start of the epoch: mem (CPU python)=4596.7109375MB; mem (CPU total)=12861.328125MB
INFO:root:[    9] Training loss: 0.51344317, Validation loss: 0.50694421, Gradient norm: 1.05468660
INFO:root:At the start of the epoch: mem (CPU python)=4617.875MB; mem (CPU total)=12778.3359375MB
INFO:root:[   10] Training loss: 0.50056583, Validation loss: 0.49645304, Gradient norm: 1.16739736
INFO:root:At the start of the epoch: mem (CPU python)=4639.04296875MB; mem (CPU total)=13010.68359375MB
INFO:root:[   11] Training loss: 0.48826081, Validation loss: 0.47964401, Gradient norm: 1.11398359
INFO:root:At the start of the epoch: mem (CPU python)=4660.20703125MB; mem (CPU total)=13214.87109375MB
INFO:root:[   12] Training loss: 0.47835682, Validation loss: 0.48834658, Gradient norm: 1.20425313
INFO:root:At the start of the epoch: mem (CPU python)=4681.3671875MB; mem (CPU total)=8986.16796875MB
INFO:root:[   13] Training loss: 0.47110212, Validation loss: 0.46580574, Gradient norm: 1.27234178
INFO:root:At the start of the epoch: mem (CPU python)=4702.6875MB; mem (CPU total)=9018.3046875MB
INFO:root:[   14] Training loss: 0.46217303, Validation loss: 0.45678538, Gradient norm: 1.09206466
INFO:root:At the start of the epoch: mem (CPU python)=4724.07421875MB; mem (CPU total)=9047.59375MB
INFO:root:[   15] Training loss: 0.46516632, Validation loss: 0.45847156, Gradient norm: 1.37404965
INFO:root:At the start of the epoch: mem (CPU python)=4745.234375MB; mem (CPU total)=9077.15234375MB
INFO:root:[   16] Training loss: 0.45466850, Validation loss: 0.44879238, Gradient norm: 1.25026190
INFO:root:At the start of the epoch: mem (CPU python)=4766.3984375MB; mem (CPU total)=9161.9921875MB
INFO:root:[   17] Training loss: 0.45053538, Validation loss: 0.45503446, Gradient norm: 1.33739458
INFO:root:At the start of the epoch: mem (CPU python)=4787.57421875MB; mem (CPU total)=9136.73828125MB
INFO:root:[   18] Training loss: 0.44826634, Validation loss: 0.45104935, Gradient norm: 1.38246790
INFO:root:At the start of the epoch: mem (CPU python)=4808.7421875MB; mem (CPU total)=9167.91796875MB
INFO:root:[   19] Training loss: 0.44694113, Validation loss: 0.46075546, Gradient norm: 1.52043600
INFO:root:At the start of the epoch: mem (CPU python)=4829.91015625MB; mem (CPU total)=9198.20703125MB
INFO:root:[   20] Training loss: 0.44124265, Validation loss: 0.44742171, Gradient norm: 1.56196703
INFO:root:At the start of the epoch: mem (CPU python)=4851.07421875MB; mem (CPU total)=9229.62109375MB
INFO:root:[   21] Training loss: 0.44291528, Validation loss: 0.44347554, Gradient norm: 1.47655036
INFO:root:At the start of the epoch: mem (CPU python)=4872.234375MB; mem (CPU total)=9259.09765625MB
INFO:root:[   22] Training loss: 0.43710046, Validation loss: 0.44295163, Gradient norm: 1.36374182
INFO:root:At the start of the epoch: mem (CPU python)=4893.3984375MB; mem (CPU total)=9290.18359375MB
INFO:root:[   23] Training loss: 0.43300615, Validation loss: 0.44296441, Gradient norm: 1.51258195
INFO:root:At the start of the epoch: mem (CPU python)=4914.5625MB; mem (CPU total)=9320.59375MB
INFO:root:[   24] Training loss: 0.43632760, Validation loss: 0.43501744, Gradient norm: 1.82127325
INFO:root:At the start of the epoch: mem (CPU python)=4936.48046875MB; mem (CPU total)=9351.10546875MB
INFO:root:[   25] Training loss: 0.43414717, Validation loss: 0.43003947, Gradient norm: 1.85115138
INFO:root:At the start of the epoch: mem (CPU python)=4957.6484375MB; mem (CPU total)=9382.37890625MB
INFO:root:[   26] Training loss: 0.42904429, Validation loss: 0.43199636, Gradient norm: 1.80093010
INFO:root:At the start of the epoch: mem (CPU python)=4978.8125MB; mem (CPU total)=9412.4921875MB
INFO:root:[   27] Training loss: 0.42985230, Validation loss: 0.44189470, Gradient norm: 1.42149191
INFO:root:At the start of the epoch: mem (CPU python)=4999.9765625MB; mem (CPU total)=9831.40234375MB
INFO:root:[   28] Training loss: 0.43255108, Validation loss: 0.42803518, Gradient norm: 2.00557475
INFO:root:At the start of the epoch: mem (CPU python)=5021.14453125MB; mem (CPU total)=10850.359375MB
INFO:root:[   29] Training loss: 0.42808974, Validation loss: 0.43006802, Gradient norm: 2.11654921
INFO:root:At the start of the epoch: mem (CPU python)=5043.16796875MB; mem (CPU total)=9506.71484375MB
INFO:root:[   30] Training loss: 0.42450014, Validation loss: 0.42133253, Gradient norm: 1.80969574
INFO:root:At the start of the epoch: mem (CPU python)=5064.6015625MB; mem (CPU total)=9615.9765625MB
INFO:root:[   31] Training loss: 0.42484875, Validation loss: 0.44452113, Gradient norm: 2.12389040
INFO:root:At the start of the epoch: mem (CPU python)=5085.8828125MB; mem (CPU total)=10938.42578125MB
INFO:root:[   32] Training loss: 0.42617777, Validation loss: 0.41703854, Gradient norm: 1.96809436
INFO:root:At the start of the epoch: mem (CPU python)=5107.296875MB; mem (CPU total)=11698.5390625MB
INFO:root:[   33] Training loss: 0.42062088, Validation loss: 0.41990683, Gradient norm: 1.80714663
INFO:root:At the start of the epoch: mem (CPU python)=5128.47265625MB; mem (CPU total)=12329.73828125MB
INFO:root:[   34] Training loss: 0.41879874, Validation loss: 0.41636699, Gradient norm: 2.28934483
INFO:root:At the start of the epoch: mem (CPU python)=5149.640625MB; mem (CPU total)=12664.2109375MB
INFO:root:[   35] Training loss: 0.42598249, Validation loss: 0.42725814, Gradient norm: 2.56259789
INFO:root:At the start of the epoch: mem (CPU python)=5170.9296875MB; mem (CPU total)=9690.046875MB
INFO:root:[   36] Training loss: 0.41849313, Validation loss: 0.41166073, Gradient norm: 2.54328653
INFO:root:At the start of the epoch: mem (CPU python)=5192.34375MB; mem (CPU total)=9721.55078125MB
INFO:root:[   37] Training loss: 0.41598172, Validation loss: 0.41515945, Gradient norm: 2.08008148
INFO:root:At the start of the epoch: mem (CPU python)=5213.5078125MB; mem (CPU total)=9751.65625MB
INFO:root:[   38] Training loss: 0.41600335, Validation loss: 0.41133000, Gradient norm: 2.25158878
INFO:root:At the start of the epoch: mem (CPU python)=5236.01953125MB; mem (CPU total)=9784.11328125MB
INFO:root:[   39] Training loss: 0.41626950, Validation loss: 0.41670794, Gradient norm: 2.73863670
INFO:root:At the start of the epoch: mem (CPU python)=5257.34375MB; mem (CPU total)=9816.5546875MB
INFO:root:[   40] Training loss: 0.41509025, Validation loss: 0.41726400, Gradient norm: 2.44004495
INFO:root:At the start of the epoch: mem (CPU python)=5278.5078125MB; mem (CPU total)=9845.09375MB
INFO:root:[   41] Training loss: 0.41799747, Validation loss: 0.43681415, Gradient norm: 2.55179727
INFO:root:At the start of the epoch: mem (CPU python)=5299.671875MB; mem (CPU total)=9875.6171875MB
INFO:root:[   42] Training loss: 0.41060688, Validation loss: 0.41463064, Gradient norm: 2.91067205
INFO:root:At the start of the epoch: mem (CPU python)=5320.8359375MB; mem (CPU total)=9905.89453125MB
INFO:root:[   43] Training loss: 0.41427778, Validation loss: 0.40356703, Gradient norm: 2.53667850
INFO:root:At the start of the epoch: mem (CPU python)=5343.37109375MB; mem (CPU total)=9938.75390625MB
INFO:root:[   44] Training loss: 0.41566906, Validation loss: 0.41121923, Gradient norm: 2.64441032
INFO:root:At the start of the epoch: mem (CPU python)=5364.66796875MB; mem (CPU total)=9968.78515625MB
INFO:root:[   45] Training loss: 0.41886788, Validation loss: 0.41564755, Gradient norm: 2.76648718
INFO:root:At the start of the epoch: mem (CPU python)=5385.8359375MB; mem (CPU total)=10000.5390625MB
INFO:root:[   46] Training loss: 0.40736248, Validation loss: 0.40949869, Gradient norm: 2.64714296
INFO:root:At the start of the epoch: mem (CPU python)=5407.0MB; mem (CPU total)=10030.52734375MB
INFO:root:[   47] Training loss: 0.40966441, Validation loss: 0.42083526, Gradient norm: 2.60404445
INFO:root:At the start of the epoch: mem (CPU python)=5428.1640625MB; mem (CPU total)=10062.02734375MB
INFO:root:[   48] Training loss: 0.41092448, Validation loss: 0.41391574, Gradient norm: 2.96050927
INFO:root:At the start of the epoch: mem (CPU python)=5449.32421875MB; mem (CPU total)=10092.3046875MB
INFO:root:[   49] Training loss: 0.40358831, Validation loss: 0.40302985, Gradient norm: 2.89918088
INFO:root:At the start of the epoch: mem (CPU python)=5470.4921875MB; mem (CPU total)=10123.3046875MB
INFO:root:[   50] Training loss: 0.40848562, Validation loss: 0.41461617, Gradient norm: 3.00594218
INFO:root:At the start of the epoch: mem (CPU python)=5491.6484375MB; mem (CPU total)=10153.32421875MB
INFO:root:[   51] Training loss: 0.41246956, Validation loss: 0.42570239, Gradient norm: 2.81777007
INFO:root:At the start of the epoch: mem (CPU python)=5513.734375MB; mem (CPU total)=10184.578125MB
INFO:root:[   52] Training loss: 0.40809486, Validation loss: 0.40965193, Gradient norm: 3.15683067
INFO:root:At the start of the epoch: mem (CPU python)=5535.2734375MB; mem (CPU total)=10216.4609375MB
INFO:root:[   53] Training loss: 0.40941945, Validation loss: 0.40873889, Gradient norm: 3.40265948
INFO:root:At the start of the epoch: mem (CPU python)=5556.56640625MB; mem (CPU total)=10245.48828125MB
INFO:root:[   54] Training loss: 0.40387349, Validation loss: 0.40553777, Gradient norm: 2.65331228
INFO:root:At the start of the epoch: mem (CPU python)=5578.00390625MB; mem (CPU total)=10277.515625MB
INFO:root:[   55] Training loss: 0.40478976, Validation loss: 0.40493365, Gradient norm: 2.65567681
INFO:root:At the start of the epoch: mem (CPU python)=5599.359375MB; mem (CPU total)=10307.79296875MB
INFO:root:[   56] Training loss: 0.40616687, Validation loss: 0.38848200, Gradient norm: 3.45993271
INFO:root:At the start of the epoch: mem (CPU python)=5620.69921875MB; mem (CPU total)=10339.79296875MB
INFO:root:[   57] Training loss: 0.40180653, Validation loss: 0.39871502, Gradient norm: 3.32523339
INFO:root:At the start of the epoch: mem (CPU python)=5642.06640625MB; mem (CPU total)=10370.2734375MB
INFO:root:[   58] Training loss: 0.41178501, Validation loss: 0.40229711, Gradient norm: 2.90784591
INFO:root:At the start of the epoch: mem (CPU python)=5663.23046875MB; mem (CPU total)=10400.796875MB
INFO:root:[   59] Training loss: 0.40177280, Validation loss: 0.42216135, Gradient norm: 3.53201980
INFO:root:At the start of the epoch: mem (CPU python)=5684.515625MB; mem (CPU total)=10432.0078125MB
INFO:root:[   60] Training loss: 0.40511909, Validation loss: 0.41534093, Gradient norm: 3.38254034
INFO:root:At the start of the epoch: mem (CPU python)=5705.9296875MB; mem (CPU total)=10464.25MB
INFO:root:[   61] Training loss: 0.40833847, Validation loss: 0.42692564, Gradient norm: 3.48774150
INFO:root:At the start of the epoch: mem (CPU python)=5727.09765625MB; mem (CPU total)=10494.0078125MB
INFO:root:[   62] Training loss: 0.40734686, Validation loss: 0.40144690, Gradient norm: 3.48343183
INFO:root:At the start of the epoch: mem (CPU python)=5748.26171875MB; mem (CPU total)=10524.28515625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.40894971, Validation loss: 0.42150845, Gradient norm: 3.78314063
INFO:root:At the start of the epoch: mem (CPU python)=5769.42578125MB; mem (CPU total)=10555.71875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.38044599, Validation loss: 0.38924644, Gradient norm: 2.34713582
INFO:root:At the start of the epoch: mem (CPU python)=5790.58984375MB; mem (CPU total)=10585.93359375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   65] Training loss: 0.37194689, Validation loss: 0.37847755, Gradient norm: 1.75003161
INFO:root:At the start of the epoch: mem (CPU python)=5812.3828125MB; mem (CPU total)=10618.09375MB
INFO:root:[   66] Training loss: 0.36837099, Validation loss: 0.37312068, Gradient norm: 1.22436943
INFO:root:At the start of the epoch: mem (CPU python)=5833.6640625MB; mem (CPU total)=10647.81640625MB
INFO:root:[   67] Training loss: 0.36628907, Validation loss: 0.37361206, Gradient norm: 1.41057829
INFO:root:At the start of the epoch: mem (CPU python)=5854.828125MB; mem (CPU total)=10679.30859375MB
INFO:root:[   68] Training loss: 0.36706629, Validation loss: 0.37171184, Gradient norm: 1.47333700
INFO:root:At the start of the epoch: mem (CPU python)=5875.9921875MB; mem (CPU total)=10710.296875MB
INFO:root:[   69] Training loss: 0.36623321, Validation loss: 0.37194115, Gradient norm: 1.67979138
INFO:root:At the start of the epoch: mem (CPU python)=5897.15625MB; mem (CPU total)=10741.80859375MB
INFO:root:[   70] Training loss: 0.36538246, Validation loss: 0.37193041, Gradient norm: 1.71760978
INFO:root:At the start of the epoch: mem (CPU python)=5918.99609375MB; mem (CPU total)=10773.28515625MB
INFO:root:[   71] Training loss: 0.36445656, Validation loss: 0.37111468, Gradient norm: 1.88233135
INFO:root:At the start of the epoch: mem (CPU python)=5940.23828125MB; mem (CPU total)=10804.79296875MB
INFO:root:[   72] Training loss: 0.36506267, Validation loss: 0.37131747, Gradient norm: 2.02903121
INFO:root:At the start of the epoch: mem (CPU python)=5961.40234375MB; mem (CPU total)=10834.93359375MB
INFO:root:[   73] Training loss: 0.36492755, Validation loss: 0.37028149, Gradient norm: 2.10390606
INFO:root:At the start of the epoch: mem (CPU python)=5982.57421875MB; mem (CPU total)=10867.1796875MB
INFO:root:[   74] Training loss: 0.36338647, Validation loss: 0.37096997, Gradient norm: 2.42761329
INFO:root:At the start of the epoch: mem (CPU python)=6003.73828125MB; mem (CPU total)=10896.9609375MB
INFO:root:[   75] Training loss: 0.36347086, Validation loss: 0.37070298, Gradient norm: 2.47684778
INFO:root:At the start of the epoch: mem (CPU python)=6024.90234375MB; mem (CPU total)=10927.8125MB
INFO:root:[   76] Training loss: 0.36450928, Validation loss: 0.37011987, Gradient norm: 2.60805063
INFO:root:At the start of the epoch: mem (CPU python)=6046.27734375MB; mem (CPU total)=10959.5234375MB
INFO:root:[   77] Training loss: 0.36418736, Validation loss: 0.36965590, Gradient norm: 2.70603266
INFO:root:At the start of the epoch: mem (CPU python)=6067.609375MB; mem (CPU total)=10989.84765625MB
INFO:root:[   78] Training loss: 0.36488895, Validation loss: 0.36980743, Gradient norm: 2.91182706
INFO:root:At the start of the epoch: mem (CPU python)=6089.2421875MB; mem (CPU total)=11022.28125MB
INFO:root:[   79] Training loss: 0.36359555, Validation loss: 0.36667983, Gradient norm: 2.99375433
INFO:root:At the start of the epoch: mem (CPU python)=6110.68359375MB; mem (CPU total)=11052.3984375MB
INFO:root:[   80] Training loss: 0.36431576, Validation loss: 0.36994585, Gradient norm: 3.30063937
INFO:root:At the start of the epoch: mem (CPU python)=6131.84765625MB; mem (CPU total)=11084.83203125MB
INFO:root:[   81] Training loss: 0.36376975, Validation loss: 0.37030490, Gradient norm: 3.49183655
INFO:root:At the start of the epoch: mem (CPU python)=6153.01171875MB; mem (CPU total)=11115.34375MB
INFO:root:[   82] Training loss: 0.36274193, Validation loss: 0.36869893, Gradient norm: 3.62608979
INFO:root:At the start of the epoch: mem (CPU python)=6175.1328125MB; mem (CPU total)=11148.7265625MB
INFO:root:[   83] Training loss: 0.36338073, Validation loss: 0.37066327, Gradient norm: 3.66530720
INFO:root:At the start of the epoch: mem (CPU python)=6196.46484375MB; mem (CPU total)=11179.4921875MB
INFO:root:[   84] Training loss: 0.36357714, Validation loss: 0.36809902, Gradient norm: 4.01900285
INFO:root:At the start of the epoch: mem (CPU python)=6217.62890625MB; mem (CPU total)=11211.23828125MB
INFO:root:[   85] Training loss: 0.36395746, Validation loss: 0.37121196, Gradient norm: 4.24409395
INFO:root:At the start of the epoch: mem (CPU python)=6240.9453125MB; mem (CPU total)=11243.8203125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   86] Training loss: 0.36237182, Validation loss: 0.37033342, Gradient norm: 4.26049589
INFO:root:At the start of the epoch: mem (CPU python)=6262.20703125MB; mem (CPU total)=11276.2734375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   87] Training loss: 0.36161670, Validation loss: 0.36772523, Gradient norm: 2.42249533
INFO:root:At the start of the epoch: mem (CPU python)=6283.921875MB; mem (CPU total)=11309.62890625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   88] Training loss: 0.36082046, Validation loss: 0.36767309, Gradient norm: 1.81743533
INFO:root:At the start of the epoch: mem (CPU python)=6305.28125MB; mem (CPU total)=11341.3828125MB
INFO:root:[   89] Training loss: 0.36126171, Validation loss: 0.36607583, Gradient norm: 1.52584478
INFO:root:At the start of the epoch: mem (CPU python)=6326.48046875MB; mem (CPU total)=11372.12109375MB
INFO:root:[   90] Training loss: 0.36029633, Validation loss: 0.36539447, Gradient norm: 1.36346425
INFO:root:At the start of the epoch: mem (CPU python)=6348.25390625MB; mem (CPU total)=11403.11328125MB
INFO:root:[   91] Training loss: 0.35976505, Validation loss: 0.36477257, Gradient norm: 1.49832021
INFO:root:At the start of the epoch: mem (CPU python)=6369.41796875MB; mem (CPU total)=11434.890625MB
INFO:root:[   92] Training loss: 0.36003091, Validation loss: 0.36616407, Gradient norm: 1.49615530
INFO:root:At the start of the epoch: mem (CPU python)=6390.5859375MB; mem (CPU total)=11464.8203125MB
INFO:root:[   93] Training loss: 0.35980932, Validation loss: 0.36589739, Gradient norm: 1.54860262
INFO:root:At the start of the epoch: mem (CPU python)=6411.75MB; mem (CPU total)=11496.66015625MB
INFO:root:[   94] Training loss: 0.36034304, Validation loss: 0.36841544, Gradient norm: 1.52525113
INFO:root:At the start of the epoch: mem (CPU python)=6432.93359375MB; mem (CPU total)=11526.62890625MB
INFO:root:[   95] Training loss: 0.36004453, Validation loss: 0.36621618, Gradient norm: 1.63887598
INFO:root:At the start of the epoch: mem (CPU python)=6454.109375MB; mem (CPU total)=11558.18359375MB
INFO:root:[   96] Training loss: 0.35997390, Validation loss: 0.36798875, Gradient norm: 1.68628084
INFO:root:At the start of the epoch: mem (CPU python)=6475.2734375MB; mem (CPU total)=11588.58984375MB
INFO:root:[   97] Training loss: 0.35954158, Validation loss: 0.36789631, Gradient norm: 1.63520234
INFO:root:At the start of the epoch: mem (CPU python)=6496.4375MB; mem (CPU total)=11620.55859375MB
INFO:root:[   98] Training loss: 0.36094481, Validation loss: 0.36560267, Gradient norm: 1.88054724
INFO:root:At the start of the epoch: mem (CPU python)=6517.60546875MB; mem (CPU total)=11653.99609375MB
INFO:root:[   99] Training loss: 0.36037115, Validation loss: 0.36562501, Gradient norm: 1.69037418
INFO:root:At the start of the epoch: mem (CPU python)=6538.77734375MB; mem (CPU total)=11684.15625MB
INFO:root:[  100] Training loss: 0.35957329, Validation loss: 0.36590092, Gradient norm: 1.80784798
INFO:root:At the start of the epoch: mem (CPU python)=6559.953125MB; mem (CPU total)=11714.37890625MB
INFO:root:EP 100: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=6581.125MB; mem (CPU total)=11747.2109375MB
INFO:root:Training the model took 2399.157s.
INFO:root:Emptying the cuda cache took 0.033s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.35112
INFO:root:EnergyScoreValidation: 0.29897
INFO:root:CRPSValidation: 0.11841
INFO:root:Gaussian NLLValidation: 3.46829
INFO:root:CoverageValidation: 0.454
INFO:root:IntervalWidthValidation: 0.19363
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.37877
INFO:root:EnergyScoreTest: 0.32625
INFO:root:CRPSTest: 0.12998
INFO:root:Gaussian NLLTest: 4.77273
INFO:root:CoverageTest: 0.4177
INFO:root:IntervalWidthTest: 0.18821
INFO:root:After validation: mem (CPU python)=6896.39453125MB; mem (CPU total)=11910.890625MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=6896.39453125MB; mem (CPU total)=11910.7421875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=6896.39453125MB; mem (CPU total)=11933.7421875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=11935.9140625MB
INFO:root:[    1] Training loss: 0.83787462, Validation loss: 0.74102738, Gradient norm: 0.51659137
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=11977.75MB
INFO:root:[    2] Training loss: 0.73834567, Validation loss: 0.73817036, Gradient norm: 0.34810880
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12010.28515625MB
INFO:root:[    3] Training loss: 0.73457686, Validation loss: 0.72994817, Gradient norm: 0.34577058
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12038.63671875MB
INFO:root:[    4] Training loss: 0.71561292, Validation loss: 0.69259632, Gradient norm: 0.50494182
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12070.49609375MB
INFO:root:[    5] Training loss: 0.67002577, Validation loss: 0.64936601, Gradient norm: 0.64407955
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12100.69140625MB
INFO:root:[    6] Training loss: 0.62037249, Validation loss: 0.61279803, Gradient norm: 0.87268281
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12131.8203125MB
INFO:root:[    7] Training loss: 0.59570985, Validation loss: 0.57360324, Gradient norm: 1.04680549
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12162.51953125MB
INFO:root:[    8] Training loss: 0.56754739, Validation loss: 0.55521675, Gradient norm: 1.26189001
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12193.0078125MB
INFO:root:[    9] Training loss: 0.55138853, Validation loss: 0.56899528, Gradient norm: 1.28509464
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12224.05078125MB
INFO:root:[   10] Training loss: 0.54105612, Validation loss: 0.53517597, Gradient norm: 1.63985418
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12254.6015625MB
INFO:root:[   11] Training loss: 0.53067746, Validation loss: 0.52090916, Gradient norm: 1.62585180
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12285.24609375MB
INFO:root:[   12] Training loss: 0.52034026, Validation loss: 0.50792778, Gradient norm: 1.60288421
INFO:root:At the start of the epoch: mem (CPU python)=6896.39453125MB; mem (CPU total)=12315.6875MB
INFO:root:[   13] Training loss: 0.50678073, Validation loss: 0.50204598, Gradient norm: 1.67376491
INFO:root:At the start of the epoch: mem (CPU python)=6906.890625MB; mem (CPU total)=12347.390625MB
INFO:root:[   14] Training loss: 0.49870265, Validation loss: 0.49807197, Gradient norm: 1.95693225
INFO:root:At the start of the epoch: mem (CPU python)=6928.0703125MB; mem (CPU total)=12377.890625MB
INFO:root:[   15] Training loss: 0.49201480, Validation loss: 0.48136379, Gradient norm: 1.91176132
INFO:root:At the start of the epoch: mem (CPU python)=6949.23828125MB; mem (CPU total)=12405.40234375MB
INFO:root:[   16] Training loss: 0.48752999, Validation loss: 0.49491415, Gradient norm: 2.04150001
INFO:root:At the start of the epoch: mem (CPU python)=6970.40625MB; mem (CPU total)=12435.5859375MB
INFO:root:[   17] Training loss: 0.48326452, Validation loss: 0.47453415, Gradient norm: 2.23235473
INFO:root:At the start of the epoch: mem (CPU python)=6991.578125MB; mem (CPU total)=12467.39453125MB
INFO:root:[   18] Training loss: 0.47866563, Validation loss: 0.49310018, Gradient norm: 1.92043790
INFO:root:At the start of the epoch: mem (CPU python)=7012.73828125MB; mem (CPU total)=12610.9609375MB
INFO:root:[   19] Training loss: 0.47417069, Validation loss: 0.47337498, Gradient norm: 2.04243364
INFO:root:At the start of the epoch: mem (CPU python)=7033.90234375MB; mem (CPU total)=12908.48046875MB
INFO:root:[   20] Training loss: 0.47322176, Validation loss: 0.46413987, Gradient norm: 1.82420985
INFO:root:At the start of the epoch: mem (CPU python)=7055.0703125MB; mem (CPU total)=13206.01953125MB
INFO:root:[   21] Training loss: 0.46817962, Validation loss: 0.47048371, Gradient norm: 2.41319897
INFO:root:At the start of the epoch: mem (CPU python)=7076.23828125MB; mem (CPU total)=18414.2421875MB
INFO:root:[   22] Training loss: 0.46856546, Validation loss: 0.46529825, Gradient norm: 2.09567765
INFO:root:At the start of the epoch: mem (CPU python)=7097.40625MB; mem (CPU total)=18767.14453125MB
INFO:root:[   23] Training loss: 0.46787586, Validation loss: 0.47088665, Gradient norm: 2.00712711
INFO:root:At the start of the epoch: mem (CPU python)=7118.5703125MB; mem (CPU total)=18802.32421875MB
INFO:root:[   24] Training loss: 0.46508959, Validation loss: 0.45975223, Gradient norm: 2.35711735
INFO:root:At the start of the epoch: mem (CPU python)=7139.734375MB; mem (CPU total)=18831.73046875MB
INFO:root:[   25] Training loss: 0.46884255, Validation loss: 0.47389802, Gradient norm: 2.18515838
INFO:root:At the start of the epoch: mem (CPU python)=7160.8984375MB; mem (CPU total)=18864.52734375MB
INFO:root:[   26] Training loss: 0.46371623, Validation loss: 0.45969168, Gradient norm: 2.10087482
INFO:root:At the start of the epoch: mem (CPU python)=7182.07421875MB; mem (CPU total)=18896.8984375MB
INFO:root:[   27] Training loss: 0.45934412, Validation loss: 0.45564379, Gradient norm: 2.22949628
INFO:root:At the start of the epoch: mem (CPU python)=7203.23828125MB; mem (CPU total)=18929.55078125MB
INFO:root:[   28] Training loss: 0.46107625, Validation loss: 0.46749320, Gradient norm: 2.54325307
INFO:root:At the start of the epoch: mem (CPU python)=7224.40625MB; mem (CPU total)=18961.66796875MB
INFO:root:[   29] Training loss: 0.46323323, Validation loss: 0.46470626, Gradient norm: 2.60332406
INFO:root:At the start of the epoch: mem (CPU python)=7245.57421875MB; mem (CPU total)=18992.16015625MB
INFO:root:[   30] Training loss: 0.46086344, Validation loss: 0.47009723, Gradient norm: 2.23078632
INFO:root:At the start of the epoch: mem (CPU python)=7266.7421875MB; mem (CPU total)=19024.484375MB
INFO:root:[   31] Training loss: 0.45912921, Validation loss: 0.46092842, Gradient norm: 2.47206666
INFO:root:At the start of the epoch: mem (CPU python)=7288.91015625MB; mem (CPU total)=19054.3828125MB
INFO:root:[   32] Training loss: 0.45659871, Validation loss: 0.45549861, Gradient norm: 2.49210064
INFO:root:At the start of the epoch: mem (CPU python)=7310.0859375MB; mem (CPU total)=19087.2265625MB
INFO:root:[   33] Training loss: 0.45396926, Validation loss: 0.45710514, Gradient norm: 2.41859528
INFO:root:At the start of the epoch: mem (CPU python)=7331.26171875MB; mem (CPU total)=19119.796875MB
INFO:root:[   34] Training loss: 0.46031736, Validation loss: 0.46472231, Gradient norm: 2.38199034
INFO:root:At the start of the epoch: mem (CPU python)=7352.453125MB; mem (CPU total)=19151.29296875MB
INFO:root:[   35] Training loss: 0.45715949, Validation loss: 0.46653446, Gradient norm: 2.77028973
INFO:root:At the start of the epoch: mem (CPU python)=7373.6328125MB; mem (CPU total)=19182.60546875MB
INFO:root:[   36] Training loss: 0.45588553, Validation loss: 0.45744177, Gradient norm: 2.53841514
INFO:root:At the start of the epoch: mem (CPU python)=7394.80859375MB; mem (CPU total)=19215.22265625MB
INFO:root:[   37] Training loss: 0.45472943, Validation loss: 0.46833780, Gradient norm: 2.79621247
INFO:root:At the start of the epoch: mem (CPU python)=7415.98828125MB; mem (CPU total)=19246.51953125MB
INFO:root:[   38] Training loss: 0.45329041, Validation loss: 0.44145146, Gradient norm: 2.75242940
INFO:root:At the start of the epoch: mem (CPU python)=7437.16015625MB; mem (CPU total)=19277.5859375MB
INFO:root:[   39] Training loss: 0.45163715, Validation loss: 0.44584297, Gradient norm: 2.62612798
INFO:root:At the start of the epoch: mem (CPU python)=7458.33984375MB; mem (CPU total)=19309.12890625MB
INFO:root:[   40] Training loss: 0.44997230, Validation loss: 0.43629668, Gradient norm: 2.83689512
INFO:root:At the start of the epoch: mem (CPU python)=7479.5078125MB; mem (CPU total)=19340.90234375MB
INFO:root:[   41] Training loss: 0.44768416, Validation loss: 0.45085182, Gradient norm: 2.59801909
INFO:root:At the start of the epoch: mem (CPU python)=7500.69140625MB; mem (CPU total)=19371.59765625MB
INFO:root:[   42] Training loss: 0.45152881, Validation loss: 0.44030188, Gradient norm: 2.58045240
INFO:root:At the start of the epoch: mem (CPU python)=7521.86328125MB; mem (CPU total)=19404.3515625MB
INFO:root:[   43] Training loss: 0.44591266, Validation loss: 0.46493761, Gradient norm: 3.37472382
INFO:root:At the start of the epoch: mem (CPU python)=7543.046875MB; mem (CPU total)=19436.5234375MB
INFO:root:[   44] Training loss: 0.45453395, Validation loss: 0.45596674, Gradient norm: 2.93617744
INFO:root:At the start of the epoch: mem (CPU python)=7564.2265625MB; mem (CPU total)=19468.0703125MB
INFO:root:[   45] Training loss: 0.45170490, Validation loss: 0.44393675, Gradient norm: 2.99926006
INFO:root:At the start of the epoch: mem (CPU python)=7585.4140625MB; mem (CPU total)=19500.18359375MB
INFO:root:[   46] Training loss: 0.44458277, Validation loss: 0.44382256, Gradient norm: 3.18683080
INFO:root:At the start of the epoch: mem (CPU python)=7606.58984375MB; mem (CPU total)=19533.1171875MB
INFO:root:[   47] Training loss: 0.44662863, Validation loss: 0.44922321, Gradient norm: 3.10565578
INFO:root:At the start of the epoch: mem (CPU python)=7627.765625MB; mem (CPU total)=19563.36328125MB
INFO:root:[   48] Training loss: 0.44611802, Validation loss: 0.44898798, Gradient norm: 2.88434624
INFO:root:At the start of the epoch: mem (CPU python)=7648.9453125MB; mem (CPU total)=19595.765625MB
INFO:root:[   49] Training loss: 0.44251378, Validation loss: 0.44014021, Gradient norm: 3.22255447
INFO:root:At the start of the epoch: mem (CPU python)=7670.109375MB; mem (CPU total)=19627.23046875MB
INFO:root:[   50] Training loss: 0.44457163, Validation loss: 0.44850801, Gradient norm: 3.47721521
INFO:root:At the start of the epoch: mem (CPU python)=7691.29296875MB; mem (CPU total)=19658.40625MB
INFO:root:[   51] Training loss: 0.44527773, Validation loss: 0.43552958, Gradient norm: 3.29980463
INFO:root:At the start of the epoch: mem (CPU python)=7712.4609375MB; mem (CPU total)=19688.79296875MB
INFO:root:[   52] Training loss: 0.44237667, Validation loss: 0.44774600, Gradient norm: 3.20936092
INFO:root:At the start of the epoch: mem (CPU python)=7733.62109375MB; mem (CPU total)=19722.35546875MB
INFO:root:[   53] Training loss: 0.44392245, Validation loss: 0.44294104, Gradient norm: 3.77437414
INFO:root:At the start of the epoch: mem (CPU python)=7754.80078125MB; mem (CPU total)=19752.7109375MB
INFO:root:[   54] Training loss: 0.44274674, Validation loss: 0.48057298, Gradient norm: 3.42643344
INFO:root:At the start of the epoch: mem (CPU python)=7775.97265625MB; mem (CPU total)=19785.71875MB
INFO:root:[   55] Training loss: 0.44445910, Validation loss: 0.43876369, Gradient norm: 3.76376079
INFO:root:At the start of the epoch: mem (CPU python)=7797.14453125MB; mem (CPU total)=19817.015625MB
INFO:root:[   56] Training loss: 0.44819111, Validation loss: 0.43760385, Gradient norm: 3.80251607
INFO:root:At the start of the epoch: mem (CPU python)=7818.3203125MB; mem (CPU total)=19849.55078125MB
INFO:root:[   57] Training loss: 0.44270051, Validation loss: 0.43069836, Gradient norm: 3.27664212
INFO:root:At the start of the epoch: mem (CPU python)=7839.48828125MB; mem (CPU total)=19879.5625MB
INFO:root:[   58] Training loss: 0.44069751, Validation loss: 0.44102158, Gradient norm: 3.84473498
INFO:root:At the start of the epoch: mem (CPU python)=7860.65234375MB; mem (CPU total)=19913.16015625MB
INFO:root:[   59] Training loss: 0.43770199, Validation loss: 0.44074936, Gradient norm: 4.04799286
INFO:root:At the start of the epoch: mem (CPU python)=7881.8359375MB; mem (CPU total)=19944.421875MB
INFO:root:[   60] Training loss: 0.43804316, Validation loss: 0.43554300, Gradient norm: 3.48499473
INFO:root:At the start of the epoch: mem (CPU python)=7903.0078125MB; mem (CPU total)=19977.7109375MB
INFO:root:[   61] Training loss: 0.44153193, Validation loss: 0.43015458, Gradient norm: 3.64464159
INFO:root:At the start of the epoch: mem (CPU python)=7924.1796875MB; mem (CPU total)=20007.23828125MB
INFO:root:[   62] Training loss: 0.44614655, Validation loss: 0.43166554, Gradient norm: 4.17089310
INFO:root:At the start of the epoch: mem (CPU python)=7945.34375MB; mem (CPU total)=20039.41015625MB
INFO:root:[   63] Training loss: 0.43947039, Validation loss: 0.44053145, Gradient norm: 4.04514264
INFO:root:At the start of the epoch: mem (CPU python)=7966.51953125MB; mem (CPU total)=20069.41796875MB
INFO:root:[   64] Training loss: 0.44231285, Validation loss: 0.42952691, Gradient norm: 3.87610893
INFO:root:At the start of the epoch: mem (CPU python)=7987.6953125MB; mem (CPU total)=20101.67578125MB
INFO:root:[   65] Training loss: 0.43812238, Validation loss: 0.42679104, Gradient norm: 4.26600865
INFO:root:At the start of the epoch: mem (CPU python)=8008.86328125MB; mem (CPU total)=20133.05078125MB
INFO:root:[   66] Training loss: 0.44040293, Validation loss: 0.43844325, Gradient norm: 3.93514500
INFO:root:At the start of the epoch: mem (CPU python)=8030.04296875MB; mem (CPU total)=20164.50390625MB
INFO:root:[   67] Training loss: 0.43821293, Validation loss: 0.43947693, Gradient norm: 4.20052782
INFO:root:At the start of the epoch: mem (CPU python)=8051.203125MB; mem (CPU total)=20195.5234375MB
INFO:root:[   68] Training loss: 0.44291468, Validation loss: 0.44334167, Gradient norm: 3.98130116
INFO:root:At the start of the epoch: mem (CPU python)=8072.37890625MB; mem (CPU total)=20226.984375MB
INFO:root:[   69] Training loss: 0.44391517, Validation loss: 0.42897364, Gradient norm: 4.02315655
INFO:root:At the start of the epoch: mem (CPU python)=8093.5546875MB; mem (CPU total)=20258.56640625MB
INFO:root:[   70] Training loss: 0.43979398, Validation loss: 0.43557019, Gradient norm: 4.68606038
INFO:root:At the start of the epoch: mem (CPU python)=8114.7265625MB; mem (CPU total)=20289.71875MB
INFO:root:[   71] Training loss: 0.43990180, Validation loss: 0.43887566, Gradient norm: 4.29934724
INFO:root:At the start of the epoch: mem (CPU python)=8135.8984375MB; mem (CPU total)=20320.91015625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   72] Training loss: 0.44258918, Validation loss: 0.43636688, Gradient norm: 4.50632809
INFO:root:At the start of the epoch: mem (CPU python)=8157.0703125MB; mem (CPU total)=20352.6171875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   73] Training loss: 0.41258944, Validation loss: 0.41478991, Gradient norm: 2.88856887
INFO:root:At the start of the epoch: mem (CPU python)=8178.24609375MB; mem (CPU total)=20385.83203125MB
INFO:root:[   74] Training loss: 0.40212778, Validation loss: 0.40414816, Gradient norm: 2.22627695
INFO:root:At the start of the epoch: mem (CPU python)=8199.41796875MB; mem (CPU total)=20417.37109375MB
INFO:root:[   75] Training loss: 0.39992162, Validation loss: 0.40541804, Gradient norm: 2.83983250
INFO:root:At the start of the epoch: mem (CPU python)=8220.58203125MB; mem (CPU total)=20449.484375MB
INFO:root:[   76] Training loss: 0.40041519, Validation loss: 0.40809011, Gradient norm: 3.11696984
INFO:root:At the start of the epoch: mem (CPU python)=8241.7578125MB; mem (CPU total)=20481.05078125MB
INFO:root:[   77] Training loss: 0.39903460, Validation loss: 0.40267945, Gradient norm: 3.33491571
INFO:root:At the start of the epoch: mem (CPU python)=8262.9296875MB; mem (CPU total)=20512.69921875MB
INFO:root:[   78] Training loss: 0.39925195, Validation loss: 0.40260108, Gradient norm: 4.01122718
INFO:root:At the start of the epoch: mem (CPU python)=8284.109375MB; mem (CPU total)=20544.48046875MB
INFO:root:[   79] Training loss: 0.39978035, Validation loss: 0.40315706, Gradient norm: 4.29422596
INFO:root:At the start of the epoch: mem (CPU python)=8305.27734375MB; mem (CPU total)=20576.0546875MB
INFO:root:[   80] Training loss: 0.39941036, Validation loss: 0.40379441, Gradient norm: 4.59580498
INFO:root:At the start of the epoch: mem (CPU python)=8326.4375MB; mem (CPU total)=20607.12890625MB
INFO:root:[   81] Training loss: 0.39882839, Validation loss: 0.40167045, Gradient norm: 4.92949380
INFO:root:At the start of the epoch: mem (CPU python)=8347.62109375MB; mem (CPU total)=20638.21484375MB
INFO:root:[   82] Training loss: 0.39939210, Validation loss: 0.40574088, Gradient norm: 4.86564372
INFO:root:At the start of the epoch: mem (CPU python)=8368.78515625MB; mem (CPU total)=20668.7890625MB
INFO:root:[   83] Training loss: 0.39966027, Validation loss: 0.40061217, Gradient norm: 5.50082891
INFO:root:At the start of the epoch: mem (CPU python)=8389.96484375MB; mem (CPU total)=20701.9921875MB
INFO:root:[   84] Training loss: 0.40036820, Validation loss: 0.43068965, Gradient norm: 5.67260884
INFO:root:At the start of the epoch: mem (CPU python)=8411.1328125MB; mem (CPU total)=20733.14453125MB
INFO:root:[   85] Training loss: 0.40231903, Validation loss: 0.41707854, Gradient norm: 5.91594693
INFO:root:At the start of the epoch: mem (CPU python)=8432.30859375MB; mem (CPU total)=20764.8515625MB
INFO:root:[   86] Training loss: 0.40154109, Validation loss: 0.40528829, Gradient norm: 6.42340912
INFO:root:At the start of the epoch: mem (CPU python)=8453.48046875MB; mem (CPU total)=20796.35546875MB
INFO:root:[   87] Training loss: 0.40038825, Validation loss: 0.40165999, Gradient norm: 6.31433709
INFO:root:At the start of the epoch: mem (CPU python)=8474.65625MB; mem (CPU total)=20827.859375MB
INFO:root:[   88] Training loss: 0.40116454, Validation loss: 0.40428530, Gradient norm: 6.71960840
INFO:root:At the start of the epoch: mem (CPU python)=8495.828125MB; mem (CPU total)=20859.69921875MB
INFO:root:[   89] Training loss: 0.40103941, Validation loss: 0.40627003, Gradient norm: 7.13289636
INFO:root:At the start of the epoch: mem (CPU python)=8516.99609375MB; mem (CPU total)=20892.3359375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   90] Training loss: 0.40208303, Validation loss: 0.40630321, Gradient norm: 7.11276555
INFO:root:At the start of the epoch: mem (CPU python)=8538.16015625MB; mem (CPU total)=20923.953125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   91] Training loss: 0.39481931, Validation loss: 0.39958790, Gradient norm: 4.69505151
INFO:root:At the start of the epoch: mem (CPU python)=8559.34765625MB; mem (CPU total)=20955.5625MB
INFO:root:[   92] Training loss: 0.39275825, Validation loss: 0.39905041, Gradient norm: 4.19563950
INFO:root:At the start of the epoch: mem (CPU python)=8580.515625MB; mem (CPU total)=20987.0MB
INFO:root:[   93] Training loss: 0.39165644, Validation loss: 0.39620620, Gradient norm: 3.41264275
INFO:root:At the start of the epoch: mem (CPU python)=8601.6796875MB; mem (CPU total)=21017.34375MB
INFO:root:[   94] Training loss: 0.39184690, Validation loss: 0.39793285, Gradient norm: 3.43722868
INFO:root:At the start of the epoch: mem (CPU python)=8622.86328125MB; mem (CPU total)=14904.36328125MB
INFO:root:[   95] Training loss: 0.39145944, Validation loss: 0.39691638, Gradient norm: 3.87736382
INFO:root:At the start of the epoch: mem (CPU python)=8644.02734375MB; mem (CPU total)=14936.34765625MB
INFO:root:[   96] Training loss: 0.39170930, Validation loss: 0.39751630, Gradient norm: 4.14890395
INFO:root:At the start of the epoch: mem (CPU python)=8665.20703125MB; mem (CPU total)=14967.3359375MB
INFO:root:[   97] Training loss: 0.39052589, Validation loss: 0.39735818, Gradient norm: 4.12086441
INFO:root:At the start of the epoch: mem (CPU python)=8686.375MB; mem (CPU total)=14997.60546875MB
INFO:root:[   98] Training loss: 0.39155203, Validation loss: 0.39502710, Gradient norm: 4.26640417
INFO:root:At the start of the epoch: mem (CPU python)=8707.546875MB; mem (CPU total)=15028.9921875MB
INFO:root:[   99] Training loss: 0.39155250, Validation loss: 0.39610844, Gradient norm: 4.46567582
INFO:root:At the start of the epoch: mem (CPU python)=8740.71875MB; mem (CPU total)=15071.22265625MB
INFO:root:[  100] Training loss: 0.39123875, Validation loss: 0.39552265, Gradient norm: 5.07829586
INFO:root:At the start of the epoch: mem (CPU python)=8761.89453125MB; mem (CPU total)=15103.12109375MB
INFO:root:[  101] Training loss: 0.39154723, Validation loss: 0.39829141, Gradient norm: 5.03744386
INFO:root:At the start of the epoch: mem (CPU python)=8783.0546875MB; mem (CPU total)=15135.1171875MB
INFO:root:[  102] Training loss: 0.39123993, Validation loss: 0.39656416, Gradient norm: 5.47033885
INFO:root:At the start of the epoch: mem (CPU python)=8804.23046875MB; mem (CPU total)=15165.96484375MB
INFO:root:[  103] Training loss: 0.39143576, Validation loss: 0.39731790, Gradient norm: 5.81527150
INFO:root:At the start of the epoch: mem (CPU python)=8825.41015625MB; mem (CPU total)=15198.2109375MB
INFO:root:[  104] Training loss: 0.39129945, Validation loss: 0.39715420, Gradient norm: 6.01533901
INFO:root:At the start of the epoch: mem (CPU python)=8846.57421875MB; mem (CPU total)=15229.1953125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  105] Training loss: 0.39107389, Validation loss: 0.39684486, Gradient norm: 6.24524146
INFO:root:At the start of the epoch: mem (CPU python)=8867.7578125MB; mem (CPU total)=15260.921875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  106] Training loss: 0.38975956, Validation loss: 0.39695190, Gradient norm: 3.96974478
INFO:root:At the start of the epoch: mem (CPU python)=8888.921875MB; mem (CPU total)=15291.8125MB
INFO:root:[  107] Training loss: 0.38887193, Validation loss: 0.39567347, Gradient norm: 3.16173381
INFO:root:At the start of the epoch: mem (CPU python)=8910.09765625MB; mem (CPU total)=15323.5703125MB
INFO:root:EP 107: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=8931.24609375MB; mem (CPU total)=15353.109375MB
INFO:root:Training the model took 2730.439s.
INFO:root:Emptying the cuda cache took 0.033s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.36407
INFO:root:EnergyScoreValidation: 0.28769
INFO:root:CRPSValidation: 0.11348
INFO:root:Gaussian NLLValidation: 0.61522
INFO:root:CoverageValidation: 0.66888
INFO:root:IntervalWidthValidation: 0.32267
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.38737
INFO:root:EnergyScoreTest: 0.30949
INFO:root:CRPSTest: 0.12287
INFO:root:Gaussian NLLTest: 0.97262
INFO:root:CoverageTest: 0.63752
INFO:root:IntervalWidthTest: 0.3207
INFO:root:After validation: mem (CPU python)=9238.0703125MB; mem (CPU total)=15462.44140625MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=9238.0703125MB; mem (CPU total)=15464.41015625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=9238.0703125MB; mem (CPU total)=15464.41015625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15466.7734375MB
INFO:root:[    1] Training loss: 0.84074616, Validation loss: 0.74542628, Gradient norm: 0.48069239
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15499.17578125MB
INFO:root:[    2] Training loss: 0.74121849, Validation loss: 0.73910888, Gradient norm: 0.38069165
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15526.96875MB
INFO:root:[    3] Training loss: 0.73630100, Validation loss: 0.72666589, Gradient norm: 0.43927918
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15560.15625MB
INFO:root:[    4] Training loss: 0.71984989, Validation loss: 0.71141334, Gradient norm: 0.63750536
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15589.6796875MB
INFO:root:[    5] Training loss: 0.68208035, Validation loss: 0.66475070, Gradient norm: 0.83714767
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15622.4140625MB
INFO:root:[    6] Training loss: 0.63832690, Validation loss: 0.62927308, Gradient norm: 1.40906444
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15652.87890625MB
INFO:root:[    7] Training loss: 0.60160333, Validation loss: 0.57741637, Gradient norm: 1.43666486
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15685.61328125MB
INFO:root:[    8] Training loss: 0.58191526, Validation loss: 0.56277509, Gradient norm: 1.53447964
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15715.9140625MB
INFO:root:[    9] Training loss: 0.56431312, Validation loss: 0.57424871, Gradient norm: 1.48333166
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15747.65625MB
INFO:root:[   10] Training loss: 0.55931642, Validation loss: 0.55171500, Gradient norm: 1.98353969
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15778.42578125MB
INFO:root:[   11] Training loss: 0.54812869, Validation loss: 0.53710416, Gradient norm: 1.87429188
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15811.41015625MB
INFO:root:[   12] Training loss: 0.53542300, Validation loss: 0.52812601, Gradient norm: 1.96814084
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15841.94921875MB
INFO:root:[   13] Training loss: 0.52649435, Validation loss: 0.51554757, Gradient norm: 2.45948943
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15873.6640625MB
INFO:root:[   14] Training loss: 0.51987758, Validation loss: 0.51183239, Gradient norm: 2.32075857
INFO:root:At the start of the epoch: mem (CPU python)=9238.0703125MB; mem (CPU total)=15900.9609375MB
INFO:root:[   15] Training loss: 0.51074212, Validation loss: 0.49655030, Gradient norm: 2.32977355
INFO:root:At the start of the epoch: mem (CPU python)=9255.74609375MB; mem (CPU total)=15921.875MB
INFO:root:[   16] Training loss: 0.50921731, Validation loss: 0.50272022, Gradient norm: 3.09425737
INFO:root:At the start of the epoch: mem (CPU python)=9276.9296875MB; mem (CPU total)=15943.27734375MB
INFO:root:[   17] Training loss: 0.50644230, Validation loss: 0.49628508, Gradient norm: 2.78095941
INFO:root:At the start of the epoch: mem (CPU python)=9298.1015625MB; mem (CPU total)=15965.42578125MB
INFO:root:[   18] Training loss: 0.50187411, Validation loss: 0.50416672, Gradient norm: 2.66272713
INFO:root:At the start of the epoch: mem (CPU python)=9319.27734375MB; mem (CPU total)=15986.875MB
INFO:root:[   19] Training loss: 0.49745926, Validation loss: 0.49498900, Gradient norm: 2.85499797
INFO:root:At the start of the epoch: mem (CPU python)=9340.4375MB; mem (CPU total)=16009.03515625MB
INFO:root:[   20] Training loss: 0.49366764, Validation loss: 0.48839595, Gradient norm: 3.39226014
INFO:root:At the start of the epoch: mem (CPU python)=9361.6171875MB; mem (CPU total)=16031.6015625MB
INFO:root:[   21] Training loss: 0.49453609, Validation loss: 0.48545085, Gradient norm: 3.52608939
INFO:root:At the start of the epoch: mem (CPU python)=9382.78515625MB; mem (CPU total)=16053.03125MB
INFO:root:[   22] Training loss: 0.48973980, Validation loss: 0.49374808, Gradient norm: 3.07467136
INFO:root:At the start of the epoch: mem (CPU python)=9403.96484375MB; mem (CPU total)=16076.34765625MB
INFO:root:[   23] Training loss: 0.49391465, Validation loss: 0.49868858, Gradient norm: 3.09231101
INFO:root:At the start of the epoch: mem (CPU python)=9425.13671875MB; mem (CPU total)=16124.640625MB
INFO:root:[   24] Training loss: 0.48823230, Validation loss: 0.48524256, Gradient norm: 3.33728547
INFO:root:At the start of the epoch: mem (CPU python)=9446.3125MB; mem (CPU total)=16156.4609375MB
INFO:root:[   25] Training loss: 0.48500512, Validation loss: 0.48901196, Gradient norm: 3.22885017
INFO:root:At the start of the epoch: mem (CPU python)=9467.4765625MB; mem (CPU total)=16187.609375MB
INFO:root:[   26] Training loss: 0.49105063, Validation loss: 0.50807911, Gradient norm: 3.36532039
INFO:root:At the start of the epoch: mem (CPU python)=9488.671875MB; mem (CPU total)=16219.60546875MB
INFO:root:[   27] Training loss: 0.48619104, Validation loss: 0.48176599, Gradient norm: 3.45316554
INFO:root:At the start of the epoch: mem (CPU python)=9509.828125MB; mem (CPU total)=16250.67578125MB
INFO:root:[   28] Training loss: 0.48272758, Validation loss: 0.47891232, Gradient norm: 3.54572994
INFO:root:At the start of the epoch: mem (CPU python)=9531.14453125MB; mem (CPU total)=16282.40625MB
INFO:root:[   29] Training loss: 0.48401061, Validation loss: 0.47862834, Gradient norm: 3.22812792
INFO:root:At the start of the epoch: mem (CPU python)=9552.32421875MB; mem (CPU total)=16314.66796875MB
INFO:root:[   30] Training loss: 0.47838920, Validation loss: 0.48187636, Gradient norm: 3.41082439
INFO:root:At the start of the epoch: mem (CPU python)=9573.484375MB; mem (CPU total)=16346.14453125MB
INFO:root:[   31] Training loss: 0.48187046, Validation loss: 0.47268550, Gradient norm: 4.12503595
INFO:root:At the start of the epoch: mem (CPU python)=9594.65234375MB; mem (CPU total)=16377.6484375MB
INFO:root:[   32] Training loss: 0.48029728, Validation loss: 0.48145762, Gradient norm: 3.62026166
INFO:root:At the start of the epoch: mem (CPU python)=9615.8359375MB; mem (CPU total)=16409.17578125MB
INFO:root:[   33] Training loss: 0.48009123, Validation loss: 0.48343422, Gradient norm: 3.48856141
INFO:root:At the start of the epoch: mem (CPU python)=9637.00390625MB; mem (CPU total)=16440.4375MB
INFO:root:[   34] Training loss: 0.47954248, Validation loss: 0.49304675, Gradient norm: 3.27953922
INFO:root:At the start of the epoch: mem (CPU python)=9658.16796875MB; mem (CPU total)=16472.91796875MB
INFO:root:[   35] Training loss: 0.48002565, Validation loss: 0.46529164, Gradient norm: 3.77460515
INFO:root:At the start of the epoch: mem (CPU python)=9679.359375MB; mem (CPU total)=16503.9609375MB
INFO:root:[   36] Training loss: 0.47826429, Validation loss: 0.49134000, Gradient norm: 3.62198434
INFO:root:At the start of the epoch: mem (CPU python)=9700.5234375MB; mem (CPU total)=16535.9375MB
INFO:root:[   37] Training loss: 0.47599622, Validation loss: 0.46887045, Gradient norm: 3.62501783
INFO:root:At the start of the epoch: mem (CPU python)=9721.703125MB; mem (CPU total)=16567.73828125MB
INFO:root:[   38] Training loss: 0.48131403, Validation loss: 0.47354448, Gradient norm: 4.06607132
INFO:root:At the start of the epoch: mem (CPU python)=9742.8671875MB; mem (CPU total)=16599.75MB
INFO:root:[   39] Training loss: 0.47811637, Validation loss: 0.47547268, Gradient norm: 3.63315772
INFO:root:At the start of the epoch: mem (CPU python)=9764.046875MB; mem (CPU total)=16630.96875MB
INFO:root:[   40] Training loss: 0.47824240, Validation loss: 0.46725241, Gradient norm: 4.00018087
INFO:root:At the start of the epoch: mem (CPU python)=9785.2109375MB; mem (CPU total)=16663.5MB
INFO:root:[   41] Training loss: 0.47239091, Validation loss: 0.46286875, Gradient norm: 3.67350158
INFO:root:At the start of the epoch: mem (CPU python)=9806.40234375MB; mem (CPU total)=16694.57421875MB
INFO:root:[   42] Training loss: 0.47240895, Validation loss: 0.47988485, Gradient norm: 3.64727067
INFO:root:At the start of the epoch: mem (CPU python)=9827.56640625MB; mem (CPU total)=16725.9921875MB
INFO:root:[   43] Training loss: 0.47327484, Validation loss: 0.47946983, Gradient norm: 3.65221759
INFO:root:At the start of the epoch: mem (CPU python)=9848.73046875MB; mem (CPU total)=16758.01171875MB
INFO:root:[   44] Training loss: 0.47545105, Validation loss: 0.46842509, Gradient norm: 4.06904960
INFO:root:At the start of the epoch: mem (CPU python)=9869.91796875MB; mem (CPU total)=16789.765625MB
INFO:root:[   45] Training loss: 0.46727584, Validation loss: 0.46291939, Gradient norm: 3.54792423
INFO:root:At the start of the epoch: mem (CPU python)=9891.08203125MB; mem (CPU total)=16821.73828125MB
INFO:root:[   46] Training loss: 0.46919723, Validation loss: 0.47064849, Gradient norm: 3.70025422
INFO:root:At the start of the epoch: mem (CPU python)=9923.93359375MB; mem (CPU total)=16865.29296875MB
INFO:root:[   47] Training loss: 0.46936684, Validation loss: 0.47743204, Gradient norm: 4.07388371
INFO:root:At the start of the epoch: mem (CPU python)=9945.08984375MB; mem (CPU total)=16897.453125MB
INFO:root:[   48] Training loss: 0.47071470, Validation loss: 0.46412660, Gradient norm: 3.93123752
INFO:root:At the start of the epoch: mem (CPU python)=9966.609375MB; mem (CPU total)=16928.70703125MB
INFO:root:[   49] Training loss: 0.46816278, Validation loss: 0.46202984, Gradient norm: 3.89734609
INFO:root:At the start of the epoch: mem (CPU python)=9987.7734375MB; mem (CPU total)=16960.68359375MB
INFO:root:[   50] Training loss: 0.46792104, Validation loss: 0.46611046, Gradient norm: 3.17059602
INFO:root:At the start of the epoch: mem (CPU python)=10009.37890625MB; mem (CPU total)=16992.890625MB
INFO:root:[   51] Training loss: 0.46006675, Validation loss: 0.46668739, Gradient norm: 4.58898187
INFO:root:At the start of the epoch: mem (CPU python)=10030.66015625MB; mem (CPU total)=17025.71875MB
INFO:root:[   52] Training loss: 0.46925173, Validation loss: 0.46938671, Gradient norm: 4.05109035
INFO:root:At the start of the epoch: mem (CPU python)=10051.82421875MB; mem (CPU total)=17056.57421875MB
INFO:root:[   53] Training loss: 0.46289975, Validation loss: 0.46986323, Gradient norm: 4.33222724
INFO:root:At the start of the epoch: mem (CPU python)=10073.46484375MB; mem (CPU total)=17088.91015625MB
INFO:root:[   54] Training loss: 0.46404289, Validation loss: 0.47595308, Gradient norm: 3.94091890
INFO:root:At the start of the epoch: mem (CPU python)=10094.67578125MB; mem (CPU total)=17120.93359375MB
INFO:root:[   55] Training loss: 0.46307678, Validation loss: 0.47274060, Gradient norm: 3.76404543
INFO:root:At the start of the epoch: mem (CPU python)=10119.01171875MB; mem (CPU total)=17155.8515625MB
INFO:root:[   56] Training loss: 0.45917161, Validation loss: 0.45674317, Gradient norm: 4.12054785
INFO:root:At the start of the epoch: mem (CPU python)=10140.39453125MB; mem (CPU total)=17187.140625MB
INFO:root:[   57] Training loss: 0.46222161, Validation loss: 0.45688205, Gradient norm: 3.76662879
INFO:root:At the start of the epoch: mem (CPU python)=10161.87890625MB; mem (CPU total)=17181.6875MB
INFO:root:[   58] Training loss: 0.45706443, Validation loss: 0.44739020, Gradient norm: 4.58228185
INFO:root:At the start of the epoch: mem (CPU python)=10183.046875MB; mem (CPU total)=17207.9375MB
INFO:root:[   59] Training loss: 0.46216605, Validation loss: 0.44719785, Gradient norm: 4.06938655
INFO:root:At the start of the epoch: mem (CPU python)=10204.2109375MB; mem (CPU total)=17241.64453125MB
INFO:root:[   60] Training loss: 0.45962256, Validation loss: 0.45807657, Gradient norm: 4.05957444
INFO:root:At the start of the epoch: mem (CPU python)=10225.375MB; mem (CPU total)=17272.4765625MB
INFO:root:[   61] Training loss: 0.46182815, Validation loss: 0.45742148, Gradient norm: 4.39513841
INFO:root:At the start of the epoch: mem (CPU python)=10246.5390625MB; mem (CPU total)=17305.6953125MB
INFO:root:[   62] Training loss: 0.45459029, Validation loss: 0.45591829, Gradient norm: 4.08494056
INFO:root:At the start of the epoch: mem (CPU python)=10267.703125MB; mem (CPU total)=17337.42578125MB
INFO:root:[   63] Training loss: 0.46275319, Validation loss: 0.46126765, Gradient norm: 4.27658060
INFO:root:At the start of the epoch: mem (CPU python)=10288.8671875MB; mem (CPU total)=17369.8515625MB
INFO:root:[   64] Training loss: 0.45683553, Validation loss: 0.44689224, Gradient norm: 4.41932036
INFO:root:At the start of the epoch: mem (CPU python)=10310.03515625MB; mem (CPU total)=17400.9140625MB
INFO:root:[   65] Training loss: 0.45558100, Validation loss: 0.47270232, Gradient norm: 4.27078791
INFO:root:At the start of the epoch: mem (CPU python)=10331.19140625MB; mem (CPU total)=17433.4296875MB
INFO:root:[   66] Training loss: 0.45522661, Validation loss: 0.47320089, Gradient norm: 3.98042689
INFO:root:At the start of the epoch: mem (CPU python)=10352.35546875MB; mem (CPU total)=17464.66796875MB
INFO:root:[   67] Training loss: 0.45897042, Validation loss: 0.47135915, Gradient norm: 3.80477143
INFO:root:At the start of the epoch: mem (CPU python)=10373.51953125MB; mem (CPU total)=17496.90234375MB
INFO:root:[   68] Training loss: 0.45910830, Validation loss: 0.45871894, Gradient norm: 4.55018569
INFO:root:At the start of the epoch: mem (CPU python)=10394.68359375MB; mem (CPU total)=17528.609375MB
INFO:root:[   69] Training loss: 0.45600780, Validation loss: 0.45359584, Gradient norm: 4.30477529
INFO:root:At the start of the epoch: mem (CPU python)=10415.84765625MB; mem (CPU total)=17563.54296875MB
INFO:root:[   70] Training loss: 0.45548640, Validation loss: 0.45090300, Gradient norm: 4.16012642
INFO:root:At the start of the epoch: mem (CPU python)=10437.015625MB; mem (CPU total)=17588.96875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   71] Training loss: 0.45083133, Validation loss: 0.45211264, Gradient norm: 4.14987616
INFO:root:At the start of the epoch: mem (CPU python)=10458.1796875MB; mem (CPU total)=17622.65234375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   72] Training loss: 0.42445526, Validation loss: 0.42851170, Gradient norm: 3.13027788
INFO:root:At the start of the epoch: mem (CPU python)=10479.34375MB; mem (CPU total)=17652.96875MB
INFO:root:[   73] Training loss: 0.41480936, Validation loss: 0.41848597, Gradient norm: 2.26967641
INFO:root:At the start of the epoch: mem (CPU python)=10500.5078125MB; mem (CPU total)=17685.6796875MB
INFO:root:[   74] Training loss: 0.41322635, Validation loss: 0.42125658, Gradient norm: 2.73188089
INFO:root:At the start of the epoch: mem (CPU python)=10521.671875MB; mem (CPU total)=17719.86328125MB
INFO:root:[   75] Training loss: 0.41315971, Validation loss: 0.42108224, Gradient norm: 3.25390073
INFO:root:At the start of the epoch: mem (CPU python)=10542.83203125MB; mem (CPU total)=17751.55078125MB
INFO:root:[   76] Training loss: 0.41376573, Validation loss: 0.42472777, Gradient norm: 3.51326086
INFO:root:At the start of the epoch: mem (CPU python)=10563.99609375MB; mem (CPU total)=17783.296875MB
INFO:root:[   77] Training loss: 0.41376081, Validation loss: 0.42155511, Gradient norm: 3.90682597
INFO:root:At the start of the epoch: mem (CPU python)=10585.1640625MB; mem (CPU total)=17814.82421875MB
INFO:root:[   78] Training loss: 0.41348342, Validation loss: 0.41700863, Gradient norm: 4.58363562
INFO:root:At the start of the epoch: mem (CPU python)=10606.328125MB; mem (CPU total)=17846.3203125MB
INFO:root:[   79] Training loss: 0.41369544, Validation loss: 0.41881962, Gradient norm: 5.10589508
INFO:root:At the start of the epoch: mem (CPU python)=10627.4921875MB; mem (CPU total)=17878.08203125MB
INFO:root:[   80] Training loss: 0.41371902, Validation loss: 0.41764829, Gradient norm: 5.27055108
INFO:root:At the start of the epoch: mem (CPU python)=10648.65625MB; mem (CPU total)=17909.84765625MB
INFO:root:[   81] Training loss: 0.41425132, Validation loss: 0.41948468, Gradient norm: 5.67513314
INFO:root:At the start of the epoch: mem (CPU python)=10669.81640625MB; mem (CPU total)=17941.703125MB
INFO:root:[   82] Training loss: 0.41325796, Validation loss: 0.41959387, Gradient norm: 6.12090989
INFO:root:At the start of the epoch: mem (CPU python)=10690.984375MB; mem (CPU total)=17973.65234375MB
INFO:root:[   83] Training loss: 0.41560875, Validation loss: 0.42282385, Gradient norm: 6.25981273
INFO:root:At the start of the epoch: mem (CPU python)=10712.1484375MB; mem (CPU total)=18005.63671875MB
INFO:root:[   84] Training loss: 0.41547551, Validation loss: 0.41773174, Gradient norm: 6.15524357
INFO:root:At the start of the epoch: mem (CPU python)=10733.3125MB; mem (CPU total)=18037.83984375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   85] Training loss: 0.41540962, Validation loss: 0.42009374, Gradient norm: 7.15108552
INFO:root:At the start of the epoch: mem (CPU python)=10754.47265625MB; mem (CPU total)=18069.546875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   86] Training loss: 0.40974593, Validation loss: 0.41465442, Gradient norm: 5.09772281
INFO:root:At the start of the epoch: mem (CPU python)=10775.640625MB; mem (CPU total)=18102.10546875MB
INFO:root:[   87] Training loss: 0.40689127, Validation loss: 0.41330842, Gradient norm: 3.25260846
INFO:root:At the start of the epoch: mem (CPU python)=10796.8046875MB; mem (CPU total)=18133.6171875MB
INFO:root:[   88] Training loss: 0.40706788, Validation loss: 0.41265346, Gradient norm: 3.31542386
INFO:root:At the start of the epoch: mem (CPU python)=10817.96875MB; mem (CPU total)=18165.640625MB
INFO:root:[   89] Training loss: 0.40664411, Validation loss: 0.41230924, Gradient norm: 3.87403661
INFO:root:At the start of the epoch: mem (CPU python)=10839.1328125MB; mem (CPU total)=18197.125MB
INFO:root:[   90] Training loss: 0.40768479, Validation loss: 0.41358481, Gradient norm: 5.78093375
INFO:root:At the start of the epoch: mem (CPU python)=10860.296875MB; mem (CPU total)=18229.85546875MB
INFO:root:[   91] Training loss: 0.40675694, Validation loss: 0.41303286, Gradient norm: 4.39852468
INFO:root:At the start of the epoch: mem (CPU python)=10881.4609375MB; mem (CPU total)=18262.39453125MB
INFO:root:[   92] Training loss: 0.40719664, Validation loss: 0.41342354, Gradient norm: 4.36162049
INFO:root:At the start of the epoch: mem (CPU python)=10902.62890625MB; mem (CPU total)=18294.03515625MB
INFO:root:[   93] Training loss: 0.40719690, Validation loss: 0.41273670, Gradient norm: 4.92460047
INFO:root:At the start of the epoch: mem (CPU python)=10923.79296875MB; mem (CPU total)=18325.8125MB
INFO:root:[   94] Training loss: 0.40736610, Validation loss: 0.41334771, Gradient norm: 4.94634143
INFO:root:At the start of the epoch: mem (CPU python)=10944.953125MB; mem (CPU total)=18357.54296875MB
INFO:root:[   95] Training loss: 0.40784303, Validation loss: 0.41247591, Gradient norm: 5.55698789
INFO:root:At the start of the epoch: mem (CPU python)=10966.1171875MB; mem (CPU total)=18389.45703125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   96] Training loss: 0.40737492, Validation loss: 0.41378233, Gradient norm: 5.61197776
INFO:root:At the start of the epoch: mem (CPU python)=10987.28125MB; mem (CPU total)=18421.66796875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   97] Training loss: 0.40598176, Validation loss: 0.41347488, Gradient norm: 4.16029202
INFO:root:At the start of the epoch: mem (CPU python)=11008.4453125MB; mem (CPU total)=18453.15625MB
INFO:root:[   98] Training loss: 0.40598636, Validation loss: 0.41144443, Gradient norm: 3.43798697
INFO:root:At the start of the epoch: mem (CPU python)=11029.61328125MB; mem (CPU total)=18485.59765625MB
INFO:root:[   99] Training loss: 0.40554630, Validation loss: 0.41247525, Gradient norm: 3.29733540
INFO:root:At the start of the epoch: mem (CPU python)=11050.7734375MB; mem (CPU total)=18517.03125MB
INFO:root:[  100] Training loss: 0.40509438, Validation loss: 0.41113413, Gradient norm: 3.48528231
INFO:root:At the start of the epoch: mem (CPU python)=11071.9375MB; mem (CPU total)=18549.71484375MB
INFO:root:[  101] Training loss: 0.40544025, Validation loss: 0.41327972, Gradient norm: 3.58965859
INFO:root:At the start of the epoch: mem (CPU python)=11093.1015625MB; mem (CPU total)=18581.4609375MB
INFO:root:[  102] Training loss: 0.40576428, Validation loss: 0.41234803, Gradient norm: 3.38100887
INFO:root:At the start of the epoch: mem (CPU python)=11114.265625MB; mem (CPU total)=18613.9609375MB
INFO:root:[  103] Training loss: 0.40626714, Validation loss: 0.41153193, Gradient norm: 3.57994392
INFO:root:At the start of the epoch: mem (CPU python)=11135.4296875MB; mem (CPU total)=18645.2578125MB
INFO:root:[  104] Training loss: 0.40559173, Validation loss: 0.41171006, Gradient norm: 3.93687044
INFO:root:At the start of the epoch: mem (CPU python)=11156.58984375MB; mem (CPU total)=18677.94921875MB
INFO:root:[  105] Training loss: 0.40528354, Validation loss: 0.41211072, Gradient norm: 4.11583473
INFO:root:At the start of the epoch: mem (CPU python)=11177.7578125MB; mem (CPU total)=18709.67578125MB
INFO:root:[  106] Training loss: 0.40602696, Validation loss: 0.41284935, Gradient norm: 4.44909658
INFO:root:At the start of the epoch: mem (CPU python)=11198.921875MB; mem (CPU total)=18742.39453125MB
INFO:root:[  107] Training loss: 0.40600455, Validation loss: 0.41251973, Gradient norm: 4.28375767
INFO:root:At the start of the epoch: mem (CPU python)=11220.08984375MB; mem (CPU total)=18773.65234375MB
INFO:root:[  108] Training loss: 0.40560971, Validation loss: 0.41200419, Gradient norm: 3.96254990
INFO:root:At the start of the epoch: mem (CPU python)=11241.25390625MB; mem (CPU total)=18807.1796875MB
INFO:root:[  109] Training loss: 0.40668597, Validation loss: 0.41170675, Gradient norm: 4.58510961
INFO:root:At the start of the epoch: mem (CPU python)=11262.421875MB; mem (CPU total)=18839.15625MB
INFO:root:EP 109: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=11283.5859375MB; mem (CPU total)=18868.2578125MB
INFO:root:Training the model took 2956.094s.
INFO:root:Emptying the cuda cache took 0.034s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.36683
INFO:root:EnergyScoreValidation: 0.28027
INFO:root:CRPSValidation: 0.10948
INFO:root:Gaussian NLLValidation: 0.05133
INFO:root:CoverageValidation: 0.75308
INFO:root:IntervalWidthValidation: 0.38823
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.38867
INFO:root:EnergyScoreTest: 0.30008
INFO:root:CRPSTest: 0.11844
INFO:root:Gaussian NLLTest: 0.30477
INFO:root:CoverageTest: 0.72007
INFO:root:IntervalWidthTest: 0.38646
INFO:root:After validation: mem (CPU python)=11590.27734375MB; mem (CPU total)=18974.6171875MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=11590.27734375MB; mem (CPU total)=18978.05859375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=11590.27734375MB; mem (CPU total)=18978.05859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=18981.01171875MB
INFO:root:[    1] Training loss: 0.84672186, Validation loss: 0.74906230, Gradient norm: 0.42380271
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19011.88671875MB
INFO:root:[    2] Training loss: 0.74525055, Validation loss: 0.74300325, Gradient norm: 0.41173532
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19043.625MB
INFO:root:[    3] Training loss: 0.73936288, Validation loss: 0.73348611, Gradient norm: 0.57895121
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19075.35546875MB
INFO:root:[    4] Training loss: 0.72440945, Validation loss: 0.71110108, Gradient norm: 0.70079037
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19107.625MB
INFO:root:[    5] Training loss: 0.69939964, Validation loss: 0.67310997, Gradient norm: 1.01734915
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19139.26171875MB
INFO:root:[    6] Training loss: 0.65737455, Validation loss: 0.64047494, Gradient norm: 1.37416575
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19171.73046875MB
INFO:root:[    7] Training loss: 0.62787506, Validation loss: 0.62617737, Gradient norm: 1.46775253
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19203.1875MB
INFO:root:[    8] Training loss: 0.61358700, Validation loss: 0.60615219, Gradient norm: 1.67343864
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19235.16796875MB
INFO:root:[    9] Training loss: 0.60424217, Validation loss: 0.59174535, Gradient norm: 1.74448950
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19267.1875MB
INFO:root:[   10] Training loss: 0.59441279, Validation loss: 0.60162779, Gradient norm: 2.00827983
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19299.3828125MB
INFO:root:[   11] Training loss: 0.58722525, Validation loss: 0.57214610, Gradient norm: 2.16021506
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19331.359375MB
INFO:root:[   12] Training loss: 0.58391345, Validation loss: 0.57520024, Gradient norm: 2.48919233
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19363.7890625MB
INFO:root:[   13] Training loss: 0.57480316, Validation loss: 0.57303707, Gradient norm: 2.66179119
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19395.69921875MB
INFO:root:[   14] Training loss: 0.57385746, Validation loss: 0.56910527, Gradient norm: 3.04592182
INFO:root:At the start of the epoch: mem (CPU python)=11590.27734375MB; mem (CPU total)=19428.265625MB
INFO:root:[   15] Training loss: 0.56523277, Validation loss: 0.55269708, Gradient norm: 3.00384568
INFO:root:At the start of the epoch: mem (CPU python)=11607.8125MB; mem (CPU total)=19460.30078125MB
INFO:root:[   16] Training loss: 0.56346228, Validation loss: 0.55245469, Gradient norm: 3.51575908
INFO:root:At the start of the epoch: mem (CPU python)=11628.98046875MB; mem (CPU total)=19492.9765625MB
INFO:root:[   17] Training loss: 0.55810652, Validation loss: 0.57046551, Gradient norm: 3.46181803
INFO:root:At the start of the epoch: mem (CPU python)=11650.14453125MB; mem (CPU total)=19524.44140625MB
INFO:root:[   18] Training loss: 0.55787967, Validation loss: 0.53764250, Gradient norm: 3.83768470
INFO:root:At the start of the epoch: mem (CPU python)=11671.30859375MB; mem (CPU total)=19556.7109375MB
INFO:root:[   19] Training loss: 0.55382261, Validation loss: 0.54733481, Gradient norm: 3.95312711
INFO:root:At the start of the epoch: mem (CPU python)=11692.47265625MB; mem (CPU total)=19588.1796875MB
INFO:root:[   20] Training loss: 0.53893463, Validation loss: 0.55034322, Gradient norm: 3.68851297
INFO:root:At the start of the epoch: mem (CPU python)=11713.6328125MB; mem (CPU total)=19614.64453125MB
INFO:root:[   21] Training loss: 0.53274000, Validation loss: 0.52336192, Gradient norm: 4.21672451
INFO:root:At the start of the epoch: mem (CPU python)=11734.80078125MB; mem (CPU total)=19650.08984375MB
INFO:root:[   22] Training loss: 0.52545090, Validation loss: 0.51514979, Gradient norm: 3.68139011
INFO:root:At the start of the epoch: mem (CPU python)=11755.9609375MB; mem (CPU total)=19680.6953125MB
INFO:root:[   23] Training loss: 0.52351637, Validation loss: 0.52072444, Gradient norm: 3.91154011
INFO:root:At the start of the epoch: mem (CPU python)=11777.125MB; mem (CPU total)=19712.8359375MB
INFO:root:[   24] Training loss: 0.53111865, Validation loss: 0.52319426, Gradient norm: 4.69103281
INFO:root:At the start of the epoch: mem (CPU python)=11798.2890625MB; mem (CPU total)=19747.78515625MB
INFO:root:[   25] Training loss: 0.53456240, Validation loss: 0.52230289, Gradient norm: 4.33789549
INFO:root:At the start of the epoch: mem (CPU python)=11819.453125MB; mem (CPU total)=19776.46484375MB
INFO:root:[   26] Training loss: 0.52261013, Validation loss: 0.52638922, Gradient norm: 3.99562043
INFO:root:At the start of the epoch: mem (CPU python)=11840.6171875MB; mem (CPU total)=19813.16796875MB
INFO:root:[   27] Training loss: 0.52400091, Validation loss: 0.54939931, Gradient norm: 4.35267844
INFO:root:At the start of the epoch: mem (CPU python)=11861.78515625MB; mem (CPU total)=19840.671875MB
INFO:root:[   28] Training loss: 0.52275235, Validation loss: 0.52056005, Gradient norm: 4.32884975
INFO:root:At the start of the epoch: mem (CPU python)=11882.94921875MB; mem (CPU total)=19876.30859375MB
INFO:root:[   29] Training loss: 0.51882111, Validation loss: 0.50638346, Gradient norm: 4.11379726
INFO:root:At the start of the epoch: mem (CPU python)=11904.11328125MB; mem (CPU total)=19906.86328125MB
INFO:root:[   30] Training loss: 0.52160717, Validation loss: 0.53571202, Gradient norm: 4.89347886
INFO:root:At the start of the epoch: mem (CPU python)=11925.2734375MB; mem (CPU total)=19940.17578125MB
INFO:root:[   31] Training loss: 0.52473055, Validation loss: 0.53986357, Gradient norm: 4.53135086
INFO:root:At the start of the epoch: mem (CPU python)=11946.4375MB; mem (CPU total)=19971.19140625MB
INFO:root:[   32] Training loss: 0.52269081, Validation loss: 0.51005324, Gradient norm: 4.52019205
INFO:root:At the start of the epoch: mem (CPU python)=11967.6015625MB; mem (CPU total)=20002.86328125MB
INFO:root:[   33] Training loss: 0.51660338, Validation loss: 0.54042072, Gradient norm: 4.42590294
INFO:root:At the start of the epoch: mem (CPU python)=11988.76953125MB; mem (CPU total)=20035.4609375MB
INFO:root:[   34] Training loss: 0.51591911, Validation loss: 0.55758441, Gradient norm: 4.16542671
INFO:root:At the start of the epoch: mem (CPU python)=12009.93359375MB; mem (CPU total)=20068.67578125MB
INFO:root:[   35] Training loss: 0.52341352, Validation loss: 0.53029776, Gradient norm: 5.29417366
INFO:root:At the start of the epoch: mem (CPU python)=12031.09765625MB; mem (CPU total)=20099.30078125MB
INFO:root:[   36] Training loss: 0.52320112, Validation loss: 0.52084177, Gradient norm: 4.64888042
INFO:root:At the start of the epoch: mem (CPU python)=12052.26171875MB; mem (CPU total)=20134.54296875MB
INFO:root:[   37] Training loss: 0.51347192, Validation loss: 0.52195162, Gradient norm: 4.57448305
INFO:root:At the start of the epoch: mem (CPU python)=12073.42578125MB; mem (CPU total)=20167.71875MB
INFO:root:[   38] Training loss: 0.51730909, Validation loss: 0.52462034, Gradient norm: 4.52090813
INFO:root:At the start of the epoch: mem (CPU python)=12094.59375MB; mem (CPU total)=20196.30859375MB
INFO:root:[   39] Training loss: 0.51731306, Validation loss: 0.50935583, Gradient norm: 4.79605066
INFO:root:At the start of the epoch: mem (CPU python)=12115.7578125MB; mem (CPU total)=20229.0390625MB
INFO:root:[   40] Training loss: 0.52127911, Validation loss: 0.51885024, Gradient norm: 4.48753214
INFO:root:At the start of the epoch: mem (CPU python)=12136.91796875MB; mem (CPU total)=20259.70703125MB
INFO:root:[   41] Training loss: 0.50746555, Validation loss: 0.49487153, Gradient norm: 4.46280496
INFO:root:At the start of the epoch: mem (CPU python)=12158.08203125MB; mem (CPU total)=20292.4375MB
INFO:root:[   42] Training loss: 0.51574773, Validation loss: 0.51640920, Gradient norm: 5.05312307
INFO:root:At the start of the epoch: mem (CPU python)=12179.24609375MB; mem (CPU total)=20326.421875MB
INFO:root:[   43] Training loss: 0.51691461, Validation loss: 0.51220595, Gradient norm: 4.92745362
INFO:root:At the start of the epoch: mem (CPU python)=12200.41015625MB; mem (CPU total)=20358.1640625MB
INFO:root:[   44] Training loss: 0.51110533, Validation loss: 0.52608433, Gradient norm: 4.51327267
INFO:root:At the start of the epoch: mem (CPU python)=12221.57421875MB; mem (CPU total)=20391.125MB
INFO:root:[   45] Training loss: 0.51669374, Validation loss: 0.50324514, Gradient norm: 5.03435991
INFO:root:At the start of the epoch: mem (CPU python)=12242.7421875MB; mem (CPU total)=20423.4921875MB
INFO:root:[   46] Training loss: 0.50595344, Validation loss: 0.50181351, Gradient norm: 4.85448909
INFO:root:At the start of the epoch: mem (CPU python)=12263.90625MB; mem (CPU total)=20455.7109375MB
INFO:root:[   47] Training loss: 0.51167201, Validation loss: 0.48800787, Gradient norm: 4.80445809
INFO:root:At the start of the epoch: mem (CPU python)=12285.0703125MB; mem (CPU total)=20489.8046875MB
INFO:root:[   48] Training loss: 0.50858886, Validation loss: 0.48843478, Gradient norm: 5.03106695
INFO:root:At the start of the epoch: mem (CPU python)=12306.234375MB; mem (CPU total)=20520.23828125MB
INFO:root:[   49] Training loss: 0.51317173, Validation loss: 0.51174035, Gradient norm: 5.17007408
INFO:root:At the start of the epoch: mem (CPU python)=12327.39453125MB; mem (CPU total)=20555.671875MB
INFO:root:[   50] Training loss: 0.50860767, Validation loss: 0.52203880, Gradient norm: 4.91438581
INFO:root:At the start of the epoch: mem (CPU python)=12348.5625MB; mem (CPU total)=20584.43359375MB
INFO:root:[   51] Training loss: 0.50820313, Validation loss: 0.51146913, Gradient norm: 5.79412261
INFO:root:At the start of the epoch: mem (CPU python)=12369.7265625MB; mem (CPU total)=20618.640625MB
INFO:root:[   52] Training loss: 0.50626168, Validation loss: 0.48848425, Gradient norm: 5.20435430
INFO:root:At the start of the epoch: mem (CPU python)=12390.890625MB; mem (CPU total)=20649.6640625MB
INFO:root:[   53] Training loss: 0.50628065, Validation loss: 0.52454690, Gradient norm: 5.47151284
INFO:root:At the start of the epoch: mem (CPU python)=12412.0546875MB; mem (CPU total)=20682.2578125MB
INFO:root:[   54] Training loss: 0.50661359, Validation loss: 0.49591970, Gradient norm: 5.67019802
INFO:root:At the start of the epoch: mem (CPU python)=12433.21484375MB; mem (CPU total)=20715.48046875MB
INFO:root:[   55] Training loss: 0.50397857, Validation loss: 0.48990199, Gradient norm: 5.25899511
INFO:root:At the start of the epoch: mem (CPU python)=12454.3828125MB; mem (CPU total)=20747.94140625MB
INFO:root:[   56] Training loss: 0.50122210, Validation loss: 0.49869030, Gradient norm: 5.67430727
INFO:root:At the start of the epoch: mem (CPU python)=12475.546875MB; mem (CPU total)=20783.9140625MB
INFO:root:[   57] Training loss: 0.50793660, Validation loss: 0.48651269, Gradient norm: 5.83132412
INFO:root:At the start of the epoch: mem (CPU python)=12496.7109375MB; mem (CPU total)=20811.8203125MB
INFO:root:[   58] Training loss: 0.49965718, Validation loss: 0.52003037, Gradient norm: 5.68058492
INFO:root:At the start of the epoch: mem (CPU python)=12517.87109375MB; mem (CPU total)=20845.5546875MB
INFO:root:[   59] Training loss: 0.50434894, Validation loss: 0.49299535, Gradient norm: 5.88491921
INFO:root:At the start of the epoch: mem (CPU python)=12539.03515625MB; mem (CPU total)=20878.734375MB
INFO:root:[   60] Training loss: 0.50205042, Validation loss: 0.52499821, Gradient norm: 5.76842582
INFO:root:At the start of the epoch: mem (CPU python)=12560.19921875MB; mem (CPU total)=20911.33203125MB
INFO:root:[   61] Training loss: 0.51108477, Validation loss: 0.50607530, Gradient norm: 5.94788464
INFO:root:At the start of the epoch: mem (CPU python)=12581.36328125MB; mem (CPU total)=20943.80078125MB
INFO:root:[   62] Training loss: 0.49891208, Validation loss: 0.50545938, Gradient norm: 5.74378503
INFO:root:At the start of the epoch: mem (CPU python)=12602.53125MB; mem (CPU total)=20976.59765625MB
INFO:root:[   63] Training loss: 0.51101619, Validation loss: 0.50067966, Gradient norm: 6.02789969
INFO:root:At the start of the epoch: mem (CPU python)=12623.6953125MB; mem (CPU total)=21008.33984375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   64] Training loss: 0.50905471, Validation loss: 0.51388655, Gradient norm: 5.93715035
INFO:root:At the start of the epoch: mem (CPU python)=12644.859375MB; mem (CPU total)=21041.80859375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   65] Training loss: 0.47116913, Validation loss: 0.46643928, Gradient norm: 4.71734752
INFO:root:At the start of the epoch: mem (CPU python)=12666.0234375MB; mem (CPU total)=21073.5625MB
INFO:root:[   66] Training loss: 0.45846588, Validation loss: 0.46349105, Gradient norm: 3.37255840
INFO:root:At the start of the epoch: mem (CPU python)=12687.19140625MB; mem (CPU total)=21107.5546875MB
INFO:root:[   67] Training loss: 0.45779199, Validation loss: 0.46363206, Gradient norm: 4.23269285
INFO:root:At the start of the epoch: mem (CPU python)=12708.3515625MB; mem (CPU total)=21137.37890625MB
INFO:root:[   68] Training loss: 0.45810932, Validation loss: 0.46127164, Gradient norm: 4.98881354
INFO:root:At the start of the epoch: mem (CPU python)=12729.515625MB; mem (CPU total)=21172.26171875MB
INFO:root:[   69] Training loss: 0.46404983, Validation loss: 0.45921081, Gradient norm: 7.19627351
INFO:root:At the start of the epoch: mem (CPU python)=12750.6796875MB; mem (CPU total)=21203.31640625MB
INFO:root:[   70] Training loss: 0.46526152, Validation loss: 0.45951259, Gradient norm: 7.41978140
INFO:root:At the start of the epoch: mem (CPU python)=12771.84375MB; mem (CPU total)=21237.59375MB
INFO:root:[   71] Training loss: 0.46109294, Validation loss: 0.45815084, Gradient norm: 6.45194225
INFO:root:At the start of the epoch: mem (CPU python)=12793.01171875MB; mem (CPU total)=21269.96484375MB
INFO:root:[   72] Training loss: 0.45986253, Validation loss: 0.46359584, Gradient norm: 6.67735158
INFO:root:At the start of the epoch: mem (CPU python)=12814.16796875MB; mem (CPU total)=21301.52734375MB
INFO:root:[   73] Training loss: 0.45981020, Validation loss: 0.46347859, Gradient norm: 7.34375086
INFO:root:At the start of the epoch: mem (CPU python)=12835.3359375MB; mem (CPU total)=21336.4609375MB
INFO:root:[   74] Training loss: 0.46125853, Validation loss: 0.46116640, Gradient norm: 8.03480810
INFO:root:At the start of the epoch: mem (CPU python)=12856.5MB; mem (CPU total)=21366.48828125MB
INFO:root:[   75] Training loss: 0.46067726, Validation loss: 0.46324965, Gradient norm: 8.22237325
INFO:root:At the start of the epoch: mem (CPU python)=12877.6640625MB; mem (CPU total)=21401.90234375MB
INFO:root:[   76] Training loss: 0.46077356, Validation loss: 0.46087141, Gradient norm: 8.49998221
INFO:root:At the start of the epoch: mem (CPU python)=12898.828125MB; mem (CPU total)=21436.52734375MB
INFO:root:[   77] Training loss: 0.46390507, Validation loss: 0.46056675, Gradient norm: 9.30123133
INFO:root:At the start of the epoch: mem (CPU python)=12919.98828125MB; mem (CPU total)=21467.109375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   78] Training loss: 0.46226738, Validation loss: 0.46126805, Gradient norm: 9.56480532
INFO:root:At the start of the epoch: mem (CPU python)=12941.15625MB; mem (CPU total)=21500.3125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   79] Training loss: 0.45513431, Validation loss: 0.45468087, Gradient norm: 6.84391861
INFO:root:At the start of the epoch: mem (CPU python)=12962.33203125MB; mem (CPU total)=21530.26953125MB
INFO:root:[   80] Training loss: 0.45194854, Validation loss: 0.45369356, Gradient norm: 4.69485198
INFO:root:At the start of the epoch: mem (CPU python)=12983.49609375MB; mem (CPU total)=21568.41796875MB
INFO:root:[   81] Training loss: 0.45059622, Validation loss: 0.45564526, Gradient norm: 5.23054898
INFO:root:At the start of the epoch: mem (CPU python)=13004.6796875MB; mem (CPU total)=21596.1796875MB
INFO:root:[   82] Training loss: 0.45142362, Validation loss: 0.45190511, Gradient norm: 6.95399290
INFO:root:At the start of the epoch: mem (CPU python)=13025.84765625MB; mem (CPU total)=21629.015625MB
INFO:root:[   83] Training loss: 0.45156650, Validation loss: 0.45402799, Gradient norm: 6.14826670
INFO:root:At the start of the epoch: mem (CPU python)=13047.0234375MB; mem (CPU total)=21663.9453125MB
INFO:root:[   84] Training loss: 0.45129042, Validation loss: 0.45280208, Gradient norm: 6.69820593
INFO:root:At the start of the epoch: mem (CPU python)=13068.1953125MB; mem (CPU total)=21695.625MB
INFO:root:[   85] Training loss: 0.45134484, Validation loss: 0.45472802, Gradient norm: 6.85680881
INFO:root:At the start of the epoch: mem (CPU python)=13089.375MB; mem (CPU total)=21729.5625MB
INFO:root:[   86] Training loss: 0.45186854, Validation loss: 0.45548172, Gradient norm: 7.94796160
INFO:root:At the start of the epoch: mem (CPU python)=13110.5390625MB; mem (CPU total)=21761.421875MB
INFO:root:[   87] Training loss: 0.45154540, Validation loss: 0.45443700, Gradient norm: 8.35788862
INFO:root:At the start of the epoch: mem (CPU python)=13131.7109375MB; mem (CPU total)=21793.90234375MB
INFO:root:[   88] Training loss: 0.45170399, Validation loss: 0.45505772, Gradient norm: 8.52887356
INFO:root:At the start of the epoch: mem (CPU python)=13152.87109375MB; mem (CPU total)=21825.17578125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   89] Training loss: 0.45176798, Validation loss: 0.45609368, Gradient norm: 9.52455050
INFO:root:At the start of the epoch: mem (CPU python)=13174.0390625MB; mem (CPU total)=21858.75390625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   90] Training loss: 0.45050098, Validation loss: 0.45208189, Gradient norm: 7.82766779
INFO:root:At the start of the epoch: mem (CPU python)=13195.2265625MB; mem (CPU total)=21892.68359375MB
INFO:root:[   91] Training loss: 0.44932338, Validation loss: 0.45033561, Gradient norm: 4.71923428
INFO:root:At the start of the epoch: mem (CPU python)=13216.390625MB; mem (CPU total)=21924.54296875MB
INFO:root:[   92] Training loss: 0.44968580, Validation loss: 0.45240063, Gradient norm: 5.30907247
INFO:root:At the start of the epoch: mem (CPU python)=13237.57421875MB; mem (CPU total)=21958.171875MB
INFO:root:[   93] Training loss: 0.44938931, Validation loss: 0.45102569, Gradient norm: 4.97331830
INFO:root:At the start of the epoch: mem (CPU python)=13258.73828125MB; mem (CPU total)=21990.265625MB
INFO:root:[   94] Training loss: 0.44971512, Validation loss: 0.45249415, Gradient norm: 5.47184312
INFO:root:At the start of the epoch: mem (CPU python)=13279.90234375MB; mem (CPU total)=22023.83984375MB
INFO:root:[   95] Training loss: 0.44948190, Validation loss: 0.45129646, Gradient norm: 5.57471864
INFO:root:At the start of the epoch: mem (CPU python)=13301.0859375MB; mem (CPU total)=22059.27734375MB
INFO:root:[   96] Training loss: 0.44953565, Validation loss: 0.45175418, Gradient norm: 6.31253420
INFO:root:At the start of the epoch: mem (CPU python)=13322.25MB; mem (CPU total)=22092.64453125MB
INFO:root:[   97] Training loss: 0.44940763, Validation loss: 0.45268278, Gradient norm: 5.89567664
INFO:root:At the start of the epoch: mem (CPU python)=13343.42578125MB; mem (CPU total)=22127.8359375MB
INFO:root:[   98] Training loss: 0.44934463, Validation loss: 0.45141391, Gradient norm: 7.10141459
INFO:root:At the start of the epoch: mem (CPU python)=13364.58984375MB; mem (CPU total)=22154.7890625MB
INFO:root:[   99] Training loss: 0.44942105, Validation loss: 0.45200113, Gradient norm: 6.20391057
INFO:root:At the start of the epoch: mem (CPU python)=13385.75390625MB; mem (CPU total)=22188.43359375MB
INFO:root:[  100] Training loss: 0.44942397, Validation loss: 0.45107237, Gradient norm: 6.67258580
INFO:root:At the start of the epoch: mem (CPU python)=13406.9453125MB; mem (CPU total)=22221.28125MB
INFO:root:EP 100: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=13427.86328125MB; mem (CPU total)=22251.32421875MB
INFO:root:Training the model took 2959.682s.
INFO:root:Emptying the cuda cache took 0.037s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.39905
INFO:root:EnergyScoreValidation: 0.30214
INFO:root:CRPSValidation: 0.11796
INFO:root:Gaussian NLLValidation: 0.06316
INFO:root:CoverageValidation: 0.77603
INFO:root:IntervalWidthValidation: 0.4376
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.41752
INFO:root:EnergyScoreTest: 0.31895
INFO:root:CRPSTest: 0.12653
INFO:root:Gaussian NLLTest: 0.27379
INFO:root:CoverageTest: 0.74329
INFO:root:IntervalWidthTest: 0.43454
INFO:root:After validation: mem (CPU python)=13734.8671875MB; mem (CPU total)=22360.52734375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=13734.8671875MB; mem (CPU total)=22361.46484375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=13734.8671875MB; mem (CPU total)=22361.46484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22363.64453125MB
INFO:root:[    1] Training loss: 0.85787321, Validation loss: 0.75659861, Gradient norm: 0.37741049
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22386.39453125MB
INFO:root:[    2] Training loss: 0.75235226, Validation loss: 0.75787624, Gradient norm: 0.45198647
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22406.8359375MB
INFO:root:[    3] Training loss: 0.74820329, Validation loss: 0.74128211, Gradient norm: 0.67774036
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22429.70703125MB
INFO:root:[    4] Training loss: 0.73563716, Validation loss: 0.74671809, Gradient norm: 0.91465665
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22452.0703125MB
INFO:root:[    5] Training loss: 0.73213889, Validation loss: 0.73287926, Gradient norm: 1.19943830
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22473.5546875MB
INFO:root:[    6] Training loss: 0.71019111, Validation loss: 0.69103910, Gradient norm: 1.50597319
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22498.67578125MB
INFO:root:[    7] Training loss: 0.68295555, Validation loss: 0.67879177, Gradient norm: 1.88972547
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22516.82421875MB
INFO:root:[    8] Training loss: 0.66669385, Validation loss: 0.67313253, Gradient norm: 2.16695024
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22543.0390625MB
INFO:root:[    9] Training loss: 0.65266512, Validation loss: 0.66083837, Gradient norm: 2.51791419
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22573.546875MB
INFO:root:[   10] Training loss: 0.64526523, Validation loss: 0.62807031, Gradient norm: 2.61998965
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22606.96875MB
INFO:root:[   11] Training loss: 0.63745692, Validation loss: 0.63477571, Gradient norm: 2.92737929
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22640.59765625MB
INFO:root:[   12] Training loss: 0.63247349, Validation loss: 0.63991056, Gradient norm: 3.16482314
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22672.7734375MB
INFO:root:[   13] Training loss: 0.62233415, Validation loss: 0.61699552, Gradient norm: 3.26633613
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22706.98046875MB
INFO:root:[   14] Training loss: 0.61212903, Validation loss: 0.60983353, Gradient norm: 3.47151277
INFO:root:At the start of the epoch: mem (CPU python)=13734.8671875MB; mem (CPU total)=22738.50390625MB
INFO:root:[   15] Training loss: 0.61247832, Validation loss: 0.60034718, Gradient norm: 3.80011482
INFO:root:At the start of the epoch: mem (CPU python)=13752.484375MB; mem (CPU total)=22773.9375MB
INFO:root:[   16] Training loss: 0.60725671, Validation loss: 0.60540594, Gradient norm: 4.04169185
INFO:root:At the start of the epoch: mem (CPU python)=13773.6484375MB; mem (CPU total)=22805.1484375MB
INFO:root:[   17] Training loss: 0.60401644, Validation loss: 0.64350642, Gradient norm: 4.00913034
INFO:root:At the start of the epoch: mem (CPU python)=13794.828125MB; mem (CPU total)=22838.35546875MB
INFO:root:[   18] Training loss: 0.60328019, Validation loss: 0.61250017, Gradient norm: 4.20453185
INFO:root:At the start of the epoch: mem (CPU python)=13815.99609375MB; mem (CPU total)=22871.5546875MB
INFO:root:[   19] Training loss: 0.60091372, Validation loss: 0.59707843, Gradient norm: 4.21477616
INFO:root:At the start of the epoch: mem (CPU python)=13837.17578125MB; mem (CPU total)=22904.265625MB
INFO:root:[   20] Training loss: 0.59440708, Validation loss: 0.62856569, Gradient norm: 4.17520452
INFO:root:At the start of the epoch: mem (CPU python)=13858.33984375MB; mem (CPU total)=22937.71875MB
INFO:root:[   21] Training loss: 0.60346285, Validation loss: 0.58954986, Gradient norm: 4.63170698
INFO:root:At the start of the epoch: mem (CPU python)=13879.5234375MB; mem (CPU total)=22970.375MB
INFO:root:[   22] Training loss: 0.59452437, Validation loss: 0.58007306, Gradient norm: 4.50590962
INFO:root:At the start of the epoch: mem (CPU python)=13900.69921875MB; mem (CPU total)=23006.5390625MB
INFO:root:[   23] Training loss: 0.59060428, Validation loss: 0.59157755, Gradient norm: 4.63945721
INFO:root:At the start of the epoch: mem (CPU python)=13921.85546875MB; mem (CPU total)=23036.66015625MB
INFO:root:[   24] Training loss: 0.59028815, Validation loss: 0.57972585, Gradient norm: 4.83849169
INFO:root:At the start of the epoch: mem (CPU python)=13943.0390625MB; mem (CPU total)=23070.68359375MB
INFO:root:[   25] Training loss: 0.58881935, Validation loss: 0.58224689, Gradient norm: 5.13021957
INFO:root:At the start of the epoch: mem (CPU python)=13964.2109375MB; mem (CPU total)=23102.92578125MB
INFO:root:[   26] Training loss: 0.59627529, Validation loss: 0.60367086, Gradient norm: 5.66695768
INFO:root:At the start of the epoch: mem (CPU python)=13985.375MB; mem (CPU total)=23135.8046875MB
INFO:root:[   27] Training loss: 0.59150071, Validation loss: 0.59535731, Gradient norm: 5.77157123
INFO:root:At the start of the epoch: mem (CPU python)=14006.5390625MB; mem (CPU total)=23169.7421875MB
INFO:root:[   28] Training loss: 0.60039599, Validation loss: 0.57626632, Gradient norm: 6.11610708
INFO:root:At the start of the epoch: mem (CPU python)=14027.72265625MB; mem (CPU total)=23202.609375MB
INFO:root:[   29] Training loss: 0.59394953, Validation loss: 0.58571972, Gradient norm: 5.45558191
INFO:root:At the start of the epoch: mem (CPU python)=14060.53515625MB; mem (CPU total)=23249.4765625MB
INFO:root:[   30] Training loss: 0.59550551, Validation loss: 0.62192814, Gradient norm: 6.01783907
INFO:root:At the start of the epoch: mem (CPU python)=14082.0625MB; mem (CPU total)=23280.08984375MB
INFO:root:[   31] Training loss: 0.58990868, Validation loss: 0.61976192, Gradient norm: 5.73771850
INFO:root:At the start of the epoch: mem (CPU python)=14103.2265625MB; mem (CPU total)=23318.078125MB
INFO:root:[   32] Training loss: 0.59974736, Validation loss: 0.58980461, Gradient norm: 6.69562527
INFO:root:At the start of the epoch: mem (CPU python)=14124.40234375MB; mem (CPU total)=23347.19140625MB
INFO:root:[   33] Training loss: 0.59143865, Validation loss: 0.59218824, Gradient norm: 6.22828479
INFO:root:At the start of the epoch: mem (CPU python)=14145.5703125MB; mem (CPU total)=23380.94140625MB
INFO:root:[   34] Training loss: 0.59665939, Validation loss: 0.57925986, Gradient norm: 6.47816213
INFO:root:At the start of the epoch: mem (CPU python)=14166.734375MB; mem (CPU total)=23415.12890625MB
INFO:root:[   35] Training loss: 0.58862647, Validation loss: 0.60205654, Gradient norm: 6.27893712
INFO:root:At the start of the epoch: mem (CPU python)=14187.921875MB; mem (CPU total)=23446.97265625MB
INFO:root:[   36] Training loss: 0.58960867, Validation loss: 0.58839634, Gradient norm: 6.40481101
INFO:root:At the start of the epoch: mem (CPU python)=14209.0859375MB; mem (CPU total)=23480.3125MB
INFO:root:[   37] Training loss: 0.58810893, Validation loss: 0.58373796, Gradient norm: 6.55388591
INFO:root:At the start of the epoch: mem (CPU python)=14230.265625MB; mem (CPU total)=23513.93359375MB
INFO:root:[   38] Training loss: 0.59936467, Validation loss: 0.58936888, Gradient norm: 7.48973163
INFO:root:At the start of the epoch: mem (CPU python)=14251.4296875MB; mem (CPU total)=23550.1484375MB
INFO:root:[   39] Training loss: 0.59413785, Validation loss: 0.58176039, Gradient norm: 7.03150209
INFO:root:At the start of the epoch: mem (CPU python)=14272.61328125MB; mem (CPU total)=23581.69921875MB
INFO:root:[   40] Training loss: 0.59650412, Validation loss: 0.59910398, Gradient norm: 7.12467854
INFO:root:At the start of the epoch: mem (CPU python)=14293.77734375MB; mem (CPU total)=23613.25MB
INFO:root:[   41] Training loss: 0.58898895, Validation loss: 0.59160218, Gradient norm: 7.25440078
INFO:root:At the start of the epoch: mem (CPU python)=14314.953125MB; mem (CPU total)=23647.2265625MB
INFO:root:[   42] Training loss: 0.58885755, Validation loss: 0.58225678, Gradient norm: 6.70233576
INFO:root:At the start of the epoch: mem (CPU python)=14336.11328125MB; mem (CPU total)=23679.35546875MB
INFO:root:[   43] Training loss: 0.58855999, Validation loss: 0.58216054, Gradient norm: 7.20968098
INFO:root:At the start of the epoch: mem (CPU python)=14357.27734375MB; mem (CPU total)=23712.8125MB
INFO:root:[   44] Training loss: 0.59830646, Validation loss: 0.60678104, Gradient norm: 8.38340929
INFO:root:At the start of the epoch: mem (CPU python)=14378.46484375MB; mem (CPU total)=23745.140625MB
INFO:root:[   45] Training loss: 0.59906334, Validation loss: 0.59691647, Gradient norm: 8.13261481
INFO:root:At the start of the epoch: mem (CPU python)=14399.62890625MB; mem (CPU total)=23784.0546875MB
INFO:root:[   46] Training loss: 0.59359925, Validation loss: 0.58115995, Gradient norm: 7.76192966
INFO:root:At the start of the epoch: mem (CPU python)=14420.8125MB; mem (CPU total)=23812.6640625MB
INFO:root:[   47] Training loss: 0.60309559, Validation loss: 0.67017473, Gradient norm: 7.97863957
INFO:root:At the start of the epoch: mem (CPU python)=14441.9765625MB; mem (CPU total)=23846.24609375MB
INFO:root:[   48] Training loss: 0.59576426, Validation loss: 0.57478279, Gradient norm: 7.56575412
INFO:root:At the start of the epoch: mem (CPU python)=14463.15625MB; mem (CPU total)=23880.7578125MB
INFO:root:[   49] Training loss: 0.59151356, Validation loss: 0.61431768, Gradient norm: 8.18204752
INFO:root:At the start of the epoch: mem (CPU python)=14484.3203125MB; mem (CPU total)=23912.80078125MB
INFO:root:[   50] Training loss: 0.60028116, Validation loss: 0.59697201, Gradient norm: 8.46335729
INFO:root:At the start of the epoch: mem (CPU python)=14505.5MB; mem (CPU total)=23946.60546875MB
INFO:root:[   51] Training loss: 0.59081994, Validation loss: 0.64903456, Gradient norm: 7.70022951
INFO:root:At the start of the epoch: mem (CPU python)=14526.6640625MB; mem (CPU total)=23979.0625MB
INFO:root:[   52] Training loss: 0.59744211, Validation loss: 0.57876577, Gradient norm: 8.38969885
INFO:root:At the start of the epoch: mem (CPU python)=14547.83984375MB; mem (CPU total)=24015.1484375MB
INFO:root:[   53] Training loss: 0.60814360, Validation loss: 0.58527471, Gradient norm: 8.94114822
INFO:root:At the start of the epoch: mem (CPU python)=14569.00390625MB; mem (CPU total)=24045.21484375MB
INFO:root:[   54] Training loss: 0.59776988, Validation loss: 0.58281454, Gradient norm: 8.38388926
INFO:root:At the start of the epoch: mem (CPU python)=14590.16796875MB; mem (CPU total)=24081.05859375MB
INFO:root:[   55] Training loss: 0.59245509, Validation loss: 0.57442990, Gradient norm: 7.83007273
INFO:root:At the start of the epoch: mem (CPU python)=14611.359375MB; mem (CPU total)=24112.7890625MB
INFO:root:[   56] Training loss: 0.59419347, Validation loss: 0.58878348, Gradient norm: 8.64180540
INFO:root:At the start of the epoch: mem (CPU python)=14632.51953125MB; mem (CPU total)=24146.109375MB
INFO:root:[   57] Training loss: 0.59343122, Validation loss: 0.59447949, Gradient norm: 9.06653950
INFO:root:At the start of the epoch: mem (CPU python)=14653.70703125MB; mem (CPU total)=24180.55859375MB
INFO:root:[   58] Training loss: 0.59806146, Validation loss: 0.57475731, Gradient norm: 9.11644346
INFO:root:At the start of the epoch: mem (CPU python)=14674.8671875MB; mem (CPU total)=24213.2265625MB
INFO:root:[   59] Training loss: 0.58681061, Validation loss: 0.56976934, Gradient norm: 8.63941537
INFO:root:At the start of the epoch: mem (CPU python)=14696.04296875MB; mem (CPU total)=24250.375MB
INFO:root:[   60] Training loss: 0.58811916, Validation loss: 0.57358017, Gradient norm: 9.76254502
INFO:root:At the start of the epoch: mem (CPU python)=14717.203125MB; mem (CPU total)=24280.3046875MB
INFO:root:[   61] Training loss: 0.60203000, Validation loss: 0.57464920, Gradient norm: 10.43767335
INFO:root:At the start of the epoch: mem (CPU python)=14738.3828125MB; mem (CPU total)=24314.74609375MB
INFO:root:[   62] Training loss: 0.59862900, Validation loss: 0.61780897, Gradient norm: 10.09862834
INFO:root:At the start of the epoch: mem (CPU python)=14759.546875MB; mem (CPU total)=24347.05859375MB
INFO:root:[   63] Training loss: 0.61375095, Validation loss: 0.60842214, Gradient norm: 9.96924487
INFO:root:At the start of the epoch: mem (CPU python)=14780.73046875MB; mem (CPU total)=24383.87890625MB
INFO:root:[   64] Training loss: 0.59657590, Validation loss: 0.59532942, Gradient norm: 9.29530054
INFO:root:At the start of the epoch: mem (CPU python)=14801.89453125MB; mem (CPU total)=24413.3671875MB
INFO:root:[   65] Training loss: 0.60413466, Validation loss: 0.61489283, Gradient norm: 9.58679418
INFO:root:At the start of the epoch: mem (CPU python)=14823.07421875MB; mem (CPU total)=24448.125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   66] Training loss: 0.60429944, Validation loss: 0.61085381, Gradient norm: 9.89278207
INFO:root:At the start of the epoch: mem (CPU python)=14844.2421875MB; mem (CPU total)=24482.93359375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   67] Training loss: 0.55743624, Validation loss: 0.55189355, Gradient norm: 7.74738273
INFO:root:At the start of the epoch: mem (CPU python)=14865.40625MB; mem (CPU total)=24514.19921875MB
INFO:root:[   68] Training loss: 0.54191999, Validation loss: 0.54331016, Gradient norm: 6.32550126
INFO:root:At the start of the epoch: mem (CPU python)=14886.59375MB; mem (CPU total)=24547.90234375MB
INFO:root:[   69] Training loss: 0.54229202, Validation loss: 0.54805011, Gradient norm: 7.43735138
INFO:root:At the start of the epoch: mem (CPU python)=14907.7578125MB; mem (CPU total)=24580.609375MB
INFO:root:[   70] Training loss: 0.54260954, Validation loss: 0.54481119, Gradient norm: 9.20884237
INFO:root:At the start of the epoch: mem (CPU python)=14928.93359375MB; mem (CPU total)=24615.54296875MB
INFO:root:[   71] Training loss: 0.54211986, Validation loss: 0.54026853, Gradient norm: 9.62197224
INFO:root:At the start of the epoch: mem (CPU python)=14950.1015625MB; mem (CPU total)=24646.58203125MB
INFO:root:[   72] Training loss: 0.54329072, Validation loss: 0.54708012, Gradient norm: 10.58900432
INFO:root:At the start of the epoch: mem (CPU python)=14971.27734375MB; mem (CPU total)=24681.52734375MB
INFO:root:[   73] Training loss: 0.54382866, Validation loss: 0.53783705, Gradient norm: 12.44816821
INFO:root:At the start of the epoch: mem (CPU python)=14992.4453125MB; mem (CPU total)=24714.90625MB
INFO:root:[   74] Training loss: 0.54476520, Validation loss: 0.54740714, Gradient norm: 12.11764652
INFO:root:At the start of the epoch: mem (CPU python)=15013.625MB; mem (CPU total)=24748.8671875MB
INFO:root:[   75] Training loss: 0.54622565, Validation loss: 0.54384068, Gradient norm: 12.72344323
INFO:root:At the start of the epoch: mem (CPU python)=15034.78515625MB; mem (CPU total)=24780.00390625MB
INFO:root:[   76] Training loss: 0.54565818, Validation loss: 0.55090085, Gradient norm: 13.72347287
INFO:root:At the start of the epoch: mem (CPU python)=15055.97265625MB; mem (CPU total)=24815.10546875MB
INFO:root:[   77] Training loss: 0.54839224, Validation loss: 0.55235874, Gradient norm: 15.09406745
INFO:root:At the start of the epoch: mem (CPU python)=15077.13671875MB; mem (CPU total)=24848.80859375MB
INFO:root:[   78] Training loss: 0.54715273, Validation loss: 0.55056676, Gradient norm: 15.30349986
INFO:root:At the start of the epoch: mem (CPU python)=15098.31640625MB; mem (CPU total)=24882.125MB
INFO:root:[   79] Training loss: 0.55361905, Validation loss: 0.59115991, Gradient norm: 15.93238437
INFO:root:At the start of the epoch: mem (CPU python)=15119.4765625MB; mem (CPU total)=24916.55859375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   80] Training loss: 0.55765537, Validation loss: 0.54657101, Gradient norm: 18.93758500
INFO:root:At the start of the epoch: mem (CPU python)=15140.640625MB; mem (CPU total)=24950.7265625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   81] Training loss: 0.53732147, Validation loss: 0.53919457, Gradient norm: 10.81088526
INFO:root:At the start of the epoch: mem (CPU python)=15161.8203125MB; mem (CPU total)=24982.91015625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   82] Training loss: 0.53437353, Validation loss: 0.53332185, Gradient norm: 11.38222432
INFO:root:At the start of the epoch: mem (CPU python)=15183.00390625MB; mem (CPU total)=25014.46875MB
INFO:root:[   83] Training loss: 0.53009250, Validation loss: 0.53035112, Gradient norm: 5.42368131
INFO:root:At the start of the epoch: mem (CPU python)=15204.16796875MB; mem (CPU total)=25050.3984375MB
INFO:root:[   84] Training loss: 0.52921023, Validation loss: 0.52970544, Gradient norm: 6.04491554
INFO:root:At the start of the epoch: mem (CPU python)=15225.33984375MB; mem (CPU total)=25081.75MB
INFO:root:[   85] Training loss: 0.52912004, Validation loss: 0.52910198, Gradient norm: 8.54794796
INFO:root:At the start of the epoch: mem (CPU python)=15246.50390625MB; mem (CPU total)=25119.26171875MB
INFO:root:[   86] Training loss: 0.52892681, Validation loss: 0.52993219, Gradient norm: 6.91906112
INFO:root:At the start of the epoch: mem (CPU python)=15267.6875MB; mem (CPU total)=25149.41015625MB
INFO:root:[   87] Training loss: 0.52845624, Validation loss: 0.52901073, Gradient norm: 7.56040187
INFO:root:At the start of the epoch: mem (CPU python)=15288.8515625MB; mem (CPU total)=25182.34375MB
INFO:root:[   88] Training loss: 0.52807786, Validation loss: 0.52914414, Gradient norm: 7.83006128
INFO:root:At the start of the epoch: mem (CPU python)=15310.03125MB; mem (CPU total)=25217.5625MB
INFO:root:[   89] Training loss: 0.52902806, Validation loss: 0.52865345, Gradient norm: 11.87547594
INFO:root:At the start of the epoch: mem (CPU python)=15331.1953125MB; mem (CPU total)=25250.17578125MB
INFO:root:[   90] Training loss: 0.52785805, Validation loss: 0.52932301, Gradient norm: 9.34171080
INFO:root:At the start of the epoch: mem (CPU python)=15352.37109375MB; mem (CPU total)=25284.63671875MB
INFO:root:[   91] Training loss: 0.52815860, Validation loss: 0.52857918, Gradient norm: 9.08453428
INFO:root:At the start of the epoch: mem (CPU python)=15373.53515625MB; mem (CPU total)=25317.3125MB
INFO:root:[   92] Training loss: 0.52879782, Validation loss: 0.52969434, Gradient norm: 11.84144189
INFO:root:At the start of the epoch: mem (CPU python)=15394.7109375MB; mem (CPU total)=25354.46484375MB
INFO:root:[   93] Training loss: 0.52845356, Validation loss: 0.52817139, Gradient norm: 13.04685573
INFO:root:At the start of the epoch: mem (CPU python)=15415.875MB; mem (CPU total)=25384.0234375MB
INFO:root:[   94] Training loss: 0.52881075, Validation loss: 0.52737638, Gradient norm: 13.10851545
INFO:root:At the start of the epoch: mem (CPU python)=15437.0625MB; mem (CPU total)=25417.703125MB
INFO:root:[   95] Training loss: 0.52811026, Validation loss: 0.53011512, Gradient norm: 13.23421814
INFO:root:At the start of the epoch: mem (CPU python)=15458.22265625MB; mem (CPU total)=25451.296875MB
INFO:root:[   96] Training loss: 0.52846150, Validation loss: 0.52892837, Gradient norm: 15.48032888
INFO:root:At the start of the epoch: mem (CPU python)=15479.390625MB; mem (CPU total)=25485.99609375MB
INFO:root:[   97] Training loss: 0.52761739, Validation loss: 0.53029991, Gradient norm: 11.42872172
INFO:root:At the start of the epoch: mem (CPU python)=15500.57421875MB; mem (CPU total)=25520.88671875MB
INFO:root:[   98] Training loss: 0.52751483, Validation loss: 0.52827277, Gradient norm: 12.42697951
INFO:root:At the start of the epoch: mem (CPU python)=15521.734375MB; mem (CPU total)=25552.33984375MB
INFO:root:[   99] Training loss: 0.52738836, Validation loss: 0.52856846, Gradient norm: 13.29863002
INFO:root:At the start of the epoch: mem (CPU python)=15542.91796875MB; mem (CPU total)=25584.828125MB
INFO:root:[  100] Training loss: 0.52783575, Validation loss: 0.52937214, Gradient norm: 14.59108249
INFO:root:At the start of the epoch: mem (CPU python)=15564.09765625MB; mem (CPU total)=25622.65234375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  101] Training loss: 0.52963994, Validation loss: 0.52781910, Gradient norm: 20.75804899
INFO:root:At the start of the epoch: mem (CPU python)=15585.26171875MB; mem (CPU total)=25656.69921875MB
INFO:root:[  102] Training loss: 0.52649623, Validation loss: 0.52841520, Gradient norm: 10.40093318
INFO:root:At the start of the epoch: mem (CPU python)=15606.44140625MB; mem (CPU total)=25687.359375MB
INFO:root:[  103] Training loss: 0.52620212, Validation loss: 0.52832901, Gradient norm: 9.92030786
INFO:root:At the start of the epoch: mem (CPU python)=15627.60546875MB; mem (CPU total)=25721.28515625MB
INFO:root:EP 103: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=15648.62109375MB; mem (CPU total)=25748.4453125MB
INFO:root:Training the model took 3312.58s.
INFO:root:Emptying the cuda cache took 0.037s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.46194
INFO:root:EnergyScoreValidation: 0.34688
INFO:root:CRPSValidation: 0.14545
INFO:root:Gaussian NLLValidation: 0.46501
INFO:root:CoverageValidation: 0.73134
INFO:root:IntervalWidthValidation: 0.52583
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.47527
INFO:root:EnergyScoreTest: 0.35882
INFO:root:CRPSTest: 0.15024
INFO:root:Gaussian NLLTest: 0.55564
INFO:root:CoverageTest: 0.71851
INFO:root:IntervalWidthTest: 0.52352
INFO:root:After validation: mem (CPU python)=15955.4609375MB; mem (CPU total)=25852.47265625MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=15955.4609375MB; mem (CPU total)=25857.3828125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=15955.4609375MB; mem (CPU total)=25857.875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=25861.734375MB
INFO:root:[    1] Training loss: 0.86891167, Validation loss: 0.76064663, Gradient norm: 0.34637988
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=25896.296875MB
INFO:root:[    2] Training loss: 0.75579077, Validation loss: 0.75527567, Gradient norm: 0.32521317
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=25935.1171875MB
INFO:root:[    3] Training loss: 0.74870224, Validation loss: 0.74266105, Gradient norm: 0.49350283
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=25967.52734375MB
INFO:root:[    4] Training loss: 0.73853562, Validation loss: 0.75785447, Gradient norm: 0.72496121
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=25999.6328125MB
INFO:root:[    5] Training loss: 0.72955113, Validation loss: 0.72409643, Gradient norm: 0.89998956
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=26034.6953125MB
INFO:root:[    6] Training loss: 0.71972897, Validation loss: 0.70636923, Gradient norm: 1.45220511
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=26071.16015625MB
INFO:root:[    7] Training loss: 0.70379241, Validation loss: 0.69020198, Gradient norm: 1.67728507
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=26103.09765625MB
INFO:root:[    8] Training loss: 0.70184450, Validation loss: 0.70153045, Gradient norm: 2.22934296
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=26137.57421875MB
INFO:root:[    9] Training loss: 0.69364184, Validation loss: 0.67942075, Gradient norm: 2.23005077
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=26170.9375MB
INFO:root:[   10] Training loss: 0.68926830, Validation loss: 0.69005939, Gradient norm: 2.54481972
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=26204.6484375MB
INFO:root:[   11] Training loss: 0.68188316, Validation loss: 0.68156351, Gradient norm: 2.67524463
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=26236.4453125MB
INFO:root:[   12] Training loss: 0.68188063, Validation loss: 0.68349556, Gradient norm: 3.15512023
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=26271.8515625MB
INFO:root:[   13] Training loss: 0.67536786, Validation loss: 0.67560479, Gradient norm: 3.21277077
INFO:root:At the start of the epoch: mem (CPU python)=15955.4609375MB; mem (CPU total)=26303.2734375MB
INFO:root:[   14] Training loss: 0.67403183, Validation loss: 0.67241278, Gradient norm: 3.74522560
INFO:root:At the start of the epoch: mem (CPU python)=15956.88671875MB; mem (CPU total)=26341.74609375MB
INFO:root:[   15] Training loss: 0.67376048, Validation loss: 0.65386013, Gradient norm: 3.94452138
INFO:root:At the start of the epoch: mem (CPU python)=15978.05078125MB; mem (CPU total)=26376.30078125MB
INFO:root:[   16] Training loss: 0.66484049, Validation loss: 0.66470671, Gradient norm: 3.69798727
INFO:root:At the start of the epoch: mem (CPU python)=15999.21484375MB; mem (CPU total)=26410.01953125MB
INFO:root:[   17] Training loss: 0.66370475, Validation loss: 0.65623923, Gradient norm: 4.15261081
INFO:root:At the start of the epoch: mem (CPU python)=16020.37890625MB; mem (CPU total)=26443.47265625MB
INFO:root:[   18] Training loss: 0.66228061, Validation loss: 0.68989975, Gradient norm: 4.33414097
INFO:root:At the start of the epoch: mem (CPU python)=16041.54296875MB; mem (CPU total)=26476.84375MB
INFO:root:[   19] Training loss: 0.66370195, Validation loss: 0.65605427, Gradient norm: 4.84173044
INFO:root:At the start of the epoch: mem (CPU python)=16062.7109375MB; mem (CPU total)=26513.73828125MB
INFO:root:[   20] Training loss: 0.66550693, Validation loss: 0.65406536, Gradient norm: 4.86485229
INFO:root:At the start of the epoch: mem (CPU python)=16083.875MB; mem (CPU total)=26545.23046875MB
INFO:root:[   21] Training loss: 0.65643164, Validation loss: 0.66042677, Gradient norm: 4.71910967
INFO:root:At the start of the epoch: mem (CPU python)=16116.66015625MB; mem (CPU total)=26590.60546875MB
INFO:root:[   22] Training loss: 0.65624225, Validation loss: 0.63810677, Gradient norm: 4.84918855
INFO:root:At the start of the epoch: mem (CPU python)=16138.203125MB; mem (CPU total)=26626.55078125MB
INFO:root:[   23] Training loss: 0.65728348, Validation loss: 0.66989421, Gradient norm: 5.39419042
INFO:root:At the start of the epoch: mem (CPU python)=16159.36328125MB; mem (CPU total)=26660.1640625MB
INFO:root:[   24] Training loss: 0.65988447, Validation loss: 0.67002676, Gradient norm: 5.61194134
INFO:root:At the start of the epoch: mem (CPU python)=16180.52734375MB; mem (CPU total)=26698.109375MB
INFO:root:[   25] Training loss: 0.65211311, Validation loss: 0.63676684, Gradient norm: 5.38782263
INFO:root:At the start of the epoch: mem (CPU python)=16201.69140625MB; mem (CPU total)=26730.9140625MB
INFO:root:[   26] Training loss: 0.65857245, Validation loss: 0.63914851, Gradient norm: 6.54189944
INFO:root:At the start of the epoch: mem (CPU python)=16222.85546875MB; mem (CPU total)=26763.4296875MB
INFO:root:[   27] Training loss: 0.65974131, Validation loss: 0.66571231, Gradient norm: 6.29455734
INFO:root:At the start of the epoch: mem (CPU python)=16244.01953125MB; mem (CPU total)=26798.53125MB
INFO:root:[   28] Training loss: 0.65535196, Validation loss: 0.68314653, Gradient norm: 6.33040592
INFO:root:At the start of the epoch: mem (CPU python)=16265.1875MB; mem (CPU total)=26831.31640625MB
INFO:root:[   29] Training loss: 0.64983584, Validation loss: 0.63565092, Gradient norm: 6.47729171
INFO:root:At the start of the epoch: mem (CPU python)=16286.3515625MB; mem (CPU total)=26866.9375MB
INFO:root:[   30] Training loss: 0.64764274, Validation loss: 0.62483837, Gradient norm: 7.42269666
INFO:root:At the start of the epoch: mem (CPU python)=16307.515625MB; mem (CPU total)=26899.59375MB
INFO:root:[   31] Training loss: 0.65056479, Validation loss: 0.62332585, Gradient norm: 7.61329976
INFO:root:At the start of the epoch: mem (CPU python)=16328.67578125MB; mem (CPU total)=26933.2421875MB
INFO:root:[   32] Training loss: 0.64206192, Validation loss: 0.62499869, Gradient norm: 7.34071896
INFO:root:At the start of the epoch: mem (CPU python)=16349.83984375MB; mem (CPU total)=26968.21484375MB
INFO:root:[   33] Training loss: 0.64359589, Validation loss: 0.62936082, Gradient norm: 7.74784990
INFO:root:At the start of the epoch: mem (CPU python)=16371.00390625MB; mem (CPU total)=27001.43359375MB
INFO:root:[   34] Training loss: 0.64008162, Validation loss: 0.64031992, Gradient norm: 7.72681624
INFO:root:At the start of the epoch: mem (CPU python)=16392.171875MB; mem (CPU total)=27036.29296875MB
INFO:root:[   35] Training loss: 0.64391386, Validation loss: 0.63452261, Gradient norm: 8.35661221
INFO:root:At the start of the epoch: mem (CPU python)=16413.3359375MB; mem (CPU total)=27069.2578125MB
INFO:root:[   36] Training loss: 0.63115892, Validation loss: 0.63323003, Gradient norm: 7.82601182
INFO:root:At the start of the epoch: mem (CPU python)=16434.5MB; mem (CPU total)=27103.23828125MB
INFO:root:[   37] Training loss: 0.63002389, Validation loss: 0.61722152, Gradient norm: 8.64379733
INFO:root:At the start of the epoch: mem (CPU python)=16455.6640625MB; mem (CPU total)=27137.078125MB
INFO:root:[   38] Training loss: 0.63713559, Validation loss: 0.62521807, Gradient norm: 9.71318319
INFO:root:At the start of the epoch: mem (CPU python)=16476.828125MB; mem (CPU total)=27170.73828125MB
INFO:root:[   39] Training loss: 0.64728618, Validation loss: 0.63036999, Gradient norm: 10.39347938
INFO:root:At the start of the epoch: mem (CPU python)=16497.98828125MB; mem (CPU total)=27205.69921875MB
INFO:root:[   40] Training loss: 0.63682136, Validation loss: 0.64826141, Gradient norm: 9.81441852
INFO:root:At the start of the epoch: mem (CPU python)=16519.15234375MB; mem (CPU total)=27238.80859375MB
INFO:root:[   41] Training loss: 0.64166671, Validation loss: 0.64914949, Gradient norm: 9.95256547
INFO:root:At the start of the epoch: mem (CPU python)=16540.31640625MB; mem (CPU total)=27272.87890625MB
INFO:root:[   42] Training loss: 0.62807052, Validation loss: 0.67436368, Gradient norm: 9.56567395
INFO:root:At the start of the epoch: mem (CPU python)=16561.48046875MB; mem (CPU total)=27307.0234375MB
INFO:root:[   43] Training loss: 0.64609756, Validation loss: 0.64366845, Gradient norm: 11.52461272
INFO:root:At the start of the epoch: mem (CPU python)=16582.64453125MB; mem (CPU total)=27340.44921875MB
INFO:root:[   44] Training loss: 0.64424344, Validation loss: 0.64687993, Gradient norm: 10.36400039
INFO:root:At the start of the epoch: mem (CPU python)=16603.80859375MB; mem (CPU total)=27375.875MB
INFO:root:[   45] Training loss: 0.63322676, Validation loss: 0.60958456, Gradient norm: 10.69826003
INFO:root:At the start of the epoch: mem (CPU python)=16624.9765625MB; mem (CPU total)=27408.8515625MB
INFO:root:[   46] Training loss: 0.65152770, Validation loss: 0.61416256, Gradient norm: 11.43039890
INFO:root:At the start of the epoch: mem (CPU python)=16646.13671875MB; mem (CPU total)=27442.8046875MB
INFO:root:[   47] Training loss: 0.63488162, Validation loss: 0.64902198, Gradient norm: 10.71369256
INFO:root:At the start of the epoch: mem (CPU python)=16667.3046875MB; mem (CPU total)=27476.75390625MB
INFO:root:[   48] Training loss: 0.63214108, Validation loss: 0.63222731, Gradient norm: 11.07895129
INFO:root:At the start of the epoch: mem (CPU python)=16688.46875MB; mem (CPU total)=27510.453125MB
INFO:root:[   49] Training loss: 0.63415461, Validation loss: 0.62392629, Gradient norm: 11.64887793
INFO:root:At the start of the epoch: mem (CPU python)=16709.6328125MB; mem (CPU total)=27546.12109375MB
INFO:root:[   50] Training loss: 0.65304127, Validation loss: 0.63461660, Gradient norm: 13.48812154
INFO:root:At the start of the epoch: mem (CPU python)=16730.79296875MB; mem (CPU total)=27579.08203125MB
INFO:root:[   51] Training loss: 0.63606421, Validation loss: 0.62387652, Gradient norm: 11.39927755
INFO:root:At the start of the epoch: mem (CPU python)=16751.95703125MB; mem (CPU total)=27612.79296875MB
INFO:root:[   52] Training loss: 0.63083857, Validation loss: 0.64914868, Gradient norm: 12.16638740
INFO:root:At the start of the epoch: mem (CPU python)=16773.125MB; mem (CPU total)=27647.24609375MB
INFO:root:[   53] Training loss: 0.65257799, Validation loss: 0.66753047, Gradient norm: 14.22221347
INFO:root:At the start of the epoch: mem (CPU python)=16794.2890625MB; mem (CPU total)=27680.71484375MB
INFO:root:[   54] Training loss: 0.65233748, Validation loss: 0.63366353, Gradient norm: 14.18873131
INFO:root:At the start of the epoch: mem (CPU python)=16815.453125MB; mem (CPU total)=27716.578125MB
INFO:root:[   55] Training loss: 0.65477090, Validation loss: 0.65581532, Gradient norm: 13.63294136
INFO:root:At the start of the epoch: mem (CPU python)=16836.6171875MB; mem (CPU total)=27749.546875MB
INFO:root:[   56] Training loss: 0.64250746, Validation loss: 0.64091108, Gradient norm: 12.98278094
INFO:root:At the start of the epoch: mem (CPU python)=16857.77734375MB; mem (CPU total)=27783.03125MB
INFO:root:[   57] Training loss: 0.65265942, Validation loss: 0.64318036, Gradient norm: 14.12231935
INFO:root:At the start of the epoch: mem (CPU python)=16878.9453125MB; mem (CPU total)=27817.73046875MB
INFO:root:[   58] Training loss: 0.63252687, Validation loss: 0.61715757, Gradient norm: 12.28649000
INFO:root:At the start of the epoch: mem (CPU python)=16900.109375MB; mem (CPU total)=27851.18359375MB
INFO:root:[   59] Training loss: 0.65198096, Validation loss: 0.66206845, Gradient norm: 14.87932308
INFO:root:At the start of the epoch: mem (CPU python)=16921.2734375MB; mem (CPU total)=27887.5390625MB
INFO:root:[   60] Training loss: 0.64777707, Validation loss: 0.64446972, Gradient norm: 13.86068665
INFO:root:At the start of the epoch: mem (CPU python)=16942.43359375MB; mem (CPU total)=27919.53515625MB
INFO:root:[   61] Training loss: 0.63852721, Validation loss: 0.61333634, Gradient norm: 13.82949163
INFO:root:At the start of the epoch: mem (CPU python)=16963.59765625MB; mem (CPU total)=27953.23046875MB
INFO:root:[   62] Training loss: 0.65405204, Validation loss: 0.65985668, Gradient norm: 15.58384935
INFO:root:At the start of the epoch: mem (CPU python)=16984.76171875MB; mem (CPU total)=27987.9296875MB
INFO:root:[   63] Training loss: 0.65284400, Validation loss: 0.66191076, Gradient norm: 15.31385322
INFO:root:At the start of the epoch: mem (CPU python)=17005.9296875MB; mem (CPU total)=28022.40625MB
INFO:root:[   64] Training loss: 0.65541556, Validation loss: 0.67308827, Gradient norm: 15.31359218
INFO:root:At the start of the epoch: mem (CPU python)=17027.09375MB; mem (CPU total)=28059.16796875MB
INFO:root:[   65] Training loss: 0.64555090, Validation loss: 0.64091014, Gradient norm: 14.13068089
INFO:root:At the start of the epoch: mem (CPU python)=17048.2578125MB; mem (CPU total)=28090.94921875MB
INFO:root:[   66] Training loss: 0.64499624, Validation loss: 0.62706770, Gradient norm: 14.20956810
INFO:root:At the start of the epoch: mem (CPU python)=17069.421875MB; mem (CPU total)=28124.62109375MB
INFO:root:[   67] Training loss: 0.64328763, Validation loss: 0.64569346, Gradient norm: 14.79969709
INFO:root:At the start of the epoch: mem (CPU python)=17090.5859375MB; mem (CPU total)=28160.0234375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   68] Training loss: 0.66217312, Validation loss: 0.66306984, Gradient norm: 17.48853766
INFO:root:At the start of the epoch: mem (CPU python)=17111.75390625MB; mem (CPU total)=28193.94921875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   69] Training loss: 0.60088795, Validation loss: 0.59737232, Gradient norm: 11.90184125
INFO:root:At the start of the epoch: mem (CPU python)=17132.9140625MB; mem (CPU total)=28229.36328125MB
INFO:root:[   70] Training loss: 0.58414842, Validation loss: 0.58665203, Gradient norm: 10.38555344
INFO:root:At the start of the epoch: mem (CPU python)=17154.078125MB; mem (CPU total)=28262.140625MB
INFO:root:[   71] Training loss: 0.58182796, Validation loss: 0.58011278, Gradient norm: 12.35629932
INFO:root:At the start of the epoch: mem (CPU python)=17175.2421875MB; mem (CPU total)=28295.65234375MB
INFO:root:[   72] Training loss: 0.58416957, Validation loss: 0.58284616, Gradient norm: 14.15008034
INFO:root:At the start of the epoch: mem (CPU python)=17196.40625MB; mem (CPU total)=28330.76171875MB
INFO:root:[   73] Training loss: 0.58489272, Validation loss: 0.58116656, Gradient norm: 15.65848322
INFO:root:At the start of the epoch: mem (CPU python)=17217.56640625MB; mem (CPU total)=28364.36328125MB
INFO:root:[   74] Training loss: 0.58744447, Validation loss: 0.58956275, Gradient norm: 17.98517204
INFO:root:At the start of the epoch: mem (CPU python)=17238.734375MB; mem (CPU total)=28399.2421875MB
INFO:root:[   75] Training loss: 0.58832861, Validation loss: 0.58608574, Gradient norm: 19.04525477
INFO:root:At the start of the epoch: mem (CPU python)=17259.8984375MB; mem (CPU total)=28433.17578125MB
INFO:root:[   76] Training loss: 0.58819978, Validation loss: 0.58749488, Gradient norm: 18.97735640
INFO:root:At the start of the epoch: mem (CPU python)=17281.0625MB; mem (CPU total)=28466.70703125MB
INFO:root:[   77] Training loss: 0.58945288, Validation loss: 0.58258091, Gradient norm: 20.86264605
INFO:root:At the start of the epoch: mem (CPU python)=17302.2265625MB; mem (CPU total)=28502.390625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   78] Training loss: 0.58964691, Validation loss: 0.58965960, Gradient norm: 22.97589281
INFO:root:At the start of the epoch: mem (CPU python)=17323.38671875MB; mem (CPU total)=28535.45703125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   79] Training loss: 0.57566635, Validation loss: 0.57606354, Gradient norm: 14.51671495
INFO:root:At the start of the epoch: mem (CPU python)=17344.5546875MB; mem (CPU total)=28569.24609375MB
INFO:root:[   80] Training loss: 0.56832455, Validation loss: 0.56866452, Gradient norm: 11.21271115
INFO:root:At the start of the epoch: mem (CPU python)=17365.71875MB; mem (CPU total)=28603.93359375MB
INFO:root:[   81] Training loss: 0.56750928, Validation loss: 0.56621255, Gradient norm: 12.66906357
INFO:root:At the start of the epoch: mem (CPU python)=17386.8828125MB; mem (CPU total)=28638.08984375MB
INFO:root:[   82] Training loss: 0.56657152, Validation loss: 0.56873282, Gradient norm: 14.53536101
INFO:root:At the start of the epoch: mem (CPU python)=17408.046875MB; mem (CPU total)=28674.921875MB
INFO:root:[   83] Training loss: 0.56596172, Validation loss: 0.56629822, Gradient norm: 15.76009210
INFO:root:At the start of the epoch: mem (CPU python)=17429.2109375MB; mem (CPU total)=28707.15625MB
INFO:root:[   84] Training loss: 0.56631544, Validation loss: 0.57004222, Gradient norm: 16.45909801
INFO:root:At the start of the epoch: mem (CPU python)=17450.375MB; mem (CPU total)=28740.48828125MB
INFO:root:[   85] Training loss: 0.56518157, Validation loss: 0.56617012, Gradient norm: 17.23376229
INFO:root:At the start of the epoch: mem (CPU python)=17471.54296875MB; mem (CPU total)=28775.8671875MB
INFO:root:[   86] Training loss: 0.56531289, Validation loss: 0.56657634, Gradient norm: 17.74816035
INFO:root:At the start of the epoch: mem (CPU python)=17492.70703125MB; mem (CPU total)=28809.6171875MB
INFO:root:[   87] Training loss: 0.56566907, Validation loss: 0.56636167, Gradient norm: 18.77401426
INFO:root:At the start of the epoch: mem (CPU python)=17513.87109375MB; mem (CPU total)=28845.08984375MB
INFO:root:[   88] Training loss: 0.56499036, Validation loss: 0.56525065, Gradient norm: 18.19131456
INFO:root:At the start of the epoch: mem (CPU python)=17535.03125MB; mem (CPU total)=28878.515625MB
INFO:root:[   89] Training loss: 0.56454347, Validation loss: 0.56370073, Gradient norm: 19.34130727
INFO:root:At the start of the epoch: mem (CPU python)=17556.1953125MB; mem (CPU total)=28911.84375MB
INFO:root:[   90] Training loss: 0.56537729, Validation loss: 0.56682105, Gradient norm: 20.56560384
INFO:root:At the start of the epoch: mem (CPU python)=17577.35546875MB; mem (CPU total)=28947.98828125MB
INFO:root:[   91] Training loss: 0.56779632, Validation loss: 0.56825638, Gradient norm: 26.81362507
INFO:root:At the start of the epoch: mem (CPU python)=17598.5234375MB; mem (CPU total)=28981.1328125MB
INFO:root:[   92] Training loss: 0.56376358, Validation loss: 0.56380614, Gradient norm: 18.51786237
INFO:root:At the start of the epoch: mem (CPU python)=17619.6875MB; mem (CPU total)=29014.75MB
INFO:root:[   93] Training loss: 0.56432725, Validation loss: 0.56557968, Gradient norm: 23.13611115
INFO:root:At the start of the epoch: mem (CPU python)=17640.8515625MB; mem (CPU total)=29051.24609375MB
INFO:root:[   94] Training loss: 0.56360631, Validation loss: 0.56295137, Gradient norm: 21.72063422
INFO:root:At the start of the epoch: mem (CPU python)=17662.015625MB; mem (CPU total)=29084.796875MB
INFO:root:[   95] Training loss: 0.56343435, Validation loss: 0.56400197, Gradient norm: 22.15233950
INFO:root:At the start of the epoch: mem (CPU python)=17683.1796875MB; mem (CPU total)=29121.546875MB
INFO:root:[   96] Training loss: 0.56401292, Validation loss: 0.56525730, Gradient norm: 22.71375179
INFO:root:At the start of the epoch: mem (CPU python)=17704.34765625MB; mem (CPU total)=29153.91015625MB
INFO:root:[   97] Training loss: 0.56404255, Validation loss: 0.56875453, Gradient norm: 24.72910717
INFO:root:At the start of the epoch: mem (CPU python)=17725.5078125MB; mem (CPU total)=29187.29296875MB
INFO:root:[   98] Training loss: 0.56386514, Validation loss: 0.56690110, Gradient norm: 26.30651199
INFO:root:At the start of the epoch: mem (CPU python)=17746.671875MB; mem (CPU total)=29222.9140625MB
INFO:root:[   99] Training loss: 0.56347706, Validation loss: 0.56436356, Gradient norm: 24.70747512
INFO:root:At the start of the epoch: mem (CPU python)=17767.8359375MB; mem (CPU total)=29256.8203125MB
INFO:root:[  100] Training loss: 0.56269613, Validation loss: 0.56460692, Gradient norm: 25.28154853
INFO:root:At the start of the epoch: mem (CPU python)=17789.0MB; mem (CPU total)=29292.30078125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  101] Training loss: 0.56369867, Validation loss: 0.56081993, Gradient norm: 25.74717775
INFO:root:At the start of the epoch: mem (CPU python)=17810.16796875MB; mem (CPU total)=29326.890625MB
INFO:root:[  102] Training loss: 0.55861777, Validation loss: 0.55906267, Gradient norm: 16.02583319
INFO:root:At the start of the epoch: mem (CPU python)=17831.33203125MB; mem (CPU total)=29360.55078125MB
INFO:root:[  103] Training loss: 0.55780520, Validation loss: 0.55748401, Gradient norm: 18.06385899
INFO:root:At the start of the epoch: mem (CPU python)=17852.49609375MB; mem (CPU total)=29397.8125MB
INFO:root:[  104] Training loss: 0.55800929, Validation loss: 0.55978388, Gradient norm: 20.55686140
INFO:root:At the start of the epoch: mem (CPU python)=17873.66015625MB; mem (CPU total)=29429.41015625MB
INFO:root:[  105] Training loss: 0.55763197, Validation loss: 0.55701016, Gradient norm: 20.71382176
INFO:root:At the start of the epoch: mem (CPU python)=17894.82421875MB; mem (CPU total)=29463.12109375MB
INFO:root:[  106] Training loss: 0.55790966, Validation loss: 0.56077171, Gradient norm: 22.39719952
INFO:root:At the start of the epoch: mem (CPU python)=17915.98828125MB; mem (CPU total)=29498.7734375MB
INFO:root:[  107] Training loss: 0.55688601, Validation loss: 0.55901618, Gradient norm: 22.66689389
INFO:root:At the start of the epoch: mem (CPU python)=17937.14453125MB; mem (CPU total)=29532.5625MB
INFO:root:[  108] Training loss: 0.55870509, Validation loss: 0.56106678, Gradient norm: 27.43277973
INFO:root:At the start of the epoch: mem (CPU python)=17958.3125MB; mem (CPU total)=29567.38671875MB
INFO:root:[  109] Training loss: 0.56073976, Validation loss: 0.55939616, Gradient norm: 33.85785223
INFO:root:At the start of the epoch: mem (CPU python)=17979.4765625MB; mem (CPU total)=29601.37890625MB
INFO:root:[  110] Training loss: 0.55908969, Validation loss: 0.55785831, Gradient norm: 26.32704289
INFO:root:At the start of the epoch: mem (CPU python)=18000.640625MB; mem (CPU total)=29635.43359375MB
INFO:root:[  111] Training loss: 0.55722740, Validation loss: 0.55860955, Gradient norm: 23.11981866
INFO:root:At the start of the epoch: mem (CPU python)=18021.8046875MB; mem (CPU total)=29673.8203125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  112] Training loss: 0.55694607, Validation loss: 0.55910695, Gradient norm: 23.72027833
INFO:root:At the start of the epoch: mem (CPU python)=18042.96875MB; mem (CPU total)=29706.046875MB
INFO:root:[  113] Training loss: 0.55488189, Validation loss: 0.55526225, Gradient norm: 19.08434086
INFO:root:At the start of the epoch: mem (CPU python)=18064.13671875MB; mem (CPU total)=29740.33203125MB
INFO:root:[  114] Training loss: 0.55426761, Validation loss: 0.55544600, Gradient norm: 20.14572848
INFO:root:At the start of the epoch: mem (CPU python)=18085.296875MB; mem (CPU total)=29775.58203125MB
INFO:root:[  115] Training loss: 0.55412020, Validation loss: 0.55580904, Gradient norm: 16.59488077
INFO:root:At the start of the epoch: mem (CPU python)=18107.18359375MB; mem (CPU total)=29810.59765625MB
INFO:root:[  116] Training loss: 0.55342229, Validation loss: 0.55502663, Gradient norm: 16.85824252
INFO:root:At the start of the epoch: mem (CPU python)=18129.609375MB; mem (CPU total)=29846.76171875MB
INFO:root:[  117] Training loss: 0.55322524, Validation loss: 0.55559389, Gradient norm: 17.67097255
INFO:root:At the start of the epoch: mem (CPU python)=18150.7734375MB; mem (CPU total)=29881.203125MB
INFO:root:[  118] Training loss: 0.55353776, Validation loss: 0.55810623, Gradient norm: 23.00806622
INFO:root:At the start of the epoch: mem (CPU python)=18172.20703125MB; mem (CPU total)=29915.390625MB
INFO:root:[  119] Training loss: 0.55397276, Validation loss: 0.55423446, Gradient norm: 27.30340361
INFO:root:At the start of the epoch: mem (CPU python)=18193.375MB; mem (CPU total)=29952.98046875MB
INFO:root:[  120] Training loss: 0.55302702, Validation loss: 0.55347231, Gradient norm: 20.15537636
INFO:root:At the start of the epoch: mem (CPU python)=18214.5390625MB; mem (CPU total)=29983.97265625MB
INFO:root:[  121] Training loss: 0.55338566, Validation loss: 0.55403324, Gradient norm: 23.57319209
INFO:root:At the start of the epoch: mem (CPU python)=18235.703125MB; mem (CPU total)=30018.42578125MB
INFO:root:[  122] Training loss: 0.55228777, Validation loss: 0.55391969, Gradient norm: 21.85779791
INFO:root:At the start of the epoch: mem (CPU python)=18256.8671875MB; mem (CPU total)=30053.5859375MB
INFO:root:[  123] Training loss: 0.55267232, Validation loss: 0.55356309, Gradient norm: 22.84481052
INFO:root:At the start of the epoch: mem (CPU python)=18278.03125MB; mem (CPU total)=30087.80859375MB
INFO:root:[  124] Training loss: 0.55248159, Validation loss: 0.55257576, Gradient norm: 23.82813692
INFO:root:At the start of the epoch: mem (CPU python)=18300.05078125MB; mem (CPU total)=30123.6953125MB
INFO:root:[  125] Training loss: 0.55304206, Validation loss: 0.55343737, Gradient norm: 23.47437848
INFO:root:At the start of the epoch: mem (CPU python)=18321.20703125MB; mem (CPU total)=30159.1328125MB
INFO:root:[  126] Training loss: 0.55221234, Validation loss: 0.55410265, Gradient norm: 24.92410788
INFO:root:At the start of the epoch: mem (CPU python)=18342.64453125MB; mem (CPU total)=30193.29296875MB
INFO:root:[  127] Training loss: 0.55179832, Validation loss: 0.55163227, Gradient norm: 26.32979121
INFO:root:At the start of the epoch: mem (CPU python)=18363.80859375MB; mem (CPU total)=30230.03125MB
INFO:root:[  128] Training loss: 0.55215232, Validation loss: 0.55241778, Gradient norm: 26.96271543
INFO:root:At the start of the epoch: mem (CPU python)=18384.97265625MB; mem (CPU total)=30262.703125MB
INFO:root:[  129] Training loss: 0.55235173, Validation loss: 0.55251684, Gradient norm: 28.96122500
INFO:root:At the start of the epoch: mem (CPU python)=18406.13671875MB; mem (CPU total)=30296.6484375MB
INFO:root:[  130] Training loss: 0.55209842, Validation loss: 0.55391781, Gradient norm: 27.45595670
INFO:root:At the start of the epoch: mem (CPU python)=18427.30078125MB; mem (CPU total)=30332.8203125MB
INFO:root:[  131] Training loss: 0.55185026, Validation loss: 0.55399498, Gradient norm: 27.40719014
INFO:root:At the start of the epoch: mem (CPU python)=18448.46875MB; mem (CPU total)=30366.0234375MB
INFO:root:[  132] Training loss: 0.55132933, Validation loss: 0.55359125, Gradient norm: 29.44423714
INFO:root:At the start of the epoch: mem (CPU python)=18469.6328125MB; mem (CPU total)=30400.21484375MB
INFO:root:[  133] Training loss: 0.55159197, Validation loss: 0.55273409, Gradient norm: 28.68230835
INFO:root:At the start of the epoch: mem (CPU python)=18490.796875MB; mem (CPU total)=30435.29296875MB
INFO:root:[  134] Training loss: 0.55187603, Validation loss: 0.55193519, Gradient norm: 30.82323039
INFO:root:At the start of the epoch: mem (CPU python)=18513.9609375MB; mem (CPU total)=30471.98828125MB
INFO:root:[  135] Training loss: 0.55122678, Validation loss: 0.55272035, Gradient norm: 28.96519387
INFO:root:At the start of the epoch: mem (CPU python)=18535.125MB; mem (CPU total)=30507.08203125MB
INFO:root:[  136] Training loss: 0.55149049, Validation loss: 0.55252784, Gradient norm: 30.70727824
INFO:root:At the start of the epoch: mem (CPU python)=18556.29296875MB; mem (CPU total)=30541.54296875MB
INFO:root:EP 136: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=18577.44140625MB; mem (CPU total)=30570.61328125MB
INFO:root:Training the model took 4776.619s.
INFO:root:Emptying the cuda cache took 0.037s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.47116
INFO:root:EnergyScoreValidation: 0.34817
INFO:root:CRPSValidation: 0.13754
INFO:root:Gaussian NLLValidation: 0.0983
INFO:root:CoverageValidation: 0.83182
INFO:root:IntervalWidthValidation: 0.60324
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.48296
INFO:root:EnergyScoreTest: 0.35795
INFO:root:CRPSTest: 0.14287
INFO:root:Gaussian NLLTest: 0.16622
INFO:root:CoverageTest: 0.82099
INFO:root:IntervalWidthTest: 0.60588
INFO:root:After validation: mem (CPU python)=18884.21875MB; mem (CPU total)=30625.296875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=18884.21875MB; mem (CPU total)=30625.5390625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=18884.21875MB; mem (CPU total)=30642.98046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30643.95703125MB
INFO:root:[    1] Training loss: 0.88003774, Validation loss: 0.77007140, Gradient norm: 0.32130336
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30678.63671875MB
INFO:root:[    2] Training loss: 0.76309241, Validation loss: 0.76259121, Gradient norm: 0.35316114
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30700.875MB
INFO:root:[    3] Training loss: 0.75734745, Validation loss: 0.75389671, Gradient norm: 0.52509317
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30733.1484375MB
INFO:root:[    4] Training loss: 0.75266114, Validation loss: 0.74864431, Gradient norm: 0.92072327
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30767.01171875MB
INFO:root:[    5] Training loss: 0.74329576, Validation loss: 0.73270855, Gradient norm: 1.15932673
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30804.609375MB
INFO:root:[    6] Training loss: 0.73149512, Validation loss: 0.72763390, Gradient norm: 1.65355110
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30837.09375MB
INFO:root:[    7] Training loss: 0.72472816, Validation loss: 0.72120670, Gradient norm: 1.90733692
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30871.26953125MB
INFO:root:[    8] Training loss: 0.72261261, Validation loss: 0.71290122, Gradient norm: 2.21453393
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30907.4453125MB
INFO:root:[    9] Training loss: 0.71449734, Validation loss: 0.71750403, Gradient norm: 2.15724325
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30940.9140625MB
INFO:root:[   10] Training loss: 0.71039115, Validation loss: 0.70746773, Gradient norm: 2.59283797
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=30976.0390625MB
INFO:root:[   11] Training loss: 0.70859343, Validation loss: 0.70987269, Gradient norm: 2.81532361
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=31010.953125MB
INFO:root:[   12] Training loss: 0.70298322, Validation loss: 0.68268061, Gradient norm: 2.86293650
INFO:root:At the start of the epoch: mem (CPU python)=18884.21875MB; mem (CPU total)=31045.23046875MB
INFO:root:[   13] Training loss: 0.70039385, Validation loss: 0.69684381, Gradient norm: 3.32804488
INFO:root:At the start of the epoch: mem (CPU python)=18889.44140625MB; mem (CPU total)=31082.1640625MB
INFO:root:[   14] Training loss: 0.69431501, Validation loss: 0.69183246, Gradient norm: 3.16273104
INFO:root:At the start of the epoch: mem (CPU python)=18910.60546875MB; mem (CPU total)=31114.8828125MB
INFO:root:[   15] Training loss: 0.69711133, Validation loss: 0.68799393, Gradient norm: 3.62457129
INFO:root:At the start of the epoch: mem (CPU python)=18931.76953125MB; mem (CPU total)=31149.3046875MB
INFO:root:[   16] Training loss: 0.69939902, Validation loss: 0.71126789, Gradient norm: 3.85539397
INFO:root:At the start of the epoch: mem (CPU python)=18952.93359375MB; mem (CPU total)=31186.70703125MB
INFO:root:[   17] Training loss: 0.69409399, Validation loss: 0.69385603, Gradient norm: 3.71412990
INFO:root:At the start of the epoch: mem (CPU python)=18974.09765625MB; mem (CPU total)=31218.8984375MB
INFO:root:[   18] Training loss: 0.68616272, Validation loss: 0.68071381, Gradient norm: 3.32710516
INFO:root:At the start of the epoch: mem (CPU python)=18995.26171875MB; mem (CPU total)=31252.765625MB
INFO:root:[   19] Training loss: 0.69295634, Validation loss: 0.68528404, Gradient norm: 4.17216196
INFO:root:At the start of the epoch: mem (CPU python)=19016.42578125MB; mem (CPU total)=31289.16015625MB
INFO:root:[   20] Training loss: 0.69169383, Validation loss: 0.73384517, Gradient norm: 4.36426018
INFO:root:At the start of the epoch: mem (CPU python)=19037.58984375MB; mem (CPU total)=31323.5546875MB
INFO:root:[   21] Training loss: 0.69276344, Validation loss: 0.68752792, Gradient norm: 4.59562625
INFO:root:At the start of the epoch: mem (CPU python)=19058.75390625MB; mem (CPU total)=31358.31640625MB
INFO:root:[   22] Training loss: 0.68890238, Validation loss: 0.66261270, Gradient norm: 4.41827522
INFO:root:At the start of the epoch: mem (CPU python)=19079.921875MB; mem (CPU total)=31393.5546875MB
INFO:root:[   23] Training loss: 0.68901159, Validation loss: 0.69785365, Gradient norm: 4.72080737
INFO:root:At the start of the epoch: mem (CPU python)=19101.08203125MB; mem (CPU total)=31427.53515625MB
INFO:root:[   24] Training loss: 0.68542701, Validation loss: 0.68509834, Gradient norm: 4.60838419
INFO:root:At the start of the epoch: mem (CPU python)=19122.24609375MB; mem (CPU total)=31464.17578125MB
INFO:root:[   25] Training loss: 0.68545737, Validation loss: 0.70425392, Gradient norm: 4.92793912
INFO:root:At the start of the epoch: mem (CPU python)=19143.41015625MB; mem (CPU total)=31497.37890625MB
INFO:root:[   26] Training loss: 0.68581164, Validation loss: 0.69414032, Gradient norm: 5.10181594
INFO:root:At the start of the epoch: mem (CPU python)=19164.57421875MB; mem (CPU total)=31531.8203125MB
INFO:root:[   27] Training loss: 0.69464747, Validation loss: 0.74502559, Gradient norm: 5.69233052
INFO:root:At the start of the epoch: mem (CPU python)=19185.73828125MB; mem (CPU total)=31569.6796875MB
INFO:root:[   28] Training loss: 0.68820183, Validation loss: 0.68290357, Gradient norm: 5.37838109
INFO:root:At the start of the epoch: mem (CPU python)=19206.90234375MB; mem (CPU total)=31603.41015625MB
INFO:root:[   29] Training loss: 0.67853699, Validation loss: 0.67019405, Gradient norm: 4.95219410
INFO:root:At the start of the epoch: mem (CPU python)=19228.06640625MB; mem (CPU total)=31637.80078125MB
INFO:root:[   30] Training loss: 0.68285350, Validation loss: 0.67286658, Gradient norm: 5.40111089
INFO:root:At the start of the epoch: mem (CPU python)=19249.23046875MB; mem (CPU total)=31673.44921875MB
INFO:root:[   31] Training loss: 0.68402882, Validation loss: 0.67279008, Gradient norm: 5.90566857
INFO:root:At the start of the epoch: mem (CPU python)=19270.39453125MB; mem (CPU total)=31707.69140625MB
INFO:root:[   32] Training loss: 0.68811241, Validation loss: 0.68838277, Gradient norm: 6.48987428
INFO:root:At the start of the epoch: mem (CPU python)=19291.5625MB; mem (CPU total)=31742.16015625MB
INFO:root:[   33] Training loss: 0.68496136, Validation loss: 0.66802457, Gradient norm: 6.14494882
INFO:root:At the start of the epoch: mem (CPU python)=19312.7265625MB; mem (CPU total)=31777.8359375MB
INFO:root:[   34] Training loss: 0.68221222, Validation loss: 0.69079252, Gradient norm: 6.13510546
INFO:root:At the start of the epoch: mem (CPU python)=19333.890625MB; mem (CPU total)=31812.59765625MB
INFO:root:[   35] Training loss: 0.68028638, Validation loss: 0.73843984, Gradient norm: 6.36827102
INFO:root:At the start of the epoch: mem (CPU python)=19355.05078125MB; mem (CPU total)=31847.734375MB
INFO:root:[   36] Training loss: 0.68692077, Validation loss: 0.68955183, Gradient norm: 6.92081207
INFO:root:At the start of the epoch: mem (CPU python)=19376.21875MB; mem (CPU total)=31883.67578125MB
INFO:root:[   37] Training loss: 0.68722286, Validation loss: 0.69888593, Gradient norm: 7.10385234
INFO:root:At the start of the epoch: mem (CPU python)=19397.3828125MB; mem (CPU total)=31917.40234375MB
INFO:root:[   38] Training loss: 0.67622232, Validation loss: 0.65850496, Gradient norm: 6.86227099
INFO:root:At the start of the epoch: mem (CPU python)=19418.546875MB; mem (CPU total)=31954.57421875MB
INFO:root:[   39] Training loss: 0.67159850, Validation loss: 0.67515719, Gradient norm: 6.45758749
INFO:root:At the start of the epoch: mem (CPU python)=19439.70703125MB; mem (CPU total)=31987.53125MB
INFO:root:[   40] Training loss: 0.67380036, Validation loss: 0.68216274, Gradient norm: 6.92420769
INFO:root:At the start of the epoch: mem (CPU python)=19460.87109375MB; mem (CPU total)=32021.73828125MB
INFO:root:[   41] Training loss: 0.66873138, Validation loss: 0.67799195, Gradient norm: 6.67135038
INFO:root:At the start of the epoch: mem (CPU python)=19482.03515625MB; mem (CPU total)=32058.65234375MB
INFO:root:[   42] Training loss: 0.67538296, Validation loss: 0.67643090, Gradient norm: 7.40475645
INFO:root:At the start of the epoch: mem (CPU python)=19503.19921875MB; mem (CPU total)=32092.88671875MB
INFO:root:[   43] Training loss: 0.67646055, Validation loss: 0.65222413, Gradient norm: 7.23743508
INFO:root:At the start of the epoch: mem (CPU python)=19524.3671875MB; mem (CPU total)=32126.3671875MB
INFO:root:[   44] Training loss: 0.67277076, Validation loss: 0.67245154, Gradient norm: 7.00118275
INFO:root:At the start of the epoch: mem (CPU python)=19545.52734375MB; mem (CPU total)=32161.7890625MB
INFO:root:[   45] Training loss: 0.67332852, Validation loss: 0.68330258, Gradient norm: 7.59726855
INFO:root:At the start of the epoch: mem (CPU python)=19566.69140625MB; mem (CPU total)=32195.765625MB
INFO:root:[   46] Training loss: 0.66188815, Validation loss: 0.67357060, Gradient norm: 6.65456791
INFO:root:At the start of the epoch: mem (CPU python)=19587.85546875MB; mem (CPU total)=32229.4921875MB
INFO:root:[   47] Training loss: 0.66810555, Validation loss: 0.65232690, Gradient norm: 7.61663468
INFO:root:At the start of the epoch: mem (CPU python)=19609.01953125MB; mem (CPU total)=32264.6484375MB
INFO:root:[   48] Training loss: 0.66099427, Validation loss: 0.65163600, Gradient norm: 6.90033772
INFO:root:At the start of the epoch: mem (CPU python)=19630.1875MB; mem (CPU total)=32298.6875MB
INFO:root:[   49] Training loss: 0.68545853, Validation loss: 0.64965106, Gradient norm: 9.12724033
INFO:root:At the start of the epoch: mem (CPU python)=19651.3515625MB; mem (CPU total)=32334.859375MB
INFO:root:[   50] Training loss: 0.67475141, Validation loss: 0.65140024, Gradient norm: 8.04195876
INFO:root:At the start of the epoch: mem (CPU python)=19672.515625MB; mem (CPU total)=32369.08203125MB
INFO:root:[   51] Training loss: 0.66758737, Validation loss: 0.65458058, Gradient norm: 7.64813625
INFO:root:At the start of the epoch: mem (CPU python)=19705.3671875MB; mem (CPU total)=32415.51953125MB
INFO:root:[   52] Training loss: 0.66184046, Validation loss: 0.68528770, Gradient norm: 7.04660064
INFO:root:At the start of the epoch: mem (CPU python)=19726.53125MB; mem (CPU total)=32452.9375MB
INFO:root:[   53] Training loss: 0.66815886, Validation loss: 0.64877198, Gradient norm: 8.20969093
INFO:root:At the start of the epoch: mem (CPU python)=19748.01171875MB; mem (CPU total)=32485.6796875MB
INFO:root:[   54] Training loss: 0.66922442, Validation loss: 0.67970382, Gradient norm: 8.59527326
INFO:root:At the start of the epoch: mem (CPU python)=19769.171875MB; mem (CPU total)=32519.88671875MB
INFO:root:[   55] Training loss: 0.66956941, Validation loss: 0.65105406, Gradient norm: 8.40470708
INFO:root:At the start of the epoch: mem (CPU python)=19790.3359375MB; mem (CPU total)=32556.4765625MB
INFO:root:[   56] Training loss: 0.66219503, Validation loss: 0.66555604, Gradient norm: 8.06606510
INFO:root:At the start of the epoch: mem (CPU python)=19811.49609375MB; mem (CPU total)=32589.50390625MB
INFO:root:[   57] Training loss: 0.67370955, Validation loss: 0.66551681, Gradient norm: 9.10861395
INFO:root:At the start of the epoch: mem (CPU python)=19832.66015625MB; mem (CPU total)=32623.4453125MB
INFO:root:[   58] Training loss: 0.66517698, Validation loss: 0.64416458, Gradient norm: 8.97072548
INFO:root:At the start of the epoch: mem (CPU python)=19853.828125MB; mem (CPU total)=32659.3828125MB
INFO:root:[   59] Training loss: 0.66492500, Validation loss: 0.67482996, Gradient norm: 8.76141864
INFO:root:At the start of the epoch: mem (CPU python)=19874.98828125MB; mem (CPU total)=32694.05078125MB
INFO:root:[   60] Training loss: 0.65912450, Validation loss: 0.64677998, Gradient norm: 7.97206056
INFO:root:At the start of the epoch: mem (CPU python)=19896.15625MB; mem (CPU total)=32729.23828125MB
INFO:root:[   61] Training loss: 0.66761381, Validation loss: 0.65399228, Gradient norm: 9.58084627
INFO:root:At the start of the epoch: mem (CPU python)=19917.3203125MB; mem (CPU total)=32764.953125MB
INFO:root:[   62] Training loss: 0.67041913, Validation loss: 0.66581923, Gradient norm: 9.18226448
INFO:root:At the start of the epoch: mem (CPU python)=19938.484375MB; mem (CPU total)=32798.92578125MB
INFO:root:[   63] Training loss: 0.66227502, Validation loss: 0.69113542, Gradient norm: 8.28102337
INFO:root:At the start of the epoch: mem (CPU python)=19959.64453125MB; mem (CPU total)=32835.140625MB
INFO:root:[   64] Training loss: 0.66724497, Validation loss: 0.68232601, Gradient norm: 9.11426628
INFO:root:At the start of the epoch: mem (CPU python)=19980.8125MB; mem (CPU total)=32868.8515625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   65] Training loss: 0.66984834, Validation loss: 0.69063062, Gradient norm: 8.84670654
INFO:root:At the start of the epoch: mem (CPU python)=20001.9765625MB; mem (CPU total)=32903.04296875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   66] Training loss: 0.62545892, Validation loss: 0.62130868, Gradient norm: 6.33431921
INFO:root:At the start of the epoch: mem (CPU python)=20023.140625MB; mem (CPU total)=32941.12109375MB
INFO:root:[   67] Training loss: 0.61276480, Validation loss: 0.61320994, Gradient norm: 5.38462627
INFO:root:At the start of the epoch: mem (CPU python)=20044.30859375MB; mem (CPU total)=32973.60546875MB
INFO:root:[   68] Training loss: 0.61158186, Validation loss: 0.61346776, Gradient norm: 6.48277456
INFO:root:At the start of the epoch: mem (CPU python)=20065.47265625MB; mem (CPU total)=33008.0078125MB
INFO:root:[   69] Training loss: 0.61256623, Validation loss: 0.61399730, Gradient norm: 7.52255594
INFO:root:At the start of the epoch: mem (CPU python)=20086.63671875MB; mem (CPU total)=33044.6796875MB
INFO:root:[   70] Training loss: 0.61499668, Validation loss: 0.60873535, Gradient norm: 8.29683478
INFO:root:At the start of the epoch: mem (CPU python)=20107.8046875MB; mem (CPU total)=33077.94921875MB
INFO:root:[   71] Training loss: 0.61312931, Validation loss: 0.62733261, Gradient norm: 8.63890002
INFO:root:At the start of the epoch: mem (CPU python)=20128.96875MB; mem (CPU total)=33112.1640625MB
INFO:root:[   72] Training loss: 0.61497458, Validation loss: 0.61165701, Gradient norm: 9.65902980
INFO:root:At the start of the epoch: mem (CPU python)=20150.1328125MB; mem (CPU total)=33148.078125MB
INFO:root:[   73] Training loss: 0.61911508, Validation loss: 0.62631136, Gradient norm: 10.94384272
INFO:root:At the start of the epoch: mem (CPU python)=20171.2890625MB; mem (CPU total)=33182.03515625MB
INFO:root:[   74] Training loss: 0.61654207, Validation loss: 0.62898085, Gradient norm: 11.01334105
INFO:root:At the start of the epoch: mem (CPU python)=20192.453125MB; mem (CPU total)=33216.74609375MB
INFO:root:[   75] Training loss: 0.61788537, Validation loss: 0.62644344, Gradient norm: 12.05940664
INFO:root:At the start of the epoch: mem (CPU python)=20213.6171875MB; mem (CPU total)=33252.65625MB
INFO:root:[   76] Training loss: 0.62015670, Validation loss: 0.62324011, Gradient norm: 12.75238389
INFO:root:At the start of the epoch: mem (CPU python)=20234.78515625MB; mem (CPU total)=33286.86328125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 0.61924940, Validation loss: 0.62387111, Gradient norm: 13.08574078
INFO:root:At the start of the epoch: mem (CPU python)=20255.94921875MB; mem (CPU total)=33323.28125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 0.61070990, Validation loss: 0.61188898, Gradient norm: 9.43601725
INFO:root:At the start of the epoch: mem (CPU python)=20277.11328125MB; mem (CPU total)=33357.69921875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   79] Training loss: 0.60423282, Validation loss: 0.60470242, Gradient norm: 6.40577313
INFO:root:At the start of the epoch: mem (CPU python)=20298.27734375MB; mem (CPU total)=33391.93359375MB
INFO:root:[   80] Training loss: 0.60273625, Validation loss: 0.60261452, Gradient norm: 4.46712525
INFO:root:At the start of the epoch: mem (CPU python)=20319.44140625MB; mem (CPU total)=33429.35546875MB
INFO:root:[   81] Training loss: 0.60215799, Validation loss: 0.60245182, Gradient norm: 5.47230127
INFO:root:At the start of the epoch: mem (CPU python)=20340.609375MB; mem (CPU total)=33462.5703125MB
INFO:root:[   82] Training loss: 0.60181437, Validation loss: 0.60288859, Gradient norm: 5.52305966
INFO:root:At the start of the epoch: mem (CPU python)=20361.76953125MB; mem (CPU total)=33496.30078125MB
INFO:root:[   83] Training loss: 0.60123534, Validation loss: 0.60232413, Gradient norm: 5.61286908
INFO:root:At the start of the epoch: mem (CPU python)=20382.93359375MB; mem (CPU total)=33533.71875MB
INFO:root:[   84] Training loss: 0.60112206, Validation loss: 0.60299067, Gradient norm: 7.59174532
INFO:root:At the start of the epoch: mem (CPU python)=20404.09765625MB; mem (CPU total)=33566.9140625MB
INFO:root:[   85] Training loss: 0.60170163, Validation loss: 0.60280585, Gradient norm: 10.01257883
INFO:root:At the start of the epoch: mem (CPU python)=20425.26171875MB; mem (CPU total)=33600.63671875MB
INFO:root:[   86] Training loss: 0.60113866, Validation loss: 0.60138707, Gradient norm: 7.58471032
INFO:root:At the start of the epoch: mem (CPU python)=20446.4296875MB; mem (CPU total)=33636.8203125MB
INFO:root:[   87] Training loss: 0.60083363, Validation loss: 0.60221240, Gradient norm: 6.84066062
INFO:root:At the start of the epoch: mem (CPU python)=20467.58984375MB; mem (CPU total)=33670.78125MB
INFO:root:[   88] Training loss: 0.60082580, Validation loss: 0.60326369, Gradient norm: 8.28538407
INFO:root:At the start of the epoch: mem (CPU python)=20488.7578125MB; mem (CPU total)=33704.69921875MB
INFO:root:[   89] Training loss: 0.60073827, Validation loss: 0.60166220, Gradient norm: 7.59417703
INFO:root:At the start of the epoch: mem (CPU python)=20509.921875MB; mem (CPU total)=33740.91015625MB
INFO:root:[   90] Training loss: 0.60052200, Validation loss: 0.60294434, Gradient norm: 7.57273989
INFO:root:At the start of the epoch: mem (CPU python)=20531.08203125MB; mem (CPU total)=33775.61328125MB
INFO:root:[   91] Training loss: 0.60057625, Validation loss: 0.60133975, Gradient norm: 8.48751277
INFO:root:At the start of the epoch: mem (CPU python)=20552.25390625MB; mem (CPU total)=33811.328125MB
INFO:root:[   92] Training loss: 0.60105730, Validation loss: 0.60179637, Gradient norm: 11.52180822
INFO:root:At the start of the epoch: mem (CPU python)=20573.40625MB; mem (CPU total)=33846.2734375MB
INFO:root:[   93] Training loss: 0.60085854, Validation loss: 0.60235226, Gradient norm: 11.83687254
INFO:root:At the start of the epoch: mem (CPU python)=20594.57421875MB; mem (CPU total)=33880.98046875MB
INFO:root:[   94] Training loss: 0.60036361, Validation loss: 0.60288609, Gradient norm: 9.87736202
INFO:root:At the start of the epoch: mem (CPU python)=20615.73828125MB; mem (CPU total)=33918.64453125MB
INFO:root:[   95] Training loss: 0.60019312, Validation loss: 0.60110757, Gradient norm: 9.77062896
INFO:root:At the start of the epoch: mem (CPU python)=20636.90234375MB; mem (CPU total)=33951.91015625MB
INFO:root:[   96] Training loss: 0.60012756, Validation loss: 0.60154975, Gradient norm: 10.04994635
INFO:root:At the start of the epoch: mem (CPU python)=20658.06640625MB; mem (CPU total)=33986.0390625MB
INFO:root:[   97] Training loss: 0.60024517, Validation loss: 0.60049572, Gradient norm: 10.90776973
INFO:root:At the start of the epoch: mem (CPU python)=20679.23046875MB; mem (CPU total)=34023.94140625MB
INFO:root:[   98] Training loss: 0.60014282, Validation loss: 0.60243873, Gradient norm: 10.65961702
INFO:root:At the start of the epoch: mem (CPU python)=20700.39453125MB; mem (CPU total)=34057.87890625MB
INFO:root:[   99] Training loss: 0.60053961, Validation loss: 0.60259458, Gradient norm: 12.01676587
INFO:root:At the start of the epoch: mem (CPU python)=20721.5625MB; mem (CPU total)=34091.35546875MB
INFO:root:[  100] Training loss: 0.60005671, Validation loss: 0.60157313, Gradient norm: 11.85678220
INFO:root:At the start of the epoch: mem (CPU python)=20742.7265625MB; mem (CPU total)=34128.0390625MB
INFO:root:[  101] Training loss: 0.60021434, Validation loss: 0.60104676, Gradient norm: 12.73339448
INFO:root:At the start of the epoch: mem (CPU python)=20763.88671875MB; mem (CPU total)=34161.83203125MB
INFO:root:[  102] Training loss: 0.60040433, Validation loss: 0.60120222, Gradient norm: 12.70443697
INFO:root:At the start of the epoch: mem (CPU python)=20785.05078125MB; mem (CPU total)=34195.8046875MB
INFO:root:[  103] Training loss: 0.60012465, Validation loss: 0.60188129, Gradient norm: 13.17978106
INFO:root:At the start of the epoch: mem (CPU python)=20806.21875MB; mem (CPU total)=34232.2109375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  104] Training loss: 0.59983476, Validation loss: 0.60142267, Gradient norm: 13.32901429
INFO:root:At the start of the epoch: mem (CPU python)=20827.3828125MB; mem (CPU total)=34266.1875MB
INFO:root:[  105] Training loss: 0.59895638, Validation loss: 0.60242966, Gradient norm: 9.89104215
INFO:root:At the start of the epoch: mem (CPU python)=20848.546875MB; mem (CPU total)=34301.66015625MB
INFO:root:[  106] Training loss: 0.59891267, Validation loss: 0.60005435, Gradient norm: 9.77865604
INFO:root:At the start of the epoch: mem (CPU python)=20869.7109375MB; mem (CPU total)=34337.14453125MB
INFO:root:[  107] Training loss: 0.59893161, Validation loss: 0.60022887, Gradient norm: 9.48022872
INFO:root:At the start of the epoch: mem (CPU python)=20890.87109375MB; mem (CPU total)=34370.640625MB
INFO:root:[  108] Training loss: 0.59859547, Validation loss: 0.60227516, Gradient norm: 9.89166943
INFO:root:At the start of the epoch: mem (CPU python)=20912.03515625MB; mem (CPU total)=34407.8046875MB
INFO:root:[  109] Training loss: 0.59909969, Validation loss: 0.59943091, Gradient norm: 10.42806162
INFO:root:At the start of the epoch: mem (CPU python)=20933.203125MB; mem (CPU total)=34441.515625MB
INFO:root:[  110] Training loss: 0.59891451, Validation loss: 0.59922302, Gradient norm: 11.83657770
INFO:root:At the start of the epoch: mem (CPU python)=20954.36328125MB; mem (CPU total)=34475.49609375MB
INFO:root:[  111] Training loss: 0.59876593, Validation loss: 0.59942357, Gradient norm: 11.97127501
INFO:root:At the start of the epoch: mem (CPU python)=20975.52734375MB; mem (CPU total)=34513.58203125MB
INFO:root:[  112] Training loss: 0.59845003, Validation loss: 0.60000251, Gradient norm: 11.46108564
INFO:root:At the start of the epoch: mem (CPU python)=20996.69140625MB; mem (CPU total)=34545.8046875MB
INFO:root:[  113] Training loss: 0.59857672, Validation loss: 0.59982521, Gradient norm: 12.39325749
INFO:root:At the start of the epoch: mem (CPU python)=21017.85546875MB; mem (CPU total)=34579.99609375MB
INFO:root:[  114] Training loss: 0.59888271, Validation loss: 0.59943883, Gradient norm: 15.26894987
INFO:root:At the start of the epoch: mem (CPU python)=21039.01953125MB; mem (CPU total)=34617.13671875MB
INFO:root:[  115] Training loss: 0.59860249, Validation loss: 0.60050366, Gradient norm: 12.04061262
INFO:root:At the start of the epoch: mem (CPU python)=21060.1875MB; mem (CPU total)=34650.3671875MB
INFO:root:[  116] Training loss: 0.59822236, Validation loss: 0.59987550, Gradient norm: 12.47756576
INFO:root:At the start of the epoch: mem (CPU python)=21081.3515625MB; mem (CPU total)=34685.35546875MB
INFO:root:[  117] Training loss: 0.59858868, Validation loss: 0.59967521, Gradient norm: 12.72430428
INFO:root:At the start of the epoch: mem (CPU python)=21102.515625MB; mem (CPU total)=34720.98046875MB
INFO:root:[  118] Training loss: 0.59825558, Validation loss: 0.60031402, Gradient norm: 15.30331141
INFO:root:At the start of the epoch: mem (CPU python)=21123.6796875MB; mem (CPU total)=34755.4140625MB
INFO:root:[  119] Training loss: 0.59875281, Validation loss: 0.59989252, Gradient norm: 17.10677879
INFO:root:At the start of the epoch: mem (CPU python)=21144.84375MB; mem (CPU total)=34789.6328125MB
INFO:root:EP 119: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=21165.83203125MB; mem (CPU total)=34818.43359375MB
INFO:root:Training the model took 4531.119s.
INFO:root:Emptying the cuda cache took 0.039s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.52981
INFO:root:EnergyScoreValidation: 0.40042
INFO:root:CRPSValidation: 0.15613
INFO:root:Gaussian NLLValidation: 0.44591
INFO:root:CoverageValidation: 0.78971
INFO:root:IntervalWidthValidation: 0.59096
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.53945
INFO:root:EnergyScoreTest: 0.40874
INFO:root:CRPSTest: 0.15996
INFO:root:Gaussian NLLTest: 0.49804
INFO:root:CoverageTest: 0.78211
INFO:root:IntervalWidthTest: 0.59208
INFO:root:After validation: mem (CPU python)=21472.66015625MB; mem (CPU total)=34916.95703125MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=21472.66015625MB; mem (CPU total)=34923.5703125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=21472.66015625MB; mem (CPU total)=34923.81640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=34928.234375MB
INFO:root:[    1] Training loss: 0.89065444, Validation loss: 0.77722812, Gradient norm: 0.32276806
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=34966.0390625MB
INFO:root:[    2] Training loss: 0.76909913, Validation loss: 0.76489143, Gradient norm: 0.33059192
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=34998.078125MB
INFO:root:[    3] Training loss: 0.76368987, Validation loss: 0.75796734, Gradient norm: 0.54546883
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35032.03515625MB
INFO:root:[    4] Training loss: 0.75835200, Validation loss: 0.75468707, Gradient norm: 0.78660003
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35068.69140625MB
INFO:root:[    5] Training loss: 0.75331870, Validation loss: 0.74317320, Gradient norm: 1.31304754
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35102.39453125MB
INFO:root:[    6] Training loss: 0.74521078, Validation loss: 0.72920440, Gradient norm: 1.57841954
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35135.66015625MB
INFO:root:[    7] Training loss: 0.73927852, Validation loss: 0.74719648, Gradient norm: 2.06798314
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35172.27734375MB
INFO:root:[    8] Training loss: 0.73662885, Validation loss: 0.75049161, Gradient norm: 2.31331254
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35206.48046875MB
INFO:root:[    9] Training loss: 0.73137038, Validation loss: 0.73277790, Gradient norm: 2.42431453
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35240.6875MB
INFO:root:[   10] Training loss: 0.72849627, Validation loss: 0.73070474, Gradient norm: 2.70236960
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35277.3359375MB
INFO:root:[   11] Training loss: 0.72257114, Validation loss: 0.72200428, Gradient norm: 2.66583042
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35311.09765625MB
INFO:root:[   12] Training loss: 0.72548738, Validation loss: 0.71865146, Gradient norm: 3.22077804
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35347.25MB
INFO:root:[   13] Training loss: 0.71849657, Validation loss: 0.70641845, Gradient norm: 3.13893588
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35381.42578125MB
INFO:root:[   14] Training loss: 0.72092919, Validation loss: 0.71384502, Gradient norm: 3.68809413
INFO:root:At the start of the epoch: mem (CPU python)=21472.66015625MB; mem (CPU total)=35415.19140625MB
INFO:root:[   15] Training loss: 0.71701766, Validation loss: 0.71483920, Gradient norm: 3.67863293
INFO:root:At the start of the epoch: mem (CPU python)=21490.234375MB; mem (CPU total)=35452.94921875MB
INFO:root:[   16] Training loss: 0.71556955, Validation loss: 0.71061494, Gradient norm: 3.71632523
INFO:root:At the start of the epoch: mem (CPU python)=21511.3984375MB; mem (CPU total)=35485.2265625MB
INFO:root:[   17] Training loss: 0.71390111, Validation loss: 0.72427685, Gradient norm: 4.07450839
INFO:root:At the start of the epoch: mem (CPU python)=21532.5625MB; mem (CPU total)=35518.46875MB
INFO:root:[   18] Training loss: 0.71271001, Validation loss: 0.74011887, Gradient norm: 4.01421802
INFO:root:At the start of the epoch: mem (CPU python)=21553.72265625MB; mem (CPU total)=35555.890625MB
INFO:root:[   19] Training loss: 0.71284600, Validation loss: 0.71211688, Gradient norm: 4.45612661
INFO:root:At the start of the epoch: mem (CPU python)=21574.890625MB; mem (CPU total)=35588.6328125MB
INFO:root:[   20] Training loss: 0.70938838, Validation loss: 0.72015486, Gradient norm: 4.70156363
INFO:root:At the start of the epoch: mem (CPU python)=21596.0546875MB; mem (CPU total)=35622.578125MB
INFO:root:[   21] Training loss: 0.71255482, Validation loss: 0.70455924, Gradient norm: 4.88735371
INFO:root:At the start of the epoch: mem (CPU python)=21617.21875MB; mem (CPU total)=35659.19921875MB
INFO:root:[   22] Training loss: 0.71379395, Validation loss: 0.74163491, Gradient norm: 5.26554467
INFO:root:At the start of the epoch: mem (CPU python)=21638.37890625MB; mem (CPU total)=35692.98046875MB
INFO:root:[   23] Training loss: 0.70621491, Validation loss: 0.71074297, Gradient norm: 4.86291371
INFO:root:At the start of the epoch: mem (CPU python)=21659.54296875MB; mem (CPU total)=35727.203125MB
INFO:root:[   24] Training loss: 0.71965535, Validation loss: 0.69251441, Gradient norm: 6.18313966
INFO:root:At the start of the epoch: mem (CPU python)=21680.70703125MB; mem (CPU total)=35763.3828125MB
INFO:root:[   25] Training loss: 0.70605411, Validation loss: 0.71314849, Gradient norm: 5.14316418
INFO:root:At the start of the epoch: mem (CPU python)=21701.87109375MB; mem (CPU total)=35797.6015625MB
INFO:root:[   26] Training loss: 0.70465069, Validation loss: 0.76637715, Gradient norm: 5.59853689
INFO:root:At the start of the epoch: mem (CPU python)=21723.0390625MB; mem (CPU total)=35833.7734375MB
INFO:root:[   27] Training loss: 0.70891531, Validation loss: 0.69602181, Gradient norm: 5.84101512
INFO:root:At the start of the epoch: mem (CPU python)=21744.203125MB; mem (CPU total)=35868.23046875MB
INFO:root:[   28] Training loss: 0.72008845, Validation loss: 0.70876443, Gradient norm: 6.76778675
INFO:root:At the start of the epoch: mem (CPU python)=21765.36328125MB; mem (CPU total)=35901.94140625MB
INFO:root:[   29] Training loss: 0.71550185, Validation loss: 0.72646055, Gradient norm: 6.47660938
INFO:root:At the start of the epoch: mem (CPU python)=21786.52734375MB; mem (CPU total)=35939.59765625MB
INFO:root:[   30] Training loss: 0.71205706, Validation loss: 0.70049975, Gradient norm: 6.43758733
INFO:root:At the start of the epoch: mem (CPU python)=21807.69140625MB; mem (CPU total)=35972.5703125MB
INFO:root:[   31] Training loss: 0.71258390, Validation loss: 0.71147210, Gradient norm: 6.76389731
INFO:root:At the start of the epoch: mem (CPU python)=21828.859375MB; mem (CPU total)=36006.7578125MB
INFO:root:[   32] Training loss: 0.71634279, Validation loss: 0.71439984, Gradient norm: 6.74262554
INFO:root:At the start of the epoch: mem (CPU python)=21850.0234375MB; mem (CPU total)=36044.3515625MB
INFO:root:[   33] Training loss: 0.70820787, Validation loss: 0.72094082, Gradient norm: 6.09870905
INFO:root:At the start of the epoch: mem (CPU python)=21871.1875MB; mem (CPU total)=36077.328125MB
INFO:root:[   34] Training loss: 0.71187006, Validation loss: 0.71093850, Gradient norm: 6.45936678
INFO:root:At the start of the epoch: mem (CPU python)=21892.3515625MB; mem (CPU total)=36111.4921875MB
INFO:root:[   35] Training loss: 0.70780728, Validation loss: 0.74188268, Gradient norm: 6.20861994
INFO:root:At the start of the epoch: mem (CPU python)=21913.515625MB; mem (CPU total)=36147.69921875MB
INFO:root:[   36] Training loss: 0.70621311, Validation loss: 0.69664127, Gradient norm: 6.76217448
INFO:root:At the start of the epoch: mem (CPU python)=21934.68359375MB; mem (CPU total)=36181.67578125MB
INFO:root:[   37] Training loss: 0.70535502, Validation loss: 0.70754120, Gradient norm: 6.53364974
INFO:root:At the start of the epoch: mem (CPU python)=21955.84375MB; mem (CPU total)=36216.14453125MB
INFO:root:[   38] Training loss: 0.70509200, Validation loss: 0.70882188, Gradient norm: 6.88395033
INFO:root:At the start of the epoch: mem (CPU python)=21977.015625MB; mem (CPU total)=36252.203125MB
INFO:root:[   39] Training loss: 0.70289507, Validation loss: 0.69687282, Gradient norm: 6.63717329
INFO:root:At the start of the epoch: mem (CPU python)=21998.17578125MB; mem (CPU total)=36286.3984375MB
INFO:root:[   40] Training loss: 0.71125202, Validation loss: 0.70722639, Gradient norm: 7.60105663
INFO:root:At the start of the epoch: mem (CPU python)=22019.33984375MB; mem (CPU total)=36321.8046875MB
INFO:root:[   41] Training loss: 0.71401358, Validation loss: 0.71576565, Gradient norm: 7.69490817
INFO:root:At the start of the epoch: mem (CPU python)=22040.5078125MB; mem (CPU total)=36356.2578125MB
INFO:root:[   42] Training loss: 0.71318188, Validation loss: 0.71244513, Gradient norm: 8.10022164
INFO:root:At the start of the epoch: mem (CPU python)=22061.671875MB; mem (CPU total)=36390.69140625MB
INFO:root:[   43] Training loss: 0.71345230, Validation loss: 0.71763701, Gradient norm: 8.01928898
INFO:root:At the start of the epoch: mem (CPU python)=22082.8359375MB; mem (CPU total)=36428.09765625MB
INFO:root:[   44] Training loss: 0.71148850, Validation loss: 0.69290037, Gradient norm: 8.00994485
INFO:root:At the start of the epoch: mem (CPU python)=22104.0MB; mem (CPU total)=36461.56640625MB
INFO:root:[   45] Training loss: 0.70590077, Validation loss: 0.68578597, Gradient norm: 7.55989847
INFO:root:At the start of the epoch: mem (CPU python)=22125.1640625MB; mem (CPU total)=36495.12109375MB
INFO:root:[   46] Training loss: 0.70562637, Validation loss: 0.69932060, Gradient norm: 7.80985366
INFO:root:At the start of the epoch: mem (CPU python)=22146.328125MB; mem (CPU total)=36533.734375MB
INFO:root:[   47] Training loss: 0.70745529, Validation loss: 0.70221337, Gradient norm: 8.33922835
INFO:root:At the start of the epoch: mem (CPU python)=22167.48828125MB; mem (CPU total)=36565.95703125MB
INFO:root:[   48] Training loss: 0.70809924, Validation loss: 0.69990753, Gradient norm: 8.35168239
INFO:root:At the start of the epoch: mem (CPU python)=22188.65625MB; mem (CPU total)=36599.69140625MB
INFO:root:[   49] Training loss: 0.70688729, Validation loss: 0.69767564, Gradient norm: 8.60455530
INFO:root:At the start of the epoch: mem (CPU python)=22209.8203125MB; mem (CPU total)=36637.3671875MB
INFO:root:[   50] Training loss: 0.70930936, Validation loss: 0.69058657, Gradient norm: 8.98732205
INFO:root:At the start of the epoch: mem (CPU python)=22230.984375MB; mem (CPU total)=36670.8046875MB
INFO:root:[   51] Training loss: 0.70601102, Validation loss: 0.70115987, Gradient norm: 8.35500314
INFO:root:At the start of the epoch: mem (CPU python)=22252.1484375MB; mem (CPU total)=36704.51171875MB
INFO:root:[   52] Training loss: 0.70847675, Validation loss: 0.67532950, Gradient norm: 8.83510982
INFO:root:At the start of the epoch: mem (CPU python)=22273.3125MB; mem (CPU total)=36741.1796875MB
INFO:root:[   53] Training loss: 0.71105354, Validation loss: 0.71579837, Gradient norm: 8.74270487
INFO:root:At the start of the epoch: mem (CPU python)=22294.4765625MB; mem (CPU total)=36775.3046875MB
INFO:root:[   54] Training loss: 0.70459688, Validation loss: 0.71075673, Gradient norm: 8.50453738
INFO:root:At the start of the epoch: mem (CPU python)=22315.64453125MB; mem (CPU total)=36810.00390625MB
INFO:root:[   55] Training loss: 0.70953338, Validation loss: 0.71206805, Gradient norm: 9.02772722
INFO:root:At the start of the epoch: mem (CPU python)=22336.8046875MB; mem (CPU total)=36846.1484375MB
INFO:root:[   56] Training loss: 0.71346251, Validation loss: 0.71050529, Gradient norm: 9.22012688
INFO:root:At the start of the epoch: mem (CPU python)=22357.96484375MB; mem (CPU total)=36879.5859375MB
INFO:root:[   57] Training loss: 0.71681815, Validation loss: 0.71559342, Gradient norm: 9.81737784
INFO:root:At the start of the epoch: mem (CPU python)=22379.12890625MB; mem (CPU total)=36916.0078125MB
INFO:root:[   58] Training loss: 0.70431812, Validation loss: 0.69075813, Gradient norm: 8.51990475
INFO:root:At the start of the epoch: mem (CPU python)=22400.29296875MB; mem (CPU total)=36950.70703125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   59] Training loss: 0.70777957, Validation loss: 0.77361187, Gradient norm: 9.25569257
INFO:root:At the start of the epoch: mem (CPU python)=22421.4609375MB; mem (CPU total)=36984.16015625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   60] Training loss: 0.67139026, Validation loss: 0.68221627, Gradient norm: 7.58658141
INFO:root:At the start of the epoch: mem (CPU python)=22442.625MB; mem (CPU total)=37021.9921875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   61] Training loss: 0.65242472, Validation loss: 0.65084947, Gradient norm: 5.80349248
INFO:root:At the start of the epoch: mem (CPU python)=22463.7890625MB; mem (CPU total)=37055.6796875MB
INFO:root:[   62] Training loss: 0.64579563, Validation loss: 0.64409880, Gradient norm: 4.61988692
INFO:root:At the start of the epoch: mem (CPU python)=22484.953125MB; mem (CPU total)=37088.96875MB
INFO:root:[   63] Training loss: 0.64433536, Validation loss: 0.64501258, Gradient norm: 5.71849059
INFO:root:At the start of the epoch: mem (CPU python)=22506.1171875MB; mem (CPU total)=37127.8515625MB
INFO:root:[   64] Training loss: 0.64473987, Validation loss: 0.64661837, Gradient norm: 6.90954443
INFO:root:At the start of the epoch: mem (CPU python)=22527.28515625MB; mem (CPU total)=37160.3359375MB
INFO:root:[   65] Training loss: 0.64482828, Validation loss: 0.64786907, Gradient norm: 7.55719805
INFO:root:At the start of the epoch: mem (CPU python)=22548.44921875MB; mem (CPU total)=37152.22265625MB
INFO:root:[   66] Training loss: 0.64812533, Validation loss: 0.65582840, Gradient norm: 10.58834775
INFO:root:At the start of the epoch: mem (CPU python)=22569.609375MB; mem (CPU total)=37177.078125MB
INFO:root:[   67] Training loss: 0.64949497, Validation loss: 0.65167675, Gradient norm: 9.76199588
INFO:root:At the start of the epoch: mem (CPU python)=22590.7734375MB; mem (CPU total)=37202.42578125MB
INFO:root:[   68] Training loss: 0.64770998, Validation loss: 0.64638732, Gradient norm: 7.52254639
INFO:root:At the start of the epoch: mem (CPU python)=22611.9375MB; mem (CPU total)=37224.55859375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   69] Training loss: 0.64620541, Validation loss: 0.64784093, Gradient norm: 8.88859182
INFO:root:At the start of the epoch: mem (CPU python)=22633.10546875MB; mem (CPU total)=37246.65625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   70] Training loss: 0.64334837, Validation loss: 0.64395537, Gradient norm: 5.32626446
INFO:root:At the start of the epoch: mem (CPU python)=22654.26953125MB; mem (CPU total)=37269.01171875MB
INFO:root:[   71] Training loss: 0.64144841, Validation loss: 0.64132173, Gradient norm: 4.21735869
INFO:root:At the start of the epoch: mem (CPU python)=22675.43359375MB; mem (CPU total)=37324.7890625MB
INFO:root:[   72] Training loss: 0.64158760, Validation loss: 0.64167577, Gradient norm: 5.30061551
INFO:root:At the start of the epoch: mem (CPU python)=22696.59765625MB; mem (CPU total)=37359.13671875MB
INFO:root:[   73] Training loss: 0.64182836, Validation loss: 0.64258457, Gradient norm: 5.23189985
INFO:root:At the start of the epoch: mem (CPU python)=22717.7578125MB; mem (CPU total)=37393.13671875MB
INFO:root:[   74] Training loss: 0.64124517, Validation loss: 0.64164863, Gradient norm: 7.09059122
INFO:root:At the start of the epoch: mem (CPU python)=22738.92578125MB; mem (CPU total)=37430.328125MB
INFO:root:[   75] Training loss: 0.64138925, Validation loss: 0.64297244, Gradient norm: 5.73103802
INFO:root:At the start of the epoch: mem (CPU python)=22760.0859375MB; mem (CPU total)=37464.296875MB
INFO:root:[   76] Training loss: 0.64168189, Validation loss: 0.64187760, Gradient norm: 5.96046783
INFO:root:At the start of the epoch: mem (CPU python)=22781.25MB; mem (CPU total)=37497.7421875MB
INFO:root:[   77] Training loss: 0.64130503, Validation loss: 0.64316545, Gradient norm: 7.05323146
INFO:root:At the start of the epoch: mem (CPU python)=22802.4140625MB; mem (CPU total)=37536.61328125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   78] Training loss: 0.64161919, Validation loss: 0.64158082, Gradient norm: 6.97465516
INFO:root:At the start of the epoch: mem (CPU python)=22823.578125MB; mem (CPU total)=37569.2734375MB
INFO:root:[   79] Training loss: 0.64041488, Validation loss: 0.64174881, Gradient norm: 5.18164533
INFO:root:At the start of the epoch: mem (CPU python)=22844.7421875MB; mem (CPU total)=37602.96875MB
INFO:root:[   80] Training loss: 0.64045518, Validation loss: 0.64167692, Gradient norm: 5.00974486
INFO:root:At the start of the epoch: mem (CPU python)=22865.90625MB; mem (CPU total)=37641.8125MB
INFO:root:EP 80: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=22887.07421875MB; mem (CPU total)=37666.6640625MB
INFO:root:Training the model took 3173.118s.
INFO:root:Emptying the cuda cache took 0.038s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.56862
INFO:root:EnergyScoreValidation: 0.43061
INFO:root:CRPSValidation: 0.17651
INFO:root:Gaussian NLLValidation: 0.65143
INFO:root:CoverageValidation: 0.74755
INFO:root:IntervalWidthValidation: 0.62632
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.57741
INFO:root:EnergyScoreTest: 0.43791
INFO:root:CRPSTest: 0.17998
INFO:root:Gaussian NLLTest: 0.69297
INFO:root:CoverageTest: 0.74277
INFO:root:IntervalWidthTest: 0.63044
INFO:root:After validation: mem (CPU python)=23193.7734375MB; mem (CPU total)=37763.53125MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.3, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=23193.7734375MB; mem (CPU total)=37771.3984375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=23193.7734375MB; mem (CPU total)=37771.3984375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=37778.03515625MB
INFO:root:[    1] Training loss: 0.91148850, Validation loss: 0.78543667, Gradient norm: 0.34498457
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=37814.05859375MB
INFO:root:[    2] Training loss: 0.77848178, Validation loss: 0.77562927, Gradient norm: 0.25048972
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=37847.3125MB
INFO:root:[    3] Training loss: 0.77014527, Validation loss: 0.76652339, Gradient norm: 0.33547879
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=37885.2109375MB
INFO:root:[    4] Training loss: 0.76947195, Validation loss: 0.77195521, Gradient norm: 0.68171746
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=37918.3671875MB
INFO:root:[    5] Training loss: 0.76539464, Validation loss: 0.76119911, Gradient norm: 0.98382504
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=37952.08984375MB
INFO:root:[    6] Training loss: 0.76602868, Validation loss: 0.76419763, Gradient norm: 1.38921347
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=37992.27734375MB
INFO:root:[    7] Training loss: 0.75829054, Validation loss: 0.74486744, Gradient norm: 1.69338475
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=38024.7734375MB
INFO:root:[    8] Training loss: 0.75999408, Validation loss: 0.75922625, Gradient norm: 2.51368363
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=38058.47265625MB
INFO:root:[    9] Training loss: 0.75835277, Validation loss: 0.79353143, Gradient norm: 2.81433941
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=38097.6328125MB
INFO:root:[   10] Training loss: 0.75555245, Validation loss: 0.75370488, Gradient norm: 3.01131548
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=38129.55078125MB
INFO:root:[   11] Training loss: 0.75487248, Validation loss: 0.75493329, Gradient norm: 3.20091370
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=38163.54296875MB
INFO:root:[   12] Training loss: 0.75172652, Validation loss: 0.76313668, Gradient norm: 3.26759291
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=38201.9453125MB
INFO:root:[   13] Training loss: 0.75271890, Validation loss: 0.76997000, Gradient norm: 3.47701492
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=38234.921875MB
INFO:root:[   14] Training loss: 0.75297873, Validation loss: 0.77000165, Gradient norm: 3.83672720
INFO:root:At the start of the epoch: mem (CPU python)=23193.7734375MB; mem (CPU total)=38268.78125MB
INFO:root:[   15] Training loss: 0.74413359, Validation loss: 0.74480406, Gradient norm: 3.64452556
INFO:root:At the start of the epoch: mem (CPU python)=23211.296875MB; mem (CPU total)=38306.46484375MB
INFO:root:[   16] Training loss: 0.75140760, Validation loss: 0.73042704, Gradient norm: 4.45492453
INFO:root:At the start of the epoch: mem (CPU python)=23232.4609375MB; mem (CPU total)=38340.203125MB
INFO:root:[   17] Training loss: 0.74733552, Validation loss: 0.74027068, Gradient norm: 4.28579619
INFO:root:At the start of the epoch: mem (CPU python)=23253.625MB; mem (CPU total)=38374.4453125MB
INFO:root:[   18] Training loss: 0.74603338, Validation loss: 0.73571377, Gradient norm: 4.37529457
INFO:root:At the start of the epoch: mem (CPU python)=23274.7890625MB; mem (CPU total)=38410.94140625MB
INFO:root:[   19] Training loss: 0.74745229, Validation loss: 0.74416765, Gradient norm: 5.06623456
INFO:root:At the start of the epoch: mem (CPU python)=23295.95703125MB; mem (CPU total)=38445.35546875MB
INFO:root:[   20] Training loss: 0.74793250, Validation loss: 0.74999936, Gradient norm: 5.10027767
INFO:root:At the start of the epoch: mem (CPU python)=23317.12109375MB; mem (CPU total)=38479.5546875MB
INFO:root:[   21] Training loss: 0.74753871, Validation loss: 0.74001128, Gradient norm: 5.17393066
INFO:root:At the start of the epoch: mem (CPU python)=23338.28515625MB; mem (CPU total)=38516.9453125MB
INFO:root:[   22] Training loss: 0.74845423, Validation loss: 0.72774585, Gradient norm: 5.11293449
INFO:root:At the start of the epoch: mem (CPU python)=23359.4453125MB; mem (CPU total)=38550.4140625MB
INFO:root:[   23] Training loss: 0.74197900, Validation loss: 0.74409919, Gradient norm: 5.02698596
INFO:root:At the start of the epoch: mem (CPU python)=23380.609375MB; mem (CPU total)=38585.01953125MB
INFO:root:[   24] Training loss: 0.74778116, Validation loss: 0.77614151, Gradient norm: 5.65979039
INFO:root:At the start of the epoch: mem (CPU python)=23401.7734375MB; mem (CPU total)=38621.43359375MB
INFO:root:[   25] Training loss: 0.74639963, Validation loss: 0.72632179, Gradient norm: 5.51974500
INFO:root:At the start of the epoch: mem (CPU python)=23422.94140625MB; mem (CPU total)=38656.3515625MB
INFO:root:[   26] Training loss: 0.74476423, Validation loss: 0.75338438, Gradient norm: 5.64091698
INFO:root:At the start of the epoch: mem (CPU python)=23444.1015625MB; mem (CPU total)=38692.84375MB
INFO:root:[   27] Training loss: 0.74151095, Validation loss: 0.75209420, Gradient norm: 5.65363631
INFO:root:At the start of the epoch: mem (CPU python)=23465.265625MB; mem (CPU total)=38727.765625MB
INFO:root:[   28] Training loss: 0.74859989, Validation loss: 0.73665338, Gradient norm: 5.96743992
INFO:root:At the start of the epoch: mem (CPU python)=23486.4296875MB; mem (CPU total)=38761.7421875MB
INFO:root:[   29] Training loss: 0.74388710, Validation loss: 0.74941897, Gradient norm: 6.00187628
INFO:root:At the start of the epoch: mem (CPU python)=23507.59375MB; mem (CPU total)=38799.625MB
INFO:root:[   30] Training loss: 0.75081728, Validation loss: 0.75452689, Gradient norm: 6.73310954
INFO:root:At the start of the epoch: mem (CPU python)=23528.7578125MB; mem (CPU total)=38834.4375MB
INFO:root:[   31] Training loss: 0.74410826, Validation loss: 0.74863996, Gradient norm: 6.28418519
INFO:root:At the start of the epoch: mem (CPU python)=23549.921875MB; mem (CPU total)=38868.12890625MB
INFO:root:[   32] Training loss: 0.75421342, Validation loss: 0.77752220, Gradient norm: 7.36162910
INFO:root:At the start of the epoch: mem (CPU python)=23571.0859375MB; mem (CPU total)=38905.08984375MB
INFO:root:[   33] Training loss: 0.74685015, Validation loss: 0.73892092, Gradient norm: 6.83822603
INFO:root:At the start of the epoch: mem (CPU python)=23592.25MB; mem (CPU total)=38938.64453125MB
INFO:root:[   34] Training loss: 0.75045318, Validation loss: 0.73447520, Gradient norm: 6.91243252
INFO:root:At the start of the epoch: mem (CPU python)=23613.4140625MB; mem (CPU total)=38972.37109375MB
INFO:root:[   35] Training loss: 0.74181293, Validation loss: 0.75123314, Gradient norm: 6.61510346
INFO:root:At the start of the epoch: mem (CPU python)=23634.578125MB; mem (CPU total)=39012.0859375MB
INFO:root:[   36] Training loss: 0.74531361, Validation loss: 0.76296126, Gradient norm: 7.05087199
INFO:root:At the start of the epoch: mem (CPU python)=23655.74609375MB; mem (CPU total)=39045.54296875MB
INFO:root:[   37] Training loss: 0.75567306, Validation loss: 0.75757656, Gradient norm: 7.72488108
INFO:root:At the start of the epoch: mem (CPU python)=23676.91015625MB; mem (CPU total)=39078.53515625MB
INFO:root:[   38] Training loss: 0.75108225, Validation loss: 0.72011274, Gradient norm: 7.49833814
INFO:root:At the start of the epoch: mem (CPU python)=23698.07421875MB; mem (CPU total)=39118.58984375MB
INFO:root:[   39] Training loss: 0.74528985, Validation loss: 0.76553375, Gradient norm: 7.46125240
INFO:root:At the start of the epoch: mem (CPU python)=23719.23828125MB; mem (CPU total)=39150.2578125MB
INFO:root:[   40] Training loss: 0.74848600, Validation loss: 0.74773709, Gradient norm: 7.35989759
INFO:root:At the start of the epoch: mem (CPU python)=23740.40234375MB; mem (CPU total)=39183.73828125MB
INFO:root:[   41] Training loss: 0.74914610, Validation loss: 0.79966519, Gradient norm: 7.87194216
INFO:root:At the start of the epoch: mem (CPU python)=23761.5625MB; mem (CPU total)=39222.62109375MB
INFO:root:[   42] Training loss: 0.75589887, Validation loss: 0.73972845, Gradient norm: 8.13908082
INFO:root:At the start of the epoch: mem (CPU python)=23782.7265625MB; mem (CPU total)=39255.59375MB
INFO:root:[   43] Training loss: 0.75054067, Validation loss: 0.75563788, Gradient norm: 7.74741929
INFO:root:At the start of the epoch: mem (CPU python)=23803.89453125MB; mem (CPU total)=39289.29296875MB
INFO:root:[   44] Training loss: 0.75706355, Validation loss: 0.73490599, Gradient norm: 8.59550155
INFO:root:At the start of the epoch: mem (CPU python)=23825.0546875MB; mem (CPU total)=39327.6484375MB
INFO:root:[   45] Training loss: 0.76183477, Validation loss: 0.75870396, Gradient norm: 8.57151160
INFO:root:At the start of the epoch: mem (CPU python)=23846.21875MB; mem (CPU total)=39360.87109375MB
INFO:root:[   46] Training loss: 0.75055566, Validation loss: 0.77022269, Gradient norm: 8.04224975
INFO:root:At the start of the epoch: mem (CPU python)=23867.3828125MB; mem (CPU total)=39394.828125MB
INFO:root:[   47] Training loss: 0.75783689, Validation loss: 0.77432134, Gradient norm: 8.42728162
INFO:root:At the start of the epoch: mem (CPU python)=23888.546875MB; mem (CPU total)=39432.30078125MB
INFO:root:[   48] Training loss: 0.76099089, Validation loss: 0.72805275, Gradient norm: 8.59442898
INFO:root:At the start of the epoch: mem (CPU python)=23909.7109375MB; mem (CPU total)=39466.5078125MB
INFO:root:[   49] Training loss: 0.74081062, Validation loss: 0.71851141, Gradient norm: 7.73043354
INFO:root:At the start of the epoch: mem (CPU python)=23930.87890625MB; mem (CPU total)=39500.95703125MB
INFO:root:[   50] Training loss: 0.75267126, Validation loss: 0.74708885, Gradient norm: 9.02718975
INFO:root:At the start of the epoch: mem (CPU python)=23952.0390625MB; mem (CPU total)=39538.109375MB
INFO:root:[   51] Training loss: 0.75688651, Validation loss: 0.75652642, Gradient norm: 9.57080151
INFO:root:At the start of the epoch: mem (CPU python)=23973.203125MB; mem (CPU total)=39571.8203125MB
INFO:root:[   52] Training loss: 0.77161663, Validation loss: 0.75233821, Gradient norm: 10.19012939
INFO:root:At the start of the epoch: mem (CPU python)=23994.3671875MB; mem (CPU total)=39606.51953125MB
INFO:root:[   53] Training loss: 0.75717684, Validation loss: 0.80026185, Gradient norm: 9.49601372
INFO:root:At the start of the epoch: mem (CPU python)=24015.53125MB; mem (CPU total)=39643.1796875MB
INFO:root:[   54] Training loss: 0.76043690, Validation loss: 0.72961200, Gradient norm: 9.63364324
INFO:root:At the start of the epoch: mem (CPU python)=24036.69921875MB; mem (CPU total)=39676.87890625MB
INFO:root:[   55] Training loss: 0.77423467, Validation loss: 0.75660699, Gradient norm: 10.75183176
INFO:root:At the start of the epoch: mem (CPU python)=24057.86328125MB; mem (CPU total)=39712.34375MB
INFO:root:[   56] Training loss: 0.76120711, Validation loss: 0.78651384, Gradient norm: 10.14641351
INFO:root:At the start of the epoch: mem (CPU python)=24079.02734375MB; mem (CPU total)=39748.125MB
INFO:root:[   57] Training loss: 0.77277609, Validation loss: 0.78096802, Gradient norm: 11.03812854
INFO:root:At the start of the epoch: mem (CPU python)=24100.19140625MB; mem (CPU total)=39782.0546875MB
INFO:root:[   58] Training loss: 0.77838380, Validation loss: 0.80703617, Gradient norm: 10.10626344
INFO:root:At the start of the epoch: mem (CPU python)=24121.35546875MB; mem (CPU total)=39818.51953125MB
INFO:root:[   59] Training loss: 0.78005483, Validation loss: 0.75767125, Gradient norm: 11.37521270
INFO:root:At the start of the epoch: mem (CPU python)=24142.53125MB; mem (CPU total)=39854.203125MB
INFO:root:[   60] Training loss: 0.76544502, Validation loss: 0.77204936, Gradient norm: 10.23245021
INFO:root:At the start of the epoch: mem (CPU python)=24163.6953125MB; mem (CPU total)=39887.671875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.77759454, Validation loss: 0.79056282, Gradient norm: 10.75623193
INFO:root:At the start of the epoch: mem (CPU python)=24184.8671875MB; mem (CPU total)=39924.87890625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 0.71736003, Validation loss: 0.71610945, Gradient norm: 9.31973864
INFO:root:At the start of the epoch: mem (CPU python)=24206.04296875MB; mem (CPU total)=39959.30078125MB
INFO:root:[   63] Training loss: 0.69664107, Validation loss: 0.69924356, Gradient norm: 8.38517981
INFO:root:At the start of the epoch: mem (CPU python)=24227.20703125MB; mem (CPU total)=39992.80078125MB
INFO:root:[   64] Training loss: 0.69777014, Validation loss: 0.68955079, Gradient norm: 10.34472752
INFO:root:At the start of the epoch: mem (CPU python)=24248.3828125MB; mem (CPU total)=40030.44921875MB
INFO:root:[   65] Training loss: 0.69736981, Validation loss: 0.70332229, Gradient norm: 11.02339884
INFO:root:At the start of the epoch: mem (CPU python)=24269.546875MB; mem (CPU total)=40064.625MB
INFO:root:[   66] Training loss: 0.69975203, Validation loss: 0.70055947, Gradient norm: 12.86339753
INFO:root:At the start of the epoch: mem (CPU python)=24290.72265625MB; mem (CPU total)=40098.37109375MB
INFO:root:[   67] Training loss: 0.70283244, Validation loss: 0.71200580, Gradient norm: 13.51648425
INFO:root:At the start of the epoch: mem (CPU python)=24311.8984375MB; mem (CPU total)=40137.0546875MB
INFO:root:[   68] Training loss: 0.70568986, Validation loss: 0.71245315, Gradient norm: 15.24559903
INFO:root:At the start of the epoch: mem (CPU python)=24333.0625MB; mem (CPU total)=40171.26953125MB
INFO:root:[   69] Training loss: 0.70569706, Validation loss: 0.70792724, Gradient norm: 16.25242626
INFO:root:At the start of the epoch: mem (CPU python)=24354.234375MB; mem (CPU total)=40207.84375MB
INFO:root:[   70] Training loss: 0.70600174, Validation loss: 0.70460431, Gradient norm: 16.74003213
INFO:root:At the start of the epoch: mem (CPU python)=24375.40234375MB; mem (CPU total)=40246.2265625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   71] Training loss: 0.70970150, Validation loss: 0.71056146, Gradient norm: 18.22887280
INFO:root:At the start of the epoch: mem (CPU python)=24396.58203125MB; mem (CPU total)=40278.8828125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   72] Training loss: 0.69162850, Validation loss: 0.68753706, Gradient norm: 13.91480186
INFO:root:At the start of the epoch: mem (CPU python)=24417.74609375MB; mem (CPU total)=40313.08984375MB
INFO:root:[   73] Training loss: 0.68266317, Validation loss: 0.68462178, Gradient norm: 8.55926079
INFO:root:At the start of the epoch: mem (CPU python)=24438.92578125MB; mem (CPU total)=40351.671875MB
INFO:root:[   74] Training loss: 0.68148176, Validation loss: 0.68443038, Gradient norm: 10.81888145
INFO:root:At the start of the epoch: mem (CPU python)=24460.1015625MB; mem (CPU total)=40384.18359375MB
INFO:root:[   75] Training loss: 0.68221287, Validation loss: 0.68298474, Gradient norm: 11.59771887
INFO:root:At the start of the epoch: mem (CPU python)=24481.26953125MB; mem (CPU total)=40417.8828125MB
INFO:root:[   76] Training loss: 0.68222792, Validation loss: 0.69141290, Gradient norm: 12.46948361
INFO:root:At the start of the epoch: mem (CPU python)=24502.4453125MB; mem (CPU total)=40457.26953125MB
INFO:root:[   77] Training loss: 0.68297853, Validation loss: 0.68458640, Gradient norm: 12.89321737
INFO:root:At the start of the epoch: mem (CPU python)=24523.6171875MB; mem (CPU total)=40489.53125MB
INFO:root:[   78] Training loss: 0.68292592, Validation loss: 0.68742478, Gradient norm: 13.52927671
INFO:root:At the start of the epoch: mem (CPU python)=24544.7734375MB; mem (CPU total)=40523.2265625MB
INFO:root:[   79] Training loss: 0.68194806, Validation loss: 0.68432739, Gradient norm: 15.05945812
INFO:root:At the start of the epoch: mem (CPU python)=24565.953125MB; mem (CPU total)=40563.1484375MB
INFO:root:[   80] Training loss: 0.68179963, Validation loss: 0.68191650, Gradient norm: 14.17404763
INFO:root:At the start of the epoch: mem (CPU python)=24587.12109375MB; mem (CPU total)=40594.640625MB
INFO:root:[   81] Training loss: 0.68204402, Validation loss: 0.68180610, Gradient norm: 14.65843323
INFO:root:At the start of the epoch: mem (CPU python)=24608.30078125MB; mem (CPU total)=40628.6484375MB
INFO:root:[   82] Training loss: 0.68249085, Validation loss: 0.68266817, Gradient norm: 15.36094080
INFO:root:At the start of the epoch: mem (CPU python)=24629.46484375MB; mem (CPU total)=40668.203125MB
INFO:root:[   83] Training loss: 0.68268400, Validation loss: 0.68384650, Gradient norm: 15.57637958
INFO:root:At the start of the epoch: mem (CPU python)=24650.64453125MB; mem (CPU total)=40699.68359375MB
INFO:root:[   84] Training loss: 0.68325364, Validation loss: 0.68409975, Gradient norm: 16.17814520
INFO:root:At the start of the epoch: mem (CPU python)=24671.81640625MB; mem (CPU total)=40733.890625MB
INFO:root:[   85] Training loss: 0.68315725, Validation loss: 0.68434840, Gradient norm: 16.74287912
INFO:root:At the start of the epoch: mem (CPU python)=24692.98046875MB; mem (CPU total)=40773.9921875MB
INFO:root:[   86] Training loss: 0.68282854, Validation loss: 0.68365680, Gradient norm: 17.31455702
INFO:root:At the start of the epoch: mem (CPU python)=24714.15625MB; mem (CPU total)=40806.52734375MB
INFO:root:[   87] Training loss: 0.68440480, Validation loss: 0.68213430, Gradient norm: 17.95342837
INFO:root:At the start of the epoch: mem (CPU python)=24735.33203125MB; mem (CPU total)=40840.42578125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   88] Training loss: 0.68366826, Validation loss: 0.68447517, Gradient norm: 18.84773843
INFO:root:At the start of the epoch: mem (CPU python)=24756.5078125MB; mem (CPU total)=40878.97265625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   89] Training loss: 0.67967373, Validation loss: 0.68163116, Gradient norm: 11.18192654
INFO:root:At the start of the epoch: mem (CPU python)=24777.671875MB; mem (CPU total)=40912.73828125MB
INFO:root:[   90] Training loss: 0.67784188, Validation loss: 0.67856169, Gradient norm: 8.24598474
INFO:root:At the start of the epoch: mem (CPU python)=24798.8359375MB; mem (CPU total)=40946.30078125MB
INFO:root:[   91] Training loss: 0.67717902, Validation loss: 0.67770873, Gradient norm: 8.39810525
INFO:root:At the start of the epoch: mem (CPU python)=24820.0234375MB; mem (CPU total)=40984.37109375MB
INFO:root:[   92] Training loss: 0.67686080, Validation loss: 0.67820078, Gradient norm: 8.94601680
INFO:root:At the start of the epoch: mem (CPU python)=24841.18359375MB; mem (CPU total)=41018.8671875MB
INFO:root:[   93] Training loss: 0.67712386, Validation loss: 0.67701614, Gradient norm: 10.64482993
INFO:root:At the start of the epoch: mem (CPU python)=24862.36328125MB; mem (CPU total)=41051.9609375MB
INFO:root:[   94] Training loss: 0.67647735, Validation loss: 0.67819147, Gradient norm: 10.00428537
INFO:root:At the start of the epoch: mem (CPU python)=24883.52734375MB; mem (CPU total)=41089.578125MB
INFO:root:[   95] Training loss: 0.67616488, Validation loss: 0.67722077, Gradient norm: 10.64699705
INFO:root:At the start of the epoch: mem (CPU python)=24904.703125MB; mem (CPU total)=41123.83203125MB
INFO:root:[   96] Training loss: 0.67605031, Validation loss: 0.67626459, Gradient norm: 11.83410009
INFO:root:At the start of the epoch: mem (CPU python)=24925.875MB; mem (CPU total)=41158.55859375MB
INFO:root:[   97] Training loss: 0.67625531, Validation loss: 0.67668511, Gradient norm: 11.91564850
INFO:root:At the start of the epoch: mem (CPU python)=24947.04296875MB; mem (CPU total)=41196.6875MB
INFO:root:[   98] Training loss: 0.67584024, Validation loss: 0.67516034, Gradient norm: 12.24777798
INFO:root:At the start of the epoch: mem (CPU python)=24968.22265625MB; mem (CPU total)=41229.66796875MB
INFO:root:[   99] Training loss: 0.67551152, Validation loss: 0.67759651, Gradient norm: 13.43420843
INFO:root:At the start of the epoch: mem (CPU python)=24989.38671875MB; mem (CPU total)=41263.30078125MB
INFO:root:[  100] Training loss: 0.67525519, Validation loss: 0.67629287, Gradient norm: 13.45991608
INFO:root:At the start of the epoch: mem (CPU python)=25010.5625MB; mem (CPU total)=41301.80859375MB
INFO:root:[  101] Training loss: 0.67541945, Validation loss: 0.67604079, Gradient norm: 13.39943728
INFO:root:At the start of the epoch: mem (CPU python)=25031.7265625MB; mem (CPU total)=41334.4296875MB
INFO:root:[  102] Training loss: 0.67575106, Validation loss: 0.67677971, Gradient norm: 14.15497134
INFO:root:At the start of the epoch: mem (CPU python)=25052.90625MB; mem (CPU total)=41368.37109375MB
INFO:root:[  103] Training loss: 0.67536826, Validation loss: 0.67633411, Gradient norm: 14.02675812
INFO:root:At the start of the epoch: mem (CPU python)=25074.08203125MB; mem (CPU total)=41408.69921875MB
INFO:root:[  104] Training loss: 0.67524715, Validation loss: 0.67638689, Gradient norm: 16.25386275
INFO:root:At the start of the epoch: mem (CPU python)=25095.25MB; mem (CPU total)=41441.19921875MB
INFO:root:[  105] Training loss: 0.67658938, Validation loss: 0.67589889, Gradient norm: 23.81201822
INFO:root:At the start of the epoch: mem (CPU python)=25116.42578125MB; mem (CPU total)=41475.21875MB
INFO:root:[  106] Training loss: 0.67520945, Validation loss: 0.67463506, Gradient norm: 15.57092964
INFO:root:At the start of the epoch: mem (CPU python)=25137.5859375MB; mem (CPU total)=41514.8984375MB
INFO:root:[  107] Training loss: 0.67519544, Validation loss: 0.67627332, Gradient norm: 15.75908714
INFO:root:At the start of the epoch: mem (CPU python)=25158.765625MB; mem (CPU total)=41547.71875MB
INFO:root:[  108] Training loss: 0.67552541, Validation loss: 0.67482970, Gradient norm: 19.76315613
INFO:root:At the start of the epoch: mem (CPU python)=25179.9375MB; mem (CPU total)=41582.36328125MB
INFO:root:[  109] Training loss: 0.67484010, Validation loss: 0.67414450, Gradient norm: 16.01890994
INFO:root:At the start of the epoch: mem (CPU python)=25201.10546875MB; mem (CPU total)=41620.33984375MB
INFO:root:[  110] Training loss: 0.67515091, Validation loss: 0.67467820, Gradient norm: 16.41434318
INFO:root:At the start of the epoch: mem (CPU python)=25222.2890625MB; mem (CPU total)=41654.10546875MB
INFO:root:[  111] Training loss: 0.67448036, Validation loss: 0.67424200, Gradient norm: 16.66129280
INFO:root:At the start of the epoch: mem (CPU python)=25243.453125MB; mem (CPU total)=41688.85546875MB
INFO:root:[  112] Training loss: 0.67461508, Validation loss: 0.67531462, Gradient norm: 17.59676559
INFO:root:At the start of the epoch: mem (CPU python)=25264.62109375MB; mem (CPU total)=41727.03125MB
INFO:root:[  113] Training loss: 0.67467051, Validation loss: 0.68120593, Gradient norm: 18.13528715
INFO:root:At the start of the epoch: mem (CPU python)=25291.9609375MB; mem (CPU total)=41767.67578125MB
INFO:root:[  114] Training loss: 0.67645830, Validation loss: 0.67580594, Gradient norm: 29.78992745
INFO:root:At the start of the epoch: mem (CPU python)=25313.375MB; mem (CPU total)=41800.92578125MB
INFO:root:[  115] Training loss: 0.67485130, Validation loss: 0.67524292, Gradient norm: 19.75872602
INFO:root:At the start of the epoch: mem (CPU python)=25334.546875MB; mem (CPU total)=41840.23046875MB
INFO:root:[  116] Training loss: 0.67469381, Validation loss: 0.67543235, Gradient norm: 17.74906960
INFO:root:At the start of the epoch: mem (CPU python)=25355.72265625MB; mem (CPU total)=41875.2265625MB
INFO:root:[  117] Training loss: 0.67431086, Validation loss: 0.67495160, Gradient norm: 19.65923654
INFO:root:At the start of the epoch: mem (CPU python)=25376.88671875MB; mem (CPU total)=41909.5078125MB
INFO:root:[  118] Training loss: 0.67420902, Validation loss: 0.67511393, Gradient norm: 18.52648659
INFO:root:At the start of the epoch: mem (CPU python)=25398.05078125MB; mem (CPU total)=41946.65234375MB
INFO:root:EP 118: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=25419.21875MB; mem (CPU total)=41973.76171875MB
INFO:root:Training the model took 4931.556s.
INFO:root:Emptying the cuda cache took 0.036s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.59074
INFO:root:EnergyScoreValidation: 0.44351
INFO:root:CRPSValidation: 0.18268
INFO:root:Gaussian NLLValidation: 0.60938
INFO:root:CoverageValidation: 0.76833
INFO:root:IntervalWidthValidation: 0.68655
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.59894
INFO:root:EnergyScoreTest: 0.45016
INFO:root:CRPSTest: 0.18585
INFO:root:Gaussian NLLTest: 0.64235
INFO:root:CoverageTest: 0.76431
INFO:root:IntervalWidthTest: 0.69102
INFO:root:After validation: mem (CPU python)=25725.87109375MB; mem (CPU total)=42067.375MB
INFO:root:###2 out of 2 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=25725.87109375MB; mem (CPU total)=42076.74609375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=25725.87109375MB; mem (CPU total)=42076.74609375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=25725.87109375MB; mem (CPU total)=42093.390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42098.2734375MB
INFO:root:[    1] Training loss: 0.83318730, Validation loss: 0.73970448, Gradient norm: 0.60771032
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42148.16015625MB
INFO:root:[    2] Training loss: 0.73502503, Validation loss: 0.73325702, Gradient norm: 0.38430298
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42181.83203125MB
INFO:root:[    3] Training loss: 0.73252594, Validation loss: 0.73248225, Gradient norm: 0.30895425
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42216.06640625MB
INFO:root:[    4] Training loss: 0.72723118, Validation loss: 0.71408572, Gradient norm: 0.44993609
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42256.421875MB
INFO:root:[    5] Training loss: 0.68626477, Validation loss: 0.65804589, Gradient norm: 0.50662932
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42290.203125MB
INFO:root:[    6] Training loss: 0.62583091, Validation loss: 0.60076104, Gradient norm: 0.70316403
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42324.5625MB
INFO:root:[    7] Training loss: 0.56703553, Validation loss: 0.55090530, Gradient norm: 0.87436516
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42362.2265625MB
INFO:root:[    8] Training loss: 0.53326708, Validation loss: 0.52463143, Gradient norm: 0.93635610
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42397.6796875MB
INFO:root:[    9] Training loss: 0.51344317, Validation loss: 0.50694421, Gradient norm: 1.05468660
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42432.6015625MB
INFO:root:[   10] Training loss: 0.50056583, Validation loss: 0.49645304, Gradient norm: 1.16739736
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42468.23046875MB
INFO:root:[   11] Training loss: 0.48826081, Validation loss: 0.47964401, Gradient norm: 1.11398359
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42505.9375MB
INFO:root:[   12] Training loss: 0.47835682, Validation loss: 0.48834658, Gradient norm: 1.20425313
INFO:root:At the start of the epoch: mem (CPU python)=25725.87109375MB; mem (CPU total)=42540.4765625MB
INFO:root:[   13] Training loss: 0.47110212, Validation loss: 0.46580574, Gradient norm: 1.27234178
INFO:root:At the start of the epoch: mem (CPU python)=25730.11328125MB; mem (CPU total)=42576.0MB
INFO:root:[   14] Training loss: 0.46217303, Validation loss: 0.45678538, Gradient norm: 1.09206466
INFO:root:At the start of the epoch: mem (CPU python)=25751.27734375MB; mem (CPU total)=42617.08984375MB
INFO:root:[   15] Training loss: 0.46516632, Validation loss: 0.45847156, Gradient norm: 1.37404965
INFO:root:At the start of the epoch: mem (CPU python)=25772.453125MB; mem (CPU total)=42650.81640625MB
INFO:root:[   16] Training loss: 0.45466850, Validation loss: 0.44879238, Gradient norm: 1.25026190
INFO:root:At the start of the epoch: mem (CPU python)=25793.62890625MB; mem (CPU total)=42685.81640625MB
INFO:root:[   17] Training loss: 0.45053538, Validation loss: 0.45503446, Gradient norm: 1.33739458
INFO:root:At the start of the epoch: mem (CPU python)=25814.796875MB; mem (CPU total)=42723.32421875MB
INFO:root:[   18] Training loss: 0.44826634, Validation loss: 0.45104935, Gradient norm: 1.38246790
INFO:root:At the start of the epoch: mem (CPU python)=25835.97265625MB; mem (CPU total)=42759.20703125MB
INFO:root:[   19] Training loss: 0.44694113, Validation loss: 0.46075546, Gradient norm: 1.52043600
INFO:root:At the start of the epoch: mem (CPU python)=25857.13671875MB; mem (CPU total)=42794.7890625MB
INFO:root:[   20] Training loss: 0.44124265, Validation loss: 0.44742171, Gradient norm: 1.56196703
INFO:root:At the start of the epoch: mem (CPU python)=25878.30859375MB; mem (CPU total)=42829.92578125MB
INFO:root:[   21] Training loss: 0.44291528, Validation loss: 0.44347554, Gradient norm: 1.47655036
INFO:root:At the start of the epoch: mem (CPU python)=25899.484375MB; mem (CPU total)=42869.29296875MB
INFO:root:[   22] Training loss: 0.43710046, Validation loss: 0.44295163, Gradient norm: 1.36374182
INFO:root:At the start of the epoch: mem (CPU python)=25920.65234375MB; mem (CPU total)=42902.796875MB
INFO:root:[   23] Training loss: 0.43300615, Validation loss: 0.44296441, Gradient norm: 1.51258195
INFO:root:At the start of the epoch: mem (CPU python)=25941.828125MB; mem (CPU total)=42937.8828125MB
INFO:root:[   24] Training loss: 0.43632760, Validation loss: 0.43501744, Gradient norm: 1.82127325
INFO:root:At the start of the epoch: mem (CPU python)=25963.00390625MB; mem (CPU total)=42978.046875MB
INFO:root:[   25] Training loss: 0.43414717, Validation loss: 0.43003947, Gradient norm: 1.85115138
INFO:root:At the start of the epoch: mem (CPU python)=25984.16796875MB; mem (CPU total)=43012.15234375MB
INFO:root:[   26] Training loss: 0.42904429, Validation loss: 0.43199636, Gradient norm: 1.80093010
INFO:root:At the start of the epoch: mem (CPU python)=26005.34375MB; mem (CPU total)=43047.4453125MB
INFO:root:[   27] Training loss: 0.42985230, Validation loss: 0.44189470, Gradient norm: 1.42149191
INFO:root:At the start of the epoch: mem (CPU python)=26026.51171875MB; mem (CPU total)=43083.4296875MB
INFO:root:[   28] Training loss: 0.43255108, Validation loss: 0.42803518, Gradient norm: 2.00557475
INFO:root:At the start of the epoch: mem (CPU python)=26047.69140625MB; mem (CPU total)=43121.49609375MB
INFO:root:[   29] Training loss: 0.42808974, Validation loss: 0.43006802, Gradient norm: 2.11654921
INFO:root:At the start of the epoch: mem (CPU python)=26068.86328125MB; mem (CPU total)=43156.71484375MB
INFO:root:[   30] Training loss: 0.42450014, Validation loss: 0.42133253, Gradient norm: 1.80969574
INFO:root:At the start of the epoch: mem (CPU python)=26090.02734375MB; mem (CPU total)=43191.3203125MB
INFO:root:[   31] Training loss: 0.42484875, Validation loss: 0.44452113, Gradient norm: 2.12389040
INFO:root:At the start of the epoch: mem (CPU python)=26111.19921875MB; mem (CPU total)=43232.453125MB
INFO:root:[   32] Training loss: 0.42617777, Validation loss: 0.41703854, Gradient norm: 1.96809436
INFO:root:At the start of the epoch: mem (CPU python)=26132.37890625MB; mem (CPU total)=43265.8828125MB
INFO:root:[   33] Training loss: 0.42062088, Validation loss: 0.41990683, Gradient norm: 1.80714663
INFO:root:At the start of the epoch: mem (CPU python)=26153.55078125MB; mem (CPU total)=43301.75MB
INFO:root:[   34] Training loss: 0.41879874, Validation loss: 0.41636699, Gradient norm: 2.28934483
INFO:root:At the start of the epoch: mem (CPU python)=26174.71484375MB; mem (CPU total)=43337.6171875MB
INFO:root:[   35] Training loss: 0.42598249, Validation loss: 0.42725814, Gradient norm: 2.56259789
INFO:root:At the start of the epoch: mem (CPU python)=26195.890625MB; mem (CPU total)=43374.12890625MB
INFO:root:[   36] Training loss: 0.41849313, Validation loss: 0.41166073, Gradient norm: 2.54328653
INFO:root:At the start of the epoch: mem (CPU python)=26217.06640625MB; mem (CPU total)=43409.44140625MB
INFO:root:[   37] Training loss: 0.41598172, Validation loss: 0.41515945, Gradient norm: 2.08008148
INFO:root:At the start of the epoch: mem (CPU python)=26238.2265625MB; mem (CPU total)=43445.015625MB
INFO:root:[   38] Training loss: 0.41600335, Validation loss: 0.41133000, Gradient norm: 2.25158878
INFO:root:At the start of the epoch: mem (CPU python)=26259.40234375MB; mem (CPU total)=43485.4453125MB
INFO:root:[   39] Training loss: 0.41626950, Validation loss: 0.41670794, Gradient norm: 2.73863670
INFO:root:At the start of the epoch: mem (CPU python)=26280.56640625MB; mem (CPU total)=43518.8203125MB
INFO:root:[   40] Training loss: 0.41509025, Validation loss: 0.41726400, Gradient norm: 2.44004495
INFO:root:At the start of the epoch: mem (CPU python)=26301.74609375MB; mem (CPU total)=43554.1484375MB
INFO:root:[   41] Training loss: 0.41799747, Validation loss: 0.43681415, Gradient norm: 2.55179727
INFO:root:At the start of the epoch: mem (CPU python)=26322.9140625MB; mem (CPU total)=43591.7578125MB
INFO:root:[   42] Training loss: 0.41060688, Validation loss: 0.41463064, Gradient norm: 2.91067205
INFO:root:At the start of the epoch: mem (CPU python)=26344.09375MB; mem (CPU total)=43628.5234375MB
INFO:root:[   43] Training loss: 0.41427778, Validation loss: 0.40356703, Gradient norm: 2.53667850
INFO:root:At the start of the epoch: mem (CPU python)=26365.26953125MB; mem (CPU total)=43664.03515625MB
INFO:root:[   44] Training loss: 0.41566906, Validation loss: 0.41121923, Gradient norm: 2.64441032
INFO:root:At the start of the epoch: mem (CPU python)=26386.4453125MB; mem (CPU total)=43699.1171875MB
INFO:root:[   45] Training loss: 0.41886788, Validation loss: 0.41564755, Gradient norm: 2.76648718
INFO:root:At the start of the epoch: mem (CPU python)=26407.609375MB; mem (CPU total)=43740.671875MB
INFO:root:[   46] Training loss: 0.40736248, Validation loss: 0.40949869, Gradient norm: 2.64714296
INFO:root:At the start of the epoch: mem (CPU python)=26428.78515625MB; mem (CPU total)=43773.73046875MB
INFO:root:[   47] Training loss: 0.40966441, Validation loss: 0.42083526, Gradient norm: 2.60404445
INFO:root:At the start of the epoch: mem (CPU python)=26449.9453125MB; mem (CPU total)=43809.33984375MB
INFO:root:[   48] Training loss: 0.41092448, Validation loss: 0.41391574, Gradient norm: 2.96050927
INFO:root:At the start of the epoch: mem (CPU python)=26471.125MB; mem (CPU total)=43846.7109375MB
INFO:root:[   49] Training loss: 0.40358831, Validation loss: 0.40302985, Gradient norm: 2.89918088
INFO:root:At the start of the epoch: mem (CPU python)=26492.3046875MB; mem (CPU total)=43884.6484375MB
INFO:root:[   50] Training loss: 0.40848562, Validation loss: 0.41461617, Gradient norm: 3.00594218
INFO:root:At the start of the epoch: mem (CPU python)=26513.46875MB; mem (CPU total)=43919.32421875MB
INFO:root:[   51] Training loss: 0.41246956, Validation loss: 0.42570239, Gradient norm: 2.81777007
INFO:root:At the start of the epoch: mem (CPU python)=26534.64453125MB; mem (CPU total)=43911.65234375MB
INFO:root:[   52] Training loss: 0.40809486, Validation loss: 0.40965193, Gradient norm: 3.15683067
INFO:root:At the start of the epoch: mem (CPU python)=26555.81640625MB; mem (CPU total)=43938.96875MB
INFO:root:[   53] Training loss: 0.40941945, Validation loss: 0.40873889, Gradient norm: 3.40265948
INFO:root:At the start of the epoch: mem (CPU python)=26576.98046875MB; mem (CPU total)=43962.06640625MB
INFO:root:[   54] Training loss: 0.40387349, Validation loss: 0.40553777, Gradient norm: 2.65331228
INFO:root:At the start of the epoch: mem (CPU python)=26598.1640625MB; mem (CPU total)=43984.93359375MB
INFO:root:[   55] Training loss: 0.40478976, Validation loss: 0.40493365, Gradient norm: 2.65567681
INFO:root:At the start of the epoch: mem (CPU python)=26619.328125MB; mem (CPU total)=44007.0625MB
INFO:root:[   56] Training loss: 0.40616687, Validation loss: 0.38848200, Gradient norm: 3.45993271
INFO:root:At the start of the epoch: mem (CPU python)=26640.50390625MB; mem (CPU total)=44029.08203125MB
INFO:root:[   57] Training loss: 0.40180653, Validation loss: 0.39871502, Gradient norm: 3.32523339
INFO:root:At the start of the epoch: mem (CPU python)=26661.67578125MB; mem (CPU total)=44096.76171875MB
INFO:root:[   58] Training loss: 0.41178501, Validation loss: 0.40229711, Gradient norm: 2.90784591
INFO:root:At the start of the epoch: mem (CPU python)=26682.83984375MB; mem (CPU total)=44132.1171875MB
INFO:root:[   59] Training loss: 0.40177280, Validation loss: 0.42216135, Gradient norm: 3.53201980
INFO:root:At the start of the epoch: mem (CPU python)=26704.015625MB; mem (CPU total)=44172.23046875MB
INFO:root:[   60] Training loss: 0.40511909, Validation loss: 0.41534093, Gradient norm: 3.38254034
INFO:root:At the start of the epoch: mem (CPU python)=26725.19140625MB; mem (CPU total)=44206.51171875MB
INFO:root:[   61] Training loss: 0.40833847, Validation loss: 0.42692564, Gradient norm: 3.48774150
INFO:root:At the start of the epoch: mem (CPU python)=26746.35546875MB; mem (CPU total)=44241.91015625MB
INFO:root:[   62] Training loss: 0.40734686, Validation loss: 0.40144690, Gradient norm: 3.48343183
INFO:root:At the start of the epoch: mem (CPU python)=26767.53515625MB; mem (CPU total)=44278.56640625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.40894971, Validation loss: 0.42150845, Gradient norm: 3.78314063
INFO:root:At the start of the epoch: mem (CPU python)=26788.7109375MB; mem (CPU total)=44317.16796875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.38044599, Validation loss: 0.38924644, Gradient norm: 2.34713582
INFO:root:At the start of the epoch: mem (CPU python)=26809.875MB; mem (CPU total)=44352.40625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   65] Training loss: 0.37194689, Validation loss: 0.37847755, Gradient norm: 1.75003161
INFO:root:At the start of the epoch: mem (CPU python)=26831.05859375MB; mem (CPU total)=44388.4453125MB
INFO:root:[   66] Training loss: 0.36837099, Validation loss: 0.37312068, Gradient norm: 1.22436943
INFO:root:At the start of the epoch: mem (CPU python)=26852.22265625MB; mem (CPU total)=44427.8359375MB
INFO:root:[   67] Training loss: 0.36628907, Validation loss: 0.37361206, Gradient norm: 1.41057829
INFO:root:At the start of the epoch: mem (CPU python)=26874.12890625MB; mem (CPU total)=44463.5703125MB
INFO:root:[   68] Training loss: 0.36706629, Validation loss: 0.37171184, Gradient norm: 1.47333700
INFO:root:At the start of the epoch: mem (CPU python)=26895.6875MB; mem (CPU total)=44498.51171875MB
INFO:root:[   69] Training loss: 0.36623321, Validation loss: 0.37194115, Gradient norm: 1.67979138
INFO:root:At the start of the epoch: mem (CPU python)=26926.86328125MB; mem (CPU total)=44544.0859375MB
INFO:root:[   70] Training loss: 0.36538246, Validation loss: 0.37193041, Gradient norm: 1.71760978
INFO:root:At the start of the epoch: mem (CPU python)=26948.0234375MB; mem (CPU total)=44584.66796875MB
INFO:root:[   71] Training loss: 0.36445656, Validation loss: 0.37111468, Gradient norm: 1.88233135
INFO:root:At the start of the epoch: mem (CPU python)=26969.1953125MB; mem (CPU total)=44618.859375MB
INFO:root:[   72] Training loss: 0.36506267, Validation loss: 0.37131747, Gradient norm: 2.02903121
INFO:root:At the start of the epoch: mem (CPU python)=26990.35546875MB; mem (CPU total)=44654.53515625MB
INFO:root:[   73] Training loss: 0.36492755, Validation loss: 0.37028149, Gradient norm: 2.10390606
INFO:root:At the start of the epoch: mem (CPU python)=27011.51953125MB; mem (CPU total)=44692.87890625MB
INFO:root:[   74] Training loss: 0.36338647, Validation loss: 0.37096997, Gradient norm: 2.42761329
INFO:root:At the start of the epoch: mem (CPU python)=27032.68359375MB; mem (CPU total)=44729.52734375MB
INFO:root:[   75] Training loss: 0.36347086, Validation loss: 0.37070298, Gradient norm: 2.47684778
INFO:root:At the start of the epoch: mem (CPU python)=27053.84765625MB; mem (CPU total)=44764.8984375MB
INFO:root:[   76] Training loss: 0.36450928, Validation loss: 0.37011987, Gradient norm: 2.60805063
INFO:root:At the start of the epoch: mem (CPU python)=27075.01171875MB; mem (CPU total)=44800.42578125MB
INFO:root:[   77] Training loss: 0.36418736, Validation loss: 0.36965590, Gradient norm: 2.70603266
INFO:root:At the start of the epoch: mem (CPU python)=27096.17578125MB; mem (CPU total)=44841.0MB
INFO:root:[   78] Training loss: 0.36488895, Validation loss: 0.36980743, Gradient norm: 2.91182706
INFO:root:At the start of the epoch: mem (CPU python)=27117.33984375MB; mem (CPU total)=44874.71484375MB
INFO:root:[   79] Training loss: 0.36359555, Validation loss: 0.36667983, Gradient norm: 2.99375433
INFO:root:At the start of the epoch: mem (CPU python)=27138.50390625MB; mem (CPU total)=44910.64453125MB
INFO:root:[   80] Training loss: 0.36431576, Validation loss: 0.36994585, Gradient norm: 3.30063937
INFO:root:At the start of the epoch: mem (CPU python)=27159.8515625MB; mem (CPU total)=44947.27734375MB
INFO:root:[   81] Training loss: 0.36376975, Validation loss: 0.37030490, Gradient norm: 3.49183655
INFO:root:At the start of the epoch: mem (CPU python)=27181.58203125MB; mem (CPU total)=44985.91015625MB
INFO:root:[   82] Training loss: 0.36274193, Validation loss: 0.36869893, Gradient norm: 3.62608979
INFO:root:At the start of the epoch: mem (CPU python)=27202.75MB; mem (CPU total)=45021.08984375MB
INFO:root:[   83] Training loss: 0.36338073, Validation loss: 0.37066327, Gradient norm: 3.66530720
INFO:root:At the start of the epoch: mem (CPU python)=27223.91796875MB; mem (CPU total)=45056.21875MB
INFO:root:[   84] Training loss: 0.36357714, Validation loss: 0.36809902, Gradient norm: 4.01900285
INFO:root:At the start of the epoch: mem (CPU python)=27245.08203125MB; mem (CPU total)=45095.58984375MB
INFO:root:[   85] Training loss: 0.36395746, Validation loss: 0.37121196, Gradient norm: 4.24409395
INFO:root:At the start of the epoch: mem (CPU python)=27266.2421875MB; mem (CPU total)=45131.2734375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   86] Training loss: 0.36237182, Validation loss: 0.37033342, Gradient norm: 4.26049589
INFO:root:At the start of the epoch: mem (CPU python)=27287.40625MB; mem (CPU total)=45166.65625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   87] Training loss: 0.36161670, Validation loss: 0.36772523, Gradient norm: 2.42249533
INFO:root:At the start of the epoch: mem (CPU python)=27308.56640625MB; mem (CPU total)=45202.3203125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   88] Training loss: 0.36082046, Validation loss: 0.36767309, Gradient norm: 1.81743533
INFO:root:At the start of the epoch: mem (CPU python)=27329.734375MB; mem (CPU total)=45243.84375MB
INFO:root:[   89] Training loss: 0.36126171, Validation loss: 0.36607583, Gradient norm: 1.52584478
INFO:root:At the start of the epoch: mem (CPU python)=27351.1015625MB; mem (CPU total)=45277.609375MB
INFO:root:[   90] Training loss: 0.36029633, Validation loss: 0.36539447, Gradient norm: 1.36346425
INFO:root:At the start of the epoch: mem (CPU python)=27372.4375MB; mem (CPU total)=45313.0078125MB
INFO:root:[   91] Training loss: 0.35976505, Validation loss: 0.36477257, Gradient norm: 1.49832021
INFO:root:At the start of the epoch: mem (CPU python)=27393.6015625MB; mem (CPU total)=45350.125MB
INFO:root:[   92] Training loss: 0.36003091, Validation loss: 0.36616407, Gradient norm: 1.49615530
INFO:root:At the start of the epoch: mem (CPU python)=27414.765625MB; mem (CPU total)=45387.53125MB
INFO:root:[   93] Training loss: 0.35980932, Validation loss: 0.36589739, Gradient norm: 1.54860262
INFO:root:At the start of the epoch: mem (CPU python)=27435.9296875MB; mem (CPU total)=45423.4453125MB
INFO:root:[   94] Training loss: 0.36034304, Validation loss: 0.36841544, Gradient norm: 1.52525113
INFO:root:At the start of the epoch: mem (CPU python)=27457.09765625MB; mem (CPU total)=45459.11328125MB
INFO:root:[   95] Training loss: 0.36004453, Validation loss: 0.36621618, Gradient norm: 1.63887598
INFO:root:At the start of the epoch: mem (CPU python)=27478.2578125MB; mem (CPU total)=45498.484375MB
INFO:root:[   96] Training loss: 0.35997390, Validation loss: 0.36798875, Gradient norm: 1.68628084
INFO:root:At the start of the epoch: mem (CPU python)=27499.421875MB; mem (CPU total)=45533.61328125MB
INFO:root:[   97] Training loss: 0.35954158, Validation loss: 0.36789631, Gradient norm: 1.63520234
INFO:root:At the start of the epoch: mem (CPU python)=27520.82421875MB; mem (CPU total)=45570.70703125MB
INFO:root:[   98] Training loss: 0.36094481, Validation loss: 0.36560267, Gradient norm: 1.88054724
INFO:root:At the start of the epoch: mem (CPU python)=27541.98828125MB; mem (CPU total)=45606.35546875MB
INFO:root:[   99] Training loss: 0.36037115, Validation loss: 0.36562501, Gradient norm: 1.69037418
INFO:root:At the start of the epoch: mem (CPU python)=27563.66796875MB; mem (CPU total)=45647.3046875MB
INFO:root:[  100] Training loss: 0.35957329, Validation loss: 0.36590092, Gradient norm: 1.80784798
INFO:root:At the start of the epoch: mem (CPU python)=27585.30859375MB; mem (CPU total)=45682.03515625MB
INFO:root:EP 100: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=27606.74609375MB; mem (CPU total)=45716.9765625MB
INFO:root:[  102] Training loss: 0.44155506, Validation loss: 0.44822905, Gradient norm: 3.53944083
INFO:root:At the start of the epoch: mem (CPU python)=27627.91015625MB; mem (CPU total)=45758.23046875MB
INFO:root:[  103] Training loss: 0.44050081, Validation loss: 0.44600736, Gradient norm: 3.41173092
INFO:root:At the start of the epoch: mem (CPU python)=27649.07421875MB; mem (CPU total)=45799.3046875MB
INFO:root:[  104] Training loss: 0.44049520, Validation loss: 0.44542203, Gradient norm: 3.69597994
INFO:root:At the start of the epoch: mem (CPU python)=27670.234375MB; mem (CPU total)=45839.9296875MB
INFO:root:[  105] Training loss: 0.43979962, Validation loss: 0.44493102, Gradient norm: 3.38960880
INFO:root:At the start of the epoch: mem (CPU python)=27691.40234375MB; mem (CPU total)=45881.9375MB
INFO:root:[  106] Training loss: 0.43972409, Validation loss: 0.44466174, Gradient norm: 3.61305050
INFO:root:At the start of the epoch: mem (CPU python)=27712.5625MB; mem (CPU total)=45924.48828125MB
INFO:root:[  107] Training loss: 0.43913464, Validation loss: 0.44347433, Gradient norm: 3.55831930
INFO:root:At the start of the epoch: mem (CPU python)=27733.7265625MB; mem (CPU total)=45966.99609375MB
INFO:root:[  108] Training loss: 0.43872064, Validation loss: 0.44435332, Gradient norm: 3.53071466
INFO:root:At the start of the epoch: mem (CPU python)=27754.890625MB; mem (CPU total)=46009.28515625MB
INFO:root:[  109] Training loss: 0.43830756, Validation loss: 0.44474660, Gradient norm: 3.34905582
INFO:root:At the start of the epoch: mem (CPU python)=27776.0546875MB; mem (CPU total)=46049.8828125MB
INFO:root:[  110] Training loss: 0.43853626, Validation loss: 0.44460652, Gradient norm: 3.22119581
INFO:root:At the start of the epoch: mem (CPU python)=27797.22265625MB; mem (CPU total)=46089.74609375MB
INFO:root:[  111] Training loss: 0.43833694, Validation loss: 0.44456598, Gradient norm: 3.39413165
INFO:root:At the start of the epoch: mem (CPU python)=27818.38671875MB; mem (CPU total)=46109.82421875MB
INFO:root:[  112] Training loss: 0.43807967, Validation loss: 0.44261142, Gradient norm: 3.41277247
INFO:root:At the start of the epoch: mem (CPU python)=27839.55078125MB; mem (CPU total)=46152.796875MB
INFO:root:[  113] Training loss: 0.43767408, Validation loss: 0.44442540, Gradient norm: 3.52892396
INFO:root:At the start of the epoch: mem (CPU python)=27860.7109375MB; mem (CPU total)=46195.703125MB
INFO:root:[  114] Training loss: 0.43836108, Validation loss: 0.44174914, Gradient norm: 3.56452843
INFO:root:At the start of the epoch: mem (CPU python)=27881.875MB; mem (CPU total)=46236.6015625MB
INFO:root:[  115] Training loss: 0.43752725, Validation loss: 0.44286831, Gradient norm: 3.61836316
INFO:root:At the start of the epoch: mem (CPU python)=27903.0390625MB; mem (CPU total)=46277.58203125MB
INFO:root:[  116] Training loss: 0.43843874, Validation loss: 0.44259485, Gradient norm: 3.87713026
INFO:root:At the start of the epoch: mem (CPU python)=27924.20703125MB; mem (CPU total)=46319.16015625MB
INFO:root:[  117] Training loss: 0.43737841, Validation loss: 0.44345223, Gradient norm: 3.38615446
INFO:root:At the start of the epoch: mem (CPU python)=27945.37109375MB; mem (CPU total)=46362.5078125MB
INFO:root:[  118] Training loss: 0.43697460, Validation loss: 0.44362643, Gradient norm: 3.32035163
INFO:root:At the start of the epoch: mem (CPU python)=27966.53515625MB; mem (CPU total)=46404.1875MB
INFO:root:[  119] Training loss: 0.43810940, Validation loss: 0.44403674, Gradient norm: 3.85717118
INFO:root:At the start of the epoch: mem (CPU python)=27987.69921875MB; mem (CPU total)=46444.94921875MB
INFO:root:[  120] Training loss: 0.43710691, Validation loss: 0.44263261, Gradient norm: 3.33485058
INFO:root:At the start of the epoch: mem (CPU python)=28008.86328125MB; mem (CPU total)=46487.3359375MB
INFO:root:[  121] Training loss: 0.43741809, Validation loss: 0.44313678, Gradient norm: 3.47588863
INFO:root:At the start of the epoch: mem (CPU python)=28030.02734375MB; mem (CPU total)=46528.0703125MB
INFO:root:[  122] Training loss: 0.43718749, Validation loss: 0.44217158, Gradient norm: 3.61163199
INFO:root:At the start of the epoch: mem (CPU python)=28051.19140625MB; mem (CPU total)=46569.1640625MB
INFO:root:[  123] Training loss: 0.43741543, Validation loss: 0.44199305, Gradient norm: 3.73040142
INFO:root:At the start of the epoch: mem (CPU python)=28072.3515625MB; mem (CPU total)=46619.27734375MB
INFO:root:EP 123: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=28093.515625MB; mem (CPU total)=46652.04296875MB
INFO:root:Training the model took 5961.238s.
INFO:root:Emptying the cuda cache took 0.063s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.49544
INFO:root:EnergyScoreValidation: 0.44307
INFO:root:CRPSValidation: 0.17982
INFO:root:Gaussian NLLValidation: 12.03848
INFO:root:CoverageValidation: 0.28952
INFO:root:IntervalWidthValidation: 0.1763
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.38485
INFO:root:EnergyScoreTest: 0.33317
INFO:root:CRPSTest: 0.1329
INFO:root:Gaussian NLLTest: 5.3931
INFO:root:CoverageTest: 0.40412
INFO:root:IntervalWidthTest: 0.18332
INFO:root:After validation: mem (CPU python)=28400.015625MB; mem (CPU total)=46742.43359375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=28400.015625MB; mem (CPU total)=46755.0546875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 159383552
INFO:root:After setting up the model: mem (CPU python)=28400.015625MB; mem (CPU total)=46746.3515625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=46750.578125MB
INFO:root:[    1] Training loss: 0.83787462, Validation loss: 0.74102738, Gradient norm: 0.51659137
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=46790.17578125MB
INFO:root:[    2] Training loss: 0.73834567, Validation loss: 0.73817036, Gradient norm: 0.34810880
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=46826.6484375MB
INFO:root:[    3] Training loss: 0.73457686, Validation loss: 0.72994817, Gradient norm: 0.34577058
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=46861.625MB
INFO:root:[    4] Training loss: 0.71561292, Validation loss: 0.69259632, Gradient norm: 0.50494182
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=46897.09375MB
INFO:root:[    5] Training loss: 0.67002577, Validation loss: 0.64936601, Gradient norm: 0.64407955
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=46937.6171875MB
INFO:root:[    6] Training loss: 0.62037249, Validation loss: 0.61279803, Gradient norm: 0.87268281
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=46973.02734375MB
INFO:root:[    7] Training loss: 0.59570985, Validation loss: 0.57360324, Gradient norm: 1.04680549
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=47008.46875MB
INFO:root:[    8] Training loss: 0.56754739, Validation loss: 0.55521675, Gradient norm: 1.26189001
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=47044.0234375MB
INFO:root:[    9] Training loss: 0.55138853, Validation loss: 0.56899528, Gradient norm: 1.28509464
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=47085.59375MB
INFO:root:[   10] Training loss: 0.54105612, Validation loss: 0.53517597, Gradient norm: 1.63985418
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=47119.52734375MB
INFO:root:[   11] Training loss: 0.53067746, Validation loss: 0.52090916, Gradient norm: 1.62585180
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=47155.2421875MB
INFO:root:[   12] Training loss: 0.52034026, Validation loss: 0.50792778, Gradient norm: 1.60288421
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=47192.59765625MB
INFO:root:[   13] Training loss: 0.50678073, Validation loss: 0.50204598, Gradient norm: 1.67376491
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=47231.1640625MB
INFO:root:[   14] Training loss: 0.49870265, Validation loss: 0.49807197, Gradient norm: 1.95693225
INFO:root:At the start of the epoch: mem (CPU python)=28400.015625MB; mem (CPU total)=47266.3828125MB
INFO:root:[   15] Training loss: 0.49201480, Validation loss: 0.48136379, Gradient norm: 1.91176132
INFO:root:At the start of the epoch: mem (CPU python)=28410.21484375MB; mem (CPU total)=47301.53125MB
INFO:root:[   16] Training loss: 0.48752999, Validation loss: 0.49491415, Gradient norm: 2.04150001
INFO:root:At the start of the epoch: mem (CPU python)=28431.375MB; mem (CPU total)=47339.953125MB
INFO:root:[   17] Training loss: 0.48326452, Validation loss: 0.47453415, Gradient norm: 2.23235473
INFO:root:At the start of the epoch: mem (CPU python)=28452.5390625MB; mem (CPU total)=47377.88671875MB
INFO:root:[   18] Training loss: 0.47866563, Validation loss: 0.49310018, Gradient norm: 1.92043790
INFO:root:At the start of the epoch: mem (CPU python)=28473.703125MB; mem (CPU total)=47413.30078125MB
INFO:root:[   19] Training loss: 0.47417069, Validation loss: 0.47337498, Gradient norm: 2.04243364
INFO:root:At the start of the epoch: mem (CPU python)=28494.8671875MB; mem (CPU total)=47448.6328125MB
INFO:root:[   20] Training loss: 0.47322176, Validation loss: 0.46413987, Gradient norm: 1.82420985
INFO:root:At the start of the epoch: mem (CPU python)=28516.0390625MB; mem (CPU total)=47488.44921875MB
INFO:root:[   21] Training loss: 0.46817962, Validation loss: 0.47048371, Gradient norm: 2.41319897
INFO:root:At the start of the epoch: mem (CPU python)=28537.203125MB; mem (CPU total)=47524.8515625MB
INFO:root:[   22] Training loss: 0.46856546, Validation loss: 0.46529825, Gradient norm: 2.09567765
INFO:root:At the start of the epoch: mem (CPU python)=28558.3671875MB; mem (CPU total)=47560.50390625MB
INFO:root:[   23] Training loss: 0.46787586, Validation loss: 0.47088665, Gradient norm: 2.00712711
INFO:root:At the start of the epoch: mem (CPU python)=28579.53125MB; mem (CPU total)=47595.90625MB
INFO:root:[   24] Training loss: 0.46508959, Validation loss: 0.45975223, Gradient norm: 2.35711735
INFO:root:At the start of the epoch: mem (CPU python)=28600.6953125MB; mem (CPU total)=47637.015625MB
INFO:root:[   25] Training loss: 0.46884255, Validation loss: 0.47389802, Gradient norm: 2.18515838
INFO:root:At the start of the epoch: mem (CPU python)=28621.859375MB; mem (CPU total)=47671.53515625MB
INFO:root:[   26] Training loss: 0.46371623, Validation loss: 0.45969168, Gradient norm: 2.10087482
INFO:root:At the start of the epoch: mem (CPU python)=28643.02734375MB; mem (CPU total)=47708.20703125MB
INFO:root:[   27] Training loss: 0.45934412, Validation loss: 0.45564379, Gradient norm: 2.22949628
INFO:root:At the start of the epoch: mem (CPU python)=28664.1875MB; mem (CPU total)=47743.609375MB
INFO:root:[   28] Training loss: 0.46107625, Validation loss: 0.46749320, Gradient norm: 2.54325307
INFO:root:At the start of the epoch: mem (CPU python)=28685.3515625MB; mem (CPU total)=47784.95703125MB
INFO:root:[   29] Training loss: 0.46323323, Validation loss: 0.46470626, Gradient norm: 2.60332406
INFO:root:At the start of the epoch: mem (CPU python)=28706.515625MB; mem (CPU total)=47818.9296875MB
INFO:root:[   30] Training loss: 0.46086344, Validation loss: 0.47009723, Gradient norm: 2.23078632
INFO:root:At the start of the epoch: mem (CPU python)=28727.6796875MB; mem (CPU total)=47854.82421875MB
INFO:root:[   31] Training loss: 0.45912921, Validation loss: 0.46092842, Gradient norm: 2.47206666
INFO:root:At the start of the epoch: mem (CPU python)=28748.84765625MB; mem (CPU total)=47891.4921875MB
INFO:root:[   32] Training loss: 0.45659871, Validation loss: 0.45549861, Gradient norm: 2.49210064
INFO:root:At the start of the epoch: mem (CPU python)=28770.01171875MB; mem (CPU total)=47932.58203125MB
INFO:root:[   33] Training loss: 0.45396926, Validation loss: 0.45710514, Gradient norm: 2.41859528
INFO:root:At the start of the epoch: mem (CPU python)=28791.171875MB; mem (CPU total)=47966.40234375MB
INFO:root:[   34] Training loss: 0.46031736, Validation loss: 0.46472231, Gradient norm: 2.38199034
INFO:root:At the start of the epoch: mem (CPU python)=28812.3359375MB; mem (CPU total)=48001.85546875MB
INFO:root:[   35] Training loss: 0.45715949, Validation loss: 0.46653446, Gradient norm: 2.77028973
INFO:root:At the start of the epoch: mem (CPU python)=28833.5MB; mem (CPU total)=48039.2421875MB
INFO:root:[   36] Training loss: 0.45588553, Validation loss: 0.45744177, Gradient norm: 2.53841514
INFO:root:At the start of the epoch: mem (CPU python)=28854.66015625MB; mem (CPU total)=48078.85546875MB
INFO:root:[   37] Training loss: 0.45472943, Validation loss: 0.46833780, Gradient norm: 2.79621247
INFO:root:At the start of the epoch: mem (CPU python)=28875.828125MB; mem (CPU total)=48114.5390625MB
INFO:root:[   38] Training loss: 0.45329041, Validation loss: 0.44145146, Gradient norm: 2.75242940
INFO:root:At the start of the epoch: mem (CPU python)=28896.9921875MB; mem (CPU total)=48149.9609375MB
INFO:root:[   39] Training loss: 0.45163715, Validation loss: 0.44584297, Gradient norm: 2.62612798
INFO:root:At the start of the epoch: mem (CPU python)=28918.15625MB; mem (CPU total)=48188.28125MB
INFO:root:[   40] Training loss: 0.44997230, Validation loss: 0.43629668, Gradient norm: 2.83689512
INFO:root:At the start of the epoch: mem (CPU python)=28939.3203125MB; mem (CPU total)=48226.2109375MB
INFO:root:[   41] Training loss: 0.44768416, Validation loss: 0.45085182, Gradient norm: 2.59801909
INFO:root:At the start of the epoch: mem (CPU python)=28960.484375MB; mem (CPU total)=48262.05078125MB
INFO:root:[   42] Training loss: 0.45152881, Validation loss: 0.44030188, Gradient norm: 2.58045240
INFO:root:At the start of the epoch: mem (CPU python)=28981.6484375MB; mem (CPU total)=48297.97265625MB
INFO:root:[   43] Training loss: 0.44591266, Validation loss: 0.46493761, Gradient norm: 3.37472382
INFO:root:At the start of the epoch: mem (CPU python)=29002.81640625MB; mem (CPU total)=48337.1015625MB
INFO:root:[   44] Training loss: 0.45453395, Validation loss: 0.45596674, Gradient norm: 2.93617744
INFO:root:At the start of the epoch: mem (CPU python)=29023.98046875MB; mem (CPU total)=48373.73828125MB
INFO:root:[   45] Training loss: 0.45170490, Validation loss: 0.44393675, Gradient norm: 2.99926006
INFO:root:At the start of the epoch: mem (CPU python)=29045.140625MB; mem (CPU total)=48409.17578125MB
INFO:root:[   46] Training loss: 0.44458277, Validation loss: 0.44382256, Gradient norm: 3.18683080
INFO:root:At the start of the epoch: mem (CPU python)=29066.3046875MB; mem (CPU total)=48445.0078125MB
INFO:root:[   47] Training loss: 0.44662863, Validation loss: 0.44922321, Gradient norm: 3.10565578
INFO:root:At the start of the epoch: mem (CPU python)=29087.46875MB; mem (CPU total)=48485.0859375MB
INFO:root:[   48] Training loss: 0.44611802, Validation loss: 0.44898798, Gradient norm: 2.88434624
INFO:root:At the start of the epoch: mem (CPU python)=29108.63671875MB; mem (CPU total)=48521.76171875MB
INFO:root:[   49] Training loss: 0.44251378, Validation loss: 0.44014021, Gradient norm: 3.22255447
INFO:root:At the start of the epoch: mem (CPU python)=29129.796875MB; mem (CPU total)=48557.2109375MB
INFO:root:[   50] Training loss: 0.44457163, Validation loss: 0.44850801, Gradient norm: 3.47721521
INFO:root:At the start of the epoch: mem (CPU python)=29150.9609375MB; mem (CPU total)=48592.91015625MB
INFO:root:[   51] Training loss: 0.44527773, Validation loss: 0.43552958, Gradient norm: 3.29980463
INFO:root:At the start of the epoch: mem (CPU python)=29172.125MB; mem (CPU total)=48634.25MB
INFO:root:[   52] Training loss: 0.44237667, Validation loss: 0.44774600, Gradient norm: 3.20936092
INFO:root:At the start of the epoch: mem (CPU python)=29193.2890625MB; mem (CPU total)=48669.63671875MB
INFO:root:[   53] Training loss: 0.44392245, Validation loss: 0.44294104, Gradient norm: 3.77437414
INFO:root:At the start of the epoch: mem (CPU python)=29214.4609375MB; mem (CPU total)=48705.53515625MB
INFO:root:[   54] Training loss: 0.44274674, Validation loss: 0.48057298, Gradient norm: 3.42643344
INFO:root:At the start of the epoch: mem (CPU python)=29235.625MB; mem (CPU total)=48740.97265625MB
INFO:root:[   55] Training loss: 0.44445910, Validation loss: 0.43876369, Gradient norm: 3.76376079
INFO:root:At the start of the epoch: mem (CPU python)=29256.78515625MB; mem (CPU total)=48782.296875MB
INFO:root:[   56] Training loss: 0.44819111, Validation loss: 0.43760385, Gradient norm: 3.80251607
INFO:root:At the start of the epoch: mem (CPU python)=29277.94921875MB; mem (CPU total)=48817.234375MB
INFO:root:[   57] Training loss: 0.44270051, Validation loss: 0.43069836, Gradient norm: 3.27664212
INFO:root:At the start of the epoch: mem (CPU python)=29299.11328125MB; mem (CPU total)=48853.12890625MB
INFO:root:[   58] Training loss: 0.44069751, Validation loss: 0.44102158, Gradient norm: 3.84473498
INFO:root:At the start of the epoch: mem (CPU python)=29320.27734375MB; mem (CPU total)=48890.33203125MB
INFO:root:[   59] Training loss: 0.43770199, Validation loss: 0.44074936, Gradient norm: 4.04799286
INFO:root:At the start of the epoch: mem (CPU python)=29341.44140625MB; mem (CPU total)=48931.94921875MB
INFO:root:[   60] Training loss: 0.43804316, Validation loss: 0.43554300, Gradient norm: 3.48499473
INFO:root:At the start of the epoch: mem (CPU python)=29362.609375MB; mem (CPU total)=48965.87890625MB
INFO:root:[   61] Training loss: 0.44153193, Validation loss: 0.43015458, Gradient norm: 3.64464159
INFO:root:At the start of the epoch: mem (CPU python)=29383.7734375MB; mem (CPU total)=49002.5859375MB
INFO:root:[   62] Training loss: 0.44614655, Validation loss: 0.43166554, Gradient norm: 4.17089310
INFO:root:At the start of the epoch: mem (CPU python)=29404.9375MB; mem (CPU total)=49037.71484375MB
INFO:root:[   63] Training loss: 0.43947039, Validation loss: 0.44053145, Gradient norm: 4.04514264
INFO:root:At the start of the epoch: mem (CPU python)=29426.10546875MB; mem (CPU total)=49080.2890625MB
INFO:root:[   64] Training loss: 0.44231285, Validation loss: 0.42952691, Gradient norm: 3.87610893
INFO:root:At the start of the epoch: mem (CPU python)=29447.26953125MB; mem (CPU total)=49114.5078125MB
INFO:root:[   65] Training loss: 0.43812238, Validation loss: 0.42679104, Gradient norm: 4.26600865
INFO:root:At the start of the epoch: mem (CPU python)=29468.43359375MB; mem (CPU total)=49149.93359375MB
INFO:root:[   66] Training loss: 0.44040293, Validation loss: 0.43844325, Gradient norm: 3.93514500
INFO:root:At the start of the epoch: mem (CPU python)=29489.58984375MB; mem (CPU total)=49186.0703125MB
INFO:root:[   67] Training loss: 0.43821293, Validation loss: 0.43947693, Gradient norm: 4.20052782
INFO:root:At the start of the epoch: mem (CPU python)=29510.75390625MB; mem (CPU total)=49227.46484375MB
INFO:root:[   68] Training loss: 0.44291468, Validation loss: 0.44334167, Gradient norm: 3.98130116
INFO:root:At the start of the epoch: mem (CPU python)=29531.91796875MB; mem (CPU total)=49261.96484375MB
INFO:root:[   69] Training loss: 0.44391517, Validation loss: 0.42897364, Gradient norm: 4.02315655
INFO:root:At the start of the epoch: mem (CPU python)=29553.08203125MB; mem (CPU total)=49297.63671875MB
INFO:root:[   70] Training loss: 0.43979398, Validation loss: 0.43557019, Gradient norm: 4.68606038
INFO:root:At the start of the epoch: mem (CPU python)=29574.24609375MB; mem (CPU total)=49335.30078125MB
INFO:root:[   71] Training loss: 0.43990180, Validation loss: 0.43887566, Gradient norm: 4.29934724
INFO:root:At the start of the epoch: mem (CPU python)=29595.4140625MB; mem (CPU total)=49375.6796875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   72] Training loss: 0.44258918, Validation loss: 0.43636688, Gradient norm: 4.50632809
INFO:root:At the start of the epoch: mem (CPU python)=29616.578125MB; mem (CPU total)=49410.36328125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   73] Training loss: 0.41258944, Validation loss: 0.41478991, Gradient norm: 2.88856887
INFO:root:At the start of the epoch: mem (CPU python)=29637.7421875MB; mem (CPU total)=49446.328125MB
INFO:root:[   74] Training loss: 0.40212778, Validation loss: 0.40414816, Gradient norm: 2.22627695
INFO:root:At the start of the epoch: mem (CPU python)=29658.90234375MB; mem (CPU total)=49483.91015625MB
INFO:root:[   75] Training loss: 0.39992162, Validation loss: 0.40541804, Gradient norm: 2.83983250
INFO:root:At the start of the epoch: mem (CPU python)=29680.06640625MB; mem (CPU total)=49523.78125MB
INFO:root:[   76] Training loss: 0.40041519, Validation loss: 0.40809011, Gradient norm: 3.11696984
INFO:root:At the start of the epoch: mem (CPU python)=29701.23046875MB; mem (CPU total)=49558.48828125MB
INFO:root:[   77] Training loss: 0.39903460, Validation loss: 0.40267945, Gradient norm: 3.33491571
INFO:root:At the start of the epoch: mem (CPU python)=29722.3984375MB; mem (CPU total)=49592.921875MB
INFO:root:[   78] Training loss: 0.39925195, Validation loss: 0.40260108, Gradient norm: 4.01122718
INFO:root:At the start of the epoch: mem (CPU python)=29743.5625MB; mem (CPU total)=49631.609375MB
INFO:root:[   79] Training loss: 0.39978035, Validation loss: 0.40315706, Gradient norm: 4.29422596
INFO:root:At the start of the epoch: mem (CPU python)=29764.7265625MB; mem (CPU total)=49669.76171875MB
INFO:root:[   80] Training loss: 0.39941036, Validation loss: 0.40379441, Gradient norm: 4.59580498
INFO:root:At the start of the epoch: mem (CPU python)=29785.890625MB; mem (CPU total)=49708.08203125MB
INFO:root:[   81] Training loss: 0.39882839, Validation loss: 0.40167045, Gradient norm: 4.92949380
INFO:root:At the start of the epoch: mem (CPU python)=29807.0546875MB; mem (CPU total)=49743.7890625MB
INFO:root:[   82] Training loss: 0.39939210, Validation loss: 0.40574088, Gradient norm: 4.86564372
INFO:root:At the start of the epoch: mem (CPU python)=29828.21875MB; mem (CPU total)=49782.234375MB
INFO:root:[   83] Training loss: 0.39966027, Validation loss: 0.40061217, Gradient norm: 5.50082891
INFO:root:At the start of the epoch: mem (CPU python)=29849.3828125MB; mem (CPU total)=49819.78125MB
INFO:root:[   84] Training loss: 0.40036820, Validation loss: 0.43068965, Gradient norm: 5.67260884
INFO:root:At the start of the epoch: mem (CPU python)=29870.54296875MB; mem (CPU total)=49855.43359375MB
INFO:root:[   85] Training loss: 0.40231903, Validation loss: 0.41707854, Gradient norm: 5.91594693
INFO:root:At the start of the epoch: mem (CPU python)=29891.70703125MB; mem (CPU total)=49891.36328125MB
INFO:root:[   86] Training loss: 0.40154109, Validation loss: 0.40528829, Gradient norm: 6.42340912
INFO:root:At the start of the epoch: mem (CPU python)=29912.87109375MB; mem (CPU total)=49930.48046875MB
INFO:root:[   87] Training loss: 0.40038825, Validation loss: 0.40165999, Gradient norm: 6.31433709
INFO:root:At the start of the epoch: mem (CPU python)=29934.0390625MB; mem (CPU total)=49967.0859375MB
INFO:root:[   88] Training loss: 0.40116454, Validation loss: 0.40428530, Gradient norm: 6.71960840
INFO:root:At the start of the epoch: mem (CPU python)=29955.203125MB; mem (CPU total)=50002.7421875MB
INFO:root:[   89] Training loss: 0.40103941, Validation loss: 0.40627003, Gradient norm: 7.13289636
INFO:root:At the start of the epoch: mem (CPU python)=29976.3671875MB; mem (CPU total)=50037.625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   90] Training loss: 0.40208303, Validation loss: 0.40630321, Gradient norm: 7.11276555
INFO:root:At the start of the epoch: mem (CPU python)=29997.53125MB; mem (CPU total)=50077.9921875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   91] Training loss: 0.39481931, Validation loss: 0.39958790, Gradient norm: 4.69505151
INFO:root:At the start of the epoch: mem (CPU python)=30018.6953125MB; mem (CPU total)=50112.59375MB
INFO:root:[   92] Training loss: 0.39275825, Validation loss: 0.39905041, Gradient norm: 4.19563950
INFO:root:At the start of the epoch: mem (CPU python)=30039.85546875MB; mem (CPU total)=50148.57421875MB
INFO:root:[   93] Training loss: 0.39165644, Validation loss: 0.39620620, Gradient norm: 3.41264275
INFO:root:At the start of the epoch: mem (CPU python)=30061.0234375MB; mem (CPU total)=50184.28125MB
INFO:root:[   94] Training loss: 0.39184690, Validation loss: 0.39793285, Gradient norm: 3.43722868
INFO:root:At the start of the epoch: mem (CPU python)=30082.1875MB; mem (CPU total)=50226.26171875MB
INFO:root:[   95] Training loss: 0.39145944, Validation loss: 0.39691638, Gradient norm: 3.87736382
INFO:root:At the start of the epoch: mem (CPU python)=30103.3515625MB; mem (CPU total)=50260.3671875MB
INFO:root:[   96] Training loss: 0.39170930, Validation loss: 0.39751630, Gradient norm: 4.14890395
INFO:root:At the start of the epoch: mem (CPU python)=30124.515625MB; mem (CPU total)=50296.31640625MB
INFO:root:[   97] Training loss: 0.39052589, Validation loss: 0.39735818, Gradient norm: 4.12086441
INFO:root:At the start of the epoch: mem (CPU python)=30145.6796875MB; mem (CPU total)=50331.5234375MB
INFO:root:[   98] Training loss: 0.39155203, Validation loss: 0.39502710, Gradient norm: 4.26640417
INFO:root:At the start of the epoch: mem (CPU python)=30166.84765625MB; mem (CPU total)=50373.87109375MB
INFO:root:[   99] Training loss: 0.39155250, Validation loss: 0.39610844, Gradient norm: 4.46567582
INFO:root:At the start of the epoch: mem (CPU python)=30188.0078125MB; mem (CPU total)=50407.83984375MB
INFO:root:[  100] Training loss: 0.39123875, Validation loss: 0.39552265, Gradient norm: 5.07829586
INFO:root:At the start of the epoch: mem (CPU python)=30209.171875MB; mem (CPU total)=50442.91796875MB
INFO:root:[  101] Training loss: 0.39154723, Validation loss: 0.39829141, Gradient norm: 5.03744386
INFO:root:At the start of the epoch: mem (CPU python)=30230.3359375MB; mem (CPU total)=50479.56640625MB
INFO:root:[  102] Training loss: 0.39123993, Validation loss: 0.39656416, Gradient norm: 5.47033885
INFO:root:At the start of the epoch: mem (CPU python)=30251.5078125MB; mem (CPU total)=50521.16796875MB
INFO:root:[  103] Training loss: 0.39143576, Validation loss: 0.39731790, Gradient norm: 5.81527150
INFO:root:At the start of the epoch: mem (CPU python)=30272.671875MB; mem (CPU total)=50555.375MB
INFO:root:[  104] Training loss: 0.39129945, Validation loss: 0.39715420, Gradient norm: 6.01533901
INFO:root:At the start of the epoch: mem (CPU python)=30293.83984375MB; mem (CPU total)=50550.06640625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  105] Training loss: 0.39107389, Validation loss: 0.39684486, Gradient norm: 6.24524146
INFO:root:At the start of the epoch: mem (CPU python)=30315.00390625MB; mem (CPU total)=50574.3984375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  106] Training loss: 0.38975956, Validation loss: 0.39695190, Gradient norm: 3.96974478
INFO:root:At the start of the epoch: mem (CPU python)=30336.16796875MB; mem (CPU total)=50598.51171875MB
INFO:root:[  107] Training loss: 0.38887193, Validation loss: 0.39567347, Gradient norm: 3.16173381
INFO:root:At the start of the epoch: mem (CPU python)=30357.33203125MB; mem (CPU total)=50620.9375MB
INFO:root:EP 107: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=30378.49609375MB; mem (CPU total)=50643.97265625MB
INFO:root:[  109] Training loss: 0.47632323, Validation loss: 0.47767664, Gradient norm: 4.70906694
INFO:root:At the start of the epoch: mem (CPU python)=30399.6640625MB; mem (CPU total)=50705.06640625MB
INFO:root:[  110] Training loss: 0.47363816, Validation loss: 0.47904448, Gradient norm: 4.88925797
INFO:root:At the start of the epoch: mem (CPU python)=30420.82421875MB; mem (CPU total)=50745.65625MB
INFO:root:[  111] Training loss: 0.47280804, Validation loss: 0.47654435, Gradient norm: 4.68444278
INFO:root:At the start of the epoch: mem (CPU python)=30441.9921875MB; mem (CPU total)=50786.71875MB
INFO:root:[  112] Training loss: 0.47193213, Validation loss: 0.47565942, Gradient norm: 5.32010095
INFO:root:At the start of the epoch: mem (CPU python)=30463.15625MB; mem (CPU total)=50827.57421875MB
INFO:root:[  113] Training loss: 0.47156187, Validation loss: 0.47546017, Gradient norm: 4.71372415
INFO:root:At the start of the epoch: mem (CPU python)=30484.3203125MB; mem (CPU total)=50868.6484375MB
INFO:root:[  114] Training loss: 0.47082242, Validation loss: 0.47565003, Gradient norm: 5.04408715
INFO:root:At the start of the epoch: mem (CPU python)=30505.484375MB; mem (CPU total)=50910.7109375MB
INFO:root:[  115] Training loss: 0.47080667, Validation loss: 0.47600952, Gradient norm: 4.66077222
INFO:root:At the start of the epoch: mem (CPU python)=30526.65234375MB; mem (CPU total)=50953.0234375MB
INFO:root:[  116] Training loss: 0.47082369, Validation loss: 0.47541357, Gradient norm: 5.04450111
INFO:root:At the start of the epoch: mem (CPU python)=30547.81640625MB; mem (CPU total)=50995.0703125MB
INFO:root:[  117] Training loss: 0.47064177, Validation loss: 0.47495178, Gradient norm: 5.17627900
INFO:root:At the start of the epoch: mem (CPU python)=30568.98046875MB; mem (CPU total)=51043.01171875MB
INFO:root:[  118] Training loss: 0.47001155, Validation loss: 0.47303427, Gradient norm: 4.91707374
INFO:root:At the start of the epoch: mem (CPU python)=30590.14453125MB; mem (CPU total)=51084.75390625MB
INFO:root:[  119] Training loss: 0.47004193, Validation loss: 0.47520442, Gradient norm: 4.83101779
INFO:root:At the start of the epoch: mem (CPU python)=30611.3046875MB; mem (CPU total)=51122.875MB
INFO:root:[  120] Training loss: 0.46965206, Validation loss: 0.47430250, Gradient norm: 5.01834146
INFO:root:At the start of the epoch: mem (CPU python)=30632.46875MB; mem (CPU total)=51162.9375MB
INFO:root:[  121] Training loss: 0.46945873, Validation loss: 0.47419387, Gradient norm: 5.19477361
INFO:root:At the start of the epoch: mem (CPU python)=30653.62890625MB; mem (CPU total)=51203.5078125MB
INFO:root:[  122] Training loss: 0.46975261, Validation loss: 0.47398015, Gradient norm: 5.25065764
INFO:root:At the start of the epoch: mem (CPU python)=30674.796875MB; mem (CPU total)=51244.83984375MB
INFO:root:[  123] Training loss: 0.46940311, Validation loss: 0.47413306, Gradient norm: 5.25773255
INFO:root:At the start of the epoch: mem (CPU python)=30695.9609375MB; mem (CPU total)=51285.671875MB
INFO:root:[  124] Training loss: 0.46922844, Validation loss: 0.47311480, Gradient norm: 5.14828362
INFO:root:At the start of the epoch: mem (CPU python)=30717.125MB; mem (CPU total)=51326.78515625MB
INFO:root:[  125] Training loss: 0.46960942, Validation loss: 0.47297072, Gradient norm: 5.65170549
INFO:root:At the start of the epoch: mem (CPU python)=30738.2890625MB; mem (CPU total)=51368.0859375MB
INFO:root:[  126] Training loss: 0.46957406, Validation loss: 0.47337447, Gradient norm: 5.05235694
INFO:root:At the start of the epoch: mem (CPU python)=30759.453125MB; mem (CPU total)=51408.71484375MB
INFO:root:[  127] Training loss: 0.46905585, Validation loss: 0.47312683, Gradient norm: 5.49053643
INFO:root:At the start of the epoch: mem (CPU python)=30780.62109375MB; mem (CPU total)=51449.09765625MB
INFO:root:[  128] Training loss: 0.46913490, Validation loss: 0.47283388, Gradient norm: 5.20877594
INFO:root:At the start of the epoch: mem (CPU python)=30801.78515625MB; mem (CPU total)=51489.70703125MB
INFO:root:[  129] Training loss: 0.46909907, Validation loss: 0.47226678, Gradient norm: 5.29954601
INFO:root:At the start of the epoch: mem (CPU python)=30822.94921875MB; mem (CPU total)=51530.58203125MB
INFO:root:[  130] Training loss: 0.46858671, Validation loss: 0.47290821, Gradient norm: 5.47957263
INFO:root:At the start of the epoch: mem (CPU python)=30844.109375MB; mem (CPU total)=51571.72265625MB
INFO:root:[  131] Training loss: 0.46824167, Validation loss: 0.47300178, Gradient norm: 5.44675816
INFO:root:At the start of the epoch: mem (CPU python)=30865.2734375MB; mem (CPU total)=51613.5MB
INFO:root:[  132] Training loss: 0.46853081, Validation loss: 0.47231774, Gradient norm: 5.77674583
INFO:root:At the start of the epoch: mem (CPU python)=30886.4375MB; mem (CPU total)=51656.10546875MB
INFO:root:[  133] Training loss: 0.46885665, Validation loss: 0.47235012, Gradient norm: 5.62098658
INFO:root:At the start of the epoch: mem (CPU python)=30907.60546875MB; mem (CPU total)=51698.4296875MB
INFO:root:[  134] Training loss: 0.46829973, Validation loss: 0.47242144, Gradient norm: 5.59189514
INFO:root:At the start of the epoch: mem (CPU python)=30928.765625MB; mem (CPU total)=51741.19921875MB
INFO:root:[  135] Training loss: 0.46834080, Validation loss: 0.47180342, Gradient norm: 6.24269991
INFO:root:At the start of the epoch: mem (CPU python)=30949.93359375MB; mem (CPU total)=51782.16015625MB
INFO:root:[  136] Training loss: 0.46860374, Validation loss: 0.47232863, Gradient norm: 5.96691495
INFO:root:At the start of the epoch: mem (CPU python)=30971.09375MB; mem (CPU total)=51821.5078125MB
INFO:root:[  137] Training loss: 0.46804443, Validation loss: 0.47239565, Gradient norm: 5.44480222
INFO:root:At the start of the epoch: mem (CPU python)=30992.2578125MB; mem (CPU total)=51862.61328125MB
INFO:root:[  138] Training loss: 0.46785548, Validation loss: 0.47160463, Gradient norm: 5.73327254
INFO:root:At the start of the epoch: mem (CPU python)=31013.42578125MB; mem (CPU total)=51904.171875MB
INFO:root:[  139] Training loss: 0.46830001, Validation loss: 0.47093671, Gradient norm: 6.02055931
INFO:root:At the start of the epoch: mem (CPU python)=31034.58984375MB; mem (CPU total)=51944.5546875MB
INFO:root:[  140] Training loss: 0.46784233, Validation loss: 0.47141438, Gradient norm: 5.93648771
INFO:root:At the start of the epoch: mem (CPU python)=31055.75MB; mem (CPU total)=51985.203125MB
INFO:root:[  141] Training loss: 0.46789804, Validation loss: 0.47273362, Gradient norm: 6.16693818
INFO:root:At the start of the epoch: mem (CPU python)=31076.9140625MB; mem (CPU total)=52027.203125MB
INFO:root:[  142] Training loss: 0.46765335, Validation loss: 0.47189635, Gradient norm: 5.93147793
INFO:root:At the start of the epoch: mem (CPU python)=31098.078125MB; mem (CPU total)=52067.5546875MB
INFO:root:[  143] Training loss: 0.46764584, Validation loss: 0.47091197, Gradient norm: 6.29798258
INFO:root:At the start of the epoch: mem (CPU python)=31119.24609375MB; mem (CPU total)=52108.17578125MB
INFO:root:[  144] Training loss: 0.46768032, Validation loss: 0.47261423, Gradient norm: 6.32149920
INFO:root:At the start of the epoch: mem (CPU python)=31140.41015625MB; mem (CPU total)=52148.98828125MB
INFO:root:[  145] Training loss: 0.46760195, Validation loss: 0.47182286, Gradient norm: 5.99048214
INFO:root:At the start of the epoch: mem (CPU python)=31161.57421875MB; mem (CPU total)=52189.30078125MB
INFO:root:[  146] Training loss: 0.46743144, Validation loss: 0.47183105, Gradient norm: 6.17127045
INFO:root:At the start of the epoch: mem (CPU python)=31182.73828125MB; mem (CPU total)=52230.40625MB
INFO:root:[  147] Training loss: 0.46741775, Validation loss: 0.47186694, Gradient norm: 5.89386836
INFO:root:At the start of the epoch: mem (CPU python)=31203.90625MB; mem (CPU total)=52273.2109375MB
INFO:root:[  148] Training loss: 0.46758755, Validation loss: 0.47107611, Gradient norm: 6.53833137
INFO:root:At the start of the epoch: mem (CPU python)=31225.0703125MB; mem (CPU total)=52315.3359375MB
INFO:root:[  149] Training loss: 0.46754610, Validation loss: 0.47194663, Gradient norm: 6.38624852
INFO:root:At the start of the epoch: mem (CPU python)=31246.234375MB; mem (CPU total)=52357.64453125MB
INFO:root:[  150] Training loss: 0.46779008, Validation loss: 0.47083662, Gradient norm: 6.52385634
INFO:root:At the start of the epoch: mem (CPU python)=31267.3984375MB; mem (CPU total)=52400.18359375MB
INFO:root:[  151] Training loss: 0.46764868, Validation loss: 0.47037385, Gradient norm: 6.68442875
INFO:root:At the start of the epoch: mem (CPU python)=31288.5625MB; mem (CPU total)=52439.8671875MB
INFO:root:[  152] Training loss: 0.46748641, Validation loss: 0.46950059, Gradient norm: 6.62575368
INFO:root:At the start of the epoch: mem (CPU python)=31309.7265625MB; mem (CPU total)=52479.30078125MB
INFO:root:[  153] Training loss: 0.46752387, Validation loss: 0.47107879, Gradient norm: 6.87337138
INFO:root:At the start of the epoch: mem (CPU python)=31330.88671875MB; mem (CPU total)=52520.078125MB
INFO:root:[  154] Training loss: 0.46689680, Validation loss: 0.47113793, Gradient norm: 6.89260553
INFO:root:At the start of the epoch: mem (CPU python)=31352.05078125MB; mem (CPU total)=52560.66796875MB
INFO:root:[  155] Training loss: 0.46729740, Validation loss: 0.47092416, Gradient norm: 6.76158463
INFO:root:At the start of the epoch: mem (CPU python)=31373.21875MB; mem (CPU total)=52601.4609375MB
INFO:root:[  156] Training loss: 0.46719634, Validation loss: 0.47131251, Gradient norm: 7.30996989
INFO:root:At the start of the epoch: mem (CPU python)=31394.3828125MB; mem (CPU total)=52641.74609375MB
INFO:root:[  157] Training loss: 0.46735856, Validation loss: 0.47093136, Gradient norm: 6.82143706
INFO:root:At the start of the epoch: mem (CPU python)=31415.546875MB; mem (CPU total)=52682.5390625MB
INFO:root:[  158] Training loss: 0.46711090, Validation loss: 0.47034594, Gradient norm: 7.00764368
INFO:root:At the start of the epoch: mem (CPU python)=31436.70703125MB; mem (CPU total)=52723.34375MB
INFO:root:[  159] Training loss: 0.46759769, Validation loss: 0.47248958, Gradient norm: 6.98618249
INFO:root:At the start of the epoch: mem (CPU python)=31457.87109375MB; mem (CPU total)=52763.9453125MB
INFO:root:[  160] Training loss: 0.46745696, Validation loss: 0.47047125, Gradient norm: 7.22693044
INFO:root:At the start of the epoch: mem (CPU python)=31479.0390625MB; mem (CPU total)=52804.00390625MB
INFO:root:[  161] Training loss: 0.46708880, Validation loss: 0.47171545, Gradient norm: 7.31886745
INFO:root:At the start of the epoch: mem (CPU python)=31500.203125MB; mem (CPU total)=52844.609375MB
INFO:root:EP 161: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=31521.1796875MB; mem (CPU total)=52879.34765625MB
INFO:root:Training the model took 8605.33s.
INFO:root:Emptying the cuda cache took 0.064s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.50008
INFO:root:EnergyScoreValidation: 0.42205
INFO:root:CRPSValidation: 0.17166
INFO:root:Gaussian NLLValidation: 3.98456
INFO:root:CoverageValidation: 0.46483
INFO:root:IntervalWidthValidation: 0.29395
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.39811
INFO:root:EnergyScoreTest: 0.32108
INFO:root:CRPSTest: 0.12853
INFO:root:Gaussian NLLTest: 1.35222
INFO:root:CoverageTest: 0.5999
INFO:root:IntervalWidthTest: 0.31152
INFO:root:After validation: mem (CPU python)=31828.08203125MB; mem (CPU total)=52962.54296875MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=31828.08203125MB; mem (CPU total)=52974.0859375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 297795584
INFO:root:After setting up the model: mem (CPU python)=31828.08203125MB; mem (CPU total)=52974.0859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=52978.4765625MB
INFO:root:[    1] Training loss: 0.84074616, Validation loss: 0.74542628, Gradient norm: 0.48069239
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53018.64453125MB
INFO:root:[    2] Training loss: 0.74121849, Validation loss: 0.73910888, Gradient norm: 0.38069165
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53053.89453125MB
INFO:root:[    3] Training loss: 0.73630100, Validation loss: 0.72666589, Gradient norm: 0.43927918
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53089.65625MB
INFO:root:[    4] Training loss: 0.71984989, Validation loss: 0.71141334, Gradient norm: 0.63750536
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53124.85546875MB
INFO:root:[    5] Training loss: 0.68208035, Validation loss: 0.66475070, Gradient norm: 0.83714767
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53167.359375MB
INFO:root:[    6] Training loss: 0.63832690, Validation loss: 0.62927308, Gradient norm: 1.40906444
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53201.34765625MB
INFO:root:[    7] Training loss: 0.60160333, Validation loss: 0.57741637, Gradient norm: 1.43666486
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53236.51953125MB
INFO:root:[    8] Training loss: 0.58191526, Validation loss: 0.56277509, Gradient norm: 1.53447964
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53273.39453125MB
INFO:root:[    9] Training loss: 0.56431312, Validation loss: 0.57424871, Gradient norm: 1.48333166
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53313.93359375MB
INFO:root:[   10] Training loss: 0.55931642, Validation loss: 0.55171500, Gradient norm: 1.98353969
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53348.375MB
INFO:root:[   11] Training loss: 0.54812869, Validation loss: 0.53710416, Gradient norm: 1.87429188
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53385.0078125MB
INFO:root:[   12] Training loss: 0.53542300, Validation loss: 0.52812601, Gradient norm: 1.96814084
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53423.0MB
INFO:root:[   13] Training loss: 0.52649435, Validation loss: 0.51554757, Gradient norm: 2.45948943
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53461.15234375MB
INFO:root:[   14] Training loss: 0.51987758, Validation loss: 0.51183239, Gradient norm: 2.32075857
INFO:root:At the start of the epoch: mem (CPU python)=31828.08203125MB; mem (CPU total)=53496.96875MB
INFO:root:[   15] Training loss: 0.51074212, Validation loss: 0.49655030, Gradient norm: 2.32977355
INFO:root:At the start of the epoch: mem (CPU python)=31845.62109375MB; mem (CPU total)=53532.21875MB
INFO:root:[   16] Training loss: 0.50921731, Validation loss: 0.50272022, Gradient norm: 3.09425737
INFO:root:At the start of the epoch: mem (CPU python)=31866.78515625MB; mem (CPU total)=53571.765625MB
INFO:root:[   17] Training loss: 0.50644230, Validation loss: 0.49628508, Gradient norm: 2.78095941
INFO:root:At the start of the epoch: mem (CPU python)=31887.94921875MB; mem (CPU total)=53608.91015625MB
INFO:root:[   18] Training loss: 0.50187411, Validation loss: 0.50416672, Gradient norm: 2.66272713
INFO:root:At the start of the epoch: mem (CPU python)=31909.11328125MB; mem (CPU total)=53643.63671875MB
INFO:root:[   19] Training loss: 0.49745926, Validation loss: 0.49498900, Gradient norm: 2.85499797
INFO:root:At the start of the epoch: mem (CPU python)=31930.28125MB; mem (CPU total)=53678.98046875MB
INFO:root:[   20] Training loss: 0.49366764, Validation loss: 0.48839595, Gradient norm: 3.39226014
INFO:root:At the start of the epoch: mem (CPU python)=31951.4453125MB; mem (CPU total)=53720.05078125MB
INFO:root:[   21] Training loss: 0.49453609, Validation loss: 0.48545085, Gradient norm: 3.52608939
INFO:root:At the start of the epoch: mem (CPU python)=31972.609375MB; mem (CPU total)=53755.8984375MB
INFO:root:[   22] Training loss: 0.48973980, Validation loss: 0.49374808, Gradient norm: 3.07467136
INFO:root:At the start of the epoch: mem (CPU python)=31993.7734375MB; mem (CPU total)=53791.4453125MB
INFO:root:[   23] Training loss: 0.49391465, Validation loss: 0.49868858, Gradient norm: 3.09231101
INFO:root:At the start of the epoch: mem (CPU python)=32014.93359375MB; mem (CPU total)=53827.2421875MB
INFO:root:[   24] Training loss: 0.48823230, Validation loss: 0.48524256, Gradient norm: 3.33728547
INFO:root:At the start of the epoch: mem (CPU python)=32036.09765625MB; mem (CPU total)=53868.484375MB
INFO:root:[   25] Training loss: 0.48500512, Validation loss: 0.48901196, Gradient norm: 3.22885017
INFO:root:At the start of the epoch: mem (CPU python)=32057.2578125MB; mem (CPU total)=53903.74609375MB
INFO:root:[   26] Training loss: 0.49105063, Validation loss: 0.50807911, Gradient norm: 3.36532039
INFO:root:At the start of the epoch: mem (CPU python)=32078.421875MB; mem (CPU total)=53939.18359375MB
INFO:root:[   27] Training loss: 0.48619104, Validation loss: 0.48176599, Gradient norm: 3.45316554
INFO:root:At the start of the epoch: mem (CPU python)=32099.58984375MB; mem (CPU total)=53974.93359375MB
INFO:root:[   28] Training loss: 0.48272758, Validation loss: 0.47891232, Gradient norm: 3.54572994
INFO:root:At the start of the epoch: mem (CPU python)=32120.75390625MB; mem (CPU total)=54017.2109375MB
INFO:root:[   29] Training loss: 0.48401061, Validation loss: 0.47862834, Gradient norm: 3.22812792
INFO:root:At the start of the epoch: mem (CPU python)=32141.91796875MB; mem (CPU total)=54051.6484375MB
INFO:root:[   30] Training loss: 0.47838920, Validation loss: 0.48187636, Gradient norm: 3.41082439
INFO:root:At the start of the epoch: mem (CPU python)=32163.08203125MB; mem (CPU total)=54087.05078125MB
INFO:root:[   31] Training loss: 0.48187046, Validation loss: 0.47268550, Gradient norm: 4.12503595
INFO:root:At the start of the epoch: mem (CPU python)=32184.25MB; mem (CPU total)=54123.3359375MB
INFO:root:[   32] Training loss: 0.48029728, Validation loss: 0.48145762, Gradient norm: 3.62026166
INFO:root:At the start of the epoch: mem (CPU python)=32205.4140625MB; mem (CPU total)=54165.6640625MB
INFO:root:[   33] Training loss: 0.48009123, Validation loss: 0.48343422, Gradient norm: 3.48856141
INFO:root:At the start of the epoch: mem (CPU python)=32226.578125MB; mem (CPU total)=54199.54296875MB
INFO:root:[   34] Training loss: 0.47954248, Validation loss: 0.49304675, Gradient norm: 3.27953922
INFO:root:At the start of the epoch: mem (CPU python)=32247.73828125MB; mem (CPU total)=54234.984375MB
INFO:root:[   35] Training loss: 0.48002565, Validation loss: 0.46529164, Gradient norm: 3.77460515
INFO:root:At the start of the epoch: mem (CPU python)=32268.90234375MB; mem (CPU total)=54271.5625MB
INFO:root:[   36] Training loss: 0.47826429, Validation loss: 0.49134000, Gradient norm: 3.62198434
INFO:root:At the start of the epoch: mem (CPU python)=32290.06640625MB; mem (CPU total)=54314.22265625MB
INFO:root:[   37] Training loss: 0.47599622, Validation loss: 0.46887045, Gradient norm: 3.62501783
INFO:root:At the start of the epoch: mem (CPU python)=32311.23828125MB; mem (CPU total)=54347.984375MB
INFO:root:[   38] Training loss: 0.48131403, Validation loss: 0.47354448, Gradient norm: 4.06607132
INFO:root:At the start of the epoch: mem (CPU python)=32332.40234375MB; mem (CPU total)=54383.66796875MB
INFO:root:[   39] Training loss: 0.47811637, Validation loss: 0.47547268, Gradient norm: 3.63315772
INFO:root:At the start of the epoch: mem (CPU python)=32353.56640625MB; mem (CPU total)=54419.703125MB
INFO:root:[   40] Training loss: 0.47824240, Validation loss: 0.46725241, Gradient norm: 4.00018087
INFO:root:At the start of the epoch: mem (CPU python)=32374.73046875MB; mem (CPU total)=54461.86328125MB
INFO:root:[   41] Training loss: 0.47239091, Validation loss: 0.46286875, Gradient norm: 3.67350158
INFO:root:At the start of the epoch: mem (CPU python)=32395.89453125MB; mem (CPU total)=54494.9765625MB
INFO:root:[   42] Training loss: 0.47240895, Validation loss: 0.47988485, Gradient norm: 3.64727067
INFO:root:At the start of the epoch: mem (CPU python)=32417.0546875MB; mem (CPU total)=54531.06640625MB
INFO:root:[   43] Training loss: 0.47327484, Validation loss: 0.47946983, Gradient norm: 3.65221759
INFO:root:At the start of the epoch: mem (CPU python)=32438.21875MB; mem (CPU total)=54567.4921875MB
INFO:root:[   44] Training loss: 0.47545105, Validation loss: 0.46842509, Gradient norm: 4.06904960
INFO:root:At the start of the epoch: mem (CPU python)=32459.3828125MB; mem (CPU total)=54609.7265625MB
INFO:root:[   45] Training loss: 0.46727584, Validation loss: 0.46291939, Gradient norm: 3.54792423
INFO:root:At the start of the epoch: mem (CPU python)=32480.546875MB; mem (CPU total)=54643.6875MB
INFO:root:[   46] Training loss: 0.46919723, Validation loss: 0.47064849, Gradient norm: 3.70025422
INFO:root:At the start of the epoch: mem (CPU python)=32501.7109375MB; mem (CPU total)=54679.6171875MB
INFO:root:[   47] Training loss: 0.46936684, Validation loss: 0.47743204, Gradient norm: 4.07388371
INFO:root:At the start of the epoch: mem (CPU python)=32522.87890625MB; mem (CPU total)=54715.421875MB
INFO:root:[   48] Training loss: 0.47071470, Validation loss: 0.46412660, Gradient norm: 3.93123752
INFO:root:At the start of the epoch: mem (CPU python)=32544.04296875MB; mem (CPU total)=54758.12109375MB
INFO:root:[   49] Training loss: 0.46816278, Validation loss: 0.46202984, Gradient norm: 3.89734609
INFO:root:At the start of the epoch: mem (CPU python)=32565.20703125MB; mem (CPU total)=54792.13671875MB
INFO:root:[   50] Training loss: 0.46792104, Validation loss: 0.46611046, Gradient norm: 3.17059602
INFO:root:At the start of the epoch: mem (CPU python)=32586.37109375MB; mem (CPU total)=54828.28515625MB
INFO:root:[   51] Training loss: 0.46006675, Validation loss: 0.46668739, Gradient norm: 4.58898187
INFO:root:At the start of the epoch: mem (CPU python)=32607.53515625MB; mem (CPU total)=54864.41015625MB
INFO:root:[   52] Training loss: 0.46925173, Validation loss: 0.46938671, Gradient norm: 4.05109035
INFO:root:At the start of the epoch: mem (CPU python)=32628.6953125MB; mem (CPU total)=54906.58984375MB
INFO:root:[   53] Training loss: 0.46289975, Validation loss: 0.46986323, Gradient norm: 4.33222724
INFO:root:At the start of the epoch: mem (CPU python)=32649.8671875MB; mem (CPU total)=54940.921875MB
INFO:root:[   54] Training loss: 0.46404289, Validation loss: 0.47595308, Gradient norm: 3.94091890
INFO:root:At the start of the epoch: mem (CPU python)=32671.03125MB; mem (CPU total)=54976.625MB
INFO:root:[   55] Training loss: 0.46307678, Validation loss: 0.47274060, Gradient norm: 3.76404543
INFO:root:At the start of the epoch: mem (CPU python)=32692.1953125MB; mem (CPU total)=55012.28125MB
INFO:root:[   56] Training loss: 0.45917161, Validation loss: 0.45674317, Gradient norm: 4.12054785
INFO:root:At the start of the epoch: mem (CPU python)=32713.359375MB; mem (CPU total)=55054.703125MB
INFO:root:[   57] Training loss: 0.46222161, Validation loss: 0.45688205, Gradient norm: 3.76662879
INFO:root:At the start of the epoch: mem (CPU python)=32734.5234375MB; mem (CPU total)=55089.7265625MB
INFO:root:[   58] Training loss: 0.45706443, Validation loss: 0.44739020, Gradient norm: 4.58228185
INFO:root:At the start of the epoch: mem (CPU python)=32755.6875MB; mem (CPU total)=55125.4296875MB
INFO:root:[   59] Training loss: 0.46216605, Validation loss: 0.44719785, Gradient norm: 4.06938655
INFO:root:At the start of the epoch: mem (CPU python)=32776.85546875MB; mem (CPU total)=55160.8203125MB
INFO:root:[   60] Training loss: 0.45962256, Validation loss: 0.45807657, Gradient norm: 4.05957444
INFO:root:At the start of the epoch: mem (CPU python)=32798.015625MB; mem (CPU total)=55202.90234375MB
INFO:root:[   61] Training loss: 0.46182815, Validation loss: 0.45742148, Gradient norm: 4.39513841
INFO:root:At the start of the epoch: mem (CPU python)=32819.1796875MB; mem (CPU total)=55238.33203125MB
INFO:root:[   62] Training loss: 0.45459029, Validation loss: 0.45591829, Gradient norm: 4.08494056
INFO:root:At the start of the epoch: mem (CPU python)=32840.33984375MB; mem (CPU total)=55274.375MB
INFO:root:[   63] Training loss: 0.46275319, Validation loss: 0.46126765, Gradient norm: 4.27658060
INFO:root:At the start of the epoch: mem (CPU python)=32861.50390625MB; mem (CPU total)=55310.0390625MB
INFO:root:[   64] Training loss: 0.45683553, Validation loss: 0.44689224, Gradient norm: 4.41932036
INFO:root:At the start of the epoch: mem (CPU python)=32882.671875MB; mem (CPU total)=55351.5859375MB
INFO:root:[   65] Training loss: 0.45558100, Validation loss: 0.47270232, Gradient norm: 4.27078791
INFO:root:At the start of the epoch: mem (CPU python)=32903.8359375MB; mem (CPU total)=55387.57421875MB
INFO:root:[   66] Training loss: 0.45522661, Validation loss: 0.47320089, Gradient norm: 3.98042689
INFO:root:At the start of the epoch: mem (CPU python)=32924.99609375MB; mem (CPU total)=55423.4921875MB
INFO:root:[   67] Training loss: 0.45897042, Validation loss: 0.47135915, Gradient norm: 3.80477143
INFO:root:At the start of the epoch: mem (CPU python)=32946.16015625MB; mem (CPU total)=55459.28515625MB
INFO:root:[   68] Training loss: 0.45910830, Validation loss: 0.45871894, Gradient norm: 4.55018569
INFO:root:At the start of the epoch: mem (CPU python)=32967.32421875MB; mem (CPU total)=55500.02734375MB
INFO:root:[   69] Training loss: 0.45600780, Validation loss: 0.45359584, Gradient norm: 4.30477529
INFO:root:At the start of the epoch: mem (CPU python)=32988.48828125MB; mem (CPU total)=55516.03515625MB
INFO:root:[   70] Training loss: 0.45548640, Validation loss: 0.45090300, Gradient norm: 4.16012642
INFO:root:At the start of the epoch: mem (CPU python)=33009.65625MB; mem (CPU total)=55550.70703125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   71] Training loss: 0.45083133, Validation loss: 0.45211264, Gradient norm: 4.14987616
INFO:root:At the start of the epoch: mem (CPU python)=33030.81640625MB; mem (CPU total)=55586.5390625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   72] Training loss: 0.42445526, Validation loss: 0.42851170, Gradient norm: 3.13027788
INFO:root:At the start of the epoch: mem (CPU python)=33051.98046875MB; mem (CPU total)=55628.21875MB
INFO:root:[   73] Training loss: 0.41480936, Validation loss: 0.41848597, Gradient norm: 2.26967641
INFO:root:At the start of the epoch: mem (CPU python)=33073.14453125MB; mem (CPU total)=55664.5078125MB
INFO:root:[   74] Training loss: 0.41322635, Validation loss: 0.42125658, Gradient norm: 2.73188089
INFO:root:At the start of the epoch: mem (CPU python)=33094.30859375MB; mem (CPU total)=55700.56640625MB
INFO:root:[   75] Training loss: 0.41315971, Validation loss: 0.42108224, Gradient norm: 3.25390073
INFO:root:At the start of the epoch: mem (CPU python)=33115.47265625MB; mem (CPU total)=55737.58203125MB
INFO:root:[   76] Training loss: 0.41376573, Validation loss: 0.42472777, Gradient norm: 3.51326086
INFO:root:At the start of the epoch: mem (CPU python)=33136.63671875MB; mem (CPU total)=55775.61328125MB
INFO:root:[   77] Training loss: 0.41376081, Validation loss: 0.42155511, Gradient norm: 3.90682597
INFO:root:At the start of the epoch: mem (CPU python)=33157.80078125MB; mem (CPU total)=55814.76171875MB
INFO:root:[   78] Training loss: 0.41348342, Validation loss: 0.41700863, Gradient norm: 4.58363562
INFO:root:At the start of the epoch: mem (CPU python)=33178.96484375MB; mem (CPU total)=55850.50390625MB
INFO:root:[   79] Training loss: 0.41369544, Validation loss: 0.41881962, Gradient norm: 5.10589508
INFO:root:At the start of the epoch: mem (CPU python)=33200.12890625MB; mem (CPU total)=55886.3984375MB
INFO:root:[   80] Training loss: 0.41371902, Validation loss: 0.41764829, Gradient norm: 5.27055108
INFO:root:At the start of the epoch: mem (CPU python)=33221.29296875MB; mem (CPU total)=55923.51171875MB
INFO:root:[   81] Training loss: 0.41425132, Validation loss: 0.41948468, Gradient norm: 5.67513314
INFO:root:At the start of the epoch: mem (CPU python)=33242.453125MB; mem (CPU total)=55965.0546875MB
INFO:root:[   82] Training loss: 0.41325796, Validation loss: 0.41959387, Gradient norm: 6.12090989
INFO:root:At the start of the epoch: mem (CPU python)=33263.62109375MB; mem (CPU total)=56000.7265625MB
INFO:root:[   83] Training loss: 0.41560875, Validation loss: 0.42282385, Gradient norm: 6.25981273
INFO:root:At the start of the epoch: mem (CPU python)=33284.78515625MB; mem (CPU total)=56036.25390625MB
INFO:root:[   84] Training loss: 0.41547551, Validation loss: 0.41773174, Gradient norm: 6.15524357
INFO:root:At the start of the epoch: mem (CPU python)=33305.953125MB; mem (CPU total)=56072.2734375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   85] Training loss: 0.41540962, Validation loss: 0.42009374, Gradient norm: 7.15108552
INFO:root:At the start of the epoch: mem (CPU python)=33327.1171875MB; mem (CPU total)=56113.89453125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   86] Training loss: 0.40974593, Validation loss: 0.41465442, Gradient norm: 5.09772281
INFO:root:At the start of the epoch: mem (CPU python)=33348.28125MB; mem (CPU total)=56152.32421875MB
INFO:root:[   87] Training loss: 0.40689127, Validation loss: 0.41330842, Gradient norm: 3.25260846
INFO:root:At the start of the epoch: mem (CPU python)=33369.44921875MB; mem (CPU total)=56186.52734375MB
INFO:root:[   88] Training loss: 0.40706788, Validation loss: 0.41265346, Gradient norm: 3.31542386
INFO:root:At the start of the epoch: mem (CPU python)=33390.61328125MB; mem (CPU total)=56221.51171875MB
INFO:root:[   89] Training loss: 0.40664411, Validation loss: 0.41230924, Gradient norm: 3.87403661
INFO:root:At the start of the epoch: mem (CPU python)=33411.77734375MB; mem (CPU total)=56262.671875MB
INFO:root:[   90] Training loss: 0.40768479, Validation loss: 0.41358481, Gradient norm: 5.78093375
INFO:root:At the start of the epoch: mem (CPU python)=33432.9375MB; mem (CPU total)=56300.0234375MB
INFO:root:[   91] Training loss: 0.40675694, Validation loss: 0.41303286, Gradient norm: 4.39852468
INFO:root:At the start of the epoch: mem (CPU python)=33454.1015625MB; mem (CPU total)=56336.12109375MB
INFO:root:[   92] Training loss: 0.40719664, Validation loss: 0.41342354, Gradient norm: 4.36162049
INFO:root:At the start of the epoch: mem (CPU python)=33475.26171875MB; mem (CPU total)=56370.859375MB
INFO:root:[   93] Training loss: 0.40719690, Validation loss: 0.41273670, Gradient norm: 4.92460047
INFO:root:At the start of the epoch: mem (CPU python)=33496.4296875MB; mem (CPU total)=56412.1796875MB
INFO:root:[   94] Training loss: 0.40736610, Validation loss: 0.41334771, Gradient norm: 4.94634143
INFO:root:At the start of the epoch: mem (CPU python)=33517.59375MB; mem (CPU total)=56449.734375MB
INFO:root:[   95] Training loss: 0.40784303, Validation loss: 0.41247591, Gradient norm: 5.55698789
INFO:root:At the start of the epoch: mem (CPU python)=33538.7578125MB; mem (CPU total)=56485.31640625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   96] Training loss: 0.40737492, Validation loss: 0.41378233, Gradient norm: 5.61197776
INFO:root:At the start of the epoch: mem (CPU python)=33559.921875MB; mem (CPU total)=56520.15625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   97] Training loss: 0.40598176, Validation loss: 0.41347488, Gradient norm: 4.16029202
INFO:root:At the start of the epoch: mem (CPU python)=33581.0859375MB; mem (CPU total)=56563.0390625MB
INFO:root:[   98] Training loss: 0.40598636, Validation loss: 0.41144443, Gradient norm: 3.43798697
INFO:root:At the start of the epoch: mem (CPU python)=33602.25390625MB; mem (CPU total)=56600.28515625MB
INFO:root:[   99] Training loss: 0.40554630, Validation loss: 0.41247525, Gradient norm: 3.29733540
INFO:root:At the start of the epoch: mem (CPU python)=33623.41015625MB; mem (CPU total)=56634.69921875MB
INFO:root:[  100] Training loss: 0.40509438, Validation loss: 0.41113413, Gradient norm: 3.48528231
INFO:root:At the start of the epoch: mem (CPU python)=33644.578125MB; mem (CPU total)=56670.40625MB
INFO:root:[  101] Training loss: 0.40544025, Validation loss: 0.41327972, Gradient norm: 3.58965859
INFO:root:At the start of the epoch: mem (CPU python)=33665.7421875MB; mem (CPU total)=56674.828125MB
INFO:root:[  102] Training loss: 0.40576428, Validation loss: 0.41234803, Gradient norm: 3.38100887
INFO:root:At the start of the epoch: mem (CPU python)=33686.90625MB; mem (CPU total)=56694.3828125MB
INFO:root:[  103] Training loss: 0.40626714, Validation loss: 0.41153193, Gradient norm: 3.57994392
INFO:root:At the start of the epoch: mem (CPU python)=33708.0703125MB; mem (CPU total)=56719.4140625MB
INFO:root:[  104] Training loss: 0.40559173, Validation loss: 0.41171006, Gradient norm: 3.93687044
INFO:root:At the start of the epoch: mem (CPU python)=33729.23828125MB; mem (CPU total)=56743.14453125MB
INFO:root:[  105] Training loss: 0.40528354, Validation loss: 0.41211072, Gradient norm: 4.11583473
INFO:root:At the start of the epoch: mem (CPU python)=33750.40234375MB; mem (CPU total)=56765.859375MB
INFO:root:[  106] Training loss: 0.40602696, Validation loss: 0.41284935, Gradient norm: 4.44909658
INFO:root:At the start of the epoch: mem (CPU python)=33771.56640625MB; mem (CPU total)=56814.3359375MB
INFO:root:[  107] Training loss: 0.40600455, Validation loss: 0.41251973, Gradient norm: 4.28375767
INFO:root:At the start of the epoch: mem (CPU python)=33792.73046875MB; mem (CPU total)=56857.11328125MB
INFO:root:[  108] Training loss: 0.40560971, Validation loss: 0.41200419, Gradient norm: 3.96254990
INFO:root:At the start of the epoch: mem (CPU python)=33813.8984375MB; mem (CPU total)=56893.046875MB
INFO:root:[  109] Training loss: 0.40668597, Validation loss: 0.41170675, Gradient norm: 4.58510961
INFO:root:At the start of the epoch: mem (CPU python)=33835.0546875MB; mem (CPU total)=56932.453125MB
INFO:root:EP 109: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=33856.21875MB; mem (CPU total)=56968.35546875MB
INFO:root:[  111] Training loss: 0.48999577, Validation loss: 0.49251566, Gradient norm: 6.84319869
INFO:root:At the start of the epoch: mem (CPU python)=33877.3828125MB; mem (CPU total)=57010.0625MB
INFO:root:[  112] Training loss: 0.48768043, Validation loss: 0.49111564, Gradient norm: 7.58635385
INFO:root:At the start of the epoch: mem (CPU python)=33898.546875MB; mem (CPU total)=57052.2109375MB
INFO:root:[  113] Training loss: 0.48740177, Validation loss: 0.49120419, Gradient norm: 6.44655673
INFO:root:At the start of the epoch: mem (CPU python)=33919.7109375MB; mem (CPU total)=57095.234375MB
INFO:root:[  114] Training loss: 0.48626148, Validation loss: 0.49219061, Gradient norm: 6.68910059
INFO:root:At the start of the epoch: mem (CPU python)=33940.875MB; mem (CPU total)=57137.8125MB
INFO:root:[  115] Training loss: 0.48633418, Validation loss: 0.49010117, Gradient norm: 6.84261056
INFO:root:At the start of the epoch: mem (CPU python)=33962.04296875MB; mem (CPU total)=57180.125MB
INFO:root:[  116] Training loss: 0.48578904, Validation loss: 0.49176023, Gradient norm: 6.21270784
INFO:root:At the start of the epoch: mem (CPU python)=33983.203125MB; mem (CPU total)=57222.63671875MB
INFO:root:[  117] Training loss: 0.48595530, Validation loss: 0.49073115, Gradient norm: 6.74832648
INFO:root:At the start of the epoch: mem (CPU python)=34004.37109375MB; mem (CPU total)=57265.1875MB
INFO:root:[  118] Training loss: 0.48512505, Validation loss: 0.48960898, Gradient norm: 6.76553252
INFO:root:At the start of the epoch: mem (CPU python)=34025.53125MB; mem (CPU total)=57308.19921875MB
INFO:root:[  119] Training loss: 0.48528630, Validation loss: 0.49071900, Gradient norm: 7.02835356
INFO:root:At the start of the epoch: mem (CPU python)=34046.6953125MB; mem (CPU total)=57350.7421875MB
INFO:root:[  120] Training loss: 0.48535851, Validation loss: 0.48903909, Gradient norm: 6.91803704
INFO:root:At the start of the epoch: mem (CPU python)=34067.859375MB; mem (CPU total)=57393.08984375MB
INFO:root:[  121] Training loss: 0.48474158, Validation loss: 0.49086933, Gradient norm: 6.70912823
INFO:root:At the start of the epoch: mem (CPU python)=34089.0234375MB; mem (CPU total)=57434.12890625MB
INFO:root:[  122] Training loss: 0.48494252, Validation loss: 0.49100439, Gradient norm: 7.35602327
INFO:root:At the start of the epoch: mem (CPU python)=34110.1953125MB; mem (CPU total)=57475.19140625MB
INFO:root:[  123] Training loss: 0.48535664, Validation loss: 0.49025230, Gradient norm: 7.21298553
INFO:root:At the start of the epoch: mem (CPU python)=34131.359375MB; mem (CPU total)=57515.73046875MB
INFO:root:[  124] Training loss: 0.48487197, Validation loss: 0.48853563, Gradient norm: 6.88555604
INFO:root:At the start of the epoch: mem (CPU python)=34152.5234375MB; mem (CPU total)=57557.08203125MB
INFO:root:[  125] Training loss: 0.48483727, Validation loss: 0.48950342, Gradient norm: 6.87821939
INFO:root:At the start of the epoch: mem (CPU python)=34173.6875MB; mem (CPU total)=57599.140625MB
INFO:root:[  126] Training loss: 0.48498651, Validation loss: 0.48915172, Gradient norm: 7.45242211
INFO:root:At the start of the epoch: mem (CPU python)=34194.8515625MB; mem (CPU total)=57640.50390625MB
INFO:root:[  127] Training loss: 0.48487355, Validation loss: 0.48917758, Gradient norm: 7.12858414
INFO:root:At the start of the epoch: mem (CPU python)=34216.015625MB; mem (CPU total)=57682.796875MB
INFO:root:[  128] Training loss: 0.48447102, Validation loss: 0.48774181, Gradient norm: 7.63620899
INFO:root:At the start of the epoch: mem (CPU python)=34237.17578125MB; mem (CPU total)=57724.6015625MB
INFO:root:[  129] Training loss: 0.48487289, Validation loss: 0.48919400, Gradient norm: 7.15137650
INFO:root:At the start of the epoch: mem (CPU python)=34258.33984375MB; mem (CPU total)=57766.015625MB
INFO:root:[  130] Training loss: 0.48464182, Validation loss: 0.48741604, Gradient norm: 7.15319938
INFO:root:At the start of the epoch: mem (CPU python)=34279.50390625MB; mem (CPU total)=57807.14453125MB
INFO:root:[  131] Training loss: 0.48426638, Validation loss: 0.48912381, Gradient norm: 7.12741078
INFO:root:At the start of the epoch: mem (CPU python)=34300.66796875MB; mem (CPU total)=57848.9765625MB
INFO:root:[  132] Training loss: 0.48392118, Validation loss: 0.48922943, Gradient norm: 7.62721460
INFO:root:At the start of the epoch: mem (CPU python)=34321.83203125MB; mem (CPU total)=57890.0234375MB
INFO:root:[  133] Training loss: 0.48504045, Validation loss: 0.48864945, Gradient norm: 8.09830107
INFO:root:At the start of the epoch: mem (CPU python)=34343.0MB; mem (CPU total)=57931.90625MB
INFO:root:[  134] Training loss: 0.48458147, Validation loss: 0.48923081, Gradient norm: 7.60156777
INFO:root:At the start of the epoch: mem (CPU python)=34364.1640625MB; mem (CPU total)=57973.05859375MB
INFO:root:[  135] Training loss: 0.48445634, Validation loss: 0.48935647, Gradient norm: 8.22370204
INFO:root:At the start of the epoch: mem (CPU python)=34385.328125MB; mem (CPU total)=58015.00390625MB
INFO:root:[  136] Training loss: 0.48431072, Validation loss: 0.48792901, Gradient norm: 8.28563683
INFO:root:At the start of the epoch: mem (CPU python)=34406.49609375MB; mem (CPU total)=58056.640625MB
INFO:root:[  137] Training loss: 0.48432131, Validation loss: 0.48954797, Gradient norm: 8.36280806
INFO:root:At the start of the epoch: mem (CPU python)=34427.65234375MB; mem (CPU total)=58097.96484375MB
INFO:root:[  138] Training loss: 0.48423372, Validation loss: 0.48911556, Gradient norm: 8.32908041
INFO:root:At the start of the epoch: mem (CPU python)=34448.8203125MB; mem (CPU total)=58139.328125MB
INFO:root:[  139] Training loss: 0.48395241, Validation loss: 0.48709847, Gradient norm: 8.13604132
INFO:root:At the start of the epoch: mem (CPU python)=34469.984375MB; mem (CPU total)=58181.65234375MB
INFO:root:[  140] Training loss: 0.48414238, Validation loss: 0.48804276, Gradient norm: 7.88977914
INFO:root:At the start of the epoch: mem (CPU python)=34491.1484375MB; mem (CPU total)=58222.7421875MB
INFO:root:[  141] Training loss: 0.48413264, Validation loss: 0.48873478, Gradient norm: 8.43208231
INFO:root:At the start of the epoch: mem (CPU python)=34512.3125MB; mem (CPU total)=58264.578125MB
INFO:root:[  142] Training loss: 0.48386861, Validation loss: 0.48817029, Gradient norm: 8.13202918
INFO:root:At the start of the epoch: mem (CPU python)=34533.48046875MB; mem (CPU total)=58306.66015625MB
INFO:root:[  143] Training loss: 0.48465361, Validation loss: 0.48800594, Gradient norm: 8.81555906
INFO:root:At the start of the epoch: mem (CPU python)=34554.63671875MB; mem (CPU total)=58349.25MB
INFO:root:[  144] Training loss: 0.48430239, Validation loss: 0.48806985, Gradient norm: 9.00147672
INFO:root:At the start of the epoch: mem (CPU python)=34575.8046875MB; mem (CPU total)=58391.51171875MB
INFO:root:[  145] Training loss: 0.48398234, Validation loss: 0.48801878, Gradient norm: 8.77131459
INFO:root:At the start of the epoch: mem (CPU python)=34596.96875MB; mem (CPU total)=58434.0625MB
INFO:root:[  146] Training loss: 0.48406652, Validation loss: 0.48778201, Gradient norm: 9.20246978
INFO:root:At the start of the epoch: mem (CPU python)=34618.1328125MB; mem (CPU total)=58476.3671875MB
INFO:root:[  147] Training loss: 0.48418453, Validation loss: 0.48777411, Gradient norm: 9.30867730
INFO:root:At the start of the epoch: mem (CPU python)=34639.29296875MB; mem (CPU total)=58519.6640625MB
INFO:root:[  148] Training loss: 0.48441486, Validation loss: 0.48812131, Gradient norm: 8.89859413
INFO:root:At the start of the epoch: mem (CPU python)=34660.45703125MB; mem (CPU total)=58562.1875MB
INFO:root:EP 148: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=34681.625MB; mem (CPU total)=58591.46484375MB
INFO:root:Training the model took 8235.127s.
INFO:root:Emptying the cuda cache took 0.069s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.5014
INFO:root:EnergyScoreValidation: 0.40908
INFO:root:CRPSValidation: 0.16537
INFO:root:Gaussian NLLValidation: 2.09806
INFO:root:CoverageValidation: 0.5585
INFO:root:IntervalWidthValidation: 0.36298
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.40117
INFO:root:EnergyScoreTest: 0.31248
INFO:root:CRPSTest: 0.12403
INFO:root:Gaussian NLLTest: 0.50047
INFO:root:CoverageTest: 0.69545
INFO:root:IntervalWidthTest: 0.38065
INFO:root:After validation: mem (CPU python)=34988.50390625MB; mem (CPU total)=58677.625MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=34988.50390625MB; mem (CPU total)=58687.28515625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 297795584
INFO:root:After setting up the model: mem (CPU python)=34988.50390625MB; mem (CPU total)=58687.28515625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=58698.8515625MB
INFO:root:[    1] Training loss: 0.84672186, Validation loss: 0.74906230, Gradient norm: 0.42380271
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=58735.47265625MB
INFO:root:[    2] Training loss: 0.74525055, Validation loss: 0.74300325, Gradient norm: 0.41173532
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=58770.89453125MB
INFO:root:[    3] Training loss: 0.73936288, Validation loss: 0.73348611, Gradient norm: 0.57895121
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=58807.06640625MB
INFO:root:[    4] Training loss: 0.72440945, Validation loss: 0.71110108, Gradient norm: 0.70079037
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=58846.6796875MB
INFO:root:[    5] Training loss: 0.69939964, Validation loss: 0.67310997, Gradient norm: 1.01734915
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=58887.50390625MB
INFO:root:[    6] Training loss: 0.65737455, Validation loss: 0.64047494, Gradient norm: 1.37416575
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=58922.42578125MB
INFO:root:[    7] Training loss: 0.62787506, Validation loss: 0.62617737, Gradient norm: 1.46775253
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=58958.1015625MB
INFO:root:[    8] Training loss: 0.61358700, Validation loss: 0.60615219, Gradient norm: 1.67343864
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=58995.24609375MB
INFO:root:[    9] Training loss: 0.60424217, Validation loss: 0.59174535, Gradient norm: 1.74448950
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=59037.59765625MB
INFO:root:[   10] Training loss: 0.59441279, Validation loss: 0.60162779, Gradient norm: 2.00827983
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=59073.48828125MB
INFO:root:[   11] Training loss: 0.58722525, Validation loss: 0.57214610, Gradient norm: 2.16021506
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=59109.8203125MB
INFO:root:[   12] Training loss: 0.58391345, Validation loss: 0.57520024, Gradient norm: 2.48919233
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=59145.72265625MB
INFO:root:[   13] Training loss: 0.57480316, Validation loss: 0.57303707, Gradient norm: 2.66179119
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=59185.8046875MB
INFO:root:[   14] Training loss: 0.57385746, Validation loss: 0.56910527, Gradient norm: 3.04592182
INFO:root:At the start of the epoch: mem (CPU python)=34988.50390625MB; mem (CPU total)=59224.93359375MB
INFO:root:[   15] Training loss: 0.56523277, Validation loss: 0.55269708, Gradient norm: 3.00384568
INFO:root:At the start of the epoch: mem (CPU python)=35005.8203125MB; mem (CPU total)=59260.35546875MB
INFO:root:[   16] Training loss: 0.56346228, Validation loss: 0.55245469, Gradient norm: 3.51575908
INFO:root:At the start of the epoch: mem (CPU python)=35026.984375MB; mem (CPU total)=59296.2578125MB
INFO:root:[   17] Training loss: 0.55810652, Validation loss: 0.57046551, Gradient norm: 3.46181803
INFO:root:At the start of the epoch: mem (CPU python)=35048.1484375MB; mem (CPU total)=59334.359375MB
INFO:root:[   18] Training loss: 0.55787967, Validation loss: 0.53764250, Gradient norm: 3.83768470
INFO:root:At the start of the epoch: mem (CPU python)=35069.3125MB; mem (CPU total)=59376.60546875MB
INFO:root:[   19] Training loss: 0.55382261, Validation loss: 0.54733481, Gradient norm: 3.95312711
INFO:root:At the start of the epoch: mem (CPU python)=35090.4765625MB; mem (CPU total)=59411.81640625MB
INFO:root:[   20] Training loss: 0.53893463, Validation loss: 0.55034322, Gradient norm: 3.68851297
INFO:root:At the start of the epoch: mem (CPU python)=35111.640625MB; mem (CPU total)=59448.66796875MB
INFO:root:[   21] Training loss: 0.53274000, Validation loss: 0.52336192, Gradient norm: 4.21672451
INFO:root:At the start of the epoch: mem (CPU python)=35132.80859375MB; mem (CPU total)=59485.0390625MB
INFO:root:[   22] Training loss: 0.52545090, Validation loss: 0.51514979, Gradient norm: 3.68139011
INFO:root:At the start of the epoch: mem (CPU python)=35153.97265625MB; mem (CPU total)=59526.12890625MB
INFO:root:[   23] Training loss: 0.52351637, Validation loss: 0.52072444, Gradient norm: 3.91154011
INFO:root:At the start of the epoch: mem (CPU python)=35175.13671875MB; mem (CPU total)=59564.77734375MB
INFO:root:[   24] Training loss: 0.53111865, Validation loss: 0.52319426, Gradient norm: 4.69103281
INFO:root:At the start of the epoch: mem (CPU python)=35196.30078125MB; mem (CPU total)=59600.5625MB
INFO:root:[   25] Training loss: 0.53456240, Validation loss: 0.52230289, Gradient norm: 4.33789549
INFO:root:At the start of the epoch: mem (CPU python)=35217.4609375MB; mem (CPU total)=59649.1484375MB
INFO:root:[   26] Training loss: 0.52261013, Validation loss: 0.52638922, Gradient norm: 3.99562043
INFO:root:At the start of the epoch: mem (CPU python)=35238.62890625MB; mem (CPU total)=59685.859375MB
INFO:root:[   27] Training loss: 0.52400091, Validation loss: 0.54939931, Gradient norm: 4.35267844
INFO:root:At the start of the epoch: mem (CPU python)=35259.79296875MB; mem (CPU total)=59728.37109375MB
INFO:root:[   28] Training loss: 0.52275235, Validation loss: 0.52056005, Gradient norm: 4.32884975
INFO:root:At the start of the epoch: mem (CPU python)=35280.95703125MB; mem (CPU total)=59762.84375MB
INFO:root:[   29] Training loss: 0.51882111, Validation loss: 0.50638346, Gradient norm: 4.11379726
INFO:root:At the start of the epoch: mem (CPU python)=35302.12109375MB; mem (CPU total)=59798.73046875MB
INFO:root:[   30] Training loss: 0.52160717, Validation loss: 0.53571202, Gradient norm: 4.89347886
INFO:root:At the start of the epoch: mem (CPU python)=35323.28515625MB; mem (CPU total)=59834.93359375MB
INFO:root:[   31] Training loss: 0.52473055, Validation loss: 0.53986357, Gradient norm: 4.53135086
INFO:root:At the start of the epoch: mem (CPU python)=35344.4453125MB; mem (CPU total)=59876.19921875MB
INFO:root:[   32] Training loss: 0.52269081, Validation loss: 0.51005324, Gradient norm: 4.52019205
INFO:root:At the start of the epoch: mem (CPU python)=35365.61328125MB; mem (CPU total)=59914.0546875MB
INFO:root:[   33] Training loss: 0.51660338, Validation loss: 0.54042072, Gradient norm: 4.42590294
INFO:root:At the start of the epoch: mem (CPU python)=35386.77734375MB; mem (CPU total)=59950.45703125MB
INFO:root:[   34] Training loss: 0.51591911, Validation loss: 0.55758441, Gradient norm: 4.16542671
INFO:root:At the start of the epoch: mem (CPU python)=35407.94140625MB; mem (CPU total)=59987.05078125MB
INFO:root:[   35] Training loss: 0.52341352, Validation loss: 0.53029776, Gradient norm: 5.29417366
INFO:root:At the start of the epoch: mem (CPU python)=35429.1015625MB; mem (CPU total)=60025.07421875MB
INFO:root:[   36] Training loss: 0.52320112, Validation loss: 0.52084177, Gradient norm: 4.64888042
INFO:root:At the start of the epoch: mem (CPU python)=35450.265625MB; mem (CPU total)=60067.62109375MB
INFO:root:[   37] Training loss: 0.51347192, Validation loss: 0.52195162, Gradient norm: 4.57448305
INFO:root:At the start of the epoch: mem (CPU python)=35471.43359375MB; mem (CPU total)=60102.25MB
INFO:root:[   38] Training loss: 0.51730909, Validation loss: 0.52462034, Gradient norm: 4.52090813
INFO:root:At the start of the epoch: mem (CPU python)=35492.59765625MB; mem (CPU total)=60138.71484375MB
INFO:root:[   39] Training loss: 0.51731306, Validation loss: 0.50935583, Gradient norm: 4.79605066
INFO:root:At the start of the epoch: mem (CPU python)=35513.76171875MB; mem (CPU total)=60174.890625MB
INFO:root:[   40] Training loss: 0.52127911, Validation loss: 0.51885024, Gradient norm: 4.48753214
INFO:root:At the start of the epoch: mem (CPU python)=35534.92578125MB; mem (CPU total)=60216.22265625MB
INFO:root:[   41] Training loss: 0.50746555, Validation loss: 0.49487153, Gradient norm: 4.46280496
INFO:root:At the start of the epoch: mem (CPU python)=35556.09375MB; mem (CPU total)=60253.859375MB
INFO:root:[   42] Training loss: 0.51574773, Validation loss: 0.51640920, Gradient norm: 5.05312307
INFO:root:At the start of the epoch: mem (CPU python)=35577.25390625MB; mem (CPU total)=60290.03515625MB
INFO:root:[   43] Training loss: 0.51691461, Validation loss: 0.51220595, Gradient norm: 4.92745362
INFO:root:At the start of the epoch: mem (CPU python)=35598.421875MB; mem (CPU total)=60325.96484375MB
INFO:root:[   44] Training loss: 0.51110533, Validation loss: 0.52608433, Gradient norm: 4.51327267
INFO:root:At the start of the epoch: mem (CPU python)=35619.58203125MB; mem (CPU total)=60364.09765625MB
INFO:root:[   45] Training loss: 0.51669374, Validation loss: 0.50324514, Gradient norm: 5.03435991
INFO:root:At the start of the epoch: mem (CPU python)=35640.74609375MB; mem (CPU total)=60406.87109375MB
INFO:root:[   46] Training loss: 0.50595344, Validation loss: 0.50181351, Gradient norm: 4.85448909
INFO:root:At the start of the epoch: mem (CPU python)=35661.91015625MB; mem (CPU total)=60441.98046875MB
INFO:root:[   47] Training loss: 0.51167201, Validation loss: 0.48800787, Gradient norm: 4.80445809
INFO:root:At the start of the epoch: mem (CPU python)=35683.078125MB; mem (CPU total)=60478.40234375MB
INFO:root:[   48] Training loss: 0.50858886, Validation loss: 0.48843478, Gradient norm: 5.03106695
INFO:root:At the start of the epoch: mem (CPU python)=35704.234375MB; mem (CPU total)=60514.5859375MB
INFO:root:[   49] Training loss: 0.51317173, Validation loss: 0.51174035, Gradient norm: 5.17007408
INFO:root:At the start of the epoch: mem (CPU python)=35725.40234375MB; mem (CPU total)=60555.43359375MB
INFO:root:[   50] Training loss: 0.50860767, Validation loss: 0.52203880, Gradient norm: 4.91438581
INFO:root:At the start of the epoch: mem (CPU python)=35746.56640625MB; mem (CPU total)=60594.53515625MB
INFO:root:[   51] Training loss: 0.50820313, Validation loss: 0.51146913, Gradient norm: 5.79412261
INFO:root:At the start of the epoch: mem (CPU python)=35767.73046875MB; mem (CPU total)=60629.99609375MB
INFO:root:[   52] Training loss: 0.50626168, Validation loss: 0.48848425, Gradient norm: 5.20435430
INFO:root:At the start of the epoch: mem (CPU python)=35788.89453125MB; mem (CPU total)=60666.09765625MB
INFO:root:[   53] Training loss: 0.50628065, Validation loss: 0.52454690, Gradient norm: 5.47151284
INFO:root:At the start of the epoch: mem (CPU python)=35810.0625MB; mem (CPU total)=60703.2734375MB
INFO:root:[   54] Training loss: 0.50661359, Validation loss: 0.49591970, Gradient norm: 5.67019802
INFO:root:At the start of the epoch: mem (CPU python)=35831.2265625MB; mem (CPU total)=60745.84765625MB
INFO:root:[   55] Training loss: 0.50397857, Validation loss: 0.48990199, Gradient norm: 5.25899511
INFO:root:At the start of the epoch: mem (CPU python)=35852.390625MB; mem (CPU total)=60781.28515625MB
INFO:root:[   56] Training loss: 0.50122210, Validation loss: 0.49869030, Gradient norm: 5.67430727
INFO:root:At the start of the epoch: mem (CPU python)=35873.5546875MB; mem (CPU total)=60817.47265625MB
INFO:root:[   57] Training loss: 0.50793660, Validation loss: 0.48651269, Gradient norm: 5.83132412
INFO:root:At the start of the epoch: mem (CPU python)=35894.71875MB; mem (CPU total)=60853.859375MB
INFO:root:[   58] Training loss: 0.49965718, Validation loss: 0.52003037, Gradient norm: 5.68058492
INFO:root:At the start of the epoch: mem (CPU python)=35915.8828125MB; mem (CPU total)=60894.21875MB
INFO:root:[   59] Training loss: 0.50434894, Validation loss: 0.49299535, Gradient norm: 5.88491921
INFO:root:At the start of the epoch: mem (CPU python)=35937.05078125MB; mem (CPU total)=60934.0703125MB
INFO:root:[   60] Training loss: 0.50205042, Validation loss: 0.52499821, Gradient norm: 5.76842582
INFO:root:At the start of the epoch: mem (CPU python)=35958.21875MB; mem (CPU total)=60969.2265625MB
INFO:root:[   61] Training loss: 0.51108477, Validation loss: 0.50607530, Gradient norm: 5.94788464
INFO:root:At the start of the epoch: mem (CPU python)=35979.3828125MB; mem (CPU total)=61005.640625MB
INFO:root:[   62] Training loss: 0.49891208, Validation loss: 0.50545938, Gradient norm: 5.74378503
INFO:root:At the start of the epoch: mem (CPU python)=36000.546875MB; mem (CPU total)=61042.796875MB
INFO:root:[   63] Training loss: 0.51101619, Validation loss: 0.50067966, Gradient norm: 6.02789969
INFO:root:At the start of the epoch: mem (CPU python)=36021.70703125MB; mem (CPU total)=61085.109375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   64] Training loss: 0.50905471, Validation loss: 0.51388655, Gradient norm: 5.93715035
INFO:root:At the start of the epoch: mem (CPU python)=36042.87109375MB; mem (CPU total)=61121.0390625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   65] Training loss: 0.47116913, Validation loss: 0.46643928, Gradient norm: 4.71734752
INFO:root:At the start of the epoch: mem (CPU python)=36064.0390625MB; mem (CPU total)=61156.86328125MB
INFO:root:[   66] Training loss: 0.45846588, Validation loss: 0.46349105, Gradient norm: 3.37255840
INFO:root:At the start of the epoch: mem (CPU python)=36085.1953125MB; mem (CPU total)=61193.3359375MB
INFO:root:[   67] Training loss: 0.45779199, Validation loss: 0.46363206, Gradient norm: 4.23269285
INFO:root:At the start of the epoch: mem (CPU python)=36106.359375MB; mem (CPU total)=61233.02734375MB
INFO:root:[   68] Training loss: 0.45810932, Validation loss: 0.46127164, Gradient norm: 4.98881354
INFO:root:At the start of the epoch: mem (CPU python)=36127.5234375MB; mem (CPU total)=61274.84765625MB
INFO:root:[   69] Training loss: 0.46404983, Validation loss: 0.45921081, Gradient norm: 7.19627351
INFO:root:At the start of the epoch: mem (CPU python)=36148.6875MB; mem (CPU total)=61309.5859375MB
INFO:root:[   70] Training loss: 0.46526152, Validation loss: 0.45951259, Gradient norm: 7.41978140
INFO:root:At the start of the epoch: mem (CPU python)=36169.8515625MB; mem (CPU total)=61346.2421875MB
INFO:root:[   71] Training loss: 0.46109294, Validation loss: 0.45815084, Gradient norm: 6.45194225
INFO:root:At the start of the epoch: mem (CPU python)=36191.01953125MB; mem (CPU total)=61383.57421875MB
INFO:root:[   72] Training loss: 0.45986253, Validation loss: 0.46359584, Gradient norm: 6.67735158
INFO:root:At the start of the epoch: mem (CPU python)=36212.1796875MB; mem (CPU total)=61425.375MB
INFO:root:[   73] Training loss: 0.45981020, Validation loss: 0.46347859, Gradient norm: 7.34375086
INFO:root:At the start of the epoch: mem (CPU python)=36233.34375MB; mem (CPU total)=61463.02734375MB
INFO:root:[   74] Training loss: 0.46125853, Validation loss: 0.46116640, Gradient norm: 8.03480810
INFO:root:At the start of the epoch: mem (CPU python)=36254.5078125MB; mem (CPU total)=61499.70703125MB
INFO:root:[   75] Training loss: 0.46067726, Validation loss: 0.46324965, Gradient norm: 8.22237325
INFO:root:At the start of the epoch: mem (CPU python)=36275.671875MB; mem (CPU total)=61535.63671875MB
INFO:root:[   76] Training loss: 0.46077356, Validation loss: 0.46087141, Gradient norm: 8.49998221
INFO:root:At the start of the epoch: mem (CPU python)=36296.8359375MB; mem (CPU total)=61573.75390625MB
INFO:root:[   77] Training loss: 0.46390507, Validation loss: 0.46056675, Gradient norm: 9.30123133
INFO:root:At the start of the epoch: mem (CPU python)=36318.00390625MB; mem (CPU total)=61616.01171875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   78] Training loss: 0.46226738, Validation loss: 0.46126805, Gradient norm: 9.56480532
INFO:root:At the start of the epoch: mem (CPU python)=36339.16796875MB; mem (CPU total)=61651.93359375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   79] Training loss: 0.45513431, Validation loss: 0.45468087, Gradient norm: 6.84391861
INFO:root:At the start of the epoch: mem (CPU python)=36360.33203125MB; mem (CPU total)=61687.85546875MB
INFO:root:[   80] Training loss: 0.45194854, Validation loss: 0.45369356, Gradient norm: 4.69485198
INFO:root:At the start of the epoch: mem (CPU python)=36381.49609375MB; mem (CPU total)=61724.5234375MB
INFO:root:[   81] Training loss: 0.45059622, Validation loss: 0.45564526, Gradient norm: 5.23054898
INFO:root:At the start of the epoch: mem (CPU python)=36402.66015625MB; mem (CPU total)=61764.6328125MB
INFO:root:[   82] Training loss: 0.45142362, Validation loss: 0.45190511, Gradient norm: 6.95399290
INFO:root:At the start of the epoch: mem (CPU python)=36423.82421875MB; mem (CPU total)=61805.21875MB
INFO:root:[   83] Training loss: 0.45156650, Validation loss: 0.45402799, Gradient norm: 6.14826670
INFO:root:At the start of the epoch: mem (CPU python)=36444.98046875MB; mem (CPU total)=61840.1875MB
INFO:root:[   84] Training loss: 0.45129042, Validation loss: 0.45280208, Gradient norm: 6.69820593
INFO:root:At the start of the epoch: mem (CPU python)=36466.1484375MB; mem (CPU total)=61876.61328125MB
INFO:root:[   85] Training loss: 0.45134484, Validation loss: 0.45472802, Gradient norm: 6.85680881
INFO:root:At the start of the epoch: mem (CPU python)=36487.3125MB; mem (CPU total)=61913.265625MB
INFO:root:[   86] Training loss: 0.45186854, Validation loss: 0.45548172, Gradient norm: 7.94796160
INFO:root:At the start of the epoch: mem (CPU python)=36508.4765625MB; mem (CPU total)=61955.0546875MB
INFO:root:[   87] Training loss: 0.45154540, Validation loss: 0.45443700, Gradient norm: 8.35788862
INFO:root:At the start of the epoch: mem (CPU python)=36529.640625MB; mem (CPU total)=61992.6953125MB
INFO:root:[   88] Training loss: 0.45170399, Validation loss: 0.45505772, Gradient norm: 8.52887356
INFO:root:At the start of the epoch: mem (CPU python)=36550.80859375MB; mem (CPU total)=62028.61328125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   89] Training loss: 0.45176798, Validation loss: 0.45609368, Gradient norm: 9.52455050
INFO:root:At the start of the epoch: mem (CPU python)=36571.97265625MB; mem (CPU total)=62064.671875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   90] Training loss: 0.45050098, Validation loss: 0.45208189, Gradient norm: 7.82766779
INFO:root:At the start of the epoch: mem (CPU python)=36593.13671875MB; mem (CPU total)=62102.58984375MB
INFO:root:[   91] Training loss: 0.44932338, Validation loss: 0.45033561, Gradient norm: 4.71923428
INFO:root:At the start of the epoch: mem (CPU python)=36614.296875MB; mem (CPU total)=62145.96875MB
INFO:root:[   92] Training loss: 0.44968580, Validation loss: 0.45240063, Gradient norm: 5.30907247
INFO:root:At the start of the epoch: mem (CPU python)=36635.4609375MB; mem (CPU total)=62182.61328125MB
INFO:root:[   93] Training loss: 0.44938931, Validation loss: 0.45102569, Gradient norm: 4.97331830
INFO:root:At the start of the epoch: mem (CPU python)=36656.625MB; mem (CPU total)=62218.7265625MB
INFO:root:[   94] Training loss: 0.44971512, Validation loss: 0.45249415, Gradient norm: 5.47184312
INFO:root:At the start of the epoch: mem (CPU python)=36677.79296875MB; mem (CPU total)=62255.1484375MB
INFO:root:[   95] Training loss: 0.44948190, Validation loss: 0.45129646, Gradient norm: 5.57471864
INFO:root:At the start of the epoch: mem (CPU python)=36698.95703125MB; mem (CPU total)=62294.51953125MB
INFO:root:[   96] Training loss: 0.44953565, Validation loss: 0.45175418, Gradient norm: 6.31253420
INFO:root:At the start of the epoch: mem (CPU python)=36720.125MB; mem (CPU total)=62336.50390625MB
INFO:root:[   97] Training loss: 0.44940763, Validation loss: 0.45268278, Gradient norm: 5.89567664
INFO:root:At the start of the epoch: mem (CPU python)=36741.2890625MB; mem (CPU total)=62370.7109375MB
INFO:root:[   98] Training loss: 0.44934463, Validation loss: 0.45141391, Gradient norm: 7.10141459
INFO:root:At the start of the epoch: mem (CPU python)=36762.453125MB; mem (CPU total)=62407.39453125MB
INFO:root:[   99] Training loss: 0.44942105, Validation loss: 0.45200113, Gradient norm: 6.20391057
INFO:root:At the start of the epoch: mem (CPU python)=36783.6171875MB; mem (CPU total)=62443.24609375MB
INFO:root:[  100] Training loss: 0.44942397, Validation loss: 0.45107237, Gradient norm: 6.67258580
INFO:root:At the start of the epoch: mem (CPU python)=36804.78125MB; mem (CPU total)=62484.08203125MB
INFO:root:EP 100: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=36825.94140625MB; mem (CPU total)=62523.4375MB
INFO:root:[  102] Training loss: 0.53541557, Validation loss: 0.53577519, Gradient norm: 7.80283864
INFO:root:At the start of the epoch: mem (CPU python)=36847.10546875MB; mem (CPU total)=62565.1875MB
INFO:root:[  103] Training loss: 0.53318009, Validation loss: 0.53406773, Gradient norm: 7.85317692
INFO:root:At the start of the epoch: mem (CPU python)=36868.26953125MB; mem (CPU total)=62606.50390625MB
INFO:root:[  104] Training loss: 0.53293532, Validation loss: 0.53342581, Gradient norm: 8.51611084
INFO:root:At the start of the epoch: mem (CPU python)=36889.43359375MB; mem (CPU total)=62648.64453125MB
INFO:root:[  105] Training loss: 0.53196004, Validation loss: 0.53305729, Gradient norm: 8.00739016
INFO:root:At the start of the epoch: mem (CPU python)=36910.6015625MB; mem (CPU total)=62690.703125MB
INFO:root:[  106] Training loss: 0.53187998, Validation loss: 0.53388572, Gradient norm: 8.22422381
INFO:root:At the start of the epoch: mem (CPU python)=36931.765625MB; mem (CPU total)=62717.890625MB
INFO:root:[  107] Training loss: 0.53160721, Validation loss: 0.53330531, Gradient norm: 8.20173631
INFO:root:At the start of the epoch: mem (CPU python)=36952.9296875MB; mem (CPU total)=62740.76171875MB
INFO:root:[  108] Training loss: 0.53100075, Validation loss: 0.53276978, Gradient norm: 8.00101558
INFO:root:At the start of the epoch: mem (CPU python)=36974.09375MB; mem (CPU total)=62763.90625MB
INFO:root:[  109] Training loss: 0.53141275, Validation loss: 0.53390977, Gradient norm: 8.83024967
INFO:root:At the start of the epoch: mem (CPU python)=36995.2578125MB; mem (CPU total)=62785.6796875MB
INFO:root:[  110] Training loss: 0.53134589, Validation loss: 0.53294201, Gradient norm: 8.92673026
INFO:root:At the start of the epoch: mem (CPU python)=37016.41796875MB; mem (CPU total)=62836.44921875MB
INFO:root:[  111] Training loss: 0.53134145, Validation loss: 0.53415629, Gradient norm: 8.48751674
INFO:root:At the start of the epoch: mem (CPU python)=37037.5859375MB; mem (CPU total)=62878.78515625MB
INFO:root:[  112] Training loss: 0.53131881, Validation loss: 0.53287880, Gradient norm: 9.05072394
INFO:root:At the start of the epoch: mem (CPU python)=37058.75MB; mem (CPU total)=62921.5078125MB
INFO:root:[  113] Training loss: 0.53088387, Validation loss: 0.53261124, Gradient norm: 9.95018900
INFO:root:At the start of the epoch: mem (CPU python)=37079.9140625MB; mem (CPU total)=62963.8671875MB
INFO:root:[  114] Training loss: 0.53117589, Validation loss: 0.53180787, Gradient norm: 8.37972745
INFO:root:At the start of the epoch: mem (CPU python)=37101.078125MB; mem (CPU total)=63006.2109375MB
INFO:root:[  115] Training loss: 0.53083008, Validation loss: 0.53178322, Gradient norm: 9.00562583
INFO:root:At the start of the epoch: mem (CPU python)=37122.24609375MB; mem (CPU total)=63048.49609375MB
INFO:root:[  116] Training loss: 0.53110887, Validation loss: 0.53246196, Gradient norm: 9.97965552
INFO:root:At the start of the epoch: mem (CPU python)=37143.40234375MB; mem (CPU total)=63091.23828125MB
INFO:root:[  117] Training loss: 0.53070037, Validation loss: 0.53174205, Gradient norm: 9.69517604
INFO:root:At the start of the epoch: mem (CPU python)=37164.5703125MB; mem (CPU total)=63133.4765625MB
INFO:root:[  118] Training loss: 0.53065042, Validation loss: 0.53161078, Gradient norm: 9.37604947
INFO:root:At the start of the epoch: mem (CPU python)=37185.734375MB; mem (CPU total)=63176.046875MB
INFO:root:[  119] Training loss: 0.53062014, Validation loss: 0.53301711, Gradient norm: 10.18185836
INFO:root:At the start of the epoch: mem (CPU python)=37206.89453125MB; mem (CPU total)=63218.08984375MB
INFO:root:[  120] Training loss: 0.53097442, Validation loss: 0.53178062, Gradient norm: 10.34803073
INFO:root:At the start of the epoch: mem (CPU python)=37228.05859375MB; mem (CPU total)=63259.69140625MB
INFO:root:[  121] Training loss: 0.53032580, Validation loss: 0.53218921, Gradient norm: 10.30034952
INFO:root:At the start of the epoch: mem (CPU python)=37249.2265625MB; mem (CPU total)=63302.234375MB
INFO:root:[  122] Training loss: 0.53051467, Validation loss: 0.53216666, Gradient norm: 10.13230397
INFO:root:At the start of the epoch: mem (CPU python)=37270.390625MB; mem (CPU total)=63343.79296875MB
INFO:root:[  123] Training loss: 0.53055170, Validation loss: 0.53285441, Gradient norm: 10.36633924
INFO:root:At the start of the epoch: mem (CPU python)=37291.5546875MB; mem (CPU total)=63384.91015625MB
INFO:root:[  124] Training loss: 0.53060356, Validation loss: 0.53388171, Gradient norm: 9.97732704
INFO:root:At the start of the epoch: mem (CPU python)=37312.71875MB; mem (CPU total)=63425.74609375MB
INFO:root:[  125] Training loss: 0.53065804, Validation loss: 0.53149968, Gradient norm: 10.57307423
INFO:root:At the start of the epoch: mem (CPU python)=37333.8828125MB; mem (CPU total)=63468.4375MB
INFO:root:[  126] Training loss: 0.53056332, Validation loss: 0.53187790, Gradient norm: 11.31926046
INFO:root:At the start of the epoch: mem (CPU python)=37355.046875MB; mem (CPU total)=63510.7109375MB
INFO:root:[  127] Training loss: 0.53039459, Validation loss: 0.53244491, Gradient norm: 10.98413847
INFO:root:At the start of the epoch: mem (CPU python)=37376.21484375MB; mem (CPU total)=63552.359375MB
INFO:root:[  128] Training loss: 0.53074552, Validation loss: 0.53161645, Gradient norm: 11.36731369
INFO:root:At the start of the epoch: mem (CPU python)=37397.37890625MB; mem (CPU total)=63593.9375MB
INFO:root:[  129] Training loss: 0.53064106, Validation loss: 0.53317858, Gradient norm: 10.90858527
INFO:root:At the start of the epoch: mem (CPU python)=37418.5390625MB; mem (CPU total)=63635.703125MB
INFO:root:[  130] Training loss: 0.53035417, Validation loss: 0.53168929, Gradient norm: 11.31565300
INFO:root:At the start of the epoch: mem (CPU python)=37439.703125MB; mem (CPU total)=63677.5234375MB
INFO:root:[  131] Training loss: 0.53031979, Validation loss: 0.53334684, Gradient norm: 11.43279960
INFO:root:At the start of the epoch: mem (CPU python)=37460.8671875MB; mem (CPU total)=63719.5625MB
INFO:root:[  132] Training loss: 0.53046479, Validation loss: 0.53265149, Gradient norm: 12.33687463
INFO:root:At the start of the epoch: mem (CPU python)=37482.03125MB; mem (CPU total)=63762.13671875MB
INFO:root:[  133] Training loss: 0.53035326, Validation loss: 0.53180987, Gradient norm: 11.66713947
INFO:root:At the start of the epoch: mem (CPU python)=37503.1953125MB; mem (CPU total)=63804.2109375MB
INFO:root:[  134] Training loss: 0.53017298, Validation loss: 0.53195050, Gradient norm: 11.50333452
INFO:root:At the start of the epoch: mem (CPU python)=37524.359375MB; mem (CPU total)=63846.25MB
INFO:root:EP 134: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=37545.5234375MB; mem (CPU total)=63875.52734375MB
INFO:root:Training the model took 7964.007s.
INFO:root:Emptying the cuda cache took 0.064s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.54211
INFO:root:EnergyScoreValidation: 0.43907
INFO:root:CRPSValidation: 0.17623
INFO:root:Gaussian NLLValidation: 1.8797
INFO:root:CoverageValidation: 0.58436
INFO:root:IntervalWidthValidation: 0.40199
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.43062
INFO:root:EnergyScoreTest: 0.33219
INFO:root:CRPSTest: 0.13198
INFO:root:Gaussian NLLTest: 0.45037
INFO:root:CoverageTest: 0.72012
INFO:root:IntervalWidthTest: 0.42495
INFO:root:After validation: mem (CPU python)=37852.23828125MB; mem (CPU total)=63960.4375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=37852.23828125MB; mem (CPU total)=63970.3203125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 297795584
INFO:root:After setting up the model: mem (CPU python)=37852.23828125MB; mem (CPU total)=63970.3203125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=63979.953125MB
INFO:root:[    1] Training loss: 0.85787321, Validation loss: 0.75659861, Gradient norm: 0.37741049
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64016.5234375MB
INFO:root:[    2] Training loss: 0.75235226, Validation loss: 0.75787624, Gradient norm: 0.45198647
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64055.390625MB
INFO:root:[    3] Training loss: 0.74820329, Validation loss: 0.74128211, Gradient norm: 0.67774036
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64097.05078125MB
INFO:root:[    4] Training loss: 0.73563716, Validation loss: 0.74671809, Gradient norm: 0.91465665
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64133.01953125MB
INFO:root:[    5] Training loss: 0.73213889, Validation loss: 0.73287926, Gradient norm: 1.19943830
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64168.9375MB
INFO:root:[    6] Training loss: 0.71019111, Validation loss: 0.69103910, Gradient norm: 1.50597319
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64215.91796875MB
INFO:root:[    7] Training loss: 0.68295555, Validation loss: 0.67879177, Gradient norm: 1.88972547
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64256.02734375MB
INFO:root:[    8] Training loss: 0.66669385, Validation loss: 0.67313253, Gradient norm: 2.16695024
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64459.61328125MB
INFO:root:[    9] Training loss: 0.65266512, Validation loss: 0.66083837, Gradient norm: 2.51791419
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64341.859375MB
INFO:root:[   10] Training loss: 0.64526523, Validation loss: 0.62807031, Gradient norm: 2.61998965
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64374.0390625MB
INFO:root:[   11] Training loss: 0.63745692, Validation loss: 0.63477571, Gradient norm: 2.92737929
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64410.12890625MB
INFO:root:[   12] Training loss: 0.63247349, Validation loss: 0.63991056, Gradient norm: 3.16482314
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64449.28125MB
INFO:root:[   13] Training loss: 0.62233415, Validation loss: 0.61699552, Gradient norm: 3.26633613
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64490.1171875MB
INFO:root:[   14] Training loss: 0.61212903, Validation loss: 0.60983353, Gradient norm: 3.47151277
INFO:root:At the start of the epoch: mem (CPU python)=37852.23828125MB; mem (CPU total)=64525.546875MB
INFO:root:[   15] Training loss: 0.61247832, Validation loss: 0.60034718, Gradient norm: 3.80011482
INFO:root:At the start of the epoch: mem (CPU python)=37869.7578125MB; mem (CPU total)=64561.3671875MB
INFO:root:[   16] Training loss: 0.60725671, Validation loss: 0.60540594, Gradient norm: 4.04169185
INFO:root:At the start of the epoch: mem (CPU python)=37890.9140625MB; mem (CPU total)=64596.5390625MB
INFO:root:[   17] Training loss: 0.60401644, Validation loss: 0.64350642, Gradient norm: 4.00913034
INFO:root:At the start of the epoch: mem (CPU python)=37912.08203125MB; mem (CPU total)=64638.27734375MB
INFO:root:[   18] Training loss: 0.60328019, Validation loss: 0.61250017, Gradient norm: 4.20453185
INFO:root:At the start of the epoch: mem (CPU python)=37933.24609375MB; mem (CPU total)=64677.140625MB
INFO:root:[   19] Training loss: 0.60091372, Validation loss: 0.59707843, Gradient norm: 4.21477616
INFO:root:At the start of the epoch: mem (CPU python)=37954.41015625MB; mem (CPU total)=64713.2734375MB
INFO:root:[   20] Training loss: 0.59440708, Validation loss: 0.62856569, Gradient norm: 4.17520452
INFO:root:At the start of the epoch: mem (CPU python)=37975.57421875MB; mem (CPU total)=64749.84765625MB
INFO:root:[   21] Training loss: 0.60346285, Validation loss: 0.58954986, Gradient norm: 4.63170698
INFO:root:At the start of the epoch: mem (CPU python)=37996.7421875MB; mem (CPU total)=64786.7265625MB
INFO:root:[   22] Training loss: 0.59452437, Validation loss: 0.58007306, Gradient norm: 4.50590962
INFO:root:At the start of the epoch: mem (CPU python)=38017.90234375MB; mem (CPU total)=64830.74609375MB
INFO:root:[   23] Training loss: 0.59060428, Validation loss: 0.59157755, Gradient norm: 4.63945721
INFO:root:At the start of the epoch: mem (CPU python)=38039.06640625MB; mem (CPU total)=64870.6640625MB
INFO:root:[   24] Training loss: 0.59028815, Validation loss: 0.57972585, Gradient norm: 4.83849169
INFO:root:At the start of the epoch: mem (CPU python)=38060.23046875MB; mem (CPU total)=64906.6953125MB
INFO:root:[   25] Training loss: 0.58881935, Validation loss: 0.58224689, Gradient norm: 5.13021957
INFO:root:At the start of the epoch: mem (CPU python)=38081.39453125MB; mem (CPU total)=64942.8359375MB
INFO:root:[   26] Training loss: 0.59627529, Validation loss: 0.60367086, Gradient norm: 5.66695768
INFO:root:At the start of the epoch: mem (CPU python)=38102.55859375MB; mem (CPU total)=64981.71875MB
INFO:root:[   27] Training loss: 0.59150071, Validation loss: 0.59535731, Gradient norm: 5.77157123
INFO:root:At the start of the epoch: mem (CPU python)=38123.72265625MB; mem (CPU total)=65026.57421875MB
INFO:root:[   28] Training loss: 0.60039599, Validation loss: 0.57626632, Gradient norm: 6.11610708
INFO:root:At the start of the epoch: mem (CPU python)=38144.890625MB; mem (CPU total)=65061.17578125MB
INFO:root:[   29] Training loss: 0.59394953, Validation loss: 0.58571972, Gradient norm: 5.45558191
INFO:root:At the start of the epoch: mem (CPU python)=38166.0546875MB; mem (CPU total)=65097.3515625MB
INFO:root:[   30] Training loss: 0.59550551, Validation loss: 0.62192814, Gradient norm: 6.01783907
INFO:root:At the start of the epoch: mem (CPU python)=38187.21875MB; mem (CPU total)=65133.9921875MB
INFO:root:[   31] Training loss: 0.58990868, Validation loss: 0.61976192, Gradient norm: 5.73771850
INFO:root:At the start of the epoch: mem (CPU python)=38208.37890625MB; mem (CPU total)=65171.64453125MB
INFO:root:[   32] Training loss: 0.59974736, Validation loss: 0.58980461, Gradient norm: 6.69562527
INFO:root:At the start of the epoch: mem (CPU python)=38229.54296875MB; mem (CPU total)=65213.52734375MB
INFO:root:[   33] Training loss: 0.59143865, Validation loss: 0.59218824, Gradient norm: 6.22828479
INFO:root:At the start of the epoch: mem (CPU python)=38250.70703125MB; mem (CPU total)=65248.71484375MB
INFO:root:[   34] Training loss: 0.59665939, Validation loss: 0.57925986, Gradient norm: 6.47816213
INFO:root:At the start of the epoch: mem (CPU python)=38271.875MB; mem (CPU total)=65285.16796875MB
INFO:root:[   35] Training loss: 0.58862647, Validation loss: 0.60205654, Gradient norm: 6.27893712
INFO:root:At the start of the epoch: mem (CPU python)=38293.0390625MB; mem (CPU total)=65321.88671875MB
INFO:root:[   36] Training loss: 0.58960867, Validation loss: 0.58839634, Gradient norm: 6.40481101
INFO:root:At the start of the epoch: mem (CPU python)=38314.203125MB; mem (CPU total)=65361.53125MB
INFO:root:[   37] Training loss: 0.58810893, Validation loss: 0.58373796, Gradient norm: 6.55388591
INFO:root:At the start of the epoch: mem (CPU python)=38335.37109375MB; mem (CPU total)=65637.80859375MB
INFO:root:[   38] Training loss: 0.59936467, Validation loss: 0.58936888, Gradient norm: 7.48973163
INFO:root:At the start of the epoch: mem (CPU python)=38356.53515625MB; mem (CPU total)=65440.21484375MB
INFO:root:[   39] Training loss: 0.59413785, Validation loss: 0.58176039, Gradient norm: 7.03150209
INFO:root:At the start of the epoch: mem (CPU python)=38377.69921875MB; mem (CPU total)=65476.14453125MB
INFO:root:[   40] Training loss: 0.59650412, Validation loss: 0.59910398, Gradient norm: 7.12467854
INFO:root:At the start of the epoch: mem (CPU python)=38398.859375MB; mem (CPU total)=65511.83203125MB
INFO:root:[   41] Training loss: 0.58898895, Validation loss: 0.59160218, Gradient norm: 7.25440078
INFO:root:At the start of the epoch: mem (CPU python)=38420.0234375MB; mem (CPU total)=65552.22265625MB
INFO:root:[   42] Training loss: 0.58885755, Validation loss: 0.58225678, Gradient norm: 6.70233576
INFO:root:At the start of the epoch: mem (CPU python)=38441.1875MB; mem (CPU total)=66052.9296875MB
INFO:root:[   43] Training loss: 0.58855999, Validation loss: 0.58216054, Gradient norm: 7.20968098
INFO:root:At the start of the epoch: mem (CPU python)=38462.35546875MB; mem (CPU total)=66392.12109375MB
INFO:root:[   44] Training loss: 0.59830646, Validation loss: 0.60678104, Gradient norm: 8.38340929
INFO:root:At the start of the epoch: mem (CPU python)=38483.51953125MB; mem (CPU total)=66467.015625MB
INFO:root:[   45] Training loss: 0.59906334, Validation loss: 0.59691647, Gradient norm: 8.13261481
INFO:root:At the start of the epoch: mem (CPU python)=38504.68359375MB; mem (CPU total)=65676.73828125MB
INFO:root:[   46] Training loss: 0.59359925, Validation loss: 0.58115995, Gradient norm: 7.76192966
INFO:root:At the start of the epoch: mem (CPU python)=38525.84765625MB; mem (CPU total)=65713.62890625MB
INFO:root:[   47] Training loss: 0.60309559, Validation loss: 0.67017473, Gradient norm: 7.97863957
INFO:root:At the start of the epoch: mem (CPU python)=38547.01171875MB; mem (CPU total)=65752.71484375MB
INFO:root:[   48] Training loss: 0.59576426, Validation loss: 0.57478279, Gradient norm: 7.56575412
INFO:root:At the start of the epoch: mem (CPU python)=38568.1796875MB; mem (CPU total)=65787.70703125MB
INFO:root:[   49] Training loss: 0.59151356, Validation loss: 0.61431768, Gradient norm: 8.18204752
INFO:root:At the start of the epoch: mem (CPU python)=38589.33984375MB; mem (CPU total)=65824.64453125MB
INFO:root:[   50] Training loss: 0.60028116, Validation loss: 0.59697201, Gradient norm: 8.46335729
INFO:root:At the start of the epoch: mem (CPU python)=38610.5MB; mem (CPU total)=65861.1328125MB
INFO:root:[   51] Training loss: 0.59081994, Validation loss: 0.64903456, Gradient norm: 7.70022951
INFO:root:At the start of the epoch: mem (CPU python)=38631.6640625MB; mem (CPU total)=65902.96875MB
INFO:root:[   52] Training loss: 0.59744211, Validation loss: 0.57876577, Gradient norm: 8.38969885
INFO:root:At the start of the epoch: mem (CPU python)=38652.828125MB; mem (CPU total)=65941.25390625MB
INFO:root:[   53] Training loss: 0.60814360, Validation loss: 0.58527471, Gradient norm: 8.94114822
INFO:root:At the start of the epoch: mem (CPU python)=38673.99609375MB; mem (CPU total)=65977.7265625MB
INFO:root:[   54] Training loss: 0.59776988, Validation loss: 0.58281454, Gradient norm: 8.38388926
INFO:root:At the start of the epoch: mem (CPU python)=38695.1640625MB; mem (CPU total)=66014.765625MB
INFO:root:[   55] Training loss: 0.59245509, Validation loss: 0.57442990, Gradient norm: 7.83007273
INFO:root:At the start of the epoch: mem (CPU python)=38716.328125MB; mem (CPU total)=66054.875MB
INFO:root:[   56] Training loss: 0.59419347, Validation loss: 0.58878348, Gradient norm: 8.64180540
INFO:root:At the start of the epoch: mem (CPU python)=38737.4921875MB; mem (CPU total)=66094.53515625MB
INFO:root:[   57] Training loss: 0.59343122, Validation loss: 0.59447949, Gradient norm: 9.06653950
INFO:root:At the start of the epoch: mem (CPU python)=38758.65625MB; mem (CPU total)=66131.4453125MB
INFO:root:[   58] Training loss: 0.59806146, Validation loss: 0.57475731, Gradient norm: 9.11644346
INFO:root:At the start of the epoch: mem (CPU python)=38779.8203125MB; mem (CPU total)=66425.98828125MB
INFO:root:[   59] Training loss: 0.58681061, Validation loss: 0.56976934, Gradient norm: 8.63941537
INFO:root:At the start of the epoch: mem (CPU python)=38800.98046875MB; mem (CPU total)=67039.0234375MB
INFO:root:[   60] Training loss: 0.58811916, Validation loss: 0.57358017, Gradient norm: 9.76254502
INFO:root:At the start of the epoch: mem (CPU python)=38822.14453125MB; mem (CPU total)=66257.85546875MB
INFO:root:[   61] Training loss: 0.60203000, Validation loss: 0.57464920, Gradient norm: 10.43767335
INFO:root:At the start of the epoch: mem (CPU python)=38843.3125MB; mem (CPU total)=66852.4921875MB
INFO:root:[   62] Training loss: 0.59862900, Validation loss: 0.61780897, Gradient norm: 10.09862834
INFO:root:At the start of the epoch: mem (CPU python)=38864.4765625MB; mem (CPU total)=67064.46484375MB
INFO:root:[   63] Training loss: 0.61375095, Validation loss: 0.60842214, Gradient norm: 9.96924487
INFO:root:At the start of the epoch: mem (CPU python)=38885.640625MB; mem (CPU total)=66357.06640625MB
INFO:root:[   64] Training loss: 0.59657590, Validation loss: 0.59532942, Gradient norm: 9.29530054
INFO:root:At the start of the epoch: mem (CPU python)=38906.8046875MB; mem (CPU total)=66393.66015625MB
INFO:root:[   65] Training loss: 0.60413466, Validation loss: 0.61489283, Gradient norm: 9.58679418
INFO:root:At the start of the epoch: mem (CPU python)=38927.96875MB; mem (CPU total)=66740.38671875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   66] Training loss: 0.60429944, Validation loss: 0.61085381, Gradient norm: 9.89278207
INFO:root:At the start of the epoch: mem (CPU python)=38949.1328125MB; mem (CPU total)=66494.44921875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   67] Training loss: 0.55743624, Validation loss: 0.55189355, Gradient norm: 7.74738273
INFO:root:At the start of the epoch: mem (CPU python)=38970.296875MB; mem (CPU total)=66917.08984375MB
INFO:root:[   68] Training loss: 0.54191999, Validation loss: 0.54331016, Gradient norm: 6.32550126
INFO:root:At the start of the epoch: mem (CPU python)=38991.45703125MB; mem (CPU total)=67181.94140625MB
INFO:root:[   69] Training loss: 0.54229202, Validation loss: 0.54805011, Gradient norm: 7.43735138
INFO:root:At the start of the epoch: mem (CPU python)=39012.6171875MB; mem (CPU total)=67262.58984375MB
INFO:root:[   70] Training loss: 0.54260954, Validation loss: 0.54481119, Gradient norm: 9.20884237
INFO:root:At the start of the epoch: mem (CPU python)=39033.78125MB; mem (CPU total)=66625.3046875MB
INFO:root:[   71] Training loss: 0.54211986, Validation loss: 0.54026853, Gradient norm: 9.62197224
INFO:root:At the start of the epoch: mem (CPU python)=39054.953125MB; mem (CPU total)=66670.4921875MB
INFO:root:[   72] Training loss: 0.54329072, Validation loss: 0.54708012, Gradient norm: 10.58900432
INFO:root:At the start of the epoch: mem (CPU python)=39076.11328125MB; mem (CPU total)=68915.47265625MB
INFO:root:[   73] Training loss: 0.54382866, Validation loss: 0.53783705, Gradient norm: 12.44816821
INFO:root:At the start of the epoch: mem (CPU python)=39097.28125MB; mem (CPU total)=68938.97265625MB
INFO:root:[   74] Training loss: 0.54476520, Validation loss: 0.54740714, Gradient norm: 12.11764652
INFO:root:At the start of the epoch: mem (CPU python)=39118.4453125MB; mem (CPU total)=67030.6796875MB
INFO:root:[   75] Training loss: 0.54622565, Validation loss: 0.54384068, Gradient norm: 12.72344323
INFO:root:At the start of the epoch: mem (CPU python)=39139.609375MB; mem (CPU total)=69354.18359375MB
INFO:root:[   76] Training loss: 0.54565818, Validation loss: 0.55090085, Gradient norm: 13.72347287
INFO:root:At the start of the epoch: mem (CPU python)=39160.7734375MB; mem (CPU total)=69478.546875MB
INFO:root:[   77] Training loss: 0.54839224, Validation loss: 0.55235874, Gradient norm: 15.09406745
INFO:root:At the start of the epoch: mem (CPU python)=39181.94140625MB; mem (CPU total)=69599.97265625MB
INFO:root:[   78] Training loss: 0.54715273, Validation loss: 0.55056676, Gradient norm: 15.30349986
INFO:root:At the start of the epoch: mem (CPU python)=39203.1015625MB; mem (CPU total)=69720.12890625MB
INFO:root:[   79] Training loss: 0.55361905, Validation loss: 0.59115991, Gradient norm: 15.93238437
INFO:root:At the start of the epoch: mem (CPU python)=39224.265625MB; mem (CPU total)=69789.125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   80] Training loss: 0.55765537, Validation loss: 0.54657101, Gradient norm: 18.93758500
INFO:root:At the start of the epoch: mem (CPU python)=39245.4296875MB; mem (CPU total)=69828.640625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   81] Training loss: 0.53732147, Validation loss: 0.53919457, Gradient norm: 10.81088526
INFO:root:At the start of the epoch: mem (CPU python)=39266.59375MB; mem (CPU total)=69869.4921875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   82] Training loss: 0.53437353, Validation loss: 0.53332185, Gradient norm: 11.38222432
INFO:root:At the start of the epoch: mem (CPU python)=39287.76171875MB; mem (CPU total)=69902.87890625MB
INFO:root:[   83] Training loss: 0.53009250, Validation loss: 0.53035112, Gradient norm: 5.42368131
INFO:root:At the start of the epoch: mem (CPU python)=39308.92578125MB; mem (CPU total)=67394.36328125MB
INFO:root:[   84] Training loss: 0.52921023, Validation loss: 0.52970544, Gradient norm: 6.04491554
INFO:root:At the start of the epoch: mem (CPU python)=39330.08984375MB; mem (CPU total)=73996.33984375MB
INFO:root:[   85] Training loss: 0.52912004, Validation loss: 0.52910198, Gradient norm: 8.54794796
INFO:root:At the start of the epoch: mem (CPU python)=39351.17578125MB; mem (CPU total)=67202.0234375MB
INFO:root:[   86] Training loss: 0.52892681, Validation loss: 0.52993219, Gradient norm: 6.91906112
INFO:root:At the start of the epoch: mem (CPU python)=39372.33984375MB; mem (CPU total)=67235.7421875MB
INFO:root:[   87] Training loss: 0.52845624, Validation loss: 0.52901073, Gradient norm: 7.56040187
INFO:root:At the start of the epoch: mem (CPU python)=39393.50390625MB; mem (CPU total)=67270.578125MB
INFO:root:[   88] Training loss: 0.52807786, Validation loss: 0.52914414, Gradient norm: 7.83006128
INFO:root:At the start of the epoch: mem (CPU python)=39414.6640625MB; mem (CPU total)=67306.60546875MB
INFO:root:[   89] Training loss: 0.52902806, Validation loss: 0.52865345, Gradient norm: 11.87547594
INFO:root:At the start of the epoch: mem (CPU python)=39435.83203125MB; mem (CPU total)=67344.28515625MB
INFO:root:[   90] Training loss: 0.52785805, Validation loss: 0.52932301, Gradient norm: 9.34171080
INFO:root:At the start of the epoch: mem (CPU python)=39456.99609375MB; mem (CPU total)=67384.5625MB
INFO:root:[   91] Training loss: 0.52815860, Validation loss: 0.52857918, Gradient norm: 9.08453428
INFO:root:At the start of the epoch: mem (CPU python)=39478.16015625MB; mem (CPU total)=67426.390625MB
INFO:root:[   92] Training loss: 0.52879782, Validation loss: 0.52969434, Gradient norm: 11.84144189
INFO:root:At the start of the epoch: mem (CPU python)=39499.32421875MB; mem (CPU total)=67461.55078125MB
INFO:root:[   93] Training loss: 0.52845356, Validation loss: 0.52817139, Gradient norm: 13.04685573
INFO:root:At the start of the epoch: mem (CPU python)=39520.4921875MB; mem (CPU total)=67498.3671875MB
INFO:root:[   94] Training loss: 0.52881075, Validation loss: 0.52737638, Gradient norm: 13.10851545
INFO:root:At the start of the epoch: mem (CPU python)=39541.65625MB; mem (CPU total)=67536.6015625MB
INFO:root:[   95] Training loss: 0.52811026, Validation loss: 0.53011512, Gradient norm: 13.23421814
INFO:root:At the start of the epoch: mem (CPU python)=39562.8203125MB; mem (CPU total)=67577.65234375MB
INFO:root:[   96] Training loss: 0.52846150, Validation loss: 0.52892837, Gradient norm: 15.48032888
INFO:root:At the start of the epoch: mem (CPU python)=39583.984375MB; mem (CPU total)=67621.76953125MB
INFO:root:[   97] Training loss: 0.52761739, Validation loss: 0.53029991, Gradient norm: 11.42872172
INFO:root:At the start of the epoch: mem (CPU python)=39605.14453125MB; mem (CPU total)=67657.9453125MB
INFO:root:[   98] Training loss: 0.52751483, Validation loss: 0.52827277, Gradient norm: 12.42697951
INFO:root:At the start of the epoch: mem (CPU python)=39626.30859375MB; mem (CPU total)=67692.20703125MB
INFO:root:[   99] Training loss: 0.52738836, Validation loss: 0.52856846, Gradient norm: 13.29863002
INFO:root:At the start of the epoch: mem (CPU python)=39647.47265625MB; mem (CPU total)=67728.984375MB
INFO:root:[  100] Training loss: 0.52783575, Validation loss: 0.52937214, Gradient norm: 14.59108249
INFO:root:At the start of the epoch: mem (CPU python)=39668.640625MB; mem (CPU total)=67767.7265625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  101] Training loss: 0.52963994, Validation loss: 0.52781910, Gradient norm: 20.75804899
INFO:root:At the start of the epoch: mem (CPU python)=39689.80078125MB; mem (CPU total)=67809.94140625MB
INFO:root:[  102] Training loss: 0.52649623, Validation loss: 0.52841520, Gradient norm: 10.40093318
INFO:root:At the start of the epoch: mem (CPU python)=39710.96484375MB; mem (CPU total)=67849.390625MB
INFO:root:[  103] Training loss: 0.52620212, Validation loss: 0.52832901, Gradient norm: 9.92030786
INFO:root:At the start of the epoch: mem (CPU python)=39732.12890625MB; mem (CPU total)=67885.984375MB
INFO:root:EP 103: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=39753.29296875MB; mem (CPU total)=67925.8125MB
INFO:root:[  105] Training loss: 0.61197297, Validation loss: 0.61111753, Gradient norm: 12.39676458
INFO:root:At the start of the epoch: mem (CPU python)=39774.4609375MB; mem (CPU total)=67969.90234375MB
INFO:root:[  106] Training loss: 0.61009164, Validation loss: 0.61069667, Gradient norm: 11.99624149
INFO:root:At the start of the epoch: mem (CPU python)=39795.62109375MB; mem (CPU total)=68006.17578125MB
INFO:root:[  107] Training loss: 0.60968680, Validation loss: 0.61075028, Gradient norm: 11.47242559
INFO:root:At the start of the epoch: mem (CPU python)=39816.78515625MB; mem (CPU total)=68051.48828125MB
INFO:root:[  108] Training loss: 0.60945935, Validation loss: 0.60979304, Gradient norm: 11.99667627
INFO:root:At the start of the epoch: mem (CPU python)=39837.94921875MB; mem (CPU total)=68093.9296875MB
INFO:root:[  109] Training loss: 0.60876589, Validation loss: 0.60883339, Gradient norm: 11.98141835
INFO:root:At the start of the epoch: mem (CPU python)=39859.11328125MB; mem (CPU total)=68135.4765625MB
INFO:root:[  110] Training loss: 0.60851972, Validation loss: 0.60940742, Gradient norm: 11.56763753
INFO:root:At the start of the epoch: mem (CPU python)=39880.27734375MB; mem (CPU total)=68178.328125MB
INFO:root:[  111] Training loss: 0.60826904, Validation loss: 0.60994681, Gradient norm: 12.10818766
INFO:root:At the start of the epoch: mem (CPU python)=39901.4453125MB; mem (CPU total)=68221.38671875MB
INFO:root:[  112] Training loss: 0.60857612, Validation loss: 0.60966907, Gradient norm: 12.18098072
INFO:root:At the start of the epoch: mem (CPU python)=39922.609375MB; mem (CPU total)=70463.44921875MB
INFO:root:[  113] Training loss: 0.60835588, Validation loss: 0.60966529, Gradient norm: 13.37582179
INFO:root:At the start of the epoch: mem (CPU python)=39943.7734375MB; mem (CPU total)=70498.80859375MB
INFO:root:[  114] Training loss: 0.60810631, Validation loss: 0.60895320, Gradient norm: 12.74389125
INFO:root:At the start of the epoch: mem (CPU python)=39964.94140625MB; mem (CPU total)=70541.13671875MB
INFO:root:[  115] Training loss: 0.60803546, Validation loss: 0.60869577, Gradient norm: 12.39941801
INFO:root:At the start of the epoch: mem (CPU python)=39986.109375MB; mem (CPU total)=70584.140625MB
INFO:root:[  116] Training loss: 0.60798032, Validation loss: 0.60880531, Gradient norm: 11.82702586
INFO:root:At the start of the epoch: mem (CPU python)=40007.265625MB; mem (CPU total)=70636.484375MB
INFO:root:[  117] Training loss: 0.60821088, Validation loss: 0.60815361, Gradient norm: 13.44349205
INFO:root:At the start of the epoch: mem (CPU python)=40028.43359375MB; mem (CPU total)=70680.109375MB
INFO:root:[  118] Training loss: 0.60794920, Validation loss: 0.60764897, Gradient norm: 14.06877558
INFO:root:At the start of the epoch: mem (CPU python)=40049.59765625MB; mem (CPU total)=70716.37109375MB
INFO:root:[  119] Training loss: 0.60787844, Validation loss: 0.60806506, Gradient norm: 14.01408607
INFO:root:At the start of the epoch: mem (CPU python)=40070.7578125MB; mem (CPU total)=70758.484375MB
INFO:root:[  120] Training loss: 0.60749783, Validation loss: 0.60795582, Gradient norm: 13.46214340
INFO:root:At the start of the epoch: mem (CPU python)=40091.921875MB; mem (CPU total)=70801.03125MB
INFO:root:[  121] Training loss: 0.60754206, Validation loss: 0.60807442, Gradient norm: 14.45256399
INFO:root:At the start of the epoch: mem (CPU python)=40113.0859375MB; mem (CPU total)=70854.3203125MB
INFO:root:[  122] Training loss: 0.60772192, Validation loss: 0.60834724, Gradient norm: 14.03568244
INFO:root:At the start of the epoch: mem (CPU python)=40134.25390625MB; mem (CPU total)=70892.37890625MB
INFO:root:[  123] Training loss: 0.60782377, Validation loss: 0.60792887, Gradient norm: 15.08653462
INFO:root:At the start of the epoch: mem (CPU python)=40155.41796875MB; mem (CPU total)=70927.0078125MB
INFO:root:[  124] Training loss: 0.60757104, Validation loss: 0.60777344, Gradient norm: 15.82631674
INFO:root:At the start of the epoch: mem (CPU python)=40176.58203125MB; mem (CPU total)=70967.5625MB
INFO:root:[  125] Training loss: 0.60714701, Validation loss: 0.60861315, Gradient norm: 14.51462064
INFO:root:At the start of the epoch: mem (CPU python)=40197.7421875MB; mem (CPU total)=71009.08984375MB
INFO:root:[  126] Training loss: 0.60764327, Validation loss: 0.60775425, Gradient norm: 14.84140228
INFO:root:At the start of the epoch: mem (CPU python)=40218.90625MB; mem (CPU total)=71057.65234375MB
INFO:root:[  127] Training loss: 0.60735931, Validation loss: 0.60783128, Gradient norm: 16.71789233
INFO:root:At the start of the epoch: mem (CPU python)=40240.0703125MB; mem (CPU total)=71082.109375MB
INFO:root:[  128] Training loss: 0.60717127, Validation loss: 0.60747508, Gradient norm: 15.62459008
INFO:root:At the start of the epoch: mem (CPU python)=40261.23828125MB; mem (CPU total)=71124.42578125MB
INFO:root:[  129] Training loss: 0.60704377, Validation loss: 0.60736976, Gradient norm: 16.31277002
INFO:root:At the start of the epoch: mem (CPU python)=40282.40234375MB; mem (CPU total)=71167.37109375MB
INFO:root:[  130] Training loss: 0.60703877, Validation loss: 0.60734824, Gradient norm: 15.86543037
INFO:root:At the start of the epoch: mem (CPU python)=40303.56640625MB; mem (CPU total)=71209.54296875MB
INFO:root:[  131] Training loss: 0.60737787, Validation loss: 0.60805260, Gradient norm: 17.27790474
INFO:root:At the start of the epoch: mem (CPU python)=40324.73046875MB; mem (CPU total)=71213.61328125MB
INFO:root:[  132] Training loss: 0.60707274, Validation loss: 0.60868375, Gradient norm: 16.35839470
INFO:root:At the start of the epoch: mem (CPU python)=40345.89453125MB; mem (CPU total)=71236.8984375MB
INFO:root:[  133] Training loss: 0.60718642, Validation loss: 0.60799499, Gradient norm: 17.02845263
INFO:root:At the start of the epoch: mem (CPU python)=40367.0625MB; mem (CPU total)=71259.78125MB
INFO:root:[  134] Training loss: 0.60711322, Validation loss: 0.60775500, Gradient norm: 18.34798394
INFO:root:At the start of the epoch: mem (CPU python)=40388.2265625MB; mem (CPU total)=71282.5234375MB
INFO:root:[  135] Training loss: 0.60696536, Validation loss: 0.60653300, Gradient norm: 18.30975706
INFO:root:At the start of the epoch: mem (CPU python)=40409.38671875MB; mem (CPU total)=71382.48828125MB
INFO:root:[  136] Training loss: 0.60652140, Validation loss: 0.60630263, Gradient norm: 17.94307712
INFO:root:At the start of the epoch: mem (CPU python)=40430.546875MB; mem (CPU total)=69235.70703125MB
INFO:root:[  137] Training loss: 0.60704489, Validation loss: 0.60819176, Gradient norm: 17.97379954
INFO:root:At the start of the epoch: mem (CPU python)=40451.7109375MB; mem (CPU total)=69275.51171875MB
INFO:root:[  138] Training loss: 0.60689624, Validation loss: 0.60734548, Gradient norm: 18.34775923
INFO:root:At the start of the epoch: mem (CPU python)=40472.875MB; mem (CPU total)=69317.53125MB
INFO:root:[  139] Training loss: 0.60660694, Validation loss: 0.60686981, Gradient norm: 18.22828732
INFO:root:At the start of the epoch: mem (CPU python)=40494.0390625MB; mem (CPU total)=69361.70703125MB
INFO:root:[  140] Training loss: 0.60685143, Validation loss: 0.60723679, Gradient norm: 18.51259517
INFO:root:At the start of the epoch: mem (CPU python)=40515.20703125MB; mem (CPU total)=69407.8515625MB
INFO:root:[  141] Training loss: 0.60655391, Validation loss: 0.60802880, Gradient norm: 18.40927435
INFO:root:At the start of the epoch: mem (CPU python)=40536.37109375MB; mem (CPU total)=69450.60546875MB
INFO:root:[  142] Training loss: 0.60708776, Validation loss: 0.60703946, Gradient norm: 19.43201601
INFO:root:At the start of the epoch: mem (CPU python)=40557.53515625MB; mem (CPU total)=69492.50390625MB
INFO:root:[  143] Training loss: 0.60688683, Validation loss: 0.60617931, Gradient norm: 19.84712356
INFO:root:At the start of the epoch: mem (CPU python)=40578.69921875MB; mem (CPU total)=71681.8828125MB
INFO:root:[  144] Training loss: 0.60706714, Validation loss: 0.60685311, Gradient norm: 19.94547391
INFO:root:At the start of the epoch: mem (CPU python)=40599.859375MB; mem (CPU total)=71723.328125MB
INFO:root:[  145] Training loss: 0.60648880, Validation loss: 0.60724574, Gradient norm: 19.17862864
INFO:root:At the start of the epoch: mem (CPU python)=40621.02734375MB; mem (CPU total)=71765.6328125MB
INFO:root:[  146] Training loss: 0.60680402, Validation loss: 0.60709688, Gradient norm: 22.01091299
INFO:root:At the start of the epoch: mem (CPU python)=40642.19140625MB; mem (CPU total)=69658.08984375MB
INFO:root:[  147] Training loss: 0.60633029, Validation loss: 0.60688889, Gradient norm: 21.63970046
INFO:root:At the start of the epoch: mem (CPU python)=40663.35546875MB; mem (CPU total)=69698.3828125MB
INFO:root:[  148] Training loss: 0.60672509, Validation loss: 0.60775727, Gradient norm: 20.01249764
INFO:root:At the start of the epoch: mem (CPU python)=40684.51953125MB; mem (CPU total)=69741.34375MB
INFO:root:[  149] Training loss: 0.60651088, Validation loss: 0.60720142, Gradient norm: 21.21687204
INFO:root:At the start of the epoch: mem (CPU python)=40705.68359375MB; mem (CPU total)=69782.1484375MB
INFO:root:[  150] Training loss: 0.60629963, Validation loss: 0.60725110, Gradient norm: 21.92188493
INFO:root:At the start of the epoch: mem (CPU python)=40726.8515625MB; mem (CPU total)=69823.921875MB
INFO:root:[  151] Training loss: 0.60626851, Validation loss: 0.60711378, Gradient norm: 20.80275356
INFO:root:At the start of the epoch: mem (CPU python)=40748.015625MB; mem (CPU total)=69864.99609375MB
INFO:root:[  152] Training loss: 0.60661779, Validation loss: 0.60645040, Gradient norm: 23.86161609
INFO:root:At the start of the epoch: mem (CPU python)=40769.17578125MB; mem (CPU total)=69907.6484375MB
INFO:root:EP 152: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=40790.3359375MB; mem (CPU total)=69939.62109375MB
INFO:root:Training the model took 9763.037s.
INFO:root:Emptying the cuda cache took 0.063s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.60637
INFO:root:EnergyScoreValidation: 0.48646
INFO:root:CRPSValidation: 0.20378
INFO:root:Gaussian NLLValidation: 2.10402
INFO:root:CoverageValidation: 0.5624
INFO:root:IntervalWidthValidation: 0.47011
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.48963
INFO:root:EnergyScoreTest: 0.37446
INFO:root:CRPSTest: 0.15627
INFO:root:Gaussian NLLTest: 0.75695
INFO:root:CoverageTest: 0.68947
INFO:root:IntervalWidthTest: 0.50111
INFO:root:After validation: mem (CPU python)=41096.87890625MB; mem (CPU total)=70019.34765625MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=41096.87890625MB; mem (CPU total)=72450.234375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 297795584
INFO:root:After setting up the model: mem (CPU python)=41096.87890625MB; mem (CPU total)=72450.72265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=72458.08984375MB
INFO:root:[    1] Training loss: 0.86891167, Validation loss: 0.76064663, Gradient norm: 0.34637988
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=72238.17578125MB
INFO:root:[    2] Training loss: 0.75579077, Validation loss: 0.75527567, Gradient norm: 0.32521317
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70118.51171875MB
INFO:root:[    3] Training loss: 0.74870224, Validation loss: 0.74266105, Gradient norm: 0.49350283
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70153.83984375MB
INFO:root:[    4] Training loss: 0.73853562, Validation loss: 0.75785447, Gradient norm: 0.72496121
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70190.0625MB
INFO:root:[    5] Training loss: 0.72955113, Validation loss: 0.72409643, Gradient norm: 0.89998956
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70227.40234375MB
INFO:root:[    6] Training loss: 0.71972897, Validation loss: 0.70636923, Gradient norm: 1.45220511
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70268.703125MB
INFO:root:[    7] Training loss: 0.70379241, Validation loss: 0.69020198, Gradient norm: 1.67728507
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70311.21875MB
INFO:root:[    8] Training loss: 0.70184450, Validation loss: 0.70153045, Gradient norm: 2.22934296
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70353.90234375MB
INFO:root:[    9] Training loss: 0.69364184, Validation loss: 0.67942075, Gradient norm: 2.23005077
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70390.03125MB
INFO:root:[   10] Training loss: 0.68926830, Validation loss: 0.69005939, Gradient norm: 2.54481972
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70426.91796875MB
INFO:root:[   11] Training loss: 0.68188316, Validation loss: 0.68156351, Gradient norm: 2.67524463
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70464.09765625MB
INFO:root:[   12] Training loss: 0.68188063, Validation loss: 0.68349556, Gradient norm: 3.15512023
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70506.765625MB
INFO:root:[   13] Training loss: 0.67536786, Validation loss: 0.67560479, Gradient norm: 3.21277077
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=70549.23046875MB
INFO:root:[   14] Training loss: 0.67403183, Validation loss: 0.67241278, Gradient norm: 3.74522560
INFO:root:At the start of the epoch: mem (CPU python)=41096.87890625MB; mem (CPU total)=72740.34375MB
INFO:root:[   15] Training loss: 0.67376048, Validation loss: 0.65386013, Gradient norm: 3.94452138
INFO:root:At the start of the epoch: mem (CPU python)=41114.55859375MB; mem (CPU total)=72765.91796875MB
INFO:root:[   16] Training loss: 0.66484049, Validation loss: 0.66470671, Gradient norm: 3.69798727
INFO:root:At the start of the epoch: mem (CPU python)=41135.71875MB; mem (CPU total)=72815.68359375MB
INFO:root:[   17] Training loss: 0.66370475, Validation loss: 0.65623923, Gradient norm: 4.15261081
INFO:root:At the start of the epoch: mem (CPU python)=41156.8828125MB; mem (CPU total)=72852.953125MB
INFO:root:[   18] Training loss: 0.66228061, Validation loss: 0.68989975, Gradient norm: 4.33414097
INFO:root:At the start of the epoch: mem (CPU python)=41178.046875MB; mem (CPU total)=72894.66796875MB
INFO:root:[   19] Training loss: 0.66370195, Validation loss: 0.65605427, Gradient norm: 4.84173044
INFO:root:At the start of the epoch: mem (CPU python)=41199.21484375MB; mem (CPU total)=72932.0859375MB
INFO:root:[   20] Training loss: 0.66550693, Validation loss: 0.65406536, Gradient norm: 4.86485229
INFO:root:At the start of the epoch: mem (CPU python)=41220.375MB; mem (CPU total)=70807.91015625MB
INFO:root:[   21] Training loss: 0.65643164, Validation loss: 0.66042677, Gradient norm: 4.71910967
INFO:root:At the start of the epoch: mem (CPU python)=41241.5390625MB; mem (CPU total)=70841.56640625MB
INFO:root:[   22] Training loss: 0.65624225, Validation loss: 0.63810677, Gradient norm: 4.84918855
INFO:root:At the start of the epoch: mem (CPU python)=41262.703125MB; mem (CPU total)=70881.07421875MB
INFO:root:[   23] Training loss: 0.65728348, Validation loss: 0.66989421, Gradient norm: 5.39419042
INFO:root:At the start of the epoch: mem (CPU python)=41283.8671875MB; mem (CPU total)=70923.62109375MB
INFO:root:[   24] Training loss: 0.65988447, Validation loss: 0.67002676, Gradient norm: 5.61194134
INFO:root:At the start of the epoch: mem (CPU python)=41305.03125MB; mem (CPU total)=70966.94140625MB
INFO:root:[   25] Training loss: 0.65211311, Validation loss: 0.63676684, Gradient norm: 5.38782263
INFO:root:At the start of the epoch: mem (CPU python)=41326.19921875MB; mem (CPU total)=71006.2578125MB
INFO:root:[   26] Training loss: 0.65857245, Validation loss: 0.63914851, Gradient norm: 6.54189944
INFO:root:At the start of the epoch: mem (CPU python)=41347.36328125MB; mem (CPU total)=71043.40234375MB
INFO:root:[   27] Training loss: 0.65974131, Validation loss: 0.66571231, Gradient norm: 6.29455734
INFO:root:At the start of the epoch: mem (CPU python)=41368.52734375MB; mem (CPU total)=71080.78515625MB
INFO:root:[   28] Training loss: 0.65535196, Validation loss: 0.68314653, Gradient norm: 6.33040592
INFO:root:At the start of the epoch: mem (CPU python)=41389.69140625MB; mem (CPU total)=71120.734375MB
INFO:root:[   29] Training loss: 0.64983584, Validation loss: 0.63565092, Gradient norm: 6.47729171
INFO:root:At the start of the epoch: mem (CPU python)=41410.85546875MB; mem (CPU total)=71164.26953125MB
INFO:root:[   30] Training loss: 0.64764274, Validation loss: 0.62483837, Gradient norm: 7.42269666
INFO:root:At the start of the epoch: mem (CPU python)=41432.01953125MB; mem (CPU total)=71200.47265625MB
INFO:root:[   31] Training loss: 0.65056479, Validation loss: 0.62332585, Gradient norm: 7.61329976
INFO:root:At the start of the epoch: mem (CPU python)=41453.18359375MB; mem (CPU total)=71237.37109375MB
INFO:root:[   32] Training loss: 0.64206192, Validation loss: 0.62499869, Gradient norm: 7.34071896
INFO:root:At the start of the epoch: mem (CPU python)=41474.34375MB; mem (CPU total)=71274.01171875MB
INFO:root:[   33] Training loss: 0.64359589, Validation loss: 0.62936082, Gradient norm: 7.74784990
INFO:root:At the start of the epoch: mem (CPU python)=41495.5078125MB; mem (CPU total)=71311.75MB
INFO:root:[   34] Training loss: 0.64008162, Validation loss: 0.64031992, Gradient norm: 7.72681624
INFO:root:At the start of the epoch: mem (CPU python)=41516.671875MB; mem (CPU total)=71354.7890625MB
INFO:root:[   35] Training loss: 0.64391386, Validation loss: 0.63452261, Gradient norm: 8.35661221
INFO:root:At the start of the epoch: mem (CPU python)=41537.83984375MB; mem (CPU total)=71394.71484375MB
INFO:root:[   36] Training loss: 0.63115892, Validation loss: 0.63323003, Gradient norm: 7.82601182
INFO:root:At the start of the epoch: mem (CPU python)=41559.00390625MB; mem (CPU total)=71431.171875MB
INFO:root:[   37] Training loss: 0.63002389, Validation loss: 0.61722152, Gradient norm: 8.64379733
INFO:root:At the start of the epoch: mem (CPU python)=41580.16796875MB; mem (CPU total)=71468.3671875MB
INFO:root:[   38] Training loss: 0.63713559, Validation loss: 0.62521807, Gradient norm: 9.71318319
INFO:root:At the start of the epoch: mem (CPU python)=41601.33203125MB; mem (CPU total)=71505.02734375MB
INFO:root:[   39] Training loss: 0.64728618, Validation loss: 0.63036999, Gradient norm: 10.39347938
INFO:root:At the start of the epoch: mem (CPU python)=41622.4921875MB; mem (CPU total)=71546.12109375MB
INFO:root:[   40] Training loss: 0.63682136, Validation loss: 0.64826141, Gradient norm: 9.81441852
INFO:root:At the start of the epoch: mem (CPU python)=41643.65625MB; mem (CPU total)=71588.4375MB
INFO:root:[   41] Training loss: 0.64166671, Validation loss: 0.64914949, Gradient norm: 9.95256547
INFO:root:At the start of the epoch: mem (CPU python)=41664.82421875MB; mem (CPU total)=71625.72265625MB
INFO:root:[   42] Training loss: 0.62807052, Validation loss: 0.67436368, Gradient norm: 9.56567395
INFO:root:At the start of the epoch: mem (CPU python)=41685.98828125MB; mem (CPU total)=71662.7890625MB
INFO:root:[   43] Training loss: 0.64609756, Validation loss: 0.64366845, Gradient norm: 11.52461272
INFO:root:At the start of the epoch: mem (CPU python)=41707.15234375MB; mem (CPU total)=73863.2109375MB
INFO:root:[   44] Training loss: 0.64424344, Validation loss: 0.64687993, Gradient norm: 10.36400039
INFO:root:At the start of the epoch: mem (CPU python)=41728.31640625MB; mem (CPU total)=73902.859375MB
INFO:root:[   45] Training loss: 0.63322676, Validation loss: 0.60958456, Gradient norm: 10.69826003
INFO:root:At the start of the epoch: mem (CPU python)=41749.48046875MB; mem (CPU total)=73944.6484375MB
INFO:root:[   46] Training loss: 0.65152770, Validation loss: 0.61416256, Gradient norm: 11.43039890
INFO:root:At the start of the epoch: mem (CPU python)=41770.64453125MB; mem (CPU total)=73984.87890625MB
INFO:root:[   47] Training loss: 0.63488162, Validation loss: 0.64902198, Gradient norm: 10.71369256
INFO:root:At the start of the epoch: mem (CPU python)=41791.81640625MB; mem (CPU total)=74009.265625MB
INFO:root:[   48] Training loss: 0.63214108, Validation loss: 0.63222731, Gradient norm: 11.07895129
INFO:root:At the start of the epoch: mem (CPU python)=41812.9765625MB; mem (CPU total)=74046.36328125MB
INFO:root:[   49] Training loss: 0.63415461, Validation loss: 0.62392629, Gradient norm: 11.64887793
INFO:root:At the start of the epoch: mem (CPU python)=41834.13671875MB; mem (CPU total)=74081.97265625MB
INFO:root:[   50] Training loss: 0.65304127, Validation loss: 0.63461660, Gradient norm: 13.48812154
INFO:root:At the start of the epoch: mem (CPU python)=41855.30078125MB; mem (CPU total)=74123.00390625MB
INFO:root:[   51] Training loss: 0.63606421, Validation loss: 0.62387652, Gradient norm: 11.39927755
INFO:root:At the start of the epoch: mem (CPU python)=41876.46484375MB; mem (CPU total)=74166.81640625MB
INFO:root:[   52] Training loss: 0.63083857, Validation loss: 0.64914868, Gradient norm: 12.16638740
INFO:root:At the start of the epoch: mem (CPU python)=41897.62890625MB; mem (CPU total)=74205.0390625MB
INFO:root:[   53] Training loss: 0.65257799, Validation loss: 0.66753047, Gradient norm: 14.22221347
INFO:root:At the start of the epoch: mem (CPU python)=41918.80078125MB; mem (CPU total)=74246.37890625MB
INFO:root:[   54] Training loss: 0.65233748, Validation loss: 0.63366353, Gradient norm: 14.18873131
INFO:root:At the start of the epoch: mem (CPU python)=41939.96484375MB; mem (CPU total)=74285.70703125MB
INFO:root:[   55] Training loss: 0.65477090, Validation loss: 0.65581532, Gradient norm: 13.63294136
INFO:root:At the start of the epoch: mem (CPU python)=41961.12890625MB; mem (CPU total)=74320.7578125MB
INFO:root:[   56] Training loss: 0.64250746, Validation loss: 0.64091108, Gradient norm: 12.98278094
INFO:root:At the start of the epoch: mem (CPU python)=41982.29296875MB; mem (CPU total)=74364.015625MB
INFO:root:[   57] Training loss: 0.65265942, Validation loss: 0.64318036, Gradient norm: 14.12231935
INFO:root:At the start of the epoch: mem (CPU python)=42003.453125MB; mem (CPU total)=74403.86328125MB
INFO:root:[   58] Training loss: 0.63252687, Validation loss: 0.61715757, Gradient norm: 12.28649000
INFO:root:At the start of the epoch: mem (CPU python)=42024.6171875MB; mem (CPU total)=74440.46875MB
INFO:root:[   59] Training loss: 0.65198096, Validation loss: 0.66206845, Gradient norm: 14.87932308
INFO:root:At the start of the epoch: mem (CPU python)=42045.78515625MB; mem (CPU total)=74477.55078125MB
INFO:root:[   60] Training loss: 0.64777707, Validation loss: 0.64446972, Gradient norm: 13.86068665
INFO:root:At the start of the epoch: mem (CPU python)=42066.94921875MB; mem (CPU total)=74514.9140625MB
INFO:root:[   61] Training loss: 0.63852721, Validation loss: 0.61333634, Gradient norm: 13.82949163
INFO:root:At the start of the epoch: mem (CPU python)=42088.11328125MB; mem (CPU total)=74556.73046875MB
INFO:root:[   62] Training loss: 0.65405204, Validation loss: 0.65985668, Gradient norm: 15.58384935
INFO:root:At the start of the epoch: mem (CPU python)=42109.27734375MB; mem (CPU total)=74599.5625MB
INFO:root:[   63] Training loss: 0.65284400, Validation loss: 0.66191076, Gradient norm: 15.31385322
INFO:root:At the start of the epoch: mem (CPU python)=42130.44140625MB; mem (CPU total)=74642.40625MB
INFO:root:[   64] Training loss: 0.65541556, Validation loss: 0.67308827, Gradient norm: 15.31359218
INFO:root:At the start of the epoch: mem (CPU python)=42151.60546875MB; mem (CPU total)=74677.8046875MB
INFO:root:[   65] Training loss: 0.64555090, Validation loss: 0.64091014, Gradient norm: 14.13068089
INFO:root:At the start of the epoch: mem (CPU python)=42172.7734375MB; mem (CPU total)=72546.7109375MB
INFO:root:[   66] Training loss: 0.64499624, Validation loss: 0.62706770, Gradient norm: 14.20956810
INFO:root:At the start of the epoch: mem (CPU python)=42193.9296875MB; mem (CPU total)=72585.578125MB
INFO:root:[   67] Training loss: 0.64328763, Validation loss: 0.64569346, Gradient norm: 14.79969709
INFO:root:At the start of the epoch: mem (CPU python)=42215.08984375MB; mem (CPU total)=72627.78515625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   68] Training loss: 0.66217312, Validation loss: 0.66306984, Gradient norm: 17.48853766
INFO:root:At the start of the epoch: mem (CPU python)=42236.25390625MB; mem (CPU total)=72667.13671875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   69] Training loss: 0.60088795, Validation loss: 0.59737232, Gradient norm: 11.90184125
INFO:root:At the start of the epoch: mem (CPU python)=42257.41796875MB; mem (CPU total)=72703.26953125MB
INFO:root:[   70] Training loss: 0.58414842, Validation loss: 0.58665203, Gradient norm: 10.38555344
INFO:root:At the start of the epoch: mem (CPU python)=42278.5859375MB; mem (CPU total)=72740.453125MB
INFO:root:[   71] Training loss: 0.58182796, Validation loss: 0.58011278, Gradient norm: 12.35629932
INFO:root:At the start of the epoch: mem (CPU python)=42299.75MB; mem (CPU total)=72777.09765625MB
INFO:root:[   72] Training loss: 0.58416957, Validation loss: 0.58284616, Gradient norm: 14.15008034
INFO:root:At the start of the epoch: mem (CPU python)=42320.9140625MB; mem (CPU total)=72817.9296875MB
INFO:root:[   73] Training loss: 0.58489272, Validation loss: 0.58116656, Gradient norm: 15.65848322
INFO:root:At the start of the epoch: mem (CPU python)=42342.078125MB; mem (CPU total)=72860.89453125MB
INFO:root:[   74] Training loss: 0.58744447, Validation loss: 0.58956275, Gradient norm: 17.98517204
INFO:root:At the start of the epoch: mem (CPU python)=42363.2421875MB; mem (CPU total)=72897.78125MB
INFO:root:[   75] Training loss: 0.58832861, Validation loss: 0.58608574, Gradient norm: 19.04525477
INFO:root:At the start of the epoch: mem (CPU python)=42384.40625MB; mem (CPU total)=72934.671875MB
INFO:root:[   76] Training loss: 0.58819978, Validation loss: 0.58749488, Gradient norm: 18.97735640
INFO:root:At the start of the epoch: mem (CPU python)=42405.5703125MB; mem (CPU total)=72971.29296875MB
INFO:root:[   77] Training loss: 0.58945288, Validation loss: 0.58258091, Gradient norm: 20.86264605
INFO:root:At the start of the epoch: mem (CPU python)=42426.734375MB; mem (CPU total)=73008.9765625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   78] Training loss: 0.58964691, Validation loss: 0.58965960, Gradient norm: 22.97589281
INFO:root:At the start of the epoch: mem (CPU python)=42447.8984375MB; mem (CPU total)=73051.23828125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   79] Training loss: 0.57566635, Validation loss: 0.57606354, Gradient norm: 14.51671495
INFO:root:At the start of the epoch: mem (CPU python)=42469.0625MB; mem (CPU total)=73084.8828125MB
INFO:root:[   80] Training loss: 0.56832455, Validation loss: 0.56866452, Gradient norm: 11.21271115
INFO:root:At the start of the epoch: mem (CPU python)=42490.2265625MB; mem (CPU total)=73120.6015625MB
INFO:root:[   81] Training loss: 0.56750928, Validation loss: 0.56621255, Gradient norm: 12.66906357
INFO:root:At the start of the epoch: mem (CPU python)=42511.39453125MB; mem (CPU total)=73157.15625MB
INFO:root:[   82] Training loss: 0.56657152, Validation loss: 0.56873282, Gradient norm: 14.53536101
INFO:root:At the start of the epoch: mem (CPU python)=42532.55859375MB; mem (CPU total)=73194.26171875MB
INFO:root:[   83] Training loss: 0.56596172, Validation loss: 0.56629822, Gradient norm: 15.76009210
INFO:root:At the start of the epoch: mem (CPU python)=42553.71875MB; mem (CPU total)=73232.89453125MB
INFO:root:[   84] Training loss: 0.56631544, Validation loss: 0.57004222, Gradient norm: 16.45909801
INFO:root:At the start of the epoch: mem (CPU python)=42574.8828125MB; mem (CPU total)=73276.7734375MB
INFO:root:[   85] Training loss: 0.56518157, Validation loss: 0.56617012, Gradient norm: 17.23376229
INFO:root:At the start of the epoch: mem (CPU python)=42596.046875MB; mem (CPU total)=73320.24609375MB
INFO:root:[   86] Training loss: 0.56531289, Validation loss: 0.56657634, Gradient norm: 17.74816035
INFO:root:At the start of the epoch: mem (CPU python)=42617.20703125MB; mem (CPU total)=73356.4375MB
INFO:root:[   87] Training loss: 0.56566907, Validation loss: 0.56636167, Gradient norm: 18.77401426
INFO:root:At the start of the epoch: mem (CPU python)=42638.375MB; mem (CPU total)=73393.52734375MB
INFO:root:[   88] Training loss: 0.56499036, Validation loss: 0.56525065, Gradient norm: 18.19131456
INFO:root:At the start of the epoch: mem (CPU python)=42659.5390625MB; mem (CPU total)=73430.1953125MB
INFO:root:[   89] Training loss: 0.56454347, Validation loss: 0.56370073, Gradient norm: 19.34130727
INFO:root:At the start of the epoch: mem (CPU python)=42680.703125MB; mem (CPU total)=73471.046875MB
INFO:root:[   90] Training loss: 0.56537729, Validation loss: 0.56682105, Gradient norm: 20.56560384
INFO:root:At the start of the epoch: mem (CPU python)=42701.87109375MB; mem (CPU total)=73513.32421875MB
INFO:root:[   91] Training loss: 0.56779632, Validation loss: 0.56825638, Gradient norm: 26.81362507
INFO:root:At the start of the epoch: mem (CPU python)=42723.03515625MB; mem (CPU total)=73552.69140625MB
INFO:root:[   92] Training loss: 0.56376358, Validation loss: 0.56380614, Gradient norm: 18.51786237
INFO:root:At the start of the epoch: mem (CPU python)=42744.19921875MB; mem (CPU total)=73590.3046875MB
INFO:root:[   93] Training loss: 0.56432725, Validation loss: 0.56557968, Gradient norm: 23.13611115
INFO:root:At the start of the epoch: mem (CPU python)=42765.3671875MB; mem (CPU total)=73627.234375MB
INFO:root:[   94] Training loss: 0.56360631, Validation loss: 0.56295137, Gradient norm: 21.72063422
INFO:root:At the start of the epoch: mem (CPU python)=42786.53125MB; mem (CPU total)=73665.140625MB
INFO:root:[   95] Training loss: 0.56343435, Validation loss: 0.56400197, Gradient norm: 22.15233950
INFO:root:At the start of the epoch: mem (CPU python)=42807.69140625MB; mem (CPU total)=73706.4765625MB
INFO:root:[   96] Training loss: 0.56401292, Validation loss: 0.56525730, Gradient norm: 22.71375179
INFO:root:At the start of the epoch: mem (CPU python)=42828.85546875MB; mem (CPU total)=73748.7734375MB
INFO:root:[   97] Training loss: 0.56404255, Validation loss: 0.56875453, Gradient norm: 24.72910717
INFO:root:At the start of the epoch: mem (CPU python)=42850.01953125MB; mem (CPU total)=73785.64453125MB
INFO:root:[   98] Training loss: 0.56386514, Validation loss: 0.56690110, Gradient norm: 26.30651199
INFO:root:At the start of the epoch: mem (CPU python)=42871.18359375MB; mem (CPU total)=73822.84765625MB
INFO:root:[   99] Training loss: 0.56347706, Validation loss: 0.56436356, Gradient norm: 24.70747512
INFO:root:At the start of the epoch: mem (CPU python)=42892.3515625MB; mem (CPU total)=73860.90234375MB
INFO:root:[  100] Training loss: 0.56269613, Validation loss: 0.56460692, Gradient norm: 25.28154853
INFO:root:At the start of the epoch: mem (CPU python)=42913.51171875MB; mem (CPU total)=73897.83984375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  101] Training loss: 0.56369867, Validation loss: 0.56081993, Gradient norm: 25.74717775
INFO:root:At the start of the epoch: mem (CPU python)=42934.6796875MB; mem (CPU total)=73940.61328125MB
INFO:root:[  102] Training loss: 0.55861777, Validation loss: 0.55906267, Gradient norm: 16.02583319
INFO:root:At the start of the epoch: mem (CPU python)=42955.84375MB; mem (CPU total)=73982.8984375MB
INFO:root:[  103] Training loss: 0.55780520, Validation loss: 0.55748401, Gradient norm: 18.06385899
INFO:root:At the start of the epoch: mem (CPU python)=42977.0078125MB; mem (CPU total)=74018.7734375MB
INFO:root:[  104] Training loss: 0.55800929, Validation loss: 0.55978388, Gradient norm: 20.55686140
INFO:root:At the start of the epoch: mem (CPU python)=42998.171875MB; mem (CPU total)=74055.66015625MB
INFO:root:[  105] Training loss: 0.55763197, Validation loss: 0.55701016, Gradient norm: 20.71382176
INFO:root:At the start of the epoch: mem (CPU python)=43019.33203125MB; mem (CPU total)=74093.04296875MB
INFO:root:[  106] Training loss: 0.55790966, Validation loss: 0.56077171, Gradient norm: 22.39719952
INFO:root:At the start of the epoch: mem (CPU python)=43040.49609375MB; mem (CPU total)=74131.62109375MB
INFO:root:[  107] Training loss: 0.55688601, Validation loss: 0.55901618, Gradient norm: 22.66689389
INFO:root:At the start of the epoch: mem (CPU python)=43061.66015625MB; mem (CPU total)=74173.94921875MB
INFO:root:[  108] Training loss: 0.55870509, Validation loss: 0.56106678, Gradient norm: 27.43277973
INFO:root:At the start of the epoch: mem (CPU python)=43082.82421875MB; mem (CPU total)=74216.46484375MB
INFO:root:[  109] Training loss: 0.56073976, Validation loss: 0.55939616, Gradient norm: 33.85785223
INFO:root:At the start of the epoch: mem (CPU python)=43103.9921875MB; mem (CPU total)=74251.9375MB
INFO:root:[  110] Training loss: 0.55908969, Validation loss: 0.55785831, Gradient norm: 26.32704289
INFO:root:At the start of the epoch: mem (CPU python)=43125.15625MB; mem (CPU total)=74289.08984375MB
INFO:root:[  111] Training loss: 0.55722740, Validation loss: 0.55860955, Gradient norm: 23.11981866
INFO:root:At the start of the epoch: mem (CPU python)=43146.3203125MB; mem (CPU total)=74327.22265625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  112] Training loss: 0.55694607, Validation loss: 0.55910695, Gradient norm: 23.72027833
INFO:root:At the start of the epoch: mem (CPU python)=43167.484375MB; mem (CPU total)=74365.8671875MB
INFO:root:[  113] Training loss: 0.55488189, Validation loss: 0.55526225, Gradient norm: 19.08434086
INFO:root:At the start of the epoch: mem (CPU python)=43188.6484375MB; mem (CPU total)=74408.46875MB
INFO:root:[  114] Training loss: 0.55426761, Validation loss: 0.55544600, Gradient norm: 20.14572848
INFO:root:At the start of the epoch: mem (CPU python)=43209.80859375MB; mem (CPU total)=74449.53125MB
INFO:root:[  115] Training loss: 0.55412020, Validation loss: 0.55580904, Gradient norm: 16.59488077
INFO:root:At the start of the epoch: mem (CPU python)=43230.9765625MB; mem (CPU total)=74485.73046875MB
INFO:root:[  116] Training loss: 0.55342229, Validation loss: 0.55502663, Gradient norm: 16.85824252
INFO:root:At the start of the epoch: mem (CPU python)=43252.140625MB; mem (CPU total)=74524.23046875MB
INFO:root:[  117] Training loss: 0.55322524, Validation loss: 0.55559389, Gradient norm: 17.67097255
INFO:root:At the start of the epoch: mem (CPU python)=43273.30078125MB; mem (CPU total)=74561.52734375MB
INFO:root:[  118] Training loss: 0.55353776, Validation loss: 0.55810623, Gradient norm: 23.00806622
INFO:root:At the start of the epoch: mem (CPU python)=43294.46484375MB; mem (CPU total)=74603.02734375MB
INFO:root:[  119] Training loss: 0.55397276, Validation loss: 0.55423446, Gradient norm: 27.30340361
INFO:root:At the start of the epoch: mem (CPU python)=43315.62890625MB; mem (CPU total)=74644.7890625MB
INFO:root:[  120] Training loss: 0.55302702, Validation loss: 0.55347231, Gradient norm: 20.15537636
INFO:root:At the start of the epoch: mem (CPU python)=43336.79296875MB; mem (CPU total)=74684.59765625MB
INFO:root:[  121] Training loss: 0.55338566, Validation loss: 0.55403324, Gradient norm: 23.57319209
INFO:root:At the start of the epoch: mem (CPU python)=43357.9609375MB; mem (CPU total)=74721.01953125MB
INFO:root:[  122] Training loss: 0.55228777, Validation loss: 0.55391969, Gradient norm: 21.85779791
INFO:root:At the start of the epoch: mem (CPU python)=43379.125MB; mem (CPU total)=74758.421875MB
INFO:root:[  123] Training loss: 0.55267232, Validation loss: 0.55356309, Gradient norm: 22.84481052
INFO:root:At the start of the epoch: mem (CPU python)=43400.28515625MB; mem (CPU total)=74795.80859375MB
INFO:root:[  124] Training loss: 0.55248159, Validation loss: 0.55257576, Gradient norm: 23.82813692
INFO:root:At the start of the epoch: mem (CPU python)=43421.44921875MB; mem (CPU total)=74835.125MB
INFO:root:[  125] Training loss: 0.55304206, Validation loss: 0.55343737, Gradient norm: 23.47437848
INFO:root:At the start of the epoch: mem (CPU python)=43442.61328125MB; mem (CPU total)=74877.38671875MB
INFO:root:[  126] Training loss: 0.55221234, Validation loss: 0.55410265, Gradient norm: 24.92410788
INFO:root:At the start of the epoch: mem (CPU python)=43463.77734375MB; mem (CPU total)=74917.73828125MB
INFO:root:[  127] Training loss: 0.55179832, Validation loss: 0.55163227, Gradient norm: 26.32979121
INFO:root:At the start of the epoch: mem (CPU python)=43484.9453125MB; mem (CPU total)=74954.390625MB
INFO:root:[  128] Training loss: 0.55215232, Validation loss: 0.55241778, Gradient norm: 26.96271543
INFO:root:At the start of the epoch: mem (CPU python)=43506.109375MB; mem (CPU total)=74990.99609375MB
INFO:root:[  129] Training loss: 0.55235173, Validation loss: 0.55251684, Gradient norm: 28.96122500
INFO:root:At the start of the epoch: mem (CPU python)=43527.2734375MB; mem (CPU total)=75027.6015625MB
INFO:root:[  130] Training loss: 0.55209842, Validation loss: 0.55391781, Gradient norm: 27.45595670
INFO:root:At the start of the epoch: mem (CPU python)=43548.4375MB; mem (CPU total)=75067.5MB
INFO:root:[  131] Training loss: 0.55185026, Validation loss: 0.55399498, Gradient norm: 27.40719014
INFO:root:At the start of the epoch: mem (CPU python)=43569.6015625MB; mem (CPU total)=75109.78515625MB
INFO:root:[  132] Training loss: 0.55132933, Validation loss: 0.55359125, Gradient norm: 29.44423714
INFO:root:At the start of the epoch: mem (CPU python)=43590.76953125MB; mem (CPU total)=75150.0703125MB
INFO:root:[  133] Training loss: 0.55159197, Validation loss: 0.55273409, Gradient norm: 28.68230835
INFO:root:At the start of the epoch: mem (CPU python)=43611.93359375MB; mem (CPU total)=75186.78515625MB
INFO:root:[  134] Training loss: 0.55187603, Validation loss: 0.55193519, Gradient norm: 30.82323039
INFO:root:At the start of the epoch: mem (CPU python)=43633.09375MB; mem (CPU total)=75223.9453125MB
INFO:root:[  135] Training loss: 0.55122678, Validation loss: 0.55272035, Gradient norm: 28.96519387
INFO:root:At the start of the epoch: mem (CPU python)=43654.2578125MB; mem (CPU total)=75261.34375MB
INFO:root:[  136] Training loss: 0.55149049, Validation loss: 0.55252784, Gradient norm: 30.70727824
INFO:root:At the start of the epoch: mem (CPU python)=43675.421875MB; mem (CPU total)=75300.87109375MB
INFO:root:EP 136: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=43696.58984375MB; mem (CPU total)=75343.1875MB
INFO:root:[  138] Training loss: 0.63719140, Validation loss: 0.63713244, Gradient norm: 24.17560720
INFO:root:At the start of the epoch: mem (CPU python)=43717.75390625MB; mem (CPU total)=75385.86328125MB
INFO:root:[  139] Training loss: 0.63480818, Validation loss: 0.63515483, Gradient norm: 24.47058977
INFO:root:At the start of the epoch: mem (CPU python)=43738.91796875MB; mem (CPU total)=75428.21484375MB
INFO:root:[  140] Training loss: 0.63430491, Validation loss: 0.63492029, Gradient norm: 25.95154450
INFO:root:At the start of the epoch: mem (CPU python)=43760.08203125MB; mem (CPU total)=75471.03515625MB
INFO:root:[  141] Training loss: 0.63399355, Validation loss: 0.63485115, Gradient norm: 25.87159236
INFO:root:At the start of the epoch: mem (CPU python)=43781.24609375MB; mem (CPU total)=75514.90234375MB
INFO:root:[  142] Training loss: 0.63336398, Validation loss: 0.63393336, Gradient norm: 25.09253123
INFO:root:At the start of the epoch: mem (CPU python)=43802.40625MB; mem (CPU total)=75557.18359375MB
INFO:root:[  143] Training loss: 0.63276096, Validation loss: 0.63344038, Gradient norm: 25.65918201
INFO:root:At the start of the epoch: mem (CPU python)=43823.57421875MB; mem (CPU total)=75599.73046875MB
INFO:root:[  144] Training loss: 0.63273571, Validation loss: 0.63390047, Gradient norm: 26.97010011
INFO:root:At the start of the epoch: mem (CPU python)=43844.73828125MB; mem (CPU total)=75641.98046875MB
INFO:root:[  145] Training loss: 0.63298390, Validation loss: 0.63334964, Gradient norm: 26.53518798
INFO:root:At the start of the epoch: mem (CPU python)=43865.90234375MB; mem (CPU total)=75684.609375MB
INFO:root:[  146] Training loss: 0.63244994, Validation loss: 0.63336976, Gradient norm: 25.92456583
INFO:root:At the start of the epoch: mem (CPU python)=43887.06640625MB; mem (CPU total)=75726.67578125MB
INFO:root:[  147] Training loss: 0.63277867, Validation loss: 0.63329094, Gradient norm: 31.04585426
INFO:root:At the start of the epoch: mem (CPU python)=43908.23046875MB; mem (CPU total)=75769.25MB
INFO:root:[  148] Training loss: 0.63233434, Validation loss: 0.63256539, Gradient norm: 29.03618192
INFO:root:At the start of the epoch: mem (CPU python)=43929.3984375MB; mem (CPU total)=75811.80078125MB
INFO:root:[  149] Training loss: 0.63191657, Validation loss: 0.63120464, Gradient norm: 26.13387216
INFO:root:At the start of the epoch: mem (CPU python)=43950.5625MB; mem (CPU total)=75854.52734375MB
INFO:root:[  150] Training loss: 0.63197847, Validation loss: 0.63211403, Gradient norm: 28.97580005
INFO:root:At the start of the epoch: mem (CPU python)=43971.7265625MB; mem (CPU total)=75896.81640625MB
INFO:root:[  151] Training loss: 0.63175663, Validation loss: 0.63214566, Gradient norm: 26.85577044
INFO:root:At the start of the epoch: mem (CPU python)=43992.88671875MB; mem (CPU total)=75939.08203125MB
INFO:root:[  152] Training loss: 0.63134928, Validation loss: 0.63247751, Gradient norm: 30.59069970
INFO:root:At the start of the epoch: mem (CPU python)=44014.046875MB; mem (CPU total)=75981.58984375MB
INFO:root:[  153] Training loss: 0.63161701, Validation loss: 0.63273742, Gradient norm: 29.15921482
INFO:root:At the start of the epoch: mem (CPU python)=44035.21484375MB; mem (CPU total)=76023.8671875MB
INFO:root:[  154] Training loss: 0.63144188, Validation loss: 0.63289103, Gradient norm: 33.13975334
INFO:root:At the start of the epoch: mem (CPU python)=44056.37890625MB; mem (CPU total)=76067.1796875MB
INFO:root:[  155] Training loss: 0.63145951, Validation loss: 0.63228113, Gradient norm: 34.23553414
INFO:root:At the start of the epoch: mem (CPU python)=44077.54296875MB; mem (CPU total)=76110.72265625MB
INFO:root:[  156] Training loss: 0.63154701, Validation loss: 0.63161853, Gradient norm: 31.37304201
INFO:root:At the start of the epoch: mem (CPU python)=44098.70703125MB; mem (CPU total)=76153.19921875MB
INFO:root:[  157] Training loss: 0.63129496, Validation loss: 0.63223002, Gradient norm: 30.47852463
INFO:root:At the start of the epoch: mem (CPU python)=44119.87109375MB; mem (CPU total)=76197.234375MB
INFO:root:[  158] Training loss: 0.63106355, Validation loss: 0.63236533, Gradient norm: 33.28523001
INFO:root:At the start of the epoch: mem (CPU python)=44141.03515625MB; mem (CPU total)=76240.02734375MB
INFO:root:[  159] Training loss: 0.63089442, Validation loss: 0.63112833, Gradient norm: 33.32611985
INFO:root:At the start of the epoch: mem (CPU python)=44162.203125MB; mem (CPU total)=76282.42578125MB
INFO:root:[  160] Training loss: 0.63091496, Validation loss: 0.63150383, Gradient norm: 32.38426891
INFO:root:At the start of the epoch: mem (CPU python)=44183.36328125MB; mem (CPU total)=76327.4453125MB
INFO:root:[  161] Training loss: 0.63063241, Validation loss: 0.63127725, Gradient norm: 32.68168879
INFO:root:At the start of the epoch: mem (CPU python)=44204.52734375MB; mem (CPU total)=76370.3984375MB
INFO:root:[  162] Training loss: 0.63046549, Validation loss: 0.63062939, Gradient norm: 30.75572550
INFO:root:At the start of the epoch: mem (CPU python)=44225.69140625MB; mem (CPU total)=76417.328125MB
INFO:root:[  163] Training loss: 0.63052794, Validation loss: 0.63092471, Gradient norm: 34.97966072
INFO:root:At the start of the epoch: mem (CPU python)=44246.85546875MB; mem (CPU total)=76437.28125MB
INFO:root:[  164] Training loss: 0.63088963, Validation loss: 0.63134530, Gradient norm: 34.99955786
INFO:root:At the start of the epoch: mem (CPU python)=44268.01953125MB; mem (CPU total)=44113.2421875MB
INFO:root:[  165] Training loss: 0.63046403, Validation loss: 0.63091061, Gradient norm: 33.84400089
INFO:root:At the start of the epoch: mem (CPU python)=44289.18359375MB; mem (CPU total)=44133.75390625MB
INFO:root:[  166] Training loss: 0.63033462, Validation loss: 0.63076326, Gradient norm: 32.66044835
INFO:root:At the start of the epoch: mem (CPU python)=44310.3515625MB; mem (CPU total)=44152.9140625MB
INFO:root:[  167] Training loss: 0.63013706, Validation loss: 0.63080189, Gradient norm: 32.48660515
INFO:root:At the start of the epoch: mem (CPU python)=44331.515625MB; mem (CPU total)=44174.0625MB
INFO:root:[  168] Training loss: 0.62996441, Validation loss: 0.63108243, Gradient norm: 36.34220990
INFO:root:At the start of the epoch: mem (CPU python)=44352.67578125MB; mem (CPU total)=44194.9609375MB
INFO:root:[  169] Training loss: 0.63009596, Validation loss: 0.63140823, Gradient norm: 33.29917443
INFO:root:At the start of the epoch: mem (CPU python)=44373.83984375MB; mem (CPU total)=44215.859375MB
INFO:root:[  170] Training loss: 0.63002185, Validation loss: 0.63081598, Gradient norm: 36.88708589
INFO:root:At the start of the epoch: mem (CPU python)=44395.00390625MB; mem (CPU total)=44236.92578125MB
INFO:root:[  171] Training loss: 0.62985446, Validation loss: 0.63057763, Gradient norm: 32.43394109
INFO:root:At the start of the epoch: mem (CPU python)=44416.16796875MB; mem (CPU total)=44257.765625MB
INFO:root:[  172] Training loss: 0.62963070, Validation loss: 0.63018509, Gradient norm: 34.88600912
INFO:root:At the start of the epoch: mem (CPU python)=44437.33203125MB; mem (CPU total)=44279.31640625MB
INFO:root:[  173] Training loss: 0.62955544, Validation loss: 0.63005335, Gradient norm: 35.83735954
INFO:root:At the start of the epoch: mem (CPU python)=44458.49609375MB; mem (CPU total)=44299.765625MB
INFO:root:[  174] Training loss: 0.62972577, Validation loss: 0.62933930, Gradient norm: 33.78478192
INFO:root:At the start of the epoch: mem (CPU python)=44479.66015625MB; mem (CPU total)=44320.60546875MB
INFO:root:[  175] Training loss: 0.62925916, Validation loss: 0.63056497, Gradient norm: 35.46426695
INFO:root:At the start of the epoch: mem (CPU python)=44500.82421875MB; mem (CPU total)=44341.34765625MB
INFO:root:[  176] Training loss: 0.62962614, Validation loss: 0.62943495, Gradient norm: 37.36800647
INFO:root:At the start of the epoch: mem (CPU python)=44521.98828125MB; mem (CPU total)=44362.4140625MB
INFO:root:[  177] Training loss: 0.62923511, Validation loss: 0.62989133, Gradient norm: 35.73725266
INFO:root:At the start of the epoch: mem (CPU python)=44543.15625MB; mem (CPU total)=44383.51953125MB
INFO:root:[  178] Training loss: 0.62915964, Validation loss: 0.62979505, Gradient norm: 37.55879795
INFO:root:At the start of the epoch: mem (CPU python)=44564.3203125MB; mem (CPU total)=44404.33984375MB
INFO:root:[  179] Training loss: 0.62903779, Validation loss: 0.62915514, Gradient norm: 37.08791551
INFO:root:At the start of the epoch: mem (CPU python)=44585.484375MB; mem (CPU total)=44425.2421875MB
INFO:root:[  180] Training loss: 0.62940792, Validation loss: 0.62989494, Gradient norm: 38.86695369
INFO:root:At the start of the epoch: mem (CPU python)=44606.6484375MB; mem (CPU total)=44446.609375MB
INFO:root:[  181] Training loss: 0.62918106, Validation loss: 0.62910125, Gradient norm: 36.72357245
INFO:root:At the start of the epoch: mem (CPU python)=44627.81640625MB; mem (CPU total)=44467.7578125MB
INFO:root:[  182] Training loss: 0.62888557, Validation loss: 0.62942289, Gradient norm: 37.40112784
INFO:root:At the start of the epoch: mem (CPU python)=44648.9765625MB; mem (CPU total)=44488.8828125MB
INFO:root:[  183] Training loss: 0.62864934, Validation loss: 0.62911862, Gradient norm: 38.00100547
INFO:root:At the start of the epoch: mem (CPU python)=44670.14453125MB; mem (CPU total)=44509.6328125MB
INFO:root:[  184] Training loss: 0.62891971, Validation loss: 0.62882453, Gradient norm: 38.32501695
INFO:root:At the start of the epoch: mem (CPU python)=44691.30859375MB; mem (CPU total)=44530.78125MB
INFO:root:[  185] Training loss: 0.62834383, Validation loss: 0.63030885, Gradient norm: 36.45983181
INFO:root:At the start of the epoch: mem (CPU python)=44712.46875MB; mem (CPU total)=44551.90625MB
INFO:root:[  186] Training loss: 0.62883435, Validation loss: 0.62915514, Gradient norm: 40.79601209
INFO:root:At the start of the epoch: mem (CPU python)=44733.6328125MB; mem (CPU total)=44573.0703125MB
INFO:root:[  187] Training loss: 0.62867085, Validation loss: 0.63037505, Gradient norm: 39.76645353
INFO:root:At the start of the epoch: mem (CPU python)=44754.80078125MB; mem (CPU total)=44594.46875MB
INFO:root:[  188] Training loss: 0.62860414, Validation loss: 0.63004245, Gradient norm: 39.97997338
INFO:root:At the start of the epoch: mem (CPU python)=44775.96484375MB; mem (CPU total)=44616.60546875MB
INFO:root:[  189] Training loss: 0.62874689, Validation loss: 0.62862860, Gradient norm: 40.69935952
INFO:root:At the start of the epoch: mem (CPU python)=44797.13671875MB; mem (CPU total)=44637.82421875MB
INFO:root:[  190] Training loss: 0.62891392, Validation loss: 0.62886323, Gradient norm: 42.62742533
INFO:root:At the start of the epoch: mem (CPU python)=44818.30078125MB; mem (CPU total)=44659.42578125MB
INFO:root:[  191] Training loss: 0.62859596, Validation loss: 0.62933823, Gradient norm: 39.74765713
INFO:root:At the start of the epoch: mem (CPU python)=44839.46484375MB; mem (CPU total)=44680.56640625MB
INFO:root:[  192] Training loss: 0.62822055, Validation loss: 0.62817755, Gradient norm: 41.64372230
INFO:root:At the start of the epoch: mem (CPU python)=44860.62890625MB; mem (CPU total)=44701.92578125MB
INFO:root:[  193] Training loss: 0.62814825, Validation loss: 0.62822447, Gradient norm: 40.93483034
INFO:root:At the start of the epoch: mem (CPU python)=44881.79296875MB; mem (CPU total)=44723.08203125MB
INFO:root:[  194] Training loss: 0.62823557, Validation loss: 0.62881431, Gradient norm: 40.05074138
INFO:root:At the start of the epoch: mem (CPU python)=44902.95703125MB; mem (CPU total)=44744.515625MB
INFO:root:[  195] Training loss: 0.62814664, Validation loss: 0.62842316, Gradient norm: 41.35294362
INFO:root:At the start of the epoch: mem (CPU python)=44924.125MB; mem (CPU total)=44765.45703125MB
INFO:root:[  196] Training loss: 0.62789244, Validation loss: 0.62890211, Gradient norm: 41.96367754
INFO:root:At the start of the epoch: mem (CPU python)=44945.2890625MB; mem (CPU total)=44786.58984375MB
INFO:root:[  197] Training loss: 0.62803623, Validation loss: 0.62881058, Gradient norm: 41.93525404
INFO:root:At the start of the epoch: mem (CPU python)=44966.453125MB; mem (CPU total)=44808.21484375MB
INFO:root:[  198] Training loss: 0.62826471, Validation loss: 0.62851863, Gradient norm: 45.13640773
INFO:root:At the start of the epoch: mem (CPU python)=44987.62109375MB; mem (CPU total)=44829.28515625MB
INFO:root:[  199] Training loss: 0.62750286, Validation loss: 0.62800253, Gradient norm: 44.27617854
INFO:root:At the start of the epoch: mem (CPU python)=45008.78125MB; mem (CPU total)=44850.48828125MB
INFO:root:[  200] Training loss: 0.62760913, Validation loss: 0.62821581, Gradient norm: 43.66650823
INFO:root:At the start of the epoch: mem (CPU python)=45029.9453125MB; mem (CPU total)=44871.6484375MB
INFO:root:[  201] Training loss: 0.62765068, Validation loss: 0.62889203, Gradient norm: 44.43351747
INFO:root:At the start of the epoch: mem (CPU python)=45051.109375MB; mem (CPU total)=44892.80078125MB
INFO:root:[  202] Training loss: 0.62776159, Validation loss: 0.62952475, Gradient norm: 44.65551794
INFO:root:At the start of the epoch: mem (CPU python)=45072.26953125MB; mem (CPU total)=44913.8828125MB
INFO:root:[  203] Training loss: 0.62774083, Validation loss: 0.63007359, Gradient norm: 43.05593741
INFO:root:At the start of the epoch: mem (CPU python)=45093.43359375MB; mem (CPU total)=44935.27734375MB
INFO:root:[  204] Training loss: 0.62784157, Validation loss: 0.62861639, Gradient norm: 41.44371495
INFO:root:At the start of the epoch: mem (CPU python)=45114.59765625MB; mem (CPU total)=44956.44140625MB
INFO:root:[  205] Training loss: 0.62771395, Validation loss: 0.63009261, Gradient norm: 47.02375945
INFO:root:At the start of the epoch: mem (CPU python)=45135.765625MB; mem (CPU total)=44977.609375MB
INFO:root:[  206] Training loss: 0.62723192, Validation loss: 0.62771173, Gradient norm: 45.03722697
INFO:root:At the start of the epoch: mem (CPU python)=45156.9296875MB; mem (CPU total)=44998.84765625MB
INFO:root:[  207] Training loss: 0.62745620, Validation loss: 0.62815089, Gradient norm: 45.12636274
INFO:root:At the start of the epoch: mem (CPU python)=45178.09375MB; mem (CPU total)=45019.76171875MB
INFO:root:[  208] Training loss: 0.62752365, Validation loss: 0.62806596, Gradient norm: 49.93947424
INFO:root:At the start of the epoch: mem (CPU python)=45199.25390625MB; mem (CPU total)=45041.546875MB
INFO:root:[  209] Training loss: 0.62691004, Validation loss: 0.62814938, Gradient norm: 44.31733072
INFO:root:At the start of the epoch: mem (CPU python)=45220.41796875MB; mem (CPU total)=45062.30859375MB
INFO:root:[  210] Training loss: 0.62703903, Validation loss: 0.62712727, Gradient norm: 44.86555600
INFO:root:At the start of the epoch: mem (CPU python)=45241.5859375MB; mem (CPU total)=45083.640625MB
INFO:root:[  211] Training loss: 0.62730072, Validation loss: 0.62812995, Gradient norm: 47.91569747
INFO:root:At the start of the epoch: mem (CPU python)=45262.74609375MB; mem (CPU total)=45104.8359375MB
INFO:root:[  212] Training loss: 0.62716080, Validation loss: 0.62733133, Gradient norm: 45.63274082
INFO:root:At the start of the epoch: mem (CPU python)=45283.9140625MB; mem (CPU total)=45126.07421875MB
INFO:root:[  213] Training loss: 0.62719796, Validation loss: 0.62781718, Gradient norm: 47.65499865
INFO:root:At the start of the epoch: mem (CPU python)=45305.078125MB; mem (CPU total)=45148.46484375MB
INFO:root:[  214] Training loss: 0.62694006, Validation loss: 0.62781288, Gradient norm: 46.51055985
INFO:root:At the start of the epoch: mem (CPU python)=45326.2421875MB; mem (CPU total)=45149.890625MB
INFO:root:[  215] Training loss: 0.62697199, Validation loss: 0.62707563, Gradient norm: 48.11247754
INFO:root:At the start of the epoch: mem (CPU python)=45347.41015625MB; mem (CPU total)=45171.91796875MB
INFO:root:[  216] Training loss: 0.62687790, Validation loss: 0.62794614, Gradient norm: 49.96865416
INFO:root:At the start of the epoch: mem (CPU python)=45368.5703125MB; mem (CPU total)=45195.26953125MB
INFO:root:[  217] Training loss: 0.62700197, Validation loss: 0.62785655, Gradient norm: 47.64494742
INFO:root:At the start of the epoch: mem (CPU python)=45389.73828125MB; mem (CPU total)=45217.5703125MB
INFO:root:[  218] Training loss: 0.62642852, Validation loss: 0.62637854, Gradient norm: 45.59149805
INFO:root:At the start of the epoch: mem (CPU python)=45410.8984375MB; mem (CPU total)=45238.8671875MB
INFO:root:[  219] Training loss: 0.62670477, Validation loss: 0.62761638, Gradient norm: 49.36603406
INFO:root:At the start of the epoch: mem (CPU python)=45432.05859375MB; mem (CPU total)=45261.3359375MB
INFO:root:[  220] Training loss: 0.62683636, Validation loss: 0.62749872, Gradient norm: 48.67835603
INFO:root:At the start of the epoch: mem (CPU python)=45453.22265625MB; mem (CPU total)=45281.80859375MB
INFO:root:[  221] Training loss: 0.62705319, Validation loss: 0.62626459, Gradient norm: 49.87550371
INFO:root:At the start of the epoch: mem (CPU python)=45474.390625MB; mem (CPU total)=45303.79296875MB
INFO:root:[  222] Training loss: 0.62674701, Validation loss: 0.62710504, Gradient norm: 49.65850243
INFO:root:At the start of the epoch: mem (CPU python)=45495.55078125MB; mem (CPU total)=45325.01953125MB
INFO:root:[  223] Training loss: 0.62641226, Validation loss: 0.62729582, Gradient norm: 48.53922155
INFO:root:At the start of the epoch: mem (CPU python)=45516.71875MB; mem (CPU total)=45346.5390625MB
INFO:root:[  224] Training loss: 0.62657665, Validation loss: 0.62569787, Gradient norm: 51.13053744
INFO:root:At the start of the epoch: mem (CPU python)=45537.8828125MB; mem (CPU total)=45367.76171875MB
INFO:root:[  225] Training loss: 0.62661462, Validation loss: 0.62716609, Gradient norm: 47.93954710
INFO:root:At the start of the epoch: mem (CPU python)=45559.046875MB; mem (CPU total)=45388.66015625MB
INFO:root:[  226] Training loss: 0.62632731, Validation loss: 0.62687180, Gradient norm: 49.22130875
INFO:root:At the start of the epoch: mem (CPU python)=45580.2109375MB; mem (CPU total)=45409.92578125MB
INFO:root:[  227] Training loss: 0.62617774, Validation loss: 0.62719058, Gradient norm: 47.85713943
INFO:root:At the start of the epoch: mem (CPU python)=45601.37109375MB; mem (CPU total)=45648.140625MB
INFO:root:[  228] Training loss: 0.62606836, Validation loss: 0.62700704, Gradient norm: 48.19592559
INFO:root:At the start of the epoch: mem (CPU python)=45622.5390625MB; mem (CPU total)=48967.89453125MB
INFO:root:[  229] Training loss: 0.62619762, Validation loss: 0.62621063, Gradient norm: 51.29514138
INFO:root:At the start of the epoch: mem (CPU python)=45643.703125MB; mem (CPU total)=49022.328125MB
INFO:root:[  230] Training loss: 0.62601771, Validation loss: 0.62735855, Gradient norm: 51.53760099
INFO:root:At the start of the epoch: mem (CPU python)=45664.8671875MB; mem (CPU total)=49077.70703125MB
INFO:root:[  231] Training loss: 0.62599347, Validation loss: 0.62555180, Gradient norm: 52.38244957
INFO:root:At the start of the epoch: mem (CPU python)=45686.03515625MB; mem (CPU total)=49132.984375MB
INFO:root:[  232] Training loss: 0.62591814, Validation loss: 0.62736663, Gradient norm: 48.56854186
INFO:root:At the start of the epoch: mem (CPU python)=45707.1953125MB; mem (CPU total)=49186.05859375MB
INFO:root:[  233] Training loss: 0.62626843, Validation loss: 0.62739867, Gradient norm: 53.31606903
INFO:root:At the start of the epoch: mem (CPU python)=45728.36328125MB; mem (CPU total)=49242.9296875MB
INFO:root:[  234] Training loss: 0.62625413, Validation loss: 0.62660764, Gradient norm: 53.48055414
INFO:root:At the start of the epoch: mem (CPU python)=45749.52734375MB; mem (CPU total)=49296.09375MB
INFO:root:[  235] Training loss: 0.62603223, Validation loss: 0.62684859, Gradient norm: 52.68603492
INFO:root:At the start of the epoch: mem (CPU python)=45770.69140625MB; mem (CPU total)=49348.6015625MB
INFO:root:[  236] Training loss: 0.62589748, Validation loss: 0.62609315, Gradient norm: 52.87523463
INFO:root:At the start of the epoch: mem (CPU python)=45791.84765625MB; mem (CPU total)=49405.6953125MB
INFO:root:[  237] Training loss: 0.62580768, Validation loss: 0.62735015, Gradient norm: 49.68475566
INFO:root:At the start of the epoch: mem (CPU python)=45813.01171875MB; mem (CPU total)=49458.46484375MB
INFO:root:[  238] Training loss: 0.62559983, Validation loss: 0.62772856, Gradient norm: 52.39871625
INFO:root:At the start of the epoch: mem (CPU python)=45834.17578125MB; mem (CPU total)=49512.8515625MB
INFO:root:[  239] Training loss: 0.62587570, Validation loss: 0.62655946, Gradient norm: 51.20190664
INFO:root:At the start of the epoch: mem (CPU python)=45855.34375MB; mem (CPU total)=49566.44921875MB
INFO:root:[  240] Training loss: 0.62596199, Validation loss: 0.62792067, Gradient norm: 52.50231306
INFO:root:At the start of the epoch: mem (CPU python)=45876.5078125MB; mem (CPU total)=49621.51953125MB
INFO:root:EP 240: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=45897.671875MB; mem (CPU total)=49657.23046875MB
INFO:root:Training the model took 17160.684s.
INFO:root:Emptying the cuda cache took 0.063s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.61857
INFO:root:EnergyScoreValidation: 0.49065
INFO:root:CRPSValidation: 0.19462
INFO:root:Gaussian NLLValidation: 1.46993
INFO:root:CoverageValidation: 0.66214
INFO:root:IntervalWidthValidation: 0.51869
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.48777
INFO:root:EnergyScoreTest: 0.3646
INFO:root:CRPSTest: 0.14361
INFO:root:Gaussian NLLTest: 0.2149
INFO:root:CoverageTest: 0.80801
INFO:root:IntervalWidthTest: 0.57852
INFO:root:After validation: mem (CPU python)=46203.62109375MB; mem (CPU total)=49807.84375MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=46203.62109375MB; mem (CPU total)=49824.71875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 297795584
INFO:root:After setting up the model: mem (CPU python)=46203.62109375MB; mem (CPU total)=49824.71875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=49841.8203125MB
INFO:root:[    1] Training loss: 0.88003774, Validation loss: 0.77007140, Gradient norm: 0.32130336
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=49889.203125MB
INFO:root:[    2] Training loss: 0.76309241, Validation loss: 0.76259121, Gradient norm: 0.35316114
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=49938.7109375MB
INFO:root:[    3] Training loss: 0.75734745, Validation loss: 0.75389671, Gradient norm: 0.52509317
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=49987.98046875MB
INFO:root:[    4] Training loss: 0.75266114, Validation loss: 0.74864431, Gradient norm: 0.92072327
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50035.21875MB
INFO:root:[    5] Training loss: 0.74329576, Validation loss: 0.73270855, Gradient norm: 1.15932673
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50082.921875MB
INFO:root:[    6] Training loss: 0.73149512, Validation loss: 0.72763390, Gradient norm: 1.65355110
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50132.50390625MB
INFO:root:[    7] Training loss: 0.72472816, Validation loss: 0.72120670, Gradient norm: 1.90733692
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50180.7109375MB
INFO:root:[    8] Training loss: 0.72261261, Validation loss: 0.71290122, Gradient norm: 2.21453393
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50229.171875MB
INFO:root:[    9] Training loss: 0.71449734, Validation loss: 0.71750403, Gradient norm: 2.15724325
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50277.05859375MB
INFO:root:[   10] Training loss: 0.71039115, Validation loss: 0.70746773, Gradient norm: 2.59283797
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50327.0625MB
INFO:root:[   11] Training loss: 0.70859343, Validation loss: 0.70987269, Gradient norm: 2.81532361
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50374.87109375MB
INFO:root:[   12] Training loss: 0.70298322, Validation loss: 0.68268061, Gradient norm: 2.86293650
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50422.5859375MB
INFO:root:[   13] Training loss: 0.70039385, Validation loss: 0.69684381, Gradient norm: 3.32804488
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50472.45703125MB
INFO:root:[   14] Training loss: 0.69431501, Validation loss: 0.69183246, Gradient norm: 3.16273104
INFO:root:At the start of the epoch: mem (CPU python)=46203.62109375MB; mem (CPU total)=50520.46484375MB
INFO:root:[   15] Training loss: 0.69711133, Validation loss: 0.68799393, Gradient norm: 3.62457129
INFO:root:At the start of the epoch: mem (CPU python)=46221.859375MB; mem (CPU total)=50568.75MB
INFO:root:[   16] Training loss: 0.69939902, Validation loss: 0.71126789, Gradient norm: 3.85539397
INFO:root:At the start of the epoch: mem (CPU python)=46243.0234375MB; mem (CPU total)=50617.52734375MB
INFO:root:[   17] Training loss: 0.69409399, Validation loss: 0.69385603, Gradient norm: 3.71412990
INFO:root:At the start of the epoch: mem (CPU python)=46264.1875MB; mem (CPU total)=50665.79296875MB
INFO:root:[   18] Training loss: 0.68616272, Validation loss: 0.68071381, Gradient norm: 3.32710516
INFO:root:At the start of the epoch: mem (CPU python)=46285.35546875MB; mem (CPU total)=50713.8125MB
INFO:root:[   19] Training loss: 0.69295634, Validation loss: 0.68528404, Gradient norm: 4.17216196
INFO:root:At the start of the epoch: mem (CPU python)=46306.51953125MB; mem (CPU total)=50762.31640625MB
INFO:root:[   20] Training loss: 0.69169383, Validation loss: 0.73384517, Gradient norm: 4.36426018
INFO:root:At the start of the epoch: mem (CPU python)=46327.68359375MB; mem (CPU total)=50811.83984375MB
INFO:root:[   21] Training loss: 0.69276344, Validation loss: 0.68752792, Gradient norm: 4.59562625
INFO:root:At the start of the epoch: mem (CPU python)=46348.84765625MB; mem (CPU total)=50860.3515625MB
INFO:root:[   22] Training loss: 0.68890238, Validation loss: 0.66261270, Gradient norm: 4.41827522
INFO:root:At the start of the epoch: mem (CPU python)=46370.01171875MB; mem (CPU total)=50908.97265625MB
INFO:root:[   23] Training loss: 0.68901159, Validation loss: 0.69785365, Gradient norm: 4.72080737
INFO:root:At the start of the epoch: mem (CPU python)=46391.171875MB; mem (CPU total)=50958.51171875MB
INFO:root:[   24] Training loss: 0.68542701, Validation loss: 0.68509834, Gradient norm: 4.60838419
INFO:root:At the start of the epoch: mem (CPU python)=46412.33984375MB; mem (CPU total)=51006.1484375MB
INFO:root:[   25] Training loss: 0.68545737, Validation loss: 0.70425392, Gradient norm: 4.92793912
INFO:root:At the start of the epoch: mem (CPU python)=46433.5078125MB; mem (CPU total)=51054.71875MB
INFO:root:[   26] Training loss: 0.68581164, Validation loss: 0.69414032, Gradient norm: 5.10181594
INFO:root:At the start of the epoch: mem (CPU python)=46454.671875MB; mem (CPU total)=51102.27734375MB
INFO:root:[   27] Training loss: 0.69464747, Validation loss: 0.74502559, Gradient norm: 5.69233052
INFO:root:At the start of the epoch: mem (CPU python)=46475.8359375MB; mem (CPU total)=51151.9921875MB
INFO:root:[   28] Training loss: 0.68820183, Validation loss: 0.68290357, Gradient norm: 5.37838109
INFO:root:At the start of the epoch: mem (CPU python)=46497.00390625MB; mem (CPU total)=51201.390625MB
INFO:root:[   29] Training loss: 0.67853699, Validation loss: 0.67019405, Gradient norm: 4.95219410
INFO:root:At the start of the epoch: mem (CPU python)=46518.16796875MB; mem (CPU total)=51249.8671875MB
INFO:root:[   30] Training loss: 0.68285350, Validation loss: 0.67286658, Gradient norm: 5.40111089
INFO:root:At the start of the epoch: mem (CPU python)=46539.328125MB; mem (CPU total)=51299.09375MB
INFO:root:[   31] Training loss: 0.68402882, Validation loss: 0.67279008, Gradient norm: 5.90566857
INFO:root:At the start of the epoch: mem (CPU python)=46560.4921875MB; mem (CPU total)=51347.2734375MB
INFO:root:[   32] Training loss: 0.68811241, Validation loss: 0.68838277, Gradient norm: 6.48987428
INFO:root:At the start of the epoch: mem (CPU python)=46581.65234375MB; mem (CPU total)=51395.52734375MB
INFO:root:[   33] Training loss: 0.68496136, Validation loss: 0.66802457, Gradient norm: 6.14494882
INFO:root:At the start of the epoch: mem (CPU python)=46602.81640625MB; mem (CPU total)=51443.73828125MB
INFO:root:[   34] Training loss: 0.68221222, Validation loss: 0.69079252, Gradient norm: 6.13510546
INFO:root:At the start of the epoch: mem (CPU python)=46623.984375MB; mem (CPU total)=51492.9453125MB
INFO:root:[   35] Training loss: 0.68028638, Validation loss: 0.73843984, Gradient norm: 6.36827102
INFO:root:At the start of the epoch: mem (CPU python)=46645.1484375MB; mem (CPU total)=51541.125MB
INFO:root:[   36] Training loss: 0.68692077, Validation loss: 0.68955183, Gradient norm: 6.92081207
INFO:root:At the start of the epoch: mem (CPU python)=46666.3125MB; mem (CPU total)=51590.12890625MB
INFO:root:[   37] Training loss: 0.68722286, Validation loss: 0.69888593, Gradient norm: 7.10385234
INFO:root:At the start of the epoch: mem (CPU python)=46687.4765625MB; mem (CPU total)=51639.5078125MB
INFO:root:[   38] Training loss: 0.67622232, Validation loss: 0.65850496, Gradient norm: 6.86227099
INFO:root:At the start of the epoch: mem (CPU python)=46708.64453125MB; mem (CPU total)=51689.25MB
INFO:root:[   39] Training loss: 0.67159850, Validation loss: 0.67515719, Gradient norm: 6.45758749
INFO:root:At the start of the epoch: mem (CPU python)=46729.8046875MB; mem (CPU total)=51738.7890625MB
INFO:root:[   40] Training loss: 0.67380036, Validation loss: 0.68216274, Gradient norm: 6.92420769
INFO:root:At the start of the epoch: mem (CPU python)=46750.97265625MB; mem (CPU total)=51788.65625MB
INFO:root:[   41] Training loss: 0.66873138, Validation loss: 0.67799195, Gradient norm: 6.67135038
INFO:root:At the start of the epoch: mem (CPU python)=46772.1328125MB; mem (CPU total)=51836.6875MB
INFO:root:[   42] Training loss: 0.67538296, Validation loss: 0.67643090, Gradient norm: 7.40475645
INFO:root:At the start of the epoch: mem (CPU python)=46793.296875MB; mem (CPU total)=51885.046875MB
INFO:root:[   43] Training loss: 0.67646055, Validation loss: 0.65222413, Gradient norm: 7.23743508
INFO:root:At the start of the epoch: mem (CPU python)=46814.4609375MB; mem (CPU total)=51933.77734375MB
INFO:root:[   44] Training loss: 0.67277076, Validation loss: 0.67245154, Gradient norm: 7.00118275
INFO:root:At the start of the epoch: mem (CPU python)=46835.625MB; mem (CPU total)=51982.51953125MB
INFO:root:[   45] Training loss: 0.67332852, Validation loss: 0.68330258, Gradient norm: 7.59726855
INFO:root:At the start of the epoch: mem (CPU python)=46856.79296875MB; mem (CPU total)=52030.44921875MB
INFO:root:[   46] Training loss: 0.66188815, Validation loss: 0.67357060, Gradient norm: 6.65456791
INFO:root:At the start of the epoch: mem (CPU python)=46877.95703125MB; mem (CPU total)=52079.1171875MB
INFO:root:[   47] Training loss: 0.66810555, Validation loss: 0.65232690, Gradient norm: 7.61663468
INFO:root:At the start of the epoch: mem (CPU python)=46899.1171875MB; mem (CPU total)=52128.71484375MB
INFO:root:[   48] Training loss: 0.66099427, Validation loss: 0.65163600, Gradient norm: 6.90033772
INFO:root:At the start of the epoch: mem (CPU python)=46920.28515625MB; mem (CPU total)=52176.71875MB
INFO:root:[   49] Training loss: 0.68545853, Validation loss: 0.64965106, Gradient norm: 9.12724033
INFO:root:At the start of the epoch: mem (CPU python)=46941.4453125MB; mem (CPU total)=52224.9375MB
INFO:root:[   50] Training loss: 0.67475141, Validation loss: 0.65140024, Gradient norm: 8.04195876
INFO:root:At the start of the epoch: mem (CPU python)=46962.60546875MB; mem (CPU total)=52275.109375MB
INFO:root:[   51] Training loss: 0.66758737, Validation loss: 0.65458058, Gradient norm: 7.64813625
INFO:root:At the start of the epoch: mem (CPU python)=46983.7734375MB; mem (CPU total)=52322.890625MB
INFO:root:[   52] Training loss: 0.66184046, Validation loss: 0.68528770, Gradient norm: 7.04660064
INFO:root:At the start of the epoch: mem (CPU python)=47004.9375MB; mem (CPU total)=52370.78125MB
INFO:root:[   53] Training loss: 0.66815886, Validation loss: 0.64877198, Gradient norm: 8.20969093
INFO:root:At the start of the epoch: mem (CPU python)=47026.10546875MB; mem (CPU total)=52418.75MB
INFO:root:[   54] Training loss: 0.66922442, Validation loss: 0.67970382, Gradient norm: 8.59527326
INFO:root:At the start of the epoch: mem (CPU python)=47047.26953125MB; mem (CPU total)=52468.6796875MB
INFO:root:[   55] Training loss: 0.66956941, Validation loss: 0.65105406, Gradient norm: 8.40470708
INFO:root:At the start of the epoch: mem (CPU python)=47068.43359375MB; mem (CPU total)=52517.578125MB
INFO:root:[   56] Training loss: 0.66219503, Validation loss: 0.66555604, Gradient norm: 8.06606510
INFO:root:At the start of the epoch: mem (CPU python)=47089.6015625MB; mem (CPU total)=52566.2578125MB
INFO:root:[   57] Training loss: 0.67370955, Validation loss: 0.66551681, Gradient norm: 9.10861395
INFO:root:At the start of the epoch: mem (CPU python)=47110.765625MB; mem (CPU total)=52617.16796875MB
INFO:root:[   58] Training loss: 0.66517698, Validation loss: 0.64416458, Gradient norm: 8.97072548
INFO:root:At the start of the epoch: mem (CPU python)=47131.9296875MB; mem (CPU total)=52666.3203125MB
INFO:root:[   59] Training loss: 0.66492500, Validation loss: 0.67482996, Gradient norm: 8.76141864
INFO:root:At the start of the epoch: mem (CPU python)=47153.09375MB; mem (CPU total)=52714.79296875MB
INFO:root:[   60] Training loss: 0.65912450, Validation loss: 0.64677998, Gradient norm: 7.97206056
INFO:root:At the start of the epoch: mem (CPU python)=47174.25390625MB; mem (CPU total)=52764.26171875MB
INFO:root:[   61] Training loss: 0.66761381, Validation loss: 0.65399228, Gradient norm: 9.58084627
INFO:root:At the start of the epoch: mem (CPU python)=47195.41796875MB; mem (CPU total)=52812.75390625MB
INFO:root:[   62] Training loss: 0.67041913, Validation loss: 0.66581923, Gradient norm: 9.18226448
INFO:root:At the start of the epoch: mem (CPU python)=47216.5859375MB; mem (CPU total)=52860.93359375MB
INFO:root:[   63] Training loss: 0.66227502, Validation loss: 0.69113542, Gradient norm: 8.28102337
INFO:root:At the start of the epoch: mem (CPU python)=47237.75MB; mem (CPU total)=52908.86328125MB
INFO:root:[   64] Training loss: 0.66724497, Validation loss: 0.68232601, Gradient norm: 9.11426628
INFO:root:At the start of the epoch: mem (CPU python)=47258.91015625MB; mem (CPU total)=52958.33203125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   65] Training loss: 0.66984834, Validation loss: 0.69063062, Gradient norm: 8.84670654
INFO:root:At the start of the epoch: mem (CPU python)=47280.07421875MB; mem (CPU total)=53005.5234375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   66] Training loss: 0.62545892, Validation loss: 0.62130868, Gradient norm: 6.33431921
INFO:root:At the start of the epoch: mem (CPU python)=47301.23828125MB; mem (CPU total)=53053.734375MB
INFO:root:[   67] Training loss: 0.61276480, Validation loss: 0.61320994, Gradient norm: 5.38462627
INFO:root:At the start of the epoch: mem (CPU python)=47322.40234375MB; mem (CPU total)=53104.15234375MB
INFO:root:[   68] Training loss: 0.61158186, Validation loss: 0.61346776, Gradient norm: 6.48277456
INFO:root:At the start of the epoch: mem (CPU python)=47343.5703125MB; mem (CPU total)=53151.3671875MB
INFO:root:[   69] Training loss: 0.61256623, Validation loss: 0.61399730, Gradient norm: 7.52255594
INFO:root:At the start of the epoch: mem (CPU python)=47364.73046875MB; mem (CPU total)=53200.0234375MB
INFO:root:[   70] Training loss: 0.61499668, Validation loss: 0.60873535, Gradient norm: 8.29683478
INFO:root:At the start of the epoch: mem (CPU python)=47385.89453125MB; mem (CPU total)=53249.04296875MB
INFO:root:[   71] Training loss: 0.61312931, Validation loss: 0.62733261, Gradient norm: 8.63890002
INFO:root:At the start of the epoch: mem (CPU python)=47407.05859375MB; mem (CPU total)=53298.17578125MB
INFO:root:[   72] Training loss: 0.61497458, Validation loss: 0.61165701, Gradient norm: 9.65902980
INFO:root:At the start of the epoch: mem (CPU python)=47428.22265625MB; mem (CPU total)=53346.109375MB
INFO:root:[   73] Training loss: 0.61911508, Validation loss: 0.62631136, Gradient norm: 10.94384272
INFO:root:At the start of the epoch: mem (CPU python)=47449.390625MB; mem (CPU total)=53394.54296875MB
INFO:root:[   74] Training loss: 0.61654207, Validation loss: 0.62898085, Gradient norm: 11.01334105
INFO:root:At the start of the epoch: mem (CPU python)=47470.5546875MB; mem (CPU total)=53420.41796875MB
INFO:root:[   75] Training loss: 0.61788537, Validation loss: 0.62644344, Gradient norm: 12.05940664
INFO:root:At the start of the epoch: mem (CPU python)=47491.71875MB; mem (CPU total)=53470.73828125MB
INFO:root:[   76] Training loss: 0.62015670, Validation loss: 0.62324011, Gradient norm: 12.75238389
INFO:root:At the start of the epoch: mem (CPU python)=47512.8828125MB; mem (CPU total)=53517.7734375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 0.61924940, Validation loss: 0.62387111, Gradient norm: 13.08574078
INFO:root:At the start of the epoch: mem (CPU python)=47534.046875MB; mem (CPU total)=53567.90234375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 0.61070990, Validation loss: 0.61188898, Gradient norm: 9.43601725
INFO:root:At the start of the epoch: mem (CPU python)=47555.21484375MB; mem (CPU total)=53615.74609375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   79] Training loss: 0.60423282, Validation loss: 0.60470242, Gradient norm: 6.40577313
INFO:root:At the start of the epoch: mem (CPU python)=47576.375MB; mem (CPU total)=53662.15625MB
INFO:root:[   80] Training loss: 0.60273625, Validation loss: 0.60261452, Gradient norm: 4.46712525
INFO:root:At the start of the epoch: mem (CPU python)=47597.5390625MB; mem (CPU total)=53710.1328125MB
INFO:root:[   81] Training loss: 0.60215799, Validation loss: 0.60245182, Gradient norm: 5.47230127
INFO:root:At the start of the epoch: mem (CPU python)=47618.703125MB; mem (CPU total)=53761.65234375MB
INFO:root:[   82] Training loss: 0.60181437, Validation loss: 0.60288859, Gradient norm: 5.52305966
INFO:root:At the start of the epoch: mem (CPU python)=47639.86328125MB; mem (CPU total)=53809.17578125MB
INFO:root:[   83] Training loss: 0.60123534, Validation loss: 0.60232413, Gradient norm: 5.61286908
INFO:root:At the start of the epoch: mem (CPU python)=47661.03125MB; mem (CPU total)=53858.03125MB
INFO:root:[   84] Training loss: 0.60112206, Validation loss: 0.60299067, Gradient norm: 7.59174532
INFO:root:At the start of the epoch: mem (CPU python)=47682.1953125MB; mem (CPU total)=53906.29296875MB
INFO:root:[   85] Training loss: 0.60170163, Validation loss: 0.60280585, Gradient norm: 10.01257883
INFO:root:At the start of the epoch: mem (CPU python)=47703.359375MB; mem (CPU total)=53954.1171875MB
INFO:root:[   86] Training loss: 0.60113866, Validation loss: 0.60138707, Gradient norm: 7.58471032
INFO:root:At the start of the epoch: mem (CPU python)=47724.5234375MB; mem (CPU total)=54004.4296875MB
INFO:root:[   87] Training loss: 0.60083363, Validation loss: 0.60221240, Gradient norm: 6.84066062
INFO:root:At the start of the epoch: mem (CPU python)=47745.6875MB; mem (CPU total)=54050.3515625MB
INFO:root:[   88] Training loss: 0.60082580, Validation loss: 0.60326369, Gradient norm: 8.28538407
INFO:root:At the start of the epoch: mem (CPU python)=47766.828125MB; mem (CPU total)=54099.5390625MB
INFO:root:[   89] Training loss: 0.60073827, Validation loss: 0.60166220, Gradient norm: 7.59417703
INFO:root:At the start of the epoch: mem (CPU python)=47787.984375MB; mem (CPU total)=54147.8984375MB
INFO:root:[   90] Training loss: 0.60052200, Validation loss: 0.60294434, Gradient norm: 7.57273989
INFO:root:At the start of the epoch: mem (CPU python)=47809.15234375MB; mem (CPU total)=54193.16015625MB
INFO:root:[   91] Training loss: 0.60057625, Validation loss: 0.60133975, Gradient norm: 8.48751277
INFO:root:At the start of the epoch: mem (CPU python)=47830.31640625MB; mem (CPU total)=54232.3046875MB
INFO:root:[   92] Training loss: 0.60105730, Validation loss: 0.60179637, Gradient norm: 11.52180822
INFO:root:At the start of the epoch: mem (CPU python)=47851.48046875MB; mem (CPU total)=54263.90234375MB
INFO:root:[   93] Training loss: 0.60085854, Validation loss: 0.60235226, Gradient norm: 11.83687254
INFO:root:At the start of the epoch: mem (CPU python)=47872.64453125MB; mem (CPU total)=54300.88671875MB
INFO:root:[   94] Training loss: 0.60036361, Validation loss: 0.60288609, Gradient norm: 9.87736202
INFO:root:At the start of the epoch: mem (CPU python)=47893.80859375MB; mem (CPU total)=54337.79296875MB
INFO:root:[   95] Training loss: 0.60019312, Validation loss: 0.60110757, Gradient norm: 9.77062896
INFO:root:At the start of the epoch: mem (CPU python)=47914.9765625MB; mem (CPU total)=54375.515625MB
INFO:root:[   96] Training loss: 0.60012756, Validation loss: 0.60154975, Gradient norm: 10.04994635
INFO:root:At the start of the epoch: mem (CPU python)=47936.140625MB; mem (CPU total)=54411.37109375MB
INFO:root:[   97] Training loss: 0.60024517, Validation loss: 0.60049572, Gradient norm: 10.90776973
INFO:root:At the start of the epoch: mem (CPU python)=47957.30078125MB; mem (CPU total)=54449.94140625MB
INFO:root:[   98] Training loss: 0.60014282, Validation loss: 0.60243873, Gradient norm: 10.65961702
INFO:root:At the start of the epoch: mem (CPU python)=47978.4609375MB; mem (CPU total)=54482.78125MB
INFO:root:[   99] Training loss: 0.60053961, Validation loss: 0.60259458, Gradient norm: 12.01676587
INFO:root:At the start of the epoch: mem (CPU python)=47999.625MB; mem (CPU total)=54523.0MB
INFO:root:[  100] Training loss: 0.60005671, Validation loss: 0.60157313, Gradient norm: 11.85678220
INFO:root:At the start of the epoch: mem (CPU python)=48020.7890625MB; mem (CPU total)=54560.16015625MB
INFO:root:[  101] Training loss: 0.60021434, Validation loss: 0.60104676, Gradient norm: 12.73339448
INFO:root:At the start of the epoch: mem (CPU python)=48041.95703125MB; mem (CPU total)=54594.98046875MB
INFO:root:[  102] Training loss: 0.60040433, Validation loss: 0.60120222, Gradient norm: 12.70443697
INFO:root:At the start of the epoch: mem (CPU python)=48063.12109375MB; mem (CPU total)=54631.8828125MB
INFO:root:[  103] Training loss: 0.60012465, Validation loss: 0.60188129, Gradient norm: 13.17978106
INFO:root:At the start of the epoch: mem (CPU python)=48084.28515625MB; mem (CPU total)=54667.1953125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  104] Training loss: 0.59983476, Validation loss: 0.60142267, Gradient norm: 13.32901429
INFO:root:At the start of the epoch: mem (CPU python)=48105.44921875MB; mem (CPU total)=54703.93359375MB
INFO:root:[  105] Training loss: 0.59895638, Validation loss: 0.60242966, Gradient norm: 9.89104215
INFO:root:At the start of the epoch: mem (CPU python)=48126.61328125MB; mem (CPU total)=54739.6875MB
INFO:root:[  106] Training loss: 0.59891267, Validation loss: 0.60005435, Gradient norm: 9.77865604
INFO:root:At the start of the epoch: mem (CPU python)=48147.78125MB; mem (CPU total)=54777.51171875MB
INFO:root:[  107] Training loss: 0.59893161, Validation loss: 0.60022887, Gradient norm: 9.48022872
INFO:root:At the start of the epoch: mem (CPU python)=48168.9375MB; mem (CPU total)=54811.82421875MB
INFO:root:[  108] Training loss: 0.59859547, Validation loss: 0.60227516, Gradient norm: 9.89166943
INFO:root:At the start of the epoch: mem (CPU python)=48190.10546875MB; mem (CPU total)=54847.72265625MB
INFO:root:[  109] Training loss: 0.59909969, Validation loss: 0.59943091, Gradient norm: 10.42806162
INFO:root:At the start of the epoch: mem (CPU python)=48211.26953125MB; mem (CPU total)=54890.875MB
INFO:root:[  110] Training loss: 0.59891451, Validation loss: 0.59922302, Gradient norm: 11.83657770
INFO:root:At the start of the epoch: mem (CPU python)=48232.43359375MB; mem (CPU total)=54927.8515625MB
INFO:root:[  111] Training loss: 0.59876593, Validation loss: 0.59942357, Gradient norm: 11.97127501
INFO:root:At the start of the epoch: mem (CPU python)=48253.6015625MB; mem (CPU total)=54961.796875MB
INFO:root:[  112] Training loss: 0.59845003, Validation loss: 0.60000251, Gradient norm: 11.46108564
INFO:root:At the start of the epoch: mem (CPU python)=48274.765625MB; mem (CPU total)=54997.3515625MB
INFO:root:[  113] Training loss: 0.59857672, Validation loss: 0.59982521, Gradient norm: 12.39325749
INFO:root:At the start of the epoch: mem (CPU python)=48295.93359375MB; mem (CPU total)=55034.55859375MB
INFO:root:[  114] Training loss: 0.59888271, Validation loss: 0.59943883, Gradient norm: 15.26894987
INFO:root:At the start of the epoch: mem (CPU python)=48317.09765625MB; mem (CPU total)=55068.9296875MB
INFO:root:[  115] Training loss: 0.59860249, Validation loss: 0.60050366, Gradient norm: 12.04061262
INFO:root:At the start of the epoch: mem (CPU python)=48338.2578125MB; mem (CPU total)=55105.80078125MB
INFO:root:[  116] Training loss: 0.59822236, Validation loss: 0.59987550, Gradient norm: 12.47756576
INFO:root:At the start of the epoch: mem (CPU python)=48359.41796875MB; mem (CPU total)=55143.6328125MB
INFO:root:[  117] Training loss: 0.59858868, Validation loss: 0.59967521, Gradient norm: 12.72430428
INFO:root:At the start of the epoch: mem (CPU python)=48380.5859375MB; mem (CPU total)=55180.81640625MB
INFO:root:[  118] Training loss: 0.59825558, Validation loss: 0.60031402, Gradient norm: 15.30331141
INFO:root:At the start of the epoch: mem (CPU python)=48401.75MB; mem (CPU total)=55213.4609375MB
INFO:root:[  119] Training loss: 0.59875281, Validation loss: 0.59989252, Gradient norm: 17.10677879
INFO:root:At the start of the epoch: mem (CPU python)=48422.9140625MB; mem (CPU total)=55255.31640625MB
INFO:root:EP 119: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=48444.078125MB; mem (CPU total)=55291.2109375MB
INFO:root:[  121] Training loss: 0.68658424, Validation loss: 0.68597662, Gradient norm: 11.65160173
INFO:root:At the start of the epoch: mem (CPU python)=48465.2421875MB; mem (CPU total)=55333.2734375MB
INFO:root:[  122] Training loss: 0.68428657, Validation loss: 0.68478425, Gradient norm: 13.61884577
INFO:root:At the start of the epoch: mem (CPU python)=48486.41015625MB; mem (CPU total)=55373.20703125MB
INFO:root:[  123] Training loss: 0.68342588, Validation loss: 0.68436646, Gradient norm: 12.22506339
INFO:root:At the start of the epoch: mem (CPU python)=48507.57421875MB; mem (CPU total)=55414.02734375MB
INFO:root:[  124] Training loss: 0.68323340, Validation loss: 0.68470160, Gradient norm: 14.51561075
INFO:root:At the start of the epoch: mem (CPU python)=48528.73828125MB; mem (CPU total)=55452.79296875MB
INFO:root:[  125] Training loss: 0.68307835, Validation loss: 0.68405145, Gradient norm: 15.10101023
INFO:root:At the start of the epoch: mem (CPU python)=48549.90234375MB; mem (CPU total)=55494.953125MB
INFO:root:[  126] Training loss: 0.68290457, Validation loss: 0.68261417, Gradient norm: 13.91925509
INFO:root:At the start of the epoch: mem (CPU python)=48571.0625MB; mem (CPU total)=55535.0234375MB
INFO:root:[  127] Training loss: 0.68241912, Validation loss: 0.68353024, Gradient norm: 13.60453644
INFO:root:At the start of the epoch: mem (CPU python)=48592.2265625MB; mem (CPU total)=55574.84375MB
INFO:root:[  128] Training loss: 0.68221232, Validation loss: 0.68307649, Gradient norm: 15.11366942
INFO:root:At the start of the epoch: mem (CPU python)=48613.390625MB; mem (CPU total)=55614.91796875MB
INFO:root:[  129] Training loss: 0.68210903, Validation loss: 0.68306081, Gradient norm: 14.99269875
INFO:root:At the start of the epoch: mem (CPU python)=48634.55859375MB; mem (CPU total)=55655.9140625MB
INFO:root:[  130] Training loss: 0.68195502, Validation loss: 0.68300345, Gradient norm: 15.22398402
INFO:root:At the start of the epoch: mem (CPU python)=48655.72265625MB; mem (CPU total)=55685.328125MB
INFO:root:[  131] Training loss: 0.68160125, Validation loss: 0.68259721, Gradient norm: 15.46458292
INFO:root:At the start of the epoch: mem (CPU python)=48676.88671875MB; mem (CPU total)=55727.1015625MB
INFO:root:[  132] Training loss: 0.68144592, Validation loss: 0.68265327, Gradient norm: 15.47661028
INFO:root:At the start of the epoch: mem (CPU python)=48698.046875MB; mem (CPU total)=55767.0703125MB
INFO:root:[  133] Training loss: 0.68146779, Validation loss: 0.68226547, Gradient norm: 18.62037718
INFO:root:At the start of the epoch: mem (CPU python)=48719.21484375MB; mem (CPU total)=55806.19140625MB
INFO:root:[  134] Training loss: 0.68100183, Validation loss: 0.68141266, Gradient norm: 16.89632581
INFO:root:At the start of the epoch: mem (CPU python)=48740.37890625MB; mem (CPU total)=55846.78125MB
INFO:root:[  135] Training loss: 0.68088906, Validation loss: 0.68126467, Gradient norm: 16.02734303
INFO:root:At the start of the epoch: mem (CPU python)=48761.5390625MB; mem (CPU total)=55888.28515625MB
INFO:root:[  136] Training loss: 0.68134119, Validation loss: 0.68172090, Gradient norm: 18.27707600
INFO:root:At the start of the epoch: mem (CPU python)=48782.703125MB; mem (CPU total)=55929.2109375MB
INFO:root:[  137] Training loss: 0.68074097, Validation loss: 0.68136408, Gradient norm: 16.39442072
INFO:root:At the start of the epoch: mem (CPU python)=48803.8671875MB; mem (CPU total)=55964.42578125MB
INFO:root:[  138] Training loss: 0.68104854, Validation loss: 0.68190318, Gradient norm: 18.99593262
INFO:root:At the start of the epoch: mem (CPU python)=48825.03125MB; mem (CPU total)=56003.828125MB
INFO:root:[  139] Training loss: 0.68048194, Validation loss: 0.68152054, Gradient norm: 18.28274957
INFO:root:At the start of the epoch: mem (CPU python)=48846.1953125MB; mem (CPU total)=56048.31640625MB
INFO:root:[  140] Training loss: 0.68069200, Validation loss: 0.68079981, Gradient norm: 19.51669266
INFO:root:At the start of the epoch: mem (CPU python)=48867.36328125MB; mem (CPU total)=56084.6328125MB
INFO:root:[  141] Training loss: 0.68045331, Validation loss: 0.68102666, Gradient norm: 19.42243670
INFO:root:At the start of the epoch: mem (CPU python)=48888.52734375MB; mem (CPU total)=56126.0390625MB
INFO:root:[  142] Training loss: 0.68024284, Validation loss: 0.68115191, Gradient norm: 19.06145930
INFO:root:At the start of the epoch: mem (CPU python)=48909.69140625MB; mem (CPU total)=56164.97265625MB
INFO:root:[  143] Training loss: 0.68044365, Validation loss: 0.68039906, Gradient norm: 21.37149855
INFO:root:At the start of the epoch: mem (CPU python)=48930.85546875MB; mem (CPU total)=56202.08203125MB
INFO:root:[  144] Training loss: 0.68023954, Validation loss: 0.68111520, Gradient norm: 20.97384051
INFO:root:At the start of the epoch: mem (CPU python)=48952.01953125MB; mem (CPU total)=56244.421875MB
INFO:root:[  145] Training loss: 0.68010288, Validation loss: 0.68076812, Gradient norm: 20.26298142
INFO:root:At the start of the epoch: mem (CPU python)=48973.1796875MB; mem (CPU total)=56283.12109375MB
INFO:root:[  146] Training loss: 0.68005843, Validation loss: 0.68157698, Gradient norm: 19.66185745
INFO:root:At the start of the epoch: mem (CPU python)=48994.34765625MB; mem (CPU total)=56324.0859375MB
INFO:root:[  147] Training loss: 0.67994543, Validation loss: 0.68082772, Gradient norm: 20.55720889
INFO:root:At the start of the epoch: mem (CPU python)=49015.51171875MB; mem (CPU total)=56363.29296875MB
INFO:root:[  148] Training loss: 0.67966604, Validation loss: 0.68083596, Gradient norm: 21.47594586
INFO:root:At the start of the epoch: mem (CPU python)=49036.67578125MB; mem (CPU total)=56403.19140625MB
INFO:root:[  149] Training loss: 0.67979594, Validation loss: 0.68034331, Gradient norm: 21.21616347
INFO:root:At the start of the epoch: mem (CPU python)=49057.83984375MB; mem (CPU total)=56443.45703125MB
INFO:root:[  150] Training loss: 0.67985137, Validation loss: 0.68085745, Gradient norm: 22.56796594
INFO:root:At the start of the epoch: mem (CPU python)=49079.0MB; mem (CPU total)=56479.765625MB
INFO:root:[  151] Training loss: 0.67952217, Validation loss: 0.68063851, Gradient norm: 21.10876894
INFO:root:At the start of the epoch: mem (CPU python)=49100.1640625MB; mem (CPU total)=56520.41015625MB
INFO:root:[  152] Training loss: 0.67963618, Validation loss: 0.68022931, Gradient norm: 22.32877447
INFO:root:At the start of the epoch: mem (CPU python)=49121.33203125MB; mem (CPU total)=56562.921875MB
INFO:root:[  153] Training loss: 0.67951904, Validation loss: 0.67980156, Gradient norm: 22.52167750
INFO:root:At the start of the epoch: mem (CPU python)=49142.49609375MB; mem (CPU total)=56604.359375MB
INFO:root:[  154] Training loss: 0.67938049, Validation loss: 0.67999812, Gradient norm: 23.74393311
INFO:root:At the start of the epoch: mem (CPU python)=49163.65625MB; mem (CPU total)=56642.23046875MB
INFO:root:[  155] Training loss: 0.67926543, Validation loss: 0.67962210, Gradient norm: 22.34231867
INFO:root:At the start of the epoch: mem (CPU python)=49184.8203125MB; mem (CPU total)=56682.34765625MB
INFO:root:[  156] Training loss: 0.67956580, Validation loss: 0.68109606, Gradient norm: 26.88550149
INFO:root:At the start of the epoch: mem (CPU python)=49205.984375MB; mem (CPU total)=56720.125MB
INFO:root:[  157] Training loss: 0.67947780, Validation loss: 0.68073546, Gradient norm: 23.92423014
INFO:root:At the start of the epoch: mem (CPU python)=49227.1484375MB; mem (CPU total)=56759.04296875MB
INFO:root:[  158] Training loss: 0.67927917, Validation loss: 0.68016622, Gradient norm: 24.32611228
INFO:root:At the start of the epoch: mem (CPU python)=49248.3203125MB; mem (CPU total)=56799.8671875MB
INFO:root:[  159] Training loss: 0.67907254, Validation loss: 0.68017559, Gradient norm: 24.95208082
INFO:root:At the start of the epoch: mem (CPU python)=49269.484375MB; mem (CPU total)=56840.59765625MB
INFO:root:[  160] Training loss: 0.67919677, Validation loss: 0.67963157, Gradient norm: 23.81792732
INFO:root:At the start of the epoch: mem (CPU python)=49290.6484375MB; mem (CPU total)=56882.29296875MB
INFO:root:[  161] Training loss: 0.67907832, Validation loss: 0.67941201, Gradient norm: 25.43150255
INFO:root:At the start of the epoch: mem (CPU python)=49311.8125MB; mem (CPU total)=56922.3203125MB
INFO:root:[  162] Training loss: 0.67899938, Validation loss: 0.67923658, Gradient norm: 24.45895870
INFO:root:At the start of the epoch: mem (CPU python)=49332.98046875MB; mem (CPU total)=56960.29296875MB
INFO:root:[  163] Training loss: 0.67882409, Validation loss: 0.67982814, Gradient norm: 25.69687291
INFO:root:At the start of the epoch: mem (CPU python)=49354.13671875MB; mem (CPU total)=56998.71484375MB
INFO:root:[  164] Training loss: 0.67869123, Validation loss: 0.68021834, Gradient norm: 25.45918052
INFO:root:At the start of the epoch: mem (CPU python)=49375.3046875MB; mem (CPU total)=57038.921875MB
INFO:root:[  165] Training loss: 0.67889364, Validation loss: 0.67924575, Gradient norm: 26.77171089
INFO:root:At the start of the epoch: mem (CPU python)=49396.46875MB; mem (CPU total)=57078.0859375MB
INFO:root:[  166] Training loss: 0.67868515, Validation loss: 0.68004857, Gradient norm: 26.52331122
INFO:root:At the start of the epoch: mem (CPU python)=49417.62890625MB; mem (CPU total)=57117.375MB
INFO:root:[  167] Training loss: 0.67864029, Validation loss: 0.67912805, Gradient norm: 27.04925780
INFO:root:At the start of the epoch: mem (CPU python)=49438.80078125MB; mem (CPU total)=57159.078125MB
INFO:root:[  168] Training loss: 0.67847685, Validation loss: 0.68013800, Gradient norm: 25.35234820
INFO:root:At the start of the epoch: mem (CPU python)=49459.95703125MB; mem (CPU total)=57199.17578125MB
INFO:root:[  169] Training loss: 0.67866510, Validation loss: 0.67965968, Gradient norm: 28.18194677
INFO:root:At the start of the epoch: mem (CPU python)=49481.125MB; mem (CPU total)=57238.3828125MB
INFO:root:[  170] Training loss: 0.67867445, Validation loss: 0.68000259, Gradient norm: 30.39174357
INFO:root:At the start of the epoch: mem (CPU python)=49502.2890625MB; mem (CPU total)=57279.5390625MB
INFO:root:[  171] Training loss: 0.67872735, Validation loss: 0.67905484, Gradient norm: 29.43797885
INFO:root:At the start of the epoch: mem (CPU python)=49523.453125MB; mem (CPU total)=57314.95703125MB
INFO:root:[  172] Training loss: 0.67818397, Validation loss: 0.67897693, Gradient norm: 29.58152205
INFO:root:At the start of the epoch: mem (CPU python)=49544.6171875MB; mem (CPU total)=57357.0234375MB
INFO:root:[  173] Training loss: 0.67863320, Validation loss: 0.67909255, Gradient norm: 31.41830213
INFO:root:At the start of the epoch: mem (CPU python)=49565.77734375MB; mem (CPU total)=57396.71875MB
INFO:root:[  174] Training loss: 0.67838091, Validation loss: 0.67933991, Gradient norm: 29.21724369
INFO:root:At the start of the epoch: mem (CPU python)=49586.9453125MB; mem (CPU total)=57435.703125MB
INFO:root:[  175] Training loss: 0.67829077, Validation loss: 0.67880206, Gradient norm: 29.51619045
INFO:root:At the start of the epoch: mem (CPU python)=49608.109375MB; mem (CPU total)=57473.2265625MB
INFO:root:[  176] Training loss: 0.67834393, Validation loss: 0.67896066, Gradient norm: 29.16483743
INFO:root:At the start of the epoch: mem (CPU python)=49629.2734375MB; mem (CPU total)=57513.8828125MB
INFO:root:[  177] Training loss: 0.67828799, Validation loss: 0.67898013, Gradient norm: 30.06789610
INFO:root:At the start of the epoch: mem (CPU python)=49650.4375MB; mem (CPU total)=57554.359375MB
INFO:root:[  178] Training loss: 0.67807668, Validation loss: 0.67946083, Gradient norm: 31.23274253
INFO:root:At the start of the epoch: mem (CPU python)=49671.6015625MB; mem (CPU total)=57593.4375MB
INFO:root:[  179] Training loss: 0.67830103, Validation loss: 0.67818932, Gradient norm: 33.60344933
INFO:root:At the start of the epoch: mem (CPU python)=49692.76953125MB; mem (CPU total)=57634.09765625MB
INFO:root:[  180] Training loss: 0.67802867, Validation loss: 0.67846879, Gradient norm: 30.10096272
INFO:root:At the start of the epoch: mem (CPU python)=49713.93359375MB; mem (CPU total)=57675.1796875MB
INFO:root:[  181] Training loss: 0.67806605, Validation loss: 0.67912328, Gradient norm: 31.64297431
INFO:root:At the start of the epoch: mem (CPU python)=49735.09765625MB; mem (CPU total)=57711.65625MB
INFO:root:[  182] Training loss: 0.67798764, Validation loss: 0.67987223, Gradient norm: 31.81120568
INFO:root:At the start of the epoch: mem (CPU python)=49756.2578125MB; mem (CPU total)=57752.3125MB
INFO:root:[  183] Training loss: 0.67810026, Validation loss: 0.67830270, Gradient norm: 33.84376016
INFO:root:At the start of the epoch: mem (CPU python)=49777.41796875MB; mem (CPU total)=57792.27734375MB
INFO:root:[  184] Training loss: 0.67790763, Validation loss: 0.67818742, Gradient norm: 32.09393853
INFO:root:At the start of the epoch: mem (CPU python)=49798.5859375MB; mem (CPU total)=57831.95703125MB
INFO:root:[  185] Training loss: 0.67767927, Validation loss: 0.67949699, Gradient norm: 31.22642774
INFO:root:At the start of the epoch: mem (CPU python)=49819.74609375MB; mem (CPU total)=57872.4921875MB
INFO:root:[  186] Training loss: 0.67804601, Validation loss: 0.67854664, Gradient norm: 34.28012086
INFO:root:At the start of the epoch: mem (CPU python)=49840.9140625MB; mem (CPU total)=57912.00390625MB
INFO:root:[  187] Training loss: 0.67786884, Validation loss: 0.67862975, Gradient norm: 33.88787770
INFO:root:At the start of the epoch: mem (CPU python)=49862.078125MB; mem (CPU total)=57949.78125MB
INFO:root:[  188] Training loss: 0.67809170, Validation loss: 0.67866096, Gradient norm: 34.31750531
INFO:root:At the start of the epoch: mem (CPU python)=49883.2421875MB; mem (CPU total)=57991.8203125MB
INFO:root:[  189] Training loss: 0.67761606, Validation loss: 0.67851368, Gradient norm: 34.85203487
INFO:root:At the start of the epoch: mem (CPU python)=49904.40625MB; mem (CPU total)=58035.1484375MB
INFO:root:[  190] Training loss: 0.67760334, Validation loss: 0.67776162, Gradient norm: 33.14666286
INFO:root:At the start of the epoch: mem (CPU python)=49925.57421875MB; mem (CPU total)=58075.5390625MB
INFO:root:[  191] Training loss: 0.67790372, Validation loss: 0.67969336, Gradient norm: 34.69527102
INFO:root:At the start of the epoch: mem (CPU python)=49946.734375MB; mem (CPU total)=58114.22265625MB
INFO:root:[  192] Training loss: 0.67736580, Validation loss: 0.67895948, Gradient norm: 34.91877129
INFO:root:At the start of the epoch: mem (CPU python)=49967.8984375MB; mem (CPU total)=58137.10546875MB
INFO:root:[  193] Training loss: 0.67757241, Validation loss: 0.67890244, Gradient norm: 35.06053085
INFO:root:At the start of the epoch: mem (CPU python)=49989.0625MB; mem (CPU total)=58160.40234375MB
INFO:root:[  194] Training loss: 0.67766862, Validation loss: 0.67871852, Gradient norm: 34.42699030
INFO:root:At the start of the epoch: mem (CPU python)=50010.2265625MB; mem (CPU total)=58204.41796875MB
INFO:root:[  195] Training loss: 0.67735253, Validation loss: 0.67927970, Gradient norm: 37.44184908
INFO:root:At the start of the epoch: mem (CPU python)=50031.39453125MB; mem (CPU total)=58258.09765625MB
INFO:root:[  196] Training loss: 0.67743511, Validation loss: 0.67898185, Gradient norm: 36.92727489
INFO:root:At the start of the epoch: mem (CPU python)=50052.55859375MB; mem (CPU total)=58314.07421875MB
INFO:root:[  197] Training loss: 0.67758331, Validation loss: 0.67830532, Gradient norm: 36.86173171
INFO:root:At the start of the epoch: mem (CPU python)=50073.7265625MB; mem (CPU total)=58368.55078125MB
INFO:root:[  198] Training loss: 0.67761840, Validation loss: 0.67854319, Gradient norm: 35.36236613
INFO:root:At the start of the epoch: mem (CPU python)=50094.890625MB; mem (CPU total)=58421.88671875MB
INFO:root:[  199] Training loss: 0.67715054, Validation loss: 0.67774265, Gradient norm: 36.34779288
INFO:root:At the start of the epoch: mem (CPU python)=50116.0546875MB; mem (CPU total)=58477.69921875MB
INFO:root:[  200] Training loss: 0.67722224, Validation loss: 0.67800802, Gradient norm: 35.65873803
INFO:root:At the start of the epoch: mem (CPU python)=50137.21484375MB; mem (CPU total)=58531.08984375MB
INFO:root:[  201] Training loss: 0.67739483, Validation loss: 0.67777885, Gradient norm: 36.03320270
INFO:root:At the start of the epoch: mem (CPU python)=50158.375MB; mem (CPU total)=58586.16796875MB
INFO:root:[  202] Training loss: 0.67720730, Validation loss: 0.67893906, Gradient norm: 36.53607574
INFO:root:At the start of the epoch: mem (CPU python)=50179.54296875MB; mem (CPU total)=58638.046875MB
INFO:root:[  203] Training loss: 0.67709717, Validation loss: 0.67741569, Gradient norm: 38.32080732
INFO:root:At the start of the epoch: mem (CPU python)=50200.70703125MB; mem (CPU total)=58693.80859375MB
INFO:root:[  204] Training loss: 0.67757773, Validation loss: 0.67797877, Gradient norm: 38.50970492
INFO:root:At the start of the epoch: mem (CPU python)=50221.87109375MB; mem (CPU total)=58745.6875MB
INFO:root:[  205] Training loss: 0.67741027, Validation loss: 0.67727639, Gradient norm: 36.80033196
INFO:root:At the start of the epoch: mem (CPU python)=50243.03515625MB; mem (CPU total)=58799.8203125MB
INFO:root:[  206] Training loss: 0.67714836, Validation loss: 0.67771863, Gradient norm: 38.96020521
INFO:root:At the start of the epoch: mem (CPU python)=50264.19921875MB; mem (CPU total)=58853.6875MB
INFO:root:[  207] Training loss: 0.67724577, Validation loss: 0.67753481, Gradient norm: 39.74829118
INFO:root:At the start of the epoch: mem (CPU python)=50285.36328125MB; mem (CPU total)=58907.25MB
INFO:root:[  208] Training loss: 0.67701606, Validation loss: 0.67851439, Gradient norm: 38.62852305
INFO:root:At the start of the epoch: mem (CPU python)=50306.53125MB; mem (CPU total)=58960.26953125MB
INFO:root:[  209] Training loss: 0.67703344, Validation loss: 0.67763871, Gradient norm: 37.73493648
INFO:root:At the start of the epoch: mem (CPU python)=50327.6953125MB; mem (CPU total)=59013.30859375MB
INFO:root:[  210] Training loss: 0.67700116, Validation loss: 0.67728642, Gradient norm: 37.24391606
INFO:root:At the start of the epoch: mem (CPU python)=50348.85546875MB; mem (CPU total)=59067.8828125MB
INFO:root:[  211] Training loss: 0.67699144, Validation loss: 0.67872667, Gradient norm: 40.40562438
INFO:root:At the start of the epoch: mem (CPU python)=50370.01953125MB; mem (CPU total)=59121.43359375MB
INFO:root:[  212] Training loss: 0.67681733, Validation loss: 0.67736604, Gradient norm: 38.90242728
INFO:root:At the start of the epoch: mem (CPU python)=50391.18359375MB; mem (CPU total)=59176.08984375MB
INFO:root:[  213] Training loss: 0.67730947, Validation loss: 0.67811397, Gradient norm: 40.37220796
INFO:root:At the start of the epoch: mem (CPU python)=50412.34765625MB; mem (CPU total)=59228.71875MB
INFO:root:[  214] Training loss: 0.67712154, Validation loss: 0.67773321, Gradient norm: 39.84946613
INFO:root:At the start of the epoch: mem (CPU python)=50433.515625MB; mem (CPU total)=59282.80859375MB
INFO:root:EP 214: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=50454.6796875MB; mem (CPU total)=59316.73828125MB
INFO:root:Training the model took 16281.505s.
INFO:root:Emptying the cuda cache took 0.064s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.6768
INFO:root:EnergyScoreValidation: 0.54508
INFO:root:CRPSValidation: 0.21349
INFO:root:Gaussian NLLValidation: 1.97587
INFO:root:CoverageValidation: 0.64788
INFO:root:IntervalWidthValidation: 0.52109
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.54653
INFO:root:EnergyScoreTest: 0.4166
INFO:root:CRPSTest: 0.16284
INFO:root:Gaussian NLLTest: 0.56271
INFO:root:CoverageTest: 0.77241
INFO:root:IntervalWidthTest: 0.57807
INFO:root:After validation: mem (CPU python)=50760.94140625MB; mem (CPU total)=59409.10546875MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=50760.94140625MB; mem (CPU total)=59430.76171875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 297795584
INFO:root:After setting up the model: mem (CPU python)=50760.94140625MB; mem (CPU total)=59430.76171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59445.04296875MB
INFO:root:[    1] Training loss: 0.89065444, Validation loss: 0.77722812, Gradient norm: 0.32276806
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59494.56640625MB
INFO:root:[    2] Training loss: 0.76909913, Validation loss: 0.76489143, Gradient norm: 0.33059192
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59541.03125MB
INFO:root:[    3] Training loss: 0.76368987, Validation loss: 0.75796734, Gradient norm: 0.54546883
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59588.66796875MB
INFO:root:[    4] Training loss: 0.75835200, Validation loss: 0.75468707, Gradient norm: 0.78660003
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59637.86328125MB
INFO:root:[    5] Training loss: 0.75331870, Validation loss: 0.74317320, Gradient norm: 1.31304754
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59687.73828125MB
INFO:root:[    6] Training loss: 0.74521078, Validation loss: 0.72920440, Gradient norm: 1.57841954
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59735.50390625MB
INFO:root:[    7] Training loss: 0.73927852, Validation loss: 0.74719648, Gradient norm: 2.06798314
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59784.203125MB
INFO:root:[    8] Training loss: 0.73662885, Validation loss: 0.75049161, Gradient norm: 2.31331254
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59832.6796875MB
INFO:root:[    9] Training loss: 0.73137038, Validation loss: 0.73277790, Gradient norm: 2.42431453
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59880.5859375MB
INFO:root:[   10] Training loss: 0.72849627, Validation loss: 0.73070474, Gradient norm: 2.70236960
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59927.98828125MB
INFO:root:[   11] Training loss: 0.72257114, Validation loss: 0.72200428, Gradient norm: 2.66583042
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=59977.15234375MB
INFO:root:[   12] Training loss: 0.72548738, Validation loss: 0.71865146, Gradient norm: 3.22077804
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=60025.1875MB
INFO:root:[   13] Training loss: 0.71849657, Validation loss: 0.70641845, Gradient norm: 3.13893588
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=60073.1640625MB
INFO:root:[   14] Training loss: 0.72092919, Validation loss: 0.71384502, Gradient norm: 3.68809413
INFO:root:At the start of the epoch: mem (CPU python)=50760.94140625MB; mem (CPU total)=60124.8125MB
INFO:root:[   15] Training loss: 0.71701766, Validation loss: 0.71483920, Gradient norm: 3.67863293
INFO:root:At the start of the epoch: mem (CPU python)=50778.87890625MB; mem (CPU total)=60172.72265625MB
INFO:root:[   16] Training loss: 0.71556955, Validation loss: 0.71061494, Gradient norm: 3.71632523
INFO:root:At the start of the epoch: mem (CPU python)=50800.04296875MB; mem (CPU total)=60221.69921875MB
INFO:root:[   17] Training loss: 0.71390111, Validation loss: 0.72427685, Gradient norm: 4.07450839
INFO:root:At the start of the epoch: mem (CPU python)=50821.2109375MB; mem (CPU total)=60262.14453125MB
INFO:root:[   18] Training loss: 0.71271001, Validation loss: 0.74011887, Gradient norm: 4.01421802
INFO:root:At the start of the epoch: mem (CPU python)=50842.375MB; mem (CPU total)=60310.38671875MB
INFO:root:[   19] Training loss: 0.71284600, Validation loss: 0.71211688, Gradient norm: 4.45612661
INFO:root:At the start of the epoch: mem (CPU python)=50863.53515625MB; mem (CPU total)=60358.88671875MB
INFO:root:[   20] Training loss: 0.70938838, Validation loss: 0.72015486, Gradient norm: 4.70156363
INFO:root:At the start of the epoch: mem (CPU python)=50884.69921875MB; mem (CPU total)=60408.3359375MB
INFO:root:[   21] Training loss: 0.71255482, Validation loss: 0.70455924, Gradient norm: 4.88735371
INFO:root:At the start of the epoch: mem (CPU python)=50905.8671875MB; mem (CPU total)=60452.7421875MB
INFO:root:[   22] Training loss: 0.71379395, Validation loss: 0.74163491, Gradient norm: 5.26554467
INFO:root:At the start of the epoch: mem (CPU python)=50927.03125MB; mem (CPU total)=60504.8671875MB
INFO:root:[   23] Training loss: 0.70621491, Validation loss: 0.71074297, Gradient norm: 4.86291371
INFO:root:At the start of the epoch: mem (CPU python)=50948.19140625MB; mem (CPU total)=60549.05859375MB
INFO:root:[   24] Training loss: 0.71965535, Validation loss: 0.69251441, Gradient norm: 6.18313966
INFO:root:At the start of the epoch: mem (CPU python)=50969.35546875MB; mem (CPU total)=60599.2265625MB
INFO:root:[   25] Training loss: 0.70605411, Validation loss: 0.71314849, Gradient norm: 5.14316418
INFO:root:At the start of the epoch: mem (CPU python)=50990.51953125MB; mem (CPU total)=60644.26953125MB
INFO:root:[   26] Training loss: 0.70465069, Validation loss: 0.76637715, Gradient norm: 5.59853689
INFO:root:At the start of the epoch: mem (CPU python)=51011.68359375MB; mem (CPU total)=60694.5546875MB
INFO:root:[   27] Training loss: 0.70891531, Validation loss: 0.69602181, Gradient norm: 5.84101512
INFO:root:At the start of the epoch: mem (CPU python)=51032.8515625MB; mem (CPU total)=60740.75MB
INFO:root:[   28] Training loss: 0.72008845, Validation loss: 0.70876443, Gradient norm: 6.76778675
INFO:root:At the start of the epoch: mem (CPU python)=51054.015625MB; mem (CPU total)=60789.640625MB
INFO:root:[   29] Training loss: 0.71550185, Validation loss: 0.72646055, Gradient norm: 6.47660938
INFO:root:At the start of the epoch: mem (CPU python)=51075.1796875MB; mem (CPU total)=60837.96484375MB
INFO:root:[   30] Training loss: 0.71205706, Validation loss: 0.70049975, Gradient norm: 6.43758733
INFO:root:At the start of the epoch: mem (CPU python)=51096.34375MB; mem (CPU total)=60887.99609375MB
INFO:root:[   31] Training loss: 0.71258390, Validation loss: 0.71147210, Gradient norm: 6.76389731
INFO:root:At the start of the epoch: mem (CPU python)=51117.5078125MB; mem (CPU total)=60936.82421875MB
INFO:root:[   32] Training loss: 0.71634279, Validation loss: 0.71439984, Gradient norm: 6.74262554
INFO:root:At the start of the epoch: mem (CPU python)=51138.67578125MB; mem (CPU total)=60984.2890625MB
INFO:root:[   33] Training loss: 0.70820787, Validation loss: 0.72094082, Gradient norm: 6.09870905
INFO:root:At the start of the epoch: mem (CPU python)=51159.8359375MB; mem (CPU total)=61032.7890625MB
INFO:root:[   34] Training loss: 0.71187006, Validation loss: 0.71093850, Gradient norm: 6.45936678
INFO:root:At the start of the epoch: mem (CPU python)=51181.0MB; mem (CPU total)=61080.75390625MB
INFO:root:[   35] Training loss: 0.70780728, Validation loss: 0.74188268, Gradient norm: 6.20861994
INFO:root:At the start of the epoch: mem (CPU python)=51202.1640625MB; mem (CPU total)=61131.96875MB
INFO:root:[   36] Training loss: 0.70621311, Validation loss: 0.69664127, Gradient norm: 6.76217448
INFO:root:At the start of the epoch: mem (CPU python)=51223.32421875MB; mem (CPU total)=61178.20703125MB
INFO:root:[   37] Training loss: 0.70535502, Validation loss: 0.70754120, Gradient norm: 6.53364974
INFO:root:At the start of the epoch: mem (CPU python)=51244.48828125MB; mem (CPU total)=61221.39453125MB
INFO:root:[   38] Training loss: 0.70509200, Validation loss: 0.70882188, Gradient norm: 6.88395033
INFO:root:At the start of the epoch: mem (CPU python)=51265.65625MB; mem (CPU total)=61270.37890625MB
INFO:root:[   39] Training loss: 0.70289507, Validation loss: 0.69687282, Gradient norm: 6.63717329
INFO:root:At the start of the epoch: mem (CPU python)=51286.8203125MB; mem (CPU total)=61319.30078125MB
INFO:root:[   40] Training loss: 0.71125202, Validation loss: 0.70722639, Gradient norm: 7.60105663
INFO:root:At the start of the epoch: mem (CPU python)=51307.984375MB; mem (CPU total)=61363.70703125MB
INFO:root:[   41] Training loss: 0.71401358, Validation loss: 0.71576565, Gradient norm: 7.69490817
INFO:root:At the start of the epoch: mem (CPU python)=51329.1484375MB; mem (CPU total)=61413.39453125MB
INFO:root:[   42] Training loss: 0.71318188, Validation loss: 0.71244513, Gradient norm: 8.10022164
INFO:root:At the start of the epoch: mem (CPU python)=51350.30859375MB; mem (CPU total)=61461.7578125MB
INFO:root:[   43] Training loss: 0.71345230, Validation loss: 0.71763701, Gradient norm: 8.01928898
INFO:root:At the start of the epoch: mem (CPU python)=51371.4765625MB; mem (CPU total)=61511.5MB
INFO:root:[   44] Training loss: 0.71148850, Validation loss: 0.69290037, Gradient norm: 8.00994485
INFO:root:At the start of the epoch: mem (CPU python)=51392.640625MB; mem (CPU total)=61555.74609375MB
INFO:root:[   45] Training loss: 0.70590077, Validation loss: 0.68578597, Gradient norm: 7.55989847
INFO:root:At the start of the epoch: mem (CPU python)=51413.8046875MB; mem (CPU total)=61603.07421875MB
INFO:root:[   46] Training loss: 0.70562637, Validation loss: 0.69932060, Gradient norm: 7.80985366
INFO:root:At the start of the epoch: mem (CPU python)=51434.96875MB; mem (CPU total)=61653.12109375MB
INFO:root:[   47] Training loss: 0.70745529, Validation loss: 0.70221337, Gradient norm: 8.33922835
INFO:root:At the start of the epoch: mem (CPU python)=51456.13671875MB; mem (CPU total)=61700.01953125MB
INFO:root:[   48] Training loss: 0.70809924, Validation loss: 0.69990753, Gradient norm: 8.35168239
INFO:root:At the start of the epoch: mem (CPU python)=51477.30078125MB; mem (CPU total)=61749.08203125MB
INFO:root:[   49] Training loss: 0.70688729, Validation loss: 0.69767564, Gradient norm: 8.60455530
INFO:root:At the start of the epoch: mem (CPU python)=51498.46875MB; mem (CPU total)=61794.4921875MB
INFO:root:[   50] Training loss: 0.70930936, Validation loss: 0.69058657, Gradient norm: 8.98732205
INFO:root:At the start of the epoch: mem (CPU python)=51519.6328125MB; mem (CPU total)=61843.91796875MB
INFO:root:[   51] Training loss: 0.70601102, Validation loss: 0.70115987, Gradient norm: 8.35500314
INFO:root:At the start of the epoch: mem (CPU python)=51540.79296875MB; mem (CPU total)=61890.94140625MB
INFO:root:[   52] Training loss: 0.70847675, Validation loss: 0.67532950, Gradient norm: 8.83510982
INFO:root:At the start of the epoch: mem (CPU python)=51561.95703125MB; mem (CPU total)=61939.65625MB
INFO:root:[   53] Training loss: 0.71105354, Validation loss: 0.71579837, Gradient norm: 8.74270487
INFO:root:At the start of the epoch: mem (CPU python)=51583.12109375MB; mem (CPU total)=61989.53515625MB
INFO:root:[   54] Training loss: 0.70459688, Validation loss: 0.71075673, Gradient norm: 8.50453738
INFO:root:At the start of the epoch: mem (CPU python)=51604.28515625MB; mem (CPU total)=62036.07421875MB
INFO:root:[   55] Training loss: 0.70953338, Validation loss: 0.71206805, Gradient norm: 9.02772722
INFO:root:At the start of the epoch: mem (CPU python)=51625.453125MB; mem (CPU total)=62083.02734375MB
INFO:root:[   56] Training loss: 0.71346251, Validation loss: 0.71050529, Gradient norm: 9.22012688
INFO:root:At the start of the epoch: mem (CPU python)=51646.6171875MB; mem (CPU total)=62129.8671875MB
INFO:root:[   57] Training loss: 0.71681815, Validation loss: 0.71559342, Gradient norm: 9.81737784
INFO:root:At the start of the epoch: mem (CPU python)=51667.78125MB; mem (CPU total)=62179.1484375MB
INFO:root:[   58] Training loss: 0.70431812, Validation loss: 0.69075813, Gradient norm: 8.51990475
INFO:root:At the start of the epoch: mem (CPU python)=51688.9453125MB; mem (CPU total)=62226.3671875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   59] Training loss: 0.70777957, Validation loss: 0.77361187, Gradient norm: 9.25569257
INFO:root:At the start of the epoch: mem (CPU python)=51710.11328125MB; mem (CPU total)=62274.4921875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   60] Training loss: 0.67139026, Validation loss: 0.68221627, Gradient norm: 7.58658141
INFO:root:At the start of the epoch: mem (CPU python)=51731.27734375MB; mem (CPU total)=62320.40625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   61] Training loss: 0.65242472, Validation loss: 0.65084947, Gradient norm: 5.80349248
INFO:root:At the start of the epoch: mem (CPU python)=51752.4375MB; mem (CPU total)=62368.8828125MB
INFO:root:[   62] Training loss: 0.64579563, Validation loss: 0.64409880, Gradient norm: 4.61988692
INFO:root:At the start of the epoch: mem (CPU python)=51773.6015625MB; mem (CPU total)=62416.98828125MB
INFO:root:[   63] Training loss: 0.64433536, Validation loss: 0.64501258, Gradient norm: 5.71849059
INFO:root:At the start of the epoch: mem (CPU python)=51794.765625MB; mem (CPU total)=62462.828125MB
INFO:root:[   64] Training loss: 0.64473987, Validation loss: 0.64661837, Gradient norm: 6.90954443
INFO:root:At the start of the epoch: mem (CPU python)=51815.9296875MB; mem (CPU total)=62511.01171875MB
INFO:root:[   65] Training loss: 0.64482828, Validation loss: 0.64786907, Gradient norm: 7.55719805
INFO:root:At the start of the epoch: mem (CPU python)=51837.09765625MB; mem (CPU total)=62560.140625MB
INFO:root:[   66] Training loss: 0.64812533, Validation loss: 0.65582840, Gradient norm: 10.58834775
INFO:root:At the start of the epoch: mem (CPU python)=51858.2578125MB; mem (CPU total)=62600.65234375MB
INFO:root:[   67] Training loss: 0.64949497, Validation loss: 0.65167675, Gradient norm: 9.76199588
INFO:root:At the start of the epoch: mem (CPU python)=51879.421875MB; mem (CPU total)=62636.66796875MB
INFO:root:[   68] Training loss: 0.64770998, Validation loss: 0.64638732, Gradient norm: 7.52254639
INFO:root:At the start of the epoch: mem (CPU python)=51900.5859375MB; mem (CPU total)=62674.78515625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   69] Training loss: 0.64620541, Validation loss: 0.64784093, Gradient norm: 8.88859182
INFO:root:At the start of the epoch: mem (CPU python)=51921.75MB; mem (CPU total)=62710.5390625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   70] Training loss: 0.64334837, Validation loss: 0.64395537, Gradient norm: 5.32626446
INFO:root:At the start of the epoch: mem (CPU python)=51942.9140625MB; mem (CPU total)=62746.94140625MB
INFO:root:[   71] Training loss: 0.64144841, Validation loss: 0.64132173, Gradient norm: 4.21735869
INFO:root:At the start of the epoch: mem (CPU python)=51964.078125MB; mem (CPU total)=62784.5625MB
INFO:root:[   72] Training loss: 0.64158760, Validation loss: 0.64167577, Gradient norm: 5.30061551
INFO:root:At the start of the epoch: mem (CPU python)=51985.23828125MB; mem (CPU total)=62822.015625MB
INFO:root:[   73] Training loss: 0.64182836, Validation loss: 0.64258457, Gradient norm: 5.23189985
INFO:root:At the start of the epoch: mem (CPU python)=52006.40234375MB; mem (CPU total)=62857.46875MB
INFO:root:[   74] Training loss: 0.64124517, Validation loss: 0.64164863, Gradient norm: 7.09059122
INFO:root:At the start of the epoch: mem (CPU python)=52027.56640625MB; mem (CPU total)=62894.90625MB
INFO:root:[   75] Training loss: 0.64138925, Validation loss: 0.64297244, Gradient norm: 5.73103802
INFO:root:At the start of the epoch: mem (CPU python)=52048.73046875MB; mem (CPU total)=62931.49609375MB
INFO:root:[   76] Training loss: 0.64168189, Validation loss: 0.64187760, Gradient norm: 5.96046783
INFO:root:At the start of the epoch: mem (CPU python)=52069.89453125MB; mem (CPU total)=62968.328125MB
INFO:root:[   77] Training loss: 0.64130503, Validation loss: 0.64316545, Gradient norm: 7.05323146
INFO:root:At the start of the epoch: mem (CPU python)=52091.0625MB; mem (CPU total)=63005.46484375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   78] Training loss: 0.64161919, Validation loss: 0.64158082, Gradient norm: 6.97465516
INFO:root:At the start of the epoch: mem (CPU python)=52112.2265625MB; mem (CPU total)=63042.06640625MB
INFO:root:[   79] Training loss: 0.64041488, Validation loss: 0.64174881, Gradient norm: 5.18164533
INFO:root:At the start of the epoch: mem (CPU python)=52133.390625MB; mem (CPU total)=63082.29296875MB
INFO:root:[   80] Training loss: 0.64045518, Validation loss: 0.64167692, Gradient norm: 5.00974486
INFO:root:At the start of the epoch: mem (CPU python)=52154.55078125MB; mem (CPU total)=63116.22265625MB
INFO:root:EP 80: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=52175.71484375MB; mem (CPU total)=63152.171875MB
INFO:root:[   82] Training loss: 0.72673768, Validation loss: 0.72529634, Gradient norm: 5.86204711
INFO:root:At the start of the epoch: mem (CPU python)=52196.8828125MB; mem (CPU total)=63194.546875MB
INFO:root:[   83] Training loss: 0.72460818, Validation loss: 0.72553598, Gradient norm: 5.67935092
INFO:root:At the start of the epoch: mem (CPU python)=52218.04296875MB; mem (CPU total)=63232.24609375MB
INFO:root:[   84] Training loss: 0.72450642, Validation loss: 0.72526786, Gradient norm: 7.12553448
INFO:root:At the start of the epoch: mem (CPU python)=52239.2109375MB; mem (CPU total)=63272.5MB
INFO:root:[   85] Training loss: 0.72448744, Validation loss: 0.72378346, Gradient norm: 6.73897822
INFO:root:At the start of the epoch: mem (CPU python)=52260.375MB; mem (CPU total)=63313.52734375MB
INFO:root:[   86] Training loss: 0.72393409, Validation loss: 0.72461904, Gradient norm: 6.32518245
INFO:root:At the start of the epoch: mem (CPU python)=52281.5390625MB; mem (CPU total)=63354.95703125MB
INFO:root:[   87] Training loss: 0.72417235, Validation loss: 0.72408422, Gradient norm: 6.32300822
INFO:root:At the start of the epoch: mem (CPU python)=52302.69921875MB; mem (CPU total)=63390.72265625MB
INFO:root:[   88] Training loss: 0.72373603, Validation loss: 0.72401440, Gradient norm: 6.53158754
INFO:root:At the start of the epoch: mem (CPU python)=52323.8671875MB; mem (CPU total)=63431.7578125MB
INFO:root:[   89] Training loss: 0.72382701, Validation loss: 0.72379308, Gradient norm: 7.26221523
INFO:root:At the start of the epoch: mem (CPU python)=52345.03125MB; mem (CPU total)=63471.265625MB
INFO:root:[   90] Training loss: 0.72308264, Validation loss: 0.72347494, Gradient norm: 6.85441693
INFO:root:At the start of the epoch: mem (CPU python)=52366.1953125MB; mem (CPU total)=63511.17578125MB
INFO:root:[   91] Training loss: 0.72314685, Validation loss: 0.72483640, Gradient norm: 6.71417611
INFO:root:At the start of the epoch: mem (CPU python)=52387.359375MB; mem (CPU total)=63549.03125MB
INFO:root:[   92] Training loss: 0.72332831, Validation loss: 0.72330317, Gradient norm: 7.59959522
INFO:root:At the start of the epoch: mem (CPU python)=52408.52734375MB; mem (CPU total)=63589.4140625MB
INFO:root:[   93] Training loss: 0.72307941, Validation loss: 0.72425513, Gradient norm: 7.63453912
INFO:root:At the start of the epoch: mem (CPU python)=52429.6875MB; mem (CPU total)=63630.8671875MB
INFO:root:[   94] Training loss: 0.72306041, Validation loss: 0.72385581, Gradient norm: 7.74883262
INFO:root:At the start of the epoch: mem (CPU python)=52450.85546875MB; mem (CPU total)=63670.80078125MB
INFO:root:[   95] Training loss: 0.72316388, Validation loss: 0.72420805, Gradient norm: 7.60120073
INFO:root:At the start of the epoch: mem (CPU python)=52472.01953125MB; mem (CPU total)=63715.88671875MB
INFO:root:[   96] Training loss: 0.72281655, Validation loss: 0.72441923, Gradient norm: 8.50878800
INFO:root:At the start of the epoch: mem (CPU python)=52493.18359375MB; mem (CPU total)=63747.4140625MB
INFO:root:[   97] Training loss: 0.72273720, Validation loss: 0.72342638, Gradient norm: 9.50365468
INFO:root:At the start of the epoch: mem (CPU python)=52514.34765625MB; mem (CPU total)=63788.5234375MB
INFO:root:[   98] Training loss: 0.72286527, Validation loss: 0.72322907, Gradient norm: 8.66619569
INFO:root:At the start of the epoch: mem (CPU python)=52535.51171875MB; mem (CPU total)=63828.92578125MB
INFO:root:[   99] Training loss: 0.72302075, Validation loss: 0.72226811, Gradient norm: 9.07240820
INFO:root:At the start of the epoch: mem (CPU python)=52556.67578125MB; mem (CPU total)=63868.9609375MB
INFO:root:[  100] Training loss: 0.72297660, Validation loss: 0.72400270, Gradient norm: 9.27540321
INFO:root:At the start of the epoch: mem (CPU python)=52577.8359375MB; mem (CPU total)=63908.19140625MB
INFO:root:[  101] Training loss: 0.72257170, Validation loss: 0.72282030, Gradient norm: 10.36353523
INFO:root:At the start of the epoch: mem (CPU python)=52599.00390625MB; mem (CPU total)=63947.54296875MB
INFO:root:[  102] Training loss: 0.72232243, Validation loss: 0.72355222, Gradient norm: 9.23738698
INFO:root:At the start of the epoch: mem (CPU python)=52620.16796875MB; mem (CPU total)=63988.1640625MB
INFO:root:[  103] Training loss: 0.72283244, Validation loss: 0.72346186, Gradient norm: 10.93660462
INFO:root:At the start of the epoch: mem (CPU python)=52641.33203125MB; mem (CPU total)=64039.7734375MB
INFO:root:[  104] Training loss: 0.72251800, Validation loss: 0.72317545, Gradient norm: 10.98918687
INFO:root:At the start of the epoch: mem (CPU python)=52662.4921875MB; mem (CPU total)=64056.1484375MB
INFO:root:[  105] Training loss: 0.72201083, Validation loss: 0.72355046, Gradient norm: 10.18793198
INFO:root:At the start of the epoch: mem (CPU python)=52683.66015625MB; mem (CPU total)=64079.04296875MB
INFO:root:[  106] Training loss: 0.72204893, Validation loss: 0.72210690, Gradient norm: 11.48142566
INFO:root:At the start of the epoch: mem (CPU python)=52704.82421875MB; mem (CPU total)=64102.9140625MB
INFO:root:[  107] Training loss: 0.72201269, Validation loss: 0.72277560, Gradient norm: 11.02317212
INFO:root:At the start of the epoch: mem (CPU python)=52725.98828125MB; mem (CPU total)=64147.90625MB
INFO:root:[  108] Training loss: 0.72173467, Validation loss: 0.72201691, Gradient norm: 10.80313679
INFO:root:At the start of the epoch: mem (CPU python)=52747.1484375MB; mem (CPU total)=64200.78515625MB
INFO:root:[  109] Training loss: 0.72211607, Validation loss: 0.72186743, Gradient norm: 12.49755056
INFO:root:At the start of the epoch: mem (CPU python)=52768.3125MB; mem (CPU total)=64252.09375MB
INFO:root:[  110] Training loss: 0.72193617, Validation loss: 0.72201440, Gradient norm: 10.73683650
INFO:root:At the start of the epoch: mem (CPU python)=52789.4765625MB; mem (CPU total)=64306.390625MB
INFO:root:[  111] Training loss: 0.72195578, Validation loss: 0.72187940, Gradient norm: 13.59697725
INFO:root:At the start of the epoch: mem (CPU python)=52810.64453125MB; mem (CPU total)=64358.21484375MB
INFO:root:[  112] Training loss: 0.72161428, Validation loss: 0.72211785, Gradient norm: 12.02044757
INFO:root:At the start of the epoch: mem (CPU python)=52831.80859375MB; mem (CPU total)=64410.98828125MB
INFO:root:[  113] Training loss: 0.72139121, Validation loss: 0.72249367, Gradient norm: 11.57942669
INFO:root:At the start of the epoch: mem (CPU python)=52852.97265625MB; mem (CPU total)=64463.30859375MB
INFO:root:[  114] Training loss: 0.72149831, Validation loss: 0.72230393, Gradient norm: 12.64209444
INFO:root:At the start of the epoch: mem (CPU python)=52874.13671875MB; mem (CPU total)=64517.00390625MB
INFO:root:[  115] Training loss: 0.72124623, Validation loss: 0.72180901, Gradient norm: 13.22490198
INFO:root:At the start of the epoch: mem (CPU python)=52895.3046875MB; mem (CPU total)=64569.68359375MB
INFO:root:[  116] Training loss: 0.72141779, Validation loss: 0.72295871, Gradient norm: 12.83297609
INFO:root:At the start of the epoch: mem (CPU python)=52916.46484375MB; mem (CPU total)=64622.10546875MB
INFO:root:[  117] Training loss: 0.72136198, Validation loss: 0.72170851, Gradient norm: 13.52068086
INFO:root:At the start of the epoch: mem (CPU python)=52937.62890625MB; mem (CPU total)=64675.078125MB
INFO:root:[  118] Training loss: 0.72115223, Validation loss: 0.72171312, Gradient norm: 14.79311301
INFO:root:At the start of the epoch: mem (CPU python)=52958.79296875MB; mem (CPU total)=64727.234375MB
INFO:root:[  119] Training loss: 0.72125169, Validation loss: 0.72205242, Gradient norm: 14.96270166
INFO:root:At the start of the epoch: mem (CPU python)=52979.95703125MB; mem (CPU total)=64781.51953125MB
INFO:root:[  120] Training loss: 0.72076161, Validation loss: 0.72176129, Gradient norm: 15.24660451
INFO:root:At the start of the epoch: mem (CPU python)=53001.12109375MB; mem (CPU total)=64833.2578125MB
INFO:root:[  121] Training loss: 0.72134166, Validation loss: 0.72128670, Gradient norm: 16.76656090
INFO:root:At the start of the epoch: mem (CPU python)=53022.2890625MB; mem (CPU total)=64887.01171875MB
INFO:root:[  122] Training loss: 0.72083563, Validation loss: 0.72161997, Gradient norm: 13.93022403
INFO:root:At the start of the epoch: mem (CPU python)=53043.44921875MB; mem (CPU total)=64937.9609375MB
INFO:root:[  123] Training loss: 0.72071725, Validation loss: 0.72265542, Gradient norm: 16.28494147
INFO:root:At the start of the epoch: mem (CPU python)=53064.61328125MB; mem (CPU total)=64994.0859375MB
INFO:root:[  124] Training loss: 0.72059226, Validation loss: 0.72112811, Gradient norm: 14.37122070
INFO:root:At the start of the epoch: mem (CPU python)=53085.77734375MB; mem (CPU total)=65043.33203125MB
INFO:root:[  125] Training loss: 0.72062380, Validation loss: 0.72079982, Gradient norm: 15.54301564
INFO:root:At the start of the epoch: mem (CPU python)=53106.94140625MB; mem (CPU total)=65098.84765625MB
INFO:root:[  126] Training loss: 0.72054765, Validation loss: 0.72163546, Gradient norm: 15.48274392
INFO:root:At the start of the epoch: mem (CPU python)=53128.10546875MB; mem (CPU total)=65148.6484375MB
INFO:root:[  127] Training loss: 0.72097235, Validation loss: 0.72097657, Gradient norm: 16.25449515
INFO:root:At the start of the epoch: mem (CPU python)=53149.26953125MB; mem (CPU total)=65203.5390625MB
INFO:root:[  128] Training loss: 0.72049949, Validation loss: 0.72020959, Gradient norm: 16.89270529
INFO:root:At the start of the epoch: mem (CPU python)=53170.43359375MB; mem (CPU total)=65252.5234375MB
INFO:root:[  129] Training loss: 0.72038165, Validation loss: 0.72099783, Gradient norm: 18.19278374
INFO:root:At the start of the epoch: mem (CPU python)=53191.59765625MB; mem (CPU total)=65306.98828125MB
INFO:root:[  130] Training loss: 0.72051085, Validation loss: 0.72158502, Gradient norm: 17.66403298
INFO:root:At the start of the epoch: mem (CPU python)=53212.76171875MB; mem (CPU total)=65358.77734375MB
INFO:root:[  131] Training loss: 0.72037414, Validation loss: 0.72136727, Gradient norm: 18.76598903
INFO:root:At the start of the epoch: mem (CPU python)=53233.92578125MB; mem (CPU total)=65413.04296875MB
INFO:root:[  132] Training loss: 0.72027191, Validation loss: 0.72053419, Gradient norm: 18.29648678
INFO:root:At the start of the epoch: mem (CPU python)=53255.09375MB; mem (CPU total)=65462.98046875MB
INFO:root:[  133] Training loss: 0.72037933, Validation loss: 0.72086757, Gradient norm: 18.41673531
INFO:root:At the start of the epoch: mem (CPU python)=53276.2578125MB; mem (CPU total)=65517.453125MB
INFO:root:[  134] Training loss: 0.72016160, Validation loss: 0.72047144, Gradient norm: 17.88295041
INFO:root:At the start of the epoch: mem (CPU python)=53297.421875MB; mem (CPU total)=65568.51953125MB
INFO:root:[  135] Training loss: 0.71999792, Validation loss: 0.72017500, Gradient norm: 18.14638928
INFO:root:At the start of the epoch: mem (CPU python)=53318.5859375MB; mem (CPU total)=65624.5234375MB
INFO:root:[  136] Training loss: 0.71961175, Validation loss: 0.72018986, Gradient norm: 19.12476292
INFO:root:At the start of the epoch: mem (CPU python)=53339.74609375MB; mem (CPU total)=65673.109375MB
INFO:root:[  137] Training loss: 0.71979229, Validation loss: 0.72088170, Gradient norm: 21.10005812
INFO:root:At the start of the epoch: mem (CPU python)=53360.9140625MB; mem (CPU total)=65726.97265625MB
INFO:root:[  138] Training loss: 0.71980212, Validation loss: 0.72070120, Gradient norm: 21.55198420
INFO:root:At the start of the epoch: mem (CPU python)=53382.078125MB; mem (CPU total)=65778.30078125MB
INFO:root:[  139] Training loss: 0.71980353, Validation loss: 0.72113465, Gradient norm: 20.42042980
INFO:root:At the start of the epoch: mem (CPU python)=53403.2421875MB; mem (CPU total)=65831.74609375MB
INFO:root:[  140] Training loss: 0.71976411, Validation loss: 0.72001840, Gradient norm: 21.11141457
INFO:root:At the start of the epoch: mem (CPU python)=53424.40625MB; mem (CPU total)=65884.72265625MB
INFO:root:[  141] Training loss: 0.71952728, Validation loss: 0.72024079, Gradient norm: 22.41790208
INFO:root:At the start of the epoch: mem (CPU python)=53445.5703125MB; mem (CPU total)=65936.84765625MB
INFO:root:[  142] Training loss: 0.71954493, Validation loss: 0.72042291, Gradient norm: 22.29435412
INFO:root:At the start of the epoch: mem (CPU python)=53466.734375MB; mem (CPU total)=65989.3359375MB
INFO:root:[  143] Training loss: 0.71900868, Validation loss: 0.71988952, Gradient norm: 22.79771667
INFO:root:At the start of the epoch: mem (CPU python)=53487.90234375MB; mem (CPU total)=66041.671875MB
INFO:root:[  144] Training loss: 0.71915797, Validation loss: 0.71940340, Gradient norm: 21.73814717
INFO:root:At the start of the epoch: mem (CPU python)=53509.06640625MB; mem (CPU total)=66097.6953125MB
INFO:root:[  145] Training loss: 0.71947697, Validation loss: 0.71919234, Gradient norm: 22.97943320
INFO:root:At the start of the epoch: mem (CPU python)=53530.23046875MB; mem (CPU total)=66145.890625MB
INFO:root:[  146] Training loss: 0.71923847, Validation loss: 0.71979693, Gradient norm: 23.29646333
INFO:root:At the start of the epoch: mem (CPU python)=53551.390625MB; mem (CPU total)=66203.93359375MB
INFO:root:[  147] Training loss: 0.71928690, Validation loss: 0.72077982, Gradient norm: 23.33301579
INFO:root:At the start of the epoch: mem (CPU python)=53572.5546875MB; mem (CPU total)=66251.796875MB
INFO:root:[  148] Training loss: 0.71929435, Validation loss: 0.72087619, Gradient norm: 24.55777851
INFO:root:At the start of the epoch: mem (CPU python)=53593.71875MB; mem (CPU total)=66305.19921875MB
INFO:root:[  149] Training loss: 0.71933197, Validation loss: 0.71871199, Gradient norm: 25.37654517
INFO:root:At the start of the epoch: mem (CPU python)=53614.88671875MB; mem (CPU total)=66356.28125MB
INFO:root:[  150] Training loss: 0.71941298, Validation loss: 0.71943464, Gradient norm: 24.58662548
INFO:root:At the start of the epoch: mem (CPU python)=53636.05078125MB; mem (CPU total)=66410.28515625MB
INFO:root:[  151] Training loss: 0.71952921, Validation loss: 0.71941074, Gradient norm: 25.61715092
INFO:root:At the start of the epoch: mem (CPU python)=53657.21484375MB; mem (CPU total)=66461.24609375MB
INFO:root:[  152] Training loss: 0.71920285, Validation loss: 0.71948858, Gradient norm: 25.70597251
INFO:root:At the start of the epoch: mem (CPU python)=53678.37890625MB; mem (CPU total)=66514.26953125MB
INFO:root:[  153] Training loss: 0.71899969, Validation loss: 0.71973700, Gradient norm: 24.89637047
INFO:root:At the start of the epoch: mem (CPU python)=53699.54296875MB; mem (CPU total)=66565.06640625MB
INFO:root:[  154] Training loss: 0.71894502, Validation loss: 0.71984649, Gradient norm: 25.27732371
INFO:root:At the start of the epoch: mem (CPU python)=53720.70703125MB; mem (CPU total)=66622.625MB
INFO:root:[  155] Training loss: 0.71905575, Validation loss: 0.71991939, Gradient norm: 25.34710350
INFO:root:At the start of the epoch: mem (CPU python)=53741.8671875MB; mem (CPU total)=66669.984375MB
INFO:root:[  156] Training loss: 0.71881571, Validation loss: 0.71942232, Gradient norm: 25.60125959
INFO:root:At the start of the epoch: mem (CPU python)=53763.03125MB; mem (CPU total)=66723.12109375MB
INFO:root:[  157] Training loss: 0.71867643, Validation loss: 0.71913718, Gradient norm: 25.64053125
INFO:root:At the start of the epoch: mem (CPU python)=53784.1953125MB; mem (CPU total)=66774.18359375MB
INFO:root:[  158] Training loss: 0.71900176, Validation loss: 0.71928939, Gradient norm: 25.65842959
INFO:root:At the start of the epoch: mem (CPU python)=53805.359375MB; mem (CPU total)=66828.484375MB
INFO:root:EP 158: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=53826.52734375MB; mem (CPU total)=66860.31640625MB
INFO:root:Training the model took 12966.88s.
INFO:root:Emptying the cuda cache took 0.063s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.71931
INFO:root:EnergyScoreValidation: 0.58335
INFO:root:CRPSValidation: 0.23775
INFO:root:Gaussian NLLValidation: 2.45046
INFO:root:CoverageValidation: 0.58483
INFO:root:IntervalWidthValidation: 0.53148
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.58688
INFO:root:EnergyScoreTest: 0.44863
INFO:root:CRPSTest: 0.18374
INFO:root:Gaussian NLLTest: 0.80245
INFO:root:CoverageTest: 0.7262
INFO:root:IntervalWidthTest: 0.61207
INFO:root:After validation: mem (CPU python)=54132.60546875MB; mem (CPU total)=66959.13671875MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.3, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=54132.60546875MB; mem (CPU total)=66974.625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 297795584
INFO:root:After setting up the model: mem (CPU python)=54132.60546875MB; mem (CPU total)=66975.1171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=66994.22265625MB
INFO:root:[    1] Training loss: 0.91148850, Validation loss: 0.78543667, Gradient norm: 0.34498457
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67039.44140625MB
INFO:root:[    2] Training loss: 0.77848178, Validation loss: 0.77562927, Gradient norm: 0.25048972
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67087.09375MB
INFO:root:[    3] Training loss: 0.77014527, Validation loss: 0.76652339, Gradient norm: 0.33547879
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67135.3125MB
INFO:root:[    4] Training loss: 0.76947195, Validation loss: 0.77195521, Gradient norm: 0.68171746
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67186.421875MB
INFO:root:[    5] Training loss: 0.76539464, Validation loss: 0.76119911, Gradient norm: 0.98382504
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67228.9921875MB
INFO:root:[    6] Training loss: 0.76602868, Validation loss: 0.76419763, Gradient norm: 1.38921347
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67276.56640625MB
INFO:root:[    7] Training loss: 0.75829054, Validation loss: 0.74486744, Gradient norm: 1.69338475
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67324.69140625MB
INFO:root:[    8] Training loss: 0.75999408, Validation loss: 0.75922625, Gradient norm: 2.51368363
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67374.53125MB
INFO:root:[    9] Training loss: 0.75835277, Validation loss: 0.79353143, Gradient norm: 2.81433941
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67417.90625MB
INFO:root:[   10] Training loss: 0.75555245, Validation loss: 0.75370488, Gradient norm: 3.01131548
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67466.55859375MB
INFO:root:[   11] Training loss: 0.75487248, Validation loss: 0.75493329, Gradient norm: 3.20091370
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67513.58984375MB
INFO:root:[   12] Training loss: 0.75172652, Validation loss: 0.76313668, Gradient norm: 3.26759291
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67566.03125MB
INFO:root:[   13] Training loss: 0.75271890, Validation loss: 0.76997000, Gradient norm: 3.47701492
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67608.296875MB
INFO:root:[   14] Training loss: 0.75297873, Validation loss: 0.77000165, Gradient norm: 3.83672720
INFO:root:At the start of the epoch: mem (CPU python)=54132.60546875MB; mem (CPU total)=67656.3515625MB
INFO:root:[   15] Training loss: 0.74413359, Validation loss: 0.74480406, Gradient norm: 3.64452556
INFO:root:At the start of the epoch: mem (CPU python)=54150.75MB; mem (CPU total)=67705.0MB
INFO:root:[   16] Training loss: 0.75140760, Validation loss: 0.73042704, Gradient norm: 4.45492453
INFO:root:At the start of the epoch: mem (CPU python)=54171.91015625MB; mem (CPU total)=67752.3671875MB
INFO:root:[   17] Training loss: 0.74733552, Validation loss: 0.74027068, Gradient norm: 4.28579619
INFO:root:At the start of the epoch: mem (CPU python)=54193.07421875MB; mem (CPU total)=67797.89453125MB
INFO:root:[   18] Training loss: 0.74603338, Validation loss: 0.73571377, Gradient norm: 4.37529457
INFO:root:At the start of the epoch: mem (CPU python)=54214.23828125MB; mem (CPU total)=67843.76171875MB
INFO:root:[   19] Training loss: 0.74745229, Validation loss: 0.74416765, Gradient norm: 5.06623456
INFO:root:At the start of the epoch: mem (CPU python)=54235.40234375MB; mem (CPU total)=67892.40234375MB
INFO:root:[   20] Training loss: 0.74793250, Validation loss: 0.74999936, Gradient norm: 5.10027767
INFO:root:At the start of the epoch: mem (CPU python)=54256.56640625MB; mem (CPU total)=67940.171875MB
INFO:root:[   21] Training loss: 0.74753871, Validation loss: 0.74001128, Gradient norm: 5.17393066
INFO:root:At the start of the epoch: mem (CPU python)=54277.734375MB; mem (CPU total)=67989.46484375MB
INFO:root:[   22] Training loss: 0.74845423, Validation loss: 0.72774585, Gradient norm: 5.11293449
INFO:root:At the start of the epoch: mem (CPU python)=54298.8984375MB; mem (CPU total)=68033.703125MB
INFO:root:[   23] Training loss: 0.74197900, Validation loss: 0.74409919, Gradient norm: 5.02698596
INFO:root:At the start of the epoch: mem (CPU python)=54320.05859375MB; mem (CPU total)=68082.32421875MB
INFO:root:[   24] Training loss: 0.74778116, Validation loss: 0.77614151, Gradient norm: 5.65979039
INFO:root:At the start of the epoch: mem (CPU python)=54341.22265625MB; mem (CPU total)=68129.875MB
INFO:root:[   25] Training loss: 0.74639963, Validation loss: 0.72632179, Gradient norm: 5.51974500
INFO:root:At the start of the epoch: mem (CPU python)=54362.38671875MB; mem (CPU total)=68180.140625MB
INFO:root:[   26] Training loss: 0.74476423, Validation loss: 0.75338438, Gradient norm: 5.64091698
INFO:root:At the start of the epoch: mem (CPU python)=54383.55078125MB; mem (CPU total)=68222.94140625MB
INFO:root:[   27] Training loss: 0.74151095, Validation loss: 0.75209420, Gradient norm: 5.65363631
INFO:root:At the start of the epoch: mem (CPU python)=54404.71875MB; mem (CPU total)=68271.71484375MB
INFO:root:[   28] Training loss: 0.74859989, Validation loss: 0.73665338, Gradient norm: 5.96743992
INFO:root:At the start of the epoch: mem (CPU python)=54425.8828125MB; mem (CPU total)=68318.7265625MB
INFO:root:[   29] Training loss: 0.74388710, Validation loss: 0.74941897, Gradient norm: 6.00187628
INFO:root:At the start of the epoch: mem (CPU python)=54447.046875MB; mem (CPU total)=68369.453125MB
INFO:root:[   30] Training loss: 0.75081728, Validation loss: 0.75452689, Gradient norm: 6.73310954
INFO:root:At the start of the epoch: mem (CPU python)=54468.2109375MB; mem (CPU total)=68413.65234375MB
INFO:root:[   31] Training loss: 0.74410826, Validation loss: 0.74863996, Gradient norm: 6.28418519
INFO:root:At the start of the epoch: mem (CPU python)=54489.375MB; mem (CPU total)=68459.44921875MB
INFO:root:[   32] Training loss: 0.75421342, Validation loss: 0.77752220, Gradient norm: 7.36162910
INFO:root:At the start of the epoch: mem (CPU python)=54510.5390625MB; mem (CPU total)=68507.92578125MB
INFO:root:[   33] Training loss: 0.74685015, Validation loss: 0.73892092, Gradient norm: 6.83822603
INFO:root:At the start of the epoch: mem (CPU python)=54531.69921875MB; mem (CPU total)=68555.52734375MB
INFO:root:[   34] Training loss: 0.75045318, Validation loss: 0.73447520, Gradient norm: 6.91243252
INFO:root:At the start of the epoch: mem (CPU python)=54552.86328125MB; mem (CPU total)=68603.7578125MB
INFO:root:[   35] Training loss: 0.74181293, Validation loss: 0.75123314, Gradient norm: 6.61510346
INFO:root:At the start of the epoch: mem (CPU python)=54574.02734375MB; mem (CPU total)=68651.58984375MB
INFO:root:[   36] Training loss: 0.74531361, Validation loss: 0.76296126, Gradient norm: 7.05087199
INFO:root:At the start of the epoch: mem (CPU python)=54595.19140625MB; mem (CPU total)=68696.98046875MB
INFO:root:[   37] Training loss: 0.75567306, Validation loss: 0.75757656, Gradient norm: 7.72488108
INFO:root:At the start of the epoch: mem (CPU python)=54616.359375MB; mem (CPU total)=68744.62109375MB
INFO:root:[   38] Training loss: 0.75108225, Validation loss: 0.72011274, Gradient norm: 7.49833814
INFO:root:At the start of the epoch: mem (CPU python)=54637.5234375MB; mem (CPU total)=68794.5703125MB
INFO:root:[   39] Training loss: 0.74528985, Validation loss: 0.76553375, Gradient norm: 7.46125240
INFO:root:At the start of the epoch: mem (CPU python)=54658.6875MB; mem (CPU total)=68837.76171875MB
INFO:root:[   40] Training loss: 0.74848600, Validation loss: 0.74773709, Gradient norm: 7.35989759
INFO:root:At the start of the epoch: mem (CPU python)=54679.8515625MB; mem (CPU total)=68886.28125MB
INFO:root:[   41] Training loss: 0.74914610, Validation loss: 0.79966519, Gradient norm: 7.87194216
INFO:root:At the start of the epoch: mem (CPU python)=54701.015625MB; mem (CPU total)=68933.38671875MB
INFO:root:[   42] Training loss: 0.75589887, Validation loss: 0.73972845, Gradient norm: 8.13908082
INFO:root:At the start of the epoch: mem (CPU python)=54722.17578125MB; mem (CPU total)=68978.11328125MB
INFO:root:[   43] Training loss: 0.75054067, Validation loss: 0.75563788, Gradient norm: 7.74741929
INFO:root:At the start of the epoch: mem (CPU python)=54743.34375MB; mem (CPU total)=69016.58203125MB
INFO:root:[   44] Training loss: 0.75706355, Validation loss: 0.73490599, Gradient norm: 8.59550155
INFO:root:At the start of the epoch: mem (CPU python)=54764.5078125MB; mem (CPU total)=69055.70703125MB
INFO:root:[   45] Training loss: 0.76183477, Validation loss: 0.75870396, Gradient norm: 8.57151160
INFO:root:At the start of the epoch: mem (CPU python)=54785.671875MB; mem (CPU total)=69086.34375MB
INFO:root:[   46] Training loss: 0.75055566, Validation loss: 0.77022269, Gradient norm: 8.04224975
INFO:root:At the start of the epoch: mem (CPU python)=54806.8359375MB; mem (CPU total)=69125.2890625MB
INFO:root:[   47] Training loss: 0.75783689, Validation loss: 0.77432134, Gradient norm: 8.42728162
INFO:root:At the start of the epoch: mem (CPU python)=54828.0MB; mem (CPU total)=69158.02734375MB
INFO:root:[   48] Training loss: 0.76099089, Validation loss: 0.72805275, Gradient norm: 8.59442898
INFO:root:At the start of the epoch: mem (CPU python)=54849.1640625MB; mem (CPU total)=69198.24609375MB
INFO:root:[   49] Training loss: 0.74081062, Validation loss: 0.71851141, Gradient norm: 7.73043354
INFO:root:At the start of the epoch: mem (CPU python)=54870.33203125MB; mem (CPU total)=69232.57421875MB
INFO:root:[   50] Training loss: 0.75267126, Validation loss: 0.74708885, Gradient norm: 9.02718975
INFO:root:At the start of the epoch: mem (CPU python)=54891.4921875MB; mem (CPU total)=69269.578125MB
INFO:root:[   51] Training loss: 0.75688651, Validation loss: 0.75652642, Gradient norm: 9.57080151
INFO:root:At the start of the epoch: mem (CPU python)=54912.65625MB; mem (CPU total)=69306.9140625MB
INFO:root:[   52] Training loss: 0.77161663, Validation loss: 0.75233821, Gradient norm: 10.19012939
INFO:root:At the start of the epoch: mem (CPU python)=54933.81640625MB; mem (CPU total)=69345.59765625MB
INFO:root:[   53] Training loss: 0.75717684, Validation loss: 0.80026185, Gradient norm: 9.49601372
INFO:root:At the start of the epoch: mem (CPU python)=54954.984375MB; mem (CPU total)=69380.953125MB
INFO:root:[   54] Training loss: 0.76043690, Validation loss: 0.72961200, Gradient norm: 9.63364324
INFO:root:At the start of the epoch: mem (CPU python)=54976.15234375MB; mem (CPU total)=69416.95703125MB
INFO:root:[   55] Training loss: 0.77423467, Validation loss: 0.75660699, Gradient norm: 10.75183176
INFO:root:At the start of the epoch: mem (CPU python)=54997.31640625MB; mem (CPU total)=69454.2109375MB
INFO:root:[   56] Training loss: 0.76120711, Validation loss: 0.78651384, Gradient norm: 10.14641351
INFO:root:At the start of the epoch: mem (CPU python)=55018.48046875MB; mem (CPU total)=69493.21875MB
INFO:root:[   57] Training loss: 0.77277609, Validation loss: 0.78096802, Gradient norm: 11.03812854
INFO:root:At the start of the epoch: mem (CPU python)=55039.64453125MB; mem (CPU total)=69529.27734375MB
INFO:root:[   58] Training loss: 0.77838380, Validation loss: 0.80703617, Gradient norm: 10.10626344
INFO:root:At the start of the epoch: mem (CPU python)=55060.80859375MB; mem (CPU total)=69569.66015625MB
INFO:root:[   59] Training loss: 0.78005483, Validation loss: 0.75767125, Gradient norm: 11.37521270
INFO:root:At the start of the epoch: mem (CPU python)=55081.9765625MB; mem (CPU total)=69604.7265625MB
INFO:root:[   60] Training loss: 0.76544502, Validation loss: 0.77204936, Gradient norm: 10.23245021
INFO:root:At the start of the epoch: mem (CPU python)=55103.140625MB; mem (CPU total)=69642.55078125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.77759454, Validation loss: 0.79056282, Gradient norm: 10.75623193
INFO:root:At the start of the epoch: mem (CPU python)=55124.30078125MB; mem (CPU total)=69678.8671875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 0.71736003, Validation loss: 0.71610945, Gradient norm: 9.31973864
INFO:root:At the start of the epoch: mem (CPU python)=55145.46484375MB; mem (CPU total)=69712.7421875MB
INFO:root:[   63] Training loss: 0.69664107, Validation loss: 0.69924356, Gradient norm: 8.38517981
INFO:root:At the start of the epoch: mem (CPU python)=55166.62890625MB; mem (CPU total)=69748.5859375MB
INFO:root:[   64] Training loss: 0.69777014, Validation loss: 0.68955079, Gradient norm: 10.34472752
INFO:root:At the start of the epoch: mem (CPU python)=55187.79296875MB; mem (CPU total)=69785.7109375MB
INFO:root:[   65] Training loss: 0.69736981, Validation loss: 0.70332229, Gradient norm: 11.02339884
INFO:root:At the start of the epoch: mem (CPU python)=55208.953125MB; mem (CPU total)=69822.4765625MB
INFO:root:[   66] Training loss: 0.69975203, Validation loss: 0.70055947, Gradient norm: 12.86339753
INFO:root:At the start of the epoch: mem (CPU python)=55230.1171875MB; mem (CPU total)=69859.59375MB
INFO:root:[   67] Training loss: 0.70283244, Validation loss: 0.71200580, Gradient norm: 13.51648425
INFO:root:At the start of the epoch: mem (CPU python)=55251.28125MB; mem (CPU total)=69898.8828125MB
INFO:root:[   68] Training loss: 0.70568986, Validation loss: 0.71245315, Gradient norm: 15.24559903
INFO:root:At the start of the epoch: mem (CPU python)=55272.4453125MB; mem (CPU total)=69934.00390625MB
INFO:root:[   69] Training loss: 0.70569706, Validation loss: 0.70792724, Gradient norm: 16.25242626
INFO:root:At the start of the epoch: mem (CPU python)=55293.609375MB; mem (CPU total)=69969.7109375MB
INFO:root:[   70] Training loss: 0.70600174, Validation loss: 0.70460431, Gradient norm: 16.74003213
INFO:root:At the start of the epoch: mem (CPU python)=55314.77734375MB; mem (CPU total)=70006.875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   71] Training loss: 0.70970150, Validation loss: 0.71056146, Gradient norm: 18.22887280
INFO:root:At the start of the epoch: mem (CPU python)=55335.9375MB; mem (CPU total)=70045.67578125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   72] Training loss: 0.69162850, Validation loss: 0.68753706, Gradient norm: 13.91480186
INFO:root:At the start of the epoch: mem (CPU python)=55357.1015625MB; mem (CPU total)=70079.28125MB
INFO:root:[   73] Training loss: 0.68266317, Validation loss: 0.68462178, Gradient norm: 8.55926079
INFO:root:At the start of the epoch: mem (CPU python)=55378.265625MB; mem (CPU total)=70116.609375MB
INFO:root:[   74] Training loss: 0.68148176, Validation loss: 0.68443038, Gradient norm: 10.81888145
INFO:root:At the start of the epoch: mem (CPU python)=55399.4296875MB; mem (CPU total)=70152.85546875MB
INFO:root:[   75] Training loss: 0.68221287, Validation loss: 0.68298474, Gradient norm: 11.59771887
INFO:root:At the start of the epoch: mem (CPU python)=55420.59375MB; mem (CPU total)=70192.15234375MB
INFO:root:[   76] Training loss: 0.68222792, Validation loss: 0.69141290, Gradient norm: 12.46948361
INFO:root:At the start of the epoch: mem (CPU python)=55441.7578125MB; mem (CPU total)=70228.94140625MB
INFO:root:[   77] Training loss: 0.68297853, Validation loss: 0.68458640, Gradient norm: 12.89321737
INFO:root:At the start of the epoch: mem (CPU python)=55462.92578125MB; mem (CPU total)=70264.734375MB
INFO:root:[   78] Training loss: 0.68292592, Validation loss: 0.68742478, Gradient norm: 13.52927671
INFO:root:At the start of the epoch: mem (CPU python)=55484.08984375MB; mem (CPU total)=70302.4375MB
INFO:root:[   79] Training loss: 0.68194806, Validation loss: 0.68432739, Gradient norm: 15.05945812
INFO:root:At the start of the epoch: mem (CPU python)=55505.25390625MB; mem (CPU total)=70339.83984375MB
INFO:root:[   80] Training loss: 0.68179963, Validation loss: 0.68191650, Gradient norm: 14.17404763
INFO:root:At the start of the epoch: mem (CPU python)=55526.4140625MB; mem (CPU total)=70373.484375MB
INFO:root:[   81] Training loss: 0.68204402, Validation loss: 0.68180610, Gradient norm: 14.65843323
INFO:root:At the start of the epoch: mem (CPU python)=55547.578125MB; mem (CPU total)=70409.921875MB
INFO:root:[   82] Training loss: 0.68249085, Validation loss: 0.68266817, Gradient norm: 15.36094080
INFO:root:At the start of the epoch: mem (CPU python)=55568.73828125MB; mem (CPU total)=70448.296875MB
INFO:root:[   83] Training loss: 0.68268400, Validation loss: 0.68384650, Gradient norm: 15.57637958
INFO:root:At the start of the epoch: mem (CPU python)=55589.90625MB; mem (CPU total)=70484.94140625MB
INFO:root:[   84] Training loss: 0.68325364, Validation loss: 0.68409975, Gradient norm: 16.17814520
INFO:root:At the start of the epoch: mem (CPU python)=55611.0703125MB; mem (CPU total)=70522.5078125MB
INFO:root:[   85] Training loss: 0.68315725, Validation loss: 0.68434840, Gradient norm: 16.74287912
INFO:root:At the start of the epoch: mem (CPU python)=55632.234375MB; mem (CPU total)=70558.56640625MB
INFO:root:[   86] Training loss: 0.68282854, Validation loss: 0.68365680, Gradient norm: 17.31455702
INFO:root:At the start of the epoch: mem (CPU python)=55653.3984375MB; mem (CPU total)=70598.91015625MB
INFO:root:[   87] Training loss: 0.68440480, Validation loss: 0.68213430, Gradient norm: 17.95342837
INFO:root:At the start of the epoch: mem (CPU python)=55674.5625MB; mem (CPU total)=70633.859375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   88] Training loss: 0.68366826, Validation loss: 0.68447517, Gradient norm: 18.84773843
INFO:root:At the start of the epoch: mem (CPU python)=55695.73046875MB; mem (CPU total)=70669.3671875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   89] Training loss: 0.67967373, Validation loss: 0.68163116, Gradient norm: 11.18192654
INFO:root:At the start of the epoch: mem (CPU python)=55716.859375MB; mem (CPU total)=70708.953125MB
INFO:root:[   90] Training loss: 0.67784188, Validation loss: 0.67856169, Gradient norm: 8.24598474
INFO:root:At the start of the epoch: mem (CPU python)=55738.0234375MB; mem (CPU total)=70743.8046875MB
INFO:root:[   91] Training loss: 0.67717902, Validation loss: 0.67770873, Gradient norm: 8.39810525
INFO:root:At the start of the epoch: mem (CPU python)=55759.1875MB; mem (CPU total)=70780.90625MB
INFO:root:[   92] Training loss: 0.67686080, Validation loss: 0.67820078, Gradient norm: 8.94601680
INFO:root:At the start of the epoch: mem (CPU python)=55780.3515625MB; mem (CPU total)=70817.57421875MB
INFO:root:[   93] Training loss: 0.67712386, Validation loss: 0.67701614, Gradient norm: 10.64482993
INFO:root:At the start of the epoch: mem (CPU python)=55801.51953125MB; mem (CPU total)=70857.91015625MB
INFO:root:[   94] Training loss: 0.67647735, Validation loss: 0.67819147, Gradient norm: 10.00428537
INFO:root:At the start of the epoch: mem (CPU python)=55822.68359375MB; mem (CPU total)=70895.08203125MB
INFO:root:[   95] Training loss: 0.67616488, Validation loss: 0.67722077, Gradient norm: 10.64699705
INFO:root:At the start of the epoch: mem (CPU python)=55843.84765625MB; mem (CPU total)=70931.51171875MB
INFO:root:[   96] Training loss: 0.67605031, Validation loss: 0.67626459, Gradient norm: 11.83410009
INFO:root:At the start of the epoch: mem (CPU python)=55865.01171875MB; mem (CPU total)=70967.79296875MB
INFO:root:[   97] Training loss: 0.67625531, Validation loss: 0.67668511, Gradient norm: 11.91564850
INFO:root:At the start of the epoch: mem (CPU python)=55886.17578125MB; mem (CPU total)=71001.05078125MB
INFO:root:[   98] Training loss: 0.67584024, Validation loss: 0.67516034, Gradient norm: 12.24777798
INFO:root:At the start of the epoch: mem (CPU python)=55907.33984375MB; mem (CPU total)=71039.05078125MB
INFO:root:[   99] Training loss: 0.67551152, Validation loss: 0.67759651, Gradient norm: 13.43420843
INFO:root:At the start of the epoch: mem (CPU python)=55928.49609375MB; mem (CPU total)=71075.8203125MB
INFO:root:[  100] Training loss: 0.67525519, Validation loss: 0.67629287, Gradient norm: 13.45991608
INFO:root:At the start of the epoch: mem (CPU python)=55949.6640625MB; mem (CPU total)=71112.40625MB
INFO:root:[  101] Training loss: 0.67541945, Validation loss: 0.67604079, Gradient norm: 13.39943728
INFO:root:At the start of the epoch: mem (CPU python)=55970.828125MB; mem (CPU total)=71150.51171875MB
INFO:root:[  102] Training loss: 0.67575106, Validation loss: 0.67677971, Gradient norm: 14.15497134
INFO:root:At the start of the epoch: mem (CPU python)=55991.9921875MB; mem (CPU total)=71186.33984375MB
INFO:root:[  103] Training loss: 0.67536826, Validation loss: 0.67633411, Gradient norm: 14.02675812
INFO:root:At the start of the epoch: mem (CPU python)=56013.15625MB; mem (CPU total)=71223.953125MB
INFO:root:[  104] Training loss: 0.67524715, Validation loss: 0.67638689, Gradient norm: 16.25386275
INFO:root:At the start of the epoch: mem (CPU python)=56034.3203125MB; mem (CPU total)=71257.77734375MB
INFO:root:[  105] Training loss: 0.67658938, Validation loss: 0.67589889, Gradient norm: 23.81201822
INFO:root:At the start of the epoch: mem (CPU python)=56055.48828125MB; mem (CPU total)=71297.12109375MB
INFO:root:[  106] Training loss: 0.67520945, Validation loss: 0.67463506, Gradient norm: 15.57092964
INFO:root:At the start of the epoch: mem (CPU python)=56076.65234375MB; mem (CPU total)=71332.66796875MB
INFO:root:[  107] Training loss: 0.67519544, Validation loss: 0.67627332, Gradient norm: 15.75908714
INFO:root:At the start of the epoch: mem (CPU python)=56097.81640625MB; mem (CPU total)=71370.1015625MB
INFO:root:[  108] Training loss: 0.67552541, Validation loss: 0.67482970, Gradient norm: 19.76315613
INFO:root:At the start of the epoch: mem (CPU python)=56118.9765625MB; mem (CPU total)=71405.546875MB
INFO:root:[  109] Training loss: 0.67484010, Validation loss: 0.67414450, Gradient norm: 16.01890994
INFO:root:At the start of the epoch: mem (CPU python)=56140.140625MB; mem (CPU total)=71446.20703125MB
INFO:root:[  110] Training loss: 0.67515091, Validation loss: 0.67467820, Gradient norm: 16.41434318
INFO:root:At the start of the epoch: mem (CPU python)=56161.3046875MB; mem (CPU total)=71480.41015625MB
INFO:root:[  111] Training loss: 0.67448036, Validation loss: 0.67424200, Gradient norm: 16.66129280
INFO:root:At the start of the epoch: mem (CPU python)=56182.47265625MB; mem (CPU total)=71518.1640625MB
INFO:root:[  112] Training loss: 0.67461508, Validation loss: 0.67531462, Gradient norm: 17.59676559
INFO:root:At the start of the epoch: mem (CPU python)=56203.63671875MB; mem (CPU total)=71556.89453125MB
INFO:root:[  113] Training loss: 0.67467051, Validation loss: 0.68120593, Gradient norm: 18.13528715
INFO:root:At the start of the epoch: mem (CPU python)=56224.61328125MB; mem (CPU total)=71591.953125MB
INFO:root:[  114] Training loss: 0.67645830, Validation loss: 0.67580594, Gradient norm: 29.78992745
INFO:root:At the start of the epoch: mem (CPU python)=56245.77734375MB; mem (CPU total)=71626.03515625MB
INFO:root:[  115] Training loss: 0.67485130, Validation loss: 0.67524292, Gradient norm: 19.75872602
INFO:root:At the start of the epoch: mem (CPU python)=56266.9453125MB; mem (CPU total)=71664.265625MB
INFO:root:[  116] Training loss: 0.67469381, Validation loss: 0.67543235, Gradient norm: 17.74906960
INFO:root:At the start of the epoch: mem (CPU python)=56288.10546875MB; mem (CPU total)=71704.234375MB
INFO:root:[  117] Training loss: 0.67431086, Validation loss: 0.67495160, Gradient norm: 19.65923654
INFO:root:At the start of the epoch: mem (CPU python)=56309.26953125MB; mem (CPU total)=71738.73046875MB
INFO:root:[  118] Training loss: 0.67420902, Validation loss: 0.67511393, Gradient norm: 18.52648659
INFO:root:At the start of the epoch: mem (CPU python)=56330.4296875MB; mem (CPU total)=71765.484375MB
INFO:root:EP 118: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=56351.59375MB; mem (CPU total)=71791.19921875MB
INFO:root:[  120] Training loss: 0.75891510, Validation loss: 0.75737357, Gradient norm: 21.29176731
INFO:root:At the start of the epoch: mem (CPU python)=56372.76171875MB; mem (CPU total)=71811.375MB
INFO:root:[  121] Training loss: 0.75694192, Validation loss: 0.75608158, Gradient norm: 18.81849568
INFO:root:At the start of the epoch: mem (CPU python)=56393.92578125MB; mem (CPU total)=71859.0546875MB
INFO:root:[  122] Training loss: 0.75598510, Validation loss: 0.75601109, Gradient norm: 16.01506180
INFO:root:At the start of the epoch: mem (CPU python)=56415.08984375MB; mem (CPU total)=71907.859375MB
INFO:root:[  123] Training loss: 0.75596178, Validation loss: 0.75564068, Gradient norm: 19.71717229
INFO:root:At the start of the epoch: mem (CPU python)=56436.25390625MB; mem (CPU total)=71960.61328125MB
INFO:root:[  124] Training loss: 0.75529988, Validation loss: 0.75600926, Gradient norm: 17.28731392
INFO:root:At the start of the epoch: mem (CPU python)=56457.41796875MB; mem (CPU total)=72008.734375MB
INFO:root:[  125] Training loss: 0.75515835, Validation loss: 0.75578881, Gradient norm: 16.85606514
INFO:root:At the start of the epoch: mem (CPU python)=56478.58203125MB; mem (CPU total)=72062.578125MB
INFO:root:[  126] Training loss: 0.75488467, Validation loss: 0.75599347, Gradient norm: 16.31705712
INFO:root:At the start of the epoch: mem (CPU python)=56499.74609375MB; mem (CPU total)=72119.62109375MB
INFO:root:[  127] Training loss: 0.75466508, Validation loss: 0.75542085, Gradient norm: 16.35382770
INFO:root:At the start of the epoch: mem (CPU python)=56520.91015625MB; mem (CPU total)=72162.73828125MB
INFO:root:[  128] Training loss: 0.75464222, Validation loss: 0.75505598, Gradient norm: 17.73652065
INFO:root:At the start of the epoch: mem (CPU python)=56542.07421875MB; mem (CPU total)=72214.890625MB
INFO:root:[  129] Training loss: 0.75448169, Validation loss: 0.75410420, Gradient norm: 19.35481466
INFO:root:At the start of the epoch: mem (CPU python)=56563.1015625MB; mem (CPU total)=72263.83984375MB
INFO:root:[  130] Training loss: 0.75408695, Validation loss: 0.75414836, Gradient norm: 16.73793236
INFO:root:At the start of the epoch: mem (CPU python)=56583.71875MB; mem (CPU total)=72315.18359375MB
INFO:root:[  131] Training loss: 0.75423163, Validation loss: 0.75546705, Gradient norm: 17.60992695
INFO:root:At the start of the epoch: mem (CPU python)=56604.12890625MB; mem (CPU total)=72366.43359375MB
INFO:root:[  132] Training loss: 0.75404964, Validation loss: 0.75369860, Gradient norm: 18.44262576
INFO:root:At the start of the epoch: mem (CPU python)=56625.296875MB; mem (CPU total)=72419.421875MB
INFO:root:[  133] Training loss: 0.75379656, Validation loss: 0.75410853, Gradient norm: 19.17067875
INFO:root:At the start of the epoch: mem (CPU python)=56646.453125MB; mem (CPU total)=72472.7265625MB
INFO:root:[  134] Training loss: 0.75358063, Validation loss: 0.75447033, Gradient norm: 19.11643212
INFO:root:At the start of the epoch: mem (CPU python)=56667.62109375MB; mem (CPU total)=72519.5390625MB
INFO:root:[  135] Training loss: 0.75340686, Validation loss: 0.75446979, Gradient norm: 19.44839901
INFO:root:At the start of the epoch: mem (CPU python)=56688.78515625MB; mem (CPU total)=72573.19921875MB
INFO:root:[  136] Training loss: 0.75351414, Validation loss: 0.75437473, Gradient norm: 19.98075839
INFO:root:At the start of the epoch: mem (CPU python)=56709.9453125MB; mem (CPU total)=72622.90625MB
INFO:root:[  137] Training loss: 0.75355568, Validation loss: 0.75452730, Gradient norm: 20.04902417
INFO:root:At the start of the epoch: mem (CPU python)=56731.109375MB; mem (CPU total)=72674.21484375MB
INFO:root:[  138] Training loss: 0.75287245, Validation loss: 0.75416771, Gradient norm: 17.92268674
INFO:root:At the start of the epoch: mem (CPU python)=56752.27734375MB; mem (CPU total)=72727.70703125MB
INFO:root:[  139] Training loss: 0.75335576, Validation loss: 0.75407070, Gradient norm: 20.13584952
INFO:root:At the start of the epoch: mem (CPU python)=56773.44140625MB; mem (CPU total)=72776.03125MB
INFO:root:[  140] Training loss: 0.75338151, Validation loss: 0.75339588, Gradient norm: 21.18928532
INFO:root:At the start of the epoch: mem (CPU python)=56794.60546875MB; mem (CPU total)=72828.27734375MB
INFO:root:[  141] Training loss: 0.75273630, Validation loss: 0.75375278, Gradient norm: 19.23497526
INFO:root:At the start of the epoch: mem (CPU python)=56815.76953125MB; mem (CPU total)=72877.546875MB
INFO:root:[  142] Training loss: 0.75289493, Validation loss: 0.75371061, Gradient norm: 19.55784207
INFO:root:At the start of the epoch: mem (CPU python)=56836.93359375MB; mem (CPU total)=72930.2421875MB
INFO:root:[  143] Training loss: 0.75279453, Validation loss: 0.75310000, Gradient norm: 20.54842955
INFO:root:At the start of the epoch: mem (CPU python)=56858.09765625MB; mem (CPU total)=72980.79296875MB
INFO:root:[  144] Training loss: 0.75283853, Validation loss: 0.75316097, Gradient norm: 21.25633054
INFO:root:At the start of the epoch: mem (CPU python)=56879.26171875MB; mem (CPU total)=73031.5546875MB
INFO:root:[  145] Training loss: 0.75278302, Validation loss: 0.75389785, Gradient norm: 20.45612730
INFO:root:At the start of the epoch: mem (CPU python)=56900.4296875MB; mem (CPU total)=73085.7421875MB
INFO:root:[  146] Training loss: 0.75271406, Validation loss: 0.75354353, Gradient norm: 20.85465294
INFO:root:At the start of the epoch: mem (CPU python)=56921.58984375MB; mem (CPU total)=73133.05078125MB
INFO:root:[  147] Training loss: 0.75263915, Validation loss: 0.75332270, Gradient norm: 21.62401251
INFO:root:At the start of the epoch: mem (CPU python)=56942.75390625MB; mem (CPU total)=73185.515625MB
INFO:root:[  148] Training loss: 0.75236851, Validation loss: 0.75313208, Gradient norm: 20.62677846
INFO:root:At the start of the epoch: mem (CPU python)=56963.91796875MB; mem (CPU total)=73235.98046875MB
INFO:root:[  149] Training loss: 0.75234859, Validation loss: 0.75267868, Gradient norm: 21.84832795
INFO:root:At the start of the epoch: mem (CPU python)=56985.0859375MB; mem (CPU total)=73287.9609375MB
INFO:root:[  150] Training loss: 0.75204100, Validation loss: 0.75271697, Gradient norm: 20.68894363
INFO:root:At the start of the epoch: mem (CPU python)=57006.24609375MB; mem (CPU total)=73343.0859375MB
INFO:root:[  151] Training loss: 0.75238634, Validation loss: 0.75252686, Gradient norm: 22.69850757
INFO:root:At the start of the epoch: mem (CPU python)=57027.41796875MB; mem (CPU total)=73392.6796875MB
INFO:root:[  152] Training loss: 0.75212961, Validation loss: 0.75244447, Gradient norm: 22.81263679
INFO:root:At the start of the epoch: mem (CPU python)=57048.578125MB; mem (CPU total)=73441.9375MB
INFO:root:[  153] Training loss: 0.75202421, Validation loss: 0.75241273, Gradient norm: 21.57923334
INFO:root:At the start of the epoch: mem (CPU python)=57069.7421875MB; mem (CPU total)=73489.046875MB
INFO:root:[  154] Training loss: 0.75196546, Validation loss: 0.75221930, Gradient norm: 24.04864232
INFO:root:At the start of the epoch: mem (CPU python)=57089.5546875MB; mem (CPU total)=73541.63671875MB
INFO:root:[  155] Training loss: 0.75192873, Validation loss: 0.75231251, Gradient norm: 23.08841036
INFO:root:At the start of the epoch: mem (CPU python)=57109.30859375MB; mem (CPU total)=73594.3515625MB
INFO:root:[  156] Training loss: 0.75159741, Validation loss: 0.75180792, Gradient norm: 23.89051524
INFO:root:At the start of the epoch: mem (CPU python)=57129.08984375MB; mem (CPU total)=73638.4453125MB
INFO:root:[  157] Training loss: 0.75193206, Validation loss: 0.75212278, Gradient norm: 24.68786177
INFO:root:At the start of the epoch: mem (CPU python)=57149.40234375MB; mem (CPU total)=73692.28515625MB
INFO:root:[  158] Training loss: 0.75166866, Validation loss: 0.75207019, Gradient norm: 23.42661664
INFO:root:At the start of the epoch: mem (CPU python)=57170.13671875MB; mem (CPU total)=73740.5859375MB
INFO:root:[  159] Training loss: 0.75169450, Validation loss: 0.75177753, Gradient norm: 23.42543305
INFO:root:At the start of the epoch: mem (CPU python)=57191.29296875MB; mem (CPU total)=73792.94921875MB
INFO:root:[  160] Training loss: 0.75141222, Validation loss: 0.75167295, Gradient norm: 23.81585138
INFO:root:At the start of the epoch: mem (CPU python)=57212.45703125MB; mem (CPU total)=73845.5MB
INFO:root:[  161] Training loss: 0.75109312, Validation loss: 0.75285514, Gradient norm: 23.76834200
INFO:root:At the start of the epoch: mem (CPU python)=57233.62109375MB; mem (CPU total)=73897.55859375MB
INFO:root:[  162] Training loss: 0.75097339, Validation loss: 0.75201952, Gradient norm: 23.39507116
INFO:root:At the start of the epoch: mem (CPU python)=57254.7890625MB; mem (CPU total)=73946.05078125MB
INFO:root:[  163] Training loss: 0.75127396, Validation loss: 0.75189188, Gradient norm: 25.46324532
INFO:root:At the start of the epoch: mem (CPU python)=57275.953125MB; mem (CPU total)=73995.0859375MB
INFO:root:[  164] Training loss: 0.75127155, Validation loss: 0.75212669, Gradient norm: 26.88039507
INFO:root:At the start of the epoch: mem (CPU python)=57297.1171875MB; mem (CPU total)=74049.64453125MB
INFO:root:[  165] Training loss: 0.75116881, Validation loss: 0.75205011, Gradient norm: 25.73332367
INFO:root:At the start of the epoch: mem (CPU python)=57318.27734375MB; mem (CPU total)=74099.3984375MB
INFO:root:[  166] Training loss: 0.75102448, Validation loss: 0.75183824, Gradient norm: 25.56804618
INFO:root:At the start of the epoch: mem (CPU python)=57339.44140625MB; mem (CPU total)=74148.64453125MB
INFO:root:[  167] Training loss: 0.75126924, Validation loss: 0.75150250, Gradient norm: 24.71294237
INFO:root:At the start of the epoch: mem (CPU python)=57360.609375MB; mem (CPU total)=74201.3046875MB
INFO:root:[  168] Training loss: 0.75097832, Validation loss: 0.75209365, Gradient norm: 24.07826995
INFO:root:At the start of the epoch: mem (CPU python)=57381.76953125MB; mem (CPU total)=74249.203125MB
INFO:root:[  169] Training loss: 0.75153183, Validation loss: 0.75169292, Gradient norm: 25.74083582
INFO:root:At the start of the epoch: mem (CPU python)=57402.93359375MB; mem (CPU total)=74302.88671875MB
INFO:root:[  170] Training loss: 0.75112452, Validation loss: 0.75093921, Gradient norm: 26.47675868
INFO:root:At the start of the epoch: mem (CPU python)=57424.09765625MB; mem (CPU total)=74356.0MB
INFO:root:[  171] Training loss: 0.75132694, Validation loss: 0.75133780, Gradient norm: 27.07173542
INFO:root:At the start of the epoch: mem (CPU python)=57443.7578125MB; mem (CPU total)=74401.5703125MB
INFO:root:[  172] Training loss: 0.75090324, Validation loss: 0.75185693, Gradient norm: 27.04444931
INFO:root:At the start of the epoch: mem (CPU python)=57464.7890625MB; mem (CPU total)=74454.86328125MB
INFO:root:[  173] Training loss: 0.75071228, Validation loss: 0.75080797, Gradient norm: 27.18696801
INFO:root:At the start of the epoch: mem (CPU python)=57485.94921875MB; mem (CPU total)=74502.95703125MB
INFO:root:[  174] Training loss: 0.75068271, Validation loss: 0.75149601, Gradient norm: 24.88740468
INFO:root:At the start of the epoch: mem (CPU python)=57507.109375MB; mem (CPU total)=74555.12109375MB
INFO:root:[  175] Training loss: 0.75080902, Validation loss: 0.75182842, Gradient norm: 26.34749009
INFO:root:At the start of the epoch: mem (CPU python)=57528.2734375MB; mem (CPU total)=74608.88671875MB
INFO:root:[  176] Training loss: 0.75100404, Validation loss: 0.75119272, Gradient norm: 27.61214606
INFO:root:At the start of the epoch: mem (CPU python)=57549.4375MB; mem (CPU total)=74656.78515625MB
INFO:root:[  177] Training loss: 0.75053538, Validation loss: 0.75105878, Gradient norm: 26.67254461
INFO:root:At the start of the epoch: mem (CPU python)=57570.58984375MB; mem (CPU total)=74710.26953125MB
INFO:root:[  178] Training loss: 0.75113412, Validation loss: 0.75160906, Gradient norm: 27.27175810
INFO:root:At the start of the epoch: mem (CPU python)=57591.7421875MB; mem (CPU total)=74756.39453125MB
INFO:root:[  179] Training loss: 0.75072936, Validation loss: 0.75026605, Gradient norm: 27.13074333
INFO:root:At the start of the epoch: mem (CPU python)=57612.90625MB; mem (CPU total)=74808.9375MB
INFO:root:[  180] Training loss: 0.75075893, Validation loss: 0.75139191, Gradient norm: 28.30224799
INFO:root:At the start of the epoch: mem (CPU python)=57634.0703125MB; mem (CPU total)=74861.83203125MB
INFO:root:[  181] Training loss: 0.75040105, Validation loss: 0.75090443, Gradient norm: 28.31942601
INFO:root:At the start of the epoch: mem (CPU python)=57655.234375MB; mem (CPU total)=74910.5546875MB
INFO:root:[  182] Training loss: 0.75069658, Validation loss: 0.75088899, Gradient norm: 28.16899517
INFO:root:At the start of the epoch: mem (CPU python)=57676.3984375MB; mem (CPU total)=74963.0078125MB
INFO:root:[  183] Training loss: 0.75024676, Validation loss: 0.75044986, Gradient norm: 26.35896733
INFO:root:At the start of the epoch: mem (CPU python)=57697.5546875MB; mem (CPU total)=75010.19921875MB
INFO:root:[  184] Training loss: 0.75034186, Validation loss: 0.75010542, Gradient norm: 30.15834003
INFO:root:At the start of the epoch: mem (CPU python)=57718.2890625MB; mem (CPU total)=75063.3828125MB
INFO:root:[  185] Training loss: 0.75035629, Validation loss: 0.75140585, Gradient norm: 27.44267237
INFO:root:At the start of the epoch: mem (CPU python)=57739.359375MB; mem (CPU total)=75116.1875MB
INFO:root:[  186] Training loss: 0.75035528, Validation loss: 0.75114194, Gradient norm: 27.84359436
INFO:root:At the start of the epoch: mem (CPU python)=57760.5234375MB; mem (CPU total)=75163.1171875MB
INFO:root:[  187] Training loss: 0.75032929, Validation loss: 0.75073145, Gradient norm: 30.48318217
INFO:root:At the start of the epoch: mem (CPU python)=57781.6875MB; mem (CPU total)=75217.625MB
INFO:root:[  188] Training loss: 0.75039073, Validation loss: 0.75134773, Gradient norm: 29.15245400
INFO:root:At the start of the epoch: mem (CPU python)=57802.8515625MB; mem (CPU total)=75266.01171875MB
INFO:root:[  189] Training loss: 0.75052223, Validation loss: 0.75062621, Gradient norm: 28.46228625
INFO:root:At the start of the epoch: mem (CPU python)=57824.01953125MB; mem (CPU total)=75322.45703125MB
INFO:root:[  190] Training loss: 0.75013370, Validation loss: 0.75015814, Gradient norm: 29.56856260
INFO:root:At the start of the epoch: mem (CPU python)=57845.18359375MB; mem (CPU total)=75369.80078125MB
INFO:root:[  191] Training loss: 0.75001634, Validation loss: 0.75033648, Gradient norm: 28.76655258
INFO:root:At the start of the epoch: mem (CPU python)=57866.34765625MB; mem (CPU total)=75416.55859375MB
INFO:root:[  192] Training loss: 0.75011585, Validation loss: 0.75085904, Gradient norm: 29.93837944
INFO:root:At the start of the epoch: mem (CPU python)=57887.515625MB; mem (CPU total)=75470.76953125MB
INFO:root:[  193] Training loss: 0.75068064, Validation loss: 0.75077296, Gradient norm: 30.53894094
INFO:root:At the start of the epoch: mem (CPU python)=57908.66015625MB; mem (CPU total)=75518.3046875MB
INFO:root:EP 193: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=57929.828125MB; mem (CPU total)=75551.78515625MB
INFO:root:Training the model took 16391.945s.
INFO:root:Emptying the cuda cache took 0.065s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.74522
INFO:root:EnergyScoreValidation: 0.60326
INFO:root:CRPSValidation: 0.24708
INFO:root:Gaussian NLLValidation: 2.55601
INFO:root:CoverageValidation: 0.59173
INFO:root:IntervalWidthValidation: 0.55768
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.60939
INFO:root:EnergyScoreTest: 0.46196
INFO:root:CRPSTest: 0.19001
INFO:root:Gaussian NLLTest: 0.76074
INFO:root:CoverageTest: 0.74642
INFO:root:IntervalWidthTest: 0.668
INFO:root:After validation: mem (CPU python)=58235.875MB; mem (CPU total)=75641.296875MB
