INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=577.62890625MB; mem (CPU total)=2972.73828125MB
INFO:root:############### Starting experiment with config file sswe/sfno.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=588.48828125MB; mem (CPU total)=2975.5859375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=590.2109375MB; mem (CPU total)=2976.03125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2292.8359375MB; mem (CPU total)=4441.66015625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2302.47265625MB; mem (CPU total)=4449.66796875MB
INFO:root:[    1] Training loss: 0.83318730, Validation loss: 0.73816248, Gradient norm: 0.60771032
INFO:root:At the start of the epoch: mem (CPU python)=4453.25MB; mem (CPU total)=6158.328125MB
INFO:root:[    2] Training loss: 0.73496889, Validation loss: 0.73539113, Gradient norm: 0.38440849
INFO:root:At the start of the epoch: mem (CPU python)=4475.72265625MB; mem (CPU total)=6177.2421875MB
INFO:root:[    3] Training loss: 0.73267302, Validation loss: 0.73223844, Gradient norm: 0.31569036
INFO:root:At the start of the epoch: mem (CPU python)=4497.15234375MB; mem (CPU total)=6200.30859375MB
INFO:root:[    4] Training loss: 0.72568760, Validation loss: 0.71224797, Gradient norm: 0.42025110
INFO:root:At the start of the epoch: mem (CPU python)=4519.66015625MB; mem (CPU total)=6217.19921875MB
INFO:root:[    5] Training loss: 0.68414872, Validation loss: 0.64939303, Gradient norm: 0.52165202
INFO:root:At the start of the epoch: mem (CPU python)=4539.046875MB; mem (CPU total)=6240.58203125MB
INFO:root:[    6] Training loss: 0.62124004, Validation loss: 0.59139576, Gradient norm: 0.75453584
INFO:root:At the start of the epoch: mem (CPU python)=4560.453125MB; mem (CPU total)=6260.484375MB
INFO:root:[    7] Training loss: 0.57106045, Validation loss: 0.54178082, Gradient norm: 0.90172416
INFO:root:At the start of the epoch: mem (CPU python)=4583.171875MB; mem (CPU total)=6283.84375MB
INFO:root:[    8] Training loss: 0.53751086, Validation loss: 0.51217314, Gradient norm: 1.01741338
INFO:root:At the start of the epoch: mem (CPU python)=4603.109375MB; mem (CPU total)=6254.921875MB
INFO:root:[    9] Training loss: 0.50987227, Validation loss: 0.49719173, Gradient norm: 0.99920223
INFO:root:At the start of the epoch: mem (CPU python)=4624.76171875MB; mem (CPU total)=6323.046875MB
INFO:root:[   10] Training loss: 0.50150972, Validation loss: 0.48877192, Gradient norm: 1.20166091
INFO:root:At the start of the epoch: mem (CPU python)=4645.59765625MB; mem (CPU total)=6344.76953125MB
INFO:root:[   11] Training loss: 0.49384541, Validation loss: 0.47507316, Gradient norm: 1.26835294
INFO:root:At the start of the epoch: mem (CPU python)=4667.63671875MB; mem (CPU total)=6364.88671875MB
INFO:root:[   12] Training loss: 0.47650067, Validation loss: 0.47446665, Gradient norm: 1.02930204
INFO:root:At the start of the epoch: mem (CPU python)=4687.8046875MB; mem (CPU total)=6385.52734375MB
INFO:root:[   13] Training loss: 0.46808503, Validation loss: 0.45858569, Gradient norm: 1.08378690
INFO:root:At the start of the epoch: mem (CPU python)=4709.42578125MB; mem (CPU total)=6406.859375MB
INFO:root:[   14] Training loss: 0.46326821, Validation loss: 0.45104820, Gradient norm: 1.13768729
INFO:root:At the start of the epoch: mem (CPU python)=4730.56640625MB; mem (CPU total)=6425.90625MB
INFO:root:[   15] Training loss: 0.45826861, Validation loss: 0.44458385, Gradient norm: 1.33531932
INFO:root:At the start of the epoch: mem (CPU python)=4751.8125MB; mem (CPU total)=6447.70703125MB
INFO:root:[   16] Training loss: 0.45516453, Validation loss: 0.44182311, Gradient norm: 1.45939196
INFO:root:At the start of the epoch: mem (CPU python)=4774.03125MB; mem (CPU total)=6471.2890625MB
INFO:root:[   17] Training loss: 0.45000139, Validation loss: 0.43573368, Gradient norm: 1.16976679
INFO:root:At the start of the epoch: mem (CPU python)=4794.59765625MB; mem (CPU total)=6492.109375MB
INFO:root:[   18] Training loss: 0.44554790, Validation loss: 0.43830644, Gradient norm: 1.28136756
INFO:root:At the start of the epoch: mem (CPU python)=4817.01171875MB; mem (CPU total)=6514.09375MB
INFO:root:[   19] Training loss: 0.44378450, Validation loss: 0.44125350, Gradient norm: 1.43930871
INFO:root:At the start of the epoch: mem (CPU python)=4840.2109375MB; mem (CPU total)=6609.27734375MB
INFO:root:[   20] Training loss: 0.43800659, Validation loss: 0.43361779, Gradient norm: 1.45647656
INFO:root:At the start of the epoch: mem (CPU python)=4862.0390625MB; mem (CPU total)=4679.03125MB
INFO:root:[   21] Training loss: 0.44041776, Validation loss: 0.43354037, Gradient norm: 1.49830238
INFO:root:At the start of the epoch: mem (CPU python)=4883.94140625MB; mem (CPU total)=4699.953125MB
INFO:root:[   22] Training loss: 0.43436332, Validation loss: 0.42565520, Gradient norm: 1.35539689
INFO:root:At the start of the epoch: mem (CPU python)=4905.25MB; mem (CPU total)=4741.734375MB
INFO:root:[   23] Training loss: 0.43454510, Validation loss: 0.43316446, Gradient norm: 1.76209396
INFO:root:At the start of the epoch: mem (CPU python)=4927.296875MB; mem (CPU total)=4861.4140625MB
INFO:root:[   24] Training loss: 0.43020171, Validation loss: 0.42810629, Gradient norm: 1.43537149
INFO:root:At the start of the epoch: mem (CPU python)=4948.46484375MB; mem (CPU total)=4942.640625MB
INFO:root:[   25] Training loss: 0.43402986, Validation loss: 0.42566085, Gradient norm: 1.43648949
INFO:root:At the start of the epoch: mem (CPU python)=4970.00390625MB; mem (CPU total)=5013.4140625MB
INFO:root:[   26] Training loss: 0.42625269, Validation loss: 0.43172911, Gradient norm: 1.63442358
INFO:root:At the start of the epoch: mem (CPU python)=4991.16796875MB; mem (CPU total)=4805.4921875MB
INFO:root:[   27] Training loss: 0.42645271, Validation loss: 0.41787924, Gradient norm: 1.60862020
INFO:root:At the start of the epoch: mem (CPU python)=5012.33203125MB; mem (CPU total)=4826.9609375MB
INFO:root:[   28] Training loss: 0.42543208, Validation loss: 0.42347930, Gradient norm: 1.61483484
INFO:root:At the start of the epoch: mem (CPU python)=5032.7109375MB; mem (CPU total)=4845.69140625MB
INFO:root:[   29] Training loss: 0.42353148, Validation loss: 0.41373675, Gradient norm: 1.83403653
INFO:root:At the start of the epoch: mem (CPU python)=5054.28515625MB; mem (CPU total)=4868.79296875MB
INFO:root:[   30] Training loss: 0.42205774, Validation loss: 0.41568484, Gradient norm: 1.64070107
INFO:root:At the start of the epoch: mem (CPU python)=5075.83984375MB; mem (CPU total)=4890.17578125MB
INFO:root:[   31] Training loss: 0.42226594, Validation loss: 0.41306641, Gradient norm: 1.78257508
INFO:root:At the start of the epoch: mem (CPU python)=5097.0078125MB; mem (CPU total)=4911.30859375MB
INFO:root:[   32] Training loss: 0.42148905, Validation loss: 0.40873200, Gradient norm: 2.00677704
INFO:root:At the start of the epoch: mem (CPU python)=5118.18359375MB; mem (CPU total)=4932.9921875MB
INFO:root:[   33] Training loss: 0.41952337, Validation loss: 0.41378541, Gradient norm: 1.66525238
INFO:root:At the start of the epoch: mem (CPU python)=5139.7265625MB; mem (CPU total)=4954.41015625MB
INFO:root:[   34] Training loss: 0.41715459, Validation loss: 0.40809867, Gradient norm: 1.66739843
INFO:root:At the start of the epoch: mem (CPU python)=5161.18359375MB; mem (CPU total)=4976.171875MB
INFO:root:[   35] Training loss: 0.41639789, Validation loss: 0.42005307, Gradient norm: 1.82860906
INFO:root:At the start of the epoch: mem (CPU python)=5182.8125MB; mem (CPU total)=4997.59765625MB
INFO:root:[   36] Training loss: 0.41456019, Validation loss: 0.39884029, Gradient norm: 2.08541572
INFO:root:At the start of the epoch: mem (CPU python)=5203.9765625MB; mem (CPU total)=5018.6328125MB
INFO:root:[   37] Training loss: 0.41354957, Validation loss: 0.40798843, Gradient norm: 1.85086374
INFO:root:At the start of the epoch: mem (CPU python)=5225.515625MB; mem (CPU total)=5040.44140625MB
INFO:root:[   38] Training loss: 0.41330986, Validation loss: 0.40170973, Gradient norm: 2.06043034
INFO:root:At the start of the epoch: mem (CPU python)=5247.44140625MB; mem (CPU total)=5061.546875MB
INFO:root:[   39] Training loss: 0.40814351, Validation loss: 0.39952980, Gradient norm: 2.07465404
INFO:root:At the start of the epoch: mem (CPU python)=5268.61328125MB; mem (CPU total)=5083.1328125MB
INFO:root:[   40] Training loss: 0.41538165, Validation loss: 0.40905295, Gradient norm: 1.76258416
INFO:root:At the start of the epoch: mem (CPU python)=5289.77734375MB; mem (CPU total)=5104.20703125MB
INFO:root:[   41] Training loss: 0.40918674, Validation loss: 0.39519090, Gradient norm: 2.33313930
INFO:root:At the start of the epoch: mem (CPU python)=5312.79296875MB; mem (CPU total)=5127.5390625MB
INFO:root:[   42] Training loss: 0.40466858, Validation loss: 0.39800866, Gradient norm: 2.28905325
INFO:root:At the start of the epoch: mem (CPU python)=5334.734375MB; mem (CPU total)=5148.7890625MB
INFO:root:[   43] Training loss: 0.41000274, Validation loss: 0.40988511, Gradient norm: 1.93796656
INFO:root:At the start of the epoch: mem (CPU python)=5355.91015625MB; mem (CPU total)=5169.7734375MB
INFO:root:[   44] Training loss: 0.40792951, Validation loss: 0.39711188, Gradient norm: 2.22878128
INFO:root:At the start of the epoch: mem (CPU python)=5377.08203125MB; mem (CPU total)=5191.34375MB
INFO:root:[   45] Training loss: 0.40577027, Validation loss: 0.40066659, Gradient norm: 2.28410722
INFO:root:At the start of the epoch: mem (CPU python)=5398.26171875MB; mem (CPU total)=5212.33984375MB
INFO:root:[   46] Training loss: 0.40368891, Validation loss: 0.38911475, Gradient norm: 2.49171920
INFO:root:At the start of the epoch: mem (CPU python)=5419.43359375MB; mem (CPU total)=5233.5859375MB
INFO:root:[   47] Training loss: 0.40114716, Validation loss: 0.38862814, Gradient norm: 2.54660404
INFO:root:At the start of the epoch: mem (CPU python)=5440.59765625MB; mem (CPU total)=5255.8828125MB
INFO:root:[   48] Training loss: 0.40491780, Validation loss: 0.39603734, Gradient norm: 2.72513426
INFO:root:At the start of the epoch: mem (CPU python)=5461.76171875MB; mem (CPU total)=5276.98828125MB
INFO:root:[   49] Training loss: 0.40487997, Validation loss: 0.38831538, Gradient norm: 2.05550861
INFO:root:At the start of the epoch: mem (CPU python)=5482.93359375MB; mem (CPU total)=5298.46484375MB
INFO:root:[   50] Training loss: 0.40334016, Validation loss: 0.40150318, Gradient norm: 2.71488608
INFO:root:At the start of the epoch: mem (CPU python)=5504.1015625MB; mem (CPU total)=5319.5625MB
INFO:root:[   51] Training loss: 0.40169717, Validation loss: 0.38978574, Gradient norm: 2.86652641
INFO:root:At the start of the epoch: mem (CPU python)=5525.26953125MB; mem (CPU total)=5340.5390625MB
INFO:root:[   52] Training loss: 0.40375267, Validation loss: 0.38601641, Gradient norm: 2.70552859
INFO:root:At the start of the epoch: mem (CPU python)=5546.43359375MB; mem (CPU total)=5362.2890625MB
INFO:root:[   53] Training loss: 0.40115244, Validation loss: 0.38924889, Gradient norm: 2.81147154
INFO:root:At the start of the epoch: mem (CPU python)=5567.69140625MB; mem (CPU total)=5383.55078125MB
INFO:root:[   54] Training loss: 0.40758363, Validation loss: 0.39695218, Gradient norm: 3.06516021
INFO:root:At the start of the epoch: mem (CPU python)=5589.13671875MB; mem (CPU total)=5404.26953125MB
INFO:root:[   55] Training loss: 0.40004415, Validation loss: 0.38310140, Gradient norm: 3.14112446
INFO:root:At the start of the epoch: mem (CPU python)=5610.30859375MB; mem (CPU total)=5425.125MB
INFO:root:[   56] Training loss: 0.40070700, Validation loss: 0.39107734, Gradient norm: 3.25494283
INFO:root:At the start of the epoch: mem (CPU python)=5631.48046875MB; mem (CPU total)=5445.92578125MB
INFO:root:[   57] Training loss: 0.40308933, Validation loss: 0.38574353, Gradient norm: 3.26496250
INFO:root:At the start of the epoch: mem (CPU python)=5652.65625MB; mem (CPU total)=5467.1484375MB
INFO:root:[   58] Training loss: 0.40384012, Validation loss: 0.39098429, Gradient norm: 2.96674402
INFO:root:At the start of the epoch: mem (CPU python)=5673.8203125MB; mem (CPU total)=5488.34375MB
INFO:root:[   59] Training loss: 0.40272938, Validation loss: 0.39135486, Gradient norm: 2.90915823
INFO:root:At the start of the epoch: mem (CPU python)=5696.484375MB; mem (CPU total)=5511.2265625MB
INFO:root:[   60] Training loss: 0.40601963, Validation loss: 0.41137379, Gradient norm: 3.56249456
INFO:root:At the start of the epoch: mem (CPU python)=5717.78515625MB; mem (CPU total)=5532.0390625MB
INFO:root:[   61] Training loss: 0.40008964, Validation loss: 0.40619075, Gradient norm: 2.88336921
INFO:root:At the start of the epoch: mem (CPU python)=5739.0625MB; mem (CPU total)=5554.23046875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   62] Training loss: 0.40180199, Validation loss: 0.39110809, Gradient norm: 2.98895058
INFO:root:At the start of the epoch: mem (CPU python)=5760.2265625MB; mem (CPU total)=5575.4140625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   63] Training loss: 0.37691954, Validation loss: 0.36607676, Gradient norm: 2.52510380
INFO:root:At the start of the epoch: mem (CPU python)=5781.390625MB; mem (CPU total)=5596.03125MB
INFO:root:[   64] Training loss: 0.36726428, Validation loss: 0.36091215, Gradient norm: 1.82973803
INFO:root:At the start of the epoch: mem (CPU python)=5803.0546875MB; mem (CPU total)=5617.3984375MB
INFO:root:[   65] Training loss: 0.36607278, Validation loss: 0.35634509, Gradient norm: 2.06208431
INFO:root:At the start of the epoch: mem (CPU python)=5824.21875MB; mem (CPU total)=5638.45703125MB
INFO:root:[   66] Training loss: 0.36816552, Validation loss: 0.35727001, Gradient norm: 2.94811536
INFO:root:At the start of the epoch: mem (CPU python)=5845.5234375MB; mem (CPU total)=5660.02734375MB
INFO:root:[   67] Training loss: 0.36553475, Validation loss: 0.35708296, Gradient norm: 2.44849352
INFO:root:At the start of the epoch: mem (CPU python)=5866.703125MB; mem (CPU total)=5680.8828125MB
INFO:root:[   68] Training loss: 0.36503705, Validation loss: 0.35742024, Gradient norm: 2.64166752
INFO:root:At the start of the epoch: mem (CPU python)=5888.109375MB; mem (CPU total)=5702.2578125MB
INFO:root:[   69] Training loss: 0.36431525, Validation loss: 0.35521233, Gradient norm: 2.98584293
INFO:root:At the start of the epoch: mem (CPU python)=5909.27734375MB; mem (CPU total)=5723.30078125MB
INFO:root:[   70] Training loss: 0.36382624, Validation loss: 0.35590986, Gradient norm: 3.20788633
INFO:root:At the start of the epoch: mem (CPU python)=5930.43359375MB; mem (CPU total)=5744.8984375MB
INFO:root:[   71] Training loss: 0.36427655, Validation loss: 0.35607431, Gradient norm: 3.19115114
INFO:root:At the start of the epoch: mem (CPU python)=5951.60546875MB; mem (CPU total)=5766.15234375MB
INFO:root:[   72] Training loss: 0.36288247, Validation loss: 0.35359108, Gradient norm: 3.28309226
INFO:root:At the start of the epoch: mem (CPU python)=5972.7734375MB; mem (CPU total)=5787.4453125MB
INFO:root:[   73] Training loss: 0.36521907, Validation loss: 0.35637458, Gradient norm: 3.91361475
INFO:root:At the start of the epoch: mem (CPU python)=5993.94140625MB; mem (CPU total)=5808.94921875MB
INFO:root:[   74] Training loss: 0.36267263, Validation loss: 0.35574383, Gradient norm: 3.74186286
INFO:root:At the start of the epoch: mem (CPU python)=6015.109375MB; mem (CPU total)=5829.6015625MB
INFO:root:[   75] Training loss: 0.36291746, Validation loss: 0.35586315, Gradient norm: 4.43834230
INFO:root:At the start of the epoch: mem (CPU python)=6036.28515625MB; mem (CPU total)=5851.1328125MB
INFO:root:[   76] Training loss: 0.36250979, Validation loss: 0.35344910, Gradient norm: 4.54347618
INFO:root:At the start of the epoch: mem (CPU python)=6057.4609375MB; mem (CPU total)=5872.2890625MB
INFO:root:[   77] Training loss: 0.36233670, Validation loss: 0.35586596, Gradient norm: 4.60669843
INFO:root:At the start of the epoch: mem (CPU python)=6079.97265625MB; mem (CPU total)=5894.6796875MB
INFO:root:[   78] Training loss: 0.36735694, Validation loss: 0.38830556, Gradient norm: 6.19012696
INFO:root:At the start of the epoch: mem (CPU python)=6101.1484375MB; mem (CPU total)=5916.16796875MB
INFO:root:[   79] Training loss: 0.36437819, Validation loss: 0.35440549, Gradient norm: 4.75015688
INFO:root:At the start of the epoch: mem (CPU python)=6122.31640625MB; mem (CPU total)=6208.69140625MB
INFO:root:[   80] Training loss: 0.36337087, Validation loss: 0.35704095, Gradient norm: 4.89514350
INFO:root:At the start of the epoch: mem (CPU python)=6143.63671875MB; mem (CPU total)=8126.81640625MB
INFO:root:[   81] Training loss: 0.36246818, Validation loss: 0.35406583, Gradient norm: 5.01502480
INFO:root:At the start of the epoch: mem (CPU python)=6166.89453125MB; mem (CPU total)=8150.64453125MB
INFO:root:[   82] Training loss: 0.36297664, Validation loss: 0.35370551, Gradient norm: 5.23697626
INFO:root:At the start of the epoch: mem (CPU python)=6188.59375MB; mem (CPU total)=8172.234375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   83] Training loss: 0.36247282, Validation loss: 0.35524383, Gradient norm: 5.42042487
INFO:root:At the start of the epoch: mem (CPU python)=6209.7734375MB; mem (CPU total)=8192.96484375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   84] Training loss: 0.35899787, Validation loss: 0.35009939, Gradient norm: 3.54719367
INFO:root:At the start of the epoch: mem (CPU python)=6230.953125MB; mem (CPU total)=8214.26171875MB
INFO:root:[   85] Training loss: 0.35555540, Validation loss: 0.34699013, Gradient norm: 2.25316041
INFO:root:At the start of the epoch: mem (CPU python)=6252.1328125MB; mem (CPU total)=8235.4375MB
INFO:root:[   86] Training loss: 0.35541754, Validation loss: 0.34736699, Gradient norm: 2.31065707
INFO:root:At the start of the epoch: mem (CPU python)=6273.2578125MB; mem (CPU total)=8256.3515625MB
INFO:root:[   87] Training loss: 0.35543328, Validation loss: 0.34694930, Gradient norm: 3.14961331
INFO:root:At the start of the epoch: mem (CPU python)=6294.4609375MB; mem (CPU total)=8277.859375MB
INFO:root:[   88] Training loss: 0.35513778, Validation loss: 0.34603643, Gradient norm: 2.49633419
INFO:root:At the start of the epoch: mem (CPU python)=6315.625MB; mem (CPU total)=8299.03125MB
INFO:root:[   89] Training loss: 0.35517636, Validation loss: 0.34567379, Gradient norm: 2.99463619
INFO:root:At the start of the epoch: mem (CPU python)=6336.78515625MB; mem (CPU total)=8320.1640625MB
INFO:root:[   90] Training loss: 0.35546169, Validation loss: 0.34756263, Gradient norm: 3.35582847
INFO:root:At the start of the epoch: mem (CPU python)=6357.953125MB; mem (CPU total)=8341.421875MB
INFO:root:[   91] Training loss: 0.35466621, Validation loss: 0.34622472, Gradient norm: 3.17193197
INFO:root:At the start of the epoch: mem (CPU python)=6379.12109375MB; mem (CPU total)=8362.5625MB
INFO:root:[   92] Training loss: 0.35469653, Validation loss: 0.34558454, Gradient norm: 3.24258535
INFO:root:At the start of the epoch: mem (CPU python)=6400.29296875MB; mem (CPU total)=8383.859375MB
INFO:root:[   93] Training loss: 0.35474828, Validation loss: 0.34707471, Gradient norm: 3.39918662
INFO:root:At the start of the epoch: mem (CPU python)=6421.45703125MB; mem (CPU total)=8404.99609375MB
INFO:root:[   94] Training loss: 0.35477567, Validation loss: 0.34650319, Gradient norm: 3.43256487
INFO:root:At the start of the epoch: mem (CPU python)=6442.63671875MB; mem (CPU total)=8426.15234375MB
INFO:root:[   95] Training loss: 0.35532015, Validation loss: 0.34588062, Gradient norm: 3.69149508
INFO:root:At the start of the epoch: mem (CPU python)=6463.8046875MB; mem (CPU total)=8447.21875MB
INFO:root:[   96] Training loss: 0.35473527, Validation loss: 0.34581704, Gradient norm: 4.85894863
INFO:root:At the start of the epoch: mem (CPU python)=6485.05078125MB; mem (CPU total)=8468.625MB
INFO:root:[   97] Training loss: 0.35610527, Validation loss: 0.35066036, Gradient norm: 6.59118025
INFO:root:At the start of the epoch: mem (CPU python)=6506.22265625MB; mem (CPU total)=8489.734375MB
INFO:root:[   98] Training loss: 0.35522384, Validation loss: 0.34508139, Gradient norm: 5.12229982
INFO:root:At the start of the epoch: mem (CPU python)=6527.69921875MB; mem (CPU total)=8511.13671875MB
INFO:root:[   99] Training loss: 0.35470647, Validation loss: 0.34541274, Gradient norm: 4.45469741
INFO:root:At the start of the epoch: mem (CPU python)=6548.859375MB; mem (CPU total)=8533.890625MB
INFO:root:[  100] Training loss: 0.35437640, Validation loss: 0.34631207, Gradient norm: 4.60791585
INFO:root:At the start of the epoch: mem (CPU python)=6570.0234375MB; mem (CPU total)=6381.828125MB
INFO:root:[  101] Training loss: 0.35543076, Validation loss: 0.34665198, Gradient norm: 6.63634640
INFO:root:At the start of the epoch: mem (CPU python)=6591.4140625MB; mem (CPU total)=6404.44140625MB
INFO:root:[  102] Training loss: 0.35414903, Validation loss: 0.34597049, Gradient norm: 4.68947003
INFO:root:At the start of the epoch: mem (CPU python)=6612.5859375MB; mem (CPU total)=6425.83984375MB
INFO:root:[  103] Training loss: 0.35488191, Validation loss: 0.34610928, Gradient norm: 4.97020506
INFO:root:At the start of the epoch: mem (CPU python)=6634.21875MB; mem (CPU total)=6447.0MB
INFO:root:[  104] Training loss: 0.35455709, Validation loss: 0.34596449, Gradient norm: 5.22285598
INFO:root:At the start of the epoch: mem (CPU python)=6655.38671875MB; mem (CPU total)=6468.1640625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  105] Training loss: 0.35417515, Validation loss: 0.34565687, Gradient norm: 5.30113811
INFO:root:At the start of the epoch: mem (CPU python)=6676.609375MB; mem (CPU total)=6485.41015625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  106] Training loss: 0.35330058, Validation loss: 0.34541428, Gradient norm: 3.49228294
INFO:root:At the start of the epoch: mem (CPU python)=6696.3515625MB; mem (CPU total)=6509.7734375MB
INFO:root:[  107] Training loss: 0.35230116, Validation loss: 0.34449936, Gradient norm: 2.47384691
INFO:root:At the start of the epoch: mem (CPU python)=6718.21484375MB; mem (CPU total)=6530.96875MB
INFO:root:[  108] Training loss: 0.35253498, Validation loss: 0.34352193, Gradient norm: 2.46571413
INFO:root:At the start of the epoch: mem (CPU python)=6739.375MB; mem (CPU total)=6551.6953125MB
INFO:root:[  109] Training loss: 0.35240726, Validation loss: 0.34382797, Gradient norm: 2.60053160
INFO:root:At the start of the epoch: mem (CPU python)=6761.0703125MB; mem (CPU total)=6573.31640625MB
INFO:root:[  110] Training loss: 0.35280633, Validation loss: 0.34391241, Gradient norm: 2.87008074
INFO:root:At the start of the epoch: mem (CPU python)=6782.359375MB; mem (CPU total)=6594.69921875MB
INFO:root:[  111] Training loss: 0.35276540, Validation loss: 0.34374266, Gradient norm: 2.86536618
INFO:root:At the start of the epoch: mem (CPU python)=6803.52734375MB; mem (CPU total)=6615.62109375MB
INFO:root:[  112] Training loss: 0.35186549, Validation loss: 0.34416267, Gradient norm: 2.66693924
INFO:root:At the start of the epoch: mem (CPU python)=6825.1171875MB; mem (CPU total)=6637.0078125MB
INFO:root:[  113] Training loss: 0.35228715, Validation loss: 0.34367282, Gradient norm: 3.10551907
INFO:root:At the start of the epoch: mem (CPU python)=6846.28125MB; mem (CPU total)=6658.08203125MB
INFO:root:[  114] Training loss: 0.35243791, Validation loss: 0.34350981, Gradient norm: 3.13927532
INFO:root:At the start of the epoch: mem (CPU python)=6867.44921875MB; mem (CPU total)=6679.10546875MB
INFO:root:[  115] Training loss: 0.35237863, Validation loss: 0.34358814, Gradient norm: 3.09204323
INFO:root:At the start of the epoch: mem (CPU python)=6888.609375MB; mem (CPU total)=6700.27734375MB
INFO:root:[  116] Training loss: 0.35207334, Validation loss: 0.34364651, Gradient norm: 3.07451573
INFO:root:At the start of the epoch: mem (CPU python)=6909.77734375MB; mem (CPU total)=6721.69921875MB
INFO:root:[  117] Training loss: 0.35216687, Validation loss: 0.34345431, Gradient norm: 3.29022083
INFO:root:At the start of the epoch: mem (CPU python)=6930.94140625MB; mem (CPU total)=6742.86328125MB
INFO:root:[  118] Training loss: 0.35264881, Validation loss: 0.34368058, Gradient norm: 3.17010360
INFO:root:At the start of the epoch: mem (CPU python)=6952.4765625MB; mem (CPU total)=6764.51171875MB
INFO:root:[  119] Training loss: 0.35271655, Validation loss: 0.34434733, Gradient norm: 3.35256174
INFO:root:At the start of the epoch: mem (CPU python)=6974.04296875MB; mem (CPU total)=6786.4140625MB
INFO:root:[  120] Training loss: 0.35225688, Validation loss: 0.34346008, Gradient norm: 3.27151708
INFO:root:At the start of the epoch: mem (CPU python)=6995.203125MB; mem (CPU total)=6807.75MB
INFO:root:[  121] Training loss: 0.35218401, Validation loss: 0.34376807, Gradient norm: 3.49171447
INFO:root:At the start of the epoch: mem (CPU python)=7017.08203125MB; mem (CPU total)=6829.59765625MB
INFO:root:[  122] Training loss: 0.35180654, Validation loss: 0.34374285, Gradient norm: 3.68067211
INFO:root:At the start of the epoch: mem (CPU python)=7038.8359375MB; mem (CPU total)=6851.5MB
INFO:root:[  123] Training loss: 0.35248417, Validation loss: 0.34328649, Gradient norm: 3.45627358
INFO:root:At the start of the epoch: mem (CPU python)=7060.55078125MB; mem (CPU total)=6872.6796875MB
INFO:root:[  124] Training loss: 0.35204660, Validation loss: 0.34405508, Gradient norm: 3.34620910
INFO:root:At the start of the epoch: mem (CPU python)=7081.71484375MB; mem (CPU total)=6893.60546875MB
INFO:root:[  125] Training loss: 0.35266281, Validation loss: 0.34318206, Gradient norm: 3.56348471
INFO:root:At the start of the epoch: mem (CPU python)=7102.9296875MB; mem (CPU total)=6915.5390625MB
INFO:root:[  126] Training loss: 0.35184097, Validation loss: 0.34304132, Gradient norm: 4.15241946
INFO:root:At the start of the epoch: mem (CPU python)=7124.09765625MB; mem (CPU total)=6936.703125MB
INFO:root:[  127] Training loss: 0.35130515, Validation loss: 0.34352110, Gradient norm: 3.91884011
INFO:root:At the start of the epoch: mem (CPU python)=7145.578125MB; mem (CPU total)=6957.8359375MB
INFO:root:[  128] Training loss: 0.35143482, Validation loss: 0.34338344, Gradient norm: 3.90238741
INFO:root:At the start of the epoch: mem (CPU python)=7166.984375MB; mem (CPU total)=6979.64453125MB
INFO:root:[  129] Training loss: 0.35224897, Validation loss: 0.34355236, Gradient norm: 3.68289824
INFO:root:At the start of the epoch: mem (CPU python)=7186.328125MB; mem (CPU total)=6999.4296875MB
INFO:root:[  130] Training loss: 0.35190980, Validation loss: 0.34329643, Gradient norm: 3.98822873
INFO:root:At the start of the epoch: mem (CPU python)=7207.96875MB; mem (CPU total)=7020.98828125MB
INFO:root:[  131] Training loss: 0.35260344, Validation loss: 0.34387789, Gradient norm: 3.86512571
INFO:root:At the start of the epoch: mem (CPU python)=7229.25390625MB; mem (CPU total)=7042.1640625MB
INFO:root:[  132] Training loss: 0.35232776, Validation loss: 0.34414611, Gradient norm: 3.87579707
INFO:root:At the start of the epoch: mem (CPU python)=7250.87890625MB; mem (CPU total)=7063.3359375MB
INFO:root:[  133] Training loss: 0.35220747, Validation loss: 0.34334541, Gradient norm: 4.26970770
INFO:root:At the start of the epoch: mem (CPU python)=7272.84765625MB; mem (CPU total)=7085.765625MB
INFO:root:[  134] Training loss: 0.35231532, Validation loss: 0.34355656, Gradient norm: 4.19607488
INFO:root:At the start of the epoch: mem (CPU python)=7292.828125MB; mem (CPU total)=7105.99609375MB
INFO:root:[  135] Training loss: 0.35262679, Validation loss: 0.34313271, Gradient norm: 3.74877489
INFO:root:At the start of the epoch: mem (CPU python)=7314.73828125MB; mem (CPU total)=7127.1640625MB
INFO:root:[  136] Training loss: 0.35236503, Validation loss: 0.34283419, Gradient norm: 3.96295578
INFO:root:At the start of the epoch: mem (CPU python)=7335.67578125MB; mem (CPU total)=7148.484375MB
INFO:root:[  137] Training loss: 0.35230748, Validation loss: 0.34361993, Gradient norm: 4.07227461
INFO:root:At the start of the epoch: mem (CPU python)=7355.5078125MB; mem (CPU total)=7168.15625MB
INFO:root:[  138] Training loss: 0.35165944, Validation loss: 0.34297515, Gradient norm: 4.16206425
INFO:root:At the start of the epoch: mem (CPU python)=7379.14453125MB; mem (CPU total)=7192.03125MB
INFO:root:[  139] Training loss: 0.35203374, Validation loss: 0.34386009, Gradient norm: 4.16459632
INFO:root:At the start of the epoch: mem (CPU python)=7399.17578125MB; mem (CPU total)=7211.9609375MB
INFO:root:[  140] Training loss: 0.35157145, Validation loss: 0.34426323, Gradient norm: 4.88082964
INFO:root:At the start of the epoch: mem (CPU python)=7421.04296875MB; mem (CPU total)=7234.109375MB
INFO:root:[  141] Training loss: 0.35269217, Validation loss: 0.34348615, Gradient norm: 4.98358170
INFO:root:At the start of the epoch: mem (CPU python)=7442.53515625MB; mem (CPU total)=7254.51953125MB
INFO:root:[  142] Training loss: 0.35201876, Validation loss: 0.34349672, Gradient norm: 4.80136000
INFO:root:At the start of the epoch: mem (CPU python)=7462.04296875MB; mem (CPU total)=7275.81640625MB
INFO:root:[  143] Training loss: 0.35173151, Validation loss: 0.34256144, Gradient norm: 4.96178713
INFO:root:At the start of the epoch: mem (CPU python)=7484.578125MB; mem (CPU total)=7297.83984375MB
INFO:root:[  144] Training loss: 0.35205552, Validation loss: 0.34326197, Gradient norm: 4.44346508
INFO:root:At the start of the epoch: mem (CPU python)=7506.29296875MB; mem (CPU total)=7317.2890625MB
INFO:root:[  145] Training loss: 0.35171584, Validation loss: 0.34330078, Gradient norm: 4.69697518
INFO:root:At the start of the epoch: mem (CPU python)=7527.6640625MB; mem (CPU total)=7340.7421875MB
INFO:root:[  146] Training loss: 0.35194065, Validation loss: 0.34328997, Gradient norm: 4.96099056
INFO:root:At the start of the epoch: mem (CPU python)=7549.19921875MB; mem (CPU total)=7362.58203125MB
INFO:root:[  147] Training loss: 0.35172380, Validation loss: 0.34360276, Gradient norm: 5.02235177
INFO:root:At the start of the epoch: mem (CPU python)=7570.94921875MB; mem (CPU total)=7383.984375MB
INFO:root:[  148] Training loss: 0.35143284, Validation loss: 0.34325662, Gradient norm: 4.99552458
INFO:root:At the start of the epoch: mem (CPU python)=7592.65234375MB; mem (CPU total)=7405.140625MB
INFO:root:[  149] Training loss: 0.35167729, Validation loss: 0.34270199, Gradient norm: 4.61070095
INFO:root:At the start of the epoch: mem (CPU python)=7613.82421875MB; mem (CPU total)=7425.7421875MB
INFO:root:[  150] Training loss: 0.35220666, Validation loss: 0.34307500, Gradient norm: 4.77144743
INFO:root:At the start of the epoch: mem (CPU python)=7634.98828125MB; mem (CPU total)=7446.91015625MB
INFO:root:[  151] Training loss: 0.35293436, Validation loss: 0.34375267, Gradient norm: 5.47024358
INFO:root:At the start of the epoch: mem (CPU python)=7635.09375MB; mem (CPU total)=7445.1875MB
INFO:root:[  152] Training loss: 0.35249615, Validation loss: 0.34294332, Gradient norm: 5.03510118
INFO:root:At the start of the epoch: mem (CPU python)=7653.78125MB; mem (CPU total)=7467.33203125MB
INFO:root:EP 152: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=7675.5234375MB; mem (CPU total)=7487.265625MB
INFO:root:[  154] Training loss: 0.43238381, Validation loss: 0.41875356, Gradient norm: 7.42171512
INFO:root:At the start of the epoch: mem (CPU python)=7695.67578125MB; mem (CPU total)=7508.19140625MB
INFO:root:[  155] Training loss: 0.42960042, Validation loss: 0.41823579, Gradient norm: 7.85192967
INFO:root:At the start of the epoch: mem (CPU python)=7717.06640625MB; mem (CPU total)=7530.76953125MB
INFO:root:[  156] Training loss: 0.42894743, Validation loss: 0.41694462, Gradient norm: 8.56082244
INFO:root:At the start of the epoch: mem (CPU python)=7738.46484375MB; mem (CPU total)=7551.69921875MB
INFO:root:[  157] Training loss: 0.42818931, Validation loss: 0.41651728, Gradient norm: 7.92728774
INFO:root:At the start of the epoch: mem (CPU python)=7760.94140625MB; mem (CPU total)=7574.70703125MB
INFO:root:[  158] Training loss: 0.42806700, Validation loss: 0.41628688, Gradient norm: 8.24000036
INFO:root:At the start of the epoch: mem (CPU python)=7781.19921875MB; mem (CPU total)=7594.87890625MB
INFO:root:[  159] Training loss: 0.42821817, Validation loss: 0.41692767, Gradient norm: 7.66821824
INFO:root:At the start of the epoch: mem (CPU python)=7802.234375MB; mem (CPU total)=7615.6953125MB
INFO:root:[  160] Training loss: 0.42750832, Validation loss: 0.41641672, Gradient norm: 8.10466846
INFO:root:At the start of the epoch: mem (CPU python)=7824.2734375MB; mem (CPU total)=7635.92578125MB
INFO:root:[  161] Training loss: 0.42782840, Validation loss: 0.41603753, Gradient norm: 8.01685457
INFO:root:At the start of the epoch: mem (CPU python)=7844.703125MB; mem (CPU total)=7657.3515625MB
INFO:root:[  162] Training loss: 0.42721718, Validation loss: 0.41528671, Gradient norm: 8.30949218
INFO:root:At the start of the epoch: mem (CPU python)=7866.3984375MB; mem (CPU total)=7631.484375MB
INFO:root:[  163] Training loss: 0.42708127, Validation loss: 0.41510954, Gradient norm: 8.35945766
INFO:root:At the start of the epoch: mem (CPU python)=7887.68359375MB; mem (CPU total)=7698.57421875MB
INFO:root:[  164] Training loss: 0.42662513, Validation loss: 0.41560985, Gradient norm: 7.83619077
INFO:root:At the start of the epoch: mem (CPU python)=7908.1640625MB; mem (CPU total)=7720.96875MB
INFO:root:[  165] Training loss: 0.42651382, Validation loss: 0.41509563, Gradient norm: 8.49994212
INFO:root:At the start of the epoch: mem (CPU python)=7928.65234375MB; mem (CPU total)=7741.66796875MB
INFO:root:[  166] Training loss: 0.42678531, Validation loss: 0.41527731, Gradient norm: 8.13351656
INFO:root:At the start of the epoch: mem (CPU python)=7951.2578125MB; mem (CPU total)=7762.5703125MB
INFO:root:[  167] Training loss: 0.42659543, Validation loss: 0.41497229, Gradient norm: 8.71016956
INFO:root:At the start of the epoch: mem (CPU python)=7970.8984375MB; mem (CPU total)=7782.46484375MB
INFO:root:[  168] Training loss: 0.42617756, Validation loss: 0.41499770, Gradient norm: 8.12942517
INFO:root:At the start of the epoch: mem (CPU python)=7993.3125MB; mem (CPU total)=7804.859375MB
INFO:root:[  169] Training loss: 0.42597084, Validation loss: 0.41500673, Gradient norm: 8.48788130
INFO:root:At the start of the epoch: mem (CPU python)=8014.08984375MB; mem (CPU total)=7825.77734375MB
INFO:root:[  170] Training loss: 0.42592410, Validation loss: 0.41457442, Gradient norm: 8.62099837
INFO:root:At the start of the epoch: mem (CPU python)=8035.37890625MB; mem (CPU total)=7846.94140625MB
INFO:root:[  171] Training loss: 0.42600178, Validation loss: 0.41500564, Gradient norm: 8.83640099
INFO:root:At the start of the epoch: mem (CPU python)=8057.078125MB; mem (CPU total)=7868.08984375MB
INFO:root:[  172] Training loss: 0.42580973, Validation loss: 0.41505120, Gradient norm: 8.97408473
INFO:root:At the start of the epoch: mem (CPU python)=8078.24609375MB; mem (CPU total)=7889.2421875MB
INFO:root:[  173] Training loss: 0.42597523, Validation loss: 0.41472429, Gradient norm: 8.69381123
INFO:root:At the start of the epoch: mem (CPU python)=8098.5390625MB; mem (CPU total)=7909.9296875MB
INFO:root:[  174] Training loss: 0.42505950, Validation loss: 0.41453311, Gradient norm: 8.44222202
INFO:root:At the start of the epoch: mem (CPU python)=8120.1953125MB; mem (CPU total)=7931.29296875MB
INFO:root:[  175] Training loss: 0.42569167, Validation loss: 0.41436111, Gradient norm: 8.36455044
INFO:root:At the start of the epoch: mem (CPU python)=8141.3828125MB; mem (CPU total)=7952.6796875MB
INFO:root:[  176] Training loss: 0.42599664, Validation loss: 0.41403833, Gradient norm: 8.57092977
INFO:root:At the start of the epoch: mem (CPU python)=8162.89453125MB; mem (CPU total)=7974.53125MB
INFO:root:[  177] Training loss: 0.42532780, Validation loss: 0.41411906, Gradient norm: 8.40195629
INFO:root:At the start of the epoch: mem (CPU python)=8184.0625MB; mem (CPU total)=7995.83203125MB
INFO:root:[  178] Training loss: 0.42459410, Validation loss: 0.41448312, Gradient norm: 8.55808814
INFO:root:At the start of the epoch: mem (CPU python)=8204.39453125MB; mem (CPU total)=8016.98046875MB
INFO:root:[  179] Training loss: 0.42564771, Validation loss: 0.41476682, Gradient norm: 9.24303772
INFO:root:At the start of the epoch: mem (CPU python)=8225.93359375MB; mem (CPU total)=8038.34375MB
INFO:root:[  180] Training loss: 0.42476957, Validation loss: 0.41389825, Gradient norm: 8.71034084
INFO:root:At the start of the epoch: mem (CPU python)=8246.33984375MB; mem (CPU total)=8058.26953125MB
INFO:root:[  181] Training loss: 0.42529020, Validation loss: 0.41414672, Gradient norm: 9.56843163
INFO:root:At the start of the epoch: mem (CPU python)=8267.1875MB; mem (CPU total)=8078.9375MB
INFO:root:[  182] Training loss: 0.42571496, Validation loss: 0.41398733, Gradient norm: 9.50067315
INFO:root:At the start of the epoch: mem (CPU python)=8289.88671875MB; mem (CPU total)=8101.07421875MB
INFO:root:[  183] Training loss: 0.42461451, Validation loss: 0.41392417, Gradient norm: 8.72879465
INFO:root:At the start of the epoch: mem (CPU python)=8310.3125MB; mem (CPU total)=8122.68359375MB
INFO:root:[  184] Training loss: 0.42523425, Validation loss: 0.41375013, Gradient norm: 9.81378469
INFO:root:At the start of the epoch: mem (CPU python)=8331.83203125MB; mem (CPU total)=8143.58984375MB
INFO:root:[  185] Training loss: 0.42502317, Validation loss: 0.41348227, Gradient norm: 8.37517526
INFO:root:At the start of the epoch: mem (CPU python)=8352.828125MB; mem (CPU total)=8164.265625MB
INFO:root:[  186] Training loss: 0.42474063, Validation loss: 0.41382197, Gradient norm: 8.66000260
INFO:root:At the start of the epoch: mem (CPU python)=8373.3671875MB; mem (CPU total)=8184.5625MB
INFO:root:[  187] Training loss: 0.42505396, Validation loss: 0.41343914, Gradient norm: 9.10478106
INFO:root:At the start of the epoch: mem (CPU python)=8395.4453125MB; mem (CPU total)=8206.71484375MB
INFO:root:[  188] Training loss: 0.42489151, Validation loss: 0.41361906, Gradient norm: 8.68289063
INFO:root:At the start of the epoch: mem (CPU python)=8417.06640625MB; mem (CPU total)=8229.0859375MB
INFO:root:[  189] Training loss: 0.42459844, Validation loss: 0.41345634, Gradient norm: 9.14911606
INFO:root:At the start of the epoch: mem (CPU python)=8437.91015625MB; mem (CPU total)=8249.14453125MB
INFO:root:[  190] Training loss: 0.42403123, Validation loss: 0.41363748, Gradient norm: 9.21666111
INFO:root:At the start of the epoch: mem (CPU python)=8459.19921875MB; mem (CPU total)=8270.28515625MB
INFO:root:[  191] Training loss: 0.42485304, Validation loss: 0.41364417, Gradient norm: 9.59576135
INFO:root:At the start of the epoch: mem (CPU python)=8480.48828125MB; mem (CPU total)=8292.15625MB
INFO:root:[  192] Training loss: 0.42431124, Validation loss: 0.41331144, Gradient norm: 9.30240849
INFO:root:At the start of the epoch: mem (CPU python)=8500.6328125MB; mem (CPU total)=8313.08984375MB
INFO:root:[  193] Training loss: 0.42498841, Validation loss: 0.41369042, Gradient norm: 9.54349064
INFO:root:At the start of the epoch: mem (CPU python)=8522.32421875MB; mem (CPU total)=8331.98828125MB
INFO:root:[  194] Training loss: 0.42410636, Validation loss: 0.41322022, Gradient norm: 8.91959488
INFO:root:At the start of the epoch: mem (CPU python)=8543.0234375MB; mem (CPU total)=8355.58984375MB
INFO:root:[  195] Training loss: 0.42392667, Validation loss: 0.41309895, Gradient norm: 9.75546997
INFO:root:At the start of the epoch: mem (CPU python)=8564.125MB; mem (CPU total)=8376.28125MB
INFO:root:[  196] Training loss: 0.42412078, Validation loss: 0.41313725, Gradient norm: 10.04489374
INFO:root:At the start of the epoch: mem (CPU python)=8585.80859375MB; mem (CPU total)=8397.671875MB
INFO:root:[  197] Training loss: 0.42454585, Validation loss: 0.41286553, Gradient norm: 10.58571770
INFO:root:At the start of the epoch: mem (CPU python)=8606.38671875MB; mem (CPU total)=8418.33984375MB
INFO:root:[  198] Training loss: 0.42442939, Validation loss: 0.41278137, Gradient norm: 9.78400839
INFO:root:At the start of the epoch: mem (CPU python)=8627.5859375MB; mem (CPU total)=8439.6015625MB
INFO:root:[  199] Training loss: 0.42408859, Validation loss: 0.41298053, Gradient norm: 9.57609583
INFO:root:At the start of the epoch: mem (CPU python)=8649.0234375MB; mem (CPU total)=8460.765625MB
INFO:root:[  200] Training loss: 0.42486840, Validation loss: 0.41311164, Gradient norm: 9.93736644
INFO:root:At the start of the epoch: mem (CPU python)=8670.84375MB; mem (CPU total)=8481.9296875MB
INFO:root:[  201] Training loss: 0.42448046, Validation loss: 0.41363484, Gradient norm: 9.76596489
INFO:root:At the start of the epoch: mem (CPU python)=8690.97265625MB; mem (CPU total)=8502.58984375MB
INFO:root:[  202] Training loss: 0.42418981, Validation loss: 0.41335389, Gradient norm: 10.16554294
INFO:root:At the start of the epoch: mem (CPU python)=8712.59375MB; mem (CPU total)=8524.05078125MB
INFO:root:[  203] Training loss: 0.42475641, Validation loss: 0.41333268, Gradient norm: 10.25072064
INFO:root:At the start of the epoch: mem (CPU python)=8732.765625MB; mem (CPU total)=8544.703125MB
INFO:root:[  204] Training loss: 0.42454193, Validation loss: 0.41332131, Gradient norm: 9.33126210
INFO:root:At the start of the epoch: mem (CPU python)=8754.3984375MB; mem (CPU total)=8566.08984375MB
INFO:root:[  205] Training loss: 0.42423849, Validation loss: 0.41334885, Gradient norm: 9.81676934
INFO:root:At the start of the epoch: mem (CPU python)=8775.53515625MB; mem (CPU total)=8587.20703125MB
INFO:root:[  206] Training loss: 0.42381671, Validation loss: 0.41200980, Gradient norm: 9.84478999
INFO:root:At the start of the epoch: mem (CPU python)=8797.828125MB; mem (CPU total)=8608.640625MB
INFO:root:[  207] Training loss: 0.42446484, Validation loss: 0.41359075, Gradient norm: 10.57631219
INFO:root:At the start of the epoch: mem (CPU python)=8818.9921875MB; mem (CPU total)=8629.8046875MB
INFO:root:[  208] Training loss: 0.42417340, Validation loss: 0.41253260, Gradient norm: 9.88474143
INFO:root:At the start of the epoch: mem (CPU python)=8840.15625MB; mem (CPU total)=8650.96875MB
INFO:root:[  209] Training loss: 0.42352600, Validation loss: 0.41246949, Gradient norm: 11.83160712
INFO:root:At the start of the epoch: mem (CPU python)=8861.3203125MB; mem (CPU total)=8672.37109375MB
INFO:root:[  210] Training loss: 0.42364124, Validation loss: 0.41252574, Gradient norm: 9.64245628
INFO:root:At the start of the epoch: mem (CPU python)=8881.859375MB; mem (CPU total)=8691.80859375MB
INFO:root:[  211] Training loss: 0.42371882, Validation loss: 0.41257613, Gradient norm: 10.30411313
INFO:root:At the start of the epoch: mem (CPU python)=8902.83203125MB; mem (CPU total)=8714.4609375MB
INFO:root:[  212] Training loss: 0.42332740, Validation loss: 0.41309572, Gradient norm: 11.15156146
INFO:root:At the start of the epoch: mem (CPU python)=8924.4375MB; mem (CPU total)=8735.37890625MB
INFO:root:[  213] Training loss: 0.42371680, Validation loss: 0.41299397, Gradient norm: 11.34832480
INFO:root:At the start of the epoch: mem (CPU python)=8945.7109375MB; mem (CPU total)=8757.25MB
INFO:root:[  214] Training loss: 0.42414554, Validation loss: 0.41234530, Gradient norm: 10.37421270
INFO:root:At the start of the epoch: mem (CPU python)=8966.875MB; mem (CPU total)=8778.4140625MB
INFO:root:[  215] Training loss: 0.42392800, Validation loss: 0.41343106, Gradient norm: 11.16426844
INFO:root:At the start of the epoch: mem (CPU python)=8988.3046875MB; mem (CPU total)=8800.40625MB
INFO:root:EP 215: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=9008.5625MB; mem (CPU total)=8821.63671875MB
INFO:root:Training the model took 6242.661s.
INFO:root:Emptying the cuda cache took 0.058s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.50811
INFO:root:EnergyScoreValidation: 0.34211
INFO:root:CRPSValidation: 0.14661
INFO:root:Gaussian NLLValidation: 19.18387
INFO:root:CoverageValidation: 0.44679
INFO:root:IntervalWidthValidation: 0.30783
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.43532
INFO:root:EnergyScoreTest: 0.28047
INFO:root:CRPSTest: 0.12068
INFO:root:Gaussian NLLTest: 23.99272
INFO:root:CoverageTest: 0.49043
INFO:root:IntervalWidthTest: 0.30352
INFO:root:After validation: mem (CPU python)=9362.20703125MB; mem (CPU total)=9055.9609375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=9362.20703125MB; mem (CPU total)=9055.61328125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 346030080
INFO:root:After setting up the model: mem (CPU python)=9390.70703125MB; mem (CPU total)=9084.04296875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=9390.96484375MB; mem (CPU total)=9084.125MB
INFO:root:[    1] Training loss: 0.83787462, Validation loss: 0.73605332, Gradient norm: 0.51659137
INFO:root:At the start of the epoch: mem (CPU python)=9418.21484375MB; mem (CPU total)=9108.265625MB
INFO:root:[    2] Training loss: 0.73831083, Validation loss: 0.73343866, Gradient norm: 0.35461291
INFO:root:At the start of the epoch: mem (CPU python)=9440.17578125MB; mem (CPU total)=9128.15234375MB
INFO:root:[    3] Training loss: 0.73502300, Validation loss: 0.73000225, Gradient norm: 0.35775215
INFO:root:At the start of the epoch: mem (CPU python)=9461.34765625MB; mem (CPU total)=9148.8046875MB
INFO:root:[    4] Training loss: 0.71570278, Validation loss: 0.69910774, Gradient norm: 0.52419393
INFO:root:At the start of the epoch: mem (CPU python)=9482.51171875MB; mem (CPU total)=9168.984375MB
INFO:root:[    5] Training loss: 0.66997410, Validation loss: 0.63783371, Gradient norm: 0.65476247
INFO:root:At the start of the epoch: mem (CPU python)=9504.265625MB; mem (CPU total)=9190.9765625MB
INFO:root:[    6] Training loss: 0.62633287, Validation loss: 0.61637208, Gradient norm: 0.98089390
INFO:root:At the start of the epoch: mem (CPU python)=9525.96875MB; mem (CPU total)=9212.3828125MB
INFO:root:[    7] Training loss: 0.59531154, Validation loss: 0.58956879, Gradient norm: 0.93730274
INFO:root:At the start of the epoch: mem (CPU python)=9547.5MB; mem (CPU total)=9233.7421875MB
INFO:root:[    8] Training loss: 0.57650475, Validation loss: 0.54643295, Gradient norm: 1.40159100
INFO:root:At the start of the epoch: mem (CPU python)=9569.05078125MB; mem (CPU total)=9255.30859375MB
INFO:root:[    9] Training loss: 0.54850952, Validation loss: 0.54106330, Gradient norm: 1.17322369
INFO:root:At the start of the epoch: mem (CPU python)=9590.2109375MB; mem (CPU total)=9275.84375MB
INFO:root:[   10] Training loss: 0.53251108, Validation loss: 0.51285840, Gradient norm: 1.40860771
INFO:root:At the start of the epoch: mem (CPU python)=9611.375MB; mem (CPU total)=9296.67578125MB
INFO:root:[   11] Training loss: 0.52280939, Validation loss: 0.49091619, Gradient norm: 1.56071152
INFO:root:At the start of the epoch: mem (CPU python)=9632.5390625MB; mem (CPU total)=9318.07421875MB
INFO:root:[   12] Training loss: 0.50573743, Validation loss: 0.47702580, Gradient norm: 1.74450007
INFO:root:At the start of the epoch: mem (CPU python)=9653.703125MB; mem (CPU total)=9338.00390625MB
INFO:root:[   13] Training loss: 0.49960472, Validation loss: 0.48415421, Gradient norm: 1.54716676
INFO:root:At the start of the epoch: mem (CPU python)=9674.87109375MB; mem (CPU total)=9359.1796875MB
INFO:root:[   14] Training loss: 0.49403792, Validation loss: 0.47817862, Gradient norm: 1.97621297
INFO:root:At the start of the epoch: mem (CPU python)=9696.15625MB; mem (CPU total)=9380.34765625MB
INFO:root:[   15] Training loss: 0.48879829, Validation loss: 0.47175877, Gradient norm: 1.81110307
INFO:root:At the start of the epoch: mem (CPU python)=9717.57421875MB; mem (CPU total)=9401.51171875MB
INFO:root:[   16] Training loss: 0.48485375, Validation loss: 0.46768987, Gradient norm: 2.04812920
INFO:root:At the start of the epoch: mem (CPU python)=9739.6953125MB; mem (CPU total)=9424.1484375MB
INFO:root:[   17] Training loss: 0.48280696, Validation loss: 0.46715702, Gradient norm: 1.88707004
INFO:root:At the start of the epoch: mem (CPU python)=9761.3984375MB; mem (CPU total)=9445.07421875MB
INFO:root:[   18] Training loss: 0.47560708, Validation loss: 0.46876911, Gradient norm: 1.90344219
INFO:root:At the start of the epoch: mem (CPU python)=9782.55859375MB; mem (CPU total)=9466.21875MB
INFO:root:[   19] Training loss: 0.47300356, Validation loss: 0.44848245, Gradient norm: 1.77479487
INFO:root:At the start of the epoch: mem (CPU python)=9803.7265625MB; mem (CPU total)=9487.78125MB
INFO:root:[   20] Training loss: 0.47050994, Validation loss: 0.44090580, Gradient norm: 2.06260154
INFO:root:At the start of the epoch: mem (CPU python)=9824.890625MB; mem (CPU total)=9508.58203125MB
INFO:root:[   21] Training loss: 0.47023347, Validation loss: 0.44795831, Gradient norm: 2.05349437
INFO:root:At the start of the epoch: mem (CPU python)=9846.0546875MB; mem (CPU total)=9528.91015625MB
INFO:root:[   22] Training loss: 0.46717524, Validation loss: 0.45884926, Gradient norm: 2.11698456
INFO:root:At the start of the epoch: mem (CPU python)=9867.21875MB; mem (CPU total)=9549.8125MB
INFO:root:[   23] Training loss: 0.46275109, Validation loss: 0.45347422, Gradient norm: 1.85266550
INFO:root:At the start of the epoch: mem (CPU python)=9888.3828125MB; mem (CPU total)=9570.8984375MB
INFO:root:[   24] Training loss: 0.46387357, Validation loss: 0.44817149, Gradient norm: 2.18157716
INFO:root:At the start of the epoch: mem (CPU python)=9909.3359375MB; mem (CPU total)=9593.14453125MB
INFO:root:[   25] Training loss: 0.46406882, Validation loss: 0.43910600, Gradient norm: 2.24106194
INFO:root:At the start of the epoch: mem (CPU python)=9931.5078125MB; mem (CPU total)=9614.28515625MB
INFO:root:[   26] Training loss: 0.45991688, Validation loss: 0.43491108, Gradient norm: 2.28590275
INFO:root:At the start of the epoch: mem (CPU python)=9951.890625MB; mem (CPU total)=9635.35546875MB
INFO:root:[   27] Training loss: 0.46241462, Validation loss: 0.47394087, Gradient norm: 2.09261396
INFO:root:At the start of the epoch: mem (CPU python)=9973.41796875MB; mem (CPU total)=9656.20703125MB
INFO:root:[   28] Training loss: 0.46187485, Validation loss: 0.44051649, Gradient norm: 2.49604601
INFO:root:At the start of the epoch: mem (CPU python)=9994.58203125MB; mem (CPU total)=9677.08984375MB
INFO:root:[   29] Training loss: 0.45855520, Validation loss: 0.44080773, Gradient norm: 2.15041508
INFO:root:At the start of the epoch: mem (CPU python)=10015.74609375MB; mem (CPU total)=9698.26171875MB
INFO:root:[   30] Training loss: 0.45709037, Validation loss: 0.44432692, Gradient norm: 2.22727742
INFO:root:At the start of the epoch: mem (CPU python)=10036.9140625MB; mem (CPU total)=9719.4296875MB
INFO:root:[   31] Training loss: 0.45739933, Validation loss: 0.43324187, Gradient norm: 2.48321804
INFO:root:At the start of the epoch: mem (CPU python)=10058.0703125MB; mem (CPU total)=9741.58203125MB
INFO:root:[   32] Training loss: 0.45433350, Validation loss: 0.43389466, Gradient norm: 2.27795963
INFO:root:At the start of the epoch: mem (CPU python)=10079.875MB; mem (CPU total)=9762.72265625MB
INFO:root:[   33] Training loss: 0.45849988, Validation loss: 0.44591253, Gradient norm: 2.24312721
INFO:root:At the start of the epoch: mem (CPU python)=10099.80859375MB; mem (CPU total)=9782.6640625MB
INFO:root:[   34] Training loss: 0.45398758, Validation loss: 0.47529668, Gradient norm: 2.31649205
INFO:root:At the start of the epoch: mem (CPU python)=10121.4375MB; mem (CPU total)=9802.4375MB
INFO:root:[   35] Training loss: 0.45752867, Validation loss: 0.42940843, Gradient norm: 2.62078044
INFO:root:At the start of the epoch: mem (CPU python)=10141.78125MB; mem (CPU total)=9824.609375MB
INFO:root:[   36] Training loss: 0.45434844, Validation loss: 0.47422387, Gradient norm: 2.47354803
INFO:root:At the start of the epoch: mem (CPU python)=10163.953125MB; mem (CPU total)=9846.99609375MB
INFO:root:[   37] Training loss: 0.45692048, Validation loss: 0.42304272, Gradient norm: 2.33922900
INFO:root:At the start of the epoch: mem (CPU python)=10185.77734375MB; mem (CPU total)=9868.39453125MB
INFO:root:[   38] Training loss: 0.45211563, Validation loss: 0.42126935, Gradient norm: 2.47828819
INFO:root:At the start of the epoch: mem (CPU python)=10208.56640625MB; mem (CPU total)=9890.7578125MB
INFO:root:[   39] Training loss: 0.45236853, Validation loss: 0.43865917, Gradient norm: 2.27209481
INFO:root:At the start of the epoch: mem (CPU python)=10229.98828125MB; mem (CPU total)=9911.91015625MB
INFO:root:[   40] Training loss: 0.45256867, Validation loss: 0.42890330, Gradient norm: 2.73072604
INFO:root:At the start of the epoch: mem (CPU python)=10251.17578125MB; mem (CPU total)=9933.0625MB
INFO:root:[   41] Training loss: 0.45504141, Validation loss: 0.42893307, Gradient norm: 2.69944467
INFO:root:At the start of the epoch: mem (CPU python)=10272.34375MB; mem (CPU total)=9954.47265625MB
INFO:root:[   42] Training loss: 0.44692364, Validation loss: 0.42198188, Gradient norm: 2.84340357
INFO:root:At the start of the epoch: mem (CPU python)=10293.5078125MB; mem (CPU total)=9975.625MB
INFO:root:[   43] Training loss: 0.45527235, Validation loss: 0.42031566, Gradient norm: 2.72417050
INFO:root:At the start of the epoch: mem (CPU python)=10314.67578125MB; mem (CPU total)=9997.26171875MB
INFO:root:[   44] Training loss: 0.45107373, Validation loss: 0.42958267, Gradient norm: 2.88504731
INFO:root:At the start of the epoch: mem (CPU python)=10336.828125MB; mem (CPU total)=10019.90234375MB
INFO:root:[   45] Training loss: 0.45137995, Validation loss: 0.42877727, Gradient norm: 2.97226767
INFO:root:At the start of the epoch: mem (CPU python)=10358.12109375MB; mem (CPU total)=10040.80078125MB
INFO:root:[   46] Training loss: 0.45388230, Validation loss: 0.42268095, Gradient norm: 2.76448354
INFO:root:At the start of the epoch: mem (CPU python)=10379.66796875MB; mem (CPU total)=10062.43359375MB
INFO:root:[   47] Training loss: 0.44451548, Validation loss: 0.45089589, Gradient norm: 3.01971776
INFO:root:At the start of the epoch: mem (CPU python)=10400.83203125MB; mem (CPU total)=10083.59765625MB
INFO:root:[   48] Training loss: 0.44918192, Validation loss: 0.42656372, Gradient norm: 3.09994217
INFO:root:At the start of the epoch: mem (CPU python)=10421.99609375MB; mem (CPU total)=10104.484375MB
INFO:root:[   49] Training loss: 0.44912571, Validation loss: 0.43853431, Gradient norm: 3.16493329
INFO:root:At the start of the epoch: mem (CPU python)=10443.16015625MB; mem (CPU total)=10125.37109375MB
INFO:root:[   50] Training loss: 0.44694064, Validation loss: 0.42855482, Gradient norm: 2.88485291
INFO:root:At the start of the epoch: mem (CPU python)=10464.3203125MB; mem (CPU total)=10146.78125MB
INFO:root:[   51] Training loss: 0.43534027, Validation loss: 0.40891308, Gradient norm: 2.98150744
INFO:root:At the start of the epoch: mem (CPU python)=10485.48828125MB; mem (CPU total)=10167.92578125MB
INFO:root:[   52] Training loss: 0.44358539, Validation loss: 0.42386966, Gradient norm: 2.82017389
INFO:root:At the start of the epoch: mem (CPU python)=10506.65234375MB; mem (CPU total)=10189.07421875MB
INFO:root:[   53] Training loss: 0.44508229, Validation loss: 0.43474326, Gradient norm: 3.16988291
INFO:root:At the start of the epoch: mem (CPU python)=10527.81640625MB; mem (CPU total)=10210.23046875MB
INFO:root:[   54] Training loss: 0.44161405, Validation loss: 0.40963371, Gradient norm: 3.27776784
INFO:root:At the start of the epoch: mem (CPU python)=10548.98046875MB; mem (CPU total)=10231.38671875MB
INFO:root:[   55] Training loss: 0.44052403, Validation loss: 0.44375505, Gradient norm: 3.25231027
INFO:root:At the start of the epoch: mem (CPU python)=10570.14453125MB; mem (CPU total)=10252.5390625MB
INFO:root:[   56] Training loss: 0.44705868, Validation loss: 0.41135008, Gradient norm: 3.36546016
INFO:root:At the start of the epoch: mem (CPU python)=10592.52734375MB; mem (CPU total)=10275.4140625MB
INFO:root:[   57] Training loss: 0.44204924, Validation loss: 0.41207587, Gradient norm: 3.14339204
INFO:root:At the start of the epoch: mem (CPU python)=10613.69140625MB; mem (CPU total)=10296.8125MB
INFO:root:[   58] Training loss: 0.43759744, Validation loss: 0.41356060, Gradient norm: 2.90771156
INFO:root:At the start of the epoch: mem (CPU python)=10635.51171875MB; mem (CPU total)=10317.9765625MB
INFO:root:[   59] Training loss: 0.44325707, Validation loss: 0.42875126, Gradient norm: 3.55471681
INFO:root:At the start of the epoch: mem (CPU python)=10656.67578125MB; mem (CPU total)=10339.140625MB
INFO:root:[   60] Training loss: 0.43547080, Validation loss: 0.42213018, Gradient norm: 3.34824934
INFO:root:At the start of the epoch: mem (CPU python)=10677.83984375MB; mem (CPU total)=10360.296875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.44109350, Validation loss: 0.41619752, Gradient norm: 3.79157954
INFO:root:At the start of the epoch: mem (CPU python)=10698.69140625MB; mem (CPU total)=10378.0MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 0.41354642, Validation loss: 0.38570318, Gradient norm: 2.52778457
INFO:root:At the start of the epoch: mem (CPU python)=10717.8515625MB; mem (CPU total)=10400.875MB
INFO:root:[   63] Training loss: 0.40479633, Validation loss: 0.38411555, Gradient norm: 1.75414193
INFO:root:At the start of the epoch: mem (CPU python)=10740.30078125MB; mem (CPU total)=10422.90234375MB
INFO:root:[   64] Training loss: 0.40330587, Validation loss: 0.38218315, Gradient norm: 2.26419956
INFO:root:At the start of the epoch: mem (CPU python)=10761.75MB; mem (CPU total)=10443.83984375MB
INFO:root:[   65] Training loss: 0.40333501, Validation loss: 0.37960708, Gradient norm: 2.48941875
INFO:root:At the start of the epoch: mem (CPU python)=10782.91015625MB; mem (CPU total)=10465.00390625MB
INFO:root:[   66] Training loss: 0.40340947, Validation loss: 0.38316325, Gradient norm: 2.87551380
INFO:root:At the start of the epoch: mem (CPU python)=10804.07421875MB; mem (CPU total)=10486.4140625MB
INFO:root:[   67] Training loss: 0.40732381, Validation loss: 0.38796035, Gradient norm: 4.35912766
INFO:root:At the start of the epoch: mem (CPU python)=10825.23828125MB; mem (CPU total)=10507.578125MB
INFO:root:[   68] Training loss: 0.40488286, Validation loss: 0.38125045, Gradient norm: 3.40278855
INFO:root:At the start of the epoch: mem (CPU python)=10846.40625MB; mem (CPU total)=10528.890625MB
INFO:root:[   69] Training loss: 0.40357569, Validation loss: 0.38359573, Gradient norm: 3.73779398
INFO:root:At the start of the epoch: mem (CPU python)=10867.98046875MB; mem (CPU total)=10551.02734375MB
INFO:root:[   70] Training loss: 0.40349016, Validation loss: 0.38191494, Gradient norm: 3.88559886
INFO:root:At the start of the epoch: mem (CPU python)=10889.859375MB; mem (CPU total)=10572.078125MB
INFO:root:[   71] Training loss: 0.40330072, Validation loss: 0.38203746, Gradient norm: 4.33929749
INFO:root:At the start of the epoch: mem (CPU python)=10911.0234375MB; mem (CPU total)=10593.48046875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   72] Training loss: 0.40237057, Validation loss: 0.37965272, Gradient norm: 4.37317114
INFO:root:At the start of the epoch: mem (CPU python)=10932.19140625MB; mem (CPU total)=10614.640625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   73] Training loss: 0.39911197, Validation loss: 0.37745113, Gradient norm: 2.86618153
INFO:root:At the start of the epoch: mem (CPU python)=10953.35546875MB; mem (CPU total)=10636.0390625MB
INFO:root:[   74] Training loss: 0.39721106, Validation loss: 0.37445233, Gradient norm: 2.55134276
INFO:root:At the start of the epoch: mem (CPU python)=10974.515625MB; mem (CPU total)=10657.19140625MB
INFO:root:[   75] Training loss: 0.39649995, Validation loss: 0.37428709, Gradient norm: 2.75653345
INFO:root:At the start of the epoch: mem (CPU python)=10995.6796875MB; mem (CPU total)=10678.09765625MB
INFO:root:[   76] Training loss: 0.39699292, Validation loss: 0.37422409, Gradient norm: 2.68678781
INFO:root:At the start of the epoch: mem (CPU python)=11016.84375MB; mem (CPU total)=10699.46875MB
INFO:root:[   77] Training loss: 0.39734298, Validation loss: 0.37376907, Gradient norm: 2.96927286
INFO:root:At the start of the epoch: mem (CPU python)=11038.0078125MB; mem (CPU total)=10720.6328125MB
INFO:root:[   78] Training loss: 0.39622051, Validation loss: 0.37347840, Gradient norm: 3.12674959
INFO:root:At the start of the epoch: mem (CPU python)=11059.17578125MB; mem (CPU total)=10741.8125MB
INFO:root:[   79] Training loss: 0.39637752, Validation loss: 0.37357028, Gradient norm: 3.16977743
INFO:root:At the start of the epoch: mem (CPU python)=11080.3359375MB; mem (CPU total)=10763.22265625MB
INFO:root:[   80] Training loss: 0.39566426, Validation loss: 0.37315642, Gradient norm: 2.69920217
INFO:root:At the start of the epoch: mem (CPU python)=11101.50390625MB; mem (CPU total)=10784.38671875MB
INFO:root:[   81] Training loss: 0.39603760, Validation loss: 0.37482148, Gradient norm: 2.93128159
INFO:root:At the start of the epoch: mem (CPU python)=11122.66796875MB; mem (CPU total)=10805.61328125MB
INFO:root:[   82] Training loss: 0.39739053, Validation loss: 0.37489318, Gradient norm: 5.05499273
INFO:root:At the start of the epoch: mem (CPU python)=11143.83203125MB; mem (CPU total)=10826.78515625MB
INFO:root:[   83] Training loss: 0.39733058, Validation loss: 0.37678085, Gradient norm: 4.93589470
INFO:root:At the start of the epoch: mem (CPU python)=11165.80859375MB; mem (CPU total)=10848.9453125MB
INFO:root:[   84] Training loss: 0.39654836, Validation loss: 0.37272496, Gradient norm: 4.07477010
INFO:root:At the start of the epoch: mem (CPU python)=11187.84375MB; mem (CPU total)=10871.59765625MB
INFO:root:[   85] Training loss: 0.39649793, Validation loss: 0.37426219, Gradient norm: 3.99411968
INFO:root:At the start of the epoch: mem (CPU python)=11209.5703125MB; mem (CPU total)=10892.51953125MB
INFO:root:[   86] Training loss: 0.39620167, Validation loss: 0.37388174, Gradient norm: 4.30537588
INFO:root:At the start of the epoch: mem (CPU python)=11230.734375MB; mem (CPU total)=10913.93359375MB
INFO:root:[   87] Training loss: 0.39630551, Validation loss: 0.37345945, Gradient norm: 3.93710928
INFO:root:At the start of the epoch: mem (CPU python)=11251.8984375MB; mem (CPU total)=10934.49609375MB
INFO:root:[   88] Training loss: 0.39696187, Validation loss: 0.37676875, Gradient norm: 4.89193131
INFO:root:At the start of the epoch: mem (CPU python)=11273.0625MB; mem (CPU total)=10955.40625MB
INFO:root:[   89] Training loss: 0.39670729, Validation loss: 0.37815323, Gradient norm: 5.09505264
INFO:root:At the start of the epoch: mem (CPU python)=11294.29296875MB; mem (CPU total)=10977.3046875MB
INFO:root:[   90] Training loss: 0.39824281, Validation loss: 0.37549860, Gradient norm: 7.15978150
INFO:root:At the start of the epoch: mem (CPU python)=11315.4609375MB; mem (CPU total)=10998.7265625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   91] Training loss: 0.39606198, Validation loss: 0.37341091, Gradient norm: 4.48845176
INFO:root:At the start of the epoch: mem (CPU python)=11336.93359375MB; mem (CPU total)=11019.76953125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   92] Training loss: 0.39434478, Validation loss: 0.37276116, Gradient norm: 3.46354492
INFO:root:At the start of the epoch: mem (CPU python)=11358.09765625MB; mem (CPU total)=11041.234375MB
INFO:root:[   93] Training loss: 0.39461644, Validation loss: 0.37204851, Gradient norm: 2.61713205
INFO:root:At the start of the epoch: mem (CPU python)=11379.2578125MB; mem (CPU total)=11061.86328125MB
INFO:root:[   94] Training loss: 0.39409480, Validation loss: 0.37229881, Gradient norm: 2.53219779
INFO:root:At the start of the epoch: mem (CPU python)=11399.71484375MB; mem (CPU total)=11083.00390625MB
INFO:root:[   95] Training loss: 0.39428240, Validation loss: 0.37145080, Gradient norm: 2.51362934
INFO:root:At the start of the epoch: mem (CPU python)=11421.58984375MB; mem (CPU total)=11104.6953125MB
INFO:root:[   96] Training loss: 0.39455569, Validation loss: 0.37159259, Gradient norm: 2.80056578
INFO:root:At the start of the epoch: mem (CPU python)=11442.75390625MB; mem (CPU total)=11125.609375MB
INFO:root:[   97] Training loss: 0.39430780, Validation loss: 0.37138660, Gradient norm: 2.75534162
INFO:root:At the start of the epoch: mem (CPU python)=11463.91796875MB; mem (CPU total)=11146.77734375MB
INFO:root:[   98] Training loss: 0.39459521, Validation loss: 0.37186191, Gradient norm: 2.79010500
INFO:root:At the start of the epoch: mem (CPU python)=11485.08203125MB; mem (CPU total)=11167.92578125MB
INFO:root:[   99] Training loss: 0.39397710, Validation loss: 0.37145040, Gradient norm: 2.92195134
INFO:root:At the start of the epoch: mem (CPU python)=11506.24609375MB; mem (CPU total)=11189.328125MB
INFO:root:[  100] Training loss: 0.39390758, Validation loss: 0.37122379, Gradient norm: 3.09513728
INFO:root:At the start of the epoch: mem (CPU python)=11528.1640625MB; mem (CPU total)=11211.4765625MB
INFO:root:[  101] Training loss: 0.39419741, Validation loss: 0.37177454, Gradient norm: 3.02893964
INFO:root:At the start of the epoch: mem (CPU python)=11550.07421875MB; mem (CPU total)=11233.37890625MB
INFO:root:[  102] Training loss: 0.39454927, Validation loss: 0.37242499, Gradient norm: 3.09449304
INFO:root:At the start of the epoch: mem (CPU python)=11571.73828125MB; mem (CPU total)=11255.03125MB
INFO:root:[  103] Training loss: 0.39406845, Validation loss: 0.37202112, Gradient norm: 2.90560888
INFO:root:At the start of the epoch: mem (CPU python)=11594.35546875MB; mem (CPU total)=11278.41015625MB
INFO:root:[  104] Training loss: 0.39399212, Validation loss: 0.37146465, Gradient norm: 3.08957378
INFO:root:At the start of the epoch: mem (CPU python)=11614.78125MB; mem (CPU total)=11299.08984375MB
INFO:root:[  105] Training loss: 0.39474159, Validation loss: 0.37124304, Gradient norm: 3.52675249
INFO:root:At the start of the epoch: mem (CPU python)=11636.5078125MB; mem (CPU total)=11320.01171875MB
INFO:root:[  106] Training loss: 0.39447300, Validation loss: 0.37188595, Gradient norm: 3.53193949
INFO:root:At the start of the epoch: mem (CPU python)=11657.67578125MB; mem (CPU total)=11340.83203125MB
INFO:root:[  107] Training loss: 0.39454747, Validation loss: 0.37269299, Gradient norm: 3.29618907
INFO:root:At the start of the epoch: mem (CPU python)=11678.83984375MB; mem (CPU total)=11362.12890625MB
INFO:root:[  108] Training loss: 0.39466111, Validation loss: 0.37183087, Gradient norm: 3.72905115
INFO:root:At the start of the epoch: mem (CPU python)=11699.80859375MB; mem (CPU total)=11383.7421875MB
INFO:root:[  109] Training loss: 0.39423929, Validation loss: 0.37112620, Gradient norm: 3.84870804
INFO:root:At the start of the epoch: mem (CPU python)=11720.578125MB; mem (CPU total)=11404.15625MB
INFO:root:[  110] Training loss: 0.39405567, Validation loss: 0.37242126, Gradient norm: 3.76917465
INFO:root:At the start of the epoch: mem (CPU python)=11742.3984375MB; mem (CPU total)=11425.60546875MB
INFO:root:[  111] Training loss: 0.39462073, Validation loss: 0.37174858, Gradient norm: 3.84231689
INFO:root:At the start of the epoch: mem (CPU python)=11762.75MB; mem (CPU total)=11446.26171875MB
INFO:root:[  112] Training loss: 0.39451706, Validation loss: 0.37252109, Gradient norm: 3.92255306
INFO:root:At the start of the epoch: mem (CPU python)=11785.421875MB; mem (CPU total)=11468.90625MB
INFO:root:[  113] Training loss: 0.39424635, Validation loss: 0.37131616, Gradient norm: 4.33026937
INFO:root:At the start of the epoch: mem (CPU python)=11806.98046875MB; mem (CPU total)=11490.80078125MB
INFO:root:[  114] Training loss: 0.39439189, Validation loss: 0.37140635, Gradient norm: 4.25467866
INFO:root:At the start of the epoch: mem (CPU python)=11825.92578125MB; mem (CPU total)=11509.3125MB
INFO:root:[  115] Training loss: 0.39400359, Validation loss: 0.37121674, Gradient norm: 4.26684499
INFO:root:At the start of the epoch: mem (CPU python)=11848.046875MB; mem (CPU total)=11529.71875MB
INFO:root:[  116] Training loss: 0.39406863, Validation loss: 0.37140229, Gradient norm: 3.92007541
INFO:root:At the start of the epoch: mem (CPU python)=11870.3515625MB; mem (CPU total)=11553.0859375MB
INFO:root:[  117] Training loss: 0.39379698, Validation loss: 0.37156203, Gradient norm: 4.39897941
INFO:root:At the start of the epoch: mem (CPU python)=11891.2265625MB; mem (CPU total)=11573.50390625MB
INFO:root:[  118] Training loss: 0.39491266, Validation loss: 0.37137768, Gradient norm: 4.26340099
INFO:root:At the start of the epoch: mem (CPU python)=11912.2890625MB; mem (CPU total)=11594.89453125MB
INFO:root:EP 118: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=11935.3515625MB; mem (CPU total)=11617.03125MB
INFO:root:[  120] Training loss: 0.48119517, Validation loss: 0.45334087, Gradient norm: 6.11510558
INFO:root:At the start of the epoch: mem (CPU python)=11943.8125MB; mem (CPU total)=11626.17578125MB
INFO:root:[  121] Training loss: 0.47819099, Validation loss: 0.45213185, Gradient norm: 5.66784911
INFO:root:At the start of the epoch: mem (CPU python)=11965.4375MB; mem (CPU total)=11647.125MB
INFO:root:[  122] Training loss: 0.47812656, Validation loss: 0.45188757, Gradient norm: 5.98609953
INFO:root:At the start of the epoch: mem (CPU python)=11986.90625MB; mem (CPU total)=11667.859375MB
INFO:root:[  123] Training loss: 0.47731424, Validation loss: 0.45097200, Gradient norm: 6.74458245
INFO:root:At the start of the epoch: mem (CPU python)=12008.0703125MB; mem (CPU total)=11689.2578125MB
INFO:root:[  124] Training loss: 0.47711657, Validation loss: 0.45061191, Gradient norm: 6.28776497
INFO:root:At the start of the epoch: mem (CPU python)=12029.234375MB; mem (CPU total)=11710.44140625MB
INFO:root:[  125] Training loss: 0.47652015, Validation loss: 0.45083220, Gradient norm: 5.49867622
INFO:root:At the start of the epoch: mem (CPU python)=12050.3984375MB; mem (CPU total)=11731.60546875MB
INFO:root:[  126] Training loss: 0.47644768, Validation loss: 0.45063694, Gradient norm: 6.26269682
INFO:root:At the start of the epoch: mem (CPU python)=12071.5625MB; mem (CPU total)=11752.76953125MB
INFO:root:[  127] Training loss: 0.47607540, Validation loss: 0.45030925, Gradient norm: 5.94556404
INFO:root:At the start of the epoch: mem (CPU python)=12092.73046875MB; mem (CPU total)=11774.44921875MB
INFO:root:[  128] Training loss: 0.47598820, Validation loss: 0.44990763, Gradient norm: 6.19120248
INFO:root:At the start of the epoch: mem (CPU python)=12113.89453125MB; mem (CPU total)=11795.5625MB
INFO:root:[  129] Training loss: 0.47553712, Validation loss: 0.45012045, Gradient norm: 6.06690196
INFO:root:At the start of the epoch: mem (CPU python)=12135.0546875MB; mem (CPU total)=11816.69921875MB
INFO:root:[  130] Training loss: 0.47564910, Validation loss: 0.44911002, Gradient norm: 6.18711588
INFO:root:At the start of the epoch: mem (CPU python)=12156.22265625MB; mem (CPU total)=11837.84375MB
INFO:root:[  131] Training loss: 0.47514594, Validation loss: 0.44958188, Gradient norm: 5.67025734
INFO:root:At the start of the epoch: mem (CPU python)=12177.3828125MB; mem (CPU total)=11858.61328125MB
INFO:root:[  132] Training loss: 0.47561183, Validation loss: 0.44918977, Gradient norm: 6.29761689
INFO:root:At the start of the epoch: mem (CPU python)=12198.546875MB; mem (CPU total)=11879.76953125MB
INFO:root:[  133] Training loss: 0.47503466, Validation loss: 0.44874735, Gradient norm: 5.86870590
INFO:root:At the start of the epoch: mem (CPU python)=12219.71484375MB; mem (CPU total)=11900.59375MB
INFO:root:[  134] Training loss: 0.47464404, Validation loss: 0.44901366, Gradient norm: 6.09078082
INFO:root:At the start of the epoch: mem (CPU python)=12240.875MB; mem (CPU total)=11921.63671875MB
INFO:root:[  135] Training loss: 0.47530253, Validation loss: 0.45054880, Gradient norm: 6.43928759
INFO:root:At the start of the epoch: mem (CPU python)=12262.0390625MB; mem (CPU total)=11942.76953125MB
INFO:root:[  136] Training loss: 0.47470025, Validation loss: 0.44815526, Gradient norm: 6.85249398
INFO:root:At the start of the epoch: mem (CPU python)=12283.203125MB; mem (CPU total)=11963.91015625MB
INFO:root:[  137] Training loss: 0.47471628, Validation loss: 0.44949446, Gradient norm: 6.15101822
INFO:root:At the start of the epoch: mem (CPU python)=12304.3671875MB; mem (CPU total)=11985.0546875MB
INFO:root:[  138] Training loss: 0.47455922, Validation loss: 0.44830756, Gradient norm: 6.08494800
INFO:root:At the start of the epoch: mem (CPU python)=12325.53125MB; mem (CPU total)=12006.43359375MB
INFO:root:[  139] Training loss: 0.47460693, Validation loss: 0.44858734, Gradient norm: 6.66471037
INFO:root:At the start of the epoch: mem (CPU python)=12346.6953125MB; mem (CPU total)=12027.828125MB
INFO:root:[  140] Training loss: 0.47484074, Validation loss: 0.44802308, Gradient norm: 6.75187361
INFO:root:At the start of the epoch: mem (CPU python)=12367.859375MB; mem (CPU total)=12049.2109375MB
INFO:root:[  141] Training loss: 0.47480268, Validation loss: 0.44865383, Gradient norm: 6.93669045
INFO:root:At the start of the epoch: mem (CPU python)=12389.0234375MB; mem (CPU total)=12070.15234375MB
INFO:root:[  142] Training loss: 0.47456280, Validation loss: 0.44785365, Gradient norm: 6.39057377
INFO:root:At the start of the epoch: mem (CPU python)=12410.1875MB; mem (CPU total)=12091.07421875MB
INFO:root:[  143] Training loss: 0.47408756, Validation loss: 0.44842186, Gradient norm: 7.04792751
INFO:root:At the start of the epoch: mem (CPU python)=12431.3515625MB; mem (CPU total)=12112.2109375MB
INFO:root:[  144] Training loss: 0.47486092, Validation loss: 0.44822510, Gradient norm: 7.15705851
INFO:root:At the start of the epoch: mem (CPU python)=12452.515625MB; mem (CPU total)=12133.35546875MB
INFO:root:[  145] Training loss: 0.47476590, Validation loss: 0.44847259, Gradient norm: 6.86938789
INFO:root:At the start of the epoch: mem (CPU python)=12473.68359375MB; mem (CPU total)=12154.5078125MB
INFO:root:[  146] Training loss: 0.47387989, Validation loss: 0.44815806, Gradient norm: 6.65220910
INFO:root:At the start of the epoch: mem (CPU python)=12494.84765625MB; mem (CPU total)=12175.5546875MB
INFO:root:[  147] Training loss: 0.47398599, Validation loss: 0.44864688, Gradient norm: 6.97597515
INFO:root:At the start of the epoch: mem (CPU python)=12516.01171875MB; mem (CPU total)=12197.43359375MB
INFO:root:[  148] Training loss: 0.47409515, Validation loss: 0.44766650, Gradient norm: 6.96069057
INFO:root:At the start of the epoch: mem (CPU python)=12537.17578125MB; mem (CPU total)=12219.49609375MB
INFO:root:[  149] Training loss: 0.47373026, Validation loss: 0.44753333, Gradient norm: 6.58903455
INFO:root:At the start of the epoch: mem (CPU python)=12558.34375MB; mem (CPU total)=12240.15625MB
INFO:root:[  150] Training loss: 0.47351886, Validation loss: 0.44759462, Gradient norm: 7.00141123
INFO:root:At the start of the epoch: mem (CPU python)=12579.5MB; mem (CPU total)=12260.09765625MB
INFO:root:[  151] Training loss: 0.47383041, Validation loss: 0.44816856, Gradient norm: 6.85104627
INFO:root:At the start of the epoch: mem (CPU python)=12600.66796875MB; mem (CPU total)=12280.5546875MB
INFO:root:[  152] Training loss: 0.47389116, Validation loss: 0.44755922, Gradient norm: 7.66873741
INFO:root:At the start of the epoch: mem (CPU python)=12621.83203125MB; mem (CPU total)=12301.71484375MB
INFO:root:[  153] Training loss: 0.47353463, Validation loss: 0.44799037, Gradient norm: 6.83121210
INFO:root:At the start of the epoch: mem (CPU python)=12642.99609375MB; mem (CPU total)=12323.0234375MB
INFO:root:[  154] Training loss: 0.47364352, Validation loss: 0.44741314, Gradient norm: 7.28552109
INFO:root:At the start of the epoch: mem (CPU python)=12664.16015625MB; mem (CPU total)=12344.1796875MB
INFO:root:[  155] Training loss: 0.47379222, Validation loss: 0.44750941, Gradient norm: 7.89095306
INFO:root:At the start of the epoch: mem (CPU python)=12685.32421875MB; mem (CPU total)=12365.2890625MB
INFO:root:[  156] Training loss: 0.47374688, Validation loss: 0.44741324, Gradient norm: 7.22349942
INFO:root:At the start of the epoch: mem (CPU python)=12706.4921875MB; mem (CPU total)=12386.41796875MB
INFO:root:[  157] Training loss: 0.47289302, Validation loss: 0.44682921, Gradient norm: 7.95014358
INFO:root:At the start of the epoch: mem (CPU python)=12727.65625MB; mem (CPU total)=12407.390625MB
INFO:root:[  158] Training loss: 0.47331276, Validation loss: 0.44739703, Gradient norm: 7.80709354
INFO:root:At the start of the epoch: mem (CPU python)=12748.8203125MB; mem (CPU total)=12428.81640625MB
INFO:root:[  159] Training loss: 0.47394701, Validation loss: 0.44757068, Gradient norm: 8.28530102
INFO:root:At the start of the epoch: mem (CPU python)=12769.98046875MB; mem (CPU total)=12449.98046875MB
INFO:root:[  160] Training loss: 0.47349029, Validation loss: 0.44725864, Gradient norm: 8.20409995
INFO:root:At the start of the epoch: mem (CPU python)=12791.14453125MB; mem (CPU total)=12471.140625MB
INFO:root:[  161] Training loss: 0.47338567, Validation loss: 0.44722593, Gradient norm: 7.53489329
INFO:root:At the start of the epoch: mem (CPU python)=12812.3125MB; mem (CPU total)=12492.54296875MB
INFO:root:[  162] Training loss: 0.47305513, Validation loss: 0.44686619, Gradient norm: 7.47549418
INFO:root:At the start of the epoch: mem (CPU python)=12833.4765625MB; mem (CPU total)=12513.70703125MB
INFO:root:[  163] Training loss: 0.47275679, Validation loss: 0.44645330, Gradient norm: 7.69583453
INFO:root:At the start of the epoch: mem (CPU python)=12854.640625MB; mem (CPU total)=12534.87109375MB
INFO:root:[  164] Training loss: 0.47358029, Validation loss: 0.44687046, Gradient norm: 7.98737537
INFO:root:At the start of the epoch: mem (CPU python)=12875.8046875MB; mem (CPU total)=12556.265625MB
INFO:root:[  165] Training loss: 0.47373251, Validation loss: 0.44657485, Gradient norm: 7.98534844
INFO:root:At the start of the epoch: mem (CPU python)=12896.96875MB; mem (CPU total)=12577.1484375MB
INFO:root:[  166] Training loss: 0.47304690, Validation loss: 0.44657684, Gradient norm: 8.02244719
INFO:root:At the start of the epoch: mem (CPU python)=12918.1328125MB; mem (CPU total)=12598.515625MB
INFO:root:[  167] Training loss: 0.47307551, Validation loss: 0.44680866, Gradient norm: 8.45833051
INFO:root:At the start of the epoch: mem (CPU python)=12939.30078125MB; mem (CPU total)=12620.890625MB
INFO:root:[  168] Training loss: 0.47334078, Validation loss: 0.44701961, Gradient norm: 8.64175343
INFO:root:At the start of the epoch: mem (CPU python)=12960.46484375MB; mem (CPU total)=12641.93359375MB
INFO:root:[  169] Training loss: 0.47260420, Validation loss: 0.44674600, Gradient norm: 8.09336129
INFO:root:At the start of the epoch: mem (CPU python)=12981.62109375MB; mem (CPU total)=12663.31640625MB
INFO:root:[  170] Training loss: 0.47293491, Validation loss: 0.44636681, Gradient norm: 8.31916696
INFO:root:At the start of the epoch: mem (CPU python)=13002.7890625MB; mem (CPU total)=12684.64453125MB
INFO:root:[  171] Training loss: 0.47268525, Validation loss: 0.44670860, Gradient norm: 8.83601311
INFO:root:At the start of the epoch: mem (CPU python)=13023.953125MB; mem (CPU total)=12705.65234375MB
INFO:root:[  172] Training loss: 0.47259815, Validation loss: 0.44650237, Gradient norm: 8.56861767
INFO:root:At the start of the epoch: mem (CPU python)=13045.12109375MB; mem (CPU total)=12726.81640625MB
INFO:root:[  173] Training loss: 0.47307245, Validation loss: 0.44666274, Gradient norm: 9.41932984
INFO:root:At the start of the epoch: mem (CPU python)=13066.28515625MB; mem (CPU total)=12747.67578125MB
INFO:root:[  174] Training loss: 0.47258408, Validation loss: 0.44719044, Gradient norm: 8.41992773
INFO:root:At the start of the epoch: mem (CPU python)=13087.44921875MB; mem (CPU total)=12769.0546875MB
INFO:root:[  175] Training loss: 0.47292447, Validation loss: 0.44702413, Gradient norm: 9.36634486
INFO:root:At the start of the epoch: mem (CPU python)=13108.61328125MB; mem (CPU total)=12790.1953125MB
INFO:root:[  176] Training loss: 0.47265019, Validation loss: 0.44629122, Gradient norm: 8.55194107
INFO:root:At the start of the epoch: mem (CPU python)=13129.77734375MB; mem (CPU total)=12810.9921875MB
INFO:root:[  177] Training loss: 0.47241222, Validation loss: 0.44670781, Gradient norm: 9.05180020
INFO:root:At the start of the epoch: mem (CPU python)=13150.94140625MB; mem (CPU total)=12831.234375MB
INFO:root:[  178] Training loss: 0.47296261, Validation loss: 0.44678047, Gradient norm: 9.12911049
INFO:root:At the start of the epoch: mem (CPU python)=13172.1015625MB; mem (CPU total)=12852.11328125MB
INFO:root:[  179] Training loss: 0.47299367, Validation loss: 0.44645317, Gradient norm: 9.49273193
INFO:root:At the start of the epoch: mem (CPU python)=13193.265625MB; mem (CPU total)=12873.0234375MB
INFO:root:[  180] Training loss: 0.47250233, Validation loss: 0.44591309, Gradient norm: 9.19621808
INFO:root:At the start of the epoch: mem (CPU python)=13214.43359375MB; mem (CPU total)=12894.1875MB
INFO:root:[  181] Training loss: 0.47225048, Validation loss: 0.44602184, Gradient norm: 9.20955914
INFO:root:At the start of the epoch: mem (CPU python)=13235.59765625MB; mem (CPU total)=12915.34765625MB
INFO:root:[  182] Training loss: 0.47209466, Validation loss: 0.44594422, Gradient norm: 9.00245688
INFO:root:At the start of the epoch: mem (CPU python)=13256.76171875MB; mem (CPU total)=12936.24609375MB
INFO:root:[  183] Training loss: 0.47217922, Validation loss: 0.44607486, Gradient norm: 9.94156944
INFO:root:At the start of the epoch: mem (CPU python)=13277.92578125MB; mem (CPU total)=12957.671875MB
INFO:root:[  184] Training loss: 0.47273904, Validation loss: 0.44582260, Gradient norm: 10.18362355
INFO:root:At the start of the epoch: mem (CPU python)=13299.09375MB; mem (CPU total)=12978.8359375MB
INFO:root:[  185] Training loss: 0.47258382, Validation loss: 0.44606507, Gradient norm: 9.86613778
INFO:root:At the start of the epoch: mem (CPU python)=13320.2578125MB; mem (CPU total)=13000.23828125MB
INFO:root:[  186] Training loss: 0.47260840, Validation loss: 0.44630930, Gradient norm: 9.90973146
INFO:root:At the start of the epoch: mem (CPU python)=13341.41796875MB; mem (CPU total)=13021.3828125MB
INFO:root:[  187] Training loss: 0.47285111, Validation loss: 0.44555490, Gradient norm: 9.78854558
INFO:root:At the start of the epoch: mem (CPU python)=13362.578125MB; mem (CPU total)=13042.53125MB
INFO:root:[  188] Training loss: 0.47263524, Validation loss: 0.44671942, Gradient norm: 9.44840839
INFO:root:At the start of the epoch: mem (CPU python)=13383.7421875MB; mem (CPU total)=13063.625MB
INFO:root:[  189] Training loss: 0.47274234, Validation loss: 0.44656209, Gradient norm: 10.19243670
INFO:root:At the start of the epoch: mem (CPU python)=13404.90625MB; mem (CPU total)=13084.76953125MB
INFO:root:[  190] Training loss: 0.47231874, Validation loss: 0.44571181, Gradient norm: 9.29743389
INFO:root:At the start of the epoch: mem (CPU python)=13426.0703125MB; mem (CPU total)=13105.91015625MB
INFO:root:[  191] Training loss: 0.47184552, Validation loss: 0.44577850, Gradient norm: 9.75916670
INFO:root:At the start of the epoch: mem (CPU python)=13447.23828125MB; mem (CPU total)=13127.0390625MB
INFO:root:[  192] Training loss: 0.47254798, Validation loss: 0.44605626, Gradient norm: 9.93064534
INFO:root:At the start of the epoch: mem (CPU python)=13468.40234375MB; mem (CPU total)=13147.9453125MB
INFO:root:[  193] Training loss: 0.47195364, Validation loss: 0.44596711, Gradient norm: 9.94497912
INFO:root:At the start of the epoch: mem (CPU python)=13489.56640625MB; mem (CPU total)=13169.05078125MB
INFO:root:[  194] Training loss: 0.47153460, Validation loss: 0.44551920, Gradient norm: 10.31514385
INFO:root:At the start of the epoch: mem (CPU python)=13510.73046875MB; mem (CPU total)=13190.2265625MB
INFO:root:[  195] Training loss: 0.47183792, Validation loss: 0.44549061, Gradient norm: 10.47219628
INFO:root:At the start of the epoch: mem (CPU python)=13531.90234375MB; mem (CPU total)=13211.61328125MB
INFO:root:[  196] Training loss: 0.47178536, Validation loss: 0.44530201, Gradient norm: 10.35182908
INFO:root:At the start of the epoch: mem (CPU python)=13553.06640625MB; mem (CPU total)=13233.01953125MB
INFO:root:[  197] Training loss: 0.47240936, Validation loss: 0.44552841, Gradient norm: 9.90634198
INFO:root:At the start of the epoch: mem (CPU python)=13574.2265625MB; mem (CPU total)=13254.140625MB
INFO:root:[  198] Training loss: 0.47202528, Validation loss: 0.44611669, Gradient norm: 11.11984126
INFO:root:At the start of the epoch: mem (CPU python)=13595.390625MB; mem (CPU total)=13275.296875MB
INFO:root:[  199] Training loss: 0.47217261, Validation loss: 0.44695755, Gradient norm: 10.61739692
INFO:root:At the start of the epoch: mem (CPU python)=13616.5546875MB; mem (CPU total)=13296.69921875MB
INFO:root:[  200] Training loss: 0.47207908, Validation loss: 0.44509810, Gradient norm: 10.80741872
INFO:root:At the start of the epoch: mem (CPU python)=13637.71875MB; mem (CPU total)=13317.85546875MB
INFO:root:[  201] Training loss: 0.47162991, Validation loss: 0.44576552, Gradient norm: 10.93268716
INFO:root:At the start of the epoch: mem (CPU python)=13658.8828125MB; mem (CPU total)=13338.96875MB
INFO:root:[  202] Training loss: 0.47154181, Validation loss: 0.44499761, Gradient norm: 11.41138953
INFO:root:At the start of the epoch: mem (CPU python)=13680.05078125MB; mem (CPU total)=13359.88671875MB
INFO:root:[  203] Training loss: 0.47202268, Validation loss: 0.44507380, Gradient norm: 11.33043648
INFO:root:At the start of the epoch: mem (CPU python)=13701.2109375MB; mem (CPU total)=13380.9375MB
INFO:root:[  204] Training loss: 0.47149063, Validation loss: 0.44508330, Gradient norm: 10.68917045
INFO:root:At the start of the epoch: mem (CPU python)=13722.375MB; mem (CPU total)=13402.33984375MB
INFO:root:[  205] Training loss: 0.47139225, Validation loss: 0.44598791, Gradient norm: 10.90681279
INFO:root:At the start of the epoch: mem (CPU python)=13743.5390625MB; mem (CPU total)=13423.49609375MB
INFO:root:[  206] Training loss: 0.47133591, Validation loss: 0.44446403, Gradient norm: 11.21100446
INFO:root:At the start of the epoch: mem (CPU python)=13764.703125MB; mem (CPU total)=13445.1484375MB
INFO:root:[  207] Training loss: 0.47211546, Validation loss: 0.44593596, Gradient norm: 11.23023288
INFO:root:At the start of the epoch: mem (CPU python)=13785.8671875MB; mem (CPU total)=13466.30078125MB
INFO:root:[  208] Training loss: 0.47196547, Validation loss: 0.44479621, Gradient norm: 11.34527426
INFO:root:At the start of the epoch: mem (CPU python)=13807.03125MB; mem (CPU total)=13487.4609375MB
INFO:root:[  209] Training loss: 0.47187978, Validation loss: 0.44510246, Gradient norm: 11.23355417
INFO:root:At the start of the epoch: mem (CPU python)=13828.1953125MB; mem (CPU total)=13508.59375MB
INFO:root:[  210] Training loss: 0.47142414, Validation loss: 0.44447596, Gradient norm: 11.28593846
INFO:root:At the start of the epoch: mem (CPU python)=13849.359375MB; mem (CPU total)=13529.421875MB
INFO:root:[  211] Training loss: 0.47143701, Validation loss: 0.44590571, Gradient norm: 11.46076510
INFO:root:At the start of the epoch: mem (CPU python)=13870.52734375MB; mem (CPU total)=13550.546875MB
INFO:root:[  212] Training loss: 0.47154216, Validation loss: 0.44558418, Gradient norm: 11.19688141
INFO:root:At the start of the epoch: mem (CPU python)=13891.69140625MB; mem (CPU total)=13571.6875MB
INFO:root:[  213] Training loss: 0.47152104, Validation loss: 0.44603730, Gradient norm: 11.74820526
INFO:root:At the start of the epoch: mem (CPU python)=13912.85546875MB; mem (CPU total)=13592.83984375MB
INFO:root:[  214] Training loss: 0.47173642, Validation loss: 0.44502536, Gradient norm: 12.19720768
INFO:root:At the start of the epoch: mem (CPU python)=13934.01953125MB; mem (CPU total)=13613.734375MB
INFO:root:[  215] Training loss: 0.47135157, Validation loss: 0.44546544, Gradient norm: 11.67234476
INFO:root:At the start of the epoch: mem (CPU python)=13955.18359375MB; mem (CPU total)=13635.1328125MB
INFO:root:EP 215: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=13976.125MB; mem (CPU total)=13656.29296875MB
INFO:root:Training the model took 7525.669s.
INFO:root:Emptying the cuda cache took 0.061s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.56335
INFO:root:EnergyScoreValidation: 0.36173
INFO:root:CRPSValidation: 0.15651
INFO:root:Gaussian NLLValidation: 14.86513
INFO:root:CoverageValidation: 0.48945
INFO:root:IntervalWidthValidation: 0.39304
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.48285
INFO:root:EnergyScoreTest: 0.29289
INFO:root:CRPSTest: 0.1291
INFO:root:Gaussian NLLTest: 11.72725
INFO:root:CoverageTest: 0.53785
INFO:root:IntervalWidthTest: 0.40132
INFO:root:After validation: mem (CPU python)=14062.8125MB; mem (CPU total)=13744.8125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=14062.8125MB; mem (CPU total)=13650.6953125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 346030080
INFO:root:After setting up the model: mem (CPU python)=14062.8125MB; mem (CPU total)=13680.38671875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=14062.8125MB; mem (CPU total)=13680.390625MB
INFO:root:[    1] Training loss: 0.84074616, Validation loss: 0.73742301, Gradient norm: 0.48069239
INFO:root:At the start of the epoch: mem (CPU python)=14062.8125MB; mem (CPU total)=13712.82421875MB
INFO:root:[    2] Training loss: 0.74151034, Validation loss: 0.73201175, Gradient norm: 0.39597610
INFO:root:At the start of the epoch: mem (CPU python)=14062.8125MB; mem (CPU total)=13734.05078125MB
INFO:root:[    3] Training loss: 0.73931278, Validation loss: 0.73269488, Gradient norm: 0.49077016
INFO:root:At the start of the epoch: mem (CPU python)=14071.9609375MB; mem (CPU total)=13755.45703125MB
INFO:root:[    4] Training loss: 0.72046235, Validation loss: 0.70781208, Gradient norm: 0.54003942
INFO:root:At the start of the epoch: mem (CPU python)=14093.125MB; mem (CPU total)=13776.609375MB
INFO:root:[    5] Training loss: 0.68632441, Validation loss: 0.65415972, Gradient norm: 0.83873132
INFO:root:At the start of the epoch: mem (CPU python)=14114.29296875MB; mem (CPU total)=13797.76953125MB
INFO:root:[    6] Training loss: 0.63252488, Validation loss: 0.58783209, Gradient norm: 1.18403594
INFO:root:At the start of the epoch: mem (CPU python)=14135.45703125MB; mem (CPU total)=13818.57421875MB
INFO:root:[    7] Training loss: 0.59489666, Validation loss: 0.56840416, Gradient norm: 1.33496077
INFO:root:At the start of the epoch: mem (CPU python)=14156.62109375MB; mem (CPU total)=13839.734375MB
INFO:root:[    8] Training loss: 0.58665431, Validation loss: 0.55095091, Gradient norm: 1.94981021
INFO:root:At the start of the epoch: mem (CPU python)=14177.78515625MB; mem (CPU total)=13861.1328125MB
INFO:root:[    9] Training loss: 0.57319450, Validation loss: 0.54048330, Gradient norm: 1.57991173
INFO:root:At the start of the epoch: mem (CPU python)=14198.94921875MB; mem (CPU total)=13882.16796875MB
INFO:root:[   10] Training loss: 0.55907366, Validation loss: 0.52055852, Gradient norm: 1.90865795
INFO:root:At the start of the epoch: mem (CPU python)=14220.11328125MB; mem (CPU total)=13903.6328125MB
INFO:root:[   11] Training loss: 0.55596529, Validation loss: 0.51826512, Gradient norm: 2.20706195
INFO:root:At the start of the epoch: mem (CPU python)=14241.27734375MB; mem (CPU total)=13924.6875MB
INFO:root:[   12] Training loss: 0.54166716, Validation loss: 0.50712612, Gradient norm: 2.09849273
INFO:root:At the start of the epoch: mem (CPU python)=14262.4375MB; mem (CPU total)=13945.890625MB
INFO:root:[   13] Training loss: 0.53255698, Validation loss: 0.49970244, Gradient norm: 2.28559804
INFO:root:At the start of the epoch: mem (CPU python)=14283.6015625MB; mem (CPU total)=13966.91796875MB
INFO:root:[   14] Training loss: 0.52729289, Validation loss: 0.49450529, Gradient norm: 2.36974352
INFO:root:At the start of the epoch: mem (CPU python)=14304.765625MB; mem (CPU total)=13988.078125MB
INFO:root:[   15] Training loss: 0.51519309, Validation loss: 0.48091615, Gradient norm: 2.52929046
INFO:root:At the start of the epoch: mem (CPU python)=14325.93359375MB; mem (CPU total)=14009.77734375MB
INFO:root:[   16] Training loss: 0.51243165, Validation loss: 0.47255209, Gradient norm: 2.73332518
INFO:root:At the start of the epoch: mem (CPU python)=14347.09765625MB; mem (CPU total)=14030.453125MB
INFO:root:[   17] Training loss: 0.50604935, Validation loss: 0.48937049, Gradient norm: 2.41389482
INFO:root:At the start of the epoch: mem (CPU python)=14368.26171875MB; mem (CPU total)=14051.6171875MB
INFO:root:[   18] Training loss: 0.50044287, Validation loss: 0.48197678, Gradient norm: 2.89369358
INFO:root:At the start of the epoch: mem (CPU python)=14389.42578125MB; mem (CPU total)=14073.09765625MB
INFO:root:[   19] Training loss: 0.51065832, Validation loss: 0.46138703, Gradient norm: 2.89111443
INFO:root:At the start of the epoch: mem (CPU python)=14410.58984375MB; mem (CPU total)=14094.5078125MB
INFO:root:[   20] Training loss: 0.49833997, Validation loss: 0.46505513, Gradient norm: 2.67570682
INFO:root:At the start of the epoch: mem (CPU python)=14431.75390625MB; mem (CPU total)=14115.66796875MB
INFO:root:[   21] Training loss: 0.49435765, Validation loss: 0.48170489, Gradient norm: 2.80235486
INFO:root:At the start of the epoch: mem (CPU python)=14452.91796875MB; mem (CPU total)=14136.44921875MB
INFO:root:[   22] Training loss: 0.49293507, Validation loss: 0.44757308, Gradient norm: 2.84230961
INFO:root:At the start of the epoch: mem (CPU python)=14474.08203125MB; mem (CPU total)=14157.609375MB
INFO:root:[   23] Training loss: 0.49524933, Validation loss: 0.46136859, Gradient norm: 3.05686809
INFO:root:At the start of the epoch: mem (CPU python)=14495.24609375MB; mem (CPU total)=14178.7421875MB
INFO:root:[   24] Training loss: 0.49201863, Validation loss: 0.47247427, Gradient norm: 2.84043623
INFO:root:At the start of the epoch: mem (CPU python)=14516.41015625MB; mem (CPU total)=14200.15625MB
INFO:root:[   25] Training loss: 0.49376545, Validation loss: 0.46470708, Gradient norm: 2.94651878
INFO:root:At the start of the epoch: mem (CPU python)=14537.57421875MB; mem (CPU total)=14221.33203125MB
INFO:root:[   26] Training loss: 0.48586064, Validation loss: 0.45711759, Gradient norm: 2.89426088
INFO:root:At the start of the epoch: mem (CPU python)=14558.73828125MB; mem (CPU total)=14242.15625MB
INFO:root:[   27] Training loss: 0.49215465, Validation loss: 0.47108773, Gradient norm: 2.70286470
INFO:root:At the start of the epoch: mem (CPU python)=14579.90234375MB; mem (CPU total)=14263.328125MB
INFO:root:[   28] Training loss: 0.48336535, Validation loss: 0.45383529, Gradient norm: 3.32480407
INFO:root:At the start of the epoch: mem (CPU python)=14601.06640625MB; mem (CPU total)=14284.4921875MB
INFO:root:[   29] Training loss: 0.48596263, Validation loss: 0.44300569, Gradient norm: 2.96041899
INFO:root:At the start of the epoch: mem (CPU python)=14622.234375MB; mem (CPU total)=14306.30859375MB
INFO:root:[   30] Training loss: 0.48148246, Validation loss: 0.48065081, Gradient norm: 3.07803495
INFO:root:At the start of the epoch: mem (CPU python)=14643.39453125MB; mem (CPU total)=14326.98828125MB
INFO:root:[   31] Training loss: 0.48655759, Validation loss: 0.45665826, Gradient norm: 3.14451874
INFO:root:At the start of the epoch: mem (CPU python)=14664.55859375MB; mem (CPU total)=14348.17578125MB
INFO:root:[   32] Training loss: 0.48080619, Validation loss: 0.47906421, Gradient norm: 3.26718405
INFO:root:At the start of the epoch: mem (CPU python)=14685.72265625MB; mem (CPU total)=14369.07421875MB
INFO:root:[   33] Training loss: 0.48494870, Validation loss: 0.46013767, Gradient norm: 3.16723911
INFO:root:At the start of the epoch: mem (CPU python)=14706.88671875MB; mem (CPU total)=14390.24609375MB
INFO:root:[   34] Training loss: 0.47715983, Validation loss: 0.44686531, Gradient norm: 2.76996125
INFO:root:At the start of the epoch: mem (CPU python)=14728.05078125MB; mem (CPU total)=14411.4140625MB
INFO:root:[   35] Training loss: 0.47982417, Validation loss: 0.44561241, Gradient norm: 3.44669562
INFO:root:At the start of the epoch: mem (CPU python)=14749.21484375MB; mem (CPU total)=14432.81640625MB
INFO:root:[   36] Training loss: 0.48017239, Validation loss: 0.46285452, Gradient norm: 3.28862694
INFO:root:At the start of the epoch: mem (CPU python)=14770.390625MB; mem (CPU total)=14453.7265625MB
INFO:root:[   37] Training loss: 0.47702638, Validation loss: 0.44596424, Gradient norm: 2.93396561
INFO:root:At the start of the epoch: mem (CPU python)=14791.5546875MB; mem (CPU total)=14475.6171875MB
INFO:root:[   38] Training loss: 0.47731192, Validation loss: 0.44457146, Gradient norm: 3.71602366
INFO:root:At the start of the epoch: mem (CPU python)=14812.71875MB; mem (CPU total)=14497.05859375MB
INFO:root:[   39] Training loss: 0.47723774, Validation loss: 0.44861292, Gradient norm: 3.49188900
INFO:root:At the start of the epoch: mem (CPU python)=14833.8828125MB; mem (CPU total)=14518.19140625MB
INFO:root:[   40] Training loss: 0.47927062, Validation loss: 0.46018463, Gradient norm: 3.21414521
INFO:root:At the start of the epoch: mem (CPU python)=14855.04296875MB; mem (CPU total)=14539.19921875MB
INFO:root:[   41] Training loss: 0.47583273, Validation loss: 0.45446759, Gradient norm: 3.43046782
INFO:root:At the start of the epoch: mem (CPU python)=14876.2109375MB; mem (CPU total)=14560.609375MB
INFO:root:[   42] Training loss: 0.47982166, Validation loss: 0.45290050, Gradient norm: 3.40791316
INFO:root:At the start of the epoch: mem (CPU python)=14897.375MB; mem (CPU total)=14581.765625MB
INFO:root:[   43] Training loss: 0.46910075, Validation loss: 0.43782207, Gradient norm: 3.93191516
INFO:root:At the start of the epoch: mem (CPU python)=14918.5390625MB; mem (CPU total)=14603.1328125MB
INFO:root:[   44] Training loss: 0.47236201, Validation loss: 0.43241439, Gradient norm: 3.48653280
INFO:root:At the start of the epoch: mem (CPU python)=14939.69921875MB; mem (CPU total)=14623.8828125MB
INFO:root:[   45] Training loss: 0.47629110, Validation loss: 0.44300306, Gradient norm: 4.18540763
INFO:root:At the start of the epoch: mem (CPU python)=14960.8671875MB; mem (CPU total)=14645.03515625MB
INFO:root:[   46] Training loss: 0.47332401, Validation loss: 0.44411006, Gradient norm: 3.60912710
INFO:root:At the start of the epoch: mem (CPU python)=14982.578125MB; mem (CPU total)=14667.421875MB
INFO:root:[   47] Training loss: 0.47158440, Validation loss: 0.45432105, Gradient norm: 3.83049782
INFO:root:At the start of the epoch: mem (CPU python)=15003.7421875MB; mem (CPU total)=14688.5703125MB
INFO:root:[   48] Training loss: 0.46757174, Validation loss: 0.43627526, Gradient norm: 3.78696595
INFO:root:At the start of the epoch: mem (CPU python)=15025.48828125MB; mem (CPU total)=14709.71484375MB
INFO:root:[   49] Training loss: 0.47014146, Validation loss: 0.43670414, Gradient norm: 3.48482944
INFO:root:At the start of the epoch: mem (CPU python)=15046.65234375MB; mem (CPU total)=14731.16015625MB
INFO:root:[   50] Training loss: 0.46779428, Validation loss: 0.43622351, Gradient norm: 4.01986235
INFO:root:At the start of the epoch: mem (CPU python)=15067.8125MB; mem (CPU total)=14752.30859375MB
INFO:root:[   51] Training loss: 0.46624732, Validation loss: 0.43499379, Gradient norm: 3.59468882
INFO:root:At the start of the epoch: mem (CPU python)=15088.98046875MB; mem (CPU total)=14773.703125MB
INFO:root:[   52] Training loss: 0.46586160, Validation loss: 0.45849848, Gradient norm: 4.05924193
INFO:root:At the start of the epoch: mem (CPU python)=15110.14453125MB; mem (CPU total)=14794.86328125MB
INFO:root:[   53] Training loss: 0.46970357, Validation loss: 0.43305267, Gradient norm: 3.78604791
INFO:root:At the start of the epoch: mem (CPU python)=15131.30859375MB; mem (CPU total)=14815.9609375MB
INFO:root:[   54] Training loss: 0.46323983, Validation loss: 0.43488876, Gradient norm: 3.45484904
INFO:root:At the start of the epoch: mem (CPU python)=15152.47265625MB; mem (CPU total)=14837.125MB
INFO:root:[   55] Training loss: 0.46785945, Validation loss: 0.43242223, Gradient norm: 4.06836315
INFO:root:At the start of the epoch: mem (CPU python)=15173.63671875MB; mem (CPU total)=14858.2890625MB
INFO:root:[   56] Training loss: 0.47196456, Validation loss: 0.43969072, Gradient norm: 3.56461604
INFO:root:At the start of the epoch: mem (CPU python)=15194.80078125MB; mem (CPU total)=14879.453125MB
INFO:root:[   57] Training loss: 0.46183864, Validation loss: 0.47151862, Gradient norm: 3.94547796
INFO:root:At the start of the epoch: mem (CPU python)=15215.96484375MB; mem (CPU total)=14900.6171875MB
INFO:root:[   58] Training loss: 0.47085555, Validation loss: 0.44636291, Gradient norm: 3.96397488
INFO:root:At the start of the epoch: mem (CPU python)=15237.1328125MB; mem (CPU total)=14921.77734375MB
INFO:root:[   59] Training loss: 0.46347700, Validation loss: 0.42969294, Gradient norm: 3.56105399
INFO:root:At the start of the epoch: mem (CPU python)=15258.29296875MB; mem (CPU total)=14943.17578125MB
INFO:root:[   60] Training loss: 0.46096191, Validation loss: 0.42503101, Gradient norm: 3.29559090
INFO:root:At the start of the epoch: mem (CPU python)=15279.45703125MB; mem (CPU total)=14964.28125MB
INFO:root:[   61] Training loss: 0.46151452, Validation loss: 0.46225602, Gradient norm: 4.24935399
INFO:root:At the start of the epoch: mem (CPU python)=15300.6171875MB; mem (CPU total)=14985.43359375MB
INFO:root:[   62] Training loss: 0.46018922, Validation loss: 0.43005589, Gradient norm: 3.93993429
INFO:root:At the start of the epoch: mem (CPU python)=15322.05078125MB; mem (CPU total)=15008.5MB
INFO:root:[   63] Training loss: 0.46163088, Validation loss: 0.42549482, Gradient norm: 3.86835311
INFO:root:At the start of the epoch: mem (CPU python)=15343.21875MB; mem (CPU total)=15029.2734375MB
INFO:root:[   64] Training loss: 0.45776591, Validation loss: 0.42332473, Gradient norm: 3.90453467
INFO:root:At the start of the epoch: mem (CPU python)=15364.86328125MB; mem (CPU total)=15050.1796875MB
INFO:root:[   65] Training loss: 0.46450757, Validation loss: 0.43486883, Gradient norm: 3.62895740
INFO:root:At the start of the epoch: mem (CPU python)=15386.02734375MB; mem (CPU total)=15071.33984375MB
INFO:root:[   66] Training loss: 0.45484235, Validation loss: 0.41387824, Gradient norm: 3.71815089
INFO:root:At the start of the epoch: mem (CPU python)=15407.1953125MB; mem (CPU total)=15092.9921875MB
INFO:root:[   67] Training loss: 0.45658987, Validation loss: 0.44105647, Gradient norm: 4.02250338
INFO:root:At the start of the epoch: mem (CPU python)=15428.359375MB; mem (CPU total)=15114.54296875MB
INFO:root:[   68] Training loss: 0.46392612, Validation loss: 0.42856170, Gradient norm: 4.18784901
INFO:root:At the start of the epoch: mem (CPU python)=15449.89453125MB; mem (CPU total)=15135.34375MB
INFO:root:[   69] Training loss: 0.45622133, Validation loss: 0.41754389, Gradient norm: 3.58870552
INFO:root:At the start of the epoch: mem (CPU python)=15471.05859375MB; mem (CPU total)=15156.4453125MB
INFO:root:[   70] Training loss: 0.45660922, Validation loss: 0.42107470, Gradient norm: 4.07123843
INFO:root:At the start of the epoch: mem (CPU python)=15492.22265625MB; mem (CPU total)=15177.61328125MB
INFO:root:[   71] Training loss: 0.45754883, Validation loss: 0.42867384, Gradient norm: 4.03544567
INFO:root:At the start of the epoch: mem (CPU python)=15513.5234375MB; mem (CPU total)=15199.23046875MB
INFO:root:[   72] Training loss: 0.45556256, Validation loss: 0.42141068, Gradient norm: 4.10531107
INFO:root:At the start of the epoch: mem (CPU python)=15534.6875MB; mem (CPU total)=15220.65234375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   73] Training loss: 0.45330975, Validation loss: 0.42221671, Gradient norm: 3.97495319
INFO:root:At the start of the epoch: mem (CPU python)=15556.09375MB; mem (CPU total)=15241.80859375MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   74] Training loss: 0.42789328, Validation loss: 0.39055470, Gradient norm: 3.06459875
INFO:root:At the start of the epoch: mem (CPU python)=15577.2578125MB; mem (CPU total)=15262.7265625MB
INFO:root:[   75] Training loss: 0.41726934, Validation loss: 0.38296933, Gradient norm: 2.06592535
INFO:root:At the start of the epoch: mem (CPU python)=15601.23828125MB; mem (CPU total)=15287.3984375MB
INFO:root:[   76] Training loss: 0.41707450, Validation loss: 0.38587547, Gradient norm: 2.48681370
INFO:root:At the start of the epoch: mem (CPU python)=15622.66015625MB; mem (CPU total)=15308.55859375MB
INFO:root:[   77] Training loss: 0.41598330, Validation loss: 0.37936469, Gradient norm: 3.04202536
INFO:root:At the start of the epoch: mem (CPU python)=15644.125MB; mem (CPU total)=15329.7265625MB
INFO:root:[   78] Training loss: 0.41533907, Validation loss: 0.38647107, Gradient norm: 3.40406975
INFO:root:At the start of the epoch: mem (CPU python)=15665.28125MB; mem (CPU total)=15351.09765625MB
INFO:root:[   79] Training loss: 0.41564535, Validation loss: 0.38394360, Gradient norm: 3.92673231
INFO:root:At the start of the epoch: mem (CPU python)=15686.4453125MB; mem (CPU total)=15372.00390625MB
INFO:root:[   80] Training loss: 0.41544103, Validation loss: 0.38272474, Gradient norm: 4.40165941
INFO:root:At the start of the epoch: mem (CPU python)=15707.609375MB; mem (CPU total)=15393.1484375MB
INFO:root:[   81] Training loss: 0.41563984, Validation loss: 0.38662385, Gradient norm: 4.71426720
INFO:root:At the start of the epoch: mem (CPU python)=15728.77734375MB; mem (CPU total)=15414.2890625MB
INFO:root:[   82] Training loss: 0.41643538, Validation loss: 0.38335936, Gradient norm: 5.06127772
INFO:root:At the start of the epoch: mem (CPU python)=15749.94140625MB; mem (CPU total)=15435.421875MB
INFO:root:[   83] Training loss: 0.41539328, Validation loss: 0.38327214, Gradient norm: 5.50293185
INFO:root:At the start of the epoch: mem (CPU python)=15771.10546875MB; mem (CPU total)=15456.328125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   84] Training loss: 0.41570884, Validation loss: 0.37888409, Gradient norm: 5.77715838
INFO:root:At the start of the epoch: mem (CPU python)=15792.26953125MB; mem (CPU total)=15477.6953125MB
INFO:root:[   85] Training loss: 0.41099769, Validation loss: 0.37632425, Gradient norm: 3.60300429
INFO:root:At the start of the epoch: mem (CPU python)=15813.4375MB; mem (CPU total)=15498.53125MB
INFO:root:[   86] Training loss: 0.41049813, Validation loss: 0.37536021, Gradient norm: 4.05399882
INFO:root:At the start of the epoch: mem (CPU python)=15834.6015625MB; mem (CPU total)=15519.9609375MB
INFO:root:[   87] Training loss: 0.41089349, Validation loss: 0.37510849, Gradient norm: 4.47652944
INFO:root:At the start of the epoch: mem (CPU python)=15856.0625MB; mem (CPU total)=15541.72265625MB
INFO:root:[   88] Training loss: 0.41131451, Validation loss: 0.37680569, Gradient norm: 4.57597655
INFO:root:At the start of the epoch: mem (CPU python)=15877.2265625MB; mem (CPU total)=15562.86328125MB
INFO:root:[   89] Training loss: 0.41098136, Validation loss: 0.37680778, Gradient norm: 5.39836081
INFO:root:At the start of the epoch: mem (CPU python)=15898.83984375MB; mem (CPU total)=15584.01953125MB
INFO:root:[   90] Training loss: 0.41126935, Validation loss: 0.37526881, Gradient norm: 5.50213470
INFO:root:At the start of the epoch: mem (CPU python)=15920.00390625MB; mem (CPU total)=15605.171875MB
INFO:root:[   91] Training loss: 0.41069706, Validation loss: 0.37633146, Gradient norm: 5.95583007
INFO:root:At the start of the epoch: mem (CPU python)=15941.171875MB; mem (CPU total)=15626.3203125MB
INFO:root:[   92] Training loss: 0.41123601, Validation loss: 0.37442098, Gradient norm: 6.22389506
INFO:root:At the start of the epoch: mem (CPU python)=15962.46484375MB; mem (CPU total)=15648.1875MB
INFO:root:[   93] Training loss: 0.41175380, Validation loss: 0.38049970, Gradient norm: 6.72713091
INFO:root:At the start of the epoch: mem (CPU python)=15983.87890625MB; mem (CPU total)=15669.3359375MB
INFO:root:[   94] Training loss: 0.41153799, Validation loss: 0.37556281, Gradient norm: 6.85049627
INFO:root:At the start of the epoch: mem (CPU python)=16005.0390625MB; mem (CPU total)=15690.23828125MB
INFO:root:[   95] Training loss: 0.41199343, Validation loss: 0.37761708, Gradient norm: 7.29177133
INFO:root:At the start of the epoch: mem (CPU python)=16026.20703125MB; mem (CPU total)=15711.39453125MB
INFO:root:[   96] Training loss: 0.41222135, Validation loss: 0.37734152, Gradient norm: 7.49491368
INFO:root:At the start of the epoch: mem (CPU python)=16047.37109375MB; mem (CPU total)=15732.76953125MB
INFO:root:[   97] Training loss: 0.41209333, Validation loss: 0.37518452, Gradient norm: 7.79229839
INFO:root:At the start of the epoch: mem (CPU python)=16068.53515625MB; mem (CPU total)=15753.92578125MB
INFO:root:[   98] Training loss: 0.41234020, Validation loss: 0.38032511, Gradient norm: 8.19408020
INFO:root:At the start of the epoch: mem (CPU python)=16089.69921875MB; mem (CPU total)=15775.5625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   99] Training loss: 0.41250745, Validation loss: 0.37565060, Gradient norm: 8.62603766
INFO:root:At the start of the epoch: mem (CPU python)=16110.86328125MB; mem (CPU total)=15796.46484375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  100] Training loss: 0.40868656, Validation loss: 0.37430736, Gradient norm: 5.43250949
INFO:root:At the start of the epoch: mem (CPU python)=16132.02734375MB; mem (CPU total)=15817.625MB
INFO:root:[  101] Training loss: 0.40775319, Validation loss: 0.37359583, Gradient norm: 4.28915936
INFO:root:At the start of the epoch: mem (CPU python)=16153.19140625MB; mem (CPU total)=15838.52734375MB
INFO:root:[  102] Training loss: 0.40748492, Validation loss: 0.37304267, Gradient norm: 4.26867871
INFO:root:At the start of the epoch: mem (CPU python)=16174.83203125MB; mem (CPU total)=15860.8984375MB
INFO:root:[  103] Training loss: 0.40792799, Validation loss: 0.37320748, Gradient norm: 4.59663526
INFO:root:At the start of the epoch: mem (CPU python)=16196.6484375MB; mem (CPU total)=15882.03125MB
INFO:root:[  104] Training loss: 0.40756829, Validation loss: 0.37329888, Gradient norm: 5.00379676
INFO:root:At the start of the epoch: mem (CPU python)=16217.94140625MB; mem (CPU total)=15903.4453125MB
INFO:root:[  105] Training loss: 0.40822368, Validation loss: 0.37512287, Gradient norm: 5.75772771
INFO:root:At the start of the epoch: mem (CPU python)=16239.3515625MB; mem (CPU total)=15924.3515625MB
INFO:root:[  106] Training loss: 0.40779694, Validation loss: 0.37425456, Gradient norm: 6.63439565
INFO:root:At the start of the epoch: mem (CPU python)=16260.51171875MB; mem (CPU total)=15945.50390625MB
INFO:root:[  107] Training loss: 0.40784502, Validation loss: 0.37357825, Gradient norm: 5.85894688
INFO:root:At the start of the epoch: mem (CPU python)=16281.6796875MB; mem (CPU total)=15966.5703125MB
INFO:root:[  108] Training loss: 0.40809653, Validation loss: 0.37228786, Gradient norm: 4.84021100
INFO:root:At the start of the epoch: mem (CPU python)=16302.9296875MB; mem (CPU total)=15988.46875MB
INFO:root:[  109] Training loss: 0.40773951, Validation loss: 0.37342043, Gradient norm: 5.61579155
INFO:root:At the start of the epoch: mem (CPU python)=16324.296875MB; mem (CPU total)=16010.12109375MB
INFO:root:[  110] Training loss: 0.40745138, Validation loss: 0.37435657, Gradient norm: 6.03522217
INFO:root:At the start of the epoch: mem (CPU python)=16345.921875MB; mem (CPU total)=16031.03125MB
INFO:root:[  111] Training loss: 0.40790015, Validation loss: 0.37277486, Gradient norm: 6.73211626
INFO:root:At the start of the epoch: mem (CPU python)=16367.08203125MB; mem (CPU total)=16052.1953125MB
INFO:root:[  112] Training loss: 0.40749338, Validation loss: 0.37322860, Gradient norm: 6.27505065
INFO:root:At the start of the epoch: mem (CPU python)=16388.24609375MB; mem (CPU total)=16073.2265625MB
INFO:root:[  113] Training loss: 0.40816136, Validation loss: 0.37273674, Gradient norm: 7.45882919
INFO:root:At the start of the epoch: mem (CPU python)=16409.4140625MB; mem (CPU total)=16094.6328125MB
INFO:root:[  114] Training loss: 0.40797775, Validation loss: 0.37646684, Gradient norm: 6.49726877
INFO:root:At the start of the epoch: mem (CPU python)=16430.578125MB; mem (CPU total)=16116.04296875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  115] Training loss: 0.40773859, Validation loss: 0.37273366, Gradient norm: 7.03466172
INFO:root:At the start of the epoch: mem (CPU python)=16452.046875MB; mem (CPU total)=16137.9375MB
INFO:root:[  116] Training loss: 0.40766621, Validation loss: 0.37145970, Gradient norm: 5.20127398
INFO:root:At the start of the epoch: mem (CPU python)=16473.20703125MB; mem (CPU total)=16159.08984375MB
INFO:root:[  117] Training loss: 0.40650113, Validation loss: 0.37200563, Gradient norm: 5.18237713
INFO:root:At the start of the epoch: mem (CPU python)=16494.81640625MB; mem (CPU total)=16180.21484375MB
INFO:root:[  118] Training loss: 0.40766450, Validation loss: 0.37145499, Gradient norm: 5.63631394
INFO:root:At the start of the epoch: mem (CPU python)=16515.984375MB; mem (CPU total)=16201.39453125MB
INFO:root:[  119] Training loss: 0.40787312, Validation loss: 0.37311179, Gradient norm: 6.22847360
INFO:root:At the start of the epoch: mem (CPU python)=16537.1484375MB; mem (CPU total)=16222.55078125MB
INFO:root:[  120] Training loss: 0.40687815, Validation loss: 0.37223238, Gradient norm: 4.96693411
INFO:root:At the start of the epoch: mem (CPU python)=16558.3125MB; mem (CPU total)=16243.70703125MB
INFO:root:[  121] Training loss: 0.40727141, Validation loss: 0.37241878, Gradient norm: 6.69630026
INFO:root:At the start of the epoch: mem (CPU python)=16579.4765625MB; mem (CPU total)=16264.87109375MB
INFO:root:[  122] Training loss: 0.40820060, Validation loss: 0.37348098, Gradient norm: 6.44073191
INFO:root:At the start of the epoch: mem (CPU python)=16600.640625MB; mem (CPU total)=16286.0546875MB
INFO:root:[  123] Training loss: 0.40729744, Validation loss: 0.37186230, Gradient norm: 6.61976079
INFO:root:At the start of the epoch: mem (CPU python)=16621.8046875MB; mem (CPU total)=16307.21484375MB
INFO:root:[  124] Training loss: 0.40747252, Validation loss: 0.37245388, Gradient norm: 6.47738994
INFO:root:At the start of the epoch: mem (CPU python)=16643.03515625MB; mem (CPU total)=16329.109375MB
INFO:root:[  125] Training loss: 0.40737860, Validation loss: 0.37176910, Gradient norm: 6.36727751
INFO:root:At the start of the epoch: mem (CPU python)=16664.19921875MB; mem (CPU total)=16350.75390625MB
INFO:root:[  126] Training loss: 0.40766034, Validation loss: 0.37182065, Gradient norm: 6.43291982
INFO:root:At the start of the epoch: mem (CPU python)=16685.671875MB; mem (CPU total)=16371.89453125MB
INFO:root:[  127] Training loss: 0.40716361, Validation loss: 0.37193468, Gradient norm: 6.06137585
INFO:root:At the start of the epoch: mem (CPU python)=16706.8359375MB; mem (CPU total)=16392.9609375MB
INFO:root:EP 127: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=16728.0MB; mem (CPU total)=16414.35546875MB
INFO:root:[  129] Training loss: 0.49319025, Validation loss: 0.45149614, Gradient norm: 9.34431152
INFO:root:At the start of the epoch: mem (CPU python)=16749.54296875MB; mem (CPU total)=16436.07421875MB
INFO:root:[  130] Training loss: 0.49084203, Validation loss: 0.45006565, Gradient norm: 8.91383788
INFO:root:At the start of the epoch: mem (CPU python)=16770.70703125MB; mem (CPU total)=16457.109375MB
INFO:root:[  131] Training loss: 0.48947188, Validation loss: 0.44926917, Gradient norm: 8.63502669
INFO:root:At the start of the epoch: mem (CPU python)=16791.87109375MB; mem (CPU total)=16478.01953125MB
INFO:root:[  132] Training loss: 0.48925940, Validation loss: 0.45039718, Gradient norm: 8.59209672
INFO:root:At the start of the epoch: mem (CPU python)=16813.03515625MB; mem (CPU total)=16499.07421875MB
INFO:root:[  133] Training loss: 0.48880117, Validation loss: 0.44886687, Gradient norm: 9.43698768
INFO:root:At the start of the epoch: mem (CPU python)=16834.19921875MB; mem (CPU total)=16520.46875MB
INFO:root:[  134] Training loss: 0.48905581, Validation loss: 0.44854388, Gradient norm: 9.93569411
INFO:root:At the start of the epoch: mem (CPU python)=16855.359375MB; mem (CPU total)=16541.59375MB
INFO:root:[  135] Training loss: 0.48808724, Validation loss: 0.44792308, Gradient norm: 9.24598086
INFO:root:At the start of the epoch: mem (CPU python)=16876.52734375MB; mem (CPU total)=16562.73828125MB
INFO:root:[  136] Training loss: 0.48782083, Validation loss: 0.44726195, Gradient norm: 9.73738083
INFO:root:At the start of the epoch: mem (CPU python)=16897.69140625MB; mem (CPU total)=16584.16796875MB
INFO:root:[  137] Training loss: 0.48786796, Validation loss: 0.44813459, Gradient norm: 9.56085058
INFO:root:At the start of the epoch: mem (CPU python)=16918.85546875MB; mem (CPU total)=16605.30078125MB
INFO:root:[  138] Training loss: 0.48703996, Validation loss: 0.44811699, Gradient norm: 9.33487261
INFO:root:At the start of the epoch: mem (CPU python)=16940.01953125MB; mem (CPU total)=16626.703125MB
INFO:root:[  139] Training loss: 0.48731082, Validation loss: 0.44747882, Gradient norm: 9.51700490
INFO:root:At the start of the epoch: mem (CPU python)=16961.18359375MB; mem (CPU total)=16647.98828125MB
INFO:root:[  140] Training loss: 0.48772264, Validation loss: 0.44733715, Gradient norm: 10.09239735
INFO:root:At the start of the epoch: mem (CPU python)=16982.34765625MB; mem (CPU total)=16669.1328125MB
INFO:root:[  141] Training loss: 0.48732354, Validation loss: 0.44774813, Gradient norm: 10.25041678
INFO:root:At the start of the epoch: mem (CPU python)=17003.515625MB; mem (CPU total)=16690.28515625MB
INFO:root:[  142] Training loss: 0.48755305, Validation loss: 0.44663485, Gradient norm: 9.44933397
INFO:root:At the start of the epoch: mem (CPU python)=17024.6796875MB; mem (CPU total)=16711.72265625MB
INFO:root:[  143] Training loss: 0.48713013, Validation loss: 0.44739128, Gradient norm: 9.33837332
INFO:root:At the start of the epoch: mem (CPU python)=17045.84375MB; mem (CPU total)=16734.55078125MB
INFO:root:[  144] Training loss: 0.48735385, Validation loss: 0.44768354, Gradient norm: 9.81902232
INFO:root:At the start of the epoch: mem (CPU python)=17067.00390625MB; mem (CPU total)=16755.45703125MB
INFO:root:[  145] Training loss: 0.48697740, Validation loss: 0.44731492, Gradient norm: 9.48571669
INFO:root:At the start of the epoch: mem (CPU python)=17088.1640625MB; mem (CPU total)=16776.53515625MB
INFO:root:[  146] Training loss: 0.48750516, Validation loss: 0.44831148, Gradient norm: 11.03517104
INFO:root:At the start of the epoch: mem (CPU python)=17109.328125MB; mem (CPU total)=16797.67578125MB
INFO:root:[  147] Training loss: 0.48703047, Validation loss: 0.44638036, Gradient norm: 10.97736495
INFO:root:At the start of the epoch: mem (CPU python)=17130.49609375MB; mem (CPU total)=16819.06640625MB
INFO:root:[  148] Training loss: 0.48673226, Validation loss: 0.44702119, Gradient norm: 10.25615825
INFO:root:At the start of the epoch: mem (CPU python)=17151.66015625MB; mem (CPU total)=16840.23046875MB
INFO:root:[  149] Training loss: 0.48730804, Validation loss: 0.44763170, Gradient norm: 10.17757350
INFO:root:At the start of the epoch: mem (CPU python)=17172.82421875MB; mem (CPU total)=16861.57421875MB
INFO:root:[  150] Training loss: 0.48670689, Validation loss: 0.44641130, Gradient norm: 10.38466984
INFO:root:At the start of the epoch: mem (CPU python)=17193.98828125MB; mem (CPU total)=16882.7265625MB
INFO:root:[  151] Training loss: 0.48662265, Validation loss: 0.44701892, Gradient norm: 10.47765017
INFO:root:At the start of the epoch: mem (CPU python)=17215.15234375MB; mem (CPU total)=16904.1328125MB
INFO:root:[  152] Training loss: 0.48692143, Validation loss: 0.44677878, Gradient norm: 10.72477997
INFO:root:At the start of the epoch: mem (CPU python)=17236.3203125MB; mem (CPU total)=16925.296875MB
INFO:root:[  153] Training loss: 0.48676907, Validation loss: 0.44682928, Gradient norm: 10.42909775
INFO:root:At the start of the epoch: mem (CPU python)=17257.48046875MB; mem (CPU total)=16946.6953125MB
INFO:root:[  154] Training loss: 0.48675966, Validation loss: 0.44771221, Gradient norm: 11.14223143
INFO:root:At the start of the epoch: mem (CPU python)=17278.64453125MB; mem (CPU total)=16967.7890625MB
INFO:root:[  155] Training loss: 0.48650743, Validation loss: 0.44717976, Gradient norm: 12.02286219
INFO:root:At the start of the epoch: mem (CPU python)=17299.80859375MB; mem (CPU total)=16988.6875MB
INFO:root:[  156] Training loss: 0.48699343, Validation loss: 0.44655627, Gradient norm: 12.18022820
INFO:root:At the start of the epoch: mem (CPU python)=17320.97265625MB; mem (CPU total)=17009.60546875MB
INFO:root:[  157] Training loss: 0.48688377, Validation loss: 0.44636836, Gradient norm: 10.33292471
INFO:root:At the start of the epoch: mem (CPU python)=17342.140625MB; mem (CPU total)=17030.7421875MB
INFO:root:[  158] Training loss: 0.48647753, Validation loss: 0.44612212, Gradient norm: 10.83073912
INFO:root:At the start of the epoch: mem (CPU python)=17363.3046875MB; mem (CPU total)=17052.4296875MB
INFO:root:[  159] Training loss: 0.48685354, Validation loss: 0.44692254, Gradient norm: 10.91420986
INFO:root:At the start of the epoch: mem (CPU python)=17384.46875MB; mem (CPU total)=17073.57421875MB
INFO:root:[  160] Training loss: 0.48662557, Validation loss: 0.44650995, Gradient norm: 10.84905246
INFO:root:At the start of the epoch: mem (CPU python)=17405.6328125MB; mem (CPU total)=17094.72265625MB
INFO:root:[  161] Training loss: 0.48583762, Validation loss: 0.44625454, Gradient norm: 12.12212896
INFO:root:At the start of the epoch: mem (CPU python)=17426.796875MB; mem (CPU total)=17116.26171875MB
INFO:root:[  162] Training loss: 0.48600644, Validation loss: 0.44604306, Gradient norm: 10.80049462
INFO:root:At the start of the epoch: mem (CPU python)=17447.9609375MB; mem (CPU total)=17137.40234375MB
INFO:root:[  163] Training loss: 0.48677559, Validation loss: 0.44632462, Gradient norm: 11.41262017
INFO:root:At the start of the epoch: mem (CPU python)=17469.1171875MB; mem (CPU total)=17158.796875MB
INFO:root:[  164] Training loss: 0.48651958, Validation loss: 0.44618642, Gradient norm: 12.80073305
INFO:root:At the start of the epoch: mem (CPU python)=17490.28125MB; mem (CPU total)=17182.04296875MB
INFO:root:[  165] Training loss: 0.48661109, Validation loss: 0.44608067, Gradient norm: 12.40202762
INFO:root:At the start of the epoch: mem (CPU python)=17511.44921875MB; mem (CPU total)=17202.9140625MB
INFO:root:[  166] Training loss: 0.48657062, Validation loss: 0.44604627, Gradient norm: 11.94051716
INFO:root:At the start of the epoch: mem (CPU python)=17532.61328125MB; mem (CPU total)=17223.81640625MB
INFO:root:[  167] Training loss: 0.48632389, Validation loss: 0.44606211, Gradient norm: 12.86357423
INFO:root:At the start of the epoch: mem (CPU python)=17553.77734375MB; mem (CPU total)=17244.83984375MB
INFO:root:[  168] Training loss: 0.48699647, Validation loss: 0.44613420, Gradient norm: 11.59339041
INFO:root:At the start of the epoch: mem (CPU python)=17574.94140625MB; mem (CPU total)=17266.0MB
INFO:root:[  169] Training loss: 0.48623064, Validation loss: 0.44618924, Gradient norm: 12.54134609
INFO:root:At the start of the epoch: mem (CPU python)=17596.109375MB; mem (CPU total)=17287.390625MB
INFO:root:[  170] Training loss: 0.48634937, Validation loss: 0.44557316, Gradient norm: 11.96509447
INFO:root:At the start of the epoch: mem (CPU python)=17617.2734375MB; mem (CPU total)=17309.32421875MB
INFO:root:[  171] Training loss: 0.48618877, Validation loss: 0.44604678, Gradient norm: 12.69278942
INFO:root:At the start of the epoch: mem (CPU python)=17638.4375MB; mem (CPU total)=17330.53515625MB
INFO:root:[  172] Training loss: 0.48626817, Validation loss: 0.44560595, Gradient norm: 12.89296047
INFO:root:At the start of the epoch: mem (CPU python)=17659.6015625MB; mem (CPU total)=17351.44921875MB
INFO:root:[  173] Training loss: 0.48630617, Validation loss: 0.44574797, Gradient norm: 12.28916237
INFO:root:At the start of the epoch: mem (CPU python)=17680.765625MB; mem (CPU total)=17570.34765625MB
INFO:root:[  174] Training loss: 0.48616123, Validation loss: 0.44559322, Gradient norm: 12.75285234
INFO:root:At the start of the epoch: mem (CPU python)=17701.9296875MB; mem (CPU total)=17588.97265625MB
INFO:root:[  175] Training loss: 0.48608706, Validation loss: 0.44562147, Gradient norm: 13.86073141
INFO:root:At the start of the epoch: mem (CPU python)=17723.09765625MB; mem (CPU total)=17417.69921875MB
INFO:root:[  176] Training loss: 0.48578978, Validation loss: 0.44558471, Gradient norm: 13.11480926
INFO:root:At the start of the epoch: mem (CPU python)=17744.26171875MB; mem (CPU total)=17563.66796875MB
INFO:root:[  177] Training loss: 0.48602410, Validation loss: 0.44616303, Gradient norm: 13.48437943
INFO:root:At the start of the epoch: mem (CPU python)=17765.42578125MB; mem (CPU total)=17459.4609375MB
INFO:root:[  178] Training loss: 0.48625703, Validation loss: 0.44645777, Gradient norm: 13.45127433
INFO:root:At the start of the epoch: mem (CPU python)=17786.58984375MB; mem (CPU total)=17480.3671875MB
INFO:root:[  179] Training loss: 0.48627833, Validation loss: 0.44714528, Gradient norm: 13.13950561
INFO:root:At the start of the epoch: mem (CPU python)=17807.75MB; mem (CPU total)=17502.37890625MB
INFO:root:EP 179: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=17828.91796875MB; mem (CPU total)=17733.4765625MB
INFO:root:Training the model took 6669.043s.
INFO:root:Emptying the cuda cache took 0.062s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8064
INFO:root:EnergyScoreValidation: 0.43778
INFO:root:CRPSValidation: 0.20098
INFO:root:Gaussian NLLValidation: 5.96227
INFO:root:CoverageValidation: 0.63309
INFO:root:IntervalWidthValidation: 0.96793
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.76188
INFO:root:EnergyScoreTest: 0.4024
INFO:root:CRPSTest: 0.18719
INFO:root:Gaussian NLLTest: 4.6325
INFO:root:CoverageTest: 0.67565
INFO:root:IntervalWidthTest: 1.03245
INFO:root:After validation: mem (CPU python)=17868.0MB; mem (CPU total)=17514.68359375MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=17868.0MB; mem (CPU total)=17514.46875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 346030080
INFO:root:After setting up the model: mem (CPU python)=17868.0MB; mem (CPU total)=17536.71484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=17868.0MB; mem (CPU total)=17537.97265625MB
INFO:root:[    1] Training loss: 0.84672186, Validation loss: 0.73706373, Gradient norm: 0.42380271
INFO:root:At the start of the epoch: mem (CPU python)=17868.0MB; mem (CPU total)=17558.58984375MB
INFO:root:[    2] Training loss: 0.74547741, Validation loss: 0.73748162, Gradient norm: 0.43665544
INFO:root:At the start of the epoch: mem (CPU python)=17885.921875MB; mem (CPU total)=17579.765625MB
INFO:root:[    3] Training loss: 0.73876069, Validation loss: 0.72074134, Gradient norm: 0.52610141
INFO:root:At the start of the epoch: mem (CPU python)=17907.08203125MB; mem (CPU total)=17600.58203125MB
INFO:root:[    4] Training loss: 0.72428624, Validation loss: 0.70732441, Gradient norm: 0.75740335
INFO:root:At the start of the epoch: mem (CPU python)=17928.24609375MB; mem (CPU total)=17886.86328125MB
INFO:root:[    5] Training loss: 0.69221966, Validation loss: 0.67164614, Gradient norm: 0.96301877
INFO:root:At the start of the epoch: mem (CPU python)=17949.41015625MB; mem (CPU total)=19808.1953125MB
INFO:root:[    6] Training loss: 0.65961597, Validation loss: 0.62850475, Gradient norm: 1.39481851
INFO:root:At the start of the epoch: mem (CPU python)=17970.57421875MB; mem (CPU total)=19829.34765625MB
INFO:root:[    7] Training loss: 0.62943557, Validation loss: 0.58558475, Gradient norm: 1.43705551
INFO:root:At the start of the epoch: mem (CPU python)=17991.73828125MB; mem (CPU total)=19850.69921875MB
INFO:root:[    8] Training loss: 0.61545037, Validation loss: 0.57410335, Gradient norm: 1.68459488
INFO:root:At the start of the epoch: mem (CPU python)=18012.90234375MB; mem (CPU total)=19871.79296875MB
INFO:root:[    9] Training loss: 0.60155112, Validation loss: 0.56379669, Gradient norm: 1.59747321
INFO:root:At the start of the epoch: mem (CPU python)=18034.06640625MB; mem (CPU total)=19894.23828125MB
INFO:root:[   10] Training loss: 0.59499336, Validation loss: 0.56005715, Gradient norm: 2.14652428
INFO:root:At the start of the epoch: mem (CPU python)=18055.234375MB; mem (CPU total)=17750.484375MB
INFO:root:[   11] Training loss: 0.58843904, Validation loss: 0.54357372, Gradient norm: 2.22198784
INFO:root:At the start of the epoch: mem (CPU python)=18076.3984375MB; mem (CPU total)=17771.8515625MB
INFO:root:[   12] Training loss: 0.58192297, Validation loss: 0.54703340, Gradient norm: 2.57941102
INFO:root:At the start of the epoch: mem (CPU python)=18097.5625MB; mem (CPU total)=17792.98046875MB
INFO:root:[   13] Training loss: 0.56772168, Validation loss: 0.52173292, Gradient norm: 2.43680172
INFO:root:At the start of the epoch: mem (CPU python)=18118.72265625MB; mem (CPU total)=17814.51171875MB
INFO:root:[   14] Training loss: 0.56669420, Validation loss: 0.53150971, Gradient norm: 2.61413460
INFO:root:At the start of the epoch: mem (CPU python)=18139.88671875MB; mem (CPU total)=17835.67578125MB
INFO:root:[   15] Training loss: 0.56035187, Validation loss: 0.50673891, Gradient norm: 3.04304955
INFO:root:At the start of the epoch: mem (CPU python)=18161.0546875MB; mem (CPU total)=17858.33203125MB
INFO:root:[   16] Training loss: 0.55819870, Validation loss: 0.50955887, Gradient norm: 3.41246771
INFO:root:At the start of the epoch: mem (CPU python)=18182.21875MB; mem (CPU total)=17879.25MB
INFO:root:[   17] Training loss: 0.55587443, Validation loss: 0.51874812, Gradient norm: 3.46568814
INFO:root:At the start of the epoch: mem (CPU python)=18203.3828125MB; mem (CPU total)=17900.16015625MB
INFO:root:[   18] Training loss: 0.55099042, Validation loss: 0.50973471, Gradient norm: 3.84636951
INFO:root:At the start of the epoch: mem (CPU python)=18224.546875MB; mem (CPU total)=17921.29296875MB
INFO:root:[   19] Training loss: 0.55472864, Validation loss: 0.52234110, Gradient norm: 3.85123347
INFO:root:At the start of the epoch: mem (CPU python)=18245.7109375MB; mem (CPU total)=18207.94921875MB
INFO:root:[   20] Training loss: 0.55281106, Validation loss: 0.49673856, Gradient norm: 3.67163952
INFO:root:At the start of the epoch: mem (CPU python)=18266.87890625MB; mem (CPU total)=20126.9140625MB
INFO:root:[   21] Training loss: 0.55715829, Validation loss: 0.51709452, Gradient norm: 4.15768929
INFO:root:At the start of the epoch: mem (CPU python)=18288.03515625MB; mem (CPU total)=20163.8125MB
INFO:root:[   22] Training loss: 0.54821804, Validation loss: 0.49881462, Gradient norm: 3.98242881
INFO:root:At the start of the epoch: mem (CPU python)=18309.19921875MB; mem (CPU total)=20183.73046875MB
INFO:root:[   23] Training loss: 0.55290338, Validation loss: 0.52003385, Gradient norm: 4.26691524
INFO:root:At the start of the epoch: mem (CPU python)=18330.36328125MB; mem (CPU total)=20210.4453125MB
INFO:root:[   24] Training loss: 0.55316595, Validation loss: 0.51598589, Gradient norm: 4.30939523
INFO:root:At the start of the epoch: mem (CPU python)=18351.52734375MB; mem (CPU total)=20226.1171875MB
INFO:root:[   25] Training loss: 0.54647649, Validation loss: 0.49384235, Gradient norm: 4.75720260
INFO:root:At the start of the epoch: mem (CPU python)=18373.24609375MB; mem (CPU total)=20246.890625MB
INFO:root:[   26] Training loss: 0.54524953, Validation loss: 0.51777815, Gradient norm: 4.73827705
INFO:root:At the start of the epoch: mem (CPU python)=18394.41015625MB; mem (CPU total)=20274.48828125MB
INFO:root:[   27] Training loss: 0.54976382, Validation loss: 0.52456069, Gradient norm: 5.12780088
INFO:root:At the start of the epoch: mem (CPU python)=18416.1484375MB; mem (CPU total)=20287.22265625MB
INFO:root:[   28] Training loss: 0.55302677, Validation loss: 0.50289834, Gradient norm: 4.76354690
INFO:root:At the start of the epoch: mem (CPU python)=18437.3125MB; mem (CPU total)=20314.94921875MB
INFO:root:[   29] Training loss: 0.54716191, Validation loss: 0.51038893, Gradient norm: 5.25580965
INFO:root:At the start of the epoch: mem (CPU python)=18458.4765625MB; mem (CPU total)=20339.99609375MB
INFO:root:[   30] Training loss: 0.54178518, Validation loss: 0.52153908, Gradient norm: 4.68747115
INFO:root:At the start of the epoch: mem (CPU python)=18479.64453125MB; mem (CPU total)=20358.8515625MB
INFO:root:[   31] Training loss: 0.54340863, Validation loss: 0.52479631, Gradient norm: 5.20114010
INFO:root:At the start of the epoch: mem (CPU python)=18500.8046875MB; mem (CPU total)=20378.7109375MB
INFO:root:[   32] Training loss: 0.54445164, Validation loss: 0.50390271, Gradient norm: 4.93094868
INFO:root:At the start of the epoch: mem (CPU python)=18521.96875MB; mem (CPU total)=20403.93359375MB
INFO:root:[   33] Training loss: 0.53918896, Validation loss: 0.51091406, Gradient norm: 4.83947033
INFO:root:At the start of the epoch: mem (CPU python)=18543.1328125MB; mem (CPU total)=20423.3984375MB
INFO:root:[   34] Training loss: 0.53447984, Validation loss: 0.48159716, Gradient norm: 4.74073090
INFO:root:At the start of the epoch: mem (CPU python)=18564.296875MB; mem (CPU total)=18260.27734375MB
INFO:root:[   35] Training loss: 0.53647980, Validation loss: 0.50303637, Gradient norm: 5.01359319
INFO:root:At the start of the epoch: mem (CPU python)=18585.4609375MB; mem (CPU total)=18281.43359375MB
INFO:root:[   36] Training loss: 0.53993294, Validation loss: 0.48958671, Gradient norm: 5.23933865
INFO:root:At the start of the epoch: mem (CPU python)=18606.625MB; mem (CPU total)=18302.59375MB
INFO:root:[   37] Training loss: 0.53589000, Validation loss: 0.50393099, Gradient norm: 4.70764701
INFO:root:At the start of the epoch: mem (CPU python)=18627.7890625MB; mem (CPU total)=18324.25390625MB
INFO:root:[   38] Training loss: 0.53508501, Validation loss: 0.51355223, Gradient norm: 4.96125305
INFO:root:At the start of the epoch: mem (CPU python)=18648.953125MB; mem (CPU total)=18345.1640625MB
INFO:root:[   39] Training loss: 0.53208613, Validation loss: 0.49195930, Gradient norm: 5.36644940
INFO:root:At the start of the epoch: mem (CPU python)=18670.1171875MB; mem (CPU total)=18366.58203125MB
INFO:root:[   40] Training loss: 0.53723432, Validation loss: 0.51318648, Gradient norm: 4.96836622
INFO:root:At the start of the epoch: mem (CPU python)=18691.28125MB; mem (CPU total)=18388.984375MB
INFO:root:[   41] Training loss: 0.53495390, Validation loss: 0.50617347, Gradient norm: 5.32827498
INFO:root:At the start of the epoch: mem (CPU python)=18712.44140625MB; mem (CPU total)=18408.921875MB
INFO:root:[   42] Training loss: 0.53211676, Validation loss: 0.49577569, Gradient norm: 5.07630736
INFO:root:At the start of the epoch: mem (CPU python)=18733.609375MB; mem (CPU total)=18430.75MB
INFO:root:[   43] Training loss: 0.53073920, Validation loss: 0.48522128, Gradient norm: 4.82570029
INFO:root:At the start of the epoch: mem (CPU python)=18754.7734375MB; mem (CPU total)=18451.890625MB
INFO:root:[   44] Training loss: 0.53224214, Validation loss: 0.48799163, Gradient norm: 5.52170498
INFO:root:At the start of the epoch: mem (CPU python)=18776.2890625MB; mem (CPU total)=18473.80078125MB
INFO:root:[   45] Training loss: 0.53060271, Validation loss: 0.50992373, Gradient norm: 5.45505474
INFO:root:At the start of the epoch: mem (CPU python)=18797.8515625MB; mem (CPU total)=18494.6796875MB
INFO:root:[   46] Training loss: 0.53882115, Validation loss: 0.50291959, Gradient norm: 5.41997088
INFO:root:At the start of the epoch: mem (CPU python)=18819.015625MB; mem (CPU total)=18515.63671875MB
INFO:root:[   47] Training loss: 0.53185800, Validation loss: 0.47600089, Gradient norm: 5.43388155
INFO:root:At the start of the epoch: mem (CPU python)=18840.18359375MB; mem (CPU total)=18536.390625MB
INFO:root:[   48] Training loss: 0.53216042, Validation loss: 0.48279194, Gradient norm: 5.15410958
INFO:root:At the start of the epoch: mem (CPU python)=18861.37890625MB; mem (CPU total)=18557.80078125MB
INFO:root:[   49] Training loss: 0.53025926, Validation loss: 0.49161365, Gradient norm: 5.31726438
INFO:root:At the start of the epoch: mem (CPU python)=18882.54296875MB; mem (CPU total)=18578.96484375MB
INFO:root:[   50] Training loss: 0.52458378, Validation loss: 0.50351782, Gradient norm: 4.85801174
INFO:root:At the start of the epoch: mem (CPU python)=18904.046875MB; mem (CPU total)=18600.0234375MB
INFO:root:[   51] Training loss: 0.52806944, Validation loss: 0.50061776, Gradient norm: 5.56637438
INFO:root:At the start of the epoch: mem (CPU python)=18925.2109375MB; mem (CPU total)=18621.1875MB
INFO:root:[   52] Training loss: 0.52867373, Validation loss: 0.50915010, Gradient norm: 5.15442608
INFO:root:At the start of the epoch: mem (CPU python)=18946.375MB; mem (CPU total)=18642.3828125MB
INFO:root:[   53] Training loss: 0.53009024, Validation loss: 0.48782014, Gradient norm: 6.15469693
INFO:root:At the start of the epoch: mem (CPU python)=18967.69921875MB; mem (CPU total)=18664.0234375MB
INFO:root:[   54] Training loss: 0.53140160, Validation loss: 0.47997671, Gradient norm: 5.53343500
INFO:root:At the start of the epoch: mem (CPU python)=18988.9921875MB; mem (CPU total)=18685.41796875MB
INFO:root:[   55] Training loss: 0.52659064, Validation loss: 0.48548631, Gradient norm: 5.52098912
INFO:root:At the start of the epoch: mem (CPU python)=19010.6171875MB; mem (CPU total)=18706.546875MB
INFO:root:[   56] Training loss: 0.53395206, Validation loss: 0.47512918, Gradient norm: 5.94151422
INFO:root:At the start of the epoch: mem (CPU python)=19031.875MB; mem (CPU total)=18728.62109375MB
INFO:root:[   57] Training loss: 0.52392335, Validation loss: 0.46433870, Gradient norm: 5.26944607
INFO:root:At the start of the epoch: mem (CPU python)=19053.04296875MB; mem (CPU total)=18749.84765625MB
INFO:root:[   58] Training loss: 0.52685682, Validation loss: 0.50944581, Gradient norm: 5.69692862
INFO:root:At the start of the epoch: mem (CPU python)=19074.484375MB; mem (CPU total)=18771.0078125MB
INFO:root:[   59] Training loss: 0.53615548, Validation loss: 0.50981256, Gradient norm: 6.42236467
INFO:root:At the start of the epoch: mem (CPU python)=19095.65234375MB; mem (CPU total)=18791.2265625MB
INFO:root:[   60] Training loss: 0.52637846, Validation loss: 0.48432740, Gradient norm: 5.08201264
INFO:root:At the start of the epoch: mem (CPU python)=19116.8125MB; mem (CPU total)=18812.265625MB
INFO:root:[   61] Training loss: 0.52687792, Validation loss: 0.50537797, Gradient norm: 6.36366511
INFO:root:At the start of the epoch: mem (CPU python)=19137.9765625MB; mem (CPU total)=18833.65625MB
INFO:root:[   62] Training loss: 0.52558190, Validation loss: 0.50017556, Gradient norm: 5.75200719
INFO:root:At the start of the epoch: mem (CPU python)=19161.25MB; mem (CPU total)=18857.5MB
INFO:root:[   63] Training loss: 0.53099868, Validation loss: 0.49701632, Gradient norm: 6.08823015
INFO:root:At the start of the epoch: mem (CPU python)=19182.9296875MB; mem (CPU total)=21055.44921875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   64] Training loss: 0.52966835, Validation loss: 0.48338888, Gradient norm: 5.75562479
INFO:root:At the start of the epoch: mem (CPU python)=19204.09765625MB; mem (CPU total)=21091.5390625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   65] Training loss: 0.50115216, Validation loss: 0.44702959, Gradient norm: 4.10310848
INFO:root:At the start of the epoch: mem (CPU python)=19225.26171875MB; mem (CPU total)=21111.29296875MB
INFO:root:[   66] Training loss: 0.48378951, Validation loss: 0.44259867, Gradient norm: 3.61414142
INFO:root:At the start of the epoch: mem (CPU python)=19246.42578125MB; mem (CPU total)=21160.32421875MB
INFO:root:[   67] Training loss: 0.48395874, Validation loss: 0.44185478, Gradient norm: 4.38795678
INFO:root:At the start of the epoch: mem (CPU python)=19267.59375MB; mem (CPU total)=18965.140625MB
INFO:root:[   68] Training loss: 0.48476923, Validation loss: 0.44392168, Gradient norm: 5.21528896
INFO:root:At the start of the epoch: mem (CPU python)=19288.7578125MB; mem (CPU total)=21141.33984375MB
INFO:root:[   69] Training loss: 0.48434684, Validation loss: 0.44065873, Gradient norm: 5.77221472
INFO:root:At the start of the epoch: mem (CPU python)=19309.921875MB; mem (CPU total)=19007.7578125MB
INFO:root:[   70] Training loss: 0.48835346, Validation loss: 0.46034140, Gradient norm: 7.00560259
INFO:root:At the start of the epoch: mem (CPU python)=19331.0859375MB; mem (CPU total)=21201.70703125MB
INFO:root:[   71] Training loss: 0.49283046, Validation loss: 0.44402386, Gradient norm: 8.48340411
INFO:root:At the start of the epoch: mem (CPU python)=19352.24609375MB; mem (CPU total)=21222.87109375MB
INFO:root:[   72] Training loss: 0.48725137, Validation loss: 0.44254495, Gradient norm: 6.82678786
INFO:root:At the start of the epoch: mem (CPU python)=19373.41015625MB; mem (CPU total)=21243.9921875MB
INFO:root:[   73] Training loss: 0.48600178, Validation loss: 0.44329517, Gradient norm: 7.48002274
INFO:root:At the start of the epoch: mem (CPU python)=19394.57421875MB; mem (CPU total)=21265.1484375MB
INFO:root:[   74] Training loss: 0.48614978, Validation loss: 0.44236888, Gradient norm: 7.76462086
INFO:root:At the start of the epoch: mem (CPU python)=19415.73828125MB; mem (CPU total)=21333.60546875MB
INFO:root:[   75] Training loss: 0.48668911, Validation loss: 0.44053468, Gradient norm: 8.42335472
INFO:root:At the start of the epoch: mem (CPU python)=19436.92578125MB; mem (CPU total)=19135.49609375MB
INFO:root:[   76] Training loss: 0.48644099, Validation loss: 0.44711373, Gradient norm: 8.41818434
INFO:root:At the start of the epoch: mem (CPU python)=19458.08984375MB; mem (CPU total)=19156.83203125MB
INFO:root:[   77] Training loss: 0.48827466, Validation loss: 0.44578451, Gradient norm: 8.74310661
INFO:root:At the start of the epoch: mem (CPU python)=19479.609375MB; mem (CPU total)=19177.7421875MB
INFO:root:[   78] Training loss: 0.48752784, Validation loss: 0.44272130, Gradient norm: 9.77728121
INFO:root:At the start of the epoch: mem (CPU python)=19500.76953125MB; mem (CPU total)=19198.90234375MB
INFO:root:[   79] Training loss: 0.48875373, Validation loss: 0.46017230, Gradient norm: 9.45494478
INFO:root:At the start of the epoch: mem (CPU python)=19521.93359375MB; mem (CPU total)=19220.046875MB
INFO:root:[   80] Training loss: 0.48945482, Validation loss: 0.43761643, Gradient norm: 10.74218250
INFO:root:At the start of the epoch: mem (CPU python)=19543.1015625MB; mem (CPU total)=19241.21875MB
INFO:root:[   81] Training loss: 0.49043758, Validation loss: 0.44686674, Gradient norm: 11.20033940
INFO:root:At the start of the epoch: mem (CPU python)=19564.8125MB; mem (CPU total)=19525.3046875MB
INFO:root:[   82] Training loss: 0.49204649, Validation loss: 0.44586894, Gradient norm: 10.99766690
INFO:root:At the start of the epoch: mem (CPU python)=19586.5546875MB; mem (CPU total)=21450.4765625MB
INFO:root:[   83] Training loss: 0.48994367, Validation loss: 0.44498314, Gradient norm: 11.84554460
INFO:root:At the start of the epoch: mem (CPU python)=19607.71875MB; mem (CPU total)=21483.265625MB
INFO:root:[   84] Training loss: 0.49289903, Validation loss: 0.44754700, Gradient norm: 12.39791751
INFO:root:At the start of the epoch: mem (CPU python)=19628.8828125MB; mem (CPU total)=21504.2734375MB
INFO:root:[   85] Training loss: 0.48857457, Validation loss: 0.45000253, Gradient norm: 11.89578973
INFO:root:At the start of the epoch: mem (CPU python)=19650.2890625MB; mem (CPU total)=21528.87890625MB
INFO:root:[   86] Training loss: 0.49165615, Validation loss: 0.44682480, Gradient norm: 12.84170973
INFO:root:At the start of the epoch: mem (CPU python)=19671.58203125MB; mem (CPU total)=21544.8203125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   87] Training loss: 0.49543032, Validation loss: 0.44711904, Gradient norm: 13.28265292
INFO:root:At the start of the epoch: mem (CPU python)=19693.12890625MB; mem (CPU total)=21576.46875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   88] Training loss: 0.48168991, Validation loss: 0.43532039, Gradient norm: 8.69424459
INFO:root:At the start of the epoch: mem (CPU python)=19714.2890625MB; mem (CPU total)=21589.91796875MB
INFO:root:[   89] Training loss: 0.47649946, Validation loss: 0.43022047, Gradient norm: 6.11138284
INFO:root:At the start of the epoch: mem (CPU python)=19735.453125MB; mem (CPU total)=21610.80859375MB
INFO:root:[   90] Training loss: 0.47663207, Validation loss: 0.43008023, Gradient norm: 7.65002894
INFO:root:At the start of the epoch: mem (CPU python)=19756.61328125MB; mem (CPU total)=21632.0234375MB
INFO:root:[   91] Training loss: 0.47575428, Validation loss: 0.42952956, Gradient norm: 7.91872425
INFO:root:At the start of the epoch: mem (CPU python)=19777.77734375MB; mem (CPU total)=21651.43359375MB
INFO:root:[   92] Training loss: 0.47607611, Validation loss: 0.42963688, Gradient norm: 8.35660535
INFO:root:At the start of the epoch: mem (CPU python)=19798.94140625MB; mem (CPU total)=21682.84765625MB
INFO:root:[   93] Training loss: 0.47616057, Validation loss: 0.43173528, Gradient norm: 9.09350197
INFO:root:At the start of the epoch: mem (CPU python)=19820.109375MB; mem (CPU total)=21694.19921875MB
INFO:root:[   94] Training loss: 0.47987040, Validation loss: 0.43053337, Gradient norm: 14.56570442
INFO:root:At the start of the epoch: mem (CPU python)=19841.2734375MB; mem (CPU total)=21714.94921875MB
INFO:root:[   95] Training loss: 0.47726740, Validation loss: 0.42892922, Gradient norm: 10.43956769
INFO:root:At the start of the epoch: mem (CPU python)=19862.4375MB; mem (CPU total)=21736.5859375MB
INFO:root:[   96] Training loss: 0.47686856, Validation loss: 0.43072324, Gradient norm: 10.39955376
INFO:root:At the start of the epoch: mem (CPU python)=19883.6015625MB; mem (CPU total)=21757.77734375MB
INFO:root:[   97] Training loss: 0.48030444, Validation loss: 0.43315443, Gradient norm: 15.65403731
INFO:root:At the start of the epoch: mem (CPU python)=19905.0078125MB; mem (CPU total)=21789.39453125MB
INFO:root:[   98] Training loss: 0.47874214, Validation loss: 0.43030706, Gradient norm: 13.44180103
INFO:root:At the start of the epoch: mem (CPU python)=19926.6796875MB; mem (CPU total)=21806.9296875MB
INFO:root:[   99] Training loss: 0.47691476, Validation loss: 0.43130131, Gradient norm: 11.28018943
INFO:root:At the start of the epoch: mem (CPU python)=19947.84375MB; mem (CPU total)=21821.96875MB
INFO:root:[  100] Training loss: 0.47743554, Validation loss: 0.43092758, Gradient norm: 13.28341310
INFO:root:At the start of the epoch: mem (CPU python)=19969.0078125MB; mem (CPU total)=21851.6484375MB
INFO:root:[  101] Training loss: 0.47689364, Validation loss: 0.43028115, Gradient norm: 12.79974280
INFO:root:At the start of the epoch: mem (CPU python)=19990.171875MB; mem (CPU total)=21866.2265625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  102] Training loss: 0.47707327, Validation loss: 0.42940285, Gradient norm: 13.64238053
INFO:root:At the start of the epoch: mem (CPU python)=20011.33984375MB; mem (CPU total)=21897.12109375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  103] Training loss: 0.47463300, Validation loss: 0.42770537, Gradient norm: 8.57321589
INFO:root:At the start of the epoch: mem (CPU python)=20032.50390625MB; mem (CPU total)=21914.9296875MB
INFO:root:[  104] Training loss: 0.47338829, Validation loss: 0.42609428, Gradient norm: 6.42187276
INFO:root:At the start of the epoch: mem (CPU python)=20053.75390625MB; mem (CPU total)=21931.9609375MB
INFO:root:[  105] Training loss: 0.47342301, Validation loss: 0.42612982, Gradient norm: 7.52419364
INFO:root:At the start of the epoch: mem (CPU python)=20075.20703125MB; mem (CPU total)=21956.59765625MB
INFO:root:[  106] Training loss: 0.47277104, Validation loss: 0.42649421, Gradient norm: 6.93566511
INFO:root:At the start of the epoch: mem (CPU python)=20096.37109375MB; mem (CPU total)=21972.546875MB
INFO:root:[  107] Training loss: 0.47285918, Validation loss: 0.42665192, Gradient norm: 8.18740804
INFO:root:At the start of the epoch: mem (CPU python)=20118.06640625MB; mem (CPU total)=22001.0390625MB
INFO:root:[  108] Training loss: 0.47328910, Validation loss: 0.42590594, Gradient norm: 7.09757012
INFO:root:At the start of the epoch: mem (CPU python)=20139.234375MB; mem (CPU total)=22026.7265625MB
INFO:root:[  109] Training loss: 0.47327906, Validation loss: 0.42609023, Gradient norm: 8.22569146
INFO:root:At the start of the epoch: mem (CPU python)=20160.98828125MB; mem (CPU total)=22047.84765625MB
INFO:root:[  110] Training loss: 0.47283936, Validation loss: 0.42696531, Gradient norm: 9.69898205
INFO:root:At the start of the epoch: mem (CPU python)=20182.15625MB; mem (CPU total)=22065.25MB
INFO:root:[  111] Training loss: 0.47277240, Validation loss: 0.42660189, Gradient norm: 8.89276351
INFO:root:At the start of the epoch: mem (CPU python)=20203.3203125MB; mem (CPU total)=22081.55078125MB
INFO:root:[  112] Training loss: 0.47274224, Validation loss: 0.42731659, Gradient norm: 8.41277966
INFO:root:At the start of the epoch: mem (CPU python)=20224.484375MB; mem (CPU total)=22106.75MB
INFO:root:[  113] Training loss: 0.47261358, Validation loss: 0.42643098, Gradient norm: 9.61769946
INFO:root:At the start of the epoch: mem (CPU python)=20245.6484375MB; mem (CPU total)=22121.515625MB
INFO:root:[  114] Training loss: 0.47270575, Validation loss: 0.42643640, Gradient norm: 9.73222887
INFO:root:At the start of the epoch: mem (CPU python)=20266.81640625MB; mem (CPU total)=22152.63671875MB
INFO:root:[  115] Training loss: 0.47287971, Validation loss: 0.42582058, Gradient norm: 9.13224978
INFO:root:At the start of the epoch: mem (CPU python)=20287.98046875MB; mem (CPU total)=22164.32421875MB
INFO:root:[  116] Training loss: 0.47340657, Validation loss: 0.42651051, Gradient norm: 9.23038724
INFO:root:At the start of the epoch: mem (CPU python)=20309.140625MB; mem (CPU total)=22185.44140625MB
INFO:root:[  117] Training loss: 0.47307218, Validation loss: 0.42648852, Gradient norm: 11.59749772
INFO:root:At the start of the epoch: mem (CPU python)=20330.3046875MB; mem (CPU total)=22207.65234375MB
INFO:root:[  118] Training loss: 0.47312023, Validation loss: 0.42621563, Gradient norm: 13.23858458
INFO:root:At the start of the epoch: mem (CPU python)=20351.46875MB; mem (CPU total)=22229.53125MB
INFO:root:[  119] Training loss: 0.47379819, Validation loss: 0.42940537, Gradient norm: 12.94988719
INFO:root:At the start of the epoch: mem (CPU python)=20372.63671875MB; mem (CPU total)=22258.9375MB
INFO:root:[  120] Training loss: 0.47286353, Validation loss: 0.42623889, Gradient norm: 11.36510433
INFO:root:At the start of the epoch: mem (CPU python)=20393.80078125MB; mem (CPU total)=22278.13671875MB
INFO:root:[  121] Training loss: 0.47370748, Validation loss: 0.42785691, Gradient norm: 12.78932021
INFO:root:At the start of the epoch: mem (CPU python)=20415.1796875MB; mem (CPU total)=22299.7265625MB
INFO:root:[  122] Training loss: 0.47356684, Validation loss: 0.42713572, Gradient norm: 10.84656735
INFO:root:At the start of the epoch: mem (CPU python)=20436.33984375MB; mem (CPU total)=22312.9296875MB
INFO:root:[  123] Training loss: 0.47304230, Validation loss: 0.42634784, Gradient norm: 11.97850164
INFO:root:At the start of the epoch: mem (CPU python)=20457.6640625MB; mem (CPU total)=22334.97265625MB
INFO:root:[  124] Training loss: 0.47371066, Validation loss: 0.42675710, Gradient norm: 12.97704387
INFO:root:At the start of the epoch: mem (CPU python)=20479.109375MB; mem (CPU total)=22360.3359375MB
INFO:root:EP 124: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=20500.26953125MB; mem (CPU total)=22378.28515625MB
INFO:root:[  126] Training loss: 0.55981630, Validation loss: 0.50926967, Gradient norm: 17.57560911
INFO:root:At the start of the epoch: mem (CPU python)=20521.90234375MB; mem (CPU total)=22401.50390625MB
INFO:root:[  127] Training loss: 0.55772448, Validation loss: 0.50703704, Gradient norm: 17.25704651
INFO:root:At the start of the epoch: mem (CPU python)=20543.06640625MB; mem (CPU total)=22422.4921875MB
INFO:root:[  128] Training loss: 0.55787248, Validation loss: 0.50759356, Gradient norm: 15.93052200
INFO:root:At the start of the epoch: mem (CPU python)=20564.23046875MB; mem (CPU total)=22442.42578125MB
INFO:root:[  129] Training loss: 0.55689455, Validation loss: 0.50692395, Gradient norm: 15.61896825
INFO:root:At the start of the epoch: mem (CPU python)=20585.3984375MB; mem (CPU total)=22507.97265625MB
INFO:root:[  130] Training loss: 0.55672688, Validation loss: 0.50602645, Gradient norm: 15.86123938
INFO:root:At the start of the epoch: mem (CPU python)=20606.5625MB; mem (CPU total)=20307.83203125MB
INFO:root:[  131] Training loss: 0.55666658, Validation loss: 0.50655859, Gradient norm: 14.81522287
INFO:root:At the start of the epoch: mem (CPU python)=20627.7265625MB; mem (CPU total)=20328.96484375MB
INFO:root:[  132] Training loss: 0.55628582, Validation loss: 0.50603688, Gradient norm: 15.75135518
INFO:root:At the start of the epoch: mem (CPU python)=20648.890625MB; mem (CPU total)=20350.1171875MB
INFO:root:[  133] Training loss: 0.55668148, Validation loss: 0.50577011, Gradient norm: 16.63039058
INFO:root:At the start of the epoch: mem (CPU python)=20670.0546875MB; mem (CPU total)=20370.44921875MB
INFO:root:[  134] Training loss: 0.55595713, Validation loss: 0.50558452, Gradient norm: 14.63053419
INFO:root:At the start of the epoch: mem (CPU python)=20691.21875MB; mem (CPU total)=20390.97265625MB
INFO:root:[  135] Training loss: 0.55534223, Validation loss: 0.50614091, Gradient norm: 15.17463772
INFO:root:At the start of the epoch: mem (CPU python)=20712.37890625MB; mem (CPU total)=20412.3828125MB
INFO:root:[  136] Training loss: 0.55612059, Validation loss: 0.50518024, Gradient norm: 16.69043714
INFO:root:At the start of the epoch: mem (CPU python)=20733.546875MB; mem (CPU total)=20433.48828125MB
INFO:root:[  137] Training loss: 0.55581368, Validation loss: 0.50618141, Gradient norm: 16.41696599
INFO:root:At the start of the epoch: mem (CPU python)=20754.7109375MB; mem (CPU total)=20454.87109375MB
INFO:root:[  138] Training loss: 0.55565469, Validation loss: 0.50581307, Gradient norm: 16.20244206
INFO:root:At the start of the epoch: mem (CPU python)=20775.875MB; mem (CPU total)=20476.0234375MB
INFO:root:[  139] Training loss: 0.55529438, Validation loss: 0.50533001, Gradient norm: 16.97594693
INFO:root:At the start of the epoch: mem (CPU python)=20797.03515625MB; mem (CPU total)=20497.1796875MB
INFO:root:[  140] Training loss: 0.55549882, Validation loss: 0.50566217, Gradient norm: 16.23647074
INFO:root:At the start of the epoch: mem (CPU python)=20818.19921875MB; mem (CPU total)=20518.5859375MB
INFO:root:[  141] Training loss: 0.55566982, Validation loss: 0.50536920, Gradient norm: 16.84682977
INFO:root:At the start of the epoch: mem (CPU python)=20839.36328125MB; mem (CPU total)=20541.0MB
INFO:root:[  142] Training loss: 0.55549885, Validation loss: 0.50497937, Gradient norm: 15.67141768
INFO:root:At the start of the epoch: mem (CPU python)=20860.53125MB; mem (CPU total)=20562.07421875MB
INFO:root:[  143] Training loss: 0.55574557, Validation loss: 0.50444543, Gradient norm: 17.45961197
INFO:root:At the start of the epoch: mem (CPU python)=20881.6953125MB; mem (CPU total)=20583.2578125MB
INFO:root:[  144] Training loss: 0.55543400, Validation loss: 0.50615884, Gradient norm: 17.38329556
INFO:root:At the start of the epoch: mem (CPU python)=20902.85546875MB; mem (CPU total)=20604.44140625MB
INFO:root:[  145] Training loss: 0.55573149, Validation loss: 0.50664143, Gradient norm: 18.25643499
INFO:root:At the start of the epoch: mem (CPU python)=20924.01953125MB; mem (CPU total)=20625.83984375MB
INFO:root:[  146] Training loss: 0.55538705, Validation loss: 0.50450120, Gradient norm: 18.89889480
INFO:root:At the start of the epoch: mem (CPU python)=20945.18359375MB; mem (CPU total)=20647.01171875MB
INFO:root:[  147] Training loss: 0.55519523, Validation loss: 0.50484051, Gradient norm: 17.73183149
INFO:root:At the start of the epoch: mem (CPU python)=20966.35546875MB; mem (CPU total)=20668.453125MB
INFO:root:[  148] Training loss: 0.55549245, Validation loss: 0.50503705, Gradient norm: 18.14636801
INFO:root:At the start of the epoch: mem (CPU python)=20987.51953125MB; mem (CPU total)=20689.6171875MB
INFO:root:[  149] Training loss: 0.55523472, Validation loss: 0.50457652, Gradient norm: 17.95475771
INFO:root:At the start of the epoch: mem (CPU python)=21008.68359375MB; mem (CPU total)=20710.69921875MB
INFO:root:[  150] Training loss: 0.55541647, Validation loss: 0.50572170, Gradient norm: 19.51086875
INFO:root:At the start of the epoch: mem (CPU python)=21029.84765625MB; mem (CPU total)=20732.2578125MB
INFO:root:[  151] Training loss: 0.55522528, Validation loss: 0.50494143, Gradient norm: 20.33427471
INFO:root:At the start of the epoch: mem (CPU python)=21051.01171875MB; mem (CPU total)=20752.515625MB
INFO:root:[  152] Training loss: 0.55468802, Validation loss: 0.50449506, Gradient norm: 19.39725794
INFO:root:At the start of the epoch: mem (CPU python)=21072.3671875MB; mem (CPU total)=20774.1796875MB
INFO:root:EP 152: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=21093.65234375MB; mem (CPU total)=20795.21484375MB
INFO:root:Training the model took 6029.22s.
INFO:root:Emptying the cuda cache took 0.063s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.75953
INFO:root:EnergyScoreValidation: 0.4308
INFO:root:CRPSValidation: 0.19422
INFO:root:Gaussian NLLValidation: 7.4899
INFO:root:CoverageValidation: 0.58098
INFO:root:IntervalWidthValidation: 0.76392
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.66859
INFO:root:EnergyScoreTest: 0.35844
INFO:root:CRPSTest: 0.16139
INFO:root:Gaussian NLLTest: 5.12913
INFO:root:CoverageTest: 0.64041
INFO:root:IntervalWidthTest: 0.80219
INFO:root:After validation: mem (CPU python)=21178.421875MB; mem (CPU total)=20839.74609375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=21178.421875MB; mem (CPU total)=20781.171875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 346030080
INFO:root:After setting up the model: mem (CPU python)=21178.421875MB; mem (CPU total)=20814.75MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=21178.421875MB; mem (CPU total)=20815.73046875MB
INFO:root:[    1] Training loss: 0.85787321, Validation loss: 0.73906795, Gradient norm: 0.37741049
INFO:root:At the start of the epoch: mem (CPU python)=21178.421875MB; mem (CPU total)=20836.44921875MB
INFO:root:[    2] Training loss: 0.75255034, Validation loss: 0.73881387, Gradient norm: 0.48656446
INFO:root:At the start of the epoch: mem (CPU python)=21178.421875MB; mem (CPU total)=20857.64453125MB
INFO:root:[    3] Training loss: 0.74698376, Validation loss: 0.72509002, Gradient norm: 0.68399091
INFO:root:At the start of the epoch: mem (CPU python)=21178.421875MB; mem (CPU total)=20878.78515625MB
INFO:root:[    4] Training loss: 0.73889185, Validation loss: 0.70862480, Gradient norm: 1.04059502
INFO:root:At the start of the epoch: mem (CPU python)=21197.28515625MB; mem (CPU total)=20899.9296875MB
INFO:root:[    5] Training loss: 0.72985313, Validation loss: 0.71023513, Gradient norm: 1.23106505
INFO:root:At the start of the epoch: mem (CPU python)=21218.44921875MB; mem (CPU total)=20921.31640625MB
INFO:root:[    6] Training loss: 0.71989520, Validation loss: 0.67299921, Gradient norm: 1.54770988
INFO:root:At the start of the epoch: mem (CPU python)=21239.6171875MB; mem (CPU total)=20942.69921875MB
INFO:root:[    7] Training loss: 0.69143429, Validation loss: 0.65481861, Gradient norm: 1.75654711
INFO:root:At the start of the epoch: mem (CPU python)=21260.78125MB; mem (CPU total)=20963.859375MB
INFO:root:[    8] Training loss: 0.66800282, Validation loss: 0.65831340, Gradient norm: 2.24657734
INFO:root:At the start of the epoch: mem (CPU python)=21281.9453125MB; mem (CPU total)=20984.703125MB
INFO:root:[    9] Training loss: 0.65799412, Validation loss: 0.60392003, Gradient norm: 2.67542691
INFO:root:At the start of the epoch: mem (CPU python)=21303.109375MB; mem (CPU total)=21005.4921875MB
INFO:root:[   10] Training loss: 0.64266354, Validation loss: 0.58783092, Gradient norm: 2.57021992
INFO:root:At the start of the epoch: mem (CPU python)=21324.27734375MB; mem (CPU total)=21026.78125MB
INFO:root:[   11] Training loss: 0.63070131, Validation loss: 0.58104216, Gradient norm: 2.73423527
INFO:root:At the start of the epoch: mem (CPU python)=21345.44140625MB; mem (CPU total)=21047.91796875MB
INFO:root:[   12] Training loss: 0.62841626, Validation loss: 0.58669125, Gradient norm: 3.25090914
INFO:root:At the start of the epoch: mem (CPU python)=21367.1015625MB; mem (CPU total)=21070.0546875MB
INFO:root:[   13] Training loss: 0.61803864, Validation loss: 0.57305955, Gradient norm: 3.03640244
INFO:root:At the start of the epoch: mem (CPU python)=21388.390625MB; mem (CPU total)=21091.19921875MB
INFO:root:[   14] Training loss: 0.61379403, Validation loss: 0.54946373, Gradient norm: 3.46021054
INFO:root:At the start of the epoch: mem (CPU python)=21410.05078125MB; mem (CPU total)=21112.609375MB
INFO:root:[   15] Training loss: 0.60131624, Validation loss: 0.54050761, Gradient norm: 3.42522090
INFO:root:At the start of the epoch: mem (CPU python)=21431.21875MB; mem (CPU total)=21133.75390625MB
INFO:root:[   16] Training loss: 0.60474032, Validation loss: 0.54930643, Gradient norm: 3.73067684
INFO:root:At the start of the epoch: mem (CPU python)=21452.3828125MB; mem (CPU total)=21154.66796875MB
INFO:root:[   17] Training loss: 0.60525961, Validation loss: 0.54189421, Gradient norm: 3.82702783
INFO:root:At the start of the epoch: mem (CPU python)=21473.546875MB; mem (CPU total)=21175.8203125MB
INFO:root:[   18] Training loss: 0.60027087, Validation loss: 0.53937467, Gradient norm: 4.48319062
INFO:root:At the start of the epoch: mem (CPU python)=21494.7109375MB; mem (CPU total)=21197.21875MB
INFO:root:[   19] Training loss: 0.60619126, Validation loss: 0.54614465, Gradient norm: 4.16751319
INFO:root:At the start of the epoch: mem (CPU python)=21515.875MB; mem (CPU total)=21218.35546875MB
INFO:root:[   20] Training loss: 0.60061284, Validation loss: 0.55579689, Gradient norm: 4.47272500
INFO:root:At the start of the epoch: mem (CPU python)=21537.0390625MB; mem (CPU total)=21239.4921875MB
INFO:root:[   21] Training loss: 0.59904244, Validation loss: 0.53613178, Gradient norm: 4.64811875
INFO:root:At the start of the epoch: mem (CPU python)=21558.20703125MB; mem (CPU total)=21260.640625MB
INFO:root:[   22] Training loss: 0.60087525, Validation loss: 0.54671729, Gradient norm: 4.44252061
INFO:root:At the start of the epoch: mem (CPU python)=21579.3671875MB; mem (CPU total)=21281.8046875MB
INFO:root:[   23] Training loss: 0.58878951, Validation loss: 0.52996268, Gradient norm: 4.50926910
INFO:root:At the start of the epoch: mem (CPU python)=21600.53125MB; mem (CPU total)=21303.05078125MB
INFO:root:[   24] Training loss: 0.59423632, Validation loss: 0.54773019, Gradient norm: 4.72934551
INFO:root:At the start of the epoch: mem (CPU python)=21621.6953125MB; mem (CPU total)=21324.71875MB
INFO:root:[   25] Training loss: 0.58940934, Validation loss: 0.53643584, Gradient norm: 4.74223034
INFO:root:At the start of the epoch: mem (CPU python)=21642.859375MB; mem (CPU total)=21346.109375MB
INFO:root:[   26] Training loss: 0.58983573, Validation loss: 0.54073128, Gradient norm: 4.97961273
INFO:root:At the start of the epoch: mem (CPU python)=21664.0234375MB; mem (CPU total)=21366.99609375MB
INFO:root:[   27] Training loss: 0.59534342, Validation loss: 0.52522971, Gradient norm: 5.52400299
INFO:root:At the start of the epoch: mem (CPU python)=21685.19140625MB; mem (CPU total)=21387.8671875MB
INFO:root:[   28] Training loss: 0.60013744, Validation loss: 0.52218009, Gradient norm: 5.45024061
INFO:root:At the start of the epoch: mem (CPU python)=21706.35546875MB; mem (CPU total)=21409.05078125MB
INFO:root:[   29] Training loss: 0.58699475, Validation loss: 0.51368715, Gradient norm: 5.16007008
INFO:root:At the start of the epoch: mem (CPU python)=21727.515625MB; mem (CPU total)=21430.4296875MB
INFO:root:[   30] Training loss: 0.58998676, Validation loss: 0.54621524, Gradient norm: 5.63871908
INFO:root:At the start of the epoch: mem (CPU python)=21748.6796875MB; mem (CPU total)=21451.82421875MB
INFO:root:[   31] Training loss: 0.59366888, Validation loss: 0.54012480, Gradient norm: 6.00130614
INFO:root:At the start of the epoch: mem (CPU python)=21769.83984375MB; mem (CPU total)=21472.7578125MB
INFO:root:[   32] Training loss: 0.59293302, Validation loss: 0.53340828, Gradient norm: 5.72519208
INFO:root:At the start of the epoch: mem (CPU python)=21791.0078125MB; mem (CPU total)=21493.90625MB
INFO:root:[   33] Training loss: 0.59391296, Validation loss: 0.53030768, Gradient norm: 6.04820440
INFO:root:At the start of the epoch: mem (CPU python)=21812.171875MB; mem (CPU total)=21515.0703125MB
INFO:root:[   34] Training loss: 0.58812143, Validation loss: 0.52070359, Gradient norm: 5.78477470
INFO:root:At the start of the epoch: mem (CPU python)=21833.3359375MB; mem (CPU total)=21536.2265625MB
INFO:root:[   35] Training loss: 0.58760626, Validation loss: 0.53687148, Gradient norm: 5.68453457
INFO:root:At the start of the epoch: mem (CPU python)=21854.9296875MB; mem (CPU total)=21558.5078125MB
INFO:root:[   36] Training loss: 0.59080440, Validation loss: 0.50987671, Gradient norm: 6.27920216
INFO:root:At the start of the epoch: mem (CPU python)=21876.7890625MB; mem (CPU total)=21579.421875MB
INFO:root:[   37] Training loss: 0.58817571, Validation loss: 0.52176893, Gradient norm: 6.37049800
INFO:root:At the start of the epoch: mem (CPU python)=21897.953125MB; mem (CPU total)=21600.71484375MB
INFO:root:[   38] Training loss: 0.59407330, Validation loss: 0.55307390, Gradient norm: 6.30561881
INFO:root:At the start of the epoch: mem (CPU python)=21919.12109375MB; mem (CPU total)=21621.875MB
INFO:root:[   39] Training loss: 0.59134718, Validation loss: 0.53520238, Gradient norm: 6.07977877
INFO:root:At the start of the epoch: mem (CPU python)=21940.28515625MB; mem (CPU total)=21643.0703125MB
INFO:root:[   40] Training loss: 0.59041440, Validation loss: 0.53159658, Gradient norm: 6.43583615
INFO:root:At the start of the epoch: mem (CPU python)=21961.66015625MB; mem (CPU total)=21664.7109375MB
INFO:root:[   41] Training loss: 0.58902716, Validation loss: 0.55424694, Gradient norm: 6.37526424
INFO:root:At the start of the epoch: mem (CPU python)=21983.359375MB; mem (CPU total)=21685.875MB
INFO:root:[   42] Training loss: 0.58910218, Validation loss: 0.53891234, Gradient norm: 6.57890331
INFO:root:At the start of the epoch: mem (CPU python)=22004.5234375MB; mem (CPU total)=21707.03515625MB
INFO:root:[   43] Training loss: 0.58300449, Validation loss: 0.55913337, Gradient norm: 6.20081770
INFO:root:At the start of the epoch: mem (CPU python)=22025.6953125MB; mem (CPU total)=21728.421875MB
INFO:root:[   44] Training loss: 0.58119085, Validation loss: 0.55809711, Gradient norm: 7.01387273
INFO:root:At the start of the epoch: mem (CPU python)=22046.859375MB; mem (CPU total)=21749.7421875MB
INFO:root:[   45] Training loss: 0.60236276, Validation loss: 0.53227630, Gradient norm: 8.72965061
INFO:root:At the start of the epoch: mem (CPU python)=22068.01953125MB; mem (CPU total)=21770.87890625MB
INFO:root:[   46] Training loss: 0.59747079, Validation loss: 0.52839751, Gradient norm: 7.55315335
INFO:root:At the start of the epoch: mem (CPU python)=22089.18359375MB; mem (CPU total)=21792.03515625MB
INFO:root:[   47] Training loss: 0.59294628, Validation loss: 0.52775472, Gradient norm: 7.07867353
INFO:root:At the start of the epoch: mem (CPU python)=22110.7734375MB; mem (CPU total)=21813.73828125MB
INFO:root:[   48] Training loss: 0.58634738, Validation loss: 0.54567353, Gradient norm: 7.27275031
INFO:root:At the start of the epoch: mem (CPU python)=22132.265625MB; mem (CPU total)=21834.41796875MB
INFO:root:[   49] Training loss: 0.59330020, Validation loss: 0.60712566, Gradient norm: 7.84605373
INFO:root:At the start of the epoch: mem (CPU python)=22153.4296875MB; mem (CPU total)=21855.80078125MB
INFO:root:[   50] Training loss: 0.60240815, Validation loss: 0.56194566, Gradient norm: 7.64363297
INFO:root:At the start of the epoch: mem (CPU python)=22174.70703125MB; mem (CPU total)=21877.43359375MB
INFO:root:[   51] Training loss: 0.58726204, Validation loss: 0.53058443, Gradient norm: 7.32332703
INFO:root:At the start of the epoch: mem (CPU python)=22196.12890625MB; mem (CPU total)=21899.87890625MB
INFO:root:[   52] Training loss: 0.58240652, Validation loss: 0.57447850, Gradient norm: 7.52906403
INFO:root:At the start of the epoch: mem (CPU python)=22217.29296875MB; mem (CPU total)=21921.0546875MB
INFO:root:[   53] Training loss: 0.60162462, Validation loss: 0.54681031, Gradient norm: 8.52792552
INFO:root:At the start of the epoch: mem (CPU python)=22238.45703125MB; mem (CPU total)=21942.61328125MB
INFO:root:[   54] Training loss: 0.59831383, Validation loss: 0.52712011, Gradient norm: 8.14992882
INFO:root:At the start of the epoch: mem (CPU python)=22259.625MB; mem (CPU total)=21963.63671875MB
INFO:root:[   55] Training loss: 0.58923045, Validation loss: 0.52036412, Gradient norm: 7.46569505
INFO:root:At the start of the epoch: mem (CPU python)=22280.7890625MB; mem (CPU total)=21985.046875MB
INFO:root:[   56] Training loss: 0.59143722, Validation loss: 0.50261057, Gradient norm: 8.25136001
INFO:root:At the start of the epoch: mem (CPU python)=22301.953125MB; mem (CPU total)=22005.93359375MB
INFO:root:[   57] Training loss: 0.59162561, Validation loss: 0.52170732, Gradient norm: 7.94469025
INFO:root:At the start of the epoch: mem (CPU python)=22323.1171875MB; mem (CPU total)=22027.1015625MB
INFO:root:[   58] Training loss: 0.58277964, Validation loss: 0.51695339, Gradient norm: 7.37125924
INFO:root:At the start of the epoch: mem (CPU python)=22344.28125MB; mem (CPU total)=22048.28125MB
INFO:root:[   59] Training loss: 0.58426947, Validation loss: 0.52378129, Gradient norm: 8.48143581
INFO:root:At the start of the epoch: mem (CPU python)=22365.4453125MB; mem (CPU total)=22069.20703125MB
INFO:root:[   60] Training loss: 0.58611549, Validation loss: 0.53328103, Gradient norm: 8.29455649
INFO:root:At the start of the epoch: mem (CPU python)=22386.609375MB; mem (CPU total)=22090.37109375MB
INFO:root:[   61] Training loss: 0.59009107, Validation loss: 0.52985582, Gradient norm: 8.95832030
INFO:root:At the start of the epoch: mem (CPU python)=22407.7734375MB; mem (CPU total)=22111.54296875MB
INFO:root:[   62] Training loss: 0.59589705, Validation loss: 0.50730153, Gradient norm: 9.34564394
INFO:root:At the start of the epoch: mem (CPU python)=22428.93359375MB; mem (CPU total)=22132.96484375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.58923556, Validation loss: 0.53324157, Gradient norm: 8.73577863
INFO:root:At the start of the epoch: mem (CPU python)=22450.09765625MB; mem (CPU total)=22154.12890625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.55279458, Validation loss: 0.49156188, Gradient norm: 7.33883156
INFO:root:At the start of the epoch: mem (CPU python)=22471.26171875MB; mem (CPU total)=22175.4765625MB
INFO:root:[   65] Training loss: 0.53905622, Validation loss: 0.47161461, Gradient norm: 5.71510707
INFO:root:At the start of the epoch: mem (CPU python)=22492.4296875MB; mem (CPU total)=22197.08984375MB
INFO:root:[   66] Training loss: 0.53912166, Validation loss: 0.46909964, Gradient norm: 6.65141630
INFO:root:At the start of the epoch: mem (CPU python)=22513.59375MB; mem (CPU total)=22217.9140625MB
INFO:root:[   67] Training loss: 0.54021112, Validation loss: 0.47279343, Gradient norm: 8.39043199
INFO:root:At the start of the epoch: mem (CPU python)=22534.7578125MB; mem (CPU total)=22239.32421875MB
INFO:root:[   68] Training loss: 0.54080848, Validation loss: 0.47363977, Gradient norm: 8.79640128
INFO:root:At the start of the epoch: mem (CPU python)=22555.921875MB; mem (CPU total)=22260.47265625MB
INFO:root:[   69] Training loss: 0.54083877, Validation loss: 0.47769806, Gradient norm: 9.18321200
INFO:root:At the start of the epoch: mem (CPU python)=22577.08203125MB; mem (CPU total)=22281.59375MB
INFO:root:[   70] Training loss: 0.54301959, Validation loss: 0.47139466, Gradient norm: 10.37450308
INFO:root:At the start of the epoch: mem (CPU python)=22598.24609375MB; mem (CPU total)=22302.75MB
INFO:root:[   71] Training loss: 0.54279401, Validation loss: 0.47448832, Gradient norm: 11.58346589
INFO:root:At the start of the epoch: mem (CPU python)=22619.41015625MB; mem (CPU total)=22324.16015625MB
INFO:root:[   72] Training loss: 0.54473063, Validation loss: 0.47306194, Gradient norm: 11.11969463
INFO:root:At the start of the epoch: mem (CPU python)=22640.578125MB; mem (CPU total)=22345.25MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   73] Training loss: 0.54275086, Validation loss: 0.48102520, Gradient norm: 12.19564770
INFO:root:At the start of the epoch: mem (CPU python)=22661.7421875MB; mem (CPU total)=22366.18359375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   74] Training loss: 0.53464222, Validation loss: 0.46676700, Gradient norm: 8.67739594
INFO:root:At the start of the epoch: mem (CPU python)=22682.90625MB; mem (CPU total)=22387.57421875MB
INFO:root:[   75] Training loss: 0.52952582, Validation loss: 0.46484163, Gradient norm: 5.92686210
INFO:root:At the start of the epoch: mem (CPU python)=22704.0703125MB; mem (CPU total)=22408.8125MB
INFO:root:[   76] Training loss: 0.53000042, Validation loss: 0.46278057, Gradient norm: 7.72325664
INFO:root:At the start of the epoch: mem (CPU python)=22725.23828125MB; mem (CPU total)=22429.73046875MB
INFO:root:[   77] Training loss: 0.52935937, Validation loss: 0.46388690, Gradient norm: 7.48055106
INFO:root:At the start of the epoch: mem (CPU python)=22746.3984375MB; mem (CPU total)=22450.89453125MB
INFO:root:[   78] Training loss: 0.52912273, Validation loss: 0.46368480, Gradient norm: 7.92924946
INFO:root:At the start of the epoch: mem (CPU python)=22767.5625MB; mem (CPU total)=22472.29296875MB
INFO:root:[   79] Training loss: 0.52965616, Validation loss: 0.46814205, Gradient norm: 9.06783046
INFO:root:At the start of the epoch: mem (CPU python)=22788.72265625MB; mem (CPU total)=22493.4453125MB
INFO:root:[   80] Training loss: 0.53020923, Validation loss: 0.46252351, Gradient norm: 10.83540898
INFO:root:At the start of the epoch: mem (CPU python)=22809.890625MB; mem (CPU total)=22514.3359375MB
INFO:root:[   81] Training loss: 0.52868089, Validation loss: 0.46462019, Gradient norm: 9.62539018
INFO:root:At the start of the epoch: mem (CPU python)=22831.0546875MB; mem (CPU total)=22535.9609375MB
INFO:root:[   82] Training loss: 0.52890459, Validation loss: 0.46826962, Gradient norm: 9.64436991
INFO:root:At the start of the epoch: mem (CPU python)=22852.22265625MB; mem (CPU total)=22557.0703125MB
INFO:root:[   83] Training loss: 0.52981789, Validation loss: 0.46395536, Gradient norm: 10.95659203
INFO:root:At the start of the epoch: mem (CPU python)=22873.38671875MB; mem (CPU total)=22578.21875MB
INFO:root:[   84] Training loss: 0.52897872, Validation loss: 0.46573431, Gradient norm: 10.98867574
INFO:root:At the start of the epoch: mem (CPU python)=22894.55078125MB; mem (CPU total)=22598.88671875MB
INFO:root:[   85] Training loss: 0.52805950, Validation loss: 0.46376233, Gradient norm: 11.28932980
INFO:root:At the start of the epoch: mem (CPU python)=22915.71484375MB; mem (CPU total)=22620.05078125MB
INFO:root:[   86] Training loss: 0.52832788, Validation loss: 0.46419828, Gradient norm: 11.83502263
INFO:root:At the start of the epoch: mem (CPU python)=22936.87890625MB; mem (CPU total)=22641.20703125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   87] Training loss: 0.52867305, Validation loss: 0.46831094, Gradient norm: 11.72744216
INFO:root:At the start of the epoch: mem (CPU python)=22958.046875MB; mem (CPU total)=22662.37109375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   88] Training loss: 0.52683512, Validation loss: 0.46241032, Gradient norm: 8.34484526
INFO:root:At the start of the epoch: mem (CPU python)=22979.20703125MB; mem (CPU total)=22683.703125MB
INFO:root:[   89] Training loss: 0.52528521, Validation loss: 0.46237059, Gradient norm: 6.61151208
INFO:root:At the start of the epoch: mem (CPU python)=23000.37109375MB; mem (CPU total)=22705.14453125MB
INFO:root:[   90] Training loss: 0.52528502, Validation loss: 0.46157014, Gradient norm: 7.15045004
INFO:root:At the start of the epoch: mem (CPU python)=23021.53515625MB; mem (CPU total)=22726.33984375MB
INFO:root:[   91] Training loss: 0.52498570, Validation loss: 0.46180559, Gradient norm: 6.68143527
INFO:root:At the start of the epoch: mem (CPU python)=23042.69921875MB; mem (CPU total)=22747.0546875MB
INFO:root:[   92] Training loss: 0.52464003, Validation loss: 0.46168020, Gradient norm: 6.57221483
INFO:root:At the start of the epoch: mem (CPU python)=23063.86328125MB; mem (CPU total)=22768.203125MB
INFO:root:[   93] Training loss: 0.52476279, Validation loss: 0.46185928, Gradient norm: 8.53395425
INFO:root:At the start of the epoch: mem (CPU python)=23085.02734375MB; mem (CPU total)=22789.3515625MB
INFO:root:[   94] Training loss: 0.52460980, Validation loss: 0.46133630, Gradient norm: 6.88679845
INFO:root:At the start of the epoch: mem (CPU python)=23106.1953125MB; mem (CPU total)=22810.328125MB
INFO:root:[   95] Training loss: 0.52478729, Validation loss: 0.46123882, Gradient norm: 8.99053077
INFO:root:At the start of the epoch: mem (CPU python)=23127.359375MB; mem (CPU total)=22831.734375MB
INFO:root:[   96] Training loss: 0.52460777, Validation loss: 0.46176665, Gradient norm: 9.28773175
INFO:root:At the start of the epoch: mem (CPU python)=23148.51953125MB; mem (CPU total)=22852.62109375MB
INFO:root:[   97] Training loss: 0.52448346, Validation loss: 0.46201042, Gradient norm: 9.82659275
INFO:root:At the start of the epoch: mem (CPU python)=23169.6796875MB; mem (CPU total)=22873.78125MB
INFO:root:[   98] Training loss: 0.52530161, Validation loss: 0.46228259, Gradient norm: 11.15360027
INFO:root:At the start of the epoch: mem (CPU python)=23190.84375MB; mem (CPU total)=22894.9453125MB
INFO:root:[   99] Training loss: 0.52470742, Validation loss: 0.46228383, Gradient norm: 9.36531677
INFO:root:At the start of the epoch: mem (CPU python)=23212.0078125MB; mem (CPU total)=22916.38671875MB
INFO:root:[  100] Training loss: 0.52441362, Validation loss: 0.46229435, Gradient norm: 8.79211707
INFO:root:At the start of the epoch: mem (CPU python)=23233.68359375MB; mem (CPU total)=22938.78125MB
INFO:root:[  101] Training loss: 0.52470266, Validation loss: 0.46266971, Gradient norm: 12.03077160
INFO:root:At the start of the epoch: mem (CPU python)=23255.30078125MB; mem (CPU total)=22959.93359375MB
INFO:root:[  102] Training loss: 0.52400441, Validation loss: 0.46166373, Gradient norm: 9.22729478
INFO:root:At the start of the epoch: mem (CPU python)=23276.62890625MB; mem (CPU total)=22980.72265625MB
INFO:root:[  103] Training loss: 0.52450890, Validation loss: 0.46236724, Gradient norm: 10.60048502
INFO:root:At the start of the epoch: mem (CPU python)=23297.79296875MB; mem (CPU total)=23001.828125MB
INFO:root:[  104] Training loss: 0.52410812, Validation loss: 0.46228772, Gradient norm: 10.74278163
INFO:root:At the start of the epoch: mem (CPU python)=23318.95703125MB; mem (CPU total)=23022.9921875MB
INFO:root:EP 104: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=23340.16796875MB; mem (CPU total)=23045.38671875MB
INFO:root:[  106] Training loss: 0.61015394, Validation loss: 0.54308842, Gradient norm: 12.86613079
INFO:root:At the start of the epoch: mem (CPU python)=23361.6640625MB; mem (CPU total)=23067.16796875MB
INFO:root:[  107] Training loss: 0.60894847, Validation loss: 0.54165579, Gradient norm: 11.54744265
INFO:root:At the start of the epoch: mem (CPU python)=23382.82421875MB; mem (CPU total)=23088.3828125MB
INFO:root:[  108] Training loss: 0.60805597, Validation loss: 0.54100925, Gradient norm: 11.81908603
INFO:root:At the start of the epoch: mem (CPU python)=23403.98828125MB; mem (CPU total)=23109.859375MB
INFO:root:[  109] Training loss: 0.60761246, Validation loss: 0.54084382, Gradient norm: 12.17662343
INFO:root:At the start of the epoch: mem (CPU python)=23425.15234375MB; mem (CPU total)=23130.78515625MB
INFO:root:[  110] Training loss: 0.60749184, Validation loss: 0.54103802, Gradient norm: 12.68927846
INFO:root:At the start of the epoch: mem (CPU python)=23446.31640625MB; mem (CPU total)=23151.94921875MB
INFO:root:[  111] Training loss: 0.60755512, Validation loss: 0.54145069, Gradient norm: 12.67437537
INFO:root:At the start of the epoch: mem (CPU python)=23467.484375MB; mem (CPU total)=23172.921875MB
INFO:root:[  112] Training loss: 0.60709423, Validation loss: 0.53998147, Gradient norm: 12.29690416
INFO:root:At the start of the epoch: mem (CPU python)=23488.6484375MB; mem (CPU total)=23194.58203125MB
INFO:root:[  113] Training loss: 0.60720490, Validation loss: 0.53985767, Gradient norm: 12.44041258
INFO:root:At the start of the epoch: mem (CPU python)=23509.8125MB; mem (CPU total)=23215.51171875MB
INFO:root:[  114] Training loss: 0.60676621, Validation loss: 0.53994421, Gradient norm: 12.35768336
INFO:root:At the start of the epoch: mem (CPU python)=23530.97265625MB; mem (CPU total)=23236.71875MB
INFO:root:[  115] Training loss: 0.60719588, Validation loss: 0.54007438, Gradient norm: 12.65557257
INFO:root:At the start of the epoch: mem (CPU python)=23552.13671875MB; mem (CPU total)=23257.89453125MB
INFO:root:[  116] Training loss: 0.60661852, Validation loss: 0.54084595, Gradient norm: 13.32571407
INFO:root:At the start of the epoch: mem (CPU python)=23573.30078125MB; mem (CPU total)=23279.0546875MB
INFO:root:[  117] Training loss: 0.60633662, Validation loss: 0.53938617, Gradient norm: 12.69386468
INFO:root:At the start of the epoch: mem (CPU python)=23594.46484375MB; mem (CPU total)=23300.22265625MB
INFO:root:[  118] Training loss: 0.60665314, Validation loss: 0.53952835, Gradient norm: 13.75580434
INFO:root:At the start of the epoch: mem (CPU python)=23615.62890625MB; mem (CPU total)=23321.37109375MB
INFO:root:[  119] Training loss: 0.60632360, Validation loss: 0.54038230, Gradient norm: 13.76426078
INFO:root:At the start of the epoch: mem (CPU python)=23636.79296875MB; mem (CPU total)=23342.44140625MB
INFO:root:[  120] Training loss: 0.60624449, Validation loss: 0.53918450, Gradient norm: 13.15675759
INFO:root:At the start of the epoch: mem (CPU python)=23657.95703125MB; mem (CPU total)=23364.11328125MB
INFO:root:[  121] Training loss: 0.60615896, Validation loss: 0.53998355, Gradient norm: 12.68540980
INFO:root:At the start of the epoch: mem (CPU python)=23679.12109375MB; mem (CPU total)=23385.44140625MB
INFO:root:[  122] Training loss: 0.60593586, Validation loss: 0.54095202, Gradient norm: 13.78778214
INFO:root:At the start of the epoch: mem (CPU python)=23700.29296875MB; mem (CPU total)=23406.86328125MB
INFO:root:[  123] Training loss: 0.60607084, Validation loss: 0.53907303, Gradient norm: 14.63672944
INFO:root:At the start of the epoch: mem (CPU python)=23721.45703125MB; mem (CPU total)=23427.86328125MB
INFO:root:[  124] Training loss: 0.60579173, Validation loss: 0.53927714, Gradient norm: 14.54323675
INFO:root:At the start of the epoch: mem (CPU python)=23742.62109375MB; mem (CPU total)=23449.01953125MB
INFO:root:[  125] Training loss: 0.60575829, Validation loss: 0.54057660, Gradient norm: 14.54298728
INFO:root:At the start of the epoch: mem (CPU python)=23763.78125MB; mem (CPU total)=23470.20703125MB
INFO:root:[  126] Training loss: 0.60543821, Validation loss: 0.54022330, Gradient norm: 14.58944855
INFO:root:At the start of the epoch: mem (CPU python)=23784.9453125MB; mem (CPU total)=23491.28515625MB
INFO:root:[  127] Training loss: 0.60581555, Validation loss: 0.54027653, Gradient norm: 15.10051733
INFO:root:At the start of the epoch: mem (CPU python)=23806.11328125MB; mem (CPU total)=23512.4453125MB
INFO:root:[  128] Training loss: 0.60587915, Validation loss: 0.53963667, Gradient norm: 15.66444784
INFO:root:At the start of the epoch: mem (CPU python)=23827.27734375MB; mem (CPU total)=23533.34765625MB
INFO:root:[  129] Training loss: 0.60558594, Validation loss: 0.53973737, Gradient norm: 15.83554555
INFO:root:At the start of the epoch: mem (CPU python)=23848.44140625MB; mem (CPU total)=23554.20703125MB
INFO:root:[  130] Training loss: 0.60564804, Validation loss: 0.53969261, Gradient norm: 15.46919834
INFO:root:At the start of the epoch: mem (CPU python)=23869.6015625MB; mem (CPU total)=23575.3671875MB
INFO:root:[  131] Training loss: 0.60566935, Validation loss: 0.53886823, Gradient norm: 15.51841478
INFO:root:At the start of the epoch: mem (CPU python)=23890.765625MB; mem (CPU total)=23596.55859375MB
INFO:root:[  132] Training loss: 0.60543687, Validation loss: 0.53897909, Gradient norm: 16.04045558
INFO:root:At the start of the epoch: mem (CPU python)=23911.9296875MB; mem (CPU total)=23617.96875MB
INFO:root:[  133] Training loss: 0.60534928, Validation loss: 0.53909023, Gradient norm: 15.95321976
INFO:root:At the start of the epoch: mem (CPU python)=23933.09765625MB; mem (CPU total)=23639.09765625MB
INFO:root:[  134] Training loss: 0.60544557, Validation loss: 0.53901643, Gradient norm: 16.63451022
INFO:root:At the start of the epoch: mem (CPU python)=23954.26171875MB; mem (CPU total)=23660.2734375MB
INFO:root:[  135] Training loss: 0.60561722, Validation loss: 0.53965128, Gradient norm: 17.14151280
INFO:root:At the start of the epoch: mem (CPU python)=23975.421875MB; mem (CPU total)=23681.4296875MB
INFO:root:[  136] Training loss: 0.60534719, Validation loss: 0.53969092, Gradient norm: 17.14573845
INFO:root:At the start of the epoch: mem (CPU python)=23996.5859375MB; mem (CPU total)=23702.58203125MB
INFO:root:[  137] Training loss: 0.60539203, Validation loss: 0.53982136, Gradient norm: 17.09113994
INFO:root:At the start of the epoch: mem (CPU python)=24017.75MB; mem (CPU total)=23723.671875MB
INFO:root:[  138] Training loss: 0.60532607, Validation loss: 0.53977969, Gradient norm: 17.63628363
INFO:root:At the start of the epoch: mem (CPU python)=24038.91796875MB; mem (CPU total)=23745.30078125MB
INFO:root:[  139] Training loss: 0.60533512, Validation loss: 0.53996146, Gradient norm: 18.72455603
INFO:root:At the start of the epoch: mem (CPU python)=24060.08203125MB; mem (CPU total)=23766.43359375MB
INFO:root:[  140] Training loss: 0.60560631, Validation loss: 0.54009225, Gradient norm: 18.22471997
INFO:root:At the start of the epoch: mem (CPU python)=24081.24609375MB; mem (CPU total)=23787.34765625MB
INFO:root:EP 140: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=24102.3671875MB; mem (CPU total)=23808.26171875MB
INFO:root:Training the model took 6136.473s.
INFO:root:Emptying the cuda cache took 0.064s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.7298
INFO:root:EnergyScoreValidation: 0.43598
INFO:root:CRPSValidation: 0.19693
INFO:root:Gaussian NLLValidation: 13.18881
INFO:root:CoverageValidation: 0.51918
INFO:root:IntervalWidthValidation: 0.61423
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.65082
INFO:root:EnergyScoreTest: 0.3699
INFO:root:CRPSTest: 0.16762
INFO:root:Gaussian NLLTest: 9.1747
INFO:root:CoverageTest: 0.56464
INFO:root:IntervalWidthTest: 0.63715
INFO:root:After validation: mem (CPU python)=24178.74609375MB; mem (CPU total)=23844.55859375MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=24178.74609375MB; mem (CPU total)=23797.29296875MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 346030080
INFO:root:After setting up the model: mem (CPU python)=24178.74609375MB; mem (CPU total)=23830.7734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=24178.74609375MB; mem (CPU total)=23831.75MB
INFO:root:[    1] Training loss: 0.86891167, Validation loss: 0.73662448, Gradient norm: 0.34637988
INFO:root:At the start of the epoch: mem (CPU python)=24178.74609375MB; mem (CPU total)=23864.42578125MB
INFO:root:[    2] Training loss: 0.75571312, Validation loss: 0.73410792, Gradient norm: 0.32610048
INFO:root:At the start of the epoch: mem (CPU python)=24179.33984375MB; mem (CPU total)=23885.58984375MB
INFO:root:[    3] Training loss: 0.74939258, Validation loss: 0.72675532, Gradient norm: 0.52415214
INFO:root:At the start of the epoch: mem (CPU python)=24200.50390625MB; mem (CPU total)=23906.74609375MB
INFO:root:[    4] Training loss: 0.74053824, Validation loss: 0.71368402, Gradient norm: 0.70537682
INFO:root:At the start of the epoch: mem (CPU python)=24221.66796875MB; mem (CPU total)=23928.1953125MB
INFO:root:[    5] Training loss: 0.72969490, Validation loss: 0.69924890, Gradient norm: 0.86549241
INFO:root:At the start of the epoch: mem (CPU python)=24242.8359375MB; mem (CPU total)=23949.9375MB
INFO:root:[    6] Training loss: 0.71919843, Validation loss: 0.68976263, Gradient norm: 1.51888805
INFO:root:At the start of the epoch: mem (CPU python)=24263.99609375MB; mem (CPU total)=23970.94921875MB
INFO:root:[    7] Training loss: 0.70853184, Validation loss: 0.64935983, Gradient norm: 1.57459738
INFO:root:At the start of the epoch: mem (CPU python)=24285.16015625MB; mem (CPU total)=23991.71484375MB
INFO:root:[    8] Training loss: 0.69905173, Validation loss: 0.65398248, Gradient norm: 2.12484221
INFO:root:At the start of the epoch: mem (CPU python)=24306.32421875MB; mem (CPU total)=24012.89453125MB
INFO:root:[    9] Training loss: 0.69414074, Validation loss: 0.64841136, Gradient norm: 2.35032966
INFO:root:At the start of the epoch: mem (CPU python)=24327.4921875MB; mem (CPU total)=24034.31640625MB
INFO:root:[   10] Training loss: 0.68676485, Validation loss: 0.64829049, Gradient norm: 2.57629907
INFO:root:At the start of the epoch: mem (CPU python)=24348.65625MB; mem (CPU total)=24055.48828125MB
INFO:root:[   11] Training loss: 0.68143960, Validation loss: 0.63226370, Gradient norm: 2.90381105
INFO:root:At the start of the epoch: mem (CPU python)=24369.8203125MB; mem (CPU total)=24076.359375MB
INFO:root:[   12] Training loss: 0.67923728, Validation loss: 0.61545028, Gradient norm: 3.37843500
INFO:root:At the start of the epoch: mem (CPU python)=24390.984375MB; mem (CPU total)=24097.19140625MB
INFO:root:[   13] Training loss: 0.67706459, Validation loss: 0.61090489, Gradient norm: 3.46586796
INFO:root:At the start of the epoch: mem (CPU python)=24412.14453125MB; mem (CPU total)=24118.5234375MB
INFO:root:[   14] Training loss: 0.67185187, Validation loss: 0.60179353, Gradient norm: 3.79241437
INFO:root:At the start of the epoch: mem (CPU python)=24433.3125MB; mem (CPU total)=24139.68359375MB
INFO:root:[   15] Training loss: 0.67257773, Validation loss: 0.61252739, Gradient norm: 4.23996567
INFO:root:At the start of the epoch: mem (CPU python)=24454.47265625MB; mem (CPU total)=24160.83984375MB
INFO:root:[   16] Training loss: 0.66497122, Validation loss: 0.59174561, Gradient norm: 4.03183947
INFO:root:At the start of the epoch: mem (CPU python)=24475.63671875MB; mem (CPU total)=24181.7578125MB
INFO:root:[   17] Training loss: 0.66912274, Validation loss: 0.60625866, Gradient norm: 4.57654986
INFO:root:At the start of the epoch: mem (CPU python)=24496.80078125MB; mem (CPU total)=24202.921875MB
INFO:root:[   18] Training loss: 0.66204646, Validation loss: 0.59184636, Gradient norm: 4.42516704
INFO:root:At the start of the epoch: mem (CPU python)=24517.96484375MB; mem (CPU total)=24224.0MB
INFO:root:[   19] Training loss: 0.65550009, Validation loss: 0.63768237, Gradient norm: 4.49815851
INFO:root:At the start of the epoch: mem (CPU python)=24539.12890625MB; mem (CPU total)=24245.41015625MB
INFO:root:[   20] Training loss: 0.66201545, Validation loss: 0.59256663, Gradient norm: 5.07782601
INFO:root:At the start of the epoch: mem (CPU python)=24560.296875MB; mem (CPU total)=24266.33984375MB
INFO:root:[   21] Training loss: 0.66151081, Validation loss: 0.59158424, Gradient norm: 5.37756559
INFO:root:At the start of the epoch: mem (CPU python)=24581.4609375MB; mem (CPU total)=24287.4453125MB
INFO:root:[   22] Training loss: 0.65633149, Validation loss: 0.58468161, Gradient norm: 5.23159968
INFO:root:At the start of the epoch: mem (CPU python)=24602.625MB; mem (CPU total)=24308.58203125MB
INFO:root:[   23] Training loss: 0.65888344, Validation loss: 0.60553718, Gradient norm: 5.54223361
INFO:root:At the start of the epoch: mem (CPU python)=24623.7890625MB; mem (CPU total)=24329.7578125MB
INFO:root:[   24] Training loss: 0.65154090, Validation loss: 0.58799368, Gradient norm: 5.05267884
INFO:root:At the start of the epoch: mem (CPU python)=24644.953125MB; mem (CPU total)=24350.921875MB
INFO:root:[   25] Training loss: 0.65264794, Validation loss: 0.59046070, Gradient norm: 5.96347363
INFO:root:At the start of the epoch: mem (CPU python)=24666.1171875MB; mem (CPU total)=24371.5859375MB
INFO:root:[   26] Training loss: 0.65053667, Validation loss: 0.58712619, Gradient norm: 5.83946778
INFO:root:At the start of the epoch: mem (CPU python)=24687.28125MB; mem (CPU total)=24392.75MB
INFO:root:[   27] Training loss: 0.65962437, Validation loss: 0.58856984, Gradient norm: 6.50155336
INFO:root:At the start of the epoch: mem (CPU python)=24708.4453125MB; mem (CPU total)=24413.91015625MB
INFO:root:[   28] Training loss: 0.65228646, Validation loss: 0.61745975, Gradient norm: 6.05504444
INFO:root:At the start of the epoch: mem (CPU python)=24729.60546875MB; mem (CPU total)=24435.0703125MB
INFO:root:[   29] Training loss: 0.65789854, Validation loss: 0.56758528, Gradient norm: 6.76314688
INFO:root:At the start of the epoch: mem (CPU python)=24750.77734375MB; mem (CPU total)=24456.4765625MB
INFO:root:[   30] Training loss: 0.65206177, Validation loss: 0.57607624, Gradient norm: 6.77747023
INFO:root:At the start of the epoch: mem (CPU python)=24771.93359375MB; mem (CPU total)=24477.61328125MB
INFO:root:[   31] Training loss: 0.65387719, Validation loss: 0.60643207, Gradient norm: 6.95272364
INFO:root:At the start of the epoch: mem (CPU python)=24793.1015625MB; mem (CPU total)=24498.77734375MB
INFO:root:[   32] Training loss: 0.64645680, Validation loss: 0.57353484, Gradient norm: 6.76727229
INFO:root:At the start of the epoch: mem (CPU python)=24814.265625MB; mem (CPU total)=24519.94140625MB
INFO:root:[   33] Training loss: 0.62594012, Validation loss: 0.53711656, Gradient norm: 6.67180352
INFO:root:At the start of the epoch: mem (CPU python)=24835.4296875MB; mem (CPU total)=24541.62890625MB
INFO:root:[   34] Training loss: 0.64398035, Validation loss: 0.61913161, Gradient norm: 9.30908584
INFO:root:At the start of the epoch: mem (CPU python)=24856.58984375MB; mem (CPU total)=24563.0546875MB
INFO:root:[   35] Training loss: 0.64461346, Validation loss: 0.57223073, Gradient norm: 8.75274815
INFO:root:At the start of the epoch: mem (CPU python)=24877.7578125MB; mem (CPU total)=24584.21484375MB
INFO:root:[   36] Training loss: 0.63555336, Validation loss: 0.51997453, Gradient norm: 8.35154598
INFO:root:At the start of the epoch: mem (CPU python)=24898.921875MB; mem (CPU total)=24605.36328125MB
INFO:root:[   37] Training loss: 0.63049271, Validation loss: 0.56102227, Gradient norm: 8.48101254
INFO:root:At the start of the epoch: mem (CPU python)=24920.0859375MB; mem (CPU total)=24625.7890625MB
INFO:root:[   38] Training loss: 0.63734649, Validation loss: 0.56802719, Gradient norm: 9.49752101
INFO:root:At the start of the epoch: mem (CPU python)=24941.25MB; mem (CPU total)=24647.1953125MB
INFO:root:[   39] Training loss: 0.63589545, Validation loss: 0.52811974, Gradient norm: 9.16012890
INFO:root:At the start of the epoch: mem (CPU python)=24962.4140625MB; mem (CPU total)=24668.35546875MB
INFO:root:[   40] Training loss: 0.63075094, Validation loss: 0.52610087, Gradient norm: 8.94072420
INFO:root:At the start of the epoch: mem (CPU python)=24983.578125MB; mem (CPU total)=24689.46875MB
INFO:root:[   41] Training loss: 0.64413438, Validation loss: 0.54253333, Gradient norm: 9.84692725
INFO:root:At the start of the epoch: mem (CPU python)=25004.74609375MB; mem (CPU total)=24710.6328125MB
INFO:root:[   42] Training loss: 0.63430914, Validation loss: 0.54055125, Gradient norm: 9.55424132
INFO:root:At the start of the epoch: mem (CPU python)=25025.91015625MB; mem (CPU total)=24731.546875MB
INFO:root:[   43] Training loss: 0.63545440, Validation loss: 0.52709253, Gradient norm: 9.65254415
INFO:root:At the start of the epoch: mem (CPU python)=25047.0703125MB; mem (CPU total)=24752.6640625MB
INFO:root:[   44] Training loss: 0.63494490, Validation loss: 0.53384909, Gradient norm: 10.19751990
INFO:root:At the start of the epoch: mem (CPU python)=25068.234375MB; mem (CPU total)=24774.02734375MB
INFO:root:[   45] Training loss: 0.63026238, Validation loss: 0.55362712, Gradient norm: 10.13584425
INFO:root:At the start of the epoch: mem (CPU python)=25089.39453125MB; mem (CPU total)=24795.1875MB
INFO:root:[   46] Training loss: 0.63488293, Validation loss: 0.52873915, Gradient norm: 10.62180683
INFO:root:At the start of the epoch: mem (CPU python)=25110.55859375MB; mem (CPU total)=24816.09375MB
INFO:root:[   47] Training loss: 0.64630581, Validation loss: 0.54414337, Gradient norm: 11.27664321
INFO:root:At the start of the epoch: mem (CPU python)=25131.7265625MB; mem (CPU total)=24837.234375MB
INFO:root:[   48] Training loss: 0.63909371, Validation loss: 0.56299221, Gradient norm: 11.21094521
INFO:root:At the start of the epoch: mem (CPU python)=25152.890625MB; mem (CPU total)=24858.65234375MB
INFO:root:[   49] Training loss: 0.63425606, Validation loss: 0.58138454, Gradient norm: 10.88145346
INFO:root:At the start of the epoch: mem (CPU python)=25174.0546875MB; mem (CPU total)=24879.8046875MB
INFO:root:[   50] Training loss: 0.65057306, Validation loss: 0.55123643, Gradient norm: 12.44447298
INFO:root:At the start of the epoch: mem (CPU python)=25195.21875MB; mem (CPU total)=24901.2109375MB
INFO:root:[   51] Training loss: 0.63707970, Validation loss: 0.59188794, Gradient norm: 10.97426453
INFO:root:At the start of the epoch: mem (CPU python)=25216.3828125MB; mem (CPU total)=24922.3515625MB
INFO:root:[   52] Training loss: 0.63747015, Validation loss: 0.53945063, Gradient norm: 11.26179420
INFO:root:At the start of the epoch: mem (CPU python)=25237.55078125MB; mem (CPU total)=24943.49609375MB
INFO:root:[   53] Training loss: 0.63234937, Validation loss: 0.54369707, Gradient norm: 11.42373176
INFO:root:At the start of the epoch: mem (CPU python)=25258.7109375MB; mem (CPU total)=24964.640625MB
INFO:root:[   54] Training loss: 0.63716010, Validation loss: 0.51602232, Gradient norm: 11.90974137
INFO:root:At the start of the epoch: mem (CPU python)=25279.875MB; mem (CPU total)=24986.078125MB
INFO:root:[   55] Training loss: 0.64469886, Validation loss: 0.60480271, Gradient norm: 12.66644194
INFO:root:At the start of the epoch: mem (CPU python)=25301.0390625MB; mem (CPU total)=25007.51171875MB
INFO:root:[   56] Training loss: 0.64072719, Validation loss: 0.52515472, Gradient norm: 12.53766141
INFO:root:At the start of the epoch: mem (CPU python)=25322.203125MB; mem (CPU total)=25028.9375MB
INFO:root:[   57] Training loss: 0.64256510, Validation loss: 0.51612946, Gradient norm: 12.89754720
INFO:root:At the start of the epoch: mem (CPU python)=25343.37109375MB; mem (CPU total)=25049.828125MB
INFO:root:[   58] Training loss: 0.63266258, Validation loss: 0.54320869, Gradient norm: 12.40505082
INFO:root:At the start of the epoch: mem (CPU python)=25364.53515625MB; mem (CPU total)=25070.97265625MB
INFO:root:[   59] Training loss: 0.64276892, Validation loss: 0.55435025, Gradient norm: 13.47350360
INFO:root:At the start of the epoch: mem (CPU python)=25385.69921875MB; mem (CPU total)=25092.125MB
INFO:root:[   60] Training loss: 0.64534053, Validation loss: 0.56541313, Gradient norm: 13.59088187
INFO:root:At the start of the epoch: mem (CPU python)=25406.86328125MB; mem (CPU total)=25113.2890625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 0.64473461, Validation loss: 0.56370184, Gradient norm: 13.26918780
INFO:root:At the start of the epoch: mem (CPU python)=25428.02734375MB; mem (CPU total)=25134.6328125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 0.60107800, Validation loss: 0.49774831, Gradient norm: 10.19812709
INFO:root:At the start of the epoch: mem (CPU python)=25449.19140625MB; mem (CPU total)=25156.05859375MB
INFO:root:[   63] Training loss: 0.57857341, Validation loss: 0.49069709, Gradient norm: 8.30788153
INFO:root:At the start of the epoch: mem (CPU python)=25470.35546875MB; mem (CPU total)=25177.48828125MB
INFO:root:[   64] Training loss: 0.58005758, Validation loss: 0.49795925, Gradient norm: 10.77227928
INFO:root:At the start of the epoch: mem (CPU python)=25491.515625MB; mem (CPU total)=25198.5703125MB
INFO:root:[   65] Training loss: 0.57982792, Validation loss: 0.48759673, Gradient norm: 11.87809008
INFO:root:At the start of the epoch: mem (CPU python)=25512.6796875MB; mem (CPU total)=25220.0078125MB
INFO:root:[   66] Training loss: 0.58248381, Validation loss: 0.48649196, Gradient norm: 14.20308138
INFO:root:At the start of the epoch: mem (CPU python)=25533.84375MB; mem (CPU total)=25240.99609375MB
INFO:root:[   67] Training loss: 0.58220074, Validation loss: 0.50341520, Gradient norm: 14.55098527
INFO:root:At the start of the epoch: mem (CPU python)=25555.0078125MB; mem (CPU total)=25262.14453125MB
INFO:root:[   68] Training loss: 0.58469822, Validation loss: 0.50673028, Gradient norm: 15.98930393
INFO:root:At the start of the epoch: mem (CPU python)=25576.17578125MB; mem (CPU total)=25283.296875MB
INFO:root:[   69] Training loss: 0.58449456, Validation loss: 0.50862281, Gradient norm: 17.15872220
INFO:root:At the start of the epoch: mem (CPU python)=25597.33984375MB; mem (CPU total)=25304.3984375MB
INFO:root:[   70] Training loss: 0.58641180, Validation loss: 0.49413345, Gradient norm: 18.39848498
INFO:root:At the start of the epoch: mem (CPU python)=25618.50390625MB; mem (CPU total)=25325.8046875MB
INFO:root:[   71] Training loss: 0.58567975, Validation loss: 0.49549717, Gradient norm: 18.93071645
INFO:root:At the start of the epoch: mem (CPU python)=25639.6640625MB; mem (CPU total)=25346.9453125MB
INFO:root:[   72] Training loss: 0.58714602, Validation loss: 0.48724769, Gradient norm: 19.73293300
INFO:root:At the start of the epoch: mem (CPU python)=25660.828125MB; mem (CPU total)=25368.31640625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   73] Training loss: 0.58911469, Validation loss: 0.50434045, Gradient norm: 20.88925062
INFO:root:At the start of the epoch: mem (CPU python)=25681.9921875MB; mem (CPU total)=25389.4140625MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   74] Training loss: 0.57289896, Validation loss: 0.48239883, Gradient norm: 14.46262280
INFO:root:At the start of the epoch: mem (CPU python)=25703.16015625MB; mem (CPU total)=25411.8515625MB
INFO:root:[   75] Training loss: 0.56697507, Validation loss: 0.47846018, Gradient norm: 10.40940917
INFO:root:At the start of the epoch: mem (CPU python)=25724.32421875MB; mem (CPU total)=25433.27734375MB
INFO:root:[   76] Training loss: 0.56617466, Validation loss: 0.48072832, Gradient norm: 12.12533616
INFO:root:At the start of the epoch: mem (CPU python)=25745.48828125MB; mem (CPU total)=25454.28125MB
INFO:root:[   77] Training loss: 0.56530679, Validation loss: 0.48244364, Gradient norm: 13.39692105
INFO:root:At the start of the epoch: mem (CPU python)=25766.65234375MB; mem (CPU total)=25475.9921875MB
INFO:root:[   78] Training loss: 0.56536747, Validation loss: 0.48054388, Gradient norm: 14.92055218
INFO:root:At the start of the epoch: mem (CPU python)=25787.81640625MB; mem (CPU total)=25496.890625MB
INFO:root:[   79] Training loss: 0.56470631, Validation loss: 0.48190939, Gradient norm: 15.11904035
INFO:root:At the start of the epoch: mem (CPU python)=25808.98046875MB; mem (CPU total)=25518.0546875MB
INFO:root:[   80] Training loss: 0.56490115, Validation loss: 0.48005988, Gradient norm: 15.71728304
INFO:root:At the start of the epoch: mem (CPU python)=25830.14453125MB; mem (CPU total)=25539.47265625MB
INFO:root:[   81] Training loss: 0.56410453, Validation loss: 0.48183675, Gradient norm: 16.66941417
INFO:root:At the start of the epoch: mem (CPU python)=25851.3046875MB; mem (CPU total)=25560.609375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   82] Training loss: 0.56392337, Validation loss: 0.48068328, Gradient norm: 17.69395091
INFO:root:At the start of the epoch: mem (CPU python)=25872.46875MB; mem (CPU total)=25581.7421875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   83] Training loss: 0.56098884, Validation loss: 0.47673112, Gradient norm: 10.91213111
INFO:root:At the start of the epoch: mem (CPU python)=25893.63671875MB; mem (CPU total)=25602.9296875MB
INFO:root:[   84] Training loss: 0.55919566, Validation loss: 0.47614586, Gradient norm: 8.80636776
INFO:root:At the start of the epoch: mem (CPU python)=25914.80078125MB; mem (CPU total)=25624.12109375MB
INFO:root:[   85] Training loss: 0.55869016, Validation loss: 0.47543414, Gradient norm: 8.96039268
INFO:root:At the start of the epoch: mem (CPU python)=25935.96484375MB; mem (CPU total)=25645.55859375MB
INFO:root:[   86] Training loss: 0.55858811, Validation loss: 0.47658859, Gradient norm: 10.79801956
INFO:root:At the start of the epoch: mem (CPU python)=25957.12890625MB; mem (CPU total)=25666.69921875MB
INFO:root:[   87] Training loss: 0.55802053, Validation loss: 0.47583226, Gradient norm: 11.38611382
INFO:root:At the start of the epoch: mem (CPU python)=25978.29296875MB; mem (CPU total)=25687.73046875MB
INFO:root:[   88] Training loss: 0.55815687, Validation loss: 0.47494049, Gradient norm: 12.45804904
INFO:root:At the start of the epoch: mem (CPU python)=25999.45703125MB; mem (CPU total)=25708.86328125MB
INFO:root:[   89] Training loss: 0.55775042, Validation loss: 0.47762508, Gradient norm: 12.21391221
INFO:root:At the start of the epoch: mem (CPU python)=26020.62109375MB; mem (CPU total)=25730.00390625MB
INFO:root:[   90] Training loss: 0.55748982, Validation loss: 0.47524904, Gradient norm: 12.72588593
INFO:root:At the start of the epoch: mem (CPU python)=26041.78125MB; mem (CPU total)=25751.4296875MB
INFO:root:[   91] Training loss: 0.55691083, Validation loss: 0.47634821, Gradient norm: 12.08559968
INFO:root:At the start of the epoch: mem (CPU python)=26062.94921875MB; mem (CPU total)=25772.58984375MB
INFO:root:[   92] Training loss: 0.55670520, Validation loss: 0.47680252, Gradient norm: 13.89984828
INFO:root:At the start of the epoch: mem (CPU python)=26084.11328125MB; mem (CPU total)=25793.45703125MB
INFO:root:[   93] Training loss: 0.55673467, Validation loss: 0.47591573, Gradient norm: 13.90572380
INFO:root:At the start of the epoch: mem (CPU python)=26105.27734375MB; mem (CPU total)=25814.59765625MB
INFO:root:[   94] Training loss: 0.55626152, Validation loss: 0.47624209, Gradient norm: 12.69292800
INFO:root:At the start of the epoch: mem (CPU python)=26126.44140625MB; mem (CPU total)=25835.72265625MB
INFO:root:[   95] Training loss: 0.55684091, Validation loss: 0.47604882, Gradient norm: 16.89781047
INFO:root:At the start of the epoch: mem (CPU python)=26147.60546875MB; mem (CPU total)=25856.8359375MB
INFO:root:[   96] Training loss: 0.55621269, Validation loss: 0.47466622, Gradient norm: 15.56628216
INFO:root:At the start of the epoch: mem (CPU python)=26168.7734375MB; mem (CPU total)=25878.26171875MB
INFO:root:[   97] Training loss: 0.55610841, Validation loss: 0.47537759, Gradient norm: 19.37880013
INFO:root:At the start of the epoch: mem (CPU python)=26189.93359375MB; mem (CPU total)=25899.66015625MB
INFO:root:[   98] Training loss: 0.55649987, Validation loss: 0.47539169, Gradient norm: 20.64289446
INFO:root:At the start of the epoch: mem (CPU python)=26211.09765625MB; mem (CPU total)=25920.81640625MB
INFO:root:[   99] Training loss: 0.55605728, Validation loss: 0.47464952, Gradient norm: 19.13800438
INFO:root:At the start of the epoch: mem (CPU python)=26232.26171875MB; mem (CPU total)=25941.97265625MB
INFO:root:[  100] Training loss: 0.55626637, Validation loss: 0.47553649, Gradient norm: 20.47894645
INFO:root:At the start of the epoch: mem (CPU python)=26253.421875MB; mem (CPU total)=25963.11328125MB
INFO:root:[  101] Training loss: 0.55545349, Validation loss: 0.47775083, Gradient norm: 16.60259801
INFO:root:At the start of the epoch: mem (CPU python)=26274.58984375MB; mem (CPU total)=25984.2578125MB
INFO:root:[  102] Training loss: 0.55567755, Validation loss: 0.47531682, Gradient norm: 21.58394845
INFO:root:At the start of the epoch: mem (CPU python)=26295.75390625MB; mem (CPU total)=26005.40625MB
INFO:root:[  103] Training loss: 0.55595200, Validation loss: 0.47602977, Gradient norm: 20.21339641
INFO:root:At the start of the epoch: mem (CPU python)=26316.91796875MB; mem (CPU total)=26026.80859375MB
INFO:root:[  104] Training loss: 0.55486709, Validation loss: 0.47439468, Gradient norm: 17.45443520
INFO:root:At the start of the epoch: mem (CPU python)=26338.08203125MB; mem (CPU total)=26048.0390625MB
INFO:root:[  105] Training loss: 0.55552554, Validation loss: 0.47840229, Gradient norm: 22.03752470
INFO:root:At the start of the epoch: mem (CPU python)=26359.24609375MB; mem (CPU total)=26069.1953125MB
INFO:root:[  106] Training loss: 0.55563529, Validation loss: 0.47577516, Gradient norm: 24.98744184
INFO:root:At the start of the epoch: mem (CPU python)=26380.41015625MB; mem (CPU total)=26090.5859375MB
INFO:root:[  107] Training loss: 0.55470837, Validation loss: 0.47365218, Gradient norm: 20.37982804
INFO:root:At the start of the epoch: mem (CPU python)=26401.578125MB; mem (CPU total)=26111.7890625MB
INFO:root:[  108] Training loss: 0.55452994, Validation loss: 0.47621870, Gradient norm: 19.76408043
INFO:root:At the start of the epoch: mem (CPU python)=26422.7421875MB; mem (CPU total)=26131.9765625MB
INFO:root:[  109] Training loss: 0.55475063, Validation loss: 0.47557992, Gradient norm: 20.91221535
INFO:root:At the start of the epoch: mem (CPU python)=26443.90234375MB; mem (CPU total)=26153.16015625MB
INFO:root:[  110] Training loss: 0.55574111, Validation loss: 0.47865653, Gradient norm: 29.90801515
INFO:root:At the start of the epoch: mem (CPU python)=26465.06640625MB; mem (CPU total)=26174.2421875MB
INFO:root:[  111] Training loss: 0.55467828, Validation loss: 0.47465659, Gradient norm: 23.72696862
INFO:root:At the start of the epoch: mem (CPU python)=26486.23046875MB; mem (CPU total)=26195.64453125MB
INFO:root:[  112] Training loss: 0.55501051, Validation loss: 0.47591651, Gradient norm: 20.89138341
INFO:root:At the start of the epoch: mem (CPU python)=26507.3984375MB; mem (CPU total)=26216.8203125MB
INFO:root:[  113] Training loss: 0.55580157, Validation loss: 0.47989964, Gradient norm: 31.26146812
INFO:root:At the start of the epoch: mem (CPU python)=26528.55859375MB; mem (CPU total)=26237.9921875MB
INFO:root:[  114] Training loss: 0.55496283, Validation loss: 0.47592669, Gradient norm: 27.48094771
INFO:root:At the start of the epoch: mem (CPU python)=26549.72265625MB; mem (CPU total)=26259.09375MB
INFO:root:[  115] Training loss: 0.55437259, Validation loss: 0.47680484, Gradient norm: 25.99898301
INFO:root:At the start of the epoch: mem (CPU python)=26570.88671875MB; mem (CPU total)=26280.26171875MB
INFO:root:[  116] Training loss: 0.55485648, Validation loss: 0.47534474, Gradient norm: 24.35671816
INFO:root:At the start of the epoch: mem (CPU python)=26592.05078125MB; mem (CPU total)=26303.171875MB
INFO:root:EP 116: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=26613.21875MB; mem (CPU total)=26322.84765625MB
INFO:root:[  118] Training loss: 0.63975593, Validation loss: 0.55740433, Gradient norm: 19.32535698
INFO:root:At the start of the epoch: mem (CPU python)=26634.3828125MB; mem (CPU total)=26344.1640625MB
INFO:root:[  119] Training loss: 0.63818556, Validation loss: 0.55636024, Gradient norm: 18.89684028
INFO:root:At the start of the epoch: mem (CPU python)=26655.54296875MB; mem (CPU total)=26365.16015625MB
INFO:root:[  120] Training loss: 0.63714915, Validation loss: 0.55582936, Gradient norm: 19.16943664
INFO:root:At the start of the epoch: mem (CPU python)=26676.70703125MB; mem (CPU total)=26386.63671875MB
INFO:root:[  121] Training loss: 0.63646748, Validation loss: 0.55504878, Gradient norm: 22.28520494
INFO:root:At the start of the epoch: mem (CPU python)=26697.87109375MB; mem (CPU total)=26407.79296875MB
INFO:root:[  122] Training loss: 0.63619229, Validation loss: 0.55507599, Gradient norm: 21.34416840
INFO:root:At the start of the epoch: mem (CPU python)=26719.03515625MB; mem (CPU total)=26429.36328125MB
INFO:root:[  123] Training loss: 0.63590182, Validation loss: 0.55490493, Gradient norm: 22.36859976
INFO:root:At the start of the epoch: mem (CPU python)=26740.203125MB; mem (CPU total)=26450.140625MB
INFO:root:[  124] Training loss: 0.63555828, Validation loss: 0.55527891, Gradient norm: 21.61980132
INFO:root:At the start of the epoch: mem (CPU python)=26761.3671875MB; mem (CPU total)=26471.42578125MB
INFO:root:[  125] Training loss: 0.63564714, Validation loss: 0.55454891, Gradient norm: 23.47769777
INFO:root:At the start of the epoch: mem (CPU python)=26782.53125MB; mem (CPU total)=26492.80078125MB
INFO:root:[  126] Training loss: 0.63531350, Validation loss: 0.55491986, Gradient norm: 23.19683647
INFO:root:At the start of the epoch: mem (CPU python)=26803.6953125MB; mem (CPU total)=26513.953125MB
INFO:root:[  127] Training loss: 0.63524805, Validation loss: 0.55427151, Gradient norm: 21.94319065
INFO:root:At the start of the epoch: mem (CPU python)=26824.859375MB; mem (CPU total)=26535.1171875MB
INFO:root:[  128] Training loss: 0.63451952, Validation loss: 0.55543016, Gradient norm: 24.26053827
INFO:root:At the start of the epoch: mem (CPU python)=26846.01953125MB; mem (CPU total)=26555.71875MB
INFO:root:[  129] Training loss: 0.63460045, Validation loss: 0.55552698, Gradient norm: 24.32841055
INFO:root:At the start of the epoch: mem (CPU python)=26867.18359375MB; mem (CPU total)=26576.265625MB
INFO:root:[  130] Training loss: 0.63452632, Validation loss: 0.55330858, Gradient norm: 25.83817754
INFO:root:At the start of the epoch: mem (CPU python)=26888.3515625MB; mem (CPU total)=26597.66796875MB
INFO:root:[  131] Training loss: 0.63454526, Validation loss: 0.55424188, Gradient norm: 26.72069188
INFO:root:At the start of the epoch: mem (CPU python)=26909.51171875MB; mem (CPU total)=26618.484375MB
INFO:root:[  132] Training loss: 0.63405362, Validation loss: 0.55486558, Gradient norm: 24.85372957
INFO:root:At the start of the epoch: mem (CPU python)=26930.67578125MB; mem (CPU total)=26638.05859375MB
INFO:root:[  133] Training loss: 0.63413201, Validation loss: 0.55443271, Gradient norm: 25.95817752
INFO:root:At the start of the epoch: mem (CPU python)=26951.83984375MB; mem (CPU total)=26658.7265625MB
INFO:root:[  134] Training loss: 0.63430618, Validation loss: 0.55420683, Gradient norm: 26.53889737
INFO:root:At the start of the epoch: mem (CPU python)=26973.0078125MB; mem (CPU total)=26679.96875MB
INFO:root:[  135] Training loss: 0.63424192, Validation loss: 0.55429122, Gradient norm: 27.95845202
INFO:root:At the start of the epoch: mem (CPU python)=26994.171875MB; mem (CPU total)=26701.03125MB
INFO:root:[  136] Training loss: 0.63398111, Validation loss: 0.55500733, Gradient norm: 27.75820944
INFO:root:At the start of the epoch: mem (CPU python)=27015.3359375MB; mem (CPU total)=26722.40625MB
INFO:root:[  137] Training loss: 0.63390317, Validation loss: 0.55522720, Gradient norm: 27.63292212
INFO:root:At the start of the epoch: mem (CPU python)=27036.49609375MB; mem (CPU total)=26743.5703125MB
INFO:root:[  138] Training loss: 0.63372645, Validation loss: 0.55269404, Gradient norm: 26.50120189
INFO:root:At the start of the epoch: mem (CPU python)=27057.66015625MB; mem (CPU total)=26764.96875MB
INFO:root:[  139] Training loss: 0.63349119, Validation loss: 0.55305268, Gradient norm: 29.00631561
INFO:root:At the start of the epoch: mem (CPU python)=27078.82421875MB; mem (CPU total)=26785.69140625MB
INFO:root:[  140] Training loss: 0.63352203, Validation loss: 0.55278633, Gradient norm: 29.15141596
INFO:root:At the start of the epoch: mem (CPU python)=27099.9921875MB; mem (CPU total)=26809.14453125MB
INFO:root:[  141] Training loss: 0.63341285, Validation loss: 0.55364164, Gradient norm: 29.56869201
INFO:root:At the start of the epoch: mem (CPU python)=27121.15625MB; mem (CPU total)=26830.53515625MB
INFO:root:[  142] Training loss: 0.63331261, Validation loss: 0.55370490, Gradient norm: 30.23362606
INFO:root:At the start of the epoch: mem (CPU python)=27142.3203125MB; mem (CPU total)=26851.91796875MB
INFO:root:[  143] Training loss: 0.63301290, Validation loss: 0.55343882, Gradient norm: 30.72058898
INFO:root:At the start of the epoch: mem (CPU python)=27163.484375MB; mem (CPU total)=26873.0625MB
INFO:root:[  144] Training loss: 0.63307554, Validation loss: 0.55376852, Gradient norm: 30.46857957
INFO:root:At the start of the epoch: mem (CPU python)=27184.6484375MB; mem (CPU total)=26893.8828125MB
INFO:root:[  145] Training loss: 0.63293299, Validation loss: 0.55255336, Gradient norm: 30.99009291
INFO:root:At the start of the epoch: mem (CPU python)=27205.81640625MB; mem (CPU total)=26915.35546875MB
INFO:root:[  146] Training loss: 0.63294192, Validation loss: 0.55254399, Gradient norm: 31.42436290
INFO:root:At the start of the epoch: mem (CPU python)=27226.9765625MB; mem (CPU total)=26936.7578125MB
INFO:root:[  147] Training loss: 0.63308098, Validation loss: 0.55424753, Gradient norm: 33.42691978
INFO:root:At the start of the epoch: mem (CPU python)=27248.13671875MB; mem (CPU total)=26957.91015625MB
INFO:root:[  148] Training loss: 0.63256695, Validation loss: 0.55371419, Gradient norm: 32.59814737
INFO:root:At the start of the epoch: mem (CPU python)=27269.30078125MB; mem (CPU total)=26979.30859375MB
INFO:root:[  149] Training loss: 0.63244939, Validation loss: 0.55360203, Gradient norm: 34.39645882
INFO:root:At the start of the epoch: mem (CPU python)=27290.46484375MB; mem (CPU total)=26999.79296875MB
INFO:root:[  150] Training loss: 0.63250624, Validation loss: 0.55299614, Gradient norm: 34.52374129
INFO:root:At the start of the epoch: mem (CPU python)=27311.62890625MB; mem (CPU total)=27020.91015625MB
INFO:root:[  151] Training loss: 0.63234581, Validation loss: 0.55359963, Gradient norm: 33.64477236
INFO:root:At the start of the epoch: mem (CPU python)=27332.796875MB; mem (CPU total)=27041.984375MB
INFO:root:[  152] Training loss: 0.63215429, Validation loss: 0.55309980, Gradient norm: 33.94797294
INFO:root:At the start of the epoch: mem (CPU python)=27353.9609375MB; mem (CPU total)=27063.390625MB
INFO:root:[  153] Training loss: 0.63230574, Validation loss: 0.55359565, Gradient norm: 33.10939744
INFO:root:At the start of the epoch: mem (CPU python)=27375.125MB; mem (CPU total)=27084.55078125MB
INFO:root:[  154] Training loss: 0.63196005, Validation loss: 0.55406726, Gradient norm: 36.20168759
INFO:root:At the start of the epoch: mem (CPU python)=27396.2890625MB; mem (CPU total)=27105.44140625MB
INFO:root:[  155] Training loss: 0.63226275, Validation loss: 0.55312859, Gradient norm: 36.46718163
INFO:root:At the start of the epoch: mem (CPU python)=27417.453125MB; mem (CPU total)=27126.6015625MB
INFO:root:EP 155: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=27438.4140625MB; mem (CPU total)=27147.4921875MB
INFO:root:Training the model took 7206.863s.
INFO:root:Emptying the cuda cache took 0.062s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.74362
INFO:root:EnergyScoreValidation: 0.44415
INFO:root:CRPSValidation: 0.19668
INFO:root:Gaussian NLLValidation: 16.16556
INFO:root:CoverageValidation: 0.53168
INFO:root:IntervalWidthValidation: 0.62073
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.65742
INFO:root:EnergyScoreTest: 0.36762
INFO:root:CRPSTest: 0.16594
INFO:root:Gaussian NLLTest: 12.27462
INFO:root:CoverageTest: 0.58718
INFO:root:IntervalWidthTest: 0.66729
INFO:root:After validation: mem (CPU python)=27504.44921875MB; mem (CPU total)=27215.875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=27504.453125MB; mem (CPU total)=27133.62890625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 346030080
INFO:root:After setting up the model: mem (CPU python)=27504.453125MB; mem (CPU total)=27165.50390625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=27504.453125MB; mem (CPU total)=27166.73046875MB
INFO:root:[    1] Training loss: 0.88003774, Validation loss: 0.73872342, Gradient norm: 0.32130336
INFO:root:At the start of the epoch: mem (CPU python)=27504.453125MB; mem (CPU total)=27201.73828125MB
INFO:root:[    2] Training loss: 0.76282338, Validation loss: 0.73333967, Gradient norm: 0.35148656
INFO:root:At the start of the epoch: mem (CPU python)=27509.125MB; mem (CPU total)=27223.0MB
INFO:root:[    3] Training loss: 0.75759491, Validation loss: 0.72835106, Gradient norm: 0.55893525
INFO:root:At the start of the epoch: mem (CPU python)=27530.2890625MB; mem (CPU total)=27244.171875MB
INFO:root:[    4] Training loss: 0.75028747, Validation loss: 0.71601044, Gradient norm: 0.87970244
INFO:root:At the start of the epoch: mem (CPU python)=27551.45703125MB; mem (CPU total)=27265.328125MB
INFO:root:[    5] Training loss: 0.74240579, Validation loss: 0.68890852, Gradient norm: 1.23131374
INFO:root:At the start of the epoch: mem (CPU python)=27572.62109375MB; mem (CPU total)=27286.53125MB
INFO:root:[    6] Training loss: 0.73477056, Validation loss: 0.67547524, Gradient norm: 1.70365076
INFO:root:At the start of the epoch: mem (CPU python)=27593.78515625MB; mem (CPU total)=27307.64453125MB
INFO:root:[    7] Training loss: 0.72705526, Validation loss: 0.67909777, Gradient norm: 2.00227418
INFO:root:At the start of the epoch: mem (CPU python)=27614.94921875MB; mem (CPU total)=27328.80078125MB
INFO:root:[    8] Training loss: 0.72210489, Validation loss: 0.67070965, Gradient norm: 2.16114185
INFO:root:At the start of the epoch: mem (CPU python)=27636.1171875MB; mem (CPU total)=27350.1953125MB
INFO:root:[    9] Training loss: 0.71241981, Validation loss: 0.67816943, Gradient norm: 2.11136255
INFO:root:At the start of the epoch: mem (CPU python)=27657.28125MB; mem (CPU total)=27371.328125MB
INFO:root:[   10] Training loss: 0.71174938, Validation loss: 0.67632088, Gradient norm: 2.53630135
INFO:root:At the start of the epoch: mem (CPU python)=27678.4453125MB; mem (CPU total)=27392.73828125MB
INFO:root:[   11] Training loss: 0.70905994, Validation loss: 0.64146164, Gradient norm: 2.87680533
INFO:root:At the start of the epoch: mem (CPU python)=27699.609375MB; mem (CPU total)=27413.80078125MB
INFO:root:[   12] Training loss: 0.70414117, Validation loss: 0.65604705, Gradient norm: 2.87492695
INFO:root:At the start of the epoch: mem (CPU python)=27720.76953125MB; mem (CPU total)=27434.8359375MB
INFO:root:[   13] Training loss: 0.70180291, Validation loss: 0.63511951, Gradient norm: 3.29457815
INFO:root:At the start of the epoch: mem (CPU python)=27741.9375MB; mem (CPU total)=27456.21875MB
INFO:root:[   14] Training loss: 0.69856569, Validation loss: 0.64975358, Gradient norm: 3.45572793
INFO:root:At the start of the epoch: mem (CPU python)=27763.1015625MB; mem (CPU total)=27477.37890625MB
INFO:root:[   15] Training loss: 0.69790953, Validation loss: 0.65762028, Gradient norm: 3.37022745
INFO:root:At the start of the epoch: mem (CPU python)=27784.26171875MB; mem (CPU total)=27499.02734375MB
INFO:root:[   16] Training loss: 0.69789481, Validation loss: 0.63417007, Gradient norm: 3.54023750
INFO:root:At the start of the epoch: mem (CPU python)=27805.4296875MB; mem (CPU total)=27520.1796875MB
INFO:root:[   17] Training loss: 0.69398754, Validation loss: 0.62086864, Gradient norm: 3.67568057
INFO:root:At the start of the epoch: mem (CPU python)=27826.59375MB; mem (CPU total)=27541.328125MB
INFO:root:[   18] Training loss: 0.68695392, Validation loss: 0.62328584, Gradient norm: 3.49194970
INFO:root:At the start of the epoch: mem (CPU python)=27847.7578125MB; mem (CPU total)=27562.20703125MB
INFO:root:[   19] Training loss: 0.69430890, Validation loss: 0.62805767, Gradient norm: 4.35181724
INFO:root:At the start of the epoch: mem (CPU python)=27868.921875MB; mem (CPU total)=27582.6484375MB
INFO:root:[   20] Training loss: 0.68792523, Validation loss: 0.63063116, Gradient norm: 3.96912497
INFO:root:At the start of the epoch: mem (CPU python)=27890.0859375MB; mem (CPU total)=27604.0546875MB
INFO:root:[   21] Training loss: 0.69234358, Validation loss: 0.62411704, Gradient norm: 4.54449015
INFO:root:At the start of the epoch: mem (CPU python)=27911.24609375MB; mem (CPU total)=27624.26171875MB
INFO:root:[   22] Training loss: 0.68706391, Validation loss: 0.62685540, Gradient norm: 4.43709180
INFO:root:At the start of the epoch: mem (CPU python)=27932.41015625MB; mem (CPU total)=27645.34765625MB
INFO:root:[   23] Training loss: 0.69044266, Validation loss: 0.60797427, Gradient norm: 4.69298664
INFO:root:At the start of the epoch: mem (CPU python)=27953.578125MB; mem (CPU total)=27666.49609375MB
INFO:root:[   24] Training loss: 0.68349179, Validation loss: 0.65866167, Gradient norm: 4.64471420
INFO:root:At the start of the epoch: mem (CPU python)=27974.7421875MB; mem (CPU total)=27687.6171875MB
INFO:root:[   25] Training loss: 0.68999777, Validation loss: 0.62824130, Gradient norm: 5.28015869
INFO:root:At the start of the epoch: mem (CPU python)=27995.90625MB; mem (CPU total)=27709.015625MB
INFO:root:[   26] Training loss: 0.68654350, Validation loss: 0.61575397, Gradient norm: 5.02018045
INFO:root:At the start of the epoch: mem (CPU python)=28017.0703125MB; mem (CPU total)=27730.171875MB
INFO:root:[   27] Training loss: 0.68566350, Validation loss: 0.61414184, Gradient norm: 5.00346102
INFO:root:At the start of the epoch: mem (CPU python)=28038.234375MB; mem (CPU total)=27751.328125MB
INFO:root:[   28] Training loss: 0.68248350, Validation loss: 0.61116060, Gradient norm: 4.80325589
INFO:root:At the start of the epoch: mem (CPU python)=28059.40234375MB; mem (CPU total)=27772.73828125MB
INFO:root:[   29] Training loss: 0.67587059, Validation loss: 0.60202044, Gradient norm: 4.45201046
INFO:root:At the start of the epoch: mem (CPU python)=28080.56640625MB; mem (CPU total)=27793.890625MB
INFO:root:[   30] Training loss: 0.68466275, Validation loss: 0.60537539, Gradient norm: 5.71937370
INFO:root:At the start of the epoch: mem (CPU python)=28101.73046875MB; mem (CPU total)=27815.2890625MB
INFO:root:[   31] Training loss: 0.68103771, Validation loss: 0.63424171, Gradient norm: 5.45022063
INFO:root:At the start of the epoch: mem (CPU python)=28122.890625MB; mem (CPU total)=27836.42578125MB
INFO:root:[   32] Training loss: 0.68723377, Validation loss: 0.61276954, Gradient norm: 6.12669171
INFO:root:At the start of the epoch: mem (CPU python)=28144.05078125MB; mem (CPU total)=27857.609375MB
INFO:root:[   33] Training loss: 0.67910917, Validation loss: 0.61270074, Gradient norm: 5.34830602
INFO:root:At the start of the epoch: mem (CPU python)=28165.21484375MB; mem (CPU total)=27878.73046875MB
INFO:root:[   34] Training loss: 0.68785939, Validation loss: 0.61499461, Gradient norm: 6.56790098
INFO:root:At the start of the epoch: mem (CPU python)=28186.3828125MB; mem (CPU total)=27899.8671875MB
INFO:root:[   35] Training loss: 0.67912932, Validation loss: 0.60215587, Gradient norm: 5.50889284
INFO:root:At the start of the epoch: mem (CPU python)=28207.546875MB; mem (CPU total)=27921.00390625MB
INFO:root:[   36] Training loss: 0.67670711, Validation loss: 0.61085364, Gradient norm: 6.49719692
INFO:root:At the start of the epoch: mem (CPU python)=28228.7109375MB; mem (CPU total)=27942.22265625MB
INFO:root:[   37] Training loss: 0.67662595, Validation loss: 0.60265287, Gradient norm: 6.39762672
INFO:root:At the start of the epoch: mem (CPU python)=28249.875MB; mem (CPU total)=27963.3671875MB
INFO:root:[   38] Training loss: 0.67223365, Validation loss: 0.63105525, Gradient norm: 6.51579894
INFO:root:At the start of the epoch: mem (CPU python)=28271.04296875MB; mem (CPU total)=27984.796875MB
INFO:root:[   39] Training loss: 0.66699499, Validation loss: 0.58837366, Gradient norm: 6.13818562
INFO:root:At the start of the epoch: mem (CPU python)=28292.20703125MB; mem (CPU total)=28006.0MB
INFO:root:[   40] Training loss: 0.66925611, Validation loss: 0.59074317, Gradient norm: 7.00506343
INFO:root:At the start of the epoch: mem (CPU python)=28313.3671875MB; mem (CPU total)=28027.13671875MB
INFO:root:[   41] Training loss: 0.67006388, Validation loss: 0.61756824, Gradient norm: 6.94991728
INFO:root:At the start of the epoch: mem (CPU python)=28334.53125MB; mem (CPU total)=28048.5390625MB
INFO:root:[   42] Training loss: 0.68032644, Validation loss: 0.59724588, Gradient norm: 8.12124218
INFO:root:At the start of the epoch: mem (CPU python)=28355.6953125MB; mem (CPU total)=28069.1640625MB
INFO:root:[   43] Training loss: 0.67040962, Validation loss: 0.58653070, Gradient norm: 7.08390441
INFO:root:At the start of the epoch: mem (CPU python)=28376.86328125MB; mem (CPU total)=28090.08203125MB
INFO:root:[   44] Training loss: 0.67253943, Validation loss: 0.60126413, Gradient norm: 7.24358060
INFO:root:At the start of the epoch: mem (CPU python)=28398.0234375MB; mem (CPU total)=28111.4609375MB
INFO:root:[   45] Training loss: 0.66186302, Validation loss: 0.58886829, Gradient norm: 7.02359559
INFO:root:At the start of the epoch: mem (CPU python)=28419.19140625MB; mem (CPU total)=28132.5234375MB
INFO:root:[   46] Training loss: 0.66856201, Validation loss: 0.57624871, Gradient norm: 7.64560675
INFO:root:At the start of the epoch: mem (CPU python)=28440.35546875MB; mem (CPU total)=28154.13671875MB
INFO:root:[   47] Training loss: 0.67908429, Validation loss: 0.59063963, Gradient norm: 8.65473242
INFO:root:At the start of the epoch: mem (CPU python)=28461.51953125MB; mem (CPU total)=28175.28125MB
INFO:root:[   48] Training loss: 0.66806153, Validation loss: 0.56655576, Gradient norm: 7.37923154
INFO:root:At the start of the epoch: mem (CPU python)=28482.6875MB; mem (CPU total)=28196.44921875MB
INFO:root:[   49] Training loss: 0.66648677, Validation loss: 0.58721039, Gradient norm: 7.61965606
INFO:root:At the start of the epoch: mem (CPU python)=28503.84375MB; mem (CPU total)=28217.5MB
INFO:root:[   50] Training loss: 0.67053352, Validation loss: 0.58332917, Gradient norm: 8.22009043
INFO:root:At the start of the epoch: mem (CPU python)=28525.0078125MB; mem (CPU total)=28238.6640625MB
INFO:root:[   51] Training loss: 0.66876191, Validation loss: 0.59960870, Gradient norm: 7.90547028
INFO:root:At the start of the epoch: mem (CPU python)=28546.171875MB; mem (CPU total)=28260.0703125MB
INFO:root:[   52] Training loss: 0.67041655, Validation loss: 0.63253737, Gradient norm: 7.87486162
INFO:root:At the start of the epoch: mem (CPU python)=28567.3359375MB; mem (CPU total)=28281.234375MB
INFO:root:[   53] Training loss: 0.67289745, Validation loss: 0.62838466, Gradient norm: 8.09086211
INFO:root:At the start of the epoch: mem (CPU python)=28588.5MB; mem (CPU total)=28303.90234375MB
INFO:root:[   54] Training loss: 0.65909207, Validation loss: 0.61120804, Gradient norm: 7.16304141
INFO:root:At the start of the epoch: mem (CPU python)=28609.66796875MB; mem (CPU total)=28325.06640625MB
INFO:root:[   55] Training loss: 0.67617742, Validation loss: 0.57623233, Gradient norm: 8.64757758
INFO:root:At the start of the epoch: mem (CPU python)=28630.83203125MB; mem (CPU total)=28346.140625MB
INFO:root:[   56] Training loss: 0.66652057, Validation loss: 0.59732371, Gradient norm: 7.72494040
INFO:root:At the start of the epoch: mem (CPU python)=28651.99609375MB; mem (CPU total)=28367.3125MB
INFO:root:[   57] Training loss: 0.66436020, Validation loss: 0.56488221, Gradient norm: 7.70059010
INFO:root:At the start of the epoch: mem (CPU python)=28673.16015625MB; mem (CPU total)=28388.80078125MB
INFO:root:[   58] Training loss: 0.66035911, Validation loss: 0.56717859, Gradient norm: 7.79117427
INFO:root:At the start of the epoch: mem (CPU python)=28694.32421875MB; mem (CPU total)=28409.58984375MB
INFO:root:[   59] Training loss: 0.66319568, Validation loss: 0.57512434, Gradient norm: 8.68068316
INFO:root:At the start of the epoch: mem (CPU python)=28715.484375MB; mem (CPU total)=28430.5234375MB
INFO:root:[   60] Training loss: 0.66708042, Validation loss: 0.58101423, Gradient norm: 8.51750470
INFO:root:At the start of the epoch: mem (CPU python)=28736.6484375MB; mem (CPU total)=28451.69921875MB
INFO:root:[   61] Training loss: 0.66648529, Validation loss: 0.59156156, Gradient norm: 8.05634748
INFO:root:At the start of the epoch: mem (CPU python)=28757.81640625MB; mem (CPU total)=28473.85546875MB
INFO:root:[   62] Training loss: 0.66740666, Validation loss: 0.58316173, Gradient norm: 8.31781313
INFO:root:At the start of the epoch: mem (CPU python)=28778.98046875MB; mem (CPU total)=28493.80078125MB
INFO:root:[   63] Training loss: 0.65949945, Validation loss: 0.59614645, Gradient norm: 7.95451872
INFO:root:At the start of the epoch: mem (CPU python)=28800.14453125MB; mem (CPU total)=28516.2109375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   64] Training loss: 0.65435894, Validation loss: 0.62173040, Gradient norm: 7.94230971
INFO:root:At the start of the epoch: mem (CPU python)=28821.30859375MB; mem (CPU total)=28537.328125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   65] Training loss: 0.62689326, Validation loss: 0.54435397, Gradient norm: 6.54078572
INFO:root:At the start of the epoch: mem (CPU python)=28842.4765625MB; mem (CPU total)=28558.81640625MB
INFO:root:[   66] Training loss: 0.61278080, Validation loss: 0.53662712, Gradient norm: 5.22587411
INFO:root:At the start of the epoch: mem (CPU python)=28863.640625MB; mem (CPU total)=28579.2265625MB
INFO:root:[   67] Training loss: 0.61070477, Validation loss: 0.54105170, Gradient norm: 6.22056534
INFO:root:At the start of the epoch: mem (CPU python)=28884.80078125MB; mem (CPU total)=28600.13671875MB
INFO:root:[   68] Training loss: 0.61024724, Validation loss: 0.54174905, Gradient norm: 6.82512560
INFO:root:At the start of the epoch: mem (CPU python)=28905.9609375MB; mem (CPU total)=28621.0859375MB
INFO:root:[   69] Training loss: 0.61120055, Validation loss: 0.53736108, Gradient norm: 7.81205600
INFO:root:At the start of the epoch: mem (CPU python)=28927.125MB; mem (CPU total)=28641.84765625MB
INFO:root:[   70] Training loss: 0.61788867, Validation loss: 0.53598833, Gradient norm: 9.63770755
INFO:root:At the start of the epoch: mem (CPU python)=28948.2890625MB; mem (CPU total)=28662.796875MB
INFO:root:[   71] Training loss: 0.61294434, Validation loss: 0.53848005, Gradient norm: 8.49403422
INFO:root:At the start of the epoch: mem (CPU python)=28969.453125MB; mem (CPU total)=28684.1328125MB
INFO:root:[   72] Training loss: 0.61377494, Validation loss: 0.54215608, Gradient norm: 9.31201446
INFO:root:At the start of the epoch: mem (CPU python)=28990.62109375MB; mem (CPU total)=28705.05078125MB
INFO:root:[   73] Training loss: 0.61348032, Validation loss: 0.54274710, Gradient norm: 9.76537497
INFO:root:At the start of the epoch: mem (CPU python)=29011.78515625MB; mem (CPU total)=28726.203125MB
INFO:root:[   74] Training loss: 0.61441011, Validation loss: 0.53820553, Gradient norm: 10.68309904
INFO:root:At the start of the epoch: mem (CPU python)=29032.94921875MB; mem (CPU total)=28747.3515625MB
INFO:root:[   75] Training loss: 0.61464657, Validation loss: 0.54037466, Gradient norm: 11.04025097
INFO:root:At the start of the epoch: mem (CPU python)=29054.11328125MB; mem (CPU total)=28768.5MB
INFO:root:[   76] Training loss: 0.61545658, Validation loss: 0.54605474, Gradient norm: 11.89878751
INFO:root:At the start of the epoch: mem (CPU python)=29075.27734375MB; mem (CPU total)=28789.6015625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 0.62038204, Validation loss: 0.54340671, Gradient norm: 12.29885196
INFO:root:At the start of the epoch: mem (CPU python)=29096.4453125MB; mem (CPU total)=28811.01171875MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 0.60596793, Validation loss: 0.53432113, Gradient norm: 8.03282388
INFO:root:At the start of the epoch: mem (CPU python)=29117.60546875MB; mem (CPU total)=28832.6640625MB
INFO:root:[   79] Training loss: 0.60215242, Validation loss: 0.53278368, Gradient norm: 5.62686747
INFO:root:At the start of the epoch: mem (CPU python)=29138.76953125MB; mem (CPU total)=28853.74609375MB
INFO:root:[   80] Training loss: 0.60082758, Validation loss: 0.53432240, Gradient norm: 6.79114359
INFO:root:At the start of the epoch: mem (CPU python)=29159.93359375MB; mem (CPU total)=28874.89453125MB
INFO:root:[   81] Training loss: 0.60062204, Validation loss: 0.53503864, Gradient norm: 7.14034850
INFO:root:At the start of the epoch: mem (CPU python)=29181.09765625MB; mem (CPU total)=28896.046875MB
INFO:root:[   82] Training loss: 0.60077313, Validation loss: 0.53417376, Gradient norm: 7.70782052
INFO:root:At the start of the epoch: mem (CPU python)=29202.26171875MB; mem (CPU total)=28916.9609375MB
INFO:root:[   83] Training loss: 0.60070720, Validation loss: 0.53322990, Gradient norm: 8.52495237
INFO:root:At the start of the epoch: mem (CPU python)=29223.421875MB; mem (CPU total)=28939.81640625MB
INFO:root:[   84] Training loss: 0.60063809, Validation loss: 0.53344335, Gradient norm: 8.99612174
INFO:root:At the start of the epoch: mem (CPU python)=29244.58984375MB; mem (CPU total)=28961.04296875MB
INFO:root:[   85] Training loss: 0.60039261, Validation loss: 0.53410414, Gradient norm: 8.93353391
INFO:root:At the start of the epoch: mem (CPU python)=29265.75390625MB; mem (CPU total)=28981.66015625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   86] Training loss: 0.60060271, Validation loss: 0.53115315, Gradient norm: 9.46706265
INFO:root:At the start of the epoch: mem (CPU python)=29286.91796875MB; mem (CPU total)=29003.12890625MB
INFO:root:[   87] Training loss: 0.59885474, Validation loss: 0.53303004, Gradient norm: 5.73317405
INFO:root:At the start of the epoch: mem (CPU python)=29308.078125MB; mem (CPU total)=29024.046875MB
INFO:root:[   88] Training loss: 0.59834003, Validation loss: 0.53113034, Gradient norm: 6.47507023
INFO:root:At the start of the epoch: mem (CPU python)=29329.24609375MB; mem (CPU total)=29045.25390625MB
INFO:root:[   89] Training loss: 0.59871221, Validation loss: 0.53390771, Gradient norm: 8.61215745
INFO:root:At the start of the epoch: mem (CPU python)=29350.41015625MB; mem (CPU total)=29066.40625MB
INFO:root:[   90] Training loss: 0.59828194, Validation loss: 0.53096016, Gradient norm: 8.81197533
INFO:root:At the start of the epoch: mem (CPU python)=29371.57421875MB; mem (CPU total)=29087.31640625MB
INFO:root:[   91] Training loss: 0.59825514, Validation loss: 0.53235828, Gradient norm: 8.11106134
INFO:root:At the start of the epoch: mem (CPU python)=29392.73828125MB; mem (CPU total)=29109.45703125MB
INFO:root:[   92] Training loss: 0.59878228, Validation loss: 0.53204395, Gradient norm: 11.51669491
INFO:root:At the start of the epoch: mem (CPU python)=29413.90234375MB; mem (CPU total)=29130.61328125MB
INFO:root:[   93] Training loss: 0.59820842, Validation loss: 0.53163131, Gradient norm: 9.65300134
INFO:root:At the start of the epoch: mem (CPU python)=29435.06640625MB; mem (CPU total)=29151.98828125MB
INFO:root:[   94] Training loss: 0.59775480, Validation loss: 0.53271185, Gradient norm: 8.67383684
INFO:root:At the start of the epoch: mem (CPU python)=29456.234375MB; mem (CPU total)=29173.15234375MB
INFO:root:[   95] Training loss: 0.59771153, Validation loss: 0.53345603, Gradient norm: 8.88510550
INFO:root:At the start of the epoch: mem (CPU python)=29477.3984375MB; mem (CPU total)=29193.97265625MB
INFO:root:[   96] Training loss: 0.59742811, Validation loss: 0.53243338, Gradient norm: 9.18464939
INFO:root:At the start of the epoch: mem (CPU python)=29498.5625MB; mem (CPU total)=29214.828125MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   97] Training loss: 0.59739199, Validation loss: 0.53145768, Gradient norm: 9.61539056
INFO:root:At the start of the epoch: mem (CPU python)=29519.72265625MB; mem (CPU total)=29235.05859375MB
INFO:root:[   98] Training loss: 0.59650501, Validation loss: 0.53171302, Gradient norm: 7.49585301
INFO:root:At the start of the epoch: mem (CPU python)=29540.88671875MB; mem (CPU total)=29255.96875MB
INFO:root:[   99] Training loss: 0.59666139, Validation loss: 0.53110702, Gradient norm: 7.65414547
INFO:root:At the start of the epoch: mem (CPU python)=29562.05078125MB; mem (CPU total)=29277.37109375MB
INFO:root:[  100] Training loss: 0.59661496, Validation loss: 0.53076723, Gradient norm: 7.89950826
INFO:root:At the start of the epoch: mem (CPU python)=29583.21875MB; mem (CPU total)=29298.76953125MB
INFO:root:[  101] Training loss: 0.59623066, Validation loss: 0.53115318, Gradient norm: 7.97591963
INFO:root:At the start of the epoch: mem (CPU python)=29604.37890625MB; mem (CPU total)=29319.93359375MB
INFO:root:[  102] Training loss: 0.59621910, Validation loss: 0.53186063, Gradient norm: 7.27455806
INFO:root:At the start of the epoch: mem (CPU python)=29625.54296875MB; mem (CPU total)=29341.09765625MB
INFO:root:[  103] Training loss: 0.59613468, Validation loss: 0.53027267, Gradient norm: 8.58401341
INFO:root:At the start of the epoch: mem (CPU python)=29646.70703125MB; mem (CPU total)=29362.5MB
INFO:root:[  104] Training loss: 0.59589243, Validation loss: 0.53176695, Gradient norm: 9.54575403
INFO:root:At the start of the epoch: mem (CPU python)=29667.87109375MB; mem (CPU total)=29383.55859375MB
INFO:root:[  105] Training loss: 0.59580338, Validation loss: 0.53164801, Gradient norm: 8.69464978
INFO:root:At the start of the epoch: mem (CPU python)=29689.03515625MB; mem (CPU total)=29404.6953125MB
INFO:root:[  106] Training loss: 0.59631608, Validation loss: 0.53026244, Gradient norm: 10.57661432
INFO:root:At the start of the epoch: mem (CPU python)=29710.19921875MB; mem (CPU total)=29425.8671875MB
INFO:root:[  107] Training loss: 0.59568456, Validation loss: 0.53036171, Gradient norm: 8.83966112
INFO:root:At the start of the epoch: mem (CPU python)=29731.36328125MB; mem (CPU total)=29446.92578125MB
INFO:root:[  108] Training loss: 0.59559708, Validation loss: 0.53134173, Gradient norm: 9.68857454
INFO:root:At the start of the epoch: mem (CPU python)=29752.52734375MB; mem (CPU total)=29468.08984375MB
INFO:root:[  109] Training loss: 0.59625730, Validation loss: 0.53143383, Gradient norm: 13.35639756
INFO:root:At the start of the epoch: mem (CPU python)=29773.69140625MB; mem (CPU total)=29489.51171875MB
INFO:root:[  110] Training loss: 0.59590808, Validation loss: 0.53120787, Gradient norm: 10.36951681
INFO:root:At the start of the epoch: mem (CPU python)=29794.85546875MB; mem (CPU total)=29510.609375MB
INFO:root:[  111] Training loss: 0.59605131, Validation loss: 0.53115756, Gradient norm: 14.01707754
INFO:root:At the start of the epoch: mem (CPU python)=29816.49609375MB; mem (CPU total)=29532.73046875MB
INFO:root:[  112] Training loss: 0.59562189, Validation loss: 0.53177122, Gradient norm: 10.61026042
INFO:root:At the start of the epoch: mem (CPU python)=29838.3125MB; mem (CPU total)=29553.63671875MB
INFO:root:[  113] Training loss: 0.59574445, Validation loss: 0.53112305, Gradient norm: 14.23983186
INFO:root:At the start of the epoch: mem (CPU python)=29859.4765625MB; mem (CPU total)=29574.765625MB
INFO:root:[  114] Training loss: 0.59585279, Validation loss: 0.53119950, Gradient norm: 13.71059913
INFO:root:At the start of the epoch: mem (CPU python)=29880.640625MB; mem (CPU total)=29595.90625MB
INFO:root:[  115] Training loss: 0.59513562, Validation loss: 0.53149652, Gradient norm: 11.58267549
INFO:root:At the start of the epoch: mem (CPU python)=29901.80078125MB; mem (CPU total)=29617.5234375MB
INFO:root:EP 115: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=29923.20703125MB; mem (CPU total)=29639.40234375MB
INFO:root:[  117] Training loss: 0.68331231, Validation loss: 0.61464084, Gradient norm: 11.45000900
INFO:root:At the start of the epoch: mem (CPU python)=29944.8828125MB; mem (CPU total)=29660.8671875MB
INFO:root:[  118] Training loss: 0.68115885, Validation loss: 0.61387069, Gradient norm: 11.82626116
INFO:root:At the start of the epoch: mem (CPU python)=29966.04296875MB; mem (CPU total)=29681.37890625MB
INFO:root:[  119] Training loss: 0.68046096, Validation loss: 0.61394941, Gradient norm: 11.10712385
INFO:root:At the start of the epoch: mem (CPU python)=29987.20703125MB; mem (CPU total)=29702.75390625MB
INFO:root:[  120] Training loss: 0.68026118, Validation loss: 0.61212272, Gradient norm: 11.00850637
INFO:root:At the start of the epoch: mem (CPU python)=30008.375MB; mem (CPU total)=29724.12109375MB
INFO:root:[  121] Training loss: 0.67963128, Validation loss: 0.61239077, Gradient norm: 11.69629828
INFO:root:At the start of the epoch: mem (CPU python)=30029.53515625MB; mem (CPU total)=29744.98828125MB
INFO:root:[  122] Training loss: 0.67941039, Validation loss: 0.61218055, Gradient norm: 12.30599635
INFO:root:At the start of the epoch: mem (CPU python)=30050.703125MB; mem (CPU total)=29765.85546875MB
INFO:root:[  123] Training loss: 0.67911982, Validation loss: 0.61217149, Gradient norm: 12.99952014
INFO:root:At the start of the epoch: mem (CPU python)=30071.8671875MB; mem (CPU total)=29786.91796875MB
INFO:root:[  124] Training loss: 0.67905883, Validation loss: 0.61226715, Gradient norm: 12.60695968
INFO:root:At the start of the epoch: mem (CPU python)=30093.03125MB; mem (CPU total)=29808.2890625MB
INFO:root:[  125] Training loss: 0.67871306, Validation loss: 0.61209446, Gradient norm: 14.50999811
INFO:root:At the start of the epoch: mem (CPU python)=30114.19140625MB; mem (CPU total)=29829.71875MB
INFO:root:[  126] Training loss: 0.67847054, Validation loss: 0.61159455, Gradient norm: 13.16123660
INFO:root:At the start of the epoch: mem (CPU python)=30135.35546875MB; mem (CPU total)=29850.73828125MB
INFO:root:[  127] Training loss: 0.67850660, Validation loss: 0.61187773, Gradient norm: 12.72714126
INFO:root:At the start of the epoch: mem (CPU python)=30156.51953125MB; mem (CPU total)=29871.875MB
INFO:root:[  128] Training loss: 0.67808314, Validation loss: 0.61118949, Gradient norm: 14.18005407
INFO:root:At the start of the epoch: mem (CPU python)=30177.6875MB; mem (CPU total)=29892.984375MB
INFO:root:[  129] Training loss: 0.67794808, Validation loss: 0.61148888, Gradient norm: 13.14129992
INFO:root:At the start of the epoch: mem (CPU python)=30198.8515625MB; mem (CPU total)=29914.1484375MB
INFO:root:[  130] Training loss: 0.67771033, Validation loss: 0.61093173, Gradient norm: 13.51275673
INFO:root:At the start of the epoch: mem (CPU python)=30220.015625MB; mem (CPU total)=29935.765625MB
INFO:root:[  131] Training loss: 0.67767927, Validation loss: 0.61240666, Gradient norm: 13.80026544
INFO:root:At the start of the epoch: mem (CPU python)=30241.1796875MB; mem (CPU total)=29956.94921875MB
INFO:root:[  132] Training loss: 0.67720001, Validation loss: 0.61055044, Gradient norm: 14.23586814
INFO:root:At the start of the epoch: mem (CPU python)=30262.34375MB; mem (CPU total)=29978.125MB
INFO:root:[  133] Training loss: 0.67739412, Validation loss: 0.61109582, Gradient norm: 15.40132875
INFO:root:At the start of the epoch: mem (CPU python)=30283.5078125MB; mem (CPU total)=29999.265625MB
INFO:root:[  134] Training loss: 0.67716276, Validation loss: 0.60955605, Gradient norm: 16.74418782
INFO:root:At the start of the epoch: mem (CPU python)=30304.671875MB; mem (CPU total)=30020.65234375MB
INFO:root:[  135] Training loss: 0.67703650, Validation loss: 0.60924636, Gradient norm: 14.94626200
INFO:root:At the start of the epoch: mem (CPU python)=30325.83203125MB; mem (CPU total)=30041.6875MB
INFO:root:[  136] Training loss: 0.67675185, Validation loss: 0.61025089, Gradient norm: 17.63490184
INFO:root:At the start of the epoch: mem (CPU python)=30346.99609375MB; mem (CPU total)=30063.078125MB
INFO:root:[  137] Training loss: 0.67681928, Validation loss: 0.61042050, Gradient norm: 15.84112737
INFO:root:At the start of the epoch: mem (CPU python)=30368.16015625MB; mem (CPU total)=30084.21875MB
INFO:root:[  138] Training loss: 0.67669857, Validation loss: 0.60994574, Gradient norm: 16.35933981
INFO:root:At the start of the epoch: mem (CPU python)=30389.32421875MB; mem (CPU total)=30105.61328125MB
INFO:root:[  139] Training loss: 0.67666555, Validation loss: 0.60941074, Gradient norm: 16.42673380
INFO:root:At the start of the epoch: mem (CPU python)=30410.4921875MB; mem (CPU total)=30126.9453125MB
INFO:root:[  140] Training loss: 0.67683004, Validation loss: 0.61045140, Gradient norm: 18.59208663
INFO:root:At the start of the epoch: mem (CPU python)=30431.65625MB; mem (CPU total)=30147.8515625MB
INFO:root:[  141] Training loss: 0.67683574, Validation loss: 0.60985077, Gradient norm: 18.87690315
INFO:root:At the start of the epoch: mem (CPU python)=30452.8203125MB; mem (CPU total)=30168.98828125MB
INFO:root:[  142] Training loss: 0.67637522, Validation loss: 0.60972149, Gradient norm: 17.52736369
INFO:root:At the start of the epoch: mem (CPU python)=30473.984375MB; mem (CPU total)=30190.14453125MB
INFO:root:[  143] Training loss: 0.67639039, Validation loss: 0.60913848, Gradient norm: 17.77333294
INFO:root:At the start of the epoch: mem (CPU python)=30495.1484375MB; mem (CPU total)=30211.6171875MB
INFO:root:[  144] Training loss: 0.67635403, Validation loss: 0.61006375, Gradient norm: 19.30911351
INFO:root:At the start of the epoch: mem (CPU python)=30516.30859375MB; mem (CPU total)=30233.3046875MB
INFO:root:[  145] Training loss: 0.67631983, Validation loss: 0.61025152, Gradient norm: 19.75293373
INFO:root:At the start of the epoch: mem (CPU python)=30537.4765625MB; mem (CPU total)=30253.58984375MB
INFO:root:[  146] Training loss: 0.67586647, Validation loss: 0.60906259, Gradient norm: 21.46121846
INFO:root:At the start of the epoch: mem (CPU python)=30558.640625MB; mem (CPU total)=30274.7265625MB
INFO:root:[  147] Training loss: 0.67587554, Validation loss: 0.60913258, Gradient norm: 20.01215643
INFO:root:At the start of the epoch: mem (CPU python)=30579.8046875MB; mem (CPU total)=30295.87109375MB
INFO:root:[  148] Training loss: 0.67606004, Validation loss: 0.60934157, Gradient norm: 20.28526429
INFO:root:At the start of the epoch: mem (CPU python)=30600.96875MB; mem (CPU total)=30316.9921875MB
INFO:root:[  149] Training loss: 0.67564167, Validation loss: 0.60957416, Gradient norm: 19.34560802
INFO:root:At the start of the epoch: mem (CPU python)=30622.1328125MB; mem (CPU total)=30337.87109375MB
INFO:root:[  150] Training loss: 0.67537565, Validation loss: 0.61004017, Gradient norm: 19.69474750
INFO:root:At the start of the epoch: mem (CPU python)=30643.30078125MB; mem (CPU total)=30359.08984375MB
INFO:root:[  151] Training loss: 0.67548783, Validation loss: 0.60865171, Gradient norm: 20.05930869
INFO:root:At the start of the epoch: mem (CPU python)=30664.46484375MB; mem (CPU total)=30380.22265625MB
INFO:root:[  152] Training loss: 0.67551800, Validation loss: 0.60986160, Gradient norm: 21.21000671
INFO:root:At the start of the epoch: mem (CPU python)=30685.625MB; mem (CPU total)=30401.38671875MB
INFO:root:[  153] Training loss: 0.67571733, Validation loss: 0.60879836, Gradient norm: 21.66869234
INFO:root:At the start of the epoch: mem (CPU python)=30706.78515625MB; mem (CPU total)=30422.54296875MB
INFO:root:[  154] Training loss: 0.67558030, Validation loss: 0.60989653, Gradient norm: 22.14443011
INFO:root:At the start of the epoch: mem (CPU python)=30727.94921875MB; mem (CPU total)=30443.6953125MB
INFO:root:[  155] Training loss: 0.67538401, Validation loss: 0.61005853, Gradient norm: 21.06803212
INFO:root:At the start of the epoch: mem (CPU python)=30749.11328125MB; mem (CPU total)=30466.078125MB
INFO:root:[  156] Training loss: 0.67564525, Validation loss: 0.60952993, Gradient norm: 23.35021090
INFO:root:At the start of the epoch: mem (CPU python)=30770.28125MB; mem (CPU total)=30487.48828125MB
INFO:root:[  157] Training loss: 0.67552494, Validation loss: 0.60964927, Gradient norm: 23.90354416
INFO:root:At the start of the epoch: mem (CPU python)=30791.4453125MB; mem (CPU total)=30508.8984375MB
INFO:root:[  158] Training loss: 0.67505771, Validation loss: 0.60956420, Gradient norm: 22.48485159
INFO:root:At the start of the epoch: mem (CPU python)=30812.609375MB; mem (CPU total)=30531.30078125MB
INFO:root:[  159] Training loss: 0.67524448, Validation loss: 0.60859995, Gradient norm: 22.69966082
INFO:root:At the start of the epoch: mem (CPU python)=30833.7734375MB; mem (CPU total)=30552.84375MB
INFO:root:[  160] Training loss: 0.67500619, Validation loss: 0.60816984, Gradient norm: 23.96099037
INFO:root:At the start of the epoch: mem (CPU python)=30854.9375MB; mem (CPU total)=30573.30859375MB
INFO:root:[  161] Training loss: 0.67479444, Validation loss: 0.60941848, Gradient norm: 22.01138163
INFO:root:At the start of the epoch: mem (CPU python)=30876.1015625MB; mem (CPU total)=30594.19140625MB
INFO:root:[  162] Training loss: 0.67509816, Validation loss: 0.60873228, Gradient norm: 24.58305061
INFO:root:At the start of the epoch: mem (CPU python)=30897.26953125MB; mem (CPU total)=30614.76953125MB
INFO:root:[  163] Training loss: 0.67520978, Validation loss: 0.60894945, Gradient norm: 23.51544745
INFO:root:At the start of the epoch: mem (CPU python)=30918.4296875MB; mem (CPU total)=30635.92578125MB
INFO:root:[  164] Training loss: 0.67487377, Validation loss: 0.60949165, Gradient norm: 26.31248977
INFO:root:At the start of the epoch: mem (CPU python)=30939.59375MB; mem (CPU total)=30657.078125MB
INFO:root:[  165] Training loss: 0.67481255, Validation loss: 0.60876334, Gradient norm: 23.98280531
INFO:root:At the start of the epoch: mem (CPU python)=30960.7578125MB; mem (CPU total)=30677.91796875MB
INFO:root:[  166] Training loss: 0.67471139, Validation loss: 0.60889917, Gradient norm: 24.20134973
INFO:root:At the start of the epoch: mem (CPU python)=30981.921875MB; mem (CPU total)=30699.546875MB
INFO:root:[  167] Training loss: 0.67473893, Validation loss: 0.60889878, Gradient norm: 24.40235330
INFO:root:At the start of the epoch: mem (CPU python)=31003.08984375MB; mem (CPU total)=30720.66796875MB
INFO:root:[  168] Training loss: 0.67483313, Validation loss: 0.60850273, Gradient norm: 27.17801897
INFO:root:At the start of the epoch: mem (CPU python)=31024.25MB; mem (CPU total)=30741.25390625MB
INFO:root:[  169] Training loss: 0.67456267, Validation loss: 0.60861359, Gradient norm: 25.20184789
INFO:root:At the start of the epoch: mem (CPU python)=31045.4140625MB; mem (CPU total)=30762.16015625MB
INFO:root:EP 169: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=31066.37109375MB; mem (CPU total)=30783.08203125MB
INFO:root:Training the model took 8663.272s.
INFO:root:Emptying the cuda cache took 0.064s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.93898
INFO:root:EnergyScoreValidation: 0.52565
INFO:root:CRPSValidation: 0.23912
INFO:root:Gaussian NLLValidation: 11.09987
INFO:root:CoverageValidation: 0.58286
INFO:root:IntervalWidthValidation: 0.9473
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87007
INFO:root:EnergyScoreTest: 0.46336
INFO:root:CRPSTest: 0.21007
INFO:root:Gaussian NLLTest: 6.3997
INFO:root:CoverageTest: 0.63439
INFO:root:IntervalWidthTest: 1.03396
INFO:root:After validation: mem (CPU python)=31099.06640625MB; mem (CPU total)=30791.2421875MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=31099.06640625MB; mem (CPU total)=30790.6328125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 346030080
INFO:root:After setting up the model: mem (CPU python)=31099.06640625MB; mem (CPU total)=30802.6328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=31099.06640625MB; mem (CPU total)=30802.62109375MB
INFO:root:[    1] Training loss: 0.89065444, Validation loss: 0.73907437, Gradient norm: 0.32276806
INFO:root:At the start of the epoch: mem (CPU python)=31102.44140625MB; mem (CPU total)=30823.5625MB
INFO:root:[    2] Training loss: 0.76919994, Validation loss: 0.73546534, Gradient norm: 0.34410750
INFO:root:At the start of the epoch: mem (CPU python)=31123.609375MB; mem (CPU total)=30844.5859375MB
INFO:root:[    3] Training loss: 0.76278654, Validation loss: 0.74772408, Gradient norm: 0.46887921
INFO:root:At the start of the epoch: mem (CPU python)=31144.76953125MB; mem (CPU total)=30865.98046875MB
INFO:root:[    4] Training loss: 0.75692556, Validation loss: 0.72046959, Gradient norm: 0.77012648
INFO:root:At the start of the epoch: mem (CPU python)=31165.94140625MB; mem (CPU total)=30886.98828125MB
INFO:root:[    5] Training loss: 0.75037652, Validation loss: 0.69914053, Gradient norm: 1.16434278
INFO:root:At the start of the epoch: mem (CPU python)=31187.09765625MB; mem (CPU total)=30907.765625MB
INFO:root:[    6] Training loss: 0.74374110, Validation loss: 0.71465143, Gradient norm: 1.72955408
INFO:root:At the start of the epoch: mem (CPU python)=31208.2578125MB; mem (CPU total)=30929.32421875MB
INFO:root:[    7] Training loss: 0.73738302, Validation loss: 0.70345526, Gradient norm: 2.05835459
INFO:root:At the start of the epoch: mem (CPU python)=31229.42578125MB; mem (CPU total)=30950.46875MB
INFO:root:[    8] Training loss: 0.73579925, Validation loss: 0.67585400, Gradient norm: 2.19310712
INFO:root:At the start of the epoch: mem (CPU python)=31250.58984375MB; mem (CPU total)=30971.2578125MB
INFO:root:[    9] Training loss: 0.72991207, Validation loss: 0.67745604, Gradient norm: 2.28451903
INFO:root:At the start of the epoch: mem (CPU python)=31271.75390625MB; mem (CPU total)=30992.421875MB
INFO:root:[   10] Training loss: 0.72154543, Validation loss: 0.65362869, Gradient norm: 2.64923987
INFO:root:At the start of the epoch: mem (CPU python)=31292.921875MB; mem (CPU total)=31013.5703125MB
INFO:root:[   11] Training loss: 0.72239453, Validation loss: 0.66144633, Gradient norm: 2.91894973
INFO:root:At the start of the epoch: mem (CPU python)=31314.0859375MB; mem (CPU total)=31034.0234375MB
INFO:root:[   12] Training loss: 0.72819738, Validation loss: 0.65949474, Gradient norm: 3.25707653
INFO:root:At the start of the epoch: mem (CPU python)=31335.25MB; mem (CPU total)=31054.93359375MB
INFO:root:[   13] Training loss: 0.72061870, Validation loss: 0.66430212, Gradient norm: 3.08501637
INFO:root:At the start of the epoch: mem (CPU python)=31368.4140625MB; mem (CPU total)=31088.34375MB
INFO:root:[   14] Training loss: 0.71620319, Validation loss: 0.66199127, Gradient norm: 3.42960490
INFO:root:At the start of the epoch: mem (CPU python)=31389.57421875MB; mem (CPU total)=31109.46484375MB
INFO:root:[   15] Training loss: 0.71813998, Validation loss: 0.66990904, Gradient norm: 3.77518176
INFO:root:At the start of the epoch: mem (CPU python)=31410.73828125MB; mem (CPU total)=31130.59375MB
INFO:root:[   16] Training loss: 0.72092022, Validation loss: 0.65893861, Gradient norm: 3.87308775
INFO:root:At the start of the epoch: mem (CPU python)=31431.90625MB; mem (CPU total)=31151.94921875MB
INFO:root:[   17] Training loss: 0.71387424, Validation loss: 0.64379235, Gradient norm: 3.49784135
INFO:root:At the start of the epoch: mem (CPU python)=31453.0703125MB; mem (CPU total)=31173.34765625MB
INFO:root:[   18] Training loss: 0.71524079, Validation loss: 0.65575822, Gradient norm: 4.05649810
INFO:root:At the start of the epoch: mem (CPU python)=31474.234375MB; mem (CPU total)=31194.75390625MB
INFO:root:[   19] Training loss: 0.71259595, Validation loss: 0.63730244, Gradient norm: 4.27403704
INFO:root:At the start of the epoch: mem (CPU python)=31495.3984375MB; mem (CPU total)=31215.95703125MB
INFO:root:[   20] Training loss: 0.70770199, Validation loss: 0.63757344, Gradient norm: 4.31613661
INFO:root:At the start of the epoch: mem (CPU python)=31516.55859375MB; mem (CPU total)=31236.86328125MB
INFO:root:[   21] Training loss: 0.70706596, Validation loss: 0.64917042, Gradient norm: 4.48707625
INFO:root:At the start of the epoch: mem (CPU python)=31537.7265625MB; mem (CPU total)=31258.00390625MB
INFO:root:[   22] Training loss: 0.70946649, Validation loss: 0.66350101, Gradient norm: 4.85535916
INFO:root:At the start of the epoch: mem (CPU python)=31558.890625MB; mem (CPU total)=31279.12890625MB
INFO:root:[   23] Training loss: 0.70315470, Validation loss: 0.65461837, Gradient norm: 4.58844308
INFO:root:At the start of the epoch: mem (CPU python)=31580.0546875MB; mem (CPU total)=31300.21484375MB
INFO:root:[   24] Training loss: 0.70909480, Validation loss: 0.61713696, Gradient norm: 5.19800917
INFO:root:At the start of the epoch: mem (CPU python)=31601.21875MB; mem (CPU total)=31321.62890625MB
INFO:root:[   25] Training loss: 0.70485920, Validation loss: 0.63133220, Gradient norm: 4.91849348
INFO:root:At the start of the epoch: mem (CPU python)=31622.37890625MB; mem (CPU total)=31343.0546875MB
INFO:root:[   26] Training loss: 0.69933931, Validation loss: 0.61997296, Gradient norm: 4.91758076
INFO:root:At the start of the epoch: mem (CPU python)=31643.546875MB; mem (CPU total)=31364.21875MB
INFO:root:[   27] Training loss: 0.71292747, Validation loss: 0.63301765, Gradient norm: 5.87742329
INFO:root:At the start of the epoch: mem (CPU python)=31664.7109375MB; mem (CPU total)=31385.375MB
INFO:root:[   28] Training loss: 0.70794316, Validation loss: 0.65181348, Gradient norm: 5.96611505
INFO:root:At the start of the epoch: mem (CPU python)=31685.875MB; mem (CPU total)=31406.5390625MB
INFO:root:[   29] Training loss: 0.71044931, Validation loss: 0.62182458, Gradient norm: 6.00134377
INFO:root:At the start of the epoch: mem (CPU python)=31707.0390625MB; mem (CPU total)=31427.4375MB
INFO:root:[   30] Training loss: 0.70865983, Validation loss: 0.63264713, Gradient norm: 5.86330337
INFO:root:At the start of the epoch: mem (CPU python)=31728.20703125MB; mem (CPU total)=31448.76953125MB
INFO:root:[   31] Training loss: 0.70840332, Validation loss: 0.63945523, Gradient norm: 6.12538590
INFO:root:At the start of the epoch: mem (CPU python)=31749.37109375MB; mem (CPU total)=31469.91796875MB
INFO:root:[   32] Training loss: 0.69738759, Validation loss: 0.62114947, Gradient norm: 5.40883960
INFO:root:At the start of the epoch: mem (CPU python)=31770.53515625MB; mem (CPU total)=31490.8828125MB
INFO:root:[   33] Training loss: 0.70642869, Validation loss: 0.64246201, Gradient norm: 6.39177701
INFO:root:At the start of the epoch: mem (CPU python)=31791.6953125MB; mem (CPU total)=31512.03515625MB
INFO:root:[   34] Training loss: 0.71006394, Validation loss: 0.65878859, Gradient norm: 6.85693835
INFO:root:At the start of the epoch: mem (CPU python)=31812.859375MB; mem (CPU total)=31533.1796875MB
INFO:root:[   35] Training loss: 0.70820759, Validation loss: 0.66847271, Gradient norm: 6.84747478
INFO:root:At the start of the epoch: mem (CPU python)=31834.0234375MB; mem (CPU total)=31554.5703125MB
INFO:root:[   36] Training loss: 0.70196821, Validation loss: 0.63116753, Gradient norm: 6.29423096
INFO:root:At the start of the epoch: mem (CPU python)=31855.19140625MB; mem (CPU total)=31575.9609375MB
INFO:root:[   37] Training loss: 0.70587603, Validation loss: 0.62009623, Gradient norm: 6.94141965
INFO:root:At the start of the epoch: mem (CPU python)=31876.3515625MB; mem (CPU total)=31597.1484375MB
INFO:root:[   38] Training loss: 0.71325407, Validation loss: 0.68270383, Gradient norm: 7.44484890
INFO:root:At the start of the epoch: mem (CPU python)=31897.515625MB; mem (CPU total)=31618.3125MB
INFO:root:[   39] Training loss: 0.70721245, Validation loss: 0.62562725, Gradient norm: 7.21733587
INFO:root:At the start of the epoch: mem (CPU python)=31918.6796875MB; mem (CPU total)=31639.4609375MB
INFO:root:[   40] Training loss: 0.70538920, Validation loss: 0.62259920, Gradient norm: 7.04849715
INFO:root:At the start of the epoch: mem (CPU python)=31939.84375MB; mem (CPU total)=31660.61328125MB
INFO:root:[   41] Training loss: 0.70814982, Validation loss: 0.60949379, Gradient norm: 7.70567104
INFO:root:At the start of the epoch: mem (CPU python)=31961.01171875MB; mem (CPU total)=31682.5625MB
INFO:root:[   42] Training loss: 0.71290360, Validation loss: 0.66841678, Gradient norm: 8.09537831
INFO:root:At the start of the epoch: mem (CPU python)=31982.171875MB; mem (CPU total)=31703.7265625MB
INFO:root:[   43] Training loss: 0.70799812, Validation loss: 0.62440112, Gradient norm: 7.65775277
INFO:root:At the start of the epoch: mem (CPU python)=32003.3359375MB; mem (CPU total)=31724.890625MB
INFO:root:[   44] Training loss: 0.70892216, Validation loss: 0.64212669, Gradient norm: 8.13573854
INFO:root:At the start of the epoch: mem (CPU python)=32024.5MB; mem (CPU total)=31745.78515625MB
INFO:root:[   45] Training loss: 0.70592133, Validation loss: 0.64657425, Gradient norm: 7.96702394
INFO:root:At the start of the epoch: mem (CPU python)=32045.6640625MB; mem (CPU total)=31767.15625MB
INFO:root:[   46] Training loss: 0.71061800, Validation loss: 0.61487607, Gradient norm: 7.84831047
INFO:root:At the start of the epoch: mem (CPU python)=32066.828125MB; mem (CPU total)=31788.30859375MB
INFO:root:[   47] Training loss: 0.69913314, Validation loss: 0.60262962, Gradient norm: 7.71336854
INFO:root:At the start of the epoch: mem (CPU python)=32087.99609375MB; mem (CPU total)=31809.45703125MB
INFO:root:[   48] Training loss: 0.70816240, Validation loss: 0.59598313, Gradient norm: 8.66487564
INFO:root:At the start of the epoch: mem (CPU python)=32109.16015625MB; mem (CPU total)=31830.84765625MB
INFO:root:[   49] Training loss: 0.71216909, Validation loss: 0.61155293, Gradient norm: 8.86626941
INFO:root:At the start of the epoch: mem (CPU python)=32130.32421875MB; mem (CPU total)=31852.01953125MB
INFO:root:[   50] Training loss: 0.70172491, Validation loss: 0.64476333, Gradient norm: 8.11416528
INFO:root:At the start of the epoch: mem (CPU python)=32151.48828125MB; mem (CPU total)=31872.96484375MB
INFO:root:[   51] Training loss: 0.69808987, Validation loss: 0.59995575, Gradient norm: 8.18752320
INFO:root:At the start of the epoch: mem (CPU python)=32172.65234375MB; mem (CPU total)=31894.52734375MB
INFO:root:[   52] Training loss: 0.70443167, Validation loss: 0.60983149, Gradient norm: 8.74232643
INFO:root:At the start of the epoch: mem (CPU python)=32193.81640625MB; mem (CPU total)=31915.66796875MB
INFO:root:[   53] Training loss: 0.71053138, Validation loss: 0.63047498, Gradient norm: 9.52464061
INFO:root:At the start of the epoch: mem (CPU python)=32214.98046875MB; mem (CPU total)=31936.80078125MB
INFO:root:[   54] Training loss: 0.72535379, Validation loss: 0.76602446, Gradient norm: 10.11947066
INFO:root:At the start of the epoch: mem (CPU python)=32236.140625MB; mem (CPU total)=31958.1640625MB
INFO:root:[   55] Training loss: 0.71925021, Validation loss: 0.61383442, Gradient norm: 9.03497334
INFO:root:At the start of the epoch: mem (CPU python)=32257.3046875MB; mem (CPU total)=31979.3125MB
INFO:root:[   56] Training loss: 0.69662105, Validation loss: 0.59462108, Gradient norm: 7.45585580
INFO:root:At the start of the epoch: mem (CPU python)=32278.46875MB; mem (CPU total)=32002.1953125MB
INFO:root:[   57] Training loss: 0.71517215, Validation loss: 0.61260689, Gradient norm: 9.11333160
INFO:root:At the start of the epoch: mem (CPU python)=32299.6328125MB; mem (CPU total)=32023.3671875MB
INFO:root:[   58] Training loss: 0.70023130, Validation loss: 0.64871337, Gradient norm: 7.68809364
INFO:root:At the start of the epoch: mem (CPU python)=32320.796875MB; mem (CPU total)=32044.51953125MB
INFO:root:[   59] Training loss: 0.70081007, Validation loss: 0.60604149, Gradient norm: 8.60885243
INFO:root:At the start of the epoch: mem (CPU python)=32341.96484375MB; mem (CPU total)=32065.94921875MB
INFO:root:[   60] Training loss: 0.70513374, Validation loss: 0.62483533, Gradient norm: 8.92049001
INFO:root:At the start of the epoch: mem (CPU python)=32363.12890625MB; mem (CPU total)=32087.125MB
INFO:root:[   61] Training loss: 0.70538242, Validation loss: 0.61809044, Gradient norm: 9.34592053
INFO:root:At the start of the epoch: mem (CPU python)=32384.2890625MB; mem (CPU total)=32108.07421875MB
INFO:root:[   62] Training loss: 0.71068832, Validation loss: 0.59984599, Gradient norm: 9.75532719
INFO:root:At the start of the epoch: mem (CPU python)=32405.453125MB; mem (CPU total)=32129.40625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.70233508, Validation loss: 0.64007550, Gradient norm: 8.84560489
INFO:root:At the start of the epoch: mem (CPU python)=32426.6171875MB; mem (CPU total)=32150.56640625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.66732583, Validation loss: 0.58589963, Gradient norm: 7.61279284
INFO:root:At the start of the epoch: mem (CPU python)=32447.78515625MB; mem (CPU total)=32171.76953125MB
INFO:root:[   65] Training loss: 0.65254138, Validation loss: 0.57660818, Gradient norm: 6.41427699
INFO:root:At the start of the epoch: mem (CPU python)=32468.94921875MB; mem (CPU total)=32193.109375MB
INFO:root:[   66] Training loss: 0.65195114, Validation loss: 0.57523866, Gradient norm: 8.37870559
INFO:root:At the start of the epoch: mem (CPU python)=32490.11328125MB; mem (CPU total)=32214.16015625MB
INFO:root:[   67] Training loss: 0.65385591, Validation loss: 0.57954701, Gradient norm: 8.93557367
INFO:root:At the start of the epoch: mem (CPU python)=32511.27734375MB; mem (CPU total)=32235.31640625MB
INFO:root:[   68] Training loss: 0.65366811, Validation loss: 0.57817759, Gradient norm: 10.04226929
INFO:root:At the start of the epoch: mem (CPU python)=32532.44140625MB; mem (CPU total)=32255.984375MB
INFO:root:[   69] Training loss: 0.65577487, Validation loss: 0.57904570, Gradient norm: 10.48610065
INFO:root:At the start of the epoch: mem (CPU python)=32553.609375MB; mem (CPU total)=32277.1328125MB
INFO:root:[   70] Training loss: 0.65761695, Validation loss: 0.57587035, Gradient norm: 11.06549311
INFO:root:At the start of the epoch: mem (CPU python)=32574.76953125MB; mem (CPU total)=32298.49609375MB
INFO:root:[   71] Training loss: 0.65947248, Validation loss: 0.57391736, Gradient norm: 13.30958291
INFO:root:At the start of the epoch: mem (CPU python)=32595.93359375MB; mem (CPU total)=32320.1171875MB
INFO:root:[   72] Training loss: 0.66256847, Validation loss: 0.57950585, Gradient norm: 13.75143507
INFO:root:At the start of the epoch: mem (CPU python)=32617.09375MB; mem (CPU total)=32341.546875MB
INFO:root:[   73] Training loss: 0.66144146, Validation loss: 0.57616243, Gradient norm: 14.00110727
INFO:root:At the start of the epoch: mem (CPU python)=32638.2578125MB; mem (CPU total)=32362.74609375MB
INFO:root:[   74] Training loss: 0.66401657, Validation loss: 0.58308656, Gradient norm: 15.61579753
INFO:root:At the start of the epoch: mem (CPU python)=32659.42578125MB; mem (CPU total)=32384.17578125MB
INFO:root:[   75] Training loss: 0.66332409, Validation loss: 0.58667496, Gradient norm: 15.64566676
INFO:root:At the start of the epoch: mem (CPU python)=32680.58984375MB; mem (CPU total)=32405.015625MB
INFO:root:[   76] Training loss: 0.66767919, Validation loss: 0.58971803, Gradient norm: 17.39497017
INFO:root:At the start of the epoch: mem (CPU python)=32701.7578125MB; mem (CPU total)=32426.1875MB
INFO:root:[   77] Training loss: 0.66553775, Validation loss: 0.58403884, Gradient norm: 17.28458020
INFO:root:At the start of the epoch: mem (CPU python)=32722.921875MB; mem (CPU total)=32447.1953125MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   78] Training loss: 0.66883565, Validation loss: 0.59115298, Gradient norm: 18.91571937
INFO:root:At the start of the epoch: mem (CPU python)=32744.08984375MB; mem (CPU total)=32468.05078125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   79] Training loss: 0.65240934, Validation loss: 0.57070701, Gradient norm: 12.75932513
INFO:root:At the start of the epoch: mem (CPU python)=32765.25390625MB; mem (CPU total)=32489.9140625MB
INFO:root:[   80] Training loss: 0.64438743, Validation loss: 0.56947506, Gradient norm: 8.03355379
INFO:root:At the start of the epoch: mem (CPU python)=32786.4140625MB; mem (CPU total)=32510.9296875MB
INFO:root:[   81] Training loss: 0.64374270, Validation loss: 0.56879615, Gradient norm: 10.94716685
INFO:root:At the start of the epoch: mem (CPU python)=32807.578125MB; mem (CPU total)=32532.3671875MB
INFO:root:[   82] Training loss: 0.64338903, Validation loss: 0.56804783, Gradient norm: 11.10663807
INFO:root:At the start of the epoch: mem (CPU python)=32828.7421875MB; mem (CPU total)=32553.42578125MB
INFO:root:[   83] Training loss: 0.64354943, Validation loss: 0.56689808, Gradient norm: 12.36838528
INFO:root:At the start of the epoch: mem (CPU python)=32849.90625MB; mem (CPU total)=32574.34375MB
INFO:root:[   84] Training loss: 0.64315962, Validation loss: 0.56598619, Gradient norm: 12.23649267
INFO:root:At the start of the epoch: mem (CPU python)=32871.0703125MB; mem (CPU total)=32595.0MB
INFO:root:[   85] Training loss: 0.64350794, Validation loss: 0.56744159, Gradient norm: 12.85715275
INFO:root:At the start of the epoch: mem (CPU python)=32892.234375MB; mem (CPU total)=32616.36328125MB
INFO:root:[   86] Training loss: 0.64351951, Validation loss: 0.57295370, Gradient norm: 13.49082115
INFO:root:At the start of the epoch: mem (CPU python)=32913.40234375MB; mem (CPU total)=32637.0703125MB
INFO:root:[   87] Training loss: 0.64522690, Validation loss: 0.56635777, Gradient norm: 15.86392153
INFO:root:At the start of the epoch: mem (CPU python)=32934.56640625MB; mem (CPU total)=32659.48046875MB
INFO:root:[   88] Training loss: 0.64350081, Validation loss: 0.56571729, Gradient norm: 14.30149165
INFO:root:At the start of the epoch: mem (CPU python)=32955.73046875MB; mem (CPU total)=32680.91015625MB
INFO:root:[   89] Training loss: 0.64312019, Validation loss: 0.56425583, Gradient norm: 15.03702102
INFO:root:At the start of the epoch: mem (CPU python)=32976.89453125MB; mem (CPU total)=32702.08984375MB
INFO:root:[   90] Training loss: 0.64329633, Validation loss: 0.56427336, Gradient norm: 16.15208915
INFO:root:At the start of the epoch: mem (CPU python)=32998.0546875MB; mem (CPU total)=32722.83984375MB
INFO:root:[   91] Training loss: 0.64248393, Validation loss: 0.56329118, Gradient norm: 16.04488291
INFO:root:At the start of the epoch: mem (CPU python)=33019.21875MB; mem (CPU total)=32743.99609375MB
INFO:root:[   92] Training loss: 0.64259319, Validation loss: 0.56640868, Gradient norm: 16.36195768
INFO:root:At the start of the epoch: mem (CPU python)=33040.3828125MB; mem (CPU total)=32764.921875MB
INFO:root:[   93] Training loss: 0.64247002, Validation loss: 0.56104023, Gradient norm: 16.51814884
INFO:root:At the start of the epoch: mem (CPU python)=33061.546875MB; mem (CPU total)=32786.0703125MB
INFO:root:[   94] Training loss: 0.64195214, Validation loss: 0.56205254, Gradient norm: 19.09194265
INFO:root:At the start of the epoch: mem (CPU python)=33082.7109375MB; mem (CPU total)=32807.25MB
INFO:root:[   95] Training loss: 0.64121852, Validation loss: 0.56744510, Gradient norm: 18.13945849
INFO:root:At the start of the epoch: mem (CPU python)=33103.875MB; mem (CPU total)=32828.92578125MB
INFO:root:[   96] Training loss: 0.64185782, Validation loss: 0.56316766, Gradient norm: 18.99192612
INFO:root:At the start of the epoch: mem (CPU python)=33125.04296875MB; mem (CPU total)=32851.3359375MB
INFO:root:[   97] Training loss: 0.64131762, Validation loss: 0.56326583, Gradient norm: 19.67107343
INFO:root:At the start of the epoch: mem (CPU python)=33146.20703125MB; mem (CPU total)=32872.734375MB
INFO:root:[   98] Training loss: 0.64032173, Validation loss: 0.56042431, Gradient norm: 18.71604954
INFO:root:At the start of the epoch: mem (CPU python)=33167.37109375MB; mem (CPU total)=32893.875MB
INFO:root:[   99] Training loss: 0.64214353, Validation loss: 0.55687353, Gradient norm: 21.80749941
INFO:root:At the start of the epoch: mem (CPU python)=33188.53125MB; mem (CPU total)=32915.3046875MB
INFO:root:[  100] Training loss: 0.64143887, Validation loss: 0.55869168, Gradient norm: 21.76359889
INFO:root:At the start of the epoch: mem (CPU python)=33209.6953125MB; mem (CPU total)=32936.46875MB
INFO:root:[  101] Training loss: 0.64013937, Validation loss: 0.55792243, Gradient norm: 20.75433889
INFO:root:At the start of the epoch: mem (CPU python)=33230.859375MB; mem (CPU total)=32957.15234375MB
INFO:root:[  102] Training loss: 0.64070971, Validation loss: 0.55744783, Gradient norm: 21.58504073
INFO:root:At the start of the epoch: mem (CPU python)=33252.02734375MB; mem (CPU total)=32977.5MB
INFO:root:[  103] Training loss: 0.64095324, Validation loss: 0.55734623, Gradient norm: 23.37117234
INFO:root:At the start of the epoch: mem (CPU python)=33273.19140625MB; mem (CPU total)=32998.63671875MB
INFO:root:[  104] Training loss: 0.64252504, Validation loss: 0.55724457, Gradient norm: 23.36062674
INFO:root:At the start of the epoch: mem (CPU python)=33294.35546875MB; mem (CPU total)=33019.80078125MB
INFO:root:[  105] Training loss: 0.64153434, Validation loss: 0.55988670, Gradient norm: 23.59129659
INFO:root:At the start of the epoch: mem (CPU python)=33315.515625MB; mem (CPU total)=33040.88671875MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[  106] Training loss: 0.64113702, Validation loss: 0.55654815, Gradient norm: 24.30080915
INFO:root:At the start of the epoch: mem (CPU python)=33336.68359375MB; mem (CPU total)=33062.07421875MB
INFO:root:[  107] Training loss: 0.63642864, Validation loss: 0.55588915, Gradient norm: 14.48432225
INFO:root:At the start of the epoch: mem (CPU python)=33357.84765625MB; mem (CPU total)=33083.26953125MB
INFO:root:[  108] Training loss: 0.63596942, Validation loss: 0.55456513, Gradient norm: 17.12652412
INFO:root:At the start of the epoch: mem (CPU python)=33379.0078125MB; mem (CPU total)=33104.19921875MB
INFO:root:[  109] Training loss: 0.63513150, Validation loss: 0.55547775, Gradient norm: 19.36821268
INFO:root:At the start of the epoch: mem (CPU python)=33400.171875MB; mem (CPU total)=33124.9453125MB
INFO:root:[  110] Training loss: 0.63490435, Validation loss: 0.55339245, Gradient norm: 19.13621410
INFO:root:At the start of the epoch: mem (CPU python)=33421.3359375MB; mem (CPU total)=33146.01171875MB
INFO:root:[  111] Training loss: 0.63481794, Validation loss: 0.55385899, Gradient norm: 20.04609472
INFO:root:At the start of the epoch: mem (CPU python)=33442.5MB; mem (CPU total)=33167.15234375MB
INFO:root:[  112] Training loss: 0.63535660, Validation loss: 0.55303786, Gradient norm: 20.56942424
INFO:root:At the start of the epoch: mem (CPU python)=33463.66796875MB; mem (CPU total)=33187.73828125MB
INFO:root:[  113] Training loss: 0.63527403, Validation loss: 0.55211370, Gradient norm: 20.68254894
INFO:root:At the start of the epoch: mem (CPU python)=33484.83203125MB; mem (CPU total)=33209.4296875MB
INFO:root:[  114] Training loss: 0.63568845, Validation loss: 0.55368074, Gradient norm: 21.89085145
INFO:root:At the start of the epoch: mem (CPU python)=33505.99609375MB; mem (CPU total)=33230.59375MB
INFO:root:[  115] Training loss: 0.63521064, Validation loss: 0.55448479, Gradient norm: 21.57400042
INFO:root:At the start of the epoch: mem (CPU python)=33527.16015625MB; mem (CPU total)=33251.7578125MB
INFO:root:[  116] Training loss: 0.63506539, Validation loss: 0.55313395, Gradient norm: 22.33242694
INFO:root:At the start of the epoch: mem (CPU python)=33548.32421875MB; mem (CPU total)=33272.91796875MB
INFO:root:[  117] Training loss: 0.63506708, Validation loss: 0.55242067, Gradient norm: 23.29881929
INFO:root:At the start of the epoch: mem (CPU python)=33569.48828125MB; mem (CPU total)=33294.3203125MB
INFO:root:[  118] Training loss: 0.63491866, Validation loss: 0.55457136, Gradient norm: 22.88979289
INFO:root:At the start of the epoch: mem (CPU python)=33590.6484375MB; mem (CPU total)=33315.23046875MB
INFO:root:[  119] Training loss: 0.63496652, Validation loss: 0.55504417, Gradient norm: 24.23384842
INFO:root:At the start of the epoch: mem (CPU python)=33611.81640625MB; mem (CPU total)=33336.33984375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  120] Training loss: 0.63496199, Validation loss: 0.55117369, Gradient norm: 24.03090432
INFO:root:At the start of the epoch: mem (CPU python)=33632.98046875MB; mem (CPU total)=33357.8046875MB
INFO:root:[  121] Training loss: 0.63298932, Validation loss: 0.55354411, Gradient norm: 14.86162804
INFO:root:At the start of the epoch: mem (CPU python)=33654.14453125MB; mem (CPU total)=33378.75MB
INFO:root:[  122] Training loss: 0.63202149, Validation loss: 0.55301126, Gradient norm: 15.92694346
INFO:root:At the start of the epoch: mem (CPU python)=33675.3046875MB; mem (CPU total)=33399.90625MB
INFO:root:[  123] Training loss: 0.63183283, Validation loss: 0.55234136, Gradient norm: 16.27480514
INFO:root:At the start of the epoch: mem (CPU python)=33696.46875MB; mem (CPU total)=33420.875MB
INFO:root:[  124] Training loss: 0.63226235, Validation loss: 0.55062127, Gradient norm: 21.58085059
INFO:root:At the start of the epoch: mem (CPU python)=33717.63671875MB; mem (CPU total)=33442.32421875MB
INFO:root:[  125] Training loss: 0.63251862, Validation loss: 0.55109820, Gradient norm: 21.88595023
INFO:root:At the start of the epoch: mem (CPU python)=33738.80078125MB; mem (CPU total)=33463.61328125MB
INFO:root:[  126] Training loss: 0.63205282, Validation loss: 0.55128245, Gradient norm: 17.31276780
INFO:root:At the start of the epoch: mem (CPU python)=33759.96484375MB; mem (CPU total)=33484.69921875MB
INFO:root:[  127] Training loss: 0.63170914, Validation loss: 0.55063997, Gradient norm: 17.86047223
INFO:root:At the start of the epoch: mem (CPU python)=33781.125MB; mem (CPU total)=33506.33203125MB
INFO:root:[  128] Training loss: 0.63182239, Validation loss: 0.55152890, Gradient norm: 19.11162987
INFO:root:At the start of the epoch: mem (CPU python)=33802.2890625MB; mem (CPU total)=33527.4765625MB
INFO:root:[  129] Training loss: 0.63170421, Validation loss: 0.55008811, Gradient norm: 20.70459694
INFO:root:At the start of the epoch: mem (CPU python)=33823.45703125MB; mem (CPU total)=33548.8828125MB
INFO:root:[  130] Training loss: 0.63154324, Validation loss: 0.55075180, Gradient norm: 19.84698645
INFO:root:At the start of the epoch: mem (CPU python)=33844.6171875MB; mem (CPU total)=33570.0234375MB
INFO:root:[  131] Training loss: 0.63126554, Validation loss: 0.55074216, Gradient norm: 20.44622169
INFO:root:At the start of the epoch: mem (CPU python)=33865.78515625MB; mem (CPU total)=33591.1875MB
INFO:root:[  132] Training loss: 0.63145401, Validation loss: 0.55240399, Gradient norm: 20.80760100
INFO:root:At the start of the epoch: mem (CPU python)=33886.94921875MB; mem (CPU total)=33612.58984375MB
INFO:root:[  133] Training loss: 0.63081737, Validation loss: 0.55338867, Gradient norm: 21.74693803
INFO:root:At the start of the epoch: mem (CPU python)=33908.11328125MB; mem (CPU total)=33633.48046875MB
INFO:root:[  134] Training loss: 0.63099762, Validation loss: 0.55182641, Gradient norm: 22.56128519
INFO:root:At the start of the epoch: mem (CPU python)=33929.27734375MB; mem (CPU total)=33654.640625MB
INFO:root:[  135] Training loss: 0.63059681, Validation loss: 0.55153814, Gradient norm: 21.04265420
INFO:root:At the start of the epoch: mem (CPU python)=33950.4453125MB; mem (CPU total)=33675.9609375MB
INFO:root:[  136] Training loss: 0.63033738, Validation loss: 0.55145979, Gradient norm: 22.05104899
INFO:root:At the start of the epoch: mem (CPU python)=33971.609375MB; mem (CPU total)=33697.109375MB
INFO:root:[  137] Training loss: 0.63003406, Validation loss: 0.55108850, Gradient norm: 23.57822989
INFO:root:At the start of the epoch: mem (CPU python)=33992.76953125MB; mem (CPU total)=33718.5MB
INFO:root:[  138] Training loss: 0.63005247, Validation loss: 0.55046028, Gradient norm: 23.49426740
INFO:root:At the start of the epoch: mem (CPU python)=34013.93359375MB; mem (CPU total)=33739.6640625MB
INFO:root:EP 138: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=34035.09375MB; mem (CPU total)=33760.81640625MB
INFO:root:[  140] Training loss: 0.71925087, Validation loss: 0.64075001, Gradient norm: 20.80887889
INFO:root:At the start of the epoch: mem (CPU python)=34056.265625MB; mem (CPU total)=33782.6015625MB
INFO:root:[  141] Training loss: 0.71678252, Validation loss: 0.63827841, Gradient norm: 19.58368498
INFO:root:At the start of the epoch: mem (CPU python)=34077.42578125MB; mem (CPU total)=33803.7734375MB
INFO:root:[  142] Training loss: 0.71601796, Validation loss: 0.63520550, Gradient norm: 20.33301224
INFO:root:At the start of the epoch: mem (CPU python)=34098.58984375MB; mem (CPU total)=33824.96484375MB
INFO:root:[  143] Training loss: 0.71557380, Validation loss: 0.63700924, Gradient norm: 21.29446230
INFO:root:At the start of the epoch: mem (CPU python)=34119.75390625MB; mem (CPU total)=33845.38671875MB
INFO:root:[  144] Training loss: 0.71531101, Validation loss: 0.63418765, Gradient norm: 21.68779913
INFO:root:At the start of the epoch: mem (CPU python)=34140.91796875MB; mem (CPU total)=33866.828125MB
INFO:root:[  145] Training loss: 0.71499427, Validation loss: 0.63493668, Gradient norm: 20.44871583
INFO:root:At the start of the epoch: mem (CPU python)=34162.08203125MB; mem (CPU total)=33887.9375MB
INFO:root:[  146] Training loss: 0.71497770, Validation loss: 0.63388364, Gradient norm: 20.74938061
INFO:root:At the start of the epoch: mem (CPU python)=34183.2421875MB; mem (CPU total)=33909.3125MB
INFO:root:[  147] Training loss: 0.71448435, Validation loss: 0.63271574, Gradient norm: 20.09852477
INFO:root:At the start of the epoch: mem (CPU python)=34204.41015625MB; mem (CPU total)=33931.359375MB
INFO:root:[  148] Training loss: 0.71434598, Validation loss: 0.63508970, Gradient norm: 19.60981242
INFO:root:At the start of the epoch: mem (CPU python)=34225.5703125MB; mem (CPU total)=33952.27734375MB
INFO:root:[  149] Training loss: 0.71385127, Validation loss: 0.63313896, Gradient norm: 19.25561520
INFO:root:At the start of the epoch: mem (CPU python)=34246.73828125MB; mem (CPU total)=33973.41015625MB
INFO:root:[  150] Training loss: 0.71369828, Validation loss: 0.63215238, Gradient norm: 19.24281987
INFO:root:At the start of the epoch: mem (CPU python)=34267.90234375MB; mem (CPU total)=33994.3203125MB
INFO:root:[  151] Training loss: 0.71364790, Validation loss: 0.63229074, Gradient norm: 20.29784475
INFO:root:At the start of the epoch: mem (CPU python)=34289.06640625MB; mem (CPU total)=34015.453125MB
INFO:root:[  152] Training loss: 0.71380773, Validation loss: 0.63406046, Gradient norm: 21.23331117
INFO:root:At the start of the epoch: mem (CPU python)=34310.234375MB; mem (CPU total)=34037.66796875MB
INFO:root:[  153] Training loss: 0.71319655, Validation loss: 0.63318865, Gradient norm: 19.85868768
INFO:root:At the start of the epoch: mem (CPU python)=34331.40234375MB; mem (CPU total)=34059.09375MB
INFO:root:[  154] Training loss: 0.71329807, Validation loss: 0.63361762, Gradient norm: 23.16075292
INFO:root:At the start of the epoch: mem (CPU python)=34352.56640625MB; mem (CPU total)=34081.26953125MB
INFO:root:[  155] Training loss: 0.71242410, Validation loss: 0.63396808, Gradient norm: 20.69974896
INFO:root:At the start of the epoch: mem (CPU python)=34373.73046875MB; mem (CPU total)=34101.76171875MB
INFO:root:[  156] Training loss: 0.71275596, Validation loss: 0.63181353, Gradient norm: 21.48046663
INFO:root:At the start of the epoch: mem (CPU python)=34394.890625MB; mem (CPU total)=34122.625MB
INFO:root:[  157] Training loss: 0.71257244, Validation loss: 0.63286862, Gradient norm: 21.26344285
INFO:root:At the start of the epoch: mem (CPU python)=34416.05078125MB; mem (CPU total)=34143.7890625MB
INFO:root:[  158] Training loss: 0.71248947, Validation loss: 0.63187585, Gradient norm: 22.77033715
INFO:root:At the start of the epoch: mem (CPU python)=34437.21875MB; mem (CPU total)=34164.953125MB
INFO:root:[  159] Training loss: 0.71204574, Validation loss: 0.63299000, Gradient norm: 22.75822493
INFO:root:At the start of the epoch: mem (CPU python)=34458.3828125MB; mem (CPU total)=34186.3359375MB
INFO:root:[  160] Training loss: 0.71246769, Validation loss: 0.63227878, Gradient norm: 21.65354855
INFO:root:At the start of the epoch: mem (CPU python)=34479.546875MB; mem (CPU total)=34207.48828125MB
INFO:root:[  161] Training loss: 0.71191237, Validation loss: 0.63241928, Gradient norm: 20.45094507
INFO:root:At the start of the epoch: mem (CPU python)=34500.7109375MB; mem (CPU total)=34228.609375MB
INFO:root:[  162] Training loss: 0.71186032, Validation loss: 0.63169162, Gradient norm: 22.20694661
INFO:root:At the start of the epoch: mem (CPU python)=34521.87890625MB; mem (CPU total)=34249.58203125MB
INFO:root:[  163] Training loss: 0.71138992, Validation loss: 0.63141707, Gradient norm: 22.86252937
INFO:root:At the start of the epoch: mem (CPU python)=34543.04296875MB; mem (CPU total)=34270.79296875MB
INFO:root:[  164] Training loss: 0.71148720, Validation loss: 0.63260697, Gradient norm: 21.14757110
INFO:root:At the start of the epoch: mem (CPU python)=34564.20703125MB; mem (CPU total)=34292.1875MB
INFO:root:[  165] Training loss: 0.71175871, Validation loss: 0.63110231, Gradient norm: 22.60194838
INFO:root:At the start of the epoch: mem (CPU python)=34585.3671875MB; mem (CPU total)=34314.8125MB
INFO:root:[  166] Training loss: 0.71167315, Validation loss: 0.63167311, Gradient norm: 23.46779488
INFO:root:At the start of the epoch: mem (CPU python)=34606.53125MB; mem (CPU total)=34335.99609375MB
INFO:root:[  167] Training loss: 0.71167065, Validation loss: 0.63165086, Gradient norm: 23.81472724
INFO:root:At the start of the epoch: mem (CPU python)=34627.6953125MB; mem (CPU total)=34356.58984375MB
INFO:root:[  168] Training loss: 0.71147323, Validation loss: 0.63249666, Gradient norm: 23.34067750
INFO:root:At the start of the epoch: mem (CPU python)=34648.859375MB; mem (CPU total)=34377.84765625MB
INFO:root:[  169] Training loss: 0.71113503, Validation loss: 0.63105998, Gradient norm: 22.61123415
INFO:root:At the start of the epoch: mem (CPU python)=34670.02734375MB; mem (CPU total)=34398.9296875MB
INFO:root:[  170] Training loss: 0.71129050, Validation loss: 0.63056828, Gradient norm: 23.62868250
INFO:root:At the start of the epoch: mem (CPU python)=34691.19140625MB; mem (CPU total)=34419.87109375MB
INFO:root:[  171] Training loss: 0.71127458, Validation loss: 0.63083262, Gradient norm: 24.18740637
INFO:root:At the start of the epoch: mem (CPU python)=34712.35546875MB; mem (CPU total)=34440.76171875MB
INFO:root:[  172] Training loss: 0.71090606, Validation loss: 0.63439232, Gradient norm: 24.08089715
INFO:root:At the start of the epoch: mem (CPU python)=34733.51953125MB; mem (CPU total)=34461.6796875MB
INFO:root:[  173] Training loss: 0.71074890, Validation loss: 0.63228907, Gradient norm: 22.49961196
INFO:root:At the start of the epoch: mem (CPU python)=34754.6796875MB; mem (CPU total)=34482.83203125MB
INFO:root:[  174] Training loss: 0.71075303, Validation loss: 0.63254475, Gradient norm: 23.28868880
INFO:root:At the start of the epoch: mem (CPU python)=34775.83984375MB; mem (CPU total)=34504.20703125MB
INFO:root:[  175] Training loss: 0.71062970, Validation loss: 0.63117944, Gradient norm: 23.20467655
INFO:root:At the start of the epoch: mem (CPU python)=34797.0078125MB; mem (CPU total)=34525.0859375MB
INFO:root:[  176] Training loss: 0.71051631, Validation loss: 0.63065127, Gradient norm: 24.72943357
INFO:root:At the start of the epoch: mem (CPU python)=34818.171875MB; mem (CPU total)=34546.0MB
INFO:root:[  177] Training loss: 0.71031829, Validation loss: 0.63167042, Gradient norm: 22.65917813
INFO:root:At the start of the epoch: mem (CPU python)=34839.3359375MB; mem (CPU total)=34567.15234375MB
INFO:root:[  178] Training loss: 0.71039356, Validation loss: 0.63169787, Gradient norm: 25.32610331
INFO:root:At the start of the epoch: mem (CPU python)=34860.5MB; mem (CPU total)=34587.15234375MB
INFO:root:[  179] Training loss: 0.71039921, Validation loss: 0.63319490, Gradient norm: 23.93528372
INFO:root:At the start of the epoch: mem (CPU python)=34881.6640625MB; mem (CPU total)=34608.3046875MB
INFO:root:EP 179: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=34902.8203125MB; mem (CPU total)=34629.50390625MB
INFO:root:Training the model took 9622.319s.
INFO:root:Emptying the cuda cache took 0.064s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 1.37024
INFO:root:EnergyScoreValidation: 0.71982
INFO:root:CRPSValidation: 0.323
INFO:root:Gaussian NLLValidation: 6.45422
INFO:root:CoverageValidation: 0.65395
INFO:root:IntervalWidthValidation: 1.73996
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 1.35318
INFO:root:EnergyScoreTest: 0.69653
INFO:root:CRPSTest: 0.30908
INFO:root:Gaussian NLLTest: 4.40645
INFO:root:CoverageTest: 0.6971
INFO:root:IntervalWidthTest: 1.89555
INFO:root:After validation: mem (CPU python)=34960.796875MB; mem (CPU total)=34647.625MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'SFNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.3, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=34960.796875MB; mem (CPU total)=34647.34375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 346030080
INFO:root:After setting up the model: mem (CPU python)=34960.796875MB; mem (CPU total)=34647.34375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=34960.796875MB; mem (CPU total)=34646.84375MB
INFO:root:[    1] Training loss: 0.91148850, Validation loss: 0.73473286, Gradient norm: 0.34498457
INFO:root:At the start of the epoch: mem (CPU python)=34960.796875MB; mem (CPU total)=34667.3515625MB
INFO:root:[    2] Training loss: 0.77815914, Validation loss: 0.73239211, Gradient norm: 0.24230703
INFO:root:At the start of the epoch: mem (CPU python)=34961.43359375MB; mem (CPU total)=34688.49609375MB
INFO:root:[    3] Training loss: 0.77082927, Validation loss: 0.72547150, Gradient norm: 0.34371216
INFO:root:At the start of the epoch: mem (CPU python)=34982.59765625MB; mem (CPU total)=34709.86328125MB
INFO:root:[    4] Training loss: 0.76671198, Validation loss: 0.72459923, Gradient norm: 0.64858570
INFO:root:At the start of the epoch: mem (CPU python)=35003.76171875MB; mem (CPU total)=34731.5MB
INFO:root:[    5] Training loss: 0.76850106, Validation loss: 0.74010040, Gradient norm: 1.12769630
INFO:root:At the start of the epoch: mem (CPU python)=35024.92578125MB; mem (CPU total)=34752.34765625MB
INFO:root:[    6] Training loss: 0.76668486, Validation loss: 0.71786736, Gradient norm: 1.62925138
INFO:root:At the start of the epoch: mem (CPU python)=35057.46484375MB; mem (CPU total)=34785.12890625MB
INFO:root:[    7] Training loss: 0.76338298, Validation loss: 0.69650025, Gradient norm: 1.79745885
INFO:root:At the start of the epoch: mem (CPU python)=35079.16796875MB; mem (CPU total)=34806.30859375MB
INFO:root:[    8] Training loss: 0.75991610, Validation loss: 0.69083948, Gradient norm: 2.33217916
INFO:root:At the start of the epoch: mem (CPU python)=35100.33203125MB; mem (CPU total)=34827.703125MB
INFO:root:[    9] Training loss: 0.75151576, Validation loss: 0.68139655, Gradient norm: 2.45351194
INFO:root:At the start of the epoch: mem (CPU python)=35121.49609375MB; mem (CPU total)=34848.85546875MB
INFO:root:[   10] Training loss: 0.75593614, Validation loss: 0.69390128, Gradient norm: 2.97025219
INFO:root:At the start of the epoch: mem (CPU python)=35142.66015625MB; mem (CPU total)=34869.90234375MB
INFO:root:[   11] Training loss: 0.75220152, Validation loss: 0.67736697, Gradient norm: 3.09192230
INFO:root:At the start of the epoch: mem (CPU python)=35163.828125MB; mem (CPU total)=34891.33203125MB
INFO:root:[   12] Training loss: 0.74829983, Validation loss: 0.67253632, Gradient norm: 3.26412043
INFO:root:At the start of the epoch: mem (CPU python)=35184.9921875MB; mem (CPU total)=34912.9453125MB
INFO:root:[   13] Training loss: 0.75331531, Validation loss: 0.69165129, Gradient norm: 3.82214985
INFO:root:At the start of the epoch: mem (CPU python)=35206.15625MB; mem (CPU total)=34934.0859375MB
INFO:root:[   14] Training loss: 0.75315368, Validation loss: 0.66341185, Gradient norm: 3.73650074
INFO:root:At the start of the epoch: mem (CPU python)=35227.3203125MB; mem (CPU total)=34955.21875MB
INFO:root:[   15] Training loss: 0.75507281, Validation loss: 0.67780988, Gradient norm: 4.36686536
INFO:root:At the start of the epoch: mem (CPU python)=35248.48046875MB; mem (CPU total)=34976.37109375MB
INFO:root:[   16] Training loss: 0.74704015, Validation loss: 0.70877639, Gradient norm: 4.15609678
INFO:root:At the start of the epoch: mem (CPU python)=35269.640625MB; mem (CPU total)=34997.51953125MB
INFO:root:[   17] Training loss: 0.75090858, Validation loss: 0.67922622, Gradient norm: 4.66463144
INFO:root:At the start of the epoch: mem (CPU python)=35290.80859375MB; mem (CPU total)=35018.64453125MB
INFO:root:[   18] Training loss: 0.74272896, Validation loss: 0.63723362, Gradient norm: 4.27487344
INFO:root:At the start of the epoch: mem (CPU python)=35311.97265625MB; mem (CPU total)=35040.0390625MB
INFO:root:[   19] Training loss: 0.74778423, Validation loss: 0.64322915, Gradient norm: 4.72168252
INFO:root:At the start of the epoch: mem (CPU python)=35333.13671875MB; mem (CPU total)=35062.265625MB
INFO:root:[   20] Training loss: 0.74758791, Validation loss: 0.67257425, Gradient norm: 5.08829923
INFO:root:At the start of the epoch: mem (CPU python)=35354.30078125MB; mem (CPU total)=35083.43359375MB
INFO:root:[   21] Training loss: 0.74697577, Validation loss: 0.65304911, Gradient norm: 5.10446186
INFO:root:At the start of the epoch: mem (CPU python)=35375.46484375MB; mem (CPU total)=35104.6015625MB
INFO:root:[   22] Training loss: 0.73764408, Validation loss: 0.66428256, Gradient norm: 4.50855351
INFO:root:At the start of the epoch: mem (CPU python)=35396.6328125MB; mem (CPU total)=35126.015625MB
INFO:root:[   23] Training loss: 0.73456356, Validation loss: 0.64637489, Gradient norm: 4.85278000
INFO:root:At the start of the epoch: mem (CPU python)=35417.796875MB; mem (CPU total)=35147.44921875MB
INFO:root:[   24] Training loss: 0.74849005, Validation loss: 0.72589003, Gradient norm: 6.04686321
INFO:root:At the start of the epoch: mem (CPU python)=35438.9609375MB; mem (CPU total)=35168.27734375MB
INFO:root:[   25] Training loss: 0.74410365, Validation loss: 0.63312023, Gradient norm: 5.47359103
INFO:root:At the start of the epoch: mem (CPU python)=35460.12109375MB; mem (CPU total)=35189.48046875MB
INFO:root:[   26] Training loss: 0.73074679, Validation loss: 0.64052357, Gradient norm: 5.20179481
INFO:root:At the start of the epoch: mem (CPU python)=35481.28515625MB; mem (CPU total)=35209.90234375MB
INFO:root:[   27] Training loss: 0.73373735, Validation loss: 0.64109674, Gradient norm: 5.92229216
INFO:root:At the start of the epoch: mem (CPU python)=35502.44921875MB; mem (CPU total)=35232.06640625MB
INFO:root:[   28] Training loss: 0.75781564, Validation loss: 0.68251212, Gradient norm: 7.43091949
INFO:root:At the start of the epoch: mem (CPU python)=35523.6171875MB; mem (CPU total)=35253.1328125MB
INFO:root:[   29] Training loss: 0.75084989, Validation loss: 0.66690281, Gradient norm: 6.52659570
INFO:root:At the start of the epoch: mem (CPU python)=35544.78125MB; mem (CPU total)=35274.28125MB
INFO:root:[   30] Training loss: 0.75059597, Validation loss: 0.65947765, Gradient norm: 6.49056266
INFO:root:At the start of the epoch: mem (CPU python)=35565.9453125MB; mem (CPU total)=35295.65625MB
INFO:root:[   31] Training loss: 0.73785268, Validation loss: 0.68725109, Gradient norm: 5.82170964
INFO:root:At the start of the epoch: mem (CPU python)=35587.109375MB; mem (CPU total)=35316.734375MB
INFO:root:[   32] Training loss: 0.74077452, Validation loss: 0.65042101, Gradient norm: 6.25577027
INFO:root:At the start of the epoch: mem (CPU python)=35608.2734375MB; mem (CPU total)=35337.65234375MB
INFO:root:[   33] Training loss: 0.74340401, Validation loss: 0.63387565, Gradient norm: 6.41415731
INFO:root:At the start of the epoch: mem (CPU python)=35629.4375MB; mem (CPU total)=35359.05859375MB
INFO:root:[   34] Training loss: 0.73456092, Validation loss: 0.62319334, Gradient norm: 6.03246941
INFO:root:At the start of the epoch: mem (CPU python)=35650.6015625MB; mem (CPU total)=35380.51953125MB
INFO:root:[   35] Training loss: 0.74138759, Validation loss: 0.64559366, Gradient norm: 7.12502057
INFO:root:At the start of the epoch: mem (CPU python)=35671.76171875MB; mem (CPU total)=35401.6640625MB
INFO:root:[   36] Training loss: 0.75545634, Validation loss: 0.62813429, Gradient norm: 7.88979650
INFO:root:At the start of the epoch: mem (CPU python)=35692.92578125MB; mem (CPU total)=35422.80859375MB
INFO:root:[   37] Training loss: 0.74124387, Validation loss: 0.65243206, Gradient norm: 7.15663785
INFO:root:At the start of the epoch: mem (CPU python)=35714.0859375MB; mem (CPU total)=35443.45703125MB
INFO:root:[   38] Training loss: 0.76013094, Validation loss: 0.69335768, Gradient norm: 8.00812062
INFO:root:At the start of the epoch: mem (CPU python)=35735.2578125MB; mem (CPU total)=35464.61328125MB
INFO:root:[   39] Training loss: 0.75326395, Validation loss: 0.64700429, Gradient norm: 7.45825490
INFO:root:At the start of the epoch: mem (CPU python)=35756.421875MB; mem (CPU total)=35488.6640625MB
INFO:root:[   40] Training loss: 0.74463423, Validation loss: 0.64104271, Gradient norm: 6.92029945
INFO:root:At the start of the epoch: mem (CPU python)=35777.5859375MB; mem (CPU total)=35509.77734375MB
INFO:root:[   41] Training loss: 0.75201775, Validation loss: 0.63872123, Gradient norm: 7.41105698
INFO:root:At the start of the epoch: mem (CPU python)=35798.75MB; mem (CPU total)=35528.69140625MB
INFO:root:[   42] Training loss: 0.75233032, Validation loss: 0.66022016, Gradient norm: 7.64143747
INFO:root:At the start of the epoch: mem (CPU python)=35819.9140625MB; mem (CPU total)=35550.0859375MB
INFO:root:[   43] Training loss: 0.74316294, Validation loss: 0.63478926, Gradient norm: 7.52296106
INFO:root:At the start of the epoch: mem (CPU python)=35841.078125MB; mem (CPU total)=35571.49609375MB
INFO:root:[   44] Training loss: 0.74066082, Validation loss: 0.70371163, Gradient norm: 8.21705659
INFO:root:At the start of the epoch: mem (CPU python)=35862.2421875MB; mem (CPU total)=35592.66015625MB
INFO:root:[   45] Training loss: 0.76259123, Validation loss: 0.66926990, Gradient norm: 9.38289124
INFO:root:At the start of the epoch: mem (CPU python)=35883.40625MB; mem (CPU total)=35614.32421875MB
INFO:root:[   46] Training loss: 0.76792142, Validation loss: 0.66516426, Gradient norm: 9.38528148
INFO:root:At the start of the epoch: mem (CPU python)=35904.5703125MB; mem (CPU total)=35635.23046875MB
INFO:root:[   47] Training loss: 0.75935429, Validation loss: 0.63247041, Gradient norm: 8.32421852
INFO:root:At the start of the epoch: mem (CPU python)=35925.734375MB; mem (CPU total)=35656.37890625MB
INFO:root:[   48] Training loss: 0.75848905, Validation loss: 0.69143658, Gradient norm: 9.33872752
INFO:root:At the start of the epoch: mem (CPU python)=35946.8984375MB; mem (CPU total)=35677.5390625MB
INFO:root:[   49] Training loss: 0.76932179, Validation loss: 0.69181667, Gradient norm: 10.03610838
INFO:root:At the start of the epoch: mem (CPU python)=35968.06640625MB; mem (CPU total)=35698.6953125MB
INFO:root:[   50] Training loss: 0.76344130, Validation loss: 0.65024609, Gradient norm: 9.63572856
INFO:root:At the start of the epoch: mem (CPU python)=35989.2265625MB; mem (CPU total)=35720.0859375MB
INFO:root:[   51] Training loss: 0.78042457, Validation loss: 0.66145934, Gradient norm: 9.97954731
INFO:root:At the start of the epoch: mem (CPU python)=36010.390625MB; mem (CPU total)=35741.23046875MB
INFO:root:[   52] Training loss: 0.75973184, Validation loss: 0.62852535, Gradient norm: 8.92122345
INFO:root:At the start of the epoch: mem (CPU python)=36031.5546875MB; mem (CPU total)=35762.3671875MB
INFO:root:[   53] Training loss: 0.76285753, Validation loss: 0.66360564, Gradient norm: 9.27756737
INFO:root:At the start of the epoch: mem (CPU python)=36052.71484375MB; mem (CPU total)=35783.53125MB
INFO:root:[   54] Training loss: 0.77977276, Validation loss: 0.68125019, Gradient norm: 10.69153570
INFO:root:At the start of the epoch: mem (CPU python)=36073.8828125MB; mem (CPU total)=35805.296875MB
INFO:root:[   55] Training loss: 0.76608387, Validation loss: 0.68871323, Gradient norm: 9.42924521
INFO:root:At the start of the epoch: mem (CPU python)=36095.046875MB; mem (CPU total)=35826.453125MB
INFO:root:[   56] Training loss: 0.76707048, Validation loss: 0.62270690, Gradient norm: 9.53816323
INFO:root:At the start of the epoch: mem (CPU python)=36116.2109375MB; mem (CPU total)=35847.8828125MB
INFO:root:[   57] Training loss: 0.78210426, Validation loss: 0.65288147, Gradient norm: 11.22020365
INFO:root:At the start of the epoch: mem (CPU python)=36137.375MB; mem (CPU total)=35869.0546875MB
INFO:root:[   58] Training loss: 0.78099681, Validation loss: 0.68085645, Gradient norm: 11.31887097
INFO:root:At the start of the epoch: mem (CPU python)=36158.5390625MB; mem (CPU total)=35889.95703125MB
INFO:root:[   59] Training loss: 0.76857218, Validation loss: 0.65496276, Gradient norm: 11.34376065
INFO:root:At the start of the epoch: mem (CPU python)=36179.703125MB; mem (CPU total)=35911.1171875MB
INFO:root:[   60] Training loss: 0.77795575, Validation loss: 0.70757011, Gradient norm: 12.08286083
INFO:root:At the start of the epoch: mem (CPU python)=36200.87109375MB; mem (CPU total)=35932.28125MB
INFO:root:[   61] Training loss: 0.79005164, Validation loss: 0.70421045, Gradient norm: 13.28928741
INFO:root:At the start of the epoch: mem (CPU python)=36222.03515625MB; mem (CPU total)=35953.69921875MB
INFO:root:[   62] Training loss: 0.79723733, Validation loss: 0.71056243, Gradient norm: 13.65221647
INFO:root:At the start of the epoch: mem (CPU python)=36243.1953125MB; mem (CPU total)=35974.8203125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   63] Training loss: 0.78632173, Validation loss: 0.74270381, Gradient norm: 13.12052029
INFO:root:At the start of the epoch: mem (CPU python)=36264.359375MB; mem (CPU total)=35996.00390625MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   64] Training loss: 0.73397934, Validation loss: 0.62528948, Gradient norm: 11.80960075
INFO:root:At the start of the epoch: mem (CPU python)=36285.5234375MB; mem (CPU total)=36017.1171875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   65] Training loss: 0.72084791, Validation loss: 0.60271163, Gradient norm: 12.20517772
INFO:root:At the start of the epoch: mem (CPU python)=36306.69140625MB; mem (CPU total)=36038.20703125MB
INFO:root:[   66] Training loss: 0.69589502, Validation loss: 0.60730552, Gradient norm: 6.96025984
INFO:root:At the start of the epoch: mem (CPU python)=36327.85546875MB; mem (CPU total)=36059.421875MB
INFO:root:[   67] Training loss: 0.69397064, Validation loss: 0.59790730, Gradient norm: 10.44946284
INFO:root:At the start of the epoch: mem (CPU python)=36349.015625MB; mem (CPU total)=36080.53515625MB
INFO:root:[   68] Training loss: 0.69441394, Validation loss: 0.60070043, Gradient norm: 11.05989618
INFO:root:At the start of the epoch: mem (CPU python)=36370.1796875MB; mem (CPU total)=36101.71875MB
INFO:root:[   69] Training loss: 0.69448044, Validation loss: 0.60099700, Gradient norm: 12.49272707
INFO:root:At the start of the epoch: mem (CPU python)=36391.34375MB; mem (CPU total)=36122.79296875MB
INFO:root:[   70] Training loss: 0.69562761, Validation loss: 0.60051610, Gradient norm: 13.41202256
INFO:root:At the start of the epoch: mem (CPU python)=36412.5078125MB; mem (CPU total)=36143.95703125MB
INFO:root:[   71] Training loss: 0.69684612, Validation loss: 0.60094117, Gradient norm: 13.43525996
INFO:root:At the start of the epoch: mem (CPU python)=36433.67578125MB; mem (CPU total)=36164.87109375MB
INFO:root:[   72] Training loss: 0.69675465, Validation loss: 0.60102706, Gradient norm: 15.33212278
INFO:root:At the start of the epoch: mem (CPU python)=36454.8359375MB; mem (CPU total)=36186.28125MB
INFO:root:[   73] Training loss: 0.69738410, Validation loss: 0.60943911, Gradient norm: 14.61030576
INFO:root:At the start of the epoch: mem (CPU python)=36476.0MB; mem (CPU total)=36207.65234375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   74] Training loss: 0.69788048, Validation loss: 0.60577333, Gradient norm: 15.48491374
INFO:root:At the start of the epoch: mem (CPU python)=36497.1640625MB; mem (CPU total)=36228.80078125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   75] Training loss: 0.69072857, Validation loss: 0.60183436, Gradient norm: 10.44329430
INFO:root:At the start of the epoch: mem (CPU python)=36518.328125MB; mem (CPU total)=36249.96484375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   76] Training loss: 0.68716874, Validation loss: 0.59813015, Gradient norm: 7.36762453
INFO:root:At the start of the epoch: mem (CPU python)=36539.49609375MB; mem (CPU total)=36271.12109375MB
INFO:root:[   77] Training loss: 0.68550024, Validation loss: 0.59582840, Gradient norm: 6.18616259
INFO:root:At the start of the epoch: mem (CPU python)=36560.66015625MB; mem (CPU total)=36292.546875MB
INFO:root:[   78] Training loss: 0.68583336, Validation loss: 0.59555651, Gradient norm: 5.99708586
INFO:root:At the start of the epoch: mem (CPU python)=36581.82421875MB; mem (CPU total)=36313.86328125MB
INFO:root:[   79] Training loss: 0.68596333, Validation loss: 0.59426076, Gradient norm: 7.88996773
INFO:root:At the start of the epoch: mem (CPU python)=36602.98828125MB; mem (CPU total)=36334.81640625MB
INFO:root:[   80] Training loss: 0.68561237, Validation loss: 0.59643631, Gradient norm: 7.45489850
INFO:root:At the start of the epoch: mem (CPU python)=36624.15234375MB; mem (CPU total)=36355.73046875MB
INFO:root:[   81] Training loss: 0.68515001, Validation loss: 0.59525613, Gradient norm: 7.81465571
INFO:root:At the start of the epoch: mem (CPU python)=36645.3125MB; mem (CPU total)=36376.92578125MB
INFO:root:[   82] Training loss: 0.68495454, Validation loss: 0.59445880, Gradient norm: 7.82695483
INFO:root:At the start of the epoch: mem (CPU python)=36666.48046875MB; mem (CPU total)=36398.08203125MB
INFO:root:[   83] Training loss: 0.68471869, Validation loss: 0.59601261, Gradient norm: 7.44445809
INFO:root:At the start of the epoch: mem (CPU python)=36687.64453125MB; mem (CPU total)=36419.44140625MB
INFO:root:[   84] Training loss: 0.68476567, Validation loss: 0.59480504, Gradient norm: 8.18422879
INFO:root:At the start of the epoch: mem (CPU python)=36708.8046875MB; mem (CPU total)=36440.73046875MB
INFO:root:[   85] Training loss: 0.68453555, Validation loss: 0.59531860, Gradient norm: 10.24265198
INFO:root:At the start of the epoch: mem (CPU python)=36729.96875MB; mem (CPU total)=36461.6171875MB
INFO:root:[   86] Training loss: 0.68456981, Validation loss: 0.59470254, Gradient norm: 9.90143321
INFO:root:At the start of the epoch: mem (CPU python)=36751.13671875MB; mem (CPU total)=36482.76171875MB
INFO:root:[   87] Training loss: 0.68458415, Validation loss: 0.59646342, Gradient norm: 9.57320705
INFO:root:At the start of the epoch: mem (CPU python)=36772.30078125MB; mem (CPU total)=36503.89453125MB
INFO:root:[   88] Training loss: 0.68451382, Validation loss: 0.59560232, Gradient norm: 10.87970652
INFO:root:At the start of the epoch: mem (CPU python)=36793.46484375MB; mem (CPU total)=36525.05078125MB
INFO:root:EP 88: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=36814.62890625MB; mem (CPU total)=36546.4609375MB
INFO:root:[   90] Training loss: 0.76931653, Validation loss: 0.68104621, Gradient norm: 12.06628505
INFO:root:At the start of the epoch: mem (CPU python)=36835.79296875MB; mem (CPU total)=36567.98828125MB
INFO:root:[   91] Training loss: 0.76743572, Validation loss: 0.67897284, Gradient norm: 11.47395540
INFO:root:At the start of the epoch: mem (CPU python)=36856.953125MB; mem (CPU total)=36589.1484375MB
INFO:root:[   92] Training loss: 0.76624404, Validation loss: 0.67903214, Gradient norm: 9.87922659
INFO:root:At the start of the epoch: mem (CPU python)=36878.1171875MB; mem (CPU total)=36610.05859375MB
INFO:root:[   93] Training loss: 0.76636785, Validation loss: 0.68019263, Gradient norm: 11.33678265
INFO:root:At the start of the epoch: mem (CPU python)=36899.28125MB; mem (CPU total)=36631.46484375MB
INFO:root:[   94] Training loss: 0.76591721, Validation loss: 0.68015276, Gradient norm: 11.46428662
INFO:root:At the start of the epoch: mem (CPU python)=36920.44921875MB; mem (CPU total)=36652.87890625MB
INFO:root:[   95] Training loss: 0.76564147, Validation loss: 0.67827084, Gradient norm: 9.94244764
INFO:root:At the start of the epoch: mem (CPU python)=36941.61328125MB; mem (CPU total)=36674.015625MB
INFO:root:[   96] Training loss: 0.76525795, Validation loss: 0.67886379, Gradient norm: 10.97939020
INFO:root:At the start of the epoch: mem (CPU python)=36962.77734375MB; mem (CPU total)=36695.16015625MB
INFO:root:[   97] Training loss: 0.76469592, Validation loss: 0.67816058, Gradient norm: 11.46646994
INFO:root:At the start of the epoch: mem (CPU python)=36983.9453125MB; mem (CPU total)=36716.11328125MB
INFO:root:[   98] Training loss: 0.76504677, Validation loss: 0.67799710, Gradient norm: 11.54175168
INFO:root:At the start of the epoch: mem (CPU python)=37005.10546875MB; mem (CPU total)=36737.5390625MB
INFO:root:[   99] Training loss: 0.76443115, Validation loss: 0.67914390, Gradient norm: 11.86085089
INFO:root:At the start of the epoch: mem (CPU python)=37026.26953125MB; mem (CPU total)=36759.21875MB
INFO:root:[  100] Training loss: 0.76487112, Validation loss: 0.67778117, Gradient norm: 11.76911384
INFO:root:At the start of the epoch: mem (CPU python)=37047.43359375MB; mem (CPU total)=36780.38671875MB
INFO:root:[  101] Training loss: 0.76442864, Validation loss: 0.67815018, Gradient norm: 12.46100572
INFO:root:At the start of the epoch: mem (CPU python)=37068.59375MB; mem (CPU total)=36801.1328125MB
INFO:root:[  102] Training loss: 0.76412064, Validation loss: 0.67651368, Gradient norm: 12.12186473
INFO:root:At the start of the epoch: mem (CPU python)=37089.76171875MB; mem (CPU total)=36822.5703125MB
INFO:root:[  103] Training loss: 0.76381134, Validation loss: 0.67622311, Gradient norm: 13.61499272
INFO:root:At the start of the epoch: mem (CPU python)=37110.92578125MB; mem (CPU total)=36843.6328125MB
INFO:root:[  104] Training loss: 0.76383146, Validation loss: 0.67938660, Gradient norm: 14.05287902
INFO:root:At the start of the epoch: mem (CPU python)=37132.0859375MB; mem (CPU total)=36864.9296875MB
INFO:root:[  105] Training loss: 0.76309968, Validation loss: 0.67811373, Gradient norm: 13.10265469
INFO:root:At the start of the epoch: mem (CPU python)=37153.25390625MB; mem (CPU total)=36885.80859375MB
INFO:root:[  106] Training loss: 0.76318602, Validation loss: 0.67580600, Gradient norm: 14.13568335
INFO:root:At the start of the epoch: mem (CPU python)=37174.41796875MB; mem (CPU total)=36907.21484375MB
INFO:root:[  107] Training loss: 0.76307322, Validation loss: 0.67836486, Gradient norm: 14.31256635
INFO:root:At the start of the epoch: mem (CPU python)=37195.58203125MB; mem (CPU total)=36928.35546875MB
INFO:root:[  108] Training loss: 0.76287350, Validation loss: 0.67690377, Gradient norm: 15.79829860
INFO:root:At the start of the epoch: mem (CPU python)=37216.74609375MB; mem (CPU total)=36949.7421875MB
INFO:root:[  109] Training loss: 0.76304324, Validation loss: 0.67704494, Gradient norm: 15.52741533
INFO:root:At the start of the epoch: mem (CPU python)=37237.90625MB; mem (CPU total)=36970.87890625MB
INFO:root:[  110] Training loss: 0.76288694, Validation loss: 0.67544966, Gradient norm: 14.88977788
INFO:root:At the start of the epoch: mem (CPU python)=37259.07421875MB; mem (CPU total)=36992.03515625MB
INFO:root:[  111] Training loss: 0.76269163, Validation loss: 0.67872804, Gradient norm: 15.58141263
INFO:root:At the start of the epoch: mem (CPU python)=37280.23828125MB; mem (CPU total)=37013.15625MB
INFO:root:[  112] Training loss: 0.76253070, Validation loss: 0.67646365, Gradient norm: 16.38209138
INFO:root:At the start of the epoch: mem (CPU python)=37301.40234375MB; mem (CPU total)=37034.30078125MB
INFO:root:[  113] Training loss: 0.76218222, Validation loss: 0.67511799, Gradient norm: 16.01415937
INFO:root:At the start of the epoch: mem (CPU python)=37322.56640625MB; mem (CPU total)=37055.4453125MB
INFO:root:[  114] Training loss: 0.76215900, Validation loss: 0.67785825, Gradient norm: 16.87186646
INFO:root:At the start of the epoch: mem (CPU python)=37343.73046875MB; mem (CPU total)=37076.56640625MB
INFO:root:[  115] Training loss: 0.76167966, Validation loss: 0.67693393, Gradient norm: 17.36028407
INFO:root:At the start of the epoch: mem (CPU python)=37364.89453125MB; mem (CPU total)=37097.6953125MB
INFO:root:[  116] Training loss: 0.76156166, Validation loss: 0.67784800, Gradient norm: 17.05747302
INFO:root:At the start of the epoch: mem (CPU python)=37386.0625MB; mem (CPU total)=37118.7734375MB
INFO:root:[  117] Training loss: 0.76159143, Validation loss: 0.67463992, Gradient norm: 16.74140491
INFO:root:At the start of the epoch: mem (CPU python)=37407.2265625MB; mem (CPU total)=37140.33984375MB
INFO:root:[  118] Training loss: 0.76168840, Validation loss: 0.67715054, Gradient norm: 17.47806177
INFO:root:At the start of the epoch: mem (CPU python)=37428.38671875MB; mem (CPU total)=37161.84765625MB
INFO:root:[  119] Training loss: 0.76178376, Validation loss: 0.67685236, Gradient norm: 20.21543616
INFO:root:At the start of the epoch: mem (CPU python)=37449.546875MB; mem (CPU total)=37182.984375MB
INFO:root:[  120] Training loss: 0.76175267, Validation loss: 0.67577624, Gradient norm: 18.90195166
INFO:root:At the start of the epoch: mem (CPU python)=37470.7109375MB; mem (CPU total)=37204.12890625MB
INFO:root:[  121] Training loss: 0.76175934, Validation loss: 0.67715007, Gradient norm: 20.04733646
INFO:root:At the start of the epoch: mem (CPU python)=37491.87890625MB; mem (CPU total)=37225.2890625MB
INFO:root:[  122] Training loss: 0.76090200, Validation loss: 0.67700672, Gradient norm: 19.37373097
INFO:root:At the start of the epoch: mem (CPU python)=37513.04296875MB; mem (CPU total)=37246.12890625MB
INFO:root:[  123] Training loss: 0.76122777, Validation loss: 0.67744257, Gradient norm: 20.25425258
INFO:root:At the start of the epoch: mem (CPU python)=37534.20703125MB; mem (CPU total)=37267.53515625MB
INFO:root:[  124] Training loss: 0.76078410, Validation loss: 0.67835502, Gradient norm: 19.21538500
INFO:root:At the start of the epoch: mem (CPU python)=37555.37109375MB; mem (CPU total)=37288.6875MB
INFO:root:[  125] Training loss: 0.76068578, Validation loss: 0.67570367, Gradient norm: 20.84526132
INFO:root:At the start of the epoch: mem (CPU python)=37576.53515625MB; mem (CPU total)=37309.8671875MB
INFO:root:[  126] Training loss: 0.76033544, Validation loss: 0.67655443, Gradient norm: 20.13239862
INFO:root:At the start of the epoch: mem (CPU python)=37597.703125MB; mem (CPU total)=37330.98828125MB
INFO:root:EP 126: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=37618.63671875MB; mem (CPU total)=37351.90234375MB
INFO:root:Training the model took 7322.35s.
INFO:root:Emptying the cuda cache took 0.063s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 1.26975
INFO:root:EnergyScoreValidation: 0.67146
INFO:root:CRPSValidation: 0.30468
INFO:root:Gaussian NLLValidation: 10.31221
INFO:root:CoverageValidation: 0.63817
INFO:root:IntervalWidthValidation: 1.57475
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 1.3281
INFO:root:EnergyScoreTest: 0.69721
INFO:root:CRPSTest: 0.31237
INFO:root:Gaussian NLLTest: 6.73576
INFO:root:CoverageTest: 0.65113
INFO:root:IntervalWidthTest: 1.66469
INFO:root:After validation: mem (CPU python)=37664.75390625MB; mem (CPU total)=37363.53515625MB
