INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=583.5703125MB; mem (CPU total)=16689.31640625MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_fourier_dropout4.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12462.3359375MB; mem (CPU total)=16727.37890625MB
INFO:root:###1 out of 5 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': 0.1, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12462.3359375MB; mem (CPU total)=16727.37890625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12462.3359375MB; mem (CPU total)=18066.74609375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=18080.28125MB
INFO:root:[    1] Training loss: 0.81049453, Validation loss: 0.74435805, Gradient norm: 1.06915908
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=19822.83203125MB
INFO:root:[    2] Training loss: 0.73796884, Validation loss: 0.74281033, Gradient norm: 0.89726140
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=19882.19921875MB
INFO:root:[    3] Training loss: 0.73203172, Validation loss: 0.73417870, Gradient norm: 0.57811179
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=19954.01171875MB
INFO:root:[    4] Training loss: 0.72947828, Validation loss: 0.73132658, Gradient norm: 0.50255716
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20017.81640625MB
INFO:root:[    5] Training loss: 0.72854235, Validation loss: 0.73140117, Gradient norm: 0.38718038
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20076.921875MB
INFO:root:[    6] Training loss: 0.72768068, Validation loss: 0.73096612, Gradient norm: 0.35872784
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20144.5234375MB
INFO:root:[    7] Training loss: 0.72665302, Validation loss: 0.72918865, Gradient norm: 0.39644998
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20212.12890625MB
INFO:root:[    8] Training loss: 0.72663946, Validation loss: 0.72933651, Gradient norm: 0.37072048
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20271.03125MB
INFO:root:[    9] Training loss: 0.72520682, Validation loss: 0.72857402, Gradient norm: 0.31721013
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20334.71484375MB
INFO:root:[   10] Training loss: 0.72619896, Validation loss: 0.72844778, Gradient norm: 0.34726102
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20406.8515625MB
INFO:root:[   11] Training loss: 0.72603730, Validation loss: 0.73252394, Gradient norm: 0.30115497
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20465.921875MB
INFO:root:[   12] Training loss: 0.72498317, Validation loss: 0.72991227, Gradient norm: 0.31827703
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20526.2421875MB
INFO:root:[   13] Training loss: 0.72519626, Validation loss: 0.72914653, Gradient norm: 0.27501162
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20601.7890625MB
INFO:root:[   14] Training loss: 0.72486368, Validation loss: 0.72830624, Gradient norm: 0.24553633
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20662.07421875MB
INFO:root:[   15] Training loss: 0.72355879, Validation loss: 0.72973821, Gradient norm: 0.25127980
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20721.7734375MB
INFO:root:[   16] Training loss: 0.72435338, Validation loss: 0.73109433, Gradient norm: 0.23443201
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20791.63671875MB
INFO:root:[   17] Training loss: 0.72509484, Validation loss: 0.72948145, Gradient norm: 0.23719579
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20857.3125MB
INFO:root:[   18] Training loss: 0.72462379, Validation loss: 0.72779284, Gradient norm: 0.24550960
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20917.578125MB
INFO:root:[   19] Training loss: 0.72449312, Validation loss: 0.72701320, Gradient norm: 0.25428106
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=20982.76953125MB
INFO:root:[   20] Training loss: 0.72458632, Validation loss: 0.72645787, Gradient norm: 0.22199675
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21052.35546875MB
INFO:root:[   21] Training loss: 0.72339649, Validation loss: 0.72560806, Gradient norm: 0.25266001
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21112.6328125MB
INFO:root:[   22] Training loss: 0.72324829, Validation loss: 0.72755233, Gradient norm: 0.20726831
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21172.9140625MB
INFO:root:[   23] Training loss: 0.72409351, Validation loss: 0.72675728, Gradient norm: 0.20887240
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21248.6953125MB
INFO:root:[   24] Training loss: 0.72364674, Validation loss: 0.72493416, Gradient norm: 0.20890853
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21307.5625MB
INFO:root:[   25] Training loss: 0.72289711, Validation loss: 0.72598158, Gradient norm: 0.19579911
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21367.59765625MB
INFO:root:[   26] Training loss: 0.72341876, Validation loss: 0.72522780, Gradient norm: 0.21223322
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21439.1875MB
INFO:root:[   27] Training loss: 0.72255901, Validation loss: 0.72548930, Gradient norm: 0.21044009
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21503.16015625MB
INFO:root:[   28] Training loss: 0.72276336, Validation loss: 0.72740148, Gradient norm: 0.19929216
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21563.04296875MB
INFO:root:[   29] Training loss: 0.72224509, Validation loss: 0.72865213, Gradient norm: 0.19138122
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21629.91796875MB
INFO:root:[   30] Training loss: 0.72314767, Validation loss: 0.72491609, Gradient norm: 0.21804180
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21699.55078125MB
INFO:root:[   31] Training loss: 0.72249246, Validation loss: 0.72585212, Gradient norm: 0.20275488
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21759.578125MB
INFO:root:[   32] Training loss: 0.72169725, Validation loss: 0.72503677, Gradient norm: 0.21214772
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21820.578125MB
INFO:root:[   33] Training loss: 0.72148190, Validation loss: 0.72375615, Gradient norm: 0.19181935
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21897.36328125MB
INFO:root:[   34] Training loss: 0.72171107, Validation loss: 0.72400832, Gradient norm: 0.19473282
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=21956.68359375MB
INFO:root:[   35] Training loss: 0.72084749, Validation loss: 0.72300124, Gradient norm: 0.19786324
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22017.203125MB
INFO:root:[   36] Training loss: 0.71892557, Validation loss: 0.71837036, Gradient norm: 0.17869127
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22088.07421875MB
INFO:root:[   37] Training loss: 0.71799535, Validation loss: 0.71974136, Gradient norm: 0.17590503
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22154.22265625MB
INFO:root:[   38] Training loss: 0.71619828, Validation loss: 0.71697173, Gradient norm: 0.20189007
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22215.24609375MB
INFO:root:[   39] Training loss: 0.71492322, Validation loss: 0.71709579, Gradient norm: 0.17757815
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22279.1953125MB
INFO:root:[   40] Training loss: 0.71282386, Validation loss: 0.71453796, Gradient norm: 0.17756091
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22352.7890625MB
INFO:root:[   41] Training loss: 0.71125299, Validation loss: 0.71270563, Gradient norm: 0.18821946
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22412.37890625MB
INFO:root:[   42] Training loss: 0.70971639, Validation loss: 0.71146208, Gradient norm: 0.20233472
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22472.91015625MB
INFO:root:[   43] Training loss: 0.70744246, Validation loss: 0.71101581, Gradient norm: 0.20995573
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22546.37890625MB
INFO:root:[   44] Training loss: 0.70647026, Validation loss: 0.70762467, Gradient norm: 0.21761680
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22610.8828125MB
INFO:root:[   45] Training loss: 0.70455009, Validation loss: 0.70550679, Gradient norm: 0.25476422
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22670.46875MB
INFO:root:[   46] Training loss: 0.70282618, Validation loss: 0.70576629, Gradient norm: 0.27015410
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22736.65625MB
INFO:root:[   47] Training loss: 0.70124201, Validation loss: 0.70333584, Gradient norm: 0.29704204
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22808.5MB
INFO:root:[   48] Training loss: 0.69931102, Validation loss: 0.69935698, Gradient norm: 0.25838508
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22868.51171875MB
INFO:root:[   49] Training loss: 0.69852412, Validation loss: 0.69983560, Gradient norm: 0.30920408
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=22929.0390625MB
INFO:root:[   50] Training loss: 0.69630127, Validation loss: 0.69743193, Gradient norm: 0.30459953
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23004.04296875MB
INFO:root:[   51] Training loss: 0.69480810, Validation loss: 0.69757210, Gradient norm: 0.30257787
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23066.8046875MB
INFO:root:[   52] Training loss: 0.69418891, Validation loss: 0.69504826, Gradient norm: 0.34693780
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23128.2109375MB
INFO:root:[   53] Training loss: 0.69271193, Validation loss: 0.69357320, Gradient norm: 0.33012038
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23195.0MB
INFO:root:[   54] Training loss: 0.69117437, Validation loss: 0.69177938, Gradient norm: 0.29877589
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23266.86328125MB
INFO:root:[   55] Training loss: 0.69049795, Validation loss: 0.69090299, Gradient norm: 0.34000094
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23327.39453125MB
INFO:root:[   56] Training loss: 0.68878960, Validation loss: 0.68929074, Gradient norm: 0.29843064
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23389.06640625MB
INFO:root:[   57] Training loss: 0.68762247, Validation loss: 0.68827112, Gradient norm: 0.39325319
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23433.61328125MB
INFO:root:[   58] Training loss: 0.68577539, Validation loss: 0.68708094, Gradient norm: 0.30855572
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23478.625MB
INFO:root:[   59] Training loss: 0.68516740, Validation loss: 0.68648420, Gradient norm: 0.37664527
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23522.9375MB
INFO:root:[   60] Training loss: 0.68381377, Validation loss: 0.68490879, Gradient norm: 0.34482516
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23567.4765625MB
INFO:root:[   61] Training loss: 0.68300581, Validation loss: 0.68504559, Gradient norm: 0.37637480
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23611.51171875MB
INFO:root:[   62] Training loss: 0.68130770, Validation loss: 0.68198158, Gradient norm: 0.35877297
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23656.5390625MB
INFO:root:[   63] Training loss: 0.68031297, Validation loss: 0.68131939, Gradient norm: 0.35174666
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23699.4296875MB
INFO:root:[   64] Training loss: 0.67901193, Validation loss: 0.68132191, Gradient norm: 0.35153139
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23739.44140625MB
INFO:root:[   65] Training loss: 0.67858498, Validation loss: 0.67903903, Gradient norm: 0.36197437
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23816.07421875MB
INFO:root:[   66] Training loss: 0.67692676, Validation loss: 0.67860566, Gradient norm: 0.34063361
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23875.6953125MB
INFO:root:[   67] Training loss: 0.67588638, Validation loss: 0.67863097, Gradient norm: 0.33286804
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=23936.75390625MB
INFO:root:[   68] Training loss: 0.67554288, Validation loss: 0.67675291, Gradient norm: 0.39181058
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24006.15234375MB
INFO:root:[   69] Training loss: 0.67446216, Validation loss: 0.67565042, Gradient norm: 0.38945512
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24075.8046875MB
INFO:root:[   70] Training loss: 0.67413448, Validation loss: 0.67589772, Gradient norm: 0.38278698
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24136.78515625MB
INFO:root:[   71] Training loss: 0.67317188, Validation loss: 0.67339195, Gradient norm: 0.38039043
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24197.55078125MB
INFO:root:[   72] Training loss: 0.67234979, Validation loss: 0.67538739, Gradient norm: 0.43630420
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24272.11328125MB
INFO:root:[   73] Training loss: 0.67176654, Validation loss: 0.67210739, Gradient norm: 0.34180148
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24337.57421875MB
INFO:root:[   74] Training loss: 0.67048422, Validation loss: 0.67241857, Gradient norm: 0.39418117
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24399.09765625MB
INFO:root:[   75] Training loss: 0.66940217, Validation loss: 0.67143235, Gradient norm: 0.33475332
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24462.8671875MB
INFO:root:[   76] Training loss: 0.66921578, Validation loss: 0.67171836, Gradient norm: 0.37535319
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24539.4296875MB
INFO:root:[   77] Training loss: 0.66836846, Validation loss: 0.67157247, Gradient norm: 0.33826921
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24600.703125MB
INFO:root:[   78] Training loss: 0.66767948, Validation loss: 0.66968766, Gradient norm: 0.33482905
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24662.5MB
INFO:root:[   79] Training loss: 0.66745163, Validation loss: 0.66826218, Gradient norm: 0.38822648
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24729.90234375MB
INFO:root:[   80] Training loss: 0.66669815, Validation loss: 0.66933923, Gradient norm: 0.35448084
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24803.7421875MB
INFO:root:[   81] Training loss: 0.66573166, Validation loss: 0.66758891, Gradient norm: 0.47313044
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24864.98828125MB
INFO:root:[   82] Training loss: 0.66432662, Validation loss: 0.66657698, Gradient norm: 0.35879989
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24926.703125MB
INFO:root:[   83] Training loss: 0.66422626, Validation loss: 0.66590029, Gradient norm: 0.34161244
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=24997.50390625MB
INFO:root:[   84] Training loss: 0.66337042, Validation loss: 0.66536622, Gradient norm: 0.29723355
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25068.80078125MB
INFO:root:[   85] Training loss: 0.66243521, Validation loss: 0.66433910, Gradient norm: 0.32861309
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25129.46484375MB
INFO:root:[   86] Training loss: 0.66240664, Validation loss: 0.66505841, Gradient norm: 0.39386487
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25191.71484375MB
INFO:root:[   87] Training loss: 0.66185039, Validation loss: 0.66328589, Gradient norm: 0.40068524
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25264.3359375MB
INFO:root:[   88] Training loss: 0.66111663, Validation loss: 0.66372490, Gradient norm: 0.38892440
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25332.4609375MB
INFO:root:[   89] Training loss: 0.66036350, Validation loss: 0.66258633, Gradient norm: 0.35427909
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25394.69140625MB
INFO:root:[   90] Training loss: 0.65953230, Validation loss: 0.66229059, Gradient norm: 0.35239270
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25456.78125MB
INFO:root:[   91] Training loss: 0.65893776, Validation loss: 0.66159409, Gradient norm: 0.38330440
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25531.359375MB
INFO:root:[   92] Training loss: 0.65931149, Validation loss: 0.66206910, Gradient norm: 0.40914135
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25597.33984375MB
INFO:root:[   93] Training loss: 0.65764964, Validation loss: 0.66044418, Gradient norm: 0.38196934
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25659.8515625MB
INFO:root:[   94] Training loss: 0.65748931, Validation loss: 0.66077095, Gradient norm: 0.37495700
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25721.8984375MB
INFO:root:[   95] Training loss: 0.65660387, Validation loss: 0.65926180, Gradient norm: 0.38945212
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25798.41015625MB
INFO:root:[   96] Training loss: 0.65581676, Validation loss: 0.65874797, Gradient norm: 0.41918535
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25863.375MB
INFO:root:[   97] Training loss: 0.65587383, Validation loss: 0.65933320, Gradient norm: 0.40249851
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25925.84765625MB
INFO:root:[   98] Training loss: 0.65535420, Validation loss: 0.65792496, Gradient norm: 0.33210027
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=25989.140625MB
INFO:root:[   99] Training loss: 0.65451286, Validation loss: 0.65935271, Gradient norm: 0.45893567
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26065.42578125MB
INFO:root:[  100] Training loss: 0.65470714, Validation loss: 0.65852936, Gradient norm: 0.51691499
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26130.1484375MB
INFO:root:[  101] Training loss: 0.65394699, Validation loss: 0.65677396, Gradient norm: 0.44757295
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26192.44921875MB
INFO:root:[  102] Training loss: 0.65343478, Validation loss: 0.65734042, Gradient norm: 0.46115992
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26256.4296875MB
INFO:root:[  103] Training loss: 0.65237340, Validation loss: 0.65587084, Gradient norm: 0.35562798
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26332.90625MB
INFO:root:[  104] Training loss: 0.65146540, Validation loss: 0.65361402, Gradient norm: 0.35850820
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26397.609375MB
INFO:root:[  105] Training loss: 0.65109984, Validation loss: 0.65478373, Gradient norm: 0.37056522
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26460.12109375MB
INFO:root:[  106] Training loss: 0.65102154, Validation loss: 0.65471463, Gradient norm: 0.38723384
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26524.328125MB
INFO:root:[  107] Training loss: 0.64994150, Validation loss: 0.65373692, Gradient norm: 0.38297007
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26600.12109375MB
INFO:root:[  108] Training loss: 0.64993724, Validation loss: 0.65308167, Gradient norm: 0.39447809
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26665.0625MB
INFO:root:[  109] Training loss: 0.64897745, Validation loss: 0.65242549, Gradient norm: 0.39767153
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26727.83203125MB
INFO:root:[  110] Training loss: 0.64870689, Validation loss: 0.65332493, Gradient norm: 0.41110471
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26790.7734375MB
INFO:root:[  111] Training loss: 0.64832519, Validation loss: 0.65360020, Gradient norm: 0.36198203
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26867.08984375MB
INFO:root:[  112] Training loss: 0.64797043, Validation loss: 0.65263382, Gradient norm: 0.41041037
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26933.28515625MB
INFO:root:[  113] Training loss: 0.64694771, Validation loss: 0.65191290, Gradient norm: 0.35843514
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=26996.28125MB
INFO:root:[  114] Training loss: 0.64679505, Validation loss: 0.65228009, Gradient norm: 0.40976441
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27057.92578125MB
INFO:root:[  115] Training loss: 0.64640502, Validation loss: 0.65010858, Gradient norm: 0.32210553
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27133.625MB
INFO:root:[  116] Training loss: 0.64569382, Validation loss: 0.65161985, Gradient norm: 0.36143048
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27201.44921875MB
INFO:root:[  117] Training loss: 0.64517802, Validation loss: 0.64922074, Gradient norm: 0.37890048
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27264.15625MB
INFO:root:[  118] Training loss: 0.64512629, Validation loss: 0.65004510, Gradient norm: 0.37149109
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27328.05859375MB
INFO:root:[  119] Training loss: 0.64456234, Validation loss: 0.64932490, Gradient norm: 0.43553634
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27401.265625MB
INFO:root:[  120] Training loss: 0.64427162, Validation loss: 0.64865519, Gradient norm: 0.35606120
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27471.296875MB
INFO:root:[  121] Training loss: 0.64304630, Validation loss: 0.64822542, Gradient norm: 0.49146565
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27533.7890625MB
INFO:root:[  122] Training loss: 0.64301306, Validation loss: 0.64823328, Gradient norm: 0.34869941
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27596.953125MB
INFO:root:[  123] Training loss: 0.64259516, Validation loss: 0.64775271, Gradient norm: 0.39475724
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27668.12109375MB
INFO:root:[  124] Training loss: 0.64213744, Validation loss: 0.64622584, Gradient norm: 0.41811519
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27741.43359375MB
INFO:root:[  125] Training loss: 0.64145042, Validation loss: 0.64623884, Gradient norm: 0.39107821
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27803.19140625MB
INFO:root:[  126] Training loss: 0.64113655, Validation loss: 0.64632897, Gradient norm: 0.34525923
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27866.17578125MB
INFO:root:[  127] Training loss: 0.64065733, Validation loss: 0.64415014, Gradient norm: 0.42725400
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=27935.3125MB
INFO:root:[  128] Training loss: 0.64001720, Validation loss: 0.64546516, Gradient norm: 0.38208943
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28011.3046875MB
INFO:root:[  129] Training loss: 0.63937019, Validation loss: 0.64590188, Gradient norm: 0.37694468
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28074.5859375MB
INFO:root:[  130] Training loss: 0.63915784, Validation loss: 0.64395423, Gradient norm: 0.36398911
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28138.5625MB
INFO:root:[  131] Training loss: 0.63897498, Validation loss: 0.64335231, Gradient norm: 0.46638978
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28205.0MB
INFO:root:[  132] Training loss: 0.63832729, Validation loss: 0.64304298, Gradient norm: 0.39946078
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28282.19140625MB
INFO:root:[  133] Training loss: 0.63852722, Validation loss: 0.64357961, Gradient norm: 0.43461617
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28346.125MB
INFO:root:[  134] Training loss: 0.63782124, Validation loss: 0.64375662, Gradient norm: 0.37226015
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28408.484375MB
INFO:root:[  135] Training loss: 0.63749140, Validation loss: 0.64303793, Gradient norm: 0.38901755
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28472.91015625MB
INFO:root:[  136] Training loss: 0.63693394, Validation loss: 0.64256223, Gradient norm: 0.39462389
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28549.2265625MB
INFO:root:[  137] Training loss: 0.63677267, Validation loss: 0.64119024, Gradient norm: 0.37675869
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28615.15234375MB
INFO:root:[  138] Training loss: 0.63610898, Validation loss: 0.64160549, Gradient norm: 0.39804394
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28677.65234375MB
INFO:root:[  139] Training loss: 0.63550964, Validation loss: 0.64178718, Gradient norm: 0.40963047
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28740.53125MB
INFO:root:[  140] Training loss: 0.63527697, Validation loss: 0.64117132, Gradient norm: 0.37644259
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28816.109375MB
INFO:root:[  141] Training loss: 0.63511307, Validation loss: 0.64031640, Gradient norm: 0.40783761
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28884.95703125MB
INFO:root:[  142] Training loss: 0.63450017, Validation loss: 0.64147092, Gradient norm: 0.38675550
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=28947.140625MB
INFO:root:[  143] Training loss: 0.63442826, Validation loss: 0.63991925, Gradient norm: 0.41307848
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29010.26171875MB
INFO:root:[  144] Training loss: 0.63379499, Validation loss: 0.64213463, Gradient norm: 0.35611690
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29083.7109375MB
INFO:root:[  145] Training loss: 0.63297987, Validation loss: 0.64086098, Gradient norm: 0.40466612
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29155.19921875MB
INFO:root:[  146] Training loss: 0.63335528, Validation loss: 0.63960804, Gradient norm: 0.35495804
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29217.0234375MB
INFO:root:[  147] Training loss: 0.63267851, Validation loss: 0.64077686, Gradient norm: 0.37679057
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29279.4921875MB
INFO:root:[  148] Training loss: 0.63278190, Validation loss: 0.63923836, Gradient norm: 0.38964412
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29350.21875MB
INFO:root:[  149] Training loss: 0.63255722, Validation loss: 0.63885957, Gradient norm: 0.35868708
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29425.453125MB
INFO:root:[  150] Training loss: 0.63162747, Validation loss: 0.63824248, Gradient norm: 0.36192718
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29487.4140625MB
INFO:root:[  151] Training loss: 0.63163232, Validation loss: 0.63883722, Gradient norm: 0.36174558
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29549.7890625MB
INFO:root:[  152] Training loss: 0.63083105, Validation loss: 0.63836109, Gradient norm: 0.38747099
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29617.484375MB
INFO:root:[  153] Training loss: 0.63052071, Validation loss: 0.63801809, Gradient norm: 0.37641358
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29693.37109375MB
INFO:root:[  154] Training loss: 0.63076365, Validation loss: 0.63783441, Gradient norm: 0.41939049
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29757.77734375MB
INFO:root:[  155] Training loss: 0.63041983, Validation loss: 0.63809572, Gradient norm: 0.41151907
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29820.64453125MB
INFO:root:[  156] Training loss: 0.62992225, Validation loss: 0.63774964, Gradient norm: 0.40258134
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29884.27734375MB
INFO:root:[  157] Training loss: 0.62941488, Validation loss: 0.63693346, Gradient norm: 0.34206373
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=29960.64453125MB
INFO:root:[  158] Training loss: 0.62918765, Validation loss: 0.63692563, Gradient norm: 0.37451785
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30028.71875MB
INFO:root:[  159] Training loss: 0.62883152, Validation loss: 0.63680870, Gradient norm: 0.37912513
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30091.1015625MB
INFO:root:[  160] Training loss: 0.62856080, Validation loss: 0.63556045, Gradient norm: 0.37782473
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30153.828125MB
INFO:root:[  161] Training loss: 0.62848664, Validation loss: 0.63657094, Gradient norm: 0.45818815
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30228.6171875MB
INFO:root:[  162] Training loss: 0.62845460, Validation loss: 0.63562061, Gradient norm: 0.45463850
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30301.69140625MB
INFO:root:[  163] Training loss: 0.62764542, Validation loss: 0.63566895, Gradient norm: 0.39408154
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30363.50390625MB
INFO:root:[  164] Training loss: 0.62767453, Validation loss: 0.63704355, Gradient norm: 0.48314359
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30426.3359375MB
INFO:root:[  165] Training loss: 0.62692904, Validation loss: 0.63542209, Gradient norm: 0.40981163
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30495.3125MB
INFO:root:[  166] Training loss: 0.62621836, Validation loss: 0.63613141, Gradient norm: 0.44980654
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30571.48828125MB
INFO:root:[  167] Training loss: 0.62654810, Validation loss: 0.63486177, Gradient norm: 0.38559168
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30634.41796875MB
INFO:root:[  168] Training loss: 0.62615170, Validation loss: 0.63465443, Gradient norm: 0.38177327
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30697.109375MB
INFO:root:[  169] Training loss: 0.62591999, Validation loss: 0.63455077, Gradient norm: 0.40395580
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30761.078125MB
INFO:root:[  170] Training loss: 0.62577204, Validation loss: 0.63383621, Gradient norm: 0.39949044
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30837.53515625MB
INFO:root:[  171] Training loss: 0.62538393, Validation loss: 0.63469632, Gradient norm: 0.41340568
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30905.78125MB
INFO:root:[  172] Training loss: 0.62505054, Validation loss: 0.63479968, Gradient norm: 0.40253140
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=30968.50390625MB
INFO:root:[  173] Training loss: 0.62462675, Validation loss: 0.63357696, Gradient norm: 0.40523591
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31031.74609375MB
INFO:root:[  174] Training loss: 0.62428123, Validation loss: 0.63392700, Gradient norm: 0.41520562
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31103.8671875MB
INFO:root:[  175] Training loss: 0.62454907, Validation loss: 0.63305914, Gradient norm: 0.41598825
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31178.94140625MB
INFO:root:[  176] Training loss: 0.62415990, Validation loss: 0.63360605, Gradient norm: 0.43361684
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31241.76171875MB
INFO:root:[  177] Training loss: 0.62362324, Validation loss: 0.63394871, Gradient norm: 0.43214309
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31304.75MB
INFO:root:[  178] Training loss: 0.62344567, Validation loss: 0.63303871, Gradient norm: 0.42325276
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31370.94921875MB
INFO:root:[  179] Training loss: 0.62313352, Validation loss: 0.63235250, Gradient norm: 0.43215284
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31447.23828125MB
INFO:root:[  180] Training loss: 0.62261293, Validation loss: 0.63238115, Gradient norm: 0.40634502
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31513.69921875MB
INFO:root:[  181] Training loss: 0.62266565, Validation loss: 0.63333001, Gradient norm: 0.48600296
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31576.7109375MB
INFO:root:[  182] Training loss: 0.62221117, Validation loss: 0.63208187, Gradient norm: 0.37700679
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31640.21875MB
INFO:root:[  183] Training loss: 0.62192121, Validation loss: 0.63215020, Gradient norm: 0.43016035
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31715.05078125MB
INFO:root:[  184] Training loss: 0.62185020, Validation loss: 0.63200910, Gradient norm: 0.40394646
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31785.90625MB
INFO:root:[  185] Training loss: 0.62134959, Validation loss: 0.63148000, Gradient norm: 0.42120291
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31847.8984375MB
INFO:root:[  186] Training loss: 0.62131794, Validation loss: 0.63134262, Gradient norm: 0.43554629
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31910.44140625MB
INFO:root:[  187] Training loss: 0.62074319, Validation loss: 0.63127347, Gradient norm: 0.47622762
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=31980.03515625MB
INFO:root:[  188] Training loss: 0.62035212, Validation loss: 0.63153702, Gradient norm: 0.41687068
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32056.46484375MB
INFO:root:[  189] Training loss: 0.62056578, Validation loss: 0.63003753, Gradient norm: 0.42381421
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32118.2890625MB
INFO:root:[  190] Training loss: 0.61997989, Validation loss: 0.63146908, Gradient norm: 0.44144464
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32181.3046875MB
INFO:root:[  191] Training loss: 0.61999878, Validation loss: 0.63032297, Gradient norm: 0.40597379
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32247.9921875MB
INFO:root:[  192] Training loss: 0.61956926, Validation loss: 0.63084371, Gradient norm: 0.38114411
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32324.0625MB
INFO:root:[  193] Training loss: 0.61946251, Validation loss: 0.62932123, Gradient norm: 0.36426315
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32389.828125MB
INFO:root:[  194] Training loss: 0.61921626, Validation loss: 0.63121873, Gradient norm: 0.42605440
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32452.8359375MB
INFO:root:[  195] Training loss: 0.61924571, Validation loss: 0.63232843, Gradient norm: 0.40416432
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32515.390625MB
INFO:root:[  196] Training loss: 0.61916898, Validation loss: 0.63010993, Gradient norm: 0.54809580
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32591.640625MB
INFO:root:[  197] Training loss: 0.61853105, Validation loss: 0.63056341, Gradient norm: 0.35265101
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32662.16796875MB
INFO:root:[  198] Training loss: 0.61818970, Validation loss: 0.63015182, Gradient norm: 0.46375508
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32724.0390625MB
INFO:root:[  199] Training loss: 0.61820651, Validation loss: 0.63053953, Gradient norm: 0.39098219
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32786.49609375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  200] Training loss: 0.61771294, Validation loss: 0.62973581, Gradient norm: 0.50312997
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32858.265625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  201] Training loss: 0.61633818, Validation loss: 0.62766247, Gradient norm: 0.28658741
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32933.5546875MB
INFO:root:[  202] Training loss: 0.61538961, Validation loss: 0.62773165, Gradient norm: 0.20881602
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=32995.31640625MB
INFO:root:[  203] Training loss: 0.61493366, Validation loss: 0.62849407, Gradient norm: 0.21136401
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33057.2890625MB
INFO:root:[  204] Training loss: 0.61491706, Validation loss: 0.62734320, Gradient norm: 0.21591947
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33125.75390625MB
INFO:root:[  205] Training loss: 0.61474624, Validation loss: 0.62813344, Gradient norm: 0.21501526
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33201.7890625MB
INFO:root:[  206] Training loss: 0.61474036, Validation loss: 0.62879018, Gradient norm: 0.22306205
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33266.76171875MB
INFO:root:[  207] Training loss: 0.61456864, Validation loss: 0.62921386, Gradient norm: 0.21365148
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33329.25390625MB
INFO:root:[  208] Training loss: 0.61450760, Validation loss: 0.62766610, Gradient norm: 0.22930914
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33393.31640625MB
INFO:root:[  209] Training loss: 0.61431097, Validation loss: 0.62697476, Gradient norm: 0.24731845
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33469.4453125MB
INFO:root:[  210] Training loss: 0.61366668, Validation loss: 0.62764507, Gradient norm: 0.23041600
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33538.88671875MB
INFO:root:[  211] Training loss: 0.61465252, Validation loss: 0.62693776, Gradient norm: 0.23199477
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33600.9296875MB
INFO:root:[  212] Training loss: 0.61434883, Validation loss: 0.62782831, Gradient norm: 0.26022193
INFO:root:At the start of the epoch: mem (CPU python)=12462.3359375MB; mem (CPU total)=33663.43359375MB
INFO:root:[  213] Training loss: 0.61487177, Validation loss: 0.62863579, Gradient norm: 0.29098229
INFO:root:At the start of the epoch: mem (CPU python)=12479.50390625MB; mem (CPU total)=33736.7734375MB
INFO:root:[  214] Training loss: 0.61444764, Validation loss: 0.62774680, Gradient norm: 0.28205680
INFO:root:At the start of the epoch: mem (CPU python)=12517.6015625MB; mem (CPU total)=33810.58984375MB
INFO:root:[  215] Training loss: 0.61406693, Validation loss: 0.62657442, Gradient norm: 0.26473797
INFO:root:At the start of the epoch: mem (CPU python)=12555.765625MB; mem (CPU total)=33872.546875MB
INFO:root:[  216] Training loss: 0.61366353, Validation loss: 0.62766501, Gradient norm: 0.25194279
INFO:root:At the start of the epoch: mem (CPU python)=12593.86328125MB; mem (CPU total)=33935.296875MB
INFO:root:[  217] Training loss: 0.61340140, Validation loss: 0.62775071, Gradient norm: 0.25315770
INFO:root:At the start of the epoch: mem (CPU python)=12631.95703125MB; mem (CPU total)=34003.46484375MB
INFO:root:[  218] Training loss: 0.61381969, Validation loss: 0.62731377, Gradient norm: 0.23811889
INFO:root:At the start of the epoch: mem (CPU python)=12670.05078125MB; mem (CPU total)=34080.6484375MB
INFO:root:[  219] Training loss: 0.61379126, Validation loss: 0.62680137, Gradient norm: 0.23532813
INFO:root:At the start of the epoch: mem (CPU python)=12708.1484375MB; mem (CPU total)=34145.8671875MB
INFO:root:[  220] Training loss: 0.61356032, Validation loss: 0.62858465, Gradient norm: 0.26860812
INFO:root:At the start of the epoch: mem (CPU python)=12746.24609375MB; mem (CPU total)=34208.41796875MB
INFO:root:[  221] Training loss: 0.61374972, Validation loss: 0.62807310, Gradient norm: 0.28289782
INFO:root:At the start of the epoch: mem (CPU python)=12784.33984375MB; mem (CPU total)=34271.1640625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  222] Training loss: 0.61353989, Validation loss: 0.62715599, Gradient norm: 0.24142599
INFO:root:At the start of the epoch: mem (CPU python)=12822.43359375MB; mem (CPU total)=34347.68359375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  223] Training loss: 0.61348061, Validation loss: 0.62638551, Gradient norm: 0.19572648
INFO:root:At the start of the epoch: mem (CPU python)=12860.53125MB; mem (CPU total)=34418.3828125MB
INFO:root:[  224] Training loss: 0.61316500, Validation loss: 0.62645809, Gradient norm: 0.17620555
INFO:root:At the start of the epoch: mem (CPU python)=12898.625MB; mem (CPU total)=34480.796875MB
INFO:root:[  225] Training loss: 0.61293755, Validation loss: 0.62659812, Gradient norm: 0.18007561
INFO:root:At the start of the epoch: mem (CPU python)=12936.71875MB; mem (CPU total)=34543.3984375MB
INFO:root:[  226] Training loss: 0.61268626, Validation loss: 0.62820593, Gradient norm: 0.21335145
INFO:root:At the start of the epoch: mem (CPU python)=12974.81640625MB; mem (CPU total)=34614.70703125MB
INFO:root:[  227] Training loss: 0.61225104, Validation loss: 0.62761762, Gradient norm: 0.18224791
INFO:root:At the start of the epoch: mem (CPU python)=13012.91015625MB; mem (CPU total)=34690.75390625MB
INFO:root:[  228] Training loss: 0.61268970, Validation loss: 0.62663635, Gradient norm: 0.19171937
INFO:root:At the start of the epoch: mem (CPU python)=13051.00390625MB; mem (CPU total)=34753.01171875MB
INFO:root:[  229] Training loss: 0.61252774, Validation loss: 0.62657746, Gradient norm: 0.17896972
INFO:root:At the start of the epoch: mem (CPU python)=13089.1015625MB; mem (CPU total)=34814.78125MB
INFO:root:[  230] Training loss: 0.61232313, Validation loss: 0.62803685, Gradient norm: 0.17664119
INFO:root:At the start of the epoch: mem (CPU python)=13127.19921875MB; mem (CPU total)=34881.62109375MB
INFO:root:[  231] Training loss: 0.61228362, Validation loss: 0.62719160, Gradient norm: 0.19027935
INFO:root:At the start of the epoch: mem (CPU python)=13165.29296875MB; mem (CPU total)=34957.921875MB
INFO:root:[  232] Training loss: 0.61269259, Validation loss: 0.62822762, Gradient norm: 0.18864927
INFO:root:At the start of the epoch: mem (CPU python)=13203.38671875MB; mem (CPU total)=35024.86328125MB
INFO:root:EP 232: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=13241.30078125MB; mem (CPU total)=35075.515625MB
INFO:root:Training the model took 10068.821s.
INFO:root:Emptying the cuda cache took 0.048s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87051
INFO:root:EnergyScoreTrain: 0.61285
INFO:root:CRPSTrain: 0.51242
INFO:root:Gaussian NLLTrain: 1.56069
INFO:root:CoverageTrain: 0.8388
INFO:root:IntervalWidthTrain: 3.21864
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89025
INFO:root:EnergyScoreValidation: 0.62686
INFO:root:CRPSValidation: 0.52393
INFO:root:Gaussian NLLValidation: 1.58469
INFO:root:CoverageValidation: 0.83349
INFO:root:IntervalWidthValidation: 3.21612
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88992
INFO:root:EnergyScoreTest: 0.62662
INFO:root:CRPSTest: 0.52363
INFO:root:Gaussian NLLTest: 1.58348
INFO:root:CoverageTest: 0.83365
INFO:root:IntervalWidthTest: 3.21513
INFO:root:After validation: mem (CPU python)=13292.6484375MB; mem (CPU total)=35270.1328125MB
INFO:root:###2 out of 5 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': 0.1, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=13292.6484375MB; mem (CPU total)=35276.2890625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=13294.34765625MB; mem (CPU total)=35278.75MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=13294.34765625MB; mem (CPU total)=35290.3125MB
INFO:root:[    1] Training loss: 0.80959091, Validation loss: 0.74364445, Gradient norm: 1.17904529
INFO:root:At the start of the epoch: mem (CPU python)=13332.5625MB; mem (CPU total)=35352.1875MB
INFO:root:[    2] Training loss: 0.74028047, Validation loss: 0.74471220, Gradient norm: 1.24592713
INFO:root:At the start of the epoch: mem (CPU python)=13370.65625MB; mem (CPU total)=35424.32421875MB
INFO:root:[    3] Training loss: 0.73351661, Validation loss: 0.74111574, Gradient norm: 0.74921239
INFO:root:At the start of the epoch: mem (CPU python)=13408.765625MB; mem (CPU total)=35500.875MB
INFO:root:[    4] Training loss: 0.73057055, Validation loss: 0.73261511, Gradient norm: 0.71660949
INFO:root:At the start of the epoch: mem (CPU python)=13446.8828125MB; mem (CPU total)=35564.63671875MB
INFO:root:[    5] Training loss: 0.72907074, Validation loss: 0.73288650, Gradient norm: 0.51364085
INFO:root:At the start of the epoch: mem (CPU python)=13484.9921875MB; mem (CPU total)=35627.3984375MB
INFO:root:[    6] Training loss: 0.72794768, Validation loss: 0.73144989, Gradient norm: 0.43102509
INFO:root:At the start of the epoch: mem (CPU python)=13523.0859375MB; mem (CPU total)=35690.921875MB
INFO:root:[    7] Training loss: 0.72698407, Validation loss: 0.72946369, Gradient norm: 0.53560199
INFO:root:At the start of the epoch: mem (CPU python)=13561.203125MB; mem (CPU total)=35767.9453125MB
INFO:root:[    8] Training loss: 0.72698617, Validation loss: 0.72945468, Gradient norm: 0.44964978
INFO:root:At the start of the epoch: mem (CPU python)=13599.3125MB; mem (CPU total)=35838.83203125MB
INFO:root:[    9] Training loss: 0.72531141, Validation loss: 0.72854427, Gradient norm: 0.37526640
INFO:root:At the start of the epoch: mem (CPU python)=13637.421875MB; mem (CPU total)=35900.46875MB
INFO:root:[   10] Training loss: 0.72649948, Validation loss: 0.72764570, Gradient norm: 0.42065203
INFO:root:At the start of the epoch: mem (CPU python)=13675.52734375MB; mem (CPU total)=35963.171875MB
INFO:root:[   11] Training loss: 0.72615393, Validation loss: 0.73169803, Gradient norm: 0.34183799
INFO:root:At the start of the epoch: mem (CPU python)=13713.625MB; mem (CPU total)=36035.046875MB
INFO:root:[   12] Training loss: 0.72468266, Validation loss: 0.73177284, Gradient norm: 0.38351044
INFO:root:At the start of the epoch: mem (CPU python)=13751.71875MB; mem (CPU total)=36111.30078125MB
INFO:root:[   13] Training loss: 0.72492800, Validation loss: 0.72897711, Gradient norm: 0.36511799
INFO:root:At the start of the epoch: mem (CPU python)=13789.8125MB; mem (CPU total)=36175.59375MB
INFO:root:[   14] Training loss: 0.72472670, Validation loss: 0.72805991, Gradient norm: 0.30283618
INFO:root:At the start of the epoch: mem (CPU python)=13827.91015625MB; mem (CPU total)=36237.76953125MB
INFO:root:[   15] Training loss: 0.72356344, Validation loss: 0.72907748, Gradient norm: 0.30681962
INFO:root:At the start of the epoch: mem (CPU python)=13866.00390625MB; mem (CPU total)=36302.32421875MB
INFO:root:[   16] Training loss: 0.72451227, Validation loss: 0.72951771, Gradient norm: 0.27243796
INFO:root:At the start of the epoch: mem (CPU python)=13904.1015625MB; mem (CPU total)=36378.3359375MB
INFO:root:[   17] Training loss: 0.72510396, Validation loss: 0.72897413, Gradient norm: 0.28592339
INFO:root:At the start of the epoch: mem (CPU python)=13942.21875MB; mem (CPU total)=36450.23046875MB
INFO:root:[   18] Training loss: 0.72408202, Validation loss: 0.72839226, Gradient norm: 0.28566845
INFO:root:At the start of the epoch: mem (CPU python)=13980.3125MB; mem (CPU total)=36512.01953125MB
INFO:root:[   19] Training loss: 0.72460893, Validation loss: 0.72703164, Gradient norm: 0.31295253
INFO:root:At the start of the epoch: mem (CPU python)=14018.40625MB; mem (CPU total)=36575.984375MB
INFO:root:[   20] Training loss: 0.72417916, Validation loss: 0.72624066, Gradient norm: 0.26283699
INFO:root:At the start of the epoch: mem (CPU python)=14056.53125MB; mem (CPU total)=36623.234375MB
INFO:root:[   21] Training loss: 0.72352941, Validation loss: 0.72545592, Gradient norm: 0.28620345
INFO:root:At the start of the epoch: mem (CPU python)=14094.62890625MB; mem (CPU total)=36669.74609375MB
INFO:root:[   22] Training loss: 0.72326177, Validation loss: 0.72756921, Gradient norm: 0.25310591
INFO:root:At the start of the epoch: mem (CPU python)=14132.7265625MB; mem (CPU total)=36716.76171875MB
INFO:root:[   23] Training loss: 0.72409563, Validation loss: 0.72681393, Gradient norm: 0.25772032
INFO:root:At the start of the epoch: mem (CPU python)=14170.82421875MB; mem (CPU total)=36763.78125MB
INFO:root:[   24] Training loss: 0.72368336, Validation loss: 0.72548279, Gradient norm: 0.25835665
INFO:root:At the start of the epoch: mem (CPU python)=14208.921875MB; mem (CPU total)=36804.375MB
INFO:root:[   25] Training loss: 0.72276852, Validation loss: 0.72622980, Gradient norm: 0.24355976
INFO:root:At the start of the epoch: mem (CPU python)=14247.046875MB; mem (CPU total)=36877.51171875MB
INFO:root:[   26] Training loss: 0.72338134, Validation loss: 0.72430823, Gradient norm: 0.25192174
INFO:root:At the start of the epoch: mem (CPU python)=14285.2734375MB; mem (CPU total)=36940.11328125MB
INFO:root:[   27] Training loss: 0.72244959, Validation loss: 0.72570621, Gradient norm: 0.23064796
INFO:root:At the start of the epoch: mem (CPU python)=14323.4375MB; mem (CPU total)=37002.34765625MB
INFO:root:[   28] Training loss: 0.72321879, Validation loss: 0.72632348, Gradient norm: 0.24719540
INFO:root:At the start of the epoch: mem (CPU python)=14361.53515625MB; mem (CPU total)=37071.80859375MB
INFO:root:[   29] Training loss: 0.72268900, Validation loss: 0.72822673, Gradient norm: 0.23641100
INFO:root:At the start of the epoch: mem (CPU python)=14400.16796875MB; mem (CPU total)=37148.6015625MB
INFO:root:[   30] Training loss: 0.72302376, Validation loss: 0.72427419, Gradient norm: 0.24035238
INFO:root:At the start of the epoch: mem (CPU python)=14438.8359375MB; mem (CPU total)=37214.53125MB
INFO:root:[   31] Training loss: 0.72295785, Validation loss: 0.72561000, Gradient norm: 0.24639573
INFO:root:At the start of the epoch: mem (CPU python)=14477.125MB; mem (CPU total)=37277.015625MB
INFO:root:[   32] Training loss: 0.72194183, Validation loss: 0.72564704, Gradient norm: 0.26394102
INFO:root:At the start of the epoch: mem (CPU python)=14515.94140625MB; mem (CPU total)=37341.3359375MB
INFO:root:[   33] Training loss: 0.72228931, Validation loss: 0.72319489, Gradient norm: 0.23722386
INFO:root:At the start of the epoch: mem (CPU python)=14554.03515625MB; mem (CPU total)=37417.27734375MB
INFO:root:[   34] Training loss: 0.72172790, Validation loss: 0.72532462, Gradient norm: 0.21836010
INFO:root:At the start of the epoch: mem (CPU python)=14592.13671875MB; mem (CPU total)=37489.81640625MB
INFO:root:[   35] Training loss: 0.72201997, Validation loss: 0.72332725, Gradient norm: 0.24061189
INFO:root:At the start of the epoch: mem (CPU python)=14630.23046875MB; mem (CPU total)=37550.6015625MB
INFO:root:[   36] Training loss: 0.72034720, Validation loss: 0.71978236, Gradient norm: 0.21058356
INFO:root:At the start of the epoch: mem (CPU python)=14668.32421875MB; mem (CPU total)=37612.56640625MB
INFO:root:[   37] Training loss: 0.71931054, Validation loss: 0.72064446, Gradient norm: 0.20010103
INFO:root:At the start of the epoch: mem (CPU python)=14706.41796875MB; mem (CPU total)=37684.38671875MB
INFO:root:[   38] Training loss: 0.71673646, Validation loss: 0.71652684, Gradient norm: 0.24973533
INFO:root:At the start of the epoch: mem (CPU python)=14744.51953125MB; mem (CPU total)=37761.375MB
INFO:root:[   39] Training loss: 0.71349445, Validation loss: 0.71453027, Gradient norm: 0.21705497
INFO:root:At the start of the epoch: mem (CPU python)=14782.61328125MB; mem (CPU total)=37822.65625MB
INFO:root:[   40] Training loss: 0.71032540, Validation loss: 0.71249263, Gradient norm: 0.22531471
INFO:root:At the start of the epoch: mem (CPU python)=14820.70703125MB; mem (CPU total)=37884.65234375MB
INFO:root:[   41] Training loss: 0.70750796, Validation loss: 0.70822287, Gradient norm: 0.27263579
INFO:root:At the start of the epoch: mem (CPU python)=14858.8046875MB; mem (CPU total)=37949.35546875MB
INFO:root:[   42] Training loss: 0.70488787, Validation loss: 0.70583456, Gradient norm: 0.24449363
INFO:root:At the start of the epoch: mem (CPU python)=14896.8984375MB; mem (CPU total)=38025.6640625MB
INFO:root:[   43] Training loss: 0.70185790, Validation loss: 0.70598465, Gradient norm: 0.30172018
INFO:root:At the start of the epoch: mem (CPU python)=14934.99609375MB; mem (CPU total)=38097.50390625MB
INFO:root:[   44] Training loss: 0.70058473, Validation loss: 0.70212037, Gradient norm: 0.32170715
INFO:root:At the start of the epoch: mem (CPU python)=14973.08984375MB; mem (CPU total)=38160.0078125MB
INFO:root:[   45] Training loss: 0.69793623, Validation loss: 0.70079455, Gradient norm: 0.37007346
INFO:root:At the start of the epoch: mem (CPU python)=15011.1875MB; mem (CPU total)=38221.6640625MB
INFO:root:[   46] Training loss: 0.69574033, Validation loss: 0.69825556, Gradient norm: 0.36153691
INFO:root:At the start of the epoch: mem (CPU python)=15049.28515625MB; mem (CPU total)=38292.7578125MB
INFO:root:[   47] Training loss: 0.69369672, Validation loss: 0.69667187, Gradient norm: 0.37022311
INFO:root:At the start of the epoch: mem (CPU python)=15087.37890625MB; mem (CPU total)=38368.765625MB
INFO:root:[   48] Training loss: 0.69203894, Validation loss: 0.69272512, Gradient norm: 0.38495615
INFO:root:At the start of the epoch: mem (CPU python)=15125.4765625MB; mem (CPU total)=38434.12109375MB
INFO:root:[   49] Training loss: 0.69039693, Validation loss: 0.69444830, Gradient norm: 0.37688068
INFO:root:At the start of the epoch: mem (CPU python)=15163.5703125MB; mem (CPU total)=38496.59375MB
INFO:root:[   50] Training loss: 0.68820227, Validation loss: 0.69080575, Gradient norm: 0.36298198
INFO:root:At the start of the epoch: mem (CPU python)=15201.6640625MB; mem (CPU total)=38559.5MB
INFO:root:[   51] Training loss: 0.68617880, Validation loss: 0.68891392, Gradient norm: 0.37481822
INFO:root:At the start of the epoch: mem (CPU python)=15239.76171875MB; mem (CPU total)=38635.734375MB
INFO:root:[   52] Training loss: 0.68561593, Validation loss: 0.68652162, Gradient norm: 0.40046537
INFO:root:At the start of the epoch: mem (CPU python)=15277.85546875MB; mem (CPU total)=38711.21484375MB
INFO:root:[   53] Training loss: 0.68410363, Validation loss: 0.68530163, Gradient norm: 0.44153579
INFO:root:At the start of the epoch: mem (CPU python)=15315.94921875MB; mem (CPU total)=38772.25MB
INFO:root:[   54] Training loss: 0.68248863, Validation loss: 0.68357216, Gradient norm: 0.40747577
INFO:root:At the start of the epoch: mem (CPU python)=15354.04296875MB; mem (CPU total)=38834.00390625MB
INFO:root:[   55] Training loss: 0.68120065, Validation loss: 0.68123686, Gradient norm: 0.44310090
INFO:root:At the start of the epoch: mem (CPU python)=15392.14453125MB; mem (CPU total)=38902.609375MB
INFO:root:[   56] Training loss: 0.67927416, Validation loss: 0.68149495, Gradient norm: 0.43168845
INFO:root:At the start of the epoch: mem (CPU python)=15430.23828125MB; mem (CPU total)=38979.6015625MB
INFO:root:[   57] Training loss: 0.67849222, Validation loss: 0.67949786, Gradient norm: 0.36398927
INFO:root:At the start of the epoch: mem (CPU python)=15468.33203125MB; mem (CPU total)=39048.23046875MB
INFO:root:[   58] Training loss: 0.67743057, Validation loss: 0.67758391, Gradient norm: 0.40257733
INFO:root:At the start of the epoch: mem (CPU python)=15506.4296875MB; mem (CPU total)=39110.4609375MB
INFO:root:[   59] Training loss: 0.67631371, Validation loss: 0.67788321, Gradient norm: 0.44313287
INFO:root:At the start of the epoch: mem (CPU python)=15544.5234375MB; mem (CPU total)=39173.296875MB
INFO:root:[   60] Training loss: 0.67511433, Validation loss: 0.67865627, Gradient norm: 0.34427467
INFO:root:At the start of the epoch: mem (CPU python)=15582.6171875MB; mem (CPU total)=39246.140625MB
INFO:root:[   61] Training loss: 0.67432215, Validation loss: 0.67633815, Gradient norm: 0.41181849
INFO:root:At the start of the epoch: mem (CPU python)=15620.71484375MB; mem (CPU total)=39322.390625MB
INFO:root:[   62] Training loss: 0.67281992, Validation loss: 0.67601656, Gradient norm: 0.36405971
INFO:root:At the start of the epoch: mem (CPU python)=15658.8125MB; mem (CPU total)=39387.125MB
INFO:root:[   63] Training loss: 0.67192308, Validation loss: 0.67380479, Gradient norm: 0.39354698
INFO:root:At the start of the epoch: mem (CPU python)=15696.90625MB; mem (CPU total)=39450.1015625MB
INFO:root:[   64] Training loss: 0.67059836, Validation loss: 0.67132732, Gradient norm: 0.30275463
INFO:root:At the start of the epoch: mem (CPU python)=15735.0MB; mem (CPU total)=39513.3046875MB
INFO:root:[   65] Training loss: 0.66988111, Validation loss: 0.67111005, Gradient norm: 0.35982940
INFO:root:At the start of the epoch: mem (CPU python)=15773.09765625MB; mem (CPU total)=39590.09765625MB
INFO:root:[   66] Training loss: 0.66912157, Validation loss: 0.67113007, Gradient norm: 0.40283203
INFO:root:At the start of the epoch: mem (CPU python)=15811.19140625MB; mem (CPU total)=39666.5703125MB
INFO:root:[   67] Training loss: 0.66754607, Validation loss: 0.66921959, Gradient norm: 0.36277329
INFO:root:At the start of the epoch: mem (CPU python)=15849.28515625MB; mem (CPU total)=39728.3515625MB
INFO:root:[   68] Training loss: 0.66734997, Validation loss: 0.66732562, Gradient norm: 0.33273749
INFO:root:At the start of the epoch: mem (CPU python)=15887.3828125MB; mem (CPU total)=39790.8359375MB
INFO:root:[   69] Training loss: 0.66556744, Validation loss: 0.66651523, Gradient norm: 0.34587924
INFO:root:At the start of the epoch: mem (CPU python)=15925.48046875MB; mem (CPU total)=39857.234375MB
INFO:root:[   70] Training loss: 0.66484737, Validation loss: 0.66645329, Gradient norm: 0.34429902
INFO:root:At the start of the epoch: mem (CPU python)=15963.57421875MB; mem (CPU total)=39933.55078125MB
INFO:root:[   71] Training loss: 0.66403858, Validation loss: 0.66545990, Gradient norm: 0.36857754
INFO:root:At the start of the epoch: mem (CPU python)=16001.66796875MB; mem (CPU total)=40006.55859375MB
INFO:root:[   72] Training loss: 0.66371640, Validation loss: 0.66606872, Gradient norm: 0.36614916
INFO:root:At the start of the epoch: mem (CPU python)=16039.765625MB; mem (CPU total)=40068.296875MB
INFO:root:[   73] Training loss: 0.66234075, Validation loss: 0.66378461, Gradient norm: 0.42687614
INFO:root:At the start of the epoch: mem (CPU python)=16077.859375MB; mem (CPU total)=40131.21875MB
INFO:root:[   74] Training loss: 0.66197817, Validation loss: 0.66380772, Gradient norm: 0.33214620
INFO:root:At the start of the epoch: mem (CPU python)=16115.953125MB; mem (CPU total)=40200.33203125MB
INFO:root:[   75] Training loss: 0.66098524, Validation loss: 0.66295296, Gradient norm: 0.38102886
INFO:root:At the start of the epoch: mem (CPU python)=16154.05078125MB; mem (CPU total)=40276.61328125MB
INFO:root:[   76] Training loss: 0.65998406, Validation loss: 0.66266224, Gradient norm: 0.34760054
INFO:root:At the start of the epoch: mem (CPU python)=16192.14453125MB; mem (CPU total)=40345.7421875MB
INFO:root:[   77] Training loss: 0.65959932, Validation loss: 0.66278367, Gradient norm: 0.36815101
INFO:root:At the start of the epoch: mem (CPU python)=16230.23828125MB; mem (CPU total)=40408.5MB
INFO:root:[   78] Training loss: 0.65866509, Validation loss: 0.66135224, Gradient norm: 0.35783139
INFO:root:At the start of the epoch: mem (CPU python)=16268.33203125MB; mem (CPU total)=40471.25MB
INFO:root:[   79] Training loss: 0.65841278, Validation loss: 0.66083411, Gradient norm: 0.33906877
INFO:root:At the start of the epoch: mem (CPU python)=16306.4296875MB; mem (CPU total)=40543.828125MB
INFO:root:[   80] Training loss: 0.65819995, Validation loss: 0.66055679, Gradient norm: 0.36782912
INFO:root:At the start of the epoch: mem (CPU python)=16344.52734375MB; mem (CPU total)=40620.3671875MB
INFO:root:[   81] Training loss: 0.65707072, Validation loss: 0.65984066, Gradient norm: 0.43231289
INFO:root:At the start of the epoch: mem (CPU python)=16382.62109375MB; mem (CPU total)=40688.5390625MB
INFO:root:[   82] Training loss: 0.65623267, Validation loss: 0.65894087, Gradient norm: 0.36086167
INFO:root:At the start of the epoch: mem (CPU python)=16420.71875MB; mem (CPU total)=40751.78515625MB
INFO:root:[   83] Training loss: 0.65632268, Validation loss: 0.65818496, Gradient norm: 0.32103131
INFO:root:At the start of the epoch: mem (CPU python)=16458.8125MB; mem (CPU total)=40815.078125MB
INFO:root:[   84] Training loss: 0.65577464, Validation loss: 0.65742361, Gradient norm: 0.38654116
INFO:root:At the start of the epoch: mem (CPU python)=16496.90625MB; mem (CPU total)=40888.05078125MB
INFO:root:[   85] Training loss: 0.65491234, Validation loss: 0.65749015, Gradient norm: 0.40831897
INFO:root:At the start of the epoch: mem (CPU python)=16535.00390625MB; mem (CPU total)=40964.81640625MB
INFO:root:[   86] Training loss: 0.65464948, Validation loss: 0.65720373, Gradient norm: 0.30563014
INFO:root:At the start of the epoch: mem (CPU python)=16573.09765625MB; mem (CPU total)=41031.48828125MB
INFO:root:[   87] Training loss: 0.65403918, Validation loss: 0.65592267, Gradient norm: 0.40061692
INFO:root:At the start of the epoch: mem (CPU python)=16611.1953125MB; mem (CPU total)=41095.23828125MB
INFO:root:[   88] Training loss: 0.65354499, Validation loss: 0.65538554, Gradient norm: 0.44101052
INFO:root:At the start of the epoch: mem (CPU python)=16649.2890625MB; mem (CPU total)=41157.9609375MB
INFO:root:[   89] Training loss: 0.65272287, Validation loss: 0.65632086, Gradient norm: 0.33766054
INFO:root:At the start of the epoch: mem (CPU python)=16687.38671875MB; mem (CPU total)=41231.5390625MB
INFO:root:[   90] Training loss: 0.65245315, Validation loss: 0.65634297, Gradient norm: 0.33087462
INFO:root:At the start of the epoch: mem (CPU python)=16725.48046875MB; mem (CPU total)=41308.31640625MB
INFO:root:[   91] Training loss: 0.65166858, Validation loss: 0.65533064, Gradient norm: 0.33039103
INFO:root:At the start of the epoch: mem (CPU python)=16763.57421875MB; mem (CPU total)=41374.33203125MB
INFO:root:[   92] Training loss: 0.65191973, Validation loss: 0.65408305, Gradient norm: 0.33992558
INFO:root:At the start of the epoch: mem (CPU python)=16801.671875MB; mem (CPU total)=41438.49609375MB
INFO:root:[   93] Training loss: 0.65142693, Validation loss: 0.65403486, Gradient norm: 0.37584423
INFO:root:At the start of the epoch: mem (CPU python)=16839.76953125MB; mem (CPU total)=41501.28515625MB
INFO:root:[   94] Training loss: 0.65053830, Validation loss: 0.65275197, Gradient norm: 0.32583647
INFO:root:At the start of the epoch: mem (CPU python)=16877.86328125MB; mem (CPU total)=41575.53515625MB
INFO:root:[   95] Training loss: 0.65032503, Validation loss: 0.65407163, Gradient norm: 0.35194024
INFO:root:At the start of the epoch: mem (CPU python)=16915.95703125MB; mem (CPU total)=41651.51171875MB
INFO:root:[   96] Training loss: 0.64943459, Validation loss: 0.65288345, Gradient norm: 0.35815278
INFO:root:At the start of the epoch: mem (CPU python)=16954.05859375MB; mem (CPU total)=41719.88671875MB
INFO:root:[   97] Training loss: 0.64886175, Validation loss: 0.65286944, Gradient norm: 0.36389797
INFO:root:At the start of the epoch: mem (CPU python)=16992.15234375MB; mem (CPU total)=41783.83203125MB
INFO:root:[   98] Training loss: 0.64874808, Validation loss: 0.65276199, Gradient norm: 0.28999582
INFO:root:At the start of the epoch: mem (CPU python)=17030.24609375MB; mem (CPU total)=41847.05859375MB
INFO:root:[   99] Training loss: 0.64820032, Validation loss: 0.65267628, Gradient norm: 0.45420646
INFO:root:At the start of the epoch: mem (CPU python)=17068.34375MB; mem (CPU total)=41918.39453125MB
INFO:root:[  100] Training loss: 0.64764673, Validation loss: 0.65163825, Gradient norm: 0.36854117
INFO:root:At the start of the epoch: mem (CPU python)=17106.4375MB; mem (CPU total)=41994.83203125MB
INFO:root:[  101] Training loss: 0.64756555, Validation loss: 0.65083645, Gradient norm: 0.32467227
INFO:root:At the start of the epoch: mem (CPU python)=17144.53125MB; mem (CPU total)=42065.1875MB
INFO:root:[  102] Training loss: 0.64680558, Validation loss: 0.65099544, Gradient norm: 0.29467032
INFO:root:At the start of the epoch: mem (CPU python)=17182.62890625MB; mem (CPU total)=42128.1640625MB
INFO:root:[  103] Training loss: 0.64592319, Validation loss: 0.65120280, Gradient norm: 0.26082734
INFO:root:At the start of the epoch: mem (CPU python)=17220.72265625MB; mem (CPU total)=42191.15625MB
INFO:root:[  104] Training loss: 0.64628742, Validation loss: 0.65032024, Gradient norm: 0.38516129
INFO:root:At the start of the epoch: mem (CPU python)=17258.8203125MB; mem (CPU total)=42262.25MB
INFO:root:[  105] Training loss: 0.64523744, Validation loss: 0.64956244, Gradient norm: 0.36876325
INFO:root:At the start of the epoch: mem (CPU python)=17296.9140625MB; mem (CPU total)=42338.7578125MB
INFO:root:[  106] Training loss: 0.64534581, Validation loss: 0.64926396, Gradient norm: 0.34628117
INFO:root:At the start of the epoch: mem (CPU python)=17335.01171875MB; mem (CPU total)=42410.8671875MB
INFO:root:[  107] Training loss: 0.64476362, Validation loss: 0.64893396, Gradient norm: 0.32473756
INFO:root:At the start of the epoch: mem (CPU python)=17373.10546875MB; mem (CPU total)=42473.82421875MB
INFO:root:[  108] Training loss: 0.64482120, Validation loss: 0.64837551, Gradient norm: 0.39813122
INFO:root:At the start of the epoch: mem (CPU python)=17411.19921875MB; mem (CPU total)=42537.28125MB
INFO:root:[  109] Training loss: 0.64417320, Validation loss: 0.64815219, Gradient norm: 0.35802406
INFO:root:At the start of the epoch: mem (CPU python)=17449.296875MB; mem (CPU total)=42605.625MB
INFO:root:[  110] Training loss: 0.64337120, Validation loss: 0.64823657, Gradient norm: 0.37473648
INFO:root:At the start of the epoch: mem (CPU python)=17487.390625MB; mem (CPU total)=42681.859375MB
INFO:root:[  111] Training loss: 0.64332656, Validation loss: 0.64802753, Gradient norm: 0.43957103
INFO:root:At the start of the epoch: mem (CPU python)=17525.484375MB; mem (CPU total)=42755.421875MB
INFO:root:[  112] Training loss: 0.64283634, Validation loss: 0.64781651, Gradient norm: 0.31624883
INFO:root:At the start of the epoch: mem (CPU python)=17563.58203125MB; mem (CPU total)=42817.63671875MB
INFO:root:[  113] Training loss: 0.64212624, Validation loss: 0.64707263, Gradient norm: 0.28857353
INFO:root:At the start of the epoch: mem (CPU python)=17601.6796875MB; mem (CPU total)=42881.125MB
INFO:root:[  114] Training loss: 0.64214815, Validation loss: 0.64675682, Gradient norm: 0.42279346
INFO:root:At the start of the epoch: mem (CPU python)=17639.7734375MB; mem (CPU total)=42949.0MB
INFO:root:[  115] Training loss: 0.64155977, Validation loss: 0.64514160, Gradient norm: 0.32535580
INFO:root:At the start of the epoch: mem (CPU python)=17677.8671875MB; mem (CPU total)=43025.43359375MB
INFO:root:[  116] Training loss: 0.64104728, Validation loss: 0.64590401, Gradient norm: 0.37214144
INFO:root:At the start of the epoch: mem (CPU python)=17715.96484375MB; mem (CPU total)=43099.6953125MB
INFO:root:[  117] Training loss: 0.64074172, Validation loss: 0.64544237, Gradient norm: 0.36127628
INFO:root:At the start of the epoch: mem (CPU python)=17754.05859375MB; mem (CPU total)=43161.89453125MB
INFO:root:[  118] Training loss: 0.64033479, Validation loss: 0.64557135, Gradient norm: 0.31456958
INFO:root:At the start of the epoch: mem (CPU python)=17792.15234375MB; mem (CPU total)=43225.3515625MB
INFO:root:[  119] Training loss: 0.64033753, Validation loss: 0.64602034, Gradient norm: 0.43247033
INFO:root:At the start of the epoch: mem (CPU python)=17830.25MB; mem (CPU total)=43292.07421875MB
INFO:root:[  120] Training loss: 0.63980823, Validation loss: 0.64456694, Gradient norm: 0.31168232
INFO:root:At the start of the epoch: mem (CPU python)=17868.34375MB; mem (CPU total)=43368.66796875MB
INFO:root:[  121] Training loss: 0.63949440, Validation loss: 0.64496370, Gradient norm: 0.45394020
INFO:root:At the start of the epoch: mem (CPU python)=17906.4375MB; mem (CPU total)=43444.19140625MB
INFO:root:[  122] Training loss: 0.63904029, Validation loss: 0.64399876, Gradient norm: 0.36874872
INFO:root:At the start of the epoch: mem (CPU python)=17944.53515625MB; mem (CPU total)=43506.90234375MB
INFO:root:[  123] Training loss: 0.63837323, Validation loss: 0.64440210, Gradient norm: 0.30102576
INFO:root:At the start of the epoch: mem (CPU python)=17982.6328125MB; mem (CPU total)=43570.12109375MB
INFO:root:[  124] Training loss: 0.63830134, Validation loss: 0.64226445, Gradient norm: 0.37593628
INFO:root:At the start of the epoch: mem (CPU python)=18020.73046875MB; mem (CPU total)=43636.34765625MB
INFO:root:[  125] Training loss: 0.63782674, Validation loss: 0.64312895, Gradient norm: 0.31626163
INFO:root:At the start of the epoch: mem (CPU python)=18058.82421875MB; mem (CPU total)=43712.58203125MB
INFO:root:[  126] Training loss: 0.63701865, Validation loss: 0.64430068, Gradient norm: 0.35770462
INFO:root:At the start of the epoch: mem (CPU python)=18096.921875MB; mem (CPU total)=43789.0625MB
INFO:root:[  127] Training loss: 0.63736745, Validation loss: 0.64183212, Gradient norm: 0.38004461
INFO:root:At the start of the epoch: mem (CPU python)=18135.015625MB; mem (CPU total)=43855.6640625MB
INFO:root:[  128] Training loss: 0.63642084, Validation loss: 0.64361828, Gradient norm: 0.37751430
INFO:root:At the start of the epoch: mem (CPU python)=18173.11328125MB; mem (CPU total)=43918.41796875MB
INFO:root:[  129] Training loss: 0.63622048, Validation loss: 0.64150874, Gradient norm: 0.34020441
INFO:root:At the start of the epoch: mem (CPU python)=18211.20703125MB; mem (CPU total)=43982.203125MB
INFO:root:[  130] Training loss: 0.63609274, Validation loss: 0.64256200, Gradient norm: 0.37112888
INFO:root:At the start of the epoch: mem (CPU python)=18249.3046875MB; mem (CPU total)=44058.734375MB
INFO:root:[  131] Training loss: 0.63598503, Validation loss: 0.64026738, Gradient norm: 0.37572319
INFO:root:At the start of the epoch: mem (CPU python)=18287.3984375MB; mem (CPU total)=44134.98828125MB
INFO:root:[  132] Training loss: 0.63528749, Validation loss: 0.64050734, Gradient norm: 0.43014565
INFO:root:At the start of the epoch: mem (CPU python)=18325.4921875MB; mem (CPU total)=44200.68359375MB
INFO:root:[  133] Training loss: 0.63558428, Validation loss: 0.64058439, Gradient norm: 0.40383050
INFO:root:At the start of the epoch: mem (CPU python)=18363.58984375MB; mem (CPU total)=44264.1171875MB
INFO:root:[  134] Training loss: 0.63483348, Validation loss: 0.64136330, Gradient norm: 0.37700966
INFO:root:At the start of the epoch: mem (CPU python)=18401.68359375MB; mem (CPU total)=44327.625MB
INFO:root:[  135] Training loss: 0.63421270, Validation loss: 0.64045642, Gradient norm: 0.36934864
INFO:root:At the start of the epoch: mem (CPU python)=18439.77734375MB; mem (CPU total)=44403.36328125MB
INFO:root:[  136] Training loss: 0.63367277, Validation loss: 0.64034420, Gradient norm: 0.33224606
INFO:root:At the start of the epoch: mem (CPU python)=18477.875MB; mem (CPU total)=44479.5703125MB
INFO:root:[  137] Training loss: 0.63391311, Validation loss: 0.63964252, Gradient norm: 0.41488164
INFO:root:At the start of the epoch: mem (CPU python)=18515.96875MB; mem (CPU total)=44547.43359375MB
INFO:root:[  138] Training loss: 0.63347669, Validation loss: 0.63949885, Gradient norm: 0.35523170
INFO:root:At the start of the epoch: mem (CPU python)=18554.0625MB; mem (CPU total)=44609.72265625MB
INFO:root:[  139] Training loss: 0.63284944, Validation loss: 0.63892388, Gradient norm: 0.32834716
INFO:root:At the start of the epoch: mem (CPU python)=18592.16796875MB; mem (CPU total)=44672.4609375MB
INFO:root:[  140] Training loss: 0.63307483, Validation loss: 0.63987247, Gradient norm: 0.33974177
INFO:root:At the start of the epoch: mem (CPU python)=18630.265625MB; mem (CPU total)=44746.0546875MB
INFO:root:[  141] Training loss: 0.63225694, Validation loss: 0.63837274, Gradient norm: 0.41676910
INFO:root:At the start of the epoch: mem (CPU python)=18668.359375MB; mem (CPU total)=44823.10546875MB
INFO:root:[  142] Training loss: 0.63235043, Validation loss: 0.63943293, Gradient norm: 0.47546447
INFO:root:At the start of the epoch: mem (CPU python)=18706.453125MB; mem (CPU total)=44891.4765625MB
INFO:root:[  143] Training loss: 0.63202947, Validation loss: 0.63915561, Gradient norm: 0.40340331
INFO:root:At the start of the epoch: mem (CPU python)=18744.55078125MB; mem (CPU total)=44954.48828125MB
INFO:root:[  144] Training loss: 0.63162764, Validation loss: 0.63940553, Gradient norm: 0.47026597
INFO:root:At the start of the epoch: mem (CPU python)=18782.64453125MB; mem (CPU total)=45017.625MB
INFO:root:[  145] Training loss: 0.63140139, Validation loss: 0.63871131, Gradient norm: 0.35506885
INFO:root:At the start of the epoch: mem (CPU python)=18820.7421875MB; mem (CPU total)=45090.0859375MB
INFO:root:[  146] Training loss: 0.63053190, Validation loss: 0.63804298, Gradient norm: 0.35587715
INFO:root:At the start of the epoch: mem (CPU python)=18858.8359375MB; mem (CPU total)=45166.45703125MB
INFO:root:[  147] Training loss: 0.63036073, Validation loss: 0.63731417, Gradient norm: 0.41319680
INFO:root:At the start of the epoch: mem (CPU python)=18896.93359375MB; mem (CPU total)=45236.88671875MB
INFO:root:[  148] Training loss: 0.63020500, Validation loss: 0.63814201, Gradient norm: 0.42775327
INFO:root:At the start of the epoch: mem (CPU python)=18935.02734375MB; mem (CPU total)=45299.3671875MB
INFO:root:[  149] Training loss: 0.62964348, Validation loss: 0.63805454, Gradient norm: 0.27283170
INFO:root:At the start of the epoch: mem (CPU python)=18973.12109375MB; mem (CPU total)=45362.09375MB
INFO:root:[  150] Training loss: 0.62928179, Validation loss: 0.63750949, Gradient norm: 0.34508151
INFO:root:At the start of the epoch: mem (CPU python)=19011.21875MB; mem (CPU total)=45433.6796875MB
INFO:root:[  151] Training loss: 0.62951590, Validation loss: 0.63867938, Gradient norm: 0.33119013
INFO:root:At the start of the epoch: mem (CPU python)=19049.3125MB; mem (CPU total)=45509.64453125MB
INFO:root:[  152] Training loss: 0.62895675, Validation loss: 0.63623189, Gradient norm: 0.44415348
INFO:root:At the start of the epoch: mem (CPU python)=19087.40625MB; mem (CPU total)=45581.7265625MB
INFO:root:[  153] Training loss: 0.62901349, Validation loss: 0.63611031, Gradient norm: 0.46359890
INFO:root:At the start of the epoch: mem (CPU python)=19125.50390625MB; mem (CPU total)=45644.53125MB
INFO:root:[  154] Training loss: 0.62866704, Validation loss: 0.63568703, Gradient norm: 0.42550860
INFO:root:At the start of the epoch: mem (CPU python)=19163.59765625MB; mem (CPU total)=45707.19921875MB
INFO:root:[  155] Training loss: 0.62827431, Validation loss: 0.63652996, Gradient norm: 0.38892799
INFO:root:At the start of the epoch: mem (CPU python)=19201.6953125MB; mem (CPU total)=45776.78125MB
INFO:root:[  156] Training loss: 0.62820690, Validation loss: 0.63613481, Gradient norm: 0.46833585
INFO:root:At the start of the epoch: mem (CPU python)=19239.79296875MB; mem (CPU total)=45853.7890625MB
INFO:root:[  157] Training loss: 0.62745144, Validation loss: 0.63716733, Gradient norm: 0.35181328
INFO:root:At the start of the epoch: mem (CPU python)=19277.890625MB; mem (CPU total)=45926.3515625MB
INFO:root:[  158] Training loss: 0.62723666, Validation loss: 0.63602274, Gradient norm: 0.42762686
INFO:root:At the start of the epoch: mem (CPU python)=19315.984375MB; mem (CPU total)=45988.07421875MB
INFO:root:[  159] Training loss: 0.62747190, Validation loss: 0.63506444, Gradient norm: 0.32313196
INFO:root:At the start of the epoch: mem (CPU python)=19354.078125MB; mem (CPU total)=46050.87109375MB
INFO:root:[  160] Training loss: 0.62682144, Validation loss: 0.63620588, Gradient norm: 0.38233375
INFO:root:At the start of the epoch: mem (CPU python)=19392.17578125MB; mem (CPU total)=46121.2265625MB
INFO:root:[  161] Training loss: 0.62676894, Validation loss: 0.63529110, Gradient norm: 0.39836826
INFO:root:At the start of the epoch: mem (CPU python)=19430.26953125MB; mem (CPU total)=46197.2265625MB
INFO:root:[  162] Training loss: 0.62619820, Validation loss: 0.63575178, Gradient norm: 0.41436108
INFO:root:At the start of the epoch: mem (CPU python)=19468.36328125MB; mem (CPU total)=46271.56640625MB
INFO:root:[  163] Training loss: 0.62605259, Validation loss: 0.63648041, Gradient norm: 0.36417030
INFO:root:At the start of the epoch: mem (CPU python)=19506.4609375MB; mem (CPU total)=46334.296875MB
INFO:root:[  164] Training loss: 0.62590787, Validation loss: 0.63438875, Gradient norm: 0.49568593
INFO:root:At the start of the epoch: mem (CPU python)=19544.55859375MB; mem (CPU total)=46395.69140625MB
INFO:root:[  165] Training loss: 0.62531169, Validation loss: 0.63460826, Gradient norm: 0.39348731
INFO:root:At the start of the epoch: mem (CPU python)=19582.65234375MB; mem (CPU total)=46465.64453125MB
INFO:root:[  166] Training loss: 0.62552406, Validation loss: 0.63590940, Gradient norm: 0.47221728
INFO:root:At the start of the epoch: mem (CPU python)=19620.74609375MB; mem (CPU total)=46542.1796875MB
INFO:root:[  167] Training loss: 0.62516891, Validation loss: 0.63521143, Gradient norm: 0.35004535
INFO:root:At the start of the epoch: mem (CPU python)=19658.84375MB; mem (CPU total)=46615.76171875MB
INFO:root:[  168] Training loss: 0.62465170, Validation loss: 0.63385642, Gradient norm: 0.37302503
INFO:root:At the start of the epoch: mem (CPU python)=19696.9375MB; mem (CPU total)=46677.37109375MB
INFO:root:[  169] Training loss: 0.62437104, Validation loss: 0.63364251, Gradient norm: 0.33665600
INFO:root:At the start of the epoch: mem (CPU python)=19735.03125MB; mem (CPU total)=46739.859375MB
INFO:root:[  170] Training loss: 0.62446289, Validation loss: 0.63469525, Gradient norm: 0.44953365
INFO:root:At the start of the epoch: mem (CPU python)=19773.1328125MB; mem (CPU total)=46808.69140625MB
INFO:root:[  171] Training loss: 0.62403482, Validation loss: 0.63427550, Gradient norm: 0.42443678
INFO:root:At the start of the epoch: mem (CPU python)=19811.2265625MB; mem (CPU total)=46885.234375MB
INFO:root:[  172] Training loss: 0.62359970, Validation loss: 0.63347425, Gradient norm: 0.35715372
INFO:root:At the start of the epoch: mem (CPU python)=19849.3203125MB; mem (CPU total)=46960.5703125MB
INFO:root:[  173] Training loss: 0.62330219, Validation loss: 0.63277577, Gradient norm: 0.40561434
INFO:root:At the start of the epoch: mem (CPU python)=19887.4140625MB; mem (CPU total)=47021.6328125MB
INFO:root:[  174] Training loss: 0.62326480, Validation loss: 0.63372238, Gradient norm: 0.37222314
INFO:root:At the start of the epoch: mem (CPU python)=19925.51171875MB; mem (CPU total)=47083.39453125MB
INFO:root:[  175] Training loss: 0.62304178, Validation loss: 0.63403056, Gradient norm: 0.38292884
INFO:root:At the start of the epoch: mem (CPU python)=19963.60546875MB; mem (CPU total)=47152.76953125MB
INFO:root:[  176] Training loss: 0.62247809, Validation loss: 0.63364204, Gradient norm: 0.37870315
INFO:root:At the start of the epoch: mem (CPU python)=20001.73046875MB; mem (CPU total)=47229.015625MB
INFO:root:[  177] Training loss: 0.62261494, Validation loss: 0.63285560, Gradient norm: 0.41568898
INFO:root:At the start of the epoch: mem (CPU python)=20039.828125MB; mem (CPU total)=47303.9765625MB
INFO:root:[  178] Training loss: 0.62250203, Validation loss: 0.63481839, Gradient norm: 0.43880060
INFO:root:At the start of the epoch: mem (CPU python)=20077.92578125MB; mem (CPU total)=47364.85546875MB
INFO:root:[  179] Training loss: 0.62231094, Validation loss: 0.63398294, Gradient norm: 0.46257786
INFO:root:At the start of the epoch: mem (CPU python)=20116.01953125MB; mem (CPU total)=47427.2109375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  180] Training loss: 0.62227457, Validation loss: 0.63265352, Gradient norm: 0.47141571
INFO:root:At the start of the epoch: mem (CPU python)=20154.11328125MB; mem (CPU total)=47495.9375MB
INFO:root:[  181] Training loss: 0.62065937, Validation loss: 0.63133748, Gradient norm: 0.33139541
INFO:root:At the start of the epoch: mem (CPU python)=20192.2109375MB; mem (CPU total)=47572.5078125MB
INFO:root:[  182] Training loss: 0.62024870, Validation loss: 0.63045664, Gradient norm: 0.27523790
INFO:root:At the start of the epoch: mem (CPU python)=20230.3046875MB; mem (CPU total)=47646.31640625MB
INFO:root:[  183] Training loss: 0.61932690, Validation loss: 0.63135487, Gradient norm: 0.26787439
INFO:root:At the start of the epoch: mem (CPU python)=20268.3984375MB; mem (CPU total)=47706.74609375MB
INFO:root:[  184] Training loss: 0.61983503, Validation loss: 0.63139472, Gradient norm: 0.32378884
INFO:root:At the start of the epoch: mem (CPU python)=20306.49609375MB; mem (CPU total)=47768.79296875MB
INFO:root:[  185] Training loss: 0.61965812, Validation loss: 0.63093466, Gradient norm: 0.24756990
INFO:root:At the start of the epoch: mem (CPU python)=20344.58984375MB; mem (CPU total)=47839.44140625MB
INFO:root:[  186] Training loss: 0.61963928, Validation loss: 0.63140791, Gradient norm: 0.27846576
INFO:root:At the start of the epoch: mem (CPU python)=20382.68359375MB; mem (CPU total)=47915.859375MB
INFO:root:[  187] Training loss: 0.61937198, Validation loss: 0.63060885, Gradient norm: 0.27299796
INFO:root:At the start of the epoch: mem (CPU python)=20420.78515625MB; mem (CPU total)=47989.296875MB
INFO:root:[  188] Training loss: 0.61926913, Validation loss: 0.63025814, Gradient norm: 0.30580506
INFO:root:At the start of the epoch: mem (CPU python)=20458.87890625MB; mem (CPU total)=48051.44921875MB
INFO:root:[  189] Training loss: 0.61901139, Validation loss: 0.63154801, Gradient norm: 0.32892992
INFO:root:At the start of the epoch: mem (CPU python)=20496.97265625MB; mem (CPU total)=48111.859375MB
INFO:root:[  190] Training loss: 0.61898344, Validation loss: 0.63125337, Gradient norm: 0.28918719
INFO:root:At the start of the epoch: mem (CPU python)=20535.06640625MB; mem (CPU total)=48181.84765625MB
INFO:root:[  191] Training loss: 0.61885718, Validation loss: 0.63116567, Gradient norm: 0.29367874
INFO:root:At the start of the epoch: mem (CPU python)=20573.1640625MB; mem (CPU total)=48258.16015625MB
INFO:root:[  192] Training loss: 0.61861511, Validation loss: 0.63002268, Gradient norm: 0.29511201
INFO:root:At the start of the epoch: mem (CPU python)=20611.2578125MB; mem (CPU total)=48330.30859375MB
INFO:root:[  193] Training loss: 0.61839807, Validation loss: 0.63102824, Gradient norm: 0.27929862
INFO:root:At the start of the epoch: mem (CPU python)=20650.8515625MB; mem (CPU total)=48393.8046875MB
INFO:root:[  194] Training loss: 0.61815231, Validation loss: 0.63083548, Gradient norm: 0.28665168
INFO:root:At the start of the epoch: mem (CPU python)=20688.94921875MB; mem (CPU total)=48456.046875MB
INFO:root:[  195] Training loss: 0.61850669, Validation loss: 0.63117285, Gradient norm: 0.31271330
INFO:root:At the start of the epoch: mem (CPU python)=20727.046875MB; mem (CPU total)=48526.69921875MB
INFO:root:[  196] Training loss: 0.61840219, Validation loss: 0.63075510, Gradient norm: 0.31179723
INFO:root:At the start of the epoch: mem (CPU python)=20765.140625MB; mem (CPU total)=48603.23828125MB
INFO:root:[  197] Training loss: 0.61800250, Validation loss: 0.63070148, Gradient norm: 0.27997984
INFO:root:At the start of the epoch: mem (CPU python)=20803.234375MB; mem (CPU total)=48675.359375MB
INFO:root:[  198] Training loss: 0.61784374, Validation loss: 0.63025667, Gradient norm: 0.30798770
INFO:root:At the start of the epoch: mem (CPU python)=20841.33203125MB; mem (CPU total)=48736.27734375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  199] Training loss: 0.61765566, Validation loss: 0.63135368, Gradient norm: 0.29629436
INFO:root:At the start of the epoch: mem (CPU python)=20879.42578125MB; mem (CPU total)=48798.33203125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  200] Training loss: 0.61725934, Validation loss: 0.63057836, Gradient norm: 0.22953649
INFO:root:At the start of the epoch: mem (CPU python)=20917.51953125MB; mem (CPU total)=48870.57421875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  201] Training loss: 0.61642917, Validation loss: 0.63035460, Gradient norm: 0.18510642
INFO:root:At the start of the epoch: mem (CPU python)=20955.6171875MB; mem (CPU total)=48946.58984375MB
INFO:root:[  202] Training loss: 0.61643836, Validation loss: 0.62916405, Gradient norm: 0.16213334
INFO:root:At the start of the epoch: mem (CPU python)=20993.7109375MB; mem (CPU total)=49018.15625MB
INFO:root:[  203] Training loss: 0.61604104, Validation loss: 0.62980809, Gradient norm: 0.16268333
INFO:root:At the start of the epoch: mem (CPU python)=21031.8046875MB; mem (CPU total)=49080.203125MB
INFO:root:[  204] Training loss: 0.61602666, Validation loss: 0.63000005, Gradient norm: 0.15974260
INFO:root:At the start of the epoch: mem (CPU python)=21069.90234375MB; mem (CPU total)=49141.1875MB
INFO:root:[  205] Training loss: 0.61639015, Validation loss: 0.62917082, Gradient norm: 0.16442305
INFO:root:At the start of the epoch: mem (CPU python)=21108.0MB; mem (CPU total)=49214.05078125MB
INFO:root:[  206] Training loss: 0.61617562, Validation loss: 0.63003603, Gradient norm: 0.16926638
INFO:root:At the start of the epoch: mem (CPU python)=21146.09375MB; mem (CPU total)=49290.30078125MB
INFO:root:[  207] Training loss: 0.61660399, Validation loss: 0.62955378, Gradient norm: 0.16892359
INFO:root:At the start of the epoch: mem (CPU python)=21184.1875MB; mem (CPU total)=49359.6796875MB
INFO:root:[  208] Training loss: 0.61542418, Validation loss: 0.62918166, Gradient norm: 0.17282049
INFO:root:At the start of the epoch: mem (CPU python)=21222.28515625MB; mem (CPU total)=49421.6171875MB
INFO:root:[  209] Training loss: 0.61591337, Validation loss: 0.62995144, Gradient norm: 0.17442319
INFO:root:At the start of the epoch: mem (CPU python)=21260.37890625MB; mem (CPU total)=49484.3359375MB
INFO:root:[  210] Training loss: 0.61583296, Validation loss: 0.62895581, Gradient norm: 0.16178025
INFO:root:At the start of the epoch: mem (CPU python)=21298.47265625MB; mem (CPU total)=49557.16796875MB
INFO:root:[  211] Training loss: 0.61612058, Validation loss: 0.63002698, Gradient norm: 0.18112392
INFO:root:At the start of the epoch: mem (CPU python)=21336.5703125MB; mem (CPU total)=49633.48828125MB
INFO:root:[  212] Training loss: 0.61617793, Validation loss: 0.62951624, Gradient norm: 0.16710343
INFO:root:At the start of the epoch: mem (CPU python)=21374.6640625MB; mem (CPU total)=49703.84765625MB
INFO:root:[  213] Training loss: 0.61616846, Validation loss: 0.62981785, Gradient norm: 0.18431343
INFO:root:At the start of the epoch: mem (CPU python)=21412.7578125MB; mem (CPU total)=49764.890625MB
INFO:root:[  214] Training loss: 0.61620381, Validation loss: 0.62896127, Gradient norm: 0.16555785
INFO:root:At the start of the epoch: mem (CPU python)=21450.85546875MB; mem (CPU total)=49827.37109375MB
INFO:root:[  215] Training loss: 0.61582203, Validation loss: 0.62889680, Gradient norm: 0.15449265
INFO:root:At the start of the epoch: mem (CPU python)=21488.953125MB; mem (CPU total)=49901.14453125MB
INFO:root:[  216] Training loss: 0.61582199, Validation loss: 0.62927025, Gradient norm: 0.16752044
INFO:root:At the start of the epoch: mem (CPU python)=21527.046875MB; mem (CPU total)=49977.53515625MB
INFO:root:[  217] Training loss: 0.61604010, Validation loss: 0.62923261, Gradient norm: 0.16988342
INFO:root:At the start of the epoch: mem (CPU python)=21565.140625MB; mem (CPU total)=50048.140625MB
INFO:root:[  218] Training loss: 0.61588204, Validation loss: 0.62846513, Gradient norm: 0.17424609
INFO:root:At the start of the epoch: mem (CPU python)=21603.23828125MB; mem (CPU total)=50109.53125MB
INFO:root:[  219] Training loss: 0.61615078, Validation loss: 0.62950305, Gradient norm: 0.18259411
INFO:root:At the start of the epoch: mem (CPU python)=21641.33203125MB; mem (CPU total)=50171.0546875MB
INFO:root:[  220] Training loss: 0.61618758, Validation loss: 0.62935203, Gradient norm: 0.18738354
INFO:root:At the start of the epoch: mem (CPU python)=21679.42578125MB; mem (CPU total)=50244.375MB
INFO:root:[  221] Training loss: 0.61555671, Validation loss: 0.62940531, Gradient norm: 0.17629162
INFO:root:At the start of the epoch: mem (CPU python)=21717.52734375MB; mem (CPU total)=50320.86328125MB
INFO:root:[  222] Training loss: 0.61585031, Validation loss: 0.62911732, Gradient norm: 0.17863045
INFO:root:At the start of the epoch: mem (CPU python)=21755.6171875MB; mem (CPU total)=50390.265625MB
INFO:root:[  223] Training loss: 0.61565998, Validation loss: 0.62896921, Gradient norm: 0.17245845
INFO:root:At the start of the epoch: mem (CPU python)=21793.71484375MB; mem (CPU total)=50452.953125MB
INFO:root:[  224] Training loss: 0.61573023, Validation loss: 0.62893404, Gradient norm: 0.17058817
INFO:root:At the start of the epoch: mem (CPU python)=21831.80859375MB; mem (CPU total)=50514.9140625MB
INFO:root:[  225] Training loss: 0.61571650, Validation loss: 0.62846011, Gradient norm: 0.18677670
INFO:root:At the start of the epoch: mem (CPU python)=21869.90625MB; mem (CPU total)=50592.28125MB
INFO:root:[  226] Training loss: 0.61583951, Validation loss: 0.62976046, Gradient norm: 0.16563357
INFO:root:At the start of the epoch: mem (CPU python)=21908.0MB; mem (CPU total)=50640.74609375MB
INFO:root:[  227] Training loss: 0.61564221, Validation loss: 0.62879626, Gradient norm: 0.17281282
INFO:root:At the start of the epoch: mem (CPU python)=21946.09375MB; mem (CPU total)=50689.6953125MB
INFO:root:[  228] Training loss: 0.61549170, Validation loss: 0.62984211, Gradient norm: 0.17565058
INFO:root:At the start of the epoch: mem (CPU python)=21984.19140625MB; mem (CPU total)=50738.171875MB
INFO:root:[  229] Training loss: 0.61575038, Validation loss: 0.63021856, Gradient norm: 0.17333015
INFO:root:At the start of the epoch: mem (CPU python)=22022.28515625MB; mem (CPU total)=50783.73046875MB
INFO:root:[  230] Training loss: 0.61560274, Validation loss: 0.62972375, Gradient norm: 0.19170690
INFO:root:At the start of the epoch: mem (CPU python)=22060.37890625MB; mem (CPU total)=50829.0859375MB
INFO:root:[  231] Training loss: 0.61568184, Validation loss: 0.62908545, Gradient norm: 0.16876353
INFO:root:At the start of the epoch: mem (CPU python)=22098.47265625MB; mem (CPU total)=50898.51953125MB
INFO:root:[  232] Training loss: 0.61570468, Validation loss: 0.62973382, Gradient norm: 0.18796120
INFO:root:At the start of the epoch: mem (CPU python)=22136.57421875MB; mem (CPU total)=50975.85546875MB
INFO:root:[  233] Training loss: 0.61555104, Validation loss: 0.62926211, Gradient norm: 0.17989925
INFO:root:At the start of the epoch: mem (CPU python)=22174.66796875MB; mem (CPU total)=51052.1484375MB
INFO:root:[  234] Training loss: 0.61580711, Validation loss: 0.62967958, Gradient norm: 0.18104891
INFO:root:At the start of the epoch: mem (CPU python)=22212.76171875MB; mem (CPU total)=51113.37890625MB
INFO:root:EP 234: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=22250.859375MB; mem (CPU total)=51166.22265625MB
INFO:root:Training the model took 12516.964s.
INFO:root:Emptying the cuda cache took 0.045s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87434
INFO:root:EnergyScoreTrain: 0.6156
INFO:root:CRPSTrain: 0.5179
INFO:root:Gaussian NLLTrain: 1.58706
INFO:root:CoverageTrain: 0.83568
INFO:root:IntervalWidthTrain: 3.24711
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89346
INFO:root:EnergyScoreValidation: 0.6292
INFO:root:CRPSValidation: 0.52906
INFO:root:Gaussian NLLValidation: 1.61121
INFO:root:CoverageValidation: 0.8305
INFO:root:IntervalWidthValidation: 3.24243
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89419
INFO:root:EnergyScoreTest: 0.62976
INFO:root:CRPSTest: 0.5296
INFO:root:Gaussian NLLTest: 1.6132
INFO:root:CoverageTest: 0.82939
INFO:root:IntervalWidthTest: 3.23633
INFO:root:After validation: mem (CPU python)=22293.59765625MB; mem (CPU total)=51327.546875MB
INFO:root:###3 out of 5 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': 0.1, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=22293.59765625MB; mem (CPU total)=51350.421875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 157286400
INFO:root:After setting up the model: mem (CPU python)=22294.15234375MB; mem (CPU total)=51351.65234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=22294.20703125MB; mem (CPU total)=51362.2265625MB
INFO:root:[    1] Training loss: 0.79486873, Validation loss: 0.75465655, Gradient norm: 2.31216428
INFO:root:At the start of the epoch: mem (CPU python)=22333.51171875MB; mem (CPU total)=51438.7265625MB
INFO:root:[    2] Training loss: 0.73304151, Validation loss: 0.72924827, Gradient norm: 3.18838453
INFO:root:At the start of the epoch: mem (CPU python)=22371.609375MB; mem (CPU total)=51499.81640625MB
INFO:root:[    3] Training loss: 0.72693422, Validation loss: 0.72419310, Gradient norm: 3.20495456
INFO:root:At the start of the epoch: mem (CPU python)=22409.72265625MB; mem (CPU total)=51562.8125MB
INFO:root:[    4] Training loss: 0.72388645, Validation loss: 0.72586826, Gradient norm: 2.48433866
INFO:root:At the start of the epoch: mem (CPU python)=22447.83203125MB; mem (CPU total)=51630.36328125MB
INFO:root:[    5] Training loss: 0.72442903, Validation loss: 0.72511020, Gradient norm: 3.43458167
INFO:root:At the start of the epoch: mem (CPU python)=22485.94140625MB; mem (CPU total)=51706.87890625MB
INFO:root:[    6] Training loss: 0.72379318, Validation loss: 0.72090653, Gradient norm: 3.38455095
INFO:root:At the start of the epoch: mem (CPU python)=22524.0546875MB; mem (CPU total)=51783.62109375MB
INFO:root:[    7] Training loss: 0.72083383, Validation loss: 0.72122664, Gradient norm: 1.71928447
INFO:root:At the start of the epoch: mem (CPU python)=22562.1640625MB; mem (CPU total)=51846.8203125MB
INFO:root:[    8] Training loss: 0.72117630, Validation loss: 0.72337455, Gradient norm: 1.92149202
INFO:root:At the start of the epoch: mem (CPU python)=22600.27734375MB; mem (CPU total)=51908.78125MB
INFO:root:[    9] Training loss: 0.72272751, Validation loss: 0.72376360, Gradient norm: 3.13692415
INFO:root:At the start of the epoch: mem (CPU python)=22638.3828125MB; mem (CPU total)=51974.203125MB
INFO:root:[   10] Training loss: 0.72144750, Validation loss: 0.72188037, Gradient norm: 3.12825106
INFO:root:At the start of the epoch: mem (CPU python)=22676.48046875MB; mem (CPU total)=52050.73828125MB
INFO:root:[   11] Training loss: 0.72129401, Validation loss: 0.72033627, Gradient norm: 3.07265422
INFO:root:At the start of the epoch: mem (CPU python)=22714.57421875MB; mem (CPU total)=52127.21875MB
INFO:root:[   12] Training loss: 0.72007054, Validation loss: 0.72014047, Gradient norm: 2.26136252
INFO:root:At the start of the epoch: mem (CPU python)=22752.66796875MB; mem (CPU total)=52194.53125MB
INFO:root:[   13] Training loss: 0.72207106, Validation loss: 0.71823543, Gradient norm: 3.13795942
INFO:root:At the start of the epoch: mem (CPU python)=22790.76171875MB; mem (CPU total)=52256.48828125MB
INFO:root:[   14] Training loss: 0.71797811, Validation loss: 0.71984666, Gradient norm: 1.48067094
INFO:root:At the start of the epoch: mem (CPU python)=22828.859375MB; mem (CPU total)=52318.90625MB
INFO:root:[   15] Training loss: 0.71685675, Validation loss: 0.71450471, Gradient norm: 2.90998126
INFO:root:At the start of the epoch: mem (CPU python)=22866.9609375MB; mem (CPU total)=52393.8984375MB
INFO:root:[   16] Training loss: 0.71267018, Validation loss: 0.71001427, Gradient norm: 2.69443490
INFO:root:At the start of the epoch: mem (CPU python)=22905.0546875MB; mem (CPU total)=52470.63671875MB
INFO:root:[   17] Training loss: 0.70738433, Validation loss: 0.70395674, Gradient norm: 1.70587852
INFO:root:At the start of the epoch: mem (CPU python)=22943.15234375MB; mem (CPU total)=52543.453125MB
INFO:root:[   18] Training loss: 0.70247781, Validation loss: 0.70203229, Gradient norm: 2.11265909
INFO:root:At the start of the epoch: mem (CPU python)=22981.24609375MB; mem (CPU total)=52604.5MB
INFO:root:[   19] Training loss: 0.69932132, Validation loss: 0.69855180, Gradient norm: 2.26872992
INFO:root:At the start of the epoch: mem (CPU python)=23019.33984375MB; mem (CPU total)=52667.0546875MB
INFO:root:[   20] Training loss: 0.69652179, Validation loss: 0.69436959, Gradient norm: 2.06095739
INFO:root:At the start of the epoch: mem (CPU python)=23057.4375MB; mem (CPU total)=52737.94140625MB
INFO:root:[   21] Training loss: 0.69314208, Validation loss: 0.69461857, Gradient norm: 1.84344411
INFO:root:At the start of the epoch: mem (CPU python)=23095.53515625MB; mem (CPU total)=52814.19140625MB
INFO:root:[   22] Training loss: 0.68852043, Validation loss: 0.68818222, Gradient norm: 1.13727781
INFO:root:At the start of the epoch: mem (CPU python)=23133.62890625MB; mem (CPU total)=52890.87890625MB
INFO:root:[   23] Training loss: 0.68515590, Validation loss: 0.68516455, Gradient norm: 0.47476950
INFO:root:At the start of the epoch: mem (CPU python)=23171.72265625MB; mem (CPU total)=52953.734375MB
INFO:root:[   24] Training loss: 0.68267226, Validation loss: 0.68291588, Gradient norm: 0.62440834
INFO:root:At the start of the epoch: mem (CPU python)=23209.8203125MB; mem (CPU total)=53015.421875MB
INFO:root:[   25] Training loss: 0.68057428, Validation loss: 0.68175816, Gradient norm: 1.10017418
INFO:root:At the start of the epoch: mem (CPU python)=23247.9140625MB; mem (CPU total)=53081.5078125MB
INFO:root:[   26] Training loss: 0.67837383, Validation loss: 0.67919392, Gradient norm: 0.63394553
INFO:root:At the start of the epoch: mem (CPU python)=23286.0078125MB; mem (CPU total)=53158.06640625MB
INFO:root:[   27] Training loss: 0.67723363, Validation loss: 0.67860062, Gradient norm: 0.58107434
INFO:root:At the start of the epoch: mem (CPU python)=23324.10546875MB; mem (CPU total)=53234.07421875MB
INFO:root:[   28] Training loss: 0.67495550, Validation loss: 0.67572000, Gradient norm: 0.58878331
INFO:root:At the start of the epoch: mem (CPU python)=23362.19921875MB; mem (CPU total)=53304.1953125MB
INFO:root:[   29] Training loss: 0.67339831, Validation loss: 0.67529705, Gradient norm: 0.74846875
INFO:root:At the start of the epoch: mem (CPU python)=23400.29296875MB; mem (CPU total)=53366.45703125MB
INFO:root:[   30] Training loss: 0.67425943, Validation loss: 0.67763154, Gradient norm: 2.00062502
INFO:root:At the start of the epoch: mem (CPU python)=23438.390625MB; mem (CPU total)=53428.69921875MB
INFO:root:[   31] Training loss: 0.67566582, Validation loss: 0.68178814, Gradient norm: 3.14905666
INFO:root:At the start of the epoch: mem (CPU python)=23476.48828125MB; mem (CPU total)=53501.23828125MB
INFO:root:[   32] Training loss: 0.67424355, Validation loss: 0.67786837, Gradient norm: 2.90395060
INFO:root:At the start of the epoch: mem (CPU python)=23514.58203125MB; mem (CPU total)=53577.921875MB
INFO:root:[   33] Training loss: 0.67130861, Validation loss: 0.67143946, Gradient norm: 1.43727975
INFO:root:At the start of the epoch: mem (CPU python)=23552.67578125MB; mem (CPU total)=53654.66796875MB
INFO:root:[   34] Training loss: 0.66876830, Validation loss: 0.67067067, Gradient norm: 0.38340421
INFO:root:At the start of the epoch: mem (CPU python)=23590.7734375MB; mem (CPU total)=53719.1328125MB
INFO:root:[   35] Training loss: 0.66759766, Validation loss: 0.66946240, Gradient norm: 0.52914466
INFO:root:At the start of the epoch: mem (CPU python)=23628.8671875MB; mem (CPU total)=53780.8671875MB
INFO:root:[   36] Training loss: 0.66574524, Validation loss: 0.66838539, Gradient norm: 0.35915135
INFO:root:At the start of the epoch: mem (CPU python)=23666.9609375MB; mem (CPU total)=53845.49609375MB
INFO:root:[   37] Training loss: 0.66468291, Validation loss: 0.66640036, Gradient norm: 0.55878759
INFO:root:At the start of the epoch: mem (CPU python)=23705.05859375MB; mem (CPU total)=53921.25390625MB
INFO:root:[   38] Training loss: 0.66301006, Validation loss: 0.66587447, Gradient norm: 0.38818041
INFO:root:At the start of the epoch: mem (CPU python)=23743.15625MB; mem (CPU total)=53997.8046875MB
INFO:root:[   39] Training loss: 0.66219625, Validation loss: 0.66442521, Gradient norm: 0.74406590
INFO:root:At the start of the epoch: mem (CPU python)=23781.25MB; mem (CPU total)=54070.828125MB
INFO:root:[   40] Training loss: 0.66114894, Validation loss: 0.66294886, Gradient norm: 0.39806044
INFO:root:At the start of the epoch: mem (CPU python)=23819.34375MB; mem (CPU total)=54132.0859375MB
INFO:root:[   41] Training loss: 0.66002423, Validation loss: 0.66328356, Gradient norm: 0.43726882
INFO:root:At the start of the epoch: mem (CPU python)=23857.44140625MB; mem (CPU total)=54194.93359375MB
INFO:root:[   42] Training loss: 0.65908587, Validation loss: 0.66297600, Gradient norm: 0.72379227
INFO:root:At the start of the epoch: mem (CPU python)=23895.53515625MB; mem (CPU total)=54264.80859375MB
INFO:root:[   43] Training loss: 0.65788732, Validation loss: 0.66175051, Gradient norm: 0.52237998
INFO:root:At the start of the epoch: mem (CPU python)=23933.62890625MB; mem (CPU total)=54341.04296875MB
INFO:root:[   44] Training loss: 0.65659435, Validation loss: 0.65903492, Gradient norm: 0.32740412
INFO:root:At the start of the epoch: mem (CPU python)=23971.734375MB; mem (CPU total)=54418.91015625MB
INFO:root:[   45] Training loss: 0.65579862, Validation loss: 0.65880292, Gradient norm: 0.58840571
INFO:root:At the start of the epoch: mem (CPU python)=24009.83203125MB; mem (CPU total)=54485.9375MB
INFO:root:[   46] Training loss: 0.65563331, Validation loss: 0.65995872, Gradient norm: 0.63551185
INFO:root:At the start of the epoch: mem (CPU python)=24047.92578125MB; mem (CPU total)=54548.16015625MB
INFO:root:[   47] Training loss: 0.65393170, Validation loss: 0.65766620, Gradient norm: 0.55864955
INFO:root:At the start of the epoch: mem (CPU python)=24086.01953125MB; mem (CPU total)=54611.3515625MB
INFO:root:[   48] Training loss: 0.65285643, Validation loss: 0.65691568, Gradient norm: 0.69129813
INFO:root:At the start of the epoch: mem (CPU python)=24124.1171875MB; mem (CPU total)=54685.39453125MB
INFO:root:[   49] Training loss: 0.65215765, Validation loss: 0.65594170, Gradient norm: 0.52098596
INFO:root:At the start of the epoch: mem (CPU python)=24162.2109375MB; mem (CPU total)=54760.8828125MB
INFO:root:[   50] Training loss: 0.65198539, Validation loss: 0.65462180, Gradient norm: 0.80793645
INFO:root:At the start of the epoch: mem (CPU python)=24200.3046875MB; mem (CPU total)=54837.12109375MB
INFO:root:[   51] Training loss: 0.65123621, Validation loss: 0.65495115, Gradient norm: 0.38835932
INFO:root:At the start of the epoch: mem (CPU python)=24238.40234375MB; mem (CPU total)=54899.57421875MB
INFO:root:[   52] Training loss: 0.65002944, Validation loss: 0.65434302, Gradient norm: 0.46397748
INFO:root:At the start of the epoch: mem (CPU python)=24276.49609375MB; mem (CPU total)=54961.296875MB
INFO:root:[   53] Training loss: 0.64969271, Validation loss: 0.65384743, Gradient norm: 0.79228400
INFO:root:At the start of the epoch: mem (CPU python)=24314.59375MB; mem (CPU total)=55027.484375MB
INFO:root:[   54] Training loss: 0.64880384, Validation loss: 0.65194002, Gradient norm: 0.79678009
INFO:root:At the start of the epoch: mem (CPU python)=24352.69140625MB; mem (CPU total)=55103.72265625MB
INFO:root:[   55] Training loss: 0.64808599, Validation loss: 0.65207925, Gradient norm: 0.80684934
INFO:root:At the start of the epoch: mem (CPU python)=24390.78515625MB; mem (CPU total)=55180.20703125MB
INFO:root:[   56] Training loss: 0.64695546, Validation loss: 0.65116121, Gradient norm: 0.45005189
INFO:root:At the start of the epoch: mem (CPU python)=24428.8828125MB; mem (CPU total)=55252.2890625MB
INFO:root:[   57] Training loss: 0.64643619, Validation loss: 0.65024323, Gradient norm: 0.42940948
INFO:root:At the start of the epoch: mem (CPU python)=24466.9765625MB; mem (CPU total)=55314.02734375MB
INFO:root:[   58] Training loss: 0.64600059, Validation loss: 0.65013207, Gradient norm: 0.63317645
INFO:root:At the start of the epoch: mem (CPU python)=24505.07421875MB; mem (CPU total)=55377.88671875MB
INFO:root:[   59] Training loss: 0.64573933, Validation loss: 0.65017090, Gradient norm: 0.62525638
INFO:root:At the start of the epoch: mem (CPU python)=24543.16796875MB; mem (CPU total)=55447.72265625MB
INFO:root:[   60] Training loss: 0.64502545, Validation loss: 0.64858295, Gradient norm: 0.43741397
INFO:root:At the start of the epoch: mem (CPU python)=24581.26171875MB; mem (CPU total)=55523.7890625MB
INFO:root:[   61] Training loss: 0.64404050, Validation loss: 0.64944211, Gradient norm: 0.57800966
INFO:root:At the start of the epoch: mem (CPU python)=24619.359375MB; mem (CPU total)=55600.6171875MB
INFO:root:[   62] Training loss: 0.64380410, Validation loss: 0.64785434, Gradient norm: 0.59565811
INFO:root:At the start of the epoch: mem (CPU python)=24657.45703125MB; mem (CPU total)=55668.01171875MB
INFO:root:[   63] Training loss: 0.64288818, Validation loss: 0.64620233, Gradient norm: 0.51722899
INFO:root:At the start of the epoch: mem (CPU python)=24695.55078125MB; mem (CPU total)=55731.65625MB
INFO:root:[   64] Training loss: 0.64206230, Validation loss: 0.64566646, Gradient norm: 0.39394019
INFO:root:At the start of the epoch: mem (CPU python)=24733.64453125MB; mem (CPU total)=55795.578125MB
INFO:root:[   65] Training loss: 0.64204936, Validation loss: 0.64690463, Gradient norm: 0.87014860
INFO:root:At the start of the epoch: mem (CPU python)=24771.7421875MB; mem (CPU total)=55867.94140625MB
INFO:root:[   66] Training loss: 0.64138453, Validation loss: 0.64544488, Gradient norm: 0.73801389
INFO:root:At the start of the epoch: mem (CPU python)=24809.8359375MB; mem (CPU total)=55944.5078125MB
INFO:root:[   67] Training loss: 0.64055070, Validation loss: 0.64589353, Gradient norm: 0.45950199
INFO:root:At the start of the epoch: mem (CPU python)=24847.9296875MB; mem (CPU total)=56020.9609375MB
INFO:root:[   68] Training loss: 0.64045800, Validation loss: 0.64461766, Gradient norm: 0.51964372
INFO:root:At the start of the epoch: mem (CPU python)=24886.03515625MB; mem (CPU total)=56085.140625MB
INFO:root:[   69] Training loss: 0.63972536, Validation loss: 0.64356228, Gradient norm: 0.51927521
INFO:root:At the start of the epoch: mem (CPU python)=24924.12890625MB; mem (CPU total)=56148.76953125MB
INFO:root:[   70] Training loss: 0.63906829, Validation loss: 0.64326103, Gradient norm: 0.43948384
INFO:root:At the start of the epoch: mem (CPU python)=24962.22265625MB; mem (CPU total)=56211.16015625MB
INFO:root:[   71] Training loss: 0.63878852, Validation loss: 0.64351074, Gradient norm: 0.90507474
INFO:root:At the start of the epoch: mem (CPU python)=25000.3203125MB; mem (CPU total)=56287.23046875MB
INFO:root:[   72] Training loss: 0.63859972, Validation loss: 0.64242266, Gradient norm: 0.44047705
INFO:root:At the start of the epoch: mem (CPU python)=25038.4140625MB; mem (CPU total)=56363.2578125MB
INFO:root:[   73] Training loss: 0.63831962, Validation loss: 0.64159984, Gradient norm: 0.81234739
INFO:root:At the start of the epoch: mem (CPU python)=25076.5078125MB; mem (CPU total)=56439.26953125MB
INFO:root:[   74] Training loss: 0.63716535, Validation loss: 0.64206641, Gradient norm: 0.64336643
INFO:root:At the start of the epoch: mem (CPU python)=25114.6015625MB; mem (CPU total)=56502.2734375MB
INFO:root:[   75] Training loss: 0.63682518, Validation loss: 0.64186062, Gradient norm: 0.76756907
INFO:root:At the start of the epoch: mem (CPU python)=25152.69921875MB; mem (CPU total)=56564.49609375MB
INFO:root:[   76] Training loss: 0.63704641, Validation loss: 0.64106239, Gradient norm: 0.62080689
INFO:root:At the start of the epoch: mem (CPU python)=25190.79296875MB; mem (CPU total)=56629.87890625MB
INFO:root:[   77] Training loss: 0.63604597, Validation loss: 0.64170646, Gradient norm: 0.54857009
INFO:root:At the start of the epoch: mem (CPU python)=25228.88671875MB; mem (CPU total)=56706.1484375MB
INFO:root:[   78] Training loss: 0.63564652, Validation loss: 0.64147439, Gradient norm: 0.47680046
INFO:root:At the start of the epoch: mem (CPU python)=25266.98828125MB; mem (CPU total)=56782.61328125MB
INFO:root:[   79] Training loss: 0.63503108, Validation loss: 0.63952098, Gradient norm: 0.48624393
INFO:root:At the start of the epoch: mem (CPU python)=25305.08203125MB; mem (CPU total)=56857.39453125MB
INFO:root:[   80] Training loss: 0.63451619, Validation loss: 0.64008237, Gradient norm: 0.57007505
INFO:root:At the start of the epoch: mem (CPU python)=25343.17578125MB; mem (CPU total)=56918.87890625MB
INFO:root:[   81] Training loss: 0.63418409, Validation loss: 0.63957461, Gradient norm: 0.49378045
INFO:root:At the start of the epoch: mem (CPU python)=25381.26953125MB; mem (CPU total)=56981.62890625MB
INFO:root:[   82] Training loss: 0.63392852, Validation loss: 0.63920541, Gradient norm: 0.82224363
INFO:root:At the start of the epoch: mem (CPU python)=25419.3671875MB; mem (CPU total)=57050.09375MB
INFO:root:[   83] Training loss: 0.63384147, Validation loss: 0.63958458, Gradient norm: 0.66450426
INFO:root:At the start of the epoch: mem (CPU python)=25457.4609375MB; mem (CPU total)=57126.421875MB
INFO:root:[   84] Training loss: 0.63334879, Validation loss: 0.63854917, Gradient norm: 0.56292978
INFO:root:At the start of the epoch: mem (CPU python)=25495.5546875MB; mem (CPU total)=57202.82421875MB
INFO:root:[   85] Training loss: 0.63287648, Validation loss: 0.63776003, Gradient norm: 0.87269987
INFO:root:At the start of the epoch: mem (CPU python)=25533.65625MB; mem (CPU total)=57272.84375MB
INFO:root:[   86] Training loss: 0.63271245, Validation loss: 0.63833031, Gradient norm: 0.60540291
INFO:root:At the start of the epoch: mem (CPU python)=25571.75MB; mem (CPU total)=57335.3046875MB
INFO:root:[   87] Training loss: 0.63230190, Validation loss: 0.63707409, Gradient norm: 0.84835647
INFO:root:At the start of the epoch: mem (CPU python)=25609.84375MB; mem (CPU total)=57399.5546875MB
INFO:root:[   88] Training loss: 0.63231649, Validation loss: 0.63776539, Gradient norm: 0.78606946
INFO:root:At the start of the epoch: mem (CPU python)=25647.94140625MB; mem (CPU total)=57469.67578125MB
INFO:root:[   89] Training loss: 0.63180484, Validation loss: 0.63613524, Gradient norm: 0.65454245
INFO:root:At the start of the epoch: mem (CPU python)=25686.03515625MB; mem (CPU total)=57545.375MB
INFO:root:[   90] Training loss: 0.63131953, Validation loss: 0.63633117, Gradient norm: 0.43423473
INFO:root:At the start of the epoch: mem (CPU python)=25724.12890625MB; mem (CPU total)=57621.88671875MB
INFO:root:[   91] Training loss: 0.63090056, Validation loss: 0.63809859, Gradient norm: 0.47318848
INFO:root:At the start of the epoch: mem (CPU python)=25762.22265625MB; mem (CPU total)=57691.57421875MB
INFO:root:[   92] Training loss: 0.63027860, Validation loss: 0.63610581, Gradient norm: 0.57769851
INFO:root:At the start of the epoch: mem (CPU python)=25800.3203125MB; mem (CPU total)=57756.0234375MB
INFO:root:[   93] Training loss: 0.63020355, Validation loss: 0.63583854, Gradient norm: 0.84148662
INFO:root:At the start of the epoch: mem (CPU python)=25838.4140625MB; mem (CPU total)=57818.46875MB
INFO:root:[   94] Training loss: 0.62978562, Validation loss: 0.63585390, Gradient norm: 0.72499763
INFO:root:At the start of the epoch: mem (CPU python)=25876.5078125MB; mem (CPU total)=57889.50390625MB
INFO:root:[   95] Training loss: 0.62986088, Validation loss: 0.63546521, Gradient norm: 0.51702341
INFO:root:At the start of the epoch: mem (CPU python)=25914.609375MB; mem (CPU total)=57965.29296875MB
INFO:root:[   96] Training loss: 0.62944025, Validation loss: 0.63653746, Gradient norm: 0.65263213
INFO:root:At the start of the epoch: mem (CPU python)=25952.703125MB; mem (CPU total)=58041.83203125MB
INFO:root:[   97] Training loss: 0.62911127, Validation loss: 0.63535391, Gradient norm: 0.68618888
INFO:root:At the start of the epoch: mem (CPU python)=25990.796875MB; mem (CPU total)=58114.9453125MB
INFO:root:[   98] Training loss: 0.62857464, Validation loss: 0.63430156, Gradient norm: 0.44931564
INFO:root:At the start of the epoch: mem (CPU python)=26028.890625MB; mem (CPU total)=58177.015625MB
INFO:root:[   99] Training loss: 0.62860472, Validation loss: 0.63459287, Gradient norm: 0.88995388
INFO:root:At the start of the epoch: mem (CPU python)=26066.98828125MB; mem (CPU total)=58239.76171875MB
INFO:root:[  100] Training loss: 0.62834109, Validation loss: 0.63506487, Gradient norm: 1.23164279
INFO:root:At the start of the epoch: mem (CPU python)=26105.0859375MB; mem (CPU total)=58309.16796875MB
INFO:root:[  101] Training loss: 0.62823113, Validation loss: 0.63431724, Gradient norm: 0.84577860
INFO:root:At the start of the epoch: mem (CPU python)=26143.1796875MB; mem (CPU total)=58385.40625MB
INFO:root:[  102] Training loss: 0.62781541, Validation loss: 0.63501329, Gradient norm: 0.56963557
INFO:root:At the start of the epoch: mem (CPU python)=26181.28125MB; mem (CPU total)=58461.39453125MB
INFO:root:[  103] Training loss: 0.62731361, Validation loss: 0.63407916, Gradient norm: 0.50031949
INFO:root:At the start of the epoch: mem (CPU python)=26219.375MB; mem (CPU total)=58536.359375MB
INFO:root:[  104] Training loss: 0.62671602, Validation loss: 0.63352702, Gradient norm: 0.56118665
INFO:root:At the start of the epoch: mem (CPU python)=26257.46484375MB; mem (CPU total)=58599.6953125MB
INFO:root:[  105] Training loss: 0.62679740, Validation loss: 0.63354021, Gradient norm: 0.74549021
INFO:root:At the start of the epoch: mem (CPU python)=26295.56640625MB; mem (CPU total)=58664.875MB
INFO:root:[  106] Training loss: 0.62626783, Validation loss: 0.63288106, Gradient norm: 0.43186468
INFO:root:At the start of the epoch: mem (CPU python)=26333.66015625MB; mem (CPU total)=58728.8984375MB
INFO:root:[  107] Training loss: 0.62588543, Validation loss: 0.63424823, Gradient norm: 0.46405085
INFO:root:At the start of the epoch: mem (CPU python)=26371.75390625MB; mem (CPU total)=58805.1015625MB
INFO:root:[  108] Training loss: 0.62588528, Validation loss: 0.63430088, Gradient norm: 0.73035232
INFO:root:At the start of the epoch: mem (CPU python)=26409.84765625MB; mem (CPU total)=58881.390625MB
INFO:root:[  109] Training loss: 0.62539007, Validation loss: 0.63417581, Gradient norm: 0.54250164
INFO:root:At the start of the epoch: mem (CPU python)=26447.94921875MB; mem (CPU total)=58958.203125MB
INFO:root:[  110] Training loss: 0.62515727, Validation loss: 0.63361980, Gradient norm: 0.94803049
INFO:root:At the start of the epoch: mem (CPU python)=26486.0390625MB; mem (CPU total)=59026.609375MB
INFO:root:[  111] Training loss: 0.62461398, Validation loss: 0.63207957, Gradient norm: 0.61389012
INFO:root:At the start of the epoch: mem (CPU python)=26524.13671875MB; mem (CPU total)=59090.80859375MB
INFO:root:[  112] Training loss: 0.62517679, Validation loss: 0.63236609, Gradient norm: 1.03376274
INFO:root:At the start of the epoch: mem (CPU python)=26562.234375MB; mem (CPU total)=59154.29296875MB
INFO:root:[  113] Training loss: 0.62442245, Validation loss: 0.63161413, Gradient norm: 0.45016811
INFO:root:At the start of the epoch: mem (CPU python)=26600.328125MB; mem (CPU total)=59225.63671875MB
INFO:root:[  114] Training loss: 0.62430858, Validation loss: 0.63115254, Gradient norm: 0.57798431
INFO:root:At the start of the epoch: mem (CPU python)=26638.421875MB; mem (CPU total)=59301.7578125MB
INFO:root:[  115] Training loss: 0.62437495, Validation loss: 0.63263722, Gradient norm: 0.58851908
INFO:root:At the start of the epoch: mem (CPU python)=26676.515625MB; mem (CPU total)=59378.01171875MB
INFO:root:[  116] Training loss: 0.62396141, Validation loss: 0.63178942, Gradient norm: 1.11857877
INFO:root:At the start of the epoch: mem (CPU python)=26714.61328125MB; mem (CPU total)=59454.5MB
INFO:root:[  117] Training loss: 0.62306701, Validation loss: 0.63186064, Gradient norm: 0.53251956
INFO:root:At the start of the epoch: mem (CPU python)=26752.70703125MB; mem (CPU total)=59518.2890625MB
INFO:root:[  118] Training loss: 0.62389552, Validation loss: 0.63079763, Gradient norm: 0.78322161
INFO:root:At the start of the epoch: mem (CPU python)=26790.80078125MB; mem (CPU total)=59585.2109375MB
INFO:root:[  119] Training loss: 0.62281252, Validation loss: 0.63254463, Gradient norm: 0.62352905
INFO:root:At the start of the epoch: mem (CPU python)=26828.8984375MB; mem (CPU total)=59649.31640625MB
INFO:root:[  120] Training loss: 0.62335671, Validation loss: 0.63085012, Gradient norm: 0.52198927
INFO:root:At the start of the epoch: mem (CPU python)=26866.99609375MB; mem (CPU total)=59722.1796875MB
INFO:root:[  121] Training loss: 0.62308249, Validation loss: 0.63089179, Gradient norm: 0.92182684
INFO:root:At the start of the epoch: mem (CPU python)=26905.08984375MB; mem (CPU total)=59798.26953125MB
INFO:root:[  122] Training loss: 0.62270205, Validation loss: 0.63137387, Gradient norm: 0.86059712
INFO:root:At the start of the epoch: mem (CPU python)=26943.1875MB; mem (CPU total)=59874.296875MB
INFO:root:[  123] Training loss: 0.62249326, Validation loss: 0.63114407, Gradient norm: 0.62751620
INFO:root:At the start of the epoch: mem (CPU python)=26981.28125MB; mem (CPU total)=59947.83203125MB
INFO:root:[  124] Training loss: 0.62197401, Validation loss: 0.62940670, Gradient norm: 0.51736835
INFO:root:At the start of the epoch: mem (CPU python)=27019.375MB; mem (CPU total)=60012.03125MB
INFO:root:[  125] Training loss: 0.62195805, Validation loss: 0.62987701, Gradient norm: 1.04148342
INFO:root:At the start of the epoch: mem (CPU python)=27057.46875MB; mem (CPU total)=60076.7421875MB
INFO:root:[  126] Training loss: 0.62194236, Validation loss: 0.63012188, Gradient norm: 0.88130426
INFO:root:At the start of the epoch: mem (CPU python)=27095.56640625MB; mem (CPU total)=60142.68359375MB
INFO:root:[  127] Training loss: 0.62132353, Validation loss: 0.63037273, Gradient norm: 0.68214937
INFO:root:At the start of the epoch: mem (CPU python)=27133.66015625MB; mem (CPU total)=60218.96875MB
INFO:root:[  128] Training loss: 0.62139072, Validation loss: 0.63096541, Gradient norm: 0.80111686
INFO:root:At the start of the epoch: mem (CPU python)=27171.7578125MB; mem (CPU total)=60294.953125MB
INFO:root:[  129] Training loss: 0.62133017, Validation loss: 0.63054715, Gradient norm: 1.11501919
INFO:root:At the start of the epoch: mem (CPU python)=27209.85546875MB; mem (CPU total)=60371.40625MB
INFO:root:[  130] Training loss: 0.62088240, Validation loss: 0.62976396, Gradient norm: 0.93794031
INFO:root:At the start of the epoch: mem (CPU python)=27247.94921875MB; mem (CPU total)=60445.0234375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  131] Training loss: 0.62020988, Validation loss: 0.62965302, Gradient norm: 0.77127085
INFO:root:At the start of the epoch: mem (CPU python)=27286.04296875MB; mem (CPU total)=60510.60546875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  132] Training loss: 0.61907247, Validation loss: 0.62877949, Gradient norm: 0.42091137
INFO:root:At the start of the epoch: mem (CPU python)=27324.13671875MB; mem (CPU total)=60574.60546875MB
INFO:root:[  133] Training loss: 0.61842411, Validation loss: 0.62740018, Gradient norm: 0.28396273
INFO:root:At the start of the epoch: mem (CPU python)=27362.234375MB; mem (CPU total)=60638.30859375MB
INFO:root:[  134] Training loss: 0.61763742, Validation loss: 0.62785894, Gradient norm: 0.29980146
INFO:root:At the start of the epoch: mem (CPU python)=27400.328125MB; mem (CPU total)=60714.3046875MB
INFO:root:[  135] Training loss: 0.61782626, Validation loss: 0.62788953, Gradient norm: 0.27649303
INFO:root:At the start of the epoch: mem (CPU python)=27438.421875MB; mem (CPU total)=60790.32421875MB
INFO:root:[  136] Training loss: 0.61777188, Validation loss: 0.62701168, Gradient norm: 0.30094076
INFO:root:At the start of the epoch: mem (CPU python)=27476.5234375MB; mem (CPU total)=60867.1640625MB
INFO:root:[  137] Training loss: 0.61780761, Validation loss: 0.62695299, Gradient norm: 0.36648245
INFO:root:At the start of the epoch: mem (CPU python)=27514.6171875MB; mem (CPU total)=60938.44921875MB
INFO:root:[  138] Training loss: 0.61730482, Validation loss: 0.62766573, Gradient norm: 0.31767715
INFO:root:At the start of the epoch: mem (CPU python)=27552.7109375MB; mem (CPU total)=61002.20703125MB
INFO:root:[  139] Training loss: 0.61778086, Validation loss: 0.62727094, Gradient norm: 0.31749442
INFO:root:At the start of the epoch: mem (CPU python)=27590.80859375MB; mem (CPU total)=61067.1484375MB
INFO:root:[  140] Training loss: 0.61715989, Validation loss: 0.62677536, Gradient norm: 0.34862406
INFO:root:At the start of the epoch: mem (CPU python)=27628.90234375MB; mem (CPU total)=61133.85546875MB
INFO:root:[  141] Training loss: 0.61726776, Validation loss: 0.62694311, Gradient norm: 0.27991491
INFO:root:At the start of the epoch: mem (CPU python)=27666.99609375MB; mem (CPU total)=61210.265625MB
INFO:root:[  142] Training loss: 0.61711410, Validation loss: 0.62758769, Gradient norm: 0.32342372
INFO:root:At the start of the epoch: mem (CPU python)=27705.09375MB; mem (CPU total)=61286.4765625MB
INFO:root:[  143] Training loss: 0.61730742, Validation loss: 0.62646232, Gradient norm: 0.31979134
INFO:root:At the start of the epoch: mem (CPU python)=27743.19140625MB; mem (CPU total)=61362.77734375MB
INFO:root:[  144] Training loss: 0.61726773, Validation loss: 0.62671808, Gradient norm: 0.42640589
INFO:root:At the start of the epoch: mem (CPU python)=27781.28515625MB; mem (CPU total)=61430.1640625MB
INFO:root:[  145] Training loss: 0.61687757, Validation loss: 0.62806345, Gradient norm: 0.37522468
INFO:root:At the start of the epoch: mem (CPU python)=27819.3828125MB; mem (CPU total)=61494.875MB
INFO:root:[  146] Training loss: 0.61693395, Validation loss: 0.62734160, Gradient norm: 0.37519408
INFO:root:At the start of the epoch: mem (CPU python)=27857.48046875MB; mem (CPU total)=61559.52734375MB
INFO:root:[  147] Training loss: 0.61688231, Validation loss: 0.62685956, Gradient norm: 0.36919421
INFO:root:At the start of the epoch: mem (CPU python)=27895.57421875MB; mem (CPU total)=61630.109375MB
INFO:root:[  148] Training loss: 0.61670482, Validation loss: 0.62733525, Gradient norm: 0.31568177
INFO:root:At the start of the epoch: mem (CPU python)=27933.66796875MB; mem (CPU total)=61706.03515625MB
INFO:root:[  149] Training loss: 0.61656558, Validation loss: 0.62673074, Gradient norm: 0.35863481
INFO:root:At the start of the epoch: mem (CPU python)=27971.76171875MB; mem (CPU total)=61782.05859375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  150] Training loss: 0.61679104, Validation loss: 0.62674266, Gradient norm: 0.36866409
INFO:root:At the start of the epoch: mem (CPU python)=28009.859375MB; mem (CPU total)=61858.57421875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  151] Training loss: 0.61612330, Validation loss: 0.62675994, Gradient norm: 0.31896312
INFO:root:At the start of the epoch: mem (CPU python)=28047.953125MB; mem (CPU total)=61924.0234375MB
INFO:root:[  152] Training loss: 0.61602017, Validation loss: 0.62683720, Gradient norm: 0.24943199
INFO:root:At the start of the epoch: mem (CPU python)=28086.046875MB; mem (CPU total)=61988.51171875MB
INFO:root:[  153] Training loss: 0.61582421, Validation loss: 0.62643932, Gradient norm: 0.25256798
INFO:root:At the start of the epoch: mem (CPU python)=28124.1484375MB; mem (CPU total)=62052.53125MB
INFO:root:[  154] Training loss: 0.61606725, Validation loss: 0.62694722, Gradient norm: 0.26497418
INFO:root:At the start of the epoch: mem (CPU python)=28162.23828125MB; mem (CPU total)=62126.62890625MB
INFO:root:[  155] Training loss: 0.61576217, Validation loss: 0.62642539, Gradient norm: 0.25767514
INFO:root:At the start of the epoch: mem (CPU python)=28200.3359375MB; mem (CPU total)=62202.91796875MB
INFO:root:[  156] Training loss: 0.61600078, Validation loss: 0.62705374, Gradient norm: 0.28171875
INFO:root:At the start of the epoch: mem (CPU python)=28238.43359375MB; mem (CPU total)=62279.36328125MB
INFO:root:[  157] Training loss: 0.61601746, Validation loss: 0.62648386, Gradient norm: 0.24753024
INFO:root:At the start of the epoch: mem (CPU python)=28276.52734375MB; mem (CPU total)=62355.46484375MB
INFO:root:[  158] Training loss: 0.61579797, Validation loss: 0.62669290, Gradient norm: 0.23163982
INFO:root:At the start of the epoch: mem (CPU python)=28314.62109375MB; mem (CPU total)=62420.97265625MB
INFO:root:[  159] Training loss: 0.61589128, Validation loss: 0.62669945, Gradient norm: 0.26503782
INFO:root:At the start of the epoch: mem (CPU python)=28352.71484375MB; mem (CPU total)=62485.40625MB
INFO:root:[  160] Training loss: 0.61609332, Validation loss: 0.62674844, Gradient norm: 0.24906306
INFO:root:At the start of the epoch: mem (CPU python)=28390.8125MB; mem (CPU total)=62549.53515625MB
INFO:root:[  161] Training loss: 0.61555478, Validation loss: 0.62662719, Gradient norm: 0.26345072
INFO:root:At the start of the epoch: mem (CPU python)=28428.90625MB; mem (CPU total)=62623.453125MB
INFO:root:[  162] Training loss: 0.61573400, Validation loss: 0.62652242, Gradient norm: 0.28849132
INFO:root:At the start of the epoch: mem (CPU python)=28467.00390625MB; mem (CPU total)=62699.74609375MB
INFO:root:[  163] Training loss: 0.61571019, Validation loss: 0.62690264, Gradient norm: 0.24800004
INFO:root:At the start of the epoch: mem (CPU python)=28505.1015625MB; mem (CPU total)=62776.52734375MB
INFO:root:[  164] Training loss: 0.61555288, Validation loss: 0.62664135, Gradient norm: 0.24399676
INFO:root:At the start of the epoch: mem (CPU python)=28543.1953125MB; mem (CPU total)=62851.58203125MB
INFO:root:[  165] Training loss: 0.61555414, Validation loss: 0.62604594, Gradient norm: 0.25759985
INFO:root:At the start of the epoch: mem (CPU python)=28581.2890625MB; mem (CPU total)=62914.98828125MB
INFO:root:[  166] Training loss: 0.61596460, Validation loss: 0.62665643, Gradient norm: 0.31999369
INFO:root:At the start of the epoch: mem (CPU python)=28619.3828125MB; mem (CPU total)=62980.44140625MB
INFO:root:[  167] Training loss: 0.61568297, Validation loss: 0.62653463, Gradient norm: 0.25770406
INFO:root:At the start of the epoch: mem (CPU python)=28657.48046875MB; mem (CPU total)=63044.4140625MB
INFO:root:[  168] Training loss: 0.61594160, Validation loss: 0.62659344, Gradient norm: 0.28335359
INFO:root:At the start of the epoch: mem (CPU python)=28695.57421875MB; mem (CPU total)=63119.97265625MB
INFO:root:[  169] Training loss: 0.61544123, Validation loss: 0.62728387, Gradient norm: 0.26244046
INFO:root:At the start of the epoch: mem (CPU python)=28733.671875MB; mem (CPU total)=63197.7734375MB
INFO:root:[  170] Training loss: 0.61546172, Validation loss: 0.62680486, Gradient norm: 0.28400941
INFO:root:At the start of the epoch: mem (CPU python)=28771.76953125MB; mem (CPU total)=63273.71875MB
INFO:root:[  171] Training loss: 0.61548927, Validation loss: 0.62686490, Gradient norm: 0.27020820
INFO:root:At the start of the epoch: mem (CPU python)=28809.8671875MB; mem (CPU total)=63344.69140625MB
INFO:root:[  172] Training loss: 0.61589533, Validation loss: 0.62603645, Gradient norm: 0.26060181
INFO:root:At the start of the epoch: mem (CPU python)=28847.9609375MB; mem (CPU total)=63409.29296875MB
INFO:root:[  173] Training loss: 0.61531940, Validation loss: 0.62581097, Gradient norm: 0.25136477
INFO:root:At the start of the epoch: mem (CPU python)=28886.05859375MB; mem (CPU total)=63474.4375MB
INFO:root:[  174] Training loss: 0.61552273, Validation loss: 0.62635929, Gradient norm: 0.27670949
INFO:root:At the start of the epoch: mem (CPU python)=28924.15234375MB; mem (CPU total)=63540.640625MB
INFO:root:[  175] Training loss: 0.61574492, Validation loss: 0.62666400, Gradient norm: 0.26257512
INFO:root:At the start of the epoch: mem (CPU python)=28962.24609375MB; mem (CPU total)=63617.19140625MB
INFO:root:[  176] Training loss: 0.61558322, Validation loss: 0.62623385, Gradient norm: 0.24581835
INFO:root:At the start of the epoch: mem (CPU python)=29000.33984375MB; mem (CPU total)=63693.19921875MB
INFO:root:[  177] Training loss: 0.61544522, Validation loss: 0.62598981, Gradient norm: 0.24911242
INFO:root:At the start of the epoch: mem (CPU python)=29038.4375MB; mem (CPU total)=63769.125MB
INFO:root:[  178] Training loss: 0.61576561, Validation loss: 0.62643660, Gradient norm: 0.25641399
INFO:root:At the start of the epoch: mem (CPU python)=29076.53125MB; mem (CPU total)=63840.95703125MB
INFO:root:[  179] Training loss: 0.61570450, Validation loss: 0.62705361, Gradient norm: 0.26268608
INFO:root:At the start of the epoch: mem (CPU python)=29114.62890625MB; mem (CPU total)=63905.0234375MB
INFO:root:[  180] Training loss: 0.61522754, Validation loss: 0.62616990, Gradient norm: 0.27165905
INFO:root:At the start of the epoch: mem (CPU python)=29152.7265625MB; mem (CPU total)=63969.71875MB
INFO:root:[  181] Training loss: 0.61532033, Validation loss: 0.62623738, Gradient norm: 0.28414811
INFO:root:At the start of the epoch: mem (CPU python)=29190.8203125MB; mem (CPU total)=64036.21875MB
INFO:root:[  182] Training loss: 0.61524044, Validation loss: 0.62595205, Gradient norm: 0.27556082
INFO:root:At the start of the epoch: mem (CPU python)=29228.9140625MB; mem (CPU total)=64112.25390625MB
INFO:root:EP 182: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=29267.0078125MB; mem (CPU total)=64173.91015625MB
INFO:root:Training the model took 11735.867s.
INFO:root:Emptying the cuda cache took 0.05s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87411
INFO:root:EnergyScoreTrain: 0.61562
INFO:root:CRPSTrain: 0.53748
INFO:root:Gaussian NLLTrain: 1.95111
INFO:root:CoverageTrain: 0.78111
INFO:root:IntervalWidthTrain: 3.1391
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88916
INFO:root:EnergyScoreValidation: 0.62623
INFO:root:CRPSValidation: 0.54597
INFO:root:Gaussian NLLValidation: 1.97156
INFO:root:CoverageValidation: 0.77778
INFO:root:IntervalWidthValidation: 3.1383
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89001
INFO:root:EnergyScoreTest: 0.62682
INFO:root:CRPSTest: 0.54665
INFO:root:Gaussian NLLTest: 1.9742
INFO:root:CoverageTest: 0.77657
INFO:root:IntervalWidthTest: 3.13698
INFO:root:After validation: mem (CPU python)=29309.875MB; mem (CPU total)=64327.3828125MB
INFO:root:###4 out of 5 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': 0.1, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=29309.875MB; mem (CPU total)=64346.07421875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=29310.24609375MB; mem (CPU total)=64346.56640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=29310.2890625MB; mem (CPU total)=64351.3828125MB
INFO:root:[    1] Training loss: 0.77684643, Validation loss: 0.72825577, Gradient norm: 1.89322627
INFO:root:At the start of the epoch: mem (CPU python)=29348.3203125MB; mem (CPU total)=64422.4765625MB
INFO:root:[    2] Training loss: 0.72420142, Validation loss: 0.72353138, Gradient norm: 1.70706510
INFO:root:At the start of the epoch: mem (CPU python)=29386.41796875MB; mem (CPU total)=64498.109375MB
INFO:root:[    3] Training loss: 0.72355392, Validation loss: 0.72600793, Gradient norm: 2.12988706
INFO:root:At the start of the epoch: mem (CPU python)=29424.52734375MB; mem (CPU total)=64574.609375MB
INFO:root:[    4] Training loss: 0.72163686, Validation loss: 0.72151985, Gradient norm: 1.46870434
INFO:root:At the start of the epoch: mem (CPU python)=29462.63671875MB; mem (CPU total)=64650.625MB
INFO:root:[    5] Training loss: 0.72064520, Validation loss: 0.72067389, Gradient norm: 1.08655868
INFO:root:At the start of the epoch: mem (CPU python)=29500.75MB; mem (CPU total)=64715.7890625MB
INFO:root:[    6] Training loss: 0.72007930, Validation loss: 0.72032570, Gradient norm: 1.02742128
INFO:root:At the start of the epoch: mem (CPU python)=29538.86328125MB; mem (CPU total)=64779.29296875MB
INFO:root:[    7] Training loss: 0.71956684, Validation loss: 0.71983810, Gradient norm: 0.86348594
INFO:root:At the start of the epoch: mem (CPU python)=29576.97265625MB; mem (CPU total)=64842.50390625MB
INFO:root:[    8] Training loss: 0.71921944, Validation loss: 0.72078890, Gradient norm: 0.87346466
INFO:root:At the start of the epoch: mem (CPU python)=29615.08203125MB; mem (CPU total)=64917.8125MB
INFO:root:[    9] Training loss: 0.71861510, Validation loss: 0.71921696, Gradient norm: 0.69108364
INFO:root:At the start of the epoch: mem (CPU python)=29653.1796875MB; mem (CPU total)=64994.2890625MB
INFO:root:[   10] Training loss: 0.71820942, Validation loss: 0.71769499, Gradient norm: 1.12931727
INFO:root:At the start of the epoch: mem (CPU python)=29691.2734375MB; mem (CPU total)=65070.09375MB
INFO:root:[   11] Training loss: 0.71598262, Validation loss: 0.71531802, Gradient norm: 0.83491991
INFO:root:At the start of the epoch: mem (CPU python)=29729.3671875MB; mem (CPU total)=65141.46484375MB
INFO:root:[   12] Training loss: 0.71086740, Validation loss: 0.70784271, Gradient norm: 0.55647168
INFO:root:At the start of the epoch: mem (CPU python)=29767.46484375MB; mem (CPU total)=65205.83203125MB
INFO:root:[   13] Training loss: 0.70478428, Validation loss: 0.70223963, Gradient norm: 0.49262236
INFO:root:At the start of the epoch: mem (CPU python)=29805.55859375MB; mem (CPU total)=65268.62890625MB
INFO:root:[   14] Training loss: 0.70015124, Validation loss: 0.69907974, Gradient norm: 0.41999415
INFO:root:At the start of the epoch: mem (CPU python)=29843.65625MB; mem (CPU total)=65337.69921875MB
INFO:root:[   15] Training loss: 0.69626696, Validation loss: 0.69567398, Gradient norm: 0.41494112
INFO:root:At the start of the epoch: mem (CPU python)=29881.75390625MB; mem (CPU total)=65415.375MB
INFO:root:[   16] Training loss: 0.69214087, Validation loss: 0.69200101, Gradient norm: 0.54581562
INFO:root:At the start of the epoch: mem (CPU python)=29919.84765625MB; mem (CPU total)=65491.41796875MB
INFO:root:[   17] Training loss: 0.68836140, Validation loss: 0.68844111, Gradient norm: 0.35282014
INFO:root:At the start of the epoch: mem (CPU python)=29957.94140625MB; mem (CPU total)=65567.921875MB
INFO:root:[   18] Training loss: 0.68478359, Validation loss: 0.68572905, Gradient norm: 0.29903208
INFO:root:At the start of the epoch: mem (CPU python)=29996.03515625MB; mem (CPU total)=65631.421875MB
INFO:root:[   19] Training loss: 0.68225853, Validation loss: 0.68264736, Gradient norm: 0.48431468
INFO:root:At the start of the epoch: mem (CPU python)=30034.1328125MB; mem (CPU total)=65694.8046875MB
INFO:root:[   20] Training loss: 0.67931532, Validation loss: 0.68006957, Gradient norm: 0.26486636
INFO:root:At the start of the epoch: mem (CPU python)=30072.2265625MB; mem (CPU total)=65758.28515625MB
INFO:root:[   21] Training loss: 0.67704727, Validation loss: 0.67778895, Gradient norm: 0.32226926
INFO:root:At the start of the epoch: mem (CPU python)=30110.3203125MB; mem (CPU total)=65834.3359375MB
INFO:root:[   22] Training loss: 0.67485949, Validation loss: 0.67654832, Gradient norm: 0.31809371
INFO:root:At the start of the epoch: mem (CPU python)=30148.421875MB; mem (CPU total)=65911.078125MB
INFO:root:[   23] Training loss: 0.67315385, Validation loss: 0.67302712, Gradient norm: 0.30753541
INFO:root:At the start of the epoch: mem (CPU python)=30186.515625MB; mem (CPU total)=65988.703125MB
INFO:root:[   24] Training loss: 0.67080059, Validation loss: 0.67051832, Gradient norm: 0.26820950
INFO:root:At the start of the epoch: mem (CPU python)=30224.61328125MB; mem (CPU total)=66039.6171875MB
INFO:root:[   25] Training loss: 0.66885372, Validation loss: 0.66985847, Gradient norm: 0.34280758
INFO:root:At the start of the epoch: mem (CPU python)=30262.70703125MB; mem (CPU total)=66090.02734375MB
INFO:root:[   26] Training loss: 0.66701449, Validation loss: 0.66723060, Gradient norm: 0.24649172
INFO:root:At the start of the epoch: mem (CPU python)=30300.8046875MB; mem (CPU total)=66140.24609375MB
INFO:root:[   27] Training loss: 0.66520289, Validation loss: 0.66748344, Gradient norm: 0.23667743
INFO:root:At the start of the epoch: mem (CPU python)=30338.8984375MB; mem (CPU total)=66183.01953125MB
INFO:root:[   28] Training loss: 0.66378953, Validation loss: 0.66490596, Gradient norm: 0.25790474
INFO:root:At the start of the epoch: mem (CPU python)=30376.99609375MB; mem (CPU total)=66221.203125MB
INFO:root:[   29] Training loss: 0.66287527, Validation loss: 0.66468812, Gradient norm: 0.31469699
INFO:root:At the start of the epoch: mem (CPU python)=30415.08984375MB; mem (CPU total)=66259.2890625MB
INFO:root:[   30] Training loss: 0.66115612, Validation loss: 0.66392381, Gradient norm: 0.32567625
INFO:root:At the start of the epoch: mem (CPU python)=30453.1875MB; mem (CPU total)=30222.1640625MB
INFO:root:[   31] Training loss: 0.65977005, Validation loss: 0.66199189, Gradient norm: 0.29845221
INFO:root:At the start of the epoch: mem (CPU python)=30491.28125MB; mem (CPU total)=30260.3046875MB
INFO:root:[   32] Training loss: 0.65846547, Validation loss: 0.66064041, Gradient norm: 0.28992059
INFO:root:At the start of the epoch: mem (CPU python)=30529.37890625MB; mem (CPU total)=30297.53515625MB
INFO:root:[   33] Training loss: 0.65729910, Validation loss: 0.65979105, Gradient norm: 0.20086934
INFO:root:At the start of the epoch: mem (CPU python)=30567.47265625MB; mem (CPU total)=30335.9140625MB
INFO:root:[   34] Training loss: 0.65652223, Validation loss: 0.65753374, Gradient norm: 0.24890938
INFO:root:At the start of the epoch: mem (CPU python)=30605.56640625MB; mem (CPU total)=30374.01171875MB
INFO:root:[   35] Training loss: 0.65523752, Validation loss: 0.65747812, Gradient norm: 0.33161017
INFO:root:At the start of the epoch: mem (CPU python)=30643.66015625MB; mem (CPU total)=30412.4140625MB
INFO:root:[   36] Training loss: 0.65470162, Validation loss: 0.65648646, Gradient norm: 0.25764614
INFO:root:At the start of the epoch: mem (CPU python)=30681.7578125MB; mem (CPU total)=30450.54296875MB
INFO:root:[   37] Training loss: 0.65376728, Validation loss: 0.65494394, Gradient norm: 0.25472642
INFO:root:At the start of the epoch: mem (CPU python)=30719.8515625MB; mem (CPU total)=30488.5390625MB
INFO:root:[   38] Training loss: 0.65275237, Validation loss: 0.65473190, Gradient norm: 0.26536100
INFO:root:At the start of the epoch: mem (CPU python)=30757.94921875MB; mem (CPU total)=30526.38671875MB
INFO:root:[   39] Training loss: 0.65227077, Validation loss: 0.65377614, Gradient norm: 0.31627440
INFO:root:At the start of the epoch: mem (CPU python)=30796.046875MB; mem (CPU total)=30564.2734375MB
INFO:root:[   40] Training loss: 0.65093789, Validation loss: 0.65359075, Gradient norm: 0.22932270
INFO:root:At the start of the epoch: mem (CPU python)=30834.140625MB; mem (CPU total)=30602.375MB
INFO:root:[   41] Training loss: 0.65014022, Validation loss: 0.65361691, Gradient norm: 0.27215163
INFO:root:At the start of the epoch: mem (CPU python)=30872.234375MB; mem (CPU total)=30640.4765625MB
INFO:root:[   42] Training loss: 0.64975465, Validation loss: 0.65200745, Gradient norm: 0.29542551
INFO:root:At the start of the epoch: mem (CPU python)=30910.328125MB; mem (CPU total)=30677.92578125MB
INFO:root:[   43] Training loss: 0.64914153, Validation loss: 0.65212563, Gradient norm: 0.29413968
INFO:root:At the start of the epoch: mem (CPU python)=30948.42578125MB; mem (CPU total)=30716.26171875MB
INFO:root:[   44] Training loss: 0.64813351, Validation loss: 0.65093828, Gradient norm: 0.23771913
INFO:root:At the start of the epoch: mem (CPU python)=30986.5234375MB; mem (CPU total)=30754.3828125MB
INFO:root:[   45] Training loss: 0.64777748, Validation loss: 0.64986447, Gradient norm: 0.25208465
INFO:root:At the start of the epoch: mem (CPU python)=31024.6171875MB; mem (CPU total)=30793.02734375MB
INFO:root:[   46] Training loss: 0.64645542, Validation loss: 0.64970835, Gradient norm: 0.23876335
INFO:root:At the start of the epoch: mem (CPU python)=31062.71484375MB; mem (CPU total)=30831.58984375MB
INFO:root:[   47] Training loss: 0.64642208, Validation loss: 0.64821166, Gradient norm: 0.24143471
INFO:root:At the start of the epoch: mem (CPU python)=31100.8125MB; mem (CPU total)=30869.4453125MB
INFO:root:[   48] Training loss: 0.64536804, Validation loss: 0.64792161, Gradient norm: 0.23890025
INFO:root:At the start of the epoch: mem (CPU python)=31138.90625MB; mem (CPU total)=30907.48828125MB
INFO:root:[   49] Training loss: 0.64474259, Validation loss: 0.64829906, Gradient norm: 0.31950406
INFO:root:At the start of the epoch: mem (CPU python)=31177.00390625MB; mem (CPU total)=30945.828125MB
INFO:root:[   50] Training loss: 0.64437440, Validation loss: 0.64696820, Gradient norm: 0.20687044
INFO:root:At the start of the epoch: mem (CPU python)=31215.09765625MB; mem (CPU total)=30983.921875MB
INFO:root:[   51] Training loss: 0.64390778, Validation loss: 0.64749617, Gradient norm: 0.25525402
INFO:root:At the start of the epoch: mem (CPU python)=31253.19140625MB; mem (CPU total)=31022.27734375MB
INFO:root:[   52] Training loss: 0.64273662, Validation loss: 0.64533463, Gradient norm: 0.23192103
INFO:root:At the start of the epoch: mem (CPU python)=31291.28515625MB; mem (CPU total)=31060.3203125MB
INFO:root:[   53] Training loss: 0.64238969, Validation loss: 0.64533915, Gradient norm: 0.27442015
INFO:root:At the start of the epoch: mem (CPU python)=31329.38671875MB; mem (CPU total)=31098.21875MB
INFO:root:[   54] Training loss: 0.64157178, Validation loss: 0.64436905, Gradient norm: 0.32636283
INFO:root:At the start of the epoch: mem (CPU python)=31367.48046875MB; mem (CPU total)=31136.4609375MB
INFO:root:[   55] Training loss: 0.64104297, Validation loss: 0.64458591, Gradient norm: 0.30122046
INFO:root:At the start of the epoch: mem (CPU python)=31405.57421875MB; mem (CPU total)=31174.828125MB
INFO:root:[   56] Training loss: 0.64067379, Validation loss: 0.64450327, Gradient norm: 0.26808477
INFO:root:At the start of the epoch: mem (CPU python)=31443.671875MB; mem (CPU total)=31214.203125MB
INFO:root:[   57] Training loss: 0.63981527, Validation loss: 0.64413880, Gradient norm: 0.23038703
INFO:root:At the start of the epoch: mem (CPU python)=31481.765625MB; mem (CPU total)=31252.33203125MB
INFO:root:[   58] Training loss: 0.63969498, Validation loss: 0.64242541, Gradient norm: 0.26797548
INFO:root:At the start of the epoch: mem (CPU python)=31519.859375MB; mem (CPU total)=31290.48046875MB
INFO:root:[   59] Training loss: 0.63826120, Validation loss: 0.64285774, Gradient norm: 0.25818016
INFO:root:At the start of the epoch: mem (CPU python)=31557.96484375MB; mem (CPU total)=31328.765625MB
INFO:root:[   60] Training loss: 0.63875751, Validation loss: 0.64254938, Gradient norm: 0.25457188
INFO:root:At the start of the epoch: mem (CPU python)=31596.0625MB; mem (CPU total)=31366.73828125MB
INFO:root:[   61] Training loss: 0.63813661, Validation loss: 0.64157179, Gradient norm: 0.31360972
INFO:root:At the start of the epoch: mem (CPU python)=31634.15625MB; mem (CPU total)=31405.65234375MB
INFO:root:[   62] Training loss: 0.63701241, Validation loss: 0.64114077, Gradient norm: 0.21843953
INFO:root:At the start of the epoch: mem (CPU python)=31672.25390625MB; mem (CPU total)=31443.109375MB
INFO:root:[   63] Training loss: 0.63707525, Validation loss: 0.64174402, Gradient norm: 0.22004223
INFO:root:At the start of the epoch: mem (CPU python)=31710.34765625MB; mem (CPU total)=31481.27734375MB
INFO:root:[   64] Training loss: 0.63660905, Validation loss: 0.63977582, Gradient norm: 0.27468330
INFO:root:At the start of the epoch: mem (CPU python)=31748.4453125MB; mem (CPU total)=31519.41796875MB
INFO:root:[   65] Training loss: 0.63606381, Validation loss: 0.64130941, Gradient norm: 0.23877734
INFO:root:At the start of the epoch: mem (CPU python)=31786.5390625MB; mem (CPU total)=31557.55859375MB
INFO:root:[   66] Training loss: 0.63573268, Validation loss: 0.63988841, Gradient norm: 0.25737978
INFO:root:At the start of the epoch: mem (CPU python)=31824.63671875MB; mem (CPU total)=31595.70703125MB
INFO:root:[   67] Training loss: 0.63507889, Validation loss: 0.63959068, Gradient norm: 0.21753832
INFO:root:At the start of the epoch: mem (CPU python)=31862.73046875MB; mem (CPU total)=31633.1796875MB
INFO:root:[   68] Training loss: 0.63426155, Validation loss: 0.63896847, Gradient norm: 0.21476547
INFO:root:At the start of the epoch: mem (CPU python)=31900.82421875MB; mem (CPU total)=31670.87890625MB
INFO:root:[   69] Training loss: 0.63421680, Validation loss: 0.63849521, Gradient norm: 0.25672895
INFO:root:At the start of the epoch: mem (CPU python)=31938.91796875MB; mem (CPU total)=31709.01953125MB
INFO:root:[   70] Training loss: 0.63409653, Validation loss: 0.63819309, Gradient norm: 0.29857006
INFO:root:At the start of the epoch: mem (CPU python)=31977.015625MB; mem (CPU total)=31746.73828125MB
INFO:root:[   71] Training loss: 0.63313667, Validation loss: 0.63846400, Gradient norm: 0.27231661
INFO:root:At the start of the epoch: mem (CPU python)=32015.109375MB; mem (CPU total)=31784.8203125MB
INFO:root:[   72] Training loss: 0.63312793, Validation loss: 0.63800764, Gradient norm: 0.26897704
INFO:root:At the start of the epoch: mem (CPU python)=32053.20703125MB; mem (CPU total)=31822.7109375MB
INFO:root:[   73] Training loss: 0.63283612, Validation loss: 0.63723120, Gradient norm: 0.27540745
INFO:root:At the start of the epoch: mem (CPU python)=32091.3046875MB; mem (CPU total)=31860.87109375MB
INFO:root:[   74] Training loss: 0.63192246, Validation loss: 0.63698138, Gradient norm: 0.25605695
INFO:root:At the start of the epoch: mem (CPU python)=32129.3984375MB; mem (CPU total)=31899.08984375MB
INFO:root:[   75] Training loss: 0.63201331, Validation loss: 0.63705330, Gradient norm: 0.26212299
INFO:root:At the start of the epoch: mem (CPU python)=32167.4921875MB; mem (CPU total)=31937.41796875MB
INFO:root:[   76] Training loss: 0.63129354, Validation loss: 0.63807368, Gradient norm: 0.24645902
INFO:root:At the start of the epoch: mem (CPU python)=32205.5859375MB; mem (CPU total)=31976.05078125MB
INFO:root:[   77] Training loss: 0.63096627, Validation loss: 0.63550538, Gradient norm: 0.29668429
INFO:root:At the start of the epoch: mem (CPU python)=32243.68359375MB; mem (CPU total)=32014.109375MB
INFO:root:[   78] Training loss: 0.63088771, Validation loss: 0.63634613, Gradient norm: 0.24598500
INFO:root:At the start of the epoch: mem (CPU python)=32281.77734375MB; mem (CPU total)=32052.41015625MB
INFO:root:[   79] Training loss: 0.63061471, Validation loss: 0.63550830, Gradient norm: 0.29403111
INFO:root:At the start of the epoch: mem (CPU python)=32319.875MB; mem (CPU total)=32089.72265625MB
INFO:root:[   80] Training loss: 0.62997133, Validation loss: 0.63515201, Gradient norm: 0.29128802
INFO:root:At the start of the epoch: mem (CPU python)=32357.97265625MB; mem (CPU total)=32128.13671875MB
INFO:root:[   81] Training loss: 0.62956034, Validation loss: 0.63553435, Gradient norm: 0.23972893
INFO:root:At the start of the epoch: mem (CPU python)=32396.06640625MB; mem (CPU total)=32165.7734375MB
INFO:root:[   82] Training loss: 0.62941197, Validation loss: 0.63479021, Gradient norm: 0.35048028
INFO:root:At the start of the epoch: mem (CPU python)=32434.16015625MB; mem (CPU total)=32203.91015625MB
INFO:root:[   83] Training loss: 0.62871204, Validation loss: 0.63501734, Gradient norm: 0.28168518
INFO:root:At the start of the epoch: mem (CPU python)=32472.2578125MB; mem (CPU total)=32242.02734375MB
INFO:root:[   84] Training loss: 0.62846042, Validation loss: 0.63449979, Gradient norm: 0.28904479
INFO:root:At the start of the epoch: mem (CPU python)=32510.3515625MB; mem (CPU total)=32279.90625MB
INFO:root:[   85] Training loss: 0.62819315, Validation loss: 0.63338503, Gradient norm: 0.27171252
INFO:root:At the start of the epoch: mem (CPU python)=32548.4453125MB; mem (CPU total)=32318.7265625MB
INFO:root:[   86] Training loss: 0.62850773, Validation loss: 0.63444153, Gradient norm: 0.32635928
INFO:root:At the start of the epoch: mem (CPU python)=32586.5390625MB; mem (CPU total)=32356.66796875MB
INFO:root:[   87] Training loss: 0.62830175, Validation loss: 0.63346313, Gradient norm: 0.35259195
INFO:root:At the start of the epoch: mem (CPU python)=32624.63671875MB; mem (CPU total)=32394.80078125MB
INFO:root:[   88] Training loss: 0.62748467, Validation loss: 0.63225183, Gradient norm: 0.27755230
INFO:root:At the start of the epoch: mem (CPU python)=32662.734375MB; mem (CPU total)=32432.953125MB
INFO:root:[   89] Training loss: 0.62732242, Validation loss: 0.63330063, Gradient norm: 0.29842867
INFO:root:At the start of the epoch: mem (CPU python)=32700.828125MB; mem (CPU total)=32471.23046875MB
INFO:root:[   90] Training loss: 0.62654702, Validation loss: 0.63187668, Gradient norm: 0.27153238
INFO:root:At the start of the epoch: mem (CPU python)=32738.92578125MB; mem (CPU total)=32509.34375MB
INFO:root:[   91] Training loss: 0.62631774, Validation loss: 0.63251494, Gradient norm: 0.32079895
INFO:root:At the start of the epoch: mem (CPU python)=32777.01953125MB; mem (CPU total)=32547.70703125MB
INFO:root:[   92] Training loss: 0.62648662, Validation loss: 0.63290296, Gradient norm: 0.31735183
INFO:root:At the start of the epoch: mem (CPU python)=32815.11328125MB; mem (CPU total)=32586.30859375MB
INFO:root:[   93] Training loss: 0.62566269, Validation loss: 0.63115474, Gradient norm: 0.26185995
INFO:root:At the start of the epoch: mem (CPU python)=32853.20703125MB; mem (CPU total)=32624.20703125MB
INFO:root:[   94] Training loss: 0.62569853, Validation loss: 0.63264428, Gradient norm: 0.26116181
INFO:root:At the start of the epoch: mem (CPU python)=32891.3046875MB; mem (CPU total)=32662.28515625MB
INFO:root:[   95] Training loss: 0.62522781, Validation loss: 0.63152442, Gradient norm: 0.27069751
INFO:root:At the start of the epoch: mem (CPU python)=32929.40234375MB; mem (CPU total)=32700.17578125MB
INFO:root:[   96] Training loss: 0.62520688, Validation loss: 0.63137189, Gradient norm: 0.34217695
INFO:root:At the start of the epoch: mem (CPU python)=32967.4921875MB; mem (CPU total)=32738.28515625MB
INFO:root:[   97] Training loss: 0.62473741, Validation loss: 0.63100632, Gradient norm: 0.35873099
INFO:root:At the start of the epoch: mem (CPU python)=33005.59375MB; mem (CPU total)=32776.62890625MB
INFO:root:[   98] Training loss: 0.62420663, Validation loss: 0.63009406, Gradient norm: 0.27092225
INFO:root:At the start of the epoch: mem (CPU python)=33043.6875MB; mem (CPU total)=32814.5078125MB
INFO:root:[   99] Training loss: 0.62382522, Validation loss: 0.63120355, Gradient norm: 0.26027009
INFO:root:At the start of the epoch: mem (CPU python)=33081.78125MB; mem (CPU total)=32852.8359375MB
INFO:root:[  100] Training loss: 0.62388337, Validation loss: 0.63064400, Gradient norm: 0.29360823
INFO:root:At the start of the epoch: mem (CPU python)=33119.87890625MB; mem (CPU total)=32891.40234375MB
INFO:root:[  101] Training loss: 0.62344449, Validation loss: 0.62990386, Gradient norm: 0.30917711
INFO:root:At the start of the epoch: mem (CPU python)=33157.97265625MB; mem (CPU total)=32929.515625MB
INFO:root:[  102] Training loss: 0.62312928, Validation loss: 0.63100204, Gradient norm: 0.35714739
INFO:root:At the start of the epoch: mem (CPU python)=33196.06640625MB; mem (CPU total)=32967.6015625MB
INFO:root:[  103] Training loss: 0.62318038, Validation loss: 0.63028744, Gradient norm: 0.32500968
INFO:root:At the start of the epoch: mem (CPU python)=33234.16015625MB; mem (CPU total)=33005.75MB
INFO:root:[  104] Training loss: 0.62273742, Validation loss: 0.62873209, Gradient norm: 0.33850200
INFO:root:At the start of the epoch: mem (CPU python)=33272.2578125MB; mem (CPU total)=33044.11328125MB
INFO:root:[  105] Training loss: 0.62219340, Validation loss: 0.62969038, Gradient norm: 0.32910416
INFO:root:At the start of the epoch: mem (CPU python)=33310.35546875MB; mem (CPU total)=33082.140625MB
INFO:root:[  106] Training loss: 0.62239940, Validation loss: 0.62797747, Gradient norm: 0.36766266
INFO:root:At the start of the epoch: mem (CPU python)=33348.44921875MB; mem (CPU total)=33120.30859375MB
INFO:root:[  107] Training loss: 0.62175073, Validation loss: 0.62832899, Gradient norm: 0.31788276
INFO:root:At the start of the epoch: mem (CPU python)=33386.546875MB; mem (CPU total)=33158.92578125MB
INFO:root:[  108] Training loss: 0.62201529, Validation loss: 0.62852281, Gradient norm: 0.28637840
INFO:root:At the start of the epoch: mem (CPU python)=33424.640625MB; mem (CPU total)=33196.78125MB
INFO:root:[  109] Training loss: 0.62190335, Validation loss: 0.62873781, Gradient norm: 0.33993103
INFO:root:At the start of the epoch: mem (CPU python)=33462.734375MB; mem (CPU total)=33235.14453125MB
INFO:root:[  110] Training loss: 0.62123449, Validation loss: 0.62854947, Gradient norm: 0.32102481
INFO:root:At the start of the epoch: mem (CPU python)=33500.828125MB; mem (CPU total)=33273.171875MB
INFO:root:[  111] Training loss: 0.62054364, Validation loss: 0.62928167, Gradient norm: 0.42091207
INFO:root:At the start of the epoch: mem (CPU python)=33538.92578125MB; mem (CPU total)=33311.39453125MB
INFO:root:[  112] Training loss: 0.62058665, Validation loss: 0.62809270, Gradient norm: 0.34520201
INFO:root:At the start of the epoch: mem (CPU python)=33577.0234375MB; mem (CPU total)=33349.73828125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  113] Training loss: 0.62002708, Validation loss: 0.62731372, Gradient norm: 0.33847644
INFO:root:At the start of the epoch: mem (CPU python)=33615.1171875MB; mem (CPU total)=33387.8984375MB
INFO:root:[  114] Training loss: 0.61896503, Validation loss: 0.62627501, Gradient norm: 0.27527988
INFO:root:At the start of the epoch: mem (CPU python)=33653.21484375MB; mem (CPU total)=33426.00390625MB
INFO:root:[  115] Training loss: 0.61920750, Validation loss: 0.62693265, Gradient norm: 0.24906104
INFO:root:At the start of the epoch: mem (CPU python)=33691.30859375MB; mem (CPU total)=33464.6015625MB
INFO:root:[  116] Training loss: 0.61912344, Validation loss: 0.62681720, Gradient norm: 0.31040132
INFO:root:At the start of the epoch: mem (CPU python)=33729.40234375MB; mem (CPU total)=33502.70703125MB
INFO:root:[  117] Training loss: 0.61871134, Validation loss: 0.62589025, Gradient norm: 0.22734263
INFO:root:At the start of the epoch: mem (CPU python)=33767.5MB; mem (CPU total)=33540.875MB
INFO:root:[  118] Training loss: 0.61875738, Validation loss: 0.62578161, Gradient norm: 0.27486978
INFO:root:At the start of the epoch: mem (CPU python)=33805.59375MB; mem (CPU total)=33579.953125MB
INFO:root:[  119] Training loss: 0.61847239, Validation loss: 0.62629324, Gradient norm: 0.32742228
INFO:root:At the start of the epoch: mem (CPU python)=33843.6875MB; mem (CPU total)=33617.421875MB
INFO:root:[  120] Training loss: 0.61822578, Validation loss: 0.62520864, Gradient norm: 0.26743743
INFO:root:At the start of the epoch: mem (CPU python)=33881.78125MB; mem (CPU total)=33656.0390625MB
INFO:root:[  121] Training loss: 0.61849037, Validation loss: 0.62635221, Gradient norm: 0.25873538
INFO:root:At the start of the epoch: mem (CPU python)=33919.8828125MB; mem (CPU total)=33693.9453125MB
INFO:root:[  122] Training loss: 0.61768409, Validation loss: 0.62462658, Gradient norm: 0.28048969
INFO:root:At the start of the epoch: mem (CPU python)=33957.9765625MB; mem (CPU total)=33732.1484375MB
INFO:root:[  123] Training loss: 0.61793855, Validation loss: 0.62696556, Gradient norm: 0.28212872
INFO:root:At the start of the epoch: mem (CPU python)=33996.0703125MB; mem (CPU total)=33770.296875MB
INFO:root:[  124] Training loss: 0.61768331, Validation loss: 0.62463315, Gradient norm: 0.28540660
INFO:root:At the start of the epoch: mem (CPU python)=34034.16796875MB; mem (CPU total)=33808.17578125MB
INFO:root:[  125] Training loss: 0.61739538, Validation loss: 0.62679774, Gradient norm: 0.30986047
INFO:root:At the start of the epoch: mem (CPU python)=34072.26171875MB; mem (CPU total)=33846.0703125MB
INFO:root:[  126] Training loss: 0.61746859, Validation loss: 0.62591932, Gradient norm: 0.29786154
INFO:root:At the start of the epoch: mem (CPU python)=34110.35546875MB; mem (CPU total)=33884.39453125MB
INFO:root:[  127] Training loss: 0.61727466, Validation loss: 0.62512307, Gradient norm: 0.26944393
INFO:root:At the start of the epoch: mem (CPU python)=34148.44921875MB; mem (CPU total)=33923.0546875MB
INFO:root:[  128] Training loss: 0.61720064, Validation loss: 0.62643397, Gradient norm: 0.28639157
INFO:root:At the start of the epoch: mem (CPU python)=34186.55078125MB; mem (CPU total)=33960.59765625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  129] Training loss: 0.61721319, Validation loss: 0.62625513, Gradient norm: 0.32233336
INFO:root:At the start of the epoch: mem (CPU python)=34224.64453125MB; mem (CPU total)=33998.73828125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  130] Training loss: 0.61676939, Validation loss: 0.62525108, Gradient norm: 0.22562544
INFO:root:At the start of the epoch: mem (CPU python)=34262.73828125MB; mem (CPU total)=34037.125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  131] Training loss: 0.61635829, Validation loss: 0.62430198, Gradient norm: 0.19394388
INFO:root:At the start of the epoch: mem (CPU python)=34300.8359375MB; mem (CPU total)=34075.57421875MB
INFO:root:[  132] Training loss: 0.61556136, Validation loss: 0.62425315, Gradient norm: 0.18048613
INFO:root:At the start of the epoch: mem (CPU python)=34338.9296875MB; mem (CPU total)=34113.72265625MB
INFO:root:[  133] Training loss: 0.61570723, Validation loss: 0.62462036, Gradient norm: 0.17618024
INFO:root:At the start of the epoch: mem (CPU python)=34377.0234375MB; mem (CPU total)=34151.0546875MB
INFO:root:[  134] Training loss: 0.61584733, Validation loss: 0.62320224, Gradient norm: 0.17429110
INFO:root:At the start of the epoch: mem (CPU python)=34415.12109375MB; mem (CPU total)=34189.515625MB
INFO:root:[  135] Training loss: 0.61549542, Validation loss: 0.62496849, Gradient norm: 0.17590536
INFO:root:At the start of the epoch: mem (CPU python)=34453.21484375MB; mem (CPU total)=34227.40625MB
INFO:root:[  136] Training loss: 0.61619504, Validation loss: 0.62483471, Gradient norm: 0.17313179
INFO:root:At the start of the epoch: mem (CPU python)=34491.30859375MB; mem (CPU total)=34266.3046875MB
INFO:root:[  137] Training loss: 0.61576331, Validation loss: 0.62455797, Gradient norm: 0.17854676
INFO:root:At the start of the epoch: mem (CPU python)=34529.41015625MB; mem (CPU total)=34304.2265625MB
INFO:root:[  138] Training loss: 0.61537337, Validation loss: 0.62369857, Gradient norm: 0.18584632
INFO:root:At the start of the epoch: mem (CPU python)=34567.50390625MB; mem (CPU total)=34342.04296875MB
INFO:root:[  139] Training loss: 0.61577803, Validation loss: 0.62474300, Gradient norm: 0.18077306
INFO:root:At the start of the epoch: mem (CPU python)=34605.6015625MB; mem (CPU total)=34380.7578125MB
INFO:root:[  140] Training loss: 0.61564208, Validation loss: 0.62417745, Gradient norm: 0.18787243
INFO:root:At the start of the epoch: mem (CPU python)=34643.6953125MB; mem (CPU total)=34421.3828125MB
INFO:root:[  141] Training loss: 0.61553562, Validation loss: 0.62340496, Gradient norm: 0.17768249
INFO:root:At the start of the epoch: mem (CPU python)=34681.79296875MB; mem (CPU total)=34459.59765625MB
INFO:root:[  142] Training loss: 0.61506403, Validation loss: 0.62490387, Gradient norm: 0.19196861
INFO:root:At the start of the epoch: mem (CPU python)=34719.88671875MB; mem (CPU total)=34496.60546875MB
INFO:root:[  143] Training loss: 0.61526131, Validation loss: 0.62509956, Gradient norm: 0.17922319
INFO:root:At the start of the epoch: mem (CPU python)=34757.98046875MB; mem (CPU total)=34534.47265625MB
INFO:root:EP 143: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=34796.06640625MB; mem (CPU total)=34571.98828125MB
INFO:root:Training the model took 10377.924s.
INFO:root:Emptying the cuda cache took 0.05s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87355
INFO:root:EnergyScoreTrain: 0.61567
INFO:root:CRPSTrain: 0.55634
INFO:root:Gaussian NLLTrain: 3.14539
INFO:root:CoverageTrain: 0.74328
INFO:root:IntervalWidthTrain: 3.09289
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88584
INFO:root:EnergyScoreValidation: 0.62419
INFO:root:CRPSValidation: 0.56301
INFO:root:Gaussian NLLValidation: 3.15277
INFO:root:CoverageValidation: 0.74088
INFO:root:IntervalWidthValidation: 3.09376
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88769
INFO:root:EnergyScoreTest: 0.62551
INFO:root:CRPSTest: 0.56432
INFO:root:Gaussian NLLTest: 3.17703
INFO:root:CoverageTest: 0.73915
INFO:root:IntervalWidthTest: 3.08736
INFO:root:After validation: mem (CPU python)=34839.078125MB; mem (CPU total)=34615.421875MB
INFO:root:###5 out of 5 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': 0.1, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=34839.078125MB; mem (CPU total)=34615.43359375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=34839.21875MB; mem (CPU total)=34615.92578125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=34839.46484375MB; mem (CPU total)=34615.8984375MB
INFO:root:[    1] Training loss: 0.76448346, Validation loss: 0.72526368, Gradient norm: 1.17671923
INFO:root:At the start of the epoch: mem (CPU python)=34877.46484375MB; mem (CPU total)=34653.59375MB
INFO:root:[    2] Training loss: 0.72263933, Validation loss: 0.72177736, Gradient norm: 0.98568570
INFO:root:At the start of the epoch: mem (CPU python)=34915.55859375MB; mem (CPU total)=34691.7421875MB
INFO:root:[    3] Training loss: 0.72057219, Validation loss: 0.72084432, Gradient norm: 0.42962673
INFO:root:At the start of the epoch: mem (CPU python)=34953.66796875MB; mem (CPU total)=34729.859375MB
INFO:root:[    4] Training loss: 0.72028190, Validation loss: 0.72048428, Gradient norm: 0.46613081
INFO:root:At the start of the epoch: mem (CPU python)=34991.77734375MB; mem (CPU total)=34767.5546875MB
INFO:root:[    5] Training loss: 0.71963987, Validation loss: 0.71969563, Gradient norm: 0.46321149
INFO:root:At the start of the epoch: mem (CPU python)=35029.89453125MB; mem (CPU total)=34806.66796875MB
INFO:root:[    6] Training loss: 0.71890214, Validation loss: 0.71870518, Gradient norm: 0.32081541
INFO:root:At the start of the epoch: mem (CPU python)=35068.00390625MB; mem (CPU total)=34844.5MB
INFO:root:[    7] Training loss: 0.71850638, Validation loss: 0.71833055, Gradient norm: 0.30358654
INFO:root:At the start of the epoch: mem (CPU python)=35106.11328125MB; mem (CPU total)=34882.86328125MB
INFO:root:[    8] Training loss: 0.71708235, Validation loss: 0.71561033, Gradient norm: 0.28505737
INFO:root:At the start of the epoch: mem (CPU python)=35144.2109375MB; mem (CPU total)=34921.19921875MB
INFO:root:[    9] Training loss: 0.71210770, Validation loss: 0.70885884, Gradient norm: 0.38198087
INFO:root:At the start of the epoch: mem (CPU python)=35182.3046875MB; mem (CPU total)=34959.08984375MB
INFO:root:[   10] Training loss: 0.70639177, Validation loss: 0.70373909, Gradient norm: 0.26892943
INFO:root:At the start of the epoch: mem (CPU python)=35220.3984375MB; mem (CPU total)=34997.421875MB
INFO:root:[   11] Training loss: 0.70178739, Validation loss: 0.70031448, Gradient norm: 0.31293798
INFO:root:At the start of the epoch: mem (CPU python)=35258.49609375MB; mem (CPU total)=35035.54296875MB
INFO:root:[   12] Training loss: 0.69746551, Validation loss: 0.69594214, Gradient norm: 0.18866449
INFO:root:At the start of the epoch: mem (CPU python)=35296.58984375MB; mem (CPU total)=35073.421875MB
INFO:root:[   13] Training loss: 0.69266659, Validation loss: 0.69070884, Gradient norm: 0.23452655
INFO:root:At the start of the epoch: mem (CPU python)=35334.6875MB; mem (CPU total)=35111.6875MB
INFO:root:[   14] Training loss: 0.68817852, Validation loss: 0.68767614, Gradient norm: 0.19537154
INFO:root:At the start of the epoch: mem (CPU python)=35372.78515625MB; mem (CPU total)=35149.8203125MB
INFO:root:[   15] Training loss: 0.68432136, Validation loss: 0.68394354, Gradient norm: 0.17003056
INFO:root:At the start of the epoch: mem (CPU python)=35410.8828125MB; mem (CPU total)=35188.21484375MB
INFO:root:[   16] Training loss: 0.68070659, Validation loss: 0.68104453, Gradient norm: 0.17116700
INFO:root:At the start of the epoch: mem (CPU python)=35448.9765625MB; mem (CPU total)=35226.0703125MB
INFO:root:[   17] Training loss: 0.67741678, Validation loss: 0.67801053, Gradient norm: 0.24772061
INFO:root:At the start of the epoch: mem (CPU python)=35487.0703125MB; mem (CPU total)=35263.96875MB
INFO:root:[   18] Training loss: 0.67470286, Validation loss: 0.67544862, Gradient norm: 0.21377541
INFO:root:At the start of the epoch: mem (CPU python)=35525.16796875MB; mem (CPU total)=35302.1015625MB
INFO:root:[   19] Training loss: 0.67222683, Validation loss: 0.67249858, Gradient norm: 0.23050062
INFO:root:At the start of the epoch: mem (CPU python)=35563.265625MB; mem (CPU total)=35340.9453125MB
INFO:root:[   20] Training loss: 0.66969178, Validation loss: 0.67065399, Gradient norm: 0.17174249
INFO:root:At the start of the epoch: mem (CPU python)=35601.359375MB; mem (CPU total)=35378.80078125MB
INFO:root:[   21] Training loss: 0.66742344, Validation loss: 0.66896051, Gradient norm: 0.14260943
INFO:root:At the start of the epoch: mem (CPU python)=35639.453125MB; mem (CPU total)=35418.15234375MB
INFO:root:[   22] Training loss: 0.66537236, Validation loss: 0.66681120, Gradient norm: 0.15344120
INFO:root:At the start of the epoch: mem (CPU python)=35677.5625MB; mem (CPU total)=35456.0546875MB
INFO:root:[   23] Training loss: 0.66367652, Validation loss: 0.66391433, Gradient norm: 0.16533824
INFO:root:At the start of the epoch: mem (CPU python)=35715.66015625MB; mem (CPU total)=35494.41796875MB
INFO:root:[   24] Training loss: 0.66203217, Validation loss: 0.66124618, Gradient norm: 0.15370794
INFO:root:At the start of the epoch: mem (CPU python)=35753.75390625MB; mem (CPU total)=35532.70703125MB
INFO:root:[   25] Training loss: 0.66043400, Validation loss: 0.66109535, Gradient norm: 0.18067198
INFO:root:At the start of the epoch: mem (CPU python)=35791.8515625MB; mem (CPU total)=35570.84375MB
INFO:root:[   26] Training loss: 0.65910147, Validation loss: 0.65986940, Gradient norm: 0.15236870
INFO:root:At the start of the epoch: mem (CPU python)=35829.9453125MB; mem (CPU total)=35608.88671875MB
INFO:root:[   27] Training loss: 0.65751876, Validation loss: 0.65920519, Gradient norm: 0.21657623
INFO:root:At the start of the epoch: mem (CPU python)=35868.0390625MB; mem (CPU total)=35647.02734375MB
INFO:root:[   28] Training loss: 0.65622759, Validation loss: 0.65681429, Gradient norm: 0.19981235
INFO:root:At the start of the epoch: mem (CPU python)=35906.140625MB; mem (CPU total)=35685.421875MB
INFO:root:[   29] Training loss: 0.65486739, Validation loss: 0.65717950, Gradient norm: 0.14301410
INFO:root:At the start of the epoch: mem (CPU python)=35944.234375MB; mem (CPU total)=35723.5625MB
INFO:root:[   30] Training loss: 0.65387315, Validation loss: 0.65556169, Gradient norm: 0.18391979
INFO:root:At the start of the epoch: mem (CPU python)=35982.328125MB; mem (CPU total)=35761.44140625MB
INFO:root:[   31] Training loss: 0.65284606, Validation loss: 0.65509638, Gradient norm: 0.14439386
INFO:root:At the start of the epoch: mem (CPU python)=36020.421875MB; mem (CPU total)=35799.5MB
INFO:root:[   32] Training loss: 0.65170402, Validation loss: 0.65433817, Gradient norm: 0.16485478
INFO:root:At the start of the epoch: mem (CPU python)=36058.51953125MB; mem (CPU total)=35837.6328125MB
INFO:root:[   33] Training loss: 0.65089741, Validation loss: 0.65323287, Gradient norm: 0.17048929
INFO:root:At the start of the epoch: mem (CPU python)=36096.61328125MB; mem (CPU total)=35876.23828125MB
INFO:root:[   34] Training loss: 0.64996274, Validation loss: 0.65204234, Gradient norm: 0.15773386
INFO:root:At the start of the epoch: mem (CPU python)=36134.70703125MB; mem (CPU total)=35914.33203125MB
INFO:root:[   35] Training loss: 0.64871034, Validation loss: 0.65122136, Gradient norm: 0.18489404
INFO:root:At the start of the epoch: mem (CPU python)=36172.8046875MB; mem (CPU total)=35952.94140625MB
INFO:root:[   36] Training loss: 0.64792097, Validation loss: 0.65043936, Gradient norm: 0.17063062
INFO:root:At the start of the epoch: mem (CPU python)=36210.90234375MB; mem (CPU total)=35989.80078125MB
INFO:root:[   37] Training loss: 0.64706901, Validation loss: 0.64911242, Gradient norm: 0.16693619
INFO:root:At the start of the epoch: mem (CPU python)=36248.99609375MB; mem (CPU total)=36027.5390625MB
INFO:root:[   38] Training loss: 0.64617340, Validation loss: 0.64822251, Gradient norm: 0.19054883
INFO:root:At the start of the epoch: mem (CPU python)=36287.08984375MB; mem (CPU total)=36065.65234375MB
INFO:root:[   39] Training loss: 0.64554419, Validation loss: 0.64868921, Gradient norm: 0.15519662
INFO:root:At the start of the epoch: mem (CPU python)=36325.1875MB; mem (CPU total)=36103.9375MB
INFO:root:[   40] Training loss: 0.64458927, Validation loss: 0.64689501, Gradient norm: 0.21343098
INFO:root:At the start of the epoch: mem (CPU python)=36363.28125MB; mem (CPU total)=36141.8125MB
INFO:root:[   41] Training loss: 0.64383975, Validation loss: 0.64711397, Gradient norm: 0.17124412
INFO:root:At the start of the epoch: mem (CPU python)=36401.375MB; mem (CPU total)=36179.88671875MB
INFO:root:[   42] Training loss: 0.64305464, Validation loss: 0.64612742, Gradient norm: 0.16864072
INFO:root:At the start of the epoch: mem (CPU python)=36439.47265625MB; mem (CPU total)=36217.72265625MB
INFO:root:[   43] Training loss: 0.64230522, Validation loss: 0.64528444, Gradient norm: 0.17810675
INFO:root:At the start of the epoch: mem (CPU python)=36477.56640625MB; mem (CPU total)=36256.140625MB
INFO:root:[   44] Training loss: 0.64175803, Validation loss: 0.64478544, Gradient norm: 0.17202400
INFO:root:At the start of the epoch: mem (CPU python)=36515.6640625MB; mem (CPU total)=36294.22265625MB
INFO:root:[   45] Training loss: 0.64091932, Validation loss: 0.64476081, Gradient norm: 0.18287370
INFO:root:At the start of the epoch: mem (CPU python)=36553.76171875MB; mem (CPU total)=36332.33203125MB
INFO:root:[   46] Training loss: 0.64006965, Validation loss: 0.64436822, Gradient norm: 0.20165063
INFO:root:At the start of the epoch: mem (CPU python)=36591.85546875MB; mem (CPU total)=36370.67578125MB
INFO:root:[   47] Training loss: 0.63979500, Validation loss: 0.64279055, Gradient norm: 0.14152954
INFO:root:At the start of the epoch: mem (CPU python)=36629.94921875MB; mem (CPU total)=36408.51171875MB
INFO:root:[   48] Training loss: 0.63890949, Validation loss: 0.64216264, Gradient norm: 0.17068200
INFO:root:At the start of the epoch: mem (CPU python)=36668.04296875MB; mem (CPU total)=36446.671875MB
INFO:root:[   49] Training loss: 0.63822126, Validation loss: 0.64271740, Gradient norm: 0.18998308
INFO:root:At the start of the epoch: mem (CPU python)=36706.140625MB; mem (CPU total)=36484.82421875MB
INFO:root:[   50] Training loss: 0.63767210, Validation loss: 0.64236994, Gradient norm: 0.16610568
INFO:root:At the start of the epoch: mem (CPU python)=36744.234375MB; mem (CPU total)=36523.08984375MB
INFO:root:[   51] Training loss: 0.63740105, Validation loss: 0.64149505, Gradient norm: 0.23406073
INFO:root:At the start of the epoch: mem (CPU python)=36782.33203125MB; mem (CPU total)=36561.44140625MB
INFO:root:[   52] Training loss: 0.63635596, Validation loss: 0.64011317, Gradient norm: 0.19646399
INFO:root:At the start of the epoch: mem (CPU python)=36820.4296875MB; mem (CPU total)=36599.8359375MB
INFO:root:[   53] Training loss: 0.63575858, Validation loss: 0.64010628, Gradient norm: 0.18648861
INFO:root:At the start of the epoch: mem (CPU python)=36858.5234375MB; mem (CPU total)=36639.015625MB
INFO:root:[   54] Training loss: 0.63511324, Validation loss: 0.63934609, Gradient norm: 0.19012501
INFO:root:At the start of the epoch: mem (CPU python)=36896.6171875MB; mem (CPU total)=36676.92578125MB
INFO:root:[   55] Training loss: 0.63466930, Validation loss: 0.63882315, Gradient norm: 0.17696429
INFO:root:At the start of the epoch: mem (CPU python)=36934.7109375MB; mem (CPU total)=36715.296875MB
INFO:root:[   56] Training loss: 0.63408555, Validation loss: 0.63856370, Gradient norm: 0.17125502
INFO:root:At the start of the epoch: mem (CPU python)=36972.80859375MB; mem (CPU total)=36753.17578125MB
INFO:root:[   57] Training loss: 0.63380436, Validation loss: 0.63769300, Gradient norm: 0.15844563
INFO:root:At the start of the epoch: mem (CPU python)=37013.40234375MB; mem (CPU total)=36794.0MB
INFO:root:[   58] Training loss: 0.63294545, Validation loss: 0.63632717, Gradient norm: 0.15610124
INFO:root:At the start of the epoch: mem (CPU python)=37051.49609375MB; mem (CPU total)=36831.90234375MB
INFO:root:[   59] Training loss: 0.63250615, Validation loss: 0.63844320, Gradient norm: 0.19274375
INFO:root:At the start of the epoch: mem (CPU python)=37089.59765625MB; mem (CPU total)=36869.796875MB
INFO:root:[   60] Training loss: 0.63241577, Validation loss: 0.63689569, Gradient norm: 0.18218726
INFO:root:At the start of the epoch: mem (CPU python)=37127.69140625MB; mem (CPU total)=36908.19140625MB
INFO:root:[   61] Training loss: 0.63163972, Validation loss: 0.63661676, Gradient norm: 0.19056279
INFO:root:At the start of the epoch: mem (CPU python)=37165.78515625MB; mem (CPU total)=36946.3125MB
INFO:root:[   62] Training loss: 0.63082653, Validation loss: 0.63660288, Gradient norm: 0.16159003
INFO:root:At the start of the epoch: mem (CPU python)=37203.8828125MB; mem (CPU total)=36984.3125MB
INFO:root:[   63] Training loss: 0.63055223, Validation loss: 0.63614371, Gradient norm: 0.20374627
INFO:root:At the start of the epoch: mem (CPU python)=37241.9765625MB; mem (CPU total)=37022.71875MB
INFO:root:[   64] Training loss: 0.62976996, Validation loss: 0.63572994, Gradient norm: 0.21340002
INFO:root:At the start of the epoch: mem (CPU python)=37280.0703125MB; mem (CPU total)=37060.44921875MB
INFO:root:[   65] Training loss: 0.62960702, Validation loss: 0.63491685, Gradient norm: 0.19621705
INFO:root:At the start of the epoch: mem (CPU python)=37318.1640625MB; mem (CPU total)=37099.0390625MB
INFO:root:[   66] Training loss: 0.62918324, Validation loss: 0.63414196, Gradient norm: 0.18327471
INFO:root:At the start of the epoch: mem (CPU python)=37356.26171875MB; mem (CPU total)=37137.35546875MB
INFO:root:[   67] Training loss: 0.62885117, Validation loss: 0.63334353, Gradient norm: 0.19340731
INFO:root:At the start of the epoch: mem (CPU python)=37394.35546875MB; mem (CPU total)=37175.54296875MB
INFO:root:[   68] Training loss: 0.62830693, Validation loss: 0.63366035, Gradient norm: 0.17336673
INFO:root:At the start of the epoch: mem (CPU python)=37432.44921875MB; mem (CPU total)=37213.6015625MB
INFO:root:[   69] Training loss: 0.62786976, Validation loss: 0.63502131, Gradient norm: 0.23943615
INFO:root:At the start of the epoch: mem (CPU python)=37470.55078125MB; mem (CPU total)=37251.8671875MB
INFO:root:[   70] Training loss: 0.62748629, Validation loss: 0.63245168, Gradient norm: 0.21047226
INFO:root:At the start of the epoch: mem (CPU python)=37508.64453125MB; mem (CPU total)=37289.890625MB
INFO:root:[   71] Training loss: 0.62703967, Validation loss: 0.63280540, Gradient norm: 0.20104274
INFO:root:At the start of the epoch: mem (CPU python)=37546.73828125MB; mem (CPU total)=37328.0MB
INFO:root:[   72] Training loss: 0.62647079, Validation loss: 0.63259517, Gradient norm: 0.20749360
INFO:root:At the start of the epoch: mem (CPU python)=37584.83203125MB; mem (CPU total)=37366.14453125MB
INFO:root:[   73] Training loss: 0.62610731, Validation loss: 0.63111334, Gradient norm: 0.16903276
INFO:root:At the start of the epoch: mem (CPU python)=37622.9296875MB; mem (CPU total)=37404.58984375MB
INFO:root:[   74] Training loss: 0.62595785, Validation loss: 0.63168056, Gradient norm: 0.18769949
INFO:root:At the start of the epoch: mem (CPU python)=37661.0234375MB; mem (CPU total)=37442.6953125MB
INFO:root:[   75] Training loss: 0.62525181, Validation loss: 0.63126560, Gradient norm: 0.21211870
INFO:root:At the start of the epoch: mem (CPU python)=37699.1171875MB; mem (CPU total)=37480.859375MB
INFO:root:[   76] Training loss: 0.62489262, Validation loss: 0.63161751, Gradient norm: 0.19501246
INFO:root:At the start of the epoch: mem (CPU python)=37737.21875MB; mem (CPU total)=37519.03125MB
INFO:root:[   77] Training loss: 0.62475984, Validation loss: 0.63156169, Gradient norm: 0.25539696
INFO:root:At the start of the epoch: mem (CPU python)=37775.3125MB; mem (CPU total)=37556.92578125MB
INFO:root:[   78] Training loss: 0.62408564, Validation loss: 0.63057116, Gradient norm: 0.18452611
INFO:root:At the start of the epoch: mem (CPU python)=37813.40625MB; mem (CPU total)=37595.59375MB
INFO:root:[   79] Training loss: 0.62349840, Validation loss: 0.63067032, Gradient norm: 0.19699920
INFO:root:At the start of the epoch: mem (CPU python)=37851.50390625MB; mem (CPU total)=37633.515625MB
INFO:root:[   80] Training loss: 0.62355060, Validation loss: 0.63055532, Gradient norm: 0.22882547
INFO:root:At the start of the epoch: mem (CPU python)=37889.59765625MB; mem (CPU total)=37672.4609375MB
INFO:root:[   81] Training loss: 0.62304851, Validation loss: 0.63012669, Gradient norm: 0.20733511
INFO:root:At the start of the epoch: mem (CPU python)=37927.69140625MB; mem (CPU total)=37710.25MB
INFO:root:[   82] Training loss: 0.62247189, Validation loss: 0.62984018, Gradient norm: 0.22621403
INFO:root:At the start of the epoch: mem (CPU python)=37965.78515625MB; mem (CPU total)=37748.14453125MB
INFO:root:[   83] Training loss: 0.62214924, Validation loss: 0.62994172, Gradient norm: 0.23867072
INFO:root:At the start of the epoch: mem (CPU python)=38003.88671875MB; mem (CPU total)=37786.5546875MB
INFO:root:[   84] Training loss: 0.62184470, Validation loss: 0.62881639, Gradient norm: 0.20134732
INFO:root:At the start of the epoch: mem (CPU python)=38041.9765625MB; mem (CPU total)=37824.4140625MB
INFO:root:[   85] Training loss: 0.62165788, Validation loss: 0.62794221, Gradient norm: 0.17959047
INFO:root:At the start of the epoch: mem (CPU python)=38080.07421875MB; mem (CPU total)=37862.37109375MB
INFO:root:[   86] Training loss: 0.62136063, Validation loss: 0.62917793, Gradient norm: 0.21759852
INFO:root:At the start of the epoch: mem (CPU python)=38118.171875MB; mem (CPU total)=37900.734375MB
INFO:root:[   87] Training loss: 0.62139079, Validation loss: 0.62777230, Gradient norm: 0.24499722
INFO:root:At the start of the epoch: mem (CPU python)=38156.265625MB; mem (CPU total)=37939.08203125MB
INFO:root:[   88] Training loss: 0.62059629, Validation loss: 0.62905445, Gradient norm: 0.23524735
INFO:root:At the start of the epoch: mem (CPU python)=38194.359375MB; mem (CPU total)=37977.7890625MB
INFO:root:[   89] Training loss: 0.62041100, Validation loss: 0.62680612, Gradient norm: 0.26809210
INFO:root:At the start of the epoch: mem (CPU python)=38232.453125MB; mem (CPU total)=38015.5MB
INFO:root:[   90] Training loss: 0.62007360, Validation loss: 0.62781272, Gradient norm: 0.21422551
INFO:root:At the start of the epoch: mem (CPU python)=38270.55078125MB; mem (CPU total)=38053.65234375MB
INFO:root:[   91] Training loss: 0.61960517, Validation loss: 0.62729628, Gradient norm: 0.21206720
INFO:root:At the start of the epoch: mem (CPU python)=38308.64453125MB; mem (CPU total)=38092.0078125MB
INFO:root:[   92] Training loss: 0.61984112, Validation loss: 0.62742598, Gradient norm: 0.21564786
INFO:root:At the start of the epoch: mem (CPU python)=38346.73828125MB; mem (CPU total)=38130.14453125MB
INFO:root:[   93] Training loss: 0.61877446, Validation loss: 0.62783614, Gradient norm: 0.20910734
INFO:root:At the start of the epoch: mem (CPU python)=38384.83984375MB; mem (CPU total)=38168.18359375MB
INFO:root:[   94] Training loss: 0.61923024, Validation loss: 0.62683167, Gradient norm: 0.21696307
INFO:root:At the start of the epoch: mem (CPU python)=38422.93359375MB; mem (CPU total)=38204.61328125MB
INFO:root:[   95] Training loss: 0.61843509, Validation loss: 0.62764361, Gradient norm: 0.21626844
INFO:root:At the start of the epoch: mem (CPU python)=38461.02734375MB; mem (CPU total)=38243.234375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   96] Training loss: 0.61828314, Validation loss: 0.62662223, Gradient norm: 0.25952383
INFO:root:At the start of the epoch: mem (CPU python)=38499.125MB; mem (CPU total)=38281.58984375MB
INFO:root:[   97] Training loss: 0.61697784, Validation loss: 0.62637795, Gradient norm: 0.16201694
INFO:root:At the start of the epoch: mem (CPU python)=38537.21875MB; mem (CPU total)=38319.5234375MB
INFO:root:[   98] Training loss: 0.61640412, Validation loss: 0.62599378, Gradient norm: 0.15926699
INFO:root:At the start of the epoch: mem (CPU python)=38575.3125MB; mem (CPU total)=38357.921875MB
INFO:root:[   99] Training loss: 0.61634347, Validation loss: 0.62587292, Gradient norm: 0.17914610
INFO:root:At the start of the epoch: mem (CPU python)=38613.40625MB; mem (CPU total)=38395.7578125MB
INFO:root:[  100] Training loss: 0.61598466, Validation loss: 0.62540700, Gradient norm: 0.16831922
INFO:root:At the start of the epoch: mem (CPU python)=38651.50390625MB; mem (CPU total)=38434.1171875MB
INFO:root:[  101] Training loss: 0.61580665, Validation loss: 0.62567825, Gradient norm: 0.17470779
INFO:root:At the start of the epoch: mem (CPU python)=38689.59765625MB; mem (CPU total)=38472.2109375MB
INFO:root:[  102] Training loss: 0.61576398, Validation loss: 0.62649974, Gradient norm: 0.18027329
INFO:root:At the start of the epoch: mem (CPU python)=38727.6953125MB; mem (CPU total)=38510.5625MB
INFO:root:[  103] Training loss: 0.61595312, Validation loss: 0.62518218, Gradient norm: 0.21873527
INFO:root:At the start of the epoch: mem (CPU python)=38765.79296875MB; mem (CPU total)=38549.4453125MB
INFO:root:[  104] Training loss: 0.61495960, Validation loss: 0.62476915, Gradient norm: 0.18127448
INFO:root:At the start of the epoch: mem (CPU python)=38803.88671875MB; mem (CPU total)=38587.40234375MB
INFO:root:[  105] Training loss: 0.61545189, Validation loss: 0.62438492, Gradient norm: 0.19202186
INFO:root:At the start of the epoch: mem (CPU python)=38841.98046875MB; mem (CPU total)=38625.515625MB
INFO:root:[  106] Training loss: 0.61486897, Validation loss: 0.62440806, Gradient norm: 0.16919557
INFO:root:At the start of the epoch: mem (CPU python)=38880.07421875MB; mem (CPU total)=38663.84765625MB
INFO:root:[  107] Training loss: 0.61486967, Validation loss: 0.62506784, Gradient norm: 0.16149451
INFO:root:At the start of the epoch: mem (CPU python)=38918.171875MB; mem (CPU total)=38702.1328125MB
INFO:root:[  108] Training loss: 0.61476576, Validation loss: 0.62410824, Gradient norm: 0.19350131
INFO:root:At the start of the epoch: mem (CPU python)=38956.26953125MB; mem (CPU total)=38740.54296875MB
INFO:root:[  109] Training loss: 0.61454792, Validation loss: 0.62490720, Gradient norm: 0.16943517
INFO:root:At the start of the epoch: mem (CPU python)=38994.36328125MB; mem (CPU total)=38778.41015625MB
INFO:root:[  110] Training loss: 0.61461881, Validation loss: 0.62411157, Gradient norm: 0.19037411
INFO:root:At the start of the epoch: mem (CPU python)=39032.4609375MB; mem (CPU total)=38816.98046875MB
INFO:root:[  111] Training loss: 0.61461998, Validation loss: 0.62464031, Gradient norm: 0.18695967
INFO:root:At the start of the epoch: mem (CPU python)=39070.5546875MB; mem (CPU total)=38854.6328125MB
INFO:root:[  112] Training loss: 0.61417440, Validation loss: 0.62415724, Gradient norm: 0.18992204
INFO:root:At the start of the epoch: mem (CPU python)=39108.6484375MB; mem (CPU total)=38892.9609375MB
INFO:root:[  113] Training loss: 0.61447477, Validation loss: 0.62459723, Gradient norm: 0.22144950
INFO:root:At the start of the epoch: mem (CPU python)=39146.74609375MB; mem (CPU total)=38931.10546875MB
INFO:root:[  114] Training loss: 0.61407881, Validation loss: 0.62445959, Gradient norm: 0.17849598
INFO:root:At the start of the epoch: mem (CPU python)=39184.83984375MB; mem (CPU total)=38969.00390625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  115] Training loss: 0.61393013, Validation loss: 0.62446491, Gradient norm: 0.18154331
INFO:root:At the start of the epoch: mem (CPU python)=39222.93359375MB; mem (CPU total)=39007.39453125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  116] Training loss: 0.61312819, Validation loss: 0.62394077, Gradient norm: 0.14939270
INFO:root:At the start of the epoch: mem (CPU python)=39261.02734375MB; mem (CPU total)=39046.03125MB
INFO:root:[  117] Training loss: 0.61288395, Validation loss: 0.62452386, Gradient norm: 0.12536249
INFO:root:At the start of the epoch: mem (CPU python)=39299.125MB; mem (CPU total)=39084.453125MB
INFO:root:[  118] Training loss: 0.61300403, Validation loss: 0.62295516, Gradient norm: 0.13615883
INFO:root:At the start of the epoch: mem (CPU python)=39337.22265625MB; mem (CPU total)=39122.6484375MB
INFO:root:[  119] Training loss: 0.61267964, Validation loss: 0.62340280, Gradient norm: 0.13115621
INFO:root:At the start of the epoch: mem (CPU python)=39375.3125MB; mem (CPU total)=39160.48828125MB
INFO:root:[  120] Training loss: 0.61252971, Validation loss: 0.62416505, Gradient norm: 0.13018399
INFO:root:At the start of the epoch: mem (CPU python)=39413.4140625MB; mem (CPU total)=39198.6640625MB
INFO:root:[  121] Training loss: 0.61272598, Validation loss: 0.62307597, Gradient norm: 0.14459121
INFO:root:At the start of the epoch: mem (CPU python)=39451.5078125MB; mem (CPU total)=39237.015625MB
INFO:root:[  122] Training loss: 0.61252167, Validation loss: 0.62300002, Gradient norm: 0.13663364
INFO:root:At the start of the epoch: mem (CPU python)=39489.6015625MB; mem (CPU total)=39275.03125MB
INFO:root:[  123] Training loss: 0.61276707, Validation loss: 0.62380281, Gradient norm: 0.12704859
INFO:root:At the start of the epoch: mem (CPU python)=39527.6953125MB; mem (CPU total)=39313.109375MB
INFO:root:[  124] Training loss: 0.61254044, Validation loss: 0.62313014, Gradient norm: 0.14945527
INFO:root:At the start of the epoch: mem (CPU python)=39565.79296875MB; mem (CPU total)=39351.43359375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  125] Training loss: 0.61200886, Validation loss: 0.62372944, Gradient norm: 0.13722795
INFO:root:At the start of the epoch: mem (CPU python)=39603.890625MB; mem (CPU total)=39389.5625MB
INFO:root:[  126] Training loss: 0.61194880, Validation loss: 0.62266820, Gradient norm: 0.12264982
INFO:root:At the start of the epoch: mem (CPU python)=39641.984375MB; mem (CPU total)=39427.671875MB
INFO:root:[  127] Training loss: 0.61213345, Validation loss: 0.62291772, Gradient norm: 0.11962179
INFO:root:At the start of the epoch: mem (CPU python)=39680.08203125MB; mem (CPU total)=39466.0390625MB
INFO:root:[  128] Training loss: 0.61210809, Validation loss: 0.62444807, Gradient norm: 0.12044590
INFO:root:At the start of the epoch: mem (CPU python)=39718.17578125MB; mem (CPU total)=39504.1484375MB
INFO:root:[  129] Training loss: 0.61210630, Validation loss: 0.62352224, Gradient norm: 0.11796460
INFO:root:At the start of the epoch: mem (CPU python)=39756.26953125MB; mem (CPU total)=39541.734375MB
INFO:root:[  130] Training loss: 0.61225411, Validation loss: 0.62311926, Gradient norm: 0.12000570
INFO:root:At the start of the epoch: mem (CPU python)=39794.3671875MB; mem (CPU total)=39580.29296875MB
INFO:root:[  131] Training loss: 0.61211637, Validation loss: 0.62294788, Gradient norm: 0.12717351
INFO:root:At the start of the epoch: mem (CPU python)=39832.4609375MB; mem (CPU total)=39618.63671875MB
INFO:root:[  132] Training loss: 0.61210563, Validation loss: 0.62339929, Gradient norm: 0.12437202
INFO:root:At the start of the epoch: mem (CPU python)=39870.5546875MB; mem (CPU total)=39656.52734375MB
INFO:root:[  133] Training loss: 0.61194541, Validation loss: 0.62312988, Gradient norm: 0.12841488
INFO:root:At the start of the epoch: mem (CPU python)=39908.6484375MB; mem (CPU total)=39694.64453125MB
INFO:root:[  134] Training loss: 0.61195508, Validation loss: 0.62283437, Gradient norm: 0.13451488
INFO:root:At the start of the epoch: mem (CPU python)=39946.75MB; mem (CPU total)=39732.7421875MB
INFO:root:[  135] Training loss: 0.61178350, Validation loss: 0.62403615, Gradient norm: 0.12071329
INFO:root:At the start of the epoch: mem (CPU python)=39984.84375MB; mem (CPU total)=39771.06640625MB
INFO:root:EP 135: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=40022.90625MB; mem (CPU total)=39808.93359375MB
INFO:root:Training the model took 10820.562s.
INFO:root:Emptying the cuda cache took 0.048s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86885
INFO:root:EnergyScoreTrain: 0.61195
INFO:root:CRPSTrain: 0.55347
INFO:root:Gaussian NLLTrain: 3.38836
INFO:root:CoverageTrain: 0.74128
INFO:root:IntervalWidthTrain: 2.99944
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88491
INFO:root:EnergyScoreValidation: 0.62322
INFO:root:CRPSValidation: 0.56263
INFO:root:Gaussian NLLValidation: 3.41487
INFO:root:CoverageValidation: 0.73654
INFO:root:IntervalWidthValidation: 2.99676
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8869
INFO:root:EnergyScoreTest: 0.62466
INFO:root:CRPSTest: 0.56395
INFO:root:Gaussian NLLTest: 3.42211
INFO:root:CoverageTest: 0.73523
INFO:root:IntervalWidthTest: 2.99044
INFO:root:After validation: mem (CPU python)=40065.90625MB; mem (CPU total)=39852.69921875MB
