INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=579.828125MB; mem (CPU total)=4649.703125MB
INFO:root:############### Starting experiment with config file sswe/sfno_sr_dropout_2_1.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=590.81640625MB; mem (CPU total)=4656.91796875MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=592.1796875MB; mem (CPU total)=4657.484375MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2241.078125MB; mem (CPU total)=6034.80859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2250.79296875MB; mem (CPU total)=6044.8671875MB
INFO:root:[    1] Training loss: 1.76076564, Validation loss: 1.67978289, Gradient norm: 0.17331650
INFO:root:At the start of the epoch: mem (CPU python)=4411.9765625MB; mem (CPU total)=7761.890625MB
INFO:root:[    2] Training loss: 1.72067981, Validation loss: 1.59500902, Gradient norm: 0.20692815
INFO:root:At the start of the epoch: mem (CPU python)=4433.828125MB; mem (CPU total)=7788.0078125MB
INFO:root:[    3] Training loss: 1.68488067, Validation loss: 1.56349430, Gradient norm: 0.31926985
INFO:root:At the start of the epoch: mem (CPU python)=4455.7109375MB; mem (CPU total)=7809.75MB
INFO:root:[    4] Training loss: 1.66923881, Validation loss: 1.55127971, Gradient norm: 0.48579875
INFO:root:At the start of the epoch: mem (CPU python)=4477.1953125MB; mem (CPU total)=7911.5859375MB
INFO:root:[    5] Training loss: 1.66168244, Validation loss: 1.54880628, Gradient norm: 0.66057734
INFO:root:At the start of the epoch: mem (CPU python)=4498.37890625MB; mem (CPU total)=7854.90625MB
INFO:root:[    6] Training loss: 1.65937003, Validation loss: 1.54405744, Gradient norm: 0.74127924
INFO:root:At the start of the epoch: mem (CPU python)=4519.5625MB; mem (CPU total)=7862.078125MB
INFO:root:[    7] Training loss: 1.65819769, Validation loss: 1.54446429, Gradient norm: 0.83474648
INFO:root:At the start of the epoch: mem (CPU python)=4540.7578125MB; mem (CPU total)=7888.12109375MB
INFO:root:[    8] Training loss: 1.65807528, Validation loss: 1.54163732, Gradient norm: 0.98063787
INFO:root:At the start of the epoch: mem (CPU python)=4562.43359375MB; mem (CPU total)=7909.55859375MB
INFO:root:[    9] Training loss: 1.65726343, Validation loss: 1.54524019, Gradient norm: 0.99164091
INFO:root:At the start of the epoch: mem (CPU python)=4584.625MB; mem (CPU total)=7973.17578125MB
INFO:root:[   10] Training loss: 1.65652316, Validation loss: 1.53996358, Gradient norm: 1.03068009
INFO:root:At the start of the epoch: mem (CPU python)=4605.80078125MB; mem (CPU total)=7943.96875MB
INFO:root:[   11] Training loss: 1.65428045, Validation loss: 1.52882891, Gradient norm: 1.05479661
INFO:root:At the start of the epoch: mem (CPU python)=4626.98828125MB; mem (CPU total)=7972.04296875MB
INFO:root:[   12] Training loss: 1.65394298, Validation loss: 1.53109018, Gradient norm: 1.17870196
INFO:root:At the start of the epoch: mem (CPU python)=4648.17578125MB; mem (CPU total)=8004.76171875MB
INFO:root:[   13] Training loss: 1.65248391, Validation loss: 1.53297362, Gradient norm: 1.19451107
INFO:root:At the start of the epoch: mem (CPU python)=4669.35546875MB; mem (CPU total)=8011.11328125MB
INFO:root:[   14] Training loss: 1.65157942, Validation loss: 1.53477032, Gradient norm: 1.24915268
INFO:root:At the start of the epoch: mem (CPU python)=4690.515625MB; mem (CPU total)=8043.3203125MB
INFO:root:[   15] Training loss: 1.65064467, Validation loss: 1.52556579, Gradient norm: 1.30916476
INFO:root:At the start of the epoch: mem (CPU python)=4711.6875MB; mem (CPU total)=8061.36328125MB
INFO:root:[   16] Training loss: 1.65091607, Validation loss: 1.53715344, Gradient norm: 1.37934236
INFO:root:At the start of the epoch: mem (CPU python)=4732.86328125MB; mem (CPU total)=8063.359375MB
INFO:root:[   17] Training loss: 1.64987809, Validation loss: 1.52192636, Gradient norm: 1.38956344
INFO:root:At the start of the epoch: mem (CPU python)=4754.03125MB; mem (CPU total)=8077.48828125MB
INFO:root:[   18] Training loss: 1.64874482, Validation loss: 1.52646966, Gradient norm: 1.43428010
INFO:root:At the start of the epoch: mem (CPU python)=4775.1953125MB; mem (CPU total)=8111.7890625MB
INFO:root:[   19] Training loss: 1.64900866, Validation loss: 1.52394153, Gradient norm: 1.48472971
INFO:root:At the start of the epoch: mem (CPU python)=4796.375MB; mem (CPU total)=8144.9375MB
INFO:root:[   20] Training loss: 1.64825221, Validation loss: 1.51974099, Gradient norm: 1.50685145
INFO:root:At the start of the epoch: mem (CPU python)=4817.55078125MB; mem (CPU total)=8136.80078125MB
INFO:root:[   21] Training loss: 1.64781681, Validation loss: 1.52041385, Gradient norm: 1.52523479
INFO:root:At the start of the epoch: mem (CPU python)=4838.71875MB; mem (CPU total)=8180.53515625MB
INFO:root:[   22] Training loss: 1.64774415, Validation loss: 1.52310931, Gradient norm: 1.59625472
INFO:root:At the start of the epoch: mem (CPU python)=4859.89453125MB; mem (CPU total)=8202.45703125MB
INFO:root:[   23] Training loss: 1.64656072, Validation loss: 1.52376317, Gradient norm: 1.62144048
INFO:root:At the start of the epoch: mem (CPU python)=4881.08984375MB; mem (CPU total)=8293.2734375MB
INFO:root:[   24] Training loss: 1.64710681, Validation loss: 1.52982742, Gradient norm: 1.68144027
INFO:root:At the start of the epoch: mem (CPU python)=4902.265625MB; mem (CPU total)=8231.53515625MB
INFO:root:[   25] Training loss: 1.64647705, Validation loss: 1.53110897, Gradient norm: 1.62923583
INFO:root:At the start of the epoch: mem (CPU python)=4923.44140625MB; mem (CPU total)=8243.453125MB
INFO:root:[   26] Training loss: 1.64624611, Validation loss: 1.53294234, Gradient norm: 1.69697444
INFO:root:At the start of the epoch: mem (CPU python)=4944.61328125MB; mem (CPU total)=8272.984375MB
INFO:root:[   27] Training loss: 1.65667928, Validation loss: 1.53113356, Gradient norm: 2.18385105
INFO:root:At the start of the epoch: mem (CPU python)=4965.8046875MB; mem (CPU total)=8283.546875MB
INFO:root:[   28] Training loss: 1.64809233, Validation loss: 1.52570842, Gradient norm: 1.90379846
INFO:root:At the start of the epoch: mem (CPU python)=4986.9765625MB; mem (CPU total)=8340.83984375MB
INFO:root:[   29] Training loss: 1.64574334, Validation loss: 1.51457091, Gradient norm: 1.82177639
INFO:root:At the start of the epoch: mem (CPU python)=5008.15625MB; mem (CPU total)=8345.26171875MB
INFO:root:[   30] Training loss: 1.64581146, Validation loss: 1.51809380, Gradient norm: 1.78012439
INFO:root:At the start of the epoch: mem (CPU python)=5029.3203125MB; mem (CPU total)=8370.51171875MB
INFO:root:[   31] Training loss: 1.64526889, Validation loss: 1.52456952, Gradient norm: 1.72695650
INFO:root:At the start of the epoch: mem (CPU python)=5050.48828125MB; mem (CPU total)=8379.984375MB
INFO:root:[   32] Training loss: 1.64439200, Validation loss: 1.51234278, Gradient norm: 1.79693770
INFO:root:At the start of the epoch: mem (CPU python)=5071.65234375MB; mem (CPU total)=8402.96875MB
INFO:root:[   33] Training loss: 1.64784668, Validation loss: 1.51652030, Gradient norm: 1.97908892
INFO:root:At the start of the epoch: mem (CPU python)=5092.8125MB; mem (CPU total)=8430.96484375MB
INFO:root:[   34] Training loss: 1.64437079, Validation loss: 1.52965597, Gradient norm: 1.79740925
INFO:root:At the start of the epoch: mem (CPU python)=5113.98828125MB; mem (CPU total)=8455.921875MB
INFO:root:[   35] Training loss: 1.64417338, Validation loss: 1.51772232, Gradient norm: 1.76874560
INFO:root:At the start of the epoch: mem (CPU python)=5135.1796875MB; mem (CPU total)=8480.01171875MB
INFO:root:[   36] Training loss: 1.64408110, Validation loss: 1.51497730, Gradient norm: 1.85536706
INFO:root:At the start of the epoch: mem (CPU python)=5156.5703125MB; mem (CPU total)=8514.82421875MB
INFO:root:[   37] Training loss: 1.64399586, Validation loss: 1.53001318, Gradient norm: 1.89939651
INFO:root:At the start of the epoch: mem (CPU python)=5178.32421875MB; mem (CPU total)=8571.31640625MB
INFO:root:[   38] Training loss: 1.64392063, Validation loss: 1.51834798, Gradient norm: 1.87095533
INFO:root:At the start of the epoch: mem (CPU python)=5199.8125MB; mem (CPU total)=8541.87109375MB
INFO:root:[   39] Training loss: 1.64375752, Validation loss: 1.53229785, Gradient norm: 1.92587067
INFO:root:At the start of the epoch: mem (CPU python)=5221.0546875MB; mem (CPU total)=8561.1015625MB
INFO:root:[   40] Training loss: 1.64372562, Validation loss: 1.51352944, Gradient norm: 1.88052080
INFO:root:At the start of the epoch: mem (CPU python)=5242.39453125MB; mem (CPU total)=8583.23828125MB
INFO:root:[   41] Training loss: 1.64334205, Validation loss: 1.52100006, Gradient norm: 1.88830874
INFO:root:At the start of the epoch: mem (CPU python)=5263.90625MB; mem (CPU total)=8573.58203125MB
INFO:root:[   42] Training loss: 1.64316229, Validation loss: 1.51634681, Gradient norm: 1.91796065
INFO:root:At the start of the epoch: mem (CPU python)=5285.06640625MB; mem (CPU total)=8616.20703125MB
INFO:root:[   43] Training loss: 1.64270146, Validation loss: 1.51858008, Gradient norm: 1.97062256
INFO:root:At the start of the epoch: mem (CPU python)=5306.23046875MB; mem (CPU total)=8630.60546875MB
INFO:root:[   44] Training loss: 1.64348194, Validation loss: 1.52492029, Gradient norm: 1.97660046
INFO:root:At the start of the epoch: mem (CPU python)=5327.39453125MB; mem (CPU total)=8669.0703125MB
INFO:root:[   45] Training loss: 1.79933608, Validation loss: 1.65589451, Gradient norm: 5.81481577
INFO:root:At the start of the epoch: mem (CPU python)=5348.55859375MB; mem (CPU total)=8702.4921875MB
INFO:root:[   46] Training loss: 1.69518131, Validation loss: 1.55403764, Gradient norm: 2.19784753
INFO:root:At the start of the epoch: mem (CPU python)=5369.7265625MB; mem (CPU total)=8715.27734375MB
INFO:root:[   47] Training loss: 1.68825422, Validation loss: 1.56024570, Gradient norm: 3.17088514
INFO:root:At the start of the epoch: mem (CPU python)=5390.890625MB; mem (CPU total)=8735.86328125MB
INFO:root:[   48] Training loss: 1.69747978, Validation loss: 1.59167924, Gradient norm: 4.55421041
INFO:root:At the start of the epoch: mem (CPU python)=5412.0546875MB; mem (CPU total)=8745.6484375MB
INFO:root:[   49] Training loss: 1.68587832, Validation loss: 1.55297812, Gradient norm: 3.36086356
INFO:root:At the start of the epoch: mem (CPU python)=5433.21875MB; mem (CPU total)=8773.375MB
INFO:root:[   50] Training loss: 1.76685958, Validation loss: 1.59603526, Gradient norm: 14.67234669
INFO:root:At the start of the epoch: mem (CPU python)=5454.3828125MB; mem (CPU total)=8811.7734375MB
INFO:root:[   51] Training loss: 1.69276396, Validation loss: 1.54732417, Gradient norm: 3.95685180
INFO:root:At the start of the epoch: mem (CPU python)=5475.546875MB; mem (CPU total)=8849.34765625MB
INFO:root:[   52] Training loss: 1.68439148, Validation loss: 1.54476214, Gradient norm: 3.36019365
INFO:root:At the start of the epoch: mem (CPU python)=5496.70703125MB; mem (CPU total)=8842.125MB
INFO:root:[   53] Training loss: 1.68045996, Validation loss: 1.55143351, Gradient norm: 3.15206097
INFO:root:At the start of the epoch: mem (CPU python)=5517.87109375MB; mem (CPU total)=8868.16015625MB
INFO:root:[   54] Training loss: 1.70131601, Validation loss: 1.53726391, Gradient norm: 5.87875617
INFO:root:At the start of the epoch: mem (CPU python)=5539.03515625MB; mem (CPU total)=8906.72265625MB
INFO:root:[   55] Training loss: 1.67867521, Validation loss: 1.54183069, Gradient norm: 3.20175079
INFO:root:At the start of the epoch: mem (CPU python)=5560.19921875MB; mem (CPU total)=8884.83984375MB
INFO:root:[   56] Training loss: 1.69676041, Validation loss: 1.63465341, Gradient norm: 5.10119339
INFO:root:At the start of the epoch: mem (CPU python)=5581.36328125MB; mem (CPU total)=8925.26953125MB
INFO:root:[   57] Training loss: 1.70741053, Validation loss: 1.55144922, Gradient norm: 7.38421535
INFO:root:At the start of the epoch: mem (CPU python)=5602.52734375MB; mem (CPU total)=8935.6875MB
INFO:root:[   58] Training loss: 1.68323896, Validation loss: 1.55161756, Gradient norm: 4.44761107
INFO:root:At the start of the epoch: mem (CPU python)=5623.6953125MB; mem (CPU total)=8967.109375MB
INFO:root:[   59] Training loss: 1.67920256, Validation loss: 1.54402378, Gradient norm: 3.93569273
INFO:root:At the start of the epoch: mem (CPU python)=5644.859375MB; mem (CPU total)=8981.76171875MB
INFO:root:[   60] Training loss: 1.67810740, Validation loss: 1.55579685, Gradient norm: 3.83075182
INFO:root:At the start of the epoch: mem (CPU python)=5666.0234375MB; mem (CPU total)=8790.703125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   61] Training loss: 1.67768501, Validation loss: 1.53903100, Gradient norm: 4.01144891
INFO:root:At the start of the epoch: mem (CPU python)=5687.18359375MB; mem (CPU total)=9031.671875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   62] Training loss: 1.67051492, Validation loss: 1.52967007, Gradient norm: 2.95076871
INFO:root:At the start of the epoch: mem (CPU python)=5708.34765625MB; mem (CPU total)=9028.1015625MB
INFO:root:[   63] Training loss: 1.66807755, Validation loss: 1.52863826, Gradient norm: 2.78350006
INFO:root:At the start of the epoch: mem (CPU python)=5729.51171875MB; mem (CPU total)=9066.08984375MB
INFO:root:[   64] Training loss: 1.66771885, Validation loss: 1.52791412, Gradient norm: 3.42564532
INFO:root:At the start of the epoch: mem (CPU python)=5750.67578125MB; mem (CPU total)=9088.91796875MB
INFO:root:[   65] Training loss: 1.66732256, Validation loss: 1.52861696, Gradient norm: 4.17895399
INFO:root:At the start of the epoch: mem (CPU python)=5771.84375MB; mem (CPU total)=9129.51171875MB
INFO:root:[   66] Training loss: 1.66736776, Validation loss: 1.52914155, Gradient norm: 4.92412675
INFO:root:At the start of the epoch: mem (CPU python)=5793.0078125MB; mem (CPU total)=8944.5390625MB
INFO:root:[   67] Training loss: 1.66928502, Validation loss: 1.52748615, Gradient norm: 6.60307604
INFO:root:At the start of the epoch: mem (CPU python)=5814.171875MB; mem (CPU total)=9150.3515625MB
INFO:root:[   68] Training loss: 1.66823088, Validation loss: 1.53292266, Gradient norm: 7.31865620
INFO:root:At the start of the epoch: mem (CPU python)=5835.3359375MB; mem (CPU total)=9165.3203125MB
INFO:root:[   69] Training loss: 1.66760061, Validation loss: 1.52758018, Gradient norm: 7.00839776
INFO:root:At the start of the epoch: mem (CPU python)=5856.5MB; mem (CPU total)=9192.39453125MB
INFO:root:[   70] Training loss: 1.66757718, Validation loss: 1.52615864, Gradient norm: 7.51759268
INFO:root:At the start of the epoch: mem (CPU python)=5877.6640625MB; mem (CPU total)=9208.52734375MB
INFO:root:[   71] Training loss: 1.66724706, Validation loss: 1.52814252, Gradient norm: 7.69267367
INFO:root:At the start of the epoch: mem (CPU python)=5898.82421875MB; mem (CPU total)=9253.8515625MB
INFO:root:[   72] Training loss: 1.66930984, Validation loss: 1.53510870, Gradient norm: 9.39300719
INFO:root:At the start of the epoch: mem (CPU python)=5919.98828125MB; mem (CPU total)=9256.27734375MB
INFO:root:[   73] Training loss: 1.66831122, Validation loss: 1.52885473, Gradient norm: 9.86446328
INFO:root:At the start of the epoch: mem (CPU python)=5941.15234375MB; mem (CPU total)=9267.2421875MB
INFO:root:[   74] Training loss: 1.66809370, Validation loss: 1.52863896, Gradient norm: 10.06868786
INFO:root:At the start of the epoch: mem (CPU python)=5962.31640625MB; mem (CPU total)=9316.0234375MB
INFO:root:[   75] Training loss: 1.67494682, Validation loss: 1.52917838, Gradient norm: 13.87217414
INFO:root:At the start of the epoch: mem (CPU python)=5983.484375MB; mem (CPU total)=9339.13671875MB
INFO:root:[   76] Training loss: 1.66817946, Validation loss: 1.53027036, Gradient norm: 11.27076170
INFO:root:At the start of the epoch: mem (CPU python)=6004.6484375MB; mem (CPU total)=9343.16796875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 1.67098306, Validation loss: 1.53363090, Gradient norm: 12.34897526
INFO:root:At the start of the epoch: mem (CPU python)=6025.8125MB; mem (CPU total)=9364.5859375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 1.66680162, Validation loss: 1.52306004, Gradient norm: 9.42450729
INFO:root:At the start of the epoch: mem (CPU python)=6046.9765625MB; mem (CPU total)=9385.57421875MB
INFO:root:[   79] Training loss: 1.66367185, Validation loss: 1.52493094, Gradient norm: 6.09328791
INFO:root:At the start of the epoch: mem (CPU python)=6068.140625MB; mem (CPU total)=9365.7578125MB
INFO:root:[   80] Training loss: 1.66347200, Validation loss: 1.52237380, Gradient norm: 7.01113344
INFO:root:At the start of the epoch: mem (CPU python)=6089.30078125MB; mem (CPU total)=9413.9296875MB
INFO:root:[   81] Training loss: 1.66312548, Validation loss: 1.52552616, Gradient norm: 6.50311058
INFO:root:At the start of the epoch: mem (CPU python)=6110.46875MB; mem (CPU total)=9448.0546875MB
INFO:root:[   82] Training loss: 1.66302877, Validation loss: 1.52194626, Gradient norm: 7.04540247
INFO:root:At the start of the epoch: mem (CPU python)=6131.6328125MB; mem (CPU total)=9469.1015625MB
INFO:root:[   83] Training loss: 1.66286468, Validation loss: 1.52299105, Gradient norm: 7.23406680
INFO:root:At the start of the epoch: mem (CPU python)=6152.796875MB; mem (CPU total)=9182.86328125MB
INFO:root:[   84] Training loss: 1.66285908, Validation loss: 1.52286787, Gradient norm: 7.57135469
INFO:root:At the start of the epoch: mem (CPU python)=6173.9609375MB; mem (CPU total)=9492.9296875MB
INFO:root:[   85] Training loss: 1.66368438, Validation loss: 1.52259125, Gradient norm: 8.46298119
INFO:root:At the start of the epoch: mem (CPU python)=6195.125MB; mem (CPU total)=9528.3671875MB
INFO:root:[   86] Training loss: 1.66314084, Validation loss: 1.52231168, Gradient norm: 9.97682399
INFO:root:At the start of the epoch: mem (CPU python)=6216.28515625MB; mem (CPU total)=9544.52734375MB
INFO:root:[   87] Training loss: 1.66309083, Validation loss: 1.52156574, Gradient norm: 9.47231213
INFO:root:At the start of the epoch: mem (CPU python)=6237.453125MB; mem (CPU total)=9553.19921875MB
INFO:root:[   88] Training loss: 1.66262248, Validation loss: 1.52507352, Gradient norm: 8.45664942
INFO:root:At the start of the epoch: mem (CPU python)=6258.6171875MB; mem (CPU total)=9653.77734375MB
INFO:root:[   89] Training loss: 1.66268026, Validation loss: 1.52258752, Gradient norm: 9.24815992
INFO:root:At the start of the epoch: mem (CPU python)=6279.78125MB; mem (CPU total)=9601.140625MB
INFO:root:[   90] Training loss: 1.66289978, Validation loss: 1.52214667, Gradient norm: 10.98678044
INFO:root:At the start of the epoch: mem (CPU python)=6300.94140625MB; mem (CPU total)=9629.5234375MB
INFO:root:[   91] Training loss: 1.66270276, Validation loss: 1.52331987, Gradient norm: 9.81366596
INFO:root:At the start of the epoch: mem (CPU python)=6322.10546875MB; mem (CPU total)=9640.47265625MB
INFO:root:[   92] Training loss: 1.66256320, Validation loss: 1.52717578, Gradient norm: 10.40463535
INFO:root:At the start of the epoch: mem (CPU python)=6343.2734375MB; mem (CPU total)=9664.203125MB
INFO:root:[   93] Training loss: 1.66239641, Validation loss: 1.52164856, Gradient norm: 10.35149522
INFO:root:At the start of the epoch: mem (CPU python)=6364.4375MB; mem (CPU total)=9696.8984375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   94] Training loss: 1.66228079, Validation loss: 1.52402103, Gradient norm: 10.73223408
INFO:root:At the start of the epoch: mem (CPU python)=6385.6015625MB; mem (CPU total)=9719.984375MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   95] Training loss: 1.66144823, Validation loss: 1.52212880, Gradient norm: 8.09359993
INFO:root:At the start of the epoch: mem (CPU python)=6406.765625MB; mem (CPU total)=9736.31640625MB
INFO:root:[   96] Training loss: 1.66097447, Validation loss: 1.52244963, Gradient norm: 5.42809724
INFO:root:At the start of the epoch: mem (CPU python)=6427.9296875MB; mem (CPU total)=9759.0546875MB
INFO:root:EP 96: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=6449.09375MB; mem (CPU total)=9817.30078125MB
INFO:root:[   98] Training loss: 0.83482114, Validation loss: 0.71500002, Gradient norm: 27.09407754
INFO:root:At the start of the epoch: mem (CPU python)=6470.26171875MB; mem (CPU total)=9789.89453125MB
INFO:root:[   99] Training loss: 0.83212816, Validation loss: 0.71362070, Gradient norm: 27.95889632
INFO:root:At the start of the epoch: mem (CPU python)=6491.421875MB; mem (CPU total)=9826.7734375MB
INFO:root:[  100] Training loss: 0.83092645, Validation loss: 0.71423928, Gradient norm: 27.09423261
INFO:root:At the start of the epoch: mem (CPU python)=6512.5859375MB; mem (CPU total)=9839.40234375MB
INFO:root:[  101] Training loss: 0.83032420, Validation loss: 0.71333015, Gradient norm: 27.07724935
INFO:root:At the start of the epoch: mem (CPU python)=6533.75MB; mem (CPU total)=9867.4609375MB
INFO:root:[  102] Training loss: 0.82951749, Validation loss: 0.71270733, Gradient norm: 27.63680201
INFO:root:At the start of the epoch: mem (CPU python)=6554.9140625MB; mem (CPU total)=9897.9375MB
INFO:root:[  103] Training loss: 0.82912244, Validation loss: 0.71218480, Gradient norm: 29.91134000
INFO:root:At the start of the epoch: mem (CPU python)=6576.078125MB; mem (CPU total)=9911.12109375MB
INFO:root:[  104] Training loss: 0.82853441, Validation loss: 0.71168488, Gradient norm: 29.29535093
INFO:root:At the start of the epoch: mem (CPU python)=6597.23828125MB; mem (CPU total)=9924.30078125MB
INFO:root:[  105] Training loss: 0.82798886, Validation loss: 0.71186406, Gradient norm: 29.26205145
INFO:root:At the start of the epoch: mem (CPU python)=6618.40625MB; mem (CPU total)=9963.75390625MB
INFO:root:[  106] Training loss: 0.82768530, Validation loss: 0.71145425, Gradient norm: 29.47222402
INFO:root:At the start of the epoch: mem (CPU python)=6639.5703125MB; mem (CPU total)=9970.82421875MB
INFO:root:[  107] Training loss: 0.82758988, Validation loss: 0.71125777, Gradient norm: 29.48087681
INFO:root:At the start of the epoch: mem (CPU python)=6660.734375MB; mem (CPU total)=9974.68359375MB
INFO:root:[  108] Training loss: 0.82716438, Validation loss: 0.71202445, Gradient norm: 28.95649582
INFO:root:At the start of the epoch: mem (CPU python)=6681.89453125MB; mem (CPU total)=10813.5MB
INFO:root:[  109] Training loss: 0.82668910, Validation loss: 0.70970770, Gradient norm: 29.38975936
INFO:root:At the start of the epoch: mem (CPU python)=6703.0625MB; mem (CPU total)=10069.703125MB
INFO:root:[  110] Training loss: 0.82601282, Validation loss: 0.70964978, Gradient norm: 28.95452966
INFO:root:At the start of the epoch: mem (CPU python)=6724.2265625MB; mem (CPU total)=10078.98046875MB
INFO:root:[  111] Training loss: 0.82604830, Validation loss: 0.70948934, Gradient norm: 30.57938685
INFO:root:At the start of the epoch: mem (CPU python)=6745.39453125MB; mem (CPU total)=10113.2421875MB
INFO:root:[  112] Training loss: 0.82600316, Validation loss: 0.71018490, Gradient norm: 30.64651178
INFO:root:At the start of the epoch: mem (CPU python)=6766.55859375MB; mem (CPU total)=10114.33203125MB
INFO:root:[  113] Training loss: 0.82565857, Validation loss: 0.70842902, Gradient norm: 30.52593443
INFO:root:At the start of the epoch: mem (CPU python)=6787.72265625MB; mem (CPU total)=9982.33984375MB
INFO:root:[  114] Training loss: 0.82572080, Validation loss: 0.70881929, Gradient norm: 31.18319106
INFO:root:At the start of the epoch: mem (CPU python)=6808.88671875MB; mem (CPU total)=10165.6796875MB
INFO:root:[  115] Training loss: 0.82501261, Validation loss: 0.71023798, Gradient norm: 32.98415015
INFO:root:At the start of the epoch: mem (CPU python)=6830.05078125MB; mem (CPU total)=10208.671875MB
INFO:root:[  116] Training loss: 0.82486316, Validation loss: 0.70891364, Gradient norm: 32.04495509
INFO:root:At the start of the epoch: mem (CPU python)=6851.21875MB; mem (CPU total)=10219.18359375MB
INFO:root:[  117] Training loss: 0.82481259, Validation loss: 0.70777105, Gradient norm: 31.69485005
INFO:root:At the start of the epoch: mem (CPU python)=6872.3828125MB; mem (CPU total)=10219.0703125MB
INFO:root:[  118] Training loss: 0.82461235, Validation loss: 0.70902353, Gradient norm: 32.43128479
INFO:root:At the start of the epoch: mem (CPU python)=6893.54296875MB; mem (CPU total)=10225.5546875MB
INFO:root:[  119] Training loss: 0.82443906, Validation loss: 0.70839200, Gradient norm: 33.79106867
INFO:root:At the start of the epoch: mem (CPU python)=6914.70703125MB; mem (CPU total)=10271.67578125MB
INFO:root:[  120] Training loss: 0.82414301, Validation loss: 0.70863734, Gradient norm: 34.43678663
INFO:root:At the start of the epoch: mem (CPU python)=6935.8671875MB; mem (CPU total)=10291.6015625MB
INFO:root:[  121] Training loss: 0.82401853, Validation loss: 0.70816313, Gradient norm: 32.41108837
INFO:root:At the start of the epoch: mem (CPU python)=6957.79296875MB; mem (CPU total)=9878.515625MB
INFO:root:[  122] Training loss: 0.82374494, Validation loss: 0.70754928, Gradient norm: 34.17476963
INFO:root:At the start of the epoch: mem (CPU python)=6979.1796875MB; mem (CPU total)=10327.66015625MB
INFO:root:[  123] Training loss: 0.82303858, Validation loss: 0.70817333, Gradient norm: 33.08952586
INFO:root:At the start of the epoch: mem (CPU python)=7000.46875MB; mem (CPU total)=10371.234375MB
INFO:root:[  124] Training loss: 0.82334199, Validation loss: 0.70740960, Gradient norm: 32.80429295
INFO:root:At the start of the epoch: mem (CPU python)=7021.71484375MB; mem (CPU total)=10381.3125MB
INFO:root:[  125] Training loss: 0.82331093, Validation loss: 0.70727777, Gradient norm: 36.87886705
INFO:root:At the start of the epoch: mem (CPU python)=7042.91796875MB; mem (CPU total)=10404.875MB
INFO:root:[  126] Training loss: 0.82268789, Validation loss: 0.70820243, Gradient norm: 34.57542946
INFO:root:At the start of the epoch: mem (CPU python)=7064.08203125MB; mem (CPU total)=10413.1015625MB
INFO:root:[  127] Training loss: 0.82247010, Validation loss: 0.70836929, Gradient norm: 35.00774587
INFO:root:At the start of the epoch: mem (CPU python)=7085.2421875MB; mem (CPU total)=10425.39453125MB
INFO:root:[  128] Training loss: 0.82267549, Validation loss: 0.70588942, Gradient norm: 34.47503086
INFO:root:At the start of the epoch: mem (CPU python)=7106.41015625MB; mem (CPU total)=10454.55859375MB
INFO:root:[  129] Training loss: 0.82214423, Validation loss: 0.70652104, Gradient norm: 35.16257056
INFO:root:At the start of the epoch: mem (CPU python)=7127.57421875MB; mem (CPU total)=10465.0703125MB
INFO:root:[  130] Training loss: 0.82231959, Validation loss: 0.70702330, Gradient norm: 34.85715457
INFO:root:At the start of the epoch: mem (CPU python)=7148.73828125MB; mem (CPU total)=10514.9765625MB
INFO:root:[  131] Training loss: 0.82178563, Validation loss: 0.70689383, Gradient norm: 36.16083645
INFO:root:At the start of the epoch: mem (CPU python)=7169.90625MB; mem (CPU total)=10540.90234375MB
INFO:root:[  132] Training loss: 0.82183327, Validation loss: 0.70590406, Gradient norm: 36.10801109
INFO:root:At the start of the epoch: mem (CPU python)=7191.0703125MB; mem (CPU total)=10523.2890625MB
INFO:root:[  133] Training loss: 0.82141729, Validation loss: 0.70477998, Gradient norm: 36.18403484
INFO:root:At the start of the epoch: mem (CPU python)=7212.234375MB; mem (CPU total)=10576.0859375MB
INFO:root:[  134] Training loss: 0.82130676, Validation loss: 0.70508003, Gradient norm: 36.72287904
INFO:root:At the start of the epoch: mem (CPU python)=7233.3984375MB; mem (CPU total)=10587.515625MB
INFO:root:[  135] Training loss: 0.82130836, Validation loss: 0.70564287, Gradient norm: 37.03734552
INFO:root:At the start of the epoch: mem (CPU python)=7254.5625MB; mem (CPU total)=10629.80859375MB
INFO:root:[  136] Training loss: 0.82103041, Validation loss: 0.70476322, Gradient norm: 37.07941792
INFO:root:At the start of the epoch: mem (CPU python)=7275.7265625MB; mem (CPU total)=10518.75390625MB
INFO:root:[  137] Training loss: 0.82110898, Validation loss: 0.70523183, Gradient norm: 38.03315396
INFO:root:At the start of the epoch: mem (CPU python)=7296.8828125MB; mem (CPU total)=10643.58984375MB
INFO:root:[  138] Training loss: 0.82082294, Validation loss: 0.70443946, Gradient norm: 36.90142139
INFO:root:At the start of the epoch: mem (CPU python)=7318.05078125MB; mem (CPU total)=10671.91796875MB
INFO:root:[  139] Training loss: 0.82094678, Validation loss: 0.70508620, Gradient norm: 37.67431714
INFO:root:At the start of the epoch: mem (CPU python)=7339.21484375MB; mem (CPU total)=10699.546875MB
INFO:root:[  140] Training loss: 0.82033914, Validation loss: 0.70415930, Gradient norm: 38.90142166
INFO:root:At the start of the epoch: mem (CPU python)=7360.37890625MB; mem (CPU total)=10728.0MB
INFO:root:[  141] Training loss: 0.82073480, Validation loss: 0.70330632, Gradient norm: 38.44606474
INFO:root:At the start of the epoch: mem (CPU python)=7381.54296875MB; mem (CPU total)=10737.80859375MB
INFO:root:[  142] Training loss: 0.82012948, Validation loss: 0.70481406, Gradient norm: 38.35767728
INFO:root:At the start of the epoch: mem (CPU python)=7402.70703125MB; mem (CPU total)=10734.5859375MB
INFO:root:[  143] Training loss: 0.82003612, Validation loss: 0.70421425, Gradient norm: 37.96347438
INFO:root:At the start of the epoch: mem (CPU python)=7423.87109375MB; mem (CPU total)=10799.52734375MB
INFO:root:[  144] Training loss: 0.82015248, Validation loss: 0.70424197, Gradient norm: 39.73696594
INFO:root:At the start of the epoch: mem (CPU python)=7445.03515625MB; mem (CPU total)=10799.4375MB
INFO:root:[  145] Training loss: 0.81988604, Validation loss: 0.70368710, Gradient norm: 39.01746410
INFO:root:At the start of the epoch: mem (CPU python)=7466.20703125MB; mem (CPU total)=10834.5MB
INFO:root:[  146] Training loss: 0.81978113, Validation loss: 0.70401751, Gradient norm: 39.90822614
INFO:root:At the start of the epoch: mem (CPU python)=7487.3671875MB; mem (CPU total)=10828.8046875MB
INFO:root:[  147] Training loss: 0.81953855, Validation loss: 0.70332861, Gradient norm: 40.46334655
INFO:root:At the start of the epoch: mem (CPU python)=7508.53125MB; mem (CPU total)=10852.25MB
INFO:root:[  148] Training loss: 0.81932381, Validation loss: 0.70429640, Gradient norm: 40.02728247
INFO:root:At the start of the epoch: mem (CPU python)=7529.6953125MB; mem (CPU total)=10886.25390625MB
INFO:root:[  149] Training loss: 0.81942470, Validation loss: 0.70436906, Gradient norm: 40.89156183
INFO:root:At the start of the epoch: mem (CPU python)=7550.86328125MB; mem (CPU total)=10906.7109375MB
INFO:root:[  150] Training loss: 0.81929336, Validation loss: 0.70321394, Gradient norm: 40.47633065
INFO:root:At the start of the epoch: mem (CPU python)=7572.02734375MB; mem (CPU total)=10904.48828125MB
INFO:root:[  151] Training loss: 0.81882343, Validation loss: 0.70183661, Gradient norm: 42.46132086
INFO:root:At the start of the epoch: mem (CPU python)=7593.19140625MB; mem (CPU total)=10939.6484375MB
INFO:root:[  152] Training loss: 0.81876149, Validation loss: 0.70261446, Gradient norm: 40.27033531
INFO:root:At the start of the epoch: mem (CPU python)=7614.35546875MB; mem (CPU total)=10962.9375MB
INFO:root:[  153] Training loss: 0.81899825, Validation loss: 0.70198932, Gradient norm: 41.25372816
INFO:root:At the start of the epoch: mem (CPU python)=7635.51953125MB; mem (CPU total)=10984.484375MB
INFO:root:[  154] Training loss: 0.81891877, Validation loss: 0.70211052, Gradient norm: 42.28435835
INFO:root:At the start of the epoch: mem (CPU python)=7656.6796875MB; mem (CPU total)=11018.30859375MB
INFO:root:[  155] Training loss: 0.81903384, Validation loss: 0.70161293, Gradient norm: 43.51977941
INFO:root:At the start of the epoch: mem (CPU python)=7677.84375MB; mem (CPU total)=11026.1640625MB
INFO:root:[  156] Training loss: 0.81847143, Validation loss: 0.70156147, Gradient norm: 41.40239035
INFO:root:At the start of the epoch: mem (CPU python)=7699.00390625MB; mem (CPU total)=11061.9921875MB
INFO:root:[  157] Training loss: 0.81816635, Validation loss: 0.70206909, Gradient norm: 41.25851152
INFO:root:At the start of the epoch: mem (CPU python)=7720.171875MB; mem (CPU total)=11094.7109375MB
INFO:root:[  158] Training loss: 0.81808591, Validation loss: 0.70125961, Gradient norm: 42.79351262
INFO:root:At the start of the epoch: mem (CPU python)=7741.3359375MB; mem (CPU total)=11117.7734375MB
INFO:root:[  159] Training loss: 0.81785467, Validation loss: 0.70281438, Gradient norm: 44.59837301
INFO:root:At the start of the epoch: mem (CPU python)=7762.5MB; mem (CPU total)=11128.6640625MB
INFO:root:[  160] Training loss: 0.81820275, Validation loss: 0.70108767, Gradient norm: 45.16449789
INFO:root:At the start of the epoch: mem (CPU python)=7783.6640625MB; mem (CPU total)=11147.11328125MB
INFO:root:[  161] Training loss: 0.81797724, Validation loss: 0.70212272, Gradient norm: 43.66287896
INFO:root:At the start of the epoch: mem (CPU python)=7804.828125MB; mem (CPU total)=11168.23046875MB
INFO:root:[  162] Training loss: 0.81747398, Validation loss: 0.70119981, Gradient norm: 44.08130450
INFO:root:At the start of the epoch: mem (CPU python)=7825.99609375MB; mem (CPU total)=11211.0078125MB
INFO:root:[  163] Training loss: 0.81767427, Validation loss: 0.70151589, Gradient norm: 43.21728275
INFO:root:At the start of the epoch: mem (CPU python)=7847.16015625MB; mem (CPU total)=11212.1953125MB
INFO:root:[  164] Training loss: 0.81721234, Validation loss: 0.70056004, Gradient norm: 44.25974696
INFO:root:At the start of the epoch: mem (CPU python)=7868.32421875MB; mem (CPU total)=11225.0703125MB
INFO:root:[  165] Training loss: 0.81690964, Validation loss: 0.70011321, Gradient norm: 43.60075361
INFO:root:At the start of the epoch: mem (CPU python)=7889.484375MB; mem (CPU total)=11255.3046875MB
INFO:root:[  166] Training loss: 0.81744220, Validation loss: 0.70134161, Gradient norm: 45.30532524
INFO:root:At the start of the epoch: mem (CPU python)=7910.6484375MB; mem (CPU total)=11255.0703125MB
INFO:root:[  167] Training loss: 0.81715824, Validation loss: 0.70134174, Gradient norm: 44.12037675
INFO:root:At the start of the epoch: mem (CPU python)=7931.8125MB; mem (CPU total)=11335.03125MB
INFO:root:[  168] Training loss: 0.81728709, Validation loss: 0.70122204, Gradient norm: 47.38007448
INFO:root:At the start of the epoch: mem (CPU python)=7952.98046875MB; mem (CPU total)=11303.76953125MB
INFO:root:[  169] Training loss: 0.81697028, Validation loss: 0.70057195, Gradient norm: 45.58203005
INFO:root:At the start of the epoch: mem (CPU python)=7974.14453125MB; mem (CPU total)=11332.3671875MB
INFO:root:[  170] Training loss: 0.81693915, Validation loss: 0.70153690, Gradient norm: 47.08237182
INFO:root:At the start of the epoch: mem (CPU python)=7995.30859375MB; mem (CPU total)=11338.03515625MB
INFO:root:[  171] Training loss: 0.81667058, Validation loss: 0.70043649, Gradient norm: 43.54043242
INFO:root:At the start of the epoch: mem (CPU python)=8016.4765625MB; mem (CPU total)=11355.9453125MB
INFO:root:[  172] Training loss: 0.81663822, Validation loss: 0.70131010, Gradient norm: 46.75878882
INFO:root:At the start of the epoch: mem (CPU python)=8037.640625MB; mem (CPU total)=11408.12109375MB
INFO:root:[  173] Training loss: 0.81636562, Validation loss: 0.70018944, Gradient norm: 44.68941420
INFO:root:At the start of the epoch: mem (CPU python)=8058.80859375MB; mem (CPU total)=11416.125MB
INFO:root:[  174] Training loss: 0.81620187, Validation loss: 0.69998713, Gradient norm: 47.68629520
INFO:root:At the start of the epoch: mem (CPU python)=8079.96875MB; mem (CPU total)=11439.81640625MB
INFO:root:[  175] Training loss: 0.81658334, Validation loss: 0.70081480, Gradient norm: 46.11252818
INFO:root:At the start of the epoch: mem (CPU python)=8101.1328125MB; mem (CPU total)=11456.671875MB
INFO:root:[  176] Training loss: 0.81605716, Validation loss: 0.70001360, Gradient norm: 45.76060535
INFO:root:At the start of the epoch: mem (CPU python)=8122.296875MB; mem (CPU total)=11467.5MB
INFO:root:[  177] Training loss: 0.81634543, Validation loss: 0.69973210, Gradient norm: 45.30491021
INFO:root:At the start of the epoch: mem (CPU python)=8143.4609375MB; mem (CPU total)=11542.05859375MB
INFO:root:[  178] Training loss: 0.81608266, Validation loss: 0.69877578, Gradient norm: 46.63241359
INFO:root:At the start of the epoch: mem (CPU python)=8164.625MB; mem (CPU total)=11521.30859375MB
INFO:root:[  179] Training loss: 0.81563948, Validation loss: 0.69919917, Gradient norm: 47.19023113
INFO:root:At the start of the epoch: mem (CPU python)=8185.79296875MB; mem (CPU total)=11555.11328125MB
INFO:root:[  180] Training loss: 0.81593201, Validation loss: 0.69957648, Gradient norm: 51.77286756
INFO:root:At the start of the epoch: mem (CPU python)=8206.95703125MB; mem (CPU total)=11557.9375MB
INFO:root:[  181] Training loss: 0.81586011, Validation loss: 0.70029650, Gradient norm: 47.90280701
INFO:root:At the start of the epoch: mem (CPU python)=8228.12109375MB; mem (CPU total)=11575.42578125MB
INFO:root:[  182] Training loss: 0.81595309, Validation loss: 0.69821028, Gradient norm: 49.11598642
INFO:root:At the start of the epoch: mem (CPU python)=8249.28515625MB; mem (CPU total)=11615.078125MB
INFO:root:[  183] Training loss: 0.81532138, Validation loss: 0.69900330, Gradient norm: 49.11550359
INFO:root:At the start of the epoch: mem (CPU python)=8270.44921875MB; mem (CPU total)=11637.05078125MB
INFO:root:[  184] Training loss: 0.81543742, Validation loss: 0.69898908, Gradient norm: 48.63483190
INFO:root:At the start of the epoch: mem (CPU python)=8291.61328125MB; mem (CPU total)=11632.0859375MB
INFO:root:[  185] Training loss: 0.81547204, Validation loss: 0.69868090, Gradient norm: 49.77070651
INFO:root:At the start of the epoch: mem (CPU python)=8312.77734375MB; mem (CPU total)=11688.22265625MB
INFO:root:[  186] Training loss: 0.81515159, Validation loss: 0.69747324, Gradient norm: 50.85956055
INFO:root:At the start of the epoch: mem (CPU python)=8333.94140625MB; mem (CPU total)=11671.78515625MB
INFO:root:[  187] Training loss: 0.81545792, Validation loss: 0.69863787, Gradient norm: 50.28132937
INFO:root:At the start of the epoch: mem (CPU python)=8355.10546875MB; mem (CPU total)=11732.11328125MB
INFO:root:[  188] Training loss: 0.81469577, Validation loss: 0.69927896, Gradient norm: 49.05871255
INFO:root:At the start of the epoch: mem (CPU python)=8376.265625MB; mem (CPU total)=11741.92578125MB
INFO:root:[  189] Training loss: 0.81489612, Validation loss: 0.70052650, Gradient norm: 49.88423365
INFO:root:At the start of the epoch: mem (CPU python)=8397.43359375MB; mem (CPU total)=11751.9453125MB
INFO:root:[  190] Training loss: 0.81507878, Validation loss: 0.69922184, Gradient norm: 50.70096606
INFO:root:At the start of the epoch: mem (CPU python)=8418.59765625MB; mem (CPU total)=11776.4609375MB
INFO:root:[  191] Training loss: 0.81495553, Validation loss: 0.69785291, Gradient norm: 50.99151465
INFO:root:At the start of the epoch: mem (CPU python)=8439.76171875MB; mem (CPU total)=11788.21484375MB
INFO:root:[  192] Training loss: 0.81454395, Validation loss: 0.69716711, Gradient norm: 49.79709873
INFO:root:At the start of the epoch: mem (CPU python)=8460.92578125MB; mem (CPU total)=11868.62109375MB
INFO:root:[  193] Training loss: 0.81498579, Validation loss: 0.69842530, Gradient norm: 51.57720332
INFO:root:At the start of the epoch: mem (CPU python)=8482.0859375MB; mem (CPU total)=11836.5390625MB
INFO:root:[  194] Training loss: 0.81502586, Validation loss: 0.69885845, Gradient norm: 54.48531980
INFO:root:At the start of the epoch: mem (CPU python)=8503.25MB; mem (CPU total)=11848.25390625MB
INFO:root:[  195] Training loss: 0.81464246, Validation loss: 0.69824418, Gradient norm: 52.18182087
INFO:root:At the start of the epoch: mem (CPU python)=8524.41796875MB; mem (CPU total)=11888.921875MB
INFO:root:[  196] Training loss: 0.81428014, Validation loss: 0.69890942, Gradient norm: 53.33093417
INFO:root:At the start of the epoch: mem (CPU python)=8545.58203125MB; mem (CPU total)=11901.3671875MB
INFO:root:[  197] Training loss: 0.81450442, Validation loss: 0.69742025, Gradient norm: 52.27823854
INFO:root:At the start of the epoch: mem (CPU python)=8566.74609375MB; mem (CPU total)=11932.19140625MB
INFO:root:[  198] Training loss: 0.81432152, Validation loss: 0.69786432, Gradient norm: 54.01506603
INFO:root:At the start of the epoch: mem (CPU python)=8587.91015625MB; mem (CPU total)=11932.63671875MB
INFO:root:[  199] Training loss: 0.81423027, Validation loss: 0.69743660, Gradient norm: 50.73098364
INFO:root:At the start of the epoch: mem (CPU python)=8609.07421875MB; mem (CPU total)=11943.23828125MB
INFO:root:[  200] Training loss: 0.81443090, Validation loss: 0.69651442, Gradient norm: 53.05076343
INFO:root:At the start of the epoch: mem (CPU python)=8630.23828125MB; mem (CPU total)=11966.94921875MB
INFO:root:[  201] Training loss: 0.81434804, Validation loss: 0.69802390, Gradient norm: 54.87914440
INFO:root:At the start of the epoch: mem (CPU python)=8651.40234375MB; mem (CPU total)=12017.65625MB
INFO:root:[  202] Training loss: 0.81402388, Validation loss: 0.69728887, Gradient norm: 51.99917338
INFO:root:At the start of the epoch: mem (CPU python)=8672.5703125MB; mem (CPU total)=12012.2421875MB
INFO:root:[  203] Training loss: 0.81405127, Validation loss: 0.69764486, Gradient norm: 56.14873435
INFO:root:At the start of the epoch: mem (CPU python)=8693.73046875MB; mem (CPU total)=12049.640625MB
INFO:root:[  204] Training loss: 0.81396467, Validation loss: 0.69772727, Gradient norm: 55.35693624
INFO:root:At the start of the epoch: mem (CPU python)=8714.89453125MB; mem (CPU total)=12074.8203125MB
INFO:root:[  205] Training loss: 0.81374108, Validation loss: 0.69705843, Gradient norm: 54.34423750
INFO:root:At the start of the epoch: mem (CPU python)=8736.0546875MB; mem (CPU total)=12078.6953125MB
INFO:root:[  206] Training loss: 0.81387826, Validation loss: 0.69758732, Gradient norm: 54.65035706
INFO:root:At the start of the epoch: mem (CPU python)=8757.22265625MB; mem (CPU total)=12088.75MB
INFO:root:[  207] Training loss: 0.81412794, Validation loss: 0.69661213, Gradient norm: 55.16566335
INFO:root:At the start of the epoch: mem (CPU python)=8778.38671875MB; mem (CPU total)=12137.81640625MB
INFO:root:[  208] Training loss: 0.81384997, Validation loss: 0.69598676, Gradient norm: 58.05786404
INFO:root:At the start of the epoch: mem (CPU python)=8799.55078125MB; mem (CPU total)=12131.984375MB
INFO:root:[  209] Training loss: 0.81404560, Validation loss: 0.69650862, Gradient norm: 55.68378010
INFO:root:At the start of the epoch: mem (CPU python)=8820.71484375MB; mem (CPU total)=12166.19921875MB
INFO:root:[  210] Training loss: 0.81352501, Validation loss: 0.69754059, Gradient norm: 56.29428361
INFO:root:At the start of the epoch: mem (CPU python)=8841.87890625MB; mem (CPU total)=12177.984375MB
INFO:root:[  211] Training loss: 0.81353542, Validation loss: 0.69612451, Gradient norm: 56.38063288
INFO:root:At the start of the epoch: mem (CPU python)=8863.04296875MB; mem (CPU total)=12198.35546875MB
INFO:root:[  212] Training loss: 0.81333438, Validation loss: 0.69831243, Gradient norm: 58.87807864
INFO:root:At the start of the epoch: mem (CPU python)=8884.203125MB; mem (CPU total)=12221.4609375MB
INFO:root:[  213] Training loss: 0.81328510, Validation loss: 0.69850355, Gradient norm: 59.20464094
INFO:root:At the start of the epoch: mem (CPU python)=8905.37109375MB; mem (CPU total)=12256.58203125MB
INFO:root:[  214] Training loss: 0.81291675, Validation loss: 0.69590100, Gradient norm: 56.93447953
INFO:root:At the start of the epoch: mem (CPU python)=8926.53515625MB; mem (CPU total)=12266.015625MB
INFO:root:[  215] Training loss: 0.81435448, Validation loss: 0.69599569, Gradient norm: 67.28024060
INFO:root:At the start of the epoch: mem (CPU python)=8947.69921875MB; mem (CPU total)=12284.6875MB
INFO:root:[  216] Training loss: 0.81280942, Validation loss: 0.69657570, Gradient norm: 58.86590082
INFO:root:At the start of the epoch: mem (CPU python)=8968.86328125MB; mem (CPU total)=12306.88671875MB
INFO:root:[  217] Training loss: 0.81315341, Validation loss: 0.70022901, Gradient norm: 60.94041493
INFO:root:At the start of the epoch: mem (CPU python)=8990.03125MB; mem (CPU total)=12354.83203125MB
INFO:root:[  218] Training loss: 0.81302424, Validation loss: 0.69544323, Gradient norm: 58.09337288
INFO:root:At the start of the epoch: mem (CPU python)=9011.1953125MB; mem (CPU total)=12362.71484375MB
INFO:root:[  219] Training loss: 0.81276956, Validation loss: 0.69606977, Gradient norm: 59.48128791
INFO:root:At the start of the epoch: mem (CPU python)=9032.359375MB; mem (CPU total)=12375.40234375MB
INFO:root:[  220] Training loss: 0.81300599, Validation loss: 0.69641406, Gradient norm: 62.02738152
INFO:root:At the start of the epoch: mem (CPU python)=9053.5234375MB; mem (CPU total)=12382.39453125MB
INFO:root:[  221] Training loss: 0.81291271, Validation loss: 0.69617223, Gradient norm: 60.70634585
INFO:root:At the start of the epoch: mem (CPU python)=9074.68359375MB; mem (CPU total)=12251.42578125MB
INFO:root:[  222] Training loss: 0.81277582, Validation loss: 0.69893243, Gradient norm: 59.37961716
INFO:root:At the start of the epoch: mem (CPU python)=9095.84375MB; mem (CPU total)=12475.74609375MB
INFO:root:[  223] Training loss: 0.81270905, Validation loss: 0.69544571, Gradient norm: 59.32488817
INFO:root:At the start of the epoch: mem (CPU python)=9117.01171875MB; mem (CPU total)=12252.31640625MB
INFO:root:[  224] Training loss: 0.81256214, Validation loss: 0.69531993, Gradient norm: 59.26311071
INFO:root:At the start of the epoch: mem (CPU python)=9138.17578125MB; mem (CPU total)=12468.2421875MB
INFO:root:[  225] Training loss: 0.81236091, Validation loss: 0.69638133, Gradient norm: 59.97150999
INFO:root:At the start of the epoch: mem (CPU python)=9159.33984375MB; mem (CPU total)=12498.1484375MB
INFO:root:[  226] Training loss: 0.81257413, Validation loss: 0.69707748, Gradient norm: 59.29368282
INFO:root:At the start of the epoch: mem (CPU python)=9180.50390625MB; mem (CPU total)=12524.91015625MB
INFO:root:[  227] Training loss: 0.81243658, Validation loss: 0.69590319, Gradient norm: 59.33504424
INFO:root:At the start of the epoch: mem (CPU python)=9201.66796875MB; mem (CPU total)=12528.046875MB
INFO:root:[  228] Training loss: 0.81223746, Validation loss: 0.69692998, Gradient norm: 64.01706745
INFO:root:At the start of the epoch: mem (CPU python)=9222.83203125MB; mem (CPU total)=12553.79296875MB
INFO:root:[  229] Training loss: 0.81232075, Validation loss: 0.69608331, Gradient norm: 59.99119363
INFO:root:At the start of the epoch: mem (CPU python)=9244.0MB; mem (CPU total)=12620.7421875MB
INFO:root:[  230] Training loss: 0.81224193, Validation loss: 0.69805757, Gradient norm: 62.95300115
INFO:root:At the start of the epoch: mem (CPU python)=9265.1640625MB; mem (CPU total)=12601.27734375MB
INFO:root:[  231] Training loss: 0.81230303, Validation loss: 0.69489253, Gradient norm: 60.28676615
INFO:root:At the start of the epoch: mem (CPU python)=9286.32421875MB; mem (CPU total)=12632.3984375MB
INFO:root:[  232] Training loss: 0.81179677, Validation loss: 0.69634951, Gradient norm: 62.89654300
INFO:root:At the start of the epoch: mem (CPU python)=9307.48828125MB; mem (CPU total)=12646.52734375MB
INFO:root:[  233] Training loss: 0.81198369, Validation loss: 0.69718280, Gradient norm: 59.96779723
INFO:root:At the start of the epoch: mem (CPU python)=9328.65234375MB; mem (CPU total)=12648.546875MB
INFO:root:[  234] Training loss: 0.81184232, Validation loss: 0.69544211, Gradient norm: 64.03190119
INFO:root:At the start of the epoch: mem (CPU python)=9349.81640625MB; mem (CPU total)=12710.39453125MB
INFO:root:[  235] Training loss: 0.81206106, Validation loss: 0.69550005, Gradient norm: 63.12228880
INFO:root:At the start of the epoch: mem (CPU python)=9370.984375MB; mem (CPU total)=12702.62109375MB
INFO:root:[  236] Training loss: 0.81163948, Validation loss: 0.69506275, Gradient norm: 61.17426949
INFO:root:At the start of the epoch: mem (CPU python)=9392.1484375MB; mem (CPU total)=12737.7890625MB
INFO:root:[  237] Training loss: 0.81204167, Validation loss: 0.69599579, Gradient norm: 60.47457534
INFO:root:At the start of the epoch: mem (CPU python)=9413.3125MB; mem (CPU total)=12756.3046875MB
INFO:root:[  238] Training loss: 0.81170810, Validation loss: 0.69718771, Gradient norm: 65.99251474
INFO:root:At the start of the epoch: mem (CPU python)=9434.4765625MB; mem (CPU total)=12766.265625MB
INFO:root:[  239] Training loss: 0.81140285, Validation loss: 0.69530443, Gradient norm: 63.72248103
INFO:root:At the start of the epoch: mem (CPU python)=9455.63671875MB; mem (CPU total)=12812.98828125MB
INFO:root:[  240] Training loss: 0.81131705, Validation loss: 0.69502238, Gradient norm: 61.97722038
INFO:root:At the start of the epoch: mem (CPU python)=9476.796875MB; mem (CPU total)=12615.6484375MB
INFO:root:EP 240: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=9497.96484375MB; mem (CPU total)=12821.58203125MB
INFO:root:Training the model took 21670.427s.
INFO:root:Emptying the cuda cache took 0.105s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.59209
INFO:root:EnergyScoreValidation: 0.46487
INFO:root:CRPSValidation: 0.18868
INFO:root:Gaussian NLLValidation: 1.29534
INFO:root:CoverageValidation: 0.64784
INFO:root:IntervalWidthValidation: 0.52113
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.47933
INFO:root:EnergyScoreTest: 0.38051
INFO:root:CRPSTest: 0.1546
INFO:root:Gaussian NLLTest: 1.50963
INFO:root:CoverageTest: 0.58859
INFO:root:IntervalWidthTest: 0.37518
INFO:root:After validation: mem (CPU python)=9513.1953125MB; mem (CPU total)=12881.74609375MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=9513.1953125MB; mem (CPU total)=12879.7890625MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 81788928
INFO:root:After setting up the model: mem (CPU python)=9522.65234375MB; mem (CPU total)=12889.234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=9522.65234375MB; mem (CPU total)=12887.66796875MB
INFO:root:[    1] Training loss: 1.76265757, Validation loss: 1.67551757, Gradient norm: 0.17306320
INFO:root:At the start of the epoch: mem (CPU python)=9547.90625MB; mem (CPU total)=12888.98828125MB
INFO:root:[    2] Training loss: 1.72200904, Validation loss: 1.60516208, Gradient norm: 0.27483317
INFO:root:At the start of the epoch: mem (CPU python)=9569.078125MB; mem (CPU total)=12923.7421875MB
INFO:root:[    3] Training loss: 1.69301897, Validation loss: 1.57513426, Gradient norm: 0.43380197
INFO:root:At the start of the epoch: mem (CPU python)=9590.2578125MB; mem (CPU total)=12933.828125MB
INFO:root:[    4] Training loss: 1.67542767, Validation loss: 1.55314795, Gradient norm: 0.55608789
INFO:root:At the start of the epoch: mem (CPU python)=9611.4296875MB; mem (CPU total)=12944.390625MB
INFO:root:[    5] Training loss: 1.66377883, Validation loss: 1.55444915, Gradient norm: 0.61401361
INFO:root:At the start of the epoch: mem (CPU python)=9632.59375MB; mem (CPU total)=12973.54296875MB
INFO:root:[    6] Training loss: 1.65936944, Validation loss: 1.53570996, Gradient norm: 0.71436026
INFO:root:At the start of the epoch: mem (CPU python)=9653.76171875MB; mem (CPU total)=12992.7109375MB
INFO:root:[    7] Training loss: 1.65868667, Validation loss: 1.53499710, Gradient norm: 0.82706039
INFO:root:At the start of the epoch: mem (CPU python)=9674.92578125MB; mem (CPU total)=13012.8828125MB
INFO:root:[    8] Training loss: 1.65747870, Validation loss: 1.53597298, Gradient norm: 0.88203898
INFO:root:At the start of the epoch: mem (CPU python)=9696.08984375MB; mem (CPU total)=13027.6015625MB
INFO:root:[    9] Training loss: 1.65518601, Validation loss: 1.53306551, Gradient norm: 0.91236885
INFO:root:At the start of the epoch: mem (CPU python)=9717.25390625MB; mem (CPU total)=13070.6328125MB
INFO:root:[   10] Training loss: 1.65508123, Validation loss: 1.53702663, Gradient norm: 0.95383297
INFO:root:At the start of the epoch: mem (CPU python)=9738.41796875MB; mem (CPU total)=13076.5546875MB
INFO:root:[   11] Training loss: 1.65303381, Validation loss: 1.54305856, Gradient norm: 1.02628718
INFO:root:At the start of the epoch: mem (CPU python)=9759.58203125MB; mem (CPU total)=13083.79296875MB
INFO:root:[   12] Training loss: 1.65268799, Validation loss: 1.53831850, Gradient norm: 1.08540168
INFO:root:At the start of the epoch: mem (CPU python)=9780.74609375MB; mem (CPU total)=13109.96484375MB
INFO:root:[   13] Training loss: 1.65251883, Validation loss: 1.52687627, Gradient norm: 1.08738458
INFO:root:At the start of the epoch: mem (CPU python)=9801.91015625MB; mem (CPU total)=13155.15625MB
INFO:root:[   14] Training loss: 1.65065714, Validation loss: 1.52335741, Gradient norm: 1.09300055
INFO:root:At the start of the epoch: mem (CPU python)=9823.07421875MB; mem (CPU total)=13172.22265625MB
INFO:root:[   15] Training loss: 1.65066797, Validation loss: 1.52831741, Gradient norm: 1.11234262
INFO:root:At the start of the epoch: mem (CPU python)=9844.23828125MB; mem (CPU total)=13181.24609375MB
INFO:root:[   16] Training loss: 1.64949766, Validation loss: 1.53636386, Gradient norm: 1.13949531
INFO:root:At the start of the epoch: mem (CPU python)=9865.40234375MB; mem (CPU total)=13192.96484375MB
INFO:root:[   17] Training loss: 1.64952664, Validation loss: 1.52474172, Gradient norm: 1.22707041
INFO:root:At the start of the epoch: mem (CPU python)=9886.5703125MB; mem (CPU total)=13296.5078125MB
INFO:root:[   18] Training loss: 1.64580102, Validation loss: 1.51871709, Gradient norm: 1.26926594
INFO:root:At the start of the epoch: mem (CPU python)=9907.734375MB; mem (CPU total)=13274.91796875MB
INFO:root:[   19] Training loss: 1.64210569, Validation loss: 1.50670337, Gradient norm: 1.28705787
INFO:root:At the start of the epoch: mem (CPU python)=9928.89453125MB; mem (CPU total)=13265.77734375MB
INFO:root:[   20] Training loss: 1.64175146, Validation loss: 1.52431680, Gradient norm: 1.34126467
INFO:root:At the start of the epoch: mem (CPU python)=9950.05859375MB; mem (CPU total)=13296.015625MB
INFO:root:[   21] Training loss: 1.64148829, Validation loss: 1.52133873, Gradient norm: 1.35234074
INFO:root:At the start of the epoch: mem (CPU python)=9971.21875MB; mem (CPU total)=13307.99609375MB
INFO:root:[   22] Training loss: 1.64079884, Validation loss: 1.52116699, Gradient norm: 1.30959394
INFO:root:At the start of the epoch: mem (CPU python)=9992.3828125MB; mem (CPU total)=13328.30078125MB
INFO:root:[   23] Training loss: 1.64105654, Validation loss: 1.51548805, Gradient norm: 1.39909791
INFO:root:At the start of the epoch: mem (CPU python)=10013.55078125MB; mem (CPU total)=13349.33203125MB
INFO:root:[   24] Training loss: 1.64004826, Validation loss: 1.51289084, Gradient norm: 1.34499678
INFO:root:At the start of the epoch: mem (CPU python)=10034.71484375MB; mem (CPU total)=13427.0859375MB
INFO:root:[   25] Training loss: 1.64024817, Validation loss: 1.51359111, Gradient norm: 1.39647508
INFO:root:At the start of the epoch: mem (CPU python)=10055.87890625MB; mem (CPU total)=13391.66015625MB
INFO:root:[   26] Training loss: 1.63941555, Validation loss: 1.51497439, Gradient norm: 1.33664905
INFO:root:At the start of the epoch: mem (CPU python)=10077.0546875MB; mem (CPU total)=13416.4453125MB
INFO:root:[   27] Training loss: 1.64039653, Validation loss: 1.51562354, Gradient norm: 1.45096366
INFO:root:At the start of the epoch: mem (CPU python)=10098.21875MB; mem (CPU total)=13395.75390625MB
INFO:root:[   28] Training loss: 1.63874191, Validation loss: 1.52627908, Gradient norm: 1.33989083
INFO:root:At the start of the epoch: mem (CPU python)=10119.38671875MB; mem (CPU total)=13458.49609375MB
INFO:root:[   29] Training loss: 1.63900746, Validation loss: 1.51144181, Gradient norm: 1.41677549
INFO:root:At the start of the epoch: mem (CPU python)=10140.55078125MB; mem (CPU total)=13478.33203125MB
INFO:root:[   30] Training loss: 1.63955367, Validation loss: 1.51031900, Gradient norm: 1.45672742
INFO:root:At the start of the epoch: mem (CPU python)=10161.71875MB; mem (CPU total)=13586.11328125MB
INFO:root:[   31] Training loss: 1.63894935, Validation loss: 1.51397936, Gradient norm: 1.48392326
INFO:root:At the start of the epoch: mem (CPU python)=10182.87890625MB; mem (CPU total)=13535.30078125MB
INFO:root:[   32] Training loss: 1.63919480, Validation loss: 1.51828759, Gradient norm: 1.49888316
INFO:root:At the start of the epoch: mem (CPU python)=10204.04296875MB; mem (CPU total)=13560.44921875MB
INFO:root:[   33] Training loss: 1.63896025, Validation loss: 1.50992182, Gradient norm: 1.47661099
INFO:root:At the start of the epoch: mem (CPU python)=10225.2109375MB; mem (CPU total)=13578.671875MB
INFO:root:[   34] Training loss: 1.63847343, Validation loss: 1.51629392, Gradient norm: 1.49231150
INFO:root:At the start of the epoch: mem (CPU python)=10246.375MB; mem (CPU total)=13597.671875MB
INFO:root:[   35] Training loss: 1.63878233, Validation loss: 1.52005976, Gradient norm: 1.47346663
INFO:root:At the start of the epoch: mem (CPU python)=10267.53515625MB; mem (CPU total)=13603.76171875MB
INFO:root:[   36] Training loss: 1.63842286, Validation loss: 1.52012562, Gradient norm: 1.47668881
INFO:root:At the start of the epoch: mem (CPU python)=10288.69921875MB; mem (CPU total)=13643.546875MB
INFO:root:[   37] Training loss: 1.63871232, Validation loss: 1.52367251, Gradient norm: 1.53296147
INFO:root:At the start of the epoch: mem (CPU python)=10309.86328125MB; mem (CPU total)=13664.4140625MB
INFO:root:[   38] Training loss: 1.63898260, Validation loss: 1.50812271, Gradient norm: 1.58361356
INFO:root:At the start of the epoch: mem (CPU python)=10331.02734375MB; mem (CPU total)=13684.53125MB
INFO:root:[   39] Training loss: 1.63866600, Validation loss: 1.51266819, Gradient norm: 1.55695813
INFO:root:At the start of the epoch: mem (CPU python)=10352.1953125MB; mem (CPU total)=13712.4453125MB
INFO:root:[   40] Training loss: 1.63791065, Validation loss: 1.51196462, Gradient norm: 1.54602184
INFO:root:At the start of the epoch: mem (CPU python)=10373.35546875MB; mem (CPU total)=13718.73828125MB
INFO:root:[   41] Training loss: 1.63799291, Validation loss: 1.51769285, Gradient norm: 1.58965444
INFO:root:At the start of the epoch: mem (CPU python)=10394.51953125MB; mem (CPU total)=13739.6953125MB
INFO:root:[   42] Training loss: 1.63794402, Validation loss: 1.51227594, Gradient norm: 1.63050728
INFO:root:At the start of the epoch: mem (CPU python)=10415.68359375MB; mem (CPU total)=13756.109375MB
INFO:root:[   43] Training loss: 1.63783022, Validation loss: 1.52006679, Gradient norm: 1.67751342
INFO:root:At the start of the epoch: mem (CPU python)=10436.84765625MB; mem (CPU total)=13767.421875MB
INFO:root:[   44] Training loss: 1.63802904, Validation loss: 1.50598082, Gradient norm: 1.71835902
INFO:root:At the start of the epoch: mem (CPU python)=10458.015625MB; mem (CPU total)=13813.65234375MB
INFO:root:[   45] Training loss: 1.63853619, Validation loss: 1.51417618, Gradient norm: 1.62489083
INFO:root:At the start of the epoch: mem (CPU python)=10479.1796875MB; mem (CPU total)=13846.890625MB
INFO:root:[   46] Training loss: 1.63988056, Validation loss: 1.51019141, Gradient norm: 1.81022368
INFO:root:At the start of the epoch: mem (CPU python)=10500.34375MB; mem (CPU total)=13845.70703125MB
INFO:root:[   47] Training loss: 1.63766843, Validation loss: 1.50923669, Gradient norm: 1.72519432
INFO:root:At the start of the epoch: mem (CPU python)=10521.5078125MB; mem (CPU total)=13860.49609375MB
INFO:root:[   48] Training loss: 1.63923189, Validation loss: 1.51794370, Gradient norm: 1.84192378
INFO:root:At the start of the epoch: mem (CPU python)=10542.671875MB; mem (CPU total)=13885.38671875MB
INFO:root:[   49] Training loss: 1.63796329, Validation loss: 1.51165134, Gradient norm: 1.80236643
INFO:root:At the start of the epoch: mem (CPU python)=10563.83203125MB; mem (CPU total)=13910.87890625MB
INFO:root:[   50] Training loss: 1.63827108, Validation loss: 1.51316613, Gradient norm: 1.83305902
INFO:root:At the start of the epoch: mem (CPU python)=10585.0MB; mem (CPU total)=13929.34375MB
INFO:root:[   51] Training loss: 1.63848169, Validation loss: 1.50459327, Gradient norm: 1.85024227
INFO:root:At the start of the epoch: mem (CPU python)=10606.1640625MB; mem (CPU total)=13951.5MB
INFO:root:[   52] Training loss: 1.63851891, Validation loss: 1.51439682, Gradient norm: 1.85297278
INFO:root:At the start of the epoch: mem (CPU python)=10627.32421875MB; mem (CPU total)=13976.6484375MB
INFO:root:[   53] Training loss: 1.64374437, Validation loss: 1.50958167, Gradient norm: 2.22627975
INFO:root:At the start of the epoch: mem (CPU python)=10648.48828125MB; mem (CPU total)=14027.58984375MB
INFO:root:[   54] Training loss: 1.63825205, Validation loss: 1.51090658, Gradient norm: 1.82952325
INFO:root:At the start of the epoch: mem (CPU python)=10669.65234375MB; mem (CPU total)=14476.08984375MB
INFO:root:[   55] Training loss: 1.63762709, Validation loss: 1.51754323, Gradient norm: 1.80723178
INFO:root:At the start of the epoch: mem (CPU python)=10690.81640625MB; mem (CPU total)=14734.93359375MB
INFO:root:[   56] Training loss: 1.63774934, Validation loss: 1.53067934, Gradient norm: 1.88995107
INFO:root:At the start of the epoch: mem (CPU python)=10711.984375MB; mem (CPU total)=14629.54296875MB
INFO:root:[   57] Training loss: 1.65227513, Validation loss: 1.58822666, Gradient norm: 2.47322880
INFO:root:At the start of the epoch: mem (CPU python)=10733.1484375MB; mem (CPU total)=14080.97265625MB
INFO:root:[   58] Training loss: 1.68175721, Validation loss: 1.50966627, Gradient norm: 4.20526330
INFO:root:At the start of the epoch: mem (CPU python)=10754.3125MB; mem (CPU total)=14789.91015625MB
INFO:root:[   59] Training loss: 1.64237458, Validation loss: 1.50534726, Gradient norm: 2.00876327
INFO:root:At the start of the epoch: mem (CPU python)=10775.47265625MB; mem (CPU total)=14953.65625MB
INFO:root:[   60] Training loss: 1.63930432, Validation loss: 1.51304934, Gradient norm: 1.87542085
INFO:root:At the start of the epoch: mem (CPU python)=10796.63671875MB; mem (CPU total)=14922.64453125MB
INFO:root:[   61] Training loss: 1.63778732, Validation loss: 1.51973097, Gradient norm: 1.84517842
INFO:root:At the start of the epoch: mem (CPU python)=10817.8046875MB; mem (CPU total)=14945.390625MB
INFO:root:[   62] Training loss: 1.63806489, Validation loss: 1.51745683, Gradient norm: 1.91841777
INFO:root:At the start of the epoch: mem (CPU python)=10838.96875MB; mem (CPU total)=14987.2734375MB
INFO:root:[   63] Training loss: 1.75065327, Validation loss: 1.62365156, Gradient norm: 7.00834950
INFO:root:At the start of the epoch: mem (CPU python)=10860.1328125MB; mem (CPU total)=14994.82421875MB
INFO:root:[   64] Training loss: 1.72007384, Validation loss: 1.51651930, Gradient norm: 5.18215107
INFO:root:At the start of the epoch: mem (CPU python)=10881.296875MB; mem (CPU total)=14229.12109375MB
INFO:root:[   65] Training loss: 1.68232200, Validation loss: 1.50314377, Gradient norm: 3.50853620
INFO:root:At the start of the epoch: mem (CPU python)=10902.4609375MB; mem (CPU total)=15054.828125MB
INFO:root:[   66] Training loss: 1.65658913, Validation loss: 1.50475260, Gradient norm: 2.83574926
INFO:root:At the start of the epoch: mem (CPU python)=10923.62890625MB; mem (CPU total)=15039.87109375MB
INFO:root:[   67] Training loss: 1.67329485, Validation loss: 1.71192351, Gradient norm: 3.80853024
INFO:root:At the start of the epoch: mem (CPU python)=10944.79296875MB; mem (CPU total)=15109.15625MB
INFO:root:[   68] Training loss: 1.71049701, Validation loss: 1.50644417, Gradient norm: 7.74137342
INFO:root:At the start of the epoch: mem (CPU python)=10965.953125MB; mem (CPU total)=15092.78515625MB
INFO:root:[   69] Training loss: 1.65779236, Validation loss: 1.50082827, Gradient norm: 3.37411171
INFO:root:At the start of the epoch: mem (CPU python)=10987.1171875MB; mem (CPU total)=15134.83203125MB
INFO:root:[   70] Training loss: 1.65238248, Validation loss: 1.49542190, Gradient norm: 2.78109669
INFO:root:At the start of the epoch: mem (CPU python)=11008.27734375MB; mem (CPU total)=14371.25390625MB
INFO:root:[   71] Training loss: 1.65025287, Validation loss: 1.50236430, Gradient norm: 2.75152950
INFO:root:At the start of the epoch: mem (CPU python)=11029.44140625MB; mem (CPU total)=14448.19921875MB
INFO:root:[   72] Training loss: 1.64863156, Validation loss: 1.51459739, Gradient norm: 2.63323226
INFO:root:At the start of the epoch: mem (CPU python)=11050.609375MB; mem (CPU total)=14396.33203125MB
INFO:root:[   73] Training loss: 1.64943760, Validation loss: 1.49688705, Gradient norm: 2.69679017
INFO:root:At the start of the epoch: mem (CPU python)=11071.77734375MB; mem (CPU total)=14442.35546875MB
INFO:root:[   74] Training loss: 1.64666850, Validation loss: 1.51021712, Gradient norm: 2.60001392
INFO:root:At the start of the epoch: mem (CPU python)=11092.94140625MB; mem (CPU total)=14440.91015625MB
INFO:root:[   75] Training loss: 1.64698231, Validation loss: 1.50047364, Gradient norm: 2.66983196
INFO:root:At the start of the epoch: mem (CPU python)=11114.10546875MB; mem (CPU total)=14483.0625MB
INFO:root:[   76] Training loss: 1.64947691, Validation loss: 1.58959181, Gradient norm: 2.89179089
INFO:root:At the start of the epoch: mem (CPU python)=11135.26953125MB; mem (CPU total)=14509.37890625MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   77] Training loss: 1.68600805, Validation loss: 1.51993126, Gradient norm: 5.89821971
INFO:root:At the start of the epoch: mem (CPU python)=11156.43359375MB; mem (CPU total)=14522.79296875MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   78] Training loss: 1.64539833, Validation loss: 1.49254887, Gradient norm: 3.07989666
INFO:root:At the start of the epoch: mem (CPU python)=11177.59765625MB; mem (CPU total)=14545.80859375MB
INFO:root:[   79] Training loss: 1.64068496, Validation loss: 1.49496476, Gradient norm: 2.61324439
INFO:root:At the start of the epoch: mem (CPU python)=11198.76171875MB; mem (CPU total)=14551.39453125MB
INFO:root:[   80] Training loss: 1.63999949, Validation loss: 1.49474589, Gradient norm: 3.20975867
INFO:root:At the start of the epoch: mem (CPU python)=11219.92578125MB; mem (CPU total)=14553.04296875MB
INFO:root:[   81] Training loss: 1.63967197, Validation loss: 1.49626020, Gradient norm: 3.69610264
INFO:root:At the start of the epoch: mem (CPU python)=11241.08984375MB; mem (CPU total)=14577.63671875MB
INFO:root:[   82] Training loss: 1.63991720, Validation loss: 1.49487770, Gradient norm: 4.15842452
INFO:root:At the start of the epoch: mem (CPU python)=11262.25390625MB; mem (CPU total)=14614.96484375MB
INFO:root:[   83] Training loss: 1.63984513, Validation loss: 1.49905644, Gradient norm: 4.57981274
INFO:root:At the start of the epoch: mem (CPU python)=11283.41796875MB; mem (CPU total)=14646.78125MB
INFO:root:[   84] Training loss: 1.63930396, Validation loss: 1.49794492, Gradient norm: 4.57715676
INFO:root:At the start of the epoch: mem (CPU python)=11304.5859375MB; mem (CPU total)=14666.5546875MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   85] Training loss: 1.63934017, Validation loss: 1.49675696, Gradient norm: 4.97418269
INFO:root:At the start of the epoch: mem (CPU python)=11325.75MB; mem (CPU total)=14679.48828125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   86] Training loss: 1.63859107, Validation loss: 1.49497739, Gradient norm: 4.71099500
INFO:root:At the start of the epoch: mem (CPU python)=11346.91015625MB; mem (CPU total)=14709.265625MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   87] Training loss: 1.63675753, Validation loss: 1.49574630, Gradient norm: 3.06453808
INFO:root:At the start of the epoch: mem (CPU python)=11368.0703125MB; mem (CPU total)=14739.5546875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:EP 87: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=11389.234375MB; mem (CPU total)=14732.484375MB
INFO:root:[   89] Training loss: 0.71925681, Validation loss: 0.60169003, Gradient norm: 14.44255624
INFO:root:At the start of the epoch: mem (CPU python)=11410.40234375MB; mem (CPU total)=14768.92578125MB
INFO:root:[   90] Training loss: 0.71538924, Validation loss: 0.60025133, Gradient norm: 14.66219620
INFO:root:At the start of the epoch: mem (CPU python)=11431.58984375MB; mem (CPU total)=14796.95703125MB
INFO:root:[   91] Training loss: 0.71383960, Validation loss: 0.59915360, Gradient norm: 14.47013833
INFO:root:At the start of the epoch: mem (CPU python)=11452.75390625MB; mem (CPU total)=14807.41015625MB
INFO:root:[   92] Training loss: 0.71344659, Validation loss: 0.59860918, Gradient norm: 14.68449951
INFO:root:At the start of the epoch: mem (CPU python)=11473.91796875MB; mem (CPU total)=14842.9765625MB
INFO:root:[   93] Training loss: 0.71352828, Validation loss: 0.59852630, Gradient norm: 15.05047470
INFO:root:At the start of the epoch: mem (CPU python)=11495.08203125MB; mem (CPU total)=14862.70703125MB
INFO:root:[   94] Training loss: 0.71219849, Validation loss: 0.59802568, Gradient norm: 15.27459804
INFO:root:At the start of the epoch: mem (CPU python)=11516.24609375MB; mem (CPU total)=14871.6875MB
INFO:root:[   95] Training loss: 0.71247874, Validation loss: 0.59806514, Gradient norm: 15.23780005
INFO:root:At the start of the epoch: mem (CPU python)=11537.41015625MB; mem (CPU total)=14897.9375MB
INFO:root:[   96] Training loss: 0.71146782, Validation loss: 0.59712154, Gradient norm: 16.45949789
INFO:root:At the start of the epoch: mem (CPU python)=11558.57421875MB; mem (CPU total)=14931.765625MB
INFO:root:[   97] Training loss: 0.71061878, Validation loss: 0.59585383, Gradient norm: 16.07353175
INFO:root:At the start of the epoch: mem (CPU python)=11579.73828125MB; mem (CPU total)=14975.61328125MB
INFO:root:[   98] Training loss: 0.71093493, Validation loss: 0.59690994, Gradient norm: 16.85812112
INFO:root:At the start of the epoch: mem (CPU python)=11600.90234375MB; mem (CPU total)=14983.484375MB
INFO:root:[   99] Training loss: 0.71048741, Validation loss: 0.59615710, Gradient norm: 16.50572465
INFO:root:At the start of the epoch: mem (CPU python)=11622.06640625MB; mem (CPU total)=14978.71484375MB
INFO:root:[  100] Training loss: 0.70986164, Validation loss: 0.59489426, Gradient norm: 17.12121286
INFO:root:At the start of the epoch: mem (CPU python)=11643.23046875MB; mem (CPU total)=14987.89453125MB
INFO:root:[  101] Training loss: 0.70976091, Validation loss: 0.59721766, Gradient norm: 17.06665727
INFO:root:At the start of the epoch: mem (CPU python)=11664.3984375MB; mem (CPU total)=15002.5859375MB
INFO:root:[  102] Training loss: 0.70950115, Validation loss: 0.59643485, Gradient norm: 17.50447070
INFO:root:At the start of the epoch: mem (CPU python)=11685.5625MB; mem (CPU total)=15055.171875MB
INFO:root:[  103] Training loss: 0.70974295, Validation loss: 0.59592794, Gradient norm: 18.29583205
INFO:root:At the start of the epoch: mem (CPU python)=11706.72265625MB; mem (CPU total)=15055.3984375MB
INFO:root:[  104] Training loss: 0.71034613, Validation loss: 0.59598807, Gradient norm: 18.13215212
INFO:root:At the start of the epoch: mem (CPU python)=11727.88671875MB; mem (CPU total)=15063.5390625MB
INFO:root:[  105] Training loss: 0.70990943, Validation loss: 0.59588529, Gradient norm: 18.62403740
INFO:root:At the start of the epoch: mem (CPU python)=11749.05078125MB; mem (CPU total)=15105.35546875MB
INFO:root:[  106] Training loss: 0.70937405, Validation loss: 0.59344297, Gradient norm: 18.41311677
INFO:root:At the start of the epoch: mem (CPU python)=11770.2109375MB; mem (CPU total)=15117.3203125MB
INFO:root:[  107] Training loss: 0.70887808, Validation loss: 0.59478464, Gradient norm: 19.21727149
INFO:root:At the start of the epoch: mem (CPU python)=11791.37890625MB; mem (CPU total)=15139.69140625MB
INFO:root:[  108] Training loss: 0.70864419, Validation loss: 0.59589337, Gradient norm: 19.27719851
INFO:root:At the start of the epoch: mem (CPU python)=11812.54296875MB; mem (CPU total)=15172.265625MB
INFO:root:[  109] Training loss: 0.70897452, Validation loss: 0.59326855, Gradient norm: 19.23139474
INFO:root:At the start of the epoch: mem (CPU python)=11833.70703125MB; mem (CPU total)=15171.33984375MB
INFO:root:[  110] Training loss: 0.70864629, Validation loss: 0.59434396, Gradient norm: 20.10268082
INFO:root:At the start of the epoch: mem (CPU python)=11854.87109375MB; mem (CPU total)=15191.66015625MB
INFO:root:[  111] Training loss: 0.70796970, Validation loss: 0.59603259, Gradient norm: 20.62470702
INFO:root:At the start of the epoch: mem (CPU python)=11876.03515625MB; mem (CPU total)=15279.0MB
INFO:root:[  112] Training loss: 0.70855265, Validation loss: 0.59346511, Gradient norm: 20.53773409
INFO:root:At the start of the epoch: mem (CPU python)=11897.19921875MB; mem (CPU total)=15247.37890625MB
INFO:root:[  113] Training loss: 0.70818544, Validation loss: 0.59306087, Gradient norm: 21.38503006
INFO:root:At the start of the epoch: mem (CPU python)=11918.3671875MB; mem (CPU total)=15266.80859375MB
INFO:root:[  114] Training loss: 0.70790177, Validation loss: 0.59298095, Gradient norm: 21.25760069
INFO:root:At the start of the epoch: mem (CPU python)=11939.53125MB; mem (CPU total)=15278.3203125MB
INFO:root:[  115] Training loss: 0.70823232, Validation loss: 0.59562049, Gradient norm: 21.57784459
INFO:root:At the start of the epoch: mem (CPU python)=11960.69140625MB; mem (CPU total)=15316.09765625MB
INFO:root:[  116] Training loss: 0.70792358, Validation loss: 0.59227185, Gradient norm: 22.53581379
INFO:root:At the start of the epoch: mem (CPU python)=11981.85546875MB; mem (CPU total)=15322.61328125MB
INFO:root:[  117] Training loss: 0.70772509, Validation loss: 0.59307198, Gradient norm: 22.42210241
INFO:root:At the start of the epoch: mem (CPU python)=12003.01953125MB; mem (CPU total)=15356.12109375MB
INFO:root:[  118] Training loss: 0.70757510, Validation loss: 0.59271927, Gradient norm: 22.73356412
INFO:root:At the start of the epoch: mem (CPU python)=12024.1875MB; mem (CPU total)=15378.46875MB
INFO:root:[  119] Training loss: 0.70724722, Validation loss: 0.59468669, Gradient norm: 22.92868299
INFO:root:At the start of the epoch: mem (CPU python)=12045.3515625MB; mem (CPU total)=15387.4921875MB
INFO:root:[  120] Training loss: 0.70685741, Validation loss: 0.59357944, Gradient norm: 23.81896256
INFO:root:At the start of the epoch: mem (CPU python)=12066.515625MB; mem (CPU total)=15414.4609375MB
INFO:root:[  121] Training loss: 0.70647809, Validation loss: 0.59233561, Gradient norm: 25.02157245
INFO:root:At the start of the epoch: mem (CPU python)=12087.6796875MB; mem (CPU total)=15440.9921875MB
INFO:root:[  122] Training loss: 0.70640815, Validation loss: 0.59378424, Gradient norm: 25.08344226
INFO:root:At the start of the epoch: mem (CPU python)=12108.84375MB; mem (CPU total)=15463.46484375MB
INFO:root:[  123] Training loss: 0.70643925, Validation loss: 0.59272819, Gradient norm: 25.46716670
INFO:root:At the start of the epoch: mem (CPU python)=12130.01171875MB; mem (CPU total)=15479.7578125MB
INFO:root:[  124] Training loss: 0.70662979, Validation loss: 0.59220347, Gradient norm: 26.32174186
INFO:root:At the start of the epoch: mem (CPU python)=12151.17578125MB; mem (CPU total)=15566.37890625MB
INFO:root:[  125] Training loss: 0.70639778, Validation loss: 0.59189924, Gradient norm: 27.22443924
INFO:root:At the start of the epoch: mem (CPU python)=12172.3359375MB; mem (CPU total)=15520.84375MB
INFO:root:[  126] Training loss: 0.70660647, Validation loss: 0.59208369, Gradient norm: 27.31143690
INFO:root:At the start of the epoch: mem (CPU python)=12193.5MB; mem (CPU total)=15514.36328125MB
INFO:root:[  127] Training loss: 0.70630864, Validation loss: 0.59296632, Gradient norm: 27.47192526
INFO:root:At the start of the epoch: mem (CPU python)=12214.6640625MB; mem (CPU total)=15554.0546875MB
INFO:root:[  128] Training loss: 0.70577022, Validation loss: 0.59293201, Gradient norm: 27.54931190
INFO:root:At the start of the epoch: mem (CPU python)=12235.828125MB; mem (CPU total)=15567.27734375MB
INFO:root:[  129] Training loss: 0.70584236, Validation loss: 0.59342543, Gradient norm: 28.46131309
INFO:root:At the start of the epoch: mem (CPU python)=12256.99609375MB; mem (CPU total)=15602.87109375MB
INFO:root:[  130] Training loss: 0.70592665, Validation loss: 0.59232404, Gradient norm: 28.69145042
INFO:root:At the start of the epoch: mem (CPU python)=12278.16015625MB; mem (CPU total)=15610.09375MB
INFO:root:[  131] Training loss: 0.70641384, Validation loss: 0.59153651, Gradient norm: 29.48998920
INFO:root:At the start of the epoch: mem (CPU python)=12299.32421875MB; mem (CPU total)=15648.95703125MB
INFO:root:[  132] Training loss: 0.70556209, Validation loss: 0.59255614, Gradient norm: 29.88927416
INFO:root:At the start of the epoch: mem (CPU python)=12320.48828125MB; mem (CPU total)=15671.9140625MB
INFO:root:[  133] Training loss: 0.70561516, Validation loss: 0.59083191, Gradient norm: 29.70475926
INFO:root:At the start of the epoch: mem (CPU python)=12341.65234375MB; mem (CPU total)=15667.13671875MB
INFO:root:[  134] Training loss: 0.70607505, Validation loss: 0.59318520, Gradient norm: 31.43399909
INFO:root:At the start of the epoch: mem (CPU python)=12362.8125MB; mem (CPU total)=15717.5546875MB
INFO:root:[  135] Training loss: 0.70519541, Validation loss: 0.59339262, Gradient norm: 31.07143451
INFO:root:At the start of the epoch: mem (CPU python)=12383.98046875MB; mem (CPU total)=15736.09765625MB
INFO:root:[  136] Training loss: 0.70470302, Validation loss: 0.59051110, Gradient norm: 32.53078998
INFO:root:At the start of the epoch: mem (CPU python)=12405.14453125MB; mem (CPU total)=15771.35546875MB
INFO:root:[  137] Training loss: 0.70557795, Validation loss: 0.59222778, Gradient norm: 32.78731989
INFO:root:At the start of the epoch: mem (CPU python)=12426.3046875MB; mem (CPU total)=15841.203125MB
INFO:root:[  138] Training loss: 0.70499393, Validation loss: 0.58969511, Gradient norm: 31.90504644
INFO:root:At the start of the epoch: mem (CPU python)=12447.46875MB; mem (CPU total)=15802.6640625MB
INFO:root:[  139] Training loss: 0.70474328, Validation loss: 0.59231247, Gradient norm: 33.84327239
INFO:root:At the start of the epoch: mem (CPU python)=12468.6328125MB; mem (CPU total)=15813.46484375MB
INFO:root:[  140] Training loss: 0.70539904, Validation loss: 0.59087663, Gradient norm: 33.92718420
INFO:root:At the start of the epoch: mem (CPU python)=12489.80078125MB; mem (CPU total)=15818.70703125MB
INFO:root:[  141] Training loss: 0.70547089, Validation loss: 0.59163522, Gradient norm: 34.15788006
INFO:root:At the start of the epoch: mem (CPU python)=12510.96484375MB; mem (CPU total)=15853.91796875MB
INFO:root:[  142] Training loss: 0.70472197, Validation loss: 0.59193791, Gradient norm: 33.73100163
INFO:root:At the start of the epoch: mem (CPU python)=12532.12890625MB; mem (CPU total)=15874.49609375MB
INFO:root:[  143] Training loss: 0.70554181, Validation loss: 0.59103490, Gradient norm: 34.94471338
INFO:root:At the start of the epoch: mem (CPU python)=12553.29296875MB; mem (CPU total)=15898.30078125MB
INFO:root:[  144] Training loss: 0.70486066, Validation loss: 0.59177041, Gradient norm: 37.04206080
INFO:root:At the start of the epoch: mem (CPU python)=12574.453125MB; mem (CPU total)=15929.53515625MB
INFO:root:[  145] Training loss: 0.70406309, Validation loss: 0.58888584, Gradient norm: 34.97764947
INFO:root:At the start of the epoch: mem (CPU python)=12595.62109375MB; mem (CPU total)=15941.65625MB
INFO:root:[  146] Training loss: 0.70466799, Validation loss: 0.59033779, Gradient norm: 36.43818466
INFO:root:At the start of the epoch: mem (CPU python)=12616.78515625MB; mem (CPU total)=15948.83203125MB
INFO:root:[  147] Training loss: 0.70401794, Validation loss: 0.59081997, Gradient norm: 35.86100640
INFO:root:At the start of the epoch: mem (CPU python)=12637.94921875MB; mem (CPU total)=12487.625MB
INFO:root:[  148] Training loss: 0.70452024, Validation loss: 0.59043155, Gradient norm: 37.36883058
INFO:root:At the start of the epoch: mem (CPU python)=12659.11328125MB; mem (CPU total)=12509.00390625MB
INFO:root:[  149] Training loss: 0.70526228, Validation loss: 0.58947552, Gradient norm: 36.72489354
INFO:root:At the start of the epoch: mem (CPU python)=12680.27734375MB; mem (CPU total)=12530.140625MB
INFO:root:[  150] Training loss: 0.70437153, Validation loss: 0.59015097, Gradient norm: 37.87498755
INFO:root:At the start of the epoch: mem (CPU python)=12701.44140625MB; mem (CPU total)=12550.96484375MB
INFO:root:[  151] Training loss: 0.70360489, Validation loss: 0.59168604, Gradient norm: 39.08811704
INFO:root:At the start of the epoch: mem (CPU python)=12722.60546875MB; mem (CPU total)=12573.36328125MB
INFO:root:[  152] Training loss: 0.70406618, Validation loss: 0.58992513, Gradient norm: 39.46318695
INFO:root:At the start of the epoch: mem (CPU python)=12743.7734375MB; mem (CPU total)=12594.59375MB
INFO:root:[  153] Training loss: 0.70451692, Validation loss: 0.58855899, Gradient norm: 38.52074087
INFO:root:At the start of the epoch: mem (CPU python)=12764.93359375MB; mem (CPU total)=12616.26953125MB
INFO:root:[  154] Training loss: 0.70398848, Validation loss: 0.58922148, Gradient norm: 39.65249676
INFO:root:At the start of the epoch: mem (CPU python)=12786.10546875MB; mem (CPU total)=12637.4921875MB
INFO:root:[  155] Training loss: 0.70416983, Validation loss: 0.58798466, Gradient norm: 39.79457730
INFO:root:At the start of the epoch: mem (CPU python)=12807.26953125MB; mem (CPU total)=12659.0078125MB
INFO:root:[  156] Training loss: 0.70390136, Validation loss: 0.59131415, Gradient norm: 39.96640705
INFO:root:At the start of the epoch: mem (CPU python)=12828.43359375MB; mem (CPU total)=12680.0MB
INFO:root:[  157] Training loss: 0.70383227, Validation loss: 0.59041346, Gradient norm: 39.10115781
INFO:root:At the start of the epoch: mem (CPU python)=12849.6015625MB; mem (CPU total)=12701.23046875MB
INFO:root:[  158] Training loss: 0.70359029, Validation loss: 0.59042121, Gradient norm: 39.95300064
INFO:root:At the start of the epoch: mem (CPU python)=12870.765625MB; mem (CPU total)=12722.46484375MB
INFO:root:[  159] Training loss: 0.70394392, Validation loss: 0.59125979, Gradient norm: 40.81381840
INFO:root:At the start of the epoch: mem (CPU python)=12891.9296875MB; mem (CPU total)=12743.87109375MB
INFO:root:[  160] Training loss: 0.70361645, Validation loss: 0.58970191, Gradient norm: 41.16451996
INFO:root:At the start of the epoch: mem (CPU python)=12913.09375MB; mem (CPU total)=12765.0078125MB
INFO:root:[  161] Training loss: 0.70327248, Validation loss: 0.58968257, Gradient norm: 41.25641853
INFO:root:At the start of the epoch: mem (CPU python)=12934.2578125MB; mem (CPU total)=12786.171875MB
INFO:root:[  162] Training loss: 0.70351085, Validation loss: 0.58964980, Gradient norm: 41.78858457
INFO:root:At the start of the epoch: mem (CPU python)=12955.41796875MB; mem (CPU total)=12806.7109375MB
INFO:root:[  163] Training loss: 0.70352427, Validation loss: 0.58818954, Gradient norm: 43.75452287
INFO:root:At the start of the epoch: mem (CPU python)=12976.5859375MB; mem (CPU total)=12827.62890625MB
INFO:root:[  164] Training loss: 0.70313150, Validation loss: 0.58862547, Gradient norm: 42.37623564
INFO:root:At the start of the epoch: mem (CPU python)=12997.75MB; mem (CPU total)=12849.03125MB
INFO:root:EP 164: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=13018.9140625MB; mem (CPU total)=12870.6875MB
INFO:root:Training the model took 14209.636s.
INFO:root:Emptying the cuda cache took 0.108s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.50942
INFO:root:EnergyScoreValidation: 0.38359
INFO:root:CRPSValidation: 0.15891
INFO:root:Gaussian NLLValidation: 0.49208
INFO:root:CoverageValidation: 0.72068
INFO:root:IntervalWidthValidation: 0.56923
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.40149
INFO:root:EnergyScoreTest: 0.30665
INFO:root:CRPSTest: 0.12746
INFO:root:Gaussian NLLTest: 0.60206
INFO:root:CoverageTest: 0.64423
INFO:root:IntervalWidthTest: 0.39309
INFO:root:After validation: mem (CPU python)=13025.99609375MB; mem (CPU total)=12877.39453125MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=13025.99609375MB; mem (CPU total)=12877.39453125MB
INFO:root:NumberParameters: 284835
INFO:root:GPU memory allocated: 81788928
INFO:root:After setting up the model: mem (CPU python)=13026.90625MB; mem (CPU total)=12878.37890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=13027.14453125MB; mem (CPU total)=12879.36328125MB
INFO:root:[    1] Training loss: 1.76277176, Validation loss: 1.67401297, Gradient norm: 0.19110284
INFO:root:At the start of the epoch: mem (CPU python)=13048.484375MB; mem (CPU total)=12899.953125MB
INFO:root:[    2] Training loss: 1.73136555, Validation loss: 1.60920272, Gradient norm: 0.26192501
INFO:root:At the start of the epoch: mem (CPU python)=13069.66796875MB; mem (CPU total)=12921.2109375MB
INFO:root:[    3] Training loss: 1.68612874, Validation loss: 1.56432126, Gradient norm: 0.46274373
INFO:root:At the start of the epoch: mem (CPU python)=13090.83984375MB; mem (CPU total)=12942.68359375MB
INFO:root:[    4] Training loss: 1.67243407, Validation loss: 1.55588894, Gradient norm: 0.61753329
INFO:root:At the start of the epoch: mem (CPU python)=13112.046875MB; mem (CPU total)=12963.84765625MB
INFO:root:[    5] Training loss: 1.66925689, Validation loss: 1.54708896, Gradient norm: 0.79629371
INFO:root:At the start of the epoch: mem (CPU python)=13133.2109375MB; mem (CPU total)=12985.078125MB
INFO:root:[    6] Training loss: 1.66643984, Validation loss: 1.55248557, Gradient norm: 0.90171330
INFO:root:At the start of the epoch: mem (CPU python)=13154.375MB; mem (CPU total)=13006.2421875MB
INFO:root:[    7] Training loss: 1.66586911, Validation loss: 1.55135202, Gradient norm: 1.07970418
INFO:root:At the start of the epoch: mem (CPU python)=13175.5390625MB; mem (CPU total)=13027.62109375MB
INFO:root:[    8] Training loss: 1.66346842, Validation loss: 1.54358320, Gradient norm: 1.03964750
INFO:root:At the start of the epoch: mem (CPU python)=13196.7109375MB; mem (CPU total)=13048.78125MB
INFO:root:[    9] Training loss: 1.66235107, Validation loss: 1.54280749, Gradient norm: 1.15102534
INFO:root:At the start of the epoch: mem (CPU python)=13217.875MB; mem (CPU total)=13071.609375MB
INFO:root:[   10] Training loss: 1.66112454, Validation loss: 1.53859355, Gradient norm: 1.15967616
INFO:root:At the start of the epoch: mem (CPU python)=13239.0390625MB; mem (CPU total)=13092.76171875MB
INFO:root:[   11] Training loss: 1.66050526, Validation loss: 1.53920361, Gradient norm: 1.27538518
INFO:root:At the start of the epoch: mem (CPU python)=13260.19921875MB; mem (CPU total)=13114.19921875MB
INFO:root:[   12] Training loss: 1.66040970, Validation loss: 1.53921170, Gradient norm: 1.34411145
INFO:root:At the start of the epoch: mem (CPU python)=13281.359375MB; mem (CPU total)=13135.140625MB
INFO:root:[   13] Training loss: 1.65811224, Validation loss: 1.53717276, Gradient norm: 1.27321724
INFO:root:At the start of the epoch: mem (CPU python)=13302.52734375MB; mem (CPU total)=13155.98046875MB
INFO:root:[   14] Training loss: 1.65796646, Validation loss: 1.53524945, Gradient norm: 1.36777533
INFO:root:At the start of the epoch: mem (CPU python)=13323.69140625MB; mem (CPU total)=13176.921875MB
INFO:root:[   15] Training loss: 1.65744094, Validation loss: 1.52850070, Gradient norm: 1.34997285
INFO:root:At the start of the epoch: mem (CPU python)=13344.85546875MB; mem (CPU total)=13198.19140625MB
INFO:root:[   16] Training loss: 1.65664908, Validation loss: 1.52890536, Gradient norm: 1.36372931
INFO:root:At the start of the epoch: mem (CPU python)=13366.01953125MB; mem (CPU total)=13984.18359375MB
INFO:root:[   17] Training loss: 1.65523181, Validation loss: 1.52823055, Gradient norm: 1.30804370
INFO:root:At the start of the epoch: mem (CPU python)=13387.18359375MB; mem (CPU total)=14003.75MB
INFO:root:[   18] Training loss: 1.65509623, Validation loss: 1.53586878, Gradient norm: 1.35282715
INFO:root:At the start of the epoch: mem (CPU python)=13408.34765625MB; mem (CPU total)=14046.05859375MB
INFO:root:[   19] Training loss: 1.65431750, Validation loss: 1.52090877, Gradient norm: 1.29207179
INFO:root:At the start of the epoch: mem (CPU python)=13429.515625MB; mem (CPU total)=14065.2734375MB
INFO:root:[   20] Training loss: 1.65383764, Validation loss: 1.53546940, Gradient norm: 1.27473243
INFO:root:At the start of the epoch: mem (CPU python)=13450.67578125MB; mem (CPU total)=14095.328125MB
INFO:root:[   21] Training loss: 1.65260858, Validation loss: 1.52916151, Gradient norm: 1.22795072
INFO:root:At the start of the epoch: mem (CPU python)=13471.83984375MB; mem (CPU total)=14115.96875MB
INFO:root:[   22] Training loss: 1.65294955, Validation loss: 1.53038405, Gradient norm: 1.27835126
INFO:root:At the start of the epoch: mem (CPU python)=13493.00390625MB; mem (CPU total)=14136.70703125MB
INFO:root:[   23] Training loss: 1.65153690, Validation loss: 1.53359183, Gradient norm: 1.23677455
INFO:root:At the start of the epoch: mem (CPU python)=13514.16796875MB; mem (CPU total)=14158.39453125MB
INFO:root:[   24] Training loss: 1.65141476, Validation loss: 1.52628334, Gradient norm: 1.25022114
INFO:root:At the start of the epoch: mem (CPU python)=13535.3359375MB; mem (CPU total)=14041.23828125MB
INFO:root:[   25] Training loss: 1.65102724, Validation loss: 1.52396457, Gradient norm: 1.25022047
INFO:root:At the start of the epoch: mem (CPU python)=13556.5MB; mem (CPU total)=14118.0859375MB
INFO:root:[   26] Training loss: 1.65085662, Validation loss: 1.54072311, Gradient norm: 1.22751926
INFO:root:At the start of the epoch: mem (CPU python)=13577.6640625MB; mem (CPU total)=14153.32421875MB
INFO:root:[   27] Training loss: 1.64948592, Validation loss: 1.53399150, Gradient norm: 1.11656538
INFO:root:At the start of the epoch: mem (CPU python)=13598.828125MB; mem (CPU total)=14177.84765625MB
INFO:root:[   28] Training loss: 1.64941039, Validation loss: 1.53485766, Gradient norm: 1.21632404
INFO:root:At the start of the epoch: mem (CPU python)=13619.9921875MB; mem (CPU total)=14201.68359375MB
INFO:root:[   29] Training loss: 1.64899323, Validation loss: 1.52255998, Gradient norm: 1.12943267
INFO:root:At the start of the epoch: mem (CPU python)=13641.15625MB; mem (CPU total)=14229.9375MB
INFO:root:[   30] Training loss: 1.64859874, Validation loss: 1.53827240, Gradient norm: 1.19547601
INFO:root:At the start of the epoch: mem (CPU python)=13662.31640625MB; mem (CPU total)=14250.46484375MB
INFO:root:[   31] Training loss: 1.64822902, Validation loss: 1.53460194, Gradient norm: 1.10442960
INFO:root:At the start of the epoch: mem (CPU python)=13683.48046875MB; mem (CPU total)=14274.48828125MB
INFO:root:[   32] Training loss: 1.64843830, Validation loss: 1.53486287, Gradient norm: 1.17899928
INFO:root:At the start of the epoch: mem (CPU python)=13704.64453125MB; mem (CPU total)=14297.1640625MB
INFO:root:[   33] Training loss: 1.64798432, Validation loss: 1.52530948, Gradient norm: 1.19137455
INFO:root:At the start of the epoch: mem (CPU python)=13725.80859375MB; mem (CPU total)=14316.5625MB
INFO:root:[   34] Training loss: 1.64740262, Validation loss: 1.52878186, Gradient norm: 1.14876051
INFO:root:At the start of the epoch: mem (CPU python)=13746.9765625MB; mem (CPU total)=14342.49609375MB
INFO:root:[   35] Training loss: 1.68927859, Validation loss: 1.54491235, Gradient norm: 2.75916140
INFO:root:At the start of the epoch: mem (CPU python)=13768.140625MB; mem (CPU total)=14370.47265625MB
INFO:root:[   36] Training loss: 1.65689652, Validation loss: 1.52276919, Gradient norm: 1.43575881
INFO:root:At the start of the epoch: mem (CPU python)=13789.3046875MB; mem (CPU total)=14389.39453125MB
INFO:root:[   37] Training loss: 1.64805983, Validation loss: 1.52493809, Gradient norm: 1.11387697
INFO:root:At the start of the epoch: mem (CPU python)=13810.46875MB; mem (CPU total)=14414.265625MB
INFO:root:[   38] Training loss: 1.64682771, Validation loss: 1.52759248, Gradient norm: 1.11045841
INFO:root:At the start of the epoch: mem (CPU python)=13831.6328125MB; mem (CPU total)=14439.125MB
INFO:root:[   39] Training loss: 1.64553517, Validation loss: 1.52374245, Gradient norm: 1.05863976
INFO:root:At the start of the epoch: mem (CPU python)=13852.79296875MB; mem (CPU total)=14460.1875MB
INFO:root:[   40] Training loss: 1.64597213, Validation loss: 1.52316835, Gradient norm: 1.13682258
INFO:root:At the start of the epoch: mem (CPU python)=13873.9609375MB; mem (CPU total)=14481.11328125MB
INFO:root:[   41] Training loss: 1.64551833, Validation loss: 1.53054718, Gradient norm: 1.08904055
INFO:root:At the start of the epoch: mem (CPU python)=13895.125MB; mem (CPU total)=14502.33984375MB
INFO:root:[   42] Training loss: 1.64545224, Validation loss: 1.52510715, Gradient norm: 1.14128507
INFO:root:At the start of the epoch: mem (CPU python)=13916.2890625MB; mem (CPU total)=14556.08984375MB
INFO:root:[   43] Training loss: 1.64458598, Validation loss: 1.52827254, Gradient norm: 1.09621866
INFO:root:At the start of the epoch: mem (CPU python)=13937.453125MB; mem (CPU total)=14547.98046875MB
INFO:root:[   44] Training loss: 1.64446811, Validation loss: 1.51576389, Gradient norm: 1.16470611
INFO:root:At the start of the epoch: mem (CPU python)=13958.6171875MB; mem (CPU total)=14569.62890625MB
INFO:root:[   45] Training loss: 1.64446040, Validation loss: 1.52958685, Gradient norm: 1.19496966
INFO:root:At the start of the epoch: mem (CPU python)=13979.78125MB; mem (CPU total)=14585.59765625MB
INFO:root:[   46] Training loss: 1.64397154, Validation loss: 1.51909863, Gradient norm: 1.10815103
INFO:root:At the start of the epoch: mem (CPU python)=14000.9453125MB; mem (CPU total)=14609.75MB
INFO:root:[   47] Training loss: 1.64157738, Validation loss: 1.52132313, Gradient norm: 1.31387079
INFO:root:At the start of the epoch: mem (CPU python)=14022.109375MB; mem (CPU total)=14578.25MB
INFO:root:[   48] Training loss: 1.64454352, Validation loss: 1.51969861, Gradient norm: 1.50310994
INFO:root:At the start of the epoch: mem (CPU python)=14043.2734375MB; mem (CPU total)=14646.56640625MB
INFO:root:[   49] Training loss: 1.63878787, Validation loss: 1.51181612, Gradient norm: 1.34187842
INFO:root:At the start of the epoch: mem (CPU python)=14064.43359375MB; mem (CPU total)=14683.48828125MB
INFO:root:[   50] Training loss: 1.63751875, Validation loss: 1.51866185, Gradient norm: 1.28159164
INFO:root:At the start of the epoch: mem (CPU python)=14085.59765625MB; mem (CPU total)=14708.21875MB
INFO:root:[   51] Training loss: 1.63766578, Validation loss: 1.51241024, Gradient norm: 1.29020183
INFO:root:At the start of the epoch: mem (CPU python)=14106.765625MB; mem (CPU total)=14734.10546875MB
INFO:root:[   52] Training loss: 1.63689666, Validation loss: 1.51482599, Gradient norm: 1.25228528
INFO:root:At the start of the epoch: mem (CPU python)=14127.93359375MB; mem (CPU total)=14756.625MB
INFO:root:[   53] Training loss: 1.63869293, Validation loss: 1.51361635, Gradient norm: 1.35881097
INFO:root:At the start of the epoch: mem (CPU python)=14149.09765625MB; mem (CPU total)=14779.921875MB
INFO:root:[   54] Training loss: 1.63624520, Validation loss: 1.51090344, Gradient norm: 1.28435665
INFO:root:At the start of the epoch: mem (CPU python)=14170.26171875MB; mem (CPU total)=14799.39453125MB
INFO:root:[   55] Training loss: 1.63670593, Validation loss: 1.51066614, Gradient norm: 1.31698103
INFO:root:At the start of the epoch: mem (CPU python)=14191.42578125MB; mem (CPU total)=14824.62109375MB
INFO:root:[   56] Training loss: 1.63674822, Validation loss: 1.50838416, Gradient norm: 1.28974494
INFO:root:At the start of the epoch: mem (CPU python)=14212.58984375MB; mem (CPU total)=14842.05859375MB
INFO:root:[   57] Training loss: 1.71173510, Validation loss: 1.52879105, Gradient norm: 3.86404706
INFO:root:At the start of the epoch: mem (CPU python)=14233.75390625MB; mem (CPU total)=14863.14453125MB
INFO:root:[   58] Training loss: 1.65579131, Validation loss: 1.51355839, Gradient norm: 1.94429109
INFO:root:At the start of the epoch: mem (CPU python)=14254.91796875MB; mem (CPU total)=14884.3203125MB
INFO:root:[   59] Training loss: 1.64264981, Validation loss: 1.50716612, Gradient norm: 1.49165061
INFO:root:At the start of the epoch: mem (CPU python)=14276.08203125MB; mem (CPU total)=14904.953125MB
INFO:root:[   60] Training loss: 1.63857065, Validation loss: 1.50609635, Gradient norm: 1.37887570
INFO:root:At the start of the epoch: mem (CPU python)=14297.24609375MB; mem (CPU total)=14926.7109375MB
INFO:root:[   61] Training loss: 1.63793914, Validation loss: 1.50512886, Gradient norm: 1.38102584
INFO:root:At the start of the epoch: mem (CPU python)=14318.41015625MB; mem (CPU total)=14947.75MB
INFO:root:[   62] Training loss: 1.63702125, Validation loss: 1.50651098, Gradient norm: 1.39608756
INFO:root:At the start of the epoch: mem (CPU python)=14339.57421875MB; mem (CPU total)=14966.75MB
INFO:root:[   63] Training loss: 1.63700150, Validation loss: 1.51687944, Gradient norm: 1.40354453
INFO:root:At the start of the epoch: mem (CPU python)=14360.73828125MB; mem (CPU total)=14993.7734375MB
INFO:root:[   64] Training loss: 1.63865890, Validation loss: 1.52697709, Gradient norm: 1.41696167
INFO:root:At the start of the epoch: mem (CPU python)=14381.90234375MB; mem (CPU total)=15021.29296875MB
INFO:root:[   65] Training loss: 1.63904225, Validation loss: 1.50952895, Gradient norm: 1.53889044
INFO:root:At the start of the epoch: mem (CPU python)=14403.06640625MB; mem (CPU total)=15040.47265625MB
INFO:root:[   66] Training loss: 1.63667432, Validation loss: 1.50641592, Gradient norm: 1.37130594
INFO:root:At the start of the epoch: mem (CPU python)=14424.23046875MB; mem (CPU total)=15062.00390625MB
INFO:root:[   67] Training loss: 1.63604567, Validation loss: 1.51275506, Gradient norm: 1.33351713
INFO:root:At the start of the epoch: mem (CPU python)=14445.390625MB; mem (CPU total)=15087.34375MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   68] Training loss: 1.63667400, Validation loss: 1.50836635, Gradient norm: 1.43562948
INFO:root:At the start of the epoch: mem (CPU python)=14466.5546875MB; mem (CPU total)=15114.8203125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   69] Training loss: 1.63019880, Validation loss: 1.49989595, Gradient norm: 1.13553144
INFO:root:At the start of the epoch: mem (CPU python)=14487.72265625MB; mem (CPU total)=15138.984375MB
INFO:root:[   70] Training loss: 1.62848670, Validation loss: 1.49885614, Gradient norm: 1.11059622
INFO:root:At the start of the epoch: mem (CPU python)=14508.88671875MB; mem (CPU total)=15155.59765625MB
INFO:root:[   71] Training loss: 1.62904740, Validation loss: 1.50035009, Gradient norm: 1.66637629
INFO:root:At the start of the epoch: mem (CPU python)=14530.05078125MB; mem (CPU total)=15178.33203125MB
INFO:root:[   72] Training loss: 1.62889655, Validation loss: 1.50059177, Gradient norm: 1.71467232
INFO:root:At the start of the epoch: mem (CPU python)=14551.21484375MB; mem (CPU total)=15199.20703125MB
INFO:root:[   73] Training loss: 1.62974491, Validation loss: 1.49982124, Gradient norm: 2.13102120
INFO:root:At the start of the epoch: mem (CPU python)=14572.37890625MB; mem (CPU total)=15220.453125MB
INFO:root:[   74] Training loss: 1.63007483, Validation loss: 1.50732724, Gradient norm: 2.52821660
INFO:root:At the start of the epoch: mem (CPU python)=14593.546875MB; mem (CPU total)=15240.125MB
INFO:root:[   75] Training loss: 1.63072273, Validation loss: 1.49922128, Gradient norm: 2.71735698
INFO:root:At the start of the epoch: mem (CPU python)=14614.7109375MB; mem (CPU total)=15265.4296875MB
INFO:root:[   76] Training loss: 1.62948049, Validation loss: 1.50383507, Gradient norm: 2.50962380
INFO:root:At the start of the epoch: mem (CPU python)=14635.875MB; mem (CPU total)=15285.94140625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   77] Training loss: 1.62963247, Validation loss: 1.50033603, Gradient norm: 2.73347087
INFO:root:At the start of the epoch: mem (CPU python)=14657.03515625MB; mem (CPU total)=15305.9609375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   78] Training loss: 1.62764097, Validation loss: 1.49900087, Gradient norm: 2.02559500
INFO:root:At the start of the epoch: mem (CPU python)=14678.203125MB; mem (CPU total)=15326.65234375MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   79] Training loss: 1.62669473, Validation loss: 1.49750708, Gradient norm: 1.74030949
INFO:root:At the start of the epoch: mem (CPU python)=14699.3671875MB; mem (CPU total)=15350.27734375MB
INFO:root:[   80] Training loss: 1.62638131, Validation loss: 1.49800432, Gradient norm: 1.42222086
INFO:root:At the start of the epoch: mem (CPU python)=14720.52734375MB; mem (CPU total)=15369.09765625MB
INFO:root:[   81] Training loss: 1.62630901, Validation loss: 1.49768042, Gradient norm: 1.58215828
INFO:root:At the start of the epoch: mem (CPU python)=14741.69140625MB; mem (CPU total)=15392.06640625MB
INFO:root:[   82] Training loss: 1.62631479, Validation loss: 1.49806326, Gradient norm: 1.77793589
INFO:root:At the start of the epoch: mem (CPU python)=14762.85546875MB; mem (CPU total)=15411.43359375MB
INFO:root:[   83] Training loss: 1.62649811, Validation loss: 1.49905296, Gradient norm: 1.95989256
INFO:root:At the start of the epoch: mem (CPU python)=14784.01953125MB; mem (CPU total)=15434.69921875MB
INFO:root:[   84] Training loss: 1.62659226, Validation loss: 1.49736315, Gradient norm: 2.08124818
INFO:root:At the start of the epoch: mem (CPU python)=14805.18359375MB; mem (CPU total)=14728.03125MB
INFO:root:[   85] Training loss: 1.62650589, Validation loss: 1.49889948, Gradient norm: 2.12035864
INFO:root:At the start of the epoch: mem (CPU python)=14826.34765625MB; mem (CPU total)=16561.0625MB
INFO:root:[   86] Training loss: 1.62653324, Validation loss: 1.49878386, Gradient norm: 2.41488744
INFO:root:At the start of the epoch: mem (CPU python)=14847.51171875MB; mem (CPU total)=16672.45703125MB
INFO:root:[   87] Training loss: 1.62704764, Validation loss: 1.49777364, Gradient norm: 2.46105415
INFO:root:At the start of the epoch: mem (CPU python)=14868.67578125MB; mem (CPU total)=16713.296875MB
INFO:root:[   88] Training loss: 1.62658441, Validation loss: 1.50080145, Gradient norm: 2.61047886
INFO:root:At the start of the epoch: mem (CPU python)=14889.83984375MB; mem (CPU total)=16750.08203125MB
INFO:root:[   89] Training loss: 1.62661123, Validation loss: 1.49851541, Gradient norm: 2.80158503
INFO:root:At the start of the epoch: mem (CPU python)=14911.00390625MB; mem (CPU total)=16750.984375MB
INFO:root:[   90] Training loss: 1.62657243, Validation loss: 1.49724011, Gradient norm: 2.96121713
INFO:root:At the start of the epoch: mem (CPU python)=14932.16796875MB; mem (CPU total)=16826.23828125MB
INFO:root:[   91] Training loss: 1.62681687, Validation loss: 1.50046668, Gradient norm: 2.94744134
INFO:root:At the start of the epoch: mem (CPU python)=14953.3359375MB; mem (CPU total)=16805.4453125MB
INFO:root:[   92] Training loss: 1.62696844, Validation loss: 1.50053890, Gradient norm: 3.32584825
INFO:root:At the start of the epoch: mem (CPU python)=14974.5MB; mem (CPU total)=16823.95703125MB
INFO:root:[   93] Training loss: 1.62678960, Validation loss: 1.49914992, Gradient norm: 3.37814859
INFO:root:At the start of the epoch: mem (CPU python)=14995.6640625MB; mem (CPU total)=16829.35546875MB
INFO:root:[   94] Training loss: 1.62683819, Validation loss: 1.49905366, Gradient norm: 3.46867182
INFO:root:At the start of the epoch: mem (CPU python)=15016.828125MB; mem (CPU total)=16834.53125MB
INFO:root:[   95] Training loss: 1.62676966, Validation loss: 1.49895975, Gradient norm: 3.55270479
INFO:root:At the start of the epoch: mem (CPU python)=15037.9921875MB; mem (CPU total)=16940.93359375MB
INFO:root:[   96] Training loss: 1.62682835, Validation loss: 1.49879018, Gradient norm: 3.57709112
INFO:root:At the start of the epoch: mem (CPU python)=15059.15625MB; mem (CPU total)=16905.0MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   97] Training loss: 1.62684005, Validation loss: 1.49929013, Gradient norm: 3.88257107
INFO:root:At the start of the epoch: mem (CPU python)=15080.31640625MB; mem (CPU total)=16936.16796875MB
INFO:root:[   98] Training loss: 1.62658642, Validation loss: 1.49861215, Gradient norm: 3.07904829
INFO:root:At the start of the epoch: mem (CPU python)=15101.48046875MB; mem (CPU total)=16993.75MB
INFO:root:[   99] Training loss: 1.62650020, Validation loss: 1.49881772, Gradient norm: 3.12363738
INFO:root:At the start of the epoch: mem (CPU python)=15122.6484375MB; mem (CPU total)=16919.29296875MB
INFO:root:EP 99: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=15143.8125MB; mem (CPU total)=16967.87890625MB
INFO:root:[  101] Training loss: 0.65329330, Validation loss: 0.54404706, Gradient norm: 41.41015855
INFO:root:At the start of the epoch: mem (CPU python)=15164.9765625MB; mem (CPU total)=17018.4296875MB
INFO:root:[  102] Training loss: 0.64741468, Validation loss: 0.54155205, Gradient norm: 40.03192471
INFO:root:At the start of the epoch: mem (CPU python)=15186.140625MB; mem (CPU total)=17038.2890625MB
INFO:root:[  103] Training loss: 0.64606163, Validation loss: 0.54871248, Gradient norm: 39.15011863
INFO:root:At the start of the epoch: mem (CPU python)=15207.30859375MB; mem (CPU total)=17086.28515625MB
INFO:root:[  104] Training loss: 0.64665687, Validation loss: 0.54093957, Gradient norm: 41.48710818
INFO:root:At the start of the epoch: mem (CPU python)=15228.47265625MB; mem (CPU total)=17108.2109375MB
INFO:root:[  105] Training loss: 0.64461424, Validation loss: 0.54400259, Gradient norm: 37.92411933
INFO:root:At the start of the epoch: mem (CPU python)=15249.6328125MB; mem (CPU total)=17106.1640625MB
INFO:root:[  106] Training loss: 0.64358226, Validation loss: 0.53935856, Gradient norm: 36.95218596
INFO:root:At the start of the epoch: mem (CPU python)=15270.796875MB; mem (CPU total)=17114.94140625MB
INFO:root:[  107] Training loss: 0.64356019, Validation loss: 0.54173021, Gradient norm: 39.44659840
INFO:root:At the start of the epoch: mem (CPU python)=15291.9609375MB; mem (CPU total)=17156.34375MB
INFO:root:[  108] Training loss: 0.64393574, Validation loss: 0.53885257, Gradient norm: 40.23220506
INFO:root:At the start of the epoch: mem (CPU python)=15313.12890625MB; mem (CPU total)=17152.77734375MB
INFO:root:[  109] Training loss: 0.64254894, Validation loss: 0.54019289, Gradient norm: 38.82114739
INFO:root:At the start of the epoch: mem (CPU python)=15334.29296875MB; mem (CPU total)=17212.7578125MB
INFO:root:[  110] Training loss: 0.64221432, Validation loss: 0.53973442, Gradient norm: 40.04937346
INFO:root:At the start of the epoch: mem (CPU python)=15355.45703125MB; mem (CPU total)=17229.40234375MB
INFO:root:[  111] Training loss: 0.64323437, Validation loss: 0.53914394, Gradient norm: 40.62195663
INFO:root:At the start of the epoch: mem (CPU python)=15376.62109375MB; mem (CPU total)=17254.59375MB
INFO:root:[  112] Training loss: 0.64262577, Validation loss: 0.53976275, Gradient norm: 41.17453682
INFO:root:At the start of the epoch: mem (CPU python)=15397.78515625MB; mem (CPU total)=17256.66796875MB
INFO:root:[  113] Training loss: 0.64227114, Validation loss: 0.53984802, Gradient norm: 40.16691597
INFO:root:At the start of the epoch: mem (CPU python)=15418.953125MB; mem (CPU total)=17291.66015625MB
INFO:root:[  114] Training loss: 0.64218941, Validation loss: 0.53761211, Gradient norm: 41.49463539
INFO:root:At the start of the epoch: mem (CPU python)=15440.11328125MB; mem (CPU total)=17359.1328125MB
INFO:root:[  115] Training loss: 0.64161503, Validation loss: 0.54177475, Gradient norm: 40.09551211
INFO:root:At the start of the epoch: mem (CPU python)=15461.2734375MB; mem (CPU total)=17344.00390625MB
INFO:root:[  116] Training loss: 0.64059757, Validation loss: 0.53767434, Gradient norm: 43.12601017
INFO:root:At the start of the epoch: mem (CPU python)=15482.4375MB; mem (CPU total)=17375.46875MB
INFO:root:[  117] Training loss: 0.64051962, Validation loss: 0.53880579, Gradient norm: 40.58400694
INFO:root:At the start of the epoch: mem (CPU python)=15503.6015625MB; mem (CPU total)=17405.1875MB
INFO:root:[  118] Training loss: 0.64132521, Validation loss: 0.53647755, Gradient norm: 42.19024337
INFO:root:At the start of the epoch: mem (CPU python)=15524.765625MB; mem (CPU total)=17371.8515625MB
INFO:root:[  119] Training loss: 0.64119734, Validation loss: 0.53845119, Gradient norm: 42.83356511
INFO:root:At the start of the epoch: mem (CPU python)=15545.9296875MB; mem (CPU total)=17419.296875MB
INFO:root:[  120] Training loss: 0.64089016, Validation loss: 0.53617929, Gradient norm: 43.75972450
INFO:root:At the start of the epoch: mem (CPU python)=15567.09765625MB; mem (CPU total)=17454.296875MB
INFO:root:[  121] Training loss: 0.64055446, Validation loss: 0.53712827, Gradient norm: 41.09484259
INFO:root:At the start of the epoch: mem (CPU python)=15588.26171875MB; mem (CPU total)=17524.16796875MB
INFO:root:[  122] Training loss: 0.63986764, Validation loss: 0.53690347, Gradient norm: 42.82789576
INFO:root:At the start of the epoch: mem (CPU python)=15609.42578125MB; mem (CPU total)=17499.2890625MB
INFO:root:[  123] Training loss: 0.63986923, Validation loss: 0.53768602, Gradient norm: 44.47439865
INFO:root:At the start of the epoch: mem (CPU python)=15630.58984375MB; mem (CPU total)=17521.69140625MB
INFO:root:[  124] Training loss: 0.64035860, Validation loss: 0.53666232, Gradient norm: 45.30730515
INFO:root:At the start of the epoch: mem (CPU python)=15651.75MB; mem (CPU total)=17589.046875MB
INFO:root:[  125] Training loss: 0.64008769, Validation loss: 0.53880574, Gradient norm: 45.63851263
INFO:root:At the start of the epoch: mem (CPU python)=15672.9140625MB; mem (CPU total)=17615.17578125MB
INFO:root:[  126] Training loss: 0.63973154, Validation loss: 0.53589237, Gradient norm: 43.01254347
INFO:root:At the start of the epoch: mem (CPU python)=15694.08203125MB; mem (CPU total)=17605.5859375MB
INFO:root:[  127] Training loss: 0.63872711, Validation loss: 0.53869130, Gradient norm: 42.99041134
INFO:root:At the start of the epoch: mem (CPU python)=15715.24609375MB; mem (CPU total)=17644.79296875MB
INFO:root:[  128] Training loss: 0.63878608, Validation loss: 0.53832431, Gradient norm: 45.55725213
INFO:root:At the start of the epoch: mem (CPU python)=15736.41015625MB; mem (CPU total)=17702.30859375MB
INFO:root:[  129] Training loss: 0.63912990, Validation loss: 0.53492030, Gradient norm: 43.64399453
INFO:root:At the start of the epoch: mem (CPU python)=15757.57421875MB; mem (CPU total)=17668.0625MB
INFO:root:[  130] Training loss: 0.63985642, Validation loss: 0.53979606, Gradient norm: 44.34859124
INFO:root:At the start of the epoch: mem (CPU python)=15778.73828125MB; mem (CPU total)=17706.2734375MB
INFO:root:[  131] Training loss: 0.64001315, Validation loss: 0.53907227, Gradient norm: 45.85452109
INFO:root:At the start of the epoch: mem (CPU python)=15799.8984375MB; mem (CPU total)=17711.50390625MB
INFO:root:[  132] Training loss: 0.63973862, Validation loss: 0.53499598, Gradient norm: 48.44874538
INFO:root:At the start of the epoch: mem (CPU python)=15821.06640625MB; mem (CPU total)=17778.28125MB
INFO:root:[  133] Training loss: 0.63931806, Validation loss: 0.53575605, Gradient norm: 46.42087095
INFO:root:At the start of the epoch: mem (CPU python)=15842.2265625MB; mem (CPU total)=17708.45703125MB
INFO:root:[  134] Training loss: 0.63885697, Validation loss: 0.53824008, Gradient norm: 45.97071785
INFO:root:At the start of the epoch: mem (CPU python)=15863.390625MB; mem (CPU total)=17781.0859375MB
INFO:root:[  135] Training loss: 0.63897668, Validation loss: 0.53524388, Gradient norm: 50.59169485
INFO:root:At the start of the epoch: mem (CPU python)=15884.55859375MB; mem (CPU total)=17781.6953125MB
INFO:root:[  136] Training loss: 0.63933036, Validation loss: 0.53432104, Gradient norm: 50.70548138
INFO:root:At the start of the epoch: mem (CPU python)=15905.7265625MB; mem (CPU total)=17835.62890625MB
INFO:root:[  137] Training loss: 0.63977612, Validation loss: 0.53666657, Gradient norm: 48.43939073
INFO:root:At the start of the epoch: mem (CPU python)=15926.88671875MB; mem (CPU total)=17859.96484375MB
INFO:root:[  138] Training loss: 0.63869692, Validation loss: 0.53474232, Gradient norm: 46.70037870
INFO:root:At the start of the epoch: mem (CPU python)=15948.0546875MB; mem (CPU total)=17908.484375MB
INFO:root:[  139] Training loss: 0.63894889, Validation loss: 0.53563113, Gradient norm: 48.24941735
INFO:root:At the start of the epoch: mem (CPU python)=15969.21875MB; mem (CPU total)=17899.21484375MB
INFO:root:[  140] Training loss: 0.63911155, Validation loss: 0.53468140, Gradient norm: 51.06698164
INFO:root:At the start of the epoch: mem (CPU python)=15990.3828125MB; mem (CPU total)=17929.65234375MB
INFO:root:[  141] Training loss: 0.63846197, Validation loss: 0.53394906, Gradient norm: 48.69840341
INFO:root:At the start of the epoch: mem (CPU python)=16011.546875MB; mem (CPU total)=17911.0MB
INFO:root:[  142] Training loss: 0.63888438, Validation loss: 0.53519056, Gradient norm: 51.69927084
INFO:root:At the start of the epoch: mem (CPU python)=16032.7109375MB; mem (CPU total)=17911.80078125MB
INFO:root:[  143] Training loss: 0.63887220, Validation loss: 0.53862037, Gradient norm: 48.73254738
INFO:root:At the start of the epoch: mem (CPU python)=16053.875MB; mem (CPU total)=17961.7578125MB
INFO:root:[  144] Training loss: 0.63907665, Validation loss: 0.53740574, Gradient norm: 54.01590041
INFO:root:At the start of the epoch: mem (CPU python)=16075.0390625MB; mem (CPU total)=17928.296875MB
INFO:root:[  145] Training loss: 0.63841509, Validation loss: 0.53542678, Gradient norm: 51.80949500
INFO:root:At the start of the epoch: mem (CPU python)=16096.203125MB; mem (CPU total)=17996.04296875MB
INFO:root:[  146] Training loss: 0.63932225, Validation loss: 0.53480439, Gradient norm: 52.44338114
INFO:root:At the start of the epoch: mem (CPU python)=16117.3671875MB; mem (CPU total)=17991.09375MB
INFO:root:[  147] Training loss: 0.63778599, Validation loss: 0.53657015, Gradient norm: 50.14616849
INFO:root:At the start of the epoch: mem (CPU python)=16138.53515625MB; mem (CPU total)=18031.5703125MB
INFO:root:[  148] Training loss: 0.63860630, Validation loss: 0.53543693, Gradient norm: 52.77077969
INFO:root:At the start of the epoch: mem (CPU python)=16159.6953125MB; mem (CPU total)=18042.28125MB
INFO:root:[  149] Training loss: 0.63863178, Validation loss: 0.53639328, Gradient norm: 53.72431691
INFO:root:At the start of the epoch: mem (CPU python)=16180.859375MB; mem (CPU total)=18082.38671875MB
INFO:root:[  150] Training loss: 0.63904507, Validation loss: 0.53649919, Gradient norm: 54.94199919
INFO:root:At the start of the epoch: mem (CPU python)=16202.0234375MB; mem (CPU total)=18093.015625MB
INFO:root:EP 150: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16223.18359375MB; mem (CPU total)=18135.40625MB
INFO:root:Training the model took 12514.426s.
INFO:root:Emptying the cuda cache took 0.111s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.45887
INFO:root:EnergyScoreValidation: 0.344
INFO:root:CRPSValidation: 0.14254
INFO:root:Gaussian NLLValidation: 0.29277
INFO:root:CoverageValidation: 0.76013
INFO:root:IntervalWidthValidation: 0.55816
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.37191
INFO:root:EnergyScoreTest: 0.28637
INFO:root:CRPSTest: 0.11559
INFO:root:Gaussian NLLTest: 0.37633
INFO:root:CoverageTest: 0.70083
INFO:root:IntervalWidthTest: 0.38064
INFO:root:After validation: mem (CPU python)=16230.1171875MB; mem (CPU total)=18178.19140625MB
