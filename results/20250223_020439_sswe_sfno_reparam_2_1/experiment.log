INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=579.875MB; mem (CPU total)=3377.71484375MB
INFO:root:############### Starting experiment with config file sswe/sfno_sr_reparam_2_3.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SSWE', 'max_training_set_size': 5000, 'pred_horizon': 1, 'train_horizon': 2, 'stepwise_evaluation': False}
INFO:root:After loading the datasets: mem (CPU python)=590.78125MB; mem (CPU total)=3379.234375MB
INFO:root:###1 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=592.203125MB; mem (CPU total)=3387.61328125MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=2240.36328125MB; mem (CPU total)=4771.0859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2250.0MB; mem (CPU total)=4743.98046875MB
INFO:root:[    1] Training loss: 1.24556711, Validation loss: 1.23041133, Gradient norm: 0.14100787
INFO:root:At the start of the epoch: mem (CPU python)=4422.94140625MB; mem (CPU total)=6568.0MB
INFO:root:[    2] Training loss: 1.21436371, Validation loss: 1.19782010, Gradient norm: 0.14232330
INFO:root:At the start of the epoch: mem (CPU python)=4445.015625MB; mem (CPU total)=6493.38671875MB
INFO:root:[    3] Training loss: 1.19359729, Validation loss: 1.18754994, Gradient norm: 0.15511589
INFO:root:At the start of the epoch: mem (CPU python)=4466.25MB; mem (CPU total)=6537.8359375MB
INFO:root:[    4] Training loss: 1.18334461, Validation loss: 1.17893569, Gradient norm: 0.15438312
INFO:root:At the start of the epoch: mem (CPU python)=4487.4296875MB; mem (CPU total)=6598.8671875MB
INFO:root:[    5] Training loss: 1.17657478, Validation loss: 1.17517091, Gradient norm: 0.15732013
INFO:root:At the start of the epoch: mem (CPU python)=4511.23828125MB; mem (CPU total)=6513.41015625MB
INFO:root:[    6] Training loss: 1.17297768, Validation loss: 1.17128225, Gradient norm: 0.16641289
INFO:root:At the start of the epoch: mem (CPU python)=4532.421875MB; mem (CPU total)=6796.0859375MB
INFO:root:[    7] Training loss: 1.17037163, Validation loss: 1.16937845, Gradient norm: 0.16886344
INFO:root:At the start of the epoch: mem (CPU python)=4553.6015625MB; mem (CPU total)=6608.85546875MB
INFO:root:[    8] Training loss: 1.16930345, Validation loss: 1.16784193, Gradient norm: 0.17441798
INFO:root:At the start of the epoch: mem (CPU python)=4574.7734375MB; mem (CPU total)=6734.13671875MB
INFO:root:[    9] Training loss: 1.16660684, Validation loss: 1.16784236, Gradient norm: 0.17049651
INFO:root:At the start of the epoch: mem (CPU python)=4595.93359375MB; mem (CPU total)=6749.8125MB
INFO:root:[   10] Training loss: 1.16658212, Validation loss: 1.16793374, Gradient norm: 0.17393190
INFO:root:At the start of the epoch: mem (CPU python)=4617.09765625MB; mem (CPU total)=6807.69140625MB
INFO:root:[   11] Training loss: 1.16474574, Validation loss: 1.16229503, Gradient norm: 0.17115699
INFO:root:At the start of the epoch: mem (CPU python)=4638.26953125MB; mem (CPU total)=6835.9609375MB
INFO:root:[   12] Training loss: 1.15935614, Validation loss: 1.16231206, Gradient norm: 0.18761159
INFO:root:At the start of the epoch: mem (CPU python)=4659.42578125MB; mem (CPU total)=6735.79296875MB
INFO:root:[   13] Training loss: 1.15825248, Validation loss: 1.16058295, Gradient norm: 0.19077852
INFO:root:At the start of the epoch: mem (CPU python)=4680.59765625MB; mem (CPU total)=6699.98046875MB
INFO:root:[   14] Training loss: 1.15758771, Validation loss: 1.15885889, Gradient norm: 0.19524535
INFO:root:At the start of the epoch: mem (CPU python)=4701.7578125MB; mem (CPU total)=6890.9765625MB
INFO:root:[   15] Training loss: 1.15764402, Validation loss: 1.16437960, Gradient norm: 0.20441339
INFO:root:At the start of the epoch: mem (CPU python)=4722.91796875MB; mem (CPU total)=6760.35546875MB
INFO:root:[   16] Training loss: 1.15916298, Validation loss: 1.16102326, Gradient norm: 0.22726326
INFO:root:At the start of the epoch: mem (CPU python)=4744.08203125MB; mem (CPU total)=6822.19140625MB
INFO:root:[   17] Training loss: 1.15848902, Validation loss: 1.16976349, Gradient norm: 0.21926431
INFO:root:At the start of the epoch: mem (CPU python)=4765.28515625MB; mem (CPU total)=6854.484375MB
INFO:root:[   18] Training loss: 1.15871312, Validation loss: 1.18169751, Gradient norm: 0.22964529
INFO:root:At the start of the epoch: mem (CPU python)=4786.78515625MB; mem (CPU total)=6882.44921875MB
INFO:root:[   19] Training loss: 1.15988088, Validation loss: 1.16702459, Gradient norm: 0.24542627
INFO:root:At the start of the epoch: mem (CPU python)=4810.17578125MB; mem (CPU total)=6971.015625MB
INFO:root:[   20] Training loss: 1.15894602, Validation loss: 1.16287973, Gradient norm: 0.26334608
INFO:root:At the start of the epoch: mem (CPU python)=4831.8046875MB; mem (CPU total)=6944.76953125MB
INFO:root:[   21] Training loss: 1.15938002, Validation loss: 1.16703694, Gradient norm: 0.27491254
INFO:root:At the start of the epoch: mem (CPU python)=4852.96875MB; mem (CPU total)=6924.05859375MB
INFO:root:[   22] Training loss: 1.15909278, Validation loss: 1.16607430, Gradient norm: 0.27117328
INFO:root:At the start of the epoch: mem (CPU python)=4874.140625MB; mem (CPU total)=7073.0234375MB
INFO:root:[   23] Training loss: 1.15913635, Validation loss: 1.16407957, Gradient norm: 0.29812351
INFO:root:At the start of the epoch: mem (CPU python)=4895.30078125MB; mem (CPU total)=7157.484375MB
INFO:root:[   24] Training loss: 1.15874376, Validation loss: 1.16378475, Gradient norm: 0.30088514
INFO:root:At the start of the epoch: mem (CPU python)=4916.5625MB; mem (CPU total)=6926.33203125MB
INFO:root:[   25] Training loss: 1.15736884, Validation loss: 1.16425191, Gradient norm: 0.29064835
INFO:root:At the start of the epoch: mem (CPU python)=4938.3125MB; mem (CPU total)=7113.01171875MB
INFO:root:[   26] Training loss: 1.15894425, Validation loss: 1.17865259, Gradient norm: 0.33019059
INFO:root:At the start of the epoch: mem (CPU python)=4959.4765625MB; mem (CPU total)=7076.77734375MB
INFO:root:[   27] Training loss: 1.16202063, Validation loss: 1.16736569, Gradient norm: 0.37192301
INFO:root:At the start of the epoch: mem (CPU python)=4980.64453125MB; mem (CPU total)=7180.7578125MB
INFO:root:[   28] Training loss: 1.15912905, Validation loss: 1.17411780, Gradient norm: 0.35246957
INFO:root:At the start of the epoch: mem (CPU python)=5001.80859375MB; mem (CPU total)=7164.453125MB
INFO:root:[   29] Training loss: 1.16068032, Validation loss: 1.17564706, Gradient norm: 0.37513711
INFO:root:At the start of the epoch: mem (CPU python)=5022.97265625MB; mem (CPU total)=7218.26171875MB
INFO:root:[   30] Training loss: 1.15891556, Validation loss: 1.17206110, Gradient norm: 0.35014461
INFO:root:At the start of the epoch: mem (CPU python)=5044.91015625MB; mem (CPU total)=7150.5078125MB
INFO:root:[   31] Training loss: 1.15914064, Validation loss: 1.17237265, Gradient norm: 0.37941451
INFO:root:At the start of the epoch: mem (CPU python)=5066.80078125MB; mem (CPU total)=7331.69140625MB
INFO:root:[   32] Training loss: 1.15819643, Validation loss: 1.17002038, Gradient norm: 0.38420390
INFO:root:At the start of the epoch: mem (CPU python)=5090.15625MB; mem (CPU total)=7317.63671875MB
INFO:root:[   33] Training loss: 1.15902729, Validation loss: 1.17271620, Gradient norm: 0.38351874
INFO:root:At the start of the epoch: mem (CPU python)=5111.75390625MB; mem (CPU total)=7180.55078125MB
INFO:root:[   34] Training loss: 1.15867234, Validation loss: 1.17547026, Gradient norm: 0.37158904
INFO:root:At the start of the epoch: mem (CPU python)=5132.9140625MB; mem (CPU total)=7186.94921875MB
INFO:root:[   35] Training loss: 1.15725914, Validation loss: 1.17441982, Gradient norm: 0.39276397
INFO:root:At the start of the epoch: mem (CPU python)=5154.078125MB; mem (CPU total)=7362.2578125MB
INFO:root:[   36] Training loss: 1.15531762, Validation loss: 1.18527208, Gradient norm: 0.35428585
INFO:root:At the start of the epoch: mem (CPU python)=5175.2421875MB; mem (CPU total)=7342.03125MB
INFO:root:[   37] Training loss: 1.15650897, Validation loss: 1.17468002, Gradient norm: 0.37781776
INFO:root:At the start of the epoch: mem (CPU python)=5196.40625MB; mem (CPU total)=7354.0234375MB
INFO:root:[   38] Training loss: 1.15418525, Validation loss: 1.18909122, Gradient norm: 0.34776961
INFO:root:At the start of the epoch: mem (CPU python)=5217.5703125MB; mem (CPU total)=7255.94921875MB
INFO:root:[   39] Training loss: 1.15480332, Validation loss: 1.18627334, Gradient norm: 0.36581825
INFO:root:At the start of the epoch: mem (CPU python)=5238.73828125MB; mem (CPU total)=7342.95703125MB
INFO:root:[   40] Training loss: 1.15409931, Validation loss: 1.18326424, Gradient norm: 0.37227772
INFO:root:At the start of the epoch: mem (CPU python)=5259.90234375MB; mem (CPU total)=7345.0078125MB
INFO:root:[   41] Training loss: 1.15435958, Validation loss: 1.18412420, Gradient norm: 0.39477613
INFO:root:At the start of the epoch: mem (CPU python)=5281.06640625MB; mem (CPU total)=7331.37890625MB
INFO:root:[   42] Training loss: 1.15361109, Validation loss: 1.19096292, Gradient norm: 0.38765805
INFO:root:At the start of the epoch: mem (CPU python)=5302.2265625MB; mem (CPU total)=7342.9140625MB
INFO:root:[   43] Training loss: 1.15313931, Validation loss: 1.20277936, Gradient norm: 0.39528748
INFO:root:At the start of the epoch: mem (CPU python)=5323.390625MB; mem (CPU total)=7448.9296875MB
INFO:root:[   44] Training loss: 1.15316861, Validation loss: 1.19897868, Gradient norm: 0.41831969
INFO:root:At the start of the epoch: mem (CPU python)=5344.55859375MB; mem (CPU total)=7440.85546875MB
INFO:root:[   45] Training loss: 1.15084571, Validation loss: 1.20676342, Gradient norm: 0.38546674
INFO:root:At the start of the epoch: mem (CPU python)=5365.72265625MB; mem (CPU total)=7590.5234375MB
INFO:root:[   46] Training loss: 1.14988795, Validation loss: 1.20986272, Gradient norm: 0.38899604
INFO:root:At the start of the epoch: mem (CPU python)=5386.88671875MB; mem (CPU total)=8057.49609375MB
INFO:root:[   47] Training loss: 1.14986408, Validation loss: 1.20451004, Gradient norm: 0.38706305
INFO:root:At the start of the epoch: mem (CPU python)=5408.05078125MB; mem (CPU total)=8187.3125MB
INFO:root:[   48] Training loss: 1.15103440, Validation loss: 1.19926692, Gradient norm: 0.44890718
INFO:root:At the start of the epoch: mem (CPU python)=5429.21484375MB; mem (CPU total)=8224.0078125MB
INFO:root:[   49] Training loss: 1.14937146, Validation loss: 1.20188821, Gradient norm: 0.42703555
INFO:root:At the start of the epoch: mem (CPU python)=5450.37890625MB; mem (CPU total)=8407.23828125MB
INFO:root:[   50] Training loss: 1.14835262, Validation loss: 1.20145619, Gradient norm: 0.41895732
INFO:root:At the start of the epoch: mem (CPU python)=5471.546875MB; mem (CPU total)=8515.6171875MB
INFO:root:[   51] Training loss: 1.14772897, Validation loss: 1.20856415, Gradient norm: 0.43025245
INFO:root:At the start of the epoch: mem (CPU python)=5492.703125MB; mem (CPU total)=8488.19921875MB
INFO:root:[   52] Training loss: 1.14853659, Validation loss: 1.21309565, Gradient norm: 0.44041093
INFO:root:At the start of the epoch: mem (CPU python)=5513.8671875MB; mem (CPU total)=8569.51171875MB
INFO:root:[   53] Training loss: 1.14733262, Validation loss: 1.20547666, Gradient norm: 0.42139161
INFO:root:At the start of the epoch: mem (CPU python)=5535.03125MB; mem (CPU total)=8540.35546875MB
INFO:root:[   54] Training loss: 1.14731146, Validation loss: 1.20998741, Gradient norm: 0.46771145
INFO:root:At the start of the epoch: mem (CPU python)=5556.1953125MB; mem (CPU total)=8591.1640625MB
INFO:root:[   55] Training loss: 1.14780684, Validation loss: 1.20959621, Gradient norm: 0.46068659
INFO:root:At the start of the epoch: mem (CPU python)=5577.36328125MB; mem (CPU total)=8499.41015625MB
INFO:root:[   56] Training loss: 1.14730257, Validation loss: 1.20690430, Gradient norm: 0.46376292
INFO:root:At the start of the epoch: mem (CPU python)=5598.52734375MB; mem (CPU total)=8684.1328125MB
INFO:root:[   57] Training loss: 1.14562056, Validation loss: 1.20558547, Gradient norm: 0.46663746
INFO:root:At the start of the epoch: mem (CPU python)=5619.69140625MB; mem (CPU total)=8619.0078125MB
INFO:root:[   58] Training loss: 1.14635715, Validation loss: 1.21016860, Gradient norm: 0.46513993
INFO:root:At the start of the epoch: mem (CPU python)=5640.85546875MB; mem (CPU total)=8656.46875MB
INFO:root:[   59] Training loss: 1.14541054, Validation loss: 1.20379386, Gradient norm: 0.47969730
INFO:root:At the start of the epoch: mem (CPU python)=5662.01953125MB; mem (CPU total)=8610.75MB
INFO:root:[   60] Training loss: 1.14519668, Validation loss: 1.21127905, Gradient norm: 0.49577147
INFO:root:At the start of the epoch: mem (CPU python)=5683.76171875MB; mem (CPU total)=8570.9140625MB
INFO:root:[   61] Training loss: 1.14293365, Validation loss: 1.21825590, Gradient norm: 0.45290246
INFO:root:At the start of the epoch: mem (CPU python)=5705.22265625MB; mem (CPU total)=8709.72265625MB
INFO:root:[   62] Training loss: 1.14465418, Validation loss: 1.21285288, Gradient norm: 0.51893808
INFO:root:At the start of the epoch: mem (CPU python)=5727.0234375MB; mem (CPU total)=8678.06640625MB
INFO:root:[   63] Training loss: 1.14361591, Validation loss: 1.21331083, Gradient norm: 0.51196494
INFO:root:At the start of the epoch: mem (CPU python)=5748.2109375MB; mem (CPU total)=8698.48046875MB
INFO:root:[   64] Training loss: 1.14371913, Validation loss: 1.23178828, Gradient norm: 0.50243774
INFO:root:At the start of the epoch: mem (CPU python)=5769.40625MB; mem (CPU total)=8697.1328125MB
INFO:root:[   65] Training loss: 1.14343955, Validation loss: 1.22028294, Gradient norm: 0.54061457
INFO:root:At the start of the epoch: mem (CPU python)=5790.58203125MB; mem (CPU total)=8880.4453125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   66] Training loss: 1.14191620, Validation loss: 1.21590515, Gradient norm: 0.49401432
INFO:root:At the start of the epoch: mem (CPU python)=5811.75390625MB; mem (CPU total)=8691.25MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   67] Training loss: 1.13588679, Validation loss: 1.21597020, Gradient norm: 0.38170698
INFO:root:At the start of the epoch: mem (CPU python)=5832.93359375MB; mem (CPU total)=8951.375MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   68] Training loss: 1.13413234, Validation loss: 1.22332620, Gradient norm: 0.33613813
INFO:root:At the start of the epoch: mem (CPU python)=5854.1015625MB; mem (CPU total)=8732.234375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:EP 68: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [0.00015625]
INFO:root:At the start of the epoch: mem (CPU python)=5875.28125MB; mem (CPU total)=8955.4375MB
INFO:root:[   70] Training loss: 0.50673156, Validation loss: 0.84924885, Gradient norm: 0.91816648
INFO:root:At the start of the epoch: mem (CPU python)=5896.46484375MB; mem (CPU total)=8780.66015625MB
INFO:root:[   71] Training loss: 0.46434007, Validation loss: 0.83833840, Gradient norm: 1.11045206
INFO:root:At the start of the epoch: mem (CPU python)=5917.6640625MB; mem (CPU total)=9039.3984375MB
INFO:root:[   72] Training loss: 0.45487024, Validation loss: 0.83277125, Gradient norm: 1.21823450
INFO:root:At the start of the epoch: mem (CPU python)=5940.4765625MB; mem (CPU total)=8995.25390625MB
INFO:root:[   73] Training loss: 0.44965478, Validation loss: 0.83660003, Gradient norm: 1.40714162
INFO:root:At the start of the epoch: mem (CPU python)=5962.63671875MB; mem (CPU total)=8979.8359375MB
INFO:root:[   74] Training loss: 0.44515519, Validation loss: 0.82685197, Gradient norm: 1.46765875
INFO:root:At the start of the epoch: mem (CPU python)=5983.82421875MB; mem (CPU total)=9167.140625MB
INFO:root:[   75] Training loss: 0.44158925, Validation loss: 0.82319569, Gradient norm: 1.59567087
INFO:root:At the start of the epoch: mem (CPU python)=6005.03125MB; mem (CPU total)=9155.33203125MB
INFO:root:[   76] Training loss: 0.43847565, Validation loss: 0.82219024, Gradient norm: 1.76196730
INFO:root:At the start of the epoch: mem (CPU python)=6026.2421875MB; mem (CPU total)=9167.91015625MB
INFO:root:[   77] Training loss: 0.43601524, Validation loss: 0.82146391, Gradient norm: 1.95391049
INFO:root:At the start of the epoch: mem (CPU python)=6047.42578125MB; mem (CPU total)=8990.3359375MB
INFO:root:[   78] Training loss: 0.43431991, Validation loss: 0.81923680, Gradient norm: 2.13504347
INFO:root:At the start of the epoch: mem (CPU python)=6068.62109375MB; mem (CPU total)=9115.03515625MB
INFO:root:[   79] Training loss: 0.43227799, Validation loss: 0.81676908, Gradient norm: 2.42927490
INFO:root:At the start of the epoch: mem (CPU python)=6089.76953125MB; mem (CPU total)=9077.9296875MB
INFO:root:[   80] Training loss: 0.43015976, Validation loss: 0.81260457, Gradient norm: 2.58881334
INFO:root:At the start of the epoch: mem (CPU python)=6110.9453125MB; mem (CPU total)=9238.0MB
INFO:root:[   81] Training loss: 0.42865334, Validation loss: 0.81111612, Gradient norm: 2.94766999
INFO:root:At the start of the epoch: mem (CPU python)=6137.390625MB; mem (CPU total)=9108.38671875MB
INFO:root:[   82] Training loss: 0.42689700, Validation loss: 0.81159011, Gradient norm: 3.34411042
INFO:root:At the start of the epoch: mem (CPU python)=6159.14453125MB; mem (CPU total)=9126.84375MB
INFO:root:[   83] Training loss: 0.42546006, Validation loss: 0.80440057, Gradient norm: 3.66231309
INFO:root:At the start of the epoch: mem (CPU python)=6180.43359375MB; mem (CPU total)=9194.8203125MB
INFO:root:[   84] Training loss: 0.42393307, Validation loss: 0.80001773, Gradient norm: 4.08339221
INFO:root:At the start of the epoch: mem (CPU python)=6201.60546875MB; mem (CPU total)=9090.125MB
INFO:root:[   85] Training loss: 0.42307471, Validation loss: 0.80605248, Gradient norm: 4.45614361
INFO:root:At the start of the epoch: mem (CPU python)=6222.765625MB; mem (CPU total)=9226.6328125MB
INFO:root:[   86] Training loss: 0.42204544, Validation loss: 0.80213821, Gradient norm: 5.22578559
INFO:root:At the start of the epoch: mem (CPU python)=6244.25MB; mem (CPU total)=9183.453125MB
INFO:root:[   87] Training loss: 0.42060727, Validation loss: 0.79882711, Gradient norm: 5.63399634
INFO:root:At the start of the epoch: mem (CPU python)=6265.9140625MB; mem (CPU total)=9229.74609375MB
INFO:root:[   88] Training loss: 0.41979606, Validation loss: 0.79514837, Gradient norm: 6.42851888
INFO:root:At the start of the epoch: mem (CPU python)=6288.37109375MB; mem (CPU total)=9315.81640625MB
INFO:root:[   89] Training loss: 0.41945761, Validation loss: 0.80863243, Gradient norm: 7.20933728
INFO:root:At the start of the epoch: mem (CPU python)=6310.265625MB; mem (CPU total)=9281.12890625MB
INFO:root:[   90] Training loss: 0.41858002, Validation loss: 0.79796043, Gradient norm: 7.50114639
INFO:root:At the start of the epoch: mem (CPU python)=6331.8671875MB; mem (CPU total)=9282.2578125MB
INFO:root:[   91] Training loss: 0.41719572, Validation loss: 0.79677360, Gradient norm: 8.31261213
INFO:root:At the start of the epoch: mem (CPU python)=6353.03515625MB; mem (CPU total)=9380.97265625MB
INFO:root:[   92] Training loss: 0.41597174, Validation loss: 0.79598870, Gradient norm: 8.97701832
INFO:root:At the start of the epoch: mem (CPU python)=6376.046875MB; mem (CPU total)=9363.6875MB
INFO:root:[   93] Training loss: 0.41581468, Validation loss: 0.79451250, Gradient norm: 9.81277332
INFO:root:At the start of the epoch: mem (CPU python)=6397.2109375MB; mem (CPU total)=9404.8046875MB
INFO:root:[   94] Training loss: 0.41513506, Validation loss: 0.79126243, Gradient norm: 11.15286109
INFO:root:At the start of the epoch: mem (CPU python)=6418.60546875MB; mem (CPU total)=9378.26171875MB
INFO:root:[   95] Training loss: 0.41346949, Validation loss: 0.79043847, Gradient norm: 11.65398196
INFO:root:At the start of the epoch: mem (CPU python)=6439.76953125MB; mem (CPU total)=9363.078125MB
INFO:root:[   96] Training loss: 0.41345229, Validation loss: 0.78504329, Gradient norm: 13.61193488
INFO:root:At the start of the epoch: mem (CPU python)=6460.93359375MB; mem (CPU total)=9497.875MB
INFO:root:[   97] Training loss: 0.41359637, Validation loss: 0.78337188, Gradient norm: 13.68184023
INFO:root:At the start of the epoch: mem (CPU python)=6482.09765625MB; mem (CPU total)=9487.01953125MB
INFO:root:[   98] Training loss: 0.41276197, Validation loss: 0.78568435, Gradient norm: 15.11711128
INFO:root:At the start of the epoch: mem (CPU python)=6503.2578125MB; mem (CPU total)=9527.4765625MB
INFO:root:[   99] Training loss: 0.41160575, Validation loss: 0.78491977, Gradient norm: 16.23063341
INFO:root:At the start of the epoch: mem (CPU python)=6527.421875MB; mem (CPU total)=9664.640625MB
INFO:root:[  100] Training loss: 0.41100524, Validation loss: 0.78649803, Gradient norm: 16.95204677
INFO:root:At the start of the epoch: mem (CPU python)=6548.5859375MB; mem (CPU total)=9673.078125MB
INFO:root:[  101] Training loss: 0.41043314, Validation loss: 0.78548439, Gradient norm: 17.59743462
INFO:root:At the start of the epoch: mem (CPU python)=6569.75390625MB; mem (CPU total)=9606.921875MB
INFO:root:[  102] Training loss: 0.40979138, Validation loss: 0.77908368, Gradient norm: 18.67249136
INFO:root:At the start of the epoch: mem (CPU python)=6590.91796875MB; mem (CPU total)=9523.80859375MB
INFO:root:[  103] Training loss: 0.40922054, Validation loss: 0.77858955, Gradient norm: 19.83131722
INFO:root:At the start of the epoch: mem (CPU python)=6612.08203125MB; mem (CPU total)=9698.83203125MB
INFO:root:[  104] Training loss: 0.40869183, Validation loss: 0.77953976, Gradient norm: 21.15437001
INFO:root:At the start of the epoch: mem (CPU python)=6633.2421875MB; mem (CPU total)=9660.24609375MB
INFO:root:[  105] Training loss: 0.40854452, Validation loss: 0.78420038, Gradient norm: 21.98505591
INFO:root:At the start of the epoch: mem (CPU python)=6654.40625MB; mem (CPU total)=9751.58203125MB
INFO:root:[  106] Training loss: 0.40781123, Validation loss: 0.78744995, Gradient norm: 23.91046095
INFO:root:At the start of the epoch: mem (CPU python)=6675.5703125MB; mem (CPU total)=9630.16015625MB
INFO:root:[  107] Training loss: 0.40705137, Validation loss: 0.78681520, Gradient norm: 25.10617879
INFO:root:At the start of the epoch: mem (CPU python)=6696.73828125MB; mem (CPU total)=9712.7109375MB
INFO:root:[  108] Training loss: 0.40756430, Validation loss: 0.78561573, Gradient norm: 27.21131367
INFO:root:At the start of the epoch: mem (CPU python)=6717.8984375MB; mem (CPU total)=9739.41015625MB
INFO:root:[  109] Training loss: 0.40656853, Validation loss: 0.78628065, Gradient norm: 26.62726205
INFO:root:At the start of the epoch: mem (CPU python)=6739.0625MB; mem (CPU total)=9760.2421875MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  110] Training loss: 0.40659874, Validation loss: 0.78233343, Gradient norm: 28.83090012
INFO:root:At the start of the epoch: mem (CPU python)=6760.2265625MB; mem (CPU total)=9829.67578125MB
INFO:root:[  111] Training loss: 0.40322753, Validation loss: 0.77911381, Gradient norm: 23.96252284
INFO:root:At the start of the epoch: mem (CPU python)=6781.390625MB; mem (CPU total)=9844.07421875MB
INFO:root:[  112] Training loss: 0.40312267, Validation loss: 0.78267330, Gradient norm: 25.98121484
INFO:root:At the start of the epoch: mem (CPU python)=6802.55859375MB; mem (CPU total)=9742.6875MB
INFO:root:[  113] Training loss: 0.40345401, Validation loss: 0.76957273, Gradient norm: 27.70371681
INFO:root:At the start of the epoch: mem (CPU python)=6823.7265625MB; mem (CPU total)=9806.98046875MB
INFO:root:[  114] Training loss: 0.40310615, Validation loss: 0.77741308, Gradient norm: 28.06863244
INFO:root:At the start of the epoch: mem (CPU python)=6844.890625MB; mem (CPU total)=9805.48828125MB
INFO:root:[  115] Training loss: 0.40333597, Validation loss: 0.77320573, Gradient norm: 29.68003136
INFO:root:At the start of the epoch: mem (CPU python)=6866.0546875MB; mem (CPU total)=9881.51953125MB
INFO:root:[  116] Training loss: 0.40249864, Validation loss: 0.79461682, Gradient norm: 31.03062935
INFO:root:At the start of the epoch: mem (CPU python)=6887.21875MB; mem (CPU total)=9811.390625MB
INFO:root:[  117] Training loss: 0.40225351, Validation loss: 0.76432271, Gradient norm: 31.78502208
INFO:root:At the start of the epoch: mem (CPU python)=6908.3828125MB; mem (CPU total)=9888.9375MB
INFO:root:[  118] Training loss: 0.40257854, Validation loss: 0.77578693, Gradient norm: 32.29491612
INFO:root:At the start of the epoch: mem (CPU python)=6929.546875MB; mem (CPU total)=10009.15625MB
INFO:root:[  119] Training loss: 0.40196388, Validation loss: 0.77789485, Gradient norm: 33.95601169
INFO:root:At the start of the epoch: mem (CPU python)=6950.70703125MB; mem (CPU total)=9903.73828125MB
INFO:root:[  120] Training loss: 0.40167176, Validation loss: 0.77485664, Gradient norm: 35.88736969
INFO:root:At the start of the epoch: mem (CPU python)=6971.87109375MB; mem (CPU total)=9875.80078125MB
INFO:root:[  121] Training loss: 0.40163739, Validation loss: 0.77576146, Gradient norm: 37.03486033
INFO:root:At the start of the epoch: mem (CPU python)=6993.03515625MB; mem (CPU total)=9923.875MB
INFO:root:[  122] Training loss: 0.40118435, Validation loss: 0.76937617, Gradient norm: 38.00770002
INFO:root:At the start of the epoch: mem (CPU python)=7014.19921875MB; mem (CPU total)=10082.09765625MB
INFO:root:[  123] Training loss: 0.40097470, Validation loss: 0.76886501, Gradient norm: 37.66809293
INFO:root:At the start of the epoch: mem (CPU python)=7035.3671875MB; mem (CPU total)=10050.7578125MB
INFO:root:[  124] Training loss: 0.40120009, Validation loss: 0.76726557, Gradient norm: 38.56726050
INFO:root:At the start of the epoch: mem (CPU python)=7056.53125MB; mem (CPU total)=9969.5546875MB
INFO:root:[  125] Training loss: 0.40105562, Validation loss: 0.76385215, Gradient norm: 40.82668875
INFO:root:At the start of the epoch: mem (CPU python)=7077.6953125MB; mem (CPU total)=10124.78515625MB
INFO:root:[  126] Training loss: 0.40055139, Validation loss: 0.76873095, Gradient norm: 40.34097878
INFO:root:At the start of the epoch: mem (CPU python)=7098.859375MB; mem (CPU total)=10240.31640625MB
INFO:root:[  127] Training loss: 0.40038485, Validation loss: 0.76511881, Gradient norm: 42.62946538
INFO:root:At the start of the epoch: mem (CPU python)=7120.01953125MB; mem (CPU total)=10046.0625MB
INFO:root:[  128] Training loss: 0.39958112, Validation loss: 0.77072023, Gradient norm: 42.93595786
INFO:root:At the start of the epoch: mem (CPU python)=7141.18359375MB; mem (CPU total)=10290.8671875MB
INFO:root:[  129] Training loss: 0.39977143, Validation loss: 0.77001242, Gradient norm: 42.88184517
INFO:root:At the start of the epoch: mem (CPU python)=7162.34765625MB; mem (CPU total)=10310.00390625MB
INFO:root:[  130] Training loss: 0.39930195, Validation loss: 0.77447721, Gradient norm: 43.29656833
INFO:root:At the start of the epoch: mem (CPU python)=7183.515625MB; mem (CPU total)=10178.37109375MB
INFO:root:[  131] Training loss: 0.39951877, Validation loss: 0.76875039, Gradient norm: 47.87474754
INFO:root:At the start of the epoch: mem (CPU python)=7204.6796875MB; mem (CPU total)=10304.734375MB
INFO:root:[  132] Training loss: 0.39919392, Validation loss: 0.77489779, Gradient norm: 45.91759206
INFO:root:At the start of the epoch: mem (CPU python)=7225.84375MB; mem (CPU total)=10373.359375MB
INFO:root:[  133] Training loss: 0.39953475, Validation loss: 0.77049696, Gradient norm: 47.02018631
INFO:root:At the start of the epoch: mem (CPU python)=7247.0078125MB; mem (CPU total)=10312.26953125MB
INFO:root:[  134] Training loss: 0.39927390, Validation loss: 0.77347580, Gradient norm: 47.68270298
INFO:root:At the start of the epoch: mem (CPU python)=7268.171875MB; mem (CPU total)=10228.484375MB
INFO:root:EP 134: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=7289.3359375MB; mem (CPU total)=10426.7734375MB
INFO:root:Training the model took 13851.52s.
INFO:root:Emptying the cuda cache took 0.137s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.61429
INFO:root:EnergyScoreValidation: 0.61418
INFO:root:CRPSValidation: 0.24471
INFO:root:Gaussian NLLValidation: 273020354.71754
INFO:root:CoverageValidation: 0.00015
INFO:root:IntervalWidthValidation: 0.0001
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.47411
INFO:root:EnergyScoreTest: 0.46926
INFO:root:CRPSTest: 0.18794
INFO:root:Gaussian NLLTest: 35699690291.20002
INFO:root:CoverageTest: 1e-05
INFO:root:IntervalWidthTest: 0.0
INFO:root:After validation: mem (CPU python)=7305.2421875MB; mem (CPU total)=10375.65234375MB
INFO:root:###2 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=7305.2421875MB; mem (CPU total)=10248.02734375MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 69206016
INFO:root:After setting up the model: mem (CPU python)=7305.2578125MB; mem (CPU total)=10238.12890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=7305.265625MB; mem (CPU total)=10400.8046875MB
INFO:root:[    1] Training loss: 1.24664358, Validation loss: 1.23009272, Gradient norm: 0.11640610
INFO:root:At the start of the epoch: mem (CPU python)=7354.765625MB; mem (CPU total)=10424.375MB
INFO:root:[    2] Training loss: 1.22447978, Validation loss: 1.21173695, Gradient norm: 0.08091475
INFO:root:At the start of the epoch: mem (CPU python)=7376.63671875MB; mem (CPU total)=10509.1875MB
INFO:root:[    3] Training loss: 1.19780804, Validation loss: 1.19131865, Gradient norm: 0.09624172
INFO:root:At the start of the epoch: mem (CPU python)=7402.11328125MB; mem (CPU total)=10329.8671875MB
INFO:root:[    4] Training loss: 1.18750256, Validation loss: 1.18375479, Gradient norm: 0.09065876
INFO:root:At the start of the epoch: mem (CPU python)=7423.8515625MB; mem (CPU total)=10375.73046875MB
INFO:root:[    5] Training loss: 1.17885104, Validation loss: 1.17295574, Gradient norm: 0.09746896
INFO:root:At the start of the epoch: mem (CPU python)=7445.015625MB; mem (CPU total)=10352.80078125MB
INFO:root:[    6] Training loss: 1.16446373, Validation loss: 1.15776864, Gradient norm: 0.11074591
INFO:root:At the start of the epoch: mem (CPU python)=7461.98046875MB; mem (CPU total)=10540.66015625MB
INFO:root:[    7] Training loss: 1.15475743, Validation loss: 1.15335328, Gradient norm: 0.11378594
INFO:root:At the start of the epoch: mem (CPU python)=7477.4375MB; mem (CPU total)=10515.921875MB
INFO:root:[    8] Training loss: 1.15148730, Validation loss: 1.15188940, Gradient norm: 0.10987117
INFO:root:At the start of the epoch: mem (CPU python)=7499.1328125MB; mem (CPU total)=10501.05859375MB
INFO:root:[    9] Training loss: 1.14964022, Validation loss: 1.15408114, Gradient norm: 0.11072016
INFO:root:At the start of the epoch: mem (CPU python)=7519.9765625MB; mem (CPU total)=10658.55078125MB
INFO:root:[   10] Training loss: 1.14884859, Validation loss: 1.15105693, Gradient norm: 0.11711223
INFO:root:At the start of the epoch: mem (CPU python)=7541.8359375MB; mem (CPU total)=10567.30859375MB
INFO:root:[   11] Training loss: 1.14813277, Validation loss: 1.15318859, Gradient norm: 0.12787567
INFO:root:At the start of the epoch: mem (CPU python)=7564.125MB; mem (CPU total)=10726.11328125MB
INFO:root:[   12] Training loss: 1.14890282, Validation loss: 1.15889056, Gradient norm: 0.14925414
INFO:root:At the start of the epoch: mem (CPU python)=7585.2890625MB; mem (CPU total)=10644.9375MB
INFO:root:[   13] Training loss: 1.15143248, Validation loss: 1.16408872, Gradient norm: 0.16691741
INFO:root:At the start of the epoch: mem (CPU python)=7606.453125MB; mem (CPU total)=10687.88671875MB
INFO:root:[   14] Training loss: 1.14897540, Validation loss: 1.15915831, Gradient norm: 0.15832001
INFO:root:At the start of the epoch: mem (CPU python)=7627.6171875MB; mem (CPU total)=10758.546875MB
INFO:root:[   15] Training loss: 1.15216520, Validation loss: 1.16157070, Gradient norm: 0.20570233
INFO:root:At the start of the epoch: mem (CPU python)=7644.6015625MB; mem (CPU total)=10629.5390625MB
INFO:root:[   16] Training loss: 1.14759376, Validation loss: 1.15589259, Gradient norm: 0.15251646
INFO:root:At the start of the epoch: mem (CPU python)=7665.921875MB; mem (CPU total)=10772.21484375MB
INFO:root:[   17] Training loss: 1.14603658, Validation loss: 1.15610790, Gradient norm: 0.15424188
INFO:root:At the start of the epoch: mem (CPU python)=7683.6328125MB; mem (CPU total)=10784.1640625MB
INFO:root:[   18] Training loss: 1.14636039, Validation loss: 1.16302860, Gradient norm: 0.15415573
INFO:root:At the start of the epoch: mem (CPU python)=7704.77734375MB; mem (CPU total)=10856.25390625MB
INFO:root:[   19] Training loss: 1.14514895, Validation loss: 1.15776249, Gradient norm: 0.14669332
INFO:root:At the start of the epoch: mem (CPU python)=7730.57421875MB; mem (CPU total)=10779.015625MB
INFO:root:[   20] Training loss: 1.14490632, Validation loss: 1.15804463, Gradient norm: 0.15960039
INFO:root:At the start of the epoch: mem (CPU python)=7752.62890625MB; mem (CPU total)=10802.90625MB
INFO:root:[   21] Training loss: 1.14440929, Validation loss: 1.15903486, Gradient norm: 0.15743182
INFO:root:At the start of the epoch: mem (CPU python)=7777.68359375MB; mem (CPU total)=10812.60546875MB
INFO:root:[   22] Training loss: 1.14569396, Validation loss: 1.17004525, Gradient norm: 0.17931170
INFO:root:At the start of the epoch: mem (CPU python)=7801.53125MB; mem (CPU total)=10769.21484375MB
INFO:root:[   23] Training loss: 1.14345030, Validation loss: 1.16757851, Gradient norm: 0.16390183
INFO:root:At the start of the epoch: mem (CPU python)=7823.34765625MB; mem (CPU total)=10895.06640625MB
INFO:root:[   24] Training loss: 1.14335917, Validation loss: 1.17982695, Gradient norm: 0.17164227
INFO:root:At the start of the epoch: mem (CPU python)=7844.515625MB; mem (CPU total)=10875.19921875MB
INFO:root:[   25] Training loss: 1.14530907, Validation loss: 1.17647918, Gradient norm: 0.20424344
INFO:root:At the start of the epoch: mem (CPU python)=7863.8125MB; mem (CPU total)=10911.109375MB
INFO:root:[   26] Training loss: 1.14246215, Validation loss: 1.17583511, Gradient norm: 0.17285817
INFO:root:At the start of the epoch: mem (CPU python)=7885.71484375MB; mem (CPU total)=10791.078125MB
INFO:root:[   27] Training loss: 1.14180897, Validation loss: 1.17809403, Gradient norm: 0.19305922
INFO:root:At the start of the epoch: mem (CPU python)=7902.6796875MB; mem (CPU total)=11034.2109375MB
INFO:root:[   28] Training loss: 1.14111805, Validation loss: 1.18167872, Gradient norm: 0.19672114
INFO:root:At the start of the epoch: mem (CPU python)=7923.5703125MB; mem (CPU total)=10893.4375MB
INFO:root:[   29] Training loss: 1.13949389, Validation loss: 1.18940552, Gradient norm: 0.18819729
INFO:root:At the start of the epoch: mem (CPU python)=7945.0859375MB; mem (CPU total)=10899.82421875MB
INFO:root:[   30] Training loss: 1.13890045, Validation loss: 1.18092910, Gradient norm: 0.19248206
INFO:root:At the start of the epoch: mem (CPU python)=7971.18359375MB; mem (CPU total)=11056.1640625MB
INFO:root:[   31] Training loss: 1.13971558, Validation loss: 1.18664385, Gradient norm: 0.20321219
INFO:root:At the start of the epoch: mem (CPU python)=7988.80859375MB; mem (CPU total)=11003.30859375MB
INFO:root:[   32] Training loss: 1.13738858, Validation loss: 1.18605498, Gradient norm: 0.17875445
INFO:root:At the start of the epoch: mem (CPU python)=8005.92578125MB; mem (CPU total)=11058.625MB
INFO:root:[   33] Training loss: 1.13901514, Validation loss: 1.18812882, Gradient norm: 0.20764200
INFO:root:At the start of the epoch: mem (CPU python)=8027.48828125MB; mem (CPU total)=11061.94921875MB
INFO:root:[   34] Training loss: 1.13768786, Validation loss: 1.21192596, Gradient norm: 0.18366962
INFO:root:At the start of the epoch: mem (CPU python)=8056.79296875MB; mem (CPU total)=11078.59765625MB
INFO:root:[   35] Training loss: 1.14028191, Validation loss: 1.19047597, Gradient norm: 0.22591322
INFO:root:At the start of the epoch: mem (CPU python)=8078.8203125MB; mem (CPU total)=11232.2421875MB
INFO:root:[   36] Training loss: 1.13676144, Validation loss: 1.19669674, Gradient norm: 0.20683753
INFO:root:At the start of the epoch: mem (CPU python)=8099.984375MB; mem (CPU total)=11237.76953125MB
INFO:root:[   37] Training loss: 1.13668064, Validation loss: 1.19453301, Gradient norm: 0.19736277
INFO:root:At the start of the epoch: mem (CPU python)=8121.1484375MB; mem (CPU total)=11177.56640625MB
INFO:root:[   38] Training loss: 1.13672176, Validation loss: 1.19595313, Gradient norm: 0.18997941
INFO:root:At the start of the epoch: mem (CPU python)=8142.3125MB; mem (CPU total)=11104.03515625MB
INFO:root:[   39] Training loss: 1.13703884, Validation loss: 1.19435060, Gradient norm: 0.19836070
INFO:root:At the start of the epoch: mem (CPU python)=8163.47265625MB; mem (CPU total)=11236.08984375MB
INFO:root:[   40] Training loss: 1.13650517, Validation loss: 1.19996878, Gradient norm: 0.19039854
INFO:root:At the start of the epoch: mem (CPU python)=8169.90234375MB; mem (CPU total)=11335.2109375MB
INFO:root:[   41] Training loss: 1.13649064, Validation loss: 1.21348927, Gradient norm: 0.20029688
INFO:root:At the start of the epoch: mem (CPU python)=8194.765625MB; mem (CPU total)=11229.3671875MB
INFO:root:[   42] Training loss: 1.13646659, Validation loss: 1.21545222, Gradient norm: 0.20059635
INFO:root:At the start of the epoch: mem (CPU python)=8223.44140625MB; mem (CPU total)=11445.26953125MB
INFO:root:[   43] Training loss: 1.13665908, Validation loss: 1.20058653, Gradient norm: 0.20010931
INFO:root:At the start of the epoch: mem (CPU python)=8245.12890625MB; mem (CPU total)=11301.82421875MB
INFO:root:[   44] Training loss: 1.13682309, Validation loss: 1.20216648, Gradient norm: 0.21653195
INFO:root:At the start of the epoch: mem (CPU python)=8266.29296875MB; mem (CPU total)=11360.58984375MB
INFO:root:[   45] Training loss: 1.13656847, Validation loss: 1.21124360, Gradient norm: 0.21599984
INFO:root:At the start of the epoch: mem (CPU python)=8287.4609375MB; mem (CPU total)=11463.046875MB
INFO:root:[   46] Training loss: 1.13565972, Validation loss: 1.21610922, Gradient norm: 0.20475017
INFO:root:At the start of the epoch: mem (CPU python)=8308.625MB; mem (CPU total)=11387.4765625MB
INFO:root:[   47] Training loss: 1.13685885, Validation loss: 1.20063556, Gradient norm: 0.21144813
INFO:root:At the start of the epoch: mem (CPU python)=8329.7890625MB; mem (CPU total)=11393.25390625MB
INFO:root:[   48] Training loss: 1.13614183, Validation loss: 1.20177333, Gradient norm: 0.20523239
INFO:root:At the start of the epoch: mem (CPU python)=8353.5234375MB; mem (CPU total)=11466.86328125MB
INFO:root:[   49] Training loss: 1.13535808, Validation loss: 1.20969269, Gradient norm: 0.21022283
INFO:root:At the start of the epoch: mem (CPU python)=8375.49609375MB; mem (CPU total)=11557.17578125MB
INFO:root:[   50] Training loss: 1.13549712, Validation loss: 1.21190756, Gradient norm: 0.20000177
INFO:root:At the start of the epoch: mem (CPU python)=8396.6640625MB; mem (CPU total)=11528.171875MB
INFO:root:[   51] Training loss: 1.13657538, Validation loss: 1.21289207, Gradient norm: 0.23501355
INFO:root:At the start of the epoch: mem (CPU python)=8413.58984375MB; mem (CPU total)=11557.26953125MB
INFO:root:[   52] Training loss: 1.13594521, Validation loss: 1.21062381, Gradient norm: 0.20129550
INFO:root:At the start of the epoch: mem (CPU python)=8432.609375MB; mem (CPU total)=11553.078125MB
INFO:root:[   53] Training loss: 1.13509444, Validation loss: 1.21512606, Gradient norm: 0.20365666
INFO:root:At the start of the epoch: mem (CPU python)=8449.57421875MB; mem (CPU total)=11439.14453125MB
INFO:root:[   54] Training loss: 1.13504723, Validation loss: 1.21043122, Gradient norm: 0.20986717
INFO:root:At the start of the epoch: mem (CPU python)=8468.23828125MB; mem (CPU total)=11440.140625MB
INFO:root:[   55] Training loss: 1.13566353, Validation loss: 1.20860901, Gradient norm: 0.22169098
INFO:root:At the start of the epoch: mem (CPU python)=8490.921875MB; mem (CPU total)=11700.375MB
INFO:root:[   56] Training loss: 1.13453252, Validation loss: 1.21271394, Gradient norm: 0.19093775
INFO:root:At the start of the epoch: mem (CPU python)=8516.5703125MB; mem (CPU total)=11681.09765625MB
INFO:root:[   57] Training loss: 1.13618489, Validation loss: 1.21122601, Gradient norm: 0.23155866
INFO:root:At the start of the epoch: mem (CPU python)=8538.4296875MB; mem (CPU total)=11662.84765625MB
INFO:root:[   58] Training loss: 1.13479731, Validation loss: 1.20942887, Gradient norm: 0.20697299
INFO:root:At the start of the epoch: mem (CPU python)=8561.8359375MB; mem (CPU total)=11575.1640625MB
INFO:root:[   59] Training loss: 1.13580970, Validation loss: 1.21537351, Gradient norm: 0.22745410
INFO:root:At the start of the epoch: mem (CPU python)=8583.7578125MB; mem (CPU total)=11798.7890625MB
INFO:root:[   60] Training loss: 1.13433346, Validation loss: 1.21109793, Gradient norm: 0.19315814
INFO:root:At the start of the epoch: mem (CPU python)=8604.921875MB; mem (CPU total)=11604.78515625MB
INFO:root:[   61] Training loss: 1.13539643, Validation loss: 1.21304327, Gradient norm: 0.23166665
INFO:root:At the start of the epoch: mem (CPU python)=8626.0859375MB; mem (CPU total)=11821.125MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   62] Training loss: 1.13520679, Validation loss: 1.20886024, Gradient norm: 0.22993201
INFO:root:At the start of the epoch: mem (CPU python)=8647.25MB; mem (CPU total)=11785.453125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   63] Training loss: 1.13040454, Validation loss: 1.20887274, Gradient norm: 0.15283335
INFO:root:At the start of the epoch: mem (CPU python)=8668.4140625MB; mem (CPU total)=11673.72265625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   64] Training loss: 1.12887699, Validation loss: 1.21248799, Gradient norm: 0.13547403
INFO:root:At the start of the epoch: mem (CPU python)=8690.3203125MB; mem (CPU total)=11743.4453125MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:EP 64: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [0.00015625]
INFO:root:At the start of the epoch: mem (CPU python)=8711.8671875MB; mem (CPU total)=11756.29296875MB
INFO:root:[   66] Training loss: 0.46968370, Validation loss: 0.85518568, Gradient norm: 0.38121544
INFO:root:At the start of the epoch: mem (CPU python)=8734.2890625MB; mem (CPU total)=11876.39453125MB
INFO:root:[   67] Training loss: 0.41545370, Validation loss: 0.84885986, Gradient norm: 0.35743758
INFO:root:At the start of the epoch: mem (CPU python)=8765.01171875MB; mem (CPU total)=11976.45703125MB
INFO:root:[   68] Training loss: 0.40291080, Validation loss: 0.83701598, Gradient norm: 0.33846640
INFO:root:At the start of the epoch: mem (CPU python)=8786.2421875MB; mem (CPU total)=11860.203125MB
INFO:root:[   69] Training loss: 0.39548478, Validation loss: 0.82549287, Gradient norm: 0.36020138
INFO:root:At the start of the epoch: mem (CPU python)=8807.40625MB; mem (CPU total)=11888.97265625MB
INFO:root:[   70] Training loss: 0.38990501, Validation loss: 0.81868245, Gradient norm: 0.36794536
INFO:root:At the start of the epoch: mem (CPU python)=8828.56640625MB; mem (CPU total)=11853.21875MB
INFO:root:[   71] Training loss: 0.38519299, Validation loss: 0.81530484, Gradient norm: 0.36797768
INFO:root:At the start of the epoch: mem (CPU python)=8849.734375MB; mem (CPU total)=12069.41015625MB
INFO:root:[   72] Training loss: 0.38137274, Validation loss: 0.80835510, Gradient norm: 0.37700493
INFO:root:At the start of the epoch: mem (CPU python)=8870.8984375MB; mem (CPU total)=11900.86328125MB
INFO:root:[   73] Training loss: 0.37858131, Validation loss: 0.80335254, Gradient norm: 0.36142850
INFO:root:At the start of the epoch: mem (CPU python)=8892.0625MB; mem (CPU total)=12006.05859375MB
INFO:root:[   74] Training loss: 0.37561368, Validation loss: 0.79610607, Gradient norm: 0.37751586
INFO:root:At the start of the epoch: mem (CPU python)=8913.22265625MB; mem (CPU total)=11926.16015625MB
INFO:root:[   75] Training loss: 0.37305318, Validation loss: 0.79229795, Gradient norm: 0.36854078
INFO:root:At the start of the epoch: mem (CPU python)=8934.38671875MB; mem (CPU total)=12098.27734375MB
INFO:root:[   76] Training loss: 0.37074998, Validation loss: 0.79236925, Gradient norm: 0.38682620
INFO:root:At the start of the epoch: mem (CPU python)=8955.55078125MB; mem (CPU total)=12088.9375MB
INFO:root:[   77] Training loss: 0.36820870, Validation loss: 0.78934772, Gradient norm: 0.37391898
INFO:root:At the start of the epoch: mem (CPU python)=8976.71484375MB; mem (CPU total)=11971.17578125MB
INFO:root:[   78] Training loss: 0.36680530, Validation loss: 0.78888023, Gradient norm: 0.38462406
INFO:root:At the start of the epoch: mem (CPU python)=8997.8828125MB; mem (CPU total)=11999.28125MB
INFO:root:[   79] Training loss: 0.36449519, Validation loss: 0.78090838, Gradient norm: 0.37962221
INFO:root:At the start of the epoch: mem (CPU python)=9019.04296875MB; mem (CPU total)=12155.73828125MB
INFO:root:[   80] Training loss: 0.36301962, Validation loss: 0.78065660, Gradient norm: 0.38872715
INFO:root:At the start of the epoch: mem (CPU python)=9040.20703125MB; mem (CPU total)=12189.4375MB
INFO:root:[   81] Training loss: 0.36154786, Validation loss: 0.77663846, Gradient norm: 0.40872983
INFO:root:At the start of the epoch: mem (CPU python)=9061.37109375MB; mem (CPU total)=12279.59765625MB
INFO:root:[   82] Training loss: 0.35952880, Validation loss: 0.77350342, Gradient norm: 0.41751011
INFO:root:At the start of the epoch: mem (CPU python)=9082.53515625MB; mem (CPU total)=12113.9453125MB
INFO:root:[   83] Training loss: 0.35871761, Validation loss: 0.77321601, Gradient norm: 0.40167890
INFO:root:At the start of the epoch: mem (CPU python)=9103.69921875MB; mem (CPU total)=12194.73828125MB
INFO:root:[   84] Training loss: 0.35697720, Validation loss: 0.77117221, Gradient norm: 0.39329804
INFO:root:At the start of the epoch: mem (CPU python)=9124.8671875MB; mem (CPU total)=12205.1796875MB
INFO:root:[   85] Training loss: 0.35595767, Validation loss: 0.76790594, Gradient norm: 0.40126974
INFO:root:At the start of the epoch: mem (CPU python)=9146.03125MB; mem (CPU total)=12195.0703125MB
INFO:root:[   86] Training loss: 0.35505188, Validation loss: 0.76603768, Gradient norm: 0.41285783
INFO:root:At the start of the epoch: mem (CPU python)=9167.1953125MB; mem (CPU total)=12252.1875MB
INFO:root:[   87] Training loss: 0.35431974, Validation loss: 0.76146867, Gradient norm: 0.39821040
INFO:root:At the start of the epoch: mem (CPU python)=9188.359375MB; mem (CPU total)=12275.85546875MB
INFO:root:[   88] Training loss: 0.35271914, Validation loss: 0.75984976, Gradient norm: 0.40654080
INFO:root:At the start of the epoch: mem (CPU python)=9209.5234375MB; mem (CPU total)=12355.15234375MB
INFO:root:[   89] Training loss: 0.35180769, Validation loss: 0.75769311, Gradient norm: 0.40774453
INFO:root:At the start of the epoch: mem (CPU python)=9230.6875MB; mem (CPU total)=12279.15625MB
INFO:root:[   90] Training loss: 0.35124378, Validation loss: 0.75625085, Gradient norm: 0.39670125
INFO:root:At the start of the epoch: mem (CPU python)=9251.8515625MB; mem (CPU total)=12398.1328125MB
INFO:root:[   91] Training loss: 0.35028968, Validation loss: 0.75612361, Gradient norm: 0.41401521
INFO:root:At the start of the epoch: mem (CPU python)=9273.01171875MB; mem (CPU total)=12444.69921875MB
INFO:root:[   92] Training loss: 0.34952345, Validation loss: 0.75018898, Gradient norm: 0.41674349
INFO:root:At the start of the epoch: mem (CPU python)=9294.17578125MB; mem (CPU total)=12440.10546875MB
INFO:root:[   93] Training loss: 0.34844100, Validation loss: 0.75209651, Gradient norm: 0.41460518
INFO:root:At the start of the epoch: mem (CPU python)=9315.33984375MB; mem (CPU total)=12375.65234375MB
INFO:root:[   94] Training loss: 0.34739681, Validation loss: 0.75888559, Gradient norm: 0.41516704
INFO:root:At the start of the epoch: mem (CPU python)=9336.50390625MB; mem (CPU total)=12542.8359375MB
INFO:root:[   95] Training loss: 0.34648488, Validation loss: 0.75056193, Gradient norm: 0.41831177
INFO:root:At the start of the epoch: mem (CPU python)=9357.66796875MB; mem (CPU total)=12335.3046875MB
INFO:root:[   96] Training loss: 0.34544600, Validation loss: 0.74589489, Gradient norm: 0.41282088
INFO:root:At the start of the epoch: mem (CPU python)=9378.8359375MB; mem (CPU total)=12471.546875MB
INFO:root:[   97] Training loss: 0.34494760, Validation loss: 0.74649920, Gradient norm: 0.40935999
INFO:root:At the start of the epoch: mem (CPU python)=9399.99609375MB; mem (CPU total)=12440.6328125MB
INFO:root:[   98] Training loss: 0.34426915, Validation loss: 0.74898677, Gradient norm: 0.43073069
INFO:root:At the start of the epoch: mem (CPU python)=9421.171875MB; mem (CPU total)=12497.68359375MB
INFO:root:[   99] Training loss: 0.34346049, Validation loss: 0.74499513, Gradient norm: 0.41153164
INFO:root:At the start of the epoch: mem (CPU python)=9442.3359375MB; mem (CPU total)=12491.6015625MB
INFO:root:[  100] Training loss: 0.34287843, Validation loss: 0.74667422, Gradient norm: 0.41037812
INFO:root:At the start of the epoch: mem (CPU python)=9463.5MB; mem (CPU total)=12558.20703125MB
INFO:root:[  101] Training loss: 0.34225006, Validation loss: 0.74155220, Gradient norm: 0.41550778
INFO:root:At the start of the epoch: mem (CPU python)=9484.66796875MB; mem (CPU total)=12671.59375MB
INFO:root:[  102] Training loss: 0.34172423, Validation loss: 0.74587431, Gradient norm: 0.41908677
INFO:root:At the start of the epoch: mem (CPU python)=9505.828125MB; mem (CPU total)=12612.29296875MB
INFO:root:[  103] Training loss: 0.34074235, Validation loss: 0.74732635, Gradient norm: 0.42159547
INFO:root:At the start of the epoch: mem (CPU python)=9526.99609375MB; mem (CPU total)=12644.6171875MB
INFO:root:[  104] Training loss: 0.34027579, Validation loss: 0.73577163, Gradient norm: 0.41028775
INFO:root:At the start of the epoch: mem (CPU python)=9548.16015625MB; mem (CPU total)=12564.31640625MB
INFO:root:[  105] Training loss: 0.33961723, Validation loss: 0.74300853, Gradient norm: 0.43007487
INFO:root:At the start of the epoch: mem (CPU python)=9569.32421875MB; mem (CPU total)=12817.93359375MB
INFO:root:[  106] Training loss: 0.33920583, Validation loss: 0.74015577, Gradient norm: 0.43402730
INFO:root:At the start of the epoch: mem (CPU python)=9590.48828125MB; mem (CPU total)=12735.30859375MB
INFO:root:[  107] Training loss: 0.33858344, Validation loss: 0.73489940, Gradient norm: 0.41975691
INFO:root:At the start of the epoch: mem (CPU python)=9611.65625MB; mem (CPU total)=12593.87109375MB
INFO:root:[  108] Training loss: 0.33833652, Validation loss: 0.73771824, Gradient norm: 0.42151460
INFO:root:At the start of the epoch: mem (CPU python)=9632.8125MB; mem (CPU total)=12814.6875MB
INFO:root:[  109] Training loss: 0.33736140, Validation loss: 0.73332383, Gradient norm: 0.41518350
INFO:root:At the start of the epoch: mem (CPU python)=9653.9765625MB; mem (CPU total)=12813.93359375MB
INFO:root:[  110] Training loss: 0.33681246, Validation loss: 0.73486261, Gradient norm: 0.43034785
INFO:root:At the start of the epoch: mem (CPU python)=9675.140625MB; mem (CPU total)=12763.59375MB
INFO:root:[  111] Training loss: 0.33653998, Validation loss: 0.73469216, Gradient norm: 0.42629871
INFO:root:At the start of the epoch: mem (CPU python)=9696.3046875MB; mem (CPU total)=12807.26953125MB
INFO:root:[  112] Training loss: 0.33601328, Validation loss: 0.73798253, Gradient norm: 0.43673838
INFO:root:At the start of the epoch: mem (CPU python)=9717.46875MB; mem (CPU total)=12778.52734375MB
INFO:root:[  113] Training loss: 0.33540097, Validation loss: 0.73161973, Gradient norm: 0.42136363
INFO:root:At the start of the epoch: mem (CPU python)=9738.63671875MB; mem (CPU total)=12964.34375MB
INFO:root:[  114] Training loss: 0.33535515, Validation loss: 0.73566838, Gradient norm: 0.45082188
INFO:root:At the start of the epoch: mem (CPU python)=9759.796875MB; mem (CPU total)=12935.109375MB
INFO:root:[  115] Training loss: 0.33406863, Validation loss: 0.73162683, Gradient norm: 0.42884076
INFO:root:At the start of the epoch: mem (CPU python)=9780.96484375MB; mem (CPU total)=12849.921875MB
INFO:root:[  116] Training loss: 0.33401933, Validation loss: 0.73381174, Gradient norm: 0.44668399
INFO:root:At the start of the epoch: mem (CPU python)=9802.12890625MB; mem (CPU total)=12898.0859375MB
INFO:root:[  117] Training loss: 0.33352509, Validation loss: 0.73068173, Gradient norm: 0.42637045
INFO:root:At the start of the epoch: mem (CPU python)=9823.2890625MB; mem (CPU total)=13001.234375MB
INFO:root:[  118] Training loss: 0.33339179, Validation loss: 0.73096386, Gradient norm: 0.44101631
INFO:root:At the start of the epoch: mem (CPU python)=9844.453125MB; mem (CPU total)=13004.76171875MB
INFO:root:[  119] Training loss: 0.33268201, Validation loss: 0.72097648, Gradient norm: 0.43991619
INFO:root:At the start of the epoch: mem (CPU python)=9865.62109375MB; mem (CPU total)=13090.1875MB
INFO:root:[  120] Training loss: 0.33244146, Validation loss: 0.72599714, Gradient norm: 0.44562840
INFO:root:At the start of the epoch: mem (CPU python)=9886.7890625MB; mem (CPU total)=12930.0859375MB
INFO:root:[  121] Training loss: 0.33155678, Validation loss: 0.73029826, Gradient norm: 0.42985943
INFO:root:At the start of the epoch: mem (CPU python)=9907.953125MB; mem (CPU total)=13077.84375MB
INFO:root:[  122] Training loss: 0.33142758, Validation loss: 0.72996551, Gradient norm: 0.44904724
INFO:root:At the start of the epoch: mem (CPU python)=9929.1171875MB; mem (CPU total)=13158.99609375MB
INFO:root:[  123] Training loss: 0.33106522, Validation loss: 0.72550360, Gradient norm: 0.44348304
INFO:root:At the start of the epoch: mem (CPU python)=9950.28125MB; mem (CPU total)=13155.546875MB
INFO:root:[  124] Training loss: 0.33042343, Validation loss: 0.72433115, Gradient norm: 0.44142328
INFO:root:At the start of the epoch: mem (CPU python)=9971.44140625MB; mem (CPU total)=13060.05078125MB
INFO:root:[  125] Training loss: 0.33013107, Validation loss: 0.72528886, Gradient norm: 0.44028260
INFO:root:At the start of the epoch: mem (CPU python)=9992.60546875MB; mem (CPU total)=13045.1640625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[  126] Training loss: 0.32956659, Validation loss: 0.72723282, Gradient norm: 0.45387168
INFO:root:At the start of the epoch: mem (CPU python)=10013.76953125MB; mem (CPU total)=13020.296875MB
INFO:root:[  127] Training loss: 0.32885259, Validation loss: 0.72086980, Gradient norm: 0.40039220
INFO:root:At the start of the epoch: mem (CPU python)=10034.93359375MB; mem (CPU total)=13116.7109375MB
INFO:root:[  128] Training loss: 0.32839622, Validation loss: 0.72077639, Gradient norm: 0.40188981
INFO:root:At the start of the epoch: mem (CPU python)=10056.09765625MB; mem (CPU total)=13072.8671875MB
INFO:root:[  129] Training loss: 0.32805545, Validation loss: 0.72645397, Gradient norm: 0.40363733
INFO:root:At the start of the epoch: mem (CPU python)=10077.26171875MB; mem (CPU total)=13095.17578125MB
INFO:root:[  130] Training loss: 0.32813803, Validation loss: 0.71881664, Gradient norm: 0.40171995
INFO:root:At the start of the epoch: mem (CPU python)=10098.4296875MB; mem (CPU total)=13122.671875MB
INFO:root:[  131] Training loss: 0.32799339, Validation loss: 0.72224796, Gradient norm: 0.40272308
INFO:root:At the start of the epoch: mem (CPU python)=10119.58984375MB; mem (CPU total)=13225.25390625MB
INFO:root:[  132] Training loss: 0.32755784, Validation loss: 0.71909366, Gradient norm: 0.40418807
INFO:root:At the start of the epoch: mem (CPU python)=10140.7578125MB; mem (CPU total)=13231.7734375MB
INFO:root:[  133] Training loss: 0.32739851, Validation loss: 0.72278017, Gradient norm: 0.40919202
INFO:root:At the start of the epoch: mem (CPU python)=10161.921875MB; mem (CPU total)=13244.16796875MB
INFO:root:[  134] Training loss: 0.32715869, Validation loss: 0.72039025, Gradient norm: 0.40625542
INFO:root:At the start of the epoch: mem (CPU python)=10183.0859375MB; mem (CPU total)=13199.03125MB
INFO:root:[  135] Training loss: 0.32684314, Validation loss: 0.71771462, Gradient norm: 0.40346339
INFO:root:At the start of the epoch: mem (CPU python)=10204.25390625MB; mem (CPU total)=13315.578125MB
INFO:root:[  136] Training loss: 0.32696832, Validation loss: 0.72198122, Gradient norm: 0.41045885
INFO:root:At the start of the epoch: mem (CPU python)=10225.41015625MB; mem (CPU total)=13405.42578125MB
INFO:root:[  137] Training loss: 0.32666086, Validation loss: 0.71867742, Gradient norm: 0.41401629
INFO:root:At the start of the epoch: mem (CPU python)=10246.57421875MB; mem (CPU total)=13302.9296875MB
INFO:root:[  138] Training loss: 0.32651074, Validation loss: 0.72148174, Gradient norm: 0.41601511
INFO:root:At the start of the epoch: mem (CPU python)=10267.7421875MB; mem (CPU total)=13391.3046875MB
INFO:root:[  139] Training loss: 0.32583279, Validation loss: 0.71996422, Gradient norm: 0.41186761
INFO:root:At the start of the epoch: mem (CPU python)=10288.90625MB; mem (CPU total)=13440.85546875MB
INFO:root:[  140] Training loss: 0.32601053, Validation loss: 0.71856977, Gradient norm: 0.40786206
INFO:root:At the start of the epoch: mem (CPU python)=10310.0703125MB; mem (CPU total)=13464.71875MB
INFO:root:[  141] Training loss: 0.32537766, Validation loss: 0.71647623, Gradient norm: 0.41648908
INFO:root:At the start of the epoch: mem (CPU python)=10331.23828125MB; mem (CPU total)=13472.72265625MB
INFO:root:[  142] Training loss: 0.32564986, Validation loss: 0.71693625, Gradient norm: 0.41891509
INFO:root:At the start of the epoch: mem (CPU python)=10352.3984375MB; mem (CPU total)=13509.73828125MB
INFO:root:[  143] Training loss: 0.32536989, Validation loss: 0.72103732, Gradient norm: 0.41702345
INFO:root:At the start of the epoch: mem (CPU python)=10373.5625MB; mem (CPU total)=13427.37109375MB
INFO:root:[  144] Training loss: 0.32485456, Validation loss: 0.71877277, Gradient norm: 0.42082224
INFO:root:At the start of the epoch: mem (CPU python)=10394.7265625MB; mem (CPU total)=13363.62890625MB
INFO:root:[  145] Training loss: 0.32491478, Validation loss: 0.71962569, Gradient norm: 0.40713839
INFO:root:At the start of the epoch: mem (CPU python)=10415.88671875MB; mem (CPU total)=13412.4453125MB
INFO:root:[  146] Training loss: 0.32469199, Validation loss: 0.71748967, Gradient norm: 0.41718353
INFO:root:At the start of the epoch: mem (CPU python)=10437.05078125MB; mem (CPU total)=13608.0078125MB
INFO:root:[  147] Training loss: 0.32441505, Validation loss: 0.71714500, Gradient norm: 0.42251637
INFO:root:At the start of the epoch: mem (CPU python)=10458.21875MB; mem (CPU total)=13503.91796875MB
INFO:root:[  148] Training loss: 0.32435244, Validation loss: 0.72091461, Gradient norm: 0.41930866
INFO:root:At the start of the epoch: mem (CPU python)=10479.3828125MB; mem (CPU total)=13618.10546875MB
INFO:root:[  149] Training loss: 0.32427449, Validation loss: 0.71652609, Gradient norm: 0.40682200
INFO:root:At the start of the epoch: mem (CPU python)=10500.546875MB; mem (CPU total)=13522.578125MB
INFO:root:[  150] Training loss: 0.32371500, Validation loss: 0.71677307, Gradient norm: 0.42134018
INFO:root:At the start of the epoch: mem (CPU python)=10521.7109375MB; mem (CPU total)=13572.2578125MB
INFO:root:EP 150: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=10542.875MB; mem (CPU total)=13670.07421875MB
INFO:root:Training the model took 15701.969s.
INFO:root:Emptying the cuda cache took 0.138s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.57318
INFO:root:EnergyScoreValidation: 0.57314
INFO:root:CRPSValidation: 0.22875
INFO:root:Gaussian NLLValidation: 866384870.41523
INFO:root:CoverageValidation: 7e-05
INFO:root:IntervalWidthValidation: 5e-05
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.44928
INFO:root:EnergyScoreTest: 0.44444
INFO:root:CRPSTest: 0.17666
INFO:root:Gaussian NLLTest: 32109818863.61602
INFO:root:CoverageTest: 1e-05
INFO:root:IntervalWidthTest: 0.0
INFO:root:After validation: mem (CPU python)=10549.5703125MB; mem (CPU total)=13545.82421875MB
INFO:root:###3 out of 3 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'SFNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 8, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.005, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 256, 'lifting_channels': 256, 'n_modes': (32, 32), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=10549.5703125MB; mem (CPU total)=13518.15625MB
INFO:root:NumberParameters: 294054
INFO:root:GPU memory allocated: 44040192
INFO:root:After setting up the model: mem (CPU python)=10549.5703125MB; mem (CPU total)=13454.78515625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=10549.5703125MB; mem (CPU total)=13647.765625MB
INFO:root:[    1] Training loss: 1.24613809, Validation loss: 1.22985388, Gradient norm: 0.13416884
INFO:root:At the start of the epoch: mem (CPU python)=10549.5703125MB; mem (CPU total)=13598.55859375MB
INFO:root:[    2] Training loss: 1.22304858, Validation loss: 1.20847797, Gradient norm: 0.09862805
INFO:root:At the start of the epoch: mem (CPU python)=10561.11328125MB; mem (CPU total)=13703.41796875MB
INFO:root:[    3] Training loss: 1.19709301, Validation loss: 1.19182007, Gradient norm: 0.11213301
INFO:root:At the start of the epoch: mem (CPU python)=10582.87890625MB; mem (CPU total)=13636.12109375MB
INFO:root:[    4] Training loss: 1.18899993, Validation loss: 1.18511922, Gradient norm: 0.10966642
INFO:root:At the start of the epoch: mem (CPU python)=10604.04296875MB; mem (CPU total)=13820.12890625MB
INFO:root:[    5] Training loss: 1.18084583, Validation loss: 1.17454173, Gradient norm: 0.11548113
INFO:root:At the start of the epoch: mem (CPU python)=10625.2109375MB; mem (CPU total)=13683.35546875MB
INFO:root:[    6] Training loss: 1.16897264, Validation loss: 1.16656737, Gradient norm: 0.12389976
INFO:root:At the start of the epoch: mem (CPU python)=10646.375MB; mem (CPU total)=13708.52734375MB
INFO:root:[    7] Training loss: 1.16411563, Validation loss: 1.16176879, Gradient norm: 0.12410809
INFO:root:At the start of the epoch: mem (CPU python)=10667.53515625MB; mem (CPU total)=13756.1015625MB
INFO:root:[    8] Training loss: 1.15972124, Validation loss: 1.15838254, Gradient norm: 0.12251022
INFO:root:At the start of the epoch: mem (CPU python)=10688.69921875MB; mem (CPU total)=13798.44921875MB
INFO:root:[    9] Training loss: 1.15685958, Validation loss: 1.15847432, Gradient norm: 0.13044923
INFO:root:At the start of the epoch: mem (CPU python)=10709.86328125MB; mem (CPU total)=13915.74609375MB
INFO:root:[   10] Training loss: 1.15499780, Validation loss: 1.15565662, Gradient norm: 0.13330168
INFO:root:At the start of the epoch: mem (CPU python)=10731.02734375MB; mem (CPU total)=13757.04296875MB
INFO:root:[   11] Training loss: 1.15390162, Validation loss: 1.15712996, Gradient norm: 0.14138017
INFO:root:At the start of the epoch: mem (CPU python)=10754.5859375MB; mem (CPU total)=13905.90234375MB
INFO:root:[   12] Training loss: 1.15228878, Validation loss: 1.15603988, Gradient norm: 0.14390651
INFO:root:At the start of the epoch: mem (CPU python)=10779.0234375MB; mem (CPU total)=13900.296875MB
INFO:root:[   13] Training loss: 1.15127525, Validation loss: 1.15433487, Gradient norm: 0.14749284
INFO:root:At the start of the epoch: mem (CPU python)=10800.51953125MB; mem (CPU total)=13920.546875MB
INFO:root:[   14] Training loss: 1.15087709, Validation loss: 1.15773569, Gradient norm: 0.16594586
INFO:root:At the start of the epoch: mem (CPU python)=10821.68359375MB; mem (CPU total)=14048.80078125MB
INFO:root:[   15] Training loss: 1.15252835, Validation loss: 1.15928980, Gradient norm: 0.19617972
INFO:root:At the start of the epoch: mem (CPU python)=10842.84765625MB; mem (CPU total)=13982.7265625MB
INFO:root:[   16] Training loss: 1.15325104, Validation loss: 1.16002739, Gradient norm: 0.20719313
INFO:root:At the start of the epoch: mem (CPU python)=10865.30078125MB; mem (CPU total)=14024.13671875MB
INFO:root:[   17] Training loss: 1.15353882, Validation loss: 1.17782064, Gradient norm: 0.22454570
INFO:root:At the start of the epoch: mem (CPU python)=10886.671875MB; mem (CPU total)=14036.22265625MB
INFO:root:[   18] Training loss: 1.15541553, Validation loss: 1.16010007, Gradient norm: 0.24608271
INFO:root:At the start of the epoch: mem (CPU python)=10907.83984375MB; mem (CPU total)=14107.7109375MB
INFO:root:[   19] Training loss: 1.15254261, Validation loss: 1.17134255, Gradient norm: 0.21239781
INFO:root:At the start of the epoch: mem (CPU python)=10929.00390625MB; mem (CPU total)=14149.6640625MB
INFO:root:[   20] Training loss: 1.15216933, Validation loss: 1.17038692, Gradient norm: 0.22566245
INFO:root:At the start of the epoch: mem (CPU python)=10950.16796875MB; mem (CPU total)=14104.0859375MB
INFO:root:[   21] Training loss: 1.15217588, Validation loss: 1.16655522, Gradient norm: 0.21920517
INFO:root:At the start of the epoch: mem (CPU python)=10971.33203125MB; mem (CPU total)=14114.30078125MB
INFO:root:[   22] Training loss: 1.15250318, Validation loss: 1.16866836, Gradient norm: 0.22918687
INFO:root:At the start of the epoch: mem (CPU python)=10992.49609375MB; mem (CPU total)=14220.73046875MB
INFO:root:[   23] Training loss: 1.14999782, Validation loss: 1.16659275, Gradient norm: 0.19722037
INFO:root:At the start of the epoch: mem (CPU python)=11013.6640625MB; mem (CPU total)=14165.12890625MB
INFO:root:[   24] Training loss: 1.15034993, Validation loss: 1.16919257, Gradient norm: 0.21480835
INFO:root:At the start of the epoch: mem (CPU python)=11034.828125MB; mem (CPU total)=14286.47265625MB
INFO:root:[   25] Training loss: 1.15170730, Validation loss: 1.17594558, Gradient norm: 0.23040372
INFO:root:At the start of the epoch: mem (CPU python)=11055.9921875MB; mem (CPU total)=14184.3671875MB
INFO:root:[   26] Training loss: 1.14956180, Validation loss: 1.16507634, Gradient norm: 0.20478279
INFO:root:At the start of the epoch: mem (CPU python)=11077.15625MB; mem (CPU total)=14232.71875MB
INFO:root:[   27] Training loss: 1.15011056, Validation loss: 1.16627629, Gradient norm: 0.20403868
INFO:root:At the start of the epoch: mem (CPU python)=11098.31640625MB; mem (CPU total)=14220.625MB
INFO:root:[   28] Training loss: 1.14829597, Validation loss: 1.18008715, Gradient norm: 0.20502084
INFO:root:At the start of the epoch: mem (CPU python)=11119.48046875MB; mem (CPU total)=14262.4140625MB
INFO:root:[   29] Training loss: 1.14995712, Validation loss: 1.16853937, Gradient norm: 0.22574904
INFO:root:At the start of the epoch: mem (CPU python)=11140.64453125MB; mem (CPU total)=14256.78515625MB
INFO:root:[   30] Training loss: 1.14866735, Validation loss: 1.16599067, Gradient norm: 0.20946213
INFO:root:At the start of the epoch: mem (CPU python)=11161.80859375MB; mem (CPU total)=14279.5390625MB
INFO:root:[   31] Training loss: 1.14826897, Validation loss: 1.17587349, Gradient norm: 0.22303506
INFO:root:At the start of the epoch: mem (CPU python)=11182.97265625MB; mem (CPU total)=14373.54296875MB
INFO:root:[   32] Training loss: 1.15089278, Validation loss: 1.16970945, Gradient norm: 0.25136341
INFO:root:At the start of the epoch: mem (CPU python)=11205.078125MB; mem (CPU total)=14267.6328125MB
INFO:root:[   33] Training loss: 1.14859543, Validation loss: 1.16858271, Gradient norm: 0.21949151
INFO:root:At the start of the epoch: mem (CPU python)=11226.46484375MB; mem (CPU total)=14312.37890625MB
INFO:root:[   34] Training loss: 1.14781648, Validation loss: 1.17007666, Gradient norm: 0.21510790
INFO:root:At the start of the epoch: mem (CPU python)=11247.9296875MB; mem (CPU total)=14504.64453125MB
INFO:root:[   35] Training loss: 1.14796286, Validation loss: 1.16719115, Gradient norm: 0.22782994
INFO:root:At the start of the epoch: mem (CPU python)=11269.1328125MB; mem (CPU total)=14393.27734375MB
INFO:root:[   36] Training loss: 1.14800178, Validation loss: 1.16600633, Gradient norm: 0.22853378
INFO:root:At the start of the epoch: mem (CPU python)=11290.29296875MB; mem (CPU total)=14431.55078125MB
INFO:root:[   37] Training loss: 1.14791126, Validation loss: 1.17097320, Gradient norm: 0.24431886
INFO:root:At the start of the epoch: mem (CPU python)=11311.45703125MB; mem (CPU total)=14517.6171875MB
INFO:root:[   38] Training loss: 1.14910492, Validation loss: 1.17803380, Gradient norm: 0.26119416
INFO:root:At the start of the epoch: mem (CPU python)=11332.62109375MB; mem (CPU total)=14450.67578125MB
INFO:root:[   39] Training loss: 1.14741518, Validation loss: 1.17094909, Gradient norm: 0.25560095
INFO:root:At the start of the epoch: mem (CPU python)=11353.7890625MB; mem (CPU total)=14486.22265625MB
INFO:root:[   40] Training loss: 1.14620473, Validation loss: 1.17594214, Gradient norm: 0.24863676
INFO:root:At the start of the epoch: mem (CPU python)=11374.953125MB; mem (CPU total)=14430.59765625MB
INFO:root:[   41] Training loss: 1.14527364, Validation loss: 1.17155037, Gradient norm: 0.20766707
INFO:root:At the start of the epoch: mem (CPU python)=11396.1171875MB; mem (CPU total)=14516.9921875MB
INFO:root:[   42] Training loss: 1.14764163, Validation loss: 1.18207664, Gradient norm: 0.26395817
INFO:root:At the start of the epoch: mem (CPU python)=11417.28125MB; mem (CPU total)=14423.60546875MB
INFO:root:[   43] Training loss: 1.14673953, Validation loss: 1.17108491, Gradient norm: 0.24497501
INFO:root:At the start of the epoch: mem (CPU python)=11438.4453125MB; mem (CPU total)=14639.7421875MB
INFO:root:[   44] Training loss: 1.14640772, Validation loss: 1.17677813, Gradient norm: 0.27023235
INFO:root:At the start of the epoch: mem (CPU python)=11459.61328125MB; mem (CPU total)=14649.05078125MB
INFO:root:[   45] Training loss: 1.14846016, Validation loss: 1.17166729, Gradient norm: 0.29024132
INFO:root:At the start of the epoch: mem (CPU python)=11480.76953125MB; mem (CPU total)=14521.3046875MB
INFO:root:[   46] Training loss: 1.14699249, Validation loss: 1.18317195, Gradient norm: 0.27910343
INFO:root:At the start of the epoch: mem (CPU python)=11501.93359375MB; mem (CPU total)=14622.7421875MB
INFO:root:[   47] Training loss: 1.14620878, Validation loss: 1.18691626, Gradient norm: 0.27665020
INFO:root:At the start of the epoch: mem (CPU python)=11523.09765625MB; mem (CPU total)=14730.125MB
INFO:root:[   48] Training loss: 1.14754615, Validation loss: 1.19062537, Gradient norm: 0.28825423
INFO:root:At the start of the epoch: mem (CPU python)=11544.26171875MB; mem (CPU total)=14576.25390625MB
INFO:root:[   49] Training loss: 1.14601602, Validation loss: 1.18375122, Gradient norm: 0.26295722
INFO:root:At the start of the epoch: mem (CPU python)=11565.42578125MB; mem (CPU total)=14798.8515625MB
INFO:root:[   50] Training loss: 1.14718982, Validation loss: 1.18161707, Gradient norm: 0.29359334
INFO:root:At the start of the epoch: mem (CPU python)=11586.58984375MB; mem (CPU total)=14618.65625MB
INFO:root:[   51] Training loss: 1.14569780, Validation loss: 1.19101730, Gradient norm: 0.26574764
INFO:root:At the start of the epoch: mem (CPU python)=11607.7578125MB; mem (CPU total)=14864.83984375MB
INFO:root:[   52] Training loss: 1.14664546, Validation loss: 1.18660628, Gradient norm: 0.28457949
INFO:root:At the start of the epoch: mem (CPU python)=11628.921875MB; mem (CPU total)=14752.08984375MB
INFO:root:[   53] Training loss: 1.14769109, Validation loss: 1.17296627, Gradient norm: 0.27585008
INFO:root:At the start of the epoch: mem (CPU python)=11650.0859375MB; mem (CPU total)=14913.0078125MB
INFO:root:[   54] Training loss: 1.14596753, Validation loss: 1.17805762, Gradient norm: 0.27183716
INFO:root:At the start of the epoch: mem (CPU python)=11671.25MB; mem (CPU total)=14935.00390625MB
INFO:root:[   55] Training loss: 1.14640228, Validation loss: 1.18643514, Gradient norm: 0.30188248
INFO:root:At the start of the epoch: mem (CPU python)=11692.4140625MB; mem (CPU total)=14956.83203125MB
INFO:root:[   56] Training loss: 1.14644176, Validation loss: 1.17695519, Gradient norm: 0.29538241
INFO:root:At the start of the epoch: mem (CPU python)=11713.578125MB; mem (CPU total)=14758.71484375MB
INFO:root:[   57] Training loss: 1.14588004, Validation loss: 1.18405393, Gradient norm: 0.29860195
INFO:root:At the start of the epoch: mem (CPU python)=11734.7421875MB; mem (CPU total)=14946.60546875MB
INFO:root:[   58] Training loss: 1.14563758, Validation loss: 1.18260847, Gradient norm: 0.29552355
INFO:root:At the start of the epoch: mem (CPU python)=11755.90625MB; mem (CPU total)=14889.0234375MB
INFO:root:[   59] Training loss: 1.14706096, Validation loss: 1.20928724, Gradient norm: 0.32189796
INFO:root:At the start of the epoch: mem (CPU python)=11777.0703125MB; mem (CPU total)=14796.2421875MB
INFO:root:Learning rate reduced to: 0.0025
INFO:root:[   60] Training loss: 1.14687422, Validation loss: 1.17937910, Gradient norm: 0.31561457
INFO:root:At the start of the epoch: mem (CPU python)=11798.234375MB; mem (CPU total)=14952.0078125MB
INFO:root:Learning rate reduced to: 0.00125
INFO:root:[   61] Training loss: 1.13866851, Validation loss: 1.18255802, Gradient norm: 0.23361185
INFO:root:At the start of the epoch: mem (CPU python)=11819.40234375MB; mem (CPU total)=14943.515625MB
INFO:root:Learning rate reduced to: 0.000625
INFO:root:[   62] Training loss: 1.13661059, Validation loss: 1.17142812, Gradient norm: 0.18556939
INFO:root:At the start of the epoch: mem (CPU python)=11840.5625MB; mem (CPU total)=15023.2265625MB
INFO:root:[   63] Training loss: 1.13559692, Validation loss: 1.17295076, Gradient norm: 0.16745459
INFO:root:At the start of the epoch: mem (CPU python)=11861.7265625MB; mem (CPU total)=15126.33203125MB
INFO:root:[   64] Training loss: 1.13500579, Validation loss: 1.17033892, Gradient norm: 0.17230147
INFO:root:At the start of the epoch: mem (CPU python)=11882.88671875MB; mem (CPU total)=15002.765625MB
INFO:root:[   65] Training loss: 1.13372112, Validation loss: 1.17392225, Gradient norm: 0.17752027
INFO:root:At the start of the epoch: mem (CPU python)=11904.05078125MB; mem (CPU total)=15014.40234375MB
INFO:root:[   66] Training loss: 1.13443542, Validation loss: 1.17377659, Gradient norm: 0.18370083
INFO:root:At the start of the epoch: mem (CPU python)=11925.21484375MB; mem (CPU total)=15080.8359375MB
INFO:root:[   67] Training loss: 1.13420884, Validation loss: 1.17978738, Gradient norm: 0.17851883
INFO:root:At the start of the epoch: mem (CPU python)=11946.37890625MB; mem (CPU total)=15020.15625MB
INFO:root:[   68] Training loss: 1.13331965, Validation loss: 1.17846650, Gradient norm: 0.18190133
INFO:root:At the start of the epoch: mem (CPU python)=11967.546875MB; mem (CPU total)=15116.41015625MB
INFO:root:[   69] Training loss: 1.13362946, Validation loss: 1.17502275, Gradient norm: 0.18574545
INFO:root:At the start of the epoch: mem (CPU python)=11988.7109375MB; mem (CPU total)=15020.00390625MB
INFO:root:[   70] Training loss: 1.13468681, Validation loss: 1.17372290, Gradient norm: 0.18794762
INFO:root:At the start of the epoch: mem (CPU python)=12009.875MB; mem (CPU total)=14135.40234375MB
INFO:root:Learning rate reduced to: 0.0003125
INFO:root:[   71] Training loss: 1.13452763, Validation loss: 1.16951316, Gradient norm: 0.17739213
INFO:root:At the start of the epoch: mem (CPU python)=12031.0390625MB; mem (CPU total)=14171.66015625MB
INFO:root:[   72] Training loss: 1.13344919, Validation loss: 1.17247880, Gradient norm: 0.16480857
INFO:root:At the start of the epoch: mem (CPU python)=12052.20703125MB; mem (CPU total)=14193.33984375MB
INFO:root:[   73] Training loss: 1.13286344, Validation loss: 1.17090715, Gradient norm: 0.16993603
INFO:root:At the start of the epoch: mem (CPU python)=12073.37109375MB; mem (CPU total)=14213.73046875MB
INFO:root:[   74] Training loss: 1.13294480, Validation loss: 1.17262625, Gradient norm: 0.17445890
INFO:root:At the start of the epoch: mem (CPU python)=12094.53125MB; mem (CPU total)=13651.8671875MB
INFO:root:[   75] Training loss: 1.13233732, Validation loss: 1.17045167, Gradient norm: 0.17129552
INFO:root:At the start of the epoch: mem (CPU python)=12115.6953125MB; mem (CPU total)=13920.234375MB
INFO:root:[   76] Training loss: 1.13341670, Validation loss: 1.16826806, Gradient norm: 0.16944880
INFO:root:At the start of the epoch: mem (CPU python)=12136.859375MB; mem (CPU total)=14040.16015625MB
INFO:root:[   77] Training loss: 1.13294490, Validation loss: 1.17009083, Gradient norm: 0.17017718
INFO:root:At the start of the epoch: mem (CPU python)=12158.0234375MB; mem (CPU total)=13978.35546875MB
INFO:root:[   78] Training loss: 1.13316042, Validation loss: 1.17032132, Gradient norm: 0.17961061
INFO:root:At the start of the epoch: mem (CPU python)=12179.19140625MB; mem (CPU total)=14207.8203125MB
INFO:root:[   79] Training loss: 1.13320047, Validation loss: 1.17232123, Gradient norm: 0.17256935
INFO:root:At the start of the epoch: mem (CPU python)=12200.3515625MB; mem (CPU total)=14026.484375MB
INFO:root:[   80] Training loss: 1.13299434, Validation loss: 1.16901084, Gradient norm: 0.18280490
INFO:root:At the start of the epoch: mem (CPU python)=12221.515625MB; mem (CPU total)=14272.3359375MB
INFO:root:[   81] Training loss: 1.13351544, Validation loss: 1.16826484, Gradient norm: 0.16955903
INFO:root:At the start of the epoch: mem (CPU python)=12242.6796875MB; mem (CPU total)=14273.2578125MB
INFO:root:[   82] Training loss: 1.13244335, Validation loss: 1.17202315, Gradient norm: 0.17270413
INFO:root:At the start of the epoch: mem (CPU python)=12263.84375MB; mem (CPU total)=14402.8203125MB
INFO:root:[   83] Training loss: 1.13277230, Validation loss: 1.17065273, Gradient norm: 0.17058276
INFO:root:At the start of the epoch: mem (CPU python)=12285.00390625MB; mem (CPU total)=14406.24609375MB
INFO:root:[   84] Training loss: 1.13287212, Validation loss: 1.16867433, Gradient norm: 0.17174840
INFO:root:At the start of the epoch: mem (CPU python)=12306.171875MB; mem (CPU total)=14453.71484375MB
INFO:root:[   85] Training loss: 1.13256789, Validation loss: 1.17377710, Gradient norm: 0.17292243
INFO:root:At the start of the epoch: mem (CPU python)=12327.3359375MB; mem (CPU total)=14449.4140625MB
INFO:root:[   86] Training loss: 1.13211569, Validation loss: 1.17020191, Gradient norm: 0.17798494
INFO:root:At the start of the epoch: mem (CPU python)=12348.5MB; mem (CPU total)=14523.02734375MB
INFO:root:[   87] Training loss: 1.13257446, Validation loss: 1.17230600, Gradient norm: 0.17915743
INFO:root:At the start of the epoch: mem (CPU python)=12369.6640625MB; mem (CPU total)=14492.953125MB
INFO:root:Learning rate reduced to: 0.00015625
INFO:root:[   88] Training loss: 1.13259827, Validation loss: 1.17214853, Gradient norm: 0.17670228
INFO:root:At the start of the epoch: mem (CPU python)=12390.828125MB; mem (CPU total)=14599.09765625MB
INFO:root:Learning rate reduced to: 7.8125e-05
INFO:root:[   89] Training loss: 1.13316033, Validation loss: 1.17008840, Gradient norm: 0.16452126
INFO:root:At the start of the epoch: mem (CPU python)=12411.99609375MB; mem (CPU total)=14518.9140625MB
INFO:root:[   90] Training loss: 1.13148302, Validation loss: 1.16980577, Gradient norm: 0.15713946
INFO:root:At the start of the epoch: mem (CPU python)=12433.16015625MB; mem (CPU total)=14698.05859375MB
INFO:root:EP 90: Early stopping
INFO:root:Training for autoregressive step 2 starts now.
INFO:root:Learning rate reduced to: [3.90625e-05]
INFO:root:At the start of the epoch: mem (CPU python)=12454.32421875MB; mem (CPU total)=14638.21875MB
INFO:root:[   92] Training loss: 0.48805532, Validation loss: 0.66200940, Gradient norm: 0.68651224
INFO:root:At the start of the epoch: mem (CPU python)=12475.48828125MB; mem (CPU total)=14737.56640625MB
INFO:root:[   93] Training loss: 0.43209008, Validation loss: 0.67035808, Gradient norm: 0.53825971
INFO:root:At the start of the epoch: mem (CPU python)=12496.6484375MB; mem (CPU total)=14780.359375MB
INFO:root:[   94] Training loss: 0.42362159, Validation loss: 0.66998764, Gradient norm: 0.54548778
INFO:root:At the start of the epoch: mem (CPU python)=12517.8125MB; mem (CPU total)=14712.99609375MB
INFO:root:[   95] Training loss: 0.41738629, Validation loss: 0.68062761, Gradient norm: 0.55841924
INFO:root:At the start of the epoch: mem (CPU python)=12538.9765625MB; mem (CPU total)=14863.671875MB
INFO:root:[   96] Training loss: 0.41396970, Validation loss: 0.67916188, Gradient norm: 0.55852025
INFO:root:At the start of the epoch: mem (CPU python)=12560.140625MB; mem (CPU total)=14882.73828125MB
INFO:root:[   97] Training loss: 0.41089540, Validation loss: 0.68161937, Gradient norm: 0.57999601
INFO:root:At the start of the epoch: mem (CPU python)=12581.30859375MB; mem (CPU total)=14902.66796875MB
INFO:root:[   98] Training loss: 0.40861559, Validation loss: 0.67990129, Gradient norm: 0.56909066
INFO:root:At the start of the epoch: mem (CPU python)=12602.47265625MB; mem (CPU total)=14800.4296875MB
INFO:root:[   99] Training loss: 0.40638509, Validation loss: 0.68127046, Gradient norm: 0.59272778
INFO:root:At the start of the epoch: mem (CPU python)=12623.63671875MB; mem (CPU total)=14764.92578125MB
INFO:root:[  100] Training loss: 0.40339154, Validation loss: 0.68039290, Gradient norm: 0.58807289
INFO:root:At the start of the epoch: mem (CPU python)=12644.80078125MB; mem (CPU total)=14893.8671875MB
INFO:root:[  101] Training loss: 0.40242306, Validation loss: 0.67753195, Gradient norm: 0.60408674
INFO:root:At the start of the epoch: mem (CPU python)=12665.96875MB; mem (CPU total)=14915.55078125MB
INFO:root:EP 101: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12687.12890625MB; mem (CPU total)=14959.4296875MB
INFO:root:Training the model took 8326.106s.
INFO:root:Emptying the cuda cache took 0.137s.
INFO:root:Starting evaluation: model SFNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.60086
INFO:root:EnergyScoreValidation: 0.54455
INFO:root:CRPSValidation: 0.2326
INFO:root:Gaussian NLLValidation: 3260.52648
INFO:root:CoverageValidation: 0.07346
INFO:root:IntervalWidthValidation: 0.07287
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.46022
INFO:root:EnergyScoreTest: 0.39896
INFO:root:CRPSTest: 0.1834
INFO:root:Gaussian NLLTest: 31630422810.624
INFO:root:CoverageTest: 0.00557
INFO:root:IntervalWidthTest: 0.01421
INFO:root:After validation: mem (CPU python)=12693.77734375MB; mem (CPU total)=14795.3125MB
