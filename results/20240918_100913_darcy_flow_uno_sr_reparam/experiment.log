INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=577.50390625MB; mem (CPU total)=1038.51953125MB
INFO:root:############### Starting experiment with config file darcy_flow/uno_sr_reparam.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'DarcyFlow', 'max_training_set_size': 10000, 'downscaling_factor': 2}
INFO:root:After loading the datasets: mem (CPU python)=1997.5MB; mem (CPU total)=1049.57421875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=1997.5MB; mem (CPU total)=1049.6328125MB
INFO:root:NumberParameters: 5816002
INFO:root:GPU memory allocated: 44040192
INFO:root:After setting up the model: mem (CPU python)=2213.5703125MB; mem (CPU total)=2432.859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2213.5703125MB; mem (CPU total)=2441.22265625MB
INFO:root:[    1] Training loss: 0.25339423, Validation loss: 0.18001076, Gradient norm: 2.33806304
INFO:root:At the start of the epoch: mem (CPU python)=4452.109375MB; mem (CPU total)=4233.66015625MB
INFO:root:[    2] Training loss: 0.16108585, Validation loss: 0.18097400, Gradient norm: 2.17969143
INFO:root:At the start of the epoch: mem (CPU python)=4528.3125MB; mem (CPU total)=4308.90234375MB
INFO:root:[    3] Training loss: 0.15114752, Validation loss: 0.16886918, Gradient norm: 2.62014765
INFO:root:At the start of the epoch: mem (CPU python)=4604.6640625MB; mem (CPU total)=4385.47265625MB
INFO:root:[    4] Training loss: 0.13262188, Validation loss: 0.17213812, Gradient norm: 1.95092681
INFO:root:At the start of the epoch: mem (CPU python)=4680.87109375MB; mem (CPU total)=4462.0078125MB
INFO:root:[    5] Training loss: 0.12591630, Validation loss: 0.17667048, Gradient norm: 1.70864791
INFO:root:At the start of the epoch: mem (CPU python)=4757.05859375MB; mem (CPU total)=4538.76953125MB
INFO:root:[    6] Training loss: 0.11866353, Validation loss: 0.15961173, Gradient norm: 1.96737127
INFO:root:At the start of the epoch: mem (CPU python)=4833.26953125MB; mem (CPU total)=4616.71875MB
INFO:root:[    7] Training loss: 0.11348209, Validation loss: 0.16246390, Gradient norm: 1.85934696
INFO:root:At the start of the epoch: mem (CPU python)=4910.08203125MB; mem (CPU total)=4693.7265625MB
INFO:root:[    8] Training loss: 0.10765205, Validation loss: 0.15752505, Gradient norm: 1.52583897
INFO:root:At the start of the epoch: mem (CPU python)=4986.31640625MB; mem (CPU total)=4770.50390625MB
INFO:root:[    9] Training loss: 0.11148936, Validation loss: 0.16036895, Gradient norm: 2.03239458
INFO:root:At the start of the epoch: mem (CPU python)=5062.5234375MB; mem (CPU total)=4846.67578125MB
INFO:root:[   10] Training loss: 0.10782798, Validation loss: 0.16603117, Gradient norm: 1.67640010
INFO:root:At the start of the epoch: mem (CPU python)=5138.73046875MB; mem (CPU total)=4922.98046875MB
INFO:root:[   11] Training loss: 0.10182786, Validation loss: 0.15384702, Gradient norm: 1.58737985
INFO:root:At the start of the epoch: mem (CPU python)=5214.9609375MB; mem (CPU total)=4999.3515625MB
INFO:root:[   12] Training loss: 0.09919952, Validation loss: 0.15344817, Gradient norm: 1.61861994
INFO:root:At the start of the epoch: mem (CPU python)=5291.1875MB; mem (CPU total)=5076.6171875MB
INFO:root:[   13] Training loss: 0.10228453, Validation loss: 0.15291982, Gradient norm: 1.86303308
INFO:root:At the start of the epoch: mem (CPU python)=5367.40625MB; mem (CPU total)=5152.921875MB
INFO:root:[   14] Training loss: 0.09443023, Validation loss: 0.15721723, Gradient norm: 1.28843553
INFO:root:At the start of the epoch: mem (CPU python)=5443.625MB; mem (CPU total)=5229.37890625MB
INFO:root:[   15] Training loss: 0.09534655, Validation loss: 0.14209724, Gradient norm: 1.84218814
INFO:root:At the start of the epoch: mem (CPU python)=5519.84375MB; mem (CPU total)=5305.0234375MB
INFO:root:[   16] Training loss: 0.09400419, Validation loss: 0.16836547, Gradient norm: 1.65821844
INFO:root:At the start of the epoch: mem (CPU python)=5596.0390625MB; mem (CPU total)=5381.4453125MB
INFO:root:[   17] Training loss: 0.08997770, Validation loss: 0.15336349, Gradient norm: 1.64773542
INFO:root:At the start of the epoch: mem (CPU python)=5672.234375MB; mem (CPU total)=5457.77734375MB
INFO:root:[   18] Training loss: 0.08527281, Validation loss: 0.15133130, Gradient norm: 1.17928026
INFO:root:At the start of the epoch: mem (CPU python)=5748.44140625MB; mem (CPU total)=5533.89453125MB
INFO:root:[   19] Training loss: 0.08682891, Validation loss: 0.15832148, Gradient norm: 1.39523069
INFO:root:At the start of the epoch: mem (CPU python)=5824.64453125MB; mem (CPU total)=5610.19140625MB
INFO:root:[   20] Training loss: 0.08453708, Validation loss: 0.18222120, Gradient norm: 1.34475884
INFO:root:At the start of the epoch: mem (CPU python)=5900.83984375MB; mem (CPU total)=5685.9140625MB
INFO:root:[   21] Training loss: 0.08315483, Validation loss: 0.15762362, Gradient norm: 1.64066181
INFO:root:At the start of the epoch: mem (CPU python)=5977.0546875MB; mem (CPU total)=5762.1640625MB
INFO:root:[   22] Training loss: 0.08693805, Validation loss: 0.18987824, Gradient norm: 2.07086551
INFO:root:At the start of the epoch: mem (CPU python)=6053.25MB; mem (CPU total)=5838.515625MB
INFO:root:[   23] Training loss: 0.08722252, Validation loss: 0.17606713, Gradient norm: 2.25025390
INFO:root:At the start of the epoch: mem (CPU python)=6129.45703125MB; mem (CPU total)=5914.62890625MB
INFO:root:[   24] Training loss: 0.08199187, Validation loss: 0.18591481, Gradient norm: 1.60426375
INFO:root:At the start of the epoch: mem (CPU python)=6205.65234375MB; mem (CPU total)=5990.87109375MB
INFO:root:[   25] Training loss: 0.07580457, Validation loss: 0.16560386, Gradient norm: 1.23288498
INFO:root:At the start of the epoch: mem (CPU python)=6281.85546875MB; mem (CPU total)=6066.8359375MB
INFO:root:[   26] Training loss: 0.07482369, Validation loss: 0.19088168, Gradient norm: 1.32637842
INFO:root:At the start of the epoch: mem (CPU python)=6358.0625MB; mem (CPU total)=6143.8203125MB
INFO:root:[   27] Training loss: 0.08031269, Validation loss: 0.17090948, Gradient norm: 2.32804968
INFO:root:At the start of the epoch: mem (CPU python)=6434.25MB; mem (CPU total)=6220.48046875MB
INFO:root:[   28] Training loss: 0.07699119, Validation loss: 0.20141457, Gradient norm: 1.54096482
INFO:root:At the start of the epoch: mem (CPU python)=6510.45703125MB; mem (CPU total)=6296.44140625MB
INFO:root:[   29] Training loss: 0.07619569, Validation loss: 0.16177362, Gradient norm: 1.74158389
INFO:root:At the start of the epoch: mem (CPU python)=6586.6640625MB; mem (CPU total)=6373.1328125MB
INFO:root:[   30] Training loss: 0.07634897, Validation loss: 0.19209079, Gradient norm: 1.37726361
INFO:root:At the start of the epoch: mem (CPU python)=6662.85546875MB; mem (CPU total)=6449.171875MB
INFO:root:[   31] Training loss: 0.07388001, Validation loss: 0.19323078, Gradient norm: 1.35889188
INFO:root:At the start of the epoch: mem (CPU python)=6739.05078125MB; mem (CPU total)=6525.0MB
INFO:root:[   32] Training loss: 0.07446128, Validation loss: 0.19121239, Gradient norm: 1.23669860
INFO:root:At the start of the epoch: mem (CPU python)=6815.25390625MB; mem (CPU total)=6601.72265625MB
INFO:root:[   33] Training loss: 0.07188295, Validation loss: 0.18013759, Gradient norm: 1.45907537
INFO:root:At the start of the epoch: mem (CPU python)=6891.44921875MB; mem (CPU total)=6677.96484375MB
INFO:root:[   34] Training loss: 0.07395700, Validation loss: 0.17111745, Gradient norm: 1.62405304
INFO:root:At the start of the epoch: mem (CPU python)=6967.63671875MB; mem (CPU total)=6754.3203125MB
