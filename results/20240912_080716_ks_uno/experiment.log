INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=576.2578125MB; mem (CPU total)=1103.2578125MB
INFO:root:############### Starting experiment with config file ks/uno1.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12454.83203125MB; mem (CPU total)=1115.21484375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.83203125MB; mem (CPU total)=1115.21484375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 23068672
INFO:root:After setting up the model: mem (CPU python)=12454.83203125MB; mem (CPU total)=2476.96484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=2485.15234375MB
INFO:root:[    1] Training loss: 1.00800716, Validation loss: 0.99385617, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4199.078125MB
INFO:root:[    2] Training loss: 0.98612564, Validation loss: 0.98219477, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4237.8515625MB
INFO:root:[    3] Training loss: 0.98002664, Validation loss: 0.97837602, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4276.3984375MB
INFO:root:[    4] Training loss: 0.97670963, Validation loss: 0.97562470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4314.08984375MB
INFO:root:[    5] Training loss: 0.97386104, Validation loss: 0.97253838, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4352.4140625MB
INFO:root:[    6] Training loss: 0.97195098, Validation loss: 0.97179366, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4390.41015625MB
INFO:root:[    7] Training loss: 0.97072780, Validation loss: 0.96991033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4428.34765625MB
INFO:root:[    8] Training loss: 0.96955602, Validation loss: 0.96853435, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4466.8515625MB
INFO:root:[    9] Training loss: 0.96863158, Validation loss: 0.96781110, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4505.3046875MB
INFO:root:[   10] Training loss: 0.96774576, Validation loss: 0.96677817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4542.91796875MB
INFO:root:[   11] Training loss: 0.96713422, Validation loss: 0.96631592, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4582.1171875MB
INFO:root:[   12] Training loss: 0.96620754, Validation loss: 0.96568191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4619.34375MB
INFO:root:[   13] Training loss: 0.96598577, Validation loss: 0.96941624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4657.6484375MB
INFO:root:[   14] Training loss: 0.96525303, Validation loss: 0.96445545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4696.7890625MB
INFO:root:[   15] Training loss: 0.96455849, Validation loss: 0.96601694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4735.15625MB
INFO:root:[   16] Training loss: 0.96357774, Validation loss: 0.96332440, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4773.38671875MB
INFO:root:[   17] Training loss: 0.96362836, Validation loss: 0.96276793, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4812.3359375MB
INFO:root:[   18] Training loss: 0.96332225, Validation loss: 0.96210299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4850.4765625MB
INFO:root:[   19] Training loss: 0.96351649, Validation loss: 0.96215986, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4889.0625MB
INFO:root:[   20] Training loss: 0.96276259, Validation loss: 0.96376563, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4927.30078125MB
INFO:root:[   21] Training loss: 0.96256840, Validation loss: 0.96263244, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=4965.3203125MB
INFO:root:[   22] Training loss: 0.96254788, Validation loss: 0.96496630, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5003.59765625MB
INFO:root:[   23] Training loss: 0.96230176, Validation loss: 0.96311961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5041.8046875MB
INFO:root:[   24] Training loss: 0.96212349, Validation loss: 0.96141768, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5079.95703125MB
INFO:root:[   25] Training loss: 0.96226451, Validation loss: 0.96234897, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5118.44921875MB
INFO:root:[   26] Training loss: 0.96134442, Validation loss: 0.95961153, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5156.26171875MB
INFO:root:[   27] Training loss: 0.96133509, Validation loss: 0.95975827, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5194.8984375MB
INFO:root:[   28] Training loss: 0.96079620, Validation loss: 0.95952420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5233.12890625MB
INFO:root:[   29] Training loss: 0.96181837, Validation loss: 0.96017219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5271.015625MB
INFO:root:[   30] Training loss: 0.96053496, Validation loss: 0.95979690, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5309.15234375MB
INFO:root:[   31] Training loss: 0.96148257, Validation loss: 0.96044286, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5347.0390625MB
INFO:root:[   32] Training loss: 0.96088082, Validation loss: 0.96405565, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5385.1796875MB
INFO:root:[   33] Training loss: 0.96092070, Validation loss: 0.95979978, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5423.28125MB
INFO:root:[   34] Training loss: 0.96001089, Validation loss: 0.96109295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5461.66796875MB
INFO:root:[   35] Training loss: 0.95911676, Validation loss: 0.95769097, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5500.3125MB
INFO:root:[   36] Training loss: 0.95970131, Validation loss: 0.95986340, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5539.421875MB
INFO:root:[   37] Training loss: 0.95902969, Validation loss: 0.95919007, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5577.78125MB
INFO:root:[   38] Training loss: 0.95992681, Validation loss: 0.95872381, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5615.6796875MB
INFO:root:[   39] Training loss: 0.95963162, Validation loss: 0.96082420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5653.81640625MB
INFO:root:[   40] Training loss: 0.95882517, Validation loss: 0.96078807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5691.95703125MB
INFO:root:[   41] Training loss: 0.95863045, Validation loss: 0.95869658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5730.37890625MB
INFO:root:[   42] Training loss: 0.95858278, Validation loss: 0.95753857, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5768.58203125MB
INFO:root:[   43] Training loss: 0.95851216, Validation loss: 0.95694749, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5807.0859375MB
INFO:root:[   44] Training loss: 0.95799840, Validation loss: 0.96112448, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5845.2421875MB
INFO:root:[   45] Training loss: 0.95751815, Validation loss: 0.95747785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5883.60546875MB
INFO:root:[   46] Training loss: 0.95764846, Validation loss: 0.95653283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5921.625MB
INFO:root:[   47] Training loss: 0.95729969, Validation loss: 0.95508777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5960.36328125MB
INFO:root:[   48] Training loss: 0.95640785, Validation loss: 0.95612161, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=5998.109375MB
INFO:root:[   49] Training loss: 0.95558865, Validation loss: 0.95635227, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6036.328125MB
INFO:root:[   50] Training loss: 0.95647006, Validation loss: 0.95759592, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6074.52734375MB
INFO:root:[   51] Training loss: 0.95641856, Validation loss: 0.95644708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6112.71484375MB
INFO:root:[   52] Training loss: 0.95625924, Validation loss: 0.95632917, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6150.6328125MB
INFO:root:[   53] Training loss: 0.95482169, Validation loss: 0.95553828, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6188.71484375MB
INFO:root:[   54] Training loss: 0.95486990, Validation loss: 0.95660057, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6226.8984375MB
INFO:root:[   55] Training loss: 0.95534217, Validation loss: 0.95616042, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6265.0390625MB
INFO:root:[   56] Training loss: 0.95465804, Validation loss: 0.95358473, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6302.90234375MB
INFO:root:[   57] Training loss: 0.95489922, Validation loss: 0.95402818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6341.31640625MB
INFO:root:[   58] Training loss: 0.95462121, Validation loss: 0.95341817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6380.0234375MB
INFO:root:[   59] Training loss: 0.95364412, Validation loss: 0.95228034, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6418.39453125MB
INFO:root:[   60] Training loss: 0.95378974, Validation loss: 0.95399936, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6456.30078125MB
INFO:root:[   61] Training loss: 0.95413186, Validation loss: 0.95438809, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6494.671875MB
INFO:root:[   62] Training loss: 0.95330757, Validation loss: 0.95485498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6532.70703125MB
INFO:root:[   63] Training loss: 0.95260579, Validation loss: 0.95198092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6570.94921875MB
INFO:root:[   64] Training loss: 0.95330589, Validation loss: 0.95236368, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6609.3828125MB
INFO:root:[   65] Training loss: 0.95272182, Validation loss: 0.95559698, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6647.375MB
INFO:root:[   66] Training loss: 0.95232899, Validation loss: 0.95170541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6685.51953125MB
INFO:root:[   67] Training loss: 0.95236851, Validation loss: 0.95285300, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6723.54296875MB
INFO:root:[   68] Training loss: 0.95214358, Validation loss: 0.95081836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6761.6796875MB
INFO:root:[   69] Training loss: 0.95112407, Validation loss: 0.95154495, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6799.546875MB
INFO:root:[   70] Training loss: 0.95151510, Validation loss: 0.95112841, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6837.9765625MB
INFO:root:[   71] Training loss: 0.95165191, Validation loss: 0.95505212, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6876.03515625MB
INFO:root:[   72] Training loss: 0.95077784, Validation loss: 0.95393918, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6914.33203125MB
INFO:root:[   73] Training loss: 0.95047352, Validation loss: 0.94957430, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6952.76953125MB
INFO:root:[   74] Training loss: 0.95033140, Validation loss: 0.95159164, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=6991.38671875MB
INFO:root:[   75] Training loss: 0.95002732, Validation loss: 0.95073658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7029.2421875MB
INFO:root:[   76] Training loss: 0.95058089, Validation loss: 0.94907502, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7067.78125MB
INFO:root:[   77] Training loss: 0.94995654, Validation loss: 0.95113064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7106.203125MB
INFO:root:[   78] Training loss: 0.94927223, Validation loss: 0.95050470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7144.2578125MB
INFO:root:[   79] Training loss: 0.94958014, Validation loss: 0.95147219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7182.32421875MB
INFO:root:[   80] Training loss: 0.94980639, Validation loss: 0.94975015, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7220.66796875MB
INFO:root:[   81] Training loss: 0.94958101, Validation loss: 0.94868151, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7258.53125MB
INFO:root:[   82] Training loss: 0.94934637, Validation loss: 0.94998105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7296.9921875MB
INFO:root:[   83] Training loss: 0.94788273, Validation loss: 0.94698834, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7335.44921875MB
INFO:root:[   84] Training loss: 0.94923083, Validation loss: 0.94774737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7373.8125MB
INFO:root:[   85] Training loss: 0.94782194, Validation loss: 0.94876097, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7412.05078125MB
INFO:root:[   86] Training loss: 0.94856957, Validation loss: 0.95003342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7450.12109375MB
INFO:root:[   87] Training loss: 0.94806605, Validation loss: 0.95097442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7487.78515625MB
INFO:root:[   88] Training loss: 0.94783254, Validation loss: 0.95000536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7526.17578125MB
INFO:root:[   89] Training loss: 0.94735934, Validation loss: 0.95056651, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7564.40625MB
INFO:root:[   90] Training loss: 0.94753904, Validation loss: 0.94841468, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7602.4453125MB
INFO:root:[   91] Training loss: 0.94698880, Validation loss: 0.94625814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7641.8671875MB
INFO:root:[   92] Training loss: 0.94833313, Validation loss: 0.94894364, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7680.26171875MB
INFO:root:[   93] Training loss: 0.94720355, Validation loss: 0.94790050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7718.1015625MB
INFO:root:[   94] Training loss: 0.94827565, Validation loss: 0.94713971, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7756.4765625MB
INFO:root:[   95] Training loss: 0.94707208, Validation loss: 0.94602970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7794.9140625MB
INFO:root:[   96] Training loss: 0.94696141, Validation loss: 0.95016419, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7833.31640625MB
INFO:root:[   97] Training loss: 0.94635347, Validation loss: 0.94674308, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7871.4765625MB
INFO:root:[   98] Training loss: 0.94694176, Validation loss: 0.94868247, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7909.41796875MB
INFO:root:[   99] Training loss: 0.94638268, Validation loss: 0.94825421, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7947.8203125MB
INFO:root:[  100] Training loss: 0.94655866, Validation loss: 0.94966665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=7986.2265625MB
INFO:root:[  101] Training loss: 0.94751808, Validation loss: 0.94710155, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8024.37109375MB
INFO:root:[  102] Training loss: 0.94680872, Validation loss: 0.94868863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8062.52734375MB
INFO:root:[  103] Training loss: 0.94691817, Validation loss: 0.94762564, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8100.125MB
INFO:root:[  104] Training loss: 0.94711642, Validation loss: 0.94813611, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8138.265625MB
INFO:root:EP 104: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12454.83203125MB; mem (CPU total)=8176.66015625MB
INFO:root:Training the model took 3956.429s.
INFO:root:Emptying the cuda cache took 0.009s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 1.06422
INFO:root:EnergyScoreTrain: 0.73948
INFO:root:CRPSTrain: 0.56932
INFO:root:Gaussian NLLTrain: 31.32587
INFO:root:CoverageTrain: 0.41431
INFO:root:IntervalWidthTrain: 1.34185
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 1.06662
INFO:root:EnergyScoreValidation: 0.74501
INFO:root:CRPSValidation: 0.57467
INFO:root:Gaussian NLLValidation: 45.69782
INFO:root:CoverageValidation: 0.40318
INFO:root:IntervalWidthValidation: 1.29771
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 1.06546
INFO:root:EnergyScoreTest: 0.72545
INFO:root:CRPSTest: 0.55494
INFO:root:Gaussian NLLTest: 20.10922
INFO:root:CoverageTest: 0.43622
INFO:root:IntervalWidthTest: 1.43677
INFO:root:After validation: mem (CPU python)=12454.83203125MB; mem (CPU total)=8463.2578125MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.005, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.83203125MB; mem (CPU total)=8462.7109375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 180355072
INFO:root:After setting up the model: mem (CPU python)=12454.83203125MB; mem (CPU total)=8466.3359375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8466.33203125MB
INFO:root:[    1] Training loss: 1.00805601, Validation loss: 0.99333604, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8503.39453125MB
INFO:root:[    2] Training loss: 0.98713301, Validation loss: 0.98275914, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8540.84765625MB
INFO:root:[    3] Training loss: 0.98100195, Validation loss: 0.97783516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8579.8046875MB
INFO:root:[    4] Training loss: 0.97710547, Validation loss: 0.97520064, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8617.3828125MB
INFO:root:[    5] Training loss: 0.97443807, Validation loss: 0.97256533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=8654.88671875MB
INFO:root:[    6] Training loss: 0.97286758, Validation loss: 0.97154936, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11144.9921875MB
INFO:root:[    7] Training loss: 0.97177985, Validation loss: 0.97087153, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11205.0859375MB
INFO:root:[    8] Training loss: 0.97060010, Validation loss: 0.96956832, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11246.58984375MB
INFO:root:[    9] Training loss: 0.96961195, Validation loss: 0.96791801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11286.875MB
INFO:root:[   10] Training loss: 0.96894014, Validation loss: 0.96777580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11327.74609375MB
INFO:root:[   11] Training loss: 0.96806462, Validation loss: 0.96674082, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11368.15625MB
INFO:root:[   12] Training loss: 0.96716065, Validation loss: 0.96546621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11408.25MB
INFO:root:[   13] Training loss: 0.96682401, Validation loss: 0.96481226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11446.7890625MB
INFO:root:[   14] Training loss: 0.96591855, Validation loss: 0.96476251, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11485.46875MB
INFO:root:[   15] Training loss: 0.96545402, Validation loss: 0.96537872, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11525.3515625MB
INFO:root:[   16] Training loss: 0.96494331, Validation loss: 0.96539829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11567.4453125MB
INFO:root:[   17] Training loss: 0.96461081, Validation loss: 0.96252913, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11607.3828125MB
INFO:root:[   18] Training loss: 0.96416462, Validation loss: 0.96246986, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11648.390625MB
INFO:root:[   19] Training loss: 0.96366414, Validation loss: 0.96130482, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11688.90625MB
INFO:root:[   20] Training loss: 0.96345112, Validation loss: 0.96250232, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11729.7421875MB
INFO:root:[   21] Training loss: 0.96325098, Validation loss: 0.96183630, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11769.625MB
INFO:root:[   22] Training loss: 0.96287456, Validation loss: 0.96271546, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11810.73828125MB
INFO:root:[   23] Training loss: 0.96245509, Validation loss: 0.96179493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11851.58984375MB
INFO:root:[   24] Training loss: 0.96260088, Validation loss: 0.96158068, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11892.11328125MB
INFO:root:[   25] Training loss: 0.96248334, Validation loss: 0.95982195, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11935.00390625MB
INFO:root:[   26] Training loss: 0.96191895, Validation loss: 0.95892718, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11974.92578125MB
INFO:root:[   27] Training loss: 0.96173187, Validation loss: 0.96074176, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=12017.90625MB
INFO:root:[   28] Training loss: 0.96129619, Validation loss: 0.96015665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=12057.69921875MB
INFO:root:[   29] Training loss: 0.96078106, Validation loss: 0.95980873, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=12098.2421875MB
INFO:root:[   30] Training loss: 0.96062697, Validation loss: 0.95903667, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=12162.65234375MB
INFO:root:[   31] Training loss: 0.96053205, Validation loss: 0.95888411, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=12201.78125MB
INFO:root:[   32] Training loss: 0.96072225, Validation loss: 0.95848229, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=9686.4140625MB
INFO:root:[   33] Training loss: 0.96009841, Validation loss: 0.95958258, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=9725.1640625MB
INFO:root:[   34] Training loss: 0.95998489, Validation loss: 0.95746805, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=9763.05859375MB
INFO:root:[   35] Training loss: 0.95924249, Validation loss: 0.95802250, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=9801.37109375MB
INFO:root:[   36] Training loss: 0.95884209, Validation loss: 0.95702693, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=9839.59375MB
INFO:root:[   37] Training loss: 0.95857797, Validation loss: 0.95672433, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=9877.8046875MB
INFO:root:[   38] Training loss: 0.95849841, Validation loss: 0.95704398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=9916.1953125MB
INFO:root:[   39] Training loss: 0.95847278, Validation loss: 0.95710037, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=9954.3359375MB
INFO:root:[   40] Training loss: 0.95821310, Validation loss: 0.95730782, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=9992.234375MB
INFO:root:[   41] Training loss: 0.95777626, Validation loss: 0.95611183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10030.359375MB
INFO:root:[   42] Training loss: 0.95731397, Validation loss: 0.95643531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10068.7421875MB
INFO:root:[   43] Training loss: 0.95669737, Validation loss: 0.95471272, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10106.4765625MB
INFO:root:[   44] Training loss: 0.95640976, Validation loss: 0.95431961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10144.9453125MB
INFO:root:[   45] Training loss: 0.95571676, Validation loss: 0.95541715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10182.80859375MB
INFO:root:[   46] Training loss: 0.95491275, Validation loss: 0.95229721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10220.04296875MB
INFO:root:[   47] Training loss: 0.95436137, Validation loss: 0.95304555, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10258.1875MB
INFO:root:[   48] Training loss: 0.95393104, Validation loss: 0.95244373, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10296.57421875MB
INFO:root:[   49] Training loss: 0.95365571, Validation loss: 0.95188635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10334.66796875MB
INFO:root:[   50] Training loss: 0.95357599, Validation loss: 0.95281621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10373.05859375MB
INFO:root:[   51] Training loss: 0.95287174, Validation loss: 0.94961993, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10411.265625MB
INFO:root:[   52] Training loss: 0.95304647, Validation loss: 0.95096181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10449.65625MB
INFO:root:[   53] Training loss: 0.95264879, Validation loss: 0.95051836, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10488.12109375MB
INFO:root:[   54] Training loss: 0.95224129, Validation loss: 0.95019378, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10525.7734375MB
INFO:root:[   55] Training loss: 0.95262485, Validation loss: 0.95041898, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10564.5546875MB
INFO:root:[   56] Training loss: 0.95212788, Validation loss: 0.95108611, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10602.93359375MB
INFO:root:[   57] Training loss: 0.95166248, Validation loss: 0.95011929, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10641.3359375MB
INFO:root:[   58] Training loss: 0.95163135, Validation loss: 0.95074428, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10678.98046875MB
INFO:root:[   59] Training loss: 0.95160708, Validation loss: 0.94980130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10717.3671875MB
INFO:root:[   60] Training loss: 0.95120880, Validation loss: 0.95203116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10755.265625MB
INFO:root:[   61] Training loss: 0.95106903, Validation loss: 0.95107887, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10793.6953125MB
INFO:root:[   62] Training loss: 0.95096040, Validation loss: 0.94907152, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10831.609375MB
INFO:root:[   63] Training loss: 0.95032328, Validation loss: 0.94888333, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10869.7421875MB
INFO:root:[   64] Training loss: 0.95045568, Validation loss: 0.94819736, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10908.33984375MB
INFO:root:[   65] Training loss: 0.95049007, Validation loss: 0.94867065, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10946.59375MB
INFO:root:[   66] Training loss: 0.95028510, Validation loss: 0.94895672, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=10984.73828125MB
INFO:root:[   67] Training loss: 0.94988809, Validation loss: 0.94832526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11022.8828125MB
INFO:root:[   68] Training loss: 0.94959220, Validation loss: 0.94742237, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11061.26171875MB
INFO:root:[   69] Training loss: 0.94931556, Validation loss: 0.94653179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11098.68359375MB
INFO:root:[   70] Training loss: 0.94886549, Validation loss: 0.94864958, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11512.96875MB
INFO:root:[   71] Training loss: 0.94886552, Validation loss: 0.94718802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11174.640625MB
INFO:root:[   72] Training loss: 0.94849967, Validation loss: 0.94542154, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11212.80078125MB
INFO:root:[   73] Training loss: 0.94795411, Validation loss: 0.94676359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11250.96875MB
INFO:root:[   74] Training loss: 0.94812235, Validation loss: 0.94770987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11289.3515625MB
INFO:root:[   75] Training loss: 0.94778501, Validation loss: 0.94721458, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11327.49609375MB
INFO:root:[   76] Training loss: 0.94779460, Validation loss: 0.94587449, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11517.03515625MB
INFO:root:[   77] Training loss: 0.94739565, Validation loss: 0.94530878, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=14131.1796875MB
INFO:root:[   78] Training loss: 0.94741792, Validation loss: 0.94509330, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11443.8828125MB
INFO:root:[   79] Training loss: 0.94709601, Validation loss: 0.94596036, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11548.8828125MB
INFO:root:[   80] Training loss: 0.94701122, Validation loss: 0.94481451, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=14302.26953125MB
INFO:root:[   81] Training loss: 0.94676205, Validation loss: 0.94529754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11557.23046875MB
INFO:root:[   82] Training loss: 0.94667569, Validation loss: 0.94613425, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=14377.89453125MB
INFO:root:[   83] Training loss: 0.94646420, Validation loss: 0.94464058, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11633.5MB
INFO:root:[   84] Training loss: 0.94647046, Validation loss: 0.94472052, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11671.83203125MB
INFO:root:[   85] Training loss: 0.94617091, Validation loss: 0.94381335, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11709.9765625MB
INFO:root:[   86] Training loss: 0.94598059, Validation loss: 0.94481109, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=14531.34765625MB
INFO:root:[   87] Training loss: 0.94579457, Validation loss: 0.94423508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11785.87890625MB
INFO:root:[   88] Training loss: 0.94575085, Validation loss: 0.94432359, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11824.00390625MB
INFO:root:[   89] Training loss: 0.94573872, Validation loss: 0.94388583, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11861.57421875MB
INFO:root:[   90] Training loss: 0.94557150, Validation loss: 0.94382745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11899.45703125MB
INFO:root:[   91] Training loss: 0.94530051, Validation loss: 0.94435740, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11938.21484375MB
INFO:root:[   92] Training loss: 0.94525246, Validation loss: 0.94368658, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=11976.49609375MB
INFO:root:[   93] Training loss: 0.94530568, Validation loss: 0.94321769, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=14797.12890625MB
INFO:root:[   94] Training loss: 0.94493997, Validation loss: 0.94304404, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=12053.58203125MB
INFO:root:[   95] Training loss: 0.94510335, Validation loss: 0.94240917, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=12091.4296875MB
INFO:root:[   96] Training loss: 0.94496141, Validation loss: 0.94308338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=12129.55859375MB
INFO:root:[   97] Training loss: 0.94470598, Validation loss: 0.94261981, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12454.83203125MB; mem (CPU total)=12167.67578125MB
INFO:root:[   98] Training loss: 0.94438175, Validation loss: 0.94397568, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12479.33984375MB; mem (CPU total)=14286.05078125MB
INFO:root:[   99] Training loss: 0.94450482, Validation loss: 0.94258652, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12517.43359375MB; mem (CPU total)=15024.40234375MB
INFO:root:[  100] Training loss: 0.94442930, Validation loss: 0.94235526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12555.53515625MB; mem (CPU total)=12282.359375MB
INFO:root:[  101] Training loss: 0.94429973, Validation loss: 0.94251130, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12593.625MB; mem (CPU total)=12320.16796875MB
INFO:root:[  102] Training loss: 0.94417986, Validation loss: 0.94200543, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12631.72265625MB; mem (CPU total)=12358.78515625MB
INFO:root:[  103] Training loss: 0.94400957, Validation loss: 0.94253972, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12669.8203125MB; mem (CPU total)=12396.8671875MB
INFO:root:[  104] Training loss: 0.94400058, Validation loss: 0.94325749, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12707.91796875MB; mem (CPU total)=12434.80859375MB
INFO:root:[  105] Training loss: 0.94390913, Validation loss: 0.94137252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12746.01171875MB; mem (CPU total)=15257.9140625MB
INFO:root:[  106] Training loss: 0.94380929, Validation loss: 0.94341320, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12784.10546875MB; mem (CPU total)=12511.63671875MB
INFO:root:[  107] Training loss: 0.94374470, Validation loss: 0.94234132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12822.203125MB; mem (CPU total)=12549.50390625MB
INFO:root:[  108] Training loss: 0.94362343, Validation loss: 0.94297533, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12860.296875MB; mem (CPU total)=12733.79296875MB
INFO:root:[  109] Training loss: 0.94339405, Validation loss: 0.94303588, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12898.390625MB; mem (CPU total)=14708.5625MB
INFO:root:[  110] Training loss: 0.94324518, Validation loss: 0.94178219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12936.48828125MB; mem (CPU total)=15447.80078125MB
INFO:root:[  111] Training loss: 0.94312083, Validation loss: 0.94164522, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=12974.5859375MB; mem (CPU total)=12702.66796875MB
INFO:root:[  112] Training loss: 0.94315075, Validation loss: 0.94091538, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13012.6796875MB; mem (CPU total)=14659.38671875MB
INFO:root:[  113] Training loss: 0.94298706, Validation loss: 0.94156287, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13050.77734375MB; mem (CPU total)=15562.63671875MB
INFO:root:[  114] Training loss: 0.94298478, Validation loss: 0.94129839, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13088.87109375MB; mem (CPU total)=14782.19921875MB
INFO:root:[  115] Training loss: 0.94292088, Validation loss: 0.94137503, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13126.96484375MB; mem (CPU total)=15638.37890625MB
INFO:root:[  116] Training loss: 0.94288064, Validation loss: 0.94217325, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13165.05859375MB; mem (CPU total)=12893.3828125MB
INFO:root:[  117] Training loss: 0.94280958, Validation loss: 0.94220677, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13203.15625MB; mem (CPU total)=12931.421875MB
INFO:root:[  118] Training loss: 0.94278338, Validation loss: 0.94171756, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13241.25390625MB; mem (CPU total)=12969.8203125MB
INFO:root:[  119] Training loss: 0.94259649, Validation loss: 0.94220521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13279.34765625MB; mem (CPU total)=13007.96875MB
INFO:root:[  120] Training loss: 0.94236288, Validation loss: 0.94167998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13317.44921875MB; mem (CPU total)=13046.12890625MB
INFO:root:[  121] Training loss: 0.94213879, Validation loss: 0.94110633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13355.5390625MB; mem (CPU total)=13084.2890625MB
INFO:root:EP 121: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=13393.6171875MB; mem (CPU total)=13122.16796875MB
INFO:root:Training the model took 4962.133s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.95209
INFO:root:EnergyScoreTrain: 0.8096
INFO:root:CRPSTrain: 0.67192
INFO:root:Gaussian NLLTrain: 51983.21209
INFO:root:CoverageTrain: 0.15783
INFO:root:IntervalWidthTrain: 0.35175
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.95709
INFO:root:EnergyScoreValidation: 0.81212
INFO:root:CRPSValidation: 0.67431
INFO:root:Gaussian NLLValidation: 28605.42284
INFO:root:CoverageValidation: 0.15793
INFO:root:IntervalWidthValidation: 0.35591
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.95559
INFO:root:EnergyScoreTest: 0.80615
INFO:root:CRPSTest: 0.67028
INFO:root:Gaussian NLLTest: 34344.40333
INFO:root:CoverageTest: 0.16442
INFO:root:IntervalWidthTest: 0.37211
INFO:root:After validation: mem (CPU python)=13467.265625MB; mem (CPU total)=15933.15625MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=13467.265625MB; mem (CPU total)=15933.14453125MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=13467.8671875MB; mem (CPU total)=15933.6484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=13467.90625MB; mem (CPU total)=15934.703125MB
INFO:root:[    1] Training loss: 1.00829532, Validation loss: 0.99309290, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13505.82421875MB; mem (CPU total)=15974.5625MB
INFO:root:[    2] Training loss: 0.98742769, Validation loss: 0.98210040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13543.9375MB; mem (CPU total)=16014.5MB
INFO:root:[    3] Training loss: 0.98022462, Validation loss: 0.97603584, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13582.03515625MB; mem (CPU total)=16056.671875MB
INFO:root:[    4] Training loss: 0.97653349, Validation loss: 0.97412333, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13620.13671875MB; mem (CPU total)=16097.60546875MB
INFO:root:[    5] Training loss: 0.97435388, Validation loss: 0.97195830, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13658.23046875MB; mem (CPU total)=16138.3671875MB
INFO:root:[    6] Training loss: 0.97294679, Validation loss: 0.97066633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13696.328125MB; mem (CPU total)=16179.046875MB
INFO:root:[    7] Training loss: 0.97191590, Validation loss: 0.97032021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13734.421875MB; mem (CPU total)=16220.33203125MB
INFO:root:[    8] Training loss: 0.97110208, Validation loss: 0.96882222, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13772.51953125MB; mem (CPU total)=16262.03125MB
INFO:root:[    9] Training loss: 0.97000734, Validation loss: 0.96733935, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13810.61328125MB; mem (CPU total)=16350.84765625MB
INFO:root:[   10] Training loss: 0.96928313, Validation loss: 0.96682799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13848.70703125MB; mem (CPU total)=16389.50390625MB
INFO:root:[   11] Training loss: 0.96840780, Validation loss: 0.96624213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13886.8046875MB; mem (CPU total)=16427.51171875MB
INFO:root:[   12] Training loss: 0.96762317, Validation loss: 0.96510933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13924.90234375MB; mem (CPU total)=16465.7421875MB
INFO:root:[   13] Training loss: 0.96716093, Validation loss: 0.96453919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=13962.99609375MB; mem (CPU total)=16503.45703125MB
INFO:root:[   14] Training loss: 0.96653175, Validation loss: 0.96446814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14001.09375MB; mem (CPU total)=16541.5703125MB
INFO:root:[   15] Training loss: 0.96573035, Validation loss: 0.96297824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14039.26171875MB; mem (CPU total)=16580.015625MB
INFO:root:[   16] Training loss: 0.96494028, Validation loss: 0.96296575, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14077.35546875MB; mem (CPU total)=16618.94921875MB
INFO:root:[   17] Training loss: 0.96427453, Validation loss: 0.96200087, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14115.44921875MB; mem (CPU total)=16657.15234375MB
INFO:root:[   18] Training loss: 0.96362048, Validation loss: 0.96159267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14153.546875MB; mem (CPU total)=16695.4296875MB
INFO:root:[   19] Training loss: 0.96329060, Validation loss: 0.96010399, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14191.64453125MB; mem (CPU total)=16761.578125MB
INFO:root:[   20] Training loss: 0.96273137, Validation loss: 0.96015789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14229.734375MB; mem (CPU total)=16800.01953125MB
INFO:root:[   21] Training loss: 0.96240010, Validation loss: 0.96003179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14267.8359375MB; mem (CPU total)=16838.375MB
INFO:root:[   22] Training loss: 0.96206381, Validation loss: 0.95979861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14305.9296875MB; mem (CPU total)=16876.9921875MB
INFO:root:[   23] Training loss: 0.96169211, Validation loss: 0.95934723, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14344.0234375MB; mem (CPU total)=16915.74609375MB
INFO:root:[   24] Training loss: 0.96139311, Validation loss: 0.95953912, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14382.1171875MB; mem (CPU total)=16954.12109375MB
INFO:root:[   25] Training loss: 0.96085593, Validation loss: 0.95738871, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14420.21875MB; mem (CPU total)=16991.7578125MB
INFO:root:[   26] Training loss: 0.96061574, Validation loss: 0.95682374, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14458.3125MB; mem (CPU total)=17029.48828125MB
INFO:root:[   27] Training loss: 0.96049019, Validation loss: 0.95557579, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14496.40625MB; mem (CPU total)=17068.08984375MB
INFO:root:[   28] Training loss: 0.95999026, Validation loss: 0.95773863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14534.5MB; mem (CPU total)=17106.76171875MB
INFO:root:[   29] Training loss: 0.95958233, Validation loss: 0.95607581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14572.35546875MB; mem (CPU total)=17165.7109375MB
INFO:root:[   30] Training loss: 0.95924605, Validation loss: 0.95639060, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14610.41796875MB; mem (CPU total)=17203.296875MB
INFO:root:[   31] Training loss: 0.95906515, Validation loss: 0.95621936, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14648.515625MB; mem (CPU total)=17241.15625MB
INFO:root:[   32] Training loss: 0.95849949, Validation loss: 0.95455628, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14686.61328125MB; mem (CPU total)=17279.59375MB
INFO:root:[   33] Training loss: 0.95801931, Validation loss: 0.95574326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14724.703125MB; mem (CPU total)=17317.71875MB
INFO:root:[   34] Training loss: 0.95762050, Validation loss: 0.95596776, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14762.796875MB; mem (CPU total)=17355.73828125MB
INFO:root:[   35] Training loss: 0.95701850, Validation loss: 0.95299618, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14800.8984375MB; mem (CPU total)=17395.046875MB
INFO:root:[   36] Training loss: 0.95665707, Validation loss: 0.95434814, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14838.9921875MB; mem (CPU total)=17432.703125MB
INFO:root:[   37] Training loss: 0.95614853, Validation loss: 0.95367311, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14877.0859375MB; mem (CPU total)=17470.48046875MB
INFO:root:[   38] Training loss: 0.95589162, Validation loss: 0.95287362, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14915.18359375MB; mem (CPU total)=17508.828125MB
INFO:root:[   39] Training loss: 0.95579106, Validation loss: 0.95599121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14953.27734375MB; mem (CPU total)=17547.140625MB
INFO:root:[   40] Training loss: 0.95544239, Validation loss: 0.95240609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=14991.375MB; mem (CPU total)=17606.46484375MB
INFO:root:[   41] Training loss: 0.95517218, Validation loss: 0.95269675, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15029.46484375MB; mem (CPU total)=17645.21875MB
INFO:root:[   42] Training loss: 0.95495033, Validation loss: 0.95252752, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15067.5625MB; mem (CPU total)=17682.93359375MB
INFO:root:[   43] Training loss: 0.95442293, Validation loss: 0.95090595, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15105.66015625MB; mem (CPU total)=17721.5078125MB
INFO:root:[   44] Training loss: 0.95425694, Validation loss: 0.95074868, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15143.75390625MB; mem (CPU total)=17759.65234375MB
INFO:root:[   45] Training loss: 0.95411597, Validation loss: 0.95053882, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15181.8515625MB; mem (CPU total)=17797.61328125MB
INFO:root:[   46] Training loss: 0.95391599, Validation loss: 0.95099642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15219.9453125MB; mem (CPU total)=17836.375MB
INFO:root:[   47] Training loss: 0.95355164, Validation loss: 0.95082535, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15258.0390625MB; mem (CPU total)=17874.45703125MB
INFO:root:[   48] Training loss: 0.95337290, Validation loss: 0.94970262, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15296.140625MB; mem (CPU total)=17913.140625MB
INFO:root:[   49] Training loss: 0.95330452, Validation loss: 0.94914172, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15334.234375MB; mem (CPU total)=17951.28125MB
INFO:root:[   50] Training loss: 0.95296331, Validation loss: 0.95038573, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15372.32421875MB; mem (CPU total)=17989.19140625MB
INFO:root:[   51] Training loss: 0.95276114, Validation loss: 0.95018689, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15410.421875MB; mem (CPU total)=15143.70703125MB
INFO:root:[   52] Training loss: 0.95258826, Validation loss: 0.94979921, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15448.51953125MB; mem (CPU total)=15181.8515625MB
INFO:root:[   53] Training loss: 0.95228085, Validation loss: 0.94961498, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15486.61328125MB; mem (CPU total)=15219.94140625MB
INFO:root:[   54] Training loss: 0.95227617, Validation loss: 0.95108169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15524.70703125MB; mem (CPU total)=15257.83984375MB
INFO:root:[   55] Training loss: 0.95204732, Validation loss: 0.94873632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15562.80859375MB; mem (CPU total)=15296.55859375MB
INFO:root:[   56] Training loss: 0.95183538, Validation loss: 0.94911786, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15600.8984375MB; mem (CPU total)=15801.15234375MB
INFO:root:[   57] Training loss: 0.95145949, Validation loss: 0.94882442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15638.9921875MB; mem (CPU total)=18109.78515625MB
INFO:root:[   58] Training loss: 0.95123067, Validation loss: 0.94876408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15677.08984375MB; mem (CPU total)=18151.08984375MB
INFO:root:[   59] Training loss: 0.95122897, Validation loss: 0.94800780, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15715.1875MB; mem (CPU total)=18193.03515625MB
INFO:root:[   60] Training loss: 0.95102487, Validation loss: 0.94799705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15753.28125MB; mem (CPU total)=18234.09765625MB
INFO:root:[   61] Training loss: 0.95076511, Validation loss: 0.94753240, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15791.375MB; mem (CPU total)=18273.3203125MB
INFO:root:[   62] Training loss: 0.95071386, Validation loss: 0.94705987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15829.4765625MB; mem (CPU total)=18313.83984375MB
INFO:root:[   63] Training loss: 0.95050950, Validation loss: 0.94778650, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15867.56640625MB; mem (CPU total)=18356.34375MB
INFO:root:[   64] Training loss: 0.95040493, Validation loss: 0.94668794, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15905.6640625MB; mem (CPU total)=18397.640625MB
INFO:root:[   65] Training loss: 0.95018716, Validation loss: 0.94666116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15943.76171875MB; mem (CPU total)=18438.14453125MB
INFO:root:[   66] Training loss: 0.94989719, Validation loss: 0.94597431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=15981.85546875MB; mem (CPU total)=18476.16796875MB
INFO:root:[   67] Training loss: 0.94953873, Validation loss: 0.94659338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16019.94921875MB; mem (CPU total)=18565.02734375MB
INFO:root:[   68] Training loss: 0.94949136, Validation loss: 0.94636842, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16058.04296875MB; mem (CPU total)=18603.37890625MB
INFO:root:[   69] Training loss: 0.94941311, Validation loss: 0.94599797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16096.140625MB; mem (CPU total)=18641.7265625MB
INFO:root:[   70] Training loss: 0.94904429, Validation loss: 0.94673020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16134.234375MB; mem (CPU total)=18679.625MB
INFO:root:[   71] Training loss: 0.94910485, Validation loss: 0.94548949, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16172.33203125MB; mem (CPU total)=18717.85546875MB
INFO:root:[   72] Training loss: 0.94885292, Validation loss: 0.94484181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16210.4296875MB; mem (CPU total)=18755.5703125MB
INFO:root:[   73] Training loss: 0.94865585, Validation loss: 0.94586265, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16248.51953125MB; mem (CPU total)=18792.40234375MB
INFO:root:[   74] Training loss: 0.94863360, Validation loss: 0.94596931, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16286.61328125MB; mem (CPU total)=18830.76171875MB
INFO:root:[   75] Training loss: 0.94851816, Validation loss: 0.94492001, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16324.70703125MB; mem (CPU total)=18868.6328125MB
INFO:root:[   76] Training loss: 0.94844602, Validation loss: 0.94543377, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16362.80859375MB; mem (CPU total)=18907.0MB
INFO:root:[   77] Training loss: 0.94819933, Validation loss: 0.94554686, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16400.90234375MB; mem (CPU total)=18945.61328125MB
INFO:root:[   78] Training loss: 0.94800225, Validation loss: 0.94491247, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16438.99609375MB; mem (CPU total)=19009.05078125MB
INFO:root:[   79] Training loss: 0.94788462, Validation loss: 0.94497423, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16477.09375MB; mem (CPU total)=19047.05859375MB
INFO:root:[   80] Training loss: 0.94780158, Validation loss: 0.94506531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16515.1875MB; mem (CPU total)=19085.16015625MB
INFO:root:[   81] Training loss: 0.94761510, Validation loss: 0.94480953, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16553.28515625MB; mem (CPU total)=19123.0234375MB
INFO:root:[   82] Training loss: 0.94756040, Validation loss: 0.94470313, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16591.3828125MB; mem (CPU total)=19160.84765625MB
INFO:root:[   83] Training loss: 0.94738334, Validation loss: 0.94558800, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16629.47265625MB; mem (CPU total)=19199.24609375MB
INFO:root:[   84] Training loss: 0.94732871, Validation loss: 0.94476478, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16667.5703125MB; mem (CPU total)=19237.74609375MB
INFO:root:[   85] Training loss: 0.94732873, Validation loss: 0.94438295, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16705.6640625MB; mem (CPU total)=19276.08203125MB
INFO:root:[   86] Training loss: 0.94707884, Validation loss: 0.94380283, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16743.765625MB; mem (CPU total)=19314.20703125MB
INFO:root:[   87] Training loss: 0.94677771, Validation loss: 0.94328125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16781.859375MB; mem (CPU total)=19352.76953125MB
INFO:root:[   88] Training loss: 0.94682288, Validation loss: 0.94354688, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16819.953125MB; mem (CPU total)=19413.00390625MB
INFO:root:[   89] Training loss: 0.94685433, Validation loss: 0.94362429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16858.05078125MB; mem (CPU total)=19451.11328125MB
INFO:root:[   90] Training loss: 0.94652287, Validation loss: 0.94345956, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16896.14453125MB; mem (CPU total)=19489.2109375MB
INFO:root:[   91] Training loss: 0.94649195, Validation loss: 0.94374444, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16934.23828125MB; mem (CPU total)=16668.8046875MB
INFO:root:[   92] Training loss: 0.94624018, Validation loss: 0.94327745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=16972.33203125MB; mem (CPU total)=16707.0703125MB
INFO:root:[   93] Training loss: 0.94636706, Validation loss: 0.94285484, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17010.4296875MB; mem (CPU total)=16745.109375MB
INFO:root:[   94] Training loss: 0.94625864, Validation loss: 0.94361604, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17048.5234375MB; mem (CPU total)=17061.72265625MB
INFO:root:[   95] Training loss: 0.94600289, Validation loss: 0.94248372, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17086.62109375MB; mem (CPU total)=19555.59765625MB
INFO:root:[   96] Training loss: 0.94604567, Validation loss: 0.94385375, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17124.71484375MB; mem (CPU total)=19598.203125MB
INFO:root:[   97] Training loss: 0.94574925, Validation loss: 0.94263699, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17162.80859375MB; mem (CPU total)=19639.01171875MB
INFO:root:[   98] Training loss: 0.94559458, Validation loss: 0.94202844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17200.90625MB; mem (CPU total)=19679.45703125MB
INFO:root:[   99] Training loss: 0.94548994, Validation loss: 0.94236588, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17239.00390625MB; mem (CPU total)=19721.75390625MB
INFO:root:[  100] Training loss: 0.94540391, Validation loss: 0.94242933, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17277.09765625MB; mem (CPU total)=19760.0859375MB
INFO:root:[  101] Training loss: 0.94523247, Validation loss: 0.94311646, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17315.19140625MB; mem (CPU total)=19800.1640625MB
INFO:root:[  102] Training loss: 0.94521001, Validation loss: 0.94228021, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17353.28515625MB; mem (CPU total)=19843.4140625MB
INFO:root:[  103] Training loss: 0.94505790, Validation loss: 0.94275030, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17391.3828125MB; mem (CPU total)=19883.765625MB
INFO:root:[  104] Training loss: 0.94517713, Validation loss: 0.94402095, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17429.4765625MB; mem (CPU total)=19925.10546875MB
INFO:root:[  105] Training loss: 0.94490532, Validation loss: 0.94214226, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17467.578125MB; mem (CPU total)=20014.94921875MB
INFO:root:[  106] Training loss: 0.94478367, Validation loss: 0.94331005, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17505.67578125MB; mem (CPU total)=20053.28515625MB
INFO:root:[  107] Training loss: 0.94490267, Validation loss: 0.94121739, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17543.76953125MB; mem (CPU total)=20091.64453125MB
INFO:root:[  108] Training loss: 0.94461826, Validation loss: 0.94161192, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17581.86328125MB; mem (CPU total)=20130.04296875MB
INFO:root:[  109] Training loss: 0.94444079, Validation loss: 0.94153489, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17619.95703125MB; mem (CPU total)=20168.2109375MB
INFO:root:[  110] Training loss: 0.94445664, Validation loss: 0.94144156, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17658.0546875MB; mem (CPU total)=20206.12890625MB
INFO:root:[  111] Training loss: 0.94427931, Validation loss: 0.94220782, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17696.1484375MB; mem (CPU total)=20242.22265625MB
INFO:root:[  112] Training loss: 0.94444962, Validation loss: 0.94161163, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17734.2421875MB; mem (CPU total)=20280.66015625MB
INFO:root:[  113] Training loss: 0.94433402, Validation loss: 0.94146093, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17772.33984375MB; mem (CPU total)=20318.53125MB
INFO:root:[  114] Training loss: 0.94422647, Validation loss: 0.94103038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17810.4375MB; mem (CPU total)=20357.07421875MB
INFO:root:[  115] Training loss: 0.94424790, Validation loss: 0.94138139, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17848.52734375MB; mem (CPU total)=20394.92578125MB
INFO:root:[  116] Training loss: 0.94394007, Validation loss: 0.94131063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17886.625MB; mem (CPU total)=20460.39453125MB
INFO:root:[  117] Training loss: 0.94398609, Validation loss: 0.94134882, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17924.72265625MB; mem (CPU total)=20498.55078125MB
INFO:root:[  118] Training loss: 0.94395436, Validation loss: 0.94100121, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=17962.8203125MB; mem (CPU total)=20536.4296875MB
INFO:root:[  119] Training loss: 0.94392712, Validation loss: 0.94149431, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18000.91015625MB; mem (CPU total)=20574.5625MB
INFO:root:[  120] Training loss: 0.94401076, Validation loss: 0.94094079, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18039.01171875MB; mem (CPU total)=20613.07421875MB
INFO:root:[  121] Training loss: 0.94365300, Validation loss: 0.94083536, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18077.10546875MB; mem (CPU total)=20650.37109375MB
INFO:root:[  122] Training loss: 0.94361523, Validation loss: 0.94054508, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18115.19921875MB; mem (CPU total)=20689.10546875MB
INFO:root:[  123] Training loss: 0.94364243, Validation loss: 0.94131190, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18153.29296875MB; mem (CPU total)=20727.5MB
INFO:root:[  124] Training loss: 0.94352572, Validation loss: 0.94163970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18191.390625MB; mem (CPU total)=20765.64453125MB
INFO:root:[  125] Training loss: 0.94345105, Validation loss: 0.94118069, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18229.484375MB; mem (CPU total)=20804.31640625MB
INFO:root:[  126] Training loss: 0.94346869, Validation loss: 0.94017914, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18267.578125MB; mem (CPU total)=20862.23828125MB
INFO:root:[  127] Training loss: 0.94337010, Validation loss: 0.94029946, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18305.67578125MB; mem (CPU total)=20900.828125MB
INFO:root:[  128] Training loss: 0.94340661, Validation loss: 0.94001341, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18343.7734375MB; mem (CPU total)=20938.67578125MB
INFO:root:[  129] Training loss: 0.94322185, Validation loss: 0.93983067, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18381.8671875MB; mem (CPU total)=20976.984375MB
INFO:root:[  130] Training loss: 0.94335720, Validation loss: 0.94020220, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18419.9609375MB; mem (CPU total)=21015.19140625MB
INFO:root:[  131] Training loss: 0.94333104, Validation loss: 0.94022072, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18458.05859375MB; mem (CPU total)=21053.265625MB
INFO:root:[  132] Training loss: 0.94306722, Validation loss: 0.93997635, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18496.15234375MB; mem (CPU total)=21091.10546875MB
INFO:root:[  133] Training loss: 0.94291451, Validation loss: 0.94079830, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18534.25MB; mem (CPU total)=21129.12109375MB
INFO:root:[  134] Training loss: 0.94287128, Validation loss: 0.94079126, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18572.34375MB; mem (CPU total)=21167.03125MB
INFO:root:[  135] Training loss: 0.94297939, Validation loss: 0.94062471, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18610.4375MB; mem (CPU total)=21206.640625MB
INFO:root:[  136] Training loss: 0.94285007, Validation loss: 0.94244339, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18648.53125MB; mem (CPU total)=21244.34765625MB
INFO:root:[  137] Training loss: 0.94281968, Validation loss: 0.93965335, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18686.6328125MB; mem (CPU total)=21303.69140625MB
INFO:root:[  138] Training loss: 0.94275867, Validation loss: 0.94120083, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18724.72265625MB; mem (CPU total)=21341.58984375MB
INFO:root:[  139] Training loss: 0.94290425, Validation loss: 0.93979073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18762.81640625MB; mem (CPU total)=21379.76171875MB
INFO:root:[  140] Training loss: 0.94245739, Validation loss: 0.94000544, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18800.91796875MB; mem (CPU total)=21417.87109375MB
INFO:root:[  141] Training loss: 0.94269416, Validation loss: 0.93985891, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18839.01171875MB; mem (CPU total)=21456.09765625MB
INFO:root:[  142] Training loss: 0.94248689, Validation loss: 0.94081225, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18877.10546875MB; mem (CPU total)=21494.1640625MB
INFO:root:[  143] Training loss: 0.94266484, Validation loss: 0.94032345, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18915.19921875MB; mem (CPU total)=21532.109375MB
INFO:root:[  144] Training loss: 0.94234797, Validation loss: 0.93924499, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18953.296875MB; mem (CPU total)=21571.66796875MB
INFO:root:[  145] Training loss: 0.94232681, Validation loss: 0.94061008, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=18991.390625MB; mem (CPU total)=21609.69921875MB
INFO:root:[  146] Training loss: 0.94239292, Validation loss: 0.93891606, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19029.48828125MB; mem (CPU total)=21648.11328125MB
INFO:root:[  147] Training loss: 0.94221365, Validation loss: 0.94008924, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19067.58203125MB; mem (CPU total)=21686.7265625MB
INFO:root:[  148] Training loss: 0.94221822, Validation loss: 0.93977627, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19105.67578125MB; mem (CPU total)=18846.6328125MB
INFO:root:[  149] Training loss: 0.94212616, Validation loss: 0.93976072, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19143.77734375MB; mem (CPU total)=18884.796875MB
INFO:root:[  150] Training loss: 0.94209806, Validation loss: 0.94030591, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19181.87890625MB; mem (CPU total)=19294.0MB
INFO:root:[  151] Training loss: 0.94209414, Validation loss: 0.94034876, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19219.97265625MB; mem (CPU total)=21693.0546875MB
INFO:root:[  152] Training loss: 0.94210539, Validation loss: 0.93984159, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19258.06640625MB; mem (CPU total)=21735.6171875MB
INFO:root:[  153] Training loss: 0.94183733, Validation loss: 0.93964525, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19296.16015625MB; mem (CPU total)=21775.8203125MB
INFO:root:[  154] Training loss: 0.94184326, Validation loss: 0.93882966, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19334.26171875MB; mem (CPU total)=21817.69140625MB
INFO:root:[  155] Training loss: 0.94174326, Validation loss: 0.93958329, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19372.3515625MB; mem (CPU total)=21857.8046875MB
INFO:root:[  156] Training loss: 0.94178311, Validation loss: 0.93947213, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19410.4453125MB; mem (CPU total)=21900.3671875MB
INFO:root:[  157] Training loss: 0.94171219, Validation loss: 0.93938851, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19448.54296875MB; mem (CPU total)=21940.27734375MB
INFO:root:[  158] Training loss: 0.94171719, Validation loss: 0.93897326, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19486.640625MB; mem (CPU total)=21983.0625MB
INFO:root:[  159] Training loss: 0.94166750, Validation loss: 0.93914636, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19524.734375MB; mem (CPU total)=22024.41015625MB
INFO:root:[  160] Training loss: 0.94155271, Validation loss: 0.93900039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19562.828125MB; mem (CPU total)=22066.3125MB
INFO:root:[  161] Training loss: 0.94162387, Validation loss: 0.93965235, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19600.9296875MB; mem (CPU total)=22107.78515625MB
INFO:root:[  162] Training loss: 0.94162434, Validation loss: 0.93845722, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19639.02734375MB; mem (CPU total)=22195.890625MB
INFO:root:[  163] Training loss: 0.94148428, Validation loss: 0.94033360, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19677.1171875MB; mem (CPU total)=22233.828125MB
INFO:root:[  164] Training loss: 0.94138287, Validation loss: 0.93962413, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19715.21484375MB; mem (CPU total)=22272.203125MB
INFO:root:[  165] Training loss: 0.94136232, Validation loss: 0.93900835, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19753.3125MB; mem (CPU total)=22310.62890625MB
INFO:root:[  166] Training loss: 0.94137076, Validation loss: 0.93864384, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19791.40625MB; mem (CPU total)=22348.44921875MB
INFO:root:[  167] Training loss: 0.94119387, Validation loss: 0.93931149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19829.50390625MB; mem (CPU total)=22387.1171875MB
INFO:root:[  168] Training loss: 0.94131965, Validation loss: 0.93849371, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19867.59765625MB; mem (CPU total)=22423.43359375MB
INFO:root:[  169] Training loss: 0.94104081, Validation loss: 0.93998621, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19905.69140625MB; mem (CPU total)=22461.63671875MB
INFO:root:[  170] Training loss: 0.94102077, Validation loss: 0.93838555, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19943.7890625MB; mem (CPU total)=22499.4921875MB
INFO:root:[  171] Training loss: 0.94102669, Validation loss: 0.93903855, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=19981.8828125MB; mem (CPU total)=22538.3359375MB
INFO:root:[  172] Training loss: 0.94104037, Validation loss: 0.93797025, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20019.98046875MB; mem (CPU total)=22605.12890625MB
INFO:root:[  173] Training loss: 0.94091952, Validation loss: 0.93783191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20058.07421875MB; mem (CPU total)=22643.828125MB
INFO:root:[  174] Training loss: 0.94105759, Validation loss: 0.93948766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20096.16796875MB; mem (CPU total)=22682.1796875MB
INFO:root:[  175] Training loss: 0.94088135, Validation loss: 0.93766844, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20134.265625MB; mem (CPU total)=22720.78515625MB
INFO:root:[  176] Training loss: 0.94062823, Validation loss: 0.93901998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20172.359375MB; mem (CPU total)=22759.703125MB
INFO:root:[  177] Training loss: 0.94063054, Validation loss: 0.93812574, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20210.453125MB; mem (CPU total)=22797.73046875MB
INFO:root:[  178] Training loss: 0.94062088, Validation loss: 0.93746051, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20248.5546875MB; mem (CPU total)=22836.12109375MB
INFO:root:[  179] Training loss: 0.94055717, Validation loss: 0.93765199, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20286.64453125MB; mem (CPU total)=22874.703125MB
INFO:root:[  180] Training loss: 0.94047692, Validation loss: 0.93804823, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20324.73828125MB; mem (CPU total)=22912.41015625MB
INFO:root:[  181] Training loss: 0.94042144, Validation loss: 0.93783577, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20362.8359375MB; mem (CPU total)=22950.78515625MB
INFO:root:[  182] Training loss: 0.94033174, Validation loss: 0.93818653, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20400.93359375MB; mem (CPU total)=22988.60546875MB
INFO:root:[  183] Training loss: 0.94013059, Validation loss: 0.93823039, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20439.02734375MB; mem (CPU total)=23056.546875MB
INFO:root:[  184] Training loss: 0.94004888, Validation loss: 0.93995050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20477.125MB; mem (CPU total)=23094.671875MB
INFO:root:[  185] Training loss: 0.94018569, Validation loss: 0.93738824, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20515.21875MB; mem (CPU total)=23133.3984375MB
INFO:root:[  186] Training loss: 0.94016767, Validation loss: 0.93708845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20553.3125MB; mem (CPU total)=23171.4921875MB
INFO:root:[  187] Training loss: 0.93987190, Validation loss: 0.93708127, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20591.40625MB; mem (CPU total)=23209.21875MB
INFO:root:[  188] Training loss: 0.93968878, Validation loss: 0.93708210, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20629.50390625MB; mem (CPU total)=23247.80078125MB
INFO:root:[  189] Training loss: 0.93970880, Validation loss: 0.93689505, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20667.6015625MB; mem (CPU total)=23285.8125MB
INFO:root:[  190] Training loss: 0.93973970, Validation loss: 0.93768988, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20705.69140625MB; mem (CPU total)=23324.3203125MB
INFO:root:[  191] Training loss: 0.93957081, Validation loss: 0.93714038, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20743.7890625MB; mem (CPU total)=23362.57421875MB
INFO:root:[  192] Training loss: 0.93950827, Validation loss: 0.93729244, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20781.88671875MB; mem (CPU total)=23400.1796875MB
INFO:root:[  193] Training loss: 0.93941706, Validation loss: 0.93745335, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20819.98046875MB; mem (CPU total)=23438.58984375MB
INFO:root:[  194] Training loss: 0.93926459, Validation loss: 0.93766198, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20858.07421875MB; mem (CPU total)=23476.703125MB
INFO:root:[  195] Training loss: 0.93919632, Validation loss: 0.93893964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20896.171875MB; mem (CPU total)=23540.59765625MB
INFO:root:[  196] Training loss: 0.93937579, Validation loss: 0.93603524, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20934.26953125MB; mem (CPU total)=23578.63671875MB
INFO:root:[  197] Training loss: 0.93908832, Validation loss: 0.93621568, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=20972.359375MB; mem (CPU total)=23617.05078125MB
INFO:root:[  198] Training loss: 0.93901400, Validation loss: 0.93741746, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21010.4609375MB; mem (CPU total)=23655.17578125MB
INFO:root:[  199] Training loss: 0.93911386, Validation loss: 0.93644133, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21048.5546875MB; mem (CPU total)=23693.140625MB
INFO:root:[  200] Training loss: 0.93897626, Validation loss: 0.93653673, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21086.6484375MB; mem (CPU total)=23731.2578125MB
INFO:root:[  201] Training loss: 0.93890329, Validation loss: 0.93643178, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21124.74609375MB; mem (CPU total)=23769.59765625MB
INFO:root:[  202] Training loss: 0.93884130, Validation loss: 0.93624260, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21162.83984375MB; mem (CPU total)=23808.90625MB
INFO:root:[  203] Training loss: 0.93879034, Validation loss: 0.93646830, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21200.9375MB; mem (CPU total)=23847.0078125MB
INFO:root:[  204] Training loss: 0.93870575, Validation loss: 0.93553698, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21239.03515625MB; mem (CPU total)=23885.8828125MB
INFO:root:[  205] Training loss: 0.93855444, Validation loss: 0.93649506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21277.12890625MB; mem (CPU total)=21024.82421875MB
INFO:root:[  206] Training loss: 0.93845231, Validation loss: 0.93541333, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21315.2265625MB; mem (CPU total)=21062.8359375MB
INFO:root:[  207] Training loss: 0.93837313, Validation loss: 0.93651541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21353.31640625MB; mem (CPU total)=21101.20703125MB
INFO:root:[  208] Training loss: 0.93836204, Validation loss: 0.93539614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21391.41796875MB; mem (CPU total)=21139.140625MB
INFO:root:[  209] Training loss: 0.93828496, Validation loss: 0.93658963, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21429.51171875MB; mem (CPU total)=21177.2734375MB
INFO:root:[  210] Training loss: 0.93811200, Validation loss: 0.93617848, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21467.60546875MB; mem (CPU total)=21215.58203125MB
INFO:root:[  211] Training loss: 0.93822283, Validation loss: 0.93485351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21505.80859375MB; mem (CPU total)=21253.72265625MB
INFO:root:[  212] Training loss: 0.93820814, Validation loss: 0.93534464, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21543.90234375MB; mem (CPU total)=21291.89453125MB
INFO:root:[  213] Training loss: 0.93816203, Validation loss: 0.93704725, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21581.99609375MB; mem (CPU total)=21330.265625MB
INFO:root:[  214] Training loss: 0.93807341, Validation loss: 0.93530120, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21620.09375MB; mem (CPU total)=24097.8203125MB
INFO:root:[  215] Training loss: 0.93798596, Validation loss: 0.93507234, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21658.19140625MB; mem (CPU total)=24139.87890625MB
INFO:root:[  216] Training loss: 0.93790271, Validation loss: 0.93511896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21696.28515625MB; mem (CPU total)=24181.4375MB
INFO:root:[  217] Training loss: 0.93802447, Validation loss: 0.93643779, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21734.37890625MB; mem (CPU total)=24222.25390625MB
INFO:root:[  218] Training loss: 0.93791516, Validation loss: 0.93612015, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21772.48046875MB; mem (CPU total)=24264.21875MB
INFO:root:[  219] Training loss: 0.93767927, Validation loss: 0.93577653, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21810.57421875MB; mem (CPU total)=24306.54296875MB
INFO:root:[  220] Training loss: 0.93772682, Validation loss: 0.93464745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21848.671875MB; mem (CPU total)=24346.2109375MB
INFO:root:[  221] Training loss: 0.93773068, Validation loss: 0.93522496, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21886.76171875MB; mem (CPU total)=24388.0703125MB
INFO:root:[  222] Training loss: 0.93777933, Validation loss: 0.93669574, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21924.859375MB; mem (CPU total)=24429.35546875MB
INFO:root:[  223] Training loss: 0.93761360, Validation loss: 0.93513941, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=21962.953125MB; mem (CPU total)=24470.4453125MB
INFO:root:[  224] Training loss: 0.93741637, Validation loss: 0.93517065, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22001.05078125MB; mem (CPU total)=24557.10546875MB
INFO:root:[  225] Training loss: 0.93754994, Validation loss: 0.93476422, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22039.1484375MB; mem (CPU total)=24595.48046875MB
INFO:root:[  226] Training loss: 0.93737289, Validation loss: 0.93582204, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22077.2421875MB; mem (CPU total)=24633.625MB
INFO:root:[  227] Training loss: 0.93747584, Validation loss: 0.93534796, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22115.3359375MB; mem (CPU total)=24671.1640625MB
INFO:root:[  228] Training loss: 0.93742309, Validation loss: 0.93475496, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22153.4296875MB; mem (CPU total)=24709.796875MB
INFO:root:[  229] Training loss: 0.93739060, Validation loss: 0.93463541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22191.52734375MB; mem (CPU total)=24748.14453125MB
INFO:root:[  230] Training loss: 0.93740923, Validation loss: 0.93466487, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22229.62109375MB; mem (CPU total)=24786.21875MB
INFO:root:[  231] Training loss: 0.93720037, Validation loss: 0.93507817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22267.71484375MB; mem (CPU total)=24824.37890625MB
INFO:root:[  232] Training loss: 0.93709270, Validation loss: 0.93516534, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22305.8125MB; mem (CPU total)=24862.51953125MB
INFO:root:[  233] Training loss: 0.93716291, Validation loss: 0.93448392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22343.91015625MB; mem (CPU total)=24930.74609375MB
INFO:root:[  234] Training loss: 0.93709152, Validation loss: 0.93482049, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22382.00390625MB; mem (CPU total)=24969.13671875MB
INFO:root:[  235] Training loss: 0.93703724, Validation loss: 0.93488791, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22420.1015625MB; mem (CPU total)=25007.0703125MB
INFO:root:[  236] Training loss: 0.93702181, Validation loss: 0.93504392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22458.1953125MB; mem (CPU total)=25045.1875MB
INFO:root:[  237] Training loss: 0.93708924, Validation loss: 0.93529543, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22496.2890625MB; mem (CPU total)=25083.8125MB
INFO:root:[  238] Training loss: 0.93680471, Validation loss: 0.93466968, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22534.3828125MB; mem (CPU total)=25122.1953125MB
INFO:root:[  239] Training loss: 0.93689304, Validation loss: 0.93498426, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22572.48046875MB; mem (CPU total)=25160.328125MB
INFO:root:[  240] Training loss: 0.93686702, Validation loss: 0.93370029, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22610.578125MB; mem (CPU total)=25198.84765625MB
INFO:root:[  241] Training loss: 0.93668998, Validation loss: 0.93472601, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22648.66796875MB; mem (CPU total)=25237.19921875MB
INFO:root:[  242] Training loss: 0.93683227, Validation loss: 0.93483694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22686.76953125MB; mem (CPU total)=25275.3359375MB
INFO:root:[  243] Training loss: 0.93674923, Validation loss: 0.93377365, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22724.86328125MB; mem (CPU total)=25335.484375MB
INFO:root:[  244] Training loss: 0.93690573, Validation loss: 0.93370937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22762.95703125MB; mem (CPU total)=25373.0546875MB
INFO:root:[  245] Training loss: 0.93684731, Validation loss: 0.93460182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22801.05078125MB; mem (CPU total)=25411.171875MB
INFO:root:[  246] Training loss: 0.93675761, Validation loss: 0.93462110, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22839.15234375MB; mem (CPU total)=25449.51953125MB
INFO:root:[  247] Training loss: 0.93652959, Validation loss: 0.93389832, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22877.24609375MB; mem (CPU total)=25487.4453125MB
INFO:root:[  248] Training loss: 0.93657172, Validation loss: 0.93461624, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22915.33984375MB; mem (CPU total)=25525.09375MB
INFO:root:[  249] Training loss: 0.93653082, Validation loss: 0.93450202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=22953.4375MB; mem (CPU total)=25563.1875MB
INFO:root:EP 249: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=22991.34375MB; mem (CPU total)=25601.07421875MB
INFO:root:Training the model took 11723.219s.
INFO:root:Emptying the cuda cache took 0.009s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.93734
INFO:root:EnergyScoreTrain: 0.82615
INFO:root:CRPSTrain: 0.67949
INFO:root:Gaussian NLLTrain: 45120.84389
INFO:root:CoverageTrain: 0.1264
INFO:root:IntervalWidthTrain: 0.25493
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94188
INFO:root:EnergyScoreValidation: 0.83419
INFO:root:CRPSValidation: 0.68565
INFO:root:Gaussian NLLValidation: 57832.43536
INFO:root:CoverageValidation: 0.12156
INFO:root:IntervalWidthValidation: 0.2455
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94116
INFO:root:EnergyScoreTest: 0.82856
INFO:root:CRPSTest: 0.68233
INFO:root:Gaussian NLLTest: 109831.85677
INFO:root:CoverageTest: 0.12608
INFO:root:IntervalWidthTest: 0.25762
INFO:root:After validation: mem (CPU python)=23065.1015625MB; mem (CPU total)=25698.17578125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.02, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=23065.1015625MB; mem (CPU total)=25698.08984375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=23066.10546875MB; mem (CPU total)=25699.07421875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=23066.2265625MB; mem (CPU total)=25699.078125MB
INFO:root:[    1] Training loss: 1.00881478, Validation loss: 0.99281478, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23104.0625MB; mem (CPU total)=25736.9609375MB
INFO:root:[    2] Training loss: 0.98805470, Validation loss: 0.98143722, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23142.17578125MB; mem (CPU total)=25775.3359375MB
INFO:root:[    3] Training loss: 0.98089061, Validation loss: 0.97576883, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23180.29296875MB; mem (CPU total)=25812.52734375MB
INFO:root:[    4] Training loss: 0.97757724, Validation loss: 0.97474775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23218.38671875MB; mem (CPU total)=25850.9609375MB
INFO:root:[    5] Training loss: 0.97565803, Validation loss: 0.97216962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23256.484375MB; mem (CPU total)=25888.98828125MB
INFO:root:[    6] Training loss: 0.97439396, Validation loss: 0.97088794, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23294.58203125MB; mem (CPU total)=25928.17578125MB
INFO:root:[    7] Training loss: 0.97323091, Validation loss: 0.96961140, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23332.67578125MB; mem (CPU total)=25966.07421875MB
INFO:root:[    8] Training loss: 0.97234859, Validation loss: 0.96849563, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23370.76953125MB; mem (CPU total)=26004.75390625MB
INFO:root:[    9] Training loss: 0.97152645, Validation loss: 0.96734392, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23408.87109375MB; mem (CPU total)=23158.31640625MB
INFO:root:[   10] Training loss: 0.97087409, Validation loss: 0.96721277, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23446.96484375MB; mem (CPU total)=23195.94921875MB
INFO:root:[   11] Training loss: 0.97041166, Validation loss: 0.96661967, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23485.05859375MB; mem (CPU total)=23234.421875MB
INFO:root:[   12] Training loss: 0.96986687, Validation loss: 0.96588559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23523.15234375MB; mem (CPU total)=23272.2734375MB
INFO:root:[   13] Training loss: 0.96955999, Validation loss: 0.96518453, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23561.25MB; mem (CPU total)=23310.42578125MB
INFO:root:[   14] Training loss: 0.96899606, Validation loss: 0.96582805, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23599.34375MB; mem (CPU total)=23348.8359375MB
INFO:root:[   15] Training loss: 0.96833073, Validation loss: 0.96567102, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23637.4375MB; mem (CPU total)=23386.72265625MB
INFO:root:[   16] Training loss: 0.96754864, Validation loss: 0.96463356, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23675.53515625MB; mem (CPU total)=23425.4453125MB
INFO:root:[   17] Training loss: 0.96706013, Validation loss: 0.96308040, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23713.6328125MB; mem (CPU total)=23464.1640625MB
INFO:root:[   18] Training loss: 0.96641884, Validation loss: 0.96449416, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23751.72265625MB; mem (CPU total)=23501.87890625MB
INFO:root:[   19] Training loss: 0.96578461, Validation loss: 0.96174201, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23789.82421875MB; mem (CPU total)=23540.2890625MB
INFO:root:[   20] Training loss: 0.96496178, Validation loss: 0.96011380, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23827.91796875MB; mem (CPU total)=23579.0078125MB
INFO:root:[   21] Training loss: 0.96450672, Validation loss: 0.96004429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23866.01171875MB; mem (CPU total)=23616.71875MB
INFO:root:[   22] Training loss: 0.96386036, Validation loss: 0.95912387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23904.10546875MB; mem (CPU total)=23654.96875MB
INFO:root:[   23] Training loss: 0.96329071, Validation loss: 0.95908173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23942.203125MB; mem (CPU total)=23693.22265625MB
INFO:root:[   24] Training loss: 0.96294205, Validation loss: 0.95883875, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=23980.296875MB; mem (CPU total)=23731.671875MB
INFO:root:[   25] Training loss: 0.96258191, Validation loss: 0.95682801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24018.39453125MB; mem (CPU total)=23770.0234375MB
INFO:root:[   26] Training loss: 0.96206160, Validation loss: 0.95724675, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24056.48828125MB; mem (CPU total)=26533.78515625MB
INFO:root:[   27] Training loss: 0.96173930, Validation loss: 0.95588076, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24094.5859375MB; mem (CPU total)=26581.97265625MB
INFO:root:[   28] Training loss: 0.96099354, Validation loss: 0.95556603, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24132.6796875MB; mem (CPU total)=26624.78515625MB
INFO:root:[   29] Training loss: 0.96090259, Validation loss: 0.95648247, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24170.76953125MB; mem (CPU total)=26666.38671875MB
INFO:root:[   30] Training loss: 0.96067573, Validation loss: 0.95623507, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24208.87109375MB; mem (CPU total)=26708.953125MB
INFO:root:[   31] Training loss: 0.95999579, Validation loss: 0.95559966, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24246.96484375MB; mem (CPU total)=26749.80078125MB
INFO:root:[   32] Training loss: 0.95965304, Validation loss: 0.95411047, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24285.05859375MB; mem (CPU total)=26790.52734375MB
INFO:root:[   33] Training loss: 0.95930289, Validation loss: 0.95515116, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24323.15625MB; mem (CPU total)=26833.1875MB
INFO:root:[   34] Training loss: 0.95898173, Validation loss: 0.95512342, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24361.25MB; mem (CPU total)=26873.7890625MB
INFO:root:[   35] Training loss: 0.95849003, Validation loss: 0.95379062, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24399.34765625MB; mem (CPU total)=26966.12109375MB
INFO:root:[   36] Training loss: 0.95840177, Validation loss: 0.95327729, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24437.4453125MB; mem (CPU total)=27004.9140625MB
INFO:root:[   37] Training loss: 0.95798483, Validation loss: 0.95256189, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24475.5390625MB; mem (CPU total)=27043.75390625MB
INFO:root:[   38] Training loss: 0.95809292, Validation loss: 0.95372386, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24513.6328125MB; mem (CPU total)=27082.109375MB
INFO:root:[   39] Training loss: 0.95756214, Validation loss: 0.95396567, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24551.7265625MB; mem (CPU total)=27120.21484375MB
INFO:root:[   40] Training loss: 0.95755944, Validation loss: 0.95165102, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24589.82421875MB; mem (CPU total)=27156.71875MB
INFO:root:[   41] Training loss: 0.95728555, Validation loss: 0.95227246, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24627.91796875MB; mem (CPU total)=27195.09375MB
INFO:root:[   42] Training loss: 0.95707413, Validation loss: 0.95285999, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24666.01171875MB; mem (CPU total)=27233.203125MB
INFO:root:[   43] Training loss: 0.95676224, Validation loss: 0.95198080, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24704.109375MB; mem (CPU total)=27271.0625MB
INFO:root:[   44] Training loss: 0.95655359, Validation loss: 0.95168045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24742.203125MB; mem (CPU total)=27337.46484375MB
INFO:root:[   45] Training loss: 0.95652340, Validation loss: 0.95069430, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24780.30078125MB; mem (CPU total)=27375.83984375MB
INFO:root:[   46] Training loss: 0.95653500, Validation loss: 0.95095957, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24818.39453125MB; mem (CPU total)=27414.15625MB
INFO:root:[   47] Training loss: 0.95592500, Validation loss: 0.95110967, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24856.4921875MB; mem (CPU total)=27452.765625MB
INFO:root:[   48] Training loss: 0.95602268, Validation loss: 0.95014588, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24894.5859375MB; mem (CPU total)=27490.42578125MB
INFO:root:[   49] Training loss: 0.95564481, Validation loss: 0.95016995, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24932.68359375MB; mem (CPU total)=27529.0703125MB
INFO:root:[   50] Training loss: 0.95566521, Validation loss: 0.94988944, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=24970.78125MB; mem (CPU total)=27567.1796875MB
INFO:root:[   51] Training loss: 0.95528168, Validation loss: 0.95022437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25008.875MB; mem (CPU total)=27605.76171875MB
INFO:root:[   52] Training loss: 0.95515843, Validation loss: 0.95050142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25046.96875MB; mem (CPU total)=27643.9375MB
INFO:root:[   53] Training loss: 0.95494992, Validation loss: 0.94991869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25085.0703125MB; mem (CPU total)=27704.36328125MB
INFO:root:[   54] Training loss: 0.95505386, Validation loss: 0.95191797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25123.16796875MB; mem (CPU total)=27742.40625MB
INFO:root:[   55] Training loss: 0.95500818, Validation loss: 0.94930509, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25161.26171875MB; mem (CPU total)=27780.71484375MB
INFO:root:[   56] Training loss: 0.95465628, Validation loss: 0.95008905, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25199.35546875MB; mem (CPU total)=27819.1015625MB
INFO:root:[   57] Training loss: 0.95430104, Validation loss: 0.95068411, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25237.453125MB; mem (CPU total)=27857.24609375MB
INFO:root:[   58] Training loss: 0.95430006, Validation loss: 0.94898830, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25275.55078125MB; mem (CPU total)=27895.38671875MB
INFO:root:[   59] Training loss: 0.95431779, Validation loss: 0.94957863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25313.640625MB; mem (CPU total)=27933.3125MB
INFO:root:[   60] Training loss: 0.95414945, Validation loss: 0.94938442, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25351.73828125MB; mem (CPU total)=27971.90625MB
INFO:root:[   61] Training loss: 0.95388226, Validation loss: 0.94860744, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25389.8359375MB; mem (CPU total)=28009.91015625MB
INFO:root:[   62] Training loss: 0.95361809, Validation loss: 0.94806412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25427.9296875MB; mem (CPU total)=28073.52734375MB
INFO:root:[   63] Training loss: 0.95362201, Validation loss: 0.94929114, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25466.0234375MB; mem (CPU total)=28111.8671875MB
INFO:root:[   64] Training loss: 0.95351464, Validation loss: 0.94739620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25504.12109375MB; mem (CPU total)=28149.96484375MB
INFO:root:[   65] Training loss: 0.95329574, Validation loss: 0.94831458, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25542.2109375MB; mem (CPU total)=28188.3515625MB
INFO:root:[   66] Training loss: 0.95318901, Validation loss: 0.94800576, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25580.3046875MB; mem (CPU total)=28226.109375MB
INFO:root:[   67] Training loss: 0.95308739, Validation loss: 0.94772578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25618.40234375MB; mem (CPU total)=28263.9609375MB
INFO:root:[   68] Training loss: 0.95279923, Validation loss: 0.94729443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25656.5MB; mem (CPU total)=28302.93359375MB
INFO:root:[   69] Training loss: 0.95269937, Validation loss: 0.94733485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25694.58984375MB; mem (CPU total)=28341.32421875MB
INFO:root:[   70] Training loss: 0.95229257, Validation loss: 0.94751626, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25732.69140625MB; mem (CPU total)=28379.171875MB
INFO:root:[   71] Training loss: 0.95231118, Validation loss: 0.94658046, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25770.78515625MB; mem (CPU total)=25527.6953125MB
INFO:root:[   72] Training loss: 0.95218508, Validation loss: 0.94644804, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25808.87890625MB; mem (CPU total)=28431.1640625MB
INFO:root:[   73] Training loss: 0.95212081, Validation loss: 0.94732270, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25846.97265625MB; mem (CPU total)=28999.28515625MB
INFO:root:[   74] Training loss: 0.95218383, Validation loss: 0.94722497, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25885.0703125MB; mem (CPU total)=29124.5234375MB
INFO:root:[   75] Training loss: 0.95214094, Validation loss: 0.94570557, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25923.16796875MB; mem (CPU total)=29249.27734375MB
INFO:root:[   76] Training loss: 0.95230024, Validation loss: 0.94617774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25961.2578125MB; mem (CPU total)=29374.9375MB
INFO:root:[   77] Training loss: 0.95187441, Validation loss: 0.94662506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=25999.359375MB; mem (CPU total)=29505.58984375MB
INFO:root:[   78] Training loss: 0.95184989, Validation loss: 0.94623281, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26037.453125MB; mem (CPU total)=29634.52734375MB
INFO:root:[   79] Training loss: 0.95156255, Validation loss: 0.94750489, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26075.546875MB; mem (CPU total)=29764.69140625MB
INFO:root:[   80] Training loss: 0.95148952, Validation loss: 0.94715550, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26113.640625MB; mem (CPU total)=29894.8515625MB
INFO:root:[   81] Training loss: 0.95145095, Validation loss: 0.94640455, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26151.73828125MB; mem (CPU total)=30025.0MB
INFO:root:[   82] Training loss: 0.95132328, Validation loss: 0.94671033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26189.83203125MB; mem (CPU total)=30157.078125MB
INFO:root:[   83] Training loss: 0.95124217, Validation loss: 0.94652410, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26227.92578125MB; mem (CPU total)=30289.01953125MB
INFO:root:[   84] Training loss: 0.95117512, Validation loss: 0.94591970, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26266.0234375MB; mem (CPU total)=30423.20703125MB
INFO:root:EP 84: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=26304.0546875MB; mem (CPU total)=30523.61328125MB
INFO:root:Training the model took 4448.717s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.95455
INFO:root:EnergyScoreTrain: 0.82484
INFO:root:CRPSTrain: 0.68206
INFO:root:Gaussian NLLTrain: 357933.03093
INFO:root:CoverageTrain: 0.14352
INFO:root:IntervalWidthTrain: 0.31798
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.95589
INFO:root:EnergyScoreValidation: 0.82911
INFO:root:CRPSValidation: 0.68537
INFO:root:Gaussian NLLValidation: 52953.96158
INFO:root:CoverageValidation: 0.14004
INFO:root:IntervalWidthValidation: 0.30959
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.95527
INFO:root:EnergyScoreTest: 0.83086
INFO:root:CRPSTest: 0.68685
INFO:root:Gaussian NLLTest: 57058.09382
INFO:root:CoverageTest: 0.13601
INFO:root:IntervalWidthTest: 0.30133
INFO:root:After validation: mem (CPU python)=26377.5703125MB; mem (CPU total)=30893.40234375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.05, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=26377.5703125MB; mem (CPU total)=30929.65625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=26377.59765625MB; mem (CPU total)=30929.65625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=26377.59765625MB; mem (CPU total)=30966.15234375MB
INFO:root:[    1] Training loss: 1.00984692, Validation loss: 0.99326509, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26415.59765625MB; mem (CPU total)=31102.390625MB
INFO:root:[    2] Training loss: 0.98955657, Validation loss: 0.98158516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26453.69921875MB; mem (CPU total)=31240.53125MB
INFO:root:[    3] Training loss: 0.98325835, Validation loss: 0.97725167, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26491.796875MB; mem (CPU total)=31379.171875MB
INFO:root:[    4] Training loss: 0.98035686, Validation loss: 0.97503785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26529.890625MB; mem (CPU total)=31519.8515625MB
INFO:root:[    5] Training loss: 0.97852575, Validation loss: 0.97261603, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26567.98828125MB; mem (CPU total)=31651.4140625MB
INFO:root:[    6] Training loss: 0.97733380, Validation loss: 0.97131710, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26606.08203125MB; mem (CPU total)=31775.79296875MB
INFO:root:[    7] Training loss: 0.97640281, Validation loss: 0.97011452, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26644.17578125MB; mem (CPU total)=31903.03125MB
INFO:root:[    8] Training loss: 0.97559402, Validation loss: 0.96967504, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26682.26953125MB; mem (CPU total)=32030.9921875MB
INFO:root:[    9] Training loss: 0.97478617, Validation loss: 0.96785351, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26720.3671875MB; mem (CPU total)=32156.58984375MB
INFO:root:[   10] Training loss: 0.97436685, Validation loss: 0.96818305, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26758.4609375MB; mem (CPU total)=32284.52734375MB
INFO:root:[   11] Training loss: 0.97380791, Validation loss: 0.96784943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26796.55859375MB; mem (CPU total)=32412.52734375MB
INFO:root:[   12] Training loss: 0.97355061, Validation loss: 0.96808632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26834.65625MB; mem (CPU total)=32538.0078125MB
INFO:root:[   13] Training loss: 0.97309352, Validation loss: 0.96675640, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26872.75390625MB; mem (CPU total)=32665.09375MB
INFO:root:[   14] Training loss: 0.97286488, Validation loss: 0.96746559, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26910.84375MB; mem (CPU total)=32791.87890625MB
INFO:root:[   15] Training loss: 0.97221048, Validation loss: 0.96526614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26948.94140625MB; mem (CPU total)=32920.13671875MB
INFO:root:[   16] Training loss: 0.97155500, Validation loss: 0.96774446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=26987.0390625MB; mem (CPU total)=33048.3046875MB
INFO:root:[   17] Training loss: 0.97103721, Validation loss: 0.96445652, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27025.1328125MB; mem (CPU total)=33175.04296875MB
INFO:root:[   18] Training loss: 0.97058680, Validation loss: 0.96506964, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27063.2265625MB; mem (CPU total)=33303.53515625MB
INFO:root:[   19] Training loss: 0.96992870, Validation loss: 0.96271404, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27101.32421875MB; mem (CPU total)=33431.6953125MB
INFO:root:[   20] Training loss: 0.96926697, Validation loss: 0.96130927, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27139.421875MB; mem (CPU total)=33557.796875MB
INFO:root:[   21] Training loss: 0.96860536, Validation loss: 0.96230104, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27177.515625MB; mem (CPU total)=33684.42578125MB
INFO:root:[   22] Training loss: 0.96799637, Validation loss: 0.96134665, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27215.61328125MB; mem (CPU total)=33812.41015625MB
INFO:root:[   23] Training loss: 0.96766700, Validation loss: 0.96031846, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27253.70703125MB; mem (CPU total)=33938.6796875MB
INFO:root:[   24] Training loss: 0.96702762, Validation loss: 0.96077202, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27291.80078125MB; mem (CPU total)=34066.1796875MB
INFO:root:[   25] Training loss: 0.96651750, Validation loss: 0.95909797, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27329.90234375MB; mem (CPU total)=34193.33984375MB
INFO:root:[   26] Training loss: 0.96599597, Validation loss: 0.95806684, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27368.0MB; mem (CPU total)=34321.3984375MB
INFO:root:[   27] Training loss: 0.96594991, Validation loss: 0.95866798, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27406.08984375MB; mem (CPU total)=34448.8984375MB
INFO:root:[   28] Training loss: 0.96542922, Validation loss: 0.95772890, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27444.1875MB; mem (CPU total)=34573.9921875MB
INFO:root:[   29] Training loss: 0.96522666, Validation loss: 0.95813714, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27482.28125MB; mem (CPU total)=34711.375MB
INFO:root:[   30] Training loss: 0.96496505, Validation loss: 0.95751387, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27520.37890625MB; mem (CPU total)=34845.1640625MB
INFO:root:[   31] Training loss: 0.96466152, Validation loss: 0.95665531, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27558.47265625MB; mem (CPU total)=34980.04296875MB
INFO:root:[   32] Training loss: 0.96433231, Validation loss: 0.95564491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27596.56640625MB; mem (CPU total)=35116.05078125MB
INFO:root:[   33] Training loss: 0.96434323, Validation loss: 0.95665724, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27634.6640625MB; mem (CPU total)=35249.84375MB
INFO:root:[   34] Training loss: 0.96396409, Validation loss: 0.95705137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27672.7578125MB; mem (CPU total)=35384.5546875MB
INFO:root:[   35] Training loss: 0.96350143, Validation loss: 0.95523526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27710.85546875MB; mem (CPU total)=35515.91796875MB
INFO:root:[   36] Training loss: 0.96367512, Validation loss: 0.95677338, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27748.953125MB; mem (CPU total)=35647.06640625MB
INFO:root:[   37] Training loss: 0.96321298, Validation loss: 0.95598499, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27787.046875MB; mem (CPU total)=35777.078125MB
INFO:root:[   38] Training loss: 0.96315180, Validation loss: 0.95577636, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27825.140625MB; mem (CPU total)=35913.44140625MB
INFO:root:[   39] Training loss: 0.96266111, Validation loss: 0.95398642, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27863.2421875MB; mem (CPU total)=36050.30078125MB
INFO:root:[   40] Training loss: 0.96249990, Validation loss: 0.95355018, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27901.3359375MB; mem (CPU total)=36180.59375MB
INFO:root:[   41] Training loss: 0.96243297, Validation loss: 0.95401201, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27939.42578125MB; mem (CPU total)=36311.53125MB
INFO:root:[   42] Training loss: 0.96217892, Validation loss: 0.95410446, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=27977.51953125MB; mem (CPU total)=36442.9453125MB
INFO:root:[   43] Training loss: 0.96221803, Validation loss: 0.95429301, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28015.6171875MB; mem (CPU total)=36576.06640625MB
INFO:root:[   44] Training loss: 0.96196750, Validation loss: 0.95598919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28053.7109375MB; mem (CPU total)=36707.2265625MB
INFO:root:[   45] Training loss: 0.96197338, Validation loss: 0.95482073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28091.80859375MB; mem (CPU total)=36839.59375MB
INFO:root:[   46] Training loss: 0.96179846, Validation loss: 0.95460068, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28129.90625MB; mem (CPU total)=36971.8984375MB
INFO:root:[   47] Training loss: 0.96144453, Validation loss: 0.95383668, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28168.0MB; mem (CPU total)=37105.52734375MB
INFO:root:[   48] Training loss: 0.96130008, Validation loss: 0.95410950, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28206.09375MB; mem (CPU total)=37237.92578125MB
INFO:root:[   49] Training loss: 0.96119784, Validation loss: 0.95269005, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28244.19140625MB; mem (CPU total)=37374.015625MB
INFO:root:[   50] Training loss: 0.96100796, Validation loss: 0.95209092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28282.2890625MB; mem (CPU total)=37509.1796875MB
INFO:root:[   51] Training loss: 0.96099937, Validation loss: 0.95208738, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28320.3828125MB; mem (CPU total)=37644.0MB
INFO:root:[   52] Training loss: 0.96087930, Validation loss: 0.95319320, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28358.47265625MB; mem (CPU total)=37779.58984375MB
INFO:root:[   53] Training loss: 0.96061031, Validation loss: 0.95212092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28396.57421875MB; mem (CPU total)=37915.6640625MB
INFO:root:[   54] Training loss: 0.96068823, Validation loss: 0.95365773, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28434.66796875MB; mem (CPU total)=38050.78515625MB
INFO:root:[   55] Training loss: 0.96059237, Validation loss: 0.95256112, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28472.76171875MB; mem (CPU total)=38188.84375MB
INFO:root:[   56] Training loss: 0.96029543, Validation loss: 0.95234216, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28510.859375MB; mem (CPU total)=38331.0859375MB
INFO:root:[   57] Training loss: 0.96005437, Validation loss: 0.95266685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28548.953125MB; mem (CPU total)=46673.01953125MB
INFO:root:[   58] Training loss: 0.96009094, Validation loss: 0.95285794, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28587.046875MB; mem (CPU total)=28351.46484375MB
INFO:root:[   59] Training loss: 0.96010987, Validation loss: 0.95382220, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28625.14453125MB; mem (CPU total)=31319.20703125MB
INFO:root:[   60] Training loss: 0.95993163, Validation loss: 0.95283946, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28663.2421875MB; mem (CPU total)=31831.04296875MB
INFO:root:[   61] Training loss: 0.95973441, Validation loss: 0.95211802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28701.3359375MB; mem (CPU total)=31969.45703125MB
INFO:root:[   62] Training loss: 0.95964822, Validation loss: 0.95202764, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28739.4296875MB; mem (CPU total)=32099.203125MB
INFO:root:[   63] Training loss: 0.95949002, Validation loss: 0.95102241, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28777.52734375MB; mem (CPU total)=32233.3125MB
INFO:root:[   64] Training loss: 0.95943580, Validation loss: 0.95164737, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28815.62109375MB; mem (CPU total)=32368.18359375MB
INFO:root:[   65] Training loss: 0.95927889, Validation loss: 0.95219655, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28853.71484375MB; mem (CPU total)=32499.85546875MB
INFO:root:[   66] Training loss: 0.95914003, Validation loss: 0.95048364, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28891.8125MB; mem (CPU total)=32639.70703125MB
INFO:root:[   67] Training loss: 0.95914849, Validation loss: 0.95166171, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28929.91015625MB; mem (CPU total)=32772.0390625MB
INFO:root:[   68] Training loss: 0.95902401, Validation loss: 0.95085024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=28968.0078125MB; mem (CPU total)=32908.16796875MB
INFO:root:[   69] Training loss: 0.95889851, Validation loss: 0.95077203, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29006.1015625MB; mem (CPU total)=33044.30859375MB
INFO:root:[   70] Training loss: 0.95866572, Validation loss: 0.95158979, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29044.19921875MB; mem (CPU total)=33182.6953125MB
INFO:root:[   71] Training loss: 0.95876514, Validation loss: 0.95059144, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29082.29296875MB; mem (CPU total)=33321.33203125MB
INFO:root:[   72] Training loss: 0.95849476, Validation loss: 0.95019919, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29120.38671875MB; mem (CPU total)=33459.08984375MB
INFO:root:[   73] Training loss: 0.95836928, Validation loss: 0.95186744, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29158.484375MB; mem (CPU total)=33599.52734375MB
INFO:root:[   74] Training loss: 0.95827985, Validation loss: 0.95089219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29196.578125MB; mem (CPU total)=33741.94921875MB
INFO:root:[   75] Training loss: 0.95829170, Validation loss: 0.95082574, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29234.671875MB; mem (CPU total)=33884.171875MB
INFO:root:[   76] Training loss: 0.95828687, Validation loss: 0.95032252, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29272.765625MB; mem (CPU total)=34024.31640625MB
INFO:root:[   77] Training loss: 0.95812411, Validation loss: 0.95134845, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29310.8671875MB; mem (CPU total)=34166.67578125MB
INFO:root:[   78] Training loss: 0.95815635, Validation loss: 0.94952412, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29348.9609375MB; mem (CPU total)=34311.33203125MB
INFO:root:[   79] Training loss: 0.95798914, Validation loss: 0.95164741, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29387.0546875MB; mem (CPU total)=34457.51171875MB
INFO:root:[   80] Training loss: 0.95781830, Validation loss: 0.95119735, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29425.15234375MB; mem (CPU total)=34601.90234375MB
INFO:root:[   81] Training loss: 0.95790426, Validation loss: 0.95187858, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29463.24609375MB; mem (CPU total)=34748.04296875MB
INFO:root:[   82] Training loss: 0.95762912, Validation loss: 0.94946884, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29501.34375MB; mem (CPU total)=34897.73046875MB
INFO:root:[   83] Training loss: 0.95773040, Validation loss: 0.95048045, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29539.43359375MB; mem (CPU total)=35047.8828125MB
INFO:root:[   84] Training loss: 0.95766246, Validation loss: 0.95196433, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29577.53125MB; mem (CPU total)=35200.2578125MB
INFO:root:[   85] Training loss: 0.95769644, Validation loss: 0.94978649, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29615.62890625MB; mem (CPU total)=35354.40234375MB
INFO:root:[   86] Training loss: 0.95745000, Validation loss: 0.95029435, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29653.72265625MB; mem (CPU total)=35508.53515625MB
INFO:root:[   87] Training loss: 0.95741578, Validation loss: 0.94990183, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29691.8203125MB; mem (CPU total)=35676.6015625MB
INFO:root:[   88] Training loss: 0.95723420, Validation loss: 0.94935971, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29729.9140625MB; mem (CPU total)=35833.08984375MB
INFO:root:[   89] Training loss: 0.95737337, Validation loss: 0.94898158, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29768.0078125MB; mem (CPU total)=35992.95703125MB
INFO:root:[   90] Training loss: 0.95712859, Validation loss: 0.94933987, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29806.10546875MB; mem (CPU total)=36153.1015625MB
INFO:root:[   91] Training loss: 0.95714003, Validation loss: 0.95113141, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29844.19921875MB; mem (CPU total)=36315.73046875MB
INFO:root:[   92] Training loss: 0.95684715, Validation loss: 0.94984149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29882.296875MB; mem (CPU total)=36483.66015625MB
INFO:root:[   93] Training loss: 0.95706046, Validation loss: 0.94862750, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29920.390625MB; mem (CPU total)=36651.0703125MB
INFO:root:[   94] Training loss: 0.95691936, Validation loss: 0.95035545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29958.48828125MB; mem (CPU total)=36819.45703125MB
INFO:root:[   95] Training loss: 0.95676480, Validation loss: 0.94888081, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=29996.58203125MB; mem (CPU total)=36991.84765625MB
INFO:root:[   96] Training loss: 0.95670490, Validation loss: 0.95026293, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30034.67578125MB; mem (CPU total)=37162.23828125MB
INFO:root:[   97] Training loss: 0.95666299, Validation loss: 0.94854581, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30072.7734375MB; mem (CPU total)=37337.25390625MB
INFO:root:[   98] Training loss: 0.95642798, Validation loss: 0.94951182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30110.8671875MB; mem (CPU total)=37511.90625MB
INFO:root:[   99] Training loss: 0.95637683, Validation loss: 0.94859616, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30148.9609375MB; mem (CPU total)=37690.15234375MB
INFO:root:[  100] Training loss: 0.95656333, Validation loss: 0.94847805, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30187.05859375MB; mem (CPU total)=37868.65234375MB
INFO:root:[  101] Training loss: 0.95609873, Validation loss: 0.94988620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30225.15234375MB; mem (CPU total)=38051.2734375MB
INFO:root:[  102] Training loss: 0.95620323, Validation loss: 0.94875346, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30263.25MB; mem (CPU total)=38235.19140625MB
INFO:root:[  103] Training loss: 0.95619160, Validation loss: 0.94858142, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30301.34375MB; mem (CPU total)=38423.63671875MB
INFO:root:[  104] Training loss: 0.95610082, Validation loss: 0.94923180, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30339.44140625MB; mem (CPU total)=38617.0390625MB
INFO:root:[  105] Training loss: 0.95590126, Validation loss: 0.94881514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30377.53515625MB; mem (CPU total)=38819.0625MB
INFO:root:[  106] Training loss: 0.95582240, Validation loss: 0.94859599, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30415.62890625MB; mem (CPU total)=39019.71875MB
INFO:root:[  107] Training loss: 0.95597552, Validation loss: 0.94811321, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30453.73046875MB; mem (CPU total)=39220.34765625MB
INFO:root:[  108] Training loss: 0.95578743, Validation loss: 0.94881902, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30491.8203125MB; mem (CPU total)=39425.24609375MB
INFO:root:[  109] Training loss: 0.95565108, Validation loss: 0.94933926, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30529.9140625MB; mem (CPU total)=39631.4140625MB
INFO:root:[  110] Training loss: 0.95555687, Validation loss: 0.94807019, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30568.015625MB; mem (CPU total)=39842.20703125MB
INFO:root:[  111] Training loss: 0.95547146, Validation loss: 0.94833833, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30606.11328125MB; mem (CPU total)=40060.87109375MB
INFO:root:[  112] Training loss: 0.95546582, Validation loss: 0.94782860, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30644.20703125MB; mem (CPU total)=40192.3515625MB
INFO:root:[  113] Training loss: 0.95541269, Validation loss: 0.94763995, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30682.30078125MB; mem (CPU total)=40325.5703125MB
INFO:root:[  114] Training loss: 0.95513091, Validation loss: 0.94729552, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30720.40234375MB; mem (CPU total)=40676.953125MB
INFO:root:[  115] Training loss: 0.95526088, Validation loss: 0.94837869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30758.4921875MB; mem (CPU total)=40893.40625MB
INFO:root:[  116] Training loss: 0.95504391, Validation loss: 0.94748063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30796.58984375MB; mem (CPU total)=42515.83984375MB
INFO:root:[  117] Training loss: 0.95509675, Validation loss: 0.94866957, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30834.68359375MB; mem (CPU total)=45644.6953125MB
INFO:root:[  118] Training loss: 0.95492828, Validation loss: 0.94674035, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30872.78125MB; mem (CPU total)=44121.59765625MB
INFO:root:[  119] Training loss: 0.95500567, Validation loss: 0.94791637, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30910.875MB; mem (CPU total)=44507.16796875MB
INFO:root:[  120] Training loss: 0.95474410, Validation loss: 0.94652378, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30948.96875MB; mem (CPU total)=44704.140625MB
INFO:root:[  121] Training loss: 0.95484556, Validation loss: 0.94702685, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=30987.06640625MB; mem (CPU total)=44865.28125MB
INFO:root:[  122] Training loss: 0.95467754, Validation loss: 0.94723400, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31025.16015625MB; mem (CPU total)=45026.75MB
INFO:root:[  123] Training loss: 0.95460712, Validation loss: 0.94621197, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31063.2578125MB; mem (CPU total)=45183.53125MB
INFO:root:[  124] Training loss: 0.95455621, Validation loss: 0.94669340, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31101.3515625MB; mem (CPU total)=45418.484375MB
INFO:root:[  125] Training loss: 0.95443204, Validation loss: 0.94659745, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31139.44921875MB; mem (CPU total)=45586.76171875MB
INFO:root:[  126] Training loss: 0.95436545, Validation loss: 0.94771801, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31177.546875MB; mem (CPU total)=45964.3203125MB
INFO:root:[  127] Training loss: 0.95449174, Validation loss: 0.94696137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31215.640625MB; mem (CPU total)=46189.78515625MB
INFO:root:[  128] Training loss: 0.95442473, Validation loss: 0.94720493, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31253.73828125MB; mem (CPU total)=46371.66015625MB
INFO:root:[  129] Training loss: 0.95420029, Validation loss: 0.94562132, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31291.83203125MB; mem (CPU total)=57285.6640625MB
INFO:root:[  130] Training loss: 0.95432851, Validation loss: 0.94667849, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31329.92578125MB; mem (CPU total)=51434.65625MB
INFO:root:[  131] Training loss: 0.95419616, Validation loss: 0.94660586, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31368.0234375MB; mem (CPU total)=35045.80859375MB
INFO:root:[  132] Training loss: 0.95397643, Validation loss: 0.94603033, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31406.11328125MB; mem (CPU total)=35165.390625MB
INFO:root:[  133] Training loss: 0.95397908, Validation loss: 0.94730102, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31444.21484375MB; mem (CPU total)=31237.453125MB
INFO:root:[  134] Training loss: 0.95389939, Validation loss: 0.94677434, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31482.3046875MB; mem (CPU total)=34201.45703125MB
INFO:root:[  135] Training loss: 0.95392049, Validation loss: 0.94619511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31520.40625MB; mem (CPU total)=41225.8046875MB
INFO:root:[  136] Training loss: 0.95387344, Validation loss: 0.94829799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31558.5MB; mem (CPU total)=31363.90625MB
INFO:root:[  137] Training loss: 0.95375585, Validation loss: 0.94622784, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31596.59375MB; mem (CPU total)=31398.52734375MB
INFO:root:[  138] Training loss: 0.95367490, Validation loss: 0.94673102, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31634.69140625MB; mem (CPU total)=31435.8984375MB
INFO:root:[  139] Training loss: 0.95372309, Validation loss: 0.94537595, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31672.7890625MB; mem (CPU total)=31472.28515625MB
INFO:root:[  140] Training loss: 0.95353504, Validation loss: 0.94644263, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31710.87890625MB; mem (CPU total)=32645.23046875MB
INFO:root:[  141] Training loss: 0.95355734, Validation loss: 0.94540547, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31748.9765625MB; mem (CPU total)=31544.6015625MB
INFO:root:[  142] Training loss: 0.95346702, Validation loss: 0.94644913, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31787.0703125MB; mem (CPU total)=31581.48046875MB
INFO:root:[  143] Training loss: 0.95342282, Validation loss: 0.94608681, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31825.16796875MB; mem (CPU total)=41472.93359375MB
INFO:root:[  144] Training loss: 0.95321065, Validation loss: 0.94505388, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31863.26171875MB; mem (CPU total)=31654.9296875MB
INFO:root:[  145] Training loss: 0.95321160, Validation loss: 0.94494317, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31901.359375MB; mem (CPU total)=34624.5546875MB
INFO:root:[  146] Training loss: 0.95336691, Validation loss: 0.94522216, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31939.453125MB; mem (CPU total)=33397.87890625MB
INFO:root:[  147] Training loss: 0.95312958, Validation loss: 0.94559364, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=31977.546875MB; mem (CPU total)=31768.4296875MB
INFO:root:[  148] Training loss: 0.95310179, Validation loss: 0.94688694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32015.64453125MB; mem (CPU total)=32180.359375MB
INFO:root:[  149] Training loss: 0.95302067, Validation loss: 0.94571046, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32053.73828125MB; mem (CPU total)=53240.01171875MB
INFO:root:[  150] Training loss: 0.95296773, Validation loss: 0.94685391, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32091.83203125MB; mem (CPU total)=53397.55078125MB
INFO:root:[  151] Training loss: 0.95282391, Validation loss: 0.94587885, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32129.9296875MB; mem (CPU total)=53458.79296875MB
INFO:root:[  152] Training loss: 0.95283417, Validation loss: 0.94516705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32168.03125MB; mem (CPU total)=53512.6640625MB
INFO:root:[  153] Training loss: 0.95281360, Validation loss: 0.94521494, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32206.125MB; mem (CPU total)=53582.890625MB
INFO:root:[  154] Training loss: 0.95272027, Validation loss: 0.94415861, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32244.21875MB; mem (CPU total)=53684.22265625MB
INFO:root:[  155] Training loss: 0.95248988, Validation loss: 0.94565808, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32282.31640625MB; mem (CPU total)=53768.30859375MB
INFO:root:[  156] Training loss: 0.95264202, Validation loss: 0.94454133, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32320.41015625MB; mem (CPU total)=54009.20703125MB
INFO:root:[  157] Training loss: 0.95251055, Validation loss: 0.94600115, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32358.50390625MB; mem (CPU total)=54130.015625MB
INFO:root:[  158] Training loss: 0.95239797, Validation loss: 0.94593539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32396.6015625MB; mem (CPU total)=54209.33203125MB
INFO:root:[  159] Training loss: 0.95242213, Validation loss: 0.94477807, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32434.6953125MB; mem (CPU total)=54266.58984375MB
INFO:root:[  160] Training loss: 0.95228425, Validation loss: 0.94477181, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32472.79296875MB; mem (CPU total)=54319.69921875MB
INFO:root:[  161] Training loss: 0.95240600, Validation loss: 0.94434153, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32510.88671875MB; mem (CPU total)=54392.01953125MB
INFO:root:[  162] Training loss: 0.95241521, Validation loss: 0.94504335, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32548.984375MB; mem (CPU total)=54598.16015625MB
INFO:root:[  163] Training loss: 0.95205192, Validation loss: 0.94484641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32587.078125MB; mem (CPU total)=50596.8984375MB
INFO:root:EP 163: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=32624.91796875MB; mem (CPU total)=50638.703125MB
INFO:root:Training the model took 9356.063s.
INFO:root:Emptying the cuda cache took 0.009s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.94502
INFO:root:EnergyScoreTrain: 0.86093
INFO:root:CRPSTrain: 0.70344
INFO:root:Gaussian NLLTrain: 81879.40281
INFO:root:CoverageTrain: 0.0929
INFO:root:IntervalWidthTrain: 0.19151
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.94767
INFO:root:EnergyScoreValidation: 0.86482
INFO:root:CRPSValidation: 0.70723
INFO:root:Gaussian NLLValidation: 58979.32499
INFO:root:CoverageValidation: 0.09035
INFO:root:IntervalWidthValidation: 0.18715
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.94673
INFO:root:EnergyScoreTest: 0.86388
INFO:root:CRPSTest: 0.70662
INFO:root:Gaussian NLLTest: 40405.83908
INFO:root:CoverageTest: 0.09044
INFO:root:IntervalWidthTest: 0.18734
INFO:root:After validation: mem (CPU python)=32698.6875MB; mem (CPU total)=50718.7578125MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=32698.6875MB; mem (CPU total)=50720.7265625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=32698.7109375MB; mem (CPU total)=50720.70703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=32698.80859375MB; mem (CPU total)=50720.640625MB
INFO:root:[    1] Training loss: 1.01147706, Validation loss: 0.99449516, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32736.66796875MB; mem (CPU total)=50762.75390625MB
INFO:root:[    2] Training loss: 0.99233880, Validation loss: 0.98294703, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32774.7578125MB; mem (CPU total)=50809.9375MB
INFO:root:[    3] Training loss: 0.98705033, Validation loss: 0.97886003, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32812.85546875MB; mem (CPU total)=50850.47265625MB
INFO:root:[    4] Training loss: 0.98437811, Validation loss: 0.97719684, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32850.9375MB; mem (CPU total)=50893.47265625MB
INFO:root:[    5] Training loss: 0.98270516, Validation loss: 0.97514236, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32889.03125MB; mem (CPU total)=50934.265625MB
INFO:root:[    6] Training loss: 0.98180870, Validation loss: 0.97415774, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32927.125MB; mem (CPU total)=50976.17578125MB
INFO:root:[    7] Training loss: 0.98103841, Validation loss: 0.97507268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=32965.21875MB; mem (CPU total)=51020.4765625MB
INFO:root:[    8] Training loss: 0.98052497, Validation loss: 0.97381495, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33003.31640625MB; mem (CPU total)=51058.86328125MB
INFO:root:[    9] Training loss: 0.98024632, Validation loss: 0.97166104, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33041.41015625MB; mem (CPU total)=51101.171875MB
INFO:root:[   10] Training loss: 0.97980686, Validation loss: 0.97129495, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33079.5078125MB; mem (CPU total)=51144.49609375MB
INFO:root:[   11] Training loss: 0.97912307, Validation loss: 0.97201111, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33117.6015625MB; mem (CPU total)=51186.35546875MB
INFO:root:[   12] Training loss: 0.97905240, Validation loss: 0.97016715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33155.69921875MB; mem (CPU total)=51225.88671875MB
INFO:root:[   13] Training loss: 0.97863238, Validation loss: 0.96951830, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33193.796875MB; mem (CPU total)=51265.74609375MB
INFO:root:[   14] Training loss: 0.97824696, Validation loss: 0.97091491, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33231.890625MB; mem (CPU total)=51311.24609375MB
INFO:root:[   15] Training loss: 0.97779803, Validation loss: 0.96889948, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33269.98828125MB; mem (CPU total)=51352.2265625MB
INFO:root:[   16] Training loss: 0.97727032, Validation loss: 0.97038985, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33308.078125MB; mem (CPU total)=51391.875MB
INFO:root:[   17] Training loss: 0.97684631, Validation loss: 0.96855545, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33346.17578125MB; mem (CPU total)=51434.75MB
INFO:root:[   18] Training loss: 0.97638755, Validation loss: 0.96876789, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33384.2734375MB; mem (CPU total)=51478.7734375MB
INFO:root:[   19] Training loss: 0.97582792, Validation loss: 0.96726831, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33422.3671875MB; mem (CPU total)=51519.49609375MB
INFO:root:[   20] Training loss: 0.97549348, Validation loss: 0.96561216, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33460.4609375MB; mem (CPU total)=51559.80859375MB
INFO:root:[   21] Training loss: 0.97488411, Validation loss: 0.96672145, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33498.55859375MB; mem (CPU total)=33243.3984375MB
INFO:root:[   22] Training loss: 0.97458971, Validation loss: 0.96557106, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33536.65625MB; mem (CPU total)=33282.87109375MB
INFO:root:[   23] Training loss: 0.97388713, Validation loss: 0.96603406, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33574.74609375MB; mem (CPU total)=33321.015625MB
INFO:root:[   24] Training loss: 0.97354116, Validation loss: 0.96380934, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33612.84375MB; mem (CPU total)=33359.68359375MB
INFO:root:[   25] Training loss: 0.97317059, Validation loss: 0.96376857, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33650.94140625MB; mem (CPU total)=33398.02734375MB
INFO:root:[   26] Training loss: 0.97268831, Validation loss: 0.96295069, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33689.03515625MB; mem (CPU total)=33436.1484375MB
INFO:root:[   27] Training loss: 0.97234920, Validation loss: 0.96244802, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33727.12890625MB; mem (CPU total)=33476.56640625MB
INFO:root:[   28] Training loss: 0.97216166, Validation loss: 0.96135555, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33765.2265625MB; mem (CPU total)=33513.74609375MB
INFO:root:[   29] Training loss: 0.97180319, Validation loss: 0.96301539, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33803.3203125MB; mem (CPU total)=33551.61328125MB
INFO:root:[   30] Training loss: 0.97141753, Validation loss: 0.96074266, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33841.41796875MB; mem (CPU total)=33590.4921875MB
INFO:root:[   31] Training loss: 0.97124639, Validation loss: 0.96042435, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33879.515625MB; mem (CPU total)=33629.12890625MB
INFO:root:[   32] Training loss: 0.97090752, Validation loss: 0.96093299, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33917.609375MB; mem (CPU total)=33667.734375MB
INFO:root:[   33] Training loss: 0.97049147, Validation loss: 0.96198799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33955.703125MB; mem (CPU total)=33705.8671875MB
INFO:root:[   34] Training loss: 0.97030230, Validation loss: 0.96170818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=33993.796875MB; mem (CPU total)=33744.8828125MB
INFO:root:[   35] Training loss: 0.96997223, Validation loss: 0.95948613, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34031.89453125MB; mem (CPU total)=33783.07421875MB
INFO:root:[   36] Training loss: 0.96983563, Validation loss: 0.95833194, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34069.9921875MB; mem (CPU total)=33821.5390625MB
INFO:root:[   37] Training loss: 0.96945124, Validation loss: 0.96057219, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34108.08203125MB; mem (CPU total)=33859.91015625MB
INFO:root:[   38] Training loss: 0.96923027, Validation loss: 0.95903474, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34146.1796875MB; mem (CPU total)=33898.30078125MB
INFO:root:[   39] Training loss: 0.96907609, Validation loss: 0.95826853, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34184.27734375MB; mem (CPU total)=33936.30078125MB
INFO:root:[   40] Training loss: 0.96870042, Validation loss: 0.95779125, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34222.37109375MB; mem (CPU total)=33974.05859375MB
INFO:root:[   41] Training loss: 0.96859633, Validation loss: 0.95816998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34260.4609375MB; mem (CPU total)=34012.203125MB
INFO:root:[   42] Training loss: 0.96843159, Validation loss: 0.95973521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34298.5625MB; mem (CPU total)=34050.34765625MB
INFO:root:[   43] Training loss: 0.96839789, Validation loss: 0.95738770, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34336.65625MB; mem (CPU total)=34088.578125MB
INFO:root:[   44] Training loss: 0.96800674, Validation loss: 0.95832077, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34374.75MB; mem (CPU total)=34126.9921875MB
INFO:root:[   45] Training loss: 0.96816895, Validation loss: 0.95766998, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34412.84765625MB; mem (CPU total)=34165.13671875MB
INFO:root:[   46] Training loss: 0.96805309, Validation loss: 0.95719008, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34450.94140625MB; mem (CPU total)=34204.609375MB
INFO:root:[   47] Training loss: 0.96774342, Validation loss: 0.95719458, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34489.03515625MB; mem (CPU total)=34242.7265625MB
INFO:root:[   48] Training loss: 0.96772158, Validation loss: 0.95798874, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34527.1328125MB; mem (CPU total)=34280.84765625MB
INFO:root:[   49] Training loss: 0.96754538, Validation loss: 0.95582709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34565.23046875MB; mem (CPU total)=34318.67578125MB
INFO:root:[   50] Training loss: 0.96732185, Validation loss: 0.95644968, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34603.3203125MB; mem (CPU total)=34357.06640625MB
INFO:root:[   51] Training loss: 0.96732827, Validation loss: 0.95604739, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34641.41796875MB; mem (CPU total)=34395.39453125MB
INFO:root:[   52] Training loss: 0.96712743, Validation loss: 0.95746709, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34679.515625MB; mem (CPU total)=34433.5390625MB
INFO:root:[   53] Training loss: 0.96700581, Validation loss: 0.95681753, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34717.609375MB; mem (CPU total)=34471.68359375MB
INFO:root:[   54] Training loss: 0.96700941, Validation loss: 0.95720230, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34755.703125MB; mem (CPU total)=34509.765625MB
INFO:root:[   55] Training loss: 0.96688767, Validation loss: 0.95642485, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34793.80078125MB; mem (CPU total)=34547.91015625MB
INFO:root:[   56] Training loss: 0.96693235, Validation loss: 0.95704651, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34831.89453125MB; mem (CPU total)=34586.3359375MB
INFO:root:[   57] Training loss: 0.96649269, Validation loss: 0.95815766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34869.9921875MB; mem (CPU total)=34624.69921875MB
INFO:root:[   58] Training loss: 0.96648816, Validation loss: 0.95605268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34908.0859375MB; mem (CPU total)=34663.65625MB
INFO:root:[   59] Training loss: 0.96666132, Validation loss: 0.95738829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34946.18359375MB; mem (CPU total)=34701.26171875MB
INFO:root:[   60] Training loss: 0.96632209, Validation loss: 0.95757937, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=34984.27734375MB; mem (CPU total)=34739.921875MB
INFO:root:[   61] Training loss: 0.96635993, Validation loss: 0.95649923, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35022.37109375MB; mem (CPU total)=34778.08984375MB
INFO:root:[   62] Training loss: 0.96629500, Validation loss: 0.95558073, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35060.47265625MB; mem (CPU total)=34816.90625MB
INFO:root:[   63] Training loss: 0.96624751, Validation loss: 0.95521085, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35098.56640625MB; mem (CPU total)=34855.23046875MB
INFO:root:[   64] Training loss: 0.96612754, Validation loss: 0.95783826, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35136.65625MB; mem (CPU total)=34893.15234375MB
INFO:root:[   65] Training loss: 0.96586597, Validation loss: 0.95667766, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35174.7578125MB; mem (CPU total)=34931.3203125MB
INFO:root:[   66] Training loss: 0.96594742, Validation loss: 0.95487032, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35212.8515625MB; mem (CPU total)=34970.5234375MB
INFO:root:[   67] Training loss: 0.96603818, Validation loss: 0.95490126, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35250.9453125MB; mem (CPU total)=35008.21484375MB
INFO:root:[   68] Training loss: 0.96568862, Validation loss: 0.95632167, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35289.0390625MB; mem (CPU total)=35046.66015625MB
INFO:root:[   69] Training loss: 0.96550672, Validation loss: 0.95634455, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35327.13671875MB; mem (CPU total)=35085.0703125MB
INFO:root:[   70] Training loss: 0.96539168, Validation loss: 0.95487614, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35365.23046875MB; mem (CPU total)=35122.9921875MB
INFO:root:[   71] Training loss: 0.96541229, Validation loss: 0.95499221, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35403.32421875MB; mem (CPU total)=35161.03515625MB
INFO:root:[   72] Training loss: 0.96529444, Validation loss: 0.95442191, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35441.42578125MB; mem (CPU total)=35199.078125MB
INFO:root:[   73] Training loss: 0.96521185, Validation loss: 0.95625742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35479.515625MB; mem (CPU total)=35236.828125MB
INFO:root:[   74] Training loss: 0.96505079, Validation loss: 0.95495763, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35517.61328125MB; mem (CPU total)=35274.97265625MB
INFO:root:[   75] Training loss: 0.96500637, Validation loss: 0.95476094, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35555.70703125MB; mem (CPU total)=35314.15625MB
INFO:root:[   76] Training loss: 0.96513036, Validation loss: 0.95633358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35593.8046875MB; mem (CPU total)=35352.5703125MB
INFO:root:[   77] Training loss: 0.96505335, Validation loss: 0.95589829, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35631.8984375MB; mem (CPU total)=35390.44921875MB
INFO:root:[   78] Training loss: 0.96518272, Validation loss: 0.95465063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35669.99609375MB; mem (CPU total)=35428.81640625MB
INFO:root:[   79] Training loss: 0.96482269, Validation loss: 0.95636282, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35708.09375MB; mem (CPU total)=35466.90625MB
INFO:root:[   80] Training loss: 0.96474071, Validation loss: 0.95664088, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35746.1875MB; mem (CPU total)=35505.359375MB
INFO:root:[   81] Training loss: 0.96471891, Validation loss: 0.95660110, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35784.28125MB; mem (CPU total)=35543.2578125MB
INFO:root:EP 81: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=35822.37890625MB; mem (CPU total)=35581.15625MB
INFO:root:Training the model took 5047.179s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.95572
INFO:root:EnergyScoreTrain: 0.87672
INFO:root:CRPSTrain: 0.72645
INFO:root:Gaussian NLLTrain: 114062.44641
INFO:root:CoverageTrain: 0.07705
INFO:root:IntervalWidthTrain: 0.15784
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.95793
INFO:root:EnergyScoreValidation: 0.87948
INFO:root:CRPSValidation: 0.7286
INFO:root:Gaussian NLLValidation: 88285.5351
INFO:root:CoverageValidation: 0.07591
INFO:root:IntervalWidthValidation: 0.15714
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.95684
INFO:root:EnergyScoreTest: 0.87634
INFO:root:CRPSTest: 0.72671
INFO:root:Gaussian NLLTest: 67810.66686
INFO:root:CoverageTest: 0.07816
INFO:root:IntervalWidthTest: 0.1613
INFO:root:After validation: mem (CPU python)=35895.85546875MB; mem (CPU total)=35654.8046875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.15, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=35895.85546875MB; mem (CPU total)=35655.5703125MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=35895.91015625MB; mem (CPU total)=35655.5703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=35895.91015625MB; mem (CPU total)=35655.5703125MB
INFO:root:[    1] Training loss: 1.01280892, Validation loss: 0.99561047, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35933.921875MB; mem (CPU total)=35694.078125MB
INFO:root:[    2] Training loss: 0.99488682, Validation loss: 0.98620715, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=35972.0MB; mem (CPU total)=35733.0MB
INFO:root:[    3] Training loss: 0.98998564, Validation loss: 0.98254775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36010.09765625MB; mem (CPU total)=35771.29296875MB
INFO:root:[    4] Training loss: 0.98788137, Validation loss: 0.98028014, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36048.19140625MB; mem (CPU total)=35809.66015625MB
INFO:root:[    5] Training loss: 0.98621706, Validation loss: 0.97793759, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36086.28515625MB; mem (CPU total)=35847.9453125MB
INFO:root:[    6] Training loss: 0.98539035, Validation loss: 0.97696393, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36124.3828125MB; mem (CPU total)=35887.2890625MB
INFO:root:[    7] Training loss: 0.98465973, Validation loss: 0.97795727, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36162.48046875MB; mem (CPU total)=35925.6796875MB
INFO:root:[    8] Training loss: 0.98431884, Validation loss: 0.97620655, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36200.578125MB; mem (CPU total)=35963.8203125MB
INFO:root:[    9] Training loss: 0.98388291, Validation loss: 0.97475758, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36238.671875MB; mem (CPU total)=36002.515625MB
INFO:root:[   10] Training loss: 0.98353204, Validation loss: 0.97595290, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36276.765625MB; mem (CPU total)=36040.16796875MB
INFO:root:[   11] Training loss: 0.98328101, Validation loss: 0.97529785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36314.859375MB; mem (CPU total)=36078.55859375MB
INFO:root:[   12] Training loss: 0.98311072, Validation loss: 0.97452010, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36352.95703125MB; mem (CPU total)=36116.703125MB
INFO:root:[   13] Training loss: 0.98280272, Validation loss: 0.97562280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36391.0546875MB; mem (CPU total)=36154.56640625MB
INFO:root:[   14] Training loss: 0.98239752, Validation loss: 0.97387860, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36429.1484375MB; mem (CPU total)=36192.953125MB
INFO:root:[   15] Training loss: 0.98184996, Validation loss: 0.97232294, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36467.2421875MB; mem (CPU total)=36230.671875MB
INFO:root:[   16] Training loss: 0.98137157, Validation loss: 0.97337074, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36505.3359375MB; mem (CPU total)=36268.78515625MB
INFO:root:[   17] Training loss: 0.98091587, Validation loss: 0.97257825, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36543.43359375MB; mem (CPU total)=36306.6796875MB
INFO:root:[   18] Training loss: 0.98081008, Validation loss: 0.97120229, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36581.53125MB; mem (CPU total)=36344.5859375MB
INFO:root:[   19] Training loss: 0.98029919, Validation loss: 0.96984818, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36619.625MB; mem (CPU total)=36383.5078125MB
INFO:root:[   20] Training loss: 0.97972088, Validation loss: 0.96922835, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36657.72265625MB; mem (CPU total)=36422.2109375MB
INFO:root:[   21] Training loss: 0.97925133, Validation loss: 0.97039733, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36695.8125MB; mem (CPU total)=36460.3828125MB
INFO:root:[   22] Training loss: 0.97899111, Validation loss: 0.96938022, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36733.91015625MB; mem (CPU total)=36498.52734375MB
INFO:root:[   23] Training loss: 0.97866895, Validation loss: 0.96960838, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36772.00390625MB; mem (CPU total)=36536.66796875MB
INFO:root:[   24] Training loss: 0.97814579, Validation loss: 0.96847137, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36810.10546875MB; mem (CPU total)=36575.109375MB
INFO:root:[   25] Training loss: 0.97775192, Validation loss: 0.96823024, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36848.19921875MB; mem (CPU total)=36613.5390625MB
INFO:root:[   26] Training loss: 0.97732565, Validation loss: 0.96690777, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36886.29296875MB; mem (CPU total)=36651.421875MB
INFO:root:[   27] Training loss: 0.97726485, Validation loss: 0.96504578, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36924.390625MB; mem (CPU total)=36689.90234375MB
INFO:root:[   28] Training loss: 0.97688477, Validation loss: 0.96640134, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=36962.48046875MB; mem (CPU total)=36728.171875MB
INFO:root:[   29] Training loss: 0.97669459, Validation loss: 0.96601995, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37000.578125MB; mem (CPU total)=36766.5546875MB
INFO:root:[   30] Training loss: 0.97621849, Validation loss: 0.96576974, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37038.67578125MB; mem (CPU total)=36804.75MB
INFO:root:[   31] Training loss: 0.97631661, Validation loss: 0.96553541, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37076.76953125MB; mem (CPU total)=36842.5859375MB
INFO:root:[   32] Training loss: 0.97598257, Validation loss: 0.96703847, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37114.86328125MB; mem (CPU total)=36880.90625MB
INFO:root:[   33] Training loss: 0.97566853, Validation loss: 0.96766133, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37152.95703125MB; mem (CPU total)=36918.58203125MB
INFO:root:[   34] Training loss: 0.97537933, Validation loss: 0.96477640, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37191.05859375MB; mem (CPU total)=36957.2421875MB
INFO:root:[   35] Training loss: 0.97532514, Validation loss: 0.96299521, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37229.15234375MB; mem (CPU total)=36995.25MB
INFO:root:[   36] Training loss: 0.97508150, Validation loss: 0.96602420, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37267.24609375MB; mem (CPU total)=37033.6640625MB
INFO:root:[   37] Training loss: 0.97492796, Validation loss: 0.96858930, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37305.34375MB; mem (CPU total)=37071.8125MB
INFO:root:[   38] Training loss: 0.97485464, Validation loss: 0.96464229, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37343.4375MB; mem (CPU total)=37110.48828125MB
INFO:root:[   39] Training loss: 0.97459836, Validation loss: 0.96360031, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37381.53125MB; mem (CPU total)=37148.87109375MB
INFO:root:[   40] Training loss: 0.97433366, Validation loss: 0.96291526, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37419.62890625MB; mem (CPU total)=37187.59375MB
INFO:root:[   41] Training loss: 0.97431744, Validation loss: 0.96419316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37457.7265625MB; mem (CPU total)=37225.8125MB
INFO:root:[   42] Training loss: 0.97415725, Validation loss: 0.96539398, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37495.8203125MB; mem (CPU total)=37263.48046875MB
INFO:root:[   43] Training loss: 0.97397513, Validation loss: 0.96367267, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37533.9140625MB; mem (CPU total)=37301.42578125MB
INFO:root:[   44] Training loss: 0.97390744, Validation loss: 0.96262982, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37572.01171875MB; mem (CPU total)=37340.03515625MB
INFO:root:[   45] Training loss: 0.97396952, Validation loss: 0.96689010, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37610.10546875MB; mem (CPU total)=37378.22265625MB
INFO:root:[   46] Training loss: 0.97371072, Validation loss: 0.96428035, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37648.19921875MB; mem (CPU total)=37416.6328125MB
INFO:root:[   47] Training loss: 0.97354855, Validation loss: 0.96066590, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37686.30078125MB; mem (CPU total)=37455.0234375MB
INFO:root:[   48] Training loss: 0.97351550, Validation loss: 0.96487641, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37724.39453125MB; mem (CPU total)=37493.453125MB
INFO:root:[   49] Training loss: 0.97323034, Validation loss: 0.96042563, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37762.48828125MB; mem (CPU total)=37531.67578125MB
INFO:root:[   50] Training loss: 0.97315070, Validation loss: 0.96108280, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37800.58203125MB; mem (CPU total)=37570.046875MB
INFO:root:[   51] Training loss: 0.97294898, Validation loss: 0.96323514, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37838.6796875MB; mem (CPU total)=37608.19140625MB
INFO:root:[   52] Training loss: 0.97286928, Validation loss: 0.96261973, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37876.7734375MB; mem (CPU total)=37645.83984375MB
INFO:root:[   53] Training loss: 0.97267041, Validation loss: 0.96287322, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37914.8671875MB; mem (CPU total)=37683.97265625MB
INFO:root:[   54] Training loss: 0.97280057, Validation loss: 0.96274616, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37952.96484375MB; mem (CPU total)=37722.2578125MB
INFO:root:[   55] Training loss: 0.97254683, Validation loss: 0.96145231, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=37991.05859375MB; mem (CPU total)=37760.40234375MB
INFO:root:[   56] Training loss: 0.97230578, Validation loss: 0.96093560, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38029.15234375MB; mem (CPU total)=37798.30078125MB
INFO:root:[   57] Training loss: 0.97220219, Validation loss: 0.96419506, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38067.25MB; mem (CPU total)=37836.4609375MB
INFO:root:[   58] Training loss: 0.97203292, Validation loss: 0.96164482, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38105.34765625MB; mem (CPU total)=37874.8515625MB
INFO:root:[   59] Training loss: 0.97201698, Validation loss: 0.96464980, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38143.44140625MB; mem (CPU total)=37912.99609375MB
INFO:root:[   60] Training loss: 0.97191468, Validation loss: 0.96431932, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38181.53515625MB; mem (CPU total)=37951.375MB
INFO:root:[   61] Training loss: 0.97175612, Validation loss: 0.96477567, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38219.6328125MB; mem (CPU total)=37989.546875MB
INFO:root:[   62] Training loss: 0.97152198, Validation loss: 0.96017316, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38257.73046875MB; mem (CPU total)=38027.66015625MB
INFO:root:[   63] Training loss: 0.97159417, Validation loss: 0.96253438, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38295.8203125MB; mem (CPU total)=38065.55859375MB
INFO:root:[   64] Training loss: 0.97153711, Validation loss: 0.96332721, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38333.91796875MB; mem (CPU total)=38103.96875MB
INFO:root:[   65] Training loss: 0.97138669, Validation loss: 0.96230562, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38372.015625MB; mem (CPU total)=38142.11328125MB
INFO:root:[   66] Training loss: 0.97114779, Validation loss: 0.95951696, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38410.109375MB; mem (CPU total)=38180.56640625MB
INFO:root:[   67] Training loss: 0.97142244, Validation loss: 0.95929133, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38448.203125MB; mem (CPU total)=38218.98828125MB
INFO:root:[   68] Training loss: 0.97104038, Validation loss: 0.95974020, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38486.30078125MB; mem (CPU total)=38257.37890625MB
INFO:root:[   69] Training loss: 0.97104098, Validation loss: 0.96158405, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38524.39453125MB; mem (CPU total)=38295.49609375MB
INFO:root:[   70] Training loss: 0.97089251, Validation loss: 0.96035079, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38562.48828125MB; mem (CPU total)=38333.3984375MB
INFO:root:[   71] Training loss: 0.97068222, Validation loss: 0.96042241, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38600.58984375MB; mem (CPU total)=38371.55859375MB
INFO:root:[   72] Training loss: 0.97057338, Validation loss: 0.96020232, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38638.68359375MB; mem (CPU total)=38409.66796875MB
INFO:root:[   73] Training loss: 0.97042206, Validation loss: 0.96086437, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38676.78125MB; mem (CPU total)=38447.8359375MB
INFO:root:[   74] Training loss: 0.97047477, Validation loss: 0.95924408, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38714.875MB; mem (CPU total)=38486.49609375MB
INFO:root:[   75] Training loss: 0.97022972, Validation loss: 0.95990136, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38752.97265625MB; mem (CPU total)=38525.28125MB
INFO:root:[   76] Training loss: 0.97028442, Validation loss: 0.96270747, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38791.06640625MB; mem (CPU total)=38563.4453125MB
INFO:root:[   77] Training loss: 0.97023377, Validation loss: 0.96155718, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38829.16015625MB; mem (CPU total)=38601.59375MB
INFO:root:[   78] Training loss: 0.97023676, Validation loss: 0.96166634, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38867.2578125MB; mem (CPU total)=38639.7421875MB
INFO:root:[   79] Training loss: 0.97009701, Validation loss: 0.96934182, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38905.3515625MB; mem (CPU total)=38677.34765625MB
INFO:root:[   80] Training loss: 0.97015474, Validation loss: 0.96585211, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38943.4453125MB; mem (CPU total)=38715.2734375MB
INFO:root:[   81] Training loss: 0.96985796, Validation loss: 0.96181700, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=38981.546875MB; mem (CPU total)=38753.44140625MB
INFO:root:[   82] Training loss: 0.96965691, Validation loss: 0.96087309, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39019.640625MB; mem (CPU total)=38791.60546875MB
INFO:root:[   83] Training loss: 0.96968448, Validation loss: 0.95876589, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39057.734375MB; mem (CPU total)=38829.609375MB
INFO:root:[   84] Training loss: 0.96962373, Validation loss: 0.96680276, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39095.828125MB; mem (CPU total)=38868.04296875MB
INFO:root:[   85] Training loss: 0.96965874, Validation loss: 0.95868105, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39133.92578125MB; mem (CPU total)=38906.078125MB
INFO:root:[   86] Training loss: 0.96944564, Validation loss: 0.96088319, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39172.01953125MB; mem (CPU total)=38944.2421875MB
INFO:root:[   87] Training loss: 0.96939368, Validation loss: 0.96305520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39210.11328125MB; mem (CPU total)=38982.6484375MB
INFO:root:[   88] Training loss: 0.96942874, Validation loss: 0.96242336, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39248.2109375MB; mem (CPU total)=39020.328125MB
INFO:root:[   89] Training loss: 0.96930736, Validation loss: 0.95909246, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39286.30859375MB; mem (CPU total)=39058.28125MB
INFO:root:[   90] Training loss: 0.96915714, Validation loss: 0.96001713, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39324.40234375MB; mem (CPU total)=39096.6328125MB
INFO:root:[   91] Training loss: 0.96917676, Validation loss: 0.96202409, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39362.49609375MB; mem (CPU total)=39134.8046875MB
INFO:root:[   92] Training loss: 0.96921433, Validation loss: 0.96375450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39400.59375MB; mem (CPU total)=39172.97265625MB
INFO:root:[   93] Training loss: 0.96906442, Validation loss: 0.96037585, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39438.6875MB; mem (CPU total)=39211.67578125MB
INFO:root:[   94] Training loss: 0.96900154, Validation loss: 0.96574816, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39476.78125MB; mem (CPU total)=39250.11328125MB
INFO:root:EP 94: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=39514.87890625MB; mem (CPU total)=39287.99609375MB
INFO:root:Training the model took 6073.675s.
INFO:root:Emptying the cuda cache took 0.009s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.95823
INFO:root:EnergyScoreTrain: 0.89525
INFO:root:CRPSTrain: 0.74532
INFO:root:Gaussian NLLTrain: 229652.76259
INFO:root:CoverageTrain: 0.05357
INFO:root:IntervalWidthTrain: 0.10512
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.95982
INFO:root:EnergyScoreValidation: 0.89731
INFO:root:CRPSValidation: 0.74702
INFO:root:Gaussian NLLValidation: 382951.40072
INFO:root:CoverageValidation: 0.05309
INFO:root:IntervalWidthValidation: 0.10484
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.95988
INFO:root:EnergyScoreTest: 0.89859
INFO:root:CRPSTest: 0.74863
INFO:root:Gaussian NLLTest: 88776.96464
INFO:root:CoverageTest: 0.05071
INFO:root:IntervalWidthTest: 0.10043
INFO:root:After validation: mem (CPU python)=39588.875MB; mem (CPU total)=39362.40625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=39588.875MB; mem (CPU total)=39362.3984375MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=39589.44140625MB; mem (CPU total)=39363.3828125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=39589.65625MB; mem (CPU total)=39363.37109375MB
INFO:root:[    1] Training loss: 1.01422864, Validation loss: 0.99826659, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39627.6640625MB; mem (CPU total)=39401.44921875MB
INFO:root:[    2] Training loss: 0.99703990, Validation loss: 0.98862026, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39665.7578125MB; mem (CPU total)=39438.59765625MB
INFO:root:[    3] Training loss: 0.99217178, Validation loss: 0.98452070, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39703.859375MB; mem (CPU total)=39476.69140625MB
INFO:root:[    4] Training loss: 0.99026812, Validation loss: 0.98183349, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39741.95703125MB; mem (CPU total)=39515.19921875MB
INFO:root:[    5] Training loss: 0.98875278, Validation loss: 0.98092742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39780.05078125MB; mem (CPU total)=39553.5078125MB
INFO:root:[    6] Training loss: 0.98804946, Validation loss: 0.97948555, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39818.14453125MB; mem (CPU total)=39591.16796875MB
INFO:root:[    7] Training loss: 0.98742673, Validation loss: 0.97940092, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39856.2421875MB; mem (CPU total)=39629.5703125MB
INFO:root:[    8] Training loss: 0.98697843, Validation loss: 0.97976450, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39894.33203125MB; mem (CPU total)=39667.69921875MB
INFO:root:[    9] Training loss: 0.98649273, Validation loss: 0.97694552, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39932.4296875MB; mem (CPU total)=39705.4453125MB
INFO:root:[   10] Training loss: 0.98640351, Validation loss: 0.97780704, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=39970.52734375MB; mem (CPU total)=39743.8046875MB
INFO:root:[   11] Training loss: 0.98591609, Validation loss: 0.97812403, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40008.62109375MB; mem (CPU total)=39781.703125MB
INFO:root:[   12] Training loss: 0.98582215, Validation loss: 0.97729484, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40046.71484375MB; mem (CPU total)=39819.84765625MB
INFO:root:[   13] Training loss: 0.98553100, Validation loss: 0.97650238, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40084.81640625MB; mem (CPU total)=39858.25390625MB
INFO:root:[   14] Training loss: 0.98524204, Validation loss: 0.97670705, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40122.91015625MB; mem (CPU total)=39896.03515625MB
INFO:root:[   15] Training loss: 0.98479602, Validation loss: 0.97552298, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40161.0078125MB; mem (CPU total)=39934.3359375MB
INFO:root:[   16] Training loss: 0.98440759, Validation loss: 0.97651520, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40199.1015625MB; mem (CPU total)=39972.74609375MB
INFO:root:[   17] Training loss: 0.98413887, Validation loss: 0.97485694, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40237.19921875MB; mem (CPU total)=40010.73046875MB
INFO:root:[   18] Training loss: 0.98402145, Validation loss: 0.97472962, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40275.29296875MB; mem (CPU total)=40049.22265625MB
INFO:root:[   19] Training loss: 0.98370905, Validation loss: 0.97429678, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40313.38671875MB; mem (CPU total)=40087.84375MB
INFO:root:[   20] Training loss: 0.98328764, Validation loss: 0.97355629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40351.48828125MB; mem (CPU total)=40126.19921875MB
INFO:root:[   21] Training loss: 0.98299135, Validation loss: 0.97379817, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40389.57421875MB; mem (CPU total)=40164.6015625MB
INFO:root:[   22] Training loss: 0.98286622, Validation loss: 0.97425632, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40427.671875MB; mem (CPU total)=40203.1953125MB
INFO:root:[   23] Training loss: 0.98250469, Validation loss: 0.97359580, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40465.76953125MB; mem (CPU total)=40242.11328125MB
INFO:root:[   24] Training loss: 0.98192295, Validation loss: 0.97220253, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40503.8671875MB; mem (CPU total)=40280.53125MB
INFO:root:[   25] Training loss: 0.98157586, Validation loss: 0.97235294, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40541.9609375MB; mem (CPU total)=40318.484375MB
INFO:root:[   26] Training loss: 0.98123183, Validation loss: 0.96930603, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40580.05859375MB; mem (CPU total)=40356.4296875MB
INFO:root:[   27] Training loss: 0.98109850, Validation loss: 0.96958785, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40618.15234375MB; mem (CPU total)=40393.859375MB
INFO:root:[   28] Training loss: 0.98077928, Validation loss: 0.97220499, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40656.24609375MB; mem (CPU total)=40432.27734375MB
INFO:root:[   29] Training loss: 0.98071623, Validation loss: 0.97093043, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40694.33984375MB; mem (CPU total)=40470.4453125MB
INFO:root:[   30] Training loss: 0.98030715, Validation loss: 0.97104224, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40732.4375MB; mem (CPU total)=40508.6171875MB
INFO:root:[   31] Training loss: 0.98026051, Validation loss: 0.97194298, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40770.53515625MB; mem (CPU total)=40546.88671875MB
INFO:root:[   32] Training loss: 0.97995785, Validation loss: 0.97318079, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40808.62890625MB; mem (CPU total)=40585.54296875MB
INFO:root:[   33] Training loss: 0.97971580, Validation loss: 0.97255600, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40846.72265625MB; mem (CPU total)=40623.70703125MB
INFO:root:[   34] Training loss: 0.97942671, Validation loss: 0.97137405, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40884.8203125MB; mem (CPU total)=40661.8671875MB
INFO:root:[   35] Training loss: 0.97925348, Validation loss: 0.96988594, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40922.9140625MB; mem (CPU total)=40700.26953125MB
INFO:root:[   36] Training loss: 0.97910490, Validation loss: 0.97222582, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40961.0078125MB; mem (CPU total)=40738.19140625MB
INFO:root:[   37] Training loss: 0.97920614, Validation loss: 0.97508048, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=40999.10546875MB; mem (CPU total)=40775.8671875MB
INFO:root:[   38] Training loss: 0.97900708, Validation loss: 0.97178388, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41037.19921875MB; mem (CPU total)=40814.28125MB
INFO:root:[   39] Training loss: 0.97870840, Validation loss: 0.97143961, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41075.296875MB; mem (CPU total)=40852.6640625MB
INFO:root:[   40] Training loss: 0.97860608, Validation loss: 0.97506758, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41113.390625MB; mem (CPU total)=40890.89453125MB
INFO:root:[   41] Training loss: 0.97864542, Validation loss: 0.97318429, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41151.48828125MB; mem (CPU total)=40929.671875MB
INFO:root:[   42] Training loss: 0.97844641, Validation loss: 0.97174317, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41189.58203125MB; mem (CPU total)=40968.0546875MB
INFO:root:[   43] Training loss: 0.97832043, Validation loss: 0.97268742, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41227.67578125MB; mem (CPU total)=41005.94140625MB
INFO:root:[   44] Training loss: 0.97817509, Validation loss: 0.97030107, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41265.7734375MB; mem (CPU total)=41043.8359375MB
INFO:root:[   45] Training loss: 0.97838218, Validation loss: 0.97978687, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41303.8671875MB; mem (CPU total)=41082.2265625MB
INFO:root:[   46] Training loss: 0.97800639, Validation loss: 0.97482524, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41341.96484375MB; mem (CPU total)=41120.37109375MB
INFO:root:[   47] Training loss: 0.97797683, Validation loss: 0.96897869, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41380.0625MB; mem (CPU total)=41158.57421875MB
INFO:root:[   48] Training loss: 0.97803759, Validation loss: 0.97149443, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41418.15625MB; mem (CPU total)=41197.20703125MB
INFO:root:[   49] Training loss: 0.97798026, Validation loss: 0.96876622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41456.25MB; mem (CPU total)=41235.1953125MB
INFO:root:[   50] Training loss: 0.97788011, Validation loss: 0.97272382, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41494.34375MB; mem (CPU total)=41273.37890625MB
INFO:root:[   51] Training loss: 0.97759534, Validation loss: 0.97368799, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41532.44140625MB; mem (CPU total)=41311.51953125MB
INFO:root:[   52] Training loss: 0.97742172, Validation loss: 0.97103938, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41570.5390625MB; mem (CPU total)=41349.90234375MB
INFO:root:[   53] Training loss: 0.97733043, Validation loss: 0.97470149, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41608.6171875MB; mem (CPU total)=41388.03515625MB
INFO:root:[   54] Training loss: 0.97742962, Validation loss: 0.97126879, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41646.71484375MB; mem (CPU total)=41426.046875MB
INFO:root:[   55] Training loss: 0.97721953, Validation loss: 0.97188297, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41684.80859375MB; mem (CPU total)=41464.19140625MB
INFO:root:[   56] Training loss: 0.97694236, Validation loss: 0.96848702, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41722.90234375MB; mem (CPU total)=41502.66015625MB
INFO:root:[   57] Training loss: 0.97697972, Validation loss: 0.97346150, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41760.99609375MB; mem (CPU total)=41540.8046875MB
INFO:root:[   58] Training loss: 0.97682267, Validation loss: 0.97085754, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41799.09375MB; mem (CPU total)=41578.98046875MB
INFO:root:[   59] Training loss: 0.97688368, Validation loss: 0.98396050, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41837.19140625MB; mem (CPU total)=41617.3671875MB
INFO:root:[   60] Training loss: 0.97656298, Validation loss: 0.97642373, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41875.28125MB; mem (CPU total)=41655.29296875MB
INFO:root:[   61] Training loss: 0.97664869, Validation loss: 0.97430188, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41913.37890625MB; mem (CPU total)=41693.09375MB
INFO:root:[   62] Training loss: 0.97643689, Validation loss: 0.96963654, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41951.4765625MB; mem (CPU total)=41731.2578125MB
INFO:root:[   63] Training loss: 0.97642389, Validation loss: 0.97282622, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=41989.5703125MB; mem (CPU total)=41769.4296875MB
INFO:root:[   64] Training loss: 0.97627580, Validation loss: 0.97272943, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42027.66796875MB; mem (CPU total)=41807.5234375MB
INFO:root:[   65] Training loss: 0.97606389, Validation loss: 0.97064821, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42065.76171875MB; mem (CPU total)=41845.859375MB
INFO:root:EP 65: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=42103.6875MB; mem (CPU total)=41883.7890625MB
INFO:root:Training the model took 4419.578s.
INFO:root:Emptying the cuda cache took 0.009s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.96871
INFO:root:EnergyScoreTrain: 0.90492
INFO:root:CRPSTrain: 0.75683
INFO:root:Gaussian NLLTrain: 180906.59335
INFO:root:CoverageTrain: 0.0509
INFO:root:IntervalWidthTrain: 0.10341
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.97012
INFO:root:EnergyScoreValidation: 0.90794
INFO:root:CRPSValidation: 0.75941
INFO:root:Gaussian NLLValidation: 363263.97582
INFO:root:CoverageValidation: 0.04899
INFO:root:IntervalWidthValidation: 0.09989
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.96944
INFO:root:EnergyScoreTest: 0.90768
INFO:root:CRPSTest: 0.75874
INFO:root:Gaussian NLLTest: 107729.49216
INFO:root:CoverageTest: 0.04917
INFO:root:IntervalWidthTest: 0.09975
INFO:root:After validation: mem (CPU python)=42177.28515625MB; mem (CPU total)=41960.72265625MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.3, 'fourier_dropout': None, 'hidden_channels': 16, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75], [1.0, 0.667], [1.0, 0.5], [1.0, 1.0], [1.0, 2.0], [1.0, 1.5], [1.0, 1.334]], 'uno_n_modes': [[4, 20], [4, 14], [4, 6], [7, 6], [7, 6], [10, 14], [10, 20]]}
INFO:root:After creating the dataloaders: mem (CPU python)=42177.28515625MB; mem (CPU total)=41960.72265625MB
INFO:root:NumberParameters: 1687601
INFO:root:GPU memory allocated: 169869312
INFO:root:After setting up the model: mem (CPU python)=42177.76171875MB; mem (CPU total)=41961.21484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=42177.76171875MB; mem (CPU total)=41961.20703125MB
INFO:root:[    1] Training loss: 1.01718852, Validation loss: 1.00206863, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42215.78125MB; mem (CPU total)=41999.359375MB
INFO:root:[    2] Training loss: 1.00148107, Validation loss: 0.99163697, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42253.87890625MB; mem (CPU total)=42036.515625MB
INFO:root:[    3] Training loss: 0.99734953, Validation loss: 0.98917184, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42291.96875MB; mem (CPU total)=42075.828125MB
INFO:root:[    4] Training loss: 0.99580084, Validation loss: 0.98914738, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42330.06640625MB; mem (CPU total)=42114.2421875MB
INFO:root:[    5] Training loss: 0.99504755, Validation loss: 0.98695967, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42368.16796875MB; mem (CPU total)=42152.37890625MB
INFO:root:[    6] Training loss: 0.99448282, Validation loss: 0.98673629, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42406.26171875MB; mem (CPU total)=42190.5234375MB
INFO:root:[    7] Training loss: 0.99381122, Validation loss: 0.98660464, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42444.35546875MB; mem (CPU total)=42228.34765625MB
INFO:root:[    8] Training loss: 0.99336319, Validation loss: 0.98653551, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42482.453125MB; mem (CPU total)=42266.31640625MB
INFO:root:[    9] Training loss: 0.99279185, Validation loss: 0.98454942, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42520.546875MB; mem (CPU total)=42304.4765625MB
INFO:root:[   10] Training loss: 0.99241883, Validation loss: 0.98335120, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42558.640625MB; mem (CPU total)=42342.8828125MB
INFO:root:[   11] Training loss: 0.99203213, Validation loss: 0.98508690, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42596.734375MB; mem (CPU total)=42381.2734375MB
INFO:root:[   12] Training loss: 0.99174771, Validation loss: 0.98380155, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42634.83203125MB; mem (CPU total)=42419.35546875MB
INFO:root:[   13] Training loss: 0.99115528, Validation loss: 0.98295063, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42672.9296875MB; mem (CPU total)=42457.09765625MB
INFO:root:[   14] Training loss: 0.99085711, Validation loss: 0.98172375, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42711.0234375MB; mem (CPU total)=42495.37890625MB
INFO:root:[   15] Training loss: 0.99033126, Validation loss: 0.98123620, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42749.12109375MB; mem (CPU total)=42534.25MB
INFO:root:[   16] Training loss: 0.98994713, Validation loss: 0.98503884, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42787.21484375MB; mem (CPU total)=42572.4765625MB
INFO:root:[   17] Training loss: 0.98958908, Validation loss: 0.98093268, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42825.30859375MB; mem (CPU total)=42610.546875MB
INFO:root:[   18] Training loss: 0.98945026, Validation loss: 0.98442135, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42863.40625MB; mem (CPU total)=42623.71875MB
INFO:root:[   19] Training loss: 0.98908628, Validation loss: 0.98233096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42901.5MB; mem (CPU total)=42661.61328125MB
INFO:root:[   20] Training loss: 0.98876414, Validation loss: 0.98159303, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42939.59375MB; mem (CPU total)=42699.7734375MB
INFO:root:[   21] Training loss: 0.98854207, Validation loss: 0.98081638, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=42977.69140625MB; mem (CPU total)=42738.34375MB
INFO:root:[   22] Training loss: 0.98851572, Validation loss: 0.98254358, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43015.78515625MB; mem (CPU total)=42776.30078125MB
INFO:root:[   23] Training loss: 0.98809091, Validation loss: 0.98328967, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43053.87890625MB; mem (CPU total)=42814.5MB
INFO:root:[   24] Training loss: 0.98787955, Validation loss: 0.98111284, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43091.9765625MB; mem (CPU total)=42852.671875MB
INFO:root:[   25] Training loss: 0.98768092, Validation loss: 0.98603707, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43130.07421875MB; mem (CPU total)=42894.5390625MB
INFO:root:[   26] Training loss: 0.98720673, Validation loss: 0.98482096, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43168.16796875MB; mem (CPU total)=42929.9921875MB
INFO:root:[   27] Training loss: 0.98719207, Validation loss: 0.98699193, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43206.26171875MB; mem (CPU total)=42967.78125MB
INFO:root:[   28] Training loss: 0.98690528, Validation loss: 0.98776455, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43244.35546875MB; mem (CPU total)=43006.296875MB
INFO:root:[   29] Training loss: 0.98677759, Validation loss: 0.98859708, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43282.453125MB; mem (CPU total)=43044.5390625MB
INFO:root:[   30] Training loss: 0.98645136, Validation loss: 0.98608366, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43320.55078125MB; mem (CPU total)=43082.6328125MB
INFO:root:[   31] Training loss: 0.98646206, Validation loss: 0.98585980, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43358.64453125MB; mem (CPU total)=43120.74609375MB
INFO:root:[   32] Training loss: 0.98626244, Validation loss: 0.99057179, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43396.7421875MB; mem (CPU total)=43159.3125MB
INFO:root:[   33] Training loss: 0.98614479, Validation loss: 0.99477633, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43434.8359375MB; mem (CPU total)=43197.02734375MB
INFO:root:[   34] Training loss: 0.98589635, Validation loss: 0.98245534, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43472.9296875MB; mem (CPU total)=43234.5546875MB
INFO:root:[   35] Training loss: 0.98595824, Validation loss: 0.98835683, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43511.02734375MB; mem (CPU total)=43272.28125MB
INFO:root:[   36] Training loss: 0.98554837, Validation loss: 0.99277405, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43549.125MB; mem (CPU total)=43310.453125MB
INFO:root:[   37] Training loss: 0.98553867, Validation loss: 0.98987470, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43587.21875MB; mem (CPU total)=43348.62109375MB
INFO:root:[   38] Training loss: 0.98540685, Validation loss: 0.99873896, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43625.3125MB; mem (CPU total)=43388.8359375MB
INFO:root:[   39] Training loss: 0.98506950, Validation loss: 1.00490595, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43663.41015625MB; mem (CPU total)=43425.8203125MB
INFO:root:[   40] Training loss: 0.98515926, Validation loss: 0.99209657, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43701.50390625MB; mem (CPU total)=43463.0703125MB
INFO:root:[   41] Training loss: 0.98501792, Validation loss: 1.00349775, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43739.59765625MB; mem (CPU total)=43501.2421875MB
INFO:root:[   42] Training loss: 0.98479972, Validation loss: 1.00253511, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43777.6953125MB; mem (CPU total)=43544.703125MB
INFO:root:[   43] Training loss: 0.98469914, Validation loss: 1.00300501, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43815.7890625MB; mem (CPU total)=43579.84375MB
INFO:root:[   44] Training loss: 0.98463761, Validation loss: 1.00305670, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43853.88671875MB; mem (CPU total)=43616.59375MB
INFO:root:[   45] Training loss: 0.98458038, Validation loss: 1.00925169, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43891.98046875MB; mem (CPU total)=43656.12890625MB
INFO:root:[   46] Training loss: 0.98402741, Validation loss: 0.99985808, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43930.078125MB; mem (CPU total)=43691.9375MB
INFO:root:[   47] Training loss: 0.98392015, Validation loss: 0.99186214, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=43968.171875MB; mem (CPU total)=43730.3515625MB
INFO:root:[   48] Training loss: 0.98405723, Validation loss: 0.98913396, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44006.265625MB; mem (CPU total)=43768.27734375MB
INFO:root:[   49] Training loss: 0.98386103, Validation loss: 0.99198577, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44044.36328125MB; mem (CPU total)=43808.6953125MB
INFO:root:[   50] Training loss: 0.98358462, Validation loss: 1.01404327, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44082.45703125MB; mem (CPU total)=43847.17578125MB
INFO:root:[   51] Training loss: 0.98338927, Validation loss: 1.00932315, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44120.55078125MB; mem (CPU total)=43885.9765625MB
INFO:root:[   52] Training loss: 0.98329782, Validation loss: 0.99456509, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44158.65234375MB; mem (CPU total)=43921.16015625MB
INFO:root:[   53] Training loss: 0.98309921, Validation loss: 1.00427173, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44196.74609375MB; mem (CPU total)=43959.08984375MB
INFO:root:[   54] Training loss: 0.98296137, Validation loss: 1.00772746, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44234.83984375MB; mem (CPU total)=43999.265625MB
INFO:root:[   55] Training loss: 0.98297838, Validation loss: 1.01346890, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44272.93359375MB; mem (CPU total)=44038.37109375MB
INFO:root:[   56] Training loss: 0.98269869, Validation loss: 1.01332609, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44311.03125MB; mem (CPU total)=44074.1328125MB
INFO:root:[   57] Training loss: 0.98256181, Validation loss: 0.99889123, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44349.125MB; mem (CPU total)=44112.546875MB
INFO:root:[   58] Training loss: 0.98247990, Validation loss: 0.99851194, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44387.21875MB; mem (CPU total)=44154.375MB
INFO:root:[   59] Training loss: 0.98243762, Validation loss: 1.00472071, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44425.31640625MB; mem (CPU total)=44190.265625MB
INFO:root:[   60] Training loss: 0.98244046, Validation loss: 1.01762890, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44463.4140625MB; mem (CPU total)=44226.87890625MB
INFO:root:[   61] Training loss: 0.98224999, Validation loss: 1.00660103, Gradient norm: 0.00000000
INFO:root:At the start of the epoch: mem (CPU python)=44501.5078125MB; mem (CPU total)=44264.390625MB
INFO:root:EP 61: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=44539.6015625MB; mem (CPU total)=44303.51171875MB
INFO:root:Training the model took 4268.112s.
INFO:root:Emptying the cuda cache took 0.009s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.98396
INFO:root:EnergyScoreTrain: 0.88396
INFO:root:CRPSTrain: 0.75885
INFO:root:Gaussian NLLTrain: 90185.07185
INFO:root:CoverageTrain: 0.06976
INFO:root:IntervalWidthTrain: 0.15884
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.98527
INFO:root:EnergyScoreValidation: 0.88716
INFO:root:CRPSValidation: 0.76077
INFO:root:Gaussian NLLValidation: 51343.88273
INFO:root:CoverageValidation: 0.06828
INFO:root:IntervalWidthValidation: 0.1553
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.98449
INFO:root:EnergyScoreTest: 0.8867
INFO:root:CRPSTest: 0.76008
INFO:root:Gaussian NLLTest: 74389.94266
INFO:root:CoverageTest: 0.06862
INFO:root:IntervalWidthTest: 0.15579
INFO:root:After validation: mem (CPU python)=44613.12890625MB; mem (CPU total)=44379.33203125MB
