INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=582.03515625MB; mem (CPU total)=1173.79296875MB
INFO:root:############### Starting experiment with config file darcy_flow/uno_laplace.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'DarcyFlow', 'max_training_set_size': 10000, 'downscaling_factor': 2}
INFO:root:After loading the datasets: mem (CPU python)=2002.015625MB; mem (CPU total)=1200.80859375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=2002.015625MB; mem (CPU total)=1200.80859375MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 44040192
INFO:root:After setting up the model: mem (CPU python)=2227.921875MB; mem (CPU total)=2567.73046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=2227.921875MB; mem (CPU total)=2574.84765625MB
INFO:root:[    1] Training loss: 0.33472679, Validation loss: 0.24160496, Gradient norm: 2.62047339
INFO:root:At the start of the epoch: mem (CPU python)=4470.2578125MB; mem (CPU total)=4354.390625MB
INFO:root:[    2] Training loss: 0.23023214, Validation loss: 0.23183683, Gradient norm: 3.11646088
INFO:root:At the start of the epoch: mem (CPU python)=4546.50390625MB; mem (CPU total)=4429.8203125MB
INFO:root:[    3] Training loss: 0.19737373, Validation loss: 0.21991432, Gradient norm: 2.60923421
INFO:root:At the start of the epoch: mem (CPU python)=4622.74609375MB; mem (CPU total)=4503.09765625MB
INFO:root:[    4] Training loss: 0.18446413, Validation loss: 0.22458764, Gradient norm: 2.87990934
INFO:root:At the start of the epoch: mem (CPU python)=4698.80078125MB; mem (CPU total)=4575.8828125MB
INFO:root:[    5] Training loss: 0.16906792, Validation loss: 0.19997500, Gradient norm: 2.40858014
INFO:root:At the start of the epoch: mem (CPU python)=4775.1484375MB; mem (CPU total)=4650.65625MB
INFO:root:[    6] Training loss: 0.17241329, Validation loss: 0.20720624, Gradient norm: 2.75485923
INFO:root:At the start of the epoch: mem (CPU python)=4851.35546875MB; mem (CPU total)=4725.7109375MB
INFO:root:[    7] Training loss: 0.15444607, Validation loss: 0.20867706, Gradient norm: 2.25373739
INFO:root:At the start of the epoch: mem (CPU python)=4928.26953125MB; mem (CPU total)=4802.60546875MB
INFO:root:[    8] Training loss: 0.15399013, Validation loss: 0.18557305, Gradient norm: 2.39581290
INFO:root:At the start of the epoch: mem (CPU python)=5004.52734375MB; mem (CPU total)=4878.76171875MB
INFO:root:[    9] Training loss: 0.14730590, Validation loss: 0.19698294, Gradient norm: 2.45341933
INFO:root:At the start of the epoch: mem (CPU python)=5081.328125MB; mem (CPU total)=4953.9375MB
INFO:root:[   10] Training loss: 0.14569789, Validation loss: 0.20283036, Gradient norm: 2.31892440
INFO:root:At the start of the epoch: mem (CPU python)=5157.56640625MB; mem (CPU total)=5029.8046875MB
INFO:root:[   11] Training loss: 0.13887393, Validation loss: 0.18745654, Gradient norm: 1.95615456
INFO:root:At the start of the epoch: mem (CPU python)=5233.78125MB; mem (CPU total)=5104.76953125MB
INFO:root:[   12] Training loss: 0.13765953, Validation loss: 0.19777036, Gradient norm: 2.14274286
INFO:root:At the start of the epoch: mem (CPU python)=5309.98828125MB; mem (CPU total)=5180.48828125MB
INFO:root:[   13] Training loss: 0.13190636, Validation loss: 0.19646620, Gradient norm: 1.88124227
INFO:root:At the start of the epoch: mem (CPU python)=5386.21484375MB; mem (CPU total)=5256.39453125MB
INFO:root:[   14] Training loss: 0.13271910, Validation loss: 0.18789662, Gradient norm: 1.98532679
INFO:root:At the start of the epoch: mem (CPU python)=5462.42578125MB; mem (CPU total)=5332.32421875MB
INFO:root:[   15] Training loss: 0.13631412, Validation loss: 0.19794505, Gradient norm: 2.40873339
INFO:root:At the start of the epoch: mem (CPU python)=5538.6328125MB; mem (CPU total)=5408.625MB
INFO:root:[   16] Training loss: 0.12989654, Validation loss: 0.19971121, Gradient norm: 2.26064354
INFO:root:At the start of the epoch: mem (CPU python)=5614.8359375MB; mem (CPU total)=5485.05078125MB
INFO:root:[   17] Training loss: 0.12426259, Validation loss: 0.18592327, Gradient norm: 1.77592891
INFO:root:At the start of the epoch: mem (CPU python)=5691.02734375MB; mem (CPU total)=5560.15234375MB
INFO:root:[   18] Training loss: 0.12605929, Validation loss: 0.17454327, Gradient norm: 2.23195759
INFO:root:At the start of the epoch: mem (CPU python)=5767.2265625MB; mem (CPU total)=5636.859375MB
INFO:root:[   19] Training loss: 0.11951072, Validation loss: 0.18358656, Gradient norm: 2.10966625
INFO:root:At the start of the epoch: mem (CPU python)=5843.41015625MB; mem (CPU total)=5711.28125MB
INFO:root:[   20] Training loss: 0.12151251, Validation loss: 0.24738200, Gradient norm: 2.39529267
INFO:root:At the start of the epoch: mem (CPU python)=5919.6171875MB; mem (CPU total)=5787.7578125MB
INFO:root:[   21] Training loss: 0.11533248, Validation loss: 0.20658171, Gradient norm: 2.02096837
INFO:root:At the start of the epoch: mem (CPU python)=5995.83203125MB; mem (CPU total)=5863.3203125MB
INFO:root:[   22] Training loss: 0.11579517, Validation loss: 0.19866652, Gradient norm: 2.04386901
INFO:root:At the start of the epoch: mem (CPU python)=6072.0234375MB; mem (CPU total)=5939.6328125MB
INFO:root:[   23] Training loss: 0.12400066, Validation loss: 0.23148107, Gradient norm: 2.50575651
INFO:root:At the start of the epoch: mem (CPU python)=6148.2265625MB; mem (CPU total)=6015.703125MB
INFO:root:[   24] Training loss: 0.11289842, Validation loss: 0.20675970, Gradient norm: 2.52022110
INFO:root:At the start of the epoch: mem (CPU python)=6224.421875MB; mem (CPU total)=6091.56640625MB
INFO:root:[   25] Training loss: 0.10630484, Validation loss: 0.20349752, Gradient norm: 1.94953437
INFO:root:At the start of the epoch: mem (CPU python)=6300.61328125MB; mem (CPU total)=6167.89453125MB
INFO:root:[   26] Training loss: 0.10659699, Validation loss: 0.22364493, Gradient norm: 1.84565129
INFO:root:At the start of the epoch: mem (CPU python)=6376.80859375MB; mem (CPU total)=6243.28515625MB
INFO:root:[   27] Training loss: 0.11085170, Validation loss: 0.22916828, Gradient norm: 2.10135089
INFO:root:At the start of the epoch: mem (CPU python)=6453.0078125MB; mem (CPU total)=6319.86328125MB
INFO:root:[   28] Training loss: 0.10561925, Validation loss: 0.20029408, Gradient norm: 2.01592877
INFO:root:At the start of the epoch: mem (CPU python)=6529.203125MB; mem (CPU total)=6395.91796875MB
INFO:root:[   29] Training loss: 0.10642958, Validation loss: 0.21433787, Gradient norm: 2.05864141
INFO:root:At the start of the epoch: mem (CPU python)=6605.4140625MB; mem (CPU total)=6472.15625MB
INFO:root:[   30] Training loss: 0.10364584, Validation loss: 0.19687426, Gradient norm: 1.79094916
INFO:root:At the start of the epoch: mem (CPU python)=6681.62109375MB; mem (CPU total)=6548.3046875MB
INFO:root:[   31] Training loss: 0.10441612, Validation loss: 0.22175375, Gradient norm: 2.31690975
INFO:root:At the start of the epoch: mem (CPU python)=6757.8125MB; mem (CPU total)=6624.3828125MB
INFO:root:[   32] Training loss: 0.10517361, Validation loss: 0.19625180, Gradient norm: 2.59231072
INFO:root:At the start of the epoch: mem (CPU python)=6834.00390625MB; mem (CPU total)=6701.01953125MB
INFO:root:[   33] Training loss: 0.11052559, Validation loss: 0.22700127, Gradient norm: 2.77228353
INFO:root:At the start of the epoch: mem (CPU python)=6910.19921875MB; mem (CPU total)=6777.68359375MB
INFO:root:[   34] Training loss: 0.10031885, Validation loss: 0.21621514, Gradient norm: 1.96720612
INFO:root:At the start of the epoch: mem (CPU python)=6986.390625MB; mem (CPU total)=6852.87890625MB
INFO:root:[   35] Training loss: 0.10398054, Validation loss: 0.23906345, Gradient norm: 2.15221565
INFO:root:At the start of the epoch: mem (CPU python)=7062.5859375MB; mem (CPU total)=6929.5390625MB
INFO:root:[   36] Training loss: 0.10267012, Validation loss: 0.22503629, Gradient norm: 2.05750331
INFO:root:At the start of the epoch: mem (CPU python)=7138.78125MB; mem (CPU total)=7005.5234375MB
INFO:root:[   37] Training loss: 0.09927935, Validation loss: 0.21484841, Gradient norm: 1.61204491
INFO:root:At the start of the epoch: mem (CPU python)=7214.97265625MB; mem (CPU total)=7081.95703125MB
INFO:root:[   38] Training loss: 0.09685425, Validation loss: 0.21358214, Gradient norm: 2.07652049
INFO:root:At the start of the epoch: mem (CPU python)=7291.1640625MB; mem (CPU total)=7158.25MB
INFO:root:[   39] Training loss: 0.10021341, Validation loss: 0.20094549, Gradient norm: 2.09183234
INFO:root:At the start of the epoch: mem (CPU python)=7367.36328125MB; mem (CPU total)=7234.45703125MB
INFO:root:[   40] Training loss: 0.09450449, Validation loss: 0.22346480, Gradient norm: 1.94401784
INFO:root:At the start of the epoch: mem (CPU python)=7443.55859375MB; mem (CPU total)=7311.15625MB
INFO:root:[   41] Training loss: 0.09827220, Validation loss: 0.20646662, Gradient norm: 1.99798967
INFO:root:At the start of the epoch: mem (CPU python)=7519.75MB; mem (CPU total)=7386.87109375MB
INFO:root:[   42] Training loss: 0.09853133, Validation loss: 0.22733355, Gradient norm: 1.92322807
INFO:root:At the start of the epoch: mem (CPU python)=7595.953125MB; mem (CPU total)=7462.92578125MB
INFO:root:[   43] Training loss: 0.09689584, Validation loss: 0.21109157, Gradient norm: 2.08023341
INFO:root:At the start of the epoch: mem (CPU python)=7672.18359375MB; mem (CPU total)=7539.37890625MB
INFO:root:[   44] Training loss: 0.09491440, Validation loss: 0.21758667, Gradient norm: 1.90722535
INFO:root:At the start of the epoch: mem (CPU python)=7748.40234375MB; mem (CPU total)=7615.6484375MB
INFO:root:[   45] Training loss: 0.09426578, Validation loss: 0.22798270, Gradient norm: 1.76128775
INFO:root:At the start of the epoch: mem (CPU python)=7824.6015625MB; mem (CPU total)=7692.2265625MB
INFO:root:[   46] Training loss: 0.09397260, Validation loss: 0.21636528, Gradient norm: 2.20720067
INFO:root:At the start of the epoch: mem (CPU python)=7900.7890625MB; mem (CPU total)=7768.27734375MB
INFO:root:[   47] Training loss: 0.09350059, Validation loss: 0.23547047, Gradient norm: 1.87806285
INFO:root:At the start of the epoch: mem (CPU python)=7976.9921875MB; mem (CPU total)=7844.6484375MB
INFO:root:[   48] Training loss: 0.09095077, Validation loss: 0.21598705, Gradient norm: 1.54035082
INFO:root:At the start of the epoch: mem (CPU python)=8053.18359375MB; mem (CPU total)=7920.796875MB
INFO:root:[   49] Training loss: 0.09256479, Validation loss: 0.21778478, Gradient norm: 1.88055605
INFO:root:At the start of the epoch: mem (CPU python)=8129.37890625MB; mem (CPU total)=7997.19921875MB
INFO:root:[   50] Training loss: 0.09567835, Validation loss: 0.22143523, Gradient norm: 2.06125807
INFO:root:At the start of the epoch: mem (CPU python)=8205.578125MB; mem (CPU total)=8073.5546875MB
INFO:root:[   51] Training loss: 0.09310706, Validation loss: 0.22848553, Gradient norm: 2.33237787
INFO:root:At the start of the epoch: mem (CPU python)=8281.7734375MB; mem (CPU total)=8149.55078125MB
INFO:root:[   52] Training loss: 0.09061607, Validation loss: 0.22080864, Gradient norm: 1.61461944
INFO:root:At the start of the epoch: mem (CPU python)=8357.98046875MB; mem (CPU total)=8226.0078125MB
INFO:root:[   53] Training loss: 0.09283270, Validation loss: 0.23215415, Gradient norm: 1.66486068
INFO:root:At the start of the epoch: mem (CPU python)=8434.16796875MB; mem (CPU total)=8302.2734375MB
INFO:root:[   54] Training loss: 0.09101280, Validation loss: 0.22140437, Gradient norm: 1.86475100
INFO:root:At the start of the epoch: mem (CPU python)=8510.36328125MB; mem (CPU total)=8378.578125MB
INFO:root:[   55] Training loss: 0.09257276, Validation loss: 0.21992537, Gradient norm: 1.92504157
INFO:root:At the start of the epoch: mem (CPU python)=8586.5546875MB; mem (CPU total)=8455.12890625MB
INFO:root:[   56] Training loss: 0.08837231, Validation loss: 0.22115679, Gradient norm: 1.84811701
INFO:root:At the start of the epoch: mem (CPU python)=8662.74609375MB; mem (CPU total)=8531.1875MB
INFO:root:[   57] Training loss: 0.09164070, Validation loss: 0.22376825, Gradient norm: 1.71662837
INFO:root:At the start of the epoch: mem (CPU python)=8738.9375MB; mem (CPU total)=8607.4921875MB
INFO:root:[   58] Training loss: 0.08949286, Validation loss: 0.23257231, Gradient norm: 2.02784608
INFO:root:At the start of the epoch: mem (CPU python)=8815.12890625MB; mem (CPU total)=8683.5546875MB
INFO:root:[   59] Training loss: 0.08623587, Validation loss: 0.23071100, Gradient norm: 1.66081021
INFO:root:At the start of the epoch: mem (CPU python)=8891.32421875MB; mem (CPU total)=8760.10546875MB
INFO:root:[   60] Training loss: 0.09415375, Validation loss: 0.23075931, Gradient norm: 2.26957691
INFO:root:At the start of the epoch: mem (CPU python)=8967.51171875MB; mem (CPU total)=8836.41015625MB
INFO:root:[   61] Training loss: 0.08648579, Validation loss: 0.22029057, Gradient norm: 1.81651836
INFO:root:At the start of the epoch: mem (CPU python)=9043.703125MB; mem (CPU total)=8912.46875MB
INFO:root:[   62] Training loss: 0.08766325, Validation loss: 0.24722035, Gradient norm: 1.95585249
INFO:root:At the start of the epoch: mem (CPU python)=9119.890625MB; mem (CPU total)=8989.01953125MB
INFO:root:[   63] Training loss: 0.09426486, Validation loss: 0.21947617, Gradient norm: 2.32673573
INFO:root:At the start of the epoch: mem (CPU python)=9196.078125MB; mem (CPU total)=9065.078125MB
INFO:root:[   64] Training loss: 0.08685364, Validation loss: 0.23480688, Gradient norm: 1.83650540
INFO:root:At the start of the epoch: mem (CPU python)=9272.2734375MB; mem (CPU total)=9141.4375MB
INFO:root:[   65] Training loss: 0.08794836, Validation loss: 0.23739035, Gradient norm: 1.60132893
INFO:root:At the start of the epoch: mem (CPU python)=9348.4609375MB; mem (CPU total)=9217.48828125MB
INFO:root:[   66] Training loss: 0.08838308, Validation loss: 0.22984216, Gradient norm: 1.55851973
INFO:root:At the start of the epoch: mem (CPU python)=9424.65234375MB; mem (CPU total)=9293.78515625MB
INFO:root:[   67] Training loss: 0.08618873, Validation loss: 0.23519086, Gradient norm: 1.78308709
INFO:root:At the start of the epoch: mem (CPU python)=9500.84375MB; mem (CPU total)=9370.3359375MB
INFO:root:[   68] Training loss: 0.08505183, Validation loss: 0.23114383, Gradient norm: 1.91243281
INFO:root:At the start of the epoch: mem (CPU python)=9577.03515625MB; mem (CPU total)=9446.3984375MB
INFO:root:[   69] Training loss: 0.08553960, Validation loss: 0.24078521, Gradient norm: 1.88608397
INFO:root:At the start of the epoch: mem (CPU python)=9653.2265625MB; mem (CPU total)=9522.94921875MB
INFO:root:[   70] Training loss: 0.08625162, Validation loss: 0.26287408, Gradient norm: 1.89767068
INFO:root:At the start of the epoch: mem (CPU python)=9729.4140625MB; mem (CPU total)=9599.08203125MB
INFO:root:[   71] Training loss: 0.09246037, Validation loss: 0.22373693, Gradient norm: 2.27140304
INFO:root:At the start of the epoch: mem (CPU python)=9805.60546875MB; mem (CPU total)=9674.59765625MB
INFO:root:[   72] Training loss: 0.08325859, Validation loss: 0.23622545, Gradient norm: 1.42803698
INFO:root:At the start of the epoch: mem (CPU python)=9881.80078125MB; mem (CPU total)=9750.86328125MB
INFO:root:EP 72: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=9957.92578125MB; mem (CPU total)=9827.16796875MB
INFO:root:Training the model took 2972.586s.
INFO:root:Emptying the cuda cache took 0.019s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.12044
INFO:root:EnergyScoreTrain: 0.09186
INFO:root:CRPSTrain: 0.07619
INFO:root:Gaussian NLLTrain: -0.42409
INFO:root:CoverageTrain: 0.84287
INFO:root:IntervalWidthTrain: 0.35107
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.17519
INFO:root:EnergyScoreValidation: 0.13763
INFO:root:CRPSValidation: 0.11135
INFO:root:Gaussian NLLValidation: 1.22746
INFO:root:CoverageValidation: 0.69226
INFO:root:IntervalWidthValidation: 0.34232
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.1789
INFO:root:EnergyScoreTest: 0.14098
INFO:root:CRPSTest: 0.11451
INFO:root:Gaussian NLLTest: 1.38719
INFO:root:CoverageTest: 0.68183
INFO:root:IntervalWidthTest: 0.34109
INFO:root:After validation: mem (CPU python)=10439.62109375MB; mem (CPU total)=10169.109375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=10439.68359375MB; mem (CPU total)=10169.2109375MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 226492416
INFO:root:After setting up the model: mem (CPU python)=10448.265625MB; mem (CPU total)=10177.85546875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=10448.265625MB; mem (CPU total)=10177.76953125MB
INFO:root:[    1] Training loss: 0.33013676, Validation loss: 0.26840040, Gradient norm: 2.44156582
INFO:root:At the start of the epoch: mem (CPU python)=10535.4765625MB; mem (CPU total)=10262.17578125MB
INFO:root:[    2] Training loss: 0.21671850, Validation loss: 0.24195652, Gradient norm: 2.28449575
INFO:root:At the start of the epoch: mem (CPU python)=10611.89453125MB; mem (CPU total)=10338.13671875MB
INFO:root:[    3] Training loss: 0.18659339, Validation loss: 0.24149933, Gradient norm: 2.25069132
INFO:root:At the start of the epoch: mem (CPU python)=10688.1015625MB; mem (CPU total)=10414.10546875MB
INFO:root:[    4] Training loss: 0.18653903, Validation loss: 0.21550846, Gradient norm: 3.13087669
INFO:root:At the start of the epoch: mem (CPU python)=10764.3046875MB; mem (CPU total)=10490.11328125MB
INFO:root:[    5] Training loss: 0.17276556, Validation loss: 0.22544671, Gradient norm: 2.30647239
INFO:root:At the start of the epoch: mem (CPU python)=10840.515625MB; mem (CPU total)=10566.109375MB
INFO:root:[    6] Training loss: 0.15904848, Validation loss: 0.20723271, Gradient norm: 1.90793357
INFO:root:At the start of the epoch: mem (CPU python)=10916.71875MB; mem (CPU total)=10642.94140625MB
INFO:root:[    7] Training loss: 0.16067766, Validation loss: 0.20431777, Gradient norm: 2.59388844
INFO:root:At the start of the epoch: mem (CPU python)=10992.9296875MB; mem (CPU total)=10719.19921875MB
INFO:root:[    8] Training loss: 0.15735245, Validation loss: 0.21573386, Gradient norm: 2.59242261
INFO:root:At the start of the epoch: mem (CPU python)=11069.12890625MB; mem (CPU total)=10795.2578125MB
INFO:root:[    9] Training loss: 0.14992593, Validation loss: 0.19399171, Gradient norm: 1.86346231
INFO:root:At the start of the epoch: mem (CPU python)=11145.33984375MB; mem (CPU total)=10871.71875MB
INFO:root:[   10] Training loss: 0.14758648, Validation loss: 0.20370714, Gradient norm: 2.42747258
INFO:root:At the start of the epoch: mem (CPU python)=11221.54296875MB; mem (CPU total)=10948.49609375MB
INFO:root:[   11] Training loss: 0.14742329, Validation loss: 0.21492059, Gradient norm: 2.48490838
INFO:root:At the start of the epoch: mem (CPU python)=11297.73046875MB; mem (CPU total)=11024.5546875MB
INFO:root:[   12] Training loss: 0.14580603, Validation loss: 0.19216737, Gradient norm: 2.70603883
INFO:root:At the start of the epoch: mem (CPU python)=11373.92578125MB; mem (CPU total)=11101.86328125MB
INFO:root:[   13] Training loss: 0.14013342, Validation loss: 0.19531058, Gradient norm: 2.11020426
INFO:root:At the start of the epoch: mem (CPU python)=11450.11328125MB; mem (CPU total)=11177.63671875MB
INFO:root:[   14] Training loss: 0.13499078, Validation loss: 0.19317171, Gradient norm: 2.13544020
INFO:root:At the start of the epoch: mem (CPU python)=11526.3046875MB; mem (CPU total)=11253.51171875MB
INFO:root:[   15] Training loss: 0.13177802, Validation loss: 0.18589465, Gradient norm: 2.41516604
INFO:root:At the start of the epoch: mem (CPU python)=11602.49609375MB; mem (CPU total)=11330.27734375MB
INFO:root:[   16] Training loss: 0.13560159, Validation loss: 0.18899972, Gradient norm: 2.32705544
INFO:root:At the start of the epoch: mem (CPU python)=11678.6875MB; mem (CPU total)=11406.265625MB
INFO:root:[   17] Training loss: 0.13058319, Validation loss: 0.19256651, Gradient norm: 2.23642840
INFO:root:At the start of the epoch: mem (CPU python)=11754.87890625MB; mem (CPU total)=11482.6484375MB
INFO:root:[   18] Training loss: 0.12869762, Validation loss: 0.20683369, Gradient norm: 2.41158988
INFO:root:At the start of the epoch: mem (CPU python)=11831.06640625MB; mem (CPU total)=11559.11328125MB
INFO:root:[   19] Training loss: 0.12620414, Validation loss: 0.20782040, Gradient norm: 2.02131437
INFO:root:At the start of the epoch: mem (CPU python)=11907.26171875MB; mem (CPU total)=11635.109375MB
INFO:root:[   20] Training loss: 0.12321696, Validation loss: 0.23083864, Gradient norm: 2.26166585
INFO:root:At the start of the epoch: mem (CPU python)=11983.44921875MB; mem (CPU total)=11711.66015625MB
INFO:root:[   21] Training loss: 0.12480294, Validation loss: 0.21533915, Gradient norm: 2.37891968
INFO:root:At the start of the epoch: mem (CPU python)=12059.64453125MB; mem (CPU total)=11788.29296875MB
INFO:root:[   22] Training loss: 0.11822897, Validation loss: 0.20394959, Gradient norm: 1.85506517
INFO:root:At the start of the epoch: mem (CPU python)=12135.8359375MB; mem (CPU total)=11862.953125MB
INFO:root:[   23] Training loss: 0.12216523, Validation loss: 0.20306430, Gradient norm: 2.26253139
INFO:root:At the start of the epoch: mem (CPU python)=12212.0234375MB; mem (CPU total)=11939.49609375MB
INFO:root:[   24] Training loss: 0.11697653, Validation loss: 0.23854624, Gradient norm: 1.90059937
INFO:root:At the start of the epoch: mem (CPU python)=12288.21875MB; mem (CPU total)=12015.5546875MB
INFO:root:[   25] Training loss: 0.11559091, Validation loss: 0.25966668, Gradient norm: 2.16003596
INFO:root:At the start of the epoch: mem (CPU python)=12364.40625MB; mem (CPU total)=12092.109375MB
INFO:root:[   26] Training loss: 0.11566333, Validation loss: 0.20632571, Gradient norm: 2.43482088
INFO:root:At the start of the epoch: mem (CPU python)=12440.59765625MB; mem (CPU total)=12168.66015625MB
INFO:root:[   27] Training loss: 0.10959811, Validation loss: 0.21506492, Gradient norm: 1.84365167
INFO:root:At the start of the epoch: mem (CPU python)=12516.7890625MB; mem (CPU total)=12243.95703125MB
INFO:root:[   28] Training loss: 0.10858287, Validation loss: 0.21930010, Gradient norm: 1.80935291
INFO:root:At the start of the epoch: mem (CPU python)=12592.9765625MB; mem (CPU total)=12319.59765625MB
INFO:root:[   29] Training loss: 0.10976833, Validation loss: 0.20605324, Gradient norm: 1.98892660
INFO:root:At the start of the epoch: mem (CPU python)=12669.171875MB; mem (CPU total)=12395.16796875MB
INFO:root:[   30] Training loss: 0.10776471, Validation loss: 0.24077336, Gradient norm: 2.13350782
INFO:root:At the start of the epoch: mem (CPU python)=12745.359375MB; mem (CPU total)=12471.46875MB
INFO:root:[   31] Training loss: 0.10723619, Validation loss: 0.21317441, Gradient norm: 2.57748689
INFO:root:At the start of the epoch: mem (CPU python)=12821.55078125MB; mem (CPU total)=12548.01171875MB
INFO:root:[   32] Training loss: 0.10566668, Validation loss: 0.22648080, Gradient norm: 2.32630913
INFO:root:At the start of the epoch: mem (CPU python)=12897.73828125MB; mem (CPU total)=12624.07421875MB
INFO:root:[   33] Training loss: 0.10252465, Validation loss: 0.21797459, Gradient norm: 2.04000502
INFO:root:At the start of the epoch: mem (CPU python)=12973.93359375MB; mem (CPU total)=12700.625MB
INFO:root:[   34] Training loss: 0.10425667, Validation loss: 0.24948194, Gradient norm: 1.79315762
INFO:root:At the start of the epoch: mem (CPU python)=13050.12890625MB; mem (CPU total)=12776.9296875MB
INFO:root:[   35] Training loss: 0.09842117, Validation loss: 0.24423733, Gradient norm: 1.82714696
INFO:root:At the start of the epoch: mem (CPU python)=13126.31640625MB; mem (CPU total)=12852.74609375MB
INFO:root:[   36] Training loss: 0.10328586, Validation loss: 0.23513187, Gradient norm: 2.18889212
INFO:root:At the start of the epoch: mem (CPU python)=13202.8828125MB; mem (CPU total)=12929.265625MB
INFO:root:[   37] Training loss: 0.10676320, Validation loss: 0.20615154, Gradient norm: 2.54722355
INFO:root:At the start of the epoch: mem (CPU python)=13279.07421875MB; mem (CPU total)=13005.30859375MB
INFO:root:[   38] Training loss: 0.10731949, Validation loss: 0.25394833, Gradient norm: 2.52786128
INFO:root:At the start of the epoch: mem (CPU python)=13355.2734375MB; mem (CPU total)=13081.86328125MB
INFO:root:[   39] Training loss: 0.09519594, Validation loss: 0.21588655, Gradient norm: 1.61122823
INFO:root:At the start of the epoch: mem (CPU python)=13431.49609375MB; mem (CPU total)=13158.25MB
INFO:root:[   40] Training loss: 0.09706196, Validation loss: 0.24671104, Gradient norm: 1.86940816
INFO:root:At the start of the epoch: mem (CPU python)=13508.00390625MB; mem (CPU total)=13235.03515625MB
INFO:root:[   41] Training loss: 0.10011273, Validation loss: 0.23770575, Gradient norm: 2.73278048
INFO:root:At the start of the epoch: mem (CPU python)=13585.51953125MB; mem (CPU total)=13313.01171875MB
INFO:root:[   42] Training loss: 0.09848941, Validation loss: 0.24766050, Gradient norm: 1.85840784
INFO:root:At the start of the epoch: mem (CPU python)=13661.7421875MB; mem (CPU total)=13389.15234375MB
INFO:root:[   43] Training loss: 0.09652272, Validation loss: 0.22628250, Gradient norm: 2.17803174
INFO:root:At the start of the epoch: mem (CPU python)=13738.30859375MB; mem (CPU total)=13466.11328125MB
INFO:root:[   44] Training loss: 0.09329676, Validation loss: 0.26690707, Gradient norm: 1.67302611
INFO:root:At the start of the epoch: mem (CPU python)=13814.6640625MB; mem (CPU total)=13542.609375MB
INFO:root:[   45] Training loss: 0.09886963, Validation loss: 0.23887958, Gradient norm: 2.82790063
INFO:root:At the start of the epoch: mem (CPU python)=13891.171875MB; mem (CPU total)=13618.81640625MB
INFO:root:[   46] Training loss: 0.09477870, Validation loss: 0.23399740, Gradient norm: 1.90315008
INFO:root:At the start of the epoch: mem (CPU python)=13967.953125MB; mem (CPU total)=13696.125MB
INFO:root:[   47] Training loss: 0.09236216, Validation loss: 0.23874041, Gradient norm: 1.88046405
INFO:root:At the start of the epoch: mem (CPU python)=14044.203125MB; mem (CPU total)=13772.046875MB
INFO:root:[   48] Training loss: 0.09559394, Validation loss: 0.23237657, Gradient norm: 2.37503823
INFO:root:At the start of the epoch: mem (CPU python)=14120.64453125MB; mem (CPU total)=13848.890625MB
INFO:root:[   49] Training loss: 0.09275470, Validation loss: 0.22627543, Gradient norm: 1.94343365
INFO:root:At the start of the epoch: mem (CPU python)=14197.14453125MB; mem (CPU total)=13925.20703125MB
INFO:root:[   50] Training loss: 0.08959549, Validation loss: 0.22820304, Gradient norm: 2.00550745
INFO:root:At the start of the epoch: mem (CPU python)=14273.3359375MB; mem (CPU total)=14001.4921875MB
INFO:root:[   51] Training loss: 0.09306095, Validation loss: 0.24155782, Gradient norm: 1.91696696
INFO:root:At the start of the epoch: mem (CPU python)=14349.52734375MB; mem (CPU total)=14078.02734375MB
INFO:root:[   52] Training loss: 0.09563087, Validation loss: 0.27770644, Gradient norm: 2.02887537
INFO:root:At the start of the epoch: mem (CPU python)=14425.71484375MB; mem (CPU total)=14154.31640625MB
INFO:root:[   53] Training loss: 0.09325906, Validation loss: 0.25917928, Gradient norm: 2.20318745
INFO:root:At the start of the epoch: mem (CPU python)=14501.91015625MB; mem (CPU total)=14230.8515625MB
INFO:root:[   54] Training loss: 0.09116438, Validation loss: 0.24305366, Gradient norm: 1.80737107
INFO:root:At the start of the epoch: mem (CPU python)=14578.09765625MB; mem (CPU total)=14307.38671875MB
INFO:root:[   55] Training loss: 0.09039514, Validation loss: 0.25723234, Gradient norm: 1.91451835
INFO:root:At the start of the epoch: mem (CPU python)=14654.29296875MB; mem (CPU total)=14383.67578125MB
INFO:root:[   56] Training loss: 0.08781197, Validation loss: 0.24655828, Gradient norm: 1.57220628
INFO:root:At the start of the epoch: mem (CPU python)=14730.484375MB; mem (CPU total)=14460.25MB
INFO:root:[   57] Training loss: 0.08702052, Validation loss: 0.24565465, Gradient norm: 1.75064556
INFO:root:At the start of the epoch: mem (CPU python)=14806.671875MB; mem (CPU total)=14536.5625MB
INFO:root:[   58] Training loss: 0.08706079, Validation loss: 0.24412893, Gradient norm: 1.73669801
INFO:root:At the start of the epoch: mem (CPU python)=14882.8671875MB; mem (CPU total)=14612.359375MB
INFO:root:[   59] Training loss: 0.09505752, Validation loss: 0.23047787, Gradient norm: 2.30714085
INFO:root:At the start of the epoch: mem (CPU python)=14959.0546875MB; mem (CPU total)=14688.6171875MB
INFO:root:[   60] Training loss: 0.08768600, Validation loss: 0.23983978, Gradient norm: 2.06177552
INFO:root:At the start of the epoch: mem (CPU python)=15035.24609375MB; mem (CPU total)=14764.90625MB
INFO:root:[   61] Training loss: 0.08904481, Validation loss: 0.23602798, Gradient norm: 2.08849799
INFO:root:At the start of the epoch: mem (CPU python)=15111.4375MB; mem (CPU total)=14841.1953125MB
INFO:root:[   62] Training loss: 0.08934588, Validation loss: 0.23812485, Gradient norm: 1.91063692
INFO:root:At the start of the epoch: mem (CPU python)=15187.62890625MB; mem (CPU total)=14917.484375MB
INFO:root:[   63] Training loss: 0.08576053, Validation loss: 0.24177971, Gradient norm: 1.57070350
INFO:root:At the start of the epoch: mem (CPU python)=15263.8203125MB; mem (CPU total)=14993.52734375MB
INFO:root:[   64] Training loss: 0.08514894, Validation loss: 0.25639830, Gradient norm: 1.93981823
INFO:root:At the start of the epoch: mem (CPU python)=15340.0078125MB; mem (CPU total)=15069.81640625MB
INFO:root:[   65] Training loss: 0.09242735, Validation loss: 0.24477274, Gradient norm: 2.32666849
INFO:root:At the start of the epoch: mem (CPU python)=15416.19921875MB; mem (CPU total)=15146.59765625MB
INFO:root:[   66] Training loss: 0.09200007, Validation loss: 0.25731187, Gradient norm: 2.26201311
INFO:root:At the start of the epoch: mem (CPU python)=15492.38671875MB; mem (CPU total)=15222.88671875MB
INFO:root:[   67] Training loss: 0.08404101, Validation loss: 0.24068502, Gradient norm: 1.44512607
INFO:root:At the start of the epoch: mem (CPU python)=15568.578125MB; mem (CPU total)=15298.9296875MB
INFO:root:[   68] Training loss: 0.08238039, Validation loss: 0.24734798, Gradient norm: 1.54758924
INFO:root:At the start of the epoch: mem (CPU python)=15644.76953125MB; mem (CPU total)=15375.21875MB
INFO:root:EP 68: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=15720.9609375MB; mem (CPU total)=15451.29296875MB
INFO:root:Training the model took 3078.018s.
INFO:root:Emptying the cuda cache took 0.019s.
INFO:root:Starting evaluation: model UNO & uncertainty quantification laplace
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.12584
INFO:root:EnergyScoreTrain: 0.09574
INFO:root:CRPSTrain: 0.07741
INFO:root:Gaussian NLLTrain: -0.46545
INFO:root:CoverageTrain: 0.85977
INFO:root:IntervalWidthTrain: 0.36271
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.18611
INFO:root:EnergyScoreValidation: 0.14661
INFO:root:CRPSValidation: 0.11637
INFO:root:Gaussian NLLValidation: 0.95807
INFO:root:CoverageValidation: 0.70585
INFO:root:IntervalWidthValidation: 0.35486
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.18833
INFO:root:EnergyScoreTest: 0.14869
INFO:root:CRPSTest: 0.11841
INFO:root:Gaussian NLLTest: 1.04851
INFO:root:CoverageTest: 0.70287
INFO:root:IntervalWidthTest: 0.35524
INFO:root:After validation: mem (CPU python)=15867.58203125MB; mem (CPU total)=15600.83203125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'UNO', 'uncertainty_quantification': 'laplace', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.001, 'fourier_dropout': None, 'hidden_channels': 32, 'projection_channels': 32, 'lifting_channels': 32, 'n_samples': 3, 'uno_out_channels': [64, 128, 128, 64, 32], 'uno_scalings': [[0.5, 0.5], [0.5, 0.5], [1.0, 1.0], [2.0, 2.0], [2.0, 2.0]], 'uno_n_modes': [[18, 18], [8, 8], [8, 8], [8, 8], [18, 18]]}
INFO:root:After creating the dataloaders: mem (CPU python)=15867.58203125MB; mem (CPU total)=15600.80078125MB
INFO:root:NumberParameters: 5814913
INFO:root:GPU memory allocated: 278921216
INFO:root:After setting up the model: mem (CPU python)=15868.83984375MB; mem (CPU total)=15602.03125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=15868.83984375MB; mem (CPU total)=15602.02734375MB
INFO:root:[    1] Training loss: 0.35183661, Validation loss: 0.25687522, Gradient norm: 2.77333839
INFO:root:At the start of the epoch: mem (CPU python)=15946.28515625MB; mem (CPU total)=15680.59375MB
INFO:root:[    2] Training loss: 0.22594525, Validation loss: 0.26139892, Gradient norm: 3.25171314
INFO:root:At the start of the epoch: mem (CPU python)=16022.4765625MB; mem (CPU total)=15756.63671875MB
INFO:root:[    3] Training loss: 0.20358726, Validation loss: 0.22488689, Gradient norm: 2.64021464
INFO:root:At the start of the epoch: mem (CPU python)=16098.68359375MB; mem (CPU total)=15833.38671875MB
INFO:root:[    4] Training loss: 0.18943160, Validation loss: 0.23208858, Gradient norm: 3.16239259
INFO:root:At the start of the epoch: mem (CPU python)=16174.88671875MB; mem (CPU total)=15909.4296875MB
INFO:root:[    5] Training loss: 0.17467958, Validation loss: 0.21299668, Gradient norm: 2.62316121
INFO:root:At the start of the epoch: mem (CPU python)=16251.09765625MB; mem (CPU total)=15986.25MB
INFO:root:[    6] Training loss: 0.16855321, Validation loss: 0.21603054, Gradient norm: 2.90980262
INFO:root:At the start of the epoch: mem (CPU python)=16327.30078125MB; mem (CPU total)=16063.03125MB
INFO:root:[    7] Training loss: 0.16455525, Validation loss: 0.20381068, Gradient norm: 2.64002707
INFO:root:At the start of the epoch: mem (CPU python)=16403.51171875MB; mem (CPU total)=16139.78125MB
INFO:root:[    8] Training loss: 0.16088797, Validation loss: 0.21073520, Gradient norm: 3.02315728
INFO:root:At the start of the epoch: mem (CPU python)=16479.71484375MB; mem (CPU total)=16215.82421875MB
INFO:root:[    9] Training loss: 0.16595116, Validation loss: 0.19917704, Gradient norm: 2.61791828
INFO:root:At the start of the epoch: mem (CPU python)=16555.90625MB; mem (CPU total)=16292.640625MB
INFO:root:[   10] Training loss: 0.14710085, Validation loss: 0.20307441, Gradient norm: 2.46883762
INFO:root:At the start of the epoch: mem (CPU python)=16632.09375MB; mem (CPU total)=16368.73828125MB
INFO:root:[   11] Training loss: 0.14789130, Validation loss: 0.21690079, Gradient norm: 2.08787669
INFO:root:At the start of the epoch: mem (CPU python)=16708.28515625MB; mem (CPU total)=16443.80859375MB
INFO:root:[   12] Training loss: 0.14485254, Validation loss: 0.20893219, Gradient norm: 2.68012941
INFO:root:At the start of the epoch: mem (CPU python)=16784.4765625MB; mem (CPU total)=16520.1015625MB
INFO:root:[   13] Training loss: 0.14502315, Validation loss: 0.19788706, Gradient norm: 2.75527063
INFO:root:At the start of the epoch: mem (CPU python)=16860.66796875MB; mem (CPU total)=16596.359375MB
INFO:root:[   14] Training loss: 0.13636411, Validation loss: 0.20840162, Gradient norm: 2.23500599
INFO:root:At the start of the epoch: mem (CPU python)=16936.859375MB; mem (CPU total)=16672.6484375MB
INFO:root:[   15] Training loss: 0.13545815, Validation loss: 0.23086049, Gradient norm: 2.15118637
INFO:root:At the start of the epoch: mem (CPU python)=17013.046875MB; mem (CPU total)=16749.18359375MB
INFO:root:[   16] Training loss: 0.13813300, Validation loss: 0.20889655, Gradient norm: 2.79283382
INFO:root:At the start of the epoch: mem (CPU python)=17089.23828125MB; mem (CPU total)=16825.125MB
INFO:root:[   17] Training loss: 0.13351353, Validation loss: 0.21521140, Gradient norm: 2.50123322
INFO:root:At the start of the epoch: mem (CPU python)=17165.43359375MB; mem (CPU total)=16901.3984375MB
INFO:root:[   18] Training loss: 0.12919101, Validation loss: 0.20273011, Gradient norm: 2.76861008
INFO:root:At the start of the epoch: mem (CPU python)=17241.62109375MB; mem (CPU total)=16977.68359375MB
INFO:root:[   19] Training loss: 0.12716286, Validation loss: 0.20804232, Gradient norm: 2.85469710
INFO:root:At the start of the epoch: mem (CPU python)=17317.8125MB; mem (CPU total)=17054.21875MB
INFO:root:[   20] Training loss: 0.12363815, Validation loss: 0.23337683, Gradient norm: 1.97110365
INFO:root:At the start of the epoch: mem (CPU python)=17394.00390625MB; mem (CPU total)=17129.1953125MB
INFO:root:[   21] Training loss: 0.12059496, Validation loss: 0.21208550, Gradient norm: 2.32510754
INFO:root:At the start of the epoch: mem (CPU python)=17470.1953125MB; mem (CPU total)=17205.73046875MB
INFO:root:[   22] Training loss: 0.12062665, Validation loss: 0.23364151, Gradient norm: 2.72738340
INFO:root:At the start of the epoch: mem (CPU python)=17546.38671875MB; mem (CPU total)=17281.8046875MB
INFO:root:[   23] Training loss: 0.11957879, Validation loss: 0.22947443, Gradient norm: 2.19032342
INFO:root:At the start of the epoch: mem (CPU python)=17622.59765625MB; mem (CPU total)=17359.63671875MB
INFO:root:[   24] Training loss: 0.11806248, Validation loss: 0.22861874, Gradient norm: 1.96871860
INFO:root:At the start of the epoch: mem (CPU python)=17698.8046875MB; mem (CPU total)=17436.0859375MB
INFO:root:[   25] Training loss: 0.12180763, Validation loss: 0.21687458, Gradient norm: 2.67993514
INFO:root:At the start of the epoch: mem (CPU python)=17775.0MB; mem (CPU total)=17512.109375MB
INFO:root:[   26] Training loss: 0.11599052, Validation loss: 0.22560297, Gradient norm: 2.27692767
INFO:root:At the start of the epoch: mem (CPU python)=17851.19140625MB; mem (CPU total)=17588.109375MB
INFO:root:[   27] Training loss: 0.11660874, Validation loss: 0.23536270, Gradient norm: 2.05908928
INFO:root:At the start of the epoch: mem (CPU python)=17927.37890625MB; mem (CPU total)=17664.41796875MB
INFO:root:[   28] Training loss: 0.11446433, Validation loss: 0.23830146, Gradient norm: 2.28558992
INFO:root:At the start of the epoch: mem (CPU python)=18003.5703125MB; mem (CPU total)=17740.7265625MB
INFO:root:[   29] Training loss: 0.11345956, Validation loss: 0.24728096, Gradient norm: 2.58177964
INFO:root:At the start of the epoch: mem (CPU python)=18079.765625MB; mem (CPU total)=17816.1484375MB
INFO:root:[   30] Training loss: 0.11357140, Validation loss: 0.23886988, Gradient norm: 2.44673588
INFO:root:At the start of the epoch: mem (CPU python)=18155.953125MB; mem (CPU total)=17892.42578125MB
INFO:root:[   31] Training loss: 0.11126440, Validation loss: 0.23016275, Gradient norm: 2.72532415
INFO:root:At the start of the epoch: mem (CPU python)=18232.14453125MB; mem (CPU total)=17968.9765625MB
INFO:root:[   32] Training loss: 0.10781187, Validation loss: 0.25132552, Gradient norm: 2.42984046
INFO:root:At the start of the epoch: mem (CPU python)=18308.33203125MB; mem (CPU total)=18045.36328125MB
INFO:root:[   33] Training loss: 0.10746553, Validation loss: 0.21468125, Gradient norm: 2.59059295
INFO:root:At the start of the epoch: mem (CPU python)=18384.52734375MB; mem (CPU total)=18121.55859375MB
INFO:root:[   34] Training loss: 0.10569420, Validation loss: 0.23774941, Gradient norm: 2.35173522
INFO:root:At the start of the epoch: mem (CPU python)=18460.71875MB; mem (CPU total)=18197.8671875MB
INFO:root:[   35] Training loss: 0.10658086, Validation loss: 0.23391712, Gradient norm: 2.24715408
INFO:root:At the start of the epoch: mem (CPU python)=18536.90625MB; mem (CPU total)=18274.21484375MB
INFO:root:[   36] Training loss: 0.10244472, Validation loss: 0.23957781, Gradient norm: 2.20472445
INFO:root:At the start of the epoch: mem (CPU python)=18613.1015625MB; mem (CPU total)=18350.265625MB
INFO:root:[   37] Training loss: 0.10469545, Validation loss: 0.24887322, Gradient norm: 2.03243899
INFO:root:At the start of the epoch: mem (CPU python)=18689.2890625MB; mem (CPU total)=18426.56640625MB
INFO:root:[   38] Training loss: 0.10309767, Validation loss: 0.23271526, Gradient norm: 2.12624462
INFO:root:At the start of the epoch: mem (CPU python)=18765.48046875MB; mem (CPU total)=18503.12109375MB
INFO:root:[   39] Training loss: 0.10746421, Validation loss: 0.22299420, Gradient norm: 2.75812248
INFO:root:At the start of the epoch: mem (CPU python)=18841.671875MB; mem (CPU total)=18579.4296875MB
INFO:root:[   40] Training loss: 0.09923530, Validation loss: 0.24270342, Gradient norm: 1.87184576
INFO:root:At the start of the epoch: mem (CPU python)=18917.859375MB; mem (CPU total)=18655.734375MB
INFO:root:[   41] Training loss: 0.10023150, Validation loss: 0.24801304, Gradient norm: 2.19258906
INFO:root:At the start of the epoch: mem (CPU python)=18994.0546875MB; mem (CPU total)=18731.796875MB
INFO:root:[   42] Training loss: 0.10136564, Validation loss: 0.25179093, Gradient norm: 2.47291303
INFO:root:At the start of the epoch: mem (CPU python)=19070.2421875MB; mem (CPU total)=18808.10546875MB
INFO:root:[   43] Training loss: 0.09746987, Validation loss: 0.24314098, Gradient norm: 2.11721576
INFO:root:At the start of the epoch: mem (CPU python)=19146.43359375MB; mem (CPU total)=18884.8984375MB
INFO:root:[   44] Training loss: 0.10176674, Validation loss: 0.23840919, Gradient norm: 2.45073153
INFO:root:At the start of the epoch: mem (CPU python)=19222.625MB; mem (CPU total)=18961.25390625MB
INFO:root:[   45] Training loss: 0.10324874, Validation loss: 0.24266492, Gradient norm: 2.39675082
INFO:root:At the start of the epoch: mem (CPU python)=19298.81640625MB; mem (CPU total)=19037.48046875MB
INFO:root:[   46] Training loss: 0.09502183, Validation loss: 0.23067945, Gradient norm: 1.68062449
INFO:root:At the start of the epoch: mem (CPU python)=19375.0078125MB; mem (CPU total)=19113.7890625MB
INFO:root:[   47] Training loss: 0.09861784, Validation loss: 0.24343470, Gradient norm: 2.25419794
INFO:root:At the start of the epoch: mem (CPU python)=19451.19921875MB; mem (CPU total)=19190.31640625MB
INFO:root:[   48] Training loss: 0.09591252, Validation loss: 0.24626316, Gradient norm: 2.14367080
INFO:root:At the start of the epoch: mem (CPU python)=19527.390625MB; mem (CPU total)=19266.6171875MB
INFO:root:[   49] Training loss: 0.09275753, Validation loss: 0.23448033, Gradient norm: 1.88370984
INFO:root:At the start of the epoch: mem (CPU python)=19603.58203125MB; mem (CPU total)=19342.6796875MB
INFO:root:[   50] Training loss: 0.09955909, Validation loss: 0.23765807, Gradient norm: 2.27788259
INFO:root:At the start of the epoch: mem (CPU python)=19679.7734375MB; mem (CPU total)=19418.984375MB
