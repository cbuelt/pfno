INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=577.73046875MB; mem (CPU total)=1086.921875MB
INFO:root:############### Starting experiment with config file ks/fno_sr_reparam_n_samples_timing.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12456.73046875MB; mem (CPU total)=1122.95703125MB
INFO:root:###1 out of 1 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 25, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=12456.73046875MB; mem (CPU total)=1122.17578125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12456.73046875MB; mem (CPU total)=2480.5625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=2489.30078125MB
INFO:root:[    1] Training loss: 0.74805712, Validation loss: 0.72445828, Gradient norm: 1.09169831
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4206.68359375MB
INFO:root:[    2] Training loss: 0.72022685, Validation loss: 0.72066010, Gradient norm: 0.56365858
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4241.640625MB
INFO:root:[    3] Training loss: 0.71951482, Validation loss: 0.71919684, Gradient norm: 0.76360883
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4278.3359375MB
INFO:root:[    4] Training loss: 0.71860504, Validation loss: 0.71804946, Gradient norm: 0.60551679
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4314.2265625MB
INFO:root:[    5] Training loss: 0.71606975, Validation loss: 0.71281683, Gradient norm: 0.40864528
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4352.31640625MB
INFO:root:[    6] Training loss: 0.70766022, Validation loss: 0.70375697, Gradient norm: 0.63748161
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4390.84375MB
INFO:root:[    7] Training loss: 0.69876970, Validation loss: 0.69493332, Gradient norm: 0.60054171
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4427.375MB
INFO:root:[    8] Training loss: 0.69046469, Validation loss: 0.68868674, Gradient norm: 0.31505568
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4464.28515625MB
INFO:root:[    9] Training loss: 0.68405437, Validation loss: 0.68315959, Gradient norm: 0.29428349
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4502.37890625MB
INFO:root:[   10] Training loss: 0.67878380, Validation loss: 0.67800461, Gradient norm: 0.28755027
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4540.41796875MB
INFO:root:[   11] Training loss: 0.67404827, Validation loss: 0.67288768, Gradient norm: 0.36362156
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4577.66015625MB
INFO:root:[   12] Training loss: 0.66967315, Validation loss: 0.66909857, Gradient norm: 0.34889583
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4615.7109375MB
INFO:root:[   13] Training loss: 0.66587259, Validation loss: 0.66525746, Gradient norm: 0.34630337
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4654.66796875MB
INFO:root:[   14] Training loss: 0.66256337, Validation loss: 0.66256928, Gradient norm: 0.25790061
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4692.16015625MB
INFO:root:[   15] Training loss: 0.65981965, Validation loss: 0.66067639, Gradient norm: 0.29244759
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4729.9375MB
INFO:root:[   16] Training loss: 0.65716536, Validation loss: 0.65808692, Gradient norm: 0.27189319
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4767.0859375MB
INFO:root:[   17] Training loss: 0.65480295, Validation loss: 0.65628805, Gradient norm: 0.26764179
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4804.8203125MB
INFO:root:[   18] Training loss: 0.65268887, Validation loss: 0.65431293, Gradient norm: 0.27072079
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4843.14453125MB
INFO:root:[   19] Training loss: 0.65080686, Validation loss: 0.65266641, Gradient norm: 0.26680173
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4880.97265625MB
INFO:root:[   20] Training loss: 0.64887543, Validation loss: 0.65084900, Gradient norm: 0.28263042
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4919.00390625MB
INFO:root:[   21] Training loss: 0.64704341, Validation loss: 0.64941857, Gradient norm: 0.30686100
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4957.234375MB
INFO:root:[   22] Training loss: 0.64542215, Validation loss: 0.64805853, Gradient norm: 0.24781818
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=4995.01953125MB
INFO:root:[   23] Training loss: 0.64377597, Validation loss: 0.64685586, Gradient norm: 0.26386243
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=5033.01953125MB
INFO:root:[   24] Training loss: 0.64228167, Validation loss: 0.64576821, Gradient norm: 0.23118272
INFO:root:At the start of the epoch: mem (CPU python)=12456.73046875MB; mem (CPU total)=5070.19921875MB
INFO:root:[   25] Training loss: 0.64093152, Validation loss: 0.64351493, Gradient norm: 0.21885449
INFO:root:After finishing all epochs: mem (CPU python)=12456.73046875MB; mem (CPU total)=5106.73046875MB
INFO:root:Training the model took 4536.358s.
INFO:root:Emptying the cuda cache took 0.375s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.91359
INFO:root:EnergyScoreTrain: 0.64375
INFO:root:CRPSTrain: 0.55984
INFO:root:Gaussian NLLTrain: 1.86056
INFO:root:CoverageTrain: 0.78101
INFO:root:IntervalWidthTrain: 3.1631
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.92
INFO:root:EnergyScoreValidation: 0.6483
INFO:root:CRPSValidation: 0.56358
INFO:root:Gaussian NLLValidation: 1.87016
INFO:root:CoverageValidation: 0.77904
INFO:root:IntervalWidthValidation: 3.15767
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.92084
INFO:root:EnergyScoreTest: 0.64895
INFO:root:CRPSTest: 0.56409
INFO:root:Gaussian NLLTest: 1.87216
INFO:root:CoverageTest: 0.77835
INFO:root:IntervalWidthTest: 3.15054
INFO:root:After validation: mem (CPU python)=12456.73046875MB; mem (CPU total)=5154.19140625MB
