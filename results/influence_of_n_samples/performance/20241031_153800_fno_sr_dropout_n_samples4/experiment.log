INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.87890625MB; mem (CPU total)=21601.54296875MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples4.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12454.76171875MB; mem (CPU total)=21649.2421875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.76171875MB; mem (CPU total)=21649.2421875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12454.76171875MB; mem (CPU total)=22994.45703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=23004.8359375MB
INFO:root:[    1] Training loss: 0.75900980, Validation loss: 0.72293694, Gradient norm: 0.63306309
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=24861.640625MB
INFO:root:[    2] Training loss: 0.72201542, Validation loss: 0.72057892, Gradient norm: 0.67691237
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25042.44921875MB
INFO:root:[    3] Training loss: 0.72038754, Validation loss: 0.72051996, Gradient norm: 0.48096805
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25216.90234375MB
INFO:root:[    4] Training loss: 0.71983677, Validation loss: 0.71972629, Gradient norm: 0.41009852
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25389.36328125MB
INFO:root:[    5] Training loss: 0.71931349, Validation loss: 0.71923209, Gradient norm: 0.27213561
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25577.37109375MB
INFO:root:[    6] Training loss: 0.71874922, Validation loss: 0.71948333, Gradient norm: 0.26568882
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25751.08203125MB
INFO:root:[    7] Training loss: 0.71815128, Validation loss: 0.71794273, Gradient norm: 0.30479386
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=25926.12890625MB
INFO:root:[    8] Training loss: 0.71330246, Validation loss: 0.70534636, Gradient norm: 0.34756173
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26110.8203125MB
INFO:root:[    9] Training loss: 0.69588645, Validation loss: 0.68840689, Gradient norm: 0.37925225
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26290.19921875MB
INFO:root:[   10] Training loss: 0.68117755, Validation loss: 0.67654338, Gradient norm: 0.25191881
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26456.55859375MB
INFO:root:[   11] Training loss: 0.67129757, Validation loss: 0.66873846, Gradient norm: 0.29056283
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26643.9296875MB
INFO:root:[   12] Training loss: 0.66481669, Validation loss: 0.66383467, Gradient norm: 0.23602432
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26816.00390625MB
INFO:root:[   13] Training loss: 0.66046079, Validation loss: 0.66002322, Gradient norm: 0.21765924
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=26985.8046875MB
INFO:root:[   14] Training loss: 0.65707729, Validation loss: 0.65726145, Gradient norm: 0.21217730
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=27173.4765625MB
INFO:root:[   15] Training loss: 0.65420795, Validation loss: 0.65473152, Gradient norm: 0.26039722
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=27340.390625MB
INFO:root:[   16] Training loss: 0.65190709, Validation loss: 0.65312293, Gradient norm: 0.22385801
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=27516.59765625MB
INFO:root:[   17] Training loss: 0.64988439, Validation loss: 0.65076541, Gradient norm: 0.26864038
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=27693.01953125MB
INFO:root:[   18] Training loss: 0.64783481, Validation loss: 0.64990974, Gradient norm: 0.25203992
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=27860.34765625MB
INFO:root:[   19] Training loss: 0.64606045, Validation loss: 0.64846213, Gradient norm: 0.20673594
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=28047.30859375MB
INFO:root:[   20] Training loss: 0.64433815, Validation loss: 0.64730680, Gradient norm: 0.24579203
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=28212.33984375MB
INFO:root:[   21] Training loss: 0.64279061, Validation loss: 0.64519846, Gradient norm: 0.20576073
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=28393.53125MB
INFO:root:[   22] Training loss: 0.64115352, Validation loss: 0.64430903, Gradient norm: 0.19700250
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=28562.50390625MB
INFO:root:[   23] Training loss: 0.63968715, Validation loss: 0.64256766, Gradient norm: 0.22542667
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=28736.55078125MB
INFO:root:[   24] Training loss: 0.63813333, Validation loss: 0.64123935, Gradient norm: 0.23069606
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=28909.32421875MB
INFO:root:[   25] Training loss: 0.63689272, Validation loss: 0.63995052, Gradient norm: 0.21977686
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=29024.32421875MB
INFO:root:[   26] Training loss: 0.63557209, Validation loss: 0.63928816, Gradient norm: 0.19385181
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=29122.0078125MB
INFO:root:[   27] Training loss: 0.63426551, Validation loss: 0.63838573, Gradient norm: 0.22972185
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=29296.359375MB
INFO:root:[   28] Training loss: 0.63306804, Validation loss: 0.63743724, Gradient norm: 0.21688249
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=29465.296875MB
INFO:root:[   29] Training loss: 0.63187048, Validation loss: 0.63602420, Gradient norm: 0.23116596
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=29640.2109375MB
INFO:root:[   30] Training loss: 0.63071078, Validation loss: 0.63597606, Gradient norm: 0.20848941
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=29809.94921875MB
INFO:root:[   31] Training loss: 0.62975628, Validation loss: 0.63435299, Gradient norm: 0.22044408
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=29984.48046875MB
INFO:root:[   32] Training loss: 0.62861031, Validation loss: 0.63383694, Gradient norm: 0.22557186
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=30151.875MB
INFO:root:[   33] Training loss: 0.62764928, Validation loss: 0.63322409, Gradient norm: 0.21523428
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=30326.6328125MB
INFO:root:[   34] Training loss: 0.62674323, Validation loss: 0.63246131, Gradient norm: 0.21837560
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=30494.828125MB
INFO:root:[   35] Training loss: 0.62573417, Validation loss: 0.63195866, Gradient norm: 0.22140963
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=30668.296875MB
INFO:root:[   36] Training loss: 0.62490050, Validation loss: 0.63167887, Gradient norm: 0.20772217
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=30837.8671875MB
INFO:root:[   37] Training loss: 0.62414004, Validation loss: 0.63075928, Gradient norm: 0.22610363
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=31008.87109375MB
INFO:root:[   38] Training loss: 0.62333043, Validation loss: 0.62966493, Gradient norm: 0.19763232
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=31180.8671875MB
INFO:root:[   39] Training loss: 0.62235460, Validation loss: 0.62976177, Gradient norm: 0.23729301
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=31336.13671875MB
INFO:root:[   40] Training loss: 0.62174902, Validation loss: 0.62874614, Gradient norm: 0.21402827
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=31512.3125MB
INFO:root:[   41] Training loss: 0.62093779, Validation loss: 0.62817713, Gradient norm: 0.24563509
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=31674.91796875MB
INFO:root:[   42] Training loss: 0.62035340, Validation loss: 0.62796510, Gradient norm: 0.23455590
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=31834.05078125MB
INFO:root:[   43] Training loss: 0.61957772, Validation loss: 0.62757811, Gradient norm: 0.27006364
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=32013.2578125MB
INFO:root:[   44] Training loss: 0.61877615, Validation loss: 0.62726208, Gradient norm: 0.25033349
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=32170.8828125MB
INFO:root:[   45] Training loss: 0.61816260, Validation loss: 0.62636011, Gradient norm: 0.24960966
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=32342.640625MB
INFO:root:[   46] Training loss: 0.61760399, Validation loss: 0.62611496, Gradient norm: 0.25120575
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=32514.28125MB
INFO:root:[   47] Training loss: 0.61697807, Validation loss: 0.62612568, Gradient norm: 0.21729335
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=32669.515625MB
INFO:root:[   48] Training loss: 0.61623361, Validation loss: 0.62542341, Gradient norm: 0.23085819
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=32846.8984375MB
INFO:root:[   49] Training loss: 0.61567328, Validation loss: 0.62537748, Gradient norm: 0.22465256
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=33011.41015625MB
INFO:root:[   50] Training loss: 0.61531910, Validation loss: 0.62489698, Gradient norm: 0.29684620
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=33175.6796875MB
INFO:root:[   51] Training loss: 0.61451505, Validation loss: 0.62485539, Gradient norm: 0.24834256
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=33350.2265625MB
INFO:root:[   52] Training loss: 0.61419696, Validation loss: 0.62457405, Gradient norm: 0.29114654
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=33507.22265625MB
INFO:root:[   53] Training loss: 0.61346208, Validation loss: 0.62405667, Gradient norm: 0.22803501
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=33677.33203125MB
INFO:root:[   54] Training loss: 0.61300198, Validation loss: 0.62422553, Gradient norm: 0.23716937
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=33851.046875MB
INFO:root:[   55] Training loss: 0.61243631, Validation loss: 0.62369185, Gradient norm: 0.30526836
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=34002.8671875MB
INFO:root:[   56] Training loss: 0.61191296, Validation loss: 0.62369834, Gradient norm: 0.28050532
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=34175.91796875MB
INFO:root:[   57] Training loss: 0.61139146, Validation loss: 0.62322637, Gradient norm: 0.26516179
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=34346.9609375MB
INFO:root:[   58] Training loss: 0.61099048, Validation loss: 0.62305460, Gradient norm: 0.24816121
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=34499.2421875MB
INFO:root:[   59] Training loss: 0.61059605, Validation loss: 0.62256721, Gradient norm: 0.30859053
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=34669.68359375MB
INFO:root:[   60] Training loss: 0.61000142, Validation loss: 0.62311713, Gradient norm: 0.28933821
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=34816.8203125MB
INFO:root:[   61] Training loss: 0.60940558, Validation loss: 0.62242853, Gradient norm: 0.27628869
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=34885.2109375MB
INFO:root:[   62] Training loss: 0.60917760, Validation loss: 0.62328192, Gradient norm: 0.27218698
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=35053.25390625MB
INFO:root:[   63] Training loss: 0.60861499, Validation loss: 0.62207488, Gradient norm: 0.32048110
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=35227.05078125MB
INFO:root:[   64] Training loss: 0.60824295, Validation loss: 0.62157480, Gradient norm: 0.34600713
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=35383.6796875MB
INFO:root:[   65] Training loss: 0.60796977, Validation loss: 0.62173822, Gradient norm: 0.27663523
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=35543.15625MB
INFO:root:[   66] Training loss: 0.60741099, Validation loss: 0.62203689, Gradient norm: 0.30155383
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=35713.4140625MB
INFO:root:[   67] Training loss: 0.60706005, Validation loss: 0.62213281, Gradient norm: 0.36720166
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=35879.87890625MB
INFO:root:[   68] Training loss: 0.60667449, Validation loss: 0.62145866, Gradient norm: 0.32103184
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=36032.02734375MB
INFO:root:[   69] Training loss: 0.60615180, Validation loss: 0.62116459, Gradient norm: 0.35874448
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=36197.5546875MB
INFO:root:[   70] Training loss: 0.60576521, Validation loss: 0.62163256, Gradient norm: 0.34731239
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=36366.51171875MB
INFO:root:[   71] Training loss: 0.60543398, Validation loss: 0.62101948, Gradient norm: 0.34290382
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=36527.3984375MB
INFO:root:[   72] Training loss: 0.60499183, Validation loss: 0.62073555, Gradient norm: 0.39325841
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=36679.08203125MB
INFO:root:[   73] Training loss: 0.60463208, Validation loss: 0.62084442, Gradient norm: 0.38560643
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=36846.921875MB
INFO:root:[   74] Training loss: 0.60410147, Validation loss: 0.62122807, Gradient norm: 0.32684036
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=37011.78515625MB
INFO:root:[   75] Training loss: 0.60391269, Validation loss: 0.62094495, Gradient norm: 0.38578177
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=37177.4140625MB
INFO:root:[   76] Training loss: 0.60360858, Validation loss: 0.62094154, Gradient norm: 0.38910583
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=37329.76953125MB
INFO:root:[   77] Training loss: 0.60309350, Validation loss: 0.62053911, Gradient norm: 0.40415458
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=37482.5703125MB
INFO:root:[   78] Training loss: 0.60281009, Validation loss: 0.62079129, Gradient norm: 0.40831866
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=37647.2578125MB
INFO:root:[   79] Training loss: 0.60255051, Validation loss: 0.62098893, Gradient norm: 0.41527076
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=37810.79296875MB
INFO:root:[   80] Training loss: 0.60213791, Validation loss: 0.62102420, Gradient norm: 0.43831688
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=37976.0625MB
INFO:root:[   81] Training loss: 0.60170764, Validation loss: 0.62019159, Gradient norm: 0.38041777
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=38129.26953125MB
INFO:root:[   82] Training loss: 0.60139255, Validation loss: 0.62065709, Gradient norm: 0.44189677
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=38281.5234375MB
INFO:root:[   83] Training loss: 0.60104893, Validation loss: 0.62073317, Gradient norm: 0.50609139
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=38438.19921875MB
INFO:root:[   84] Training loss: 0.60073097, Validation loss: 0.62119471, Gradient norm: 0.46870704
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=38601.125MB
INFO:root:[   85] Training loss: 0.60040860, Validation loss: 0.62014067, Gradient norm: 0.45106493
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=38764.48046875MB
INFO:root:[   86] Training loss: 0.60002584, Validation loss: 0.62050244, Gradient norm: 0.45656900
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=38927.94921875MB
INFO:root:[   87] Training loss: 0.59973548, Validation loss: 0.62174176, Gradient norm: 0.53249927
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=39085.4765625MB
INFO:root:[   88] Training loss: 0.59967546, Validation loss: 0.62075322, Gradient norm: 1.01222920
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=39237.98046875MB
INFO:root:[   89] Training loss: 0.59936484, Validation loss: 0.62007024, Gradient norm: 0.50957576
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=39390.25390625MB
INFO:root:[   90] Training loss: 0.59914618, Validation loss: 0.62067906, Gradient norm: 0.72826224
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=39542.9375MB
INFO:root:[   91] Training loss: 0.59903385, Validation loss: 0.62080491, Gradient norm: 0.84254438
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=39700.2265625MB
INFO:root:[   92] Training loss: 0.59938795, Validation loss: 0.62170407, Gradient norm: 2.29713261
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=39858.38671875MB
INFO:root:[   93] Training loss: 0.59895065, Validation loss: 0.62148343, Gradient norm: 1.91964441
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=40019.7734375MB
INFO:root:[   94] Training loss: 0.59828446, Validation loss: 0.62070271, Gradient norm: 0.89328163
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=40180.90234375MB
INFO:root:[   95] Training loss: 0.59794918, Validation loss: 0.62085033, Gradient norm: 0.36432775
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=40344.02734375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   96] Training loss: 0.59736496, Validation loss: 0.62092758, Gradient norm: 0.40490166
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=40497.015625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   97] Training loss: 0.59511394, Validation loss: 0.62045827, Gradient norm: 0.33908587
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=40650.04296875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   98] Training loss: 0.59384475, Validation loss: 0.61995116, Gradient norm: 0.24274626
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=40804.3359375MB
INFO:root:[   99] Training loss: 0.59316190, Validation loss: 0.61986692, Gradient norm: 0.20315586
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=40956.78515625MB
INFO:root:[  100] Training loss: 0.59309838, Validation loss: 0.61985720, Gradient norm: 0.19686558
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=41109.5703125MB
INFO:root:[  101] Training loss: 0.59302803, Validation loss: 0.62037204, Gradient norm: 0.20392408
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=41262.66796875MB
INFO:root:[  102] Training loss: 0.59291873, Validation loss: 0.62054161, Gradient norm: 0.19831971
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=41418.7109375MB
INFO:root:[  103] Training loss: 0.59296504, Validation loss: 0.61980086, Gradient norm: 0.21388278
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=41577.8671875MB
INFO:root:[  104] Training loss: 0.59294727, Validation loss: 0.61981479, Gradient norm: 0.21807710
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=41678.0625MB
INFO:root:[  105] Training loss: 0.59283944, Validation loss: 0.62063036, Gradient norm: 0.21551070
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8163.44140625MB
INFO:root:[  106] Training loss: 0.59284836, Validation loss: 0.62043478, Gradient norm: 0.24256273
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8200.734375MB
INFO:root:[  107] Training loss: 0.59269298, Validation loss: 0.62003234, Gradient norm: 0.21862070
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8238.2734375MB
INFO:root:[  108] Training loss: 0.59279273, Validation loss: 0.62038575, Gradient norm: 0.24740335
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8276.32421875MB
INFO:root:[  109] Training loss: 0.59266046, Validation loss: 0.62062512, Gradient norm: 0.23027228
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8314.109375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  110] Training loss: 0.59273184, Validation loss: 0.62054564, Gradient norm: 0.23414135
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8352.24609375MB
INFO:root:[  111] Training loss: 0.59241285, Validation loss: 0.62044814, Gradient norm: 0.20413690
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8390.8359375MB
INFO:root:[  112] Training loss: 0.59238162, Validation loss: 0.62049089, Gradient norm: 0.20582129
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8429.27734375MB
INFO:root:EP 112: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12454.76171875MB; mem (CPU total)=8468.078125MB
INFO:root:Training the model took 20508.678s.
INFO:root:Emptying the cuda cache took 0.376s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84248
INFO:root:EnergyScoreTrain: 0.59347
INFO:root:CRPSTrain: 0.51009
INFO:root:Gaussian NLLTrain: 2.06134
INFO:root:CoverageTrain: 0.81575
INFO:root:IntervalWidthTrain: 3.12682
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88202
INFO:root:EnergyScoreValidation: 0.62121
INFO:root:CRPSValidation: 0.53317
INFO:root:Gaussian NLLValidation: 2.12771
INFO:root:CoverageValidation: 0.80293
INFO:root:IntervalWidthValidation: 3.12024
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88232
INFO:root:EnergyScoreTest: 0.62141
INFO:root:CRPSTest: 0.53335
INFO:root:Gaussian NLLTest: 2.12461
INFO:root:CoverageTest: 0.80254
INFO:root:IntervalWidthTest: 3.11531
INFO:root:After validation: mem (CPU python)=12454.76171875MB; mem (CPU total)=8509.17578125MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.76171875MB; mem (CPU total)=8508.95703125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 157286400
INFO:root:After setting up the model: mem (CPU python)=12454.76171875MB; mem (CPU total)=8509.94140625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8510.1875MB
INFO:root:[    1] Training loss: 0.76387808, Validation loss: 0.72223281, Gradient norm: 0.87122181
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8550.30078125MB
INFO:root:[    2] Training loss: 0.72083140, Validation loss: 0.72023202, Gradient norm: 0.50880133
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8587.55078125MB
INFO:root:[    3] Training loss: 0.71996209, Validation loss: 0.72020905, Gradient norm: 0.47905385
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8625.32421875MB
INFO:root:[    4] Training loss: 0.71942425, Validation loss: 0.71975452, Gradient norm: 0.36250777
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8662.69921875MB
INFO:root:[    5] Training loss: 0.71886192, Validation loss: 0.71856985, Gradient norm: 0.34564522
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8701.11328125MB
INFO:root:[    6] Training loss: 0.71820521, Validation loss: 0.71791451, Gradient norm: 0.40715706
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8739.65234375MB
INFO:root:[    7] Training loss: 0.71559277, Validation loss: 0.71179228, Gradient norm: 0.34733040
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8777.2890625MB
INFO:root:[    8] Training loss: 0.70473168, Validation loss: 0.69822406, Gradient norm: 0.34012780
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8815.66796875MB
INFO:root:[    9] Training loss: 0.69160740, Validation loss: 0.68692006, Gradient norm: 0.36335589
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8853.66015625MB
INFO:root:[   10] Training loss: 0.68126697, Validation loss: 0.67757479, Gradient norm: 0.25682380
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8891.6953125MB
INFO:root:[   11] Training loss: 0.67348013, Validation loss: 0.67069104, Gradient norm: 0.20489512
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8928.80859375MB
INFO:root:[   12] Training loss: 0.66719773, Validation loss: 0.66513128, Gradient norm: 0.21306696
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=8966.4375MB
INFO:root:[   13] Training loss: 0.66216403, Validation loss: 0.66105261, Gradient norm: 0.23389758
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9005.234375MB
INFO:root:[   14] Training loss: 0.65826381, Validation loss: 0.65795595, Gradient norm: 0.22269795
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9043.30078125MB
INFO:root:[   15] Training loss: 0.65513751, Validation loss: 0.65500105, Gradient norm: 0.26773807
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9082.14453125MB
INFO:root:[   16] Training loss: 0.65228388, Validation loss: 0.65252248, Gradient norm: 0.25416100
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9120.20703125MB
INFO:root:[   17] Training loss: 0.64981716, Validation loss: 0.65057328, Gradient norm: 0.24466494
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9158.3203125MB
INFO:root:[   18] Training loss: 0.64763706, Validation loss: 0.64805831, Gradient norm: 0.26229567
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9196.15625MB
INFO:root:[   19] Training loss: 0.64554342, Validation loss: 0.64697798, Gradient norm: 0.21652312
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9234.7265625MB
INFO:root:[   20] Training loss: 0.64368865, Validation loss: 0.64478989, Gradient norm: 0.25142268
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9273.02734375MB
INFO:root:[   21] Training loss: 0.64190816, Validation loss: 0.64334097, Gradient norm: 0.21128602
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9309.9296875MB
INFO:root:[   22] Training loss: 0.64022493, Validation loss: 0.64313911, Gradient norm: 0.19726483
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9347.6015625MB
INFO:root:[   23] Training loss: 0.63884944, Validation loss: 0.64069906, Gradient norm: 0.25137627
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9385.5078125MB
INFO:root:[   24] Training loss: 0.63745877, Validation loss: 0.63933522, Gradient norm: 0.30792734
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9423.2734375MB
INFO:root:[   25] Training loss: 0.63597273, Validation loss: 0.63815602, Gradient norm: 0.23491906
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9461.87109375MB
INFO:root:[   26] Training loss: 0.63480074, Validation loss: 0.63731068, Gradient norm: 0.25995779
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9500.16796875MB
INFO:root:[   27] Training loss: 0.63351490, Validation loss: 0.63759072, Gradient norm: 0.27185908
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9539.390625MB
INFO:root:[   28] Training loss: 0.63251267, Validation loss: 0.63521402, Gradient norm: 0.22358469
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9577.0390625MB
INFO:root:[   29] Training loss: 0.63139489, Validation loss: 0.63448819, Gradient norm: 0.27531747
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9615.3828125MB
INFO:root:[   30] Training loss: 0.63047526, Validation loss: 0.63411215, Gradient norm: 0.28960376
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9653.1484375MB
INFO:root:[   31] Training loss: 0.62927682, Validation loss: 0.63325890, Gradient norm: 0.26382454
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9691.1953125MB
INFO:root:[   32] Training loss: 0.62847789, Validation loss: 0.63207143, Gradient norm: 0.28879884
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9729.7109375MB
INFO:root:[   33] Training loss: 0.62736594, Validation loss: 0.63134797, Gradient norm: 0.28735814
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9768.7890625MB
INFO:root:[   34] Training loss: 0.62660657, Validation loss: 0.63138885, Gradient norm: 0.23905088
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9806.875MB
INFO:root:[   35] Training loss: 0.62580235, Validation loss: 0.63068132, Gradient norm: 0.28429710
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9845.37890625MB
INFO:root:[   36] Training loss: 0.62508282, Validation loss: 0.63031450, Gradient norm: 0.28723672
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9882.84765625MB
INFO:root:[   37] Training loss: 0.62416856, Validation loss: 0.62984828, Gradient norm: 0.24542773
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9921.359375MB
INFO:root:[   38] Training loss: 0.62358366, Validation loss: 0.62968376, Gradient norm: 0.34265388
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9959.91796875MB
INFO:root:[   39] Training loss: 0.62289183, Validation loss: 0.62786944, Gradient norm: 0.29683249
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=9998.1875MB
INFO:root:[   40] Training loss: 0.62209048, Validation loss: 0.62884194, Gradient norm: 0.33916617
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10035.79296875MB
INFO:root:[   41] Training loss: 0.62137331, Validation loss: 0.62737394, Gradient norm: 0.34515246
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10073.80859375MB
INFO:root:[   42] Training loss: 0.62072046, Validation loss: 0.62711931, Gradient norm: 0.33698653
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10111.82421875MB
INFO:root:[   43] Training loss: 0.62010451, Validation loss: 0.62699364, Gradient norm: 0.30341282
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10148.88671875MB
INFO:root:[   44] Training loss: 0.61953769, Validation loss: 0.62602601, Gradient norm: 0.30866753
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10186.63671875MB
INFO:root:[   45] Training loss: 0.61897137, Validation loss: 0.62567618, Gradient norm: 0.33986820
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10226.23046875MB
INFO:root:[   46] Training loss: 0.61832907, Validation loss: 0.62542573, Gradient norm: 0.33566649
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10264.19921875MB
INFO:root:[   47] Training loss: 0.61782515, Validation loss: 0.62487064, Gradient norm: 0.36897891
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10301.98046875MB
INFO:root:[   48] Training loss: 0.61730631, Validation loss: 0.62454083, Gradient norm: 0.32891782
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10340.3671875MB
INFO:root:[   49] Training loss: 0.61665463, Validation loss: 0.62471157, Gradient norm: 0.35762872
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10378.98046875MB
INFO:root:[   50] Training loss: 0.61607098, Validation loss: 0.62378616, Gradient norm: 0.40319423
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10416.921875MB
INFO:root:[   51] Training loss: 0.61564271, Validation loss: 0.62403527, Gradient norm: 0.37025381
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10456.51953125MB
INFO:root:[   52] Training loss: 0.61513617, Validation loss: 0.62361269, Gradient norm: 0.43696903
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10494.2734375MB
INFO:root:[   53] Training loss: 0.61449656, Validation loss: 0.62360025, Gradient norm: 0.40289746
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10531.9921875MB
INFO:root:[   54] Training loss: 0.61428522, Validation loss: 0.62339285, Gradient norm: 0.41202802
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10570.140625MB
INFO:root:[   55] Training loss: 0.61388254, Validation loss: 0.62296087, Gradient norm: 0.53551872
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10607.92578125MB
INFO:root:[   56] Training loss: 0.61328324, Validation loss: 0.62229044, Gradient norm: 0.42044041
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10645.4453125MB
INFO:root:[   57] Training loss: 0.61344019, Validation loss: 0.62197498, Gradient norm: 0.88684280
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10683.53125MB
INFO:root:[   58] Training loss: 0.61249498, Validation loss: 0.62149816, Gradient norm: 0.41243219
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10721.99609375MB
INFO:root:[   59] Training loss: 0.61192148, Validation loss: 0.62197078, Gradient norm: 0.40955007
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10761.55078125MB
INFO:root:[   60] Training loss: 0.61169560, Validation loss: 0.62215215, Gradient norm: 0.51026773
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10799.4296875MB
INFO:root:[   61] Training loss: 0.61134515, Validation loss: 0.62172592, Gradient norm: 0.54650394
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10838.03125MB
INFO:root:[   62] Training loss: 0.61114138, Validation loss: 0.62074640, Gradient norm: 0.78156280
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10876.0859375MB
INFO:root:[   63] Training loss: 0.61039817, Validation loss: 0.62244720, Gradient norm: 0.49600971
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10914.57421875MB
INFO:root:[   64] Training loss: 0.61020259, Validation loss: 0.62192627, Gradient norm: 1.17140061
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10952.5859375MB
INFO:root:[   65] Training loss: 0.61005553, Validation loss: 0.62270804, Gradient norm: 1.29448215
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=10990.37890625MB
INFO:root:[   66] Training loss: 0.60950634, Validation loss: 0.62054217, Gradient norm: 0.49272326
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11028.2265625MB
INFO:root:[   67] Training loss: 0.60907248, Validation loss: 0.62071475, Gradient norm: 0.45399945
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11066.4140625MB
INFO:root:[   68] Training loss: 0.60867360, Validation loss: 0.62052012, Gradient norm: 0.53080053
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11104.3046875MB
INFO:root:[   69] Training loss: 0.60838857, Validation loss: 0.62018263, Gradient norm: 0.65350610
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11142.453125MB
INFO:root:[   70] Training loss: 0.60801824, Validation loss: 0.62058506, Gradient norm: 1.24422176
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11180.51953125MB
INFO:root:[   71] Training loss: 0.60772360, Validation loss: 0.62013423, Gradient norm: 1.13517995
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11218.25MB
INFO:root:[   72] Training loss: 0.60817282, Validation loss: 0.62062515, Gradient norm: 1.16028011
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11256.37109375MB
INFO:root:[   73] Training loss: 0.60706123, Validation loss: 0.62043209, Gradient norm: 0.72558126
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11293.9921875MB
INFO:root:[   74] Training loss: 0.60699002, Validation loss: 0.61940631, Gradient norm: 0.78134603
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11332.34765625MB
INFO:root:[   75] Training loss: 0.60663222, Validation loss: 0.61949356, Gradient norm: 1.50227594
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11370.72265625MB
INFO:root:[   76] Training loss: 0.60636006, Validation loss: 0.62008843, Gradient norm: 1.42305545
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11409.3203125MB
INFO:root:[   77] Training loss: 0.60675563, Validation loss: 0.61978436, Gradient norm: 1.55920998
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11447.16015625MB
INFO:root:[   78] Training loss: 0.60626488, Validation loss: 0.61979648, Gradient norm: 2.46599345
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11485.046875MB
INFO:root:[   79] Training loss: 0.60624955, Validation loss: 0.62019304, Gradient norm: 2.25899040
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11523.078125MB
INFO:root:[   80] Training loss: 0.60604770, Validation loss: 0.62043055, Gradient norm: 2.14313714
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11561.42578125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   81] Training loss: 0.60605449, Validation loss: 0.62002549, Gradient norm: 2.05675991
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11599.109375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   82] Training loss: 0.60354420, Validation loss: 0.61912926, Gradient norm: 0.32849155
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11637.7265625MB
INFO:root:[   83] Training loss: 0.60208006, Validation loss: 0.61821525, Gradient norm: 0.24212175
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11675.765625MB
INFO:root:[   84] Training loss: 0.60185703, Validation loss: 0.61847765, Gradient norm: 0.24354489
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11713.53515625MB
INFO:root:[   85] Training loss: 0.60172758, Validation loss: 0.61828308, Gradient norm: 0.24765627
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11752.24609375MB
INFO:root:[   86] Training loss: 0.60162157, Validation loss: 0.61825104, Gradient norm: 0.27311031
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11790.2578125MB
INFO:root:[   87] Training loss: 0.60148496, Validation loss: 0.61819271, Gradient norm: 0.26721697
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11828.34765625MB
INFO:root:[   88] Training loss: 0.60139122, Validation loss: 0.61838727, Gradient norm: 0.28593530
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11866.8671875MB
INFO:root:[   89] Training loss: 0.60126164, Validation loss: 0.61791027, Gradient norm: 0.29990108
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11904.890625MB
INFO:root:[   90] Training loss: 0.60123701, Validation loss: 0.61818966, Gradient norm: 0.34476110
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11942.98828125MB
INFO:root:[   91] Training loss: 0.60122607, Validation loss: 0.61819560, Gradient norm: 0.33858136
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=11981.3984375MB
INFO:root:[   92] Training loss: 0.60098509, Validation loss: 0.61837142, Gradient norm: 0.33614086
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=12019.98046875MB
INFO:root:[   93] Training loss: 0.60105164, Validation loss: 0.61832437, Gradient norm: 0.36926528
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=12058.1015625MB
INFO:root:[   94] Training loss: 0.60091052, Validation loss: 0.61854410, Gradient norm: 0.37932798
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=12095.703125MB
INFO:root:[   95] Training loss: 0.60073847, Validation loss: 0.61816140, Gradient norm: 0.35756778
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=12136.04296875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   96] Training loss: 0.60073713, Validation loss: 0.61875709, Gradient norm: 0.41389106
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=12173.63671875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   97] Training loss: 0.60015101, Validation loss: 0.61810487, Gradient norm: 0.33405051
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=12212.265625MB
INFO:root:[   98] Training loss: 0.59981367, Validation loss: 0.61833521, Gradient norm: 0.26167201
INFO:root:At the start of the epoch: mem (CPU python)=12454.76171875MB; mem (CPU total)=12250.27734375MB
INFO:root:EP 98: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12487.78515625MB; mem (CPU total)=12288.73828125MB
INFO:root:Training the model took 18203.45s.
INFO:root:Emptying the cuda cache took 0.379s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86806
INFO:root:EnergyScoreTrain: 0.61147
INFO:root:CRPSTrain: 0.52504
INFO:root:Gaussian NLLTrain: 1.88931
INFO:root:CoverageTrain: 0.80403
INFO:root:IntervalWidthTrain: 3.09039
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88964
INFO:root:EnergyScoreValidation: 0.62695
INFO:root:CRPSValidation: 0.5378
INFO:root:Gaussian NLLValidation: 1.92606
INFO:root:CoverageValidation: 0.79665
INFO:root:IntervalWidthValidation: 3.08319
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8916
INFO:root:EnergyScoreTest: 0.6284
INFO:root:CRPSTest: 0.53912
INFO:root:Gaussian NLLTest: 1.92956
INFO:root:CoverageTest: 0.79618
INFO:root:IntervalWidthTest: 3.08451
INFO:root:After validation: mem (CPU python)=12530.4296875MB; mem (CPU total)=12329.40234375MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=12530.4296875MB; mem (CPU total)=12329.15234375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 157286400
INFO:root:After setting up the model: mem (CPU python)=12530.515625MB; mem (CPU total)=12329.140625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12530.74609375MB; mem (CPU total)=12329.41015625MB
INFO:root:[    1] Training loss: 0.75709969, Validation loss: 0.72079078, Gradient norm: 0.57381460
INFO:root:At the start of the epoch: mem (CPU python)=12568.69140625MB; mem (CPU total)=12369.36328125MB
INFO:root:[    2] Training loss: 0.72028192, Validation loss: 0.71981384, Gradient norm: 0.46516149
INFO:root:At the start of the epoch: mem (CPU python)=12606.890625MB; mem (CPU total)=12407.3203125MB
INFO:root:[    3] Training loss: 0.71954367, Validation loss: 0.71941299, Gradient norm: 0.35975153
INFO:root:At the start of the epoch: mem (CPU python)=12645.0MB; mem (CPU total)=12445.88671875MB
INFO:root:[    4] Training loss: 0.71902146, Validation loss: 0.71888108, Gradient norm: 0.41998153
INFO:root:At the start of the epoch: mem (CPU python)=12683.109375MB; mem (CPU total)=12483.5234375MB
INFO:root:[    5] Training loss: 0.71723562, Validation loss: 0.71404596, Gradient norm: 0.37166568
INFO:root:At the start of the epoch: mem (CPU python)=12721.22265625MB; mem (CPU total)=12521.625MB
INFO:root:[    6] Training loss: 0.70545967, Validation loss: 0.69744270, Gradient norm: 0.33944503
INFO:root:At the start of the epoch: mem (CPU python)=12759.33203125MB; mem (CPU total)=12559.4375MB
INFO:root:[    7] Training loss: 0.68970289, Validation loss: 0.68411928, Gradient norm: 0.26694670
INFO:root:At the start of the epoch: mem (CPU python)=12797.44140625MB; mem (CPU total)=12597.3203125MB
INFO:root:[    8] Training loss: 0.67851936, Validation loss: 0.67478620, Gradient norm: 0.22014542
INFO:root:At the start of the epoch: mem (CPU python)=12835.5546875MB; mem (CPU total)=12635.37109375MB
INFO:root:[    9] Training loss: 0.67065806, Validation loss: 0.66853407, Gradient norm: 0.25631770
INFO:root:At the start of the epoch: mem (CPU python)=12873.6484375MB; mem (CPU total)=12673.7578125MB
INFO:root:[   10] Training loss: 0.66505564, Validation loss: 0.66371091, Gradient norm: 0.32864108
INFO:root:At the start of the epoch: mem (CPU python)=12911.7421875MB; mem (CPU total)=12711.125MB
INFO:root:[   11] Training loss: 0.66070292, Validation loss: 0.66025900, Gradient norm: 0.27933376
INFO:root:At the start of the epoch: mem (CPU python)=12949.8359375MB; mem (CPU total)=12749.96484375MB
INFO:root:[   12] Training loss: 0.65735801, Validation loss: 0.65804934, Gradient norm: 0.26488726
INFO:root:At the start of the epoch: mem (CPU python)=12987.93359375MB; mem (CPU total)=12788.53515625MB
INFO:root:[   13] Training loss: 0.65434536, Validation loss: 0.65588920, Gradient norm: 0.27869508
INFO:root:At the start of the epoch: mem (CPU python)=13026.03125MB; mem (CPU total)=12826.7265625MB
INFO:root:[   14] Training loss: 0.65174434, Validation loss: 0.65231372, Gradient norm: 0.26587650
INFO:root:At the start of the epoch: mem (CPU python)=13064.125MB; mem (CPU total)=12864.1640625MB
INFO:root:[   15] Training loss: 0.64945312, Validation loss: 0.65069962, Gradient norm: 0.24204850
INFO:root:At the start of the epoch: mem (CPU python)=13102.2265625MB; mem (CPU total)=12902.625MB
INFO:root:[   16] Training loss: 0.64729941, Validation loss: 0.64868191, Gradient norm: 0.24412078
INFO:root:At the start of the epoch: mem (CPU python)=13140.3203125MB; mem (CPU total)=12940.76953125MB
INFO:root:[   17] Training loss: 0.64530553, Validation loss: 0.64644894, Gradient norm: 0.26979559
INFO:root:At the start of the epoch: mem (CPU python)=13178.4140625MB; mem (CPU total)=12979.08203125MB
INFO:root:[   18] Training loss: 0.64348086, Validation loss: 0.64596304, Gradient norm: 0.27654606
INFO:root:At the start of the epoch: mem (CPU python)=13216.51171875MB; mem (CPU total)=13017.19921875MB
INFO:root:[   19] Training loss: 0.64172054, Validation loss: 0.64366256, Gradient norm: 0.25294382
INFO:root:At the start of the epoch: mem (CPU python)=13254.60546875MB; mem (CPU total)=13054.35546875MB
INFO:root:[   20] Training loss: 0.64008632, Validation loss: 0.64270722, Gradient norm: 0.31164396
INFO:root:At the start of the epoch: mem (CPU python)=13292.69921875MB; mem (CPU total)=13093.98828125MB
INFO:root:[   21] Training loss: 0.63868285, Validation loss: 0.64215132, Gradient norm: 0.26973545
INFO:root:At the start of the epoch: mem (CPU python)=13330.79296875MB; mem (CPU total)=13132.36328125MB
INFO:root:[   22] Training loss: 0.63708499, Validation loss: 0.63988584, Gradient norm: 0.25566983
INFO:root:At the start of the epoch: mem (CPU python)=13368.890625MB; mem (CPU total)=13170.1953125MB
INFO:root:[   23] Training loss: 0.63578376, Validation loss: 0.64049544, Gradient norm: 0.25156336
INFO:root:At the start of the epoch: mem (CPU python)=13406.98828125MB; mem (CPU total)=13208.81640625MB
INFO:root:[   24] Training loss: 0.63458010, Validation loss: 0.63766813, Gradient norm: 0.28125513
INFO:root:At the start of the epoch: mem (CPU python)=13445.08203125MB; mem (CPU total)=13246.62109375MB
INFO:root:[   25] Training loss: 0.63325226, Validation loss: 0.63658695, Gradient norm: 0.24729198
INFO:root:At the start of the epoch: mem (CPU python)=13483.1796875MB; mem (CPU total)=13284.953125MB
INFO:root:[   26] Training loss: 0.63223196, Validation loss: 0.63625009, Gradient norm: 0.30624249
INFO:root:At the start of the epoch: mem (CPU python)=13521.2734375MB; mem (CPU total)=13323.08203125MB
INFO:root:[   27] Training loss: 0.63101463, Validation loss: 0.63476751, Gradient norm: 0.26823249
INFO:root:At the start of the epoch: mem (CPU python)=13559.3671875MB; mem (CPU total)=13361.09765625MB
INFO:root:[   28] Training loss: 0.62987940, Validation loss: 0.63414741, Gradient norm: 0.25652778
INFO:root:At the start of the epoch: mem (CPU python)=13597.4609375MB; mem (CPU total)=13399.1875MB
INFO:root:[   29] Training loss: 0.62888250, Validation loss: 0.63335744, Gradient norm: 0.26588268
INFO:root:At the start of the epoch: mem (CPU python)=13635.55859375MB; mem (CPU total)=13438.328125MB
INFO:root:[   30] Training loss: 0.62789812, Validation loss: 0.63277592, Gradient norm: 0.28684408
INFO:root:At the start of the epoch: mem (CPU python)=13673.65234375MB; mem (CPU total)=13476.16796875MB
INFO:root:[   31] Training loss: 0.62691286, Validation loss: 0.63202891, Gradient norm: 0.30416071
INFO:root:At the start of the epoch: mem (CPU python)=13711.74609375MB; mem (CPU total)=13514.1328125MB
INFO:root:[   32] Training loss: 0.62617313, Validation loss: 0.63126886, Gradient norm: 0.33862964
INFO:root:At the start of the epoch: mem (CPU python)=13749.84375MB; mem (CPU total)=13552.47265625MB
INFO:root:[   33] Training loss: 0.62511627, Validation loss: 0.63137055, Gradient norm: 0.23553702
INFO:root:At the start of the epoch: mem (CPU python)=13787.94140625MB; mem (CPU total)=13591.34375MB
INFO:root:[   34] Training loss: 0.62427650, Validation loss: 0.62990543, Gradient norm: 0.31083946
INFO:root:At the start of the epoch: mem (CPU python)=13826.03515625MB; mem (CPU total)=13628.7109375MB
INFO:root:[   35] Training loss: 0.62333218, Validation loss: 0.62919038, Gradient norm: 0.28094498
INFO:root:At the start of the epoch: mem (CPU python)=13864.1328125MB; mem (CPU total)=13667.7109375MB
INFO:root:[   36] Training loss: 0.62261653, Validation loss: 0.62868533, Gradient norm: 0.25498249
INFO:root:At the start of the epoch: mem (CPU python)=13902.2265625MB; mem (CPU total)=13705.28125MB
INFO:root:[   37] Training loss: 0.62192642, Validation loss: 0.62853644, Gradient norm: 0.30964979
INFO:root:At the start of the epoch: mem (CPU python)=13940.3203125MB; mem (CPU total)=13743.5078125MB
INFO:root:[   38] Training loss: 0.62115288, Validation loss: 0.62855268, Gradient norm: 0.33596229
INFO:root:At the start of the epoch: mem (CPU python)=13978.41796875MB; mem (CPU total)=13781.9765625MB
INFO:root:[   39] Training loss: 0.62042360, Validation loss: 0.62819551, Gradient norm: 0.32534792
INFO:root:At the start of the epoch: mem (CPU python)=14016.51171875MB; mem (CPU total)=13821.16015625MB
INFO:root:[   40] Training loss: 0.61979163, Validation loss: 0.62716374, Gradient norm: 0.32750034
INFO:root:At the start of the epoch: mem (CPU python)=14054.60546875MB; mem (CPU total)=13858.59765625MB
INFO:root:[   41] Training loss: 0.61896025, Validation loss: 0.62691192, Gradient norm: 0.32586553
INFO:root:At the start of the epoch: mem (CPU python)=14092.703125MB; mem (CPU total)=13896.76171875MB
INFO:root:[   42] Training loss: 0.61827752, Validation loss: 0.62645718, Gradient norm: 0.33801732
INFO:root:At the start of the epoch: mem (CPU python)=14130.80078125MB; mem (CPU total)=13933.5859375MB
INFO:root:[   43] Training loss: 0.61773442, Validation loss: 0.62627363, Gradient norm: 0.33877496
INFO:root:At the start of the epoch: mem (CPU python)=14168.89453125MB; mem (CPU total)=13970.94921875MB
INFO:root:[   44] Training loss: 0.61715654, Validation loss: 0.62636259, Gradient norm: 0.32225908
INFO:root:At the start of the epoch: mem (CPU python)=14206.98828125MB; mem (CPU total)=14009.03515625MB
INFO:root:[   45] Training loss: 0.61669225, Validation loss: 0.62579610, Gradient norm: 0.49569944
INFO:root:At the start of the epoch: mem (CPU python)=14245.08203125MB; mem (CPU total)=14046.99609375MB
INFO:root:[   46] Training loss: 0.61601161, Validation loss: 0.62455535, Gradient norm: 0.33038930
INFO:root:At the start of the epoch: mem (CPU python)=14283.1796875MB; mem (CPU total)=14085.3984375MB
INFO:root:[   47] Training loss: 0.61531884, Validation loss: 0.62464100, Gradient norm: 0.32223573
INFO:root:At the start of the epoch: mem (CPU python)=14321.28125MB; mem (CPU total)=14123.7109375MB
INFO:root:[   48] Training loss: 0.61483231, Validation loss: 0.62387053, Gradient norm: 0.32784023
INFO:root:At the start of the epoch: mem (CPU python)=14359.375MB; mem (CPU total)=14161.1875MB
INFO:root:[   49] Training loss: 0.61416423, Validation loss: 0.62436385, Gradient norm: 0.35219826
INFO:root:At the start of the epoch: mem (CPU python)=14397.47265625MB; mem (CPU total)=14200.078125MB
INFO:root:[   50] Training loss: 0.61391303, Validation loss: 0.62437284, Gradient norm: 0.47588688
INFO:root:At the start of the epoch: mem (CPU python)=14435.56640625MB; mem (CPU total)=14237.62109375MB
INFO:root:[   51] Training loss: 0.61332215, Validation loss: 0.62337427, Gradient norm: 0.35323519
INFO:root:At the start of the epoch: mem (CPU python)=14473.66015625MB; mem (CPU total)=14277.39453125MB
INFO:root:[   52] Training loss: 0.61261174, Validation loss: 0.62277765, Gradient norm: 0.46985310
INFO:root:At the start of the epoch: mem (CPU python)=14511.7578125MB; mem (CPU total)=14316.34765625MB
INFO:root:[   53] Training loss: 0.61219578, Validation loss: 0.62331165, Gradient norm: 0.41168426
INFO:root:At the start of the epoch: mem (CPU python)=14549.8515625MB; mem (CPU total)=14354.1015625MB
INFO:root:[   54] Training loss: 0.61163494, Validation loss: 0.62271288, Gradient norm: 0.42465936
INFO:root:At the start of the epoch: mem (CPU python)=14587.94921875MB; mem (CPU total)=14392.8203125MB
INFO:root:[   55] Training loss: 0.61117396, Validation loss: 0.62236573, Gradient norm: 0.42064171
INFO:root:At the start of the epoch: mem (CPU python)=14626.04296875MB; mem (CPU total)=14430.94140625MB
INFO:root:[   56] Training loss: 0.61081432, Validation loss: 0.62201702, Gradient norm: 0.49981289
INFO:root:At the start of the epoch: mem (CPU python)=14664.140625MB; mem (CPU total)=14468.2578125MB
INFO:root:[   57] Training loss: 0.61031774, Validation loss: 0.62226974, Gradient norm: 0.39186907
INFO:root:At the start of the epoch: mem (CPU python)=14702.234375MB; mem (CPU total)=14506.3828125MB
INFO:root:[   58] Training loss: 0.61001704, Validation loss: 0.62171266, Gradient norm: 0.48668125
INFO:root:At the start of the epoch: mem (CPU python)=14740.328125MB; mem (CPU total)=14544.05078125MB
INFO:root:[   59] Training loss: 0.60929773, Validation loss: 0.62171252, Gradient norm: 0.45311746
INFO:root:At the start of the epoch: mem (CPU python)=14778.42578125MB; mem (CPU total)=14582.19921875MB
INFO:root:[   60] Training loss: 0.60898072, Validation loss: 0.62201826, Gradient norm: 0.48121509
INFO:root:At the start of the epoch: mem (CPU python)=14816.51953125MB; mem (CPU total)=14620.58203125MB
INFO:root:[   61] Training loss: 0.60858259, Validation loss: 0.62123970, Gradient norm: 0.61414473
INFO:root:At the start of the epoch: mem (CPU python)=14854.6171875MB; mem (CPU total)=14658.2421875MB
INFO:root:[   62] Training loss: 0.60929999, Validation loss: 0.62353918, Gradient norm: 1.50622082
INFO:root:At the start of the epoch: mem (CPU python)=14892.71484375MB; mem (CPU total)=14696.828125MB
INFO:root:[   63] Training loss: 0.60900948, Validation loss: 0.62306858, Gradient norm: 2.05618912
INFO:root:At the start of the epoch: mem (CPU python)=14930.8125MB; mem (CPU total)=14734.76171875MB
INFO:root:[   64] Training loss: 0.60826015, Validation loss: 0.62123995, Gradient norm: 1.13778884
INFO:root:At the start of the epoch: mem (CPU python)=14968.90625MB; mem (CPU total)=14773.140625MB
INFO:root:[   65] Training loss: 0.60745683, Validation loss: 0.62131878, Gradient norm: 0.39876585
INFO:root:At the start of the epoch: mem (CPU python)=15007.0MB; mem (CPU total)=14811.72265625MB
INFO:root:[   66] Training loss: 0.60686660, Validation loss: 0.62125356, Gradient norm: 0.45591983
INFO:root:At the start of the epoch: mem (CPU python)=15045.09765625MB; mem (CPU total)=14850.8671875MB
INFO:root:[   67] Training loss: 0.60626657, Validation loss: 0.62061531, Gradient norm: 0.40173657
INFO:root:At the start of the epoch: mem (CPU python)=15083.19140625MB; mem (CPU total)=14889.24609375MB
INFO:root:[   68] Training loss: 0.60591137, Validation loss: 0.61997029, Gradient norm: 0.45384496
INFO:root:At the start of the epoch: mem (CPU python)=15121.28515625MB; mem (CPU total)=14927.0MB
INFO:root:[   69] Training loss: 0.60568647, Validation loss: 0.62076617, Gradient norm: 0.54930861
INFO:root:At the start of the epoch: mem (CPU python)=15159.3828125MB; mem (CPU total)=14964.58203125MB
INFO:root:[   70] Training loss: 0.60507461, Validation loss: 0.62041568, Gradient norm: 0.59500063
INFO:root:At the start of the epoch: mem (CPU python)=15197.4765625MB; mem (CPU total)=15002.55859375MB
INFO:root:[   71] Training loss: 0.60482747, Validation loss: 0.62002776, Gradient norm: 1.07209052
INFO:root:At the start of the epoch: mem (CPU python)=15235.57421875MB; mem (CPU total)=15041.6640625MB
INFO:root:[   72] Training loss: 0.60457653, Validation loss: 0.62035890, Gradient norm: 0.86279464
INFO:root:At the start of the epoch: mem (CPU python)=15273.66796875MB; mem (CPU total)=15079.15234375MB
INFO:root:[   73] Training loss: 0.60397373, Validation loss: 0.61997927, Gradient norm: 0.53036393
INFO:root:At the start of the epoch: mem (CPU python)=15311.765625MB; mem (CPU total)=15117.234375MB
INFO:root:[   74] Training loss: 0.60379827, Validation loss: 0.62055241, Gradient norm: 0.92360898
INFO:root:At the start of the epoch: mem (CPU python)=15349.859375MB; mem (CPU total)=15155.29296875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   75] Training loss: 0.60308976, Validation loss: 0.62147917, Gradient norm: 1.14599582
INFO:root:At the start of the epoch: mem (CPU python)=15387.953125MB; mem (CPU total)=15193.6328125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   76] Training loss: 0.60139054, Validation loss: 0.61943250, Gradient norm: 0.38552071
INFO:root:At the start of the epoch: mem (CPU python)=15426.05078125MB; mem (CPU total)=15231.46484375MB
INFO:root:[   77] Training loss: 0.60007801, Validation loss: 0.61909742, Gradient norm: 0.29009844
INFO:root:At the start of the epoch: mem (CPU python)=15464.14453125MB; mem (CPU total)=15270.1484375MB
INFO:root:[   78] Training loss: 0.59981727, Validation loss: 0.61932073, Gradient norm: 0.25882442
INFO:root:At the start of the epoch: mem (CPU python)=15502.23828125MB; mem (CPU total)=15308.1015625MB
INFO:root:[   79] Training loss: 0.59978479, Validation loss: 0.61931297, Gradient norm: 0.28058927
INFO:root:At the start of the epoch: mem (CPU python)=15540.33203125MB; mem (CPU total)=15345.83203125MB
INFO:root:[   80] Training loss: 0.59961669, Validation loss: 0.61927178, Gradient norm: 0.28847154
INFO:root:At the start of the epoch: mem (CPU python)=15578.4296875MB; mem (CPU total)=15385.484375MB
INFO:root:[   81] Training loss: 0.59948370, Validation loss: 0.61964683, Gradient norm: 0.27895026
INFO:root:At the start of the epoch: mem (CPU python)=15616.52734375MB; mem (CPU total)=15423.96484375MB
INFO:root:[   82] Training loss: 0.59942780, Validation loss: 0.61877512, Gradient norm: 0.31591505
INFO:root:At the start of the epoch: mem (CPU python)=15654.6328125MB; mem (CPU total)=15461.90234375MB
INFO:root:[   83] Training loss: 0.59935141, Validation loss: 0.61894659, Gradient norm: 0.32460741
INFO:root:At the start of the epoch: mem (CPU python)=15692.73046875MB; mem (CPU total)=15499.05078125MB
INFO:root:[   84] Training loss: 0.59937574, Validation loss: 0.61903758, Gradient norm: 0.31928264
INFO:root:At the start of the epoch: mem (CPU python)=15730.82421875MB; mem (CPU total)=15536.546875MB
INFO:root:[   85] Training loss: 0.59913979, Validation loss: 0.61922053, Gradient norm: 0.32191646
INFO:root:At the start of the epoch: mem (CPU python)=15768.91796875MB; mem (CPU total)=15574.1796875MB
INFO:root:[   86] Training loss: 0.59901685, Validation loss: 0.61947031, Gradient norm: 0.34528558
INFO:root:At the start of the epoch: mem (CPU python)=15807.015625MB; mem (CPU total)=15612.41015625MB
INFO:root:[   87] Training loss: 0.59899630, Validation loss: 0.61949471, Gradient norm: 0.35519167
INFO:root:At the start of the epoch: mem (CPU python)=15845.109375MB; mem (CPU total)=15651.3203125MB
INFO:root:[   88] Training loss: 0.59896924, Validation loss: 0.61911164, Gradient norm: 0.35034467
INFO:root:At the start of the epoch: mem (CPU python)=15883.20703125MB; mem (CPU total)=15689.88671875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   89] Training loss: 0.59873176, Validation loss: 0.61944047, Gradient norm: 0.35174680
INFO:root:At the start of the epoch: mem (CPU python)=15921.30078125MB; mem (CPU total)=15727.69921875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   90] Training loss: 0.59822224, Validation loss: 0.61890410, Gradient norm: 0.26683497
INFO:root:At the start of the epoch: mem (CPU python)=15959.3984375MB; mem (CPU total)=15765.3046875MB
INFO:root:[   91] Training loss: 0.59788083, Validation loss: 0.61922479, Gradient norm: 0.23131752
INFO:root:At the start of the epoch: mem (CPU python)=15997.4921875MB; mem (CPU total)=15803.9140625MB
INFO:root:EP 91: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=16035.5859375MB; mem (CPU total)=15842.28515625MB
INFO:root:Training the model took 17211.037s.
INFO:root:Emptying the cuda cache took 0.381s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85424
INFO:root:EnergyScoreTrain: 0.60163
INFO:root:CRPSTrain: 0.51843
INFO:root:Gaussian NLLTrain: 1.88172
INFO:root:CoverageTrain: 0.80493
INFO:root:IntervalWidthTrain: 3.09928
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88202
INFO:root:EnergyScoreValidation: 0.62127
INFO:root:CRPSValidation: 0.53463
INFO:root:Gaussian NLLValidation: 1.92504
INFO:root:CoverageValidation: 0.79642
INFO:root:IntervalWidthValidation: 3.09704
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88301
INFO:root:EnergyScoreTest: 0.62206
INFO:root:CRPSTest: 0.53548
INFO:root:Gaussian NLLTest: 1.92849
INFO:root:CoverageTest: 0.79517
INFO:root:IntervalWidthTest: 3.09
INFO:root:After validation: mem (CPU python)=16078.44921875MB; mem (CPU total)=15883.03125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=16078.44921875MB; mem (CPU total)=15883.03125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 165675008
INFO:root:After setting up the model: mem (CPU python)=16078.4921875MB; mem (CPU total)=15883.03125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=16078.546875MB; mem (CPU total)=15883.2734375MB
INFO:root:[    1] Training loss: 0.75466980, Validation loss: 0.72162802, Gradient norm: 1.06008257
INFO:root:At the start of the epoch: mem (CPU python)=16116.4921875MB; mem (CPU total)=15922.87890625MB
INFO:root:[    2] Training loss: 0.72062916, Validation loss: 0.72078564, Gradient norm: 0.60051144
INFO:root:At the start of the epoch: mem (CPU python)=16154.58203125MB; mem (CPU total)=15960.82421875MB
INFO:root:[    3] Training loss: 0.71994357, Validation loss: 0.72006532, Gradient norm: 0.60760925
INFO:root:At the start of the epoch: mem (CPU python)=16192.6953125MB; mem (CPU total)=16004.14453125MB
INFO:root:[    4] Training loss: 0.71916930, Validation loss: 0.71932642, Gradient norm: 0.35986385
INFO:root:At the start of the epoch: mem (CPU python)=16230.80859375MB; mem (CPU total)=16042.4375MB
INFO:root:[    5] Training loss: 0.71733626, Validation loss: 0.71419134, Gradient norm: 0.41064168
INFO:root:At the start of the epoch: mem (CPU python)=16268.91796875MB; mem (CPU total)=16075.43359375MB
INFO:root:[    6] Training loss: 0.70712534, Validation loss: 0.69836555, Gradient norm: 0.54273516
INFO:root:At the start of the epoch: mem (CPU python)=16307.02734375MB; mem (CPU total)=16114.0MB
INFO:root:[    7] Training loss: 0.69047624, Validation loss: 0.68377212, Gradient norm: 0.40213043
INFO:root:At the start of the epoch: mem (CPU python)=16345.125MB; mem (CPU total)=16152.48828125MB
INFO:root:[    8] Training loss: 0.67894996, Validation loss: 0.67479911, Gradient norm: 0.26430981
INFO:root:At the start of the epoch: mem (CPU python)=16383.21875MB; mem (CPU total)=16191.17578125MB
INFO:root:[    9] Training loss: 0.67144660, Validation loss: 0.66890691, Gradient norm: 0.32840153
INFO:root:At the start of the epoch: mem (CPU python)=16421.3125MB; mem (CPU total)=16230.00390625MB
INFO:root:[   10] Training loss: 0.66634820, Validation loss: 0.66499464, Gradient norm: 0.24538745
INFO:root:At the start of the epoch: mem (CPU python)=16459.40625MB; mem (CPU total)=16267.51953125MB
INFO:root:[   11] Training loss: 0.66268170, Validation loss: 0.66196249, Gradient norm: 0.28835133
INFO:root:At the start of the epoch: mem (CPU python)=16497.50390625MB; mem (CPU total)=16305.85546875MB
INFO:root:[   12] Training loss: 0.65964284, Validation loss: 0.65949975, Gradient norm: 0.33028344
INFO:root:At the start of the epoch: mem (CPU python)=16535.6015625MB; mem (CPU total)=16343.140625MB
INFO:root:[   13] Training loss: 0.65686767, Validation loss: 0.65734193, Gradient norm: 0.28161308
INFO:root:At the start of the epoch: mem (CPU python)=16573.6953125MB; mem (CPU total)=16381.59765625MB
INFO:root:[   14] Training loss: 0.65432560, Validation loss: 0.65492086, Gradient norm: 0.29013100
INFO:root:At the start of the epoch: mem (CPU python)=16611.79296875MB; mem (CPU total)=16419.3828125MB
INFO:root:[   15] Training loss: 0.65221312, Validation loss: 0.65317877, Gradient norm: 0.31687528
INFO:root:At the start of the epoch: mem (CPU python)=16649.88671875MB; mem (CPU total)=16457.7890625MB
INFO:root:[   16] Training loss: 0.65009959, Validation loss: 0.65117191, Gradient norm: 0.27424755
INFO:root:At the start of the epoch: mem (CPU python)=16687.98046875MB; mem (CPU total)=16495.63671875MB
INFO:root:[   17] Training loss: 0.64824718, Validation loss: 0.65090701, Gradient norm: 0.28657819
INFO:root:At the start of the epoch: mem (CPU python)=16726.07421875MB; mem (CPU total)=16533.796875MB
INFO:root:[   18] Training loss: 0.64639934, Validation loss: 0.64824343, Gradient norm: 0.24988044
INFO:root:At the start of the epoch: mem (CPU python)=16764.171875MB; mem (CPU total)=16572.1171875MB
INFO:root:[   19] Training loss: 0.64471529, Validation loss: 0.64648110, Gradient norm: 0.30107587
INFO:root:At the start of the epoch: mem (CPU python)=16802.265625MB; mem (CPU total)=16610.23046875MB
INFO:root:[   20] Training loss: 0.64301306, Validation loss: 0.64509703, Gradient norm: 0.24348134
INFO:root:At the start of the epoch: mem (CPU python)=16840.359375MB; mem (CPU total)=16648.3125MB
INFO:root:[   21] Training loss: 0.64153863, Validation loss: 0.64379379, Gradient norm: 0.33640817
INFO:root:At the start of the epoch: mem (CPU python)=16878.4609375MB; mem (CPU total)=16686.32421875MB
INFO:root:[   22] Training loss: 0.64007806, Validation loss: 0.64296588, Gradient norm: 0.27055334
INFO:root:At the start of the epoch: mem (CPU python)=16916.5546875MB; mem (CPU total)=16724.3828125MB
INFO:root:[   23] Training loss: 0.63861167, Validation loss: 0.64128755, Gradient norm: 0.30777181
INFO:root:At the start of the epoch: mem (CPU python)=16954.6484375MB; mem (CPU total)=16762.60546875MB
INFO:root:[   24] Training loss: 0.63734029, Validation loss: 0.64073986, Gradient norm: 0.28161710
INFO:root:At the start of the epoch: mem (CPU python)=16992.74609375MB; mem (CPU total)=16800.56640625MB
INFO:root:[   25] Training loss: 0.63603090, Validation loss: 0.63893853, Gradient norm: 0.28145603
INFO:root:At the start of the epoch: mem (CPU python)=17030.83984375MB; mem (CPU total)=16838.04296875MB
INFO:root:[   26] Training loss: 0.63467574, Validation loss: 0.63822221, Gradient norm: 0.33116591
INFO:root:At the start of the epoch: mem (CPU python)=17068.93359375MB; mem (CPU total)=16876.5703125MB
INFO:root:[   27] Training loss: 0.63348416, Validation loss: 0.63691341, Gradient norm: 0.29664586
INFO:root:At the start of the epoch: mem (CPU python)=17107.03125MB; mem (CPU total)=16913.921875MB
INFO:root:[   28] Training loss: 0.63246075, Validation loss: 0.63652273, Gradient norm: 0.34571706
INFO:root:At the start of the epoch: mem (CPU python)=17145.12890625MB; mem (CPU total)=16952.25MB
INFO:root:[   29] Training loss: 0.63132519, Validation loss: 0.63520983, Gradient norm: 0.30013204
INFO:root:At the start of the epoch: mem (CPU python)=17183.22265625MB; mem (CPU total)=16990.28125MB
INFO:root:[   30] Training loss: 0.63026686, Validation loss: 0.63486184, Gradient norm: 0.29403738
INFO:root:At the start of the epoch: mem (CPU python)=17221.31640625MB; mem (CPU total)=17028.62109375MB
INFO:root:[   31] Training loss: 0.62929931, Validation loss: 0.63380702, Gradient norm: 0.31478376
INFO:root:At the start of the epoch: mem (CPU python)=17259.4140625MB; mem (CPU total)=17066.90625MB
INFO:root:[   32] Training loss: 0.62828027, Validation loss: 0.63293532, Gradient norm: 0.31497430
INFO:root:At the start of the epoch: mem (CPU python)=17297.5078125MB; mem (CPU total)=17105.11328125MB
INFO:root:[   33] Training loss: 0.62739783, Validation loss: 0.63254698, Gradient norm: 0.31985056
INFO:root:At the start of the epoch: mem (CPU python)=17335.6015625MB; mem (CPU total)=17143.54296875MB
INFO:root:[   34] Training loss: 0.62641442, Validation loss: 0.63175595, Gradient norm: 0.29199967
INFO:root:At the start of the epoch: mem (CPU python)=17373.6953125MB; mem (CPU total)=17182.4453125MB
INFO:root:[   35] Training loss: 0.62564159, Validation loss: 0.63104241, Gradient norm: 0.31258502
INFO:root:At the start of the epoch: mem (CPU python)=17411.79296875MB; mem (CPU total)=17219.8515625MB
INFO:root:[   36] Training loss: 0.62485352, Validation loss: 0.63042423, Gradient norm: 0.32434495
INFO:root:At the start of the epoch: mem (CPU python)=17449.890625MB; mem (CPU total)=17258.171875MB
INFO:root:[   37] Training loss: 0.62403994, Validation loss: 0.62984072, Gradient norm: 0.33359057
INFO:root:At the start of the epoch: mem (CPU python)=17487.984375MB; mem (CPU total)=17296.0625MB
INFO:root:[   38] Training loss: 0.62319743, Validation loss: 0.62949511, Gradient norm: 0.33247501
INFO:root:At the start of the epoch: mem (CPU python)=17526.08203125MB; mem (CPU total)=17335.88671875MB
INFO:root:[   39] Training loss: 0.62243390, Validation loss: 0.62893123, Gradient norm: 0.33849026
INFO:root:At the start of the epoch: mem (CPU python)=17564.17578125MB; mem (CPU total)=17374.12109375MB
INFO:root:[   40] Training loss: 0.62174725, Validation loss: 0.62814773, Gradient norm: 0.33634440
INFO:root:At the start of the epoch: mem (CPU python)=17602.2734375MB; mem (CPU total)=17411.2265625MB
INFO:root:[   41] Training loss: 0.62114821, Validation loss: 0.62778348, Gradient norm: 0.32720873
INFO:root:At the start of the epoch: mem (CPU python)=17640.37109375MB; mem (CPU total)=17450.12109375MB
INFO:root:[   42] Training loss: 0.62035254, Validation loss: 0.62737101, Gradient norm: 0.41308058
INFO:root:At the start of the epoch: mem (CPU python)=17678.4765625MB; mem (CPU total)=17487.921875MB
INFO:root:[   43] Training loss: 0.61965349, Validation loss: 0.62659722, Gradient norm: 0.34597239
INFO:root:At the start of the epoch: mem (CPU python)=17716.57421875MB; mem (CPU total)=17525.98046875MB
INFO:root:[   44] Training loss: 0.61898531, Validation loss: 0.62676502, Gradient norm: 0.30801928
INFO:root:At the start of the epoch: mem (CPU python)=17754.6640625MB; mem (CPU total)=17563.296875MB
INFO:root:[   45] Training loss: 0.61849171, Validation loss: 0.62569694, Gradient norm: 0.37878960
INFO:root:At the start of the epoch: mem (CPU python)=17792.765625MB; mem (CPU total)=17601.40625MB
INFO:root:[   46] Training loss: 0.61776500, Validation loss: 0.62609533, Gradient norm: 0.41182714
INFO:root:At the start of the epoch: mem (CPU python)=17830.859375MB; mem (CPU total)=17639.3046875MB
INFO:root:[   47] Training loss: 0.61735199, Validation loss: 0.62531672, Gradient norm: 0.32071286
INFO:root:At the start of the epoch: mem (CPU python)=17868.953125MB; mem (CPU total)=17678.1875MB
INFO:root:[   48] Training loss: 0.61651893, Validation loss: 0.62511694, Gradient norm: 0.38056261
INFO:root:At the start of the epoch: mem (CPU python)=17907.05078125MB; mem (CPU total)=17716.109375MB
INFO:root:[   49] Training loss: 0.61606038, Validation loss: 0.62610814, Gradient norm: 0.36532098
INFO:root:At the start of the epoch: mem (CPU python)=17945.14453125MB; mem (CPU total)=17753.2421875MB
INFO:root:[   50] Training loss: 0.61531716, Validation loss: 0.62458039, Gradient norm: 0.28877668
INFO:root:At the start of the epoch: mem (CPU python)=17983.2421875MB; mem (CPU total)=17791.23046875MB
INFO:root:[   51] Training loss: 0.61493034, Validation loss: 0.62414051, Gradient norm: 0.41760404
INFO:root:At the start of the epoch: mem (CPU python)=18021.3359375MB; mem (CPU total)=17829.28125MB
INFO:root:[   52] Training loss: 0.61444150, Validation loss: 0.62358119, Gradient norm: 0.37599087
INFO:root:At the start of the epoch: mem (CPU python)=18059.43359375MB; mem (CPU total)=17867.4296875MB
INFO:root:[   53] Training loss: 0.61375216, Validation loss: 0.62312712, Gradient norm: 0.39690529
INFO:root:At the start of the epoch: mem (CPU python)=18097.52734375MB; mem (CPU total)=17906.53125MB
INFO:root:[   54] Training loss: 0.61329100, Validation loss: 0.62357631, Gradient norm: 0.40347514
INFO:root:At the start of the epoch: mem (CPU python)=18135.62109375MB; mem (CPU total)=17944.61328125MB
INFO:root:[   55] Training loss: 0.61290484, Validation loss: 0.62296245, Gradient norm: 0.43223679
INFO:root:At the start of the epoch: mem (CPU python)=18173.71875MB; mem (CPU total)=17982.21875MB
INFO:root:[   56] Training loss: 0.61240062, Validation loss: 0.62290004, Gradient norm: 0.42940959
INFO:root:At the start of the epoch: mem (CPU python)=18211.8125MB; mem (CPU total)=18020.54296875MB
INFO:root:[   57] Training loss: 0.61194956, Validation loss: 0.62242454, Gradient norm: 0.40137532
INFO:root:At the start of the epoch: mem (CPU python)=18249.90625MB; mem (CPU total)=18058.4296875MB
INFO:root:[   58] Training loss: 0.61146395, Validation loss: 0.62246264, Gradient norm: 0.46314163
INFO:root:At the start of the epoch: mem (CPU python)=18288.00390625MB; mem (CPU total)=18097.23828125MB
INFO:root:[   59] Training loss: 0.61097617, Validation loss: 0.62255968, Gradient norm: 0.47381032
INFO:root:At the start of the epoch: mem (CPU python)=18326.09765625MB; mem (CPU total)=18135.31640625MB
INFO:root:[   60] Training loss: 0.61042348, Validation loss: 0.62204834, Gradient norm: 0.42566075
INFO:root:At the start of the epoch: mem (CPU python)=18364.1953125MB; mem (CPU total)=18173.36328125MB
INFO:root:[   61] Training loss: 0.61010953, Validation loss: 0.62226644, Gradient norm: 0.44616996
INFO:root:At the start of the epoch: mem (CPU python)=18402.2890625MB; mem (CPU total)=18211.453125MB
INFO:root:[   62] Training loss: 0.61196332, Validation loss: 0.62404835, Gradient norm: 2.31513068
INFO:root:At the start of the epoch: mem (CPU python)=18440.38671875MB; mem (CPU total)=18250.0703125MB
INFO:root:[   63] Training loss: 0.61088641, Validation loss: 0.62317895, Gradient norm: 1.91459591
INFO:root:At the start of the epoch: mem (CPU python)=18478.48046875MB; mem (CPU total)=18287.9375MB
INFO:root:[   64] Training loss: 0.60931872, Validation loss: 0.62164919, Gradient norm: 0.36563463
INFO:root:At the start of the epoch: mem (CPU python)=18516.57421875MB; mem (CPU total)=18326.046875MB
INFO:root:[   65] Training loss: 0.60871670, Validation loss: 0.62183352, Gradient norm: 0.34576970
INFO:root:At the start of the epoch: mem (CPU python)=18554.671875MB; mem (CPU total)=18364.82421875MB
INFO:root:[   66] Training loss: 0.60820746, Validation loss: 0.62078604, Gradient norm: 0.33860613
INFO:root:At the start of the epoch: mem (CPU python)=18592.76953125MB; mem (CPU total)=18403.4140625MB
INFO:root:[   67] Training loss: 0.60778575, Validation loss: 0.62060340, Gradient norm: 0.42168627
INFO:root:At the start of the epoch: mem (CPU python)=18630.859375MB; mem (CPU total)=18441.78515625MB
INFO:root:[   68] Training loss: 0.60749486, Validation loss: 0.62043406, Gradient norm: 0.41366810
INFO:root:At the start of the epoch: mem (CPU python)=18668.953125MB; mem (CPU total)=18479.921875MB
INFO:root:[   69] Training loss: 0.60700801, Validation loss: 0.62091020, Gradient norm: 0.52867348
INFO:root:At the start of the epoch: mem (CPU python)=18707.05078125MB; mem (CPU total)=18518.34375MB
INFO:root:[   70] Training loss: 0.60644896, Validation loss: 0.62087226, Gradient norm: 0.44838056
INFO:root:At the start of the epoch: mem (CPU python)=18745.1484375MB; mem (CPU total)=18556.27734375MB
INFO:root:[   71] Training loss: 0.60618524, Validation loss: 0.62114027, Gradient norm: 0.68450346
INFO:root:At the start of the epoch: mem (CPU python)=18783.2421875MB; mem (CPU total)=18594.39453125MB
INFO:root:[   72] Training loss: 0.60589698, Validation loss: 0.62075831, Gradient norm: 0.81250243
INFO:root:At the start of the epoch: mem (CPU python)=18821.33984375MB; mem (CPU total)=18633.0078125MB
INFO:root:[   73] Training loss: 0.60584256, Validation loss: 0.62088278, Gradient norm: 1.14589177
INFO:root:At the start of the epoch: mem (CPU python)=18859.43359375MB; mem (CPU total)=18671.1953125MB
INFO:root:[   74] Training loss: 0.60511420, Validation loss: 0.62066687, Gradient norm: 0.69098447
INFO:root:At the start of the epoch: mem (CPU python)=18897.52734375MB; mem (CPU total)=18709.05078125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   75] Training loss: 0.60477467, Validation loss: 0.62156071, Gradient norm: 0.45479536
INFO:root:At the start of the epoch: mem (CPU python)=18935.625MB; mem (CPU total)=18746.1875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   76] Training loss: 0.60279570, Validation loss: 0.61981568, Gradient norm: 0.30370309
INFO:root:At the start of the epoch: mem (CPU python)=18973.72265625MB; mem (CPU total)=18785.13671875MB
INFO:root:[   77] Training loss: 0.60166243, Validation loss: 0.61932308, Gradient norm: 0.22923130
INFO:root:At the start of the epoch: mem (CPU python)=19011.8203125MB; mem (CPU total)=18824.05859375MB
INFO:root:[   78] Training loss: 0.60146800, Validation loss: 0.61929020, Gradient norm: 0.25624172
INFO:root:At the start of the epoch: mem (CPU python)=19049.9140625MB; mem (CPU total)=18861.59765625MB
INFO:root:[   79] Training loss: 0.60131929, Validation loss: 0.61923962, Gradient norm: 0.25454451
INFO:root:At the start of the epoch: mem (CPU python)=19088.01171875MB; mem (CPU total)=18899.24609375MB
INFO:root:[   80] Training loss: 0.60129106, Validation loss: 0.61955401, Gradient norm: 0.26588621
INFO:root:At the start of the epoch: mem (CPU python)=19126.10546875MB; mem (CPU total)=18937.87109375MB
INFO:root:[   81] Training loss: 0.60113095, Validation loss: 0.62007006, Gradient norm: 0.29577078
INFO:root:At the start of the epoch: mem (CPU python)=19164.19921875MB; mem (CPU total)=18975.45703125MB
INFO:root:[   82] Training loss: 0.60120642, Validation loss: 0.61916522, Gradient norm: 0.30215617
INFO:root:At the start of the epoch: mem (CPU python)=19202.296875MB; mem (CPU total)=19014.05859375MB
INFO:root:[   83] Training loss: 0.60110040, Validation loss: 0.61966528, Gradient norm: 0.27744547
INFO:root:At the start of the epoch: mem (CPU python)=19240.390625MB; mem (CPU total)=19051.88671875MB
INFO:root:[   84] Training loss: 0.60080982, Validation loss: 0.61924993, Gradient norm: 0.26871079
INFO:root:At the start of the epoch: mem (CPU python)=19278.484375MB; mem (CPU total)=19089.8984375MB
INFO:root:[   85] Training loss: 0.60077890, Validation loss: 0.61950944, Gradient norm: 0.28714067
INFO:root:At the start of the epoch: mem (CPU python)=19316.578125MB; mem (CPU total)=19128.05859375MB
INFO:root:[   86] Training loss: 0.60074361, Validation loss: 0.61954017, Gradient norm: 0.34094150
INFO:root:At the start of the epoch: mem (CPU python)=19354.6796875MB; mem (CPU total)=19166.30078125MB
INFO:root:[   87] Training loss: 0.60064086, Validation loss: 0.61962418, Gradient norm: 0.35804510
INFO:root:At the start of the epoch: mem (CPU python)=19392.7734375MB; mem (CPU total)=19204.12890625MB
INFO:root:[   88] Training loss: 0.60058930, Validation loss: 0.61927338, Gradient norm: 0.33535787
INFO:root:At the start of the epoch: mem (CPU python)=19430.8671875MB; mem (CPU total)=19243.0078125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   89] Training loss: 0.60055432, Validation loss: 0.61917785, Gradient norm: 0.31950220
INFO:root:At the start of the epoch: mem (CPU python)=19468.96484375MB; mem (CPU total)=19281.12890625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   90] Training loss: 0.59989141, Validation loss: 0.61924918, Gradient norm: 0.25145563
INFO:root:At the start of the epoch: mem (CPU python)=19507.05859375MB; mem (CPU total)=19319.23828125MB
INFO:root:[   91] Training loss: 0.59956408, Validation loss: 0.61964718, Gradient norm: 0.21447136
INFO:root:At the start of the epoch: mem (CPU python)=19545.15234375MB; mem (CPU total)=19358.11328125MB
INFO:root:[   92] Training loss: 0.59934372, Validation loss: 0.61908681, Gradient norm: 0.21526378
INFO:root:At the start of the epoch: mem (CPU python)=19583.25390625MB; mem (CPU total)=19396.2265625MB
INFO:root:[   93] Training loss: 0.59951642, Validation loss: 0.61945789, Gradient norm: 0.20868117
INFO:root:At the start of the epoch: mem (CPU python)=19621.34375MB; mem (CPU total)=19434.58203125MB
INFO:root:[   94] Training loss: 0.59938025, Validation loss: 0.61951570, Gradient norm: 0.20429313
INFO:root:At the start of the epoch: mem (CPU python)=19659.44140625MB; mem (CPU total)=19471.9765625MB
INFO:root:[   95] Training loss: 0.59932393, Validation loss: 0.61962374, Gradient norm: 0.22387962
INFO:root:At the start of the epoch: mem (CPU python)=19697.53515625MB; mem (CPU total)=19511.0MB
INFO:root:[   96] Training loss: 0.59938903, Validation loss: 0.61949042, Gradient norm: 0.25649973
INFO:root:At the start of the epoch: mem (CPU python)=19735.6328125MB; mem (CPU total)=19548.92578125MB
INFO:root:[   97] Training loss: 0.59936397, Validation loss: 0.61944644, Gradient norm: 0.22290928
INFO:root:At the start of the epoch: mem (CPU python)=19773.7265625MB; mem (CPU total)=19587.109375MB
INFO:root:[   98] Training loss: 0.59936012, Validation loss: 0.61938757, Gradient norm: 0.23208307
INFO:root:At the start of the epoch: mem (CPU python)=19811.8203125MB; mem (CPU total)=19625.55859375MB
INFO:root:[   99] Training loss: 0.59932011, Validation loss: 0.61943749, Gradient norm: 0.23324303
INFO:root:At the start of the epoch: mem (CPU python)=19849.91796875MB; mem (CPU total)=19663.765625MB
INFO:root:[  100] Training loss: 0.59929864, Validation loss: 0.61920923, Gradient norm: 0.23574006
INFO:root:At the start of the epoch: mem (CPU python)=19888.01171875MB; mem (CPU total)=19701.15234375MB
INFO:root:[  101] Training loss: 0.59929455, Validation loss: 0.61930720, Gradient norm: 0.22370008
INFO:root:At the start of the epoch: mem (CPU python)=19926.1171875MB; mem (CPU total)=19739.890625MB
INFO:root:EP 101: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19964.2109375MB; mem (CPU total)=19778.01953125MB
INFO:root:Training the model took 19408.251s.
INFO:root:Emptying the cuda cache took 0.383s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85235
INFO:root:EnergyScoreTrain: 0.60045
INFO:root:CRPSTrain: 0.51659
INFO:root:Gaussian NLLTrain: 1.84795
INFO:root:CoverageTrain: 0.81452
INFO:root:IntervalWidthTrain: 3.18685
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88093
INFO:root:EnergyScoreValidation: 0.62037
INFO:root:CRPSValidation: 0.53309
INFO:root:Gaussian NLLValidation: 1.89064
INFO:root:CoverageValidation: 0.80578
INFO:root:IntervalWidthValidation: 3.18312
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88132
INFO:root:EnergyScoreTest: 0.62068
INFO:root:CRPSTest: 0.53357
INFO:root:Gaussian NLLTest: 1.89138
INFO:root:CoverageTest: 0.80469
INFO:root:IntervalWidthTest: 3.17714
INFO:root:After validation: mem (CPU python)=20007.06640625MB; mem (CPU total)=19818.1640625MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=20007.06640625MB; mem (CPU total)=19818.40234375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 165675008
INFO:root:After setting up the model: mem (CPU python)=20007.11328125MB; mem (CPU total)=19818.40234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=20007.1875MB; mem (CPU total)=19818.3984375MB
INFO:root:[    1] Training loss: 0.75797959, Validation loss: 0.72313096, Gradient norm: 0.98209580
INFO:root:At the start of the epoch: mem (CPU python)=20045.12109375MB; mem (CPU total)=21719.1328125MB
INFO:root:[    2] Training loss: 0.72113907, Validation loss: 0.72151967, Gradient norm: 0.56721716
INFO:root:At the start of the epoch: mem (CPU python)=20083.21484375MB; mem (CPU total)=19903.1875MB
INFO:root:[    3] Training loss: 0.71998827, Validation loss: 0.71997529, Gradient norm: 0.41676150
INFO:root:At the start of the epoch: mem (CPU python)=20121.32421875MB; mem (CPU total)=19940.2265625MB
INFO:root:[    4] Training loss: 0.71958431, Validation loss: 0.71964020, Gradient norm: 0.47817345
INFO:root:At the start of the epoch: mem (CPU python)=20159.4375MB; mem (CPU total)=19978.1484375MB
INFO:root:[    5] Training loss: 0.71921786, Validation loss: 0.71922449, Gradient norm: 0.52220517
INFO:root:At the start of the epoch: mem (CPU python)=20197.54296875MB; mem (CPU total)=21859.60546875MB
INFO:root:[    6] Training loss: 0.71862513, Validation loss: 0.71827819, Gradient norm: 0.46900560
INFO:root:At the start of the epoch: mem (CPU python)=20235.64453125MB; mem (CPU total)=21925.21484375MB
INFO:root:[    7] Training loss: 0.71380660, Validation loss: 0.70381270, Gradient norm: 0.32214665
INFO:root:At the start of the epoch: mem (CPU python)=20273.73828125MB; mem (CPU total)=20093.5MB
INFO:root:[    8] Training loss: 0.69261160, Validation loss: 0.68453726, Gradient norm: 0.33547079
INFO:root:At the start of the epoch: mem (CPU python)=20311.83203125MB; mem (CPU total)=20132.0703125MB
INFO:root:[    9] Training loss: 0.67790933, Validation loss: 0.67410725, Gradient norm: 0.28078913
INFO:root:At the start of the epoch: mem (CPU python)=20349.92578125MB; mem (CPU total)=20170.765625MB
INFO:root:[   10] Training loss: 0.66931506, Validation loss: 0.66758115, Gradient norm: 0.23506846
INFO:root:At the start of the epoch: mem (CPU python)=20388.0234375MB; mem (CPU total)=20208.6171875MB
INFO:root:[   11] Training loss: 0.66384486, Validation loss: 0.66345429, Gradient norm: 0.23989788
INFO:root:At the start of the epoch: mem (CPU python)=20426.12109375MB; mem (CPU total)=20246.421875MB
INFO:root:[   12] Training loss: 0.65966780, Validation loss: 0.65981493, Gradient norm: 0.25081215
INFO:root:At the start of the epoch: mem (CPU python)=20464.21484375MB; mem (CPU total)=20284.7890625MB
INFO:root:[   13] Training loss: 0.65637302, Validation loss: 0.65667614, Gradient norm: 0.21962197
INFO:root:At the start of the epoch: mem (CPU python)=20502.3125MB; mem (CPU total)=20324.0390625MB
INFO:root:[   14] Training loss: 0.65367348, Validation loss: 0.65405589, Gradient norm: 0.19018776
INFO:root:At the start of the epoch: mem (CPU python)=20540.40625MB; mem (CPU total)=20362.125MB
INFO:root:[   15] Training loss: 0.65131791, Validation loss: 0.65221412, Gradient norm: 0.20481252
INFO:root:At the start of the epoch: mem (CPU python)=20578.5MB; mem (CPU total)=20400.3984375MB
INFO:root:[   16] Training loss: 0.64918318, Validation loss: 0.65041359, Gradient norm: 0.23782035
INFO:root:At the start of the epoch: mem (CPU python)=20617.359375MB; mem (CPU total)=20438.8671875MB
INFO:root:[   17] Training loss: 0.64701504, Validation loss: 0.64833110, Gradient norm: 0.21922918
INFO:root:At the start of the epoch: mem (CPU python)=20655.44921875MB; mem (CPU total)=20476.828125MB
INFO:root:[   18] Training loss: 0.64524827, Validation loss: 0.64693603, Gradient norm: 0.24034797
INFO:root:At the start of the epoch: mem (CPU python)=20693.54296875MB; mem (CPU total)=20514.60546875MB
INFO:root:[   19] Training loss: 0.64341475, Validation loss: 0.64541929, Gradient norm: 0.23889268
INFO:root:At the start of the epoch: mem (CPU python)=20731.640625MB; mem (CPU total)=20552.91015625MB
INFO:root:[   20] Training loss: 0.64177477, Validation loss: 0.64337024, Gradient norm: 0.27235076
INFO:root:At the start of the epoch: mem (CPU python)=20769.7421875MB; mem (CPU total)=20590.7421875MB
INFO:root:[   21] Training loss: 0.64012634, Validation loss: 0.64287680, Gradient norm: 0.26981286
INFO:root:At the start of the epoch: mem (CPU python)=20807.8359375MB; mem (CPU total)=20629.31640625MB
INFO:root:[   22] Training loss: 0.63859517, Validation loss: 0.64090090, Gradient norm: 0.21919626
INFO:root:At the start of the epoch: mem (CPU python)=20845.9296875MB; mem (CPU total)=20668.3046875MB
INFO:root:[   23] Training loss: 0.63735345, Validation loss: 0.63940755, Gradient norm: 0.28153467
INFO:root:At the start of the epoch: mem (CPU python)=20884.02734375MB; mem (CPU total)=20706.3203125MB
INFO:root:[   24] Training loss: 0.63584629, Validation loss: 0.63823486, Gradient norm: 0.26677890
INFO:root:At the start of the epoch: mem (CPU python)=20922.12109375MB; mem (CPU total)=20744.16796875MB
INFO:root:[   25] Training loss: 0.63442766, Validation loss: 0.63748399, Gradient norm: 0.25262651
INFO:root:At the start of the epoch: mem (CPU python)=20960.21484375MB; mem (CPU total)=20782.7109375MB
INFO:root:[   26] Training loss: 0.63321996, Validation loss: 0.63625703, Gradient norm: 0.26393977
INFO:root:At the start of the epoch: mem (CPU python)=20998.30859375MB; mem (CPU total)=20820.51953125MB
INFO:root:[   27] Training loss: 0.63212632, Validation loss: 0.63496275, Gradient norm: 0.24990101
INFO:root:At the start of the epoch: mem (CPU python)=21036.41015625MB; mem (CPU total)=20858.6640625MB
INFO:root:[   28] Training loss: 0.63103727, Validation loss: 0.63415482, Gradient norm: 0.28291753
INFO:root:At the start of the epoch: mem (CPU python)=21074.5078125MB; mem (CPU total)=20896.73828125MB
INFO:root:[   29] Training loss: 0.62997134, Validation loss: 0.63324069, Gradient norm: 0.25174882
INFO:root:At the start of the epoch: mem (CPU python)=21112.6015625MB; mem (CPU total)=20934.85546875MB
INFO:root:[   30] Training loss: 0.62898217, Validation loss: 0.63287690, Gradient norm: 0.28653086
INFO:root:At the start of the epoch: mem (CPU python)=21150.69921875MB; mem (CPU total)=20972.92578125MB
INFO:root:[   31] Training loss: 0.62783643, Validation loss: 0.63214586, Gradient norm: 0.24721997
INFO:root:At the start of the epoch: mem (CPU python)=21188.79296875MB; mem (CPU total)=21011.25MB
INFO:root:[   32] Training loss: 0.62695008, Validation loss: 0.63160528, Gradient norm: 0.27690279
INFO:root:At the start of the epoch: mem (CPU python)=21226.88671875MB; mem (CPU total)=21049.3046875MB
INFO:root:[   33] Training loss: 0.62599354, Validation loss: 0.63025039, Gradient norm: 0.24457839
INFO:root:At the start of the epoch: mem (CPU python)=21264.98828125MB; mem (CPU total)=21087.43359375MB
INFO:root:[   34] Training loss: 0.62521542, Validation loss: 0.62997674, Gradient norm: 0.28982630
INFO:root:At the start of the epoch: mem (CPU python)=21303.08203125MB; mem (CPU total)=21124.4375MB
INFO:root:[   35] Training loss: 0.62440977, Validation loss: 0.62930514, Gradient norm: 0.28242421
INFO:root:At the start of the epoch: mem (CPU python)=21341.17578125MB; mem (CPU total)=21162.69140625MB
INFO:root:[   36] Training loss: 0.62350740, Validation loss: 0.62856171, Gradient norm: 0.28132547
INFO:root:At the start of the epoch: mem (CPU python)=21379.26953125MB; mem (CPU total)=21201.01171875MB
INFO:root:[   37] Training loss: 0.62278475, Validation loss: 0.62817339, Gradient norm: 0.30222469
INFO:root:At the start of the epoch: mem (CPU python)=21417.3671875MB; mem (CPU total)=21238.78515625MB
INFO:root:[   38] Training loss: 0.62199643, Validation loss: 0.62749648, Gradient norm: 0.30777243
INFO:root:At the start of the epoch: mem (CPU python)=21455.4609375MB; mem (CPU total)=23138.9765625MB
INFO:root:[   39] Training loss: 0.62120160, Validation loss: 0.62692199, Gradient norm: 0.28927000
INFO:root:At the start of the epoch: mem (CPU python)=21493.5546875MB; mem (CPU total)=21315.3359375MB
INFO:root:[   40] Training loss: 0.62057609, Validation loss: 0.62639229, Gradient norm: 0.27947371
INFO:root:At the start of the epoch: mem (CPU python)=21531.65234375MB; mem (CPU total)=21354.17578125MB
INFO:root:[   41] Training loss: 0.61993727, Validation loss: 0.62650185, Gradient norm: 0.33840941
INFO:root:At the start of the epoch: mem (CPU python)=21569.74609375MB; mem (CPU total)=21392.203125MB
INFO:root:[   42] Training loss: 0.61939427, Validation loss: 0.62552005, Gradient norm: 0.32542147
INFO:root:At the start of the epoch: mem (CPU python)=21607.83984375MB; mem (CPU total)=23288.44921875MB
INFO:root:[   43] Training loss: 0.61853736, Validation loss: 0.62605785, Gradient norm: 0.30213171
INFO:root:At the start of the epoch: mem (CPU python)=21645.93359375MB; mem (CPU total)=23326.328125MB
INFO:root:[   44] Training loss: 0.61797171, Validation loss: 0.62515564, Gradient norm: 0.31827411
INFO:root:At the start of the epoch: mem (CPU python)=21684.03515625MB; mem (CPU total)=21505.66796875MB
INFO:root:[   45] Training loss: 0.61731962, Validation loss: 0.62483634, Gradient norm: 0.32960127
INFO:root:At the start of the epoch: mem (CPU python)=21722.12890625MB; mem (CPU total)=23713.28515625MB
INFO:root:[   46] Training loss: 0.61669259, Validation loss: 0.62465536, Gradient norm: 0.34255704
INFO:root:At the start of the epoch: mem (CPU python)=21760.22265625MB; mem (CPU total)=23712.7578125MB
INFO:root:[   47] Training loss: 0.61618738, Validation loss: 0.62374982, Gradient norm: 0.34808678
INFO:root:At the start of the epoch: mem (CPU python)=21798.3203125MB; mem (CPU total)=23749.3671875MB
INFO:root:[   48] Training loss: 0.61556862, Validation loss: 0.62371347, Gradient norm: 0.36972990
INFO:root:At the start of the epoch: mem (CPU python)=21836.4140625MB; mem (CPU total)=21662.15625MB
INFO:root:[   49] Training loss: 0.61498459, Validation loss: 0.62243364, Gradient norm: 0.33587474
INFO:root:At the start of the epoch: mem (CPU python)=21874.5078125MB; mem (CPU total)=21700.57421875MB
INFO:root:[   50] Training loss: 0.61440705, Validation loss: 0.62274067, Gradient norm: 0.31748888
INFO:root:At the start of the epoch: mem (CPU python)=21912.609375MB; mem (CPU total)=21738.06640625MB
INFO:root:[   51] Training loss: 0.61404720, Validation loss: 0.62236507, Gradient norm: 0.34546307
INFO:root:At the start of the epoch: mem (CPU python)=21950.703125MB; mem (CPU total)=21775.7578125MB
INFO:root:[   52] Training loss: 0.61333558, Validation loss: 0.62281866, Gradient norm: 0.36803465
INFO:root:At the start of the epoch: mem (CPU python)=21988.796875MB; mem (CPU total)=21814.1171875MB
INFO:root:[   53] Training loss: 0.61308857, Validation loss: 0.62261756, Gradient norm: 0.36471907
INFO:root:At the start of the epoch: mem (CPU python)=22026.890625MB; mem (CPU total)=21852.5078125MB
INFO:root:[   54] Training loss: 0.61244386, Validation loss: 0.62183429, Gradient norm: 0.39388588
INFO:root:At the start of the epoch: mem (CPU python)=22064.98828125MB; mem (CPU total)=21890.87890625MB
INFO:root:[   55] Training loss: 0.61215623, Validation loss: 0.62249243, Gradient norm: 0.46199723
INFO:root:At the start of the epoch: mem (CPU python)=22103.08203125MB; mem (CPU total)=21930.26171875MB
INFO:root:[   56] Training loss: 0.61175024, Validation loss: 0.62176069, Gradient norm: 0.43165390
INFO:root:At the start of the epoch: mem (CPU python)=22141.1796875MB; mem (CPU total)=21968.609375MB
INFO:root:[   57] Training loss: 0.61102116, Validation loss: 0.62095717, Gradient norm: 0.37176660
INFO:root:At the start of the epoch: mem (CPU python)=22179.27734375MB; mem (CPU total)=22006.76171875MB
INFO:root:[   58] Training loss: 0.61075371, Validation loss: 0.62122415, Gradient norm: 0.45125071
INFO:root:At the start of the epoch: mem (CPU python)=22217.37109375MB; mem (CPU total)=22045.40625MB
INFO:root:[   59] Training loss: 0.61019820, Validation loss: 0.62186841, Gradient norm: 0.41494950
INFO:root:At the start of the epoch: mem (CPU python)=22255.46875MB; mem (CPU total)=22083.140625MB
INFO:root:[   60] Training loss: 0.60979194, Validation loss: 0.62108067, Gradient norm: 0.43472246
INFO:root:At the start of the epoch: mem (CPU python)=22293.5703125MB; mem (CPU total)=22121.08984375MB
INFO:root:[   61] Training loss: 0.60963565, Validation loss: 0.62067130, Gradient norm: 0.63401315
INFO:root:At the start of the epoch: mem (CPU python)=22331.66796875MB; mem (CPU total)=22159.51953125MB
INFO:root:[   62] Training loss: 0.60894596, Validation loss: 0.62085529, Gradient norm: 0.40470668
INFO:root:At the start of the epoch: mem (CPU python)=22369.76171875MB; mem (CPU total)=22197.65234375MB
INFO:root:[   63] Training loss: 0.60855059, Validation loss: 0.62071355, Gradient norm: 0.54128872
INFO:root:At the start of the epoch: mem (CPU python)=22407.85546875MB; mem (CPU total)=22235.3125MB
INFO:root:[   64] Training loss: 0.60814612, Validation loss: 0.61996565, Gradient norm: 0.45858675
INFO:root:At the start of the epoch: mem (CPU python)=22445.953125MB; mem (CPU total)=22273.72265625MB
INFO:root:[   65] Training loss: 0.60781824, Validation loss: 0.62007027, Gradient norm: 0.52238106
INFO:root:At the start of the epoch: mem (CPU python)=22484.046875MB; mem (CPU total)=22311.0078125MB
INFO:root:[   66] Training loss: 0.60729989, Validation loss: 0.61978517, Gradient norm: 0.59101157
INFO:root:At the start of the epoch: mem (CPU python)=22522.140625MB; mem (CPU total)=22349.0703125MB
INFO:root:[   67] Training loss: 0.60695497, Validation loss: 0.62074449, Gradient norm: 0.53734139
INFO:root:At the start of the epoch: mem (CPU python)=22560.23828125MB; mem (CPU total)=22387.4453125MB
INFO:root:[   68] Training loss: 0.60679254, Validation loss: 0.62336549, Gradient norm: 0.62903026
INFO:root:At the start of the epoch: mem (CPU python)=22598.3359375MB; mem (CPU total)=22426.01171875MB
INFO:root:[   69] Training loss: 0.60799041, Validation loss: 0.62079240, Gradient norm: 2.43424381
INFO:root:At the start of the epoch: mem (CPU python)=22636.4296875MB; mem (CPU total)=22463.96484375MB
INFO:root:[   70] Training loss: 0.60693304, Validation loss: 0.62073857, Gradient norm: 1.69099321
INFO:root:At the start of the epoch: mem (CPU python)=22674.5234375MB; mem (CPU total)=22502.2890625MB
INFO:root:[   71] Training loss: 0.60608722, Validation loss: 0.61998769, Gradient norm: 0.39082423
INFO:root:At the start of the epoch: mem (CPU python)=22712.62109375MB; mem (CPU total)=22540.53125MB
INFO:root:[   72] Training loss: 0.60561967, Validation loss: 0.61972941, Gradient norm: 0.41270666
INFO:root:At the start of the epoch: mem (CPU python)=22750.71484375MB; mem (CPU total)=22578.3828125MB
INFO:root:[   73] Training loss: 0.60502063, Validation loss: 0.61982208, Gradient norm: 0.51728208
INFO:root:At the start of the epoch: mem (CPU python)=22788.80859375MB; mem (CPU total)=22617.0234375MB
INFO:root:[   74] Training loss: 0.60473452, Validation loss: 0.61981158, Gradient norm: 0.76934399
INFO:root:At the start of the epoch: mem (CPU python)=22826.90625MB; mem (CPU total)=22654.84375MB
INFO:root:[   75] Training loss: 0.60406814, Validation loss: 0.61895586, Gradient norm: 0.78500616
INFO:root:At the start of the epoch: mem (CPU python)=22865.0MB; mem (CPU total)=22692.8984375MB
INFO:root:[   76] Training loss: 0.60381887, Validation loss: 0.62000389, Gradient norm: 0.47145571
INFO:root:At the start of the epoch: mem (CPU python)=22903.09765625MB; mem (CPU total)=22730.76953125MB
INFO:root:[   77] Training loss: 0.60426549, Validation loss: 0.62174342, Gradient norm: 1.05999957
INFO:root:At the start of the epoch: mem (CPU python)=22941.19140625MB; mem (CPU total)=22768.828125MB
INFO:root:[   78] Training loss: 0.60433909, Validation loss: 0.62007877, Gradient norm: 2.43417725
INFO:root:At the start of the epoch: mem (CPU python)=22979.2890625MB; mem (CPU total)=22806.921875MB
INFO:root:[   79] Training loss: 0.60395705, Validation loss: 0.61933373, Gradient norm: 2.08739352
INFO:root:At the start of the epoch: mem (CPU python)=23017.3828125MB; mem (CPU total)=22845.27734375MB
INFO:root:[   80] Training loss: 0.60344712, Validation loss: 0.62040714, Gradient norm: 1.49057438
INFO:root:At the start of the epoch: mem (CPU python)=23055.4765625MB; mem (CPU total)=22883.05859375MB
INFO:root:[   81] Training loss: 0.60292354, Validation loss: 0.61857127, Gradient norm: 0.39012274
INFO:root:At the start of the epoch: mem (CPU python)=23093.57421875MB; mem (CPU total)=22921.53515625MB
INFO:root:[   82] Training loss: 0.60222921, Validation loss: 0.61917868, Gradient norm: 0.59042801
INFO:root:At the start of the epoch: mem (CPU python)=23131.66796875MB; mem (CPU total)=22959.59765625MB
INFO:root:[   83] Training loss: 0.60190277, Validation loss: 0.61882470, Gradient norm: 0.54630455
INFO:root:At the start of the epoch: mem (CPU python)=23169.765625MB; mem (CPU total)=22997.8359375MB
INFO:root:[   84] Training loss: 0.60137785, Validation loss: 0.61988667, Gradient norm: 0.56493664
INFO:root:At the start of the epoch: mem (CPU python)=23207.86328125MB; mem (CPU total)=23035.6484375MB
INFO:root:[   85] Training loss: 0.60116843, Validation loss: 0.62035025, Gradient norm: 0.76417549
INFO:root:At the start of the epoch: mem (CPU python)=23245.95703125MB; mem (CPU total)=23074.0MB
INFO:root:[   86] Training loss: 0.60059870, Validation loss: 0.61897182, Gradient norm: 0.92299789
INFO:root:At the start of the epoch: mem (CPU python)=23284.05078125MB; mem (CPU total)=23111.7578125MB
INFO:root:[   87] Training loss: 0.60079781, Validation loss: 0.61917402, Gradient norm: 1.06295918
INFO:root:At the start of the epoch: mem (CPU python)=23322.14453125MB; mem (CPU total)=23149.71875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   88] Training loss: 0.60035773, Validation loss: 0.62017925, Gradient norm: 1.22019102
INFO:root:At the start of the epoch: mem (CPU python)=23360.2421875MB; mem (CPU total)=23188.34375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   89] Training loss: 0.59804351, Validation loss: 0.61823486, Gradient norm: 0.47222310
INFO:root:At the start of the epoch: mem (CPU python)=23398.3359375MB; mem (CPU total)=23225.9453125MB
INFO:root:[   90] Training loss: 0.59687114, Validation loss: 0.61823629, Gradient norm: 0.24906064
INFO:root:At the start of the epoch: mem (CPU python)=23436.4296875MB; mem (CPU total)=23264.39453125MB
INFO:root:[   91] Training loss: 0.59658466, Validation loss: 0.61807570, Gradient norm: 0.24648868
INFO:root:At the start of the epoch: mem (CPU python)=23474.53125MB; mem (CPU total)=23302.69140625MB
INFO:root:[   92] Training loss: 0.59656011, Validation loss: 0.61834785, Gradient norm: 0.26243780
INFO:root:At the start of the epoch: mem (CPU python)=23512.62109375MB; mem (CPU total)=23341.046875MB
INFO:root:[   93] Training loss: 0.59638336, Validation loss: 0.61852214, Gradient norm: 0.26654050
INFO:root:At the start of the epoch: mem (CPU python)=23550.71875MB; mem (CPU total)=23379.1796875MB
INFO:root:[   94] Training loss: 0.59633212, Validation loss: 0.61815299, Gradient norm: 0.27991657
INFO:root:At the start of the epoch: mem (CPU python)=23588.8125MB; mem (CPU total)=23417.17578125MB
INFO:root:[   95] Training loss: 0.59628584, Validation loss: 0.61849888, Gradient norm: 0.31898101
INFO:root:At the start of the epoch: mem (CPU python)=23626.91015625MB; mem (CPU total)=23455.234375MB
INFO:root:[   96] Training loss: 0.59612199, Validation loss: 0.61833148, Gradient norm: 0.34068868
INFO:root:At the start of the epoch: mem (CPU python)=23665.00390625MB; mem (CPU total)=23494.234375MB
INFO:root:[   97] Training loss: 0.59612283, Validation loss: 0.61809575, Gradient norm: 0.30363237
INFO:root:At the start of the epoch: mem (CPU python)=23703.09765625MB; mem (CPU total)=23532.58203125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   98] Training loss: 0.59593278, Validation loss: 0.61855811, Gradient norm: 0.36168867
INFO:root:At the start of the epoch: mem (CPU python)=23741.1953125MB; mem (CPU total)=23570.39453125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   99] Training loss: 0.59535051, Validation loss: 0.61827690, Gradient norm: 0.25836188
INFO:root:At the start of the epoch: mem (CPU python)=23779.2890625MB; mem (CPU total)=23608.6484375MB
INFO:root:[  100] Training loss: 0.59509233, Validation loss: 0.61822646, Gradient norm: 0.21491571
INFO:root:At the start of the epoch: mem (CPU python)=23817.38671875MB; mem (CPU total)=23647.36328125MB
INFO:root:EP 100: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=23855.484375MB; mem (CPU total)=23685.48046875MB
INFO:root:Training the model took 19548.601s.
INFO:root:Emptying the cuda cache took 0.386s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85009
INFO:root:EnergyScoreTrain: 0.59875
INFO:root:CRPSTrain: 0.51724
INFO:root:Gaussian NLLTrain: 1.98921
INFO:root:CoverageTrain: 0.80195
INFO:root:IntervalWidthTrain: 3.07707
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88017
INFO:root:EnergyScoreValidation: 0.62006
INFO:root:CRPSValidation: 0.53494
INFO:root:Gaussian NLLValidation: 2.03898
INFO:root:CoverageValidation: 0.79182
INFO:root:IntervalWidthValidation: 3.07345
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88114
INFO:root:EnergyScoreTest: 0.62084
INFO:root:CRPSTest: 0.53576
INFO:root:Gaussian NLLTest: 2.04546
INFO:root:CoverageTest: 0.79008
INFO:root:IntervalWidthTest: 3.05982
INFO:root:After validation: mem (CPU python)=23898.69921875MB; mem (CPU total)=23726.97265625MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=23898.69921875MB; mem (CPU total)=23726.97265625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=23898.7109375MB; mem (CPU total)=23726.97265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=23898.7734375MB; mem (CPU total)=23726.97265625MB
INFO:root:[    1] Training loss: 0.75838311, Validation loss: 0.72138286, Gradient norm: 0.72343927
INFO:root:At the start of the epoch: mem (CPU python)=23936.80078125MB; mem (CPU total)=23767.75390625MB
INFO:root:[    2] Training loss: 0.72072893, Validation loss: 0.72157510, Gradient norm: 0.52910093
INFO:root:At the start of the epoch: mem (CPU python)=23974.89453125MB; mem (CPU total)=23805.51171875MB
INFO:root:[    3] Training loss: 0.71992879, Validation loss: 0.71961292, Gradient norm: 0.45370552
INFO:root:At the start of the epoch: mem (CPU python)=24013.0078125MB; mem (CPU total)=23843.58984375MB
INFO:root:[    4] Training loss: 0.71935700, Validation loss: 0.71917357, Gradient norm: 0.40373542
INFO:root:At the start of the epoch: mem (CPU python)=24051.1171875MB; mem (CPU total)=23881.7421875MB
INFO:root:[    5] Training loss: 0.71799013, Validation loss: 0.71580423, Gradient norm: 0.37441502
INFO:root:At the start of the epoch: mem (CPU python)=24089.2109375MB; mem (CPU total)=23919.79296875MB
INFO:root:[    6] Training loss: 0.71017968, Validation loss: 0.70374019, Gradient norm: 0.36420662
INFO:root:At the start of the epoch: mem (CPU python)=24127.30859375MB; mem (CPU total)=23958.10546875MB
INFO:root:[    7] Training loss: 0.69653437, Validation loss: 0.69199054, Gradient norm: 0.29997443
INFO:root:At the start of the epoch: mem (CPU python)=24165.40234375MB; mem (CPU total)=23996.4609375MB
INFO:root:[    8] Training loss: 0.68655770, Validation loss: 0.68330077, Gradient norm: 0.28163510
INFO:root:At the start of the epoch: mem (CPU python)=24203.5MB; mem (CPU total)=24034.96875MB
INFO:root:[    9] Training loss: 0.67974449, Validation loss: 0.67712408, Gradient norm: 0.25022805
INFO:root:At the start of the epoch: mem (CPU python)=24241.59765625MB; mem (CPU total)=24073.06640625MB
INFO:root:[   10] Training loss: 0.67378517, Validation loss: 0.67187878, Gradient norm: 0.21615214
INFO:root:At the start of the epoch: mem (CPU python)=24279.69921875MB; mem (CPU total)=24107.73828125MB
INFO:root:[   11] Training loss: 0.66866846, Validation loss: 0.66804940, Gradient norm: 0.21391354
INFO:root:At the start of the epoch: mem (CPU python)=24317.79296875MB; mem (CPU total)=24145.56640625MB
INFO:root:[   12] Training loss: 0.66441788, Validation loss: 0.66400176, Gradient norm: 0.22668338
INFO:root:At the start of the epoch: mem (CPU python)=24355.88671875MB; mem (CPU total)=24182.8828125MB
INFO:root:[   13] Training loss: 0.66057786, Validation loss: 0.66076389, Gradient norm: 0.21709082
INFO:root:At the start of the epoch: mem (CPU python)=24393.984375MB; mem (CPU total)=24220.4609375MB
INFO:root:[   14] Training loss: 0.65735420, Validation loss: 0.65782298, Gradient norm: 0.24136322
INFO:root:At the start of the epoch: mem (CPU python)=24432.08203125MB; mem (CPU total)=24258.1953125MB
INFO:root:[   15] Training loss: 0.65453467, Validation loss: 0.65583726, Gradient norm: 0.18331306
INFO:root:At the start of the epoch: mem (CPU python)=24470.1796875MB; mem (CPU total)=24297.17578125MB
INFO:root:[   16] Training loss: 0.65220656, Validation loss: 0.65286861, Gradient norm: 0.20336218
INFO:root:At the start of the epoch: mem (CPU python)=24508.2734375MB; mem (CPU total)=24335.41796875MB
INFO:root:[   17] Training loss: 0.64989629, Validation loss: 0.65111050, Gradient norm: 0.23788773
INFO:root:At the start of the epoch: mem (CPU python)=24546.37109375MB; mem (CPU total)=24373.71875MB
INFO:root:[   18] Training loss: 0.64795493, Validation loss: 0.65001695, Gradient norm: 0.21101159
INFO:root:At the start of the epoch: mem (CPU python)=24584.46484375MB; mem (CPU total)=24411.86328125MB
INFO:root:[   19] Training loss: 0.64602044, Validation loss: 0.64795720, Gradient norm: 0.21433660
INFO:root:At the start of the epoch: mem (CPU python)=24622.55859375MB; mem (CPU total)=24450.11328125MB
INFO:root:[   20] Training loss: 0.64441104, Validation loss: 0.64632442, Gradient norm: 0.20225776
INFO:root:At the start of the epoch: mem (CPU python)=24660.65625MB; mem (CPU total)=24488.05078125MB
INFO:root:[   21] Training loss: 0.64274199, Validation loss: 0.64507212, Gradient norm: 0.25566453
INFO:root:At the start of the epoch: mem (CPU python)=24698.75MB; mem (CPU total)=24525.37890625MB
INFO:root:[   22] Training loss: 0.64113692, Validation loss: 0.64469210, Gradient norm: 0.20201743
INFO:root:At the start of the epoch: mem (CPU python)=24736.84375MB; mem (CPU total)=24564.171875MB
INFO:root:[   23] Training loss: 0.63976774, Validation loss: 0.64299452, Gradient norm: 0.22438997
INFO:root:At the start of the epoch: mem (CPU python)=24774.94140625MB; mem (CPU total)=24602.296875MB
INFO:root:[   24] Training loss: 0.63844232, Validation loss: 0.64164181, Gradient norm: 0.20945039
INFO:root:At the start of the epoch: mem (CPU python)=24813.0390625MB; mem (CPU total)=24641.50390625MB
INFO:root:[   25] Training loss: 0.63698334, Validation loss: 0.64045595, Gradient norm: 0.20649761
INFO:root:At the start of the epoch: mem (CPU python)=24851.14453125MB; mem (CPU total)=24680.328125MB
INFO:root:[   26] Training loss: 0.63578714, Validation loss: 0.63999543, Gradient norm: 0.22655052
INFO:root:At the start of the epoch: mem (CPU python)=24889.2421875MB; mem (CPU total)=24718.828125MB
INFO:root:[   27] Training loss: 0.63454268, Validation loss: 0.63816598, Gradient norm: 0.24988412
INFO:root:At the start of the epoch: mem (CPU python)=24927.3359375MB; mem (CPU total)=24757.65234375MB
INFO:root:[   28] Training loss: 0.63335327, Validation loss: 0.63802973, Gradient norm: 0.19113646
INFO:root:At the start of the epoch: mem (CPU python)=24965.4296875MB; mem (CPU total)=24795.21484375MB
INFO:root:[   29] Training loss: 0.63226569, Validation loss: 0.63676363, Gradient norm: 0.21743424
INFO:root:At the start of the epoch: mem (CPU python)=25003.5234375MB; mem (CPU total)=24833.640625MB
INFO:root:[   30] Training loss: 0.63112425, Validation loss: 0.63649052, Gradient norm: 0.21405659
INFO:root:At the start of the epoch: mem (CPU python)=25041.62109375MB; mem (CPU total)=24871.12890625MB
INFO:root:[   31] Training loss: 0.63018116, Validation loss: 0.63524227, Gradient norm: 0.21636352
INFO:root:At the start of the epoch: mem (CPU python)=25079.71484375MB; mem (CPU total)=24909.00390625MB
INFO:root:[   32] Training loss: 0.62907562, Validation loss: 0.63458698, Gradient norm: 0.24419426
INFO:root:At the start of the epoch: mem (CPU python)=25117.80859375MB; mem (CPU total)=24947.5MB
INFO:root:[   33] Training loss: 0.62822229, Validation loss: 0.63364401, Gradient norm: 0.27141830
INFO:root:At the start of the epoch: mem (CPU python)=25156.0625MB; mem (CPU total)=24984.51953125MB
INFO:root:[   34] Training loss: 0.62713337, Validation loss: 0.63269341, Gradient norm: 0.22635586
INFO:root:At the start of the epoch: mem (CPU python)=25194.16015625MB; mem (CPU total)=25022.30078125MB
INFO:root:[   35] Training loss: 0.62624826, Validation loss: 0.63264040, Gradient norm: 0.23050102
INFO:root:At the start of the epoch: mem (CPU python)=25232.25390625MB; mem (CPU total)=25060.03125MB
INFO:root:[   36] Training loss: 0.62547433, Validation loss: 0.63204623, Gradient norm: 0.21593621
INFO:root:At the start of the epoch: mem (CPU python)=25270.34765625MB; mem (CPU total)=25098.77734375MB
INFO:root:[   37] Training loss: 0.62458082, Validation loss: 0.63164738, Gradient norm: 0.23703247
INFO:root:At the start of the epoch: mem (CPU python)=25308.4453125MB; mem (CPU total)=25138.1484375MB
INFO:root:[   38] Training loss: 0.62380230, Validation loss: 0.63031661, Gradient norm: 0.21086924
INFO:root:At the start of the epoch: mem (CPU python)=25346.5390625MB; mem (CPU total)=25175.80078125MB
INFO:root:[   39] Training loss: 0.62303375, Validation loss: 0.63028941, Gradient norm: 0.24056547
INFO:root:At the start of the epoch: mem (CPU python)=25384.63671875MB; mem (CPU total)=25213.60546875MB
INFO:root:[   40] Training loss: 0.62244455, Validation loss: 0.63033117, Gradient norm: 0.24442486
INFO:root:At the start of the epoch: mem (CPU python)=25422.73046875MB; mem (CPU total)=25251.609375MB
INFO:root:[   41] Training loss: 0.62160235, Validation loss: 0.62894778, Gradient norm: 0.24415175
INFO:root:At the start of the epoch: mem (CPU python)=25460.828125MB; mem (CPU total)=27163.40625MB
INFO:root:[   42] Training loss: 0.62085281, Validation loss: 0.62849744, Gradient norm: 0.24363750
INFO:root:At the start of the epoch: mem (CPU python)=25498.921875MB; mem (CPU total)=25331.453125MB
INFO:root:[   43] Training loss: 0.62016252, Validation loss: 0.62855138, Gradient norm: 0.28495256
INFO:root:At the start of the epoch: mem (CPU python)=25537.01953125MB; mem (CPU total)=25369.28515625MB
INFO:root:[   44] Training loss: 0.61934473, Validation loss: 0.62810527, Gradient norm: 0.23229031
INFO:root:At the start of the epoch: mem (CPU python)=25575.11328125MB; mem (CPU total)=25407.25390625MB
INFO:root:[   45] Training loss: 0.61874360, Validation loss: 0.62822139, Gradient norm: 0.22111222
INFO:root:At the start of the epoch: mem (CPU python)=25613.20703125MB; mem (CPU total)=25444.9453125MB
INFO:root:[   46] Training loss: 0.61816314, Validation loss: 0.62656698, Gradient norm: 0.26438304
INFO:root:At the start of the epoch: mem (CPU python)=25651.30078125MB; mem (CPU total)=25483.04296875MB
INFO:root:[   47] Training loss: 0.61764265, Validation loss: 0.62722179, Gradient norm: 0.24694890
INFO:root:At the start of the epoch: mem (CPU python)=25689.3984375MB; mem (CPU total)=25521.13671875MB
INFO:root:[   48] Training loss: 0.61688095, Validation loss: 0.62668876, Gradient norm: 0.27882639
INFO:root:At the start of the epoch: mem (CPU python)=25727.49609375MB; mem (CPU total)=25558.85546875MB
INFO:root:[   49] Training loss: 0.61638493, Validation loss: 0.62623772, Gradient norm: 0.24579527
INFO:root:At the start of the epoch: mem (CPU python)=25765.58984375MB; mem (CPU total)=27463.0390625MB
INFO:root:[   50] Training loss: 0.61572911, Validation loss: 0.62577949, Gradient norm: 0.26159512
INFO:root:At the start of the epoch: mem (CPU python)=25803.6875MB; mem (CPU total)=25636.296875MB
INFO:root:[   51] Training loss: 0.61499697, Validation loss: 0.62576450, Gradient norm: 0.25128365
INFO:root:At the start of the epoch: mem (CPU python)=25841.78125MB; mem (CPU total)=25673.671875MB
INFO:root:[   52] Training loss: 0.61456146, Validation loss: 0.62544908, Gradient norm: 0.27391455
INFO:root:At the start of the epoch: mem (CPU python)=25879.875MB; mem (CPU total)=25711.09375MB
INFO:root:[   53] Training loss: 0.61423689, Validation loss: 0.62629638, Gradient norm: 0.28152391
INFO:root:At the start of the epoch: mem (CPU python)=25917.96875MB; mem (CPU total)=25749.1796875MB
INFO:root:[   54] Training loss: 0.61346091, Validation loss: 0.62494491, Gradient norm: 0.31794124
INFO:root:At the start of the epoch: mem (CPU python)=25956.06640625MB; mem (CPU total)=25787.34375MB
INFO:root:[   55] Training loss: 0.61295395, Validation loss: 0.62460974, Gradient norm: 0.30237823
INFO:root:At the start of the epoch: mem (CPU python)=25994.16015625MB; mem (CPU total)=27738.453125MB
INFO:root:[   56] Training loss: 0.61243007, Validation loss: 0.62382152, Gradient norm: 0.25686677
INFO:root:At the start of the epoch: mem (CPU python)=26032.25390625MB; mem (CPU total)=25989.05859375MB
INFO:root:[   57] Training loss: 0.61196292, Validation loss: 0.62362867, Gradient norm: 0.24971053
INFO:root:At the start of the epoch: mem (CPU python)=26070.35546875MB; mem (CPU total)=25901.2109375MB
INFO:root:[   58] Training loss: 0.61155842, Validation loss: 0.62458898, Gradient norm: 0.29331717
INFO:root:At the start of the epoch: mem (CPU python)=26108.44921875MB; mem (CPU total)=25939.00390625MB
INFO:root:[   59] Training loss: 0.61095303, Validation loss: 0.62408364, Gradient norm: 0.28484149
INFO:root:At the start of the epoch: mem (CPU python)=26146.54296875MB; mem (CPU total)=25978.72265625MB
INFO:root:[   60] Training loss: 0.61046327, Validation loss: 0.62311722, Gradient norm: 0.35523991
INFO:root:At the start of the epoch: mem (CPU python)=26184.640625MB; mem (CPU total)=26016.8359375MB
INFO:root:[   61] Training loss: 0.60998445, Validation loss: 0.62254249, Gradient norm: 0.29538497
INFO:root:At the start of the epoch: mem (CPU python)=26222.734375MB; mem (CPU total)=26055.67578125MB
INFO:root:[   62] Training loss: 0.60956391, Validation loss: 0.62320115, Gradient norm: 0.29911076
INFO:root:At the start of the epoch: mem (CPU python)=26260.828125MB; mem (CPU total)=26093.90625MB
INFO:root:[   63] Training loss: 0.60908663, Validation loss: 0.62313772, Gradient norm: 0.31016039
INFO:root:At the start of the epoch: mem (CPU python)=26298.921875MB; mem (CPU total)=28032.73046875MB
INFO:root:[   64] Training loss: 0.60858306, Validation loss: 0.62322777, Gradient norm: 0.35475052
INFO:root:At the start of the epoch: mem (CPU python)=26337.01953125MB; mem (CPU total)=26170.3359375MB
INFO:root:[   65] Training loss: 0.60829483, Validation loss: 0.62279470, Gradient norm: 0.36015246
INFO:root:At the start of the epoch: mem (CPU python)=26375.1171875MB; mem (CPU total)=26204.5859375MB
INFO:root:[   66] Training loss: 0.60757100, Validation loss: 0.62295417, Gradient norm: 0.30498285
INFO:root:At the start of the epoch: mem (CPU python)=26413.2109375MB; mem (CPU total)=26242.95703125MB
INFO:root:[   67] Training loss: 0.60743561, Validation loss: 0.62257556, Gradient norm: 0.36308340
INFO:root:At the start of the epoch: mem (CPU python)=26451.3125MB; mem (CPU total)=26281.53125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   68] Training loss: 0.60679741, Validation loss: 0.62324550, Gradient norm: 0.34011327
INFO:root:At the start of the epoch: mem (CPU python)=26489.40625MB; mem (CPU total)=26320.13671875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   69] Training loss: 0.60464149, Validation loss: 0.62142656, Gradient norm: 0.18626993
INFO:root:At the start of the epoch: mem (CPU python)=26527.5MB; mem (CPU total)=26358.015625MB
INFO:root:[   70] Training loss: 0.60349896, Validation loss: 0.62128906, Gradient norm: 0.16683553
INFO:root:At the start of the epoch: mem (CPU python)=26565.59375MB; mem (CPU total)=26395.6640625MB
INFO:root:[   71] Training loss: 0.60327423, Validation loss: 0.62122702, Gradient norm: 0.16155700
INFO:root:At the start of the epoch: mem (CPU python)=26603.69140625MB; mem (CPU total)=26433.96875MB
INFO:root:[   72] Training loss: 0.60319528, Validation loss: 0.62098186, Gradient norm: 0.18116570
INFO:root:At the start of the epoch: mem (CPU python)=26641.78515625MB; mem (CPU total)=26471.8046875MB
INFO:root:[   73] Training loss: 0.60301001, Validation loss: 0.62128545, Gradient norm: 0.15695625
INFO:root:At the start of the epoch: mem (CPU python)=26679.87890625MB; mem (CPU total)=26510.63671875MB
INFO:root:[   74] Training loss: 0.60294792, Validation loss: 0.62144025, Gradient norm: 0.17869441
INFO:root:At the start of the epoch: mem (CPU python)=26717.98046875MB; mem (CPU total)=26548.77734375MB
INFO:root:[   75] Training loss: 0.60283926, Validation loss: 0.62126206, Gradient norm: 0.17592513
INFO:root:At the start of the epoch: mem (CPU python)=26756.07421875MB; mem (CPU total)=26587.125MB
INFO:root:[   76] Training loss: 0.60272134, Validation loss: 0.62123471, Gradient norm: 0.19433128
INFO:root:At the start of the epoch: mem (CPU python)=26794.16796875MB; mem (CPU total)=26625.22265625MB
INFO:root:[   77] Training loss: 0.60266896, Validation loss: 0.62106456, Gradient norm: 0.18681012
INFO:root:At the start of the epoch: mem (CPU python)=26832.265625MB; mem (CPU total)=26663.52734375MB
INFO:root:[   78] Training loss: 0.60253034, Validation loss: 0.62151213, Gradient norm: 0.18468376
INFO:root:At the start of the epoch: mem (CPU python)=26870.359375MB; mem (CPU total)=26701.125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   79] Training loss: 0.60244561, Validation loss: 0.62132177, Gradient norm: 0.19369401
INFO:root:At the start of the epoch: mem (CPU python)=26908.453125MB; mem (CPU total)=26739.87890625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   80] Training loss: 0.60176554, Validation loss: 0.62103182, Gradient norm: 0.17062544
INFO:root:At the start of the epoch: mem (CPU python)=26946.546875MB; mem (CPU total)=26777.9453125MB
INFO:root:[   81] Training loss: 0.60145166, Validation loss: 0.62111550, Gradient norm: 0.13528495
INFO:root:At the start of the epoch: mem (CPU python)=26984.6484375MB; mem (CPU total)=26816.05859375MB
INFO:root:EP 81: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=27022.7421875MB; mem (CPU total)=26854.69140625MB
INFO:root:Training the model took 16136.405s.
INFO:root:Emptying the cuda cache took 0.384s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86798
INFO:root:EnergyScoreTrain: 0.61126
INFO:root:CRPSTrain: 0.52525
INFO:root:Gaussian NLLTrain: 1.85611
INFO:root:CoverageTrain: 0.80896
INFO:root:IntervalWidthTrain: 3.17244
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89221
INFO:root:EnergyScoreValidation: 0.62835
INFO:root:CRPSValidation: 0.53921
INFO:root:Gaussian NLLValidation: 1.8897
INFO:root:CoverageValidation: 0.8016
INFO:root:IntervalWidthValidation: 3.1658
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89337
INFO:root:EnergyScoreTest: 0.62918
INFO:root:CRPSTest: 0.54004
INFO:root:Gaussian NLLTest: 1.89146
INFO:root:CoverageTest: 0.80123
INFO:root:IntervalWidthTest: 3.16507
INFO:root:After validation: mem (CPU python)=27065.3828125MB; mem (CPU total)=26895.10546875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=27065.3828125MB; mem (CPU total)=26894.98046875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 157286400
INFO:root:After setting up the model: mem (CPU python)=27065.6015625MB; mem (CPU total)=26894.98046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=27065.6015625MB; mem (CPU total)=26895.2265625MB
INFO:root:[    1] Training loss: 0.75475257, Validation loss: 0.72139995, Gradient norm: 0.67821938
INFO:root:At the start of the epoch: mem (CPU python)=27103.6640625MB; mem (CPU total)=26935.33984375MB
INFO:root:[    2] Training loss: 0.72060846, Validation loss: 0.72022056, Gradient norm: 0.51954451
INFO:root:At the start of the epoch: mem (CPU python)=27141.765625MB; mem (CPU total)=26973.2421875MB
INFO:root:[    3] Training loss: 0.72000439, Validation loss: 0.71976272, Gradient norm: 0.55851490
INFO:root:At the start of the epoch: mem (CPU python)=27179.859375MB; mem (CPU total)=27010.98046875MB
INFO:root:[    4] Training loss: 0.71889168, Validation loss: 0.71773723, Gradient norm: 0.52993214
INFO:root:At the start of the epoch: mem (CPU python)=27217.95703125MB; mem (CPU total)=27050.33984375MB
INFO:root:[    5] Training loss: 0.71294466, Validation loss: 0.70517703, Gradient norm: 0.49360527
INFO:root:At the start of the epoch: mem (CPU python)=27256.07421875MB; mem (CPU total)=27088.63671875MB
INFO:root:[    6] Training loss: 0.69827583, Validation loss: 0.69230032, Gradient norm: 0.33522630
INFO:root:At the start of the epoch: mem (CPU python)=27294.16796875MB; mem (CPU total)=27127.05859375MB
INFO:root:[    7] Training loss: 0.68815711, Validation loss: 0.68403777, Gradient norm: 0.26094983
INFO:root:At the start of the epoch: mem (CPU python)=27332.26171875MB; mem (CPU total)=27164.58203125MB
INFO:root:[    8] Training loss: 0.67969200, Validation loss: 0.67714261, Gradient norm: 0.24030662
INFO:root:At the start of the epoch: mem (CPU python)=27370.359375MB; mem (CPU total)=27201.81640625MB
INFO:root:[    9] Training loss: 0.67301312, Validation loss: 0.67126620, Gradient norm: 0.31267350
INFO:root:At the start of the epoch: mem (CPU python)=27408.453125MB; mem (CPU total)=27240.4296875MB
INFO:root:[   10] Training loss: 0.66805031, Validation loss: 0.66751544, Gradient norm: 0.27141762
INFO:root:At the start of the epoch: mem (CPU python)=27446.546875MB; mem (CPU total)=27278.66796875MB
INFO:root:[   11] Training loss: 0.66413007, Validation loss: 0.66375681, Gradient norm: 0.23308005
INFO:root:At the start of the epoch: mem (CPU python)=27484.64453125MB; mem (CPU total)=27316.54296875MB
INFO:root:[   12] Training loss: 0.66103604, Validation loss: 0.66106397, Gradient norm: 0.19385995
INFO:root:At the start of the epoch: mem (CPU python)=27522.7421875MB; mem (CPU total)=27354.6328125MB
INFO:root:[   13] Training loss: 0.65823738, Validation loss: 0.65838333, Gradient norm: 0.25784348
INFO:root:At the start of the epoch: mem (CPU python)=27560.83984375MB; mem (CPU total)=27392.8984375MB
INFO:root:[   14] Training loss: 0.65583272, Validation loss: 0.65656213, Gradient norm: 0.25950042
INFO:root:At the start of the epoch: mem (CPU python)=27598.93359375MB; mem (CPU total)=27430.515625MB
INFO:root:[   15] Training loss: 0.65340976, Validation loss: 0.65477897, Gradient norm: 0.20460205
INFO:root:At the start of the epoch: mem (CPU python)=27637.03125MB; mem (CPU total)=27468.59765625MB
INFO:root:[   16] Training loss: 0.65108422, Validation loss: 0.65251910, Gradient norm: 0.26627277
INFO:root:At the start of the epoch: mem (CPU python)=27675.125MB; mem (CPU total)=27507.47265625MB
INFO:root:[   17] Training loss: 0.64905210, Validation loss: 0.65077351, Gradient norm: 0.24272452
INFO:root:At the start of the epoch: mem (CPU python)=27713.21875MB; mem (CPU total)=27545.6796875MB
INFO:root:[   18] Training loss: 0.64709900, Validation loss: 0.64975434, Gradient norm: 0.24528594
INFO:root:At the start of the epoch: mem (CPU python)=27751.31640625MB; mem (CPU total)=27582.6171875MB
INFO:root:[   19] Training loss: 0.64536325, Validation loss: 0.64697032, Gradient norm: 0.24553620
INFO:root:At the start of the epoch: mem (CPU python)=27789.41015625MB; mem (CPU total)=27621.890625MB
INFO:root:[   20] Training loss: 0.64353483, Validation loss: 0.64559994, Gradient norm: 0.24618689
INFO:root:At the start of the epoch: mem (CPU python)=27827.50390625MB; mem (CPU total)=27659.59375MB
INFO:root:[   21] Training loss: 0.64182681, Validation loss: 0.64400404, Gradient norm: 0.28293919
INFO:root:At the start of the epoch: mem (CPU python)=27865.6015625MB; mem (CPU total)=27697.83203125MB
INFO:root:[   22] Training loss: 0.64028183, Validation loss: 0.64295774, Gradient norm: 0.23860876
INFO:root:At the start of the epoch: mem (CPU python)=27903.69921875MB; mem (CPU total)=27735.70703125MB
INFO:root:[   23] Training loss: 0.63876709, Validation loss: 0.64150299, Gradient norm: 0.23038553
INFO:root:At the start of the epoch: mem (CPU python)=27941.79296875MB; mem (CPU total)=27773.50390625MB
INFO:root:[   24] Training loss: 0.63730093, Validation loss: 0.63981930, Gradient norm: 0.25743553
INFO:root:At the start of the epoch: mem (CPU python)=27979.88671875MB; mem (CPU total)=27811.4375MB
INFO:root:[   25] Training loss: 0.63590236, Validation loss: 0.63916550, Gradient norm: 0.29160655
INFO:root:At the start of the epoch: mem (CPU python)=28017.984375MB; mem (CPU total)=27849.5234375MB
INFO:root:[   26] Training loss: 0.63465758, Validation loss: 0.63812043, Gradient norm: 0.29243867
INFO:root:At the start of the epoch: mem (CPU python)=28056.078125MB; mem (CPU total)=27887.93359375MB
INFO:root:[   27] Training loss: 0.63338836, Validation loss: 0.63673269, Gradient norm: 0.26522421
INFO:root:At the start of the epoch: mem (CPU python)=28094.171875MB; mem (CPU total)=27926.1328125MB
INFO:root:[   28] Training loss: 0.63217531, Validation loss: 0.63583581, Gradient norm: 0.22699757
INFO:root:At the start of the epoch: mem (CPU python)=28132.26953125MB; mem (CPU total)=27964.984375MB
INFO:root:[   29] Training loss: 0.63098176, Validation loss: 0.63484404, Gradient norm: 0.24778592
INFO:root:At the start of the epoch: mem (CPU python)=28170.36328125MB; mem (CPU total)=28002.76171875MB
INFO:root:[   30] Training loss: 0.62996316, Validation loss: 0.63376357, Gradient norm: 0.21976640
INFO:root:At the start of the epoch: mem (CPU python)=28208.4609375MB; mem (CPU total)=28041.3515625MB
INFO:root:[   31] Training loss: 0.62896565, Validation loss: 0.63338693, Gradient norm: 0.25444066
INFO:root:At the start of the epoch: mem (CPU python)=28246.5546875MB; mem (CPU total)=28078.53125MB
INFO:root:[   32] Training loss: 0.62800647, Validation loss: 0.63248380, Gradient norm: 0.29040191
INFO:root:At the start of the epoch: mem (CPU python)=28284.65234375MB; mem (CPU total)=28116.703125MB
INFO:root:[   33] Training loss: 0.62698394, Validation loss: 0.63197366, Gradient norm: 0.26362002
INFO:root:At the start of the epoch: mem (CPU python)=28322.74609375MB; mem (CPU total)=28154.9765625MB
INFO:root:[   34] Training loss: 0.62602560, Validation loss: 0.63112129, Gradient norm: 0.25830796
INFO:root:At the start of the epoch: mem (CPU python)=28360.83984375MB; mem (CPU total)=28193.26953125MB
INFO:root:[   35] Training loss: 0.62517342, Validation loss: 0.63027952, Gradient norm: 0.24001833
INFO:root:At the start of the epoch: mem (CPU python)=28398.9375MB; mem (CPU total)=28230.80859375MB
INFO:root:[   36] Training loss: 0.62442376, Validation loss: 0.63015708, Gradient norm: 0.25784421
INFO:root:At the start of the epoch: mem (CPU python)=28437.03125MB; mem (CPU total)=28268.8828125MB
INFO:root:[   37] Training loss: 0.62374982, Validation loss: 0.62954025, Gradient norm: 0.32045815
INFO:root:At the start of the epoch: mem (CPU python)=28475.12890625MB; mem (CPU total)=28307.37109375MB
INFO:root:[   38] Training loss: 0.62294097, Validation loss: 0.62826304, Gradient norm: 0.33355727
INFO:root:At the start of the epoch: mem (CPU python)=28513.2265625MB; mem (CPU total)=28345.421875MB
INFO:root:[   39] Training loss: 0.62205266, Validation loss: 0.62833589, Gradient norm: 0.24541230
INFO:root:At the start of the epoch: mem (CPU python)=28551.3203125MB; mem (CPU total)=28383.51953125MB
INFO:root:[   40] Training loss: 0.62146886, Validation loss: 0.62801998, Gradient norm: 0.36954882
INFO:root:At the start of the epoch: mem (CPU python)=28589.4140625MB; mem (CPU total)=28422.04296875MB
INFO:root:[   41] Training loss: 0.62055983, Validation loss: 0.62739103, Gradient norm: 0.25538456
INFO:root:At the start of the epoch: mem (CPU python)=28627.5078125MB; mem (CPU total)=28459.6953125MB
INFO:root:[   42] Training loss: 0.61997667, Validation loss: 0.62690928, Gradient norm: 0.26956981
INFO:root:At the start of the epoch: mem (CPU python)=28665.60546875MB; mem (CPU total)=28497.9765625MB
INFO:root:[   43] Training loss: 0.61949633, Validation loss: 0.62667763, Gradient norm: 0.26244420
INFO:root:At the start of the epoch: mem (CPU python)=28703.69921875MB; mem (CPU total)=28536.08984375MB
INFO:root:[   44] Training loss: 0.61870155, Validation loss: 0.62656539, Gradient norm: 0.32645135
INFO:root:At the start of the epoch: mem (CPU python)=28741.79296875MB; mem (CPU total)=28574.19921875MB
INFO:root:[   45] Training loss: 0.61819811, Validation loss: 0.62608579, Gradient norm: 0.33266078
INFO:root:At the start of the epoch: mem (CPU python)=28779.890625MB; mem (CPU total)=28612.17578125MB
INFO:root:[   46] Training loss: 0.61762971, Validation loss: 0.62549914, Gradient norm: 0.33140044
INFO:root:At the start of the epoch: mem (CPU python)=28817.98828125MB; mem (CPU total)=28650.078125MB
INFO:root:[   47] Training loss: 0.61695412, Validation loss: 0.62521339, Gradient norm: 0.30930259
INFO:root:At the start of the epoch: mem (CPU python)=28856.08203125MB; mem (CPU total)=28688.16796875MB
INFO:root:[   48] Training loss: 0.61648650, Validation loss: 0.62481811, Gradient norm: 0.30348496
INFO:root:At the start of the epoch: mem (CPU python)=28894.17578125MB; mem (CPU total)=28726.52734375MB
INFO:root:[   49] Training loss: 0.61584184, Validation loss: 0.62434451, Gradient norm: 0.30082229
INFO:root:At the start of the epoch: mem (CPU python)=28932.2734375MB; mem (CPU total)=28764.1171875MB
INFO:root:[   50] Training loss: 0.61526307, Validation loss: 0.62426815, Gradient norm: 0.33465057
INFO:root:At the start of the epoch: mem (CPU python)=28970.3671875MB; mem (CPU total)=28801.96484375MB
INFO:root:[   51] Training loss: 0.61476417, Validation loss: 0.62447058, Gradient norm: 0.34355074
INFO:root:At the start of the epoch: mem (CPU python)=29008.4609375MB; mem (CPU total)=28839.734375MB
INFO:root:[   52] Training loss: 0.61421028, Validation loss: 0.62412803, Gradient norm: 0.34960923
INFO:root:At the start of the epoch: mem (CPU python)=29046.5625MB; mem (CPU total)=28878.9140625MB
INFO:root:[   53] Training loss: 0.61378696, Validation loss: 0.62347113, Gradient norm: 0.35367167
INFO:root:At the start of the epoch: mem (CPU python)=29084.65625MB; mem (CPU total)=28917.16015625MB
INFO:root:[   54] Training loss: 0.61331638, Validation loss: 0.62305410, Gradient norm: 0.39801534
INFO:root:At the start of the epoch: mem (CPU python)=29122.75MB; mem (CPU total)=28955.3203125MB
INFO:root:[   55] Training loss: 0.61282723, Validation loss: 0.62278285, Gradient norm: 0.40317443
INFO:root:At the start of the epoch: mem (CPU python)=29160.84765625MB; mem (CPU total)=28994.39453125MB
INFO:root:[   56] Training loss: 0.61231315, Validation loss: 0.62308531, Gradient norm: 0.37339269
INFO:root:At the start of the epoch: mem (CPU python)=29198.94140625MB; mem (CPU total)=29032.23046875MB
INFO:root:[   57] Training loss: 0.61195716, Validation loss: 0.62230067, Gradient norm: 0.40737579
INFO:root:At the start of the epoch: mem (CPU python)=29237.03515625MB; mem (CPU total)=29070.52734375MB
INFO:root:[   58] Training loss: 0.61147183, Validation loss: 0.62240697, Gradient norm: 0.41883722
INFO:root:At the start of the epoch: mem (CPU python)=29275.12890625MB; mem (CPU total)=29109.359375MB
INFO:root:[   59] Training loss: 0.61105104, Validation loss: 0.62202885, Gradient norm: 0.41259646
INFO:root:At the start of the epoch: mem (CPU python)=29313.2265625MB; mem (CPU total)=29147.1953125MB
INFO:root:[   60] Training loss: 0.61063170, Validation loss: 0.62297507, Gradient norm: 0.41666087
INFO:root:At the start of the epoch: mem (CPU python)=29351.32421875MB; mem (CPU total)=29185.30078125MB
INFO:root:[   61] Training loss: 0.61021602, Validation loss: 0.62242929, Gradient norm: 0.43901437
INFO:root:At the start of the epoch: mem (CPU python)=29389.41796875MB; mem (CPU total)=29223.13671875MB
INFO:root:[   62] Training loss: 0.60973890, Validation loss: 0.62174469, Gradient norm: 0.45762393
INFO:root:At the start of the epoch: mem (CPU python)=29427.515625MB; mem (CPU total)=29260.390625MB
INFO:root:[   63] Training loss: 0.60934430, Validation loss: 0.62196601, Gradient norm: 0.44974075
INFO:root:At the start of the epoch: mem (CPU python)=29465.609375MB; mem (CPU total)=29299.953125MB
INFO:root:[   64] Training loss: 0.60879785, Validation loss: 0.62126839, Gradient norm: 0.40484731
INFO:root:At the start of the epoch: mem (CPU python)=29503.703125MB; mem (CPU total)=29338.25390625MB
INFO:root:[   65] Training loss: 0.60865324, Validation loss: 0.62184185, Gradient norm: 0.87695881
INFO:root:At the start of the epoch: mem (CPU python)=29541.796875MB; mem (CPU total)=29376.3515625MB
INFO:root:[   66] Training loss: 0.60815673, Validation loss: 0.62142448, Gradient norm: 0.48261769
INFO:root:At the start of the epoch: mem (CPU python)=29579.89453125MB; mem (CPU total)=29414.0546875MB
INFO:root:[   67] Training loss: 0.60779107, Validation loss: 0.62164879, Gradient norm: 0.47677418
INFO:root:At the start of the epoch: mem (CPU python)=29617.98828125MB; mem (CPU total)=29452.49609375MB
INFO:root:[   68] Training loss: 0.60743919, Validation loss: 0.62135823, Gradient norm: 0.51333400
INFO:root:At the start of the epoch: mem (CPU python)=29656.0859375MB; mem (CPU total)=29490.6171875MB
INFO:root:[   69] Training loss: 0.60721101, Validation loss: 0.62061882, Gradient norm: 0.66915278
INFO:root:At the start of the epoch: mem (CPU python)=29694.1796875MB; mem (CPU total)=29528.9921875MB
INFO:root:[   70] Training loss: 0.60670863, Validation loss: 0.62077479, Gradient norm: 0.87500695
INFO:root:At the start of the epoch: mem (CPU python)=29732.27734375MB; mem (CPU total)=29567.078125MB
INFO:root:[   71] Training loss: 0.60635756, Validation loss: 0.62133318, Gradient norm: 0.57820239
INFO:root:At the start of the epoch: mem (CPU python)=29770.37109375MB; mem (CPU total)=29605.16796875MB
INFO:root:[   72] Training loss: 0.60636395, Validation loss: 0.62121635, Gradient norm: 0.90365040
INFO:root:At the start of the epoch: mem (CPU python)=29808.46875MB; mem (CPU total)=29643.25390625MB
INFO:root:[   73] Training loss: 0.60692505, Validation loss: 0.62550449, Gradient norm: 2.42959952
INFO:root:At the start of the epoch: mem (CPU python)=29846.5625MB; mem (CPU total)=29680.91796875MB
INFO:root:[   74] Training loss: 0.60628294, Validation loss: 0.62143965, Gradient norm: 1.98688342
INFO:root:At the start of the epoch: mem (CPU python)=29884.65625MB; mem (CPU total)=29719.51171875MB
INFO:root:[   75] Training loss: 0.60545279, Validation loss: 0.62090053, Gradient norm: 0.36858471
INFO:root:At the start of the epoch: mem (CPU python)=29922.75MB; mem (CPU total)=29757.875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   76] Training loss: 0.60499212, Validation loss: 0.62059780, Gradient norm: 0.37788446
INFO:root:At the start of the epoch: mem (CPU python)=29960.84765625MB; mem (CPU total)=29796.65625MB
INFO:root:[   77] Training loss: 0.60276985, Validation loss: 0.62012497, Gradient norm: 0.28890971
INFO:root:At the start of the epoch: mem (CPU python)=29998.94140625MB; mem (CPU total)=29834.19921875MB
INFO:root:[   78] Training loss: 0.60240555, Validation loss: 0.61979190, Gradient norm: 0.30769645
INFO:root:At the start of the epoch: mem (CPU python)=30037.03515625MB; mem (CPU total)=29872.31640625MB
INFO:root:[   79] Training loss: 0.60216815, Validation loss: 0.62049653, Gradient norm: 0.33492707
INFO:root:At the start of the epoch: mem (CPU python)=30075.13671875MB; mem (CPU total)=29910.91796875MB
INFO:root:[   80] Training loss: 0.60205757, Validation loss: 0.61994108, Gradient norm: 0.35005542
INFO:root:At the start of the epoch: mem (CPU python)=30113.23046875MB; mem (CPU total)=29948.42578125MB
INFO:root:[   81] Training loss: 0.60174407, Validation loss: 0.61981096, Gradient norm: 0.37410955
INFO:root:At the start of the epoch: mem (CPU python)=30151.32421875MB; mem (CPU total)=29986.5MB
INFO:root:[   82] Training loss: 0.60165539, Validation loss: 0.61998915, Gradient norm: 0.38786950
INFO:root:At the start of the epoch: mem (CPU python)=30189.41796875MB; mem (CPU total)=30024.3828125MB
INFO:root:[   83] Training loss: 0.60149028, Validation loss: 0.62033437, Gradient norm: 0.41620839
INFO:root:At the start of the epoch: mem (CPU python)=30227.515625MB; mem (CPU total)=30062.23828125MB
INFO:root:[   84] Training loss: 0.60128921, Validation loss: 0.61972412, Gradient norm: 0.50953580
INFO:root:At the start of the epoch: mem (CPU python)=30265.609375MB; mem (CPU total)=30100.58203125MB
INFO:root:[   85] Training loss: 0.60104947, Validation loss: 0.61972462, Gradient norm: 0.44433957
INFO:root:At the start of the epoch: mem (CPU python)=30303.703125MB; mem (CPU total)=30138.73828125MB
INFO:root:[   86] Training loss: 0.60086658, Validation loss: 0.62015286, Gradient norm: 0.41942291
INFO:root:At the start of the epoch: mem (CPU python)=30341.80078125MB; mem (CPU total)=30176.74609375MB
INFO:root:[   87] Training loss: 0.60065104, Validation loss: 0.62009989, Gradient norm: 0.48853627
INFO:root:At the start of the epoch: mem (CPU python)=30379.8984375MB; mem (CPU total)=30214.83984375MB
INFO:root:[   88] Training loss: 0.60062633, Validation loss: 0.62012353, Gradient norm: 0.48157131
INFO:root:At the start of the epoch: mem (CPU python)=30417.9921875MB; mem (CPU total)=30254.8671875MB
INFO:root:[   89] Training loss: 0.60025035, Validation loss: 0.62012771, Gradient norm: 0.47243204
INFO:root:At the start of the epoch: mem (CPU python)=30456.08984375MB; mem (CPU total)=30291.75390625MB
INFO:root:[   90] Training loss: 0.60023817, Validation loss: 0.62051396, Gradient norm: 0.46857370
INFO:root:At the start of the epoch: mem (CPU python)=30494.18359375MB; mem (CPU total)=30332.90234375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   91] Training loss: 0.59996326, Validation loss: 0.61984036, Gradient norm: 0.50802117
INFO:root:At the start of the epoch: mem (CPU python)=30532.27734375MB; mem (CPU total)=30369.703125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   92] Training loss: 0.59876529, Validation loss: 0.61969779, Gradient norm: 0.31272266
INFO:root:At the start of the epoch: mem (CPU python)=30570.37109375MB; mem (CPU total)=30407.3671875MB
INFO:root:[   93] Training loss: 0.59814033, Validation loss: 0.61988396, Gradient norm: 0.27505150
INFO:root:At the start of the epoch: mem (CPU python)=30608.46875MB; mem (CPU total)=30445.484375MB
INFO:root:[   94] Training loss: 0.59807485, Validation loss: 0.62012307, Gradient norm: 0.26339193
INFO:root:At the start of the epoch: mem (CPU python)=30646.5625MB; mem (CPU total)=30483.64453125MB
INFO:root:[   95] Training loss: 0.59805499, Validation loss: 0.61977942, Gradient norm: 0.26500870
INFO:root:At the start of the epoch: mem (CPU python)=30684.66015625MB; mem (CPU total)=30521.19921875MB
INFO:root:[   96] Training loss: 0.59800282, Validation loss: 0.61999148, Gradient norm: 0.28082264
INFO:root:At the start of the epoch: mem (CPU python)=30722.7578125MB; mem (CPU total)=30558.82421875MB
INFO:root:[   97] Training loss: 0.59790453, Validation loss: 0.61957488, Gradient norm: 0.28817408
INFO:root:At the start of the epoch: mem (CPU python)=30760.8515625MB; mem (CPU total)=30597.078125MB
INFO:root:[   98] Training loss: 0.59792094, Validation loss: 0.61999939, Gradient norm: 0.29250234
INFO:root:At the start of the epoch: mem (CPU python)=30798.9453125MB; mem (CPU total)=30635.375MB
INFO:root:[   99] Training loss: 0.59787324, Validation loss: 0.61986163, Gradient norm: 0.30596352
INFO:root:At the start of the epoch: mem (CPU python)=30837.0390625MB; mem (CPU total)=30672.94921875MB
INFO:root:[  100] Training loss: 0.59783552, Validation loss: 0.61988695, Gradient norm: 0.28384760
INFO:root:At the start of the epoch: mem (CPU python)=30875.13671875MB; mem (CPU total)=30711.1953125MB
INFO:root:[  101] Training loss: 0.59776939, Validation loss: 0.62012828, Gradient norm: 0.30741085
INFO:root:At the start of the epoch: mem (CPU python)=30913.23046875MB; mem (CPU total)=30749.25390625MB
INFO:root:[  102] Training loss: 0.59780036, Validation loss: 0.62003545, Gradient norm: 0.31490653
INFO:root:At the start of the epoch: mem (CPU python)=30951.32421875MB; mem (CPU total)=30787.33984375MB
INFO:root:[  103] Training loss: 0.59771198, Validation loss: 0.62015755, Gradient norm: 0.30475625
INFO:root:At the start of the epoch: mem (CPU python)=30989.421875MB; mem (CPU total)=30825.49609375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  104] Training loss: 0.59769263, Validation loss: 0.61986081, Gradient norm: 0.33711692
INFO:root:At the start of the epoch: mem (CPU python)=31027.515625MB; mem (CPU total)=30863.79296875MB
INFO:root:[  105] Training loss: 0.59721740, Validation loss: 0.62000052, Gradient norm: 0.23735058
INFO:root:At the start of the epoch: mem (CPU python)=31065.61328125MB; mem (CPU total)=30903.2890625MB
INFO:root:[  106] Training loss: 0.59726729, Validation loss: 0.62031120, Gradient norm: 0.25928058
INFO:root:At the start of the epoch: mem (CPU python)=31103.7109375MB; mem (CPU total)=30941.59375MB
INFO:root:EP 106: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=31141.8046875MB; mem (CPU total)=30979.77734375MB
INFO:root:Training the model took 21399.756s.
INFO:root:Emptying the cuda cache took 0.387s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85039
INFO:root:EnergyScoreTrain: 0.59934
INFO:root:CRPSTrain: 0.51412
INFO:root:Gaussian NLLTrain: 1.80024
INFO:root:CoverageTrain: 0.82348
INFO:root:IntervalWidthTrain: 3.25044
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88215
INFO:root:EnergyScoreValidation: 0.62128
INFO:root:CRPSValidation: 0.53206
INFO:root:Gaussian NLLValidation: 1.84411
INFO:root:CoverageValidation: 0.81458
INFO:root:IntervalWidthValidation: 3.24778
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88326
INFO:root:EnergyScoreTest: 0.62199
INFO:root:CRPSTest: 0.53268
INFO:root:Gaussian NLLTest: 1.84712
INFO:root:CoverageTest: 0.81333
INFO:root:IntervalWidthTest: 3.23688
INFO:root:After validation: mem (CPU python)=31184.40234375MB; mem (CPU total)=31020.703125MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=31184.40234375MB; mem (CPU total)=31021.0859375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 157286400
INFO:root:After setting up the model: mem (CPU python)=31184.640625MB; mem (CPU total)=31021.0859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=31184.640625MB; mem (CPU total)=31021.5703125MB
INFO:root:[    1] Training loss: 0.76828494, Validation loss: 0.72213429, Gradient norm: 0.51552567
INFO:root:At the start of the epoch: mem (CPU python)=31222.70703125MB; mem (CPU total)=31061.84375MB
INFO:root:[    2] Training loss: 0.72043210, Validation loss: 0.72037863, Gradient norm: 0.38545167
INFO:root:At the start of the epoch: mem (CPU python)=31260.8046875MB; mem (CPU total)=31100.1796875MB
INFO:root:[    3] Training loss: 0.71980446, Validation loss: 0.71990122, Gradient norm: 0.30761263
INFO:root:At the start of the epoch: mem (CPU python)=31298.90625MB; mem (CPU total)=31138.29296875MB
INFO:root:[    4] Training loss: 0.71937540, Validation loss: 0.71911701, Gradient norm: 0.25419227
INFO:root:At the start of the epoch: mem (CPU python)=31337.0MB; mem (CPU total)=31176.9140625MB
INFO:root:[    5] Training loss: 0.71826496, Validation loss: 0.71732907, Gradient norm: 0.29019904
INFO:root:At the start of the epoch: mem (CPU python)=31375.1015625MB; mem (CPU total)=31215.0546875MB
INFO:root:[    6] Training loss: 0.71121881, Validation loss: 0.70274930, Gradient norm: 0.33955949
INFO:root:At the start of the epoch: mem (CPU python)=31413.1953125MB; mem (CPU total)=31253.0703125MB
INFO:root:[    7] Training loss: 0.69232788, Validation loss: 0.68355133, Gradient norm: 0.24249608
INFO:root:At the start of the epoch: mem (CPU python)=31451.2890625MB; mem (CPU total)=31291.4453125MB
INFO:root:[    8] Training loss: 0.67748166, Validation loss: 0.67244598, Gradient norm: 0.21093175
INFO:root:At the start of the epoch: mem (CPU python)=31489.38671875MB; mem (CPU total)=31329.71484375MB
INFO:root:[    9] Training loss: 0.66867492, Validation loss: 0.66597351, Gradient norm: 0.20292136
INFO:root:At the start of the epoch: mem (CPU python)=31527.48046875MB; mem (CPU total)=31368.046875MB
INFO:root:[   10] Training loss: 0.66280224, Validation loss: 0.66104764, Gradient norm: 0.20664390
INFO:root:At the start of the epoch: mem (CPU python)=31565.57421875MB; mem (CPU total)=31406.140625MB
INFO:root:[   11] Training loss: 0.65865891, Validation loss: 0.65831954, Gradient norm: 0.21796601
INFO:root:At the start of the epoch: mem (CPU python)=31603.66796875MB; mem (CPU total)=31444.0234375MB
INFO:root:[   12] Training loss: 0.65566663, Validation loss: 0.65537354, Gradient norm: 0.23727679
INFO:root:At the start of the epoch: mem (CPU python)=31641.765625MB; mem (CPU total)=31481.7265625MB
INFO:root:[   13] Training loss: 0.65273999, Validation loss: 0.65292948, Gradient norm: 0.21110146
INFO:root:At the start of the epoch: mem (CPU python)=31679.86328125MB; mem (CPU total)=31520.13671875MB
INFO:root:[   14] Training loss: 0.65022053, Validation loss: 0.65102196, Gradient norm: 0.18739210
INFO:root:At the start of the epoch: mem (CPU python)=31717.95703125MB; mem (CPU total)=31558.15234375MB
INFO:root:[   15] Training loss: 0.64797712, Validation loss: 0.64920401, Gradient norm: 0.21915731
INFO:root:At the start of the epoch: mem (CPU python)=31756.0546875MB; mem (CPU total)=31596.80859375MB
INFO:root:[   16] Training loss: 0.64598242, Validation loss: 0.64672728, Gradient norm: 0.19416903
INFO:root:At the start of the epoch: mem (CPU python)=31794.1484375MB; mem (CPU total)=31634.90625MB
INFO:root:[   17] Training loss: 0.64402984, Validation loss: 0.64561967, Gradient norm: 0.23201982
INFO:root:At the start of the epoch: mem (CPU python)=31832.2421875MB; mem (CPU total)=31673.01953125MB
INFO:root:[   18] Training loss: 0.64224012, Validation loss: 0.64371740, Gradient norm: 0.24861496
INFO:root:At the start of the epoch: mem (CPU python)=31870.33984375MB; mem (CPU total)=31711.32421875MB
INFO:root:[   19] Training loss: 0.64061028, Validation loss: 0.64241221, Gradient norm: 0.20397693
INFO:root:At the start of the epoch: mem (CPU python)=31908.4375MB; mem (CPU total)=31749.83203125MB
INFO:root:[   20] Training loss: 0.63897525, Validation loss: 0.64128839, Gradient norm: 0.19260741
INFO:root:At the start of the epoch: mem (CPU python)=31946.53125MB; mem (CPU total)=31788.4140625MB
INFO:root:[   21] Training loss: 0.63785152, Validation loss: 0.64026224, Gradient norm: 0.24504705
INFO:root:At the start of the epoch: mem (CPU python)=31984.625MB; mem (CPU total)=31826.73828125MB
INFO:root:[   22] Training loss: 0.63628321, Validation loss: 0.63898681, Gradient norm: 0.22751884
INFO:root:At the start of the epoch: mem (CPU python)=32022.72265625MB; mem (CPU total)=31864.41015625MB
INFO:root:[   23] Training loss: 0.63517799, Validation loss: 0.63822858, Gradient norm: 0.22654400
INFO:root:At the start of the epoch: mem (CPU python)=32060.81640625MB; mem (CPU total)=31906.01953125MB
INFO:root:[   24] Training loss: 0.63398093, Validation loss: 0.63774212, Gradient norm: 0.21783995
INFO:root:At the start of the epoch: mem (CPU python)=32098.91015625MB; mem (CPU total)=31943.66796875MB
INFO:root:[   25] Training loss: 0.63276990, Validation loss: 0.63689850, Gradient norm: 0.22965340
INFO:root:At the start of the epoch: mem (CPU python)=32137.0078125MB; mem (CPU total)=31981.62890625MB
INFO:root:[   26] Training loss: 0.63170624, Validation loss: 0.63543022, Gradient norm: 0.28016795
INFO:root:At the start of the epoch: mem (CPU python)=32175.1015625MB; mem (CPU total)=32019.26953125MB
INFO:root:[   27] Training loss: 0.63053975, Validation loss: 0.63458336, Gradient norm: 0.24914123
INFO:root:At the start of the epoch: mem (CPU python)=32213.1953125MB; mem (CPU total)=32057.60546875MB
INFO:root:[   28] Training loss: 0.62966766, Validation loss: 0.63385795, Gradient norm: 0.20539136
INFO:root:At the start of the epoch: mem (CPU python)=32251.29296875MB; mem (CPU total)=32095.65234375MB
INFO:root:[   29] Training loss: 0.62861744, Validation loss: 0.63310863, Gradient norm: 0.22108066
INFO:root:At the start of the epoch: mem (CPU python)=32289.390625MB; mem (CPU total)=32133.703125MB
INFO:root:[   30] Training loss: 0.62771548, Validation loss: 0.63266979, Gradient norm: 0.25436363
INFO:root:At the start of the epoch: mem (CPU python)=32327.484375MB; mem (CPU total)=32171.5390625MB
INFO:root:[   31] Training loss: 0.62697805, Validation loss: 0.63211428, Gradient norm: 0.23552482
INFO:root:At the start of the epoch: mem (CPU python)=32365.578125MB; mem (CPU total)=32208.64453125MB
INFO:root:[   32] Training loss: 0.62597564, Validation loss: 0.63088073, Gradient norm: 0.22219725
INFO:root:At the start of the epoch: mem (CPU python)=32403.67578125MB; mem (CPU total)=32247.46484375MB
INFO:root:[   33] Training loss: 0.62518417, Validation loss: 0.63095742, Gradient norm: 0.23287815
INFO:root:At the start of the epoch: mem (CPU python)=32441.76953125MB; mem (CPU total)=32285.26953125MB
INFO:root:[   34] Training loss: 0.62431180, Validation loss: 0.63006396, Gradient norm: 0.23735069
INFO:root:At the start of the epoch: mem (CPU python)=32479.86328125MB; mem (CPU total)=32323.56640625MB
INFO:root:[   35] Training loss: 0.62350255, Validation loss: 0.62948287, Gradient norm: 0.22533973
INFO:root:At the start of the epoch: mem (CPU python)=32517.95703125MB; mem (CPU total)=32361.69140625MB
INFO:root:[   36] Training loss: 0.62289466, Validation loss: 0.62961676, Gradient norm: 0.24780868
INFO:root:At the start of the epoch: mem (CPU python)=32556.0546875MB; mem (CPU total)=32400.8515625MB
INFO:root:[   37] Training loss: 0.62207559, Validation loss: 0.62854476, Gradient norm: 0.23403742
INFO:root:At the start of the epoch: mem (CPU python)=32594.15234375MB; mem (CPU total)=32439.1953125MB
INFO:root:[   38] Training loss: 0.62142585, Validation loss: 0.62855607, Gradient norm: 0.26503874
INFO:root:At the start of the epoch: mem (CPU python)=32632.24609375MB; mem (CPU total)=32477.31640625MB
INFO:root:[   39] Training loss: 0.62076385, Validation loss: 0.62853780, Gradient norm: 0.23317897
INFO:root:At the start of the epoch: mem (CPU python)=32670.34375MB; mem (CPU total)=32516.1328125MB
INFO:root:[   40] Training loss: 0.62002029, Validation loss: 0.62722663, Gradient norm: 0.25724543
INFO:root:At the start of the epoch: mem (CPU python)=32708.4375MB; mem (CPU total)=32554.703125MB
INFO:root:[   41] Training loss: 0.61950713, Validation loss: 0.62697947, Gradient norm: 0.23735554
INFO:root:At the start of the epoch: mem (CPU python)=32746.53515625MB; mem (CPU total)=32592.375MB
INFO:root:[   42] Training loss: 0.61886128, Validation loss: 0.62701544, Gradient norm: 0.28581138
INFO:root:At the start of the epoch: mem (CPU python)=32784.6328125MB; mem (CPU total)=32630.046875MB
INFO:root:[   43] Training loss: 0.61823643, Validation loss: 0.62645626, Gradient norm: 0.34362742
INFO:root:At the start of the epoch: mem (CPU python)=32822.7265625MB; mem (CPU total)=32668.36328125MB
INFO:root:[   44] Training loss: 0.61758671, Validation loss: 0.62530970, Gradient norm: 0.27709630
INFO:root:At the start of the epoch: mem (CPU python)=32860.8203125MB; mem (CPU total)=32705.98046875MB
INFO:root:[   45] Training loss: 0.61693566, Validation loss: 0.62573159, Gradient norm: 0.29171209
INFO:root:At the start of the epoch: mem (CPU python)=32898.921875MB; mem (CPU total)=32743.8125MB
INFO:root:[   46] Training loss: 0.61649502, Validation loss: 0.62505727, Gradient norm: 0.26897610
INFO:root:At the start of the epoch: mem (CPU python)=32937.01953125MB; mem (CPU total)=32783.95703125MB
INFO:root:[   47] Training loss: 0.61585271, Validation loss: 0.62551776, Gradient norm: 0.26934278
INFO:root:At the start of the epoch: mem (CPU python)=32975.11328125MB; mem (CPU total)=32822.0625MB
INFO:root:[   48] Training loss: 0.61535092, Validation loss: 0.62517547, Gradient norm: 0.27846189
INFO:root:At the start of the epoch: mem (CPU python)=33013.20703125MB; mem (CPU total)=32860.2421875MB
INFO:root:[   49] Training loss: 0.61485397, Validation loss: 0.62417166, Gradient norm: 0.27996552
INFO:root:At the start of the epoch: mem (CPU python)=33051.3046875MB; mem (CPU total)=32898.5546875MB
INFO:root:[   50] Training loss: 0.61441748, Validation loss: 0.62410628, Gradient norm: 0.30168516
INFO:root:At the start of the epoch: mem (CPU python)=33089.3984375MB; mem (CPU total)=32938.19140625MB
INFO:root:[   51] Training loss: 0.61399624, Validation loss: 0.62426855, Gradient norm: 0.31562954
INFO:root:At the start of the epoch: mem (CPU python)=33127.4921875MB; mem (CPU total)=32976.4140625MB
INFO:root:[   52] Training loss: 0.61327325, Validation loss: 0.62312920, Gradient norm: 0.28867308
INFO:root:At the start of the epoch: mem (CPU python)=33165.58984375MB; mem (CPU total)=33014.37890625MB
INFO:root:[   53] Training loss: 0.61268989, Validation loss: 0.62359725, Gradient norm: 0.34459806
INFO:root:At the start of the epoch: mem (CPU python)=33203.6875MB; mem (CPU total)=33052.2578125MB
INFO:root:[   54] Training loss: 0.61239979, Validation loss: 0.62386130, Gradient norm: 0.36140773
INFO:root:At the start of the epoch: mem (CPU python)=33241.78125MB; mem (CPU total)=33090.51953125MB
INFO:root:[   55] Training loss: 0.61184064, Validation loss: 0.62314332, Gradient norm: 0.35750637
INFO:root:At the start of the epoch: mem (CPU python)=33279.875MB; mem (CPU total)=33128.5859375MB
INFO:root:[   56] Training loss: 0.61126963, Validation loss: 0.62309466, Gradient norm: 0.35379139
INFO:root:At the start of the epoch: mem (CPU python)=33317.97265625MB; mem (CPU total)=33166.96484375MB
INFO:root:[   57] Training loss: 0.61101652, Validation loss: 0.62286336, Gradient norm: 0.36438216
INFO:root:At the start of the epoch: mem (CPU python)=33356.06640625MB; mem (CPU total)=33205.12890625MB
INFO:root:[   58] Training loss: 0.61041826, Validation loss: 0.62224969, Gradient norm: 0.32328639
INFO:root:At the start of the epoch: mem (CPU python)=33394.16015625MB; mem (CPU total)=33243.15234375MB
INFO:root:[   59] Training loss: 0.61012574, Validation loss: 0.62238034, Gradient norm: 0.42744197
INFO:root:At the start of the epoch: mem (CPU python)=33432.2578125MB; mem (CPU total)=33281.27734375MB
INFO:root:[   60] Training loss: 0.60968736, Validation loss: 0.62244759, Gradient norm: 0.37384058
INFO:root:At the start of the epoch: mem (CPU python)=33470.3515625MB; mem (CPU total)=33319.3671875MB
INFO:root:[   61] Training loss: 0.60907877, Validation loss: 0.62211013, Gradient norm: 0.38216640
INFO:root:At the start of the epoch: mem (CPU python)=33508.44921875MB; mem (CPU total)=33357.4375MB
INFO:root:[   62] Training loss: 0.60874524, Validation loss: 0.62162011, Gradient norm: 0.41635844
INFO:root:At the start of the epoch: mem (CPU python)=33546.5390625MB; mem (CPU total)=33395.78515625MB
INFO:root:[   63] Training loss: 0.60829625, Validation loss: 0.62215220, Gradient norm: 0.40068657
INFO:root:At the start of the epoch: mem (CPU python)=33584.640625MB; mem (CPU total)=33433.58203125MB
INFO:root:[   64] Training loss: 0.60794940, Validation loss: 0.62172385, Gradient norm: 0.39314922
INFO:root:At the start of the epoch: mem (CPU python)=33622.734375MB; mem (CPU total)=33471.39453125MB
INFO:root:[   65] Training loss: 0.60786393, Validation loss: 0.62292313, Gradient norm: 0.73227371
INFO:root:At the start of the epoch: mem (CPU python)=33660.828125MB; mem (CPU total)=33509.046875MB
INFO:root:[   66] Training loss: 0.60720549, Validation loss: 0.62160420, Gradient norm: 0.38265669
INFO:root:At the start of the epoch: mem (CPU python)=33698.92578125MB; mem (CPU total)=33546.91015625MB
INFO:root:[   67] Training loss: 0.60668524, Validation loss: 0.62164478, Gradient norm: 0.40946677
INFO:root:At the start of the epoch: mem (CPU python)=33737.01953125MB; mem (CPU total)=33584.984375MB
INFO:root:[   68] Training loss: 0.60640211, Validation loss: 0.62124521, Gradient norm: 0.41962332
INFO:root:At the start of the epoch: mem (CPU python)=33775.11328125MB; mem (CPU total)=33623.00390625MB
INFO:root:[   69] Training loss: 0.60614270, Validation loss: 0.62195104, Gradient norm: 0.39964790
INFO:root:At the start of the epoch: mem (CPU python)=33813.20703125MB; mem (CPU total)=33660.5859375MB
INFO:root:[   70] Training loss: 0.60562611, Validation loss: 0.62161387, Gradient norm: 0.56587507
INFO:root:At the start of the epoch: mem (CPU python)=33851.30859375MB; mem (CPU total)=33699.125MB
INFO:root:[   71] Training loss: 0.60521916, Validation loss: 0.62089789, Gradient norm: 0.48921375
INFO:root:At the start of the epoch: mem (CPU python)=33889.40234375MB; mem (CPU total)=33737.03125MB
INFO:root:[   72] Training loss: 0.60503620, Validation loss: 0.62110070, Gradient norm: 0.53888097
INFO:root:At the start of the epoch: mem (CPU python)=33927.49609375MB; mem (CPU total)=33774.921875MB
INFO:root:[   73] Training loss: 0.60436056, Validation loss: 0.62116309, Gradient norm: 0.51786215
INFO:root:At the start of the epoch: mem (CPU python)=33965.59375MB; mem (CPU total)=33812.74609375MB
INFO:root:[   74] Training loss: 0.60453654, Validation loss: 0.62071819, Gradient norm: 0.82404282
INFO:root:At the start of the epoch: mem (CPU python)=34003.6875MB; mem (CPU total)=33851.125MB
INFO:root:[   75] Training loss: 0.60370439, Validation loss: 0.62120179, Gradient norm: 1.28820330
INFO:root:At the start of the epoch: mem (CPU python)=34041.78125MB; mem (CPU total)=33889.29296875MB
INFO:root:[   76] Training loss: 0.60343355, Validation loss: 0.62127186, Gradient norm: 0.57273762
INFO:root:At the start of the epoch: mem (CPU python)=34079.8828125MB; mem (CPU total)=33929.05078125MB
INFO:root:[   77] Training loss: 0.60312230, Validation loss: 0.62115314, Gradient norm: 0.41608320
INFO:root:At the start of the epoch: mem (CPU python)=34117.9765625MB; mem (CPU total)=33966.94921875MB
INFO:root:[   78] Training loss: 0.60300101, Validation loss: 0.62109518, Gradient norm: 1.00168216
INFO:root:At the start of the epoch: mem (CPU python)=34156.0703125MB; mem (CPU total)=34005.29296875MB
INFO:root:[   79] Training loss: 0.60258653, Validation loss: 0.62102387, Gradient norm: 0.48519039
INFO:root:At the start of the epoch: mem (CPU python)=34194.16796875MB; mem (CPU total)=34043.640625MB
INFO:root:[   80] Training loss: 0.60229912, Validation loss: 0.62171224, Gradient norm: 0.82597862
INFO:root:At the start of the epoch: mem (CPU python)=34232.265625MB; mem (CPU total)=34081.93359375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   81] Training loss: 0.60171817, Validation loss: 0.62155798, Gradient norm: 0.99970856
INFO:root:At the start of the epoch: mem (CPU python)=34270.359375MB; mem (CPU total)=34119.328125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   82] Training loss: 0.59972367, Validation loss: 0.62031521, Gradient norm: 0.30723471
INFO:root:At the start of the epoch: mem (CPU python)=34308.453125MB; mem (CPU total)=34157.05859375MB
INFO:root:[   83] Training loss: 0.59843907, Validation loss: 0.61994781, Gradient norm: 0.23214686
INFO:root:At the start of the epoch: mem (CPU python)=34346.55078125MB; mem (CPU total)=34194.875MB
INFO:root:[   84] Training loss: 0.59823617, Validation loss: 0.62052359, Gradient norm: 0.24971505
INFO:root:At the start of the epoch: mem (CPU python)=34384.64453125MB; mem (CPU total)=34233.38671875MB
INFO:root:[   85] Training loss: 0.59813884, Validation loss: 0.62049208, Gradient norm: 0.28631436
INFO:root:At the start of the epoch: mem (CPU python)=34422.73828125MB; mem (CPU total)=34271.43359375MB
INFO:root:[   86] Training loss: 0.59797425, Validation loss: 0.62022869, Gradient norm: 0.27986301
INFO:root:At the start of the epoch: mem (CPU python)=34460.8359375MB; mem (CPU total)=34308.859375MB
INFO:root:[   87] Training loss: 0.59796328, Validation loss: 0.62008571, Gradient norm: 0.31495204
INFO:root:At the start of the epoch: mem (CPU python)=34498.93359375MB; mem (CPU total)=34347.20703125MB
INFO:root:[   88] Training loss: 0.59782917, Validation loss: 0.62067280, Gradient norm: 0.30172780
INFO:root:At the start of the epoch: mem (CPU python)=34537.02734375MB; mem (CPU total)=34385.57421875MB
INFO:root:[   89] Training loss: 0.59784476, Validation loss: 0.62056877, Gradient norm: 0.30579805
INFO:root:At the start of the epoch: mem (CPU python)=34575.12109375MB; mem (CPU total)=34423.69921875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   90] Training loss: 0.59767788, Validation loss: 0.62024882, Gradient norm: 0.31267191
INFO:root:At the start of the epoch: mem (CPU python)=34613.21875MB; mem (CPU total)=34461.51953125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   91] Training loss: 0.59712903, Validation loss: 0.62069814, Gradient norm: 0.24763639
INFO:root:At the start of the epoch: mem (CPU python)=34651.3125MB; mem (CPU total)=34499.41796875MB
INFO:root:[   92] Training loss: 0.59667974, Validation loss: 0.62021449, Gradient norm: 0.21712313
INFO:root:At the start of the epoch: mem (CPU python)=34689.40625MB; mem (CPU total)=34538.03515625MB
INFO:root:EP 92: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=34727.50390625MB; mem (CPU total)=34576.8515625MB
INFO:root:Training the model took 18937.817s.
INFO:root:Emptying the cuda cache took 0.389s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8512
INFO:root:EnergyScoreTrain: 0.59967
INFO:root:CRPSTrain: 0.51224
INFO:root:Gaussian NLLTrain: 1.71203
INFO:root:CoverageTrain: 0.82369
INFO:root:IntervalWidthTrain: 3.18097
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88301
INFO:root:EnergyScoreValidation: 0.62198
INFO:root:CRPSValidation: 0.53094
INFO:root:Gaussian NLLValidation: 1.76141
INFO:root:CoverageValidation: 0.81323
INFO:root:IntervalWidthValidation: 3.17658
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88371
INFO:root:EnergyScoreTest: 0.62252
INFO:root:CRPSTest: 0.53168
INFO:root:Gaussian NLLTest: 1.76376
INFO:root:CoverageTest: 0.81189
INFO:root:IntervalWidthTest: 3.17038
INFO:root:After validation: mem (CPU python)=34770.2109375MB; mem (CPU total)=34617.80859375MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=34770.2109375MB; mem (CPU total)=34617.51171875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 157286400
INFO:root:After setting up the model: mem (CPU python)=34770.3203125MB; mem (CPU total)=34617.51171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=34770.40234375MB; mem (CPU total)=34617.765625MB
INFO:root:[    1] Training loss: 0.74805712, Validation loss: 0.72445828, Gradient norm: 1.09169831
INFO:root:At the start of the epoch: mem (CPU python)=34808.4609375MB; mem (CPU total)=34657.45703125MB
INFO:root:[    2] Training loss: 0.72022685, Validation loss: 0.72066010, Gradient norm: 0.56365858
INFO:root:At the start of the epoch: mem (CPU python)=34846.5625MB; mem (CPU total)=34695.828125MB
INFO:root:[    3] Training loss: 0.71951482, Validation loss: 0.71919684, Gradient norm: 0.76360883
INFO:root:At the start of the epoch: mem (CPU python)=34884.66015625MB; mem (CPU total)=36610.5859375MB
INFO:root:[    4] Training loss: 0.71860504, Validation loss: 0.71804946, Gradient norm: 0.60551679
INFO:root:At the start of the epoch: mem (CPU python)=34922.7578125MB; mem (CPU total)=36644.67578125MB
INFO:root:[    5] Training loss: 0.71606975, Validation loss: 0.71281683, Gradient norm: 0.40864528
INFO:root:At the start of the epoch: mem (CPU python)=34960.8515625MB; mem (CPU total)=36678.3671875MB
INFO:root:[    6] Training loss: 0.70766022, Validation loss: 0.70375697, Gradient norm: 0.63748161
INFO:root:At the start of the epoch: mem (CPU python)=34998.94921875MB; mem (CPU total)=35931.671875MB
INFO:root:[    7] Training loss: 0.69876970, Validation loss: 0.69493332, Gradient norm: 0.60054171
INFO:root:At the start of the epoch: mem (CPU python)=35037.04296875MB; mem (CPU total)=37364.4296875MB
INFO:root:[    8] Training loss: 0.69046469, Validation loss: 0.68868674, Gradient norm: 0.31505568
INFO:root:At the start of the epoch: mem (CPU python)=35075.13671875MB; mem (CPU total)=36964.3125MB
INFO:root:[    9] Training loss: 0.68405437, Validation loss: 0.68315959, Gradient norm: 0.29428349
INFO:root:At the start of the epoch: mem (CPU python)=35113.234375MB; mem (CPU total)=37461.01953125MB
INFO:root:[   10] Training loss: 0.67878380, Validation loss: 0.67800461, Gradient norm: 0.28755027
INFO:root:At the start of the epoch: mem (CPU python)=35151.328125MB; mem (CPU total)=37492.1328125MB
INFO:root:[   11] Training loss: 0.67404827, Validation loss: 0.67288768, Gradient norm: 0.36362156
INFO:root:At the start of the epoch: mem (CPU python)=35189.42578125MB; mem (CPU total)=37533.60546875MB
INFO:root:[   12] Training loss: 0.66967315, Validation loss: 0.66909857, Gradient norm: 0.34889583
INFO:root:At the start of the epoch: mem (CPU python)=35227.51953125MB; mem (CPU total)=37573.56640625MB
INFO:root:[   13] Training loss: 0.66587259, Validation loss: 0.66525746, Gradient norm: 0.34630337
INFO:root:At the start of the epoch: mem (CPU python)=35265.6015625MB; mem (CPU total)=37610.0546875MB
INFO:root:[   14] Training loss: 0.66256337, Validation loss: 0.66256928, Gradient norm: 0.25790061
INFO:root:At the start of the epoch: mem (CPU python)=35303.6953125MB; mem (CPU total)=37651.90625MB
INFO:root:[   15] Training loss: 0.65981965, Validation loss: 0.66067639, Gradient norm: 0.29244759
INFO:root:At the start of the epoch: mem (CPU python)=35341.7890625MB; mem (CPU total)=37681.54296875MB
INFO:root:[   16] Training loss: 0.65716536, Validation loss: 0.65808692, Gradient norm: 0.27189319
INFO:root:At the start of the epoch: mem (CPU python)=35379.88671875MB; mem (CPU total)=37719.3828125MB
INFO:root:[   17] Training loss: 0.65480295, Validation loss: 0.65628805, Gradient norm: 0.26764179
INFO:root:At the start of the epoch: mem (CPU python)=35417.98046875MB; mem (CPU total)=37757.16796875MB
INFO:root:[   18] Training loss: 0.65268887, Validation loss: 0.65431293, Gradient norm: 0.27072079
INFO:root:At the start of the epoch: mem (CPU python)=35456.078125MB; mem (CPU total)=37795.40234375MB
INFO:root:[   19] Training loss: 0.65080686, Validation loss: 0.65266641, Gradient norm: 0.26680173
INFO:root:At the start of the epoch: mem (CPU python)=35494.171875MB; mem (CPU total)=37496.08984375MB
INFO:root:[   20] Training loss: 0.64887543, Validation loss: 0.65084900, Gradient norm: 0.28263042
INFO:root:At the start of the epoch: mem (CPU python)=35532.26953125MB; mem (CPU total)=37536.3671875MB
INFO:root:[   21] Training loss: 0.64704341, Validation loss: 0.64941857, Gradient norm: 0.30686100
INFO:root:At the start of the epoch: mem (CPU python)=35570.36328125MB; mem (CPU total)=37575.68359375MB
INFO:root:[   22] Training loss: 0.64542215, Validation loss: 0.64805853, Gradient norm: 0.24781818
INFO:root:At the start of the epoch: mem (CPU python)=35608.45703125MB; mem (CPU total)=37610.46875MB
INFO:root:[   23] Training loss: 0.64377597, Validation loss: 0.64685586, Gradient norm: 0.26386243
INFO:root:At the start of the epoch: mem (CPU python)=35646.5546875MB; mem (CPU total)=35503.0390625MB
INFO:root:[   24] Training loss: 0.64228167, Validation loss: 0.64576821, Gradient norm: 0.23118272
INFO:root:At the start of the epoch: mem (CPU python)=35684.6484375MB; mem (CPU total)=35540.73046875MB
INFO:root:[   25] Training loss: 0.64093152, Validation loss: 0.64351493, Gradient norm: 0.21885449
INFO:root:At the start of the epoch: mem (CPU python)=35722.74609375MB; mem (CPU total)=35578.4765625MB
INFO:root:[   26] Training loss: 0.63973057, Validation loss: 0.64288278, Gradient norm: 0.28125096
INFO:root:At the start of the epoch: mem (CPU python)=35760.84375MB; mem (CPU total)=35616.6953125MB
INFO:root:[   27] Training loss: 0.63843026, Validation loss: 0.64181983, Gradient norm: 0.22677324
INFO:root:At the start of the epoch: mem (CPU python)=35798.9375MB; mem (CPU total)=35654.89453125MB
INFO:root:[   28] Training loss: 0.63703685, Validation loss: 0.64162032, Gradient norm: 0.24151194
INFO:root:At the start of the epoch: mem (CPU python)=35837.03125MB; mem (CPU total)=35693.25MB
INFO:root:[   29] Training loss: 0.63602774, Validation loss: 0.64017008, Gradient norm: 0.27985187
INFO:root:At the start of the epoch: mem (CPU python)=35875.125MB; mem (CPU total)=35732.2265625MB
INFO:root:[   30] Training loss: 0.63492186, Validation loss: 0.63897852, Gradient norm: 0.24893941
INFO:root:At the start of the epoch: mem (CPU python)=35913.22265625MB; mem (CPU total)=35943.33203125MB
INFO:root:[   31] Training loss: 0.63370211, Validation loss: 0.63835541, Gradient norm: 0.24280934
INFO:root:At the start of the epoch: mem (CPU python)=35951.31640625MB; mem (CPU total)=37987.5078125MB
INFO:root:[   32] Training loss: 0.63271744, Validation loss: 0.63831941, Gradient norm: 0.25221090
INFO:root:At the start of the epoch: mem (CPU python)=35989.41015625MB; mem (CPU total)=35947.44921875MB
INFO:root:[   33] Training loss: 0.63172475, Validation loss: 0.63684711, Gradient norm: 0.21270978
INFO:root:At the start of the epoch: mem (CPU python)=36027.5078125MB; mem (CPU total)=35883.81640625MB
INFO:root:[   34] Training loss: 0.63083756, Validation loss: 0.63577808, Gradient norm: 0.25473437
INFO:root:At the start of the epoch: mem (CPU python)=36065.6015625MB; mem (CPU total)=35921.23046875MB
INFO:root:[   35] Training loss: 0.62988356, Validation loss: 0.63538994, Gradient norm: 0.22999866
INFO:root:At the start of the epoch: mem (CPU python)=36103.69921875MB; mem (CPU total)=35959.9140625MB
INFO:root:[   36] Training loss: 0.62894260, Validation loss: 0.63448320, Gradient norm: 0.20877445
INFO:root:At the start of the epoch: mem (CPU python)=36141.79296875MB; mem (CPU total)=35998.05859375MB
INFO:root:[   37] Training loss: 0.62813996, Validation loss: 0.63372083, Gradient norm: 0.27051248
INFO:root:At the start of the epoch: mem (CPU python)=36179.890625MB; mem (CPU total)=36036.4453125MB
INFO:root:[   38] Training loss: 0.62737621, Validation loss: 0.63343819, Gradient norm: 0.25004699
INFO:root:At the start of the epoch: mem (CPU python)=36217.984375MB; mem (CPU total)=36074.6640625MB
INFO:root:[   39] Training loss: 0.62651460, Validation loss: 0.63334668, Gradient norm: 0.26443957
INFO:root:At the start of the epoch: mem (CPU python)=36256.078125MB; mem (CPU total)=36113.26171875MB
INFO:root:[   40] Training loss: 0.62584478, Validation loss: 0.63219898, Gradient norm: 0.23191561
INFO:root:At the start of the epoch: mem (CPU python)=36294.17578125MB; mem (CPU total)=36152.56640625MB
INFO:root:[   41] Training loss: 0.62494391, Validation loss: 0.63195741, Gradient norm: 0.24093354
INFO:root:At the start of the epoch: mem (CPU python)=36332.26953125MB; mem (CPU total)=36190.54296875MB
INFO:root:[   42] Training loss: 0.62430141, Validation loss: 0.63131420, Gradient norm: 0.25725466
INFO:root:At the start of the epoch: mem (CPU python)=36370.36328125MB; mem (CPU total)=36228.89453125MB
INFO:root:[   43] Training loss: 0.62353724, Validation loss: 0.63096207, Gradient norm: 0.24640236
INFO:root:At the start of the epoch: mem (CPU python)=36408.46484375MB; mem (CPU total)=36266.73828125MB
INFO:root:[   44] Training loss: 0.62291994, Validation loss: 0.63063248, Gradient norm: 0.25227691
INFO:root:At the start of the epoch: mem (CPU python)=36446.55859375MB; mem (CPU total)=36304.85546875MB
INFO:root:[   45] Training loss: 0.62215458, Validation loss: 0.62991662, Gradient norm: 0.27494294
INFO:root:At the start of the epoch: mem (CPU python)=36484.65234375MB; mem (CPU total)=36341.7109375MB
INFO:root:[   46] Training loss: 0.62147456, Validation loss: 0.62979876, Gradient norm: 0.25251267
INFO:root:At the start of the epoch: mem (CPU python)=36522.74609375MB; mem (CPU total)=36379.81640625MB
INFO:root:[   47] Training loss: 0.62090565, Validation loss: 0.62903937, Gradient norm: 0.25379922
INFO:root:At the start of the epoch: mem (CPU python)=36560.84375MB; mem (CPU total)=36417.734375MB
INFO:root:[   48] Training loss: 0.62029843, Validation loss: 0.62844701, Gradient norm: 0.24951473
INFO:root:At the start of the epoch: mem (CPU python)=36598.9375MB; mem (CPU total)=36455.8984375MB
INFO:root:[   49] Training loss: 0.61952198, Validation loss: 0.62843116, Gradient norm: 0.28503599
INFO:root:At the start of the epoch: mem (CPU python)=36637.03125MB; mem (CPU total)=36493.72265625MB
INFO:root:[   50] Training loss: 0.61919203, Validation loss: 0.62812898, Gradient norm: 0.26026854
INFO:root:At the start of the epoch: mem (CPU python)=36675.12890625MB; mem (CPU total)=36533.3984375MB
INFO:root:[   51] Training loss: 0.61850097, Validation loss: 0.62786358, Gradient norm: 0.27643189
INFO:root:At the start of the epoch: mem (CPU python)=36713.2265625MB; mem (CPU total)=36571.93359375MB
INFO:root:[   52] Training loss: 0.61799148, Validation loss: 0.62778923, Gradient norm: 0.23520136
INFO:root:At the start of the epoch: mem (CPU python)=36751.3203125MB; mem (CPU total)=36610.0546875MB
INFO:root:[   53] Training loss: 0.61720015, Validation loss: 0.62692576, Gradient norm: 0.25360461
INFO:root:At the start of the epoch: mem (CPU python)=36789.4140625MB; mem (CPU total)=36647.87109375MB
INFO:root:[   54] Training loss: 0.61677729, Validation loss: 0.62741896, Gradient norm: 0.25495294
INFO:root:At the start of the epoch: mem (CPU python)=36827.51171875MB; mem (CPU total)=36685.7578125MB
INFO:root:[   55] Training loss: 0.61624263, Validation loss: 0.62664786, Gradient norm: 0.29519471
INFO:root:At the start of the epoch: mem (CPU python)=36865.60546875MB; mem (CPU total)=36723.5625MB
INFO:root:[   56] Training loss: 0.61572231, Validation loss: 0.62640776, Gradient norm: 0.26331443
INFO:root:At the start of the epoch: mem (CPU python)=36903.69921875MB; mem (CPU total)=36761.44921875MB
INFO:root:[   57] Training loss: 0.61508817, Validation loss: 0.62605162, Gradient norm: 0.31003620
INFO:root:At the start of the epoch: mem (CPU python)=36941.796875MB; mem (CPU total)=36798.8515625MB
INFO:root:[   58] Training loss: 0.61473281, Validation loss: 0.62555284, Gradient norm: 0.28288184
INFO:root:At the start of the epoch: mem (CPU python)=36979.890625MB; mem (CPU total)=36837.39453125MB
INFO:root:[   59] Training loss: 0.61401786, Validation loss: 0.62535993, Gradient norm: 0.28187718
INFO:root:At the start of the epoch: mem (CPU python)=37018.859375MB; mem (CPU total)=36876.28515625MB
INFO:root:[   60] Training loss: 0.61376785, Validation loss: 0.62602103, Gradient norm: 0.33107783
INFO:root:At the start of the epoch: mem (CPU python)=37056.9609375MB; mem (CPU total)=36913.84375MB
INFO:root:[   61] Training loss: 0.61326818, Validation loss: 0.62490676, Gradient norm: 0.31132988
INFO:root:At the start of the epoch: mem (CPU python)=37095.0546875MB; mem (CPU total)=36952.41796875MB
INFO:root:[   62] Training loss: 0.61271812, Validation loss: 0.62485971, Gradient norm: 0.32125537
INFO:root:At the start of the epoch: mem (CPU python)=37133.1484375MB; mem (CPU total)=36991.75MB
INFO:root:[   63] Training loss: 0.61223670, Validation loss: 0.62432827, Gradient norm: 0.28255050
INFO:root:At the start of the epoch: mem (CPU python)=37171.2421875MB; mem (CPU total)=37030.3671875MB
INFO:root:[   64] Training loss: 0.61183031, Validation loss: 0.62459153, Gradient norm: 0.29940837
INFO:root:At the start of the epoch: mem (CPU python)=37209.33984375MB; mem (CPU total)=37067.13671875MB
INFO:root:[   65] Training loss: 0.61133222, Validation loss: 0.62467215, Gradient norm: 0.35551835
INFO:root:At the start of the epoch: mem (CPU python)=37247.43359375MB; mem (CPU total)=37104.68359375MB
INFO:root:[   66] Training loss: 0.61084812, Validation loss: 0.62444915, Gradient norm: 0.32400132
INFO:root:At the start of the epoch: mem (CPU python)=37286.15234375MB; mem (CPU total)=37143.56640625MB
INFO:root:[   67] Training loss: 0.61052227, Validation loss: 0.62444330, Gradient norm: 0.33533188
INFO:root:At the start of the epoch: mem (CPU python)=37324.25390625MB; mem (CPU total)=37182.109375MB
INFO:root:[   68] Training loss: 0.60983417, Validation loss: 0.62423870, Gradient norm: 0.36211747
INFO:root:At the start of the epoch: mem (CPU python)=37362.34765625MB; mem (CPU total)=37219.8515625MB
INFO:root:[   69] Training loss: 0.60953658, Validation loss: 0.62351382, Gradient norm: 0.31480736
INFO:root:At the start of the epoch: mem (CPU python)=37400.4375MB; mem (CPU total)=37257.91015625MB
INFO:root:[   70] Training loss: 0.60907967, Validation loss: 0.62387038, Gradient norm: 0.32539786
INFO:root:At the start of the epoch: mem (CPU python)=37438.53515625MB; mem (CPU total)=37295.89453125MB
INFO:root:[   71] Training loss: 0.60866919, Validation loss: 0.62340424, Gradient norm: 0.38931214
INFO:root:At the start of the epoch: mem (CPU python)=37476.6328125MB; mem (CPU total)=37334.7578125MB
INFO:root:[   72] Training loss: 0.60827623, Validation loss: 0.62312654, Gradient norm: 0.37642790
INFO:root:At the start of the epoch: mem (CPU python)=37514.7265625MB; mem (CPU total)=37467.65625MB
INFO:root:[   73] Training loss: 0.60785605, Validation loss: 0.62329743, Gradient norm: 0.33188613
INFO:root:At the start of the epoch: mem (CPU python)=37552.8203125MB; mem (CPU total)=37411.1875MB
INFO:root:[   74] Training loss: 0.60737934, Validation loss: 0.62329659, Gradient norm: 0.37495977
INFO:root:At the start of the epoch: mem (CPU python)=37590.91796875MB; mem (CPU total)=39569.67578125MB
INFO:root:[   75] Training loss: 0.60712732, Validation loss: 0.62227782, Gradient norm: 0.38109293
INFO:root:At the start of the epoch: mem (CPU python)=37629.01171875MB; mem (CPU total)=39626.8125MB
INFO:root:[   76] Training loss: 0.60672204, Validation loss: 0.62242510, Gradient norm: 0.39440794
INFO:root:At the start of the epoch: mem (CPU python)=37667.10546875MB; mem (CPU total)=39456.74609375MB
INFO:root:[   77] Training loss: 0.60611518, Validation loss: 0.62329597, Gradient norm: 0.33219438
INFO:root:At the start of the epoch: mem (CPU python)=37705.20703125MB; mem (CPU total)=37564.34375MB
INFO:root:[   78] Training loss: 0.60565343, Validation loss: 0.62333621, Gradient norm: 0.42473132
INFO:root:At the start of the epoch: mem (CPU python)=37743.30078125MB; mem (CPU total)=37603.0703125MB
INFO:root:[   79] Training loss: 0.60555968, Validation loss: 0.62239155, Gradient norm: 0.39300633
INFO:root:At the start of the epoch: mem (CPU python)=37781.39453125MB; mem (CPU total)=39610.0546875MB
INFO:root:[   80] Training loss: 0.60512807, Validation loss: 0.62313853, Gradient norm: 0.47019454
INFO:root:At the start of the epoch: mem (CPU python)=37819.48828125MB; mem (CPU total)=39650.66796875MB
INFO:root:[   81] Training loss: 0.60465260, Validation loss: 0.62206314, Gradient norm: 0.47231495
INFO:root:At the start of the epoch: mem (CPU python)=37857.5859375MB; mem (CPU total)=37717.8984375MB
INFO:root:[   82] Training loss: 0.60444843, Validation loss: 0.62226979, Gradient norm: 0.59170990
INFO:root:At the start of the epoch: mem (CPU python)=37895.6796875MB; mem (CPU total)=64237.5859375MB
INFO:root:[   83] Training loss: 0.60423234, Validation loss: 0.62333054, Gradient norm: 0.63280685
INFO:root:At the start of the epoch: mem (CPU python)=37933.7734375MB; mem (CPU total)=37794.2109375MB
INFO:root:[   84] Training loss: 0.60364402, Validation loss: 0.62265971, Gradient norm: 0.48436653
INFO:root:At the start of the epoch: mem (CPU python)=37971.87109375MB; mem (CPU total)=40911.4609375MB
INFO:root:[   85] Training loss: 0.60330445, Validation loss: 0.62167453, Gradient norm: 0.42992049
INFO:root:At the start of the epoch: mem (CPU python)=38009.96875MB; mem (CPU total)=37870.34375MB
INFO:root:[   86] Training loss: 0.60299616, Validation loss: 0.62295364, Gradient norm: 0.87250535
INFO:root:At the start of the epoch: mem (CPU python)=38048.05859375MB; mem (CPU total)=37908.62109375MB
INFO:root:[   87] Training loss: 0.60242685, Validation loss: 0.62223764, Gradient norm: 0.42895794
INFO:root:At the start of the epoch: mem (CPU python)=38086.15625MB; mem (CPU total)=37948.640625MB
INFO:root:[   88] Training loss: 0.60223281, Validation loss: 0.62341843, Gradient norm: 0.45834259
INFO:root:At the start of the epoch: mem (CPU python)=38124.2578125MB; mem (CPU total)=37986.2734375MB
INFO:root:[   89] Training loss: 0.60187762, Validation loss: 0.62203230, Gradient norm: 0.49399532
INFO:root:At the start of the epoch: mem (CPU python)=38162.3515625MB; mem (CPU total)=38024.39453125MB
INFO:root:[   90] Training loss: 0.60150365, Validation loss: 0.62184630, Gradient norm: 0.49850407
INFO:root:At the start of the epoch: mem (CPU python)=38200.4453125MB; mem (CPU total)=38062.7578125MB
INFO:root:[   91] Training loss: 0.60120937, Validation loss: 0.62246882, Gradient norm: 0.49514947
INFO:root:At the start of the epoch: mem (CPU python)=38238.54296875MB; mem (CPU total)=38100.83203125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   92] Training loss: 0.60121437, Validation loss: 0.62298338, Gradient norm: 0.88919157
INFO:root:At the start of the epoch: mem (CPU python)=38276.640625MB; mem (CPU total)=38139.1015625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   93] Training loss: 0.59871581, Validation loss: 0.62143622, Gradient norm: 0.30458663
INFO:root:At the start of the epoch: mem (CPU python)=38314.734375MB; mem (CPU total)=38175.375MB
INFO:root:[   94] Training loss: 0.59751056, Validation loss: 0.62075546, Gradient norm: 0.24573666
INFO:root:At the start of the epoch: mem (CPU python)=38352.83203125MB; mem (CPU total)=38213.83203125MB
INFO:root:[   95] Training loss: 0.59739993, Validation loss: 0.62129629, Gradient norm: 0.25315521
INFO:root:At the start of the epoch: mem (CPU python)=38390.92578125MB; mem (CPU total)=38251.89453125MB
INFO:root:[   96] Training loss: 0.59710824, Validation loss: 0.62126281, Gradient norm: 0.27106465
INFO:root:At the start of the epoch: mem (CPU python)=38429.01953125MB; mem (CPU total)=38289.9140625MB
INFO:root:[   97] Training loss: 0.59712802, Validation loss: 0.62094159, Gradient norm: 0.28004268
INFO:root:At the start of the epoch: mem (CPU python)=38467.11328125MB; mem (CPU total)=38328.23828125MB
INFO:root:[   98] Training loss: 0.59701672, Validation loss: 0.62124830, Gradient norm: 0.28538212
INFO:root:At the start of the epoch: mem (CPU python)=38505.2109375MB; mem (CPU total)=38366.37890625MB
INFO:root:[   99] Training loss: 0.59694085, Validation loss: 0.62168063, Gradient norm: 0.29699609
INFO:root:At the start of the epoch: mem (CPU python)=38543.3046875MB; mem (CPU total)=38404.4609375MB
INFO:root:[  100] Training loss: 0.59680732, Validation loss: 0.62168591, Gradient norm: 0.27952729
INFO:root:At the start of the epoch: mem (CPU python)=38581.40234375MB; mem (CPU total)=38443.01171875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  101] Training loss: 0.59672525, Validation loss: 0.62155364, Gradient norm: 0.29131785
INFO:root:At the start of the epoch: mem (CPU python)=38619.5MB; mem (CPU total)=38480.61328125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  102] Training loss: 0.59617947, Validation loss: 0.62161744, Gradient norm: 0.22304984
INFO:root:At the start of the epoch: mem (CPU python)=38657.59375MB; mem (CPU total)=38519.03515625MB
INFO:root:[  103] Training loss: 0.59583087, Validation loss: 0.62113231, Gradient norm: 0.20646979
INFO:root:At the start of the epoch: mem (CPU python)=38695.6875MB; mem (CPU total)=38557.13671875MB
INFO:root:EP 103: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=38733.78125MB; mem (CPU total)=38595.0MB
INFO:root:Training the model took 21452.941s.
INFO:root:Emptying the cuda cache took 0.389s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85868
INFO:root:EnergyScoreTrain: 0.60582
INFO:root:CRPSTrain: 0.51948
INFO:root:Gaussian NLLTrain: 1.78709
INFO:root:CoverageTrain: 0.82901
INFO:root:IntervalWidthTrain: 3.33691
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89233
INFO:root:EnergyScoreValidation: 0.62868
INFO:root:CRPSValidation: 0.5385
INFO:root:Gaussian NLLValidation: 1.83575
INFO:root:CoverageValidation: 0.81809
INFO:root:IntervalWidthValidation: 3.31876
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89195
INFO:root:EnergyScoreTest: 0.62843
INFO:root:CRPSTest: 0.53841
INFO:root:Gaussian NLLTest: 1.83487
INFO:root:CoverageTest: 0.81753
INFO:root:IntervalWidthTest: 3.30982
INFO:root:After validation: mem (CPU python)=38776.68359375MB; mem (CPU total)=38637.71484375MB
