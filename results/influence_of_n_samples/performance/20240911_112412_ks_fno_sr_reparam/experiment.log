INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=576.32421875MB; mem (CPU total)=941.96875MB
INFO:root:############### Starting experiment with config file ks/fno_sr_reparam.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12455.5234375MB; mem (CPU total)=948.09765625MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12455.5234375MB; mem (CPU total)=947.703125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12455.5234375MB; mem (CPU total)=2141.953125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=2152.90625MB
INFO:root:[    1] Training loss: 0.72493498, Validation loss: 0.72053942, Gradient norm: 0.01838229
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3360.00390625MB
INFO:root:[    2] Training loss: 0.72001753, Validation loss: 0.71959114, Gradient norm: 0.00565320
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3398.59375MB
INFO:root:[    3] Training loss: 0.71861572, Validation loss: 0.71700395, Gradient norm: 0.00642091
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3437.0625MB
INFO:root:[    4] Training loss: 0.71358921, Validation loss: 0.70715408, Gradient norm: 0.01404428
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3475.70703125MB
INFO:root:[    5] Training loss: 0.70620942, Validation loss: 0.70005436, Gradient norm: 0.01961631
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3513.51953125MB
INFO:root:[    6] Training loss: 0.70034110, Validation loss: 0.69447955, Gradient norm: 0.02674406
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3552.046875MB
INFO:root:[    7] Training loss: 0.69514712, Validation loss: 0.68823737, Gradient norm: 0.02641164
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3590.40234375MB
INFO:root:[    8] Training loss: 0.68941656, Validation loss: 0.68109854, Gradient norm: 0.03070647
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3628.62890625MB
INFO:root:[    9] Training loss: 0.68393610, Validation loss: 0.67495899, Gradient norm: 0.02950771
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3666.56640625MB
INFO:root:[   10] Training loss: 0.67937578, Validation loss: 0.66935695, Gradient norm: 0.03344146
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3704.93359375MB
INFO:root:[   11] Training loss: 0.67537717, Validation loss: 0.66583613, Gradient norm: 0.03255893
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3743.10546875MB
INFO:root:[   12] Training loss: 0.67189543, Validation loss: 0.66262737, Gradient norm: 0.03243411
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3781.1328125MB
INFO:root:[   13] Training loss: 0.66924496, Validation loss: 0.65959053, Gradient norm: 0.03404084
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3819.3828125MB
INFO:root:[   14] Training loss: 0.66671466, Validation loss: 0.65680977, Gradient norm: 0.03574987
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3857.2265625MB
INFO:root:[   15] Training loss: 0.66452706, Validation loss: 0.65398934, Gradient norm: 0.03630879
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3895.8203125MB
INFO:root:[   16] Training loss: 0.66258295, Validation loss: 0.65203783, Gradient norm: 0.03451390
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3933.95703125MB
INFO:root:[   17] Training loss: 0.66076686, Validation loss: 0.64951207, Gradient norm: 0.03443571
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=3971.515625MB
INFO:root:[   18] Training loss: 0.65923442, Validation loss: 0.64910412, Gradient norm: 0.03513985
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4009.75390625MB
INFO:root:[   19] Training loss: 0.65790471, Validation loss: 0.64794341, Gradient norm: 0.03733068
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4048.15625MB
INFO:root:[   20] Training loss: 0.65652045, Validation loss: 0.64645427, Gradient norm: 0.03906732
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4086.4609375MB
INFO:root:[   21] Training loss: 0.65517976, Validation loss: 0.64430866, Gradient norm: 0.03846237
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4124.58203125MB
INFO:root:[   22] Training loss: 0.65400453, Validation loss: 0.64378260, Gradient norm: 0.04032224
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4162.87890625MB
INFO:root:[   23] Training loss: 0.65285951, Validation loss: 0.64205965, Gradient norm: 0.04098917
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4201.0MB
INFO:root:[   24] Training loss: 0.65169132, Validation loss: 0.64138741, Gradient norm: 0.04101791
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4239.12890625MB
INFO:root:[   25] Training loss: 0.65085075, Validation loss: 0.64032276, Gradient norm: 0.03993780
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4277.46875MB
INFO:root:[   26] Training loss: 0.64974891, Validation loss: 0.63975257, Gradient norm: 0.04430935
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4315.625MB
INFO:root:[   27] Training loss: 0.64904678, Validation loss: 0.63953844, Gradient norm: 0.04313862
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4353.66015625MB
INFO:root:[   28] Training loss: 0.64786721, Validation loss: 0.63781744, Gradient norm: 0.04301790
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4391.8046875MB
INFO:root:[   29] Training loss: 0.64715494, Validation loss: 0.63720983, Gradient norm: 0.04447976
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4429.93359375MB
INFO:root:[   30] Training loss: 0.64632623, Validation loss: 0.63616309, Gradient norm: 0.04533736
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4468.0234375MB
INFO:root:[   31] Training loss: 0.64535217, Validation loss: 0.63544643, Gradient norm: 0.04160994
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4506.328125MB
INFO:root:[   32] Training loss: 0.64468759, Validation loss: 0.63442913, Gradient norm: 0.04375800
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4544.48046875MB
INFO:root:[   33] Training loss: 0.64391661, Validation loss: 0.63317236, Gradient norm: 0.04981859
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4583.21875MB
INFO:root:[   34] Training loss: 0.64321233, Validation loss: 0.63390219, Gradient norm: 0.04608831
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4620.828125MB
INFO:root:[   35] Training loss: 0.64283891, Validation loss: 0.63331319, Gradient norm: 0.04951106
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4658.8203125MB
INFO:root:[   36] Training loss: 0.64188787, Validation loss: 0.63248345, Gradient norm: 0.04586478
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4697.3125MB
INFO:root:[   37] Training loss: 0.64132845, Validation loss: 0.63228009, Gradient norm: 0.04691759
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4735.49609375MB
INFO:root:[   38] Training loss: 0.64069571, Validation loss: 0.63197450, Gradient norm: 0.05117577
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4774.0859375MB
INFO:root:[   39] Training loss: 0.64020341, Validation loss: 0.62969303, Gradient norm: 0.04759367
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4812.05078125MB
INFO:root:[   40] Training loss: 0.63942534, Validation loss: 0.62952434, Gradient norm: 0.04846792
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4849.95703125MB
INFO:root:[   41] Training loss: 0.63891610, Validation loss: 0.62939539, Gradient norm: 0.05194334
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4888.47265625MB
INFO:root:[   42] Training loss: 0.63831377, Validation loss: 0.62834619, Gradient norm: 0.04596547
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4926.6875MB
INFO:root:[   43] Training loss: 0.63781709, Validation loss: 0.62797658, Gradient norm: 0.04539140
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=4964.93359375MB
INFO:root:[   44] Training loss: 0.63740438, Validation loss: 0.62712837, Gradient norm: 0.05372204
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5003.09375MB
INFO:root:[   45] Training loss: 0.63701189, Validation loss: 0.62700218, Gradient norm: 0.05056462
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5041.2421875MB
INFO:root:[   46] Training loss: 0.63650502, Validation loss: 0.62698821, Gradient norm: 0.05376298
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5079.18359375MB
INFO:root:[   47] Training loss: 0.63603694, Validation loss: 0.62631105, Gradient norm: 0.05763664
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5117.328125MB
INFO:root:[   48] Training loss: 0.63536908, Validation loss: 0.62635136, Gradient norm: 0.04982784
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5155.734375MB
INFO:root:[   49] Training loss: 0.63543002, Validation loss: 0.62619057, Gradient norm: 0.05887517
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5193.66015625MB
INFO:root:[   50] Training loss: 0.63471953, Validation loss: 0.62420628, Gradient norm: 0.05384615
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5231.56640625MB
INFO:root:[   51] Training loss: 0.63431721, Validation loss: 0.62428106, Gradient norm: 0.05315498
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5270.27734375MB
INFO:root:[   52] Training loss: 0.63363757, Validation loss: 0.62417447, Gradient norm: 0.04678823
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5307.52734375MB
INFO:root:[   53] Training loss: 0.63357294, Validation loss: 0.62392858, Gradient norm: 0.05152661
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5345.6875MB
INFO:root:[   54] Training loss: 0.63297905, Validation loss: 0.62238789, Gradient norm: 0.05092361
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5383.59375MB
INFO:root:[   55] Training loss: 0.63261877, Validation loss: 0.62317118, Gradient norm: 0.04966553
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5421.5078125MB
INFO:root:[   56] Training loss: 0.63231515, Validation loss: 0.62288397, Gradient norm: 0.04978120
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5459.6640625MB
INFO:root:[   57] Training loss: 0.63193543, Validation loss: 0.62158464, Gradient norm: 0.05458494
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5497.81640625MB
INFO:root:[   58] Training loss: 0.63135549, Validation loss: 0.62207888, Gradient norm: 0.05001424
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5535.97265625MB
INFO:root:[   59] Training loss: 0.63133701, Validation loss: 0.62246160, Gradient norm: 0.05784271
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5573.86328125MB
INFO:root:[   60] Training loss: 0.63077624, Validation loss: 0.62173907, Gradient norm: 0.05276363
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5612.01953125MB
INFO:root:[   61] Training loss: 0.63046263, Validation loss: 0.62090047, Gradient norm: 0.05394750
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5650.42578125MB
INFO:root:[   62] Training loss: 0.63020972, Validation loss: 0.62048903, Gradient norm: 0.05195489
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5688.578125MB
INFO:root:[   63] Training loss: 0.62974743, Validation loss: 0.62045872, Gradient norm: 0.05255663
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5727.04296875MB
INFO:root:[   64] Training loss: 0.62938574, Validation loss: 0.62070030, Gradient norm: 0.05065340
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5764.93359375MB
INFO:root:[   65] Training loss: 0.62915598, Validation loss: 0.62050756, Gradient norm: 0.05388588
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5802.84375MB
INFO:root:[   66] Training loss: 0.62906534, Validation loss: 0.61933980, Gradient norm: 0.06495372
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5840.89453125MB
INFO:root:[   67] Training loss: 0.62873798, Validation loss: 0.61931815, Gradient norm: 0.05344456
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5879.4765625MB
INFO:root:[   68] Training loss: 0.62829186, Validation loss: 0.61957695, Gradient norm: 0.05105792
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5917.2421875MB
INFO:root:[   69] Training loss: 0.62815011, Validation loss: 0.61899355, Gradient norm: 0.05789609
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5955.50390625MB
INFO:root:[   70] Training loss: 0.62763617, Validation loss: 0.61888597, Gradient norm: 0.05386197
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=5993.66015625MB
INFO:root:[   71] Training loss: 0.62756496, Validation loss: 0.61841166, Gradient norm: 0.05897103
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6032.0MB
INFO:root:[   72] Training loss: 0.62713828, Validation loss: 0.61898917, Gradient norm: 0.05743158
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6070.8515625MB
INFO:root:[   73] Training loss: 0.62683005, Validation loss: 0.61861961, Gradient norm: 0.05518800
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6109.96484375MB
INFO:root:[   74] Training loss: 0.62668388, Validation loss: 0.61922289, Gradient norm: 0.05304426
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6147.890625MB
INFO:root:[   75] Training loss: 0.62625146, Validation loss: 0.61710620, Gradient norm: 0.05355206
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6186.52734375MB
INFO:root:[   76] Training loss: 0.62609215, Validation loss: 0.61613001, Gradient norm: 0.05844609
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6224.703125MB
INFO:root:[   77] Training loss: 0.62569255, Validation loss: 0.61822023, Gradient norm: 0.05345180
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6262.6015625MB
INFO:root:[   78] Training loss: 0.62547192, Validation loss: 0.61777522, Gradient norm: 0.06161693
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6300.953125MB
INFO:root:[   79] Training loss: 0.62518314, Validation loss: 0.61678655, Gradient norm: 0.04967545
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6338.8515625MB
INFO:root:[   80] Training loss: 0.62501439, Validation loss: 0.61580254, Gradient norm: 0.05782078
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6376.97265625MB
INFO:root:[   81] Training loss: 0.62499296, Validation loss: 0.61737084, Gradient norm: 0.05561923
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6415.36328125MB
INFO:root:[   82] Training loss: 0.62482569, Validation loss: 0.61665762, Gradient norm: 0.05772289
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6453.5MB
INFO:root:[   83] Training loss: 0.62441005, Validation loss: 0.61645754, Gradient norm: 0.05793145
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6491.54296875MB
INFO:root:[   84] Training loss: 0.62413040, Validation loss: 0.61515217, Gradient norm: 0.06170000
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6529.6484375MB
INFO:root:[   85] Training loss: 0.62394720, Validation loss: 0.61658021, Gradient norm: 0.06412341
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6568.03125MB
INFO:root:[   86] Training loss: 0.62381734, Validation loss: 0.61612568, Gradient norm: 0.05960326
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6606.1484375MB
INFO:root:[   87] Training loss: 0.62355578, Validation loss: 0.61585310, Gradient norm: 0.06099405
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6644.5390625MB
INFO:root:[   88] Training loss: 0.62344862, Validation loss: 0.61638735, Gradient norm: 0.06027293
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6682.68359375MB
INFO:root:[   89] Training loss: 0.62323667, Validation loss: 0.61454858, Gradient norm: 0.05947526
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6720.48828125MB
INFO:root:[   90] Training loss: 0.62270205, Validation loss: 0.61493231, Gradient norm: 0.05384611
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6758.87890625MB
INFO:root:[   91] Training loss: 0.62276429, Validation loss: 0.61577909, Gradient norm: 0.05864920
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6797.0234375MB
INFO:root:[   92] Training loss: 0.62261871, Validation loss: 0.61444878, Gradient norm: 0.06027791
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6835.16796875MB
INFO:root:[   93] Training loss: 0.62212318, Validation loss: 0.61587465, Gradient norm: 0.05490875
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6873.55078125MB
INFO:root:[   94] Training loss: 0.62223667, Validation loss: 0.61472886, Gradient norm: 0.05727586
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6911.92578125MB
INFO:root:[   95] Training loss: 0.62203543, Validation loss: 0.61369030, Gradient norm: 0.06324459
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6949.57421875MB
INFO:root:[   96] Training loss: 0.62171273, Validation loss: 0.61413884, Gradient norm: 0.07172561
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=6987.96484375MB
INFO:root:[   97] Training loss: 0.62171493, Validation loss: 0.61343843, Gradient norm: 0.06044456
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7026.09765625MB
INFO:root:[   98] Training loss: 0.62150293, Validation loss: 0.61266178, Gradient norm: 0.06735680
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7064.296875MB
INFO:root:[   99] Training loss: 0.62104486, Validation loss: 0.61456716, Gradient norm: 0.06141576
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7102.828125MB
INFO:root:[  100] Training loss: 0.62110722, Validation loss: 0.61554364, Gradient norm: 0.05743015
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7140.72265625MB
INFO:root:[  101] Training loss: 0.62112263, Validation loss: 0.61302184, Gradient norm: 0.06232155
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7178.8671875MB
INFO:root:[  102] Training loss: 0.62096603, Validation loss: 0.61296531, Gradient norm: 0.05977503
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7217.2578125MB
INFO:root:[  103] Training loss: 0.62058905, Validation loss: 0.61258223, Gradient norm: 0.05864218
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7255.39453125MB
INFO:root:[  104] Training loss: 0.62033463, Validation loss: 0.61281916, Gradient norm: 0.05856231
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7293.5390625MB
INFO:root:[  105] Training loss: 0.62024523, Validation loss: 0.61358066, Gradient norm: 0.06301607
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7331.19140625MB
INFO:root:[  106] Training loss: 0.61997588, Validation loss: 0.61286842, Gradient norm: 0.06137979
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7369.3046875MB
INFO:root:[  107] Training loss: 0.61989378, Validation loss: 0.61191714, Gradient norm: 0.05887047
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7407.3046875MB
INFO:root:[  108] Training loss: 0.61965739, Validation loss: 0.61360356, Gradient norm: 0.06021130
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7445.6953125MB
INFO:root:[  109] Training loss: 0.61932242, Validation loss: 0.61468388, Gradient norm: 0.05952302
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7483.87109375MB
INFO:root:[  110] Training loss: 0.61944808, Validation loss: 0.61236613, Gradient norm: 0.06966025
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7521.75390625MB
INFO:root:[  111] Training loss: 0.61913834, Validation loss: 0.61425548, Gradient norm: 0.05993533
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7560.140625MB
INFO:root:[  112] Training loss: 0.61888509, Validation loss: 0.61243238, Gradient norm: 0.06048319
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7597.80078125MB
INFO:root:[  113] Training loss: 0.61909088, Validation loss: 0.61076869, Gradient norm: 0.06016555
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7635.97265625MB
INFO:root:[  114] Training loss: 0.61878266, Validation loss: 0.61328642, Gradient norm: 0.06750194
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7674.87109375MB
INFO:root:[  115] Training loss: 0.61853240, Validation loss: 0.61308217, Gradient norm: 0.05924374
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7712.7421875MB
INFO:root:[  116] Training loss: 0.61869638, Validation loss: 0.61438500, Gradient norm: 0.06943522
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7751.1015625MB
INFO:root:[  117] Training loss: 0.61838470, Validation loss: 0.61360647, Gradient norm: 0.06011863
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7789.5078125MB
INFO:root:[  118] Training loss: 0.61843351, Validation loss: 0.61231843, Gradient norm: 0.06000676
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7827.66796875MB
INFO:root:[  119] Training loss: 0.61826284, Validation loss: 0.61238707, Gradient norm: 0.07031227
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7865.828125MB
INFO:root:[  120] Training loss: 0.61823903, Validation loss: 0.61276749, Gradient norm: 0.06250054
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7903.734375MB
INFO:root:[  121] Training loss: 0.61773813, Validation loss: 0.61141928, Gradient norm: 0.05812289
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7942.03515625MB
INFO:root:[  122] Training loss: 0.61779865, Validation loss: 0.61051946, Gradient norm: 0.06398466
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=7980.44140625MB
INFO:root:[  123] Training loss: 0.61740835, Validation loss: 0.61136018, Gradient norm: 0.06187857
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8018.35546875MB
INFO:root:[  124] Training loss: 0.61759962, Validation loss: 0.61074221, Gradient norm: 0.06693003
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8056.76171875MB
INFO:root:[  125] Training loss: 0.61728895, Validation loss: 0.61135240, Gradient norm: 0.06445582
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8094.53515625MB
INFO:root:[  126] Training loss: 0.61711390, Validation loss: 0.61145244, Gradient norm: 0.06233379
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8133.30078125MB
INFO:root:[  127] Training loss: 0.61662613, Validation loss: 0.61232832, Gradient norm: 0.06330719
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8171.30859375MB
INFO:root:[  128] Training loss: 0.61690541, Validation loss: 0.61265090, Gradient norm: 0.07374344
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8209.46875MB
INFO:root:[  129] Training loss: 0.61680808, Validation loss: 0.61039067, Gradient norm: 0.06793934
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8248.171875MB
INFO:root:[  130] Training loss: 0.61648661, Validation loss: 0.61164812, Gradient norm: 0.06047528
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8285.96875MB
INFO:root:[  131] Training loss: 0.61627759, Validation loss: 0.61001283, Gradient norm: 0.06274862
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8324.1640625MB
INFO:root:[  132] Training loss: 0.61630409, Validation loss: 0.61317519, Gradient norm: 0.06694939
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8362.078125MB
INFO:root:[  133] Training loss: 0.61599905, Validation loss: 0.61171177, Gradient norm: 0.06331730
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8400.875MB
INFO:root:[  134] Training loss: 0.61598042, Validation loss: 0.61125269, Gradient norm: 0.05969996
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8438.640625MB
INFO:root:[  135] Training loss: 0.61583425, Validation loss: 0.61038000, Gradient norm: 0.05870867
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8476.3046875MB
INFO:root:[  136] Training loss: 0.61585136, Validation loss: 0.61034183, Gradient norm: 0.06143829
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8514.765625MB
INFO:root:[  137] Training loss: 0.61572679, Validation loss: 0.61223733, Gradient norm: 0.06894729
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8552.92578125MB
INFO:root:[  138] Training loss: 0.61574768, Validation loss: 0.61167498, Gradient norm: 0.06915411
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8591.0859375MB
INFO:root:[  139] Training loss: 0.61562329, Validation loss: 0.61190321, Gradient norm: 0.06477591
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8629.4296875MB
INFO:root:[  140] Training loss: 0.61541766, Validation loss: 0.61014569, Gradient norm: 0.06677194
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8667.3671875MB
INFO:root:EP 140: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12455.5234375MB; mem (CPU total)=8705.51953125MB
INFO:root:Training the model took 5273.416s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84951
INFO:root:EnergyScoreTrain: 0.59797
INFO:root:CRPSTrain: 0.46803
INFO:root:Gaussian NLLTrain: 1.215
INFO:root:CoverageTrain: 0.94403
INFO:root:IntervalWidthTrain: 3.26994
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8673
INFO:root:EnergyScoreValidation: 0.61045
INFO:root:CRPSValidation: 0.4786
INFO:root:Gaussian NLLValidation: 1.23879
INFO:root:CoverageValidation: 0.93787
INFO:root:IntervalWidthValidation: 3.2719
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86909
INFO:root:EnergyScoreTest: 0.6117
INFO:root:CRPSTest: 0.47969
INFO:root:Gaussian NLLTest: 1.24093
INFO:root:CoverageTest: 0.93734
INFO:root:IntervalWidthTest: 3.27215
INFO:root:After validation: mem (CPU python)=12455.5234375MB; mem (CPU total)=8753.79296875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=12455.5234375MB; mem (CPU total)=8754.09375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12455.5234375MB; mem (CPU total)=8754.5859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8754.515625MB
INFO:root:[    1] Training loss: 0.72542543, Validation loss: 0.72095413, Gradient norm: 0.02236171
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8792.625MB
INFO:root:[    2] Training loss: 0.71985797, Validation loss: 0.71913494, Gradient norm: 0.00575617
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8830.19140625MB
INFO:root:[    3] Training loss: 0.71770882, Validation loss: 0.71374727, Gradient norm: 0.00857840
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8868.34765625MB
INFO:root:[    4] Training loss: 0.71110089, Validation loss: 0.70545655, Gradient norm: 0.01735657
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8906.50390625MB
INFO:root:[    5] Training loss: 0.70427535, Validation loss: 0.69786310, Gradient norm: 0.02373386
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8944.38671875MB
INFO:root:[    6] Training loss: 0.69920011, Validation loss: 0.69287278, Gradient norm: 0.02449935
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=8982.546875MB
INFO:root:[    7] Training loss: 0.69471543, Validation loss: 0.68885059, Gradient norm: 0.02612252
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9020.70703125MB
INFO:root:[    8] Training loss: 0.69087397, Validation loss: 0.68437715, Gradient norm: 0.02875704
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9058.8671875MB
INFO:root:[    9] Training loss: 0.68750261, Validation loss: 0.68102549, Gradient norm: 0.03197768
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9097.2734375MB
INFO:root:[   10] Training loss: 0.68434905, Validation loss: 0.67751929, Gradient norm: 0.03152348
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9134.203125MB
INFO:root:[   11] Training loss: 0.68186341, Validation loss: 0.67510155, Gradient norm: 0.03355039
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9172.59765625MB
INFO:root:[   12] Training loss: 0.67942242, Validation loss: 0.67193333, Gradient norm: 0.03803069
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9210.6484375MB
INFO:root:[   13] Training loss: 0.67731361, Validation loss: 0.66897919, Gradient norm: 0.03418353
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9249.08203125MB
INFO:root:[   14] Training loss: 0.67520310, Validation loss: 0.66748048, Gradient norm: 0.03881806
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9286.2578125MB
INFO:root:[   15] Training loss: 0.67308460, Validation loss: 0.66539385, Gradient norm: 0.03748858
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9324.45703125MB
INFO:root:[   16] Training loss: 0.67132272, Validation loss: 0.66289121, Gradient norm: 0.03632207
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9362.5078125MB
INFO:root:[   17] Training loss: 0.66958134, Validation loss: 0.66225072, Gradient norm: 0.03721161
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9400.66796875MB
INFO:root:[   18] Training loss: 0.66796807, Validation loss: 0.65914625, Gradient norm: 0.03925176
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9438.7421875MB
INFO:root:[   19] Training loss: 0.66629515, Validation loss: 0.65793662, Gradient norm: 0.03833266
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9476.88671875MB
INFO:root:[   20] Training loss: 0.66486425, Validation loss: 0.65548592, Gradient norm: 0.03852199
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9514.78515625MB
INFO:root:[   21] Training loss: 0.66352942, Validation loss: 0.65437251, Gradient norm: 0.04065986
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9552.9296875MB
INFO:root:[   22] Training loss: 0.66221586, Validation loss: 0.65300673, Gradient norm: 0.04292902
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9591.2890625MB
INFO:root:[   23] Training loss: 0.66076652, Validation loss: 0.65115316, Gradient norm: 0.03892972
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9629.1875MB
INFO:root:[   24] Training loss: 0.65936836, Validation loss: 0.64968887, Gradient norm: 0.04348539
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9667.57421875MB
INFO:root:[   25] Training loss: 0.65812590, Validation loss: 0.64899031, Gradient norm: 0.04349274
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9705.6875MB
INFO:root:[   26] Training loss: 0.65710254, Validation loss: 0.64797502, Gradient norm: 0.04306503
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9743.9609375MB
INFO:root:[   27] Training loss: 0.65583092, Validation loss: 0.64557047, Gradient norm: 0.04491135
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9782.35546875MB
INFO:root:[   28] Training loss: 0.65462528, Validation loss: 0.64469265, Gradient norm: 0.04202697
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9820.49609375MB
INFO:root:[   29] Training loss: 0.65371844, Validation loss: 0.64382759, Gradient norm: 0.04347385
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9858.88671875MB
INFO:root:[   30] Training loss: 0.65264813, Validation loss: 0.64329690, Gradient norm: 0.04666201
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9897.0234375MB
INFO:root:[   31] Training loss: 0.65170177, Validation loss: 0.64225336, Gradient norm: 0.04733030
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9935.40234375MB
INFO:root:[   32] Training loss: 0.65050703, Validation loss: 0.64055309, Gradient norm: 0.04461479
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=9973.53125MB
INFO:root:[   33] Training loss: 0.64973763, Validation loss: 0.63930885, Gradient norm: 0.04617041
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10011.69140625MB
INFO:root:[   34] Training loss: 0.64894446, Validation loss: 0.63882828, Gradient norm: 0.04624839
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10049.8359375MB
INFO:root:[   35] Training loss: 0.64792684, Validation loss: 0.63767444, Gradient norm: 0.04788164
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10087.98046875MB
INFO:root:[   36] Training loss: 0.64732039, Validation loss: 0.63761341, Gradient norm: 0.05066573
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10126.37109375MB
INFO:root:[   37] Training loss: 0.64649122, Validation loss: 0.63603755, Gradient norm: 0.04783775
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10164.76171875MB
INFO:root:[   38] Training loss: 0.64570914, Validation loss: 0.63518940, Gradient norm: 0.04740267
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10202.90625MB
INFO:root:[   39] Training loss: 0.64505875, Validation loss: 0.63560039, Gradient norm: 0.04807668
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10241.05078125MB
INFO:root:[   40] Training loss: 0.64434612, Validation loss: 0.63476824, Gradient norm: 0.04707240
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10278.98046875MB
INFO:root:[   41] Training loss: 0.64377218, Validation loss: 0.63392675, Gradient norm: 0.05161608
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10317.125MB
INFO:root:[   42] Training loss: 0.64297171, Validation loss: 0.63429096, Gradient norm: 0.05239701
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10355.484375MB
INFO:root:[   43] Training loss: 0.64243564, Validation loss: 0.63246954, Gradient norm: 0.04964277
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10393.60546875MB
INFO:root:[   44] Training loss: 0.64168839, Validation loss: 0.63418440, Gradient norm: 0.04629378
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10431.55859375MB
INFO:root:[   45] Training loss: 0.64117295, Validation loss: 0.63041850, Gradient norm: 0.05827271
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10469.94140625MB
INFO:root:[   46] Training loss: 0.64077449, Validation loss: 0.63138137, Gradient norm: 0.04923285
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10508.10546875MB
INFO:root:[   47] Training loss: 0.64012766, Validation loss: 0.62999349, Gradient norm: 0.05168874
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10546.265625MB
INFO:root:[   48] Training loss: 0.63951039, Validation loss: 0.63276980, Gradient norm: 0.05003738
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10584.42578125MB
INFO:root:[   49] Training loss: 0.63889823, Validation loss: 0.63079144, Gradient norm: 0.05232576
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10622.30859375MB
INFO:root:[   50] Training loss: 0.63853726, Validation loss: 0.62910252, Gradient norm: 0.05064807
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10660.69921875MB
INFO:root:[   51] Training loss: 0.63812160, Validation loss: 0.62791075, Gradient norm: 0.05322291
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10699.05078125MB
INFO:root:[   52] Training loss: 0.63748136, Validation loss: 0.62862929, Gradient norm: 0.04860350
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10737.3046875MB
INFO:root:[   53] Training loss: 0.63717039, Validation loss: 0.62782155, Gradient norm: 0.05551359
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10775.5234375MB
INFO:root:[   54] Training loss: 0.63666074, Validation loss: 0.62698200, Gradient norm: 0.05888975
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10813.4375MB
INFO:root:[   55] Training loss: 0.63656559, Validation loss: 0.62591020, Gradient norm: 0.06165812
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10851.578125MB
INFO:root:[   56] Training loss: 0.63583012, Validation loss: 0.62640728, Gradient norm: 0.05252512
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10890.33203125MB
INFO:root:[   57] Training loss: 0.63543556, Validation loss: 0.62431519, Gradient norm: 0.05182654
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10928.47265625MB
INFO:root:[   58] Training loss: 0.63510491, Validation loss: 0.62522693, Gradient norm: 0.05333151
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=10966.6171875MB
INFO:root:[   59] Training loss: 0.63454929, Validation loss: 0.62470555, Gradient norm: 0.05485556
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=11004.33203125MB
INFO:root:[   60] Training loss: 0.63393057, Validation loss: 0.62498908, Gradient norm: 0.05098777
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=11042.46484375MB
INFO:root:[   61] Training loss: 0.63370159, Validation loss: 0.62411895, Gradient norm: 0.05594569
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=11080.609375MB
INFO:root:[   62] Training loss: 0.63329764, Validation loss: 0.62421059, Gradient norm: 0.06007174
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=11119.0MB
INFO:root:[   63] Training loss: 0.63298176, Validation loss: 0.62380778, Gradient norm: 0.05339004
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=11157.14453125MB
INFO:root:[   64] Training loss: 0.63281654, Validation loss: 0.62436702, Gradient norm: 0.05988219
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=12391.9453125MB
INFO:root:[   65] Training loss: 0.63225825, Validation loss: 0.62246906, Gradient norm: 0.05884823
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=13971.8203125MB
INFO:root:[   66] Training loss: 0.63198838, Validation loss: 0.62242637, Gradient norm: 0.05202746
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14059.890625MB
INFO:root:[   67] Training loss: 0.63150885, Validation loss: 0.62282932, Gradient norm: 0.05674510
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14150.2890625MB
INFO:root:[   68] Training loss: 0.63134756, Validation loss: 0.62185002, Gradient norm: 0.05764808
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14235.78125MB
INFO:root:[   69] Training loss: 0.63121319, Validation loss: 0.62140203, Gradient norm: 0.05998042
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14318.49609375MB
INFO:root:[   70] Training loss: 0.63062809, Validation loss: 0.62199341, Gradient norm: 0.05462162
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14401.91796875MB
INFO:root:[   71] Training loss: 0.63042677, Validation loss: 0.62060561, Gradient norm: 0.05547910
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14484.07421875MB
INFO:root:[   72] Training loss: 0.63021477, Validation loss: 0.61965295, Gradient norm: 0.05962164
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14566.28125MB
INFO:root:[   73] Training loss: 0.62994195, Validation loss: 0.62050803, Gradient norm: 0.05830343
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14648.93359375MB
INFO:root:[   74] Training loss: 0.62969411, Validation loss: 0.61983374, Gradient norm: 0.05463309
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14732.59375MB
INFO:root:[   75] Training loss: 0.62928110, Validation loss: 0.62000112, Gradient norm: 0.05816465
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14815.5078125MB
INFO:root:[   76] Training loss: 0.62903106, Validation loss: 0.61999966, Gradient norm: 0.06043271
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14898.94921875MB
INFO:root:[   77] Training loss: 0.62855681, Validation loss: 0.61880748, Gradient norm: 0.05417902
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14981.41015625MB
INFO:root:[   78] Training loss: 0.62859038, Validation loss: 0.62032029, Gradient norm: 0.05890190
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=15065.05859375MB
INFO:root:[   79] Training loss: 0.62813066, Validation loss: 0.61905355, Gradient norm: 0.05693088
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=15151.71484375MB
INFO:root:[   80] Training loss: 0.62769278, Validation loss: 0.61803065, Gradient norm: 0.05664027
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=15234.14453125MB
INFO:root:[   81] Training loss: 0.62767009, Validation loss: 0.61860799, Gradient norm: 0.05777694
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=15317.67578125MB
INFO:root:[   82] Training loss: 0.62729370, Validation loss: 0.61783694, Gradient norm: 0.05863238
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=15400.44921875MB
INFO:root:[   83] Training loss: 0.62716627, Validation loss: 0.61760002, Gradient norm: 0.06042839
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=15483.1171875MB
INFO:root:[   84] Training loss: 0.62690691, Validation loss: 0.61899700, Gradient norm: 0.05854221
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=23041.53515625MB
INFO:root:[   85] Training loss: 0.62659791, Validation loss: 0.61773515, Gradient norm: 0.05576581
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14753.77734375MB
INFO:root:[   86] Training loss: 0.62639702, Validation loss: 0.61825978, Gradient norm: 0.05985783
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14841.11328125MB
INFO:root:[   87] Training loss: 0.62612528, Validation loss: 0.61782107, Gradient norm: 0.05731022
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=14933.1328125MB
INFO:root:[   88] Training loss: 0.62596096, Validation loss: 0.61668512, Gradient norm: 0.05623896
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=15018.83984375MB
INFO:root:[   89] Training loss: 0.62578568, Validation loss: 0.61707337, Gradient norm: 0.05945755
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=15111.84765625MB
INFO:root:[   90] Training loss: 0.62563684, Validation loss: 0.61614258, Gradient norm: 0.05756073
INFO:root:At the start of the epoch: mem (CPU python)=12455.5234375MB; mem (CPU total)=15198.75MB
INFO:root:[   91] Training loss: 0.62525648, Validation loss: 0.61603503, Gradient norm: 0.05883531
INFO:root:At the start of the epoch: mem (CPU python)=12466.27734375MB; mem (CPU total)=15285.53515625MB
INFO:root:[   92] Training loss: 0.62493036, Validation loss: 0.61561035, Gradient norm: 0.05789553
INFO:root:At the start of the epoch: mem (CPU python)=12504.375MB; mem (CPU total)=15372.14453125MB
INFO:root:[   93] Training loss: 0.62518039, Validation loss: 0.61729635, Gradient norm: 0.05957519
INFO:root:At the start of the epoch: mem (CPU python)=12542.4765625MB; mem (CPU total)=15458.75390625MB
INFO:root:[   94] Training loss: 0.62464720, Validation loss: 0.61716015, Gradient norm: 0.05734701
INFO:root:At the start of the epoch: mem (CPU python)=12580.58203125MB; mem (CPU total)=15547.12890625MB
INFO:root:[   95] Training loss: 0.62448963, Validation loss: 0.61507050, Gradient norm: 0.06240565
INFO:root:At the start of the epoch: mem (CPU python)=12618.6640625MB; mem (CPU total)=15634.203125MB
INFO:root:[   96] Training loss: 0.62449665, Validation loss: 0.61469012, Gradient norm: 0.06334868
INFO:root:At the start of the epoch: mem (CPU python)=12656.76171875MB; mem (CPU total)=15720.34375MB
INFO:root:[   97] Training loss: 0.62419467, Validation loss: 0.61545022, Gradient norm: 0.05851056
INFO:root:At the start of the epoch: mem (CPU python)=12694.85546875MB; mem (CPU total)=15806.9609375MB
INFO:root:[   98] Training loss: 0.62401220, Validation loss: 0.61475538, Gradient norm: 0.05972057
INFO:root:At the start of the epoch: mem (CPU python)=12732.94921875MB; mem (CPU total)=15894.13671875MB
INFO:root:[   99] Training loss: 0.62381606, Validation loss: 0.61555994, Gradient norm: 0.06435401
INFO:root:At the start of the epoch: mem (CPU python)=12771.05078125MB; mem (CPU total)=15982.2265625MB
INFO:root:[  100] Training loss: 0.62332937, Validation loss: 0.61631388, Gradient norm: 0.05969104
INFO:root:At the start of the epoch: mem (CPU python)=12809.14453125MB; mem (CPU total)=16068.3515625MB
INFO:root:[  101] Training loss: 0.62339401, Validation loss: 0.61413842, Gradient norm: 0.06233425
INFO:root:At the start of the epoch: mem (CPU python)=12847.23828125MB; mem (CPU total)=16155.7109375MB
INFO:root:[  102] Training loss: 0.62303641, Validation loss: 0.61409272, Gradient norm: 0.06212242
INFO:root:At the start of the epoch: mem (CPU python)=12885.33203125MB; mem (CPU total)=16242.04296875MB
INFO:root:[  103] Training loss: 0.62275979, Validation loss: 0.61461225, Gradient norm: 0.06155797
INFO:root:At the start of the epoch: mem (CPU python)=12923.4296875MB; mem (CPU total)=16329.62109375MB
INFO:root:[  104] Training loss: 0.62258169, Validation loss: 0.61494172, Gradient norm: 0.05876628
INFO:root:At the start of the epoch: mem (CPU python)=12961.5234375MB; mem (CPU total)=16414.56640625MB
INFO:root:[  105] Training loss: 0.62262181, Validation loss: 0.61337625, Gradient norm: 0.06306139
INFO:root:At the start of the epoch: mem (CPU python)=12999.6171875MB; mem (CPU total)=16501.44140625MB
INFO:root:[  106] Training loss: 0.62254567, Validation loss: 0.61461593, Gradient norm: 0.05635579
INFO:root:At the start of the epoch: mem (CPU python)=13037.71484375MB; mem (CPU total)=16588.73828125MB
INFO:root:[  107] Training loss: 0.62226561, Validation loss: 0.61375112, Gradient norm: 0.06067964
INFO:root:At the start of the epoch: mem (CPU python)=13075.80859375MB; mem (CPU total)=16675.390625MB
INFO:root:[  108] Training loss: 0.62200690, Validation loss: 0.61445979, Gradient norm: 0.06273784
INFO:root:At the start of the epoch: mem (CPU python)=13113.90625MB; mem (CPU total)=16762.3125MB
INFO:root:[  109] Training loss: 0.62196026, Validation loss: 0.61558736, Gradient norm: 0.05975557
INFO:root:At the start of the epoch: mem (CPU python)=13152.00390625MB; mem (CPU total)=16849.421875MB
INFO:root:[  110] Training loss: 0.62174188, Validation loss: 0.61230685, Gradient norm: 0.06042266
INFO:root:At the start of the epoch: mem (CPU python)=13190.09765625MB; mem (CPU total)=16937.40234375MB
INFO:root:[  111] Training loss: 0.62161341, Validation loss: 0.61321706, Gradient norm: 0.05903422
INFO:root:At the start of the epoch: mem (CPU python)=13228.19140625MB; mem (CPU total)=17024.36328125MB
INFO:root:[  112] Training loss: 0.62165953, Validation loss: 0.61248550, Gradient norm: 0.06536480
INFO:root:At the start of the epoch: mem (CPU python)=13266.28515625MB; mem (CPU total)=17111.765625MB
INFO:root:[  113] Training loss: 0.62113230, Validation loss: 0.61400095, Gradient norm: 0.06391761
INFO:root:At the start of the epoch: mem (CPU python)=13304.3828125MB; mem (CPU total)=17198.8203125MB
INFO:root:[  114] Training loss: 0.62107262, Validation loss: 0.61428909, Gradient norm: 0.06349934
INFO:root:At the start of the epoch: mem (CPU python)=13342.4765625MB; mem (CPU total)=17286.875MB
INFO:root:[  115] Training loss: 0.62102626, Validation loss: 0.61254135, Gradient norm: 0.06205696
INFO:root:At the start of the epoch: mem (CPU python)=13380.5703125MB; mem (CPU total)=13311.23828125MB
INFO:root:[  116] Training loss: 0.62087025, Validation loss: 0.61297012, Gradient norm: 0.06160963
INFO:root:At the start of the epoch: mem (CPU python)=13418.671875MB; mem (CPU total)=15136.3203125MB
INFO:root:[  117] Training loss: 0.62063952, Validation loss: 0.61298786, Gradient norm: 0.05799655
INFO:root:At the start of the epoch: mem (CPU python)=13456.765625MB; mem (CPU total)=15993.59375MB
INFO:root:[  118] Training loss: 0.62058534, Validation loss: 0.61205788, Gradient norm: 0.06060329
INFO:root:At the start of the epoch: mem (CPU python)=13494.859375MB; mem (CPU total)=16084.7421875MB
INFO:root:[  119] Training loss: 0.62056488, Validation loss: 0.61213638, Gradient norm: 0.06510452
INFO:root:At the start of the epoch: mem (CPU python)=13532.953125MB; mem (CPU total)=16172.5859375MB
INFO:root:[  120] Training loss: 0.62039454, Validation loss: 0.61151078, Gradient norm: 0.06159341
INFO:root:At the start of the epoch: mem (CPU python)=13571.05078125MB; mem (CPU total)=16260.41796875MB
INFO:root:[  121] Training loss: 0.62004014, Validation loss: 0.61260514, Gradient norm: 0.06352360
INFO:root:At the start of the epoch: mem (CPU python)=13609.14453125MB; mem (CPU total)=16348.5MB
INFO:root:[  122] Training loss: 0.62002482, Validation loss: 0.61394337, Gradient norm: 0.06243746
INFO:root:At the start of the epoch: mem (CPU python)=13647.23828125MB; mem (CPU total)=13426.26953125MB
INFO:root:[  123] Training loss: 0.61988396, Validation loss: 0.61297523, Gradient norm: 0.06427467
INFO:root:At the start of the epoch: mem (CPU python)=13685.3359375MB; mem (CPU total)=13464.79296875MB
INFO:root:[  124] Training loss: 0.61992447, Validation loss: 0.61245831, Gradient norm: 0.06201948
INFO:root:At the start of the epoch: mem (CPU python)=13723.4296875MB; mem (CPU total)=13502.44140625MB
INFO:root:[  125] Training loss: 0.61941221, Validation loss: 0.61323329, Gradient norm: 0.06080789
INFO:root:At the start of the epoch: mem (CPU python)=13761.53125MB; mem (CPU total)=13747.1640625MB
INFO:root:[  126] Training loss: 0.61920399, Validation loss: 0.61327584, Gradient norm: 0.05731246
INFO:root:At the start of the epoch: mem (CPU python)=13799.62890625MB; mem (CPU total)=16292.33984375MB
INFO:root:[  127] Training loss: 0.61943023, Validation loss: 0.61303221, Gradient norm: 0.06001610
INFO:root:At the start of the epoch: mem (CPU python)=13837.72265625MB; mem (CPU total)=16371.6875MB
INFO:root:[  128] Training loss: 0.61906453, Validation loss: 0.61194829, Gradient norm: 0.06060659
INFO:root:At the start of the epoch: mem (CPU python)=13875.81640625MB; mem (CPU total)=16452.1640625MB
INFO:root:[  129] Training loss: 0.61871593, Validation loss: 0.61040273, Gradient norm: 0.05958485
INFO:root:At the start of the epoch: mem (CPU python)=13913.91015625MB; mem (CPU total)=16532.01953125MB
INFO:root:[  130] Training loss: 0.61895303, Validation loss: 0.61169642, Gradient norm: 0.06286384
INFO:root:At the start of the epoch: mem (CPU python)=13952.0078125MB; mem (CPU total)=16612.0859375MB
INFO:root:[  131] Training loss: 0.61871366, Validation loss: 0.61064897, Gradient norm: 0.06347389
INFO:root:At the start of the epoch: mem (CPU python)=13990.1015625MB; mem (CPU total)=16693.29296875MB
INFO:root:[  132] Training loss: 0.61862508, Validation loss: 0.61154008, Gradient norm: 0.06121050
INFO:root:At the start of the epoch: mem (CPU python)=14028.1953125MB; mem (CPU total)=16773.640625MB
INFO:root:[  133] Training loss: 0.61835956, Validation loss: 0.61080947, Gradient norm: 0.06316792
INFO:root:At the start of the epoch: mem (CPU python)=14066.29296875MB; mem (CPU total)=16854.328125MB
INFO:root:[  134] Training loss: 0.61838323, Validation loss: 0.61198982, Gradient norm: 0.06330417
INFO:root:At the start of the epoch: mem (CPU python)=14104.390625MB; mem (CPU total)=16935.78515625MB
INFO:root:[  135] Training loss: 0.61816169, Validation loss: 0.61016617, Gradient norm: 0.06055333
INFO:root:At the start of the epoch: mem (CPU python)=14142.484375MB; mem (CPU total)=17016.50390625MB
INFO:root:[  136] Training loss: 0.61782858, Validation loss: 0.61171990, Gradient norm: 0.06340621
INFO:root:At the start of the epoch: mem (CPU python)=14180.578125MB; mem (CPU total)=17097.4140625MB
INFO:root:[  137] Training loss: 0.61801068, Validation loss: 0.61059196, Gradient norm: 0.06265212
INFO:root:At the start of the epoch: mem (CPU python)=14218.67578125MB; mem (CPU total)=17178.23828125MB
INFO:root:[  138] Training loss: 0.61765505, Validation loss: 0.61034918, Gradient norm: 0.06106548
INFO:root:At the start of the epoch: mem (CPU python)=14256.76953125MB; mem (CPU total)=17259.4921875MB
INFO:root:[  139] Training loss: 0.61768231, Validation loss: 0.61073309, Gradient norm: 0.06243177
INFO:root:At the start of the epoch: mem (CPU python)=14294.86328125MB; mem (CPU total)=17340.109375MB
INFO:root:[  140] Training loss: 0.61767986, Validation loss: 0.61121506, Gradient norm: 0.06873510
INFO:root:At the start of the epoch: mem (CPU python)=14332.96484375MB; mem (CPU total)=17422.32421875MB
INFO:root:[  141] Training loss: 0.61786038, Validation loss: 0.61307984, Gradient norm: 0.06680970
INFO:root:At the start of the epoch: mem (CPU python)=14371.05859375MB; mem (CPU total)=17503.77734375MB
INFO:root:[  142] Training loss: 0.61721849, Validation loss: 0.61076914, Gradient norm: 0.06637655
INFO:root:At the start of the epoch: mem (CPU python)=14409.15234375MB; mem (CPU total)=17584.49609375MB
INFO:root:[  143] Training loss: 0.61710824, Validation loss: 0.61191195, Gradient norm: 0.06187166
INFO:root:At the start of the epoch: mem (CPU python)=14447.25MB; mem (CPU total)=17665.69921875MB
INFO:root:[  144] Training loss: 0.61728849, Validation loss: 0.60998167, Gradient norm: 0.06399205
INFO:root:At the start of the epoch: mem (CPU python)=14485.34375MB; mem (CPU total)=17746.8125MB
INFO:root:[  145] Training loss: 0.61671232, Validation loss: 0.61079110, Gradient norm: 0.06165482
INFO:root:At the start of the epoch: mem (CPU python)=14523.4375MB; mem (CPU total)=17827.5234375MB
INFO:root:[  146] Training loss: 0.61678546, Validation loss: 0.61115102, Gradient norm: 0.06265044
INFO:root:At the start of the epoch: mem (CPU python)=14561.53125MB; mem (CPU total)=17911.0390625MB
INFO:root:[  147] Training loss: 0.61658977, Validation loss: 0.61087425, Gradient norm: 0.06341749
INFO:root:At the start of the epoch: mem (CPU python)=14599.62890625MB; mem (CPU total)=17992.65234375MB
INFO:root:[  148] Training loss: 0.61669186, Validation loss: 0.61047039, Gradient norm: 0.06467767
INFO:root:At the start of the epoch: mem (CPU python)=14637.72265625MB; mem (CPU total)=18074.1484375MB
INFO:root:[  149] Training loss: 0.61649987, Validation loss: 0.60949871, Gradient norm: 0.06450250
INFO:root:At the start of the epoch: mem (CPU python)=14675.81640625MB; mem (CPU total)=18153.75390625MB
INFO:root:[  150] Training loss: 0.61647411, Validation loss: 0.60944872, Gradient norm: 0.07013703
INFO:root:At the start of the epoch: mem (CPU python)=14713.9140625MB; mem (CPU total)=18235.4765625MB
INFO:root:[  151] Training loss: 0.61642079, Validation loss: 0.60943468, Gradient norm: 0.06047167
INFO:root:At the start of the epoch: mem (CPU python)=14752.01171875MB; mem (CPU total)=18316.703125MB
INFO:root:[  152] Training loss: 0.61616037, Validation loss: 0.61007702, Gradient norm: 0.06661427
INFO:root:At the start of the epoch: mem (CPU python)=14790.10546875MB; mem (CPU total)=18397.59765625MB
INFO:root:[  153] Training loss: 0.61619877, Validation loss: 0.61180049, Gradient norm: 0.06552848
INFO:root:At the start of the epoch: mem (CPU python)=14828.19921875MB; mem (CPU total)=18478.81640625MB
INFO:root:[  154] Training loss: 0.61602049, Validation loss: 0.60929341, Gradient norm: 0.05964178
INFO:root:At the start of the epoch: mem (CPU python)=14866.296875MB; mem (CPU total)=18560.28515625MB
INFO:root:[  155] Training loss: 0.61603647, Validation loss: 0.61191237, Gradient norm: 0.06191801
INFO:root:At the start of the epoch: mem (CPU python)=14904.39453125MB; mem (CPU total)=18641.01953125MB
INFO:root:[  156] Training loss: 0.61565473, Validation loss: 0.61004688, Gradient norm: 0.06548090
INFO:root:At the start of the epoch: mem (CPU python)=14942.48828125MB; mem (CPU total)=18723.97265625MB
INFO:root:[  157] Training loss: 0.61566968, Validation loss: 0.60865206, Gradient norm: 0.06195514
INFO:root:At the start of the epoch: mem (CPU python)=14980.5859375MB; mem (CPU total)=18802.88671875MB
INFO:root:[  158] Training loss: 0.61567335, Validation loss: 0.60941153, Gradient norm: 0.06472262
INFO:root:At the start of the epoch: mem (CPU python)=15018.6796875MB; mem (CPU total)=18883.12109375MB
INFO:root:[  159] Training loss: 0.61537522, Validation loss: 0.60819671, Gradient norm: 0.06648513
INFO:root:At the start of the epoch: mem (CPU python)=15056.77734375MB; mem (CPU total)=18964.16796875MB
INFO:root:[  160] Training loss: 0.61581781, Validation loss: 0.60844166, Gradient norm: 0.07148451
INFO:root:At the start of the epoch: mem (CPU python)=15094.87109375MB; mem (CPU total)=19045.21484375MB
INFO:root:[  161] Training loss: 0.61510178, Validation loss: 0.60882317, Gradient norm: 0.06554690
INFO:root:At the start of the epoch: mem (CPU python)=15136.09375MB; mem (CPU total)=19129.09375MB
INFO:root:[  162] Training loss: 0.61526733, Validation loss: 0.60936108, Gradient norm: 0.06673138
INFO:root:At the start of the epoch: mem (CPU python)=15174.1875MB; mem (CPU total)=19210.1796875MB
INFO:root:[  163] Training loss: 0.61500525, Validation loss: 0.60996033, Gradient norm: 0.06559660
INFO:root:At the start of the epoch: mem (CPU python)=15212.28125MB; mem (CPU total)=19291.27734375MB
INFO:root:[  164] Training loss: 0.61498507, Validation loss: 0.60921650, Gradient norm: 0.06526219
INFO:root:At the start of the epoch: mem (CPU python)=15250.37890625MB; mem (CPU total)=19372.93359375MB
INFO:root:[  165] Training loss: 0.61502971, Validation loss: 0.60954709, Gradient norm: 0.06561662
INFO:root:At the start of the epoch: mem (CPU python)=15288.47265625MB; mem (CPU total)=19452.6640625MB
INFO:root:[  166] Training loss: 0.61480472, Validation loss: 0.60859704, Gradient norm: 0.06831621
INFO:root:At the start of the epoch: mem (CPU python)=15326.56640625MB; mem (CPU total)=19534.16015625MB
INFO:root:[  167] Training loss: 0.61466725, Validation loss: 0.60887100, Gradient norm: 0.06618948
INFO:root:At the start of the epoch: mem (CPU python)=15364.671875MB; mem (CPU total)=19614.51953125MB
INFO:root:[  168] Training loss: 0.61469977, Validation loss: 0.61025277, Gradient norm: 0.06661752
INFO:root:At the start of the epoch: mem (CPU python)=15402.765625MB; mem (CPU total)=19695.33984375MB
INFO:root:EP 168: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=15440.67578125MB; mem (CPU total)=19763.4765625MB
INFO:root:Training the model took 7577.195s.
INFO:root:Emptying the cuda cache took 0.008s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84243
INFO:root:EnergyScoreTrain: 0.59313
INFO:root:CRPSTrain: 0.46317
INFO:root:Gaussian NLLTrain: 1.20262
INFO:root:CoverageTrain: 0.94712
INFO:root:IntervalWidthTrain: 3.28785
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86472
INFO:root:EnergyScoreValidation: 0.60866
INFO:root:CRPSValidation: 0.47614
INFO:root:Gaussian NLLValidation: 1.23005
INFO:root:CoverageValidation: 0.9403
INFO:root:IntervalWidthValidation: 3.29064
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86564
INFO:root:EnergyScoreTest: 0.6093
INFO:root:CRPSTest: 0.47674
INFO:root:Gaussian NLLTest: 1.23139
INFO:root:CoverageTest: 0.93998
INFO:root:IntervalWidthTest: 3.29124
INFO:root:After validation: mem (CPU python)=15556.32421875MB; mem (CPU total)=19916.44140625MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=15556.32421875MB; mem (CPU total)=19930.16796875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=15556.32421875MB; mem (CPU total)=19931.3984375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=15556.32421875MB; mem (CPU total)=19942.8359375MB
INFO:root:[    1] Training loss: 0.72431443, Validation loss: 0.72092387, Gradient norm: 0.01873263
INFO:root:At the start of the epoch: mem (CPU python)=15556.32421875MB; mem (CPU total)=20023.08203125MB
INFO:root:[    2] Training loss: 0.72001535, Validation loss: 0.71892163, Gradient norm: 0.00622437
INFO:root:At the start of the epoch: mem (CPU python)=15576.67578125MB; mem (CPU total)=20104.28515625MB
INFO:root:[    3] Training loss: 0.71842349, Validation loss: 0.71578496, Gradient norm: 0.00755641
INFO:root:At the start of the epoch: mem (CPU python)=15614.78515625MB; mem (CPU total)=20185.0859375MB
INFO:root:[    4] Training loss: 0.71263147, Validation loss: 0.70581562, Gradient norm: 0.01664927
INFO:root:At the start of the epoch: mem (CPU python)=15652.89453125MB; mem (CPU total)=20266.03125MB
INFO:root:[    5] Training loss: 0.70502203, Validation loss: 0.69918337, Gradient norm: 0.02293277
INFO:root:At the start of the epoch: mem (CPU python)=15691.0078125MB; mem (CPU total)=20347.87890625MB
INFO:root:[    6] Training loss: 0.69946199, Validation loss: 0.69302335, Gradient norm: 0.02811359
INFO:root:At the start of the epoch: mem (CPU python)=15729.11328125MB; mem (CPU total)=20429.40625MB
INFO:root:[    7] Training loss: 0.69461248, Validation loss: 0.68844269, Gradient norm: 0.03282015
INFO:root:At the start of the epoch: mem (CPU python)=15767.20703125MB; mem (CPU total)=20507.76171875MB
INFO:root:[    8] Training loss: 0.69011496, Validation loss: 0.68352785, Gradient norm: 0.02963626
INFO:root:At the start of the epoch: mem (CPU python)=15805.3125MB; mem (CPU total)=20588.49609375MB
INFO:root:[    9] Training loss: 0.68628779, Validation loss: 0.67927287, Gradient norm: 0.03286954
INFO:root:At the start of the epoch: mem (CPU python)=15843.40625MB; mem (CPU total)=20669.5390625MB
INFO:root:[   10] Training loss: 0.68248425, Validation loss: 0.67553491, Gradient norm: 0.03351874
INFO:root:At the start of the epoch: mem (CPU python)=15881.5MB; mem (CPU total)=20750.6953125MB
INFO:root:[   11] Training loss: 0.67896319, Validation loss: 0.67091959, Gradient norm: 0.03434444
INFO:root:At the start of the epoch: mem (CPU python)=15919.59765625MB; mem (CPU total)=20832.0703125MB
INFO:root:[   12] Training loss: 0.67588728, Validation loss: 0.66755877, Gradient norm: 0.03475976
INFO:root:At the start of the epoch: mem (CPU python)=15957.6953125MB; mem (CPU total)=20912.828125MB
INFO:root:[   13] Training loss: 0.67266583, Validation loss: 0.66383829, Gradient norm: 0.03404570
INFO:root:At the start of the epoch: mem (CPU python)=15995.79296875MB; mem (CPU total)=20993.9140625MB
INFO:root:[   14] Training loss: 0.67015142, Validation loss: 0.66110746, Gradient norm: 0.03961562
INFO:root:At the start of the epoch: mem (CPU python)=16033.88671875MB; mem (CPU total)=21074.83984375MB
INFO:root:[   15] Training loss: 0.66744690, Validation loss: 0.65816426, Gradient norm: 0.03707469
INFO:root:At the start of the epoch: mem (CPU python)=16071.984375MB; mem (CPU total)=21156.06640625MB
INFO:root:[   16] Training loss: 0.66497881, Validation loss: 0.65510197, Gradient norm: 0.03798246
INFO:root:At the start of the epoch: mem (CPU python)=16110.078125MB; mem (CPU total)=21234.2890625MB
INFO:root:[   17] Training loss: 0.66305824, Validation loss: 0.65286131, Gradient norm: 0.04161615
INFO:root:At the start of the epoch: mem (CPU python)=16148.171875MB; mem (CPU total)=21315.1171875MB
INFO:root:[   18] Training loss: 0.66071591, Validation loss: 0.65115065, Gradient norm: 0.03982426
INFO:root:At the start of the epoch: mem (CPU python)=16186.265625MB; mem (CPU total)=21396.10546875MB
INFO:root:[   19] Training loss: 0.65866806, Validation loss: 0.64859010, Gradient norm: 0.03666480
INFO:root:At the start of the epoch: mem (CPU python)=16224.36328125MB; mem (CPU total)=21476.8359375MB
INFO:root:[   20] Training loss: 0.65694413, Validation loss: 0.64608134, Gradient norm: 0.04105138
INFO:root:At the start of the epoch: mem (CPU python)=16262.45703125MB; mem (CPU total)=21558.05859375MB
INFO:root:[   21] Training loss: 0.65535054, Validation loss: 0.64515628, Gradient norm: 0.04405961
INFO:root:At the start of the epoch: mem (CPU python)=16300.5546875MB; mem (CPU total)=21639.6796875MB
INFO:root:[   22] Training loss: 0.65392986, Validation loss: 0.64400514, Gradient norm: 0.04863305
INFO:root:At the start of the epoch: mem (CPU python)=16338.6484375MB; mem (CPU total)=21719.77734375MB
INFO:root:[   23] Training loss: 0.65254584, Validation loss: 0.64182695, Gradient norm: 0.04613674
INFO:root:At the start of the epoch: mem (CPU python)=16376.74609375MB; mem (CPU total)=21802.20703125MB
INFO:root:[   24] Training loss: 0.65130244, Validation loss: 0.64157755, Gradient norm: 0.04414373
INFO:root:At the start of the epoch: mem (CPU python)=16414.83984375MB; mem (CPU total)=21880.66015625MB
INFO:root:[   25] Training loss: 0.64993086, Validation loss: 0.63944114, Gradient norm: 0.04505008
INFO:root:At the start of the epoch: mem (CPU python)=16452.9375MB; mem (CPU total)=21960.40625MB
INFO:root:[   26] Training loss: 0.64886799, Validation loss: 0.63802475, Gradient norm: 0.05027725
INFO:root:At the start of the epoch: mem (CPU python)=16491.03125MB; mem (CPU total)=22041.5625MB
INFO:root:[   27] Training loss: 0.64793862, Validation loss: 0.63785224, Gradient norm: 0.05216977
INFO:root:At the start of the epoch: mem (CPU python)=16529.125MB; mem (CPU total)=22122.8828125MB
INFO:root:[   28] Training loss: 0.64697215, Validation loss: 0.63671275, Gradient norm: 0.04881863
INFO:root:At the start of the epoch: mem (CPU python)=16567.21875MB; mem (CPU total)=22204.34375MB
INFO:root:[   29] Training loss: 0.64589452, Validation loss: 0.63504790, Gradient norm: 0.04622431
INFO:root:At the start of the epoch: mem (CPU python)=16605.31640625MB; mem (CPU total)=22285.3125MB
INFO:root:[   30] Training loss: 0.64483839, Validation loss: 0.63441275, Gradient norm: 0.04705888
INFO:root:At the start of the epoch: mem (CPU python)=16643.41015625MB; mem (CPU total)=22366.25MB
INFO:root:[   31] Training loss: 0.64422746, Validation loss: 0.63370140, Gradient norm: 0.05017482
INFO:root:At the start of the epoch: mem (CPU python)=16681.5078125MB; mem (CPU total)=22447.7265625MB
INFO:root:[   32] Training loss: 0.64307039, Validation loss: 0.63192060, Gradient norm: 0.04553578
INFO:root:At the start of the epoch: mem (CPU python)=16719.60546875MB; mem (CPU total)=22529.4296875MB
INFO:root:[   33] Training loss: 0.64236615, Validation loss: 0.63253893, Gradient norm: 0.05084372
INFO:root:At the start of the epoch: mem (CPU python)=16757.69921875MB; mem (CPU total)=22607.0078125MB
INFO:root:[   34] Training loss: 0.64139850, Validation loss: 0.63085808, Gradient norm: 0.04809636
INFO:root:At the start of the epoch: mem (CPU python)=16795.79296875MB; mem (CPU total)=22688.47265625MB
INFO:root:[   35] Training loss: 0.64092446, Validation loss: 0.63032748, Gradient norm: 0.05153946
INFO:root:At the start of the epoch: mem (CPU python)=16833.88671875MB; mem (CPU total)=22768.95703125MB
INFO:root:[   36] Training loss: 0.63977677, Validation loss: 0.62967314, Gradient norm: 0.04980373
INFO:root:At the start of the epoch: mem (CPU python)=16871.98828125MB; mem (CPU total)=22849.87890625MB
INFO:root:[   37] Training loss: 0.63938562, Validation loss: 0.62907665, Gradient norm: 0.05293217
INFO:root:At the start of the epoch: mem (CPU python)=16910.078125MB; mem (CPU total)=22930.859375MB
INFO:root:[   38] Training loss: 0.63848637, Validation loss: 0.62838077, Gradient norm: 0.05032886
INFO:root:At the start of the epoch: mem (CPU python)=16948.17578125MB; mem (CPU total)=23011.3515625MB
INFO:root:[   39] Training loss: 0.63776558, Validation loss: 0.62783928, Gradient norm: 0.05406744
INFO:root:At the start of the epoch: mem (CPU python)=16986.2734375MB; mem (CPU total)=23093.09375MB
INFO:root:[   40] Training loss: 0.63745060, Validation loss: 0.62666490, Gradient norm: 0.05339438
INFO:root:At the start of the epoch: mem (CPU python)=17024.3671875MB; mem (CPU total)=23174.78125MB
INFO:root:[   41] Training loss: 0.63694153, Validation loss: 0.62683871, Gradient norm: 0.04950297
INFO:root:At the start of the epoch: mem (CPU python)=17062.4609375MB; mem (CPU total)=23253.55078125MB
INFO:root:[   42] Training loss: 0.63624355, Validation loss: 0.62663769, Gradient norm: 0.04888419
INFO:root:At the start of the epoch: mem (CPU python)=17100.55859375MB; mem (CPU total)=23333.05859375MB
INFO:root:[   43] Training loss: 0.63551973, Validation loss: 0.62547225, Gradient norm: 0.05126340
INFO:root:At the start of the epoch: mem (CPU python)=17138.65234375MB; mem (CPU total)=23414.2890625MB
INFO:root:[   44] Training loss: 0.63519242, Validation loss: 0.62489569, Gradient norm: 0.05390636
INFO:root:At the start of the epoch: mem (CPU python)=17176.74609375MB; mem (CPU total)=23495.27734375MB
INFO:root:[   45] Training loss: 0.63458078, Validation loss: 0.62551057, Gradient norm: 0.05500139
INFO:root:At the start of the epoch: mem (CPU python)=17214.83984375MB; mem (CPU total)=23576.4765625MB
INFO:root:[   46] Training loss: 0.63390910, Validation loss: 0.62378881, Gradient norm: 0.05066843
INFO:root:At the start of the epoch: mem (CPU python)=17252.9375MB; mem (CPU total)=23657.953125MB
INFO:root:[   47] Training loss: 0.63342335, Validation loss: 0.62307464, Gradient norm: 0.05120653
INFO:root:At the start of the epoch: mem (CPU python)=17291.03125MB; mem (CPU total)=23739.171875MB
INFO:root:[   48] Training loss: 0.63294840, Validation loss: 0.62324700, Gradient norm: 0.05369087
INFO:root:At the start of the epoch: mem (CPU python)=17329.12890625MB; mem (CPU total)=23820.90625MB
INFO:root:[   49] Training loss: 0.63241565, Validation loss: 0.62289185, Gradient norm: 0.05339231
INFO:root:At the start of the epoch: mem (CPU python)=17367.2265625MB; mem (CPU total)=23901.640625MB
INFO:root:[   50] Training loss: 0.63219615, Validation loss: 0.62276335, Gradient norm: 0.06918595
INFO:root:At the start of the epoch: mem (CPU python)=17405.3203125MB; mem (CPU total)=23979.16015625MB
INFO:root:[   51] Training loss: 0.63152757, Validation loss: 0.62159182, Gradient norm: 0.05760296
INFO:root:At the start of the epoch: mem (CPU python)=17443.4140625MB; mem (CPU total)=24059.5234375MB
INFO:root:[   52] Training loss: 0.63074820, Validation loss: 0.62175171, Gradient norm: 0.04841633
INFO:root:At the start of the epoch: mem (CPU python)=17481.5078125MB; mem (CPU total)=24140.67578125MB
INFO:root:[   53] Training loss: 0.63076990, Validation loss: 0.62033731, Gradient norm: 0.05723202
INFO:root:At the start of the epoch: mem (CPU python)=17519.60546875MB; mem (CPU total)=24222.48828125MB
INFO:root:[   54] Training loss: 0.63014437, Validation loss: 0.61995160, Gradient norm: 0.05436832
INFO:root:At the start of the epoch: mem (CPU python)=17557.69921875MB; mem (CPU total)=24303.5390625MB
INFO:root:[   55] Training loss: 0.62974917, Validation loss: 0.62025430, Gradient norm: 0.05532990
INFO:root:At the start of the epoch: mem (CPU python)=17595.796875MB; mem (CPU total)=24385.83984375MB
INFO:root:[   56] Training loss: 0.62958031, Validation loss: 0.61949551, Gradient norm: 0.06219095
INFO:root:At the start of the epoch: mem (CPU python)=17633.89453125MB; mem (CPU total)=24467.97265625MB
INFO:root:[   57] Training loss: 0.62885669, Validation loss: 0.61911813, Gradient norm: 0.05696803
INFO:root:At the start of the epoch: mem (CPU python)=17671.98828125MB; mem (CPU total)=24549.7734375MB
INFO:root:[   58] Training loss: 0.62858315, Validation loss: 0.61840461, Gradient norm: 0.05798868
INFO:root:At the start of the epoch: mem (CPU python)=17710.08203125MB; mem (CPU total)=24627.78515625MB
INFO:root:[   59] Training loss: 0.62837520, Validation loss: 0.61831968, Gradient norm: 0.06220417
INFO:root:At the start of the epoch: mem (CPU python)=17748.1796875MB; mem (CPU total)=24709.02734375MB
INFO:root:[   60] Training loss: 0.62797566, Validation loss: 0.61836564, Gradient norm: 0.05790312
INFO:root:At the start of the epoch: mem (CPU python)=17786.2734375MB; mem (CPU total)=24790.70703125MB
INFO:root:[   61] Training loss: 0.62753679, Validation loss: 0.61768823, Gradient norm: 0.06276143
INFO:root:At the start of the epoch: mem (CPU python)=17824.3671875MB; mem (CPU total)=24872.65625MB
INFO:root:[   62] Training loss: 0.62697169, Validation loss: 0.61743337, Gradient norm: 0.05889779
INFO:root:At the start of the epoch: mem (CPU python)=17862.4609375MB; mem (CPU total)=24953.3671875MB
INFO:root:[   63] Training loss: 0.62688370, Validation loss: 0.61742619, Gradient norm: 0.05769155
INFO:root:At the start of the epoch: mem (CPU python)=17900.5625MB; mem (CPU total)=25034.8046875MB
INFO:root:[   64] Training loss: 0.62646701, Validation loss: 0.61618577, Gradient norm: 0.05742887
INFO:root:At the start of the epoch: mem (CPU python)=17938.65625MB; mem (CPU total)=25115.96875MB
INFO:root:[   65] Training loss: 0.62597903, Validation loss: 0.61748704, Gradient norm: 0.05430050
INFO:root:At the start of the epoch: mem (CPU python)=17976.75390625MB; mem (CPU total)=25198.37890625MB
INFO:root:[   66] Training loss: 0.62561334, Validation loss: 0.61688311, Gradient norm: 0.06072903
INFO:root:At the start of the epoch: mem (CPU python)=18014.8515625MB; mem (CPU total)=25275.64453125MB
INFO:root:[   67] Training loss: 0.62547817, Validation loss: 0.61611922, Gradient norm: 0.05672906
INFO:root:At the start of the epoch: mem (CPU python)=18052.9453125MB; mem (CPU total)=25356.8828125MB
INFO:root:[   68] Training loss: 0.62528935, Validation loss: 0.61595624, Gradient norm: 0.05812985
INFO:root:At the start of the epoch: mem (CPU python)=18091.0390625MB; mem (CPU total)=25437.08984375MB
INFO:root:[   69] Training loss: 0.62487084, Validation loss: 0.61591827, Gradient norm: 0.05937375
INFO:root:At the start of the epoch: mem (CPU python)=18129.1328125MB; mem (CPU total)=25518.0546875MB
INFO:root:[   70] Training loss: 0.62460198, Validation loss: 0.61519302, Gradient norm: 0.06160576
INFO:root:At the start of the epoch: mem (CPU python)=18167.23046875MB; mem (CPU total)=25599.46484375MB
INFO:root:[   71] Training loss: 0.62434735, Validation loss: 0.61432919, Gradient norm: 0.06049466
INFO:root:At the start of the epoch: mem (CPU python)=18205.32421875MB; mem (CPU total)=25680.4296875MB
INFO:root:[   72] Training loss: 0.62380982, Validation loss: 0.61466058, Gradient norm: 0.05576542
INFO:root:At the start of the epoch: mem (CPU python)=18243.421875MB; mem (CPU total)=25762.109375MB
INFO:root:[   73] Training loss: 0.62373007, Validation loss: 0.61500474, Gradient norm: 0.06253333
INFO:root:At the start of the epoch: mem (CPU python)=18281.51953125MB; mem (CPU total)=25844.359375MB
INFO:root:[   74] Training loss: 0.62302091, Validation loss: 0.61479567, Gradient norm: 0.05538206
INFO:root:At the start of the epoch: mem (CPU python)=18319.61328125MB; mem (CPU total)=25921.90625MB
INFO:root:[   75] Training loss: 0.62327567, Validation loss: 0.61406486, Gradient norm: 0.05659001
INFO:root:At the start of the epoch: mem (CPU python)=18357.70703125MB; mem (CPU total)=26002.15625MB
INFO:root:[   76] Training loss: 0.62290514, Validation loss: 0.61350138, Gradient norm: 0.05595479
INFO:root:At the start of the epoch: mem (CPU python)=18395.8046875MB; mem (CPU total)=26083.5859375MB
INFO:root:[   77] Training loss: 0.62274037, Validation loss: 0.61344074, Gradient norm: 0.06466876
INFO:root:At the start of the epoch: mem (CPU python)=18433.8984375MB; mem (CPU total)=26164.58203125MB
INFO:root:[   78] Training loss: 0.62220165, Validation loss: 0.61432963, Gradient norm: 0.05895475
INFO:root:At the start of the epoch: mem (CPU python)=18471.9921875MB; mem (CPU total)=26246.53125MB
INFO:root:[   79] Training loss: 0.62208617, Validation loss: 0.61401593, Gradient norm: 0.06532715
INFO:root:At the start of the epoch: mem (CPU python)=18510.0859375MB; mem (CPU total)=26327.95703125MB
INFO:root:[   80] Training loss: 0.62197710, Validation loss: 0.61309416, Gradient norm: 0.06453935
INFO:root:At the start of the epoch: mem (CPU python)=18548.1875MB; mem (CPU total)=26409.90625MB
INFO:root:[   81] Training loss: 0.62192346, Validation loss: 0.61353626, Gradient norm: 0.07733231
INFO:root:At the start of the epoch: mem (CPU python)=18586.28125MB; mem (CPU total)=26492.83984375MB
INFO:root:[   82] Training loss: 0.62122847, Validation loss: 0.61176276, Gradient norm: 0.06354126
INFO:root:At the start of the epoch: mem (CPU python)=18624.375MB; mem (CPU total)=26572.91796875MB
INFO:root:[   83] Training loss: 0.62132480, Validation loss: 0.61224749, Gradient norm: 0.06165397
INFO:root:At the start of the epoch: mem (CPU python)=18662.47265625MB; mem (CPU total)=26620.4296875MB
INFO:root:[   84] Training loss: 0.62086557, Validation loss: 0.61335821, Gradient norm: 0.06188163
INFO:root:At the start of the epoch: mem (CPU python)=18700.56640625MB; mem (CPU total)=26667.92578125MB
INFO:root:[   85] Training loss: 0.62071671, Validation loss: 0.61250499, Gradient norm: 0.06167859
INFO:root:At the start of the epoch: mem (CPU python)=18738.66015625MB; mem (CPU total)=26715.17578125MB
INFO:root:[   86] Training loss: 0.62060310, Validation loss: 0.61118000, Gradient norm: 0.06767290
INFO:root:At the start of the epoch: mem (CPU python)=18776.75390625MB; mem (CPU total)=26763.7265625MB
INFO:root:[   87] Training loss: 0.62011829, Validation loss: 0.61227495, Gradient norm: 0.06321431
INFO:root:At the start of the epoch: mem (CPU python)=18814.8515625MB; mem (CPU total)=26822.0234375MB
INFO:root:[   88] Training loss: 0.61973107, Validation loss: 0.61182122, Gradient norm: 0.06117526
INFO:root:At the start of the epoch: mem (CPU python)=18852.94921875MB; mem (CPU total)=26904.12890625MB
INFO:root:[   89] Training loss: 0.61992243, Validation loss: 0.61172407, Gradient norm: 0.06601088
INFO:root:At the start of the epoch: mem (CPU python)=18891.04296875MB; mem (CPU total)=26986.328125MB
INFO:root:[   90] Training loss: 0.61956102, Validation loss: 0.61232138, Gradient norm: 0.06327057
INFO:root:At the start of the epoch: mem (CPU python)=18929.140625MB; mem (CPU total)=27067.5078125MB
INFO:root:[   91] Training loss: 0.61948224, Validation loss: 0.61091153, Gradient norm: 0.05909712
INFO:root:At the start of the epoch: mem (CPU python)=18967.234375MB; mem (CPU total)=27149.921875MB
INFO:root:[   92] Training loss: 0.61924248, Validation loss: 0.61070930, Gradient norm: 0.06213001
INFO:root:At the start of the epoch: mem (CPU python)=19005.328125MB; mem (CPU total)=27227.9140625MB
INFO:root:[   93] Training loss: 0.61877943, Validation loss: 0.61137597, Gradient norm: 0.06732962
INFO:root:At the start of the epoch: mem (CPU python)=19043.42578125MB; mem (CPU total)=27306.25390625MB
INFO:root:[   94] Training loss: 0.61901803, Validation loss: 0.61033204, Gradient norm: 0.06672230
INFO:root:At the start of the epoch: mem (CPU python)=19081.51953125MB; mem (CPU total)=27386.41015625MB
INFO:root:[   95] Training loss: 0.61845026, Validation loss: 0.61005454, Gradient norm: 0.06294740
INFO:root:At the start of the epoch: mem (CPU python)=19119.61328125MB; mem (CPU total)=27468.53515625MB
INFO:root:[   96] Training loss: 0.61823820, Validation loss: 0.61136608, Gradient norm: 0.06450000
INFO:root:At the start of the epoch: mem (CPU python)=19157.7109375MB; mem (CPU total)=27550.23828125MB
INFO:root:[   97] Training loss: 0.61811667, Validation loss: 0.61033210, Gradient norm: 0.06535245
INFO:root:At the start of the epoch: mem (CPU python)=19195.80859375MB; mem (CPU total)=27631.84375MB
INFO:root:[   98] Training loss: 0.61777630, Validation loss: 0.60963233, Gradient norm: 0.06395787
INFO:root:At the start of the epoch: mem (CPU python)=19233.90625MB; mem (CPU total)=27713.77734375MB
INFO:root:[   99] Training loss: 0.61791467, Validation loss: 0.60950855, Gradient norm: 0.06554924
INFO:root:At the start of the epoch: mem (CPU python)=19272.0MB; mem (CPU total)=27796.1796875MB
INFO:root:[  100] Training loss: 0.61761339, Validation loss: 0.61058702, Gradient norm: 0.05911870
INFO:root:At the start of the epoch: mem (CPU python)=19310.09765625MB; mem (CPU total)=27874.921875MB
INFO:root:[  101] Training loss: 0.61740889, Validation loss: 0.60982983, Gradient norm: 0.06107075
INFO:root:At the start of the epoch: mem (CPU python)=19348.19140625MB; mem (CPU total)=27953.1796875MB
INFO:root:[  102] Training loss: 0.61706002, Validation loss: 0.60916484, Gradient norm: 0.06346736
INFO:root:At the start of the epoch: mem (CPU python)=19386.28515625MB; mem (CPU total)=28034.625MB
INFO:root:[  103] Training loss: 0.61686221, Validation loss: 0.60897501, Gradient norm: 0.06311914
INFO:root:At the start of the epoch: mem (CPU python)=19424.37890625MB; mem (CPU total)=28116.10546875MB
INFO:root:[  104] Training loss: 0.61736164, Validation loss: 0.60874455, Gradient norm: 0.06613763
INFO:root:At the start of the epoch: mem (CPU python)=19462.4765625MB; mem (CPU total)=28198.23046875MB
INFO:root:[  105] Training loss: 0.61668762, Validation loss: 0.60944544, Gradient norm: 0.06400368
INFO:root:At the start of the epoch: mem (CPU python)=19500.5703125MB; mem (CPU total)=28279.68359375MB
INFO:root:[  106] Training loss: 0.61647218, Validation loss: 0.60899866, Gradient norm: 0.06205709
INFO:root:At the start of the epoch: mem (CPU python)=19538.66796875MB; mem (CPU total)=28360.87109375MB
INFO:root:[  107] Training loss: 0.61641191, Validation loss: 0.60843661, Gradient norm: 0.06895480
INFO:root:At the start of the epoch: mem (CPU python)=19576.765625MB; mem (CPU total)=28444.0390625MB
INFO:root:[  108] Training loss: 0.61621460, Validation loss: 0.60880137, Gradient norm: 0.06048904
INFO:root:At the start of the epoch: mem (CPU python)=19614.859375MB; mem (CPU total)=28523.48046875MB
INFO:root:[  109] Training loss: 0.61609419, Validation loss: 0.60859504, Gradient norm: 0.06611576
INFO:root:At the start of the epoch: mem (CPU python)=19652.953125MB; mem (CPU total)=28600.57421875MB
INFO:root:[  110] Training loss: 0.61599575, Validation loss: 0.60781733, Gradient norm: 0.07105726
INFO:root:At the start of the epoch: mem (CPU python)=19691.05078125MB; mem (CPU total)=28682.1953125MB
INFO:root:[  111] Training loss: 0.61572535, Validation loss: 0.60792144, Gradient norm: 0.07236949
INFO:root:At the start of the epoch: mem (CPU python)=19729.14453125MB; mem (CPU total)=28763.65234375MB
INFO:root:[  112] Training loss: 0.61558193, Validation loss: 0.60814325, Gradient norm: 0.06618181
INFO:root:At the start of the epoch: mem (CPU python)=19767.23828125MB; mem (CPU total)=28845.35546875MB
INFO:root:[  113] Training loss: 0.61542350, Validation loss: 0.60888827, Gradient norm: 0.06833078
INFO:root:At the start of the epoch: mem (CPU python)=19805.3359375MB; mem (CPU total)=28926.56640625MB
INFO:root:[  114] Training loss: 0.61527394, Validation loss: 0.60881212, Gradient norm: 0.06627466
INFO:root:At the start of the epoch: mem (CPU python)=19843.43359375MB; mem (CPU total)=29008.578125MB
INFO:root:[  115] Training loss: 0.61502812, Validation loss: 0.60861250, Gradient norm: 0.06479272
INFO:root:At the start of the epoch: mem (CPU python)=19881.52734375MB; mem (CPU total)=29090.765625MB
INFO:root:[  116] Training loss: 0.61484755, Validation loss: 0.60813323, Gradient norm: 0.06346346
INFO:root:At the start of the epoch: mem (CPU python)=19919.62109375MB; mem (CPU total)=29172.76953125MB
INFO:root:[  117] Training loss: 0.61480349, Validation loss: 0.60739844, Gradient norm: 0.06520040
INFO:root:At the start of the epoch: mem (CPU python)=19957.71875MB; mem (CPU total)=29248.984375MB
INFO:root:[  118] Training loss: 0.61478462, Validation loss: 0.60839773, Gradient norm: 0.07256309
INFO:root:At the start of the epoch: mem (CPU python)=19995.8125MB; mem (CPU total)=29327.74609375MB
INFO:root:[  119] Training loss: 0.61447980, Validation loss: 0.60827262, Gradient norm: 0.06760584
INFO:root:At the start of the epoch: mem (CPU python)=20033.90625MB; mem (CPU total)=29409.47265625MB
INFO:root:[  120] Training loss: 0.61440321, Validation loss: 0.60823665, Gradient norm: 0.06360296
INFO:root:At the start of the epoch: mem (CPU python)=20072.0MB; mem (CPU total)=29491.47265625MB
INFO:root:[  121] Training loss: 0.61425751, Validation loss: 0.60747304, Gradient norm: 0.06981590
INFO:root:At the start of the epoch: mem (CPU python)=20110.10546875MB; mem (CPU total)=29573.16796875MB
INFO:root:[  122] Training loss: 0.61369448, Validation loss: 0.60760457, Gradient norm: 0.06140371
INFO:root:At the start of the epoch: mem (CPU python)=20148.19921875MB; mem (CPU total)=29654.64453125MB
INFO:root:[  123] Training loss: 0.61405202, Validation loss: 0.60705085, Gradient norm: 0.07029339
INFO:root:At the start of the epoch: mem (CPU python)=20186.29296875MB; mem (CPU total)=29735.265625MB
INFO:root:[  124] Training loss: 0.61348568, Validation loss: 0.60711065, Gradient norm: 0.06864604
INFO:root:At the start of the epoch: mem (CPU python)=20224.38671875MB; mem (CPU total)=29817.234375MB
INFO:root:[  125] Training loss: 0.61369394, Validation loss: 0.60793565, Gradient norm: 0.06855289
INFO:root:At the start of the epoch: mem (CPU python)=20262.484375MB; mem (CPU total)=29898.21875MB
INFO:root:[  126] Training loss: 0.61330200, Validation loss: 0.60692373, Gradient norm: 0.06873057
INFO:root:At the start of the epoch: mem (CPU python)=20300.578125MB; mem (CPU total)=29975.0078125MB
INFO:root:[  127] Training loss: 0.61323060, Validation loss: 0.60632467, Gradient norm: 0.06435130
INFO:root:At the start of the epoch: mem (CPU python)=20338.67578125MB; mem (CPU total)=30054.3671875MB
INFO:root:[  128] Training loss: 0.61344685, Validation loss: 0.60711132, Gradient norm: 0.07041265
INFO:root:At the start of the epoch: mem (CPU python)=20376.76953125MB; mem (CPU total)=30135.81640625MB
INFO:root:[  129] Training loss: 0.61311204, Validation loss: 0.60769813, Gradient norm: 0.07185127
INFO:root:At the start of the epoch: mem (CPU python)=20414.8671875MB; mem (CPU total)=30217.5390625MB
INFO:root:[  130] Training loss: 0.61273007, Validation loss: 0.60654635, Gradient norm: 0.06715436
INFO:root:At the start of the epoch: mem (CPU python)=20452.9609375MB; mem (CPU total)=30299.2578125MB
INFO:root:[  131] Training loss: 0.61285353, Validation loss: 0.60641980, Gradient norm: 0.06629146
INFO:root:At the start of the epoch: mem (CPU python)=20491.05859375MB; mem (CPU total)=30381.49609375MB
INFO:root:[  132] Training loss: 0.61262698, Validation loss: 0.60615888, Gradient norm: 0.06923713
INFO:root:At the start of the epoch: mem (CPU python)=20529.15234375MB; mem (CPU total)=30462.5390625MB
INFO:root:[  133] Training loss: 0.61272589, Validation loss: 0.60658384, Gradient norm: 0.07934363
INFO:root:At the start of the epoch: mem (CPU python)=20567.24609375MB; mem (CPU total)=30545.21875MB
INFO:root:[  134] Training loss: 0.61220757, Validation loss: 0.60670147, Gradient norm: 0.06478950
INFO:root:At the start of the epoch: mem (CPU python)=20605.34375MB; mem (CPU total)=30623.25MB
INFO:root:[  135] Training loss: 0.61234003, Validation loss: 0.60538104, Gradient norm: 0.06843185
INFO:root:At the start of the epoch: mem (CPU python)=20643.4375MB; mem (CPU total)=30699.55078125MB
INFO:root:[  136] Training loss: 0.61230650, Validation loss: 0.60594779, Gradient norm: 0.07730089
INFO:root:At the start of the epoch: mem (CPU python)=20681.53125MB; mem (CPU total)=30781.27734375MB
INFO:root:[  137] Training loss: 0.61196715, Validation loss: 0.60693623, Gradient norm: 0.07392064
INFO:root:At the start of the epoch: mem (CPU python)=20719.625MB; mem (CPU total)=30862.5390625MB
INFO:root:[  138] Training loss: 0.61173957, Validation loss: 0.60618514, Gradient norm: 0.07702216
INFO:root:At the start of the epoch: mem (CPU python)=20757.72265625MB; mem (CPU total)=30944.66015625MB
INFO:root:[  139] Training loss: 0.61190716, Validation loss: 0.60514226, Gradient norm: 0.07028129
INFO:root:At the start of the epoch: mem (CPU python)=20795.82421875MB; mem (CPU total)=31026.27734375MB
INFO:root:[  140] Training loss: 0.61141159, Validation loss: 0.60540152, Gradient norm: 0.06931014
INFO:root:At the start of the epoch: mem (CPU python)=20833.91796875MB; mem (CPU total)=31107.75390625MB
INFO:root:[  141] Training loss: 0.61124507, Validation loss: 0.60539055, Gradient norm: 0.07341069
INFO:root:At the start of the epoch: mem (CPU python)=20872.015625MB; mem (CPU total)=31190.44921875MB
INFO:root:[  142] Training loss: 0.61110794, Validation loss: 0.60686448, Gradient norm: 0.06979728
INFO:root:At the start of the epoch: mem (CPU python)=20910.109375MB; mem (CPU total)=31272.21484375MB
INFO:root:[  143] Training loss: 0.61145711, Validation loss: 0.60574523, Gradient norm: 0.06714846
INFO:root:At the start of the epoch: mem (CPU python)=20948.203125MB; mem (CPU total)=31348.4921875MB
INFO:root:[  144] Training loss: 0.61092597, Validation loss: 0.60474603, Gradient norm: 0.07189949
INFO:root:At the start of the epoch: mem (CPU python)=20986.30078125MB; mem (CPU total)=31427.51171875MB
INFO:root:[  145] Training loss: 0.61097731, Validation loss: 0.60582417, Gradient norm: 0.06740008
INFO:root:At the start of the epoch: mem (CPU python)=21024.39453125MB; mem (CPU total)=31508.49609375MB
INFO:root:[  146] Training loss: 0.61075482, Validation loss: 0.60558897, Gradient norm: 0.06437003
INFO:root:At the start of the epoch: mem (CPU python)=21062.48828125MB; mem (CPU total)=31590.21875MB
INFO:root:[  147] Training loss: 0.61070073, Validation loss: 0.60459349, Gradient norm: 0.06821363
INFO:root:At the start of the epoch: mem (CPU python)=21100.58203125MB; mem (CPU total)=31672.56640625MB
INFO:root:[  148] Training loss: 0.61066284, Validation loss: 0.60561175, Gradient norm: 0.07106072
INFO:root:At the start of the epoch: mem (CPU python)=21138.6796875MB; mem (CPU total)=31754.5625MB
INFO:root:[  149] Training loss: 0.61034732, Validation loss: 0.60518362, Gradient norm: 0.07379698
INFO:root:At the start of the epoch: mem (CPU python)=21176.77734375MB; mem (CPU total)=31835.95703125MB
INFO:root:[  150] Training loss: 0.61018571, Validation loss: 0.60612797, Gradient norm: 0.07319024
INFO:root:At the start of the epoch: mem (CPU python)=21214.87109375MB; mem (CPU total)=31918.41015625MB
INFO:root:[  151] Training loss: 0.61032635, Validation loss: 0.60569652, Gradient norm: 0.07272271
INFO:root:At the start of the epoch: mem (CPU python)=21252.96875MB; mem (CPU total)=31997.42578125MB
INFO:root:[  152] Training loss: 0.61031860, Validation loss: 0.60567629, Gradient norm: 0.07018671
INFO:root:At the start of the epoch: mem (CPU python)=21291.0625MB; mem (CPU total)=32073.9765625MB
INFO:root:[  153] Training loss: 0.60973223, Validation loss: 0.60483589, Gradient norm: 0.07459574
INFO:root:At the start of the epoch: mem (CPU python)=21329.15625MB; mem (CPU total)=32154.70703125MB
INFO:root:[  154] Training loss: 0.60990224, Validation loss: 0.60444130, Gradient norm: 0.07492708
INFO:root:At the start of the epoch: mem (CPU python)=21367.25MB; mem (CPU total)=32237.171875MB
INFO:root:[  155] Training loss: 0.60998264, Validation loss: 0.60557697, Gradient norm: 0.07098044
INFO:root:At the start of the epoch: mem (CPU python)=21405.34765625MB; mem (CPU total)=32318.24609375MB
INFO:root:[  156] Training loss: 0.60978559, Validation loss: 0.60466187, Gradient norm: 0.07481255
INFO:root:At the start of the epoch: mem (CPU python)=21443.4453125MB; mem (CPU total)=32399.94140625MB
INFO:root:[  157] Training loss: 0.60947106, Validation loss: 0.60527609, Gradient norm: 0.06992142
INFO:root:At the start of the epoch: mem (CPU python)=21481.5390625MB; mem (CPU total)=32482.13671875MB
INFO:root:[  158] Training loss: 0.60936821, Validation loss: 0.60506727, Gradient norm: 0.06867441
INFO:root:At the start of the epoch: mem (CPU python)=21519.63671875MB; mem (CPU total)=32564.0859375MB
INFO:root:[  159] Training loss: 0.60899306, Validation loss: 0.60539049, Gradient norm: 0.06404730
INFO:root:At the start of the epoch: mem (CPU python)=21557.73046875MB; mem (CPU total)=32646.5234375MB
INFO:root:[  160] Training loss: 0.60950510, Validation loss: 0.60334274, Gradient norm: 0.08341416
INFO:root:At the start of the epoch: mem (CPU python)=21595.82421875MB; mem (CPU total)=32723.03125MB
INFO:root:[  161] Training loss: 0.60919081, Validation loss: 0.60526887, Gradient norm: 0.07179389
INFO:root:At the start of the epoch: mem (CPU python)=21633.921875MB; mem (CPU total)=32800.359375MB
INFO:root:[  162] Training loss: 0.60882973, Validation loss: 0.60390325, Gradient norm: 0.06725332
INFO:root:At the start of the epoch: mem (CPU python)=21672.015625MB; mem (CPU total)=32882.33203125MB
INFO:root:[  163] Training loss: 0.60907677, Validation loss: 0.60369054, Gradient norm: 0.07499126
INFO:root:At the start of the epoch: mem (CPU python)=21710.109375MB; mem (CPU total)=32964.02734375MB
INFO:root:[  164] Training loss: 0.60845924, Validation loss: 0.60452861, Gradient norm: 0.06777167
INFO:root:At the start of the epoch: mem (CPU python)=21748.20703125MB; mem (CPU total)=33045.98046875MB
INFO:root:[  165] Training loss: 0.60850153, Validation loss: 0.60379886, Gradient norm: 0.06376063
INFO:root:At the start of the epoch: mem (CPU python)=21786.3046875MB; mem (CPU total)=33127.09765625MB
INFO:root:[  166] Training loss: 0.60858035, Validation loss: 0.60511983, Gradient norm: 0.07397325
INFO:root:At the start of the epoch: mem (CPU python)=21824.3984375MB; mem (CPU total)=33209.015625MB
INFO:root:[  167] Training loss: 0.60847924, Validation loss: 0.60480508, Gradient norm: 0.07154111
INFO:root:At the start of the epoch: mem (CPU python)=21862.4921875MB; mem (CPU total)=33291.45703125MB
INFO:root:[  168] Training loss: 0.60817958, Validation loss: 0.60410167, Gradient norm: 0.07290341
INFO:root:At the start of the epoch: mem (CPU python)=21900.58984375MB; mem (CPU total)=33371.6640625MB
INFO:root:[  169] Training loss: 0.60839654, Validation loss: 0.60449089, Gradient norm: 0.07371566
INFO:root:At the start of the epoch: mem (CPU python)=21938.68359375MB; mem (CPU total)=33448.23046875MB
INFO:root:EP 169: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=21976.77734375MB; mem (CPU total)=33514.3984375MB
INFO:root:Training the model took 8868.34s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83557
INFO:root:EnergyScoreTrain: 0.58826
INFO:root:CRPSTrain: 0.45473
INFO:root:Gaussian NLLTrain: 1.17989
INFO:root:CoverageTrain: 0.94793
INFO:root:IntervalWidthTrain: 3.21012
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.85829
INFO:root:EnergyScoreValidation: 0.60413
INFO:root:CRPSValidation: 0.4682
INFO:root:Gaussian NLLValidation: 1.21274
INFO:root:CoverageValidation: 0.94083
INFO:root:IntervalWidthValidation: 3.21445
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.85972
INFO:root:EnergyScoreTest: 0.60514
INFO:root:CRPSTest: 0.46912
INFO:root:Gaussian NLLTest: 1.21544
INFO:root:CoverageTest: 0.94011
INFO:root:IntervalWidthTest: 3.21494
INFO:root:After validation: mem (CPU python)=22019.72265625MB; mem (CPU total)=33615.0MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=22019.72265625MB; mem (CPU total)=33638.125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=22019.984375MB; mem (CPU total)=33639.35546875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=22020.125MB; mem (CPU total)=33650.67578125MB
INFO:root:[    1] Training loss: 0.72418783, Validation loss: 0.72079133, Gradient norm: 0.01377146
INFO:root:At the start of the epoch: mem (CPU python)=22058.2109375MB; mem (CPU total)=33732.62890625MB
INFO:root:[    2] Training loss: 0.71996914, Validation loss: 0.71916583, Gradient norm: 0.00580924
INFO:root:At the start of the epoch: mem (CPU python)=22096.3046875MB; mem (CPU total)=33814.0703125MB
INFO:root:[    3] Training loss: 0.71864013, Validation loss: 0.71666370, Gradient norm: 0.00706153
INFO:root:At the start of the epoch: mem (CPU python)=22134.41796875MB; mem (CPU total)=33895.46875MB
INFO:root:[    4] Training loss: 0.71383944, Validation loss: 0.70708089, Gradient norm: 0.01506181
INFO:root:At the start of the epoch: mem (CPU python)=22172.52734375MB; mem (CPU total)=33977.171875MB
INFO:root:[    5] Training loss: 0.70597628, Validation loss: 0.69963709, Gradient norm: 0.02432005
INFO:root:At the start of the epoch: mem (CPU python)=22210.62109375MB; mem (CPU total)=34058.8203125MB
INFO:root:[    6] Training loss: 0.69982282, Validation loss: 0.69322664, Gradient norm: 0.02788053
INFO:root:At the start of the epoch: mem (CPU python)=22248.71875MB; mem (CPU total)=34140.5234375MB
INFO:root:[    7] Training loss: 0.69381413, Validation loss: 0.68667186, Gradient norm: 0.03135510
INFO:root:At the start of the epoch: mem (CPU python)=22286.8125MB; mem (CPU total)=34217.05859375MB
INFO:root:[    8] Training loss: 0.68901979, Validation loss: 0.68087414, Gradient norm: 0.02789144
INFO:root:At the start of the epoch: mem (CPU python)=22324.91015625MB; mem (CPU total)=34294.03515625MB
INFO:root:[    9] Training loss: 0.68514779, Validation loss: 0.67828903, Gradient norm: 0.03056770
INFO:root:At the start of the epoch: mem (CPU python)=22363.00390625MB; mem (CPU total)=34375.73828125MB
INFO:root:[   10] Training loss: 0.68142326, Validation loss: 0.67360143, Gradient norm: 0.02912593
INFO:root:At the start of the epoch: mem (CPU python)=22401.1015625MB; mem (CPU total)=34456.671875MB
INFO:root:[   11] Training loss: 0.67868217, Validation loss: 0.67180571, Gradient norm: 0.03074688
INFO:root:At the start of the epoch: mem (CPU python)=22439.1953125MB; mem (CPU total)=34538.12890625MB
INFO:root:[   12] Training loss: 0.67627771, Validation loss: 0.66827251, Gradient norm: 0.02944191
INFO:root:At the start of the epoch: mem (CPU python)=22477.2890625MB; mem (CPU total)=34619.83203125MB
INFO:root:[   13] Training loss: 0.67372618, Validation loss: 0.66609768, Gradient norm: 0.02976088
INFO:root:At the start of the epoch: mem (CPU python)=22515.38671875MB; mem (CPU total)=34701.4453125MB
INFO:root:[   14] Training loss: 0.67177290, Validation loss: 0.66380774, Gradient norm: 0.03280593
INFO:root:At the start of the epoch: mem (CPU python)=22553.48046875MB; mem (CPU total)=34783.37109375MB
INFO:root:[   15] Training loss: 0.66979634, Validation loss: 0.66166082, Gradient norm: 0.03354475
INFO:root:At the start of the epoch: mem (CPU python)=22591.57421875MB; mem (CPU total)=34866.44140625MB
INFO:root:[   16] Training loss: 0.66799082, Validation loss: 0.66044199, Gradient norm: 0.03184997
INFO:root:At the start of the epoch: mem (CPU python)=22629.67578125MB; mem (CPU total)=34942.609375MB
INFO:root:[   17] Training loss: 0.66634126, Validation loss: 0.65807300, Gradient norm: 0.03336240
INFO:root:At the start of the epoch: mem (CPU python)=22667.76953125MB; mem (CPU total)=35019.15234375MB
INFO:root:[   18] Training loss: 0.66448921, Validation loss: 0.65736293, Gradient norm: 0.03326704
INFO:root:At the start of the epoch: mem (CPU python)=22705.86328125MB; mem (CPU total)=35099.58203125MB
INFO:root:[   19] Training loss: 0.66317298, Validation loss: 0.65482602, Gradient norm: 0.03553072
INFO:root:At the start of the epoch: mem (CPU python)=22743.95703125MB; mem (CPU total)=35181.32421875MB
INFO:root:[   20] Training loss: 0.66180741, Validation loss: 0.65331454, Gradient norm: 0.03849781
INFO:root:At the start of the epoch: mem (CPU python)=22782.0546875MB; mem (CPU total)=35262.80859375MB
INFO:root:[   21] Training loss: 0.66052638, Validation loss: 0.65147365, Gradient norm: 0.03563809
INFO:root:At the start of the epoch: mem (CPU python)=22820.1484375MB; mem (CPU total)=35344.27734375MB
INFO:root:[   22] Training loss: 0.65912941, Validation loss: 0.65018531, Gradient norm: 0.03990433
INFO:root:At the start of the epoch: mem (CPU python)=22858.2421875MB; mem (CPU total)=35426.16796875MB
INFO:root:[   23] Training loss: 0.65781667, Validation loss: 0.64852302, Gradient norm: 0.03773298
INFO:root:At the start of the epoch: mem (CPU python)=22896.33984375MB; mem (CPU total)=35507.9140625MB
INFO:root:[   24] Training loss: 0.65642792, Validation loss: 0.64788134, Gradient norm: 0.03557763
INFO:root:At the start of the epoch: mem (CPU python)=22934.43359375MB; mem (CPU total)=35590.5546875MB
INFO:root:[   25] Training loss: 0.65545740, Validation loss: 0.64631367, Gradient norm: 0.04264842
INFO:root:At the start of the epoch: mem (CPU python)=22972.53125MB; mem (CPU total)=35666.796875MB
INFO:root:[   26] Training loss: 0.65406776, Validation loss: 0.64511252, Gradient norm: 0.04095010
INFO:root:At the start of the epoch: mem (CPU python)=23010.625MB; mem (CPU total)=35743.37890625MB
INFO:root:[   27] Training loss: 0.65300447, Validation loss: 0.64336611, Gradient norm: 0.03773682
INFO:root:At the start of the epoch: mem (CPU python)=23048.72265625MB; mem (CPU total)=35825.56640625MB
INFO:root:[   28] Training loss: 0.65198786, Validation loss: 0.64242806, Gradient norm: 0.04004651
INFO:root:At the start of the epoch: mem (CPU python)=23086.81640625MB; mem (CPU total)=35907.49609375MB
INFO:root:[   29] Training loss: 0.65090301, Validation loss: 0.64132417, Gradient norm: 0.04663588
INFO:root:At the start of the epoch: mem (CPU python)=23124.91015625MB; mem (CPU total)=35989.66796875MB
INFO:root:[   30] Training loss: 0.64978399, Validation loss: 0.64065203, Gradient norm: 0.04455278
INFO:root:At the start of the epoch: mem (CPU python)=23163.0078125MB; mem (CPU total)=36070.8125MB
INFO:root:[   31] Training loss: 0.64885641, Validation loss: 0.63890557, Gradient norm: 0.04468073
INFO:root:At the start of the epoch: mem (CPU python)=23201.1015625MB; mem (CPU total)=36152.7109375MB
INFO:root:[   32] Training loss: 0.64813714, Validation loss: 0.63810732, Gradient norm: 0.04224034
INFO:root:At the start of the epoch: mem (CPU python)=23239.1953125MB; mem (CPU total)=36236.1328125MB
INFO:root:[   33] Training loss: 0.64721397, Validation loss: 0.63823984, Gradient norm: 0.04492365
INFO:root:At the start of the epoch: mem (CPU python)=23277.296875MB; mem (CPU total)=36315.8671875MB
INFO:root:[   34] Training loss: 0.64652198, Validation loss: 0.63663838, Gradient norm: 0.04641416
INFO:root:At the start of the epoch: mem (CPU python)=23315.390625MB; mem (CPU total)=36391.87890625MB
INFO:root:[   35] Training loss: 0.64581971, Validation loss: 0.63641248, Gradient norm: 0.04529075
INFO:root:At the start of the epoch: mem (CPU python)=23353.484375MB; mem (CPU total)=36469.58203125MB
INFO:root:[   36] Training loss: 0.64482801, Validation loss: 0.63541733, Gradient norm: 0.04510366
INFO:root:At the start of the epoch: mem (CPU python)=23391.578125MB; mem (CPU total)=36551.74609375MB
INFO:root:[   37] Training loss: 0.64435272, Validation loss: 0.63425528, Gradient norm: 0.04817830
INFO:root:At the start of the epoch: mem (CPU python)=23429.67578125MB; mem (CPU total)=36633.515625MB
INFO:root:[   38] Training loss: 0.64362295, Validation loss: 0.63340368, Gradient norm: 0.04678805
INFO:root:At the start of the epoch: mem (CPU python)=23467.76953125MB; mem (CPU total)=36715.44140625MB
INFO:root:[   39] Training loss: 0.64330574, Validation loss: 0.63297548, Gradient norm: 0.06070125
INFO:root:At the start of the epoch: mem (CPU python)=23505.86328125MB; mem (CPU total)=36797.14453125MB
INFO:root:[   40] Training loss: 0.64240622, Validation loss: 0.63257650, Gradient norm: 0.04909376
INFO:root:At the start of the epoch: mem (CPU python)=23543.96484375MB; mem (CPU total)=36879.06640625MB
INFO:root:[   41] Training loss: 0.64166976, Validation loss: 0.63164032, Gradient norm: 0.04695774
INFO:root:At the start of the epoch: mem (CPU python)=23582.0625MB; mem (CPU total)=36961.83203125MB
INFO:root:[   42] Training loss: 0.64088035, Validation loss: 0.63091962, Gradient norm: 0.04226369
INFO:root:At the start of the epoch: mem (CPU python)=23620.15625MB; mem (CPU total)=37041.0625MB
INFO:root:[   43] Training loss: 0.64062669, Validation loss: 0.63021782, Gradient norm: 0.04541627
INFO:root:At the start of the epoch: mem (CPU python)=23658.25MB; mem (CPU total)=37117.5703125MB
INFO:root:[   44] Training loss: 0.63979313, Validation loss: 0.62972484, Gradient norm: 0.04680198
INFO:root:At the start of the epoch: mem (CPU python)=23696.34765625MB; mem (CPU total)=37195.28125MB
INFO:root:[   45] Training loss: 0.63943744, Validation loss: 0.62934754, Gradient norm: 0.04807547
INFO:root:At the start of the epoch: mem (CPU python)=23734.44140625MB; mem (CPU total)=37276.68359375MB
INFO:root:[   46] Training loss: 0.63879097, Validation loss: 0.62902200, Gradient norm: 0.04922727
INFO:root:At the start of the epoch: mem (CPU python)=23772.53515625MB; mem (CPU total)=37358.81640625MB
INFO:root:[   47] Training loss: 0.63845178, Validation loss: 0.62865022, Gradient norm: 0.05217729
INFO:root:At the start of the epoch: mem (CPU python)=23810.6328125MB; mem (CPU total)=37440.71484375MB
INFO:root:[   48] Training loss: 0.63820571, Validation loss: 0.62840061, Gradient norm: 0.05537209
INFO:root:At the start of the epoch: mem (CPU python)=23848.7265625MB; mem (CPU total)=37522.890625MB
INFO:root:[   49] Training loss: 0.63758020, Validation loss: 0.62754758, Gradient norm: 0.05081113
INFO:root:At the start of the epoch: mem (CPU python)=23886.8203125MB; mem (CPU total)=37604.63671875MB
INFO:root:[   50] Training loss: 0.63705658, Validation loss: 0.62723852, Gradient norm: 0.05040632
INFO:root:At the start of the epoch: mem (CPU python)=23924.921875MB; mem (CPU total)=37687.078125MB
INFO:root:[   51] Training loss: 0.63647289, Validation loss: 0.62668271, Gradient norm: 0.05017584
INFO:root:At the start of the epoch: mem (CPU python)=23963.015625MB; mem (CPU total)=37768.109375MB
INFO:root:[   52] Training loss: 0.63622687, Validation loss: 0.62622185, Gradient norm: 0.05352599
INFO:root:At the start of the epoch: mem (CPU python)=24001.109375MB; mem (CPU total)=37844.16015625MB
INFO:root:[   53] Training loss: 0.63577720, Validation loss: 0.62567420, Gradient norm: 0.05408074
INFO:root:At the start of the epoch: mem (CPU python)=24039.203125MB; mem (CPU total)=37921.6953125MB
INFO:root:[   54] Training loss: 0.63537592, Validation loss: 0.62580489, Gradient norm: 0.05194860
INFO:root:At the start of the epoch: mem (CPU python)=24077.3125MB; mem (CPU total)=38003.19921875MB
INFO:root:[   55] Training loss: 0.63452061, Validation loss: 0.62470741, Gradient norm: 0.04999476
INFO:root:At the start of the epoch: mem (CPU python)=24115.40625MB; mem (CPU total)=38085.38671875MB
INFO:root:[   56] Training loss: 0.63454260, Validation loss: 0.62418460, Gradient norm: 0.05600678
INFO:root:At the start of the epoch: mem (CPU python)=24153.5MB; mem (CPU total)=38166.85546875MB
INFO:root:[   57] Training loss: 0.63401273, Validation loss: 0.62455802, Gradient norm: 0.05657883
INFO:root:At the start of the epoch: mem (CPU python)=24191.6015625MB; mem (CPU total)=38247.55078125MB
INFO:root:[   58] Training loss: 0.63371126, Validation loss: 0.62377612, Gradient norm: 0.05915248
INFO:root:At the start of the epoch: mem (CPU python)=24229.6953125MB; mem (CPU total)=38329.43359375MB
INFO:root:[   59] Training loss: 0.63326593, Validation loss: 0.62384367, Gradient norm: 0.05299440
INFO:root:At the start of the epoch: mem (CPU python)=24267.7890625MB; mem (CPU total)=38411.9375MB
INFO:root:[   60] Training loss: 0.63278387, Validation loss: 0.62321243, Gradient norm: 0.05045360
INFO:root:At the start of the epoch: mem (CPU python)=24305.8828125MB; mem (CPU total)=38493.18359375MB
INFO:root:[   61] Training loss: 0.63274774, Validation loss: 0.62278603, Gradient norm: 0.05463383
INFO:root:At the start of the epoch: mem (CPU python)=24343.98046875MB; mem (CPU total)=38569.5MB
INFO:root:[   62] Training loss: 0.63229064, Validation loss: 0.62293922, Gradient norm: 0.05054412
INFO:root:At the start of the epoch: mem (CPU python)=24382.07421875MB; mem (CPU total)=38646.0703125MB
INFO:root:[   63] Training loss: 0.63176816, Validation loss: 0.62305095, Gradient norm: 0.05480211
INFO:root:At the start of the epoch: mem (CPU python)=24420.16796875MB; mem (CPU total)=38725.8046875MB
INFO:root:[   64] Training loss: 0.63166106, Validation loss: 0.62137926, Gradient norm: 0.05714347
INFO:root:At the start of the epoch: mem (CPU python)=24458.26953125MB; mem (CPU total)=38806.859375MB
INFO:root:[   65] Training loss: 0.63139681, Validation loss: 0.62201328, Gradient norm: 0.05583928
INFO:root:At the start of the epoch: mem (CPU python)=24496.36328125MB; mem (CPU total)=38888.5625MB
INFO:root:[   66] Training loss: 0.63089600, Validation loss: 0.62192364, Gradient norm: 0.05728738
INFO:root:At the start of the epoch: mem (CPU python)=24534.45703125MB; mem (CPU total)=38969.71875MB
INFO:root:[   67] Training loss: 0.63064005, Validation loss: 0.62038017, Gradient norm: 0.05505942
INFO:root:At the start of the epoch: mem (CPU python)=24572.5546875MB; mem (CPU total)=39050.8828125MB
INFO:root:[   68] Training loss: 0.63033401, Validation loss: 0.62073765, Gradient norm: 0.05399904
INFO:root:At the start of the epoch: mem (CPU python)=24610.6484375MB; mem (CPU total)=39132.63671875MB
INFO:root:[   69] Training loss: 0.63005425, Validation loss: 0.62048475, Gradient norm: 0.05489629
INFO:root:At the start of the epoch: mem (CPU python)=24648.7421875MB; mem (CPU total)=39214.8515625MB
INFO:root:[   70] Training loss: 0.62984193, Validation loss: 0.62044352, Gradient norm: 0.05602543
INFO:root:At the start of the epoch: mem (CPU python)=24686.8359375MB; mem (CPU total)=39294.36328125MB
INFO:root:[   71] Training loss: 0.62933488, Validation loss: 0.61987068, Gradient norm: 0.05638923
INFO:root:At the start of the epoch: mem (CPU python)=24724.93359375MB; mem (CPU total)=39371.37890625MB
INFO:root:[   72] Training loss: 0.62886298, Validation loss: 0.62002805, Gradient norm: 0.05333044
INFO:root:At the start of the epoch: mem (CPU python)=24763.02734375MB; mem (CPU total)=39447.1875MB
INFO:root:[   73] Training loss: 0.62879422, Validation loss: 0.61906272, Gradient norm: 0.05355573
INFO:root:At the start of the epoch: mem (CPU python)=24801.125MB; mem (CPU total)=39526.4375MB
INFO:root:[   74] Training loss: 0.62870517, Validation loss: 0.61953478, Gradient norm: 0.05759092
INFO:root:At the start of the epoch: mem (CPU python)=24839.22265625MB; mem (CPU total)=39608.1796875MB
INFO:root:[   75] Training loss: 0.62823958, Validation loss: 0.61875308, Gradient norm: 0.06014312
INFO:root:At the start of the epoch: mem (CPU python)=24877.31640625MB; mem (CPU total)=39689.65234375MB
INFO:root:[   76] Training loss: 0.62789841, Validation loss: 0.61839961, Gradient norm: 0.05261813
INFO:root:At the start of the epoch: mem (CPU python)=24915.41015625MB; mem (CPU total)=39770.875MB
INFO:root:[   77] Training loss: 0.62794685, Validation loss: 0.61849631, Gradient norm: 0.05731579
INFO:root:At the start of the epoch: mem (CPU python)=24953.50390625MB; mem (CPU total)=39852.48828125MB
INFO:root:[   78] Training loss: 0.62760868, Validation loss: 0.61835672, Gradient norm: 0.05979122
INFO:root:At the start of the epoch: mem (CPU python)=24991.6015625MB; mem (CPU total)=39933.73046875MB
INFO:root:[   79] Training loss: 0.62723541, Validation loss: 0.61823477, Gradient norm: 0.05647358
INFO:root:At the start of the epoch: mem (CPU python)=25029.6953125MB; mem (CPU total)=40015.2421875MB
INFO:root:[   80] Training loss: 0.62677407, Validation loss: 0.61794628, Gradient norm: 0.05759377
INFO:root:At the start of the epoch: mem (CPU python)=25067.7890625MB; mem (CPU total)=40097.4453125MB
INFO:root:[   81] Training loss: 0.62665048, Validation loss: 0.61768357, Gradient norm: 0.05418728
INFO:root:At the start of the epoch: mem (CPU python)=25105.88671875MB; mem (CPU total)=40145.75MB
INFO:root:[   82] Training loss: 0.62645000, Validation loss: 0.61652543, Gradient norm: 0.05787223
INFO:root:At the start of the epoch: mem (CPU python)=25143.984375MB; mem (CPU total)=40194.984375MB
INFO:root:[   83] Training loss: 0.62614135, Validation loss: 0.61666314, Gradient norm: 0.05825284
INFO:root:At the start of the epoch: mem (CPU python)=25182.078125MB; mem (CPU total)=40243.97265625MB
INFO:root:[   84] Training loss: 0.62585627, Validation loss: 0.61681837, Gradient norm: 0.05760537
INFO:root:At the start of the epoch: mem (CPU python)=25220.17578125MB; mem (CPU total)=40292.4765625MB
INFO:root:[   85] Training loss: 0.62606477, Validation loss: 0.61586864, Gradient norm: 0.06002117
INFO:root:At the start of the epoch: mem (CPU python)=25258.26953125MB; mem (CPU total)=40364.84375MB
INFO:root:[   86] Training loss: 0.62576263, Validation loss: 0.61602692, Gradient norm: 0.05788536
INFO:root:At the start of the epoch: mem (CPU python)=25296.36328125MB; mem (CPU total)=40446.3359375MB
INFO:root:[   87] Training loss: 0.62535564, Validation loss: 0.61592435, Gradient norm: 0.07112709
INFO:root:At the start of the epoch: mem (CPU python)=25334.45703125MB; mem (CPU total)=40522.453125MB
INFO:root:[   88] Training loss: 0.62519321, Validation loss: 0.61631914, Gradient norm: 0.05799093
INFO:root:At the start of the epoch: mem (CPU python)=25372.5546875MB; mem (CPU total)=40599.3125MB
INFO:root:[   89] Training loss: 0.62492990, Validation loss: 0.61602588, Gradient norm: 0.06473389
INFO:root:At the start of the epoch: mem (CPU python)=25410.6484375MB; mem (CPU total)=40675.87109375MB
INFO:root:[   90] Training loss: 0.62459200, Validation loss: 0.61600535, Gradient norm: 0.05690355
INFO:root:At the start of the epoch: mem (CPU python)=25448.74609375MB; mem (CPU total)=40757.46484375MB
INFO:root:[   91] Training loss: 0.62445264, Validation loss: 0.61540989, Gradient norm: 0.06018690
INFO:root:At the start of the epoch: mem (CPU python)=25486.84375MB; mem (CPU total)=40839.1953125MB
INFO:root:[   92] Training loss: 0.62428475, Validation loss: 0.61529719, Gradient norm: 0.06272752
INFO:root:At the start of the epoch: mem (CPU python)=25524.9375MB; mem (CPU total)=40919.54296875MB
INFO:root:[   93] Training loss: 0.62385145, Validation loss: 0.61583064, Gradient norm: 0.06222292
INFO:root:At the start of the epoch: mem (CPU python)=25563.03125MB; mem (CPU total)=41000.4609375MB
INFO:root:[   94] Training loss: 0.62349652, Validation loss: 0.61519970, Gradient norm: 0.06171784
INFO:root:At the start of the epoch: mem (CPU python)=25601.125MB; mem (CPU total)=41081.69140625MB
INFO:root:[   95] Training loss: 0.62348158, Validation loss: 0.61530859, Gradient norm: 0.06152225
INFO:root:At the start of the epoch: mem (CPU python)=25639.22265625MB; mem (CPU total)=41162.6796875MB
INFO:root:[   96] Training loss: 0.62337513, Validation loss: 0.61457272, Gradient norm: 0.07001294
INFO:root:At the start of the epoch: mem (CPU python)=25677.31640625MB; mem (CPU total)=41243.9140625MB
INFO:root:[   97] Training loss: 0.62292605, Validation loss: 0.61541554, Gradient norm: 0.06042612
INFO:root:At the start of the epoch: mem (CPU python)=25715.41015625MB; mem (CPU total)=41324.90234375MB
INFO:root:[   98] Training loss: 0.62314640, Validation loss: 0.61389834, Gradient norm: 0.06641758
INFO:root:At the start of the epoch: mem (CPU python)=25753.51171875MB; mem (CPU total)=41400.70703125MB
INFO:root:[   99] Training loss: 0.62285380, Validation loss: 0.61344911, Gradient norm: 0.06360230
INFO:root:At the start of the epoch: mem (CPU python)=25791.60546875MB; mem (CPU total)=41476.65234375MB
INFO:root:[  100] Training loss: 0.62252559, Validation loss: 0.61426181, Gradient norm: 0.05737794
INFO:root:At the start of the epoch: mem (CPU python)=25829.69921875MB; mem (CPU total)=41553.2109375MB
INFO:root:[  101] Training loss: 0.62235475, Validation loss: 0.61332167, Gradient norm: 0.06249499
INFO:root:At the start of the epoch: mem (CPU python)=25867.796875MB; mem (CPU total)=41633.453125MB
INFO:root:[  102] Training loss: 0.62213447, Validation loss: 0.61361843, Gradient norm: 0.05699029
INFO:root:At the start of the epoch: mem (CPU python)=25905.89453125MB; mem (CPU total)=41714.68359375MB
INFO:root:[  103] Training loss: 0.62182494, Validation loss: 0.61397898, Gradient norm: 0.06136863
INFO:root:At the start of the epoch: mem (CPU python)=25943.98828125MB; mem (CPU total)=41795.3671875MB
INFO:root:[  104] Training loss: 0.62184872, Validation loss: 0.61276094, Gradient norm: 0.06176654
INFO:root:At the start of the epoch: mem (CPU python)=25982.08203125MB; mem (CPU total)=41876.68359375MB
INFO:root:[  105] Training loss: 0.62162335, Validation loss: 0.61282323, Gradient norm: 0.06462883
INFO:root:At the start of the epoch: mem (CPU python)=26020.17578125MB; mem (CPU total)=41957.6328125MB
INFO:root:[  106] Training loss: 0.62124186, Validation loss: 0.61296701, Gradient norm: 0.06093449
INFO:root:At the start of the epoch: mem (CPU python)=26058.2734375MB; mem (CPU total)=42038.3515625MB
INFO:root:[  107] Training loss: 0.62155603, Validation loss: 0.61320838, Gradient norm: 0.06874710
INFO:root:At the start of the epoch: mem (CPU python)=26096.3671875MB; mem (CPU total)=42119.51953125MB
INFO:root:[  108] Training loss: 0.62119625, Validation loss: 0.61287706, Gradient norm: 0.05999766
INFO:root:At the start of the epoch: mem (CPU python)=26134.46875MB; mem (CPU total)=42201.24609375MB
INFO:root:[  109] Training loss: 0.62087107, Validation loss: 0.61205513, Gradient norm: 0.06718540
INFO:root:At the start of the epoch: mem (CPU python)=26172.5625MB; mem (CPU total)=42278.2890625MB
INFO:root:[  110] Training loss: 0.62059850, Validation loss: 0.61204186, Gradient norm: 0.06078064
INFO:root:At the start of the epoch: mem (CPU python)=26210.65625MB; mem (CPU total)=42354.4140625MB
INFO:root:[  111] Training loss: 0.62051183, Validation loss: 0.61168077, Gradient norm: 0.06116781
INFO:root:At the start of the epoch: mem (CPU python)=26248.75MB; mem (CPU total)=42429.9765625MB
INFO:root:[  112] Training loss: 0.62028653, Validation loss: 0.61207617, Gradient norm: 0.05703029
INFO:root:At the start of the epoch: mem (CPU python)=26286.84765625MB; mem (CPU total)=42506.09765625MB
INFO:root:[  113] Training loss: 0.62016024, Validation loss: 0.61317050, Gradient norm: 0.06380096
INFO:root:At the start of the epoch: mem (CPU python)=26324.94140625MB; mem (CPU total)=42586.046875MB
INFO:root:[  114] Training loss: 0.62013320, Validation loss: 0.61184871, Gradient norm: 0.06543183
INFO:root:At the start of the epoch: mem (CPU python)=26363.03515625MB; mem (CPU total)=42665.9609375MB
INFO:root:[  115] Training loss: 0.61978969, Validation loss: 0.61216507, Gradient norm: 0.06022359
INFO:root:At the start of the epoch: mem (CPU python)=26401.13671875MB; mem (CPU total)=42745.95703125MB
INFO:root:[  116] Training loss: 0.61943940, Validation loss: 0.61148749, Gradient norm: 0.06310822
INFO:root:At the start of the epoch: mem (CPU python)=26439.23046875MB; mem (CPU total)=42826.6328125MB
INFO:root:[  117] Training loss: 0.61948928, Validation loss: 0.61160989, Gradient norm: 0.07041042
INFO:root:At the start of the epoch: mem (CPU python)=26477.32421875MB; mem (CPU total)=42906.63671875MB
INFO:root:[  118] Training loss: 0.61955406, Validation loss: 0.61113355, Gradient norm: 0.06877728
INFO:root:At the start of the epoch: mem (CPU python)=26515.421875MB; mem (CPU total)=42986.734375MB
INFO:root:[  119] Training loss: 0.61934878, Validation loss: 0.61123549, Gradient norm: 0.06376303
INFO:root:At the start of the epoch: mem (CPU python)=26553.515625MB; mem (CPU total)=43067.21484375MB
INFO:root:[  120] Training loss: 0.61925475, Validation loss: 0.61084997, Gradient norm: 0.07030396
INFO:root:At the start of the epoch: mem (CPU python)=26591.609375MB; mem (CPU total)=43146.89453125MB
INFO:root:[  121] Training loss: 0.61912213, Validation loss: 0.61112696, Gradient norm: 0.06804276
INFO:root:At the start of the epoch: mem (CPU python)=26629.703125MB; mem (CPU total)=43228.0390625MB
INFO:root:[  122] Training loss: 0.61844524, Validation loss: 0.61181363, Gradient norm: 0.06570679
INFO:root:At the start of the epoch: mem (CPU python)=26667.80078125MB; mem (CPU total)=43307.55078125MB
INFO:root:[  123] Training loss: 0.61841591, Validation loss: 0.61095665, Gradient norm: 0.06999054
INFO:root:At the start of the epoch: mem (CPU python)=26705.89453125MB; mem (CPU total)=43383.859375MB
INFO:root:[  124] Training loss: 0.61842702, Validation loss: 0.61116414, Gradient norm: 0.06819734
INFO:root:At the start of the epoch: mem (CPU python)=26743.9921875MB; mem (CPU total)=43460.20703125MB
INFO:root:[  125] Training loss: 0.61814852, Validation loss: 0.61106076, Gradient norm: 0.07329409
INFO:root:At the start of the epoch: mem (CPU python)=26782.08984375MB; mem (CPU total)=43536.75MB
INFO:root:[  126] Training loss: 0.61818337, Validation loss: 0.61107535, Gradient norm: 0.06914466
INFO:root:At the start of the epoch: mem (CPU python)=26820.18359375MB; mem (CPU total)=43613.0625MB
INFO:root:[  127] Training loss: 0.61785622, Validation loss: 0.61055274, Gradient norm: 0.06274719
INFO:root:At the start of the epoch: mem (CPU python)=26858.27734375MB; mem (CPU total)=43693.3125MB
INFO:root:[  128] Training loss: 0.61791562, Validation loss: 0.61011549, Gradient norm: 0.07283677
INFO:root:At the start of the epoch: mem (CPU python)=26896.37109375MB; mem (CPU total)=43773.02734375MB
INFO:root:[  129] Training loss: 0.61780660, Validation loss: 0.60990483, Gradient norm: 0.06799798
INFO:root:At the start of the epoch: mem (CPU python)=26934.46875MB; mem (CPU total)=43853.02734375MB
INFO:root:[  130] Training loss: 0.61775006, Validation loss: 0.61020107, Gradient norm: 0.06965460
INFO:root:At the start of the epoch: mem (CPU python)=26972.5625MB; mem (CPU total)=43932.5234375MB
INFO:root:[  131] Training loss: 0.61750940, Validation loss: 0.60960714, Gradient norm: 0.06782890
INFO:root:At the start of the epoch: mem (CPU python)=27010.65625MB; mem (CPU total)=44012.296875MB
INFO:root:[  132] Training loss: 0.61726547, Validation loss: 0.60971056, Gradient norm: 0.06945416
INFO:root:At the start of the epoch: mem (CPU python)=27048.7578125MB; mem (CPU total)=44092.203125MB
INFO:root:[  133] Training loss: 0.61717161, Validation loss: 0.61033856, Gradient norm: 0.06293124
INFO:root:At the start of the epoch: mem (CPU python)=27086.8515625MB; mem (CPU total)=44172.4453125MB
INFO:root:[  134] Training loss: 0.61684645, Validation loss: 0.60994627, Gradient norm: 0.06557155
INFO:root:At the start of the epoch: mem (CPU python)=27124.9453125MB; mem (CPU total)=44252.44140625MB
INFO:root:[  135] Training loss: 0.61665053, Validation loss: 0.60919522, Gradient norm: 0.07295098
INFO:root:At the start of the epoch: mem (CPU python)=27163.0546875MB; mem (CPU total)=44332.546875MB
INFO:root:[  136] Training loss: 0.61685536, Validation loss: 0.60946399, Gradient norm: 0.07507173
INFO:root:At the start of the epoch: mem (CPU python)=27201.1484375MB; mem (CPU total)=44413.04296875MB
INFO:root:[  137] Training loss: 0.61683587, Validation loss: 0.61009657, Gradient norm: 0.06660415
INFO:root:At the start of the epoch: mem (CPU python)=27239.2421875MB; mem (CPU total)=44491.96484375MB
INFO:root:[  138] Training loss: 0.61653404, Validation loss: 0.60996937, Gradient norm: 0.06313087
INFO:root:At the start of the epoch: mem (CPU python)=27277.3359375MB; mem (CPU total)=44567.39453125MB
INFO:root:[  139] Training loss: 0.61628678, Validation loss: 0.60989880, Gradient norm: 0.06578973
INFO:root:At the start of the epoch: mem (CPU python)=27315.43359375MB; mem (CPU total)=44643.9453125MB
INFO:root:[  140] Training loss: 0.61647762, Validation loss: 0.60857990, Gradient norm: 0.06527671
INFO:root:At the start of the epoch: mem (CPU python)=27353.52734375MB; mem (CPU total)=44720.21484375MB
INFO:root:[  141] Training loss: 0.61635504, Validation loss: 0.60946488, Gradient norm: 0.07231762
INFO:root:At the start of the epoch: mem (CPU python)=27391.62109375MB; mem (CPU total)=44796.2734375MB
INFO:root:[  142] Training loss: 0.61594720, Validation loss: 0.60961726, Gradient norm: 0.06865948
INFO:root:At the start of the epoch: mem (CPU python)=27429.72265625MB; mem (CPU total)=44873.5703125MB
INFO:root:[  143] Training loss: 0.61594345, Validation loss: 0.60959609, Gradient norm: 0.07335021
INFO:root:At the start of the epoch: mem (CPU python)=27467.81640625MB; mem (CPU total)=44953.015625MB
INFO:root:[  144] Training loss: 0.61563126, Validation loss: 0.61034306, Gradient norm: 0.06860514
INFO:root:At the start of the epoch: mem (CPU python)=27505.91015625MB; mem (CPU total)=45032.828125MB
INFO:root:[  145] Training loss: 0.61576352, Validation loss: 0.60984373, Gradient norm: 0.06770179
INFO:root:At the start of the epoch: mem (CPU python)=27544.00390625MB; mem (CPU total)=45112.30859375MB
INFO:root:[  146] Training loss: 0.61564778, Validation loss: 0.60921441, Gradient norm: 0.07491512
INFO:root:At the start of the epoch: mem (CPU python)=27582.1015625MB; mem (CPU total)=45191.2890625MB
INFO:root:[  147] Training loss: 0.61520732, Validation loss: 0.60879263, Gradient norm: 0.06514142
INFO:root:At the start of the epoch: mem (CPU python)=27620.19921875MB; mem (CPU total)=45270.52734375MB
INFO:root:[  148] Training loss: 0.61519248, Validation loss: 0.60959238, Gradient norm: 0.06924934
INFO:root:At the start of the epoch: mem (CPU python)=27658.29296875MB; mem (CPU total)=45349.38671875MB
INFO:root:[  149] Training loss: 0.61516221, Validation loss: 0.60964625, Gradient norm: 0.06908287
INFO:root:At the start of the epoch: mem (CPU python)=27696.390625MB; mem (CPU total)=45428.53125MB
INFO:root:EP 149: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=27734.484375MB; mem (CPU total)=45482.171875MB
INFO:root:Training the model took 8996.5s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84615
INFO:root:EnergyScoreTrain: 0.59566
INFO:root:CRPSTrain: 0.46369
INFO:root:Gaussian NLLTrain: 1.2024
INFO:root:CoverageTrain: 0.94883
INFO:root:IntervalWidthTrain: 3.27285
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86543
INFO:root:EnergyScoreValidation: 0.60913
INFO:root:CRPSValidation: 0.47504
INFO:root:Gaussian NLLValidation: 1.22711
INFO:root:CoverageValidation: 0.9428
INFO:root:IntervalWidthValidation: 3.27472
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86745
INFO:root:EnergyScoreTest: 0.61054
INFO:root:CRPSTest: 0.47631
INFO:root:Gaussian NLLTest: 1.22925
INFO:root:CoverageTest: 0.94242
INFO:root:IntervalWidthTest: 3.27478
INFO:root:After validation: mem (CPU python)=27833.01171875MB; mem (CPU total)=45582.48046875MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=27833.01171875MB; mem (CPU total)=45600.72265625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=27833.01171875MB; mem (CPU total)=45601.21484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=27833.01171875MB; mem (CPU total)=45622.41015625MB
INFO:root:[    1] Training loss: 0.72508374, Validation loss: 0.72075442, Gradient norm: 0.01744050
INFO:root:At the start of the epoch: mem (CPU python)=27833.01171875MB; mem (CPU total)=45701.37890625MB
INFO:root:[    2] Training loss: 0.71976413, Validation loss: 0.71836599, Gradient norm: 0.00624311
INFO:root:At the start of the epoch: mem (CPU python)=27852.71484375MB; mem (CPU total)=45780.8671875MB
INFO:root:[    3] Training loss: 0.71453849, Validation loss: 0.70792956, Gradient norm: 0.01268922
INFO:root:At the start of the epoch: mem (CPU python)=27890.81640625MB; mem (CPU total)=45861.3359375MB
INFO:root:[    4] Training loss: 0.70710306, Validation loss: 0.70175263, Gradient norm: 0.02122946
INFO:root:At the start of the epoch: mem (CPU python)=27928.91015625MB; mem (CPU total)=45941.83203125MB
INFO:root:[    5] Training loss: 0.70173667, Validation loss: 0.69605532, Gradient norm: 0.02626702
INFO:root:At the start of the epoch: mem (CPU python)=27967.00390625MB; mem (CPU total)=46021.58984375MB
INFO:root:[    6] Training loss: 0.69659458, Validation loss: 0.68994309, Gradient norm: 0.02988793
INFO:root:At the start of the epoch: mem (CPU python)=28005.1015625MB; mem (CPU total)=46097.859375MB
INFO:root:[    7] Training loss: 0.69140320, Validation loss: 0.68346387, Gradient norm: 0.03026262
INFO:root:At the start of the epoch: mem (CPU python)=28043.1953125MB; mem (CPU total)=46173.8671875MB
INFO:root:[    8] Training loss: 0.68610648, Validation loss: 0.67841077, Gradient norm: 0.02792620
INFO:root:At the start of the epoch: mem (CPU python)=28081.2890625MB; mem (CPU total)=46250.203125MB
INFO:root:[    9] Training loss: 0.68197707, Validation loss: 0.67219225, Gradient norm: 0.03039513
INFO:root:At the start of the epoch: mem (CPU python)=28119.3828125MB; mem (CPU total)=46326.25MB
INFO:root:[   10] Training loss: 0.67816226, Validation loss: 0.66896850, Gradient norm: 0.03207150
INFO:root:At the start of the epoch: mem (CPU python)=28157.484375MB; mem (CPU total)=46403.01953125MB
INFO:root:[   11] Training loss: 0.67471168, Validation loss: 0.66571711, Gradient norm: 0.03029547
INFO:root:At the start of the epoch: mem (CPU python)=28195.58203125MB; mem (CPU total)=46479.34765625MB
INFO:root:[   12] Training loss: 0.67130295, Validation loss: 0.66225123, Gradient norm: 0.03153610
INFO:root:At the start of the epoch: mem (CPU python)=28233.67578125MB; mem (CPU total)=46558.859375MB
INFO:root:[   13] Training loss: 0.66895641, Validation loss: 0.65930391, Gradient norm: 0.03226911
INFO:root:At the start of the epoch: mem (CPU python)=28271.7734375MB; mem (CPU total)=46637.9453125MB
INFO:root:[   14] Training loss: 0.66653642, Validation loss: 0.65704028, Gradient norm: 0.03317205
INFO:root:At the start of the epoch: mem (CPU python)=28309.8671875MB; mem (CPU total)=46715.65625MB
INFO:root:[   15] Training loss: 0.66450962, Validation loss: 0.65387851, Gradient norm: 0.03330329
INFO:root:At the start of the epoch: mem (CPU python)=28347.9609375MB; mem (CPU total)=46794.8984375MB
INFO:root:[   16] Training loss: 0.66256195, Validation loss: 0.65251671, Gradient norm: 0.03599038
INFO:root:At the start of the epoch: mem (CPU python)=28386.05859375MB; mem (CPU total)=46874.2109375MB
INFO:root:[   17] Training loss: 0.66063810, Validation loss: 0.65060912, Gradient norm: 0.03288499
INFO:root:At the start of the epoch: mem (CPU python)=28424.15625MB; mem (CPU total)=46955.03515625MB
INFO:root:[   18] Training loss: 0.65897975, Validation loss: 0.64871985, Gradient norm: 0.03691325
INFO:root:At the start of the epoch: mem (CPU python)=28462.25MB; mem (CPU total)=47035.015625MB
INFO:root:[   19] Training loss: 0.65771038, Validation loss: 0.64703610, Gradient norm: 0.03856048
INFO:root:At the start of the epoch: mem (CPU python)=28500.34375MB; mem (CPU total)=47114.140625MB
INFO:root:[   20] Training loss: 0.65618132, Validation loss: 0.64607905, Gradient norm: 0.04156316
INFO:root:At the start of the epoch: mem (CPU python)=28538.44140625MB; mem (CPU total)=47193.3671875MB
INFO:root:[   21] Training loss: 0.65503723, Validation loss: 0.64416650, Gradient norm: 0.03935672
INFO:root:At the start of the epoch: mem (CPU python)=28576.53515625MB; mem (CPU total)=47272.87890625MB
INFO:root:[   22] Training loss: 0.65376666, Validation loss: 0.64298544, Gradient norm: 0.04467206
INFO:root:At the start of the epoch: mem (CPU python)=28614.62890625MB; mem (CPU total)=47351.51171875MB
INFO:root:[   23] Training loss: 0.65250211, Validation loss: 0.64154000, Gradient norm: 0.04109788
INFO:root:At the start of the epoch: mem (CPU python)=28652.7265625MB; mem (CPU total)=47431.4921875MB
INFO:root:[   24] Training loss: 0.65129163, Validation loss: 0.63985039, Gradient norm: 0.04180501
INFO:root:At the start of the epoch: mem (CPU python)=28690.8203125MB; mem (CPU total)=47509.2890625MB
INFO:root:[   25] Training loss: 0.65044865, Validation loss: 0.63978785, Gradient norm: 0.04883652
INFO:root:At the start of the epoch: mem (CPU python)=28728.91796875MB; mem (CPU total)=47584.9609375MB
INFO:root:[   26] Training loss: 0.64944697, Validation loss: 0.63807316, Gradient norm: 0.04694927
INFO:root:At the start of the epoch: mem (CPU python)=28767.01171875MB; mem (CPU total)=47661.73046875MB
INFO:root:[   27] Training loss: 0.64842575, Validation loss: 0.63726065, Gradient norm: 0.04789438
INFO:root:At the start of the epoch: mem (CPU python)=28805.109375MB; mem (CPU total)=47738.25MB
INFO:root:[   28] Training loss: 0.64745402, Validation loss: 0.63646515, Gradient norm: 0.04708715
INFO:root:At the start of the epoch: mem (CPU python)=28843.203125MB; mem (CPU total)=47814.96484375MB
INFO:root:[   29] Training loss: 0.64670336, Validation loss: 0.63639181, Gradient norm: 0.05180305
INFO:root:At the start of the epoch: mem (CPU python)=28881.296875MB; mem (CPU total)=47890.75390625MB
INFO:root:[   30] Training loss: 0.64554779, Validation loss: 0.63388375, Gradient norm: 0.04543430
INFO:root:At the start of the epoch: mem (CPU python)=28919.39453125MB; mem (CPU total)=47967.27734375MB
INFO:root:[   31] Training loss: 0.64499064, Validation loss: 0.63321248, Gradient norm: 0.04628061
INFO:root:At the start of the epoch: mem (CPU python)=28957.48828125MB; mem (CPU total)=48044.796875MB
INFO:root:[   32] Training loss: 0.64410284, Validation loss: 0.63253821, Gradient norm: 0.04930023
INFO:root:At the start of the epoch: mem (CPU python)=28995.58203125MB; mem (CPU total)=48123.69921875MB
INFO:root:[   33] Training loss: 0.64279419, Validation loss: 0.63207494, Gradient norm: 0.04647292
INFO:root:At the start of the epoch: mem (CPU python)=29033.67578125MB; mem (CPU total)=48203.21875MB
INFO:root:[   34] Training loss: 0.64253906, Validation loss: 0.63049376, Gradient norm: 0.05046236
INFO:root:At the start of the epoch: mem (CPU python)=29071.77734375MB; mem (CPU total)=48281.2734375MB
INFO:root:[   35] Training loss: 0.64212745, Validation loss: 0.63098329, Gradient norm: 0.05207947
INFO:root:At the start of the epoch: mem (CPU python)=29109.87109375MB; mem (CPU total)=48360.30078125MB
INFO:root:[   36] Training loss: 0.64113246, Validation loss: 0.62939724, Gradient norm: 0.05043435
INFO:root:At the start of the epoch: mem (CPU python)=29147.96484375MB; mem (CPU total)=48440.05078125MB
INFO:root:[   37] Training loss: 0.64051800, Validation loss: 0.62984740, Gradient norm: 0.04619113
INFO:root:At the start of the epoch: mem (CPU python)=29186.0625MB; mem (CPU total)=48519.046875MB
INFO:root:[   38] Training loss: 0.63993498, Validation loss: 0.62841170, Gradient norm: 0.05194335
INFO:root:At the start of the epoch: mem (CPU python)=29224.15625MB; mem (CPU total)=48598.2890625MB
INFO:root:[   39] Training loss: 0.63971634, Validation loss: 0.62832174, Gradient norm: 0.05455818
INFO:root:At the start of the epoch: mem (CPU python)=29262.25MB; mem (CPU total)=48677.10546875MB
INFO:root:[   40] Training loss: 0.63836936, Validation loss: 0.62763366, Gradient norm: 0.04839129
INFO:root:At the start of the epoch: mem (CPU python)=29300.34765625MB; mem (CPU total)=48755.29296875MB
INFO:root:[   41] Training loss: 0.63805072, Validation loss: 0.62852214, Gradient norm: 0.05486644
INFO:root:At the start of the epoch: mem (CPU python)=29338.4453125MB; mem (CPU total)=48834.2890625MB
INFO:root:[   42] Training loss: 0.63767514, Validation loss: 0.62641288, Gradient norm: 0.05569861
INFO:root:At the start of the epoch: mem (CPU python)=29376.54296875MB; mem (CPU total)=48913.77734375MB
INFO:root:[   43] Training loss: 0.63717705, Validation loss: 0.62719355, Gradient norm: 0.05092631
INFO:root:At the start of the epoch: mem (CPU python)=29414.63671875MB; mem (CPU total)=48993.7578125MB
INFO:root:[   44] Training loss: 0.63656565, Validation loss: 0.62549937, Gradient norm: 0.05665631
INFO:root:At the start of the epoch: mem (CPU python)=29452.734375MB; mem (CPU total)=49074.10546875MB
INFO:root:[   45] Training loss: 0.63632566, Validation loss: 0.62445204, Gradient norm: 0.06014670
INFO:root:At the start of the epoch: mem (CPU python)=29490.828125MB; mem (CPU total)=49124.08203125MB
INFO:root:[   46] Training loss: 0.63547054, Validation loss: 0.62440020, Gradient norm: 0.05038637
INFO:root:At the start of the epoch: mem (CPU python)=29528.921875MB; mem (CPU total)=49173.81640625MB
INFO:root:[   47] Training loss: 0.63472365, Validation loss: 0.62392063, Gradient norm: 0.05176778
INFO:root:At the start of the epoch: mem (CPU python)=29567.01953125MB; mem (CPU total)=49223.56640625MB
INFO:root:[   48] Training loss: 0.63442904, Validation loss: 0.62438970, Gradient norm: 0.05758764
INFO:root:At the start of the epoch: mem (CPU python)=29605.11328125MB; mem (CPU total)=49270.08203125MB
INFO:root:[   49] Training loss: 0.63405669, Validation loss: 0.62266650, Gradient norm: 0.05726311
INFO:root:At the start of the epoch: mem (CPU python)=29643.20703125MB; mem (CPU total)=49346.4296875MB
INFO:root:[   50] Training loss: 0.63343741, Validation loss: 0.62317050, Gradient norm: 0.04861860
INFO:root:At the start of the epoch: mem (CPU python)=29681.3046875MB; mem (CPU total)=49423.234375MB
INFO:root:[   51] Training loss: 0.63315891, Validation loss: 0.62301678, Gradient norm: 0.05561658
INFO:root:At the start of the epoch: mem (CPU python)=29719.40234375MB; mem (CPU total)=49499.58203125MB
INFO:root:[   52] Training loss: 0.63295121, Validation loss: 0.62105144, Gradient norm: 0.05711842
INFO:root:At the start of the epoch: mem (CPU python)=29757.49609375MB; mem (CPU total)=49575.640625MB
INFO:root:[   53] Training loss: 0.63220007, Validation loss: 0.62194550, Gradient norm: 0.05614077
INFO:root:At the start of the epoch: mem (CPU python)=29795.58984375MB; mem (CPU total)=49652.4453125MB
INFO:root:[   54] Training loss: 0.63182278, Validation loss: 0.62145700, Gradient norm: 0.05772923
INFO:root:At the start of the epoch: mem (CPU python)=29833.6875MB; mem (CPU total)=49729.0MB
INFO:root:[   55] Training loss: 0.63158396, Validation loss: 0.62047186, Gradient norm: 0.06484099
INFO:root:At the start of the epoch: mem (CPU python)=29871.78125MB; mem (CPU total)=49804.62890625MB
INFO:root:[   56] Training loss: 0.63129756, Validation loss: 0.62168175, Gradient norm: 0.05997968
INFO:root:At the start of the epoch: mem (CPU python)=29909.875MB; mem (CPU total)=49883.55078125MB
INFO:root:[   57] Training loss: 0.63080394, Validation loss: 0.62095628, Gradient norm: 0.05611577
INFO:root:At the start of the epoch: mem (CPU python)=29947.9765625MB; mem (CPU total)=49962.93359375MB
INFO:root:[   58] Training loss: 0.63033933, Validation loss: 0.61971859, Gradient norm: 0.05320373
INFO:root:At the start of the epoch: mem (CPU python)=29986.0703125MB; mem (CPU total)=50041.9375MB
INFO:root:[   59] Training loss: 0.62998703, Validation loss: 0.61946365, Gradient norm: 0.05401732
INFO:root:At the start of the epoch: mem (CPU python)=30024.1640625MB; mem (CPU total)=50121.6484375MB
INFO:root:[   60] Training loss: 0.62955727, Validation loss: 0.61949646, Gradient norm: 0.05573233
INFO:root:At the start of the epoch: mem (CPU python)=30062.2578125MB; mem (CPU total)=50200.421875MB
INFO:root:[   61] Training loss: 0.62919853, Validation loss: 0.61862876, Gradient norm: 0.06319244
INFO:root:At the start of the epoch: mem (CPU python)=30100.35546875MB; mem (CPU total)=50279.9140625MB
INFO:root:[   62] Training loss: 0.62897971, Validation loss: 0.61907509, Gradient norm: 0.06161076
INFO:root:At the start of the epoch: mem (CPU python)=30138.44921875MB; mem (CPU total)=50359.15234375MB
INFO:root:[   63] Training loss: 0.62863511, Validation loss: 0.61857723, Gradient norm: 0.05473587
INFO:root:At the start of the epoch: mem (CPU python)=30176.54296875MB; mem (CPU total)=50438.6640625MB
INFO:root:[   64] Training loss: 0.62829607, Validation loss: 0.61750190, Gradient norm: 0.05982087
INFO:root:At the start of the epoch: mem (CPU python)=30214.640625MB; mem (CPU total)=50518.80859375MB
INFO:root:[   65] Training loss: 0.62807708, Validation loss: 0.61763860, Gradient norm: 0.05913866
INFO:root:At the start of the epoch: mem (CPU python)=30252.734375MB; mem (CPU total)=50597.828125MB
INFO:root:[   66] Training loss: 0.62768275, Validation loss: 0.61723694, Gradient norm: 0.05969341
INFO:root:At the start of the epoch: mem (CPU python)=30290.83203125MB; mem (CPU total)=50678.1875MB
INFO:root:[   67] Training loss: 0.62718757, Validation loss: 0.61797867, Gradient norm: 0.05204685
INFO:root:At the start of the epoch: mem (CPU python)=30328.92578125MB; mem (CPU total)=50758.68359375MB
INFO:root:[   68] Training loss: 0.62703566, Validation loss: 0.61718226, Gradient norm: 0.06342106
INFO:root:At the start of the epoch: mem (CPU python)=30367.0234375MB; mem (CPU total)=50835.8515625MB
INFO:root:[   69] Training loss: 0.62663769, Validation loss: 0.61797713, Gradient norm: 0.05958208
INFO:root:At the start of the epoch: mem (CPU python)=30405.1171875MB; mem (CPU total)=50911.921875MB
INFO:root:[   70] Training loss: 0.62619892, Validation loss: 0.61683445, Gradient norm: 0.05367103
INFO:root:At the start of the epoch: mem (CPU python)=30443.2109375MB; mem (CPU total)=50988.4140625MB
INFO:root:[   71] Training loss: 0.62617743, Validation loss: 0.61616018, Gradient norm: 0.06078415
INFO:root:At the start of the epoch: mem (CPU python)=30481.30859375MB; mem (CPU total)=51065.3828125MB
INFO:root:[   72] Training loss: 0.62575263, Validation loss: 0.61585762, Gradient norm: 0.06476307
INFO:root:At the start of the epoch: mem (CPU python)=30519.40234375MB; mem (CPU total)=51141.3046875MB
INFO:root:[   73] Training loss: 0.62555383, Validation loss: 0.61552118, Gradient norm: 0.06094881
INFO:root:At the start of the epoch: mem (CPU python)=30557.49609375MB; mem (CPU total)=51218.6015625MB
INFO:root:[   74] Training loss: 0.62533022, Validation loss: 0.61529235, Gradient norm: 0.06981392
INFO:root:At the start of the epoch: mem (CPU python)=30595.59765625MB; mem (CPU total)=51294.90625MB
INFO:root:[   75] Training loss: 0.62504632, Validation loss: 0.61544671, Gradient norm: 0.05652317
INFO:root:At the start of the epoch: mem (CPU python)=30633.69140625MB; mem (CPU total)=51375.1875MB
INFO:root:[   76] Training loss: 0.62497218, Validation loss: 0.61516217, Gradient norm: 0.05950896
INFO:root:At the start of the epoch: mem (CPU python)=30671.78515625MB; mem (CPU total)=51454.9453125MB
INFO:root:[   77] Training loss: 0.62432920, Validation loss: 0.61465711, Gradient norm: 0.06459173
INFO:root:At the start of the epoch: mem (CPU python)=30709.87890625MB; mem (CPU total)=51534.703125MB
INFO:root:[   78] Training loss: 0.62440371, Validation loss: 0.61532976, Gradient norm: 0.06210434
INFO:root:At the start of the epoch: mem (CPU python)=30747.9765625MB; mem (CPU total)=51614.46484375MB
INFO:root:[   79] Training loss: 0.62398447, Validation loss: 0.61374747, Gradient norm: 0.05618489
INFO:root:At the start of the epoch: mem (CPU python)=30786.0703125MB; mem (CPU total)=51694.71484375MB
INFO:root:[   80] Training loss: 0.62382810, Validation loss: 0.61335779, Gradient norm: 0.06168762
INFO:root:At the start of the epoch: mem (CPU python)=30824.1640625MB; mem (CPU total)=51774.23046875MB
INFO:root:[   81] Training loss: 0.62349428, Validation loss: 0.61412642, Gradient norm: 0.05532422
INFO:root:At the start of the epoch: mem (CPU python)=30862.26171875MB; mem (CPU total)=51854.48046875MB
INFO:root:[   82] Training loss: 0.62321709, Validation loss: 0.61387759, Gradient norm: 0.05492955
INFO:root:At the start of the epoch: mem (CPU python)=30900.359375MB; mem (CPU total)=51933.98046875MB
INFO:root:[   83] Training loss: 0.62285141, Validation loss: 0.61406978, Gradient norm: 0.06073701
INFO:root:At the start of the epoch: mem (CPU python)=30938.453125MB; mem (CPU total)=52013.5MB
INFO:root:[   84] Training loss: 0.62282598, Validation loss: 0.61337851, Gradient norm: 0.06590402
INFO:root:At the start of the epoch: mem (CPU python)=30976.546875MB; mem (CPU total)=52093.8203125MB
INFO:root:[   85] Training loss: 0.62256192, Validation loss: 0.61400918, Gradient norm: 0.06008493
INFO:root:At the start of the epoch: mem (CPU python)=31014.64453125MB; mem (CPU total)=52171.98046875MB
INFO:root:[   86] Training loss: 0.62240848, Validation loss: 0.61422836, Gradient norm: 0.06599910
INFO:root:At the start of the epoch: mem (CPU python)=31052.7421875MB; mem (CPU total)=52248.27734375MB
INFO:root:[   87] Training loss: 0.62230491, Validation loss: 0.61320346, Gradient norm: 0.06562899
INFO:root:At the start of the epoch: mem (CPU python)=31090.8359375MB; mem (CPU total)=52324.5546875MB
INFO:root:[   88] Training loss: 0.62183433, Validation loss: 0.61330451, Gradient norm: 0.05894552
INFO:root:At the start of the epoch: mem (CPU python)=31128.93359375MB; mem (CPU total)=52401.0859375MB
INFO:root:[   89] Training loss: 0.62136094, Validation loss: 0.61263448, Gradient norm: 0.05844589
INFO:root:At the start of the epoch: mem (CPU python)=31167.02734375MB; mem (CPU total)=52477.31640625MB
INFO:root:[   90] Training loss: 0.62134934, Validation loss: 0.61375337, Gradient norm: 0.05612347
INFO:root:At the start of the epoch: mem (CPU python)=31205.12109375MB; mem (CPU total)=52553.31640625MB
INFO:root:[   91] Training loss: 0.62111018, Validation loss: 0.61264290, Gradient norm: 0.06483034
INFO:root:At the start of the epoch: mem (CPU python)=31243.22265625MB; mem (CPU total)=52631.1171875MB
INFO:root:[   92] Training loss: 0.62100076, Validation loss: 0.61486848, Gradient norm: 0.06502570
INFO:root:At the start of the epoch: mem (CPU python)=31281.31640625MB; mem (CPU total)=52710.86328125MB
INFO:root:[   93] Training loss: 0.62085848, Validation loss: 0.61132911, Gradient norm: 0.06335220
INFO:root:At the start of the epoch: mem (CPU python)=31319.41015625MB; mem (CPU total)=52791.390625MB
INFO:root:[   94] Training loss: 0.62056194, Validation loss: 0.61171166, Gradient norm: 0.06273337
INFO:root:At the start of the epoch: mem (CPU python)=31357.50390625MB; mem (CPU total)=52871.57421875MB
INFO:root:[   95] Training loss: 0.62039936, Validation loss: 0.61183671, Gradient norm: 0.05922702
INFO:root:At the start of the epoch: mem (CPU python)=31395.60546875MB; mem (CPU total)=52951.08984375MB
INFO:root:[   96] Training loss: 0.62021800, Validation loss: 0.61187335, Gradient norm: 0.06774032
INFO:root:At the start of the epoch: mem (CPU python)=31433.69921875MB; mem (CPU total)=53031.09375MB
INFO:root:[   97] Training loss: 0.61990105, Validation loss: 0.61194806, Gradient norm: 0.05796001
INFO:root:At the start of the epoch: mem (CPU python)=31471.796875MB; mem (CPU total)=53111.0703125MB
INFO:root:[   98] Training loss: 0.61948178, Validation loss: 0.61051445, Gradient norm: 0.05842827
INFO:root:At the start of the epoch: mem (CPU python)=31509.89453125MB; mem (CPU total)=53191.7734375MB
INFO:root:[   99] Training loss: 0.61941518, Validation loss: 0.61186778, Gradient norm: 0.06045838
INFO:root:At the start of the epoch: mem (CPU python)=31547.984375MB; mem (CPU total)=53271.96484375MB
INFO:root:[  100] Training loss: 0.61938615, Validation loss: 0.61179869, Gradient norm: 0.06071392
INFO:root:At the start of the epoch: mem (CPU python)=31586.08203125MB; mem (CPU total)=53352.484375MB
INFO:root:[  101] Training loss: 0.61900342, Validation loss: 0.61166277, Gradient norm: 0.06341646
INFO:root:At the start of the epoch: mem (CPU python)=31624.17578125MB; mem (CPU total)=53432.23828125MB
INFO:root:[  102] Training loss: 0.61888492, Validation loss: 0.61089208, Gradient norm: 0.06460290
INFO:root:At the start of the epoch: mem (CPU python)=31662.2734375MB; mem (CPU total)=53508.03515625MB
INFO:root:[  103] Training loss: 0.61880763, Validation loss: 0.61076455, Gradient norm: 0.06150601
INFO:root:At the start of the epoch: mem (CPU python)=31700.3671875MB; mem (CPU total)=53584.20703125MB
INFO:root:[  104] Training loss: 0.61843889, Validation loss: 0.61037455, Gradient norm: 0.06372755
INFO:root:At the start of the epoch: mem (CPU python)=31738.4609375MB; mem (CPU total)=53661.01953125MB
INFO:root:[  105] Training loss: 0.61832914, Validation loss: 0.60943645, Gradient norm: 0.05939829
INFO:root:At the start of the epoch: mem (CPU python)=31776.55859375MB; mem (CPU total)=53736.9453125MB
INFO:root:[  106] Training loss: 0.61817248, Validation loss: 0.61101676, Gradient norm: 0.06760916
INFO:root:At the start of the epoch: mem (CPU python)=31814.65234375MB; mem (CPU total)=53813.26171875MB
INFO:root:[  107] Training loss: 0.61810048, Validation loss: 0.61033680, Gradient norm: 0.06674483
INFO:root:At the start of the epoch: mem (CPU python)=31852.74609375MB; mem (CPU total)=53891.79296875MB
INFO:root:[  108] Training loss: 0.61766530, Validation loss: 0.61023835, Gradient norm: 0.05945625
INFO:root:At the start of the epoch: mem (CPU python)=31890.84765625MB; mem (CPU total)=53971.765625MB
INFO:root:[  109] Training loss: 0.61759966, Validation loss: 0.61094139, Gradient norm: 0.06522252
INFO:root:At the start of the epoch: mem (CPU python)=31928.94140625MB; mem (CPU total)=54051.67578125MB
INFO:root:[  110] Training loss: 0.61734014, Validation loss: 0.61034972, Gradient norm: 0.06196675
INFO:root:At the start of the epoch: mem (CPU python)=31967.03515625MB; mem (CPU total)=54132.23828125MB
INFO:root:[  111] Training loss: 0.61736399, Validation loss: 0.60940651, Gradient norm: 0.06738836
INFO:root:At the start of the epoch: mem (CPU python)=32005.12890625MB; mem (CPU total)=54212.375MB
INFO:root:[  112] Training loss: 0.61700272, Validation loss: 0.60889983, Gradient norm: 0.06035198
INFO:root:At the start of the epoch: mem (CPU python)=32043.2265625MB; mem (CPU total)=54292.60546875MB
INFO:root:[  113] Training loss: 0.61701484, Validation loss: 0.60913782, Gradient norm: 0.06310818
INFO:root:At the start of the epoch: mem (CPU python)=32081.3203125MB; mem (CPU total)=54373.52734375MB
INFO:root:[  114] Training loss: 0.61694272, Validation loss: 0.60831441, Gradient norm: 0.05906963
INFO:root:At the start of the epoch: mem (CPU python)=32119.4140625MB; mem (CPU total)=54453.59375MB
INFO:root:[  115] Training loss: 0.61653099, Validation loss: 0.60868428, Gradient norm: 0.06387031
INFO:root:At the start of the epoch: mem (CPU python)=32157.51171875MB; mem (CPU total)=54534.5546875MB
INFO:root:[  116] Training loss: 0.61653179, Validation loss: 0.60961303, Gradient norm: 0.06766239
INFO:root:At the start of the epoch: mem (CPU python)=32195.609375MB; mem (CPU total)=54615.3515625MB
INFO:root:[  117] Training loss: 0.61625484, Validation loss: 0.60785244, Gradient norm: 0.06359971
INFO:root:At the start of the epoch: mem (CPU python)=32233.703125MB; mem (CPU total)=54690.8046875MB
INFO:root:[  118] Training loss: 0.61619130, Validation loss: 0.60781936, Gradient norm: 0.06740296
INFO:root:At the start of the epoch: mem (CPU python)=32271.796875MB; mem (CPU total)=54767.4296875MB
INFO:root:[  119] Training loss: 0.61619376, Validation loss: 0.60835068, Gradient norm: 0.06668747
INFO:root:At the start of the epoch: mem (CPU python)=32309.89453125MB; mem (CPU total)=54843.73828125MB
INFO:root:[  120] Training loss: 0.61591934, Validation loss: 0.60834932, Gradient norm: 0.06180695
INFO:root:At the start of the epoch: mem (CPU python)=32347.98828125MB; mem (CPU total)=54920.05859375MB
INFO:root:[  121] Training loss: 0.61586823, Validation loss: 0.60856415, Gradient norm: 0.07602124
INFO:root:At the start of the epoch: mem (CPU python)=32386.08203125MB; mem (CPU total)=54996.65234375MB
INFO:root:[  122] Training loss: 0.61548647, Validation loss: 0.60822403, Gradient norm: 0.06530293
INFO:root:At the start of the epoch: mem (CPU python)=32424.1796875MB; mem (CPU total)=55075.078125MB
INFO:root:[  123] Training loss: 0.61559108, Validation loss: 0.60917920, Gradient norm: 0.06170802
INFO:root:At the start of the epoch: mem (CPU python)=32462.2734375MB; mem (CPU total)=55155.84765625MB
INFO:root:[  124] Training loss: 0.61510411, Validation loss: 0.60797439, Gradient norm: 0.06205581
INFO:root:At the start of the epoch: mem (CPU python)=32500.37109375MB; mem (CPU total)=55236.34765625MB
INFO:root:[  125] Training loss: 0.61512032, Validation loss: 0.60774175, Gradient norm: 0.06727578
INFO:root:At the start of the epoch: mem (CPU python)=32538.46875MB; mem (CPU total)=55316.484375MB
INFO:root:[  126] Training loss: 0.61471902, Validation loss: 0.60846590, Gradient norm: 0.06576171
INFO:root:At the start of the epoch: mem (CPU python)=32576.5625MB; mem (CPU total)=55397.21875MB
INFO:root:[  127] Training loss: 0.61483302, Validation loss: 0.60715366, Gradient norm: 0.06483616
INFO:root:At the start of the epoch: mem (CPU python)=32614.65625MB; mem (CPU total)=55477.47265625MB
INFO:root:[  128] Training loss: 0.61456580, Validation loss: 0.60810566, Gradient norm: 0.06724232
INFO:root:At the start of the epoch: mem (CPU python)=32652.75390625MB; mem (CPU total)=55558.2578125MB
INFO:root:[  129] Training loss: 0.61459800, Validation loss: 0.60868465, Gradient norm: 0.07646807
INFO:root:At the start of the epoch: mem (CPU python)=32690.8515625MB; mem (CPU total)=55639.93359375MB
INFO:root:[  130] Training loss: 0.61445094, Validation loss: 0.60795010, Gradient norm: 0.06712224
INFO:root:At the start of the epoch: mem (CPU python)=32728.9453125MB; mem (CPU total)=55721.65625MB
INFO:root:[  131] Training loss: 0.61409287, Validation loss: 0.61029104, Gradient norm: 0.06180916
INFO:root:At the start of the epoch: mem (CPU python)=32767.0390625MB; mem (CPU total)=55797.7265625MB
INFO:root:[  132] Training loss: 0.61391464, Validation loss: 0.60687086, Gradient norm: 0.06677808
INFO:root:At the start of the epoch: mem (CPU python)=32805.13671875MB; mem (CPU total)=55874.3046875MB
INFO:root:[  133] Training loss: 0.61400080, Validation loss: 0.60725350, Gradient norm: 0.06894437
INFO:root:At the start of the epoch: mem (CPU python)=32843.23046875MB; mem (CPU total)=55951.171875MB
INFO:root:[  134] Training loss: 0.61364660, Validation loss: 0.60787349, Gradient norm: 0.06931977
INFO:root:At the start of the epoch: mem (CPU python)=32881.328125MB; mem (CPU total)=56027.71875MB
INFO:root:[  135] Training loss: 0.61323353, Validation loss: 0.60730406, Gradient norm: 0.06245544
INFO:root:At the start of the epoch: mem (CPU python)=32919.421875MB; mem (CPU total)=56103.78125MB
INFO:root:[  136] Training loss: 0.61325086, Validation loss: 0.60666584, Gradient norm: 0.06708196
INFO:root:At the start of the epoch: mem (CPU python)=32957.51953125MB; mem (CPU total)=56182.58984375MB
INFO:root:[  137] Training loss: 0.61349361, Validation loss: 0.60790030, Gradient norm: 0.07183203
INFO:root:At the start of the epoch: mem (CPU python)=32995.61328125MB; mem (CPU total)=56264.37890625MB
INFO:root:[  138] Training loss: 0.61294739, Validation loss: 0.60797457, Gradient norm: 0.06361065
INFO:root:At the start of the epoch: mem (CPU python)=33033.70703125MB; mem (CPU total)=56345.0703125MB
INFO:root:[  139] Training loss: 0.61301244, Validation loss: 0.60739586, Gradient norm: 0.07251393
INFO:root:At the start of the epoch: mem (CPU python)=33071.8046875MB; mem (CPU total)=56426.05859375MB
INFO:root:[  140] Training loss: 0.61294088, Validation loss: 0.60568251, Gradient norm: 0.07310756
INFO:root:At the start of the epoch: mem (CPU python)=33109.90234375MB; mem (CPU total)=56506.97265625MB
INFO:root:[  141] Training loss: 0.61287648, Validation loss: 0.60600395, Gradient norm: 0.06882964
INFO:root:At the start of the epoch: mem (CPU python)=33147.9921875MB; mem (CPU total)=56588.0078125MB
INFO:root:[  142] Training loss: 0.61282828, Validation loss: 0.60696872, Gradient norm: 0.07340515
INFO:root:At the start of the epoch: mem (CPU python)=33186.09375MB; mem (CPU total)=56668.75390625MB
INFO:root:[  143] Training loss: 0.61220873, Validation loss: 0.60621570, Gradient norm: 0.06326321
INFO:root:At the start of the epoch: mem (CPU python)=33224.1875MB; mem (CPU total)=56751.1796875MB
INFO:root:[  144] Training loss: 0.61227829, Validation loss: 0.60599021, Gradient norm: 0.06629451
INFO:root:At the start of the epoch: mem (CPU python)=33262.28125MB; mem (CPU total)=56830.3828125MB
INFO:root:[  145] Training loss: 0.61220727, Validation loss: 0.60607455, Gradient norm: 0.06755394
INFO:root:At the start of the epoch: mem (CPU python)=33300.375MB; mem (CPU total)=56906.1796875MB
INFO:root:[  146] Training loss: 0.61189270, Validation loss: 0.60768420, Gradient norm: 0.06582457
INFO:root:At the start of the epoch: mem (CPU python)=33338.47265625MB; mem (CPU total)=56982.13671875MB
INFO:root:[  147] Training loss: 0.61226345, Validation loss: 0.60548632, Gradient norm: 0.07661590
INFO:root:At the start of the epoch: mem (CPU python)=33376.56640625MB; mem (CPU total)=57058.76171875MB
INFO:root:[  148] Training loss: 0.61184470, Validation loss: 0.60561827, Gradient norm: 0.07097491
INFO:root:At the start of the epoch: mem (CPU python)=33414.66015625MB; mem (CPU total)=57135.18359375MB
INFO:root:[  149] Training loss: 0.61191527, Validation loss: 0.60633370, Gradient norm: 0.06764707
INFO:root:At the start of the epoch: mem (CPU python)=33452.7578125MB; mem (CPU total)=57212.55078125MB
INFO:root:[  150] Training loss: 0.61157753, Validation loss: 0.60586277, Gradient norm: 0.07284792
INFO:root:At the start of the epoch: mem (CPU python)=33490.85546875MB; mem (CPU total)=57294.00390625MB
INFO:root:[  151] Training loss: 0.61159812, Validation loss: 0.60534993, Gradient norm: 0.07013625
INFO:root:At the start of the epoch: mem (CPU python)=33528.94921875MB; mem (CPU total)=57374.72265625MB
INFO:root:[  152] Training loss: 0.61162113, Validation loss: 0.60618569, Gradient norm: 0.06988524
INFO:root:At the start of the epoch: mem (CPU python)=33567.04296875MB; mem (CPU total)=57455.1875MB
INFO:root:[  153] Training loss: 0.61120416, Validation loss: 0.60526532, Gradient norm: 0.06382596
INFO:root:At the start of the epoch: mem (CPU python)=33605.140625MB; mem (CPU total)=57536.33984375MB
INFO:root:[  154] Training loss: 0.61119288, Validation loss: 0.60542750, Gradient norm: 0.06445040
INFO:root:At the start of the epoch: mem (CPU python)=33643.234375MB; mem (CPU total)=57617.12109375MB
INFO:root:[  155] Training loss: 0.61099124, Validation loss: 0.60618261, Gradient norm: 0.06732980
INFO:root:At the start of the epoch: mem (CPU python)=33681.328125MB; mem (CPU total)=57697.5MB
INFO:root:[  156] Training loss: 0.61101116, Validation loss: 0.60551274, Gradient norm: 0.06739390
INFO:root:At the start of the epoch: mem (CPU python)=33719.42578125MB; mem (CPU total)=57779.6328125MB
INFO:root:[  157] Training loss: 0.61084745, Validation loss: 0.60628451, Gradient norm: 0.07056780
INFO:root:At the start of the epoch: mem (CPU python)=33757.5234375MB; mem (CPU total)=57860.03515625MB
INFO:root:[  158] Training loss: 0.61074100, Validation loss: 0.60693778, Gradient norm: 0.06798313
INFO:root:At the start of the epoch: mem (CPU python)=33795.6171875MB; mem (CPU total)=57936.35546875MB
INFO:root:[  159] Training loss: 0.61078632, Validation loss: 0.60634846, Gradient norm: 0.07270581
INFO:root:At the start of the epoch: mem (CPU python)=33833.71484375MB; mem (CPU total)=58012.4609375MB
INFO:root:[  160] Training loss: 0.61011479, Validation loss: 0.60717179, Gradient norm: 0.06828045
INFO:root:At the start of the epoch: mem (CPU python)=33871.80859375MB; mem (CPU total)=58088.25MB
INFO:root:[  161] Training loss: 0.61043530, Validation loss: 0.60539823, Gradient norm: 0.06581991
INFO:root:At the start of the epoch: mem (CPU python)=33909.90234375MB; mem (CPU total)=58164.66015625MB
INFO:root:[  162] Training loss: 0.61046101, Validation loss: 0.60579297, Gradient norm: 0.07438751
INFO:root:At the start of the epoch: mem (CPU python)=33947.99609375MB; mem (CPU total)=58240.703125MB
INFO:root:EP 162: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=33985.921875MB; mem (CPU total)=58308.5703125MB
INFO:root:Training the model took 10839.104s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83711
INFO:root:EnergyScoreTrain: 0.58923
INFO:root:CRPSTrain: 0.45917
INFO:root:Gaussian NLLTrain: 1.19421
INFO:root:CoverageTrain: 0.9418
INFO:root:IntervalWidthTrain: 3.20585
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86036
INFO:root:EnergyScoreValidation: 0.60559
INFO:root:CRPSValidation: 0.47296
INFO:root:Gaussian NLLValidation: 1.22524
INFO:root:CoverageValidation: 0.93425
INFO:root:IntervalWidthValidation: 3.21023
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86112
INFO:root:EnergyScoreTest: 0.60612
INFO:root:CRPSTest: 0.47339
INFO:root:Gaussian NLLTest: 1.22595
INFO:root:CoverageTest: 0.93379
INFO:root:IntervalWidthTest: 3.20999
INFO:root:After validation: mem (CPU python)=34041.140625MB; mem (CPU total)=58385.00390625MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=34041.140625MB; mem (CPU total)=58404.69140625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=34041.140625MB; mem (CPU total)=58405.671875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=34041.140625MB; mem (CPU total)=58423.63671875MB
INFO:root:[    1] Training loss: 0.72562069, Validation loss: 0.72042672, Gradient norm: 0.02307942
INFO:root:At the start of the epoch: mem (CPU python)=34053.77734375MB; mem (CPU total)=58499.79296875MB
INFO:root:[    2] Training loss: 0.72013808, Validation loss: 0.71848786, Gradient norm: 0.00688018
INFO:root:At the start of the epoch: mem (CPU python)=34091.87890625MB; mem (CPU total)=58577.34375MB
INFO:root:[    3] Training loss: 0.71847022, Validation loss: 0.71622927, Gradient norm: 0.00789049
INFO:root:At the start of the epoch: mem (CPU python)=34129.97265625MB; mem (CPU total)=58659.046875MB
INFO:root:[    4] Training loss: 0.71341468, Validation loss: 0.70842997, Gradient norm: 0.01679677
INFO:root:At the start of the epoch: mem (CPU python)=34168.0703125MB; mem (CPU total)=58740.2421875MB
INFO:root:[    5] Training loss: 0.70781788, Validation loss: 0.70190260, Gradient norm: 0.02652803
INFO:root:At the start of the epoch: mem (CPU python)=34206.1640625MB; mem (CPU total)=58820.61328125MB
INFO:root:[    6] Training loss: 0.70278761, Validation loss: 0.69689425, Gradient norm: 0.02914372
INFO:root:At the start of the epoch: mem (CPU python)=34244.2578125MB; mem (CPU total)=58900.1015625MB
INFO:root:[    7] Training loss: 0.69821994, Validation loss: 0.69189206, Gradient norm: 0.02852714
INFO:root:At the start of the epoch: mem (CPU python)=34282.35546875MB; mem (CPU total)=58981.12109375MB
INFO:root:[    8] Training loss: 0.69437215, Validation loss: 0.68798471, Gradient norm: 0.03469983
INFO:root:At the start of the epoch: mem (CPU python)=34320.44921875MB; mem (CPU total)=59061.8359375MB
INFO:root:[    9] Training loss: 0.69008557, Validation loss: 0.68321549, Gradient norm: 0.03373433
INFO:root:At the start of the epoch: mem (CPU python)=34358.54296875MB; mem (CPU total)=59142.8828125MB
INFO:root:[   10] Training loss: 0.68666892, Validation loss: 0.68003360, Gradient norm: 0.03489870
INFO:root:At the start of the epoch: mem (CPU python)=34396.640625MB; mem (CPU total)=59225.078125MB
INFO:root:[   11] Training loss: 0.68306209, Validation loss: 0.67508334, Gradient norm: 0.03408935
INFO:root:At the start of the epoch: mem (CPU python)=34434.73828125MB; mem (CPU total)=59301.3203125MB
INFO:root:[   12] Training loss: 0.68041816, Validation loss: 0.67184405, Gradient norm: 0.03709551
INFO:root:At the start of the epoch: mem (CPU python)=34472.83203125MB; mem (CPU total)=59377.88671875MB
INFO:root:[   13] Training loss: 0.67748543, Validation loss: 0.66950043, Gradient norm: 0.03741673
INFO:root:At the start of the epoch: mem (CPU python)=34510.92578125MB; mem (CPU total)=59454.4140625MB
INFO:root:[   14] Training loss: 0.67498680, Validation loss: 0.66721367, Gradient norm: 0.03752624
INFO:root:At the start of the epoch: mem (CPU python)=34549.0234375MB; mem (CPU total)=59530.43359375MB
INFO:root:[   15] Training loss: 0.67244126, Validation loss: 0.66362973, Gradient norm: 0.03703014
INFO:root:At the start of the epoch: mem (CPU python)=34587.1171875MB; mem (CPU total)=59606.86328125MB
INFO:root:[   16] Training loss: 0.67050709, Validation loss: 0.66232915, Gradient norm: 0.03760345
INFO:root:At the start of the epoch: mem (CPU python)=34625.2109375MB; mem (CPU total)=59688.17578125MB
INFO:root:[   17] Training loss: 0.66879872, Validation loss: 0.65916625, Gradient norm: 0.03973301
INFO:root:At the start of the epoch: mem (CPU python)=34663.3125MB; mem (CPU total)=59739.3515625MB
INFO:root:[   18] Training loss: 0.66658186, Validation loss: 0.65693813, Gradient norm: 0.03945921
INFO:root:At the start of the epoch: mem (CPU python)=34701.40234375MB; mem (CPU total)=59790.29296875MB
INFO:root:[   19] Training loss: 0.66467943, Validation loss: 0.65438990, Gradient norm: 0.03945371
INFO:root:At the start of the epoch: mem (CPU python)=34739.5MB; mem (CPU total)=59840.953125MB
INFO:root:[   20] Training loss: 0.66294911, Validation loss: 0.65262796, Gradient norm: 0.04117146
INFO:root:At the start of the epoch: mem (CPU python)=34777.59375MB; mem (CPU total)=59900.53515625MB
INFO:root:[   21] Training loss: 0.66139099, Validation loss: 0.65070217, Gradient norm: 0.04488077
INFO:root:At the start of the epoch: mem (CPU python)=34815.69140625MB; mem (CPU total)=59981.265625MB
INFO:root:[   22] Training loss: 0.65956661, Validation loss: 0.64903277, Gradient norm: 0.03991071
INFO:root:At the start of the epoch: mem (CPU python)=34853.78515625MB; mem (CPU total)=60061.81640625MB
INFO:root:[   23] Training loss: 0.65785455, Validation loss: 0.64800292, Gradient norm: 0.04322166
INFO:root:At the start of the epoch: mem (CPU python)=34891.87890625MB; mem (CPU total)=60143.69921875MB
INFO:root:[   24] Training loss: 0.65658443, Validation loss: 0.64537934, Gradient norm: 0.04237860
INFO:root:At the start of the epoch: mem (CPU python)=34929.9765625MB; mem (CPU total)=60222.43359375MB
INFO:root:[   25] Training loss: 0.65509459, Validation loss: 0.64508036, Gradient norm: 0.04771671
INFO:root:At the start of the epoch: mem (CPU python)=34968.07421875MB; mem (CPU total)=60298.22265625MB
INFO:root:[   26] Training loss: 0.65405777, Validation loss: 0.64359146, Gradient norm: 0.04963956
INFO:root:At the start of the epoch: mem (CPU python)=35006.16796875MB; mem (CPU total)=60374.51171875MB
INFO:root:[   27] Training loss: 0.65270444, Validation loss: 0.64145708, Gradient norm: 0.04384450
INFO:root:At the start of the epoch: mem (CPU python)=35044.26171875MB; mem (CPU total)=60450.5546875MB
INFO:root:[   28] Training loss: 0.65149565, Validation loss: 0.64030848, Gradient norm: 0.04466930
INFO:root:At the start of the epoch: mem (CPU python)=35082.359375MB; mem (CPU total)=60526.83984375MB
INFO:root:[   29] Training loss: 0.65047579, Validation loss: 0.63929074, Gradient norm: 0.04649668
INFO:root:At the start of the epoch: mem (CPU python)=35120.453125MB; mem (CPU total)=60608.31640625MB
INFO:root:[   30] Training loss: 0.64955174, Validation loss: 0.63821855, Gradient norm: 0.04766647
INFO:root:At the start of the epoch: mem (CPU python)=35158.546875MB; mem (CPU total)=60690.43359375MB
INFO:root:[   31] Training loss: 0.64842888, Validation loss: 0.63736104, Gradient norm: 0.04915112
INFO:root:At the start of the epoch: mem (CPU python)=35196.64453125MB; mem (CPU total)=60771.83984375MB
INFO:root:[   32] Training loss: 0.64773892, Validation loss: 0.63616187, Gradient norm: 0.05088941
INFO:root:At the start of the epoch: mem (CPU python)=35234.73828125MB; mem (CPU total)=60853.16796875MB
INFO:root:[   33] Training loss: 0.64663358, Validation loss: 0.63555359, Gradient norm: 0.04937897
INFO:root:At the start of the epoch: mem (CPU python)=35272.83203125MB; mem (CPU total)=60935.34765625MB
INFO:root:[   34] Training loss: 0.64604917, Validation loss: 0.63509509, Gradient norm: 0.04952338
INFO:root:At the start of the epoch: mem (CPU python)=35310.9375MB; mem (CPU total)=61017.78125MB
INFO:root:[   35] Training loss: 0.64504626, Validation loss: 0.63349417, Gradient norm: 0.04869905
INFO:root:At the start of the epoch: mem (CPU python)=35349.03125MB; mem (CPU total)=61099.4140625MB
INFO:root:[   36] Training loss: 0.64441908, Validation loss: 0.63325857, Gradient norm: 0.05413002
INFO:root:At the start of the epoch: mem (CPU python)=35387.125MB; mem (CPU total)=61175.69140625MB
INFO:root:[   37] Training loss: 0.64365151, Validation loss: 0.63277326, Gradient norm: 0.05068762
INFO:root:At the start of the epoch: mem (CPU python)=35425.21875MB; mem (CPU total)=61251.94921875MB
INFO:root:[   38] Training loss: 0.64307172, Validation loss: 0.63259091, Gradient norm: 0.04998114
INFO:root:At the start of the epoch: mem (CPU python)=35463.31640625MB; mem (CPU total)=61328.12890625MB
INFO:root:[   39] Training loss: 0.64222347, Validation loss: 0.63157885, Gradient norm: 0.05346860
INFO:root:At the start of the epoch: mem (CPU python)=35501.41015625MB; mem (CPU total)=61404.73828125MB
INFO:root:[   40] Training loss: 0.64166595, Validation loss: 0.63054159, Gradient norm: 0.05272282
INFO:root:At the start of the epoch: mem (CPU python)=35539.50390625MB; mem (CPU total)=61484.69921875MB
INFO:root:[   41] Training loss: 0.64129493, Validation loss: 0.63095566, Gradient norm: 0.05761161
INFO:root:At the start of the epoch: mem (CPU python)=35577.60546875MB; mem (CPU total)=61566.34765625MB
INFO:root:[   42] Training loss: 0.64035864, Validation loss: 0.62943730, Gradient norm: 0.05748451
INFO:root:At the start of the epoch: mem (CPU python)=35615.69921875MB; mem (CPU total)=61647.8984375MB
INFO:root:[   43] Training loss: 0.64001406, Validation loss: 0.62930476, Gradient norm: 0.05315463
INFO:root:At the start of the epoch: mem (CPU python)=35653.79296875MB; mem (CPU total)=61729.578125MB
INFO:root:[   44] Training loss: 0.63943820, Validation loss: 0.62816031, Gradient norm: 0.05796515
INFO:root:At the start of the epoch: mem (CPU python)=35691.88671875MB; mem (CPU total)=61816.62890625MB
INFO:root:[   45] Training loss: 0.63902653, Validation loss: 0.62887724, Gradient norm: 0.05787705
INFO:root:At the start of the epoch: mem (CPU python)=35729.984375MB; mem (CPU total)=61898.0390625MB
INFO:root:[   46] Training loss: 0.63860813, Validation loss: 0.62704903, Gradient norm: 0.05478634
INFO:root:At the start of the epoch: mem (CPU python)=35768.078125MB; mem (CPU total)=61981.6875MB
INFO:root:[   47] Training loss: 0.63792505, Validation loss: 0.62716284, Gradient norm: 0.05073496
INFO:root:At the start of the epoch: mem (CPU python)=35806.171875MB; mem (CPU total)=62058.1796875MB
INFO:root:[   48] Training loss: 0.63757527, Validation loss: 0.62697726, Gradient norm: 0.05470291
INFO:root:At the start of the epoch: mem (CPU python)=35844.2734375MB; mem (CPU total)=62134.90234375MB
INFO:root:[   49] Training loss: 0.63699960, Validation loss: 0.62745352, Gradient norm: 0.05505471
INFO:root:At the start of the epoch: mem (CPU python)=35882.3671875MB; mem (CPU total)=62211.19140625MB
INFO:root:[   50] Training loss: 0.63654724, Validation loss: 0.62602106, Gradient norm: 0.06252641
INFO:root:At the start of the epoch: mem (CPU python)=35920.4609375MB; mem (CPU total)=62287.45703125MB
INFO:root:[   51] Training loss: 0.63612200, Validation loss: 0.62539824, Gradient norm: 0.06123436
INFO:root:At the start of the epoch: mem (CPU python)=35958.55859375MB; mem (CPU total)=62364.13671875MB
INFO:root:[   52] Training loss: 0.63573081, Validation loss: 0.62451434, Gradient norm: 0.05996206
INFO:root:At the start of the epoch: mem (CPU python)=35996.65234375MB; mem (CPU total)=62446.51953125MB
INFO:root:[   53] Training loss: 0.63489080, Validation loss: 0.62485266, Gradient norm: 0.05090948
INFO:root:At the start of the epoch: mem (CPU python)=36034.74609375MB; mem (CPU total)=62528.71484375MB
INFO:root:[   54] Training loss: 0.63490492, Validation loss: 0.62504663, Gradient norm: 0.05812785
INFO:root:At the start of the epoch: mem (CPU python)=36072.83984375MB; mem (CPU total)=62610.64453125MB
INFO:root:[   55] Training loss: 0.63423257, Validation loss: 0.62379224, Gradient norm: 0.05876370
INFO:root:At the start of the epoch: mem (CPU python)=36110.9375MB; mem (CPU total)=62692.04296875MB
INFO:root:[   56] Training loss: 0.63392760, Validation loss: 0.62276092, Gradient norm: 0.05959724
INFO:root:At the start of the epoch: mem (CPU python)=36149.03125MB; mem (CPU total)=62774.16015625MB
INFO:root:[   57] Training loss: 0.63384731, Validation loss: 0.62330558, Gradient norm: 0.05506258
INFO:root:At the start of the epoch: mem (CPU python)=36187.125MB; mem (CPU total)=62856.86328125MB
INFO:root:[   58] Training loss: 0.63325353, Validation loss: 0.62340099, Gradient norm: 0.05778279
INFO:root:At the start of the epoch: mem (CPU python)=36225.2265625MB; mem (CPU total)=62936.09375MB
INFO:root:[   59] Training loss: 0.63293721, Validation loss: 0.62223219, Gradient norm: 0.05851988
INFO:root:At the start of the epoch: mem (CPU python)=36263.3203125MB; mem (CPU total)=63012.61328125MB
INFO:root:[   60] Training loss: 0.63246148, Validation loss: 0.62345691, Gradient norm: 0.05983395
INFO:root:At the start of the epoch: mem (CPU python)=36301.4140625MB; mem (CPU total)=63089.109375MB
INFO:root:[   61] Training loss: 0.63221667, Validation loss: 0.62198247, Gradient norm: 0.05957017
INFO:root:At the start of the epoch: mem (CPU python)=36339.5078125MB; mem (CPU total)=63165.42578125MB
INFO:root:[   62] Training loss: 0.63176332, Validation loss: 0.62111578, Gradient norm: 0.05430061
INFO:root:At the start of the epoch: mem (CPU python)=36377.60546875MB; mem (CPU total)=63241.39453125MB
INFO:root:[   63] Training loss: 0.63157307, Validation loss: 0.62165488, Gradient norm: 0.05839769
INFO:root:At the start of the epoch: mem (CPU python)=36415.69921875MB; mem (CPU total)=63319.890625MB
INFO:root:[   64] Training loss: 0.63142372, Validation loss: 0.62128215, Gradient norm: 0.06640082
INFO:root:At the start of the epoch: mem (CPU python)=36453.79296875MB; mem (CPU total)=63402.0625MB
INFO:root:[   65] Training loss: 0.63095145, Validation loss: 0.62164194, Gradient norm: 0.06474606
INFO:root:At the start of the epoch: mem (CPU python)=36491.890625MB; mem (CPU total)=63486.33203125MB
INFO:root:[   66] Training loss: 0.63046140, Validation loss: 0.62027044, Gradient norm: 0.06309114
INFO:root:At the start of the epoch: mem (CPU python)=36529.98828125MB; mem (CPU total)=63568.265625MB
INFO:root:[   67] Training loss: 0.63020713, Validation loss: 0.62017166, Gradient norm: 0.05958313
INFO:root:At the start of the epoch: mem (CPU python)=36568.08203125MB; mem (CPU total)=63649.1875MB
INFO:root:[   68] Training loss: 0.63023646, Validation loss: 0.62018543, Gradient norm: 0.05852576
INFO:root:At the start of the epoch: mem (CPU python)=36606.1796875MB; mem (CPU total)=63730.125MB
INFO:root:[   69] Training loss: 0.62965352, Validation loss: 0.61953557, Gradient norm: 0.06179024
INFO:root:At the start of the epoch: mem (CPU python)=36644.2734375MB; mem (CPU total)=63813.79296875MB
INFO:root:[   70] Training loss: 0.62936076, Validation loss: 0.61987599, Gradient norm: 0.06084261
INFO:root:At the start of the epoch: mem (CPU python)=36682.3671875MB; mem (CPU total)=63891.859375MB
INFO:root:[   71] Training loss: 0.62909897, Validation loss: 0.61922214, Gradient norm: 0.05953702
INFO:root:At the start of the epoch: mem (CPU python)=36720.4609375MB; mem (CPU total)=63968.20703125MB
INFO:root:[   72] Training loss: 0.62902517, Validation loss: 0.61860713, Gradient norm: 0.06247463
INFO:root:At the start of the epoch: mem (CPU python)=36758.55859375MB; mem (CPU total)=64044.7421875MB
INFO:root:[   73] Training loss: 0.62879659, Validation loss: 0.61935157, Gradient norm: 0.06108921
INFO:root:At the start of the epoch: mem (CPU python)=36796.65234375MB; mem (CPU total)=64121.0MB
INFO:root:[   74] Training loss: 0.62832952, Validation loss: 0.61841950, Gradient norm: 0.06303709
INFO:root:At the start of the epoch: mem (CPU python)=36834.74609375MB; mem (CPU total)=64197.80859375MB
INFO:root:[   75] Training loss: 0.62826341, Validation loss: 0.62082837, Gradient norm: 0.06620078
INFO:root:At the start of the epoch: mem (CPU python)=36872.8515625MB; mem (CPU total)=64276.375MB
INFO:root:[   76] Training loss: 0.62786855, Validation loss: 0.61756135, Gradient norm: 0.07054371
INFO:root:At the start of the epoch: mem (CPU python)=36910.9453125MB; mem (CPU total)=64357.8828125MB
INFO:root:[   77] Training loss: 0.62740783, Validation loss: 0.61775310, Gradient norm: 0.05944289
INFO:root:At the start of the epoch: mem (CPU python)=36949.04296875MB; mem (CPU total)=64438.765625MB
INFO:root:[   78] Training loss: 0.62738631, Validation loss: 0.61760536, Gradient norm: 0.06510697
INFO:root:At the start of the epoch: mem (CPU python)=36987.13671875MB; mem (CPU total)=64520.2265625MB
INFO:root:[   79] Training loss: 0.62723744, Validation loss: 0.61773069, Gradient norm: 0.06846116
INFO:root:At the start of the epoch: mem (CPU python)=37025.234375MB; mem (CPU total)=64601.734375MB
INFO:root:[   80] Training loss: 0.62701053, Validation loss: 0.61826242, Gradient norm: 0.05885022
INFO:root:At the start of the epoch: mem (CPU python)=37063.328125MB; mem (CPU total)=64682.89453125MB
INFO:root:[   81] Training loss: 0.62670010, Validation loss: 0.61678350, Gradient norm: 0.05953633
INFO:root:At the start of the epoch: mem (CPU python)=37101.421875MB; mem (CPU total)=64765.609375MB
INFO:root:[   82] Training loss: 0.62658972, Validation loss: 0.61728918, Gradient norm: 0.06658673
INFO:root:At the start of the epoch: mem (CPU python)=37139.51953125MB; mem (CPU total)=64845.8671875MB
INFO:root:[   83] Training loss: 0.62609776, Validation loss: 0.61672901, Gradient norm: 0.06093944
INFO:root:At the start of the epoch: mem (CPU python)=37177.6171875MB; mem (CPU total)=64922.1484375MB
INFO:root:[   84] Training loss: 0.62602676, Validation loss: 0.61725137, Gradient norm: 0.07082410
INFO:root:At the start of the epoch: mem (CPU python)=37215.7109375MB; mem (CPU total)=64999.09375MB
INFO:root:[   85] Training loss: 0.62586864, Validation loss: 0.61568281, Gradient norm: 0.06404509
INFO:root:At the start of the epoch: mem (CPU python)=37253.80859375MB; mem (CPU total)=65074.9140625MB
INFO:root:[   86] Training loss: 0.62537403, Validation loss: 0.61633127, Gradient norm: 0.06586171
INFO:root:At the start of the epoch: mem (CPU python)=37291.90234375MB; mem (CPU total)=65151.7109375MB
INFO:root:[   87] Training loss: 0.62547980, Validation loss: 0.61638035, Gradient norm: 0.07193805
INFO:root:At the start of the epoch: mem (CPU python)=37329.99609375MB; mem (CPU total)=65228.3515625MB
INFO:root:[   88] Training loss: 0.62517879, Validation loss: 0.61584080, Gradient norm: 0.06514106
INFO:root:At the start of the epoch: mem (CPU python)=37368.08984375MB; mem (CPU total)=65305.62109375MB
INFO:root:[   89] Training loss: 0.62491533, Validation loss: 0.61581488, Gradient norm: 0.06732029
INFO:root:At the start of the epoch: mem (CPU python)=37406.1875MB; mem (CPU total)=65387.09375MB
INFO:root:[   90] Training loss: 0.62470499, Validation loss: 0.61566270, Gradient norm: 0.06817928
INFO:root:At the start of the epoch: mem (CPU python)=37444.28515625MB; mem (CPU total)=65468.32421875MB
INFO:root:[   91] Training loss: 0.62444919, Validation loss: 0.61514246, Gradient norm: 0.05830709
INFO:root:At the start of the epoch: mem (CPU python)=37482.37890625MB; mem (CPU total)=65549.3125MB
INFO:root:[   92] Training loss: 0.62421344, Validation loss: 0.61576645, Gradient norm: 0.06747763
INFO:root:At the start of the epoch: mem (CPU python)=37520.4765625MB; mem (CPU total)=65629.80078125MB
INFO:root:[   93] Training loss: 0.62445198, Validation loss: 0.61528221, Gradient norm: 0.07007701
INFO:root:At the start of the epoch: mem (CPU python)=37558.5703125MB; mem (CPU total)=65712.015625MB
INFO:root:[   94] Training loss: 0.62389437, Validation loss: 0.61486363, Gradient norm: 0.06397432
INFO:root:At the start of the epoch: mem (CPU python)=37596.6640625MB; mem (CPU total)=65792.49609375MB
INFO:root:[   95] Training loss: 0.62385198, Validation loss: 0.61477458, Gradient norm: 0.06246781
INFO:root:At the start of the epoch: mem (CPU python)=37634.7578125MB; mem (CPU total)=65874.69921875MB
INFO:root:[   96] Training loss: 0.62326780, Validation loss: 0.61405738, Gradient norm: 0.06455644
INFO:root:At the start of the epoch: mem (CPU python)=37672.85546875MB; mem (CPU total)=65953.76953125MB
INFO:root:[   97] Training loss: 0.62347701, Validation loss: 0.61442996, Gradient norm: 0.06564108
INFO:root:At the start of the epoch: mem (CPU python)=37710.94921875MB; mem (CPU total)=66030.0859375MB
INFO:root:[   98] Training loss: 0.62336246, Validation loss: 0.61436470, Gradient norm: 0.06774048
INFO:root:At the start of the epoch: mem (CPU python)=37749.04296875MB; mem (CPU total)=66106.6171875MB
INFO:root:[   99] Training loss: 0.62300991, Validation loss: 0.61418527, Gradient norm: 0.06402295
INFO:root:At the start of the epoch: mem (CPU python)=37787.14453125MB; mem (CPU total)=66182.625MB
INFO:root:[  100] Training loss: 0.62292766, Validation loss: 0.61458951, Gradient norm: 0.06785996
INFO:root:At the start of the epoch: mem (CPU python)=37825.23828125MB; mem (CPU total)=66259.19140625MB
INFO:root:[  101] Training loss: 0.62268930, Validation loss: 0.61446402, Gradient norm: 0.07299865
INFO:root:At the start of the epoch: mem (CPU python)=37863.33203125MB; mem (CPU total)=66335.46484375MB
INFO:root:[  102] Training loss: 0.62241045, Validation loss: 0.61454265, Gradient norm: 0.06736969
INFO:root:At the start of the epoch: mem (CPU python)=37901.4296875MB; mem (CPU total)=66411.69921875MB
INFO:root:[  103] Training loss: 0.62228175, Validation loss: 0.61431957, Gradient norm: 0.06300224
INFO:root:At the start of the epoch: mem (CPU python)=37939.5234375MB; mem (CPU total)=66490.9375MB
INFO:root:[  104] Training loss: 0.62206145, Validation loss: 0.61319289, Gradient norm: 0.06427605
INFO:root:At the start of the epoch: mem (CPU python)=37977.6171875MB; mem (CPU total)=66572.75390625MB
INFO:root:[  105] Training loss: 0.62213444, Validation loss: 0.61304498, Gradient norm: 0.06530239
INFO:root:At the start of the epoch: mem (CPU python)=38015.7109375MB; mem (CPU total)=66653.44140625MB
INFO:root:[  106] Training loss: 0.62192459, Validation loss: 0.61493456, Gradient norm: 0.07047292
INFO:root:At the start of the epoch: mem (CPU python)=38053.80859375MB; mem (CPU total)=66734.19140625MB
INFO:root:[  107] Training loss: 0.62186728, Validation loss: 0.61384323, Gradient norm: 0.06598829
INFO:root:At the start of the epoch: mem (CPU python)=38091.90234375MB; mem (CPU total)=66814.4453125MB
INFO:root:[  108] Training loss: 0.62163166, Validation loss: 0.61394983, Gradient norm: 0.07078837
INFO:root:At the start of the epoch: mem (CPU python)=38130.0MB; mem (CPU total)=66895.37890625MB
INFO:root:[  109] Training loss: 0.62140440, Validation loss: 0.61276199, Gradient norm: 0.06440868
INFO:root:At the start of the epoch: mem (CPU python)=38168.09765625MB; mem (CPU total)=66975.12109375MB
INFO:root:[  110] Training loss: 0.62109065, Validation loss: 0.61321455, Gradient norm: 0.06336650
INFO:root:At the start of the epoch: mem (CPU python)=38206.19140625MB; mem (CPU total)=67056.84765625MB
INFO:root:[  111] Training loss: 0.62099346, Validation loss: 0.61354658, Gradient norm: 0.06547287
INFO:root:At the start of the epoch: mem (CPU python)=38244.28515625MB; mem (CPU total)=67136.41796875MB
INFO:root:[  112] Training loss: 0.62073783, Validation loss: 0.61363128, Gradient norm: 0.06770896
INFO:root:At the start of the epoch: mem (CPU python)=38282.37890625MB; mem (CPU total)=67213.17578125MB
INFO:root:[  113] Training loss: 0.62073952, Validation loss: 0.61347707, Gradient norm: 0.06751135
INFO:root:At the start of the epoch: mem (CPU python)=38320.4765625MB; mem (CPU total)=67289.4921875MB
INFO:root:[  114] Training loss: 0.62059763, Validation loss: 0.61264220, Gradient norm: 0.06281445
INFO:root:At the start of the epoch: mem (CPU python)=38358.5703125MB; mem (CPU total)=67365.82421875MB
INFO:root:[  115] Training loss: 0.62055709, Validation loss: 0.61281180, Gradient norm: 0.06584260
INFO:root:At the start of the epoch: mem (CPU python)=38396.6640625MB; mem (CPU total)=67441.89453125MB
INFO:root:[  116] Training loss: 0.62012569, Validation loss: 0.61284958, Gradient norm: 0.06663294
INFO:root:At the start of the epoch: mem (CPU python)=38434.76171875MB; mem (CPU total)=67518.4296875MB
INFO:root:[  117] Training loss: 0.62032487, Validation loss: 0.61261353, Gradient norm: 0.06748299
INFO:root:At the start of the epoch: mem (CPU python)=38472.85546875MB; mem (CPU total)=67595.25MB
INFO:root:[  118] Training loss: 0.61992980, Validation loss: 0.61149605, Gradient norm: 0.06729067
INFO:root:At the start of the epoch: mem (CPU python)=38510.953125MB; mem (CPU total)=67671.58984375MB
INFO:root:[  119] Training loss: 0.61971682, Validation loss: 0.61234047, Gradient norm: 0.06676999
INFO:root:At the start of the epoch: mem (CPU python)=38549.05078125MB; mem (CPU total)=67751.390625MB
INFO:root:[  120] Training loss: 0.61970570, Validation loss: 0.61195646, Gradient norm: 0.06817172
INFO:root:At the start of the epoch: mem (CPU python)=38587.1484375MB; mem (CPU total)=67832.5703125MB
INFO:root:[  121] Training loss: 0.61958788, Validation loss: 0.61162021, Gradient norm: 0.06674443
INFO:root:At the start of the epoch: mem (CPU python)=38625.2421875MB; mem (CPU total)=67912.79296875MB
INFO:root:[  122] Training loss: 0.61964724, Validation loss: 0.61181062, Gradient norm: 0.06860980
INFO:root:At the start of the epoch: mem (CPU python)=38663.3359375MB; mem (CPU total)=67992.0625MB
INFO:root:[  123] Training loss: 0.61916112, Validation loss: 0.61163949, Gradient norm: 0.06653350
INFO:root:At the start of the epoch: mem (CPU python)=38701.43359375MB; mem (CPU total)=68072.28515625MB
INFO:root:[  124] Training loss: 0.61927254, Validation loss: 0.61100382, Gradient norm: 0.06701345
INFO:root:At the start of the epoch: mem (CPU python)=38739.52734375MB; mem (CPU total)=68156.30859375MB
INFO:root:[  125] Training loss: 0.61915676, Validation loss: 0.61174949, Gradient norm: 0.06892861
INFO:root:At the start of the epoch: mem (CPU python)=38777.625MB; mem (CPU total)=68236.4921875MB
INFO:root:[  126] Training loss: 0.61883264, Validation loss: 0.61113978, Gradient norm: 0.07295615
INFO:root:At the start of the epoch: mem (CPU python)=38815.72265625MB; mem (CPU total)=68316.93359375MB
INFO:root:[  127] Training loss: 0.61850952, Validation loss: 0.61206638, Gradient norm: 0.06456566
INFO:root:At the start of the epoch: mem (CPU python)=38853.81640625MB; mem (CPU total)=68397.16796875MB
INFO:root:[  128] Training loss: 0.61859944, Validation loss: 0.61076315, Gradient norm: 0.07312212
INFO:root:At the start of the epoch: mem (CPU python)=38891.91015625MB; mem (CPU total)=68476.9921875MB
INFO:root:[  129] Training loss: 0.61849168, Validation loss: 0.61084168, Gradient norm: 0.07016063
INFO:root:At the start of the epoch: mem (CPU python)=38930.00390625MB; mem (CPU total)=68553.06640625MB
INFO:root:[  130] Training loss: 0.61846490, Validation loss: 0.61113397, Gradient norm: 0.06945488
INFO:root:At the start of the epoch: mem (CPU python)=38968.1015625MB; mem (CPU total)=68629.55078125MB
INFO:root:[  131] Training loss: 0.61808988, Validation loss: 0.61103688, Gradient norm: 0.06246256
INFO:root:At the start of the epoch: mem (CPU python)=39006.1953125MB; mem (CPU total)=68706.0MB
INFO:root:[  132] Training loss: 0.61800807, Validation loss: 0.61040112, Gradient norm: 0.06724571
INFO:root:At the start of the epoch: mem (CPU python)=39044.2890625MB; mem (CPU total)=68781.78125MB
INFO:root:[  133] Training loss: 0.61798846, Validation loss: 0.61014963, Gradient norm: 0.06735586
INFO:root:At the start of the epoch: mem (CPU python)=39082.38671875MB; mem (CPU total)=68859.078125MB
INFO:root:[  134] Training loss: 0.61786624, Validation loss: 0.61073510, Gradient norm: 0.06428707
INFO:root:At the start of the epoch: mem (CPU python)=39120.48046875MB; mem (CPU total)=68934.68359375MB
INFO:root:[  135] Training loss: 0.61798930, Validation loss: 0.61095589, Gradient norm: 0.06933478
INFO:root:At the start of the epoch: mem (CPU python)=39158.578125MB; mem (CPU total)=69010.76171875MB
INFO:root:[  136] Training loss: 0.61748984, Validation loss: 0.61059401, Gradient norm: 0.06856694
INFO:root:At the start of the epoch: mem (CPU python)=39196.67578125MB; mem (CPU total)=69087.265625MB
INFO:root:[  137] Training loss: 0.61741903, Validation loss: 0.61038842, Gradient norm: 0.07494119
INFO:root:At the start of the epoch: mem (CPU python)=39234.76953125MB; mem (CPU total)=69165.30859375MB
INFO:root:[  138] Training loss: 0.61760920, Validation loss: 0.61063358, Gradient norm: 0.06795491
INFO:root:At the start of the epoch: mem (CPU python)=39272.86328125MB; mem (CPU total)=69245.2890625MB
INFO:root:[  139] Training loss: 0.61715618, Validation loss: 0.61060832, Gradient norm: 0.06755703
INFO:root:At the start of the epoch: mem (CPU python)=39310.95703125MB; mem (CPU total)=69325.296875MB
INFO:root:[  140] Training loss: 0.61699889, Validation loss: 0.61058812, Gradient norm: 0.06591878
INFO:root:At the start of the epoch: mem (CPU python)=39349.0546875MB; mem (CPU total)=69404.84765625MB
INFO:root:[  141] Training loss: 0.61702566, Validation loss: 0.61057504, Gradient norm: 0.07465159
INFO:root:At the start of the epoch: mem (CPU python)=39387.15234375MB; mem (CPU total)=69483.58203125MB
INFO:root:[  142] Training loss: 0.61665160, Validation loss: 0.61163763, Gradient norm: 0.07109543
INFO:root:At the start of the epoch: mem (CPU python)=39425.24609375MB; mem (CPU total)=69564.078125MB
INFO:root:EP 142: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=39463.34375MB; mem (CPU total)=69621.859375MB
INFO:root:Training the model took 10749.836s.
INFO:root:Emptying the cuda cache took 0.005s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84811
INFO:root:EnergyScoreTrain: 0.59703
INFO:root:CRPSTrain: 0.46585
INFO:root:Gaussian NLLTrain: 1.20727
INFO:root:CoverageTrain: 0.9475
INFO:root:IntervalWidthTrain: 3.28575
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86709
INFO:root:EnergyScoreValidation: 0.6103
INFO:root:CRPSValidation: 0.47714
INFO:root:Gaussian NLLValidation: 1.23127
INFO:root:CoverageValidation: 0.94175
INFO:root:IntervalWidthValidation: 3.28849
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86885
INFO:root:EnergyScoreTest: 0.61153
INFO:root:CRPSTest: 0.47817
INFO:root:Gaussian NLLTest: 1.23356
INFO:root:CoverageTest: 0.94101
INFO:root:IntervalWidthTest: 3.28751
INFO:root:After validation: mem (CPU python)=39536.0390625MB; mem (CPU total)=69709.71875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=39536.0390625MB; mem (CPU total)=69740.03515625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=39536.0390625MB; mem (CPU total)=69741.01953125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=39536.0390625MB; mem (CPU total)=69750.390625MB
INFO:root:[    1] Training loss: 0.72561810, Validation loss: 0.72023112, Gradient norm: 0.02414094
INFO:root:At the start of the epoch: mem (CPU python)=39548.1875MB; mem (CPU total)=69830.03125MB
INFO:root:[    2] Training loss: 0.71970066, Validation loss: 0.71933988, Gradient norm: 0.00658843
INFO:root:At the start of the epoch: mem (CPU python)=39586.27734375MB; mem (CPU total)=69909.69921875MB
INFO:root:[    3] Training loss: 0.71801635, Validation loss: 0.71527804, Gradient norm: 0.00831949
INFO:root:At the start of the epoch: mem (CPU python)=39624.37109375MB; mem (CPU total)=69990.21484375MB
INFO:root:[    4] Training loss: 0.71212044, Validation loss: 0.70629157, Gradient norm: 0.01685691
INFO:root:At the start of the epoch: mem (CPU python)=39662.47265625MB; mem (CPU total)=70063.796875MB
INFO:root:[    5] Training loss: 0.70507439, Validation loss: 0.69888134, Gradient norm: 0.02628459
INFO:root:At the start of the epoch: mem (CPU python)=39700.56640625MB; mem (CPU total)=70116.140625MB
INFO:root:[    6] Training loss: 0.69949720, Validation loss: 0.69406306, Gradient norm: 0.02722517
INFO:root:At the start of the epoch: mem (CPU python)=39738.66015625MB; mem (CPU total)=70168.11328125MB
INFO:root:[    7] Training loss: 0.69464366, Validation loss: 0.68775132, Gradient norm: 0.02872478
INFO:root:At the start of the epoch: mem (CPU python)=39776.75390625MB; mem (CPU total)=70212.17578125MB
INFO:root:[    8] Training loss: 0.69030374, Validation loss: 0.68318284, Gradient norm: 0.02797210
INFO:root:At the start of the epoch: mem (CPU python)=39814.8515625MB; mem (CPU total)=70288.7265625MB
INFO:root:[    9] Training loss: 0.68631332, Validation loss: 0.67952418, Gradient norm: 0.02818340
INFO:root:At the start of the epoch: mem (CPU python)=39852.94921875MB; mem (CPU total)=70365.3359375MB
INFO:root:[   10] Training loss: 0.68307224, Validation loss: 0.67604060, Gradient norm: 0.02930309
INFO:root:At the start of the epoch: mem (CPU python)=39891.04296875MB; mem (CPU total)=70441.93359375MB
INFO:root:[   11] Training loss: 0.68027861, Validation loss: 0.67270000, Gradient norm: 0.02877715
INFO:root:At the start of the epoch: mem (CPU python)=39929.140625MB; mem (CPU total)=70517.49609375MB
INFO:root:[   12] Training loss: 0.67779842, Validation loss: 0.67054895, Gradient norm: 0.03356835
INFO:root:At the start of the epoch: mem (CPU python)=39967.234375MB; mem (CPU total)=70594.0MB
INFO:root:[   13] Training loss: 0.67551895, Validation loss: 0.66731120, Gradient norm: 0.03022636
INFO:root:At the start of the epoch: mem (CPU python)=40005.328125MB; mem (CPU total)=70670.3984375MB
INFO:root:[   14] Training loss: 0.67351242, Validation loss: 0.66626597, Gradient norm: 0.03058164
INFO:root:At the start of the epoch: mem (CPU python)=40043.42578125MB; mem (CPU total)=70749.08984375MB
INFO:root:[   15] Training loss: 0.67159113, Validation loss: 0.66443057, Gradient norm: 0.03331587
INFO:root:At the start of the epoch: mem (CPU python)=40081.51953125MB; mem (CPU total)=70828.36328125MB
INFO:root:[   16] Training loss: 0.67000197, Validation loss: 0.66217775, Gradient norm: 0.03304554
INFO:root:At the start of the epoch: mem (CPU python)=40119.61328125MB; mem (CPU total)=70907.60546875MB
INFO:root:[   17] Training loss: 0.66841178, Validation loss: 0.66037019, Gradient norm: 0.03198827
INFO:root:At the start of the epoch: mem (CPU python)=40157.70703125MB; mem (CPU total)=70987.61328125MB
INFO:root:[   18] Training loss: 0.66654995, Validation loss: 0.65981528, Gradient norm: 0.03310587
INFO:root:At the start of the epoch: mem (CPU python)=40195.8046875MB; mem (CPU total)=71067.5546875MB
INFO:root:[   19] Training loss: 0.66549272, Validation loss: 0.65727639, Gradient norm: 0.03490395
INFO:root:At the start of the epoch: mem (CPU python)=40233.90234375MB; mem (CPU total)=71145.75390625MB
INFO:root:[   20] Training loss: 0.66415913, Validation loss: 0.65629970, Gradient norm: 0.03568520
INFO:root:At the start of the epoch: mem (CPU python)=40271.99609375MB; mem (CPU total)=71224.80859375MB
INFO:root:[   21] Training loss: 0.66272982, Validation loss: 0.65480673, Gradient norm: 0.03355207
INFO:root:At the start of the epoch: mem (CPU python)=40310.09375MB; mem (CPU total)=71304.9609375MB
INFO:root:[   22] Training loss: 0.66162602, Validation loss: 0.65352457, Gradient norm: 0.03197462
INFO:root:At the start of the epoch: mem (CPU python)=40348.1875MB; mem (CPU total)=71383.890625MB
INFO:root:[   23] Training loss: 0.66035236, Validation loss: 0.65172971, Gradient norm: 0.03699528
INFO:root:At the start of the epoch: mem (CPU python)=40386.28125MB; mem (CPU total)=71462.640625MB
INFO:root:[   24] Training loss: 0.65938724, Validation loss: 0.65069982, Gradient norm: 0.03800823
INFO:root:At the start of the epoch: mem (CPU python)=40424.375MB; mem (CPU total)=71542.375MB
INFO:root:[   25] Training loss: 0.65812241, Validation loss: 0.65038818, Gradient norm: 0.03771041
INFO:root:At the start of the epoch: mem (CPU python)=40462.47265625MB; mem (CPU total)=71623.08203125MB
INFO:root:[   26] Training loss: 0.65725172, Validation loss: 0.64863842, Gradient norm: 0.04025841
INFO:root:At the start of the epoch: mem (CPU python)=40500.56640625MB; mem (CPU total)=71701.33203125MB
INFO:root:[   27] Training loss: 0.65616115, Validation loss: 0.64712838, Gradient norm: 0.03721428
INFO:root:At the start of the epoch: mem (CPU python)=40538.6640625MB; mem (CPU total)=71777.53515625MB
INFO:root:[   28] Training loss: 0.65532726, Validation loss: 0.64601935, Gradient norm: 0.04017180
INFO:root:At the start of the epoch: mem (CPU python)=40576.76171875MB; mem (CPU total)=71853.54296875MB
INFO:root:[   29] Training loss: 0.65418058, Validation loss: 0.64564308, Gradient norm: 0.03706886
INFO:root:At the start of the epoch: mem (CPU python)=40614.85546875MB; mem (CPU total)=71929.76171875MB
INFO:root:[   30] Training loss: 0.65360836, Validation loss: 0.64420730, Gradient norm: 0.03760223
INFO:root:At the start of the epoch: mem (CPU python)=40652.94921875MB; mem (CPU total)=72006.02734375MB
INFO:root:[   31] Training loss: 0.65251453, Validation loss: 0.64429107, Gradient norm: 0.03972777
INFO:root:At the start of the epoch: mem (CPU python)=40691.046875MB; mem (CPU total)=72082.0703125MB
INFO:root:[   32] Training loss: 0.65174128, Validation loss: 0.64228945, Gradient norm: 0.04812883
INFO:root:At the start of the epoch: mem (CPU python)=40729.14453125MB; mem (CPU total)=72158.390625MB
INFO:root:[   33] Training loss: 0.65078257, Validation loss: 0.64167442, Gradient norm: 0.04009304
INFO:root:At the start of the epoch: mem (CPU python)=40767.234375MB; mem (CPU total)=72234.4296875MB
INFO:root:[   34] Training loss: 0.65025553, Validation loss: 0.64062030, Gradient norm: 0.04833582
INFO:root:At the start of the epoch: mem (CPU python)=40805.33203125MB; mem (CPU total)=72310.84375MB
INFO:root:[   35] Training loss: 0.64945892, Validation loss: 0.64064297, Gradient norm: 0.04038699
INFO:root:At the start of the epoch: mem (CPU python)=40843.4296875MB; mem (CPU total)=72387.84765625MB
INFO:root:[   36] Training loss: 0.64874166, Validation loss: 0.64007480, Gradient norm: 0.04638695
INFO:root:At the start of the epoch: mem (CPU python)=40881.5234375MB; mem (CPU total)=72463.26171875MB
INFO:root:[   37] Training loss: 0.64807619, Validation loss: 0.63863355, Gradient norm: 0.04014629
INFO:root:At the start of the epoch: mem (CPU python)=40919.6171875MB; mem (CPU total)=72539.3046875MB
INFO:root:[   38] Training loss: 0.64705157, Validation loss: 0.63704476, Gradient norm: 0.04013874
INFO:root:At the start of the epoch: mem (CPU python)=40957.71484375MB; mem (CPU total)=72618.65625MB
INFO:root:[   39] Training loss: 0.64652592, Validation loss: 0.63666367, Gradient norm: 0.04525038
INFO:root:At the start of the epoch: mem (CPU python)=40995.80859375MB; mem (CPU total)=72697.65234375MB
INFO:root:[   40] Training loss: 0.64590450, Validation loss: 0.63545143, Gradient norm: 0.04589557
INFO:root:At the start of the epoch: mem (CPU python)=41033.90234375MB; mem (CPU total)=72776.88671875MB
INFO:root:[   41] Training loss: 0.64550516, Validation loss: 0.63591817, Gradient norm: 0.05301307
INFO:root:At the start of the epoch: mem (CPU python)=41071.99609375MB; mem (CPU total)=72856.61328125MB
INFO:root:[   42] Training loss: 0.64458153, Validation loss: 0.63544301, Gradient norm: 0.04846837
INFO:root:At the start of the epoch: mem (CPU python)=41110.09765625MB; mem (CPU total)=72935.5546875MB
INFO:root:[   43] Training loss: 0.64411528, Validation loss: 0.63464651, Gradient norm: 0.04600794
INFO:root:At the start of the epoch: mem (CPU python)=41148.19140625MB; mem (CPU total)=73013.9921875MB
INFO:root:[   44] Training loss: 0.64334541, Validation loss: 0.63302251, Gradient norm: 0.04540890
INFO:root:At the start of the epoch: mem (CPU python)=41186.28515625MB; mem (CPU total)=73093.71875MB
INFO:root:[   45] Training loss: 0.64270769, Validation loss: 0.63330362, Gradient norm: 0.04776810
INFO:root:At the start of the epoch: mem (CPU python)=41224.3828125MB; mem (CPU total)=73173.94140625MB
INFO:root:[   46] Training loss: 0.64259597, Validation loss: 0.63250619, Gradient norm: 0.05587209
INFO:root:At the start of the epoch: mem (CPU python)=41262.4765625MB; mem (CPU total)=73252.19921875MB
INFO:root:[   47] Training loss: 0.64148909, Validation loss: 0.63178894, Gradient norm: 0.04613472
INFO:root:At the start of the epoch: mem (CPU python)=41300.5703125MB; mem (CPU total)=73331.44140625MB
INFO:root:[   48] Training loss: 0.64106706, Validation loss: 0.63070398, Gradient norm: 0.05578847
INFO:root:At the start of the epoch: mem (CPU python)=41338.66796875MB; mem (CPU total)=73412.08203125MB
INFO:root:[   49] Training loss: 0.64026724, Validation loss: 0.63017580, Gradient norm: 0.04717382
INFO:root:At the start of the epoch: mem (CPU python)=41376.76171875MB; mem (CPU total)=73490.71875MB
INFO:root:[   50] Training loss: 0.63979493, Validation loss: 0.62942429, Gradient norm: 0.04637539
INFO:root:At the start of the epoch: mem (CPU python)=41414.85546875MB; mem (CPU total)=73569.55078125MB
INFO:root:[   51] Training loss: 0.63949524, Validation loss: 0.62924529, Gradient norm: 0.05000883
INFO:root:At the start of the epoch: mem (CPU python)=41452.953125MB; mem (CPU total)=73645.1484375MB
INFO:root:[   52] Training loss: 0.63869519, Validation loss: 0.62899646, Gradient norm: 0.05014495
INFO:root:At the start of the epoch: mem (CPU python)=41491.05078125MB; mem (CPU total)=73720.86328125MB
INFO:root:[   53] Training loss: 0.63832096, Validation loss: 0.62848949, Gradient norm: 0.05074654
INFO:root:At the start of the epoch: mem (CPU python)=41529.14453125MB; mem (CPU total)=73798.08203125MB
INFO:root:[   54] Training loss: 0.63779585, Validation loss: 0.62806796, Gradient norm: 0.05094256
INFO:root:At the start of the epoch: mem (CPU python)=41567.23828125MB; mem (CPU total)=73874.37109375MB
INFO:root:[   55] Training loss: 0.63736470, Validation loss: 0.62733461, Gradient norm: 0.05571255
INFO:root:At the start of the epoch: mem (CPU python)=41605.3359375MB; mem (CPU total)=73950.3984375MB
INFO:root:[   56] Training loss: 0.63690735, Validation loss: 0.62763535, Gradient norm: 0.04598938
INFO:root:At the start of the epoch: mem (CPU python)=41643.4296875MB; mem (CPU total)=74026.671875MB
INFO:root:[   57] Training loss: 0.63641749, Validation loss: 0.62650494, Gradient norm: 0.05412624
INFO:root:At the start of the epoch: mem (CPU python)=41681.5234375MB; mem (CPU total)=74102.9140625MB
INFO:root:[   58] Training loss: 0.63584654, Validation loss: 0.62595301, Gradient norm: 0.05048487
INFO:root:At the start of the epoch: mem (CPU python)=41719.6171875MB; mem (CPU total)=74179.61328125MB
INFO:root:[   59] Training loss: 0.63563969, Validation loss: 0.62529995, Gradient norm: 0.05944772
INFO:root:At the start of the epoch: mem (CPU python)=41757.71484375MB; mem (CPU total)=74255.86328125MB
INFO:root:[   60] Training loss: 0.63497646, Validation loss: 0.62536906, Gradient norm: 0.05455874
INFO:root:At the start of the epoch: mem (CPU python)=41795.8125MB; mem (CPU total)=74331.9375MB
INFO:root:[   61] Training loss: 0.63457346, Validation loss: 0.62431590, Gradient norm: 0.05112861
INFO:root:At the start of the epoch: mem (CPU python)=41833.90625MB; mem (CPU total)=74407.9296875MB
INFO:root:[   62] Training loss: 0.63425419, Validation loss: 0.62469322, Gradient norm: 0.05234488
INFO:root:At the start of the epoch: mem (CPU python)=41872.00390625MB; mem (CPU total)=74484.45703125MB
INFO:root:[   63] Training loss: 0.63386447, Validation loss: 0.62519849, Gradient norm: 0.05765572
INFO:root:At the start of the epoch: mem (CPU python)=41910.09765625MB; mem (CPU total)=74563.69921875MB
INFO:root:[   64] Training loss: 0.63347312, Validation loss: 0.62291372, Gradient norm: 0.05470511
INFO:root:At the start of the epoch: mem (CPU python)=41948.19140625MB; mem (CPU total)=74642.1953125MB
INFO:root:[   65] Training loss: 0.63327219, Validation loss: 0.62375560, Gradient norm: 0.05066736
INFO:root:At the start of the epoch: mem (CPU python)=41986.2890625MB; mem (CPU total)=74721.21484375MB
INFO:root:[   66] Training loss: 0.63259396, Validation loss: 0.62406145, Gradient norm: 0.05150209
INFO:root:At the start of the epoch: mem (CPU python)=42024.38671875MB; mem (CPU total)=74800.609375MB
INFO:root:[   67] Training loss: 0.63220930, Validation loss: 0.62371731, Gradient norm: 0.05328074
INFO:root:At the start of the epoch: mem (CPU python)=42062.48046875MB; mem (CPU total)=74879.5625MB
INFO:root:[   68] Training loss: 0.63193964, Validation loss: 0.62248961, Gradient norm: 0.05212669
INFO:root:At the start of the epoch: mem (CPU python)=42100.57421875MB; mem (CPU total)=74957.7890625MB
INFO:root:[   69] Training loss: 0.63167106, Validation loss: 0.62242005, Gradient norm: 0.05446043
INFO:root:At the start of the epoch: mem (CPU python)=42138.671875MB; mem (CPU total)=75037.83984375MB
INFO:root:[   70] Training loss: 0.63114842, Validation loss: 0.62182999, Gradient norm: 0.05322492
INFO:root:At the start of the epoch: mem (CPU python)=42176.765625MB; mem (CPU total)=75118.06640625MB
INFO:root:[   71] Training loss: 0.63082600, Validation loss: 0.62181238, Gradient norm: 0.05379139
INFO:root:At the start of the epoch: mem (CPU python)=42214.859375MB; mem (CPU total)=75196.078125MB
INFO:root:[   72] Training loss: 0.63046734, Validation loss: 0.62139098, Gradient norm: 0.05523703
INFO:root:At the start of the epoch: mem (CPU python)=42252.95703125MB; mem (CPU total)=75275.2890625MB
INFO:root:[   73] Training loss: 0.63012437, Validation loss: 0.62183773, Gradient norm: 0.05557736
INFO:root:At the start of the epoch: mem (CPU python)=42291.05078125MB; mem (CPU total)=75356.25390625MB
INFO:root:[   74] Training loss: 0.62991793, Validation loss: 0.62068569, Gradient norm: 0.05395405
INFO:root:At the start of the epoch: mem (CPU python)=42329.14453125MB; mem (CPU total)=75434.75MB
INFO:root:[   75] Training loss: 0.62958381, Validation loss: 0.62125178, Gradient norm: 0.06455185
INFO:root:At the start of the epoch: mem (CPU python)=42367.24609375MB; mem (CPU total)=75514.20703125MB
INFO:root:[   76] Training loss: 0.62925881, Validation loss: 0.62037532, Gradient norm: 0.05314624
INFO:root:At the start of the epoch: mem (CPU python)=42405.34375MB; mem (CPU total)=75591.1484375MB
INFO:root:[   77] Training loss: 0.62884167, Validation loss: 0.61949504, Gradient norm: 0.06109873
INFO:root:At the start of the epoch: mem (CPU python)=42443.4375MB; mem (CPU total)=75667.453125MB
INFO:root:[   78] Training loss: 0.62869338, Validation loss: 0.62020669, Gradient norm: 0.05397284
INFO:root:At the start of the epoch: mem (CPU python)=42481.53125MB; mem (CPU total)=75743.96875MB
INFO:root:[   79] Training loss: 0.62849836, Validation loss: 0.61929917, Gradient norm: 0.05878568
INFO:root:At the start of the epoch: mem (CPU python)=42519.62890625MB; mem (CPU total)=75820.2265625MB
INFO:root:[   80] Training loss: 0.62778483, Validation loss: 0.61893907, Gradient norm: 0.05586325
INFO:root:At the start of the epoch: mem (CPU python)=42557.72265625MB; mem (CPU total)=75896.578125MB
INFO:root:[   81] Training loss: 0.62759018, Validation loss: 0.61798752, Gradient norm: 0.05084597
INFO:root:At the start of the epoch: mem (CPU python)=42595.81640625MB; mem (CPU total)=75973.12890625MB
INFO:root:[   82] Training loss: 0.62741261, Validation loss: 0.61801860, Gradient norm: 0.05843605
INFO:root:At the start of the epoch: mem (CPU python)=42633.9140625MB; mem (CPU total)=76048.92578125MB
INFO:root:[   83] Training loss: 0.62692787, Validation loss: 0.61679725, Gradient norm: 0.05204975
INFO:root:At the start of the epoch: mem (CPU python)=42672.01171875MB; mem (CPU total)=76124.9140625MB
INFO:root:[   84] Training loss: 0.62679391, Validation loss: 0.61755080, Gradient norm: 0.05700128
INFO:root:At the start of the epoch: mem (CPU python)=42710.10546875MB; mem (CPU total)=76206.9765625MB
INFO:root:[   85] Training loss: 0.62648123, Validation loss: 0.61741136, Gradient norm: 0.06187667
INFO:root:At the start of the epoch: mem (CPU python)=42748.19921875MB; mem (CPU total)=76281.41796875MB
INFO:root:[   86] Training loss: 0.62621059, Validation loss: 0.61742068, Gradient norm: 0.06524862
INFO:root:At the start of the epoch: mem (CPU python)=42786.29296875MB; mem (CPU total)=76356.765625MB
INFO:root:[   87] Training loss: 0.62589619, Validation loss: 0.61636130, Gradient norm: 0.05123580
INFO:root:At the start of the epoch: mem (CPU python)=42824.390625MB; mem (CPU total)=76432.77734375MB
INFO:root:[   88] Training loss: 0.62550585, Validation loss: 0.61630485, Gradient norm: 0.05497545
INFO:root:At the start of the epoch: mem (CPU python)=42862.484375MB; mem (CPU total)=76509.328125MB
INFO:root:[   89] Training loss: 0.62531971, Validation loss: 0.61700392, Gradient norm: 0.05479688
INFO:root:At the start of the epoch: mem (CPU python)=42900.58203125MB; mem (CPU total)=76588.65625MB
INFO:root:[   90] Training loss: 0.62506185, Validation loss: 0.61733191, Gradient norm: 0.05722687
INFO:root:At the start of the epoch: mem (CPU python)=42938.67578125MB; mem (CPU total)=76668.390625MB
INFO:root:[   91] Training loss: 0.62499225, Validation loss: 0.61562331, Gradient norm: 0.05695642
INFO:root:At the start of the epoch: mem (CPU python)=42976.76953125MB; mem (CPU total)=76746.30859375MB
INFO:root:[   92] Training loss: 0.62451878, Validation loss: 0.61617425, Gradient norm: 0.05584352
INFO:root:At the start of the epoch: mem (CPU python)=43014.8671875MB; mem (CPU total)=76825.27734375MB
INFO:root:[   93] Training loss: 0.62424749, Validation loss: 0.61556613, Gradient norm: 0.06286175
INFO:root:At the start of the epoch: mem (CPU python)=43052.96484375MB; mem (CPU total)=76905.96484375MB
INFO:root:[   94] Training loss: 0.62428858, Validation loss: 0.61543515, Gradient norm: 0.06518633
INFO:root:At the start of the epoch: mem (CPU python)=43091.05859375MB; mem (CPU total)=76983.9765625MB
INFO:root:[   95] Training loss: 0.62382264, Validation loss: 0.61625862, Gradient norm: 0.05529882
INFO:root:At the start of the epoch: mem (CPU python)=43129.15234375MB; mem (CPU total)=77062.60546875MB
INFO:root:[   96] Training loss: 0.62373600, Validation loss: 0.61399511, Gradient norm: 0.06324143
INFO:root:At the start of the epoch: mem (CPU python)=43167.25MB; mem (CPU total)=77143.078125MB
INFO:root:[   97] Training loss: 0.62326502, Validation loss: 0.61486701, Gradient norm: 0.05731341
INFO:root:At the start of the epoch: mem (CPU python)=43205.34375MB; mem (CPU total)=77221.08984375MB
INFO:root:[   98] Training loss: 0.62299533, Validation loss: 0.61473924, Gradient norm: 0.05454008
INFO:root:At the start of the epoch: mem (CPU python)=43243.4375MB; mem (CPU total)=77300.0078125MB
INFO:root:[   99] Training loss: 0.62324369, Validation loss: 0.61474563, Gradient norm: 0.06179550
INFO:root:At the start of the epoch: mem (CPU python)=43281.53515625MB; mem (CPU total)=77380.9296875MB
INFO:root:[  100] Training loss: 0.62296740, Validation loss: 0.61395980, Gradient norm: 0.05613149
INFO:root:At the start of the epoch: mem (CPU python)=43319.6328125MB; mem (CPU total)=77459.921875MB
INFO:root:[  101] Training loss: 0.62251872, Validation loss: 0.61373183, Gradient norm: 0.05755286
INFO:root:At the start of the epoch: mem (CPU python)=43357.7265625MB; mem (CPU total)=77539.078125MB
INFO:root:[  102] Training loss: 0.62224325, Validation loss: 0.61365850, Gradient norm: 0.05931382
INFO:root:At the start of the epoch: mem (CPU python)=43395.8203125MB; mem (CPU total)=77615.625MB
INFO:root:[  103] Training loss: 0.62198704, Validation loss: 0.61410403, Gradient norm: 0.06368577
INFO:root:At the start of the epoch: mem (CPU python)=43433.91796875MB; mem (CPU total)=77691.65234375MB
INFO:root:[  104] Training loss: 0.62207028, Validation loss: 0.61261739, Gradient norm: 0.05799836
INFO:root:At the start of the epoch: mem (CPU python)=43472.01171875MB; mem (CPU total)=77768.15625MB
INFO:root:[  105] Training loss: 0.62168615, Validation loss: 0.61263505, Gradient norm: 0.05611207
INFO:root:At the start of the epoch: mem (CPU python)=43510.10546875MB; mem (CPU total)=77844.69140625MB
INFO:root:[  106] Training loss: 0.62126068, Validation loss: 0.61278590, Gradient norm: 0.06053193
INFO:root:At the start of the epoch: mem (CPU python)=43548.203125MB; mem (CPU total)=77921.171875MB
INFO:root:[  107] Training loss: 0.62118876, Validation loss: 0.61297467, Gradient norm: 0.06384225
INFO:root:At the start of the epoch: mem (CPU python)=43586.296875MB; mem (CPU total)=77997.6953125MB
INFO:root:[  108] Training loss: 0.62110042, Validation loss: 0.61233233, Gradient norm: 0.06322259
INFO:root:At the start of the epoch: mem (CPU python)=43624.39453125MB; mem (CPU total)=78073.24609375MB
INFO:root:[  109] Training loss: 0.62072147, Validation loss: 0.61360295, Gradient norm: 0.05669941
INFO:root:At the start of the epoch: mem (CPU python)=43662.484375MB; mem (CPU total)=78149.5625MB
INFO:root:[  110] Training loss: 0.62070851, Validation loss: 0.61213738, Gradient norm: 0.06449556
INFO:root:At the start of the epoch: mem (CPU python)=43700.5859375MB; mem (CPU total)=78226.32421875MB
INFO:root:[  111] Training loss: 0.62029558, Validation loss: 0.61304604, Gradient norm: 0.05832747
INFO:root:At the start of the epoch: mem (CPU python)=43738.6796875MB; mem (CPU total)=78302.58203125MB
INFO:root:[  112] Training loss: 0.62015451, Validation loss: 0.61266438, Gradient norm: 0.06109832
INFO:root:At the start of the epoch: mem (CPU python)=43776.7734375MB; mem (CPU total)=78378.87109375MB
INFO:root:[  113] Training loss: 0.62025636, Validation loss: 0.61189604, Gradient norm: 0.06266047
INFO:root:At the start of the epoch: mem (CPU python)=43814.87109375MB; mem (CPU total)=78455.48046875MB
INFO:root:[  114] Training loss: 0.61981930, Validation loss: 0.61179870, Gradient norm: 0.06567984
INFO:root:At the start of the epoch: mem (CPU python)=43852.96484375MB; mem (CPU total)=78531.7421875MB
INFO:root:[  115] Training loss: 0.61946973, Validation loss: 0.61250284, Gradient norm: 0.05908016
INFO:root:At the start of the epoch: mem (CPU python)=43891.05859375MB; mem (CPU total)=78611.6953125MB
INFO:root:[  116] Training loss: 0.61943052, Validation loss: 0.61083037, Gradient norm: 0.06519153
INFO:root:At the start of the epoch: mem (CPU python)=43929.15625MB; mem (CPU total)=78689.77734375MB
INFO:root:[  117] Training loss: 0.61942983, Validation loss: 0.61070754, Gradient norm: 0.05909190
INFO:root:At the start of the epoch: mem (CPU python)=43967.25390625MB; mem (CPU total)=78768.46875MB
INFO:root:[  118] Training loss: 0.61927031, Validation loss: 0.61146670, Gradient norm: 0.07152457
INFO:root:At the start of the epoch: mem (CPU python)=44005.34765625MB; mem (CPU total)=78848.46484375MB
INFO:root:[  119] Training loss: 0.61909687, Validation loss: 0.61089987, Gradient norm: 0.06534115
INFO:root:At the start of the epoch: mem (CPU python)=44043.44140625MB; mem (CPU total)=78926.5078125MB
INFO:root:[  120] Training loss: 0.61855387, Validation loss: 0.61289465, Gradient norm: 0.05582279
INFO:root:At the start of the epoch: mem (CPU python)=44081.5390625MB; mem (CPU total)=79006.765625MB
INFO:root:[  121] Training loss: 0.61838925, Validation loss: 0.61098117, Gradient norm: 0.06037403
INFO:root:At the start of the epoch: mem (CPU python)=44119.6328125MB; mem (CPU total)=79085.47265625MB
INFO:root:[  122] Training loss: 0.61863851, Validation loss: 0.61038126, Gradient norm: 0.06182870
INFO:root:At the start of the epoch: mem (CPU python)=44157.7265625MB; mem (CPU total)=79163.0078125MB
INFO:root:[  123] Training loss: 0.61842269, Validation loss: 0.61000415, Gradient norm: 0.06222811
INFO:root:At the start of the epoch: mem (CPU python)=44195.82421875MB; mem (CPU total)=79242.94140625MB
INFO:root:[  124] Training loss: 0.61832259, Validation loss: 0.61136604, Gradient norm: 0.06216756
INFO:root:At the start of the epoch: mem (CPU python)=44233.91796875MB; mem (CPU total)=79321.1328125MB
INFO:root:[  125] Training loss: 0.61797029, Validation loss: 0.60936664, Gradient norm: 0.05981426
INFO:root:At the start of the epoch: mem (CPU python)=44272.01171875MB; mem (CPU total)=79398.9453125MB
INFO:root:[  126] Training loss: 0.61762797, Validation loss: 0.60962451, Gradient norm: 0.06041469
INFO:root:At the start of the epoch: mem (CPU python)=44310.109375MB; mem (CPU total)=79479.19140625MB
INFO:root:[  127] Training loss: 0.61780514, Validation loss: 0.61059793, Gradient norm: 0.06344392
INFO:root:At the start of the epoch: mem (CPU python)=44348.20703125MB; mem (CPU total)=79557.3828125MB
INFO:root:[  128] Training loss: 0.61740240, Validation loss: 0.61021584, Gradient norm: 0.06250372
INFO:root:At the start of the epoch: mem (CPU python)=44386.30078125MB; mem (CPU total)=79636.73828125MB
INFO:root:[  129] Training loss: 0.61743902, Validation loss: 0.60990259, Gradient norm: 0.06550822
INFO:root:At the start of the epoch: mem (CPU python)=44424.39453125MB; mem (CPU total)=79717.37890625MB
INFO:root:[  130] Training loss: 0.61710006, Validation loss: 0.61238819, Gradient norm: 0.06451369
INFO:root:At the start of the epoch: mem (CPU python)=44462.4921875MB; mem (CPU total)=79793.73046875MB
INFO:root:[  131] Training loss: 0.61738652, Validation loss: 0.61036992, Gradient norm: 0.06418499
INFO:root:At the start of the epoch: mem (CPU python)=44500.5859375MB; mem (CPU total)=79871.2578125MB
INFO:root:[  132] Training loss: 0.61688845, Validation loss: 0.60962322, Gradient norm: 0.06530898
INFO:root:At the start of the epoch: mem (CPU python)=44538.6796875MB; mem (CPU total)=79947.515625MB
INFO:root:[  133] Training loss: 0.61676106, Validation loss: 0.60892890, Gradient norm: 0.05960997
INFO:root:At the start of the epoch: mem (CPU python)=44576.83203125MB; mem (CPU total)=80023.09375MB
INFO:root:[  134] Training loss: 0.61671565, Validation loss: 0.60952049, Gradient norm: 0.06062109
INFO:root:At the start of the epoch: mem (CPU python)=44614.92578125MB; mem (CPU total)=80099.41015625MB
INFO:root:[  135] Training loss: 0.61655260, Validation loss: 0.60835925, Gradient norm: 0.06322951
INFO:root:At the start of the epoch: mem (CPU python)=44653.01953125MB; mem (CPU total)=80176.26953125MB
INFO:root:[  136] Training loss: 0.61631285, Validation loss: 0.61011787, Gradient norm: 0.06394290
INFO:root:At the start of the epoch: mem (CPU python)=44691.11328125MB; mem (CPU total)=80252.5859375MB
INFO:root:[  137] Training loss: 0.61590124, Validation loss: 0.61028129, Gradient norm: 0.06428961
INFO:root:At the start of the epoch: mem (CPU python)=44729.2109375MB; mem (CPU total)=80328.90625MB
INFO:root:[  138] Training loss: 0.61598215, Validation loss: 0.60910531, Gradient norm: 0.06600466
INFO:root:At the start of the epoch: mem (CPU python)=44767.3046875MB; mem (CPU total)=80405.21484375MB
INFO:root:[  139] Training loss: 0.61583228, Validation loss: 0.60940596, Gradient norm: 0.06605072
INFO:root:At the start of the epoch: mem (CPU python)=44805.3984375MB; mem (CPU total)=80481.59375MB
INFO:root:[  140] Training loss: 0.61577512, Validation loss: 0.60876363, Gradient norm: 0.06462838
INFO:root:At the start of the epoch: mem (CPU python)=44843.49609375MB; mem (CPU total)=80558.015625MB
INFO:root:[  141] Training loss: 0.61542548, Validation loss: 0.60852321, Gradient norm: 0.05764004
INFO:root:At the start of the epoch: mem (CPU python)=44881.58984375MB; mem (CPU total)=80634.796875MB
INFO:root:[  142] Training loss: 0.61537892, Validation loss: 0.60947170, Gradient norm: 0.06150350
INFO:root:At the start of the epoch: mem (CPU python)=44919.6875MB; mem (CPU total)=80710.82421875MB
INFO:root:[  143] Training loss: 0.61544974, Validation loss: 0.60763484, Gradient norm: 0.06638878
INFO:root:At the start of the epoch: mem (CPU python)=44957.78125MB; mem (CPU total)=80786.890625MB
INFO:root:[  144] Training loss: 0.61521337, Validation loss: 0.60812277, Gradient norm: 0.07390595
INFO:root:At the start of the epoch: mem (CPU python)=44995.8828125MB; mem (CPU total)=80863.17578125MB
INFO:root:[  145] Training loss: 0.61503369, Validation loss: 0.60885580, Gradient norm: 0.06092278
INFO:root:At the start of the epoch: mem (CPU python)=45033.9765625MB; mem (CPU total)=80939.94140625MB
INFO:root:[  146] Training loss: 0.61489444, Validation loss: 0.60895704, Gradient norm: 0.06364579
INFO:root:At the start of the epoch: mem (CPU python)=45072.0703125MB; mem (CPU total)=81016.2109375MB
INFO:root:[  147] Training loss: 0.61479461, Validation loss: 0.60874163, Gradient norm: 0.06404845
INFO:root:At the start of the epoch: mem (CPU python)=45110.16796875MB; mem (CPU total)=81092.453125MB
INFO:root:[  148] Training loss: 0.61488640, Validation loss: 0.60707958, Gradient norm: 0.07142743
INFO:root:At the start of the epoch: mem (CPU python)=45148.26171875MB; mem (CPU total)=81168.8203125MB
INFO:root:[  149] Training loss: 0.61461753, Validation loss: 0.60906769, Gradient norm: 0.06273024
INFO:root:At the start of the epoch: mem (CPU python)=45186.35546875MB; mem (CPU total)=81245.38671875MB
INFO:root:[  150] Training loss: 0.61456604, Validation loss: 0.60766391, Gradient norm: 0.06770066
INFO:root:At the start of the epoch: mem (CPU python)=45224.453125MB; mem (CPU total)=81322.24609375MB
INFO:root:[  151] Training loss: 0.61433858, Validation loss: 0.60782025, Gradient norm: 0.06309177
INFO:root:At the start of the epoch: mem (CPU python)=45262.55078125MB; mem (CPU total)=81399.26953125MB
INFO:root:[  152] Training loss: 0.61424315, Validation loss: 0.60725167, Gradient norm: 0.06145310
INFO:root:At the start of the epoch: mem (CPU python)=45300.64453125MB; mem (CPU total)=81477.515625MB
INFO:root:[  153] Training loss: 0.61399338, Validation loss: 0.60746388, Gradient norm: 0.06376163
INFO:root:At the start of the epoch: mem (CPU python)=45338.73828125MB; mem (CPU total)=81555.26171875MB
INFO:root:[  154] Training loss: 0.61404789, Validation loss: 0.60792186, Gradient norm: 0.07288699
INFO:root:At the start of the epoch: mem (CPU python)=45376.8359375MB; mem (CPU total)=81633.44140625MB
INFO:root:[  155] Training loss: 0.61382965, Validation loss: 0.60721280, Gradient norm: 0.06691746
INFO:root:At the start of the epoch: mem (CPU python)=45414.9296875MB; mem (CPU total)=81712.4375MB
INFO:root:[  156] Training loss: 0.61385444, Validation loss: 0.60823888, Gradient norm: 0.06331122
INFO:root:At the start of the epoch: mem (CPU python)=45453.0234375MB; mem (CPU total)=81789.40234375MB
INFO:root:[  157] Training loss: 0.61344172, Validation loss: 0.60642833, Gradient norm: 0.06636561
INFO:root:At the start of the epoch: mem (CPU python)=45491.12109375MB; mem (CPU total)=81866.78515625MB
INFO:root:[  158] Training loss: 0.61349840, Validation loss: 0.60758663, Gradient norm: 0.06379749
INFO:root:At the start of the epoch: mem (CPU python)=45529.21484375MB; mem (CPU total)=81944.5078125MB
INFO:root:[  159] Training loss: 0.61325057, Validation loss: 0.60653903, Gradient norm: 0.06614403
INFO:root:At the start of the epoch: mem (CPU python)=45567.3125MB; mem (CPU total)=82022.54296875MB
INFO:root:[  160] Training loss: 0.61325232, Validation loss: 0.60767107, Gradient norm: 0.07034858
INFO:root:At the start of the epoch: mem (CPU python)=45605.40625MB; mem (CPU total)=82101.16796875MB
INFO:root:[  161] Training loss: 0.61277885, Validation loss: 0.60752363, Gradient norm: 0.06405735
INFO:root:At the start of the epoch: mem (CPU python)=45643.50390625MB; mem (CPU total)=82178.734375MB
INFO:root:[  162] Training loss: 0.61294447, Validation loss: 0.60675675, Gradient norm: 0.06520017
INFO:root:At the start of the epoch: mem (CPU python)=45681.59765625MB; mem (CPU total)=82256.25390625MB
INFO:root:[  163] Training loss: 0.61301925, Validation loss: 0.60698822, Gradient norm: 0.06233324
INFO:root:At the start of the epoch: mem (CPU python)=45719.69140625MB; mem (CPU total)=82335.49609375MB
INFO:root:[  164] Training loss: 0.61269480, Validation loss: 0.60675080, Gradient norm: 0.06442885
INFO:root:At the start of the epoch: mem (CPU python)=45757.7890625MB; mem (CPU total)=82411.984375MB
INFO:root:[  165] Training loss: 0.61232436, Validation loss: 0.60745115, Gradient norm: 0.06019189
INFO:root:At the start of the epoch: mem (CPU python)=45795.8828125MB; mem (CPU total)=82490.953125MB
INFO:root:[  166] Training loss: 0.61228438, Validation loss: 0.60710133, Gradient norm: 0.06394437
INFO:root:At the start of the epoch: mem (CPU python)=45833.9765625MB; mem (CPU total)=82569.73046875MB
INFO:root:EP 166: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=45872.07421875MB; mem (CPU total)=82618.609375MB
INFO:root:Training the model took 13640.506s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84217
INFO:root:EnergyScoreTrain: 0.59293
INFO:root:CRPSTrain: 0.46165
INFO:root:Gaussian NLLTrain: 1.19935
INFO:root:CoverageTrain: 0.94731
INFO:root:IntervalWidthTrain: 3.27308
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86216
INFO:root:EnergyScoreValidation: 0.60687
INFO:root:CRPSValidation: 0.47346
INFO:root:Gaussian NLLValidation: 1.22598
INFO:root:CoverageValidation: 0.94076
INFO:root:IntervalWidthValidation: 3.27426
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86244
INFO:root:EnergyScoreTest: 0.60704
INFO:root:CRPSTest: 0.47362
INFO:root:Gaussian NLLTest: 1.22633
INFO:root:CoverageTest: 0.94062
INFO:root:IntervalWidthTest: 3.27438
INFO:root:After validation: mem (CPU python)=45926.00390625MB; mem (CPU total)=82696.00390625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=45926.00390625MB; mem (CPU total)=82724.05859375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=45926.00390625MB; mem (CPU total)=82724.796875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=45926.00390625MB; mem (CPU total)=82734.640625MB
INFO:root:[    1] Training loss: 0.72548186, Validation loss: 0.72077003, Gradient norm: 0.02112029
INFO:root:At the start of the epoch: mem (CPU python)=45951.66015625MB; mem (CPU total)=82810.71484375MB
INFO:root:[    2] Training loss: 0.72021769, Validation loss: 0.71943767, Gradient norm: 0.00608933
INFO:root:At the start of the epoch: mem (CPU python)=45989.75390625MB; mem (CPU total)=82896.28515625MB
INFO:root:[    3] Training loss: 0.71891085, Validation loss: 0.71792507, Gradient norm: 0.00698121
INFO:root:At the start of the epoch: mem (CPU python)=46027.84765625MB; mem (CPU total)=82949.42578125MB
INFO:root:[    4] Training loss: 0.71657802, Validation loss: 0.71169364, Gradient norm: 0.01249618
INFO:root:At the start of the epoch: mem (CPU python)=46065.9453125MB; mem (CPU total)=83003.0703125MB
INFO:root:[    5] Training loss: 0.71001820, Validation loss: 0.70413397, Gradient norm: 0.02134768
INFO:root:At the start of the epoch: mem (CPU python)=46104.0390625MB; mem (CPU total)=83045.25390625MB
INFO:root:[    6] Training loss: 0.70491921, Validation loss: 0.69905972, Gradient norm: 0.02381267
INFO:root:At the start of the epoch: mem (CPU python)=46142.13671875MB; mem (CPU total)=83121.3828125MB
INFO:root:[    7] Training loss: 0.70023495, Validation loss: 0.69398126, Gradient norm: 0.02602286
INFO:root:At the start of the epoch: mem (CPU python)=46180.23046875MB; mem (CPU total)=83197.91796875MB
INFO:root:[    8] Training loss: 0.69590157, Validation loss: 0.68848637, Gradient norm: 0.03074317
INFO:root:At the start of the epoch: mem (CPU python)=46218.328125MB; mem (CPU total)=83274.63671875MB
INFO:root:[    9] Training loss: 0.69138634, Validation loss: 0.68354783, Gradient norm: 0.03109221
INFO:root:At the start of the epoch: mem (CPU python)=46256.421875MB; mem (CPU total)=83350.69921875MB
INFO:root:[   10] Training loss: 0.68668194, Validation loss: 0.67782087, Gradient norm: 0.02907691
INFO:root:At the start of the epoch: mem (CPU python)=46294.515625MB; mem (CPU total)=83427.39453125MB
INFO:root:[   11] Training loss: 0.68213270, Validation loss: 0.67244843, Gradient norm: 0.03323052
INFO:root:At the start of the epoch: mem (CPU python)=46332.61328125MB; mem (CPU total)=83502.96484375MB
INFO:root:[   12] Training loss: 0.67776187, Validation loss: 0.66718810, Gradient norm: 0.03018740
INFO:root:At the start of the epoch: mem (CPU python)=46371.08203125MB; mem (CPU total)=83579.546875MB
INFO:root:[   13] Training loss: 0.67394929, Validation loss: 0.66440613, Gradient norm: 0.03000764
INFO:root:At the start of the epoch: mem (CPU python)=46409.30078125MB; mem (CPU total)=83655.84765625MB
INFO:root:[   14] Training loss: 0.67079743, Validation loss: 0.66116432, Gradient norm: 0.03668877
INFO:root:At the start of the epoch: mem (CPU python)=46447.39453125MB; mem (CPU total)=83731.88671875MB
INFO:root:[   15] Training loss: 0.66796949, Validation loss: 0.65849115, Gradient norm: 0.03183637
INFO:root:At the start of the epoch: mem (CPU python)=46485.49609375MB; mem (CPU total)=83808.3359375MB
INFO:root:[   16] Training loss: 0.66525475, Validation loss: 0.65518569, Gradient norm: 0.03269194
INFO:root:At the start of the epoch: mem (CPU python)=46523.58984375MB; mem (CPU total)=83885.1171875MB
INFO:root:[   17] Training loss: 0.66310041, Validation loss: 0.65364158, Gradient norm: 0.03274603
INFO:root:At the start of the epoch: mem (CPU python)=46561.68359375MB; mem (CPU total)=83960.875MB
INFO:root:[   18] Training loss: 0.66110721, Validation loss: 0.65068042, Gradient norm: 0.03482606
INFO:root:At the start of the epoch: mem (CPU python)=46599.78125MB; mem (CPU total)=84037.12109375MB
INFO:root:[   19] Training loss: 0.65924617, Validation loss: 0.64875553, Gradient norm: 0.03313067
INFO:root:At the start of the epoch: mem (CPU python)=46637.875MB; mem (CPU total)=84113.421875MB
INFO:root:[   20] Training loss: 0.65758176, Validation loss: 0.64632108, Gradient norm: 0.03375601
INFO:root:At the start of the epoch: mem (CPU python)=46675.96875MB; mem (CPU total)=84189.26953125MB
INFO:root:[   21] Training loss: 0.65578132, Validation loss: 0.64563561, Gradient norm: 0.03419933
INFO:root:At the start of the epoch: mem (CPU python)=46714.06640625MB; mem (CPU total)=84265.7734375MB
INFO:root:[   22] Training loss: 0.65435523, Validation loss: 0.64377755, Gradient norm: 0.03327086
INFO:root:At the start of the epoch: mem (CPU python)=46752.1640625MB; mem (CPU total)=84342.33984375MB
INFO:root:[   23] Training loss: 0.65298526, Validation loss: 0.64281195, Gradient norm: 0.03830839
INFO:root:At the start of the epoch: mem (CPU python)=46790.2578125MB; mem (CPU total)=84418.3359375MB
INFO:root:[   24] Training loss: 0.65154032, Validation loss: 0.64145752, Gradient norm: 0.03551726
INFO:root:At the start of the epoch: mem (CPU python)=46828.3515625MB; mem (CPU total)=84494.125MB
INFO:root:[   25] Training loss: 0.65025569, Validation loss: 0.63941703, Gradient norm: 0.03959849
INFO:root:At the start of the epoch: mem (CPU python)=46866.44921875MB; mem (CPU total)=84570.84375MB
INFO:root:[   26] Training loss: 0.64949507, Validation loss: 0.63860195, Gradient norm: 0.04072340
INFO:root:At the start of the epoch: mem (CPU python)=46904.54296875MB; mem (CPU total)=84648.4453125MB
INFO:root:[   27] Training loss: 0.64817660, Validation loss: 0.63734430, Gradient norm: 0.03657827
INFO:root:At the start of the epoch: mem (CPU python)=46942.63671875MB; mem (CPU total)=84725.4453125MB
INFO:root:[   28] Training loss: 0.64737923, Validation loss: 0.63628887, Gradient norm: 0.04354747
INFO:root:At the start of the epoch: mem (CPU python)=46980.73828125MB; mem (CPU total)=84803.671875MB
INFO:root:[   29] Training loss: 0.64592904, Validation loss: 0.63514911, Gradient norm: 0.03872484
INFO:root:At the start of the epoch: mem (CPU python)=47018.828125MB; mem (CPU total)=84881.12890625MB
INFO:root:[   30] Training loss: 0.64513734, Validation loss: 0.63385626, Gradient norm: 0.04237080
INFO:root:At the start of the epoch: mem (CPU python)=47056.92578125MB; mem (CPU total)=84957.53125MB
INFO:root:[   31] Training loss: 0.64431057, Validation loss: 0.63369623, Gradient norm: 0.03979566
INFO:root:At the start of the epoch: mem (CPU python)=47095.01953125MB; mem (CPU total)=85035.05859375MB
INFO:root:[   32] Training loss: 0.64335109, Validation loss: 0.63292311, Gradient norm: 0.03956019
INFO:root:At the start of the epoch: mem (CPU python)=47133.1171875MB; mem (CPU total)=85112.03125MB
INFO:root:[   33] Training loss: 0.64279713, Validation loss: 0.63170514, Gradient norm: 0.04313050
INFO:root:At the start of the epoch: mem (CPU python)=47171.2109375MB; mem (CPU total)=85190.48046875MB
INFO:root:[   34] Training loss: 0.64203605, Validation loss: 0.63053021, Gradient norm: 0.04223988
INFO:root:At the start of the epoch: mem (CPU python)=47209.3046875MB; mem (CPU total)=85268.5234375MB
INFO:root:[   35] Training loss: 0.64129281, Validation loss: 0.63092279, Gradient norm: 0.04292881
INFO:root:At the start of the epoch: mem (CPU python)=47247.40234375MB; mem (CPU total)=85345.23828125MB
INFO:root:[   36] Training loss: 0.64064901, Validation loss: 0.63019470, Gradient norm: 0.04463686
INFO:root:At the start of the epoch: mem (CPU python)=47285.49609375MB; mem (CPU total)=85423.52734375MB
INFO:root:[   37] Training loss: 0.64002250, Validation loss: 0.62834170, Gradient norm: 0.04546775
INFO:root:At the start of the epoch: mem (CPU python)=47323.58984375MB; mem (CPU total)=85500.30859375MB
INFO:root:[   38] Training loss: 0.63898098, Validation loss: 0.62863353, Gradient norm: 0.04063748
INFO:root:At the start of the epoch: mem (CPU python)=47361.69140625MB; mem (CPU total)=85577.30078125MB
INFO:root:[   39] Training loss: 0.63864113, Validation loss: 0.62811615, Gradient norm: 0.04417439
INFO:root:At the start of the epoch: mem (CPU python)=47399.78515625MB; mem (CPU total)=85656.328125MB
INFO:root:[   40] Training loss: 0.63806334, Validation loss: 0.62680256, Gradient norm: 0.04112388
INFO:root:At the start of the epoch: mem (CPU python)=47437.87890625MB; mem (CPU total)=85732.0390625MB
INFO:root:[   41] Training loss: 0.63746429, Validation loss: 0.62619870, Gradient norm: 0.04145686
INFO:root:At the start of the epoch: mem (CPU python)=47475.97265625MB; mem (CPU total)=85811.02734375MB
INFO:root:[   42] Training loss: 0.63686828, Validation loss: 0.62705350, Gradient norm: 0.03950884
INFO:root:At the start of the epoch: mem (CPU python)=47514.0703125MB; mem (CPU total)=85887.84375MB
INFO:root:[   43] Training loss: 0.63640474, Validation loss: 0.62505883, Gradient norm: 0.04520567
INFO:root:At the start of the epoch: mem (CPU python)=47552.1640625MB; mem (CPU total)=85964.90234375MB
INFO:root:[   44] Training loss: 0.63567715, Validation loss: 0.62505566, Gradient norm: 0.04359093
INFO:root:At the start of the epoch: mem (CPU python)=47590.2578125MB; mem (CPU total)=86044.1796875MB
INFO:root:[   45] Training loss: 0.63536025, Validation loss: 0.62455176, Gradient norm: 0.04332000
INFO:root:At the start of the epoch: mem (CPU python)=47628.35546875MB; mem (CPU total)=86120.23046875MB
INFO:root:[   46] Training loss: 0.63500294, Validation loss: 0.62431610, Gradient norm: 0.05449044
INFO:root:At the start of the epoch: mem (CPU python)=47666.453125MB; mem (CPU total)=86199.91796875MB
INFO:root:[   47] Training loss: 0.63458968, Validation loss: 0.62533916, Gradient norm: 0.04449817
INFO:root:At the start of the epoch: mem (CPU python)=47704.55078125MB; mem (CPU total)=86276.40234375MB
INFO:root:[   48] Training loss: 0.63381734, Validation loss: 0.62349495, Gradient norm: 0.04369983
INFO:root:At the start of the epoch: mem (CPU python)=47742.64453125MB; mem (CPU total)=86354.5078125MB
INFO:root:[   49] Training loss: 0.63352561, Validation loss: 0.62320061, Gradient norm: 0.04612545
INFO:root:At the start of the epoch: mem (CPU python)=47780.7421875MB; mem (CPU total)=86433.04296875MB
INFO:root:[   50] Training loss: 0.63290377, Validation loss: 0.62304543, Gradient norm: 0.04511708
INFO:root:At the start of the epoch: mem (CPU python)=47818.8359375MB; mem (CPU total)=86509.91796875MB
INFO:root:[   51] Training loss: 0.63263776, Validation loss: 0.62304475, Gradient norm: 0.04907671
INFO:root:At the start of the epoch: mem (CPU python)=47856.9296875MB; mem (CPU total)=86589.5859375MB
INFO:root:[   52] Training loss: 0.63219512, Validation loss: 0.62189472, Gradient norm: 0.04676303
INFO:root:At the start of the epoch: mem (CPU python)=47895.02734375MB; mem (CPU total)=86666.4453125MB
INFO:root:[   53] Training loss: 0.63202764, Validation loss: 0.62198620, Gradient norm: 0.05020251
INFO:root:At the start of the epoch: mem (CPU python)=47933.12109375MB; mem (CPU total)=86745.3984375MB
INFO:root:[   54] Training loss: 0.63149533, Validation loss: 0.62076136, Gradient norm: 0.04706152
INFO:root:At the start of the epoch: mem (CPU python)=47971.21484375MB; mem (CPU total)=86822.91015625MB
INFO:root:[   55] Training loss: 0.63135045, Validation loss: 0.62134702, Gradient norm: 0.04878601
INFO:root:At the start of the epoch: mem (CPU python)=48009.31640625MB; mem (CPU total)=86900.21484375MB
INFO:root:[   56] Training loss: 0.63081269, Validation loss: 0.62079915, Gradient norm: 0.04551596
INFO:root:At the start of the epoch: mem (CPU python)=48047.41015625MB; mem (CPU total)=86975.9921875MB
INFO:root:[   57] Training loss: 0.63018283, Validation loss: 0.62061423, Gradient norm: 0.04777308
INFO:root:At the start of the epoch: mem (CPU python)=48085.50390625MB; mem (CPU total)=87052.59375MB
INFO:root:[   58] Training loss: 0.63000508, Validation loss: 0.62058634, Gradient norm: 0.04635191
INFO:root:At the start of the epoch: mem (CPU python)=48123.59765625MB; mem (CPU total)=87128.9140625MB
INFO:root:[   59] Training loss: 0.62985114, Validation loss: 0.62029107, Gradient norm: 0.04924933
INFO:root:At the start of the epoch: mem (CPU python)=48161.6953125MB; mem (CPU total)=87205.546875MB
INFO:root:[   60] Training loss: 0.62944407, Validation loss: 0.62019537, Gradient norm: 0.04510157
INFO:root:At the start of the epoch: mem (CPU python)=48199.7890625MB; mem (CPU total)=87282.33984375MB
INFO:root:[   61] Training loss: 0.62931731, Validation loss: 0.61901222, Gradient norm: 0.05104370
INFO:root:At the start of the epoch: mem (CPU python)=48237.8828125MB; mem (CPU total)=87357.7890625MB
INFO:root:[   62] Training loss: 0.62908536, Validation loss: 0.61857199, Gradient norm: 0.04715284
INFO:root:At the start of the epoch: mem (CPU python)=48275.98046875MB; mem (CPU total)=87434.01953125MB
INFO:root:[   63] Training loss: 0.62861406, Validation loss: 0.61888160, Gradient norm: 0.05090182
INFO:root:At the start of the epoch: mem (CPU python)=48314.078125MB; mem (CPU total)=87510.3359375MB
INFO:root:[   64] Training loss: 0.62845765, Validation loss: 0.61926143, Gradient norm: 0.05244782
INFO:root:At the start of the epoch: mem (CPU python)=48352.171875MB; mem (CPU total)=87586.9140625MB
INFO:root:[   65] Training loss: 0.62773831, Validation loss: 0.61820469, Gradient norm: 0.04698902
INFO:root:At the start of the epoch: mem (CPU python)=48390.265625MB; mem (CPU total)=87663.5859375MB
INFO:root:[   66] Training loss: 0.62774055, Validation loss: 0.61807324, Gradient norm: 0.04655040
INFO:root:At the start of the epoch: mem (CPU python)=48428.36328125MB; mem (CPU total)=87739.625MB
INFO:root:[   67] Training loss: 0.62717412, Validation loss: 0.61714743, Gradient norm: 0.05021287
INFO:root:At the start of the epoch: mem (CPU python)=48466.45703125MB; mem (CPU total)=87815.609375MB
INFO:root:[   68] Training loss: 0.62701571, Validation loss: 0.61807365, Gradient norm: 0.05384433
INFO:root:At the start of the epoch: mem (CPU python)=48504.55078125MB; mem (CPU total)=87892.1015625MB
INFO:root:[   69] Training loss: 0.62683217, Validation loss: 0.61722101, Gradient norm: 0.04614932
INFO:root:At the start of the epoch: mem (CPU python)=48542.6484375MB; mem (CPU total)=87968.3828125MB
INFO:root:[   70] Training loss: 0.62645666, Validation loss: 0.61733168, Gradient norm: 0.04895584
INFO:root:At the start of the epoch: mem (CPU python)=48580.7421875MB; mem (CPU total)=88048.34375MB
INFO:root:[   71] Training loss: 0.62648820, Validation loss: 0.61615699, Gradient norm: 0.05182517
INFO:root:At the start of the epoch: mem (CPU python)=48618.8359375MB; mem (CPU total)=88122.8046875MB
INFO:root:[   72] Training loss: 0.62593092, Validation loss: 0.61634917, Gradient norm: 0.05411044
INFO:root:At the start of the epoch: mem (CPU python)=48656.93359375MB; mem (CPU total)=88199.12890625MB
INFO:root:[   73] Training loss: 0.62586382, Validation loss: 0.61574991, Gradient norm: 0.06144794
INFO:root:At the start of the epoch: mem (CPU python)=48695.03125MB; mem (CPU total)=88275.40625MB
INFO:root:[   74] Training loss: 0.62572137, Validation loss: 0.61580233, Gradient norm: 0.05299808
INFO:root:At the start of the epoch: mem (CPU python)=48733.125MB; mem (CPU total)=88351.2109375MB
INFO:root:[   75] Training loss: 0.62507300, Validation loss: 0.61526208, Gradient norm: 0.04791683
INFO:root:At the start of the epoch: mem (CPU python)=48771.21875MB; mem (CPU total)=88427.69921875MB
INFO:root:[   76] Training loss: 0.62497642, Validation loss: 0.61540984, Gradient norm: 0.04694729
INFO:root:At the start of the epoch: mem (CPU python)=48809.31640625MB; mem (CPU total)=88503.73046875MB
INFO:root:[   77] Training loss: 0.62486232, Validation loss: 0.61643409, Gradient norm: 0.05267143
INFO:root:At the start of the epoch: mem (CPU python)=48847.41015625MB; mem (CPU total)=88580.578125MB
INFO:root:[   78] Training loss: 0.62447357, Validation loss: 0.61430384, Gradient norm: 0.04805699
INFO:root:At the start of the epoch: mem (CPU python)=48885.50390625MB; mem (CPU total)=88656.65234375MB
INFO:root:[   79] Training loss: 0.62452530, Validation loss: 0.61599955, Gradient norm: 0.05595952
INFO:root:At the start of the epoch: mem (CPU python)=48923.6015625MB; mem (CPU total)=88733.24609375MB
INFO:root:[   80] Training loss: 0.62425888, Validation loss: 0.61497505, Gradient norm: 0.05291408
INFO:root:At the start of the epoch: mem (CPU python)=48961.69921875MB; mem (CPU total)=88810.921875MB
INFO:root:[   81] Training loss: 0.62387908, Validation loss: 0.61553605, Gradient norm: 0.04923424
INFO:root:At the start of the epoch: mem (CPU python)=48999.79296875MB; mem (CPU total)=88889.01171875MB
INFO:root:[   82] Training loss: 0.62374218, Validation loss: 0.61514874, Gradient norm: 0.05138670
INFO:root:At the start of the epoch: mem (CPU python)=49037.88671875MB; mem (CPU total)=88966.8125MB
INFO:root:[   83] Training loss: 0.62332738, Validation loss: 0.61419113, Gradient norm: 0.05293082
INFO:root:At the start of the epoch: mem (CPU python)=49075.984375MB; mem (CPU total)=89046.30859375MB
INFO:root:[   84] Training loss: 0.62310501, Validation loss: 0.61464282, Gradient norm: 0.05275757
INFO:root:At the start of the epoch: mem (CPU python)=49114.078125MB; mem (CPU total)=89123.6171875MB
INFO:root:[   85] Training loss: 0.62285142, Validation loss: 0.61343802, Gradient norm: 0.05253463
INFO:root:At the start of the epoch: mem (CPU python)=49152.171875MB; mem (CPU total)=89202.40234375MB
INFO:root:[   86] Training loss: 0.62301666, Validation loss: 0.61326141, Gradient norm: 0.05155678
INFO:root:At the start of the epoch: mem (CPU python)=49190.26953125MB; mem (CPU total)=89279.63671875MB
INFO:root:[   87] Training loss: 0.62278524, Validation loss: 0.61297653, Gradient norm: 0.05479754
INFO:root:At the start of the epoch: mem (CPU python)=49228.36328125MB; mem (CPU total)=89358.484375MB
INFO:root:[   88] Training loss: 0.62251966, Validation loss: 0.61311342, Gradient norm: 0.05799807
INFO:root:At the start of the epoch: mem (CPU python)=49266.4609375MB; mem (CPU total)=89437.39453125MB
INFO:root:[   89] Training loss: 0.62205271, Validation loss: 0.61251720, Gradient norm: 0.05447111
INFO:root:At the start of the epoch: mem (CPU python)=49304.55859375MB; mem (CPU total)=89515.1015625MB
INFO:root:[   90] Training loss: 0.62211736, Validation loss: 0.61222848, Gradient norm: 0.05691244
INFO:root:At the start of the epoch: mem (CPU python)=49342.65234375MB; mem (CPU total)=89594.296875MB
INFO:root:[   91] Training loss: 0.62183528, Validation loss: 0.61276193, Gradient norm: 0.05045408
INFO:root:At the start of the epoch: mem (CPU python)=49380.74609375MB; mem (CPU total)=89671.08203125MB
INFO:root:[   92] Training loss: 0.62186357, Validation loss: 0.61237799, Gradient norm: 0.05538962
INFO:root:At the start of the epoch: mem (CPU python)=49418.83984375MB; mem (CPU total)=89751.0546875MB
INFO:root:[   93] Training loss: 0.62128336, Validation loss: 0.61354075, Gradient norm: 0.05112308
INFO:root:At the start of the epoch: mem (CPU python)=49456.9375MB; mem (CPU total)=89829.0234375MB
INFO:root:[   94] Training loss: 0.62134601, Validation loss: 0.61175453, Gradient norm: 0.04861757
INFO:root:At the start of the epoch: mem (CPU python)=49495.03125MB; mem (CPU total)=89908.03515625MB
INFO:root:[   95] Training loss: 0.62109392, Validation loss: 0.61183578, Gradient norm: 0.05374822
INFO:root:At the start of the epoch: mem (CPU python)=49533.125MB; mem (CPU total)=89987.0390625MB
INFO:root:[   96] Training loss: 0.62104391, Validation loss: 0.61208613, Gradient norm: 0.05380413
INFO:root:At the start of the epoch: mem (CPU python)=49571.2265625MB; mem (CPU total)=90065.546875MB
INFO:root:[   97] Training loss: 0.62071705, Validation loss: 0.61217879, Gradient norm: 0.05581187
INFO:root:At the start of the epoch: mem (CPU python)=49609.3203125MB; mem (CPU total)=90144.5390625MB
INFO:root:[   98] Training loss: 0.62050673, Validation loss: 0.61210901, Gradient norm: 0.05099765
INFO:root:At the start of the epoch: mem (CPU python)=49647.4140625MB; mem (CPU total)=90221.07421875MB
INFO:root:[   99] Training loss: 0.62051245, Validation loss: 0.61150113, Gradient norm: 0.05387328
INFO:root:At the start of the epoch: mem (CPU python)=49685.5078125MB; mem (CPU total)=90297.4609375MB
INFO:root:[  100] Training loss: 0.62017895, Validation loss: 0.61129436, Gradient norm: 0.05284704
INFO:root:At the start of the epoch: mem (CPU python)=49723.60546875MB; mem (CPU total)=90373.5MB
INFO:root:[  101] Training loss: 0.61986473, Validation loss: 0.61199867, Gradient norm: 0.05065386
INFO:root:At the start of the epoch: mem (CPU python)=49761.69921875MB; mem (CPU total)=90450.11328125MB
INFO:root:[  102] Training loss: 0.61970247, Validation loss: 0.61144190, Gradient norm: 0.05184034
INFO:root:At the start of the epoch: mem (CPU python)=49799.79296875MB; mem (CPU total)=90526.1875MB
INFO:root:[  103] Training loss: 0.61970095, Validation loss: 0.61064190, Gradient norm: 0.05332112
INFO:root:At the start of the epoch: mem (CPU python)=49837.890625MB; mem (CPU total)=90602.265625MB
INFO:root:[  104] Training loss: 0.61955873, Validation loss: 0.61141027, Gradient norm: 0.05782832
INFO:root:At the start of the epoch: mem (CPU python)=49875.984375MB; mem (CPU total)=90678.69140625MB
INFO:root:[  105] Training loss: 0.61937577, Validation loss: 0.61082479, Gradient norm: 0.05679355
INFO:root:At the start of the epoch: mem (CPU python)=49914.078125MB; mem (CPU total)=90754.78515625MB
INFO:root:[  106] Training loss: 0.61924923, Validation loss: 0.61017386, Gradient norm: 0.05632356
INFO:root:At the start of the epoch: mem (CPU python)=49952.1796875MB; mem (CPU total)=90830.19921875MB
INFO:root:[  107] Training loss: 0.61908981, Validation loss: 0.61104016, Gradient norm: 0.05502833
INFO:root:At the start of the epoch: mem (CPU python)=49990.2734375MB; mem (CPU total)=90906.99609375MB
INFO:root:[  108] Training loss: 0.61884097, Validation loss: 0.61059821, Gradient norm: 0.06282030
INFO:root:At the start of the epoch: mem (CPU python)=50028.3671875MB; mem (CPU total)=90983.32421875MB
INFO:root:[  109] Training loss: 0.61869182, Validation loss: 0.61015849, Gradient norm: 0.05285663
INFO:root:At the start of the epoch: mem (CPU python)=50066.4609375MB; mem (CPU total)=91059.640625MB
INFO:root:[  110] Training loss: 0.61840400, Validation loss: 0.60980310, Gradient norm: 0.05131619
INFO:root:At the start of the epoch: mem (CPU python)=50104.55859375MB; mem (CPU total)=91136.59765625MB
INFO:root:[  111] Training loss: 0.61831121, Validation loss: 0.60946606, Gradient norm: 0.05897482
INFO:root:At the start of the epoch: mem (CPU python)=50142.65234375MB; mem (CPU total)=91211.96484375MB
INFO:root:[  112] Training loss: 0.61838214, Validation loss: 0.61086217, Gradient norm: 0.06048340
INFO:root:At the start of the epoch: mem (CPU python)=50180.74609375MB; mem (CPU total)=91288.1875MB
INFO:root:[  113] Training loss: 0.61829016, Validation loss: 0.60969752, Gradient norm: 0.05747694
INFO:root:At the start of the epoch: mem (CPU python)=50218.84375MB; mem (CPU total)=91365.21875MB
INFO:root:[  114] Training loss: 0.61783013, Validation loss: 0.60929650, Gradient norm: 0.05082468
INFO:root:At the start of the epoch: mem (CPU python)=50256.94140625MB; mem (CPU total)=91442.1328125MB
INFO:root:[  115] Training loss: 0.61808620, Validation loss: 0.60929314, Gradient norm: 0.05464623
INFO:root:At the start of the epoch: mem (CPU python)=50295.03515625MB; mem (CPU total)=91521.12109375MB
INFO:root:[  116] Training loss: 0.61792035, Validation loss: 0.60997071, Gradient norm: 0.05706170
INFO:root:At the start of the epoch: mem (CPU python)=50333.12890625MB; mem (CPU total)=91601.64453125MB
INFO:root:[  117] Training loss: 0.61762741, Validation loss: 0.61027474, Gradient norm: 0.05621046
INFO:root:At the start of the epoch: mem (CPU python)=50371.2265625MB; mem (CPU total)=91679.66015625MB
INFO:root:[  118] Training loss: 0.61739689, Validation loss: 0.60965460, Gradient norm: 0.05861154
INFO:root:At the start of the epoch: mem (CPU python)=50409.3203125MB; mem (CPU total)=91760.04296875MB
INFO:root:[  119] Training loss: 0.61726189, Validation loss: 0.60893215, Gradient norm: 0.05204579
INFO:root:At the start of the epoch: mem (CPU python)=50447.4140625MB; mem (CPU total)=91838.390625MB
INFO:root:[  120] Training loss: 0.61691293, Validation loss: 0.60847316, Gradient norm: 0.05316499
INFO:root:At the start of the epoch: mem (CPU python)=50485.51171875MB; mem (CPU total)=91918.8984375MB
INFO:root:[  121] Training loss: 0.61706402, Validation loss: 0.60885581, Gradient norm: 0.05803796
INFO:root:At the start of the epoch: mem (CPU python)=50523.609375MB; mem (CPU total)=91997.44921875MB
INFO:root:[  122] Training loss: 0.61675776, Validation loss: 0.60842367, Gradient norm: 0.05532824
INFO:root:At the start of the epoch: mem (CPU python)=50561.703125MB; mem (CPU total)=92078.21875MB
INFO:root:[  123] Training loss: 0.61691059, Validation loss: 0.60861499, Gradient norm: 0.05392846
INFO:root:At the start of the epoch: mem (CPU python)=50599.80078125MB; mem (CPU total)=92157.44921875MB
INFO:root:[  124] Training loss: 0.61657814, Validation loss: 0.60823365, Gradient norm: 0.05502435
INFO:root:At the start of the epoch: mem (CPU python)=50637.89453125MB; mem (CPU total)=92237.44140625MB
INFO:root:[  125] Training loss: 0.61633694, Validation loss: 0.60892376, Gradient norm: 0.05193231
INFO:root:At the start of the epoch: mem (CPU python)=50675.98828125MB; mem (CPU total)=92317.734375MB
INFO:root:[  126] Training loss: 0.61623688, Validation loss: 0.60767325, Gradient norm: 0.05908990
INFO:root:At the start of the epoch: mem (CPU python)=50714.08203125MB; mem (CPU total)=92395.5234375MB
INFO:root:[  127] Training loss: 0.61615117, Validation loss: 0.60823128, Gradient norm: 0.05888068
INFO:root:At the start of the epoch: mem (CPU python)=50752.1796875MB; mem (CPU total)=92472.08984375MB
INFO:root:[  128] Training loss: 0.61612587, Validation loss: 0.60906052, Gradient norm: 0.05347405
INFO:root:At the start of the epoch: mem (CPU python)=50790.2734375MB; mem (CPU total)=92549.171875MB
INFO:root:[  129] Training loss: 0.61587333, Validation loss: 0.60751847, Gradient norm: 0.05869333
INFO:root:At the start of the epoch: mem (CPU python)=50828.3671875MB; mem (CPU total)=92625.21875MB
INFO:root:[  130] Training loss: 0.61569810, Validation loss: 0.60732911, Gradient norm: 0.05686750
INFO:root:At the start of the epoch: mem (CPU python)=50866.46875MB; mem (CPU total)=92701.78515625MB
INFO:root:[  131] Training loss: 0.61565372, Validation loss: 0.60779729, Gradient norm: 0.05899831
INFO:root:At the start of the epoch: mem (CPU python)=50904.5625MB; mem (CPU total)=92778.35546875MB
INFO:root:[  132] Training loss: 0.61539571, Validation loss: 0.60683902, Gradient norm: 0.05521111
INFO:root:At the start of the epoch: mem (CPU python)=50942.65625MB; mem (CPU total)=92854.16796875MB
INFO:root:[  133] Training loss: 0.61532060, Validation loss: 0.60731566, Gradient norm: 0.05384065
INFO:root:At the start of the epoch: mem (CPU python)=50980.75MB; mem (CPU total)=92930.44140625MB
INFO:root:[  134] Training loss: 0.61514090, Validation loss: 0.60760958, Gradient norm: 0.05460798
INFO:root:At the start of the epoch: mem (CPU python)=51018.84765625MB; mem (CPU total)=93006.51953125MB
INFO:root:[  135] Training loss: 0.61525396, Validation loss: 0.60770371, Gradient norm: 0.05793442
INFO:root:At the start of the epoch: mem (CPU python)=51056.94140625MB; mem (CPU total)=93082.99609375MB
INFO:root:[  136] Training loss: 0.61480057, Validation loss: 0.60719302, Gradient norm: 0.05277898
INFO:root:At the start of the epoch: mem (CPU python)=51095.03515625MB; mem (CPU total)=93159.54296875MB
INFO:root:[  137] Training loss: 0.61465908, Validation loss: 0.60731959, Gradient norm: 0.05638259
INFO:root:At the start of the epoch: mem (CPU python)=51133.13671875MB; mem (CPU total)=93235.62109375MB
INFO:root:[  138] Training loss: 0.61480393, Validation loss: 0.60807562, Gradient norm: 0.05699085
INFO:root:At the start of the epoch: mem (CPU python)=51171.23046875MB; mem (CPU total)=93312.46484375MB
INFO:root:[  139] Training loss: 0.61456621, Validation loss: 0.60686132, Gradient norm: 0.05845186
INFO:root:At the start of the epoch: mem (CPU python)=51209.32421875MB; mem (CPU total)=93392.76171875MB
INFO:root:[  140] Training loss: 0.61474153, Validation loss: 0.60783028, Gradient norm: 0.06312617
INFO:root:At the start of the epoch: mem (CPU python)=51247.421875MB; mem (CPU total)=93471.80078125MB
INFO:root:[  141] Training loss: 0.61463060, Validation loss: 0.60680240, Gradient norm: 0.05885071
INFO:root:At the start of the epoch: mem (CPU python)=51285.515625MB; mem (CPU total)=93552.46875MB
INFO:root:[  142] Training loss: 0.61437184, Validation loss: 0.60619689, Gradient norm: 0.05660350
INFO:root:At the start of the epoch: mem (CPU python)=51323.609375MB; mem (CPU total)=93631.5546875MB
INFO:root:[  143] Training loss: 0.61419135, Validation loss: 0.60626062, Gradient norm: 0.05750999
INFO:root:At the start of the epoch: mem (CPU python)=51361.703125MB; mem (CPU total)=93712.5546875MB
INFO:root:[  144] Training loss: 0.61424660, Validation loss: 0.60670247, Gradient norm: 0.05630552
INFO:root:At the start of the epoch: mem (CPU python)=51399.80078125MB; mem (CPU total)=93792.52734375MB
INFO:root:[  145] Training loss: 0.61389016, Validation loss: 0.60618674, Gradient norm: 0.05480182
INFO:root:At the start of the epoch: mem (CPU python)=51437.89453125MB; mem (CPU total)=93873.2265625MB
INFO:root:[  146] Training loss: 0.61394072, Validation loss: 0.60650782, Gradient norm: 0.05828890
INFO:root:At the start of the epoch: mem (CPU python)=51475.98828125MB; mem (CPU total)=93953.10546875MB
INFO:root:[  147] Training loss: 0.61372793, Validation loss: 0.60681404, Gradient norm: 0.05580247
INFO:root:At the start of the epoch: mem (CPU python)=51514.08984375MB; mem (CPU total)=94035.7734375MB
INFO:root:[  148] Training loss: 0.61324262, Validation loss: 0.60637860, Gradient norm: 0.05822954
INFO:root:At the start of the epoch: mem (CPU python)=51552.18359375MB; mem (CPU total)=94113.41015625MB
INFO:root:[  149] Training loss: 0.61350225, Validation loss: 0.60562475, Gradient norm: 0.06288908
INFO:root:At the start of the epoch: mem (CPU python)=51590.27734375MB; mem (CPU total)=94189.13671875MB
INFO:root:[  150] Training loss: 0.61350143, Validation loss: 0.60631250, Gradient norm: 0.05602777
INFO:root:At the start of the epoch: mem (CPU python)=51628.37109375MB; mem (CPU total)=94265.45703125MB
INFO:root:[  151] Training loss: 0.61350156, Validation loss: 0.60622421, Gradient norm: 0.06228198
INFO:root:At the start of the epoch: mem (CPU python)=51666.46875MB; mem (CPU total)=94342.03515625MB
INFO:root:[  152] Training loss: 0.61299328, Validation loss: 0.60576574, Gradient norm: 0.05594172
INFO:root:At the start of the epoch: mem (CPU python)=51704.5625MB; mem (CPU total)=94418.23046875MB
INFO:root:[  153] Training loss: 0.61302381, Validation loss: 0.60650491, Gradient norm: 0.05675721
INFO:root:At the start of the epoch: mem (CPU python)=51742.65625MB; mem (CPU total)=94494.51953125MB
INFO:root:[  154] Training loss: 0.61284461, Validation loss: 0.60564684, Gradient norm: 0.05680205
INFO:root:At the start of the epoch: mem (CPU python)=51780.75390625MB; mem (CPU total)=94570.74609375MB
INFO:root:[  155] Training loss: 0.61288455, Validation loss: 0.60642085, Gradient norm: 0.05779151
INFO:root:At the start of the epoch: mem (CPU python)=51818.8515625MB; mem (CPU total)=94647.265625MB
INFO:root:[  156] Training loss: 0.61268182, Validation loss: 0.60561065, Gradient norm: 0.06031114
INFO:root:At the start of the epoch: mem (CPU python)=51856.9453125MB; mem (CPU total)=94723.57421875MB
INFO:root:[  157] Training loss: 0.61274634, Validation loss: 0.60496618, Gradient norm: 0.06314256
INFO:root:At the start of the epoch: mem (CPU python)=51895.04296875MB; mem (CPU total)=94799.91796875MB
INFO:root:[  158] Training loss: 0.61271643, Validation loss: 0.60534521, Gradient norm: 0.06537435
INFO:root:At the start of the epoch: mem (CPU python)=51933.13671875MB; mem (CPU total)=94875.9921875MB
INFO:root:[  159] Training loss: 0.61242542, Validation loss: 0.60569206, Gradient norm: 0.05622480
INFO:root:At the start of the epoch: mem (CPU python)=51971.23046875MB; mem (CPU total)=94956.2109375MB
INFO:root:[  160] Training loss: 0.61221974, Validation loss: 0.60540792, Gradient norm: 0.05795702
INFO:root:At the start of the epoch: mem (CPU python)=52009.328125MB; mem (CPU total)=95036.3203125MB
INFO:root:[  161] Training loss: 0.61244097, Validation loss: 0.60572762, Gradient norm: 0.05823023
INFO:root:At the start of the epoch: mem (CPU python)=52047.42578125MB; mem (CPU total)=95117.5546875MB
INFO:root:[  162] Training loss: 0.61222108, Validation loss: 0.60575132, Gradient norm: 0.05860292
INFO:root:At the start of the epoch: mem (CPU python)=52085.51953125MB; mem (CPU total)=95197.2890625MB
INFO:root:[  163] Training loss: 0.61186922, Validation loss: 0.60606900, Gradient norm: 0.05815547
INFO:root:At the start of the epoch: mem (CPU python)=52123.61328125MB; mem (CPU total)=95271.078125MB
INFO:root:[  164] Training loss: 0.61209568, Validation loss: 0.60577268, Gradient norm: 0.05997995
INFO:root:At the start of the epoch: mem (CPU python)=52161.71484375MB; mem (CPU total)=95325.94921875MB
INFO:root:[  165] Training loss: 0.61196044, Validation loss: 0.60553388, Gradient norm: 0.05997683
INFO:root:At the start of the epoch: mem (CPU python)=52199.80859375MB; mem (CPU total)=95377.40234375MB
INFO:root:[  166] Training loss: 0.61201158, Validation loss: 0.60473050, Gradient norm: 0.06287581
INFO:root:At the start of the epoch: mem (CPU python)=52237.90234375MB; mem (CPU total)=95430.953125MB
INFO:root:[  167] Training loss: 0.61136581, Validation loss: 0.60564509, Gradient norm: 0.05854687
INFO:root:At the start of the epoch: mem (CPU python)=52275.99609375MB; mem (CPU total)=95512.6171875MB
INFO:root:[  168] Training loss: 0.61165563, Validation loss: 0.60491897, Gradient norm: 0.05697169
INFO:root:At the start of the epoch: mem (CPU python)=52314.09375MB; mem (CPU total)=95592.10546875MB
INFO:root:[  169] Training loss: 0.61169627, Validation loss: 0.60494105, Gradient norm: 0.06318715
INFO:root:At the start of the epoch: mem (CPU python)=52352.1875MB; mem (CPU total)=95673.83203125MB
INFO:root:[  170] Training loss: 0.61159329, Validation loss: 0.60511152, Gradient norm: 0.05996850
INFO:root:At the start of the epoch: mem (CPU python)=52390.28125MB; mem (CPU total)=95753.52734375MB
INFO:root:[  171] Training loss: 0.61115800, Validation loss: 0.60454012, Gradient norm: 0.05480576
INFO:root:At the start of the epoch: mem (CPU python)=52428.37890625MB; mem (CPU total)=95836.01953125MB
INFO:root:[  172] Training loss: 0.61139792, Validation loss: 0.60573582, Gradient norm: 0.06929216
INFO:root:At the start of the epoch: mem (CPU python)=52466.47265625MB; mem (CPU total)=95914.28515625MB
INFO:root:[  173] Training loss: 0.61099489, Validation loss: 0.60432932, Gradient norm: 0.05589532
INFO:root:At the start of the epoch: mem (CPU python)=52504.56640625MB; mem (CPU total)=95990.44140625MB
INFO:root:[  174] Training loss: 0.61101098, Validation loss: 0.60518984, Gradient norm: 0.06321176
INFO:root:At the start of the epoch: mem (CPU python)=52542.66796875MB; mem (CPU total)=96067.484375MB
INFO:root:[  175] Training loss: 0.61115780, Validation loss: 0.60506832, Gradient norm: 0.06596972
INFO:root:At the start of the epoch: mem (CPU python)=52580.76171875MB; mem (CPU total)=96143.52734375MB
INFO:root:[  176] Training loss: 0.61107996, Validation loss: 0.60458171, Gradient norm: 0.06204865
INFO:root:At the start of the epoch: mem (CPU python)=52618.85546875MB; mem (CPU total)=96219.5703125MB
INFO:root:[  177] Training loss: 0.61083747, Validation loss: 0.60516020, Gradient norm: 0.06291625
INFO:root:At the start of the epoch: mem (CPU python)=52656.94921875MB; mem (CPU total)=96296.08203125MB
INFO:root:[  178] Training loss: 0.61047883, Validation loss: 0.60522586, Gradient norm: 0.06158466
INFO:root:At the start of the epoch: mem (CPU python)=52695.046875MB; mem (CPU total)=96372.2890625MB
INFO:root:[  179] Training loss: 0.61067493, Validation loss: 0.60462031, Gradient norm: 0.05783432
INFO:root:At the start of the epoch: mem (CPU python)=52733.140625MB; mem (CPU total)=96448.57421875MB
INFO:root:[  180] Training loss: 0.61047984, Validation loss: 0.60399880, Gradient norm: 0.06210390
INFO:root:At the start of the epoch: mem (CPU python)=52771.23828125MB; mem (CPU total)=96525.171875MB
INFO:root:[  181] Training loss: 0.61031297, Validation loss: 0.60468552, Gradient norm: 0.06141267
INFO:root:At the start of the epoch: mem (CPU python)=52809.33203125MB; mem (CPU total)=96601.21484375MB
INFO:root:[  182] Training loss: 0.61031962, Validation loss: 0.60442324, Gradient norm: 0.05916175
INFO:root:At the start of the epoch: mem (CPU python)=52847.4296875MB; mem (CPU total)=96677.4140625MB
INFO:root:[  183] Training loss: 0.61015098, Validation loss: 0.60533069, Gradient norm: 0.05994499
INFO:root:At the start of the epoch: mem (CPU python)=52885.5234375MB; mem (CPU total)=96756.4453125MB
INFO:root:[  184] Training loss: 0.61032396, Validation loss: 0.60477792, Gradient norm: 0.06767759
INFO:root:At the start of the epoch: mem (CPU python)=52923.6171875MB; mem (CPU total)=96837.5703125MB
INFO:root:[  185] Training loss: 0.60963451, Validation loss: 0.60434805, Gradient norm: 0.05854632
INFO:root:At the start of the epoch: mem (CPU python)=52961.71484375MB; mem (CPU total)=96917.55078125MB
INFO:root:[  186] Training loss: 0.61006900, Validation loss: 0.60404091, Gradient norm: 0.05941319
INFO:root:At the start of the epoch: mem (CPU python)=52999.80859375MB; mem (CPU total)=96999.0078125MB
INFO:root:[  187] Training loss: 0.60970928, Validation loss: 0.60397623, Gradient norm: 0.06446203
INFO:root:At the start of the epoch: mem (CPU python)=53037.90234375MB; mem (CPU total)=97078.31640625MB
INFO:root:[  188] Training loss: 0.60976535, Validation loss: 0.60504535, Gradient norm: 0.06260725
INFO:root:At the start of the epoch: mem (CPU python)=53076.0MB; mem (CPU total)=97159.7734375MB
INFO:root:[  189] Training loss: 0.60988700, Validation loss: 0.60554908, Gradient norm: 0.05788151
INFO:root:At the start of the epoch: mem (CPU python)=53114.09375MB; mem (CPU total)=97239.69921875MB
INFO:root:[  190] Training loss: 0.60931695, Validation loss: 0.60394721, Gradient norm: 0.05933039
INFO:root:At the start of the epoch: mem (CPU python)=53152.1875MB; mem (CPU total)=97321.58984375MB
INFO:root:[  191] Training loss: 0.60927721, Validation loss: 0.60367839, Gradient norm: 0.05888419
INFO:root:At the start of the epoch: mem (CPU python)=53190.2890625MB; mem (CPU total)=97401.3203125MB
INFO:root:[  192] Training loss: 0.60960105, Validation loss: 0.60464307, Gradient norm: 0.06519426
INFO:root:At the start of the epoch: mem (CPU python)=53228.3828125MB; mem (CPU total)=97477.89453125MB
INFO:root:[  193] Training loss: 0.60949916, Validation loss: 0.60407509, Gradient norm: 0.06246236
INFO:root:At the start of the epoch: mem (CPU python)=53266.4765625MB; mem (CPU total)=97554.22265625MB
INFO:root:[  194] Training loss: 0.60931632, Validation loss: 0.60435387, Gradient norm: 0.06615018
INFO:root:At the start of the epoch: mem (CPU python)=53304.5703125MB; mem (CPU total)=97630.47265625MB
INFO:root:[  195] Training loss: 0.60896127, Validation loss: 0.60386634, Gradient norm: 0.05567782
INFO:root:At the start of the epoch: mem (CPU python)=53342.66796875MB; mem (CPU total)=97706.515625MB
INFO:root:[  196] Training loss: 0.60925148, Validation loss: 0.60449513, Gradient norm: 0.05885917
INFO:root:At the start of the epoch: mem (CPU python)=53380.76171875MB; mem (CPU total)=97783.265625MB
INFO:root:[  197] Training loss: 0.60893548, Validation loss: 0.60356367, Gradient norm: 0.05996098
INFO:root:At the start of the epoch: mem (CPU python)=53418.859375MB; mem (CPU total)=97859.296875MB
INFO:root:[  198] Training loss: 0.60922163, Validation loss: 0.60350804, Gradient norm: 0.06570089
INFO:root:At the start of the epoch: mem (CPU python)=53456.95703125MB; mem (CPU total)=97936.12109375MB
INFO:root:[  199] Training loss: 0.60883151, Validation loss: 0.60294741, Gradient norm: 0.05702409
INFO:root:At the start of the epoch: mem (CPU python)=53495.05078125MB; mem (CPU total)=98012.59375MB
INFO:root:[  200] Training loss: 0.60899489, Validation loss: 0.60557596, Gradient norm: 0.06518956
INFO:root:At the start of the epoch: mem (CPU python)=53533.14453125MB; mem (CPU total)=98088.57421875MB
INFO:root:[  201] Training loss: 0.60890754, Validation loss: 0.60398960, Gradient norm: 0.06264892
INFO:root:At the start of the epoch: mem (CPU python)=53571.23828125MB; mem (CPU total)=98164.89453125MB
INFO:root:[  202] Training loss: 0.60864496, Validation loss: 0.60422733, Gradient norm: 0.05939851
INFO:root:At the start of the epoch: mem (CPU python)=53609.3359375MB; mem (CPU total)=98241.8828125MB
INFO:root:[  203] Training loss: 0.60846835, Validation loss: 0.60438348, Gradient norm: 0.06406067
INFO:root:At the start of the epoch: mem (CPU python)=53647.4296875MB; mem (CPU total)=98322.7265625MB
INFO:root:[  204] Training loss: 0.60869978, Validation loss: 0.60421299, Gradient norm: 0.07004657
INFO:root:At the start of the epoch: mem (CPU python)=53685.5234375MB; mem (CPU total)=98403.46875MB
INFO:root:[  205] Training loss: 0.60860466, Validation loss: 0.60384914, Gradient norm: 0.06271847
INFO:root:At the start of the epoch: mem (CPU python)=53723.62109375MB; mem (CPU total)=98483.63671875MB
INFO:root:[  206] Training loss: 0.60842204, Validation loss: 0.60348854, Gradient norm: 0.06163656
INFO:root:At the start of the epoch: mem (CPU python)=53761.71484375MB; mem (CPU total)=98565.078125MB
INFO:root:[  207] Training loss: 0.60836019, Validation loss: 0.60336345, Gradient norm: 0.06186355
INFO:root:At the start of the epoch: mem (CPU python)=53799.8125MB; mem (CPU total)=98643.75MB
INFO:root:[  208] Training loss: 0.60845754, Validation loss: 0.60347108, Gradient norm: 0.06410010
INFO:root:At the start of the epoch: mem (CPU python)=53837.91015625MB; mem (CPU total)=98725.9453125MB
INFO:root:EP 208: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=53876.00390625MB; mem (CPU total)=98775.65625MB
INFO:root:Training the model took 18780.235s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83274
INFO:root:EnergyScoreTrain: 0.58638
INFO:root:CRPSTrain: 0.45392
INFO:root:Gaussian NLLTrain: 1.19159
INFO:root:CoverageTrain: 0.95031
INFO:root:IntervalWidthTrain: 3.24244
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.85772
INFO:root:EnergyScoreValidation: 0.60376
INFO:root:CRPSValidation: 0.46834
INFO:root:Gaussian NLLValidation: 1.22202
INFO:root:CoverageValidation: 0.94251
INFO:root:IntervalWidthValidation: 3.24322
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.85947
INFO:root:EnergyScoreTest: 0.60496
INFO:root:CRPSTest: 0.46962
INFO:root:Gaussian NLLTest: 1.22341
INFO:root:CoverageTest: 0.94278
INFO:root:IntervalWidthTest: 3.25104
INFO:root:After validation: mem (CPU python)=53950.0390625MB; mem (CPU total)=98859.59765625MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 3}
INFO:root:After creating the dataloaders: mem (CPU python)=53950.0390625MB; mem (CPU total)=98883.70703125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 50331648
INFO:root:After setting up the model: mem (CPU python)=53950.0390625MB; mem (CPU total)=98884.9375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=53950.0390625MB; mem (CPU total)=98898.6796875MB
INFO:root:[    1] Training loss: 0.72693330, Validation loss: 0.72089785, Gradient norm: 0.03091230
INFO:root:At the start of the epoch: mem (CPU python)=53958.3828125MB; mem (CPU total)=98975.0703125MB
INFO:root:[    2] Training loss: 0.71994472, Validation loss: 0.71837262, Gradient norm: 0.00647742
INFO:root:At the start of the epoch: mem (CPU python)=53996.4765625MB; mem (CPU total)=99055.3203125MB
INFO:root:[    3] Training loss: 0.71810952, Validation loss: 0.71510278, Gradient norm: 0.00849524
INFO:root:At the start of the epoch: mem (CPU python)=54034.57421875MB; mem (CPU total)=99135.79296875MB
INFO:root:[    4] Training loss: 0.71219199, Validation loss: 0.70605877, Gradient norm: 0.01770218
INFO:root:At the start of the epoch: mem (CPU python)=54072.66796875MB; mem (CPU total)=99217.6875MB
INFO:root:[    5] Training loss: 0.70553827, Validation loss: 0.69895561, Gradient norm: 0.02262327
INFO:root:At the start of the epoch: mem (CPU python)=54110.76171875MB; mem (CPU total)=99298.61328125MB
INFO:root:[    6] Training loss: 0.69926930, Validation loss: 0.69271931, Gradient norm: 0.02828549
INFO:root:At the start of the epoch: mem (CPU python)=54148.859375MB; mem (CPU total)=99378.71875MB
INFO:root:[    7] Training loss: 0.69392766, Validation loss: 0.68637887, Gradient norm: 0.02779980
INFO:root:At the start of the epoch: mem (CPU python)=54186.95703125MB; mem (CPU total)=99459.3828125MB
INFO:root:[    8] Training loss: 0.68907484, Validation loss: 0.68129714, Gradient norm: 0.02855547
INFO:root:At the start of the epoch: mem (CPU python)=54225.05078125MB; mem (CPU total)=99539.76953125MB
INFO:root:[    9] Training loss: 0.68439951, Validation loss: 0.67672330, Gradient norm: 0.02670477
INFO:root:At the start of the epoch: mem (CPU python)=54263.14453125MB; mem (CPU total)=99622.1875MB
INFO:root:[   10] Training loss: 0.68032651, Validation loss: 0.67185886, Gradient norm: 0.02816834
INFO:root:At the start of the epoch: mem (CPU python)=54301.2421875MB; mem (CPU total)=99702.13671875MB
INFO:root:[   11] Training loss: 0.67640487, Validation loss: 0.66688753, Gradient norm: 0.02797557
INFO:root:At the start of the epoch: mem (CPU python)=54339.3359375MB; mem (CPU total)=99778.1875MB
INFO:root:[   12] Training loss: 0.67298129, Validation loss: 0.66404845, Gradient norm: 0.02822215
INFO:root:At the start of the epoch: mem (CPU python)=54377.4296875MB; mem (CPU total)=99854.55078125MB
INFO:root:[   13] Training loss: 0.67009063, Validation loss: 0.66030346, Gradient norm: 0.02754598
INFO:root:At the start of the epoch: mem (CPU python)=54415.52734375MB; mem (CPU total)=99931.1171875MB
INFO:root:[   14] Training loss: 0.66736722, Validation loss: 0.65735482, Gradient norm: 0.03202149
INFO:root:At the start of the epoch: mem (CPU python)=54453.625MB; mem (CPU total)=100007.11328125MB
INFO:root:[   15] Training loss: 0.66492838, Validation loss: 0.65489724, Gradient norm: 0.03030980
INFO:root:At the start of the epoch: mem (CPU python)=54491.71875MB; mem (CPU total)=100083.1640625MB
INFO:root:[   16] Training loss: 0.66288706, Validation loss: 0.65299712, Gradient norm: 0.03168944
INFO:root:At the start of the epoch: mem (CPU python)=54529.8125MB; mem (CPU total)=100159.984375MB
INFO:root:[   17] Training loss: 0.66079736, Validation loss: 0.65055940, Gradient norm: 0.03195011
INFO:root:At the start of the epoch: mem (CPU python)=54567.91015625MB; mem (CPU total)=100236.26171875MB
INFO:root:[   18] Training loss: 0.65917817, Validation loss: 0.64904504, Gradient norm: 0.03351398
INFO:root:At the start of the epoch: mem (CPU python)=54606.0078125MB; mem (CPU total)=100313.45703125MB
INFO:root:[   19] Training loss: 0.65768928, Validation loss: 0.64803862, Gradient norm: 0.03293420
INFO:root:At the start of the epoch: mem (CPU python)=54644.09765625MB; mem (CPU total)=100389.4765625MB
INFO:root:[   20] Training loss: 0.65619400, Validation loss: 0.64572980, Gradient norm: 0.03699201
INFO:root:At the start of the epoch: mem (CPU python)=54682.19921875MB; mem (CPU total)=100465.203125MB
INFO:root:[   21] Training loss: 0.65476471, Validation loss: 0.64387530, Gradient norm: 0.03436022
INFO:root:At the start of the epoch: mem (CPU python)=54720.29296875MB; mem (CPU total)=100541.703125MB
INFO:root:[   22] Training loss: 0.65347881, Validation loss: 0.64332868, Gradient norm: 0.03772829
INFO:root:At the start of the epoch: mem (CPU python)=54758.38671875MB; mem (CPU total)=100619.05078125MB
INFO:root:[   23] Training loss: 0.65222808, Validation loss: 0.64095844, Gradient norm: 0.03764629
INFO:root:At the start of the epoch: mem (CPU python)=54796.48046875MB; mem (CPU total)=100700.78515625MB
INFO:root:[   24] Training loss: 0.65115055, Validation loss: 0.63989978, Gradient norm: 0.03713926
INFO:root:At the start of the epoch: mem (CPU python)=54834.578125MB; mem (CPU total)=100779.921875MB
INFO:root:[   25] Training loss: 0.65003321, Validation loss: 0.63950671, Gradient norm: 0.03900424
INFO:root:At the start of the epoch: mem (CPU python)=54872.671875MB; mem (CPU total)=100861.65234375MB
INFO:root:[   26] Training loss: 0.64894928, Validation loss: 0.63749245, Gradient norm: 0.03840104
INFO:root:At the start of the epoch: mem (CPU python)=54910.765625MB; mem (CPU total)=100940.49609375MB
INFO:root:[   27] Training loss: 0.64782367, Validation loss: 0.63722793, Gradient norm: 0.04121018
INFO:root:At the start of the epoch: mem (CPU python)=54948.8671875MB; mem (CPU total)=101022.4453125MB
INFO:root:[   28] Training loss: 0.64686586, Validation loss: 0.63678376, Gradient norm: 0.04745369
INFO:root:At the start of the epoch: mem (CPU python)=54986.9609375MB; mem (CPU total)=101102.44140625MB
INFO:root:[   29] Training loss: 0.64635259, Validation loss: 0.63494440, Gradient norm: 0.04476621
INFO:root:At the start of the epoch: mem (CPU python)=55025.0546875MB; mem (CPU total)=101182.9140625MB
INFO:root:[   30] Training loss: 0.64515709, Validation loss: 0.63478517, Gradient norm: 0.04342017
INFO:root:At the start of the epoch: mem (CPU python)=55063.1484375MB; mem (CPU total)=101265.33984375MB
INFO:root:[   31] Training loss: 0.64443504, Validation loss: 0.63442345, Gradient norm: 0.04162994
INFO:root:At the start of the epoch: mem (CPU python)=55101.24609375MB; mem (CPU total)=101343.07421875MB
INFO:root:[   32] Training loss: 0.64371158, Validation loss: 0.63292750, Gradient norm: 0.04532557
INFO:root:At the start of the epoch: mem (CPU python)=55139.33984375MB; mem (CPU total)=101418.92578125MB
INFO:root:[   33] Training loss: 0.64277433, Validation loss: 0.63170460, Gradient norm: 0.04800571
INFO:root:At the start of the epoch: mem (CPU python)=55177.43359375MB; mem (CPU total)=101495.6875MB
INFO:root:[   34] Training loss: 0.64213391, Validation loss: 0.63165462, Gradient norm: 0.05087838
INFO:root:At the start of the epoch: mem (CPU python)=55215.53125MB; mem (CPU total)=101571.9765625MB
INFO:root:[   35] Training loss: 0.64123732, Validation loss: 0.63089219, Gradient norm: 0.04323911
INFO:root:At the start of the epoch: mem (CPU python)=55253.625MB; mem (CPU total)=101647.98828125MB
INFO:root:[   36] Training loss: 0.64069683, Validation loss: 0.63035885, Gradient norm: 0.04837503
INFO:root:At the start of the epoch: mem (CPU python)=55291.72265625MB; mem (CPU total)=101725.015625MB
INFO:root:[   37] Training loss: 0.63989883, Validation loss: 0.62845292, Gradient norm: 0.04175195
INFO:root:At the start of the epoch: mem (CPU python)=55329.8203125MB; mem (CPU total)=101800.80078125MB
INFO:root:[   38] Training loss: 0.63948451, Validation loss: 0.62892672, Gradient norm: 0.04933331
INFO:root:At the start of the epoch: mem (CPU python)=55367.9140625MB; mem (CPU total)=101877.07421875MB
INFO:root:[   39] Training loss: 0.63862406, Validation loss: 0.62886438, Gradient norm: 0.04401744
INFO:root:At the start of the epoch: mem (CPU python)=55406.0078125MB; mem (CPU total)=101954.3828125MB
INFO:root:[   40] Training loss: 0.63817034, Validation loss: 0.62635265, Gradient norm: 0.04641989
INFO:root:At the start of the epoch: mem (CPU python)=55444.1015625MB; mem (CPU total)=102030.34765625MB
INFO:root:[   41] Training loss: 0.63761493, Validation loss: 0.62650305, Gradient norm: 0.04909260
INFO:root:At the start of the epoch: mem (CPU python)=55482.19921875MB; mem (CPU total)=102106.63671875MB
INFO:root:[   42] Training loss: 0.63719336, Validation loss: 0.62678608, Gradient norm: 0.04854506
INFO:root:At the start of the epoch: mem (CPU python)=55520.29296875MB; mem (CPU total)=102182.203125MB
INFO:root:[   43] Training loss: 0.63668387, Validation loss: 0.62578656, Gradient norm: 0.04409155
INFO:root:At the start of the epoch: mem (CPU python)=55558.38671875MB; mem (CPU total)=102260.4453125MB
INFO:root:[   44] Training loss: 0.63601878, Validation loss: 0.62567248, Gradient norm: 0.05037205
INFO:root:At the start of the epoch: mem (CPU python)=55596.484375MB; mem (CPU total)=102341.87890625MB
INFO:root:[   45] Training loss: 0.63543269, Validation loss: 0.62560845, Gradient norm: 0.04668031
INFO:root:At the start of the epoch: mem (CPU python)=55634.58203125MB; mem (CPU total)=102422.5859375MB
INFO:root:[   46] Training loss: 0.63479280, Validation loss: 0.62453318, Gradient norm: 0.04542553
INFO:root:At the start of the epoch: mem (CPU python)=55672.67578125MB; mem (CPU total)=102502.3515625MB
INFO:root:[   47] Training loss: 0.63465111, Validation loss: 0.62430263, Gradient norm: 0.05707571
INFO:root:At the start of the epoch: mem (CPU python)=55710.76953125MB; mem (CPU total)=102585.05078125MB
INFO:root:[   48] Training loss: 0.63426448, Validation loss: 0.62418399, Gradient norm: 0.04823001
INFO:root:At the start of the epoch: mem (CPU python)=55748.8671875MB; mem (CPU total)=102663.44921875MB
INFO:root:[   49] Training loss: 0.63382671, Validation loss: 0.62364920, Gradient norm: 0.05113045
INFO:root:At the start of the epoch: mem (CPU python)=55786.9609375MB; mem (CPU total)=102744.91015625MB
INFO:root:[   50] Training loss: 0.63309143, Validation loss: 0.62299428, Gradient norm: 0.04801747
INFO:root:At the start of the epoch: mem (CPU python)=55825.0546875MB; mem (CPU total)=102824.625MB
INFO:root:[   51] Training loss: 0.63284866, Validation loss: 0.62230630, Gradient norm: 0.05212731
INFO:root:At the start of the epoch: mem (CPU python)=55863.15234375MB; mem (CPU total)=102906.32421875MB
INFO:root:[   52] Training loss: 0.63243878, Validation loss: 0.62340339, Gradient norm: 0.04958181
INFO:root:At the start of the epoch: mem (CPU python)=55901.24609375MB; mem (CPU total)=102983.59375MB
INFO:root:[   53] Training loss: 0.63203647, Validation loss: 0.62192328, Gradient norm: 0.05260631
INFO:root:At the start of the epoch: mem (CPU python)=55939.34375MB; mem (CPU total)=103059.60546875MB
INFO:root:[   54] Training loss: 0.63164432, Validation loss: 0.62170840, Gradient norm: 0.05327099
INFO:root:At the start of the epoch: mem (CPU python)=55977.44140625MB; mem (CPU total)=103135.7109375MB
INFO:root:[   55] Training loss: 0.63109760, Validation loss: 0.62022305, Gradient norm: 0.05413226
INFO:root:At the start of the epoch: mem (CPU python)=56015.53515625MB; mem (CPU total)=103212.0078125MB
INFO:root:[   56] Training loss: 0.63095729, Validation loss: 0.62088357, Gradient norm: 0.05512404
INFO:root:At the start of the epoch: mem (CPU python)=56053.62890625MB; mem (CPU total)=103288.73828125MB
INFO:root:[   57] Training loss: 0.63038318, Validation loss: 0.62029286, Gradient norm: 0.05203404
INFO:root:At the start of the epoch: mem (CPU python)=56091.72265625MB; mem (CPU total)=103364.578125MB
INFO:root:[   58] Training loss: 0.62999879, Validation loss: 0.61998250, Gradient norm: 0.05148844
INFO:root:At the start of the epoch: mem (CPU python)=56129.82421875MB; mem (CPU total)=103441.578125MB
INFO:root:[   59] Training loss: 0.62965838, Validation loss: 0.61927143, Gradient norm: 0.05052730
INFO:root:At the start of the epoch: mem (CPU python)=56167.9140625MB; mem (CPU total)=103517.97265625MB
INFO:root:[   60] Training loss: 0.62939796, Validation loss: 0.61835805, Gradient norm: 0.05272404
INFO:root:At the start of the epoch: mem (CPU python)=56206.01171875MB; mem (CPU total)=103594.0MB
INFO:root:[   61] Training loss: 0.62889895, Validation loss: 0.61891549, Gradient norm: 0.05928132
INFO:root:At the start of the epoch: mem (CPU python)=56244.109375MB; mem (CPU total)=103670.484375MB
INFO:root:[   62] Training loss: 0.62869673, Validation loss: 0.61900876, Gradient norm: 0.05502967
INFO:root:At the start of the epoch: mem (CPU python)=56282.203125MB; mem (CPU total)=103746.73828125MB
INFO:root:[   63] Training loss: 0.62834111, Validation loss: 0.61807613, Gradient norm: 0.05203697
INFO:root:At the start of the epoch: mem (CPU python)=56320.296875MB; mem (CPU total)=103822.96875MB
INFO:root:[   64] Training loss: 0.62813071, Validation loss: 0.61912615, Gradient norm: 0.06010377
INFO:root:At the start of the epoch: mem (CPU python)=56358.390625MB; mem (CPU total)=103900.484375MB
INFO:root:[   65] Training loss: 0.62763963, Validation loss: 0.61826821, Gradient norm: 0.04950285
INFO:root:At the start of the epoch: mem (CPU python)=56396.48828125MB; mem (CPU total)=103981.6953125MB
INFO:root:[   66] Training loss: 0.62742813, Validation loss: 0.61711710, Gradient norm: 0.05726730
INFO:root:At the start of the epoch: mem (CPU python)=56434.58203125MB; mem (CPU total)=104060.98828125MB
INFO:root:[   67] Training loss: 0.62733083, Validation loss: 0.61723410, Gradient norm: 0.06028956
INFO:root:At the start of the epoch: mem (CPU python)=56472.67578125MB; mem (CPU total)=104143.640625MB
INFO:root:[   68] Training loss: 0.62665234, Validation loss: 0.61721254, Gradient norm: 0.05453965
INFO:root:At the start of the epoch: mem (CPU python)=56510.77734375MB; mem (CPU total)=104222.37890625MB
INFO:root:[   69] Training loss: 0.62662737, Validation loss: 0.61783731, Gradient norm: 0.05427982
INFO:root:At the start of the epoch: mem (CPU python)=56548.87109375MB; mem (CPU total)=104303.34375MB
INFO:root:[   70] Training loss: 0.62616175, Validation loss: 0.61638860, Gradient norm: 0.05206218
INFO:root:At the start of the epoch: mem (CPU python)=56586.96484375MB; mem (CPU total)=104383.86328125MB
INFO:root:[   71] Training loss: 0.62586039, Validation loss: 0.61614363, Gradient norm: 0.05426602
INFO:root:At the start of the epoch: mem (CPU python)=56625.0625MB; mem (CPU total)=104463.5078125MB
INFO:root:[   72] Training loss: 0.62559393, Validation loss: 0.61546773, Gradient norm: 0.05439677
INFO:root:At the start of the epoch: mem (CPU python)=56663.15625MB; mem (CPU total)=104546.3671875MB
INFO:root:[   73] Training loss: 0.62548160, Validation loss: 0.61586814, Gradient norm: 0.05584638
INFO:root:At the start of the epoch: mem (CPU python)=56701.25MB; mem (CPU total)=104624.3671875MB
INFO:root:[   74] Training loss: 0.62501170, Validation loss: 0.61600525, Gradient norm: 0.05491132
INFO:root:At the start of the epoch: mem (CPU python)=56739.34375MB; mem (CPU total)=104700.64453125MB
INFO:root:[   75] Training loss: 0.62462255, Validation loss: 0.61585805, Gradient norm: 0.05441148
INFO:root:At the start of the epoch: mem (CPU python)=56777.44140625MB; mem (CPU total)=104776.828125MB
INFO:root:[   76] Training loss: 0.62467132, Validation loss: 0.61599945, Gradient norm: 0.05624095
INFO:root:At the start of the epoch: mem (CPU python)=56815.5390625MB; mem (CPU total)=104853.05078125MB
INFO:root:[   77] Training loss: 0.62414457, Validation loss: 0.61543211, Gradient norm: 0.05741275
INFO:root:At the start of the epoch: mem (CPU python)=56853.6328125MB; mem (CPU total)=104929.28515625MB
INFO:root:[   78] Training loss: 0.62421170, Validation loss: 0.61458682, Gradient norm: 0.05280792
INFO:root:At the start of the epoch: mem (CPU python)=56891.73046875MB; mem (CPU total)=105005.8203125MB
INFO:root:[   79] Training loss: 0.62409552, Validation loss: 0.61396575, Gradient norm: 0.05694145
INFO:root:At the start of the epoch: mem (CPU python)=56929.82421875MB; mem (CPU total)=105082.7421875MB
INFO:root:[   80] Training loss: 0.62402606, Validation loss: 0.61431206, Gradient norm: 0.06027117
INFO:root:At the start of the epoch: mem (CPU python)=56967.91796875MB; mem (CPU total)=105158.51953125MB
INFO:root:[   81] Training loss: 0.62346048, Validation loss: 0.61428030, Gradient norm: 0.05819211
INFO:root:At the start of the epoch: mem (CPU python)=57006.01171875MB; mem (CPU total)=105234.48046875MB
INFO:root:[   82] Training loss: 0.62335095, Validation loss: 0.61451129, Gradient norm: 0.06388299
INFO:root:At the start of the epoch: mem (CPU python)=57044.109375MB; mem (CPU total)=105312.51171875MB
INFO:root:[   83] Training loss: 0.62307592, Validation loss: 0.61458613, Gradient norm: 0.06898667
INFO:root:At the start of the epoch: mem (CPU python)=57082.203125MB; mem (CPU total)=105388.6796875MB
INFO:root:[   84] Training loss: 0.62291909, Validation loss: 0.61545926, Gradient norm: 0.06178715
INFO:root:At the start of the epoch: mem (CPU python)=57120.30078125MB; mem (CPU total)=105464.8984375MB
INFO:root:[   85] Training loss: 0.62246405, Validation loss: 0.61430849, Gradient norm: 0.06616441
INFO:root:At the start of the epoch: mem (CPU python)=57158.3984375MB; mem (CPU total)=105541.4765625MB
INFO:root:[   86] Training loss: 0.62233187, Validation loss: 0.61366085, Gradient norm: 0.05559936
INFO:root:At the start of the epoch: mem (CPU python)=57196.4921875MB; mem (CPU total)=105623.625MB
INFO:root:[   87] Training loss: 0.62229101, Validation loss: 0.61288063, Gradient norm: 0.05374517
INFO:root:At the start of the epoch: mem (CPU python)=57234.5859375MB; mem (CPU total)=105703.59765625MB
INFO:root:[   88] Training loss: 0.62203882, Validation loss: 0.61377188, Gradient norm: 0.05265550
INFO:root:At the start of the epoch: mem (CPU python)=57272.68359375MB; mem (CPU total)=105785.9296875MB
INFO:root:[   89] Training loss: 0.62182938, Validation loss: 0.61222915, Gradient norm: 0.06048530
INFO:root:At the start of the epoch: mem (CPU python)=57310.77734375MB; mem (CPU total)=105866.4375MB
INFO:root:[   90] Training loss: 0.62159414, Validation loss: 0.61260182, Gradient norm: 0.05994863
INFO:root:At the start of the epoch: mem (CPU python)=57348.87109375MB; mem (CPU total)=105947.09375MB
INFO:root:[   91] Training loss: 0.62139134, Validation loss: 0.61446872, Gradient norm: 0.05304604
INFO:root:At the start of the epoch: mem (CPU python)=57386.96484375MB; mem (CPU total)=106029.58203125MB
INFO:root:[   92] Training loss: 0.62132508, Validation loss: 0.61206530, Gradient norm: 0.05725632
INFO:root:At the start of the epoch: mem (CPU python)=57425.0625MB; mem (CPU total)=106110.08984375MB
INFO:root:[   93] Training loss: 0.62113335, Validation loss: 0.61348086, Gradient norm: 0.06359351
INFO:root:At the start of the epoch: mem (CPU python)=57463.15625MB; mem (CPU total)=106189.53125MB
INFO:root:[   94] Training loss: 0.62072240, Validation loss: 0.61163136, Gradient norm: 0.06088264
INFO:root:At the start of the epoch: mem (CPU python)=57501.2578125MB; mem (CPU total)=106266.08984375MB
INFO:root:[   95] Training loss: 0.62080087, Validation loss: 0.61259301, Gradient norm: 0.06703706
INFO:root:At the start of the epoch: mem (CPU python)=57539.35546875MB; mem (CPU total)=106342.171875MB
INFO:root:[   96] Training loss: 0.62042786, Validation loss: 0.61171617, Gradient norm: 0.05220201
INFO:root:At the start of the epoch: mem (CPU python)=57577.44921875MB; mem (CPU total)=106418.69921875MB
INFO:root:[   97] Training loss: 0.62032756, Validation loss: 0.61173387, Gradient norm: 0.05525821
INFO:root:At the start of the epoch: mem (CPU python)=57615.54296875MB; mem (CPU total)=106495.2578125MB
INFO:root:[   98] Training loss: 0.62019084, Validation loss: 0.61107880, Gradient norm: 0.05548802
INFO:root:At the start of the epoch: mem (CPU python)=57653.63671875MB; mem (CPU total)=106571.421875MB
INFO:root:[   99] Training loss: 0.61999603, Validation loss: 0.61115611, Gradient norm: 0.06008219
INFO:root:At the start of the epoch: mem (CPU python)=57691.734375MB; mem (CPU total)=106647.8671875MB
INFO:root:[  100] Training loss: 0.61994952, Validation loss: 0.61018073, Gradient norm: 0.05788391
INFO:root:At the start of the epoch: mem (CPU python)=57729.828125MB; mem (CPU total)=106724.2734375MB
INFO:root:[  101] Training loss: 0.61970439, Validation loss: 0.61010334, Gradient norm: 0.06023551
INFO:root:At the start of the epoch: mem (CPU python)=57767.921875MB; mem (CPU total)=106800.5546875MB
INFO:root:[  102] Training loss: 0.61975667, Validation loss: 0.61207049, Gradient norm: 0.07107181
INFO:root:At the start of the epoch: mem (CPU python)=57806.0234375MB; mem (CPU total)=106877.125MB
INFO:root:[  103] Training loss: 0.61928111, Validation loss: 0.61042142, Gradient norm: 0.06234778
INFO:root:At the start of the epoch: mem (CPU python)=57844.1171875MB; mem (CPU total)=106954.1484375MB
INFO:root:[  104] Training loss: 0.61924032, Validation loss: 0.60934948, Gradient norm: 0.06147144
INFO:root:At the start of the epoch: mem (CPU python)=57882.2109375MB; mem (CPU total)=107030.13671875MB
INFO:root:[  105] Training loss: 0.61894686, Validation loss: 0.61121616, Gradient norm: 0.05808271
INFO:root:At the start of the epoch: mem (CPU python)=57920.30859375MB; mem (CPU total)=107109.68359375MB
INFO:root:[  106] Training loss: 0.61880771, Validation loss: 0.61028760, Gradient norm: 0.05583468
INFO:root:At the start of the epoch: mem (CPU python)=57958.40234375MB; mem (CPU total)=107190.13671875MB
INFO:root:[  107] Training loss: 0.61871130, Validation loss: 0.61025923, Gradient norm: 0.05442892
INFO:root:At the start of the epoch: mem (CPU python)=57996.49609375MB; mem (CPU total)=107269.6484375MB
INFO:root:[  108] Training loss: 0.61861567, Validation loss: 0.61074931, Gradient norm: 0.05874221
INFO:root:At the start of the epoch: mem (CPU python)=58034.58984375MB; mem (CPU total)=107351.390625MB
INFO:root:[  109] Training loss: 0.61849535, Validation loss: 0.61068811, Gradient norm: 0.06255218
INFO:root:At the start of the epoch: mem (CPU python)=58072.6875MB; mem (CPU total)=107430.51953125MB
INFO:root:[  110] Training loss: 0.61790718, Validation loss: 0.60995643, Gradient norm: 0.05863002
INFO:root:At the start of the epoch: mem (CPU python)=58110.78515625MB; mem (CPU total)=107511.6875MB
INFO:root:[  111] Training loss: 0.61836805, Validation loss: 0.61043502, Gradient norm: 0.06349040
INFO:root:At the start of the epoch: mem (CPU python)=58148.87890625MB; mem (CPU total)=107591.79296875MB
INFO:root:[  112] Training loss: 0.61802263, Validation loss: 0.60919111, Gradient norm: 0.06223105
INFO:root:At the start of the epoch: mem (CPU python)=58186.9765625MB; mem (CPU total)=107670.05859375MB
INFO:root:[  113] Training loss: 0.61790563, Validation loss: 0.60932172, Gradient norm: 0.05388724
INFO:root:At the start of the epoch: mem (CPU python)=58225.0703125MB; mem (CPU total)=107752.29296875MB
INFO:root:[  114] Training loss: 0.61769015, Validation loss: 0.60916505, Gradient norm: 0.05820255
INFO:root:At the start of the epoch: mem (CPU python)=58263.1640625MB; mem (CPU total)=107830.95703125MB
INFO:root:[  115] Training loss: 0.61778702, Validation loss: 0.60959198, Gradient norm: 0.06743775
INFO:root:At the start of the epoch: mem (CPU python)=58301.2578125MB; mem (CPU total)=107907.2421875MB
INFO:root:[  116] Training loss: 0.61768856, Validation loss: 0.60884307, Gradient norm: 0.05897412
INFO:root:At the start of the epoch: mem (CPU python)=58339.35546875MB; mem (CPU total)=107986.68359375MB
INFO:root:[  117] Training loss: 0.61733392, Validation loss: 0.60990043, Gradient norm: 0.05673503
INFO:root:At the start of the epoch: mem (CPU python)=58377.44921875MB; mem (CPU total)=108043.3046875MB
INFO:root:[  118] Training loss: 0.61722281, Validation loss: 0.60909304, Gradient norm: 0.06517021
INFO:root:At the start of the epoch: mem (CPU python)=58415.546875MB; mem (CPU total)=108099.6875MB
INFO:root:[  119] Training loss: 0.61698428, Validation loss: 0.60907414, Gradient norm: 0.05783662
INFO:root:At the start of the epoch: mem (CPU python)=58453.64453125MB; mem (CPU total)=108142.1171875MB
INFO:root:[  120] Training loss: 0.61690516, Validation loss: 0.60873871, Gradient norm: 0.05877375
INFO:root:At the start of the epoch: mem (CPU python)=58491.73828125MB; mem (CPU total)=108218.33203125MB
INFO:root:[  121] Training loss: 0.61668743, Validation loss: 0.60931941, Gradient norm: 0.06445834
INFO:root:At the start of the epoch: mem (CPU python)=58529.83203125MB; mem (CPU total)=108294.95703125MB
INFO:root:[  122] Training loss: 0.61663985, Validation loss: 0.60853543, Gradient norm: 0.06072022
INFO:root:At the start of the epoch: mem (CPU python)=58567.9296875MB; mem (CPU total)=108371.6640625MB
INFO:root:[  123] Training loss: 0.61653109, Validation loss: 0.60880127, Gradient norm: 0.05587346
INFO:root:At the start of the epoch: mem (CPU python)=58606.0234375MB; mem (CPU total)=108447.7734375MB
INFO:root:[  124] Training loss: 0.61645128, Validation loss: 0.60835435, Gradient norm: 0.05693730
INFO:root:At the start of the epoch: mem (CPU python)=58644.1171875MB; mem (CPU total)=108523.60546875MB
INFO:root:[  125] Training loss: 0.61624813, Validation loss: 0.60866063, Gradient norm: 0.06260590
INFO:root:At the start of the epoch: mem (CPU python)=58682.2109375MB; mem (CPU total)=108600.42578125MB
INFO:root:[  126] Training loss: 0.61628840, Validation loss: 0.60799070, Gradient norm: 0.06211395
INFO:root:At the start of the epoch: mem (CPU python)=58720.30859375MB; mem (CPU total)=108675.515625MB
INFO:root:[  127] Training loss: 0.61604212, Validation loss: 0.60778699, Gradient norm: 0.06179230
INFO:root:At the start of the epoch: mem (CPU python)=58758.40625MB; mem (CPU total)=108750.99609375MB
INFO:root:[  128] Training loss: 0.61577279, Validation loss: 0.60868166, Gradient norm: 0.05769319
INFO:root:At the start of the epoch: mem (CPU python)=58796.49609375MB; mem (CPU total)=108831.0234375MB
INFO:root:[  129] Training loss: 0.61557549, Validation loss: 0.60809671, Gradient norm: 0.05583028
INFO:root:At the start of the epoch: mem (CPU python)=58834.59765625MB; mem (CPU total)=108908.78125MB
INFO:root:[  130] Training loss: 0.61562349, Validation loss: 0.60744921, Gradient norm: 0.06741815
INFO:root:At the start of the epoch: mem (CPU python)=58872.69140625MB; mem (CPU total)=108990.01953125MB
INFO:root:[  131] Training loss: 0.61533790, Validation loss: 0.60833088, Gradient norm: 0.06174212
INFO:root:At the start of the epoch: mem (CPU python)=58910.78515625MB; mem (CPU total)=109068.29296875MB
INFO:root:[  132] Training loss: 0.61544967, Validation loss: 0.60807840, Gradient norm: 0.06350267
INFO:root:At the start of the epoch: mem (CPU python)=58948.87890625MB; mem (CPU total)=109146.82421875MB
INFO:root:[  133] Training loss: 0.61543387, Validation loss: 0.60701850, Gradient norm: 0.06224663
INFO:root:At the start of the epoch: mem (CPU python)=58986.9765625MB; mem (CPU total)=109226.8125MB
INFO:root:[  134] Training loss: 0.61515915, Validation loss: 0.60838216, Gradient norm: 0.06234551
INFO:root:At the start of the epoch: mem (CPU python)=59025.0703125MB; mem (CPU total)=109305.984375MB
INFO:root:[  135] Training loss: 0.61528183, Validation loss: 0.60738806, Gradient norm: 0.06733128
INFO:root:At the start of the epoch: mem (CPU python)=59063.1640625MB; mem (CPU total)=109384.91015625MB
INFO:root:[  136] Training loss: 0.61506630, Validation loss: 0.60776177, Gradient norm: 0.06644237
INFO:root:At the start of the epoch: mem (CPU python)=59101.26171875MB; mem (CPU total)=109463.6171875MB
INFO:root:[  137] Training loss: 0.61495052, Validation loss: 0.60623674, Gradient norm: 0.06280533
INFO:root:At the start of the epoch: mem (CPU python)=59139.359375MB; mem (CPU total)=109544.8984375MB
INFO:root:[  138] Training loss: 0.61471797, Validation loss: 0.60677943, Gradient norm: 0.06151041
INFO:root:At the start of the epoch: mem (CPU python)=59177.453125MB; mem (CPU total)=109621.953125MB
INFO:root:[  139] Training loss: 0.61456338, Validation loss: 0.60660020, Gradient norm: 0.06024454
INFO:root:At the start of the epoch: mem (CPU python)=59215.55078125MB; mem (CPU total)=109701.71484375MB
INFO:root:[  140] Training loss: 0.61461435, Validation loss: 0.60752299, Gradient norm: 0.06489856
INFO:root:At the start of the epoch: mem (CPU python)=59253.64453125MB; mem (CPU total)=109782.1875MB
INFO:root:[  141] Training loss: 0.61424873, Validation loss: 0.60758521, Gradient norm: 0.06073279
INFO:root:At the start of the epoch: mem (CPU python)=59291.73828125MB; mem (CPU total)=109858.73046875MB
INFO:root:[  142] Training loss: 0.61412632, Validation loss: 0.60767606, Gradient norm: 0.06476328
INFO:root:At the start of the epoch: mem (CPU python)=59329.83203125MB; mem (CPU total)=109934.15625MB
INFO:root:[  143] Training loss: 0.61415067, Validation loss: 0.60642346, Gradient norm: 0.06460293
INFO:root:At the start of the epoch: mem (CPU python)=59367.93359375MB; mem (CPU total)=110010.73046875MB
INFO:root:[  144] Training loss: 0.61413332, Validation loss: 0.60595883, Gradient norm: 0.06376767
INFO:root:At the start of the epoch: mem (CPU python)=59406.02734375MB; mem (CPU total)=110088.6796875MB
INFO:root:[  145] Training loss: 0.61368455, Validation loss: 0.60724412, Gradient norm: 0.06224223
INFO:root:At the start of the epoch: mem (CPU python)=59444.12109375MB; mem (CPU total)=110163.80859375MB
INFO:root:[  146] Training loss: 0.61403316, Validation loss: 0.60758171, Gradient norm: 0.06016262
INFO:root:At the start of the epoch: mem (CPU python)=59482.21875MB; mem (CPU total)=110239.86328125MB
INFO:root:[  147] Training loss: 0.61380771, Validation loss: 0.60682051, Gradient norm: 0.06628397
INFO:root:At the start of the epoch: mem (CPU python)=59520.3203125MB; mem (CPU total)=110315.98828125MB
INFO:root:[  148] Training loss: 0.61368639, Validation loss: 0.60639658, Gradient norm: 0.06691758
INFO:root:At the start of the epoch: mem (CPU python)=59558.4140625MB; mem (CPU total)=110392.5625MB
INFO:root:[  149] Training loss: 0.61361456, Validation loss: 0.60754765, Gradient norm: 0.06304282
INFO:root:At the start of the epoch: mem (CPU python)=59596.5078125MB; mem (CPU total)=110468.82421875MB
INFO:root:[  150] Training loss: 0.61372557, Validation loss: 0.60757631, Gradient norm: 0.06373614
INFO:root:At the start of the epoch: mem (CPU python)=59634.609375MB; mem (CPU total)=110545.41796875MB
INFO:root:[  151] Training loss: 0.61339172, Validation loss: 0.60621335, Gradient norm: 0.07126401
INFO:root:At the start of the epoch: mem (CPU python)=59672.6796875MB; mem (CPU total)=110602.60546875MB
INFO:root:[  152] Training loss: 0.61355738, Validation loss: 0.60611976, Gradient norm: 0.06436162
INFO:root:At the start of the epoch: mem (CPU python)=59710.7734375MB; mem (CPU total)=110678.84375MB
INFO:root:[  153] Training loss: 0.61333089, Validation loss: 0.60541195, Gradient norm: 0.06782316
INFO:root:At the start of the epoch: mem (CPU python)=59748.87109375MB; mem (CPU total)=110756.13671875MB
INFO:root:[  154] Training loss: 0.61316456, Validation loss: 0.60609301, Gradient norm: 0.06940215
INFO:root:At the start of the epoch: mem (CPU python)=59786.9609375MB; mem (CPU total)=110829.890625MB
INFO:root:[  155] Training loss: 0.61276034, Validation loss: 0.60679647, Gradient norm: 0.05649497
INFO:root:At the start of the epoch: mem (CPU python)=59825.0546875MB; mem (CPU total)=110904.73828125MB
INFO:root:[  156] Training loss: 0.61312904, Validation loss: 0.60571146, Gradient norm: 0.06201121
INFO:root:At the start of the epoch: mem (CPU python)=59863.15234375MB; mem (CPU total)=110978.86328125MB
INFO:root:[  157] Training loss: 0.61290908, Validation loss: 0.60607223, Gradient norm: 0.05861586
INFO:root:At the start of the epoch: mem (CPU python)=59901.24609375MB; mem (CPU total)=111058.71484375MB
INFO:root:[  158] Training loss: 0.61269342, Validation loss: 0.60605132, Gradient norm: 0.06124355
INFO:root:At the start of the epoch: mem (CPU python)=59939.33984375MB; mem (CPU total)=111131.06640625MB
INFO:root:[  159] Training loss: 0.61267814, Validation loss: 0.60570573, Gradient norm: 0.06742808
INFO:root:At the start of the epoch: mem (CPU python)=59977.43359375MB; mem (CPU total)=111207.94140625MB
INFO:root:[  160] Training loss: 0.61258023, Validation loss: 0.60593132, Gradient norm: 0.06241131
INFO:root:At the start of the epoch: mem (CPU python)=60015.53515625MB; mem (CPU total)=111283.75390625MB
INFO:root:[  161] Training loss: 0.61239845, Validation loss: 0.60672595, Gradient norm: 0.06820797
INFO:root:At the start of the epoch: mem (CPU python)=60053.62890625MB; mem (CPU total)=111360.83984375MB
INFO:root:[  162] Training loss: 0.61230316, Validation loss: 0.60673071, Gradient norm: 0.06678078
INFO:root:At the start of the epoch: mem (CPU python)=60091.72265625MB; mem (CPU total)=111440.05078125MB
INFO:root:EP 162: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=60129.8203125MB; mem (CPU total)=111498.1328125MB
INFO:root:Training the model took 16248.545s.
INFO:root:Emptying the cuda cache took 0.003s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84114
INFO:root:EnergyScoreTrain: 0.59216
INFO:root:CRPSTrain: 0.45966
INFO:root:Gaussian NLLTrain: 1.1867
INFO:root:CoverageTrain: 0.94962
INFO:root:IntervalWidthTrain: 3.25325
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86071
INFO:root:EnergyScoreValidation: 0.60583
INFO:root:CRPSValidation: 0.47135
INFO:root:Gaussian NLLValidation: 1.21397
INFO:root:CoverageValidation: 0.94322
INFO:root:IntervalWidthValidation: 3.25585
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86185
INFO:root:EnergyScoreTest: 0.60661
INFO:root:CRPSTest: 0.47202
INFO:root:Gaussian NLLTest: 1.21502
INFO:root:CoverageTest: 0.9432
INFO:root:IntervalWidthTest: 3.25849
INFO:root:After validation: mem (CPU python)=60202.23828125MB; mem (CPU total)=111560.13671875MB
