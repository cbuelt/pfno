INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=574.9921875MB; mem (CPU total)=33605.46875MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples3.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12453.96875MB; mem (CPU total)=33679.9609375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=12453.96875MB; mem (CPU total)=33679.9609375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12453.96875MB; mem (CPU total)=35021.0703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=35029.30078125MB
INFO:root:[    1] Training loss: 0.77904213, Validation loss: 0.72697477, Gradient norm: 0.43296064
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=36791.99609375MB
INFO:root:[    2] Training loss: 0.72355524, Validation loss: 0.72218628, Gradient norm: 0.26672614
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=36863.2109375MB
INFO:root:[    3] Training loss: 0.72125144, Validation loss: 0.72212162, Gradient norm: 0.26849184
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=36937.5625MB
INFO:root:[    4] Training loss: 0.72048594, Validation loss: 0.72095890, Gradient norm: 0.25335754
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37012.7109375MB
INFO:root:[    5] Training loss: 0.72005048, Validation loss: 0.72070569, Gradient norm: 0.23187863
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37086.02734375MB
INFO:root:[    6] Training loss: 0.71969245, Validation loss: 0.72014746, Gradient norm: 0.16821984
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37164.55859375MB
INFO:root:[    7] Training loss: 0.71946477, Validation loss: 0.71979462, Gradient norm: 0.20656164
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37244.41015625MB
INFO:root:[    8] Training loss: 0.71900989, Validation loss: 0.71948909, Gradient norm: 0.20779702
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37325.65625MB
INFO:root:[    9] Training loss: 0.71830367, Validation loss: 0.71848999, Gradient norm: 0.17681102
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37405.76171875MB
INFO:root:[   10] Training loss: 0.71636080, Validation loss: 0.71321217, Gradient norm: 0.15233950
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37487.265625MB
INFO:root:[   11] Training loss: 0.70795124, Validation loss: 0.70295406, Gradient norm: 0.19512664
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37567.7421875MB
INFO:root:[   12] Training loss: 0.69823269, Validation loss: 0.69412036, Gradient norm: 0.12937699
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37647.91015625MB
INFO:root:[   13] Training loss: 0.69012827, Validation loss: 0.68702360, Gradient norm: 0.11938835
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37706.94140625MB
INFO:root:[   14] Training loss: 0.68364071, Validation loss: 0.68185974, Gradient norm: 0.11743224
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37759.96875MB
INFO:root:[   15] Training loss: 0.67817610, Validation loss: 0.67683606, Gradient norm: 0.08875690
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37810.4296875MB
INFO:root:[   16] Training loss: 0.67383133, Validation loss: 0.67303717, Gradient norm: 0.10692968
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37849.8984375MB
INFO:root:[   17] Training loss: 0.67014615, Validation loss: 0.66886971, Gradient norm: 0.09532268
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=37926.7890625MB
INFO:root:[   18] Training loss: 0.66690528, Validation loss: 0.66633258, Gradient norm: 0.10873327
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38002.15234375MB
INFO:root:[   19] Training loss: 0.66410279, Validation loss: 0.66442618, Gradient norm: 0.11125379
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38077.6796875MB
INFO:root:[   20] Training loss: 0.66160383, Validation loss: 0.66247539, Gradient norm: 0.13315306
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38155.8984375MB
INFO:root:[   21] Training loss: 0.65935955, Validation loss: 0.65962366, Gradient norm: 0.10824772
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38237.64453125MB
INFO:root:[   22] Training loss: 0.65737463, Validation loss: 0.65853146, Gradient norm: 0.11423776
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38321.60546875MB
INFO:root:[   23] Training loss: 0.65556000, Validation loss: 0.65648234, Gradient norm: 0.08534660
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38404.17578125MB
INFO:root:[   24] Training loss: 0.65377905, Validation loss: 0.65499223, Gradient norm: 0.08677576
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38485.1796875MB
INFO:root:[   25] Training loss: 0.65215435, Validation loss: 0.65351449, Gradient norm: 0.09825167
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38566.11328125MB
INFO:root:[   26] Training loss: 0.65076129, Validation loss: 0.65271703, Gradient norm: 0.08733948
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38649.34375MB
INFO:root:[   27] Training loss: 0.64926581, Validation loss: 0.65099389, Gradient norm: 0.09212679
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38727.09765625MB
INFO:root:[   28] Training loss: 0.64802463, Validation loss: 0.64947851, Gradient norm: 0.10074984
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38803.515625MB
INFO:root:[   29] Training loss: 0.64685828, Validation loss: 0.64864219, Gradient norm: 0.09748635
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38879.953125MB
INFO:root:[   30] Training loss: 0.64550653, Validation loss: 0.64767784, Gradient norm: 0.09850532
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=38956.0MB
INFO:root:[   31] Training loss: 0.64442158, Validation loss: 0.64693748, Gradient norm: 0.13919372
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39032.4453125MB
INFO:root:[   32] Training loss: 0.64339046, Validation loss: 0.64623055, Gradient norm: 0.11444790
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39108.90234375MB
INFO:root:[   33] Training loss: 0.64230577, Validation loss: 0.64516032, Gradient norm: 0.09124596
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39184.91015625MB
INFO:root:[   34] Training loss: 0.64121729, Validation loss: 0.64373209, Gradient norm: 0.12184318
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39263.2890625MB
INFO:root:[   35] Training loss: 0.64017348, Validation loss: 0.64325689, Gradient norm: 0.11247959
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39344.8046875MB
INFO:root:[   36] Training loss: 0.63928760, Validation loss: 0.64291040, Gradient norm: 0.11432389
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39424.90625MB
INFO:root:[   37] Training loss: 0.63841228, Validation loss: 0.64201845, Gradient norm: 0.10478893
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39506.8125MB
INFO:root:[   38] Training loss: 0.63736818, Validation loss: 0.64051187, Gradient norm: 0.11578901
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39588.515625MB
INFO:root:[   39] Training loss: 0.63639990, Validation loss: 0.63985637, Gradient norm: 0.08849559
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39670.625MB
INFO:root:[   40] Training loss: 0.63573455, Validation loss: 0.63933808, Gradient norm: 0.11874409
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39751.6796875MB
INFO:root:[   41] Training loss: 0.63485810, Validation loss: 0.63893947, Gradient norm: 0.13260681
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39832.60546875MB
INFO:root:[   42] Training loss: 0.63404005, Validation loss: 0.63820514, Gradient norm: 0.11577938
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39909.1953125MB
INFO:root:[   43] Training loss: 0.63327349, Validation loss: 0.63750814, Gradient norm: 0.10419973
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=39985.45703125MB
INFO:root:[   44] Training loss: 0.63264940, Validation loss: 0.63686684, Gradient norm: 0.15871599
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40061.80078125MB
INFO:root:[   45] Training loss: 0.63186891, Validation loss: 0.63616990, Gradient norm: 0.10875396
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40138.5546875MB
INFO:root:[   46] Training loss: 0.63143718, Validation loss: 0.63537375, Gradient norm: 0.11831440
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40216.75390625MB
INFO:root:[   47] Training loss: 0.63042226, Validation loss: 0.63505966, Gradient norm: 0.12669986
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40292.76171875MB
INFO:root:[   48] Training loss: 0.62998221, Validation loss: 0.63445713, Gradient norm: 0.10287160
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40369.27734375MB
INFO:root:[   49] Training loss: 0.62941074, Validation loss: 0.63474872, Gradient norm: 0.13868485
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40446.64453125MB
INFO:root:[   50] Training loss: 0.62878012, Validation loss: 0.63325255, Gradient norm: 0.11799104
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40526.38671875MB
INFO:root:[   51] Training loss: 0.62806998, Validation loss: 0.63291996, Gradient norm: 0.09653657
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40607.85546875MB
INFO:root:[   52] Training loss: 0.62752010, Validation loss: 0.63294573, Gradient norm: 0.11640761
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40689.57421875MB
INFO:root:[   53] Training loss: 0.62702099, Validation loss: 0.63243022, Gradient norm: 0.11088084
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40770.87890625MB
INFO:root:[   54] Training loss: 0.62647498, Validation loss: 0.63169393, Gradient norm: 0.10905993
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40849.86328125MB
INFO:root:[   55] Training loss: 0.62609147, Validation loss: 0.63141608, Gradient norm: 0.11608975
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=40931.04296875MB
INFO:root:[   56] Training loss: 0.62541516, Validation loss: 0.63111212, Gradient norm: 0.13067980
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41012.88671875MB
INFO:root:[   57] Training loss: 0.62494088, Validation loss: 0.63050647, Gradient norm: 0.11284748
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41093.7890625MB
INFO:root:[   58] Training loss: 0.62451757, Validation loss: 0.63045723, Gradient norm: 0.12107639
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41170.59765625MB
INFO:root:[   59] Training loss: 0.62416581, Validation loss: 0.63007026, Gradient norm: 0.14970506
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41248.3828125MB
INFO:root:[   60] Training loss: 0.62354030, Validation loss: 0.62969472, Gradient norm: 0.13009369
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41325.23046875MB
INFO:root:[   61] Training loss: 0.62306080, Validation loss: 0.62960734, Gradient norm: 0.12335469
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41401.734375MB
INFO:root:[   62] Training loss: 0.62257876, Validation loss: 0.62887833, Gradient norm: 0.11443217
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41477.95703125MB
INFO:root:[   63] Training loss: 0.62224847, Validation loss: 0.62888267, Gradient norm: 0.15070898
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41554.3515625MB
INFO:root:[   64] Training loss: 0.62189288, Validation loss: 0.62801589, Gradient norm: 0.15615251
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41630.40625MB
INFO:root:[   65] Training loss: 0.62149194, Validation loss: 0.62801179, Gradient norm: 0.15079453
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41706.640625MB
INFO:root:[   66] Training loss: 0.62107127, Validation loss: 0.62798881, Gradient norm: 0.14697197
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41782.828125MB
INFO:root:[   67] Training loss: 0.62047014, Validation loss: 0.62778186, Gradient norm: 0.13632014
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41859.03125MB
INFO:root:[   68] Training loss: 0.62024242, Validation loss: 0.62747340, Gradient norm: 0.11548939
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=41937.99609375MB
INFO:root:[   69] Training loss: 0.61987334, Validation loss: 0.62713598, Gradient norm: 0.13993137
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42019.375MB
INFO:root:[   70] Training loss: 0.61928566, Validation loss: 0.62673050, Gradient norm: 0.13418970
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42100.34765625MB
INFO:root:[   71] Training loss: 0.61905474, Validation loss: 0.62580165, Gradient norm: 0.11351607
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42179.78125MB
INFO:root:[   72] Training loss: 0.61876161, Validation loss: 0.62594366, Gradient norm: 0.14177419
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42259.671875MB
INFO:root:[   73] Training loss: 0.61840577, Validation loss: 0.62571855, Gradient norm: 0.13232426
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42340.58203125MB
INFO:root:[   74] Training loss: 0.61795655, Validation loss: 0.62614313, Gradient norm: 0.13395119
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42421.1953125MB
INFO:root:[   75] Training loss: 0.61773187, Validation loss: 0.62636526, Gradient norm: 0.14792134
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42499.64453125MB
INFO:root:[   76] Training loss: 0.61745045, Validation loss: 0.62527116, Gradient norm: 0.18241605
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42580.55078125MB
INFO:root:[   77] Training loss: 0.61684080, Validation loss: 0.62533791, Gradient norm: 0.14000383
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42659.2421875MB
INFO:root:[   78] Training loss: 0.61651799, Validation loss: 0.62539377, Gradient norm: 0.16116353
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42735.015625MB
INFO:root:[   79] Training loss: 0.61642353, Validation loss: 0.62504363, Gradient norm: 0.13408354
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42812.48828125MB
INFO:root:[   80] Training loss: 0.61601432, Validation loss: 0.62559009, Gradient norm: 0.12385859
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42888.72265625MB
INFO:root:[   81] Training loss: 0.61570803, Validation loss: 0.62458906, Gradient norm: 0.15346206
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=42965.4453125MB
INFO:root:[   82] Training loss: 0.61535900, Validation loss: 0.62484931, Gradient norm: 0.16156480
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43041.3984375MB
INFO:root:[   83] Training loss: 0.61506893, Validation loss: 0.62454174, Gradient norm: 0.13970354
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43117.3671875MB
INFO:root:[   84] Training loss: 0.61489372, Validation loss: 0.62423722, Gradient norm: 0.22410616
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43193.921875MB
INFO:root:[   85] Training loss: 0.61455652, Validation loss: 0.62440407, Gradient norm: 0.13763511
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43270.15625MB
INFO:root:[   86] Training loss: 0.61415628, Validation loss: 0.62335720, Gradient norm: 0.16991029
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43348.140625MB
INFO:root:[   87] Training loss: 0.61387908, Validation loss: 0.62396115, Gradient norm: 0.19448478
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43424.48828125MB
INFO:root:[   88] Training loss: 0.61366884, Validation loss: 0.62316581, Gradient norm: 0.17731871
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43500.8828125MB
INFO:root:[   89] Training loss: 0.61346024, Validation loss: 0.62247272, Gradient norm: 0.16396477
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43576.953125MB
INFO:root:[   90] Training loss: 0.61296800, Validation loss: 0.62280671, Gradient norm: 0.15338337
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43655.921875MB
INFO:root:[   91] Training loss: 0.61278596, Validation loss: 0.62314287, Gradient norm: 0.19430869
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43735.44921875MB
INFO:root:[   92] Training loss: 0.61252353, Validation loss: 0.62282506, Gradient norm: 0.18602338
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43816.125MB
INFO:root:[   93] Training loss: 0.61227017, Validation loss: 0.62283259, Gradient norm: 0.16129285
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43894.81640625MB
INFO:root:[   94] Training loss: 0.61208377, Validation loss: 0.62278379, Gradient norm: 0.17786102
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=43974.953125MB
INFO:root:[   95] Training loss: 0.61168907, Validation loss: 0.62273884, Gradient norm: 0.16492778
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44055.76953125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   96] Training loss: 0.61141262, Validation loss: 0.62372727, Gradient norm: 0.18075754
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44135.1171875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   97] Training loss: 0.61026196, Validation loss: 0.62188024, Gradient norm: 0.12443105
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44214.78125MB
INFO:root:[   98] Training loss: 0.60977598, Validation loss: 0.62142163, Gradient norm: 0.09989778
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44295.40625MB
INFO:root:[   99] Training loss: 0.60965598, Validation loss: 0.62160457, Gradient norm: 0.09445648
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44375.8828125MB
INFO:root:[  100] Training loss: 0.60963380, Validation loss: 0.62200268, Gradient norm: 0.09756404
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44455.6953125MB
INFO:root:[  101] Training loss: 0.60946887, Validation loss: 0.62238119, Gradient norm: 0.09403469
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44533.48828125MB
INFO:root:[  102] Training loss: 0.60935272, Validation loss: 0.62235539, Gradient norm: 0.09901948
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44609.90234375MB
INFO:root:[  103] Training loss: 0.60936781, Validation loss: 0.62133703, Gradient norm: 0.10054510
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44686.2890625MB
INFO:root:[  104] Training loss: 0.60925525, Validation loss: 0.62109642, Gradient norm: 0.11327087
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44762.5625MB
INFO:root:[  105] Training loss: 0.60915884, Validation loss: 0.62269407, Gradient norm: 0.09833534
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44839.5MB
INFO:root:[  106] Training loss: 0.60936256, Validation loss: 0.62166185, Gradient norm: 0.09807345
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44915.3984375MB
INFO:root:[  107] Training loss: 0.60904562, Validation loss: 0.62115435, Gradient norm: 0.09791913
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=44992.17578125MB
INFO:root:[  108] Training loss: 0.60910574, Validation loss: 0.62216313, Gradient norm: 0.10144402
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45068.65234375MB
INFO:root:[  109] Training loss: 0.60898577, Validation loss: 0.62199719, Gradient norm: 0.10832039
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45144.96484375MB
INFO:root:[  110] Training loss: 0.60881898, Validation loss: 0.62120661, Gradient norm: 0.10725047
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45221.2734375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  111] Training loss: 0.60897263, Validation loss: 0.62125097, Gradient norm: 0.11367598
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45297.59375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  112] Training loss: 0.60850333, Validation loss: 0.62104109, Gradient norm: 0.09201907
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45377.8515625MB
INFO:root:[  113] Training loss: 0.60831420, Validation loss: 0.62153792, Gradient norm: 0.07854321
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45459.09375MB
INFO:root:[  114] Training loss: 0.60820877, Validation loss: 0.62157000, Gradient norm: 0.07580331
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45539.8359375MB
INFO:root:[  115] Training loss: 0.60818016, Validation loss: 0.62118714, Gradient norm: 0.07541254
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45620.43359375MB
INFO:root:[  116] Training loss: 0.60819411, Validation loss: 0.62143536, Gradient norm: 0.08131216
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45700.28125MB
INFO:root:[  117] Training loss: 0.60827998, Validation loss: 0.62111750, Gradient norm: 0.08582219
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45780.69921875MB
INFO:root:[  118] Training loss: 0.60839211, Validation loss: 0.62135286, Gradient norm: 0.08088636
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45861.33984375MB
INFO:root:[  119] Training loss: 0.60835649, Validation loss: 0.62122336, Gradient norm: 0.07921459
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=45943.02734375MB
INFO:root:[  120] Training loss: 0.60819042, Validation loss: 0.62073924, Gradient norm: 0.08056989
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46020.7734375MB
INFO:root:[  121] Training loss: 0.60821570, Validation loss: 0.62163098, Gradient norm: 0.08050978
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46097.26171875MB
INFO:root:[  122] Training loss: 0.60825250, Validation loss: 0.62179116, Gradient norm: 0.08550657
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46173.6484375MB
INFO:root:[  123] Training loss: 0.60810193, Validation loss: 0.62082456, Gradient norm: 0.08152591
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46249.66796875MB
INFO:root:[  124] Training loss: 0.60808924, Validation loss: 0.62157831, Gradient norm: 0.09356291
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46326.3125MB
INFO:root:[  125] Training loss: 0.60830209, Validation loss: 0.62128975, Gradient norm: 0.09086298
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46402.57421875MB
INFO:root:[  126] Training loss: 0.60825817, Validation loss: 0.62150545, Gradient norm: 0.08135129
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46478.87109375MB
INFO:root:[  127] Training loss: 0.60823643, Validation loss: 0.62126157, Gradient norm: 0.08331979
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46555.37890625MB
INFO:root:[  128] Training loss: 0.60812139, Validation loss: 0.62166282, Gradient norm: 0.08298147
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46631.55859375MB
INFO:root:[  129] Training loss: 0.60818574, Validation loss: 0.62177642, Gradient norm: 0.08530037
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46708.04296875MB
INFO:root:EP 129: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12453.96875MB; mem (CPU total)=46784.421875MB
INFO:root:Training the model took 10715.527s.
INFO:root:Emptying the cuda cache took 0.305s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8632
INFO:root:EnergyScoreTrain: 0.60808
INFO:root:CRPSTrain: 0.53303
INFO:root:Gaussian NLLTrain: 2.24087
INFO:root:CoverageTrain: 0.80114
INFO:root:IntervalWidthTrain: 3.19988
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88227
INFO:root:EnergyScoreValidation: 0.62132
INFO:root:CRPSValidation: 0.54391
INFO:root:Gaussian NLLValidation: 2.2784
INFO:root:CoverageValidation: 0.79432
INFO:root:IntervalWidthValidation: 3.19162
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88324
INFO:root:EnergyScoreTest: 0.62204
INFO:root:CRPSTest: 0.54455
INFO:root:Gaussian NLLTest: 2.2872
INFO:root:CoverageTest: 0.79364
INFO:root:IntervalWidthTest: 3.18602
INFO:root:After validation: mem (CPU python)=12453.96875MB; mem (CPU total)=46941.8828125MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=12453.96875MB; mem (CPU total)=46941.875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=12453.96875MB; mem (CPU total)=46942.3671875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=46945.5625MB
INFO:root:[    1] Training loss: 0.78509124, Validation loss: 0.72484261, Gradient norm: 0.40682751
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47028.03515625MB
INFO:root:[    2] Training loss: 0.72190969, Validation loss: 0.72106519, Gradient norm: 0.32792976
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47107.53515625MB
INFO:root:[    3] Training loss: 0.72025517, Validation loss: 0.72062867, Gradient norm: 0.21005525
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47188.76171875MB
INFO:root:[    4] Training loss: 0.71975041, Validation loss: 0.72091246, Gradient norm: 0.17607995
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47269.58984375MB
INFO:root:[    5] Training loss: 0.71956117, Validation loss: 0.71961677, Gradient norm: 0.23199018
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47349.5078125MB
INFO:root:[    6] Training loss: 0.71907270, Validation loss: 0.71950901, Gradient norm: 0.20434304
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47430.23828125MB
INFO:root:[    7] Training loss: 0.71866918, Validation loss: 0.71873988, Gradient norm: 0.14584232
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47509.70703125MB
INFO:root:[    8] Training loss: 0.71818054, Validation loss: 0.71860769, Gradient norm: 0.15374425
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47589.91015625MB
INFO:root:[    9] Training loss: 0.71607490, Validation loss: 0.71396069, Gradient norm: 0.25437862
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47670.11328125MB
INFO:root:[   10] Training loss: 0.70908917, Validation loss: 0.70510767, Gradient norm: 0.16690585
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47746.62890625MB
INFO:root:[   11] Training loss: 0.69932312, Validation loss: 0.69500149, Gradient norm: 0.15033973
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47823.1796875MB
INFO:root:[   12] Training loss: 0.69050827, Validation loss: 0.68701228, Gradient norm: 0.10880658
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47902.21484375MB
INFO:root:[   13] Training loss: 0.68343295, Validation loss: 0.68103973, Gradient norm: 0.11635914
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=47955.359375MB
INFO:root:[   14] Training loss: 0.67794305, Validation loss: 0.67621219, Gradient norm: 0.15343977
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=48009.41796875MB
INFO:root:[   15] Training loss: 0.67330151, Validation loss: 0.67252242, Gradient norm: 0.10447852
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=48056.83203125MB
INFO:root:[   16] Training loss: 0.66960246, Validation loss: 0.66876390, Gradient norm: 0.13570818
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=48094.91796875MB
INFO:root:[   17] Training loss: 0.66649951, Validation loss: 0.66617999, Gradient norm: 0.10020006
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=48133.29296875MB
INFO:root:[   18] Training loss: 0.66359516, Validation loss: 0.66451947, Gradient norm: 0.13135075
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=9797.3046875MB
INFO:root:[   19] Training loss: 0.66107292, Validation loss: 0.66207751, Gradient norm: 0.10983071
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=9835.33984375MB
INFO:root:[   20] Training loss: 0.65889483, Validation loss: 0.65961660, Gradient norm: 0.10453136
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=9873.2109375MB
INFO:root:[   21] Training loss: 0.65712394, Validation loss: 0.65803393, Gradient norm: 0.11768407
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=9910.48046875MB
INFO:root:[   22] Training loss: 0.65517059, Validation loss: 0.65709900, Gradient norm: 0.11917645
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=9948.50390625MB
INFO:root:[   23] Training loss: 0.65370869, Validation loss: 0.65483339, Gradient norm: 0.11394646
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=9986.328125MB
INFO:root:[   24] Training loss: 0.65202454, Validation loss: 0.65361070, Gradient norm: 0.11955506
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10024.13671875MB
INFO:root:[   25] Training loss: 0.65066707, Validation loss: 0.65214920, Gradient norm: 0.11958890
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10061.96875MB
INFO:root:[   26] Training loss: 0.64948991, Validation loss: 0.65070647, Gradient norm: 0.11743429
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10100.26953125MB
INFO:root:[   27] Training loss: 0.64813086, Validation loss: 0.65055067, Gradient norm: 0.16161498
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10138.3671875MB
INFO:root:[   28] Training loss: 0.64684253, Validation loss: 0.64838436, Gradient norm: 0.11207214
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10176.69921875MB
INFO:root:[   29] Training loss: 0.64568855, Validation loss: 0.64742742, Gradient norm: 0.13308938
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10215.015625MB
INFO:root:[   30] Training loss: 0.64456477, Validation loss: 0.64714652, Gradient norm: 0.14384160
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10253.125MB
INFO:root:[   31] Training loss: 0.64351250, Validation loss: 0.64612605, Gradient norm: 0.13525407
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10291.234375MB
INFO:root:[   32] Training loss: 0.64261791, Validation loss: 0.64442823, Gradient norm: 0.14767736
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10329.08203125MB
INFO:root:[   33] Training loss: 0.64161922, Validation loss: 0.64376022, Gradient norm: 0.12642402
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10367.3359375MB
INFO:root:[   34] Training loss: 0.64074042, Validation loss: 0.64294875, Gradient norm: 0.14866779
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10405.16796875MB
INFO:root:[   35] Training loss: 0.63972829, Validation loss: 0.64269110, Gradient norm: 0.18485935
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10443.23828125MB
INFO:root:[   36] Training loss: 0.63902742, Validation loss: 0.64156349, Gradient norm: 0.15416191
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10481.5625MB
INFO:root:[   37] Training loss: 0.63808125, Validation loss: 0.64101760, Gradient norm: 0.14564496
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10519.40234375MB
INFO:root:[   38] Training loss: 0.63739864, Validation loss: 0.64062495, Gradient norm: 0.17295032
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10557.28515625MB
INFO:root:[   39] Training loss: 0.63648909, Validation loss: 0.63911188, Gradient norm: 0.16152583
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10595.65234375MB
INFO:root:[   40] Training loss: 0.63575015, Validation loss: 0.63883255, Gradient norm: 0.17398025
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10633.75390625MB
INFO:root:[   41] Training loss: 0.63498783, Validation loss: 0.63866828, Gradient norm: 0.15998623
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10672.25390625MB
INFO:root:[   42] Training loss: 0.63436672, Validation loss: 0.63756116, Gradient norm: 0.22683343
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10709.99609375MB
INFO:root:[   43] Training loss: 0.63370101, Validation loss: 0.63727017, Gradient norm: 0.18315378
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10747.84765625MB
INFO:root:[   44] Training loss: 0.63287189, Validation loss: 0.63639396, Gradient norm: 0.13995705
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10785.8203125MB
INFO:root:[   45] Training loss: 0.63252227, Validation loss: 0.63590750, Gradient norm: 0.17128525
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10824.1796875MB
INFO:root:[   46] Training loss: 0.63184732, Validation loss: 0.63570613, Gradient norm: 0.17974812
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10862.0390625MB
INFO:root:[   47] Training loss: 0.63125403, Validation loss: 0.63517199, Gradient norm: 0.16781067
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10900.3828125MB
INFO:root:[   48] Training loss: 0.63078274, Validation loss: 0.63488437, Gradient norm: 0.18281137
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10938.78125MB
INFO:root:[   49] Training loss: 0.63003705, Validation loss: 0.63395270, Gradient norm: 0.21920126
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=10976.953125MB
INFO:root:[   50] Training loss: 0.62965831, Validation loss: 0.63323125, Gradient norm: 0.25443408
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11015.30859375MB
INFO:root:[   51] Training loss: 0.62903869, Validation loss: 0.63362123, Gradient norm: 0.19418884
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11053.66796875MB
INFO:root:[   52] Training loss: 0.62852514, Validation loss: 0.63298520, Gradient norm: 0.28092120
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11091.65234375MB
INFO:root:[   53] Training loss: 0.62802764, Validation loss: 0.63282898, Gradient norm: 0.26755134
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11129.73828125MB
INFO:root:[   54] Training loss: 0.62764705, Validation loss: 0.63202046, Gradient norm: 0.25672752
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11168.06640625MB
INFO:root:[   55] Training loss: 0.62707257, Validation loss: 0.63194156, Gradient norm: 0.23716084
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11206.19140625MB
INFO:root:[   56] Training loss: 0.62655696, Validation loss: 0.63078254, Gradient norm: 0.23278853
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11244.5078125MB
INFO:root:[   57] Training loss: 0.62626994, Validation loss: 0.63070174, Gradient norm: 0.26153935
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11282.6640625MB
INFO:root:[   58] Training loss: 0.62574362, Validation loss: 0.63030005, Gradient norm: 0.28823459
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11320.7578125MB
INFO:root:[   59] Training loss: 0.62539029, Validation loss: 0.62999394, Gradient norm: 0.30746741
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11358.98046875MB
INFO:root:[   60] Training loss: 0.62498519, Validation loss: 0.63011908, Gradient norm: 0.26078794
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11396.7734375MB
INFO:root:[   61] Training loss: 0.62456391, Validation loss: 0.63066029, Gradient norm: 0.38894348
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11435.05078125MB
INFO:root:[   62] Training loss: 0.62398317, Validation loss: 0.62935265, Gradient norm: 0.31254193
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11472.96875MB
INFO:root:[   63] Training loss: 0.62386781, Validation loss: 0.63014698, Gradient norm: 0.43847044
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11511.078125MB
INFO:root:[   64] Training loss: 0.62325893, Validation loss: 0.62904633, Gradient norm: 0.35513089
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11549.34375MB
INFO:root:[   65] Training loss: 0.62304053, Validation loss: 0.62933925, Gradient norm: 0.42546272
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11587.71875MB
INFO:root:[   66] Training loss: 0.62280690, Validation loss: 0.62817157, Gradient norm: 0.42399397
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11625.84375MB
INFO:root:[   67] Training loss: 0.62236493, Validation loss: 0.62836200, Gradient norm: 0.50246494
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11664.18359375MB
INFO:root:[   68] Training loss: 0.62215932, Validation loss: 0.62722371, Gradient norm: 0.57413063
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11701.94921875MB
INFO:root:[   69] Training loss: 0.62192303, Validation loss: 0.62678507, Gradient norm: 0.64421978
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11739.8359375MB
INFO:root:[   70] Training loss: 0.62129302, Validation loss: 0.62700458, Gradient norm: 0.47817731
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11777.89453125MB
INFO:root:[   71] Training loss: 0.62168722, Validation loss: 0.62760673, Gradient norm: 1.21111795
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11815.99609375MB
INFO:root:[   72] Training loss: 0.62088287, Validation loss: 0.62693456, Gradient norm: 0.65119726
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11854.54296875MB
INFO:root:[   73] Training loss: 0.62099305, Validation loss: 0.62705379, Gradient norm: 0.81088527
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11892.3515625MB
INFO:root:[   74] Training loss: 0.62054180, Validation loss: 0.62633728, Gradient norm: 1.19071456
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11930.5859375MB
INFO:root:[   75] Training loss: 0.62000682, Validation loss: 0.62577440, Gradient norm: 0.41122859
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=11968.59765625MB
INFO:root:[   76] Training loss: 0.61974574, Validation loss: 0.62562202, Gradient norm: 0.47312644
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=12006.6328125MB
INFO:root:[   77] Training loss: 0.62024724, Validation loss: 0.62553003, Gradient norm: 1.28718301
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=12045.80078125MB
INFO:root:[   78] Training loss: 0.62041558, Validation loss: 0.62760751, Gradient norm: 1.70675279
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=12083.92578125MB
INFO:root:[   79] Training loss: 0.61920025, Validation loss: 0.62577116, Gradient norm: 0.61366116
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=12122.01171875MB
INFO:root:[   80] Training loss: 0.61921274, Validation loss: 0.62656680, Gradient norm: 1.12357775
INFO:root:At the start of the epoch: mem (CPU python)=12453.96875MB; mem (CPU total)=12160.26953125MB
INFO:root:[   81] Training loss: 0.61884196, Validation loss: 0.62622975, Gradient norm: 1.59985580
INFO:root:At the start of the epoch: mem (CPU python)=12454.9921875MB; mem (CPU total)=12198.8046875MB
INFO:root:[   82] Training loss: 0.61867866, Validation loss: 0.62553773, Gradient norm: 0.85953784
INFO:root:At the start of the epoch: mem (CPU python)=12493.0859375MB; mem (CPU total)=12236.921875MB
INFO:root:[   83] Training loss: 0.62002103, Validation loss: 0.62596253, Gradient norm: 2.52416302
INFO:root:At the start of the epoch: mem (CPU python)=12531.18359375MB; mem (CPU total)=12274.59375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   84] Training loss: 0.61954708, Validation loss: 0.62637625, Gradient norm: 2.45226399
INFO:root:At the start of the epoch: mem (CPU python)=12569.27734375MB; mem (CPU total)=12312.73828125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   85] Training loss: 0.61722034, Validation loss: 0.62476320, Gradient norm: 0.44414523
INFO:root:At the start of the epoch: mem (CPU python)=12607.37109375MB; mem (CPU total)=12351.52734375MB
INFO:root:[   86] Training loss: 0.61655438, Validation loss: 0.62455221, Gradient norm: 0.25131517
INFO:root:At the start of the epoch: mem (CPU python)=12645.46484375MB; mem (CPU total)=12390.66796875MB
INFO:root:[   87] Training loss: 0.61654672, Validation loss: 0.62429133, Gradient norm: 0.23898112
INFO:root:At the start of the epoch: mem (CPU python)=12683.5625MB; mem (CPU total)=12428.91015625MB
INFO:root:[   88] Training loss: 0.61649165, Validation loss: 0.62419848, Gradient norm: 0.23395773
INFO:root:At the start of the epoch: mem (CPU python)=12721.65625MB; mem (CPU total)=12467.04296875MB
INFO:root:[   89] Training loss: 0.61630837, Validation loss: 0.62391620, Gradient norm: 0.24314710
INFO:root:At the start of the epoch: mem (CPU python)=12759.7578125MB; mem (CPU total)=12504.953125MB
INFO:root:[   90] Training loss: 0.61628196, Validation loss: 0.62384029, Gradient norm: 0.26116907
INFO:root:At the start of the epoch: mem (CPU python)=12797.8515625MB; mem (CPU total)=12543.28125MB
INFO:root:[   91] Training loss: 0.61625394, Validation loss: 0.62412798, Gradient norm: 0.25671288
INFO:root:At the start of the epoch: mem (CPU python)=12835.94921875MB; mem (CPU total)=12581.33984375MB
INFO:root:[   92] Training loss: 0.61618040, Validation loss: 0.62418828, Gradient norm: 0.34406443
INFO:root:At the start of the epoch: mem (CPU python)=12874.04296875MB; mem (CPU total)=12618.5859375MB
INFO:root:[   93] Training loss: 0.61633316, Validation loss: 0.62414201, Gradient norm: 0.39534391
INFO:root:At the start of the epoch: mem (CPU python)=12912.140625MB; mem (CPU total)=12656.6640625MB
INFO:root:[   94] Training loss: 0.61614147, Validation loss: 0.62459025, Gradient norm: 0.33979439
INFO:root:At the start of the epoch: mem (CPU python)=12950.234375MB; mem (CPU total)=12695.17578125MB
INFO:root:[   95] Training loss: 0.61613584, Validation loss: 0.62354446, Gradient norm: 0.30384733
INFO:root:At the start of the epoch: mem (CPU python)=12988.328125MB; mem (CPU total)=12733.03515625MB
INFO:root:[   96] Training loss: 0.61614898, Validation loss: 0.62444472, Gradient norm: 0.37026735
INFO:root:At the start of the epoch: mem (CPU python)=13026.421875MB; mem (CPU total)=12771.35546875MB
INFO:root:[   97] Training loss: 0.61609156, Validation loss: 0.62413972, Gradient norm: 0.39815853
INFO:root:At the start of the epoch: mem (CPU python)=13064.51953125MB; mem (CPU total)=12809.42578125MB
INFO:root:[   98] Training loss: 0.61607108, Validation loss: 0.62431628, Gradient norm: 0.43090670
INFO:root:At the start of the epoch: mem (CPU python)=13102.6171875MB; mem (CPU total)=12847.234375MB
INFO:root:[   99] Training loss: 0.61610080, Validation loss: 0.62419026, Gradient norm: 0.35669575
INFO:root:At the start of the epoch: mem (CPU python)=13140.7109375MB; mem (CPU total)=12885.6953125MB
INFO:root:[  100] Training loss: 0.61603305, Validation loss: 0.62399134, Gradient norm: 0.42241286
INFO:root:At the start of the epoch: mem (CPU python)=13178.80859375MB; mem (CPU total)=12923.75390625MB
INFO:root:[  101] Training loss: 0.61605613, Validation loss: 0.62426535, Gradient norm: 0.50358523
INFO:root:At the start of the epoch: mem (CPU python)=13216.90234375MB; mem (CPU total)=12961.859375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  102] Training loss: 0.61601461, Validation loss: 0.62420953, Gradient norm: 0.50034100
INFO:root:At the start of the epoch: mem (CPU python)=13254.99609375MB; mem (CPU total)=13000.421875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  103] Training loss: 0.61568790, Validation loss: 0.62405749, Gradient norm: 0.37991089
INFO:root:At the start of the epoch: mem (CPU python)=13293.08984375MB; mem (CPU total)=13038.2734375MB
INFO:root:[  104] Training loss: 0.61558824, Validation loss: 0.62379285, Gradient norm: 0.28657171
INFO:root:At the start of the epoch: mem (CPU python)=13331.1875MB; mem (CPU total)=13076.37109375MB
INFO:root:[  105] Training loss: 0.61541659, Validation loss: 0.62315158, Gradient norm: 0.25542023
INFO:root:At the start of the epoch: mem (CPU python)=13369.28125MB; mem (CPU total)=13114.25MB
INFO:root:[  106] Training loss: 0.61565703, Validation loss: 0.62339149, Gradient norm: 0.29047836
INFO:root:At the start of the epoch: mem (CPU python)=13407.375MB; mem (CPU total)=13152.12890625MB
INFO:root:[  107] Training loss: 0.61554873, Validation loss: 0.62397556, Gradient norm: 0.29918346
INFO:root:At the start of the epoch: mem (CPU python)=13445.4765625MB; mem (CPU total)=13190.53125MB
INFO:root:[  108] Training loss: 0.61556907, Validation loss: 0.62347584, Gradient norm: 0.29845625
INFO:root:At the start of the epoch: mem (CPU python)=13483.5703125MB; mem (CPU total)=13229.296875MB
INFO:root:[  109] Training loss: 0.61554099, Validation loss: 0.62420502, Gradient norm: 0.28110034
INFO:root:At the start of the epoch: mem (CPU python)=13521.6640625MB; mem (CPU total)=13266.7421875MB
INFO:root:[  110] Training loss: 0.61545345, Validation loss: 0.62396819, Gradient norm: 0.33169658
INFO:root:At the start of the epoch: mem (CPU python)=13559.76171875MB; mem (CPU total)=13304.77734375MB
INFO:root:[  111] Training loss: 0.61549365, Validation loss: 0.62413238, Gradient norm: 0.31150762
INFO:root:At the start of the epoch: mem (CPU python)=13597.85546875MB; mem (CPU total)=13343.09375MB
INFO:root:[  112] Training loss: 0.61555454, Validation loss: 0.62384991, Gradient norm: 0.30713871
INFO:root:At the start of the epoch: mem (CPU python)=13635.94921875MB; mem (CPU total)=13381.234375MB
INFO:root:[  113] Training loss: 0.61549212, Validation loss: 0.62383180, Gradient norm: 0.30570126
INFO:root:At the start of the epoch: mem (CPU python)=13674.04296875MB; mem (CPU total)=13419.0625MB
INFO:root:[  114] Training loss: 0.61553629, Validation loss: 0.62313852, Gradient norm: 0.32865151
INFO:root:At the start of the epoch: mem (CPU python)=13712.140625MB; mem (CPU total)=13457.2109375MB
INFO:root:[  115] Training loss: 0.61552339, Validation loss: 0.62433088, Gradient norm: 0.34208888
INFO:root:At the start of the epoch: mem (CPU python)=13750.234375MB; mem (CPU total)=13495.3203125MB
INFO:root:[  116] Training loss: 0.61544555, Validation loss: 0.62314981, Gradient norm: 0.30658953
INFO:root:At the start of the epoch: mem (CPU python)=13788.328125MB; mem (CPU total)=13533.41796875MB
INFO:root:[  117] Training loss: 0.61546218, Validation loss: 0.62359578, Gradient norm: 0.30735538
INFO:root:At the start of the epoch: mem (CPU python)=13826.5078125MB; mem (CPU total)=13571.66796875MB
INFO:root:[  118] Training loss: 0.61543558, Validation loss: 0.62407023, Gradient norm: 0.38045179
INFO:root:At the start of the epoch: mem (CPU python)=13864.6015625MB; mem (CPU total)=13609.57421875MB
INFO:root:[  119] Training loss: 0.61554680, Validation loss: 0.62350014, Gradient norm: 0.34371126
INFO:root:At the start of the epoch: mem (CPU python)=13902.6953125MB; mem (CPU total)=13647.93359375MB
INFO:root:[  120] Training loss: 0.61556189, Validation loss: 0.62379762, Gradient norm: 0.38748031
INFO:root:At the start of the epoch: mem (CPU python)=13940.79296875MB; mem (CPU total)=13686.875MB
INFO:root:[  121] Training loss: 0.61548561, Validation loss: 0.62418289, Gradient norm: 0.33998900
INFO:root:At the start of the epoch: mem (CPU python)=13978.890625MB; mem (CPU total)=13724.984375MB
INFO:root:[  122] Training loss: 0.61544407, Validation loss: 0.62411607, Gradient norm: 0.41142331
INFO:root:At the start of the epoch: mem (CPU python)=14016.984375MB; mem (CPU total)=13762.80859375MB
INFO:root:[  123] Training loss: 0.61556178, Validation loss: 0.62396652, Gradient norm: 0.37716605
INFO:root:At the start of the epoch: mem (CPU python)=14055.08203125MB; mem (CPU total)=13800.8671875MB
INFO:root:EP 123: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=14093.1796875MB; mem (CPU total)=13839.234375MB
INFO:root:Training the model took 10882.223s.
INFO:root:Emptying the cuda cache took 0.311s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87352
INFO:root:EnergyScoreTrain: 0.61535
INFO:root:CRPSTrain: 0.56156
INFO:root:Gaussian NLLTrain: 5.52779
INFO:root:CoverageTrain: 0.74273
INFO:root:IntervalWidthTrain: 3.08473
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88583
INFO:root:EnergyScoreValidation: 0.62387
INFO:root:CRPSValidation: 0.56841
INFO:root:Gaussian NLLValidation: 5.57598
INFO:root:CoverageValidation: 0.73885
INFO:root:IntervalWidthValidation: 3.0818
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88701
INFO:root:EnergyScoreTest: 0.62472
INFO:root:CRPSTest: 0.56906
INFO:root:Gaussian NLLTest: 5.58568
INFO:root:CoverageTest: 0.73796
INFO:root:IntervalWidthTest: 3.07349
INFO:root:After validation: mem (CPU python)=14136.44921875MB; mem (CPU total)=13880.68359375MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=14136.44921875MB; mem (CPU total)=13880.92578125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=14136.6171875MB; mem (CPU total)=13880.921875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=14136.7265625MB; mem (CPU total)=13881.1640625MB
INFO:root:[    1] Training loss: 0.77645047, Validation loss: 0.72226080, Gradient norm: 0.35745596
INFO:root:At the start of the epoch: mem (CPU python)=14175.57421875MB; mem (CPU total)=13921.82421875MB
INFO:root:[    2] Training loss: 0.72110445, Validation loss: 0.72053412, Gradient norm: 0.21923156
INFO:root:At the start of the epoch: mem (CPU python)=14213.66796875MB; mem (CPU total)=13960.265625MB
INFO:root:[    3] Training loss: 0.72005381, Validation loss: 0.71982549, Gradient norm: 0.21595844
INFO:root:At the start of the epoch: mem (CPU python)=14251.78125MB; mem (CPU total)=13998.9453125MB
INFO:root:[    4] Training loss: 0.71966872, Validation loss: 0.71993414, Gradient norm: 0.14612787
INFO:root:At the start of the epoch: mem (CPU python)=14289.890625MB; mem (CPU total)=14037.578125MB
INFO:root:[    5] Training loss: 0.71946856, Validation loss: 0.71994556, Gradient norm: 0.19219991
INFO:root:At the start of the epoch: mem (CPU python)=14328.0MB; mem (CPU total)=14075.7421875MB
INFO:root:[    6] Training loss: 0.71894514, Validation loss: 0.71907933, Gradient norm: 0.16025367
INFO:root:At the start of the epoch: mem (CPU python)=14366.109375MB; mem (CPU total)=14113.58984375MB
INFO:root:[    7] Training loss: 0.71811682, Validation loss: 0.71753411, Gradient norm: 0.13472056
INFO:root:At the start of the epoch: mem (CPU python)=14404.22265625MB; mem (CPU total)=14151.98828125MB
INFO:root:[    8] Training loss: 0.71543904, Validation loss: 0.71167247, Gradient norm: 0.18284694
INFO:root:At the start of the epoch: mem (CPU python)=14442.33203125MB; mem (CPU total)=14189.8203125MB
INFO:root:[    9] Training loss: 0.70624081, Validation loss: 0.70039391, Gradient norm: 0.15341816
INFO:root:At the start of the epoch: mem (CPU python)=14480.4296875MB; mem (CPU total)=14227.92578125MB
INFO:root:[   10] Training loss: 0.69516297, Validation loss: 0.69105577, Gradient norm: 0.16735771
INFO:root:At the start of the epoch: mem (CPU python)=14518.52734375MB; mem (CPU total)=14266.5546875MB
INFO:root:[   11] Training loss: 0.68689197, Validation loss: 0.68443954, Gradient norm: 0.16331805
INFO:root:At the start of the epoch: mem (CPU python)=14556.62109375MB; mem (CPU total)=14304.62890625MB
INFO:root:[   12] Training loss: 0.68063562, Validation loss: 0.67882766, Gradient norm: 0.14511277
INFO:root:At the start of the epoch: mem (CPU python)=14594.71484375MB; mem (CPU total)=14343.015625MB
INFO:root:[   13] Training loss: 0.67540268, Validation loss: 0.67376570, Gradient norm: 0.14120654
INFO:root:At the start of the epoch: mem (CPU python)=14632.80859375MB; mem (CPU total)=14380.60546875MB
INFO:root:[   14] Training loss: 0.67123260, Validation loss: 0.66944417, Gradient norm: 0.13545645
INFO:root:At the start of the epoch: mem (CPU python)=14670.90625MB; mem (CPU total)=14418.9921875MB
INFO:root:[   15] Training loss: 0.66741828, Validation loss: 0.66672757, Gradient norm: 0.12017591
INFO:root:At the start of the epoch: mem (CPU python)=14709.00390625MB; mem (CPU total)=14457.1015625MB
INFO:root:[   16] Training loss: 0.66417121, Validation loss: 0.66411764, Gradient norm: 0.12967588
INFO:root:At the start of the epoch: mem (CPU python)=14747.09765625MB; mem (CPU total)=14495.21484375MB
INFO:root:[   17] Training loss: 0.66127524, Validation loss: 0.66074619, Gradient norm: 0.13211208
INFO:root:At the start of the epoch: mem (CPU python)=14785.1953125MB; mem (CPU total)=14533.8359375MB
INFO:root:[   18] Training loss: 0.65871454, Validation loss: 0.65934227, Gradient norm: 0.15511955
INFO:root:At the start of the epoch: mem (CPU python)=14823.2890625MB; mem (CPU total)=14571.83984375MB
INFO:root:[   19] Training loss: 0.65640091, Validation loss: 0.65623889, Gradient norm: 0.12009598
INFO:root:At the start of the epoch: mem (CPU python)=14861.3828125MB; mem (CPU total)=14610.12109375MB
INFO:root:[   20] Training loss: 0.65414348, Validation loss: 0.65498492, Gradient norm: 0.12750635
INFO:root:At the start of the epoch: mem (CPU python)=14899.48046875MB; mem (CPU total)=14648.26171875MB
INFO:root:[   21] Training loss: 0.65234181, Validation loss: 0.65341774, Gradient norm: 0.12160771
INFO:root:At the start of the epoch: mem (CPU python)=14937.57421875MB; mem (CPU total)=14685.91015625MB
INFO:root:[   22] Training loss: 0.65048366, Validation loss: 0.65152034, Gradient norm: 0.12133104
INFO:root:At the start of the epoch: mem (CPU python)=14975.66796875MB; mem (CPU total)=14723.3046875MB
INFO:root:[   23] Training loss: 0.64893147, Validation loss: 0.65064489, Gradient norm: 0.13217417
INFO:root:At the start of the epoch: mem (CPU python)=15013.76171875MB; mem (CPU total)=14761.16796875MB
INFO:root:[   24] Training loss: 0.64734746, Validation loss: 0.64845600, Gradient norm: 0.12130771
INFO:root:At the start of the epoch: mem (CPU python)=15051.86328125MB; mem (CPU total)=14799.5546875MB
INFO:root:[   25] Training loss: 0.64612129, Validation loss: 0.64780710, Gradient norm: 0.14902907
INFO:root:At the start of the epoch: mem (CPU python)=15089.95703125MB; mem (CPU total)=14836.87109375MB
INFO:root:[   26] Training loss: 0.64471298, Validation loss: 0.64659905, Gradient norm: 0.15319784
INFO:root:At the start of the epoch: mem (CPU python)=15128.05078125MB; mem (CPU total)=14874.96875MB
INFO:root:[   27] Training loss: 0.64341018, Validation loss: 0.64494172, Gradient norm: 0.13253222
INFO:root:At the start of the epoch: mem (CPU python)=15166.1484375MB; mem (CPU total)=14913.09375MB
INFO:root:[   28] Training loss: 0.64215928, Validation loss: 0.64429287, Gradient norm: 0.14382357
INFO:root:At the start of the epoch: mem (CPU python)=15204.2421875MB; mem (CPU total)=14951.23828125MB
INFO:root:[   29] Training loss: 0.64105660, Validation loss: 0.64350532, Gradient norm: 0.14612783
INFO:root:At the start of the epoch: mem (CPU python)=15242.3359375MB; mem (CPU total)=14989.62890625MB
INFO:root:[   30] Training loss: 0.63994484, Validation loss: 0.64260964, Gradient norm: 0.14752143
INFO:root:At the start of the epoch: mem (CPU python)=15280.45703125MB; mem (CPU total)=15028.453125MB
INFO:root:[   31] Training loss: 0.63886938, Validation loss: 0.64128075, Gradient norm: 0.13162627
INFO:root:At the start of the epoch: mem (CPU python)=15318.52734375MB; mem (CPU total)=15066.875MB
INFO:root:[   32] Training loss: 0.63781575, Validation loss: 0.64070718, Gradient norm: 0.12515269
INFO:root:At the start of the epoch: mem (CPU python)=15356.625MB; mem (CPU total)=15105.078125MB
INFO:root:[   33] Training loss: 0.63684471, Validation loss: 0.64010650, Gradient norm: 0.14465923
INFO:root:At the start of the epoch: mem (CPU python)=15394.71875MB; mem (CPU total)=15143.34765625MB
INFO:root:[   34] Training loss: 0.63606606, Validation loss: 0.63966185, Gradient norm: 0.13737635
INFO:root:At the start of the epoch: mem (CPU python)=15432.81640625MB; mem (CPU total)=15181.7421875MB
INFO:root:[   35] Training loss: 0.63519193, Validation loss: 0.63861996, Gradient norm: 0.13568495
INFO:root:At the start of the epoch: mem (CPU python)=15470.91796875MB; mem (CPU total)=15219.88671875MB
INFO:root:[   36] Training loss: 0.63415266, Validation loss: 0.63770106, Gradient norm: 0.13571200
INFO:root:At the start of the epoch: mem (CPU python)=15509.01171875MB; mem (CPU total)=15258.265625MB
INFO:root:[   37] Training loss: 0.63342553, Validation loss: 0.63679933, Gradient norm: 0.15508960
INFO:root:At the start of the epoch: mem (CPU python)=15547.109375MB; mem (CPU total)=15296.4296875MB
INFO:root:[   38] Training loss: 0.63274397, Validation loss: 0.63700319, Gradient norm: 0.15332005
INFO:root:At the start of the epoch: mem (CPU python)=15585.203125MB; mem (CPU total)=15335.23828125MB
INFO:root:[   39] Training loss: 0.63193387, Validation loss: 0.63543179, Gradient norm: 0.13608832
INFO:root:At the start of the epoch: mem (CPU python)=15623.30078125MB; mem (CPU total)=15373.3984375MB
INFO:root:[   40] Training loss: 0.63111347, Validation loss: 0.63529853, Gradient norm: 0.13150084
INFO:root:At the start of the epoch: mem (CPU python)=15661.39453125MB; mem (CPU total)=15411.390625MB
INFO:root:[   41] Training loss: 0.63043626, Validation loss: 0.63452869, Gradient norm: 0.14290517
INFO:root:At the start of the epoch: mem (CPU python)=15699.49609375MB; mem (CPU total)=15449.5859375MB
INFO:root:[   42] Training loss: 0.62990597, Validation loss: 0.63414551, Gradient norm: 0.15238189
INFO:root:At the start of the epoch: mem (CPU python)=15737.58984375MB; mem (CPU total)=15487.9140625MB
INFO:root:[   43] Training loss: 0.62916420, Validation loss: 0.63357423, Gradient norm: 0.12355980
INFO:root:At the start of the epoch: mem (CPU python)=15775.68359375MB; mem (CPU total)=15526.01953125MB
INFO:root:[   44] Training loss: 0.62869025, Validation loss: 0.63342874, Gradient norm: 0.14749660
INFO:root:At the start of the epoch: mem (CPU python)=15813.78125MB; mem (CPU total)=15564.421875MB
INFO:root:[   45] Training loss: 0.62795577, Validation loss: 0.63282243, Gradient norm: 0.16918078
INFO:root:At the start of the epoch: mem (CPU python)=15851.875MB; mem (CPU total)=15602.73828125MB
INFO:root:[   46] Training loss: 0.62746718, Validation loss: 0.63186075, Gradient norm: 0.15140308
INFO:root:At the start of the epoch: mem (CPU python)=15889.96875MB; mem (CPU total)=15640.8671875MB
INFO:root:[   47] Training loss: 0.62664943, Validation loss: 0.63145544, Gradient norm: 0.12678034
INFO:root:At the start of the epoch: mem (CPU python)=15928.0625MB; mem (CPU total)=15679.0078125MB
INFO:root:[   48] Training loss: 0.62625087, Validation loss: 0.63095935, Gradient norm: 0.19228664
INFO:root:At the start of the epoch: mem (CPU python)=15966.16015625MB; mem (CPU total)=15717.51171875MB
INFO:root:[   49] Training loss: 0.62568975, Validation loss: 0.63161314, Gradient norm: 0.14535767
INFO:root:At the start of the epoch: mem (CPU python)=16004.2578125MB; mem (CPU total)=15755.3984375MB
INFO:root:[   50] Training loss: 0.62511467, Validation loss: 0.63031851, Gradient norm: 0.14388521
INFO:root:At the start of the epoch: mem (CPU python)=16042.3515625MB; mem (CPU total)=15793.51171875MB
INFO:root:[   51] Training loss: 0.62471746, Validation loss: 0.63014542, Gradient norm: 0.18357726
INFO:root:At the start of the epoch: mem (CPU python)=16080.44921875MB; mem (CPU total)=15830.96875MB
INFO:root:[   52] Training loss: 0.62417946, Validation loss: 0.62899576, Gradient norm: 0.13588651
INFO:root:At the start of the epoch: mem (CPU python)=16118.54296875MB; mem (CPU total)=15869.08203125MB
INFO:root:[   53] Training loss: 0.62353412, Validation loss: 0.62910728, Gradient norm: 0.14956266
INFO:root:At the start of the epoch: mem (CPU python)=16156.63671875MB; mem (CPU total)=15907.42578125MB
INFO:root:[   54] Training loss: 0.62302463, Validation loss: 0.62839380, Gradient norm: 0.13248228
INFO:root:At the start of the epoch: mem (CPU python)=16194.734375MB; mem (CPU total)=15946.0234375MB
INFO:root:[   55] Training loss: 0.62280281, Validation loss: 0.62790662, Gradient norm: 0.22765116
INFO:root:At the start of the epoch: mem (CPU python)=16232.828125MB; mem (CPU total)=15984.12890625MB
INFO:root:[   56] Training loss: 0.62230089, Validation loss: 0.62797571, Gradient norm: 0.17211235
INFO:root:At the start of the epoch: mem (CPU python)=16270.921875MB; mem (CPU total)=16022.01171875MB
INFO:root:[   57] Training loss: 0.62163190, Validation loss: 0.62778256, Gradient norm: 0.17794649
INFO:root:At the start of the epoch: mem (CPU python)=16309.01953125MB; mem (CPU total)=16060.1328125MB
INFO:root:[   58] Training loss: 0.62124881, Validation loss: 0.62711739, Gradient norm: 0.16027610
INFO:root:At the start of the epoch: mem (CPU python)=16347.1171875MB; mem (CPU total)=16098.2421875MB
INFO:root:[   59] Training loss: 0.62086305, Validation loss: 0.62685129, Gradient norm: 0.16179614
INFO:root:At the start of the epoch: mem (CPU python)=16385.2109375MB; mem (CPU total)=16136.859375MB
INFO:root:[   60] Training loss: 0.62043496, Validation loss: 0.62694729, Gradient norm: 0.16922552
INFO:root:At the start of the epoch: mem (CPU python)=16423.3046875MB; mem (CPU total)=16174.9609375MB
INFO:root:[   61] Training loss: 0.62012064, Validation loss: 0.62623753, Gradient norm: 0.15694744
INFO:root:At the start of the epoch: mem (CPU python)=16461.40625MB; mem (CPU total)=16213.08984375MB
INFO:root:[   62] Training loss: 0.61969593, Validation loss: 0.62558311, Gradient norm: 0.21539149
INFO:root:At the start of the epoch: mem (CPU python)=16499.5MB; mem (CPU total)=16251.2265625MB
INFO:root:[   63] Training loss: 0.61934404, Validation loss: 0.62556189, Gradient norm: 0.19295604
INFO:root:At the start of the epoch: mem (CPU python)=16537.60546875MB; mem (CPU total)=16289.35546875MB
INFO:root:[   64] Training loss: 0.61898792, Validation loss: 0.62587279, Gradient norm: 0.19424691
INFO:root:At the start of the epoch: mem (CPU python)=16575.6875MB; mem (CPU total)=16327.6875MB
INFO:root:[   65] Training loss: 0.61849790, Validation loss: 0.62516547, Gradient norm: 0.18905129
INFO:root:At the start of the epoch: mem (CPU python)=16613.7890625MB; mem (CPU total)=16365.8671875MB
INFO:root:[   66] Training loss: 0.61831587, Validation loss: 0.62581008, Gradient norm: 0.23267747
INFO:root:At the start of the epoch: mem (CPU python)=16651.8671875MB; mem (CPU total)=16404.0390625MB
INFO:root:[   67] Training loss: 0.61775854, Validation loss: 0.62475233, Gradient norm: 0.16809705
INFO:root:At the start of the epoch: mem (CPU python)=16689.9609375MB; mem (CPU total)=16442.2109375MB
INFO:root:[   68] Training loss: 0.61740376, Validation loss: 0.62461176, Gradient norm: 0.17914980
INFO:root:At the start of the epoch: mem (CPU python)=16728.05859375MB; mem (CPU total)=16480.38671875MB
INFO:root:[   69] Training loss: 0.61712256, Validation loss: 0.62431025, Gradient norm: 0.19825659
INFO:root:At the start of the epoch: mem (CPU python)=16766.15234375MB; mem (CPU total)=16518.52734375MB
INFO:root:[   70] Training loss: 0.61684732, Validation loss: 0.62388253, Gradient norm: 0.20164604
INFO:root:At the start of the epoch: mem (CPU python)=16804.24609375MB; mem (CPU total)=16556.8359375MB
INFO:root:[   71] Training loss: 0.61647574, Validation loss: 0.62362693, Gradient norm: 0.27164598
INFO:root:At the start of the epoch: mem (CPU python)=16842.34375MB; mem (CPU total)=16595.2578125MB
INFO:root:[   72] Training loss: 0.61620338, Validation loss: 0.62354613, Gradient norm: 0.20510827
INFO:root:At the start of the epoch: mem (CPU python)=16880.4375MB; mem (CPU total)=16633.54296875MB
INFO:root:[   73] Training loss: 0.61581224, Validation loss: 0.62299060, Gradient norm: 0.18639287
INFO:root:At the start of the epoch: mem (CPU python)=16918.53125MB; mem (CPU total)=16671.66015625MB
INFO:root:[   74] Training loss: 0.61568882, Validation loss: 0.62281766, Gradient norm: 0.22796678
INFO:root:At the start of the epoch: mem (CPU python)=16956.62890625MB; mem (CPU total)=16709.73828125MB
INFO:root:[   75] Training loss: 0.61522881, Validation loss: 0.62266308, Gradient norm: 0.23263766
INFO:root:At the start of the epoch: mem (CPU python)=16994.7265625MB; mem (CPU total)=16748.01171875MB
INFO:root:[   76] Training loss: 0.61485509, Validation loss: 0.62313536, Gradient norm: 0.24471740
INFO:root:At the start of the epoch: mem (CPU python)=17032.8203125MB; mem (CPU total)=16785.9140625MB
INFO:root:[   77] Training loss: 0.61470380, Validation loss: 0.62277973, Gradient norm: 0.25643057
INFO:root:At the start of the epoch: mem (CPU python)=17070.9140625MB; mem (CPU total)=16824.03125MB
INFO:root:[   78] Training loss: 0.61445010, Validation loss: 0.62214458, Gradient norm: 0.31640271
INFO:root:At the start of the epoch: mem (CPU python)=17109.01171875MB; mem (CPU total)=16862.3828125MB
INFO:root:[   79] Training loss: 0.61411175, Validation loss: 0.62232585, Gradient norm: 0.27577426
INFO:root:At the start of the epoch: mem (CPU python)=17147.10546875MB; mem (CPU total)=16900.7578125MB
INFO:root:[   80] Training loss: 0.61387233, Validation loss: 0.62167119, Gradient norm: 0.29866362
INFO:root:At the start of the epoch: mem (CPU python)=17185.19921875MB; mem (CPU total)=16939.35546875MB
INFO:root:[   81] Training loss: 0.61332477, Validation loss: 0.62232035, Gradient norm: 0.26371780
INFO:root:At the start of the epoch: mem (CPU python)=17223.29296875MB; mem (CPU total)=16977.28515625MB
INFO:root:[   82] Training loss: 0.61309589, Validation loss: 0.62080069, Gradient norm: 0.25821588
INFO:root:At the start of the epoch: mem (CPU python)=17261.390625MB; mem (CPU total)=17015.48046875MB
INFO:root:[   83] Training loss: 0.61325645, Validation loss: 0.62141151, Gradient norm: 0.28057099
INFO:root:At the start of the epoch: mem (CPU python)=17299.48828125MB; mem (CPU total)=17053.84765625MB
INFO:root:[   84] Training loss: 0.61277203, Validation loss: 0.62128827, Gradient norm: 0.29398757
INFO:root:At the start of the epoch: mem (CPU python)=17337.58203125MB; mem (CPU total)=17092.0MB
INFO:root:[   85] Training loss: 0.61232229, Validation loss: 0.62098967, Gradient norm: 0.27504417
INFO:root:At the start of the epoch: mem (CPU python)=17375.6796875MB; mem (CPU total)=17130.140625MB
INFO:root:[   86] Training loss: 0.61229312, Validation loss: 0.62078873, Gradient norm: 0.28700696
INFO:root:At the start of the epoch: mem (CPU python)=17413.7734375MB; mem (CPU total)=17168.21875MB
INFO:root:[   87] Training loss: 0.61209887, Validation loss: 0.62147232, Gradient norm: 0.30242439
INFO:root:At the start of the epoch: mem (CPU python)=17451.8671875MB; mem (CPU total)=17206.22265625MB
INFO:root:[   88] Training loss: 0.61160465, Validation loss: 0.62043099, Gradient norm: 0.27018972
INFO:root:At the start of the epoch: mem (CPU python)=17489.96484375MB; mem (CPU total)=17244.52734375MB
INFO:root:[   89] Training loss: 0.61135274, Validation loss: 0.62048565, Gradient norm: 0.25167467
INFO:root:At the start of the epoch: mem (CPU python)=17528.05859375MB; mem (CPU total)=17282.1015625MB
INFO:root:[   90] Training loss: 0.61122619, Validation loss: 0.61975161, Gradient norm: 0.27495793
INFO:root:At the start of the epoch: mem (CPU python)=17566.15625MB; mem (CPU total)=17320.1796875MB
INFO:root:[   91] Training loss: 0.61101837, Validation loss: 0.62066817, Gradient norm: 0.39910077
INFO:root:At the start of the epoch: mem (CPU python)=17604.25MB; mem (CPU total)=17358.07421875MB
INFO:root:[   92] Training loss: 0.61061784, Validation loss: 0.61983154, Gradient norm: 0.29205882
INFO:root:At the start of the epoch: mem (CPU python)=17642.3515625MB; mem (CPU total)=17396.44921875MB
INFO:root:[   93] Training loss: 0.61058141, Validation loss: 0.62039661, Gradient norm: 0.42578843
INFO:root:At the start of the epoch: mem (CPU python)=17680.4453125MB; mem (CPU total)=17434.31640625MB
INFO:root:[   94] Training loss: 0.61023846, Validation loss: 0.61975705, Gradient norm: 0.34695004
INFO:root:At the start of the epoch: mem (CPU python)=17718.5390625MB; mem (CPU total)=17472.359375MB
INFO:root:[   95] Training loss: 0.61015985, Validation loss: 0.62043077, Gradient norm: 0.38712058
INFO:root:At the start of the epoch: mem (CPU python)=17756.63671875MB; mem (CPU total)=17511.25390625MB
INFO:root:[   96] Training loss: 0.61011188, Validation loss: 0.61956107, Gradient norm: 0.35806269
INFO:root:At the start of the epoch: mem (CPU python)=17794.734375MB; mem (CPU total)=17549.14453125MB
INFO:root:[   97] Training loss: 0.61014553, Validation loss: 0.62017598, Gradient norm: 0.72972990
INFO:root:At the start of the epoch: mem (CPU python)=17832.82421875MB; mem (CPU total)=17587.3046875MB
INFO:root:[   98] Training loss: 0.60971842, Validation loss: 0.61918031, Gradient norm: 0.72513473
INFO:root:At the start of the epoch: mem (CPU python)=17870.921875MB; mem (CPU total)=17627.64453125MB
INFO:root:[   99] Training loss: 0.60899647, Validation loss: 0.61952824, Gradient norm: 0.26491691
INFO:root:At the start of the epoch: mem (CPU python)=17909.015625MB; mem (CPU total)=17665.37109375MB
INFO:root:[  100] Training loss: 0.60911489, Validation loss: 0.61945168, Gradient norm: 0.33561726
INFO:root:At the start of the epoch: mem (CPU python)=17947.11328125MB; mem (CPU total)=17704.328125MB
INFO:root:[  101] Training loss: 0.60877854, Validation loss: 0.61923330, Gradient norm: 0.34993255
INFO:root:At the start of the epoch: mem (CPU python)=17985.20703125MB; mem (CPU total)=17741.8671875MB
INFO:root:[  102] Training loss: 0.60865392, Validation loss: 0.61876425, Gradient norm: 0.35732169
INFO:root:At the start of the epoch: mem (CPU python)=18023.3046875MB; mem (CPU total)=17779.8828125MB
INFO:root:[  103] Training loss: 0.60828852, Validation loss: 0.61781013, Gradient norm: 0.37656761
INFO:root:At the start of the epoch: mem (CPU python)=18061.3984375MB; mem (CPU total)=17817.95703125MB
INFO:root:[  104] Training loss: 0.60822171, Validation loss: 0.61911611, Gradient norm: 0.41956065
INFO:root:At the start of the epoch: mem (CPU python)=18099.4921875MB; mem (CPU total)=17856.3359375MB
INFO:root:[  105] Training loss: 0.60800330, Validation loss: 0.61884830, Gradient norm: 0.45070320
INFO:root:At the start of the epoch: mem (CPU python)=18137.58984375MB; mem (CPU total)=17894.49609375MB
INFO:root:[  106] Training loss: 0.60780836, Validation loss: 0.61919275, Gradient norm: 0.45350159
INFO:root:At the start of the epoch: mem (CPU python)=18175.68359375MB; mem (CPU total)=17932.296875MB
INFO:root:[  107] Training loss: 0.60758775, Validation loss: 0.61813083, Gradient norm: 0.46267739
INFO:root:At the start of the epoch: mem (CPU python)=18213.78125MB; mem (CPU total)=17970.67578125MB
INFO:root:[  108] Training loss: 0.60738482, Validation loss: 0.61851581, Gradient norm: 0.54892194
INFO:root:At the start of the epoch: mem (CPU python)=18251.875MB; mem (CPU total)=18008.79296875MB
INFO:root:[  109] Training loss: 0.60737388, Validation loss: 0.61862505, Gradient norm: 0.49672098
INFO:root:At the start of the epoch: mem (CPU python)=18289.97265625MB; mem (CPU total)=18046.87890625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  110] Training loss: 0.60716183, Validation loss: 0.61838921, Gradient norm: 0.45565529
INFO:root:At the start of the epoch: mem (CPU python)=18328.06640625MB; mem (CPU total)=18085.1953125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  111] Training loss: 0.60594929, Validation loss: 0.61793451, Gradient norm: 0.30236258
INFO:root:At the start of the epoch: mem (CPU python)=18366.16015625MB; mem (CPU total)=18123.02734375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  112] Training loss: 0.60529551, Validation loss: 0.61730672, Gradient norm: 0.21924856
INFO:root:At the start of the epoch: mem (CPU python)=18404.2578125MB; mem (CPU total)=18161.1640625MB
INFO:root:[  113] Training loss: 0.60497060, Validation loss: 0.61759319, Gradient norm: 0.19736634
INFO:root:At the start of the epoch: mem (CPU python)=18442.3515625MB; mem (CPU total)=18199.67578125MB
INFO:root:[  114] Training loss: 0.60498250, Validation loss: 0.61672836, Gradient norm: 0.22626989
INFO:root:At the start of the epoch: mem (CPU python)=18480.4453125MB; mem (CPU total)=18237.53515625MB
INFO:root:[  115] Training loss: 0.60488880, Validation loss: 0.61755819, Gradient norm: 0.17957658
INFO:root:At the start of the epoch: mem (CPU python)=18518.5390625MB; mem (CPU total)=18275.41796875MB
INFO:root:[  116] Training loss: 0.60493251, Validation loss: 0.61747288, Gradient norm: 0.18712905
INFO:root:At the start of the epoch: mem (CPU python)=18556.640625MB; mem (CPU total)=18313.7109375MB
INFO:root:[  117] Training loss: 0.60479909, Validation loss: 0.61727064, Gradient norm: 0.16594676
INFO:root:At the start of the epoch: mem (CPU python)=18594.734375MB; mem (CPU total)=18351.796875MB
INFO:root:[  118] Training loss: 0.60480495, Validation loss: 0.61782555, Gradient norm: 0.17924221
INFO:root:At the start of the epoch: mem (CPU python)=18632.828125MB; mem (CPU total)=18389.47265625MB
INFO:root:[  119] Training loss: 0.60493382, Validation loss: 0.61733407, Gradient norm: 0.19481932
INFO:root:At the start of the epoch: mem (CPU python)=18670.92578125MB; mem (CPU total)=18428.09765625MB
INFO:root:[  120] Training loss: 0.60470391, Validation loss: 0.61762368, Gradient norm: 0.19690599
INFO:root:At the start of the epoch: mem (CPU python)=18709.01953125MB; mem (CPU total)=18466.2109375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  121] Training loss: 0.60481511, Validation loss: 0.61666303, Gradient norm: 0.18836687
INFO:root:At the start of the epoch: mem (CPU python)=18747.11328125MB; mem (CPU total)=18504.3828125MB
INFO:root:[  122] Training loss: 0.60472085, Validation loss: 0.61704121, Gradient norm: 0.17343400
INFO:root:At the start of the epoch: mem (CPU python)=18785.2109375MB; mem (CPU total)=18542.7734375MB
INFO:root:[  123] Training loss: 0.60452790, Validation loss: 0.61761758, Gradient norm: 0.17238289
INFO:root:At the start of the epoch: mem (CPU python)=18823.30859375MB; mem (CPU total)=18580.89453125MB
INFO:root:[  124] Training loss: 0.60472835, Validation loss: 0.61744849, Gradient norm: 0.17089978
INFO:root:At the start of the epoch: mem (CPU python)=18861.40234375MB; mem (CPU total)=18618.62890625MB
INFO:root:[  125] Training loss: 0.60455420, Validation loss: 0.61673554, Gradient norm: 0.16647234
INFO:root:At the start of the epoch: mem (CPU python)=18899.49609375MB; mem (CPU total)=18656.51953125MB
INFO:root:[  126] Training loss: 0.60456028, Validation loss: 0.61709127, Gradient norm: 0.17841398
INFO:root:At the start of the epoch: mem (CPU python)=18937.59375MB; mem (CPU total)=18694.8828125MB
INFO:root:[  127] Training loss: 0.60463430, Validation loss: 0.61709314, Gradient norm: 0.17067337
INFO:root:At the start of the epoch: mem (CPU python)=18975.6875MB; mem (CPU total)=18732.98828125MB
INFO:root:[  128] Training loss: 0.60470314, Validation loss: 0.61722289, Gradient norm: 0.17030134
INFO:root:At the start of the epoch: mem (CPU python)=19013.78125MB; mem (CPU total)=18770.3671875MB
INFO:root:[  129] Training loss: 0.60443181, Validation loss: 0.61684855, Gradient norm: 0.19455705
INFO:root:At the start of the epoch: mem (CPU python)=19051.87890625MB; mem (CPU total)=18808.5MB
INFO:root:[  130] Training loss: 0.60461177, Validation loss: 0.61736249, Gradient norm: 0.17838248
INFO:root:At the start of the epoch: mem (CPU python)=19089.97265625MB; mem (CPU total)=18846.6171875MB
INFO:root:EP 130: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19128.0703125MB; mem (CPU total)=18884.94921875MB
INFO:root:Training the model took 12389.615s.
INFO:root:Emptying the cuda cache took 0.313s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85846
INFO:root:EnergyScoreTrain: 0.60461
INFO:root:CRPSTrain: 0.54195
INFO:root:Gaussian NLLTrain: 5.9776
INFO:root:CoverageTrain: 0.7659
INFO:root:IntervalWidthTrain: 3.09918
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87668
INFO:root:EnergyScoreValidation: 0.61727
INFO:root:CRPSValidation: 0.55194
INFO:root:Gaussian NLLValidation: 6.01558
INFO:root:CoverageValidation: 0.76077
INFO:root:IntervalWidthValidation: 3.09659
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87759
INFO:root:EnergyScoreTest: 0.61788
INFO:root:CRPSTest: 0.55243
INFO:root:Gaussian NLLTest: 5.98827
INFO:root:CoverageTest: 0.76008
INFO:root:IntervalWidthTest: 3.09168
INFO:root:After validation: mem (CPU python)=19171.140625MB; mem (CPU total)=18926.3203125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=19171.140625MB; mem (CPU total)=18926.3125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=19171.44140625MB; mem (CPU total)=18926.55859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=19171.47265625MB; mem (CPU total)=18926.55078125MB
INFO:root:[    1] Training loss: 0.77347626, Validation loss: 0.72306348, Gradient norm: 0.37935040
INFO:root:At the start of the epoch: mem (CPU python)=19209.4609375MB; mem (CPU total)=18966.19140625MB
INFO:root:[    2] Training loss: 0.72166928, Validation loss: 0.72164072, Gradient norm: 0.42044368
INFO:root:At the start of the epoch: mem (CPU python)=19247.5546875MB; mem (CPU total)=19004.35546875MB
INFO:root:[    3] Training loss: 0.72019722, Validation loss: 0.72048274, Gradient norm: 0.22643100
INFO:root:At the start of the epoch: mem (CPU python)=19285.66796875MB; mem (CPU total)=19042.74609375MB
INFO:root:[    4] Training loss: 0.71972674, Validation loss: 0.72018288, Gradient norm: 0.22114370
INFO:root:At the start of the epoch: mem (CPU python)=19323.78125MB; mem (CPU total)=19080.828125MB
INFO:root:[    5] Training loss: 0.71940609, Validation loss: 0.71964247, Gradient norm: 0.25577104
INFO:root:At the start of the epoch: mem (CPU python)=19361.890625MB; mem (CPU total)=19119.25MB
INFO:root:[    6] Training loss: 0.71895859, Validation loss: 0.71958531, Gradient norm: 0.16110151
INFO:root:At the start of the epoch: mem (CPU python)=19400.00390625MB; mem (CPU total)=19157.25MB
INFO:root:[    7] Training loss: 0.71790591, Validation loss: 0.71699867, Gradient norm: 0.15438859
INFO:root:At the start of the epoch: mem (CPU python)=19438.11328125MB; mem (CPU total)=19195.62890625MB
INFO:root:[    8] Training loss: 0.71417838, Validation loss: 0.71042672, Gradient norm: 0.20453010
INFO:root:At the start of the epoch: mem (CPU python)=19476.2109375MB; mem (CPU total)=19233.421875MB
INFO:root:[    9] Training loss: 0.70576836, Validation loss: 0.70126292, Gradient norm: 0.18418358
INFO:root:At the start of the epoch: mem (CPU python)=19514.30859375MB; mem (CPU total)=19271.62109375MB
INFO:root:[   10] Training loss: 0.69660901, Validation loss: 0.69299325, Gradient norm: 0.19296746
INFO:root:At the start of the epoch: mem (CPU python)=19552.40234375MB; mem (CPU total)=19309.99609375MB
INFO:root:[   11] Training loss: 0.68896551, Validation loss: 0.68642756, Gradient norm: 0.13394979
INFO:root:At the start of the epoch: mem (CPU python)=19590.49609375MB; mem (CPU total)=19348.66796875MB
INFO:root:[   12] Training loss: 0.68313215, Validation loss: 0.68039931, Gradient norm: 0.14237874
INFO:root:At the start of the epoch: mem (CPU python)=19628.58984375MB; mem (CPU total)=19387.04296875MB
INFO:root:[   13] Training loss: 0.67829790, Validation loss: 0.67805918, Gradient norm: 0.15037497
INFO:root:At the start of the epoch: mem (CPU python)=19666.6875MB; mem (CPU total)=19424.640625MB
INFO:root:[   14] Training loss: 0.67413500, Validation loss: 0.67347643, Gradient norm: 0.11327582
INFO:root:At the start of the epoch: mem (CPU python)=19704.78125MB; mem (CPU total)=19462.7421875MB
INFO:root:[   15] Training loss: 0.67042731, Validation loss: 0.67067389, Gradient norm: 0.13062337
INFO:root:At the start of the epoch: mem (CPU python)=19742.875MB; mem (CPU total)=19501.35546875MB
INFO:root:[   16] Training loss: 0.66760685, Validation loss: 0.66737218, Gradient norm: 0.14448010
INFO:root:At the start of the epoch: mem (CPU python)=19780.9765625MB; mem (CPU total)=19539.265625MB
INFO:root:[   17] Training loss: 0.66478152, Validation loss: 0.66518711, Gradient norm: 0.14569739
INFO:root:At the start of the epoch: mem (CPU python)=19819.0703125MB; mem (CPU total)=19577.4296875MB
INFO:root:[   18] Training loss: 0.66266755, Validation loss: 0.66308878, Gradient norm: 0.11514491
INFO:root:At the start of the epoch: mem (CPU python)=19857.1640625MB; mem (CPU total)=19616.171875MB
INFO:root:[   19] Training loss: 0.66035367, Validation loss: 0.66101818, Gradient norm: 0.14921930
INFO:root:At the start of the epoch: mem (CPU python)=19895.2578125MB; mem (CPU total)=19654.01953125MB
INFO:root:[   20] Training loss: 0.65854123, Validation loss: 0.65943960, Gradient norm: 0.13377887
INFO:root:At the start of the epoch: mem (CPU python)=19933.35546875MB; mem (CPU total)=19692.53125MB
INFO:root:[   21] Training loss: 0.65665199, Validation loss: 0.65749509, Gradient norm: 0.13726271
INFO:root:At the start of the epoch: mem (CPU python)=19971.44921875MB; mem (CPU total)=19730.1328125MB
INFO:root:[   22] Training loss: 0.65491852, Validation loss: 0.65634595, Gradient norm: 0.16609290
INFO:root:At the start of the epoch: mem (CPU python)=20009.54296875MB; mem (CPU total)=19768.51171875MB
INFO:root:[   23] Training loss: 0.65349696, Validation loss: 0.65464784, Gradient norm: 0.12763811
INFO:root:At the start of the epoch: mem (CPU python)=20047.640625MB; mem (CPU total)=19806.88671875MB
INFO:root:[   24] Training loss: 0.65217071, Validation loss: 0.65321334, Gradient norm: 0.16480948
INFO:root:At the start of the epoch: mem (CPU python)=20085.73828125MB; mem (CPU total)=19845.0234375MB
INFO:root:[   25] Training loss: 0.65077771, Validation loss: 0.65264517, Gradient norm: 0.12199096
INFO:root:At the start of the epoch: mem (CPU python)=20123.828125MB; mem (CPU total)=19883.25390625MB
INFO:root:[   26] Training loss: 0.64969516, Validation loss: 0.65125378, Gradient norm: 0.14908966
INFO:root:At the start of the epoch: mem (CPU python)=20161.9296875MB; mem (CPU total)=19921.6171875MB
INFO:root:[   27] Training loss: 0.64838944, Validation loss: 0.65027269, Gradient norm: 0.13261207
INFO:root:At the start of the epoch: mem (CPU python)=20200.0234375MB; mem (CPU total)=19959.9921875MB
INFO:root:[   28] Training loss: 0.64744748, Validation loss: 0.64931141, Gradient norm: 0.14648322
INFO:root:At the start of the epoch: mem (CPU python)=20238.1171875MB; mem (CPU total)=19997.87890625MB
INFO:root:[   29] Training loss: 0.64627454, Validation loss: 0.64835750, Gradient norm: 0.12302106
INFO:root:At the start of the epoch: mem (CPU python)=20276.2109375MB; mem (CPU total)=20035.6875MB
INFO:root:[   30] Training loss: 0.64528919, Validation loss: 0.64784227, Gradient norm: 0.14349708
INFO:root:At the start of the epoch: mem (CPU python)=20314.30859375MB; mem (CPU total)=20074.03125MB
INFO:root:[   31] Training loss: 0.64424038, Validation loss: 0.64635962, Gradient norm: 0.18005639
INFO:root:At the start of the epoch: mem (CPU python)=20352.40234375MB; mem (CPU total)=20112.4296875MB
INFO:root:[   32] Training loss: 0.64341994, Validation loss: 0.64520905, Gradient norm: 0.17603264
INFO:root:At the start of the epoch: mem (CPU python)=20390.49609375MB; mem (CPU total)=20150.48828125MB
INFO:root:[   33] Training loss: 0.64242358, Validation loss: 0.64554536, Gradient norm: 0.14281102
INFO:root:At the start of the epoch: mem (CPU python)=20428.59765625MB; mem (CPU total)=20188.37890625MB
INFO:root:[   34] Training loss: 0.64156074, Validation loss: 0.64407787, Gradient norm: 0.13972956
INFO:root:At the start of the epoch: mem (CPU python)=20466.69140625MB; mem (CPU total)=20226.05078125MB
INFO:root:[   35] Training loss: 0.64070655, Validation loss: 0.64323370, Gradient norm: 0.16780793
INFO:root:At the start of the epoch: mem (CPU python)=20504.78515625MB; mem (CPU total)=20264.15625MB
INFO:root:[   36] Training loss: 0.64011154, Validation loss: 0.64224747, Gradient norm: 0.21312145
INFO:root:At the start of the epoch: mem (CPU python)=20542.8828125MB; mem (CPU total)=20302.31640625MB
INFO:root:[   37] Training loss: 0.63936359, Validation loss: 0.64186367, Gradient norm: 0.20888522
INFO:root:At the start of the epoch: mem (CPU python)=20580.98046875MB; mem (CPU total)=20340.703125MB
INFO:root:[   38] Training loss: 0.63843553, Validation loss: 0.64133957, Gradient norm: 0.14315288
INFO:root:At the start of the epoch: mem (CPU python)=20619.07421875MB; mem (CPU total)=20378.8828125MB
INFO:root:[   39] Training loss: 0.63769052, Validation loss: 0.64028884, Gradient norm: 0.17315547
INFO:root:At the start of the epoch: mem (CPU python)=20657.16796875MB; mem (CPU total)=20417.0MB
INFO:root:[   40] Training loss: 0.63691674, Validation loss: 0.64090353, Gradient norm: 0.15178553
INFO:root:At the start of the epoch: mem (CPU python)=20695.26953125MB; mem (CPU total)=20455.3828125MB
INFO:root:[   41] Training loss: 0.63652060, Validation loss: 0.63969313, Gradient norm: 0.27590477
INFO:root:At the start of the epoch: mem (CPU python)=20733.36328125MB; mem (CPU total)=20494.09375MB
INFO:root:[   42] Training loss: 0.63579384, Validation loss: 0.63921661, Gradient norm: 0.21786388
INFO:root:At the start of the epoch: mem (CPU python)=20771.45703125MB; mem (CPU total)=20531.98828125MB
INFO:root:[   43] Training loss: 0.63517260, Validation loss: 0.63911401, Gradient norm: 0.20365021
INFO:root:At the start of the epoch: mem (CPU python)=20809.5546875MB; mem (CPU total)=20570.16015625MB
INFO:root:[   44] Training loss: 0.63435274, Validation loss: 0.63858832, Gradient norm: 0.19286158
INFO:root:At the start of the epoch: mem (CPU python)=20847.6484375MB; mem (CPU total)=20608.3046875MB
INFO:root:[   45] Training loss: 0.63408928, Validation loss: 0.63754674, Gradient norm: 0.20087038
INFO:root:At the start of the epoch: mem (CPU python)=20885.7421875MB; mem (CPU total)=20646.6328125MB
INFO:root:[   46] Training loss: 0.63342146, Validation loss: 0.63769526, Gradient norm: 0.23798716
INFO:root:At the start of the epoch: mem (CPU python)=20923.8359375MB; mem (CPU total)=20684.7578125MB
INFO:root:[   47] Training loss: 0.63289799, Validation loss: 0.63715736, Gradient norm: 0.22532477
INFO:root:At the start of the epoch: mem (CPU python)=20961.93359375MB; mem (CPU total)=20723.23828125MB
INFO:root:[   48] Training loss: 0.63224734, Validation loss: 0.63631274, Gradient norm: 0.18533072
INFO:root:At the start of the epoch: mem (CPU python)=21000.02734375MB; mem (CPU total)=20760.87109375MB
INFO:root:[   49] Training loss: 0.63202718, Validation loss: 0.63587408, Gradient norm: 0.30762581
INFO:root:At the start of the epoch: mem (CPU python)=21038.12109375MB; mem (CPU total)=20798.921875MB
INFO:root:[   50] Training loss: 0.63143840, Validation loss: 0.63495834, Gradient norm: 0.35114647
INFO:root:At the start of the epoch: mem (CPU python)=21076.22265625MB; mem (CPU total)=20837.73046875MB
INFO:root:[   51] Training loss: 0.63081394, Validation loss: 0.63483578, Gradient norm: 0.24123189
INFO:root:At the start of the epoch: mem (CPU python)=21114.3125MB; mem (CPU total)=20875.60546875MB
INFO:root:[   52] Training loss: 0.63038862, Validation loss: 0.63506434, Gradient norm: 0.30049204
INFO:root:At the start of the epoch: mem (CPU python)=21152.41015625MB; mem (CPU total)=20913.77734375MB
INFO:root:[   53] Training loss: 0.62989997, Validation loss: 0.63398460, Gradient norm: 0.26488604
INFO:root:At the start of the epoch: mem (CPU python)=21190.50390625MB; mem (CPU total)=20952.17578125MB
INFO:root:[   54] Training loss: 0.62952034, Validation loss: 0.63406709, Gradient norm: 0.29886329
INFO:root:At the start of the epoch: mem (CPU python)=21228.6015625MB; mem (CPU total)=20990.35546875MB
INFO:root:[   55] Training loss: 0.62903668, Validation loss: 0.63352386, Gradient norm: 0.30098524
INFO:root:At the start of the epoch: mem (CPU python)=21266.6953125MB; mem (CPU total)=21028.23046875MB
INFO:root:[   56] Training loss: 0.62847032, Validation loss: 0.63359510, Gradient norm: 0.27855486
INFO:root:At the start of the epoch: mem (CPU python)=21304.7890625MB; mem (CPU total)=21066.59765625MB
INFO:root:[   57] Training loss: 0.62829994, Validation loss: 0.63260996, Gradient norm: 0.35491474
INFO:root:At the start of the epoch: mem (CPU python)=21342.88671875MB; mem (CPU total)=21104.73046875MB
INFO:root:[   58] Training loss: 0.62775964, Validation loss: 0.63226025, Gradient norm: 0.36748396
INFO:root:At the start of the epoch: mem (CPU python)=21380.98046875MB; mem (CPU total)=21142.58203125MB
INFO:root:[   59] Training loss: 0.62745222, Validation loss: 0.63276172, Gradient norm: 0.38230561
INFO:root:At the start of the epoch: mem (CPU python)=21419.07421875MB; mem (CPU total)=21180.82421875MB
INFO:root:[   60] Training loss: 0.62703660, Validation loss: 0.63214989, Gradient norm: 0.38472568
INFO:root:At the start of the epoch: mem (CPU python)=21457.1796875MB; mem (CPU total)=21218.69140625MB
INFO:root:[   61] Training loss: 0.62662801, Validation loss: 0.63193091, Gradient norm: 0.37143377
INFO:root:At the start of the epoch: mem (CPU python)=21495.2734375MB; mem (CPU total)=21256.79296875MB
INFO:root:[   62] Training loss: 0.62634252, Validation loss: 0.63217554, Gradient norm: 0.43501042
INFO:root:At the start of the epoch: mem (CPU python)=21533.3671875MB; mem (CPU total)=21295.1796875MB
INFO:root:[   63] Training loss: 0.62668201, Validation loss: 0.63323173, Gradient norm: 1.04914804
INFO:root:At the start of the epoch: mem (CPU python)=21571.4609375MB; mem (CPU total)=21333.03515625MB
INFO:root:[   64] Training loss: 0.62606528, Validation loss: 0.63099899, Gradient norm: 0.86778528
INFO:root:At the start of the epoch: mem (CPU python)=21609.55859375MB; mem (CPU total)=21371.140625MB
INFO:root:[   65] Training loss: 0.62531207, Validation loss: 0.63052967, Gradient norm: 0.30605329
INFO:root:At the start of the epoch: mem (CPU python)=21647.65234375MB; mem (CPU total)=21409.58984375MB
INFO:root:[   66] Training loss: 0.62497664, Validation loss: 0.62996027, Gradient norm: 0.30543664
INFO:root:At the start of the epoch: mem (CPU python)=21685.74609375MB; mem (CPU total)=21447.703125MB
INFO:root:[   67] Training loss: 0.62456395, Validation loss: 0.62950933, Gradient norm: 0.34919325
INFO:root:At the start of the epoch: mem (CPU python)=21723.84375MB; mem (CPU total)=21485.88671875MB
INFO:root:[   68] Training loss: 0.62414784, Validation loss: 0.63007033, Gradient norm: 0.47548204
INFO:root:At the start of the epoch: mem (CPU python)=21761.9453125MB; mem (CPU total)=21523.796875MB
INFO:root:[   69] Training loss: 0.62406617, Validation loss: 0.62975894, Gradient norm: 0.46862549
INFO:root:At the start of the epoch: mem (CPU python)=21800.0390625MB; mem (CPU total)=21561.953125MB
INFO:root:[   70] Training loss: 0.62367137, Validation loss: 0.62901079, Gradient norm: 0.59182278
INFO:root:At the start of the epoch: mem (CPU python)=21838.1328125MB; mem (CPU total)=21600.29296875MB
INFO:root:[   71] Training loss: 0.62392210, Validation loss: 0.63001014, Gradient norm: 1.07473222
INFO:root:At the start of the epoch: mem (CPU python)=21876.23046875MB; mem (CPU total)=21638.78515625MB
INFO:root:[   72] Training loss: 0.62306874, Validation loss: 0.62876804, Gradient norm: 0.49812654
INFO:root:At the start of the epoch: mem (CPU python)=21914.32421875MB; mem (CPU total)=21676.8984375MB
INFO:root:[   73] Training loss: 0.62295128, Validation loss: 0.62965571, Gradient norm: 0.76236304
INFO:root:At the start of the epoch: mem (CPU python)=21952.41796875MB; mem (CPU total)=21715.28515625MB
INFO:root:[   74] Training loss: 0.62322404, Validation loss: 0.63089409, Gradient norm: 1.56622183
INFO:root:At the start of the epoch: mem (CPU python)=21990.515625MB; mem (CPU total)=21753.3984375MB
INFO:root:[   75] Training loss: 0.62244148, Validation loss: 0.62973984, Gradient norm: 0.86491961
INFO:root:At the start of the epoch: mem (CPU python)=22028.609375MB; mem (CPU total)=21791.23046875MB
INFO:root:[   76] Training loss: 0.62207258, Validation loss: 0.62835712, Gradient norm: 0.54439062
INFO:root:At the start of the epoch: mem (CPU python)=22066.70703125MB; mem (CPU total)=21829.6796875MB
INFO:root:[   77] Training loss: 0.62320331, Validation loss: 0.63141121, Gradient norm: 1.70798948
INFO:root:At the start of the epoch: mem (CPU python)=22104.8046875MB; mem (CPU total)=21867.58203125MB
INFO:root:[   78] Training loss: 0.62358560, Validation loss: 0.63307412, Gradient norm: 2.45773685
INFO:root:At the start of the epoch: mem (CPU python)=22142.8984375MB; mem (CPU total)=21905.44140625MB
INFO:root:[   79] Training loss: 0.62316227, Validation loss: 0.62981654, Gradient norm: 2.13665184
INFO:root:At the start of the epoch: mem (CPU python)=22180.9921875MB; mem (CPU total)=21943.2734375MB
INFO:root:[   80] Training loss: 0.62285324, Validation loss: 0.62887158, Gradient norm: 1.95960697
INFO:root:At the start of the epoch: mem (CPU python)=22219.0859375MB; mem (CPU total)=21981.40234375MB
INFO:root:[   81] Training loss: 0.62199732, Validation loss: 0.62813976, Gradient norm: 1.24929522
INFO:root:At the start of the epoch: mem (CPU python)=22257.18359375MB; mem (CPU total)=22019.515625MB
INFO:root:[   82] Training loss: 0.62086595, Validation loss: 0.62769298, Gradient norm: 0.35076156
INFO:root:At the start of the epoch: mem (CPU python)=22295.27734375MB; mem (CPU total)=22058.05078125MB
INFO:root:[   83] Training loss: 0.62070758, Validation loss: 0.62742742, Gradient norm: 0.44403337
INFO:root:At the start of the epoch: mem (CPU python)=22333.37109375MB; mem (CPU total)=22095.703125MB
INFO:root:[   84] Training loss: 0.62035602, Validation loss: 0.62707745, Gradient norm: 0.51664537
INFO:root:At the start of the epoch: mem (CPU python)=22371.47265625MB; mem (CPU total)=22134.0546875MB
INFO:root:[   85] Training loss: 0.62028144, Validation loss: 0.62696773, Gradient norm: 1.30843503
INFO:root:At the start of the epoch: mem (CPU python)=22409.56640625MB; mem (CPU total)=22171.8515625MB
INFO:root:[   86] Training loss: 0.62016956, Validation loss: 0.62740348, Gradient norm: 1.46400832
INFO:root:At the start of the epoch: mem (CPU python)=22447.66015625MB; mem (CPU total)=22210.44140625MB
INFO:root:[   87] Training loss: 0.62087095, Validation loss: 0.62831511, Gradient norm: 2.08729091
INFO:root:At the start of the epoch: mem (CPU python)=22485.75390625MB; mem (CPU total)=22248.203125MB
INFO:root:[   88] Training loss: 0.62095592, Validation loss: 0.62714116, Gradient norm: 2.29480851
INFO:root:At the start of the epoch: mem (CPU python)=22523.8515625MB; mem (CPU total)=22286.2578125MB
INFO:root:[   89] Training loss: 0.62046860, Validation loss: 0.62901219, Gradient norm: 2.10734139
INFO:root:At the start of the epoch: mem (CPU python)=22561.9453125MB; mem (CPU total)=22323.94140625MB
INFO:root:[   90] Training loss: 0.62049896, Validation loss: 0.62712517, Gradient norm: 2.02739655
INFO:root:At the start of the epoch: mem (CPU python)=22600.0390625MB; mem (CPU total)=22362.29296875MB
INFO:root:[   91] Training loss: 0.62010302, Validation loss: 0.62669135, Gradient norm: 1.94395205
INFO:root:At the start of the epoch: mem (CPU python)=22638.140625MB; mem (CPU total)=22399.90234375MB
INFO:root:[   92] Training loss: 0.61984227, Validation loss: 0.62982410, Gradient norm: 1.87889006
INFO:root:At the start of the epoch: mem (CPU python)=22676.234375MB; mem (CPU total)=22437.98828125MB
INFO:root:[   93] Training loss: 0.61983266, Validation loss: 0.62687899, Gradient norm: 1.85721799
INFO:root:At the start of the epoch: mem (CPU python)=22714.328125MB; mem (CPU total)=22476.5859375MB
INFO:root:[   94] Training loss: 0.61878309, Validation loss: 0.62524510, Gradient norm: 0.80278923
INFO:root:At the start of the epoch: mem (CPU python)=22752.42578125MB; mem (CPU total)=22514.94921875MB
INFO:root:[   95] Training loss: 0.61827423, Validation loss: 0.62552782, Gradient norm: 0.45975603
INFO:root:At the start of the epoch: mem (CPU python)=22790.51953125MB; mem (CPU total)=22553.28125MB
INFO:root:[   96] Training loss: 0.61825310, Validation loss: 0.62596340, Gradient norm: 0.64588466
INFO:root:At the start of the epoch: mem (CPU python)=22828.61328125MB; mem (CPU total)=22591.31640625MB
INFO:root:[   97] Training loss: 0.61770778, Validation loss: 0.62566431, Gradient norm: 0.69209180
INFO:root:At the start of the epoch: mem (CPU python)=22866.70703125MB; mem (CPU total)=22629.3671875MB
INFO:root:[   98] Training loss: 0.61745749, Validation loss: 0.62423484, Gradient norm: 1.12190687
INFO:root:At the start of the epoch: mem (CPU python)=22904.8046875MB; mem (CPU total)=22667.47265625MB
INFO:root:[   99] Training loss: 0.61740484, Validation loss: 0.62522122, Gradient norm: 1.48685611
INFO:root:At the start of the epoch: mem (CPU python)=22942.8984375MB; mem (CPU total)=22705.8203125MB
INFO:root:[  100] Training loss: 0.61705209, Validation loss: 0.62547311, Gradient norm: 1.65304354
INFO:root:At the start of the epoch: mem (CPU python)=22980.99609375MB; mem (CPU total)=22743.96484375MB
INFO:root:[  101] Training loss: 0.61721332, Validation loss: 0.62505749, Gradient norm: 1.61930655
INFO:root:At the start of the epoch: mem (CPU python)=23019.09375MB; mem (CPU total)=22782.34375MB
INFO:root:[  102] Training loss: 0.61671287, Validation loss: 0.62540633, Gradient norm: 1.71619460
INFO:root:At the start of the epoch: mem (CPU python)=23057.1875MB; mem (CPU total)=22820.46875MB
INFO:root:[  103] Training loss: 0.61650618, Validation loss: 0.62508017, Gradient norm: 1.34562748
INFO:root:At the start of the epoch: mem (CPU python)=23095.28125MB; mem (CPU total)=22858.58203125MB
INFO:root:[  104] Training loss: 0.61669746, Validation loss: 0.62507371, Gradient norm: 1.76954436
INFO:root:At the start of the epoch: mem (CPU python)=23133.375MB; mem (CPU total)=22896.70703125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  105] Training loss: 0.61612991, Validation loss: 0.62438468, Gradient norm: 1.76795632
INFO:root:At the start of the epoch: mem (CPU python)=23171.47265625MB; mem (CPU total)=22935.30859375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  106] Training loss: 0.61513268, Validation loss: 0.62395824, Gradient norm: 0.61603248
INFO:root:At the start of the epoch: mem (CPU python)=23209.56640625MB; mem (CPU total)=22973.66796875MB
INFO:root:[  107] Training loss: 0.61453577, Validation loss: 0.62305595, Gradient norm: 0.38328632
INFO:root:At the start of the epoch: mem (CPU python)=23247.66015625MB; mem (CPU total)=23011.5078125MB
INFO:root:[  108] Training loss: 0.61436102, Validation loss: 0.62360725, Gradient norm: 0.34763432
INFO:root:At the start of the epoch: mem (CPU python)=23285.7578125MB; mem (CPU total)=23049.625MB
INFO:root:[  109] Training loss: 0.61428971, Validation loss: 0.62326295, Gradient norm: 0.39835919
INFO:root:At the start of the epoch: mem (CPU python)=23323.85546875MB; mem (CPU total)=23087.5078125MB
INFO:root:[  110] Training loss: 0.61415853, Validation loss: 0.62271115, Gradient norm: 0.37926625
INFO:root:At the start of the epoch: mem (CPU python)=23361.94921875MB; mem (CPU total)=23129.26171875MB
INFO:root:[  111] Training loss: 0.61417985, Validation loss: 0.62327245, Gradient norm: 0.43163281
INFO:root:At the start of the epoch: mem (CPU python)=23400.05078125MB; mem (CPU total)=23166.8984375MB
INFO:root:[  112] Training loss: 0.61412807, Validation loss: 0.62308213, Gradient norm: 0.43894630
INFO:root:At the start of the epoch: mem (CPU python)=23438.14453125MB; mem (CPU total)=23209.5546875MB
INFO:root:[  113] Training loss: 0.61413558, Validation loss: 0.62284530, Gradient norm: 0.44176714
INFO:root:At the start of the epoch: mem (CPU python)=23476.23828125MB; mem (CPU total)=23246.90625MB
INFO:root:[  114] Training loss: 0.61398615, Validation loss: 0.62323981, Gradient norm: 0.42638706
INFO:root:At the start of the epoch: mem (CPU python)=23514.33203125MB; mem (CPU total)=23285.04296875MB
INFO:root:[  115] Training loss: 0.61403972, Validation loss: 0.62328040, Gradient norm: 0.44244638
INFO:root:At the start of the epoch: mem (CPU python)=23552.4296875MB; mem (CPU total)=23322.65625MB
INFO:root:[  116] Training loss: 0.61402842, Validation loss: 0.62333206, Gradient norm: 0.50935525
INFO:root:At the start of the epoch: mem (CPU python)=23590.5234375MB; mem (CPU total)=23361.046875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  117] Training loss: 0.61386120, Validation loss: 0.62308471, Gradient norm: 0.53237899
INFO:root:At the start of the epoch: mem (CPU python)=23628.62109375MB; mem (CPU total)=23398.64453125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  118] Training loss: 0.61366819, Validation loss: 0.62347362, Gradient norm: 0.39648956
INFO:root:At the start of the epoch: mem (CPU python)=23666.71875MB; mem (CPU total)=23436.99609375MB
INFO:root:[  119] Training loss: 0.61349073, Validation loss: 0.62304765, Gradient norm: 0.30000072
INFO:root:At the start of the epoch: mem (CPU python)=23704.8125MB; mem (CPU total)=23474.1875MB
INFO:root:[  120] Training loss: 0.61336502, Validation loss: 0.62267739, Gradient norm: 0.31251336
INFO:root:At the start of the epoch: mem (CPU python)=23742.90625MB; mem (CPU total)=23512.49609375MB
INFO:root:[  121] Training loss: 0.61344150, Validation loss: 0.62250839, Gradient norm: 0.33632460
INFO:root:At the start of the epoch: mem (CPU python)=23781.0MB; mem (CPU total)=23550.859375MB
INFO:root:[  122] Training loss: 0.61337346, Validation loss: 0.62319790, Gradient norm: 0.30360825
INFO:root:At the start of the epoch: mem (CPU python)=23819.09765625MB; mem (CPU total)=23588.98828125MB
INFO:root:[  123] Training loss: 0.61336015, Validation loss: 0.62297845, Gradient norm: 0.31475880
INFO:root:At the start of the epoch: mem (CPU python)=23857.19140625MB; mem (CPU total)=23627.0703125MB
INFO:root:[  124] Training loss: 0.61345007, Validation loss: 0.62299674, Gradient norm: 0.36401211
INFO:root:At the start of the epoch: mem (CPU python)=23895.28515625MB; mem (CPU total)=23664.53515625MB
INFO:root:[  125] Training loss: 0.61322550, Validation loss: 0.62281470, Gradient norm: 0.31557329
INFO:root:At the start of the epoch: mem (CPU python)=23933.38671875MB; mem (CPU total)=23702.65625MB
INFO:root:[  126] Training loss: 0.61332744, Validation loss: 0.62246039, Gradient norm: 0.34972104
INFO:root:At the start of the epoch: mem (CPU python)=23971.48046875MB; mem (CPU total)=23741.53515625MB
INFO:root:[  127] Training loss: 0.61328739, Validation loss: 0.62322704, Gradient norm: 0.35178005
INFO:root:At the start of the epoch: mem (CPU python)=24009.57421875MB; mem (CPU total)=23779.8828125MB
INFO:root:[  128] Training loss: 0.61329511, Validation loss: 0.62338108, Gradient norm: 0.31828797
INFO:root:At the start of the epoch: mem (CPU python)=24047.671875MB; mem (CPU total)=23818.02734375MB
INFO:root:[  129] Training loss: 0.61335431, Validation loss: 0.62281407, Gradient norm: 0.33283635
INFO:root:At the start of the epoch: mem (CPU python)=24085.765625MB; mem (CPU total)=23855.875MB
INFO:root:[  130] Training loss: 0.61335355, Validation loss: 0.62253334, Gradient norm: 0.36306192
INFO:root:At the start of the epoch: mem (CPU python)=24123.859375MB; mem (CPU total)=23893.52734375MB
INFO:root:[  131] Training loss: 0.61336028, Validation loss: 0.62261562, Gradient norm: 0.38932983
INFO:root:At the start of the epoch: mem (CPU python)=24161.953125MB; mem (CPU total)=23931.5859375MB
INFO:root:[  132] Training loss: 0.61316615, Validation loss: 0.62288338, Gradient norm: 0.34559142
INFO:root:At the start of the epoch: mem (CPU python)=24200.05078125MB; mem (CPU total)=23969.9296875MB
INFO:root:[  133] Training loss: 0.61335775, Validation loss: 0.62236503, Gradient norm: 0.33453949
INFO:root:At the start of the epoch: mem (CPU python)=24238.14453125MB; mem (CPU total)=24008.55078125MB
INFO:root:[  134] Training loss: 0.61323144, Validation loss: 0.62296453, Gradient norm: 0.36682821
INFO:root:At the start of the epoch: mem (CPU python)=24276.23828125MB; mem (CPU total)=24046.47265625MB
INFO:root:[  135] Training loss: 0.61321252, Validation loss: 0.62295127, Gradient norm: 0.39918473
INFO:root:At the start of the epoch: mem (CPU python)=24314.33984375MB; mem (CPU total)=24083.578125MB
INFO:root:[  136] Training loss: 0.61316188, Validation loss: 0.62289377, Gradient norm: 0.38397208
INFO:root:At the start of the epoch: mem (CPU python)=24352.43359375MB; mem (CPU total)=24121.68359375MB
INFO:root:[  137] Training loss: 0.61336335, Validation loss: 0.62309555, Gradient norm: 0.41413965
INFO:root:At the start of the epoch: mem (CPU python)=24390.52734375MB; mem (CPU total)=24159.3203125MB
INFO:root:[  138] Training loss: 0.61327065, Validation loss: 0.62288965, Gradient norm: 0.37870663
INFO:root:At the start of the epoch: mem (CPU python)=24428.62109375MB; mem (CPU total)=24197.5625MB
INFO:root:[  139] Training loss: 0.61308415, Validation loss: 0.62330027, Gradient norm: 0.38427736
INFO:root:At the start of the epoch: mem (CPU python)=24466.71875MB; mem (CPU total)=24235.75390625MB
INFO:root:[  140] Training loss: 0.61323744, Validation loss: 0.62300538, Gradient norm: 0.35971358
INFO:root:At the start of the epoch: mem (CPU python)=24504.8125MB; mem (CPU total)=24274.12890625MB
INFO:root:[  141] Training loss: 0.61314796, Validation loss: 0.62325755, Gradient norm: 0.38544895
INFO:root:At the start of the epoch: mem (CPU python)=24542.90625MB; mem (CPU total)=24311.9765625MB
INFO:root:[  142] Training loss: 0.61304304, Validation loss: 0.62268135, Gradient norm: 0.36056156
INFO:root:At the start of the epoch: mem (CPU python)=24581.00390625MB; mem (CPU total)=24349.64453125MB
INFO:root:EP 142: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=24619.1015625MB; mem (CPU total)=24387.51953125MB
INFO:root:Training the model took 14394.703s.
INFO:root:Emptying the cuda cache took 0.313s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87047
INFO:root:EnergyScoreTrain: 0.61315
INFO:root:CRPSTrain: 0.55761
INFO:root:Gaussian NLLTrain: 7.2848
INFO:root:CoverageTrain: 0.75043
INFO:root:IntervalWidthTrain: 3.09731
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8843
INFO:root:EnergyScoreValidation: 0.62282
INFO:root:CRPSValidation: 0.56518
INFO:root:Gaussian NLLValidation: 7.37887
INFO:root:CoverageValidation: 0.7462
INFO:root:IntervalWidthValidation: 3.09045
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88491
INFO:root:EnergyScoreTest: 0.62328
INFO:root:CRPSTest: 0.56568
INFO:root:Gaussian NLLTest: 7.31944
INFO:root:CoverageTest: 0.74592
INFO:root:IntervalWidthTest: 3.09214
INFO:root:After validation: mem (CPU python)=24662.26953125MB; mem (CPU total)=24429.109375MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=24662.26953125MB; mem (CPU total)=24428.84765625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=24662.46875MB; mem (CPU total)=24428.84765625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=24662.52734375MB; mem (CPU total)=24429.3203125MB
INFO:root:[    1] Training loss: 0.77608752, Validation loss: 0.72510120, Gradient norm: 0.35847998
INFO:root:At the start of the epoch: mem (CPU python)=24701.265625MB; mem (CPU total)=24470.1796875MB
INFO:root:[    2] Training loss: 0.72200339, Validation loss: 0.72122556, Gradient norm: 0.38688525
INFO:root:At the start of the epoch: mem (CPU python)=24739.359375MB; mem (CPU total)=24508.27734375MB
INFO:root:[    3] Training loss: 0.72039522, Validation loss: 0.72082060, Gradient norm: 0.27786265
INFO:root:At the start of the epoch: mem (CPU python)=24777.47265625MB; mem (CPU total)=24546.41796875MB
INFO:root:[    4] Training loss: 0.71996430, Validation loss: 0.72018283, Gradient norm: 0.29113384
INFO:root:At the start of the epoch: mem (CPU python)=24815.59765625MB; mem (CPU total)=24584.73828125MB
INFO:root:[    5] Training loss: 0.71951679, Validation loss: 0.71974776, Gradient norm: 0.16779757
INFO:root:At the start of the epoch: mem (CPU python)=24853.70703125MB; mem (CPU total)=24623.078125MB
INFO:root:[    6] Training loss: 0.71925526, Validation loss: 0.71942794, Gradient norm: 0.18881640
INFO:root:At the start of the epoch: mem (CPU python)=24891.80859375MB; mem (CPU total)=24660.91796875MB
INFO:root:[    7] Training loss: 0.71885102, Validation loss: 0.71878901, Gradient norm: 0.17092676
INFO:root:At the start of the epoch: mem (CPU python)=24929.90625MB; mem (CPU total)=24698.88671875MB
INFO:root:[    8] Training loss: 0.71832859, Validation loss: 0.71844250, Gradient norm: 0.11532790
INFO:root:At the start of the epoch: mem (CPU python)=24968.0MB; mem (CPU total)=24737.4140625MB
INFO:root:[    9] Training loss: 0.71706609, Validation loss: 0.71601512, Gradient norm: 0.17590337
INFO:root:At the start of the epoch: mem (CPU python)=25006.09375MB; mem (CPU total)=24775.265625MB
INFO:root:[   10] Training loss: 0.71151023, Validation loss: 0.70743937, Gradient norm: 0.18236549
INFO:root:At the start of the epoch: mem (CPU python)=25044.19140625MB; mem (CPU total)=24813.6484375MB
INFO:root:[   11] Training loss: 0.70261777, Validation loss: 0.69947072, Gradient norm: 0.13749443
INFO:root:At the start of the epoch: mem (CPU python)=25082.28515625MB; mem (CPU total)=24851.76171875MB
INFO:root:[   12] Training loss: 0.69509157, Validation loss: 0.69257685, Gradient norm: 0.13503788
INFO:root:At the start of the epoch: mem (CPU python)=25120.37890625MB; mem (CPU total)=24889.80859375MB
INFO:root:[   13] Training loss: 0.68925526, Validation loss: 0.68736222, Gradient norm: 0.14889357
INFO:root:At the start of the epoch: mem (CPU python)=25158.4765625MB; mem (CPU total)=24927.81640625MB
INFO:root:[   14] Training loss: 0.68435740, Validation loss: 0.68304024, Gradient norm: 0.13203219
INFO:root:At the start of the epoch: mem (CPU python)=25196.5703125MB; mem (CPU total)=24966.08203125MB
INFO:root:[   15] Training loss: 0.67986175, Validation loss: 0.67834305, Gradient norm: 0.12710658
INFO:root:At the start of the epoch: mem (CPU python)=25234.67578125MB; mem (CPU total)=25004.68359375MB
INFO:root:[   16] Training loss: 0.67585660, Validation loss: 0.67487538, Gradient norm: 0.13749462
INFO:root:At the start of the epoch: mem (CPU python)=25272.7734375MB; mem (CPU total)=25042.890625MB
INFO:root:[   17] Training loss: 0.67216825, Validation loss: 0.67155248, Gradient norm: 0.12672067
INFO:root:At the start of the epoch: mem (CPU python)=25310.87109375MB; mem (CPU total)=25080.671875MB
INFO:root:[   18] Training loss: 0.66895307, Validation loss: 0.66889361, Gradient norm: 0.13628987
INFO:root:At the start of the epoch: mem (CPU python)=25348.96484375MB; mem (CPU total)=25118.62890625MB
INFO:root:[   19] Training loss: 0.66599839, Validation loss: 0.66613083, Gradient norm: 0.16068914
INFO:root:At the start of the epoch: mem (CPU python)=25387.05859375MB; mem (CPU total)=25156.51171875MB
INFO:root:[   20] Training loss: 0.66336429, Validation loss: 0.66342793, Gradient norm: 0.12036317
INFO:root:At the start of the epoch: mem (CPU python)=25425.15625MB; mem (CPU total)=25195.51171875MB
INFO:root:[   21] Training loss: 0.66093363, Validation loss: 0.66193527, Gradient norm: 0.12318696
INFO:root:At the start of the epoch: mem (CPU python)=25463.25MB; mem (CPU total)=25233.01953125MB
INFO:root:[   22] Training loss: 0.65876705, Validation loss: 0.65905004, Gradient norm: 0.13127678
INFO:root:At the start of the epoch: mem (CPU python)=25501.34765625MB; mem (CPU total)=25270.9140625MB
INFO:root:[   23] Training loss: 0.65677980, Validation loss: 0.65797951, Gradient norm: 0.11748498
INFO:root:At the start of the epoch: mem (CPU python)=25539.44140625MB; mem (CPU total)=25309.33203125MB
INFO:root:[   24] Training loss: 0.65498723, Validation loss: 0.65568830, Gradient norm: 0.14630002
INFO:root:At the start of the epoch: mem (CPU python)=25577.5390625MB; mem (CPU total)=25347.3046875MB
INFO:root:[   25] Training loss: 0.65356681, Validation loss: 0.65470500, Gradient norm: 0.15499344
INFO:root:At the start of the epoch: mem (CPU python)=25615.6328125MB; mem (CPU total)=25385.96484375MB
INFO:root:[   26] Training loss: 0.65198213, Validation loss: 0.65342589, Gradient norm: 0.15060509
INFO:root:At the start of the epoch: mem (CPU python)=25653.7265625MB; mem (CPU total)=25424.1171875MB
INFO:root:[   27] Training loss: 0.65030075, Validation loss: 0.65088347, Gradient norm: 0.11938227
INFO:root:At the start of the epoch: mem (CPU python)=25691.82421875MB; mem (CPU total)=25461.80859375MB
INFO:root:[   28] Training loss: 0.64898593, Validation loss: 0.65060226, Gradient norm: 0.15294137
INFO:root:At the start of the epoch: mem (CPU python)=25729.91796875MB; mem (CPU total)=25500.25MB
INFO:root:[   29] Training loss: 0.64764405, Validation loss: 0.64885870, Gradient norm: 0.16338263
INFO:root:At the start of the epoch: mem (CPU python)=25768.01171875MB; mem (CPU total)=25538.42578125MB
INFO:root:[   30] Training loss: 0.64639777, Validation loss: 0.64845667, Gradient norm: 0.14954896
INFO:root:At the start of the epoch: mem (CPU python)=25806.109375MB; mem (CPU total)=25576.8671875MB
INFO:root:[   31] Training loss: 0.64507264, Validation loss: 0.64750598, Gradient norm: 0.13941052
INFO:root:At the start of the epoch: mem (CPU python)=25844.20703125MB; mem (CPU total)=25614.796875MB
INFO:root:[   32] Training loss: 0.64405392, Validation loss: 0.64594056, Gradient norm: 0.16739876
INFO:root:At the start of the epoch: mem (CPU python)=25882.30078125MB; mem (CPU total)=25652.47265625MB
INFO:root:[   33] Training loss: 0.64295978, Validation loss: 0.64535943, Gradient norm: 0.16139670
INFO:root:At the start of the epoch: mem (CPU python)=25920.39453125MB; mem (CPU total)=25690.8671875MB
INFO:root:[   34] Training loss: 0.64189006, Validation loss: 0.64412841, Gradient norm: 0.16526483
INFO:root:At the start of the epoch: mem (CPU python)=25958.4921875MB; mem (CPU total)=25729.25MB
INFO:root:[   35] Training loss: 0.64078189, Validation loss: 0.64330590, Gradient norm: 0.20766598
INFO:root:At the start of the epoch: mem (CPU python)=25996.5859375MB; mem (CPU total)=25767.68359375MB
INFO:root:[   36] Training loss: 0.63997518, Validation loss: 0.64260984, Gradient norm: 0.16174126
INFO:root:At the start of the epoch: mem (CPU python)=26034.68359375MB; mem (CPU total)=25805.48046875MB
INFO:root:[   37] Training loss: 0.63912166, Validation loss: 0.64138353, Gradient norm: 0.18527672
INFO:root:At the start of the epoch: mem (CPU python)=26072.78125MB; mem (CPU total)=25843.28515625MB
INFO:root:[   38] Training loss: 0.63804706, Validation loss: 0.64120922, Gradient norm: 0.17051117
INFO:root:At the start of the epoch: mem (CPU python)=26110.875MB; mem (CPU total)=25881.6875MB
INFO:root:[   39] Training loss: 0.63711870, Validation loss: 0.63980025, Gradient norm: 0.17085632
INFO:root:At the start of the epoch: mem (CPU python)=26148.96875MB; mem (CPU total)=25919.80859375MB
INFO:root:[   40] Training loss: 0.63625924, Validation loss: 0.63908929, Gradient norm: 0.16646353
INFO:root:At the start of the epoch: mem (CPU python)=26187.0703125MB; mem (CPU total)=25958.19140625MB
INFO:root:[   41] Training loss: 0.63542327, Validation loss: 0.63839166, Gradient norm: 0.17070487
INFO:root:At the start of the epoch: mem (CPU python)=26225.1640625MB; mem (CPU total)=25996.5390625MB
INFO:root:[   42] Training loss: 0.63459181, Validation loss: 0.63754962, Gradient norm: 0.20083815
INFO:root:At the start of the epoch: mem (CPU python)=26263.265625MB; mem (CPU total)=26034.75390625MB
INFO:root:[   43] Training loss: 0.63393321, Validation loss: 0.63658901, Gradient norm: 0.19580907
INFO:root:At the start of the epoch: mem (CPU python)=26301.359375MB; mem (CPU total)=26073.03515625MB
INFO:root:[   44] Training loss: 0.63320277, Validation loss: 0.63640904, Gradient norm: 0.18481337
INFO:root:At the start of the epoch: mem (CPU python)=26339.45703125MB; mem (CPU total)=26111.140625MB
INFO:root:[   45] Training loss: 0.63266159, Validation loss: 0.63589763, Gradient norm: 0.23350755
INFO:root:At the start of the epoch: mem (CPU python)=26377.55078125MB; mem (CPU total)=26148.43359375MB
INFO:root:[   46] Training loss: 0.63191347, Validation loss: 0.63570939, Gradient norm: 0.22088363
INFO:root:At the start of the epoch: mem (CPU python)=26415.64453125MB; mem (CPU total)=26186.41015625MB
INFO:root:[   47] Training loss: 0.63136999, Validation loss: 0.63468272, Gradient norm: 0.21588527
INFO:root:At the start of the epoch: mem (CPU python)=26453.7421875MB; mem (CPU total)=26229.5390625MB
INFO:root:[   48] Training loss: 0.63054444, Validation loss: 0.63432047, Gradient norm: 0.23086741
INFO:root:At the start of the epoch: mem (CPU python)=26491.83984375MB; mem (CPU total)=26267.08203125MB
INFO:root:[   49] Training loss: 0.63011288, Validation loss: 0.63330989, Gradient norm: 0.21510251
INFO:root:At the start of the epoch: mem (CPU python)=26529.93359375MB; mem (CPU total)=26305.63671875MB
INFO:root:[   50] Training loss: 0.62933741, Validation loss: 0.63350352, Gradient norm: 0.19275295
INFO:root:At the start of the epoch: mem (CPU python)=26568.02734375MB; mem (CPU total)=26343.546875MB
INFO:root:[   51] Training loss: 0.62891431, Validation loss: 0.63364783, Gradient norm: 0.25872243
INFO:root:At the start of the epoch: mem (CPU python)=26606.125MB; mem (CPU total)=26381.66015625MB
INFO:root:[   52] Training loss: 0.62864661, Validation loss: 0.63194281, Gradient norm: 0.26321177
INFO:root:At the start of the epoch: mem (CPU python)=26644.21875MB; mem (CPU total)=26420.51953125MB
INFO:root:[   53] Training loss: 0.62785063, Validation loss: 0.63210753, Gradient norm: 0.26496820
INFO:root:At the start of the epoch: mem (CPU python)=26682.3125MB; mem (CPU total)=26457.8984375MB
INFO:root:[   54] Training loss: 0.62748228, Validation loss: 0.63165963, Gradient norm: 0.28238705
INFO:root:At the start of the epoch: mem (CPU python)=26720.41015625MB; mem (CPU total)=26495.765625MB
INFO:root:[   55] Training loss: 0.62696370, Validation loss: 0.63125072, Gradient norm: 0.26420573
INFO:root:At the start of the epoch: mem (CPU python)=26758.50390625MB; mem (CPU total)=26533.8125MB
INFO:root:[   56] Training loss: 0.62637171, Validation loss: 0.63103643, Gradient norm: 0.26555219
INFO:root:At the start of the epoch: mem (CPU python)=26796.6015625MB; mem (CPU total)=26571.58203125MB
INFO:root:[   57] Training loss: 0.62605077, Validation loss: 0.63035917, Gradient norm: 0.26742507
INFO:root:At the start of the epoch: mem (CPU python)=26834.69921875MB; mem (CPU total)=26609.69140625MB
INFO:root:[   58] Training loss: 0.62559105, Validation loss: 0.63007916, Gradient norm: 0.31079360
INFO:root:At the start of the epoch: mem (CPU python)=26872.79296875MB; mem (CPU total)=26647.63671875MB
INFO:root:[   59] Training loss: 0.62496133, Validation loss: 0.62972380, Gradient norm: 0.26066338
INFO:root:At the start of the epoch: mem (CPU python)=26910.88671875MB; mem (CPU total)=26685.67578125MB
INFO:root:[   60] Training loss: 0.62469716, Validation loss: 0.62889390, Gradient norm: 0.32125331
INFO:root:At the start of the epoch: mem (CPU python)=26948.984375MB; mem (CPU total)=26723.828125MB
INFO:root:[   61] Training loss: 0.62439796, Validation loss: 0.62863682, Gradient norm: 0.32908546
INFO:root:At the start of the epoch: mem (CPU python)=26987.08203125MB; mem (CPU total)=26761.7421875MB
INFO:root:[   62] Training loss: 0.62397005, Validation loss: 0.62907603, Gradient norm: 0.33734801
INFO:root:At the start of the epoch: mem (CPU python)=27025.17578125MB; mem (CPU total)=26799.98828125MB
INFO:root:[   63] Training loss: 0.62348447, Validation loss: 0.62897265, Gradient norm: 0.29873633
INFO:root:At the start of the epoch: mem (CPU python)=27063.26953125MB; mem (CPU total)=26838.58203125MB
INFO:root:[   64] Training loss: 0.62326782, Validation loss: 0.62784794, Gradient norm: 0.37165401
INFO:root:At the start of the epoch: mem (CPU python)=27101.3671875MB; mem (CPU total)=26877.16796875MB
INFO:root:[   65] Training loss: 0.62294534, Validation loss: 0.62725865, Gradient norm: 0.37101517
INFO:root:At the start of the epoch: mem (CPU python)=27139.4609375MB; mem (CPU total)=26915.140625MB
INFO:root:[   66] Training loss: 0.62251384, Validation loss: 0.62727897, Gradient norm: 0.37808989
INFO:root:At the start of the epoch: mem (CPU python)=27177.55859375MB; mem (CPU total)=26953.50390625MB
INFO:root:[   67] Training loss: 0.62228074, Validation loss: 0.62723622, Gradient norm: 0.46085982
INFO:root:At the start of the epoch: mem (CPU python)=27215.65234375MB; mem (CPU total)=26991.171875MB
INFO:root:[   68] Training loss: 0.62189833, Validation loss: 0.62713214, Gradient norm: 0.39195160
INFO:root:At the start of the epoch: mem (CPU python)=27253.75MB; mem (CPU total)=27029.76953125MB
INFO:root:[   69] Training loss: 0.62143685, Validation loss: 0.62604238, Gradient norm: 0.36934065
INFO:root:At the start of the epoch: mem (CPU python)=27291.84375MB; mem (CPU total)=27067.62109375MB
INFO:root:[   70] Training loss: 0.62111166, Validation loss: 0.62664846, Gradient norm: 0.39945521
INFO:root:At the start of the epoch: mem (CPU python)=27329.9375MB; mem (CPU total)=27105.74609375MB
INFO:root:[   71] Training loss: 0.62106544, Validation loss: 0.62663471, Gradient norm: 0.41936054
INFO:root:At the start of the epoch: mem (CPU python)=27368.03515625MB; mem (CPU total)=27143.76171875MB
INFO:root:[   72] Training loss: 0.62051876, Validation loss: 0.62629600, Gradient norm: 0.41556680
INFO:root:At the start of the epoch: mem (CPU python)=27406.12890625MB; mem (CPU total)=27181.828125MB
INFO:root:[   73] Training loss: 0.62033696, Validation loss: 0.62571112, Gradient norm: 0.50951739
INFO:root:At the start of the epoch: mem (CPU python)=27444.2265625MB; mem (CPU total)=27219.94140625MB
INFO:root:[   74] Training loss: 0.61995689, Validation loss: 0.62587187, Gradient norm: 0.47844438
INFO:root:At the start of the epoch: mem (CPU python)=27482.3203125MB; mem (CPU total)=27258.03515625MB
INFO:root:[   75] Training loss: 0.61987073, Validation loss: 0.62666726, Gradient norm: 0.55863300
INFO:root:At the start of the epoch: mem (CPU python)=27520.41796875MB; mem (CPU total)=27296.1875MB
INFO:root:[   76] Training loss: 0.61945972, Validation loss: 0.62493936, Gradient norm: 0.59990490
INFO:root:At the start of the epoch: mem (CPU python)=27558.51171875MB; mem (CPU total)=27334.30859375MB
INFO:root:[   77] Training loss: 0.61923317, Validation loss: 0.62603527, Gradient norm: 0.53247737
INFO:root:At the start of the epoch: mem (CPU python)=27596.60546875MB; mem (CPU total)=27372.6796875MB
INFO:root:[   78] Training loss: 0.61931031, Validation loss: 0.62446096, Gradient norm: 1.00400352
INFO:root:At the start of the epoch: mem (CPU python)=27634.703125MB; mem (CPU total)=27410.85546875MB
INFO:root:[   79] Training loss: 0.61879659, Validation loss: 0.62510462, Gradient norm: 0.56767675
INFO:root:At the start of the epoch: mem (CPU python)=27672.796875MB; mem (CPU total)=27448.71484375MB
INFO:root:[   80] Training loss: 0.61869624, Validation loss: 0.62559381, Gradient norm: 1.13352309
INFO:root:At the start of the epoch: mem (CPU python)=27710.89453125MB; mem (CPU total)=27486.83203125MB
INFO:root:[   81] Training loss: 0.61894870, Validation loss: 0.62528594, Gradient norm: 1.40448485
INFO:root:At the start of the epoch: mem (CPU python)=27748.9921875MB; mem (CPU total)=27524.85546875MB
INFO:root:[   82] Training loss: 0.61989719, Validation loss: 0.62840410, Gradient norm: 2.17449538
INFO:root:At the start of the epoch: mem (CPU python)=27787.0859375MB; mem (CPU total)=27562.9921875MB
INFO:root:[   83] Training loss: 0.61872059, Validation loss: 0.62425047, Gradient norm: 1.24877765
INFO:root:At the start of the epoch: mem (CPU python)=27825.1796875MB; mem (CPU total)=27600.9453125MB
INFO:root:[   84] Training loss: 0.61769199, Validation loss: 0.62408937, Gradient norm: 0.37322246
INFO:root:At the start of the epoch: mem (CPU python)=27863.2734375MB; mem (CPU total)=27638.62890625MB
INFO:root:[   85] Training loss: 0.61741399, Validation loss: 0.62376428, Gradient norm: 0.46061150
INFO:root:At the start of the epoch: mem (CPU python)=27901.37109375MB; mem (CPU total)=27676.97265625MB
INFO:root:[   86] Training loss: 0.61729069, Validation loss: 0.62377184, Gradient norm: 0.52713744
INFO:root:At the start of the epoch: mem (CPU python)=27939.46484375MB; mem (CPU total)=27719.28125MB
INFO:root:[   87] Training loss: 0.61710679, Validation loss: 0.62387185, Gradient norm: 0.54707159
INFO:root:At the start of the epoch: mem (CPU python)=27977.55859375MB; mem (CPU total)=27757.3828125MB
INFO:root:[   88] Training loss: 0.61676470, Validation loss: 0.62353224, Gradient norm: 0.59320462
INFO:root:At the start of the epoch: mem (CPU python)=28015.65625MB; mem (CPU total)=27794.953125MB
INFO:root:[   89] Training loss: 0.61712132, Validation loss: 0.62380825, Gradient norm: 1.32718088
INFO:root:At the start of the epoch: mem (CPU python)=28053.75390625MB; mem (CPU total)=27833.0390625MB
INFO:root:[   90] Training loss: 0.61812506, Validation loss: 0.62418046, Gradient norm: 2.32353476
INFO:root:At the start of the epoch: mem (CPU python)=28091.84765625MB; mem (CPU total)=27871.15234375MB
INFO:root:[   91] Training loss: 0.61773585, Validation loss: 0.62389184, Gradient norm: 2.31107805
INFO:root:At the start of the epoch: mem (CPU python)=28129.9453125MB; mem (CPU total)=27908.94140625MB
INFO:root:[   92] Training loss: 0.61767079, Validation loss: 0.62733540, Gradient norm: 2.09726017
INFO:root:At the start of the epoch: mem (CPU python)=28168.0390625MB; mem (CPU total)=27947.27734375MB
INFO:root:[   93] Training loss: 0.61726214, Validation loss: 0.62475644, Gradient norm: 1.98099967
INFO:root:At the start of the epoch: mem (CPU python)=28206.1328125MB; mem (CPU total)=27985.37890625MB
INFO:root:[   94] Training loss: 0.61657613, Validation loss: 0.62281388, Gradient norm: 1.37885174
INFO:root:At the start of the epoch: mem (CPU python)=28244.2265625MB; mem (CPU total)=28023.08984375MB
INFO:root:[   95] Training loss: 0.61556370, Validation loss: 0.62309137, Gradient norm: 0.51721743
INFO:root:At the start of the epoch: mem (CPU python)=28282.32421875MB; mem (CPU total)=28061.4375MB
INFO:root:[   96] Training loss: 0.61543710, Validation loss: 0.62322911, Gradient norm: 0.53387259
INFO:root:At the start of the epoch: mem (CPU python)=28320.41796875MB; mem (CPU total)=28099.56640625MB
INFO:root:[   97] Training loss: 0.61542046, Validation loss: 0.62206450, Gradient norm: 1.07133449
INFO:root:At the start of the epoch: mem (CPU python)=28358.515625MB; mem (CPU total)=28137.390625MB
INFO:root:[   98] Training loss: 0.61514145, Validation loss: 0.62248476, Gradient norm: 1.45541343
INFO:root:At the start of the epoch: mem (CPU python)=28396.61328125MB; mem (CPU total)=28175.7265625MB
INFO:root:[   99] Training loss: 0.61503420, Validation loss: 0.62237303, Gradient norm: 0.92888879
INFO:root:At the start of the epoch: mem (CPU python)=28434.70703125MB; mem (CPU total)=28213.21484375MB
INFO:root:[  100] Training loss: 0.61497991, Validation loss: 0.62147886, Gradient norm: 1.10351095
INFO:root:At the start of the epoch: mem (CPU python)=28472.80078125MB; mem (CPU total)=28251.12890625MB
INFO:root:[  101] Training loss: 0.61471888, Validation loss: 0.62161314, Gradient norm: 1.54715787
INFO:root:At the start of the epoch: mem (CPU python)=28510.89453125MB; mem (CPU total)=28289.734375MB
INFO:root:[  102] Training loss: 0.61441311, Validation loss: 0.62200839, Gradient norm: 1.60432244
INFO:root:At the start of the epoch: mem (CPU python)=28548.9921875MB; mem (CPU total)=28327.8203125MB
INFO:root:[  103] Training loss: 0.61428372, Validation loss: 0.62288590, Gradient norm: 1.57838013
INFO:root:At the start of the epoch: mem (CPU python)=28587.0859375MB; mem (CPU total)=28365.78125MB
INFO:root:[  104] Training loss: 0.61405063, Validation loss: 0.62179832, Gradient norm: 0.93925718
INFO:root:At the start of the epoch: mem (CPU python)=28625.1796875MB; mem (CPU total)=28403.1640625MB
INFO:root:[  105] Training loss: 0.61445057, Validation loss: 0.62346065, Gradient norm: 1.25564232
INFO:root:At the start of the epoch: mem (CPU python)=28663.28125MB; mem (CPU total)=28441.53515625MB
INFO:root:[  106] Training loss: 0.61515034, Validation loss: 0.62405052, Gradient norm: 2.94916753
INFO:root:At the start of the epoch: mem (CPU python)=28701.375MB; mem (CPU total)=28479.4140625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  107] Training loss: 0.61487563, Validation loss: 0.62314469, Gradient norm: 2.64798707
INFO:root:At the start of the epoch: mem (CPU python)=28739.46875MB; mem (CPU total)=28517.48828125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  108] Training loss: 0.61281588, Validation loss: 0.62124489, Gradient norm: 0.61375879
INFO:root:At the start of the epoch: mem (CPU python)=28777.56640625MB; mem (CPU total)=28556.0703125MB
INFO:root:[  109] Training loss: 0.61214287, Validation loss: 0.62043961, Gradient norm: 0.32967091
INFO:root:At the start of the epoch: mem (CPU python)=28815.66015625MB; mem (CPU total)=28594.23046875MB
INFO:root:[  110] Training loss: 0.61199842, Validation loss: 0.61992891, Gradient norm: 0.30969371
INFO:root:At the start of the epoch: mem (CPU python)=28853.75390625MB; mem (CPU total)=28632.60546875MB
INFO:root:[  111] Training loss: 0.61178491, Validation loss: 0.62070475, Gradient norm: 0.37437339
INFO:root:At the start of the epoch: mem (CPU python)=28891.84765625MB; mem (CPU total)=28670.703125MB
INFO:root:[  112] Training loss: 0.61202708, Validation loss: 0.62089589, Gradient norm: 0.35351719
INFO:root:At the start of the epoch: mem (CPU python)=28929.9453125MB; mem (CPU total)=28708.80078125MB
INFO:root:[  113] Training loss: 0.61185594, Validation loss: 0.62060129, Gradient norm: 0.40238567
INFO:root:At the start of the epoch: mem (CPU python)=28968.0390625MB; mem (CPU total)=28746.65625MB
INFO:root:[  114] Training loss: 0.61196846, Validation loss: 0.62096333, Gradient norm: 0.38980466
INFO:root:At the start of the epoch: mem (CPU python)=29006.13671875MB; mem (CPU total)=28784.7734375MB
INFO:root:[  115] Training loss: 0.61189015, Validation loss: 0.62049371, Gradient norm: 0.52666127
INFO:root:At the start of the epoch: mem (CPU python)=29044.234375MB; mem (CPU total)=28822.6796875MB
INFO:root:[  116] Training loss: 0.61184423, Validation loss: 0.62045372, Gradient norm: 0.42672786
INFO:root:At the start of the epoch: mem (CPU python)=29082.328125MB; mem (CPU total)=28860.73828125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  117] Training loss: 0.61188315, Validation loss: 0.62024364, Gradient norm: 0.45145367
INFO:root:At the start of the epoch: mem (CPU python)=29120.421875MB; mem (CPU total)=28898.85546875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  118] Training loss: 0.61153657, Validation loss: 0.62068205, Gradient norm: 0.38009429
INFO:root:At the start of the epoch: mem (CPU python)=29158.515625MB; mem (CPU total)=28936.984375MB
INFO:root:[  119] Training loss: 0.61147457, Validation loss: 0.62101704, Gradient norm: 0.32590932
INFO:root:At the start of the epoch: mem (CPU python)=29196.61328125MB; mem (CPU total)=28974.37109375MB
INFO:root:EP 119: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=29234.70703125MB; mem (CPU total)=29012.72265625MB
INFO:root:Training the model took 12905.246s.
INFO:root:Emptying the cuda cache took 0.317s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86835
INFO:root:EnergyScoreTrain: 0.61164
INFO:root:CRPSTrain: 0.55678
INFO:root:Gaussian NLLTrain: 7.17762
INFO:root:CoverageTrain: 0.74589
INFO:root:IntervalWidthTrain: 3.09211
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88102
INFO:root:EnergyScoreValidation: 0.62045
INFO:root:CRPSValidation: 0.56355
INFO:root:Gaussian NLLValidation: 7.21978
INFO:root:CoverageValidation: 0.74254
INFO:root:IntervalWidthValidation: 3.08947
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88306
INFO:root:EnergyScoreTest: 0.62192
INFO:root:CRPSTest: 0.56517
INFO:root:Gaussian NLLTest: 7.23561
INFO:root:CoverageTest: 0.74113
INFO:root:IntervalWidthTest: 3.08659
INFO:root:After validation: mem (CPU python)=29277.703125MB; mem (CPU total)=29053.6484375MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=29277.703125MB; mem (CPU total)=29053.6484375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=29278.0625MB; mem (CPU total)=29053.890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=29278.0625MB; mem (CPU total)=29054.125MB
INFO:root:[    1] Training loss: 0.77899202, Validation loss: 0.72356316, Gradient norm: 0.45784028
INFO:root:At the start of the epoch: mem (CPU python)=29316.078125MB; mem (CPU total)=29093.56640625MB
INFO:root:[    2] Training loss: 0.72195809, Validation loss: 0.72083347, Gradient norm: 0.30128880
INFO:root:At the start of the epoch: mem (CPU python)=29354.171875MB; mem (CPU total)=29131.48828125MB
INFO:root:[    3] Training loss: 0.72037097, Validation loss: 0.72054901, Gradient norm: 0.25417662
INFO:root:At the start of the epoch: mem (CPU python)=29392.2890625MB; mem (CPU total)=29169.53125MB
INFO:root:[    4] Training loss: 0.71987762, Validation loss: 0.71979479, Gradient norm: 0.21212565
INFO:root:At the start of the epoch: mem (CPU python)=29430.3828125MB; mem (CPU total)=29207.91796875MB
INFO:root:[    5] Training loss: 0.71962276, Validation loss: 0.71946633, Gradient norm: 0.16340447
INFO:root:At the start of the epoch: mem (CPU python)=29468.48046875MB; mem (CPU total)=29245.80078125MB
INFO:root:[    6] Training loss: 0.71939991, Validation loss: 0.71981829, Gradient norm: 0.20270194
INFO:root:At the start of the epoch: mem (CPU python)=29506.578125MB; mem (CPU total)=29283.921875MB
INFO:root:[    7] Training loss: 0.71896402, Validation loss: 0.71936588, Gradient norm: 0.15801987
INFO:root:At the start of the epoch: mem (CPU python)=29544.671875MB; mem (CPU total)=29322.5MB
INFO:root:[    8] Training loss: 0.71833000, Validation loss: 0.71744852, Gradient norm: 0.16950715
INFO:root:At the start of the epoch: mem (CPU python)=29582.765625MB; mem (CPU total)=29360.34765625MB
INFO:root:[    9] Training loss: 0.71655881, Validation loss: 0.71433296, Gradient norm: 0.16839638
INFO:root:At the start of the epoch: mem (CPU python)=29620.859375MB; mem (CPU total)=29398.89453125MB
INFO:root:[   10] Training loss: 0.71024025, Validation loss: 0.70625770, Gradient norm: 0.14995397
INFO:root:At the start of the epoch: mem (CPU python)=29658.95703125MB; mem (CPU total)=29436.71484375MB
INFO:root:[   11] Training loss: 0.70261983, Validation loss: 0.69930484, Gradient norm: 0.11685842
INFO:root:At the start of the epoch: mem (CPU python)=29697.05078125MB; mem (CPU total)=29474.44140625MB
INFO:root:[   12] Training loss: 0.69639610, Validation loss: 0.69436040, Gradient norm: 0.13775676
INFO:root:At the start of the epoch: mem (CPU python)=29735.15625MB; mem (CPU total)=29513.04296875MB
INFO:root:[   13] Training loss: 0.69124237, Validation loss: 0.69026445, Gradient norm: 0.10978930
INFO:root:At the start of the epoch: mem (CPU python)=29773.2578125MB; mem (CPU total)=29551.09765625MB
INFO:root:[   14] Training loss: 0.68686101, Validation loss: 0.68631584, Gradient norm: 0.11400468
INFO:root:At the start of the epoch: mem (CPU python)=29811.3515625MB; mem (CPU total)=29589.734375MB
INFO:root:[   15] Training loss: 0.68310335, Validation loss: 0.68251589, Gradient norm: 0.12099209
INFO:root:At the start of the epoch: mem (CPU python)=29849.4453125MB; mem (CPU total)=29627.40234375MB
INFO:root:[   16] Training loss: 0.67982836, Validation loss: 0.67889168, Gradient norm: 0.08817361
INFO:root:At the start of the epoch: mem (CPU python)=29887.54296875MB; mem (CPU total)=29665.72265625MB
INFO:root:[   17] Training loss: 0.67655458, Validation loss: 0.67652796, Gradient norm: 0.09300490
INFO:root:At the start of the epoch: mem (CPU python)=29925.63671875MB; mem (CPU total)=29704.04296875MB
INFO:root:[   18] Training loss: 0.67333872, Validation loss: 0.67390492, Gradient norm: 0.08909117
INFO:root:At the start of the epoch: mem (CPU python)=29963.73046875MB; mem (CPU total)=29741.921875MB
INFO:root:[   19] Training loss: 0.67055156, Validation loss: 0.67011639, Gradient norm: 0.09741982
INFO:root:At the start of the epoch: mem (CPU python)=30001.82421875MB; mem (CPU total)=29780.8125MB
INFO:root:[   20] Training loss: 0.66767739, Validation loss: 0.66768257, Gradient norm: 0.07235316
INFO:root:At the start of the epoch: mem (CPU python)=30039.921875MB; mem (CPU total)=29818.7109375MB
INFO:root:[   21] Training loss: 0.66516571, Validation loss: 0.66603336, Gradient norm: 0.07480252
INFO:root:At the start of the epoch: mem (CPU python)=30078.015625MB; mem (CPU total)=29856.48828125MB
INFO:root:[   22] Training loss: 0.66300290, Validation loss: 0.66387813, Gradient norm: 0.07821258
INFO:root:At the start of the epoch: mem (CPU python)=30116.11328125MB; mem (CPU total)=29894.734375MB
INFO:root:[   23] Training loss: 0.66080479, Validation loss: 0.66173219, Gradient norm: 0.08853035
INFO:root:At the start of the epoch: mem (CPU python)=30154.2109375MB; mem (CPU total)=29932.70703125MB
INFO:root:[   24] Training loss: 0.65896065, Validation loss: 0.66020987, Gradient norm: 0.08433427
INFO:root:At the start of the epoch: mem (CPU python)=30192.3046875MB; mem (CPU total)=29971.3125MB
INFO:root:[   25] Training loss: 0.65734427, Validation loss: 0.65842385, Gradient norm: 0.08992816
INFO:root:At the start of the epoch: mem (CPU python)=30230.3984375MB; mem (CPU total)=30009.42578125MB
INFO:root:[   26] Training loss: 0.65560636, Validation loss: 0.65767683, Gradient norm: 0.06501353
INFO:root:At the start of the epoch: mem (CPU python)=30268.4921875MB; mem (CPU total)=30047.76171875MB
INFO:root:[   27] Training loss: 0.65437408, Validation loss: 0.65519050, Gradient norm: 0.07357311
INFO:root:At the start of the epoch: mem (CPU python)=30306.58984375MB; mem (CPU total)=30086.125MB
INFO:root:[   28] Training loss: 0.65283462, Validation loss: 0.65415781, Gradient norm: 0.07414899
INFO:root:At the start of the epoch: mem (CPU python)=30344.68359375MB; mem (CPU total)=30129.1953125MB
INFO:root:[   29] Training loss: 0.65144463, Validation loss: 0.65369832, Gradient norm: 0.08508521
INFO:root:At the start of the epoch: mem (CPU python)=30382.77734375MB; mem (CPU total)=30167.08203125MB
INFO:root:[   30] Training loss: 0.65026685, Validation loss: 0.65231899, Gradient norm: 0.08349044
INFO:root:At the start of the epoch: mem (CPU python)=30420.87890625MB; mem (CPU total)=30204.90625MB
INFO:root:[   31] Training loss: 0.64891625, Validation loss: 0.65146803, Gradient norm: 0.07747973
INFO:root:At the start of the epoch: mem (CPU python)=30458.97265625MB; mem (CPU total)=30243.10546875MB
INFO:root:[   32] Training loss: 0.64771678, Validation loss: 0.65019533, Gradient norm: 0.06758569
INFO:root:At the start of the epoch: mem (CPU python)=30497.06640625MB; mem (CPU total)=30281.58984375MB
INFO:root:[   33] Training loss: 0.64674519, Validation loss: 0.64900603, Gradient norm: 0.08378057
INFO:root:At the start of the epoch: mem (CPU python)=30535.1640625MB; mem (CPU total)=30319.671875MB
INFO:root:[   34] Training loss: 0.64578594, Validation loss: 0.64830573, Gradient norm: 0.08505901
INFO:root:At the start of the epoch: mem (CPU python)=30573.2578125MB; mem (CPU total)=30357.01171875MB
INFO:root:[   35] Training loss: 0.64464260, Validation loss: 0.64714473, Gradient norm: 0.07083980
INFO:root:At the start of the epoch: mem (CPU python)=30611.3515625MB; mem (CPU total)=30394.86328125MB
INFO:root:[   36] Training loss: 0.64374125, Validation loss: 0.64605312, Gradient norm: 0.07779527
INFO:root:At the start of the epoch: mem (CPU python)=30649.4453125MB; mem (CPU total)=30432.2734375MB
INFO:root:[   37] Training loss: 0.64284332, Validation loss: 0.64622025, Gradient norm: 0.08012675
INFO:root:At the start of the epoch: mem (CPU python)=30687.546875MB; mem (CPU total)=30471.26953125MB
INFO:root:[   38] Training loss: 0.64171105, Validation loss: 0.64519409, Gradient norm: 0.07989266
INFO:root:At the start of the epoch: mem (CPU python)=30725.640625MB; mem (CPU total)=30509.60546875MB
INFO:root:[   39] Training loss: 0.64067984, Validation loss: 0.64402976, Gradient norm: 0.08039468
INFO:root:At the start of the epoch: mem (CPU python)=30763.734375MB; mem (CPU total)=30547.08984375MB
INFO:root:[   40] Training loss: 0.64007339, Validation loss: 0.64292839, Gradient norm: 0.07070744
INFO:root:At the start of the epoch: mem (CPU python)=30801.83203125MB; mem (CPU total)=30585.23046875MB
INFO:root:[   41] Training loss: 0.63909591, Validation loss: 0.64215233, Gradient norm: 0.08096524
INFO:root:At the start of the epoch: mem (CPU python)=30839.92578125MB; mem (CPU total)=30623.40234375MB
INFO:root:[   42] Training loss: 0.63809096, Validation loss: 0.64160719, Gradient norm: 0.07312909
INFO:root:At the start of the epoch: mem (CPU python)=30878.01953125MB; mem (CPU total)=30661.78125MB
INFO:root:[   43] Training loss: 0.63749636, Validation loss: 0.64082052, Gradient norm: 0.07477808
INFO:root:At the start of the epoch: mem (CPU python)=30916.11328125MB; mem (CPU total)=30699.9375MB
INFO:root:[   44] Training loss: 0.63661768, Validation loss: 0.63940195, Gradient norm: 0.08395995
INFO:root:At the start of the epoch: mem (CPU python)=30954.2109375MB; mem (CPU total)=30737.765625MB
INFO:root:[   45] Training loss: 0.63575090, Validation loss: 0.63905538, Gradient norm: 0.07404460
INFO:root:At the start of the epoch: mem (CPU python)=30992.30859375MB; mem (CPU total)=30775.7421875MB
INFO:root:[   46] Training loss: 0.63493710, Validation loss: 0.63965896, Gradient norm: 0.08234358
INFO:root:At the start of the epoch: mem (CPU python)=31030.40234375MB; mem (CPU total)=30813.91796875MB
INFO:root:[   47] Training loss: 0.63432851, Validation loss: 0.63776367, Gradient norm: 0.07054452
INFO:root:At the start of the epoch: mem (CPU python)=31068.5MB; mem (CPU total)=30851.8203125MB
INFO:root:[   48] Training loss: 0.63375171, Validation loss: 0.63767593, Gradient norm: 0.07937684
INFO:root:At the start of the epoch: mem (CPU python)=31106.59375MB; mem (CPU total)=30890.48046875MB
INFO:root:[   49] Training loss: 0.63272486, Validation loss: 0.63740768, Gradient norm: 0.07869619
INFO:root:At the start of the epoch: mem (CPU python)=31144.6875MB; mem (CPU total)=30928.390625MB
INFO:root:[   50] Training loss: 0.63248067, Validation loss: 0.63622893, Gradient norm: 0.07997757
INFO:root:At the start of the epoch: mem (CPU python)=31182.78515625MB; mem (CPU total)=30965.875MB
INFO:root:[   51] Training loss: 0.63158604, Validation loss: 0.63530110, Gradient norm: 0.07784757
INFO:root:At the start of the epoch: mem (CPU python)=31220.87890625MB; mem (CPU total)=31004.05859375MB
INFO:root:[   52] Training loss: 0.63084058, Validation loss: 0.63507199, Gradient norm: 0.09108725
INFO:root:At the start of the epoch: mem (CPU python)=31258.97265625MB; mem (CPU total)=31042.234375MB
INFO:root:[   53] Training loss: 0.63038810, Validation loss: 0.63494907, Gradient norm: 0.08654085
INFO:root:At the start of the epoch: mem (CPU python)=31297.06640625MB; mem (CPU total)=31080.85546875MB
INFO:root:[   54] Training loss: 0.62973295, Validation loss: 0.63464859, Gradient norm: 0.07272255
INFO:root:At the start of the epoch: mem (CPU python)=31335.1640625MB; mem (CPU total)=31118.828125MB
INFO:root:[   55] Training loss: 0.62910102, Validation loss: 0.63325636, Gradient norm: 0.07114503
INFO:root:At the start of the epoch: mem (CPU python)=31373.26171875MB; mem (CPU total)=31157.40625MB
INFO:root:[   56] Training loss: 0.62851171, Validation loss: 0.63338646, Gradient norm: 0.08053666
INFO:root:At the start of the epoch: mem (CPU python)=31411.35546875MB; mem (CPU total)=31195.5546875MB
INFO:root:[   57] Training loss: 0.62771464, Validation loss: 0.63195029, Gradient norm: 0.07393711
INFO:root:At the start of the epoch: mem (CPU python)=31449.453125MB; mem (CPU total)=31233.86328125MB
INFO:root:[   58] Training loss: 0.62737948, Validation loss: 0.63208606, Gradient norm: 0.06720844
INFO:root:At the start of the epoch: mem (CPU python)=31487.546875MB; mem (CPU total)=31271.75MB
INFO:root:[   59] Training loss: 0.62668352, Validation loss: 0.63293388, Gradient norm: 0.08485583
INFO:root:At the start of the epoch: mem (CPU python)=31525.640625MB; mem (CPU total)=31309.4375MB
INFO:root:[   60] Training loss: 0.62622479, Validation loss: 0.63127406, Gradient norm: 0.08485103
INFO:root:At the start of the epoch: mem (CPU python)=31563.73828125MB; mem (CPU total)=31347.53125MB
INFO:root:[   61] Training loss: 0.62578625, Validation loss: 0.63045641, Gradient norm: 0.09173845
INFO:root:At the start of the epoch: mem (CPU python)=31601.83203125MB; mem (CPU total)=31386.03515625MB
INFO:root:[   62] Training loss: 0.62524764, Validation loss: 0.63042556, Gradient norm: 0.08281342
INFO:root:At the start of the epoch: mem (CPU python)=31639.9296875MB; mem (CPU total)=31424.18359375MB
INFO:root:[   63] Training loss: 0.62459167, Validation loss: 0.62986693, Gradient norm: 0.08269160
INFO:root:At the start of the epoch: mem (CPU python)=31678.0234375MB; mem (CPU total)=31462.640625MB
INFO:root:[   64] Training loss: 0.62426146, Validation loss: 0.62963146, Gradient norm: 0.09002264
INFO:root:At the start of the epoch: mem (CPU python)=31716.12109375MB; mem (CPU total)=31500.51171875MB
INFO:root:[   65] Training loss: 0.62382896, Validation loss: 0.62940101, Gradient norm: 0.09711150
INFO:root:At the start of the epoch: mem (CPU python)=31754.21484375MB; mem (CPU total)=31538.69921875MB
INFO:root:[   66] Training loss: 0.62338511, Validation loss: 0.62856353, Gradient norm: 0.08748019
INFO:root:At the start of the epoch: mem (CPU python)=31792.30859375MB; mem (CPU total)=31577.40625MB
INFO:root:[   67] Training loss: 0.62262918, Validation loss: 0.62797596, Gradient norm: 0.07756372
INFO:root:At the start of the epoch: mem (CPU python)=31830.40625MB; mem (CPU total)=31615.4921875MB
INFO:root:[   68] Training loss: 0.62232626, Validation loss: 0.62789361, Gradient norm: 0.09195406
INFO:root:At the start of the epoch: mem (CPU python)=31868.5MB; mem (CPU total)=31653.78125MB
INFO:root:[   69] Training loss: 0.62155636, Validation loss: 0.62787309, Gradient norm: 0.09579588
INFO:root:At the start of the epoch: mem (CPU python)=31906.59375MB; mem (CPU total)=31691.51171875MB
INFO:root:[   70] Training loss: 0.62110285, Validation loss: 0.62738336, Gradient norm: 0.07745288
INFO:root:At the start of the epoch: mem (CPU python)=31944.6875MB; mem (CPU total)=31729.609375MB
INFO:root:[   71] Training loss: 0.62062334, Validation loss: 0.62664273, Gradient norm: 0.09035779
INFO:root:At the start of the epoch: mem (CPU python)=31982.7890625MB; mem (CPU total)=31767.55859375MB
INFO:root:[   72] Training loss: 0.62038028, Validation loss: 0.62587123, Gradient norm: 0.09344980
INFO:root:At the start of the epoch: mem (CPU python)=32020.8828125MB; mem (CPU total)=31805.65625MB
INFO:root:[   73] Training loss: 0.61993132, Validation loss: 0.62546313, Gradient norm: 0.08018740
INFO:root:At the start of the epoch: mem (CPU python)=32058.9765625MB; mem (CPU total)=31844.36328125MB
INFO:root:[   74] Training loss: 0.61948539, Validation loss: 0.62572994, Gradient norm: 0.08729039
INFO:root:At the start of the epoch: mem (CPU python)=32097.07421875MB; mem (CPU total)=31882.203125MB
INFO:root:[   75] Training loss: 0.61901994, Validation loss: 0.62518941, Gradient norm: 0.11069715
INFO:root:At the start of the epoch: mem (CPU python)=32135.16796875MB; mem (CPU total)=31920.07421875MB
INFO:root:[   76] Training loss: 0.61863390, Validation loss: 0.62565635, Gradient norm: 0.09033440
INFO:root:At the start of the epoch: mem (CPU python)=32173.26171875MB; mem (CPU total)=31958.42578125MB
INFO:root:[   77] Training loss: 0.61791473, Validation loss: 0.62392599, Gradient norm: 0.09042040
INFO:root:At the start of the epoch: mem (CPU python)=32211.35546875MB; mem (CPU total)=31996.55078125MB
INFO:root:[   78] Training loss: 0.61785358, Validation loss: 0.62403141, Gradient norm: 0.08983422
INFO:root:At the start of the epoch: mem (CPU python)=32249.45703125MB; mem (CPU total)=32034.90234375MB
INFO:root:[   79] Training loss: 0.61731080, Validation loss: 0.62391663, Gradient norm: 0.08863047
INFO:root:At the start of the epoch: mem (CPU python)=32287.55078125MB; mem (CPU total)=32073.52734375MB
INFO:root:[   80] Training loss: 0.61703313, Validation loss: 0.62332555, Gradient norm: 0.09810194
INFO:root:At the start of the epoch: mem (CPU python)=32325.640625MB; mem (CPU total)=32111.16015625MB
INFO:root:[   81] Training loss: 0.61668588, Validation loss: 0.62316753, Gradient norm: 0.09230350
INFO:root:At the start of the epoch: mem (CPU python)=32363.7421875MB; mem (CPU total)=32149.28125MB
INFO:root:[   82] Training loss: 0.61639545, Validation loss: 0.62348444, Gradient norm: 0.09748089
INFO:root:At the start of the epoch: mem (CPU python)=32401.8359375MB; mem (CPU total)=32187.66015625MB
INFO:root:[   83] Training loss: 0.61599562, Validation loss: 0.62238326, Gradient norm: 0.10409945
INFO:root:At the start of the epoch: mem (CPU python)=32439.93359375MB; mem (CPU total)=32225.86328125MB
INFO:root:[   84] Training loss: 0.61562443, Validation loss: 0.62300135, Gradient norm: 0.09545825
INFO:root:At the start of the epoch: mem (CPU python)=32478.03125MB; mem (CPU total)=32263.83984375MB
INFO:root:[   85] Training loss: 0.61541979, Validation loss: 0.62274602, Gradient norm: 0.09561925
INFO:root:At the start of the epoch: mem (CPU python)=32516.125MB; mem (CPU total)=32301.73046875MB
INFO:root:[   86] Training loss: 0.61489978, Validation loss: 0.62271116, Gradient norm: 0.08776283
INFO:root:At the start of the epoch: mem (CPU python)=32554.21875MB; mem (CPU total)=32340.0703125MB
INFO:root:[   87] Training loss: 0.61471845, Validation loss: 0.62178136, Gradient norm: 0.11337770
INFO:root:At the start of the epoch: mem (CPU python)=32592.3125MB; mem (CPU total)=32378.9375MB
INFO:root:[   88] Training loss: 0.61438011, Validation loss: 0.62134501, Gradient norm: 0.11069463
INFO:root:At the start of the epoch: mem (CPU python)=32630.4140625MB; mem (CPU total)=32417.57421875MB
INFO:root:[   89] Training loss: 0.61394238, Validation loss: 0.62094885, Gradient norm: 0.10600294
INFO:root:At the start of the epoch: mem (CPU python)=32668.5078125MB; mem (CPU total)=32455.671875MB
INFO:root:[   90] Training loss: 0.61382782, Validation loss: 0.62068621, Gradient norm: 0.12718885
INFO:root:At the start of the epoch: mem (CPU python)=32706.6015625MB; mem (CPU total)=32493.25390625MB
INFO:root:[   91] Training loss: 0.61324649, Validation loss: 0.62095133, Gradient norm: 0.09907453
INFO:root:At the start of the epoch: mem (CPU python)=32744.69921875MB; mem (CPU total)=32530.87109375MB
INFO:root:[   92] Training loss: 0.61312062, Validation loss: 0.61968901, Gradient norm: 0.10987578
INFO:root:At the start of the epoch: mem (CPU python)=32782.79296875MB; mem (CPU total)=32569.53515625MB
INFO:root:[   93] Training loss: 0.61269248, Validation loss: 0.62060229, Gradient norm: 0.09791539
INFO:root:At the start of the epoch: mem (CPU python)=32820.88671875MB; mem (CPU total)=32607.95703125MB
INFO:root:[   94] Training loss: 0.61242898, Validation loss: 0.62003591, Gradient norm: 0.11649405
INFO:root:At the start of the epoch: mem (CPU python)=32858.98046875MB; mem (CPU total)=32645.8203125MB
INFO:root:[   95] Training loss: 0.61204612, Validation loss: 0.62111638, Gradient norm: 0.11876703
INFO:root:At the start of the epoch: mem (CPU python)=32897.078125MB; mem (CPU total)=32683.3984375MB
INFO:root:[   96] Training loss: 0.61187335, Validation loss: 0.62012039, Gradient norm: 0.12876100
INFO:root:At the start of the epoch: mem (CPU python)=32935.17578125MB; mem (CPU total)=32721.15234375MB
INFO:root:[   97] Training loss: 0.61149167, Validation loss: 0.61953164, Gradient norm: 0.09876770
INFO:root:At the start of the epoch: mem (CPU python)=32973.26953125MB; mem (CPU total)=32759.73046875MB
INFO:root:[   98] Training loss: 0.61144999, Validation loss: 0.62019245, Gradient norm: 0.12128893
INFO:root:At the start of the epoch: mem (CPU python)=33011.3671875MB; mem (CPU total)=32797.87890625MB
INFO:root:[   99] Training loss: 0.61090715, Validation loss: 0.61860251, Gradient norm: 0.11325670
INFO:root:At the start of the epoch: mem (CPU python)=33049.4609375MB; mem (CPU total)=32836.12109375MB
INFO:root:[  100] Training loss: 0.61070681, Validation loss: 0.61938630, Gradient norm: 0.12952230
INFO:root:At the start of the epoch: mem (CPU python)=33087.5546875MB; mem (CPU total)=32874.0078125MB
INFO:root:[  101] Training loss: 0.61052284, Validation loss: 0.61798340, Gradient norm: 0.11248266
INFO:root:At the start of the epoch: mem (CPU python)=33125.65234375MB; mem (CPU total)=32912.16796875MB
INFO:root:[  102] Training loss: 0.61036771, Validation loss: 0.61902333, Gradient norm: 0.11418583
INFO:root:At the start of the epoch: mem (CPU python)=33163.74609375MB; mem (CPU total)=32950.44140625MB
INFO:root:[  103] Training loss: 0.61032279, Validation loss: 0.61836722, Gradient norm: 0.11805884
INFO:root:At the start of the epoch: mem (CPU python)=33201.84375MB; mem (CPU total)=32988.5078125MB
INFO:root:[  104] Training loss: 0.60986576, Validation loss: 0.61841309, Gradient norm: 0.13081322
INFO:root:At the start of the epoch: mem (CPU python)=33239.9375MB; mem (CPU total)=33026.58203125MB
INFO:root:[  105] Training loss: 0.60947427, Validation loss: 0.61771111, Gradient norm: 0.11197209
INFO:root:At the start of the epoch: mem (CPU python)=33278.03515625MB; mem (CPU total)=33064.48046875MB
INFO:root:[  106] Training loss: 0.60934465, Validation loss: 0.61826887, Gradient norm: 0.12505825
INFO:root:At the start of the epoch: mem (CPU python)=33316.12890625MB; mem (CPU total)=33102.8828125MB
INFO:root:[  107] Training loss: 0.60913629, Validation loss: 0.61768433, Gradient norm: 0.13138938
INFO:root:At the start of the epoch: mem (CPU python)=33354.22265625MB; mem (CPU total)=33141.05859375MB
INFO:root:[  108] Training loss: 0.60886109, Validation loss: 0.61707287, Gradient norm: 0.13687197
INFO:root:At the start of the epoch: mem (CPU python)=33392.3203125MB; mem (CPU total)=33179.48046875MB
INFO:root:[  109] Training loss: 0.60866822, Validation loss: 0.61728544, Gradient norm: 0.15797726
INFO:root:At the start of the epoch: mem (CPU python)=33430.4140625MB; mem (CPU total)=33217.6171875MB
INFO:root:[  110] Training loss: 0.60850755, Validation loss: 0.61738437, Gradient norm: 0.15557230
INFO:root:At the start of the epoch: mem (CPU python)=33468.5078125MB; mem (CPU total)=33255.24609375MB
INFO:root:[  111] Training loss: 0.60831757, Validation loss: 0.61648227, Gradient norm: 0.12518220
INFO:root:At the start of the epoch: mem (CPU python)=33506.6015625MB; mem (CPU total)=33294.08984375MB
INFO:root:[  112] Training loss: 0.60797969, Validation loss: 0.61725378, Gradient norm: 0.13357718
INFO:root:At the start of the epoch: mem (CPU python)=33544.703125MB; mem (CPU total)=33332.2265625MB
INFO:root:[  113] Training loss: 0.60793097, Validation loss: 0.61656934, Gradient norm: 0.16136663
INFO:root:At the start of the epoch: mem (CPU python)=33582.796875MB; mem (CPU total)=33370.3828125MB
INFO:root:[  114] Training loss: 0.60768513, Validation loss: 0.61621023, Gradient norm: 0.15747236
INFO:root:At the start of the epoch: mem (CPU python)=33620.890625MB; mem (CPU total)=33408.68359375MB
INFO:root:[  115] Training loss: 0.60764889, Validation loss: 0.61541951, Gradient norm: 0.19101891
INFO:root:At the start of the epoch: mem (CPU python)=33658.98828125MB; mem (CPU total)=33446.30859375MB
INFO:root:[  116] Training loss: 0.60736348, Validation loss: 0.61634849, Gradient norm: 0.17382286
INFO:root:At the start of the epoch: mem (CPU python)=33697.08203125MB; mem (CPU total)=33484.42578125MB
INFO:root:[  117] Training loss: 0.60719630, Validation loss: 0.61613348, Gradient norm: 0.14061425
INFO:root:At the start of the epoch: mem (CPU python)=33735.17578125MB; mem (CPU total)=33522.74609375MB
INFO:root:[  118] Training loss: 0.60705058, Validation loss: 0.61664161, Gradient norm: 0.16176834
INFO:root:At the start of the epoch: mem (CPU python)=33773.2734375MB; mem (CPU total)=33560.921875MB
INFO:root:[  119] Training loss: 0.60654981, Validation loss: 0.61639903, Gradient norm: 0.14959747
INFO:root:At the start of the epoch: mem (CPU python)=33811.3671875MB; mem (CPU total)=33599.0390625MB
INFO:root:[  120] Training loss: 0.60655429, Validation loss: 0.61548895, Gradient norm: 0.16153824
INFO:root:At the start of the epoch: mem (CPU python)=33849.4609375MB; mem (CPU total)=33636.91015625MB
INFO:root:[  121] Training loss: 0.60646158, Validation loss: 0.61612220, Gradient norm: 0.18021274
INFO:root:At the start of the epoch: mem (CPU python)=33887.55859375MB; mem (CPU total)=33675.01953125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  122] Training loss: 0.60631080, Validation loss: 0.61539705, Gradient norm: 0.17573912
INFO:root:At the start of the epoch: mem (CPU python)=33925.65625MB; mem (CPU total)=33713.1640625MB
INFO:root:[  123] Training loss: 0.60542752, Validation loss: 0.61519907, Gradient norm: 0.13633437
INFO:root:At the start of the epoch: mem (CPU python)=33963.75MB; mem (CPU total)=33751.60546875MB
INFO:root:[  124] Training loss: 0.60518442, Validation loss: 0.61536773, Gradient norm: 0.13404445
INFO:root:At the start of the epoch: mem (CPU python)=34001.84375MB; mem (CPU total)=33789.98046875MB
INFO:root:[  125] Training loss: 0.60511033, Validation loss: 0.61503188, Gradient norm: 0.12796815
INFO:root:At the start of the epoch: mem (CPU python)=34039.94140625MB; mem (CPU total)=33828.3828125MB
INFO:root:[  126] Training loss: 0.60512676, Validation loss: 0.61432696, Gradient norm: 0.12734318
INFO:root:At the start of the epoch: mem (CPU python)=34078.03515625MB; mem (CPU total)=33866.1953125MB
INFO:root:[  127] Training loss: 0.60483182, Validation loss: 0.61438946, Gradient norm: 0.13307607
INFO:root:At the start of the epoch: mem (CPU python)=34116.12890625MB; mem (CPU total)=33904.3359375MB
INFO:root:[  128] Training loss: 0.60466713, Validation loss: 0.61441514, Gradient norm: 0.14501617
INFO:root:At the start of the epoch: mem (CPU python)=34154.2265625MB; mem (CPU total)=33942.3671875MB
INFO:root:[  129] Training loss: 0.60485358, Validation loss: 0.61421291, Gradient norm: 0.13975389
INFO:root:At the start of the epoch: mem (CPU python)=34192.3203125MB; mem (CPU total)=33980.98046875MB
INFO:root:[  130] Training loss: 0.60457205, Validation loss: 0.61512216, Gradient norm: 0.12839556
INFO:root:At the start of the epoch: mem (CPU python)=34230.41796875MB; mem (CPU total)=34018.83984375MB
INFO:root:[  131] Training loss: 0.60473114, Validation loss: 0.61462136, Gradient norm: 0.15062167
INFO:root:At the start of the epoch: mem (CPU python)=34268.51171875MB; mem (CPU total)=34056.9609375MB
INFO:root:[  132] Training loss: 0.60460868, Validation loss: 0.61479949, Gradient norm: 0.19838753
INFO:root:At the start of the epoch: mem (CPU python)=34306.609375MB; mem (CPU total)=34095.296875MB
INFO:root:[  133] Training loss: 0.60457281, Validation loss: 0.61452123, Gradient norm: 0.16633636
INFO:root:At the start of the epoch: mem (CPU python)=34344.703125MB; mem (CPU total)=34133.671875MB
INFO:root:[  134] Training loss: 0.60459347, Validation loss: 0.61438461, Gradient norm: 0.16826180
INFO:root:At the start of the epoch: mem (CPU python)=34382.796875MB; mem (CPU total)=34171.80078125MB
INFO:root:[  135] Training loss: 0.60457362, Validation loss: 0.61510319, Gradient norm: 0.17303246
INFO:root:At the start of the epoch: mem (CPU python)=34420.89453125MB; mem (CPU total)=34209.6640625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  136] Training loss: 0.60436282, Validation loss: 0.61439600, Gradient norm: 0.17062867
INFO:root:At the start of the epoch: mem (CPU python)=34458.98828125MB; mem (CPU total)=34247.796875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  137] Training loss: 0.60379052, Validation loss: 0.61457151, Gradient norm: 0.11894383
INFO:root:At the start of the epoch: mem (CPU python)=34497.0859375MB; mem (CPU total)=34286.20703125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  138] Training loss: 0.60361020, Validation loss: 0.61358787, Gradient norm: 0.10834549
INFO:root:At the start of the epoch: mem (CPU python)=34535.17578125MB; mem (CPU total)=34324.328125MB
INFO:root:[  139] Training loss: 0.60358453, Validation loss: 0.61391436, Gradient norm: 0.10361499
INFO:root:At the start of the epoch: mem (CPU python)=34573.27734375MB; mem (CPU total)=34362.53515625MB
INFO:root:[  140] Training loss: 0.60351126, Validation loss: 0.61423302, Gradient norm: 0.10730179
INFO:root:At the start of the epoch: mem (CPU python)=34611.37109375MB; mem (CPU total)=34400.375MB
INFO:root:[  141] Training loss: 0.60340037, Validation loss: 0.61486896, Gradient norm: 0.10100853
INFO:root:At the start of the epoch: mem (CPU python)=34649.46484375MB; mem (CPU total)=34438.30078125MB
INFO:root:[  142] Training loss: 0.60339857, Validation loss: 0.61416303, Gradient norm: 0.10451922
INFO:root:At the start of the epoch: mem (CPU python)=34687.5625MB; mem (CPU total)=34476.68359375MB
INFO:root:[  143] Training loss: 0.60340854, Validation loss: 0.61330911, Gradient norm: 0.10355302
INFO:root:At the start of the epoch: mem (CPU python)=34725.65625MB; mem (CPU total)=34515.04296875MB
INFO:root:[  144] Training loss: 0.60334294, Validation loss: 0.61457430, Gradient norm: 0.10839464
INFO:root:At the start of the epoch: mem (CPU python)=34763.75MB; mem (CPU total)=34553.16796875MB
INFO:root:[  145] Training loss: 0.60346953, Validation loss: 0.61484013, Gradient norm: 0.11105759
INFO:root:At the start of the epoch: mem (CPU python)=34801.84375MB; mem (CPU total)=34591.49609375MB
INFO:root:[  146] Training loss: 0.60356883, Validation loss: 0.61420869, Gradient norm: 0.10969359
INFO:root:At the start of the epoch: mem (CPU python)=34839.9453125MB; mem (CPU total)=34629.3125MB
INFO:root:[  147] Training loss: 0.60331755, Validation loss: 0.61413437, Gradient norm: 0.10420014
INFO:root:At the start of the epoch: mem (CPU python)=34878.0390625MB; mem (CPU total)=34667.41015625MB
INFO:root:[  148] Training loss: 0.60339762, Validation loss: 0.61473855, Gradient norm: 0.10429939
INFO:root:At the start of the epoch: mem (CPU python)=34916.1328125MB; mem (CPU total)=34705.8203125MB
INFO:root:[  149] Training loss: 0.60330596, Validation loss: 0.61462991, Gradient norm: 0.10475844
INFO:root:At the start of the epoch: mem (CPU python)=34954.23046875MB; mem (CPU total)=34743.7265625MB
INFO:root:[  150] Training loss: 0.60356176, Validation loss: 0.61376309, Gradient norm: 0.10477418
INFO:root:At the start of the epoch: mem (CPU python)=34992.32421875MB; mem (CPU total)=34781.5625MB
INFO:root:[  151] Training loss: 0.60338560, Validation loss: 0.61379519, Gradient norm: 0.11754861
INFO:root:At the start of the epoch: mem (CPU python)=35030.41796875MB; mem (CPU total)=34819.94140625MB
INFO:root:[  152] Training loss: 0.60332775, Validation loss: 0.61402343, Gradient norm: 0.10894808
INFO:root:At the start of the epoch: mem (CPU python)=35068.515625MB; mem (CPU total)=34858.15625MB
INFO:root:EP 152: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=35106.609375MB; mem (CPU total)=34895.85546875MB
INFO:root:Training the model took 17393.15s.
INFO:root:Emptying the cuda cache took 0.315s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85481
INFO:root:EnergyScoreTrain: 0.60327
INFO:root:CRPSTrain: 0.54838
INFO:root:Gaussian NLLTrain: 5.09594
INFO:root:CoverageTrain: 0.76387
INFO:root:IntervalWidthTrain: 3.21625
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87079
INFO:root:EnergyScoreValidation: 0.61408
INFO:root:CRPSValidation: 0.55677
INFO:root:Gaussian NLLValidation: 5.133
INFO:root:CoverageValidation: 0.75914
INFO:root:IntervalWidthValidation: 3.21101
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87231
INFO:root:EnergyScoreTest: 0.61514
INFO:root:CRPSTest: 0.5579
INFO:root:Gaussian NLLTest: 5.16142
INFO:root:CoverageTest: 0.75734
INFO:root:IntervalWidthTest: 3.20398
INFO:root:After validation: mem (CPU python)=35149.26171875MB; mem (CPU total)=34937.75390625MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=35149.265625MB; mem (CPU total)=34937.63671875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 50331648
INFO:root:After setting up the model: mem (CPU python)=35149.89453125MB; mem (CPU total)=34938.12890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=35149.89453125MB; mem (CPU total)=34938.09765625MB
INFO:root:[    1] Training loss: 0.77305755, Validation loss: 0.72363775, Gradient norm: 0.47743828
INFO:root:At the start of the epoch: mem (CPU python)=35188.0078125MB; mem (CPU total)=34978.2109375MB
INFO:root:[    2] Training loss: 0.72152849, Validation loss: 0.72105308, Gradient norm: 0.29632356
INFO:root:At the start of the epoch: mem (CPU python)=35226.1015625MB; mem (CPU total)=35015.8828125MB
INFO:root:[    3] Training loss: 0.72019655, Validation loss: 0.72030023, Gradient norm: 0.24187606
INFO:root:At the start of the epoch: mem (CPU python)=35264.21484375MB; mem (CPU total)=35054.5078125MB
INFO:root:[    4] Training loss: 0.71988652, Validation loss: 0.71965623, Gradient norm: 0.21464539
INFO:root:At the start of the epoch: mem (CPU python)=35302.328125MB; mem (CPU total)=35092.19921875MB
INFO:root:[    5] Training loss: 0.71944702, Validation loss: 0.71925614, Gradient norm: 0.15605244
INFO:root:At the start of the epoch: mem (CPU python)=35340.4296875MB; mem (CPU total)=35130.7890625MB
INFO:root:[    6] Training loss: 0.71902903, Validation loss: 0.71879027, Gradient norm: 0.23375705
INFO:root:At the start of the epoch: mem (CPU python)=35378.5234375MB; mem (CPU total)=35168.8828125MB
INFO:root:[    7] Training loss: 0.71823043, Validation loss: 0.71807909, Gradient norm: 0.13857217
INFO:root:At the start of the epoch: mem (CPU python)=35416.62109375MB; mem (CPU total)=35206.99609375MB
INFO:root:[    8] Training loss: 0.71601398, Validation loss: 0.71383139, Gradient norm: 0.18922683
INFO:root:At the start of the epoch: mem (CPU python)=35454.71875MB; mem (CPU total)=35244.921875MB
INFO:root:[    9] Training loss: 0.70970284, Validation loss: 0.70666094, Gradient norm: 0.15107203
INFO:root:At the start of the epoch: mem (CPU python)=35492.8125MB; mem (CPU total)=35283.34375MB
INFO:root:[   10] Training loss: 0.70295138, Validation loss: 0.70097961, Gradient norm: 0.15064926
INFO:root:At the start of the epoch: mem (CPU python)=35530.91015625MB; mem (CPU total)=35321.71875MB
INFO:root:[   11] Training loss: 0.69777488, Validation loss: 0.69553531, Gradient norm: 0.14343097
INFO:root:At the start of the epoch: mem (CPU python)=35569.00390625MB; mem (CPU total)=35359.5625MB
INFO:root:[   12] Training loss: 0.69294707, Validation loss: 0.69074458, Gradient norm: 0.08867847
INFO:root:At the start of the epoch: mem (CPU python)=35607.09765625MB; mem (CPU total)=35397.73828125MB
INFO:root:[   13] Training loss: 0.68832296, Validation loss: 0.68620930, Gradient norm: 0.09510348
INFO:root:At the start of the epoch: mem (CPU python)=35645.1953125MB; mem (CPU total)=35435.64453125MB
INFO:root:[   14] Training loss: 0.68375966, Validation loss: 0.68232730, Gradient norm: 0.13883744
INFO:root:At the start of the epoch: mem (CPU python)=35683.29296875MB; mem (CPU total)=35473.72265625MB
INFO:root:[   15] Training loss: 0.67983512, Validation loss: 0.67942167, Gradient norm: 0.10928677
INFO:root:At the start of the epoch: mem (CPU python)=35721.38671875MB; mem (CPU total)=35512.125MB
INFO:root:[   16] Training loss: 0.67612355, Validation loss: 0.67513698, Gradient norm: 0.08967903
INFO:root:At the start of the epoch: mem (CPU python)=35759.48046875MB; mem (CPU total)=35551.18359375MB
INFO:root:[   17] Training loss: 0.67290586, Validation loss: 0.67234125, Gradient norm: 0.08096713
INFO:root:At the start of the epoch: mem (CPU python)=35797.578125MB; mem (CPU total)=35588.7421875MB
INFO:root:[   18] Training loss: 0.66971025, Validation loss: 0.66958531, Gradient norm: 0.08566156
INFO:root:At the start of the epoch: mem (CPU python)=35835.671875MB; mem (CPU total)=35626.90625MB
INFO:root:[   19] Training loss: 0.66696006, Validation loss: 0.66664930, Gradient norm: 0.06907375
INFO:root:At the start of the epoch: mem (CPU python)=35873.765625MB; mem (CPU total)=35664.58203125MB
INFO:root:[   20] Training loss: 0.66403851, Validation loss: 0.66485558, Gradient norm: 0.08304959
INFO:root:At the start of the epoch: mem (CPU python)=35911.86328125MB; mem (CPU total)=35702.859375MB
INFO:root:[   21] Training loss: 0.66180179, Validation loss: 0.66226575, Gradient norm: 0.09294720
INFO:root:At the start of the epoch: mem (CPU python)=35949.95703125MB; mem (CPU total)=35741.23046875MB
INFO:root:[   22] Training loss: 0.65957429, Validation loss: 0.65989143, Gradient norm: 0.08125343
INFO:root:At the start of the epoch: mem (CPU python)=35988.0546875MB; mem (CPU total)=35779.44921875MB
INFO:root:[   23] Training loss: 0.65741826, Validation loss: 0.65815401, Gradient norm: 0.08413580
INFO:root:At the start of the epoch: mem (CPU python)=36026.14453125MB; mem (CPU total)=35817.328125MB
INFO:root:[   24] Training loss: 0.65531971, Validation loss: 0.65619897, Gradient norm: 0.07556434
INFO:root:At the start of the epoch: mem (CPU python)=36064.24609375MB; mem (CPU total)=35855.4765625MB
INFO:root:[   25] Training loss: 0.65351426, Validation loss: 0.65528087, Gradient norm: 0.08180907
INFO:root:At the start of the epoch: mem (CPU python)=36102.33984375MB; mem (CPU total)=35893.41796875MB
INFO:root:[   26] Training loss: 0.65169573, Validation loss: 0.65378131, Gradient norm: 0.07797192
INFO:root:At the start of the epoch: mem (CPU python)=36140.43359375MB; mem (CPU total)=35931.53125MB
INFO:root:[   27] Training loss: 0.65017064, Validation loss: 0.65093774, Gradient norm: 0.08237792
INFO:root:At the start of the epoch: mem (CPU python)=36178.53125MB; mem (CPU total)=35969.4609375MB
INFO:root:[   28] Training loss: 0.64831856, Validation loss: 0.64995719, Gradient norm: 0.06970030
INFO:root:At the start of the epoch: mem (CPU python)=36216.625MB; mem (CPU total)=36007.62890625MB
INFO:root:[   29] Training loss: 0.64719162, Validation loss: 0.64882710, Gradient norm: 0.07607638
INFO:root:At the start of the epoch: mem (CPU python)=36254.71875MB; mem (CPU total)=36045.84375MB
INFO:root:[   30] Training loss: 0.64568259, Validation loss: 0.64675891, Gradient norm: 0.07569427
INFO:root:At the start of the epoch: mem (CPU python)=36292.81640625MB; mem (CPU total)=36084.01171875MB
INFO:root:[   31] Training loss: 0.64408259, Validation loss: 0.64575252, Gradient norm: 0.08422503
INFO:root:At the start of the epoch: mem (CPU python)=36330.9140625MB; mem (CPU total)=36122.71484375MB
INFO:root:[   32] Training loss: 0.64284595, Validation loss: 0.64412007, Gradient norm: 0.06925777
INFO:root:At the start of the epoch: mem (CPU python)=36369.0078125MB; mem (CPU total)=36160.30859375MB
INFO:root:[   33] Training loss: 0.64170528, Validation loss: 0.64353258, Gradient norm: 0.07353325
INFO:root:At the start of the epoch: mem (CPU python)=36407.1015625MB; mem (CPU total)=36198.5390625MB
INFO:root:[   34] Training loss: 0.64032839, Validation loss: 0.64257690, Gradient norm: 0.07421715
INFO:root:At the start of the epoch: mem (CPU python)=36445.19921875MB; mem (CPU total)=36236.61328125MB
INFO:root:[   35] Training loss: 0.63920958, Validation loss: 0.64149597, Gradient norm: 0.07417557
INFO:root:At the start of the epoch: mem (CPU python)=36483.29296875MB; mem (CPU total)=36274.98828125MB
INFO:root:[   36] Training loss: 0.63810535, Validation loss: 0.63990376, Gradient norm: 0.07881733
INFO:root:At the start of the epoch: mem (CPU python)=36521.38671875MB; mem (CPU total)=36313.35546875MB
INFO:root:[   37] Training loss: 0.63714315, Validation loss: 0.63911533, Gradient norm: 0.07627527
INFO:root:At the start of the epoch: mem (CPU python)=36559.484375MB; mem (CPU total)=36351.25390625MB
INFO:root:[   38] Training loss: 0.63588995, Validation loss: 0.63762485, Gradient norm: 0.06103770
INFO:root:At the start of the epoch: mem (CPU python)=36597.578125MB; mem (CPU total)=36388.81640625MB
INFO:root:[   39] Training loss: 0.63487293, Validation loss: 0.63707494, Gradient norm: 0.07295978
INFO:root:At the start of the epoch: mem (CPU python)=36635.67578125MB; mem (CPU total)=36426.91796875MB
INFO:root:[   40] Training loss: 0.63397990, Validation loss: 0.63624798, Gradient norm: 0.07478376
INFO:root:At the start of the epoch: mem (CPU python)=36673.76953125MB; mem (CPU total)=36464.83203125MB
INFO:root:[   41] Training loss: 0.63299492, Validation loss: 0.63522636, Gradient norm: 0.07754750
INFO:root:At the start of the epoch: mem (CPU python)=36711.8671875MB; mem (CPU total)=36503.20703125MB
INFO:root:[   42] Training loss: 0.63198572, Validation loss: 0.63432644, Gradient norm: 0.08198731
INFO:root:At the start of the epoch: mem (CPU python)=36749.9609375MB; mem (CPU total)=36541.2421875MB
INFO:root:[   43] Training loss: 0.63115388, Validation loss: 0.63398170, Gradient norm: 0.08441790
INFO:root:At the start of the epoch: mem (CPU python)=36788.0546875MB; mem (CPU total)=36579.08984375MB
INFO:root:[   44] Training loss: 0.63025771, Validation loss: 0.63414521, Gradient norm: 0.07239547
INFO:root:At the start of the epoch: mem (CPU python)=36826.15625MB; mem (CPU total)=36617.05859375MB
INFO:root:[   45] Training loss: 0.62956770, Validation loss: 0.63267655, Gradient norm: 0.08149738
INFO:root:At the start of the epoch: mem (CPU python)=36864.25MB; mem (CPU total)=36655.44140625MB
INFO:root:[   46] Training loss: 0.62857121, Validation loss: 0.63101002, Gradient norm: 0.08358477
INFO:root:At the start of the epoch: mem (CPU python)=36902.34375MB; mem (CPU total)=36693.2890625MB
INFO:root:[   47] Training loss: 0.62771845, Validation loss: 0.63073698, Gradient norm: 0.07303278
INFO:root:At the start of the epoch: mem (CPU python)=36940.44140625MB; mem (CPU total)=36731.08984375MB
INFO:root:[   48] Training loss: 0.62729284, Validation loss: 0.62980883, Gradient norm: 0.08180516
INFO:root:At the start of the epoch: mem (CPU python)=36978.5390625MB; mem (CPU total)=36769.46484375MB
INFO:root:[   49] Training loss: 0.62618675, Validation loss: 0.62986732, Gradient norm: 0.06831221
INFO:root:At the start of the epoch: mem (CPU python)=37019.1328125MB; mem (CPU total)=36810.00390625MB
INFO:root:[   50] Training loss: 0.62556250, Validation loss: 0.62827982, Gradient norm: 0.07428038
INFO:root:At the start of the epoch: mem (CPU python)=37057.2265625MB; mem (CPU total)=36848.59765625MB
INFO:root:[   51] Training loss: 0.62486304, Validation loss: 0.62894845, Gradient norm: 0.07829053
INFO:root:At the start of the epoch: mem (CPU python)=37095.32421875MB; mem (CPU total)=36886.4921875MB
INFO:root:[   52] Training loss: 0.62411008, Validation loss: 0.62729588, Gradient norm: 0.08075632
INFO:root:At the start of the epoch: mem (CPU python)=37133.41796875MB; mem (CPU total)=36924.80078125MB
INFO:root:[   53] Training loss: 0.62338109, Validation loss: 0.62657614, Gradient norm: 0.07617847
INFO:root:At the start of the epoch: mem (CPU python)=37171.51171875MB; mem (CPU total)=36963.16796875MB
INFO:root:[   54] Training loss: 0.62285826, Validation loss: 0.62654218, Gradient norm: 0.08200679
INFO:root:At the start of the epoch: mem (CPU python)=37209.609375MB; mem (CPU total)=37001.2734375MB
INFO:root:[   55] Training loss: 0.62213738, Validation loss: 0.62542919, Gradient norm: 0.08658462
INFO:root:At the start of the epoch: mem (CPU python)=37247.70703125MB; mem (CPU total)=37038.96484375MB
INFO:root:[   56] Training loss: 0.62123535, Validation loss: 0.62570907, Gradient norm: 0.07382159
INFO:root:At the start of the epoch: mem (CPU python)=37285.80078125MB; mem (CPU total)=37077.10546875MB
INFO:root:[   57] Training loss: 0.62080291, Validation loss: 0.62433007, Gradient norm: 0.07849416
INFO:root:At the start of the epoch: mem (CPU python)=37323.89453125MB; mem (CPU total)=37115.22265625MB
INFO:root:[   58] Training loss: 0.62021592, Validation loss: 0.62410551, Gradient norm: 0.08152534
INFO:root:At the start of the epoch: mem (CPU python)=37361.9921875MB; mem (CPU total)=37153.546875MB
INFO:root:[   59] Training loss: 0.61980949, Validation loss: 0.62326706, Gradient norm: 0.08344124
INFO:root:At the start of the epoch: mem (CPU python)=37400.0859375MB; mem (CPU total)=37191.5859375MB
INFO:root:[   60] Training loss: 0.61896052, Validation loss: 0.62300025, Gradient norm: 0.08602328
INFO:root:At the start of the epoch: mem (CPU python)=37438.1796875MB; mem (CPU total)=37229.7109375MB
INFO:root:[   61] Training loss: 0.61856141, Validation loss: 0.62251429, Gradient norm: 0.08605411
INFO:root:At the start of the epoch: mem (CPU python)=37476.27734375MB; mem (CPU total)=37267.4609375MB
INFO:root:[   62] Training loss: 0.61799446, Validation loss: 0.62278492, Gradient norm: 0.08840403
INFO:root:At the start of the epoch: mem (CPU python)=37514.375MB; mem (CPU total)=37305.42578125MB
INFO:root:[   63] Training loss: 0.61751410, Validation loss: 0.62179122, Gradient norm: 0.06861722
INFO:root:At the start of the epoch: mem (CPU python)=37552.46875MB; mem (CPU total)=37344.00390625MB
INFO:root:[   64] Training loss: 0.61696736, Validation loss: 0.62120099, Gradient norm: 0.07451869
INFO:root:At the start of the epoch: mem (CPU python)=37590.56640625MB; mem (CPU total)=37382.1015625MB
INFO:root:[   65] Training loss: 0.61673247, Validation loss: 0.62124957, Gradient norm: 0.07940952
INFO:root:At the start of the epoch: mem (CPU python)=37628.66015625MB; mem (CPU total)=37420.26953125MB
INFO:root:[   66] Training loss: 0.61583109, Validation loss: 0.62086657, Gradient norm: 0.07092805
INFO:root:At the start of the epoch: mem (CPU python)=37666.75390625MB; mem (CPU total)=37458.39453125MB
INFO:root:[   67] Training loss: 0.61551052, Validation loss: 0.62054541, Gradient norm: 0.08546450
INFO:root:At the start of the epoch: mem (CPU python)=37704.84765625MB; mem (CPU total)=37496.5546875MB
INFO:root:[   68] Training loss: 0.61492447, Validation loss: 0.61886837, Gradient norm: 0.08077451
INFO:root:At the start of the epoch: mem (CPU python)=37742.9453125MB; mem (CPU total)=37535.12890625MB
INFO:root:[   69] Training loss: 0.61466001, Validation loss: 0.61883851, Gradient norm: 0.10287897
INFO:root:At the start of the epoch: mem (CPU python)=37781.0390625MB; mem (CPU total)=37573.24609375MB
INFO:root:[   70] Training loss: 0.61406026, Validation loss: 0.61956575, Gradient norm: 0.07723880
INFO:root:At the start of the epoch: mem (CPU python)=37819.1328125MB; mem (CPU total)=37611.140625MB
INFO:root:[   71] Training loss: 0.61366902, Validation loss: 0.61844656, Gradient norm: 0.08539759
INFO:root:At the start of the epoch: mem (CPU python)=37857.234375MB; mem (CPU total)=37649.37890625MB
INFO:root:[   72] Training loss: 0.61323478, Validation loss: 0.61771614, Gradient norm: 0.07413534
INFO:root:At the start of the epoch: mem (CPU python)=37895.328125MB; mem (CPU total)=37687.7109375MB
INFO:root:[   73] Training loss: 0.61277756, Validation loss: 0.61817089, Gradient norm: 0.07881667
INFO:root:At the start of the epoch: mem (CPU python)=37933.42578125MB; mem (CPU total)=37725.8046875MB
INFO:root:[   74] Training loss: 0.61214807, Validation loss: 0.61772313, Gradient norm: 0.08750596
INFO:root:At the start of the epoch: mem (CPU python)=37971.51953125MB; mem (CPU total)=37764.37890625MB
INFO:root:[   75] Training loss: 0.61207537, Validation loss: 0.61651007, Gradient norm: 0.07886855
INFO:root:At the start of the epoch: mem (CPU python)=38009.6171875MB; mem (CPU total)=37802.0078125MB
INFO:root:[   76] Training loss: 0.61162157, Validation loss: 0.61672986, Gradient norm: 0.08558491
INFO:root:At the start of the epoch: mem (CPU python)=38047.7109375MB; mem (CPU total)=37839.84375MB
INFO:root:[   77] Training loss: 0.61117779, Validation loss: 0.61668469, Gradient norm: 0.08221593
INFO:root:At the start of the epoch: mem (CPU python)=38085.8046875MB; mem (CPU total)=37878.21484375MB
INFO:root:[   78] Training loss: 0.61085539, Validation loss: 0.61618774, Gradient norm: 0.08687999
INFO:root:At the start of the epoch: mem (CPU python)=38123.90234375MB; mem (CPU total)=37916.61328125MB
INFO:root:[   79] Training loss: 0.61068213, Validation loss: 0.61605091, Gradient norm: 0.09112903
INFO:root:At the start of the epoch: mem (CPU python)=38161.99609375MB; mem (CPU total)=37954.96875MB
INFO:root:[   80] Training loss: 0.61007290, Validation loss: 0.61540431, Gradient norm: 0.08261448
INFO:root:At the start of the epoch: mem (CPU python)=38200.09375MB; mem (CPU total)=37992.77734375MB
INFO:root:[   81] Training loss: 0.60956920, Validation loss: 0.61471547, Gradient norm: 0.08196968
INFO:root:At the start of the epoch: mem (CPU python)=38238.19140625MB; mem (CPU total)=38030.8203125MB
INFO:root:[   82] Training loss: 0.60942833, Validation loss: 0.61421978, Gradient norm: 0.08373261
INFO:root:At the start of the epoch: mem (CPU python)=38276.28515625MB; mem (CPU total)=38069.41796875MB
INFO:root:[   83] Training loss: 0.60905541, Validation loss: 0.61527163, Gradient norm: 0.07597194
INFO:root:At the start of the epoch: mem (CPU python)=38314.37890625MB; mem (CPU total)=38107.5390625MB
INFO:root:[   84] Training loss: 0.60875880, Validation loss: 0.61394626, Gradient norm: 0.08629134
INFO:root:At the start of the epoch: mem (CPU python)=38352.47265625MB; mem (CPU total)=38145.64453125MB
INFO:root:[   85] Training loss: 0.60852742, Validation loss: 0.61404920, Gradient norm: 0.09090290
INFO:root:At the start of the epoch: mem (CPU python)=38390.5703125MB; mem (CPU total)=38184.03515625MB
INFO:root:[   86] Training loss: 0.60841937, Validation loss: 0.61348300, Gradient norm: 0.10637588
INFO:root:At the start of the epoch: mem (CPU python)=38428.6640625MB; mem (CPU total)=38222.63671875MB
INFO:root:[   87] Training loss: 0.60778990, Validation loss: 0.61297174, Gradient norm: 0.08343543
INFO:root:At the start of the epoch: mem (CPU python)=38466.7578125MB; mem (CPU total)=38260.66015625MB
INFO:root:[   88] Training loss: 0.60744478, Validation loss: 0.61340893, Gradient norm: 0.07727932
INFO:root:At the start of the epoch: mem (CPU python)=38504.86328125MB; mem (CPU total)=38299.01171875MB
INFO:root:[   89] Training loss: 0.60724850, Validation loss: 0.61296992, Gradient norm: 0.08179705
INFO:root:At the start of the epoch: mem (CPU python)=38542.953125MB; mem (CPU total)=38337.00390625MB
INFO:root:[   90] Training loss: 0.60725865, Validation loss: 0.61256881, Gradient norm: 0.08735846
INFO:root:At the start of the epoch: mem (CPU python)=38581.05078125MB; mem (CPU total)=38375.1484375MB
INFO:root:[   91] Training loss: 0.60651425, Validation loss: 0.61224160, Gradient norm: 0.09405485
INFO:root:At the start of the epoch: mem (CPU python)=38619.14453125MB; mem (CPU total)=38413.234375MB
INFO:root:[   92] Training loss: 0.60640666, Validation loss: 0.61234972, Gradient norm: 0.08549433
INFO:root:At the start of the epoch: mem (CPU python)=38657.2421875MB; mem (CPU total)=38451.3125MB
INFO:root:[   93] Training loss: 0.60620774, Validation loss: 0.61188231, Gradient norm: 0.08721320
INFO:root:At the start of the epoch: mem (CPU python)=38695.3359375MB; mem (CPU total)=38489.6796875MB
INFO:root:[   94] Training loss: 0.60595532, Validation loss: 0.61292836, Gradient norm: 0.09544405
INFO:root:At the start of the epoch: mem (CPU python)=38733.4296875MB; mem (CPU total)=38527.82421875MB
INFO:root:[   95] Training loss: 0.60553492, Validation loss: 0.61212869, Gradient norm: 0.07961334
INFO:root:At the start of the epoch: mem (CPU python)=38771.52734375MB; mem (CPU total)=38565.3671875MB
INFO:root:[   96] Training loss: 0.60541559, Validation loss: 0.61195915, Gradient norm: 0.08818130
INFO:root:At the start of the epoch: mem (CPU python)=38809.62109375MB; mem (CPU total)=38603.9375MB
INFO:root:[   97] Training loss: 0.60527968, Validation loss: 0.61136959, Gradient norm: 0.09756620
INFO:root:At the start of the epoch: mem (CPU python)=38847.71875MB; mem (CPU total)=38641.875MB
INFO:root:[   98] Training loss: 0.60479111, Validation loss: 0.61205256, Gradient norm: 0.09161169
INFO:root:At the start of the epoch: mem (CPU python)=38885.81640625MB; mem (CPU total)=38680.22265625MB
INFO:root:[   99] Training loss: 0.60452595, Validation loss: 0.61112136, Gradient norm: 0.08679414
INFO:root:At the start of the epoch: mem (CPU python)=38923.91015625MB; mem (CPU total)=38718.58984375MB
INFO:root:[  100] Training loss: 0.60430177, Validation loss: 0.61097547, Gradient norm: 0.08988383
INFO:root:At the start of the epoch: mem (CPU python)=38962.00390625MB; mem (CPU total)=38756.33984375MB
INFO:root:[  101] Training loss: 0.60426032, Validation loss: 0.61096048, Gradient norm: 0.09624055
INFO:root:At the start of the epoch: mem (CPU python)=39000.09765625MB; mem (CPU total)=38794.5234375MB
INFO:root:[  102] Training loss: 0.60382821, Validation loss: 0.61091723, Gradient norm: 0.09182317
INFO:root:At the start of the epoch: mem (CPU python)=39038.1953125MB; mem (CPU total)=38832.36328125MB
INFO:root:[  103] Training loss: 0.60384353, Validation loss: 0.61094732, Gradient norm: 0.09075045
INFO:root:At the start of the epoch: mem (CPU python)=39076.2890625MB; mem (CPU total)=38870.453125MB
INFO:root:[  104] Training loss: 0.60356699, Validation loss: 0.60992601, Gradient norm: 0.10678783
INFO:root:At the start of the epoch: mem (CPU python)=39114.3828125MB; mem (CPU total)=38908.53125MB
INFO:root:[  105] Training loss: 0.60337681, Validation loss: 0.60994297, Gradient norm: 0.09851479
INFO:root:At the start of the epoch: mem (CPU python)=39152.484375MB; mem (CPU total)=38946.8828125MB
INFO:root:[  106] Training loss: 0.60300079, Validation loss: 0.61042887, Gradient norm: 0.09267028
INFO:root:At the start of the epoch: mem (CPU python)=39190.578125MB; mem (CPU total)=38985.01953125MB
INFO:root:[  107] Training loss: 0.60299431, Validation loss: 0.60969803, Gradient norm: 0.10179310
INFO:root:At the start of the epoch: mem (CPU python)=39228.671875MB; mem (CPU total)=39022.859375MB
INFO:root:[  108] Training loss: 0.60278847, Validation loss: 0.60955989, Gradient norm: 0.09387917
INFO:root:At the start of the epoch: mem (CPU python)=39266.765625MB; mem (CPU total)=39060.6015625MB
INFO:root:[  109] Training loss: 0.60246537, Validation loss: 0.60890353, Gradient norm: 0.10225619
INFO:root:At the start of the epoch: mem (CPU python)=39304.86328125MB; mem (CPU total)=39098.9765625MB
INFO:root:[  110] Training loss: 0.60243599, Validation loss: 0.60874060, Gradient norm: 0.09919564
INFO:root:At the start of the epoch: mem (CPU python)=39342.95703125MB; mem (CPU total)=39137.64453125MB
INFO:root:[  111] Training loss: 0.60199625, Validation loss: 0.60978114, Gradient norm: 0.10419667
INFO:root:At the start of the epoch: mem (CPU python)=39381.05078125MB; mem (CPU total)=39175.6171875MB
INFO:root:[  112] Training loss: 0.60198382, Validation loss: 0.60876066, Gradient norm: 0.11052768
INFO:root:At the start of the epoch: mem (CPU python)=39419.1484375MB; mem (CPU total)=39213.71875MB
INFO:root:[  113] Training loss: 0.60165935, Validation loss: 0.60868066, Gradient norm: 0.09726389
INFO:root:At the start of the epoch: mem (CPU python)=39457.24609375MB; mem (CPU total)=39251.5MB
INFO:root:[  114] Training loss: 0.60146050, Validation loss: 0.60962085, Gradient norm: 0.09760756
INFO:root:At the start of the epoch: mem (CPU python)=39495.33984375MB; mem (CPU total)=39289.65234375MB
INFO:root:[  115] Training loss: 0.60120689, Validation loss: 0.60843468, Gradient norm: 0.10834972
INFO:root:At the start of the epoch: mem (CPU python)=39533.4375MB; mem (CPU total)=39328.0390625MB
INFO:root:[  116] Training loss: 0.60124982, Validation loss: 0.60833518, Gradient norm: 0.11433947
INFO:root:At the start of the epoch: mem (CPU python)=39571.53125MB; mem (CPU total)=39365.953125MB
INFO:root:[  117] Training loss: 0.60093893, Validation loss: 0.60848604, Gradient norm: 0.11224487
INFO:root:At the start of the epoch: mem (CPU python)=39609.625MB; mem (CPU total)=39404.640625MB
INFO:root:[  118] Training loss: 0.60090698, Validation loss: 0.60851785, Gradient norm: 0.12012797
INFO:root:At the start of the epoch: mem (CPU python)=39647.71875MB; mem (CPU total)=39442.74609375MB
INFO:root:[  119] Training loss: 0.60072177, Validation loss: 0.60765584, Gradient norm: 0.10738594
INFO:root:At the start of the epoch: mem (CPU python)=39685.81640625MB; mem (CPU total)=39480.796875MB
INFO:root:[  120] Training loss: 0.60050859, Validation loss: 0.60786172, Gradient norm: 0.10943839
INFO:root:At the start of the epoch: mem (CPU python)=39723.91015625MB; mem (CPU total)=39518.89453125MB
INFO:root:[  121] Training loss: 0.60041542, Validation loss: 0.60810166, Gradient norm: 0.12886668
INFO:root:At the start of the epoch: mem (CPU python)=39762.00390625MB; mem (CPU total)=39557.0234375MB
INFO:root:[  122] Training loss: 0.60011020, Validation loss: 0.60762608, Gradient norm: 0.12867346
INFO:root:At the start of the epoch: mem (CPU python)=39800.10546875MB; mem (CPU total)=39594.6015625MB
INFO:root:[  123] Training loss: 0.59993011, Validation loss: 0.60741471, Gradient norm: 0.10348624
INFO:root:At the start of the epoch: mem (CPU python)=39838.19921875MB; mem (CPU total)=39633.23046875MB
INFO:root:[  124] Training loss: 0.59984807, Validation loss: 0.60817425, Gradient norm: 0.11479301
INFO:root:At the start of the epoch: mem (CPU python)=39876.29296875MB; mem (CPU total)=39671.125MB
INFO:root:[  125] Training loss: 0.59957545, Validation loss: 0.60692967, Gradient norm: 0.10160343
INFO:root:At the start of the epoch: mem (CPU python)=39914.38671875MB; mem (CPU total)=39709.5078125MB
INFO:root:[  126] Training loss: 0.59950531, Validation loss: 0.60722482, Gradient norm: 0.12298979
INFO:root:At the start of the epoch: mem (CPU python)=39952.484375MB; mem (CPU total)=39748.03515625MB
INFO:root:[  127] Training loss: 0.59922963, Validation loss: 0.60714541, Gradient norm: 0.11146276
INFO:root:At the start of the epoch: mem (CPU python)=39990.578125MB; mem (CPU total)=39785.6640625MB
INFO:root:[  128] Training loss: 0.59927259, Validation loss: 0.60689096, Gradient norm: 0.14264900
INFO:root:At the start of the epoch: mem (CPU python)=40028.671875MB; mem (CPU total)=39823.79296875MB
INFO:root:[  129] Training loss: 0.59894460, Validation loss: 0.60650420, Gradient norm: 0.14206861
INFO:root:At the start of the epoch: mem (CPU python)=40066.76953125MB; mem (CPU total)=39862.1796875MB
INFO:root:[  130] Training loss: 0.59871060, Validation loss: 0.60655910, Gradient norm: 0.11591275
INFO:root:At the start of the epoch: mem (CPU python)=40104.86328125MB; mem (CPU total)=39900.3125MB
INFO:root:[  131] Training loss: 0.59880781, Validation loss: 0.60667452, Gradient norm: 0.12526847
INFO:root:At the start of the epoch: mem (CPU python)=40142.9609375MB; mem (CPU total)=39938.203125MB
INFO:root:[  132] Training loss: 0.59843025, Validation loss: 0.60675262, Gradient norm: 0.12566342
INFO:root:At the start of the epoch: mem (CPU python)=40181.05859375MB; mem (CPU total)=39976.515625MB
INFO:root:[  133] Training loss: 0.59842683, Validation loss: 0.60681312, Gradient norm: 0.15776731
INFO:root:At the start of the epoch: mem (CPU python)=40219.15234375MB; mem (CPU total)=40014.62890625MB
INFO:root:[  134] Training loss: 0.59834990, Validation loss: 0.60603896, Gradient norm: 0.13925834
INFO:root:At the start of the epoch: mem (CPU python)=40257.24609375MB; mem (CPU total)=40054.8828125MB
INFO:root:[  135] Training loss: 0.59830035, Validation loss: 0.60690232, Gradient norm: 0.13705621
INFO:root:At the start of the epoch: mem (CPU python)=40295.33984375MB; mem (CPU total)=40093.24609375MB
INFO:root:[  136] Training loss: 0.59808947, Validation loss: 0.60596364, Gradient norm: 0.13168485
INFO:root:At the start of the epoch: mem (CPU python)=40333.4375MB; mem (CPU total)=40130.71484375MB
INFO:root:[  137] Training loss: 0.59784729, Validation loss: 0.60669971, Gradient norm: 0.14994719
INFO:root:At the start of the epoch: mem (CPU python)=40371.53125MB; mem (CPU total)=40168.828125MB
INFO:root:[  138] Training loss: 0.59765039, Validation loss: 0.60639320, Gradient norm: 0.17695184
INFO:root:At the start of the epoch: mem (CPU python)=40409.625MB; mem (CPU total)=40207.17578125MB
INFO:root:[  139] Training loss: 0.59758171, Validation loss: 0.60705825, Gradient norm: 0.14123496
INFO:root:At the start of the epoch: mem (CPU python)=40447.7265625MB; mem (CPU total)=40244.9765625MB
INFO:root:[  140] Training loss: 0.59753373, Validation loss: 0.60614282, Gradient norm: 0.14721050
INFO:root:At the start of the epoch: mem (CPU python)=40485.82421875MB; mem (CPU total)=40283.13671875MB
INFO:root:[  141] Training loss: 0.59706715, Validation loss: 0.60643997, Gradient norm: 0.14884409
INFO:root:At the start of the epoch: mem (CPU python)=40523.91796875MB; mem (CPU total)=40321.2578125MB
INFO:root:[  142] Training loss: 0.59734821, Validation loss: 0.60544590, Gradient norm: 0.14856501
INFO:root:At the start of the epoch: mem (CPU python)=40562.01171875MB; mem (CPU total)=40360.37109375MB
INFO:root:[  143] Training loss: 0.59717450, Validation loss: 0.60581295, Gradient norm: 0.15987909
INFO:root:At the start of the epoch: mem (CPU python)=40600.11328125MB; mem (CPU total)=40398.18359375MB
INFO:root:[  144] Training loss: 0.59709918, Validation loss: 0.60571962, Gradient norm: 0.18702273
INFO:root:At the start of the epoch: mem (CPU python)=40638.203125MB; mem (CPU total)=40436.30078125MB
INFO:root:[  145] Training loss: 0.59695087, Validation loss: 0.60562125, Gradient norm: 0.19915902
INFO:root:At the start of the epoch: mem (CPU python)=40676.296875MB; mem (CPU total)=40474.37109375MB
INFO:root:[  146] Training loss: 0.59667531, Validation loss: 0.60634408, Gradient norm: 0.16885720
INFO:root:At the start of the epoch: mem (CPU python)=40714.3984375MB; mem (CPU total)=40512.2578125MB
INFO:root:[  147] Training loss: 0.59668510, Validation loss: 0.60498070, Gradient norm: 0.16591634
INFO:root:At the start of the epoch: mem (CPU python)=40752.4921875MB; mem (CPU total)=40551.36328125MB
INFO:root:[  148] Training loss: 0.59669282, Validation loss: 0.60529561, Gradient norm: 0.19438977
INFO:root:At the start of the epoch: mem (CPU python)=40790.5859375MB; mem (CPU total)=40588.71875MB
INFO:root:[  149] Training loss: 0.59648457, Validation loss: 0.60576871, Gradient norm: 0.18985822
INFO:root:At the start of the epoch: mem (CPU python)=40828.68359375MB; mem (CPU total)=40626.83984375MB
INFO:root:[  150] Training loss: 0.59631851, Validation loss: 0.60572013, Gradient norm: 0.18023701
INFO:root:At the start of the epoch: mem (CPU python)=40866.77734375MB; mem (CPU total)=40664.9296875MB
INFO:root:[  151] Training loss: 0.59612843, Validation loss: 0.60552806, Gradient norm: 0.20552013
INFO:root:At the start of the epoch: mem (CPU python)=40904.87109375MB; mem (CPU total)=40703.0546875MB
INFO:root:[  152] Training loss: 0.59605854, Validation loss: 0.60432206, Gradient norm: 0.19237127
INFO:root:At the start of the epoch: mem (CPU python)=40942.96484375MB; mem (CPU total)=40741.3828125MB
INFO:root:[  153] Training loss: 0.59595052, Validation loss: 0.60499921, Gradient norm: 0.17779388
INFO:root:At the start of the epoch: mem (CPU python)=40981.0625MB; mem (CPU total)=40779.7734375MB
INFO:root:[  154] Training loss: 0.59572785, Validation loss: 0.60487386, Gradient norm: 0.21384374
INFO:root:At the start of the epoch: mem (CPU python)=41019.16015625MB; mem (CPU total)=40817.9140625MB
INFO:root:[  155] Training loss: 0.59587401, Validation loss: 0.60541729, Gradient norm: 0.22312070
INFO:root:At the start of the epoch: mem (CPU python)=41057.25MB; mem (CPU total)=40856.265625MB
INFO:root:[  156] Training loss: 0.59548864, Validation loss: 0.60571940, Gradient norm: 0.19666267
INFO:root:At the start of the epoch: mem (CPU python)=41095.3515625MB; mem (CPU total)=40894.12890625MB
INFO:root:[  157] Training loss: 0.59560369, Validation loss: 0.60520008, Gradient norm: 0.21287156
INFO:root:At the start of the epoch: mem (CPU python)=41133.4453125MB; mem (CPU total)=40932.23828125MB
INFO:root:[  158] Training loss: 0.59548328, Validation loss: 0.60555004, Gradient norm: 0.23460682
INFO:root:At the start of the epoch: mem (CPU python)=41171.5390625MB; mem (CPU total)=40970.3203125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  159] Training loss: 0.59538267, Validation loss: 0.60503768, Gradient norm: 0.24208575
INFO:root:At the start of the epoch: mem (CPU python)=41209.6328125MB; mem (CPU total)=41008.47265625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  160] Training loss: 0.59439392, Validation loss: 0.60485467, Gradient norm: 0.15161181
INFO:root:At the start of the epoch: mem (CPU python)=41247.73046875MB; mem (CPU total)=41047.3125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  161] Training loss: 0.59375799, Validation loss: 0.60382825, Gradient norm: 0.12663723
INFO:root:At the start of the epoch: mem (CPU python)=41285.82421875MB; mem (CPU total)=41085.2109375MB
INFO:root:[  162] Training loss: 0.59356346, Validation loss: 0.60396589, Gradient norm: 0.10954163
INFO:root:At the start of the epoch: mem (CPU python)=41323.91796875MB; mem (CPU total)=41123.07421875MB
INFO:root:[  163] Training loss: 0.59333333, Validation loss: 0.60467677, Gradient norm: 0.10805130
INFO:root:At the start of the epoch: mem (CPU python)=41362.015625MB; mem (CPU total)=41161.23828125MB
INFO:root:[  164] Training loss: 0.59339291, Validation loss: 0.60351577, Gradient norm: 0.10875636
INFO:root:At the start of the epoch: mem (CPU python)=41400.11328125MB; mem (CPU total)=41199.77734375MB
INFO:root:[  165] Training loss: 0.59332878, Validation loss: 0.60414393, Gradient norm: 0.10740636
INFO:root:At the start of the epoch: mem (CPU python)=41438.20703125MB; mem (CPU total)=41237.8671875MB
INFO:root:[  166] Training loss: 0.59347704, Validation loss: 0.60347454, Gradient norm: 0.11067019
INFO:root:At the start of the epoch: mem (CPU python)=41476.3046875MB; mem (CPU total)=41275.72265625MB
INFO:root:[  167] Training loss: 0.59362225, Validation loss: 0.60369757, Gradient norm: 0.10685975
INFO:root:At the start of the epoch: mem (CPU python)=41514.3984375MB; mem (CPU total)=41314.12109375MB
INFO:root:[  168] Training loss: 0.59354660, Validation loss: 0.60367049, Gradient norm: 0.11662699
INFO:root:At the start of the epoch: mem (CPU python)=41552.4921875MB; mem (CPU total)=41352.08203125MB
INFO:root:[  169] Training loss: 0.59339205, Validation loss: 0.60386828, Gradient norm: 0.11594874
INFO:root:At the start of the epoch: mem (CPU python)=41590.5859375MB; mem (CPU total)=41390.08203125MB
INFO:root:[  170] Training loss: 0.59336513, Validation loss: 0.60369785, Gradient norm: 0.12356448
INFO:root:At the start of the epoch: mem (CPU python)=41628.68359375MB; mem (CPU total)=41428.44921875MB
INFO:root:[  171] Training loss: 0.59315691, Validation loss: 0.60429948, Gradient norm: 0.12136759
INFO:root:At the start of the epoch: mem (CPU python)=41666.78125MB; mem (CPU total)=41466.30078125MB
INFO:root:[  172] Training loss: 0.59330065, Validation loss: 0.60451236, Gradient norm: 0.12743032
INFO:root:At the start of the epoch: mem (CPU python)=41704.875MB; mem (CPU total)=41504.6640625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  173] Training loss: 0.59330534, Validation loss: 0.60353524, Gradient norm: 0.12544163
INFO:root:At the start of the epoch: mem (CPU python)=41742.9765625MB; mem (CPU total)=41542.7734375MB
INFO:root:[  174] Training loss: 0.59299590, Validation loss: 0.60392372, Gradient norm: 0.11508644
INFO:root:At the start of the epoch: mem (CPU python)=41781.0703125MB; mem (CPU total)=41580.95703125MB
INFO:root:[  175] Training loss: 0.59321239, Validation loss: 0.60364872, Gradient norm: 0.10736247
INFO:root:At the start of the epoch: mem (CPU python)=41819.1640625MB; mem (CPU total)=41619.20703125MB
INFO:root:EP 175: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=41857.2578125MB; mem (CPU total)=41657.0859375MB
INFO:root:Training the model took 21385.381s.
INFO:root:Emptying the cuda cache took 0.314s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8402
INFO:root:EnergyScoreTrain: 0.59316
INFO:root:CRPSTrain: 0.53635
INFO:root:Gaussian NLLTrain: 4.60688
INFO:root:CoverageTrain: 0.77385
INFO:root:IntervalWidthTrain: 3.1971
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.85515
INFO:root:EnergyScoreValidation: 0.60331
INFO:root:CRPSValidation: 0.54418
INFO:root:Gaussian NLLValidation: 4.63631
INFO:root:CoverageValidation: 0.76895
INFO:root:IntervalWidthValidation: 3.19894
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.85705
INFO:root:EnergyScoreTest: 0.60455
INFO:root:CRPSTest: 0.54532
INFO:root:Gaussian NLLTest: 4.65709
INFO:root:CoverageTest: 0.76728
INFO:root:IntervalWidthTest: 3.18488
INFO:root:After validation: mem (CPU python)=41899.90234375MB; mem (CPU total)=41698.7109375MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=41899.90234375MB; mem (CPU total)=41698.63671875MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 50331648
INFO:root:After setting up the model: mem (CPU python)=41900.52734375MB; mem (CPU total)=41699.375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=41900.52734375MB; mem (CPU total)=41699.29296875MB
INFO:root:[    1] Training loss: 0.79699783, Validation loss: 0.72522080, Gradient norm: 0.33101522
INFO:root:At the start of the epoch: mem (CPU python)=41938.89453125MB; mem (CPU total)=41739.77734375MB
INFO:root:[    2] Training loss: 0.72195599, Validation loss: 0.72102436, Gradient norm: 0.23585532
INFO:root:At the start of the epoch: mem (CPU python)=41976.9921875MB; mem (CPU total)=41777.84765625MB
INFO:root:[    3] Training loss: 0.72034584, Validation loss: 0.72037974, Gradient norm: 0.20266643
INFO:root:At the start of the epoch: mem (CPU python)=42015.1015625MB; mem (CPU total)=41816.2578125MB
INFO:root:[    4] Training loss: 0.71984770, Validation loss: 0.71994797, Gradient norm: 0.15022624
INFO:root:At the start of the epoch: mem (CPU python)=42053.19921875MB; mem (CPU total)=41855.41015625MB
INFO:root:[    5] Training loss: 0.71964008, Validation loss: 0.72047228, Gradient norm: 0.14684791
INFO:root:At the start of the epoch: mem (CPU python)=42091.30078125MB; mem (CPU total)=41893.03125MB
INFO:root:[    6] Training loss: 0.71910477, Validation loss: 0.71935421, Gradient norm: 0.09085073
INFO:root:At the start of the epoch: mem (CPU python)=42129.39453125MB; mem (CPU total)=41931.53125MB
INFO:root:[    7] Training loss: 0.71837400, Validation loss: 0.71818111, Gradient norm: 0.10870882
INFO:root:At the start of the epoch: mem (CPU python)=42167.48828125MB; mem (CPU total)=41969.390625MB
INFO:root:[    8] Training loss: 0.71673144, Validation loss: 0.71427082, Gradient norm: 0.13062825
INFO:root:At the start of the epoch: mem (CPU python)=42205.5859375MB; mem (CPU total)=42007.5234375MB
INFO:root:[    9] Training loss: 0.71057653, Validation loss: 0.70682334, Gradient norm: 0.13924002
INFO:root:At the start of the epoch: mem (CPU python)=42243.6796875MB; mem (CPU total)=42045.875MB
INFO:root:[   10] Training loss: 0.70236179, Validation loss: 0.69935925, Gradient norm: 0.11053656
INFO:root:At the start of the epoch: mem (CPU python)=42281.77734375MB; mem (CPU total)=42084.00390625MB
INFO:root:[   11] Training loss: 0.69612995, Validation loss: 0.69401899, Gradient norm: 0.09800341
INFO:root:At the start of the epoch: mem (CPU python)=42319.875MB; mem (CPU total)=42122.359375MB
INFO:root:[   12] Training loss: 0.69083089, Validation loss: 0.68946556, Gradient norm: 0.12252091
INFO:root:At the start of the epoch: mem (CPU python)=42357.96875MB; mem (CPU total)=42160.234375MB
INFO:root:[   13] Training loss: 0.68621029, Validation loss: 0.68524737, Gradient norm: 0.11346193
INFO:root:At the start of the epoch: mem (CPU python)=42396.0625MB; mem (CPU total)=42198.84375MB
INFO:root:[   14] Training loss: 0.68213368, Validation loss: 0.68147973, Gradient norm: 0.10384562
INFO:root:At the start of the epoch: mem (CPU python)=42434.15625MB; mem (CPU total)=42236.8515625MB
INFO:root:[   15] Training loss: 0.67852853, Validation loss: 0.67832029, Gradient norm: 0.10276477
INFO:root:At the start of the epoch: mem (CPU python)=42472.25390625MB; mem (CPU total)=42274.60546875MB
INFO:root:[   16] Training loss: 0.67525130, Validation loss: 0.67563080, Gradient norm: 0.10051729
INFO:root:At the start of the epoch: mem (CPU python)=42510.3515625MB; mem (CPU total)=42312.9609375MB
INFO:root:[   17] Training loss: 0.67233175, Validation loss: 0.67313503, Gradient norm: 0.09595881
INFO:root:At the start of the epoch: mem (CPU python)=42548.4453125MB; mem (CPU total)=42351.10546875MB
INFO:root:[   18] Training loss: 0.66961671, Validation loss: 0.66974913, Gradient norm: 0.09359237
INFO:root:At the start of the epoch: mem (CPU python)=42586.54296875MB; mem (CPU total)=42389.046875MB
INFO:root:[   19] Training loss: 0.66694651, Validation loss: 0.66768042, Gradient norm: 0.08784841
INFO:root:At the start of the epoch: mem (CPU python)=42624.63671875MB; mem (CPU total)=42427.01953125MB
INFO:root:[   20] Training loss: 0.66441654, Validation loss: 0.66463979, Gradient norm: 0.11413548
INFO:root:At the start of the epoch: mem (CPU python)=42662.734375MB; mem (CPU total)=42464.953125MB
INFO:root:[   21] Training loss: 0.66197779, Validation loss: 0.66292148, Gradient norm: 0.10943366
INFO:root:At the start of the epoch: mem (CPU python)=42700.828125MB; mem (CPU total)=42503.0MB
INFO:root:[   22] Training loss: 0.65995891, Validation loss: 0.66145658, Gradient norm: 0.10012613
INFO:root:At the start of the epoch: mem (CPU python)=42738.92578125MB; mem (CPU total)=42542.4609375MB
INFO:root:[   23] Training loss: 0.65780749, Validation loss: 0.65918407, Gradient norm: 0.11444965
INFO:root:At the start of the epoch: mem (CPU python)=42777.0234375MB; mem (CPU total)=42580.62109375MB
INFO:root:[   24] Training loss: 0.65573690, Validation loss: 0.65756913, Gradient norm: 0.09216240
INFO:root:At the start of the epoch: mem (CPU python)=42815.11328125MB; mem (CPU total)=42619.02734375MB
INFO:root:[   25] Training loss: 0.65414416, Validation loss: 0.65591728, Gradient norm: 0.09625583
INFO:root:At the start of the epoch: mem (CPU python)=42853.21484375MB; mem (CPU total)=42657.73828125MB
INFO:root:[   26] Training loss: 0.65236567, Validation loss: 0.65342153, Gradient norm: 0.10055502
INFO:root:At the start of the epoch: mem (CPU python)=42891.30859375MB; mem (CPU total)=42695.88671875MB
INFO:root:[   27] Training loss: 0.65079776, Validation loss: 0.65222076, Gradient norm: 0.11079895
INFO:root:At the start of the epoch: mem (CPU python)=42929.40234375MB; mem (CPU total)=42734.59765625MB
INFO:root:[   28] Training loss: 0.64935477, Validation loss: 0.65103802, Gradient norm: 0.10385103
INFO:root:At the start of the epoch: mem (CPU python)=42967.5MB; mem (CPU total)=42772.27734375MB
INFO:root:[   29] Training loss: 0.64783554, Validation loss: 0.65018694, Gradient norm: 0.09529197
INFO:root:At the start of the epoch: mem (CPU python)=43005.59375MB; mem (CPU total)=42811.234375MB
INFO:root:[   30] Training loss: 0.64688081, Validation loss: 0.64882390, Gradient norm: 0.09429827
INFO:root:At the start of the epoch: mem (CPU python)=43043.6875MB; mem (CPU total)=42848.80859375MB
INFO:root:[   31] Training loss: 0.64545266, Validation loss: 0.64771269, Gradient norm: 0.09133082
INFO:root:At the start of the epoch: mem (CPU python)=43081.78125MB; mem (CPU total)=42886.91015625MB
INFO:root:[   32] Training loss: 0.64420324, Validation loss: 0.64669410, Gradient norm: 0.09641788
INFO:root:At the start of the epoch: mem (CPU python)=43119.8828125MB; mem (CPU total)=42925.48828125MB
INFO:root:[   33] Training loss: 0.64320822, Validation loss: 0.64675193, Gradient norm: 0.10704805
INFO:root:At the start of the epoch: mem (CPU python)=43157.9765625MB; mem (CPU total)=42963.421875MB
INFO:root:[   34] Training loss: 0.64205624, Validation loss: 0.64452813, Gradient norm: 0.08924851
INFO:root:At the start of the epoch: mem (CPU python)=43196.0703125MB; mem (CPU total)=43001.82421875MB
INFO:root:[   35] Training loss: 0.64106081, Validation loss: 0.64382918, Gradient norm: 0.08162337
INFO:root:At the start of the epoch: mem (CPU python)=43234.16796875MB; mem (CPU total)=43039.73046875MB
INFO:root:[   36] Training loss: 0.64013091, Validation loss: 0.64322081, Gradient norm: 0.08881677
INFO:root:At the start of the epoch: mem (CPU python)=43272.265625MB; mem (CPU total)=43077.93359375MB
INFO:root:[   37] Training loss: 0.63911487, Validation loss: 0.64267229, Gradient norm: 0.09715852
INFO:root:At the start of the epoch: mem (CPU python)=43310.359375MB; mem (CPU total)=43116.08984375MB
INFO:root:[   38] Training loss: 0.63824557, Validation loss: 0.64174790, Gradient norm: 0.08964954
INFO:root:At the start of the epoch: mem (CPU python)=43348.453125MB; mem (CPU total)=43153.9765625MB
INFO:root:[   39] Training loss: 0.63750206, Validation loss: 0.64159454, Gradient norm: 0.09071187
INFO:root:At the start of the epoch: mem (CPU python)=43386.55078125MB; mem (CPU total)=43191.8671875MB
INFO:root:[   40] Training loss: 0.63651135, Validation loss: 0.64010998, Gradient norm: 0.09076182
INFO:root:At the start of the epoch: mem (CPU python)=43424.6484375MB; mem (CPU total)=43230.265625MB
INFO:root:[   41] Training loss: 0.63581722, Validation loss: 0.63931025, Gradient norm: 0.10831397
INFO:root:At the start of the epoch: mem (CPU python)=43462.73828125MB; mem (CPU total)=43268.8359375MB
INFO:root:[   42] Training loss: 0.63507421, Validation loss: 0.63881167, Gradient norm: 0.09912786
INFO:root:At the start of the epoch: mem (CPU python)=43500.83984375MB; mem (CPU total)=43306.98828125MB
INFO:root:[   43] Training loss: 0.63431911, Validation loss: 0.63794807, Gradient norm: 0.09507114
INFO:root:At the start of the epoch: mem (CPU python)=43538.93359375MB; mem (CPU total)=43345.5078125MB
INFO:root:[   44] Training loss: 0.63343481, Validation loss: 0.63668884, Gradient norm: 0.09097009
INFO:root:At the start of the epoch: mem (CPU python)=43577.02734375MB; mem (CPU total)=43382.921875MB
INFO:root:[   45] Training loss: 0.63283511, Validation loss: 0.63744790, Gradient norm: 0.10034859
INFO:root:At the start of the epoch: mem (CPU python)=43615.125MB; mem (CPU total)=43421.26171875MB
INFO:root:[   46] Training loss: 0.63214730, Validation loss: 0.63608515, Gradient norm: 0.10237817
INFO:root:At the start of the epoch: mem (CPU python)=43653.21875MB; mem (CPU total)=43459.4375MB
INFO:root:[   47] Training loss: 0.63139239, Validation loss: 0.63613288, Gradient norm: 0.11672551
INFO:root:At the start of the epoch: mem (CPU python)=43691.3125MB; mem (CPU total)=43497.11328125MB
INFO:root:[   48] Training loss: 0.63081448, Validation loss: 0.63417095, Gradient norm: 0.11176971
INFO:root:At the start of the epoch: mem (CPU python)=43729.41015625MB; mem (CPU total)=43535.3828125MB
INFO:root:[   49] Training loss: 0.63006724, Validation loss: 0.63382062, Gradient norm: 0.11190524
INFO:root:At the start of the epoch: mem (CPU python)=43767.50390625MB; mem (CPU total)=43573.515625MB
INFO:root:[   50] Training loss: 0.62949857, Validation loss: 0.63354616, Gradient norm: 0.12749284
INFO:root:At the start of the epoch: mem (CPU python)=43805.6015625MB; mem (CPU total)=43612.109375MB
INFO:root:[   51] Training loss: 0.62867184, Validation loss: 0.63270193, Gradient norm: 0.09514589
INFO:root:At the start of the epoch: mem (CPU python)=43843.6953125MB; mem (CPU total)=43651.2109375MB
INFO:root:[   52] Training loss: 0.62841153, Validation loss: 0.63278455, Gradient norm: 0.11169499
INFO:root:At the start of the epoch: mem (CPU python)=43881.79296875MB; mem (CPU total)=43689.109375MB
INFO:root:[   53] Training loss: 0.62784176, Validation loss: 0.63204843, Gradient norm: 0.11620552
INFO:root:At the start of the epoch: mem (CPU python)=43919.88671875MB; mem (CPU total)=43727.78125MB
INFO:root:[   54] Training loss: 0.62722528, Validation loss: 0.63114751, Gradient norm: 0.09948791
INFO:root:At the start of the epoch: mem (CPU python)=43957.98046875MB; mem (CPU total)=43765.3828125MB
INFO:root:[   55] Training loss: 0.62673686, Validation loss: 0.63210206, Gradient norm: 0.10395143
INFO:root:At the start of the epoch: mem (CPU python)=43996.07421875MB; mem (CPU total)=43803.24609375MB
INFO:root:[   56] Training loss: 0.62615952, Validation loss: 0.63067442, Gradient norm: 0.12460989
INFO:root:At the start of the epoch: mem (CPU python)=44034.171875MB; mem (CPU total)=43841.06640625MB
INFO:root:[   57] Training loss: 0.62590667, Validation loss: 0.63005260, Gradient norm: 0.09742488
INFO:root:At the start of the epoch: mem (CPU python)=44072.265625MB; mem (CPU total)=43879.125MB
INFO:root:[   58] Training loss: 0.62509546, Validation loss: 0.62955867, Gradient norm: 0.10356924
INFO:root:At the start of the epoch: mem (CPU python)=44110.36328125MB; mem (CPU total)=43917.515625MB
INFO:root:[   59] Training loss: 0.62472144, Validation loss: 0.62875432, Gradient norm: 0.11316759
INFO:root:At the start of the epoch: mem (CPU python)=44148.4609375MB; mem (CPU total)=43955.7890625MB
INFO:root:[   60] Training loss: 0.62430525, Validation loss: 0.62959266, Gradient norm: 0.10654978
INFO:root:At the start of the epoch: mem (CPU python)=44186.5546875MB; mem (CPU total)=43993.859375MB
INFO:root:[   61] Training loss: 0.62399259, Validation loss: 0.62842397, Gradient norm: 0.12167676
INFO:root:At the start of the epoch: mem (CPU python)=44224.6484375MB; mem (CPU total)=44031.91796875MB
INFO:root:[   62] Training loss: 0.62330338, Validation loss: 0.62844791, Gradient norm: 0.10217745
INFO:root:At the start of the epoch: mem (CPU python)=44262.74609375MB; mem (CPU total)=44070.0546875MB
INFO:root:[   63] Training loss: 0.62282182, Validation loss: 0.62827770, Gradient norm: 0.11792417
INFO:root:At the start of the epoch: mem (CPU python)=44300.84375MB; mem (CPU total)=44108.18359375MB
INFO:root:[   64] Training loss: 0.62248573, Validation loss: 0.62765626, Gradient norm: 0.12506796
INFO:root:At the start of the epoch: mem (CPU python)=44338.9375MB; mem (CPU total)=44146.81640625MB
INFO:root:[   65] Training loss: 0.62215249, Validation loss: 0.62772131, Gradient norm: 0.11930109
INFO:root:At the start of the epoch: mem (CPU python)=44377.03125MB; mem (CPU total)=44184.53515625MB
INFO:root:[   66] Training loss: 0.62178463, Validation loss: 0.62678366, Gradient norm: 0.11503090
INFO:root:At the start of the epoch: mem (CPU python)=44415.1328125MB; mem (CPU total)=44222.6796875MB
INFO:root:[   67] Training loss: 0.62135954, Validation loss: 0.62696757, Gradient norm: 0.11558948
INFO:root:At the start of the epoch: mem (CPU python)=44453.2265625MB; mem (CPU total)=44260.8125MB
INFO:root:[   68] Training loss: 0.62102312, Validation loss: 0.62638149, Gradient norm: 0.13369444
INFO:root:At the start of the epoch: mem (CPU python)=44491.3203125MB; mem (CPU total)=44298.98828125MB
INFO:root:[   69] Training loss: 0.62059016, Validation loss: 0.62651113, Gradient norm: 0.15294407
INFO:root:At the start of the epoch: mem (CPU python)=44529.41796875MB; mem (CPU total)=44337.57421875MB
INFO:root:[   70] Training loss: 0.62022691, Validation loss: 0.62589498, Gradient norm: 0.11541157
INFO:root:At the start of the epoch: mem (CPU python)=44567.51171875MB; mem (CPU total)=44376.1953125MB
INFO:root:[   71] Training loss: 0.61986488, Validation loss: 0.62516087, Gradient norm: 0.14299830
INFO:root:At the start of the epoch: mem (CPU python)=44605.60546875MB; mem (CPU total)=44413.9375MB
INFO:root:[   72] Training loss: 0.61957688, Validation loss: 0.62538511, Gradient norm: 0.13196997
INFO:root:At the start of the epoch: mem (CPU python)=44643.69921875MB; mem (CPU total)=44452.3125MB
INFO:root:[   73] Training loss: 0.61925302, Validation loss: 0.62444258, Gradient norm: 0.13412480
INFO:root:At the start of the epoch: mem (CPU python)=44681.796875MB; mem (CPU total)=44490.4765625MB
INFO:root:[   74] Training loss: 0.61887605, Validation loss: 0.62467043, Gradient norm: 0.15114260
INFO:root:At the start of the epoch: mem (CPU python)=44719.89453125MB; mem (CPU total)=44528.578125MB
INFO:root:[   75] Training loss: 0.61854217, Validation loss: 0.62448232, Gradient norm: 0.17643253
INFO:root:At the start of the epoch: mem (CPU python)=44757.98828125MB; mem (CPU total)=44567.234375MB
INFO:root:[   76] Training loss: 0.61800054, Validation loss: 0.62473401, Gradient norm: 0.13035954
INFO:root:At the start of the epoch: mem (CPU python)=44796.0859375MB; mem (CPU total)=44605.26171875MB
INFO:root:[   77] Training loss: 0.61798895, Validation loss: 0.62429713, Gradient norm: 0.14362058
INFO:root:At the start of the epoch: mem (CPU python)=44834.1796875MB; mem (CPU total)=44643.64453125MB
INFO:root:[   78] Training loss: 0.61769260, Validation loss: 0.62373000, Gradient norm: 0.14511468
INFO:root:At the start of the epoch: mem (CPU python)=44872.2734375MB; mem (CPU total)=44681.9921875MB
INFO:root:[   79] Training loss: 0.61724313, Validation loss: 0.62364544, Gradient norm: 0.15751143
INFO:root:At the start of the epoch: mem (CPU python)=44910.37109375MB; mem (CPU total)=44719.921875MB
INFO:root:[   80] Training loss: 0.61693187, Validation loss: 0.62299473, Gradient norm: 0.15018710
INFO:root:At the start of the epoch: mem (CPU python)=44948.46484375MB; mem (CPU total)=44758.30078125MB
INFO:root:[   81] Training loss: 0.61671118, Validation loss: 0.62338899, Gradient norm: 0.15798300
INFO:root:At the start of the epoch: mem (CPU python)=44986.55859375MB; mem (CPU total)=44796.1171875MB
INFO:root:[   82] Training loss: 0.61642042, Validation loss: 0.62328161, Gradient norm: 0.21182220
INFO:root:At the start of the epoch: mem (CPU python)=45024.65625MB; mem (CPU total)=44833.9375MB
INFO:root:[   83] Training loss: 0.61618867, Validation loss: 0.62284430, Gradient norm: 0.18532060
INFO:root:At the start of the epoch: mem (CPU python)=45062.75390625MB; mem (CPU total)=44872.03125MB
INFO:root:[   84] Training loss: 0.61593443, Validation loss: 0.62298170, Gradient norm: 0.20006542
INFO:root:At the start of the epoch: mem (CPU python)=45100.84765625MB; mem (CPU total)=44910.18359375MB
INFO:root:[   85] Training loss: 0.61562627, Validation loss: 0.62242122, Gradient norm: 0.18370673
INFO:root:At the start of the epoch: mem (CPU python)=45138.94140625MB; mem (CPU total)=44948.078125MB
INFO:root:[   86] Training loss: 0.61547552, Validation loss: 0.62177537, Gradient norm: 0.20493219
INFO:root:At the start of the epoch: mem (CPU python)=45177.0390625MB; mem (CPU total)=44986.16796875MB
INFO:root:[   87] Training loss: 0.61505663, Validation loss: 0.62227795, Gradient norm: 0.17251274
INFO:root:At the start of the epoch: mem (CPU python)=45215.1328125MB; mem (CPU total)=45024.4921875MB
INFO:root:[   88] Training loss: 0.61481575, Validation loss: 0.62282091, Gradient norm: 0.20128620
INFO:root:At the start of the epoch: mem (CPU python)=45253.2265625MB; mem (CPU total)=45063.0546875MB
INFO:root:[   89] Training loss: 0.61488208, Validation loss: 0.62192142, Gradient norm: 0.20739987
INFO:root:At the start of the epoch: mem (CPU python)=45291.3203125MB; mem (CPU total)=45101.39453125MB
INFO:root:[   90] Training loss: 0.61436543, Validation loss: 0.62186516, Gradient norm: 0.22604660
INFO:root:At the start of the epoch: mem (CPU python)=45329.41796875MB; mem (CPU total)=45139.27734375MB
INFO:root:[   91] Training loss: 0.61418869, Validation loss: 0.62252720, Gradient norm: 0.21548967
INFO:root:At the start of the epoch: mem (CPU python)=45367.515625MB; mem (CPU total)=45177.078125MB
INFO:root:[   92] Training loss: 0.61397741, Validation loss: 0.62129214, Gradient norm: 0.26620434
INFO:root:At the start of the epoch: mem (CPU python)=45405.609375MB; mem (CPU total)=45215.41015625MB
INFO:root:[   93] Training loss: 0.61376886, Validation loss: 0.62084122, Gradient norm: 0.25902061
INFO:root:At the start of the epoch: mem (CPU python)=45443.70703125MB; mem (CPU total)=45254.30078125MB
INFO:root:[   94] Training loss: 0.61351582, Validation loss: 0.62055714, Gradient norm: 0.24076974
INFO:root:At the start of the epoch: mem (CPU python)=45481.80078125MB; mem (CPU total)=45292.23046875MB
INFO:root:[   95] Training loss: 0.61329015, Validation loss: 0.62080081, Gradient norm: 0.23944983
INFO:root:At the start of the epoch: mem (CPU python)=45519.89453125MB; mem (CPU total)=45329.63671875MB
INFO:root:[   96] Training loss: 0.61293209, Validation loss: 0.62085557, Gradient norm: 0.23914917
INFO:root:At the start of the epoch: mem (CPU python)=45557.9921875MB; mem (CPU total)=45367.6953125MB
INFO:root:[   97] Training loss: 0.61281056, Validation loss: 0.62013426, Gradient norm: 0.25687209
INFO:root:At the start of the epoch: mem (CPU python)=45596.0859375MB; mem (CPU total)=45405.765625MB
INFO:root:[   98] Training loss: 0.61277233, Validation loss: 0.62038096, Gradient norm: 0.36156685
INFO:root:At the start of the epoch: mem (CPU python)=45634.1796875MB; mem (CPU total)=45443.82421875MB
INFO:root:[   99] Training loss: 0.61242834, Validation loss: 0.62010223, Gradient norm: 0.34800097
INFO:root:At the start of the epoch: mem (CPU python)=45672.2734375MB; mem (CPU total)=45483.5546875MB
INFO:root:[  100] Training loss: 0.61222809, Validation loss: 0.62047483, Gradient norm: 0.27768050
INFO:root:At the start of the epoch: mem (CPU python)=45710.375MB; mem (CPU total)=45521.828125MB
INFO:root:[  101] Training loss: 0.61194269, Validation loss: 0.62059732, Gradient norm: 0.32084085
INFO:root:At the start of the epoch: mem (CPU python)=45748.46875MB; mem (CPU total)=45559.34765625MB
INFO:root:[  102] Training loss: 0.61181904, Validation loss: 0.61963252, Gradient norm: 0.28870276
INFO:root:At the start of the epoch: mem (CPU python)=45786.5625MB; mem (CPU total)=45597.7109375MB
INFO:root:[  103] Training loss: 0.61166332, Validation loss: 0.61986123, Gradient norm: 0.30352469
INFO:root:At the start of the epoch: mem (CPU python)=45824.66015625MB; mem (CPU total)=45635.4296875MB
INFO:root:[  104] Training loss: 0.61152772, Validation loss: 0.62000070, Gradient norm: 0.38550344
INFO:root:At the start of the epoch: mem (CPU python)=45862.75390625MB; mem (CPU total)=45673.20703125MB
INFO:root:[  105] Training loss: 0.61137351, Validation loss: 0.61994426, Gradient norm: 0.35663630
INFO:root:At the start of the epoch: mem (CPU python)=45900.84765625MB; mem (CPU total)=45711.8125MB
INFO:root:[  106] Training loss: 0.61118558, Validation loss: 0.61966801, Gradient norm: 0.40015948
INFO:root:At the start of the epoch: mem (CPU python)=45938.9453125MB; mem (CPU total)=45750.14453125MB
INFO:root:[  107] Training loss: 0.61110558, Validation loss: 0.61969730, Gradient norm: 0.42540793
INFO:root:At the start of the epoch: mem (CPU python)=45977.04296875MB; mem (CPU total)=45788.26953125MB
INFO:root:[  108] Training loss: 0.61205954, Validation loss: 0.62111973, Gradient norm: 0.80808575
INFO:root:At the start of the epoch: mem (CPU python)=46015.13671875MB; mem (CPU total)=45826.1875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  109] Training loss: 0.61115281, Validation loss: 0.61937179, Gradient norm: 0.56953104
INFO:root:At the start of the epoch: mem (CPU python)=46053.23046875MB; mem (CPU total)=45864.0703125MB
INFO:root:[  110] Training loss: 0.60965399, Validation loss: 0.61918354, Gradient norm: 0.21254462
INFO:root:At the start of the epoch: mem (CPU python)=46091.328125MB; mem (CPU total)=45902.1015625MB
INFO:root:[  111] Training loss: 0.60963562, Validation loss: 0.61870182, Gradient norm: 0.27344951
INFO:root:At the start of the epoch: mem (CPU python)=46129.421875MB; mem (CPU total)=45941.76171875MB
INFO:root:[  112] Training loss: 0.60939908, Validation loss: 0.61775902, Gradient norm: 0.23250124
INFO:root:At the start of the epoch: mem (CPU python)=46167.515625MB; mem (CPU total)=45979.453125MB
INFO:root:[  113] Training loss: 0.60960315, Validation loss: 0.61850016, Gradient norm: 0.24745401
INFO:root:At the start of the epoch: mem (CPU python)=46205.61328125MB; mem (CPU total)=46017.55859375MB
INFO:root:[  114] Training loss: 0.60947013, Validation loss: 0.61836849, Gradient norm: 0.29859794
INFO:root:At the start of the epoch: mem (CPU python)=46243.7109375MB; mem (CPU total)=46055.5390625MB
INFO:root:[  115] Training loss: 0.60949184, Validation loss: 0.61837064, Gradient norm: 0.34147637
INFO:root:At the start of the epoch: mem (CPU python)=46281.80859375MB; mem (CPU total)=46093.61328125MB
INFO:root:[  116] Training loss: 0.60923606, Validation loss: 0.61924097, Gradient norm: 0.25451110
INFO:root:At the start of the epoch: mem (CPU python)=46319.90234375MB; mem (CPU total)=46131.99609375MB
INFO:root:[  117] Training loss: 0.60939048, Validation loss: 0.61827384, Gradient norm: 0.33188819
INFO:root:At the start of the epoch: mem (CPU python)=46358.0MB; mem (CPU total)=46170.375MB
INFO:root:[  118] Training loss: 0.60933481, Validation loss: 0.61858843, Gradient norm: 0.30356196
INFO:root:At the start of the epoch: mem (CPU python)=46396.09375MB; mem (CPU total)=46208.76171875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  119] Training loss: 0.60922833, Validation loss: 0.61818242, Gradient norm: 0.32620642
INFO:root:At the start of the epoch: mem (CPU python)=46434.1875MB; mem (CPU total)=46246.66015625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  120] Training loss: 0.60867676, Validation loss: 0.61889397, Gradient norm: 0.21819405
INFO:root:At the start of the epoch: mem (CPU python)=46472.28515625MB; mem (CPU total)=46284.54296875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  121] Training loss: 0.60834464, Validation loss: 0.61799011, Gradient norm: 0.20228477
INFO:root:At the start of the epoch: mem (CPU python)=46510.37890625MB; mem (CPU total)=46322.921875MB
INFO:root:[  122] Training loss: 0.60811806, Validation loss: 0.61708721, Gradient norm: 0.19224527
INFO:root:At the start of the epoch: mem (CPU python)=46548.47265625MB; mem (CPU total)=46361.08203125MB
INFO:root:[  123] Training loss: 0.60805347, Validation loss: 0.61795636, Gradient norm: 0.18108545
INFO:root:At the start of the epoch: mem (CPU python)=46586.5703125MB; mem (CPU total)=46402.9296875MB
INFO:root:[  124] Training loss: 0.60826237, Validation loss: 0.61777073, Gradient norm: 0.17112745
INFO:root:At the start of the epoch: mem (CPU python)=46624.66796875MB; mem (CPU total)=46440.47265625MB
INFO:root:[  125] Training loss: 0.60824341, Validation loss: 0.61775447, Gradient norm: 0.17951142
INFO:root:At the start of the epoch: mem (CPU python)=46662.76171875MB; mem (CPU total)=46478.3671875MB
INFO:root:[  126] Training loss: 0.60832299, Validation loss: 0.61761667, Gradient norm: 0.19034741
INFO:root:At the start of the epoch: mem (CPU python)=46700.85546875MB; mem (CPU total)=46516.20703125MB
INFO:root:[  127] Training loss: 0.60830752, Validation loss: 0.61774392, Gradient norm: 0.18776195
INFO:root:At the start of the epoch: mem (CPU python)=46738.953125MB; mem (CPU total)=46554.3359375MB
INFO:root:[  128] Training loss: 0.60815126, Validation loss: 0.61773261, Gradient norm: 0.18851117
INFO:root:At the start of the epoch: mem (CPU python)=46777.046875MB; mem (CPU total)=46592.7109375MB
INFO:root:[  129] Training loss: 0.60816523, Validation loss: 0.61781666, Gradient norm: 0.19553384
INFO:root:At the start of the epoch: mem (CPU python)=46815.140625MB; mem (CPU total)=46630.5625MB
INFO:root:[  130] Training loss: 0.60823295, Validation loss: 0.61811486, Gradient norm: 0.18957388
INFO:root:At the start of the epoch: mem (CPU python)=46853.23828125MB; mem (CPU total)=46668.6796875MB
INFO:root:[  131] Training loss: 0.60812039, Validation loss: 0.61833469, Gradient norm: 0.20240167
INFO:root:At the start of the epoch: mem (CPU python)=46891.3359375MB; mem (CPU total)=46706.59375MB
INFO:root:EP 131: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=46929.42578125MB; mem (CPU total)=46744.72265625MB
INFO:root:Training the model took 16873.557s.
INFO:root:Emptying the cuda cache took 0.318s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86328
INFO:root:EnergyScoreTrain: 0.60812
INFO:root:CRPSTrain: 0.54762
INFO:root:Gaussian NLLTrain: 4.82992
INFO:root:CoverageTrain: 0.76402
INFO:root:IntervalWidthTrain: 3.12911
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8772
INFO:root:EnergyScoreValidation: 0.61777
INFO:root:CRPSValidation: 0.55514
INFO:root:Gaussian NLLValidation: 4.84317
INFO:root:CoverageValidation: 0.76054
INFO:root:IntervalWidthValidation: 3.12995
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87866
INFO:root:EnergyScoreTest: 0.61878
INFO:root:CRPSTest: 0.55604
INFO:root:Gaussian NLLTest: 4.84186
INFO:root:CoverageTest: 0.75957
INFO:root:IntervalWidthTest: 3.12363
INFO:root:After validation: mem (CPU python)=46972.18359375MB; mem (CPU total)=46786.2109375MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=46972.18359375MB; mem (CPU total)=46785.94140625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 50331648
INFO:root:After setting up the model: mem (CPU python)=46972.7265625MB; mem (CPU total)=46786.43359375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=46972.7265625MB; mem (CPU total)=46786.66796875MB
INFO:root:[    1] Training loss: 0.76047712, Validation loss: 0.72313456, Gradient norm: 0.44482468
INFO:root:At the start of the epoch: mem (CPU python)=47010.86328125MB; mem (CPU total)=46826.53515625MB
INFO:root:[    2] Training loss: 0.72100450, Validation loss: 0.72051671, Gradient norm: 0.35552202
INFO:root:At the start of the epoch: mem (CPU python)=47048.9609375MB; mem (CPU total)=46864.6171875MB
INFO:root:[    3] Training loss: 0.71980935, Validation loss: 0.72032529, Gradient norm: 0.27059779
INFO:root:At the start of the epoch: mem (CPU python)=47087.05859375MB; mem (CPU total)=46902.93359375MB
INFO:root:[    4] Training loss: 0.71924606, Validation loss: 0.71946600, Gradient norm: 0.26865054
INFO:root:At the start of the epoch: mem (CPU python)=47125.15234375MB; mem (CPU total)=46940.78125MB
INFO:root:[    5] Training loss: 0.71870140, Validation loss: 0.71884314, Gradient norm: 0.28062106
INFO:root:At the start of the epoch: mem (CPU python)=47163.24609375MB; mem (CPU total)=46979.06640625MB
INFO:root:[    6] Training loss: 0.71776578, Validation loss: 0.71696071, Gradient norm: 0.28795236
INFO:root:At the start of the epoch: mem (CPU python)=47201.34375MB; mem (CPU total)=47017.23046875MB
INFO:root:[    7] Training loss: 0.71506871, Validation loss: 0.71350417, Gradient norm: 0.15528838
INFO:root:At the start of the epoch: mem (CPU python)=47239.44140625MB; mem (CPU total)=47055.35546875MB
INFO:root:[    8] Training loss: 0.70949199, Validation loss: 0.70672773, Gradient norm: 0.19198336
INFO:root:At the start of the epoch: mem (CPU python)=47277.53515625MB; mem (CPU total)=47093.703125MB
INFO:root:[    9] Training loss: 0.70320063, Validation loss: 0.70085784, Gradient norm: 0.19865721
INFO:root:At the start of the epoch: mem (CPU python)=47315.6328125MB; mem (CPU total)=47131.8125MB
INFO:root:[   10] Training loss: 0.69743619, Validation loss: 0.69481020, Gradient norm: 0.15744714
INFO:root:At the start of the epoch: mem (CPU python)=47353.7265625MB; mem (CPU total)=47170.8515625MB
INFO:root:[   11] Training loss: 0.69205413, Validation loss: 0.69074321, Gradient norm: 0.16369622
INFO:root:At the start of the epoch: mem (CPU python)=47391.8203125MB; mem (CPU total)=47208.765625MB
INFO:root:[   12] Training loss: 0.68722435, Validation loss: 0.68623820, Gradient norm: 0.15101388
INFO:root:At the start of the epoch: mem (CPU python)=47429.9140625MB; mem (CPU total)=47246.88671875MB
INFO:root:[   13] Training loss: 0.68281181, Validation loss: 0.68096367, Gradient norm: 0.15837685
INFO:root:At the start of the epoch: mem (CPU python)=47468.01171875MB; mem (CPU total)=47284.984375MB
INFO:root:[   14] Training loss: 0.67842316, Validation loss: 0.67749623, Gradient norm: 0.13858183
INFO:root:At the start of the epoch: mem (CPU python)=47506.10546875MB; mem (CPU total)=47323.12890625MB
INFO:root:[   15] Training loss: 0.67463381, Validation loss: 0.67512024, Gradient norm: 0.12878693
INFO:root:At the start of the epoch: mem (CPU python)=47544.19921875MB; mem (CPU total)=47361.23828125MB
INFO:root:[   16] Training loss: 0.67124640, Validation loss: 0.67168803, Gradient norm: 0.14975811
INFO:root:At the start of the epoch: mem (CPU python)=47582.296875MB; mem (CPU total)=47399.22265625MB
INFO:root:[   17] Training loss: 0.66824848, Validation loss: 0.66872382, Gradient norm: 0.14929267
INFO:root:At the start of the epoch: mem (CPU python)=47620.390625MB; mem (CPU total)=47437.0703125MB
INFO:root:[   18] Training loss: 0.66551417, Validation loss: 0.66599875, Gradient norm: 0.11996233
INFO:root:At the start of the epoch: mem (CPU python)=47658.48828125MB; mem (CPU total)=47475.69921875MB
INFO:root:[   19] Training loss: 0.66303824, Validation loss: 0.66347007, Gradient norm: 0.13362025
INFO:root:At the start of the epoch: mem (CPU python)=47696.5859375MB; mem (CPU total)=47514.0078125MB
INFO:root:[   20] Training loss: 0.66082679, Validation loss: 0.66154216, Gradient norm: 0.10927639
INFO:root:At the start of the epoch: mem (CPU python)=47734.6796875MB; mem (CPU total)=47552.0625MB
INFO:root:[   21] Training loss: 0.65875666, Validation loss: 0.65976049, Gradient norm: 0.13434556
INFO:root:At the start of the epoch: mem (CPU python)=47772.7734375MB; mem (CPU total)=47590.15234375MB
INFO:root:[   22] Training loss: 0.65694743, Validation loss: 0.65843600, Gradient norm: 0.12087161
INFO:root:At the start of the epoch: mem (CPU python)=47810.8671875MB; mem (CPU total)=47628.27734375MB
INFO:root:[   23] Training loss: 0.65508149, Validation loss: 0.65607136, Gradient norm: 0.15548451
INFO:root:At the start of the epoch: mem (CPU python)=47848.96484375MB; mem (CPU total)=47666.1171875MB
INFO:root:[   24] Training loss: 0.65342432, Validation loss: 0.65446624, Gradient norm: 0.13191799
INFO:root:At the start of the epoch: mem (CPU python)=47887.05859375MB; mem (CPU total)=47704.28125MB
INFO:root:[   25] Training loss: 0.65182545, Validation loss: 0.65297512, Gradient norm: 0.12319663
INFO:root:At the start of the epoch: mem (CPU python)=47925.15234375MB; mem (CPU total)=47742.5859375MB
INFO:root:[   26] Training loss: 0.65047043, Validation loss: 0.65207574, Gradient norm: 0.12209571
INFO:root:At the start of the epoch: mem (CPU python)=47963.25390625MB; mem (CPU total)=47780.71484375MB
INFO:root:[   27] Training loss: 0.64923762, Validation loss: 0.65187596, Gradient norm: 0.10948891
INFO:root:At the start of the epoch: mem (CPU python)=48001.34765625MB; mem (CPU total)=47818.5546875MB
INFO:root:[   28] Training loss: 0.64800478, Validation loss: 0.64961874, Gradient norm: 0.10744098
INFO:root:At the start of the epoch: mem (CPU python)=48039.44140625MB; mem (CPU total)=47856.65625MB
INFO:root:[   29] Training loss: 0.64687416, Validation loss: 0.64919648, Gradient norm: 0.10647587
INFO:root:At the start of the epoch: mem (CPU python)=48077.53515625MB; mem (CPU total)=47894.625MB
INFO:root:[   30] Training loss: 0.64568393, Validation loss: 0.64808137, Gradient norm: 0.13513822
INFO:root:At the start of the epoch: mem (CPU python)=48115.6328125MB; mem (CPU total)=47933.0234375MB
INFO:root:[   31] Training loss: 0.64466953, Validation loss: 0.64779759, Gradient norm: 0.13877190
INFO:root:At the start of the epoch: mem (CPU python)=48153.7265625MB; mem (CPU total)=47971.359375MB
INFO:root:[   32] Training loss: 0.64365081, Validation loss: 0.64723689, Gradient norm: 0.12876157
INFO:root:At the start of the epoch: mem (CPU python)=48191.8203125MB; mem (CPU total)=48008.9296875MB
INFO:root:[   33] Training loss: 0.64267015, Validation loss: 0.64582267, Gradient norm: 0.12635577
INFO:root:At the start of the epoch: mem (CPU python)=48229.921875MB; mem (CPU total)=48047.06640625MB
INFO:root:[   34] Training loss: 0.64175877, Validation loss: 0.64470331, Gradient norm: 0.16214388
INFO:root:At the start of the epoch: mem (CPU python)=48268.015625MB; mem (CPU total)=48085.23046875MB
INFO:root:[   35] Training loss: 0.64083853, Validation loss: 0.64436606, Gradient norm: 0.13825403
INFO:root:At the start of the epoch: mem (CPU python)=48306.109375MB; mem (CPU total)=48123.6171875MB
INFO:root:[   36] Training loss: 0.63988623, Validation loss: 0.64311788, Gradient norm: 0.13210899
INFO:root:At the start of the epoch: mem (CPU python)=48344.20703125MB; mem (CPU total)=48161.71875MB
INFO:root:[   37] Training loss: 0.63914102, Validation loss: 0.64233394, Gradient norm: 0.12141755
INFO:root:At the start of the epoch: mem (CPU python)=48382.30078125MB; mem (CPU total)=48199.47265625MB
INFO:root:[   38] Training loss: 0.63817001, Validation loss: 0.64149343, Gradient norm: 0.14537738
INFO:root:At the start of the epoch: mem (CPU python)=48420.39453125MB; mem (CPU total)=48237.88671875MB
INFO:root:[   39] Training loss: 0.63738722, Validation loss: 0.64119121, Gradient norm: 0.11592041
INFO:root:At the start of the epoch: mem (CPU python)=48458.4921875MB; mem (CPU total)=48276.00390625MB
INFO:root:[   40] Training loss: 0.63657488, Validation loss: 0.64009244, Gradient norm: 0.12835504
INFO:root:At the start of the epoch: mem (CPU python)=48496.58984375MB; mem (CPU total)=48314.09375MB
INFO:root:[   41] Training loss: 0.63597738, Validation loss: 0.64039242, Gradient norm: 0.13648207
INFO:root:At the start of the epoch: mem (CPU python)=48534.68359375MB; mem (CPU total)=48352.5MB
INFO:root:[   42] Training loss: 0.63520106, Validation loss: 0.63885265, Gradient norm: 0.15932968
INFO:root:At the start of the epoch: mem (CPU python)=48572.7734375MB; mem (CPU total)=48390.140625MB
INFO:root:[   43] Training loss: 0.63432321, Validation loss: 0.63866397, Gradient norm: 0.15417935
INFO:root:At the start of the epoch: mem (CPU python)=48610.875MB; mem (CPU total)=48429.00390625MB
INFO:root:[   44] Training loss: 0.63359505, Validation loss: 0.63800743, Gradient norm: 0.11789683
INFO:root:At the start of the epoch: mem (CPU python)=48648.96875MB; mem (CPU total)=48467.109375MB
INFO:root:[   45] Training loss: 0.63282648, Validation loss: 0.63760365, Gradient norm: 0.12803746
INFO:root:At the start of the epoch: mem (CPU python)=48687.0625MB; mem (CPU total)=48505.4375MB
INFO:root:[   46] Training loss: 0.63224095, Validation loss: 0.63707186, Gradient norm: 0.13269897
INFO:root:At the start of the epoch: mem (CPU python)=48725.15625MB; mem (CPU total)=48543.3046875MB
INFO:root:[   47] Training loss: 0.63143127, Validation loss: 0.63611667, Gradient norm: 0.11648931
INFO:root:At the start of the epoch: mem (CPU python)=48763.2578125MB; mem (CPU total)=48584.00390625MB
INFO:root:[   48] Training loss: 0.63084415, Validation loss: 0.63531750, Gradient norm: 0.13298961
INFO:root:At the start of the epoch: mem (CPU python)=48801.3515625MB; mem (CPU total)=48622.58984375MB
INFO:root:[   49] Training loss: 0.63012799, Validation loss: 0.63536994, Gradient norm: 0.14190994
INFO:root:At the start of the epoch: mem (CPU python)=48839.4453125MB; mem (CPU total)=48660.44921875MB
INFO:root:[   50] Training loss: 0.62962423, Validation loss: 0.63461153, Gradient norm: 0.17929048
INFO:root:At the start of the epoch: mem (CPU python)=48877.546875MB; mem (CPU total)=48698.76953125MB
INFO:root:[   51] Training loss: 0.62887367, Validation loss: 0.63481934, Gradient norm: 0.14135673
INFO:root:At the start of the epoch: mem (CPU python)=48915.640625MB; mem (CPU total)=48736.8125MB
INFO:root:[   52] Training loss: 0.62841560, Validation loss: 0.63384202, Gradient norm: 0.15483656
INFO:root:At the start of the epoch: mem (CPU python)=48953.734375MB; mem (CPU total)=48774.44140625MB
INFO:root:[   53] Training loss: 0.62773207, Validation loss: 0.63342617, Gradient norm: 0.15837081
INFO:root:At the start of the epoch: mem (CPU python)=48991.83203125MB; mem (CPU total)=48812.3359375MB
INFO:root:[   54] Training loss: 0.62723071, Validation loss: 0.63210541, Gradient norm: 0.13337595
INFO:root:At the start of the epoch: mem (CPU python)=49029.92578125MB; mem (CPU total)=48850.453125MB
INFO:root:[   55] Training loss: 0.62659328, Validation loss: 0.63243086, Gradient norm: 0.16698263
INFO:root:At the start of the epoch: mem (CPU python)=49068.01953125MB; mem (CPU total)=48888.6796875MB
INFO:root:[   56] Training loss: 0.62597966, Validation loss: 0.63223539, Gradient norm: 0.15483329
INFO:root:At the start of the epoch: mem (CPU python)=49106.11328125MB; mem (CPU total)=48926.1640625MB
INFO:root:[   57] Training loss: 0.62552638, Validation loss: 0.63140593, Gradient norm: 0.16279497
INFO:root:At the start of the epoch: mem (CPU python)=49144.2109375MB; mem (CPU total)=48964.48046875MB
INFO:root:[   58] Training loss: 0.62508157, Validation loss: 0.63040418, Gradient norm: 0.13213657
INFO:root:At the start of the epoch: mem (CPU python)=49182.3046875MB; mem (CPU total)=49002.3515625MB
INFO:root:[   59] Training loss: 0.62439936, Validation loss: 0.63086451, Gradient norm: 0.18911052
INFO:root:At the start of the epoch: mem (CPU python)=49220.40234375MB; mem (CPU total)=49040.3984375MB
INFO:root:[   60] Training loss: 0.62407943, Validation loss: 0.62991717, Gradient norm: 0.14450856
INFO:root:At the start of the epoch: mem (CPU python)=49258.5MB; mem (CPU total)=49078.37890625MB
INFO:root:[   61] Training loss: 0.62350145, Validation loss: 0.62969808, Gradient norm: 0.15783319
INFO:root:At the start of the epoch: mem (CPU python)=49296.59375MB; mem (CPU total)=49116.484375MB
INFO:root:[   62] Training loss: 0.62299510, Validation loss: 0.62950739, Gradient norm: 0.15722769
INFO:root:At the start of the epoch: mem (CPU python)=49334.6875MB; mem (CPU total)=49155.08203125MB
INFO:root:[   63] Training loss: 0.62262528, Validation loss: 0.63002094, Gradient norm: 0.15299881
INFO:root:At the start of the epoch: mem (CPU python)=49372.78125MB; mem (CPU total)=49192.44140625MB
INFO:root:[   64] Training loss: 0.62209670, Validation loss: 0.62850752, Gradient norm: 0.17619920
INFO:root:At the start of the epoch: mem (CPU python)=49410.8828125MB; mem (CPU total)=49230.53515625MB
INFO:root:[   65] Training loss: 0.62146757, Validation loss: 0.62875123, Gradient norm: 0.15192005
INFO:root:At the start of the epoch: mem (CPU python)=49448.9765625MB; mem (CPU total)=49268.73828125MB
INFO:root:[   66] Training loss: 0.62109060, Validation loss: 0.62784003, Gradient norm: 0.14367324
INFO:root:At the start of the epoch: mem (CPU python)=49487.0703125MB; mem (CPU total)=49306.80859375MB
INFO:root:[   67] Training loss: 0.62083010, Validation loss: 0.62750707, Gradient norm: 0.15666597
INFO:root:At the start of the epoch: mem (CPU python)=49525.16796875MB; mem (CPU total)=49344.87109375MB
INFO:root:[   68] Training loss: 0.62041056, Validation loss: 0.62797260, Gradient norm: 0.22110609
INFO:root:At the start of the epoch: mem (CPU python)=49563.26171875MB; mem (CPU total)=49382.609375MB
INFO:root:[   69] Training loss: 0.61988685, Validation loss: 0.62710453, Gradient norm: 0.18751616
INFO:root:At the start of the epoch: mem (CPU python)=49601.35546875MB; mem (CPU total)=49420.984375MB
INFO:root:[   70] Training loss: 0.61951292, Validation loss: 0.62677819, Gradient norm: 0.20105082
INFO:root:At the start of the epoch: mem (CPU python)=49639.453125MB; mem (CPU total)=49459.5859375MB
INFO:root:[   71] Training loss: 0.61906707, Validation loss: 0.62664939, Gradient norm: 0.15469135
INFO:root:At the start of the epoch: mem (CPU python)=49677.546875MB; mem (CPU total)=49497.6875MB
INFO:root:[   72] Training loss: 0.61865783, Validation loss: 0.62636868, Gradient norm: 0.19033541
INFO:root:At the start of the epoch: mem (CPU python)=49715.640625MB; mem (CPU total)=49536.0546875MB
INFO:root:[   73] Training loss: 0.61830673, Validation loss: 0.62584657, Gradient norm: 0.19346639
INFO:root:At the start of the epoch: mem (CPU python)=49753.73828125MB; mem (CPU total)=49573.8671875MB
INFO:root:[   74] Training loss: 0.61785152, Validation loss: 0.62566491, Gradient norm: 0.18544375
INFO:root:At the start of the epoch: mem (CPU python)=49791.8359375MB; mem (CPU total)=49611.62890625MB
INFO:root:[   75] Training loss: 0.61753164, Validation loss: 0.62623820, Gradient norm: 0.17732097
INFO:root:At the start of the epoch: mem (CPU python)=49829.9296875MB; mem (CPU total)=49650.01953125MB
INFO:root:[   76] Training loss: 0.61712325, Validation loss: 0.62543370, Gradient norm: 0.21713499
INFO:root:At the start of the epoch: mem (CPU python)=49868.0234375MB; mem (CPU total)=49688.41015625MB
INFO:root:[   77] Training loss: 0.61677262, Validation loss: 0.62544282, Gradient norm: 0.18431112
INFO:root:At the start of the epoch: mem (CPU python)=49906.12109375MB; mem (CPU total)=49726.33203125MB
INFO:root:[   78] Training loss: 0.61645326, Validation loss: 0.62498147, Gradient norm: 0.17947742
INFO:root:At the start of the epoch: mem (CPU python)=49944.21875MB; mem (CPU total)=49764.171875MB
INFO:root:[   79] Training loss: 0.61606705, Validation loss: 0.62494103, Gradient norm: 0.18852342
INFO:root:At the start of the epoch: mem (CPU python)=49982.30859375MB; mem (CPU total)=49802.27734375MB
INFO:root:[   80] Training loss: 0.61559162, Validation loss: 0.62464757, Gradient norm: 0.22532361
INFO:root:At the start of the epoch: mem (CPU python)=50020.40234375MB; mem (CPU total)=49840.4140625MB
INFO:root:[   81] Training loss: 0.61530867, Validation loss: 0.62384118, Gradient norm: 0.17434649
INFO:root:At the start of the epoch: mem (CPU python)=50058.5MB; mem (CPU total)=49878.75MB
INFO:root:[   82] Training loss: 0.61497192, Validation loss: 0.62417219, Gradient norm: 0.19910712
INFO:root:At the start of the epoch: mem (CPU python)=50096.59375MB; mem (CPU total)=49916.625MB
INFO:root:[   83] Training loss: 0.61481304, Validation loss: 0.62336776, Gradient norm: 0.24638324
INFO:root:At the start of the epoch: mem (CPU python)=50134.69140625MB; mem (CPU total)=49955.09765625MB
INFO:root:[   84] Training loss: 0.61424074, Validation loss: 0.62333782, Gradient norm: 0.19483642
INFO:root:At the start of the epoch: mem (CPU python)=50172.7890625MB; mem (CPU total)=49993.45703125MB
INFO:root:[   85] Training loss: 0.61396028, Validation loss: 0.62301191, Gradient norm: 0.16669454
INFO:root:At the start of the epoch: mem (CPU python)=50210.8828125MB; mem (CPU total)=50031.83203125MB
INFO:root:[   86] Training loss: 0.61378834, Validation loss: 0.62253402, Gradient norm: 0.21590576
INFO:root:At the start of the epoch: mem (CPU python)=50248.9765625MB; mem (CPU total)=50069.91796875MB
INFO:root:[   87] Training loss: 0.61346505, Validation loss: 0.62271423, Gradient norm: 0.20554043
INFO:root:At the start of the epoch: mem (CPU python)=50287.07421875MB; mem (CPU total)=50108.02734375MB
INFO:root:[   88] Training loss: 0.61304994, Validation loss: 0.62224269, Gradient norm: 0.21925745
INFO:root:At the start of the epoch: mem (CPU python)=50325.16796875MB; mem (CPU total)=50146.0625MB
INFO:root:[   89] Training loss: 0.61276167, Validation loss: 0.62213732, Gradient norm: 0.21656647
INFO:root:At the start of the epoch: mem (CPU python)=50363.26171875MB; mem (CPU total)=50184.6484375MB
INFO:root:[   90] Training loss: 0.61258381, Validation loss: 0.62253414, Gradient norm: 0.28523213
INFO:root:At the start of the epoch: mem (CPU python)=50401.35546875MB; mem (CPU total)=50222.234375MB
INFO:root:[   91] Training loss: 0.61223926, Validation loss: 0.62220076, Gradient norm: 0.22632651
INFO:root:At the start of the epoch: mem (CPU python)=50439.45703125MB; mem (CPU total)=50260.046875MB
INFO:root:[   92] Training loss: 0.61203784, Validation loss: 0.62210504, Gradient norm: 0.25269705
INFO:root:At the start of the epoch: mem (CPU python)=50477.5546875MB; mem (CPU total)=50298.6484375MB
INFO:root:[   93] Training loss: 0.61166784, Validation loss: 0.62114799, Gradient norm: 0.22636623
INFO:root:At the start of the epoch: mem (CPU python)=50515.6484375MB; mem (CPU total)=50336.7578125MB
INFO:root:[   94] Training loss: 0.61127585, Validation loss: 0.62178504, Gradient norm: 0.25782937
INFO:root:At the start of the epoch: mem (CPU python)=50553.74609375MB; mem (CPU total)=50374.6953125MB
INFO:root:[   95] Training loss: 0.61122906, Validation loss: 0.62241528, Gradient norm: 0.26439579
INFO:root:At the start of the epoch: mem (CPU python)=50591.83984375MB; mem (CPU total)=50412.76171875MB
INFO:root:[   96] Training loss: 0.61084567, Validation loss: 0.62148813, Gradient norm: 0.24486811
INFO:root:At the start of the epoch: mem (CPU python)=50629.93359375MB; mem (CPU total)=50455.9296875MB
INFO:root:[   97] Training loss: 0.61062406, Validation loss: 0.62140245, Gradient norm: 0.25318214
INFO:root:At the start of the epoch: mem (CPU python)=50668.02734375MB; mem (CPU total)=50493.77734375MB
INFO:root:[   98] Training loss: 0.61042088, Validation loss: 0.62120942, Gradient norm: 0.31963267
INFO:root:At the start of the epoch: mem (CPU python)=50706.125MB; mem (CPU total)=50531.19921875MB
INFO:root:[   99] Training loss: 0.61002462, Validation loss: 0.62187340, Gradient norm: 0.24629026
INFO:root:At the start of the epoch: mem (CPU python)=50744.21875MB; mem (CPU total)=50569.10546875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  100] Training loss: 0.60986211, Validation loss: 0.62066925, Gradient norm: 0.28687663
INFO:root:At the start of the epoch: mem (CPU python)=50782.31640625MB; mem (CPU total)=50606.77734375MB
INFO:root:[  101] Training loss: 0.60875324, Validation loss: 0.62025659, Gradient norm: 0.16246916
INFO:root:At the start of the epoch: mem (CPU python)=50820.4140625MB; mem (CPU total)=50644.9140625MB
INFO:root:[  102] Training loss: 0.60851170, Validation loss: 0.62072843, Gradient norm: 0.18877203
INFO:root:At the start of the epoch: mem (CPU python)=50858.5078125MB; mem (CPU total)=50683.2734375MB
INFO:root:[  103] Training loss: 0.60842046, Validation loss: 0.61998078, Gradient norm: 0.18339374
INFO:root:At the start of the epoch: mem (CPU python)=50896.6015625MB; mem (CPU total)=50720.609375MB
INFO:root:[  104] Training loss: 0.60829715, Validation loss: 0.61918132, Gradient norm: 0.15967465
INFO:root:At the start of the epoch: mem (CPU python)=50934.69921875MB; mem (CPU total)=50758.16015625MB
INFO:root:[  105] Training loss: 0.60810669, Validation loss: 0.62003450, Gradient norm: 0.15579047
INFO:root:At the start of the epoch: mem (CPU python)=50972.79296875MB; mem (CPU total)=50796.28515625MB
INFO:root:[  106] Training loss: 0.60799037, Validation loss: 0.61979911, Gradient norm: 0.19450526
INFO:root:At the start of the epoch: mem (CPU python)=51010.88671875MB; mem (CPU total)=50834.5703125MB
INFO:root:[  107] Training loss: 0.60793464, Validation loss: 0.62005951, Gradient norm: 0.19595458
INFO:root:At the start of the epoch: mem (CPU python)=51048.984375MB; mem (CPU total)=50872.4609375MB
INFO:root:[  108] Training loss: 0.60780834, Validation loss: 0.61950891, Gradient norm: 0.18968836
INFO:root:At the start of the epoch: mem (CPU python)=51087.08203125MB; mem (CPU total)=50910.078125MB
INFO:root:[  109] Training loss: 0.60760902, Validation loss: 0.61966007, Gradient norm: 0.22318629
INFO:root:At the start of the epoch: mem (CPU python)=51125.17578125MB; mem (CPU total)=50948.44140625MB
INFO:root:[  110] Training loss: 0.60749087, Validation loss: 0.61992011, Gradient norm: 0.23239065
INFO:root:At the start of the epoch: mem (CPU python)=51163.26953125MB; mem (CPU total)=50986.76953125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  111] Training loss: 0.60730442, Validation loss: 0.62028385, Gradient norm: 0.20492930
INFO:root:At the start of the epoch: mem (CPU python)=51201.3671875MB; mem (CPU total)=51025.375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  112] Training loss: 0.60679524, Validation loss: 0.61998656, Gradient norm: 0.14180875
INFO:root:At the start of the epoch: mem (CPU python)=51239.4609375MB; mem (CPU total)=51063.40234375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  113] Training loss: 0.60636890, Validation loss: 0.62013783, Gradient norm: 0.13050273
INFO:root:At the start of the epoch: mem (CPU python)=51277.5546875MB; mem (CPU total)=51101.6953125MB
INFO:root:EP 113: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=51315.6484375MB; mem (CPU total)=51139.625MB
INFO:root:Training the model took 15410.135s.
INFO:root:Emptying the cuda cache took 0.315s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86239
INFO:root:EnergyScoreTrain: 0.60747
INFO:root:CRPSTrain: 0.54208
INFO:root:Gaussian NLLTrain: 4.70397
INFO:root:CoverageTrain: 0.77589
INFO:root:IntervalWidthTrain: 3.13868
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88057
INFO:root:EnergyScoreValidation: 0.62013
INFO:root:CRPSValidation: 0.55215
INFO:root:Gaussian NLLValidation: 4.75536
INFO:root:CoverageValidation: 0.77005
INFO:root:IntervalWidthValidation: 3.13182
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88166
INFO:root:EnergyScoreTest: 0.6209
INFO:root:CRPSTest: 0.55286
INFO:root:Gaussian NLLTest: 4.756
INFO:root:CoverageTest: 0.76957
INFO:root:IntervalWidthTest: 3.12954
INFO:root:After validation: mem (CPU python)=51358.77734375MB; mem (CPU total)=51181.90234375MB
