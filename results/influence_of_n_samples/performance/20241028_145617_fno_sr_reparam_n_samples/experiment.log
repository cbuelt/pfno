INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=578.93359375MB; mem (CPU total)=974.0859375MB
INFO:root:############### Starting experiment with config file ks/fno_sr_reparam_n_samples.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12458.51953125MB; mem (CPU total)=982.97265625MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=12458.51953125MB; mem (CPU total)=982.578125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12458.51953125MB; mem (CPU total)=2173.62109375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=2186.45703125MB
INFO:root:[    1] Training loss: 0.72481095, Validation loss: 0.72081184, Gradient norm: 0.01803614
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3375.94921875MB
INFO:root:[    2] Training loss: 0.71990365, Validation loss: 0.71934986, Gradient norm: 0.00559703
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3434.09375MB
INFO:root:[    3] Training loss: 0.71836176, Validation loss: 0.71620294, Gradient norm: 0.00660831
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3472.2734375MB
INFO:root:[    4] Training loss: 0.71243592, Validation loss: 0.70631936, Gradient norm: 0.01454360
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3510.09765625MB
INFO:root:[    5] Training loss: 0.70510312, Validation loss: 0.69874404, Gradient norm: 0.02171397
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3548.26171875MB
INFO:root:[    6] Training loss: 0.69919346, Validation loss: 0.69222360, Gradient norm: 0.02808872
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3586.421875MB
INFO:root:[    7] Training loss: 0.69334318, Validation loss: 0.68518014, Gradient norm: 0.02820614
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3624.57421875MB
INFO:root:[    8] Training loss: 0.68776369, Validation loss: 0.67990183, Gradient norm: 0.02860836
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3662.95703125MB
INFO:root:[    9] Training loss: 0.68256516, Validation loss: 0.67339690, Gradient norm: 0.03532453
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3701.09765625MB
INFO:root:[   10] Training loss: 0.67815569, Validation loss: 0.66906243, Gradient norm: 0.03271539
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3739.046875MB
INFO:root:[   11] Training loss: 0.67440231, Validation loss: 0.66493747, Gradient norm: 0.03540130
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3776.7890625MB
INFO:root:[   12] Training loss: 0.67142373, Validation loss: 0.66133479, Gradient norm: 0.03390181
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3814.98828125MB
INFO:root:[   13] Training loss: 0.66860618, Validation loss: 0.65910058, Gradient norm: 0.03179628
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3854.25390625MB
INFO:root:[   14] Training loss: 0.66656999, Validation loss: 0.65614724, Gradient norm: 0.03382774
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3898.5390625MB
INFO:root:[   15] Training loss: 0.66436805, Validation loss: 0.65380587, Gradient norm: 0.03847575
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3937.05859375MB
INFO:root:[   16] Training loss: 0.66256620, Validation loss: 0.65108328, Gradient norm: 0.03710779
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=3974.9609375MB
INFO:root:[   17] Training loss: 0.66076710, Validation loss: 0.65114672, Gradient norm: 0.03830227
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4013.109375MB
INFO:root:[   18] Training loss: 0.65929534, Validation loss: 0.64863789, Gradient norm: 0.03760104
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4051.5MB
INFO:root:[   19] Training loss: 0.65770512, Validation loss: 0.64724349, Gradient norm: 0.03706579
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4089.203125MB
INFO:root:[   20] Training loss: 0.65667102, Validation loss: 0.64604604, Gradient norm: 0.04184165
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4127.18359375MB
INFO:root:[   21] Training loss: 0.65527590, Validation loss: 0.64534235, Gradient norm: 0.03976216
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4165.24609375MB
INFO:root:[   22] Training loss: 0.65415095, Validation loss: 0.64251269, Gradient norm: 0.03644923
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4203.25MB
INFO:root:[   23] Training loss: 0.65301761, Validation loss: 0.64273856, Gradient norm: 0.03886098
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4241.6484375MB
INFO:root:[   24] Training loss: 0.65179318, Validation loss: 0.64135790, Gradient norm: 0.04101143
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4279.62109375MB
INFO:root:[   25] Training loss: 0.65096703, Validation loss: 0.64014718, Gradient norm: 0.04653450
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4318.1328125MB
INFO:root:[   26] Training loss: 0.64993428, Validation loss: 0.63920301, Gradient norm: 0.04228286
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4356.46875MB
INFO:root:[   27] Training loss: 0.64903900, Validation loss: 0.63901132, Gradient norm: 0.04543378
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4394.24609375MB
INFO:root:[   28] Training loss: 0.64807027, Validation loss: 0.63772046, Gradient norm: 0.04489187
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4432.859375MB
INFO:root:[   29] Training loss: 0.64698929, Validation loss: 0.63550552, Gradient norm: 0.04687455
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4470.91015625MB
INFO:root:[   30] Training loss: 0.64626526, Validation loss: 0.63656508, Gradient norm: 0.05053369
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4508.87890625MB
INFO:root:[   31] Training loss: 0.64542820, Validation loss: 0.63456079, Gradient norm: 0.04706155
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4553.59765625MB
INFO:root:[   32] Training loss: 0.64468713, Validation loss: 0.63399946, Gradient norm: 0.04567933
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4578.0546875MB
INFO:root:[   33] Training loss: 0.64385205, Validation loss: 0.63349110, Gradient norm: 0.04578468
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4616.2421875MB
INFO:root:[   34] Training loss: 0.64307581, Validation loss: 0.63236840, Gradient norm: 0.04595410
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4655.3359375MB
INFO:root:[   35] Training loss: 0.64269699, Validation loss: 0.63344301, Gradient norm: 0.05450110
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4693.51953125MB
INFO:root:[   36] Training loss: 0.64200098, Validation loss: 0.63198446, Gradient norm: 0.04728246
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4731.87109375MB
INFO:root:[   37] Training loss: 0.64127088, Validation loss: 0.63167758, Gradient norm: 0.05313021
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4770.921875MB
INFO:root:[   38] Training loss: 0.64061740, Validation loss: 0.63025188, Gradient norm: 0.05529987
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4811.1640625MB
INFO:root:[   39] Training loss: 0.63999267, Validation loss: 0.62943543, Gradient norm: 0.05361253
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4852.61328125MB
INFO:root:[   40] Training loss: 0.63936903, Validation loss: 0.62992838, Gradient norm: 0.04607669
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4890.76953125MB
INFO:root:[   41] Training loss: 0.63878834, Validation loss: 0.62909927, Gradient norm: 0.05262741
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4928.4375MB
INFO:root:[   42] Training loss: 0.63826178, Validation loss: 0.62774789, Gradient norm: 0.05126650
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=4966.359375MB
INFO:root:[   43] Training loss: 0.63745021, Validation loss: 0.62727311, Gradient norm: 0.04985208
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5017.21875MB
INFO:root:[   44] Training loss: 0.63712160, Validation loss: 0.62722199, Gradient norm: 0.04964351
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5038.23828125MB
INFO:root:[   45] Training loss: 0.63687536, Validation loss: 0.62777146, Gradient norm: 0.05162877
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5076.640625MB
INFO:root:[   46] Training loss: 0.63609561, Validation loss: 0.62616744, Gradient norm: 0.05113396
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5115.23828125MB
INFO:root:[   47] Training loss: 0.63567142, Validation loss: 0.62593080, Gradient norm: 0.05065620
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5152.796875MB
INFO:root:[   48] Training loss: 0.63541579, Validation loss: 0.62536783, Gradient norm: 0.04956146
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5197.203125MB
INFO:root:[   49] Training loss: 0.63488033, Validation loss: 0.62503777, Gradient norm: 0.05308097
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5235.109375MB
INFO:root:[   50] Training loss: 0.63444307, Validation loss: 0.62430531, Gradient norm: 0.05424469
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5273.26171875MB
INFO:root:[   51] Training loss: 0.63377773, Validation loss: 0.62400559, Gradient norm: 0.05676472
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5311.66796875MB
INFO:root:[   52] Training loss: 0.63350915, Validation loss: 0.62351953, Gradient norm: 0.05137292
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5349.78125MB
INFO:root:[   53] Training loss: 0.63320721, Validation loss: 0.62302088, Gradient norm: 0.05416278
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5388.18359375MB
INFO:root:[   54] Training loss: 0.63274458, Validation loss: 0.62304583, Gradient norm: 0.05172817
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5426.390625MB
INFO:root:[   55] Training loss: 0.63245325, Validation loss: 0.62309616, Gradient norm: 0.05417595
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5464.52734375MB
INFO:root:[   56] Training loss: 0.63214899, Validation loss: 0.62294626, Gradient norm: 0.05632374
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5510.34765625MB
INFO:root:[   57] Training loss: 0.63151339, Validation loss: 0.62153993, Gradient norm: 0.05454385
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5548.17578125MB
INFO:root:[   58] Training loss: 0.63125204, Validation loss: 0.62224459, Gradient norm: 0.05211868
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5576.87890625MB
INFO:root:[   59] Training loss: 0.63106756, Validation loss: 0.62047276, Gradient norm: 0.05943714
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5614.7890625MB
INFO:root:[   60] Training loss: 0.63021173, Validation loss: 0.62194632, Gradient norm: 0.04887417
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5653.0078125MB
INFO:root:[   61] Training loss: 0.63005051, Validation loss: 0.62191131, Gradient norm: 0.05371633
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5690.91015625MB
INFO:root:[   62] Training loss: 0.63003673, Validation loss: 0.62127651, Gradient norm: 0.05893320
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5729.5390625MB
INFO:root:[   63] Training loss: 0.62948426, Validation loss: 0.62128748, Gradient norm: 0.05254138
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5767.53515625MB
INFO:root:[   64] Training loss: 0.62951815, Validation loss: 0.62054278, Gradient norm: 0.06010980
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5805.7421875MB
INFO:root:[   65] Training loss: 0.62908549, Validation loss: 0.62116650, Gradient norm: 0.05658849
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5843.890625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   66] Training loss: 0.62868156, Validation loss: 0.62018015, Gradient norm: 0.06463660
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5882.62109375MB
INFO:root:[   67] Training loss: 0.62764017, Validation loss: 0.61869887, Gradient norm: 0.05164413
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5920.71484375MB
INFO:root:[   68] Training loss: 0.62728965, Validation loss: 0.61875560, Gradient norm: 0.05017469
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5958.87890625MB
INFO:root:[   69] Training loss: 0.62711561, Validation loss: 0.61912514, Gradient norm: 0.05074996
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=5996.6875MB
INFO:root:[   70] Training loss: 0.62701978, Validation loss: 0.61791468, Gradient norm: 0.04817746
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6034.33984375MB
INFO:root:[   71] Training loss: 0.62666560, Validation loss: 0.61783842, Gradient norm: 0.05227175
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6071.9921875MB
INFO:root:[   72] Training loss: 0.62689152, Validation loss: 0.61775122, Gradient norm: 0.05402107
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6109.890625MB
INFO:root:[   73] Training loss: 0.62667298, Validation loss: 0.61779841, Gradient norm: 0.06021032
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6147.77734375MB
INFO:root:[   74] Training loss: 0.62647506, Validation loss: 0.61849727, Gradient norm: 0.05127144
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6185.66796875MB
INFO:root:[   75] Training loss: 0.62636483, Validation loss: 0.61753398, Gradient norm: 0.04906164
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6223.55859375MB
INFO:root:[   76] Training loss: 0.62602441, Validation loss: 0.61705801, Gradient norm: 0.04919084
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6261.765625MB
INFO:root:[   77] Training loss: 0.62586883, Validation loss: 0.61734913, Gradient norm: 0.05138072
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6299.91015625MB
INFO:root:[   78] Training loss: 0.62584427, Validation loss: 0.61733007, Gradient norm: 0.04965094
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6337.890625MB
INFO:root:[   79] Training loss: 0.62578838, Validation loss: 0.61759472, Gradient norm: 0.04965501
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6376.42578125MB
INFO:root:[   80] Training loss: 0.62549016, Validation loss: 0.61732262, Gradient norm: 0.05159556
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6414.3203125MB
INFO:root:[   81] Training loss: 0.62562618, Validation loss: 0.61680314, Gradient norm: 0.05420529
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6452.46484375MB
INFO:root:[   82] Training loss: 0.62509846, Validation loss: 0.61719721, Gradient norm: 0.05020839
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6490.84765625MB
INFO:root:[   83] Training loss: 0.62530225, Validation loss: 0.61709075, Gradient norm: 0.05612043
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6528.98828125MB
INFO:root:[   84] Training loss: 0.62484306, Validation loss: 0.61668078, Gradient norm: 0.05291447
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6567.34765625MB
INFO:root:[   85] Training loss: 0.62496910, Validation loss: 0.61611374, Gradient norm: 0.05287229
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6605.5234375MB
INFO:root:[   86] Training loss: 0.62469692, Validation loss: 0.61652020, Gradient norm: 0.05479708
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6643.66796875MB
INFO:root:[   87] Training loss: 0.62458899, Validation loss: 0.61633730, Gradient norm: 0.05500582
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6681.8125MB
INFO:root:[   88] Training loss: 0.62440196, Validation loss: 0.61695849, Gradient norm: 0.05604920
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6719.95703125MB
INFO:root:[   89] Training loss: 0.62444008, Validation loss: 0.61622673, Gradient norm: 0.05525400
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6757.35546875MB
INFO:root:[   90] Training loss: 0.62423471, Validation loss: 0.61628545, Gradient norm: 0.05375169
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6795.23046875MB
INFO:root:[   91] Training loss: 0.62411934, Validation loss: 0.61616061, Gradient norm: 0.05690192
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6834.359375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   92] Training loss: 0.62388189, Validation loss: 0.61469866, Gradient norm: 0.05126930
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6875.73046875MB
INFO:root:[   93] Training loss: 0.62338493, Validation loss: 0.61556389, Gradient norm: 0.04857440
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6913.87109375MB
INFO:root:[   94] Training loss: 0.62342022, Validation loss: 0.61575737, Gradient norm: 0.05020088
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6952.63671875MB
INFO:root:[   95] Training loss: 0.62326580, Validation loss: 0.61533286, Gradient norm: 0.04727057
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=6990.5078125MB
INFO:root:[   96] Training loss: 0.62286046, Validation loss: 0.61492096, Gradient norm: 0.04821794
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7028.6484375MB
INFO:root:[   97] Training loss: 0.62296129, Validation loss: 0.61493165, Gradient norm: 0.05029601
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7066.79296875MB
INFO:root:[   98] Training loss: 0.62302014, Validation loss: 0.61511214, Gradient norm: 0.04954629
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7104.9296875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   99] Training loss: 0.62286846, Validation loss: 0.61474942, Gradient norm: 0.05013517
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7143.0703125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  100] Training loss: 0.62270341, Validation loss: 0.61491906, Gradient norm: 0.04774774
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7181.18359375MB
INFO:root:[  101] Training loss: 0.62263500, Validation loss: 0.61506044, Gradient norm: 0.04465328
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7221.2578125MB
INFO:root:[  102] Training loss: 0.62247274, Validation loss: 0.61438595, Gradient norm: 0.04481397
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7259.3984375MB
INFO:root:[  103] Training loss: 0.62236929, Validation loss: 0.61543575, Gradient norm: 0.04530964
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7297.8203125MB
INFO:root:[  104] Training loss: 0.62223121, Validation loss: 0.61479745, Gradient norm: 0.04590356
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7335.99609375MB
INFO:root:[  105] Training loss: 0.62242689, Validation loss: 0.61471173, Gradient norm: 0.04476041
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7373.89453125MB
INFO:root:[  106] Training loss: 0.62246834, Validation loss: 0.61439655, Gradient norm: 0.04732242
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7412.015625MB
INFO:root:[  107] Training loss: 0.62247253, Validation loss: 0.61525426, Gradient norm: 0.04580120
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7450.640625MB
INFO:root:[  108] Training loss: 0.62255334, Validation loss: 0.61425928, Gradient norm: 0.04642450
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7488.78125MB
INFO:root:[  109] Training loss: 0.62232791, Validation loss: 0.61480006, Gradient norm: 0.04560820
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7528.25390625MB
INFO:root:[  110] Training loss: 0.62232305, Validation loss: 0.61415549, Gradient norm: 0.04498606
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7566.26171875MB
INFO:root:[  111] Training loss: 0.62218537, Validation loss: 0.61532841, Gradient norm: 0.04616278
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7604.33203125MB
INFO:root:[  112] Training loss: 0.62220162, Validation loss: 0.61434722, Gradient norm: 0.04516663
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7642.48828125MB
INFO:root:[  113] Training loss: 0.62231837, Validation loss: 0.61426017, Gradient norm: 0.04529278
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7680.890625MB
INFO:root:[  114] Training loss: 0.62214450, Validation loss: 0.61447976, Gradient norm: 0.04628199
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7719.05078125MB
INFO:root:[  115] Training loss: 0.62228622, Validation loss: 0.61416019, Gradient norm: 0.04625116
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7757.33984375MB
INFO:root:[  116] Training loss: 0.62205221, Validation loss: 0.61431048, Gradient norm: 0.04704156
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7795.3203125MB
INFO:root:[  117] Training loss: 0.62208844, Validation loss: 0.61418966, Gradient norm: 0.04620856
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7833.7265625MB
INFO:root:[  118] Training loss: 0.62220669, Validation loss: 0.61447378, Gradient norm: 0.04715285
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7871.82421875MB
INFO:root:[  119] Training loss: 0.62209592, Validation loss: 0.61456833, Gradient norm: 0.04636290
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7909.984375MB
INFO:root:EP 119: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12458.51953125MB; mem (CPU total)=7947.89453125MB
INFO:root:Training the model took 4494.35s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86048
INFO:root:EnergyScoreTrain: 0.60567
INFO:root:CRPSTrain: 0.47392
INFO:root:Gaussian NLLTrain: 1.22388
INFO:root:CoverageTrain: 0.94692
INFO:root:IntervalWidthTrain: 3.31211
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87334
INFO:root:EnergyScoreValidation: 0.61469
INFO:root:CRPSValidation: 0.48164
INFO:root:Gaussian NLLValidation: 1.24046
INFO:root:CoverageValidation: 0.94292
INFO:root:IntervalWidthValidation: 3.31452
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87406
INFO:root:EnergyScoreTest: 0.61518
INFO:root:CRPSTest: 0.48205
INFO:root:Gaussian NLLTest: 1.24144
INFO:root:CoverageTest: 0.94247
INFO:root:IntervalWidthTest: 3.31335
INFO:root:After validation: mem (CPU python)=12458.51953125MB; mem (CPU total)=7984.07421875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=12458.51953125MB; mem (CPU total)=7983.82421875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=12458.51953125MB; mem (CPU total)=7983.82421875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=7984.0703125MB
INFO:root:[    1] Training loss: 0.72517621, Validation loss: 0.72026570, Gradient norm: 0.02240939
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8082.796875MB
INFO:root:[    2] Training loss: 0.71976255, Validation loss: 0.71886346, Gradient norm: 0.00571346
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8070.875MB
INFO:root:[    3] Training loss: 0.71768558, Validation loss: 0.71402687, Gradient norm: 0.00812919
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8108.7890625MB
INFO:root:[    4] Training loss: 0.71112210, Validation loss: 0.70445187, Gradient norm: 0.01705935
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8154.13671875MB
INFO:root:[    5] Training loss: 0.70423511, Validation loss: 0.69776541, Gradient norm: 0.02250090
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8192.99609375MB
INFO:root:[    6] Training loss: 0.69870182, Validation loss: 0.69317839, Gradient norm: 0.02712123
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8231.109375MB
INFO:root:[    7] Training loss: 0.69406600, Validation loss: 0.68672127, Gradient norm: 0.02566306
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8274.0MB
INFO:root:[    8] Training loss: 0.69019323, Validation loss: 0.68331815, Gradient norm: 0.03034224
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8312.16015625MB
INFO:root:[    9] Training loss: 0.68677926, Validation loss: 0.67952634, Gradient norm: 0.02870636
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8358.04296875MB
INFO:root:[   10] Training loss: 0.68371584, Validation loss: 0.67571176, Gradient norm: 0.03063759
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8396.44921875MB
INFO:root:[   11] Training loss: 0.68074210, Validation loss: 0.67251913, Gradient norm: 0.03316916
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8393.83984375MB
INFO:root:[   12] Training loss: 0.67797078, Validation loss: 0.66922012, Gradient norm: 0.03114813
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8459.62890625MB
INFO:root:[   13] Training loss: 0.67545398, Validation loss: 0.66678919, Gradient norm: 0.03503401
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8506.45703125MB
INFO:root:[   14] Training loss: 0.67279767, Validation loss: 0.66413431, Gradient norm: 0.03340551
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8544.37109375MB
INFO:root:[   15] Training loss: 0.67051931, Validation loss: 0.66105894, Gradient norm: 0.03392332
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8582.76953125MB
INFO:root:[   16] Training loss: 0.66832871, Validation loss: 0.65869302, Gradient norm: 0.03270109
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8620.6796875MB
INFO:root:[   17] Training loss: 0.66657095, Validation loss: 0.65725302, Gradient norm: 0.03563806
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8659.0546875MB
INFO:root:[   18] Training loss: 0.66470814, Validation loss: 0.65561373, Gradient norm: 0.03311622
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8696.953125MB
INFO:root:[   19] Training loss: 0.66314058, Validation loss: 0.65313178, Gradient norm: 0.03593572
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8735.10546875MB
INFO:root:[   20] Training loss: 0.66160276, Validation loss: 0.65181490, Gradient norm: 0.03294694
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8773.51171875MB
INFO:root:[   21] Training loss: 0.66015023, Validation loss: 0.64991742, Gradient norm: 0.03799285
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8811.671875MB
INFO:root:[   22] Training loss: 0.65858498, Validation loss: 0.64847888, Gradient norm: 0.03626863
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8849.83203125MB
INFO:root:[   23] Training loss: 0.65721053, Validation loss: 0.64725148, Gradient norm: 0.03370346
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8887.98828125MB
INFO:root:[   24] Training loss: 0.65590690, Validation loss: 0.64628857, Gradient norm: 0.03506709
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8926.140625MB
INFO:root:[   25] Training loss: 0.65485237, Validation loss: 0.64504256, Gradient norm: 0.04089787
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=8964.29296875MB
INFO:root:[   26] Training loss: 0.65388125, Validation loss: 0.64332869, Gradient norm: 0.03648928
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9002.484375MB
INFO:root:[   27] Training loss: 0.65289572, Validation loss: 0.64190698, Gradient norm: 0.03906850
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9040.3984375MB
INFO:root:[   28] Training loss: 0.65179923, Validation loss: 0.64148682, Gradient norm: 0.04116510
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9078.30078125MB
INFO:root:[   29] Training loss: 0.65079266, Validation loss: 0.64051098, Gradient norm: 0.03940480
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9116.3671875MB
INFO:root:[   30] Training loss: 0.64963124, Validation loss: 0.63956268, Gradient norm: 0.04106824
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9154.50390625MB
INFO:root:[   31] Training loss: 0.64896926, Validation loss: 0.63843803, Gradient norm: 0.04127820
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9203.35546875MB
INFO:root:[   32] Training loss: 0.64810323, Validation loss: 0.63874945, Gradient norm: 0.04329771
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9242.01171875MB
INFO:root:[   33] Training loss: 0.64743869, Validation loss: 0.63859248, Gradient norm: 0.04208380
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9279.6484375MB
INFO:root:[   34] Training loss: 0.64660028, Validation loss: 0.63628363, Gradient norm: 0.04429525
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9317.515625MB
INFO:root:[   35] Training loss: 0.64569508, Validation loss: 0.63555207, Gradient norm: 0.04145484
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9355.75MB
INFO:root:[   36] Training loss: 0.64517991, Validation loss: 0.63588361, Gradient norm: 0.04199139
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9366.57421875MB
INFO:root:[   37] Training loss: 0.64451738, Validation loss: 0.63421491, Gradient norm: 0.04306608
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9423.39453125MB
INFO:root:[   38] Training loss: 0.64390151, Validation loss: 0.63490026, Gradient norm: 0.04684875
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9461.78515625MB
INFO:root:[   39] Training loss: 0.64320549, Validation loss: 0.63289180, Gradient norm: 0.04605924
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9499.70703125MB
INFO:root:[   40] Training loss: 0.64238614, Validation loss: 0.63251647, Gradient norm: 0.04832405
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9537.8359375MB
INFO:root:[   41] Training loss: 0.64207741, Validation loss: 0.63268212, Gradient norm: 0.04408528
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9575.98046875MB
INFO:root:[   42] Training loss: 0.64111083, Validation loss: 0.63240235, Gradient norm: 0.04511266
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9614.125MB
INFO:root:[   43] Training loss: 0.64098602, Validation loss: 0.63199989, Gradient norm: 0.04653414
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9652.25MB
INFO:root:[   44] Training loss: 0.64008235, Validation loss: 0.63048083, Gradient norm: 0.04547284
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9690.12890625MB
INFO:root:[   45] Training loss: 0.63942762, Validation loss: 0.63056169, Gradient norm: 0.04487561
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9728.265625MB
INFO:root:[   46] Training loss: 0.63900746, Validation loss: 0.62926694, Gradient norm: 0.04316346
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9767.26171875MB
INFO:root:[   47] Training loss: 0.63861568, Validation loss: 0.62884582, Gradient norm: 0.04516826
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9805.328125MB
INFO:root:[   48] Training loss: 0.63796182, Validation loss: 0.62761689, Gradient norm: 0.04938173
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9843.71875MB
INFO:root:[   49] Training loss: 0.63759077, Validation loss: 0.62769122, Gradient norm: 0.04888168
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9881.6171875MB
INFO:root:[   50] Training loss: 0.63702874, Validation loss: 0.62725074, Gradient norm: 0.04186341
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9921.33203125MB
INFO:root:[   51] Training loss: 0.63654541, Validation loss: 0.62657996, Gradient norm: 0.04599566
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9959.66796875MB
INFO:root:[   52] Training loss: 0.63614024, Validation loss: 0.62608628, Gradient norm: 0.05132290
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=9997.9453125MB
INFO:root:[   53] Training loss: 0.63578197, Validation loss: 0.62644272, Gradient norm: 0.04737221
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10035.87109375MB
INFO:root:[   54] Training loss: 0.63535039, Validation loss: 0.62706961, Gradient norm: 0.05320197
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10073.77734375MB
INFO:root:[   55] Training loss: 0.63506997, Validation loss: 0.62512728, Gradient norm: 0.05346081
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10102.4921875MB
INFO:root:[   56] Training loss: 0.63455816, Validation loss: 0.62678346, Gradient norm: 0.04834188
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10140.63671875MB
INFO:root:[   57] Training loss: 0.63402831, Validation loss: 0.62489066, Gradient norm: 0.04570937
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10178.30078125MB
INFO:root:[   58] Training loss: 0.63378629, Validation loss: 0.62406394, Gradient norm: 0.04519737
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10216.02734375MB
INFO:root:[   59] Training loss: 0.63310319, Validation loss: 0.62490512, Gradient norm: 0.04503998
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10260.6484375MB
INFO:root:[   60] Training loss: 0.63293863, Validation loss: 0.62333752, Gradient norm: 0.04945060
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10299.10546875MB
INFO:root:[   61] Training loss: 0.63252446, Validation loss: 0.62400497, Gradient norm: 0.05168718
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10336.91015625MB
INFO:root:[   62] Training loss: 0.63213219, Validation loss: 0.62249707, Gradient norm: 0.04670850
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10374.546875MB
INFO:root:[   63] Training loss: 0.63167726, Validation loss: 0.62217144, Gradient norm: 0.05024098
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10412.44140625MB
INFO:root:[   64] Training loss: 0.63142748, Validation loss: 0.62346486, Gradient norm: 0.04706050
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10450.5859375MB
INFO:root:[   65] Training loss: 0.63131188, Validation loss: 0.62281415, Gradient norm: 0.05045639
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10488.23828125MB
INFO:root:[   66] Training loss: 0.63060289, Validation loss: 0.62137449, Gradient norm: 0.04853428
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10526.515625MB
INFO:root:[   67] Training loss: 0.63061829, Validation loss: 0.62042244, Gradient norm: 0.05047940
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10564.69921875MB
INFO:root:[   68] Training loss: 0.63011185, Validation loss: 0.62267129, Gradient norm: 0.05204878
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10602.59765625MB
INFO:root:[   69] Training loss: 0.62958715, Validation loss: 0.62113639, Gradient norm: 0.05382920
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10645.44140625MB
INFO:root:[   70] Training loss: 0.62938386, Validation loss: 0.62054791, Gradient norm: 0.04949066
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10683.78515625MB
INFO:root:[   71] Training loss: 0.62921004, Validation loss: 0.61998775, Gradient norm: 0.05043851
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10722.16796875MB
INFO:root:[   72] Training loss: 0.62879612, Validation loss: 0.61980570, Gradient norm: 0.04953273
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10760.34375MB
INFO:root:[   73] Training loss: 0.62858131, Validation loss: 0.62051761, Gradient norm: 0.05368925
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10798.45703125MB
INFO:root:[   74] Training loss: 0.62850684, Validation loss: 0.61975296, Gradient norm: 0.05223508
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10836.6015625MB
INFO:root:[   75] Training loss: 0.62799576, Validation loss: 0.61971688, Gradient norm: 0.04922853
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10875.25390625MB
INFO:root:[   76] Training loss: 0.62766702, Validation loss: 0.61961984, Gradient norm: 0.04885949
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10913.3984375MB
INFO:root:[   77] Training loss: 0.62769225, Validation loss: 0.61978611, Gradient norm: 0.05225003
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10951.296875MB
INFO:root:[   78] Training loss: 0.62729273, Validation loss: 0.61884292, Gradient norm: 0.05328518
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=10989.6875MB
INFO:root:[   79] Training loss: 0.62711694, Validation loss: 0.61922953, Gradient norm: 0.05050567
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11027.83203125MB
INFO:root:[   80] Training loss: 0.62683791, Validation loss: 0.61797613, Gradient norm: 0.05689072
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11065.9765625MB
INFO:root:[   81] Training loss: 0.62654694, Validation loss: 0.61737512, Gradient norm: 0.05470639
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11104.12109375MB
INFO:root:[   82] Training loss: 0.62642585, Validation loss: 0.61764707, Gradient norm: 0.05648788
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11142.01953125MB
INFO:root:[   83] Training loss: 0.62595809, Validation loss: 0.61825057, Gradient norm: 0.05371931
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11179.921875MB
INFO:root:[   84] Training loss: 0.62573081, Validation loss: 0.61794768, Gradient norm: 0.05360794
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11218.06640625MB
INFO:root:[   85] Training loss: 0.62547500, Validation loss: 0.61896626, Gradient norm: 0.05588369
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11256.19140625MB
INFO:root:[   86] Training loss: 0.62535574, Validation loss: 0.61702473, Gradient norm: 0.05721450
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11294.3359375MB
INFO:root:[   87] Training loss: 0.62504465, Validation loss: 0.61704969, Gradient norm: 0.04774851
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11332.47265625MB
INFO:root:[   88] Training loss: 0.62490907, Validation loss: 0.61723590, Gradient norm: 0.05401760
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11371.37109375MB
INFO:root:[   89] Training loss: 0.62446509, Validation loss: 0.61628088, Gradient norm: 0.05505612
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11408.91015625MB
INFO:root:[   90] Training loss: 0.62432571, Validation loss: 0.61600408, Gradient norm: 0.05475399
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11447.30078125MB
INFO:root:[   91] Training loss: 0.62428128, Validation loss: 0.61621087, Gradient norm: 0.05805818
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11490.7109375MB
INFO:root:[   92] Training loss: 0.62410623, Validation loss: 0.61577112, Gradient norm: 0.06111861
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11529.01953125MB
INFO:root:[   93] Training loss: 0.62393023, Validation loss: 0.61679569, Gradient norm: 0.05617045
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11566.91015625MB
INFO:root:[   94] Training loss: 0.62362410, Validation loss: 0.61738876, Gradient norm: 0.05299184
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11605.0546875MB
INFO:root:[   95] Training loss: 0.62329518, Validation loss: 0.61651089, Gradient norm: 0.05244739
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11642.953125MB
INFO:root:[   96] Training loss: 0.62295178, Validation loss: 0.61623009, Gradient norm: 0.05408613
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11681.09765625MB
INFO:root:[   97] Training loss: 0.62299076, Validation loss: 0.61399029, Gradient norm: 0.05829232
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11719.51171875MB
INFO:root:[   98] Training loss: 0.62277871, Validation loss: 0.61596083, Gradient norm: 0.05845969
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11757.65625MB
INFO:root:[   99] Training loss: 0.62266928, Validation loss: 0.61385233, Gradient norm: 0.05542764
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11798.22265625MB
INFO:root:[  100] Training loss: 0.62249303, Validation loss: 0.61443934, Gradient norm: 0.05320752
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11837.6015625MB
INFO:root:[  101] Training loss: 0.62206499, Validation loss: 0.61384840, Gradient norm: 0.05795021
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11875.98046875MB
INFO:root:[  102] Training loss: 0.62194589, Validation loss: 0.61380942, Gradient norm: 0.05052592
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11913.91015625MB
INFO:root:[  103] Training loss: 0.62177422, Validation loss: 0.61425235, Gradient norm: 0.05260949
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11951.9765625MB
INFO:root:[  104] Training loss: 0.62170903, Validation loss: 0.61323274, Gradient norm: 0.05369931
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=11989.59765625MB
INFO:root:[  105] Training loss: 0.62167994, Validation loss: 0.61473167, Gradient norm: 0.05901368
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=12027.25MB
INFO:root:[  106] Training loss: 0.62141823, Validation loss: 0.61379452, Gradient norm: 0.05222626
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=12065.1484375MB
INFO:root:[  107] Training loss: 0.62121894, Validation loss: 0.61253368, Gradient norm: 0.05981355
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=12103.29296875MB
INFO:root:[  108] Training loss: 0.62090705, Validation loss: 0.61352764, Gradient norm: 0.05691707
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=12141.2578125MB
INFO:root:[  109] Training loss: 0.62067833, Validation loss: 0.61371432, Gradient norm: 0.05709373
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=12179.38671875MB
INFO:root:[  110] Training loss: 0.62073508, Validation loss: 0.61228455, Gradient norm: 0.05915343
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=12217.68359375MB
INFO:root:[  111] Training loss: 0.62074740, Validation loss: 0.61453730, Gradient norm: 0.05707479
INFO:root:At the start of the epoch: mem (CPU python)=12458.51953125MB; mem (CPU total)=12254.61328125MB
INFO:root:[  112] Training loss: 0.62047336, Validation loss: 0.61315613, Gradient norm: 0.05737886
INFO:root:At the start of the epoch: mem (CPU python)=12494.46875MB; mem (CPU total)=12292.6484375MB
INFO:root:[  113] Training loss: 0.62013488, Validation loss: 0.61181522, Gradient norm: 0.05449296
INFO:root:At the start of the epoch: mem (CPU python)=12532.5625MB; mem (CPU total)=12331.609375MB
INFO:root:[  114] Training loss: 0.61999415, Validation loss: 0.61378960, Gradient norm: 0.05672428
INFO:root:At the start of the epoch: mem (CPU python)=12570.66015625MB; mem (CPU total)=12369.5078125MB
INFO:root:[  115] Training loss: 0.61980947, Validation loss: 0.61275589, Gradient norm: 0.05953373
INFO:root:At the start of the epoch: mem (CPU python)=12608.7578125MB; mem (CPU total)=12407.67578125MB
INFO:root:[  116] Training loss: 0.61977567, Validation loss: 0.61482980, Gradient norm: 0.06056579
INFO:root:At the start of the epoch: mem (CPU python)=12646.8515625MB; mem (CPU total)=12445.78125MB
INFO:root:[  117] Training loss: 0.61960601, Validation loss: 0.61246475, Gradient norm: 0.05967335
INFO:root:At the start of the epoch: mem (CPU python)=12684.94921875MB; mem (CPU total)=12483.89453125MB
INFO:root:[  118] Training loss: 0.61944529, Validation loss: 0.61171309, Gradient norm: 0.05412981
INFO:root:At the start of the epoch: mem (CPU python)=12723.04296875MB; mem (CPU total)=12522.265625MB
INFO:root:[  119] Training loss: 0.61925122, Validation loss: 0.61137902, Gradient norm: 0.05927555
INFO:root:At the start of the epoch: mem (CPU python)=12761.13671875MB; mem (CPU total)=12560.41015625MB
INFO:root:[  120] Training loss: 0.61881611, Validation loss: 0.61250483, Gradient norm: 0.05982665
INFO:root:At the start of the epoch: mem (CPU python)=12799.234375MB; mem (CPU total)=12598.83203125MB
INFO:root:[  121] Training loss: 0.61881980, Validation loss: 0.61127692, Gradient norm: 0.05895245
INFO:root:At the start of the epoch: mem (CPU python)=12837.328125MB; mem (CPU total)=12636.9765625MB
INFO:root:[  122] Training loss: 0.61899016, Validation loss: 0.61199186, Gradient norm: 0.05819164
INFO:root:At the start of the epoch: mem (CPU python)=12875.421875MB; mem (CPU total)=12675.12109375MB
INFO:root:[  123] Training loss: 0.61841663, Validation loss: 0.61352303, Gradient norm: 0.05640984
INFO:root:At the start of the epoch: mem (CPU python)=12913.51953125MB; mem (CPU total)=12713.265625MB
INFO:root:[  124] Training loss: 0.61853149, Validation loss: 0.61048961, Gradient norm: 0.05929705
INFO:root:At the start of the epoch: mem (CPU python)=12951.6171875MB; mem (CPU total)=12751.40625MB
INFO:root:[  125] Training loss: 0.61831259, Validation loss: 0.61309259, Gradient norm: 0.05500771
INFO:root:At the start of the epoch: mem (CPU python)=12989.7109375MB; mem (CPU total)=12789.77734375MB
INFO:root:[  126] Training loss: 0.61829101, Validation loss: 0.61109927, Gradient norm: 0.05890898
INFO:root:At the start of the epoch: mem (CPU python)=13027.80859375MB; mem (CPU total)=12827.88671875MB
INFO:root:[  127] Training loss: 0.61817607, Validation loss: 0.61017401, Gradient norm: 0.05642876
INFO:root:At the start of the epoch: mem (CPU python)=13065.90625MB; mem (CPU total)=12865.80859375MB
INFO:root:[  128] Training loss: 0.61794191, Validation loss: 0.61145035, Gradient norm: 0.05502041
INFO:root:At the start of the epoch: mem (CPU python)=13104.0MB; mem (CPU total)=12904.16796875MB
INFO:root:[  129] Training loss: 0.61797497, Validation loss: 0.61245423, Gradient norm: 0.06113190
INFO:root:At the start of the epoch: mem (CPU python)=13142.09375MB; mem (CPU total)=12941.82421875MB
INFO:root:[  130] Training loss: 0.61786968, Validation loss: 0.60977733, Gradient norm: 0.06206358
INFO:root:At the start of the epoch: mem (CPU python)=13180.1875MB; mem (CPU total)=12980.2265625MB
INFO:root:[  131] Training loss: 0.61766971, Validation loss: 0.60997585, Gradient norm: 0.05709408
INFO:root:At the start of the epoch: mem (CPU python)=13218.2890625MB; mem (CPU total)=13018.6171875MB
INFO:root:[  132] Training loss: 0.61761766, Validation loss: 0.61102426, Gradient norm: 0.06166917
INFO:root:At the start of the epoch: mem (CPU python)=13256.3828125MB; mem (CPU total)=13056.76171875MB
INFO:root:[  133] Training loss: 0.61744742, Validation loss: 0.61012562, Gradient norm: 0.06541711
INFO:root:At the start of the epoch: mem (CPU python)=13294.4765625MB; mem (CPU total)=13094.90625MB
INFO:root:[  134] Training loss: 0.61719336, Validation loss: 0.61288148, Gradient norm: 0.06191187
INFO:root:At the start of the epoch: mem (CPU python)=13332.57421875MB; mem (CPU total)=13132.8046875MB
INFO:root:[  135] Training loss: 0.61733380, Validation loss: 0.61051035, Gradient norm: 0.06468913
INFO:root:At the start of the epoch: mem (CPU python)=13370.66796875MB; mem (CPU total)=13170.94921875MB
INFO:root:[  136] Training loss: 0.61685239, Validation loss: 0.61167828, Gradient norm: 0.05879301
INFO:root:At the start of the epoch: mem (CPU python)=13408.76171875MB; mem (CPU total)=13209.33984375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  137] Training loss: 0.61681708, Validation loss: 0.60967715, Gradient norm: 0.06011601
INFO:root:At the start of the epoch: mem (CPU python)=13446.86328125MB; mem (CPU total)=13249.03515625MB
INFO:root:[  138] Training loss: 0.61574191, Validation loss: 0.60968268, Gradient norm: 0.05130053
INFO:root:At the start of the epoch: mem (CPU python)=13484.95703125MB; mem (CPU total)=13287.18359375MB
INFO:root:[  139] Training loss: 0.61587427, Validation loss: 0.60928460, Gradient norm: 0.05656417
INFO:root:At the start of the epoch: mem (CPU python)=13523.05078125MB; mem (CPU total)=13325.08984375MB
INFO:root:[  140] Training loss: 0.61574951, Validation loss: 0.61013719, Gradient norm: 0.05303180
INFO:root:At the start of the epoch: mem (CPU python)=13561.14453125MB; mem (CPU total)=13363.30859375MB
INFO:root:[  141] Training loss: 0.61548029, Validation loss: 0.61094077, Gradient norm: 0.05141665
INFO:root:At the start of the epoch: mem (CPU python)=13599.2421875MB; mem (CPU total)=13401.46875MB
INFO:root:[  142] Training loss: 0.61532047, Validation loss: 0.60957300, Gradient norm: 0.05337048
INFO:root:At the start of the epoch: mem (CPU python)=13637.3359375MB; mem (CPU total)=13439.81640625MB
INFO:root:[  143] Training loss: 0.61555014, Validation loss: 0.60894802, Gradient norm: 0.05553912
INFO:root:At the start of the epoch: mem (CPU python)=13675.4296875MB; mem (CPU total)=13477.70703125MB
INFO:root:[  144] Training loss: 0.61503251, Validation loss: 0.60990259, Gradient norm: 0.05054205
INFO:root:At the start of the epoch: mem (CPU python)=13713.52734375MB; mem (CPU total)=13515.859375MB
INFO:root:[  145] Training loss: 0.61509169, Validation loss: 0.60891387, Gradient norm: 0.05290816
INFO:root:At the start of the epoch: mem (CPU python)=13751.62109375MB; mem (CPU total)=13554.0546875MB
INFO:root:[  146] Training loss: 0.61530059, Validation loss: 0.60858568, Gradient norm: 0.05152922
INFO:root:At the start of the epoch: mem (CPU python)=13789.71484375MB; mem (CPU total)=13592.20703125MB
INFO:root:[  147] Training loss: 0.61541316, Validation loss: 0.61004180, Gradient norm: 0.05636203
INFO:root:At the start of the epoch: mem (CPU python)=13827.8125MB; mem (CPU total)=13630.125MB
INFO:root:[  148] Training loss: 0.61504835, Validation loss: 0.61047481, Gradient norm: 0.05648436
INFO:root:At the start of the epoch: mem (CPU python)=13865.91015625MB; mem (CPU total)=13668.5234375MB
INFO:root:[  149] Training loss: 0.61503929, Validation loss: 0.61007085, Gradient norm: 0.05477062
INFO:root:At the start of the epoch: mem (CPU python)=13904.00390625MB; mem (CPU total)=13706.6875MB
INFO:root:[  150] Training loss: 0.61490451, Validation loss: 0.60955178, Gradient norm: 0.05326176
INFO:root:At the start of the epoch: mem (CPU python)=13942.09765625MB; mem (CPU total)=13744.84765625MB
INFO:root:[  151] Training loss: 0.61486922, Validation loss: 0.60926673, Gradient norm: 0.05477017
INFO:root:At the start of the epoch: mem (CPU python)=13980.1953125MB; mem (CPU total)=13782.98828125MB
INFO:root:[  152] Training loss: 0.61496999, Validation loss: 0.60884577, Gradient norm: 0.05479945
INFO:root:At the start of the epoch: mem (CPU python)=14018.2890625MB; mem (CPU total)=13821.7578125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  153] Training loss: 0.61458750, Validation loss: 0.60959630, Gradient norm: 0.05553012
INFO:root:At the start of the epoch: mem (CPU python)=14056.3828125MB; mem (CPU total)=13859.48828125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  154] Training loss: 0.61410411, Validation loss: 0.60939274, Gradient norm: 0.05086077
INFO:root:At the start of the epoch: mem (CPU python)=14094.48046875MB; mem (CPU total)=13897.40625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  155] Training loss: 0.61377057, Validation loss: 0.60904804, Gradient norm: 0.04812355
INFO:root:At the start of the epoch: mem (CPU python)=14132.58203125MB; mem (CPU total)=13935.6640625MB
INFO:root:EP 155: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=14170.6796875MB; mem (CPU total)=13973.5546875MB
INFO:root:Training the model took 6740.276s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84613
INFO:root:EnergyScoreTrain: 0.59562
INFO:root:CRPSTrain: 0.46345
INFO:root:Gaussian NLLTrain: 1.20355
INFO:root:CoverageTrain: 0.94484
INFO:root:IntervalWidthTrain: 3.24135
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86492
INFO:root:EnergyScoreValidation: 0.60878
INFO:root:CRPSValidation: 0.47479
INFO:root:Gaussian NLLValidation: 1.23314
INFO:root:CoverageValidation: 0.93842
INFO:root:IntervalWidthValidation: 3.24453
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86592
INFO:root:EnergyScoreTest: 0.60948
INFO:root:CRPSTest: 0.47533
INFO:root:Gaussian NLLTest: 1.23488
INFO:root:CoverageTest: 0.93813
INFO:root:IntervalWidthTest: 3.24536
INFO:root:After validation: mem (CPU python)=14263.07421875MB; mem (CPU total)=14006.234375MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=14263.07421875MB; mem (CPU total)=14006.23828125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=14263.07421875MB; mem (CPU total)=14006.73046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=14263.07421875MB; mem (CPU total)=14006.484375MB
INFO:root:[    1] Training loss: 0.72436281, Validation loss: 0.72084641, Gradient norm: 0.01857680
INFO:root:At the start of the epoch: mem (CPU python)=14263.07421875MB; mem (CPU total)=14063.44140625MB
INFO:root:[    2] Training loss: 0.71975552, Validation loss: 0.71865889, Gradient norm: 0.00602330
INFO:root:At the start of the epoch: mem (CPU python)=14315.2265625MB; mem (CPU total)=14120.00390625MB
INFO:root:[    3] Training loss: 0.71814860, Validation loss: 0.71543233, Gradient norm: 0.00779406
INFO:root:At the start of the epoch: mem (CPU python)=14353.3359375MB; mem (CPU total)=14158.1640625MB
INFO:root:[    4] Training loss: 0.71188990, Validation loss: 0.70479645, Gradient norm: 0.01696635
INFO:root:At the start of the epoch: mem (CPU python)=14383.73828125MB; mem (CPU total)=14140.9765625MB
INFO:root:[    5] Training loss: 0.70436222, Validation loss: 0.69835026, Gradient norm: 0.02308872
INFO:root:At the start of the epoch: mem (CPU python)=14383.73828125MB; mem (CPU total)=14186.3359375MB
INFO:root:[    6] Training loss: 0.69888885, Validation loss: 0.69286813, Gradient norm: 0.03162482
INFO:root:At the start of the epoch: mem (CPU python)=14424.78125MB; mem (CPU total)=14230.94140625MB
INFO:root:[    7] Training loss: 0.69449687, Validation loss: 0.68848425, Gradient norm: 0.02873282
INFO:root:At the start of the epoch: mem (CPU python)=14462.88671875MB; mem (CPU total)=14269.10546875MB
INFO:root:[    8] Training loss: 0.68985819, Validation loss: 0.68397941, Gradient norm: 0.03044076
INFO:root:At the start of the epoch: mem (CPU python)=14500.98046875MB; mem (CPU total)=14307.05078125MB
INFO:root:[    9] Training loss: 0.68560714, Validation loss: 0.67802740, Gradient norm: 0.03351186
INFO:root:At the start of the epoch: mem (CPU python)=14556.96875MB; mem (CPU total)=14364.07421875MB
INFO:root:[   10] Training loss: 0.68160369, Validation loss: 0.67239481, Gradient norm: 0.03151288
INFO:root:At the start of the epoch: mem (CPU python)=14595.0625MB; mem (CPU total)=14402.25MB
INFO:root:[   11] Training loss: 0.67769630, Validation loss: 0.66965708, Gradient norm: 0.03272957
INFO:root:At the start of the epoch: mem (CPU python)=14633.15625MB; mem (CPU total)=14440.421875MB
INFO:root:[   12] Training loss: 0.67441527, Validation loss: 0.66518442, Gradient norm: 0.03417473
INFO:root:At the start of the epoch: mem (CPU python)=14671.2578125MB; mem (CPU total)=14478.3515625MB
INFO:root:[   13] Training loss: 0.67131226, Validation loss: 0.66152183, Gradient norm: 0.03495200
INFO:root:At the start of the epoch: mem (CPU python)=14709.3515625MB; mem (CPU total)=14516.265625MB
INFO:root:[   14] Training loss: 0.66865281, Validation loss: 0.65901456, Gradient norm: 0.03641175
INFO:root:At the start of the epoch: mem (CPU python)=14747.44921875MB; mem (CPU total)=14554.4296875MB
INFO:root:[   15] Training loss: 0.66598933, Validation loss: 0.65609652, Gradient norm: 0.03509851
INFO:root:At the start of the epoch: mem (CPU python)=14785.546875MB; mem (CPU total)=14592.1015625MB
INFO:root:[   16] Training loss: 0.66365660, Validation loss: 0.65409382, Gradient norm: 0.03615999
INFO:root:At the start of the epoch: mem (CPU python)=14823.640625MB; mem (CPU total)=14630.5078125MB
INFO:root:[   17] Training loss: 0.66150030, Validation loss: 0.65204706, Gradient norm: 0.03650997
INFO:root:At the start of the epoch: mem (CPU python)=14861.734375MB; mem (CPU total)=14668.9140625MB
INFO:root:[   18] Training loss: 0.65960611, Validation loss: 0.64949526, Gradient norm: 0.03857369
INFO:root:At the start of the epoch: mem (CPU python)=14899.828125MB; mem (CPU total)=14707.22265625MB
INFO:root:[   19] Training loss: 0.65791052, Validation loss: 0.64796099, Gradient norm: 0.03830464
INFO:root:At the start of the epoch: mem (CPU python)=14937.92578125MB; mem (CPU total)=14745.23046875MB
INFO:root:[   20] Training loss: 0.65633405, Validation loss: 0.64655956, Gradient norm: 0.04186593
INFO:root:At the start of the epoch: mem (CPU python)=14976.01953125MB; mem (CPU total)=14783.39453125MB
INFO:root:[   21] Training loss: 0.65475002, Validation loss: 0.64372114, Gradient norm: 0.04011175
INFO:root:At the start of the epoch: mem (CPU python)=15014.11328125MB; mem (CPU total)=14821.59375MB
INFO:root:[   22] Training loss: 0.65355165, Validation loss: 0.64269249, Gradient norm: 0.04209215
INFO:root:At the start of the epoch: mem (CPU python)=15052.21484375MB; mem (CPU total)=14859.98046875MB
INFO:root:[   23] Training loss: 0.65193250, Validation loss: 0.64131868, Gradient norm: 0.04015923
INFO:root:At the start of the epoch: mem (CPU python)=15090.3125MB; mem (CPU total)=14897.8828125MB
INFO:root:[   24] Training loss: 0.65075770, Validation loss: 0.63874249, Gradient norm: 0.04434124
INFO:root:At the start of the epoch: mem (CPU python)=15128.40625MB; mem (CPU total)=14936.45703125MB
INFO:root:[   25] Training loss: 0.64972945, Validation loss: 0.63877417, Gradient norm: 0.04373274
INFO:root:At the start of the epoch: mem (CPU python)=15166.5MB; mem (CPU total)=14974.65234375MB
INFO:root:[   26] Training loss: 0.64842782, Validation loss: 0.63795358, Gradient norm: 0.04504570
INFO:root:At the start of the epoch: mem (CPU python)=15204.59765625MB; mem (CPU total)=15013.0625MB
INFO:root:[   27] Training loss: 0.64735751, Validation loss: 0.63625912, Gradient norm: 0.04448784
INFO:root:At the start of the epoch: mem (CPU python)=15242.69140625MB; mem (CPU total)=15050.23828125MB
INFO:root:[   28] Training loss: 0.64626562, Validation loss: 0.63610907, Gradient norm: 0.04418663
INFO:root:At the start of the epoch: mem (CPU python)=15280.7890625MB; mem (CPU total)=15088.1953125MB
INFO:root:[   29] Training loss: 0.64548520, Validation loss: 0.63471581, Gradient norm: 0.05153694
INFO:root:At the start of the epoch: mem (CPU python)=15318.88671875MB; mem (CPU total)=15125.8515625MB
INFO:root:[   30] Training loss: 0.64440576, Validation loss: 0.63361898, Gradient norm: 0.04672057
INFO:root:At the start of the epoch: mem (CPU python)=15356.98046875MB; mem (CPU total)=15163.92578125MB
INFO:root:[   31] Training loss: 0.64341996, Validation loss: 0.63292119, Gradient norm: 0.04081997
INFO:root:At the start of the epoch: mem (CPU python)=15395.07421875MB; mem (CPU total)=15202.08984375MB
INFO:root:[   32] Training loss: 0.64300708, Validation loss: 0.63224131, Gradient norm: 0.05229578
INFO:root:At the start of the epoch: mem (CPU python)=15433.171875MB; mem (CPU total)=15240.31640625MB
INFO:root:[   33] Training loss: 0.64218463, Validation loss: 0.63164243, Gradient norm: 0.04868312
INFO:root:At the start of the epoch: mem (CPU python)=15471.26171875MB; mem (CPU total)=15278.4765625MB
INFO:root:[   34] Training loss: 0.64130098, Validation loss: 0.63068736, Gradient norm: 0.04681299
INFO:root:At the start of the epoch: mem (CPU python)=15509.359375MB; mem (CPU total)=15317.1953125MB
INFO:root:[   35] Training loss: 0.64059375, Validation loss: 0.62948451, Gradient norm: 0.05167640
INFO:root:At the start of the epoch: mem (CPU python)=15547.453125MB; mem (CPU total)=15355.40625MB
INFO:root:[   36] Training loss: 0.63970571, Validation loss: 0.62978951, Gradient norm: 0.04488260
INFO:root:At the start of the epoch: mem (CPU python)=15585.5546875MB; mem (CPU total)=15393.953125MB
INFO:root:[   37] Training loss: 0.63902113, Validation loss: 0.62930309, Gradient norm: 0.04804283
INFO:root:At the start of the epoch: mem (CPU python)=15623.6484375MB; mem (CPU total)=15431.7109375MB
INFO:root:[   38] Training loss: 0.63844246, Validation loss: 0.62827446, Gradient norm: 0.05597318
INFO:root:At the start of the epoch: mem (CPU python)=15661.7421875MB; mem (CPU total)=15470.12109375MB
INFO:root:[   39] Training loss: 0.63776750, Validation loss: 0.62702467, Gradient norm: 0.04747559
INFO:root:At the start of the epoch: mem (CPU python)=15699.83984375MB; mem (CPU total)=15508.0390625MB
INFO:root:[   40] Training loss: 0.63732804, Validation loss: 0.62721559, Gradient norm: 0.05698661
INFO:root:At the start of the epoch: mem (CPU python)=15737.93359375MB; mem (CPU total)=15546.19921875MB
INFO:root:[   41] Training loss: 0.63651478, Validation loss: 0.62596205, Gradient norm: 0.04950227
INFO:root:At the start of the epoch: mem (CPU python)=15776.02734375MB; mem (CPU total)=15584.36328125MB
INFO:root:[   42] Training loss: 0.63561712, Validation loss: 0.62530087, Gradient norm: 0.05150765
INFO:root:At the start of the epoch: mem (CPU python)=15814.12109375MB; mem (CPU total)=15622.25MB
INFO:root:[   43] Training loss: 0.63540080, Validation loss: 0.62519154, Gradient norm: 0.04958407
INFO:root:At the start of the epoch: mem (CPU python)=15852.21875MB; mem (CPU total)=15660.8359375MB
INFO:root:[   44] Training loss: 0.63440246, Validation loss: 0.62392802, Gradient norm: 0.04977652
INFO:root:At the start of the epoch: mem (CPU python)=15890.36328125MB; mem (CPU total)=15698.828125MB
INFO:root:[   45] Training loss: 0.63422437, Validation loss: 0.62437763, Gradient norm: 0.05440469
INFO:root:At the start of the epoch: mem (CPU python)=15928.45703125MB; mem (CPU total)=15736.9921875MB
INFO:root:[   46] Training loss: 0.63355097, Validation loss: 0.62388024, Gradient norm: 0.05611062
INFO:root:At the start of the epoch: mem (CPU python)=15966.55859375MB; mem (CPU total)=15775.15625MB
INFO:root:[   47] Training loss: 0.63328804, Validation loss: 0.62305218, Gradient norm: 0.04983443
INFO:root:At the start of the epoch: mem (CPU python)=16004.65234375MB; mem (CPU total)=15812.81640625MB
INFO:root:[   48] Training loss: 0.63253596, Validation loss: 0.62248298, Gradient norm: 0.04379508
INFO:root:At the start of the epoch: mem (CPU python)=16042.74609375MB; mem (CPU total)=15851.4609375MB
INFO:root:[   49] Training loss: 0.63218214, Validation loss: 0.62340565, Gradient norm: 0.05113416
INFO:root:At the start of the epoch: mem (CPU python)=16080.84375MB; mem (CPU total)=15889.58984375MB
INFO:root:[   50] Training loss: 0.63187135, Validation loss: 0.62192459, Gradient norm: 0.05826261
INFO:root:At the start of the epoch: mem (CPU python)=16118.9375MB; mem (CPU total)=15927.734375MB
INFO:root:[   51] Training loss: 0.63137794, Validation loss: 0.62077061, Gradient norm: 0.05939890
INFO:root:At the start of the epoch: mem (CPU python)=16157.03125MB; mem (CPU total)=15965.35546875MB
INFO:root:[   52] Training loss: 0.63072229, Validation loss: 0.62108765, Gradient norm: 0.05621666
INFO:root:At the start of the epoch: mem (CPU python)=16195.125MB; mem (CPU total)=16002.76171875MB
INFO:root:[   53] Training loss: 0.63016026, Validation loss: 0.61908137, Gradient norm: 0.05031709
INFO:root:At the start of the epoch: mem (CPU python)=16233.2265625MB; mem (CPU total)=16040.90625MB
INFO:root:[   54] Training loss: 0.62959662, Validation loss: 0.62053463, Gradient norm: 0.05408880
INFO:root:At the start of the epoch: mem (CPU python)=16271.3203125MB; mem (CPU total)=16078.99609375MB
INFO:root:[   55] Training loss: 0.62940070, Validation loss: 0.61977463, Gradient norm: 0.05662105
INFO:root:At the start of the epoch: mem (CPU python)=16315.6640625MB; mem (CPU total)=16123.35546875MB
INFO:root:[   56] Training loss: 0.62923140, Validation loss: 0.61966131, Gradient norm: 0.06095433
INFO:root:At the start of the epoch: mem (CPU python)=16353.76171875MB; mem (CPU total)=16161.734375MB
INFO:root:[   57] Training loss: 0.62870101, Validation loss: 0.61899120, Gradient norm: 0.05952697
INFO:root:At the start of the epoch: mem (CPU python)=16391.85546875MB; mem (CPU total)=16199.625MB
INFO:root:[   58] Training loss: 0.62834711, Validation loss: 0.61954440, Gradient norm: 0.05758214
INFO:root:At the start of the epoch: mem (CPU python)=16429.94921875MB; mem (CPU total)=16237.76953125MB
INFO:root:[   59] Training loss: 0.62776905, Validation loss: 0.61829186, Gradient norm: 0.05725402
INFO:root:At the start of the epoch: mem (CPU python)=16468.04296875MB; mem (CPU total)=16276.546875MB
INFO:root:[   60] Training loss: 0.62762385, Validation loss: 0.61805380, Gradient norm: 0.05529804
INFO:root:At the start of the epoch: mem (CPU python)=16506.140625MB; mem (CPU total)=16314.4140625MB
INFO:root:[   61] Training loss: 0.62711145, Validation loss: 0.61771615, Gradient norm: 0.05989310
INFO:root:At the start of the epoch: mem (CPU python)=16544.234375MB; mem (CPU total)=16352.55078125MB
INFO:root:[   62] Training loss: 0.62698074, Validation loss: 0.61740811, Gradient norm: 0.05678426
INFO:root:At the start of the epoch: mem (CPU python)=16582.33203125MB; mem (CPU total)=16390.4453125MB
INFO:root:[   63] Training loss: 0.62640682, Validation loss: 0.61700947, Gradient norm: 0.05624318
INFO:root:At the start of the epoch: mem (CPU python)=16620.4296875MB; mem (CPU total)=16428.62109375MB
INFO:root:[   64] Training loss: 0.62597209, Validation loss: 0.61606379, Gradient norm: 0.05802721
INFO:root:At the start of the epoch: mem (CPU python)=16658.5234375MB; mem (CPU total)=16466.765625MB
INFO:root:[   65] Training loss: 0.62561361, Validation loss: 0.61662712, Gradient norm: 0.05629480
INFO:root:At the start of the epoch: mem (CPU python)=16696.62109375MB; mem (CPU total)=16504.91015625MB
INFO:root:[   66] Training loss: 0.62545481, Validation loss: 0.61570591, Gradient norm: 0.05488970
INFO:root:At the start of the epoch: mem (CPU python)=16734.71875MB; mem (CPU total)=16543.04296875MB
INFO:root:[   67] Training loss: 0.62522285, Validation loss: 0.61511166, Gradient norm: 0.05794952
INFO:root:At the start of the epoch: mem (CPU python)=16772.8125MB; mem (CPU total)=16581.46484375MB
INFO:root:[   68] Training loss: 0.62488302, Validation loss: 0.61613835, Gradient norm: 0.05461878
INFO:root:At the start of the epoch: mem (CPU python)=16810.90625MB; mem (CPU total)=16619.35546875MB
INFO:root:[   69] Training loss: 0.62458388, Validation loss: 0.61671607, Gradient norm: 0.05816982
INFO:root:At the start of the epoch: mem (CPU python)=16849.00390625MB; mem (CPU total)=16657.49609375MB
INFO:root:[   70] Training loss: 0.62406132, Validation loss: 0.61557013, Gradient norm: 0.05668757
INFO:root:At the start of the epoch: mem (CPU python)=16887.1015625MB; mem (CPU total)=16695.88671875MB
INFO:root:[   71] Training loss: 0.62387241, Validation loss: 0.61578235, Gradient norm: 0.05477155
INFO:root:At the start of the epoch: mem (CPU python)=16925.19140625MB; mem (CPU total)=16734.33203125MB
INFO:root:[   72] Training loss: 0.62381523, Validation loss: 0.61495124, Gradient norm: 0.06305408
INFO:root:At the start of the epoch: mem (CPU python)=16963.2890625MB; mem (CPU total)=16772.421875MB
INFO:root:[   73] Training loss: 0.62343798, Validation loss: 0.61458512, Gradient norm: 0.06704915
INFO:root:At the start of the epoch: mem (CPU python)=17001.38671875MB; mem (CPU total)=16810.5546875MB
INFO:root:[   74] Training loss: 0.62322759, Validation loss: 0.61486448, Gradient norm: 0.06225890
INFO:root:At the start of the epoch: mem (CPU python)=17039.48046875MB; mem (CPU total)=16848.69921875MB
INFO:root:[   75] Training loss: 0.62292045, Validation loss: 0.61364478, Gradient norm: 0.05685703
INFO:root:At the start of the epoch: mem (CPU python)=17077.57421875MB; mem (CPU total)=16886.875MB
INFO:root:[   76] Training loss: 0.62255864, Validation loss: 0.61424907, Gradient norm: 0.05917617
INFO:root:At the start of the epoch: mem (CPU python)=17115.66796875MB; mem (CPU total)=16924.7734375MB
INFO:root:[   77] Training loss: 0.62239051, Validation loss: 0.61361067, Gradient norm: 0.05750156
INFO:root:At the start of the epoch: mem (CPU python)=17153.765625MB; mem (CPU total)=16962.91796875MB
INFO:root:[   78] Training loss: 0.62216935, Validation loss: 0.61349138, Gradient norm: 0.06052423
INFO:root:At the start of the epoch: mem (CPU python)=17191.86328125MB; mem (CPU total)=17001.05859375MB
INFO:root:[   79] Training loss: 0.62204868, Validation loss: 0.61345949, Gradient norm: 0.06488930
INFO:root:At the start of the epoch: mem (CPU python)=17229.95703125MB; mem (CPU total)=17039.203125MB
INFO:root:[   80] Training loss: 0.62168473, Validation loss: 0.61286763, Gradient norm: 0.06186081
INFO:root:At the start of the epoch: mem (CPU python)=17268.0546875MB; mem (CPU total)=17076.83984375MB
INFO:root:[   81] Training loss: 0.62146042, Validation loss: 0.61342929, Gradient norm: 0.05684185
INFO:root:At the start of the epoch: mem (CPU python)=17306.1484375MB; mem (CPU total)=17114.9921875MB
INFO:root:[   82] Training loss: 0.62128024, Validation loss: 0.61299735, Gradient norm: 0.05543541
INFO:root:At the start of the epoch: mem (CPU python)=17344.2421875MB; mem (CPU total)=17153.125MB
INFO:root:[   83] Training loss: 0.62114776, Validation loss: 0.61298882, Gradient norm: 0.06467663
INFO:root:At the start of the epoch: mem (CPU python)=17382.33984375MB; mem (CPU total)=17191.55078125MB
INFO:root:[   84] Training loss: 0.62073349, Validation loss: 0.61214683, Gradient norm: 0.06090658
INFO:root:At the start of the epoch: mem (CPU python)=17420.4375MB; mem (CPU total)=17229.65625MB
INFO:root:[   85] Training loss: 0.62048483, Validation loss: 0.61232479, Gradient norm: 0.05686506
INFO:root:At the start of the epoch: mem (CPU python)=17458.52734375MB; mem (CPU total)=17267.765625MB
INFO:root:[   86] Training loss: 0.62001476, Validation loss: 0.61212031, Gradient norm: 0.05953212
INFO:root:At the start of the epoch: mem (CPU python)=17496.625MB; mem (CPU total)=17305.92578125MB
INFO:root:[   87] Training loss: 0.61995773, Validation loss: 0.61210322, Gradient norm: 0.05979080
INFO:root:At the start of the epoch: mem (CPU python)=17534.72265625MB; mem (CPU total)=17344.06640625MB
INFO:root:[   88] Training loss: 0.61983655, Validation loss: 0.61244111, Gradient norm: 0.06393999
INFO:root:At the start of the epoch: mem (CPU python)=17572.81640625MB; mem (CPU total)=17381.96484375MB
INFO:root:[   89] Training loss: 0.61943385, Validation loss: 0.61218901, Gradient norm: 0.06097547
INFO:root:At the start of the epoch: mem (CPU python)=17610.91015625MB; mem (CPU total)=17420.109375MB
INFO:root:[   90] Training loss: 0.61954459, Validation loss: 0.61181267, Gradient norm: 0.05892496
INFO:root:At the start of the epoch: mem (CPU python)=17649.0078125MB; mem (CPU total)=17458.5MB
INFO:root:[   91] Training loss: 0.61943323, Validation loss: 0.61187433, Gradient norm: 0.06451588
INFO:root:At the start of the epoch: mem (CPU python)=17687.1015625MB; mem (CPU total)=17496.64453125MB
INFO:root:[   92] Training loss: 0.61870627, Validation loss: 0.61205070, Gradient norm: 0.06495441
INFO:root:At the start of the epoch: mem (CPU python)=17725.1953125MB; mem (CPU total)=17534.765625MB
INFO:root:[   93] Training loss: 0.61876536, Validation loss: 0.61110169, Gradient norm: 0.06552543
INFO:root:At the start of the epoch: mem (CPU python)=17763.2890625MB; mem (CPU total)=17572.8984375MB
INFO:root:[   94] Training loss: 0.61851090, Validation loss: 0.61033742, Gradient norm: 0.06091070
INFO:root:At the start of the epoch: mem (CPU python)=17801.38671875MB; mem (CPU total)=17611.0703125MB
INFO:root:[   95] Training loss: 0.61819286, Validation loss: 0.61220179, Gradient norm: 0.06506451
INFO:root:At the start of the epoch: mem (CPU python)=17839.484375MB; mem (CPU total)=17649.73828125MB
INFO:root:[   96] Training loss: 0.61810868, Validation loss: 0.61140898, Gradient norm: 0.05998688
INFO:root:At the start of the epoch: mem (CPU python)=17877.578125MB; mem (CPU total)=17687.86328125MB
INFO:root:[   97] Training loss: 0.61765670, Validation loss: 0.61043591, Gradient norm: 0.05954202
INFO:root:At the start of the epoch: mem (CPU python)=17915.6796875MB; mem (CPU total)=17725.99609375MB
INFO:root:[   98] Training loss: 0.61773466, Validation loss: 0.61130266, Gradient norm: 0.06135817
INFO:root:At the start of the epoch: mem (CPU python)=17953.7734375MB; mem (CPU total)=17763.890625MB
INFO:root:[   99] Training loss: 0.61762953, Validation loss: 0.61070958, Gradient norm: 0.07091840
INFO:root:At the start of the epoch: mem (CPU python)=17991.8671875MB; mem (CPU total)=17802.00390625MB
INFO:root:[  100] Training loss: 0.61718544, Validation loss: 0.61016595, Gradient norm: 0.06077597
INFO:root:At the start of the epoch: mem (CPU python)=18029.96484375MB; mem (CPU total)=17840.1796875MB
INFO:root:[  101] Training loss: 0.61708550, Validation loss: 0.61025275, Gradient norm: 0.06546954
INFO:root:At the start of the epoch: mem (CPU python)=18068.05859375MB; mem (CPU total)=17879.09375MB
INFO:root:[  102] Training loss: 0.61715011, Validation loss: 0.60939184, Gradient norm: 0.06845596
INFO:root:At the start of the epoch: mem (CPU python)=18106.15234375MB; mem (CPU total)=17918.52734375MB
INFO:root:[  103] Training loss: 0.61676419, Validation loss: 0.60923662, Gradient norm: 0.06479313
INFO:root:At the start of the epoch: mem (CPU python)=18144.25MB; mem (CPU total)=17956.4296875MB
INFO:root:[  104] Training loss: 0.61689545, Validation loss: 0.60889291, Gradient norm: 0.06276051
INFO:root:At the start of the epoch: mem (CPU python)=18182.34765625MB; mem (CPU total)=17994.4765625MB
INFO:root:[  105] Training loss: 0.61652999, Validation loss: 0.60899954, Gradient norm: 0.06608223
INFO:root:At the start of the epoch: mem (CPU python)=18220.44140625MB; mem (CPU total)=18032.37109375MB
INFO:root:[  106] Training loss: 0.61627042, Validation loss: 0.60888190, Gradient norm: 0.06451504
INFO:root:At the start of the epoch: mem (CPU python)=18258.53515625MB; mem (CPU total)=18069.98046875MB
INFO:root:[  107] Training loss: 0.61598952, Validation loss: 0.60868192, Gradient norm: 0.06940708
INFO:root:At the start of the epoch: mem (CPU python)=18296.6328125MB; mem (CPU total)=18108.51953125MB
INFO:root:[  108] Training loss: 0.61600113, Validation loss: 0.60851666, Gradient norm: 0.06267146
INFO:root:At the start of the epoch: mem (CPU python)=18334.7265625MB; mem (CPU total)=18147.76953125MB
INFO:root:[  109] Training loss: 0.61575992, Validation loss: 0.60814254, Gradient norm: 0.06132958
INFO:root:At the start of the epoch: mem (CPU python)=18372.8203125MB; mem (CPU total)=18186.40625MB
INFO:root:[  110] Training loss: 0.61583229, Validation loss: 0.60977412, Gradient norm: 0.06429636
INFO:root:At the start of the epoch: mem (CPU python)=18410.9140625MB; mem (CPU total)=18224.62109375MB
INFO:root:[  111] Training loss: 0.61554733, Validation loss: 0.60948080, Gradient norm: 0.06450222
INFO:root:At the start of the epoch: mem (CPU python)=18449.01171875MB; mem (CPU total)=18262.46484375MB
INFO:root:[  112] Training loss: 0.61543031, Validation loss: 0.60907016, Gradient norm: 0.06847334
INFO:root:At the start of the epoch: mem (CPU python)=18487.109375MB; mem (CPU total)=18300.6484375MB
INFO:root:[  113] Training loss: 0.61516036, Validation loss: 0.60908149, Gradient norm: 0.06608033
INFO:root:At the start of the epoch: mem (CPU python)=18525.203125MB; mem (CPU total)=18338.546875MB
INFO:root:[  114] Training loss: 0.61479308, Validation loss: 0.60846140, Gradient norm: 0.06015024
INFO:root:At the start of the epoch: mem (CPU python)=18563.30859375MB; mem (CPU total)=18376.9140625MB
INFO:root:[  115] Training loss: 0.61499458, Validation loss: 0.60842660, Gradient norm: 0.06881099
INFO:root:At the start of the epoch: mem (CPU python)=18601.40234375MB; mem (CPU total)=18414.96484375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  116] Training loss: 0.61480240, Validation loss: 0.60734196, Gradient norm: 0.06341972
INFO:root:At the start of the epoch: mem (CPU python)=18639.49609375MB; mem (CPU total)=18453.0859375MB
INFO:root:[  117] Training loss: 0.61354340, Validation loss: 0.60778209, Gradient norm: 0.05793429
INFO:root:At the start of the epoch: mem (CPU python)=18677.59375MB; mem (CPU total)=18490.7578125MB
INFO:root:[  118] Training loss: 0.61359281, Validation loss: 0.60765759, Gradient norm: 0.05860980
INFO:root:At the start of the epoch: mem (CPU python)=18715.6875MB; mem (CPU total)=18528.40234375MB
INFO:root:[  119] Training loss: 0.61325690, Validation loss: 0.60795770, Gradient norm: 0.05936636
INFO:root:At the start of the epoch: mem (CPU python)=18753.78125MB; mem (CPU total)=18566.65234375MB
INFO:root:[  120] Training loss: 0.61323629, Validation loss: 0.60727365, Gradient norm: 0.05676319
INFO:root:At the start of the epoch: mem (CPU python)=18791.87890625MB; mem (CPU total)=18604.828125MB
INFO:root:[  121] Training loss: 0.61313421, Validation loss: 0.60801468, Gradient norm: 0.05628915
INFO:root:At the start of the epoch: mem (CPU python)=18829.9765625MB; mem (CPU total)=18642.9609375MB
INFO:root:[  122] Training loss: 0.61308608, Validation loss: 0.60685182, Gradient norm: 0.06132744
INFO:root:At the start of the epoch: mem (CPU python)=18868.0703125MB; mem (CPU total)=18681.1171875MB
INFO:root:[  123] Training loss: 0.61307524, Validation loss: 0.60684623, Gradient norm: 0.05982326
INFO:root:At the start of the epoch: mem (CPU python)=18906.1640625MB; mem (CPU total)=18719.015625MB
INFO:root:[  124] Training loss: 0.61304590, Validation loss: 0.60686990, Gradient norm: 0.06043849
INFO:root:At the start of the epoch: mem (CPU python)=18944.26171875MB; mem (CPU total)=18757.16015625MB
INFO:root:[  125] Training loss: 0.61285380, Validation loss: 0.60645576, Gradient norm: 0.06234388
INFO:root:At the start of the epoch: mem (CPU python)=18982.35546875MB; mem (CPU total)=18795.55078125MB
INFO:root:[  126] Training loss: 0.61267930, Validation loss: 0.60741810, Gradient norm: 0.05974373
INFO:root:At the start of the epoch: mem (CPU python)=19020.44921875MB; mem (CPU total)=18833.94140625MB
INFO:root:[  127] Training loss: 0.61256359, Validation loss: 0.60695358, Gradient norm: 0.06044307
INFO:root:At the start of the epoch: mem (CPU python)=19058.54296875MB; mem (CPU total)=18872.078125MB
INFO:root:[  128] Training loss: 0.61285276, Validation loss: 0.60772411, Gradient norm: 0.05970610
INFO:root:At the start of the epoch: mem (CPU python)=19096.64453125MB; mem (CPU total)=18910.21875MB
INFO:root:[  129] Training loss: 0.61266132, Validation loss: 0.60653070, Gradient norm: 0.05967924
INFO:root:At the start of the epoch: mem (CPU python)=19134.73828125MB; mem (CPU total)=18948.32421875MB
INFO:root:[  130] Training loss: 0.61237580, Validation loss: 0.60666137, Gradient norm: 0.05629265
INFO:root:At the start of the epoch: mem (CPU python)=19172.83203125MB; mem (CPU total)=18986.4765625MB
INFO:root:[  131] Training loss: 0.61239406, Validation loss: 0.60695743, Gradient norm: 0.05994170
INFO:root:At the start of the epoch: mem (CPU python)=19210.9296875MB; mem (CPU total)=19024.765625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  132] Training loss: 0.61236897, Validation loss: 0.60663326, Gradient norm: 0.06405773
INFO:root:At the start of the epoch: mem (CPU python)=19249.0234375MB; mem (CPU total)=19062.91015625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  133] Training loss: 0.61189766, Validation loss: 0.60664484, Gradient norm: 0.05543596
INFO:root:At the start of the epoch: mem (CPU python)=19287.1171875MB; mem (CPU total)=19100.55078125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  134] Training loss: 0.61136821, Validation loss: 0.60660717, Gradient norm: 0.05262014
INFO:root:At the start of the epoch: mem (CPU python)=19325.21484375MB; mem (CPU total)=19138.6953125MB
INFO:root:[  135] Training loss: 0.61133487, Validation loss: 0.60586314, Gradient norm: 0.05318947
INFO:root:At the start of the epoch: mem (CPU python)=19363.3125MB; mem (CPU total)=19176.83984375MB
INFO:root:[  136] Training loss: 0.61108817, Validation loss: 0.60655957, Gradient norm: 0.05117414
INFO:root:At the start of the epoch: mem (CPU python)=19401.40625MB; mem (CPU total)=19214.984375MB
INFO:root:[  137] Training loss: 0.61120477, Validation loss: 0.60671163, Gradient norm: 0.05202715
INFO:root:At the start of the epoch: mem (CPU python)=19439.50390625MB; mem (CPU total)=19253.6171875MB
INFO:root:[  138] Training loss: 0.61108153, Validation loss: 0.60619199, Gradient norm: 0.05105604
INFO:root:At the start of the epoch: mem (CPU python)=19477.6015625MB; mem (CPU total)=19291.515625MB
INFO:root:[  139] Training loss: 0.61102441, Validation loss: 0.60701770, Gradient norm: 0.05099337
INFO:root:At the start of the epoch: mem (CPU python)=19515.69921875MB; mem (CPU total)=19329.40234375MB
INFO:root:[  140] Training loss: 0.61097112, Validation loss: 0.60699551, Gradient norm: 0.05177791
INFO:root:At the start of the epoch: mem (CPU python)=19553.79296875MB; mem (CPU total)=19367.546875MB
INFO:root:[  141] Training loss: 0.61095048, Validation loss: 0.60630408, Gradient norm: 0.05362934
INFO:root:At the start of the epoch: mem (CPU python)=19591.890625MB; mem (CPU total)=19405.9296875MB
INFO:root:[  142] Training loss: 0.61085759, Validation loss: 0.60619620, Gradient norm: 0.05211990
INFO:root:At the start of the epoch: mem (CPU python)=19629.984375MB; mem (CPU total)=19444.5390625MB
INFO:root:[  143] Training loss: 0.61100312, Validation loss: 0.60688061, Gradient norm: 0.05304959
INFO:root:At the start of the epoch: mem (CPU python)=19668.078125MB; mem (CPU total)=19482.43359375MB
INFO:root:[  144] Training loss: 0.61111100, Validation loss: 0.60605170, Gradient norm: 0.05187454
INFO:root:At the start of the epoch: mem (CPU python)=19706.171875MB; mem (CPU total)=19520.578125MB
INFO:root:EP 144: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19744.2734375MB; mem (CPU total)=19558.72265625MB
INFO:root:Training the model took 7216.797s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84025
INFO:root:EnergyScoreTrain: 0.59152
INFO:root:CRPSTrain: 0.45854
INFO:root:Gaussian NLLTrain: 1.19553
INFO:root:CoverageTrain: 0.94721
INFO:root:IntervalWidthTrain: 3.23062
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86139
INFO:root:EnergyScoreValidation: 0.60632
INFO:root:CRPSValidation: 0.47125
INFO:root:Gaussian NLLValidation: 1.22511
INFO:root:CoverageValidation: 0.94056
INFO:root:IntervalWidthValidation: 3.23591
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86283
INFO:root:EnergyScoreTest: 0.60732
INFO:root:CRPSTest: 0.472
INFO:root:Gaussian NLLTest: 1.22722
INFO:root:CoverageTest: 0.94019
INFO:root:IntervalWidthTest: 3.235
INFO:root:After validation: mem (CPU python)=19845.9296875MB; mem (CPU total)=19602.38671875MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=19845.9296875MB; mem (CPU total)=19602.38671875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=19845.9296875MB; mem (CPU total)=19602.87890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=19845.9296875MB; mem (CPU total)=19603.125MB
INFO:root:[    1] Training loss: 0.72412729, Validation loss: 0.72077068, Gradient norm: 0.01374056
INFO:root:At the start of the epoch: mem (CPU python)=19845.9296875MB; mem (CPU total)=19642.55078125MB
INFO:root:[    2] Training loss: 0.71993050, Validation loss: 0.71875774, Gradient norm: 0.00544547
INFO:root:At the start of the epoch: mem (CPU python)=19863.7265625MB; mem (CPU total)=19680.7109375MB
INFO:root:[    3] Training loss: 0.71828197, Validation loss: 0.71648569, Gradient norm: 0.00708493
INFO:root:At the start of the epoch: mem (CPU python)=19908.08203125MB; mem (CPU total)=19725.09765625MB
INFO:root:[    4] Training loss: 0.71222417, Validation loss: 0.70543549, Gradient norm: 0.01821511
INFO:root:At the start of the epoch: mem (CPU python)=19946.19921875MB; mem (CPU total)=19763.25MB
INFO:root:[    5] Training loss: 0.70433379, Validation loss: 0.69837110, Gradient norm: 0.02268887
INFO:root:At the start of the epoch: mem (CPU python)=19984.30859375MB; mem (CPU total)=19801.64453125MB
INFO:root:[    6] Training loss: 0.69837657, Validation loss: 0.69231866, Gradient norm: 0.03107772
INFO:root:At the start of the epoch: mem (CPU python)=20027.49609375MB; mem (CPU total)=19844.5625MB
INFO:root:[    7] Training loss: 0.69286787, Validation loss: 0.68632527, Gradient norm: 0.02670785
INFO:root:At the start of the epoch: mem (CPU python)=20065.59765625MB; mem (CPU total)=19882.95703125MB
INFO:root:[    8] Training loss: 0.68868412, Validation loss: 0.68200629, Gradient norm: 0.03063792
INFO:root:At the start of the epoch: mem (CPU python)=20072.42578125MB; mem (CPU total)=19887.6796875MB
INFO:root:[    9] Training loss: 0.68471684, Validation loss: 0.67738824, Gradient norm: 0.02851601
INFO:root:At the start of the epoch: mem (CPU python)=20135.5234375MB; mem (CPU total)=19950.34375MB
INFO:root:[   10] Training loss: 0.68180655, Validation loss: 0.67468312, Gradient norm: 0.03037677
INFO:root:At the start of the epoch: mem (CPU python)=20173.6171875MB; mem (CPU total)=19988.5078125MB
INFO:root:[   11] Training loss: 0.67882851, Validation loss: 0.67048519, Gradient norm: 0.03061503
INFO:root:At the start of the epoch: mem (CPU python)=20224.21875MB; mem (CPU total)=20038.921875MB
INFO:root:[   12] Training loss: 0.67628858, Validation loss: 0.66943933, Gradient norm: 0.03007574
INFO:root:At the start of the epoch: mem (CPU python)=20224.80859375MB; mem (CPU total)=20039.2421875MB
INFO:root:[   13] Training loss: 0.67404413, Validation loss: 0.66626118, Gradient norm: 0.03318881
INFO:root:At the start of the epoch: mem (CPU python)=20312.90625MB; mem (CPU total)=20127.43359375MB
INFO:root:[   14] Training loss: 0.67209173, Validation loss: 0.66408937, Gradient norm: 0.03078480
INFO:root:At the start of the epoch: mem (CPU python)=20326.0MB; mem (CPU total)=20140.69921875MB
INFO:root:[   15] Training loss: 0.67018308, Validation loss: 0.66207543, Gradient norm: 0.03359510
INFO:root:At the start of the epoch: mem (CPU python)=20370.35546875MB; mem (CPU total)=20185.109375MB
INFO:root:[   16] Training loss: 0.66824305, Validation loss: 0.66016059, Gradient norm: 0.03219401
INFO:root:At the start of the epoch: mem (CPU python)=20414.6953125MB; mem (CPU total)=20229.05859375MB
INFO:root:[   17] Training loss: 0.66653972, Validation loss: 0.65811527, Gradient norm: 0.03434252
INFO:root:At the start of the epoch: mem (CPU python)=20452.7890625MB; mem (CPU total)=20267.66796875MB
INFO:root:[   18] Training loss: 0.66488051, Validation loss: 0.65664072, Gradient norm: 0.03357736
INFO:root:At the start of the epoch: mem (CPU python)=20497.13671875MB; mem (CPU total)=20311.98828125MB
INFO:root:[   19] Training loss: 0.66336948, Validation loss: 0.65489638, Gradient norm: 0.03732631
INFO:root:At the start of the epoch: mem (CPU python)=20535.23046875MB; mem (CPU total)=20349.90625MB
INFO:root:[   20] Training loss: 0.66186210, Validation loss: 0.65251408, Gradient norm: 0.03729884
INFO:root:At the start of the epoch: mem (CPU python)=20567.07421875MB; mem (CPU total)=20383.82421875MB
INFO:root:[   21] Training loss: 0.66015057, Validation loss: 0.65087926, Gradient norm: 0.03587017
INFO:root:At the start of the epoch: mem (CPU python)=20605.171875MB; mem (CPU total)=20420.26171875MB
INFO:root:[   22] Training loss: 0.65866044, Validation loss: 0.65037102, Gradient norm: 0.03599782
INFO:root:At the start of the epoch: mem (CPU python)=20643.265625MB; mem (CPU total)=20458.453125MB
INFO:root:[   23] Training loss: 0.65751112, Validation loss: 0.64789552, Gradient norm: 0.03465726
INFO:root:At the start of the epoch: mem (CPU python)=20681.36328125MB; mem (CPU total)=20497.08203125MB
INFO:root:[   24] Training loss: 0.65597325, Validation loss: 0.64681920, Gradient norm: 0.03839452
INFO:root:At the start of the epoch: mem (CPU python)=20719.4609375MB; mem (CPU total)=20535.25MB
INFO:root:[   25] Training loss: 0.65487877, Validation loss: 0.64601146, Gradient norm: 0.03970406
INFO:root:At the start of the epoch: mem (CPU python)=20757.5546875MB; mem (CPU total)=20573.60546875MB
INFO:root:[   26] Training loss: 0.65364944, Validation loss: 0.64444784, Gradient norm: 0.03936737
INFO:root:At the start of the epoch: mem (CPU python)=20795.6484375MB; mem (CPU total)=20611.51953125MB
INFO:root:[   27] Training loss: 0.65234211, Validation loss: 0.64301866, Gradient norm: 0.04185336
INFO:root:At the start of the epoch: mem (CPU python)=20833.7421875MB; mem (CPU total)=20649.93359375MB
INFO:root:[   28] Training loss: 0.65132538, Validation loss: 0.64213669, Gradient norm: 0.03854173
INFO:root:At the start of the epoch: mem (CPU python)=20871.84375MB; mem (CPU total)=20688.11328125MB
INFO:root:[   29] Training loss: 0.65056700, Validation loss: 0.64039875, Gradient norm: 0.04196233
INFO:root:At the start of the epoch: mem (CPU python)=20916.1875MB; mem (CPU total)=20732.7109375MB
INFO:root:[   30] Training loss: 0.64957389, Validation loss: 0.63946333, Gradient norm: 0.04281679
INFO:root:At the start of the epoch: mem (CPU python)=20954.28125MB; mem (CPU total)=20770.3828125MB
INFO:root:[   31] Training loss: 0.64884927, Validation loss: 0.63910648, Gradient norm: 0.04393847
INFO:root:At the start of the epoch: mem (CPU python)=20955.04296875MB; mem (CPU total)=20770.94921875MB
INFO:root:[   32] Training loss: 0.64789731, Validation loss: 0.63775259, Gradient norm: 0.04755685
INFO:root:At the start of the epoch: mem (CPU python)=21024.2265625MB; mem (CPU total)=20840.49609375MB
INFO:root:[   33] Training loss: 0.64677138, Validation loss: 0.63747815, Gradient norm: 0.04588737
INFO:root:At the start of the epoch: mem (CPU python)=21068.5703125MB; mem (CPU total)=20884.87890625MB
INFO:root:[   34] Training loss: 0.64654177, Validation loss: 0.63607330, Gradient norm: 0.05021399
INFO:root:At the start of the epoch: mem (CPU python)=21106.6640625MB; mem (CPU total)=20923.53515625MB
INFO:root:[   35] Training loss: 0.64547927, Validation loss: 0.63546558, Gradient norm: 0.04328597
INFO:root:At the start of the epoch: mem (CPU python)=21113.5078125MB; mem (CPU total)=20929.3359375MB
INFO:root:[   36] Training loss: 0.64464834, Validation loss: 0.63530340, Gradient norm: 0.04294039
INFO:root:At the start of the epoch: mem (CPU python)=21176.609375MB; mem (CPU total)=20992.65234375MB
INFO:root:[   37] Training loss: 0.64400129, Validation loss: 0.63369670, Gradient norm: 0.04987540
INFO:root:At the start of the epoch: mem (CPU python)=21214.703125MB; mem (CPU total)=21031.0546875MB
INFO:root:[   38] Training loss: 0.64345106, Validation loss: 0.63381590, Gradient norm: 0.04718259
INFO:root:At the start of the epoch: mem (CPU python)=21252.80078125MB; mem (CPU total)=21068.9765625MB
INFO:root:[   39] Training loss: 0.64269969, Validation loss: 0.63310258, Gradient norm: 0.04758843
INFO:root:At the start of the epoch: mem (CPU python)=21297.14453125MB; mem (CPU total)=21113.8125MB
INFO:root:[   40] Training loss: 0.64211338, Validation loss: 0.63230901, Gradient norm: 0.04525977
INFO:root:At the start of the epoch: mem (CPU python)=21335.2421875MB; mem (CPU total)=21151.7265625MB
INFO:root:[   41] Training loss: 0.64153848, Validation loss: 0.63085793, Gradient norm: 0.04119472
INFO:root:At the start of the epoch: mem (CPU python)=21344.9609375MB; mem (CPU total)=21162.96484375MB
INFO:root:[   42] Training loss: 0.64080766, Validation loss: 0.63089191, Gradient norm: 0.04866966
INFO:root:At the start of the epoch: mem (CPU python)=21395.5546875MB; mem (CPU total)=21213.80859375MB
INFO:root:[   43] Training loss: 0.64039257, Validation loss: 0.62988195, Gradient norm: 0.04783234
INFO:root:At the start of the epoch: mem (CPU python)=21433.6484375MB; mem (CPU total)=21251.9609375MB
INFO:root:[   44] Training loss: 0.63984040, Validation loss: 0.63032080, Gradient norm: 0.05360708
INFO:root:At the start of the epoch: mem (CPU python)=21475.12890625MB; mem (CPU total)=21293.6015625MB
INFO:root:[   45] Training loss: 0.63929949, Validation loss: 0.62987856, Gradient norm: 0.04740557
INFO:root:At the start of the epoch: mem (CPU python)=21513.2265625MB; mem (CPU total)=21331.24609375MB
INFO:root:[   46] Training loss: 0.63865446, Validation loss: 0.62823183, Gradient norm: 0.04801491
INFO:root:At the start of the epoch: mem (CPU python)=21532.55859375MB; mem (CPU total)=21348.58203125MB
INFO:root:[   47] Training loss: 0.63822324, Validation loss: 0.62797812, Gradient norm: 0.05019231
INFO:root:At the start of the epoch: mem (CPU python)=21589.41796875MB; mem (CPU total)=21405.54296875MB
INFO:root:[   48] Training loss: 0.63800616, Validation loss: 0.62942265, Gradient norm: 0.05414305
INFO:root:At the start of the epoch: mem (CPU python)=21640.0078125MB; mem (CPU total)=21456.12890625MB
INFO:root:[   49] Training loss: 0.63747853, Validation loss: 0.62736198, Gradient norm: 0.05115529
INFO:root:At the start of the epoch: mem (CPU python)=21678.1015625MB; mem (CPU total)=21494.296875MB
INFO:root:[   50] Training loss: 0.63697873, Validation loss: 0.62677611, Gradient norm: 0.04980810
INFO:root:At the start of the epoch: mem (CPU python)=21708.4765625MB; mem (CPU total)=21519.2578125MB
INFO:root:[   51] Training loss: 0.63654722, Validation loss: 0.62676329, Gradient norm: 0.05051202
INFO:root:At the start of the epoch: mem (CPU python)=21740.5390625MB; mem (CPU total)=21557.1640625MB
INFO:root:[   52] Training loss: 0.63633342, Validation loss: 0.62625715, Gradient norm: 0.05492289
INFO:root:At the start of the epoch: mem (CPU python)=21786.13671875MB; mem (CPU total)=21603.0390625MB
INFO:root:[   53] Training loss: 0.63575588, Validation loss: 0.62593060, Gradient norm: 0.05179726
INFO:root:At the start of the epoch: mem (CPU python)=21824.23046875MB; mem (CPU total)=21641.34765625MB
INFO:root:[   54] Training loss: 0.63535124, Validation loss: 0.62506781, Gradient norm: 0.04962849
INFO:root:At the start of the epoch: mem (CPU python)=21862.32421875MB; mem (CPU total)=21679.3671875MB
INFO:root:[   55] Training loss: 0.63514464, Validation loss: 0.62539987, Gradient norm: 0.05418749
INFO:root:At the start of the epoch: mem (CPU python)=21900.421875MB; mem (CPU total)=21717.92578125MB
INFO:root:[   56] Training loss: 0.63461676, Validation loss: 0.62475701, Gradient norm: 0.04950818
INFO:root:At the start of the epoch: mem (CPU python)=21926.015625MB; mem (CPU total)=21743.20703125MB
INFO:root:[   57] Training loss: 0.63413809, Validation loss: 0.62368549, Gradient norm: 0.05461418
INFO:root:At the start of the epoch: mem (CPU python)=21964.109375MB; mem (CPU total)=21781.27734375MB
INFO:root:[   58] Training loss: 0.63403640, Validation loss: 0.62553677, Gradient norm: 0.05587439
INFO:root:At the start of the epoch: mem (CPU python)=22002.20703125MB; mem (CPU total)=21819.18359375MB
INFO:root:[   59] Training loss: 0.63346290, Validation loss: 0.62407952, Gradient norm: 0.05567435
INFO:root:At the start of the epoch: mem (CPU python)=22040.30078125MB; mem (CPU total)=21857.3359375MB
INFO:root:[   60] Training loss: 0.63308208, Validation loss: 0.62285412, Gradient norm: 0.04961642
INFO:root:At the start of the epoch: mem (CPU python)=22078.39453125MB; mem (CPU total)=21895.78125MB
INFO:root:[   61] Training loss: 0.63286095, Validation loss: 0.62254957, Gradient norm: 0.05370418
INFO:root:At the start of the epoch: mem (CPU python)=22116.48828125MB; mem (CPU total)=21933.9140625MB
INFO:root:[   62] Training loss: 0.63247456, Validation loss: 0.62289341, Gradient norm: 0.05526688
INFO:root:At the start of the epoch: mem (CPU python)=22154.5859375MB; mem (CPU total)=21972.08203125MB
INFO:root:[   63] Training loss: 0.63205258, Validation loss: 0.62210553, Gradient norm: 0.05087597
INFO:root:At the start of the epoch: mem (CPU python)=22192.68359375MB; mem (CPU total)=22009.9765625MB
INFO:root:[   64] Training loss: 0.63186036, Validation loss: 0.62210255, Gradient norm: 0.05418856
INFO:root:At the start of the epoch: mem (CPU python)=22249.52734375MB; mem (CPU total)=22066.390625MB
INFO:root:[   65] Training loss: 0.63150053, Validation loss: 0.62163426, Gradient norm: 0.05454771
INFO:root:At the start of the epoch: mem (CPU python)=22287.62890625MB; mem (CPU total)=22104.30859375MB
INFO:root:[   66] Training loss: 0.63118454, Validation loss: 0.62162873, Gradient norm: 0.06126602
INFO:root:At the start of the epoch: mem (CPU python)=22318.046875MB; mem (CPU total)=22116.5703125MB
INFO:root:[   67] Training loss: 0.63079362, Validation loss: 0.62080702, Gradient norm: 0.05362300
INFO:root:At the start of the epoch: mem (CPU python)=22357.56640625MB; mem (CPU total)=22173.15625MB
INFO:root:[   68] Training loss: 0.63060008, Validation loss: 0.62142446, Gradient norm: 0.06005619
INFO:root:At the start of the epoch: mem (CPU python)=22395.6640625MB; mem (CPU total)=22211.30859375MB
INFO:root:[   69] Training loss: 0.63047353, Validation loss: 0.62094709, Gradient norm: 0.05682718
INFO:root:At the start of the epoch: mem (CPU python)=22433.76171875MB; mem (CPU total)=22249.359375MB
INFO:root:[   70] Training loss: 0.62964067, Validation loss: 0.61978256, Gradient norm: 0.05443614
INFO:root:At the start of the epoch: mem (CPU python)=22440.6015625MB; mem (CPU total)=22256.35546875MB
INFO:root:[   71] Training loss: 0.62981999, Validation loss: 0.61914471, Gradient norm: 0.05559657
INFO:root:At the start of the epoch: mem (CPU python)=22497.4453125MB; mem (CPU total)=22313.546875MB
INFO:root:[   72] Training loss: 0.62933470, Validation loss: 0.61966876, Gradient norm: 0.05357313
INFO:root:At the start of the epoch: mem (CPU python)=22535.54296875MB; mem (CPU total)=22351.4296875MB
INFO:root:[   73] Training loss: 0.62933439, Validation loss: 0.61924155, Gradient norm: 0.05356805
INFO:root:At the start of the epoch: mem (CPU python)=22573.63671875MB; mem (CPU total)=22389.34375MB
INFO:root:[   74] Training loss: 0.62883422, Validation loss: 0.61915231, Gradient norm: 0.05760298
INFO:root:At the start of the epoch: mem (CPU python)=22611.734375MB; mem (CPU total)=22427.23046875MB
INFO:root:[   75] Training loss: 0.62841191, Validation loss: 0.61974676, Gradient norm: 0.05618859
INFO:root:At the start of the epoch: mem (CPU python)=22649.83203125MB; mem (CPU total)=22465.62109375MB
INFO:root:[   76] Training loss: 0.62865149, Validation loss: 0.61826181, Gradient norm: 0.05756357
INFO:root:At the start of the epoch: mem (CPU python)=22700.4296875MB; mem (CPU total)=22515.94140625MB
INFO:root:[   77] Training loss: 0.62809641, Validation loss: 0.61812154, Gradient norm: 0.05685154
INFO:root:At the start of the epoch: mem (CPU python)=22732.28125MB; mem (CPU total)=22548.0859375MB
INFO:root:[   78] Training loss: 0.62792026, Validation loss: 0.61904525, Gradient norm: 0.05402329
INFO:root:At the start of the epoch: mem (CPU python)=22770.375MB; mem (CPU total)=22586.4765625MB
INFO:root:[   79] Training loss: 0.62767920, Validation loss: 0.61820212, Gradient norm: 0.06239172
INFO:root:At the start of the epoch: mem (CPU python)=22808.47265625MB; mem (CPU total)=22624.60546875MB
INFO:root:[   80] Training loss: 0.62731668, Validation loss: 0.61836039, Gradient norm: 0.05544385
INFO:root:At the start of the epoch: mem (CPU python)=22865.30859375MB; mem (CPU total)=22681.66796875MB
INFO:root:[   81] Training loss: 0.62699915, Validation loss: 0.61814567, Gradient norm: 0.05391821
INFO:root:At the start of the epoch: mem (CPU python)=22903.40625MB; mem (CPU total)=22719.80078125MB
INFO:root:[   82] Training loss: 0.62678691, Validation loss: 0.61727849, Gradient norm: 0.05310087
INFO:root:At the start of the epoch: mem (CPU python)=22903.859375MB; mem (CPU total)=22703.375MB
INFO:root:[   83] Training loss: 0.62682319, Validation loss: 0.61714577, Gradient norm: 0.05772828
INFO:root:At the start of the epoch: mem (CPU python)=22935.84375MB; mem (CPU total)=22753.9375MB
INFO:root:[   84] Training loss: 0.62644865, Validation loss: 0.61698582, Gradient norm: 0.05976924
INFO:root:At the start of the epoch: mem (CPU python)=23006.6953125MB; mem (CPU total)=22825.15625MB
INFO:root:[   85] Training loss: 0.62619752, Validation loss: 0.61726683, Gradient norm: 0.05858906
INFO:root:At the start of the epoch: mem (CPU python)=23037.04296875MB; mem (CPU total)=22853.671875MB
INFO:root:[   86] Training loss: 0.62621091, Validation loss: 0.61647251, Gradient norm: 0.05739978
INFO:root:At the start of the epoch: mem (CPU python)=23067.5234375MB; mem (CPU total)=22873.140625MB
INFO:root:[   87] Training loss: 0.62563998, Validation loss: 0.61669294, Gradient norm: 0.05626800
INFO:root:At the start of the epoch: mem (CPU python)=23106.97265625MB; mem (CPU total)=22923.72265625MB
INFO:root:[   88] Training loss: 0.62579180, Validation loss: 0.61641681, Gradient norm: 0.06232745
INFO:root:At the start of the epoch: mem (CPU python)=23145.0703125MB; mem (CPU total)=22962.015625MB
INFO:root:[   89] Training loss: 0.62541897, Validation loss: 0.61598043, Gradient norm: 0.05949995
INFO:root:At the start of the epoch: mem (CPU python)=23192.54296875MB; mem (CPU total)=23009.3515625MB
INFO:root:[   90] Training loss: 0.62514028, Validation loss: 0.61603952, Gradient norm: 0.06081851
INFO:root:At the start of the epoch: mem (CPU python)=23230.640625MB; mem (CPU total)=23047.453125MB
INFO:root:[   91] Training loss: 0.62502560, Validation loss: 0.61593435, Gradient norm: 0.05529815
INFO:root:At the start of the epoch: mem (CPU python)=23261.09765625MB; mem (CPU total)=23064.20703125MB
INFO:root:[   92] Training loss: 0.62488091, Validation loss: 0.61584976, Gradient norm: 0.06289808
INFO:root:At the start of the epoch: mem (CPU python)=23316.20703125MB; mem (CPU total)=23133.64453125MB
INFO:root:[   93] Training loss: 0.62475553, Validation loss: 0.61590695, Gradient norm: 0.05813171
INFO:root:At the start of the epoch: mem (CPU python)=23354.30078125MB; mem (CPU total)=23171.75MB
INFO:root:[   94] Training loss: 0.62443715, Validation loss: 0.61502776, Gradient norm: 0.06129152
INFO:root:At the start of the epoch: mem (CPU python)=23398.64453125MB; mem (CPU total)=23216.10546875MB
INFO:root:[   95] Training loss: 0.62436023, Validation loss: 0.61560040, Gradient norm: 0.05673848
INFO:root:At the start of the epoch: mem (CPU python)=23429.12109375MB; mem (CPU total)=23203.9765625MB
INFO:root:[   96] Training loss: 0.62420548, Validation loss: 0.61516167, Gradient norm: 0.06074301
INFO:root:At the start of the epoch: mem (CPU python)=23456.09765625MB; mem (CPU total)=23273.2265625MB
INFO:root:[   97] Training loss: 0.62393959, Validation loss: 0.61483461, Gradient norm: 0.05747415
INFO:root:At the start of the epoch: mem (CPU python)=23494.1875MB; mem (CPU total)=23311.40234375MB
INFO:root:[   98] Training loss: 0.62383364, Validation loss: 0.61528302, Gradient norm: 0.06129209
INFO:root:At the start of the epoch: mem (CPU python)=23544.77734375MB; mem (CPU total)=23362.0078125MB
INFO:root:[   99] Training loss: 0.62364296, Validation loss: 0.61490017, Gradient norm: 0.05785064
INFO:root:At the start of the epoch: mem (CPU python)=23582.875MB; mem (CPU total)=23400.3984375MB
INFO:root:[  100] Training loss: 0.62371229, Validation loss: 0.61466440, Gradient norm: 0.06502268
INFO:root:At the start of the epoch: mem (CPU python)=23620.96875MB; mem (CPU total)=23438.515625MB
INFO:root:[  101] Training loss: 0.62337573, Validation loss: 0.61444350, Gradient norm: 0.06193681
INFO:root:At the start of the epoch: mem (CPU python)=23659.0625MB; mem (CPU total)=23476.4140625MB
INFO:root:[  102] Training loss: 0.62301121, Validation loss: 0.61451936, Gradient norm: 0.05783025
INFO:root:At the start of the epoch: mem (CPU python)=23697.15625MB; mem (CPU total)=23515.04296875MB
INFO:root:[  103] Training loss: 0.62284144, Validation loss: 0.61399667, Gradient norm: 0.05819039
INFO:root:At the start of the epoch: mem (CPU python)=23704.0MB; mem (CPU total)=23521.94921875MB
INFO:root:[  104] Training loss: 0.62273094, Validation loss: 0.61493809, Gradient norm: 0.05748560
INFO:root:At the start of the epoch: mem (CPU python)=23760.85546875MB; mem (CPU total)=23578.7578125MB
INFO:root:[  105] Training loss: 0.62268207, Validation loss: 0.61327487, Gradient norm: 0.06284676
INFO:root:At the start of the epoch: mem (CPU python)=23805.19140625MB; mem (CPU total)=23622.87109375MB
INFO:root:[  106] Training loss: 0.62245869, Validation loss: 0.61412519, Gradient norm: 0.06749226
INFO:root:At the start of the epoch: mem (CPU python)=23835.60546875MB; mem (CPU total)=23642.30859375MB
INFO:root:[  107] Training loss: 0.62230475, Validation loss: 0.61370791, Gradient norm: 0.06180187
INFO:root:At the start of the epoch: mem (CPU python)=23875.14453125MB; mem (CPU total)=23692.9140625MB
INFO:root:[  108] Training loss: 0.62213342, Validation loss: 0.61431638, Gradient norm: 0.05818902
INFO:root:At the start of the epoch: mem (CPU python)=23906.9765625MB; mem (CPU total)=23725.05859375MB
INFO:root:[  109] Training loss: 0.62214695, Validation loss: 0.61308289, Gradient norm: 0.06091687
INFO:root:At the start of the epoch: mem (CPU python)=23951.3359375MB; mem (CPU total)=23769.203125MB
INFO:root:[  110] Training loss: 0.62167260, Validation loss: 0.61395765, Gradient norm: 0.05830770
INFO:root:At the start of the epoch: mem (CPU python)=23989.4296875MB; mem (CPU total)=23807.5859375MB
INFO:root:[  111] Training loss: 0.62129801, Validation loss: 0.61302792, Gradient norm: 0.06106791
INFO:root:At the start of the epoch: mem (CPU python)=24027.52734375MB; mem (CPU total)=23845.71875MB
INFO:root:[  112] Training loss: 0.62125368, Validation loss: 0.61226347, Gradient norm: 0.05762215
INFO:root:At the start of the epoch: mem (CPU python)=24065.62109375MB; mem (CPU total)=23884.10546875MB
INFO:root:[  113] Training loss: 0.62123242, Validation loss: 0.61392572, Gradient norm: 0.06080528
INFO:root:At the start of the epoch: mem (CPU python)=24103.71875MB; mem (CPU total)=23922.734375MB
INFO:root:[  114] Training loss: 0.62137614, Validation loss: 0.61263744, Gradient norm: 0.07121509
INFO:root:At the start of the epoch: mem (CPU python)=24141.8125MB; mem (CPU total)=23960.59375MB
INFO:root:[  115] Training loss: 0.62102340, Validation loss: 0.61289888, Gradient norm: 0.05997942
INFO:root:At the start of the epoch: mem (CPU python)=24186.15234375MB; mem (CPU total)=24004.69921875MB
INFO:root:[  116] Training loss: 0.62091374, Validation loss: 0.61287543, Gradient norm: 0.06144050
INFO:root:At the start of the epoch: mem (CPU python)=24224.25MB; mem (CPU total)=24043.08984375MB
INFO:root:[  117] Training loss: 0.62073301, Validation loss: 0.61290848, Gradient norm: 0.05877808
INFO:root:At the start of the epoch: mem (CPU python)=24262.34375MB; mem (CPU total)=24081.234375MB
INFO:root:[  118] Training loss: 0.62060645, Validation loss: 0.61314371, Gradient norm: 0.06398997
INFO:root:At the start of the epoch: mem (CPU python)=24300.4375MB; mem (CPU total)=24119.34765625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  119] Training loss: 0.62063543, Validation loss: 0.61341418, Gradient norm: 0.06224381
INFO:root:At the start of the epoch: mem (CPU python)=24338.53125MB; mem (CPU total)=24157.4921875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  120] Training loss: 0.61958250, Validation loss: 0.61181064, Gradient norm: 0.05237871
INFO:root:At the start of the epoch: mem (CPU python)=24379.75390625MB; mem (CPU total)=24198.8359375MB
INFO:root:[  121] Training loss: 0.61888014, Validation loss: 0.61153620, Gradient norm: 0.04958148
INFO:root:At the start of the epoch: mem (CPU python)=24383.46875MB; mem (CPU total)=24202.63671875MB
INFO:root:[  122] Training loss: 0.61896758, Validation loss: 0.61164302, Gradient norm: 0.05225978
INFO:root:At the start of the epoch: mem (CPU python)=24459.06640625MB; mem (CPU total)=24279.89453125MB
INFO:root:[  123] Training loss: 0.61904242, Validation loss: 0.61149123, Gradient norm: 0.05113987
INFO:root:At the start of the epoch: mem (CPU python)=24497.05859375MB; mem (CPU total)=24257.53515625MB
INFO:root:[  124] Training loss: 0.61902202, Validation loss: 0.61154798, Gradient norm: 0.05154838
INFO:root:At the start of the epoch: mem (CPU python)=24497.75390625MB; mem (CPU total)=24320.0078125MB
INFO:root:[  125] Training loss: 0.61858780, Validation loss: 0.61157674, Gradient norm: 0.05185756
INFO:root:At the start of the epoch: mem (CPU python)=24560.86328125MB; mem (CPU total)=24383.28125MB
INFO:root:[  126] Training loss: 0.61863113, Validation loss: 0.61084118, Gradient norm: 0.04940453
INFO:root:At the start of the epoch: mem (CPU python)=24598.9609375MB; mem (CPU total)=24421.1484375MB
INFO:root:[  127] Training loss: 0.61862614, Validation loss: 0.61142549, Gradient norm: 0.05290752
INFO:root:At the start of the epoch: mem (CPU python)=24637.0546875MB; mem (CPU total)=24457.5703125MB
INFO:root:[  128] Training loss: 0.61865588, Validation loss: 0.61050367, Gradient norm: 0.05346594
INFO:root:At the start of the epoch: mem (CPU python)=24675.1484375MB; mem (CPU total)=24495.46875MB
INFO:root:[  129] Training loss: 0.61859573, Validation loss: 0.61056407, Gradient norm: 0.05129785
INFO:root:At the start of the epoch: mem (CPU python)=24713.2421875MB; mem (CPU total)=24533.859375MB
INFO:root:[  130] Training loss: 0.61850360, Validation loss: 0.61114157, Gradient norm: 0.05312724
INFO:root:At the start of the epoch: mem (CPU python)=24751.33984375MB; mem (CPU total)=24572.00390625MB
INFO:root:[  131] Training loss: 0.61831524, Validation loss: 0.61124751, Gradient norm: 0.05299117
INFO:root:At the start of the epoch: mem (CPU python)=24789.4375MB; mem (CPU total)=24610.1328125MB
INFO:root:[  132] Training loss: 0.61851896, Validation loss: 0.61187572, Gradient norm: 0.05358811
INFO:root:At the start of the epoch: mem (CPU python)=24827.52734375MB; mem (CPU total)=24648.73828125MB
INFO:root:[  133] Training loss: 0.61825788, Validation loss: 0.61153924, Gradient norm: 0.05504493
INFO:root:At the start of the epoch: mem (CPU python)=24865.625MB; mem (CPU total)=24686.328125MB
INFO:root:[  134] Training loss: 0.61845255, Validation loss: 0.61183296, Gradient norm: 0.05497296
INFO:root:At the start of the epoch: mem (CPU python)=24891.2109375MB; mem (CPU total)=24711.75MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  135] Training loss: 0.61830454, Validation loss: 0.61152800, Gradient norm: 0.05188914
INFO:root:At the start of the epoch: mem (CPU python)=24929.3046875MB; mem (CPU total)=24749.80859375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  136] Training loss: 0.61815895, Validation loss: 0.61050236, Gradient norm: 0.05189160
INFO:root:At the start of the epoch: mem (CPU python)=24986.15234375MB; mem (CPU total)=24806.5703125MB
INFO:root:[  137] Training loss: 0.61783288, Validation loss: 0.61071579, Gradient norm: 0.05114117
INFO:root:At the start of the epoch: mem (CPU python)=25030.5MB; mem (CPU total)=24850.9296875MB
INFO:root:[  138] Training loss: 0.61788693, Validation loss: 0.61037361, Gradient norm: 0.04842056
INFO:root:At the start of the epoch: mem (CPU python)=25068.59375MB; mem (CPU total)=24889.3515625MB
INFO:root:[  139] Training loss: 0.61772491, Validation loss: 0.61080838, Gradient norm: 0.04843265
INFO:root:At the start of the epoch: mem (CPU python)=25106.6875MB; mem (CPU total)=24927.28125MB
INFO:root:[  140] Training loss: 0.61795090, Validation loss: 0.61087867, Gradient norm: 0.05026440
INFO:root:At the start of the epoch: mem (CPU python)=25144.78515625MB; mem (CPU total)=24965.671875MB
INFO:root:[  141] Training loss: 0.61765013, Validation loss: 0.61037862, Gradient norm: 0.05123784
INFO:root:At the start of the epoch: mem (CPU python)=25182.8828125MB; mem (CPU total)=25004.05859375MB
INFO:root:[  142] Training loss: 0.61774093, Validation loss: 0.61137616, Gradient norm: 0.04862883
INFO:root:At the start of the epoch: mem (CPU python)=25220.9765625MB; mem (CPU total)=25042.44921875MB
INFO:root:[  143] Training loss: 0.61799655, Validation loss: 0.61054450, Gradient norm: 0.04817220
INFO:root:At the start of the epoch: mem (CPU python)=25259.078125MB; mem (CPU total)=25080.22265625MB
INFO:root:[  144] Training loss: 0.61773344, Validation loss: 0.61136775, Gradient norm: 0.04955970
INFO:root:At the start of the epoch: mem (CPU python)=25297.171875MB; mem (CPU total)=25118.08203125MB
INFO:root:[  145] Training loss: 0.61742224, Validation loss: 0.61021914, Gradient norm: 0.04956995
INFO:root:At the start of the epoch: mem (CPU python)=25335.265625MB; mem (CPU total)=25156.2265625MB
INFO:root:[  146] Training loss: 0.61762547, Validation loss: 0.61149605, Gradient norm: 0.05019429
INFO:root:At the start of the epoch: mem (CPU python)=25373.359375MB; mem (CPU total)=25194.6171875MB
INFO:root:[  147] Training loss: 0.61767477, Validation loss: 0.61081965, Gradient norm: 0.04970253
INFO:root:At the start of the epoch: mem (CPU python)=25411.45703125MB; mem (CPU total)=25232.515625MB
INFO:root:[  148] Training loss: 0.61765632, Validation loss: 0.61112998, Gradient norm: 0.04911150
INFO:root:At the start of the epoch: mem (CPU python)=25411.91015625MB; mem (CPU total)=25221.1328125MB
INFO:root:[  149] Training loss: 0.61779884, Validation loss: 0.61116693, Gradient norm: 0.04994718
INFO:root:At the start of the epoch: mem (CPU python)=25456.39453125MB; mem (CPU total)=25277.921875MB
INFO:root:[  150] Training loss: 0.61748477, Validation loss: 0.61157147, Gradient norm: 0.04891959
INFO:root:At the start of the epoch: mem (CPU python)=25519.49609375MB; mem (CPU total)=25340.99609375MB
INFO:root:[  151] Training loss: 0.61742073, Validation loss: 0.61132132, Gradient norm: 0.05094653
INFO:root:At the start of the epoch: mem (CPU python)=25549.80859375MB; mem (CPU total)=25359.4375MB
INFO:root:[  152] Training loss: 0.61778780, Validation loss: 0.61074467, Gradient norm: 0.05003739
INFO:root:At the start of the epoch: mem (CPU python)=25576.93359375MB; mem (CPU total)=25397.734375MB
INFO:root:[  153] Training loss: 0.61768638, Validation loss: 0.61020484, Gradient norm: 0.05035314
INFO:root:At the start of the epoch: mem (CPU python)=25615.02734375MB; mem (CPU total)=25436.33203125MB
INFO:root:[  154] Training loss: 0.61776474, Validation loss: 0.61058202, Gradient norm: 0.05009020
INFO:root:At the start of the epoch: mem (CPU python)=25665.63671875MB; mem (CPU total)=25486.89453125MB
INFO:root:[  155] Training loss: 0.61734185, Validation loss: 0.61095029, Gradient norm: 0.05038396
INFO:root:At the start of the epoch: mem (CPU python)=25709.97265625MB; mem (CPU total)=25531.0703125MB
INFO:root:[  156] Training loss: 0.61772832, Validation loss: 0.61092437, Gradient norm: 0.05008445
INFO:root:At the start of the epoch: mem (CPU python)=25748.06640625MB; mem (CPU total)=25569.4609375MB
INFO:root:[  157] Training loss: 0.61738378, Validation loss: 0.61066521, Gradient norm: 0.04915139
INFO:root:At the start of the epoch: mem (CPU python)=25786.1640625MB; mem (CPU total)=25607.359375MB
INFO:root:[  158] Training loss: 0.61783426, Validation loss: 0.61038140, Gradient norm: 0.04950782
INFO:root:At the start of the epoch: mem (CPU python)=25818.01953125MB; mem (CPU total)=25639.1875MB
INFO:root:[  159] Training loss: 0.61747659, Validation loss: 0.61068656, Gradient norm: 0.04881885
INFO:root:At the start of the epoch: mem (CPU python)=25862.35546875MB; mem (CPU total)=25683.578125MB
INFO:root:[  160] Training loss: 0.61767154, Validation loss: 0.61018191, Gradient norm: 0.05096440
INFO:root:At the start of the epoch: mem (CPU python)=25900.453125MB; mem (CPU total)=25722.0MB
INFO:root:[  161] Training loss: 0.61769872, Validation loss: 0.61052006, Gradient norm: 0.04937552
INFO:root:At the start of the epoch: mem (CPU python)=25926.04296875MB; mem (CPU total)=25747.88671875MB
INFO:root:[  162] Training loss: 0.61739126, Validation loss: 0.60994541, Gradient norm: 0.05138057
INFO:root:At the start of the epoch: mem (CPU python)=25982.890625MB; mem (CPU total)=25805.0390625MB
INFO:root:[  163] Training loss: 0.61755128, Validation loss: 0.61073282, Gradient norm: 0.05022085
INFO:root:At the start of the epoch: mem (CPU python)=26020.984375MB; mem (CPU total)=25843.18359375MB
INFO:root:[  164] Training loss: 0.61756100, Validation loss: 0.61036404, Gradient norm: 0.04912187
INFO:root:At the start of the epoch: mem (CPU python)=26051.46484375MB; mem (CPU total)=25844.0078125MB
INFO:root:[  165] Training loss: 0.61741174, Validation loss: 0.61034591, Gradient norm: 0.05105737
INFO:root:At the start of the epoch: mem (CPU python)=26059.671875MB; mem (CPU total)=25881.90625MB
INFO:root:[  166] Training loss: 0.61746736, Validation loss: 0.61063887, Gradient norm: 0.04983615
INFO:root:At the start of the epoch: mem (CPU python)=26116.515625MB; mem (CPU total)=25938.6953125MB
INFO:root:[  167] Training loss: 0.61747466, Validation loss: 0.61111620, Gradient norm: 0.05053866
INFO:root:At the start of the epoch: mem (CPU python)=26154.6171875MB; mem (CPU total)=25976.9921875MB
INFO:root:[  168] Training loss: 0.61749253, Validation loss: 0.61108904, Gradient norm: 0.05110154
INFO:root:At the start of the epoch: mem (CPU python)=26192.7109375MB; mem (CPU total)=26014.890625MB
INFO:root:[  169] Training loss: 0.61720395, Validation loss: 0.61061385, Gradient norm: 0.05066297
INFO:root:At the start of the epoch: mem (CPU python)=26243.30859375MB; mem (CPU total)=26065.52734375MB
INFO:root:[  170] Training loss: 0.61741069, Validation loss: 0.61072728, Gradient norm: 0.05164489
INFO:root:At the start of the epoch: mem (CPU python)=26281.40234375MB; mem (CPU total)=26103.91796875MB
INFO:root:[  171] Training loss: 0.61754541, Validation loss: 0.61079528, Gradient norm: 0.05110916
INFO:root:At the start of the epoch: mem (CPU python)=26319.5MB; mem (CPU total)=26142.30078125MB
INFO:root:EP 171: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=26338.71484375MB; mem (CPU total)=26161.734375MB
INFO:root:Training the model took 9837.613s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8504
INFO:root:EnergyScoreTrain: 0.59865
INFO:root:CRPSTrain: 0.46625
INFO:root:Gaussian NLLTrain: 1.20496
INFO:root:CoverageTrain: 0.94876
INFO:root:IntervalWidthTrain: 3.2855
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86772
INFO:root:EnergyScoreValidation: 0.61075
INFO:root:CRPSValidation: 0.47671
INFO:root:Gaussian NLLValidation: 1.22886
INFO:root:CoverageValidation: 0.94291
INFO:root:IntervalWidthValidation: 3.28758
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86841
INFO:root:EnergyScoreTest: 0.61122
INFO:root:CRPSTest: 0.47708
INFO:root:Gaussian NLLTest: 1.22934
INFO:root:CoverageTest: 0.94287
INFO:root:IntervalWidthTest: 3.28742
INFO:root:After validation: mem (CPU python)=26454.2734375MB; mem (CPU total)=26162.35546875MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=26454.2734375MB; mem (CPU total)=26161.95703125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=26454.2734375MB; mem (CPU total)=26161.95703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=26454.2734375MB; mem (CPU total)=26161.953125MB
INFO:root:[    1] Training loss: 0.72501462, Validation loss: 0.72094926, Gradient norm: 0.01759667
INFO:root:At the start of the epoch: mem (CPU python)=26454.2734375MB; mem (CPU total)=26218.203125MB
INFO:root:[    2] Training loss: 0.71955232, Validation loss: 0.71699096, Gradient norm: 0.00674197
INFO:root:At the start of the epoch: mem (CPU python)=26470.87890625MB; mem (CPU total)=26293.9453125MB
INFO:root:[    3] Training loss: 0.71382359, Validation loss: 0.70791880, Gradient norm: 0.01490512
INFO:root:At the start of the epoch: mem (CPU python)=26508.9921875MB; mem (CPU total)=26333.234375MB
INFO:root:[    4] Training loss: 0.70646066, Validation loss: 0.70064630, Gradient norm: 0.02139201
INFO:root:At the start of the epoch: mem (CPU python)=26547.1015625MB; mem (CPU total)=26371.421875MB
INFO:root:[    5] Training loss: 0.70098993, Validation loss: 0.69562340, Gradient norm: 0.02763055
INFO:root:At the start of the epoch: mem (CPU python)=26603.953125MB; mem (CPU total)=26428.921875MB
INFO:root:[    6] Training loss: 0.69535027, Validation loss: 0.68756153, Gradient norm: 0.02635618
INFO:root:At the start of the epoch: mem (CPU python)=26642.05859375MB; mem (CPU total)=26466.48046875MB
INFO:root:[    7] Training loss: 0.68958883, Validation loss: 0.68100326, Gradient norm: 0.03007721
INFO:root:At the start of the epoch: mem (CPU python)=26680.37109375MB; mem (CPU total)=26505.33203125MB
INFO:root:[    8] Training loss: 0.68456655, Validation loss: 0.67631607, Gradient norm: 0.02907874
INFO:root:At the start of the epoch: mem (CPU python)=26718.75MB; mem (CPU total)=26543.5703125MB
INFO:root:[    9] Training loss: 0.68033809, Validation loss: 0.67109483, Gradient norm: 0.02956582
INFO:root:At the start of the epoch: mem (CPU python)=26756.84765625MB; mem (CPU total)=26582.09765625MB
INFO:root:[   10] Training loss: 0.67644147, Validation loss: 0.66675637, Gradient norm: 0.02991948
INFO:root:At the start of the epoch: mem (CPU python)=26794.94140625MB; mem (CPU total)=26619.734375MB
INFO:root:[   11] Training loss: 0.67327417, Validation loss: 0.66342712, Gradient norm: 0.03029901
INFO:root:At the start of the epoch: mem (CPU python)=26801.78125MB; mem (CPU total)=26628.1953125MB
INFO:root:[   12] Training loss: 0.67042274, Validation loss: 0.66048002, Gradient norm: 0.03269905
INFO:root:At the start of the epoch: mem (CPU python)=26858.62890625MB; mem (CPU total)=26685.29296875MB
INFO:root:[   13] Training loss: 0.66768598, Validation loss: 0.65728483, Gradient norm: 0.03466416
INFO:root:At the start of the epoch: mem (CPU python)=26896.7265625MB; mem (CPU total)=26723.4375MB
INFO:root:[   14] Training loss: 0.66552037, Validation loss: 0.65530968, Gradient norm: 0.03248884
INFO:root:At the start of the epoch: mem (CPU python)=26897.3203125MB; mem (CPU total)=26722.26171875MB
INFO:root:[   15] Training loss: 0.66332233, Validation loss: 0.65307566, Gradient norm: 0.03416996
INFO:root:At the start of the epoch: mem (CPU python)=26954.1640625MB; mem (CPU total)=26779.296875MB
INFO:root:[   16] Training loss: 0.66165512, Validation loss: 0.65118973, Gradient norm: 0.03758183
INFO:root:At the start of the epoch: mem (CPU python)=26992.26171875MB; mem (CPU total)=26817.671875MB
INFO:root:[   17] Training loss: 0.65986042, Validation loss: 0.64951693, Gradient norm: 0.03568629
INFO:root:At the start of the epoch: mem (CPU python)=27042.8671875MB; mem (CPU total)=26868.26953125MB
INFO:root:[   18] Training loss: 0.65813471, Validation loss: 0.64822886, Gradient norm: 0.03668143
INFO:root:At the start of the epoch: mem (CPU python)=27099.703125MB; mem (CPU total)=26925.33203125MB
INFO:root:[   19] Training loss: 0.65673926, Validation loss: 0.64574222, Gradient norm: 0.04059413
INFO:root:At the start of the epoch: mem (CPU python)=27137.796875MB; mem (CPU total)=26962.0625MB
INFO:root:[   20] Training loss: 0.65525143, Validation loss: 0.64424340, Gradient norm: 0.03770139
INFO:root:At the start of the epoch: mem (CPU python)=27175.89453125MB; mem (CPU total)=27000.203125MB
INFO:root:[   21] Training loss: 0.65393044, Validation loss: 0.64291084, Gradient norm: 0.03777075
INFO:root:At the start of the epoch: mem (CPU python)=27213.98828125MB; mem (CPU total)=27038.5234375MB
INFO:root:[   22] Training loss: 0.65264072, Validation loss: 0.64204913, Gradient norm: 0.03854453
INFO:root:At the start of the epoch: mem (CPU python)=27244.46484375MB; mem (CPU total)=27045.28515625MB
INFO:root:[   23] Training loss: 0.65142201, Validation loss: 0.63979461, Gradient norm: 0.04315855
INFO:root:At the start of the epoch: mem (CPU python)=27265.1796875MB; mem (CPU total)=27089.64453125MB
INFO:root:[   24] Training loss: 0.65030156, Validation loss: 0.63951389, Gradient norm: 0.04413505
INFO:root:At the start of the epoch: mem (CPU python)=27315.77734375MB; mem (CPU total)=27140.1953125MB
INFO:root:[   25] Training loss: 0.64933180, Validation loss: 0.63805429, Gradient norm: 0.04450849
INFO:root:At the start of the epoch: mem (CPU python)=27366.37109375MB; mem (CPU total)=27190.5234375MB
INFO:root:[   26] Training loss: 0.64839032, Validation loss: 0.63805307, Gradient norm: 0.05024439
INFO:root:At the start of the epoch: mem (CPU python)=27404.46875MB; mem (CPU total)=27229.1484375MB
INFO:root:[   27] Training loss: 0.64734523, Validation loss: 0.63629135, Gradient norm: 0.04696456
INFO:root:At the start of the epoch: mem (CPU python)=27434.9453125MB; mem (CPU total)=27242.125MB
INFO:root:[   28] Training loss: 0.64654246, Validation loss: 0.63512881, Gradient norm: 0.04805125
INFO:root:At the start of the epoch: mem (CPU python)=27455.65234375MB; mem (CPU total)=27280.2578125MB
INFO:root:[   29] Training loss: 0.64552562, Validation loss: 0.63382947, Gradient norm: 0.04546401
INFO:root:At the start of the epoch: mem (CPU python)=27512.5MB; mem (CPU total)=27337.05078125MB
INFO:root:[   30] Training loss: 0.64483093, Validation loss: 0.63336192, Gradient norm: 0.05325749
INFO:root:At the start of the epoch: mem (CPU python)=27569.3515625MB; mem (CPU total)=27393.83203125MB
INFO:root:[   31] Training loss: 0.64377276, Validation loss: 0.63268896, Gradient norm: 0.04497049
INFO:root:At the start of the epoch: mem (CPU python)=27607.4453125MB; mem (CPU total)=27432.21875MB
INFO:root:[   32] Training loss: 0.64302965, Validation loss: 0.63248112, Gradient norm: 0.04713947
INFO:root:At the start of the epoch: mem (CPU python)=27645.5390625MB; mem (CPU total)=27470.36328125MB
INFO:root:[   33] Training loss: 0.64234750, Validation loss: 0.63042383, Gradient norm: 0.05303999
INFO:root:At the start of the epoch: mem (CPU python)=27646.1328125MB; mem (CPU total)=27471.046875MB
INFO:root:[   34] Training loss: 0.64194013, Validation loss: 0.63041809, Gradient norm: 0.05262657
INFO:root:At the start of the epoch: mem (CPU python)=27696.73046875MB; mem (CPU total)=27521.671875MB
INFO:root:[   35] Training loss: 0.64107121, Validation loss: 0.62885539, Gradient norm: 0.05163443
INFO:root:At the start of the epoch: mem (CPU python)=27734.82421875MB; mem (CPU total)=27559.95703125MB
INFO:root:[   36] Training loss: 0.64022993, Validation loss: 0.62896898, Gradient norm: 0.04998419
INFO:root:At the start of the epoch: mem (CPU python)=27772.91796875MB; mem (CPU total)=27598.09765625MB
INFO:root:[   37] Training loss: 0.63988583, Validation loss: 0.62851818, Gradient norm: 0.04976742
INFO:root:At the start of the epoch: mem (CPU python)=27823.515625MB; mem (CPU total)=27649.1875MB
INFO:root:[   38] Training loss: 0.63929536, Validation loss: 0.62717576, Gradient norm: 0.04907025
INFO:root:At the start of the epoch: mem (CPU python)=27867.86328125MB; mem (CPU total)=27693.4609375MB
INFO:root:[   39] Training loss: 0.63847875, Validation loss: 0.62724071, Gradient norm: 0.05491942
INFO:root:At the start of the epoch: mem (CPU python)=27905.95703125MB; mem (CPU total)=27733.2421875MB
INFO:root:[   40] Training loss: 0.63781216, Validation loss: 0.62677569, Gradient norm: 0.05545299
INFO:root:At the start of the epoch: mem (CPU python)=27936.4296875MB; mem (CPU total)=27746.171875MB
INFO:root:[   41] Training loss: 0.63742522, Validation loss: 0.62546550, Gradient norm: 0.05647392
INFO:root:At the start of the epoch: mem (CPU python)=27963.40234375MB; mem (CPU total)=27790.578125MB
INFO:root:[   42] Training loss: 0.63693358, Validation loss: 0.62603243, Gradient norm: 0.05343461
INFO:root:At the start of the epoch: mem (CPU python)=28001.49609375MB; mem (CPU total)=27828.73828125MB
INFO:root:[   43] Training loss: 0.63618737, Validation loss: 0.62572361, Gradient norm: 0.05011276
INFO:root:At the start of the epoch: mem (CPU python)=28039.59375MB; mem (CPU total)=27866.90625MB
INFO:root:[   44] Training loss: 0.63561316, Validation loss: 0.62440858, Gradient norm: 0.05548729
INFO:root:At the start of the epoch: mem (CPU python)=28090.1875MB; mem (CPU total)=27917.78515625MB
INFO:root:[   45] Training loss: 0.63529707, Validation loss: 0.62436206, Gradient norm: 0.05771977
INFO:root:At the start of the epoch: mem (CPU python)=28120.62109375MB; mem (CPU total)=27937.22265625MB
INFO:root:[   46] Training loss: 0.63474681, Validation loss: 0.62344597, Gradient norm: 0.05128855
INFO:root:At the start of the epoch: mem (CPU python)=28153.87890625MB; mem (CPU total)=27981.63671875MB
INFO:root:[   47] Training loss: 0.63426638, Validation loss: 0.62247329, Gradient norm: 0.05899039
INFO:root:At the start of the epoch: mem (CPU python)=28184.35546875MB; mem (CPU total)=28008.125MB
INFO:root:[   48] Training loss: 0.63361693, Validation loss: 0.62252202, Gradient norm: 0.05428999
INFO:root:At the start of the epoch: mem (CPU python)=28248.8203125MB; mem (CPU total)=28077.02734375MB
INFO:root:[   49] Training loss: 0.63331089, Validation loss: 0.62134432, Gradient norm: 0.05362176
INFO:root:At the start of the epoch: mem (CPU python)=28286.921875MB; mem (CPU total)=28115.44140625MB
INFO:root:[   50] Training loss: 0.63271549, Validation loss: 0.62216332, Gradient norm: 0.05158462
INFO:root:At the start of the epoch: mem (CPU python)=28325.01953125MB; mem (CPU total)=28153.3203125MB
INFO:root:[   51] Training loss: 0.63229728, Validation loss: 0.62079745, Gradient norm: 0.05408199
INFO:root:At the start of the epoch: mem (CPU python)=28344.36328125MB; mem (CPU total)=28172.87890625MB
INFO:root:[   52] Training loss: 0.63178385, Validation loss: 0.62072420, Gradient norm: 0.05668720
INFO:root:At the start of the epoch: mem (CPU python)=28388.70703125MB; mem (CPU total)=28217.19921875MB
INFO:root:[   53] Training loss: 0.63171907, Validation loss: 0.62112951, Gradient norm: 0.07425775
INFO:root:At the start of the epoch: mem (CPU python)=28426.8046875MB; mem (CPU total)=28255.61328125MB
INFO:root:[   54] Training loss: 0.63107859, Validation loss: 0.62033489, Gradient norm: 0.05991899
INFO:root:At the start of the epoch: mem (CPU python)=28439.8984375MB; mem (CPU total)=28271.34375MB
INFO:root:[   55] Training loss: 0.63050884, Validation loss: 0.62041336, Gradient norm: 0.05032004
INFO:root:At the start of the epoch: mem (CPU python)=28477.9921875MB; mem (CPU total)=28309.5MB
INFO:root:[   56] Training loss: 0.63015812, Validation loss: 0.61976581, Gradient norm: 0.05752906
INFO:root:At the start of the epoch: mem (CPU python)=28534.83984375MB; mem (CPU total)=28366.171875MB
INFO:root:[   57] Training loss: 0.62992958, Validation loss: 0.61833931, Gradient norm: 0.06060097
INFO:root:At the start of the epoch: mem (CPU python)=28588.5625MB; mem (CPU total)=28419.92578125MB
INFO:root:[   58] Training loss: 0.62951764, Validation loss: 0.61916629, Gradient norm: 0.05963766
INFO:root:At the start of the epoch: mem (CPU python)=28626.65625MB; mem (CPU total)=28458.09765625MB
INFO:root:[   59] Training loss: 0.62913823, Validation loss: 0.61857034, Gradient norm: 0.05631761
INFO:root:At the start of the epoch: mem (CPU python)=28664.75MB; mem (CPU total)=28496.2578125MB
INFO:root:[   60] Training loss: 0.62850517, Validation loss: 0.61846158, Gradient norm: 0.05683154
INFO:root:At the start of the epoch: mem (CPU python)=28694.98046875MB; mem (CPU total)=28526.57421875MB
INFO:root:[   61] Training loss: 0.62848049, Validation loss: 0.61799586, Gradient norm: 0.06271700
INFO:root:At the start of the epoch: mem (CPU python)=28733.07421875MB; mem (CPU total)=28567.45703125MB
INFO:root:[   62] Training loss: 0.62797857, Validation loss: 0.61697607, Gradient norm: 0.05515413
INFO:root:At the start of the epoch: mem (CPU python)=28763.49609375MB; mem (CPU total)=28599.296875MB
INFO:root:[   63] Training loss: 0.62762169, Validation loss: 0.61700310, Gradient norm: 0.05687419
INFO:root:At the start of the epoch: mem (CPU python)=28801.5078125MB; mem (CPU total)=28637.2109375MB
INFO:root:[   64] Training loss: 0.62740327, Validation loss: 0.61677186, Gradient norm: 0.05677782
INFO:root:At the start of the epoch: mem (CPU python)=28845.85546875MB; mem (CPU total)=28681.6171875MB
INFO:root:[   65] Training loss: 0.62711802, Validation loss: 0.61731618, Gradient norm: 0.06323687
INFO:root:At the start of the epoch: mem (CPU python)=28883.94921875MB; mem (CPU total)=28719.05078125MB
INFO:root:[   66] Training loss: 0.62674081, Validation loss: 0.61612845, Gradient norm: 0.05911675
INFO:root:At the start of the epoch: mem (CPU python)=28922.04296875MB; mem (CPU total)=28756.58984375MB
INFO:root:[   67] Training loss: 0.62641889, Validation loss: 0.61662366, Gradient norm: 0.05921852
INFO:root:At the start of the epoch: mem (CPU python)=28966.390625MB; mem (CPU total)=28801.17578125MB
INFO:root:[   68] Training loss: 0.62619304, Validation loss: 0.61568641, Gradient norm: 0.06695880
INFO:root:At the start of the epoch: mem (CPU python)=29004.484375MB; mem (CPU total)=28839.34765625MB
INFO:root:[   69] Training loss: 0.62599980, Validation loss: 0.61484957, Gradient norm: 0.06957103
INFO:root:At the start of the epoch: mem (CPU python)=29034.7890625MB; mem (CPU total)=28842.671875MB
INFO:root:[   70] Training loss: 0.62536544, Validation loss: 0.61465003, Gradient norm: 0.06489493
INFO:root:At the start of the epoch: mem (CPU python)=29074.421875MB; mem (CPU total)=28905.75390625MB
INFO:root:[   71] Training loss: 0.62504969, Validation loss: 0.61501493, Gradient norm: 0.06217664
INFO:root:At the start of the epoch: mem (CPU python)=29118.76953125MB; mem (CPU total)=28950.62109375MB
INFO:root:[   72] Training loss: 0.62494599, Validation loss: 0.61488193, Gradient norm: 0.05932534
INFO:root:At the start of the epoch: mem (CPU python)=29144.3671875MB; mem (CPU total)=28977.58203125MB
INFO:root:[   73] Training loss: 0.62455469, Validation loss: 0.61400036, Gradient norm: 0.06503195
INFO:root:At the start of the epoch: mem (CPU python)=29194.9609375MB; mem (CPU total)=29027.828125MB
INFO:root:[   74] Training loss: 0.62444829, Validation loss: 0.61466559, Gradient norm: 0.05647953
INFO:root:At the start of the epoch: mem (CPU python)=29233.05859375MB; mem (CPU total)=29066.28125MB
INFO:root:[   75] Training loss: 0.62378249, Validation loss: 0.61385933, Gradient norm: 0.05906864
INFO:root:At the start of the epoch: mem (CPU python)=29258.65234375MB; mem (CPU total)=29092.0625MB
INFO:root:[   76] Training loss: 0.62385182, Validation loss: 0.61341095, Gradient norm: 0.06267065
INFO:root:At the start of the epoch: mem (CPU python)=29296.74609375MB; mem (CPU total)=29130.515625MB
INFO:root:[   77] Training loss: 0.62325868, Validation loss: 0.61459217, Gradient norm: 0.05900752
INFO:root:At the start of the epoch: mem (CPU python)=29327.2265625MB; mem (CPU total)=29141.234375MB
INFO:root:[   78] Training loss: 0.62293520, Validation loss: 0.61472102, Gradient norm: 0.06192131
INFO:root:At the start of the epoch: mem (CPU python)=29354.18359375MB; mem (CPU total)=29185.33203125MB
INFO:root:[   79] Training loss: 0.62280133, Validation loss: 0.61364801, Gradient norm: 0.05742696
INFO:root:At the start of the epoch: mem (CPU python)=29404.79296875MB; mem (CPU total)=29235.95703125MB
INFO:root:[   80] Training loss: 0.62284727, Validation loss: 0.61355974, Gradient norm: 0.06051644
INFO:root:At the start of the epoch: mem (CPU python)=29442.88671875MB; mem (CPU total)=29274.3359375MB
INFO:root:[   81] Training loss: 0.62230368, Validation loss: 0.61282809, Gradient norm: 0.06337134
INFO:root:At the start of the epoch: mem (CPU python)=29473.3671875MB; mem (CPU total)=29300.28515625MB
INFO:root:[   82] Training loss: 0.62244872, Validation loss: 0.61226626, Gradient norm: 0.06361412
INFO:root:At the start of the epoch: mem (CPU python)=29531.5703125MB; mem (CPU total)=29362.33984375MB
INFO:root:[   83] Training loss: 0.62212539, Validation loss: 0.61288938, Gradient norm: 0.06512551
INFO:root:At the start of the epoch: mem (CPU python)=29569.6640625MB; mem (CPU total)=29400.49609375MB
INFO:root:[   84] Training loss: 0.62167872, Validation loss: 0.61343316, Gradient norm: 0.06273670
INFO:root:At the start of the epoch: mem (CPU python)=29600.1484375MB; mem (CPU total)=29425.94140625MB
INFO:root:[   85] Training loss: 0.62143993, Validation loss: 0.61237624, Gradient norm: 0.06616487
INFO:root:At the start of the epoch: mem (CPU python)=29664.60546875MB; mem (CPU total)=29495.44921875MB
INFO:root:[   86] Training loss: 0.62120036, Validation loss: 0.61219549, Gradient norm: 0.06506096
INFO:root:At the start of the epoch: mem (CPU python)=29702.69921875MB; mem (CPU total)=29533.39453125MB
INFO:root:[   87] Training loss: 0.62102876, Validation loss: 0.61134764, Gradient norm: 0.06293848
INFO:root:At the start of the epoch: mem (CPU python)=29740.64453125MB; mem (CPU total)=29508.83984375MB
INFO:root:[   88] Training loss: 0.62088322, Validation loss: 0.61017920, Gradient norm: 0.07030440
INFO:root:At the start of the epoch: mem (CPU python)=29740.64453125MB; mem (CPU total)=29565.40625MB
INFO:root:[   89] Training loss: 0.62056524, Validation loss: 0.61054674, Gradient norm: 0.06496469
INFO:root:At the start of the epoch: mem (CPU python)=29798.23828125MB; mem (CPU total)=29631.46875MB
INFO:root:[   90] Training loss: 0.62023219, Validation loss: 0.61181991, Gradient norm: 0.07422475
INFO:root:At the start of the epoch: mem (CPU python)=29836.33203125MB; mem (CPU total)=29669.4375MB
INFO:root:[   91] Training loss: 0.62021274, Validation loss: 0.61158303, Gradient norm: 0.06358914
INFO:root:At the start of the epoch: mem (CPU python)=29874.4296875MB; mem (CPU total)=29707.32421875MB
INFO:root:[   92] Training loss: 0.61974662, Validation loss: 0.61095484, Gradient norm: 0.06987100
INFO:root:At the start of the epoch: mem (CPU python)=29912.5234375MB; mem (CPU total)=29745.44921875MB
INFO:root:[   93] Training loss: 0.61976079, Validation loss: 0.60973971, Gradient norm: 0.06844011
INFO:root:At the start of the epoch: mem (CPU python)=29942.91015625MB; mem (CPU total)=29766.578125MB
INFO:root:[   94] Training loss: 0.61935876, Validation loss: 0.61078187, Gradient norm: 0.05875861
INFO:root:At the start of the epoch: mem (CPU python)=29976.22265625MB; mem (CPU total)=29810.96484375MB
INFO:root:[   95] Training loss: 0.61921279, Validation loss: 0.61041471, Gradient norm: 0.07187980
INFO:root:At the start of the epoch: mem (CPU python)=30033.05859375MB; mem (CPU total)=29868.0859375MB
INFO:root:[   96] Training loss: 0.61896086, Validation loss: 0.60896917, Gradient norm: 0.07014973
INFO:root:At the start of the epoch: mem (CPU python)=30071.15625MB; mem (CPU total)=29906.53515625MB
INFO:root:[   97] Training loss: 0.61874304, Validation loss: 0.60986394, Gradient norm: 0.07054257
INFO:root:At the start of the epoch: mem (CPU python)=30109.24609375MB; mem (CPU total)=29944.45703125MB
INFO:root:[   98] Training loss: 0.61857410, Validation loss: 0.60965507, Gradient norm: 0.06555154
INFO:root:At the start of the epoch: mem (CPU python)=30147.34765625MB; mem (CPU total)=29983.1171875MB
INFO:root:[   99] Training loss: 0.61849438, Validation loss: 0.60944466, Gradient norm: 0.05881471
INFO:root:At the start of the epoch: mem (CPU python)=30185.44140625MB; mem (CPU total)=30021.28125MB
INFO:root:[  100] Training loss: 0.61814204, Validation loss: 0.61096376, Gradient norm: 0.06546519
INFO:root:At the start of the epoch: mem (CPU python)=30223.53515625MB; mem (CPU total)=30060.16796875MB
INFO:root:[  101] Training loss: 0.61794390, Validation loss: 0.60895917, Gradient norm: 0.06839113
INFO:root:At the start of the epoch: mem (CPU python)=30254.015625MB; mem (CPU total)=30083.8671875MB
INFO:root:[  102] Training loss: 0.61784621, Validation loss: 0.60867286, Gradient norm: 0.06882794
INFO:root:At the start of the epoch: mem (CPU python)=30287.2265625MB; mem (CPU total)=30121.80859375MB
INFO:root:[  103] Training loss: 0.61734150, Validation loss: 0.60966359, Gradient norm: 0.05931102
INFO:root:At the start of the epoch: mem (CPU python)=30325.3203125MB; mem (CPU total)=30159.36328125MB
INFO:root:[  104] Training loss: 0.61734462, Validation loss: 0.60958406, Gradient norm: 0.06929122
INFO:root:At the start of the epoch: mem (CPU python)=30344.66015625MB; mem (CPU total)=30178.41796875MB
INFO:root:[  105] Training loss: 0.61738229, Validation loss: 0.60988740, Gradient norm: 0.06886910
INFO:root:At the start of the epoch: mem (CPU python)=30395.26953125MB; mem (CPU total)=30229.07421875MB
INFO:root:[  106] Training loss: 0.61719578, Validation loss: 0.60932650, Gradient norm: 0.07106196
INFO:root:At the start of the epoch: mem (CPU python)=30433.3671875MB; mem (CPU total)=30267.48828125MB
INFO:root:[  107] Training loss: 0.61687319, Validation loss: 0.60873545, Gradient norm: 0.06655519
INFO:root:At the start of the epoch: mem (CPU python)=30463.71875MB; mem (CPU total)=30293.37890625MB
INFO:root:[  108] Training loss: 0.61666429, Validation loss: 0.60772680, Gradient norm: 0.06069717
INFO:root:At the start of the epoch: mem (CPU python)=30522.05078125MB; mem (CPU total)=30356.48828125MB
INFO:root:[  109] Training loss: 0.61632084, Validation loss: 0.60868937, Gradient norm: 0.06311682
INFO:root:At the start of the epoch: mem (CPU python)=30572.64453125MB; mem (CPU total)=30406.828125MB
INFO:root:[  110] Training loss: 0.61650583, Validation loss: 0.60818237, Gradient norm: 0.07126535
INFO:root:At the start of the epoch: mem (CPU python)=30610.73828125MB; mem (CPU total)=30444.73828125MB
INFO:root:[  111] Training loss: 0.61616398, Validation loss: 0.60835909, Gradient norm: 0.07012017
INFO:root:At the start of the epoch: mem (CPU python)=30648.8359375MB; mem (CPU total)=30482.6484375MB
INFO:root:[  112] Training loss: 0.61606249, Validation loss: 0.60969754, Gradient norm: 0.06611073
INFO:root:At the start of the epoch: mem (CPU python)=30679.15234375MB; mem (CPU total)=30490.09765625MB
INFO:root:[  113] Training loss: 0.61605201, Validation loss: 0.60909031, Gradient norm: 0.07124294
INFO:root:At the start of the epoch: mem (CPU python)=30700.03515625MB; mem (CPU total)=30534.21484375MB
INFO:root:[  114] Training loss: 0.61551994, Validation loss: 0.60884922, Gradient norm: 0.06920749
INFO:root:At the start of the epoch: mem (CPU python)=30738.1328125MB; mem (CPU total)=30572.6328125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  115] Training loss: 0.61533213, Validation loss: 0.60844570, Gradient norm: 0.06658108
INFO:root:At the start of the epoch: mem (CPU python)=30782.48046875MB; mem (CPU total)=30616.84375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  116] Training loss: 0.61444732, Validation loss: 0.60830123, Gradient norm: 0.05696204
INFO:root:At the start of the epoch: mem (CPU python)=30820.578125MB; mem (CPU total)=30655.234375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  117] Training loss: 0.61378367, Validation loss: 0.60686424, Gradient norm: 0.05373928
INFO:root:At the start of the epoch: mem (CPU python)=30858.671875MB; mem (CPU total)=30693.64453125MB
INFO:root:[  118] Training loss: 0.61356715, Validation loss: 0.60649720, Gradient norm: 0.05330843
INFO:root:At the start of the epoch: mem (CPU python)=30903.01953125MB; mem (CPU total)=30737.9921875MB
INFO:root:[  119] Training loss: 0.61339502, Validation loss: 0.60697679, Gradient norm: 0.05080684
INFO:root:At the start of the epoch: mem (CPU python)=30941.11328125MB; mem (CPU total)=30776.125MB
INFO:root:[  120] Training loss: 0.61315100, Validation loss: 0.60707869, Gradient norm: 0.05083243
INFO:root:At the start of the epoch: mem (CPU python)=30979.20703125MB; mem (CPU total)=30814.26953125MB
INFO:root:[  121] Training loss: 0.61323005, Validation loss: 0.60706382, Gradient norm: 0.05376729
INFO:root:At the start of the epoch: mem (CPU python)=30992.296875MB; mem (CPU total)=30827.22265625MB
INFO:root:[  122] Training loss: 0.61333386, Validation loss: 0.60664767, Gradient norm: 0.05230908
INFO:root:At the start of the epoch: mem (CPU python)=31049.15234375MB; mem (CPU total)=30884.0546875MB
INFO:root:[  123] Training loss: 0.61328131, Validation loss: 0.60658653, Gradient norm: 0.05358440
INFO:root:At the start of the epoch: mem (CPU python)=31093.49609375MB; mem (CPU total)=30928.578125MB
INFO:root:[  124] Training loss: 0.61298194, Validation loss: 0.60603744, Gradient norm: 0.05384413
INFO:root:At the start of the epoch: mem (CPU python)=31112.8359375MB; mem (CPU total)=30947.7265625MB
INFO:root:[  125] Training loss: 0.61296031, Validation loss: 0.60617339, Gradient norm: 0.05458839
INFO:root:At the start of the epoch: mem (CPU python)=31157.1953125MB; mem (CPU total)=30992.36328125MB
INFO:root:[  126] Training loss: 0.61298929, Validation loss: 0.60649994, Gradient norm: 0.05211390
INFO:root:At the start of the epoch: mem (CPU python)=31201.53125MB; mem (CPU total)=31037.0MB
INFO:root:[  127] Training loss: 0.61298198, Validation loss: 0.60654842, Gradient norm: 0.05323281
INFO:root:At the start of the epoch: mem (CPU python)=31239.625MB; mem (CPU total)=31074.8984375MB
INFO:root:[  128] Training loss: 0.61291842, Validation loss: 0.60625913, Gradient norm: 0.05350258
INFO:root:At the start of the epoch: mem (CPU python)=31258.96875MB; mem (CPU total)=31094.3125MB
INFO:root:[  129] Training loss: 0.61313820, Validation loss: 0.60726557, Gradient norm: 0.05144959
INFO:root:At the start of the epoch: mem (CPU python)=31322.06640625MB; mem (CPU total)=31157.5625MB
INFO:root:[  130] Training loss: 0.61290492, Validation loss: 0.60606341, Gradient norm: 0.05630552
INFO:root:At the start of the epoch: mem (CPU python)=31363.28515625MB; mem (CPU total)=31198.35546875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  131] Training loss: 0.61297512, Validation loss: 0.60588052, Gradient norm: 0.05325003
INFO:root:At the start of the epoch: mem (CPU python)=31401.3828125MB; mem (CPU total)=31236.51171875MB
INFO:root:[  132] Training loss: 0.61282908, Validation loss: 0.60601349, Gradient norm: 0.05049530
INFO:root:At the start of the epoch: mem (CPU python)=31439.48046875MB; mem (CPU total)=31274.66015625MB
INFO:root:[  133] Training loss: 0.61277334, Validation loss: 0.60671456, Gradient norm: 0.05256252
INFO:root:At the start of the epoch: mem (CPU python)=31486.94921875MB; mem (CPU total)=31322.1484375MB
INFO:root:[  134] Training loss: 0.61300117, Validation loss: 0.60567251, Gradient norm: 0.05239381
INFO:root:At the start of the epoch: mem (CPU python)=31525.04296875MB; mem (CPU total)=31360.109375MB
INFO:root:[  135] Training loss: 0.61292514, Validation loss: 0.60694334, Gradient norm: 0.05274342
INFO:root:At the start of the epoch: mem (CPU python)=31563.140625MB; mem (CPU total)=31398.5MB
INFO:root:[  136] Training loss: 0.61272528, Validation loss: 0.60592649, Gradient norm: 0.05287740
INFO:root:At the start of the epoch: mem (CPU python)=31601.234375MB; mem (CPU total)=31436.67578125MB
INFO:root:[  137] Training loss: 0.61258303, Validation loss: 0.60704529, Gradient norm: 0.05157653
INFO:root:At the start of the epoch: mem (CPU python)=31611.203125MB; mem (CPU total)=31446.9609375MB
INFO:root:[  138] Training loss: 0.61280280, Validation loss: 0.60693409, Gradient norm: 0.05357278
INFO:root:At the start of the epoch: mem (CPU python)=31674.296875MB; mem (CPU total)=31509.9609375MB
INFO:root:[  139] Training loss: 0.61255609, Validation loss: 0.60607813, Gradient norm: 0.05426052
INFO:root:At the start of the epoch: mem (CPU python)=31712.39453125MB; mem (CPU total)=31548.3125MB
INFO:root:[  140] Training loss: 0.61254081, Validation loss: 0.60602632, Gradient norm: 0.05262181
INFO:root:At the start of the epoch: mem (CPU python)=31741.11328125MB; mem (CPU total)=31576.19140625MB
INFO:root:[  141] Training loss: 0.61227465, Validation loss: 0.60608986, Gradient norm: 0.05336336
INFO:root:At the start of the epoch: mem (CPU python)=31779.2109375MB; mem (CPU total)=31614.3203125MB
INFO:root:[  142] Training loss: 0.61242685, Validation loss: 0.60706192, Gradient norm: 0.05311978
INFO:root:At the start of the epoch: mem (CPU python)=31817.30859375MB; mem (CPU total)=31652.46484375MB
INFO:root:[  143] Training loss: 0.61245987, Validation loss: 0.60581568, Gradient norm: 0.05213884
INFO:root:At the start of the epoch: mem (CPU python)=31849.15234375MB; mem (CPU total)=31684.88671875MB
INFO:root:EP 143: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=31855.9921875MB; mem (CPU total)=31691.6484375MB
INFO:root:Training the model took 9255.373s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8406
INFO:root:EnergyScoreTrain: 0.59174
INFO:root:CRPSTrain: 0.45932
INFO:root:Gaussian NLLTrain: 1.19078
INFO:root:CoverageTrain: 0.94651
INFO:root:IntervalWidthTrain: 3.23391
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86096
INFO:root:EnergyScoreValidation: 0.606
INFO:root:CRPSValidation: 0.47148
INFO:root:Gaussian NLLValidation: 1.21933
INFO:root:CoverageValidation: 0.9399
INFO:root:IntervalWidthValidation: 3.23761
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86265
INFO:root:EnergyScoreTest: 0.60718
INFO:root:CRPSTest: 0.47256
INFO:root:Gaussian NLLTest: 1.22159
INFO:root:CoverageTest: 0.93945
INFO:root:IntervalWidthTest: 3.23812
INFO:root:After validation: mem (CPU python)=31923.12890625MB; mem (CPU total)=31728.78125MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=31923.12890625MB; mem (CPU total)=31728.56640625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=31923.12890625MB; mem (CPU total)=31729.05859375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=31923.12890625MB; mem (CPU total)=31729.05859375MB
INFO:root:[    1] Training loss: 0.72556407, Validation loss: 0.72073955, Gradient norm: 0.02282854
INFO:root:At the start of the epoch: mem (CPU python)=31962.40625MB; mem (CPU total)=31798.390625MB
INFO:root:[    2] Training loss: 0.72001678, Validation loss: 0.71887500, Gradient norm: 0.00782931
INFO:root:At the start of the epoch: mem (CPU python)=32000.50390625MB; mem (CPU total)=31836.84375MB
INFO:root:[    3] Training loss: 0.71818389, Validation loss: 0.71559770, Gradient norm: 0.00811999
INFO:root:At the start of the epoch: mem (CPU python)=32038.6171875MB; mem (CPU total)=31875.015625MB
INFO:root:[    4] Training loss: 0.71307213, Validation loss: 0.70807250, Gradient norm: 0.01754281
INFO:root:At the start of the epoch: mem (CPU python)=32045.44921875MB; mem (CPU total)=31881.71484375MB
INFO:root:[    5] Training loss: 0.70751994, Validation loss: 0.70221557, Gradient norm: 0.02421165
INFO:root:At the start of the epoch: mem (CPU python)=32099.16796875MB; mem (CPU total)=31935.765625MB
INFO:root:[    6] Training loss: 0.70278234, Validation loss: 0.69734143, Gradient norm: 0.02980119
INFO:root:At the start of the epoch: mem (CPU python)=32137.26953125MB; mem (CPU total)=31973.91015625MB
INFO:root:[    7] Training loss: 0.69832747, Validation loss: 0.69179419, Gradient norm: 0.03257784
INFO:root:At the start of the epoch: mem (CPU python)=32175.36328125MB; mem (CPU total)=32012.296875MB
INFO:root:[    8] Training loss: 0.69421980, Validation loss: 0.68801241, Gradient norm: 0.03183391
INFO:root:At the start of the epoch: mem (CPU python)=32213.45703125MB; mem (CPU total)=32050.42578125MB
INFO:root:[    9] Training loss: 0.69026531, Validation loss: 0.68363004, Gradient norm: 0.03392074
INFO:root:At the start of the epoch: mem (CPU python)=32251.55078125MB; mem (CPU total)=32088.34375MB
INFO:root:[   10] Training loss: 0.68662863, Validation loss: 0.67969089, Gradient norm: 0.03167380
INFO:root:At the start of the epoch: mem (CPU python)=32289.6484375MB; mem (CPU total)=32126.71875MB
INFO:root:[   11] Training loss: 0.68345936, Validation loss: 0.67548135, Gradient norm: 0.03353706
INFO:root:At the start of the epoch: mem (CPU python)=32327.7421875MB; mem (CPU total)=32164.86328125MB
INFO:root:[   12] Training loss: 0.68024658, Validation loss: 0.67245343, Gradient norm: 0.03556252
INFO:root:At the start of the epoch: mem (CPU python)=32365.84375MB; mem (CPU total)=32202.64453125MB
INFO:root:[   13] Training loss: 0.67759094, Validation loss: 0.66894554, Gradient norm: 0.03465812
INFO:root:At the start of the epoch: mem (CPU python)=32403.9375MB; mem (CPU total)=32240.4765625MB
INFO:root:[   14] Training loss: 0.67502256, Validation loss: 0.66649458, Gradient norm: 0.03301399
INFO:root:At the start of the epoch: mem (CPU python)=32442.03125MB; mem (CPU total)=32278.65234375MB
INFO:root:[   15] Training loss: 0.67259046, Validation loss: 0.66377679, Gradient norm: 0.03568668
INFO:root:At the start of the epoch: mem (CPU python)=32480.125MB; mem (CPU total)=32316.765625MB
INFO:root:[   16] Training loss: 0.67040442, Validation loss: 0.66134906, Gradient norm: 0.03660356
INFO:root:At the start of the epoch: mem (CPU python)=32518.22265625MB; mem (CPU total)=32355.15625MB
INFO:root:[   17] Training loss: 0.66842730, Validation loss: 0.65993135, Gradient norm: 0.03722579
INFO:root:At the start of the epoch: mem (CPU python)=32556.31640625MB; mem (CPU total)=32393.0546875MB
INFO:root:[   18] Training loss: 0.66634527, Validation loss: 0.65758230, Gradient norm: 0.04133176
INFO:root:At the start of the epoch: mem (CPU python)=32594.41015625MB; mem (CPU total)=32431.66796875MB
INFO:root:[   19] Training loss: 0.66436640, Validation loss: 0.65479403, Gradient norm: 0.04112723
INFO:root:At the start of the epoch: mem (CPU python)=32632.5078125MB; mem (CPU total)=32470.23828125MB
INFO:root:[   20] Training loss: 0.66259290, Validation loss: 0.65280159, Gradient norm: 0.04072860
INFO:root:At the start of the epoch: mem (CPU python)=32670.60546875MB; mem (CPU total)=32508.6484375MB
INFO:root:[   21] Training loss: 0.66080013, Validation loss: 0.65064570, Gradient norm: 0.04040509
INFO:root:At the start of the epoch: mem (CPU python)=32708.69921875MB; mem (CPU total)=32546.77734375MB
INFO:root:[   22] Training loss: 0.65903677, Validation loss: 0.64928756, Gradient norm: 0.04439894
INFO:root:At the start of the epoch: mem (CPU python)=32746.79296875MB; mem (CPU total)=32584.91015625MB
INFO:root:[   23] Training loss: 0.65759600, Validation loss: 0.64721095, Gradient norm: 0.03934608
INFO:root:At the start of the epoch: mem (CPU python)=32784.890625MB; mem (CPU total)=32623.0546875MB
INFO:root:[   24] Training loss: 0.65600774, Validation loss: 0.64521483, Gradient norm: 0.03923713
INFO:root:At the start of the epoch: mem (CPU python)=32822.984375MB; mem (CPU total)=32661.4453125MB
INFO:root:[   25] Training loss: 0.65481878, Validation loss: 0.64361105, Gradient norm: 0.04564165
INFO:root:At the start of the epoch: mem (CPU python)=32861.078125MB; mem (CPU total)=32699.34375MB
INFO:root:[   26] Training loss: 0.65351876, Validation loss: 0.64294332, Gradient norm: 0.04973081
INFO:root:At the start of the epoch: mem (CPU python)=32899.17578125MB; mem (CPU total)=32736.984375MB
INFO:root:[   27] Training loss: 0.65226094, Validation loss: 0.64144653, Gradient norm: 0.04444713
INFO:root:At the start of the epoch: mem (CPU python)=32937.26953125MB; mem (CPU total)=32775.11328125MB
INFO:root:[   28] Training loss: 0.65129387, Validation loss: 0.63959877, Gradient norm: 0.04603473
INFO:root:At the start of the epoch: mem (CPU python)=32975.3671875MB; mem (CPU total)=32813.02734375MB
INFO:root:[   29] Training loss: 0.65024104, Validation loss: 0.63940819, Gradient norm: 0.04865170
INFO:root:At the start of the epoch: mem (CPU python)=33013.46875MB; mem (CPU total)=32851.359375MB
INFO:root:[   30] Training loss: 0.64891698, Validation loss: 0.63781216, Gradient norm: 0.04706029
INFO:root:At the start of the epoch: mem (CPU python)=33051.5625MB; mem (CPU total)=32889.35546875MB
INFO:root:[   31] Training loss: 0.64821070, Validation loss: 0.63646663, Gradient norm: 0.05298094
INFO:root:At the start of the epoch: mem (CPU python)=33089.65625MB; mem (CPU total)=32927.49609375MB
INFO:root:[   32] Training loss: 0.64737762, Validation loss: 0.63609339, Gradient norm: 0.04690378
INFO:root:At the start of the epoch: mem (CPU python)=33127.75MB; mem (CPU total)=32965.609375MB
INFO:root:[   33] Training loss: 0.64625005, Validation loss: 0.63542167, Gradient norm: 0.04771368
INFO:root:At the start of the epoch: mem (CPU python)=33165.84765625MB; mem (CPU total)=33004.0MB
INFO:root:[   34] Training loss: 0.64561207, Validation loss: 0.63451688, Gradient norm: 0.05062116
INFO:root:At the start of the epoch: mem (CPU python)=33203.94140625MB; mem (CPU total)=33042.14453125MB
INFO:root:[   35] Training loss: 0.64497324, Validation loss: 0.63396184, Gradient norm: 0.05152739
INFO:root:At the start of the epoch: mem (CPU python)=33242.03515625MB; mem (CPU total)=33080.2890625MB
INFO:root:[   36] Training loss: 0.64416460, Validation loss: 0.63271622, Gradient norm: 0.05098590
INFO:root:At the start of the epoch: mem (CPU python)=33280.13671875MB; mem (CPU total)=33118.38671875MB
INFO:root:[   37] Training loss: 0.64323953, Validation loss: 0.63263637, Gradient norm: 0.04829214
INFO:root:At the start of the epoch: mem (CPU python)=33318.23046875MB; mem (CPU total)=33156.5234375MB
INFO:root:[   38] Training loss: 0.64296381, Validation loss: 0.63206488, Gradient norm: 0.05496722
INFO:root:At the start of the epoch: mem (CPU python)=33356.32421875MB; mem (CPU total)=33194.34765625MB
INFO:root:[   39] Training loss: 0.64219578, Validation loss: 0.63053846, Gradient norm: 0.05257146
INFO:root:At the start of the epoch: mem (CPU python)=33394.41796875MB; mem (CPU total)=33232.4453125MB
INFO:root:[   40] Training loss: 0.64158615, Validation loss: 0.63016048, Gradient norm: 0.05067867
INFO:root:At the start of the epoch: mem (CPU python)=33432.515625MB; mem (CPU total)=33270.75390625MB
INFO:root:[   41] Training loss: 0.64112308, Validation loss: 0.63041882, Gradient norm: 0.05282648
INFO:root:At the start of the epoch: mem (CPU python)=33470.609375MB; mem (CPU total)=33309.13671875MB
INFO:root:[   42] Training loss: 0.64027021, Validation loss: 0.62934163, Gradient norm: 0.05634333
INFO:root:At the start of the epoch: mem (CPU python)=33508.703125MB; mem (CPU total)=33347.3125MB
INFO:root:[   43] Training loss: 0.63983358, Validation loss: 0.62932861, Gradient norm: 0.05229864
INFO:root:At the start of the epoch: mem (CPU python)=33546.80078125MB; mem (CPU total)=33385.1796875MB
INFO:root:[   44] Training loss: 0.63938963, Validation loss: 0.62817981, Gradient norm: 0.05922446
INFO:root:At the start of the epoch: mem (CPU python)=33584.8984375MB; mem (CPU total)=33423.6015625MB
INFO:root:[   45] Training loss: 0.63886622, Validation loss: 0.62751851, Gradient norm: 0.05560250
INFO:root:At the start of the epoch: mem (CPU python)=33622.98828125MB; mem (CPU total)=33461.94921875MB
INFO:root:[   46] Training loss: 0.63833775, Validation loss: 0.62681033, Gradient norm: 0.05175069
INFO:root:At the start of the epoch: mem (CPU python)=33661.08984375MB; mem (CPU total)=33500.0859375MB
INFO:root:[   47] Training loss: 0.63774605, Validation loss: 0.62661371, Gradient norm: 0.05442640
INFO:root:At the start of the epoch: mem (CPU python)=33699.18359375MB; mem (CPU total)=33538.1484375MB
INFO:root:[   48] Training loss: 0.63734621, Validation loss: 0.62588324, Gradient norm: 0.05140919
INFO:root:At the start of the epoch: mem (CPU python)=33737.27734375MB; mem (CPU total)=33576.5234375MB
INFO:root:[   49] Training loss: 0.63698446, Validation loss: 0.62541498, Gradient norm: 0.06606716
INFO:root:At the start of the epoch: mem (CPU python)=33775.37109375MB; mem (CPU total)=33614.421875MB
INFO:root:[   50] Training loss: 0.63620594, Validation loss: 0.62567453, Gradient norm: 0.05461194
INFO:root:At the start of the epoch: mem (CPU python)=33813.46875MB; mem (CPU total)=33652.8125MB
INFO:root:[   51] Training loss: 0.63594353, Validation loss: 0.62513169, Gradient norm: 0.05886366
INFO:root:At the start of the epoch: mem (CPU python)=33851.56640625MB; mem (CPU total)=33691.1953125MB
INFO:root:[   52] Training loss: 0.63554670, Validation loss: 0.62460119, Gradient norm: 0.06101747
INFO:root:At the start of the epoch: mem (CPU python)=33889.65625MB; mem (CPU total)=33729.125MB
INFO:root:[   53] Training loss: 0.63521726, Validation loss: 0.62427920, Gradient norm: 0.05936289
INFO:root:At the start of the epoch: mem (CPU python)=33927.7578125MB; mem (CPU total)=33767.5078125MB
INFO:root:[   54] Training loss: 0.63446404, Validation loss: 0.62344150, Gradient norm: 0.06133327
INFO:root:At the start of the epoch: mem (CPU python)=33965.8515625MB; mem (CPU total)=33805.38671875MB
INFO:root:[   55] Training loss: 0.63414413, Validation loss: 0.62331519, Gradient norm: 0.05437925
INFO:root:At the start of the epoch: mem (CPU python)=34003.9453125MB; mem (CPU total)=33843.6015625MB
INFO:root:[   56] Training loss: 0.63370916, Validation loss: 0.62328656, Gradient norm: 0.05452704
INFO:root:At the start of the epoch: mem (CPU python)=34042.0390625MB; mem (CPU total)=33881.87109375MB
INFO:root:[   57] Training loss: 0.63354961, Validation loss: 0.62225363, Gradient norm: 0.06158531
INFO:root:At the start of the epoch: mem (CPU python)=34080.13671875MB; mem (CPU total)=33920.00390625MB
INFO:root:[   58] Training loss: 0.63336641, Validation loss: 0.62194939, Gradient norm: 0.06397045
INFO:root:At the start of the epoch: mem (CPU python)=34118.23046875MB; mem (CPU total)=33958.640625MB
INFO:root:[   59] Training loss: 0.63298774, Validation loss: 0.62206184, Gradient norm: 0.05787357
INFO:root:At the start of the epoch: mem (CPU python)=34156.32421875MB; mem (CPU total)=33996.5390625MB
INFO:root:[   60] Training loss: 0.63247447, Validation loss: 0.62198532, Gradient norm: 0.06075817
INFO:root:At the start of the epoch: mem (CPU python)=34194.421875MB; mem (CPU total)=34034.40625MB
INFO:root:[   61] Training loss: 0.63226460, Validation loss: 0.62242355, Gradient norm: 0.05925940
INFO:root:At the start of the epoch: mem (CPU python)=34232.515625MB; mem (CPU total)=34072.55078125MB
INFO:root:[   62] Training loss: 0.63184530, Validation loss: 0.62181343, Gradient norm: 0.06354814
INFO:root:At the start of the epoch: mem (CPU python)=34270.61328125MB; mem (CPU total)=34110.91796875MB
INFO:root:[   63] Training loss: 0.63133535, Validation loss: 0.62041387, Gradient norm: 0.05494419
INFO:root:At the start of the epoch: mem (CPU python)=34308.7109375MB; mem (CPU total)=34148.84765625MB
INFO:root:[   64] Training loss: 0.63115986, Validation loss: 0.62073268, Gradient norm: 0.05580590
INFO:root:At the start of the epoch: mem (CPU python)=34346.8046875MB; mem (CPU total)=34186.97265625MB
INFO:root:[   65] Training loss: 0.63076617, Validation loss: 0.62121730, Gradient norm: 0.05900658
INFO:root:At the start of the epoch: mem (CPU python)=34384.8984375MB; mem (CPU total)=34225.1171875MB
INFO:root:[   66] Training loss: 0.63021797, Validation loss: 0.61976517, Gradient norm: 0.06285229
INFO:root:At the start of the epoch: mem (CPU python)=34422.9921875MB; mem (CPU total)=34263.4609375MB
INFO:root:[   67] Training loss: 0.63042804, Validation loss: 0.62035204, Gradient norm: 0.06125471
INFO:root:At the start of the epoch: mem (CPU python)=34461.08984375MB; mem (CPU total)=34301.8515625MB
INFO:root:[   68] Training loss: 0.62987711, Validation loss: 0.61971015, Gradient norm: 0.06503549
INFO:root:At the start of the epoch: mem (CPU python)=34499.1875MB; mem (CPU total)=34339.9921875MB
INFO:root:[   69] Training loss: 0.62951129, Validation loss: 0.61975546, Gradient norm: 0.05731149
INFO:root:At the start of the epoch: mem (CPU python)=34540.40234375MB; mem (CPU total)=34380.84375MB
INFO:root:[   70] Training loss: 0.62912033, Validation loss: 0.61932197, Gradient norm: 0.05892300
INFO:root:At the start of the epoch: mem (CPU python)=34578.51171875MB; mem (CPU total)=34420.6171875MB
INFO:root:[   71] Training loss: 0.62910780, Validation loss: 0.61864176, Gradient norm: 0.05832920
INFO:root:At the start of the epoch: mem (CPU python)=34616.60546875MB; mem (CPU total)=34458.7890625MB
INFO:root:[   72] Training loss: 0.62870119, Validation loss: 0.61792206, Gradient norm: 0.06231776
INFO:root:At the start of the epoch: mem (CPU python)=34654.69921875MB; mem (CPU total)=34496.68359375MB
INFO:root:[   73] Training loss: 0.62861214, Validation loss: 0.61795438, Gradient norm: 0.06147718
INFO:root:At the start of the epoch: mem (CPU python)=34692.79296875MB; mem (CPU total)=34535.02734375MB
INFO:root:[   74] Training loss: 0.62830323, Validation loss: 0.61783436, Gradient norm: 0.05853725
INFO:root:At the start of the epoch: mem (CPU python)=34730.890625MB; mem (CPU total)=34573.19921875MB
INFO:root:[   75] Training loss: 0.62789384, Validation loss: 0.61820791, Gradient norm: 0.06384805
INFO:root:At the start of the epoch: mem (CPU python)=34768.984375MB; mem (CPU total)=34611.58984375MB
INFO:root:[   76] Training loss: 0.62769760, Validation loss: 0.61794983, Gradient norm: 0.05986005
INFO:root:At the start of the epoch: mem (CPU python)=34807.08203125MB; mem (CPU total)=34649.39453125MB
INFO:root:[   77] Training loss: 0.62755682, Validation loss: 0.61710322, Gradient norm: 0.06538260
INFO:root:At the start of the epoch: mem (CPU python)=34845.17578125MB; mem (CPU total)=34687.28515625MB
INFO:root:[   78] Training loss: 0.62731121, Validation loss: 0.61757776, Gradient norm: 0.06117464
INFO:root:At the start of the epoch: mem (CPU python)=34883.2734375MB; mem (CPU total)=34725.1796875MB
INFO:root:[   79] Training loss: 0.62690502, Validation loss: 0.61673385, Gradient norm: 0.06785294
INFO:root:At the start of the epoch: mem (CPU python)=34921.3671875MB; mem (CPU total)=34763.375MB
INFO:root:[   80] Training loss: 0.62653523, Validation loss: 0.61579423, Gradient norm: 0.06063834
INFO:root:At the start of the epoch: mem (CPU python)=34959.46484375MB; mem (CPU total)=34801.75390625MB
INFO:root:[   81] Training loss: 0.62638456, Validation loss: 0.61707111, Gradient norm: 0.06122108
INFO:root:At the start of the epoch: mem (CPU python)=34997.55859375MB; mem (CPU total)=34839.59765625MB
INFO:root:[   82] Training loss: 0.62601122, Validation loss: 0.61628623, Gradient norm: 0.06333746
INFO:root:At the start of the epoch: mem (CPU python)=35035.65234375MB; mem (CPU total)=34877.73828125MB
INFO:root:[   83] Training loss: 0.62592696, Validation loss: 0.61554856, Gradient norm: 0.05977890
INFO:root:At the start of the epoch: mem (CPU python)=35073.74609375MB; mem (CPU total)=34916.12890625MB
INFO:root:[   84] Training loss: 0.62574190, Validation loss: 0.61560994, Gradient norm: 0.05923893
INFO:root:At the start of the epoch: mem (CPU python)=35111.84375MB; mem (CPU total)=34954.2421875MB
INFO:root:[   85] Training loss: 0.62549438, Validation loss: 0.61584295, Gradient norm: 0.06564171
INFO:root:At the start of the epoch: mem (CPU python)=35149.9375MB; mem (CPU total)=34992.38671875MB
INFO:root:[   86] Training loss: 0.62517918, Validation loss: 0.61544348, Gradient norm: 0.05876021
INFO:root:At the start of the epoch: mem (CPU python)=35188.03125MB; mem (CPU total)=35030.53125MB
INFO:root:[   87] Training loss: 0.62501754, Validation loss: 0.61544837, Gradient norm: 0.06221055
INFO:root:At the start of the epoch: mem (CPU python)=35226.1328125MB; mem (CPU total)=35068.41015625MB
INFO:root:[   88] Training loss: 0.62497488, Validation loss: 0.61478450, Gradient norm: 0.06364935
INFO:root:At the start of the epoch: mem (CPU python)=35264.2265625MB; mem (CPU total)=35107.0390625MB
INFO:root:[   89] Training loss: 0.62475435, Validation loss: 0.61449144, Gradient norm: 0.06847758
INFO:root:At the start of the epoch: mem (CPU python)=35302.3203125MB; mem (CPU total)=35144.96875MB
INFO:root:[   90] Training loss: 0.62468539, Validation loss: 0.61500193, Gradient norm: 0.06568357
INFO:root:At the start of the epoch: mem (CPU python)=35340.4140625MB; mem (CPU total)=35183.0MB
INFO:root:[   91] Training loss: 0.62398485, Validation loss: 0.61468558, Gradient norm: 0.06619257
INFO:root:At the start of the epoch: mem (CPU python)=35378.51171875MB; mem (CPU total)=35221.41015625MB
INFO:root:[   92] Training loss: 0.62411351, Validation loss: 0.61443721, Gradient norm: 0.07110286
INFO:root:At the start of the epoch: mem (CPU python)=35416.60546875MB; mem (CPU total)=35259.24609375MB
INFO:root:[   93] Training loss: 0.62383766, Validation loss: 0.61427895, Gradient norm: 0.06320986
INFO:root:At the start of the epoch: mem (CPU python)=35454.69921875MB; mem (CPU total)=35297.09765625MB
INFO:root:[   94] Training loss: 0.62362767, Validation loss: 0.61476436, Gradient norm: 0.05840497
INFO:root:At the start of the epoch: mem (CPU python)=35492.796875MB; mem (CPU total)=35335.48828125MB
INFO:root:[   95] Training loss: 0.62352419, Validation loss: 0.61410130, Gradient norm: 0.06740117
INFO:root:At the start of the epoch: mem (CPU python)=35530.89453125MB; mem (CPU total)=35373.6640625MB
INFO:root:[   96] Training loss: 0.62294356, Validation loss: 0.61411555, Gradient norm: 0.06617850
INFO:root:At the start of the epoch: mem (CPU python)=35568.98828125MB; mem (CPU total)=35412.04296875MB
INFO:root:[   97] Training loss: 0.62282281, Validation loss: 0.61402622, Gradient norm: 0.06158765
INFO:root:At the start of the epoch: mem (CPU python)=35607.0859375MB; mem (CPU total)=35449.97265625MB
INFO:root:[   98] Training loss: 0.62288695, Validation loss: 0.61396705, Gradient norm: 0.06894099
INFO:root:At the start of the epoch: mem (CPU python)=35645.1796875MB; mem (CPU total)=35487.90625MB
INFO:root:[   99] Training loss: 0.62265120, Validation loss: 0.61310983, Gradient norm: 0.06457669
INFO:root:At the start of the epoch: mem (CPU python)=35683.2734375MB; mem (CPU total)=35526.29296875MB
INFO:root:[  100] Training loss: 0.62220593, Validation loss: 0.61371540, Gradient norm: 0.06470293
INFO:root:At the start of the epoch: mem (CPU python)=35721.3671875MB; mem (CPU total)=35564.68359375MB
INFO:root:[  101] Training loss: 0.62205790, Validation loss: 0.61317587, Gradient norm: 0.06097259
INFO:root:At the start of the epoch: mem (CPU python)=35759.46484375MB; mem (CPU total)=35602.859375MB
INFO:root:[  102] Training loss: 0.62205449, Validation loss: 0.61383384, Gradient norm: 0.06256014
INFO:root:At the start of the epoch: mem (CPU python)=35797.55859375MB; mem (CPU total)=35640.6953125MB
INFO:root:[  103] Training loss: 0.62191546, Validation loss: 0.61253126, Gradient norm: 0.06207835
INFO:root:At the start of the epoch: mem (CPU python)=35835.65234375MB; mem (CPU total)=35678.80859375MB
INFO:root:[  104] Training loss: 0.62151006, Validation loss: 0.61311476, Gradient norm: 0.06282852
INFO:root:At the start of the epoch: mem (CPU python)=35873.75390625MB; mem (CPU total)=35716.1953125MB
INFO:root:[  105] Training loss: 0.62171637, Validation loss: 0.61228498, Gradient norm: 0.07194995
INFO:root:At the start of the epoch: mem (CPU python)=35911.84765625MB; mem (CPU total)=35754.3984375MB
INFO:root:[  106] Training loss: 0.62138109, Validation loss: 0.61299938, Gradient norm: 0.06696191
INFO:root:At the start of the epoch: mem (CPU python)=35949.94140625MB; mem (CPU total)=35792.52734375MB
INFO:root:[  107] Training loss: 0.62105621, Validation loss: 0.61293544, Gradient norm: 0.06290866
INFO:root:At the start of the epoch: mem (CPU python)=35988.03515625MB; mem (CPU total)=35830.375MB
INFO:root:[  108] Training loss: 0.62082502, Validation loss: 0.61241569, Gradient norm: 0.06724677
INFO:root:At the start of the epoch: mem (CPU python)=36026.1328125MB; mem (CPU total)=35869.0078125MB
INFO:root:[  109] Training loss: 0.62079005, Validation loss: 0.61176094, Gradient norm: 0.06621004
INFO:root:At the start of the epoch: mem (CPU python)=36064.2265625MB; mem (CPU total)=35907.11328125MB
INFO:root:[  110] Training loss: 0.62047366, Validation loss: 0.61290203, Gradient norm: 0.06417712
INFO:root:At the start of the epoch: mem (CPU python)=36102.3203125MB; mem (CPU total)=35945.01171875MB
INFO:root:[  111] Training loss: 0.62038626, Validation loss: 0.61154652, Gradient norm: 0.06931255
INFO:root:At the start of the epoch: mem (CPU python)=36140.421875MB; mem (CPU total)=35983.2734375MB
INFO:root:[  112] Training loss: 0.62008247, Validation loss: 0.61182809, Gradient norm: 0.06589956
INFO:root:At the start of the epoch: mem (CPU python)=36178.51953125MB; mem (CPU total)=36021.38671875MB
INFO:root:[  113] Training loss: 0.62003494, Validation loss: 0.61222440, Gradient norm: 0.06463069
INFO:root:At the start of the epoch: mem (CPU python)=36216.609375MB; mem (CPU total)=36059.23828125MB
INFO:root:[  114] Training loss: 0.61984666, Validation loss: 0.61166456, Gradient norm: 0.06819256
INFO:root:At the start of the epoch: mem (CPU python)=36254.7109375MB; mem (CPU total)=36097.6484375MB
INFO:root:[  115] Training loss: 0.61964900, Validation loss: 0.61174056, Gradient norm: 0.06678450
INFO:root:At the start of the epoch: mem (CPU python)=36292.8046875MB; mem (CPU total)=36137.09765625MB
INFO:root:[  116] Training loss: 0.61966342, Validation loss: 0.61148432, Gradient norm: 0.06922580
INFO:root:At the start of the epoch: mem (CPU python)=36330.8984375MB; mem (CPU total)=36175.42578125MB
INFO:root:[  117] Training loss: 0.61972934, Validation loss: 0.61181517, Gradient norm: 0.07170659
INFO:root:At the start of the epoch: mem (CPU python)=36369.0MB; mem (CPU total)=36213.453125MB
INFO:root:[  118] Training loss: 0.61936835, Validation loss: 0.61066417, Gradient norm: 0.06572005
INFO:root:At the start of the epoch: mem (CPU python)=36407.09765625MB; mem (CPU total)=36251.08203125MB
INFO:root:[  119] Training loss: 0.61925827, Validation loss: 0.61048388, Gradient norm: 0.06799496
INFO:root:At the start of the epoch: mem (CPU python)=36446.69140625MB; mem (CPU total)=36290.734375MB
INFO:root:[  120] Training loss: 0.61894176, Validation loss: 0.61101905, Gradient norm: 0.07441329
INFO:root:At the start of the epoch: mem (CPU python)=36484.78515625MB; mem (CPU total)=36328.609375MB
INFO:root:[  121] Training loss: 0.61873180, Validation loss: 0.61146280, Gradient norm: 0.06926590
INFO:root:At the start of the epoch: mem (CPU python)=36522.88671875MB; mem (CPU total)=36366.99609375MB
INFO:root:[  122] Training loss: 0.61896467, Validation loss: 0.61129272, Gradient norm: 0.07138349
INFO:root:At the start of the epoch: mem (CPU python)=36560.98046875MB; mem (CPU total)=36405.12890625MB
INFO:root:[  123] Training loss: 0.61841970, Validation loss: 0.61005079, Gradient norm: 0.06466404
INFO:root:At the start of the epoch: mem (CPU python)=36599.07421875MB; mem (CPU total)=36443.0078125MB
INFO:root:[  124] Training loss: 0.61836871, Validation loss: 0.61060877, Gradient norm: 0.06817795
INFO:root:At the start of the epoch: mem (CPU python)=36637.16796875MB; mem (CPU total)=36481.64453125MB
INFO:root:[  125] Training loss: 0.61826713, Validation loss: 0.61011513, Gradient norm: 0.06604326
INFO:root:At the start of the epoch: mem (CPU python)=36675.265625MB; mem (CPU total)=36519.765625MB
INFO:root:[  126] Training loss: 0.61809331, Validation loss: 0.61059146, Gradient norm: 0.06461691
INFO:root:At the start of the epoch: mem (CPU python)=36713.359375MB; mem (CPU total)=36557.6640625MB
INFO:root:[  127] Training loss: 0.61786893, Validation loss: 0.61019132, Gradient norm: 0.06487183
INFO:root:At the start of the epoch: mem (CPU python)=36751.453125MB; mem (CPU total)=36599.71484375MB
INFO:root:[  128] Training loss: 0.61784903, Validation loss: 0.61017363, Gradient norm: 0.06282911
INFO:root:At the start of the epoch: mem (CPU python)=36789.55078125MB; mem (CPU total)=36636.953125MB
INFO:root:[  129] Training loss: 0.61791619, Validation loss: 0.61047529, Gradient norm: 0.07034068
INFO:root:At the start of the epoch: mem (CPU python)=36827.6484375MB; mem (CPU total)=36675.0703125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  130] Training loss: 0.61739306, Validation loss: 0.60968516, Gradient norm: 0.06488419
INFO:root:At the start of the epoch: mem (CPU python)=36865.7421875MB; mem (CPU total)=36713.73046875MB
INFO:root:[  131] Training loss: 0.61626211, Validation loss: 0.60976543, Gradient norm: 0.06739341
INFO:root:At the start of the epoch: mem (CPU python)=36903.83984375MB; mem (CPU total)=36752.35546875MB
INFO:root:[  132] Training loss: 0.61614284, Validation loss: 0.60936789, Gradient norm: 0.05785329
INFO:root:At the start of the epoch: mem (CPU python)=36941.93359375MB; mem (CPU total)=36790.77734375MB
INFO:root:[  133] Training loss: 0.61611270, Validation loss: 0.60851825, Gradient norm: 0.06218483
INFO:root:At the start of the epoch: mem (CPU python)=36980.02734375MB; mem (CPU total)=36828.96875MB
INFO:root:[  134] Training loss: 0.61616827, Validation loss: 0.60896703, Gradient norm: 0.06626446
INFO:root:At the start of the epoch: mem (CPU python)=37018.12109375MB; mem (CPU total)=36866.73828125MB
INFO:root:[  135] Training loss: 0.61588291, Validation loss: 0.60902948, Gradient norm: 0.06233542
INFO:root:At the start of the epoch: mem (CPU python)=37062.46875MB; mem (CPU total)=36911.09765625MB
INFO:root:[  136] Training loss: 0.61582717, Validation loss: 0.60944231, Gradient norm: 0.05922144
INFO:root:At the start of the epoch: mem (CPU python)=37100.5625MB; mem (CPU total)=36949.45703125MB
INFO:root:[  137] Training loss: 0.61571384, Validation loss: 0.60882672, Gradient norm: 0.06235754
INFO:root:At the start of the epoch: mem (CPU python)=37138.66015625MB; mem (CPU total)=36987.54296875MB
INFO:root:[  138] Training loss: 0.61583212, Validation loss: 0.60908609, Gradient norm: 0.05862254
INFO:root:At the start of the epoch: mem (CPU python)=37176.7578125MB; mem (CPU total)=37025.6796875MB
INFO:root:[  139] Training loss: 0.61575039, Validation loss: 0.60937361, Gradient norm: 0.06090099
INFO:root:At the start of the epoch: mem (CPU python)=37214.8515625MB; mem (CPU total)=37063.2265625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  140] Training loss: 0.61563132, Validation loss: 0.60985210, Gradient norm: 0.06231394
INFO:root:At the start of the epoch: mem (CPU python)=37252.9453125MB; mem (CPU total)=37101.40234375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  141] Training loss: 0.61491669, Validation loss: 0.60907486, Gradient norm: 0.05709383
INFO:root:At the start of the epoch: mem (CPU python)=37291.0390625MB; mem (CPU total)=37139.51171875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  142] Training loss: 0.61473225, Validation loss: 0.60829833, Gradient norm: 0.05558132
INFO:root:At the start of the epoch: mem (CPU python)=37329.13671875MB; mem (CPU total)=37177.51953125MB
INFO:root:[  143] Training loss: 0.61442848, Validation loss: 0.60829896, Gradient norm: 0.05488219
INFO:root:At the start of the epoch: mem (CPU python)=37367.23046875MB; mem (CPU total)=37215.6640625MB
INFO:root:[  144] Training loss: 0.61448068, Validation loss: 0.60788018, Gradient norm: 0.05371941
INFO:root:At the start of the epoch: mem (CPU python)=37405.32421875MB; mem (CPU total)=37253.59375MB
INFO:root:[  145] Training loss: 0.61430171, Validation loss: 0.60845566, Gradient norm: 0.05391270
INFO:root:At the start of the epoch: mem (CPU python)=37443.421875MB; mem (CPU total)=37291.97265625MB
INFO:root:[  146] Training loss: 0.61430341, Validation loss: 0.60767180, Gradient norm: 0.05486231
INFO:root:At the start of the epoch: mem (CPU python)=37481.515625MB; mem (CPU total)=37330.1484375MB
INFO:root:[  147] Training loss: 0.61443092, Validation loss: 0.60868307, Gradient norm: 0.05346541
INFO:root:At the start of the epoch: mem (CPU python)=37519.61328125MB; mem (CPU total)=37369.51953125MB
INFO:root:[  148] Training loss: 0.61439352, Validation loss: 0.60838820, Gradient norm: 0.05417364
INFO:root:At the start of the epoch: mem (CPU python)=37557.7109375MB; mem (CPU total)=37408.13671875MB
INFO:root:[  149] Training loss: 0.61421104, Validation loss: 0.60785064, Gradient norm: 0.05447139
INFO:root:At the start of the epoch: mem (CPU python)=37595.8046875MB; mem (CPU total)=37446.0625MB
INFO:root:[  150] Training loss: 0.61415743, Validation loss: 0.60817879, Gradient norm: 0.05409633
INFO:root:At the start of the epoch: mem (CPU python)=37633.8984375MB; mem (CPU total)=37483.89453125MB
INFO:root:[  151] Training loss: 0.61435047, Validation loss: 0.60821751, Gradient norm: 0.05257924
INFO:root:At the start of the epoch: mem (CPU python)=37671.9921875MB; mem (CPU total)=37522.31640625MB
INFO:root:[  152] Training loss: 0.61452275, Validation loss: 0.60865891, Gradient norm: 0.05520439
INFO:root:At the start of the epoch: mem (CPU python)=37710.08984375MB; mem (CPU total)=37560.48828125MB
INFO:root:[  153] Training loss: 0.61431552, Validation loss: 0.60843771, Gradient norm: 0.05510453
INFO:root:At the start of the epoch: mem (CPU python)=37748.18359375MB; mem (CPU total)=37598.6484375MB
INFO:root:[  154] Training loss: 0.61428020, Validation loss: 0.60818381, Gradient norm: 0.05330104
INFO:root:At the start of the epoch: mem (CPU python)=37786.27734375MB; mem (CPU total)=37636.8125MB
INFO:root:[  155] Training loss: 0.61420344, Validation loss: 0.60795790, Gradient norm: 0.05500303
INFO:root:At the start of the epoch: mem (CPU python)=37824.37890625MB; mem (CPU total)=37675.1953125MB
INFO:root:EP 155: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=37862.41796875MB; mem (CPU total)=37713.3359375MB
INFO:root:Training the model took 11060.818s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84275
INFO:root:EnergyScoreTrain: 0.59333
INFO:root:CRPSTrain: 0.46166
INFO:root:Gaussian NLLTrain: 1.19736
INFO:root:CoverageTrain: 0.95067
INFO:root:IntervalWidthTrain: 3.29135
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86434
INFO:root:EnergyScoreValidation: 0.60838
INFO:root:CRPSValidation: 0.47431
INFO:root:Gaussian NLLValidation: 1.22372
INFO:root:CoverageValidation: 0.9443
INFO:root:IntervalWidthValidation: 3.29527
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86595
INFO:root:EnergyScoreTest: 0.60951
INFO:root:CRPSTest: 0.47527
INFO:root:Gaussian NLLTest: 1.22557
INFO:root:CoverageTest: 0.94393
INFO:root:IntervalWidthTest: 3.29529
INFO:root:After validation: mem (CPU python)=37942.9296875MB; mem (CPU total)=37794.78125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=37942.9296875MB; mem (CPU total)=37795.19140625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=37943.19921875MB; mem (CPU total)=37795.046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=37943.3359375MB; mem (CPU total)=37795.4375MB
INFO:root:[    1] Training loss: 0.72559977, Validation loss: 0.72034960, Gradient norm: 0.02401747
INFO:root:At the start of the epoch: mem (CPU python)=37981.3984375MB; mem (CPU total)=37833.109375MB
INFO:root:[    2] Training loss: 0.71977874, Validation loss: 0.71869994, Gradient norm: 0.00610272
INFO:root:At the start of the epoch: mem (CPU python)=38019.4921875MB; mem (CPU total)=37870.30859375MB
INFO:root:[    3] Training loss: 0.71792504, Validation loss: 0.71487751, Gradient norm: 0.00778405
INFO:root:At the start of the epoch: mem (CPU python)=38057.60546875MB; mem (CPU total)=37908.4921875MB
INFO:root:[    4] Training loss: 0.71169331, Validation loss: 0.70540734, Gradient norm: 0.01768368
INFO:root:At the start of the epoch: mem (CPU python)=38095.69921875MB; mem (CPU total)=37946.66015625MB
INFO:root:[    5] Training loss: 0.70456538, Validation loss: 0.69844406, Gradient norm: 0.02634916
INFO:root:At the start of the epoch: mem (CPU python)=38133.79296875MB; mem (CPU total)=37985.5859375MB
INFO:root:[    6] Training loss: 0.69909370, Validation loss: 0.69282332, Gradient norm: 0.02667969
INFO:root:At the start of the epoch: mem (CPU python)=38171.890625MB; mem (CPU total)=38023.1484375MB
INFO:root:[    7] Training loss: 0.69365941, Validation loss: 0.68699067, Gradient norm: 0.02814844
INFO:root:At the start of the epoch: mem (CPU python)=38209.984375MB; mem (CPU total)=38060.109375MB
INFO:root:[    8] Training loss: 0.68891317, Validation loss: 0.68171068, Gradient norm: 0.02944788
INFO:root:At the start of the epoch: mem (CPU python)=38248.078125MB; mem (CPU total)=38098.0390625MB
INFO:root:[    9] Training loss: 0.68479856, Validation loss: 0.67754008, Gradient norm: 0.03093284
INFO:root:At the start of the epoch: mem (CPU python)=38286.17578125MB; mem (CPU total)=38136.2109375MB
INFO:root:[   10] Training loss: 0.68124083, Validation loss: 0.67346604, Gradient norm: 0.02833655
INFO:root:At the start of the epoch: mem (CPU python)=38324.2734375MB; mem (CPU total)=38174.3828125MB
INFO:root:[   11] Training loss: 0.67817121, Validation loss: 0.67123085, Gradient norm: 0.03000338
INFO:root:At the start of the epoch: mem (CPU python)=38362.3671875MB; mem (CPU total)=38212.3046875MB
INFO:root:[   12] Training loss: 0.67575233, Validation loss: 0.66898429, Gradient norm: 0.03078269
INFO:root:At the start of the epoch: mem (CPU python)=38400.4609375MB; mem (CPU total)=38250.47265625MB
INFO:root:[   13] Training loss: 0.67326813, Validation loss: 0.66588754, Gradient norm: 0.03140991
INFO:root:At the start of the epoch: mem (CPU python)=38438.55859375MB; mem (CPU total)=38288.921875MB
INFO:root:[   14] Training loss: 0.67107364, Validation loss: 0.66301865, Gradient norm: 0.03171593
INFO:root:At the start of the epoch: mem (CPU python)=38476.65234375MB; mem (CPU total)=38327.61328125MB
INFO:root:[   15] Training loss: 0.66909638, Validation loss: 0.66114168, Gradient norm: 0.03225329
INFO:root:At the start of the epoch: mem (CPU python)=38514.74609375MB; mem (CPU total)=38365.13671875MB
INFO:root:[   16] Training loss: 0.66679932, Validation loss: 0.65788484, Gradient norm: 0.03148118
INFO:root:At the start of the epoch: mem (CPU python)=38552.83984375MB; mem (CPU total)=38403.046875MB
INFO:root:[   17] Training loss: 0.66472915, Validation loss: 0.65533022, Gradient norm: 0.03309871
INFO:root:At the start of the epoch: mem (CPU python)=38590.9375MB; mem (CPU total)=38441.21875MB
INFO:root:[   18] Training loss: 0.66290184, Validation loss: 0.65352562, Gradient norm: 0.03753741
INFO:root:At the start of the epoch: mem (CPU python)=38629.03515625MB; mem (CPU total)=38479.6640625MB
INFO:root:[   19] Training loss: 0.66115063, Validation loss: 0.65119147, Gradient norm: 0.03582103
INFO:root:At the start of the epoch: mem (CPU python)=38667.12890625MB; mem (CPU total)=38517.82421875MB
INFO:root:[   20] Training loss: 0.65932324, Validation loss: 0.64965160, Gradient norm: 0.03487624
INFO:root:At the start of the epoch: mem (CPU python)=38705.2265625MB; mem (CPU total)=38555.74609375MB
INFO:root:[   21] Training loss: 0.65752865, Validation loss: 0.64745382, Gradient norm: 0.03592615
INFO:root:At the start of the epoch: mem (CPU python)=38743.3203125MB; mem (CPU total)=38594.1796875MB
INFO:root:[   22] Training loss: 0.65601062, Validation loss: 0.64635132, Gradient norm: 0.03592912
INFO:root:At the start of the epoch: mem (CPU python)=38781.4140625MB; mem (CPU total)=38632.5859375MB
INFO:root:[   23] Training loss: 0.65490853, Validation loss: 0.64497274, Gradient norm: 0.03949042
INFO:root:At the start of the epoch: mem (CPU python)=38819.51171875MB; mem (CPU total)=38671.00390625MB
INFO:root:[   24] Training loss: 0.65349677, Validation loss: 0.64276742, Gradient norm: 0.03890327
INFO:root:At the start of the epoch: mem (CPU python)=38857.60546875MB; mem (CPU total)=38708.40625MB
INFO:root:[   25] Training loss: 0.65230011, Validation loss: 0.64241034, Gradient norm: 0.04038130
INFO:root:At the start of the epoch: mem (CPU python)=38895.69921875MB; mem (CPU total)=38746.3359375MB
INFO:root:[   26] Training loss: 0.65101135, Validation loss: 0.64017789, Gradient norm: 0.03701293
INFO:root:At the start of the epoch: mem (CPU python)=38933.796875MB; mem (CPU total)=38784.78515625MB
INFO:root:[   27] Training loss: 0.65014214, Validation loss: 0.64012668, Gradient norm: 0.03944345
INFO:root:At the start of the epoch: mem (CPU python)=38971.89453125MB; mem (CPU total)=38823.171875MB
INFO:root:[   28] Training loss: 0.64916933, Validation loss: 0.63866546, Gradient norm: 0.03762336
INFO:root:At the start of the epoch: mem (CPU python)=39009.98828125MB; mem (CPU total)=38860.32421875MB
INFO:root:[   29] Training loss: 0.64807861, Validation loss: 0.63814607, Gradient norm: 0.03933336
INFO:root:At the start of the epoch: mem (CPU python)=39048.08203125MB; mem (CPU total)=38899.03515625MB
INFO:root:[   30] Training loss: 0.64713626, Validation loss: 0.63644891, Gradient norm: 0.03770229
INFO:root:At the start of the epoch: mem (CPU python)=39086.1796875MB; mem (CPU total)=38937.421875MB
INFO:root:[   31] Training loss: 0.64649891, Validation loss: 0.63508831, Gradient norm: 0.04184588
INFO:root:At the start of the epoch: mem (CPU python)=39124.2734375MB; mem (CPU total)=38975.76953125MB
INFO:root:[   32] Training loss: 0.64537772, Validation loss: 0.63467611, Gradient norm: 0.04066038
INFO:root:At the start of the epoch: mem (CPU python)=39162.3671875MB; mem (CPU total)=39013.453125MB
INFO:root:[   33] Training loss: 0.64482422, Validation loss: 0.63465484, Gradient norm: 0.04342720
INFO:root:At the start of the epoch: mem (CPU python)=39200.4609375MB; mem (CPU total)=39051.37890625MB
INFO:root:[   34] Training loss: 0.64374338, Validation loss: 0.63336491, Gradient norm: 0.04682961
INFO:root:At the start of the epoch: mem (CPU python)=39238.55859375MB; mem (CPU total)=39089.7890625MB
INFO:root:[   35] Training loss: 0.64317177, Validation loss: 0.63346549, Gradient norm: 0.04476054
INFO:root:At the start of the epoch: mem (CPU python)=39276.6640625MB; mem (CPU total)=39127.95703125MB
INFO:root:[   36] Training loss: 0.64244339, Validation loss: 0.63214680, Gradient norm: 0.04749740
INFO:root:At the start of the epoch: mem (CPU python)=39314.7578125MB; mem (CPU total)=39166.11328125MB
INFO:root:[   37] Training loss: 0.64175351, Validation loss: 0.63139503, Gradient norm: 0.04341917
INFO:root:At the start of the epoch: mem (CPU python)=39352.85546875MB; mem (CPU total)=39204.21484375MB
INFO:root:[   38] Training loss: 0.64108865, Validation loss: 0.63061754, Gradient norm: 0.04733785
INFO:root:At the start of the epoch: mem (CPU python)=39390.94921875MB; mem (CPU total)=39242.58984375MB
INFO:root:[   39] Training loss: 0.64059321, Validation loss: 0.63007954, Gradient norm: 0.04205677
INFO:root:At the start of the epoch: mem (CPU python)=39429.04296875MB; mem (CPU total)=39281.1875MB
INFO:root:[   40] Training loss: 0.63988152, Validation loss: 0.62964144, Gradient norm: 0.04477047
INFO:root:At the start of the epoch: mem (CPU python)=39467.140625MB; mem (CPU total)=39318.72265625MB
INFO:root:[   41] Training loss: 0.63915857, Validation loss: 0.62925482, Gradient norm: 0.04517440
INFO:root:At the start of the epoch: mem (CPU python)=39505.23828125MB; mem (CPU total)=39356.86328125MB
INFO:root:[   42] Training loss: 0.63876782, Validation loss: 0.62868079, Gradient norm: 0.04968631
INFO:root:At the start of the epoch: mem (CPU python)=39543.3359375MB; mem (CPU total)=39395.03515625MB
INFO:root:[   43] Training loss: 0.63815940, Validation loss: 0.62856991, Gradient norm: 0.04984980
INFO:root:At the start of the epoch: mem (CPU python)=39581.42578125MB; mem (CPU total)=39433.4609375MB
INFO:root:[   44] Training loss: 0.63763827, Validation loss: 0.62750050, Gradient norm: 0.05214913
INFO:root:At the start of the epoch: mem (CPU python)=39619.5234375MB; mem (CPU total)=39471.609375MB
INFO:root:[   45] Training loss: 0.63716073, Validation loss: 0.62621036, Gradient norm: 0.05386567
INFO:root:At the start of the epoch: mem (CPU python)=39657.62109375MB; mem (CPU total)=39509.92578125MB
INFO:root:[   46] Training loss: 0.63664379, Validation loss: 0.62607056, Gradient norm: 0.05329024
INFO:root:At the start of the epoch: mem (CPU python)=39695.71484375MB; mem (CPU total)=39548.10546875MB
INFO:root:[   47] Training loss: 0.63607007, Validation loss: 0.62584461, Gradient norm: 0.04788690
INFO:root:At the start of the epoch: mem (CPU python)=39733.8125MB; mem (CPU total)=39586.265625MB
INFO:root:[   48] Training loss: 0.63563842, Validation loss: 0.62639764, Gradient norm: 0.05335869
INFO:root:At the start of the epoch: mem (CPU python)=39771.90625MB; mem (CPU total)=39623.9453125MB
INFO:root:[   49] Training loss: 0.63507877, Validation loss: 0.62482461, Gradient norm: 0.05746240
INFO:root:At the start of the epoch: mem (CPU python)=39810.0MB; mem (CPU total)=39662.36328125MB
INFO:root:[   50] Training loss: 0.63474116, Validation loss: 0.62418333, Gradient norm: 0.05250837
INFO:root:At the start of the epoch: mem (CPU python)=39848.09375MB; mem (CPU total)=39700.32421875MB
INFO:root:[   51] Training loss: 0.63433889, Validation loss: 0.62375598, Gradient norm: 0.05361993
INFO:root:At the start of the epoch: mem (CPU python)=39886.19140625MB; mem (CPU total)=39738.23046875MB
INFO:root:[   52] Training loss: 0.63376698, Validation loss: 0.62315428, Gradient norm: 0.04888278
INFO:root:At the start of the epoch: mem (CPU python)=39924.28515625MB; mem (CPU total)=39776.6328125MB
INFO:root:[   53] Training loss: 0.63357082, Validation loss: 0.62323013, Gradient norm: 0.05712591
INFO:root:At the start of the epoch: mem (CPU python)=39962.3828125MB; mem (CPU total)=39814.80078125MB
INFO:root:[   54] Training loss: 0.63318183, Validation loss: 0.62208373, Gradient norm: 0.06007349
INFO:root:At the start of the epoch: mem (CPU python)=40000.48046875MB; mem (CPU total)=39853.234375MB
INFO:root:[   55] Training loss: 0.63286650, Validation loss: 0.62279799, Gradient norm: 0.05951640
INFO:root:At the start of the epoch: mem (CPU python)=40038.57421875MB; mem (CPU total)=39891.40625MB
INFO:root:[   56] Training loss: 0.63240341, Validation loss: 0.62195825, Gradient norm: 0.05305017
INFO:root:At the start of the epoch: mem (CPU python)=40076.66796875MB; mem (CPU total)=39929.33203125MB
INFO:root:[   57] Training loss: 0.63182337, Validation loss: 0.62126517, Gradient norm: 0.05218969
INFO:root:At the start of the epoch: mem (CPU python)=40114.765625MB; mem (CPU total)=39967.5078125MB
INFO:root:[   58] Training loss: 0.63159157, Validation loss: 0.62206845, Gradient norm: 0.05279917
INFO:root:At the start of the epoch: mem (CPU python)=40152.859375MB; mem (CPU total)=40005.92578125MB
INFO:root:[   59] Training loss: 0.63113308, Validation loss: 0.62111778, Gradient norm: 0.05309944
INFO:root:At the start of the epoch: mem (CPU python)=40190.953125MB; mem (CPU total)=40043.84375MB
INFO:root:[   60] Training loss: 0.63059599, Validation loss: 0.62071337, Gradient norm: 0.05249738
INFO:root:At the start of the epoch: mem (CPU python)=40229.05078125MB; mem (CPU total)=40082.25MB
INFO:root:[   61] Training loss: 0.63045390, Validation loss: 0.62075489, Gradient norm: 0.05531235
INFO:root:At the start of the epoch: mem (CPU python)=40267.1484375MB; mem (CPU total)=40120.82421875MB
INFO:root:[   62] Training loss: 0.63027761, Validation loss: 0.62002764, Gradient norm: 0.05482324
INFO:root:At the start of the epoch: mem (CPU python)=40305.2421875MB; mem (CPU total)=40158.58203125MB
INFO:root:[   63] Training loss: 0.62963745, Validation loss: 0.62009134, Gradient norm: 0.05525816
INFO:root:At the start of the epoch: mem (CPU python)=40343.3359375MB; mem (CPU total)=40196.75390625MB
INFO:root:[   64] Training loss: 0.62933824, Validation loss: 0.61972917, Gradient norm: 0.05994753
INFO:root:At the start of the epoch: mem (CPU python)=40381.43359375MB; mem (CPU total)=40234.9296875MB
INFO:root:[   65] Training loss: 0.62919943, Validation loss: 0.61871983, Gradient norm: 0.05796823
INFO:root:At the start of the epoch: mem (CPU python)=40419.52734375MB; mem (CPU total)=40273.09375MB
INFO:root:[   66] Training loss: 0.62889229, Validation loss: 0.61872788, Gradient norm: 0.05934592
INFO:root:At the start of the epoch: mem (CPU python)=40457.62109375MB; mem (CPU total)=40311.2578125MB
INFO:root:[   67] Training loss: 0.62825721, Validation loss: 0.61932348, Gradient norm: 0.05383508
INFO:root:At the start of the epoch: mem (CPU python)=40495.71875MB; mem (CPU total)=40348.66015625MB
INFO:root:[   68] Training loss: 0.62824861, Validation loss: 0.61853788, Gradient norm: 0.05959770
INFO:root:At the start of the epoch: mem (CPU python)=40533.81640625MB; mem (CPU total)=40386.82421875MB
INFO:root:[   69] Training loss: 0.62780184, Validation loss: 0.61816645, Gradient norm: 0.05334377
INFO:root:At the start of the epoch: mem (CPU python)=40571.91015625MB; mem (CPU total)=40425.1015625MB
INFO:root:[   70] Training loss: 0.62762781, Validation loss: 0.61775139, Gradient norm: 0.05697011
INFO:root:At the start of the epoch: mem (CPU python)=40610.00390625MB; mem (CPU total)=40463.234375MB
INFO:root:[   71] Training loss: 0.62725349, Validation loss: 0.61757989, Gradient norm: 0.06047661
INFO:root:At the start of the epoch: mem (CPU python)=40648.1015625MB; mem (CPU total)=40501.1328125MB
INFO:root:[   72] Training loss: 0.62688774, Validation loss: 0.61767556, Gradient norm: 0.05663941
INFO:root:At the start of the epoch: mem (CPU python)=40686.1953125MB; mem (CPU total)=40539.29296875MB
INFO:root:[   73] Training loss: 0.62678337, Validation loss: 0.61668666, Gradient norm: 0.06271121
INFO:root:At the start of the epoch: mem (CPU python)=40724.2890625MB; mem (CPU total)=40577.4375MB
INFO:root:[   74] Training loss: 0.62646650, Validation loss: 0.61646146, Gradient norm: 0.05822601
INFO:root:At the start of the epoch: mem (CPU python)=40762.38671875MB; mem (CPU total)=40615.828125MB
INFO:root:[   75] Training loss: 0.62600134, Validation loss: 0.61639507, Gradient norm: 0.05919653
INFO:root:At the start of the epoch: mem (CPU python)=40800.48046875MB; mem (CPU total)=40653.9140625MB
INFO:root:[   76] Training loss: 0.62578800, Validation loss: 0.61704473, Gradient norm: 0.05587227
INFO:root:At the start of the epoch: mem (CPU python)=40838.57421875MB; mem (CPU total)=40691.80078125MB
INFO:root:[   77] Training loss: 0.62558500, Validation loss: 0.61584606, Gradient norm: 0.05633293
INFO:root:At the start of the epoch: mem (CPU python)=40876.66796875MB; mem (CPU total)=40730.42578125MB
INFO:root:[   78] Training loss: 0.62544217, Validation loss: 0.61616267, Gradient norm: 0.05830686
INFO:root:At the start of the epoch: mem (CPU python)=40914.76953125MB; mem (CPU total)=40768.99609375MB
INFO:root:[   79] Training loss: 0.62520264, Validation loss: 0.61549399, Gradient norm: 0.06009299
INFO:root:At the start of the epoch: mem (CPU python)=40952.86328125MB; mem (CPU total)=40806.7265625MB
INFO:root:[   80] Training loss: 0.62472670, Validation loss: 0.61660169, Gradient norm: 0.06232242
INFO:root:At the start of the epoch: mem (CPU python)=40990.95703125MB; mem (CPU total)=40845.14453125MB
INFO:root:[   81] Training loss: 0.62453210, Validation loss: 0.61531181, Gradient norm: 0.05673982
INFO:root:At the start of the epoch: mem (CPU python)=41029.0546875MB; mem (CPU total)=40883.1875MB
INFO:root:[   82] Training loss: 0.62434376, Validation loss: 0.61530906, Gradient norm: 0.06723105
INFO:root:At the start of the epoch: mem (CPU python)=41067.1484375MB; mem (CPU total)=40921.57421875MB
INFO:root:[   83] Training loss: 0.62417803, Validation loss: 0.61533351, Gradient norm: 0.06103790
INFO:root:At the start of the epoch: mem (CPU python)=41105.2421875MB; mem (CPU total)=40959.70703125MB
INFO:root:[   84] Training loss: 0.62401742, Validation loss: 0.61524132, Gradient norm: 0.05706452
INFO:root:At the start of the epoch: mem (CPU python)=41143.33984375MB; mem (CPU total)=40997.921875MB
INFO:root:[   85] Training loss: 0.62359205, Validation loss: 0.61406348, Gradient norm: 0.06288572
INFO:root:At the start of the epoch: mem (CPU python)=41181.4375MB; mem (CPU total)=41036.2421875MB
INFO:root:[   86] Training loss: 0.62335152, Validation loss: 0.61419665, Gradient norm: 0.06254248
INFO:root:At the start of the epoch: mem (CPU python)=41219.53515625MB; mem (CPU total)=41073.89453125MB
INFO:root:[   87] Training loss: 0.62326365, Validation loss: 0.61407065, Gradient norm: 0.06079914
INFO:root:At the start of the epoch: mem (CPU python)=41257.62890625MB; mem (CPU total)=41112.0234375MB
INFO:root:[   88] Training loss: 0.62306569, Validation loss: 0.61364371, Gradient norm: 0.05667079
INFO:root:At the start of the epoch: mem (CPU python)=41295.7265625MB; mem (CPU total)=41150.40625MB
INFO:root:[   89] Training loss: 0.62256013, Validation loss: 0.61393826, Gradient norm: 0.05569875
INFO:root:At the start of the epoch: mem (CPU python)=41333.8203125MB; mem (CPU total)=41189.91796875MB
INFO:root:[   90] Training loss: 0.62279444, Validation loss: 0.61384624, Gradient norm: 0.05838415
INFO:root:At the start of the epoch: mem (CPU python)=41371.9140625MB; mem (CPU total)=41228.00390625MB
INFO:root:[   91] Training loss: 0.62242120, Validation loss: 0.61334023, Gradient norm: 0.06329378
INFO:root:At the start of the epoch: mem (CPU python)=41410.01171875MB; mem (CPU total)=41266.390625MB
INFO:root:[   92] Training loss: 0.62201329, Validation loss: 0.61326830, Gradient norm: 0.05730778
INFO:root:At the start of the epoch: mem (CPU python)=41448.10546875MB; mem (CPU total)=41304.328125MB
INFO:root:[   93] Training loss: 0.62219878, Validation loss: 0.61363151, Gradient norm: 0.06513295
INFO:root:At the start of the epoch: mem (CPU python)=41486.19921875MB; mem (CPU total)=41342.5078125MB
INFO:root:[   94] Training loss: 0.62202110, Validation loss: 0.61404500, Gradient norm: 0.06903989
INFO:root:At the start of the epoch: mem (CPU python)=41524.296875MB; mem (CPU total)=41380.65234375MB
INFO:root:[   95] Training loss: 0.62161324, Validation loss: 0.61280436, Gradient norm: 0.05804602
INFO:root:At the start of the epoch: mem (CPU python)=41562.39453125MB; mem (CPU total)=41419.04296875MB
INFO:root:[   96] Training loss: 0.62122807, Validation loss: 0.61248439, Gradient norm: 0.06030920
INFO:root:At the start of the epoch: mem (CPU python)=41600.48828125MB; mem (CPU total)=41456.94140625MB
INFO:root:[   97] Training loss: 0.62092489, Validation loss: 0.61273966, Gradient norm: 0.05956052
INFO:root:At the start of the epoch: mem (CPU python)=41638.58203125MB; mem (CPU total)=41495.0859375MB
INFO:root:[   98] Training loss: 0.62105197, Validation loss: 0.61268494, Gradient norm: 0.07022395
INFO:root:At the start of the epoch: mem (CPU python)=41676.68359375MB; mem (CPU total)=41533.2109375MB
INFO:root:[   99] Training loss: 0.62088153, Validation loss: 0.61227492, Gradient norm: 0.06470145
INFO:root:At the start of the epoch: mem (CPU python)=41714.77734375MB; mem (CPU total)=41571.84375MB
INFO:root:[  100] Training loss: 0.62046761, Validation loss: 0.61243572, Gradient norm: 0.06069841
INFO:root:At the start of the epoch: mem (CPU python)=41752.87109375MB; mem (CPU total)=41610.015625MB
INFO:root:[  101] Training loss: 0.62042516, Validation loss: 0.61330231, Gradient norm: 0.06753932
INFO:root:At the start of the epoch: mem (CPU python)=41790.96484375MB; mem (CPU total)=41647.88671875MB
INFO:root:[  102] Training loss: 0.62026435, Validation loss: 0.61148727, Gradient norm: 0.06315751
INFO:root:At the start of the epoch: mem (CPU python)=41829.0625MB; mem (CPU total)=41686.2734375MB
INFO:root:[  103] Training loss: 0.61994792, Validation loss: 0.61209560, Gradient norm: 0.05929756
INFO:root:At the start of the epoch: mem (CPU python)=41867.15625MB; mem (CPU total)=41724.33984375MB
INFO:root:[  104] Training loss: 0.61997722, Validation loss: 0.61235822, Gradient norm: 0.06022608
INFO:root:At the start of the epoch: mem (CPU python)=41905.25390625MB; mem (CPU total)=41762.23828125MB
INFO:root:[  105] Training loss: 0.61969694, Validation loss: 0.61146567, Gradient norm: 0.07261215
INFO:root:At the start of the epoch: mem (CPU python)=41943.3515625MB; mem (CPU total)=41799.8828125MB
INFO:root:[  106] Training loss: 0.61928350, Validation loss: 0.61124851, Gradient norm: 0.05758759
INFO:root:At the start of the epoch: mem (CPU python)=41981.4453125MB; mem (CPU total)=41838.04296875MB
INFO:root:[  107] Training loss: 0.61937946, Validation loss: 0.61128763, Gradient norm: 0.06435425
INFO:root:At the start of the epoch: mem (CPU python)=42019.5390625MB; mem (CPU total)=41876.1875MB
INFO:root:[  108] Training loss: 0.61887095, Validation loss: 0.61076471, Gradient norm: 0.05781271
INFO:root:At the start of the epoch: mem (CPU python)=42057.63671875MB; mem (CPU total)=41914.32421875MB
INFO:root:[  109] Training loss: 0.61890463, Validation loss: 0.61052055, Gradient norm: 0.06349433
INFO:root:At the start of the epoch: mem (CPU python)=42095.73046875MB; mem (CPU total)=41952.33203125MB
INFO:root:[  110] Training loss: 0.61869354, Validation loss: 0.60989364, Gradient norm: 0.06698188
INFO:root:At the start of the epoch: mem (CPU python)=42133.82421875MB; mem (CPU total)=41990.4921875MB
INFO:root:[  111] Training loss: 0.61846709, Validation loss: 0.61064801, Gradient norm: 0.05884716
INFO:root:At the start of the epoch: mem (CPU python)=42171.921875MB; mem (CPU total)=42028.390625MB
INFO:root:[  112] Training loss: 0.61845521, Validation loss: 0.61034037, Gradient norm: 0.06968863
INFO:root:At the start of the epoch: mem (CPU python)=42210.01953125MB; mem (CPU total)=42066.50390625MB
INFO:root:[  113] Training loss: 0.61820640, Validation loss: 0.61010803, Gradient norm: 0.06630059
INFO:root:At the start of the epoch: mem (CPU python)=42248.11328125MB; mem (CPU total)=42104.39453125MB
INFO:root:[  114] Training loss: 0.61802128, Validation loss: 0.61095082, Gradient norm: 0.06674046
INFO:root:At the start of the epoch: mem (CPU python)=42286.20703125MB; mem (CPU total)=42142.9453125MB
INFO:root:[  115] Training loss: 0.61775191, Validation loss: 0.61042725, Gradient norm: 0.06504639
INFO:root:At the start of the epoch: mem (CPU python)=42324.3046875MB; mem (CPU total)=42181.13671875MB
INFO:root:[  116] Training loss: 0.61777438, Validation loss: 0.61030068, Gradient norm: 0.07135975
INFO:root:At the start of the epoch: mem (CPU python)=42362.3984375MB; mem (CPU total)=42219.0078125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  117] Training loss: 0.61764937, Validation loss: 0.60979854, Gradient norm: 0.06248954
INFO:root:At the start of the epoch: mem (CPU python)=42400.4921875MB; mem (CPU total)=42257.37890625MB
INFO:root:[  118] Training loss: 0.61663732, Validation loss: 0.60878456, Gradient norm: 0.05577045
INFO:root:At the start of the epoch: mem (CPU python)=42438.5859375MB; mem (CPU total)=42295.5546875MB
INFO:root:[  119] Training loss: 0.61630692, Validation loss: 0.60937551, Gradient norm: 0.06199572
INFO:root:At the start of the epoch: mem (CPU python)=42476.68359375MB; mem (CPU total)=42333.453125MB
INFO:root:[  120] Training loss: 0.61630193, Validation loss: 0.60897719, Gradient norm: 0.05795660
INFO:root:At the start of the epoch: mem (CPU python)=42514.78125MB; mem (CPU total)=42371.59765625MB
INFO:root:[  121] Training loss: 0.61605542, Validation loss: 0.60856083, Gradient norm: 0.05630441
INFO:root:At the start of the epoch: mem (CPU python)=42552.875MB; mem (CPU total)=42409.48828125MB
INFO:root:[  122] Training loss: 0.61599470, Validation loss: 0.60936803, Gradient norm: 0.05741450
INFO:root:At the start of the epoch: mem (CPU python)=42590.97265625MB; mem (CPU total)=42447.3828125MB
INFO:root:[  123] Training loss: 0.61575593, Validation loss: 0.60961836, Gradient norm: 0.05782529
INFO:root:At the start of the epoch: mem (CPU python)=42629.06640625MB; mem (CPU total)=42485.78515625MB
INFO:root:[  124] Training loss: 0.61585747, Validation loss: 0.60960994, Gradient norm: 0.06267494
INFO:root:At the start of the epoch: mem (CPU python)=42667.16015625MB; mem (CPU total)=42524.21484375MB
INFO:root:[  125] Training loss: 0.61540912, Validation loss: 0.60823201, Gradient norm: 0.05694510
INFO:root:At the start of the epoch: mem (CPU python)=42705.2578125MB; mem (CPU total)=42562.1015625MB
INFO:root:[  126] Training loss: 0.61575269, Validation loss: 0.60878468, Gradient norm: 0.06128967
INFO:root:At the start of the epoch: mem (CPU python)=42749.6015625MB; mem (CPU total)=42606.20703125MB
INFO:root:[  127] Training loss: 0.61570885, Validation loss: 0.60899410, Gradient norm: 0.06181250
INFO:root:At the start of the epoch: mem (CPU python)=42787.69921875MB; mem (CPU total)=42644.3515625MB
INFO:root:[  128] Training loss: 0.61574179, Validation loss: 0.60827251, Gradient norm: 0.06167782
INFO:root:At the start of the epoch: mem (CPU python)=42825.79296875MB; mem (CPU total)=42682.71875MB
INFO:root:[  129] Training loss: 0.61535541, Validation loss: 0.60845644, Gradient norm: 0.05856615
INFO:root:At the start of the epoch: mem (CPU python)=42863.890625MB; mem (CPU total)=42721.0234375MB
INFO:root:[  130] Training loss: 0.61508910, Validation loss: 0.60865878, Gradient norm: 0.05808756
INFO:root:At the start of the epoch: mem (CPU python)=42901.984375MB; mem (CPU total)=42758.91796875MB
INFO:root:[  131] Training loss: 0.61520450, Validation loss: 0.60878149, Gradient norm: 0.05932305
INFO:root:At the start of the epoch: mem (CPU python)=42940.078125MB; mem (CPU total)=42797.57421875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  132] Training loss: 0.61513326, Validation loss: 0.60818101, Gradient norm: 0.06024084
INFO:root:At the start of the epoch: mem (CPU python)=42978.17578125MB; mem (CPU total)=42835.7890625MB
INFO:root:[  133] Training loss: 0.61470688, Validation loss: 0.60782313, Gradient norm: 0.05510009
INFO:root:At the start of the epoch: mem (CPU python)=43016.26953125MB; mem (CPU total)=42873.9609375MB
INFO:root:[  134] Training loss: 0.61434043, Validation loss: 0.60802525, Gradient norm: 0.05490891
INFO:root:At the start of the epoch: mem (CPU python)=43054.36328125MB; mem (CPU total)=42913.328125MB
INFO:root:[  135] Training loss: 0.61457993, Validation loss: 0.60835460, Gradient norm: 0.05550284
INFO:root:At the start of the epoch: mem (CPU python)=43092.45703125MB; mem (CPU total)=42951.05078125MB
INFO:root:[  136] Training loss: 0.61436308, Validation loss: 0.60811400, Gradient norm: 0.05649342
INFO:root:At the start of the epoch: mem (CPU python)=43130.5625MB; mem (CPU total)=42989.1015625MB
INFO:root:[  137] Training loss: 0.61429463, Validation loss: 0.60771489, Gradient norm: 0.05951483
INFO:root:At the start of the epoch: mem (CPU python)=43168.65625MB; mem (CPU total)=43027.44921875MB
INFO:root:[  138] Training loss: 0.61454545, Validation loss: 0.60809580, Gradient norm: 0.05637924
INFO:root:At the start of the epoch: mem (CPU python)=43206.75MB; mem (CPU total)=43065.5234375MB
INFO:root:[  139] Training loss: 0.61413991, Validation loss: 0.60783991, Gradient norm: 0.05830821
INFO:root:At the start of the epoch: mem (CPU python)=43244.84765625MB; mem (CPU total)=43106.80078125MB
INFO:root:[  140] Training loss: 0.61428095, Validation loss: 0.60859441, Gradient norm: 0.05956099
INFO:root:At the start of the epoch: mem (CPU python)=43282.94140625MB; mem (CPU total)=43143.88671875MB
INFO:root:[  141] Training loss: 0.61416950, Validation loss: 0.60772814, Gradient norm: 0.05547902
INFO:root:At the start of the epoch: mem (CPU python)=43321.03515625MB; mem (CPU total)=43182.015625MB
INFO:root:[  142] Training loss: 0.61407292, Validation loss: 0.60731188, Gradient norm: 0.05966770
INFO:root:At the start of the epoch: mem (CPU python)=43359.1328125MB; mem (CPU total)=43220.15625MB
INFO:root:[  143] Training loss: 0.61418904, Validation loss: 0.60784219, Gradient norm: 0.05612230
INFO:root:At the start of the epoch: mem (CPU python)=43397.23046875MB; mem (CPU total)=43258.578125MB
INFO:root:[  144] Training loss: 0.61422226, Validation loss: 0.60721028, Gradient norm: 0.05537599
INFO:root:At the start of the epoch: mem (CPU python)=43435.3203125MB; mem (CPU total)=43296.69921875MB
INFO:root:[  145] Training loss: 0.61410811, Validation loss: 0.60779612, Gradient norm: 0.05568039
INFO:root:At the start of the epoch: mem (CPU python)=43473.41796875MB; mem (CPU total)=43334.58984375MB
INFO:root:[  146] Training loss: 0.61433112, Validation loss: 0.60735533, Gradient norm: 0.06138318
INFO:root:At the start of the epoch: mem (CPU python)=43511.515625MB; mem (CPU total)=43372.98828125MB
INFO:root:[  147] Training loss: 0.61394289, Validation loss: 0.60787897, Gradient norm: 0.05924818
INFO:root:At the start of the epoch: mem (CPU python)=43549.609375MB; mem (CPU total)=43410.87890625MB
INFO:root:[  148] Training loss: 0.61387040, Validation loss: 0.60806439, Gradient norm: 0.05645886
INFO:root:At the start of the epoch: mem (CPU python)=43587.703125MB; mem (CPU total)=43448.921875MB
INFO:root:[  149] Training loss: 0.61396870, Validation loss: 0.60811316, Gradient norm: 0.05431778
INFO:root:At the start of the epoch: mem (CPU python)=43625.80078125MB; mem (CPU total)=43487.3125MB
INFO:root:[  150] Training loss: 0.61375053, Validation loss: 0.60788644, Gradient norm: 0.05613085
INFO:root:At the start of the epoch: mem (CPU python)=43663.89453125MB; mem (CPU total)=43525.2109375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  151] Training loss: 0.61376143, Validation loss: 0.60796027, Gradient norm: 0.05663532
INFO:root:At the start of the epoch: mem (CPU python)=43701.98828125MB; mem (CPU total)=43563.34765625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  152] Training loss: 0.61343717, Validation loss: 0.60720706, Gradient norm: 0.05532225
INFO:root:At the start of the epoch: mem (CPU python)=43740.08203125MB; mem (CPU total)=43601.73828125MB
INFO:root:[  153] Training loss: 0.61320537, Validation loss: 0.60755199, Gradient norm: 0.05222181
INFO:root:At the start of the epoch: mem (CPU python)=43778.1796875MB; mem (CPU total)=43639.9296875MB
INFO:root:[  154] Training loss: 0.61323451, Validation loss: 0.60693330, Gradient norm: 0.05428943
INFO:root:At the start of the epoch: mem (CPU python)=43816.27734375MB; mem (CPU total)=43677.578125MB
INFO:root:[  155] Training loss: 0.61318439, Validation loss: 0.60750592, Gradient norm: 0.05341086
INFO:root:At the start of the epoch: mem (CPU python)=43854.37109375MB; mem (CPU total)=43715.46875MB
INFO:root:[  156] Training loss: 0.61304428, Validation loss: 0.60770604, Gradient norm: 0.05380929
INFO:root:At the start of the epoch: mem (CPU python)=43892.46875MB; mem (CPU total)=43753.84375MB
INFO:root:[  157] Training loss: 0.61312389, Validation loss: 0.60780563, Gradient norm: 0.05463952
INFO:root:At the start of the epoch: mem (CPU python)=43930.5625MB; mem (CPU total)=43791.98828125MB
INFO:root:[  158] Training loss: 0.61311020, Validation loss: 0.60842271, Gradient norm: 0.05473521
INFO:root:At the start of the epoch: mem (CPU python)=43968.65625MB; mem (CPU total)=43830.0390625MB
INFO:root:[  159] Training loss: 0.61317040, Validation loss: 0.60741905, Gradient norm: 0.05403241
INFO:root:At the start of the epoch: mem (CPU python)=44006.75390625MB; mem (CPU total)=43868.40625MB
INFO:root:[  160] Training loss: 0.61313951, Validation loss: 0.60747152, Gradient norm: 0.05450281
INFO:root:At the start of the epoch: mem (CPU python)=44044.84765625MB; mem (CPU total)=43906.55078125MB
INFO:root:[  161] Training loss: 0.61341874, Validation loss: 0.60714409, Gradient norm: 0.05423751
INFO:root:At the start of the epoch: mem (CPU python)=44082.94140625MB; mem (CPU total)=43944.453125MB
INFO:root:[  162] Training loss: 0.61320963, Validation loss: 0.60699992, Gradient norm: 0.05329033
INFO:root:At the start of the epoch: mem (CPU python)=44121.0390625MB; mem (CPU total)=43982.5859375MB
INFO:root:[  163] Training loss: 0.61311699, Validation loss: 0.60688574, Gradient norm: 0.05312303
INFO:root:At the start of the epoch: mem (CPU python)=44159.13671875MB; mem (CPU total)=44020.4765625MB
INFO:root:[  164] Training loss: 0.61301431, Validation loss: 0.60663785, Gradient norm: 0.05333204
INFO:root:At the start of the epoch: mem (CPU python)=44197.23046875MB; mem (CPU total)=44058.68359375MB
INFO:root:[  165] Training loss: 0.61305441, Validation loss: 0.60672830, Gradient norm: 0.05345848
INFO:root:At the start of the epoch: mem (CPU python)=44235.32421875MB; mem (CPU total)=44097.06640625MB
INFO:root:[  166] Training loss: 0.61318296, Validation loss: 0.60744198, Gradient norm: 0.05358980
INFO:root:At the start of the epoch: mem (CPU python)=44273.421875MB; mem (CPU total)=44134.97265625MB
INFO:root:[  167] Training loss: 0.61322162, Validation loss: 0.60691717, Gradient norm: 0.05311891
INFO:root:At the start of the epoch: mem (CPU python)=44311.515625MB; mem (CPU total)=44173.1171875MB
INFO:root:[  168] Training loss: 0.61309786, Validation loss: 0.60704370, Gradient norm: 0.05299004
INFO:root:At the start of the epoch: mem (CPU python)=44349.61328125MB; mem (CPU total)=44212.16015625MB
INFO:root:[  169] Training loss: 0.61304799, Validation loss: 0.60688949, Gradient norm: 0.05389226
INFO:root:At the start of the epoch: mem (CPU python)=44387.7109375MB; mem (CPU total)=44250.05078125MB
INFO:root:[  170] Training loss: 0.61307108, Validation loss: 0.60683643, Gradient norm: 0.05402186
INFO:root:At the start of the epoch: mem (CPU python)=44425.80859375MB; mem (CPU total)=44288.44921875MB
INFO:root:[  171] Training loss: 0.61292672, Validation loss: 0.60737803, Gradient norm: 0.05476336
INFO:root:At the start of the epoch: mem (CPU python)=44463.90234375MB; mem (CPU total)=44326.25390625MB
INFO:root:[  172] Training loss: 0.61334827, Validation loss: 0.60730776, Gradient norm: 0.05376676
INFO:root:At the start of the epoch: mem (CPU python)=44501.99609375MB; mem (CPU total)=44364.3984375MB
INFO:root:[  173] Training loss: 0.61287767, Validation loss: 0.60703103, Gradient norm: 0.05676845
INFO:root:At the start of the epoch: mem (CPU python)=44540.09375MB; mem (CPU total)=44402.52734375MB
INFO:root:EP 173: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=44578.1875MB; mem (CPU total)=44440.34375MB
INFO:root:Training the model took 13470.095s.
INFO:root:Emptying the cuda cache took 0.01s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8428
INFO:root:EnergyScoreTrain: 0.59334
INFO:root:CRPSTrain: 0.46015
INFO:root:Gaussian NLLTrain: 1.1885
INFO:root:CoverageTrain: 0.95163
INFO:root:IntervalWidthTrain: 3.27588
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8629
INFO:root:EnergyScoreValidation: 0.60737
INFO:root:CRPSValidation: 0.47204
INFO:root:Gaussian NLLValidation: 1.21423
INFO:root:CoverageValidation: 0.94517
INFO:root:IntervalWidthValidation: 3.27736
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86428
INFO:root:EnergyScoreTest: 0.60834
INFO:root:CRPSTest: 0.47294
INFO:root:Gaussian NLLTest: 1.21603
INFO:root:CoverageTest: 0.94492
INFO:root:IntervalWidthTest: 3.27891
INFO:root:After validation: mem (CPU python)=44634.375MB; mem (CPU total)=44475.78125MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=44634.375MB; mem (CPU total)=44408.7734375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=44634.375MB; mem (CPU total)=44408.7734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=44634.375MB; mem (CPU total)=44409.96875MB
INFO:root:[    1] Training loss: 0.72545917, Validation loss: 0.72062012, Gradient norm: 0.02109332
INFO:root:At the start of the epoch: mem (CPU python)=44634.375MB; mem (CPU total)=44447.046875MB
INFO:root:[    2] Training loss: 0.71991747, Validation loss: 0.71906459, Gradient norm: 0.00588445
INFO:root:At the start of the epoch: mem (CPU python)=44678.94921875MB; mem (CPU total)=44542.56640625MB
INFO:root:[    3] Training loss: 0.71883326, Validation loss: 0.71719799, Gradient norm: 0.00687134
INFO:root:At the start of the epoch: mem (CPU python)=44717.046875MB; mem (CPU total)=44580.5MB
INFO:root:[    4] Training loss: 0.71593970, Validation loss: 0.71056229, Gradient norm: 0.01237177
INFO:root:At the start of the epoch: mem (CPU python)=44717.2421875MB; mem (CPU total)=44554.71875MB
INFO:root:[    5] Training loss: 0.70916848, Validation loss: 0.70346832, Gradient norm: 0.02317675
INFO:root:At the start of the epoch: mem (CPU python)=44761.98046875MB; mem (CPU total)=44623.82421875MB
INFO:root:[    6] Training loss: 0.70317374, Validation loss: 0.69675519, Gradient norm: 0.02516757
INFO:root:At the start of the epoch: mem (CPU python)=44800.078125MB; mem (CPU total)=44661.68359375MB
INFO:root:[    7] Training loss: 0.69796793, Validation loss: 0.69132636, Gradient norm: 0.03053755
INFO:root:At the start of the epoch: mem (CPU python)=44838.171875MB; mem (CPU total)=44699.57421875MB
INFO:root:[    8] Training loss: 0.69336141, Validation loss: 0.68707903, Gradient norm: 0.02979351
INFO:root:At the start of the epoch: mem (CPU python)=44876.26953125MB; mem (CPU total)=44737.7109375MB
INFO:root:[    9] Training loss: 0.68865837, Validation loss: 0.68068928, Gradient norm: 0.02955111
INFO:root:At the start of the epoch: mem (CPU python)=44933.1171875MB; mem (CPU total)=44794.4765625MB
INFO:root:[   10] Training loss: 0.68431660, Validation loss: 0.67555854, Gradient norm: 0.03016718
INFO:root:At the start of the epoch: mem (CPU python)=44971.21484375MB; mem (CPU total)=44832.8671875MB
INFO:root:[   11] Training loss: 0.68006869, Validation loss: 0.67165042, Gradient norm: 0.02854689
INFO:root:At the start of the epoch: mem (CPU python)=45009.3046875MB; mem (CPU total)=44870.734375MB
INFO:root:[   12] Training loss: 0.67643701, Validation loss: 0.66750268, Gradient norm: 0.02962834
INFO:root:At the start of the epoch: mem (CPU python)=45034.90234375MB; mem (CPU total)=44896.44921875MB
INFO:root:[   13] Training loss: 0.67302842, Validation loss: 0.66367791, Gradient norm: 0.03139892
INFO:root:At the start of the epoch: mem (CPU python)=45085.50390625MB; mem (CPU total)=44947.73828125MB
INFO:root:[   14] Training loss: 0.66973699, Validation loss: 0.65993030, Gradient norm: 0.03063024
INFO:root:At the start of the epoch: mem (CPU python)=45123.59765625MB; mem (CPU total)=44985.72265625MB
INFO:root:[   15] Training loss: 0.66690550, Validation loss: 0.65723505, Gradient norm: 0.03138687
INFO:root:At the start of the epoch: mem (CPU python)=45174.19140625MB; mem (CPU total)=45036.0234375MB
INFO:root:[   16] Training loss: 0.66449720, Validation loss: 0.65437554, Gradient norm: 0.03366318
INFO:root:At the start of the epoch: mem (CPU python)=45212.28515625MB; mem (CPU total)=45074.16796875MB
INFO:root:[   17] Training loss: 0.66233750, Validation loss: 0.65219913, Gradient norm: 0.03306498
INFO:root:At the start of the epoch: mem (CPU python)=45250.38671875MB; mem (CPU total)=45112.3125MB
INFO:root:[   18] Training loss: 0.66023480, Validation loss: 0.64957203, Gradient norm: 0.03293217
INFO:root:At the start of the epoch: mem (CPU python)=45288.48046875MB; mem (CPU total)=45150.421875MB
INFO:root:[   19] Training loss: 0.65843021, Validation loss: 0.64828021, Gradient norm: 0.03276640
INFO:root:At the start of the epoch: mem (CPU python)=45339.07421875MB; mem (CPU total)=45200.99609375MB
INFO:root:[   20] Training loss: 0.65675148, Validation loss: 0.64615354, Gradient norm: 0.03744483
INFO:root:At the start of the epoch: mem (CPU python)=45377.171875MB; mem (CPU total)=45239.12109375MB
INFO:root:[   21] Training loss: 0.65521797, Validation loss: 0.64421772, Gradient norm: 0.03809145
INFO:root:At the start of the epoch: mem (CPU python)=45384.015625MB; mem (CPU total)=45246.375MB
INFO:root:[   22] Training loss: 0.65382072, Validation loss: 0.64372809, Gradient norm: 0.03587310
INFO:root:At the start of the epoch: mem (CPU python)=45447.109375MB; mem (CPU total)=45309.609375MB
INFO:root:[   23] Training loss: 0.65232441, Validation loss: 0.64078595, Gradient norm: 0.03691967
INFO:root:At the start of the epoch: mem (CPU python)=45485.20703125MB; mem (CPU total)=45347.74609375MB
INFO:root:[   24] Training loss: 0.65112323, Validation loss: 0.63960190, Gradient norm: 0.04111679
INFO:root:At the start of the epoch: mem (CPU python)=45523.30078125MB; mem (CPU total)=45385.875MB
INFO:root:[   25] Training loss: 0.64992979, Validation loss: 0.63930812, Gradient norm: 0.04048653
INFO:root:At the start of the epoch: mem (CPU python)=45553.71484375MB; mem (CPU total)=45380.16796875MB
INFO:root:[   26] Training loss: 0.64872369, Validation loss: 0.63717264, Gradient norm: 0.04073229
INFO:root:At the start of the epoch: mem (CPU python)=45587.0MB; mem (CPU total)=45449.6953125MB
INFO:root:[   27] Training loss: 0.64756678, Validation loss: 0.63620556, Gradient norm: 0.03896911
INFO:root:At the start of the epoch: mem (CPU python)=45625.09765625MB; mem (CPU total)=45487.83203125MB
INFO:root:[   28] Training loss: 0.64667771, Validation loss: 0.63561876, Gradient norm: 0.04070535
INFO:root:At the start of the epoch: mem (CPU python)=45669.43359375MB; mem (CPU total)=45532.4296875MB
INFO:root:[   29] Training loss: 0.64560460, Validation loss: 0.63516704, Gradient norm: 0.04455489
INFO:root:At the start of the epoch: mem (CPU python)=45701.28515625MB; mem (CPU total)=45564.3828125MB
INFO:root:[   30] Training loss: 0.64462177, Validation loss: 0.63365807, Gradient norm: 0.04092643
INFO:root:At the start of the epoch: mem (CPU python)=45733.125MB; mem (CPU total)=45596.2421875MB
INFO:root:[   31] Training loss: 0.64393170, Validation loss: 0.63236296, Gradient norm: 0.04250730
INFO:root:At the start of the epoch: mem (CPU python)=45789.9296875MB; mem (CPU total)=45653.22265625MB
INFO:root:[   32] Training loss: 0.64298950, Validation loss: 0.63162471, Gradient norm: 0.04477916
INFO:root:At the start of the epoch: mem (CPU python)=45820.41015625MB; mem (CPU total)=45672.4453125MB
INFO:root:[   33] Training loss: 0.64244536, Validation loss: 0.63078322, Gradient norm: 0.04285873
INFO:root:At the start of the epoch: mem (CPU python)=45859.91015625MB; mem (CPU total)=45723.08203125MB
INFO:root:[   34] Training loss: 0.64139504, Validation loss: 0.63006948, Gradient norm: 0.04404480
INFO:root:At the start of the epoch: mem (CPU python)=45898.00390625MB; mem (CPU total)=45761.45703125MB
INFO:root:[   35] Training loss: 0.64065857, Validation loss: 0.62891900, Gradient norm: 0.04198920
INFO:root:At the start of the epoch: mem (CPU python)=45929.859375MB; mem (CPU total)=45793.55859375MB
INFO:root:[   36] Training loss: 0.64003666, Validation loss: 0.62815300, Gradient norm: 0.04684515
INFO:root:At the start of the epoch: mem (CPU python)=45961.6953125MB; mem (CPU total)=45825.0078125MB
INFO:root:[   37] Training loss: 0.63922514, Validation loss: 0.62763277, Gradient norm: 0.04578424
INFO:root:At the start of the epoch: mem (CPU python)=46006.05078125MB; mem (CPU total)=45869.26953125MB
INFO:root:[   38] Training loss: 0.63882159, Validation loss: 0.62771670, Gradient norm: 0.04339800
INFO:root:At the start of the epoch: mem (CPU python)=46044.14453125MB; mem (CPU total)=45907.2578125MB
INFO:root:[   39] Training loss: 0.63823936, Validation loss: 0.62766796, Gradient norm: 0.04410153
INFO:root:At the start of the epoch: mem (CPU python)=46080.453125MB; mem (CPU total)=45944.2109375MB
INFO:root:[   40] Training loss: 0.63762978, Validation loss: 0.62629378, Gradient norm: 0.04536620
INFO:root:At the start of the epoch: mem (CPU python)=46118.55078125MB; mem (CPU total)=45982.31640625MB
INFO:root:[   41] Training loss: 0.63699502, Validation loss: 0.62606013, Gradient norm: 0.05293479
INFO:root:At the start of the epoch: mem (CPU python)=46164.671875MB; mem (CPU total)=46029.16015625MB
INFO:root:[   42] Training loss: 0.63634761, Validation loss: 0.62493589, Gradient norm: 0.04559886
INFO:root:At the start of the epoch: mem (CPU python)=46202.76953125MB; mem (CPU total)=46067.82421875MB
INFO:root:[   43] Training loss: 0.63583582, Validation loss: 0.62433680, Gradient norm: 0.04538123
INFO:root:At the start of the epoch: mem (CPU python)=46240.86328125MB; mem (CPU total)=46105.61328125MB
INFO:root:[   44] Training loss: 0.63555780, Validation loss: 0.62386680, Gradient norm: 0.04929070
INFO:root:At the start of the epoch: mem (CPU python)=46285.2109375MB; mem (CPU total)=46151.921875MB
INFO:root:[   45] Training loss: 0.63493225, Validation loss: 0.62410246, Gradient norm: 0.04906078
INFO:root:At the start of the epoch: mem (CPU python)=46326.43359375MB; mem (CPU total)=46192.84375MB
INFO:root:[   46] Training loss: 0.63438673, Validation loss: 0.62382189, Gradient norm: 0.05101127
INFO:root:At the start of the epoch: mem (CPU python)=46364.52734375MB; mem (CPU total)=46231.2734375MB
INFO:root:[   47] Training loss: 0.63397981, Validation loss: 0.62315069, Gradient norm: 0.04756067
INFO:root:At the start of the epoch: mem (CPU python)=46374.5MB; mem (CPU total)=46242.55859375MB
INFO:root:[   48] Training loss: 0.63322721, Validation loss: 0.62264152, Gradient norm: 0.04572303
INFO:root:At the start of the epoch: mem (CPU python)=46412.59375MB; mem (CPU total)=46280.6953125MB
INFO:root:[   49] Training loss: 0.63309417, Validation loss: 0.62182915, Gradient norm: 0.04425927
INFO:root:At the start of the epoch: mem (CPU python)=46450.69140625MB; mem (CPU total)=46319.08203125MB
INFO:root:[   50] Training loss: 0.63257099, Validation loss: 0.62087270, Gradient norm: 0.04476897
INFO:root:At the start of the epoch: mem (CPU python)=46488.78515625MB; mem (CPU total)=46353.49609375MB
INFO:root:[   51] Training loss: 0.63207091, Validation loss: 0.62145870, Gradient norm: 0.04958641
INFO:root:At the start of the epoch: mem (CPU python)=46545.6328125MB; mem (CPU total)=46410.2265625MB
INFO:root:[   52] Training loss: 0.63161432, Validation loss: 0.62044182, Gradient norm: 0.04931431
INFO:root:At the start of the epoch: mem (CPU python)=46589.9765625MB; mem (CPU total)=46454.66796875MB
INFO:root:[   53] Training loss: 0.63135873, Validation loss: 0.62052137, Gradient norm: 0.04638873
INFO:root:At the start of the epoch: mem (CPU python)=46609.3203125MB; mem (CPU total)=46474.07421875MB
INFO:root:[   54] Training loss: 0.63098936, Validation loss: 0.62018559, Gradient norm: 0.04906650
INFO:root:At the start of the epoch: mem (CPU python)=46672.41796875MB; mem (CPU total)=46537.39453125MB
INFO:root:[   55] Training loss: 0.63054786, Validation loss: 0.61974774, Gradient norm: 0.04922389
INFO:root:At the start of the epoch: mem (CPU python)=46710.51171875MB; mem (CPU total)=46575.5703125MB
INFO:root:[   56] Training loss: 0.63031317, Validation loss: 0.61980449, Gradient norm: 0.05131410
INFO:root:At the start of the epoch: mem (CPU python)=46742.359375MB; mem (CPU total)=46607.69921875MB
INFO:root:[   57] Training loss: 0.62959242, Validation loss: 0.61777820, Gradient norm: 0.04597323
INFO:root:At the start of the epoch: mem (CPU python)=46780.453125MB; mem (CPU total)=46645.24609375MB
INFO:root:[   58] Training loss: 0.62937670, Validation loss: 0.61878158, Gradient norm: 0.05052988
INFO:root:At the start of the epoch: mem (CPU python)=46818.55078125MB; mem (CPU total)=46683.37109375MB
INFO:root:[   59] Training loss: 0.62893443, Validation loss: 0.61762041, Gradient norm: 0.05324663
INFO:root:At the start of the epoch: mem (CPU python)=46856.64453125MB; mem (CPU total)=46721.76171875MB
INFO:root:[   60] Training loss: 0.62875083, Validation loss: 0.61823811, Gradient norm: 0.05237434
INFO:root:At the start of the epoch: mem (CPU python)=46869.73828125MB; mem (CPU total)=46736.984375MB
INFO:root:[   61] Training loss: 0.62833278, Validation loss: 0.61705722, Gradient norm: 0.05190935
INFO:root:At the start of the epoch: mem (CPU python)=46920.34375MB; mem (CPU total)=46787.16796875MB
INFO:root:[   62] Training loss: 0.62807856, Validation loss: 0.61752715, Gradient norm: 0.05441998
INFO:root:At the start of the epoch: mem (CPU python)=46970.9296875MB; mem (CPU total)=46838.05078125MB
INFO:root:[   63] Training loss: 0.62755456, Validation loss: 0.61738685, Gradient norm: 0.04816957
INFO:root:At the start of the epoch: mem (CPU python)=46984.02734375MB; mem (CPU total)=46851.234375MB
INFO:root:[   64] Training loss: 0.62737331, Validation loss: 0.61634798, Gradient norm: 0.05034733
INFO:root:At the start of the epoch: mem (CPU python)=47022.125MB; mem (CPU total)=46887.6875MB
INFO:root:[   65] Training loss: 0.62715336, Validation loss: 0.61600126, Gradient norm: 0.04789085
INFO:root:At the start of the epoch: mem (CPU python)=47082.09375MB; mem (CPU total)=46947.11328125MB
INFO:root:[   66] Training loss: 0.62659117, Validation loss: 0.61575646, Gradient norm: 0.04929038
INFO:root:At the start of the epoch: mem (CPU python)=47104.5625MB; mem (CPU total)=46969.84375MB
INFO:root:[   67] Training loss: 0.62630165, Validation loss: 0.61596789, Gradient norm: 0.05380649
INFO:root:At the start of the epoch: mem (CPU python)=47155.16015625MB; mem (CPU total)=47020.48046875MB
INFO:root:[   68] Training loss: 0.62620626, Validation loss: 0.61586045, Gradient norm: 0.05592523
INFO:root:At the start of the epoch: mem (CPU python)=47193.2578125MB; mem (CPU total)=47058.34765625MB
INFO:root:[   69] Training loss: 0.62602421, Validation loss: 0.61553245, Gradient norm: 0.05512143
INFO:root:At the start of the epoch: mem (CPU python)=47231.3515625MB; mem (CPU total)=47096.46875MB
INFO:root:[   70] Training loss: 0.62555351, Validation loss: 0.61512322, Gradient norm: 0.04960468
INFO:root:At the start of the epoch: mem (CPU python)=47275.6953125MB; mem (CPU total)=47141.37109375MB
INFO:root:[   71] Training loss: 0.62548269, Validation loss: 0.61529046, Gradient norm: 0.05179348
INFO:root:At the start of the epoch: mem (CPU python)=47313.79296875MB; mem (CPU total)=47179.5625MB
INFO:root:[   72] Training loss: 0.62511025, Validation loss: 0.61511667, Gradient norm: 0.05785330
INFO:root:At the start of the epoch: mem (CPU python)=47351.88671875MB; mem (CPU total)=47217.48046875MB
INFO:root:[   73] Training loss: 0.62460467, Validation loss: 0.61412912, Gradient norm: 0.05285501
INFO:root:At the start of the epoch: mem (CPU python)=47389.98046875MB; mem (CPU total)=47255.59375MB
INFO:root:[   74] Training loss: 0.62435093, Validation loss: 0.61468102, Gradient norm: 0.04997750
INFO:root:At the start of the epoch: mem (CPU python)=47415.58984375MB; mem (CPU total)=47281.23046875MB
INFO:root:[   75] Training loss: 0.62406200, Validation loss: 0.61353039, Gradient norm: 0.05386592
INFO:root:At the start of the epoch: mem (CPU python)=47453.68359375MB; mem (CPU total)=47319.62109375MB
INFO:root:[   76] Training loss: 0.62398490, Validation loss: 0.61424107, Gradient norm: 0.05121715
INFO:root:At the start of the epoch: mem (CPU python)=47491.77734375MB; mem (CPU total)=47356.19921875MB
INFO:root:[   77] Training loss: 0.62376637, Validation loss: 0.61356560, Gradient norm: 0.05574723
INFO:root:At the start of the epoch: mem (CPU python)=47529.87109375MB; mem (CPU total)=47394.5703125MB
INFO:root:[   78] Training loss: 0.62333755, Validation loss: 0.61396912, Gradient norm: 0.05020313
INFO:root:At the start of the epoch: mem (CPU python)=47567.96875MB; mem (CPU total)=47432.72265625MB
INFO:root:[   79] Training loss: 0.62317468, Validation loss: 0.61332236, Gradient norm: 0.05198576
INFO:root:At the start of the epoch: mem (CPU python)=47606.0625MB; mem (CPU total)=47471.03125MB
INFO:root:[   80] Training loss: 0.62311043, Validation loss: 0.61320308, Gradient norm: 0.05258485
INFO:root:At the start of the epoch: mem (CPU python)=47644.15625MB; mem (CPU total)=47509.20703125MB
INFO:root:[   81] Training loss: 0.62270246, Validation loss: 0.61269942, Gradient norm: 0.05052271
INFO:root:At the start of the epoch: mem (CPU python)=47682.25390625MB; mem (CPU total)=47547.0703125MB
INFO:root:[   82] Training loss: 0.62250496, Validation loss: 0.61212404, Gradient norm: 0.06100413
INFO:root:At the start of the epoch: mem (CPU python)=47720.34765625MB; mem (CPU total)=47584.96875MB
INFO:root:[   83] Training loss: 0.62241286, Validation loss: 0.61337203, Gradient norm: 0.05732915
INFO:root:At the start of the epoch: mem (CPU python)=47745.9375MB; mem (CPU total)=47610.859375MB
INFO:root:[   84] Training loss: 0.62213212, Validation loss: 0.61212997, Gradient norm: 0.05581289
INFO:root:At the start of the epoch: mem (CPU python)=47784.03125MB; mem (CPU total)=47650.44140625MB
INFO:root:[   85] Training loss: 0.62202382, Validation loss: 0.61251625, Gradient norm: 0.05241083
INFO:root:At the start of the epoch: mem (CPU python)=47840.99609375MB; mem (CPU total)=47707.296875MB
INFO:root:[   86] Training loss: 0.62164083, Validation loss: 0.61257914, Gradient norm: 0.05625000
INFO:root:At the start of the epoch: mem (CPU python)=47879.08984375MB; mem (CPU total)=47745.29296875MB
INFO:root:[   87] Training loss: 0.62147384, Validation loss: 0.61027929, Gradient norm: 0.05283890
INFO:root:At the start of the epoch: mem (CPU python)=47917.18359375MB; mem (CPU total)=47783.46875MB
INFO:root:[   88] Training loss: 0.62140376, Validation loss: 0.61131128, Gradient norm: 0.05387732
INFO:root:At the start of the epoch: mem (CPU python)=47947.6171875MB; mem (CPU total)=47802.71484375MB
INFO:root:[   89] Training loss: 0.62098862, Validation loss: 0.61098875, Gradient norm: 0.05355173
INFO:root:At the start of the epoch: mem (CPU python)=47999.5078125MB; mem (CPU total)=47866.2421875MB
INFO:root:[   90] Training loss: 0.62080827, Validation loss: 0.61073692, Gradient norm: 0.05559524
INFO:root:At the start of the epoch: mem (CPU python)=48037.6015625MB; mem (CPU total)=47904.609375MB
INFO:root:[   91] Training loss: 0.62069586, Validation loss: 0.61171895, Gradient norm: 0.05464541
INFO:root:At the start of the epoch: mem (CPU python)=48075.69921875MB; mem (CPU total)=47942.609375MB
INFO:root:[   92] Training loss: 0.62045477, Validation loss: 0.61104514, Gradient norm: 0.05720079
INFO:root:At the start of the epoch: mem (CPU python)=48090.671875MB; mem (CPU total)=47959.0703125MB
INFO:root:[   93] Training loss: 0.62051108, Validation loss: 0.61114477, Gradient norm: 0.05288364
INFO:root:At the start of the epoch: mem (CPU python)=48141.265625MB; mem (CPU total)=48009.63671875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   94] Training loss: 0.61994832, Validation loss: 0.61035081, Gradient norm: 0.05120393
INFO:root:At the start of the epoch: mem (CPU python)=48158.73046875MB; mem (CPU total)=48025.15234375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   95] Training loss: 0.61929383, Validation loss: 0.61071902, Gradient norm: 0.05212663
INFO:root:At the start of the epoch: mem (CPU python)=48196.828125MB; mem (CPU total)=48063.28125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   96] Training loss: 0.61879665, Validation loss: 0.61015355, Gradient norm: 0.04394737
INFO:root:At the start of the epoch: mem (CPU python)=48247.42578125MB; mem (CPU total)=48114.34765625MB
INFO:root:[   97] Training loss: 0.61840712, Validation loss: 0.60962547, Gradient norm: 0.04250708
INFO:root:At the start of the epoch: mem (CPU python)=48254.265625MB; mem (CPU total)=48122.89453125MB
INFO:root:[   98] Training loss: 0.61820282, Validation loss: 0.60920231, Gradient norm: 0.04290604
INFO:root:At the start of the epoch: mem (CPU python)=48336.1171875MB; mem (CPU total)=48204.63671875MB
INFO:root:[   99] Training loss: 0.61825891, Validation loss: 0.60911053, Gradient norm: 0.04306625
INFO:root:At the start of the epoch: mem (CPU python)=48380.4609375MB; mem (CPU total)=48248.82421875MB
INFO:root:[  100] Training loss: 0.61828717, Validation loss: 0.60930237, Gradient norm: 0.04431463
INFO:root:At the start of the epoch: mem (CPU python)=48418.55859375MB; mem (CPU total)=48286.62109375MB
INFO:root:[  101] Training loss: 0.61804236, Validation loss: 0.60832353, Gradient norm: 0.04417621
INFO:root:At the start of the epoch: mem (CPU python)=48456.65234375MB; mem (CPU total)=48325.2578125MB
INFO:root:[  102] Training loss: 0.61795171, Validation loss: 0.60882413, Gradient norm: 0.04316840
INFO:root:At the start of the epoch: mem (CPU python)=48494.75MB; mem (CPU total)=48365.37109375MB
INFO:root:[  103] Training loss: 0.61807525, Validation loss: 0.60925428, Gradient norm: 0.04221668
INFO:root:At the start of the epoch: mem (CPU python)=48520.3515625MB; mem (CPU total)=48387.39453125MB
INFO:root:[  104] Training loss: 0.61788592, Validation loss: 0.60964038, Gradient norm: 0.04295149
INFO:root:At the start of the epoch: mem (CPU python)=48558.4453125MB; mem (CPU total)=48425.9375MB
INFO:root:[  105] Training loss: 0.61792814, Validation loss: 0.60879644, Gradient norm: 0.04374307
INFO:root:At the start of the epoch: mem (CPU python)=48596.54296875MB; mem (CPU total)=48463.82421875MB
INFO:root:[  106] Training loss: 0.61785313, Validation loss: 0.60901961, Gradient norm: 0.04229815
INFO:root:At the start of the epoch: mem (CPU python)=48634.640625MB; mem (CPU total)=48501.42578125MB
INFO:root:[  107] Training loss: 0.61803984, Validation loss: 0.60937654, Gradient norm: 0.04427704
INFO:root:At the start of the epoch: mem (CPU python)=48672.734375MB; mem (CPU total)=48539.77734375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  108] Training loss: 0.61770397, Validation loss: 0.60921572, Gradient norm: 0.04610811
INFO:root:At the start of the epoch: mem (CPU python)=48712.703125MB; mem (CPU total)=48580.59765625MB
INFO:root:[  109] Training loss: 0.61797144, Validation loss: 0.60955048, Gradient norm: 0.04339505
INFO:root:At the start of the epoch: mem (CPU python)=48750.796875MB; mem (CPU total)=48618.7421875MB
INFO:root:[  110] Training loss: 0.61777602, Validation loss: 0.60926048, Gradient norm: 0.04422353
INFO:root:At the start of the epoch: mem (CPU python)=48788.890625MB; mem (CPU total)=48656.88671875MB
INFO:root:EP 110: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=48820.109375MB; mem (CPU total)=48689.6171875MB
INFO:root:Training the model took 9394.38s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8526
INFO:root:EnergyScoreTrain: 0.6002
INFO:root:CRPSTrain: 0.46761
INFO:root:Gaussian NLLTrain: 2.47117
INFO:root:CoverageTrain: 0.94489
INFO:root:IntervalWidthTrain: 3.27816
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86555
INFO:root:EnergyScoreValidation: 0.60925
INFO:root:CRPSValidation: 0.47533
INFO:root:Gaussian NLLValidation: 2.54494
INFO:root:CoverageValidation: 0.94072
INFO:root:IntervalWidthValidation: 3.27959
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86696
INFO:root:EnergyScoreTest: 0.61022
INFO:root:CRPSTest: 0.47629
INFO:root:Gaussian NLLTest: 2.57912
INFO:root:CoverageTest: 0.94076
INFO:root:IntervalWidthTest: 3.2836
INFO:root:After validation: mem (CPU python)=48925.57421875MB; mem (CPU total)=48735.07421875MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=48925.57421875MB; mem (CPU total)=48734.7578125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=48925.57421875MB; mem (CPU total)=48734.7578125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=48925.57421875MB; mem (CPU total)=48734.765625MB
INFO:root:[    1] Training loss: 0.72691991, Validation loss: 0.72037251, Gradient norm: 0.03099800
INFO:root:At the start of the epoch: mem (CPU python)=48925.57421875MB; mem (CPU total)=48772.44140625MB
INFO:root:[    2] Training loss: 0.71999806, Validation loss: 0.71829452, Gradient norm: 0.00603500
INFO:root:At the start of the epoch: mem (CPU python)=48945.4921875MB; mem (CPU total)=48816.12890625MB
INFO:root:[    3] Training loss: 0.71750600, Validation loss: 0.71320107, Gradient norm: 0.00883733
INFO:root:At the start of the epoch: mem (CPU python)=48983.5859375MB; mem (CPU total)=48854.53515625MB
INFO:root:[    4] Training loss: 0.71120607, Validation loss: 0.70495841, Gradient norm: 0.01773815
INFO:root:At the start of the epoch: mem (CPU python)=49021.6796875MB; mem (CPU total)=48892.74609375MB
INFO:root:[    5] Training loss: 0.70410246, Validation loss: 0.69767852, Gradient norm: 0.02325049
INFO:root:At the start of the epoch: mem (CPU python)=49059.78125MB; mem (CPU total)=48931.5625MB
INFO:root:[    6] Training loss: 0.69823380, Validation loss: 0.69124910, Gradient norm: 0.02599658
INFO:root:At the start of the epoch: mem (CPU python)=49097.875MB; mem (CPU total)=48968.81640625MB
INFO:root:[    7] Training loss: 0.69330206, Validation loss: 0.68640873, Gradient norm: 0.02714059
INFO:root:At the start of the epoch: mem (CPU python)=49135.96875MB; mem (CPU total)=49006.80078125MB
INFO:root:[    8] Training loss: 0.68872635, Validation loss: 0.68176820, Gradient norm: 0.02648490
INFO:root:At the start of the epoch: mem (CPU python)=49186.56640625MB; mem (CPU total)=49057.6015625MB
INFO:root:[    9] Training loss: 0.68483771, Validation loss: 0.67636873, Gradient norm: 0.02839914
INFO:root:At the start of the epoch: mem (CPU python)=49224.66015625MB; mem (CPU total)=49095.7890625MB
INFO:root:[   10] Training loss: 0.68124672, Validation loss: 0.67294300, Gradient norm: 0.02740984
INFO:root:At the start of the epoch: mem (CPU python)=49262.75390625MB; mem (CPU total)=49134.09375MB
INFO:root:[   11] Training loss: 0.67790621, Validation loss: 0.66949916, Gradient norm: 0.02585134
INFO:root:At the start of the epoch: mem (CPU python)=49262.9765625MB; mem (CPU total)=49127.96484375MB
INFO:root:[   12] Training loss: 0.67441472, Validation loss: 0.66547768, Gradient norm: 0.02655653
INFO:root:At the start of the epoch: mem (CPU python)=49307.6953125MB; mem (CPU total)=49178.8515625MB
INFO:root:[   13] Training loss: 0.67137499, Validation loss: 0.66152657, Gradient norm: 0.02935419
INFO:root:At the start of the epoch: mem (CPU python)=49358.2890625MB; mem (CPU total)=49229.4375MB
INFO:root:[   14] Training loss: 0.66858141, Validation loss: 0.65917057, Gradient norm: 0.03055409
INFO:root:At the start of the epoch: mem (CPU python)=49396.38671875MB; mem (CPU total)=49268.125MB
INFO:root:[   15] Training loss: 0.66602306, Validation loss: 0.65567135, Gradient norm: 0.03170319
INFO:root:At the start of the epoch: mem (CPU python)=49434.484375MB; mem (CPU total)=49305.921875MB
INFO:root:[   16] Training loss: 0.66380959, Validation loss: 0.65419263, Gradient norm: 0.03102399
INFO:root:At the start of the epoch: mem (CPU python)=49472.578125MB; mem (CPU total)=49344.06640625MB
INFO:root:[   17] Training loss: 0.66183323, Validation loss: 0.65245557, Gradient norm: 0.03224134
INFO:root:At the start of the epoch: mem (CPU python)=49520.2421875MB; mem (CPU total)=49391.96484375MB
INFO:root:[   18] Training loss: 0.65997210, Validation loss: 0.65036486, Gradient norm: 0.03246677
INFO:root:At the start of the epoch: mem (CPU python)=49558.33984375MB; mem (CPU total)=49430.69140625MB
INFO:root:[   19] Training loss: 0.65831870, Validation loss: 0.64760250, Gradient norm: 0.03221478
INFO:root:At the start of the epoch: mem (CPU python)=49596.43359375MB; mem (CPU total)=49468.61328125MB
INFO:root:[   20] Training loss: 0.65680787, Validation loss: 0.64669658, Gradient norm: 0.03793334
INFO:root:At the start of the epoch: mem (CPU python)=49634.52734375MB; mem (CPU total)=49506.3828125MB
INFO:root:[   21] Training loss: 0.65527363, Validation loss: 0.64497250, Gradient norm: 0.03681217
INFO:root:At the start of the epoch: mem (CPU python)=49672.625MB; mem (CPU total)=49544.96484375MB
INFO:root:[   22] Training loss: 0.65405229, Validation loss: 0.64403715, Gradient norm: 0.03859169
INFO:root:At the start of the epoch: mem (CPU python)=49710.72265625MB; mem (CPU total)=49583.0625MB
INFO:root:[   23] Training loss: 0.65264017, Validation loss: 0.64238126, Gradient norm: 0.03874723
INFO:root:At the start of the epoch: mem (CPU python)=49748.81640625MB; mem (CPU total)=49620.95703125MB
INFO:root:[   24] Training loss: 0.65157389, Validation loss: 0.64122127, Gradient norm: 0.03881517
INFO:root:At the start of the epoch: mem (CPU python)=49786.91015625MB; mem (CPU total)=49659.1328125MB
INFO:root:[   25] Training loss: 0.65034716, Validation loss: 0.63949216, Gradient norm: 0.03926107
INFO:root:At the start of the epoch: mem (CPU python)=49827.9375MB; mem (CPU total)=49700.5078125MB
INFO:root:[   26] Training loss: 0.64928326, Validation loss: 0.63897730, Gradient norm: 0.04109602
INFO:root:At the start of the epoch: mem (CPU python)=49866.03125MB; mem (CPU total)=49738.671875MB
INFO:root:[   27] Training loss: 0.64836435, Validation loss: 0.63789821, Gradient norm: 0.04446920
INFO:root:At the start of the epoch: mem (CPU python)=49904.125MB; mem (CPU total)=49776.6015625MB
INFO:root:[   28] Training loss: 0.64735570, Validation loss: 0.63668068, Gradient norm: 0.03909121
INFO:root:At the start of the epoch: mem (CPU python)=49923.47265625MB; mem (CPU total)=49795.8828125MB
INFO:root:[   29] Training loss: 0.64635410, Validation loss: 0.63581457, Gradient norm: 0.04228470
INFO:root:At the start of the epoch: mem (CPU python)=49980.3203125MB; mem (CPU total)=49852.9375MB
INFO:root:[   30] Training loss: 0.64535919, Validation loss: 0.63531335, Gradient norm: 0.04524502
INFO:root:At the start of the epoch: mem (CPU python)=50018.4140625MB; mem (CPU total)=49891.11328125MB
INFO:root:[   31] Training loss: 0.64458029, Validation loss: 0.63352628, Gradient norm: 0.04093064
INFO:root:At the start of the epoch: mem (CPU python)=50056.5078125MB; mem (CPU total)=49929.5390625MB
INFO:root:[   32] Training loss: 0.64379936, Validation loss: 0.63365021, Gradient norm: 0.04925204
INFO:root:At the start of the epoch: mem (CPU python)=50100.85546875MB; mem (CPU total)=49973.91015625MB
INFO:root:[   33] Training loss: 0.64285861, Validation loss: 0.63280108, Gradient norm: 0.04204858
INFO:root:At the start of the epoch: mem (CPU python)=50138.94921875MB; mem (CPU total)=50010.80859375MB
INFO:root:[   34] Training loss: 0.64215486, Validation loss: 0.63158307, Gradient norm: 0.04646173
INFO:root:At the start of the epoch: mem (CPU python)=50177.04296875MB; mem (CPU total)=50048.95703125MB
INFO:root:[   35] Training loss: 0.64137966, Validation loss: 0.63071471, Gradient norm: 0.04480604
INFO:root:At the start of the epoch: mem (CPU python)=50184.57421875MB; mem (CPU total)=50056.89453125MB
INFO:root:[   36] Training loss: 0.64063897, Validation loss: 0.62967055, Gradient norm: 0.04179159
INFO:root:At the start of the epoch: mem (CPU python)=50228.91796875MB; mem (CPU total)=50101.28515625MB
INFO:root:[   37] Training loss: 0.64002710, Validation loss: 0.62976734, Gradient norm: 0.05034962
INFO:root:At the start of the epoch: mem (CPU python)=50279.515625MB; mem (CPU total)=50152.16796875MB
INFO:root:[   38] Training loss: 0.63933886, Validation loss: 0.62816578, Gradient norm: 0.04307028
INFO:root:At the start of the epoch: mem (CPU python)=50323.17578125MB; mem (CPU total)=50195.83203125MB
INFO:root:[   39] Training loss: 0.63871634, Validation loss: 0.62885615, Gradient norm: 0.04564024
INFO:root:At the start of the epoch: mem (CPU python)=50361.2734375MB; mem (CPU total)=50234.22265625MB
INFO:root:[   40] Training loss: 0.63810574, Validation loss: 0.62714870, Gradient norm: 0.04539733
INFO:root:At the start of the epoch: mem (CPU python)=50380.6171875MB; mem (CPU total)=50253.01953125MB
INFO:root:[   41] Training loss: 0.63729727, Validation loss: 0.62727271, Gradient norm: 0.04919350
INFO:root:At the start of the epoch: mem (CPU python)=50418.7109375MB; mem (CPU total)=50291.23046875MB
INFO:root:[   42] Training loss: 0.63680245, Validation loss: 0.62681871, Gradient norm: 0.04651124
INFO:root:At the start of the epoch: mem (CPU python)=50475.55859375MB; mem (CPU total)=50348.11328125MB
INFO:root:[   43] Training loss: 0.63649788, Validation loss: 0.62593281, Gradient norm: 0.04433173
INFO:root:At the start of the epoch: mem (CPU python)=50513.65234375MB; mem (CPU total)=50386.26171875MB
INFO:root:[   44] Training loss: 0.63584036, Validation loss: 0.62512705, Gradient norm: 0.04558142
INFO:root:At the start of the epoch: mem (CPU python)=50551.74609375MB; mem (CPU total)=50424.4375MB
INFO:root:[   45] Training loss: 0.63537426, Validation loss: 0.62522545, Gradient norm: 0.04949555
INFO:root:At the start of the epoch: mem (CPU python)=50564.84375MB; mem (CPU total)=50437.98828125MB
INFO:root:[   46] Training loss: 0.63447400, Validation loss: 0.62451998, Gradient norm: 0.04333327
INFO:root:At the start of the epoch: mem (CPU python)=50640.44140625MB; mem (CPU total)=50513.71484375MB
INFO:root:[   47] Training loss: 0.63436143, Validation loss: 0.62448101, Gradient norm: 0.05370617
INFO:root:At the start of the epoch: mem (CPU python)=50678.53515625MB; mem (CPU total)=50551.64453125MB
INFO:root:[   48] Training loss: 0.63356486, Validation loss: 0.62432264, Gradient norm: 0.04710073
INFO:root:At the start of the epoch: mem (CPU python)=50697.87890625MB; mem (CPU total)=50570.95703125MB
INFO:root:[   49] Training loss: 0.63339106, Validation loss: 0.62337542, Gradient norm: 0.04740811
INFO:root:At the start of the epoch: mem (CPU python)=50735.9765625MB; mem (CPU total)=50609.64453125MB
INFO:root:[   50] Training loss: 0.63272998, Validation loss: 0.62207028, Gradient norm: 0.04994232
INFO:root:At the start of the epoch: mem (CPU python)=50774.0703125MB; mem (CPU total)=50647.48046875MB
INFO:root:[   51] Training loss: 0.63253149, Validation loss: 0.62290509, Gradient norm: 0.04814207
INFO:root:At the start of the epoch: mem (CPU python)=50812.1640625MB; mem (CPU total)=50685.64453125MB
INFO:root:[   52] Training loss: 0.63193520, Validation loss: 0.62207256, Gradient norm: 0.04958958
INFO:root:At the start of the epoch: mem (CPU python)=50850.26171875MB; mem (CPU total)=50724.0078125MB
INFO:root:[   53] Training loss: 0.63169811, Validation loss: 0.62143950, Gradient norm: 0.04758915
INFO:root:At the start of the epoch: mem (CPU python)=50900.859375MB; mem (CPU total)=50774.9140625MB
INFO:root:[   54] Training loss: 0.63129466, Validation loss: 0.62239603, Gradient norm: 0.05657661
INFO:root:At the start of the epoch: mem (CPU python)=50938.953125MB; mem (CPU total)=50812.85546875MB
INFO:root:[   55] Training loss: 0.63072109, Validation loss: 0.62079203, Gradient norm: 0.05073073
INFO:root:At the start of the epoch: mem (CPU python)=50939.84375MB; mem (CPU total)=50807.03125MB
INFO:root:[   56] Training loss: 0.63036603, Validation loss: 0.62055504, Gradient norm: 0.04834549
INFO:root:At the start of the epoch: mem (CPU python)=50983.89453125MB; mem (CPU total)=50857.64453125MB
INFO:root:[   57] Training loss: 0.62996302, Validation loss: 0.62162181, Gradient norm: 0.04891651
INFO:root:At the start of the epoch: mem (CPU python)=51040.73828125MB; mem (CPU total)=50914.63671875MB
INFO:root:[   58] Training loss: 0.62986193, Validation loss: 0.62027782, Gradient norm: 0.04931822
INFO:root:At the start of the epoch: mem (CPU python)=51085.08203125MB; mem (CPU total)=50959.16796875MB
INFO:root:[   59] Training loss: 0.62927982, Validation loss: 0.61931638, Gradient norm: 0.05204050
INFO:root:At the start of the epoch: mem (CPU python)=51123.1796875MB; mem (CPU total)=50997.3671875MB
INFO:root:[   60] Training loss: 0.62920250, Validation loss: 0.61952238, Gradient norm: 0.05112587
INFO:root:At the start of the epoch: mem (CPU python)=51148.7734375MB; mem (CPU total)=51022.6171875MB
INFO:root:[   61] Training loss: 0.62871077, Validation loss: 0.61966494, Gradient norm: 0.04907127
INFO:root:At the start of the epoch: mem (CPU python)=51186.87109375MB; mem (CPU total)=51060.7890625MB
INFO:root:[   62] Training loss: 0.62843707, Validation loss: 0.61915986, Gradient norm: 0.05656389
INFO:root:At the start of the epoch: mem (CPU python)=51224.9609375MB; mem (CPU total)=51098.7265625MB
INFO:root:[   63] Training loss: 0.62800049, Validation loss: 0.61807396, Gradient norm: 0.05433334
INFO:root:At the start of the epoch: mem (CPU python)=51263.0625MB; mem (CPU total)=51137.14453125MB
INFO:root:[   64] Training loss: 0.62748473, Validation loss: 0.61829317, Gradient norm: 0.05064203
INFO:root:At the start of the epoch: mem (CPU python)=51313.65625MB; mem (CPU total)=51187.43359375MB
INFO:root:[   65] Training loss: 0.62744711, Validation loss: 0.61787657, Gradient norm: 0.05475116
INFO:root:At the start of the epoch: mem (CPU python)=51345.5MB; mem (CPU total)=51219.640625MB
INFO:root:[   66] Training loss: 0.62706300, Validation loss: 0.61802885, Gradient norm: 0.05082874
INFO:root:At the start of the epoch: mem (CPU python)=51383.59765625MB; mem (CPU total)=51257.54296875MB
INFO:root:[   67] Training loss: 0.62684442, Validation loss: 0.61690064, Gradient norm: 0.05357794
INFO:root:At the start of the epoch: mem (CPU python)=51427.94140625MB; mem (CPU total)=51302.3984375MB
INFO:root:[   68] Training loss: 0.62659741, Validation loss: 0.61694767, Gradient norm: 0.05328329
INFO:root:At the start of the epoch: mem (CPU python)=51458.39453125MB; mem (CPU total)=51315.5MB
INFO:root:[   69] Training loss: 0.62644707, Validation loss: 0.61758388, Gradient norm: 0.05221059
INFO:root:At the start of the epoch: mem (CPU python)=51479.1328125MB; mem (CPU total)=51353.42578125MB
INFO:root:[   70] Training loss: 0.62595196, Validation loss: 0.61656918, Gradient norm: 0.04894821
INFO:root:At the start of the epoch: mem (CPU python)=51517.23046875MB; mem (CPU total)=51391.63671875MB
INFO:root:[   71] Training loss: 0.62591631, Validation loss: 0.61597704, Gradient norm: 0.05605431
INFO:root:At the start of the epoch: mem (CPU python)=51577.234375MB; mem (CPU total)=51452.2109375MB
INFO:root:[   72] Training loss: 0.62530112, Validation loss: 0.61592283, Gradient norm: 0.05569419
INFO:root:At the start of the epoch: mem (CPU python)=51615.328125MB; mem (CPU total)=51490.390625MB
INFO:root:[   73] Training loss: 0.62500795, Validation loss: 0.61578822, Gradient norm: 0.05039687
INFO:root:At the start of the epoch: mem (CPU python)=51653.42578125MB; mem (CPU total)=51528.5390625MB
INFO:root:[   74] Training loss: 0.62484226, Validation loss: 0.61634595, Gradient norm: 0.05686558
INFO:root:At the start of the epoch: mem (CPU python)=51691.51953125MB; mem (CPU total)=51566.69921875MB
INFO:root:[   75] Training loss: 0.62459700, Validation loss: 0.61685130, Gradient norm: 0.05401807
INFO:root:At the start of the epoch: mem (CPU python)=51729.61328125MB; mem (CPU total)=51604.87109375MB
INFO:root:[   76] Training loss: 0.62451237, Validation loss: 0.61504990, Gradient norm: 0.05552606
INFO:root:At the start of the epoch: mem (CPU python)=51770.80078125MB; mem (CPU total)=51646.49609375MB
INFO:root:[   77] Training loss: 0.62407842, Validation loss: 0.61504258, Gradient norm: 0.05312707
INFO:root:At the start of the epoch: mem (CPU python)=51771.39453125MB; mem (CPU total)=51646.9609375MB
INFO:root:[   78] Training loss: 0.62404829, Validation loss: 0.61456928, Gradient norm: 0.05222662
INFO:root:At the start of the epoch: mem (CPU python)=51846.98828125MB; mem (CPU total)=51722.34765625MB
INFO:root:[   79] Training loss: 0.62374015, Validation loss: 0.61443354, Gradient norm: 0.05766893
INFO:root:At the start of the epoch: mem (CPU python)=51891.33203125MB; mem (CPU total)=51766.4609375MB
INFO:root:[   80] Training loss: 0.62342748, Validation loss: 0.61451613, Gradient norm: 0.04903804
INFO:root:At the start of the epoch: mem (CPU python)=51929.43359375MB; mem (CPU total)=51804.06640625MB
INFO:root:[   81] Training loss: 0.62318086, Validation loss: 0.61402171, Gradient norm: 0.05448020
INFO:root:At the start of the epoch: mem (CPU python)=51967.53125MB; mem (CPU total)=51842.2421875MB
INFO:root:[   82] Training loss: 0.62300824, Validation loss: 0.61372837, Gradient norm: 0.06247857
INFO:root:At the start of the epoch: mem (CPU python)=52005.625MB; mem (CPU total)=51880.40625MB
INFO:root:[   83] Training loss: 0.62260738, Validation loss: 0.61295604, Gradient norm: 0.05416183
INFO:root:At the start of the epoch: mem (CPU python)=52043.72265625MB; mem (CPU total)=51918.55078125MB
INFO:root:[   84] Training loss: 0.62274281, Validation loss: 0.61395306, Gradient norm: 0.05305208
INFO:root:At the start of the epoch: mem (CPU python)=52069.31640625MB; mem (CPU total)=51945.203125MB
INFO:root:[   85] Training loss: 0.62241723, Validation loss: 0.61373276, Gradient norm: 0.05704346
INFO:root:At the start of the epoch: mem (CPU python)=52107.4140625MB; mem (CPU total)=51983.33984375MB
INFO:root:[   86] Training loss: 0.62209257, Validation loss: 0.61359328, Gradient norm: 0.05938767
INFO:root:At the start of the epoch: mem (CPU python)=52145.51171875MB; mem (CPU total)=52021.421875MB
INFO:root:[   87] Training loss: 0.62198538, Validation loss: 0.61292356, Gradient norm: 0.05571653
INFO:root:At the start of the epoch: mem (CPU python)=52202.35546875MB; mem (CPU total)=52078.15625MB
INFO:root:[   88] Training loss: 0.62165225, Validation loss: 0.61420200, Gradient norm: 0.05566866
INFO:root:At the start of the epoch: mem (CPU python)=52240.44921875MB; mem (CPU total)=52116.2890625MB
INFO:root:[   89] Training loss: 0.62145646, Validation loss: 0.61323748, Gradient norm: 0.05295959
INFO:root:At the start of the epoch: mem (CPU python)=52278.54296875MB; mem (CPU total)=52153.7109375MB
INFO:root:[   90] Training loss: 0.62129957, Validation loss: 0.61292674, Gradient norm: 0.05390446
INFO:root:At the start of the epoch: mem (CPU python)=52291.640625MB; mem (CPU total)=52169.76171875MB
INFO:root:[   91] Training loss: 0.62140368, Validation loss: 0.61247156, Gradient norm: 0.05642362
INFO:root:At the start of the epoch: mem (CPU python)=52329.734375MB; mem (CPU total)=52207.234375MB
INFO:root:[   92] Training loss: 0.62101624, Validation loss: 0.61193842, Gradient norm: 0.05902559
INFO:root:At the start of the epoch: mem (CPU python)=52386.578125MB; mem (CPU total)=52264.50390625MB
INFO:root:[   93] Training loss: 0.62072837, Validation loss: 0.61185257, Gradient norm: 0.05544628
INFO:root:At the start of the epoch: mem (CPU python)=52424.67578125MB; mem (CPU total)=52302.37109375MB
INFO:root:[   94] Training loss: 0.62072889, Validation loss: 0.61200043, Gradient norm: 0.06541393
INFO:root:At the start of the epoch: mem (CPU python)=52469.01953125MB; mem (CPU total)=52346.96875MB
INFO:root:[   95] Training loss: 0.62043758, Validation loss: 0.61127450, Gradient norm: 0.05224920
INFO:root:At the start of the epoch: mem (CPU python)=52507.1171875MB; mem (CPU total)=52384.9765625MB
INFO:root:[   96] Training loss: 0.62019844, Validation loss: 0.61175541, Gradient norm: 0.06259135
INFO:root:At the start of the epoch: mem (CPU python)=52520.21484375MB; mem (CPU total)=52397.23828125MB
INFO:root:[   97] Training loss: 0.62028700, Validation loss: 0.61070057, Gradient norm: 0.05910592
INFO:root:At the start of the epoch: mem (CPU python)=52577.0625MB; mem (CPU total)=52454.51953125MB
INFO:root:[   98] Training loss: 0.61969713, Validation loss: 0.61195253, Gradient norm: 0.05401646
INFO:root:At the start of the epoch: mem (CPU python)=52607.51953125MB; mem (CPU total)=52455.0546875MB
INFO:root:[   99] Training loss: 0.61949958, Validation loss: 0.61223918, Gradient norm: 0.06162381
INFO:root:At the start of the epoch: mem (CPU python)=52622.0MB; mem (CPU total)=52498.9765625MB
INFO:root:[  100] Training loss: 0.61962402, Validation loss: 0.61038004, Gradient norm: 0.05432535
INFO:root:At the start of the epoch: mem (CPU python)=52697.59765625MB; mem (CPU total)=52574.8515625MB
INFO:root:[  101] Training loss: 0.61931459, Validation loss: 0.61081495, Gradient norm: 0.05812053
INFO:root:At the start of the epoch: mem (CPU python)=52735.69140625MB; mem (CPU total)=52612.90625MB
INFO:root:[  102] Training loss: 0.61907323, Validation loss: 0.61102546, Gradient norm: 0.05387798
INFO:root:At the start of the epoch: mem (CPU python)=52751.91015625MB; mem (CPU total)=52631.16796875MB
INFO:root:[  103] Training loss: 0.61888848, Validation loss: 0.61091528, Gradient norm: 0.05286054
INFO:root:At the start of the epoch: mem (CPU python)=52808.76171875MB; mem (CPU total)=52687.9453125MB
INFO:root:[  104] Training loss: 0.61880206, Validation loss: 0.61041363, Gradient norm: 0.06185518
INFO:root:At the start of the epoch: mem (CPU python)=52846.85546875MB; mem (CPU total)=52726.2421875MB
INFO:root:[  105] Training loss: 0.61886103, Validation loss: 0.61055975, Gradient norm: 0.05959253
INFO:root:At the start of the epoch: mem (CPU python)=52856.82421875MB; mem (CPU total)=52734.25390625MB
INFO:root:[  106] Training loss: 0.61860401, Validation loss: 0.61030568, Gradient norm: 0.06398624
INFO:root:At the start of the epoch: mem (CPU python)=52894.91796875MB; mem (CPU total)=52772.3984375MB
INFO:root:[  107] Training loss: 0.61842852, Validation loss: 0.61106252, Gradient norm: 0.05774792
INFO:root:At the start of the epoch: mem (CPU python)=52939.265625MB; mem (CPU total)=52816.95703125MB
INFO:root:[  108] Training loss: 0.61814315, Validation loss: 0.61136955, Gradient norm: 0.05505314
INFO:root:At the start of the epoch: mem (CPU python)=52977.359375MB; mem (CPU total)=52855.12109375MB
INFO:root:[  109] Training loss: 0.61808322, Validation loss: 0.61087920, Gradient norm: 0.05731944
INFO:root:At the start of the epoch: mem (CPU python)=53015.453125MB; mem (CPU total)=52893.66796875MB
INFO:root:[  110] Training loss: 0.61792554, Validation loss: 0.60967411, Gradient norm: 0.05993842
INFO:root:At the start of the epoch: mem (CPU python)=53059.80078125MB; mem (CPU total)=52938.02734375MB
INFO:root:[  111] Training loss: 0.61799506, Validation loss: 0.61111097, Gradient norm: 0.05876547
INFO:root:At the start of the epoch: mem (CPU python)=53097.89453125MB; mem (CPU total)=52975.91015625MB
INFO:root:[  112] Training loss: 0.61771460, Validation loss: 0.61032476, Gradient norm: 0.05941786
INFO:root:At the start of the epoch: mem (CPU python)=53135.9921875MB; mem (CPU total)=53014.29296875MB
INFO:root:[  113] Training loss: 0.61731388, Validation loss: 0.60897496, Gradient norm: 0.05485631
INFO:root:At the start of the epoch: mem (CPU python)=53180.33984375MB; mem (CPU total)=53058.71484375MB
INFO:root:[  114] Training loss: 0.61742576, Validation loss: 0.60958655, Gradient norm: 0.05963250
INFO:root:At the start of the epoch: mem (CPU python)=53218.4375MB; mem (CPU total)=53097.84375MB
INFO:root:[  115] Training loss: 0.61725866, Validation loss: 0.60889881, Gradient norm: 0.06549902
INFO:root:At the start of the epoch: mem (CPU python)=53256.53125MB; mem (CPU total)=53136.234375MB
INFO:root:[  116] Training loss: 0.61696776, Validation loss: 0.60981415, Gradient norm: 0.05792690
INFO:root:At the start of the epoch: mem (CPU python)=53294.625MB; mem (CPU total)=53174.5859375MB
INFO:root:[  117] Training loss: 0.61709563, Validation loss: 0.61067168, Gradient norm: 0.05658185
INFO:root:At the start of the epoch: mem (CPU python)=53332.72265625MB; mem (CPU total)=53212.73046875MB
INFO:root:[  118] Training loss: 0.61687676, Validation loss: 0.60805326, Gradient norm: 0.06617661
INFO:root:At the start of the epoch: mem (CPU python)=53370.81640625MB; mem (CPU total)=53250.5546875MB
INFO:root:[  119] Training loss: 0.61662558, Validation loss: 0.60868456, Gradient norm: 0.06252222
INFO:root:At the start of the epoch: mem (CPU python)=53408.9140625MB; mem (CPU total)=53289.19921875MB
INFO:root:[  120] Training loss: 0.61669342, Validation loss: 0.60923226, Gradient norm: 0.06138225
INFO:root:At the start of the epoch: mem (CPU python)=53452.48046875MB; mem (CPU total)=53332.8125MB
INFO:root:[  121] Training loss: 0.61635156, Validation loss: 0.60867193, Gradient norm: 0.06087534
INFO:root:At the start of the epoch: mem (CPU python)=53490.578125MB; mem (CPU total)=53370.640625MB
INFO:root:[  122] Training loss: 0.61624838, Validation loss: 0.60795863, Gradient norm: 0.06028035
INFO:root:At the start of the epoch: mem (CPU python)=53528.671875MB; mem (CPU total)=53408.7109375MB
INFO:root:[  123] Training loss: 0.61611521, Validation loss: 0.60847471, Gradient norm: 0.05629623
INFO:root:At the start of the epoch: mem (CPU python)=53567.54296875MB; mem (CPU total)=53447.625MB
INFO:root:[  124] Training loss: 0.61617919, Validation loss: 0.60868638, Gradient norm: 0.06052707
INFO:root:At the start of the epoch: mem (CPU python)=53586.890625MB; mem (CPU total)=53466.6171875MB
INFO:root:[  125] Training loss: 0.61582233, Validation loss: 0.60972659, Gradient norm: 0.05967315
INFO:root:At the start of the epoch: mem (CPU python)=53643.734375MB; mem (CPU total)=53523.375MB
INFO:root:[  126] Training loss: 0.61580389, Validation loss: 0.60901635, Gradient norm: 0.05538296
INFO:root:At the start of the epoch: mem (CPU python)=53681.828125MB; mem (CPU total)=53561.9765625MB
INFO:root:[  127] Training loss: 0.61565621, Validation loss: 0.60813736, Gradient norm: 0.05670163
INFO:root:At the start of the epoch: mem (CPU python)=53694.92578125MB; mem (CPU total)=53574.9921875MB
INFO:root:[  128] Training loss: 0.61553536, Validation loss: 0.60815953, Gradient norm: 0.05729084
INFO:root:At the start of the epoch: mem (CPU python)=53739.2734375MB; mem (CPU total)=53619.328125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  129] Training loss: 0.61539524, Validation loss: 0.60834549, Gradient norm: 0.06305839
INFO:root:At the start of the epoch: mem (CPU python)=53796.1171875MB; mem (CPU total)=53676.33984375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  130] Training loss: 0.61465231, Validation loss: 0.60768551, Gradient norm: 0.05465383
INFO:root:At the start of the epoch: mem (CPU python)=53834.2109375MB; mem (CPU total)=53713.8671875MB
INFO:root:[  131] Training loss: 0.61408822, Validation loss: 0.60591303, Gradient norm: 0.05301248
INFO:root:At the start of the epoch: mem (CPU python)=53864.5859375MB; mem (CPU total)=53727.3984375MB
INFO:root:[  132] Training loss: 0.61365079, Validation loss: 0.60684895, Gradient norm: 0.04901781
INFO:root:At the start of the epoch: mem (CPU python)=53885.40234375MB; mem (CPU total)=53765.8203125MB
INFO:root:[  133] Training loss: 0.61363040, Validation loss: 0.60735326, Gradient norm: 0.04879836
INFO:root:At the start of the epoch: mem (CPU python)=53929.74609375MB; mem (CPU total)=53810.15625MB
INFO:root:[  134] Training loss: 0.61362214, Validation loss: 0.60641131, Gradient norm: 0.05022893
INFO:root:At the start of the epoch: mem (CPU python)=53986.59375MB; mem (CPU total)=53867.12890625MB
INFO:root:[  135] Training loss: 0.61345470, Validation loss: 0.60731473, Gradient norm: 0.04777749
INFO:root:At the start of the epoch: mem (CPU python)=54005.9375MB; mem (CPU total)=53885.89453125MB
INFO:root:[  136] Training loss: 0.61339012, Validation loss: 0.60685033, Gradient norm: 0.04957745
INFO:root:At the start of the epoch: mem (CPU python)=54044.03515625MB; mem (CPU total)=53924.03125MB
INFO:root:[  137] Training loss: 0.61338986, Validation loss: 0.60701983, Gradient norm: 0.04875499
INFO:root:At the start of the epoch: mem (CPU python)=54082.1328125MB; mem (CPU total)=53962.421875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  138] Training loss: 0.61343174, Validation loss: 0.60676389, Gradient norm: 0.05152683
INFO:root:At the start of the epoch: mem (CPU python)=54120.2265625MB; mem (CPU total)=54000.83984375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  139] Training loss: 0.61325668, Validation loss: 0.60668667, Gradient norm: 0.04791291
INFO:root:At the start of the epoch: mem (CPU python)=54170.8203125MB; mem (CPU total)=54051.3984375MB
INFO:root:[  140] Training loss: 0.61298217, Validation loss: 0.60645159, Gradient norm: 0.04784285
INFO:root:At the start of the epoch: mem (CPU python)=54208.9140625MB; mem (CPU total)=54089.78125MB
INFO:root:EP 140: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=54239.390625MB; mem (CPU total)=54114.7421875MB
INFO:root:Training the model took 12605.918s.
INFO:root:Emptying the cuda cache took 0.004s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84445
INFO:root:EnergyScoreTrain: 0.59455
INFO:root:CRPSTrain: 0.46124
INFO:root:Gaussian NLLTrain: 1.18933
INFO:root:CoverageTrain: 0.95229
INFO:root:IntervalWidthTrain: 3.28401
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86194
INFO:root:EnergyScoreValidation: 0.60673
INFO:root:CRPSValidation: 0.47172
INFO:root:Gaussian NLLValidation: 1.21337
INFO:root:CoverageValidation: 0.94678
INFO:root:IntervalWidthValidation: 3.28729
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86358
INFO:root:EnergyScoreTest: 0.60785
INFO:root:CRPSTest: 0.47272
INFO:root:Gaussian NLLTest: 1.21572
INFO:root:CoverageTest: 0.94639
INFO:root:IntervalWidthTest: 3.29061
INFO:root:After validation: mem (CPU python)=54295.36328125MB; mem (CPU total)=54145.515625MB
