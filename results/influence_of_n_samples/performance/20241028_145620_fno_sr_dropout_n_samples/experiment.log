INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.1953125MB; mem (CPU total)=1065.29296875MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12454.546875MB; mem (CPU total)=1071.69140625MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.546875MB; mem (CPU total)=1070.83203125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12454.546875MB; mem (CPU total)=2432.16015625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=2444.328125MB
INFO:root:[    1] Training loss: 0.78112180, Validation loss: 0.72783879, Gradient norm: 0.49991432
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4166.85546875MB
INFO:root:[    2] Training loss: 0.72513041, Validation loss: 0.72371069, Gradient norm: 0.44990651
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4205.0234375MB
INFO:root:[    3] Training loss: 0.72219551, Validation loss: 0.72252023, Gradient norm: 0.38527882
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4242.67578125MB
INFO:root:[    4] Training loss: 0.72110236, Validation loss: 0.72147138, Gradient norm: 0.34261830
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4280.58984375MB
INFO:root:[    5] Training loss: 0.72056623, Validation loss: 0.72028650, Gradient norm: 0.32455403
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4318.34765625MB
INFO:root:[    6] Training loss: 0.72012133, Validation loss: 0.72018253, Gradient norm: 0.22073126
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4356.85546875MB
INFO:root:[    7] Training loss: 0.71995487, Validation loss: 0.72064619, Gradient norm: 0.29024271
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4394.859375MB
INFO:root:[    8] Training loss: 0.71977133, Validation loss: 0.72010366, Gradient norm: 0.28504107
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4432.8046875MB
INFO:root:[    9] Training loss: 0.71943709, Validation loss: 0.72017480, Gradient norm: 0.27724985
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4471.4375MB
INFO:root:[   10] Training loss: 0.71899485, Validation loss: 0.71880611, Gradient norm: 0.23827926
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4509.671875MB
INFO:root:[   11] Training loss: 0.71899270, Validation loss: 0.71906762, Gradient norm: 0.35829578
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4547.5859375MB
INFO:root:[   12] Training loss: 0.71805803, Validation loss: 0.71762308, Gradient norm: 0.20773749
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4586.0546875MB
INFO:root:[   13] Training loss: 0.71597495, Validation loss: 0.71352330, Gradient norm: 0.16242872
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4624.41015625MB
INFO:root:[   14] Training loss: 0.70926086, Validation loss: 0.70539947, Gradient norm: 0.16300315
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4662.2734375MB
INFO:root:[   15] Training loss: 0.70128411, Validation loss: 0.69769357, Gradient norm: 0.14113858
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4700.7578125MB
INFO:root:[   16] Training loss: 0.69330301, Validation loss: 0.69037737, Gradient norm: 0.12092085
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4738.44921875MB
INFO:root:[   17] Training loss: 0.68697450, Validation loss: 0.68462383, Gradient norm: 0.12370013
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4776.80859375MB
INFO:root:[   18] Training loss: 0.68197007, Validation loss: 0.68010828, Gradient norm: 0.11691740
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4815.12109375MB
INFO:root:[   19] Training loss: 0.67773671, Validation loss: 0.67675199, Gradient norm: 0.12873783
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4853.26953125MB
INFO:root:[   20] Training loss: 0.67398512, Validation loss: 0.67434313, Gradient norm: 0.11269846
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4891.72265625MB
INFO:root:[   21] Training loss: 0.67087999, Validation loss: 0.67099886, Gradient norm: 0.10963152
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4929.62890625MB
INFO:root:[   22] Training loss: 0.66827876, Validation loss: 0.66873228, Gradient norm: 0.10626162
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=4968.08984375MB
INFO:root:[   23] Training loss: 0.66605721, Validation loss: 0.66653805, Gradient norm: 0.12262932
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5005.80859375MB
INFO:root:[   24] Training loss: 0.66405322, Validation loss: 0.66489656, Gradient norm: 0.10849855
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5043.99609375MB
INFO:root:[   25] Training loss: 0.66206235, Validation loss: 0.66228946, Gradient norm: 0.12219827
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5082.08203125MB
INFO:root:[   26] Training loss: 0.66058509, Validation loss: 0.66249482, Gradient norm: 0.15324716
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5120.02734375MB
INFO:root:[   27] Training loss: 0.65894841, Validation loss: 0.65985455, Gradient norm: 0.10555932
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5158.33984375MB
INFO:root:[   28] Training loss: 0.65758932, Validation loss: 0.65828074, Gradient norm: 0.13931279
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5195.87109375MB
INFO:root:[   29] Training loss: 0.65623950, Validation loss: 0.65819335, Gradient norm: 0.10920418
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5233.9609375MB
INFO:root:[   30] Training loss: 0.65503496, Validation loss: 0.65683456, Gradient norm: 0.11549356
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5272.35546875MB
INFO:root:[   31] Training loss: 0.65374468, Validation loss: 0.65528091, Gradient norm: 0.12778212
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5310.6015625MB
INFO:root:[   32] Training loss: 0.65272767, Validation loss: 0.65471504, Gradient norm: 0.12418642
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5348.7578125MB
INFO:root:[   33] Training loss: 0.65162547, Validation loss: 0.65345347, Gradient norm: 0.13738022
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5386.90234375MB
INFO:root:[   34] Training loss: 0.65042021, Validation loss: 0.65216864, Gradient norm: 0.14037351
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5425.046875MB
INFO:root:[   35] Training loss: 0.64944115, Validation loss: 0.65193315, Gradient norm: 0.10833343
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5463.23046875MB
INFO:root:[   36] Training loss: 0.64850981, Validation loss: 0.65098601, Gradient norm: 0.10186666
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5501.171875MB
INFO:root:[   37] Training loss: 0.64731403, Validation loss: 0.64996232, Gradient norm: 0.11047298
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5539.390625MB
INFO:root:[   38] Training loss: 0.64629910, Validation loss: 0.64890405, Gradient norm: 0.13001252
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5577.8203125MB
INFO:root:[   39] Training loss: 0.64532611, Validation loss: 0.64809704, Gradient norm: 0.12631102
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5615.6953125MB
INFO:root:[   40] Training loss: 0.64465252, Validation loss: 0.64791765, Gradient norm: 0.13752030
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5653.90234375MB
INFO:root:[   41] Training loss: 0.64360401, Validation loss: 0.64661749, Gradient norm: 0.15078850
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5692.05078125MB
INFO:root:[   42] Training loss: 0.64285546, Validation loss: 0.64564030, Gradient norm: 0.12113733
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5731.12109375MB
INFO:root:[   43] Training loss: 0.64196719, Validation loss: 0.64541671, Gradient norm: 0.11335453
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5769.3046875MB
INFO:root:[   44] Training loss: 0.64101348, Validation loss: 0.64383824, Gradient norm: 0.14009767
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5807.0859375MB
INFO:root:[   45] Training loss: 0.64005358, Validation loss: 0.64356366, Gradient norm: 0.11118496
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5845.4609375MB
INFO:root:[   46] Training loss: 0.63972089, Validation loss: 0.64262538, Gradient norm: 0.12321796
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5883.58984375MB
INFO:root:[   47] Training loss: 0.63885322, Validation loss: 0.64137388, Gradient norm: 0.12031301
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5922.203125MB
INFO:root:[   48] Training loss: 0.63828960, Validation loss: 0.64112227, Gradient norm: 0.13968113
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5959.9140625MB
INFO:root:[   49] Training loss: 0.63739887, Validation loss: 0.64127510, Gradient norm: 0.14644016
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=5997.2734375MB
INFO:root:[   50] Training loss: 0.63691377, Validation loss: 0.64072398, Gradient norm: 0.16816475
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6035.6484375MB
INFO:root:[   51] Training loss: 0.63623121, Validation loss: 0.64017735, Gradient norm: 0.13431016
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6074.0234375MB
INFO:root:[   52] Training loss: 0.63613064, Validation loss: 0.63933665, Gradient norm: 0.13849262
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6112.3984375MB
INFO:root:[   53] Training loss: 0.63510012, Validation loss: 0.63888377, Gradient norm: 0.13476002
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6150.83203125MB
INFO:root:[   54] Training loss: 0.63431831, Validation loss: 0.63825629, Gradient norm: 0.10629489
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6188.95703125MB
INFO:root:[   55] Training loss: 0.63389819, Validation loss: 0.63752110, Gradient norm: 0.14785865
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6226.84765625MB
INFO:root:[   56] Training loss: 0.63303713, Validation loss: 0.63745574, Gradient norm: 0.13624485
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6265.21484375MB
INFO:root:[   57] Training loss: 0.63250332, Validation loss: 0.63651012, Gradient norm: 0.11922785
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6303.25MB
INFO:root:[   58] Training loss: 0.63244216, Validation loss: 0.63604697, Gradient norm: 0.13560590
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6341.86328125MB
INFO:root:[   59] Training loss: 0.63172582, Validation loss: 0.63687597, Gradient norm: 0.13238125
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6379.9921875MB
INFO:root:[   60] Training loss: 0.63112617, Validation loss: 0.63568468, Gradient norm: 0.15413006
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6417.3828125MB
INFO:root:[   61] Training loss: 0.63044402, Validation loss: 0.63555521, Gradient norm: 0.15199709
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6456.0MB
INFO:root:[   62] Training loss: 0.63008608, Validation loss: 0.63448554, Gradient norm: 0.13439608
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6493.8828125MB
INFO:root:[   63] Training loss: 0.62969090, Validation loss: 0.63466967, Gradient norm: 0.12822891
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6532.2578125MB
INFO:root:[   64] Training loss: 0.62894803, Validation loss: 0.63396108, Gradient norm: 0.12367851
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6570.625MB
INFO:root:[   65] Training loss: 0.62867722, Validation loss: 0.63378928, Gradient norm: 0.15026655
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6608.0078125MB
INFO:root:[   66] Training loss: 0.62816673, Validation loss: 0.63262434, Gradient norm: 0.14497879
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6646.37890625MB
INFO:root:[   67] Training loss: 0.62765758, Validation loss: 0.63276209, Gradient norm: 0.14563447
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6684.75390625MB
INFO:root:[   68] Training loss: 0.62754402, Validation loss: 0.63261006, Gradient norm: 0.12719779
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6722.62890625MB
INFO:root:[   69] Training loss: 0.62667632, Validation loss: 0.63177186, Gradient norm: 0.13945055
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6761.43359375MB
INFO:root:[   70] Training loss: 0.62653694, Validation loss: 0.63253782, Gradient norm: 0.15466885
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6798.30078125MB
INFO:root:[   71] Training loss: 0.62603087, Validation loss: 0.63129882, Gradient norm: 0.15312821
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6838.08984375MB
INFO:root:[   72] Training loss: 0.62572894, Validation loss: 0.63150760, Gradient norm: 0.14923651
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6876.94140625MB
INFO:root:[   73] Training loss: 0.62526296, Validation loss: 0.63074104, Gradient norm: 0.14642612
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6915.0625MB
INFO:root:[   74] Training loss: 0.62486437, Validation loss: 0.63094323, Gradient norm: 0.14061984
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6953.1796875MB
INFO:root:[   75] Training loss: 0.62449984, Validation loss: 0.63111457, Gradient norm: 0.13325307
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=6991.265625MB
INFO:root:[   76] Training loss: 0.62400690, Validation loss: 0.62973359, Gradient norm: 0.13415524
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7029.33984375MB
INFO:root:[   77] Training loss: 0.62392244, Validation loss: 0.63005245, Gradient norm: 0.13542330
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7067.42578125MB
INFO:root:[   78] Training loss: 0.62321889, Validation loss: 0.62905046, Gradient norm: 0.15826583
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7105.78515625MB
INFO:root:[   79] Training loss: 0.62294429, Validation loss: 0.62926334, Gradient norm: 0.17270809
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7143.65234375MB
INFO:root:[   80] Training loss: 0.62251524, Validation loss: 0.62938957, Gradient norm: 0.12669626
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7182.00390625MB
INFO:root:[   81] Training loss: 0.62218573, Validation loss: 0.62787722, Gradient norm: 0.13918333
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7220.328125MB
INFO:root:[   82] Training loss: 0.62200204, Validation loss: 0.62906790, Gradient norm: 0.15007700
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7258.44140625MB
INFO:root:[   83] Training loss: 0.62162416, Validation loss: 0.62835702, Gradient norm: 0.14023124
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7296.80078125MB
INFO:root:[   84] Training loss: 0.62158303, Validation loss: 0.62897773, Gradient norm: 0.16355104
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7334.9140625MB
INFO:root:[   85] Training loss: 0.62109891, Validation loss: 0.62722087, Gradient norm: 0.14875856
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7372.8046875MB
INFO:root:[   86] Training loss: 0.62024201, Validation loss: 0.62743901, Gradient norm: 0.17082988
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7411.17578125MB
INFO:root:[   87] Training loss: 0.62017811, Validation loss: 0.62717342, Gradient norm: 0.16183048
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7449.52734375MB
INFO:root:[   88] Training loss: 0.62010424, Validation loss: 0.62699249, Gradient norm: 0.15366448
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7487.6328125MB
INFO:root:[   89] Training loss: 0.61969379, Validation loss: 0.62638362, Gradient norm: 0.14265537
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7525.25390625MB
INFO:root:[   90] Training loss: 0.61924196, Validation loss: 0.62622929, Gradient norm: 0.13620874
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7563.1171875MB
INFO:root:[   91] Training loss: 0.61936157, Validation loss: 0.62686524, Gradient norm: 0.16429812
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7601.00390625MB
INFO:root:[   92] Training loss: 0.61893697, Validation loss: 0.62624303, Gradient norm: 0.16342198
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7639.140625MB
INFO:root:[   93] Training loss: 0.61868416, Validation loss: 0.62606561, Gradient norm: 0.17414448
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7677.0078125MB
INFO:root:[   94] Training loss: 0.61814019, Validation loss: 0.62558729, Gradient norm: 0.15612731
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7715.609375MB
INFO:root:[   95] Training loss: 0.61804929, Validation loss: 0.62571487, Gradient norm: 0.17908502
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7753.47265625MB
INFO:root:[   96] Training loss: 0.61770378, Validation loss: 0.62552184, Gradient norm: 0.15586255
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7791.09375MB
INFO:root:[   97] Training loss: 0.61762230, Validation loss: 0.62623425, Gradient norm: 0.16990833
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7829.20703125MB
INFO:root:[   98] Training loss: 0.61709579, Validation loss: 0.62479401, Gradient norm: 0.17236435
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7867.25MB
INFO:root:[   99] Training loss: 0.61705691, Validation loss: 0.62502375, Gradient norm: 0.18581984
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7905.10546875MB
INFO:root:[  100] Training loss: 0.61682166, Validation loss: 0.62544151, Gradient norm: 0.18116113
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7943.00390625MB
INFO:root:[  101] Training loss: 0.61647043, Validation loss: 0.62534371, Gradient norm: 0.18427854
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=7981.60546875MB
INFO:root:[  102] Training loss: 0.61636006, Validation loss: 0.62527667, Gradient norm: 0.19501901
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8019.71875MB
INFO:root:[  103] Training loss: 0.61620024, Validation loss: 0.62419873, Gradient norm: 0.19397261
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8057.5859375MB
INFO:root:[  104] Training loss: 0.61569486, Validation loss: 0.62398257, Gradient norm: 0.19367841
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8095.71875MB
INFO:root:[  105] Training loss: 0.61549884, Validation loss: 0.62494376, Gradient norm: 0.17574937
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8133.84765625MB
INFO:root:[  106] Training loss: 0.61547147, Validation loss: 0.62414353, Gradient norm: 0.15977075
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8171.9609375MB
INFO:root:[  107] Training loss: 0.61488233, Validation loss: 0.62382386, Gradient norm: 0.20908110
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8210.3203125MB
INFO:root:[  108] Training loss: 0.61477835, Validation loss: 0.62473729, Gradient norm: 0.21881449
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8248.21484375MB
INFO:root:[  109] Training loss: 0.61463752, Validation loss: 0.62424822, Gradient norm: 0.16093189
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8286.8125MB
INFO:root:[  110] Training loss: 0.61419572, Validation loss: 0.62404243, Gradient norm: 0.21854176
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8325.171875MB
INFO:root:[  111] Training loss: 0.61408227, Validation loss: 0.62419011, Gradient norm: 0.17614042
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8363.0078125MB
INFO:root:[  112] Training loss: 0.61366188, Validation loss: 0.62349001, Gradient norm: 0.22348961
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8401.15234375MB
INFO:root:[  113] Training loss: 0.61376552, Validation loss: 0.62372621, Gradient norm: 0.19691333
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8439.015625MB
INFO:root:[  114] Training loss: 0.61316696, Validation loss: 0.62321564, Gradient norm: 0.22773435
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8477.1484375MB
INFO:root:[  115] Training loss: 0.61283786, Validation loss: 0.62319521, Gradient norm: 0.20143971
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8514.5546875MB
INFO:root:[  116] Training loss: 0.61319858, Validation loss: 0.62254252, Gradient norm: 0.20226803
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8552.9140625MB
INFO:root:[  117] Training loss: 0.61271536, Validation loss: 0.62285837, Gradient norm: 0.18163347
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8590.53515625MB
INFO:root:[  118] Training loss: 0.61214934, Validation loss: 0.62253205, Gradient norm: 0.19773849
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8629.29296875MB
INFO:root:[  119] Training loss: 0.61220507, Validation loss: 0.62236939, Gradient norm: 0.21065723
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8667.40625MB
INFO:root:[  120] Training loss: 0.61255173, Validation loss: 0.62212892, Gradient norm: 0.22914189
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8705.7578125MB
INFO:root:[  121] Training loss: 0.61164479, Validation loss: 0.62309899, Gradient norm: 0.19027061
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8743.87109375MB
INFO:root:[  122] Training loss: 0.61164990, Validation loss: 0.62282900, Gradient norm: 0.19378540
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8781.7265625MB
INFO:root:[  123] Training loss: 0.61177395, Validation loss: 0.62157966, Gradient norm: 0.22714805
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8820.07421875MB
INFO:root:[  124] Training loss: 0.61135259, Validation loss: 0.62245711, Gradient norm: 0.24663537
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8858.6796875MB
INFO:root:[  125] Training loss: 0.61116085, Validation loss: 0.62220022, Gradient norm: 0.22771808
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8896.546875MB
INFO:root:[  126] Training loss: 0.61111141, Validation loss: 0.62211058, Gradient norm: 0.27464074
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8934.875MB
INFO:root:[  127] Training loss: 0.61102210, Validation loss: 0.62145447, Gradient norm: 0.23089832
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=8972.73828125MB
INFO:root:[  128] Training loss: 0.61048419, Validation loss: 0.62241016, Gradient norm: 0.22698497
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9012.1328125MB
INFO:root:[  129] Training loss: 0.61042840, Validation loss: 0.62186640, Gradient norm: 0.22007332
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9050.7109375MB
INFO:root:[  130] Training loss: 0.61000902, Validation loss: 0.62241879, Gradient norm: 0.22578231
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9088.71484375MB
INFO:root:[  131] Training loss: 0.60999404, Validation loss: 0.62176363, Gradient norm: 0.21712310
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9126.8125MB
INFO:root:[  132] Training loss: 0.60992124, Validation loss: 0.62244157, Gradient norm: 0.27952462
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9164.93359375MB
INFO:root:[  133] Training loss: 0.60982883, Validation loss: 0.62082727, Gradient norm: 0.26329437
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9203.078125MB
INFO:root:[  134] Training loss: 0.60945534, Validation loss: 0.62106515, Gradient norm: 0.27390170
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9241.3203125MB
INFO:root:[  135] Training loss: 0.60930984, Validation loss: 0.62249488, Gradient norm: 0.27598737
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9279.5703125MB
INFO:root:[  136] Training loss: 0.60904470, Validation loss: 0.62028442, Gradient norm: 0.25987724
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9317.71484375MB
INFO:root:[  137] Training loss: 0.60902893, Validation loss: 0.62069739, Gradient norm: 0.26485687
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9355.94921875MB
INFO:root:[  138] Training loss: 0.60873970, Validation loss: 0.62096260, Gradient norm: 0.25704928
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9393.83203125MB
INFO:root:[  139] Training loss: 0.60835367, Validation loss: 0.62072087, Gradient norm: 0.31781303
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9432.0234375MB
INFO:root:[  140] Training loss: 0.60828284, Validation loss: 0.62110892, Gradient norm: 0.25151986
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9469.828125MB
INFO:root:[  141] Training loss: 0.60837656, Validation loss: 0.62046086, Gradient norm: 0.26840117
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9507.91796875MB
INFO:root:[  142] Training loss: 0.60826873, Validation loss: 0.62022436, Gradient norm: 0.31332287
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9546.8125MB
INFO:root:[  143] Training loss: 0.60802644, Validation loss: 0.62078596, Gradient norm: 0.28196368
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9585.171875MB
INFO:root:[  144] Training loss: 0.60804779, Validation loss: 0.62072335, Gradient norm: 0.31382858
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9623.265625MB
INFO:root:[  145] Training loss: 0.60705336, Validation loss: 0.62090837, Gradient norm: 0.28439451
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9661.1328125MB
INFO:root:[  146] Training loss: 0.60728164, Validation loss: 0.62048998, Gradient norm: 0.28406572
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9699.2578125MB
INFO:root:[  147] Training loss: 0.60724758, Validation loss: 0.62044496, Gradient norm: 0.33996740
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9737.6328125MB
INFO:root:[  148] Training loss: 0.60701397, Validation loss: 0.62067417, Gradient norm: 0.27817444
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9775.78125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  149] Training loss: 0.60705003, Validation loss: 0.62001988, Gradient norm: 0.33868599
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9814.15625MB
INFO:root:[  150] Training loss: 0.60557174, Validation loss: 0.61963833, Gradient norm: 0.20809297
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9852.5234375MB
INFO:root:[  151] Training loss: 0.60554004, Validation loss: 0.61950977, Gradient norm: 0.20417656
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9890.64453125MB
INFO:root:[  152] Training loss: 0.60547119, Validation loss: 0.61920655, Gradient norm: 0.20207733
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9928.77734375MB
INFO:root:[  153] Training loss: 0.60548129, Validation loss: 0.61907667, Gradient norm: 0.21537566
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=9967.1640625MB
INFO:root:[  154] Training loss: 0.60531211, Validation loss: 0.62029058, Gradient norm: 0.20419583
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10005.53125MB
INFO:root:[  155] Training loss: 0.60499084, Validation loss: 0.61990724, Gradient norm: 0.25235804
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10043.48828125MB
INFO:root:[  156] Training loss: 0.60511133, Validation loss: 0.61928333, Gradient norm: 0.28649862
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10081.76953125MB
INFO:root:[  157] Training loss: 0.60483508, Validation loss: 0.61948454, Gradient norm: 0.24709424
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10119.79296875MB
INFO:root:[  158] Training loss: 0.60464643, Validation loss: 0.61998956, Gradient norm: 0.22652823
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10157.87109375MB
INFO:root:[  159] Training loss: 0.60506676, Validation loss: 0.61925121, Gradient norm: 0.25186543
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10196.01171875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  160] Training loss: 0.60465977, Validation loss: 0.61960107, Gradient norm: 0.28236120
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10233.8828125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  161] Training loss: 0.60427396, Validation loss: 0.61904279, Gradient norm: 0.18202354
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10271.6953125MB
INFO:root:[  162] Training loss: 0.60384096, Validation loss: 0.61867271, Gradient norm: 0.15665110
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10310.640625MB
INFO:root:[  163] Training loss: 0.60370269, Validation loss: 0.61934648, Gradient norm: 0.15797426
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10348.46875MB
INFO:root:[  164] Training loss: 0.60345489, Validation loss: 0.61787000, Gradient norm: 0.16046423
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10386.53125MB
INFO:root:[  165] Training loss: 0.60379470, Validation loss: 0.61858810, Gradient norm: 0.15975600
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10424.65234375MB
INFO:root:[  166] Training loss: 0.60361491, Validation loss: 0.61946006, Gradient norm: 0.16384674
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10462.52734375MB
INFO:root:[  167] Training loss: 0.60369510, Validation loss: 0.61864472, Gradient norm: 0.16198773
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10500.65625MB
INFO:root:[  168] Training loss: 0.60383369, Validation loss: 0.61879263, Gradient norm: 0.16442030
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10538.77734375MB
INFO:root:[  169] Training loss: 0.60345229, Validation loss: 0.61891610, Gradient norm: 0.15746752
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10576.9375MB
INFO:root:[  170] Training loss: 0.60347118, Validation loss: 0.61882064, Gradient norm: 0.17310750
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10615.89453125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  171] Training loss: 0.60340333, Validation loss: 0.61923459, Gradient norm: 0.16107342
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10654.09765625MB
INFO:root:[  172] Training loss: 0.60330456, Validation loss: 0.61861921, Gradient norm: 0.15150458
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10692.26953125MB
INFO:root:[  173] Training loss: 0.60304940, Validation loss: 0.61810960, Gradient norm: 0.15750547
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10730.07421875MB
INFO:root:EP 173: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12454.546875MB; mem (CPU total)=10768.2734375MB
INFO:root:Training the model took 7250.796s.
INFO:root:Emptying the cuda cache took 0.078s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85666
INFO:root:EnergyScoreTrain: 0.60345
INFO:root:CRPSTrain: 0.52867
INFO:root:Gaussian NLLTrain: 2.54365
INFO:root:CoverageTrain: 0.80132
INFO:root:IntervalWidthTrain: 3.18677
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87912
INFO:root:EnergyScoreValidation: 0.61908
INFO:root:CRPSValidation: 0.54139
INFO:root:Gaussian NLLValidation: 2.59483
INFO:root:CoverageValidation: 0.79371
INFO:root:IntervalWidthValidation: 3.17826
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88014
INFO:root:EnergyScoreTest: 0.61987
INFO:root:CRPSTest: 0.54207
INFO:root:Gaussian NLLTest: 2.58931
INFO:root:CoverageTest: 0.79324
INFO:root:IntervalWidthTest: 3.17632
INFO:root:After validation: mem (CPU python)=12454.546875MB; mem (CPU total)=10814.875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.546875MB; mem (CPU total)=10814.87109375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=12454.546875MB; mem (CPU total)=10815.36328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10815.87890625MB
INFO:root:[    1] Training loss: 0.78823424, Validation loss: 0.72902116, Gradient norm: 0.68998694
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10854.88671875MB
INFO:root:[    2] Training loss: 0.72311354, Validation loss: 0.72182279, Gradient norm: 0.48854827
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10893.23046875MB
INFO:root:[    3] Training loss: 0.72131647, Validation loss: 0.72460182, Gradient norm: 0.52729067
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10931.06640625MB
INFO:root:[    4] Training loss: 0.72043693, Validation loss: 0.72056972, Gradient norm: 0.37206862
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=10969.16796875MB
INFO:root:[    5] Training loss: 0.72003071, Validation loss: 0.72034983, Gradient norm: 0.25007025
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11007.5546875MB
INFO:root:[    6] Training loss: 0.71990155, Validation loss: 0.72097542, Gradient norm: 0.35944622
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11045.40625MB
INFO:root:[    7] Training loss: 0.71936761, Validation loss: 0.71959045, Gradient norm: 0.22309042
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11083.7265625MB
INFO:root:[    8] Training loss: 0.71888131, Validation loss: 0.71973650, Gradient norm: 0.19556183
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11121.8359375MB
INFO:root:[    9] Training loss: 0.71864768, Validation loss: 0.71933350, Gradient norm: 0.24384693
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11159.6953125MB
INFO:root:[   10] Training loss: 0.71809633, Validation loss: 0.71817300, Gradient norm: 0.25379713
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11197.83203125MB
INFO:root:[   11] Training loss: 0.71688944, Validation loss: 0.71581656, Gradient norm: 0.18246914
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11236.1796875MB
INFO:root:[   12] Training loss: 0.71297748, Validation loss: 0.70976724, Gradient norm: 0.15845338
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11274.1640625MB
INFO:root:[   13] Training loss: 0.70688007, Validation loss: 0.70448118, Gradient norm: 0.19265000
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11312.79296875MB
INFO:root:[   14] Training loss: 0.70141860, Validation loss: 0.70010087, Gradient norm: 0.14358913
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11350.4140625MB
INFO:root:[   15] Training loss: 0.69720109, Validation loss: 0.69604617, Gradient norm: 0.13966178
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11388.265625MB
INFO:root:[   16] Training loss: 0.69317119, Validation loss: 0.69216881, Gradient norm: 0.13419924
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11426.375MB
INFO:root:[   17] Training loss: 0.68933368, Validation loss: 0.68873960, Gradient norm: 0.11611725
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11464.2578125MB
INFO:root:[   18] Training loss: 0.68671585, Validation loss: 0.68624720, Gradient norm: 0.15826609
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11501.91015625MB
INFO:root:[   19] Training loss: 0.68337780, Validation loss: 0.68366720, Gradient norm: 0.12260558
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11541.12890625MB
INFO:root:[   20] Training loss: 0.68078387, Validation loss: 0.68138047, Gradient norm: 0.16244134
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11578.8359375MB
INFO:root:[   21] Training loss: 0.67835362, Validation loss: 0.67853305, Gradient norm: 0.10816196
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11616.515625MB
INFO:root:[   22] Training loss: 0.67618305, Validation loss: 0.67693513, Gradient norm: 0.11752182
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11655.0703125MB
INFO:root:[   23] Training loss: 0.67373379, Validation loss: 0.67462925, Gradient norm: 0.13837740
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11693.18359375MB
INFO:root:[   24] Training loss: 0.67205668, Validation loss: 0.67229952, Gradient norm: 0.12954969
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11730.34375MB
INFO:root:[   25] Training loss: 0.67002815, Validation loss: 0.67056781, Gradient norm: 0.12750399
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11768.76953125MB
INFO:root:[   26] Training loss: 0.66818235, Validation loss: 0.66827490, Gradient norm: 0.14291269
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11806.890625MB
INFO:root:[   27] Training loss: 0.66650050, Validation loss: 0.66733425, Gradient norm: 0.14420614
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11844.87109375MB
INFO:root:[   28] Training loss: 0.66485796, Validation loss: 0.66512855, Gradient norm: 0.12567196
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11882.98046875MB
INFO:root:[   29] Training loss: 0.66350231, Validation loss: 0.66353907, Gradient norm: 0.13631777
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11920.83984375MB
INFO:root:[   30] Training loss: 0.66160050, Validation loss: 0.66372110, Gradient norm: 0.13085012
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11958.70703125MB
INFO:root:[   31] Training loss: 0.66023921, Validation loss: 0.66168767, Gradient norm: 0.13415004
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=11996.5546875MB
INFO:root:[   32] Training loss: 0.65894257, Validation loss: 0.65982499, Gradient norm: 0.15014840
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=12035.9375MB
INFO:root:[   33] Training loss: 0.65778859, Validation loss: 0.65877189, Gradient norm: 0.13712628
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=12074.2890625MB
INFO:root:[   34] Training loss: 0.65646919, Validation loss: 0.65854037, Gradient norm: 0.12567632
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=12112.88671875MB
INFO:root:[   35] Training loss: 0.65516434, Validation loss: 0.65661771, Gradient norm: 0.13354617
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=12150.9921875MB
INFO:root:[   36] Training loss: 0.65439500, Validation loss: 0.65607056, Gradient norm: 0.16718117
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=12189.09375MB
INFO:root:[   37] Training loss: 0.65305652, Validation loss: 0.65580855, Gradient norm: 0.13649979
INFO:root:At the start of the epoch: mem (CPU python)=12454.546875MB; mem (CPU total)=12227.453125MB
INFO:root:[   38] Training loss: 0.65213738, Validation loss: 0.65403711, Gradient norm: 0.15161101
INFO:root:At the start of the epoch: mem (CPU python)=12471.8046875MB; mem (CPU total)=12265.3515625MB
INFO:root:[   39] Training loss: 0.65093571, Validation loss: 0.65224612, Gradient norm: 0.15765483
INFO:root:At the start of the epoch: mem (CPU python)=12509.90234375MB; mem (CPU total)=12303.46484375MB
INFO:root:[   40] Training loss: 0.65020330, Validation loss: 0.65246315, Gradient norm: 0.14520470
INFO:root:At the start of the epoch: mem (CPU python)=12547.99609375MB; mem (CPU total)=12341.8125MB
INFO:root:[   41] Training loss: 0.64922636, Validation loss: 0.65079459, Gradient norm: 0.15898016
INFO:root:At the start of the epoch: mem (CPU python)=12586.08984375MB; mem (CPU total)=12380.19140625MB
INFO:root:[   42] Training loss: 0.64840364, Validation loss: 0.65065981, Gradient norm: 0.15685708
INFO:root:At the start of the epoch: mem (CPU python)=12624.1875MB; mem (CPU total)=12418.54296875MB
INFO:root:[   43] Training loss: 0.64724048, Validation loss: 0.64931705, Gradient norm: 0.16796013
INFO:root:At the start of the epoch: mem (CPU python)=12662.28515625MB; mem (CPU total)=12456.640625MB
INFO:root:[   44] Training loss: 0.64646590, Validation loss: 0.64907051, Gradient norm: 0.15605757
INFO:root:At the start of the epoch: mem (CPU python)=12700.37890625MB; mem (CPU total)=12494.75MB
INFO:root:[   45] Training loss: 0.64558683, Validation loss: 0.64737319, Gradient norm: 0.13836614
INFO:root:At the start of the epoch: mem (CPU python)=12738.47265625MB; mem (CPU total)=12532.80859375MB
INFO:root:[   46] Training loss: 0.64484970, Validation loss: 0.64670676, Gradient norm: 0.19362622
INFO:root:At the start of the epoch: mem (CPU python)=12776.5703125MB; mem (CPU total)=12571.16015625MB
INFO:root:[   47] Training loss: 0.64380369, Validation loss: 0.64601887, Gradient norm: 0.16883535
INFO:root:At the start of the epoch: mem (CPU python)=12814.69921875MB; mem (CPU total)=12609.7578125MB
INFO:root:[   48] Training loss: 0.64308802, Validation loss: 0.64648481, Gradient norm: 0.12177260
INFO:root:At the start of the epoch: mem (CPU python)=12852.79296875MB; mem (CPU total)=12647.859375MB
INFO:root:[   49] Training loss: 0.64233960, Validation loss: 0.64456619, Gradient norm: 0.16211145
INFO:root:At the start of the epoch: mem (CPU python)=12890.890625MB; mem (CPU total)=12684.98828125MB
INFO:root:[   50] Training loss: 0.64203738, Validation loss: 0.64400983, Gradient norm: 0.14186252
INFO:root:At the start of the epoch: mem (CPU python)=12928.984375MB; mem (CPU total)=12722.59375MB
INFO:root:[   51] Training loss: 0.64100778, Validation loss: 0.64417304, Gradient norm: 0.19363910
INFO:root:At the start of the epoch: mem (CPU python)=12967.08203125MB; mem (CPU total)=12760.70703125MB
INFO:root:[   52] Training loss: 0.64039631, Validation loss: 0.64323437, Gradient norm: 0.15928930
INFO:root:At the start of the epoch: mem (CPU python)=13005.1796875MB; mem (CPU total)=12798.79296875MB
INFO:root:[   53] Training loss: 0.63969133, Validation loss: 0.64247566, Gradient norm: 0.16224540
INFO:root:At the start of the epoch: mem (CPU python)=13043.27734375MB; mem (CPU total)=12836.8984375MB
INFO:root:[   54] Training loss: 0.63879528, Validation loss: 0.64183322, Gradient norm: 0.16758499
INFO:root:At the start of the epoch: mem (CPU python)=13081.375MB; mem (CPU total)=12875.25390625MB
INFO:root:[   55] Training loss: 0.63829897, Validation loss: 0.64216154, Gradient norm: 0.15350750
INFO:root:At the start of the epoch: mem (CPU python)=13119.46875MB; mem (CPU total)=12913.11328125MB
INFO:root:[   56] Training loss: 0.63761040, Validation loss: 0.64023214, Gradient norm: 0.17255985
INFO:root:At the start of the epoch: mem (CPU python)=13157.56640625MB; mem (CPU total)=12951.46484375MB
INFO:root:[   57] Training loss: 0.63714930, Validation loss: 0.64027345, Gradient norm: 0.16214712
INFO:root:At the start of the epoch: mem (CPU python)=13195.66015625MB; mem (CPU total)=12989.578125MB
INFO:root:[   58] Training loss: 0.63655523, Validation loss: 0.63876887, Gradient norm: 0.15767891
INFO:root:At the start of the epoch: mem (CPU python)=13233.7578125MB; mem (CPU total)=13027.078125MB
INFO:root:[   59] Training loss: 0.63586591, Validation loss: 0.63950765, Gradient norm: 0.21412169
INFO:root:At the start of the epoch: mem (CPU python)=13271.85546875MB; mem (CPU total)=13065.19140625MB
INFO:root:[   60] Training loss: 0.63524548, Validation loss: 0.63874959, Gradient norm: 0.15766410
INFO:root:At the start of the epoch: mem (CPU python)=13309.94921875MB; mem (CPU total)=13103.5390625MB
INFO:root:[   61] Training loss: 0.63510607, Validation loss: 0.63813005, Gradient norm: 0.19859475
INFO:root:At the start of the epoch: mem (CPU python)=13348.04296875MB; mem (CPU total)=13140.8828125MB
INFO:root:[   62] Training loss: 0.63429582, Validation loss: 0.63798870, Gradient norm: 0.18766002
INFO:root:At the start of the epoch: mem (CPU python)=13386.13671875MB; mem (CPU total)=13178.74609375MB
INFO:root:[   63] Training loss: 0.63340668, Validation loss: 0.63859435, Gradient norm: 0.15935113
INFO:root:At the start of the epoch: mem (CPU python)=13424.234375MB; mem (CPU total)=13216.60546875MB
INFO:root:[   64] Training loss: 0.63319562, Validation loss: 0.63673004, Gradient norm: 0.16608893
INFO:root:At the start of the epoch: mem (CPU python)=13462.328125MB; mem (CPU total)=13254.94921875MB
INFO:root:[   65] Training loss: 0.63293391, Validation loss: 0.63647515, Gradient norm: 0.19559928
INFO:root:At the start of the epoch: mem (CPU python)=13500.42578125MB; mem (CPU total)=13293.03125MB
INFO:root:[   66] Training loss: 0.63219102, Validation loss: 0.63582052, Gradient norm: 0.16473134
INFO:root:At the start of the epoch: mem (CPU python)=13538.5234375MB; mem (CPU total)=13331.1640625MB
INFO:root:[   67] Training loss: 0.63198712, Validation loss: 0.63687694, Gradient norm: 0.17467527
INFO:root:At the start of the epoch: mem (CPU python)=13576.6171875MB; mem (CPU total)=13369.01953125MB
INFO:root:[   68] Training loss: 0.63144822, Validation loss: 0.63511466, Gradient norm: 0.17467829
INFO:root:At the start of the epoch: mem (CPU python)=13614.7109375MB; mem (CPU total)=13407.41015625MB
INFO:root:[   69] Training loss: 0.63083044, Validation loss: 0.63402220, Gradient norm: 0.16170371
INFO:root:At the start of the epoch: mem (CPU python)=13652.80859375MB; mem (CPU total)=13445.765625MB
INFO:root:[   70] Training loss: 0.63061010, Validation loss: 0.63532945, Gradient norm: 0.20071258
INFO:root:At the start of the epoch: mem (CPU python)=13690.90234375MB; mem (CPU total)=13483.8671875MB
INFO:root:[   71] Training loss: 0.63002695, Validation loss: 0.63407158, Gradient norm: 0.19684399
INFO:root:At the start of the epoch: mem (CPU python)=13729.09375MB; mem (CPU total)=13522.4765625MB
INFO:root:[   72] Training loss: 0.62955553, Validation loss: 0.63310195, Gradient norm: 0.19401797
INFO:root:At the start of the epoch: mem (CPU python)=13767.1875MB; mem (CPU total)=13560.4296875MB
INFO:root:[   73] Training loss: 0.62930040, Validation loss: 0.63429992, Gradient norm: 0.19998133
INFO:root:At the start of the epoch: mem (CPU python)=13805.28515625MB; mem (CPU total)=13598.53515625MB
INFO:root:[   74] Training loss: 0.62880330, Validation loss: 0.63283396, Gradient norm: 0.18964627
INFO:root:At the start of the epoch: mem (CPU python)=13843.3828125MB; mem (CPU total)=13636.3984375MB
INFO:root:[   75] Training loss: 0.62852729, Validation loss: 0.63333486, Gradient norm: 0.24261160
INFO:root:At the start of the epoch: mem (CPU python)=13881.47265625MB; mem (CPU total)=13674.73828125MB
INFO:root:[   76] Training loss: 0.62816210, Validation loss: 0.63206731, Gradient norm: 0.26231621
INFO:root:At the start of the epoch: mem (CPU python)=13919.57421875MB; mem (CPU total)=13713.12109375MB
INFO:root:[   77] Training loss: 0.62769547, Validation loss: 0.63142614, Gradient norm: 0.20247747
INFO:root:At the start of the epoch: mem (CPU python)=13957.671875MB; mem (CPU total)=13750.98046875MB
INFO:root:[   78] Training loss: 0.62705030, Validation loss: 0.63118055, Gradient norm: 0.18093447
INFO:root:At the start of the epoch: mem (CPU python)=13995.8046875MB; mem (CPU total)=13790.703125MB
INFO:root:[   79] Training loss: 0.62706832, Validation loss: 0.63150760, Gradient norm: 0.21911799
INFO:root:At the start of the epoch: mem (CPU python)=14033.88671875MB; mem (CPU total)=13828.546875MB
INFO:root:[   80] Training loss: 0.62668942, Validation loss: 0.63090675, Gradient norm: 0.24902810
INFO:root:At the start of the epoch: mem (CPU python)=14071.984375MB; mem (CPU total)=13866.45703125MB
INFO:root:[   81] Training loss: 0.62604361, Validation loss: 0.63072776, Gradient norm: 0.19613833
INFO:root:At the start of the epoch: mem (CPU python)=14110.078125MB; mem (CPU total)=13905.328125MB
INFO:root:[   82] Training loss: 0.62574324, Validation loss: 0.62951923, Gradient norm: 0.24026491
INFO:root:At the start of the epoch: mem (CPU python)=14148.171875MB; mem (CPU total)=13943.453125MB
INFO:root:[   83] Training loss: 0.62541037, Validation loss: 0.63066476, Gradient norm: 0.22554620
INFO:root:At the start of the epoch: mem (CPU python)=14186.2734375MB; mem (CPU total)=13981.5MB
INFO:root:[   84] Training loss: 0.62507224, Validation loss: 0.62985556, Gradient norm: 0.23730282
INFO:root:At the start of the epoch: mem (CPU python)=14224.3671875MB; mem (CPU total)=14019.86328125MB
INFO:root:[   85] Training loss: 0.62473849, Validation loss: 0.62985969, Gradient norm: 0.22808253
INFO:root:At the start of the epoch: mem (CPU python)=14262.4609375MB; mem (CPU total)=14057.95703125MB
INFO:root:[   86] Training loss: 0.62445208, Validation loss: 0.62974499, Gradient norm: 0.25542909
INFO:root:At the start of the epoch: mem (CPU python)=14300.55859375MB; mem (CPU total)=14096.0859375MB
INFO:root:[   87] Training loss: 0.62411067, Validation loss: 0.62910057, Gradient norm: 0.25690423
INFO:root:At the start of the epoch: mem (CPU python)=14338.65234375MB; mem (CPU total)=14134.421875MB
INFO:root:[   88] Training loss: 0.62364281, Validation loss: 0.62902098, Gradient norm: 0.23619946
INFO:root:At the start of the epoch: mem (CPU python)=14376.74609375MB; mem (CPU total)=14172.7578125MB
INFO:root:[   89] Training loss: 0.62339405, Validation loss: 0.62877465, Gradient norm: 0.21404544
INFO:root:At the start of the epoch: mem (CPU python)=14414.83984375MB; mem (CPU total)=14210.92578125MB
INFO:root:[   90] Training loss: 0.62295450, Validation loss: 0.62795149, Gradient norm: 0.23904590
INFO:root:At the start of the epoch: mem (CPU python)=14452.9375MB; mem (CPU total)=14248.58984375MB
INFO:root:[   91] Training loss: 0.62282932, Validation loss: 0.62847220, Gradient norm: 0.31038077
INFO:root:At the start of the epoch: mem (CPU python)=14491.03515625MB; mem (CPU total)=14286.7109375MB
INFO:root:[   92] Training loss: 0.62243669, Validation loss: 0.62799909, Gradient norm: 0.26312846
INFO:root:At the start of the epoch: mem (CPU python)=14529.12890625MB; mem (CPU total)=14325.08984375MB
INFO:root:[   93] Training loss: 0.62242017, Validation loss: 0.62799728, Gradient norm: 0.30641874
INFO:root:At the start of the epoch: mem (CPU python)=14567.2265625MB; mem (CPU total)=14363.2109375MB
INFO:root:[   94] Training loss: 0.62197565, Validation loss: 0.62823606, Gradient norm: 0.24749450
INFO:root:At the start of the epoch: mem (CPU python)=14605.32421875MB; mem (CPU total)=14401.09375MB
INFO:root:[   95] Training loss: 0.62154973, Validation loss: 0.62686804, Gradient norm: 0.27181631
INFO:root:At the start of the epoch: mem (CPU python)=14643.41796875MB; mem (CPU total)=14439.49609375MB
INFO:root:[   96] Training loss: 0.62128095, Validation loss: 0.62784611, Gradient norm: 0.25996762
INFO:root:At the start of the epoch: mem (CPU python)=14681.51171875MB; mem (CPU total)=14477.6015625MB
INFO:root:[   97] Training loss: 0.62132603, Validation loss: 0.62719805, Gradient norm: 0.30745302
INFO:root:At the start of the epoch: mem (CPU python)=14719.60546875MB; mem (CPU total)=14515.99609375MB
INFO:root:[   98] Training loss: 0.62047306, Validation loss: 0.62735241, Gradient norm: 0.27990435
INFO:root:At the start of the epoch: mem (CPU python)=14757.703125MB; mem (CPU total)=14554.15234375MB
INFO:root:[   99] Training loss: 0.62035674, Validation loss: 0.62682558, Gradient norm: 0.30173084
INFO:root:At the start of the epoch: mem (CPU python)=14795.80078125MB; mem (CPU total)=14592.62109375MB
INFO:root:[  100] Training loss: 0.62012345, Validation loss: 0.62642666, Gradient norm: 0.34077739
INFO:root:At the start of the epoch: mem (CPU python)=14833.8984375MB; mem (CPU total)=14631.515625MB
INFO:root:[  101] Training loss: 0.61971339, Validation loss: 0.62568441, Gradient norm: 0.27983681
INFO:root:At the start of the epoch: mem (CPU python)=14871.9921875MB; mem (CPU total)=14668.7578125MB
INFO:root:[  102] Training loss: 0.61969136, Validation loss: 0.62648589, Gradient norm: 0.29189813
INFO:root:At the start of the epoch: mem (CPU python)=14910.0859375MB; mem (CPU total)=14706.89453125MB
INFO:root:[  103] Training loss: 0.61921322, Validation loss: 0.62536329, Gradient norm: 0.31534043
INFO:root:At the start of the epoch: mem (CPU python)=14948.18359375MB; mem (CPU total)=14744.77734375MB
INFO:root:[  104] Training loss: 0.61912546, Validation loss: 0.62589098, Gradient norm: 0.30396500
INFO:root:At the start of the epoch: mem (CPU python)=14986.27734375MB; mem (CPU total)=14782.90234375MB
INFO:root:[  105] Training loss: 0.61860788, Validation loss: 0.62481851, Gradient norm: 0.35521735
INFO:root:At the start of the epoch: mem (CPU python)=15024.37109375MB; mem (CPU total)=14821.02734375MB
INFO:root:[  106] Training loss: 0.61890213, Validation loss: 0.62533268, Gradient norm: 0.34195789
INFO:root:At the start of the epoch: mem (CPU python)=15062.46484375MB; mem (CPU total)=14859.109375MB
INFO:root:[  107] Training loss: 0.61836711, Validation loss: 0.62673569, Gradient norm: 0.38036820
INFO:root:At the start of the epoch: mem (CPU python)=15100.56640625MB; mem (CPU total)=14897.74609375MB
INFO:root:[  108] Training loss: 0.61849469, Validation loss: 0.62445251, Gradient norm: 0.39590997
INFO:root:At the start of the epoch: mem (CPU python)=15138.6640625MB; mem (CPU total)=14935.8671875MB
INFO:root:[  109] Training loss: 0.61773417, Validation loss: 0.62594011, Gradient norm: 0.31531911
INFO:root:At the start of the epoch: mem (CPU python)=15176.7578125MB; mem (CPU total)=14975.47265625MB
INFO:root:[  110] Training loss: 0.61775474, Validation loss: 0.62485677, Gradient norm: 0.34577142
INFO:root:At the start of the epoch: mem (CPU python)=15214.85546875MB; mem (CPU total)=15012.6640625MB
INFO:root:[  111] Training loss: 0.61732792, Validation loss: 0.62509534, Gradient norm: 0.33740981
INFO:root:At the start of the epoch: mem (CPU python)=15252.94921875MB; mem (CPU total)=15050.80078125MB
INFO:root:[  112] Training loss: 0.61722038, Validation loss: 0.62458283, Gradient norm: 0.38792150
INFO:root:At the start of the epoch: mem (CPU python)=15291.08984375MB; mem (CPU total)=15088.9296875MB
INFO:root:[  113] Training loss: 0.61733188, Validation loss: 0.62432549, Gradient norm: 0.44197313
INFO:root:At the start of the epoch: mem (CPU python)=15329.18359375MB; mem (CPU total)=15127.5703125MB
INFO:root:[  114] Training loss: 0.61672826, Validation loss: 0.62275760, Gradient norm: 0.35658040
INFO:root:At the start of the epoch: mem (CPU python)=15367.28125MB; mem (CPU total)=15165.234375MB
INFO:root:[  115] Training loss: 0.61673548, Validation loss: 0.62492001, Gradient norm: 0.42081063
INFO:root:At the start of the epoch: mem (CPU python)=15405.37890625MB; mem (CPU total)=15203.28125MB
INFO:root:[  116] Training loss: 0.61626416, Validation loss: 0.62404596, Gradient norm: 0.37927885
INFO:root:At the start of the epoch: mem (CPU python)=15443.47265625MB; mem (CPU total)=15241.64453125MB
INFO:root:[  117] Training loss: 0.61637667, Validation loss: 0.62412801, Gradient norm: 0.43416550
INFO:root:At the start of the epoch: mem (CPU python)=15481.5703125MB; mem (CPU total)=15279.7890625MB
INFO:root:[  118] Training loss: 0.61586859, Validation loss: 0.62297413, Gradient norm: 0.40983578
INFO:root:At the start of the epoch: mem (CPU python)=15519.6640625MB; mem (CPU total)=15318.41015625MB
INFO:root:[  119] Training loss: 0.61570185, Validation loss: 0.62268267, Gradient norm: 0.37819736
INFO:root:At the start of the epoch: mem (CPU python)=15557.7578125MB; mem (CPU total)=15356.3046875MB
INFO:root:[  120] Training loss: 0.61541477, Validation loss: 0.62322154, Gradient norm: 0.38658485
INFO:root:At the start of the epoch: mem (CPU python)=15595.85546875MB; mem (CPU total)=15394.703125MB
INFO:root:[  121] Training loss: 0.61522770, Validation loss: 0.62362188, Gradient norm: 0.42224996
INFO:root:At the start of the epoch: mem (CPU python)=15633.94921875MB; mem (CPU total)=15433.09375MB
INFO:root:[  122] Training loss: 0.61503948, Validation loss: 0.62313356, Gradient norm: 0.37376704
INFO:root:At the start of the epoch: mem (CPU python)=15672.046875MB; mem (CPU total)=15471.4921875MB
INFO:root:[  123] Training loss: 0.61467470, Validation loss: 0.62304021, Gradient norm: 0.38647747
INFO:root:At the start of the epoch: mem (CPU python)=15710.13671875MB; mem (CPU total)=15509.1328125MB
INFO:root:[  124] Training loss: 0.61462190, Validation loss: 0.62361463, Gradient norm: 0.41976508
INFO:root:At the start of the epoch: mem (CPU python)=15748.23828125MB; mem (CPU total)=15547.27734375MB
INFO:root:[  125] Training loss: 0.61441350, Validation loss: 0.62234382, Gradient norm: 0.37283674
INFO:root:At the start of the epoch: mem (CPU python)=15786.33203125MB; mem (CPU total)=15585.18359375MB
INFO:root:[  126] Training loss: 0.61460875, Validation loss: 0.62319721, Gradient norm: 0.52075663
INFO:root:At the start of the epoch: mem (CPU python)=15824.42578125MB; mem (CPU total)=15622.80078125MB
INFO:root:[  127] Training loss: 0.61406612, Validation loss: 0.62281555, Gradient norm: 0.49091344
INFO:root:At the start of the epoch: mem (CPU python)=15862.5234375MB; mem (CPU total)=15661.17578125MB
INFO:root:[  128] Training loss: 0.61407009, Validation loss: 0.62154585, Gradient norm: 0.49506664
INFO:root:At the start of the epoch: mem (CPU python)=15900.6171875MB; mem (CPU total)=15699.33203125MB
INFO:root:[  129] Training loss: 0.61412419, Validation loss: 0.62089947, Gradient norm: 0.61170110
INFO:root:At the start of the epoch: mem (CPU python)=15938.7109375MB; mem (CPU total)=15737.515625MB
INFO:root:[  130] Training loss: 0.61382701, Validation loss: 0.62200900, Gradient norm: 0.49147855
INFO:root:At the start of the epoch: mem (CPU python)=15976.8046875MB; mem (CPU total)=15775.6796875MB
INFO:root:[  131] Training loss: 0.61342863, Validation loss: 0.62213351, Gradient norm: 0.49228336
INFO:root:At the start of the epoch: mem (CPU python)=16014.90234375MB; mem (CPU total)=15814.0703125MB
INFO:root:[  132] Training loss: 0.61335404, Validation loss: 0.62167507, Gradient norm: 0.63449165
INFO:root:At the start of the epoch: mem (CPU python)=16053.0MB; mem (CPU total)=15852.28125MB
INFO:root:[  133] Training loss: 0.61351343, Validation loss: 0.62236985, Gradient norm: 0.70869249
INFO:root:At the start of the epoch: mem (CPU python)=16091.09375MB; mem (CPU total)=15890.34765625MB
INFO:root:[  134] Training loss: 0.61292719, Validation loss: 0.62196507, Gradient norm: 0.53159214
INFO:root:At the start of the epoch: mem (CPU python)=16129.19140625MB; mem (CPU total)=15928.4765625MB
INFO:root:[  135] Training loss: 0.61265052, Validation loss: 0.62216873, Gradient norm: 0.40507776
INFO:root:At the start of the epoch: mem (CPU python)=16167.28515625MB; mem (CPU total)=15966.8203125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  136] Training loss: 0.61246466, Validation loss: 0.62112363, Gradient norm: 0.46307595
INFO:root:At the start of the epoch: mem (CPU python)=16205.37890625MB; mem (CPU total)=16004.76171875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  137] Training loss: 0.61168793, Validation loss: 0.62026212, Gradient norm: 0.33727778
INFO:root:At the start of the epoch: mem (CPU python)=16243.4765625MB; mem (CPU total)=16043.05078125MB
INFO:root:[  138] Training loss: 0.61075141, Validation loss: 0.61993871, Gradient norm: 0.29825030
INFO:root:At the start of the epoch: mem (CPU python)=16281.5703125MB; mem (CPU total)=16081.171875MB
INFO:root:[  139] Training loss: 0.61048783, Validation loss: 0.62053242, Gradient norm: 0.32962335
INFO:root:At the start of the epoch: mem (CPU python)=16319.6640625MB; mem (CPU total)=16118.78125MB
INFO:root:[  140] Training loss: 0.61036502, Validation loss: 0.62026964, Gradient norm: 0.27324121
INFO:root:At the start of the epoch: mem (CPU python)=16357.7578125MB; mem (CPU total)=16157.140625MB
INFO:root:[  141] Training loss: 0.61043501, Validation loss: 0.62022269, Gradient norm: 0.28807838
INFO:root:At the start of the epoch: mem (CPU python)=16395.859375MB; mem (CPU total)=16195.26171875MB
INFO:root:[  142] Training loss: 0.61059065, Validation loss: 0.62012631, Gradient norm: 0.28999844
INFO:root:At the start of the epoch: mem (CPU python)=16433.953125MB; mem (CPU total)=16233.37890625MB
INFO:root:[  143] Training loss: 0.61031483, Validation loss: 0.61997397, Gradient norm: 0.29451814
INFO:root:At the start of the epoch: mem (CPU python)=16472.046875MB; mem (CPU total)=16271.75MB
INFO:root:[  144] Training loss: 0.61023744, Validation loss: 0.62127252, Gradient norm: 0.29015775
INFO:root:At the start of the epoch: mem (CPU python)=16510.14453125MB; mem (CPU total)=16309.38671875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  145] Training loss: 0.61012251, Validation loss: 0.62054640, Gradient norm: 0.32050219
INFO:root:At the start of the epoch: mem (CPU python)=16548.23828125MB; mem (CPU total)=16347.51171875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  146] Training loss: 0.60983765, Validation loss: 0.61969988, Gradient norm: 0.26336957
INFO:root:At the start of the epoch: mem (CPU python)=16586.33203125MB; mem (CPU total)=16386.20703125MB
INFO:root:[  147] Training loss: 0.60956826, Validation loss: 0.61957497, Gradient norm: 0.24927388
INFO:root:At the start of the epoch: mem (CPU python)=16624.42578125MB; mem (CPU total)=16424.56640625MB
INFO:root:[  148] Training loss: 0.60969279, Validation loss: 0.61965446, Gradient norm: 0.22393095
INFO:root:At the start of the epoch: mem (CPU python)=16662.5234375MB; mem (CPU total)=16462.6796875MB
INFO:root:[  149] Training loss: 0.60995353, Validation loss: 0.61996046, Gradient norm: 0.22433725
INFO:root:At the start of the epoch: mem (CPU python)=16700.6171875MB; mem (CPU total)=16501.34765625MB
INFO:root:[  150] Training loss: 0.60939200, Validation loss: 0.62067751, Gradient norm: 0.23089662
INFO:root:At the start of the epoch: mem (CPU python)=16738.71875MB; mem (CPU total)=16539.24609375MB
INFO:root:[  151] Training loss: 0.60942869, Validation loss: 0.61957968, Gradient norm: 0.23482355
INFO:root:At the start of the epoch: mem (CPU python)=16776.81640625MB; mem (CPU total)=16577.37109375MB
INFO:root:[  152] Training loss: 0.60949953, Validation loss: 0.61983841, Gradient norm: 0.25446760
INFO:root:At the start of the epoch: mem (CPU python)=16814.91015625MB; mem (CPU total)=16615.73828125MB
INFO:root:[  153] Training loss: 0.60972555, Validation loss: 0.61951496, Gradient norm: 0.25068592
INFO:root:At the start of the epoch: mem (CPU python)=16853.00390625MB; mem (CPU total)=16653.9296875MB
INFO:root:[  154] Training loss: 0.60972221, Validation loss: 0.61893407, Gradient norm: 0.22425217
INFO:root:At the start of the epoch: mem (CPU python)=16891.1015625MB; mem (CPU total)=16691.828125MB
INFO:root:[  155] Training loss: 0.60962468, Validation loss: 0.62037540, Gradient norm: 0.23183592
INFO:root:At the start of the epoch: mem (CPU python)=16929.1953125MB; mem (CPU total)=16730.2109375MB
INFO:root:[  156] Training loss: 0.60973521, Validation loss: 0.61920493, Gradient norm: 0.23248598
INFO:root:At the start of the epoch: mem (CPU python)=16967.2890625MB; mem (CPU total)=16768.33984375MB
INFO:root:[  157] Training loss: 0.60954498, Validation loss: 0.61984105, Gradient norm: 0.23359580
INFO:root:At the start of the epoch: mem (CPU python)=17005.38671875MB; mem (CPU total)=16806.4765625MB
INFO:root:[  158] Training loss: 0.60956206, Validation loss: 0.62054004, Gradient norm: 0.25749606
INFO:root:At the start of the epoch: mem (CPU python)=17043.484375MB; mem (CPU total)=16845.49609375MB
INFO:root:[  159] Training loss: 0.60921360, Validation loss: 0.61952403, Gradient norm: 0.24156181
INFO:root:At the start of the epoch: mem (CPU python)=17081.578125MB; mem (CPU total)=16883.359375MB
INFO:root:[  160] Training loss: 0.60953156, Validation loss: 0.62079008, Gradient norm: 0.24545045
INFO:root:At the start of the epoch: mem (CPU python)=17119.671875MB; mem (CPU total)=16921.71875MB
INFO:root:[  161] Training loss: 0.60943176, Validation loss: 0.61990203, Gradient norm: 0.25787622
INFO:root:At the start of the epoch: mem (CPU python)=17157.76953125MB; mem (CPU total)=16960.06640625MB
INFO:root:[  162] Training loss: 0.60940028, Validation loss: 0.61886350, Gradient norm: 0.23199578
INFO:root:At the start of the epoch: mem (CPU python)=17195.86328125MB; mem (CPU total)=16997.94921875MB
INFO:root:[  163] Training loss: 0.60930439, Validation loss: 0.61918399, Gradient norm: 0.26421002
INFO:root:At the start of the epoch: mem (CPU python)=17233.95703125MB; mem (CPU total)=17036.125MB
INFO:root:[  164] Training loss: 0.60940535, Validation loss: 0.61991387, Gradient norm: 0.26243384
INFO:root:At the start of the epoch: mem (CPU python)=17272.05078125MB; mem (CPU total)=17074.2578125MB
INFO:root:[  165] Training loss: 0.60956511, Validation loss: 0.62016402, Gradient norm: 0.24097646
INFO:root:At the start of the epoch: mem (CPU python)=17310.15234375MB; mem (CPU total)=17112.40234375MB
INFO:root:[  166] Training loss: 0.60935401, Validation loss: 0.61959279, Gradient norm: 0.25320579
INFO:root:At the start of the epoch: mem (CPU python)=17348.24609375MB; mem (CPU total)=17150.546875MB
INFO:root:[  167] Training loss: 0.60946846, Validation loss: 0.61926408, Gradient norm: 0.24941531
INFO:root:At the start of the epoch: mem (CPU python)=17386.33984375MB; mem (CPU total)=17188.67578125MB
INFO:root:[  168] Training loss: 0.60944586, Validation loss: 0.61932750, Gradient norm: 0.25475814
INFO:root:At the start of the epoch: mem (CPU python)=17424.4375MB; mem (CPU total)=17227.05859375MB
INFO:root:[  169] Training loss: 0.60971643, Validation loss: 0.61963612, Gradient norm: 0.24316627
INFO:root:At the start of the epoch: mem (CPU python)=17462.53125MB; mem (CPU total)=17265.16015625MB
INFO:root:[  170] Training loss: 0.60933690, Validation loss: 0.61950790, Gradient norm: 0.25877864
INFO:root:At the start of the epoch: mem (CPU python)=17500.625MB; mem (CPU total)=17303.5703125MB
INFO:root:[  171] Training loss: 0.60938453, Validation loss: 0.61931327, Gradient norm: 0.24449986
INFO:root:At the start of the epoch: mem (CPU python)=17538.72265625MB; mem (CPU total)=17341.92578125MB
INFO:root:EP 171: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=17576.8203125MB; mem (CPU total)=17380.0859375MB
INFO:root:Training the model took 8131.678s.
INFO:root:Emptying the cuda cache took 0.078s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86512
INFO:root:EnergyScoreTrain: 0.60935
INFO:root:CRPSTrain: 0.55227
INFO:root:Gaussian NLLTrain: 4.97005
INFO:root:CoverageTrain: 0.74867
INFO:root:IntervalWidthTrain: 3.08802
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8801
INFO:root:EnergyScoreValidation: 0.61977
INFO:root:CRPSValidation: 0.5603
INFO:root:Gaussian NLLValidation: 4.98608
INFO:root:CoverageValidation: 0.74447
INFO:root:IntervalWidthValidation: 3.08653
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88145
INFO:root:EnergyScoreTest: 0.62073
INFO:root:CRPSTest: 0.5614
INFO:root:Gaussian NLLTest: 5.02156
INFO:root:CoverageTest: 0.74302
INFO:root:IntervalWidthTest: 3.07836
INFO:root:After validation: mem (CPU python)=17619.83984375MB; mem (CPU total)=17422.0703125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=17619.83984375MB; mem (CPU total)=17422.30859375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=17620.265625MB; mem (CPU total)=17422.80078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=17620.28125MB; mem (CPU total)=17422.79296875MB
INFO:root:[    1] Training loss: 0.77807092, Validation loss: 0.72383123, Gradient norm: 0.46939140
INFO:root:At the start of the epoch: mem (CPU python)=17658.28515625MB; mem (CPU total)=17461.22265625MB
INFO:root:[    2] Training loss: 0.72196984, Validation loss: 0.72066027, Gradient norm: 0.45086258
INFO:root:At the start of the epoch: mem (CPU python)=17696.3671875MB; mem (CPU total)=17499.38671875MB
INFO:root:[    3] Training loss: 0.72049152, Validation loss: 0.71962313, Gradient norm: 0.29949830
INFO:root:At the start of the epoch: mem (CPU python)=17734.48046875MB; mem (CPU total)=17537.76953125MB
INFO:root:[    4] Training loss: 0.72003219, Validation loss: 0.72028887, Gradient norm: 0.26949882
INFO:root:At the start of the epoch: mem (CPU python)=17772.58984375MB; mem (CPU total)=17575.87109375MB
INFO:root:[    5] Training loss: 0.71973064, Validation loss: 0.72039757, Gradient norm: 0.22573329
INFO:root:At the start of the epoch: mem (CPU python)=17810.703125MB; mem (CPU total)=17614.23828125MB
INFO:root:[    6] Training loss: 0.71948102, Validation loss: 0.71969593, Gradient norm: 0.22334874
INFO:root:At the start of the epoch: mem (CPU python)=17848.81640625MB; mem (CPU total)=17652.13671875MB
INFO:root:[    7] Training loss: 0.71907640, Validation loss: 0.71909565, Gradient norm: 0.20038466
INFO:root:At the start of the epoch: mem (CPU python)=17886.92578125MB; mem (CPU total)=17690.4765625MB
INFO:root:[    8] Training loss: 0.71855126, Validation loss: 0.71816337, Gradient norm: 0.19423005
INFO:root:At the start of the epoch: mem (CPU python)=17925.01953125MB; mem (CPU total)=17728.56640625MB
INFO:root:[    9] Training loss: 0.71753364, Validation loss: 0.71631517, Gradient norm: 0.23884559
INFO:root:At the start of the epoch: mem (CPU python)=17963.11328125MB; mem (CPU total)=17766.6796875MB
INFO:root:[   10] Training loss: 0.71395184, Validation loss: 0.71059074, Gradient norm: 0.22927727
INFO:root:At the start of the epoch: mem (CPU python)=18001.2109375MB; mem (CPU total)=17804.578125MB
INFO:root:[   11] Training loss: 0.70693596, Validation loss: 0.70346185, Gradient norm: 0.25064033
INFO:root:At the start of the epoch: mem (CPU python)=18039.3046875MB; mem (CPU total)=17842.72265625MB
INFO:root:[   12] Training loss: 0.69978323, Validation loss: 0.69804602, Gradient norm: 0.17203370
INFO:root:At the start of the epoch: mem (CPU python)=18077.3984375MB; mem (CPU total)=17881.37109375MB
INFO:root:[   13] Training loss: 0.69429543, Validation loss: 0.69180412, Gradient norm: 0.17024898
INFO:root:At the start of the epoch: mem (CPU python)=18115.49609375MB; mem (CPU total)=17919.67578125MB
INFO:root:[   14] Training loss: 0.68961922, Validation loss: 0.68748737, Gradient norm: 0.18080557
INFO:root:At the start of the epoch: mem (CPU python)=18153.58984375MB; mem (CPU total)=17956.55859375MB
INFO:root:[   15] Training loss: 0.68541485, Validation loss: 0.68499123, Gradient norm: 0.13083399
INFO:root:At the start of the epoch: mem (CPU python)=18191.6875MB; mem (CPU total)=17994.69140625MB
INFO:root:[   16] Training loss: 0.68201604, Validation loss: 0.68129687, Gradient norm: 0.15559073
INFO:root:At the start of the epoch: mem (CPU python)=18229.78515625MB; mem (CPU total)=18032.59765625MB
INFO:root:[   17] Training loss: 0.67912064, Validation loss: 0.67764851, Gradient norm: 0.18904039
INFO:root:At the start of the epoch: mem (CPU python)=18267.87890625MB; mem (CPU total)=18071.03515625MB
INFO:root:[   18] Training loss: 0.67590917, Validation loss: 0.67613465, Gradient norm: 0.14220435
INFO:root:At the start of the epoch: mem (CPU python)=18305.97265625MB; mem (CPU total)=18109.38671875MB
INFO:root:[   19] Training loss: 0.67322691, Validation loss: 0.67328609, Gradient norm: 0.15190539
INFO:root:At the start of the epoch: mem (CPU python)=18344.06640625MB; mem (CPU total)=18147.27734375MB
INFO:root:[   20] Training loss: 0.67092042, Validation loss: 0.67111118, Gradient norm: 0.12953713
INFO:root:At the start of the epoch: mem (CPU python)=18382.1640625MB; mem (CPU total)=18185.6328125MB
INFO:root:[   21] Training loss: 0.66885551, Validation loss: 0.66927493, Gradient norm: 0.13042950
INFO:root:At the start of the epoch: mem (CPU python)=18420.26171875MB; mem (CPU total)=18223.4921875MB
INFO:root:[   22] Training loss: 0.66673625, Validation loss: 0.66601746, Gradient norm: 0.14170097
INFO:root:At the start of the epoch: mem (CPU python)=18458.35546875MB; mem (CPU total)=18263.08203125MB
INFO:root:[   23] Training loss: 0.66476057, Validation loss: 0.66554152, Gradient norm: 0.13527885
INFO:root:At the start of the epoch: mem (CPU python)=18496.453125MB; mem (CPU total)=18301.453125MB
INFO:root:[   24] Training loss: 0.66280595, Validation loss: 0.66359881, Gradient norm: 0.16668761
INFO:root:At the start of the epoch: mem (CPU python)=18534.546875MB; mem (CPU total)=18339.24609375MB
INFO:root:[   25] Training loss: 0.66131846, Validation loss: 0.66201824, Gradient norm: 0.16530574
INFO:root:At the start of the epoch: mem (CPU python)=18572.640625MB; mem (CPU total)=18377.65234375MB
INFO:root:[   26] Training loss: 0.65985899, Validation loss: 0.66061820, Gradient norm: 0.16099084
INFO:root:At the start of the epoch: mem (CPU python)=18610.734375MB; mem (CPU total)=18415.4765625MB
INFO:root:[   27] Training loss: 0.65808386, Validation loss: 0.65887237, Gradient norm: 0.13428045
INFO:root:At the start of the epoch: mem (CPU python)=18648.83203125MB; mem (CPU total)=18453.3203125MB
INFO:root:[   28] Training loss: 0.65724048, Validation loss: 0.65815520, Gradient norm: 0.15239617
INFO:root:At the start of the epoch: mem (CPU python)=18686.9296875MB; mem (CPU total)=18491.39453125MB
INFO:root:[   29] Training loss: 0.65568466, Validation loss: 0.65715282, Gradient norm: 0.12762162
INFO:root:At the start of the epoch: mem (CPU python)=18725.0234375MB; mem (CPU total)=18529.859375MB
INFO:root:[   30] Training loss: 0.65448020, Validation loss: 0.65619874, Gradient norm: 0.15973275
INFO:root:At the start of the epoch: mem (CPU python)=18763.12109375MB; mem (CPU total)=18567.296875MB
INFO:root:[   31] Training loss: 0.65357508, Validation loss: 0.65563476, Gradient norm: 0.15562354
INFO:root:At the start of the epoch: mem (CPU python)=18801.21484375MB; mem (CPU total)=18605.9453125MB
INFO:root:[   32] Training loss: 0.65207769, Validation loss: 0.65427827, Gradient norm: 0.16720258
INFO:root:At the start of the epoch: mem (CPU python)=18839.30859375MB; mem (CPU total)=18643.546875MB
INFO:root:[   33] Training loss: 0.65168819, Validation loss: 0.65301351, Gradient norm: 0.14997100
INFO:root:At the start of the epoch: mem (CPU python)=18877.40625MB; mem (CPU total)=18681.421875MB
INFO:root:[   34] Training loss: 0.65024104, Validation loss: 0.65211518, Gradient norm: 0.14651159
INFO:root:At the start of the epoch: mem (CPU python)=18915.5MB; mem (CPU total)=18719.046875MB
INFO:root:[   35] Training loss: 0.64892657, Validation loss: 0.65069733, Gradient norm: 0.13779497
INFO:root:At the start of the epoch: mem (CPU python)=18953.59375MB; mem (CPU total)=18757.140625MB
INFO:root:[   36] Training loss: 0.64827293, Validation loss: 0.64974588, Gradient norm: 0.15888449
INFO:root:At the start of the epoch: mem (CPU python)=18991.6875MB; mem (CPU total)=18795.7578125MB
INFO:root:[   37] Training loss: 0.64727359, Validation loss: 0.64908629, Gradient norm: 0.14428336
INFO:root:At the start of the epoch: mem (CPU python)=19029.7890625MB; mem (CPU total)=18833.8828125MB
INFO:root:[   38] Training loss: 0.64672271, Validation loss: 0.64925256, Gradient norm: 0.13686488
INFO:root:At the start of the epoch: mem (CPU python)=19067.8828125MB; mem (CPU total)=18872.25MB
INFO:root:[   39] Training loss: 0.64566644, Validation loss: 0.64800845, Gradient norm: 0.14221831
INFO:root:At the start of the epoch: mem (CPU python)=19105.9765625MB; mem (CPU total)=18910.13671875MB
INFO:root:[   40] Training loss: 0.64514834, Validation loss: 0.64781088, Gradient norm: 0.15639625
INFO:root:At the start of the epoch: mem (CPU python)=19144.07421875MB; mem (CPU total)=18948.5234375MB
INFO:root:[   41] Training loss: 0.64415394, Validation loss: 0.64740034, Gradient norm: 0.15274026
INFO:root:At the start of the epoch: mem (CPU python)=19182.16796875MB; mem (CPU total)=18986.68359375MB
INFO:root:[   42] Training loss: 0.64352173, Validation loss: 0.64574780, Gradient norm: 0.15113038
INFO:root:At the start of the epoch: mem (CPU python)=19220.26171875MB; mem (CPU total)=19024.80078125MB
INFO:root:[   43] Training loss: 0.64266876, Validation loss: 0.64549275, Gradient norm: 0.14163186
INFO:root:At the start of the epoch: mem (CPU python)=19258.35546875MB; mem (CPU total)=19063.15625MB
INFO:root:[   44] Training loss: 0.64194321, Validation loss: 0.64506292, Gradient norm: 0.16236214
INFO:root:At the start of the epoch: mem (CPU python)=19296.4609375MB; mem (CPU total)=19101.03125MB
INFO:root:[   45] Training loss: 0.64130946, Validation loss: 0.64416531, Gradient norm: 0.18106430
INFO:root:At the start of the epoch: mem (CPU python)=19334.5546875MB; mem (CPU total)=19139.1796875MB
INFO:root:[   46] Training loss: 0.64025174, Validation loss: 0.64401571, Gradient norm: 0.14752932
INFO:root:At the start of the epoch: mem (CPU python)=19372.6484375MB; mem (CPU total)=19177.546875MB
INFO:root:[   47] Training loss: 0.63961550, Validation loss: 0.64280842, Gradient norm: 0.14792101
INFO:root:At the start of the epoch: mem (CPU python)=19410.74609375MB; mem (CPU total)=19215.42578125MB
INFO:root:[   48] Training loss: 0.63875721, Validation loss: 0.64157111, Gradient norm: 0.13452215
INFO:root:At the start of the epoch: mem (CPU python)=19448.83984375MB; mem (CPU total)=19253.8203125MB
INFO:root:[   49] Training loss: 0.63824179, Validation loss: 0.64172873, Gradient norm: 0.17216764
INFO:root:At the start of the epoch: mem (CPU python)=19486.93359375MB; mem (CPU total)=19291.69921875MB
INFO:root:[   50] Training loss: 0.63744989, Validation loss: 0.64058344, Gradient norm: 0.15301857
INFO:root:At the start of the epoch: mem (CPU python)=19525.03125MB; mem (CPU total)=19329.8125MB
INFO:root:[   51] Training loss: 0.63672106, Validation loss: 0.64032272, Gradient norm: 0.14470231
INFO:root:At the start of the epoch: mem (CPU python)=19563.125MB; mem (CPU total)=19368.40625MB
INFO:root:[   52] Training loss: 0.63619435, Validation loss: 0.63866801, Gradient norm: 0.14549608
INFO:root:At the start of the epoch: mem (CPU python)=19601.21875MB; mem (CPU total)=19406.55078125MB
INFO:root:[   53] Training loss: 0.63546039, Validation loss: 0.63916091, Gradient norm: 0.16090522
INFO:root:At the start of the epoch: mem (CPU python)=19639.3125MB; mem (CPU total)=19444.80859375MB
INFO:root:[   54] Training loss: 0.63502866, Validation loss: 0.63725440, Gradient norm: 0.13609489
INFO:root:At the start of the epoch: mem (CPU python)=19677.41015625MB; mem (CPU total)=19482.87109375MB
INFO:root:[   55] Training loss: 0.63433406, Validation loss: 0.63787939, Gradient norm: 0.14574563
INFO:root:At the start of the epoch: mem (CPU python)=19715.5078125MB; mem (CPU total)=19520.98046875MB
INFO:root:[   56] Training loss: 0.63374708, Validation loss: 0.63708243, Gradient norm: 0.18440244
INFO:root:At the start of the epoch: mem (CPU python)=19753.6015625MB; mem (CPU total)=19559.3671875MB
INFO:root:[   57] Training loss: 0.63311791, Validation loss: 0.63695984, Gradient norm: 0.15127407
INFO:root:At the start of the epoch: mem (CPU python)=19791.703125MB; mem (CPU total)=19597.46875MB
INFO:root:[   58] Training loss: 0.63252142, Validation loss: 0.63565766, Gradient norm: 0.15679218
INFO:root:At the start of the epoch: mem (CPU python)=19829.796875MB; mem (CPU total)=19635.6015625MB
INFO:root:[   59] Training loss: 0.63197258, Validation loss: 0.63537805, Gradient norm: 0.14361621
INFO:root:At the start of the epoch: mem (CPU python)=19867.890625MB; mem (CPU total)=19673.73046875MB
INFO:root:[   60] Training loss: 0.63186249, Validation loss: 0.63504086, Gradient norm: 0.18141109
INFO:root:At the start of the epoch: mem (CPU python)=19905.984375MB; mem (CPU total)=19711.6328125MB
INFO:root:[   61] Training loss: 0.63117811, Validation loss: 0.63408116, Gradient norm: 0.19101298
INFO:root:At the start of the epoch: mem (CPU python)=19944.08203125MB; mem (CPU total)=19749.75MB
INFO:root:[   62] Training loss: 0.63029415, Validation loss: 0.63400339, Gradient norm: 0.18434259
INFO:root:At the start of the epoch: mem (CPU python)=19982.17578125MB; mem (CPU total)=19788.12109375MB
INFO:root:[   63] Training loss: 0.62991762, Validation loss: 0.63326872, Gradient norm: 0.18821301
INFO:root:At the start of the epoch: mem (CPU python)=20020.26953125MB; mem (CPU total)=19826.7421875MB
INFO:root:[   64] Training loss: 0.62948268, Validation loss: 0.63357676, Gradient norm: 0.18867826
INFO:root:At the start of the epoch: mem (CPU python)=20058.37109375MB; mem (CPU total)=19865.6640625MB
INFO:root:[   65] Training loss: 0.62895520, Validation loss: 0.63225219, Gradient norm: 0.17823108
INFO:root:At the start of the epoch: mem (CPU python)=20096.46484375MB; mem (CPU total)=19903.64453125MB
INFO:root:[   66] Training loss: 0.62852659, Validation loss: 0.63332918, Gradient norm: 0.17404952
INFO:root:At the start of the epoch: mem (CPU python)=20134.55859375MB; mem (CPU total)=19941.75390625MB
INFO:root:[   67] Training loss: 0.62793648, Validation loss: 0.63215188, Gradient norm: 0.16365580
INFO:root:At the start of the epoch: mem (CPU python)=20172.65625MB; mem (CPU total)=19980.03515625MB
INFO:root:[   68] Training loss: 0.62744659, Validation loss: 0.63114783, Gradient norm: 0.19045220
INFO:root:At the start of the epoch: mem (CPU python)=20210.75MB; mem (CPU total)=20018.140625MB
INFO:root:[   69] Training loss: 0.62729333, Validation loss: 0.63149767, Gradient norm: 0.19276502
INFO:root:At the start of the epoch: mem (CPU python)=20248.84375MB; mem (CPU total)=20056.2734375MB
INFO:root:[   70] Training loss: 0.62663942, Validation loss: 0.63060766, Gradient norm: 0.16985223
INFO:root:At the start of the epoch: mem (CPU python)=20286.9375MB; mem (CPU total)=20094.4140625MB
INFO:root:[   71] Training loss: 0.62639380, Validation loss: 0.63118442, Gradient norm: 0.19371583
INFO:root:At the start of the epoch: mem (CPU python)=20325.03515625MB; mem (CPU total)=20132.3046875MB
INFO:root:[   72] Training loss: 0.62590780, Validation loss: 0.63017009, Gradient norm: 0.19780042
INFO:root:At the start of the epoch: mem (CPU python)=20363.1328125MB; mem (CPU total)=20170.4375MB
INFO:root:[   73] Training loss: 0.62556410, Validation loss: 0.62972360, Gradient norm: 0.17021592
INFO:root:At the start of the epoch: mem (CPU python)=20401.2265625MB; mem (CPU total)=20208.62109375MB
INFO:root:[   74] Training loss: 0.62494605, Validation loss: 0.62948193, Gradient norm: 0.18709616
INFO:root:At the start of the epoch: mem (CPU python)=20439.32421875MB; mem (CPU total)=20247.46484375MB
INFO:root:[   75] Training loss: 0.62461914, Validation loss: 0.63027706, Gradient norm: 0.17056850
INFO:root:At the start of the epoch: mem (CPU python)=20477.41796875MB; mem (CPU total)=20285.61328125MB
INFO:root:[   76] Training loss: 0.62415497, Validation loss: 0.62918125, Gradient norm: 0.21170033
INFO:root:At the start of the epoch: mem (CPU python)=20515.515625MB; mem (CPU total)=20323.5859375MB
INFO:root:[   77] Training loss: 0.62376425, Validation loss: 0.62895095, Gradient norm: 0.19574917
INFO:root:At the start of the epoch: mem (CPU python)=20553.609375MB; mem (CPU total)=20363.2578125MB
INFO:root:[   78] Training loss: 0.62347272, Validation loss: 0.62825815, Gradient norm: 0.21507584
INFO:root:At the start of the epoch: mem (CPU python)=20591.70703125MB; mem (CPU total)=20398.01953125MB
INFO:root:[   79] Training loss: 0.62325452, Validation loss: 0.62780180, Gradient norm: 0.21781091
INFO:root:At the start of the epoch: mem (CPU python)=20630.5703125MB; mem (CPU total)=20436.5859375MB
INFO:root:[   80] Training loss: 0.62297133, Validation loss: 0.62779465, Gradient norm: 0.21322893
INFO:root:At the start of the epoch: mem (CPU python)=20668.6640625MB; mem (CPU total)=20474.9921875MB
INFO:root:[   81] Training loss: 0.62245323, Validation loss: 0.62831849, Gradient norm: 0.24700495
INFO:root:At the start of the epoch: mem (CPU python)=20706.76171875MB; mem (CPU total)=20513.125MB
INFO:root:[   82] Training loss: 0.62225140, Validation loss: 0.62605673, Gradient norm: 0.21974388
INFO:root:At the start of the epoch: mem (CPU python)=20744.85546875MB; mem (CPU total)=20549.953125MB
INFO:root:[   83] Training loss: 0.62167466, Validation loss: 0.62740167, Gradient norm: 0.20892131
INFO:root:At the start of the epoch: mem (CPU python)=20782.94921875MB; mem (CPU total)=20588.9609375MB
INFO:root:[   84] Training loss: 0.62150018, Validation loss: 0.62601786, Gradient norm: 0.22471432
INFO:root:At the start of the epoch: mem (CPU python)=20821.046875MB; mem (CPU total)=20627.125MB
INFO:root:[   85] Training loss: 0.62087729, Validation loss: 0.62561019, Gradient norm: 0.21996950
INFO:root:At the start of the epoch: mem (CPU python)=20859.140625MB; mem (CPU total)=20665.484375MB
INFO:root:[   86] Training loss: 0.62084589, Validation loss: 0.62621733, Gradient norm: 0.19191087
INFO:root:At the start of the epoch: mem (CPU python)=20897.234375MB; mem (CPU total)=20703.82421875MB
INFO:root:[   87] Training loss: 0.62069032, Validation loss: 0.62629998, Gradient norm: 0.27356234
INFO:root:At the start of the epoch: mem (CPU python)=20935.41015625MB; mem (CPU total)=20741.9765625MB
INFO:root:[   88] Training loss: 0.62009745, Validation loss: 0.62577549, Gradient norm: 0.20982890
INFO:root:At the start of the epoch: mem (CPU python)=20973.5078125MB; mem (CPU total)=20779.8515625MB
INFO:root:[   89] Training loss: 0.62024080, Validation loss: 0.62622376, Gradient norm: 0.29242472
INFO:root:At the start of the epoch: mem (CPU python)=21011.6015625MB; mem (CPU total)=20817.984375MB
INFO:root:[   90] Training loss: 0.61971455, Validation loss: 0.62470232, Gradient norm: 0.23521793
INFO:root:At the start of the epoch: mem (CPU python)=21049.6953125MB; mem (CPU total)=20856.140625MB
INFO:root:[   91] Training loss: 0.61955395, Validation loss: 0.62433158, Gradient norm: 0.29729063
INFO:root:At the start of the epoch: mem (CPU python)=21087.80078125MB; mem (CPU total)=20894.5546875MB
INFO:root:[   92] Training loss: 0.61906430, Validation loss: 0.62485758, Gradient norm: 0.26738459
INFO:root:At the start of the epoch: mem (CPU python)=21125.89453125MB; mem (CPU total)=20932.6875MB
INFO:root:[   93] Training loss: 0.61875663, Validation loss: 0.62466466, Gradient norm: 0.25593697
INFO:root:At the start of the epoch: mem (CPU python)=21163.98828125MB; mem (CPU total)=20970.66796875MB
INFO:root:[   94] Training loss: 0.61855212, Validation loss: 0.62403562, Gradient norm: 0.24170067
INFO:root:At the start of the epoch: mem (CPU python)=21202.0859375MB; mem (CPU total)=21008.98046875MB
INFO:root:[   95] Training loss: 0.61785673, Validation loss: 0.62408224, Gradient norm: 0.20244295
INFO:root:At the start of the epoch: mem (CPU python)=21240.18359375MB; mem (CPU total)=21047.11328125MB
INFO:root:[   96] Training loss: 0.61776777, Validation loss: 0.62346605, Gradient norm: 0.24830386
INFO:root:At the start of the epoch: mem (CPU python)=21278.27734375MB; mem (CPU total)=21085.47265625MB
INFO:root:[   97] Training loss: 0.61761637, Validation loss: 0.62370503, Gradient norm: 0.25442428
INFO:root:At the start of the epoch: mem (CPU python)=21316.37109375MB; mem (CPU total)=21123.86328125MB
INFO:root:[   98] Training loss: 0.61741095, Validation loss: 0.62330434, Gradient norm: 0.30423210
INFO:root:At the start of the epoch: mem (CPU python)=21354.46875MB; mem (CPU total)=21162.01953125MB
INFO:root:[   99] Training loss: 0.61673062, Validation loss: 0.62390144, Gradient norm: 0.29350338
INFO:root:At the start of the epoch: mem (CPU python)=21392.5625MB; mem (CPU total)=21200.4609375MB
INFO:root:[  100] Training loss: 0.61728383, Validation loss: 0.62311147, Gradient norm: 0.38400418
INFO:root:At the start of the epoch: mem (CPU python)=21430.65625MB; mem (CPU total)=21238.76171875MB
INFO:root:[  101] Training loss: 0.61672917, Validation loss: 0.62318541, Gradient norm: 0.34173682
INFO:root:At the start of the epoch: mem (CPU python)=21468.75390625MB; mem (CPU total)=21276.640625MB
INFO:root:[  102] Training loss: 0.61644257, Validation loss: 0.62307863, Gradient norm: 0.30289687
INFO:root:At the start of the epoch: mem (CPU python)=21506.84765625MB; mem (CPU total)=21314.7734375MB
INFO:root:[  103] Training loss: 0.61612858, Validation loss: 0.62192421, Gradient norm: 0.27845843
INFO:root:At the start of the epoch: mem (CPU python)=21544.94140625MB; mem (CPU total)=21352.6640625MB
INFO:root:[  104] Training loss: 0.61583972, Validation loss: 0.62284442, Gradient norm: 0.31421550
INFO:root:At the start of the epoch: mem (CPU python)=21583.0390625MB; mem (CPU total)=21391.03515625MB
INFO:root:[  105] Training loss: 0.61576297, Validation loss: 0.62167376, Gradient norm: 0.32771957
INFO:root:At the start of the epoch: mem (CPU python)=21621.13671875MB; mem (CPU total)=21428.91015625MB
INFO:root:[  106] Training loss: 0.61522081, Validation loss: 0.62249296, Gradient norm: 0.37024932
INFO:root:At the start of the epoch: mem (CPU python)=21659.23046875MB; mem (CPU total)=21466.7890625MB
INFO:root:[  107] Training loss: 0.61528212, Validation loss: 0.62232982, Gradient norm: 0.35138831
INFO:root:At the start of the epoch: mem (CPU python)=21697.32421875MB; mem (CPU total)=21505.17578125MB
INFO:root:[  108] Training loss: 0.61468289, Validation loss: 0.62150493, Gradient norm: 0.33429859
INFO:root:At the start of the epoch: mem (CPU python)=21735.421875MB; mem (CPU total)=21543.0625MB
INFO:root:[  109] Training loss: 0.61492061, Validation loss: 0.62191269, Gradient norm: 0.35109287
INFO:root:At the start of the epoch: mem (CPU python)=21773.51953125MB; mem (CPU total)=21580.93359375MB
INFO:root:[  110] Training loss: 0.61462326, Validation loss: 0.62206796, Gradient norm: 0.34629992
INFO:root:At the start of the epoch: mem (CPU python)=21811.61328125MB; mem (CPU total)=21619.08984375MB
INFO:root:[  111] Training loss: 0.61469054, Validation loss: 0.62109932, Gradient norm: 0.33744243
INFO:root:At the start of the epoch: mem (CPU python)=21849.7109375MB; mem (CPU total)=21657.34375MB
INFO:root:[  112] Training loss: 0.61426954, Validation loss: 0.62106839, Gradient norm: 0.46903706
INFO:root:At the start of the epoch: mem (CPU python)=21887.8046875MB; mem (CPU total)=21695.48828125MB
INFO:root:[  113] Training loss: 0.61381110, Validation loss: 0.62111445, Gradient norm: 0.32653184
INFO:root:At the start of the epoch: mem (CPU python)=21925.8984375MB; mem (CPU total)=21733.37109375MB
INFO:root:[  114] Training loss: 0.61370736, Validation loss: 0.62106261, Gradient norm: 0.36006900
INFO:root:At the start of the epoch: mem (CPU python)=21963.99609375MB; mem (CPU total)=21771.38671875MB
INFO:root:[  115] Training loss: 0.61358882, Validation loss: 0.62199687, Gradient norm: 0.44447893
INFO:root:At the start of the epoch: mem (CPU python)=22002.09375MB; mem (CPU total)=21809.3046875MB
INFO:root:[  116] Training loss: 0.61331925, Validation loss: 0.61988546, Gradient norm: 0.33930498
INFO:root:At the start of the epoch: mem (CPU python)=22040.1875MB; mem (CPU total)=21847.71484375MB
INFO:root:[  117] Training loss: 0.61319415, Validation loss: 0.61963682, Gradient norm: 0.45459267
INFO:root:At the start of the epoch: mem (CPU python)=22078.28125MB; mem (CPU total)=21885.87109375MB
INFO:root:[  118] Training loss: 0.61293380, Validation loss: 0.62076973, Gradient norm: 0.35034835
INFO:root:At the start of the epoch: mem (CPU python)=22116.37890625MB; mem (CPU total)=21924.01953125MB
INFO:root:[  119] Training loss: 0.61281349, Validation loss: 0.62045456, Gradient norm: 0.39699631
INFO:root:At the start of the epoch: mem (CPU python)=22154.47265625MB; mem (CPU total)=21962.4140625MB
INFO:root:[  120] Training loss: 0.61283979, Validation loss: 0.62058083, Gradient norm: 0.54558324
INFO:root:At the start of the epoch: mem (CPU python)=22192.5703125MB; mem (CPU total)=22000.5546875MB
INFO:root:[  121] Training loss: 0.61217367, Validation loss: 0.61868908, Gradient norm: 0.37042704
INFO:root:At the start of the epoch: mem (CPU python)=22230.6640625MB; mem (CPU total)=22038.9765625MB
INFO:root:[  122] Training loss: 0.61194157, Validation loss: 0.61911528, Gradient norm: 0.42955047
INFO:root:At the start of the epoch: mem (CPU python)=22268.76171875MB; mem (CPU total)=22077.0859375MB
INFO:root:[  123] Training loss: 0.61164756, Validation loss: 0.62007718, Gradient norm: 0.41596839
INFO:root:At the start of the epoch: mem (CPU python)=22306.85546875MB; mem (CPU total)=22115.171875MB
INFO:root:[  124] Training loss: 0.61187464, Validation loss: 0.62012419, Gradient norm: 0.45413066
INFO:root:At the start of the epoch: mem (CPU python)=22344.94921875MB; mem (CPU total)=22153.0546875MB
INFO:root:[  125] Training loss: 0.61175298, Validation loss: 0.61908976, Gradient norm: 0.48749528
INFO:root:At the start of the epoch: mem (CPU python)=22383.046875MB; mem (CPU total)=22190.94140625MB
INFO:root:[  126] Training loss: 0.61162826, Validation loss: 0.61905993, Gradient norm: 0.45063538
INFO:root:At the start of the epoch: mem (CPU python)=22421.140625MB; mem (CPU total)=22228.83984375MB
INFO:root:[  127] Training loss: 0.61134051, Validation loss: 0.61882874, Gradient norm: 0.45830008
INFO:root:At the start of the epoch: mem (CPU python)=22459.234375MB; mem (CPU total)=22266.95703125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  128] Training loss: 0.61126855, Validation loss: 0.61898391, Gradient norm: 0.50953857
INFO:root:At the start of the epoch: mem (CPU python)=22497.33203125MB; mem (CPU total)=22304.875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  129] Training loss: 0.61003304, Validation loss: 0.61781591, Gradient norm: 0.33501995
INFO:root:At the start of the epoch: mem (CPU python)=22535.4296875MB; mem (CPU total)=22343.3984375MB
INFO:root:[  130] Training loss: 0.60926598, Validation loss: 0.61794672, Gradient norm: 0.25266532
INFO:root:At the start of the epoch: mem (CPU python)=22573.5234375MB; mem (CPU total)=22381.71484375MB
INFO:root:[  131] Training loss: 0.60910684, Validation loss: 0.61779129, Gradient norm: 0.27698741
INFO:root:At the start of the epoch: mem (CPU python)=22611.6171875MB; mem (CPU total)=22419.86328125MB
INFO:root:[  132] Training loss: 0.60905062, Validation loss: 0.61845765, Gradient norm: 0.28011971
INFO:root:At the start of the epoch: mem (CPU python)=22649.71484375MB; mem (CPU total)=22458.2890625MB
INFO:root:[  133] Training loss: 0.60888608, Validation loss: 0.61756956, Gradient norm: 0.27794650
INFO:root:At the start of the epoch: mem (CPU python)=22687.80859375MB; mem (CPU total)=22496.453125MB
INFO:root:[  134] Training loss: 0.60892944, Validation loss: 0.61731253, Gradient norm: 0.30751058
INFO:root:At the start of the epoch: mem (CPU python)=22725.90234375MB; mem (CPU total)=22534.6484375MB
INFO:root:[  135] Training loss: 0.60896763, Validation loss: 0.61764102, Gradient norm: 0.25584691
INFO:root:At the start of the epoch: mem (CPU python)=22764.0MB; mem (CPU total)=22572.765625MB
INFO:root:[  136] Training loss: 0.60888604, Validation loss: 0.61735813, Gradient norm: 0.27056696
INFO:root:At the start of the epoch: mem (CPU python)=22802.09375MB; mem (CPU total)=22611.15234375MB
INFO:root:[  137] Training loss: 0.60876954, Validation loss: 0.61753052, Gradient norm: 0.32206832
INFO:root:At the start of the epoch: mem (CPU python)=22840.19140625MB; mem (CPU total)=22649.05859375MB
INFO:root:[  138] Training loss: 0.60874725, Validation loss: 0.61736879, Gradient norm: 0.27702238
INFO:root:At the start of the epoch: mem (CPU python)=22878.28515625MB; mem (CPU total)=22686.7109375MB
INFO:root:[  139] Training loss: 0.60862012, Validation loss: 0.61700685, Gradient norm: 0.27736372
INFO:root:At the start of the epoch: mem (CPU python)=22916.3828125MB; mem (CPU total)=22725.1015625MB
INFO:root:[  140] Training loss: 0.60858126, Validation loss: 0.61773813, Gradient norm: 0.30302233
INFO:root:At the start of the epoch: mem (CPU python)=22954.4765625MB; mem (CPU total)=22763.4609375MB
INFO:root:[  141] Training loss: 0.60841473, Validation loss: 0.61843050, Gradient norm: 0.30153550
INFO:root:At the start of the epoch: mem (CPU python)=22992.5703125MB; mem (CPU total)=22801.6015625MB
INFO:root:[  142] Training loss: 0.60842436, Validation loss: 0.61730873, Gradient norm: 0.33069334
INFO:root:At the start of the epoch: mem (CPU python)=23030.66796875MB; mem (CPU total)=22839.26171875MB
INFO:root:[  143] Training loss: 0.60822520, Validation loss: 0.61753480, Gradient norm: 0.28394417
INFO:root:At the start of the epoch: mem (CPU python)=23068.76171875MB; mem (CPU total)=22877.05078125MB
INFO:root:[  144] Training loss: 0.60840984, Validation loss: 0.61724500, Gradient norm: 0.28626970
INFO:root:At the start of the epoch: mem (CPU python)=23106.85546875MB; mem (CPU total)=22915.21484375MB
INFO:root:[  145] Training loss: 0.60839118, Validation loss: 0.61687790, Gradient norm: 0.32736038
INFO:root:At the start of the epoch: mem (CPU python)=23144.94921875MB; mem (CPU total)=22953.56640625MB
INFO:root:[  146] Training loss: 0.60826985, Validation loss: 0.61704058, Gradient norm: 0.31791654
INFO:root:At the start of the epoch: mem (CPU python)=23183.046875MB; mem (CPU total)=22991.69140625MB
INFO:root:[  147] Training loss: 0.60820031, Validation loss: 0.61791442, Gradient norm: 0.32987777
INFO:root:At the start of the epoch: mem (CPU python)=23221.14453125MB; mem (CPU total)=23029.82421875MB
INFO:root:[  148] Training loss: 0.60839271, Validation loss: 0.61713787, Gradient norm: 0.29584266
INFO:root:At the start of the epoch: mem (CPU python)=23259.23828125MB; mem (CPU total)=23068.21875MB
INFO:root:[  149] Training loss: 0.60800102, Validation loss: 0.61763333, Gradient norm: 0.34610843
INFO:root:At the start of the epoch: mem (CPU python)=23297.3359375MB; mem (CPU total)=23105.75MB
INFO:root:[  150] Training loss: 0.60832344, Validation loss: 0.61737023, Gradient norm: 0.28683593
INFO:root:At the start of the epoch: mem (CPU python)=23335.4296875MB; mem (CPU total)=23143.890625MB
INFO:root:[  151] Training loss: 0.60792972, Validation loss: 0.61673122, Gradient norm: 0.29180554
INFO:root:At the start of the epoch: mem (CPU python)=23373.5234375MB; mem (CPU total)=23182.5234375MB
INFO:root:[  152] Training loss: 0.60820880, Validation loss: 0.61684941, Gradient norm: 0.33823299
INFO:root:At the start of the epoch: mem (CPU python)=23411.62109375MB; mem (CPU total)=23220.734375MB
INFO:root:[  153] Training loss: 0.60810477, Validation loss: 0.61740786, Gradient norm: 0.34223065
INFO:root:At the start of the epoch: mem (CPU python)=23449.71484375MB; mem (CPU total)=23258.62109375MB
INFO:root:[  154] Training loss: 0.60791089, Validation loss: 0.61619394, Gradient norm: 0.34628165
INFO:root:At the start of the epoch: mem (CPU python)=23487.8125MB; mem (CPU total)=23297.4921875MB
INFO:root:[  155] Training loss: 0.60784673, Validation loss: 0.61805383, Gradient norm: 0.37106412
INFO:root:At the start of the epoch: mem (CPU python)=23525.90625MB; mem (CPU total)=23334.4140625MB
INFO:root:[  156] Training loss: 0.60787607, Validation loss: 0.61707421, Gradient norm: 0.33861478
INFO:root:At the start of the epoch: mem (CPU python)=23564.00390625MB; mem (CPU total)=23372.515625MB
INFO:root:[  157] Training loss: 0.60751817, Validation loss: 0.61622700, Gradient norm: 0.31103272
INFO:root:At the start of the epoch: mem (CPU python)=23602.09765625MB; mem (CPU total)=23410.87890625MB
INFO:root:[  158] Training loss: 0.60780625, Validation loss: 0.61595318, Gradient norm: 0.34575325
INFO:root:At the start of the epoch: mem (CPU python)=23640.19140625MB; mem (CPU total)=23448.78125MB
INFO:root:[  159] Training loss: 0.60739116, Validation loss: 0.61657437, Gradient norm: 0.34714189
INFO:root:At the start of the epoch: mem (CPU python)=23678.2890625MB; mem (CPU total)=23487.4296875MB
INFO:root:[  160] Training loss: 0.60780741, Validation loss: 0.61650004, Gradient norm: 0.33323698
INFO:root:At the start of the epoch: mem (CPU python)=23716.3828125MB; mem (CPU total)=23526.2578125MB
INFO:root:[  161] Training loss: 0.60756965, Validation loss: 0.61661537, Gradient norm: 0.34597987
INFO:root:At the start of the epoch: mem (CPU python)=23754.4765625MB; mem (CPU total)=23564.66015625MB
INFO:root:[  162] Training loss: 0.60757111, Validation loss: 0.61687207, Gradient norm: 0.35936908
INFO:root:At the start of the epoch: mem (CPU python)=23792.5703125MB; mem (CPU total)=23603.03125MB
INFO:root:[  163] Training loss: 0.60740368, Validation loss: 0.61739891, Gradient norm: 0.35434862
INFO:root:At the start of the epoch: mem (CPU python)=23830.671875MB; mem (CPU total)=23641.15625MB
INFO:root:[  164] Training loss: 0.60723647, Validation loss: 0.61746325, Gradient norm: 0.38039744
INFO:root:At the start of the epoch: mem (CPU python)=23868.765625MB; mem (CPU total)=23679.21875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  165] Training loss: 0.60737373, Validation loss: 0.61607009, Gradient norm: 0.33953589
INFO:root:At the start of the epoch: mem (CPU python)=23906.859375MB; mem (CPU total)=23717.109375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  166] Training loss: 0.60713692, Validation loss: 0.61571071, Gradient norm: 0.26760621
INFO:root:At the start of the epoch: mem (CPU python)=23944.95703125MB; mem (CPU total)=23754.97265625MB
INFO:root:[  167] Training loss: 0.60676677, Validation loss: 0.61595766, Gradient norm: 0.24262549
INFO:root:At the start of the epoch: mem (CPU python)=23983.05078125MB; mem (CPU total)=23793.34375MB
INFO:root:[  168] Training loss: 0.60698227, Validation loss: 0.61650042, Gradient norm: 0.24456577
INFO:root:At the start of the epoch: mem (CPU python)=24021.14453125MB; mem (CPU total)=23831.203125MB
INFO:root:[  169] Training loss: 0.60704836, Validation loss: 0.61638599, Gradient norm: 0.25188092
INFO:root:At the start of the epoch: mem (CPU python)=24059.2421875MB; mem (CPU total)=23869.5546875MB
INFO:root:[  170] Training loss: 0.60677405, Validation loss: 0.61683247, Gradient norm: 0.25291446
INFO:root:At the start of the epoch: mem (CPU python)=24097.34375MB; mem (CPU total)=23907.42578125MB
INFO:root:[  171] Training loss: 0.60691595, Validation loss: 0.61668091, Gradient norm: 0.24450657
INFO:root:At the start of the epoch: mem (CPU python)=24135.4375MB; mem (CPU total)=23945.52734375MB
INFO:root:[  172] Training loss: 0.60696787, Validation loss: 0.61588037, Gradient norm: 0.26583785
INFO:root:At the start of the epoch: mem (CPU python)=24173.53125MB; mem (CPU total)=23983.87109375MB
INFO:root:[  173] Training loss: 0.60670689, Validation loss: 0.61638685, Gradient norm: 0.25205882
INFO:root:At the start of the epoch: mem (CPU python)=24211.625MB; mem (CPU total)=24021.75MB
INFO:root:[  174] Training loss: 0.60695070, Validation loss: 0.61620535, Gradient norm: 0.24970343
INFO:root:At the start of the epoch: mem (CPU python)=24249.72265625MB; mem (CPU total)=24060.1171875MB
INFO:root:[  175] Training loss: 0.60682975, Validation loss: 0.61695316, Gradient norm: 0.24246339
INFO:root:At the start of the epoch: mem (CPU python)=24287.81640625MB; mem (CPU total)=24098.49609375MB
INFO:root:EP 175: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=24325.91015625MB; mem (CPU total)=24136.609375MB
INFO:root:Training the model took 9308.947s.
INFO:root:Emptying the cuda cache took 0.079s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86186
INFO:root:EnergyScoreTrain: 0.60694
INFO:root:CRPSTrain: 0.55451
INFO:root:Gaussian NLLTrain: 8.28507
INFO:root:CoverageTrain: 0.73505
INFO:root:IntervalWidthTrain: 3.02241
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87574
INFO:root:EnergyScoreValidation: 0.61662
INFO:root:CRPSValidation: 0.56196
INFO:root:Gaussian NLLValidation: 8.31261
INFO:root:CoverageValidation: 0.73134
INFO:root:IntervalWidthValidation: 3.02002
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87652
INFO:root:EnergyScoreTest: 0.61721
INFO:root:CRPSTest: 0.56243
INFO:root:Gaussian NLLTest: 8.25904
INFO:root:CoverageTest: 0.73024
INFO:root:IntervalWidthTest: 3.01333
INFO:root:After validation: mem (CPU python)=24368.71875MB; mem (CPU total)=24179.35546875MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=24368.71875MB; mem (CPU total)=24179.34375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=24369.22265625MB; mem (CPU total)=24179.8359375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=24369.22265625MB; mem (CPU total)=24179.828125MB
INFO:root:[    1] Training loss: 0.77699719, Validation loss: 0.72571590, Gradient norm: 0.83887445
INFO:root:At the start of the epoch: mem (CPU python)=24407.265625MB; mem (CPU total)=24218.16796875MB
INFO:root:[    2] Training loss: 0.72244789, Validation loss: 0.72191614, Gradient norm: 0.42219795
INFO:root:At the start of the epoch: mem (CPU python)=24445.359375MB; mem (CPU total)=24257.703125MB
INFO:root:[    3] Training loss: 0.72128137, Validation loss: 0.72084904, Gradient norm: 0.50999071
INFO:root:At the start of the epoch: mem (CPU python)=24483.47265625MB; mem (CPU total)=24296.09765625MB
INFO:root:[    4] Training loss: 0.72038435, Validation loss: 0.72094441, Gradient norm: 0.42811173
INFO:root:At the start of the epoch: mem (CPU python)=24521.58203125MB; mem (CPU total)=24334.4765625MB
INFO:root:[    5] Training loss: 0.72017247, Validation loss: 0.72023363, Gradient norm: 0.38140149
INFO:root:At the start of the epoch: mem (CPU python)=24559.6953125MB; mem (CPU total)=24372.640625MB
INFO:root:[    6] Training loss: 0.71958398, Validation loss: 0.72051898, Gradient norm: 0.29673109
INFO:root:At the start of the epoch: mem (CPU python)=24597.8046875MB; mem (CPU total)=24410.3125MB
INFO:root:[    7] Training loss: 0.71939948, Validation loss: 0.71963775, Gradient norm: 0.29279204
INFO:root:At the start of the epoch: mem (CPU python)=24635.8984375MB; mem (CPU total)=24448.41015625MB
INFO:root:[    8] Training loss: 0.71876911, Validation loss: 0.71816346, Gradient norm: 0.30365659
INFO:root:At the start of the epoch: mem (CPU python)=24673.99609375MB; mem (CPU total)=24486.5703125MB
INFO:root:[    9] Training loss: 0.71738509, Validation loss: 0.71646881, Gradient norm: 0.22892330
INFO:root:At the start of the epoch: mem (CPU python)=24712.09375MB; mem (CPU total)=24525.15234375MB
INFO:root:[   10] Training loss: 0.71363190, Validation loss: 0.71087754, Gradient norm: 0.20885130
INFO:root:At the start of the epoch: mem (CPU python)=24750.1875MB; mem (CPU total)=24563.26953125MB
INFO:root:[   11] Training loss: 0.70761877, Validation loss: 0.70497555, Gradient norm: 0.19573948
INFO:root:At the start of the epoch: mem (CPU python)=24788.28515625MB; mem (CPU total)=24601.41796875MB
INFO:root:[   12] Training loss: 0.70185395, Validation loss: 0.69904315, Gradient norm: 0.24975895
INFO:root:At the start of the epoch: mem (CPU python)=24826.37890625MB; mem (CPU total)=24639.28515625MB
INFO:root:[   13] Training loss: 0.69608484, Validation loss: 0.69490353, Gradient norm: 0.16571846
INFO:root:At the start of the epoch: mem (CPU python)=24864.47265625MB; mem (CPU total)=24677.64453125MB
INFO:root:[   14] Training loss: 0.69104389, Validation loss: 0.68903181, Gradient norm: 0.15880167
INFO:root:At the start of the epoch: mem (CPU python)=24902.56640625MB; mem (CPU total)=24716.01953125MB
INFO:root:[   15] Training loss: 0.68656458, Validation loss: 0.68570997, Gradient norm: 0.18084706
INFO:root:At the start of the epoch: mem (CPU python)=24940.6640625MB; mem (CPU total)=24754.12890625MB
INFO:root:[   16] Training loss: 0.68259978, Validation loss: 0.68132060, Gradient norm: 0.19646219
INFO:root:At the start of the epoch: mem (CPU python)=24978.7578125MB; mem (CPU total)=24792.2265625MB
INFO:root:[   17] Training loss: 0.67904287, Validation loss: 0.67839625, Gradient norm: 0.17313569
INFO:root:At the start of the epoch: mem (CPU python)=25016.85546875MB; mem (CPU total)=24830.6171875MB
INFO:root:[   18] Training loss: 0.67565577, Validation loss: 0.67506347, Gradient norm: 0.12365887
INFO:root:At the start of the epoch: mem (CPU python)=25054.95703125MB; mem (CPU total)=24868.75390625MB
INFO:root:[   19] Training loss: 0.67273545, Validation loss: 0.67242616, Gradient norm: 0.14334904
INFO:root:At the start of the epoch: mem (CPU python)=25093.05078125MB; mem (CPU total)=24906.6640625MB
INFO:root:[   20] Training loss: 0.67009675, Validation loss: 0.67021785, Gradient norm: 0.17290825
INFO:root:At the start of the epoch: mem (CPU python)=25131.14453125MB; mem (CPU total)=24945.03125MB
INFO:root:[   21] Training loss: 0.66747555, Validation loss: 0.66811800, Gradient norm: 0.13606475
INFO:root:At the start of the epoch: mem (CPU python)=25169.23828125MB; mem (CPU total)=24983.15234375MB
INFO:root:[   22] Training loss: 0.66547605, Validation loss: 0.66633862, Gradient norm: 0.14225630
INFO:root:At the start of the epoch: mem (CPU python)=25207.3359375MB; mem (CPU total)=25021.015625MB
INFO:root:[   23] Training loss: 0.66359650, Validation loss: 0.66337558, Gradient norm: 0.19126011
INFO:root:At the start of the epoch: mem (CPU python)=25245.4296875MB; mem (CPU total)=25059.1328125MB
INFO:root:[   24] Training loss: 0.66157288, Validation loss: 0.66195471, Gradient norm: 0.12946697
INFO:root:At the start of the epoch: mem (CPU python)=25283.5234375MB; mem (CPU total)=25097.234375MB
INFO:root:[   25] Training loss: 0.65969335, Validation loss: 0.66146675, Gradient norm: 0.12131681
INFO:root:At the start of the epoch: mem (CPU python)=25321.62109375MB; mem (CPU total)=25135.34375MB
INFO:root:[   26] Training loss: 0.65835452, Validation loss: 0.65892493, Gradient norm: 0.15468711
INFO:root:At the start of the epoch: mem (CPU python)=25359.71875MB; mem (CPU total)=25173.46875MB
INFO:root:[   27] Training loss: 0.65661259, Validation loss: 0.65810952, Gradient norm: 0.14021246
INFO:root:At the start of the epoch: mem (CPU python)=25397.8125MB; mem (CPU total)=25211.3203125MB
INFO:root:[   28] Training loss: 0.65537256, Validation loss: 0.65630272, Gradient norm: 0.14493617
INFO:root:At the start of the epoch: mem (CPU python)=25435.91015625MB; mem (CPU total)=25249.6796875MB
INFO:root:[   29] Training loss: 0.65407733, Validation loss: 0.65523334, Gradient norm: 0.15580620
INFO:root:At the start of the epoch: mem (CPU python)=25474.00390625MB; mem (CPU total)=25287.5625MB
INFO:root:[   30] Training loss: 0.65269992, Validation loss: 0.65434787, Gradient norm: 0.12425749
INFO:root:At the start of the epoch: mem (CPU python)=25512.09765625MB; mem (CPU total)=25325.94921875MB
INFO:root:[   31] Training loss: 0.65156969, Validation loss: 0.65253776, Gradient norm: 0.13027455
INFO:root:At the start of the epoch: mem (CPU python)=25550.19140625MB; mem (CPU total)=25364.07421875MB
INFO:root:[   32] Training loss: 0.65056046, Validation loss: 0.65153339, Gradient norm: 0.15926980
INFO:root:At the start of the epoch: mem (CPU python)=25588.29296875MB; mem (CPU total)=25402.1953125MB
INFO:root:[   33] Training loss: 0.64922476, Validation loss: 0.65123832, Gradient norm: 0.15001155
INFO:root:At the start of the epoch: mem (CPU python)=25626.390625MB; mem (CPU total)=25440.40625MB
INFO:root:[   34] Training loss: 0.64862978, Validation loss: 0.65026078, Gradient norm: 0.19077434
INFO:root:At the start of the epoch: mem (CPU python)=25664.484375MB; mem (CPU total)=25478.2890625MB
INFO:root:[   35] Training loss: 0.64754756, Validation loss: 0.64807634, Gradient norm: 0.15898826
INFO:root:At the start of the epoch: mem (CPU python)=25702.578125MB; mem (CPU total)=25516.6640625MB
INFO:root:[   36] Training loss: 0.64647220, Validation loss: 0.64808652, Gradient norm: 0.14144781
INFO:root:At the start of the epoch: mem (CPU python)=25740.67578125MB; mem (CPU total)=25554.7890625MB
INFO:root:[   37] Training loss: 0.64573806, Validation loss: 0.64805379, Gradient norm: 0.16762219
INFO:root:At the start of the epoch: mem (CPU python)=25778.76953125MB; mem (CPU total)=25593.37890625MB
INFO:root:[   38] Training loss: 0.64479846, Validation loss: 0.64665011, Gradient norm: 0.15463414
INFO:root:At the start of the epoch: mem (CPU python)=25816.86328125MB; mem (CPU total)=25631.74609375MB
INFO:root:[   39] Training loss: 0.64384668, Validation loss: 0.64542704, Gradient norm: 0.14188796
INFO:root:At the start of the epoch: mem (CPU python)=25854.9609375MB; mem (CPU total)=25669.62890625MB
INFO:root:[   40] Training loss: 0.64336093, Validation loss: 0.64565551, Gradient norm: 0.14031763
INFO:root:At the start of the epoch: mem (CPU python)=25893.0546875MB; mem (CPU total)=25707.99609375MB
INFO:root:[   41] Training loss: 0.64252966, Validation loss: 0.64561878, Gradient norm: 0.19277920
INFO:root:At the start of the epoch: mem (CPU python)=25931.15234375MB; mem (CPU total)=25746.09375MB
INFO:root:[   42] Training loss: 0.64195551, Validation loss: 0.64426498, Gradient norm: 0.17304839
INFO:root:At the start of the epoch: mem (CPU python)=25969.25MB; mem (CPU total)=25784.21484375MB
INFO:root:[   43] Training loss: 0.64114246, Validation loss: 0.64446804, Gradient norm: 0.14625034
INFO:root:At the start of the epoch: mem (CPU python)=26007.34375MB; mem (CPU total)=25822.58203125MB
INFO:root:[   44] Training loss: 0.64048225, Validation loss: 0.64350525, Gradient norm: 0.16108203
INFO:root:At the start of the epoch: mem (CPU python)=26045.4375MB; mem (CPU total)=25860.75390625MB
INFO:root:[   45] Training loss: 0.63978431, Validation loss: 0.64175737, Gradient norm: 0.19530813
INFO:root:At the start of the epoch: mem (CPU python)=26083.53515625MB; mem (CPU total)=25898.8671875MB
INFO:root:[   46] Training loss: 0.63929203, Validation loss: 0.64241451, Gradient norm: 0.15221608
INFO:root:At the start of the epoch: mem (CPU python)=26121.62890625MB; mem (CPU total)=25937.234375MB
INFO:root:[   47] Training loss: 0.63874590, Validation loss: 0.64297172, Gradient norm: 0.17380086
INFO:root:At the start of the epoch: mem (CPU python)=26159.72265625MB; mem (CPU total)=25975.375MB
INFO:root:[   48] Training loss: 0.63819391, Validation loss: 0.64122153, Gradient norm: 0.23687482
INFO:root:At the start of the epoch: mem (CPU python)=26197.81640625MB; mem (CPU total)=26013.2265625MB
INFO:root:[   49] Training loss: 0.63760359, Validation loss: 0.64013768, Gradient norm: 0.21883379
INFO:root:At the start of the epoch: mem (CPU python)=26235.9140625MB; mem (CPU total)=26051.57421875MB
INFO:root:[   50] Training loss: 0.63729623, Validation loss: 0.64006487, Gradient norm: 0.19880246
INFO:root:At the start of the epoch: mem (CPU python)=26274.015625MB; mem (CPU total)=26089.7421875MB
INFO:root:[   51] Training loss: 0.63646598, Validation loss: 0.63920674, Gradient norm: 0.21617093
INFO:root:At the start of the epoch: mem (CPU python)=26312.109375MB; mem (CPU total)=26127.88671875MB
INFO:root:[   52] Training loss: 0.63584359, Validation loss: 0.63962165, Gradient norm: 0.19936247
INFO:root:At the start of the epoch: mem (CPU python)=26350.20703125MB; mem (CPU total)=26166.27734375MB
INFO:root:[   53] Training loss: 0.63531718, Validation loss: 0.63893715, Gradient norm: 0.15980670
INFO:root:At the start of the epoch: mem (CPU python)=26388.30078125MB; mem (CPU total)=26204.64453125MB
INFO:root:[   54] Training loss: 0.63464350, Validation loss: 0.63919505, Gradient norm: 0.19464467
INFO:root:At the start of the epoch: mem (CPU python)=26426.39453125MB; mem (CPU total)=26242.75MB
INFO:root:[   55] Training loss: 0.63432545, Validation loss: 0.63847414, Gradient norm: 0.22189860
INFO:root:At the start of the epoch: mem (CPU python)=26464.48828125MB; mem (CPU total)=26280.87109375MB
INFO:root:[   56] Training loss: 0.63366527, Validation loss: 0.63820923, Gradient norm: 0.16458909
INFO:root:At the start of the epoch: mem (CPU python)=26502.5859375MB; mem (CPU total)=26319.25MB
INFO:root:[   57] Training loss: 0.63331912, Validation loss: 0.63759538, Gradient norm: 0.21017382
INFO:root:At the start of the epoch: mem (CPU python)=26540.6796875MB; mem (CPU total)=26357.59765625MB
INFO:root:[   58] Training loss: 0.63326916, Validation loss: 0.63609496, Gradient norm: 0.21151390
INFO:root:At the start of the epoch: mem (CPU python)=26578.77734375MB; mem (CPU total)=26395.6953125MB
INFO:root:[   59] Training loss: 0.63219347, Validation loss: 0.63616862, Gradient norm: 0.18879096
INFO:root:At the start of the epoch: mem (CPU python)=26616.875MB; mem (CPU total)=26433.28125MB
INFO:root:[   60] Training loss: 0.63206489, Validation loss: 0.63653452, Gradient norm: 0.23133749
INFO:root:At the start of the epoch: mem (CPU python)=26654.96875MB; mem (CPU total)=26471.671875MB
INFO:root:[   61] Training loss: 0.63170784, Validation loss: 0.63624340, Gradient norm: 0.20416669
INFO:root:At the start of the epoch: mem (CPU python)=26693.0625MB; mem (CPU total)=26509.796875MB
INFO:root:[   62] Training loss: 0.63125966, Validation loss: 0.63582004, Gradient norm: 0.24123758
INFO:root:At the start of the epoch: mem (CPU python)=26731.16015625MB; mem (CPU total)=26547.88671875MB
INFO:root:[   63] Training loss: 0.63066765, Validation loss: 0.63524357, Gradient norm: 0.22281024
INFO:root:At the start of the epoch: mem (CPU python)=26769.25390625MB; mem (CPU total)=26586.25390625MB
INFO:root:[   64] Training loss: 0.63030362, Validation loss: 0.63408024, Gradient norm: 0.22825369
INFO:root:At the start of the epoch: mem (CPU python)=26807.3515625MB; mem (CPU total)=26624.33984375MB
INFO:root:[   65] Training loss: 0.62951852, Validation loss: 0.63509417, Gradient norm: 0.27212412
INFO:root:At the start of the epoch: mem (CPU python)=26845.4453125MB; mem (CPU total)=26662.453125MB
INFO:root:[   66] Training loss: 0.62958994, Validation loss: 0.63376244, Gradient norm: 0.25042784
INFO:root:At the start of the epoch: mem (CPU python)=26883.54296875MB; mem (CPU total)=26700.86328125MB
INFO:root:[   67] Training loss: 0.62888568, Validation loss: 0.63378134, Gradient norm: 0.24145563
INFO:root:At the start of the epoch: mem (CPU python)=26921.63671875MB; mem (CPU total)=26739.0MB
INFO:root:[   68] Training loss: 0.62877343, Validation loss: 0.63352666, Gradient norm: 0.26356905
INFO:root:At the start of the epoch: mem (CPU python)=26959.73046875MB; mem (CPU total)=26777.3984375MB
INFO:root:[   69] Training loss: 0.62800493, Validation loss: 0.63228927, Gradient norm: 0.23749827
INFO:root:At the start of the epoch: mem (CPU python)=26997.828125MB; mem (CPU total)=26815.25MB
INFO:root:[   70] Training loss: 0.62783877, Validation loss: 0.63260820, Gradient norm: 0.27770739
INFO:root:At the start of the epoch: mem (CPU python)=27035.921875MB; mem (CPU total)=26853.80859375MB
INFO:root:[   71] Training loss: 0.62746821, Validation loss: 0.63330706, Gradient norm: 0.25772693
INFO:root:At the start of the epoch: mem (CPU python)=27074.015625MB; mem (CPU total)=26892.14453125MB
INFO:root:[   72] Training loss: 0.62712496, Validation loss: 0.63197167, Gradient norm: 0.26963915
INFO:root:At the start of the epoch: mem (CPU python)=27112.109375MB; mem (CPU total)=26930.26171875MB
INFO:root:[   73] Training loss: 0.62685410, Validation loss: 0.63293235, Gradient norm: 0.29801466
INFO:root:At the start of the epoch: mem (CPU python)=27150.20703125MB; mem (CPU total)=26968.3828125MB
INFO:root:[   74] Training loss: 0.62638741, Validation loss: 0.63210250, Gradient norm: 0.23919221
INFO:root:At the start of the epoch: mem (CPU python)=27188.3046875MB; mem (CPU total)=27006.75MB
INFO:root:[   75] Training loss: 0.62586730, Validation loss: 0.63227790, Gradient norm: 0.25658637
INFO:root:At the start of the epoch: mem (CPU python)=27226.3984375MB; mem (CPU total)=27044.87109375MB
INFO:root:[   76] Training loss: 0.62544104, Validation loss: 0.63054605, Gradient norm: 0.23433087
INFO:root:At the start of the epoch: mem (CPU python)=27264.49609375MB; mem (CPU total)=27083.03515625MB
INFO:root:[   77] Training loss: 0.62520478, Validation loss: 0.63131550, Gradient norm: 0.21590607
INFO:root:At the start of the epoch: mem (CPU python)=27302.58984375MB; mem (CPU total)=27122.84765625MB
INFO:root:[   78] Training loss: 0.62469087, Validation loss: 0.63057644, Gradient norm: 0.31111432
INFO:root:At the start of the epoch: mem (CPU python)=27340.68359375MB; mem (CPU total)=27160.97265625MB
INFO:root:[   79] Training loss: 0.62444195, Validation loss: 0.63038737, Gradient norm: 0.31390079
INFO:root:At the start of the epoch: mem (CPU python)=27378.78125MB; mem (CPU total)=27198.796875MB
INFO:root:[   80] Training loss: 0.62416998, Validation loss: 0.62985306, Gradient norm: 0.33866510
INFO:root:At the start of the epoch: mem (CPU python)=27416.875MB; mem (CPU total)=27237.1015625MB
INFO:root:[   81] Training loss: 0.62366697, Validation loss: 0.62988036, Gradient norm: 0.33042992
INFO:root:At the start of the epoch: mem (CPU python)=27454.96875MB; mem (CPU total)=27275.19921875MB
INFO:root:[   82] Training loss: 0.62375695, Validation loss: 0.62953689, Gradient norm: 0.25926592
INFO:root:At the start of the epoch: mem (CPU python)=27493.06640625MB; mem (CPU total)=27313.37109375MB
INFO:root:[   83] Training loss: 0.62333060, Validation loss: 0.62911258, Gradient norm: 0.29248398
INFO:root:At the start of the epoch: mem (CPU python)=27531.1640625MB; mem (CPU total)=27351.4609375MB
INFO:root:[   84] Training loss: 0.62273843, Validation loss: 0.62903979, Gradient norm: 0.27747865
INFO:root:At the start of the epoch: mem (CPU python)=27569.2578125MB; mem (CPU total)=27389.578125MB
INFO:root:[   85] Training loss: 0.62263343, Validation loss: 0.62930991, Gradient norm: 0.37089985
INFO:root:At the start of the epoch: mem (CPU python)=27607.3515625MB; mem (CPU total)=27428.078125MB
INFO:root:[   86] Training loss: 0.62282394, Validation loss: 0.62845951, Gradient norm: 0.33784688
INFO:root:At the start of the epoch: mem (CPU python)=27645.44921875MB; mem (CPU total)=27466.03515625MB
INFO:root:[   87] Training loss: 0.62228044, Validation loss: 0.62844332, Gradient norm: 0.29856058
INFO:root:At the start of the epoch: mem (CPU python)=27683.54296875MB; mem (CPU total)=27504.1484375MB
INFO:root:[   88] Training loss: 0.62208353, Validation loss: 0.62879219, Gradient norm: 0.36059644
INFO:root:At the start of the epoch: mem (CPU python)=27721.63671875MB; mem (CPU total)=27542.50390625MB
INFO:root:[   89] Training loss: 0.62142323, Validation loss: 0.62771527, Gradient norm: 0.36619185
INFO:root:At the start of the epoch: mem (CPU python)=27759.73046875MB; mem (CPU total)=27580.11328125MB
INFO:root:[   90] Training loss: 0.62131911, Validation loss: 0.62820720, Gradient norm: 0.33290291
INFO:root:At the start of the epoch: mem (CPU python)=27797.828125MB; mem (CPU total)=27622.16796875MB
INFO:root:[   91] Training loss: 0.62098785, Validation loss: 0.62751007, Gradient norm: 0.36090472
INFO:root:At the start of the epoch: mem (CPU python)=27835.92578125MB; mem (CPU total)=27659.50390625MB
INFO:root:[   92] Training loss: 0.62062695, Validation loss: 0.62724672, Gradient norm: 0.38014245
INFO:root:At the start of the epoch: mem (CPU python)=27874.01953125MB; mem (CPU total)=27697.35546875MB
INFO:root:[   93] Training loss: 0.62073865, Validation loss: 0.62779136, Gradient norm: 0.39393224
INFO:root:At the start of the epoch: mem (CPU python)=27912.1171875MB; mem (CPU total)=27735.49609375MB
INFO:root:[   94] Training loss: 0.62045147, Validation loss: 0.62633903, Gradient norm: 0.45836256
INFO:root:At the start of the epoch: mem (CPU python)=27950.21484375MB; mem (CPU total)=27773.296875MB
INFO:root:[   95] Training loss: 0.62005979, Validation loss: 0.62755619, Gradient norm: 0.41277692
INFO:root:At the start of the epoch: mem (CPU python)=27988.30859375MB; mem (CPU total)=27810.91015625MB
INFO:root:[   96] Training loss: 0.61979646, Validation loss: 0.62664017, Gradient norm: 0.35578962
INFO:root:At the start of the epoch: mem (CPU python)=28026.40625MB; mem (CPU total)=27848.77734375MB
INFO:root:[   97] Training loss: 0.61938594, Validation loss: 0.62601984, Gradient norm: 0.37849900
INFO:root:At the start of the epoch: mem (CPU python)=28064.5MB; mem (CPU total)=27887.359375MB
INFO:root:[   98] Training loss: 0.61907120, Validation loss: 0.62534964, Gradient norm: 0.40476561
INFO:root:At the start of the epoch: mem (CPU python)=28102.59765625MB; mem (CPU total)=27925.48828125MB
INFO:root:[   99] Training loss: 0.61892997, Validation loss: 0.62564538, Gradient norm: 0.59289721
INFO:root:At the start of the epoch: mem (CPU python)=28140.69140625MB; mem (CPU total)=27963.59765625MB
INFO:root:[  100] Training loss: 0.61847872, Validation loss: 0.62537939, Gradient norm: 0.35638722
INFO:root:At the start of the epoch: mem (CPU python)=28178.7890625MB; mem (CPU total)=28001.9921875MB
INFO:root:[  101] Training loss: 0.61850017, Validation loss: 0.62512346, Gradient norm: 0.35353176
INFO:root:At the start of the epoch: mem (CPU python)=28216.8828125MB; mem (CPU total)=28039.984375MB
INFO:root:[  102] Training loss: 0.61825019, Validation loss: 0.62613332, Gradient norm: 0.48508359
INFO:root:At the start of the epoch: mem (CPU python)=28254.9765625MB; mem (CPU total)=28078.0859375MB
INFO:root:[  103] Training loss: 0.61836370, Validation loss: 0.62566651, Gradient norm: 0.51419883
INFO:root:At the start of the epoch: mem (CPU python)=28293.07421875MB; mem (CPU total)=28116.4765625MB
INFO:root:[  104] Training loss: 0.61761876, Validation loss: 0.62520877, Gradient norm: 0.34027273
INFO:root:At the start of the epoch: mem (CPU python)=28331.16796875MB; mem (CPU total)=28154.3359375MB
INFO:root:[  105] Training loss: 0.61722311, Validation loss: 0.62493566, Gradient norm: 0.38573420
INFO:root:At the start of the epoch: mem (CPU python)=28369.26171875MB; mem (CPU total)=28192.46875MB
INFO:root:[  106] Training loss: 0.61704691, Validation loss: 0.62509706, Gradient norm: 0.42573931
INFO:root:At the start of the epoch: mem (CPU python)=28407.35546875MB; mem (CPU total)=28230.85546875MB
INFO:root:[  107] Training loss: 0.61667542, Validation loss: 0.62378982, Gradient norm: 0.41321561
INFO:root:At the start of the epoch: mem (CPU python)=28445.45703125MB; mem (CPU total)=28268.95703125MB
INFO:root:[  108] Training loss: 0.61671434, Validation loss: 0.62495227, Gradient norm: 0.50156699
INFO:root:At the start of the epoch: mem (CPU python)=28483.55078125MB; mem (CPU total)=28307.3203125MB
INFO:root:[  109] Training loss: 0.61639469, Validation loss: 0.62460190, Gradient norm: 0.45536762
INFO:root:At the start of the epoch: mem (CPU python)=28521.64453125MB; mem (CPU total)=28345.19140625MB
INFO:root:[  110] Training loss: 0.61622239, Validation loss: 0.62369377, Gradient norm: 0.48223719
INFO:root:At the start of the epoch: mem (CPU python)=28559.7421875MB; mem (CPU total)=28383.59375MB
INFO:root:[  111] Training loss: 0.61660414, Validation loss: 0.62389758, Gradient norm: 0.95257298
INFO:root:At the start of the epoch: mem (CPU python)=28597.8359375MB; mem (CPU total)=28421.953125MB
INFO:root:[  112] Training loss: 0.61602543, Validation loss: 0.62391008, Gradient norm: 0.56148269
INFO:root:At the start of the epoch: mem (CPU python)=28635.9296875MB; mem (CPU total)=28460.01171875MB
INFO:root:[  113] Training loss: 0.61572163, Validation loss: 0.62244036, Gradient norm: 0.40482875
INFO:root:At the start of the epoch: mem (CPU python)=28674.02734375MB; mem (CPU total)=28498.16796875MB
INFO:root:[  114] Training loss: 0.61548846, Validation loss: 0.62496600, Gradient norm: 0.50962902
INFO:root:At the start of the epoch: mem (CPU python)=28712.12109375MB; mem (CPU total)=28536.53515625MB
INFO:root:[  115] Training loss: 0.61516410, Validation loss: 0.62431311, Gradient norm: 0.49591682
INFO:root:At the start of the epoch: mem (CPU python)=28750.21484375MB; mem (CPU total)=28574.609375MB
INFO:root:[  116] Training loss: 0.61476877, Validation loss: 0.62288323, Gradient norm: 0.44457139
INFO:root:At the start of the epoch: mem (CPU python)=28788.3125MB; mem (CPU total)=28612.72265625MB
INFO:root:[  117] Training loss: 0.61494330, Validation loss: 0.62273971, Gradient norm: 0.54655511
INFO:root:At the start of the epoch: mem (CPU python)=28826.41015625MB; mem (CPU total)=28651.06640625MB
INFO:root:[  118] Training loss: 0.61494283, Validation loss: 0.62328725, Gradient norm: 0.60924491
INFO:root:At the start of the epoch: mem (CPU python)=28864.50390625MB; mem (CPU total)=28689.359375MB
INFO:root:[  119] Training loss: 0.61454697, Validation loss: 0.62336524, Gradient norm: 0.91622714
INFO:root:At the start of the epoch: mem (CPU python)=28902.67578125MB; mem (CPU total)=28727.45703125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  120] Training loss: 0.61410860, Validation loss: 0.62232359, Gradient norm: 0.53108406
INFO:root:At the start of the epoch: mem (CPU python)=28940.7734375MB; mem (CPU total)=28764.94140625MB
INFO:root:[  121] Training loss: 0.61320679, Validation loss: 0.62176346, Gradient norm: 0.32199292
INFO:root:At the start of the epoch: mem (CPU python)=28978.8671875MB; mem (CPU total)=28803.078125MB
INFO:root:[  122] Training loss: 0.61312950, Validation loss: 0.62119522, Gradient norm: 0.38688993
INFO:root:At the start of the epoch: mem (CPU python)=29016.9609375MB; mem (CPU total)=28841.19921875MB
INFO:root:[  123] Training loss: 0.61264353, Validation loss: 0.62122361, Gradient norm: 0.39295940
INFO:root:At the start of the epoch: mem (CPU python)=29055.0546875MB; mem (CPU total)=28879.546875MB
INFO:root:[  124] Training loss: 0.61218281, Validation loss: 0.62158851, Gradient norm: 0.30674060
INFO:root:At the start of the epoch: mem (CPU python)=29093.15625MB; mem (CPU total)=28917.44921875MB
INFO:root:[  125] Training loss: 0.61218529, Validation loss: 0.62175154, Gradient norm: 0.37313823
INFO:root:At the start of the epoch: mem (CPU python)=29131.25MB; mem (CPU total)=28958.296875MB
INFO:root:[  126] Training loss: 0.61264989, Validation loss: 0.62142023, Gradient norm: 0.44395077
INFO:root:At the start of the epoch: mem (CPU python)=29169.34375MB; mem (CPU total)=28996.14453125MB
INFO:root:[  127] Training loss: 0.61218475, Validation loss: 0.62113945, Gradient norm: 0.36505635
INFO:root:At the start of the epoch: mem (CPU python)=29207.44140625MB; mem (CPU total)=29033.78125MB
INFO:root:[  128] Training loss: 0.61229439, Validation loss: 0.62128816, Gradient norm: 0.46766716
INFO:root:At the start of the epoch: mem (CPU python)=29245.53515625MB; mem (CPU total)=29072.6640625MB
INFO:root:[  129] Training loss: 0.61229362, Validation loss: 0.62058586, Gradient norm: 0.46069385
INFO:root:At the start of the epoch: mem (CPU python)=29283.62890625MB; mem (CPU total)=29110.44140625MB
INFO:root:[  130] Training loss: 0.61213490, Validation loss: 0.62084188, Gradient norm: 0.45358942
INFO:root:At the start of the epoch: mem (CPU python)=29321.7265625MB; mem (CPU total)=29147.62890625MB
INFO:root:[  131] Training loss: 0.61178864, Validation loss: 0.62044965, Gradient norm: 0.49293236
INFO:root:At the start of the epoch: mem (CPU python)=29359.8203125MB; mem (CPU total)=29185.5078125MB
INFO:root:[  132] Training loss: 0.61193922, Validation loss: 0.62075188, Gradient norm: 0.43973597
INFO:root:At the start of the epoch: mem (CPU python)=29397.9140625MB; mem (CPU total)=29223.8828125MB
INFO:root:[  133] Training loss: 0.61173831, Validation loss: 0.62013579, Gradient norm: 0.38662728
INFO:root:At the start of the epoch: mem (CPU python)=29436.01171875MB; mem (CPU total)=29262.03125MB
INFO:root:[  134] Training loss: 0.61159455, Validation loss: 0.62136803, Gradient norm: 0.46877609
INFO:root:At the start of the epoch: mem (CPU python)=29474.109375MB; mem (CPU total)=29300.37890625MB
INFO:root:[  135] Training loss: 0.61134269, Validation loss: 0.62108498, Gradient norm: 0.42818585
INFO:root:At the start of the epoch: mem (CPU python)=29512.20703125MB; mem (CPU total)=29338.76953125MB
INFO:root:[  136] Training loss: 0.61126701, Validation loss: 0.62054778, Gradient norm: 0.43271922
INFO:root:At the start of the epoch: mem (CPU python)=29550.30078125MB; mem (CPU total)=29376.87890625MB
INFO:root:[  137] Training loss: 0.61122524, Validation loss: 0.62125689, Gradient norm: 0.46419029
INFO:root:At the start of the epoch: mem (CPU python)=29588.3984375MB; mem (CPU total)=29415.0078125MB
INFO:root:[  138] Training loss: 0.61112014, Validation loss: 0.62106150, Gradient norm: 0.45737130
INFO:root:At the start of the epoch: mem (CPU python)=29626.4921875MB; mem (CPU total)=29453.0859375MB
INFO:root:[  139] Training loss: 0.61105017, Validation loss: 0.62081275, Gradient norm: 0.60790419
INFO:root:At the start of the epoch: mem (CPU python)=29664.58984375MB; mem (CPU total)=29490.96484375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  140] Training loss: 0.61093133, Validation loss: 0.62050800, Gradient norm: 0.52418443
INFO:root:At the start of the epoch: mem (CPU python)=29702.68359375MB; mem (CPU total)=29529.16015625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  141] Training loss: 0.61012792, Validation loss: 0.62118275, Gradient norm: 0.31392379
INFO:root:At the start of the epoch: mem (CPU python)=29740.78125MB; mem (CPU total)=29567.31640625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  142] Training loss: 0.60985150, Validation loss: 0.61937874, Gradient norm: 0.26582222
INFO:root:At the start of the epoch: mem (CPU python)=29778.875MB; mem (CPU total)=29605.28515625MB
INFO:root:[  143] Training loss: 0.60983808, Validation loss: 0.61957954, Gradient norm: 0.23564148
INFO:root:At the start of the epoch: mem (CPU python)=29816.96875MB; mem (CPU total)=29643.421875MB
INFO:root:[  144] Training loss: 0.60987459, Validation loss: 0.61991452, Gradient norm: 0.24093305
INFO:root:At the start of the epoch: mem (CPU python)=29855.06640625MB; mem (CPU total)=29681.56640625MB
INFO:root:[  145] Training loss: 0.60999878, Validation loss: 0.61971929, Gradient norm: 0.24965282
INFO:root:At the start of the epoch: mem (CPU python)=29893.1640625MB; mem (CPU total)=29719.953125MB
INFO:root:[  146] Training loss: 0.60971824, Validation loss: 0.62048611, Gradient norm: 0.24653479
INFO:root:At the start of the epoch: mem (CPU python)=29931.2578125MB; mem (CPU total)=29758.07421875MB
INFO:root:[  147] Training loss: 0.60964075, Validation loss: 0.61997893, Gradient norm: 0.24003046
INFO:root:At the start of the epoch: mem (CPU python)=29969.35546875MB; mem (CPU total)=29796.16796875MB
INFO:root:[  148] Training loss: 0.60994448, Validation loss: 0.61953517, Gradient norm: 0.23241957
INFO:root:At the start of the epoch: mem (CPU python)=30007.4453125MB; mem (CPU total)=29834.3125MB
INFO:root:[  149] Training loss: 0.60940417, Validation loss: 0.61987546, Gradient norm: 0.24316210
INFO:root:At the start of the epoch: mem (CPU python)=30045.546875MB; mem (CPU total)=29872.1953125MB
INFO:root:[  150] Training loss: 0.60948209, Validation loss: 0.62006106, Gradient norm: 0.26539327
INFO:root:At the start of the epoch: mem (CPU python)=30083.640625MB; mem (CPU total)=29910.88671875MB
INFO:root:[  151] Training loss: 0.60965684, Validation loss: 0.61973544, Gradient norm: 0.25391712
INFO:root:At the start of the epoch: mem (CPU python)=30121.73828125MB; mem (CPU total)=29948.890625MB
INFO:root:EP 151: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=30159.71484375MB; mem (CPU total)=29986.78515625MB
INFO:root:Training the model took 8881.134s.
INFO:root:Emptying the cuda cache took 0.078s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86562
INFO:root:EnergyScoreTrain: 0.60982
INFO:root:CRPSTrain: 0.55325
INFO:root:Gaussian NLLTrain: 6.18138
INFO:root:CoverageTrain: 0.751
INFO:root:IntervalWidthTrain: 3.0949
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88
INFO:root:EnergyScoreValidation: 0.61982
INFO:root:CRPSValidation: 0.56115
INFO:root:Gaussian NLLValidation: 6.23802
INFO:root:CoverageValidation: 0.74653
INFO:root:IntervalWidthValidation: 3.08997
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88109
INFO:root:EnergyScoreTest: 0.62063
INFO:root:CRPSTest: 0.56175
INFO:root:Gaussian NLLTest: 6.21656
INFO:root:CoverageTest: 0.74627
INFO:root:IntervalWidthTest: 3.08967
INFO:root:After validation: mem (CPU python)=30202.8046875MB; mem (CPU total)=30030.03515625MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=30202.8046875MB; mem (CPU total)=30030.03125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 58720256
INFO:root:After setting up the model: mem (CPU python)=30203.09375MB; mem (CPU total)=30030.5234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=30203.2265625MB; mem (CPU total)=30030.53125MB
INFO:root:[    1] Training loss: 0.78058004, Validation loss: 0.72966790, Gradient norm: 0.58793985
INFO:root:At the start of the epoch: mem (CPU python)=30241.26171875MB; mem (CPU total)=30069.10546875MB
INFO:root:[    2] Training loss: 0.72423991, Validation loss: 0.72156029, Gradient norm: 0.52362906
INFO:root:At the start of the epoch: mem (CPU python)=30279.37109375MB; mem (CPU total)=30107.05859375MB
INFO:root:[    3] Training loss: 0.72134236, Validation loss: 0.72031843, Gradient norm: 0.48370337
INFO:root:At the start of the epoch: mem (CPU python)=30317.484375MB; mem (CPU total)=30145.5MB
INFO:root:[    4] Training loss: 0.72049993, Validation loss: 0.72027150, Gradient norm: 0.32976213
INFO:root:At the start of the epoch: mem (CPU python)=30355.5859375MB; mem (CPU total)=30183.42578125MB
INFO:root:[    5] Training loss: 0.72020782, Validation loss: 0.71995546, Gradient norm: 0.31371500
INFO:root:At the start of the epoch: mem (CPU python)=30393.6796875MB; mem (CPU total)=30221.33984375MB
INFO:root:[    6] Training loss: 0.71976741, Validation loss: 0.72004873, Gradient norm: 0.30531414
INFO:root:At the start of the epoch: mem (CPU python)=30431.78125MB; mem (CPU total)=30259.76171875MB
INFO:root:[    7] Training loss: 0.71940498, Validation loss: 0.71972916, Gradient norm: 0.23483936
INFO:root:At the start of the epoch: mem (CPU python)=30469.875MB; mem (CPU total)=30298.12890625MB
INFO:root:[    8] Training loss: 0.71922640, Validation loss: 0.71986943, Gradient norm: 0.33573310
INFO:root:At the start of the epoch: mem (CPU python)=30507.96875MB; mem (CPU total)=30336.01953125MB
INFO:root:[    9] Training loss: 0.71877491, Validation loss: 0.71883429, Gradient norm: 0.24913943
INFO:root:At the start of the epoch: mem (CPU python)=30546.0625MB; mem (CPU total)=30374.4140625MB
INFO:root:[   10] Training loss: 0.71822910, Validation loss: 0.71891754, Gradient norm: 0.18441052
INFO:root:At the start of the epoch: mem (CPU python)=30584.16015625MB; mem (CPU total)=30412.55859375MB
INFO:root:[   11] Training loss: 0.71730155, Validation loss: 0.71653554, Gradient norm: 0.24807261
INFO:root:At the start of the epoch: mem (CPU python)=30622.25390625MB; mem (CPU total)=30450.7109375MB
INFO:root:[   12] Training loss: 0.71197631, Validation loss: 0.70769914, Gradient norm: 0.19482081
INFO:root:At the start of the epoch: mem (CPU python)=30660.34765625MB; mem (CPU total)=30489.09375MB
INFO:root:[   13] Training loss: 0.70296875, Validation loss: 0.69969661, Gradient norm: 0.18217737
INFO:root:At the start of the epoch: mem (CPU python)=30698.4453125MB; mem (CPU total)=30527.0MB
INFO:root:[   14] Training loss: 0.69565247, Validation loss: 0.69276453, Gradient norm: 0.15051886
INFO:root:At the start of the epoch: mem (CPU python)=30736.54296875MB; mem (CPU total)=30565.7734375MB
INFO:root:[   15] Training loss: 0.68990418, Validation loss: 0.68767653, Gradient norm: 0.12963006
INFO:root:At the start of the epoch: mem (CPU python)=30774.63671875MB; mem (CPU total)=30603.35546875MB
INFO:root:[   16] Training loss: 0.68505664, Validation loss: 0.68430971, Gradient norm: 0.16288435
INFO:root:At the start of the epoch: mem (CPU python)=30812.734375MB; mem (CPU total)=30641.23046875MB
INFO:root:[   17] Training loss: 0.68106147, Validation loss: 0.68087773, Gradient norm: 0.14035979
INFO:root:At the start of the epoch: mem (CPU python)=30850.83203125MB; mem (CPU total)=30679.59765625MB
INFO:root:[   18] Training loss: 0.67779620, Validation loss: 0.67717234, Gradient norm: 0.14946160
INFO:root:At the start of the epoch: mem (CPU python)=30888.92578125MB; mem (CPU total)=30718.00390625MB
INFO:root:[   19] Training loss: 0.67471889, Validation loss: 0.67417490, Gradient norm: 0.12512719
INFO:root:At the start of the epoch: mem (CPU python)=30927.01953125MB; mem (CPU total)=30756.0859375MB
INFO:root:[   20] Training loss: 0.67208774, Validation loss: 0.67120110, Gradient norm: 0.14403838
INFO:root:At the start of the epoch: mem (CPU python)=30965.1171875MB; mem (CPU total)=30794.2734375MB
INFO:root:[   21] Training loss: 0.66967730, Validation loss: 0.66956464, Gradient norm: 0.16016628
INFO:root:At the start of the epoch: mem (CPU python)=31003.2109375MB; mem (CPU total)=30832.6796875MB
INFO:root:[   22] Training loss: 0.66714082, Validation loss: 0.66748299, Gradient norm: 0.15374283
INFO:root:At the start of the epoch: mem (CPU python)=31041.30859375MB; mem (CPU total)=30870.84765625MB
INFO:root:[   23] Training loss: 0.66525036, Validation loss: 0.66577036, Gradient norm: 0.12495515
INFO:root:At the start of the epoch: mem (CPU python)=31079.41015625MB; mem (CPU total)=30908.97265625MB
INFO:root:[   24] Training loss: 0.66298799, Validation loss: 0.66389227, Gradient norm: 0.18546280
INFO:root:At the start of the epoch: mem (CPU python)=31117.50390625MB; mem (CPU total)=30946.84765625MB
INFO:root:[   25] Training loss: 0.66127060, Validation loss: 0.66235866, Gradient norm: 0.15736703
INFO:root:At the start of the epoch: mem (CPU python)=31155.59765625MB; mem (CPU total)=30985.234375MB
INFO:root:[   26] Training loss: 0.65963805, Validation loss: 0.66041736, Gradient norm: 0.13748311
INFO:root:At the start of the epoch: mem (CPU python)=31193.69140625MB; mem (CPU total)=31023.125MB
INFO:root:[   27] Training loss: 0.65785252, Validation loss: 0.65764334, Gradient norm: 0.12882861
INFO:root:At the start of the epoch: mem (CPU python)=31231.7890625MB; mem (CPU total)=31061.4765625MB
INFO:root:[   28] Training loss: 0.65670291, Validation loss: 0.65678911, Gradient norm: 0.15355474
INFO:root:At the start of the epoch: mem (CPU python)=31269.8828125MB; mem (CPU total)=31099.19140625MB
INFO:root:[   29] Training loss: 0.65514587, Validation loss: 0.65576637, Gradient norm: 0.17049088
INFO:root:At the start of the epoch: mem (CPU python)=31307.9765625MB; mem (CPU total)=31137.671875MB
INFO:root:[   30] Training loss: 0.65375987, Validation loss: 0.65537586, Gradient norm: 0.14361467
INFO:root:At the start of the epoch: mem (CPU python)=31346.07421875MB; mem (CPU total)=31175.72265625MB
INFO:root:[   31] Training loss: 0.65254573, Validation loss: 0.65422544, Gradient norm: 0.14734280
INFO:root:At the start of the epoch: mem (CPU python)=31384.171875MB; mem (CPU total)=31214.09765625MB
INFO:root:[   32] Training loss: 0.65139453, Validation loss: 0.65395275, Gradient norm: 0.16332834
INFO:root:At the start of the epoch: mem (CPU python)=31422.265625MB; mem (CPU total)=31251.73828125MB
INFO:root:[   33] Training loss: 0.65023232, Validation loss: 0.65216713, Gradient norm: 0.12774026
INFO:root:At the start of the epoch: mem (CPU python)=31460.36328125MB; mem (CPU total)=31290.0859375MB
INFO:root:[   34] Training loss: 0.64941178, Validation loss: 0.65089442, Gradient norm: 0.22060917
INFO:root:At the start of the epoch: mem (CPU python)=31498.453125MB; mem (CPU total)=31328.73046875MB
INFO:root:[   35] Training loss: 0.64814214, Validation loss: 0.64972845, Gradient norm: 0.16237829
INFO:root:At the start of the epoch: mem (CPU python)=31536.55078125MB; mem (CPU total)=31366.578125MB
INFO:root:[   36] Training loss: 0.64734073, Validation loss: 0.64930215, Gradient norm: 0.14703801
INFO:root:At the start of the epoch: mem (CPU python)=31574.64453125MB; mem (CPU total)=31404.74609375MB
INFO:root:[   37] Training loss: 0.64630937, Validation loss: 0.64851991, Gradient norm: 0.16606889
INFO:root:At the start of the epoch: mem (CPU python)=31612.7421875MB; mem (CPU total)=31442.88671875MB
INFO:root:[   38] Training loss: 0.64526897, Validation loss: 0.64710730, Gradient norm: 0.16585496
INFO:root:At the start of the epoch: mem (CPU python)=31650.83984375MB; mem (CPU total)=31481.27734375MB
INFO:root:[   39] Training loss: 0.64439757, Validation loss: 0.64658677, Gradient norm: 0.14511308
INFO:root:At the start of the epoch: mem (CPU python)=31688.93359375MB; mem (CPU total)=31519.3984375MB
INFO:root:[   40] Training loss: 0.64341702, Validation loss: 0.64564306, Gradient norm: 0.14624866
INFO:root:At the start of the epoch: mem (CPU python)=31727.03125MB; mem (CPU total)=31557.26953125MB
INFO:root:[   41] Training loss: 0.64245067, Validation loss: 0.64491754, Gradient norm: 0.12967208
INFO:root:At the start of the epoch: mem (CPU python)=31765.125MB; mem (CPU total)=31595.65625MB
INFO:root:[   42] Training loss: 0.64137472, Validation loss: 0.64388967, Gradient norm: 0.14438156
INFO:root:At the start of the epoch: mem (CPU python)=31803.21875MB; mem (CPU total)=31633.80078125MB
INFO:root:[   43] Training loss: 0.64077493, Validation loss: 0.64282757, Gradient norm: 0.15620708
INFO:root:At the start of the epoch: mem (CPU python)=31841.3125MB; mem (CPU total)=31672.12109375MB
INFO:root:[   44] Training loss: 0.64005494, Validation loss: 0.64334049, Gradient norm: 0.14158180
INFO:root:At the start of the epoch: mem (CPU python)=31879.41015625MB; mem (CPU total)=31710.2421875MB
INFO:root:[   45] Training loss: 0.63959139, Validation loss: 0.64250747, Gradient norm: 0.17682307
INFO:root:At the start of the epoch: mem (CPU python)=31917.50390625MB; mem (CPU total)=31748.484375MB
INFO:root:[   46] Training loss: 0.63872046, Validation loss: 0.64084570, Gradient norm: 0.19403450
INFO:root:At the start of the epoch: mem (CPU python)=31955.6015625MB; mem (CPU total)=31786.6484375MB
INFO:root:[   47] Training loss: 0.63806942, Validation loss: 0.64086217, Gradient norm: 0.15873432
INFO:root:At the start of the epoch: mem (CPU python)=31993.69921875MB; mem (CPU total)=31824.56640625MB
INFO:root:[   48] Training loss: 0.63725516, Validation loss: 0.64000689, Gradient norm: 0.17757369
INFO:root:At the start of the epoch: mem (CPU python)=32031.79296875MB; mem (CPU total)=31862.62109375MB
INFO:root:[   49] Training loss: 0.63669845, Validation loss: 0.63880286, Gradient norm: 0.16196481
INFO:root:At the start of the epoch: mem (CPU python)=32069.88671875MB; mem (CPU total)=31900.5078125MB
INFO:root:[   50] Training loss: 0.63601190, Validation loss: 0.63929800, Gradient norm: 0.18593091
INFO:root:At the start of the epoch: mem (CPU python)=32107.984375MB; mem (CPU total)=31938.59765625MB
INFO:root:[   51] Training loss: 0.63536854, Validation loss: 0.63823805, Gradient norm: 0.15449779
INFO:root:At the start of the epoch: mem (CPU python)=32146.078125MB; mem (CPU total)=31976.46875MB
INFO:root:[   52] Training loss: 0.63474425, Validation loss: 0.63800428, Gradient norm: 0.17331021
INFO:root:At the start of the epoch: mem (CPU python)=32184.171875MB; mem (CPU total)=32014.83984375MB
INFO:root:[   53] Training loss: 0.63386737, Validation loss: 0.63757136, Gradient norm: 0.21490009
INFO:root:At the start of the epoch: mem (CPU python)=32222.265625MB; mem (CPU total)=32053.2734375MB
INFO:root:[   54] Training loss: 0.63346648, Validation loss: 0.63724887, Gradient norm: 0.14834314
INFO:root:At the start of the epoch: mem (CPU python)=32260.36328125MB; mem (CPU total)=32091.4453125MB
INFO:root:[   55] Training loss: 0.63267300, Validation loss: 0.63591341, Gradient norm: 0.16984408
INFO:root:At the start of the epoch: mem (CPU python)=32298.45703125MB; mem (CPU total)=32129.34375MB
INFO:root:[   56] Training loss: 0.63243629, Validation loss: 0.63547310, Gradient norm: 0.15808093
INFO:root:At the start of the epoch: mem (CPU python)=32336.5546875MB; mem (CPU total)=32167.47265625MB
INFO:root:[   57] Training loss: 0.63210300, Validation loss: 0.63508785, Gradient norm: 0.22005351
INFO:root:At the start of the epoch: mem (CPU python)=32374.65234375MB; mem (CPU total)=32205.52734375MB
INFO:root:[   58] Training loss: 0.63117601, Validation loss: 0.63514494, Gradient norm: 0.18422461
INFO:root:At the start of the epoch: mem (CPU python)=32412.74609375MB; mem (CPU total)=32244.12109375MB
INFO:root:[   59] Training loss: 0.63036883, Validation loss: 0.63507459, Gradient norm: 0.19748930
INFO:root:At the start of the epoch: mem (CPU python)=32450.83984375MB; mem (CPU total)=32282.03515625MB
INFO:root:[   60] Training loss: 0.63030430, Validation loss: 0.63301684, Gradient norm: 0.14472925
INFO:root:At the start of the epoch: mem (CPU python)=32488.93359375MB; mem (CPU total)=32319.9140625MB
INFO:root:[   61] Training loss: 0.62963336, Validation loss: 0.63332866, Gradient norm: 0.18810099
INFO:root:At the start of the epoch: mem (CPU python)=32527.03125MB; mem (CPU total)=32357.8203125MB
INFO:root:[   62] Training loss: 0.62934525, Validation loss: 0.63434447, Gradient norm: 0.16531058
INFO:root:At the start of the epoch: mem (CPU python)=32565.12890625MB; mem (CPU total)=32396.203125MB
INFO:root:[   63] Training loss: 0.62872471, Validation loss: 0.63276653, Gradient norm: 0.17406583
INFO:root:At the start of the epoch: mem (CPU python)=32603.2265625MB; mem (CPU total)=32434.5390625MB
INFO:root:[   64] Training loss: 0.62831625, Validation loss: 0.63230257, Gradient norm: 0.18840022
INFO:root:At the start of the epoch: mem (CPU python)=32641.32421875MB; mem (CPU total)=32472.62890625MB
INFO:root:[   65] Training loss: 0.62792066, Validation loss: 0.63141122, Gradient norm: 0.17521494
INFO:root:At the start of the epoch: mem (CPU python)=32679.41796875MB; mem (CPU total)=32510.77734375MB
INFO:root:[   66] Training loss: 0.62754930, Validation loss: 0.63101721, Gradient norm: 0.19542513
INFO:root:At the start of the epoch: mem (CPU python)=32717.51171875MB; mem (CPU total)=32548.890625MB
INFO:root:[   67] Training loss: 0.62675640, Validation loss: 0.63075568, Gradient norm: 0.18296684
INFO:root:At the start of the epoch: mem (CPU python)=32755.609375MB; mem (CPU total)=32587.26171875MB
INFO:root:[   68] Training loss: 0.62643642, Validation loss: 0.63041956, Gradient norm: 0.18916968
INFO:root:At the start of the epoch: mem (CPU python)=32793.703125MB; mem (CPU total)=32625.12890625MB
INFO:root:[   69] Training loss: 0.62626383, Validation loss: 0.63004648, Gradient norm: 0.19722319
INFO:root:At the start of the epoch: mem (CPU python)=32831.796875MB; mem (CPU total)=32663.25MB
INFO:root:[   70] Training loss: 0.62590831, Validation loss: 0.63012348, Gradient norm: 0.25403356
INFO:root:At the start of the epoch: mem (CPU python)=32869.890625MB; mem (CPU total)=32701.60546875MB
INFO:root:[   71] Training loss: 0.62522587, Validation loss: 0.63050426, Gradient norm: 0.22317316
INFO:root:At the start of the epoch: mem (CPU python)=32907.98828125MB; mem (CPU total)=32738.7578125MB
INFO:root:[   72] Training loss: 0.62485264, Validation loss: 0.62944449, Gradient norm: 0.18987177
INFO:root:At the start of the epoch: mem (CPU python)=32946.08203125MB; mem (CPU total)=32777.2734375MB
INFO:root:[   73] Training loss: 0.62444534, Validation loss: 0.62924583, Gradient norm: 0.19562539
INFO:root:At the start of the epoch: mem (CPU python)=32984.1796875MB; mem (CPU total)=32815.3984375MB
INFO:root:[   74] Training loss: 0.62408527, Validation loss: 0.62886902, Gradient norm: 0.22659444
INFO:root:At the start of the epoch: mem (CPU python)=33022.27734375MB; mem (CPU total)=32853.5078125MB
INFO:root:[   75] Training loss: 0.62393974, Validation loss: 0.62751937, Gradient norm: 0.17981580
INFO:root:At the start of the epoch: mem (CPU python)=33060.37109375MB; mem (CPU total)=32891.64453125MB
INFO:root:[   76] Training loss: 0.62332768, Validation loss: 0.62872673, Gradient norm: 0.19780834
INFO:root:At the start of the epoch: mem (CPU python)=33098.46484375MB; mem (CPU total)=32930.0078125MB
INFO:root:[   77] Training loss: 0.62306092, Validation loss: 0.62884006, Gradient norm: 0.20575915
INFO:root:At the start of the epoch: mem (CPU python)=33136.55859375MB; mem (CPU total)=32968.36328125MB
INFO:root:[   78] Training loss: 0.62286900, Validation loss: 0.62711007, Gradient norm: 0.23906891
INFO:root:At the start of the epoch: mem (CPU python)=33174.65625MB; mem (CPU total)=33006.2109375MB
INFO:root:[   79] Training loss: 0.62266146, Validation loss: 0.62765227, Gradient norm: 0.21810770
INFO:root:At the start of the epoch: mem (CPU python)=33212.75MB; mem (CPU total)=33044.56640625MB
INFO:root:[   80] Training loss: 0.62205637, Validation loss: 0.62777306, Gradient norm: 0.19536377
INFO:root:At the start of the epoch: mem (CPU python)=33250.84765625MB; mem (CPU total)=33082.65625MB
INFO:root:[   81] Training loss: 0.62211665, Validation loss: 0.62622996, Gradient norm: 0.31400890
INFO:root:At the start of the epoch: mem (CPU python)=33288.9453125MB; mem (CPU total)=33120.78125MB
INFO:root:[   82] Training loss: 0.62160771, Validation loss: 0.62788022, Gradient norm: 0.23142254
INFO:root:At the start of the epoch: mem (CPU python)=33327.0390625MB; mem (CPU total)=33159.12890625MB
INFO:root:[   83] Training loss: 0.62078780, Validation loss: 0.62640956, Gradient norm: 0.21914432
INFO:root:At the start of the epoch: mem (CPU python)=33365.1328125MB; mem (CPU total)=33196.94921875MB
INFO:root:[   84] Training loss: 0.62098679, Validation loss: 0.62604264, Gradient norm: 0.27933395
INFO:root:At the start of the epoch: mem (CPU python)=33403.23046875MB; mem (CPU total)=33235.06640625MB
INFO:root:[   85] Training loss: 0.62064285, Validation loss: 0.62593256, Gradient norm: 0.25747630
INFO:root:At the start of the epoch: mem (CPU python)=33441.32421875MB; mem (CPU total)=33273.79296875MB
INFO:root:[   86] Training loss: 0.62024448, Validation loss: 0.62576779, Gradient norm: 0.22913046
INFO:root:At the start of the epoch: mem (CPU python)=33479.41796875MB; mem (CPU total)=33312.234375MB
INFO:root:[   87] Training loss: 0.61991700, Validation loss: 0.62542652, Gradient norm: 0.23760799
INFO:root:At the start of the epoch: mem (CPU python)=33517.51171875MB; mem (CPU total)=33350.82421875MB
INFO:root:[   88] Training loss: 0.61949377, Validation loss: 0.62550032, Gradient norm: 0.22567485
INFO:root:At the start of the epoch: mem (CPU python)=33555.609375MB; mem (CPU total)=33388.68359375MB
INFO:root:[   89] Training loss: 0.61892679, Validation loss: 0.62531091, Gradient norm: 0.25266640
INFO:root:At the start of the epoch: mem (CPU python)=33593.70703125MB; mem (CPU total)=33426.55859375MB
INFO:root:[   90] Training loss: 0.61894187, Validation loss: 0.62482346, Gradient norm: 0.28948234
INFO:root:At the start of the epoch: mem (CPU python)=33631.80078125MB; mem (CPU total)=33464.92578125MB
INFO:root:[   91] Training loss: 0.61860267, Validation loss: 0.62440563, Gradient norm: 0.26362162
INFO:root:At the start of the epoch: mem (CPU python)=33669.8984375MB; mem (CPU total)=33502.734375MB
INFO:root:[   92] Training loss: 0.61822548, Validation loss: 0.62436910, Gradient norm: 0.27415925
INFO:root:At the start of the epoch: mem (CPU python)=33707.9921875MB; mem (CPU total)=33541.0703125MB
INFO:root:[   93] Training loss: 0.61802897, Validation loss: 0.62503664, Gradient norm: 0.24254571
INFO:root:At the start of the epoch: mem (CPU python)=33746.0859375MB; mem (CPU total)=33578.9453125MB
INFO:root:[   94] Training loss: 0.61773791, Validation loss: 0.62425466, Gradient norm: 0.29461116
INFO:root:At the start of the epoch: mem (CPU python)=33784.1796875MB; mem (CPU total)=33617.03515625MB
INFO:root:[   95] Training loss: 0.61769754, Validation loss: 0.62388596, Gradient norm: 0.30119390
INFO:root:At the start of the epoch: mem (CPU python)=33822.27734375MB; mem (CPU total)=33655.90234375MB
INFO:root:[   96] Training loss: 0.61733441, Validation loss: 0.62441187, Gradient norm: 0.35090319
INFO:root:At the start of the epoch: mem (CPU python)=33860.37109375MB; mem (CPU total)=33693.9921875MB
INFO:root:[   97] Training loss: 0.61740403, Validation loss: 0.62287286, Gradient norm: 0.32005495
INFO:root:At the start of the epoch: mem (CPU python)=33898.46875MB; mem (CPU total)=33732.171875MB
INFO:root:[   98] Training loss: 0.61652002, Validation loss: 0.62341015, Gradient norm: 0.26975043
INFO:root:At the start of the epoch: mem (CPU python)=33936.56640625MB; mem (CPU total)=33770.06640625MB
INFO:root:[   99] Training loss: 0.61659213, Validation loss: 0.62278026, Gradient norm: 0.32405124
INFO:root:At the start of the epoch: mem (CPU python)=33974.66015625MB; mem (CPU total)=33808.2109375MB
INFO:root:[  100] Training loss: 0.61608598, Validation loss: 0.62243416, Gradient norm: 0.28545534
INFO:root:At the start of the epoch: mem (CPU python)=34012.75390625MB; mem (CPU total)=33846.60546875MB
INFO:root:[  101] Training loss: 0.61632775, Validation loss: 0.62208225, Gradient norm: 0.28428724
INFO:root:At the start of the epoch: mem (CPU python)=34050.8515625MB; mem (CPU total)=33884.98828125MB
INFO:root:[  102] Training loss: 0.61555552, Validation loss: 0.62243709, Gradient norm: 0.26579731
INFO:root:At the start of the epoch: mem (CPU python)=34088.9453125MB; mem (CPU total)=33922.89453125MB
INFO:root:[  103] Training loss: 0.61547262, Validation loss: 0.62338579, Gradient norm: 0.25466812
INFO:root:At the start of the epoch: mem (CPU python)=34127.04296875MB; mem (CPU total)=33961.03515625MB
INFO:root:[  104] Training loss: 0.61508964, Validation loss: 0.62130772, Gradient norm: 0.27958790
INFO:root:At the start of the epoch: mem (CPU python)=34165.13671875MB; mem (CPU total)=33999.4140625MB
INFO:root:[  105] Training loss: 0.61504492, Validation loss: 0.62221115, Gradient norm: 0.29784653
INFO:root:At the start of the epoch: mem (CPU python)=34203.234375MB; mem (CPU total)=34037.48828125MB
INFO:root:[  106] Training loss: 0.61502615, Validation loss: 0.62198600, Gradient norm: 0.38227504
INFO:root:At the start of the epoch: mem (CPU python)=34241.33203125MB; mem (CPU total)=34075.84765625MB
INFO:root:[  107] Training loss: 0.61486979, Validation loss: 0.62115268, Gradient norm: 0.35449330
INFO:root:At the start of the epoch: mem (CPU python)=34279.42578125MB; mem (CPU total)=34113.734375MB
INFO:root:[  108] Training loss: 0.61466632, Validation loss: 0.62245531, Gradient norm: 0.34103880
INFO:root:At the start of the epoch: mem (CPU python)=34317.5234375MB; mem (CPU total)=34152.09765625MB
INFO:root:[  109] Training loss: 0.61435631, Validation loss: 0.62160494, Gradient norm: 0.39889806
INFO:root:At the start of the epoch: mem (CPU python)=34355.6171875MB; mem (CPU total)=34189.95703125MB
INFO:root:[  110] Training loss: 0.61401624, Validation loss: 0.62097763, Gradient norm: 0.32019489
INFO:root:At the start of the epoch: mem (CPU python)=34393.7109375MB; mem (CPU total)=34227.87890625MB
INFO:root:[  111] Training loss: 0.61375612, Validation loss: 0.62101176, Gradient norm: 0.39570494
INFO:root:At the start of the epoch: mem (CPU python)=34431.8046875MB; mem (CPU total)=34265.88671875MB
INFO:root:[  112] Training loss: 0.61360513, Validation loss: 0.62187032, Gradient norm: 0.38649370
INFO:root:At the start of the epoch: mem (CPU python)=34469.90234375MB; mem (CPU total)=34303.97265625MB
INFO:root:[  113] Training loss: 0.61342409, Validation loss: 0.62025807, Gradient norm: 0.33127565
INFO:root:At the start of the epoch: mem (CPU python)=34507.99609375MB; mem (CPU total)=34342.5859375MB
INFO:root:[  114] Training loss: 0.61301399, Validation loss: 0.62130504, Gradient norm: 0.28424597
INFO:root:At the start of the epoch: mem (CPU python)=34546.08984375MB; mem (CPU total)=34380.48046875MB
INFO:root:[  115] Training loss: 0.61283071, Validation loss: 0.62175884, Gradient norm: 0.31817612
INFO:root:At the start of the epoch: mem (CPU python)=34584.19140625MB; mem (CPU total)=34418.57421875MB
INFO:root:[  116] Training loss: 0.61307096, Validation loss: 0.62009156, Gradient norm: 0.45608380
INFO:root:At the start of the epoch: mem (CPU python)=34622.28515625MB; mem (CPU total)=34456.68359375MB
INFO:root:[  117] Training loss: 0.61249438, Validation loss: 0.62020710, Gradient norm: 0.37743248
INFO:root:At the start of the epoch: mem (CPU python)=34660.37890625MB; mem (CPU total)=34494.55078125MB
INFO:root:[  118] Training loss: 0.61225194, Validation loss: 0.62058817, Gradient norm: 0.41410333
INFO:root:At the start of the epoch: mem (CPU python)=34698.4765625MB; mem (CPU total)=34533.1171875MB
INFO:root:[  119] Training loss: 0.61212211, Validation loss: 0.62135612, Gradient norm: 0.42488586
INFO:root:At the start of the epoch: mem (CPU python)=34736.5703125MB; mem (CPU total)=34570.65625MB
INFO:root:[  120] Training loss: 0.61169718, Validation loss: 0.62050206, Gradient norm: 0.36119091
INFO:root:At the start of the epoch: mem (CPU python)=34774.6640625MB; mem (CPU total)=34608.75390625MB
INFO:root:[  121] Training loss: 0.61191877, Validation loss: 0.61963819, Gradient norm: 0.43596857
INFO:root:At the start of the epoch: mem (CPU python)=34812.76171875MB; mem (CPU total)=34647.09765625MB
INFO:root:[  122] Training loss: 0.61150968, Validation loss: 0.62045004, Gradient norm: 0.48705171
INFO:root:At the start of the epoch: mem (CPU python)=34850.85546875MB; mem (CPU total)=34685.23046875MB
INFO:root:[  123] Training loss: 0.61128304, Validation loss: 0.61926819, Gradient norm: 0.47881598
INFO:root:At the start of the epoch: mem (CPU python)=34888.94921875MB; mem (CPU total)=34723.63671875MB
INFO:root:[  124] Training loss: 0.61119282, Validation loss: 0.61975991, Gradient norm: 0.42818984
INFO:root:At the start of the epoch: mem (CPU python)=34927.04296875MB; mem (CPU total)=34760.7734375MB
INFO:root:[  125] Training loss: 0.61088991, Validation loss: 0.61956648, Gradient norm: 0.39649354
INFO:root:At the start of the epoch: mem (CPU python)=34965.140625MB; mem (CPU total)=34798.875MB
INFO:root:[  126] Training loss: 0.61099225, Validation loss: 0.61963992, Gradient norm: 0.46645608
INFO:root:At the start of the epoch: mem (CPU python)=35003.23828125MB; mem (CPU total)=34836.98828125MB
INFO:root:[  127] Training loss: 0.61100990, Validation loss: 0.61948910, Gradient norm: 0.47484061
INFO:root:At the start of the epoch: mem (CPU python)=35041.33203125MB; mem (CPU total)=34875.1328125MB
INFO:root:[  128] Training loss: 0.61033760, Validation loss: 0.61843956, Gradient norm: 0.46122982
INFO:root:At the start of the epoch: mem (CPU python)=35079.42578125MB; mem (CPU total)=34913.46484375MB
INFO:root:[  129] Training loss: 0.61044495, Validation loss: 0.61929802, Gradient norm: 0.45399789
INFO:root:At the start of the epoch: mem (CPU python)=35117.5234375MB; mem (CPU total)=34951.5703125MB
INFO:root:[  130] Training loss: 0.61012629, Validation loss: 0.61923567, Gradient norm: 0.45994429
INFO:root:At the start of the epoch: mem (CPU python)=35155.6171875MB; mem (CPU total)=34989.69140625MB
INFO:root:[  131] Training loss: 0.61014975, Validation loss: 0.61817266, Gradient norm: 0.51676795
INFO:root:At the start of the epoch: mem (CPU python)=35193.7109375MB; mem (CPU total)=35028.109375MB
INFO:root:[  132] Training loss: 0.60969668, Validation loss: 0.61836610, Gradient norm: 0.39284326
INFO:root:At the start of the epoch: mem (CPU python)=35231.80859375MB; mem (CPU total)=35066.5MB
INFO:root:[  133] Training loss: 0.60925097, Validation loss: 0.61829883, Gradient norm: 0.42802593
INFO:root:At the start of the epoch: mem (CPU python)=35269.90625MB; mem (CPU total)=35104.37109375MB
INFO:root:[  134] Training loss: 0.60989757, Validation loss: 0.61864020, Gradient norm: 0.55397366
INFO:root:At the start of the epoch: mem (CPU python)=35308.0MB; mem (CPU total)=35142.484375MB
INFO:root:[  135] Training loss: 0.60953293, Validation loss: 0.61945559, Gradient norm: 0.60189132
INFO:root:At the start of the epoch: mem (CPU python)=35346.09765625MB; mem (CPU total)=35180.59765625MB
INFO:root:[  136] Training loss: 0.60930010, Validation loss: 0.61879596, Gradient norm: 0.71942175
INFO:root:At the start of the epoch: mem (CPU python)=35384.1953125MB; mem (CPU total)=35218.921875MB
INFO:root:[  137] Training loss: 0.60899926, Validation loss: 0.61824809, Gradient norm: 0.48347971
INFO:root:At the start of the epoch: mem (CPU python)=35422.2890625MB; mem (CPU total)=35257.0625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  138] Training loss: 0.60894734, Validation loss: 0.61808414, Gradient norm: 0.47453393
INFO:root:At the start of the epoch: mem (CPU python)=35460.3828125MB; mem (CPU total)=35294.9296875MB
INFO:root:[  139] Training loss: 0.60755497, Validation loss: 0.61682193, Gradient norm: 0.33960593
INFO:root:At the start of the epoch: mem (CPU python)=35498.48046875MB; mem (CPU total)=35333.125MB
INFO:root:[  140] Training loss: 0.60715687, Validation loss: 0.61729726, Gradient norm: 0.33049882
INFO:root:At the start of the epoch: mem (CPU python)=35536.578125MB; mem (CPU total)=35371.484375MB
INFO:root:[  141] Training loss: 0.60752584, Validation loss: 0.61830416, Gradient norm: 0.32256251
INFO:root:At the start of the epoch: mem (CPU python)=35574.671875MB; mem (CPU total)=35410.07421875MB
INFO:root:[  142] Training loss: 0.60740179, Validation loss: 0.61729233, Gradient norm: 0.39427311
INFO:root:At the start of the epoch: mem (CPU python)=35612.76953125MB; mem (CPU total)=35448.17578125MB
INFO:root:[  143] Training loss: 0.60721749, Validation loss: 0.61832999, Gradient norm: 0.37747585
INFO:root:At the start of the epoch: mem (CPU python)=35650.86328125MB; mem (CPU total)=35486.2734375MB
INFO:root:[  144] Training loss: 0.60691173, Validation loss: 0.61749805, Gradient norm: 0.37955300
INFO:root:At the start of the epoch: mem (CPU python)=35688.95703125MB; mem (CPU total)=35524.35546875MB
INFO:root:[  145] Training loss: 0.60670956, Validation loss: 0.61731566, Gradient norm: 0.35849715
INFO:root:At the start of the epoch: mem (CPU python)=35727.05078125MB; mem (CPU total)=35562.47265625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  146] Training loss: 0.60673052, Validation loss: 0.61740531, Gradient norm: 0.31883302
INFO:root:At the start of the epoch: mem (CPU python)=35765.1484375MB; mem (CPU total)=35600.609375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  147] Training loss: 0.60631407, Validation loss: 0.61693474, Gradient norm: 0.29362065
INFO:root:At the start of the epoch: mem (CPU python)=35803.2421875MB; mem (CPU total)=35640.00390625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  148] Training loss: 0.60590720, Validation loss: 0.61640797, Gradient norm: 0.24252116
INFO:root:At the start of the epoch: mem (CPU python)=35841.3359375MB; mem (CPU total)=35678.30078125MB
INFO:root:[  149] Training loss: 0.60574866, Validation loss: 0.61595867, Gradient norm: 0.22024074
INFO:root:At the start of the epoch: mem (CPU python)=35879.43359375MB; mem (CPU total)=35716.6875MB
INFO:root:[  150] Training loss: 0.60577914, Validation loss: 0.61611375, Gradient norm: 0.20995674
INFO:root:At the start of the epoch: mem (CPU python)=35917.53125MB; mem (CPU total)=35754.859375MB
INFO:root:[  151] Training loss: 0.60568250, Validation loss: 0.61648448, Gradient norm: 0.20896793
INFO:root:At the start of the epoch: mem (CPU python)=35955.625MB; mem (CPU total)=35792.9765625MB
INFO:root:[  152] Training loss: 0.60561562, Validation loss: 0.61632554, Gradient norm: 0.21128759
INFO:root:At the start of the epoch: mem (CPU python)=35993.72265625MB; mem (CPU total)=35831.09375MB
INFO:root:[  153] Training loss: 0.60567661, Validation loss: 0.61698285, Gradient norm: 0.21152799
INFO:root:At the start of the epoch: mem (CPU python)=36031.81640625MB; mem (CPU total)=35869.4375MB
INFO:root:[  154] Training loss: 0.60559469, Validation loss: 0.61543715, Gradient norm: 0.23075092
INFO:root:At the start of the epoch: mem (CPU python)=36069.91015625MB; mem (CPU total)=35907.48828125MB
INFO:root:[  155] Training loss: 0.60553056, Validation loss: 0.61692487, Gradient norm: 0.22381593
INFO:root:At the start of the epoch: mem (CPU python)=36108.00390625MB; mem (CPU total)=35945.3515625MB
INFO:root:[  156] Training loss: 0.60566987, Validation loss: 0.61691910, Gradient norm: 0.21319986
INFO:root:At the start of the epoch: mem (CPU python)=36146.109375MB; mem (CPU total)=35983.5625MB
INFO:root:[  157] Training loss: 0.60539701, Validation loss: 0.61643045, Gradient norm: 0.23473131
INFO:root:At the start of the epoch: mem (CPU python)=36184.203125MB; mem (CPU total)=36021.66796875MB
INFO:root:[  158] Training loss: 0.60554698, Validation loss: 0.61583713, Gradient norm: 0.22947299
INFO:root:At the start of the epoch: mem (CPU python)=36222.296875MB; mem (CPU total)=36060.03125MB
INFO:root:[  159] Training loss: 0.60563943, Validation loss: 0.61683655, Gradient norm: 0.23542203
INFO:root:At the start of the epoch: mem (CPU python)=36260.39453125MB; mem (CPU total)=36098.65625MB
INFO:root:[  160] Training loss: 0.60562801, Validation loss: 0.61649818, Gradient norm: 0.24538413
INFO:root:At the start of the epoch: mem (CPU python)=36298.48828125MB; mem (CPU total)=36136.52734375MB
INFO:root:[  161] Training loss: 0.60541551, Validation loss: 0.61586858, Gradient norm: 0.21954167
INFO:root:At the start of the epoch: mem (CPU python)=36336.58203125MB; mem (CPU total)=36174.65234375MB
INFO:root:[  162] Training loss: 0.60565635, Validation loss: 0.61711866, Gradient norm: 0.21910820
INFO:root:At the start of the epoch: mem (CPU python)=36374.67578125MB; mem (CPU total)=36212.75390625MB
INFO:root:[  163] Training loss: 0.60534218, Validation loss: 0.61715108, Gradient norm: 0.21224644
INFO:root:At the start of the epoch: mem (CPU python)=36412.7734375MB; mem (CPU total)=36250.8671875MB
INFO:root:EP 163: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=36450.75390625MB; mem (CPU total)=36288.5MB
INFO:root:Training the model took 10413.129s.
INFO:root:Emptying the cuda cache took 0.081s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85962
INFO:root:EnergyScoreTrain: 0.60554
INFO:root:CRPSTrain: 0.54264
INFO:root:Gaussian NLLTrain: 3.92579
INFO:root:CoverageTrain: 0.76761
INFO:root:IntervalWidthTrain: 3.10627
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87556
INFO:root:EnergyScoreValidation: 0.61656
INFO:root:CRPSValidation: 0.55133
INFO:root:Gaussian NLLValidation: 3.96091
INFO:root:CoverageValidation: 0.76306
INFO:root:IntervalWidthValidation: 3.10503
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87688
INFO:root:EnergyScoreTest: 0.61755
INFO:root:CRPSTest: 0.55236
INFO:root:Gaussian NLLTest: 3.94515
INFO:root:CoverageTest: 0.762
INFO:root:IntervalWidthTest: 3.10176
INFO:root:After validation: mem (CPU python)=36493.6953125MB; mem (CPU total)=36331.1796875MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=36493.6953125MB; mem (CPU total)=36331.4453125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=36493.91796875MB; mem (CPU total)=36332.1796875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=36494.1640625MB; mem (CPU total)=36332.171875MB
INFO:root:[    1] Training loss: 0.78155887, Validation loss: 0.72606719, Gradient norm: 0.67471423
INFO:root:At the start of the epoch: mem (CPU python)=36533.16796875MB; mem (CPU total)=36371.48828125MB
INFO:root:[    2] Training loss: 0.72277763, Validation loss: 0.72224876, Gradient norm: 0.44246262
INFO:root:At the start of the epoch: mem (CPU python)=36571.26171875MB; mem (CPU total)=36409.703125MB
INFO:root:[    3] Training loss: 0.72091387, Validation loss: 0.72189989, Gradient norm: 0.45983476
INFO:root:At the start of the epoch: mem (CPU python)=36609.36328125MB; mem (CPU total)=36447.83203125MB
INFO:root:[    4] Training loss: 0.72031889, Validation loss: 0.72016842, Gradient norm: 0.34657142
INFO:root:At the start of the epoch: mem (CPU python)=36647.47265625MB; mem (CPU total)=36485.69921875MB
INFO:root:[    5] Training loss: 0.72011201, Validation loss: 0.72013441, Gradient norm: 0.33204321
INFO:root:At the start of the epoch: mem (CPU python)=36685.5703125MB; mem (CPU total)=36523.82421875MB
INFO:root:[    6] Training loss: 0.71994608, Validation loss: 0.71980092, Gradient norm: 0.40487351
INFO:root:At the start of the epoch: mem (CPU python)=36723.66796875MB; mem (CPU total)=36562.0MB
INFO:root:[    7] Training loss: 0.71958988, Validation loss: 0.72011588, Gradient norm: 0.27637398
INFO:root:At the start of the epoch: mem (CPU python)=36761.76171875MB; mem (CPU total)=36599.89453125MB
INFO:root:[    8] Training loss: 0.71924696, Validation loss: 0.71885361, Gradient norm: 0.30008031
INFO:root:At the start of the epoch: mem (CPU python)=36799.85546875MB; mem (CPU total)=36638.01171875MB
INFO:root:[    9] Training loss: 0.71842161, Validation loss: 0.71799862, Gradient norm: 0.29821132
INFO:root:At the start of the epoch: mem (CPU python)=36837.953125MB; mem (CPU total)=36676.33984375MB
INFO:root:[   10] Training loss: 0.71707640, Validation loss: 0.71569199, Gradient norm: 0.24124634
INFO:root:At the start of the epoch: mem (CPU python)=36876.05078125MB; mem (CPU total)=36714.67578125MB
INFO:root:[   11] Training loss: 0.71278854, Validation loss: 0.70913054, Gradient norm: 0.21585366
INFO:root:At the start of the epoch: mem (CPU python)=36914.1484375MB; mem (CPU total)=36753.01953125MB
INFO:root:[   12] Training loss: 0.70501765, Validation loss: 0.70152877, Gradient norm: 0.16655865
INFO:root:At the start of the epoch: mem (CPU python)=36952.2421875MB; mem (CPU total)=36790.87890625MB
INFO:root:[   13] Training loss: 0.69623444, Validation loss: 0.69305495, Gradient norm: 0.14619151
INFO:root:At the start of the epoch: mem (CPU python)=36992.83984375MB; mem (CPU total)=36831.48046875MB
INFO:root:[   14] Training loss: 0.68840020, Validation loss: 0.68584672, Gradient norm: 0.12388248
INFO:root:At the start of the epoch: mem (CPU python)=37030.93359375MB; mem (CPU total)=36869.59765625MB
INFO:root:[   15] Training loss: 0.68181932, Validation loss: 0.67995786, Gradient norm: 0.12416355
INFO:root:At the start of the epoch: mem (CPU python)=37069.02734375MB; mem (CPU total)=36907.515625MB
INFO:root:[   16] Training loss: 0.67713813, Validation loss: 0.67584133, Gradient norm: 0.14628504
INFO:root:At the start of the epoch: mem (CPU python)=37107.125MB; mem (CPU total)=36945.90625MB
INFO:root:[   17] Training loss: 0.67298183, Validation loss: 0.67250264, Gradient norm: 0.13819794
INFO:root:At the start of the epoch: mem (CPU python)=37145.21875MB; mem (CPU total)=36984.0234375MB
INFO:root:[   18] Training loss: 0.66956334, Validation loss: 0.67008183, Gradient norm: 0.08910428
INFO:root:At the start of the epoch: mem (CPU python)=37183.3125MB; mem (CPU total)=37022.66015625MB
INFO:root:[   19] Training loss: 0.66644136, Validation loss: 0.66617915, Gradient norm: 0.13491715
INFO:root:At the start of the epoch: mem (CPU python)=37221.41015625MB; mem (CPU total)=37060.8046875MB
INFO:root:[   20] Training loss: 0.66410855, Validation loss: 0.66405456, Gradient norm: 0.09917576
INFO:root:At the start of the epoch: mem (CPU python)=37259.5078125MB; mem (CPU total)=37098.6796875MB
INFO:root:[   21] Training loss: 0.66170066, Validation loss: 0.66200820, Gradient norm: 0.10444363
INFO:root:At the start of the epoch: mem (CPU python)=37297.6015625MB; mem (CPU total)=37137.0234375MB
INFO:root:[   22] Training loss: 0.65978886, Validation loss: 0.66008104, Gradient norm: 0.11690439
INFO:root:At the start of the epoch: mem (CPU python)=37335.6953125MB; mem (CPU total)=37175.1484375MB
INFO:root:[   23] Training loss: 0.65801600, Validation loss: 0.65843062, Gradient norm: 0.09357067
INFO:root:At the start of the epoch: mem (CPU python)=37373.79296875MB; mem (CPU total)=37213.2890625MB
INFO:root:[   24] Training loss: 0.65615431, Validation loss: 0.65750175, Gradient norm: 0.11130782
INFO:root:At the start of the epoch: mem (CPU python)=37411.88671875MB; mem (CPU total)=37251.6875MB
INFO:root:[   25] Training loss: 0.65511775, Validation loss: 0.65574682, Gradient norm: 0.12236736
INFO:root:At the start of the epoch: mem (CPU python)=37449.98046875MB; mem (CPU total)=37290.0703125MB
INFO:root:[   26] Training loss: 0.65347555, Validation loss: 0.65538518, Gradient norm: 0.11209760
INFO:root:At the start of the epoch: mem (CPU python)=37488.078125MB; mem (CPU total)=37327.94140625MB
INFO:root:[   27] Training loss: 0.65244836, Validation loss: 0.65356717, Gradient norm: 0.13589772
INFO:root:At the start of the epoch: mem (CPU python)=37526.17578125MB; mem (CPU total)=37366.53515625MB
INFO:root:[   28] Training loss: 0.65133625, Validation loss: 0.65284105, Gradient norm: 0.12503193
INFO:root:At the start of the epoch: mem (CPU python)=37564.26953125MB; mem (CPU total)=37404.703125MB
INFO:root:[   29] Training loss: 0.65028033, Validation loss: 0.65240294, Gradient norm: 0.14562345
INFO:root:At the start of the epoch: mem (CPU python)=37602.36328125MB; mem (CPU total)=37445.21875MB
INFO:root:[   30] Training loss: 0.64920856, Validation loss: 0.65076158, Gradient norm: 0.11834890
INFO:root:At the start of the epoch: mem (CPU python)=37640.4609375MB; mem (CPU total)=37482.34375MB
INFO:root:[   31] Training loss: 0.64831334, Validation loss: 0.65155841, Gradient norm: 0.11768797
INFO:root:At the start of the epoch: mem (CPU python)=37678.5546875MB; mem (CPU total)=37519.671875MB
INFO:root:[   32] Training loss: 0.64710142, Validation loss: 0.64953084, Gradient norm: 0.11878990
INFO:root:At the start of the epoch: mem (CPU python)=37716.6484375MB; mem (CPU total)=37557.22265625MB
INFO:root:[   33] Training loss: 0.64644875, Validation loss: 0.64921468, Gradient norm: 0.11613793
INFO:root:At the start of the epoch: mem (CPU python)=37754.74609375MB; mem (CPU total)=37595.48046875MB
INFO:root:[   34] Training loss: 0.64570949, Validation loss: 0.64850424, Gradient norm: 0.11252399
INFO:root:At the start of the epoch: mem (CPU python)=37792.83984375MB; mem (CPU total)=37633.60546875MB
INFO:root:[   35] Training loss: 0.64465721, Validation loss: 0.64688723, Gradient norm: 0.12523711
INFO:root:At the start of the epoch: mem (CPU python)=37830.93359375MB; mem (CPU total)=37672.1875MB
INFO:root:[   36] Training loss: 0.64410872, Validation loss: 0.64706212, Gradient norm: 0.11968922
INFO:root:At the start of the epoch: mem (CPU python)=37869.02734375MB; mem (CPU total)=37710.5390625MB
INFO:root:[   37] Training loss: 0.64343691, Validation loss: 0.64639762, Gradient norm: 0.11924463
INFO:root:At the start of the epoch: mem (CPU python)=37907.12890625MB; mem (CPU total)=37748.64453125MB
INFO:root:[   38] Training loss: 0.64264100, Validation loss: 0.64531630, Gradient norm: 0.14871340
INFO:root:At the start of the epoch: mem (CPU python)=37945.22265625MB; mem (CPU total)=37787.015625MB
INFO:root:[   39] Training loss: 0.64158041, Validation loss: 0.64560584, Gradient norm: 0.13929050
INFO:root:At the start of the epoch: mem (CPU python)=37983.31640625MB; mem (CPU total)=37824.88671875MB
INFO:root:[   40] Training loss: 0.64106862, Validation loss: 0.64426508, Gradient norm: 0.13219829
INFO:root:At the start of the epoch: mem (CPU python)=38021.4140625MB; mem (CPU total)=37862.9453125MB
INFO:root:[   41] Training loss: 0.64068752, Validation loss: 0.64306937, Gradient norm: 0.14335745
INFO:root:At the start of the epoch: mem (CPU python)=38059.5078125MB; mem (CPU total)=37900.84765625MB
INFO:root:[   42] Training loss: 0.63982056, Validation loss: 0.64266488, Gradient norm: 0.12407078
INFO:root:At the start of the epoch: mem (CPU python)=38097.6015625MB; mem (CPU total)=37938.96875MB
INFO:root:[   43] Training loss: 0.63910256, Validation loss: 0.64229794, Gradient norm: 0.15205144
INFO:root:At the start of the epoch: mem (CPU python)=38135.6953125MB; mem (CPU total)=37977.8203125MB
INFO:root:[   44] Training loss: 0.63872135, Validation loss: 0.64248869, Gradient norm: 0.14165156
INFO:root:At the start of the epoch: mem (CPU python)=38173.796875MB; mem (CPU total)=38016.21875MB
INFO:root:[   45] Training loss: 0.63832344, Validation loss: 0.64164735, Gradient norm: 0.15263324
INFO:root:At the start of the epoch: mem (CPU python)=38211.890625MB; mem (CPU total)=38054.3125MB
INFO:root:[   46] Training loss: 0.63754843, Validation loss: 0.64150194, Gradient norm: 0.13895807
INFO:root:At the start of the epoch: mem (CPU python)=38249.984375MB; mem (CPU total)=38093.73046875MB
INFO:root:[   47] Training loss: 0.63702175, Validation loss: 0.64087367, Gradient norm: 0.13087393
INFO:root:At the start of the epoch: mem (CPU python)=38288.08203125MB; mem (CPU total)=38131.78125MB
INFO:root:[   48] Training loss: 0.63659330, Validation loss: 0.64044627, Gradient norm: 0.17089649
INFO:root:At the start of the epoch: mem (CPU python)=38326.17578125MB; mem (CPU total)=38169.9140625MB
INFO:root:[   49] Training loss: 0.63609337, Validation loss: 0.63999416, Gradient norm: 0.16207017
INFO:root:At the start of the epoch: mem (CPU python)=38364.26953125MB; mem (CPU total)=38207.9609375MB
INFO:root:[   50] Training loss: 0.63566459, Validation loss: 0.63950970, Gradient norm: 0.20046307
INFO:root:At the start of the epoch: mem (CPU python)=38402.3671875MB; mem (CPU total)=38245.9140625MB
INFO:root:[   51] Training loss: 0.63472986, Validation loss: 0.63881030, Gradient norm: 0.14928592
INFO:root:At the start of the epoch: mem (CPU python)=38440.46484375MB; mem (CPU total)=38284.2578125MB
INFO:root:[   52] Training loss: 0.63452092, Validation loss: 0.63878895, Gradient norm: 0.16615662
INFO:root:At the start of the epoch: mem (CPU python)=38478.56640625MB; mem (CPU total)=38322.49609375MB
INFO:root:[   53] Training loss: 0.63429982, Validation loss: 0.63839431, Gradient norm: 0.16854092
INFO:root:At the start of the epoch: mem (CPU python)=38516.65625MB; mem (CPU total)=38360.87109375MB
INFO:root:[   54] Training loss: 0.63378510, Validation loss: 0.63791755, Gradient norm: 0.15836951
INFO:root:At the start of the epoch: mem (CPU python)=38554.7578125MB; mem (CPU total)=38398.875MB
INFO:root:[   55] Training loss: 0.63306515, Validation loss: 0.63672215, Gradient norm: 0.18080481
INFO:root:At the start of the epoch: mem (CPU python)=38592.8515625MB; mem (CPU total)=38436.703125MB
INFO:root:[   56] Training loss: 0.63247213, Validation loss: 0.63781183, Gradient norm: 0.17585819
INFO:root:At the start of the epoch: mem (CPU python)=38630.9453125MB; mem (CPU total)=38474.76953125MB
INFO:root:[   57] Training loss: 0.63242240, Validation loss: 0.63585354, Gradient norm: 0.21947795
INFO:root:At the start of the epoch: mem (CPU python)=38669.04296875MB; mem (CPU total)=38513.125MB
INFO:root:[   58] Training loss: 0.63180662, Validation loss: 0.63659300, Gradient norm: 0.16747121
INFO:root:At the start of the epoch: mem (CPU python)=38707.13671875MB; mem (CPU total)=38551.5MB
INFO:root:[   59] Training loss: 0.63132878, Validation loss: 0.63701503, Gradient norm: 0.22973997
INFO:root:At the start of the epoch: mem (CPU python)=38745.234375MB; mem (CPU total)=38589.171875MB
INFO:root:[   60] Training loss: 0.63106429, Validation loss: 0.63552731, Gradient norm: 0.18836000
INFO:root:At the start of the epoch: mem (CPU python)=38783.328125MB; mem (CPU total)=38627.5390625MB
INFO:root:[   61] Training loss: 0.63070945, Validation loss: 0.63507311, Gradient norm: 0.18469841
INFO:root:At the start of the epoch: mem (CPU python)=38821.42578125MB; mem (CPU total)=38665.88671875MB
INFO:root:[   62] Training loss: 0.62992988, Validation loss: 0.63592527, Gradient norm: 0.18363021
INFO:root:At the start of the epoch: mem (CPU python)=38859.51953125MB; mem (CPU total)=38704.21484375MB
INFO:root:[   63] Training loss: 0.62979677, Validation loss: 0.63485323, Gradient norm: 0.20104967
INFO:root:At the start of the epoch: mem (CPU python)=38897.61328125MB; mem (CPU total)=38742.30859375MB
INFO:root:[   64] Training loss: 0.62936773, Validation loss: 0.63429625, Gradient norm: 0.25089784
INFO:root:At the start of the epoch: mem (CPU python)=38935.7109375MB; mem (CPU total)=38779.91015625MB
INFO:root:[   65] Training loss: 0.62883663, Validation loss: 0.63388569, Gradient norm: 0.20705622
INFO:root:At the start of the epoch: mem (CPU python)=38973.8046875MB; mem (CPU total)=38818.49609375MB
INFO:root:[   66] Training loss: 0.62846253, Validation loss: 0.63372157, Gradient norm: 0.20599511
INFO:root:At the start of the epoch: mem (CPU python)=39011.8984375MB; mem (CPU total)=38856.83984375MB
INFO:root:[   67] Training loss: 0.62818712, Validation loss: 0.63336975, Gradient norm: 0.23377806
INFO:root:At the start of the epoch: mem (CPU python)=39049.99609375MB; mem (CPU total)=38895.203125MB
INFO:root:[   68] Training loss: 0.62783337, Validation loss: 0.63348864, Gradient norm: 0.26102799
INFO:root:At the start of the epoch: mem (CPU python)=39088.08984375MB; mem (CPU total)=38932.79296875MB
INFO:root:[   69] Training loss: 0.62735277, Validation loss: 0.63308773, Gradient norm: 0.26017540
INFO:root:At the start of the epoch: mem (CPU python)=39126.1875MB; mem (CPU total)=38970.6875MB
INFO:root:[   70] Training loss: 0.62701447, Validation loss: 0.63264015, Gradient norm: 0.29608531
INFO:root:At the start of the epoch: mem (CPU python)=39164.28125MB; mem (CPU total)=39009.07421875MB
INFO:root:[   71] Training loss: 0.62631196, Validation loss: 0.63226961, Gradient norm: 0.20884101
INFO:root:At the start of the epoch: mem (CPU python)=39202.37890625MB; mem (CPU total)=39046.94921875MB
INFO:root:[   72] Training loss: 0.62641841, Validation loss: 0.63190929, Gradient norm: 0.25705082
INFO:root:At the start of the epoch: mem (CPU python)=39240.47265625MB; mem (CPU total)=39084.82421875MB
INFO:root:[   73] Training loss: 0.62569271, Validation loss: 0.63078121, Gradient norm: 0.22332720
INFO:root:At the start of the epoch: mem (CPU python)=39278.56640625MB; mem (CPU total)=39122.93359375MB
INFO:root:[   74] Training loss: 0.62536867, Validation loss: 0.63175547, Gradient norm: 0.24025618
INFO:root:At the start of the epoch: mem (CPU python)=39316.6640625MB; mem (CPU total)=39161.2890625MB
INFO:root:[   75] Training loss: 0.62529572, Validation loss: 0.62998800, Gradient norm: 0.24428539
INFO:root:At the start of the epoch: mem (CPU python)=39354.7578125MB; mem (CPU total)=39199.390625MB
INFO:root:[   76] Training loss: 0.62506866, Validation loss: 0.63121288, Gradient norm: 0.22829581
INFO:root:At the start of the epoch: mem (CPU python)=39392.8515625MB; mem (CPU total)=39237.5703125MB
INFO:root:[   77] Training loss: 0.62457445, Validation loss: 0.62984526, Gradient norm: 0.26501088
INFO:root:At the start of the epoch: mem (CPU python)=39430.9453125MB; mem (CPU total)=39275.41796875MB
INFO:root:[   78] Training loss: 0.62451380, Validation loss: 0.63015361, Gradient norm: 0.28212497
INFO:root:At the start of the epoch: mem (CPU python)=39469.046875MB; mem (CPU total)=39313.7734375MB
INFO:root:[   79] Training loss: 0.62392811, Validation loss: 0.63124701, Gradient norm: 0.28736729
INFO:root:At the start of the epoch: mem (CPU python)=39507.140625MB; mem (CPU total)=39352.1171875MB
INFO:root:[   80] Training loss: 0.62346248, Validation loss: 0.62957187, Gradient norm: 0.26749869
INFO:root:At the start of the epoch: mem (CPU python)=39545.234375MB; mem (CPU total)=39389.95703125MB
INFO:root:[   81] Training loss: 0.62382530, Validation loss: 0.62998675, Gradient norm: 0.32391749
INFO:root:At the start of the epoch: mem (CPU python)=39583.33203125MB; mem (CPU total)=39428.28515625MB
INFO:root:[   82] Training loss: 0.62314919, Validation loss: 0.62942758, Gradient norm: 0.28368353
INFO:root:At the start of the epoch: mem (CPU python)=39621.42578125MB; mem (CPU total)=39466.64453125MB
INFO:root:[   83] Training loss: 0.62236762, Validation loss: 0.62940962, Gradient norm: 0.24914699
INFO:root:At the start of the epoch: mem (CPU python)=39659.51953125MB; mem (CPU total)=39505.0390625MB
INFO:root:[   84] Training loss: 0.62252364, Validation loss: 0.62850156, Gradient norm: 0.34948514
INFO:root:At the start of the epoch: mem (CPU python)=39697.6171875MB; mem (CPU total)=39543.15625MB
INFO:root:[   85] Training loss: 0.62195123, Validation loss: 0.62843734, Gradient norm: 0.28472533
INFO:root:At the start of the epoch: mem (CPU python)=39735.71484375MB; mem (CPU total)=39581.31640625MB
INFO:root:[   86] Training loss: 0.62186725, Validation loss: 0.62871784, Gradient norm: 0.37224133
INFO:root:At the start of the epoch: mem (CPU python)=39773.80859375MB; mem (CPU total)=39619.41796875MB
INFO:root:[   87] Training loss: 0.62170070, Validation loss: 0.62890353, Gradient norm: 0.35591041
INFO:root:At the start of the epoch: mem (CPU python)=39811.90234375MB; mem (CPU total)=39657.35546875MB
INFO:root:[   88] Training loss: 0.62124049, Validation loss: 0.62840350, Gradient norm: 0.28186943
INFO:root:At the start of the epoch: mem (CPU python)=39850.0MB; mem (CPU total)=39695.70703125MB
INFO:root:[   89] Training loss: 0.62085690, Validation loss: 0.62796988, Gradient norm: 0.30279731
INFO:root:At the start of the epoch: mem (CPU python)=39888.09375MB; mem (CPU total)=39734.109375MB
INFO:root:[   90] Training loss: 0.62094075, Validation loss: 0.62682189, Gradient norm: 0.42399787
INFO:root:At the start of the epoch: mem (CPU python)=39926.1875MB; mem (CPU total)=39771.9765625MB
INFO:root:[   91] Training loss: 0.62066500, Validation loss: 0.62705512, Gradient norm: 0.33166795
INFO:root:At the start of the epoch: mem (CPU python)=39964.28515625MB; mem (CPU total)=39810.31640625MB
INFO:root:[   92] Training loss: 0.62007539, Validation loss: 0.62713866, Gradient norm: 0.34028474
INFO:root:At the start of the epoch: mem (CPU python)=40002.37890625MB; mem (CPU total)=39848.6484375MB
INFO:root:[   93] Training loss: 0.62013422, Validation loss: 0.62747884, Gradient norm: 0.40746320
INFO:root:At the start of the epoch: mem (CPU python)=40040.47265625MB; mem (CPU total)=39888.0078125MB
INFO:root:[   94] Training loss: 0.61999464, Validation loss: 0.62692531, Gradient norm: 0.32737519
INFO:root:At the start of the epoch: mem (CPU python)=40078.5703125MB; mem (CPU total)=39926.13671875MB
INFO:root:[   95] Training loss: 0.61973918, Validation loss: 0.62677591, Gradient norm: 0.43323037
INFO:root:At the start of the epoch: mem (CPU python)=40116.66796875MB; mem (CPU total)=39963.79296875MB
INFO:root:[   96] Training loss: 0.61972761, Validation loss: 0.62729676, Gradient norm: 0.33458195
INFO:root:At the start of the epoch: mem (CPU python)=40154.76171875MB; mem (CPU total)=40000.63671875MB
INFO:root:[   97] Training loss: 0.61924997, Validation loss: 0.62679624, Gradient norm: 0.47820636
INFO:root:At the start of the epoch: mem (CPU python)=40192.85546875MB; mem (CPU total)=40038.99609375MB
INFO:root:[   98] Training loss: 0.61902177, Validation loss: 0.62673324, Gradient norm: 0.53342704
INFO:root:At the start of the epoch: mem (CPU python)=40230.953125MB; mem (CPU total)=40077.4453125MB
INFO:root:[   99] Training loss: 0.61878539, Validation loss: 0.62749899, Gradient norm: 0.36382774
INFO:root:At the start of the epoch: mem (CPU python)=40269.046875MB; mem (CPU total)=40115.7265625MB
INFO:root:[  100] Training loss: 0.61855328, Validation loss: 0.62663630, Gradient norm: 0.45012789
INFO:root:At the start of the epoch: mem (CPU python)=40307.140625MB; mem (CPU total)=40153.609375MB
INFO:root:[  101] Training loss: 0.61836907, Validation loss: 0.62538876, Gradient norm: 0.41405296
INFO:root:At the start of the epoch: mem (CPU python)=40345.23828125MB; mem (CPU total)=40192.03125MB
INFO:root:[  102] Training loss: 0.61843334, Validation loss: 0.62690458, Gradient norm: 0.40127461
INFO:root:At the start of the epoch: mem (CPU python)=40383.33203125MB; mem (CPU total)=40230.484375MB
INFO:root:[  103] Training loss: 0.61806560, Validation loss: 0.62690063, Gradient norm: 0.40134954
INFO:root:At the start of the epoch: mem (CPU python)=40421.4296875MB; mem (CPU total)=40268.34375MB
INFO:root:[  104] Training loss: 0.61774795, Validation loss: 0.62592502, Gradient norm: 0.46229153
INFO:root:At the start of the epoch: mem (CPU python)=40459.5234375MB; mem (CPU total)=40306.64453125MB
INFO:root:[  105] Training loss: 0.61733687, Validation loss: 0.62428418, Gradient norm: 0.49987433
INFO:root:At the start of the epoch: mem (CPU python)=40497.62109375MB; mem (CPU total)=40344.734375MB
INFO:root:[  106] Training loss: 0.61737585, Validation loss: 0.62505459, Gradient norm: 0.54779526
INFO:root:At the start of the epoch: mem (CPU python)=40535.71484375MB; mem (CPU total)=40382.8203125MB
INFO:root:[  107] Training loss: 0.61719237, Validation loss: 0.62508458, Gradient norm: 0.55660122
INFO:root:At the start of the epoch: mem (CPU python)=40573.80859375MB; mem (CPU total)=40421.1796875MB
INFO:root:[  108] Training loss: 0.61695056, Validation loss: 0.62450693, Gradient norm: 0.49041129
INFO:root:At the start of the epoch: mem (CPU python)=40611.90625MB; mem (CPU total)=40459.58203125MB
INFO:root:[  109] Training loss: 0.61655702, Validation loss: 0.62493442, Gradient norm: 0.47690873
INFO:root:At the start of the epoch: mem (CPU python)=40650.0MB; mem (CPU total)=40497.7109375MB
INFO:root:[  110] Training loss: 0.61672422, Validation loss: 0.62448123, Gradient norm: 1.03189904
INFO:root:At the start of the epoch: mem (CPU python)=40688.09765625MB; mem (CPU total)=40535.9296875MB
INFO:root:[  111] Training loss: 0.61630371, Validation loss: 0.62460682, Gradient norm: 0.60409456
INFO:root:At the start of the epoch: mem (CPU python)=40726.1875MB; mem (CPU total)=40573.92578125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  112] Training loss: 0.61626838, Validation loss: 0.62487940, Gradient norm: 0.56593897
INFO:root:At the start of the epoch: mem (CPU python)=40764.2890625MB; mem (CPU total)=40612.0625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  113] Training loss: 0.61483747, Validation loss: 0.62342993, Gradient norm: 0.30905131
INFO:root:At the start of the epoch: mem (CPU python)=40802.3828125MB; mem (CPU total)=40650.4765625MB
INFO:root:[  114] Training loss: 0.61431576, Validation loss: 0.62308554, Gradient norm: 0.23923386
INFO:root:At the start of the epoch: mem (CPU python)=40840.4765625MB; mem (CPU total)=40687.61328125MB
INFO:root:[  115] Training loss: 0.61438216, Validation loss: 0.62235281, Gradient norm: 0.27053275
INFO:root:At the start of the epoch: mem (CPU python)=40878.578125MB; mem (CPU total)=40725.52734375MB
INFO:root:[  116] Training loss: 0.61421572, Validation loss: 0.62322094, Gradient norm: 0.22886347
INFO:root:At the start of the epoch: mem (CPU python)=40916.671875MB; mem (CPU total)=40763.609375MB
INFO:root:[  117] Training loss: 0.61381638, Validation loss: 0.62413938, Gradient norm: 0.27964824
INFO:root:At the start of the epoch: mem (CPU python)=40954.765625MB; mem (CPU total)=40801.7265625MB
INFO:root:[  118] Training loss: 0.61403014, Validation loss: 0.62361436, Gradient norm: 0.24750346
INFO:root:At the start of the epoch: mem (CPU python)=40992.859375MB; mem (CPU total)=40839.84765625MB
INFO:root:[  119] Training loss: 0.61392391, Validation loss: 0.62394008, Gradient norm: 0.27802984
INFO:root:At the start of the epoch: mem (CPU python)=41030.95703125MB; mem (CPU total)=40877.66015625MB
INFO:root:[  120] Training loss: 0.61376019, Validation loss: 0.62258119, Gradient norm: 0.31307913
INFO:root:At the start of the epoch: mem (CPU python)=41069.0546875MB; mem (CPU total)=40915.80078125MB
INFO:root:[  121] Training loss: 0.61371379, Validation loss: 0.62368096, Gradient norm: 0.32129792
INFO:root:At the start of the epoch: mem (CPU python)=41107.1484375MB; mem (CPU total)=40953.640625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  122] Training loss: 0.61398815, Validation loss: 0.62270108, Gradient norm: 0.26630072
INFO:root:At the start of the epoch: mem (CPU python)=41145.24609375MB; mem (CPU total)=40991.73046875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  123] Training loss: 0.61379080, Validation loss: 0.62305738, Gradient norm: 0.24006280
INFO:root:At the start of the epoch: mem (CPU python)=41183.33984375MB; mem (CPU total)=41029.84375MB
INFO:root:[  124] Training loss: 0.61349794, Validation loss: 0.62347404, Gradient norm: 0.19004156
INFO:root:At the start of the epoch: mem (CPU python)=41221.43359375MB; mem (CPU total)=41068.19140625MB
INFO:root:EP 124: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=41259.53125MB; mem (CPU total)=41107.98828125MB
INFO:root:Training the model took 8658.081s.
INFO:root:Emptying the cuda cache took 0.082s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87168
INFO:root:EnergyScoreTrain: 0.61402
INFO:root:CRPSTrain: 0.55596
INFO:root:Gaussian NLLTrain: 4.27596
INFO:root:CoverageTrain: 0.75499
INFO:root:IntervalWidthTrain: 3.13215
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88503
INFO:root:EnergyScoreValidation: 0.62327
INFO:root:CRPSValidation: 0.56338
INFO:root:Gaussian NLLValidation: 4.30485
INFO:root:CoverageValidation: 0.75078
INFO:root:IntervalWidthValidation: 3.1269
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8868
INFO:root:EnergyScoreTest: 0.62452
INFO:root:CRPSTest: 0.56438
INFO:root:Gaussian NLLTest: 4.32487
INFO:root:CoverageTest: 0.74985
INFO:root:IntervalWidthTest: 3.1225
INFO:root:After validation: mem (CPU python)=41302.52734375MB; mem (CPU total)=41151.29296875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=41302.52734375MB; mem (CPU total)=41151.2890625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=41302.734375MB; mem (CPU total)=41151.2890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=41302.9375MB; mem (CPU total)=41151.52734375MB
INFO:root:[    1] Training loss: 0.77612762, Validation loss: 0.72559897, Gradient norm: 0.72937177
INFO:root:At the start of the epoch: mem (CPU python)=41340.98828125MB; mem (CPU total)=41189.85546875MB
INFO:root:[    2] Training loss: 0.72286495, Validation loss: 0.72144427, Gradient norm: 0.52827633
INFO:root:At the start of the epoch: mem (CPU python)=41379.08203125MB; mem (CPU total)=41227.54296875MB
INFO:root:[    3] Training loss: 0.72090115, Validation loss: 0.72067757, Gradient norm: 0.41589102
INFO:root:At the start of the epoch: mem (CPU python)=41417.18359375MB; mem (CPU total)=41265.69921875MB
INFO:root:[    4] Training loss: 0.72025161, Validation loss: 0.71974745, Gradient norm: 0.32109366
INFO:root:At the start of the epoch: mem (CPU python)=41455.28125MB; mem (CPU total)=41304.39453125MB
INFO:root:[    5] Training loss: 0.72001245, Validation loss: 0.71974573, Gradient norm: 0.28679692
INFO:root:At the start of the epoch: mem (CPU python)=41493.37890625MB; mem (CPU total)=41342.7890625MB
INFO:root:[    6] Training loss: 0.71959689, Validation loss: 0.72002230, Gradient norm: 0.36539492
INFO:root:At the start of the epoch: mem (CPU python)=41531.4765625MB; mem (CPU total)=41380.90234375MB
INFO:root:[    7] Training loss: 0.71919705, Validation loss: 0.71931523, Gradient norm: 0.29159876
INFO:root:At the start of the epoch: mem (CPU python)=41569.57421875MB; mem (CPU total)=41419.1328125MB
INFO:root:[    8] Training loss: 0.71866729, Validation loss: 0.71898943, Gradient norm: 0.33548864
INFO:root:At the start of the epoch: mem (CPU python)=41607.66796875MB; mem (CPU total)=41456.97265625MB
INFO:root:[    9] Training loss: 0.71770593, Validation loss: 0.71757838, Gradient norm: 0.29479166
INFO:root:At the start of the epoch: mem (CPU python)=41645.76171875MB; mem (CPU total)=41495.2890625MB
INFO:root:[   10] Training loss: 0.71476537, Validation loss: 0.71248924, Gradient norm: 0.22874509
INFO:root:At the start of the epoch: mem (CPU python)=41683.85546875MB; mem (CPU total)=41533.4375MB
INFO:root:[   11] Training loss: 0.70871201, Validation loss: 0.70614844, Gradient norm: 0.15654261
INFO:root:At the start of the epoch: mem (CPU python)=41721.953125MB; mem (CPU total)=41571.578125MB
INFO:root:[   12] Training loss: 0.70359113, Validation loss: 0.70112558, Gradient norm: 0.12181169
INFO:root:At the start of the epoch: mem (CPU python)=41760.046875MB; mem (CPU total)=41610.0390625MB
INFO:root:[   13] Training loss: 0.69949417, Validation loss: 0.69792082, Gradient norm: 0.12597345
INFO:root:At the start of the epoch: mem (CPU python)=41798.14453125MB; mem (CPU total)=41647.83984375MB
INFO:root:[   14] Training loss: 0.69555341, Validation loss: 0.69409364, Gradient norm: 0.13266270
INFO:root:At the start of the epoch: mem (CPU python)=41836.2421875MB; mem (CPU total)=41686.01171875MB
INFO:root:[   15] Training loss: 0.69141437, Validation loss: 0.69054413, Gradient norm: 0.12824187
INFO:root:At the start of the epoch: mem (CPU python)=41874.3359375MB; mem (CPU total)=41724.3984375MB
INFO:root:[   16] Training loss: 0.68762741, Validation loss: 0.68637223, Gradient norm: 0.12287748
INFO:root:At the start of the epoch: mem (CPU python)=41912.4296875MB; mem (CPU total)=41762.61328125MB
INFO:root:[   17] Training loss: 0.68436531, Validation loss: 0.68298465, Gradient norm: 0.10634683
INFO:root:At the start of the epoch: mem (CPU python)=41950.5234375MB; mem (CPU total)=41801.25390625MB
INFO:root:[   18] Training loss: 0.68045209, Validation loss: 0.68101713, Gradient norm: 0.12156634
INFO:root:At the start of the epoch: mem (CPU python)=41988.62109375MB; mem (CPU total)=41839.00390625MB
INFO:root:[   19] Training loss: 0.67766125, Validation loss: 0.67664658, Gradient norm: 0.12624550
INFO:root:At the start of the epoch: mem (CPU python)=42026.71484375MB; mem (CPU total)=41876.6171875MB
INFO:root:[   20] Training loss: 0.67447160, Validation loss: 0.67405660, Gradient norm: 0.11093721
INFO:root:At the start of the epoch: mem (CPU python)=42064.81640625MB; mem (CPU total)=41915.24609375MB
INFO:root:[   21] Training loss: 0.67170159, Validation loss: 0.67097450, Gradient norm: 0.09091893
INFO:root:At the start of the epoch: mem (CPU python)=42102.91015625MB; mem (CPU total)=41953.4140625MB
INFO:root:[   22] Training loss: 0.66884632, Validation loss: 0.66971984, Gradient norm: 0.09924812
INFO:root:At the start of the epoch: mem (CPU python)=42141.01171875MB; mem (CPU total)=41991.58203125MB
INFO:root:[   23] Training loss: 0.66678552, Validation loss: 0.66675244, Gradient norm: 0.09320696
INFO:root:At the start of the epoch: mem (CPU python)=42179.10546875MB; mem (CPU total)=42029.3984375MB
INFO:root:[   24] Training loss: 0.66410490, Validation loss: 0.66371282, Gradient norm: 0.09022033
INFO:root:At the start of the epoch: mem (CPU python)=42217.203125MB; mem (CPU total)=42068.078125MB
INFO:root:[   25] Training loss: 0.66213858, Validation loss: 0.66357635, Gradient norm: 0.11111535
INFO:root:At the start of the epoch: mem (CPU python)=42255.296875MB; mem (CPU total)=42106.5MB
INFO:root:[   26] Training loss: 0.66009392, Validation loss: 0.66105564, Gradient norm: 0.10433671
INFO:root:At the start of the epoch: mem (CPU python)=42293.390625MB; mem (CPU total)=42144.6484375MB
INFO:root:[   27] Training loss: 0.65865064, Validation loss: 0.65920833, Gradient norm: 0.09777108
INFO:root:At the start of the epoch: mem (CPU python)=42331.484375MB; mem (CPU total)=42182.51953125MB
INFO:root:[   28] Training loss: 0.65631005, Validation loss: 0.65680288, Gradient norm: 0.09262119
INFO:root:At the start of the epoch: mem (CPU python)=42369.58203125MB; mem (CPU total)=42220.40625MB
INFO:root:[   29] Training loss: 0.65537336, Validation loss: 0.65594308, Gradient norm: 0.09498880
INFO:root:At the start of the epoch: mem (CPU python)=42407.6796875MB; mem (CPU total)=42258.0546875MB
INFO:root:[   30] Training loss: 0.65338306, Validation loss: 0.65464625, Gradient norm: 0.09857421
INFO:root:At the start of the epoch: mem (CPU python)=42445.7734375MB; mem (CPU total)=42295.94140625MB
INFO:root:[   31] Training loss: 0.65175973, Validation loss: 0.65242848, Gradient norm: 0.09834258
INFO:root:At the start of the epoch: mem (CPU python)=42483.8671875MB; mem (CPU total)=42339.375MB
INFO:root:[   32] Training loss: 0.65086622, Validation loss: 0.65239988, Gradient norm: 0.09971366
INFO:root:At the start of the epoch: mem (CPU python)=42521.96484375MB; mem (CPU total)=42377.2578125MB
INFO:root:[   33] Training loss: 0.64938000, Validation loss: 0.65023354, Gradient norm: 0.09882474
INFO:root:At the start of the epoch: mem (CPU python)=42560.05859375MB; mem (CPU total)=42414.890625MB
INFO:root:[   34] Training loss: 0.64848960, Validation loss: 0.65061225, Gradient norm: 0.09000423
INFO:root:At the start of the epoch: mem (CPU python)=42598.15234375MB; mem (CPU total)=42454.12890625MB
INFO:root:[   35] Training loss: 0.64699723, Validation loss: 0.64885195, Gradient norm: 0.08595902
INFO:root:At the start of the epoch: mem (CPU python)=42636.25MB; mem (CPU total)=42492.47265625MB
INFO:root:[   36] Training loss: 0.64582393, Validation loss: 0.64703322, Gradient norm: 0.08741911
INFO:root:At the start of the epoch: mem (CPU python)=42674.34375MB; mem (CPU total)=42530.62890625MB
INFO:root:[   37] Training loss: 0.64546623, Validation loss: 0.64634982, Gradient norm: 0.10926556
INFO:root:At the start of the epoch: mem (CPU python)=42712.4375MB; mem (CPU total)=42568.97265625MB
INFO:root:[   38] Training loss: 0.64360997, Validation loss: 0.64511605, Gradient norm: 0.10213040
INFO:root:At the start of the epoch: mem (CPU python)=42750.5390625MB; mem (CPU total)=42606.09765625MB
INFO:root:[   39] Training loss: 0.64277075, Validation loss: 0.64390216, Gradient norm: 0.09780807
INFO:root:At the start of the epoch: mem (CPU python)=42788.6328125MB; mem (CPU total)=42644.4296875MB
INFO:root:[   40] Training loss: 0.64184518, Validation loss: 0.64287410, Gradient norm: 0.09790922
INFO:root:At the start of the epoch: mem (CPU python)=42826.7265625MB; mem (CPU total)=42682.5234375MB
INFO:root:[   41] Training loss: 0.64126484, Validation loss: 0.64305756, Gradient norm: 0.09299652
INFO:root:At the start of the epoch: mem (CPU python)=42864.82421875MB; mem (CPU total)=42720.171875MB
INFO:root:[   42] Training loss: 0.64047574, Validation loss: 0.64266805, Gradient norm: 0.09044236
INFO:root:At the start of the epoch: mem (CPU python)=42902.91796875MB; mem (CPU total)=42758.7734375MB
INFO:root:[   43] Training loss: 0.63933392, Validation loss: 0.64117720, Gradient norm: 0.08752465
INFO:root:At the start of the epoch: mem (CPU python)=42941.01171875MB; mem (CPU total)=42796.40234375MB
INFO:root:[   44] Training loss: 0.63846481, Validation loss: 0.64042660, Gradient norm: 0.10317831
INFO:root:At the start of the epoch: mem (CPU python)=42979.10546875MB; mem (CPU total)=42834.546875MB
INFO:root:[   45] Training loss: 0.63789804, Validation loss: 0.64013859, Gradient norm: 0.09725593
INFO:root:At the start of the epoch: mem (CPU python)=43017.203125MB; mem (CPU total)=42873.17578125MB
INFO:root:[   46] Training loss: 0.63635051, Validation loss: 0.63893747, Gradient norm: 0.09043452
INFO:root:At the start of the epoch: mem (CPU python)=43055.30078125MB; mem (CPU total)=42909.87109375MB
INFO:root:[   47] Training loss: 0.63555398, Validation loss: 0.63779215, Gradient norm: 0.09480063
INFO:root:At the start of the epoch: mem (CPU python)=43093.39453125MB; mem (CPU total)=42948.00390625MB
INFO:root:[   48] Training loss: 0.63548650, Validation loss: 0.63802299, Gradient norm: 0.09889552
INFO:root:At the start of the epoch: mem (CPU python)=43131.4921875MB; mem (CPU total)=42986.375MB
INFO:root:[   49] Training loss: 0.63444228, Validation loss: 0.63616572, Gradient norm: 0.09088471
INFO:root:At the start of the epoch: mem (CPU python)=43169.5859375MB; mem (CPU total)=43024.203125MB
INFO:root:[   50] Training loss: 0.63345842, Validation loss: 0.63524312, Gradient norm: 0.09808043
INFO:root:At the start of the epoch: mem (CPU python)=43207.6796875MB; mem (CPU total)=43062.33203125MB
INFO:root:[   51] Training loss: 0.63298716, Validation loss: 0.63540128, Gradient norm: 0.09981466
INFO:root:At the start of the epoch: mem (CPU python)=43245.7734375MB; mem (CPU total)=43100.5390625MB
INFO:root:[   52] Training loss: 0.63210355, Validation loss: 0.63409911, Gradient norm: 0.09432724
INFO:root:At the start of the epoch: mem (CPU python)=43283.875MB; mem (CPU total)=43138.390625MB
INFO:root:[   53] Training loss: 0.63198387, Validation loss: 0.63330531, Gradient norm: 0.09554052
INFO:root:At the start of the epoch: mem (CPU python)=43321.96875MB; mem (CPU total)=43177.04296875MB
INFO:root:[   54] Training loss: 0.63107077, Validation loss: 0.63268966, Gradient norm: 0.10715953
INFO:root:At the start of the epoch: mem (CPU python)=43360.0625MB; mem (CPU total)=43215.1796875MB
INFO:root:[   55] Training loss: 0.63055750, Validation loss: 0.63329480, Gradient norm: 0.09643379
INFO:root:At the start of the epoch: mem (CPU python)=43398.16015625MB; mem (CPU total)=43253.3203125MB
INFO:root:[   56] Training loss: 0.62955760, Validation loss: 0.63257102, Gradient norm: 0.09866012
INFO:root:At the start of the epoch: mem (CPU python)=43436.25390625MB; mem (CPU total)=43291.4921875MB
INFO:root:[   57] Training loss: 0.62920966, Validation loss: 0.63209565, Gradient norm: 0.09680535
INFO:root:At the start of the epoch: mem (CPU python)=43474.34765625MB; mem (CPU total)=43329.71484375MB
INFO:root:[   58] Training loss: 0.62839512, Validation loss: 0.63217745, Gradient norm: 0.09622150
INFO:root:At the start of the epoch: mem (CPU python)=43512.4453125MB; mem (CPU total)=43367.734375MB
INFO:root:[   59] Training loss: 0.62786953, Validation loss: 0.63014065, Gradient norm: 0.09835084
INFO:root:At the start of the epoch: mem (CPU python)=43550.5390625MB; mem (CPU total)=43406.1796875MB
INFO:root:[   60] Training loss: 0.62723977, Validation loss: 0.63125050, Gradient norm: 0.10562258
INFO:root:At the start of the epoch: mem (CPU python)=43588.6328125MB; mem (CPU total)=43443.96484375MB
INFO:root:[   61] Training loss: 0.62662517, Validation loss: 0.62907509, Gradient norm: 0.09091190
INFO:root:At the start of the epoch: mem (CPU python)=43626.7265625MB; mem (CPU total)=43482.078125MB
INFO:root:[   62] Training loss: 0.62596112, Validation loss: 0.62914227, Gradient norm: 0.09189168
INFO:root:At the start of the epoch: mem (CPU python)=43664.82421875MB; mem (CPU total)=43520.46875MB
INFO:root:[   63] Training loss: 0.62534574, Validation loss: 0.62699508, Gradient norm: 0.10240402
INFO:root:At the start of the epoch: mem (CPU python)=43702.921875MB; mem (CPU total)=43558.87890625MB
INFO:root:[   64] Training loss: 0.62520281, Validation loss: 0.62837189, Gradient norm: 0.09736115
INFO:root:At the start of the epoch: mem (CPU python)=43741.015625MB; mem (CPU total)=43597.046875MB
INFO:root:[   65] Training loss: 0.62493614, Validation loss: 0.62812946, Gradient norm: 0.10316141
INFO:root:At the start of the epoch: mem (CPU python)=43779.1171875MB; mem (CPU total)=43634.75MB
INFO:root:[   66] Training loss: 0.62415848, Validation loss: 0.62706568, Gradient norm: 0.09497049
INFO:root:At the start of the epoch: mem (CPU python)=43817.2109375MB; mem (CPU total)=43672.71484375MB
INFO:root:[   67] Training loss: 0.62313980, Validation loss: 0.62537799, Gradient norm: 0.10382662
INFO:root:At the start of the epoch: mem (CPU python)=43855.3046875MB; mem (CPU total)=43710.87890625MB
INFO:root:[   68] Training loss: 0.62322068, Validation loss: 0.62552252, Gradient norm: 0.09417015
INFO:root:At the start of the epoch: mem (CPU python)=43893.3984375MB; mem (CPU total)=43749.01171875MB
INFO:root:[   69] Training loss: 0.62206650, Validation loss: 0.62495852, Gradient norm: 0.09873070
INFO:root:At the start of the epoch: mem (CPU python)=43931.49609375MB; mem (CPU total)=43786.9296875MB
INFO:root:[   70] Training loss: 0.62216289, Validation loss: 0.62475516, Gradient norm: 0.09396065
INFO:root:At the start of the epoch: mem (CPU python)=43969.58984375MB; mem (CPU total)=43825.0546875MB
INFO:root:[   71] Training loss: 0.62166318, Validation loss: 0.62449289, Gradient norm: 0.11048524
INFO:root:At the start of the epoch: mem (CPU python)=44007.68359375MB; mem (CPU total)=43862.90625MB
INFO:root:[   72] Training loss: 0.62105819, Validation loss: 0.62400464, Gradient norm: 0.09228126
INFO:root:At the start of the epoch: mem (CPU python)=44045.78515625MB; mem (CPU total)=43901.02734375MB
INFO:root:[   73] Training loss: 0.62045023, Validation loss: 0.62337808, Gradient norm: 0.09652112
INFO:root:At the start of the epoch: mem (CPU python)=44083.87890625MB; mem (CPU total)=43939.37109375MB
INFO:root:[   74] Training loss: 0.62051971, Validation loss: 0.62479023, Gradient norm: 0.12269267
INFO:root:At the start of the epoch: mem (CPU python)=44121.97265625MB; mem (CPU total)=43977.29296875MB
INFO:root:[   75] Training loss: 0.61957847, Validation loss: 0.62329848, Gradient norm: 0.09683695
INFO:root:At the start of the epoch: mem (CPU python)=44160.0703125MB; mem (CPU total)=44015.390625MB
INFO:root:[   76] Training loss: 0.61892365, Validation loss: 0.62296522, Gradient norm: 0.09213739
INFO:root:At the start of the epoch: mem (CPU python)=44198.1640625MB; mem (CPU total)=44053.796875MB
INFO:root:[   77] Training loss: 0.61916166, Validation loss: 0.62299489, Gradient norm: 0.09965365
INFO:root:At the start of the epoch: mem (CPU python)=44236.2578125MB; mem (CPU total)=44091.9140625MB
INFO:root:[   78] Training loss: 0.61908918, Validation loss: 0.62223846, Gradient norm: 0.10285550
INFO:root:At the start of the epoch: mem (CPU python)=44274.3515625MB; mem (CPU total)=44130.91015625MB
INFO:root:[   79] Training loss: 0.61860756, Validation loss: 0.62107560, Gradient norm: 0.10398340
INFO:root:At the start of the epoch: mem (CPU python)=44312.453125MB; mem (CPU total)=44168.703125MB
INFO:root:[   80] Training loss: 0.61761994, Validation loss: 0.62151543, Gradient norm: 0.09468119
INFO:root:At the start of the epoch: mem (CPU python)=44350.546875MB; mem (CPU total)=44206.79296875MB
INFO:root:[   81] Training loss: 0.61710456, Validation loss: 0.62138157, Gradient norm: 0.09563497
INFO:root:At the start of the epoch: mem (CPU python)=44388.640625MB; mem (CPU total)=44245.421875MB
INFO:root:[   82] Training loss: 0.61685280, Validation loss: 0.61930780, Gradient norm: 0.10278131
INFO:root:At the start of the epoch: mem (CPU python)=44426.73828125MB; mem (CPU total)=44283.09765625MB
INFO:root:[   83] Training loss: 0.61629132, Validation loss: 0.61944447, Gradient norm: 0.10642385
INFO:root:At the start of the epoch: mem (CPU python)=44464.83203125MB; mem (CPU total)=44320.9765625MB
INFO:root:[   84] Training loss: 0.61625629, Validation loss: 0.61939987, Gradient norm: 0.10554236
INFO:root:At the start of the epoch: mem (CPU python)=44502.92578125MB; mem (CPU total)=44359.34375MB
INFO:root:[   85] Training loss: 0.61621922, Validation loss: 0.62011681, Gradient norm: 0.10642222
INFO:root:At the start of the epoch: mem (CPU python)=44541.01953125MB; mem (CPU total)=44403.69921875MB
INFO:root:[   86] Training loss: 0.61522688, Validation loss: 0.61979521, Gradient norm: 0.10565997
INFO:root:At the start of the epoch: mem (CPU python)=44579.1171875MB; mem (CPU total)=44441.0234375MB
INFO:root:[   87] Training loss: 0.61533036, Validation loss: 0.61825648, Gradient norm: 0.11028596
INFO:root:At the start of the epoch: mem (CPU python)=44617.21484375MB; mem (CPU total)=44478.08203125MB
INFO:root:[   88] Training loss: 0.61485043, Validation loss: 0.61832349, Gradient norm: 0.10664289
INFO:root:At the start of the epoch: mem (CPU python)=44655.30859375MB; mem (CPU total)=44515.921875MB
INFO:root:[   89] Training loss: 0.61510227, Validation loss: 0.61800519, Gradient norm: 0.11269076
INFO:root:At the start of the epoch: mem (CPU python)=44693.40625MB; mem (CPU total)=44554.0625MB
INFO:root:[   90] Training loss: 0.61393278, Validation loss: 0.61706593, Gradient norm: 0.10486018
INFO:root:At the start of the epoch: mem (CPU python)=44731.5MB; mem (CPU total)=44592.07421875MB
INFO:root:[   91] Training loss: 0.61366397, Validation loss: 0.61809668, Gradient norm: 0.11695696
INFO:root:At the start of the epoch: mem (CPU python)=44769.59375MB; mem (CPU total)=44630.453125MB
INFO:root:[   92] Training loss: 0.61349162, Validation loss: 0.61833170, Gradient norm: 0.10518452
INFO:root:At the start of the epoch: mem (CPU python)=44807.69140625MB; mem (CPU total)=44668.5625MB
INFO:root:[   93] Training loss: 0.61349963, Validation loss: 0.61600581, Gradient norm: 0.10335385
INFO:root:At the start of the epoch: mem (CPU python)=44845.78515625MB; mem (CPU total)=44706.671875MB
INFO:root:[   94] Training loss: 0.61301637, Validation loss: 0.61567674, Gradient norm: 0.10774767
INFO:root:At the start of the epoch: mem (CPU python)=44883.87890625MB; mem (CPU total)=44744.8203125MB
INFO:root:[   95] Training loss: 0.61256777, Validation loss: 0.61666271, Gradient norm: 0.09845893
INFO:root:At the start of the epoch: mem (CPU python)=44921.97265625MB; mem (CPU total)=44782.95703125MB
INFO:root:[   96] Training loss: 0.61237226, Validation loss: 0.61599983, Gradient norm: 0.10102660
INFO:root:At the start of the epoch: mem (CPU python)=44960.07421875MB; mem (CPU total)=44820.7890625MB
INFO:root:[   97] Training loss: 0.61206993, Validation loss: 0.61502138, Gradient norm: 0.10397592
INFO:root:At the start of the epoch: mem (CPU python)=44998.16796875MB; mem (CPU total)=44858.671875MB
INFO:root:[   98] Training loss: 0.61228878, Validation loss: 0.61619729, Gradient norm: 0.09730804
INFO:root:At the start of the epoch: mem (CPU python)=45036.26171875MB; mem (CPU total)=44897.04296875MB
INFO:root:[   99] Training loss: 0.61168765, Validation loss: 0.61665086, Gradient norm: 0.10615571
INFO:root:At the start of the epoch: mem (CPU python)=45074.359375MB; mem (CPU total)=44935.17578125MB
INFO:root:[  100] Training loss: 0.61140941, Validation loss: 0.61491394, Gradient norm: 0.11485693
INFO:root:At the start of the epoch: mem (CPU python)=45112.453125MB; mem (CPU total)=44973.56640625MB
INFO:root:[  101] Training loss: 0.61104742, Validation loss: 0.61651019, Gradient norm: 0.09864885
INFO:root:At the start of the epoch: mem (CPU python)=45150.546875MB; mem (CPU total)=45011.9453125MB
INFO:root:[  102] Training loss: 0.61044888, Validation loss: 0.61603821, Gradient norm: 0.10517005
INFO:root:At the start of the epoch: mem (CPU python)=45188.640625MB; mem (CPU total)=45049.828125MB
INFO:root:[  103] Training loss: 0.61016877, Validation loss: 0.61516578, Gradient norm: 0.10875064
INFO:root:At the start of the epoch: mem (CPU python)=45226.73828125MB; mem (CPU total)=45087.93359375MB
INFO:root:[  104] Training loss: 0.61020177, Validation loss: 0.61422361, Gradient norm: 0.09859963
INFO:root:At the start of the epoch: mem (CPU python)=45264.8359375MB; mem (CPU total)=45125.9453125MB
INFO:root:[  105] Training loss: 0.60966085, Validation loss: 0.61408763, Gradient norm: 0.09486022
INFO:root:At the start of the epoch: mem (CPU python)=45302.92578125MB; mem (CPU total)=45164.32421875MB
INFO:root:[  106] Training loss: 0.60951064, Validation loss: 0.61468490, Gradient norm: 0.10525747
INFO:root:At the start of the epoch: mem (CPU python)=45341.02734375MB; mem (CPU total)=45203.1796875MB
INFO:root:[  107] Training loss: 0.60961577, Validation loss: 0.61311588, Gradient norm: 0.11094626
INFO:root:At the start of the epoch: mem (CPU python)=45379.12109375MB; mem (CPU total)=45240.83984375MB
INFO:root:[  108] Training loss: 0.60905248, Validation loss: 0.61367703, Gradient norm: 0.10977351
INFO:root:At the start of the epoch: mem (CPU python)=45417.21484375MB; mem (CPU total)=45279.1484375MB
INFO:root:[  109] Training loss: 0.60880209, Validation loss: 0.61391834, Gradient norm: 0.10817641
INFO:root:At the start of the epoch: mem (CPU python)=45455.3125MB; mem (CPU total)=45317.51171875MB
INFO:root:[  110] Training loss: 0.60832973, Validation loss: 0.61377296, Gradient norm: 0.11112703
INFO:root:At the start of the epoch: mem (CPU python)=45493.40625MB; mem (CPU total)=45355.62890625MB
INFO:root:[  111] Training loss: 0.60807423, Validation loss: 0.61186553, Gradient norm: 0.11618193
INFO:root:At the start of the epoch: mem (CPU python)=45531.5MB; mem (CPU total)=45393.9765625MB
INFO:root:[  112] Training loss: 0.60849507, Validation loss: 0.61300964, Gradient norm: 0.10042422
INFO:root:At the start of the epoch: mem (CPU python)=45569.59375MB; mem (CPU total)=45431.609375MB
INFO:root:[  113] Training loss: 0.60811710, Validation loss: 0.61272027, Gradient norm: 0.11819476
INFO:root:At the start of the epoch: mem (CPU python)=45607.69140625MB; mem (CPU total)=45469.98046875MB
INFO:root:[  114] Training loss: 0.60814983, Validation loss: 0.61230384, Gradient norm: 0.10279881
INFO:root:At the start of the epoch: mem (CPU python)=45645.7890625MB; mem (CPU total)=45507.77734375MB
INFO:root:[  115] Training loss: 0.60739166, Validation loss: 0.61210674, Gradient norm: 0.10933338
INFO:root:At the start of the epoch: mem (CPU python)=45683.8828125MB; mem (CPU total)=45545.984375MB
INFO:root:[  116] Training loss: 0.60729964, Validation loss: 0.61340905, Gradient norm: 0.10087720
INFO:root:At the start of the epoch: mem (CPU python)=45721.98046875MB; mem (CPU total)=45584.125MB
INFO:root:[  117] Training loss: 0.60722695, Validation loss: 0.61262815, Gradient norm: 0.11446860
INFO:root:At the start of the epoch: mem (CPU python)=45760.07421875MB; mem (CPU total)=45622.23828125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  118] Training loss: 0.60690952, Validation loss: 0.61213041, Gradient norm: 0.10749771
INFO:root:At the start of the epoch: mem (CPU python)=45798.171875MB; mem (CPU total)=45660.48828125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  119] Training loss: 0.60574535, Validation loss: 0.61053098, Gradient norm: 0.08522779
INFO:root:At the start of the epoch: mem (CPU python)=45836.265625MB; mem (CPU total)=45698.60546875MB
INFO:root:[  120] Training loss: 0.60487606, Validation loss: 0.61025422, Gradient norm: 0.08560820
INFO:root:At the start of the epoch: mem (CPU python)=45874.36328125MB; mem (CPU total)=45736.56640625MB
INFO:root:[  121] Training loss: 0.60490839, Validation loss: 0.61093481, Gradient norm: 0.08503693
INFO:root:At the start of the epoch: mem (CPU python)=45912.45703125MB; mem (CPU total)=45774.93359375MB
INFO:root:[  122] Training loss: 0.60488824, Validation loss: 0.61023015, Gradient norm: 0.08220049
INFO:root:At the start of the epoch: mem (CPU python)=45950.5546875MB; mem (CPU total)=45811.40234375MB
INFO:root:[  123] Training loss: 0.60480158, Validation loss: 0.61095441, Gradient norm: 0.07727562
INFO:root:At the start of the epoch: mem (CPU python)=45988.65234375MB; mem (CPU total)=45849.5MB
INFO:root:[  124] Training loss: 0.60506423, Validation loss: 0.61054742, Gradient norm: 0.08149464
INFO:root:At the start of the epoch: mem (CPU python)=46026.74609375MB; mem (CPU total)=45888.0390625MB
INFO:root:[  125] Training loss: 0.60452785, Validation loss: 0.61079838, Gradient norm: 0.08456507
INFO:root:At the start of the epoch: mem (CPU python)=46064.83984375MB; mem (CPU total)=45926.1328125MB
INFO:root:[  126] Training loss: 0.60422491, Validation loss: 0.61070790, Gradient norm: 0.07971153
INFO:root:At the start of the epoch: mem (CPU python)=46102.9375MB; mem (CPU total)=45965.0MB
INFO:root:[  127] Training loss: 0.60403696, Validation loss: 0.61018577, Gradient norm: 0.08311320
INFO:root:At the start of the epoch: mem (CPU python)=46141.03125MB; mem (CPU total)=46003.0859375MB
INFO:root:[  128] Training loss: 0.60383627, Validation loss: 0.61056284, Gradient norm: 0.08051833
INFO:root:At the start of the epoch: mem (CPU python)=46179.125MB; mem (CPU total)=46040.3828125MB
INFO:root:[  129] Training loss: 0.60423535, Validation loss: 0.60992025, Gradient norm: 0.08376391
INFO:root:At the start of the epoch: mem (CPU python)=46217.21875MB; mem (CPU total)=46078.4921875MB
INFO:root:[  130] Training loss: 0.60461438, Validation loss: 0.61003965, Gradient norm: 0.09020757
INFO:root:At the start of the epoch: mem (CPU python)=46255.31640625MB; mem (CPU total)=46116.9453125MB
INFO:root:[  131] Training loss: 0.60391546, Validation loss: 0.60914227, Gradient norm: 0.08740656
INFO:root:At the start of the epoch: mem (CPU python)=46293.4140625MB; mem (CPU total)=46154.875MB
INFO:root:[  132] Training loss: 0.60406763, Validation loss: 0.60981630, Gradient norm: 0.08780041
INFO:root:At the start of the epoch: mem (CPU python)=46331.5078125MB; mem (CPU total)=46192.96484375MB
INFO:root:[  133] Training loss: 0.60383813, Validation loss: 0.61025745, Gradient norm: 0.08628208
INFO:root:At the start of the epoch: mem (CPU python)=46369.609375MB; mem (CPU total)=46231.30859375MB
INFO:root:[  134] Training loss: 0.60411497, Validation loss: 0.60958534, Gradient norm: 0.08177327
INFO:root:At the start of the epoch: mem (CPU python)=46407.703125MB; mem (CPU total)=46269.4375MB
INFO:root:[  135] Training loss: 0.60374861, Validation loss: 0.61078931, Gradient norm: 0.09051282
INFO:root:At the start of the epoch: mem (CPU python)=46445.796875MB; mem (CPU total)=46308.64453125MB
INFO:root:[  136] Training loss: 0.60382391, Validation loss: 0.61000794, Gradient norm: 0.08581913
INFO:root:At the start of the epoch: mem (CPU python)=46483.890625MB; mem (CPU total)=46346.9765625MB
INFO:root:[  137] Training loss: 0.60368222, Validation loss: 0.61071881, Gradient norm: 0.09256502
INFO:root:At the start of the epoch: mem (CPU python)=46521.98828125MB; mem (CPU total)=46384.8125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  138] Training loss: 0.60358391, Validation loss: 0.60936719, Gradient norm: 0.08600650
INFO:root:At the start of the epoch: mem (CPU python)=46560.0859375MB; mem (CPU total)=46423.19140625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  139] Training loss: 0.60344759, Validation loss: 0.61056273, Gradient norm: 0.08022360
INFO:root:At the start of the epoch: mem (CPU python)=46598.1796875MB; mem (CPU total)=46461.140625MB
INFO:root:[  140] Training loss: 0.60329212, Validation loss: 0.60916429, Gradient norm: 0.07632557
INFO:root:At the start of the epoch: mem (CPU python)=46636.27734375MB; mem (CPU total)=46499.48046875MB
INFO:root:EP 140: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=46674.37109375MB; mem (CPU total)=46537.375MB
INFO:root:Training the model took 10331.558s.
INFO:root:Emptying the cuda cache took 0.084s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85549
INFO:root:EnergyScoreTrain: 0.60397
INFO:root:CRPSTrain: 0.55347
INFO:root:Gaussian NLLTrain: 4.69267
INFO:root:CoverageTrain: 0.75279
INFO:root:IntervalWidthTrain: 3.2013
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86423
INFO:root:EnergyScoreValidation: 0.60981
INFO:root:CRPSValidation: 0.55802
INFO:root:Gaussian NLLValidation: 4.71671
INFO:root:CoverageValidation: 0.75016
INFO:root:IntervalWidthValidation: 3.20033
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86574
INFO:root:EnergyScoreTest: 0.61086
INFO:root:CRPSTest: 0.55905
INFO:root:Gaussian NLLTest: 4.73718
INFO:root:CoverageTest: 0.74876
INFO:root:IntervalWidthTest: 3.19394
INFO:root:After validation: mem (CPU python)=46717.1875MB; mem (CPU total)=46580.37890625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=46717.1875MB; mem (CPU total)=46580.34765625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=46717.5546875MB; mem (CPU total)=46580.59375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=46717.6875MB; mem (CPU total)=46580.81640625MB
INFO:root:[    1] Training loss: 0.80005218, Validation loss: 0.72879554, Gradient norm: 0.55076181
INFO:root:At the start of the epoch: mem (CPU python)=46755.80859375MB; mem (CPU total)=46618.60546875MB
INFO:root:[    2] Training loss: 0.72372441, Validation loss: 0.72247591, Gradient norm: 0.41517335
INFO:root:At the start of the epoch: mem (CPU python)=46793.90234375MB; mem (CPU total)=46657.25MB
INFO:root:[    3] Training loss: 0.72124658, Validation loss: 0.72041438, Gradient norm: 0.33390127
INFO:root:At the start of the epoch: mem (CPU python)=46832.0MB; mem (CPU total)=46695.59765625MB
INFO:root:[    4] Training loss: 0.72050189, Validation loss: 0.72098947, Gradient norm: 0.32028176
INFO:root:At the start of the epoch: mem (CPU python)=46870.09375MB; mem (CPU total)=46733.94140625MB
INFO:root:[    5] Training loss: 0.71998927, Validation loss: 0.72095190, Gradient norm: 0.21081439
INFO:root:At the start of the epoch: mem (CPU python)=46908.1875MB; mem (CPU total)=46772.00390625MB
INFO:root:[    6] Training loss: 0.71981853, Validation loss: 0.72004672, Gradient norm: 0.26237095
INFO:root:At the start of the epoch: mem (CPU python)=46946.2890625MB; mem (CPU total)=46810.125MB
INFO:root:[    7] Training loss: 0.71944213, Validation loss: 0.71927362, Gradient norm: 0.21551303
INFO:root:At the start of the epoch: mem (CPU python)=46984.3828125MB; mem (CPU total)=46848.00390625MB
INFO:root:[    8] Training loss: 0.71887858, Validation loss: 0.71817955, Gradient norm: 0.20642238
INFO:root:At the start of the epoch: mem (CPU python)=47022.4765625MB; mem (CPU total)=46886.3515625MB
INFO:root:[    9] Training loss: 0.71792975, Validation loss: 0.71838619, Gradient norm: 0.15098948
INFO:root:At the start of the epoch: mem (CPU python)=47060.5703125MB; mem (CPU total)=46924.5234375MB
INFO:root:[   10] Training loss: 0.71610928, Validation loss: 0.71336508, Gradient norm: 0.16185077
INFO:root:At the start of the epoch: mem (CPU python)=47098.66796875MB; mem (CPU total)=46963.28125MB
INFO:root:[   11] Training loss: 0.71064006, Validation loss: 0.70726033, Gradient norm: 0.09368287
INFO:root:At the start of the epoch: mem (CPU python)=47136.76171875MB; mem (CPU total)=47001.38671875MB
INFO:root:[   12] Training loss: 0.70341785, Validation loss: 0.70169301, Gradient norm: 0.13775335
INFO:root:At the start of the epoch: mem (CPU python)=47174.859375MB; mem (CPU total)=47039.46875MB
INFO:root:[   13] Training loss: 0.69756939, Validation loss: 0.69500826, Gradient norm: 0.12654959
INFO:root:At the start of the epoch: mem (CPU python)=47212.95703125MB; mem (CPU total)=47077.07421875MB
INFO:root:[   14] Training loss: 0.69269347, Validation loss: 0.69148715, Gradient norm: 0.12444726
INFO:root:At the start of the epoch: mem (CPU python)=47251.05078125MB; mem (CPU total)=47115.203125MB
INFO:root:[   15] Training loss: 0.68813431, Validation loss: 0.68703014, Gradient norm: 0.11582550
INFO:root:At the start of the epoch: mem (CPU python)=47289.14453125MB; mem (CPU total)=47153.53515625MB
INFO:root:[   16] Training loss: 0.68405515, Validation loss: 0.68346419, Gradient norm: 0.10521369
INFO:root:At the start of the epoch: mem (CPU python)=47327.23828125MB; mem (CPU total)=47191.671875MB
INFO:root:[   17] Training loss: 0.68011025, Validation loss: 0.67969021, Gradient norm: 0.11101034
INFO:root:At the start of the epoch: mem (CPU python)=47365.3359375MB; mem (CPU total)=47229.53125MB
INFO:root:[   18] Training loss: 0.67690805, Validation loss: 0.67620022, Gradient norm: 0.12095241
INFO:root:At the start of the epoch: mem (CPU python)=47403.43359375MB; mem (CPU total)=47267.9375MB
INFO:root:[   19] Training loss: 0.67388749, Validation loss: 0.67357026, Gradient norm: 0.11565034
INFO:root:At the start of the epoch: mem (CPU python)=47441.52734375MB; mem (CPU total)=47306.29296875MB
INFO:root:[   20] Training loss: 0.67083476, Validation loss: 0.67067214, Gradient norm: 0.11015953
INFO:root:At the start of the epoch: mem (CPU python)=47479.625MB; mem (CPU total)=47344.25390625MB
INFO:root:[   21] Training loss: 0.66842006, Validation loss: 0.66861843, Gradient norm: 0.12907815
INFO:root:At the start of the epoch: mem (CPU python)=47517.72265625MB; mem (CPU total)=47382.109375MB
INFO:root:[   22] Training loss: 0.66615626, Validation loss: 0.66756692, Gradient norm: 0.13143005
INFO:root:At the start of the epoch: mem (CPU python)=47555.81640625MB; mem (CPU total)=47419.94921875MB
INFO:root:[   23] Training loss: 0.66383046, Validation loss: 0.66435793, Gradient norm: 0.12069055
INFO:root:At the start of the epoch: mem (CPU python)=47593.9140625MB; mem (CPU total)=47458.046875MB
INFO:root:[   24] Training loss: 0.66219447, Validation loss: 0.66372642, Gradient norm: 0.12167847
INFO:root:At the start of the epoch: mem (CPU python)=47632.0078125MB; mem (CPU total)=47496.171875MB
INFO:root:[   25] Training loss: 0.66043064, Validation loss: 0.66236143, Gradient norm: 0.13083306
INFO:root:At the start of the epoch: mem (CPU python)=47670.1015625MB; mem (CPU total)=47534.00390625MB
INFO:root:[   26] Training loss: 0.65882945, Validation loss: 0.65959111, Gradient norm: 0.14584862
INFO:root:At the start of the epoch: mem (CPU python)=47708.1953125MB; mem (CPU total)=47571.93359375MB
INFO:root:[   27] Training loss: 0.65744732, Validation loss: 0.65882651, Gradient norm: 0.11888756
INFO:root:At the start of the epoch: mem (CPU python)=47746.29296875MB; mem (CPU total)=47610.0703125MB
INFO:root:[   28] Training loss: 0.65597828, Validation loss: 0.65743957, Gradient norm: 0.12708802
INFO:root:At the start of the epoch: mem (CPU python)=47784.38671875MB; mem (CPU total)=47648.4609375MB
INFO:root:[   29] Training loss: 0.65468138, Validation loss: 0.65573809, Gradient norm: 0.12506800
INFO:root:At the start of the epoch: mem (CPU python)=47822.484375MB; mem (CPU total)=47686.32421875MB
INFO:root:[   30] Training loss: 0.65363417, Validation loss: 0.65469251, Gradient norm: 0.16202097
INFO:root:At the start of the epoch: mem (CPU python)=47860.58203125MB; mem (CPU total)=47724.75MB
INFO:root:[   31] Training loss: 0.65245673, Validation loss: 0.65397953, Gradient norm: 0.10444318
INFO:root:At the start of the epoch: mem (CPU python)=47898.67578125MB; mem (CPU total)=47763.08984375MB
INFO:root:[   32] Training loss: 0.65141452, Validation loss: 0.65300222, Gradient norm: 0.11875854
INFO:root:At the start of the epoch: mem (CPU python)=47936.76953125MB; mem (CPU total)=47800.93359375MB
INFO:root:[   33] Training loss: 0.65028323, Validation loss: 0.65248570, Gradient norm: 0.12542334
INFO:root:At the start of the epoch: mem (CPU python)=47974.86328125MB; mem (CPU total)=47839.35546875MB
INFO:root:[   34] Training loss: 0.64923598, Validation loss: 0.65069519, Gradient norm: 0.09909015
INFO:root:At the start of the epoch: mem (CPU python)=48012.9609375MB; mem (CPU total)=47877.76171875MB
INFO:root:[   35] Training loss: 0.64824316, Validation loss: 0.64992835, Gradient norm: 0.11236930
INFO:root:At the start of the epoch: mem (CPU python)=48051.0546875MB; mem (CPU total)=47916.42578125MB
INFO:root:[   36] Training loss: 0.64746618, Validation loss: 0.64994710, Gradient norm: 0.13618516
INFO:root:At the start of the epoch: mem (CPU python)=48089.1484375MB; mem (CPU total)=47954.5703125MB
INFO:root:[   37] Training loss: 0.64637726, Validation loss: 0.64858835, Gradient norm: 0.11665516
INFO:root:At the start of the epoch: mem (CPU python)=48127.25MB; mem (CPU total)=47991.54296875MB
INFO:root:[   38] Training loss: 0.64542372, Validation loss: 0.64850688, Gradient norm: 0.12238652
INFO:root:At the start of the epoch: mem (CPU python)=48165.34375MB; mem (CPU total)=48029.4921875MB
INFO:root:[   39] Training loss: 0.64488466, Validation loss: 0.64809860, Gradient norm: 0.12728829
INFO:root:At the start of the epoch: mem (CPU python)=48203.4375MB; mem (CPU total)=48067.53515625MB
INFO:root:[   40] Training loss: 0.64396570, Validation loss: 0.64667901, Gradient norm: 0.12541216
INFO:root:At the start of the epoch: mem (CPU python)=48241.53515625MB; mem (CPU total)=48105.95703125MB
INFO:root:[   41] Training loss: 0.64348724, Validation loss: 0.64573372, Gradient norm: 0.15989614
INFO:root:At the start of the epoch: mem (CPU python)=48279.62890625MB; mem (CPU total)=48144.15234375MB
INFO:root:[   42] Training loss: 0.64267991, Validation loss: 0.64496139, Gradient norm: 0.12399992
INFO:root:At the start of the epoch: mem (CPU python)=48317.72265625MB; mem (CPU total)=48181.74609375MB
INFO:root:[   43] Training loss: 0.64199523, Validation loss: 0.64464380, Gradient norm: 0.13051720
INFO:root:At the start of the epoch: mem (CPU python)=48355.81640625MB; mem (CPU total)=48219.58203125MB
INFO:root:[   44] Training loss: 0.64105721, Validation loss: 0.64323919, Gradient norm: 0.14754460
INFO:root:At the start of the epoch: mem (CPU python)=48393.9140625MB; mem (CPU total)=48257.90234375MB
INFO:root:[   45] Training loss: 0.64030923, Validation loss: 0.64405657, Gradient norm: 0.15281924
INFO:root:At the start of the epoch: mem (CPU python)=48432.0078125MB; mem (CPU total)=48295.75390625MB
INFO:root:[   46] Training loss: 0.63964613, Validation loss: 0.64304026, Gradient norm: 0.12754637
INFO:root:At the start of the epoch: mem (CPU python)=48470.10546875MB; mem (CPU total)=48335.26953125MB
INFO:root:[   47] Training loss: 0.63879942, Validation loss: 0.64158882, Gradient norm: 0.13645604
INFO:root:At the start of the epoch: mem (CPU python)=48508.203125MB; mem (CPU total)=48373.625MB
INFO:root:[   48] Training loss: 0.63800605, Validation loss: 0.64101424, Gradient norm: 0.13579246
INFO:root:At the start of the epoch: mem (CPU python)=48546.296875MB; mem (CPU total)=48411.47265625MB
INFO:root:[   49] Training loss: 0.63781904, Validation loss: 0.64029901, Gradient norm: 0.14247114
INFO:root:At the start of the epoch: mem (CPU python)=48584.390625MB; mem (CPU total)=48449.8671875MB
INFO:root:[   50] Training loss: 0.63684227, Validation loss: 0.64022034, Gradient norm: 0.12011053
INFO:root:At the start of the epoch: mem (CPU python)=48622.484375MB; mem (CPU total)=48488.234375MB
INFO:root:[   51] Training loss: 0.63619866, Validation loss: 0.63872800, Gradient norm: 0.15591751
INFO:root:At the start of the epoch: mem (CPU python)=48660.58203125MB; mem (CPU total)=48526.3515625MB
INFO:root:[   52] Training loss: 0.63578443, Validation loss: 0.63896238, Gradient norm: 0.16532205
INFO:root:At the start of the epoch: mem (CPU python)=48698.67578125MB; mem (CPU total)=48564.64453125MB
INFO:root:[   53] Training loss: 0.63511868, Validation loss: 0.63909881, Gradient norm: 0.14895052
INFO:root:At the start of the epoch: mem (CPU python)=48736.76953125MB; mem (CPU total)=48602.5MB
INFO:root:[   54] Training loss: 0.63445977, Validation loss: 0.63808180, Gradient norm: 0.13465087
INFO:root:At the start of the epoch: mem (CPU python)=48774.87109375MB; mem (CPU total)=48640.6015625MB
INFO:root:[   55] Training loss: 0.63418690, Validation loss: 0.63779432, Gradient norm: 0.14047874
INFO:root:At the start of the epoch: mem (CPU python)=48812.96484375MB; mem (CPU total)=48678.6875MB
INFO:root:[   56] Training loss: 0.63329552, Validation loss: 0.63733768, Gradient norm: 0.13461699
INFO:root:At the start of the epoch: mem (CPU python)=48851.05859375MB; mem (CPU total)=48716.828125MB
INFO:root:[   57] Training loss: 0.63307720, Validation loss: 0.63699470, Gradient norm: 0.13219923
INFO:root:At the start of the epoch: mem (CPU python)=48889.15625MB; mem (CPU total)=48755.21484375MB
INFO:root:[   58] Training loss: 0.63258933, Validation loss: 0.63594656, Gradient norm: 0.17298894
INFO:root:At the start of the epoch: mem (CPU python)=48927.25MB; mem (CPU total)=48793.51953125MB
INFO:root:[   59] Training loss: 0.63219975, Validation loss: 0.63574530, Gradient norm: 0.15590204
INFO:root:At the start of the epoch: mem (CPU python)=48965.34375MB; mem (CPU total)=48831.90625MB
INFO:root:[   60] Training loss: 0.63147727, Validation loss: 0.63576455, Gradient norm: 0.14144198
INFO:root:At the start of the epoch: mem (CPU python)=49003.4375MB; mem (CPU total)=48870.0MB
INFO:root:[   61] Training loss: 0.63123616, Validation loss: 0.63471867, Gradient norm: 0.18738522
INFO:root:At the start of the epoch: mem (CPU python)=49041.5390625MB; mem (CPU total)=48908.05078125MB
INFO:root:[   62] Training loss: 0.63070457, Validation loss: 0.63483930, Gradient norm: 0.17495256
INFO:root:At the start of the epoch: mem (CPU python)=49079.6328125MB; mem (CPU total)=48945.89453125MB
INFO:root:[   63] Training loss: 0.63003832, Validation loss: 0.63472873, Gradient norm: 0.16299749
INFO:root:At the start of the epoch: mem (CPU python)=49117.7265625MB; mem (CPU total)=48983.734375MB
INFO:root:[   64] Training loss: 0.62972189, Validation loss: 0.63410296, Gradient norm: 0.18559330
INFO:root:At the start of the epoch: mem (CPU python)=49155.82421875MB; mem (CPU total)=49021.609375MB
INFO:root:[   65] Training loss: 0.62922108, Validation loss: 0.63320641, Gradient norm: 0.14938994
INFO:root:At the start of the epoch: mem (CPU python)=49193.91796875MB; mem (CPU total)=49059.5078125MB
INFO:root:[   66] Training loss: 0.62888421, Validation loss: 0.63349555, Gradient norm: 0.16135760
INFO:root:At the start of the epoch: mem (CPU python)=49232.01171875MB; mem (CPU total)=49097.42578125MB
INFO:root:[   67] Training loss: 0.62856748, Validation loss: 0.63294892, Gradient norm: 0.18638728
INFO:root:At the start of the epoch: mem (CPU python)=49270.10546875MB; mem (CPU total)=49135.5MB
INFO:root:[   68] Training loss: 0.62811554, Validation loss: 0.63266450, Gradient norm: 0.18577054
INFO:root:At the start of the epoch: mem (CPU python)=49308.203125MB; mem (CPU total)=49173.3984375MB
INFO:root:[   69] Training loss: 0.62767315, Validation loss: 0.63250989, Gradient norm: 0.15053604
INFO:root:At the start of the epoch: mem (CPU python)=49346.296875MB; mem (CPU total)=49211.296875MB
INFO:root:[   70] Training loss: 0.62728999, Validation loss: 0.63248868, Gradient norm: 0.21011752
INFO:root:At the start of the epoch: mem (CPU python)=49384.390625MB; mem (CPU total)=49249.66015625MB
INFO:root:[   71] Training loss: 0.62693912, Validation loss: 0.63157393, Gradient norm: 0.20809013
INFO:root:At the start of the epoch: mem (CPU python)=49422.4921875MB; mem (CPU total)=49287.8046875MB
INFO:root:[   72] Training loss: 0.62652879, Validation loss: 0.63113062, Gradient norm: 0.17263894
INFO:root:At the start of the epoch: mem (CPU python)=49460.5859375MB; mem (CPU total)=49325.94921875MB
INFO:root:[   73] Training loss: 0.62619902, Validation loss: 0.63038258, Gradient norm: 0.17656500
INFO:root:At the start of the epoch: mem (CPU python)=49498.6796875MB; mem (CPU total)=49364.05078125MB
INFO:root:[   74] Training loss: 0.62577417, Validation loss: 0.63038085, Gradient norm: 0.20557139
INFO:root:At the start of the epoch: mem (CPU python)=49536.77734375MB; mem (CPU total)=49401.890625MB
INFO:root:[   75] Training loss: 0.62547442, Validation loss: 0.62939821, Gradient norm: 0.18180711
INFO:root:At the start of the epoch: mem (CPU python)=49574.87109375MB; mem (CPU total)=49440.0078125MB
INFO:root:[   76] Training loss: 0.62524919, Validation loss: 0.63008374, Gradient norm: 0.22172059
INFO:root:At the start of the epoch: mem (CPU python)=49612.96484375MB; mem (CPU total)=49478.3515625MB
INFO:root:[   77] Training loss: 0.62483092, Validation loss: 0.62992530, Gradient norm: 0.19987089
INFO:root:At the start of the epoch: mem (CPU python)=49651.05859375MB; mem (CPU total)=49516.46875MB
INFO:root:[   78] Training loss: 0.62454232, Validation loss: 0.62986772, Gradient norm: 0.21079193
INFO:root:At the start of the epoch: mem (CPU python)=49689.16015625MB; mem (CPU total)=49554.875MB
INFO:root:[   79] Training loss: 0.62409619, Validation loss: 0.62863762, Gradient norm: 0.21091023
INFO:root:At the start of the epoch: mem (CPU python)=49727.25390625MB; mem (CPU total)=49592.95703125MB
INFO:root:[   80] Training loss: 0.62351269, Validation loss: 0.62921244, Gradient norm: 0.25549370
INFO:root:At the start of the epoch: mem (CPU python)=49765.34765625MB; mem (CPU total)=49630.40234375MB
INFO:root:[   81] Training loss: 0.62342178, Validation loss: 0.62919490, Gradient norm: 0.20647280
INFO:root:At the start of the epoch: mem (CPU python)=49803.4453125MB; mem (CPU total)=49668.28125MB
INFO:root:[   82] Training loss: 0.62325075, Validation loss: 0.62797494, Gradient norm: 0.19641151
INFO:root:At the start of the epoch: mem (CPU python)=49841.5390625MB; mem (CPU total)=49705.97265625MB
INFO:root:[   83] Training loss: 0.62259549, Validation loss: 0.62804055, Gradient norm: 0.21500921
INFO:root:At the start of the epoch: mem (CPU python)=49879.6328125MB; mem (CPU total)=49744.06640625MB
INFO:root:[   84] Training loss: 0.62239466, Validation loss: 0.62831853, Gradient norm: 0.21881948
INFO:root:At the start of the epoch: mem (CPU python)=49917.7265625MB; mem (CPU total)=49782.42578125MB
INFO:root:[   85] Training loss: 0.62242203, Validation loss: 0.62776419, Gradient norm: 0.22465346
INFO:root:At the start of the epoch: mem (CPU python)=49955.82421875MB; mem (CPU total)=49820.59375MB
INFO:root:[   86] Training loss: 0.62198479, Validation loss: 0.62710394, Gradient norm: 0.23269137
INFO:root:At the start of the epoch: mem (CPU python)=49993.91796875MB; mem (CPU total)=49858.703125MB
INFO:root:[   87] Training loss: 0.62171697, Validation loss: 0.62766878, Gradient norm: 0.19379825
INFO:root:At the start of the epoch: mem (CPU python)=50032.015625MB; mem (CPU total)=49896.81640625MB
INFO:root:[   88] Training loss: 0.62154478, Validation loss: 0.62849120, Gradient norm: 0.25067407
INFO:root:At the start of the epoch: mem (CPU python)=50070.11328125MB; mem (CPU total)=49934.94921875MB
INFO:root:[   89] Training loss: 0.62109131, Validation loss: 0.62732536, Gradient norm: 0.33167972
INFO:root:At the start of the epoch: mem (CPU python)=50108.20703125MB; mem (CPU total)=49973.06640625MB
INFO:root:[   90] Training loss: 0.62075996, Validation loss: 0.62672714, Gradient norm: 0.26202211
INFO:root:At the start of the epoch: mem (CPU python)=50146.30078125MB; mem (CPU total)=50011.37890625MB
INFO:root:[   91] Training loss: 0.62087632, Validation loss: 0.62737832, Gradient norm: 0.26130778
INFO:root:At the start of the epoch: mem (CPU python)=50184.3984375MB; mem (CPU total)=50049.4609375MB
INFO:root:[   92] Training loss: 0.62048602, Validation loss: 0.62635754, Gradient norm: 0.30888035
INFO:root:At the start of the epoch: mem (CPU python)=50222.4921875MB; mem (CPU total)=50087.0859375MB
INFO:root:[   93] Training loss: 0.62050274, Validation loss: 0.62586758, Gradient norm: 0.28473647
INFO:root:At the start of the epoch: mem (CPU python)=50260.5859375MB; mem (CPU total)=50125.52734375MB
INFO:root:[   94] Training loss: 0.61986827, Validation loss: 0.62614542, Gradient norm: 0.24328722
INFO:root:At the start of the epoch: mem (CPU python)=50298.6875MB; mem (CPU total)=50163.68359375MB
INFO:root:[   95] Training loss: 0.61982300, Validation loss: 0.62701716, Gradient norm: 0.29905553
INFO:root:At the start of the epoch: mem (CPU python)=50336.78515625MB; mem (CPU total)=50201.79296875MB
INFO:root:[   96] Training loss: 0.61971219, Validation loss: 0.62588626, Gradient norm: 0.28772780
INFO:root:At the start of the epoch: mem (CPU python)=50374.87890625MB; mem (CPU total)=50240.60546875MB
INFO:root:[   97] Training loss: 0.61939479, Validation loss: 0.62523872, Gradient norm: 0.37485279
INFO:root:At the start of the epoch: mem (CPU python)=50412.97265625MB; mem (CPU total)=50278.22265625MB
INFO:root:[   98] Training loss: 0.61905794, Validation loss: 0.62590251, Gradient norm: 0.34123734
INFO:root:At the start of the epoch: mem (CPU python)=50451.0703125MB; mem (CPU total)=50317.60546875MB
INFO:root:[   99] Training loss: 0.61884495, Validation loss: 0.62466891, Gradient norm: 0.28948654
INFO:root:At the start of the epoch: mem (CPU python)=50489.1640625MB; mem (CPU total)=50356.13671875MB
INFO:root:[  100] Training loss: 0.61861783, Validation loss: 0.62543914, Gradient norm: 0.34843675
INFO:root:At the start of the epoch: mem (CPU python)=50527.2578125MB; mem (CPU total)=50394.25390625MB
INFO:root:[  101] Training loss: 0.61831986, Validation loss: 0.62575933, Gradient norm: 0.35402938
INFO:root:At the start of the epoch: mem (CPU python)=50565.3515625MB; mem (CPU total)=50432.3828125MB
INFO:root:[  102] Training loss: 0.61821909, Validation loss: 0.62456239, Gradient norm: 0.33466018
INFO:root:At the start of the epoch: mem (CPU python)=50603.44921875MB; mem (CPU total)=50470.30078125MB
INFO:root:[  103] Training loss: 0.61798028, Validation loss: 0.62441499, Gradient norm: 0.35657654
INFO:root:At the start of the epoch: mem (CPU python)=50641.546875MB; mem (CPU total)=50509.41796875MB
INFO:root:[  104] Training loss: 0.61777437, Validation loss: 0.62528688, Gradient norm: 0.36535765
INFO:root:At the start of the epoch: mem (CPU python)=50679.640625MB; mem (CPU total)=50547.7734375MB
INFO:root:[  105] Training loss: 0.61748772, Validation loss: 0.62448231, Gradient norm: 0.37004889
INFO:root:At the start of the epoch: mem (CPU python)=50717.73828125MB; mem (CPU total)=50585.6171875MB
INFO:root:[  106] Training loss: 0.61752043, Validation loss: 0.62514670, Gradient norm: 0.48944290
INFO:root:At the start of the epoch: mem (CPU python)=50755.83203125MB; mem (CPU total)=50623.44921875MB
INFO:root:[  107] Training loss: 0.61732273, Validation loss: 0.62415908, Gradient norm: 0.37976639
INFO:root:At the start of the epoch: mem (CPU python)=50793.92578125MB; mem (CPU total)=50661.51171875MB
INFO:root:[  108] Training loss: 0.61674296, Validation loss: 0.62345779, Gradient norm: 0.44726868
INFO:root:At the start of the epoch: mem (CPU python)=50832.0234375MB; mem (CPU total)=50699.609375MB
INFO:root:[  109] Training loss: 0.61685419, Validation loss: 0.62460081, Gradient norm: 0.32893741
INFO:root:At the start of the epoch: mem (CPU python)=50870.1171875MB; mem (CPU total)=50737.74609375MB
INFO:root:[  110] Training loss: 0.61636414, Validation loss: 0.62493461, Gradient norm: 0.41555458
INFO:root:At the start of the epoch: mem (CPU python)=50908.2109375MB; mem (CPU total)=50776.375MB
INFO:root:[  111] Training loss: 0.61607760, Validation loss: 0.62403839, Gradient norm: 0.42091577
INFO:root:At the start of the epoch: mem (CPU python)=50946.30859375MB; mem (CPU total)=50814.0390625MB
INFO:root:[  112] Training loss: 0.61632476, Validation loss: 0.62360470, Gradient norm: 0.46789019
INFO:root:At the start of the epoch: mem (CPU python)=50984.40625MB; mem (CPU total)=50852.09375MB
INFO:root:[  113] Training loss: 0.61599574, Validation loss: 0.62236978, Gradient norm: 0.44107060
INFO:root:At the start of the epoch: mem (CPU python)=51022.5MB; mem (CPU total)=50890.2109375MB
INFO:root:[  114] Training loss: 0.61618812, Validation loss: 0.62271741, Gradient norm: 0.40788626
INFO:root:At the start of the epoch: mem (CPU python)=51060.59375MB; mem (CPU total)=50928.32421875MB
INFO:root:[  115] Training loss: 0.61580904, Validation loss: 0.62402480, Gradient norm: 0.49739798
INFO:root:At the start of the epoch: mem (CPU python)=51098.69140625MB; mem (CPU total)=50966.4609375MB
INFO:root:[  116] Training loss: 0.61575632, Validation loss: 0.62357207, Gradient norm: 0.62403661
INFO:root:At the start of the epoch: mem (CPU python)=51136.78515625MB; mem (CPU total)=51004.58984375MB
INFO:root:[  117] Training loss: 0.61556428, Validation loss: 0.62255040, Gradient norm: 0.53130232
INFO:root:At the start of the epoch: mem (CPU python)=51174.87890625MB; mem (CPU total)=51042.42578125MB
INFO:root:[  118] Training loss: 0.61521097, Validation loss: 0.62337600, Gradient norm: 0.50905961
INFO:root:At the start of the epoch: mem (CPU python)=51212.97265625MB; mem (CPU total)=51081.0546875MB
INFO:root:[  119] Training loss: 0.61507795, Validation loss: 0.62272321, Gradient norm: 0.50336878
INFO:root:At the start of the epoch: mem (CPU python)=51251.07421875MB; mem (CPU total)=51119.41015625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  120] Training loss: 0.61505039, Validation loss: 0.62395572, Gradient norm: 0.54512154
INFO:root:At the start of the epoch: mem (CPU python)=51289.16796875MB; mem (CPU total)=51157.2578125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  121] Training loss: 0.61425197, Validation loss: 0.62181930, Gradient norm: 0.31460633
INFO:root:At the start of the epoch: mem (CPU python)=51327.26171875MB; mem (CPU total)=51195.37890625MB
INFO:root:[  122] Training loss: 0.61354569, Validation loss: 0.62086547, Gradient norm: 0.25202402
INFO:root:At the start of the epoch: mem (CPU python)=51365.359375MB; mem (CPU total)=51233.75MB
INFO:root:[  123] Training loss: 0.61296028, Validation loss: 0.62154963, Gradient norm: 0.28040512
INFO:root:At the start of the epoch: mem (CPU python)=51403.453125MB; mem (CPU total)=51272.10546875MB
INFO:root:[  124] Training loss: 0.61321726, Validation loss: 0.62092268, Gradient norm: 0.25756496
INFO:root:At the start of the epoch: mem (CPU python)=51441.546875MB; mem (CPU total)=51310.05859375MB
INFO:root:[  125] Training loss: 0.61319011, Validation loss: 0.62152005, Gradient norm: 0.31196562
INFO:root:At the start of the epoch: mem (CPU python)=51479.64453125MB; mem (CPU total)=51348.390625MB
INFO:root:[  126] Training loss: 0.61310837, Validation loss: 0.62136085, Gradient norm: 0.28662992
INFO:root:At the start of the epoch: mem (CPU python)=51517.7421875MB; mem (CPU total)=51386.3203125MB
INFO:root:[  127] Training loss: 0.61299997, Validation loss: 0.62185325, Gradient norm: 0.29836621
INFO:root:At the start of the epoch: mem (CPU python)=51555.8359375MB; mem (CPU total)=51424.4296875MB
INFO:root:[  128] Training loss: 0.61314411, Validation loss: 0.62109498, Gradient norm: 0.36233738
INFO:root:At the start of the epoch: mem (CPU python)=51593.9296875MB; mem (CPU total)=51462.2734375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  129] Training loss: 0.61289632, Validation loss: 0.62129039, Gradient norm: 0.36067560
INFO:root:At the start of the epoch: mem (CPU python)=51632.03125MB; mem (CPU total)=51500.61328125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  130] Training loss: 0.61236460, Validation loss: 0.62149914, Gradient norm: 0.26430805
INFO:root:At the start of the epoch: mem (CPU python)=51670.125MB; mem (CPU total)=51538.71484375MB
INFO:root:[  131] Training loss: 0.61228498, Validation loss: 0.62190295, Gradient norm: 0.23086745
INFO:root:At the start of the epoch: mem (CPU python)=51708.22265625MB; mem (CPU total)=51576.80859375MB
INFO:root:EP 131: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=51746.21875MB; mem (CPU total)=51614.9375MB
INFO:root:Training the model took 10283.793s.
INFO:root:Emptying the cuda cache took 0.085s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87021
INFO:root:EnergyScoreTrain: 0.61294
INFO:root:CRPSTrain: 0.55871
INFO:root:Gaussian NLLTrain: 8.00515
INFO:root:CoverageTrain: 0.74583
INFO:root:IntervalWidthTrain: 3.07654
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88234
INFO:root:EnergyScoreValidation: 0.62139
INFO:root:CRPSValidation: 0.56543
INFO:root:Gaussian NLLValidation: 8.04705
INFO:root:CoverageValidation: 0.74196
INFO:root:IntervalWidthValidation: 3.07389
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8832
INFO:root:EnergyScoreTest: 0.62201
INFO:root:CRPSTest: 0.56604
INFO:root:Gaussian NLLTest: 8.03028
INFO:root:CoverageTest: 0.74144
INFO:root:IntervalWidthTest: 3.07163
INFO:root:After validation: mem (CPU python)=51789.1328125MB; mem (CPU total)=51658.15625MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 5}
INFO:root:After creating the dataloaders: mem (CPU python)=51789.1328125MB; mem (CPU total)=51658.16015625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 56623104
INFO:root:After setting up the model: mem (CPU python)=51789.64453125MB; mem (CPU total)=51658.40625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=51789.64453125MB; mem (CPU total)=51658.37109375MB
INFO:root:[    1] Training loss: 0.76271719, Validation loss: 0.72542583, Gradient norm: 0.86442365
INFO:root:At the start of the epoch: mem (CPU python)=51827.765625MB; mem (CPU total)=51696.4296875MB
INFO:root:[    2] Training loss: 0.72175223, Validation loss: 0.72171968, Gradient norm: 0.64538434
INFO:root:At the start of the epoch: mem (CPU python)=51865.859375MB; mem (CPU total)=51734.78125MB
INFO:root:[    3] Training loss: 0.72041792, Validation loss: 0.72161802, Gradient norm: 0.32234044
INFO:root:At the start of the epoch: mem (CPU python)=51903.953125MB; mem (CPU total)=51772.9296875MB
INFO:root:[    4] Training loss: 0.71975314, Validation loss: 0.72012470, Gradient norm: 0.33533467
INFO:root:At the start of the epoch: mem (CPU python)=51942.05078125MB; mem (CPU total)=51811.01953125MB
INFO:root:[    5] Training loss: 0.71925654, Validation loss: 0.71922337, Gradient norm: 0.33475723
INFO:root:At the start of the epoch: mem (CPU python)=51980.14453125MB; mem (CPU total)=51849.61328125MB
INFO:root:[    6] Training loss: 0.71870524, Validation loss: 0.71866300, Gradient norm: 0.29912488
INFO:root:At the start of the epoch: mem (CPU python)=52018.23828125MB; mem (CPU total)=51887.79296875MB
INFO:root:[    7] Training loss: 0.71793711, Validation loss: 0.71787231, Gradient norm: 0.21290000
INFO:root:At the start of the epoch: mem (CPU python)=52056.33203125MB; mem (CPU total)=51926.1796875MB
INFO:root:[    8] Training loss: 0.71627264, Validation loss: 0.71474964, Gradient norm: 0.22832275
INFO:root:At the start of the epoch: mem (CPU python)=52094.4296875MB; mem (CPU total)=51964.01953125MB
INFO:root:[    9] Training loss: 0.71174401, Validation loss: 0.70944166, Gradient norm: 0.29960973
INFO:root:At the start of the epoch: mem (CPU python)=52132.5234375MB; mem (CPU total)=52002.07421875MB
INFO:root:[   10] Training loss: 0.70649499, Validation loss: 0.70435131, Gradient norm: 0.22957960
INFO:root:At the start of the epoch: mem (CPU python)=52170.62109375MB; mem (CPU total)=52040.41015625MB
INFO:root:[   11] Training loss: 0.70153922, Validation loss: 0.70049952, Gradient norm: 0.22402753
INFO:root:At the start of the epoch: mem (CPU python)=52208.71875MB; mem (CPU total)=52078.265625MB
INFO:root:[   12] Training loss: 0.69645637, Validation loss: 0.69481305, Gradient norm: 0.20034661
INFO:root:At the start of the epoch: mem (CPU python)=52246.8125MB; mem (CPU total)=52116.8671875MB
INFO:root:[   13] Training loss: 0.69138490, Validation loss: 0.68914747, Gradient norm: 0.16289184
INFO:root:At the start of the epoch: mem (CPU python)=52284.90625MB; mem (CPU total)=52155.26171875MB
INFO:root:[   14] Training loss: 0.68690297, Validation loss: 0.68584431, Gradient norm: 0.20777495
INFO:root:At the start of the epoch: mem (CPU python)=52323.00390625MB; mem (CPU total)=52193.55078125MB
INFO:root:[   15] Training loss: 0.68265709, Validation loss: 0.68191231, Gradient norm: 0.16477820
INFO:root:At the start of the epoch: mem (CPU python)=52361.1015625MB; mem (CPU total)=52230.7578125MB
INFO:root:[   16] Training loss: 0.67886820, Validation loss: 0.67889676, Gradient norm: 0.19636067
INFO:root:At the start of the epoch: mem (CPU python)=52399.1953125MB; mem (CPU total)=52268.625MB
INFO:root:[   17] Training loss: 0.67544811, Validation loss: 0.67545452, Gradient norm: 0.12251969
INFO:root:At the start of the epoch: mem (CPU python)=52437.2890625MB; mem (CPU total)=52306.98828125MB
INFO:root:[   18] Training loss: 0.67260794, Validation loss: 0.67261021, Gradient norm: 0.16291376
INFO:root:At the start of the epoch: mem (CPU python)=52475.38671875MB; mem (CPU total)=52345.0390625MB
INFO:root:[   19] Training loss: 0.66990596, Validation loss: 0.66937046, Gradient norm: 0.14099807
INFO:root:At the start of the epoch: mem (CPU python)=52513.48046875MB; mem (CPU total)=52384.34375MB
INFO:root:[   20] Training loss: 0.66727279, Validation loss: 0.66771934, Gradient norm: 0.16910529
INFO:root:At the start of the epoch: mem (CPU python)=52551.57421875MB; mem (CPU total)=52421.9921875MB
INFO:root:[   21] Training loss: 0.66497397, Validation loss: 0.66548746, Gradient norm: 0.12733303
INFO:root:At the start of the epoch: mem (CPU python)=52589.671875MB; mem (CPU total)=52459.8984375MB
INFO:root:[   22] Training loss: 0.66281135, Validation loss: 0.66427719, Gradient norm: 0.13362749
INFO:root:At the start of the epoch: mem (CPU python)=52627.765625MB; mem (CPU total)=52499.45703125MB
INFO:root:[   23] Training loss: 0.66105748, Validation loss: 0.66121484, Gradient norm: 0.18271421
INFO:root:At the start of the epoch: mem (CPU python)=52665.859375MB; mem (CPU total)=52535.93359375MB
INFO:root:[   24] Training loss: 0.65919989, Validation loss: 0.65954526, Gradient norm: 0.13351792
INFO:root:At the start of the epoch: mem (CPU python)=52703.953125MB; mem (CPU total)=52575.23828125MB
INFO:root:[   25] Training loss: 0.65756942, Validation loss: 0.65841008, Gradient norm: 0.12873587
INFO:root:At the start of the epoch: mem (CPU python)=52742.0546875MB; mem (CPU total)=52613.5390625MB
INFO:root:[   26] Training loss: 0.65611157, Validation loss: 0.65785255, Gradient norm: 0.16946313
INFO:root:At the start of the epoch: mem (CPU python)=52780.1484375MB; mem (CPU total)=52650.81640625MB
INFO:root:[   27] Training loss: 0.65480863, Validation loss: 0.65596661, Gradient norm: 0.13654127
INFO:root:At the start of the epoch: mem (CPU python)=52818.2421875MB; mem (CPU total)=52690.0859375MB
INFO:root:[   28] Training loss: 0.65344190, Validation loss: 0.65357911, Gradient norm: 0.15361664
INFO:root:At the start of the epoch: mem (CPU python)=52856.33984375MB; mem (CPU total)=52728.9921875MB
INFO:root:[   29] Training loss: 0.65223851, Validation loss: 0.65344786, Gradient norm: 0.16390695
INFO:root:At the start of the epoch: mem (CPU python)=52894.4375MB; mem (CPU total)=52767.3515625MB
INFO:root:[   30] Training loss: 0.65086862, Validation loss: 0.65268987, Gradient norm: 0.14572105
INFO:root:At the start of the epoch: mem (CPU python)=52932.53125MB; mem (CPU total)=52804.2890625MB
INFO:root:[   31] Training loss: 0.64977387, Validation loss: 0.65213165, Gradient norm: 0.13577137
INFO:root:At the start of the epoch: mem (CPU python)=52970.6328125MB; mem (CPU total)=52842.0234375MB
INFO:root:[   32] Training loss: 0.64887659, Validation loss: 0.65107665, Gradient norm: 0.16962715
INFO:root:At the start of the epoch: mem (CPU python)=53008.71875MB; mem (CPU total)=52879.45703125MB
INFO:root:[   33] Training loss: 0.64751567, Validation loss: 0.64950151, Gradient norm: 0.14351378
INFO:root:At the start of the epoch: mem (CPU python)=53046.8203125MB; mem (CPU total)=52917.5703125MB
INFO:root:[   34] Training loss: 0.64659837, Validation loss: 0.64887610, Gradient norm: 0.16248215
INFO:root:At the start of the epoch: mem (CPU python)=53084.9140625MB; mem (CPU total)=52956.74609375MB
INFO:root:[   35] Training loss: 0.64551024, Validation loss: 0.64797186, Gradient norm: 0.14946905
INFO:root:At the start of the epoch: mem (CPU python)=53123.01171875MB; mem (CPU total)=52994.8828125MB
INFO:root:[   36] Training loss: 0.64461019, Validation loss: 0.64678833, Gradient norm: 0.17540711
INFO:root:At the start of the epoch: mem (CPU python)=53161.10546875MB; mem (CPU total)=53033.2421875MB
INFO:root:[   37] Training loss: 0.64384208, Validation loss: 0.64560513, Gradient norm: 0.14088397
INFO:root:At the start of the epoch: mem (CPU python)=53199.19921875MB; mem (CPU total)=53071.32421875MB
INFO:root:[   38] Training loss: 0.64264608, Validation loss: 0.64510372, Gradient norm: 0.13785082
INFO:root:At the start of the epoch: mem (CPU python)=53237.296875MB; mem (CPU total)=53109.32421875MB
INFO:root:[   39] Training loss: 0.64179642, Validation loss: 0.64552367, Gradient norm: 0.14737124
INFO:root:At the start of the epoch: mem (CPU python)=53275.390625MB; mem (CPU total)=53147.44140625MB
INFO:root:[   40] Training loss: 0.64129408, Validation loss: 0.64340491, Gradient norm: 0.14697095
INFO:root:At the start of the epoch: mem (CPU python)=53313.48828125MB; mem (CPU total)=53185.33203125MB
INFO:root:[   41] Training loss: 0.64044954, Validation loss: 0.64413079, Gradient norm: 0.13516750
INFO:root:At the start of the epoch: mem (CPU python)=53351.58203125MB; mem (CPU total)=53223.6875MB
INFO:root:[   42] Training loss: 0.63961943, Validation loss: 0.64279598, Gradient norm: 0.15216087
INFO:root:At the start of the epoch: mem (CPU python)=53389.6796875MB; mem (CPU total)=53262.28515625MB
INFO:root:[   43] Training loss: 0.63897381, Validation loss: 0.64244164, Gradient norm: 0.15360808
INFO:root:At the start of the epoch: mem (CPU python)=53427.7734375MB; mem (CPU total)=53300.39453125MB
INFO:root:[   44] Training loss: 0.63795406, Validation loss: 0.64118111, Gradient norm: 0.16694635
INFO:root:At the start of the epoch: mem (CPU python)=53465.8671875MB; mem (CPU total)=53338.73828125MB
INFO:root:[   45] Training loss: 0.63716797, Validation loss: 0.64057620, Gradient norm: 0.14907186
INFO:root:At the start of the epoch: mem (CPU python)=53503.96484375MB; mem (CPU total)=53376.66015625MB
INFO:root:[   46] Training loss: 0.63671408, Validation loss: 0.64079705, Gradient norm: 0.13240041
INFO:root:At the start of the epoch: mem (CPU python)=53542.05859375MB; mem (CPU total)=53414.546875MB
INFO:root:[   47] Training loss: 0.63599715, Validation loss: 0.63915330, Gradient norm: 0.17184517
INFO:root:At the start of the epoch: mem (CPU python)=53580.15234375MB; mem (CPU total)=53452.8984375MB
INFO:root:[   48] Training loss: 0.63495545, Validation loss: 0.63861996, Gradient norm: 0.13792222
INFO:root:At the start of the epoch: mem (CPU python)=53618.25MB; mem (CPU total)=53491.2578125MB
INFO:root:[   49] Training loss: 0.63464576, Validation loss: 0.63805293, Gradient norm: 0.15293672
INFO:root:At the start of the epoch: mem (CPU python)=53656.34375MB; mem (CPU total)=53529.640625MB
INFO:root:[   50] Training loss: 0.63396454, Validation loss: 0.63765142, Gradient norm: 0.15675475
INFO:root:At the start of the epoch: mem (CPU python)=53694.44140625MB; mem (CPU total)=53567.34765625MB
INFO:root:[   51] Training loss: 0.63332712, Validation loss: 0.63783714, Gradient norm: 0.16273780
INFO:root:At the start of the epoch: mem (CPU python)=53732.53515625MB; mem (CPU total)=53605.45703125MB
INFO:root:[   52] Training loss: 0.63252084, Validation loss: 0.63673789, Gradient norm: 0.12293912
INFO:root:At the start of the epoch: mem (CPU python)=53770.6328125MB; mem (CPU total)=53643.7890625MB
INFO:root:[   53] Training loss: 0.63214161, Validation loss: 0.63617820, Gradient norm: 0.16094901
INFO:root:At the start of the epoch: mem (CPU python)=53808.7265625MB; mem (CPU total)=53681.84375MB
INFO:root:[   54] Training loss: 0.63170787, Validation loss: 0.63542856, Gradient norm: 0.16445989
INFO:root:At the start of the epoch: mem (CPU python)=53846.8203125MB; mem (CPU total)=53899.9921875MB
INFO:root:[   55] Training loss: 0.63104729, Validation loss: 0.63561188, Gradient norm: 0.13438644
INFO:root:At the start of the epoch: mem (CPU python)=53884.91796875MB; mem (CPU total)=53777.265625MB
INFO:root:[   56] Training loss: 0.63042649, Validation loss: 0.63461801, Gradient norm: 0.13780533
INFO:root:At the start of the epoch: mem (CPU python)=53923.01171875MB; mem (CPU total)=53814.6015625MB
INFO:root:[   57] Training loss: 0.62987125, Validation loss: 0.63457314, Gradient norm: 0.14604745
INFO:root:At the start of the epoch: mem (CPU python)=53961.109375MB; mem (CPU total)=53851.7421875MB
INFO:root:[   58] Training loss: 0.62948962, Validation loss: 0.63367600, Gradient norm: 0.14152758
INFO:root:At the start of the epoch: mem (CPU python)=53999.203125MB; mem (CPU total)=53994.42578125MB
INFO:root:[   59] Training loss: 0.62895960, Validation loss: 0.63348976, Gradient norm: 0.17814919
INFO:root:At the start of the epoch: mem (CPU python)=54037.30078125MB; mem (CPU total)=53931.28515625MB
INFO:root:[   60] Training loss: 0.62861245, Validation loss: 0.63305170, Gradient norm: 0.14694171
INFO:root:At the start of the epoch: mem (CPU python)=54075.39453125MB; mem (CPU total)=53967.7265625MB
INFO:root:[   61] Training loss: 0.62805625, Validation loss: 0.63347612, Gradient norm: 0.16633449
INFO:root:At the start of the epoch: mem (CPU python)=54113.48828125MB; mem (CPU total)=54013.1953125MB
INFO:root:[   62] Training loss: 0.62745088, Validation loss: 0.63252886, Gradient norm: 0.17007032
INFO:root:At the start of the epoch: mem (CPU python)=54151.5859375MB; mem (CPU total)=54097.515625MB
INFO:root:[   63] Training loss: 0.62681436, Validation loss: 0.63252973, Gradient norm: 0.16548347
INFO:root:At the start of the epoch: mem (CPU python)=54189.6796875MB; mem (CPU total)=54174.23828125MB
INFO:root:[   64] Training loss: 0.62647342, Validation loss: 0.63139482, Gradient norm: 0.14026116
INFO:root:At the start of the epoch: mem (CPU python)=54227.7734375MB; mem (CPU total)=54125.671875MB
INFO:root:[   65] Training loss: 0.62603849, Validation loss: 0.63085081, Gradient norm: 0.15976509
INFO:root:At the start of the epoch: mem (CPU python)=54265.875MB; mem (CPU total)=54163.0625MB
INFO:root:[   66] Training loss: 0.62550785, Validation loss: 0.63094981, Gradient norm: 0.19115250
INFO:root:At the start of the epoch: mem (CPU python)=54303.96875MB; mem (CPU total)=54200.76953125MB
INFO:root:[   67] Training loss: 0.62540938, Validation loss: 0.63119027, Gradient norm: 0.16527800
INFO:root:At the start of the epoch: mem (CPU python)=54342.0625MB; mem (CPU total)=55344.41796875MB
INFO:root:[   68] Training loss: 0.62504323, Validation loss: 0.62929554, Gradient norm: 0.15873289
INFO:root:At the start of the epoch: mem (CPU python)=54380.15625MB; mem (CPU total)=54276.41796875MB
INFO:root:[   69] Training loss: 0.62450710, Validation loss: 0.62943570, Gradient norm: 0.16901835
INFO:root:At the start of the epoch: mem (CPU python)=54418.25390625MB; mem (CPU total)=54313.91015625MB
INFO:root:[   70] Training loss: 0.62417963, Validation loss: 0.62944676, Gradient norm: 0.19046131
INFO:root:At the start of the epoch: mem (CPU python)=54456.34765625MB; mem (CPU total)=56226.296875MB
INFO:root:[   71] Training loss: 0.62347122, Validation loss: 0.62953959, Gradient norm: 0.20706422
INFO:root:At the start of the epoch: mem (CPU python)=54494.44140625MB; mem (CPU total)=54389.28515625MB
INFO:root:[   72] Training loss: 0.62334489, Validation loss: 0.62954509, Gradient norm: 0.15875616
INFO:root:At the start of the epoch: mem (CPU python)=54532.54296875MB; mem (CPU total)=54426.390625MB
INFO:root:[   73] Training loss: 0.62297395, Validation loss: 0.62812370, Gradient norm: 0.14969356
INFO:root:At the start of the epoch: mem (CPU python)=54570.640625MB; mem (CPU total)=54464.59375MB
INFO:root:[   74] Training loss: 0.62228407, Validation loss: 0.62844532, Gradient norm: 0.17541915
INFO:root:At the start of the epoch: mem (CPU python)=54608.734375MB; mem (CPU total)=54686.578125MB
INFO:root:[   75] Training loss: 0.62172044, Validation loss: 0.62858771, Gradient norm: 0.14783426
INFO:root:At the start of the epoch: mem (CPU python)=54646.828125MB; mem (CPU total)=54728.22265625MB
INFO:root:[   76] Training loss: 0.62188740, Validation loss: 0.62726123, Gradient norm: 0.18030639
INFO:root:At the start of the epoch: mem (CPU python)=54684.92578125MB; mem (CPU total)=56457.5078125MB
INFO:root:[   77] Training loss: 0.62150796, Validation loss: 0.62793142, Gradient norm: 0.19037157
INFO:root:At the start of the epoch: mem (CPU python)=54723.01953125MB; mem (CPU total)=54618.15625MB
INFO:root:[   78] Training loss: 0.62120437, Validation loss: 0.62701426, Gradient norm: 0.17661214
INFO:root:At the start of the epoch: mem (CPU python)=54761.11328125MB; mem (CPU total)=54751.109375MB
INFO:root:[   79] Training loss: 0.62042258, Validation loss: 0.62744408, Gradient norm: 0.20080539
INFO:root:At the start of the epoch: mem (CPU python)=54799.2109375MB; mem (CPU total)=56574.796875MB
INFO:root:[   80] Training loss: 0.62052118, Validation loss: 0.62698570, Gradient norm: 0.19799340
INFO:root:At the start of the epoch: mem (CPU python)=54837.3046875MB; mem (CPU total)=54915.8515625MB
INFO:root:[   81] Training loss: 0.62017814, Validation loss: 0.62653864, Gradient norm: 0.19931168
INFO:root:At the start of the epoch: mem (CPU python)=54875.3984375MB; mem (CPU total)=54770.22265625MB
INFO:root:[   82] Training loss: 0.61959770, Validation loss: 0.62606805, Gradient norm: 0.19812035
INFO:root:At the start of the epoch: mem (CPU python)=54913.49609375MB; mem (CPU total)=54808.07421875MB
INFO:root:[   83] Training loss: 0.61933483, Validation loss: 0.62622232, Gradient norm: 0.19612359
INFO:root:At the start of the epoch: mem (CPU python)=54951.59375MB; mem (CPU total)=54846.15625MB
INFO:root:[   84] Training loss: 0.61886448, Validation loss: 0.62633239, Gradient norm: 0.18272800
INFO:root:At the start of the epoch: mem (CPU python)=54989.6875MB; mem (CPU total)=54884.1015625MB
INFO:root:[   85] Training loss: 0.61895263, Validation loss: 0.62544815, Gradient norm: 0.22294754
INFO:root:At the start of the epoch: mem (CPU python)=55027.78125MB; mem (CPU total)=54922.26171875MB
INFO:root:[   86] Training loss: 0.61853435, Validation loss: 0.62582802, Gradient norm: 0.23444320
INFO:root:At the start of the epoch: mem (CPU python)=55065.87890625MB; mem (CPU total)=56834.07421875MB
INFO:root:[   87] Training loss: 0.61820286, Validation loss: 0.62523670, Gradient norm: 0.21339603
INFO:root:At the start of the epoch: mem (CPU python)=55103.97265625MB; mem (CPU total)=54996.92578125MB
INFO:root:[   88] Training loss: 0.61777124, Validation loss: 0.62527563, Gradient norm: 0.20245915
INFO:root:At the start of the epoch: mem (CPU python)=55142.06640625MB; mem (CPU total)=55035.07421875MB
INFO:root:[   89] Training loss: 0.61761179, Validation loss: 0.62524787, Gradient norm: 0.24107343
INFO:root:At the start of the epoch: mem (CPU python)=55180.1640625MB; mem (CPU total)=55255.80078125MB
INFO:root:[   90] Training loss: 0.61701339, Validation loss: 0.62464750, Gradient norm: 0.18763184
INFO:root:At the start of the epoch: mem (CPU python)=55218.2578125MB; mem (CPU total)=55110.70703125MB
INFO:root:[   91] Training loss: 0.61718059, Validation loss: 0.62457650, Gradient norm: 0.19726516
INFO:root:At the start of the epoch: mem (CPU python)=55256.35546875MB; mem (CPU total)=55148.27734375MB
INFO:root:[   92] Training loss: 0.61692844, Validation loss: 0.62479009, Gradient norm: 0.18681270
INFO:root:At the start of the epoch: mem (CPU python)=55294.4453125MB; mem (CPU total)=55185.70703125MB
INFO:root:[   93] Training loss: 0.61659321, Validation loss: 0.62405443, Gradient norm: 0.24701011
INFO:root:At the start of the epoch: mem (CPU python)=55332.546875MB; mem (CPU total)=55224.19921875MB
INFO:root:[   94] Training loss: 0.61608475, Validation loss: 0.62431908, Gradient norm: 0.22386781
INFO:root:At the start of the epoch: mem (CPU python)=55370.640625MB; mem (CPU total)=57144.34765625MB
INFO:root:[   95] Training loss: 0.61623922, Validation loss: 0.62383093, Gradient norm: 0.24874414
INFO:root:At the start of the epoch: mem (CPU python)=55408.734375MB; mem (CPU total)=55300.61328125MB
INFO:root:[   96] Training loss: 0.61573482, Validation loss: 0.62350731, Gradient norm: 0.20541258
INFO:root:At the start of the epoch: mem (CPU python)=55446.83203125MB; mem (CPU total)=55339.203125MB
INFO:root:[   97] Training loss: 0.61523973, Validation loss: 0.62285086, Gradient norm: 0.23705984
INFO:root:At the start of the epoch: mem (CPU python)=55484.92578125MB; mem (CPU total)=55377.28125MB
INFO:root:[   98] Training loss: 0.61523818, Validation loss: 0.62386992, Gradient norm: 0.24674945
INFO:root:At the start of the epoch: mem (CPU python)=55523.01953125MB; mem (CPU total)=55598.2421875MB
INFO:root:[   99] Training loss: 0.61475408, Validation loss: 0.62374576, Gradient norm: 0.27432010
INFO:root:At the start of the epoch: mem (CPU python)=55561.12109375MB; mem (CPU total)=55453.3046875MB
INFO:root:[  100] Training loss: 0.61467066, Validation loss: 0.62341559, Gradient norm: 0.28644908
INFO:root:At the start of the epoch: mem (CPU python)=55599.21484375MB; mem (CPU total)=55492.375MB
INFO:root:[  101] Training loss: 0.61460038, Validation loss: 0.62362308, Gradient norm: 0.25913907
INFO:root:At the start of the epoch: mem (CPU python)=55637.30859375MB; mem (CPU total)=55529.5390625MB
INFO:root:[  102] Training loss: 0.61398782, Validation loss: 0.62272154, Gradient norm: 0.26306577
INFO:root:At the start of the epoch: mem (CPU python)=55675.40234375MB; mem (CPU total)=55567.359375MB
INFO:root:[  103] Training loss: 0.61369570, Validation loss: 0.62254465, Gradient norm: 0.20893378
INFO:root:At the start of the epoch: mem (CPU python)=55713.5MB; mem (CPU total)=55605.20703125MB
INFO:root:[  104] Training loss: 0.61394387, Validation loss: 0.62232498, Gradient norm: 0.27873521
INFO:root:At the start of the epoch: mem (CPU python)=55751.59765625MB; mem (CPU total)=55643.73046875MB
INFO:root:[  105] Training loss: 0.61329083, Validation loss: 0.62260331, Gradient norm: 0.24208528
INFO:root:At the start of the epoch: mem (CPU python)=55789.69140625MB; mem (CPU total)=57554.96875MB
INFO:root:[  106] Training loss: 0.61340536, Validation loss: 0.62157815, Gradient norm: 0.24962734
INFO:root:At the start of the epoch: mem (CPU python)=55827.7890625MB; mem (CPU total)=55719.375MB
INFO:root:[  107] Training loss: 0.61304295, Validation loss: 0.62138803, Gradient norm: 0.23353982
INFO:root:At the start of the epoch: mem (CPU python)=55865.8828125MB; mem (CPU total)=55756.4765625MB
INFO:root:[  108] Training loss: 0.61269906, Validation loss: 0.62166840, Gradient norm: 0.29493769
INFO:root:At the start of the epoch: mem (CPU python)=55903.98046875MB; mem (CPU total)=55794.61328125MB
INFO:root:[  109] Training loss: 0.61256786, Validation loss: 0.62207856, Gradient norm: 0.31445986
INFO:root:At the start of the epoch: mem (CPU python)=55942.07421875MB; mem (CPU total)=55832.2109375MB
INFO:root:[  110] Training loss: 0.61229097, Validation loss: 0.62162915, Gradient norm: 0.25211197
INFO:root:At the start of the epoch: mem (CPU python)=55980.171875MB; mem (CPU total)=55870.3671875MB
INFO:root:[  111] Training loss: 0.61210574, Validation loss: 0.62118197, Gradient norm: 0.26207393
INFO:root:At the start of the epoch: mem (CPU python)=56018.265625MB; mem (CPU total)=55908.23046875MB
INFO:root:[  112] Training loss: 0.61220733, Validation loss: 0.62207038, Gradient norm: 0.28699054
INFO:root:At the start of the epoch: mem (CPU python)=56056.359375MB; mem (CPU total)=55946.4296875MB
INFO:root:[  113] Training loss: 0.61146048, Validation loss: 0.62141590, Gradient norm: 0.26587618
INFO:root:At the start of the epoch: mem (CPU python)=56094.45703125MB; mem (CPU total)=55984.359375MB
INFO:root:[  114] Training loss: 0.61155657, Validation loss: 0.62239754, Gradient norm: 0.28623247
INFO:root:At the start of the epoch: mem (CPU python)=56132.55078125MB; mem (CPU total)=56024.2578125MB
INFO:root:[  115] Training loss: 0.61139680, Validation loss: 0.62114818, Gradient norm: 0.31136910
INFO:root:At the start of the epoch: mem (CPU python)=56170.6484375MB; mem (CPU total)=56063.0859375MB
INFO:root:[  116] Training loss: 0.61089209, Validation loss: 0.62167564, Gradient norm: 0.30937879
INFO:root:At the start of the epoch: mem (CPU python)=56208.74609375MB; mem (CPU total)=56101.03125MB
INFO:root:[  117] Training loss: 0.61062614, Validation loss: 0.62063564, Gradient norm: 0.28204443
INFO:root:At the start of the epoch: mem (CPU python)=56246.83984375MB; mem (CPU total)=56139.46875MB
INFO:root:[  118] Training loss: 0.61092345, Validation loss: 0.62025936, Gradient norm: 0.33337503
INFO:root:At the start of the epoch: mem (CPU python)=56284.93359375MB; mem (CPU total)=56178.44140625MB
INFO:root:[  119] Training loss: 0.61040924, Validation loss: 0.62074627, Gradient norm: 0.26749163
INFO:root:At the start of the epoch: mem (CPU python)=56323.02734375MB; mem (CPU total)=56216.5078125MB
INFO:root:[  120] Training loss: 0.61051967, Validation loss: 0.61995728, Gradient norm: 0.35976579
INFO:root:At the start of the epoch: mem (CPU python)=56361.125MB; mem (CPU total)=56216.7890625MB
INFO:root:[  121] Training loss: 0.60991885, Validation loss: 0.62057898, Gradient norm: 0.31451260
INFO:root:At the start of the epoch: mem (CPU python)=56399.21875MB; mem (CPU total)=56257.62109375MB
INFO:root:[  122] Training loss: 0.61020368, Validation loss: 0.61989523, Gradient norm: 0.27025110
INFO:root:At the start of the epoch: mem (CPU python)=56437.3125MB; mem (CPU total)=56292.5234375MB
INFO:root:[  123] Training loss: 0.60952096, Validation loss: 0.62063309, Gradient norm: 0.27408300
INFO:root:At the start of the epoch: mem (CPU python)=56475.41015625MB; mem (CPU total)=56331.3203125MB
INFO:root:[  124] Training loss: 0.60961465, Validation loss: 0.61907947, Gradient norm: 0.31088155
INFO:root:At the start of the epoch: mem (CPU python)=56513.50390625MB; mem (CPU total)=56368.015625MB
INFO:root:[  125] Training loss: 0.60906378, Validation loss: 0.62044327, Gradient norm: 0.31926163
INFO:root:At the start of the epoch: mem (CPU python)=56551.6015625MB; mem (CPU total)=56405.87890625MB
INFO:root:[  126] Training loss: 0.60909090, Validation loss: 0.62037806, Gradient norm: 0.37483933
INFO:root:At the start of the epoch: mem (CPU python)=56589.6953125MB; mem (CPU total)=56444.2890625MB
INFO:root:[  127] Training loss: 0.60902429, Validation loss: 0.61879063, Gradient norm: 0.43455019
INFO:root:At the start of the epoch: mem (CPU python)=56627.79296875MB; mem (CPU total)=56503.359375MB
INFO:root:[  128] Training loss: 0.60864023, Validation loss: 0.62082128, Gradient norm: 0.31469610
INFO:root:At the start of the epoch: mem (CPU python)=56665.88671875MB; mem (CPU total)=56523.60546875MB
INFO:root:[  129] Training loss: 0.60848975, Validation loss: 0.62008140, Gradient norm: 0.35961046
INFO:root:At the start of the epoch: mem (CPU python)=56703.98046875MB; mem (CPU total)=56561.03125MB
INFO:root:[  130] Training loss: 0.60795224, Validation loss: 0.62060051, Gradient norm: 0.28084042
INFO:root:At the start of the epoch: mem (CPU python)=56742.078125MB; mem (CPU total)=56596.9453125MB
INFO:root:[  131] Training loss: 0.60827493, Validation loss: 0.61931390, Gradient norm: 0.44576218
INFO:root:At the start of the epoch: mem (CPU python)=56780.171875MB; mem (CPU total)=56635.796875MB
INFO:root:[  132] Training loss: 0.60771022, Validation loss: 0.61989564, Gradient norm: 0.34594208
INFO:root:At the start of the epoch: mem (CPU python)=56818.265625MB; mem (CPU total)=56674.203125MB
INFO:root:[  133] Training loss: 0.60785653, Validation loss: 0.61902173, Gradient norm: 0.47430309
INFO:root:At the start of the epoch: mem (CPU python)=56856.3671875MB; mem (CPU total)=56712.62109375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  134] Training loss: 0.60755516, Validation loss: 0.61829386, Gradient norm: 0.33871901
INFO:root:At the start of the epoch: mem (CPU python)=56894.4609375MB; mem (CPU total)=56751.203125MB
INFO:root:[  135] Training loss: 0.60667629, Validation loss: 0.61943053, Gradient norm: 0.24552041
INFO:root:At the start of the epoch: mem (CPU python)=56932.5546875MB; mem (CPU total)=56788.42578125MB
INFO:root:[  136] Training loss: 0.60615192, Validation loss: 0.61831383, Gradient norm: 0.25569820
INFO:root:At the start of the epoch: mem (CPU python)=56970.6484375MB; mem (CPU total)=56826.8515625MB
INFO:root:[  137] Training loss: 0.60593030, Validation loss: 0.61780409, Gradient norm: 0.24846987
INFO:root:At the start of the epoch: mem (CPU python)=57008.74609375MB; mem (CPU total)=56865.56640625MB
INFO:root:[  138] Training loss: 0.60614947, Validation loss: 0.61806116, Gradient norm: 0.33050237
INFO:root:At the start of the epoch: mem (CPU python)=57046.83984375MB; mem (CPU total)=56903.19140625MB
INFO:root:[  139] Training loss: 0.60592882, Validation loss: 0.61781260, Gradient norm: 0.24763472
INFO:root:At the start of the epoch: mem (CPU python)=57084.93359375MB; mem (CPU total)=56942.71875MB
INFO:root:[  140] Training loss: 0.60570491, Validation loss: 0.61800928, Gradient norm: 0.24983393
INFO:root:At the start of the epoch: mem (CPU python)=57123.03125MB; mem (CPU total)=56979.05078125MB
INFO:root:[  141] Training loss: 0.60560686, Validation loss: 0.61769311, Gradient norm: 0.23780291
INFO:root:At the start of the epoch: mem (CPU python)=57161.12890625MB; mem (CPU total)=57016.9375MB
INFO:root:[  142] Training loss: 0.60550749, Validation loss: 0.61878920, Gradient norm: 0.34583785
INFO:root:At the start of the epoch: mem (CPU python)=57199.2265625MB; mem (CPU total)=57054.43359375MB
INFO:root:[  143] Training loss: 0.60574831, Validation loss: 0.61749743, Gradient norm: 0.27934308
INFO:root:At the start of the epoch: mem (CPU python)=57237.3203125MB; mem (CPU total)=57094.12109375MB
INFO:root:[  144] Training loss: 0.60564405, Validation loss: 0.61793664, Gradient norm: 0.27754864
INFO:root:At the start of the epoch: mem (CPU python)=57275.41796875MB; mem (CPU total)=57132.87109375MB
INFO:root:[  145] Training loss: 0.60537885, Validation loss: 0.61845615, Gradient norm: 0.30279378
INFO:root:At the start of the epoch: mem (CPU python)=57313.515625MB; mem (CPU total)=57170.00390625MB
INFO:root:[  146] Training loss: 0.60543333, Validation loss: 0.61836434, Gradient norm: 0.32536419
INFO:root:At the start of the epoch: mem (CPU python)=57351.609375MB; mem (CPU total)=57207.92578125MB
INFO:root:[  147] Training loss: 0.60494391, Validation loss: 0.61733627, Gradient norm: 0.29990004
INFO:root:At the start of the epoch: mem (CPU python)=57389.70703125MB; mem (CPU total)=57246.796875MB
INFO:root:[  148] Training loss: 0.60520218, Validation loss: 0.61809891, Gradient norm: 0.28478367
INFO:root:At the start of the epoch: mem (CPU python)=57427.80078125MB; mem (CPU total)=57284.90625MB
INFO:root:[  149] Training loss: 0.60522121, Validation loss: 0.61759374, Gradient norm: 0.30355834
INFO:root:At the start of the epoch: mem (CPU python)=57465.89453125MB; mem (CPU total)=57324.875MB
INFO:root:[  150] Training loss: 0.60524750, Validation loss: 0.61741823, Gradient norm: 0.31303625
INFO:root:At the start of the epoch: mem (CPU python)=57503.99609375MB; mem (CPU total)=57361.3125MB
INFO:root:[  151] Training loss: 0.60476844, Validation loss: 0.61844426, Gradient norm: 0.29875904
INFO:root:At the start of the epoch: mem (CPU python)=57542.08984375MB; mem (CPU total)=57399.46875MB
INFO:root:[  152] Training loss: 0.60467308, Validation loss: 0.61768367, Gradient norm: 0.32774081
INFO:root:At the start of the epoch: mem (CPU python)=57580.18359375MB; mem (CPU total)=57437.875MB
INFO:root:[  153] Training loss: 0.60482449, Validation loss: 0.61757515, Gradient norm: 0.37014251
INFO:root:At the start of the epoch: mem (CPU python)=57618.27734375MB; mem (CPU total)=57476.9296875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  154] Training loss: 0.60478696, Validation loss: 0.61779122, Gradient norm: 0.35278326
INFO:root:At the start of the epoch: mem (CPU python)=57656.375MB; mem (CPU total)=57513.25MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  155] Training loss: 0.60415748, Validation loss: 0.61854776, Gradient norm: 0.24117357
INFO:root:At the start of the epoch: mem (CPU python)=57694.46875MB; mem (CPU total)=57551.6484375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  156] Training loss: 0.60369104, Validation loss: 0.61795889, Gradient norm: 0.21218762
INFO:root:At the start of the epoch: mem (CPU python)=57732.5625MB; mem (CPU total)=57592.3046875MB
INFO:root:EP 156: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=57770.6640625MB; mem (CPU total)=57628.76953125MB
INFO:root:Training the model took 13088.066s.
INFO:root:Emptying the cuda cache took 0.087s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85858
INFO:root:EnergyScoreTrain: 0.60468
INFO:root:CRPSTrain: 0.53826
INFO:root:Gaussian NLLTrain: 4.43775
INFO:root:CoverageTrain: 0.77839
INFO:root:IntervalWidthTrain: 3.12234
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87744
INFO:root:EnergyScoreValidation: 0.61782
INFO:root:CRPSValidation: 0.54869
INFO:root:Gaussian NLLValidation: 4.47982
INFO:root:CoverageValidation: 0.77228
INFO:root:IntervalWidthValidation: 3.11601
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87878
INFO:root:EnergyScoreTest: 0.61881
INFO:root:CRPSTest: 0.54959
INFO:root:Gaussian NLLTest: 4.46101
INFO:root:CoverageTest: 0.77167
INFO:root:IntervalWidthTest: 3.11376
INFO:root:After validation: mem (CPU python)=57813.359375MB; mem (CPU total)=57672.125MB
