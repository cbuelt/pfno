INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=580.046875MB; mem (CPU total)=966.58203125MB
INFO:root:############### Starting experiment with config file ks/fno_sr_reparam_n_samples4.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12459.03515625MB; mem (CPU total)=979.5703125MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=12459.03515625MB; mem (CPU total)=979.5703125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12459.03515625MB; mem (CPU total)=2173.8359375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=2182.203125MB
INFO:root:[    1] Training loss: 0.72468209, Validation loss: 0.72040603, Gradient norm: 0.01805377
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3360.76171875MB
INFO:root:[    2] Training loss: 0.71972545, Validation loss: 0.71907445, Gradient norm: 0.00517157
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3422.7734375MB
INFO:root:[    3] Training loss: 0.71791864, Validation loss: 0.71422095, Gradient norm: 0.00739402
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3460.484375MB
INFO:root:[    4] Training loss: 0.71138892, Validation loss: 0.70560822, Gradient norm: 0.01661651
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3499.08203125MB
INFO:root:[    5] Training loss: 0.70452626, Validation loss: 0.69859833, Gradient norm: 0.02195076
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3537.1953125MB
INFO:root:[    6] Training loss: 0.69873733, Validation loss: 0.69157090, Gradient norm: 0.02661573
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3575.30078125MB
INFO:root:[    7] Training loss: 0.69277863, Validation loss: 0.68421934, Gradient norm: 0.02798057
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3613.703125MB
INFO:root:[    8] Training loss: 0.68680177, Validation loss: 0.67791153, Gradient norm: 0.03047443
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3651.67578125MB
INFO:root:[    9] Training loss: 0.68165651, Validation loss: 0.67200706, Gradient norm: 0.02880042
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3690.0078125MB
INFO:root:[   10] Training loss: 0.67751687, Validation loss: 0.66827370, Gradient norm: 0.03221220
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3728.10546875MB
INFO:root:[   11] Training loss: 0.67381341, Validation loss: 0.66416011, Gradient norm: 0.03323567
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3766.86328125MB
INFO:root:[   12] Training loss: 0.67083572, Validation loss: 0.66169317, Gradient norm: 0.03414008
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3804.86328125MB
INFO:root:[   13] Training loss: 0.66818088, Validation loss: 0.65937936, Gradient norm: 0.03235695
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3842.95703125MB
INFO:root:[   14] Training loss: 0.66597948, Validation loss: 0.65593357, Gradient norm: 0.03571393
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3881.2421875MB
INFO:root:[   15] Training loss: 0.66375138, Validation loss: 0.65335577, Gradient norm: 0.03325721
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3919.28125MB
INFO:root:[   16] Training loss: 0.66189756, Validation loss: 0.65214080, Gradient norm: 0.03318282
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3957.37890625MB
INFO:root:[   17] Training loss: 0.66022142, Validation loss: 0.65003958, Gradient norm: 0.03371431
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=3995.79296875MB
INFO:root:[   18] Training loss: 0.65872587, Validation loss: 0.64840252, Gradient norm: 0.03874154
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4033.83984375MB
INFO:root:[   19] Training loss: 0.65736280, Validation loss: 0.64696551, Gradient norm: 0.03762253
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4072.03125MB
INFO:root:[   20] Training loss: 0.65605861, Validation loss: 0.64617759, Gradient norm: 0.03893956
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4110.5234375MB
INFO:root:[   21] Training loss: 0.65445959, Validation loss: 0.64431157, Gradient norm: 0.03407013
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4149.11328125MB
INFO:root:[   22] Training loss: 0.65357336, Validation loss: 0.64264558, Gradient norm: 0.03897489
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4187.0234375MB
INFO:root:[   23] Training loss: 0.65251193, Validation loss: 0.64178373, Gradient norm: 0.03771398
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4224.45703125MB
INFO:root:[   24] Training loss: 0.65118606, Validation loss: 0.64096877, Gradient norm: 0.03940515
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4262.859375MB
INFO:root:[   25] Training loss: 0.65035478, Validation loss: 0.64042810, Gradient norm: 0.04191759
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4302.72265625MB
INFO:root:[   26] Training loss: 0.64921227, Validation loss: 0.63896385, Gradient norm: 0.04013819
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4341.02734375MB
INFO:root:[   27] Training loss: 0.64848079, Validation loss: 0.63857762, Gradient norm: 0.04570592
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4379.1328125MB
INFO:root:[   28] Training loss: 0.64753020, Validation loss: 0.63709220, Gradient norm: 0.04140367
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4417.34765625MB
INFO:root:[   29] Training loss: 0.64668885, Validation loss: 0.63624169, Gradient norm: 0.04129819
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4455.5078125MB
INFO:root:[   30] Training loss: 0.64589062, Validation loss: 0.63546876, Gradient norm: 0.04043629
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4493.66796875MB
INFO:root:[   31] Training loss: 0.64493064, Validation loss: 0.63497869, Gradient norm: 0.04249062
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4531.80078125MB
INFO:root:[   32] Training loss: 0.64409666, Validation loss: 0.63431338, Gradient norm: 0.04252223
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4569.99609375MB
INFO:root:[   33] Training loss: 0.64359398, Validation loss: 0.63304017, Gradient norm: 0.04557342
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4608.15625MB
INFO:root:[   34] Training loss: 0.64294352, Validation loss: 0.63249091, Gradient norm: 0.04745399
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4646.55859375MB
INFO:root:[   35] Training loss: 0.64211213, Validation loss: 0.63154756, Gradient norm: 0.04822811
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4684.72265625MB
INFO:root:[   36] Training loss: 0.64155412, Validation loss: 0.63119594, Gradient norm: 0.04844668
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4721.87109375MB
INFO:root:[   37] Training loss: 0.64084850, Validation loss: 0.63081305, Gradient norm: 0.04483756
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4760.08203125MB
INFO:root:[   38] Training loss: 0.64037015, Validation loss: 0.63047196, Gradient norm: 0.05323155
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4798.21484375MB
INFO:root:[   39] Training loss: 0.63972960, Validation loss: 0.62951883, Gradient norm: 0.05158531
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4836.36328125MB
INFO:root:[   40] Training loss: 0.63911256, Validation loss: 0.62861720, Gradient norm: 0.04887286
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4874.26171875MB
INFO:root:[   41] Training loss: 0.63868048, Validation loss: 0.62828824, Gradient norm: 0.05149871
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4912.86328125MB
INFO:root:[   42] Training loss: 0.63804986, Validation loss: 0.62829600, Gradient norm: 0.05214550
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4951.48046875MB
INFO:root:[   43] Training loss: 0.63780228, Validation loss: 0.62738032, Gradient norm: 0.05364864
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=4989.1640625MB
INFO:root:[   44] Training loss: 0.63700166, Validation loss: 0.62723056, Gradient norm: 0.04548786
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5027.30859375MB
INFO:root:[   45] Training loss: 0.63677165, Validation loss: 0.62710965, Gradient norm: 0.05586563
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5065.453125MB
INFO:root:[   46] Training loss: 0.63601829, Validation loss: 0.62592891, Gradient norm: 0.04509689
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5103.58984375MB
INFO:root:[   47] Training loss: 0.63557831, Validation loss: 0.62589673, Gradient norm: 0.05182744
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5141.96875MB
INFO:root:[   48] Training loss: 0.63516503, Validation loss: 0.62578170, Gradient norm: 0.05216889
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5179.85546875MB
INFO:root:[   49] Training loss: 0.63468949, Validation loss: 0.62418854, Gradient norm: 0.05129807
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5218.02734375MB
INFO:root:[   50] Training loss: 0.63432688, Validation loss: 0.62454700, Gradient norm: 0.05060438
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5256.453125MB
INFO:root:[   51] Training loss: 0.63368170, Validation loss: 0.62387918, Gradient norm: 0.05016086
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5294.2578125MB
INFO:root:[   52] Training loss: 0.63347180, Validation loss: 0.62498381, Gradient norm: 0.05140830
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5332.6484375MB
INFO:root:[   53] Training loss: 0.63300385, Validation loss: 0.62323889, Gradient norm: 0.05540142
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5370.54296875MB
INFO:root:[   54] Training loss: 0.63259015, Validation loss: 0.62286109, Gradient norm: 0.04776941
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5408.546875MB
INFO:root:[   55] Training loss: 0.63234634, Validation loss: 0.62238927, Gradient norm: 0.05464015
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5446.9375MB
INFO:root:[   56] Training loss: 0.63195137, Validation loss: 0.62167002, Gradient norm: 0.05362848
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5485.23046875MB
INFO:root:[   57] Training loss: 0.63161685, Validation loss: 0.62186612, Gradient norm: 0.06052139
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5524.11328125MB
INFO:root:[   58] Training loss: 0.63112922, Validation loss: 0.62145838, Gradient norm: 0.06168660
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5560.89453125MB
INFO:root:[   59] Training loss: 0.63071203, Validation loss: 0.62103821, Gradient norm: 0.05044461
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5599.03515625MB
INFO:root:[   60] Training loss: 0.63044967, Validation loss: 0.62072112, Gradient norm: 0.05856428
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5637.4140625MB
INFO:root:[   61] Training loss: 0.63012708, Validation loss: 0.62191260, Gradient norm: 0.06013017
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5676.0546875MB
INFO:root:[   62] Training loss: 0.62990474, Validation loss: 0.61995590, Gradient norm: 0.06016294
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5713.125MB
INFO:root:[   63] Training loss: 0.62932157, Validation loss: 0.61896236, Gradient norm: 0.05282464
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5751.26953125MB
INFO:root:[   64] Training loss: 0.62915291, Validation loss: 0.61935016, Gradient norm: 0.05570715
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5790.15234375MB
INFO:root:[   65] Training loss: 0.62862085, Validation loss: 0.61904243, Gradient norm: 0.05238380
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5829.66015625MB
INFO:root:[   66] Training loss: 0.62828564, Validation loss: 0.61958071, Gradient norm: 0.05270348
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5867.82421875MB
INFO:root:[   67] Training loss: 0.62814507, Validation loss: 0.61839774, Gradient norm: 0.05399785
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5905.48828125MB
INFO:root:[   68] Training loss: 0.62775064, Validation loss: 0.61817729, Gradient norm: 0.05305466
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5944.04296875MB
INFO:root:[   69] Training loss: 0.62777169, Validation loss: 0.61789571, Gradient norm: 0.06294406
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=5981.80078125MB
INFO:root:[   70] Training loss: 0.62729929, Validation loss: 0.61849788, Gradient norm: 0.05955563
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6020.44140625MB
INFO:root:[   71] Training loss: 0.62687694, Validation loss: 0.61800427, Gradient norm: 0.05473726
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6058.9921875MB
INFO:root:[   72] Training loss: 0.62665346, Validation loss: 0.61686383, Gradient norm: 0.05792790
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6096.30078125MB
INFO:root:[   73] Training loss: 0.62637009, Validation loss: 0.61711861, Gradient norm: 0.05574370
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6134.6171875MB
INFO:root:[   74] Training loss: 0.62616459, Validation loss: 0.61762048, Gradient norm: 0.05366762
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6172.50390625MB
INFO:root:[   75] Training loss: 0.62586832, Validation loss: 0.61660023, Gradient norm: 0.05680850
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6210.9140625MB
INFO:root:[   76] Training loss: 0.62554807, Validation loss: 0.61747113, Gradient norm: 0.05324147
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6249.27734375MB
INFO:root:[   77] Training loss: 0.62526924, Validation loss: 0.61542850, Gradient norm: 0.05884202
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6287.23046875MB
INFO:root:[   78] Training loss: 0.62512299, Validation loss: 0.61654850, Gradient norm: 0.05840251
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6326.1328125MB
INFO:root:[   79] Training loss: 0.62480922, Validation loss: 0.61590204, Gradient norm: 0.06294162
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6364.296875MB
INFO:root:[   80] Training loss: 0.62452189, Validation loss: 0.61499000, Gradient norm: 0.05840815
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6402.2109375MB
INFO:root:[   81] Training loss: 0.62422070, Validation loss: 0.61589849, Gradient norm: 0.05550452
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6440.80078125MB
INFO:root:[   82] Training loss: 0.62415391, Validation loss: 0.61521509, Gradient norm: 0.05674752
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6478.94140625MB
INFO:root:[   83] Training loss: 0.62388905, Validation loss: 0.61497474, Gradient norm: 0.05732171
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6516.62109375MB
INFO:root:[   84] Training loss: 0.62360492, Validation loss: 0.61458451, Gradient norm: 0.06083692
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6554.4921875MB
INFO:root:[   85] Training loss: 0.62343108, Validation loss: 0.61537871, Gradient norm: 0.06108861
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6593.37109375MB
INFO:root:[   86] Training loss: 0.62327091, Validation loss: 0.61548333, Gradient norm: 0.05430872
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6631.515625MB
INFO:root:[   87] Training loss: 0.62301896, Validation loss: 0.61387655, Gradient norm: 0.05960330
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6669.12109375MB
INFO:root:[   88] Training loss: 0.62271629, Validation loss: 0.61440778, Gradient norm: 0.05274450
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6707.99609375MB
INFO:root:[   89] Training loss: 0.62246009, Validation loss: 0.61429089, Gradient norm: 0.05875619
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6746.13671875MB
INFO:root:[   90] Training loss: 0.62241872, Validation loss: 0.61390149, Gradient norm: 0.05672325
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6784.49609375MB
INFO:root:[   91] Training loss: 0.62220931, Validation loss: 0.61362240, Gradient norm: 0.06096569
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6821.96875MB
INFO:root:[   92] Training loss: 0.62205601, Validation loss: 0.61500782, Gradient norm: 0.05923306
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6860.62109375MB
INFO:root:[   93] Training loss: 0.62168236, Validation loss: 0.61337829, Gradient norm: 0.06365822
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6898.33984375MB
INFO:root:[   94] Training loss: 0.62155363, Validation loss: 0.61375991, Gradient norm: 0.05317998
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6936.98828125MB
INFO:root:[   95] Training loss: 0.62138330, Validation loss: 0.61350434, Gradient norm: 0.05762450
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=6976.5078125MB
INFO:root:[   96] Training loss: 0.62116935, Validation loss: 0.61260648, Gradient norm: 0.05840014
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7014.59375MB
INFO:root:[   97] Training loss: 0.62090414, Validation loss: 0.61307739, Gradient norm: 0.05577577
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7053.359375MB
INFO:root:[   98] Training loss: 0.62065178, Validation loss: 0.61250820, Gradient norm: 0.06178225
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7091.2421875MB
INFO:root:[   99] Training loss: 0.62046243, Validation loss: 0.61196020, Gradient norm: 0.05952020
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7129.703125MB
INFO:root:[  100] Training loss: 0.62063057, Validation loss: 0.61250195, Gradient norm: 0.07198983
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7168.5859375MB
INFO:root:[  101] Training loss: 0.62011597, Validation loss: 0.61183088, Gradient norm: 0.06113022
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7206.23828125MB
INFO:root:[  102] Training loss: 0.62006395, Validation loss: 0.61229179, Gradient norm: 0.06307058
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7244.828125MB
INFO:root:[  103] Training loss: 0.61990505, Validation loss: 0.61291760, Gradient norm: 0.06322312
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7282.96484375MB
INFO:root:[  104] Training loss: 0.61966503, Validation loss: 0.61149383, Gradient norm: 0.06621033
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7320.6015625MB
INFO:root:[  105] Training loss: 0.61965851, Validation loss: 0.61091011, Gradient norm: 0.06193604
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7358.703125MB
INFO:root:[  106] Training loss: 0.61933719, Validation loss: 0.61097704, Gradient norm: 0.05638554
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7397.33203125MB
INFO:root:[  107] Training loss: 0.61910020, Validation loss: 0.61077097, Gradient norm: 0.05928203
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7434.67578125MB
INFO:root:[  108] Training loss: 0.61891900, Validation loss: 0.61179895, Gradient norm: 0.05667840
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7473.30859375MB
INFO:root:[  109] Training loss: 0.61890807, Validation loss: 0.61093386, Gradient norm: 0.06603217
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7511.69921875MB
INFO:root:[  110] Training loss: 0.61882181, Validation loss: 0.61052981, Gradient norm: 0.06518695
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7549.10546875MB
INFO:root:[  111] Training loss: 0.61862342, Validation loss: 0.61104511, Gradient norm: 0.06057331
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7587.7421875MB
INFO:root:[  112] Training loss: 0.61830769, Validation loss: 0.61037325, Gradient norm: 0.06129754
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7625.640625MB
INFO:root:[  113] Training loss: 0.61808024, Validation loss: 0.61091326, Gradient norm: 0.06056663
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7663.7421875MB
INFO:root:[  114] Training loss: 0.61815304, Validation loss: 0.61070786, Gradient norm: 0.06203242
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7701.63671875MB
INFO:root:[  115] Training loss: 0.61805008, Validation loss: 0.61037795, Gradient norm: 0.06914615
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7740.8203125MB
INFO:root:[  116] Training loss: 0.61769539, Validation loss: 0.60964887, Gradient norm: 0.06375220
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7778.26953125MB
INFO:root:[  117] Training loss: 0.61753008, Validation loss: 0.60993382, Gradient norm: 0.06286571
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7816.65625MB
INFO:root:[  118] Training loss: 0.61742082, Validation loss: 0.60926582, Gradient norm: 0.06011358
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7854.578125MB
INFO:root:[  119] Training loss: 0.61714013, Validation loss: 0.60929232, Gradient norm: 0.06138202
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7893.6875MB
INFO:root:[  120] Training loss: 0.61692608, Validation loss: 0.60974359, Gradient norm: 0.06076782
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7931.86328125MB
INFO:root:[  121] Training loss: 0.61717757, Validation loss: 0.60894574, Gradient norm: 0.06964136
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=7969.265625MB
INFO:root:[  122] Training loss: 0.61671082, Validation loss: 0.60951548, Gradient norm: 0.06121993
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8008.17578125MB
INFO:root:[  123] Training loss: 0.61664355, Validation loss: 0.60979735, Gradient norm: 0.06207283
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8046.06640625MB
INFO:root:[  124] Training loss: 0.61648093, Validation loss: 0.60882960, Gradient norm: 0.05983794
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8084.91796875MB
INFO:root:[  125] Training loss: 0.61626418, Validation loss: 0.60892954, Gradient norm: 0.06560049
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8123.328125MB
INFO:root:[  126] Training loss: 0.61658940, Validation loss: 0.60890632, Gradient norm: 0.06795153
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8162.03515625MB
INFO:root:[  127] Training loss: 0.61613365, Validation loss: 0.60924145, Gradient norm: 0.06155701
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8199.87109375MB
INFO:root:[  128] Training loss: 0.61603957, Validation loss: 0.60934399, Gradient norm: 0.06053703
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8238.28515625MB
INFO:root:[  129] Training loss: 0.61578290, Validation loss: 0.60840341, Gradient norm: 0.05924598
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8275.703125MB
INFO:root:[  130] Training loss: 0.61568081, Validation loss: 0.60804439, Gradient norm: 0.05859823
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8313.61328125MB
INFO:root:[  131] Training loss: 0.61559062, Validation loss: 0.60814789, Gradient norm: 0.06458079
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8352.51953125MB
INFO:root:[  132] Training loss: 0.61539946, Validation loss: 0.60835262, Gradient norm: 0.06159710
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8390.4296875MB
INFO:root:[  133] Training loss: 0.61534685, Validation loss: 0.60845931, Gradient norm: 0.06370198
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8428.34765625MB
INFO:root:[  134] Training loss: 0.61515851, Validation loss: 0.60853137, Gradient norm: 0.06451088
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8466.515625MB
INFO:root:[  135] Training loss: 0.61505097, Validation loss: 0.60881317, Gradient norm: 0.06018051
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8504.42578125MB
INFO:root:[  136] Training loss: 0.61506862, Validation loss: 0.60833361, Gradient norm: 0.06657382
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8542.33203125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  137] Training loss: 0.61483464, Validation loss: 0.60819586, Gradient norm: 0.07249427
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8580.73828125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  138] Training loss: 0.61385395, Validation loss: 0.60733848, Gradient norm: 0.05704660
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8618.66015625MB
INFO:root:[  139] Training loss: 0.61334029, Validation loss: 0.60727713, Gradient norm: 0.05609148
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8657.49609375MB
INFO:root:[  140] Training loss: 0.61316343, Validation loss: 0.60647328, Gradient norm: 0.05247521
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8695.01171875MB
INFO:root:[  141] Training loss: 0.61286229, Validation loss: 0.60680847, Gradient norm: 0.05329778
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8733.91796875MB
INFO:root:[  142] Training loss: 0.61291225, Validation loss: 0.60724494, Gradient norm: 0.05751746
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8772.08203125MB
INFO:root:[  143] Training loss: 0.61314285, Validation loss: 0.60656407, Gradient norm: 0.05253331
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8810.25MB
INFO:root:[  144] Training loss: 0.61302082, Validation loss: 0.60655068, Gradient norm: 0.05477784
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8847.94140625MB
INFO:root:[  145] Training loss: 0.61278168, Validation loss: 0.60688383, Gradient norm: 0.05586729
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8885.82421875MB
INFO:root:[  146] Training loss: 0.61285313, Validation loss: 0.60700987, Gradient norm: 0.05249591
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8923.95703125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  147] Training loss: 0.61276507, Validation loss: 0.60771233, Gradient norm: 0.05374662
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=8963.31640625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  148] Training loss: 0.61257123, Validation loss: 0.60662126, Gradient norm: 0.05139534
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9000.82421875MB
INFO:root:[  149] Training loss: 0.61244588, Validation loss: 0.60648756, Gradient norm: 0.05024092
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9038.9921875MB
INFO:root:EP 149: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12459.03515625MB; mem (CPU total)=9077.22265625MB
INFO:root:Training the model took 8208.422s.
INFO:root:Emptying the cuda cache took 0.007s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84212
INFO:root:EnergyScoreTrain: 0.59282
INFO:root:CRPSTrain: 0.4608
INFO:root:Gaussian NLLTrain: 1.1907
INFO:root:CoverageTrain: 0.94923
INFO:root:IntervalWidthTrain: 3.25845
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86203
INFO:root:EnergyScoreValidation: 0.60676
INFO:root:CRPSValidation: 0.47266
INFO:root:Gaussian NLLValidation: 1.21748
INFO:root:CoverageValidation: 0.94267
INFO:root:IntervalWidthValidation: 3.26022
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8629
INFO:root:EnergyScoreTest: 0.60736
INFO:root:CRPSTest: 0.47311
INFO:root:Gaussian NLLTest: 1.21842
INFO:root:CoverageTest: 0.9425
INFO:root:IntervalWidthTest: 3.2623
INFO:root:After validation: mem (CPU python)=12459.03515625MB; mem (CPU total)=9123.0859375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=12459.03515625MB; mem (CPU total)=9123.3203125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12459.03515625MB; mem (CPU total)=9123.56640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9123.8125MB
INFO:root:[    1] Training loss: 0.72516692, Validation loss: 0.71998839, Gradient norm: 0.02230272
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9161.81640625MB
INFO:root:[    2] Training loss: 0.71969532, Validation loss: 0.71853247, Gradient norm: 0.00545449
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9200.20703125MB
INFO:root:[    3] Training loss: 0.71727520, Validation loss: 0.71269288, Gradient norm: 0.00891262
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9238.34375MB
INFO:root:[    4] Training loss: 0.70992721, Validation loss: 0.70328635, Gradient norm: 0.01835563
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9276.4765625MB
INFO:root:[    5] Training loss: 0.70289540, Validation loss: 0.69667334, Gradient norm: 0.02366434
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9314.86328125MB
INFO:root:[    6] Training loss: 0.69718297, Validation loss: 0.69003340, Gradient norm: 0.02851941
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9353.23828125MB
INFO:root:[    7] Training loss: 0.69263825, Validation loss: 0.68526794, Gradient norm: 0.02916395
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9391.59765625MB
INFO:root:[    8] Training loss: 0.68864653, Validation loss: 0.68183421, Gradient norm: 0.02984004
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9429.7421875MB
INFO:root:[    9] Training loss: 0.68519739, Validation loss: 0.67790634, Gradient norm: 0.03126732
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9469.109375MB
INFO:root:[   10] Training loss: 0.68215452, Validation loss: 0.67443827, Gradient norm: 0.03265300
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9507.28125MB
INFO:root:[   11] Training loss: 0.67950594, Validation loss: 0.67180794, Gradient norm: 0.03019969
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9545.42578125MB
INFO:root:[   12] Training loss: 0.67702834, Validation loss: 0.66934504, Gradient norm: 0.03046683
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9583.5703125MB
INFO:root:[   13] Training loss: 0.67490207, Validation loss: 0.66704903, Gradient norm: 0.03429492
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9621.43359375MB
INFO:root:[   14] Training loss: 0.67273974, Validation loss: 0.66475557, Gradient norm: 0.03391679
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9659.81640625MB
INFO:root:[   15] Training loss: 0.67093519, Validation loss: 0.66304341, Gradient norm: 0.03239288
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9697.91796875MB
INFO:root:[   16] Training loss: 0.66890804, Validation loss: 0.66122048, Gradient norm: 0.03215828
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9736.08984375MB
INFO:root:[   17] Training loss: 0.66709043, Validation loss: 0.65892220, Gradient norm: 0.03492034
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9773.96875MB
INFO:root:[   18] Training loss: 0.66535476, Validation loss: 0.65610899, Gradient norm: 0.03524737
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9811.8203125MB
INFO:root:[   19] Training loss: 0.66357746, Validation loss: 0.65450821, Gradient norm: 0.03358656
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9849.6171875MB
INFO:root:[   20] Training loss: 0.66209724, Validation loss: 0.65255850, Gradient norm: 0.03640222
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9887.99609375MB
INFO:root:[   21] Training loss: 0.66061715, Validation loss: 0.65150464, Gradient norm: 0.03508838
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9926.140625MB
INFO:root:[   22] Training loss: 0.65879064, Validation loss: 0.64888668, Gradient norm: 0.03529641
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=9964.0390625MB
INFO:root:[   23] Training loss: 0.65766413, Validation loss: 0.64768299, Gradient norm: 0.03997219
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10003.17578125MB
INFO:root:[   24] Training loss: 0.65638155, Validation loss: 0.64582998, Gradient norm: 0.03524974
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10041.29296875MB
INFO:root:[   25] Training loss: 0.65515016, Validation loss: 0.64497949, Gradient norm: 0.03623543
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10079.68359375MB
INFO:root:[   26] Training loss: 0.65385076, Validation loss: 0.64384616, Gradient norm: 0.03825576
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10118.125MB
INFO:root:[   27] Training loss: 0.65285322, Validation loss: 0.64245928, Gradient norm: 0.03883613
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10155.83203125MB
INFO:root:[   28] Training loss: 0.65172090, Validation loss: 0.64146085, Gradient norm: 0.03812996
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10194.421875MB
INFO:root:[   29] Training loss: 0.65077533, Validation loss: 0.64069149, Gradient norm: 0.03976922
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10232.56640625MB
INFO:root:[   30] Training loss: 0.64989640, Validation loss: 0.64092263, Gradient norm: 0.03964993
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10271.13671875MB
INFO:root:[   31] Training loss: 0.64895834, Validation loss: 0.63841838, Gradient norm: 0.04189790
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10309.04296875MB
INFO:root:[   32] Training loss: 0.64792951, Validation loss: 0.63888584, Gradient norm: 0.04190984
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10347.64453125MB
INFO:root:[   33] Training loss: 0.64724416, Validation loss: 0.63675939, Gradient norm: 0.04162062
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10385.32421875MB
INFO:root:[   34] Training loss: 0.64653555, Validation loss: 0.63608191, Gradient norm: 0.04569890
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10423.6953125MB
INFO:root:[   35] Training loss: 0.64551375, Validation loss: 0.63462677, Gradient norm: 0.04013447
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10461.83984375MB
INFO:root:[   36] Training loss: 0.64501823, Validation loss: 0.63445549, Gradient norm: 0.04545889
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10499.96484375MB
INFO:root:[   37] Training loss: 0.64422138, Validation loss: 0.63357019, Gradient norm: 0.04310164
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10538.33203125MB
INFO:root:[   38] Training loss: 0.64340551, Validation loss: 0.63327683, Gradient norm: 0.04593434
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10576.46875MB
INFO:root:[   39] Training loss: 0.64259124, Validation loss: 0.63339381, Gradient norm: 0.04371189
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10615.10546875MB
INFO:root:[   40] Training loss: 0.64192901, Validation loss: 0.63245487, Gradient norm: 0.04252814
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10652.7578125MB
INFO:root:[   41] Training loss: 0.64133679, Validation loss: 0.63067226, Gradient norm: 0.04461011
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10691.1484375MB
INFO:root:[   42] Training loss: 0.64073811, Validation loss: 0.63139645, Gradient norm: 0.04493241
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10729.28515625MB
INFO:root:[   43] Training loss: 0.64035805, Validation loss: 0.63116344, Gradient norm: 0.04457075
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10767.42578125MB
INFO:root:[   44] Training loss: 0.63959700, Validation loss: 0.62984640, Gradient norm: 0.04332529
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10805.0234375MB
INFO:root:[   45] Training loss: 0.63929881, Validation loss: 0.62816192, Gradient norm: 0.04878962
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10843.4453125MB
INFO:root:[   46] Training loss: 0.63855970, Validation loss: 0.62904184, Gradient norm: 0.04614880
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10881.765625MB
INFO:root:[   47] Training loss: 0.63782981, Validation loss: 0.62874514, Gradient norm: 0.04290616
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10919.859375MB
INFO:root:[   48] Training loss: 0.63757815, Validation loss: 0.62884590, Gradient norm: 0.04463536
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10957.99609375MB
INFO:root:[   49] Training loss: 0.63708549, Validation loss: 0.62691192, Gradient norm: 0.04678271
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=10995.6796875MB
INFO:root:[   50] Training loss: 0.63669200, Validation loss: 0.62880356, Gradient norm: 0.05425885
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11034.5625MB
INFO:root:[   51] Training loss: 0.63594197, Validation loss: 0.62705583, Gradient norm: 0.04818135
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11072.70703125MB
INFO:root:[   52] Training loss: 0.63573903, Validation loss: 0.62524924, Gradient norm: 0.04991962
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11109.8671875MB
INFO:root:[   53] Training loss: 0.63525637, Validation loss: 0.62513755, Gradient norm: 0.04743256
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11148.03125MB
INFO:root:[   54] Training loss: 0.63470932, Validation loss: 0.62448825, Gradient norm: 0.05008713
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11186.37109375MB
INFO:root:[   55] Training loss: 0.63418453, Validation loss: 0.62419007, Gradient norm: 0.04460127
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11224.03515625MB
INFO:root:[   56] Training loss: 0.63392666, Validation loss: 0.62540665, Gradient norm: 0.04630328
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11262.69921875MB
INFO:root:[   57] Training loss: 0.63345014, Validation loss: 0.62439093, Gradient norm: 0.04632519
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11300.84375MB
INFO:root:[   58] Training loss: 0.63303202, Validation loss: 0.62313585, Gradient norm: 0.04723086
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11338.26171875MB
INFO:root:[   59] Training loss: 0.63281058, Validation loss: 0.62180176, Gradient norm: 0.04925281
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11376.64453125MB
INFO:root:[   60] Training loss: 0.63220252, Validation loss: 0.62239030, Gradient norm: 0.04888068
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11415.32421875MB
INFO:root:[   61] Training loss: 0.63193762, Validation loss: 0.62238595, Gradient norm: 0.04437248
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11452.84375MB
INFO:root:[   62] Training loss: 0.63173992, Validation loss: 0.62236814, Gradient norm: 0.04715556
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11491.2421875MB
INFO:root:[   63] Training loss: 0.63113674, Validation loss: 0.62136485, Gradient norm: 0.05143435
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11529.1640625MB
INFO:root:[   64] Training loss: 0.63075444, Validation loss: 0.62311384, Gradient norm: 0.04983043
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11567.56640625MB
INFO:root:[   65] Training loss: 0.63056048, Validation loss: 0.62119130, Gradient norm: 0.05031289
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11605.48828125MB
INFO:root:[   66] Training loss: 0.63017973, Validation loss: 0.62131120, Gradient norm: 0.04821978
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11644.65625MB
INFO:root:[   67] Training loss: 0.62972469, Validation loss: 0.61952509, Gradient norm: 0.04901427
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11682.3125MB
INFO:root:[   68] Training loss: 0.62963782, Validation loss: 0.61994220, Gradient norm: 0.05223051
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11721.20703125MB
INFO:root:[   69] Training loss: 0.62923634, Validation loss: 0.61861587, Gradient norm: 0.04761568
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11758.66796875MB
INFO:root:[   70] Training loss: 0.62885895, Validation loss: 0.62046453, Gradient norm: 0.05388581
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11797.4765625MB
INFO:root:[   71] Training loss: 0.62857890, Validation loss: 0.61887903, Gradient norm: 0.05259148
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11835.64453125MB
INFO:root:[   72] Training loss: 0.62830931, Validation loss: 0.61764744, Gradient norm: 0.05518129
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11872.828125MB
INFO:root:[   73] Training loss: 0.62785258, Validation loss: 0.62043248, Gradient norm: 0.04920381
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11911.72265625MB
INFO:root:[   74] Training loss: 0.62778766, Validation loss: 0.61747984, Gradient norm: 0.04807871
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11949.37109375MB
INFO:root:[   75] Training loss: 0.62744737, Validation loss: 0.61820547, Gradient norm: 0.04924873
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=11988.0078125MB
INFO:root:[   76] Training loss: 0.62724963, Validation loss: 0.61959972, Gradient norm: 0.05026850
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=12026.328125MB
INFO:root:[   77] Training loss: 0.62693351, Validation loss: 0.61714311, Gradient norm: 0.05272826
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=12063.9296875MB
INFO:root:[   78] Training loss: 0.62664694, Validation loss: 0.61714197, Gradient norm: 0.05096490
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=12101.9765625MB
INFO:root:[   79] Training loss: 0.62621759, Validation loss: 0.61674717, Gradient norm: 0.05173997
INFO:root:At the start of the epoch: mem (CPU python)=12459.03515625MB; mem (CPU total)=12140.3984375MB
INFO:root:[   80] Training loss: 0.62605501, Validation loss: 0.61648301, Gradient norm: 0.05019871
INFO:root:At the start of the epoch: mem (CPU python)=12470.40625MB; mem (CPU total)=12178.53515625MB
INFO:root:[   81] Training loss: 0.62593759, Validation loss: 0.61671791, Gradient norm: 0.05175208
INFO:root:At the start of the epoch: mem (CPU python)=12508.5234375MB; mem (CPU total)=12217.171875MB
INFO:root:[   82] Training loss: 0.62566121, Validation loss: 0.61636465, Gradient norm: 0.05350041
INFO:root:At the start of the epoch: mem (CPU python)=12546.66796875MB; mem (CPU total)=12255.0703125MB
INFO:root:[   83] Training loss: 0.62528602, Validation loss: 0.61795301, Gradient norm: 0.05265082
INFO:root:At the start of the epoch: mem (CPU python)=12584.7734375MB; mem (CPU total)=12293.44921875MB
INFO:root:[   84] Training loss: 0.62519138, Validation loss: 0.61614158, Gradient norm: 0.05620435
INFO:root:At the start of the epoch: mem (CPU python)=12622.875MB; mem (CPU total)=12331.34375MB
INFO:root:[   85] Training loss: 0.62495110, Validation loss: 0.61673760, Gradient norm: 0.05113092
INFO:root:At the start of the epoch: mem (CPU python)=12660.96875MB; mem (CPU total)=12369.703125MB
INFO:root:[   86] Training loss: 0.62459669, Validation loss: 0.61600204, Gradient norm: 0.05101361
INFO:root:At the start of the epoch: mem (CPU python)=12699.00390625MB; mem (CPU total)=12407.52734375MB
INFO:root:[   87] Training loss: 0.62429743, Validation loss: 0.61636723, Gradient norm: 0.04987360
INFO:root:At the start of the epoch: mem (CPU python)=12737.12109375MB; mem (CPU total)=12446.1328125MB
INFO:root:[   88] Training loss: 0.62413500, Validation loss: 0.61428971, Gradient norm: 0.05575965
INFO:root:At the start of the epoch: mem (CPU python)=12775.13671875MB; mem (CPU total)=12483.77734375MB
INFO:root:[   89] Training loss: 0.62394704, Validation loss: 0.61423068, Gradient norm: 0.05661258
INFO:root:At the start of the epoch: mem (CPU python)=12813.296875MB; mem (CPU total)=12521.953125MB
INFO:root:[   90] Training loss: 0.62356483, Validation loss: 0.61566411, Gradient norm: 0.05255779
INFO:root:At the start of the epoch: mem (CPU python)=12851.390625MB; mem (CPU total)=12561.08203125MB
INFO:root:[   91] Training loss: 0.62355031, Validation loss: 0.61399328, Gradient norm: 0.05584945
INFO:root:At the start of the epoch: mem (CPU python)=12889.46484375MB; mem (CPU total)=12598.3828125MB
INFO:root:[   92] Training loss: 0.62321284, Validation loss: 0.61479339, Gradient norm: 0.05747284
INFO:root:At the start of the epoch: mem (CPU python)=12927.5859375MB; mem (CPU total)=12637.2578125MB
INFO:root:[   93] Training loss: 0.62331423, Validation loss: 0.61441463, Gradient norm: 0.05209881
INFO:root:At the start of the epoch: mem (CPU python)=12965.6796875MB; mem (CPU total)=12674.11328125MB
INFO:root:[   94] Training loss: 0.62288125, Validation loss: 0.61533094, Gradient norm: 0.05026657
INFO:root:At the start of the epoch: mem (CPU python)=13003.78125MB; mem (CPU total)=12712.65234375MB
INFO:root:[   95] Training loss: 0.62274686, Validation loss: 0.61293214, Gradient norm: 0.05734479
INFO:root:At the start of the epoch: mem (CPU python)=13041.875MB; mem (CPU total)=12750.578125MB
INFO:root:[   96] Training loss: 0.62245069, Validation loss: 0.61418842, Gradient norm: 0.05346976
INFO:root:At the start of the epoch: mem (CPU python)=13079.97265625MB; mem (CPU total)=12789.41015625MB
INFO:root:[   97] Training loss: 0.62211034, Validation loss: 0.61465297, Gradient norm: 0.05195521
INFO:root:At the start of the epoch: mem (CPU python)=13118.11328125MB; mem (CPU total)=12827.5390625MB
INFO:root:[   98] Training loss: 0.62191752, Validation loss: 0.61355791, Gradient norm: 0.05012385
INFO:root:At the start of the epoch: mem (CPU python)=13156.21875MB; mem (CPU total)=12865.68359375MB
INFO:root:[   99] Training loss: 0.62186152, Validation loss: 0.61489632, Gradient norm: 0.05185034
INFO:root:At the start of the epoch: mem (CPU python)=13194.3125MB; mem (CPU total)=12903.69140625MB
INFO:root:[  100] Training loss: 0.62139878, Validation loss: 0.61407018, Gradient norm: 0.05393133
INFO:root:At the start of the epoch: mem (CPU python)=13232.41015625MB; mem (CPU total)=12941.3125MB
INFO:root:[  101] Training loss: 0.62143532, Validation loss: 0.61713858, Gradient norm: 0.05615401
INFO:root:At the start of the epoch: mem (CPU python)=13270.5078125MB; mem (CPU total)=12979.4453125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  102] Training loss: 0.62127627, Validation loss: 0.61399714, Gradient norm: 0.05033192
INFO:root:At the start of the epoch: mem (CPU python)=13308.59765625MB; mem (CPU total)=13017.33203125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  103] Training loss: 0.62053466, Validation loss: 0.61226551, Gradient norm: 0.05632443
INFO:root:At the start of the epoch: mem (CPU python)=13346.64453125MB; mem (CPU total)=13055.44921875MB
INFO:root:[  104] Training loss: 0.61943035, Validation loss: 0.61193304, Gradient norm: 0.04532997
INFO:root:At the start of the epoch: mem (CPU python)=13384.765625MB; mem (CPU total)=13094.07421875MB
INFO:root:[  105] Training loss: 0.61946752, Validation loss: 0.61191901, Gradient norm: 0.04403546
INFO:root:At the start of the epoch: mem (CPU python)=13422.875MB; mem (CPU total)=13132.21875MB
INFO:root:[  106] Training loss: 0.61946019, Validation loss: 0.61192451, Gradient norm: 0.04540880
INFO:root:At the start of the epoch: mem (CPU python)=13460.96875MB; mem (CPU total)=13170.59765625MB
INFO:root:[  107] Training loss: 0.61918860, Validation loss: 0.61214803, Gradient norm: 0.04672638
INFO:root:At the start of the epoch: mem (CPU python)=13499.015625MB; mem (CPU total)=13209.2265625MB
INFO:root:[  108] Training loss: 0.61943283, Validation loss: 0.61262522, Gradient norm: 0.04544324
INFO:root:At the start of the epoch: mem (CPU python)=13537.109375MB; mem (CPU total)=13247.37109375MB
INFO:root:[  109] Training loss: 0.61937605, Validation loss: 0.61100507, Gradient norm: 0.04587206
INFO:root:At the start of the epoch: mem (CPU python)=13575.203125MB; mem (CPU total)=13285.0546875MB
INFO:root:[  110] Training loss: 0.61920145, Validation loss: 0.61200977, Gradient norm: 0.04675096
INFO:root:At the start of the epoch: mem (CPU python)=13613.30859375MB; mem (CPU total)=13323.67578125MB
INFO:root:[  111] Training loss: 0.61895949, Validation loss: 0.61172598, Gradient norm: 0.04422006
INFO:root:At the start of the epoch: mem (CPU python)=13651.40234375MB; mem (CPU total)=13361.81640625MB
INFO:root:[  112] Training loss: 0.61914295, Validation loss: 0.61095813, Gradient norm: 0.04589551
INFO:root:At the start of the epoch: mem (CPU python)=13689.49609375MB; mem (CPU total)=13399.4453125MB
INFO:root:[  113] Training loss: 0.61903480, Validation loss: 0.61122701, Gradient norm: 0.04551905
INFO:root:At the start of the epoch: mem (CPU python)=13727.59375MB; mem (CPU total)=13438.3125MB
INFO:root:[  114] Training loss: 0.61882512, Validation loss: 0.61285074, Gradient norm: 0.04665683
INFO:root:At the start of the epoch: mem (CPU python)=13765.6875MB; mem (CPU total)=13476.390625MB
INFO:root:[  115] Training loss: 0.61884128, Validation loss: 0.61110209, Gradient norm: 0.05236531
INFO:root:At the start of the epoch: mem (CPU python)=13803.73046875MB; mem (CPU total)=13514.34765625MB
INFO:root:[  116] Training loss: 0.61881480, Validation loss: 0.61076260, Gradient norm: 0.04837823
INFO:root:At the start of the epoch: mem (CPU python)=13841.828125MB; mem (CPU total)=13551.9921875MB
INFO:root:[  117] Training loss: 0.61889181, Validation loss: 0.61177051, Gradient norm: 0.04643365
INFO:root:At the start of the epoch: mem (CPU python)=13879.95703125MB; mem (CPU total)=13590.62890625MB
INFO:root:[  118] Training loss: 0.61847501, Validation loss: 0.61076512, Gradient norm: 0.04596775
INFO:root:At the start of the epoch: mem (CPU python)=13918.125MB; mem (CPU total)=13629.01953125MB
INFO:root:[  119] Training loss: 0.61849753, Validation loss: 0.61100027, Gradient norm: 0.04758041
INFO:root:At the start of the epoch: mem (CPU python)=13956.21875MB; mem (CPU total)=13666.91015625MB
INFO:root:[  120] Training loss: 0.61882356, Validation loss: 0.61071151, Gradient norm: 0.04761922
INFO:root:At the start of the epoch: mem (CPU python)=13994.3125MB; mem (CPU total)=13704.609375MB
INFO:root:[  121] Training loss: 0.61871550, Validation loss: 0.61009317, Gradient norm: 0.04613097
INFO:root:At the start of the epoch: mem (CPU python)=14032.40234375MB; mem (CPU total)=13742.87890625MB
INFO:root:[  122] Training loss: 0.61849638, Validation loss: 0.61115491, Gradient norm: 0.04669933
INFO:root:At the start of the epoch: mem (CPU python)=14070.5078125MB; mem (CPU total)=13781.28515625MB
INFO:root:[  123] Training loss: 0.61849870, Validation loss: 0.61033949, Gradient norm: 0.04717408
INFO:root:At the start of the epoch: mem (CPU python)=14108.6015625MB; mem (CPU total)=13819.4453125MB
INFO:root:[  124] Training loss: 0.61859278, Validation loss: 0.61056183, Gradient norm: 0.04921839
INFO:root:At the start of the epoch: mem (CPU python)=14146.703125MB; mem (CPU total)=13857.52734375MB
INFO:root:[  125] Training loss: 0.61840627, Validation loss: 0.61013533, Gradient norm: 0.04696656
INFO:root:At the start of the epoch: mem (CPU python)=14184.76953125MB; mem (CPU total)=13895.60546875MB
INFO:root:[  126] Training loss: 0.61827429, Validation loss: 0.61051744, Gradient norm: 0.04576684
INFO:root:At the start of the epoch: mem (CPU python)=14222.88671875MB; mem (CPU total)=13933.73828125MB
INFO:root:[  127] Training loss: 0.61837851, Validation loss: 0.61073849, Gradient norm: 0.04795810
INFO:root:At the start of the epoch: mem (CPU python)=14260.98828125MB; mem (CPU total)=13972.15234375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  128] Training loss: 0.61845651, Validation loss: 0.61080536, Gradient norm: 0.04659440
INFO:root:At the start of the epoch: mem (CPU python)=14299.0MB; mem (CPU total)=14010.8125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  129] Training loss: 0.61803350, Validation loss: 0.61035807, Gradient norm: 0.04554036
INFO:root:At the start of the epoch: mem (CPU python)=14337.10546875MB; mem (CPU total)=14048.734375MB
INFO:root:[  130] Training loss: 0.61758709, Validation loss: 0.61055188, Gradient norm: 0.04396870
INFO:root:At the start of the epoch: mem (CPU python)=14375.21875MB; mem (CPU total)=14086.890625MB
INFO:root:EP 130: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=14413.3203125MB; mem (CPU total)=14125.32421875MB
INFO:root:Training the model took 7970.13s.
INFO:root:Emptying the cuda cache took 0.005s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85119
INFO:root:EnergyScoreTrain: 0.59915
INFO:root:CRPSTrain: 0.46702
INFO:root:Gaussian NLLTrain: 1.20521
INFO:root:CoverageTrain: 0.94669
INFO:root:IntervalWidthTrain: 3.26755
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86746
INFO:root:EnergyScoreValidation: 0.61055
INFO:root:CRPSValidation: 0.47675
INFO:root:Gaussian NLLValidation: 1.22723
INFO:root:CoverageValidation: 0.94129
INFO:root:IntervalWidthValidation: 3.26924
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86918
INFO:root:EnergyScoreTest: 0.61175
INFO:root:CRPSTest: 0.47775
INFO:root:Gaussian NLLTest: 1.22905
INFO:root:CoverageTest: 0.94089
INFO:root:IntervalWidthTest: 3.27074
INFO:root:After validation: mem (CPU python)=14485.55859375MB; mem (CPU total)=14260.55078125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=14485.55859375MB; mem (CPU total)=14260.5546875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=14485.5703125MB; mem (CPU total)=14142.0234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=14485.5703125MB; mem (CPU total)=14141.875MB
INFO:root:[    1] Training loss: 0.72427310, Validation loss: 0.72036341, Gradient norm: 0.01863044
INFO:root:At the start of the epoch: mem (CPU python)=14497.125MB; mem (CPU total)=14210.24609375MB
INFO:root:[    2] Training loss: 0.71972107, Validation loss: 0.71893861, Gradient norm: 0.00587100
INFO:root:At the start of the epoch: mem (CPU python)=14535.1796875MB; mem (CPU total)=14248.6953125MB
INFO:root:[    3] Training loss: 0.71747853, Validation loss: 0.71294436, Gradient norm: 0.00829848
INFO:root:At the start of the epoch: mem (CPU python)=14573.32421875MB; mem (CPU total)=14286.87109375MB
INFO:root:[    4] Training loss: 0.71006611, Validation loss: 0.70400447, Gradient norm: 0.01990050
INFO:root:At the start of the epoch: mem (CPU python)=14611.44140625MB; mem (CPU total)=14325.26953125MB
INFO:root:[    5] Training loss: 0.70317439, Validation loss: 0.69702808, Gradient norm: 0.02589401
INFO:root:At the start of the epoch: mem (CPU python)=14649.5390625MB; mem (CPU total)=14363.68359375MB
INFO:root:[    6] Training loss: 0.69787515, Validation loss: 0.69154979, Gradient norm: 0.02842868
INFO:root:At the start of the epoch: mem (CPU python)=14687.65625MB; mem (CPU total)=14401.85546875MB
INFO:root:[    7] Training loss: 0.69286019, Validation loss: 0.68611042, Gradient norm: 0.02918734
INFO:root:At the start of the epoch: mem (CPU python)=14725.7734375MB; mem (CPU total)=14439.63671875MB
INFO:root:[    8] Training loss: 0.68835967, Validation loss: 0.68074074, Gradient norm: 0.03011127
INFO:root:At the start of the epoch: mem (CPU python)=14763.8671875MB; mem (CPU total)=14477.546875MB
INFO:root:[    9] Training loss: 0.68403793, Validation loss: 0.67606847, Gradient norm: 0.03312745
INFO:root:At the start of the epoch: mem (CPU python)=14801.96484375MB; mem (CPU total)=14515.71484375MB
INFO:root:[   10] Training loss: 0.68010513, Validation loss: 0.67136842, Gradient norm: 0.03189358
INFO:root:At the start of the epoch: mem (CPU python)=14840.0625MB; mem (CPU total)=14553.88671875MB
INFO:root:[   11] Training loss: 0.67678130, Validation loss: 0.66758686, Gradient norm: 0.03214990
INFO:root:At the start of the epoch: mem (CPU python)=14878.15625MB; mem (CPU total)=14592.23046875MB
INFO:root:[   12] Training loss: 0.67342153, Validation loss: 0.66431998, Gradient norm: 0.03328460
INFO:root:At the start of the epoch: mem (CPU python)=14916.2421875MB; mem (CPU total)=14630.625MB
INFO:root:[   13] Training loss: 0.67063267, Validation loss: 0.66138296, Gradient norm: 0.03281110
INFO:root:At the start of the epoch: mem (CPU python)=14954.30078125MB; mem (CPU total)=14668.8671875MB
INFO:root:[   14] Training loss: 0.66790791, Validation loss: 0.65769499, Gradient norm: 0.03318686
INFO:root:At the start of the epoch: mem (CPU python)=14992.4375MB; mem (CPU total)=14707.0078125MB
INFO:root:[   15] Training loss: 0.66533528, Validation loss: 0.65636666, Gradient norm: 0.03361239
INFO:root:At the start of the epoch: mem (CPU python)=15030.5MB; mem (CPU total)=14745.1015625MB
INFO:root:[   16] Training loss: 0.66338721, Validation loss: 0.65334000, Gradient norm: 0.03563249
INFO:root:At the start of the epoch: mem (CPU python)=15068.62890625MB; mem (CPU total)=14782.8671875MB
INFO:root:[   17] Training loss: 0.66140392, Validation loss: 0.65070743, Gradient norm: 0.03744752
INFO:root:At the start of the epoch: mem (CPU python)=15106.7265625MB; mem (CPU total)=14820.98828125MB
INFO:root:[   18] Training loss: 0.65980719, Validation loss: 0.64964770, Gradient norm: 0.04285658
INFO:root:At the start of the epoch: mem (CPU python)=15144.828125MB; mem (CPU total)=14859.37890625MB
INFO:root:[   19] Training loss: 0.65791914, Validation loss: 0.64802879, Gradient norm: 0.03548576
INFO:root:At the start of the epoch: mem (CPU python)=15182.91015625MB; mem (CPU total)=14897.515625MB
INFO:root:[   20] Training loss: 0.65631141, Validation loss: 0.64548702, Gradient norm: 0.03616398
INFO:root:At the start of the epoch: mem (CPU python)=15221.01171875MB; mem (CPU total)=14935.640625MB
INFO:root:[   21] Training loss: 0.65496621, Validation loss: 0.64471966, Gradient norm: 0.03873769
INFO:root:At the start of the epoch: mem (CPU python)=15259.11328125MB; mem (CPU total)=14973.78515625MB
INFO:root:[   22] Training loss: 0.65361680, Validation loss: 0.64353524, Gradient norm: 0.03857130
INFO:root:At the start of the epoch: mem (CPU python)=15297.203125MB; mem (CPU total)=15011.9296875MB
INFO:root:[   23] Training loss: 0.65231632, Validation loss: 0.64198926, Gradient norm: 0.04080018
INFO:root:At the start of the epoch: mem (CPU python)=15335.3046875MB; mem (CPU total)=15050.05078125MB
INFO:root:[   24] Training loss: 0.65116568, Validation loss: 0.64085169, Gradient norm: 0.04036417
INFO:root:At the start of the epoch: mem (CPU python)=15373.34765625MB; mem (CPU total)=15088.1953125MB
INFO:root:[   25] Training loss: 0.65025302, Validation loss: 0.63943626, Gradient norm: 0.04509714
INFO:root:At the start of the epoch: mem (CPU python)=15411.328125MB; mem (CPU total)=15126.83203125MB
INFO:root:[   26] Training loss: 0.64930643, Validation loss: 0.63838021, Gradient norm: 0.04382152
INFO:root:At the start of the epoch: mem (CPU python)=15449.52734375MB; mem (CPU total)=15164.95703125MB
INFO:root:[   27] Training loss: 0.64807965, Validation loss: 0.63774728, Gradient norm: 0.04125965
INFO:root:At the start of the epoch: mem (CPU python)=15487.63671875MB; mem (CPU total)=15202.34375MB
INFO:root:[   28] Training loss: 0.64701367, Validation loss: 0.63635073, Gradient norm: 0.04268407
INFO:root:At the start of the epoch: mem (CPU python)=15525.73046875MB; mem (CPU total)=15240.734375MB
INFO:root:[   29] Training loss: 0.64636258, Validation loss: 0.63633460, Gradient norm: 0.04847419
INFO:root:At the start of the epoch: mem (CPU python)=15563.80859375MB; mem (CPU total)=15278.578125MB
INFO:root:[   30] Training loss: 0.64555065, Validation loss: 0.63576369, Gradient norm: 0.04509649
INFO:root:At the start of the epoch: mem (CPU python)=15601.921875MB; mem (CPU total)=15316.69140625MB
INFO:root:[   31] Training loss: 0.64457526, Validation loss: 0.63475367, Gradient norm: 0.04924427
INFO:root:At the start of the epoch: mem (CPU python)=15640.015625MB; mem (CPU total)=15355.07421875MB
INFO:root:[   32] Training loss: 0.64398552, Validation loss: 0.63329561, Gradient norm: 0.04758096
INFO:root:At the start of the epoch: mem (CPU python)=15678.04296875MB; mem (CPU total)=15393.73828125MB
INFO:root:[   33] Training loss: 0.64309874, Validation loss: 0.63354322, Gradient norm: 0.05047032
INFO:root:At the start of the epoch: mem (CPU python)=15716.19140625MB; mem (CPU total)=15432.375MB
INFO:root:[   34] Training loss: 0.64240010, Validation loss: 0.63170325, Gradient norm: 0.04274757
INFO:root:At the start of the epoch: mem (CPU python)=15754.29296875MB; mem (CPU total)=15469.78125MB
INFO:root:[   35] Training loss: 0.64165512, Validation loss: 0.63121661, Gradient norm: 0.04303412
INFO:root:At the start of the epoch: mem (CPU python)=15792.3828125MB; mem (CPU total)=15507.92578125MB
INFO:root:[   36] Training loss: 0.64113318, Validation loss: 0.63126920, Gradient norm: 0.04919355
INFO:root:At the start of the epoch: mem (CPU python)=15830.5078125MB; mem (CPU total)=15546.8125MB
INFO:root:[   37] Training loss: 0.64041194, Validation loss: 0.63005535, Gradient norm: 0.04558630
INFO:root:At the start of the epoch: mem (CPU python)=15868.640625MB; mem (CPU total)=15584.234375MB
INFO:root:[   38] Training loss: 0.63974424, Validation loss: 0.62992008, Gradient norm: 0.04291946
INFO:root:At the start of the epoch: mem (CPU python)=15906.734375MB; mem (CPU total)=15622.75390625MB
INFO:root:[   39] Training loss: 0.63922675, Validation loss: 0.62977062, Gradient norm: 0.04922159
INFO:root:At the start of the epoch: mem (CPU python)=15944.828125MB; mem (CPU total)=15660.515625MB
INFO:root:[   40] Training loss: 0.63842805, Validation loss: 0.62808357, Gradient norm: 0.04929674
INFO:root:At the start of the epoch: mem (CPU python)=15982.92578125MB; mem (CPU total)=15698.921875MB
INFO:root:[   41] Training loss: 0.63797335, Validation loss: 0.62876186, Gradient norm: 0.05087248
INFO:root:At the start of the epoch: mem (CPU python)=16021.0234375MB; mem (CPU total)=15737.32421875MB
INFO:root:[   42] Training loss: 0.63751012, Validation loss: 0.62729041, Gradient norm: 0.04833985
INFO:root:At the start of the epoch: mem (CPU python)=16059.109375MB; mem (CPU total)=15775.23046875MB
INFO:root:[   43] Training loss: 0.63686452, Validation loss: 0.62679810, Gradient norm: 0.04575164
INFO:root:At the start of the epoch: mem (CPU python)=16097.2109375MB; mem (CPU total)=15813.578125MB
INFO:root:[   44] Training loss: 0.63650755, Validation loss: 0.62673915, Gradient norm: 0.04975280
INFO:root:At the start of the epoch: mem (CPU python)=16135.28515625MB; mem (CPU total)=15851.32421875MB
INFO:root:[   45] Training loss: 0.63599146, Validation loss: 0.62629289, Gradient norm: 0.05656239
INFO:root:At the start of the epoch: mem (CPU python)=16173.34765625MB; mem (CPU total)=15889.7265625MB
INFO:root:[   46] Training loss: 0.63519518, Validation loss: 0.62473216, Gradient norm: 0.04832856
INFO:root:At the start of the epoch: mem (CPU python)=16211.43359375MB; mem (CPU total)=15927.8984375MB
INFO:root:[   47] Training loss: 0.63491114, Validation loss: 0.62373271, Gradient norm: 0.05245451
INFO:root:At the start of the epoch: mem (CPU python)=16249.5390625MB; mem (CPU total)=15966.05078125MB
INFO:root:[   48] Training loss: 0.63426764, Validation loss: 0.62421538, Gradient norm: 0.04832900
INFO:root:At the start of the epoch: mem (CPU python)=16287.6328125MB; mem (CPU total)=16004.5MB
INFO:root:[   49] Training loss: 0.63403886, Validation loss: 0.62594859, Gradient norm: 0.05127769
INFO:root:At the start of the epoch: mem (CPU python)=16325.73046875MB; mem (CPU total)=16042.73046875MB
INFO:root:[   50] Training loss: 0.63359790, Validation loss: 0.62392924, Gradient norm: 0.06163213
INFO:root:At the start of the epoch: mem (CPU python)=16363.82421875MB; mem (CPU total)=16080.8359375MB
INFO:root:[   51] Training loss: 0.63302549, Validation loss: 0.62326783, Gradient norm: 0.05265046
INFO:root:At the start of the epoch: mem (CPU python)=16401.9140625MB; mem (CPU total)=16118.48828125MB
INFO:root:[   52] Training loss: 0.63256048, Validation loss: 0.62258287, Gradient norm: 0.04727346
INFO:root:At the start of the epoch: mem (CPU python)=16439.91796875MB; mem (CPU total)=16156.828125MB
INFO:root:[   53] Training loss: 0.63217966, Validation loss: 0.62237605, Gradient norm: 0.05057444
INFO:root:At the start of the epoch: mem (CPU python)=16478.109375MB; mem (CPU total)=16195.00390625MB
INFO:root:[   54] Training loss: 0.63163866, Validation loss: 0.62162319, Gradient norm: 0.05057881
INFO:root:At the start of the epoch: mem (CPU python)=16516.20703125MB; mem (CPU total)=16232.61328125MB
INFO:root:[   55] Training loss: 0.63142320, Validation loss: 0.62300005, Gradient norm: 0.05585000
INFO:root:At the start of the epoch: mem (CPU python)=16554.34765625MB; mem (CPU total)=16271.2890625MB
INFO:root:[   56] Training loss: 0.63112179, Validation loss: 0.62175088, Gradient norm: 0.05351631
INFO:root:At the start of the epoch: mem (CPU python)=16592.44921875MB; mem (CPU total)=16309.3828125MB
INFO:root:[   57] Training loss: 0.63066859, Validation loss: 0.62126482, Gradient norm: 0.05807778
INFO:root:At the start of the epoch: mem (CPU python)=16630.54296875MB; mem (CPU total)=16347.03515625MB
INFO:root:[   58] Training loss: 0.63019808, Validation loss: 0.62151089, Gradient norm: 0.05033802
INFO:root:At the start of the epoch: mem (CPU python)=16668.6328125MB; mem (CPU total)=16385.94921875MB
INFO:root:[   59] Training loss: 0.62999098, Validation loss: 0.62108808, Gradient norm: 0.05290600
INFO:root:At the start of the epoch: mem (CPU python)=16706.65625MB; mem (CPU total)=16423.5625MB
INFO:root:[   60] Training loss: 0.62958194, Validation loss: 0.62077358, Gradient norm: 0.05503187
INFO:root:At the start of the epoch: mem (CPU python)=16744.8125MB; mem (CPU total)=16462.16796875MB
INFO:root:[   61] Training loss: 0.62937234, Validation loss: 0.61970140, Gradient norm: 0.05899598
INFO:root:At the start of the epoch: mem (CPU python)=16782.90625MB; mem (CPU total)=16500.06640625MB
INFO:root:[   62] Training loss: 0.62890963, Validation loss: 0.61932746, Gradient norm: 0.05177022
INFO:root:At the start of the epoch: mem (CPU python)=16821.0234375MB; mem (CPU total)=16538.45703125MB
INFO:root:[   63] Training loss: 0.62848150, Validation loss: 0.61906832, Gradient norm: 0.05293454
INFO:root:At the start of the epoch: mem (CPU python)=16859.109375MB; mem (CPU total)=16576.5390625MB
INFO:root:[   64] Training loss: 0.62841997, Validation loss: 0.61882511, Gradient norm: 0.05723372
INFO:root:At the start of the epoch: mem (CPU python)=16897.21484375MB; mem (CPU total)=16613.953125MB
INFO:root:[   65] Training loss: 0.62787938, Validation loss: 0.61819925, Gradient norm: 0.05643222
INFO:root:At the start of the epoch: mem (CPU python)=16935.3125MB; mem (CPU total)=16652.3984375MB
INFO:root:[   66] Training loss: 0.62761618, Validation loss: 0.61816055, Gradient norm: 0.05596203
INFO:root:At the start of the epoch: mem (CPU python)=16973.35546875MB; mem (CPU total)=16690.75MB
INFO:root:[   67] Training loss: 0.62728073, Validation loss: 0.61867856, Gradient norm: 0.05090167
INFO:root:At the start of the epoch: mem (CPU python)=17011.421875MB; mem (CPU total)=16729.37109375MB
INFO:root:[   68] Training loss: 0.62699144, Validation loss: 0.61816162, Gradient norm: 0.05690582
INFO:root:At the start of the epoch: mem (CPU python)=17049.60546875MB; mem (CPU total)=16767.484375MB
INFO:root:[   69] Training loss: 0.62668332, Validation loss: 0.61880605, Gradient norm: 0.05630831
INFO:root:At the start of the epoch: mem (CPU python)=17087.62890625MB; mem (CPU total)=16805.53125MB
INFO:root:[   70] Training loss: 0.62647706, Validation loss: 0.61780658, Gradient norm: 0.05449010
INFO:root:At the start of the epoch: mem (CPU python)=17125.72265625MB; mem (CPU total)=16843.140625MB
INFO:root:[   71] Training loss: 0.62617419, Validation loss: 0.61711251, Gradient norm: 0.05464793
INFO:root:At the start of the epoch: mem (CPU python)=17163.8203125MB; mem (CPU total)=16881.26953125MB
INFO:root:[   72] Training loss: 0.62586555, Validation loss: 0.61680077, Gradient norm: 0.06469630
INFO:root:At the start of the epoch: mem (CPU python)=17201.91796875MB; mem (CPU total)=16919.59375MB
INFO:root:[   73] Training loss: 0.62559940, Validation loss: 0.61685938, Gradient norm: 0.05670298
INFO:root:At the start of the epoch: mem (CPU python)=17240.01953125MB; mem (CPU total)=16958.55859375MB
INFO:root:[   74] Training loss: 0.62547041, Validation loss: 0.61631780, Gradient norm: 0.05571546
INFO:root:At the start of the epoch: mem (CPU python)=17278.11328125MB; mem (CPU total)=16996.44921875MB
INFO:root:[   75] Training loss: 0.62509070, Validation loss: 0.61642356, Gradient norm: 0.05657221
INFO:root:At the start of the epoch: mem (CPU python)=17316.15625MB; mem (CPU total)=17034.88671875MB
INFO:root:[   76] Training loss: 0.62485619, Validation loss: 0.61576847, Gradient norm: 0.05773842
INFO:root:At the start of the epoch: mem (CPU python)=17354.31640625MB; mem (CPU total)=17072.5546875MB
INFO:root:[   77] Training loss: 0.62454968, Validation loss: 0.61610733, Gradient norm: 0.05861142
INFO:root:At the start of the epoch: mem (CPU python)=17392.44140625MB; mem (CPU total)=17111.4375MB
INFO:root:[   78] Training loss: 0.62438824, Validation loss: 0.61633687, Gradient norm: 0.05953643
INFO:root:At the start of the epoch: mem (CPU python)=17430.5546875MB; mem (CPU total)=17149.828125MB
INFO:root:[   79] Training loss: 0.62416950, Validation loss: 0.61565722, Gradient norm: 0.05367347
INFO:root:At the start of the epoch: mem (CPU python)=17468.6484375MB; mem (CPU total)=17187.51171875MB
INFO:root:[   80] Training loss: 0.62407693, Validation loss: 0.61493571, Gradient norm: 0.05925321
INFO:root:At the start of the epoch: mem (CPU python)=17506.7421875MB; mem (CPU total)=17225.65625MB
INFO:root:[   81] Training loss: 0.62377031, Validation loss: 0.61465091, Gradient norm: 0.05970984
INFO:root:At the start of the epoch: mem (CPU python)=17544.83984375MB; mem (CPU total)=17263.03125MB
INFO:root:[   82] Training loss: 0.62326816, Validation loss: 0.61497258, Gradient norm: 0.06027568
INFO:root:At the start of the epoch: mem (CPU python)=17582.8984375MB; mem (CPU total)=17301.421875MB
INFO:root:[   83] Training loss: 0.62330041, Validation loss: 0.61438851, Gradient norm: 0.05528864
INFO:root:At the start of the epoch: mem (CPU python)=17621.015625MB; mem (CPU total)=17339.3203125MB
INFO:root:[   84] Training loss: 0.62289526, Validation loss: 0.61466819, Gradient norm: 0.05308206
INFO:root:At the start of the epoch: mem (CPU python)=17659.125MB; mem (CPU total)=17377.94140625MB
INFO:root:[   85] Training loss: 0.62269272, Validation loss: 0.61440854, Gradient norm: 0.06196260
INFO:root:At the start of the epoch: mem (CPU python)=17697.21484375MB; mem (CPU total)=17416.0859375MB
INFO:root:[   86] Training loss: 0.62230305, Validation loss: 0.61359679, Gradient norm: 0.05276942
INFO:root:At the start of the epoch: mem (CPU python)=17735.31640625MB; mem (CPU total)=17454.23046875MB
INFO:root:[   87] Training loss: 0.62213183, Validation loss: 0.61494607, Gradient norm: 0.05611022
INFO:root:At the start of the epoch: mem (CPU python)=17773.35546875MB; mem (CPU total)=17493.14453125MB
INFO:root:[   88] Training loss: 0.62212465, Validation loss: 0.61372988, Gradient norm: 0.06023366
INFO:root:At the start of the epoch: mem (CPU python)=17811.44921875MB; mem (CPU total)=17531.32421875MB
INFO:root:[   89] Training loss: 0.62187831, Validation loss: 0.61431205, Gradient norm: 0.06479067
INFO:root:At the start of the epoch: mem (CPU python)=17849.484375MB; mem (CPU total)=17569.65625MB
INFO:root:[   90] Training loss: 0.62159990, Validation loss: 0.61310524, Gradient norm: 0.06354717
INFO:root:At the start of the epoch: mem (CPU python)=17887.61328125MB; mem (CPU total)=17607.05078125MB
INFO:root:[   91] Training loss: 0.62148233, Validation loss: 0.61383642, Gradient norm: 0.05726886
INFO:root:At the start of the epoch: mem (CPU python)=17925.73828125MB; mem (CPU total)=17645.8984375MB
INFO:root:[   92] Training loss: 0.62133027, Validation loss: 0.61283354, Gradient norm: 0.06437656
INFO:root:At the start of the epoch: mem (CPU python)=17963.83984375MB; mem (CPU total)=17683.75390625MB
INFO:root:[   93] Training loss: 0.62112448, Validation loss: 0.61310918, Gradient norm: 0.06138946
INFO:root:At the start of the epoch: mem (CPU python)=18001.93359375MB; mem (CPU total)=17722.19921875MB
INFO:root:[   94] Training loss: 0.62091630, Validation loss: 0.61425262, Gradient norm: 0.06081025
INFO:root:At the start of the epoch: mem (CPU python)=18040.02734375MB; mem (CPU total)=17760.25390625MB
INFO:root:[   95] Training loss: 0.62092328, Validation loss: 0.61236019, Gradient norm: 0.06254368
INFO:root:At the start of the epoch: mem (CPU python)=18078.125MB; mem (CPU total)=17798.12890625MB
INFO:root:[   96] Training loss: 0.62039571, Validation loss: 0.61216732, Gradient norm: 0.05801846
INFO:root:At the start of the epoch: mem (CPU python)=18116.2109375MB; mem (CPU total)=17836.0859375MB
INFO:root:[   97] Training loss: 0.62035012, Validation loss: 0.61253972, Gradient norm: 0.06192977
INFO:root:At the start of the epoch: mem (CPU python)=18154.36328125MB; mem (CPU total)=17874.96484375MB
INFO:root:[   98] Training loss: 0.62002040, Validation loss: 0.61271844, Gradient norm: 0.05941488
INFO:root:At the start of the epoch: mem (CPU python)=18192.4609375MB; mem (CPU total)=17913.25MB
INFO:root:[   99] Training loss: 0.61985845, Validation loss: 0.61233836, Gradient norm: 0.06042382
INFO:root:At the start of the epoch: mem (CPU python)=18230.55859375MB; mem (CPU total)=17951.62890625MB
INFO:root:[  100] Training loss: 0.61952492, Validation loss: 0.61202645, Gradient norm: 0.05884194
INFO:root:At the start of the epoch: mem (CPU python)=18268.66015625MB; mem (CPU total)=17989.25MB
INFO:root:[  101] Training loss: 0.61948512, Validation loss: 0.61157745, Gradient norm: 0.05604803
INFO:root:At the start of the epoch: mem (CPU python)=18306.75390625MB; mem (CPU total)=18027.34375MB
INFO:root:[  102] Training loss: 0.61957194, Validation loss: 0.61143696, Gradient norm: 0.06502288
INFO:root:At the start of the epoch: mem (CPU python)=18344.8359375MB; mem (CPU total)=18064.99609375MB
INFO:root:[  103] Training loss: 0.61895827, Validation loss: 0.61188777, Gradient norm: 0.06312255
INFO:root:At the start of the epoch: mem (CPU python)=18382.890625MB; mem (CPU total)=18103.37890625MB
INFO:root:[  104] Training loss: 0.61903899, Validation loss: 0.61163867, Gradient norm: 0.06600883
INFO:root:At the start of the epoch: mem (CPU python)=18421.03125MB; mem (CPU total)=18141.5234375MB
INFO:root:[  105] Training loss: 0.61879734, Validation loss: 0.61201766, Gradient norm: 0.05403574
INFO:root:At the start of the epoch: mem (CPU python)=18459.13671875MB; mem (CPU total)=18179.8671875MB
INFO:root:[  106] Training loss: 0.61869751, Validation loss: 0.61154689, Gradient norm: 0.06103510
INFO:root:At the start of the epoch: mem (CPU python)=18497.2265625MB; mem (CPU total)=18217.98046875MB
INFO:root:[  107] Training loss: 0.61861355, Validation loss: 0.61095795, Gradient norm: 0.07066993
INFO:root:At the start of the epoch: mem (CPU python)=18535.328125MB; mem (CPU total)=18256.09375MB
INFO:root:[  108] Training loss: 0.61847305, Validation loss: 0.61099753, Gradient norm: 0.06498332
INFO:root:At the start of the epoch: mem (CPU python)=18573.2578125MB; mem (CPU total)=18295.234375MB
INFO:root:[  109] Training loss: 0.61807569, Validation loss: 0.61149265, Gradient norm: 0.06552873
INFO:root:At the start of the epoch: mem (CPU python)=18611.2734375MB; mem (CPU total)=18333.37890625MB
INFO:root:[  110] Training loss: 0.61809171, Validation loss: 0.61101829, Gradient norm: 0.06547678
INFO:root:At the start of the epoch: mem (CPU python)=18649.55859375MB; mem (CPU total)=18371.53125MB
INFO:root:[  111] Training loss: 0.61784522, Validation loss: 0.61111557, Gradient norm: 0.07469906
INFO:root:At the start of the epoch: mem (CPU python)=18687.61328125MB; mem (CPU total)=18409.66796875MB
INFO:root:[  112] Training loss: 0.61753107, Validation loss: 0.61092493, Gradient norm: 0.05825018
INFO:root:At the start of the epoch: mem (CPU python)=18725.75MB; mem (CPU total)=18447.16015625MB
INFO:root:[  113] Training loss: 0.61731430, Validation loss: 0.61059280, Gradient norm: 0.05837284
INFO:root:At the start of the epoch: mem (CPU python)=18763.83984375MB; mem (CPU total)=18485.32421875MB
INFO:root:[  114] Training loss: 0.61722349, Validation loss: 0.61033044, Gradient norm: 0.06283294
INFO:root:At the start of the epoch: mem (CPU python)=18801.9140625MB; mem (CPU total)=18523.25390625MB
INFO:root:[  115] Training loss: 0.61717733, Validation loss: 0.61283703, Gradient norm: 0.06292130
INFO:root:At the start of the epoch: mem (CPU python)=18839.9375MB; mem (CPU total)=18561.890625MB
INFO:root:[  116] Training loss: 0.61687164, Validation loss: 0.60999001, Gradient norm: 0.06510433
INFO:root:At the start of the epoch: mem (CPU python)=18878.12890625MB; mem (CPU total)=18599.56640625MB
INFO:root:[  117] Training loss: 0.61677842, Validation loss: 0.60963703, Gradient norm: 0.06558298
INFO:root:At the start of the epoch: mem (CPU python)=18916.2265625MB; mem (CPU total)=18637.70703125MB
INFO:root:[  118] Training loss: 0.61657712, Validation loss: 0.60986660, Gradient norm: 0.06135890
INFO:root:At the start of the epoch: mem (CPU python)=18954.3671875MB; mem (CPU total)=18676.8046875MB
INFO:root:[  119] Training loss: 0.61652854, Validation loss: 0.61031280, Gradient norm: 0.06258248
INFO:root:At the start of the epoch: mem (CPU python)=18992.46484375MB; mem (CPU total)=18714.75390625MB
INFO:root:[  120] Training loss: 0.61643167, Validation loss: 0.61041245, Gradient norm: 0.07008284
INFO:root:At the start of the epoch: mem (CPU python)=19030.56640625MB; mem (CPU total)=18752.69140625MB
INFO:root:[  121] Training loss: 0.61614675, Validation loss: 0.60931476, Gradient norm: 0.06399837
INFO:root:At the start of the epoch: mem (CPU python)=19068.63671875MB; mem (CPU total)=18790.515625MB
INFO:root:[  122] Training loss: 0.61601359, Validation loss: 0.60986929, Gradient norm: 0.06330788
INFO:root:At the start of the epoch: mem (CPU python)=19106.7578125MB; mem (CPU total)=18828.890625MB
INFO:root:[  123] Training loss: 0.61589839, Validation loss: 0.60997414, Gradient norm: 0.06273313
INFO:root:At the start of the epoch: mem (CPU python)=19144.8515625MB; mem (CPU total)=18866.98046875MB
INFO:root:[  124] Training loss: 0.61565847, Validation loss: 0.60948330, Gradient norm: 0.06986579
INFO:root:At the start of the epoch: mem (CPU python)=19182.94140625MB; mem (CPU total)=18905.1171875MB
INFO:root:[  125] Training loss: 0.61560812, Validation loss: 0.60869634, Gradient norm: 0.06949041
INFO:root:At the start of the epoch: mem (CPU python)=19221.0390625MB; mem (CPU total)=18942.7734375MB
INFO:root:[  126] Training loss: 0.61535927, Validation loss: 0.61021029, Gradient norm: 0.06271796
INFO:root:At the start of the epoch: mem (CPU python)=19259.0078125MB; mem (CPU total)=18981.1328125MB
INFO:root:[  127] Training loss: 0.61522403, Validation loss: 0.61071886, Gradient norm: 0.06041907
INFO:root:At the start of the epoch: mem (CPU python)=19297.2265625MB; mem (CPU total)=19018.99609375MB
INFO:root:[  128] Training loss: 0.61515611, Validation loss: 0.60905293, Gradient norm: 0.06319950
INFO:root:At the start of the epoch: mem (CPU python)=19335.3203125MB; mem (CPU total)=19057.37109375MB
INFO:root:[  129] Training loss: 0.61498320, Validation loss: 0.60891356, Gradient norm: 0.06017515
INFO:root:At the start of the epoch: mem (CPU python)=19373.36328125MB; mem (CPU total)=19096.0MB
INFO:root:[  130] Training loss: 0.61487437, Validation loss: 0.60955670, Gradient norm: 0.06384566
INFO:root:At the start of the epoch: mem (CPU python)=19411.46484375MB; mem (CPU total)=19134.07421875MB
INFO:root:[  131] Training loss: 0.61478260, Validation loss: 0.60868645, Gradient norm: 0.07123529
INFO:root:At the start of the epoch: mem (CPU python)=19449.55859375MB; mem (CPU total)=19171.97265625MB
INFO:root:[  132] Training loss: 0.61468678, Validation loss: 0.60843179, Gradient norm: 0.06560890
INFO:root:At the start of the epoch: mem (CPU python)=19487.62109375MB; mem (CPU total)=19210.1015625MB
INFO:root:[  133] Training loss: 0.61449184, Validation loss: 0.60842534, Gradient norm: 0.07109083
INFO:root:At the start of the epoch: mem (CPU python)=19525.72265625MB; mem (CPU total)=19248.02734375MB
INFO:root:[  134] Training loss: 0.61435361, Validation loss: 0.60886133, Gradient norm: 0.06928648
INFO:root:At the start of the epoch: mem (CPU python)=19563.84375MB; mem (CPU total)=19286.92578125MB
INFO:root:[  135] Training loss: 0.61429337, Validation loss: 0.60864733, Gradient norm: 0.06609008
INFO:root:At the start of the epoch: mem (CPU python)=19601.94140625MB; mem (CPU total)=19325.0703125MB
INFO:root:[  136] Training loss: 0.61430196, Validation loss: 0.60849557, Gradient norm: 0.06927376
INFO:root:At the start of the epoch: mem (CPU python)=19640.03515625MB; mem (CPU total)=19363.13671875MB
INFO:root:[  137] Training loss: 0.61393825, Validation loss: 0.60861233, Gradient norm: 0.06798791
INFO:root:At the start of the epoch: mem (CPU python)=19678.1328125MB; mem (CPU total)=19400.98828125MB
INFO:root:[  138] Training loss: 0.61361930, Validation loss: 0.60885871, Gradient norm: 0.07091051
INFO:root:At the start of the epoch: mem (CPU python)=19716.09765625MB; mem (CPU total)=19439.31640625MB
INFO:root:[  139] Training loss: 0.61368796, Validation loss: 0.60850850, Gradient norm: 0.06926573
INFO:root:At the start of the epoch: mem (CPU python)=19754.3671875MB; mem (CPU total)=19477.4609375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  140] Training loss: 0.61324805, Validation loss: 0.60768519, Gradient norm: 0.06788098
INFO:root:At the start of the epoch: mem (CPU python)=19792.4765625MB; mem (CPU total)=19514.5078125MB
INFO:root:[  141] Training loss: 0.61226252, Validation loss: 0.60772345, Gradient norm: 0.05653828
INFO:root:At the start of the epoch: mem (CPU python)=19830.55859375MB; mem (CPU total)=19553.54296875MB
INFO:root:[  142] Training loss: 0.61219428, Validation loss: 0.60772099, Gradient norm: 0.05879121
INFO:root:At the start of the epoch: mem (CPU python)=19868.66796875MB; mem (CPU total)=19590.8515625MB
INFO:root:[  143] Training loss: 0.61203429, Validation loss: 0.60839172, Gradient norm: 0.06202352
INFO:root:At the start of the epoch: mem (CPU python)=19906.71875MB; mem (CPU total)=19630.0703125MB
INFO:root:[  144] Training loss: 0.61207276, Validation loss: 0.60759072, Gradient norm: 0.05852509
INFO:root:At the start of the epoch: mem (CPU python)=19944.8203125MB; mem (CPU total)=19667.69921875MB
INFO:root:[  145] Training loss: 0.61183473, Validation loss: 0.60751867, Gradient norm: 0.05621116
INFO:root:At the start of the epoch: mem (CPU python)=19982.9453125MB; mem (CPU total)=19705.59375MB
INFO:root:[  146] Training loss: 0.61189128, Validation loss: 0.60764317, Gradient norm: 0.05894826
INFO:root:At the start of the epoch: mem (CPU python)=20021.05078125MB; mem (CPU total)=19744.18359375MB
INFO:root:[  147] Training loss: 0.61172291, Validation loss: 0.60776270, Gradient norm: 0.05840171
INFO:root:At the start of the epoch: mem (CPU python)=20059.14453125MB; mem (CPU total)=19782.3046875MB
INFO:root:[  148] Training loss: 0.61169365, Validation loss: 0.60746720, Gradient norm: 0.05674155
INFO:root:At the start of the epoch: mem (CPU python)=20097.21875MB; mem (CPU total)=19820.3984375MB
INFO:root:[  149] Training loss: 0.61159098, Validation loss: 0.60735193, Gradient norm: 0.05834005
INFO:root:At the start of the epoch: mem (CPU python)=20135.2890625MB; mem (CPU total)=19858.81640625MB
INFO:root:[  150] Training loss: 0.61129567, Validation loss: 0.60757149, Gradient norm: 0.05744180
INFO:root:At the start of the epoch: mem (CPU python)=20173.3828125MB; mem (CPU total)=19897.6796875MB
INFO:root:[  151] Training loss: 0.61144941, Validation loss: 0.60740002, Gradient norm: 0.06186150
INFO:root:At the start of the epoch: mem (CPU python)=20211.48046875MB; mem (CPU total)=19935.8046875MB
INFO:root:[  152] Training loss: 0.61134378, Validation loss: 0.60766509, Gradient norm: 0.06411640
INFO:root:At the start of the epoch: mem (CPU python)=20249.56640625MB; mem (CPU total)=19973.94140625MB
INFO:root:[  153] Training loss: 0.61130291, Validation loss: 0.60741773, Gradient norm: 0.06348923
INFO:root:At the start of the epoch: mem (CPU python)=20287.66796875MB; mem (CPU total)=20012.08984375MB
INFO:root:[  154] Training loss: 0.61119362, Validation loss: 0.60855417, Gradient norm: 0.06120454
INFO:root:At the start of the epoch: mem (CPU python)=20325.765625MB; mem (CPU total)=20050.1484375MB
INFO:root:[  155] Training loss: 0.61124740, Validation loss: 0.60701045, Gradient norm: 0.06430910
INFO:root:At the start of the epoch: mem (CPU python)=20363.859375MB; mem (CPU total)=20087.83203125MB
INFO:root:[  156] Training loss: 0.61116970, Validation loss: 0.60737830, Gradient norm: 0.06128760
INFO:root:At the start of the epoch: mem (CPU python)=20401.94921875MB; mem (CPU total)=20126.37890625MB
INFO:root:[  157] Training loss: 0.61111189, Validation loss: 0.60729200, Gradient norm: 0.06140721
INFO:root:At the start of the epoch: mem (CPU python)=20440.04296875MB; mem (CPU total)=20164.5234375MB
INFO:root:[  158] Training loss: 0.61089199, Validation loss: 0.60710108, Gradient norm: 0.06007780
INFO:root:At the start of the epoch: mem (CPU python)=20478.1484375MB; mem (CPU total)=20202.66796875MB
INFO:root:[  159] Training loss: 0.61073716, Validation loss: 0.60705049, Gradient norm: 0.05969815
INFO:root:At the start of the epoch: mem (CPU python)=20516.2421875MB; mem (CPU total)=20241.03515625MB
INFO:root:[  160] Training loss: 0.61070716, Validation loss: 0.60679762, Gradient norm: 0.06324641
INFO:root:At the start of the epoch: mem (CPU python)=20554.39453125MB; mem (CPU total)=20278.40234375MB
INFO:root:[  161] Training loss: 0.61076427, Validation loss: 0.60664308, Gradient norm: 0.06501941
INFO:root:At the start of the epoch: mem (CPU python)=20592.4765625MB; mem (CPU total)=20317.09765625MB
INFO:root:[  162] Training loss: 0.61056763, Validation loss: 0.60688106, Gradient norm: 0.06105249
INFO:root:At the start of the epoch: mem (CPU python)=20630.56640625MB; mem (CPU total)=20355.96484375MB
INFO:root:[  163] Training loss: 0.61066024, Validation loss: 0.60703565, Gradient norm: 0.06071325
INFO:root:At the start of the epoch: mem (CPU python)=20668.6796875MB; mem (CPU total)=20394.0078125MB
INFO:root:[  164] Training loss: 0.61053653, Validation loss: 0.60690162, Gradient norm: 0.06066227
INFO:root:At the start of the epoch: mem (CPU python)=20706.7734375MB; mem (CPU total)=20432.03515625MB
INFO:root:[  165] Training loss: 0.61064965, Validation loss: 0.60713476, Gradient norm: 0.06480750
INFO:root:At the start of the epoch: mem (CPU python)=20744.859375MB; mem (CPU total)=20470.1484375MB
INFO:root:[  166] Training loss: 0.61049482, Validation loss: 0.60702154, Gradient norm: 0.06312231
INFO:root:At the start of the epoch: mem (CPU python)=20782.9609375MB; mem (CPU total)=20508.015625MB
INFO:root:[  167] Training loss: 0.61021925, Validation loss: 0.60676683, Gradient norm: 0.06362457
INFO:root:At the start of the epoch: mem (CPU python)=20821.0625MB; mem (CPU total)=20546.40625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  168] Training loss: 0.61040042, Validation loss: 0.60719592, Gradient norm: 0.06433588
INFO:root:At the start of the epoch: mem (CPU python)=20859.1484375MB; mem (CPU total)=20584.296875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  169] Training loss: 0.60975312, Validation loss: 0.60685151, Gradient norm: 0.05576605
INFO:root:At the start of the epoch: mem (CPU python)=20897.25MB; mem (CPU total)=20622.6796875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  170] Training loss: 0.60957173, Validation loss: 0.60680497, Gradient norm: 0.05439551
INFO:root:At the start of the epoch: mem (CPU python)=20935.34765625MB; mem (CPU total)=20660.984375MB
INFO:root:[  171] Training loss: 0.60885060, Validation loss: 0.60621527, Gradient norm: 0.05425407
INFO:root:At the start of the epoch: mem (CPU python)=20973.38671875MB; mem (CPU total)=20698.875MB
INFO:root:[  172] Training loss: 0.60918876, Validation loss: 0.60594608, Gradient norm: 0.05499142
INFO:root:At the start of the epoch: mem (CPU python)=21011.48046875MB; mem (CPU total)=20737.03515625MB
INFO:root:[  173] Training loss: 0.60926334, Validation loss: 0.60629181, Gradient norm: 0.05360736
INFO:root:At the start of the epoch: mem (CPU python)=21049.57421875MB; mem (CPU total)=20776.19140625MB
INFO:root:[  174] Training loss: 0.60920904, Validation loss: 0.60624725, Gradient norm: 0.05590566
INFO:root:At the start of the epoch: mem (CPU python)=21087.66796875MB; mem (CPU total)=20814.23828125MB
INFO:root:[  175] Training loss: 0.60933930, Validation loss: 0.60598784, Gradient norm: 0.05449190
INFO:root:At the start of the epoch: mem (CPU python)=21125.76953125MB; mem (CPU total)=20852.6171875MB
INFO:root:[  176] Training loss: 0.60915669, Validation loss: 0.60636763, Gradient norm: 0.05476909
INFO:root:At the start of the epoch: mem (CPU python)=21163.86328125MB; mem (CPU total)=20891.0MB
INFO:root:[  177] Training loss: 0.60901088, Validation loss: 0.60623590, Gradient norm: 0.05600928
INFO:root:At the start of the epoch: mem (CPU python)=21201.9609375MB; mem (CPU total)=20929.140625MB
INFO:root:[  178] Training loss: 0.60893587, Validation loss: 0.60645537, Gradient norm: 0.05475379
INFO:root:At the start of the epoch: mem (CPU python)=21240.0546875MB; mem (CPU total)=20967.3359375MB
INFO:root:[  179] Training loss: 0.60907788, Validation loss: 0.60628060, Gradient norm: 0.05531457
INFO:root:At the start of the epoch: mem (CPU python)=21278.09765625MB; mem (CPU total)=21005.484375MB
INFO:root:[  180] Training loss: 0.60884298, Validation loss: 0.60689384, Gradient norm: 0.05392107
INFO:root:At the start of the epoch: mem (CPU python)=21316.23828125MB; mem (CPU total)=21043.65625MB
INFO:root:[  181] Training loss: 0.60877244, Validation loss: 0.60650576, Gradient norm: 0.05543386
INFO:root:At the start of the epoch: mem (CPU python)=21354.3828125MB; mem (CPU total)=21081.45703125MB
INFO:root:EP 181: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=21392.4921875MB; mem (CPU total)=21119.62109375MB
INFO:root:Training the model took 12339.281s.
INFO:root:Emptying the cuda cache took 0.005s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83724
INFO:root:EnergyScoreTrain: 0.58944
INFO:root:CRPSTrain: 0.45597
INFO:root:Gaussian NLLTrain: 1.17417
INFO:root:CoverageTrain: 0.95307
INFO:root:IntervalWidthTrain: 3.25174
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86137
INFO:root:EnergyScoreValidation: 0.60632
INFO:root:CRPSValidation: 0.47021
INFO:root:Gaussian NLLValidation: 1.20522
INFO:root:CoverageValidation: 0.94564
INFO:root:IntervalWidthValidation: 3.25675
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86273
INFO:root:EnergyScoreTest: 0.60725
INFO:root:CRPSTest: 0.47097
INFO:root:Gaussian NLLTest: 1.20678
INFO:root:CoverageTest: 0.94527
INFO:root:IntervalWidthTest: 3.25617
INFO:root:After validation: mem (CPU python)=21445.89453125MB; mem (CPU total)=21130.9453125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=21445.89453125MB; mem (CPU total)=21130.94140625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=21445.89453125MB; mem (CPU total)=21134.6640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=21445.89453125MB; mem (CPU total)=21134.9140625MB
INFO:root:[    1] Training loss: 0.72413316, Validation loss: 0.72055338, Gradient norm: 0.01356924
INFO:root:At the start of the epoch: mem (CPU python)=21473.36328125MB; mem (CPU total)=21201.609375MB
INFO:root:[    2] Training loss: 0.71976787, Validation loss: 0.71926330, Gradient norm: 0.00549523
INFO:root:At the start of the epoch: mem (CPU python)=21511.46484375MB; mem (CPU total)=21240.09375MB
INFO:root:[    3] Training loss: 0.71786994, Validation loss: 0.71407229, Gradient norm: 0.00791420
INFO:root:At the start of the epoch: mem (CPU python)=21549.53515625MB; mem (CPU total)=21278.28125MB
INFO:root:[    4] Training loss: 0.71074432, Validation loss: 0.70379656, Gradient norm: 0.01781290
INFO:root:At the start of the epoch: mem (CPU python)=21587.68359375MB; mem (CPU total)=21316.46875MB
INFO:root:[    5] Training loss: 0.70343456, Validation loss: 0.69722786, Gradient norm: 0.02651156
INFO:root:At the start of the epoch: mem (CPU python)=21625.78515625MB; mem (CPU total)=21354.640625MB
INFO:root:[    6] Training loss: 0.69746319, Validation loss: 0.69044385, Gradient norm: 0.02557788
INFO:root:At the start of the epoch: mem (CPU python)=21663.89453125MB; mem (CPU total)=21392.4375MB
INFO:root:[    7] Training loss: 0.69235202, Validation loss: 0.68559134, Gradient norm: 0.02966213
INFO:root:At the start of the epoch: mem (CPU python)=21701.9609375MB; mem (CPU total)=21430.85546875MB
INFO:root:[    8] Training loss: 0.68780786, Validation loss: 0.68090952, Gradient norm: 0.02756996
INFO:root:At the start of the epoch: mem (CPU python)=21740.07421875MB; mem (CPU total)=21469.2734375MB
INFO:root:[    9] Training loss: 0.68419871, Validation loss: 0.67639094, Gradient norm: 0.02963352
INFO:root:At the start of the epoch: mem (CPU python)=21778.125MB; mem (CPU total)=21507.6796875MB
INFO:root:[   10] Training loss: 0.68103239, Validation loss: 0.67377456, Gradient norm: 0.03058727
INFO:root:At the start of the epoch: mem (CPU python)=21816.2578125MB; mem (CPU total)=21545.8828125MB
INFO:root:[   11] Training loss: 0.67801775, Validation loss: 0.67053665, Gradient norm: 0.02949837
INFO:root:At the start of the epoch: mem (CPU python)=21854.3671875MB; mem (CPU total)=21583.80078125MB
INFO:root:[   12] Training loss: 0.67562277, Validation loss: 0.66760071, Gradient norm: 0.03135696
INFO:root:At the start of the epoch: mem (CPU python)=21892.3984375MB; mem (CPU total)=21621.95703125MB
INFO:root:[   13] Training loss: 0.67344348, Validation loss: 0.66524384, Gradient norm: 0.03402870
INFO:root:At the start of the epoch: mem (CPU python)=21930.5MB; mem (CPU total)=21660.37890625MB
INFO:root:[   14] Training loss: 0.67134499, Validation loss: 0.66393926, Gradient norm: 0.02957059
INFO:root:At the start of the epoch: mem (CPU python)=21968.58984375MB; mem (CPU total)=21698.5234375MB
INFO:root:[   15] Training loss: 0.66961911, Validation loss: 0.66175912, Gradient norm: 0.03324516
INFO:root:At the start of the epoch: mem (CPU python)=22006.6953125MB; mem (CPU total)=21736.8203125MB
INFO:root:[   16] Training loss: 0.66788828, Validation loss: 0.65972174, Gradient norm: 0.03208273
INFO:root:At the start of the epoch: mem (CPU python)=22044.79296875MB; mem (CPU total)=21774.96484375MB
INFO:root:[   17] Training loss: 0.66606670, Validation loss: 0.65719602, Gradient norm: 0.03552999
INFO:root:At the start of the epoch: mem (CPU python)=22082.83984375MB; mem (CPU total)=21812.85546875MB
INFO:root:[   18] Training loss: 0.66453879, Validation loss: 0.65572536, Gradient norm: 0.03366464
INFO:root:At the start of the epoch: mem (CPU python)=22120.98046875MB; mem (CPU total)=21850.90625MB
INFO:root:[   19] Training loss: 0.66314854, Validation loss: 0.65465642, Gradient norm: 0.03628265
INFO:root:At the start of the epoch: mem (CPU python)=22159.078125MB; mem (CPU total)=21889.59765625MB
INFO:root:[   20] Training loss: 0.66170481, Validation loss: 0.65209884, Gradient norm: 0.03851556
INFO:root:At the start of the epoch: mem (CPU python)=22197.1640625MB; mem (CPU total)=21927.234375MB
INFO:root:[   21] Training loss: 0.66018960, Validation loss: 0.65101629, Gradient norm: 0.03632895
INFO:root:At the start of the epoch: mem (CPU python)=22235.2265625MB; mem (CPU total)=21965.65234375MB
INFO:root:[   22] Training loss: 0.65892586, Validation loss: 0.64922030, Gradient norm: 0.03829861
INFO:root:At the start of the epoch: mem (CPU python)=22273.40625MB; mem (CPU total)=22003.796875MB
INFO:root:[   23] Training loss: 0.65759296, Validation loss: 0.64843651, Gradient norm: 0.03950273
INFO:root:At the start of the epoch: mem (CPU python)=22311.515625MB; mem (CPU total)=22041.94140625MB
INFO:root:[   24] Training loss: 0.65623106, Validation loss: 0.64734607, Gradient norm: 0.03729483
INFO:root:At the start of the epoch: mem (CPU python)=22349.609375MB; mem (CPU total)=22079.83984375MB
INFO:root:[   25] Training loss: 0.65521176, Validation loss: 0.64574397, Gradient norm: 0.03909721
INFO:root:At the start of the epoch: mem (CPU python)=22387.6953125MB; mem (CPU total)=22118.19921875MB
INFO:root:[   26] Training loss: 0.65400551, Validation loss: 0.64450793, Gradient norm: 0.04344480
INFO:root:At the start of the epoch: mem (CPU python)=22425.77734375MB; mem (CPU total)=22156.328125MB
INFO:root:[   27] Training loss: 0.65298764, Validation loss: 0.64382319, Gradient norm: 0.04130742
INFO:root:At the start of the epoch: mem (CPU python)=22463.89453125MB; mem (CPU total)=22194.50390625MB
INFO:root:[   28] Training loss: 0.65176097, Validation loss: 0.64221710, Gradient norm: 0.04246258
INFO:root:At the start of the epoch: mem (CPU python)=22501.98046875MB; mem (CPU total)=22233.37890625MB
INFO:root:[   29] Training loss: 0.65089869, Validation loss: 0.64151696, Gradient norm: 0.04104369
INFO:root:At the start of the epoch: mem (CPU python)=22540.07421875MB; mem (CPU total)=22271.5390625MB
INFO:root:[   30] Training loss: 0.64982427, Validation loss: 0.64058408, Gradient norm: 0.04121699
INFO:root:At the start of the epoch: mem (CPU python)=22578.17578125MB; mem (CPU total)=22309.6953125MB
INFO:root:[   31] Training loss: 0.64913725, Validation loss: 0.63961433, Gradient norm: 0.04303477
INFO:root:At the start of the epoch: mem (CPU python)=22616.27734375MB; mem (CPU total)=22348.03125MB
INFO:root:[   32] Training loss: 0.64815383, Validation loss: 0.63900007, Gradient norm: 0.04337721
INFO:root:At the start of the epoch: mem (CPU python)=22654.2890625MB; mem (CPU total)=22386.453125MB
INFO:root:[   33] Training loss: 0.64757060, Validation loss: 0.63804432, Gradient norm: 0.04546439
INFO:root:At the start of the epoch: mem (CPU python)=22692.4140625MB; mem (CPU total)=22424.34765625MB
INFO:root:[   34] Training loss: 0.64676829, Validation loss: 0.63676108, Gradient norm: 0.04847671
INFO:root:At the start of the epoch: mem (CPU python)=22730.453125MB; mem (CPU total)=22462.53515625MB
INFO:root:[   35] Training loss: 0.64593506, Validation loss: 0.63621554, Gradient norm: 0.04696929
INFO:root:At the start of the epoch: mem (CPU python)=22768.59375MB; mem (CPU total)=22499.5078125MB
INFO:root:[   36] Training loss: 0.64518566, Validation loss: 0.63475709, Gradient norm: 0.04383749
INFO:root:At the start of the epoch: mem (CPU python)=22806.70703125MB; mem (CPU total)=22537.7109375MB
INFO:root:[   37] Training loss: 0.64452616, Validation loss: 0.63536694, Gradient norm: 0.05040746
INFO:root:At the start of the epoch: mem (CPU python)=22844.80078125MB; mem (CPU total)=22576.859375MB
INFO:root:[   38] Training loss: 0.64367305, Validation loss: 0.63397779, Gradient norm: 0.04531445
INFO:root:At the start of the epoch: mem (CPU python)=22882.88671875MB; mem (CPU total)=22614.22265625MB
INFO:root:[   39] Training loss: 0.64307854, Validation loss: 0.63307845, Gradient norm: 0.04904284
INFO:root:At the start of the epoch: mem (CPU python)=22920.984375MB; mem (CPU total)=22652.1484375MB
INFO:root:[   40] Training loss: 0.64246414, Validation loss: 0.63284465, Gradient norm: 0.04454110
INFO:root:At the start of the epoch: mem (CPU python)=22959.0859375MB; mem (CPU total)=22690.546875MB
INFO:root:[   41] Training loss: 0.64182603, Validation loss: 0.63180579, Gradient norm: 0.04414975
INFO:root:At the start of the epoch: mem (CPU python)=22997.14453125MB; mem (CPU total)=22728.3515625MB
INFO:root:[   42] Training loss: 0.64155243, Validation loss: 0.63163062, Gradient norm: 0.05280513
INFO:root:At the start of the epoch: mem (CPU python)=23035.2578125MB; mem (CPU total)=22765.75MB
INFO:root:[   43] Training loss: 0.64089277, Validation loss: 0.63129667, Gradient norm: 0.05246857
INFO:root:At the start of the epoch: mem (CPU python)=23073.42578125MB; mem (CPU total)=22804.1328125MB
INFO:root:[   44] Training loss: 0.64023081, Validation loss: 0.63001117, Gradient norm: 0.04729122
INFO:root:At the start of the epoch: mem (CPU python)=23111.51953125MB; mem (CPU total)=22842.6171875MB
INFO:root:[   45] Training loss: 0.63979380, Validation loss: 0.62967531, Gradient norm: 0.04938104
INFO:root:At the start of the epoch: mem (CPU python)=23149.609375MB; mem (CPU total)=22880.75MB
INFO:root:[   46] Training loss: 0.63921561, Validation loss: 0.62958573, Gradient norm: 0.04826247
INFO:root:At the start of the epoch: mem (CPU python)=23187.66796875MB; mem (CPU total)=22919.171875MB
INFO:root:[   47] Training loss: 0.63876062, Validation loss: 0.62826075, Gradient norm: 0.04804281
INFO:root:At the start of the epoch: mem (CPU python)=23225.80859375MB; mem (CPU total)=22956.3984375MB
INFO:root:[   48] Training loss: 0.63814619, Validation loss: 0.62825243, Gradient norm: 0.04668675
INFO:root:At the start of the epoch: mem (CPU python)=23263.90234375MB; mem (CPU total)=22994.54296875MB
INFO:root:[   49] Training loss: 0.63780426, Validation loss: 0.62807636, Gradient norm: 0.05809928
INFO:root:At the start of the epoch: mem (CPU python)=23301.99609375MB; mem (CPU total)=23032.6875MB
INFO:root:[   50] Training loss: 0.63730132, Validation loss: 0.62816020, Gradient norm: 0.05284881
INFO:root:At the start of the epoch: mem (CPU python)=23340.1015625MB; mem (CPU total)=23071.30078125MB
INFO:root:[   51] Training loss: 0.63698834, Validation loss: 0.62734644, Gradient norm: 0.05226990
INFO:root:At the start of the epoch: mem (CPU python)=23378.1875MB; mem (CPU total)=23109.1875MB
INFO:root:[   52] Training loss: 0.63664648, Validation loss: 0.62611726, Gradient norm: 0.05068611
INFO:root:At the start of the epoch: mem (CPU python)=23416.27734375MB; mem (CPU total)=23147.26171875MB
INFO:root:[   53] Training loss: 0.63618913, Validation loss: 0.62696494, Gradient norm: 0.05378479
INFO:root:At the start of the epoch: mem (CPU python)=23454.32421875MB; mem (CPU total)=23186.125MB
INFO:root:[   54] Training loss: 0.63590227, Validation loss: 0.62539857, Gradient norm: 0.05358413
INFO:root:At the start of the epoch: mem (CPU python)=23492.44921875MB; mem (CPU total)=23224.0390625MB
INFO:root:[   55] Training loss: 0.63525958, Validation loss: 0.62597066, Gradient norm: 0.04846061
INFO:root:At the start of the epoch: mem (CPU python)=23530.5MB; mem (CPU total)=23262.67578125MB
INFO:root:[   56] Training loss: 0.63485925, Validation loss: 0.62452853, Gradient norm: 0.05476473
INFO:root:At the start of the epoch: mem (CPU python)=23568.6015625MB; mem (CPU total)=23300.328125MB
INFO:root:[   57] Training loss: 0.63440073, Validation loss: 0.62391509, Gradient norm: 0.05146091
INFO:root:At the start of the epoch: mem (CPU python)=23606.70703125MB; mem (CPU total)=23338.2265625MB
INFO:root:[   58] Training loss: 0.63398266, Validation loss: 0.62414471, Gradient norm: 0.05105140
INFO:root:At the start of the epoch: mem (CPU python)=23644.79296875MB; mem (CPU total)=23377.08203125MB
INFO:root:[   59] Training loss: 0.63371363, Validation loss: 0.62374611, Gradient norm: 0.05144960
INFO:root:At the start of the epoch: mem (CPU python)=23682.890625MB; mem (CPU total)=23414.48046875MB
INFO:root:[   60] Training loss: 0.63337612, Validation loss: 0.62335722, Gradient norm: 0.05488549
INFO:root:At the start of the epoch: mem (CPU python)=23720.99609375MB; mem (CPU total)=23452.953125MB
INFO:root:[   61] Training loss: 0.63292608, Validation loss: 0.62371923, Gradient norm: 0.05554186
INFO:root:At the start of the epoch: mem (CPU python)=23759.08203125MB; mem (CPU total)=23491.56640625MB
INFO:root:[   62] Training loss: 0.63268496, Validation loss: 0.62293094, Gradient norm: 0.05143266
INFO:root:At the start of the epoch: mem (CPU python)=23797.1484375MB; mem (CPU total)=23529.25MB
INFO:root:[   63] Training loss: 0.63238295, Validation loss: 0.62296806, Gradient norm: 0.04986942
INFO:root:At the start of the epoch: mem (CPU python)=23835.26171875MB; mem (CPU total)=23568.2890625MB
INFO:root:[   64] Training loss: 0.63236004, Validation loss: 0.62241019, Gradient norm: 0.06137645
INFO:root:At the start of the epoch: mem (CPU python)=23873.42578125MB; mem (CPU total)=23607.02734375MB
INFO:root:[   65] Training loss: 0.63180790, Validation loss: 0.62234229, Gradient norm: 0.04997822
INFO:root:At the start of the epoch: mem (CPU python)=23911.52734375MB; mem (CPU total)=23644.65234375MB
INFO:root:[   66] Training loss: 0.63146406, Validation loss: 0.62183585, Gradient norm: 0.05370866
INFO:root:At the start of the epoch: mem (CPU python)=23949.59375MB; mem (CPU total)=23683.25MB
INFO:root:[   67] Training loss: 0.63117543, Validation loss: 0.62185888, Gradient norm: 0.05223576
INFO:root:At the start of the epoch: mem (CPU python)=23987.71875MB; mem (CPU total)=23721.6328125MB
INFO:root:[   68] Training loss: 0.63082591, Validation loss: 0.62115284, Gradient norm: 0.05371716
INFO:root:At the start of the epoch: mem (CPU python)=24025.81640625MB; mem (CPU total)=23759.62109375MB
INFO:root:[   69] Training loss: 0.63072344, Validation loss: 0.62066494, Gradient norm: 0.06160999
INFO:root:At the start of the epoch: mem (CPU python)=24063.90234375MB; mem (CPU total)=23797.53515625MB
INFO:root:[   70] Training loss: 0.63023517, Validation loss: 0.62090808, Gradient norm: 0.05238617
INFO:root:At the start of the epoch: mem (CPU python)=24101.9453125MB; mem (CPU total)=23835.91796875MB
INFO:root:[   71] Training loss: 0.63038439, Validation loss: 0.62045149, Gradient norm: 0.06948772
INFO:root:At the start of the epoch: mem (CPU python)=24140.09765625MB; mem (CPU total)=23873.8671875MB
INFO:root:[   72] Training loss: 0.62970022, Validation loss: 0.62019358, Gradient norm: 0.05527879
INFO:root:At the start of the epoch: mem (CPU python)=24178.19921875MB; mem (CPU total)=23913.375MB
INFO:root:[   73] Training loss: 0.62957122, Validation loss: 0.62043482, Gradient norm: 0.05275991
INFO:root:At the start of the epoch: mem (CPU python)=24216.28515625MB; mem (CPU total)=23951.078125MB
INFO:root:[   74] Training loss: 0.62911114, Validation loss: 0.61911815, Gradient norm: 0.05356277
INFO:root:At the start of the epoch: mem (CPU python)=24254.3203125MB; mem (CPU total)=23989.20703125MB
INFO:root:[   75] Training loss: 0.62907683, Validation loss: 0.61935336, Gradient norm: 0.06047246
INFO:root:At the start of the epoch: mem (CPU python)=24292.421875MB; mem (CPU total)=24028.08203125MB
INFO:root:[   76] Training loss: 0.62869051, Validation loss: 0.62032937, Gradient norm: 0.05756354
INFO:root:At the start of the epoch: mem (CPU python)=24330.5234375MB; mem (CPU total)=24066.44140625MB
INFO:root:[   77] Training loss: 0.62840035, Validation loss: 0.61974874, Gradient norm: 0.05907738
INFO:root:At the start of the epoch: mem (CPU python)=24368.62109375MB; mem (CPU total)=24104.87109375MB
INFO:root:[   78] Training loss: 0.62829950, Validation loss: 0.61894174, Gradient norm: 0.05825590
INFO:root:At the start of the epoch: mem (CPU python)=24406.68359375MB; mem (CPU total)=24141.90234375MB
INFO:root:[   79] Training loss: 0.62805984, Validation loss: 0.61806789, Gradient norm: 0.05661187
INFO:root:At the start of the epoch: mem (CPU python)=24444.8125MB; mem (CPU total)=24179.0859375MB
INFO:root:[   80] Training loss: 0.62766118, Validation loss: 0.61857469, Gradient norm: 0.05654380
INFO:root:At the start of the epoch: mem (CPU python)=24482.90234375MB; mem (CPU total)=24218.20703125MB
INFO:root:[   81] Training loss: 0.62754133, Validation loss: 0.61882172, Gradient norm: 0.05780248
INFO:root:At the start of the epoch: mem (CPU python)=24521.00390625MB; mem (CPU total)=24256.36328125MB
INFO:root:[   82] Training loss: 0.62716545, Validation loss: 0.61761527, Gradient norm: 0.05837129
INFO:root:At the start of the epoch: mem (CPU python)=24559.08984375MB; mem (CPU total)=24294.0390625MB
INFO:root:[   83] Training loss: 0.62702227, Validation loss: 0.61749581, Gradient norm: 0.05487407
INFO:root:At the start of the epoch: mem (CPU python)=24597.19140625MB; mem (CPU total)=24331.9375MB
INFO:root:[   84] Training loss: 0.62679037, Validation loss: 0.61838570, Gradient norm: 0.06022348
INFO:root:At the start of the epoch: mem (CPU python)=24635.2890625MB; mem (CPU total)=24371.08203125MB
INFO:root:[   85] Training loss: 0.62671760, Validation loss: 0.61723576, Gradient norm: 0.05765810
INFO:root:At the start of the epoch: mem (CPU python)=24673.3984375MB; mem (CPU total)=24408.97265625MB
INFO:root:[   86] Training loss: 0.62641051, Validation loss: 0.61664832, Gradient norm: 0.06366462
INFO:root:At the start of the epoch: mem (CPU python)=24711.53125MB; mem (CPU total)=24446.81640625MB
INFO:root:[   87] Training loss: 0.62613734, Validation loss: 0.61788737, Gradient norm: 0.05838814
INFO:root:At the start of the epoch: mem (CPU python)=24749.6171875MB; mem (CPU total)=24485.73046875MB
INFO:root:[   88] Training loss: 0.62595331, Validation loss: 0.61699453, Gradient norm: 0.05663014
INFO:root:At the start of the epoch: mem (CPU python)=24787.72265625MB; mem (CPU total)=24524.140625MB
INFO:root:[   89] Training loss: 0.62586004, Validation loss: 0.61656863, Gradient norm: 0.05847262
INFO:root:At the start of the epoch: mem (CPU python)=24825.8125MB; mem (CPU total)=24561.75MB
INFO:root:[   90] Training loss: 0.62542929, Validation loss: 0.61712581, Gradient norm: 0.05311238
INFO:root:At the start of the epoch: mem (CPU python)=24863.90625MB; mem (CPU total)=24600.4296875MB
INFO:root:[   91] Training loss: 0.62538781, Validation loss: 0.61626777, Gradient norm: 0.05945841
INFO:root:At the start of the epoch: mem (CPU python)=24902.01171875MB; mem (CPU total)=24638.4140625MB
INFO:root:[   92] Training loss: 0.62498253, Validation loss: 0.61691599, Gradient norm: 0.05736492
INFO:root:At the start of the epoch: mem (CPU python)=24940.08203125MB; mem (CPU total)=24676.73046875MB
INFO:root:[   93] Training loss: 0.62519017, Validation loss: 0.61612494, Gradient norm: 0.05864325
INFO:root:At the start of the epoch: mem (CPU python)=24978.19921875MB; mem (CPU total)=24714.8984375MB
INFO:root:[   94] Training loss: 0.62472619, Validation loss: 0.61614302, Gradient norm: 0.05538964
INFO:root:At the start of the epoch: mem (CPU python)=25016.2890625MB; mem (CPU total)=24753.0546875MB
INFO:root:[   95] Training loss: 0.62470432, Validation loss: 0.61525645, Gradient norm: 0.05670586
INFO:root:At the start of the epoch: mem (CPU python)=25054.3359375MB; mem (CPU total)=24791.1953125MB
INFO:root:[   96] Training loss: 0.62440818, Validation loss: 0.61617532, Gradient norm: 0.05816895
INFO:root:At the start of the epoch: mem (CPU python)=25092.41796875MB; mem (CPU total)=24830.09765625MB
INFO:root:[   97] Training loss: 0.62434808, Validation loss: 0.61635833, Gradient norm: 0.05824952
INFO:root:At the start of the epoch: mem (CPU python)=25130.52734375MB; mem (CPU total)=24868.5703125MB
INFO:root:[   98] Training loss: 0.62420912, Validation loss: 0.61545984, Gradient norm: 0.06372860
INFO:root:At the start of the epoch: mem (CPU python)=25168.625MB; mem (CPU total)=24906.3515625MB
INFO:root:[   99] Training loss: 0.62391375, Validation loss: 0.61543405, Gradient norm: 0.06015272
INFO:root:At the start of the epoch: mem (CPU python)=25206.58984375MB; mem (CPU total)=24944.8203125MB
INFO:root:[  100] Training loss: 0.62388675, Validation loss: 0.61544989, Gradient norm: 0.06767882
INFO:root:At the start of the epoch: mem (CPU python)=25244.8203125MB; mem (CPU total)=24982.56640625MB
INFO:root:[  101] Training loss: 0.62347972, Validation loss: 0.61482572, Gradient norm: 0.05817484
INFO:root:At the start of the epoch: mem (CPU python)=25282.921875MB; mem (CPU total)=25020.109375MB
INFO:root:[  102] Training loss: 0.62365905, Validation loss: 0.61483163, Gradient norm: 0.06829347
INFO:root:At the start of the epoch: mem (CPU python)=25321.015625MB; mem (CPU total)=25058.5MB
INFO:root:[  103] Training loss: 0.62311123, Validation loss: 0.61458809, Gradient norm: 0.06069324
INFO:root:At the start of the epoch: mem (CPU python)=25358.9453125MB; mem (CPU total)=25096.18359375MB
INFO:root:[  104] Training loss: 0.62315088, Validation loss: 0.61441194, Gradient norm: 0.06245340
INFO:root:At the start of the epoch: mem (CPU python)=25397.18359375MB; mem (CPU total)=25134.3515625MB
INFO:root:[  105] Training loss: 0.62299319, Validation loss: 0.61516301, Gradient norm: 0.05890411
INFO:root:At the start of the epoch: mem (CPU python)=25435.35546875MB; mem (CPU total)=25173.22265625MB
INFO:root:[  106] Training loss: 0.62283095, Validation loss: 0.61452486, Gradient norm: 0.06386498
INFO:root:At the start of the epoch: mem (CPU python)=25473.44921875MB; mem (CPU total)=25211.36328125MB
INFO:root:[  107] Training loss: 0.62267170, Validation loss: 0.61456370, Gradient norm: 0.06196977
INFO:root:At the start of the epoch: mem (CPU python)=25511.5390625MB; mem (CPU total)=25249.91796875MB
INFO:root:[  108] Training loss: 0.62235753, Validation loss: 0.61555216, Gradient norm: 0.06393494
INFO:root:At the start of the epoch: mem (CPU python)=25549.640625MB; mem (CPU total)=25287.7578125MB
INFO:root:[  109] Training loss: 0.62207749, Validation loss: 0.61325182, Gradient norm: 0.06122438
INFO:root:At the start of the epoch: mem (CPU python)=25587.734375MB; mem (CPU total)=25325.6484375MB
INFO:root:[  110] Training loss: 0.62209185, Validation loss: 0.61430479, Gradient norm: 0.06935841
INFO:root:At the start of the epoch: mem (CPU python)=25625.81640625MB; mem (CPU total)=25364.0234375MB
INFO:root:[  111] Training loss: 0.62182918, Validation loss: 0.61386256, Gradient norm: 0.05590516
INFO:root:At the start of the epoch: mem (CPU python)=25663.9296875MB; mem (CPU total)=25402.19140625MB
INFO:root:[  112] Training loss: 0.62178398, Validation loss: 0.61389057, Gradient norm: 0.05986783
INFO:root:At the start of the epoch: mem (CPU python)=25702.0234375MB; mem (CPU total)=25440.29296875MB
INFO:root:[  113] Training loss: 0.62155212, Validation loss: 0.61339135, Gradient norm: 0.06156031
INFO:root:At the start of the epoch: mem (CPU python)=25740.1171875MB; mem (CPU total)=25478.421875MB
INFO:root:[  114] Training loss: 0.62141988, Validation loss: 0.61365126, Gradient norm: 0.06251052
INFO:root:At the start of the epoch: mem (CPU python)=25778.1953125MB; mem (CPU total)=25516.56640625MB
INFO:root:[  115] Training loss: 0.62147470, Validation loss: 0.61403629, Gradient norm: 0.06359523
INFO:root:At the start of the epoch: mem (CPU python)=25816.3046875MB; mem (CPU total)=25554.73046875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  116] Training loss: 0.62116778, Validation loss: 0.61325427, Gradient norm: 0.06194453
INFO:root:At the start of the epoch: mem (CPU python)=25854.34765625MB; mem (CPU total)=25593.34765625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  117] Training loss: 0.62023813, Validation loss: 0.61306097, Gradient norm: 0.05897677
INFO:root:At the start of the epoch: mem (CPU python)=25892.37890625MB; mem (CPU total)=25630.91796875MB
INFO:root:[  118] Training loss: 0.61947908, Validation loss: 0.61257793, Gradient norm: 0.04942270
INFO:root:At the start of the epoch: mem (CPU python)=25930.5390625MB; mem (CPU total)=25669.32421875MB
INFO:root:[  119] Training loss: 0.61950566, Validation loss: 0.61165204, Gradient norm: 0.05502049
INFO:root:At the start of the epoch: mem (CPU python)=25968.6328125MB; mem (CPU total)=25707.5MB
INFO:root:[  120] Training loss: 0.61950510, Validation loss: 0.61200152, Gradient norm: 0.05133652
INFO:root:At the start of the epoch: mem (CPU python)=26006.57421875MB; mem (CPU total)=25746.3828125MB
INFO:root:[  121] Training loss: 0.61945122, Validation loss: 0.61178539, Gradient norm: 0.05388979
INFO:root:At the start of the epoch: mem (CPU python)=26044.7890625MB; mem (CPU total)=25783.75390625MB
INFO:root:[  122] Training loss: 0.61931452, Validation loss: 0.61223582, Gradient norm: 0.05064228
INFO:root:At the start of the epoch: mem (CPU python)=26082.90234375MB; mem (CPU total)=25822.32421875MB
INFO:root:[  123] Training loss: 0.61923845, Validation loss: 0.61214341, Gradient norm: 0.05275128
INFO:root:At the start of the epoch: mem (CPU python)=26121.015625MB; mem (CPU total)=25860.4609375MB
INFO:root:[  124] Training loss: 0.61924863, Validation loss: 0.61187238, Gradient norm: 0.05179894
INFO:root:At the start of the epoch: mem (CPU python)=26159.1015625MB; mem (CPU total)=25898.453125MB
INFO:root:[  125] Training loss: 0.61901007, Validation loss: 0.61257255, Gradient norm: 0.05419912
INFO:root:At the start of the epoch: mem (CPU python)=26197.20703125MB; mem (CPU total)=25936.6171875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  126] Training loss: 0.61925844, Validation loss: 0.61168603, Gradient norm: 0.05448574
INFO:root:At the start of the epoch: mem (CPU python)=26235.35546875MB; mem (CPU total)=25974.76171875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  127] Training loss: 0.61894605, Validation loss: 0.61201921, Gradient norm: 0.05172173
INFO:root:At the start of the epoch: mem (CPU python)=26273.3828125MB; mem (CPU total)=26012.90625MB
INFO:root:[  128] Training loss: 0.61866070, Validation loss: 0.61190510, Gradient norm: 0.04774522
INFO:root:At the start of the epoch: mem (CPU python)=26311.546875MB; mem (CPU total)=26050.7578125MB
INFO:root:EP 128: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=26349.640625MB; mem (CPU total)=26088.890625MB
INFO:root:Training the model took 9697.381s.
INFO:root:Emptying the cuda cache took 0.005s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85285
INFO:root:EnergyScoreTrain: 0.60043
INFO:root:CRPSTrain: 0.46651
INFO:root:Gaussian NLLTrain: 1.19787
INFO:root:CoverageTrain: 0.9543
INFO:root:IntervalWidthTrain: 3.31898
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8696
INFO:root:EnergyScoreValidation: 0.61208
INFO:root:CRPSValidation: 0.47643
INFO:root:Gaussian NLLValidation: 1.2191
INFO:root:CoverageValidation: 0.94932
INFO:root:IntervalWidthValidation: 3.32174
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87075
INFO:root:EnergyScoreTest: 0.61289
INFO:root:CRPSTest: 0.47713
INFO:root:Gaussian NLLTest: 1.22007
INFO:root:CoverageTest: 0.94903
INFO:root:IntervalWidthTest: 3.32112
INFO:root:After validation: mem (CPU python)=26386.76953125MB; mem (CPU total)=26161.8203125MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=26386.76953125MB; mem (CPU total)=26100.7265625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=26386.76953125MB; mem (CPU total)=26103.61328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=26386.76953125MB; mem (CPU total)=26103.2578125MB
INFO:root:[    1] Training loss: 0.72494322, Validation loss: 0.72057814, Gradient norm: 0.01741319
INFO:root:At the start of the epoch: mem (CPU python)=26429.203125MB; mem (CPU total)=26168.4296875MB
INFO:root:[    2] Training loss: 0.71935771, Validation loss: 0.71717733, Gradient norm: 0.00643061
INFO:root:At the start of the epoch: mem (CPU python)=26467.2734375MB; mem (CPU total)=26206.47265625MB
INFO:root:[    3] Training loss: 0.71293083, Validation loss: 0.70634635, Gradient norm: 0.01455173
INFO:root:At the start of the epoch: mem (CPU python)=26505.4140625MB; mem (CPU total)=26244.6796875MB
INFO:root:[    4] Training loss: 0.70565647, Validation loss: 0.70012260, Gradient norm: 0.02236256
INFO:root:At the start of the epoch: mem (CPU python)=26543.49609375MB; mem (CPU total)=26283.375MB
INFO:root:[    5] Training loss: 0.69954341, Validation loss: 0.69385806, Gradient norm: 0.02644273
INFO:root:At the start of the epoch: mem (CPU python)=26581.58984375MB; mem (CPU total)=26320.29296875MB
INFO:root:[    6] Training loss: 0.69373550, Validation loss: 0.68678478, Gradient norm: 0.02566757
INFO:root:At the start of the epoch: mem (CPU python)=26619.6875MB; mem (CPU total)=26358.69921875MB
INFO:root:[    7] Training loss: 0.68810801, Validation loss: 0.67917874, Gradient norm: 0.02908306
INFO:root:At the start of the epoch: mem (CPU python)=26657.7890625MB; mem (CPU total)=26397.07421875MB
INFO:root:[    8] Training loss: 0.68351998, Validation loss: 0.67515415, Gradient norm: 0.02903153
INFO:root:At the start of the epoch: mem (CPU python)=26695.87109375MB; mem (CPU total)=26434.52734375MB
INFO:root:[    9] Training loss: 0.67958640, Validation loss: 0.67097705, Gradient norm: 0.02847246
INFO:root:At the start of the epoch: mem (CPU python)=26733.98046875MB; mem (CPU total)=26472.6953125MB
INFO:root:[   10] Training loss: 0.67614242, Validation loss: 0.66696400, Gradient norm: 0.02756135
INFO:root:At the start of the epoch: mem (CPU python)=26772.07421875MB; mem (CPU total)=26510.859375MB
INFO:root:[   11] Training loss: 0.67284444, Validation loss: 0.66312648, Gradient norm: 0.02725503
INFO:root:At the start of the epoch: mem (CPU python)=26810.1640625MB; mem (CPU total)=26549.03125MB
INFO:root:[   12] Training loss: 0.67021158, Validation loss: 0.66084660, Gradient norm: 0.03132553
INFO:root:At the start of the epoch: mem (CPU python)=26848.265625MB; mem (CPU total)=26587.20703125MB
INFO:root:[   13] Training loss: 0.66772189, Validation loss: 0.65843243, Gradient norm: 0.02935306
INFO:root:At the start of the epoch: mem (CPU python)=26886.30078125MB; mem (CPU total)=26625.34765625MB
INFO:root:[   14] Training loss: 0.66559947, Validation loss: 0.65536654, Gradient norm: 0.02918535
INFO:root:At the start of the epoch: mem (CPU python)=26924.44140625MB; mem (CPU total)=26663.515625MB
INFO:root:[   15] Training loss: 0.66361246, Validation loss: 0.65375818, Gradient norm: 0.03208120
INFO:root:At the start of the epoch: mem (CPU python)=26962.484375MB; mem (CPU total)=26701.49609375MB
INFO:root:[   16] Training loss: 0.66165457, Validation loss: 0.65164567, Gradient norm: 0.03273809
INFO:root:At the start of the epoch: mem (CPU python)=27000.50390625MB; mem (CPU total)=26739.64453125MB
INFO:root:[   17] Training loss: 0.66005517, Validation loss: 0.64974607, Gradient norm: 0.03276388
INFO:root:At the start of the epoch: mem (CPU python)=27038.65234375MB; mem (CPU total)=26777.80078125MB
INFO:root:[   18] Training loss: 0.65846304, Validation loss: 0.64877894, Gradient norm: 0.03515715
INFO:root:At the start of the epoch: mem (CPU python)=27076.76953125MB; mem (CPU total)=26816.140625MB
INFO:root:[   19] Training loss: 0.65703950, Validation loss: 0.64663684, Gradient norm: 0.03547219
INFO:root:At the start of the epoch: mem (CPU python)=27114.8671875MB; mem (CPU total)=26854.31640625MB
INFO:root:[   20] Training loss: 0.65571110, Validation loss: 0.64577227, Gradient norm: 0.03793750
INFO:root:At the start of the epoch: mem (CPU python)=27152.94921875MB; mem (CPU total)=26892.4609375MB
INFO:root:[   21] Training loss: 0.65431359, Validation loss: 0.64349812, Gradient norm: 0.03812908
INFO:root:At the start of the epoch: mem (CPU python)=27191.05859375MB; mem (CPU total)=26930.59375MB
INFO:root:[   22] Training loss: 0.65308123, Validation loss: 0.64252710, Gradient norm: 0.04220216
INFO:root:At the start of the epoch: mem (CPU python)=27229.15234375MB; mem (CPU total)=26968.98046875MB
INFO:root:[   23] Training loss: 0.65168017, Validation loss: 0.64103124, Gradient norm: 0.03775472
INFO:root:At the start of the epoch: mem (CPU python)=27267.20703125MB; mem (CPU total)=27007.1953125MB
INFO:root:[   24] Training loss: 0.65070435, Validation loss: 0.63957546, Gradient norm: 0.04085108
INFO:root:At the start of the epoch: mem (CPU python)=27305.3359375MB; mem (CPU total)=27045.109375MB
INFO:root:[   25] Training loss: 0.64947120, Validation loss: 0.63915351, Gradient norm: 0.04114386
INFO:root:At the start of the epoch: mem (CPU python)=27343.48828125MB; mem (CPU total)=27083.2421875MB
INFO:root:[   26] Training loss: 0.64860496, Validation loss: 0.63715685, Gradient norm: 0.04175865
INFO:root:At the start of the epoch: mem (CPU python)=27381.453125MB; mem (CPU total)=27121.3828125MB
INFO:root:[   27] Training loss: 0.64752553, Validation loss: 0.63687381, Gradient norm: 0.04371005
INFO:root:At the start of the epoch: mem (CPU python)=27419.6875MB; mem (CPU total)=27159.76171875MB
INFO:root:[   28] Training loss: 0.64667824, Validation loss: 0.63515699, Gradient norm: 0.04299208
INFO:root:At the start of the epoch: mem (CPU python)=27457.78125MB; mem (CPU total)=27198.1171875MB
INFO:root:[   29] Training loss: 0.64570910, Validation loss: 0.63445839, Gradient norm: 0.04323190
INFO:root:At the start of the epoch: mem (CPU python)=27495.828125MB; mem (CPU total)=27236.25390625MB
INFO:root:[   30] Training loss: 0.64482618, Validation loss: 0.63401642, Gradient norm: 0.04584678
INFO:root:At the start of the epoch: mem (CPU python)=27533.95703125MB; mem (CPU total)=27274.109375MB
INFO:root:[   31] Training loss: 0.64394254, Validation loss: 0.63300178, Gradient norm: 0.04281850
INFO:root:At the start of the epoch: mem (CPU python)=27572.06640625MB; mem (CPU total)=27312.21484375MB
INFO:root:[   32] Training loss: 0.64323477, Validation loss: 0.63150366, Gradient norm: 0.04181245
INFO:root:At the start of the epoch: mem (CPU python)=27610.03515625MB; mem (CPU total)=27350.10546875MB
INFO:root:[   33] Training loss: 0.64223181, Validation loss: 0.63119248, Gradient norm: 0.04683016
INFO:root:At the start of the epoch: mem (CPU python)=27648.23828125MB; mem (CPU total)=27388.45703125MB
INFO:root:[   34] Training loss: 0.64161786, Validation loss: 0.63038245, Gradient norm: 0.04207441
INFO:root:At the start of the epoch: mem (CPU python)=27686.34765625MB; mem (CPU total)=27426.6015625MB
INFO:root:[   35] Training loss: 0.64096612, Validation loss: 0.63063812, Gradient norm: 0.04882191
INFO:root:At the start of the epoch: mem (CPU python)=27724.44921875MB; mem (CPU total)=27464.9921875MB
INFO:root:[   36] Training loss: 0.64049778, Validation loss: 0.62966983, Gradient norm: 0.05829030
INFO:root:At the start of the epoch: mem (CPU python)=27762.48046875MB; mem (CPU total)=27503.12109375MB
INFO:root:[   37] Training loss: 0.63968288, Validation loss: 0.62900330, Gradient norm: 0.04789654
INFO:root:At the start of the epoch: mem (CPU python)=27800.58203125MB; mem (CPU total)=27541.234375MB
INFO:root:[   38] Training loss: 0.63917606, Validation loss: 0.62750134, Gradient norm: 0.04544627
INFO:root:At the start of the epoch: mem (CPU python)=27838.6796875MB; mem (CPU total)=27579.37109375MB
INFO:root:[   39] Training loss: 0.63875631, Validation loss: 0.62769645, Gradient norm: 0.05616807
INFO:root:At the start of the epoch: mem (CPU python)=27876.76171875MB; mem (CPU total)=27618.51953125MB
INFO:root:[   40] Training loss: 0.63799128, Validation loss: 0.62659527, Gradient norm: 0.05018250
INFO:root:At the start of the epoch: mem (CPU python)=27914.87109375MB; mem (CPU total)=27655.61328125MB
INFO:root:[   41] Training loss: 0.63745138, Validation loss: 0.62644119, Gradient norm: 0.05195566
INFO:root:At the start of the epoch: mem (CPU python)=27952.96484375MB; mem (CPU total)=27693.8046875MB
INFO:root:[   42] Training loss: 0.63681216, Validation loss: 0.62642791, Gradient norm: 0.04984939
INFO:root:At the start of the epoch: mem (CPU python)=27991.06640625MB; mem (CPU total)=27732.22265625MB
INFO:root:[   43] Training loss: 0.63623417, Validation loss: 0.62518469, Gradient norm: 0.04916080
INFO:root:At the start of the epoch: mem (CPU python)=28029.16015625MB; mem (CPU total)=27770.37890625MB
INFO:root:[   44] Training loss: 0.63573452, Validation loss: 0.62563571, Gradient norm: 0.04814704
INFO:root:At the start of the epoch: mem (CPU python)=28067.2578125MB; mem (CPU total)=27809.5MB
INFO:root:[   45] Training loss: 0.63555440, Validation loss: 0.62384968, Gradient norm: 0.05669407
INFO:root:At the start of the epoch: mem (CPU python)=28105.32421875MB; mem (CPU total)=27846.68359375MB
INFO:root:[   46] Training loss: 0.63481331, Validation loss: 0.62464078, Gradient norm: 0.05665252
INFO:root:At the start of the epoch: mem (CPU python)=28143.5MB; mem (CPU total)=27884.6484375MB
INFO:root:[   47] Training loss: 0.63422939, Validation loss: 0.62363617, Gradient norm: 0.04488804
INFO:root:At the start of the epoch: mem (CPU python)=28181.59765625MB; mem (CPU total)=27922.46875MB
INFO:root:[   48] Training loss: 0.63369620, Validation loss: 0.62342120, Gradient norm: 0.05499210
INFO:root:At the start of the epoch: mem (CPU python)=28219.67578125MB; mem (CPU total)=27960.48046875MB
INFO:root:[   49] Training loss: 0.63361393, Validation loss: 0.62294109, Gradient norm: 0.05035819
INFO:root:At the start of the epoch: mem (CPU python)=28257.79296875MB; mem (CPU total)=27998.87109375MB
INFO:root:[   50] Training loss: 0.63298337, Validation loss: 0.62239866, Gradient norm: 0.04883024
INFO:root:At the start of the epoch: mem (CPU python)=28295.88671875MB; mem (CPU total)=28037.32421875MB
INFO:root:[   51] Training loss: 0.63267781, Validation loss: 0.62196873, Gradient norm: 0.05138758
INFO:root:At the start of the epoch: mem (CPU python)=28333.9296875MB; mem (CPU total)=28075.4921875MB
INFO:root:[   52] Training loss: 0.63213420, Validation loss: 0.62166966, Gradient norm: 0.05429673
INFO:root:At the start of the epoch: mem (CPU python)=28372.078125MB; mem (CPU total)=28114.08984375MB
INFO:root:[   53] Training loss: 0.63149316, Validation loss: 0.62073818, Gradient norm: 0.05339859
INFO:root:At the start of the epoch: mem (CPU python)=28410.17578125MB; mem (CPU total)=28151.76953125MB
INFO:root:[   54] Training loss: 0.63126115, Validation loss: 0.61998589, Gradient norm: 0.05114387
INFO:root:At the start of the epoch: mem (CPU python)=28448.25390625MB; mem (CPU total)=28189.421875MB
INFO:root:[   55] Training loss: 0.63108194, Validation loss: 0.61976096, Gradient norm: 0.06010201
INFO:root:At the start of the epoch: mem (CPU python)=28486.3671875MB; mem (CPU total)=28228.08984375MB
INFO:root:[   56] Training loss: 0.63066993, Validation loss: 0.61981096, Gradient norm: 0.06118824
INFO:root:At the start of the epoch: mem (CPU python)=28524.45703125MB; mem (CPU total)=28266.48046875MB
INFO:root:[   57] Training loss: 0.63006107, Validation loss: 0.61993948, Gradient norm: 0.04889903
INFO:root:At the start of the epoch: mem (CPU python)=28562.46875MB; mem (CPU total)=28305.1484375MB
INFO:root:[   58] Training loss: 0.62996828, Validation loss: 0.61885098, Gradient norm: 0.05661384
INFO:root:At the start of the epoch: mem (CPU python)=28600.59765625MB; mem (CPU total)=28342.58203125MB
INFO:root:[   59] Training loss: 0.62933489, Validation loss: 0.61969831, Gradient norm: 0.06191225
INFO:root:At the start of the epoch: mem (CPU python)=28638.6796875MB; mem (CPU total)=28381.44140625MB
INFO:root:[   60] Training loss: 0.62908530, Validation loss: 0.61801273, Gradient norm: 0.05259479
INFO:root:At the start of the epoch: mem (CPU python)=28676.765625MB; mem (CPU total)=28419.046875MB
INFO:root:[   61] Training loss: 0.62882740, Validation loss: 0.61826814, Gradient norm: 0.06007457
INFO:root:At the start of the epoch: mem (CPU python)=28714.88671875MB; mem (CPU total)=28458.171875MB
INFO:root:[   62] Training loss: 0.62854381, Validation loss: 0.61875391, Gradient norm: 0.05780852
INFO:root:At the start of the epoch: mem (CPU python)=28752.98046875MB; mem (CPU total)=28496.05859375MB
INFO:root:[   63] Training loss: 0.62817484, Validation loss: 0.61762572, Gradient norm: 0.05195166
INFO:root:At the start of the epoch: mem (CPU python)=28791.03515625MB; mem (CPU total)=28533.46484375MB
INFO:root:[   64] Training loss: 0.62773942, Validation loss: 0.61762147, Gradient norm: 0.05847328
INFO:root:At the start of the epoch: mem (CPU python)=28829.171875MB; mem (CPU total)=28571.59375MB
INFO:root:[   65] Training loss: 0.62746846, Validation loss: 0.61712846, Gradient norm: 0.06254149
INFO:root:At the start of the epoch: mem (CPU python)=28867.265625MB; mem (CPU total)=28610.015625MB
INFO:root:[   66] Training loss: 0.62724414, Validation loss: 0.61798020, Gradient norm: 0.05797500
INFO:root:At the start of the epoch: mem (CPU python)=28905.24609375MB; mem (CPU total)=28647.66015625MB
INFO:root:[   67] Training loss: 0.62686867, Validation loss: 0.61702274, Gradient norm: 0.05792508
INFO:root:At the start of the epoch: mem (CPU python)=28943.5MB; mem (CPU total)=28685.7734375MB
INFO:root:[   68] Training loss: 0.62632961, Validation loss: 0.61636291, Gradient norm: 0.05764215
INFO:root:At the start of the epoch: mem (CPU python)=28981.59765625MB; mem (CPU total)=28724.19140625MB
INFO:root:[   69] Training loss: 0.62665321, Validation loss: 0.61606019, Gradient norm: 0.06057048
INFO:root:At the start of the epoch: mem (CPU python)=29019.7109375MB; mem (CPU total)=28762.3203125MB
INFO:root:[   70] Training loss: 0.62575083, Validation loss: 0.61637861, Gradient norm: 0.05336854
INFO:root:At the start of the epoch: mem (CPU python)=29057.796875MB; mem (CPU total)=28800.6953125MB
INFO:root:[   71] Training loss: 0.62584923, Validation loss: 0.61539055, Gradient norm: 0.06224423
INFO:root:At the start of the epoch: mem (CPU python)=29095.89453125MB; mem (CPU total)=28838.578125MB
INFO:root:[   72] Training loss: 0.62515563, Validation loss: 0.61595429, Gradient norm: 0.05768650
INFO:root:At the start of the epoch: mem (CPU python)=29133.94921875MB; mem (CPU total)=28876.95703125MB
INFO:root:[   73] Training loss: 0.62536844, Validation loss: 0.61570881, Gradient norm: 0.05993423
INFO:root:At the start of the epoch: mem (CPU python)=29172.07421875MB; mem (CPU total)=28914.82421875MB
INFO:root:[   74] Training loss: 0.62474072, Validation loss: 0.61581508, Gradient norm: 0.05224144
INFO:root:At the start of the epoch: mem (CPU python)=29210.1796875MB; mem (CPU total)=28953.19921875MB
INFO:root:[   75] Training loss: 0.62466730, Validation loss: 0.61593033, Gradient norm: 0.05692997
INFO:root:At the start of the epoch: mem (CPU python)=29248.234375MB; mem (CPU total)=28991.57421875MB
INFO:root:[   76] Training loss: 0.62442280, Validation loss: 0.61505949, Gradient norm: 0.05889148
INFO:root:At the start of the epoch: mem (CPU python)=29286.37109375MB; mem (CPU total)=29029.4453125MB
INFO:root:[   77] Training loss: 0.62408541, Validation loss: 0.61437146, Gradient norm: 0.06044850
INFO:root:At the start of the epoch: mem (CPU python)=29324.46875MB; mem (CPU total)=29067.61328125MB
INFO:root:[   78] Training loss: 0.62374133, Validation loss: 0.61345546, Gradient norm: 0.05939637
INFO:root:At the start of the epoch: mem (CPU python)=29362.50390625MB; mem (CPU total)=29105.66796875MB
INFO:root:[   79] Training loss: 0.62355689, Validation loss: 0.61302922, Gradient norm: 0.05653446
INFO:root:At the start of the epoch: mem (CPU python)=29400.60546875MB; mem (CPU total)=29144.08984375MB
INFO:root:[   80] Training loss: 0.62339535, Validation loss: 0.61409009, Gradient norm: 0.06219080
INFO:root:At the start of the epoch: mem (CPU python)=29438.69921875MB; mem (CPU total)=29182.97265625MB
INFO:root:[   81] Training loss: 0.62293044, Validation loss: 0.61346051, Gradient norm: 0.05945927
INFO:root:At the start of the epoch: mem (CPU python)=29476.7578125MB; mem (CPU total)=29221.0625MB
INFO:root:[   82] Training loss: 0.62284816, Validation loss: 0.61337419, Gradient norm: 0.06164426
INFO:root:At the start of the epoch: mem (CPU python)=29514.890625MB; mem (CPU total)=29259.296875MB
INFO:root:[   83] Training loss: 0.62259056, Validation loss: 0.61319245, Gradient norm: 0.06349122
INFO:root:At the start of the epoch: mem (CPU python)=29552.984375MB; mem (CPU total)=29297.2578125MB
INFO:root:[   84] Training loss: 0.62235333, Validation loss: 0.61343938, Gradient norm: 0.05643276
INFO:root:At the start of the epoch: mem (CPU python)=29591.0625MB; mem (CPU total)=29335.671875MB
INFO:root:[   85] Training loss: 0.62207515, Validation loss: 0.61277909, Gradient norm: 0.05791747
INFO:root:At the start of the epoch: mem (CPU python)=29629.16796875MB; mem (CPU total)=29372.91015625MB
INFO:root:[   86] Training loss: 0.62193600, Validation loss: 0.61194073, Gradient norm: 0.06124701
INFO:root:At the start of the epoch: mem (CPU python)=29667.2109375MB; mem (CPU total)=29411.046875MB
INFO:root:[   87] Training loss: 0.62156135, Validation loss: 0.61207796, Gradient norm: 0.05840324
INFO:root:At the start of the epoch: mem (CPU python)=29705.3671875MB; mem (CPU total)=29449.68359375MB
INFO:root:[   88] Training loss: 0.62130890, Validation loss: 0.61176910, Gradient norm: 0.06164384
INFO:root:At the start of the epoch: mem (CPU python)=29743.51953125MB; mem (CPU total)=29487.30078125MB
INFO:root:[   89] Training loss: 0.62118773, Validation loss: 0.61406817, Gradient norm: 0.06066704
INFO:root:At the start of the epoch: mem (CPU python)=29781.54296875MB; mem (CPU total)=29526.4609375MB
INFO:root:[   90] Training loss: 0.62073915, Validation loss: 0.61205129, Gradient norm: 0.06110234
INFO:root:At the start of the epoch: mem (CPU python)=29819.69921875MB; mem (CPU total)=29564.59765625MB
INFO:root:[   91] Training loss: 0.62084512, Validation loss: 0.61285925, Gradient norm: 0.06593082
INFO:root:At the start of the epoch: mem (CPU python)=29857.79296875MB; mem (CPU total)=29602.46875MB
INFO:root:[   92] Training loss: 0.62065526, Validation loss: 0.61213044, Gradient norm: 0.06510039
INFO:root:At the start of the epoch: mem (CPU python)=29895.8515625MB; mem (CPU total)=29640.54296875MB
INFO:root:[   93] Training loss: 0.62043151, Validation loss: 0.61105855, Gradient norm: 0.06882972
INFO:root:At the start of the epoch: mem (CPU python)=29933.98046875MB; mem (CPU total)=29678.1953125MB
INFO:root:[   94] Training loss: 0.62006252, Validation loss: 0.61074578, Gradient norm: 0.05728615
INFO:root:At the start of the epoch: mem (CPU python)=29972.0859375MB; mem (CPU total)=29716.37109375MB
INFO:root:[   95] Training loss: 0.61994189, Validation loss: 0.61167629, Gradient norm: 0.06292761
INFO:root:At the start of the epoch: mem (CPU python)=30010.171875MB; mem (CPU total)=29754.76171875MB
INFO:root:[   96] Training loss: 0.61972192, Validation loss: 0.61012392, Gradient norm: 0.06507675
INFO:root:At the start of the epoch: mem (CPU python)=30048.265625MB; mem (CPU total)=29792.26953125MB
INFO:root:[   97] Training loss: 0.61969409, Validation loss: 0.61090708, Gradient norm: 0.06362709
INFO:root:At the start of the epoch: mem (CPU python)=30086.375MB; mem (CPU total)=29830.90234375MB
INFO:root:[   98] Training loss: 0.61914977, Validation loss: 0.60970946, Gradient norm: 0.06274684
INFO:root:At the start of the epoch: mem (CPU python)=30124.47265625MB; mem (CPU total)=29869.015625MB
INFO:root:[   99] Training loss: 0.61925300, Validation loss: 0.61090580, Gradient norm: 0.06512803
INFO:root:At the start of the epoch: mem (CPU python)=30162.51171875MB; mem (CPU total)=29907.8984375MB
INFO:root:[  100] Training loss: 0.61915305, Validation loss: 0.61051834, Gradient norm: 0.06556195
INFO:root:At the start of the epoch: mem (CPU python)=30200.60546875MB; mem (CPU total)=29946.50390625MB
INFO:root:[  101] Training loss: 0.61888307, Validation loss: 0.61009810, Gradient norm: 0.05544896
INFO:root:At the start of the epoch: mem (CPU python)=30238.69140625MB; mem (CPU total)=29984.6484375MB
INFO:root:[  102] Training loss: 0.61844433, Validation loss: 0.61033052, Gradient norm: 0.05945415
INFO:root:At the start of the epoch: mem (CPU python)=30276.796875MB; mem (CPU total)=30022.7265625MB
INFO:root:[  103] Training loss: 0.61838556, Validation loss: 0.61018895, Gradient norm: 0.05828965
INFO:root:At the start of the epoch: mem (CPU python)=30314.87109375MB; mem (CPU total)=30060.6171875MB
INFO:root:[  104] Training loss: 0.61829534, Validation loss: 0.60932014, Gradient norm: 0.06127418
INFO:root:At the start of the epoch: mem (CPU python)=30352.98828125MB; mem (CPU total)=30098.26953125MB
INFO:root:[  105] Training loss: 0.61812976, Validation loss: 0.60869214, Gradient norm: 0.06495577
INFO:root:At the start of the epoch: mem (CPU python)=30391.0859375MB; mem (CPU total)=30137.1875MB
INFO:root:[  106] Training loss: 0.61803539, Validation loss: 0.60948945, Gradient norm: 0.06784828
INFO:root:At the start of the epoch: mem (CPU python)=30429.1796875MB; mem (CPU total)=30175.84765625MB
INFO:root:[  107] Training loss: 0.61770295, Validation loss: 0.61047688, Gradient norm: 0.06391971
INFO:root:At the start of the epoch: mem (CPU python)=30467.2734375MB; mem (CPU total)=30213.6484375MB
INFO:root:[  108] Training loss: 0.61738951, Validation loss: 0.60919402, Gradient norm: 0.06203293
INFO:root:At the start of the epoch: mem (CPU python)=30505.2421875MB; mem (CPU total)=30251.76171875MB
INFO:root:[  109] Training loss: 0.61746009, Validation loss: 0.60982570, Gradient norm: 0.06678664
INFO:root:At the start of the epoch: mem (CPU python)=30543.51953125MB; mem (CPU total)=30289.84375MB
INFO:root:[  110] Training loss: 0.61735472, Validation loss: 0.60852633, Gradient norm: 0.06616947
INFO:root:At the start of the epoch: mem (CPU python)=30581.60546875MB; mem (CPU total)=30327.49609375MB
INFO:root:[  111] Training loss: 0.61688646, Validation loss: 0.60802002, Gradient norm: 0.06198809
INFO:root:At the start of the epoch: mem (CPU python)=30619.7109375MB; mem (CPU total)=30365.91796875MB
INFO:root:[  112] Training loss: 0.61682867, Validation loss: 0.60882472, Gradient norm: 0.06523221
INFO:root:At the start of the epoch: mem (CPU python)=30657.80859375MB; mem (CPU total)=30404.59765625MB
INFO:root:[  113] Training loss: 0.61650025, Validation loss: 0.60886588, Gradient norm: 0.06107262
INFO:root:At the start of the epoch: mem (CPU python)=30695.90234375MB; mem (CPU total)=30442.73046875MB
INFO:root:[  114] Training loss: 0.61665894, Validation loss: 0.60844838, Gradient norm: 0.06240271
INFO:root:At the start of the epoch: mem (CPU python)=30733.984375MB; mem (CPU total)=30480.875MB
INFO:root:[  115] Training loss: 0.61618316, Validation loss: 0.60926116, Gradient norm: 0.06240024
INFO:root:At the start of the epoch: mem (CPU python)=30772.09375MB; mem (CPU total)=30518.46484375MB
INFO:root:[  116] Training loss: 0.61604881, Validation loss: 0.60824977, Gradient norm: 0.06364538
INFO:root:At the start of the epoch: mem (CPU python)=30810.1328125MB; mem (CPU total)=30560.84375MB
INFO:root:[  117] Training loss: 0.61595378, Validation loss: 0.60927240, Gradient norm: 0.06173348
INFO:root:At the start of the epoch: mem (CPU python)=30848.2734375MB; mem (CPU total)=30595.00390625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  118] Training loss: 0.61591027, Validation loss: 0.61028973, Gradient norm: 0.06347227
INFO:root:At the start of the epoch: mem (CPU python)=30886.375MB; mem (CPU total)=30633.14453125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  119] Training loss: 0.61500142, Validation loss: 0.60783028, Gradient norm: 0.05829464
INFO:root:At the start of the epoch: mem (CPU python)=30924.4765625MB; mem (CPU total)=30671.11328125MB
INFO:root:[  120] Training loss: 0.61433176, Validation loss: 0.60691177, Gradient norm: 0.05234499
INFO:root:At the start of the epoch: mem (CPU python)=30962.515625MB; mem (CPU total)=30709.53125MB
INFO:root:[  121] Training loss: 0.61398550, Validation loss: 0.60805899, Gradient norm: 0.05237798
INFO:root:At the start of the epoch: mem (CPU python)=31000.609375MB; mem (CPU total)=30748.73046875MB
INFO:root:[  122] Training loss: 0.61396867, Validation loss: 0.60738314, Gradient norm: 0.05295939
INFO:root:At the start of the epoch: mem (CPU python)=31038.70703125MB; mem (CPU total)=30786.90234375MB
INFO:root:[  123] Training loss: 0.61401932, Validation loss: 0.60687758, Gradient norm: 0.05562694
INFO:root:At the start of the epoch: mem (CPU python)=31076.80078125MB; mem (CPU total)=30824.33984375MB
INFO:root:[  124] Training loss: 0.61384997, Validation loss: 0.60728167, Gradient norm: 0.05512286
INFO:root:At the start of the epoch: mem (CPU python)=31114.8671875MB; mem (CPU total)=30862.9453125MB
INFO:root:[  125] Training loss: 0.61372787, Validation loss: 0.60704404, Gradient norm: 0.05310726
INFO:root:At the start of the epoch: mem (CPU python)=31152.98828125MB; mem (CPU total)=30901.10546875MB
INFO:root:[  126] Training loss: 0.61375431, Validation loss: 0.60763617, Gradient norm: 0.05290958
INFO:root:At the start of the epoch: mem (CPU python)=31191.0859375MB; mem (CPU total)=30939.48828125MB
INFO:root:[  127] Training loss: 0.61359560, Validation loss: 0.60681548, Gradient norm: 0.05496806
INFO:root:At the start of the epoch: mem (CPU python)=31229.1796875MB; mem (CPU total)=30976.87109375MB
INFO:root:[  128] Training loss: 0.61371095, Validation loss: 0.60766316, Gradient norm: 0.05364592
INFO:root:At the start of the epoch: mem (CPU python)=31267.2734375MB; mem (CPU total)=31015.76171875MB
INFO:root:[  129] Training loss: 0.61379041, Validation loss: 0.60748489, Gradient norm: 0.05452824
INFO:root:At the start of the epoch: mem (CPU python)=31305.3125MB; mem (CPU total)=31054.13671875MB
INFO:root:[  130] Training loss: 0.61372575, Validation loss: 0.60668591, Gradient norm: 0.05513198
INFO:root:At the start of the epoch: mem (CPU python)=31343.5234375MB; mem (CPU total)=31091.5546875MB
INFO:root:[  131] Training loss: 0.61350642, Validation loss: 0.60657665, Gradient norm: 0.05499327
INFO:root:At the start of the epoch: mem (CPU python)=31381.6171875MB; mem (CPU total)=31129.76953125MB
INFO:root:[  132] Training loss: 0.61347741, Validation loss: 0.60682819, Gradient norm: 0.05326353
INFO:root:At the start of the epoch: mem (CPU python)=31419.71484375MB; mem (CPU total)=31168.65234375MB
INFO:root:[  133] Training loss: 0.61335001, Validation loss: 0.60804819, Gradient norm: 0.05612923
INFO:root:At the start of the epoch: mem (CPU python)=31457.80078125MB; mem (CPU total)=31206.7578125MB
INFO:root:[  134] Training loss: 0.61340132, Validation loss: 0.60668506, Gradient norm: 0.05550972
INFO:root:At the start of the epoch: mem (CPU python)=31495.85546875MB; mem (CPU total)=31244.6484375MB
INFO:root:[  135] Training loss: 0.61343712, Validation loss: 0.60641004, Gradient norm: 0.05335656
INFO:root:At the start of the epoch: mem (CPU python)=31533.99609375MB; mem (CPU total)=31282.2578125MB
INFO:root:[  136] Training loss: 0.61299303, Validation loss: 0.60701101, Gradient norm: 0.05454842
INFO:root:At the start of the epoch: mem (CPU python)=31572.09375MB; mem (CPU total)=31320.89453125MB
INFO:root:[  137] Training loss: 0.61336036, Validation loss: 0.60642121, Gradient norm: 0.05587179
INFO:root:At the start of the epoch: mem (CPU python)=31610.1875MB; mem (CPU total)=31359.0390625MB
INFO:root:[  138] Training loss: 0.61308672, Validation loss: 0.60743627, Gradient norm: 0.05636847
INFO:root:At the start of the epoch: mem (CPU python)=31648.28515625MB; mem (CPU total)=31396.4453125MB
INFO:root:[  139] Training loss: 0.61332562, Validation loss: 0.60678698, Gradient norm: 0.05972493
INFO:root:At the start of the epoch: mem (CPU python)=31686.3828125MB; mem (CPU total)=31434.375MB
INFO:root:[  140] Training loss: 0.61320739, Validation loss: 0.60706223, Gradient norm: 0.05578550
INFO:root:At the start of the epoch: mem (CPU python)=31724.4765625MB; mem (CPU total)=31472.51953125MB
INFO:root:[  141] Training loss: 0.61310831, Validation loss: 0.60574493, Gradient norm: 0.05602868
INFO:root:At the start of the epoch: mem (CPU python)=31762.51171875MB; mem (CPU total)=31511.08203125MB
INFO:root:[  142] Training loss: 0.61307807, Validation loss: 0.60662553, Gradient norm: 0.05603522
INFO:root:At the start of the epoch: mem (CPU python)=31800.59375MB; mem (CPU total)=31549.45703125MB
INFO:root:[  143] Training loss: 0.61318364, Validation loss: 0.60619436, Gradient norm: 0.05700190
INFO:root:At the start of the epoch: mem (CPU python)=31838.70703125MB; mem (CPU total)=31587.6015625MB
INFO:root:[  144] Training loss: 0.61285187, Validation loss: 0.60667021, Gradient norm: 0.05571114
INFO:root:At the start of the epoch: mem (CPU python)=31876.8046875MB; mem (CPU total)=31625.9921875MB
INFO:root:[  145] Training loss: 0.61302298, Validation loss: 0.60656517, Gradient norm: 0.05829429
INFO:root:At the start of the epoch: mem (CPU python)=31914.8984375MB; mem (CPU total)=31664.09765625MB
INFO:root:[  146] Training loss: 0.61293809, Validation loss: 0.60715351, Gradient norm: 0.05867646
INFO:root:At the start of the epoch: mem (CPU python)=31952.984375MB; mem (CPU total)=31702.23828125MB
INFO:root:[  147] Training loss: 0.61284174, Validation loss: 0.60634268, Gradient norm: 0.05647900
INFO:root:At the start of the epoch: mem (CPU python)=31991.08203125MB; mem (CPU total)=31740.3828125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  148] Training loss: 0.61249448, Validation loss: 0.60604272, Gradient norm: 0.05395553
INFO:root:At the start of the epoch: mem (CPU python)=32029.18359375MB; mem (CPU total)=31778.76953125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  149] Training loss: 0.61278360, Validation loss: 0.60552569, Gradient norm: 0.05387606
INFO:root:At the start of the epoch: mem (CPU python)=32067.28125MB; mem (CPU total)=31816.40625MB
INFO:root:[  150] Training loss: 0.61238341, Validation loss: 0.60640281, Gradient norm: 0.05180230
INFO:root:At the start of the epoch: mem (CPU python)=32105.375MB; mem (CPU total)=31854.828125MB
INFO:root:[  151] Training loss: 0.61241970, Validation loss: 0.60614313, Gradient norm: 0.05215673
INFO:root:At the start of the epoch: mem (CPU python)=32143.5234375MB; mem (CPU total)=31892.97265625MB
INFO:root:[  152] Training loss: 0.61229832, Validation loss: 0.60658891, Gradient norm: 0.05167932
INFO:root:At the start of the epoch: mem (CPU python)=32181.59375MB; mem (CPU total)=31931.11328125MB
INFO:root:[  153] Training loss: 0.61225136, Validation loss: 0.60671216, Gradient norm: 0.05228265
INFO:root:At the start of the epoch: mem (CPU python)=32219.71484375MB; mem (CPU total)=31969.6953125MB
INFO:root:[  154] Training loss: 0.61242727, Validation loss: 0.60588612, Gradient norm: 0.05137449
INFO:root:At the start of the epoch: mem (CPU python)=32257.76171875MB; mem (CPU total)=32007.85546875MB
INFO:root:[  155] Training loss: 0.61220546, Validation loss: 0.60643913, Gradient norm: 0.05040584
INFO:root:At the start of the epoch: mem (CPU python)=32295.8984375MB; mem (CPU total)=32046.046875MB
INFO:root:[  156] Training loss: 0.61216824, Validation loss: 0.60615684, Gradient norm: 0.05181947
INFO:root:At the start of the epoch: mem (CPU python)=32334.00390625MB; mem (CPU total)=32083.875MB
INFO:root:[  157] Training loss: 0.61209562, Validation loss: 0.60638218, Gradient norm: 0.05272122
INFO:root:At the start of the epoch: mem (CPU python)=32372.07421875MB; mem (CPU total)=32121.7265625MB
INFO:root:[  158] Training loss: 0.61217068, Validation loss: 0.60617720, Gradient norm: 0.05323583
INFO:root:At the start of the epoch: mem (CPU python)=32410.17578125MB; mem (CPU total)=32160.1171875MB
INFO:root:EP 158: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=32448.234375MB; mem (CPU total)=32198.26171875MB
INFO:root:Training the model took 12944.483s.
INFO:root:Emptying the cuda cache took 0.006s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84076
INFO:root:EnergyScoreTrain: 0.59186
INFO:root:CRPSTrain: 0.45747
INFO:root:Gaussian NLLTrain: 1.17534
INFO:root:CoverageTrain: 0.95181
INFO:root:IntervalWidthTrain: 3.24091
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86101
INFO:root:EnergyScoreValidation: 0.60604
INFO:root:CRPSValidation: 0.46949
INFO:root:Gaussian NLLValidation: 1.20283
INFO:root:CoverageValidation: 0.9454
INFO:root:IntervalWidthValidation: 3.24493
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86209
INFO:root:EnergyScoreTest: 0.60679
INFO:root:CRPSTest: 0.4701
INFO:root:Gaussian NLLTest: 1.20371
INFO:root:CoverageTest: 0.94505
INFO:root:IntervalWidthTest: 3.24319
INFO:root:After validation: mem (CPU python)=32484.51171875MB; mem (CPU total)=32256.5078125MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=32484.51171875MB; mem (CPU total)=32256.5MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=32484.51171875MB; mem (CPU total)=32256.9921875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=32484.51171875MB; mem (CPU total)=32256.9921875MB
INFO:root:[    1] Training loss: 0.72547066, Validation loss: 0.72060438, Gradient norm: 0.02268623
INFO:root:At the start of the epoch: mem (CPU python)=32545.3984375MB; mem (CPU total)=32295.24609375MB
INFO:root:[    2] Training loss: 0.71981453, Validation loss: 0.71836038, Gradient norm: 0.00634031
INFO:root:At the start of the epoch: mem (CPU python)=32583.4921875MB; mem (CPU total)=32333.5390625MB
INFO:root:[    3] Training loss: 0.71784757, Validation loss: 0.71443050, Gradient norm: 0.00898707
INFO:root:At the start of the epoch: mem (CPU python)=32621.56640625MB; mem (CPU total)=32371.70703125MB
INFO:root:[    4] Training loss: 0.71198387, Validation loss: 0.70661070, Gradient norm: 0.01751997
INFO:root:At the start of the epoch: mem (CPU python)=32659.66796875MB; mem (CPU total)=32410.09765625MB
INFO:root:[    5] Training loss: 0.70662118, Validation loss: 0.70105419, Gradient norm: 0.02705076
INFO:root:At the start of the epoch: mem (CPU python)=32697.7734375MB; mem (CPU total)=32448.2421875MB
INFO:root:[    6] Training loss: 0.70212063, Validation loss: 0.69602381, Gradient norm: 0.02938846
INFO:root:At the start of the epoch: mem (CPU python)=32735.87109375MB; mem (CPU total)=32486.38671875MB
INFO:root:[    7] Training loss: 0.69789156, Validation loss: 0.69209560, Gradient norm: 0.03208518
INFO:root:At the start of the epoch: mem (CPU python)=32773.953125MB; mem (CPU total)=32524.47265625MB
INFO:root:[    8] Training loss: 0.69422969, Validation loss: 0.68743733, Gradient norm: 0.03270007
INFO:root:At the start of the epoch: mem (CPU python)=32812.0625MB; mem (CPU total)=32562.921875MB
INFO:root:[    9] Training loss: 0.69030818, Validation loss: 0.68336287, Gradient norm: 0.03091097
INFO:root:At the start of the epoch: mem (CPU python)=32850.140625MB; mem (CPU total)=32601.28125MB
INFO:root:[   10] Training loss: 0.68689430, Validation loss: 0.68007133, Gradient norm: 0.03350920
INFO:root:At the start of the epoch: mem (CPU python)=32888.2265625MB; mem (CPU total)=32639.43359375MB
INFO:root:[   11] Training loss: 0.68347784, Validation loss: 0.67599280, Gradient norm: 0.03152086
INFO:root:At the start of the epoch: mem (CPU python)=32926.28515625MB; mem (CPU total)=32677.28515625MB
INFO:root:[   12] Training loss: 0.68068610, Validation loss: 0.67245490, Gradient norm: 0.03448579
INFO:root:At the start of the epoch: mem (CPU python)=32964.234375MB; mem (CPU total)=32715.2578125MB
INFO:root:[   13] Training loss: 0.67800716, Validation loss: 0.67028412, Gradient norm: 0.03491590
INFO:root:At the start of the epoch: mem (CPU python)=33002.4765625MB; mem (CPU total)=32753.90625MB
INFO:root:[   14] Training loss: 0.67540092, Validation loss: 0.66723137, Gradient norm: 0.03566679
INFO:root:At the start of the epoch: mem (CPU python)=33040.578125MB; mem (CPU total)=32792.04296875MB
INFO:root:[   15] Training loss: 0.67304076, Validation loss: 0.66435578, Gradient norm: 0.03707639
INFO:root:At the start of the epoch: mem (CPU python)=33078.67578125MB; mem (CPU total)=32830.2265625MB
INFO:root:[   16] Training loss: 0.67088756, Validation loss: 0.66214256, Gradient norm: 0.04057743
INFO:root:At the start of the epoch: mem (CPU python)=33116.7734375MB; mem (CPU total)=32868.33984375MB
INFO:root:[   17] Training loss: 0.66854640, Validation loss: 0.65869743, Gradient norm: 0.03759547
INFO:root:At the start of the epoch: mem (CPU python)=33154.859375MB; mem (CPU total)=32906.4453125MB
INFO:root:[   18] Training loss: 0.66619579, Validation loss: 0.65680476, Gradient norm: 0.03635039
INFO:root:At the start of the epoch: mem (CPU python)=33192.96484375MB; mem (CPU total)=32944.58984375MB
INFO:root:[   19] Training loss: 0.66428989, Validation loss: 0.65403658, Gradient norm: 0.03782017
INFO:root:At the start of the epoch: mem (CPU python)=33231.08203125MB; mem (CPU total)=32983.01171875MB
INFO:root:[   20] Training loss: 0.66247203, Validation loss: 0.65228100, Gradient norm: 0.04306731
INFO:root:At the start of the epoch: mem (CPU python)=33269.20703125MB; mem (CPU total)=33021.15625MB
INFO:root:[   21] Training loss: 0.66050090, Validation loss: 0.64997756, Gradient norm: 0.03979775
INFO:root:At the start of the epoch: mem (CPU python)=33307.30078125MB; mem (CPU total)=33059.2890625MB
INFO:root:[   22] Training loss: 0.65882160, Validation loss: 0.64819106, Gradient norm: 0.04208761
INFO:root:At the start of the epoch: mem (CPU python)=33345.3984375MB; mem (CPU total)=33097.7265625MB
INFO:root:[   23] Training loss: 0.65707918, Validation loss: 0.64566923, Gradient norm: 0.04386253
INFO:root:At the start of the epoch: mem (CPU python)=33383.4921875MB; mem (CPU total)=33136.4921875MB
INFO:root:[   24] Training loss: 0.65532954, Validation loss: 0.64473731, Gradient norm: 0.04374089
INFO:root:At the start of the epoch: mem (CPU python)=33421.57421875MB; mem (CPU total)=33173.890625MB
INFO:root:[   25] Training loss: 0.65398399, Validation loss: 0.64326178, Gradient norm: 0.04359143
INFO:root:At the start of the epoch: mem (CPU python)=33459.68359375MB; mem (CPU total)=33211.7578125MB
INFO:root:[   26] Training loss: 0.65275248, Validation loss: 0.64164011, Gradient norm: 0.04353967
INFO:root:At the start of the epoch: mem (CPU python)=33497.76171875MB; mem (CPU total)=33249.90234375MB
INFO:root:[   27] Training loss: 0.65146099, Validation loss: 0.64033025, Gradient norm: 0.04711770
INFO:root:At the start of the epoch: mem (CPU python)=33535.87890625MB; mem (CPU total)=33288.27734375MB
INFO:root:[   28] Training loss: 0.65017745, Validation loss: 0.63907868, Gradient norm: 0.04410116
INFO:root:At the start of the epoch: mem (CPU python)=33573.96875MB; mem (CPU total)=33326.15625MB
INFO:root:[   29] Training loss: 0.64917586, Validation loss: 0.63813492, Gradient norm: 0.04590552
INFO:root:At the start of the epoch: mem (CPU python)=33612.0625MB; mem (CPU total)=33364.44140625MB
INFO:root:[   30] Training loss: 0.64810739, Validation loss: 0.63807831, Gradient norm: 0.04612477
INFO:root:At the start of the epoch: mem (CPU python)=33650.109375MB; mem (CPU total)=33402.62109375MB
INFO:root:[   31] Training loss: 0.64737433, Validation loss: 0.63742531, Gradient norm: 0.05509210
INFO:root:At the start of the epoch: mem (CPU python)=33688.1953125MB; mem (CPU total)=33440.72265625MB
INFO:root:[   32] Training loss: 0.64639999, Validation loss: 0.63531168, Gradient norm: 0.05440582
INFO:root:At the start of the epoch: mem (CPU python)=33726.30078125MB; mem (CPU total)=33478.859375MB
INFO:root:[   33] Training loss: 0.64556342, Validation loss: 0.63492361, Gradient norm: 0.05197141
INFO:root:At the start of the epoch: mem (CPU python)=33764.390625MB; mem (CPU total)=33516.546875MB
INFO:root:[   34] Training loss: 0.64485372, Validation loss: 0.63300063, Gradient norm: 0.05439921
INFO:root:At the start of the epoch: mem (CPU python)=33802.4765625MB; mem (CPU total)=33555.18359375MB
INFO:root:[   35] Training loss: 0.64385129, Validation loss: 0.63314168, Gradient norm: 0.04691594
INFO:root:At the start of the epoch: mem (CPU python)=33840.5703125MB; mem (CPU total)=33593.80859375MB
INFO:root:[   36] Training loss: 0.64320383, Validation loss: 0.63269093, Gradient norm: 0.05568595
INFO:root:At the start of the epoch: mem (CPU python)=33878.68359375MB; mem (CPU total)=33631.4375MB
INFO:root:[   37] Training loss: 0.64247486, Validation loss: 0.63232742, Gradient norm: 0.05212284
INFO:root:At the start of the epoch: mem (CPU python)=33916.76953125MB; mem (CPU total)=33669.1015625MB
INFO:root:[   38] Training loss: 0.64183218, Validation loss: 0.63068863, Gradient norm: 0.05406954
INFO:root:At the start of the epoch: mem (CPU python)=33954.87109375MB; mem (CPU total)=33707.2265625MB
INFO:root:[   39] Training loss: 0.64106324, Validation loss: 0.63068846, Gradient norm: 0.05329530
INFO:root:At the start of the epoch: mem (CPU python)=33992.96875MB; mem (CPU total)=33745.33203125MB
INFO:root:[   40] Training loss: 0.64062690, Validation loss: 0.62986404, Gradient norm: 0.05688341
INFO:root:At the start of the epoch: mem (CPU python)=34031.109375MB; mem (CPU total)=33783.96875MB
INFO:root:[   41] Training loss: 0.63981731, Validation loss: 0.62844589, Gradient norm: 0.05563929
INFO:root:At the start of the epoch: mem (CPU python)=34069.2109375MB; mem (CPU total)=33822.11328125MB
INFO:root:[   42] Training loss: 0.63932617, Validation loss: 0.62867000, Gradient norm: 0.05076671
INFO:root:At the start of the epoch: mem (CPU python)=34107.30859375MB; mem (CPU total)=33860.9921875MB
INFO:root:[   43] Training loss: 0.63893433, Validation loss: 0.62735773, Gradient norm: 0.05892655
INFO:root:At the start of the epoch: mem (CPU python)=34145.40234375MB; mem (CPU total)=33898.3125MB
INFO:root:[   44] Training loss: 0.63819413, Validation loss: 0.62738884, Gradient norm: 0.05126262
INFO:root:At the start of the epoch: mem (CPU python)=34183.4921875MB; mem (CPU total)=33937.17578125MB
INFO:root:[   45] Training loss: 0.63770296, Validation loss: 0.62718265, Gradient norm: 0.05390064
INFO:root:At the start of the epoch: mem (CPU python)=34221.5859375MB; mem (CPU total)=33974.796875MB
INFO:root:[   46] Training loss: 0.63754706, Validation loss: 0.62692125, Gradient norm: 0.06412583
INFO:root:At the start of the epoch: mem (CPU python)=34259.6875MB; mem (CPU total)=34012.6953125MB
INFO:root:[   47] Training loss: 0.63706935, Validation loss: 0.62647223, Gradient norm: 0.06387369
INFO:root:At the start of the epoch: mem (CPU python)=34297.78515625MB; mem (CPU total)=34051.0859375MB
INFO:root:[   48] Training loss: 0.63626497, Validation loss: 0.62566195, Gradient norm: 0.05604544
INFO:root:At the start of the epoch: mem (CPU python)=34335.8671875MB; mem (CPU total)=34088.1328125MB
INFO:root:[   49] Training loss: 0.63590394, Validation loss: 0.62602021, Gradient norm: 0.05903546
INFO:root:At the start of the epoch: mem (CPU python)=34373.9765625MB; mem (CPU total)=34126.765625MB
INFO:root:[   50] Training loss: 0.63557464, Validation loss: 0.62497087, Gradient norm: 0.05264926
INFO:root:At the start of the epoch: mem (CPU python)=34412.078125MB; mem (CPU total)=34164.5390625MB
INFO:root:[   51] Training loss: 0.63495698, Validation loss: 0.62401339, Gradient norm: 0.05619645
INFO:root:At the start of the epoch: mem (CPU python)=34450.10546875MB; mem (CPU total)=34203.34375MB
INFO:root:[   52] Training loss: 0.63446754, Validation loss: 0.62436116, Gradient norm: 0.05699394
INFO:root:At the start of the epoch: mem (CPU python)=34488.1875MB; mem (CPU total)=34241.6015625MB
INFO:root:[   53] Training loss: 0.63417331, Validation loss: 0.62346352, Gradient norm: 0.05827691
INFO:root:At the start of the epoch: mem (CPU python)=34526.3046875MB; mem (CPU total)=34279.07421875MB
INFO:root:[   54] Training loss: 0.63373018, Validation loss: 0.62470079, Gradient norm: 0.05520364
INFO:root:At the start of the epoch: mem (CPU python)=34564.3984375MB; mem (CPU total)=34318.5078125MB
INFO:root:[   55] Training loss: 0.63344847, Validation loss: 0.62320368, Gradient norm: 0.06006341
INFO:root:At the start of the epoch: mem (CPU python)=34602.4765625MB; mem (CPU total)=34356.09375MB
INFO:root:[   56] Training loss: 0.63309594, Validation loss: 0.62275388, Gradient norm: 0.05439567
INFO:root:At the start of the epoch: mem (CPU python)=34640.58984375MB; mem (CPU total)=34394.265625MB
INFO:root:[   57] Training loss: 0.63280123, Validation loss: 0.62228305, Gradient norm: 0.05853494
INFO:root:At the start of the epoch: mem (CPU python)=34678.67578125MB; mem (CPU total)=34432.765625MB
INFO:root:[   58] Training loss: 0.63229417, Validation loss: 0.62154075, Gradient norm: 0.06132886
INFO:root:At the start of the epoch: mem (CPU python)=34716.76953125MB; mem (CPU total)=34471.171875MB
INFO:root:[   59] Training loss: 0.63217567, Validation loss: 0.62172835, Gradient norm: 0.06361223
INFO:root:At the start of the epoch: mem (CPU python)=34754.85546875MB; mem (CPU total)=34509.80859375MB
INFO:root:[   60] Training loss: 0.63167122, Validation loss: 0.62186153, Gradient norm: 0.05611531
INFO:root:At the start of the epoch: mem (CPU python)=34792.9765625MB; mem (CPU total)=34547.859375MB
INFO:root:[   61] Training loss: 0.63136124, Validation loss: 0.62077565, Gradient norm: 0.06370069
INFO:root:At the start of the epoch: mem (CPU python)=34831.1015625MB; mem (CPU total)=34585.54296875MB
INFO:root:[   62] Training loss: 0.63099499, Validation loss: 0.62091977, Gradient norm: 0.06558938
INFO:root:At the start of the epoch: mem (CPU python)=34869.21875MB; mem (CPU total)=34624.3359375MB
INFO:root:[   63] Training loss: 0.63060608, Validation loss: 0.62035547, Gradient norm: 0.05938235
INFO:root:At the start of the epoch: mem (CPU python)=34907.26953125MB; mem (CPU total)=34661.9921875MB
INFO:root:[   64] Training loss: 0.63046016, Validation loss: 0.62138828, Gradient norm: 0.05899234
INFO:root:At the start of the epoch: mem (CPU python)=34945.39453125MB; mem (CPU total)=34700.53515625MB
INFO:root:[   65] Training loss: 0.63017506, Validation loss: 0.61994588, Gradient norm: 0.06142628
INFO:root:At the start of the epoch: mem (CPU python)=34983.50390625MB; mem (CPU total)=34738.3828125MB
INFO:root:[   66] Training loss: 0.62982020, Validation loss: 0.61972051, Gradient norm: 0.06139227
INFO:root:At the start of the epoch: mem (CPU python)=35021.6015625MB; mem (CPU total)=34776.51171875MB
INFO:root:[   67] Training loss: 0.62949250, Validation loss: 0.61928032, Gradient norm: 0.06980799
INFO:root:At the start of the epoch: mem (CPU python)=35059.69140625MB; mem (CPU total)=34814.41015625MB
INFO:root:[   68] Training loss: 0.62905760, Validation loss: 0.61931616, Gradient norm: 0.05995680
INFO:root:At the start of the epoch: mem (CPU python)=35097.79296875MB; mem (CPU total)=34852.5MB
INFO:root:[   69] Training loss: 0.62898101, Validation loss: 0.61866291, Gradient norm: 0.06575260
INFO:root:At the start of the epoch: mem (CPU python)=35135.890625MB; mem (CPU total)=34890.44921875MB
INFO:root:[   70] Training loss: 0.62872008, Validation loss: 0.61897573, Gradient norm: 0.06365959
INFO:root:At the start of the epoch: mem (CPU python)=35173.98828125MB; mem (CPU total)=34929.671875MB
INFO:root:[   71] Training loss: 0.62839648, Validation loss: 0.61902707, Gradient norm: 0.06275153
INFO:root:At the start of the epoch: mem (CPU python)=35212.08203125MB; mem (CPU total)=34967.73828125MB
INFO:root:[   72] Training loss: 0.62780816, Validation loss: 0.61833952, Gradient norm: 0.05654026
INFO:root:At the start of the epoch: mem (CPU python)=35250.109375MB; mem (CPU total)=35005.91796875MB
INFO:root:[   73] Training loss: 0.62775986, Validation loss: 0.61744725, Gradient norm: 0.05762664
INFO:root:At the start of the epoch: mem (CPU python)=35288.2109375MB; mem (CPU total)=35044.01953125MB
INFO:root:[   74] Training loss: 0.62736953, Validation loss: 0.61783466, Gradient norm: 0.05836272
INFO:root:At the start of the epoch: mem (CPU python)=35326.30859375MB; mem (CPU total)=35082.93359375MB
INFO:root:[   75] Training loss: 0.62725275, Validation loss: 0.61763560, Gradient norm: 0.06212041
INFO:root:At the start of the epoch: mem (CPU python)=35364.41015625MB; mem (CPU total)=35120.8515625MB
INFO:root:[   76] Training loss: 0.62710643, Validation loss: 0.61730601, Gradient norm: 0.06612877
INFO:root:At the start of the epoch: mem (CPU python)=35402.50390625MB; mem (CPU total)=35158.25390625MB
INFO:root:[   77] Training loss: 0.62651300, Validation loss: 0.61713543, Gradient norm: 0.05887415
INFO:root:At the start of the epoch: mem (CPU python)=35440.59375MB; mem (CPU total)=35196.33203125MB
INFO:root:[   78] Training loss: 0.62643756, Validation loss: 0.61664619, Gradient norm: 0.06324066
INFO:root:At the start of the epoch: mem (CPU python)=35478.6875MB; mem (CPU total)=35235.15625MB
INFO:root:[   79] Training loss: 0.62625782, Validation loss: 0.61605409, Gradient norm: 0.06095450
INFO:root:At the start of the epoch: mem (CPU python)=35516.7890625MB; mem (CPU total)=35272.9375MB
INFO:root:[   80] Training loss: 0.62607903, Validation loss: 0.61588475, Gradient norm: 0.06536439
INFO:root:At the start of the epoch: mem (CPU python)=35554.86328125MB; mem (CPU total)=35311.1171875MB
INFO:root:[   81] Training loss: 0.62596195, Validation loss: 0.61624115, Gradient norm: 0.07103553
INFO:root:At the start of the epoch: mem (CPU python)=35592.98046875MB; mem (CPU total)=35350.00390625MB
INFO:root:[   82] Training loss: 0.62559750, Validation loss: 0.61608380, Gradient norm: 0.06684550
INFO:root:At the start of the epoch: mem (CPU python)=35631.07421875MB; mem (CPU total)=35388.31640625MB
INFO:root:[   83] Training loss: 0.62527093, Validation loss: 0.61520938, Gradient norm: 0.05986116
INFO:root:At the start of the epoch: mem (CPU python)=35669.2265625MB; mem (CPU total)=35425.6171875MB
INFO:root:[   84] Training loss: 0.62526828, Validation loss: 0.61565786, Gradient norm: 0.06206567
INFO:root:At the start of the epoch: mem (CPU python)=35707.28125MB; mem (CPU total)=35464.3046875MB
INFO:root:[   85] Training loss: 0.62482543, Validation loss: 0.61543936, Gradient norm: 0.05939651
INFO:root:At the start of the epoch: mem (CPU python)=35745.41796875MB; mem (CPU total)=35502.23828125MB
INFO:root:[   86] Training loss: 0.62480671, Validation loss: 0.61537586, Gradient norm: 0.06385840
INFO:root:At the start of the epoch: mem (CPU python)=35783.46875MB; mem (CPU total)=35540.15234375MB
INFO:root:[   87] Training loss: 0.62447946, Validation loss: 0.61384094, Gradient norm: 0.06911749
INFO:root:At the start of the epoch: mem (CPU python)=35821.6015625MB; mem (CPU total)=35577.9375MB
INFO:root:[   88] Training loss: 0.62407894, Validation loss: 0.61439508, Gradient norm: 0.06290271
INFO:root:At the start of the epoch: mem (CPU python)=35859.703125MB; mem (CPU total)=35616.05859375MB
INFO:root:[   89] Training loss: 0.62390818, Validation loss: 0.61437455, Gradient norm: 0.06109749
INFO:root:At the start of the epoch: mem (CPU python)=35897.796875MB; mem (CPU total)=35654.1953125MB
INFO:root:[   90] Training loss: 0.62364369, Validation loss: 0.61479574, Gradient norm: 0.06312096
INFO:root:At the start of the epoch: mem (CPU python)=35935.89453125MB; mem (CPU total)=35692.6171875MB
INFO:root:[   91] Training loss: 0.62337809, Validation loss: 0.61501540, Gradient norm: 0.06397125
INFO:root:At the start of the epoch: mem (CPU python)=35973.98046875MB; mem (CPU total)=35730.65234375MB
INFO:root:[   92] Training loss: 0.62342263, Validation loss: 0.61533400, Gradient norm: 0.06775574
INFO:root:At the start of the epoch: mem (CPU python)=36012.08203125MB; mem (CPU total)=35768.74609375MB
INFO:root:[   93] Training loss: 0.62334336, Validation loss: 0.61356594, Gradient norm: 0.07028047
INFO:root:At the start of the epoch: mem (CPU python)=36050.11328125MB; mem (CPU total)=35806.62109375MB
INFO:root:[   94] Training loss: 0.62312755, Validation loss: 0.61400446, Gradient norm: 0.05868002
INFO:root:At the start of the epoch: mem (CPU python)=36088.22265625MB; mem (CPU total)=35845.5MB
INFO:root:[   95] Training loss: 0.62273500, Validation loss: 0.61343606, Gradient norm: 0.06092089
INFO:root:At the start of the epoch: mem (CPU python)=36126.30859375MB; mem (CPU total)=35882.671875MB
INFO:root:[   96] Training loss: 0.62275023, Validation loss: 0.61370959, Gradient norm: 0.05994223
INFO:root:At the start of the epoch: mem (CPU python)=36164.41015625MB; mem (CPU total)=35920.8125MB
INFO:root:[   97] Training loss: 0.62229793, Validation loss: 0.61269320, Gradient norm: 0.06075973
INFO:root:At the start of the epoch: mem (CPU python)=36202.5078125MB; mem (CPU total)=35958.84765625MB
INFO:root:[   98] Training loss: 0.62210211, Validation loss: 0.61359713, Gradient norm: 0.05970208
INFO:root:At the start of the epoch: mem (CPU python)=36240.6015625MB; mem (CPU total)=35997.47265625MB
INFO:root:[   99] Training loss: 0.62205591, Validation loss: 0.61280034, Gradient norm: 0.06488403
INFO:root:At the start of the epoch: mem (CPU python)=36278.6875MB; mem (CPU total)=36035.6015625MB
INFO:root:[  100] Training loss: 0.62178319, Validation loss: 0.61340931, Gradient norm: 0.06252614
INFO:root:At the start of the epoch: mem (CPU python)=36316.79296875MB; mem (CPU total)=36073.78515625MB
INFO:root:[  101] Training loss: 0.62147310, Validation loss: 0.61292806, Gradient norm: 0.05742343
INFO:root:At the start of the epoch: mem (CPU python)=36354.890625MB; mem (CPU total)=36111.87109375MB
INFO:root:[  102] Training loss: 0.62145561, Validation loss: 0.61273076, Gradient norm: 0.05822657
INFO:root:At the start of the epoch: mem (CPU python)=36392.984375MB; mem (CPU total)=36150.04296875MB
INFO:root:[  103] Training loss: 0.62144388, Validation loss: 0.61314760, Gradient norm: 0.06470804
INFO:root:At the start of the epoch: mem (CPU python)=36431.13671875MB; mem (CPU total)=36188.46484375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  104] Training loss: 0.62110068, Validation loss: 0.61236882, Gradient norm: 0.06709176
INFO:root:At the start of the epoch: mem (CPU python)=36469.23046875MB; mem (CPU total)=36226.8671875MB
INFO:root:[  105] Training loss: 0.62011494, Validation loss: 0.61133871, Gradient norm: 0.05700235
INFO:root:At the start of the epoch: mem (CPU python)=36507.23046875MB; mem (CPU total)=36264.640625MB
INFO:root:[  106] Training loss: 0.61975765, Validation loss: 0.61135018, Gradient norm: 0.05533118
INFO:root:At the start of the epoch: mem (CPU python)=36545.41796875MB; mem (CPU total)=36312.2265625MB
INFO:root:[  107] Training loss: 0.61971436, Validation loss: 0.61198515, Gradient norm: 0.05606739
INFO:root:At the start of the epoch: mem (CPU python)=36583.5078125MB; mem (CPU total)=36349.9765625MB
INFO:root:[  108] Training loss: 0.61957952, Validation loss: 0.61099145, Gradient norm: 0.05802693
INFO:root:At the start of the epoch: mem (CPU python)=36621.60546875MB; mem (CPU total)=36387.67578125MB
INFO:root:[  109] Training loss: 0.61966697, Validation loss: 0.61100358, Gradient norm: 0.05715626
INFO:root:At the start of the epoch: mem (CPU python)=36659.67578125MB; mem (CPU total)=36419.984375MB
INFO:root:[  110] Training loss: 0.61958848, Validation loss: 0.61172100, Gradient norm: 0.05675624
INFO:root:At the start of the epoch: mem (CPU python)=36697.8046875MB; mem (CPU total)=36457.70703125MB
INFO:root:[  111] Training loss: 0.61940546, Validation loss: 0.61162985, Gradient norm: 0.05618136
INFO:root:At the start of the epoch: mem (CPU python)=36735.8203125MB; mem (CPU total)=36495.57421875MB
INFO:root:[  112] Training loss: 0.61911190, Validation loss: 0.61078842, Gradient norm: 0.05852400
INFO:root:At the start of the epoch: mem (CPU python)=36773.9921875MB; mem (CPU total)=36533.625MB
INFO:root:[  113] Training loss: 0.61921727, Validation loss: 0.61080609, Gradient norm: 0.05837877
INFO:root:At the start of the epoch: mem (CPU python)=36812.05078125MB; mem (CPU total)=36572.015625MB
INFO:root:[  114] Training loss: 0.61880348, Validation loss: 0.61122184, Gradient norm: 0.05659256
INFO:root:At the start of the epoch: mem (CPU python)=36850.1328125MB; mem (CPU total)=36610.6484375MB
INFO:root:[  115] Training loss: 0.61895145, Validation loss: 0.61155436, Gradient norm: 0.06048263
INFO:root:At the start of the epoch: mem (CPU python)=36888.109375MB; mem (CPU total)=36647.74609375MB
INFO:root:[  116] Training loss: 0.61896006, Validation loss: 0.61121993, Gradient norm: 0.05568447
INFO:root:At the start of the epoch: mem (CPU python)=36926.32421875MB; mem (CPU total)=36686.1328125MB
INFO:root:[  117] Training loss: 0.61893551, Validation loss: 0.61061431, Gradient norm: 0.05998409
INFO:root:At the start of the epoch: mem (CPU python)=36964.48046875MB; mem (CPU total)=36723.453125MB
INFO:root:[  118] Training loss: 0.61875413, Validation loss: 0.61111511, Gradient norm: 0.05826649
INFO:root:At the start of the epoch: mem (CPU python)=37002.5MB; mem (CPU total)=36762.07421875MB
INFO:root:[  119] Training loss: 0.61858406, Validation loss: 0.61083530, Gradient norm: 0.06272425
INFO:root:At the start of the epoch: mem (CPU python)=37040.41015625MB; mem (CPU total)=36800.19921875MB
INFO:root:[  120] Training loss: 0.61854418, Validation loss: 0.61120603, Gradient norm: 0.05900187
INFO:root:At the start of the epoch: mem (CPU python)=37078.70703125MB; mem (CPU total)=36838.55859375MB
INFO:root:[  121] Training loss: 0.61848973, Validation loss: 0.61068752, Gradient norm: 0.06227598
INFO:root:At the start of the epoch: mem (CPU python)=37116.80859375MB; mem (CPU total)=36876.48828125MB
INFO:root:[  122] Training loss: 0.61884673, Validation loss: 0.61060332, Gradient norm: 0.06630712
INFO:root:At the start of the epoch: mem (CPU python)=37154.89453125MB; mem (CPU total)=36913.37890625MB
INFO:root:[  123] Training loss: 0.61845198, Validation loss: 0.61046419, Gradient norm: 0.06139294
INFO:root:At the start of the epoch: mem (CPU python)=37192.91015625MB; mem (CPU total)=36951.28125MB
INFO:root:[  124] Training loss: 0.61820353, Validation loss: 0.61000981, Gradient norm: 0.05855457
INFO:root:At the start of the epoch: mem (CPU python)=37231.140625MB; mem (CPU total)=36989.6796875MB
INFO:root:[  125] Training loss: 0.61823606, Validation loss: 0.61039148, Gradient norm: 0.05819470
INFO:root:At the start of the epoch: mem (CPU python)=37269.1953125MB; mem (CPU total)=37028.33984375MB
INFO:root:[  126] Training loss: 0.61819636, Validation loss: 0.61066481, Gradient norm: 0.06075200
INFO:root:At the start of the epoch: mem (CPU python)=37307.32421875MB; mem (CPU total)=37066.39453125MB
INFO:root:[  127] Training loss: 0.61808852, Validation loss: 0.61086651, Gradient norm: 0.05795965
INFO:root:At the start of the epoch: mem (CPU python)=37345.40625MB; mem (CPU total)=37104.25MB
INFO:root:[  128] Training loss: 0.61816417, Validation loss: 0.61012401, Gradient norm: 0.06128887
INFO:root:At the start of the epoch: mem (CPU python)=37383.52734375MB; mem (CPU total)=37142.3984375MB
INFO:root:[  129] Training loss: 0.61780219, Validation loss: 0.60958423, Gradient norm: 0.06287904
INFO:root:At the start of the epoch: mem (CPU python)=37421.59375MB; mem (CPU total)=37180.5625MB
INFO:root:[  130] Training loss: 0.61786642, Validation loss: 0.61040226, Gradient norm: 0.06339201
INFO:root:At the start of the epoch: mem (CPU python)=37459.71484375MB; mem (CPU total)=37218.47265625MB
INFO:root:[  131] Training loss: 0.61777929, Validation loss: 0.61006992, Gradient norm: 0.06860228
INFO:root:At the start of the epoch: mem (CPU python)=37497.78515625MB; mem (CPU total)=37256.55078125MB
INFO:root:[  132] Training loss: 0.61775537, Validation loss: 0.61008914, Gradient norm: 0.06332511
INFO:root:At the start of the epoch: mem (CPU python)=37535.90234375MB; mem (CPU total)=37294.70703125MB
INFO:root:[  133] Training loss: 0.61749168, Validation loss: 0.60988494, Gradient norm: 0.06311023
INFO:root:At the start of the epoch: mem (CPU python)=37573.984375MB; mem (CPU total)=37332.87890625MB
INFO:root:[  134] Training loss: 0.61742345, Validation loss: 0.60979277, Gradient norm: 0.06137644
INFO:root:At the start of the epoch: mem (CPU python)=37612.0859375MB; mem (CPU total)=37370.77734375MB
INFO:root:[  135] Training loss: 0.61712858, Validation loss: 0.60976386, Gradient norm: 0.05958518
INFO:root:At the start of the epoch: mem (CPU python)=37650.1171875MB; mem (CPU total)=37409.6953125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  136] Training loss: 0.61726290, Validation loss: 0.60977264, Gradient norm: 0.06062039
INFO:root:At the start of the epoch: mem (CPU python)=37688.234375MB; mem (CPU total)=37447.875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  137] Training loss: 0.61661095, Validation loss: 0.60935915, Gradient norm: 0.05647778
INFO:root:At the start of the epoch: mem (CPU python)=37726.29296875MB; mem (CPU total)=37485.01171875MB
INFO:root:[  138] Training loss: 0.61633223, Validation loss: 0.60932996, Gradient norm: 0.05335490
INFO:root:At the start of the epoch: mem (CPU python)=37764.4296875MB; mem (CPU total)=37523.57421875MB
INFO:root:[  139] Training loss: 0.61634789, Validation loss: 0.60916318, Gradient norm: 0.05150154
INFO:root:At the start of the epoch: mem (CPU python)=37802.48046875MB; mem (CPU total)=37561.6328125MB
INFO:root:[  140] Training loss: 0.61624929, Validation loss: 0.60897433, Gradient norm: 0.05147991
INFO:root:At the start of the epoch: mem (CPU python)=37840.609375MB; mem (CPU total)=37599.82421875MB
INFO:root:[  141] Training loss: 0.61636233, Validation loss: 0.60917556, Gradient norm: 0.05448008
INFO:root:At the start of the epoch: mem (CPU python)=37878.70703125MB; mem (CPU total)=37638.70703125MB
INFO:root:[  142] Training loss: 0.61630938, Validation loss: 0.60968244, Gradient norm: 0.05401576
INFO:root:At the start of the epoch: mem (CPU python)=37916.80078125MB; mem (CPU total)=37677.11328125MB
INFO:root:[  143] Training loss: 0.61618054, Validation loss: 0.60935386, Gradient norm: 0.05557509
INFO:root:At the start of the epoch: mem (CPU python)=37954.87109375MB; mem (CPU total)=37715.26171875MB
INFO:root:[  144] Training loss: 0.61629513, Validation loss: 0.60919353, Gradient norm: 0.05418012
INFO:root:At the start of the epoch: mem (CPU python)=37992.9921875MB; mem (CPU total)=37752.94140625MB
INFO:root:[  145] Training loss: 0.61611634, Validation loss: 0.60856297, Gradient norm: 0.05372497
INFO:root:At the start of the epoch: mem (CPU python)=38031.0859375MB; mem (CPU total)=37790.16015625MB
INFO:root:[  146] Training loss: 0.61623878, Validation loss: 0.60900041, Gradient norm: 0.05306601
INFO:root:At the start of the epoch: mem (CPU python)=38069.23828125MB; mem (CPU total)=37829.0703125MB
INFO:root:[  147] Training loss: 0.61644463, Validation loss: 0.60886158, Gradient norm: 0.05529451
INFO:root:At the start of the epoch: mem (CPU python)=38107.31640625MB; mem (CPU total)=37867.25MB
INFO:root:[  148] Training loss: 0.61599972, Validation loss: 0.60903300, Gradient norm: 0.05382373
INFO:root:At the start of the epoch: mem (CPU python)=38145.4296875MB; mem (CPU total)=37905.421875MB
INFO:root:[  149] Training loss: 0.61611951, Validation loss: 0.60932292, Gradient norm: 0.05462865
INFO:root:At the start of the epoch: mem (CPU python)=38183.5078125MB; mem (CPU total)=37943.546875MB
INFO:root:[  150] Training loss: 0.61590701, Validation loss: 0.60896244, Gradient norm: 0.05366561
INFO:root:At the start of the epoch: mem (CPU python)=38221.6171875MB; mem (CPU total)=37981.6796875MB
INFO:root:[  151] Training loss: 0.61593575, Validation loss: 0.60933247, Gradient norm: 0.05410971
INFO:root:At the start of the epoch: mem (CPU python)=38259.72265625MB; mem (CPU total)=38019.60546875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  152] Training loss: 0.61580272, Validation loss: 0.60871905, Gradient norm: 0.05168051
INFO:root:At the start of the epoch: mem (CPU python)=38297.8046875MB; mem (CPU total)=38057.5234375MB
INFO:root:[  153] Training loss: 0.61605532, Validation loss: 0.60937919, Gradient norm: 0.05165909
INFO:root:At the start of the epoch: mem (CPU python)=38335.89453125MB; mem (CPU total)=38095.69921875MB
INFO:root:[  154] Training loss: 0.61579438, Validation loss: 0.60954729, Gradient norm: 0.05274901
INFO:root:At the start of the epoch: mem (CPU python)=38374.0078125MB; mem (CPU total)=38133.87890625MB
INFO:root:[  155] Training loss: 0.61580656, Validation loss: 0.60823026, Gradient norm: 0.05267569
INFO:root:At the start of the epoch: mem (CPU python)=38412.1015625MB; mem (CPU total)=38172.046875MB
INFO:root:[  156] Training loss: 0.61575830, Validation loss: 0.60884556, Gradient norm: 0.05362777
INFO:root:At the start of the epoch: mem (CPU python)=38450.12890625MB; mem (CPU total)=38211.27734375MB
INFO:root:[  157] Training loss: 0.61571278, Validation loss: 0.60876300, Gradient norm: 0.05208799
INFO:root:At the start of the epoch: mem (CPU python)=38488.23046875MB; mem (CPU total)=38249.37109375MB
INFO:root:[  158] Training loss: 0.61590054, Validation loss: 0.60873661, Gradient norm: 0.05162321
INFO:root:At the start of the epoch: mem (CPU python)=38526.328125MB; mem (CPU total)=38287.2890625MB
INFO:root:[  159] Training loss: 0.61564533, Validation loss: 0.60811086, Gradient norm: 0.05232911
INFO:root:At the start of the epoch: mem (CPU python)=38564.421875MB; mem (CPU total)=38324.68359375MB
INFO:root:[  160] Training loss: 0.61584413, Validation loss: 0.60888527, Gradient norm: 0.05297575
INFO:root:At the start of the epoch: mem (CPU python)=38602.515625MB; mem (CPU total)=38363.6953125MB
INFO:root:[  161] Training loss: 0.61567368, Validation loss: 0.60937253, Gradient norm: 0.05291829
INFO:root:At the start of the epoch: mem (CPU python)=38640.60546875MB; mem (CPU total)=38402.07421875MB
INFO:root:[  162] Training loss: 0.61571763, Validation loss: 0.60952086, Gradient norm: 0.05304003
INFO:root:At the start of the epoch: mem (CPU python)=38678.71484375MB; mem (CPU total)=38440.15625MB
INFO:root:[  163] Training loss: 0.61569492, Validation loss: 0.60903043, Gradient norm: 0.05246228
INFO:root:At the start of the epoch: mem (CPU python)=38716.8125MB; mem (CPU total)=38478.546875MB
INFO:root:[  164] Training loss: 0.61572375, Validation loss: 0.60920559, Gradient norm: 0.05128668
INFO:root:At the start of the epoch: mem (CPU python)=38754.89453125MB; mem (CPU total)=38516.703125MB
INFO:root:[  165] Training loss: 0.61578911, Validation loss: 0.60938916, Gradient norm: 0.05360888
INFO:root:At the start of the epoch: mem (CPU python)=38792.98828125MB; mem (CPU total)=38554.80078125MB
INFO:root:[  166] Training loss: 0.61557775, Validation loss: 0.60872987, Gradient norm: 0.05139782
INFO:root:At the start of the epoch: mem (CPU python)=38831.1484375MB; mem (CPU total)=38592.69921875MB
INFO:root:[  167] Training loss: 0.61556540, Validation loss: 0.60885601, Gradient norm: 0.05202335
INFO:root:At the start of the epoch: mem (CPU python)=38869.2421875MB; mem (CPU total)=38630.8203125MB
INFO:root:[  168] Training loss: 0.61549225, Validation loss: 0.60894702, Gradient norm: 0.05274172
INFO:root:At the start of the epoch: mem (CPU python)=38907.34765625MB; mem (CPU total)=38669.1796875MB
INFO:root:EP 168: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=38945.4375MB; mem (CPU total)=38707.07421875MB
INFO:root:Training the model took 15103.593s.
INFO:root:Emptying the cuda cache took 0.005s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84676
INFO:root:EnergyScoreTrain: 0.59607
INFO:root:CRPSTrain: 0.46079
INFO:root:Gaussian NLLTrain: 1.1785
INFO:root:CoverageTrain: 0.95412
INFO:root:IntervalWidthTrain: 3.26385
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86506
INFO:root:EnergyScoreValidation: 0.60887
INFO:root:CRPSValidation: 0.47172
INFO:root:Gaussian NLLValidation: 1.20225
INFO:root:CoverageValidation: 0.94839
INFO:root:IntervalWidthValidation: 3.26704
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86647
INFO:root:EnergyScoreTest: 0.60985
INFO:root:CRPSTest: 0.4725
INFO:root:Gaussian NLLTest: 1.20363
INFO:root:CoverageTest: 0.94802
INFO:root:IntervalWidthTest: 3.26629
INFO:root:After validation: mem (CPU python)=39026.6796875MB; mem (CPU total)=38741.01171875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=39026.6796875MB; mem (CPU total)=38741.0MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=39026.6796875MB; mem (CPU total)=38741.0MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=39026.6796875MB; mem (CPU total)=38741.0MB
INFO:root:[    1] Training loss: 0.72549425, Validation loss: 0.72024991, Gradient norm: 0.02372732
INFO:root:At the start of the epoch: mem (CPU python)=39026.6796875MB; mem (CPU total)=38778.234375MB
INFO:root:[    2] Training loss: 0.71966568, Validation loss: 0.71831593, Gradient norm: 0.00613493
INFO:root:At the start of the epoch: mem (CPU python)=39053.8984375MB; mem (CPU total)=38816.90234375MB
INFO:root:[    3] Training loss: 0.71729156, Validation loss: 0.71249235, Gradient norm: 0.00965100
INFO:root:At the start of the epoch: mem (CPU python)=39092.08203125MB; mem (CPU total)=38854.6796875MB
INFO:root:[    4] Training loss: 0.71004535, Validation loss: 0.70402524, Gradient norm: 0.01989778
INFO:root:At the start of the epoch: mem (CPU python)=39130.1640625MB; mem (CPU total)=38893.0625MB
INFO:root:[    5] Training loss: 0.70313296, Validation loss: 0.69688545, Gradient norm: 0.02399161
INFO:root:At the start of the epoch: mem (CPU python)=39168.26953125MB; mem (CPU total)=38931.7421875MB
INFO:root:[    6] Training loss: 0.69755671, Validation loss: 0.69091940, Gradient norm: 0.02652891
INFO:root:At the start of the epoch: mem (CPU python)=39206.359375MB; mem (CPU total)=38969.8046875MB
INFO:root:[    7] Training loss: 0.69251809, Validation loss: 0.68503141, Gradient norm: 0.02785936
INFO:root:At the start of the epoch: mem (CPU python)=39244.46484375MB; mem (CPU total)=39007.9375MB
INFO:root:[    8] Training loss: 0.68798256, Validation loss: 0.68043386, Gradient norm: 0.02605346
INFO:root:At the start of the epoch: mem (CPU python)=39282.55859375MB; mem (CPU total)=39046.06640625MB
INFO:root:[    9] Training loss: 0.68434511, Validation loss: 0.67714083, Gradient norm: 0.02786217
INFO:root:At the start of the epoch: mem (CPU python)=39320.63671875MB; mem (CPU total)=39084.63671875MB
INFO:root:[   10] Training loss: 0.68100539, Validation loss: 0.67340424, Gradient norm: 0.02748118
INFO:root:At the start of the epoch: mem (CPU python)=39358.66015625MB; mem (CPU total)=39122.28125MB
INFO:root:[   11] Training loss: 0.67836989, Validation loss: 0.67067912, Gradient norm: 0.02871881
INFO:root:At the start of the epoch: mem (CPU python)=39396.84765625MB; mem (CPU total)=39160.62890625MB
INFO:root:[   12] Training loss: 0.67600655, Validation loss: 0.66891825, Gradient norm: 0.03213783
INFO:root:At the start of the epoch: mem (CPU python)=39434.92578125MB; mem (CPU total)=39198.54296875MB
INFO:root:[   13] Training loss: 0.67399442, Validation loss: 0.66628975, Gradient norm: 0.03087796
INFO:root:At the start of the epoch: mem (CPU python)=39473.0234375MB; mem (CPU total)=39236.6796875MB
INFO:root:[   14] Training loss: 0.67206548, Validation loss: 0.66462287, Gradient norm: 0.03185224
INFO:root:At the start of the epoch: mem (CPU python)=39511.1328125MB; mem (CPU total)=39274.80859375MB
INFO:root:[   15] Training loss: 0.67021255, Validation loss: 0.66300681, Gradient norm: 0.03046605
INFO:root:At the start of the epoch: mem (CPU python)=39549.171875MB; mem (CPU total)=39313.1953125MB
INFO:root:[   16] Training loss: 0.66854353, Validation loss: 0.66030440, Gradient norm: 0.02980745
INFO:root:At the start of the epoch: mem (CPU python)=39587.26171875MB; mem (CPU total)=39351.30859375MB
INFO:root:[   17] Training loss: 0.66710405, Validation loss: 0.65939506, Gradient norm: 0.02989656
INFO:root:At the start of the epoch: mem (CPU python)=39625.3515625MB; mem (CPU total)=39389.62890625MB
INFO:root:[   18] Training loss: 0.66549695, Validation loss: 0.65754419, Gradient norm: 0.03244773
INFO:root:At the start of the epoch: mem (CPU python)=39663.45703125MB; mem (CPU total)=39427.5546875MB
INFO:root:[   19] Training loss: 0.66401433, Validation loss: 0.65580412, Gradient norm: 0.03480144
INFO:root:At the start of the epoch: mem (CPU python)=39701.5MB; mem (CPU total)=39465.609375MB
INFO:root:[   20] Training loss: 0.66254799, Validation loss: 0.65478632, Gradient norm: 0.03197355
INFO:root:At the start of the epoch: mem (CPU python)=39739.64453125MB; mem (CPU total)=39503.953125MB
INFO:root:[   21] Training loss: 0.66130134, Validation loss: 0.65276194, Gradient norm: 0.03279999
INFO:root:At the start of the epoch: mem (CPU python)=39777.7578125MB; mem (CPU total)=39542.12890625MB
INFO:root:[   22] Training loss: 0.65981898, Validation loss: 0.65073477, Gradient norm: 0.03102662
INFO:root:At the start of the epoch: mem (CPU python)=39815.83984375MB; mem (CPU total)=39580.234375MB
INFO:root:[   23] Training loss: 0.65862555, Validation loss: 0.64959521, Gradient norm: 0.03676544
INFO:root:At the start of the epoch: mem (CPU python)=39853.9296875MB; mem (CPU total)=39618.625MB
INFO:root:[   24] Training loss: 0.65742667, Validation loss: 0.64862496, Gradient norm: 0.03550759
INFO:root:At the start of the epoch: mem (CPU python)=39892.03125MB; mem (CPU total)=39656.66796875MB
INFO:root:[   25] Training loss: 0.65622956, Validation loss: 0.64718139, Gradient norm: 0.03562522
INFO:root:At the start of the epoch: mem (CPU python)=39930.171875MB; mem (CPU total)=39695.125MB
INFO:root:[   26] Training loss: 0.65502254, Validation loss: 0.64619273, Gradient norm: 0.03806041
INFO:root:At the start of the epoch: mem (CPU python)=39968.2734375MB; mem (CPU total)=39733.015625MB
INFO:root:[   27] Training loss: 0.65386497, Validation loss: 0.64441381, Gradient norm: 0.03750801
INFO:root:At the start of the epoch: mem (CPU python)=40006.36328125MB; mem (CPU total)=39770.9609375MB
INFO:root:[   28] Training loss: 0.65277303, Validation loss: 0.64375403, Gradient norm: 0.04036610
INFO:root:At the start of the epoch: mem (CPU python)=40044.46484375MB; mem (CPU total)=39809.12890625MB
INFO:root:[   29] Training loss: 0.65171226, Validation loss: 0.64235489, Gradient norm: 0.03848518
INFO:root:At the start of the epoch: mem (CPU python)=40082.5625MB; mem (CPU total)=39847.45703125MB
INFO:root:[   30] Training loss: 0.65090307, Validation loss: 0.64056192, Gradient norm: 0.04076250
INFO:root:At the start of the epoch: mem (CPU python)=40120.66015625MB; mem (CPU total)=39885.80859375MB
INFO:root:[   31] Training loss: 0.64961377, Validation loss: 0.64033537, Gradient norm: 0.04001073
INFO:root:At the start of the epoch: mem (CPU python)=40158.74609375MB; mem (CPU total)=39924.01171875MB
INFO:root:[   32] Training loss: 0.64884840, Validation loss: 0.63865357, Gradient norm: 0.04150744
INFO:root:At the start of the epoch: mem (CPU python)=40196.85546875MB; mem (CPU total)=39962.36328125MB
INFO:root:[   33] Training loss: 0.64811682, Validation loss: 0.63786243, Gradient norm: 0.04777729
INFO:root:At the start of the epoch: mem (CPU python)=40234.94921875MB; mem (CPU total)=40000.41015625MB
INFO:root:[   34] Training loss: 0.64708138, Validation loss: 0.63732937, Gradient norm: 0.04524483
INFO:root:At the start of the epoch: mem (CPU python)=40273.00390625MB; mem (CPU total)=40038.3046875MB
INFO:root:[   35] Training loss: 0.64612341, Validation loss: 0.63609677, Gradient norm: 0.04031458
INFO:root:At the start of the epoch: mem (CPU python)=40311.1328125MB; mem (CPU total)=40076.4453125MB
INFO:root:[   36] Training loss: 0.64548362, Validation loss: 0.63516400, Gradient norm: 0.04324995
INFO:root:At the start of the epoch: mem (CPU python)=40349.15234375MB; mem (CPU total)=40115.07421875MB
INFO:root:[   37] Training loss: 0.64467630, Validation loss: 0.63451090, Gradient norm: 0.04343584
INFO:root:At the start of the epoch: mem (CPU python)=40387.26953125MB; mem (CPU total)=40153.20703125MB
INFO:root:[   38] Training loss: 0.64407609, Validation loss: 0.63379852, Gradient norm: 0.05322217
INFO:root:At the start of the epoch: mem (CPU python)=40425.37109375MB; mem (CPU total)=40191.62109375MB
INFO:root:[   39] Training loss: 0.64330279, Validation loss: 0.63347067, Gradient norm: 0.04608873
INFO:root:At the start of the epoch: mem (CPU python)=40463.46484375MB; mem (CPU total)=40229.85546875MB
INFO:root:[   40] Training loss: 0.64244747, Validation loss: 0.63167447, Gradient norm: 0.04539928
INFO:root:At the start of the epoch: mem (CPU python)=40501.53515625MB; mem (CPU total)=40267.9609375MB
INFO:root:[   41] Training loss: 0.64178513, Validation loss: 0.63146215, Gradient norm: 0.04531892
INFO:root:At the start of the epoch: mem (CPU python)=40539.65625MB; mem (CPU total)=40306.13671875MB
INFO:root:[   42] Training loss: 0.64123199, Validation loss: 0.63134054, Gradient norm: 0.04994125
INFO:root:At the start of the epoch: mem (CPU python)=40577.75390625MB; mem (CPU total)=40344.23046875MB
INFO:root:[   43] Training loss: 0.64078812, Validation loss: 0.63038860, Gradient norm: 0.04739339
INFO:root:At the start of the epoch: mem (CPU python)=40615.7734375MB; mem (CPU total)=40382.359375MB
INFO:root:[   44] Training loss: 0.63998136, Validation loss: 0.63012757, Gradient norm: 0.04772073
INFO:root:At the start of the epoch: mem (CPU python)=40653.94921875MB; mem (CPU total)=40420.27734375MB
INFO:root:[   45] Training loss: 0.63928727, Validation loss: 0.62979311, Gradient norm: 0.05050957
INFO:root:At the start of the epoch: mem (CPU python)=40692.01953125MB; mem (CPU total)=40458.421875MB
INFO:root:[   46] Training loss: 0.63893303, Validation loss: 0.62817382, Gradient norm: 0.05341720
INFO:root:At the start of the epoch: mem (CPU python)=40730.17578125MB; mem (CPU total)=40496.83984375MB
INFO:root:[   47] Training loss: 0.63837258, Validation loss: 0.62740525, Gradient norm: 0.05076436
INFO:root:At the start of the epoch: mem (CPU python)=40768.265625MB; mem (CPU total)=40535.16015625MB
INFO:root:[   48] Training loss: 0.63777865, Validation loss: 0.62744594, Gradient norm: 0.05687129
INFO:root:At the start of the epoch: mem (CPU python)=40806.3828125MB; mem (CPU total)=40574.421875MB
INFO:root:[   49] Training loss: 0.63726685, Validation loss: 0.62736877, Gradient norm: 0.04738287
INFO:root:At the start of the epoch: mem (CPU python)=40844.4765625MB; mem (CPU total)=40611.79296875MB
INFO:root:[   50] Training loss: 0.63679908, Validation loss: 0.62655847, Gradient norm: 0.05099441
INFO:root:At the start of the epoch: mem (CPU python)=40882.5703125MB; mem (CPU total)=40649.90234375MB
INFO:root:[   51] Training loss: 0.63640479, Validation loss: 0.62654673, Gradient norm: 0.05268315
INFO:root:At the start of the epoch: mem (CPU python)=40920.66796875MB; mem (CPU total)=40688.3125MB
INFO:root:[   52] Training loss: 0.63585182, Validation loss: 0.62559637, Gradient norm: 0.05713310
INFO:root:At the start of the epoch: mem (CPU python)=40958.75390625MB; mem (CPU total)=40726.2109375MB
INFO:root:[   53] Training loss: 0.63527901, Validation loss: 0.62521945, Gradient norm: 0.05155180
INFO:root:At the start of the epoch: mem (CPU python)=40996.85546875MB; mem (CPU total)=40764.53125MB
INFO:root:[   54] Training loss: 0.63499459, Validation loss: 0.62478224, Gradient norm: 0.05455049
INFO:root:At the start of the epoch: mem (CPU python)=41034.9453125MB; mem (CPU total)=40802.90625MB
INFO:root:[   55] Training loss: 0.63464123, Validation loss: 0.62454536, Gradient norm: 0.05207549
INFO:root:At the start of the epoch: mem (CPU python)=41073.05078125MB; mem (CPU total)=40841.0859375MB
INFO:root:[   56] Training loss: 0.63409241, Validation loss: 0.62499746, Gradient norm: 0.05353008
INFO:root:At the start of the epoch: mem (CPU python)=41111.14453125MB; mem (CPU total)=40879.30078125MB
INFO:root:[   57] Training loss: 0.63382835, Validation loss: 0.62402700, Gradient norm: 0.05484124
INFO:root:At the start of the epoch: mem (CPU python)=41149.1875MB; mem (CPU total)=40917.3046875MB
INFO:root:[   58] Training loss: 0.63330627, Validation loss: 0.62448828, Gradient norm: 0.05712533
INFO:root:At the start of the epoch: mem (CPU python)=41187.28125MB; mem (CPU total)=40955.93359375MB
INFO:root:[   59] Training loss: 0.63295601, Validation loss: 0.62236927, Gradient norm: 0.06293405
INFO:root:At the start of the epoch: mem (CPU python)=41225.328125MB; mem (CPU total)=40993.5859375MB
INFO:root:[   60] Training loss: 0.63251585, Validation loss: 0.62292791, Gradient norm: 0.05286425
INFO:root:At the start of the epoch: mem (CPU python)=41263.46875MB; mem (CPU total)=41032.65234375MB
INFO:root:[   61] Training loss: 0.63239401, Validation loss: 0.62284647, Gradient norm: 0.06864953
INFO:root:At the start of the epoch: mem (CPU python)=41301.55859375MB; mem (CPU total)=41070.7890625MB
INFO:root:[   62] Training loss: 0.63192359, Validation loss: 0.62227734, Gradient norm: 0.06040874
INFO:root:At the start of the epoch: mem (CPU python)=41339.66015625MB; mem (CPU total)=41107.9765625MB
INFO:root:[   63] Training loss: 0.63180626, Validation loss: 0.62177153, Gradient norm: 0.06583520
INFO:root:At the start of the epoch: mem (CPU python)=41377.7578125MB; mem (CPU total)=41146.3046875MB
INFO:root:[   64] Training loss: 0.63112603, Validation loss: 0.62084607, Gradient norm: 0.05195269
INFO:root:At the start of the epoch: mem (CPU python)=41415.85546875MB; mem (CPU total)=41184.4375MB
INFO:root:[   65] Training loss: 0.63093511, Validation loss: 0.62019712, Gradient norm: 0.05354077
INFO:root:At the start of the epoch: mem (CPU python)=41453.94921875MB; mem (CPU total)=41222.56640625MB
INFO:root:[   66] Training loss: 0.63046422, Validation loss: 0.62038519, Gradient norm: 0.05604364
INFO:root:At the start of the epoch: mem (CPU python)=41492.1015625MB; mem (CPU total)=41261.44921875MB
INFO:root:[   67] Training loss: 0.63044565, Validation loss: 0.62129998, Gradient norm: 0.06350302
INFO:root:At the start of the epoch: mem (CPU python)=41530.1953125MB; mem (CPU total)=41299.83984375MB
INFO:root:[   68] Training loss: 0.63002745, Validation loss: 0.62056815, Gradient norm: 0.05858932
INFO:root:At the start of the epoch: mem (CPU python)=41568.28125MB; mem (CPU total)=41337.84375MB
INFO:root:[   69] Training loss: 0.62953982, Validation loss: 0.62012846, Gradient norm: 0.05049414
INFO:root:At the start of the epoch: mem (CPU python)=41606.3828125MB; mem (CPU total)=41375.5859375MB
INFO:root:[   70] Training loss: 0.62942232, Validation loss: 0.61919814, Gradient norm: 0.05699924
INFO:root:At the start of the epoch: mem (CPU python)=41644.4765625MB; mem (CPU total)=41413.69140625MB
INFO:root:[   71] Training loss: 0.62909418, Validation loss: 0.61891884, Gradient norm: 0.06487178
INFO:root:At the start of the epoch: mem (CPU python)=41682.57421875MB; mem (CPU total)=41451.90234375MB
INFO:root:[   72] Training loss: 0.62875670, Validation loss: 0.61888434, Gradient norm: 0.05405625
INFO:root:At the start of the epoch: mem (CPU python)=41720.66796875MB; mem (CPU total)=41490.4765625MB
INFO:root:[   73] Training loss: 0.62864093, Validation loss: 0.61831295, Gradient norm: 0.06215013
INFO:root:At the start of the epoch: mem (CPU python)=41758.72265625MB; mem (CPU total)=41528.265625MB
INFO:root:[   74] Training loss: 0.62811860, Validation loss: 0.61807257, Gradient norm: 0.05263160
INFO:root:At the start of the epoch: mem (CPU python)=41796.859375MB; mem (CPU total)=41565.54296875MB
INFO:root:[   75] Training loss: 0.62798177, Validation loss: 0.61766230, Gradient norm: 0.05918526
INFO:root:At the start of the epoch: mem (CPU python)=41834.94140625MB; mem (CPU total)=41603.6796875MB
INFO:root:[   76] Training loss: 0.62747291, Validation loss: 0.61763648, Gradient norm: 0.06131982
INFO:root:At the start of the epoch: mem (CPU python)=41873.04296875MB; mem (CPU total)=41641.76953125MB
INFO:root:[   77] Training loss: 0.62748376, Validation loss: 0.61843378, Gradient norm: 0.05959932
INFO:root:At the start of the epoch: mem (CPU python)=41911.14453125MB; mem (CPU total)=41680.16796875MB
INFO:root:[   78] Training loss: 0.62713055, Validation loss: 0.61698353, Gradient norm: 0.06091691
INFO:root:At the start of the epoch: mem (CPU python)=41949.14453125MB; mem (CPU total)=41718.05859375MB
INFO:root:[   79] Training loss: 0.62701074, Validation loss: 0.61707966, Gradient norm: 0.05789546
INFO:root:At the start of the epoch: mem (CPU python)=41987.28125MB; mem (CPU total)=41757.140625MB
INFO:root:[   80] Training loss: 0.62676323, Validation loss: 0.61695052, Gradient norm: 0.06338820
INFO:root:At the start of the epoch: mem (CPU python)=42025.3515625MB; mem (CPU total)=41794.80078125MB
INFO:root:[   81] Training loss: 0.62628836, Validation loss: 0.61684502, Gradient norm: 0.06087575
INFO:root:At the start of the epoch: mem (CPU python)=42063.47265625MB; mem (CPU total)=41832.97265625MB
INFO:root:[   82] Training loss: 0.62630363, Validation loss: 0.61712230, Gradient norm: 0.06519032
INFO:root:At the start of the epoch: mem (CPU python)=42101.55859375MB; mem (CPU total)=41872.109375MB
INFO:root:[   83] Training loss: 0.62603775, Validation loss: 0.61713167, Gradient norm: 0.06116649
INFO:root:At the start of the epoch: mem (CPU python)=42139.6640625MB; mem (CPU total)=41909.96875MB
INFO:root:[   84] Training loss: 0.62566098, Validation loss: 0.61573863, Gradient norm: 0.05812663
INFO:root:At the start of the epoch: mem (CPU python)=42177.765625MB; mem (CPU total)=41947.359375MB
INFO:root:[   85] Training loss: 0.62536469, Validation loss: 0.61601046, Gradient norm: 0.05708201
INFO:root:At the start of the epoch: mem (CPU python)=42215.76953125MB; mem (CPU total)=41986.27734375MB
INFO:root:[   86] Training loss: 0.62522878, Validation loss: 0.61628105, Gradient norm: 0.05494557
INFO:root:At the start of the epoch: mem (CPU python)=42253.953125MB; mem (CPU total)=42024.390625MB
INFO:root:[   87] Training loss: 0.62503471, Validation loss: 0.61588315, Gradient norm: 0.06357809
INFO:root:At the start of the epoch: mem (CPU python)=42292.03125MB; mem (CPU total)=42062.46484375MB
INFO:root:[   88] Training loss: 0.62459015, Validation loss: 0.61492752, Gradient norm: 0.06190578
INFO:root:At the start of the epoch: mem (CPU python)=42330.203125MB; mem (CPU total)=42100.1953125MB
INFO:root:[   89] Training loss: 0.62457734, Validation loss: 0.61567506, Gradient norm: 0.06215503
INFO:root:At the start of the epoch: mem (CPU python)=42368.29296875MB; mem (CPU total)=42138.70703125MB
INFO:root:[   90] Training loss: 0.62438359, Validation loss: 0.61518400, Gradient norm: 0.06478898
INFO:root:At the start of the epoch: mem (CPU python)=42406.265625MB; mem (CPU total)=42176.8828125MB
INFO:root:[   91] Training loss: 0.62402817, Validation loss: 0.61447299, Gradient norm: 0.05772507
INFO:root:At the start of the epoch: mem (CPU python)=42444.48828125MB; mem (CPU total)=42214.35546875MB
INFO:root:[   92] Training loss: 0.62387787, Validation loss: 0.61493922, Gradient norm: 0.06099224
INFO:root:At the start of the epoch: mem (CPU python)=42482.5625MB; mem (CPU total)=42253.01953125MB
INFO:root:[   93] Training loss: 0.62359942, Validation loss: 0.61535290, Gradient norm: 0.06097980
INFO:root:At the start of the epoch: mem (CPU python)=42520.67578125MB; mem (CPU total)=42291.1953125MB
INFO:root:[   94] Training loss: 0.62359814, Validation loss: 0.61510917, Gradient norm: 0.06635519
INFO:root:At the start of the epoch: mem (CPU python)=42558.76171875MB; mem (CPU total)=42328.58203125MB
INFO:root:[   95] Training loss: 0.62318010, Validation loss: 0.61450204, Gradient norm: 0.06203130
INFO:root:At the start of the epoch: mem (CPU python)=42596.8671875MB; mem (CPU total)=42366.8515625MB
INFO:root:[   96] Training loss: 0.62319506, Validation loss: 0.61467653, Gradient norm: 0.06575546
INFO:root:At the start of the epoch: mem (CPU python)=42634.9609375MB; mem (CPU total)=42404.98046875MB
INFO:root:[   97] Training loss: 0.62285734, Validation loss: 0.61417945, Gradient norm: 0.06251331
INFO:root:At the start of the epoch: mem (CPU python)=42673.03125MB; mem (CPU total)=42442.875MB
INFO:root:[   98] Training loss: 0.62264654, Validation loss: 0.61414999, Gradient norm: 0.06313417
INFO:root:At the start of the epoch: mem (CPU python)=42711.15625MB; mem (CPU total)=42481.015625MB
INFO:root:[   99] Training loss: 0.62249537, Validation loss: 0.61337287, Gradient norm: 0.05776570
INFO:root:At the start of the epoch: mem (CPU python)=42749.1875MB; mem (CPU total)=42519.21875MB
INFO:root:[  100] Training loss: 0.62226430, Validation loss: 0.61373681, Gradient norm: 0.06154998
INFO:root:At the start of the epoch: mem (CPU python)=42787.28125MB; mem (CPU total)=42558.31640625MB
INFO:root:[  101] Training loss: 0.62242352, Validation loss: 0.61358693, Gradient norm: 0.07194415
INFO:root:At the start of the epoch: mem (CPU python)=42825.3828125MB; mem (CPU total)=42596.45703125MB
INFO:root:[  102] Training loss: 0.62185906, Validation loss: 0.61356448, Gradient norm: 0.06050251
INFO:root:At the start of the epoch: mem (CPU python)=42863.48046875MB; mem (CPU total)=42634.58984375MB
INFO:root:[  103] Training loss: 0.62175045, Validation loss: 0.61310597, Gradient norm: 0.06484112
INFO:root:At the start of the epoch: mem (CPU python)=42901.57421875MB; mem (CPU total)=42672.5234375MB
INFO:root:[  104] Training loss: 0.62154020, Validation loss: 0.61323751, Gradient norm: 0.06550534
INFO:root:At the start of the epoch: mem (CPU python)=42939.65234375MB; mem (CPU total)=42711.16796875MB
INFO:root:[  105] Training loss: 0.62138978, Validation loss: 0.61275472, Gradient norm: 0.06595333
INFO:root:At the start of the epoch: mem (CPU python)=42977.76953125MB; mem (CPU total)=42748.5546875MB
INFO:root:[  106] Training loss: 0.62145576, Validation loss: 0.61259984, Gradient norm: 0.07443829
INFO:root:At the start of the epoch: mem (CPU python)=43015.86328125MB; mem (CPU total)=42786.72265625MB
INFO:root:[  107] Training loss: 0.62111080, Validation loss: 0.61280289, Gradient norm: 0.06070229
INFO:root:At the start of the epoch: mem (CPU python)=43053.94921875MB; mem (CPU total)=42825.34375MB
INFO:root:[  108] Training loss: 0.62103766, Validation loss: 0.61252763, Gradient norm: 0.06129500
INFO:root:At the start of the epoch: mem (CPU python)=43092.0546875MB; mem (CPU total)=42862.99609375MB
INFO:root:[  109] Training loss: 0.62092471, Validation loss: 0.61260431, Gradient norm: 0.06540724
INFO:root:At the start of the epoch: mem (CPU python)=43130.1640625MB; mem (CPU total)=42901.84765625MB
INFO:root:[  110] Training loss: 0.62061859, Validation loss: 0.61281018, Gradient norm: 0.05646235
INFO:root:At the start of the epoch: mem (CPU python)=43168.2890625MB; mem (CPU total)=42940.23046875MB
INFO:root:[  111] Training loss: 0.62024031, Validation loss: 0.61390594, Gradient norm: 0.06675826
INFO:root:At the start of the epoch: mem (CPU python)=43206.390625MB; mem (CPU total)=42978.0859375MB
INFO:root:[  112] Training loss: 0.62024733, Validation loss: 0.61206273, Gradient norm: 0.05926515
INFO:root:At the start of the epoch: mem (CPU python)=43244.47265625MB; mem (CPU total)=43015.48828125MB
INFO:root:[  113] Training loss: 0.62003597, Validation loss: 0.61280025, Gradient norm: 0.07464630
INFO:root:At the start of the epoch: mem (CPU python)=43282.58203125MB; mem (CPU total)=43054.38671875MB
INFO:root:[  114] Training loss: 0.62001227, Validation loss: 0.61236879, Gradient norm: 0.06415991
INFO:root:At the start of the epoch: mem (CPU python)=43320.5625MB; mem (CPU total)=43092.7734375MB
INFO:root:[  115] Training loss: 0.61993054, Validation loss: 0.61117024, Gradient norm: 0.06349569
INFO:root:At the start of the epoch: mem (CPU python)=43358.7734375MB; mem (CPU total)=43130.16796875MB
INFO:root:[  116] Training loss: 0.61954274, Validation loss: 0.61257517, Gradient norm: 0.06036243
INFO:root:At the start of the epoch: mem (CPU python)=43396.85546875MB; mem (CPU total)=43168.80078125MB
INFO:root:[  117] Training loss: 0.61967882, Validation loss: 0.61124351, Gradient norm: 0.06568728
INFO:root:At the start of the epoch: mem (CPU python)=43434.95703125MB; mem (CPU total)=43207.1796875MB
INFO:root:[  118] Training loss: 0.61933878, Validation loss: 0.61291109, Gradient norm: 0.06315520
INFO:root:At the start of the epoch: mem (CPU python)=43473.0625MB; mem (CPU total)=43244.9609375MB
INFO:root:[  119] Training loss: 0.61918800, Validation loss: 0.61183977, Gradient norm: 0.07208503
INFO:root:At the start of the epoch: mem (CPU python)=43511.15625MB; mem (CPU total)=43283.0390625MB
INFO:root:[  120] Training loss: 0.61921199, Validation loss: 0.61079375, Gradient norm: 0.06246018
INFO:root:At the start of the epoch: mem (CPU python)=43549.1953125MB; mem (CPU total)=43320.72265625MB
INFO:root:[  121] Training loss: 0.61885499, Validation loss: 0.61096280, Gradient norm: 0.06795761
INFO:root:At the start of the epoch: mem (CPU python)=43587.28515625MB; mem (CPU total)=43359.88671875MB
INFO:root:[  122] Training loss: 0.61861216, Validation loss: 0.61145165, Gradient norm: 0.06172599
INFO:root:At the start of the epoch: mem (CPU python)=43625.390625MB; mem (CPU total)=43397.8203125MB
INFO:root:[  123] Training loss: 0.61845350, Validation loss: 0.61069512, Gradient norm: 0.06754961
INFO:root:At the start of the epoch: mem (CPU python)=43663.484375MB; mem (CPU total)=43435.4375MB
INFO:root:[  124] Training loss: 0.61862632, Validation loss: 0.61030710, Gradient norm: 0.07026629
INFO:root:At the start of the epoch: mem (CPU python)=43701.59765625MB; mem (CPU total)=43473.39453125MB
INFO:root:[  125] Training loss: 0.61814185, Validation loss: 0.61081470, Gradient norm: 0.06584131
INFO:root:At the start of the epoch: mem (CPU python)=43739.6640625MB; mem (CPU total)=43512.57421875MB
INFO:root:[  126] Training loss: 0.61819860, Validation loss: 0.61068155, Gradient norm: 0.06123049
INFO:root:At the start of the epoch: mem (CPU python)=43777.75MB; mem (CPU total)=43550.71875MB
INFO:root:[  127] Training loss: 0.61807785, Validation loss: 0.61099083, Gradient norm: 0.07081204
INFO:root:At the start of the epoch: mem (CPU python)=43815.859375MB; mem (CPU total)=43588.47265625MB
INFO:root:[  128] Training loss: 0.61808773, Validation loss: 0.61071256, Gradient norm: 0.07233892
INFO:root:At the start of the epoch: mem (CPU python)=43853.94140625MB; mem (CPU total)=43626.88671875MB
INFO:root:[  129] Training loss: 0.61789246, Validation loss: 0.60977307, Gradient norm: 0.06227568
INFO:root:At the start of the epoch: mem (CPU python)=43891.9375MB; mem (CPU total)=43664.5078125MB
INFO:root:[  130] Training loss: 0.61756842, Validation loss: 0.61073001, Gradient norm: 0.06568693
INFO:root:At the start of the epoch: mem (CPU python)=43930.20703125MB; mem (CPU total)=43703.14453125MB
INFO:root:[  131] Training loss: 0.61754234, Validation loss: 0.61013106, Gradient norm: 0.06330806
INFO:root:At the start of the epoch: mem (CPU python)=43968.28515625MB; mem (CPU total)=43741.95703125MB
INFO:root:[  132] Training loss: 0.61736510, Validation loss: 0.61038207, Gradient norm: 0.06159170
INFO:root:At the start of the epoch: mem (CPU python)=44006.39453125MB; mem (CPU total)=43780.01953125MB
INFO:root:[  133] Training loss: 0.61741829, Validation loss: 0.61067297, Gradient norm: 0.06656162
INFO:root:At the start of the epoch: mem (CPU python)=44044.4921875MB; mem (CPU total)=43817.87109375MB
INFO:root:[  134] Training loss: 0.61721792, Validation loss: 0.61003385, Gradient norm: 0.06477267
INFO:root:At the start of the epoch: mem (CPU python)=44082.546875MB; mem (CPU total)=43856.015625MB
INFO:root:[  135] Training loss: 0.61702945, Validation loss: 0.61044142, Gradient norm: 0.07030085
INFO:root:At the start of the epoch: mem (CPU python)=44120.68359375MB; mem (CPU total)=43893.64453125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  136] Training loss: 0.61677446, Validation loss: 0.60924227, Gradient norm: 0.06209161
INFO:root:At the start of the epoch: mem (CPU python)=44158.77734375MB; mem (CPU total)=43931.03515625MB
INFO:root:[  137] Training loss: 0.61599478, Validation loss: 0.61033293, Gradient norm: 0.06115025
INFO:root:At the start of the epoch: mem (CPU python)=44196.8828125MB; mem (CPU total)=43969.58984375MB
INFO:root:[  138] Training loss: 0.61558468, Validation loss: 0.60950426, Gradient norm: 0.05641422
INFO:root:At the start of the epoch: mem (CPU python)=44234.96875MB; mem (CPU total)=44007.765625MB
INFO:root:[  139] Training loss: 0.61532917, Validation loss: 0.60926625, Gradient norm: 0.05719220
INFO:root:At the start of the epoch: mem (CPU python)=44273.06640625MB; mem (CPU total)=44045.4921875MB
INFO:root:[  140] Training loss: 0.61535746, Validation loss: 0.60936647, Gradient norm: 0.05646965
INFO:root:At the start of the epoch: mem (CPU python)=44311.109375MB; mem (CPU total)=44084.39453125MB
INFO:root:[  141] Training loss: 0.61545288, Validation loss: 0.60901855, Gradient norm: 0.05662990
INFO:root:At the start of the epoch: mem (CPU python)=44349.19921875MB; mem (CPU total)=44122.09765625MB
INFO:root:[  142] Training loss: 0.61550096, Validation loss: 0.60912668, Gradient norm: 0.05799630
INFO:root:At the start of the epoch: mem (CPU python)=44387.26953125MB; mem (CPU total)=44161.13671875MB
INFO:root:[  143] Training loss: 0.61516624, Validation loss: 0.60907722, Gradient norm: 0.06018779
INFO:root:At the start of the epoch: mem (CPU python)=44425.39453125MB; mem (CPU total)=44199.05859375MB
INFO:root:[  144] Training loss: 0.61529719, Validation loss: 0.61010044, Gradient norm: 0.05583383
INFO:root:At the start of the epoch: mem (CPU python)=44463.47265625MB; mem (CPU total)=44237.16015625MB
INFO:root:[  145] Training loss: 0.61513815, Validation loss: 0.60820216, Gradient norm: 0.05937138
INFO:root:At the start of the epoch: mem (CPU python)=44501.5546875MB; mem (CPU total)=44275.140625MB
INFO:root:[  146] Training loss: 0.61525160, Validation loss: 0.60877444, Gradient norm: 0.05764822
INFO:root:At the start of the epoch: mem (CPU python)=44539.68359375MB; mem (CPU total)=44314.0546875MB
INFO:root:[  147] Training loss: 0.61515613, Validation loss: 0.60845303, Gradient norm: 0.05958884
INFO:root:At the start of the epoch: mem (CPU python)=44577.77734375MB; mem (CPU total)=44351.98828125MB
INFO:root:[  148] Training loss: 0.61493389, Validation loss: 0.60863179, Gradient norm: 0.06012910
INFO:root:At the start of the epoch: mem (CPU python)=44615.87109375MB; mem (CPU total)=44389.890625MB
INFO:root:[  149] Training loss: 0.61466828, Validation loss: 0.60884923, Gradient norm: 0.05799885
INFO:root:At the start of the epoch: mem (CPU python)=44653.96875MB; mem (CPU total)=44430.9453125MB
INFO:root:[  150] Training loss: 0.61467262, Validation loss: 0.60824215, Gradient norm: 0.05771080
INFO:root:At the start of the epoch: mem (CPU python)=44692.06640625MB; mem (CPU total)=44469.078125MB
INFO:root:[  151] Training loss: 0.61476920, Validation loss: 0.60880599, Gradient norm: 0.06297180
INFO:root:At the start of the epoch: mem (CPU python)=44730.21484375MB; mem (CPU total)=44507.1953125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  152] Training loss: 0.61471905, Validation loss: 0.60873701, Gradient norm: 0.06511991
INFO:root:At the start of the epoch: mem (CPU python)=44768.3125MB; mem (CPU total)=44545.08984375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  153] Training loss: 0.61415194, Validation loss: 0.60846929, Gradient norm: 0.05672970
INFO:root:At the start of the epoch: mem (CPU python)=44806.3828125MB; mem (CPU total)=44583.234375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  154] Training loss: 0.61388470, Validation loss: 0.60857911, Gradient norm: 0.05426491
INFO:root:At the start of the epoch: mem (CPU python)=44844.50390625MB; mem (CPU total)=44621.12890625MB
INFO:root:[  155] Training loss: 0.61361394, Validation loss: 0.60789555, Gradient norm: 0.05193819
INFO:root:At the start of the epoch: mem (CPU python)=44882.59375MB; mem (CPU total)=44658.796875MB
INFO:root:[  156] Training loss: 0.61358210, Validation loss: 0.60814136, Gradient norm: 0.05325791
INFO:root:At the start of the epoch: mem (CPU python)=44920.5625MB; mem (CPU total)=44696.921875MB
INFO:root:[  157] Training loss: 0.61368396, Validation loss: 0.60838731, Gradient norm: 0.05098604
INFO:root:At the start of the epoch: mem (CPU python)=44958.78515625MB; mem (CPU total)=44735.09765625MB
INFO:root:[  158] Training loss: 0.61363103, Validation loss: 0.60737878, Gradient norm: 0.05077076
INFO:root:At the start of the epoch: mem (CPU python)=44996.875MB; mem (CPU total)=44772.8046875MB
INFO:root:[  159] Training loss: 0.61352337, Validation loss: 0.60813534, Gradient norm: 0.05114091
INFO:root:At the start of the epoch: mem (CPU python)=45034.98046875MB; mem (CPU total)=44810.31640625MB
INFO:root:[  160] Training loss: 0.61368726, Validation loss: 0.60843552, Gradient norm: 0.05291220
INFO:root:At the start of the epoch: mem (CPU python)=45073.06640625MB; mem (CPU total)=44848.44921875MB
INFO:root:[  161] Training loss: 0.61373600, Validation loss: 0.60803040, Gradient norm: 0.05194333
INFO:root:At the start of the epoch: mem (CPU python)=45111.0859375MB; mem (CPU total)=44887.16796875MB
INFO:root:[  162] Training loss: 0.61352210, Validation loss: 0.60765146, Gradient norm: 0.05304070
INFO:root:At the start of the epoch: mem (CPU python)=45149.19921875MB; mem (CPU total)=44925.78515625MB
INFO:root:[  163] Training loss: 0.61342051, Validation loss: 0.60870153, Gradient norm: 0.05304857
INFO:root:At the start of the epoch: mem (CPU python)=45187.3046875MB; mem (CPU total)=44963.6875MB
INFO:root:[  164] Training loss: 0.61326772, Validation loss: 0.60809385, Gradient norm: 0.05122195
INFO:root:At the start of the epoch: mem (CPU python)=45225.37109375MB; mem (CPU total)=45001.859375MB
INFO:root:[  165] Training loss: 0.61348117, Validation loss: 0.60784336, Gradient norm: 0.05250706
INFO:root:At the start of the epoch: mem (CPU python)=45263.4921875MB; mem (CPU total)=45039.796875MB
INFO:root:[  166] Training loss: 0.61342024, Validation loss: 0.60780541, Gradient norm: 0.05321149
INFO:root:At the start of the epoch: mem (CPU python)=45301.59375MB; mem (CPU total)=45078.18359375MB
INFO:root:[  167] Training loss: 0.61335264, Validation loss: 0.60847912, Gradient norm: 0.05293595
INFO:root:At the start of the epoch: mem (CPU python)=45339.6328125MB; mem (CPU total)=45116.3515625MB
INFO:root:EP 167: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=45377.78125MB; mem (CPU total)=45154.80859375MB
INFO:root:Training the model took 16182.608s.
INFO:root:Emptying the cuda cache took 0.011s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84304
INFO:root:EnergyScoreTrain: 0.59349
INFO:root:CRPSTrain: 0.46097
INFO:root:Gaussian NLLTrain: 1.19043
INFO:root:CoverageTrain: 0.95021
INFO:root:IntervalWidthTrain: 3.26877
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86399
INFO:root:EnergyScoreValidation: 0.60813
INFO:root:CRPSValidation: 0.4734
INFO:root:Gaussian NLLValidation: 1.21777
INFO:root:CoverageValidation: 0.94359
INFO:root:IntervalWidthValidation: 3.27023
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86518
INFO:root:EnergyScoreTest: 0.60897
INFO:root:CRPSTest: 0.47412
INFO:root:Gaussian NLLTest: 1.21891
INFO:root:CoverageTest: 0.94336
INFO:root:IntervalWidthTest: 3.27105
INFO:root:After validation: mem (CPU python)=45415.59765625MB; mem (CPU total)=45193.828125MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=45415.59765625MB; mem (CPU total)=45193.84375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=45415.59765625MB; mem (CPU total)=45194.3359375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=45415.59765625MB; mem (CPU total)=45194.10546875MB
INFO:root:[    1] Training loss: 0.72533388, Validation loss: 0.72044655, Gradient norm: 0.02099278
INFO:root:At the start of the epoch: mem (CPU python)=45457.30859375MB; mem (CPU total)=45232.375MB
INFO:root:[    2] Training loss: 0.71973666, Validation loss: 0.71859181, Gradient norm: 0.00558944
INFO:root:At the start of the epoch: mem (CPU python)=45496.0859375MB; mem (CPU total)=45271.5859375MB
INFO:root:[    3] Training loss: 0.71852657, Validation loss: 0.71734578, Gradient norm: 0.00748569
INFO:root:At the start of the epoch: mem (CPU python)=45534.2109375MB; mem (CPU total)=45310.00390625MB
INFO:root:[    4] Training loss: 0.71475161, Validation loss: 0.70866010, Gradient norm: 0.01532379
INFO:root:At the start of the epoch: mem (CPU python)=45572.30078125MB; mem (CPU total)=45349.30859375MB
INFO:root:[    5] Training loss: 0.70783367, Validation loss: 0.70239279, Gradient norm: 0.02567108
INFO:root:At the start of the epoch: mem (CPU python)=45610.29296875MB; mem (CPU total)=45387.73046875MB
INFO:root:[    6] Training loss: 0.70208968, Validation loss: 0.69669685, Gradient norm: 0.02564477
INFO:root:At the start of the epoch: mem (CPU python)=45648.4765625MB; mem (CPU total)=45426.1875MB
INFO:root:[    7] Training loss: 0.69703249, Validation loss: 0.69140818, Gradient norm: 0.02895487
INFO:root:At the start of the epoch: mem (CPU python)=45686.56640625MB; mem (CPU total)=45464.1171875MB
INFO:root:[    8] Training loss: 0.69271555, Validation loss: 0.68536065, Gradient norm: 0.02766220
INFO:root:At the start of the epoch: mem (CPU python)=45724.65234375MB; mem (CPU total)=45502.27734375MB
INFO:root:[    9] Training loss: 0.68872867, Validation loss: 0.68175517, Gradient norm: 0.02925262
INFO:root:At the start of the epoch: mem (CPU python)=45762.7578125MB; mem (CPU total)=45543.9375MB
INFO:root:[   10] Training loss: 0.68529758, Validation loss: 0.67805173, Gradient norm: 0.03026774
INFO:root:At the start of the epoch: mem (CPU python)=45800.78515625MB; mem (CPU total)=45578.63671875MB
INFO:root:[   11] Training loss: 0.68222115, Validation loss: 0.67492400, Gradient norm: 0.02885445
INFO:root:At the start of the epoch: mem (CPU python)=45838.94140625MB; mem (CPU total)=45617.06640625MB
INFO:root:[   12] Training loss: 0.67933484, Validation loss: 0.67226005, Gradient norm: 0.03107484
INFO:root:At the start of the epoch: mem (CPU python)=45877.0546875MB; mem (CPU total)=45655.25MB
INFO:root:[   13] Training loss: 0.67649989, Validation loss: 0.66851954, Gradient norm: 0.02960520
INFO:root:At the start of the epoch: mem (CPU python)=45915.1015625MB; mem (CPU total)=45692.875MB
INFO:root:[   14] Training loss: 0.67393397, Validation loss: 0.66518824, Gradient norm: 0.03056346
INFO:root:At the start of the epoch: mem (CPU python)=45953.2421875MB; mem (CPU total)=45731.26953125MB
INFO:root:[   15] Training loss: 0.67151264, Validation loss: 0.66287586, Gradient norm: 0.03272161
INFO:root:At the start of the epoch: mem (CPU python)=45991.3359375MB; mem (CPU total)=45769.125MB
INFO:root:[   16] Training loss: 0.66882641, Validation loss: 0.65968996, Gradient norm: 0.03022625
INFO:root:At the start of the epoch: mem (CPU python)=46029.34765625MB; mem (CPU total)=45807.03125MB
INFO:root:[   17] Training loss: 0.66650436, Validation loss: 0.65650090, Gradient norm: 0.03133460
INFO:root:At the start of the epoch: mem (CPU python)=46067.52734375MB; mem (CPU total)=45844.58984375MB
INFO:root:[   18] Training loss: 0.66426527, Validation loss: 0.65447914, Gradient norm: 0.03479402
INFO:root:At the start of the epoch: mem (CPU python)=46105.59765625MB; mem (CPU total)=45882.97265625MB
INFO:root:[   19] Training loss: 0.66221124, Validation loss: 0.65267591, Gradient norm: 0.03486902
INFO:root:At the start of the epoch: mem (CPU python)=46143.70703125MB; mem (CPU total)=45921.109375MB
INFO:root:[   20] Training loss: 0.66048526, Validation loss: 0.65048851, Gradient norm: 0.03353598
INFO:root:At the start of the epoch: mem (CPU python)=46181.81640625MB; mem (CPU total)=45958.96484375MB
INFO:root:[   21] Training loss: 0.65836457, Validation loss: 0.64831538, Gradient norm: 0.03346411
INFO:root:At the start of the epoch: mem (CPU python)=46219.83203125MB; mem (CPU total)=45997.56640625MB
INFO:root:[   22] Training loss: 0.65703808, Validation loss: 0.64731479, Gradient norm: 0.03696209
INFO:root:At the start of the epoch: mem (CPU python)=46257.953125MB; mem (CPU total)=46035.7421875MB
INFO:root:[   23] Training loss: 0.65530932, Validation loss: 0.64551898, Gradient norm: 0.03345512
INFO:root:At the start of the epoch: mem (CPU python)=46296.04296875MB; mem (CPU total)=46073.87890625MB
INFO:root:[   24] Training loss: 0.65387393, Validation loss: 0.64365822, Gradient norm: 0.03442457
INFO:root:At the start of the epoch: mem (CPU python)=46334.1328125MB; mem (CPU total)=46112.26953125MB
INFO:root:[   25] Training loss: 0.65269873, Validation loss: 0.64255759, Gradient norm: 0.03659227
INFO:root:At the start of the epoch: mem (CPU python)=46372.23046875MB; mem (CPU total)=46150.26171875MB
INFO:root:[   26] Training loss: 0.65145977, Validation loss: 0.64114288, Gradient norm: 0.03780760
INFO:root:At the start of the epoch: mem (CPU python)=46410.3359375MB; mem (CPU total)=46187.40234375MB
INFO:root:[   27] Training loss: 0.65001314, Validation loss: 0.63946902, Gradient norm: 0.03658862
INFO:root:At the start of the epoch: mem (CPU python)=46448.3828125MB; mem (CPU total)=46224.6796875MB
INFO:root:[   28] Training loss: 0.64907581, Validation loss: 0.63814901, Gradient norm: 0.03766326
INFO:root:At the start of the epoch: mem (CPU python)=46486.515625MB; mem (CPU total)=46263.00390625MB
INFO:root:[   29] Training loss: 0.64793920, Validation loss: 0.63743477, Gradient norm: 0.04186411
INFO:root:At the start of the epoch: mem (CPU python)=46524.62109375MB; mem (CPU total)=46301.0078125MB
INFO:root:[   30] Training loss: 0.64697670, Validation loss: 0.63585336, Gradient norm: 0.04086827
INFO:root:At the start of the epoch: mem (CPU python)=46562.5546875MB; mem (CPU total)=46339.12109375MB
INFO:root:[   31] Training loss: 0.64610918, Validation loss: 0.63500037, Gradient norm: 0.04346795
INFO:root:At the start of the epoch: mem (CPU python)=46600.80859375MB; mem (CPU total)=46377.51171875MB
INFO:root:[   32] Training loss: 0.64509408, Validation loss: 0.63465538, Gradient norm: 0.04042049
INFO:root:At the start of the epoch: mem (CPU python)=46638.95703125MB; mem (CPU total)=46415.64453125MB
INFO:root:[   33] Training loss: 0.64426471, Validation loss: 0.63317810, Gradient norm: 0.04257533
INFO:root:At the start of the epoch: mem (CPU python)=46677.015625MB; mem (CPU total)=46453.8125MB
INFO:root:[   34] Training loss: 0.64334758, Validation loss: 0.63238671, Gradient norm: 0.04064606
INFO:root:At the start of the epoch: mem (CPU python)=46715.14453125MB; mem (CPU total)=46492.1953125MB
INFO:root:[   35] Training loss: 0.64266413, Validation loss: 0.63095651, Gradient norm: 0.04504963
INFO:root:At the start of the epoch: mem (CPU python)=46753.24609375MB; mem (CPU total)=46530.36328125MB
INFO:root:[   36] Training loss: 0.64209390, Validation loss: 0.63092116, Gradient norm: 0.05002816
INFO:root:At the start of the epoch: mem (CPU python)=46791.26171875MB; mem (CPU total)=46568.78515625MB
INFO:root:[   37] Training loss: 0.64111619, Validation loss: 0.62963822, Gradient norm: 0.04420707
INFO:root:At the start of the epoch: mem (CPU python)=46829.43359375MB; mem (CPU total)=46608.38671875MB
INFO:root:[   38] Training loss: 0.64053712, Validation loss: 0.62926989, Gradient norm: 0.04452022
INFO:root:At the start of the epoch: mem (CPU python)=46867.5234375MB; mem (CPU total)=46646.25390625MB
INFO:root:[   39] Training loss: 0.63991168, Validation loss: 0.62841291, Gradient norm: 0.04861962
INFO:root:At the start of the epoch: mem (CPU python)=46905.6328125MB; mem (CPU total)=46683.65625MB
INFO:root:[   40] Training loss: 0.63919061, Validation loss: 0.62783949, Gradient norm: 0.04356774
INFO:root:At the start of the epoch: mem (CPU python)=46943.71484375MB; mem (CPU total)=46721.21484375MB
INFO:root:[   41] Training loss: 0.63841884, Validation loss: 0.62732852, Gradient norm: 0.04444501
INFO:root:At the start of the epoch: mem (CPU python)=46981.80859375MB; mem (CPU total)=46759.34375MB
INFO:root:[   42] Training loss: 0.63798625, Validation loss: 0.62669395, Gradient norm: 0.04483738
INFO:root:At the start of the epoch: mem (CPU python)=47019.85546875MB; mem (CPU total)=46797.7109375MB
INFO:root:[   43] Training loss: 0.63713810, Validation loss: 0.62638704, Gradient norm: 0.04399700
INFO:root:At the start of the epoch: mem (CPU python)=47057.94921875MB; mem (CPU total)=46835.82421875MB
INFO:root:[   44] Training loss: 0.63677120, Validation loss: 0.62567286, Gradient norm: 0.05184360
INFO:root:At the start of the epoch: mem (CPU python)=47096.04296875MB; mem (CPU total)=46873.96875MB
INFO:root:[   45] Training loss: 0.63601708, Validation loss: 0.62526547, Gradient norm: 0.04497682
INFO:root:At the start of the epoch: mem (CPU python)=47134.1328125MB; mem (CPU total)=46912.66015625MB
INFO:root:[   46] Training loss: 0.63558603, Validation loss: 0.62407731, Gradient norm: 0.04234102
INFO:root:At the start of the epoch: mem (CPU python)=47172.21875MB; mem (CPU total)=46951.02734375MB
INFO:root:[   47] Training loss: 0.63510477, Validation loss: 0.62482514, Gradient norm: 0.04640386
INFO:root:At the start of the epoch: mem (CPU python)=47210.33984375MB; mem (CPU total)=46989.6640625MB
INFO:root:[   48] Training loss: 0.63463050, Validation loss: 0.62366089, Gradient norm: 0.04464170
INFO:root:At the start of the epoch: mem (CPU python)=47248.41796875MB; mem (CPU total)=47027.28515625MB
INFO:root:[   49] Training loss: 0.63417246, Validation loss: 0.62228026, Gradient norm: 0.04828898
INFO:root:At the start of the epoch: mem (CPU python)=47286.51171875MB; mem (CPU total)=47065.4296875MB
INFO:root:[   50] Training loss: 0.63340373, Validation loss: 0.62270007, Gradient norm: 0.04396260
INFO:root:At the start of the epoch: mem (CPU python)=47324.59765625MB; mem (CPU total)=47104.05078125MB
INFO:root:[   51] Training loss: 0.63319677, Validation loss: 0.62237959, Gradient norm: 0.04828666
INFO:root:At the start of the epoch: mem (CPU python)=47362.71875MB; mem (CPU total)=47142.5078125MB
INFO:root:[   52] Training loss: 0.63270650, Validation loss: 0.62182961, Gradient norm: 0.04926298
INFO:root:At the start of the epoch: mem (CPU python)=47400.796875MB; mem (CPU total)=47179.61328125MB
INFO:root:[   53] Training loss: 0.63227812, Validation loss: 0.62092678, Gradient norm: 0.04602056
INFO:root:At the start of the epoch: mem (CPU python)=47438.94921875MB; mem (CPU total)=47218.265625MB
INFO:root:[   54] Training loss: 0.63183718, Validation loss: 0.62091076, Gradient norm: 0.05342780
INFO:root:At the start of the epoch: mem (CPU python)=47477.05078125MB; mem (CPU total)=47256.40234375MB
INFO:root:[   55] Training loss: 0.63163953, Validation loss: 0.62069082, Gradient norm: 0.05118547
INFO:root:At the start of the epoch: mem (CPU python)=47515.15234375MB; mem (CPU total)=47294.546875MB
INFO:root:[   56] Training loss: 0.63119147, Validation loss: 0.62104847, Gradient norm: 0.04751498
INFO:root:At the start of the epoch: mem (CPU python)=47553.25MB; mem (CPU total)=47332.8515625MB
INFO:root:[   57] Training loss: 0.63057676, Validation loss: 0.62050695, Gradient norm: 0.05523075
INFO:root:At the start of the epoch: mem (CPU python)=47591.3515625MB; mem (CPU total)=47370.5703125MB
INFO:root:[   58] Training loss: 0.63031467, Validation loss: 0.61963656, Gradient norm: 0.05406992
INFO:root:At the start of the epoch: mem (CPU python)=47629.43359375MB; mem (CPU total)=47408.96484375MB
INFO:root:[   59] Training loss: 0.62997881, Validation loss: 0.61917738, Gradient norm: 0.05432819
INFO:root:At the start of the epoch: mem (CPU python)=47667.53125MB; mem (CPU total)=47447.35546875MB
INFO:root:[   60] Training loss: 0.62935934, Validation loss: 0.61860764, Gradient norm: 0.05149458
INFO:root:At the start of the epoch: mem (CPU python)=47705.609375MB; mem (CPU total)=47485.44921875MB
INFO:root:[   61] Training loss: 0.62915588, Validation loss: 0.61914945, Gradient norm: 0.04638425
INFO:root:At the start of the epoch: mem (CPU python)=47743.7265625MB; mem (CPU total)=47523.83203125MB
INFO:root:[   62] Training loss: 0.62864716, Validation loss: 0.61804688, Gradient norm: 0.04963288
INFO:root:At the start of the epoch: mem (CPU python)=47781.8203125MB; mem (CPU total)=47561.7578125MB
INFO:root:[   63] Training loss: 0.62853668, Validation loss: 0.61849977, Gradient norm: 0.04799163
INFO:root:At the start of the epoch: mem (CPU python)=47819.7734375MB; mem (CPU total)=47601.39453125MB
INFO:root:[   64] Training loss: 0.62819869, Validation loss: 0.61734963, Gradient norm: 0.05215730
INFO:root:At the start of the epoch: mem (CPU python)=47857.95703125MB; mem (CPU total)=47639.30859375MB
INFO:root:[   65] Training loss: 0.62761987, Validation loss: 0.61750688, Gradient norm: 0.05087467
INFO:root:At the start of the epoch: mem (CPU python)=47896.04296875MB; mem (CPU total)=47677.9140625MB
INFO:root:[   66] Training loss: 0.62763345, Validation loss: 0.61676928, Gradient norm: 0.05799665
INFO:root:At the start of the epoch: mem (CPU python)=47934.13671875MB; mem (CPU total)=47715.6875MB
INFO:root:[   67] Training loss: 0.62734271, Validation loss: 0.61690394, Gradient norm: 0.05864797
INFO:root:At the start of the epoch: mem (CPU python)=47972.2421875MB; mem (CPU total)=47754.53125MB
INFO:root:[   68] Training loss: 0.62671773, Validation loss: 0.61605925, Gradient norm: 0.04681261
INFO:root:At the start of the epoch: mem (CPU python)=48010.33203125MB; mem (CPU total)=47791.71875MB
INFO:root:[   69] Training loss: 0.62657572, Validation loss: 0.61628782, Gradient norm: 0.05318961
INFO:root:At the start of the epoch: mem (CPU python)=48048.3984375MB; mem (CPU total)=47830.65234375MB
INFO:root:[   70] Training loss: 0.62618368, Validation loss: 0.61611393, Gradient norm: 0.04597086
INFO:root:At the start of the epoch: mem (CPU python)=48086.53125MB; mem (CPU total)=47869.03125MB
INFO:root:[   71] Training loss: 0.62595080, Validation loss: 0.61610453, Gradient norm: 0.05464236
INFO:root:At the start of the epoch: mem (CPU python)=48124.61328125MB; mem (CPU total)=47907.08203125MB
INFO:root:[   72] Training loss: 0.62567063, Validation loss: 0.61556206, Gradient norm: 0.05164833
INFO:root:At the start of the epoch: mem (CPU python)=48162.7109375MB; mem (CPU total)=47944.734375MB
INFO:root:[   73] Training loss: 0.62527355, Validation loss: 0.61545621, Gradient norm: 0.05803336
INFO:root:At the start of the epoch: mem (CPU python)=48200.81640625MB; mem (CPU total)=47983.7109375MB
INFO:root:[   74] Training loss: 0.62520865, Validation loss: 0.61515727, Gradient norm: 0.05040402
INFO:root:At the start of the epoch: mem (CPU python)=48238.96484375MB; mem (CPU total)=48021.58984375MB
INFO:root:[   75] Training loss: 0.62484538, Validation loss: 0.61413298, Gradient norm: 0.05550689
INFO:root:At the start of the epoch: mem (CPU python)=48277.05078125MB; mem (CPU total)=48059.01171875MB
INFO:root:[   76] Training loss: 0.62464684, Validation loss: 0.61440225, Gradient norm: 0.05413795
INFO:root:At the start of the epoch: mem (CPU python)=48315.14453125MB; mem (CPU total)=48097.42578125MB
INFO:root:[   77] Training loss: 0.62441084, Validation loss: 0.61401955, Gradient norm: 0.05520565
INFO:root:At the start of the epoch: mem (CPU python)=48353.25MB; mem (CPU total)=48134.7890625MB
INFO:root:[   78] Training loss: 0.62398480, Validation loss: 0.61388547, Gradient norm: 0.05226083
INFO:root:At the start of the epoch: mem (CPU python)=48391.33984375MB; mem (CPU total)=48173.421875MB
INFO:root:[   79] Training loss: 0.62383917, Validation loss: 0.61364994, Gradient norm: 0.05834063
INFO:root:At the start of the epoch: mem (CPU python)=48429.37890625MB; mem (CPU total)=48211.29296875MB
INFO:root:[   80] Training loss: 0.62339846, Validation loss: 0.61360325, Gradient norm: 0.05390859
INFO:root:At the start of the epoch: mem (CPU python)=48467.4921875MB; mem (CPU total)=48249.65625MB
INFO:root:[   81] Training loss: 0.62316534, Validation loss: 0.61333260, Gradient norm: 0.04901190
INFO:root:At the start of the epoch: mem (CPU python)=48505.62890625MB; mem (CPU total)=48287.80078125MB
INFO:root:[   82] Training loss: 0.62305350, Validation loss: 0.61436750, Gradient norm: 0.05390882
INFO:root:At the start of the epoch: mem (CPU python)=48543.6796875MB; mem (CPU total)=48326.17578125MB
INFO:root:[   83] Training loss: 0.62273389, Validation loss: 0.61264938, Gradient norm: 0.05641487
INFO:root:At the start of the epoch: mem (CPU python)=48581.82421875MB; mem (CPU total)=48364.10546875MB
INFO:root:[   84] Training loss: 0.62258893, Validation loss: 0.61294227, Gradient norm: 0.05568627
INFO:root:At the start of the epoch: mem (CPU python)=48619.8671875MB; mem (CPU total)=48403.234375MB
INFO:root:[   85] Training loss: 0.62220654, Validation loss: 0.61174000, Gradient norm: 0.05766996
INFO:root:At the start of the epoch: mem (CPU python)=48657.94921875MB; mem (CPU total)=48440.86328125MB
INFO:root:[   86] Training loss: 0.62228005, Validation loss: 0.61267757, Gradient norm: 0.05646534
INFO:root:At the start of the epoch: mem (CPU python)=48696.0390625MB; mem (CPU total)=48479.52734375MB
INFO:root:[   87] Training loss: 0.62178860, Validation loss: 0.61268561, Gradient norm: 0.05340974
INFO:root:At the start of the epoch: mem (CPU python)=48734.15234375MB; mem (CPU total)=48518.1796875MB
INFO:root:[   88] Training loss: 0.62153364, Validation loss: 0.61224286, Gradient norm: 0.05499060
INFO:root:At the start of the epoch: mem (CPU python)=48772.23046875MB; mem (CPU total)=48556.234375MB
INFO:root:[   89] Training loss: 0.62146834, Validation loss: 0.61133510, Gradient norm: 0.05283033
INFO:root:At the start of the epoch: mem (CPU python)=48810.33984375MB; mem (CPU total)=48593.703125MB
INFO:root:[   90] Training loss: 0.62117498, Validation loss: 0.61271062, Gradient norm: 0.05752038
INFO:root:At the start of the epoch: mem (CPU python)=48848.4296875MB; mem (CPU total)=48632.5859375MB
INFO:root:[   91] Training loss: 0.62104086, Validation loss: 0.61153790, Gradient norm: 0.05341789
INFO:root:At the start of the epoch: mem (CPU python)=48886.52734375MB; mem (CPU total)=48670.47265625MB
INFO:root:[   92] Training loss: 0.62072396, Validation loss: 0.61099790, Gradient norm: 0.04953079
INFO:root:At the start of the epoch: mem (CPU python)=48924.578125MB; mem (CPU total)=48708.12109375MB
INFO:root:[   93] Training loss: 0.62053590, Validation loss: 0.61039640, Gradient norm: 0.05269607
INFO:root:At the start of the epoch: mem (CPU python)=48962.72265625MB; mem (CPU total)=48746.31640625MB
INFO:root:[   94] Training loss: 0.62048987, Validation loss: 0.61185346, Gradient norm: 0.05521522
INFO:root:At the start of the epoch: mem (CPU python)=49000.81640625MB; mem (CPU total)=48785.19921875MB
INFO:root:[   95] Training loss: 0.62017533, Validation loss: 0.61058671, Gradient norm: 0.05797197
INFO:root:At the start of the epoch: mem (CPU python)=49038.9296875MB; mem (CPU total)=48823.609375MB
INFO:root:[   96] Training loss: 0.61982364, Validation loss: 0.61052573, Gradient norm: 0.05057796
INFO:root:At the start of the epoch: mem (CPU python)=49077.0625MB; mem (CPU total)=48861.45703125MB
INFO:root:[   97] Training loss: 0.61972039, Validation loss: 0.61011111, Gradient norm: 0.05844472
INFO:root:At the start of the epoch: mem (CPU python)=49115.16015625MB; mem (CPU total)=48898.87890625MB
INFO:root:[   98] Training loss: 0.61988532, Validation loss: 0.60998079, Gradient norm: 0.05921452
INFO:root:At the start of the epoch: mem (CPU python)=49153.22265625MB; mem (CPU total)=48937.0390625MB
INFO:root:[   99] Training loss: 0.61959693, Validation loss: 0.61083164, Gradient norm: 0.06373502
INFO:root:At the start of the epoch: mem (CPU python)=49191.34765625MB; mem (CPU total)=48975.6640625MB
INFO:root:[  100] Training loss: 0.61924995, Validation loss: 0.61002332, Gradient norm: 0.05154266
INFO:root:At the start of the epoch: mem (CPU python)=49229.44140625MB; mem (CPU total)=49013.5625MB
INFO:root:[  101] Training loss: 0.61918953, Validation loss: 0.60915640, Gradient norm: 0.05744769
INFO:root:At the start of the epoch: mem (CPU python)=49267.5390625MB; mem (CPU total)=49051.64453125MB
INFO:root:[  102] Training loss: 0.61895466, Validation loss: 0.60898208, Gradient norm: 0.06007205
INFO:root:At the start of the epoch: mem (CPU python)=49305.58984375MB; mem (CPU total)=49089.75390625MB
INFO:root:[  103] Training loss: 0.61865877, Validation loss: 0.60890420, Gradient norm: 0.05949524
INFO:root:At the start of the epoch: mem (CPU python)=49343.73046875MB; mem (CPU total)=49129.19140625MB
INFO:root:[  104] Training loss: 0.61860109, Validation loss: 0.60856543, Gradient norm: 0.06155455
INFO:root:At the start of the epoch: mem (CPU python)=49381.8203125MB; mem (CPU total)=49166.66015625MB
INFO:root:[  105] Training loss: 0.61835129, Validation loss: 0.60854390, Gradient norm: 0.06065675
INFO:root:At the start of the epoch: mem (CPU python)=49419.81640625MB; mem (CPU total)=49204.5703125MB
INFO:root:[  106] Training loss: 0.61817553, Validation loss: 0.60940805, Gradient norm: 0.05951389
INFO:root:At the start of the epoch: mem (CPU python)=49457.9453125MB; mem (CPU total)=49243.17578125MB
INFO:root:[  107] Training loss: 0.61806832, Validation loss: 0.60800808, Gradient norm: 0.06742454
INFO:root:At the start of the epoch: mem (CPU python)=49496.0625MB; mem (CPU total)=49280.828125MB
INFO:root:[  108] Training loss: 0.61781815, Validation loss: 0.60842279, Gradient norm: 0.06049194
INFO:root:At the start of the epoch: mem (CPU python)=49534.125MB; mem (CPU total)=49319.69921875MB
INFO:root:[  109] Training loss: 0.61770221, Validation loss: 0.60899739, Gradient norm: 0.06141610
INFO:root:At the start of the epoch: mem (CPU python)=49572.24609375MB; mem (CPU total)=49358.11328125MB
INFO:root:[  110] Training loss: 0.61731012, Validation loss: 0.60848237, Gradient norm: 0.05772790
INFO:root:At the start of the epoch: mem (CPU python)=49610.34375MB; mem (CPU total)=49395.9296875MB
INFO:root:[  111] Training loss: 0.61743198, Validation loss: 0.60789409, Gradient norm: 0.06906209
INFO:root:At the start of the epoch: mem (CPU python)=49648.44140625MB; mem (CPU total)=49433.55078125MB
INFO:root:[  112] Training loss: 0.61727584, Validation loss: 0.60840047, Gradient norm: 0.05900428
INFO:root:At the start of the epoch: mem (CPU python)=49686.5MB; mem (CPU total)=49472.1796875MB
INFO:root:[  113] Training loss: 0.61698127, Validation loss: 0.60980065, Gradient norm: 0.05675566
INFO:root:At the start of the epoch: mem (CPU python)=49724.62890625MB; mem (CPU total)=49510.5703125MB
INFO:root:[  114] Training loss: 0.61690929, Validation loss: 0.60953437, Gradient norm: 0.06286990
INFO:root:At the start of the epoch: mem (CPU python)=49762.7265625MB; mem (CPU total)=49548.921875MB
INFO:root:[  115] Training loss: 0.61692695, Validation loss: 0.60732913, Gradient norm: 0.06110575
INFO:root:At the start of the epoch: mem (CPU python)=49800.8125MB; mem (CPU total)=49586.84765625MB
INFO:root:[  116] Training loss: 0.61658028, Validation loss: 0.60820629, Gradient norm: 0.06359740
INFO:root:At the start of the epoch: mem (CPU python)=49838.9765625MB; mem (CPU total)=49625.46875MB
INFO:root:[  117] Training loss: 0.61631649, Validation loss: 0.60839326, Gradient norm: 0.05728038
INFO:root:At the start of the epoch: mem (CPU python)=49877.05859375MB; mem (CPU total)=49663.88671875MB
INFO:root:[  118] Training loss: 0.61597294, Validation loss: 0.60749606, Gradient norm: 0.05572648
INFO:root:At the start of the epoch: mem (CPU python)=49915.15234375MB; mem (CPU total)=49701.78125MB
INFO:root:[  119] Training loss: 0.61618204, Validation loss: 0.60739174, Gradient norm: 0.05796561
INFO:root:At the start of the epoch: mem (CPU python)=49953.2421875MB; mem (CPU total)=49739.91796875MB
INFO:root:[  120] Training loss: 0.61600472, Validation loss: 0.60835193, Gradient norm: 0.05780956
INFO:root:At the start of the epoch: mem (CPU python)=49991.35546875MB; mem (CPU total)=49778.0625MB
INFO:root:[  121] Training loss: 0.61578975, Validation loss: 0.60653703, Gradient norm: 0.05470420
INFO:root:At the start of the epoch: mem (CPU python)=50029.453125MB; mem (CPU total)=49815.484375MB
INFO:root:[  122] Training loss: 0.61578951, Validation loss: 0.60795791, Gradient norm: 0.06025463
INFO:root:At the start of the epoch: mem (CPU python)=50067.546875MB; mem (CPU total)=49853.7734375MB
INFO:root:[  123] Training loss: 0.61571688, Validation loss: 0.60675605, Gradient norm: 0.06357985
INFO:root:At the start of the epoch: mem (CPU python)=50105.63671875MB; mem (CPU total)=49892.15625MB
INFO:root:[  124] Training loss: 0.61541537, Validation loss: 0.60655609, Gradient norm: 0.06061652
INFO:root:At the start of the epoch: mem (CPU python)=50143.73828125MB; mem (CPU total)=49930.20703125MB
INFO:root:[  125] Training loss: 0.61533602, Validation loss: 0.60639938, Gradient norm: 0.05967831
INFO:root:At the start of the epoch: mem (CPU python)=50181.82421875MB; mem (CPU total)=49968.40234375MB
INFO:root:[  126] Training loss: 0.61541617, Validation loss: 0.60746428, Gradient norm: 0.06260586
INFO:root:At the start of the epoch: mem (CPU python)=50219.8671875MB; mem (CPU total)=50007.3359375MB
INFO:root:[  127] Training loss: 0.61482938, Validation loss: 0.60822641, Gradient norm: 0.05984334
INFO:root:At the start of the epoch: mem (CPU python)=50257.96484375MB; mem (CPU total)=50044.86328125MB
INFO:root:[  128] Training loss: 0.61499083, Validation loss: 0.60651934, Gradient norm: 0.06368168
INFO:root:At the start of the epoch: mem (CPU python)=50296.06640625MB; mem (CPU total)=50082.73046875MB
INFO:root:[  129] Training loss: 0.61470490, Validation loss: 0.60624435, Gradient norm: 0.06122622
INFO:root:At the start of the epoch: mem (CPU python)=50334.16015625MB; mem (CPU total)=50120.66796875MB
INFO:root:[  130] Training loss: 0.61479854, Validation loss: 0.60657772, Gradient norm: 0.07144570
INFO:root:At the start of the epoch: mem (CPU python)=50372.18359375MB; mem (CPU total)=50159.69140625MB
INFO:root:[  131] Training loss: 0.61448724, Validation loss: 0.60680251, Gradient norm: 0.06050065
INFO:root:At the start of the epoch: mem (CPU python)=50410.3515625MB; mem (CPU total)=50197.83203125MB
INFO:root:[  132] Training loss: 0.61410098, Validation loss: 0.60758209, Gradient norm: 0.05659384
INFO:root:At the start of the epoch: mem (CPU python)=50448.4375MB; mem (CPU total)=50236.0MB
INFO:root:[  133] Training loss: 0.61442726, Validation loss: 0.60574973, Gradient norm: 0.07169359
INFO:root:At the start of the epoch: mem (CPU python)=50486.53125MB; mem (CPU total)=50273.640625MB
INFO:root:[  134] Training loss: 0.61377806, Validation loss: 0.60532822, Gradient norm: 0.05686962
INFO:root:At the start of the epoch: mem (CPU python)=50524.63671875MB; mem (CPU total)=50311.5390625MB
INFO:root:[  135] Training loss: 0.61408786, Validation loss: 0.60671625, Gradient norm: 0.06463279
INFO:root:At the start of the epoch: mem (CPU python)=50562.734375MB; mem (CPU total)=50350.421875MB
INFO:root:[  136] Training loss: 0.61415524, Validation loss: 0.60557859, Gradient norm: 0.05768447
INFO:root:At the start of the epoch: mem (CPU python)=50600.87109375MB; mem (CPU total)=50388.5625MB
INFO:root:[  137] Training loss: 0.61350993, Validation loss: 0.60632128, Gradient norm: 0.05800624
INFO:root:At the start of the epoch: mem (CPU python)=50638.94140625MB; mem (CPU total)=50426.640625MB
INFO:root:[  138] Training loss: 0.61365993, Validation loss: 0.60713732, Gradient norm: 0.06121656
INFO:root:At the start of the epoch: mem (CPU python)=50677.07421875MB; mem (CPU total)=50464.7890625MB
INFO:root:[  139] Training loss: 0.61356812, Validation loss: 0.60672634, Gradient norm: 0.06457531
INFO:root:At the start of the epoch: mem (CPU python)=50715.16796875MB; mem (CPU total)=50502.4296875MB
INFO:root:[  140] Training loss: 0.61336222, Validation loss: 0.60717434, Gradient norm: 0.06220263
INFO:root:At the start of the epoch: mem (CPU python)=50753.24609375MB; mem (CPU total)=50540.8203125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  141] Training loss: 0.61340137, Validation loss: 0.60514106, Gradient norm: 0.07110619
INFO:root:At the start of the epoch: mem (CPU python)=50791.2734375MB; mem (CPU total)=50578.50390625MB
INFO:root:[  142] Training loss: 0.61231305, Validation loss: 0.60624897, Gradient norm: 0.05435471
INFO:root:At the start of the epoch: mem (CPU python)=50829.453125MB; mem (CPU total)=50616.375MB
INFO:root:[  143] Training loss: 0.61206193, Validation loss: 0.60644000, Gradient norm: 0.05109960
INFO:root:At the start of the epoch: mem (CPU python)=50867.54296875MB; mem (CPU total)=50655.34765625MB
INFO:root:[  144] Training loss: 0.61185157, Validation loss: 0.60595259, Gradient norm: 0.05562541
INFO:root:At the start of the epoch: mem (CPU python)=50905.63671875MB; mem (CPU total)=50692.85546875MB
INFO:root:[  145] Training loss: 0.61225945, Validation loss: 0.60422436, Gradient norm: 0.05667809
INFO:root:At the start of the epoch: mem (CPU python)=50943.74609375MB; mem (CPU total)=50729.80078125MB
INFO:root:[  146] Training loss: 0.61213952, Validation loss: 0.60529705, Gradient norm: 0.05827026
INFO:root:At the start of the epoch: mem (CPU python)=50981.8359375MB; mem (CPU total)=50768.45703125MB
INFO:root:[  147] Training loss: 0.61179048, Validation loss: 0.60548464, Gradient norm: 0.05351443
INFO:root:At the start of the epoch: mem (CPU python)=51019.875MB; mem (CPU total)=50807.09375MB
INFO:root:[  148] Training loss: 0.61160546, Validation loss: 0.60576226, Gradient norm: 0.05494969
INFO:root:At the start of the epoch: mem (CPU python)=51057.96875MB; mem (CPU total)=50845.18359375MB
INFO:root:[  149] Training loss: 0.61173348, Validation loss: 0.60452281, Gradient norm: 0.05712515
INFO:root:At the start of the epoch: mem (CPU python)=51096.015625MB; mem (CPU total)=50883.41796875MB
INFO:root:[  150] Training loss: 0.61159368, Validation loss: 0.60508228, Gradient norm: 0.05443253
INFO:root:At the start of the epoch: mem (CPU python)=51134.1640625MB; mem (CPU total)=50921.7890625MB
INFO:root:[  151] Training loss: 0.61161935, Validation loss: 0.60537129, Gradient norm: 0.05685320
INFO:root:At the start of the epoch: mem (CPU python)=51172.25MB; mem (CPU total)=50959.6875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  152] Training loss: 0.61140714, Validation loss: 0.60586322, Gradient norm: 0.05969312
INFO:root:At the start of the epoch: mem (CPU python)=51210.33984375MB; mem (CPU total)=50997.83203125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  153] Training loss: 0.61102809, Validation loss: 0.60423749, Gradient norm: 0.05412382
INFO:root:At the start of the epoch: mem (CPU python)=51248.484375MB; mem (CPU total)=51035.953125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  154] Training loss: 0.61085924, Validation loss: 0.60379334, Gradient norm: 0.04992325
INFO:root:At the start of the epoch: mem (CPU python)=51286.52734375MB; mem (CPU total)=51073.59765625MB
INFO:root:[  155] Training loss: 0.61060315, Validation loss: 0.60413369, Gradient norm: 0.04861983
INFO:root:At the start of the epoch: mem (CPU python)=51324.640625MB; mem (CPU total)=51113.14453125MB
INFO:root:[  156] Training loss: 0.61038648, Validation loss: 0.60416826, Gradient norm: 0.04844752
INFO:root:At the start of the epoch: mem (CPU python)=51362.734375MB; mem (CPU total)=51151.109375MB
INFO:root:[  157] Training loss: 0.61035684, Validation loss: 0.60399302, Gradient norm: 0.04797752
INFO:root:At the start of the epoch: mem (CPU python)=51400.83984375MB; mem (CPU total)=51189.25MB
INFO:root:[  158] Training loss: 0.61038741, Validation loss: 0.60403055, Gradient norm: 0.04864059
INFO:root:At the start of the epoch: mem (CPU python)=51438.97265625MB; mem (CPU total)=51227.36328125MB
INFO:root:[  159] Training loss: 0.61041718, Validation loss: 0.60410238, Gradient norm: 0.04932969
INFO:root:At the start of the epoch: mem (CPU python)=51477.078125MB; mem (CPU total)=51265.4921875MB
INFO:root:[  160] Training loss: 0.61048456, Validation loss: 0.60467462, Gradient norm: 0.04932548
INFO:root:At the start of the epoch: mem (CPU python)=51515.1640625MB; mem (CPU total)=51303.40625MB
INFO:root:[  161] Training loss: 0.61030092, Validation loss: 0.60423420, Gradient norm: 0.04803829
INFO:root:At the start of the epoch: mem (CPU python)=51553.2734375MB; mem (CPU total)=51341.53515625MB
INFO:root:[  162] Training loss: 0.61047871, Validation loss: 0.60509823, Gradient norm: 0.04839769
INFO:root:At the start of the epoch: mem (CPU python)=51591.3515625MB; mem (CPU total)=51379.67578125MB
INFO:root:[  163] Training loss: 0.61037893, Validation loss: 0.60435528, Gradient norm: 0.04862899
INFO:root:At the start of the epoch: mem (CPU python)=51629.45703125MB; mem (CPU total)=51417.21875MB
INFO:root:EP 163: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=51667.54296875MB; mem (CPU total)=51455.609375MB
INFO:root:Training the model took 16989.505s.
INFO:root:Emptying the cuda cache took 0.005s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83844
INFO:root:EnergyScoreTrain: 0.59027
INFO:root:CRPSTrain: 0.45812
INFO:root:Gaussian NLLTrain: 1.18479
INFO:root:CoverageTrain: 0.9492
INFO:root:IntervalWidthTrain: 3.25115
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8585
INFO:root:EnergyScoreValidation: 0.60427
INFO:root:CRPSValidation: 0.46997
INFO:root:Gaussian NLLValidation: 1.21134
INFO:root:CoverageValidation: 0.94268
INFO:root:IntervalWidthValidation: 3.25357
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.85976
INFO:root:EnergyScoreTest: 0.60515
INFO:root:CRPSTest: 0.47074
INFO:root:Gaussian NLLTest: 1.2126
INFO:root:CoverageTest: 0.94267
INFO:root:IntervalWidthTest: 3.25648
INFO:root:After validation: mem (CPU python)=51701.25MB; mem (CPU total)=51481.87109375MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=51701.25MB; mem (CPU total)=51481.87109375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=51701.25MB; mem (CPU total)=51482.1171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=51701.25MB; mem (CPU total)=51482.64453125MB
INFO:root:[    1] Training loss: 0.72680591, Validation loss: 0.72064881, Gradient norm: 0.03079641
INFO:root:At the start of the epoch: mem (CPU python)=51747.58984375MB; mem (CPU total)=51535.86328125MB
INFO:root:[    2] Training loss: 0.71979124, Validation loss: 0.71857558, Gradient norm: 0.00597920
INFO:root:At the start of the epoch: mem (CPU python)=51785.6875MB; mem (CPU total)=51574.30078125MB
INFO:root:[    3] Training loss: 0.71729601, Validation loss: 0.71287347, Gradient norm: 0.00968588
INFO:root:At the start of the epoch: mem (CPU python)=51823.76171875MB; mem (CPU total)=51612.19140625MB
INFO:root:[    4] Training loss: 0.71039414, Validation loss: 0.70402748, Gradient norm: 0.01813880
INFO:root:At the start of the epoch: mem (CPU python)=51861.87890625MB; mem (CPU total)=51650.58203125MB
INFO:root:[    5] Training loss: 0.70357716, Validation loss: 0.69736534, Gradient norm: 0.02414903
INFO:root:At the start of the epoch: mem (CPU python)=51899.91796875MB; mem (CPU total)=51688.9921875MB
INFO:root:[    6] Training loss: 0.69780422, Validation loss: 0.69084054, Gradient norm: 0.02440410
INFO:root:At the start of the epoch: mem (CPU python)=51938.0703125MB; mem (CPU total)=51726.921875MB
INFO:root:[    7] Training loss: 0.69221979, Validation loss: 0.68498266, Gradient norm: 0.02585234
INFO:root:At the start of the epoch: mem (CPU python)=51976.15625MB; mem (CPU total)=51765.828125MB
INFO:root:[    8] Training loss: 0.68718973, Validation loss: 0.67825825, Gradient norm: 0.02641862
INFO:root:At the start of the epoch: mem (CPU python)=52014.25390625MB; mem (CPU total)=51803.69140625MB
INFO:root:[    9] Training loss: 0.68246803, Validation loss: 0.67355361, Gradient norm: 0.02573883
INFO:root:At the start of the epoch: mem (CPU python)=52052.33984375MB; mem (CPU total)=51841.3125MB
INFO:root:[   10] Training loss: 0.67822728, Validation loss: 0.66873037, Gradient norm: 0.02662344
INFO:root:At the start of the epoch: mem (CPU python)=52090.43359375MB; mem (CPU total)=51879.69921875MB
INFO:root:[   11] Training loss: 0.67437823, Validation loss: 0.66477736, Gradient norm: 0.02981508
INFO:root:At the start of the epoch: mem (CPU python)=52128.54296875MB; mem (CPU total)=51917.8359375MB
INFO:root:[   12] Training loss: 0.67091070, Validation loss: 0.66053350, Gradient norm: 0.02730114
INFO:root:At the start of the epoch: mem (CPU python)=52166.64453125MB; mem (CPU total)=51956.1953125MB
INFO:root:[   13] Training loss: 0.66809075, Validation loss: 0.65813305, Gradient norm: 0.02926808
INFO:root:At the start of the epoch: mem (CPU python)=52204.73046875MB; mem (CPU total)=51994.61328125MB
INFO:root:[   14] Training loss: 0.66587726, Validation loss: 0.65608597, Gradient norm: 0.02795551
INFO:root:At the start of the epoch: mem (CPU python)=52242.77734375MB; mem (CPU total)=52032.48046875MB
INFO:root:[   15] Training loss: 0.66341466, Validation loss: 0.65319289, Gradient norm: 0.02970862
INFO:root:At the start of the epoch: mem (CPU python)=52280.8359375MB; mem (CPU total)=52070.65625MB
INFO:root:[   16] Training loss: 0.66149041, Validation loss: 0.65066644, Gradient norm: 0.03009754
INFO:root:At the start of the epoch: mem (CPU python)=52318.96484375MB; mem (CPU total)=52108.77734375MB
INFO:root:[   17] Training loss: 0.65968216, Validation loss: 0.64877592, Gradient norm: 0.03145675
INFO:root:At the start of the epoch: mem (CPU python)=52357.078125MB; mem (CPU total)=52147.4609375MB
INFO:root:[   18] Training loss: 0.65822584, Validation loss: 0.64812953, Gradient norm: 0.03477305
INFO:root:At the start of the epoch: mem (CPU python)=52395.15625MB; mem (CPU total)=52185.59765625MB
INFO:root:[   19] Training loss: 0.65662289, Validation loss: 0.64547600, Gradient norm: 0.03335244
INFO:root:At the start of the epoch: mem (CPU python)=52433.25390625MB; mem (CPU total)=52223.91796875MB
INFO:root:[   20] Training loss: 0.65511809, Validation loss: 0.64387347, Gradient norm: 0.03540806
INFO:root:At the start of the epoch: mem (CPU python)=52471.32421875MB; mem (CPU total)=52263.109375MB
INFO:root:[   21] Training loss: 0.65360735, Validation loss: 0.64292110, Gradient norm: 0.03367796
INFO:root:At the start of the epoch: mem (CPU python)=52509.47265625MB; mem (CPU total)=52301.5078125MB
INFO:root:[   22] Training loss: 0.65239673, Validation loss: 0.64116093, Gradient norm: 0.03416529
INFO:root:At the start of the epoch: mem (CPU python)=52547.58984375MB; mem (CPU total)=52339.6640625MB
INFO:root:[   23] Training loss: 0.65137082, Validation loss: 0.64047122, Gradient norm: 0.03949263
INFO:root:At the start of the epoch: mem (CPU python)=52585.69140625MB; mem (CPU total)=52377.453125MB
INFO:root:[   24] Training loss: 0.65016265, Validation loss: 0.63981938, Gradient norm: 0.03498041
INFO:root:At the start of the epoch: mem (CPU python)=52623.78515625MB; mem (CPU total)=52416.125MB
INFO:root:[   25] Training loss: 0.64901617, Validation loss: 0.63755455, Gradient norm: 0.03790124
INFO:root:At the start of the epoch: mem (CPU python)=52661.875MB; mem (CPU total)=52454.2734375MB
INFO:root:[   26] Training loss: 0.64806607, Validation loss: 0.63746509, Gradient norm: 0.03473870
INFO:root:At the start of the epoch: mem (CPU python)=52699.97265625MB; mem (CPU total)=52492.0MB
INFO:root:[   27] Training loss: 0.64696027, Validation loss: 0.63614407, Gradient norm: 0.03870700
INFO:root:At the start of the epoch: mem (CPU python)=52738.07421875MB; mem (CPU total)=52530.16796875MB
INFO:root:[   28] Training loss: 0.64606206, Validation loss: 0.63470196, Gradient norm: 0.04311026
INFO:root:At the start of the epoch: mem (CPU python)=52776.16796875MB; mem (CPU total)=52568.1015625MB
INFO:root:[   29] Training loss: 0.64526972, Validation loss: 0.63497279, Gradient norm: 0.04320835
INFO:root:At the start of the epoch: mem (CPU python)=52814.2578125MB; mem (CPU total)=52606.53515625MB
INFO:root:[   30] Training loss: 0.64440595, Validation loss: 0.63387377, Gradient norm: 0.04611863
INFO:root:At the start of the epoch: mem (CPU python)=52852.3515625MB; mem (CPU total)=52644.68359375MB
INFO:root:[   31] Training loss: 0.64347426, Validation loss: 0.63326153, Gradient norm: 0.04289452
INFO:root:At the start of the epoch: mem (CPU python)=52890.453125MB; mem (CPU total)=52683.171875MB
INFO:root:[   32] Training loss: 0.64277207, Validation loss: 0.63262089, Gradient norm: 0.04307730
INFO:root:At the start of the epoch: mem (CPU python)=52928.48828125MB; mem (CPU total)=52720.19921875MB
INFO:root:[   33] Training loss: 0.64199930, Validation loss: 0.63097394, Gradient norm: 0.04203919
INFO:root:At the start of the epoch: mem (CPU python)=52966.58984375MB; mem (CPU total)=52758.578125MB
INFO:root:[   34] Training loss: 0.64135782, Validation loss: 0.63023000, Gradient norm: 0.04527856
INFO:root:At the start of the epoch: mem (CPU python)=53004.68359375MB; mem (CPU total)=52797.73828125MB
INFO:root:[   35] Training loss: 0.64058901, Validation loss: 0.62962450, Gradient norm: 0.03987742
INFO:root:At the start of the epoch: mem (CPU python)=53042.6640625MB; mem (CPU total)=52835.921875MB
INFO:root:[   36] Training loss: 0.63985895, Validation loss: 0.62881771, Gradient norm: 0.04729934
INFO:root:At the start of the epoch: mem (CPU python)=53080.87109375MB; mem (CPU total)=52873.88671875MB
INFO:root:[   37] Training loss: 0.63933076, Validation loss: 0.62881193, Gradient norm: 0.04480645
INFO:root:At the start of the epoch: mem (CPU python)=53118.9609375MB; mem (CPU total)=52911.828125MB
INFO:root:[   38] Training loss: 0.63876141, Validation loss: 0.62842298, Gradient norm: 0.04467784
INFO:root:At the start of the epoch: mem (CPU python)=53157.05859375MB; mem (CPU total)=52949.96875MB
INFO:root:[   39] Training loss: 0.63801808, Validation loss: 0.62756879, Gradient norm: 0.04512052
INFO:root:At the start of the epoch: mem (CPU python)=53195.1484375MB; mem (CPU total)=52987.703125MB
INFO:root:[   40] Training loss: 0.63764802, Validation loss: 0.62651478, Gradient norm: 0.05083571
INFO:root:At the start of the epoch: mem (CPU python)=53233.2578125MB; mem (CPU total)=53026.09765625MB
INFO:root:[   41] Training loss: 0.63686293, Validation loss: 0.62699542, Gradient norm: 0.04423581
INFO:root:At the start of the epoch: mem (CPU python)=53271.3515625MB; mem (CPU total)=53064.7734375MB
INFO:root:[   42] Training loss: 0.63679048, Validation loss: 0.62571510, Gradient norm: 0.05660800
INFO:root:At the start of the epoch: mem (CPU python)=53309.484375MB; mem (CPU total)=53102.22265625MB
INFO:root:[   43] Training loss: 0.63605957, Validation loss: 0.62623599, Gradient norm: 0.04992969
INFO:root:At the start of the epoch: mem (CPU python)=53347.46484375MB; mem (CPU total)=53112.046875MB
INFO:root:[   44] Training loss: 0.63553205, Validation loss: 0.62433762, Gradient norm: 0.04681637
INFO:root:At the start of the epoch: mem (CPU python)=53385.55078125MB; mem (CPU total)=53151.96484375MB
INFO:root:[   45] Training loss: 0.63483282, Validation loss: 0.62424067, Gradient norm: 0.04981845
INFO:root:At the start of the epoch: mem (CPU python)=53423.66015625MB; mem (CPU total)=53188.42578125MB
INFO:root:[   46] Training loss: 0.63449297, Validation loss: 0.62626336, Gradient norm: 0.04460265
INFO:root:At the start of the epoch: mem (CPU python)=53461.75390625MB; mem (CPU total)=53226.359375MB
INFO:root:[   47] Training loss: 0.63400538, Validation loss: 0.62389697, Gradient norm: 0.05102866
INFO:root:At the start of the epoch: mem (CPU python)=53499.85546875MB; mem (CPU total)=53264.55859375MB
INFO:root:[   48] Training loss: 0.63363282, Validation loss: 0.62308634, Gradient norm: 0.04590092
INFO:root:At the start of the epoch: mem (CPU python)=53537.94140625MB; mem (CPU total)=53305.5078125MB
INFO:root:[   49] Training loss: 0.63328874, Validation loss: 0.62411420, Gradient norm: 0.05356832
INFO:root:At the start of the epoch: mem (CPU python)=53576.046875MB; mem (CPU total)=53343.7421875MB
INFO:root:[   50] Training loss: 0.63280963, Validation loss: 0.62239154, Gradient norm: 0.04541114
INFO:root:At the start of the epoch: mem (CPU python)=53614.07421875MB; mem (CPU total)=53381.765625MB
INFO:root:[   51] Training loss: 0.63210192, Validation loss: 0.62227325, Gradient norm: 0.04628170
INFO:root:At the start of the epoch: mem (CPU python)=53652.25MB; mem (CPU total)=53419.75MB
INFO:root:[   52] Training loss: 0.63184423, Validation loss: 0.62192257, Gradient norm: 0.04893438
INFO:root:At the start of the epoch: mem (CPU python)=53690.328125MB; mem (CPU total)=53458.1015625MB
INFO:root:[   53] Training loss: 0.63154807, Validation loss: 0.62099237, Gradient norm: 0.04420082
INFO:root:At the start of the epoch: mem (CPU python)=53728.4296875MB; mem (CPU total)=53495.80859375MB
INFO:root:[   54] Training loss: 0.63135826, Validation loss: 0.62061719, Gradient norm: 0.04988273
INFO:root:At the start of the epoch: mem (CPU python)=53766.5234375MB; mem (CPU total)=53535.73046875MB
INFO:root:[   55] Training loss: 0.63067788, Validation loss: 0.62016810, Gradient norm: 0.05074385
INFO:root:At the start of the epoch: mem (CPU python)=53804.6015625MB; mem (CPU total)=53574.7890625MB
INFO:root:[   56] Training loss: 0.63050487, Validation loss: 0.62013266, Gradient norm: 0.05280839
INFO:root:At the start of the epoch: mem (CPU python)=53842.71484375MB; mem (CPU total)=53612.60546875MB
INFO:root:[   57] Training loss: 0.63001184, Validation loss: 0.61993324, Gradient norm: 0.05024001
INFO:root:At the start of the epoch: mem (CPU python)=53880.875MB; mem (CPU total)=53648.78515625MB
INFO:root:[   58] Training loss: 0.62980958, Validation loss: 0.61869690, Gradient norm: 0.05271959
INFO:root:At the start of the epoch: mem (CPU python)=53918.9609375MB; mem (CPU total)=53686.9296875MB
INFO:root:[   59] Training loss: 0.62925393, Validation loss: 0.61867353, Gradient norm: 0.04509411
INFO:root:At the start of the epoch: mem (CPU python)=53957.0546875MB; mem (CPU total)=53725.77734375MB
INFO:root:[   60] Training loss: 0.62884250, Validation loss: 0.61840894, Gradient norm: 0.04934902
INFO:root:At the start of the epoch: mem (CPU python)=53995.14453125MB; mem (CPU total)=53764.1640625MB
INFO:root:[   61] Training loss: 0.62869834, Validation loss: 0.62015538, Gradient norm: 0.04948104
INFO:root:At the start of the epoch: mem (CPU python)=54033.24609375MB; mem (CPU total)=53805.03125MB
INFO:root:[   62] Training loss: 0.62819880, Validation loss: 0.61938094, Gradient norm: 0.05224293
INFO:root:At the start of the epoch: mem (CPU python)=54071.32421875MB; mem (CPU total)=53843.15625MB
INFO:root:[   63] Training loss: 0.62809308, Validation loss: 0.61821672, Gradient norm: 0.05697211
INFO:root:At the start of the epoch: mem (CPU python)=54109.38671875MB; mem (CPU total)=53881.26171875MB
INFO:root:[   64] Training loss: 0.62791123, Validation loss: 0.61810953, Gradient norm: 0.05432998
INFO:root:At the start of the epoch: mem (CPU python)=54147.53515625MB; mem (CPU total)=53919.453125MB
INFO:root:[   65] Training loss: 0.62744795, Validation loss: 0.61755823, Gradient norm: 0.05478819
INFO:root:At the start of the epoch: mem (CPU python)=54185.62890625MB; mem (CPU total)=53959.08984375MB
INFO:root:[   66] Training loss: 0.62716188, Validation loss: 0.61765275, Gradient norm: 0.05414135
INFO:root:At the start of the epoch: mem (CPU python)=54223.7265625MB; mem (CPU total)=53998.53515625MB
INFO:root:[   67] Training loss: 0.62680545, Validation loss: 0.61789071, Gradient norm: 0.05331587
INFO:root:At the start of the epoch: mem (CPU python)=54261.8125MB; mem (CPU total)=54036.53125MB
INFO:root:[   68] Training loss: 0.62665670, Validation loss: 0.61625375, Gradient norm: 0.04989393
INFO:root:At the start of the epoch: mem (CPU python)=54299.90625MB; mem (CPU total)=54074.64453125MB
INFO:root:[   69] Training loss: 0.62612634, Validation loss: 0.61630970, Gradient norm: 0.05491716
INFO:root:At the start of the epoch: mem (CPU python)=54337.8984375MB; mem (CPU total)=54113.55078125MB
INFO:root:[   70] Training loss: 0.62555026, Validation loss: 0.61570820, Gradient norm: 0.04778737
INFO:root:At the start of the epoch: mem (CPU python)=54376.109375MB; mem (CPU total)=54151.38671875MB
INFO:root:[   71] Training loss: 0.62596351, Validation loss: 0.61644781, Gradient norm: 0.05654124
INFO:root:At the start of the epoch: mem (CPU python)=54414.14453125MB; mem (CPU total)=54186.421875MB
INFO:root:[   72] Training loss: 0.62546618, Validation loss: 0.61551373, Gradient norm: 0.05203353
INFO:root:At the start of the epoch: mem (CPU python)=54452.23828125MB; mem (CPU total)=54221.5MB
INFO:root:[   73] Training loss: 0.62530594, Validation loss: 0.61598442, Gradient norm: 0.05771534
INFO:root:At the start of the epoch: mem (CPU python)=54490.3359375MB; mem (CPU total)=54260.15234375MB
INFO:root:[   74] Training loss: 0.62479382, Validation loss: 0.61480412, Gradient norm: 0.04952858
INFO:root:At the start of the epoch: mem (CPU python)=54528.421875MB; mem (CPU total)=54297.9296875MB
INFO:root:[   75] Training loss: 0.62455263, Validation loss: 0.61608403, Gradient norm: 0.05274781
INFO:root:At the start of the epoch: mem (CPU python)=54566.5078125MB; mem (CPU total)=54337.04296875MB
INFO:root:[   76] Training loss: 0.62432038, Validation loss: 0.61476058, Gradient norm: 0.05815337
INFO:root:At the start of the epoch: mem (CPU python)=54604.5703125MB; mem (CPU total)=54373.94921875MB
INFO:root:[   77] Training loss: 0.62416081, Validation loss: 0.61428594, Gradient norm: 0.05848865
INFO:root:At the start of the epoch: mem (CPU python)=54642.71875MB; mem (CPU total)=54412.33203125MB
INFO:root:[   78] Training loss: 0.62383468, Validation loss: 0.61391387, Gradient norm: 0.05316179
INFO:root:At the start of the epoch: mem (CPU python)=54680.8046875MB; mem (CPU total)=54448.38671875MB
INFO:root:[   79] Training loss: 0.62361165, Validation loss: 0.61522975, Gradient norm: 0.05885701
INFO:root:At the start of the epoch: mem (CPU python)=54718.8984375MB; mem (CPU total)=54485.953125MB
INFO:root:[   80] Training loss: 0.62325969, Validation loss: 0.61354554, Gradient norm: 0.05700095
INFO:root:At the start of the epoch: mem (CPU python)=54757.00390625MB; mem (CPU total)=54524.78515625MB
INFO:root:[   81] Training loss: 0.62288179, Validation loss: 0.61467114, Gradient norm: 0.05140560
INFO:root:At the start of the epoch: mem (CPU python)=54795.09765625MB; mem (CPU total)=54562.21484375MB
INFO:root:[   82] Training loss: 0.62280494, Validation loss: 0.61307805, Gradient norm: 0.04768384
INFO:root:At the start of the epoch: mem (CPU python)=54833.0859375MB; mem (CPU total)=54603.09765625MB
INFO:root:[   83] Training loss: 0.62261329, Validation loss: 0.61422172, Gradient norm: 0.05645103
INFO:root:At the start of the epoch: mem (CPU python)=54871.2890625MB; mem (CPU total)=54638.953125MB
INFO:root:[   84] Training loss: 0.62234335, Validation loss: 0.61347376, Gradient norm: 0.05009605
INFO:root:At the start of the epoch: mem (CPU python)=54909.3828125MB; mem (CPU total)=54678.41015625MB
INFO:root:[   85] Training loss: 0.62210515, Validation loss: 0.61184735, Gradient norm: 0.05421207
INFO:root:At the start of the epoch: mem (CPU python)=54947.48046875MB; mem (CPU total)=54715.52734375MB
INFO:root:[   86] Training loss: 0.62195067, Validation loss: 0.61405526, Gradient norm: 0.05793363
INFO:root:At the start of the epoch: mem (CPU python)=54985.57421875MB; mem (CPU total)=54752.3125MB
INFO:root:[   87] Training loss: 0.62169520, Validation loss: 0.61370841, Gradient norm: 0.05444957
INFO:root:At the start of the epoch: mem (CPU python)=55023.6640625MB; mem (CPU total)=54793.59375MB
INFO:root:[   88] Training loss: 0.62153083, Validation loss: 0.61284749, Gradient norm: 0.05666412
INFO:root:At the start of the epoch: mem (CPU python)=55061.74609375MB; mem (CPU total)=54832.2890625MB
INFO:root:[   89] Training loss: 0.62134182, Validation loss: 0.61145290, Gradient norm: 0.05976021
INFO:root:At the start of the epoch: mem (CPU python)=55099.84375MB; mem (CPU total)=54868.1953125MB
INFO:root:[   90] Training loss: 0.62091324, Validation loss: 0.61168518, Gradient norm: 0.05475395
INFO:root:At the start of the epoch: mem (CPU python)=55137.95703125MB; mem (CPU total)=54906.1171875MB
INFO:root:[   91] Training loss: 0.62074963, Validation loss: 0.61386757, Gradient norm: 0.05487208
INFO:root:At the start of the epoch: mem (CPU python)=55176.05078125MB; mem (CPU total)=54946.32421875MB
INFO:root:[   92] Training loss: 0.62073273, Validation loss: 0.61050497, Gradient norm: 0.05969566
INFO:root:At the start of the epoch: mem (CPU python)=55214.1484375MB; mem (CPU total)=54982.57421875MB
INFO:root:[   93] Training loss: 0.62043223, Validation loss: 0.61175481, Gradient norm: 0.05378449
INFO:root:At the start of the epoch: mem (CPU python)=55252.234375MB; mem (CPU total)=55020.1015625MB
INFO:root:[   94] Training loss: 0.62034701, Validation loss: 0.60999091, Gradient norm: 0.04981314
INFO:root:At the start of the epoch: mem (CPU python)=55290.33203125MB; mem (CPU total)=55058.78125MB
INFO:root:[   95] Training loss: 0.62022510, Validation loss: 0.61074033, Gradient norm: 0.06004121
INFO:root:At the start of the epoch: mem (CPU python)=55328.4296875MB; mem (CPU total)=55096.5234375MB
INFO:root:[   96] Training loss: 0.62006479, Validation loss: 0.61104597, Gradient norm: 0.06232140
INFO:root:At the start of the epoch: mem (CPU python)=55366.45703125MB; mem (CPU total)=55136.15234375MB
INFO:root:[   97] Training loss: 0.61971478, Validation loss: 0.61104947, Gradient norm: 0.05575649
INFO:root:At the start of the epoch: mem (CPU python)=55404.5703125MB; mem (CPU total)=55173.1953125MB
INFO:root:[   98] Training loss: 0.61930209, Validation loss: 0.61185131, Gradient norm: 0.05462053
INFO:root:At the start of the epoch: mem (CPU python)=55442.69921875MB; mem (CPU total)=55214.3046875MB
INFO:root:[   99] Training loss: 0.61916527, Validation loss: 0.61198654, Gradient norm: 0.05584188
INFO:root:At the start of the epoch: mem (CPU python)=55480.81640625MB; mem (CPU total)=55253.6796875MB
INFO:root:[  100] Training loss: 0.61896961, Validation loss: 0.61009484, Gradient norm: 0.05565140
INFO:root:At the start of the epoch: mem (CPU python)=55518.91796875MB; mem (CPU total)=55292.0703125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  101] Training loss: 0.61898366, Validation loss: 0.61029253, Gradient norm: 0.06560343
INFO:root:At the start of the epoch: mem (CPU python)=55556.9609375MB; mem (CPU total)=55330.19921875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  102] Training loss: 0.61779905, Validation loss: 0.60897421, Gradient norm: 0.04820162
INFO:root:At the start of the epoch: mem (CPU python)=55595.10546875MB; mem (CPU total)=55368.359375MB
INFO:root:[  103] Training loss: 0.61718614, Validation loss: 0.60957728, Gradient norm: 0.04764207
INFO:root:At the start of the epoch: mem (CPU python)=55633.1953125MB; mem (CPU total)=55408.03125MB
INFO:root:[  104] Training loss: 0.61728232, Validation loss: 0.60951065, Gradient norm: 0.05409521
INFO:root:At the start of the epoch: mem (CPU python)=55671.40625MB; mem (CPU total)=55447.65234375MB
INFO:root:[  105] Training loss: 0.61723754, Validation loss: 0.60893702, Gradient norm: 0.05050414
INFO:root:At the start of the epoch: mem (CPU python)=55709.3046875MB; mem (CPU total)=55485.2421875MB
INFO:root:[  106] Training loss: 0.61702786, Validation loss: 0.60977178, Gradient norm: 0.04938919
INFO:root:At the start of the epoch: mem (CPU python)=55747.3671875MB; mem (CPU total)=55523.6328125MB
INFO:root:[  107] Training loss: 0.61689798, Validation loss: 0.60842164, Gradient norm: 0.04638188
INFO:root:At the start of the epoch: mem (CPU python)=55785.515625MB; mem (CPU total)=55562.7578125MB
INFO:root:[  108] Training loss: 0.61704495, Validation loss: 0.60845995, Gradient norm: 0.04689278
INFO:root:At the start of the epoch: mem (CPU python)=55823.5625MB; mem (CPU total)=55600.8984375MB
INFO:root:[  109] Training loss: 0.61687982, Validation loss: 0.60904322, Gradient norm: 0.04854824
INFO:root:At the start of the epoch: mem (CPU python)=55861.71875MB; mem (CPU total)=55633.6875MB
INFO:root:[  110] Training loss: 0.61685807, Validation loss: 0.60880880, Gradient norm: 0.04926266
INFO:root:At the start of the epoch: mem (CPU python)=55899.765625MB; mem (CPU total)=55671.76953125MB
INFO:root:[  111] Training loss: 0.61687769, Validation loss: 0.60805614, Gradient norm: 0.05125647
INFO:root:At the start of the epoch: mem (CPU python)=55937.8984375MB; mem (CPU total)=55709.69921875MB
INFO:root:[  112] Training loss: 0.61660963, Validation loss: 0.60874538, Gradient norm: 0.04843904
INFO:root:At the start of the epoch: mem (CPU python)=55976.08984375MB; mem (CPU total)=55748.578125MB
INFO:root:[  113] Training loss: 0.61661654, Validation loss: 0.60951185, Gradient norm: 0.05126079
INFO:root:At the start of the epoch: mem (CPU python)=56014.03515625MB; mem (CPU total)=55786.71875MB
INFO:root:[  114] Training loss: 0.61667080, Validation loss: 0.60872148, Gradient norm: 0.05023699
INFO:root:At the start of the epoch: mem (CPU python)=56052.23828125MB; mem (CPU total)=55827.6328125MB
INFO:root:[  115] Training loss: 0.61673263, Validation loss: 0.60848397, Gradient norm: 0.04621575
INFO:root:At the start of the epoch: mem (CPU python)=56090.26953125MB; mem (CPU total)=55865.52734375MB
INFO:root:[  116] Training loss: 0.61651803, Validation loss: 0.60868009, Gradient norm: 0.04617228
INFO:root:At the start of the epoch: mem (CPU python)=56128.37109375MB; mem (CPU total)=55904.1640625MB
INFO:root:[  117] Training loss: 0.61637221, Validation loss: 0.60860425, Gradient norm: 0.04507783
INFO:root:At the start of the epoch: mem (CPU python)=56166.4765625MB; mem (CPU total)=55942.30859375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  118] Training loss: 0.61645995, Validation loss: 0.60869067, Gradient norm: 0.04919610
INFO:root:At the start of the epoch: mem (CPU python)=56204.55859375MB; mem (CPU total)=55976.58203125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  119] Training loss: 0.61620102, Validation loss: 0.60874054, Gradient norm: 0.04352635
INFO:root:At the start of the epoch: mem (CPU python)=56242.84765625MB; mem (CPU total)=56017.1953125MB
INFO:root:[  120] Training loss: 0.61608836, Validation loss: 0.60791170, Gradient norm: 0.04406405
INFO:root:At the start of the epoch: mem (CPU python)=56280.94140625MB; mem (CPU total)=56055.39453125MB
INFO:root:[  121] Training loss: 0.61606212, Validation loss: 0.60770074, Gradient norm: 0.04477288
INFO:root:At the start of the epoch: mem (CPU python)=56318.90625MB; mem (CPU total)=56093.5625MB
INFO:root:[  122] Training loss: 0.61608884, Validation loss: 0.60909625, Gradient norm: 0.04549340
INFO:root:At the start of the epoch: mem (CPU python)=56356.98828125MB; mem (CPU total)=56132.4765625MB
INFO:root:[  123] Training loss: 0.61613525, Validation loss: 0.60838559, Gradient norm: 0.04470964
INFO:root:At the start of the epoch: mem (CPU python)=56395.140625MB; mem (CPU total)=56170.37109375MB
INFO:root:[  124] Training loss: 0.61577242, Validation loss: 0.60807033, Gradient norm: 0.04540509
INFO:root:At the start of the epoch: mem (CPU python)=56433.2578125MB; mem (CPU total)=56209.19921875MB
INFO:root:[  125] Training loss: 0.61587953, Validation loss: 0.60766911, Gradient norm: 0.04425541
INFO:root:At the start of the epoch: mem (CPU python)=56471.23046875MB; mem (CPU total)=56246.8359375MB
INFO:root:[  126] Training loss: 0.61578473, Validation loss: 0.60839719, Gradient norm: 0.04550678
INFO:root:At the start of the epoch: mem (CPU python)=56509.33984375MB; mem (CPU total)=56285.47265625MB
INFO:root:[  127] Training loss: 0.61572968, Validation loss: 0.60804094, Gradient norm: 0.04521512
INFO:root:At the start of the epoch: mem (CPU python)=56547.46484375MB; mem (CPU total)=56323.65625MB
INFO:root:[  128] Training loss: 0.61593230, Validation loss: 0.60830849, Gradient norm: 0.04324631
INFO:root:At the start of the epoch: mem (CPU python)=56585.53515625MB; mem (CPU total)=56363.28515625MB
INFO:root:[  129] Training loss: 0.61578296, Validation loss: 0.60863246, Gradient norm: 0.04430771
INFO:root:At the start of the epoch: mem (CPU python)=56623.62890625MB; mem (CPU total)=56402.015625MB
INFO:root:[  130] Training loss: 0.61586252, Validation loss: 0.60821010, Gradient norm: 0.04550147
INFO:root:At the start of the epoch: mem (CPU python)=56661.703125MB; mem (CPU total)=56440.15234375MB
INFO:root:[  131] Training loss: 0.61573015, Validation loss: 0.60860078, Gradient norm: 0.04333282
INFO:root:At the start of the epoch: mem (CPU python)=56699.81640625MB; mem (CPU total)=56480.04296875MB
INFO:root:[  132] Training loss: 0.61598777, Validation loss: 0.60764146, Gradient norm: 0.04457297
INFO:root:At the start of the epoch: mem (CPU python)=56737.94140625MB; mem (CPU total)=56517.76953125MB
INFO:root:[  133] Training loss: 0.61584005, Validation loss: 0.60825101, Gradient norm: 0.04515493
INFO:root:At the start of the epoch: mem (CPU python)=56776.01171875MB; mem (CPU total)=56556.234375MB
INFO:root:[  134] Training loss: 0.61568543, Validation loss: 0.60804372, Gradient norm: 0.04692165
INFO:root:At the start of the epoch: mem (CPU python)=56814.10546875MB; mem (CPU total)=56595.3984375MB
INFO:root:[  135] Training loss: 0.61585886, Validation loss: 0.60829145, Gradient norm: 0.04650939
INFO:root:At the start of the epoch: mem (CPU python)=56852.2109375MB; mem (CPU total)=56633.80078125MB
INFO:root:[  136] Training loss: 0.61569233, Validation loss: 0.60791717, Gradient norm: 0.04533382
INFO:root:At the start of the epoch: mem (CPU python)=56890.296875MB; mem (CPU total)=56663.29296875MB
INFO:root:[  137] Training loss: 0.61576139, Validation loss: 0.60756582, Gradient norm: 0.04576001
INFO:root:At the start of the epoch: mem (CPU python)=56928.38671875MB; mem (CPU total)=56701.7265625MB
INFO:root:[  138] Training loss: 0.61586968, Validation loss: 0.60739771, Gradient norm: 0.04439790
INFO:root:At the start of the epoch: mem (CPU python)=56966.4765625MB; mem (CPU total)=56739.23828125MB
INFO:root:[  139] Training loss: 0.61590412, Validation loss: 0.60837055, Gradient norm: 0.04390519
INFO:root:At the start of the epoch: mem (CPU python)=57004.5234375MB; mem (CPU total)=56777.96875MB
INFO:root:[  140] Training loss: 0.61562832, Validation loss: 0.60785419, Gradient norm: 0.04496570
INFO:root:At the start of the epoch: mem (CPU python)=57042.6640625MB; mem (CPU total)=56816.5234375MB
INFO:root:[  141] Training loss: 0.61568482, Validation loss: 0.60931479, Gradient norm: 0.04500369
INFO:root:At the start of the epoch: mem (CPU python)=57080.95703125MB; mem (CPU total)=56854.2578125MB
INFO:root:[  142] Training loss: 0.61549187, Validation loss: 0.60744150, Gradient norm: 0.04479900
INFO:root:At the start of the epoch: mem (CPU python)=57119.046875MB; mem (CPU total)=56891.09765625MB
INFO:root:[  143] Training loss: 0.61548799, Validation loss: 0.60864748, Gradient norm: 0.04633490
INFO:root:At the start of the epoch: mem (CPU python)=57156.953125MB; mem (CPU total)=56929.5MB
INFO:root:[  144] Training loss: 0.61561950, Validation loss: 0.60841118, Gradient norm: 0.04369204
INFO:root:At the start of the epoch: mem (CPU python)=57195.2421875MB; mem (CPU total)=56969.94921875MB
INFO:root:[  145] Training loss: 0.61544783, Validation loss: 0.60832865, Gradient norm: 0.04506587
INFO:root:At the start of the epoch: mem (CPU python)=57233.13671875MB; mem (CPU total)=57005.18359375MB
INFO:root:[  146] Training loss: 0.61565344, Validation loss: 0.60759287, Gradient norm: 0.04600386
INFO:root:At the start of the epoch: mem (CPU python)=57271.41796875MB; mem (CPU total)=57044.09375MB
INFO:root:[  147] Training loss: 0.61564692, Validation loss: 0.60853811, Gradient norm: 0.04590640
INFO:root:At the start of the epoch: mem (CPU python)=57309.5234375MB; mem (CPU total)=57081.76953125MB
INFO:root:EP 147: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=57347.38671875MB; mem (CPU total)=57123.1171875MB
INFO:root:Training the model took 16672.95s.
INFO:root:Emptying the cuda cache took 0.005s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84836
INFO:root:EnergyScoreTrain: 0.59725
INFO:root:CRPSTrain: 0.463
INFO:root:Gaussian NLLTrain: 1.18787
INFO:root:CoverageTrain: 0.9526
INFO:root:IntervalWidthTrain: 3.28019
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86355
INFO:root:EnergyScoreValidation: 0.60784
INFO:root:CRPSValidation: 0.47207
INFO:root:Gaussian NLLValidation: 1.2083
INFO:root:CoverageValidation: 0.94782
INFO:root:IntervalWidthValidation: 3.28253
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86535
INFO:root:EnergyScoreTest: 0.60909
INFO:root:CRPSTest: 0.47331
INFO:root:Gaussian NLLTest: 1.21123
INFO:root:CoverageTest: 0.94741
INFO:root:IntervalWidthTest: 3.28646
INFO:root:After validation: mem (CPU python)=57474.796875MB; mem (CPU total)=57168.87109375MB
