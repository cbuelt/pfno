INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=567.3203125MB; mem (CPU total)=1060.62890625MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples4.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12446.0234375MB; mem (CPU total)=1069.859375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=12446.0234375MB; mem (CPU total)=1069.82421875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12446.0234375MB; mem (CPU total)=2431.41015625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=2442.19140625MB
INFO:root:[    1] Training loss: 0.72489599, Validation loss: 0.72048462, Gradient norm: 0.01864508
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4165.2890625MB
INFO:root:[    2] Training loss: 0.71986393, Validation loss: 0.71906884, Gradient norm: 0.00557695
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4229.2421875MB
INFO:root:[    3] Training loss: 0.71830047, Validation loss: 0.71511244, Gradient norm: 0.00852215
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4267.26171875MB
INFO:root:[    4] Training loss: 0.71253379, Validation loss: 0.70568612, Gradient norm: 0.02142990
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4305.01171875MB
INFO:root:[    5] Training loss: 0.70585136, Validation loss: 0.69905494, Gradient norm: 0.02794227
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4343.62890625MB
INFO:root:[    6] Training loss: 0.70007775, Validation loss: 0.69082752, Gradient norm: 0.04088009
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4381.28515625MB
INFO:root:[    7] Training loss: 0.69408687, Validation loss: 0.68360192, Gradient norm: 0.04046331
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4418.89453125MB
INFO:root:[    8] Training loss: 0.68874893, Validation loss: 0.67835516, Gradient norm: 0.04624814
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4457.22265625MB
INFO:root:[    9] Training loss: 0.68430471, Validation loss: 0.67272415, Gradient norm: 0.04051595
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4495.10546875MB
INFO:root:[   10] Training loss: 0.68057660, Validation loss: 0.66920696, Gradient norm: 0.04375106
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4533.15234375MB
INFO:root:[   11] Training loss: 0.67721328, Validation loss: 0.66531582, Gradient norm: 0.04610906
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4571.72265625MB
INFO:root:[   12] Training loss: 0.67430102, Validation loss: 0.66288871, Gradient norm: 0.04261522
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4610.08984375MB
INFO:root:[   13] Training loss: 0.67164688, Validation loss: 0.65980977, Gradient norm: 0.04352560
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4648.19921875MB
INFO:root:[   14] Training loss: 0.66969640, Validation loss: 0.65718068, Gradient norm: 0.04944550
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4685.859375MB
INFO:root:[   15] Training loss: 0.66758098, Validation loss: 0.65502378, Gradient norm: 0.04420500
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4724.49609375MB
INFO:root:[   16] Training loss: 0.66605396, Validation loss: 0.65355860, Gradient norm: 0.05340643
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4762.83984375MB
INFO:root:[   17] Training loss: 0.66449526, Validation loss: 0.65184168, Gradient norm: 0.05213585
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4800.7265625MB
INFO:root:[   18] Training loss: 0.66303913, Validation loss: 0.65042332, Gradient norm: 0.05718746
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4838.625MB
INFO:root:[   19] Training loss: 0.66189169, Validation loss: 0.64876683, Gradient norm: 0.06170894
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4878.13671875MB
INFO:root:[   20] Training loss: 0.66106762, Validation loss: 0.64819602, Gradient norm: 0.06693000
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4916.6171875MB
INFO:root:[   21] Training loss: 0.65998841, Validation loss: 0.64706123, Gradient norm: 0.07207611
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4955.1484375MB
INFO:root:[   22] Training loss: 0.65907881, Validation loss: 0.64557619, Gradient norm: 0.07566362
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=4992.875MB
INFO:root:[   23] Training loss: 0.65802616, Validation loss: 0.64489050, Gradient norm: 0.08778815
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5031.21484375MB
INFO:root:[   24] Training loss: 0.65746808, Validation loss: 0.64418892, Gradient norm: 0.10902184
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5069.4921875MB
INFO:root:[   25] Training loss: 0.65685443, Validation loss: 0.64488850, Gradient norm: 0.08552989
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5108.5078125MB
INFO:root:[   26] Training loss: 0.65609204, Validation loss: 0.64367174, Gradient norm: 0.11919346
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5145.80078125MB
INFO:root:[   27] Training loss: 0.65553096, Validation loss: 0.64361004, Gradient norm: 0.14599848
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5184.1796875MB
INFO:root:[   28] Training loss: 0.65480418, Validation loss: 0.64396165, Gradient norm: 0.15225235
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5223.05078125MB
INFO:root:[   29] Training loss: 0.65429451, Validation loss: 0.64487724, Gradient norm: 0.14427645
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5260.92578125MB
INFO:root:[   30] Training loss: 0.65370541, Validation loss: 0.64371662, Gradient norm: 0.15645494
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5299.0625MB
INFO:root:[   31] Training loss: 0.65302419, Validation loss: 0.64411855, Gradient norm: 0.19429757
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5336.9375MB
INFO:root:[   32] Training loss: 0.65261810, Validation loss: 0.64287601, Gradient norm: 0.19015173
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5374.06640625MB
INFO:root:[   33] Training loss: 0.65228684, Validation loss: 0.64505267, Gradient norm: 0.22952851
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5412.8984375MB
INFO:root:[   34] Training loss: 0.65170918, Validation loss: 0.64670767, Gradient norm: 0.21986794
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5450.78125MB
INFO:root:[   35] Training loss: 0.65133718, Validation loss: 0.64438749, Gradient norm: 0.26469319
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5488.87890625MB
INFO:root:[   36] Training loss: 0.65105823, Validation loss: 0.64263575, Gradient norm: 0.27748575
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5526.75390625MB
INFO:root:[   37] Training loss: 0.65064430, Validation loss: 0.64324600, Gradient norm: 0.30983961
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5565.11328125MB
INFO:root:[   38] Training loss: 0.65036763, Validation loss: 0.64466797, Gradient norm: 0.34179935
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5603.2421875MB
INFO:root:[   39] Training loss: 0.64968802, Validation loss: 0.64132801, Gradient norm: 0.32196476
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5641.15234375MB
INFO:root:[   40] Training loss: 0.64948952, Validation loss: 0.64325509, Gradient norm: 0.35761378
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5679.7578125MB
INFO:root:[   41] Training loss: 0.64923241, Validation loss: 0.64531386, Gradient norm: 0.42606752
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5717.625MB
INFO:root:[   42] Training loss: 0.64893034, Validation loss: 0.63896846, Gradient norm: 0.43911329
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5755.74609375MB
INFO:root:[   43] Training loss: 0.64877919, Validation loss: 0.64277942, Gradient norm: 0.47496753
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5794.625MB
INFO:root:[   44] Training loss: 0.64814328, Validation loss: 0.64543029, Gradient norm: 0.46255848
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5832.765625MB
INFO:root:[   45] Training loss: 0.64793010, Validation loss: 0.64604867, Gradient norm: 0.53392883
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5870.94140625MB
INFO:root:[   46] Training loss: 0.64753284, Validation loss: 0.64148697, Gradient norm: 0.52598897
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5909.07421875MB
INFO:root:[   47] Training loss: 0.64745012, Validation loss: 0.64259851, Gradient norm: 0.60797724
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5947.19921875MB
INFO:root:[   48] Training loss: 0.64721466, Validation loss: 0.64061954, Gradient norm: 0.67666717
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=5985.31640625MB
INFO:root:[   49] Training loss: 0.64676859, Validation loss: 0.63695097, Gradient norm: 0.62396315
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6024.328125MB
INFO:root:[   50] Training loss: 0.64675250, Validation loss: 0.63747248, Gradient norm: 0.74972329
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6062.90234375MB
INFO:root:[   51] Training loss: 0.64643332, Validation loss: 0.64005763, Gradient norm: 0.76576614
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6100.9375MB
INFO:root:[   52] Training loss: 0.64627994, Validation loss: 0.63583180, Gradient norm: 0.78552673
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6138.5234375MB
INFO:root:[   53] Training loss: 0.64639194, Validation loss: 0.63435397, Gradient norm: 1.11986458
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6176.78125MB
INFO:root:[   54] Training loss: 0.64584733, Validation loss: 0.63445240, Gradient norm: 0.89935116
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6215.64453125MB
INFO:root:[   55] Training loss: 0.64581848, Validation loss: 0.63509729, Gradient norm: 0.89438253
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6253.27734375MB
INFO:root:[   56] Training loss: 0.64556025, Validation loss: 0.63276531, Gradient norm: 1.01056834
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6290.89453125MB
INFO:root:[   57] Training loss: 0.64521688, Validation loss: 0.63341979, Gradient norm: 0.98655309
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6329.0078125MB
INFO:root:[   58] Training loss: 0.64542320, Validation loss: 0.63134393, Gradient norm: 1.18480103
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6366.68359375MB
INFO:root:[   59] Training loss: 0.64527125, Validation loss: 0.63237141, Gradient norm: 1.30216161
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6405.09765625MB
INFO:root:[   60] Training loss: 0.64519519, Validation loss: 0.63093470, Gradient norm: 1.65969734
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6442.98046875MB
INFO:root:[   61] Training loss: 0.64487987, Validation loss: 0.63212115, Gradient norm: 1.18817389
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6481.32421875MB
INFO:root:[   62] Training loss: 0.64500694, Validation loss: 0.62944894, Gradient norm: 1.40527826
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6519.22265625MB
INFO:root:[   63] Training loss: 0.64461173, Validation loss: 0.62926536, Gradient norm: 1.73828974
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6557.66015625MB
INFO:root:[   64] Training loss: 0.64472612, Validation loss: 0.62838690, Gradient norm: 1.66271872
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6595.7890625MB
INFO:root:[   65] Training loss: 0.64446130, Validation loss: 0.63116876, Gradient norm: 1.86638304
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6634.65234375MB
INFO:root:[   66] Training loss: 0.64451235, Validation loss: 0.63065660, Gradient norm: 1.84941717
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6672.78125MB
INFO:root:[   67] Training loss: 0.64446201, Validation loss: 0.62916428, Gradient norm: 1.89279879
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6710.91015625MB
INFO:root:[   68] Training loss: 0.64434537, Validation loss: 0.62924129, Gradient norm: 2.01255410
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6749.2734375MB
INFO:root:[   69] Training loss: 0.64422928, Validation loss: 0.62782851, Gradient norm: 2.03071441
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6786.6640625MB
INFO:root:[   70] Training loss: 0.64425094, Validation loss: 0.62860327, Gradient norm: 1.82861858
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6825.296875MB
INFO:root:[   71] Training loss: 0.64410620, Validation loss: 0.62773672, Gradient norm: 2.14543843
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6862.91015625MB
INFO:root:[   72] Training loss: 0.64403292, Validation loss: 0.62902237, Gradient norm: 2.06879294
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6901.98046875MB
INFO:root:[   73] Training loss: 0.64390279, Validation loss: 0.62757711, Gradient norm: 2.43509473
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6939.71484375MB
INFO:root:[   74] Training loss: 0.64389017, Validation loss: 0.62870621, Gradient norm: 2.05043005
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=6978.58203125MB
INFO:root:[   75] Training loss: 0.64383229, Validation loss: 0.62834979, Gradient norm: 2.42550127
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7016.6953125MB
INFO:root:[   76] Training loss: 0.64388710, Validation loss: 0.62762095, Gradient norm: 2.36042995
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7054.5625MB
INFO:root:[   77] Training loss: 0.64372099, Validation loss: 0.62831879, Gradient norm: 2.73963689
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7092.671875MB
INFO:root:[   78] Training loss: 0.64369412, Validation loss: 0.62828557, Gradient norm: 2.66527573
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7130.7890625MB
INFO:root:[   79] Training loss: 0.64367767, Validation loss: 0.62761795, Gradient norm: 2.83800489
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7168.80078125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   80] Training loss: 0.64352642, Validation loss: 0.62687985, Gradient norm: 2.93458399
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7206.78515625MB
INFO:root:[   81] Training loss: 0.64261455, Validation loss: 0.62700595, Gradient norm: 1.69493911
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7245.34765625MB
INFO:root:[   82] Training loss: 0.64246938, Validation loss: 0.62650980, Gradient norm: 1.93399634
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7283.51953125MB
INFO:root:[   83] Training loss: 0.64242171, Validation loss: 0.62681331, Gradient norm: 2.02963340
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7321.8671875MB
INFO:root:[   84] Training loss: 0.64228866, Validation loss: 0.62668249, Gradient norm: 2.12255651
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7361.12890625MB
INFO:root:[   85] Training loss: 0.64242833, Validation loss: 0.62668511, Gradient norm: 2.17253874
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7398.87109375MB
INFO:root:[   86] Training loss: 0.64240174, Validation loss: 0.62628756, Gradient norm: 2.34251870
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7436.65625MB
INFO:root:[   87] Training loss: 0.64238477, Validation loss: 0.62718090, Gradient norm: 2.40161361
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7475.38671875MB
INFO:root:[   88] Training loss: 0.64249583, Validation loss: 0.62670216, Gradient norm: 2.55489799
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7513.84375MB
INFO:root:[   89] Training loss: 0.64223061, Validation loss: 0.62684817, Gradient norm: 2.21096880
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7551.78515625MB
INFO:root:[   90] Training loss: 0.64249952, Validation loss: 0.62690698, Gradient norm: 2.70745184
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7589.859375MB
INFO:root:[   91] Training loss: 0.64247083, Validation loss: 0.62551484, Gradient norm: 3.07893829
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7627.25390625MB
INFO:root:[   92] Training loss: 0.64213485, Validation loss: 0.62584032, Gradient norm: 3.06650265
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7666.12109375MB
INFO:root:[   93] Training loss: 0.64239975, Validation loss: 0.62635610, Gradient norm: 3.06909378
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7704.22265625MB
INFO:root:[   94] Training loss: 0.64219445, Validation loss: 0.62641650, Gradient norm: 3.22663954
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7742.328125MB
INFO:root:[   95] Training loss: 0.64211980, Validation loss: 0.62696928, Gradient norm: 2.99276290
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7780.44140625MB
INFO:root:[   96] Training loss: 0.64224383, Validation loss: 0.62636944, Gradient norm: 2.96748526
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7818.5546875MB
INFO:root:[   97] Training loss: 0.64216667, Validation loss: 0.62696587, Gradient norm: 3.44755089
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7856.66015625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   98] Training loss: 0.64215748, Validation loss: 0.62688825, Gradient norm: 3.54451214
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7895.015625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   99] Training loss: 0.64156926, Validation loss: 0.62552507, Gradient norm: 2.11987682
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7933.08203125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  100] Training loss: 0.64136268, Validation loss: 0.62527957, Gradient norm: 1.51349370
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=7970.71484375MB
INFO:root:[  101] Training loss: 0.64119753, Validation loss: 0.62539560, Gradient norm: 1.39124967
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8009.109375MB
INFO:root:[  102] Training loss: 0.64123956, Validation loss: 0.62530648, Gradient norm: 1.50476251
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8048.1328125MB
INFO:root:[  103] Training loss: 0.64122834, Validation loss: 0.62569853, Gradient norm: 1.37913773
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8086.27734375MB
INFO:root:[  104] Training loss: 0.64107798, Validation loss: 0.62529582, Gradient norm: 1.47683945
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8124.41015625MB
INFO:root:[  105] Training loss: 0.64112571, Validation loss: 0.62509146, Gradient norm: 1.41820481
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8162.58203125MB
INFO:root:[  106] Training loss: 0.64107701, Validation loss: 0.62467183, Gradient norm: 1.47089528
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8201.1953125MB
INFO:root:[  107] Training loss: 0.64115771, Validation loss: 0.62542229, Gradient norm: 1.51817083
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8239.76953125MB
INFO:root:[  108] Training loss: 0.64115437, Validation loss: 0.62573112, Gradient norm: 1.51839853
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8277.88671875MB
INFO:root:[  109] Training loss: 0.64121743, Validation loss: 0.62557298, Gradient norm: 1.61924203
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8316.24609375MB
INFO:root:[  110] Training loss: 0.64114147, Validation loss: 0.62495476, Gradient norm: 1.57915733
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8354.38671875MB
INFO:root:[  111] Training loss: 0.64109632, Validation loss: 0.62585595, Gradient norm: 1.65076199
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8392.5078125MB
INFO:root:[  112] Training loss: 0.64104522, Validation loss: 0.62523156, Gradient norm: 1.62453915
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8430.63671875MB
INFO:root:[  113] Training loss: 0.64094469, Validation loss: 0.62511484, Gradient norm: 1.52194167
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8469.99609375MB
INFO:root:[  114] Training loss: 0.64115394, Validation loss: 0.62520350, Gradient norm: 1.68694967
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8508.06640625MB
INFO:root:[  115] Training loss: 0.64119539, Validation loss: 0.62475959, Gradient norm: 1.61426148
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8546.7421875MB
INFO:root:EP 115: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12446.0234375MB; mem (CPU total)=8584.85546875MB
INFO:root:Training the model took 4849.68s.
INFO:root:Emptying the cuda cache took 0.036s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.88265
INFO:root:EnergyScoreTrain: 0.62134
INFO:root:CRPSTrain: 0.53322
INFO:root:Gaussian NLLTrain: 20406081003.51998
INFO:root:CoverageTrain: 0.60914
INFO:root:IntervalWidthTrain: 2.51591
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88823
INFO:root:EnergyScoreValidation: 0.62535
INFO:root:CRPSValidation: 0.5381
INFO:root:Gaussian NLLValidation: 21561404001.84889
INFO:root:CoverageValidation: 0.6075
INFO:root:IntervalWidthValidation: 2.51412
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8893
INFO:root:EnergyScoreTest: 0.62611
INFO:root:CRPSTest: 0.53908
INFO:root:Gaussian NLLTest: 21489283874.816
INFO:root:CoverageTest: 0.6078
INFO:root:IntervalWidthTest: 2.51603
INFO:root:After validation: mem (CPU python)=12446.0234375MB; mem (CPU total)=8629.71484375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=12446.0234375MB; mem (CPU total)=8629.7265625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12446.0234375MB; mem (CPU total)=8629.97265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8629.97265625MB
INFO:root:[    1] Training loss: 0.72526770, Validation loss: 0.72001738, Gradient norm: 0.02240429
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8670.80078125MB
INFO:root:[    2] Training loss: 0.71988802, Validation loss: 0.71859463, Gradient norm: 0.00613714
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8709.171875MB
INFO:root:[    3] Training loss: 0.71775545, Validation loss: 0.71352429, Gradient norm: 0.01012475
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8747.55859375MB
INFO:root:[    4] Training loss: 0.71025319, Validation loss: 0.70211370, Gradient norm: 0.02504961
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8785.453125MB
INFO:root:[    5] Training loss: 0.70267610, Validation loss: 0.69448999, Gradient norm: 0.04052102
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8823.80859375MB
INFO:root:[    6] Training loss: 0.69721569, Validation loss: 0.68862719, Gradient norm: 0.04860250
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8862.171875MB
INFO:root:[    7] Training loss: 0.69289430, Validation loss: 0.68370631, Gradient norm: 0.04699922
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8900.2578125MB
INFO:root:[    8] Training loss: 0.68916327, Validation loss: 0.67985664, Gradient norm: 0.05828888
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8938.43359375MB
INFO:root:[    9] Training loss: 0.68536652, Validation loss: 0.67495154, Gradient norm: 0.06082349
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=8976.734375MB
INFO:root:[   10] Training loss: 0.68170069, Validation loss: 0.67029863, Gradient norm: 0.05983270
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9014.890625MB
INFO:root:[   11] Training loss: 0.67838734, Validation loss: 0.66686561, Gradient norm: 0.07090492
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9052.71484375MB
INFO:root:[   12] Training loss: 0.67574159, Validation loss: 0.66444651, Gradient norm: 0.08660909
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9090.80078125MB
INFO:root:[   13] Training loss: 0.67335239, Validation loss: 0.66200906, Gradient norm: 0.08302286
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9129.01953125MB
INFO:root:[   14] Training loss: 0.67128349, Validation loss: 0.66070959, Gradient norm: 0.08151092
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9167.21484375MB
INFO:root:[   15] Training loss: 0.66958915, Validation loss: 0.65912970, Gradient norm: 0.09346215
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9205.6015625MB
INFO:root:[   16] Training loss: 0.66832320, Validation loss: 0.65702153, Gradient norm: 0.11908131
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9243.703125MB
INFO:root:[   17] Training loss: 0.66691763, Validation loss: 0.65686998, Gradient norm: 0.11974496
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9281.75390625MB
INFO:root:[   18] Training loss: 0.66567251, Validation loss: 0.65498066, Gradient norm: 0.14143732
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9320.08984375MB
INFO:root:[   19] Training loss: 0.66467694, Validation loss: 0.65295757, Gradient norm: 0.16569239
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9358.2578125MB
INFO:root:[   20] Training loss: 0.66349107, Validation loss: 0.65622616, Gradient norm: 0.18087783
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9396.6328125MB
INFO:root:[   21] Training loss: 0.66265376, Validation loss: 0.65834336, Gradient norm: 0.19516676
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9435.0MB
INFO:root:[   22] Training loss: 0.66167183, Validation loss: 0.65536344, Gradient norm: 0.19718426
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9473.61328125MB
INFO:root:[   23] Training loss: 0.66080578, Validation loss: 0.66394444, Gradient norm: 0.24323221
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9511.9921875MB
INFO:root:[   24] Training loss: 0.66006862, Validation loss: 0.65942687, Gradient norm: 0.25601632
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9550.1015625MB
INFO:root:[   25] Training loss: 0.65932716, Validation loss: 0.65529697, Gradient norm: 0.29120831
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9589.00390625MB
INFO:root:[   26] Training loss: 0.65855280, Validation loss: 0.65656659, Gradient norm: 0.31609790
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9627.06640625MB
INFO:root:[   27] Training loss: 0.65771586, Validation loss: 0.66112840, Gradient norm: 0.29246828
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9665.234375MB
INFO:root:[   28] Training loss: 0.65697540, Validation loss: 0.66596558, Gradient norm: 0.31721829
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9703.37109375MB
INFO:root:[   29] Training loss: 0.65649573, Validation loss: 0.66568850, Gradient norm: 0.38014911
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9741.5078125MB
INFO:root:[   30] Training loss: 0.65566755, Validation loss: 0.66772957, Gradient norm: 0.36189090
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9779.64453125MB
INFO:root:[   31] Training loss: 0.65513271, Validation loss: 0.66587040, Gradient norm: 0.35931971
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9817.7734375MB
INFO:root:[   32] Training loss: 0.65447213, Validation loss: 0.67266276, Gradient norm: 0.44814798
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9855.8984375MB
INFO:root:[   33] Training loss: 0.65406317, Validation loss: 0.66214465, Gradient norm: 0.50676650
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9894.0234375MB
INFO:root:[   34] Training loss: 0.65344343, Validation loss: 0.65922917, Gradient norm: 0.50403030
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9932.13671875MB
INFO:root:[   35] Training loss: 0.65283649, Validation loss: 0.66623252, Gradient norm: 0.45410847
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=9970.00390625MB
INFO:root:[   36] Training loss: 0.65240173, Validation loss: 0.67260773, Gradient norm: 0.53060849
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10008.37109375MB
INFO:root:[   37] Training loss: 0.65187815, Validation loss: 0.66520910, Gradient norm: 0.46832843
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10046.75390625MB
INFO:root:[   38] Training loss: 0.65148994, Validation loss: 0.66202324, Gradient norm: 0.67265314
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10084.65625MB
INFO:root:[   39] Training loss: 0.65082703, Validation loss: 0.66541110, Gradient norm: 0.51512702
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10122.77734375MB
INFO:root:[   40] Training loss: 0.65063906, Validation loss: 0.66367441, Gradient norm: 0.76338202
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10160.90625MB
INFO:root:[   41] Training loss: 0.65000080, Validation loss: 0.66048349, Gradient norm: 0.55823103
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10199.03515625MB
INFO:root:[   42] Training loss: 0.64966209, Validation loss: 0.65310336, Gradient norm: 0.74754616
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10237.15625MB
INFO:root:[   43] Training loss: 0.64907747, Validation loss: 0.65273147, Gradient norm: 0.63266886
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10275.34375MB
INFO:root:[   44] Training loss: 0.64902174, Validation loss: 0.65310557, Gradient norm: 0.83026714
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10314.2109375MB
INFO:root:[   45] Training loss: 0.64838043, Validation loss: 0.66331558, Gradient norm: 0.62332664
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10352.375MB
INFO:root:[   46] Training loss: 0.64808518, Validation loss: 0.65731493, Gradient norm: 0.73560312
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10390.5MB
INFO:root:[   47] Training loss: 0.64779112, Validation loss: 0.65450135, Gradient norm: 0.90118722
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10428.3828125MB
INFO:root:[   48] Training loss: 0.64739812, Validation loss: 0.65093405, Gradient norm: 0.77456045
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10466.58203125MB
INFO:root:[   49] Training loss: 0.64717115, Validation loss: 0.65373093, Gradient norm: 0.94456538
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10505.45703125MB
INFO:root:[   50] Training loss: 0.64683914, Validation loss: 0.66065747, Gradient norm: 0.91779649
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10543.5546875MB
INFO:root:[   51] Training loss: 0.64671312, Validation loss: 0.65104367, Gradient norm: 1.07972281
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10582.21875MB
INFO:root:[   52] Training loss: 0.64617362, Validation loss: 0.64888364, Gradient norm: 1.02951962
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10619.90234375MB
INFO:root:[   53] Training loss: 0.64583698, Validation loss: 0.65003385, Gradient norm: 0.91188555
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10658.76953125MB
INFO:root:[   54] Training loss: 0.64581910, Validation loss: 0.64029559, Gradient norm: 1.22245578
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10696.16796875MB
INFO:root:[   55] Training loss: 0.64538697, Validation loss: 0.64195194, Gradient norm: 0.95914511
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10735.0234375MB
INFO:root:[   56] Training loss: 0.64512866, Validation loss: 0.64318947, Gradient norm: 1.24399630
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10772.9140625MB
INFO:root:[   57] Training loss: 0.64504081, Validation loss: 0.64385167, Gradient norm: 1.09360455
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10811.0390625MB
INFO:root:[   58] Training loss: 0.64515219, Validation loss: 0.63806126, Gradient norm: 1.53965453
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10848.89453125MB
INFO:root:[   59] Training loss: 0.64447746, Validation loss: 0.64045934, Gradient norm: 1.45055215
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10887.23828125MB
INFO:root:[   60] Training loss: 0.64422098, Validation loss: 0.64038957, Gradient norm: 1.20727750
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10925.3671875MB
INFO:root:[   61] Training loss: 0.64409341, Validation loss: 0.64080229, Gradient norm: 1.44994671
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=10963.4765625MB
INFO:root:[   62] Training loss: 0.64368957, Validation loss: 0.63744232, Gradient norm: 1.45610013
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11001.60546875MB
INFO:root:[   63] Training loss: 0.64361527, Validation loss: 0.63715976, Gradient norm: 1.59334299
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11038.4140625MB
INFO:root:[   64] Training loss: 0.64333219, Validation loss: 0.63400709, Gradient norm: 1.46435766
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11076.26171875MB
INFO:root:[   65] Training loss: 0.64333227, Validation loss: 0.63483527, Gradient norm: 1.39400666
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11114.609375MB
INFO:root:[   66] Training loss: 0.64294852, Validation loss: 0.63411026, Gradient norm: 1.72385213
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11152.71484375MB
INFO:root:[   67] Training loss: 0.64291190, Validation loss: 0.63186456, Gradient norm: 1.48142824
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11190.171875MB
INFO:root:[   68] Training loss: 0.64284269, Validation loss: 0.63104678, Gradient norm: 1.76278423
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11228.80859375MB
INFO:root:[   69] Training loss: 0.64248449, Validation loss: 0.62995931, Gradient norm: 1.83486162
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11266.9453125MB
INFO:root:[   70] Training loss: 0.64223391, Validation loss: 0.62998923, Gradient norm: 1.70119983
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11305.71875MB
INFO:root:[   71] Training loss: 0.64227629, Validation loss: 0.63111301, Gradient norm: 1.80003646
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11343.83203125MB
INFO:root:[   72] Training loss: 0.64194716, Validation loss: 0.62833107, Gradient norm: 1.86087767
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11380.9921875MB
INFO:root:[   73] Training loss: 0.64208428, Validation loss: 0.62911800, Gradient norm: 2.02960232
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11419.86328125MB
INFO:root:[   74] Training loss: 0.64201062, Validation loss: 0.62816571, Gradient norm: 1.99395360
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11457.74609375MB
INFO:root:[   75] Training loss: 0.64170061, Validation loss: 0.62822950, Gradient norm: 2.10788639
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11496.34375MB
INFO:root:[   76] Training loss: 0.64157814, Validation loss: 0.62791207, Gradient norm: 2.10803216
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11533.72265625MB
INFO:root:[   77] Training loss: 0.64143197, Validation loss: 0.62787566, Gradient norm: 2.17347599
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11571.625MB
INFO:root:[   78] Training loss: 0.64147526, Validation loss: 0.62695830, Gradient norm: 2.23786832
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11609.78125MB
INFO:root:[   79] Training loss: 0.64127538, Validation loss: 0.62714483, Gradient norm: 2.26312596
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11648.41015625MB
INFO:root:[   80] Training loss: 0.64134014, Validation loss: 0.62724039, Gradient norm: 2.20653941
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11686.30859375MB
INFO:root:[   81] Training loss: 0.64104243, Validation loss: 0.62785867, Gradient norm: 2.34805197
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11724.17578125MB
INFO:root:[   82] Training loss: 0.64121620, Validation loss: 0.62688003, Gradient norm: 2.35941592
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11761.828125MB
INFO:root:[   83] Training loss: 0.64089470, Validation loss: 0.62668485, Gradient norm: 2.47588434
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11799.984375MB
INFO:root:[   84] Training loss: 0.64101046, Validation loss: 0.62660455, Gradient norm: 2.31716479
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11838.11328125MB
INFO:root:[   85] Training loss: 0.64076669, Validation loss: 0.62616893, Gradient norm: 2.59708482
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11876.2265625MB
INFO:root:[   86] Training loss: 0.64056873, Validation loss: 0.62647117, Gradient norm: 2.09945334
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11915.06640625MB
INFO:root:[   87] Training loss: 0.64048346, Validation loss: 0.62638192, Gradient norm: 2.73295459
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11953.4453125MB
INFO:root:[   88] Training loss: 0.64041825, Validation loss: 0.62539276, Gradient norm: 2.76797457
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=11991.08984375MB
INFO:root:[   89] Training loss: 0.64001880, Validation loss: 0.62494508, Gradient norm: 2.78791577
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=12028.98046875MB
INFO:root:[   90] Training loss: 0.64035308, Validation loss: 0.62487730, Gradient norm: 2.83357118
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=12067.60546875MB
INFO:root:[   91] Training loss: 0.64029776, Validation loss: 0.62510912, Gradient norm: 2.81437479
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=12107.50390625MB
INFO:root:[   92] Training loss: 0.64002827, Validation loss: 0.62557359, Gradient norm: 2.94051033
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=12145.5703125MB
INFO:root:[   93] Training loss: 0.64028337, Validation loss: 0.62448963, Gradient norm: 2.91531829
INFO:root:At the start of the epoch: mem (CPU python)=12446.0234375MB; mem (CPU total)=12182.95703125MB
INFO:root:[   94] Training loss: 0.64008278, Validation loss: 0.62539249, Gradient norm: 2.98133567
INFO:root:At the start of the epoch: mem (CPU python)=12470.9375MB; mem (CPU total)=12221.82421875MB
INFO:root:[   95] Training loss: 0.64016256, Validation loss: 0.62479776, Gradient norm: 3.07210221
INFO:root:At the start of the epoch: mem (CPU python)=12509.078125MB; mem (CPU total)=12259.7890625MB
INFO:root:[   96] Training loss: 0.63972143, Validation loss: 0.62568312, Gradient norm: 2.98070277
INFO:root:At the start of the epoch: mem (CPU python)=12547.1796875MB; mem (CPU total)=12297.90625MB
INFO:root:[   97] Training loss: 0.63996087, Validation loss: 0.62480529, Gradient norm: 3.07128242
INFO:root:At the start of the epoch: mem (CPU python)=12585.27734375MB; mem (CPU total)=12335.86328125MB
INFO:root:[   98] Training loss: 0.63970052, Validation loss: 0.62658876, Gradient norm: 3.04306353
INFO:root:At the start of the epoch: mem (CPU python)=12623.37109375MB; mem (CPU total)=12373.7109375MB
INFO:root:[   99] Training loss: 0.63971997, Validation loss: 0.62495526, Gradient norm: 3.23600219
INFO:root:At the start of the epoch: mem (CPU python)=12661.46484375MB; mem (CPU total)=12412.546875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  100] Training loss: 0.63940171, Validation loss: 0.62402996, Gradient norm: 3.24813482
INFO:root:At the start of the epoch: mem (CPU python)=12699.5390625MB; mem (CPU total)=12449.9140625MB
INFO:root:[  101] Training loss: 0.63836330, Validation loss: 0.62369467, Gradient norm: 1.87688581
INFO:root:At the start of the epoch: mem (CPU python)=12737.6640625MB; mem (CPU total)=12488.04296875MB
INFO:root:[  102] Training loss: 0.63826446, Validation loss: 0.62372316, Gradient norm: 2.07248341
INFO:root:At the start of the epoch: mem (CPU python)=12775.73828125MB; mem (CPU total)=12526.39453125MB
INFO:root:[  103] Training loss: 0.63816224, Validation loss: 0.62376283, Gradient norm: 1.89799362
INFO:root:At the start of the epoch: mem (CPU python)=12813.84765625MB; mem (CPU total)=12565.0MB
INFO:root:[  104] Training loss: 0.63786204, Validation loss: 0.62425817, Gradient norm: 2.34250093
INFO:root:At the start of the epoch: mem (CPU python)=12851.9375MB; mem (CPU total)=12603.1171875MB
INFO:root:[  105] Training loss: 0.63833300, Validation loss: 0.62373183, Gradient norm: 2.57981564
INFO:root:At the start of the epoch: mem (CPU python)=12890.0390625MB; mem (CPU total)=12641.28125MB
INFO:root:[  106] Training loss: 0.63848265, Validation loss: 0.62361452, Gradient norm: 3.56100433
INFO:root:At the start of the epoch: mem (CPU python)=12928.10546875MB; mem (CPU total)=12678.9296875MB
INFO:root:[  107] Training loss: 0.63812837, Validation loss: 0.62297260, Gradient norm: 2.63609696
INFO:root:At the start of the epoch: mem (CPU python)=12966.140625MB; mem (CPU total)=12716.3828125MB
INFO:root:[  108] Training loss: 0.63803203, Validation loss: 0.62324105, Gradient norm: 2.60676978
INFO:root:At the start of the epoch: mem (CPU python)=13004.26953125MB; mem (CPU total)=12754.99609375MB
INFO:root:[  109] Training loss: 0.63791587, Validation loss: 0.62311054, Gradient norm: 2.72096910
INFO:root:At the start of the epoch: mem (CPU python)=13042.36328125MB; mem (CPU total)=12792.8828125MB
INFO:root:[  110] Training loss: 0.63797344, Validation loss: 0.62429962, Gradient norm: 2.59852624
INFO:root:At the start of the epoch: mem (CPU python)=13080.46875MB; mem (CPU total)=12830.79296875MB
INFO:root:[  111] Training loss: 0.63778609, Validation loss: 0.62367449, Gradient norm: 2.66526704
INFO:root:At the start of the epoch: mem (CPU python)=13118.53125MB; mem (CPU total)=12868.89453125MB
INFO:root:[  112] Training loss: 0.63796018, Validation loss: 0.62281622, Gradient norm: 3.06460406
INFO:root:At the start of the epoch: mem (CPU python)=13156.65234375MB; mem (CPU total)=12906.765625MB
INFO:root:[  113] Training loss: 0.63776488, Validation loss: 0.62334605, Gradient norm: 3.12203735
INFO:root:At the start of the epoch: mem (CPU python)=13194.7265625MB; mem (CPU total)=12945.37890625MB
INFO:root:[  114] Training loss: 0.63780252, Validation loss: 0.62311453, Gradient norm: 3.11076387
INFO:root:At the start of the epoch: mem (CPU python)=13232.828125MB; mem (CPU total)=12983.41015625MB
INFO:root:[  115] Training loss: 0.63769657, Validation loss: 0.62311544, Gradient norm: 3.23376483
INFO:root:At the start of the epoch: mem (CPU python)=13270.9296875MB; mem (CPU total)=13022.296875MB
INFO:root:[  116] Training loss: 0.63771857, Validation loss: 0.62318942, Gradient norm: 3.36830686
INFO:root:At the start of the epoch: mem (CPU python)=13309.09375MB; mem (CPU total)=13060.875MB
INFO:root:[  117] Training loss: 0.63771570, Validation loss: 0.62301083, Gradient norm: 3.28742653
INFO:root:At the start of the epoch: mem (CPU python)=13347.1953125MB; mem (CPU total)=13098.7421875MB
INFO:root:[  118] Training loss: 0.63764205, Validation loss: 0.62276101, Gradient norm: 3.49032212
INFO:root:At the start of the epoch: mem (CPU python)=13385.27734375MB; mem (CPU total)=13136.12890625MB
INFO:root:[  119] Training loss: 0.63785556, Validation loss: 0.62281226, Gradient norm: 3.44465133
INFO:root:At the start of the epoch: mem (CPU python)=13423.38671875MB; mem (CPU total)=13174.7578125MB
INFO:root:[  120] Training loss: 0.63755047, Validation loss: 0.62245395, Gradient norm: 3.62788039
INFO:root:At the start of the epoch: mem (CPU python)=13461.484375MB; mem (CPU total)=13212.65625MB
INFO:root:[  121] Training loss: 0.63765432, Validation loss: 0.62288088, Gradient norm: 3.50812297
INFO:root:At the start of the epoch: mem (CPU python)=13499.5703125MB; mem (CPU total)=13251.0234375MB
INFO:root:[  122] Training loss: 0.63755599, Validation loss: 0.62212009, Gradient norm: 3.81433439
INFO:root:At the start of the epoch: mem (CPU python)=13537.640625MB; mem (CPU total)=13289.109375MB
INFO:root:[  123] Training loss: 0.63773945, Validation loss: 0.62315073, Gradient norm: 3.68320719
INFO:root:At the start of the epoch: mem (CPU python)=13575.765625MB; mem (CPU total)=13326.8125MB
INFO:root:[  124] Training loss: 0.63756425, Validation loss: 0.62285356, Gradient norm: 3.83462456
INFO:root:At the start of the epoch: mem (CPU python)=13613.86328125MB; mem (CPU total)=13365.203125MB
INFO:root:[  125] Training loss: 0.63773386, Validation loss: 0.62295732, Gradient norm: 3.87663924
INFO:root:At the start of the epoch: mem (CPU python)=13651.95703125MB; mem (CPU total)=13403.31640625MB
INFO:root:[  126] Training loss: 0.63748537, Validation loss: 0.62184655, Gradient norm: 3.99834001
INFO:root:At the start of the epoch: mem (CPU python)=13690.05078125MB; mem (CPU total)=13441.234375MB
INFO:root:[  127] Training loss: 0.63758795, Validation loss: 0.62271314, Gradient norm: 4.03404462
INFO:root:At the start of the epoch: mem (CPU python)=13728.078125MB; mem (CPU total)=13479.87890625MB
INFO:root:[  128] Training loss: 0.63748874, Validation loss: 0.62264427, Gradient norm: 3.93782870
INFO:root:At the start of the epoch: mem (CPU python)=13766.1484375MB; mem (CPU total)=13518.03515625MB
INFO:root:[  129] Training loss: 0.63731097, Validation loss: 0.62209464, Gradient norm: 4.08540729
INFO:root:At the start of the epoch: mem (CPU python)=13804.22265625MB; mem (CPU total)=13556.1640625MB
INFO:root:[  130] Training loss: 0.63744096, Validation loss: 0.62347886, Gradient norm: 4.33124977
INFO:root:At the start of the epoch: mem (CPU python)=13842.37109375MB; mem (CPU total)=13594.1171875MB
INFO:root:[  131] Training loss: 0.63746306, Validation loss: 0.62405601, Gradient norm: 4.33208495
INFO:root:At the start of the epoch: mem (CPU python)=13880.4765625MB; mem (CPU total)=13631.75MB
INFO:root:[  132] Training loss: 0.63748122, Validation loss: 0.62192258, Gradient norm: 3.98835788
INFO:root:At the start of the epoch: mem (CPU python)=13918.55078125MB; mem (CPU total)=13669.87109375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  133] Training loss: 0.63747185, Validation loss: 0.62267307, Gradient norm: 4.41151475
INFO:root:At the start of the epoch: mem (CPU python)=13956.6640625MB; mem (CPU total)=13708.1328125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  134] Training loss: 0.63678787, Validation loss: 0.62270764, Gradient norm: 2.49152696
INFO:root:At the start of the epoch: mem (CPU python)=13994.72265625MB; mem (CPU total)=13745.7734375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  135] Training loss: 0.63641253, Validation loss: 0.62242434, Gradient norm: 1.88459852
INFO:root:At the start of the epoch: mem (CPU python)=14032.8515625MB; mem (CPU total)=13783.8984375MB
INFO:root:EP 135: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=14070.94921875MB; mem (CPU total)=13822.0625MB
INFO:root:Training the model took 6265.526s.
INFO:root:Emptying the cuda cache took 0.038s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.87667
INFO:root:EnergyScoreTrain: 0.61714
INFO:root:CRPSTrain: 0.54983
INFO:root:Gaussian NLLTrain: 54922670471.39556
INFO:root:CoverageTrain: 0.49747
INFO:root:IntervalWidthTrain: 2.27329
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88372
INFO:root:EnergyScoreValidation: 0.62221
INFO:root:CRPSValidation: 0.55604
INFO:root:Gaussian NLLValidation: 58038096581.97334
INFO:root:CoverageValidation: 0.49742
INFO:root:IntervalWidthValidation: 2.27456
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88457
INFO:root:EnergyScoreTest: 0.62281
INFO:root:CRPSTest: 0.55668
INFO:root:Gaussian NLLTest: 58019912941.56801
INFO:root:CoverageTest: 0.49744
INFO:root:IntervalWidthTest: 2.27544
INFO:root:After validation: mem (CPU python)=14130.79296875MB; mem (CPU total)=13896.67578125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=14130.79296875MB; mem (CPU total)=13831.5078125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=14130.79296875MB; mem (CPU total)=13834.69921875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=14130.79296875MB; mem (CPU total)=13834.9453125MB
INFO:root:[    1] Training loss: 0.72454702, Validation loss: 0.72044827, Gradient norm: 0.01922508
INFO:root:At the start of the epoch: mem (CPU python)=14152.75390625MB; mem (CPU total)=13903.390625MB
INFO:root:[    2] Training loss: 0.71987292, Validation loss: 0.71894223, Gradient norm: 0.00671517
INFO:root:At the start of the epoch: mem (CPU python)=14190.8359375MB; mem (CPU total)=13941.35546875MB
INFO:root:[    3] Training loss: 0.71788798, Validation loss: 0.71348277, Gradient norm: 0.01059821
INFO:root:At the start of the epoch: mem (CPU python)=14228.96875MB; mem (CPU total)=13979.71875MB
INFO:root:[    4] Training loss: 0.71086173, Validation loss: 0.70450245, Gradient norm: 0.02819256
INFO:root:At the start of the epoch: mem (CPU python)=14267.078125MB; mem (CPU total)=14017.859375MB
INFO:root:[    5] Training loss: 0.70447806, Validation loss: 0.69750031, Gradient norm: 0.03105640
INFO:root:At the start of the epoch: mem (CPU python)=14305.1875MB; mem (CPU total)=14056.0MB
INFO:root:[    6] Training loss: 0.69881237, Validation loss: 0.69106607, Gradient norm: 0.04108788
INFO:root:At the start of the epoch: mem (CPU python)=14343.28515625MB; mem (CPU total)=14093.8984375MB
INFO:root:[    7] Training loss: 0.69273566, Validation loss: 0.68366432, Gradient norm: 0.04174090
INFO:root:At the start of the epoch: mem (CPU python)=14381.3984375MB; mem (CPU total)=14132.28515625MB
INFO:root:[    8] Training loss: 0.68778022, Validation loss: 0.67746726, Gradient norm: 0.04364875
INFO:root:At the start of the epoch: mem (CPU python)=14419.46875MB; mem (CPU total)=14170.45703125MB
INFO:root:[    9] Training loss: 0.68366510, Validation loss: 0.67314763, Gradient norm: 0.04412882
INFO:root:At the start of the epoch: mem (CPU python)=14457.5390625MB; mem (CPU total)=14208.546875MB
INFO:root:[   10] Training loss: 0.67976125, Validation loss: 0.66879754, Gradient norm: 0.04810732
INFO:root:At the start of the epoch: mem (CPU python)=14495.6875MB; mem (CPU total)=14246.40625MB
INFO:root:[   11] Training loss: 0.67640471, Validation loss: 0.66556478, Gradient norm: 0.04310347
INFO:root:At the start of the epoch: mem (CPU python)=14533.77734375MB; mem (CPU total)=14284.7734375MB
INFO:root:[   12] Training loss: 0.67365843, Validation loss: 0.66216150, Gradient norm: 0.05385409
INFO:root:At the start of the epoch: mem (CPU python)=14571.87109375MB; mem (CPU total)=14323.1328125MB
INFO:root:[   13] Training loss: 0.67103907, Validation loss: 0.65938464, Gradient norm: 0.04626718
INFO:root:At the start of the epoch: mem (CPU python)=14609.97265625MB; mem (CPU total)=14361.23828125MB
INFO:root:[   14] Training loss: 0.66908209, Validation loss: 0.65663331, Gradient norm: 0.05222120
INFO:root:At the start of the epoch: mem (CPU python)=14648.0703125MB; mem (CPU total)=14398.7109375MB
INFO:root:[   15] Training loss: 0.66722796, Validation loss: 0.65509628, Gradient norm: 0.05332947
INFO:root:At the start of the epoch: mem (CPU python)=14686.16796875MB; mem (CPU total)=14437.36328125MB
INFO:root:[   16] Training loss: 0.66561261, Validation loss: 0.65265464, Gradient norm: 0.05243751
INFO:root:At the start of the epoch: mem (CPU python)=14724.265625MB; mem (CPU total)=14475.734375MB
INFO:root:[   17] Training loss: 0.66428411, Validation loss: 0.65123994, Gradient norm: 0.05485284
INFO:root:At the start of the epoch: mem (CPU python)=14762.359375MB; mem (CPU total)=14513.81640625MB
INFO:root:[   18] Training loss: 0.66298834, Validation loss: 0.65002273, Gradient norm: 0.06284560
INFO:root:At the start of the epoch: mem (CPU python)=14800.375MB; mem (CPU total)=14551.92578125MB
INFO:root:[   19] Training loss: 0.66191281, Validation loss: 0.64856308, Gradient norm: 0.06672977
INFO:root:At the start of the epoch: mem (CPU python)=14838.5MB; mem (CPU total)=14590.296875MB
INFO:root:[   20] Training loss: 0.66107038, Validation loss: 0.64770028, Gradient norm: 0.07976186
INFO:root:At the start of the epoch: mem (CPU python)=14876.44921875MB; mem (CPU total)=14628.375MB
INFO:root:[   21] Training loss: 0.66014900, Validation loss: 0.64625423, Gradient norm: 0.08299823
INFO:root:At the start of the epoch: mem (CPU python)=14914.6875MB; mem (CPU total)=14666.55078125MB
INFO:root:[   22] Training loss: 0.65922881, Validation loss: 0.64525576, Gradient norm: 0.09262378
INFO:root:At the start of the epoch: mem (CPU python)=14952.78515625MB; mem (CPU total)=14704.69140625MB
INFO:root:[   23] Training loss: 0.65861046, Validation loss: 0.64470600, Gradient norm: 0.10968384
INFO:root:At the start of the epoch: mem (CPU python)=14990.87890625MB; mem (CPU total)=14743.05859375MB
INFO:root:[   24] Training loss: 0.65819401, Validation loss: 0.64433871, Gradient norm: 0.11272632
INFO:root:At the start of the epoch: mem (CPU python)=15028.9609375MB; mem (CPU total)=14781.41015625MB
INFO:root:[   25] Training loss: 0.65774737, Validation loss: 0.64356979, Gradient norm: 0.13860436
INFO:root:At the start of the epoch: mem (CPU python)=15067.12890625MB; mem (CPU total)=14819.53515625MB
INFO:root:[   26] Training loss: 0.65715889, Validation loss: 0.64286724, Gradient norm: 0.15238650
INFO:root:At the start of the epoch: mem (CPU python)=15105.1328125MB; mem (CPU total)=14857.4296875MB
INFO:root:[   27] Training loss: 0.65657016, Validation loss: 0.64524325, Gradient norm: 0.20064315
INFO:root:At the start of the epoch: mem (CPU python)=15143.26171875MB; mem (CPU total)=14896.83984375MB
INFO:root:[   28] Training loss: 0.65626893, Validation loss: 0.64167963, Gradient norm: 0.24703648
INFO:root:At the start of the epoch: mem (CPU python)=15181.33984375MB; mem (CPU total)=14933.84375MB
INFO:root:[   29] Training loss: 0.65563203, Validation loss: 0.64524665, Gradient norm: 0.23888849
INFO:root:At the start of the epoch: mem (CPU python)=15219.49609375MB; mem (CPU total)=14972.6796875MB
INFO:root:[   30] Training loss: 0.65535881, Validation loss: 0.64470621, Gradient norm: 0.25134616
INFO:root:At the start of the epoch: mem (CPU python)=15257.5859375MB; mem (CPU total)=15010.79296875MB
INFO:root:[   31] Training loss: 0.65493177, Validation loss: 0.64206071, Gradient norm: 0.25664898
INFO:root:At the start of the epoch: mem (CPU python)=15295.6953125MB; mem (CPU total)=15048.91796875MB
INFO:root:[   32] Training loss: 0.65467155, Validation loss: 0.64495069, Gradient norm: 0.36814233
INFO:root:At the start of the epoch: mem (CPU python)=15333.79296875MB; mem (CPU total)=15086.75MB
INFO:root:[   33] Training loss: 0.65419364, Validation loss: 0.64408727, Gradient norm: 0.36075391
INFO:root:At the start of the epoch: mem (CPU python)=15371.89453125MB; mem (CPU total)=15124.8515625MB
INFO:root:[   34] Training loss: 0.65358983, Validation loss: 0.64381271, Gradient norm: 0.39300842
INFO:root:At the start of the epoch: mem (CPU python)=15409.984375MB; mem (CPU total)=15162.9453125MB
INFO:root:[   35] Training loss: 0.65337127, Validation loss: 0.64834288, Gradient norm: 0.40772890
INFO:root:At the start of the epoch: mem (CPU python)=15448.08203125MB; mem (CPU total)=15201.3359375MB
INFO:root:[   36] Training loss: 0.65308400, Validation loss: 0.65049896, Gradient norm: 0.49039008
INFO:root:At the start of the epoch: mem (CPU python)=15486.17578125MB; mem (CPU total)=15242.1953125MB
INFO:root:[   37] Training loss: 0.65296782, Validation loss: 0.64703340, Gradient norm: 0.55231809
INFO:root:At the start of the epoch: mem (CPU python)=15524.26953125MB; mem (CPU total)=15280.34765625MB
INFO:root:[   38] Training loss: 0.65247852, Validation loss: 0.64554992, Gradient norm: 0.58405904
INFO:root:At the start of the epoch: mem (CPU python)=15562.26953125MB; mem (CPU total)=15318.5703125MB
INFO:root:[   39] Training loss: 0.65225923, Validation loss: 0.64670700, Gradient norm: 0.62686427
INFO:root:At the start of the epoch: mem (CPU python)=15600.3671875MB; mem (CPU total)=15356.8828125MB
INFO:root:[   40] Training loss: 0.65173469, Validation loss: 0.64585327, Gradient norm: 0.58946325
INFO:root:At the start of the epoch: mem (CPU python)=15638.50390625MB; mem (CPU total)=15395.015625MB
INFO:root:[   41] Training loss: 0.65178622, Validation loss: 0.64860733, Gradient norm: 0.79451914
INFO:root:At the start of the epoch: mem (CPU python)=15676.6015625MB; mem (CPU total)=15432.890625MB
INFO:root:[   42] Training loss: 0.65144386, Validation loss: 0.64620033, Gradient norm: 0.77299485
INFO:root:At the start of the epoch: mem (CPU python)=15714.69921875MB; mem (CPU total)=15471.28515625MB
INFO:root:[   43] Training loss: 0.65138607, Validation loss: 0.63943837, Gradient norm: 0.91297736
INFO:root:At the start of the epoch: mem (CPU python)=15752.78515625MB; mem (CPU total)=15508.83984375MB
INFO:root:[   44] Training loss: 0.65109211, Validation loss: 0.64366702, Gradient norm: 0.94177519
INFO:root:At the start of the epoch: mem (CPU python)=15790.85546875MB; mem (CPU total)=15547.703125MB
INFO:root:[   45] Training loss: 0.65068818, Validation loss: 0.64125945, Gradient norm: 1.05023050
INFO:root:At the start of the epoch: mem (CPU python)=15828.9765625MB; mem (CPU total)=15585.58984375MB
INFO:root:[   46] Training loss: 0.65024714, Validation loss: 0.63904851, Gradient norm: 1.15236077
INFO:root:At the start of the epoch: mem (CPU python)=15867.0703125MB; mem (CPU total)=15622.72265625MB
INFO:root:[   47] Training loss: 0.65004911, Validation loss: 0.63692364, Gradient norm: 0.85250557
INFO:root:At the start of the epoch: mem (CPU python)=15905.08984375MB; mem (CPU total)=15660.69140625MB
INFO:root:[   48] Training loss: 0.65012875, Validation loss: 0.63648656, Gradient norm: 1.40673133
INFO:root:At the start of the epoch: mem (CPU python)=15943.265625MB; mem (CPU total)=15698.79296875MB
INFO:root:[   49] Training loss: 0.64986250, Validation loss: 0.63744917, Gradient norm: 1.26375755
INFO:root:At the start of the epoch: mem (CPU python)=15981.421875MB; mem (CPU total)=15737.390625MB
INFO:root:[   50] Training loss: 0.64956266, Validation loss: 0.63601868, Gradient norm: 1.12934198
INFO:root:At the start of the epoch: mem (CPU python)=16019.5078125MB; mem (CPU total)=15775.0234375MB
INFO:root:[   51] Training loss: 0.64951025, Validation loss: 0.63554768, Gradient norm: 1.25773486
INFO:root:At the start of the epoch: mem (CPU python)=16057.60546875MB; mem (CPU total)=15813.671875MB
INFO:root:[   52] Training loss: 0.64917709, Validation loss: 0.63596146, Gradient norm: 1.42055991
INFO:root:At the start of the epoch: mem (CPU python)=16095.70703125MB; mem (CPU total)=15851.7578125MB
INFO:root:[   53] Training loss: 0.64892740, Validation loss: 0.63393512, Gradient norm: 1.58766142
INFO:root:At the start of the epoch: mem (CPU python)=16133.7890625MB; mem (CPU total)=15889.38671875MB
INFO:root:[   54] Training loss: 0.64899542, Validation loss: 0.63375981, Gradient norm: 1.74367766
INFO:root:At the start of the epoch: mem (CPU python)=16171.8828125MB; mem (CPU total)=15927.55859375MB
INFO:root:[   55] Training loss: 0.64883113, Validation loss: 0.63599148, Gradient norm: 1.33258784
INFO:root:At the start of the epoch: mem (CPU python)=16209.98828125MB; mem (CPU total)=15965.9453125MB
INFO:root:[   56] Training loss: 0.64879824, Validation loss: 0.63462232, Gradient norm: 1.82605958
INFO:root:At the start of the epoch: mem (CPU python)=16248.0859375MB; mem (CPU total)=16003.82421875MB
INFO:root:[   57] Training loss: 0.64855133, Validation loss: 0.63429704, Gradient norm: 1.96015304
INFO:root:At the start of the epoch: mem (CPU python)=16286.18359375MB; mem (CPU total)=16041.96875MB
INFO:root:[   58] Training loss: 0.64850179, Validation loss: 0.63410003, Gradient norm: 2.03360865
INFO:root:At the start of the epoch: mem (CPU python)=16324.26953125MB; mem (CPU total)=16079.47265625MB
INFO:root:[   59] Training loss: 0.64814328, Validation loss: 0.63348245, Gradient norm: 1.95782545
INFO:root:At the start of the epoch: mem (CPU python)=16362.31640625MB; mem (CPU total)=16117.2109375MB
INFO:root:[   60] Training loss: 0.64837874, Validation loss: 0.63467859, Gradient norm: 2.11403554
INFO:root:At the start of the epoch: mem (CPU python)=16400.359375MB; mem (CPU total)=16156.078125MB
INFO:root:[   61] Training loss: 0.64803962, Validation loss: 0.63323359, Gradient norm: 2.31018775
INFO:root:At the start of the epoch: mem (CPU python)=16438.5078125MB; mem (CPU total)=16193.73046875MB
INFO:root:[   62] Training loss: 0.64790959, Validation loss: 0.63184219, Gradient norm: 2.25299438
INFO:root:At the start of the epoch: mem (CPU python)=16476.6015625MB; mem (CPU total)=16231.6484375MB
INFO:root:[   63] Training loss: 0.64794533, Validation loss: 0.63266909, Gradient norm: 2.35035003
INFO:root:At the start of the epoch: mem (CPU python)=16514.6953125MB; mem (CPU total)=16272.25390625MB
INFO:root:[   64] Training loss: 0.64767562, Validation loss: 0.63291488, Gradient norm: 2.12296488
INFO:root:At the start of the epoch: mem (CPU python)=16552.79296875MB; mem (CPU total)=16310.37890625MB
INFO:root:[   65] Training loss: 0.64766064, Validation loss: 0.63174343, Gradient norm: 2.66778824
INFO:root:At the start of the epoch: mem (CPU python)=16590.875MB; mem (CPU total)=16347.51953125MB
INFO:root:[   66] Training loss: 0.64785237, Validation loss: 0.63155879, Gradient norm: 2.61265647
INFO:root:At the start of the epoch: mem (CPU python)=16628.9375MB; mem (CPU total)=16385.6328125MB
INFO:root:[   67] Training loss: 0.64772329, Validation loss: 0.63316716, Gradient norm: 2.70589864
INFO:root:At the start of the epoch: mem (CPU python)=16667.06640625MB; mem (CPU total)=16424.46484375MB
INFO:root:[   68] Training loss: 0.64779441, Validation loss: 0.63299542, Gradient norm: 2.74138326
INFO:root:At the start of the epoch: mem (CPU python)=16705.17578125MB; mem (CPU total)=16462.546875MB
INFO:root:[   69] Training loss: 0.64750925, Validation loss: 0.63227932, Gradient norm: 2.85107569
INFO:root:At the start of the epoch: mem (CPU python)=16743.26953125MB; mem (CPU total)=16500.640625MB
INFO:root:[   70] Training loss: 0.64714816, Validation loss: 0.63179349, Gradient norm: 2.95164467
INFO:root:At the start of the epoch: mem (CPU python)=16781.35546875MB; mem (CPU total)=16539.265625MB
INFO:root:[   71] Training loss: 0.64718725, Validation loss: 0.63284476, Gradient norm: 3.01927585
INFO:root:At the start of the epoch: mem (CPU python)=16819.51953125MB; mem (CPU total)=16577.37890625MB
INFO:root:[   72] Training loss: 0.64747391, Validation loss: 0.63160198, Gradient norm: 3.11428892
INFO:root:At the start of the epoch: mem (CPU python)=16857.6015625MB; mem (CPU total)=16615.50390625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   73] Training loss: 0.64727404, Validation loss: 0.63226896, Gradient norm: 3.19452901
INFO:root:At the start of the epoch: mem (CPU python)=16895.7109375MB; mem (CPU total)=16653.3515625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   74] Training loss: 0.64626044, Validation loss: 0.63075272, Gradient norm: 1.96553931
INFO:root:At the start of the epoch: mem (CPU python)=16933.8125MB; mem (CPU total)=16691.01171875MB
INFO:root:[   75] Training loss: 0.64575211, Validation loss: 0.63073418, Gradient norm: 1.43534055
INFO:root:At the start of the epoch: mem (CPU python)=16971.84765625MB; mem (CPU total)=16729.29296875MB
INFO:root:[   76] Training loss: 0.64572661, Validation loss: 0.62972142, Gradient norm: 1.52228032
INFO:root:At the start of the epoch: mem (CPU python)=17010.0MB; mem (CPU total)=16767.23828125MB
INFO:root:[   77] Training loss: 0.64558246, Validation loss: 0.63005618, Gradient norm: 1.57257716
INFO:root:At the start of the epoch: mem (CPU python)=17048.09375MB; mem (CPU total)=16805.8515625MB
INFO:root:[   78] Training loss: 0.64587533, Validation loss: 0.63035332, Gradient norm: 1.60759336
INFO:root:At the start of the epoch: mem (CPU python)=17086.1875MB; mem (CPU total)=16843.95703125MB
INFO:root:[   79] Training loss: 0.64562047, Validation loss: 0.63039006, Gradient norm: 1.66234128
INFO:root:At the start of the epoch: mem (CPU python)=17124.28125MB; mem (CPU total)=16882.078125MB
INFO:root:[   80] Training loss: 0.64562103, Validation loss: 0.63000224, Gradient norm: 1.76611323
INFO:root:At the start of the epoch: mem (CPU python)=17162.37890625MB; mem (CPU total)=16920.203125MB
INFO:root:[   81] Training loss: 0.64567837, Validation loss: 0.62963136, Gradient norm: 1.91612873
INFO:root:At the start of the epoch: mem (CPU python)=17200.39453125MB; mem (CPU total)=16958.29296875MB
INFO:root:[   82] Training loss: 0.64543062, Validation loss: 0.62949976, Gradient norm: 1.89148858
INFO:root:At the start of the epoch: mem (CPU python)=17238.51171875MB; mem (CPU total)=16996.6875MB
INFO:root:[   83] Training loss: 0.64550564, Validation loss: 0.63006459, Gradient norm: 2.00005448
INFO:root:At the start of the epoch: mem (CPU python)=17276.58203125MB; mem (CPU total)=17035.30859375MB
INFO:root:[   84] Training loss: 0.64540991, Validation loss: 0.62992197, Gradient norm: 1.92836845
INFO:root:At the start of the epoch: mem (CPU python)=17314.70703125MB; mem (CPU total)=17073.69921875MB
INFO:root:[   85] Training loss: 0.64546597, Validation loss: 0.62963101, Gradient norm: 1.91942708
INFO:root:At the start of the epoch: mem (CPU python)=17352.79296875MB; mem (CPU total)=17113.4140625MB
INFO:root:[   86] Training loss: 0.64552908, Validation loss: 0.62954834, Gradient norm: 2.02785993
INFO:root:At the start of the epoch: mem (CPU python)=17390.8984375MB; mem (CPU total)=17151.0859375MB
INFO:root:[   87] Training loss: 0.64545105, Validation loss: 0.63011106, Gradient norm: 2.25244859
INFO:root:At the start of the epoch: mem (CPU python)=17428.984375MB; mem (CPU total)=17188.875MB
INFO:root:[   88] Training loss: 0.64549505, Validation loss: 0.63037075, Gradient norm: 2.23690041
INFO:root:At the start of the epoch: mem (CPU python)=17467.0703125MB; mem (CPU total)=17226.9375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   89] Training loss: 0.64547739, Validation loss: 0.62977949, Gradient norm: 2.33879843
INFO:root:At the start of the epoch: mem (CPU python)=17505.1796875MB; mem (CPU total)=17264.69921875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   90] Training loss: 0.64524382, Validation loss: 0.62951239, Gradient norm: 1.88855031
INFO:root:At the start of the epoch: mem (CPU python)=17543.28125MB; mem (CPU total)=17303.08203125MB
INFO:root:[   91] Training loss: 0.64499649, Validation loss: 0.62997047, Gradient norm: 1.58926231
INFO:root:At the start of the epoch: mem (CPU python)=17581.42578125MB; mem (CPU total)=17341.234375MB
INFO:root:[   92] Training loss: 0.64501942, Validation loss: 0.62919273, Gradient norm: 1.57358078
INFO:root:At the start of the epoch: mem (CPU python)=17619.5234375MB; mem (CPU total)=17379.13671875MB
INFO:root:[   93] Training loss: 0.64502913, Validation loss: 0.62981562, Gradient norm: 1.58207312
INFO:root:At the start of the epoch: mem (CPU python)=17657.62109375MB; mem (CPU total)=17417.7890625MB
INFO:root:[   94] Training loss: 0.64492469, Validation loss: 0.62988210, Gradient norm: 1.54024348
INFO:root:At the start of the epoch: mem (CPU python)=17695.71484375MB; mem (CPU total)=17455.6875MB
INFO:root:[   95] Training loss: 0.64496024, Validation loss: 0.62958470, Gradient norm: 1.68030778
INFO:root:At the start of the epoch: mem (CPU python)=17733.80859375MB; mem (CPU total)=17494.109375MB
INFO:root:[   96] Training loss: 0.64520919, Validation loss: 0.62898883, Gradient norm: 1.70594281
INFO:root:At the start of the epoch: mem (CPU python)=17771.89453125MB; mem (CPU total)=17531.76171875MB
INFO:root:[   97] Training loss: 0.64502356, Validation loss: 0.62924924, Gradient norm: 1.56113836
INFO:root:At the start of the epoch: mem (CPU python)=17809.9765625MB; mem (CPU total)=17569.24609375MB
INFO:root:[   98] Training loss: 0.64481173, Validation loss: 0.62924835, Gradient norm: 1.67130720
INFO:root:At the start of the epoch: mem (CPU python)=17848.06640625MB; mem (CPU total)=17607.421875MB
INFO:root:[   99] Training loss: 0.64503939, Validation loss: 0.62923774, Gradient norm: 1.77203081
INFO:root:At the start of the epoch: mem (CPU python)=17886.1796875MB; mem (CPU total)=17645.32421875MB
INFO:root:[  100] Training loss: 0.64493777, Validation loss: 0.62944180, Gradient norm: 1.63936921
INFO:root:At the start of the epoch: mem (CPU python)=17924.2890625MB; mem (CPU total)=17683.45703125MB
INFO:root:[  101] Training loss: 0.64500246, Validation loss: 0.62901890, Gradient norm: 1.65662074
INFO:root:At the start of the epoch: mem (CPU python)=17962.3828125MB; mem (CPU total)=17721.82421875MB
INFO:root:[  102] Training loss: 0.64490912, Validation loss: 0.62872414, Gradient norm: 1.81530360
INFO:root:At the start of the epoch: mem (CPU python)=18000.421875MB; mem (CPU total)=17759.71484375MB
INFO:root:[  103] Training loss: 0.64490107, Validation loss: 0.62986304, Gradient norm: 1.77785854
INFO:root:At the start of the epoch: mem (CPU python)=18038.51953125MB; mem (CPU total)=17798.5625MB
INFO:root:[  104] Training loss: 0.64505339, Validation loss: 0.62958878, Gradient norm: 1.73843075
INFO:root:At the start of the epoch: mem (CPU python)=18076.61328125MB; mem (CPU total)=17837.16015625MB
INFO:root:[  105] Training loss: 0.64489808, Validation loss: 0.62946682, Gradient norm: 1.81383898
INFO:root:At the start of the epoch: mem (CPU python)=18114.67578125MB; mem (CPU total)=17875.30078125MB
INFO:root:[  106] Training loss: 0.64499720, Validation loss: 0.62938233, Gradient norm: 1.85136464
INFO:root:At the start of the epoch: mem (CPU python)=18152.7890625MB; mem (CPU total)=17913.41015625MB
INFO:root:[  107] Training loss: 0.64501481, Validation loss: 0.62883130, Gradient norm: 1.84358002
INFO:root:At the start of the epoch: mem (CPU python)=18190.88671875MB; mem (CPU total)=17951.546875MB
INFO:root:[  108] Training loss: 0.64491264, Validation loss: 0.62876123, Gradient norm: 1.77833968
INFO:root:At the start of the epoch: mem (CPU python)=18228.99609375MB; mem (CPU total)=17989.62109375MB
INFO:root:[  109] Training loss: 0.64477840, Validation loss: 0.62917504, Gradient norm: 1.75532976
INFO:root:At the start of the epoch: mem (CPU python)=18267.05078125MB; mem (CPU total)=18027.76953125MB
INFO:root:[  110] Training loss: 0.64489131, Validation loss: 0.62930193, Gradient norm: 1.93717765
INFO:root:At the start of the epoch: mem (CPU python)=18305.1875MB; mem (CPU total)=18066.12109375MB
INFO:root:[  111] Training loss: 0.64489599, Validation loss: 0.62921846, Gradient norm: 1.92401740
INFO:root:At the start of the epoch: mem (CPU python)=18343.27734375MB; mem (CPU total)=18104.0MB
INFO:root:EP 111: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=18381.42578125MB; mem (CPU total)=18142.40234375MB
INFO:root:Training the model took 5679.733s.
INFO:root:Emptying the cuda cache took 0.039s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.88899
INFO:root:EnergyScoreTrain: 0.62568
INFO:root:CRPSTrain: 0.50304
INFO:root:Gaussian NLLTrain: 585976956.99556
INFO:root:CoverageTrain: 0.84528
INFO:root:IntervalWidthTrain: 3.05319
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89376
INFO:root:EnergyScoreValidation: 0.62909
INFO:root:CRPSValidation: 0.50648
INFO:root:Gaussian NLLValidation: 671025367.91111
INFO:root:CoverageValidation: 0.84325
INFO:root:IntervalWidthValidation: 3.05209
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89596
INFO:root:EnergyScoreTest: 0.63064
INFO:root:CRPSTest: 0.50813
INFO:root:Gaussian NLLTest: 696280395.0105
INFO:root:CoverageTest: 0.84377
INFO:root:IntervalWidthTest: 3.05898
INFO:root:After validation: mem (CPU python)=18421.83984375MB; mem (CPU total)=18187.7734375MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=18421.83984375MB; mem (CPU total)=18187.7734375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=18421.83984375MB; mem (CPU total)=18188.265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=18421.83984375MB; mem (CPU total)=18188.26171875MB
INFO:root:[    1] Training loss: 0.72427121, Validation loss: 0.72060816, Gradient norm: 0.01393422
INFO:root:At the start of the epoch: mem (CPU python)=18463.73828125MB; mem (CPU total)=18227.01171875MB
INFO:root:[    2] Training loss: 0.71987614, Validation loss: 0.71923195, Gradient norm: 0.00640131
INFO:root:At the start of the epoch: mem (CPU python)=18501.84765625MB; mem (CPU total)=18265.40625MB
INFO:root:[    3] Training loss: 0.71803941, Validation loss: 0.71414200, Gradient norm: 0.01377845
INFO:root:At the start of the epoch: mem (CPU python)=18539.953125MB; mem (CPU total)=18303.55078125MB
INFO:root:[    4] Training loss: 0.71159612, Validation loss: 0.70477990, Gradient norm: 0.03040823
INFO:root:At the start of the epoch: mem (CPU python)=18578.0625MB; mem (CPU total)=18341.6953125MB
INFO:root:[    5] Training loss: 0.70529516, Validation loss: 0.69865033, Gradient norm: 0.03714599
INFO:root:At the start of the epoch: mem (CPU python)=18616.15625MB; mem (CPU total)=18379.84765625MB
INFO:root:[    6] Training loss: 0.70017701, Validation loss: 0.69291801, Gradient norm: 0.04065637
INFO:root:At the start of the epoch: mem (CPU python)=18654.25390625MB; mem (CPU total)=18417.953125MB
INFO:root:[    7] Training loss: 0.69568589, Validation loss: 0.68774565, Gradient norm: 0.04843877
INFO:root:At the start of the epoch: mem (CPU python)=18692.34765625MB; mem (CPU total)=18456.0859375MB
INFO:root:[    8] Training loss: 0.69142846, Validation loss: 0.68334148, Gradient norm: 0.04569775
INFO:root:At the start of the epoch: mem (CPU python)=18730.44140625MB; mem (CPU total)=18494.0703125MB
INFO:root:[    9] Training loss: 0.68768009, Validation loss: 0.67834319, Gradient norm: 0.04585567
INFO:root:At the start of the epoch: mem (CPU python)=18768.46875MB; mem (CPU total)=18532.171875MB
INFO:root:[   10] Training loss: 0.68415425, Validation loss: 0.67427161, Gradient norm: 0.04288518
INFO:root:At the start of the epoch: mem (CPU python)=18806.63671875MB; mem (CPU total)=18570.26953125MB
INFO:root:[   11] Training loss: 0.68049323, Validation loss: 0.66956012, Gradient norm: 0.03899944
INFO:root:At the start of the epoch: mem (CPU python)=18844.67578125MB; mem (CPU total)=18608.375MB
INFO:root:[   12] Training loss: 0.67716339, Validation loss: 0.66586726, Gradient norm: 0.04418952
INFO:root:At the start of the epoch: mem (CPU python)=18882.828125MB; mem (CPU total)=18646.5MB
INFO:root:[   13] Training loss: 0.67403175, Validation loss: 0.66236667, Gradient norm: 0.04372862
INFO:root:At the start of the epoch: mem (CPU python)=18920.92578125MB; mem (CPU total)=18684.99609375MB
INFO:root:[   14] Training loss: 0.67137268, Validation loss: 0.65998898, Gradient norm: 0.04081213
INFO:root:At the start of the epoch: mem (CPU python)=18959.01953125MB; mem (CPU total)=18723.10546875MB
INFO:root:[   15] Training loss: 0.66909749, Validation loss: 0.65764892, Gradient norm: 0.04507739
INFO:root:At the start of the epoch: mem (CPU python)=18997.11328125MB; mem (CPU total)=18761.4765625MB
INFO:root:[   16] Training loss: 0.66713532, Validation loss: 0.65513725, Gradient norm: 0.04051483
INFO:root:At the start of the epoch: mem (CPU python)=19035.21484375MB; mem (CPU total)=18799.10546875MB
INFO:root:[   17] Training loss: 0.66533207, Validation loss: 0.65275342, Gradient norm: 0.04315494
INFO:root:At the start of the epoch: mem (CPU python)=19073.25390625MB; mem (CPU total)=18837.04296875MB
INFO:root:[   18] Training loss: 0.66361362, Validation loss: 0.65127393, Gradient norm: 0.04471120
INFO:root:At the start of the epoch: mem (CPU python)=19111.34765625MB; mem (CPU total)=18875.1484375MB
INFO:root:[   19] Training loss: 0.66211783, Validation loss: 0.65009992, Gradient norm: 0.05183495
INFO:root:At the start of the epoch: mem (CPU python)=19149.42578125MB; mem (CPU total)=18913.85546875MB
INFO:root:[   20] Training loss: 0.66060950, Validation loss: 0.64795399, Gradient norm: 0.05425550
INFO:root:At the start of the epoch: mem (CPU python)=19187.42578125MB; mem (CPU total)=18951.9921875MB
INFO:root:[   21] Training loss: 0.65943022, Validation loss: 0.64694430, Gradient norm: 0.04826519
INFO:root:At the start of the epoch: mem (CPU python)=19225.6015625MB; mem (CPU total)=18990.109375MB
INFO:root:[   22] Training loss: 0.65827118, Validation loss: 0.64495398, Gradient norm: 0.04529081
INFO:root:At the start of the epoch: mem (CPU python)=19263.6953125MB; mem (CPU total)=19027.9765625MB
INFO:root:[   23] Training loss: 0.65695387, Validation loss: 0.64374842, Gradient norm: 0.04937264
INFO:root:At the start of the epoch: mem (CPU python)=19301.828125MB; mem (CPU total)=19066.265625MB
INFO:root:[   24] Training loss: 0.65599741, Validation loss: 0.64300401, Gradient norm: 0.05720690
INFO:root:At the start of the epoch: mem (CPU python)=19339.921875MB; mem (CPU total)=19104.609375MB
INFO:root:[   25] Training loss: 0.65486624, Validation loss: 0.64204429, Gradient norm: 0.05960315
INFO:root:At the start of the epoch: mem (CPU python)=19378.0078125MB; mem (CPU total)=19142.71484375MB
INFO:root:[   26] Training loss: 0.65397580, Validation loss: 0.64032446, Gradient norm: 0.05302508
INFO:root:At the start of the epoch: mem (CPU python)=19416.1015625MB; mem (CPU total)=19180.5703125MB
INFO:root:[   27] Training loss: 0.65304132, Validation loss: 0.64067529, Gradient norm: 0.05837328
INFO:root:At the start of the epoch: mem (CPU python)=19454.26171875MB; mem (CPU total)=19219.4296875MB
INFO:root:[   28] Training loss: 0.65211714, Validation loss: 0.63866324, Gradient norm: 0.05792995
INFO:root:At the start of the epoch: mem (CPU python)=19492.35546875MB; mem (CPU total)=19256.80078125MB
INFO:root:[   29] Training loss: 0.65140472, Validation loss: 0.63837219, Gradient norm: 0.06819364
INFO:root:At the start of the epoch: mem (CPU python)=19530.41796875MB; mem (CPU total)=19294.91015625MB
INFO:root:[   30] Training loss: 0.65067495, Validation loss: 0.63738416, Gradient norm: 0.07453810
INFO:root:At the start of the epoch: mem (CPU python)=19568.5546875MB; mem (CPU total)=19333.56640625MB
INFO:root:[   31] Training loss: 0.64986696, Validation loss: 0.63669937, Gradient norm: 0.07672590
INFO:root:At the start of the epoch: mem (CPU python)=19606.58203125MB; mem (CPU total)=19371.66015625MB
INFO:root:[   32] Training loss: 0.64916450, Validation loss: 0.63570277, Gradient norm: 0.06947434
INFO:root:At the start of the epoch: mem (CPU python)=19644.67578125MB; mem (CPU total)=19409.734375MB
INFO:root:[   33] Training loss: 0.64852815, Validation loss: 0.63498875, Gradient norm: 0.09076220
INFO:root:At the start of the epoch: mem (CPU python)=19682.83203125MB; mem (CPU total)=19447.5859375MB
INFO:root:[   34] Training loss: 0.64781924, Validation loss: 0.63348640, Gradient norm: 0.07989749
INFO:root:At the start of the epoch: mem (CPU python)=19720.92578125MB; mem (CPU total)=19485.703125MB
INFO:root:[   35] Training loss: 0.64714829, Validation loss: 0.63442951, Gradient norm: 0.09713535
INFO:root:At the start of the epoch: mem (CPU python)=19759.0234375MB; mem (CPU total)=19524.30078125MB
INFO:root:[   36] Training loss: 0.64667966, Validation loss: 0.63255462, Gradient norm: 0.10166984
INFO:root:At the start of the epoch: mem (CPU python)=19797.1171875MB; mem (CPU total)=19562.17578125MB
INFO:root:[   37] Training loss: 0.64605039, Validation loss: 0.63283334, Gradient norm: 0.10386887
INFO:root:At the start of the epoch: mem (CPU python)=19835.21484375MB; mem (CPU total)=19600.05078125MB
INFO:root:[   38] Training loss: 0.64552663, Validation loss: 0.63197582, Gradient norm: 0.08649290
INFO:root:At the start of the epoch: mem (CPU python)=19873.24609375MB; mem (CPU total)=19638.1796875MB
INFO:root:[   39] Training loss: 0.64510526, Validation loss: 0.63163040, Gradient norm: 0.11264048
INFO:root:At the start of the epoch: mem (CPU python)=19911.34765625MB; mem (CPU total)=19676.08984375MB
INFO:root:[   40] Training loss: 0.64441076, Validation loss: 0.63011925, Gradient norm: 0.13258036
INFO:root:At the start of the epoch: mem (CPU python)=19949.421875MB; mem (CPU total)=19714.20703125MB
INFO:root:[   41] Training loss: 0.64418057, Validation loss: 0.62934098, Gradient norm: 0.11370586
INFO:root:At the start of the epoch: mem (CPU python)=19987.49609375MB; mem (CPU total)=19752.48828125MB
INFO:root:[   42] Training loss: 0.64356712, Validation loss: 0.63014456, Gradient norm: 0.11315849
INFO:root:At the start of the epoch: mem (CPU python)=20025.5625MB; mem (CPU total)=19791.6015625MB
INFO:root:[   43] Training loss: 0.64329612, Validation loss: 0.63050966, Gradient norm: 0.12689041
INFO:root:At the start of the epoch: mem (CPU python)=20063.7265625MB; mem (CPU total)=19829.7109375MB
INFO:root:[   44] Training loss: 0.64288239, Validation loss: 0.62884389, Gradient norm: 0.16453647
INFO:root:At the start of the epoch: mem (CPU python)=20101.89453125MB; mem (CPU total)=19867.33203125MB
INFO:root:[   45] Training loss: 0.64251426, Validation loss: 0.62938612, Gradient norm: 0.14789736
INFO:root:At the start of the epoch: mem (CPU python)=20139.9296875MB; mem (CPU total)=19905.94921875MB
INFO:root:[   46] Training loss: 0.64208868, Validation loss: 0.62880819, Gradient norm: 0.14189717
INFO:root:At the start of the epoch: mem (CPU python)=20178.015625MB; mem (CPU total)=19943.57421875MB
INFO:root:[   47] Training loss: 0.64155300, Validation loss: 0.62781247, Gradient norm: 0.16051880
INFO:root:At the start of the epoch: mem (CPU python)=20216.12109375MB; mem (CPU total)=19981.69921875MB
INFO:root:[   48] Training loss: 0.64123581, Validation loss: 0.62855305, Gradient norm: 0.16327607
INFO:root:At the start of the epoch: mem (CPU python)=20254.26953125MB; mem (CPU total)=20020.58203125MB
INFO:root:[   49] Training loss: 0.64093201, Validation loss: 0.62910655, Gradient norm: 0.14915738
INFO:root:At the start of the epoch: mem (CPU python)=20292.3671875MB; mem (CPU total)=20058.6875MB
INFO:root:[   50] Training loss: 0.64069830, Validation loss: 0.62795864, Gradient norm: 0.16899554
INFO:root:At the start of the epoch: mem (CPU python)=20330.46484375MB; mem (CPU total)=20096.76953125MB
INFO:root:[   51] Training loss: 0.64026026, Validation loss: 0.62849654, Gradient norm: 0.20862758
INFO:root:At the start of the epoch: mem (CPU python)=20368.546875MB; mem (CPU total)=20135.83984375MB
INFO:root:[   52] Training loss: 0.64015969, Validation loss: 0.62917284, Gradient norm: 0.24067757
INFO:root:At the start of the epoch: mem (CPU python)=20406.64453125MB; mem (CPU total)=20174.25MB
INFO:root:[   53] Training loss: 0.63964765, Validation loss: 0.62852330, Gradient norm: 0.19091453
INFO:root:At the start of the epoch: mem (CPU python)=20444.7265625MB; mem (CPU total)=20212.33203125MB
INFO:root:[   54] Training loss: 0.63946555, Validation loss: 0.62572520, Gradient norm: 0.19939738
INFO:root:At the start of the epoch: mem (CPU python)=20482.78125MB; mem (CPU total)=20250.21484375MB
INFO:root:[   55] Training loss: 0.63912893, Validation loss: 0.62655141, Gradient norm: 0.20995440
INFO:root:At the start of the epoch: mem (CPU python)=20520.8828125MB; mem (CPU total)=20288.65625MB
INFO:root:[   56] Training loss: 0.63872969, Validation loss: 0.62685040, Gradient norm: 0.23708397
INFO:root:At the start of the epoch: mem (CPU python)=20559.0MB; mem (CPU total)=20326.81640625MB
INFO:root:[   57] Training loss: 0.63862243, Validation loss: 0.62663787, Gradient norm: 0.24022120
INFO:root:At the start of the epoch: mem (CPU python)=20597.12890625MB; mem (CPU total)=20364.9453125MB
INFO:root:[   58] Training loss: 0.63827760, Validation loss: 0.62861450, Gradient norm: 0.21898523
INFO:root:At the start of the epoch: mem (CPU python)=20635.2265625MB; mem (CPU total)=20403.1171875MB
INFO:root:[   59] Training loss: 0.63826164, Validation loss: 0.62567416, Gradient norm: 0.28722254
INFO:root:At the start of the epoch: mem (CPU python)=20673.265625MB; mem (CPU total)=20441.27734375MB
INFO:root:[   60] Training loss: 0.63804712, Validation loss: 0.62460177, Gradient norm: 0.26933575
INFO:root:At the start of the epoch: mem (CPU python)=20711.359375MB; mem (CPU total)=20479.390625MB
INFO:root:[   61] Training loss: 0.63772758, Validation loss: 0.62472241, Gradient norm: 0.25869098
INFO:root:At the start of the epoch: mem (CPU python)=20749.44921875MB; mem (CPU total)=20518.25390625MB
INFO:root:[   62] Training loss: 0.63749323, Validation loss: 0.62545753, Gradient norm: 0.26611270
INFO:root:At the start of the epoch: mem (CPU python)=20787.55078125MB; mem (CPU total)=20556.125MB
INFO:root:[   63] Training loss: 0.63717238, Validation loss: 0.62541032, Gradient norm: 0.27054470
INFO:root:At the start of the epoch: mem (CPU python)=20825.61328125MB; mem (CPU total)=20594.55078125MB
INFO:root:[   64] Training loss: 0.63698630, Validation loss: 0.62498745, Gradient norm: 0.28999084
INFO:root:At the start of the epoch: mem (CPU python)=20863.7421875MB; mem (CPU total)=20632.69140625MB
INFO:root:[   65] Training loss: 0.63702240, Validation loss: 0.62399273, Gradient norm: 0.35229117
INFO:root:At the start of the epoch: mem (CPU python)=20901.83203125MB; mem (CPU total)=20670.3203125MB
INFO:root:[   66] Training loss: 0.63652757, Validation loss: 0.62397110, Gradient norm: 0.29707532
INFO:root:At the start of the epoch: mem (CPU python)=20939.93359375MB; mem (CPU total)=20708.75390625MB
INFO:root:[   67] Training loss: 0.63645708, Validation loss: 0.62420997, Gradient norm: 0.35002039
INFO:root:At the start of the epoch: mem (CPU python)=20978.03125MB; mem (CPU total)=20747.5390625MB
INFO:root:[   68] Training loss: 0.63616244, Validation loss: 0.62421016, Gradient norm: 0.31757279
INFO:root:At the start of the epoch: mem (CPU python)=21016.1328125MB; mem (CPU total)=20785.90234375MB
INFO:root:[   69] Training loss: 0.63602305, Validation loss: 0.62427672, Gradient norm: 0.36805038
INFO:root:At the start of the epoch: mem (CPU python)=21054.22265625MB; mem (CPU total)=20824.05859375MB
INFO:root:[   70] Training loss: 0.63579857, Validation loss: 0.62278478, Gradient norm: 0.33523521
INFO:root:At the start of the epoch: mem (CPU python)=21092.3828125MB; mem (CPU total)=20860.96875MB
INFO:root:[   71] Training loss: 0.63583785, Validation loss: 0.62274541, Gradient norm: 0.41736880
INFO:root:At the start of the epoch: mem (CPU python)=21130.47265625MB; mem (CPU total)=20899.11328125MB
INFO:root:[   72] Training loss: 0.63551826, Validation loss: 0.62219559, Gradient norm: 0.39352447
INFO:root:At the start of the epoch: mem (CPU python)=21168.56640625MB; mem (CPU total)=20937.2421875MB
INFO:root:[   73] Training loss: 0.63534833, Validation loss: 0.62160981, Gradient norm: 0.37692447
INFO:root:At the start of the epoch: mem (CPU python)=21206.66015625MB; mem (CPU total)=20975.63671875MB
INFO:root:[   74] Training loss: 0.63544514, Validation loss: 0.62169219, Gradient norm: 0.42930296
INFO:root:At the start of the epoch: mem (CPU python)=21244.76171875MB; mem (CPU total)=21014.125MB
INFO:root:[   75] Training loss: 0.63507634, Validation loss: 0.62226621, Gradient norm: 0.39688610
INFO:root:At the start of the epoch: mem (CPU python)=21282.85546875MB; mem (CPU total)=21052.265625MB
INFO:root:[   76] Training loss: 0.63502976, Validation loss: 0.62066626, Gradient norm: 0.42612053
INFO:root:At the start of the epoch: mem (CPU python)=21320.94921875MB; mem (CPU total)=21090.15625MB
INFO:root:[   77] Training loss: 0.63475685, Validation loss: 0.62276446, Gradient norm: 0.46646455
INFO:root:At the start of the epoch: mem (CPU python)=21359.03515625MB; mem (CPU total)=21128.796875MB
INFO:root:[   78] Training loss: 0.63462898, Validation loss: 0.62168382, Gradient norm: 0.46184412
INFO:root:At the start of the epoch: mem (CPU python)=21397.13671875MB; mem (CPU total)=21167.0234375MB
INFO:root:[   79] Training loss: 0.63449123, Validation loss: 0.62020397, Gradient norm: 0.44830264
INFO:root:At the start of the epoch: mem (CPU python)=21435.23046875MB; mem (CPU total)=21205.046875MB
INFO:root:[   80] Training loss: 0.63430404, Validation loss: 0.62065918, Gradient norm: 0.45693587
INFO:root:At the start of the epoch: mem (CPU python)=21473.265625MB; mem (CPU total)=21243.9140625MB
INFO:root:[   81] Training loss: 0.63419927, Validation loss: 0.62090439, Gradient norm: 0.47556443
INFO:root:At the start of the epoch: mem (CPU python)=21511.34765625MB; mem (CPU total)=21282.0703125MB
INFO:root:[   82] Training loss: 0.63437958, Validation loss: 0.62197727, Gradient norm: 0.55421307
INFO:root:At the start of the epoch: mem (CPU python)=21549.40234375MB; mem (CPU total)=21320.1640625MB
INFO:root:[   83] Training loss: 0.63418755, Validation loss: 0.62107016, Gradient norm: 0.51834753
INFO:root:At the start of the epoch: mem (CPU python)=21587.390625MB; mem (CPU total)=21358.53125MB
INFO:root:[   84] Training loss: 0.63395735, Validation loss: 0.62040752, Gradient norm: 0.54879655
INFO:root:At the start of the epoch: mem (CPU python)=21625.66015625MB; mem (CPU total)=21396.68359375MB
INFO:root:[   85] Training loss: 0.63388153, Validation loss: 0.61970695, Gradient norm: 0.55627300
INFO:root:At the start of the epoch: mem (CPU python)=21663.71875MB; mem (CPU total)=21433.828125MB
INFO:root:[   86] Training loss: 0.63388044, Validation loss: 0.62017245, Gradient norm: 0.59550595
INFO:root:At the start of the epoch: mem (CPU python)=21701.84765625MB; mem (CPU total)=21472.68359375MB
INFO:root:[   87] Training loss: 0.63369459, Validation loss: 0.61976569, Gradient norm: 0.60127311
INFO:root:At the start of the epoch: mem (CPU python)=21739.8671875MB; mem (CPU total)=21510.80078125MB
INFO:root:[   88] Training loss: 0.63346050, Validation loss: 0.61976010, Gradient norm: 0.56919664
INFO:root:At the start of the epoch: mem (CPU python)=21778.0390625MB; mem (CPU total)=21548.67578125MB
INFO:root:[   89] Training loss: 0.63372501, Validation loss: 0.61996447, Gradient norm: 0.64151444
INFO:root:At the start of the epoch: mem (CPU python)=21816.12109375MB; mem (CPU total)=21586.80078125MB
INFO:root:[   90] Training loss: 0.63353240, Validation loss: 0.61951697, Gradient norm: 0.68147970
INFO:root:At the start of the epoch: mem (CPU python)=21854.28125MB; mem (CPU total)=21624.171875MB
INFO:root:[   91] Training loss: 0.63323932, Validation loss: 0.61940498, Gradient norm: 0.67500443
INFO:root:At the start of the epoch: mem (CPU python)=21892.37890625MB; mem (CPU total)=21662.31640625MB
INFO:root:[   92] Training loss: 0.63340963, Validation loss: 0.61970178, Gradient norm: 0.70411488
INFO:root:At the start of the epoch: mem (CPU python)=21930.46875MB; mem (CPU total)=21701.2265625MB
INFO:root:[   93] Training loss: 0.63344900, Validation loss: 0.62036684, Gradient norm: 0.82393065
INFO:root:At the start of the epoch: mem (CPU python)=21968.56640625MB; mem (CPU total)=21738.1796875MB
INFO:root:[   94] Training loss: 0.63323632, Validation loss: 0.61923189, Gradient norm: 0.75913824
INFO:root:At the start of the epoch: mem (CPU python)=22006.65234375MB; mem (CPU total)=21775.7890625MB
INFO:root:[   95] Training loss: 0.63292337, Validation loss: 0.61862062, Gradient norm: 0.70929601
INFO:root:At the start of the epoch: mem (CPU python)=22044.76171875MB; mem (CPU total)=21813.66796875MB
INFO:root:[   96] Training loss: 0.63281250, Validation loss: 0.61943450, Gradient norm: 0.77051195
INFO:root:At the start of the epoch: mem (CPU python)=22082.84765625MB; mem (CPU total)=21851.37890625MB
INFO:root:[   97] Training loss: 0.63288698, Validation loss: 0.61881806, Gradient norm: 0.83811495
INFO:root:At the start of the epoch: mem (CPU python)=22120.94140625MB; mem (CPU total)=21889.5078125MB
INFO:root:[   98] Training loss: 0.63295184, Validation loss: 0.61907962, Gradient norm: 0.94195766
INFO:root:At the start of the epoch: mem (CPU python)=22159.03125MB; mem (CPU total)=21927.88671875MB
INFO:root:[   99] Training loss: 0.63262260, Validation loss: 0.61884825, Gradient norm: 0.83488652
INFO:root:At the start of the epoch: mem (CPU python)=22197.1328125MB; mem (CPU total)=21966.0078125MB
INFO:root:[  100] Training loss: 0.63254730, Validation loss: 0.61871137, Gradient norm: 0.88565495
INFO:root:At the start of the epoch: mem (CPU python)=22235.2109375MB; mem (CPU total)=22004.09765625MB
INFO:root:[  101] Training loss: 0.63242412, Validation loss: 0.61814781, Gradient norm: 0.92818564
INFO:root:At the start of the epoch: mem (CPU python)=22273.26171875MB; mem (CPU total)=22041.9296875MB
INFO:root:[  102] Training loss: 0.63238932, Validation loss: 0.61913533, Gradient norm: 0.91738046
INFO:root:At the start of the epoch: mem (CPU python)=22311.33984375MB; mem (CPU total)=22080.62109375MB
INFO:root:[  103] Training loss: 0.63236471, Validation loss: 0.61868885, Gradient norm: 0.96269493
INFO:root:At the start of the epoch: mem (CPU python)=22349.4296875MB; mem (CPU total)=22118.7578125MB
INFO:root:[  104] Training loss: 0.63280487, Validation loss: 0.61831099, Gradient norm: 1.27221015
INFO:root:At the start of the epoch: mem (CPU python)=22387.546875MB; mem (CPU total)=22156.87109375MB
INFO:root:[  105] Training loss: 0.63240562, Validation loss: 0.61785785, Gradient norm: 0.90529294
INFO:root:At the start of the epoch: mem (CPU python)=22425.64453125MB; mem (CPU total)=22194.5078125MB
INFO:root:[  106] Training loss: 0.63234295, Validation loss: 0.61809284, Gradient norm: 1.06789579
INFO:root:At the start of the epoch: mem (CPU python)=22463.734375MB; mem (CPU total)=22233.87109375MB
INFO:root:[  107] Training loss: 0.63245838, Validation loss: 0.61913617, Gradient norm: 1.05297095
INFO:root:At the start of the epoch: mem (CPU python)=22501.828125MB; mem (CPU total)=22271.98828125MB
INFO:root:[  108] Training loss: 0.63213770, Validation loss: 0.61827535, Gradient norm: 0.99230807
INFO:root:At the start of the epoch: mem (CPU python)=22539.92578125MB; mem (CPU total)=22310.08203125MB
INFO:root:[  109] Training loss: 0.63215825, Validation loss: 0.61788210, Gradient norm: 1.12757777
INFO:root:At the start of the epoch: mem (CPU python)=22578.0234375MB; mem (CPU total)=22348.1953125MB
INFO:root:[  110] Training loss: 0.63212265, Validation loss: 0.61805147, Gradient norm: 1.03193879
INFO:root:At the start of the epoch: mem (CPU python)=22616.1171875MB; mem (CPU total)=22386.578125MB
INFO:root:[  111] Training loss: 0.63231032, Validation loss: 0.61689040, Gradient norm: 1.33119887
INFO:root:At the start of the epoch: mem (CPU python)=22654.2109375MB; mem (CPU total)=22424.1015625MB
INFO:root:[  112] Training loss: 0.63232678, Validation loss: 0.61763968, Gradient norm: 1.47177282
INFO:root:At the start of the epoch: mem (CPU python)=22692.3671875MB; mem (CPU total)=22462.96484375MB
INFO:root:[  113] Training loss: 0.63211005, Validation loss: 0.61772427, Gradient norm: 1.17469466
INFO:root:At the start of the epoch: mem (CPU python)=22730.4453125MB; mem (CPU total)=22501.1015625MB
INFO:root:[  114] Training loss: 0.63212708, Validation loss: 0.61815292, Gradient norm: 1.13603947
INFO:root:At the start of the epoch: mem (CPU python)=22768.546875MB; mem (CPU total)=22538.95703125MB
INFO:root:[  115] Training loss: 0.63217728, Validation loss: 0.61750282, Gradient norm: 1.51942451
INFO:root:At the start of the epoch: mem (CPU python)=22806.63671875MB; mem (CPU total)=22577.09765625MB
INFO:root:[  116] Training loss: 0.63211216, Validation loss: 0.61750009, Gradient norm: 1.24178867
INFO:root:At the start of the epoch: mem (CPU python)=22844.74609375MB; mem (CPU total)=22615.7578125MB
INFO:root:[  117] Training loss: 0.63211456, Validation loss: 0.61833826, Gradient norm: 1.51780879
INFO:root:At the start of the epoch: mem (CPU python)=22882.84375MB; mem (CPU total)=22653.859375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  118] Training loss: 0.63207779, Validation loss: 0.61809800, Gradient norm: 1.74587754
INFO:root:At the start of the epoch: mem (CPU python)=22920.93359375MB; mem (CPU total)=22693.3203125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  119] Training loss: 0.63076917, Validation loss: 0.61623356, Gradient norm: 0.80889588
INFO:root:At the start of the epoch: mem (CPU python)=22959.02734375MB; mem (CPU total)=22731.1953125MB
INFO:root:[  120] Training loss: 0.63025616, Validation loss: 0.61579804, Gradient norm: 0.62000741
INFO:root:At the start of the epoch: mem (CPU python)=22997.08203125MB; mem (CPU total)=22769.35546875MB
INFO:root:[  121] Training loss: 0.63027467, Validation loss: 0.61576742, Gradient norm: 0.67826839
INFO:root:At the start of the epoch: mem (CPU python)=23035.22265625MB; mem (CPU total)=22807.72265625MB
INFO:root:[  122] Training loss: 0.63037046, Validation loss: 0.61621000, Gradient norm: 0.68604701
INFO:root:At the start of the epoch: mem (CPU python)=23073.21875MB; mem (CPU total)=22846.4609375MB
INFO:root:[  123] Training loss: 0.63024269, Validation loss: 0.61573894, Gradient norm: 0.74809509
INFO:root:At the start of the epoch: mem (CPU python)=23111.3046875MB; mem (CPU total)=22883.8828125MB
INFO:root:[  124] Training loss: 0.63031120, Validation loss: 0.61559477, Gradient norm: 0.79144021
INFO:root:At the start of the epoch: mem (CPU python)=23149.39453125MB; mem (CPU total)=22922.00390625MB
INFO:root:[  125] Training loss: 0.63031080, Validation loss: 0.61631094, Gradient norm: 0.89440083
INFO:root:At the start of the epoch: mem (CPU python)=23187.5078125MB; mem (CPU total)=22960.8671875MB
INFO:root:[  126] Training loss: 0.63024383, Validation loss: 0.61568515, Gradient norm: 0.94757078
INFO:root:At the start of the epoch: mem (CPU python)=23225.62890625MB; mem (CPU total)=22998.9921875MB
INFO:root:[  127] Training loss: 0.63031086, Validation loss: 0.61642352, Gradient norm: 0.97332289
INFO:root:At the start of the epoch: mem (CPU python)=23263.73828125MB; mem (CPU total)=23037.57421875MB
INFO:root:[  128] Training loss: 0.63030263, Validation loss: 0.61656684, Gradient norm: 0.92691590
INFO:root:At the start of the epoch: mem (CPU python)=23301.8359375MB; mem (CPU total)=23075.71875MB
INFO:root:[  129] Training loss: 0.63030224, Validation loss: 0.61638410, Gradient norm: 1.02627431
INFO:root:At the start of the epoch: mem (CPU python)=23339.93359375MB; mem (CPU total)=23114.296875MB
INFO:root:[  130] Training loss: 0.63007375, Validation loss: 0.61639555, Gradient norm: 1.08416765
INFO:root:At the start of the epoch: mem (CPU python)=23378.02734375MB; mem (CPU total)=23152.04296875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  131] Training loss: 0.63026478, Validation loss: 0.61592501, Gradient norm: 1.14724446
INFO:root:At the start of the epoch: mem (CPU python)=23416.12109375MB; mem (CPU total)=23190.13671875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  132] Training loss: 0.62986286, Validation loss: 0.61579357, Gradient norm: 0.83452489
INFO:root:At the start of the epoch: mem (CPU python)=23454.2109375MB; mem (CPU total)=23228.25390625MB
INFO:root:[  133] Training loss: 0.62965766, Validation loss: 0.61536723, Gradient norm: 0.69818417
INFO:root:At the start of the epoch: mem (CPU python)=23492.3671875MB; mem (CPU total)=23265.65234375MB
INFO:root:[  134] Training loss: 0.62965642, Validation loss: 0.61498352, Gradient norm: 0.74182611
INFO:root:At the start of the epoch: mem (CPU python)=23530.44921875MB; mem (CPU total)=23304.0234375MB
INFO:root:[  135] Training loss: 0.62966926, Validation loss: 0.61597142, Gradient norm: 0.74472080
INFO:root:At the start of the epoch: mem (CPU python)=23568.55078125MB; mem (CPU total)=23342.375MB
INFO:root:[  136] Training loss: 0.62972818, Validation loss: 0.61526218, Gradient norm: 0.71193700
INFO:root:At the start of the epoch: mem (CPU python)=23606.65234375MB; mem (CPU total)=23380.7265625MB
INFO:root:[  137] Training loss: 0.62973365, Validation loss: 0.61584632, Gradient norm: 0.80212565
INFO:root:At the start of the epoch: mem (CPU python)=23644.74609375MB; mem (CPU total)=23419.37109375MB
INFO:root:[  138] Training loss: 0.62965048, Validation loss: 0.61588136, Gradient norm: 0.73387651
INFO:root:At the start of the epoch: mem (CPU python)=23682.84375MB; mem (CPU total)=23457.44140625MB
INFO:root:[  139] Training loss: 0.62976817, Validation loss: 0.61530692, Gradient norm: 0.80947588
INFO:root:At the start of the epoch: mem (CPU python)=23720.9375MB; mem (CPU total)=23495.48828125MB
INFO:root:[  140] Training loss: 0.62961458, Validation loss: 0.61587419, Gradient norm: 0.86031670
INFO:root:At the start of the epoch: mem (CPU python)=23759.02734375MB; mem (CPU total)=23533.5703125MB
INFO:root:[  141] Training loss: 0.62956844, Validation loss: 0.61629898, Gradient norm: 0.86771407
INFO:root:At the start of the epoch: mem (CPU python)=23797.07421875MB; mem (CPU total)=23571.68359375MB
INFO:root:[  142] Training loss: 0.62946008, Validation loss: 0.61520415, Gradient norm: 0.79061142
INFO:root:At the start of the epoch: mem (CPU python)=23835.2265625MB; mem (CPU total)=23609.6171875MB
INFO:root:[  143] Training loss: 0.62959877, Validation loss: 0.61561263, Gradient norm: 0.82604867
INFO:root:At the start of the epoch: mem (CPU python)=23873.234375MB; mem (CPU total)=23648.1171875MB
INFO:root:EP 143: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=23911.3515625MB; mem (CPU total)=23686.25MB
INFO:root:Training the model took 7985.508s.
INFO:root:Emptying the cuda cache took 0.04s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86538
INFO:root:EnergyScoreTrain: 0.60906
INFO:root:CRPSTrain: 0.49012
INFO:root:Gaussian NLLTrain: 335579001.12
INFO:root:CoverageTrain: 0.81094
INFO:root:IntervalWidthTrain: 2.89663
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87467
INFO:root:EnergyScoreValidation: 0.6157
INFO:root:CRPSValidation: 0.49651
INFO:root:Gaussian NLLValidation: 335649422.15111
INFO:root:CoverageValidation: 0.80803
INFO:root:IntervalWidthValidation: 2.89977
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87573
INFO:root:EnergyScoreTest: 0.61644
INFO:root:CRPSTest: 0.49748
INFO:root:Gaussian NLLTest: 369177368.192
INFO:root:CoverageTest: 0.80808
INFO:root:IntervalWidthTest: 2.90246
INFO:root:After validation: mem (CPU python)=23978.95703125MB; mem (CPU total)=23760.41015625MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=23978.95703125MB; mem (CPU total)=23760.3984375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=23978.95703125MB; mem (CPU total)=23760.890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=23978.95703125MB; mem (CPU total)=23760.88671875MB
INFO:root:[    1] Training loss: 0.72506652, Validation loss: 0.72055052, Gradient norm: 0.01734822
INFO:root:At the start of the epoch: mem (CPU python)=24024.90625MB; mem (CPU total)=23799.16015625MB
INFO:root:[    2] Training loss: 0.71919096, Validation loss: 0.71564844, Gradient norm: 0.00778639
INFO:root:At the start of the epoch: mem (CPU python)=24063.015625MB; mem (CPU total)=23837.58984375MB
INFO:root:[    3] Training loss: 0.71209053, Validation loss: 0.70514673, Gradient norm: 0.02187540
INFO:root:At the start of the epoch: mem (CPU python)=24101.11328125MB; mem (CPU total)=23875.69140625MB
INFO:root:[    4] Training loss: 0.70558322, Validation loss: 0.69956268, Gradient norm: 0.03113547
INFO:root:At the start of the epoch: mem (CPU python)=24139.2109375MB; mem (CPU total)=23913.84375MB
INFO:root:[    5] Training loss: 0.70040498, Validation loss: 0.69260535, Gradient norm: 0.03852397
INFO:root:At the start of the epoch: mem (CPU python)=24177.29296875MB; mem (CPU total)=23951.01953125MB
INFO:root:[    6] Training loss: 0.69478640, Validation loss: 0.68596955, Gradient norm: 0.03993977
INFO:root:At the start of the epoch: mem (CPU python)=24215.40234375MB; mem (CPU total)=23989.1484375MB
INFO:root:[    7] Training loss: 0.68999683, Validation loss: 0.67953145, Gradient norm: 0.04307720
INFO:root:At the start of the epoch: mem (CPU python)=24253.48828125MB; mem (CPU total)=24027.51171875MB
INFO:root:[    8] Training loss: 0.68594911, Validation loss: 0.67564616, Gradient norm: 0.04579414
INFO:root:At the start of the epoch: mem (CPU python)=24291.578125MB; mem (CPU total)=24065.640625MB
INFO:root:[    9] Training loss: 0.68239489, Validation loss: 0.67171278, Gradient norm: 0.04333916
INFO:root:At the start of the epoch: mem (CPU python)=24329.63671875MB; mem (CPU total)=24103.78515625MB
INFO:root:[   10] Training loss: 0.67915962, Validation loss: 0.66783965, Gradient norm: 0.04214923
INFO:root:At the start of the epoch: mem (CPU python)=24367.703125MB; mem (CPU total)=24141.9296875MB
INFO:root:[   11] Training loss: 0.67629564, Validation loss: 0.66415024, Gradient norm: 0.04069822
INFO:root:At the start of the epoch: mem (CPU python)=24405.8203125MB; mem (CPU total)=24179.08984375MB
INFO:root:[   12] Training loss: 0.67366538, Validation loss: 0.66223526, Gradient norm: 0.04325248
INFO:root:At the start of the epoch: mem (CPU python)=24443.8671875MB; mem (CPU total)=24217.9453125MB
INFO:root:[   13] Training loss: 0.67154872, Validation loss: 0.66049582, Gradient norm: 0.03850134
INFO:root:At the start of the epoch: mem (CPU python)=24481.984375MB; mem (CPU total)=24256.01171875MB
INFO:root:[   14] Training loss: 0.66965868, Validation loss: 0.65702555, Gradient norm: 0.04179169
INFO:root:At the start of the epoch: mem (CPU python)=24520.08203125MB; mem (CPU total)=24293.91015625MB
INFO:root:[   15] Training loss: 0.66779238, Validation loss: 0.65534500, Gradient norm: 0.04094368
INFO:root:At the start of the epoch: mem (CPU python)=24558.23828125MB; mem (CPU total)=24332.0625MB
INFO:root:[   16] Training loss: 0.66613887, Validation loss: 0.65381545, Gradient norm: 0.04260042
INFO:root:At the start of the epoch: mem (CPU python)=24596.375MB; mem (CPU total)=24370.46875MB
INFO:root:[   17] Training loss: 0.66461116, Validation loss: 0.65196635, Gradient norm: 0.04260435
INFO:root:At the start of the epoch: mem (CPU python)=24634.46484375MB; mem (CPU total)=24408.62109375MB
INFO:root:[   18] Training loss: 0.66322683, Validation loss: 0.65070641, Gradient norm: 0.04330332
INFO:root:At the start of the epoch: mem (CPU python)=24672.55078125MB; mem (CPU total)=24446.515625MB
INFO:root:[   19] Training loss: 0.66184876, Validation loss: 0.64889058, Gradient norm: 0.04441551
INFO:root:At the start of the epoch: mem (CPU python)=24710.65625MB; mem (CPU total)=24484.65625MB
INFO:root:[   20] Training loss: 0.66060378, Validation loss: 0.64778984, Gradient norm: 0.04335847
INFO:root:At the start of the epoch: mem (CPU python)=24748.75390625MB; mem (CPU total)=24522.79296875MB
INFO:root:[   21] Training loss: 0.65954520, Validation loss: 0.64647090, Gradient norm: 0.04542815
INFO:root:At the start of the epoch: mem (CPU python)=24786.84765625MB; mem (CPU total)=24561.41796875MB
INFO:root:[   22] Training loss: 0.65833349, Validation loss: 0.64503262, Gradient norm: 0.04609054
INFO:root:At the start of the epoch: mem (CPU python)=24824.93359375MB; mem (CPU total)=24599.30078125MB
INFO:root:[   23] Training loss: 0.65735035, Validation loss: 0.64393659, Gradient norm: 0.04616727
INFO:root:At the start of the epoch: mem (CPU python)=24863.0390625MB; mem (CPU total)=24637.51171875MB
INFO:root:[   24] Training loss: 0.65639553, Validation loss: 0.64228658, Gradient norm: 0.04681585
INFO:root:At the start of the epoch: mem (CPU python)=24901.1328125MB; mem (CPU total)=24675.6640625MB
INFO:root:[   25] Training loss: 0.65555782, Validation loss: 0.64181433, Gradient norm: 0.05159504
INFO:root:At the start of the epoch: mem (CPU python)=24939.2265625MB; mem (CPU total)=24713.82421875MB
INFO:root:[   26] Training loss: 0.65467653, Validation loss: 0.63998006, Gradient norm: 0.04838747
INFO:root:At the start of the epoch: mem (CPU python)=24977.2734375MB; mem (CPU total)=24752.06640625MB
INFO:root:[   27] Training loss: 0.65383387, Validation loss: 0.63996552, Gradient norm: 0.04883497
INFO:root:At the start of the epoch: mem (CPU python)=25015.36328125MB; mem (CPU total)=24790.1875MB
INFO:root:[   28] Training loss: 0.65298259, Validation loss: 0.63833120, Gradient norm: 0.04536186
INFO:root:At the start of the epoch: mem (CPU python)=25053.4609375MB; mem (CPU total)=24827.8203125MB
INFO:root:[   29] Training loss: 0.65215962, Validation loss: 0.63775422, Gradient norm: 0.05070280
INFO:root:At the start of the epoch: mem (CPU python)=25091.55859375MB; mem (CPU total)=24866.1171875MB
INFO:root:[   30] Training loss: 0.65179908, Validation loss: 0.63700937, Gradient norm: 0.05339215
INFO:root:At the start of the epoch: mem (CPU python)=25129.65234375MB; mem (CPU total)=24904.265625MB
INFO:root:[   31] Training loss: 0.65096096, Validation loss: 0.63699208, Gradient norm: 0.04958058
INFO:root:At the start of the epoch: mem (CPU python)=25167.74609375MB; mem (CPU total)=24942.65625MB
INFO:root:[   32] Training loss: 0.65056137, Validation loss: 0.63543982, Gradient norm: 0.05181702
INFO:root:At the start of the epoch: mem (CPU python)=25205.8359375MB; mem (CPU total)=24980.765625MB
INFO:root:[   33] Training loss: 0.64961762, Validation loss: 0.63485013, Gradient norm: 0.05422397
INFO:root:At the start of the epoch: mem (CPU python)=25243.9296875MB; mem (CPU total)=25018.87890625MB
INFO:root:[   34] Training loss: 0.64922973, Validation loss: 0.63454828, Gradient norm: 0.05553529
INFO:root:At the start of the epoch: mem (CPU python)=25282.03515625MB; mem (CPU total)=25057.06640625MB
INFO:root:[   35] Training loss: 0.64865475, Validation loss: 0.63431301, Gradient norm: 0.05930196
INFO:root:At the start of the epoch: mem (CPU python)=25320.12890625MB; mem (CPU total)=25095.1875MB
INFO:root:[   36] Training loss: 0.64807979, Validation loss: 0.63374852, Gradient norm: 0.05616333
INFO:root:At the start of the epoch: mem (CPU python)=25358.2265625MB; mem (CPU total)=25133.30859375MB
INFO:root:[   37] Training loss: 0.64770900, Validation loss: 0.63299211, Gradient norm: 0.05720581
INFO:root:At the start of the epoch: mem (CPU python)=25396.375MB; mem (CPU total)=25171.67578125MB
INFO:root:[   38] Training loss: 0.64720429, Validation loss: 0.63148992, Gradient norm: 0.05715445
INFO:root:At the start of the epoch: mem (CPU python)=25434.46875MB; mem (CPU total)=25209.8046875MB
INFO:root:[   39] Training loss: 0.64673539, Validation loss: 0.63186352, Gradient norm: 0.06427032
INFO:root:At the start of the epoch: mem (CPU python)=25472.55859375MB; mem (CPU total)=25248.6640625MB
INFO:root:[   40] Training loss: 0.64616672, Validation loss: 0.63108548, Gradient norm: 0.05948715
INFO:root:At the start of the epoch: mem (CPU python)=25510.66015625MB; mem (CPU total)=25286.2734375MB
INFO:root:[   41] Training loss: 0.64585295, Validation loss: 0.63129677, Gradient norm: 0.06274449
INFO:root:At the start of the epoch: mem (CPU python)=25548.7578125MB; mem (CPU total)=25324.86328125MB
INFO:root:[   42] Training loss: 0.64561242, Validation loss: 0.63043505, Gradient norm: 0.06441813
INFO:root:At the start of the epoch: mem (CPU python)=25586.85546875MB; mem (CPU total)=25362.74609375MB
INFO:root:[   43] Training loss: 0.64512586, Validation loss: 0.62972245, Gradient norm: 0.06819928
INFO:root:At the start of the epoch: mem (CPU python)=25624.953125MB; mem (CPU total)=25400.6484375MB
INFO:root:[   44] Training loss: 0.64458975, Validation loss: 0.63015707, Gradient norm: 0.06579886
INFO:root:At the start of the epoch: mem (CPU python)=25663.046875MB; mem (CPU total)=25439.27734375MB
INFO:root:[   45] Training loss: 0.64423221, Validation loss: 0.62911169, Gradient norm: 0.06940294
INFO:root:At the start of the epoch: mem (CPU python)=25701.109375MB; mem (CPU total)=25477.640625MB
INFO:root:[   46] Training loss: 0.64390524, Validation loss: 0.62906014, Gradient norm: 0.06745353
INFO:root:At the start of the epoch: mem (CPU python)=25739.23828125MB; mem (CPU total)=25515.76171875MB
INFO:root:[   47] Training loss: 0.64380047, Validation loss: 0.62865290, Gradient norm: 0.07628631
INFO:root:At the start of the epoch: mem (CPU python)=25777.26953125MB; mem (CPU total)=25553.84765625MB
INFO:root:[   48] Training loss: 0.64308830, Validation loss: 0.62884295, Gradient norm: 0.07379524
INFO:root:At the start of the epoch: mem (CPU python)=25815.36328125MB; mem (CPU total)=25592.4609375MB
INFO:root:[   49] Training loss: 0.64277088, Validation loss: 0.62749699, Gradient norm: 0.07310117
INFO:root:At the start of the epoch: mem (CPU python)=25853.46484375MB; mem (CPU total)=25629.83984375MB
INFO:root:[   50] Training loss: 0.64261222, Validation loss: 0.62760317, Gradient norm: 0.07240570
INFO:root:At the start of the epoch: mem (CPU python)=25891.55859375MB; mem (CPU total)=25668.6953125MB
INFO:root:[   51] Training loss: 0.64220916, Validation loss: 0.62699944, Gradient norm: 0.07920208
INFO:root:At the start of the epoch: mem (CPU python)=25929.66015625MB; mem (CPU total)=25706.09765625MB
INFO:root:[   52] Training loss: 0.64197354, Validation loss: 0.62736272, Gradient norm: 0.08031200
INFO:root:At the start of the epoch: mem (CPU python)=25967.75390625MB; mem (CPU total)=25744.9453125MB
INFO:root:[   53] Training loss: 0.64173093, Validation loss: 0.62624515, Gradient norm: 0.08224956
INFO:root:At the start of the epoch: mem (CPU python)=26005.8515625MB; mem (CPU total)=25782.08984375MB
INFO:root:[   54] Training loss: 0.64142086, Validation loss: 0.62660927, Gradient norm: 0.08756541
INFO:root:At the start of the epoch: mem (CPU python)=26043.9375MB; mem (CPU total)=25820.7109375MB
INFO:root:[   55] Training loss: 0.64129679, Validation loss: 0.62610419, Gradient norm: 0.09603241
INFO:root:At the start of the epoch: mem (CPU python)=26082.04296875MB; mem (CPU total)=25858.23828125MB
INFO:root:[   56] Training loss: 0.64078292, Validation loss: 0.62618409, Gradient norm: 0.08846063
INFO:root:At the start of the epoch: mem (CPU python)=26120.1171875MB; mem (CPU total)=25897.078125MB
INFO:root:[   57] Training loss: 0.64054105, Validation loss: 0.62636704, Gradient norm: 0.08872788
INFO:root:At the start of the epoch: mem (CPU python)=26158.234375MB; mem (CPU total)=25935.171875MB
INFO:root:[   58] Training loss: 0.64054843, Validation loss: 0.62603486, Gradient norm: 0.09800653
INFO:root:At the start of the epoch: mem (CPU python)=26196.375MB; mem (CPU total)=25972.8671875MB
INFO:root:[   59] Training loss: 0.64023442, Validation loss: 0.62600293, Gradient norm: 0.10001818
INFO:root:At the start of the epoch: mem (CPU python)=26234.4609375MB; mem (CPU total)=26010.8359375MB
INFO:root:[   60] Training loss: 0.64007691, Validation loss: 0.62412763, Gradient norm: 0.09869964
INFO:root:At the start of the epoch: mem (CPU python)=26272.578125MB; mem (CPU total)=26048.9765625MB
INFO:root:[   61] Training loss: 0.63980415, Validation loss: 0.62505418, Gradient norm: 0.10977217
INFO:root:At the start of the epoch: mem (CPU python)=26310.671875MB; mem (CPU total)=26087.78515625MB
INFO:root:[   62] Training loss: 0.63939558, Validation loss: 0.62558938, Gradient norm: 0.10348689
INFO:root:At the start of the epoch: mem (CPU python)=26348.765625MB; mem (CPU total)=26125.89453125MB
INFO:root:[   63] Training loss: 0.63923568, Validation loss: 0.62408501, Gradient norm: 0.10818491
INFO:root:At the start of the epoch: mem (CPU python)=26386.86328125MB; mem (CPU total)=26163.7265625MB
INFO:root:[   64] Training loss: 0.63895346, Validation loss: 0.62496767, Gradient norm: 0.11059943
INFO:root:At the start of the epoch: mem (CPU python)=26424.94140625MB; mem (CPU total)=26202.08984375MB
INFO:root:[   65] Training loss: 0.63879314, Validation loss: 0.62391992, Gradient norm: 0.11783776
INFO:root:At the start of the epoch: mem (CPU python)=26463.0546875MB; mem (CPU total)=26239.953125MB
INFO:root:[   66] Training loss: 0.63871053, Validation loss: 0.62423308, Gradient norm: 0.12625714
INFO:root:At the start of the epoch: mem (CPU python)=26501.14453125MB; mem (CPU total)=26278.2890625MB
INFO:root:[   67] Training loss: 0.63835888, Validation loss: 0.62428156, Gradient norm: 0.12425317
INFO:root:At the start of the epoch: mem (CPU python)=26539.234375MB; mem (CPU total)=26316.40625MB
INFO:root:[   68] Training loss: 0.63861398, Validation loss: 0.62376931, Gradient norm: 0.13555050
INFO:root:At the start of the epoch: mem (CPU python)=26577.26953125MB; mem (CPU total)=26354.2265625MB
INFO:root:[   69] Training loss: 0.63817823, Validation loss: 0.62343276, Gradient norm: 0.13925554
INFO:root:At the start of the epoch: mem (CPU python)=26615.37890625MB; mem (CPU total)=26392.62109375MB
INFO:root:[   70] Training loss: 0.63821675, Validation loss: 0.62347016, Gradient norm: 0.14451497
INFO:root:At the start of the epoch: mem (CPU python)=26653.4765625MB; mem (CPU total)=26431.37890625MB
INFO:root:[   71] Training loss: 0.63795019, Validation loss: 0.62261961, Gradient norm: 0.14819798
INFO:root:At the start of the epoch: mem (CPU python)=26691.5703125MB; mem (CPU total)=26469.1953125MB
INFO:root:[   72] Training loss: 0.63785298, Validation loss: 0.62352856, Gradient norm: 0.14698604
INFO:root:At the start of the epoch: mem (CPU python)=26729.65625MB; mem (CPU total)=26508.046875MB
INFO:root:[   73] Training loss: 0.63765582, Validation loss: 0.62229895, Gradient norm: 0.16231787
INFO:root:At the start of the epoch: mem (CPU python)=26767.75MB; mem (CPU total)=26545.79296875MB
INFO:root:[   74] Training loss: 0.63725086, Validation loss: 0.62268855, Gradient norm: 0.15119993
INFO:root:At the start of the epoch: mem (CPU python)=26805.84765625MB; mem (CPU total)=26584.65234375MB
INFO:root:[   75] Training loss: 0.63718857, Validation loss: 0.62242150, Gradient norm: 0.15870370
INFO:root:At the start of the epoch: mem (CPU python)=26843.94921875MB; mem (CPU total)=26623.03515625MB
INFO:root:[   76] Training loss: 0.63706714, Validation loss: 0.62272556, Gradient norm: 0.17802218
INFO:root:At the start of the epoch: mem (CPU python)=26882.046875MB; mem (CPU total)=26661.16796875MB
INFO:root:[   77] Training loss: 0.63682342, Validation loss: 0.62235001, Gradient norm: 0.17135353
INFO:root:At the start of the epoch: mem (CPU python)=26920.14453125MB; mem (CPU total)=26699.30859375MB
INFO:root:[   78] Training loss: 0.63693807, Validation loss: 0.62167176, Gradient norm: 0.19025547
INFO:root:At the start of the epoch: mem (CPU python)=26958.23046875MB; mem (CPU total)=26736.68359375MB
INFO:root:[   79] Training loss: 0.63690178, Validation loss: 0.62162909, Gradient norm: 0.20649980
INFO:root:At the start of the epoch: mem (CPU python)=26996.37890625MB; mem (CPU total)=26774.859375MB
INFO:root:[   80] Training loss: 0.63643399, Validation loss: 0.62230079, Gradient norm: 0.19578371
INFO:root:At the start of the epoch: mem (CPU python)=27034.484375MB; mem (CPU total)=26813.94140625MB
INFO:root:[   81] Training loss: 0.63654155, Validation loss: 0.62306327, Gradient norm: 0.20910325
INFO:root:At the start of the epoch: mem (CPU python)=27072.5625MB; mem (CPU total)=26851.8046875MB
INFO:root:[   82] Training loss: 0.63624717, Validation loss: 0.62164019, Gradient norm: 0.21120418
INFO:root:At the start of the epoch: mem (CPU python)=27110.671875MB; mem (CPU total)=26889.65625MB
INFO:root:[   83] Training loss: 0.63602521, Validation loss: 0.62156700, Gradient norm: 0.22372043
INFO:root:At the start of the epoch: mem (CPU python)=27148.765625MB; mem (CPU total)=26927.76171875MB
INFO:root:[   84] Training loss: 0.63606133, Validation loss: 0.62146361, Gradient norm: 0.23213876
INFO:root:At the start of the epoch: mem (CPU python)=27186.84765625MB; mem (CPU total)=26965.859375MB
INFO:root:[   85] Training loss: 0.63606515, Validation loss: 0.62136231, Gradient norm: 0.24518581
INFO:root:At the start of the epoch: mem (CPU python)=27224.95703125MB; mem (CPU total)=27003.953125MB
INFO:root:[   86] Training loss: 0.63583685, Validation loss: 0.62130118, Gradient norm: 0.25853675
INFO:root:At the start of the epoch: mem (CPU python)=27263.0546875MB; mem (CPU total)=27042.33203125MB
INFO:root:[   87] Training loss: 0.63565679, Validation loss: 0.62143529, Gradient norm: 0.25789152
INFO:root:At the start of the epoch: mem (CPU python)=27301.15234375MB; mem (CPU total)=27083.0390625MB
INFO:root:[   88] Training loss: 0.63562950, Validation loss: 0.62101892, Gradient norm: 0.28643187
INFO:root:At the start of the epoch: mem (CPU python)=27339.24609375MB; mem (CPU total)=27120.56640625MB
INFO:root:[   89] Training loss: 0.63546069, Validation loss: 0.62104830, Gradient norm: 0.27449954
INFO:root:At the start of the epoch: mem (CPU python)=27377.28515625MB; mem (CPU total)=27159.27734375MB
INFO:root:[   90] Training loss: 0.63521223, Validation loss: 0.62074569, Gradient norm: 0.26260968
INFO:root:At the start of the epoch: mem (CPU python)=27415.37890625MB; mem (CPU total)=27196.62109375MB
INFO:root:[   91] Training loss: 0.63530774, Validation loss: 0.62090265, Gradient norm: 0.27535235
INFO:root:At the start of the epoch: mem (CPU python)=27453.48046875MB; mem (CPU total)=27235.453125MB
INFO:root:[   92] Training loss: 0.63522143, Validation loss: 0.62060464, Gradient norm: 0.28377441
INFO:root:At the start of the epoch: mem (CPU python)=27491.55859375MB; mem (CPU total)=27273.3984375MB
INFO:root:[   93] Training loss: 0.63486509, Validation loss: 0.62038608, Gradient norm: 0.30859285
INFO:root:At the start of the epoch: mem (CPU python)=27529.66796875MB; mem (CPU total)=27311.4765625MB
INFO:root:[   94] Training loss: 0.63487131, Validation loss: 0.62053748, Gradient norm: 0.31514937
INFO:root:At the start of the epoch: mem (CPU python)=27567.70703125MB; mem (CPU total)=27350.33984375MB
INFO:root:[   95] Training loss: 0.63490996, Validation loss: 0.62101340, Gradient norm: 0.32697996
INFO:root:At the start of the epoch: mem (CPU python)=27605.703125MB; mem (CPU total)=27388.453125MB
INFO:root:[   96] Training loss: 0.63486695, Validation loss: 0.61920938, Gradient norm: 0.35331944
INFO:root:At the start of the epoch: mem (CPU python)=27643.9375MB; mem (CPU total)=27426.078125MB
INFO:root:[   97] Training loss: 0.63485981, Validation loss: 0.62011949, Gradient norm: 0.34789856
INFO:root:At the start of the epoch: mem (CPU python)=27682.046875MB; mem (CPU total)=27464.6640625MB
INFO:root:[   98] Training loss: 0.63453110, Validation loss: 0.62048707, Gradient norm: 0.37221828
INFO:root:At the start of the epoch: mem (CPU python)=27720.14453125MB; mem (CPU total)=27503.2890625MB
INFO:root:[   99] Training loss: 0.63455858, Validation loss: 0.62025408, Gradient norm: 0.38276528
INFO:root:At the start of the epoch: mem (CPU python)=27758.17578125MB; mem (CPU total)=27541.42578125MB
INFO:root:[  100] Training loss: 0.63457534, Validation loss: 0.61945394, Gradient norm: 0.41143854
INFO:root:At the start of the epoch: mem (CPU python)=27796.375MB; mem (CPU total)=27579.3203125MB
INFO:root:[  101] Training loss: 0.63427946, Validation loss: 0.61956227, Gradient norm: 0.39197717
INFO:root:At the start of the epoch: mem (CPU python)=27834.484375MB; mem (CPU total)=27617.43359375MB
INFO:root:[  102] Training loss: 0.63410421, Validation loss: 0.61986033, Gradient norm: 0.40290904
INFO:root:At the start of the epoch: mem (CPU python)=27872.5625MB; mem (CPU total)=27655.14453125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  103] Training loss: 0.63401224, Validation loss: 0.61966607, Gradient norm: 0.40135446
INFO:root:At the start of the epoch: mem (CPU python)=27910.671875MB; mem (CPU total)=27693.00390625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  104] Training loss: 0.63300982, Validation loss: 0.61825021, Gradient norm: 0.32677916
INFO:root:At the start of the epoch: mem (CPU python)=27948.76953125MB; mem (CPU total)=27730.625MB
INFO:root:[  105] Training loss: 0.63251496, Validation loss: 0.61731765, Gradient norm: 0.27268269
INFO:root:At the start of the epoch: mem (CPU python)=27986.86328125MB; mem (CPU total)=27768.8984375MB
INFO:root:[  106] Training loss: 0.63253764, Validation loss: 0.61765300, Gradient norm: 0.28557448
INFO:root:At the start of the epoch: mem (CPU python)=28024.95703125MB; mem (CPU total)=27807.26953125MB
INFO:root:[  107] Training loss: 0.63244917, Validation loss: 0.61815923, Gradient norm: 0.29618503
INFO:root:At the start of the epoch: mem (CPU python)=28063.05859375MB; mem (CPU total)=27845.1484375MB
INFO:root:[  108] Training loss: 0.63249272, Validation loss: 0.61760577, Gradient norm: 0.31403618
INFO:root:At the start of the epoch: mem (CPU python)=28101.15625MB; mem (CPU total)=27883.5390625MB
INFO:root:[  109] Training loss: 0.63246504, Validation loss: 0.61824836, Gradient norm: 0.33068600
INFO:root:At the start of the epoch: mem (CPU python)=28139.24609375MB; mem (CPU total)=27921.70703125MB
INFO:root:[  110] Training loss: 0.63239608, Validation loss: 0.61764088, Gradient norm: 0.33931038
INFO:root:At the start of the epoch: mem (CPU python)=28177.29296875MB; mem (CPU total)=27960.03515625MB
INFO:root:[  111] Training loss: 0.63241004, Validation loss: 0.61824313, Gradient norm: 0.34833698
INFO:root:At the start of the epoch: mem (CPU python)=28215.38671875MB; mem (CPU total)=27998.1953125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  112] Training loss: 0.63238461, Validation loss: 0.61838598, Gradient norm: 0.35935281
INFO:root:At the start of the epoch: mem (CPU python)=28253.48046875MB; mem (CPU total)=28036.609375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  113] Training loss: 0.63204363, Validation loss: 0.61763412, Gradient norm: 0.29721404
INFO:root:At the start of the epoch: mem (CPU python)=28291.578125MB; mem (CPU total)=28074.58984375MB
INFO:root:[  114] Training loss: 0.63178273, Validation loss: 0.61777956, Gradient norm: 0.25651780
INFO:root:At the start of the epoch: mem (CPU python)=28329.67578125MB; mem (CPU total)=28112.69921875MB
INFO:root:EP 114: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=28367.76171875MB; mem (CPU total)=28151.125MB
INFO:root:Training the model took 6932.166s.
INFO:root:Emptying the cuda cache took 0.042s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86858
INFO:root:EnergyScoreTrain: 0.61129
INFO:root:CRPSTrain: 0.48049
INFO:root:Gaussian NLLTrain: 66.30111
INFO:root:CoverageTrain: 0.91996
INFO:root:IntervalWidthTrain: 3.16849
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8779
INFO:root:EnergyScoreValidation: 0.61792
INFO:root:CRPSValidation: 0.48637
INFO:root:Gaussian NLLValidation: 46.37047
INFO:root:CoverageValidation: 0.91674
INFO:root:IntervalWidthValidation: 3.17095
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87911
INFO:root:EnergyScoreTest: 0.61878
INFO:root:CRPSTest: 0.4873
INFO:root:Gaussian NLLTest: 13.91878
INFO:root:CoverageTest: 0.91664
INFO:root:IntervalWidthTest: 3.17362
INFO:root:After validation: mem (CPU python)=28457.69921875MB; mem (CPU total)=28193.859375MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=28457.69921875MB; mem (CPU total)=28126.265625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=28457.69921875MB; mem (CPU total)=28130.13671875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=28457.69921875MB; mem (CPU total)=28130.1328125MB
INFO:root:[    1] Training loss: 0.72567736, Validation loss: 0.72086488, Gradient norm: 0.02322472
INFO:root:At the start of the epoch: mem (CPU python)=28457.69921875MB; mem (CPU total)=28197.87109375MB
INFO:root:[    2] Training loss: 0.72003568, Validation loss: 0.71846032, Gradient norm: 0.00670354
INFO:root:At the start of the epoch: mem (CPU python)=28457.69921875MB; mem (CPU total)=28235.92578125MB
INFO:root:[    3] Training loss: 0.71817600, Validation loss: 0.71523621, Gradient norm: 0.00984421
INFO:root:At the start of the epoch: mem (CPU python)=28492.69140625MB; mem (CPU total)=28274.31640625MB
INFO:root:[    4] Training loss: 0.71272432, Validation loss: 0.70691151, Gradient norm: 0.02403132
INFO:root:At the start of the epoch: mem (CPU python)=28530.73046875MB; mem (CPU total)=28312.21484375MB
INFO:root:[    5] Training loss: 0.70705870, Validation loss: 0.70090696, Gradient norm: 0.03713329
INFO:root:At the start of the epoch: mem (CPU python)=28568.87890625MB; mem (CPU total)=28350.8515625MB
INFO:root:[    6] Training loss: 0.70273307, Validation loss: 0.69603116, Gradient norm: 0.04203849
INFO:root:At the start of the epoch: mem (CPU python)=28607.02734375MB; mem (CPU total)=28389.19140625MB
INFO:root:[    7] Training loss: 0.69871732, Validation loss: 0.69199493, Gradient norm: 0.03988339
INFO:root:At the start of the epoch: mem (CPU python)=28645.11328125MB; mem (CPU total)=28427.08203125MB
INFO:root:[    8] Training loss: 0.69514708, Validation loss: 0.68720501, Gradient norm: 0.04203501
INFO:root:At the start of the epoch: mem (CPU python)=28683.1796875MB; mem (CPU total)=28465.17578125MB
INFO:root:[    9] Training loss: 0.69160412, Validation loss: 0.68347474, Gradient norm: 0.04050524
INFO:root:At the start of the epoch: mem (CPU python)=28721.3203125MB; mem (CPU total)=28503.52734375MB
INFO:root:[   10] Training loss: 0.68857823, Validation loss: 0.68029845, Gradient norm: 0.04322070
INFO:root:At the start of the epoch: mem (CPU python)=28759.40234375MB; mem (CPU total)=28541.79296875MB
INFO:root:[   11] Training loss: 0.68569385, Validation loss: 0.67684710, Gradient norm: 0.04351915
INFO:root:At the start of the epoch: mem (CPU python)=28797.5MB; mem (CPU total)=28579.9296875MB
INFO:root:[   12] Training loss: 0.68306323, Validation loss: 0.67360931, Gradient norm: 0.04009872
INFO:root:At the start of the epoch: mem (CPU python)=28835.56640625MB; mem (CPU total)=28618.27734375MB
INFO:root:[   13] Training loss: 0.68065862, Validation loss: 0.67150254, Gradient norm: 0.04180335
INFO:root:At the start of the epoch: mem (CPU python)=28873.69140625MB; mem (CPU total)=28656.37109375MB
INFO:root:[   14] Training loss: 0.67829200, Validation loss: 0.66891889, Gradient norm: 0.03835901
INFO:root:At the start of the epoch: mem (CPU python)=28911.78125MB; mem (CPU total)=28694.484375MB
INFO:root:[   15] Training loss: 0.67634870, Validation loss: 0.66623529, Gradient norm: 0.04044581
INFO:root:At the start of the epoch: mem (CPU python)=28949.89453125MB; mem (CPU total)=28732.91796875MB
INFO:root:[   16] Training loss: 0.67450426, Validation loss: 0.66439518, Gradient norm: 0.04067939
INFO:root:At the start of the epoch: mem (CPU python)=28987.98828125MB; mem (CPU total)=28770.7578125MB
INFO:root:[   17] Training loss: 0.67284695, Validation loss: 0.66198414, Gradient norm: 0.04252694
INFO:root:At the start of the epoch: mem (CPU python)=29026.0859375MB; mem (CPU total)=28808.87109375MB
INFO:root:[   18] Training loss: 0.67108914, Validation loss: 0.66026842, Gradient norm: 0.04148454
INFO:root:At the start of the epoch: mem (CPU python)=29064.18359375MB; mem (CPU total)=28846.95703125MB
INFO:root:[   19] Training loss: 0.66945419, Validation loss: 0.65817165, Gradient norm: 0.04396851
INFO:root:At the start of the epoch: mem (CPU python)=29102.2734375MB; mem (CPU total)=28885.0859375MB
INFO:root:[   20] Training loss: 0.66787043, Validation loss: 0.65642595, Gradient norm: 0.04166398
INFO:root:At the start of the epoch: mem (CPU python)=29140.36328125MB; mem (CPU total)=28923.45703125MB
INFO:root:[   21] Training loss: 0.66669630, Validation loss: 0.65491685, Gradient norm: 0.04274063
INFO:root:At the start of the epoch: mem (CPU python)=29178.46875MB; mem (CPU total)=28961.5859375MB
INFO:root:[   22] Training loss: 0.66523886, Validation loss: 0.65325048, Gradient norm: 0.04519667
INFO:root:At the start of the epoch: mem (CPU python)=29216.5625MB; mem (CPU total)=28999.9765625MB
INFO:root:[   23] Training loss: 0.66393485, Validation loss: 0.65060638, Gradient norm: 0.04905450
INFO:root:At the start of the epoch: mem (CPU python)=29254.6015625MB; mem (CPU total)=29037.84765625MB
INFO:root:[   24] Training loss: 0.66243990, Validation loss: 0.64999205, Gradient norm: 0.04178968
INFO:root:At the start of the epoch: mem (CPU python)=29292.69921875MB; mem (CPU total)=29075.70703125MB
INFO:root:[   25] Training loss: 0.66110191, Validation loss: 0.64836628, Gradient norm: 0.04258430
INFO:root:At the start of the epoch: mem (CPU python)=29330.79296875MB; mem (CPU total)=29114.05078125MB
INFO:root:[   26] Training loss: 0.66007661, Validation loss: 0.64673483, Gradient norm: 0.04518129
INFO:root:At the start of the epoch: mem (CPU python)=29368.74609375MB; mem (CPU total)=29152.203125MB
INFO:root:[   27] Training loss: 0.65906331, Validation loss: 0.64529563, Gradient norm: 0.04753460
INFO:root:At the start of the epoch: mem (CPU python)=29406.9765625MB; mem (CPU total)=29190.27734375MB
INFO:root:[   28] Training loss: 0.65778178, Validation loss: 0.64415753, Gradient norm: 0.04641628
INFO:root:At the start of the epoch: mem (CPU python)=29444.984375MB; mem (CPU total)=29228.38671875MB
INFO:root:[   29] Training loss: 0.65708477, Validation loss: 0.64342349, Gradient norm: 0.05177933
INFO:root:At the start of the epoch: mem (CPU python)=29483.1484375MB; mem (CPU total)=29266.75390625MB
INFO:root:[   30] Training loss: 0.65602502, Validation loss: 0.64244092, Gradient norm: 0.04941596
INFO:root:At the start of the epoch: mem (CPU python)=29521.25390625MB; mem (CPU total)=29305.5859375MB
INFO:root:[   31] Training loss: 0.65523373, Validation loss: 0.64218745, Gradient norm: 0.04951613
INFO:root:At the start of the epoch: mem (CPU python)=29559.359375MB; mem (CPU total)=29343.70703125MB
INFO:root:[   32] Training loss: 0.65444587, Validation loss: 0.64034519, Gradient norm: 0.04877913
INFO:root:At the start of the epoch: mem (CPU python)=29597.4375MB; mem (CPU total)=29381.8203125MB
INFO:root:[   33] Training loss: 0.65374869, Validation loss: 0.64035863, Gradient norm: 0.04931935
INFO:root:At the start of the epoch: mem (CPU python)=29635.609375MB; mem (CPU total)=29419.7421875MB
INFO:root:[   34] Training loss: 0.65283869, Validation loss: 0.63853080, Gradient norm: 0.04789527
INFO:root:At the start of the epoch: mem (CPU python)=29673.70703125MB; mem (CPU total)=29457.67578125MB
INFO:root:[   35] Training loss: 0.65216092, Validation loss: 0.63817078, Gradient norm: 0.05455970
INFO:root:At the start of the epoch: mem (CPU python)=29711.78515625MB; mem (CPU total)=29495.82421875MB
INFO:root:[   36] Training loss: 0.65168374, Validation loss: 0.63796557, Gradient norm: 0.05111413
INFO:root:At the start of the epoch: mem (CPU python)=29749.8828125MB; mem (CPU total)=29534.203125MB
INFO:root:[   37] Training loss: 0.65098433, Validation loss: 0.63705225, Gradient norm: 0.04725862
INFO:root:At the start of the epoch: mem (CPU python)=29787.99609375MB; mem (CPU total)=29572.0859375MB
INFO:root:[   38] Training loss: 0.65040279, Validation loss: 0.63569357, Gradient norm: 0.05604567
INFO:root:At the start of the epoch: mem (CPU python)=29826.08984375MB; mem (CPU total)=29610.23828125MB
INFO:root:[   39] Training loss: 0.64962480, Validation loss: 0.63571031, Gradient norm: 0.05260962
INFO:root:At the start of the epoch: mem (CPU python)=29864.08203125MB; mem (CPU total)=29648.89453125MB
INFO:root:[   40] Training loss: 0.64916302, Validation loss: 0.63540109, Gradient norm: 0.05392043
INFO:root:At the start of the epoch: mem (CPU python)=29902.2734375MB; mem (CPU total)=29686.51953125MB
INFO:root:[   41] Training loss: 0.64860941, Validation loss: 0.63418188, Gradient norm: 0.05546840
INFO:root:At the start of the epoch: mem (CPU python)=29940.375MB; mem (CPU total)=29724.66015625MB
INFO:root:[   42] Training loss: 0.64791246, Validation loss: 0.63393348, Gradient norm: 0.04925506
INFO:root:At the start of the epoch: mem (CPU python)=29978.453125MB; mem (CPU total)=29762.5546875MB
INFO:root:[   43] Training loss: 0.64784107, Validation loss: 0.63287946, Gradient norm: 0.05963662
INFO:root:At the start of the epoch: mem (CPU python)=30016.56640625MB; mem (CPU total)=29800.8671875MB
INFO:root:[   44] Training loss: 0.64714974, Validation loss: 0.63311525, Gradient norm: 0.05260415
INFO:root:At the start of the epoch: mem (CPU python)=30054.55859375MB; mem (CPU total)=29839.74609375MB
INFO:root:[   45] Training loss: 0.64691044, Validation loss: 0.63251270, Gradient norm: 0.05592932
INFO:root:At the start of the epoch: mem (CPU python)=30092.6796875MB; mem (CPU total)=29876.97265625MB
INFO:root:[   46] Training loss: 0.64643204, Validation loss: 0.63210479, Gradient norm: 0.05805017
INFO:root:At the start of the epoch: mem (CPU python)=30130.78515625MB; mem (CPU total)=29915.05859375MB
INFO:root:[   47] Training loss: 0.64598662, Validation loss: 0.63239410, Gradient norm: 0.05704213
INFO:root:At the start of the epoch: mem (CPU python)=30168.88671875MB; mem (CPU total)=29954.16015625MB
INFO:root:[   48] Training loss: 0.64527921, Validation loss: 0.63096877, Gradient norm: 0.05817403
INFO:root:At the start of the epoch: mem (CPU python)=30206.96484375MB; mem (CPU total)=29992.03515625MB
INFO:root:[   49] Training loss: 0.64516433, Validation loss: 0.63156958, Gradient norm: 0.06694429
INFO:root:At the start of the epoch: mem (CPU python)=30245.07421875MB; mem (CPU total)=30030.9140625MB
INFO:root:[   50] Training loss: 0.64472874, Validation loss: 0.63013734, Gradient norm: 0.05830562
INFO:root:At the start of the epoch: mem (CPU python)=30283.17578125MB; mem (CPU total)=30068.3515625MB
INFO:root:[   51] Training loss: 0.64436709, Validation loss: 0.62929477, Gradient norm: 0.05756390
INFO:root:At the start of the epoch: mem (CPU python)=30321.26171875MB; mem (CPU total)=30106.23046875MB
INFO:root:[   52] Training loss: 0.64368242, Validation loss: 0.62963376, Gradient norm: 0.05718506
INFO:root:At the start of the epoch: mem (CPU python)=30359.375MB; mem (CPU total)=30145.10546875MB
INFO:root:[   53] Training loss: 0.64358295, Validation loss: 0.62927975, Gradient norm: 0.06406684
INFO:root:At the start of the epoch: mem (CPU python)=30397.46875MB; mem (CPU total)=30182.75MB
INFO:root:[   54] Training loss: 0.64305840, Validation loss: 0.62914645, Gradient norm: 0.06023234
INFO:root:At the start of the epoch: mem (CPU python)=30435.62109375MB; mem (CPU total)=30220.85546875MB
INFO:root:[   55] Training loss: 0.64286837, Validation loss: 0.62968784, Gradient norm: 0.06186624
INFO:root:At the start of the epoch: mem (CPU python)=30473.7109375MB; mem (CPU total)=30259.4609375MB
INFO:root:[   56] Training loss: 0.64252658, Validation loss: 0.62895980, Gradient norm: 0.06062815
INFO:root:At the start of the epoch: mem (CPU python)=30511.80859375MB; mem (CPU total)=30297.0703125MB
INFO:root:[   57] Training loss: 0.64212998, Validation loss: 0.62797558, Gradient norm: 0.06248998
INFO:root:At the start of the epoch: mem (CPU python)=30549.90234375MB; mem (CPU total)=30335.42578125MB
INFO:root:[   58] Training loss: 0.64170314, Validation loss: 0.62710552, Gradient norm: 0.06736784
INFO:root:At the start of the epoch: mem (CPU python)=30588.0078125MB; mem (CPU total)=30373.7890625MB
INFO:root:[   59] Training loss: 0.64147713, Validation loss: 0.62777976, Gradient norm: 0.06143883
INFO:root:At the start of the epoch: mem (CPU python)=30626.03515625MB; mem (CPU total)=30412.3984375MB
INFO:root:[   60] Training loss: 0.64149247, Validation loss: 0.62743469, Gradient norm: 0.06382807
INFO:root:At the start of the epoch: mem (CPU python)=30664.14453125MB; mem (CPU total)=30450.52734375MB
INFO:root:[   61] Training loss: 0.64121762, Validation loss: 0.62673416, Gradient norm: 0.06752766
INFO:root:At the start of the epoch: mem (CPU python)=30702.26171875MB; mem (CPU total)=30488.34765625MB
INFO:root:[   62] Training loss: 0.64060444, Validation loss: 0.62688700, Gradient norm: 0.07432772
INFO:root:At the start of the epoch: mem (CPU python)=30740.375MB; mem (CPU total)=30526.64453125MB
INFO:root:[   63] Training loss: 0.64042937, Validation loss: 0.62610137, Gradient norm: 0.06818813
INFO:root:At the start of the epoch: mem (CPU python)=30778.46875MB; mem (CPU total)=30564.26171875MB
INFO:root:[   64] Training loss: 0.64033904, Validation loss: 0.62605218, Gradient norm: 0.06759973
INFO:root:At the start of the epoch: mem (CPU python)=30816.5703125MB; mem (CPU total)=30602.359375MB
INFO:root:[   65] Training loss: 0.63993152, Validation loss: 0.62591463, Gradient norm: 0.06485428
INFO:root:At the start of the epoch: mem (CPU python)=30854.61328125MB; mem (CPU total)=30640.7109375MB
INFO:root:[   66] Training loss: 0.63955620, Validation loss: 0.62501452, Gradient norm: 0.07222125
INFO:root:At the start of the epoch: mem (CPU python)=30892.70703125MB; mem (CPU total)=30679.5390625MB
INFO:root:[   67] Training loss: 0.63963946, Validation loss: 0.62512552, Gradient norm: 0.07316807
INFO:root:At the start of the epoch: mem (CPU python)=30930.80078125MB; mem (CPU total)=30718.1640625MB
INFO:root:[   68] Training loss: 0.63923843, Validation loss: 0.62441458, Gradient norm: 0.07296947
INFO:root:At the start of the epoch: mem (CPU python)=30968.8984375MB; mem (CPU total)=30755.81640625MB
INFO:root:[   69] Training loss: 0.63899414, Validation loss: 0.62428409, Gradient norm: 0.07238045
INFO:root:At the start of the epoch: mem (CPU python)=31006.99609375MB; mem (CPU total)=30793.9296875MB
INFO:root:[   70] Training loss: 0.63869766, Validation loss: 0.62386896, Gradient norm: 0.07289632
INFO:root:At the start of the epoch: mem (CPU python)=31045.0859375MB; mem (CPU total)=30831.828125MB
INFO:root:[   71] Training loss: 0.63861575, Validation loss: 0.62440492, Gradient norm: 0.07021956
INFO:root:At the start of the epoch: mem (CPU python)=31083.1796875MB; mem (CPU total)=30870.515625MB
INFO:root:[   72] Training loss: 0.63832929, Validation loss: 0.62381910, Gradient norm: 0.07628132
INFO:root:At the start of the epoch: mem (CPU python)=31121.28515625MB; mem (CPU total)=30908.14453125MB
INFO:root:[   73] Training loss: 0.63822505, Validation loss: 0.62340471, Gradient norm: 0.07261763
INFO:root:At the start of the epoch: mem (CPU python)=31159.33203125MB; mem (CPU total)=30948.23828125MB
INFO:root:[   74] Training loss: 0.63781869, Validation loss: 0.62331145, Gradient norm: 0.08475320
INFO:root:At the start of the epoch: mem (CPU python)=31197.44921875MB; mem (CPU total)=30986.05859375MB
INFO:root:[   75] Training loss: 0.63759648, Validation loss: 0.62316928, Gradient norm: 0.07955927
INFO:root:At the start of the epoch: mem (CPU python)=31235.609375MB; mem (CPU total)=31024.4609375MB
INFO:root:[   76] Training loss: 0.63778948, Validation loss: 0.62324176, Gradient norm: 0.08924850
INFO:root:At the start of the epoch: mem (CPU python)=31273.71875MB; mem (CPU total)=31063.5625MB
INFO:root:[   77] Training loss: 0.63716365, Validation loss: 0.62307579, Gradient norm: 0.07715370
INFO:root:At the start of the epoch: mem (CPU python)=31311.8125MB; mem (CPU total)=31101.1875MB
INFO:root:[   78] Training loss: 0.63722560, Validation loss: 0.62342516, Gradient norm: 0.08954819
INFO:root:At the start of the epoch: mem (CPU python)=31349.91015625MB; mem (CPU total)=31139.55859375MB
INFO:root:[   79] Training loss: 0.63688658, Validation loss: 0.62197261, Gradient norm: 0.07788592
INFO:root:At the start of the epoch: mem (CPU python)=31388.0078125MB; mem (CPU total)=31177.1875MB
INFO:root:[   80] Training loss: 0.63696819, Validation loss: 0.62248706, Gradient norm: 0.08930758
INFO:root:At the start of the epoch: mem (CPU python)=31426.1015625MB; mem (CPU total)=31215.3125MB
INFO:root:[   81] Training loss: 0.63669492, Validation loss: 0.62226916, Gradient norm: 0.09073109
INFO:root:At the start of the epoch: mem (CPU python)=31464.1953125MB; mem (CPU total)=31253.1875MB
INFO:root:[   82] Training loss: 0.63648654, Validation loss: 0.62178731, Gradient norm: 0.08871754
INFO:root:At the start of the epoch: mem (CPU python)=31502.2578125MB; mem (CPU total)=31291.125MB
INFO:root:[   83] Training loss: 0.63643294, Validation loss: 0.62079583, Gradient norm: 0.09002879
INFO:root:At the start of the epoch: mem (CPU python)=31540.37109375MB; mem (CPU total)=31329.2578125MB
INFO:root:[   84] Training loss: 0.63646442, Validation loss: 0.62161835, Gradient norm: 0.09600718
INFO:root:At the start of the epoch: mem (CPU python)=31578.484375MB; mem (CPU total)=31367.65625MB
INFO:root:[   85] Training loss: 0.63622913, Validation loss: 0.62196258, Gradient norm: 0.09483331
INFO:root:At the start of the epoch: mem (CPU python)=31616.55078125MB; mem (CPU total)=31405.80859375MB
INFO:root:[   86] Training loss: 0.63599109, Validation loss: 0.62184821, Gradient norm: 0.10098125
INFO:root:At the start of the epoch: mem (CPU python)=31654.58203125MB; mem (CPU total)=31444.96875MB
INFO:root:[   87] Training loss: 0.63583516, Validation loss: 0.62078243, Gradient norm: 0.10150050
INFO:root:At the start of the epoch: mem (CPU python)=31692.71484375MB; mem (CPU total)=31482.5625MB
INFO:root:[   88] Training loss: 0.63577594, Validation loss: 0.62137111, Gradient norm: 0.10947606
INFO:root:At the start of the epoch: mem (CPU python)=31730.8125MB; mem (CPU total)=31521.16796875MB
INFO:root:[   89] Training loss: 0.63556126, Validation loss: 0.62147390, Gradient norm: 0.10681349
INFO:root:At the start of the epoch: mem (CPU python)=31768.890625MB; mem (CPU total)=31559.13671875MB
INFO:root:[   90] Training loss: 0.63538039, Validation loss: 0.62112892, Gradient norm: 0.10374731
INFO:root:At the start of the epoch: mem (CPU python)=31807.00390625MB; mem (CPU total)=31597.23828125MB
INFO:root:[   91] Training loss: 0.63511880, Validation loss: 0.62146342, Gradient norm: 0.10974714
INFO:root:At the start of the epoch: mem (CPU python)=31845.09765625MB; mem (CPU total)=31635.33203125MB
INFO:root:[   92] Training loss: 0.63521469, Validation loss: 0.62109625, Gradient norm: 0.11441770
INFO:root:At the start of the epoch: mem (CPU python)=31883.1953125MB; mem (CPU total)=31673.375MB
INFO:root:[   93] Training loss: 0.63538110, Validation loss: 0.62042100, Gradient norm: 0.11909278
INFO:root:At the start of the epoch: mem (CPU python)=31921.2890625MB; mem (CPU total)=31711.25MB
INFO:root:[   94] Training loss: 0.63515725, Validation loss: 0.62138379, Gradient norm: 0.10877425
INFO:root:At the start of the epoch: mem (CPU python)=31959.19140625MB; mem (CPU total)=31750.10546875MB
INFO:root:[   95] Training loss: 0.63508617, Validation loss: 0.62041510, Gradient norm: 0.11225252
INFO:root:At the start of the epoch: mem (CPU python)=31997.4765625MB; mem (CPU total)=31787.71875MB
INFO:root:[   96] Training loss: 0.63480351, Validation loss: 0.62026718, Gradient norm: 0.12116526
INFO:root:At the start of the epoch: mem (CPU python)=32035.6328125MB; mem (CPU total)=31825.8984375MB
INFO:root:[   97] Training loss: 0.63488441, Validation loss: 0.62018958, Gradient norm: 0.13402788
INFO:root:At the start of the epoch: mem (CPU python)=32073.7265625MB; mem (CPU total)=31863.75MB
INFO:root:[   98] Training loss: 0.63464356, Validation loss: 0.62024076, Gradient norm: 0.12377327
INFO:root:At the start of the epoch: mem (CPU python)=32111.8203125MB; mem (CPU total)=31902.796875MB
INFO:root:[   99] Training loss: 0.63473290, Validation loss: 0.61974155, Gradient norm: 0.13827214
INFO:root:At the start of the epoch: mem (CPU python)=32149.90234375MB; mem (CPU total)=31940.42578125MB
INFO:root:[  100] Training loss: 0.63453807, Validation loss: 0.62060637, Gradient norm: 0.13262052
INFO:root:At the start of the epoch: mem (CPU python)=32188.01171875MB; mem (CPU total)=31978.94921875MB
INFO:root:[  101] Training loss: 0.63437051, Validation loss: 0.62017718, Gradient norm: 0.13604460
INFO:root:At the start of the epoch: mem (CPU python)=32226.0859375MB; mem (CPU total)=32016.80859375MB
INFO:root:[  102] Training loss: 0.63421961, Validation loss: 0.62126415, Gradient norm: 0.14154525
INFO:root:At the start of the epoch: mem (CPU python)=32264.203125MB; mem (CPU total)=32055.16015625MB
INFO:root:[  103] Training loss: 0.63447243, Validation loss: 0.62029311, Gradient norm: 0.15273763
INFO:root:At the start of the epoch: mem (CPU python)=32302.296875MB; mem (CPU total)=32093.50390625MB
INFO:root:[  104] Training loss: 0.63442102, Validation loss: 0.62029078, Gradient norm: 0.15819673
INFO:root:At the start of the epoch: mem (CPU python)=32340.39453125MB; mem (CPU total)=32131.28125MB
INFO:root:[  105] Training loss: 0.63414373, Validation loss: 0.62013909, Gradient norm: 0.15287076
INFO:root:At the start of the epoch: mem (CPU python)=32378.4375MB; mem (CPU total)=32169.1640625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  106] Training loss: 0.63425929, Validation loss: 0.61994423, Gradient norm: 0.15243236
INFO:root:At the start of the epoch: mem (CPU python)=32416.5625MB; mem (CPU total)=32206.7890625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  107] Training loss: 0.63313266, Validation loss: 0.61933809, Gradient norm: 0.13424253
INFO:root:At the start of the epoch: mem (CPU python)=32454.6171875MB; mem (CPU total)=32244.8203125MB
INFO:root:[  108] Training loss: 0.63274341, Validation loss: 0.61840003, Gradient norm: 0.11525251
INFO:root:At the start of the epoch: mem (CPU python)=32492.71875MB; mem (CPU total)=32282.89453125MB
INFO:root:[  109] Training loss: 0.63269432, Validation loss: 0.61818654, Gradient norm: 0.12040410
INFO:root:At the start of the epoch: mem (CPU python)=32530.80859375MB; mem (CPU total)=32321.0546875MB
INFO:root:[  110] Training loss: 0.63249902, Validation loss: 0.61846707, Gradient norm: 0.12300311
INFO:root:At the start of the epoch: mem (CPU python)=32568.90234375MB; mem (CPU total)=32359.8828125MB
INFO:root:[  111] Training loss: 0.63264806, Validation loss: 0.61880811, Gradient norm: 0.11922918
INFO:root:At the start of the epoch: mem (CPU python)=32607.00390625MB; mem (CPU total)=32398.4765625MB
INFO:root:[  112] Training loss: 0.63253988, Validation loss: 0.61797041, Gradient norm: 0.12549600
INFO:root:At the start of the epoch: mem (CPU python)=32645.10546875MB; mem (CPU total)=32435.8828125MB
INFO:root:[  113] Training loss: 0.63245028, Validation loss: 0.61814157, Gradient norm: 0.12711269
INFO:root:At the start of the epoch: mem (CPU python)=32683.19921875MB; mem (CPU total)=32474.7109375MB
INFO:root:[  114] Training loss: 0.63254971, Validation loss: 0.61868936, Gradient norm: 0.13279836
INFO:root:At the start of the epoch: mem (CPU python)=32721.2890625MB; mem (CPU total)=32512.80078125MB
INFO:root:[  115] Training loss: 0.63257521, Validation loss: 0.61863349, Gradient norm: 0.14136323
INFO:root:At the start of the epoch: mem (CPU python)=32759.36328125MB; mem (CPU total)=32550.67578125MB
INFO:root:[  116] Training loss: 0.63255423, Validation loss: 0.61930391, Gradient norm: 0.13425908
INFO:root:At the start of the epoch: mem (CPU python)=32797.4765625MB; mem (CPU total)=32588.9765625MB
INFO:root:[  117] Training loss: 0.63262217, Validation loss: 0.61795190, Gradient norm: 0.13605599
INFO:root:At the start of the epoch: mem (CPU python)=32835.6328125MB; mem (CPU total)=32626.2734375MB
INFO:root:[  118] Training loss: 0.63249161, Validation loss: 0.61856002, Gradient norm: 0.14528476
INFO:root:At the start of the epoch: mem (CPU python)=32873.71875MB; mem (CPU total)=32665.375MB
INFO:root:[  119] Training loss: 0.63251840, Validation loss: 0.61847129, Gradient norm: 0.14712865
INFO:root:At the start of the epoch: mem (CPU python)=32911.82421875MB; mem (CPU total)=32704.953125MB
INFO:root:[  120] Training loss: 0.63249466, Validation loss: 0.61832109, Gradient norm: 0.14310224
INFO:root:At the start of the epoch: mem (CPU python)=32949.91796875MB; mem (CPU total)=32742.84765625MB
INFO:root:[  121] Training loss: 0.63243359, Validation loss: 0.61889443, Gradient norm: 0.15019253
INFO:root:At the start of the epoch: mem (CPU python)=32988.015625MB; mem (CPU total)=32780.9921875MB
INFO:root:[  122] Training loss: 0.63253061, Validation loss: 0.61826023, Gradient norm: 0.15508203
INFO:root:At the start of the epoch: mem (CPU python)=33026.09375MB; mem (CPU total)=32819.13671875MB
INFO:root:[  123] Training loss: 0.63246534, Validation loss: 0.61846101, Gradient norm: 0.15838797
INFO:root:At the start of the epoch: mem (CPU python)=33064.20703125MB; mem (CPU total)=32857.30078125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  124] Training loss: 0.63249984, Validation loss: 0.61836820, Gradient norm: 0.16457303
INFO:root:At the start of the epoch: mem (CPU python)=33102.3046875MB; mem (CPU total)=32895.27734375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  125] Training loss: 0.63228277, Validation loss: 0.61801181, Gradient norm: 0.13888048
INFO:root:At the start of the epoch: mem (CPU python)=33140.33984375MB; mem (CPU total)=32933.6015625MB
INFO:root:[  126] Training loss: 0.63214071, Validation loss: 0.61831880, Gradient norm: 0.13057965
INFO:root:At the start of the epoch: mem (CPU python)=33178.4140625MB; mem (CPU total)=32972.45703125MB
INFO:root:EP 126: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=33216.58984375MB; mem (CPU total)=33010.59765625MB
INFO:root:Training the model took 8235.595s.
INFO:root:Emptying the cuda cache took 0.041s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86629
INFO:root:EnergyScoreTrain: 0.60997
INFO:root:CRPSTrain: 0.47516
INFO:root:Gaussian NLLTrain: 1.49919
INFO:root:CoverageTrain: 0.89518
INFO:root:IntervalWidthTrain: 2.95007
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87791
INFO:root:EnergyScoreValidation: 0.61836
INFO:root:CRPSValidation: 0.48301
INFO:root:Gaussian NLLValidation: 1.54088
INFO:root:CoverageValidation: 0.89059
INFO:root:IntervalWidthValidation: 2.9568
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87872
INFO:root:EnergyScoreTest: 0.61896
INFO:root:CRPSTest: 0.48357
INFO:root:Gaussian NLLTest: 1.53625
INFO:root:CoverageTest: 0.88936
INFO:root:IntervalWidthTest: 2.95212
INFO:root:After validation: mem (CPU python)=33268.41796875MB; mem (CPU total)=33055.51171875MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=33268.41796875MB; mem (CPU total)=33055.7890625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=33268.41796875MB; mem (CPU total)=33056.28125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=33268.41796875MB; mem (CPU total)=33056.52734375MB
INFO:root:[    1] Training loss: 0.72590371, Validation loss: 0.72037581, Gradient norm: 0.02388151
INFO:root:At the start of the epoch: mem (CPU python)=33299.4765625MB; mem (CPU total)=33094.56640625MB
INFO:root:[    2] Training loss: 0.71984153, Validation loss: 0.71823695, Gradient norm: 0.00746050
INFO:root:At the start of the epoch: mem (CPU python)=33337.5703125MB; mem (CPU total)=33133.01953125MB
INFO:root:[    3] Training loss: 0.71712173, Validation loss: 0.71193469, Gradient norm: 0.01522164
INFO:root:At the start of the epoch: mem (CPU python)=33375.62890625MB; mem (CPU total)=33171.13671875MB
INFO:root:[    4] Training loss: 0.71049068, Validation loss: 0.70405103, Gradient norm: 0.02814435
INFO:root:At the start of the epoch: mem (CPU python)=33413.7578125MB; mem (CPU total)=33209.25390625MB
INFO:root:[    5] Training loss: 0.70403326, Validation loss: 0.69747514, Gradient norm: 0.03474259
INFO:root:At the start of the epoch: mem (CPU python)=33451.859375MB; mem (CPU total)=33247.13671875MB
INFO:root:[    6] Training loss: 0.69897661, Validation loss: 0.69113646, Gradient norm: 0.03695925
INFO:root:At the start of the epoch: mem (CPU python)=33489.953125MB; mem (CPU total)=33285.30078125MB
INFO:root:[    7] Training loss: 0.69440213, Validation loss: 0.68600479, Gradient norm: 0.03792164
INFO:root:At the start of the epoch: mem (CPU python)=33528.05078125MB; mem (CPU total)=33323.46875MB
INFO:root:[    8] Training loss: 0.68999204, Validation loss: 0.68117285, Gradient norm: 0.04183631
INFO:root:At the start of the epoch: mem (CPU python)=33566.14453125MB; mem (CPU total)=33361.9921875MB
INFO:root:[    9] Training loss: 0.68667213, Validation loss: 0.67819944, Gradient norm: 0.04071967
INFO:root:At the start of the epoch: mem (CPU python)=33604.23828125MB; mem (CPU total)=33400.3515625MB
INFO:root:[   10] Training loss: 0.68372428, Validation loss: 0.67467397, Gradient norm: 0.04022976
INFO:root:At the start of the epoch: mem (CPU python)=33642.33984375MB; mem (CPU total)=33438.74609375MB
INFO:root:[   11] Training loss: 0.68113964, Validation loss: 0.67251671, Gradient norm: 0.03835824
INFO:root:At the start of the epoch: mem (CPU python)=33680.43359375MB; mem (CPU total)=33476.625MB
INFO:root:[   12] Training loss: 0.67899172, Validation loss: 0.67027656, Gradient norm: 0.04204814
INFO:root:At the start of the epoch: mem (CPU python)=33718.515625MB; mem (CPU total)=33514.96484375MB
INFO:root:[   13] Training loss: 0.67708576, Validation loss: 0.66729052, Gradient norm: 0.04045720
INFO:root:At the start of the epoch: mem (CPU python)=33756.6171875MB; mem (CPU total)=33552.58203125MB
INFO:root:[   14] Training loss: 0.67519615, Validation loss: 0.66551608, Gradient norm: 0.04047606
INFO:root:At the start of the epoch: mem (CPU python)=33794.65625MB; mem (CPU total)=33590.6875MB
INFO:root:[   15] Training loss: 0.67350164, Validation loss: 0.66409920, Gradient norm: 0.04075329
INFO:root:At the start of the epoch: mem (CPU python)=33832.75390625MB; mem (CPU total)=33629.078125MB
INFO:root:[   16] Training loss: 0.67205406, Validation loss: 0.66106800, Gradient norm: 0.04251758
INFO:root:At the start of the epoch: mem (CPU python)=33870.859375MB; mem (CPU total)=33667.18359375MB
INFO:root:[   17] Training loss: 0.67048510, Validation loss: 0.66055072, Gradient norm: 0.04582987
INFO:root:At the start of the epoch: mem (CPU python)=33908.953125MB; mem (CPU total)=33705.5703125MB
INFO:root:[   18] Training loss: 0.66917468, Validation loss: 0.65888914, Gradient norm: 0.04530914
INFO:root:At the start of the epoch: mem (CPU python)=33947.1015625MB; mem (CPU total)=33743.91796875MB
INFO:root:[   19] Training loss: 0.66782361, Validation loss: 0.65659243, Gradient norm: 0.04706736
INFO:root:At the start of the epoch: mem (CPU python)=33985.1953125MB; mem (CPU total)=33782.03515625MB
INFO:root:[   20] Training loss: 0.66668557, Validation loss: 0.65576919, Gradient norm: 0.04637598
INFO:root:At the start of the epoch: mem (CPU python)=34023.2890625MB; mem (CPU total)=33820.3515625MB
INFO:root:[   21] Training loss: 0.66556495, Validation loss: 0.65350747, Gradient norm: 0.05321804
INFO:root:At the start of the epoch: mem (CPU python)=34061.390625MB; mem (CPU total)=33858.43359375MB
INFO:root:[   22] Training loss: 0.66433860, Validation loss: 0.65199966, Gradient norm: 0.06128470
INFO:root:At the start of the epoch: mem (CPU python)=34099.4453125MB; mem (CPU total)=33897.4921875MB
INFO:root:[   23] Training loss: 0.66342613, Validation loss: 0.65114552, Gradient norm: 0.05439523
INFO:root:At the start of the epoch: mem (CPU python)=34137.578125MB; mem (CPU total)=33935.625MB
INFO:root:[   24] Training loss: 0.66232163, Validation loss: 0.65025024, Gradient norm: 0.05645820
INFO:root:At the start of the epoch: mem (CPU python)=34175.67578125MB; mem (CPU total)=33973.734375MB
INFO:root:[   25] Training loss: 0.66147018, Validation loss: 0.64838045, Gradient norm: 0.05760876
INFO:root:At the start of the epoch: mem (CPU python)=34213.77734375MB; mem (CPU total)=34011.85546875MB
INFO:root:[   26] Training loss: 0.66062349, Validation loss: 0.64831351, Gradient norm: 0.06467473
INFO:root:At the start of the epoch: mem (CPU python)=34251.87109375MB; mem (CPU total)=34050.1796875MB
INFO:root:[   27] Training loss: 0.65976784, Validation loss: 0.64642591, Gradient norm: 0.06905283
INFO:root:At the start of the epoch: mem (CPU python)=34289.96875MB; mem (CPU total)=34087.0703125MB
INFO:root:[   28] Training loss: 0.65911147, Validation loss: 0.64620486, Gradient norm: 0.07610969
INFO:root:At the start of the epoch: mem (CPU python)=34328.05078125MB; mem (CPU total)=34125.15625MB
INFO:root:[   29] Training loss: 0.65838280, Validation loss: 0.64565386, Gradient norm: 0.08511154
INFO:root:At the start of the epoch: mem (CPU python)=34366.1015625MB; mem (CPU total)=34163.5078125MB
INFO:root:[   30] Training loss: 0.65777145, Validation loss: 0.64463314, Gradient norm: 0.08368377
INFO:root:At the start of the epoch: mem (CPU python)=34404.17578125MB; mem (CPU total)=34203.296875MB
INFO:root:[   31] Training loss: 0.65693175, Validation loss: 0.64416460, Gradient norm: 0.10430032
INFO:root:At the start of the epoch: mem (CPU python)=34442.28515625MB; mem (CPU total)=34241.12109375MB
INFO:root:[   32] Training loss: 0.65636721, Validation loss: 0.64258327, Gradient norm: 0.09711490
INFO:root:At the start of the epoch: mem (CPU python)=34480.3828125MB; mem (CPU total)=34278.27734375MB
INFO:root:[   33] Training loss: 0.65586582, Validation loss: 0.64198516, Gradient norm: 0.10772140
INFO:root:At the start of the epoch: mem (CPU python)=34518.48828125MB; mem (CPU total)=34317.16015625MB
INFO:root:[   34] Training loss: 0.65534844, Validation loss: 0.64362720, Gradient norm: 0.10971323
INFO:root:At the start of the epoch: mem (CPU python)=34556.57421875MB; mem (CPU total)=34355.5234375MB
INFO:root:[   35] Training loss: 0.65476354, Validation loss: 0.64335132, Gradient norm: 0.13459066
INFO:root:At the start of the epoch: mem (CPU python)=34594.6640625MB; mem (CPU total)=34392.65234375MB
INFO:root:[   36] Training loss: 0.65428985, Validation loss: 0.64264775, Gradient norm: 0.14036473
INFO:root:At the start of the epoch: mem (CPU python)=34632.62890625MB; mem (CPU total)=34430.5234375MB
INFO:root:[   37] Training loss: 0.65365944, Validation loss: 0.64266395, Gradient norm: 0.14987768
INFO:root:At the start of the epoch: mem (CPU python)=34670.83984375MB; mem (CPU total)=34468.625MB
INFO:root:[   38] Training loss: 0.65334357, Validation loss: 0.64088144, Gradient norm: 0.17546670
INFO:root:At the start of the epoch: mem (CPU python)=34708.94140625MB; mem (CPU total)=34506.19921875MB
INFO:root:[   39] Training loss: 0.65290031, Validation loss: 0.64149399, Gradient norm: 0.20349405
INFO:root:At the start of the epoch: mem (CPU python)=34747.09375MB; mem (CPU total)=34544.80859375MB
INFO:root:[   40] Training loss: 0.65239894, Validation loss: 0.64047479, Gradient norm: 0.19075278
INFO:root:At the start of the epoch: mem (CPU python)=34785.1796875MB; mem (CPU total)=34583.8046875MB
INFO:root:[   41] Training loss: 0.65219072, Validation loss: 0.63959515, Gradient norm: 0.22029138
INFO:root:At the start of the epoch: mem (CPU python)=34823.28125MB; mem (CPU total)=34621.515625MB
INFO:root:[   42] Training loss: 0.65166763, Validation loss: 0.64156876, Gradient norm: 0.24730783
INFO:root:At the start of the epoch: mem (CPU python)=34861.3984375MB; mem (CPU total)=34660.1484375MB
INFO:root:[   43] Training loss: 0.65113018, Validation loss: 0.63945938, Gradient norm: 0.21615280
INFO:root:At the start of the epoch: mem (CPU python)=34899.4921875MB; mem (CPU total)=34698.05859375MB
INFO:root:[   44] Training loss: 0.65096741, Validation loss: 0.64196584, Gradient norm: 0.31992562
INFO:root:At the start of the epoch: mem (CPU python)=34937.578125MB; mem (CPU total)=34736.17578125MB
INFO:root:[   45] Training loss: 0.65045549, Validation loss: 0.63953021, Gradient norm: 0.27741663
INFO:root:At the start of the epoch: mem (CPU python)=34975.6875MB; mem (CPU total)=34774.01171875MB
INFO:root:[   46] Training loss: 0.65007511, Validation loss: 0.64001015, Gradient norm: 0.32200671
INFO:root:At the start of the epoch: mem (CPU python)=35013.73828125MB; mem (CPU total)=34812.39453125MB
INFO:root:[   47] Training loss: 0.64989630, Validation loss: 0.63916100, Gradient norm: 0.35984866
INFO:root:At the start of the epoch: mem (CPU python)=35051.86328125MB; mem (CPU total)=34850.09765625MB
INFO:root:[   48] Training loss: 0.64945774, Validation loss: 0.64001335, Gradient norm: 0.35508422
INFO:root:At the start of the epoch: mem (CPU python)=35089.9375MB; mem (CPU total)=34888.48046875MB
INFO:root:[   49] Training loss: 0.64935849, Validation loss: 0.63890209, Gradient norm: 0.38169442
INFO:root:At the start of the epoch: mem (CPU python)=35128.05859375MB; mem (CPU total)=34925.94140625MB
INFO:root:[   50] Training loss: 0.64894228, Validation loss: 0.63689073, Gradient norm: 0.36113134
INFO:root:At the start of the epoch: mem (CPU python)=35166.09375MB; mem (CPU total)=34964.15234375MB
INFO:root:[   51] Training loss: 0.64880301, Validation loss: 0.63806330, Gradient norm: 0.43929006
INFO:root:At the start of the epoch: mem (CPU python)=35204.19921875MB; mem (CPU total)=35003.05859375MB
INFO:root:[   52] Training loss: 0.64835059, Validation loss: 0.63699158, Gradient norm: 0.44506215
INFO:root:At the start of the epoch: mem (CPU python)=35242.296875MB; mem (CPU total)=35041.42578125MB
INFO:root:[   53] Training loss: 0.64813240, Validation loss: 0.63797933, Gradient norm: 0.52904824
INFO:root:At the start of the epoch: mem (CPU python)=35280.3984375MB; mem (CPU total)=35079.6875MB
INFO:root:[   54] Training loss: 0.64791081, Validation loss: 0.63857219, Gradient norm: 0.45930679
INFO:root:At the start of the epoch: mem (CPU python)=35318.39453125MB; mem (CPU total)=35117.8046875MB
INFO:root:[   55] Training loss: 0.64762522, Validation loss: 0.63677917, Gradient norm: 0.48112742
INFO:root:At the start of the epoch: mem (CPU python)=35356.5703125MB; mem (CPU total)=35155.1640625MB
INFO:root:[   56] Training loss: 0.64741686, Validation loss: 0.63782175, Gradient norm: 0.52412847
INFO:root:At the start of the epoch: mem (CPU python)=35394.6796875MB; mem (CPU total)=35194.078125MB
INFO:root:[   57] Training loss: 0.64711200, Validation loss: 0.63562108, Gradient norm: 0.61820417
INFO:root:At the start of the epoch: mem (CPU python)=35432.77734375MB; mem (CPU total)=35231.4765625MB
INFO:root:[   58] Training loss: 0.64675903, Validation loss: 0.63492952, Gradient norm: 0.61308005
INFO:root:At the start of the epoch: mem (CPU python)=35470.87109375MB; mem (CPU total)=35269.6796875MB
INFO:root:[   59] Training loss: 0.64650105, Validation loss: 0.63423880, Gradient norm: 0.61945363
INFO:root:At the start of the epoch: mem (CPU python)=35508.953125MB; mem (CPU total)=35307.796875MB
INFO:root:[   60] Training loss: 0.64648421, Validation loss: 0.63454827, Gradient norm: 0.68494078
INFO:root:At the start of the epoch: mem (CPU python)=35547.11328125MB; mem (CPU total)=35346.6875MB
INFO:root:[   61] Training loss: 0.64612458, Validation loss: 0.63399945, Gradient norm: 0.62254763
INFO:root:At the start of the epoch: mem (CPU python)=35585.19921875MB; mem (CPU total)=35384.3203125MB
INFO:root:[   62] Training loss: 0.64571960, Validation loss: 0.63312227, Gradient norm: 0.67662883
INFO:root:At the start of the epoch: mem (CPU python)=35623.28515625MB; mem (CPU total)=35422.46484375MB
INFO:root:[   63] Training loss: 0.64549881, Validation loss: 0.63292655, Gradient norm: 0.70704951
INFO:root:At the start of the epoch: mem (CPU python)=35661.40234375MB; mem (CPU total)=35464.01953125MB
INFO:root:[   64] Training loss: 0.64541614, Validation loss: 0.63177814, Gradient norm: 0.75776882
INFO:root:At the start of the epoch: mem (CPU python)=35699.4921875MB; mem (CPU total)=35501.13671875MB
INFO:root:[   65] Training loss: 0.64554593, Validation loss: 0.63115681, Gradient norm: 0.84866690
INFO:root:At the start of the epoch: mem (CPU python)=35737.58984375MB; mem (CPU total)=35539.00390625MB
INFO:root:[   66] Training loss: 0.64507515, Validation loss: 0.63218817, Gradient norm: 0.82083130
INFO:root:At the start of the epoch: mem (CPU python)=35775.68359375MB; mem (CPU total)=35577.5625MB
INFO:root:[   67] Training loss: 0.64490276, Validation loss: 0.63135596, Gradient norm: 0.90176833
INFO:root:At the start of the epoch: mem (CPU python)=35813.78125MB; mem (CPU total)=35614.984375MB
INFO:root:[   68] Training loss: 0.64492076, Validation loss: 0.63226534, Gradient norm: 0.91266597
INFO:root:At the start of the epoch: mem (CPU python)=35851.8359375MB; mem (CPU total)=35653.07421875MB
INFO:root:[   69] Training loss: 0.64467897, Validation loss: 0.63111957, Gradient norm: 1.01522474
INFO:root:At the start of the epoch: mem (CPU python)=35889.92578125MB; mem (CPU total)=35690.984375MB
INFO:root:[   70] Training loss: 0.64477098, Validation loss: 0.62978751, Gradient norm: 1.25489165
INFO:root:At the start of the epoch: mem (CPU python)=35928.06640625MB; mem (CPU total)=35729.078125MB
INFO:root:[   71] Training loss: 0.64441300, Validation loss: 0.63032387, Gradient norm: 0.97859196
INFO:root:At the start of the epoch: mem (CPU python)=35966.11328125MB; mem (CPU total)=35767.90625MB
INFO:root:[   72] Training loss: 0.64444578, Validation loss: 0.63014423, Gradient norm: 1.13161963
INFO:root:At the start of the epoch: mem (CPU python)=36004.20703125MB; mem (CPU total)=35806.27734375MB
INFO:root:[   73] Training loss: 0.64389535, Validation loss: 0.62995957, Gradient norm: 0.94008702
INFO:root:At the start of the epoch: mem (CPU python)=36042.30078125MB; mem (CPU total)=35844.1640625MB
INFO:root:[   74] Training loss: 0.64371667, Validation loss: 0.62902538, Gradient norm: 0.96836412
INFO:root:At the start of the epoch: mem (CPU python)=36080.3984375MB; mem (CPU total)=35881.79296875MB
INFO:root:[   75] Training loss: 0.64368193, Validation loss: 0.62908124, Gradient norm: 1.06221058
INFO:root:At the start of the epoch: mem (CPU python)=36118.484375MB; mem (CPU total)=35920.5078125MB
INFO:root:[   76] Training loss: 0.64364656, Validation loss: 0.62966239, Gradient norm: 1.33332591
INFO:root:At the start of the epoch: mem (CPU python)=36156.546875MB; mem (CPU total)=35958.14453125MB
INFO:root:[   77] Training loss: 0.64378917, Validation loss: 0.62964377, Gradient norm: 1.60947134
INFO:root:At the start of the epoch: mem (CPU python)=36194.6796875MB; mem (CPU total)=35996.28125MB
INFO:root:[   78] Training loss: 0.64359100, Validation loss: 0.62902009, Gradient norm: 1.32256009
INFO:root:At the start of the epoch: mem (CPU python)=36232.76171875MB; mem (CPU total)=36033.546875MB
INFO:root:[   79] Training loss: 0.64322837, Validation loss: 0.62918396, Gradient norm: 1.31309555
INFO:root:At the start of the epoch: mem (CPU python)=36270.86328125MB; mem (CPU total)=36072.86328125MB
INFO:root:[   80] Training loss: 0.64322873, Validation loss: 0.62914598, Gradient norm: 1.31299647
INFO:root:At the start of the epoch: mem (CPU python)=36308.96875MB; mem (CPU total)=36110.98828125MB
INFO:root:[   81] Training loss: 0.64341665, Validation loss: 0.62833928, Gradient norm: 1.67984502
INFO:root:At the start of the epoch: mem (CPU python)=36347.12109375MB; mem (CPU total)=36148.64453125MB
INFO:root:[   82] Training loss: 0.64317875, Validation loss: 0.62878209, Gradient norm: 1.56085554
INFO:root:At the start of the epoch: mem (CPU python)=36385.21484375MB; mem (CPU total)=36187.01171875MB
INFO:root:[   83] Training loss: 0.64296005, Validation loss: 0.62893049, Gradient norm: 1.52597360
INFO:root:At the start of the epoch: mem (CPU python)=36423.30078125MB; mem (CPU total)=36225.79296875MB
INFO:root:[   84] Training loss: 0.64261608, Validation loss: 0.62804029, Gradient norm: 1.53392198
INFO:root:At the start of the epoch: mem (CPU python)=36461.40625MB; mem (CPU total)=36263.5703125MB
INFO:root:[   85] Training loss: 0.64288664, Validation loss: 0.62821854, Gradient norm: 1.59999359
INFO:root:At the start of the epoch: mem (CPU python)=36499.49609375MB; mem (CPU total)=36301.30078125MB
INFO:root:[   86] Training loss: 0.64267585, Validation loss: 0.62887956, Gradient norm: 1.86211711
INFO:root:At the start of the epoch: mem (CPU python)=36537.6015625MB; mem (CPU total)=36339.1796875MB
INFO:root:[   87] Training loss: 0.64247368, Validation loss: 0.62790503, Gradient norm: 1.77234005
INFO:root:At the start of the epoch: mem (CPU python)=36575.6953125MB; mem (CPU total)=36377.0078125MB
INFO:root:[   88] Training loss: 0.64251732, Validation loss: 0.62736788, Gradient norm: 1.87696599
INFO:root:At the start of the epoch: mem (CPU python)=36613.78515625MB; mem (CPU total)=36414.8515625MB
INFO:root:[   89] Training loss: 0.64242671, Validation loss: 0.62803443, Gradient norm: 1.95917450
INFO:root:At the start of the epoch: mem (CPU python)=36651.85546875MB; mem (CPU total)=36453.21484375MB
INFO:root:[   90] Training loss: 0.64237632, Validation loss: 0.62748912, Gradient norm: 1.76119914
INFO:root:At the start of the epoch: mem (CPU python)=36689.96875MB; mem (CPU total)=36491.30859375MB
INFO:root:[   91] Training loss: 0.64214796, Validation loss: 0.62780267, Gradient norm: 2.07677667
INFO:root:At the start of the epoch: mem (CPU python)=36728.0234375MB; mem (CPU total)=36530.1484375MB
INFO:root:[   92] Training loss: 0.64203255, Validation loss: 0.62765632, Gradient norm: 1.98764584
INFO:root:At the start of the epoch: mem (CPU python)=36766.1171875MB; mem (CPU total)=36568.28515625MB
INFO:root:[   93] Training loss: 0.64205887, Validation loss: 0.62806449, Gradient norm: 2.14451224
INFO:root:At the start of the epoch: mem (CPU python)=36804.2109375MB; mem (CPU total)=36605.89453125MB
INFO:root:[   94] Training loss: 0.64200472, Validation loss: 0.62814726, Gradient norm: 1.85379665
INFO:root:At the start of the epoch: mem (CPU python)=36842.30859375MB; mem (CPU total)=36644.09765625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   95] Training loss: 0.64177329, Validation loss: 0.62765619, Gradient norm: 2.23645231
INFO:root:At the start of the epoch: mem (CPU python)=36880.40234375MB; mem (CPU total)=36682.421875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   96] Training loss: 0.64104938, Validation loss: 0.62651374, Gradient norm: 1.51161310
INFO:root:At the start of the epoch: mem (CPU python)=36918.47265625MB; mem (CPU total)=36720.0859375MB
INFO:root:[   97] Training loss: 0.64050416, Validation loss: 0.62600727, Gradient norm: 0.96220160
INFO:root:At the start of the epoch: mem (CPU python)=36956.5703125MB; mem (CPU total)=36758.23046875MB
INFO:root:[   98] Training loss: 0.64050250, Validation loss: 0.62635523, Gradient norm: 0.95208047
INFO:root:At the start of the epoch: mem (CPU python)=36994.68359375MB; mem (CPU total)=36797.2109375MB
INFO:root:[   99] Training loss: 0.64031291, Validation loss: 0.62534604, Gradient norm: 1.06080870
INFO:root:At the start of the epoch: mem (CPU python)=37032.78515625MB; mem (CPU total)=36834.40625MB
INFO:root:[  100] Training loss: 0.64028043, Validation loss: 0.62585847, Gradient norm: 1.07636405
INFO:root:At the start of the epoch: mem (CPU python)=37070.8828125MB; mem (CPU total)=36873.48828125MB
INFO:root:[  101] Training loss: 0.64044092, Validation loss: 0.62584162, Gradient norm: 1.12503504
INFO:root:At the start of the epoch: mem (CPU python)=37108.96484375MB; mem (CPU total)=36911.56640625MB
INFO:root:[  102] Training loss: 0.64034542, Validation loss: 0.62608157, Gradient norm: 1.06717569
INFO:root:At the start of the epoch: mem (CPU python)=37147.12890625MB; mem (CPU total)=36949.69921875MB
INFO:root:[  103] Training loss: 0.64036355, Validation loss: 0.62615393, Gradient norm: 1.11682030
INFO:root:At the start of the epoch: mem (CPU python)=37185.17578125MB; mem (CPU total)=36988.046875MB
INFO:root:[  104] Training loss: 0.64039043, Validation loss: 0.62601780, Gradient norm: 1.20773813
INFO:root:At the start of the epoch: mem (CPU python)=37223.31640625MB; mem (CPU total)=37026.12109375MB
INFO:root:[  105] Training loss: 0.64036946, Validation loss: 0.62517098, Gradient norm: 1.23029621
INFO:root:At the start of the epoch: mem (CPU python)=37261.3828125MB; mem (CPU total)=37063.9609375MB
INFO:root:[  106] Training loss: 0.64037749, Validation loss: 0.62576132, Gradient norm: 1.36505522
INFO:root:At the start of the epoch: mem (CPU python)=37299.5MB; mem (CPU total)=37102.31640625MB
INFO:root:[  107] Training loss: 0.64026873, Validation loss: 0.62588865, Gradient norm: 1.20412694
INFO:root:At the start of the epoch: mem (CPU python)=37337.59375MB; mem (CPU total)=37140.40625MB
INFO:root:[  108] Training loss: 0.64025045, Validation loss: 0.62549271, Gradient norm: 1.34596140
INFO:root:At the start of the epoch: mem (CPU python)=37375.6953125MB; mem (CPU total)=37178.265625MB
INFO:root:[  109] Training loss: 0.64019188, Validation loss: 0.62557021, Gradient norm: 1.22261823
INFO:root:At the start of the epoch: mem (CPU python)=37413.7890625MB; mem (CPU total)=37216.40234375MB
INFO:root:[  110] Training loss: 0.64028122, Validation loss: 0.62595214, Gradient norm: 1.31279809
INFO:root:At the start of the epoch: mem (CPU python)=37451.86328125MB; mem (CPU total)=37255.0390625MB
INFO:root:[  111] Training loss: 0.64022848, Validation loss: 0.62633153, Gradient norm: 1.29531660
INFO:root:At the start of the epoch: mem (CPU python)=37489.96484375MB; mem (CPU total)=37293.15234375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  112] Training loss: 0.64022947, Validation loss: 0.62561428, Gradient norm: 1.25533108
INFO:root:At the start of the epoch: mem (CPU python)=37528.0625MB; mem (CPU total)=37331.5234375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  113] Training loss: 0.63987248, Validation loss: 0.62554572, Gradient norm: 1.23850075
INFO:root:At the start of the epoch: mem (CPU python)=37566.125MB; mem (CPU total)=37370.1328125MB
INFO:root:[  114] Training loss: 0.63959637, Validation loss: 0.62505798, Gradient norm: 0.95863997
INFO:root:At the start of the epoch: mem (CPU python)=37604.1953125MB; mem (CPU total)=37407.984375MB
INFO:root:[  115] Training loss: 0.63962753, Validation loss: 0.62523367, Gradient norm: 0.88442172
INFO:root:At the start of the epoch: mem (CPU python)=37642.31640625MB; mem (CPU total)=37446.5859375MB
INFO:root:[  116] Training loss: 0.63970880, Validation loss: 0.62574719, Gradient norm: 1.04657463
INFO:root:At the start of the epoch: mem (CPU python)=37680.41015625MB; mem (CPU total)=37483.96484375MB
INFO:root:[  117] Training loss: 0.63967443, Validation loss: 0.62530200, Gradient norm: 0.95999165
INFO:root:At the start of the epoch: mem (CPU python)=37718.4921875MB; mem (CPU total)=37521.671875MB
INFO:root:[  118] Training loss: 0.63986697, Validation loss: 0.62528308, Gradient norm: 1.00373903
INFO:root:At the start of the epoch: mem (CPU python)=37756.59375MB; mem (CPU total)=37560.0234375MB
INFO:root:[  119] Training loss: 0.63970068, Validation loss: 0.62506867, Gradient norm: 0.98848561
INFO:root:At the start of the epoch: mem (CPU python)=37794.6953125MB; mem (CPU total)=37598.36328125MB
INFO:root:[  120] Training loss: 0.63972562, Validation loss: 0.62555942, Gradient norm: 0.97783187
INFO:root:At the start of the epoch: mem (CPU python)=37832.7890625MB; mem (CPU total)=37636.71484375MB
INFO:root:[  121] Training loss: 0.63980174, Validation loss: 0.62474502, Gradient norm: 0.99678799
INFO:root:At the start of the epoch: mem (CPU python)=37870.87890625MB; mem (CPU total)=37674.296875MB
INFO:root:[  122] Training loss: 0.63953527, Validation loss: 0.62579031, Gradient norm: 0.97622165
INFO:root:At the start of the epoch: mem (CPU python)=37908.984375MB; mem (CPU total)=37712.8828125MB
INFO:root:[  123] Training loss: 0.63968725, Validation loss: 0.62525101, Gradient norm: 1.00458715
INFO:root:At the start of the epoch: mem (CPU python)=37947.08984375MB; mem (CPU total)=37751.2421875MB
INFO:root:[  124] Training loss: 0.63962840, Validation loss: 0.62473586, Gradient norm: 1.06114384
INFO:root:At the start of the epoch: mem (CPU python)=37985.203125MB; mem (CPU total)=37788.6796875MB
INFO:root:[  125] Training loss: 0.63967716, Validation loss: 0.62485624, Gradient norm: 0.98075504
INFO:root:At the start of the epoch: mem (CPU python)=38023.30078125MB; mem (CPU total)=37827.8046875MB
INFO:root:[  126] Training loss: 0.63978294, Validation loss: 0.62510907, Gradient norm: 0.99299768
INFO:root:At the start of the epoch: mem (CPU python)=38061.41015625MB; mem (CPU total)=37865.66796875MB
INFO:root:[  127] Training loss: 0.63976881, Validation loss: 0.62499703, Gradient norm: 1.10913185
INFO:root:At the start of the epoch: mem (CPU python)=38099.51171875MB; mem (CPU total)=37903.75390625MB
INFO:root:[  128] Training loss: 0.63966081, Validation loss: 0.62546397, Gradient norm: 1.00715195
INFO:root:At the start of the epoch: mem (CPU python)=38137.61328125MB; mem (CPU total)=37941.53125MB
INFO:root:[  129] Training loss: 0.63968107, Validation loss: 0.62488979, Gradient norm: 1.04797594
INFO:root:At the start of the epoch: mem (CPU python)=38175.68359375MB; mem (CPU total)=37979.6953125MB
INFO:root:[  130] Training loss: 0.63972989, Validation loss: 0.62525974, Gradient norm: 1.05083816
INFO:root:At the start of the epoch: mem (CPU python)=38213.7734375MB; mem (CPU total)=38017.80859375MB
INFO:root:[  131] Training loss: 0.63974765, Validation loss: 0.62534667, Gradient norm: 1.00971914
INFO:root:At the start of the epoch: mem (CPU python)=38251.90234375MB; mem (CPU total)=38056.29296875MB
INFO:root:[  132] Training loss: 0.63967345, Validation loss: 0.62508070, Gradient norm: 1.02613822
INFO:root:At the start of the epoch: mem (CPU python)=38290.00390625MB; mem (CPU total)=38094.3515625MB
INFO:root:[  133] Training loss: 0.63965816, Validation loss: 0.62528394, Gradient norm: 1.08349703
INFO:root:At the start of the epoch: mem (CPU python)=38328.0390625MB; mem (CPU total)=38132.4921875MB
INFO:root:EP 133: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=38366.13671875MB; mem (CPU total)=38170.94140625MB
INFO:root:Training the model took 9247.868s.
INFO:root:Emptying the cuda cache took 0.043s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.88103
INFO:root:EnergyScoreTrain: 0.62013
INFO:root:CRPSTrain: 0.49958
INFO:root:Gaussian NLLTrain: 421141643.37778
INFO:root:CoverageTrain: 0.85343
INFO:root:IntervalWidthTrain: 3.02056
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88808
INFO:root:EnergyScoreValidation: 0.6252
INFO:root:CRPSValidation: 0.50448
INFO:root:Gaussian NLLValidation: 426535762.70222
INFO:root:CoverageValidation: 0.8515
INFO:root:IntervalWidthValidation: 3.02345
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88863
INFO:root:EnergyScoreTest: 0.62557
INFO:root:CRPSTest: 0.50481
INFO:root:Gaussian NLLTest: 429362765.44
INFO:root:CoverageTest: 0.85212
INFO:root:IntervalWidthTest: 3.02757
INFO:root:After validation: mem (CPU python)=38470.57421875MB; mem (CPU total)=38279.56640625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=38470.57421875MB; mem (CPU total)=38279.83984375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=38470.57421875MB; mem (CPU total)=38280.33203125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=38470.57421875MB; mem (CPU total)=38280.42578125MB
INFO:root:[    1] Training loss: 0.72542955, Validation loss: 0.72051122, Gradient norm: 0.02138054
INFO:root:At the start of the epoch: mem (CPU python)=38511.64453125MB; mem (CPU total)=38318.625MB
INFO:root:[    2] Training loss: 0.71987265, Validation loss: 0.71856668, Gradient norm: 0.00618563
INFO:root:At the start of the epoch: mem (CPU python)=38549.74609375MB; mem (CPU total)=38357.0625MB
INFO:root:[    3] Training loss: 0.71860026, Validation loss: 0.71731027, Gradient norm: 0.00840015
INFO:root:At the start of the epoch: mem (CPU python)=38586.75MB; mem (CPU total)=38395.203125MB
INFO:root:[    4] Training loss: 0.71472617, Validation loss: 0.70795851, Gradient norm: 0.01930909
INFO:root:At the start of the epoch: mem (CPU python)=38625.6015625MB; mem (CPU total)=38433.3203125MB
INFO:root:[    5] Training loss: 0.70797937, Validation loss: 0.70170865, Gradient norm: 0.02964426
INFO:root:At the start of the epoch: mem (CPU python)=38662.86328125MB; mem (CPU total)=38471.5546875MB
INFO:root:[    6] Training loss: 0.70226120, Validation loss: 0.69506382, Gradient norm: 0.03767545
INFO:root:At the start of the epoch: mem (CPU python)=38702.125MB; mem (CPU total)=38509.890625MB
INFO:root:[    7] Training loss: 0.69652761, Validation loss: 0.68802031, Gradient norm: 0.03767055
INFO:root:At the start of the epoch: mem (CPU python)=38740.22265625MB; mem (CPU total)=38548.4921875MB
INFO:root:[    8] Training loss: 0.69093257, Validation loss: 0.68055613, Gradient norm: 0.03834757
INFO:root:At the start of the epoch: mem (CPU python)=38778.30859375MB; mem (CPU total)=38586.3203125MB
INFO:root:[    9] Training loss: 0.68608057, Validation loss: 0.67517772, Gradient norm: 0.03899638
INFO:root:At the start of the epoch: mem (CPU python)=38816.15234375MB; mem (CPU total)=38624.7578125MB
INFO:root:[   10] Training loss: 0.68170213, Validation loss: 0.66982793, Gradient norm: 0.03994552
INFO:root:At the start of the epoch: mem (CPU python)=38854.4765625MB; mem (CPU total)=38663.1171875MB
INFO:root:[   11] Training loss: 0.67772241, Validation loss: 0.66612913, Gradient norm: 0.03653006
INFO:root:At the start of the epoch: mem (CPU python)=38892.53515625MB; mem (CPU total)=38701.23046875MB
INFO:root:[   12] Training loss: 0.67436250, Validation loss: 0.66278064, Gradient norm: 0.04047548
INFO:root:At the start of the epoch: mem (CPU python)=38930.421875MB; mem (CPU total)=38738.90625MB
INFO:root:[   13] Training loss: 0.67144245, Validation loss: 0.65927218, Gradient norm: 0.03919740
INFO:root:At the start of the epoch: mem (CPU python)=38968.796875MB; mem (CPU total)=38777.03125MB
INFO:root:[   14] Training loss: 0.66895049, Validation loss: 0.65593111, Gradient norm: 0.03864450
INFO:root:At the start of the epoch: mem (CPU python)=39006.8828125MB; mem (CPU total)=38815.39453125MB
INFO:root:[   15] Training loss: 0.66662129, Validation loss: 0.65409022, Gradient norm: 0.03363057
INFO:root:At the start of the epoch: mem (CPU python)=39044.69921875MB; mem (CPU total)=38853.578125MB
INFO:root:[   16] Training loss: 0.66501148, Validation loss: 0.65240362, Gradient norm: 0.03980875
INFO:root:At the start of the epoch: mem (CPU python)=39083.04296875MB; mem (CPU total)=38891.7109375MB
INFO:root:[   17] Training loss: 0.66330450, Validation loss: 0.65014147, Gradient norm: 0.04636438
INFO:root:At the start of the epoch: mem (CPU python)=39121.15234375MB; mem (CPU total)=38930.12109375MB
INFO:root:[   18] Training loss: 0.66159633, Validation loss: 0.64928603, Gradient norm: 0.04022686
INFO:root:At the start of the epoch: mem (CPU python)=39158.9375MB; mem (CPU total)=38968.48046875MB
INFO:root:[   19] Training loss: 0.66026019, Validation loss: 0.64768259, Gradient norm: 0.04429727
INFO:root:At the start of the epoch: mem (CPU python)=39197.35546875MB; mem (CPU total)=39006.6328125MB
INFO:root:[   20] Training loss: 0.65925086, Validation loss: 0.64700960, Gradient norm: 0.04289180
INFO:root:At the start of the epoch: mem (CPU python)=39235.45703125MB; mem (CPU total)=39044.2890625MB
INFO:root:[   21] Training loss: 0.65776684, Validation loss: 0.64451412, Gradient norm: 0.04168448
INFO:root:At the start of the epoch: mem (CPU python)=39273.5625MB; mem (CPU total)=39082.41015625MB
INFO:root:[   22] Training loss: 0.65662070, Validation loss: 0.64364438, Gradient norm: 0.04559989
INFO:root:At the start of the epoch: mem (CPU python)=39311.58203125MB; mem (CPU total)=39120.76171875MB
INFO:root:[   23] Training loss: 0.65564542, Validation loss: 0.64281531, Gradient norm: 0.04908335
INFO:root:At the start of the epoch: mem (CPU python)=39349.75MB; mem (CPU total)=39159.23046875MB
INFO:root:[   24] Training loss: 0.65467596, Validation loss: 0.64140070, Gradient norm: 0.04751376
INFO:root:At the start of the epoch: mem (CPU python)=39386.96875MB; mem (CPU total)=39197.27734375MB
INFO:root:[   25] Training loss: 0.65366044, Validation loss: 0.64075203, Gradient norm: 0.05262242
INFO:root:At the start of the epoch: mem (CPU python)=39425.9296875MB; mem (CPU total)=39235.35546875MB
INFO:root:[   26] Training loss: 0.65295017, Validation loss: 0.63854760, Gradient norm: 0.05730476
INFO:root:At the start of the epoch: mem (CPU python)=39464.03515625MB; mem (CPU total)=39273.734375MB
INFO:root:[   27] Training loss: 0.65205071, Validation loss: 0.63804088, Gradient norm: 0.05327786
INFO:root:At the start of the epoch: mem (CPU python)=39502.06640625MB; mem (CPU total)=39312.10546875MB
INFO:root:[   28] Training loss: 0.65152275, Validation loss: 0.63729157, Gradient norm: 0.06211213
INFO:root:At the start of the epoch: mem (CPU python)=39539.3828125MB; mem (CPU total)=39350.2421875MB
INFO:root:[   29] Training loss: 0.65054409, Validation loss: 0.63666621, Gradient norm: 0.06149462
INFO:root:At the start of the epoch: mem (CPU python)=39578.26953125MB; mem (CPU total)=39388.375MB
INFO:root:[   30] Training loss: 0.64992290, Validation loss: 0.63574329, Gradient norm: 0.06950355
INFO:root:At the start of the epoch: mem (CPU python)=39616.36328125MB; mem (CPU total)=39426.25MB
INFO:root:[   31] Training loss: 0.64934292, Validation loss: 0.63554690, Gradient norm: 0.06880081
INFO:root:At the start of the epoch: mem (CPU python)=39654.45703125MB; mem (CPU total)=39465.33984375MB
INFO:root:[   32] Training loss: 0.64883100, Validation loss: 0.63512390, Gradient norm: 0.07154929
INFO:root:At the start of the epoch: mem (CPU python)=39692.4765625MB; mem (CPU total)=39503.46875MB
INFO:root:[   33] Training loss: 0.64817871, Validation loss: 0.63449932, Gradient norm: 0.07641635
INFO:root:At the start of the epoch: mem (CPU python)=39730.33984375MB; mem (CPU total)=39541.625MB
INFO:root:[   34] Training loss: 0.64779218, Validation loss: 0.63415135, Gradient norm: 0.08054483
INFO:root:At the start of the epoch: mem (CPU python)=39768.74609375MB; mem (CPU total)=39579.5703125MB
INFO:root:[   35] Training loss: 0.64734728, Validation loss: 0.63360260, Gradient norm: 0.09989336
INFO:root:At the start of the epoch: mem (CPU python)=39806.5625MB; mem (CPU total)=39618.25390625MB
INFO:root:[   36] Training loss: 0.64693164, Validation loss: 0.63398175, Gradient norm: 0.09758666
INFO:root:At the start of the epoch: mem (CPU python)=39844.921875MB; mem (CPU total)=39656.875MB
INFO:root:[   37] Training loss: 0.64633966, Validation loss: 0.63276813, Gradient norm: 0.09820387
INFO:root:At the start of the epoch: mem (CPU python)=39881.73046875MB; mem (CPU total)=39694.27734375MB
INFO:root:[   38] Training loss: 0.64609088, Validation loss: 0.63185843, Gradient norm: 0.09850741
INFO:root:At the start of the epoch: mem (CPU python)=39921.125MB; mem (CPU total)=39732.65234375MB
INFO:root:[   39] Training loss: 0.64566168, Validation loss: 0.63202408, Gradient norm: 0.12806927
INFO:root:At the start of the epoch: mem (CPU python)=39958.92578125MB; mem (CPU total)=39771.0234375MB
INFO:root:[   40] Training loss: 0.64515767, Validation loss: 0.63363963, Gradient norm: 0.12793029
INFO:root:At the start of the epoch: mem (CPU python)=39997.36328125MB; mem (CPU total)=39809.15234375MB
INFO:root:[   41] Training loss: 0.64474063, Validation loss: 0.63335600, Gradient norm: 0.14705376
INFO:root:At the start of the epoch: mem (CPU python)=40035.46484375MB; mem (CPU total)=39847.03125MB
INFO:root:[   42] Training loss: 0.64442767, Validation loss: 0.63233233, Gradient norm: 0.16883765
INFO:root:At the start of the epoch: mem (CPU python)=40073.47265625MB; mem (CPU total)=39885.37109375MB
INFO:root:[   43] Training loss: 0.64395823, Validation loss: 0.63432952, Gradient norm: 0.15435151
INFO:root:At the start of the epoch: mem (CPU python)=40111.61328125MB; mem (CPU total)=39923.2421875MB
INFO:root:[   44] Training loss: 0.64388938, Validation loss: 0.63439369, Gradient norm: 0.14144405
INFO:root:At the start of the epoch: mem (CPU python)=40149.20703125MB; mem (CPU total)=39961.37109375MB
INFO:root:[   45] Training loss: 0.64360679, Validation loss: 0.63556221, Gradient norm: 0.17715986
INFO:root:At the start of the epoch: mem (CPU python)=40187.25390625MB; mem (CPU total)=39999.26953125MB
INFO:root:[   46] Training loss: 0.64319127, Validation loss: 0.63736855, Gradient norm: 0.17141008
INFO:root:At the start of the epoch: mem (CPU python)=40225.55078125MB; mem (CPU total)=40037.63671875MB
INFO:root:[   47] Training loss: 0.64291308, Validation loss: 0.63477263, Gradient norm: 0.21718983
INFO:root:At the start of the epoch: mem (CPU python)=40264.015625MB; mem (CPU total)=40076.0MB
INFO:root:[   48] Training loss: 0.64271704, Validation loss: 0.63915554, Gradient norm: 0.21347428
INFO:root:At the start of the epoch: mem (CPU python)=40302.0234375MB; mem (CPU total)=40114.84765625MB
INFO:root:[   49] Training loss: 0.64221551, Validation loss: 0.63599275, Gradient norm: 0.21720295
INFO:root:At the start of the epoch: mem (CPU python)=40340.17578125MB; mem (CPU total)=40152.71484375MB
INFO:root:[   50] Training loss: 0.64215280, Validation loss: 0.63992242, Gradient norm: 0.28797106
INFO:root:At the start of the epoch: mem (CPU python)=40377.2421875MB; mem (CPU total)=40190.30859375MB
INFO:root:[   51] Training loss: 0.64178149, Validation loss: 0.63096518, Gradient norm: 0.32977905
INFO:root:At the start of the epoch: mem (CPU python)=40416.359375MB; mem (CPU total)=40228.89453125MB
INFO:root:[   52] Training loss: 0.64157166, Validation loss: 0.63503409, Gradient norm: 0.28751427
INFO:root:At the start of the epoch: mem (CPU python)=40454.4453125MB; mem (CPU total)=40267.50390625MB
INFO:root:[   53] Training loss: 0.64108429, Validation loss: 0.63619715, Gradient norm: 0.25227477
INFO:root:At the start of the epoch: mem (CPU python)=40492.5625MB; mem (CPU total)=40305.63671875MB
INFO:root:[   54] Training loss: 0.64073932, Validation loss: 0.63959171, Gradient norm: 0.28401663
INFO:root:At the start of the epoch: mem (CPU python)=40530.3671875MB; mem (CPU total)=40343.52734375MB
INFO:root:[   55] Training loss: 0.64064680, Validation loss: 0.64263609, Gradient norm: 0.37460750
INFO:root:At the start of the epoch: mem (CPU python)=40568.71875MB; mem (CPU total)=40385.78125MB
INFO:root:[   56] Training loss: 0.64038909, Validation loss: 0.63571026, Gradient norm: 0.36084255
INFO:root:At the start of the epoch: mem (CPU python)=40606.8359375MB; mem (CPU total)=40423.765625MB
INFO:root:[   57] Training loss: 0.64024681, Validation loss: 0.63650931, Gradient norm: 0.39502219
INFO:root:At the start of the epoch: mem (CPU python)=40644.92578125MB; mem (CPU total)=40461.87109375MB
INFO:root:[   58] Training loss: 0.63987974, Validation loss: 0.63764786, Gradient norm: 0.28861821
INFO:root:At the start of the epoch: mem (CPU python)=40683.015625MB; mem (CPU total)=40500.0625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   59] Training loss: 0.63988569, Validation loss: 0.63912619, Gradient norm: 0.34306780
INFO:root:At the start of the epoch: mem (CPU python)=40721.11328125MB; mem (CPU total)=40538.03515625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   60] Training loss: 0.63901555, Validation loss: 0.64300006, Gradient norm: 0.26222028
INFO:root:At the start of the epoch: mem (CPU python)=40759.2734375MB; mem (CPU total)=40576.35546875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   61] Training loss: 0.63847365, Validation loss: 0.64234576, Gradient norm: 0.20631274
INFO:root:At the start of the epoch: mem (CPU python)=40797.375MB; mem (CPU total)=40614.4453125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:EP 61: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=40835.46875MB; mem (CPU total)=40652.5859375MB
INFO:root:Training the model took 4489.716s.
INFO:root:Emptying the cuda cache took 0.041s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.88342
INFO:root:EnergyScoreTrain: 0.62703
INFO:root:CRPSTrain: 0.51766
INFO:root:Gaussian NLLTrain: 220409.46445
INFO:root:CoverageTrain: 0.69994
INFO:root:IntervalWidthTrain: 2.34265
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88839
INFO:root:EnergyScoreValidation: 0.63089
INFO:root:CRPSValidation: 0.52134
INFO:root:Gaussian NLLValidation: 209730.56208
INFO:root:CoverageValidation: 0.69653
INFO:root:IntervalWidthValidation: 2.33998
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.8899
INFO:root:EnergyScoreTest: 0.63206
INFO:root:CRPSTest: 0.52226
INFO:root:Gaussian NLLTest: 175035.91694
INFO:root:CoverageTest: 0.69633
INFO:root:IntervalWidthTest: 2.34195
INFO:root:After validation: mem (CPU python)=40843.8203125MB; mem (CPU total)=40695.046875MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 50}
INFO:root:After creating the dataloaders: mem (CPU python)=40843.8203125MB; mem (CPU total)=40618.14453125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=40843.8203125MB; mem (CPU total)=40618.10546875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=40843.8203125MB; mem (CPU total)=40618.0859375MB
INFO:root:[    1] Training loss: 0.72705244, Validation loss: 0.72073863, Gradient norm: 0.03142282
INFO:root:At the start of the epoch: mem (CPU python)=40869.078125MB; mem (CPU total)=40686.53125MB
INFO:root:[    2] Training loss: 0.71990025, Validation loss: 0.71839813, Gradient norm: 0.00669250
INFO:root:At the start of the epoch: mem (CPU python)=40907.1953125MB; mem (CPU total)=40723.625MB
INFO:root:[    3] Training loss: 0.71694291, Validation loss: 0.71117607, Gradient norm: 0.01368389
INFO:root:At the start of the epoch: mem (CPU python)=40945.26171875MB; mem (CPU total)=40762.00390625MB
INFO:root:[    4] Training loss: 0.71011682, Validation loss: 0.70308553, Gradient norm: 0.03207957
INFO:root:At the start of the epoch: mem (CPU python)=40983.37890625MB; mem (CPU total)=40800.12890625MB
INFO:root:[    5] Training loss: 0.70391945, Validation loss: 0.69657222, Gradient norm: 0.03885798
INFO:root:At the start of the epoch: mem (CPU python)=41021.5MB; mem (CPU total)=40838.74609375MB
INFO:root:[    6] Training loss: 0.69817982, Validation loss: 0.68889181, Gradient norm: 0.04651735
INFO:root:At the start of the epoch: mem (CPU python)=41059.58203125MB; mem (CPU total)=40876.8359375MB
INFO:root:[    7] Training loss: 0.69217933, Validation loss: 0.68256470, Gradient norm: 0.04633087
INFO:root:At the start of the epoch: mem (CPU python)=41097.6875MB; mem (CPU total)=40914.953125MB
INFO:root:[    8] Training loss: 0.68738941, Validation loss: 0.67648877, Gradient norm: 0.05392063
INFO:root:At the start of the epoch: mem (CPU python)=41135.78125MB; mem (CPU total)=40953.3125MB
INFO:root:[    9] Training loss: 0.68331650, Validation loss: 0.67222415, Gradient norm: 0.05092364
INFO:root:At the start of the epoch: mem (CPU python)=41173.87890625MB; mem (CPU total)=40991.16015625MB
INFO:root:[   10] Training loss: 0.67982755, Validation loss: 0.66805678, Gradient norm: 0.05342701
INFO:root:At the start of the epoch: mem (CPU python)=41211.94140625MB; mem (CPU total)=41029.49609375MB
INFO:root:[   11] Training loss: 0.67696310, Validation loss: 0.66515135, Gradient norm: 0.06118019
INFO:root:At the start of the epoch: mem (CPU python)=41250.03515625MB; mem (CPU total)=41067.87109375MB
INFO:root:[   12] Training loss: 0.67429397, Validation loss: 0.66242902, Gradient norm: 0.06189133
INFO:root:At the start of the epoch: mem (CPU python)=41288.171875MB; mem (CPU total)=41105.46875MB
INFO:root:[   13] Training loss: 0.67249019, Validation loss: 0.66007041, Gradient norm: 0.07609138
INFO:root:At the start of the epoch: mem (CPU python)=41326.265625MB; mem (CPU total)=41143.5546875MB
INFO:root:[   14] Training loss: 0.67056382, Validation loss: 0.65930175, Gradient norm: 0.07544971
INFO:root:At the start of the epoch: mem (CPU python)=41364.3046875MB; mem (CPU total)=41181.66796875MB
INFO:root:[   15] Training loss: 0.66907694, Validation loss: 0.65823145, Gradient norm: 0.10633966
INFO:root:At the start of the epoch: mem (CPU python)=41402.34375MB; mem (CPU total)=41219.78125MB
INFO:root:[   16] Training loss: 0.66792236, Validation loss: 0.65645825, Gradient norm: 0.11567454
INFO:root:At the start of the epoch: mem (CPU python)=41440.4765625MB; mem (CPU total)=41257.87890625MB
INFO:root:[   17] Training loss: 0.66671887, Validation loss: 0.65731167, Gradient norm: 0.11968759
INFO:root:At the start of the epoch: mem (CPU python)=41478.5859375MB; mem (CPU total)=41296.95703125MB
INFO:root:[   18] Training loss: 0.66578543, Validation loss: 0.65796797, Gradient norm: 0.13823514
INFO:root:At the start of the epoch: mem (CPU python)=41516.6640625MB; mem (CPU total)=41335.0625MB
INFO:root:[   19] Training loss: 0.66478731, Validation loss: 0.65563628, Gradient norm: 0.19459654
INFO:root:At the start of the epoch: mem (CPU python)=41554.78125MB; mem (CPU total)=41372.9296875MB
INFO:root:[   20] Training loss: 0.66395010, Validation loss: 0.66245340, Gradient norm: 0.20840701
INFO:root:At the start of the epoch: mem (CPU python)=41592.87109375MB; mem (CPU total)=41411.546875MB
INFO:root:[   21] Training loss: 0.66307715, Validation loss: 0.66039429, Gradient norm: 0.23306834
INFO:root:At the start of the epoch: mem (CPU python)=41630.94140625MB; mem (CPU total)=41449.6171875MB
INFO:root:[   22] Training loss: 0.66244598, Validation loss: 0.66248237, Gradient norm: 0.25793899
INFO:root:At the start of the epoch: mem (CPU python)=41669.0625MB; mem (CPU total)=41487.9375MB
INFO:root:[   23] Training loss: 0.66164866, Validation loss: 0.66571011, Gradient norm: 0.24292848
INFO:root:At the start of the epoch: mem (CPU python)=41707.16015625MB; mem (CPU total)=41524.2578125MB
INFO:root:[   24] Training loss: 0.66104122, Validation loss: 0.66957567, Gradient norm: 0.31624544
INFO:root:At the start of the epoch: mem (CPU python)=41745.30859375MB; mem (CPU total)=41562.33984375MB
INFO:root:[   25] Training loss: 0.66021659, Validation loss: 0.66399828, Gradient norm: 0.26670870
INFO:root:At the start of the epoch: mem (CPU python)=41783.39453125MB; mem (CPU total)=41600.66015625MB
INFO:root:[   26] Training loss: 0.65964252, Validation loss: 0.67721040, Gradient norm: 0.32708882
INFO:root:At the start of the epoch: mem (CPU python)=41821.484375MB; mem (CPU total)=41638.69921875MB
INFO:root:[   27] Training loss: 0.65905726, Validation loss: 0.68290217, Gradient norm: 0.33892182
INFO:root:At the start of the epoch: mem (CPU python)=41859.59765625MB; mem (CPU total)=41676.77734375MB
INFO:root:[   28] Training loss: 0.65839198, Validation loss: 0.67585643, Gradient norm: 0.42994061
INFO:root:At the start of the epoch: mem (CPU python)=41897.69140625MB; mem (CPU total)=41715.3828125MB
INFO:root:[   29] Training loss: 0.65780015, Validation loss: 0.68207653, Gradient norm: 0.37735766
INFO:root:At the start of the epoch: mem (CPU python)=41935.79296875MB; mem (CPU total)=41753.00390625MB
INFO:root:[   30] Training loss: 0.65762611, Validation loss: 0.67458211, Gradient norm: 0.59389475
INFO:root:At the start of the epoch: mem (CPU python)=41973.8828125MB; mem (CPU total)=41790.8515625MB
INFO:root:[   31] Training loss: 0.65684969, Validation loss: 0.66610917, Gradient norm: 0.45838119
INFO:root:At the start of the epoch: mem (CPU python)=42011.9765625MB; mem (CPU total)=41828.6875MB
INFO:root:[   32] Training loss: 0.65623663, Validation loss: 0.67769332, Gradient norm: 0.45308713
INFO:root:At the start of the epoch: mem (CPU python)=42050.07421875MB; mem (CPU total)=41866.77734375MB
INFO:root:[   33] Training loss: 0.65570557, Validation loss: 0.68371175, Gradient norm: 0.43969672
INFO:root:At the start of the epoch: mem (CPU python)=42088.1171875MB; mem (CPU total)=41905.12109375MB
INFO:root:[   34] Training loss: 0.65521685, Validation loss: 0.68877915, Gradient norm: 0.48845236
INFO:root:At the start of the epoch: mem (CPU python)=42126.25390625MB; mem (CPU total)=41943.203125MB
INFO:root:[   35] Training loss: 0.65480900, Validation loss: 0.68587590, Gradient norm: 0.50305629
INFO:root:At the start of the epoch: mem (CPU python)=42164.26171875MB; mem (CPU total)=41982.02734375MB
INFO:root:[   36] Training loss: 0.65451798, Validation loss: 0.66300688, Gradient norm: 0.66791853
INFO:root:At the start of the epoch: mem (CPU python)=42202.40234375MB; mem (CPU total)=42021.8125MB
INFO:root:[   37] Training loss: 0.65378132, Validation loss: 0.67860126, Gradient norm: 0.44927896
INFO:root:At the start of the epoch: mem (CPU python)=42240.49609375MB; mem (CPU total)=42059.69140625MB
INFO:root:[   38] Training loss: 0.65359971, Validation loss: 0.67331614, Gradient norm: 0.64333491
INFO:root:At the start of the epoch: mem (CPU python)=42278.60546875MB; mem (CPU total)=42097.80859375MB
INFO:root:[   39] Training loss: 0.65325240, Validation loss: 0.67790196, Gradient norm: 0.73874715
INFO:root:At the start of the epoch: mem (CPU python)=42316.6796875MB; mem (CPU total)=42135.921875MB
INFO:root:[   40] Training loss: 0.65280767, Validation loss: 0.67584584, Gradient norm: 0.69184785
INFO:root:At the start of the epoch: mem (CPU python)=42354.77734375MB; mem (CPU total)=42174.796875MB
INFO:root:[   41] Training loss: 0.65256700, Validation loss: 0.68325115, Gradient norm: 0.78208740
INFO:root:At the start of the epoch: mem (CPU python)=42392.875MB; mem (CPU total)=42213.15234375MB
INFO:root:[   42] Training loss: 0.65203990, Validation loss: 0.67561113, Gradient norm: 0.73211402
INFO:root:At the start of the epoch: mem (CPU python)=42430.9453125MB; mem (CPU total)=42250.97265625MB
INFO:root:[   43] Training loss: 0.65173915, Validation loss: 0.66832610, Gradient norm: 0.81019843
INFO:root:At the start of the epoch: mem (CPU python)=42469.0546875MB; mem (CPU total)=42289.578125MB
INFO:root:[   44] Training loss: 0.65151218, Validation loss: 0.68212086, Gradient norm: 0.86729376
INFO:root:At the start of the epoch: mem (CPU python)=42507.1640625MB; mem (CPU total)=42327.734375MB
INFO:root:[   45] Training loss: 0.65122920, Validation loss: 0.67661128, Gradient norm: 0.99653774
INFO:root:At the start of the epoch: mem (CPU python)=42545.3125MB; mem (CPU total)=42366.171875MB
INFO:root:[   46] Training loss: 0.65075020, Validation loss: 0.67152176, Gradient norm: 0.94929147
INFO:root:At the start of the epoch: mem (CPU python)=42583.37890625MB; mem (CPU total)=42406.92578125MB
INFO:root:[   47] Training loss: 0.65040208, Validation loss: 0.68522387, Gradient norm: 0.88620393
INFO:root:At the start of the epoch: mem (CPU python)=42621.49609375MB; mem (CPU total)=42443.54296875MB
INFO:root:[   48] Training loss: 0.65017380, Validation loss: 0.66013054, Gradient norm: 1.09119609
INFO:root:At the start of the epoch: mem (CPU python)=42659.59375MB; mem (CPU total)=42481.18359375MB
INFO:root:[   49] Training loss: 0.64979874, Validation loss: 0.67514859, Gradient norm: 1.04957439
INFO:root:At the start of the epoch: mem (CPU python)=42697.6875MB; mem (CPU total)=42519.296875MB
INFO:root:[   50] Training loss: 0.64961195, Validation loss: 0.66828352, Gradient norm: 1.18236685
INFO:root:At the start of the epoch: mem (CPU python)=42735.7890625MB; mem (CPU total)=42557.66796875MB
INFO:root:[   51] Training loss: 0.64946604, Validation loss: 0.66884327, Gradient norm: 1.05020576
INFO:root:At the start of the epoch: mem (CPU python)=42773.87109375MB; mem (CPU total)=42594.54296875MB
INFO:root:[   52] Training loss: 0.64924318, Validation loss: 0.66557888, Gradient norm: 1.16792689
INFO:root:At the start of the epoch: mem (CPU python)=42811.95703125MB; mem (CPU total)=42632.6640625MB
INFO:root:[   53] Training loss: 0.64870506, Validation loss: 0.65936183, Gradient norm: 1.25261936
INFO:root:At the start of the epoch: mem (CPU python)=42850.078125MB; mem (CPU total)=42670.78125MB
INFO:root:[   54] Training loss: 0.64842657, Validation loss: 0.65820397, Gradient norm: 1.29884481
INFO:root:At the start of the epoch: mem (CPU python)=42888.171875MB; mem (CPU total)=42708.85546875MB
INFO:root:[   55] Training loss: 0.64850393, Validation loss: 0.65588407, Gradient norm: 1.36504194
INFO:root:At the start of the epoch: mem (CPU python)=42926.19140625MB; mem (CPU total)=42747.48828125MB
INFO:root:[   56] Training loss: 0.64815173, Validation loss: 0.65133958, Gradient norm: 1.38379706
INFO:root:At the start of the epoch: mem (CPU python)=42964.30859375MB; mem (CPU total)=42784.3671875MB
INFO:root:[   57] Training loss: 0.64789576, Validation loss: 0.65183349, Gradient norm: 1.33500231
INFO:root:At the start of the epoch: mem (CPU python)=43002.40234375MB; mem (CPU total)=42822.69140625MB
INFO:root:[   58] Training loss: 0.64780185, Validation loss: 0.64901849, Gradient norm: 1.44027023
INFO:root:At the start of the epoch: mem (CPU python)=43040.5MB; mem (CPU total)=42860.55078125MB
INFO:root:[   59] Training loss: 0.64726577, Validation loss: 0.65289956, Gradient norm: 1.43361746
INFO:root:At the start of the epoch: mem (CPU python)=43078.44140625MB; mem (CPU total)=42898.6953125MB
INFO:root:[   60] Training loss: 0.64712690, Validation loss: 0.64721542, Gradient norm: 1.45128071
INFO:root:At the start of the epoch: mem (CPU python)=43116.6875MB; mem (CPU total)=42936.48828125MB
INFO:root:[   61] Training loss: 0.64707662, Validation loss: 0.64777647, Gradient norm: 1.58357581
INFO:root:At the start of the epoch: mem (CPU python)=43154.7890625MB; mem (CPU total)=42974.73828125MB
INFO:root:[   62] Training loss: 0.64689366, Validation loss: 0.64919978, Gradient norm: 1.58734097
INFO:root:At the start of the epoch: mem (CPU python)=43192.8828125MB; mem (CPU total)=43013.09765625MB
INFO:root:[   63] Training loss: 0.64670346, Validation loss: 0.64401076, Gradient norm: 1.62031153
INFO:root:At the start of the epoch: mem (CPU python)=43230.9765625MB; mem (CPU total)=43050.5390625MB
INFO:root:[   64] Training loss: 0.64652460, Validation loss: 0.65250935, Gradient norm: 1.68519103
INFO:root:At the start of the epoch: mem (CPU python)=43269.0703125MB; mem (CPU total)=43089.12890625MB
INFO:root:[   65] Training loss: 0.64633630, Validation loss: 0.64396021, Gradient norm: 1.65203094
INFO:root:At the start of the epoch: mem (CPU python)=43307.14453125MB; mem (CPU total)=43126.08203125MB
INFO:root:[   66] Training loss: 0.64629389, Validation loss: 0.63770427, Gradient norm: 1.89878694
INFO:root:At the start of the epoch: mem (CPU python)=43345.3203125MB; mem (CPU total)=43163.91015625MB
INFO:root:[   67] Training loss: 0.64602797, Validation loss: 0.64324141, Gradient norm: 1.70657227
INFO:root:At the start of the epoch: mem (CPU python)=43383.421875MB; mem (CPU total)=43202.59375MB
INFO:root:[   68] Training loss: 0.64590122, Validation loss: 0.63913325, Gradient norm: 1.82600074
INFO:root:At the start of the epoch: mem (CPU python)=43421.48828125MB; mem (CPU total)=43241.1640625MB
INFO:root:[   69] Training loss: 0.64595818, Validation loss: 0.64469749, Gradient norm: 2.00228671
INFO:root:At the start of the epoch: mem (CPU python)=43459.60546875MB; mem (CPU total)=43278.6171875MB
INFO:root:[   70] Training loss: 0.64570018, Validation loss: 0.63843714, Gradient norm: 2.01743852
INFO:root:At the start of the epoch: mem (CPU python)=43497.703125MB; mem (CPU total)=43316.89453125MB
INFO:root:[   71] Training loss: 0.64546648, Validation loss: 0.63671757, Gradient norm: 2.09005604
INFO:root:At the start of the epoch: mem (CPU python)=43535.66796875MB; mem (CPU total)=43354.49609375MB
INFO:root:[   72] Training loss: 0.64528899, Validation loss: 0.63135949, Gradient norm: 2.00528914
INFO:root:At the start of the epoch: mem (CPU python)=43573.8515625MB; mem (CPU total)=43392.59375MB
INFO:root:[   73] Training loss: 0.64521425, Validation loss: 0.63201079, Gradient norm: 2.11022345
INFO:root:At the start of the epoch: mem (CPU python)=43611.98828125MB; mem (CPU total)=43431.17578125MB
INFO:root:[   74] Training loss: 0.64497339, Validation loss: 0.63697034, Gradient norm: 1.99310297
INFO:root:At the start of the epoch: mem (CPU python)=43650.08203125MB; mem (CPU total)=43469.53515625MB
INFO:root:[   75] Training loss: 0.64498000, Validation loss: 0.63388596, Gradient norm: 2.35183182
INFO:root:At the start of the epoch: mem (CPU python)=43688.12109375MB; mem (CPU total)=43508.19921875MB
INFO:root:[   76] Training loss: 0.64488966, Validation loss: 0.63424090, Gradient norm: 2.52023098
INFO:root:At the start of the epoch: mem (CPU python)=43726.203125MB; mem (CPU total)=43546.6328125MB
INFO:root:[   77] Training loss: 0.64459493, Validation loss: 0.63259586, Gradient norm: 2.37557168
INFO:root:At the start of the epoch: mem (CPU python)=43764.31640625MB; mem (CPU total)=43584.8046875MB
INFO:root:[   78] Training loss: 0.64493425, Validation loss: 0.63101031, Gradient norm: 2.60524222
INFO:root:At the start of the epoch: mem (CPU python)=43802.41015625MB; mem (CPU total)=43622.203125MB
INFO:root:[   79] Training loss: 0.64451869, Validation loss: 0.63085501, Gradient norm: 2.41909425
INFO:root:At the start of the epoch: mem (CPU python)=43840.4765625MB; mem (CPU total)=43660.3046875MB
INFO:root:[   80] Training loss: 0.64436353, Validation loss: 0.63006833, Gradient norm: 2.57716790
INFO:root:At the start of the epoch: mem (CPU python)=43878.58984375MB; mem (CPU total)=43698.94921875MB
INFO:root:[   81] Training loss: 0.64424967, Validation loss: 0.62941062, Gradient norm: 2.47306514
INFO:root:At the start of the epoch: mem (CPU python)=43916.6953125MB; mem (CPU total)=43737.03515625MB
INFO:root:[   82] Training loss: 0.64413331, Validation loss: 0.62956255, Gradient norm: 2.57206354
INFO:root:At the start of the epoch: mem (CPU python)=43954.7890625MB; mem (CPU total)=43775.875MB
INFO:root:[   83] Training loss: 0.64402004, Validation loss: 0.62872912, Gradient norm: 2.33058645
INFO:root:At the start of the epoch: mem (CPU python)=43992.88671875MB; mem (CPU total)=43813.109375MB
INFO:root:[   84] Training loss: 0.64402843, Validation loss: 0.62853285, Gradient norm: 3.03848284
INFO:root:At the start of the epoch: mem (CPU python)=44030.98046875MB; mem (CPU total)=43851.1953125MB
INFO:root:[   85] Training loss: 0.64405325, Validation loss: 0.62998303, Gradient norm: 2.95852774
INFO:root:At the start of the epoch: mem (CPU python)=44069.0625MB; mem (CPU total)=43890.0390625MB
INFO:root:[   86] Training loss: 0.64392178, Validation loss: 0.63008378, Gradient norm: 2.90791029
INFO:root:At the start of the epoch: mem (CPU python)=44107.11328125MB; mem (CPU total)=43928.0390625MB
INFO:root:[   87] Training loss: 0.64378294, Validation loss: 0.62945682, Gradient norm: 3.15474426
INFO:root:At the start of the epoch: mem (CPU python)=44145.28515625MB; mem (CPU total)=43966.42578125MB
INFO:root:[   88] Training loss: 0.64371885, Validation loss: 0.62933221, Gradient norm: 3.24441506
INFO:root:At the start of the epoch: mem (CPU python)=44183.41015625MB; mem (CPU total)=44004.046875MB
INFO:root:[   89] Training loss: 0.64383262, Validation loss: 0.62890257, Gradient norm: 3.21840013
INFO:root:At the start of the epoch: mem (CPU python)=44221.51171875MB; mem (CPU total)=44042.38671875MB
INFO:root:[   90] Training loss: 0.64384288, Validation loss: 0.62835967, Gradient norm: 3.30066778
INFO:root:At the start of the epoch: mem (CPU python)=44259.61328125MB; mem (CPU total)=44079.5390625MB
INFO:root:[   91] Training loss: 0.64369827, Validation loss: 0.62858527, Gradient norm: 3.27297587
INFO:root:At the start of the epoch: mem (CPU python)=44297.703125MB; mem (CPU total)=44118.8359375MB
INFO:root:[   92] Training loss: 0.64347756, Validation loss: 0.62793098, Gradient norm: 3.30557508
INFO:root:At the start of the epoch: mem (CPU python)=44335.7734375MB; mem (CPU total)=44156.7109375MB
INFO:root:[   93] Training loss: 0.64335498, Validation loss: 0.62882850, Gradient norm: 3.50628048
INFO:root:At the start of the epoch: mem (CPU python)=44373.890625MB; mem (CPU total)=44196.38671875MB
INFO:root:[   94] Training loss: 0.64344209, Validation loss: 0.62791524, Gradient norm: 3.38710842
INFO:root:At the start of the epoch: mem (CPU python)=44411.8828125MB; mem (CPU total)=44234.58984375MB
INFO:root:[   95] Training loss: 0.64337181, Validation loss: 0.62842854, Gradient norm: 3.50974801
INFO:root:At the start of the epoch: mem (CPU python)=44450.078125MB; mem (CPU total)=44273.125MB
INFO:root:[   96] Training loss: 0.64338437, Validation loss: 0.62872980, Gradient norm: 3.66926427
INFO:root:At the start of the epoch: mem (CPU python)=44488.1796875MB; mem (CPU total)=44310.9765625MB
INFO:root:[   97] Training loss: 0.64316076, Validation loss: 0.62854963, Gradient norm: 3.67641134
INFO:root:At the start of the epoch: mem (CPU python)=44526.27734375MB; mem (CPU total)=44349.109375MB
INFO:root:[   98] Training loss: 0.64343783, Validation loss: 0.62968644, Gradient norm: 3.74891895
INFO:root:At the start of the epoch: mem (CPU python)=44564.3125MB; mem (CPU total)=44387.484375MB
INFO:root:[   99] Training loss: 0.64336355, Validation loss: 0.62906799, Gradient norm: 3.83415640
INFO:root:At the start of the epoch: mem (CPU python)=44602.39453125MB; mem (CPU total)=44425.625MB
INFO:root:[  100] Training loss: 0.64331509, Validation loss: 0.62889465, Gradient norm: 3.83582462
INFO:root:At the start of the epoch: mem (CPU python)=44640.5078125MB; mem (CPU total)=44463.875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  101] Training loss: 0.64317761, Validation loss: 0.62768456, Gradient norm: 3.42041976
INFO:root:At the start of the epoch: mem (CPU python)=44678.59375MB; mem (CPU total)=44501.49609375MB
INFO:root:[  102] Training loss: 0.64185948, Validation loss: 0.62549004, Gradient norm: 2.36562086
INFO:root:At the start of the epoch: mem (CPU python)=44716.68359375MB; mem (CPU total)=44538.6640625MB
INFO:root:[  103] Training loss: 0.64184981, Validation loss: 0.62681734, Gradient norm: 2.57538776
INFO:root:At the start of the epoch: mem (CPU python)=44754.79296875MB; mem (CPU total)=44577.51953125MB
INFO:root:[  104] Training loss: 0.64176204, Validation loss: 0.62759207, Gradient norm: 2.49193821
INFO:root:At the start of the epoch: mem (CPU python)=44792.890625MB; mem (CPU total)=44615.7109375MB
INFO:root:[  105] Training loss: 0.64168352, Validation loss: 0.62742210, Gradient norm: 2.85478773
INFO:root:At the start of the epoch: mem (CPU python)=44830.9453125MB; mem (CPU total)=44653.91796875MB
INFO:root:[  106] Training loss: 0.64159895, Validation loss: 0.62610319, Gradient norm: 2.65722045
INFO:root:At the start of the epoch: mem (CPU python)=44869.06640625MB; mem (CPU total)=44692.67578125MB
INFO:root:[  107] Training loss: 0.64163071, Validation loss: 0.62630361, Gradient norm: 3.22615958
INFO:root:At the start of the epoch: mem (CPU python)=44907.16015625MB; mem (CPU total)=44731.05078125MB
INFO:root:[  108] Training loss: 0.64155548, Validation loss: 0.62638511, Gradient norm: 3.54942104
INFO:root:At the start of the epoch: mem (CPU python)=44945.32421875MB; mem (CPU total)=44769.16796875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  109] Training loss: 0.64156189, Validation loss: 0.62685946, Gradient norm: 3.20158234
INFO:root:At the start of the epoch: mem (CPU python)=44983.3671875MB; mem (CPU total)=44807.37890625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  110] Training loss: 0.64102848, Validation loss: 0.62584802, Gradient norm: 2.22789318
INFO:root:At the start of the epoch: mem (CPU python)=45021.5MB; mem (CPU total)=44846.66015625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  111] Training loss: 0.64084514, Validation loss: 0.62549558, Gradient norm: 1.72401904
INFO:root:At the start of the epoch: mem (CPU python)=45059.6015625MB; mem (CPU total)=44882.94140625MB
INFO:root:EP 111: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=45097.70703125MB; mem (CPU total)=44921.07421875MB
INFO:root:Training the model took 8480.627s.
INFO:root:Emptying the cuda cache took 0.042s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.88429
INFO:root:EnergyScoreTrain: 0.62246
INFO:root:CRPSTrain: 0.55349
INFO:root:Gaussian NLLTrain: 55427140539.73335
INFO:root:CoverageTrain: 0.51114
INFO:root:IntervalWidthTrain: 2.33225
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88969
INFO:root:EnergyScoreValidation: 0.62634
INFO:root:CRPSValidation: 0.55829
INFO:root:Gaussian NLLValidation: 57566697845.19115
INFO:root:CoverageValidation: 0.51078
INFO:root:IntervalWidthValidation: 2.33235
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89129
INFO:root:EnergyScoreTest: 0.62748
INFO:root:CRPSTest: 0.55973
INFO:root:Gaussian NLLTest: 57869683326.97601
INFO:root:CoverageTest: 0.51195
INFO:root:IntervalWidthTest: 2.33771
INFO:root:After validation: mem (CPU python)=45140.91796875MB; mem (CPU total)=45025.96875MB
