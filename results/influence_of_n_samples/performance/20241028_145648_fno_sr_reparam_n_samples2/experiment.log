INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=574.4453125MB; mem (CPU total)=1076.6328125MB
INFO:root:############### Starting experiment with config file ks/fno_sr_reparam_n_samples2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12453.7578125MB; mem (CPU total)=1086.1953125MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=12453.7578125MB; mem (CPU total)=1085.41015625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12453.7578125MB; mem (CPU total)=2286.03125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=2300.0234375MB
INFO:root:[    1] Training loss: 0.72470799, Validation loss: 0.72049884, Gradient norm: 0.01806598
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3500.75390625MB
INFO:root:[    2] Training loss: 0.71966699, Validation loss: 0.71888311, Gradient norm: 0.00527700
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3551.8125MB
INFO:root:[    3] Training loss: 0.71801849, Validation loss: 0.71530220, Gradient norm: 0.00683408
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3589.75MB
INFO:root:[    4] Training loss: 0.71203693, Validation loss: 0.70561804, Gradient norm: 0.01436709
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3627.8125MB
INFO:root:[    5] Training loss: 0.70467976, Validation loss: 0.69855780, Gradient norm: 0.02358656
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3666.22265625MB
INFO:root:[    6] Training loss: 0.69881570, Validation loss: 0.69180104, Gradient norm: 0.03079048
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3704.359375MB
INFO:root:[    7] Training loss: 0.69270435, Validation loss: 0.68490113, Gradient norm: 0.02747653
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3755.28125MB
INFO:root:[    8] Training loss: 0.68714091, Validation loss: 0.67965904, Gradient norm: 0.03185142
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3793.421875MB
INFO:root:[    9] Training loss: 0.68206822, Validation loss: 0.67331147, Gradient norm: 0.02882813
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3831.7265625MB
INFO:root:[   10] Training loss: 0.67755370, Validation loss: 0.66834046, Gradient norm: 0.03162474
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3869.4375MB
INFO:root:[   11] Training loss: 0.67374026, Validation loss: 0.66427071, Gradient norm: 0.03298676
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3907.59375MB
INFO:root:[   12] Training loss: 0.67060188, Validation loss: 0.66143869, Gradient norm: 0.03222027
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3945.9453125MB
INFO:root:[   13] Training loss: 0.66797679, Validation loss: 0.65810426, Gradient norm: 0.03401112
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=3984.09765625MB
INFO:root:[   14] Training loss: 0.66551973, Validation loss: 0.65486328, Gradient norm: 0.03313063
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4022.70703125MB
INFO:root:[   15] Training loss: 0.66346223, Validation loss: 0.65358274, Gradient norm: 0.03669018
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4060.796875MB
INFO:root:[   16] Training loss: 0.66152185, Validation loss: 0.65117321, Gradient norm: 0.03411462
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4098.80078125MB
INFO:root:[   17] Training loss: 0.65989068, Validation loss: 0.64955982, Gradient norm: 0.03317040
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4136.95703125MB
INFO:root:[   18] Training loss: 0.65832774, Validation loss: 0.64868972, Gradient norm: 0.03618934
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4175.140625MB
INFO:root:[   19] Training loss: 0.65698588, Validation loss: 0.64689689, Gradient norm: 0.03807039
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4213.48046875MB
INFO:root:[   20] Training loss: 0.65566192, Validation loss: 0.64567400, Gradient norm: 0.03691468
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4251.57421875MB
INFO:root:[   21] Training loss: 0.65413722, Validation loss: 0.64398368, Gradient norm: 0.03516147
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4289.39453125MB
INFO:root:[   22] Training loss: 0.65310393, Validation loss: 0.64309156, Gradient norm: 0.04160502
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4327.4609375MB
INFO:root:[   23] Training loss: 0.65191408, Validation loss: 0.64152501, Gradient norm: 0.03779495
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4366.0390625MB
INFO:root:[   24] Training loss: 0.65071349, Validation loss: 0.64046907, Gradient norm: 0.04228715
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4404.046875MB
INFO:root:[   25] Training loss: 0.64967523, Validation loss: 0.63874704, Gradient norm: 0.03659914
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4442.296875MB
INFO:root:[   26] Training loss: 0.64876815, Validation loss: 0.63944546, Gradient norm: 0.04236392
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4480.515625MB
INFO:root:[   27] Training loss: 0.64796149, Validation loss: 0.63804927, Gradient norm: 0.04608807
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4518.484375MB
INFO:root:[   28] Training loss: 0.64699963, Validation loss: 0.63698330, Gradient norm: 0.04029270
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4557.05078125MB
INFO:root:[   29] Training loss: 0.64618289, Validation loss: 0.63701953, Gradient norm: 0.04424572
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4595.26171875MB
INFO:root:[   30] Training loss: 0.64513082, Validation loss: 0.63566534, Gradient norm: 0.04138131
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4633.5078125MB
INFO:root:[   31] Training loss: 0.64461557, Validation loss: 0.63418199, Gradient norm: 0.04005167
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4671.62109375MB
INFO:root:[   32] Training loss: 0.64378309, Validation loss: 0.63354359, Gradient norm: 0.04236268
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4709.80859375MB
INFO:root:[   33] Training loss: 0.64320960, Validation loss: 0.63274075, Gradient norm: 0.05230229
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4747.40625MB
INFO:root:[   34] Training loss: 0.64250965, Validation loss: 0.63209131, Gradient norm: 0.04542714
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4785.46875MB
INFO:root:[   35] Training loss: 0.64178888, Validation loss: 0.63207839, Gradient norm: 0.04554565
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4824.02734375MB
INFO:root:[   36] Training loss: 0.64129229, Validation loss: 0.63111621, Gradient norm: 0.04617388
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4862.02734375MB
INFO:root:[   37] Training loss: 0.64076837, Validation loss: 0.63121622, Gradient norm: 0.05720914
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4900.609375MB
INFO:root:[   38] Training loss: 0.64015870, Validation loss: 0.63032475, Gradient norm: 0.04488887
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4938.546875MB
INFO:root:[   39] Training loss: 0.63938384, Validation loss: 0.62952310, Gradient norm: 0.04506944
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=4976.4609375MB
INFO:root:[   40] Training loss: 0.63881710, Validation loss: 0.62951609, Gradient norm: 0.04581819
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5014.65234375MB
INFO:root:[   41] Training loss: 0.63852979, Validation loss: 0.62846340, Gradient norm: 0.05302333
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5053.203125MB
INFO:root:[   42] Training loss: 0.63788847, Validation loss: 0.62785974, Gradient norm: 0.05005773
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5090.96875MB
INFO:root:[   43] Training loss: 0.63725496, Validation loss: 0.62733953, Gradient norm: 0.05171488
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5129.3984375MB
INFO:root:[   44] Training loss: 0.63701863, Validation loss: 0.62719534, Gradient norm: 0.05482039
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5167.0390625MB
INFO:root:[   45] Training loss: 0.63647869, Validation loss: 0.62573138, Gradient norm: 0.04605557
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5205.4375MB
INFO:root:[   46] Training loss: 0.63598094, Validation loss: 0.62576646, Gradient norm: 0.04853664
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5243.5625MB
INFO:root:[   47] Training loss: 0.63559576, Validation loss: 0.62558629, Gradient norm: 0.05174784
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5281.71484375MB
INFO:root:[   48] Training loss: 0.63523267, Validation loss: 0.62566635, Gradient norm: 0.04695519
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5319.875MB
INFO:root:[   49] Training loss: 0.63456881, Validation loss: 0.62491385, Gradient norm: 0.04920359
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5358.03515625MB
INFO:root:[   50] Training loss: 0.63431332, Validation loss: 0.62478212, Gradient norm: 0.05246598
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5396.1953125MB
INFO:root:[   51] Training loss: 0.63403293, Validation loss: 0.62445968, Gradient norm: 0.05095468
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5435.10546875MB
INFO:root:[   52] Training loss: 0.63349263, Validation loss: 0.62385911, Gradient norm: 0.05207788
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5473.12890625MB
INFO:root:[   53] Training loss: 0.63301785, Validation loss: 0.62375904, Gradient norm: 0.05294547
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5511.30859375MB
INFO:root:[   54] Training loss: 0.63277542, Validation loss: 0.62276132, Gradient norm: 0.04883207
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5561.6875MB
INFO:root:[   55] Training loss: 0.63231854, Validation loss: 0.62205656, Gradient norm: 0.05113340
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5600.078125MB
INFO:root:[   56] Training loss: 0.63195780, Validation loss: 0.62152382, Gradient norm: 0.05360479
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5614.65234375MB
INFO:root:[   57] Training loss: 0.63169701, Validation loss: 0.62115241, Gradient norm: 0.05053226
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5652.55078125MB
INFO:root:[   58] Training loss: 0.63122989, Validation loss: 0.62167437, Gradient norm: 0.05082197
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5690.81640625MB
INFO:root:[   59] Training loss: 0.63110528, Validation loss: 0.62048657, Gradient norm: 0.05579882
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5728.51171875MB
INFO:root:[   60] Training loss: 0.63059975, Validation loss: 0.62255403, Gradient norm: 0.05229936
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5779.11328125MB
INFO:root:[   61] Training loss: 0.63020756, Validation loss: 0.62157488, Gradient norm: 0.05161685
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5817.50390625MB
INFO:root:[   62] Training loss: 0.63005682, Validation loss: 0.62063667, Gradient norm: 0.04926337
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5855.1796875MB
INFO:root:[   63] Training loss: 0.62979612, Validation loss: 0.62078709, Gradient norm: 0.06221043
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5893.078125MB
INFO:root:[   64] Training loss: 0.62917652, Validation loss: 0.61981855, Gradient norm: 0.05057173
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5931.21484375MB
INFO:root:[   65] Training loss: 0.62928142, Validation loss: 0.62019902, Gradient norm: 0.05562508
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=5969.359375MB
INFO:root:[   66] Training loss: 0.62893583, Validation loss: 0.62004932, Gradient norm: 0.05486874
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6007.50390625MB
INFO:root:[   67] Training loss: 0.62835728, Validation loss: 0.62050549, Gradient norm: 0.05304753
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6045.6484375MB
INFO:root:[   68] Training loss: 0.62818396, Validation loss: 0.61893247, Gradient norm: 0.05035670
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6083.78125MB
INFO:root:[   69] Training loss: 0.62783935, Validation loss: 0.61808127, Gradient norm: 0.05165745
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6134.44921875MB
INFO:root:[   70] Training loss: 0.62770257, Validation loss: 0.61834167, Gradient norm: 0.05424402
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6172.83984375MB
INFO:root:[   71] Training loss: 0.62737551, Validation loss: 0.61816417, Gradient norm: 0.05272509
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6173.29296875MB
INFO:root:[   72] Training loss: 0.62721245, Validation loss: 0.61778474, Gradient norm: 0.05303523
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6223.8671875MB
INFO:root:[   73] Training loss: 0.62709796, Validation loss: 0.61826998, Gradient norm: 0.05633747
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6262.2578125MB
INFO:root:[   74] Training loss: 0.62666706, Validation loss: 0.61777429, Gradient norm: 0.05359435
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6300.15234375MB
INFO:root:[   75] Training loss: 0.62641350, Validation loss: 0.61710214, Gradient norm: 0.05590495
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6338.05078125MB
INFO:root:[   76] Training loss: 0.62605588, Validation loss: 0.61677020, Gradient norm: 0.05943211
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6388.93359375MB
INFO:root:[   77] Training loss: 0.62583243, Validation loss: 0.61855488, Gradient norm: 0.05142948
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6426.5MB
INFO:root:[   78] Training loss: 0.62570681, Validation loss: 0.61658778, Gradient norm: 0.05633705
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6464.8828125MB
INFO:root:[   79] Training loss: 0.62548110, Validation loss: 0.61689500, Gradient norm: 0.05734329
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6503.02734375MB
INFO:root:[   80] Training loss: 0.62517351, Validation loss: 0.61631684, Gradient norm: 0.06058867
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6541.171875MB
INFO:root:[   81] Training loss: 0.62487873, Validation loss: 0.61744506, Gradient norm: 0.06155631
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6579.5625MB
INFO:root:[   82] Training loss: 0.62470118, Validation loss: 0.61660242, Gradient norm: 0.05622795
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6617.4609375MB
INFO:root:[   83] Training loss: 0.62444885, Validation loss: 0.61616679, Gradient norm: 0.05740226
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6655.60546875MB
INFO:root:[   84] Training loss: 0.62427625, Validation loss: 0.61543093, Gradient norm: 0.05878193
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6694.47265625MB
INFO:root:[   85] Training loss: 0.62428962, Validation loss: 0.61591175, Gradient norm: 0.06154580
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6732.61328125MB
INFO:root:[   86] Training loss: 0.62386529, Validation loss: 0.61615643, Gradient norm: 0.05772538
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6770.7578125MB
INFO:root:[   87] Training loss: 0.62363315, Validation loss: 0.61482099, Gradient norm: 0.05634432
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6808.93359375MB
INFO:root:[   88] Training loss: 0.62351104, Validation loss: 0.61462649, Gradient norm: 0.05997791
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6846.83203125MB
INFO:root:[   89] Training loss: 0.62340311, Validation loss: 0.61445284, Gradient norm: 0.05535787
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6884.97265625MB
INFO:root:[   90] Training loss: 0.62292644, Validation loss: 0.61379258, Gradient norm: 0.05475818
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6923.1171875MB
INFO:root:[   91] Training loss: 0.62273936, Validation loss: 0.61350726, Gradient norm: 0.05904871
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=6962.16796875MB
INFO:root:[   92] Training loss: 0.62277738, Validation loss: 0.61376145, Gradient norm: 0.06573364
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7000.328125MB
INFO:root:[   93] Training loss: 0.62264232, Validation loss: 0.61559039, Gradient norm: 0.06110793
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7038.48046875MB
INFO:root:[   94] Training loss: 0.62246657, Validation loss: 0.61354581, Gradient norm: 0.06148453
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7076.63671875MB
INFO:root:[   95] Training loss: 0.62203148, Validation loss: 0.61446503, Gradient norm: 0.06020315
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7115.04296875MB
INFO:root:[   96] Training loss: 0.62207849, Validation loss: 0.61400243, Gradient norm: 0.06051026
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7153.203125MB
INFO:root:[   97] Training loss: 0.62192958, Validation loss: 0.61442881, Gradient norm: 0.05932262
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7191.109375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   98] Training loss: 0.62168832, Validation loss: 0.61306553, Gradient norm: 0.06199137
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7229.30078125MB
INFO:root:[   99] Training loss: 0.62053247, Validation loss: 0.61263218, Gradient norm: 0.05499319
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7267.19921875MB
INFO:root:[  100] Training loss: 0.62053731, Validation loss: 0.61191971, Gradient norm: 0.06005054
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7305.375MB
INFO:root:[  101] Training loss: 0.62015802, Validation loss: 0.61232477, Gradient norm: 0.05312602
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7343.54296875MB
INFO:root:[  102] Training loss: 0.62015985, Validation loss: 0.61263262, Gradient norm: 0.05533441
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7382.671875MB
INFO:root:[  103] Training loss: 0.61993676, Validation loss: 0.61192432, Gradient norm: 0.05457523
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7420.33984375MB
INFO:root:[  104] Training loss: 0.62007062, Validation loss: 0.61200660, Gradient norm: 0.05521728
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7458.4765625MB
INFO:root:[  105] Training loss: 0.61988804, Validation loss: 0.61222887, Gradient norm: 0.05548167
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7496.62109375MB
INFO:root:[  106] Training loss: 0.61993385, Validation loss: 0.61301335, Gradient norm: 0.05556623
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7533.84765625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  107] Training loss: 0.61975503, Validation loss: 0.61255875, Gradient norm: 0.05670724
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7571.70703125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  108] Training loss: 0.61926853, Validation loss: 0.61145030, Gradient norm: 0.05162314
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7610.01953125MB
INFO:root:[  109] Training loss: 0.61901461, Validation loss: 0.61096853, Gradient norm: 0.04789685
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7648.1640625MB
INFO:root:[  110] Training loss: 0.61881456, Validation loss: 0.61125369, Gradient norm: 0.04909390
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7686.5859375MB
INFO:root:[  111] Training loss: 0.61881273, Validation loss: 0.61180927, Gradient norm: 0.04786767
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7724.73046875MB
INFO:root:[  112] Training loss: 0.61862788, Validation loss: 0.61107340, Gradient norm: 0.04820590
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7762.62890625MB
INFO:root:[  113] Training loss: 0.61864647, Validation loss: 0.61082604, Gradient norm: 0.04763960
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7801.05078125MB
INFO:root:[  114] Training loss: 0.61866003, Validation loss: 0.61166216, Gradient norm: 0.04855944
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7839.17578125MB
INFO:root:[  115] Training loss: 0.61862550, Validation loss: 0.61138784, Gradient norm: 0.04585708
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7877.56640625MB
INFO:root:[  116] Training loss: 0.61870704, Validation loss: 0.61138813, Gradient norm: 0.05002231
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7915.6796875MB
INFO:root:[  117] Training loss: 0.61871094, Validation loss: 0.61144843, Gradient norm: 0.04880561
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7953.5625MB
INFO:root:[  118] Training loss: 0.61848837, Validation loss: 0.61110978, Gradient norm: 0.04799813
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=7991.70703125MB
INFO:root:[  119] Training loss: 0.61849280, Validation loss: 0.61081134, Gradient norm: 0.04947119
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8029.8515625MB
INFO:root:[  120] Training loss: 0.61865219, Validation loss: 0.61181884, Gradient norm: 0.04930864
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8067.13671875MB
INFO:root:[  121] Training loss: 0.61845836, Validation loss: 0.61078087, Gradient norm: 0.04790647
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8105.3046875MB
INFO:root:[  122] Training loss: 0.61854481, Validation loss: 0.61102811, Gradient norm: 0.04882032
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8143.44921875MB
INFO:root:[  123] Training loss: 0.61845807, Validation loss: 0.61054735, Gradient norm: 0.04832356
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8181.59375MB
INFO:root:[  124] Training loss: 0.61864769, Validation loss: 0.61108656, Gradient norm: 0.05000247
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8219.73828125MB
INFO:root:[  125] Training loss: 0.61836271, Validation loss: 0.61115470, Gradient norm: 0.04928451
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8258.12890625MB
INFO:root:[  126] Training loss: 0.61834386, Validation loss: 0.61111504, Gradient norm: 0.05032043
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8296.2734375MB
INFO:root:[  127] Training loss: 0.61851411, Validation loss: 0.61058742, Gradient norm: 0.04806125
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8334.41796875MB
INFO:root:[  128] Training loss: 0.61851588, Validation loss: 0.61119286, Gradient norm: 0.04962443
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8372.53125MB
INFO:root:[  129] Training loss: 0.61829345, Validation loss: 0.61112374, Gradient norm: 0.04915846
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8410.66015625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  130] Training loss: 0.61825593, Validation loss: 0.61103247, Gradient norm: 0.04849206
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8448.8046875MB
INFO:root:[  131] Training loss: 0.61812138, Validation loss: 0.61079685, Gradient norm: 0.04601126
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8486.6328125MB
INFO:root:[  132] Training loss: 0.61807937, Validation loss: 0.61092303, Gradient norm: 0.04701425
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8524.77734375MB
INFO:root:[  133] Training loss: 0.61819410, Validation loss: 0.61043774, Gradient norm: 0.04690542
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8575.4140625MB
INFO:root:[  134] Training loss: 0.61795534, Validation loss: 0.61088035, Gradient norm: 0.04735285
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8588.5078125MB
INFO:root:[  135] Training loss: 0.61809366, Validation loss: 0.61053693, Gradient norm: 0.04674181
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8627.71484375MB
INFO:root:[  136] Training loss: 0.61811104, Validation loss: 0.61058551, Gradient norm: 0.04836510
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8666.12109375MB
INFO:root:[  137] Training loss: 0.61807836, Validation loss: 0.61047476, Gradient norm: 0.04859860
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8704.52734375MB
INFO:root:[  138] Training loss: 0.61782035, Validation loss: 0.61105792, Gradient norm: 0.04776298
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8742.265625MB
INFO:root:[  139] Training loss: 0.61808532, Validation loss: 0.61028460, Gradient norm: 0.04848515
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8781.12890625MB
INFO:root:[  140] Training loss: 0.61799830, Validation loss: 0.61028851, Gradient norm: 0.04777182
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8819.52734375MB
INFO:root:[  141] Training loss: 0.61808624, Validation loss: 0.61071186, Gradient norm: 0.04823704
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8857.2265625MB
INFO:root:[  142] Training loss: 0.61790831, Validation loss: 0.61099566, Gradient norm: 0.04777140
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8895.6328125MB
INFO:root:[  143] Training loss: 0.61810911, Validation loss: 0.61054131, Gradient norm: 0.04673307
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8946.05078125MB
INFO:root:[  144] Training loss: 0.61817084, Validation loss: 0.61001291, Gradient norm: 0.04874206
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=8983.98046875MB
INFO:root:[  145] Training loss: 0.61795114, Validation loss: 0.61110136, Gradient norm: 0.04953051
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9022.296875MB
INFO:root:[  146] Training loss: 0.61781986, Validation loss: 0.61091088, Gradient norm: 0.04890454
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9060.8203125MB
INFO:root:[  147] Training loss: 0.61791569, Validation loss: 0.61066967, Gradient norm: 0.04637670
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9098.58984375MB
INFO:root:[  148] Training loss: 0.61793088, Validation loss: 0.61051191, Gradient norm: 0.05069273
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9136.99609375MB
INFO:root:[  149] Training loss: 0.61804545, Validation loss: 0.61020507, Gradient norm: 0.04703663
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9175.40234375MB
INFO:root:[  150] Training loss: 0.61777795, Validation loss: 0.61086530, Gradient norm: 0.04779900
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9213.3203125MB
INFO:root:[  151] Training loss: 0.61802214, Validation loss: 0.61024021, Gradient norm: 0.04927999
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9251.44921875MB
INFO:root:[  152] Training loss: 0.61781041, Validation loss: 0.61082088, Gradient norm: 0.04835948
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9289.85546875MB
INFO:root:[  153] Training loss: 0.61796264, Validation loss: 0.61058289, Gradient norm: 0.04771339
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9328.01953125MB
INFO:root:EP 153: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12453.7578125MB; mem (CPU total)=9365.9296875MB
INFO:root:Training the model took 6243.193s.
INFO:root:Emptying the cuda cache took 0.025s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85284
INFO:root:EnergyScoreTrain: 0.60033
INFO:root:CRPSTrain: 0.46721
INFO:root:Gaussian NLLTrain: 1.20395
INFO:root:CoverageTrain: 0.94833
INFO:root:IntervalWidthTrain: 3.27579
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86752
INFO:root:EnergyScoreValidation: 0.6106
INFO:root:CRPSValidation: 0.47601
INFO:root:Gaussian NLLValidation: 1.22452
INFO:root:CoverageValidation: 0.94324
INFO:root:IntervalWidthValidation: 3.27749
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86892
INFO:root:EnergyScoreTest: 0.61157
INFO:root:CRPSTest: 0.47695
INFO:root:Gaussian NLLTest: 1.22664
INFO:root:CoverageTest: 0.94284
INFO:root:IntervalWidthTest: 3.27834
INFO:root:After validation: mem (CPU python)=12453.7578125MB; mem (CPU total)=9374.36328125MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=12453.7578125MB; mem (CPU total)=9374.36328125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12453.7578125MB; mem (CPU total)=9374.36328125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9374.3671875MB
INFO:root:[    1] Training loss: 0.72522207, Validation loss: 0.72134999, Gradient norm: 0.02272062
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9449.05859375MB
INFO:root:[    2] Training loss: 0.71971985, Validation loss: 0.71818863, Gradient norm: 0.00558650
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9499.2734375MB
INFO:root:[    3] Training loss: 0.71742499, Validation loss: 0.71349484, Gradient norm: 0.00820269
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9537.41015625MB
INFO:root:[    4] Training loss: 0.71039411, Validation loss: 0.70404979, Gradient norm: 0.01981696
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9575.79296875MB
INFO:root:[    5] Training loss: 0.70379504, Validation loss: 0.69811980, Gradient norm: 0.02490861
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9613.90625MB
INFO:root:[    6] Training loss: 0.69872365, Validation loss: 0.69302677, Gradient norm: 0.02555917
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9652.05078125MB
INFO:root:[    7] Training loss: 0.69436619, Validation loss: 0.68700193, Gradient norm: 0.02937295
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9690.44140625MB
INFO:root:[    8] Training loss: 0.69035025, Validation loss: 0.68352922, Gradient norm: 0.03006224
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9728.33984375MB
INFO:root:[    9] Training loss: 0.68709169, Validation loss: 0.68009314, Gradient norm: 0.03189815
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9766.33203125MB
INFO:root:[   10] Training loss: 0.68395343, Validation loss: 0.67675616, Gradient norm: 0.03112885
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9804.734375MB
INFO:root:[   11] Training loss: 0.68094739, Validation loss: 0.67239762, Gradient norm: 0.02989026
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9842.63671875MB
INFO:root:[   12] Training loss: 0.67838999, Validation loss: 0.67050429, Gradient norm: 0.03077232
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9880.90625MB
INFO:root:[   13] Training loss: 0.67584884, Validation loss: 0.66774505, Gradient norm: 0.03321280
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9918.8203125MB
INFO:root:[   14] Training loss: 0.67393721, Validation loss: 0.66525798, Gradient norm: 0.03475962
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9956.9765625MB
INFO:root:[   15] Training loss: 0.67190848, Validation loss: 0.66301136, Gradient norm: 0.03566718
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=9995.3828125MB
INFO:root:[   16] Training loss: 0.66995999, Validation loss: 0.66195866, Gradient norm: 0.03296013
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10033.41015625MB
INFO:root:[   17] Training loss: 0.66833251, Validation loss: 0.65904442, Gradient norm: 0.03764789
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10071.56640625MB
INFO:root:[   18] Training loss: 0.66674844, Validation loss: 0.65701484, Gradient norm: 0.03915432
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10109.71875MB
INFO:root:[   19] Training loss: 0.66501291, Validation loss: 0.65571211, Gradient norm: 0.03780329
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10147.8828125MB
INFO:root:[   20] Training loss: 0.66347372, Validation loss: 0.65389164, Gradient norm: 0.03694165
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10198.75MB
INFO:root:[   21] Training loss: 0.66214482, Validation loss: 0.65249844, Gradient norm: 0.04107375
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10236.91015625MB
INFO:root:[   22] Training loss: 0.66098063, Validation loss: 0.65090165, Gradient norm: 0.04498640
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10275.10546875MB
INFO:root:[   23] Training loss: 0.65956707, Validation loss: 0.64991398, Gradient norm: 0.03977951
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10313.05078125MB
INFO:root:[   24] Training loss: 0.65810653, Validation loss: 0.64856545, Gradient norm: 0.04022631
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10351.453125MB
INFO:root:[   25] Training loss: 0.65702888, Validation loss: 0.64704217, Gradient norm: 0.04125686
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10364.4140625MB
INFO:root:[   26] Training loss: 0.65571503, Validation loss: 0.64569588, Gradient norm: 0.04303140
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10402.328125MB
INFO:root:[   27] Training loss: 0.65480513, Validation loss: 0.64470343, Gradient norm: 0.04851761
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10440.73828125MB
INFO:root:[   28] Training loss: 0.65345343, Validation loss: 0.64299275, Gradient norm: 0.04188655
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10503.8515625MB
INFO:root:[   29] Training loss: 0.65289705, Validation loss: 0.64206309, Gradient norm: 0.05027789
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10541.984375MB
INFO:root:[   30] Training loss: 0.65136690, Validation loss: 0.64164857, Gradient norm: 0.04371023
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10567.78515625MB
INFO:root:[   31] Training loss: 0.65055789, Validation loss: 0.64137316, Gradient norm: 0.04664082
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10605.6015625MB
INFO:root:[   32] Training loss: 0.64986350, Validation loss: 0.63942019, Gradient norm: 0.04864088
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10643.74609375MB
INFO:root:[   33] Training loss: 0.64890901, Validation loss: 0.63930853, Gradient norm: 0.05156800
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10681.859375MB
INFO:root:[   34] Training loss: 0.64805731, Validation loss: 0.63830480, Gradient norm: 0.04868278
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10720.25MB
INFO:root:[   35] Training loss: 0.64747529, Validation loss: 0.63626126, Gradient norm: 0.05226135
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10770.82421875MB
INFO:root:[   36] Training loss: 0.64655891, Validation loss: 0.63599483, Gradient norm: 0.04701283
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10796.5390625MB
INFO:root:[   37] Training loss: 0.64579229, Validation loss: 0.63538802, Gradient norm: 0.04727445
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10834.71484375MB
INFO:root:[   38] Training loss: 0.64526245, Validation loss: 0.63452243, Gradient norm: 0.04535077
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10872.61328125MB
INFO:root:[   39] Training loss: 0.64437014, Validation loss: 0.63406475, Gradient norm: 0.04764917
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10910.7578125MB
INFO:root:[   40] Training loss: 0.64408293, Validation loss: 0.63383497, Gradient norm: 0.05144138
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10949.1484375MB
INFO:root:[   41] Training loss: 0.64328324, Validation loss: 0.63279971, Gradient norm: 0.04873664
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=10987.28515625MB
INFO:root:[   42] Training loss: 0.64275428, Validation loss: 0.63237841, Gradient norm: 0.05286963
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11025.69921875MB
INFO:root:[   43] Training loss: 0.64218846, Validation loss: 0.63212377, Gradient norm: 0.05123143
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11063.4609375MB
INFO:root:[   44] Training loss: 0.64160904, Validation loss: 0.63104562, Gradient norm: 0.04735248
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11101.94921875MB
INFO:root:[   45] Training loss: 0.64101374, Validation loss: 0.63090975, Gradient norm: 0.05091033
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11140.125MB
INFO:root:[   46] Training loss: 0.64076995, Validation loss: 0.63141893, Gradient norm: 0.05508879
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11190.75MB
INFO:root:[   47] Training loss: 0.64016600, Validation loss: 0.62961860, Gradient norm: 0.05439751
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11216.203125MB
INFO:root:[   48] Training loss: 0.63948370, Validation loss: 0.62961532, Gradient norm: 0.05569875
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11254.12109375MB
INFO:root:[   49] Training loss: 0.63913874, Validation loss: 0.62935922, Gradient norm: 0.04808664
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11292.52734375MB
INFO:root:[   50] Training loss: 0.63871355, Validation loss: 0.62981459, Gradient norm: 0.05140953
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11330.6484375MB
INFO:root:[   51] Training loss: 0.63809110, Validation loss: 0.62791829, Gradient norm: 0.05831528
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11368.5625MB
INFO:root:[   52] Training loss: 0.63786697, Validation loss: 0.62761959, Gradient norm: 0.05228670
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11407.09375MB
INFO:root:[   53] Training loss: 0.63754705, Validation loss: 0.62678472, Gradient norm: 0.05538480
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11445.0390625MB
INFO:root:[   54] Training loss: 0.63711115, Validation loss: 0.62769539, Gradient norm: 0.05672375
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11483.44921875MB
INFO:root:[   55] Training loss: 0.63651811, Validation loss: 0.62588363, Gradient norm: 0.05571092
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11522.375MB
INFO:root:[   56] Training loss: 0.63603647, Validation loss: 0.62642131, Gradient norm: 0.05262407
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11560.75390625MB
INFO:root:[   57] Training loss: 0.63564702, Validation loss: 0.62615566, Gradient norm: 0.05505849
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11611.375MB
INFO:root:[   58] Training loss: 0.63538113, Validation loss: 0.62537851, Gradient norm: 0.05398364
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11637.046875MB
INFO:root:[   59] Training loss: 0.63499986, Validation loss: 0.62599290, Gradient norm: 0.05882833
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11675.171875MB
INFO:root:[   60] Training loss: 0.63464814, Validation loss: 0.62519532, Gradient norm: 0.05858919
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11676.37109375MB
INFO:root:[   61] Training loss: 0.63426919, Validation loss: 0.62591483, Gradient norm: 0.05599279
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11726.72265625MB
INFO:root:[   62] Training loss: 0.63384168, Validation loss: 0.62427558, Gradient norm: 0.05342612
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11789.99609375MB
INFO:root:[   63] Training loss: 0.63384533, Validation loss: 0.62379648, Gradient norm: 0.05593033
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11841.4140625MB
INFO:root:[   64] Training loss: 0.63323208, Validation loss: 0.62365463, Gradient norm: 0.05651717
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11892.05078125MB
INFO:root:[   65] Training loss: 0.63286710, Validation loss: 0.62310523, Gradient norm: 0.05255000
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11917.48828125MB
INFO:root:[   66] Training loss: 0.63265287, Validation loss: 0.62367897, Gradient norm: 0.06007957
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11955.87890625MB
INFO:root:[   67] Training loss: 0.63246926, Validation loss: 0.62198592, Gradient norm: 0.05698103
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=11993.9921875MB
INFO:root:[   68] Training loss: 0.63188608, Validation loss: 0.62231193, Gradient norm: 0.05717877
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12006.4375MB
INFO:root:[   69] Training loss: 0.63164262, Validation loss: 0.62219491, Gradient norm: 0.05378645
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12044.3359375MB
INFO:root:[   70] Training loss: 0.63141580, Validation loss: 0.62250303, Gradient norm: 0.05413344
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12082.48046875MB
INFO:root:[   71] Training loss: 0.63110331, Validation loss: 0.62194676, Gradient norm: 0.05636206
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12120.8984375MB
INFO:root:[   72] Training loss: 0.63091379, Validation loss: 0.62075693, Gradient norm: 0.05741666
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12171.62890625MB
INFO:root:[   73] Training loss: 0.63073145, Validation loss: 0.62132016, Gradient norm: 0.05886557
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12209.7734375MB
INFO:root:[   74] Training loss: 0.63036432, Validation loss: 0.62364207, Gradient norm: 0.05576443
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12260.65625MB
INFO:root:[   75] Training loss: 0.63012965, Validation loss: 0.62048724, Gradient norm: 0.06007018
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12273.625MB
INFO:root:[   76] Training loss: 0.62991457, Validation loss: 0.62064932, Gradient norm: 0.06212444
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12311.76953125MB
INFO:root:[   77] Training loss: 0.62964588, Validation loss: 0.62055948, Gradient norm: 0.05951062
INFO:root:At the start of the epoch: mem (CPU python)=12453.7578125MB; mem (CPU total)=12362.68359375MB
INFO:root:[   78] Training loss: 0.62916104, Validation loss: 0.62088596, Gradient norm: 0.05315325
INFO:root:At the start of the epoch: mem (CPU python)=12487.34765625MB; mem (CPU total)=12400.58203125MB
INFO:root:[   79] Training loss: 0.62905699, Validation loss: 0.61960330, Gradient norm: 0.05532840
INFO:root:At the start of the epoch: mem (CPU python)=12525.44921875MB; mem (CPU total)=12438.6953125MB
INFO:root:[   80] Training loss: 0.62890329, Validation loss: 0.61921068, Gradient norm: 0.06348043
INFO:root:At the start of the epoch: mem (CPU python)=12563.54296875MB; mem (CPU total)=12477.1015625MB
INFO:root:[   81] Training loss: 0.62869719, Validation loss: 0.62197358, Gradient norm: 0.05896120
INFO:root:At the start of the epoch: mem (CPU python)=12601.640625MB; mem (CPU total)=12515.015625MB
INFO:root:[   82] Training loss: 0.62859682, Validation loss: 0.62128061, Gradient norm: 0.06111566
INFO:root:At the start of the epoch: mem (CPU python)=12639.734375MB; mem (CPU total)=12553.12890625MB
INFO:root:[   83] Training loss: 0.62830462, Validation loss: 0.61922556, Gradient norm: 0.05735030
INFO:root:At the start of the epoch: mem (CPU python)=12690.33203125MB; mem (CPU total)=12603.734375MB
INFO:root:[   84] Training loss: 0.62791622, Validation loss: 0.61813602, Gradient norm: 0.06007139
INFO:root:At the start of the epoch: mem (CPU python)=12691.1640625MB; mem (CPU total)=12604.43359375MB
INFO:root:[   85] Training loss: 0.62755757, Validation loss: 0.61869713, Gradient norm: 0.05896191
INFO:root:At the start of the epoch: mem (CPU python)=12754.01953125MB; mem (CPU total)=12667.80859375MB
INFO:root:[   86] Training loss: 0.62750110, Validation loss: 0.61849443, Gradient norm: 0.05837984
INFO:root:At the start of the epoch: mem (CPU python)=12792.12109375MB; mem (CPU total)=12705.921875MB
INFO:root:[   87] Training loss: 0.62740730, Validation loss: 0.61792598, Gradient norm: 0.06280906
INFO:root:At the start of the epoch: mem (CPU python)=12842.71484375MB; mem (CPU total)=12756.03515625MB
INFO:root:[   88] Training loss: 0.62710273, Validation loss: 0.61833426, Gradient norm: 0.05809984
INFO:root:At the start of the epoch: mem (CPU python)=12855.8359375MB; mem (CPU total)=12769.2265625MB
INFO:root:[   89] Training loss: 0.62677092, Validation loss: 0.61875080, Gradient norm: 0.05694383
INFO:root:At the start of the epoch: mem (CPU python)=12906.40234375MB; mem (CPU total)=12819.6171875MB
INFO:root:[   90] Training loss: 0.62677624, Validation loss: 0.61822013, Gradient norm: 0.05742116
INFO:root:At the start of the epoch: mem (CPU python)=12944.5MB; mem (CPU total)=12857.75390625MB
INFO:root:[   91] Training loss: 0.62630809, Validation loss: 0.61887944, Gradient norm: 0.06140617
INFO:root:At the start of the epoch: mem (CPU python)=12982.59375MB; mem (CPU total)=12895.89453125MB
INFO:root:[   92] Training loss: 0.62604375, Validation loss: 0.61678450, Gradient norm: 0.05795642
INFO:root:At the start of the epoch: mem (CPU python)=13020.6875MB; mem (CPU total)=12934.0859375MB
INFO:root:[   93] Training loss: 0.62575565, Validation loss: 0.61717415, Gradient norm: 0.05887345
INFO:root:At the start of the epoch: mem (CPU python)=13058.78515625MB; mem (CPU total)=12972.1328125MB
INFO:root:[   94] Training loss: 0.62577373, Validation loss: 0.61859673, Gradient norm: 0.06337253
INFO:root:At the start of the epoch: mem (CPU python)=13096.87890625MB; mem (CPU total)=13010.23046875MB
INFO:root:[   95] Training loss: 0.62576693, Validation loss: 0.61682175, Gradient norm: 0.05818544
INFO:root:At the start of the epoch: mem (CPU python)=13147.4765625MB; mem (CPU total)=13062.16015625MB
INFO:root:[   96] Training loss: 0.62549381, Validation loss: 0.61687113, Gradient norm: 0.06069373
INFO:root:At the start of the epoch: mem (CPU python)=13185.5703125MB; mem (CPU total)=13100.12890625MB
INFO:root:[   97] Training loss: 0.62516423, Validation loss: 0.61709337, Gradient norm: 0.05981094
INFO:root:At the start of the epoch: mem (CPU python)=13198.6953125MB; mem (CPU total)=13113.2421875MB
INFO:root:[   98] Training loss: 0.62487982, Validation loss: 0.61646735, Gradient norm: 0.05747631
INFO:root:At the start of the epoch: mem (CPU python)=13236.7890625MB; mem (CPU total)=13151.375MB
INFO:root:[   99] Training loss: 0.62485240, Validation loss: 0.61750385, Gradient norm: 0.05614604
INFO:root:At the start of the epoch: mem (CPU python)=13299.85546875MB; mem (CPU total)=13214.73828125MB
INFO:root:[  100] Training loss: 0.62480653, Validation loss: 0.61701126, Gradient norm: 0.06475154
INFO:root:At the start of the epoch: mem (CPU python)=13337.953125MB; mem (CPU total)=13252.65625MB
INFO:root:[  101] Training loss: 0.62447502, Validation loss: 0.61772579, Gradient norm: 0.06141234
INFO:root:At the start of the epoch: mem (CPU python)=13376.05859375MB; mem (CPU total)=13290.54296875MB
INFO:root:[  102] Training loss: 0.62435385, Validation loss: 0.61628900, Gradient norm: 0.05703054
INFO:root:At the start of the epoch: mem (CPU python)=13389.18359375MB; mem (CPU total)=13304.015625MB
INFO:root:[  103] Training loss: 0.62409776, Validation loss: 0.61635708, Gradient norm: 0.05991734
INFO:root:At the start of the epoch: mem (CPU python)=13439.75390625MB; mem (CPU total)=13354.91796875MB
INFO:root:[  104] Training loss: 0.62392372, Validation loss: 0.61693239, Gradient norm: 0.05759025
INFO:root:At the start of the epoch: mem (CPU python)=13477.84765625MB; mem (CPU total)=13392.8359375MB
INFO:root:[  105] Training loss: 0.62366578, Validation loss: 0.61503861, Gradient norm: 0.05569785
INFO:root:At the start of the epoch: mem (CPU python)=13528.44140625MB; mem (CPU total)=13443.69140625MB
INFO:root:[  106] Training loss: 0.62382730, Validation loss: 0.61573614, Gradient norm: 0.06621369
INFO:root:At the start of the epoch: mem (CPU python)=13566.53515625MB; mem (CPU total)=13481.8671875MB
INFO:root:[  107] Training loss: 0.62329965, Validation loss: 0.61486188, Gradient norm: 0.06383274
INFO:root:At the start of the epoch: mem (CPU python)=13566.76171875MB; mem (CPU total)=13469.91015625MB
INFO:root:[  108] Training loss: 0.62343169, Validation loss: 0.61568041, Gradient norm: 0.06214283
INFO:root:At the start of the epoch: mem (CPU python)=13630.2265625MB; mem (CPU total)=13545.2734375MB
INFO:root:[  109] Training loss: 0.62306049, Validation loss: 0.61537207, Gradient norm: 0.06500055
INFO:root:At the start of the epoch: mem (CPU python)=13668.3203125MB; mem (CPU total)=13583.68359375MB
INFO:root:[  110] Training loss: 0.62300326, Validation loss: 0.61459893, Gradient norm: 0.06306285
INFO:root:At the start of the epoch: mem (CPU python)=13706.41796875MB; mem (CPU total)=13621.87890625MB
INFO:root:[  111] Training loss: 0.62273544, Validation loss: 0.61497706, Gradient norm: 0.06074274
INFO:root:At the start of the epoch: mem (CPU python)=13744.515625MB; mem (CPU total)=13659.7890625MB
INFO:root:[  112] Training loss: 0.62260963, Validation loss: 0.61449441, Gradient norm: 0.05802232
INFO:root:At the start of the epoch: mem (CPU python)=13782.609375MB; mem (CPU total)=13698.16796875MB
INFO:root:[  113] Training loss: 0.62250416, Validation loss: 0.61504068, Gradient norm: 0.05948999
INFO:root:At the start of the epoch: mem (CPU python)=13820.69921875MB; mem (CPU total)=13736.36328125MB
INFO:root:[  114] Training loss: 0.62235818, Validation loss: 0.61471214, Gradient norm: 0.05826339
INFO:root:At the start of the epoch: mem (CPU python)=13858.80078125MB; mem (CPU total)=13774.52734375MB
INFO:root:[  115] Training loss: 0.62223427, Validation loss: 0.61442620, Gradient norm: 0.06039749
INFO:root:At the start of the epoch: mem (CPU python)=13896.89453125MB; mem (CPU total)=13812.69140625MB
INFO:root:[  116] Training loss: 0.62192158, Validation loss: 0.61514432, Gradient norm: 0.06602460
INFO:root:At the start of the epoch: mem (CPU python)=13947.48828125MB; mem (CPU total)=13863.3125MB
INFO:root:[  117] Training loss: 0.62171864, Validation loss: 0.61355613, Gradient norm: 0.06025388
INFO:root:At the start of the epoch: mem (CPU python)=13947.48828125MB; mem (CPU total)=13852.0625MB
INFO:root:[  118] Training loss: 0.62146946, Validation loss: 0.61434612, Gradient norm: 0.06051743
INFO:root:At the start of the epoch: mem (CPU python)=14011.1796875MB; mem (CPU total)=13927.66796875MB
INFO:root:[  119] Training loss: 0.62153762, Validation loss: 0.61379630, Gradient norm: 0.06274250
INFO:root:At the start of the epoch: mem (CPU python)=14049.2734375MB; mem (CPU total)=13965.83203125MB
INFO:root:[  120] Training loss: 0.62140328, Validation loss: 0.61302251, Gradient norm: 0.06233459
INFO:root:At the start of the epoch: mem (CPU python)=14087.37109375MB; mem (CPU total)=14004.15234375MB
INFO:root:[  121] Training loss: 0.62078691, Validation loss: 0.61551415, Gradient norm: 0.05988437
INFO:root:At the start of the epoch: mem (CPU python)=14125.46875MB; mem (CPU total)=14042.2890625MB
INFO:root:[  122] Training loss: 0.62111712, Validation loss: 0.61297353, Gradient norm: 0.06469984
INFO:root:At the start of the epoch: mem (CPU python)=14163.56640625MB; mem (CPU total)=14080.20703125MB
INFO:root:[  123] Training loss: 0.62088395, Validation loss: 0.61313874, Gradient norm: 0.05771528
INFO:root:At the start of the epoch: mem (CPU python)=14214.16015625MB; mem (CPU total)=14130.80078125MB
INFO:root:[  124] Training loss: 0.62075777, Validation loss: 0.61379619, Gradient norm: 0.05947704
INFO:root:At the start of the epoch: mem (CPU python)=14227.28515625MB; mem (CPU total)=14144.01171875MB
INFO:root:[  125] Training loss: 0.62060460, Validation loss: 0.61333159, Gradient norm: 0.06267421
INFO:root:At the start of the epoch: mem (CPU python)=14277.8515625MB; mem (CPU total)=14194.66015625MB
INFO:root:[  126] Training loss: 0.62058240, Validation loss: 0.61283846, Gradient norm: 0.06497969
INFO:root:At the start of the epoch: mem (CPU python)=14315.9453125MB; mem (CPU total)=14233.0390625MB
INFO:root:[  127] Training loss: 0.62055734, Validation loss: 0.61406122, Gradient norm: 0.06411895
INFO:root:At the start of the epoch: mem (CPU python)=14354.04296875MB; mem (CPU total)=14271.44921875MB
INFO:root:[  128] Training loss: 0.62034930, Validation loss: 0.61334884, Gradient norm: 0.06101198
INFO:root:At the start of the epoch: mem (CPU python)=14392.13671875MB; mem (CPU total)=14310.00390625MB
INFO:root:[  129] Training loss: 0.62011738, Validation loss: 0.61257677, Gradient norm: 0.06636354
INFO:root:At the start of the epoch: mem (CPU python)=14430.234375MB; mem (CPU total)=14347.7734375MB
INFO:root:[  130] Training loss: 0.62025057, Validation loss: 0.61293181, Gradient norm: 0.06503487
INFO:root:At the start of the epoch: mem (CPU python)=14468.328125MB; mem (CPU total)=14385.58203125MB
INFO:root:[  131] Training loss: 0.61993293, Validation loss: 0.61346457, Gradient norm: 0.06202111
INFO:root:At the start of the epoch: mem (CPU python)=14506.42578125MB; mem (CPU total)=14423.7734375MB
INFO:root:[  132] Training loss: 0.61971871, Validation loss: 0.61193115, Gradient norm: 0.05816268
INFO:root:At the start of the epoch: mem (CPU python)=14544.51953125MB; mem (CPU total)=14462.21484375MB
INFO:root:[  133] Training loss: 0.61965472, Validation loss: 0.61237661, Gradient norm: 0.06033891
INFO:root:At the start of the epoch: mem (CPU python)=14582.61328125MB; mem (CPU total)=14500.37890625MB
INFO:root:[  134] Training loss: 0.61946122, Validation loss: 0.61249731, Gradient norm: 0.06082572
INFO:root:At the start of the epoch: mem (CPU python)=14620.7109375MB; mem (CPU total)=14538.28515625MB
INFO:root:[  135] Training loss: 0.61944070, Validation loss: 0.61210095, Gradient norm: 0.06278633
INFO:root:At the start of the epoch: mem (CPU python)=14658.8046875MB; mem (CPU total)=14576.38671875MB
INFO:root:[  136] Training loss: 0.61931895, Validation loss: 0.61212418, Gradient norm: 0.06339512
INFO:root:At the start of the epoch: mem (CPU python)=14696.9453125MB; mem (CPU total)=14615.21875MB
INFO:root:[  137] Training loss: 0.61897147, Validation loss: 0.61214326, Gradient norm: 0.05654754
INFO:root:At the start of the epoch: mem (CPU python)=14735.046875MB; mem (CPU total)=14652.734375MB
INFO:root:[  138] Training loss: 0.61911707, Validation loss: 0.61163143, Gradient norm: 0.06453553
INFO:root:At the start of the epoch: mem (CPU python)=14773.140625MB; mem (CPU total)=14691.0390625MB
INFO:root:[  139] Training loss: 0.61885696, Validation loss: 0.61206757, Gradient norm: 0.06261253
INFO:root:At the start of the epoch: mem (CPU python)=14811.234375MB; mem (CPU total)=14728.95703125MB
INFO:root:[  140] Training loss: 0.61883450, Validation loss: 0.61290204, Gradient norm: 0.06360680
INFO:root:At the start of the epoch: mem (CPU python)=14849.328125MB; mem (CPU total)=14767.38671875MB
INFO:root:[  141] Training loss: 0.61863666, Validation loss: 0.61168598, Gradient norm: 0.06673590
INFO:root:At the start of the epoch: mem (CPU python)=14887.42578125MB; mem (CPU total)=14805.796875MB
INFO:root:[  142] Training loss: 0.61858576, Validation loss: 0.61199548, Gradient norm: 0.05735285
INFO:root:At the start of the epoch: mem (CPU python)=14938.01953125MB; mem (CPU total)=14856.30078125MB
INFO:root:[  143] Training loss: 0.61833916, Validation loss: 0.61151220, Gradient norm: 0.05960180
INFO:root:At the start of the epoch: mem (CPU python)=14976.11328125MB; mem (CPU total)=14894.7265625MB
INFO:root:[  144] Training loss: 0.61824623, Validation loss: 0.61316254, Gradient norm: 0.06226701
INFO:root:At the start of the epoch: mem (CPU python)=15014.2109375MB; mem (CPU total)=14932.828125MB
INFO:root:[  145] Training loss: 0.61812042, Validation loss: 0.61176738, Gradient norm: 0.06200700
INFO:root:At the start of the epoch: mem (CPU python)=15052.3046875MB; mem (CPU total)=14970.62109375MB
INFO:root:[  146] Training loss: 0.61838047, Validation loss: 0.61113308, Gradient norm: 0.06771817
INFO:root:At the start of the epoch: mem (CPU python)=15127.8984375MB; mem (CPU total)=15046.703125MB
INFO:root:[  147] Training loss: 0.61797750, Validation loss: 0.61073346, Gradient norm: 0.06278769
INFO:root:At the start of the epoch: mem (CPU python)=15128.109375MB; mem (CPU total)=15022.265625MB
INFO:root:[  148] Training loss: 0.61785435, Validation loss: 0.61182236, Gradient norm: 0.06449340
INFO:root:At the start of the epoch: mem (CPU python)=15141.62109375MB; mem (CPU total)=15060.65625MB
INFO:root:[  149] Training loss: 0.61742212, Validation loss: 0.61122768, Gradient norm: 0.06063595
INFO:root:At the start of the epoch: mem (CPU python)=15192.1875MB; mem (CPU total)=15111.5390625MB
INFO:root:[  150] Training loss: 0.61740884, Validation loss: 0.61240036, Gradient norm: 0.06014229
INFO:root:At the start of the epoch: mem (CPU python)=15230.28125MB; mem (CPU total)=15149.68359375MB
INFO:root:[  151] Training loss: 0.61756549, Validation loss: 0.61092906, Gradient norm: 0.06690548
INFO:root:At the start of the epoch: mem (CPU python)=15268.37890625MB; mem (CPU total)=15187.82421875MB
INFO:root:[  152] Training loss: 0.61746895, Validation loss: 0.61120380, Gradient norm: 0.06080572
INFO:root:At the start of the epoch: mem (CPU python)=15306.47265625MB; mem (CPU total)=15225.9375MB
INFO:root:[  153] Training loss: 0.61737640, Validation loss: 0.61151879, Gradient norm: 0.06142751
INFO:root:At the start of the epoch: mem (CPU python)=15355.71484375MB; mem (CPU total)=15238.5859375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  154] Training loss: 0.61731949, Validation loss: 0.61060161, Gradient norm: 0.06209135
INFO:root:At the start of the epoch: mem (CPU python)=15370.19140625MB; mem (CPU total)=15289.08984375MB
INFO:root:[  155] Training loss: 0.61627989, Validation loss: 0.61002946, Gradient norm: 0.05813245
INFO:root:At the start of the epoch: mem (CPU python)=15408.7265625MB; mem (CPU total)=15327.99609375MB
INFO:root:[  156] Training loss: 0.61599572, Validation loss: 0.60961758, Gradient norm: 0.05587951
INFO:root:At the start of the epoch: mem (CPU python)=15458.85546875MB; mem (CPU total)=15378.109375MB
INFO:root:[  157] Training loss: 0.61567443, Validation loss: 0.61080493, Gradient norm: 0.05796812
INFO:root:At the start of the epoch: mem (CPU python)=15509.44921875MB; mem (CPU total)=15428.74609375MB
INFO:root:[  158] Training loss: 0.61571264, Validation loss: 0.61091874, Gradient norm: 0.05851193
INFO:root:At the start of the epoch: mem (CPU python)=15535.046875MB; mem (CPU total)=15454.70703125MB
INFO:root:[  159] Training loss: 0.61555384, Validation loss: 0.60961232, Gradient norm: 0.05913812
INFO:root:At the start of the epoch: mem (CPU python)=15585.640625MB; mem (CPU total)=15505.55859375MB
INFO:root:[  160] Training loss: 0.61541897, Validation loss: 0.60962873, Gradient norm: 0.05724328
INFO:root:At the start of the epoch: mem (CPU python)=15623.734375MB; mem (CPU total)=15543.671875MB
INFO:root:[  161] Training loss: 0.61568756, Validation loss: 0.61029538, Gradient norm: 0.05818398
INFO:root:At the start of the epoch: mem (CPU python)=15661.83203125MB; mem (CPU total)=15581.5390625MB
INFO:root:[  162] Training loss: 0.61554758, Validation loss: 0.60916660, Gradient norm: 0.05780675
INFO:root:At the start of the epoch: mem (CPU python)=15674.953125MB; mem (CPU total)=15594.75390625MB
INFO:root:[  163] Training loss: 0.61554944, Validation loss: 0.60967041, Gradient norm: 0.05802326
INFO:root:At the start of the epoch: mem (CPU python)=15713.046875MB; mem (CPU total)=15632.890625MB
INFO:root:[  164] Training loss: 0.61543377, Validation loss: 0.60899983, Gradient norm: 0.05851418
INFO:root:At the start of the epoch: mem (CPU python)=15751.14453125MB; mem (CPU total)=15671.06640625MB
INFO:root:[  165] Training loss: 0.61531585, Validation loss: 0.61071164, Gradient norm: 0.05696140
INFO:root:At the start of the epoch: mem (CPU python)=15789.2421875MB; mem (CPU total)=15709.7265625MB
INFO:root:[  166] Training loss: 0.61547210, Validation loss: 0.60946517, Gradient norm: 0.06089423
INFO:root:At the start of the epoch: mem (CPU python)=15839.8046875MB; mem (CPU total)=15760.2265625MB
INFO:root:[  167] Training loss: 0.61533130, Validation loss: 0.60925641, Gradient norm: 0.05847417
INFO:root:At the start of the epoch: mem (CPU python)=15877.90234375MB; mem (CPU total)=15798.36328125MB
INFO:root:[  168] Training loss: 0.61530824, Validation loss: 0.60951730, Gradient norm: 0.05972761
INFO:root:At the start of the epoch: mem (CPU python)=15916.0MB; mem (CPU total)=15836.4296875MB
INFO:root:[  169] Training loss: 0.61543865, Validation loss: 0.60969941, Gradient norm: 0.05882425
INFO:root:At the start of the epoch: mem (CPU python)=15954.09375MB; mem (CPU total)=15874.8203125MB
INFO:root:[  170] Training loss: 0.61523180, Validation loss: 0.60940092, Gradient norm: 0.06014391
INFO:root:At the start of the epoch: mem (CPU python)=15992.1875MB; mem (CPU total)=15912.93359375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  171] Training loss: 0.61521101, Validation loss: 0.60954372, Gradient norm: 0.06157258
INFO:root:At the start of the epoch: mem (CPU python)=16042.78515625MB; mem (CPU total)=15963.53515625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  172] Training loss: 0.61430050, Validation loss: 0.60876262, Gradient norm: 0.05497032
INFO:root:At the start of the epoch: mem (CPU python)=16055.91015625MB; mem (CPU total)=15976.71875MB
INFO:root:[  173] Training loss: 0.61412791, Validation loss: 0.61010860, Gradient norm: 0.05320094
INFO:root:At the start of the epoch: mem (CPU python)=16106.4765625MB; mem (CPU total)=16027.109375MB
INFO:root:[  174] Training loss: 0.61401145, Validation loss: 0.60889075, Gradient norm: 0.05244955
INFO:root:At the start of the epoch: mem (CPU python)=16157.0703125MB; mem (CPU total)=16077.74609375MB
INFO:root:[  175] Training loss: 0.61413554, Validation loss: 0.60898272, Gradient norm: 0.05320011
INFO:root:At the start of the epoch: mem (CPU python)=16170.1953125MB; mem (CPU total)=16090.9296875MB
INFO:root:[  176] Training loss: 0.61393718, Validation loss: 0.60922424, Gradient norm: 0.05289815
INFO:root:At the start of the epoch: mem (CPU python)=16208.2890625MB; mem (CPU total)=16129.3203125MB
INFO:root:[  177] Training loss: 0.61380816, Validation loss: 0.60888899, Gradient norm: 0.05235107
INFO:root:At the start of the epoch: mem (CPU python)=16258.85546875MB; mem (CPU total)=16179.76953125MB
INFO:root:[  178] Training loss: 0.61391153, Validation loss: 0.60920084, Gradient norm: 0.05306042
INFO:root:At the start of the epoch: mem (CPU python)=16296.953125MB; mem (CPU total)=16217.63671875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  179] Training loss: 0.61375275, Validation loss: 0.60910911, Gradient norm: 0.05342254
INFO:root:At the start of the epoch: mem (CPU python)=16335.046875MB; mem (CPU total)=16255.78125MB
INFO:root:[  180] Training loss: 0.61398008, Validation loss: 0.60892274, Gradient norm: 0.05107630
INFO:root:At the start of the epoch: mem (CPU python)=16373.140625MB; mem (CPU total)=16294.171875MB
INFO:root:[  181] Training loss: 0.61374388, Validation loss: 0.60941366, Gradient norm: 0.05164782
INFO:root:At the start of the epoch: mem (CPU python)=16411.234375MB; mem (CPU total)=16332.33984375MB
INFO:root:[  182] Training loss: 0.61367580, Validation loss: 0.60847507, Gradient norm: 0.05180780
INFO:root:At the start of the epoch: mem (CPU python)=16474.3359375MB; mem (CPU total)=16395.65234375MB
INFO:root:[  183] Training loss: 0.61344168, Validation loss: 0.60904636, Gradient norm: 0.05302047
INFO:root:At the start of the epoch: mem (CPU python)=16512.4296875MB; mem (CPU total)=16433.58203125MB
INFO:root:[  184] Training loss: 0.61378251, Validation loss: 0.60844893, Gradient norm: 0.05222399
INFO:root:At the start of the epoch: mem (CPU python)=16512.87890625MB; mem (CPU total)=16421.60546875MB
INFO:root:[  185] Training loss: 0.61354539, Validation loss: 0.60857988, Gradient norm: 0.05250584
INFO:root:At the start of the epoch: mem (CPU python)=16538.62109375MB; mem (CPU total)=16459.99609375MB
INFO:root:[  186] Training loss: 0.61370713, Validation loss: 0.60904246, Gradient norm: 0.05406893
INFO:root:At the start of the epoch: mem (CPU python)=16601.71484375MB; mem (CPU total)=16523.37109375MB
INFO:root:[  187] Training loss: 0.61366482, Validation loss: 0.60833958, Gradient norm: 0.05220464
INFO:root:At the start of the epoch: mem (CPU python)=16639.80859375MB; mem (CPU total)=16561.546875MB
INFO:root:[  188] Training loss: 0.61366485, Validation loss: 0.60923495, Gradient norm: 0.05192845
INFO:root:At the start of the epoch: mem (CPU python)=16677.90625MB; mem (CPU total)=16599.19921875MB
INFO:root:[  189] Training loss: 0.61354038, Validation loss: 0.60897401, Gradient norm: 0.05289918
INFO:root:At the start of the epoch: mem (CPU python)=16716.0MB; mem (CPU total)=16637.57421875MB
INFO:root:[  190] Training loss: 0.61362777, Validation loss: 0.60888906, Gradient norm: 0.05407756
INFO:root:At the start of the epoch: mem (CPU python)=16754.09375MB; mem (CPU total)=16675.71875MB
INFO:root:[  191] Training loss: 0.61339783, Validation loss: 0.60930101, Gradient norm: 0.05176314
INFO:root:At the start of the epoch: mem (CPU python)=16792.19140625MB; mem (CPU total)=16713.6015625MB
INFO:root:[  192] Training loss: 0.61357708, Validation loss: 0.60890971, Gradient norm: 0.05151620
INFO:root:At the start of the epoch: mem (CPU python)=16830.2890625MB; mem (CPU total)=16751.74609375MB
INFO:root:[  193] Training loss: 0.61363996, Validation loss: 0.60842350, Gradient norm: 0.05338346
INFO:root:At the start of the epoch: mem (CPU python)=16868.3828125MB; mem (CPU total)=16789.3046875MB
INFO:root:[  194] Training loss: 0.61352000, Validation loss: 0.60918595, Gradient norm: 0.05241569
INFO:root:At the start of the epoch: mem (CPU python)=16906.4765625MB; mem (CPU total)=16827.44921875MB
INFO:root:[  195] Training loss: 0.61372511, Validation loss: 0.60894299, Gradient norm: 0.05281053
INFO:root:At the start of the epoch: mem (CPU python)=16944.57421875MB; mem (CPU total)=16866.0859375MB
INFO:root:[  196] Training loss: 0.61350715, Validation loss: 0.60861641, Gradient norm: 0.05409723
INFO:root:At the start of the epoch: mem (CPU python)=16982.671875MB; mem (CPU total)=16904.21484375MB
INFO:root:EP 196: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=17020.765625MB; mem (CPU total)=16942.359375MB
INFO:root:Training the model took 9551.147s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83986
INFO:root:EnergyScoreTrain: 0.59127
INFO:root:CRPSTrain: 0.45928
INFO:root:Gaussian NLLTrain: 1.18768
INFO:root:CoverageTrain: 0.94983
INFO:root:IntervalWidthTrain: 3.25709
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86513
INFO:root:EnergyScoreValidation: 0.60893
INFO:root:CRPSValidation: 0.47412
INFO:root:Gaussian NLLValidation: 1.22049
INFO:root:CoverageValidation: 0.94195
INFO:root:IntervalWidthValidation: 3.26094
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86677
INFO:root:EnergyScoreTest: 0.61008
INFO:root:CRPSTest: 0.47512
INFO:root:Gaussian NLLTest: 1.22235
INFO:root:CoverageTest: 0.94153
INFO:root:IntervalWidthTest: 3.26058
INFO:root:After validation: mem (CPU python)=17104.8046875MB; mem (CPU total)=16965.61328125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=17104.8046875MB; mem (CPU total)=16965.64453125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=17104.8046875MB; mem (CPU total)=16965.890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=17104.8046875MB; mem (CPU total)=16967.35546875MB
INFO:root:[    1] Training loss: 0.72435021, Validation loss: 0.72035140, Gradient norm: 0.01886024
INFO:root:At the start of the epoch: mem (CPU python)=17139.79296875MB; mem (CPU total)=17061.84765625MB
INFO:root:[    2] Training loss: 0.71985054, Validation loss: 0.71878291, Gradient norm: 0.00560018
INFO:root:At the start of the epoch: mem (CPU python)=17140.35546875MB; mem (CPU total)=17062.30078125MB
INFO:root:[    3] Training loss: 0.71795807, Validation loss: 0.71459800, Gradient norm: 0.00770143
INFO:root:At the start of the epoch: mem (CPU python)=17215.9921875MB; mem (CPU total)=17137.3984375MB
INFO:root:[    4] Training loss: 0.71122686, Validation loss: 0.70469070, Gradient norm: 0.01848632
INFO:root:At the start of the epoch: mem (CPU python)=17254.1015625MB; mem (CPU total)=17175.5703125MB
INFO:root:[    5] Training loss: 0.70350833, Validation loss: 0.69737857, Gradient norm: 0.02476708
INFO:root:At the start of the epoch: mem (CPU python)=17279.69140625MB; mem (CPU total)=17201.0078125MB
INFO:root:[    6] Training loss: 0.69784793, Validation loss: 0.69126794, Gradient norm: 0.02679103
INFO:root:At the start of the epoch: mem (CPU python)=17305.30078125MB; mem (CPU total)=17226.875MB
INFO:root:[    7] Training loss: 0.69308712, Validation loss: 0.68673536, Gradient norm: 0.02832456
INFO:root:At the start of the epoch: mem (CPU python)=17393.39453125MB; mem (CPU total)=17315.15625MB
INFO:root:[    8] Training loss: 0.68847773, Validation loss: 0.68103971, Gradient norm: 0.03070491
INFO:root:At the start of the epoch: mem (CPU python)=17393.39453125MB; mem (CPU total)=17303.140625MB
INFO:root:[    9] Training loss: 0.68419386, Validation loss: 0.67634791, Gradient norm: 0.03128568
INFO:root:At the start of the epoch: mem (CPU python)=17444.61328125MB; mem (CPU total)=17366.73046875MB
INFO:root:[   10] Training loss: 0.68028894, Validation loss: 0.67199980, Gradient norm: 0.03026421
INFO:root:At the start of the epoch: mem (CPU python)=17482.70703125MB; mem (CPU total)=17404.62890625MB
INFO:root:[   11] Training loss: 0.67675190, Validation loss: 0.66857350, Gradient norm: 0.03036736
INFO:root:At the start of the epoch: mem (CPU python)=17482.9296875MB; mem (CPU total)=17392.08984375MB
INFO:root:[   12] Training loss: 0.67377068, Validation loss: 0.66530448, Gradient norm: 0.03435534
INFO:root:At the start of the epoch: mem (CPU python)=17546.37109375MB; mem (CPU total)=17471.03515625MB
INFO:root:[   13] Training loss: 0.67092168, Validation loss: 0.66149011, Gradient norm: 0.03490803
INFO:root:At the start of the epoch: mem (CPU python)=17584.46484375MB; mem (CPU total)=17509.3359375MB
INFO:root:[   14] Training loss: 0.66802555, Validation loss: 0.65842013, Gradient norm: 0.03412590
INFO:root:At the start of the epoch: mem (CPU python)=17610.0625MB; mem (CPU total)=17534.7421875MB
INFO:root:[   15] Training loss: 0.66546273, Validation loss: 0.65654559, Gradient norm: 0.03233192
INFO:root:At the start of the epoch: mem (CPU python)=17674.09375MB; mem (CPU total)=17598.74609375MB
INFO:root:[   16] Training loss: 0.66317681, Validation loss: 0.65399378, Gradient norm: 0.03774103
INFO:root:At the start of the epoch: mem (CPU python)=17749.75390625MB; mem (CPU total)=17674.64453125MB
INFO:root:[   17] Training loss: 0.66125301, Validation loss: 0.65107335, Gradient norm: 0.03628587
INFO:root:At the start of the epoch: mem (CPU python)=17750.37109375MB; mem (CPU total)=17675.11328125MB
INFO:root:[   18] Training loss: 0.65929853, Validation loss: 0.64934399, Gradient norm: 0.03871697
INFO:root:At the start of the epoch: mem (CPU python)=17763.44140625MB; mem (CPU total)=17688.30859375MB
INFO:root:[   19] Training loss: 0.65765698, Validation loss: 0.64710033, Gradient norm: 0.03866772
INFO:root:At the start of the epoch: mem (CPU python)=17776.56640625MB; mem (CPU total)=17701.234375MB
INFO:root:[   20] Training loss: 0.65600741, Validation loss: 0.64620093, Gradient norm: 0.03789882
INFO:root:At the start of the epoch: mem (CPU python)=17839.6328125MB; mem (CPU total)=17764.578125MB
INFO:root:[   21] Training loss: 0.65445419, Validation loss: 0.64460904, Gradient norm: 0.03818913
INFO:root:At the start of the epoch: mem (CPU python)=17852.75390625MB; mem (CPU total)=17777.5234375MB
INFO:root:[   22] Training loss: 0.65310856, Validation loss: 0.64267981, Gradient norm: 0.04055578
INFO:root:At the start of the epoch: mem (CPU python)=17940.8515625MB; mem (CPU total)=17866.06640625MB
INFO:root:[   23] Training loss: 0.65176137, Validation loss: 0.64136554, Gradient norm: 0.04136393
INFO:root:At the start of the epoch: mem (CPU python)=17971.4765625MB; mem (CPU total)=17828.578125MB
INFO:root:[   24] Training loss: 0.65045121, Validation loss: 0.63982759, Gradient norm: 0.03907470
INFO:root:At the start of the epoch: mem (CPU python)=18013.92578125MB; mem (CPU total)=17891.94921875MB
INFO:root:[   25] Training loss: 0.64946505, Validation loss: 0.63873958, Gradient norm: 0.04735133
INFO:root:At the start of the epoch: mem (CPU python)=18030.11328125MB; mem (CPU total)=17955.046875MB
INFO:root:[   26] Training loss: 0.64797215, Validation loss: 0.63789049, Gradient norm: 0.04321961
INFO:root:At the start of the epoch: mem (CPU python)=18080.70703125MB; mem (CPU total)=18005.8984375MB
INFO:root:[   27] Training loss: 0.64701000, Validation loss: 0.63667793, Gradient norm: 0.04095480
INFO:root:At the start of the epoch: mem (CPU python)=18118.80078125MB; mem (CPU total)=18044.04296875MB
INFO:root:[   28] Training loss: 0.64631915, Validation loss: 0.63786565, Gradient norm: 0.05038064
INFO:root:At the start of the epoch: mem (CPU python)=18144.39453125MB; mem (CPU total)=18069.48046875MB
INFO:root:[   29] Training loss: 0.64528685, Validation loss: 0.63494829, Gradient norm: 0.04898831
INFO:root:At the start of the epoch: mem (CPU python)=18194.9921875MB; mem (CPU total)=18120.33203125MB
INFO:root:[   30] Training loss: 0.64417465, Validation loss: 0.63429601, Gradient norm: 0.04292384
INFO:root:At the start of the epoch: mem (CPU python)=18270.58984375MB; mem (CPU total)=18196.16796875MB
INFO:root:[   31] Training loss: 0.64331481, Validation loss: 0.63317252, Gradient norm: 0.04361179
INFO:root:At the start of the epoch: mem (CPU python)=18308.68359375MB; mem (CPU total)=18245.87890625MB
INFO:root:[   32] Training loss: 0.64242360, Validation loss: 0.63231253, Gradient norm: 0.04314918
INFO:root:At the start of the epoch: mem (CPU python)=18309.05078125MB; mem (CPU total)=18233.3828125MB
INFO:root:[   33] Training loss: 0.64164531, Validation loss: 0.63070339, Gradient norm: 0.04684499
INFO:root:At the start of the epoch: mem (CPU python)=18334.875MB; mem (CPU total)=18270.78125MB
INFO:root:[   34] Training loss: 0.64113939, Validation loss: 0.62999992, Gradient norm: 0.04650949
INFO:root:At the start of the epoch: mem (CPU python)=18397.99609375MB; mem (CPU total)=18333.546875MB
INFO:root:[   35] Training loss: 0.64030979, Validation loss: 0.62984764, Gradient norm: 0.05056441
INFO:root:At the start of the epoch: mem (CPU python)=18436.08984375MB; mem (CPU total)=18371.66015625MB
INFO:root:[   36] Training loss: 0.63959631, Validation loss: 0.62899522, Gradient norm: 0.05214861
INFO:root:At the start of the epoch: mem (CPU python)=18474.1875MB; mem (CPU total)=18407.09375MB
INFO:root:[   37] Training loss: 0.63878868, Validation loss: 0.62847786, Gradient norm: 0.04975938
INFO:root:At the start of the epoch: mem (CPU python)=18512.28125MB; mem (CPU total)=18442.78515625MB
INFO:root:[   38] Training loss: 0.63806001, Validation loss: 0.62767620, Gradient norm: 0.04907598
INFO:root:At the start of the epoch: mem (CPU python)=18550.375MB; mem (CPU total)=18480.4375MB
INFO:root:[   39] Training loss: 0.63747153, Validation loss: 0.62726235, Gradient norm: 0.04405999
INFO:root:At the start of the epoch: mem (CPU python)=18550.8359375MB; mem (CPU total)=18710.09765625MB
INFO:root:[   40] Training loss: 0.63682983, Validation loss: 0.62648274, Gradient norm: 0.04754230
INFO:root:At the start of the epoch: mem (CPU python)=18626.56640625MB; mem (CPU total)=18560.2578125MB
INFO:root:[   41] Training loss: 0.63639151, Validation loss: 0.62632496, Gradient norm: 0.04607227
INFO:root:At the start of the epoch: mem (CPU python)=18664.6640625MB; mem (CPU total)=18597.6484375MB
INFO:root:[   42] Training loss: 0.63542927, Validation loss: 0.62578563, Gradient norm: 0.04846588
INFO:root:At the start of the epoch: mem (CPU python)=18695.5078125MB; mem (CPU total)=18621.96875MB
INFO:root:[   43] Training loss: 0.63530855, Validation loss: 0.62502221, Gradient norm: 0.05285050
INFO:root:At the start of the epoch: mem (CPU python)=18703.328125MB; mem (CPU total)=18634.65625MB
INFO:root:[   44] Training loss: 0.63461232, Validation loss: 0.62432268, Gradient norm: 0.04775834
INFO:root:At the start of the epoch: mem (CPU python)=18753.921875MB; mem (CPU total)=18685.3046875MB
INFO:root:[   45] Training loss: 0.63396835, Validation loss: 0.62523808, Gradient norm: 0.04911235
INFO:root:At the start of the epoch: mem (CPU python)=18804.515625MB; mem (CPU total)=18734.74609375MB
INFO:root:[   46] Training loss: 0.63368077, Validation loss: 0.62392900, Gradient norm: 0.05463548
INFO:root:At the start of the epoch: mem (CPU python)=18805.140625MB; mem (CPU total)=18736.37109375MB
INFO:root:[   47] Training loss: 0.63304919, Validation loss: 0.62393665, Gradient norm: 0.05240921
INFO:root:At the start of the epoch: mem (CPU python)=18868.20703125MB; mem (CPU total)=18799.46875MB
INFO:root:[   48] Training loss: 0.63251408, Validation loss: 0.62270272, Gradient norm: 0.05305120
INFO:root:At the start of the epoch: mem (CPU python)=18893.8046875MB; mem (CPU total)=18824.96875MB
INFO:root:[   49] Training loss: 0.63192863, Validation loss: 0.62281248, Gradient norm: 0.05048240
INFO:root:At the start of the epoch: mem (CPU python)=18969.4296875MB; mem (CPU total)=18900.52734375MB
INFO:root:[   50] Training loss: 0.63176502, Validation loss: 0.62143480, Gradient norm: 0.05783092
INFO:root:At the start of the epoch: mem (CPU python)=19020.0MB; mem (CPU total)=18950.7734375MB
INFO:root:[   51] Training loss: 0.63123390, Validation loss: 0.62122292, Gradient norm: 0.05451953
INFO:root:At the start of the epoch: mem (CPU python)=19058.09375MB; mem (CPU total)=18989.1171875MB
INFO:root:[   52] Training loss: 0.63081607, Validation loss: 0.62083616, Gradient norm: 0.05027437
INFO:root:At the start of the epoch: mem (CPU python)=19096.1875MB; mem (CPU total)=19027.2734375MB
INFO:root:[   53] Training loss: 0.63029095, Validation loss: 0.62025812, Gradient norm: 0.05692821
INFO:root:At the start of the epoch: mem (CPU python)=19121.8125MB; mem (CPU total)=19053.87890625MB
INFO:root:[   54] Training loss: 0.62999144, Validation loss: 0.62038957, Gradient norm: 0.05004479
INFO:root:At the start of the epoch: mem (CPU python)=19134.87890625MB; mem (CPU total)=19066.58203125MB
INFO:root:[   55] Training loss: 0.62949689, Validation loss: 0.62046731, Gradient norm: 0.05157006
INFO:root:At the start of the epoch: mem (CPU python)=19210.47265625MB; mem (CPU total)=19140.69921875MB
INFO:root:[   56] Training loss: 0.62908921, Validation loss: 0.61955691, Gradient norm: 0.05143287
INFO:root:At the start of the epoch: mem (CPU python)=19261.07421875MB; mem (CPU total)=19190.8515625MB
INFO:root:[   57] Training loss: 0.62887433, Validation loss: 0.61985502, Gradient norm: 0.05570034
INFO:root:At the start of the epoch: mem (CPU python)=19299.16796875MB; mem (CPU total)=19228.296875MB
INFO:root:[   58] Training loss: 0.62857547, Validation loss: 0.61863791, Gradient norm: 0.04957552
INFO:root:At the start of the epoch: mem (CPU python)=19299.171875MB; mem (CPU total)=19203.46484375MB
INFO:root:[   59] Training loss: 0.62814224, Validation loss: 0.61889801, Gradient norm: 0.05180995
INFO:root:At the start of the epoch: mem (CPU python)=19337.859375MB; mem (CPU total)=19266.55078125MB
INFO:root:[   60] Training loss: 0.62793599, Validation loss: 0.61827647, Gradient norm: 0.05482849
INFO:root:At the start of the epoch: mem (CPU python)=19400.95703125MB; mem (CPU total)=19329.94921875MB
INFO:root:[   61] Training loss: 0.62733109, Validation loss: 0.61805809, Gradient norm: 0.05440529
INFO:root:At the start of the epoch: mem (CPU python)=19426.578125MB; mem (CPU total)=19357.1015625MB
INFO:root:[   62] Training loss: 0.62697453, Validation loss: 0.61829312, Gradient norm: 0.05114676
INFO:root:At the start of the epoch: mem (CPU python)=19452.14453125MB; mem (CPU total)=19380.796875MB
INFO:root:[   63] Training loss: 0.62676251, Validation loss: 0.61781559, Gradient norm: 0.05452000
INFO:root:At the start of the epoch: mem (CPU python)=19453.04296875MB; mem (CPU total)=20991.87890625MB
INFO:root:[   64] Training loss: 0.62637959, Validation loss: 0.61667573, Gradient norm: 0.05111516
INFO:root:At the start of the epoch: mem (CPU python)=19515.83984375MB; mem (CPU total)=19451.59765625MB
INFO:root:[   65] Training loss: 0.62632437, Validation loss: 0.61697706, Gradient norm: 0.06158777
INFO:root:At the start of the epoch: mem (CPU python)=19553.93359375MB; mem (CPU total)=19491.88671875MB
INFO:root:[   66] Training loss: 0.62596312, Validation loss: 0.61772282, Gradient norm: 0.05977602
INFO:root:At the start of the epoch: mem (CPU python)=19592.03125MB; mem (CPU total)=19529.29296875MB
INFO:root:[   67] Training loss: 0.62550134, Validation loss: 0.61710132, Gradient norm: 0.05461844
INFO:root:At the start of the epoch: mem (CPU python)=19655.15234375MB; mem (CPU total)=19591.421875MB
INFO:root:[   68] Training loss: 0.62519042, Validation loss: 0.61649800, Gradient norm: 0.05853268
INFO:root:At the start of the epoch: mem (CPU python)=19693.24609375MB; mem (CPU total)=19628.31640625MB
INFO:root:[   69] Training loss: 0.62499205, Validation loss: 0.61637969, Gradient norm: 0.06098495
INFO:root:At the start of the epoch: mem (CPU python)=19706.3125MB; mem (CPU total)=19641.51953125MB
INFO:root:[   70] Training loss: 0.62464227, Validation loss: 0.61602102, Gradient norm: 0.05482600
INFO:root:At the start of the epoch: mem (CPU python)=19731.91015625MB; mem (CPU total)=19665.9453125MB
INFO:root:[   71] Training loss: 0.62426948, Validation loss: 0.61585171, Gradient norm: 0.05211363
INFO:root:At the start of the epoch: mem (CPU python)=19782.50390625MB; mem (CPU total)=19715.8671875MB
INFO:root:[   72] Training loss: 0.62424228, Validation loss: 0.61631174, Gradient norm: 0.05460365
INFO:root:At the start of the epoch: mem (CPU python)=19858.1015625MB; mem (CPU total)=19791.859375MB
INFO:root:[   73] Training loss: 0.62406945, Validation loss: 0.61507569, Gradient norm: 0.06501188
INFO:root:At the start of the epoch: mem (CPU python)=19883.7265625MB; mem (CPU total)=19818.86328125MB
INFO:root:[   74] Training loss: 0.62370300, Validation loss: 0.61489187, Gradient norm: 0.05962590
INFO:root:At the start of the epoch: mem (CPU python)=19946.79296875MB; mem (CPU total)=19882.15234375MB
INFO:root:[   75] Training loss: 0.62364872, Validation loss: 0.61467620, Gradient norm: 0.06255557
INFO:root:At the start of the epoch: mem (CPU python)=19947.01171875MB; mem (CPU total)=19869.76953125MB
INFO:root:[   76] Training loss: 0.62310515, Validation loss: 0.61495333, Gradient norm: 0.05717438
INFO:root:At the start of the epoch: mem (CPU python)=19965.2265625MB; mem (CPU total)=19893.05078125MB
INFO:root:[   77] Training loss: 0.62291603, Validation loss: 0.61485842, Gradient norm: 0.05747555
INFO:root:At the start of the epoch: mem (CPU python)=20023.578125MB; mem (CPU total)=19955.80078125MB
INFO:root:[   78] Training loss: 0.62263940, Validation loss: 0.61440532, Gradient norm: 0.05958637
INFO:root:At the start of the epoch: mem (CPU python)=20074.19921875MB; mem (CPU total)=20006.51171875MB
INFO:root:[   79] Training loss: 0.62247576, Validation loss: 0.61462130, Gradient norm: 0.05954925
INFO:root:At the start of the epoch: mem (CPU python)=20124.765625MB; mem (CPU total)=20056.953125MB
INFO:root:[   80] Training loss: 0.62228925, Validation loss: 0.61397067, Gradient norm: 0.05775947
INFO:root:At the start of the epoch: mem (CPU python)=20187.86328125MB; mem (CPU total)=20119.8125MB
INFO:root:[   81] Training loss: 0.62184346, Validation loss: 0.61357343, Gradient norm: 0.05592026
INFO:root:At the start of the epoch: mem (CPU python)=20225.9609375MB; mem (CPU total)=20157.9921875MB
INFO:root:[   82] Training loss: 0.62171664, Validation loss: 0.61428471, Gradient norm: 0.06198826
INFO:root:At the start of the epoch: mem (CPU python)=20264.05859375MB; mem (CPU total)=20196.40234375MB
INFO:root:[   83] Training loss: 0.62140121, Validation loss: 0.61344742, Gradient norm: 0.06704296
INFO:root:At the start of the epoch: mem (CPU python)=20264.11328125MB; mem (CPU total)=20159.52734375MB
INFO:root:[   84] Training loss: 0.62097505, Validation loss: 0.61434189, Gradient norm: 0.05717033
INFO:root:At the start of the epoch: mem (CPU python)=20265.375MB; mem (CPU total)=20197.65625MB
INFO:root:[   85] Training loss: 0.62106711, Validation loss: 0.61325886, Gradient norm: 0.05995027
INFO:root:At the start of the epoch: mem (CPU python)=20328.34375MB; mem (CPU total)=20260.9921875MB
INFO:root:[   86] Training loss: 0.62094522, Validation loss: 0.61237306, Gradient norm: 0.05947128
INFO:root:At the start of the epoch: mem (CPU python)=20341.4375MB; mem (CPU total)=20273.87890625MB
INFO:root:[   87] Training loss: 0.62057544, Validation loss: 0.61326081, Gradient norm: 0.06033534
INFO:root:At the start of the epoch: mem (CPU python)=20404.53515625MB; mem (CPU total)=20336.75390625MB
INFO:root:[   88] Training loss: 0.62034977, Validation loss: 0.61217036, Gradient norm: 0.05660294
INFO:root:At the start of the epoch: mem (CPU python)=20417.62890625MB; mem (CPU total)=20349.5390625MB
INFO:root:[   89] Training loss: 0.62014733, Validation loss: 0.61234998, Gradient norm: 0.05734300
INFO:root:At the start of the epoch: mem (CPU python)=20493.25MB; mem (CPU total)=20425.1171875MB
INFO:root:[   90] Training loss: 0.61977521, Validation loss: 0.61331096, Gradient norm: 0.05640166
INFO:root:At the start of the epoch: mem (CPU python)=20518.82421875MB; mem (CPU total)=20451.0390625MB
INFO:root:[   91] Training loss: 0.62007985, Validation loss: 0.61315792, Gradient norm: 0.06031781
INFO:root:At the start of the epoch: mem (CPU python)=20556.91796875MB; mem (CPU total)=20489.20703125MB
INFO:root:[   92] Training loss: 0.61954604, Validation loss: 0.61203703, Gradient norm: 0.06099462
INFO:root:At the start of the epoch: mem (CPU python)=20582.51171875MB; mem (CPU total)=20514.71875MB
INFO:root:[   93] Training loss: 0.61934109, Validation loss: 0.61234018, Gradient norm: 0.05933175
INFO:root:At the start of the epoch: mem (CPU python)=20645.63671875MB; mem (CPU total)=20578.0859375MB
INFO:root:[   94] Training loss: 0.61927190, Validation loss: 0.61191404, Gradient norm: 0.06204107
INFO:root:At the start of the epoch: mem (CPU python)=20683.73046875MB; mem (CPU total)=20616.67578125MB
INFO:root:[   95] Training loss: 0.61934151, Validation loss: 0.61167647, Gradient norm: 0.07507166
INFO:root:At the start of the epoch: mem (CPU python)=20684.296875MB; mem (CPU total)=20616.78125MB
INFO:root:[   96] Training loss: 0.61890495, Validation loss: 0.61155311, Gradient norm: 0.05612298
INFO:root:At the start of the epoch: mem (CPU python)=20759.91796875MB; mem (CPU total)=20692.609375MB
INFO:root:[   97] Training loss: 0.61876813, Validation loss: 0.61075054, Gradient norm: 0.05951102
INFO:root:At the start of the epoch: mem (CPU python)=20798.015625MB; mem (CPU total)=20730.64453125MB
INFO:root:[   98] Training loss: 0.61865394, Validation loss: 0.61175025, Gradient norm: 0.06164041
INFO:root:At the start of the epoch: mem (CPU python)=20848.58203125MB; mem (CPU total)=20781.796875MB
INFO:root:[   99] Training loss: 0.61821165, Validation loss: 0.61096360, Gradient norm: 0.06143467
INFO:root:At the start of the epoch: mem (CPU python)=20849.03515625MB; mem (CPU total)=20757.3515625MB
INFO:root:[  100] Training loss: 0.61812774, Validation loss: 0.61196777, Gradient norm: 0.05900579
INFO:root:At the start of the epoch: mem (CPU python)=20912.3046875MB; mem (CPU total)=20845.62890625MB
INFO:root:[  101] Training loss: 0.61792565, Validation loss: 0.61163438, Gradient norm: 0.05892381
INFO:root:At the start of the epoch: mem (CPU python)=20950.3984375MB; mem (CPU total)=20883.55078125MB
INFO:root:[  102] Training loss: 0.61791311, Validation loss: 0.61097299, Gradient norm: 0.06101610
INFO:root:At the start of the epoch: mem (CPU python)=20988.4921875MB; mem (CPU total)=20921.71875MB
INFO:root:[  103] Training loss: 0.61762397, Validation loss: 0.61101333, Gradient norm: 0.06029987
INFO:root:At the start of the epoch: mem (CPU python)=21018.95703125MB; mem (CPU total)=20922.16015625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  104] Training loss: 0.61752984, Validation loss: 0.61035836, Gradient norm: 0.06864387
INFO:root:At the start of the epoch: mem (CPU python)=21027.15625MB; mem (CPU total)=20960.34765625MB
INFO:root:[  105] Training loss: 0.61643548, Validation loss: 0.61016661, Gradient norm: 0.05801281
INFO:root:At the start of the epoch: mem (CPU python)=21065.25MB; mem (CPU total)=20998.75390625MB
INFO:root:[  106] Training loss: 0.61597011, Validation loss: 0.60984483, Gradient norm: 0.05271474
INFO:root:At the start of the epoch: mem (CPU python)=21103.34375MB; mem (CPU total)=21035.71875MB
INFO:root:[  107] Training loss: 0.61599722, Validation loss: 0.61019964, Gradient norm: 0.05260507
INFO:root:At the start of the epoch: mem (CPU python)=21141.4453125MB; mem (CPU total)=21074.36328125MB
INFO:root:[  108] Training loss: 0.61593350, Validation loss: 0.60913314, Gradient norm: 0.05556337
INFO:root:At the start of the epoch: mem (CPU python)=21179.5390625MB; mem (CPU total)=21112.51171875MB
INFO:root:[  109] Training loss: 0.61555140, Validation loss: 0.60979016, Gradient norm: 0.05482622
INFO:root:At the start of the epoch: mem (CPU python)=21242.6328125MB; mem (CPU total)=21175.59765625MB
INFO:root:[  110] Training loss: 0.61580404, Validation loss: 0.61037874, Gradient norm: 0.05324946
INFO:root:At the start of the epoch: mem (CPU python)=21280.73046875MB; mem (CPU total)=21213.98046875MB
INFO:root:[  111] Training loss: 0.61571324, Validation loss: 0.61081640, Gradient norm: 0.05607649
INFO:root:At the start of the epoch: mem (CPU python)=21318.82421875MB; mem (CPU total)=21252.1171875MB
INFO:root:[  112] Training loss: 0.61557002, Validation loss: 0.60889945, Gradient norm: 0.05621278
INFO:root:At the start of the epoch: mem (CPU python)=21319.4453125MB; mem (CPU total)=21252.8984375MB
INFO:root:[  113] Training loss: 0.61568614, Validation loss: 0.60935948, Gradient norm: 0.05656077
INFO:root:At the start of the epoch: mem (CPU python)=21357.5390625MB; mem (CPU total)=21290.75390625MB
INFO:root:[  114] Training loss: 0.61558868, Validation loss: 0.61008704, Gradient norm: 0.05578613
INFO:root:At the start of the epoch: mem (CPU python)=21433.11328125MB; mem (CPU total)=21366.55859375MB
INFO:root:[  115] Training loss: 0.61548581, Validation loss: 0.60987402, Gradient norm: 0.05884250
INFO:root:At the start of the epoch: mem (CPU python)=21483.734375MB; mem (CPU total)=21416.94921875MB
INFO:root:[  116] Training loss: 0.61528346, Validation loss: 0.61027312, Gradient norm: 0.05574412
INFO:root:At the start of the epoch: mem (CPU python)=21495.24609375MB; mem (CPU total)=21397.7109375MB
INFO:root:[  117] Training loss: 0.61502180, Validation loss: 0.60916488, Gradient norm: 0.06019016
INFO:root:At the start of the epoch: mem (CPU python)=21534.82421875MB; mem (CPU total)=21406.90234375MB
INFO:root:[  118] Training loss: 0.61508935, Validation loss: 0.60980557, Gradient norm: 0.05688251
INFO:root:At the start of the epoch: mem (CPU python)=21585.4921875MB; mem (CPU total)=21518.55078125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  119] Training loss: 0.61498526, Validation loss: 0.60852386, Gradient norm: 0.06282928
INFO:root:At the start of the epoch: mem (CPU python)=21623.5859375MB; mem (CPU total)=21556.90625MB
INFO:root:[  120] Training loss: 0.61447557, Validation loss: 0.60879980, Gradient norm: 0.05239494
INFO:root:At the start of the epoch: mem (CPU python)=21661.6796875MB; mem (CPU total)=21594.93359375MB
INFO:root:[  121] Training loss: 0.61451268, Validation loss: 0.60881486, Gradient norm: 0.05402262
INFO:root:At the start of the epoch: mem (CPU python)=21699.77734375MB; mem (CPU total)=21633.078125MB
INFO:root:[  122] Training loss: 0.61431253, Validation loss: 0.60956106, Gradient norm: 0.05414599
INFO:root:At the start of the epoch: mem (CPU python)=21723.375MB; mem (CPU total)=21638.76171875MB
INFO:root:[  123] Training loss: 0.61441010, Validation loss: 0.60932071, Gradient norm: 0.05368438
INFO:root:At the start of the epoch: mem (CPU python)=21780.96875MB; mem (CPU total)=21714.34375MB
INFO:root:[  124] Training loss: 0.61421626, Validation loss: 0.60912337, Gradient norm: 0.05420103
INFO:root:At the start of the epoch: mem (CPU python)=21826.59375MB; mem (CPU total)=21760.453125MB
INFO:root:[  125] Training loss: 0.61422924, Validation loss: 0.60924001, Gradient norm: 0.05312119
INFO:root:At the start of the epoch: mem (CPU python)=21852.11328125MB; mem (CPU total)=21724.5078125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  126] Training loss: 0.61405266, Validation loss: 0.60860358, Gradient norm: 0.05260993
INFO:root:At the start of the epoch: mem (CPU python)=21915.2578125MB; mem (CPU total)=21848.9765625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  127] Training loss: 0.61383800, Validation loss: 0.60822310, Gradient norm: 0.05052841
INFO:root:At the start of the epoch: mem (CPU python)=21915.48046875MB; mem (CPU total)=21836.9921875MB
INFO:root:[  128] Training loss: 0.61360305, Validation loss: 0.60794237, Gradient norm: 0.05070649
INFO:root:At the start of the epoch: mem (CPU python)=21941.44921875MB; mem (CPU total)=21875.1875MB
INFO:root:[  129] Training loss: 0.61350105, Validation loss: 0.60903449, Gradient norm: 0.04940247
INFO:root:At the start of the epoch: mem (CPU python)=21979.54296875MB; mem (CPU total)=21913.625MB
INFO:root:[  130] Training loss: 0.61376584, Validation loss: 0.60921553, Gradient norm: 0.05065880
INFO:root:At the start of the epoch: mem (CPU python)=22017.63671875MB; mem (CPU total)=21951.76953125MB
INFO:root:[  131] Training loss: 0.61361829, Validation loss: 0.60879803, Gradient norm: 0.05083330
INFO:root:At the start of the epoch: mem (CPU python)=22068.23828125MB; mem (CPU total)=22002.375MB
INFO:root:[  132] Training loss: 0.61359121, Validation loss: 0.60863702, Gradient norm: 0.05163646
INFO:root:At the start of the epoch: mem (CPU python)=22073.83203125MB; mem (CPU total)=22008.2734375MB
INFO:root:[  133] Training loss: 0.61354056, Validation loss: 0.60875923, Gradient norm: 0.05307892
INFO:root:At the start of the epoch: mem (CPU python)=22119.453125MB; mem (CPU total)=22054.125MB
INFO:root:[  134] Training loss: 0.61333199, Validation loss: 0.60896894, Gradient norm: 0.05130231
INFO:root:At the start of the epoch: mem (CPU python)=22207.55078125MB; mem (CPU total)=22142.234375MB
INFO:root:[  135] Training loss: 0.61358586, Validation loss: 0.60823697, Gradient norm: 0.04991958
INFO:root:At the start of the epoch: mem (CPU python)=22245.64453125MB; mem (CPU total)=22179.375MB
INFO:root:[  136] Training loss: 0.61349892, Validation loss: 0.60877980, Gradient norm: 0.05050970
INFO:root:At the start of the epoch: mem (CPU python)=22246.09375MB; mem (CPU total)=22167.38671875MB
INFO:root:[  137] Training loss: 0.61352436, Validation loss: 0.60824226, Gradient norm: 0.05176324
INFO:root:At the start of the epoch: mem (CPU python)=22295.61328125MB; mem (CPU total)=22198.0234375MB
INFO:root:EP 137: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=22359.7890625MB; mem (CPU total)=22293.796875MB
INFO:root:Training the model took 7819.674s.
INFO:root:Emptying the cuda cache took 0.027s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84457
INFO:root:EnergyScoreTrain: 0.59457
INFO:root:CRPSTrain: 0.46177
INFO:root:Gaussian NLLTrain: 1.19274
INFO:root:CoverageTrain: 0.95141
INFO:root:IntervalWidthTrain: 3.28116
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86448
INFO:root:EnergyScoreValidation: 0.60849
INFO:root:CRPSValidation: 0.47364
INFO:root:Gaussian NLLValidation: 1.21843
INFO:root:CoverageValidation: 0.9453
INFO:root:IntervalWidthValidation: 3.28642
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86534
INFO:root:EnergyScoreTest: 0.60908
INFO:root:CRPSTest: 0.47406
INFO:root:Gaussian NLLTest: 1.21889
INFO:root:CoverageTest: 0.945
INFO:root:IntervalWidthTest: 3.28577
INFO:root:After validation: mem (CPU python)=22425.06640625MB; mem (CPU total)=22343.32421875MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=22425.06640625MB; mem (CPU total)=22343.32421875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=22425.06640625MB; mem (CPU total)=22343.3203125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=22425.06640625MB; mem (CPU total)=22343.53515625MB
INFO:root:[    1] Training loss: 0.72422437, Validation loss: 0.72007229, Gradient norm: 0.01398632
INFO:root:At the start of the epoch: mem (CPU python)=22425.06640625MB; mem (CPU total)=22337.8828125MB
INFO:root:[    2] Training loss: 0.71984663, Validation loss: 0.71916866, Gradient norm: 0.00526081
INFO:root:At the start of the epoch: mem (CPU python)=22446.85546875MB; mem (CPU total)=22381.50390625MB
INFO:root:[    3] Training loss: 0.71783091, Validation loss: 0.71432787, Gradient norm: 0.00798144
INFO:root:At the start of the epoch: mem (CPU python)=22517.4921875MB; mem (CPU total)=22452.078125MB
INFO:root:[    4] Training loss: 0.71035875, Validation loss: 0.70323239, Gradient norm: 0.01883018
INFO:root:At the start of the epoch: mem (CPU python)=22555.60546875MB; mem (CPU total)=22490.5MB
INFO:root:[    5] Training loss: 0.70295951, Validation loss: 0.69648658, Gradient norm: 0.02436896
INFO:root:At the start of the epoch: mem (CPU python)=22593.69921875MB; mem (CPU total)=22528.390625MB
INFO:root:[    6] Training loss: 0.69685625, Validation loss: 0.68959995, Gradient norm: 0.02746267
INFO:root:At the start of the epoch: mem (CPU python)=22636.765625MB; mem (CPU total)=22571.2734375MB
INFO:root:[    7] Training loss: 0.69148268, Validation loss: 0.68405155, Gradient norm: 0.02846052
INFO:root:At the start of the epoch: mem (CPU python)=22674.8671875MB; mem (CPU total)=22609.609375MB
INFO:root:[    8] Training loss: 0.68653147, Validation loss: 0.67810949, Gradient norm: 0.03079731
INFO:root:At the start of the epoch: mem (CPU python)=22712.9609375MB; mem (CPU total)=22648.03125MB
INFO:root:[    9] Training loss: 0.68191078, Validation loss: 0.67246018, Gradient norm: 0.02760221
INFO:root:At the start of the epoch: mem (CPU python)=22726.08203125MB; mem (CPU total)=22660.09375MB
INFO:root:[   10] Training loss: 0.67768203, Validation loss: 0.66791082, Gradient norm: 0.02850001
INFO:root:At the start of the epoch: mem (CPU python)=22758.6796875MB; mem (CPU total)=22660.30078125MB
INFO:root:[   11] Training loss: 0.67397911, Validation loss: 0.66341496, Gradient norm: 0.02921120
INFO:root:At the start of the epoch: mem (CPU python)=22797.24609375MB; mem (CPU total)=22730.890625MB
INFO:root:[   12] Training loss: 0.67094563, Validation loss: 0.66079893, Gradient norm: 0.02988577
INFO:root:At the start of the epoch: mem (CPU python)=22860.3671875MB; mem (CPU total)=22794.265625MB
INFO:root:[   13] Training loss: 0.66792579, Validation loss: 0.65839233, Gradient norm: 0.02926241
INFO:root:At the start of the epoch: mem (CPU python)=22873.43359375MB; mem (CPU total)=22807.2109375MB
INFO:root:[   14] Training loss: 0.66526414, Validation loss: 0.65434923, Gradient norm: 0.02992812
INFO:root:At the start of the epoch: mem (CPU python)=22911.53125MB; mem (CPU total)=22845.38671875MB
INFO:root:[   15] Training loss: 0.66280547, Validation loss: 0.65216084, Gradient norm: 0.03050249
INFO:root:At the start of the epoch: mem (CPU python)=22942.68359375MB; mem (CPU total)=22871.0703125MB
INFO:root:[   16] Training loss: 0.66088746, Validation loss: 0.64952317, Gradient norm: 0.03202657
INFO:root:At the start of the epoch: mem (CPU python)=23012.74609375MB; mem (CPU total)=22946.83984375MB
INFO:root:[   17] Training loss: 0.65909065, Validation loss: 0.64883362, Gradient norm: 0.03075868
INFO:root:At the start of the epoch: mem (CPU python)=23050.84375MB; mem (CPU total)=22985.45703125MB
INFO:root:[   18] Training loss: 0.65722201, Validation loss: 0.64682632, Gradient norm: 0.03482566
INFO:root:At the start of the epoch: mem (CPU python)=23088.94140625MB; mem (CPU total)=23024.140625MB
INFO:root:[   19] Training loss: 0.65553445, Validation loss: 0.64499036, Gradient norm: 0.03631025
INFO:root:At the start of the epoch: mem (CPU python)=23127.03515625MB; mem (CPU total)=23062.03125MB
INFO:root:[   20] Training loss: 0.65411029, Validation loss: 0.64365913, Gradient norm: 0.03608241
INFO:root:At the start of the epoch: mem (CPU python)=23140.1015625MB; mem (CPU total)=23075.19921875MB
INFO:root:[   21] Training loss: 0.65282291, Validation loss: 0.64140108, Gradient norm: 0.03390518
INFO:root:At the start of the epoch: mem (CPU python)=23215.703125MB; mem (CPU total)=23151.03515625MB
INFO:root:[   22] Training loss: 0.65131045, Validation loss: 0.64136935, Gradient norm: 0.03790521
INFO:root:At the start of the epoch: mem (CPU python)=23215.703125MB; mem (CPU total)=23128.53515625MB
INFO:root:[   23] Training loss: 0.65005389, Validation loss: 0.64008908, Gradient norm: 0.03776775
INFO:root:At the start of the epoch: mem (CPU python)=23254.390625MB; mem (CPU total)=23191.35546875MB
INFO:root:[   24] Training loss: 0.64902406, Validation loss: 0.63778728, Gradient norm: 0.03857592
INFO:root:At the start of the epoch: mem (CPU python)=23292.48828125MB; mem (CPU total)=23229.73828125MB
INFO:root:[   25] Training loss: 0.64799827, Validation loss: 0.63631122, Gradient norm: 0.04075642
INFO:root:At the start of the epoch: mem (CPU python)=23330.58203125MB; mem (CPU total)=23265.8828125MB
INFO:root:[   26] Training loss: 0.64699982, Validation loss: 0.63596986, Gradient norm: 0.04382446
INFO:root:At the start of the epoch: mem (CPU python)=23361.55078125MB; mem (CPU total)=23291.8125MB
INFO:root:[   27] Training loss: 0.64587583, Validation loss: 0.63515244, Gradient norm: 0.04288845
INFO:root:At the start of the epoch: mem (CPU python)=23406.7734375MB; mem (CPU total)=23342.41796875MB
INFO:root:[   28] Training loss: 0.64486706, Validation loss: 0.63382850, Gradient norm: 0.04484952
INFO:root:At the start of the epoch: mem (CPU python)=23444.87109375MB; mem (CPU total)=23380.93359375MB
INFO:root:[   29] Training loss: 0.64418085, Validation loss: 0.63332635, Gradient norm: 0.04499156
INFO:root:At the start of the epoch: mem (CPU python)=23482.96484375MB; mem (CPU total)=23419.09375MB
INFO:root:[   30] Training loss: 0.64324706, Validation loss: 0.63212520, Gradient norm: 0.04518275
INFO:root:At the start of the epoch: mem (CPU python)=23533.55859375MB; mem (CPU total)=23469.9453125MB
INFO:root:[   31] Training loss: 0.64230885, Validation loss: 0.63254360, Gradient norm: 0.04317244
INFO:root:At the start of the epoch: mem (CPU python)=23571.65625MB; mem (CPU total)=23507.84375MB
INFO:root:[   32] Training loss: 0.64180509, Validation loss: 0.63037384, Gradient norm: 0.04467340
INFO:root:At the start of the epoch: mem (CPU python)=23647.25390625MB; mem (CPU total)=23583.6796875MB
INFO:root:[   33] Training loss: 0.64106171, Validation loss: 0.63047395, Gradient norm: 0.04447363
INFO:root:At the start of the epoch: mem (CPU python)=23685.34765625MB; mem (CPU total)=23621.578125MB
INFO:root:[   34] Training loss: 0.64023683, Validation loss: 0.62977217, Gradient norm: 0.04819021
INFO:root:At the start of the epoch: mem (CPU python)=23698.45703125MB; mem (CPU total)=23559.91015625MB
INFO:root:[   35] Training loss: 0.63961417, Validation loss: 0.62888145, Gradient norm: 0.04183492
INFO:root:At the start of the epoch: mem (CPU python)=23724.0390625MB; mem (CPU total)=23660.421875MB
INFO:root:[   36] Training loss: 0.63910006, Validation loss: 0.62842276, Gradient norm: 0.04824045
INFO:root:At the start of the epoch: mem (CPU python)=23787.13671875MB; mem (CPU total)=23723.79296875MB
INFO:root:[   37] Training loss: 0.63819550, Validation loss: 0.62857463, Gradient norm: 0.04574547
INFO:root:At the start of the epoch: mem (CPU python)=23825.234375MB; mem (CPU total)=23761.9375MB
INFO:root:[   38] Training loss: 0.63783951, Validation loss: 0.62761651, Gradient norm: 0.05331389
INFO:root:At the start of the epoch: mem (CPU python)=23825.96484375MB; mem (CPU total)=23751.57421875MB
INFO:root:[   39] Training loss: 0.63732652, Validation loss: 0.62674874, Gradient norm: 0.04596605
INFO:root:At the start of the epoch: mem (CPU python)=23851.4296875MB; mem (CPU total)=23789.7109375MB
INFO:root:[   40] Training loss: 0.63668321, Validation loss: 0.62552821, Gradient norm: 0.04145321
INFO:root:At the start of the epoch: mem (CPU python)=23914.51953125MB; mem (CPU total)=23853.015625MB
INFO:root:[   41] Training loss: 0.63590860, Validation loss: 0.62536611, Gradient norm: 0.05238207
INFO:root:At the start of the epoch: mem (CPU python)=23952.62109375MB; mem (CPU total)=23889.19140625MB
INFO:root:[   42] Training loss: 0.63552219, Validation loss: 0.62493655, Gradient norm: 0.04582811
INFO:root:At the start of the epoch: mem (CPU python)=23990.71484375MB; mem (CPU total)=23927.3359375MB
INFO:root:[   43] Training loss: 0.63517290, Validation loss: 0.62425477, Gradient norm: 0.05318779
INFO:root:At the start of the epoch: mem (CPU python)=24028.80859375MB; mem (CPU total)=23965.7265625MB
INFO:root:[   44] Training loss: 0.63445253, Validation loss: 0.62415142, Gradient norm: 0.04656008
INFO:root:At the start of the epoch: mem (CPU python)=24029.4296875MB; mem (CPU total)=23966.2109375MB
INFO:root:[   45] Training loss: 0.63417200, Validation loss: 0.62354845, Gradient norm: 0.05038713
INFO:root:At the start of the epoch: mem (CPU python)=24092.5MB; mem (CPU total)=24029.578125MB
INFO:root:[   46] Training loss: 0.63390819, Validation loss: 0.62356690, Gradient norm: 0.05602505
INFO:root:At the start of the epoch: mem (CPU python)=24123.5234375MB; mem (CPU total)=24042.5234375MB
INFO:root:[   47] Training loss: 0.63317138, Validation loss: 0.62392131, Gradient norm: 0.04937731
INFO:root:At the start of the epoch: mem (CPU python)=24156.19140625MB; mem (CPU total)=24093.30859375MB
INFO:root:[   48] Training loss: 0.63267447, Validation loss: 0.62283466, Gradient norm: 0.04888232
INFO:root:At the start of the epoch: mem (CPU python)=24244.24609375MB; mem (CPU total)=24121.421875MB
INFO:root:[   49] Training loss: 0.63233850, Validation loss: 0.62194425, Gradient norm: 0.05295914
INFO:root:At the start of the epoch: mem (CPU python)=24269.91015625MB; mem (CPU total)=24209.1484375MB
INFO:root:[   50] Training loss: 0.63199679, Validation loss: 0.62253250, Gradient norm: 0.05468746
INFO:root:At the start of the epoch: mem (CPU python)=24295.4765625MB; mem (CPU total)=24233.0625MB
INFO:root:[   51] Training loss: 0.63150470, Validation loss: 0.62040649, Gradient norm: 0.05792311
INFO:root:At the start of the epoch: mem (CPU python)=24346.09765625MB; mem (CPU total)=24283.94140625MB
INFO:root:[   52] Training loss: 0.63097713, Validation loss: 0.62089271, Gradient norm: 0.04973049
INFO:root:At the start of the epoch: mem (CPU python)=24371.671875MB; mem (CPU total)=24309.37109375MB
INFO:root:[   53] Training loss: 0.63070480, Validation loss: 0.62122342, Gradient norm: 0.05409717
INFO:root:At the start of the epoch: mem (CPU python)=24409.76953125MB; mem (CPU total)=24347.5390625MB
INFO:root:[   54] Training loss: 0.63040106, Validation loss: 0.61994971, Gradient norm: 0.05142285
INFO:root:At the start of the epoch: mem (CPU python)=24447.86328125MB; mem (CPU total)=24385.7265625MB
INFO:root:[   55] Training loss: 0.62995224, Validation loss: 0.61976018, Gradient norm: 0.05044694
INFO:root:At the start of the epoch: mem (CPU python)=24498.48828125MB; mem (CPU total)=24435.15625MB
INFO:root:[   56] Training loss: 0.62962982, Validation loss: 0.61979803, Gradient norm: 0.05270096
INFO:root:At the start of the epoch: mem (CPU python)=24536.58203125MB; mem (CPU total)=24473.328125MB
INFO:root:[   57] Training loss: 0.62908080, Validation loss: 0.61941333, Gradient norm: 0.04977686
INFO:root:At the start of the epoch: mem (CPU python)=24574.67578125MB; mem (CPU total)=24511.59375MB
INFO:root:[   58] Training loss: 0.62891981, Validation loss: 0.61818050, Gradient norm: 0.05307186
INFO:root:At the start of the epoch: mem (CPU python)=24625.24609375MB; mem (CPU total)=24562.5078125MB
INFO:root:[   59] Training loss: 0.62859024, Validation loss: 0.61872841, Gradient norm: 0.05693354
INFO:root:At the start of the epoch: mem (CPU python)=24663.33984375MB; mem (CPU total)=24600.62109375MB
INFO:root:[   60] Training loss: 0.62825583, Validation loss: 0.61852267, Gradient norm: 0.05359772
INFO:root:At the start of the epoch: mem (CPU python)=24701.43359375MB; mem (CPU total)=24638.51953125MB
INFO:root:[   61] Training loss: 0.62804744, Validation loss: 0.61785894, Gradient norm: 0.05447674
INFO:root:At the start of the epoch: mem (CPU python)=24702.02734375MB; mem (CPU total)=24639.2421875MB
INFO:root:[   62] Training loss: 0.62750079, Validation loss: 0.61770344, Gradient norm: 0.05022386
INFO:root:At the start of the epoch: mem (CPU python)=24777.625MB; mem (CPU total)=24714.6171875MB
INFO:root:[   63] Training loss: 0.62745521, Validation loss: 0.61912004, Gradient norm: 0.05613705
INFO:root:At the start of the epoch: mem (CPU python)=24815.72265625MB; mem (CPU total)=24753.0078125MB
INFO:root:[   64] Training loss: 0.62701283, Validation loss: 0.61960976, Gradient norm: 0.06587158
INFO:root:At the start of the epoch: mem (CPU python)=24846.61328125MB; mem (CPU total)=24778.66015625MB
INFO:root:[   65] Training loss: 0.62687775, Validation loss: 0.61689379, Gradient norm: 0.05680884
INFO:root:At the start of the epoch: mem (CPU python)=24879.44140625MB; mem (CPU total)=24816.06640625MB
INFO:root:[   66] Training loss: 0.62658080, Validation loss: 0.61576162, Gradient norm: 0.06590122
INFO:root:At the start of the epoch: mem (CPU python)=24917.53515625MB; mem (CPU total)=24854.86328125MB
INFO:root:[   67] Training loss: 0.62607991, Validation loss: 0.61653252, Gradient norm: 0.05915677
INFO:root:At the start of the epoch: mem (CPU python)=24948.01171875MB; mem (CPU total)=24880.4765625MB
INFO:root:[   68] Training loss: 0.62580411, Validation loss: 0.61582263, Gradient norm: 0.05409401
INFO:root:At the start of the epoch: mem (CPU python)=24981.1953125MB; mem (CPU total)=24918.62109375MB
INFO:root:[   69] Training loss: 0.62568625, Validation loss: 0.61684351, Gradient norm: 0.05649884
INFO:root:At the start of the epoch: mem (CPU python)=25031.8203125MB; mem (CPU total)=24969.2578125MB
INFO:root:[   70] Training loss: 0.62534442, Validation loss: 0.61605119, Gradient norm: 0.05216510
INFO:root:At the start of the epoch: mem (CPU python)=25069.9140625MB; mem (CPU total)=25007.2890625MB
INFO:root:[   71] Training loss: 0.62508647, Validation loss: 0.61635024, Gradient norm: 0.05830596
INFO:root:At the start of the epoch: mem (CPU python)=25120.48046875MB; mem (CPU total)=25057.9609375MB
INFO:root:[   72] Training loss: 0.62487140, Validation loss: 0.61474175, Gradient norm: 0.05912514
INFO:root:At the start of the epoch: mem (CPU python)=25146.10546875MB; mem (CPU total)=25083.6953125MB
INFO:root:[   73] Training loss: 0.62459629, Validation loss: 0.61574787, Gradient norm: 0.05523523
INFO:root:At the start of the epoch: mem (CPU python)=25184.20703125MB; mem (CPU total)=25122.11328125MB
INFO:root:[   74] Training loss: 0.62435424, Validation loss: 0.61509791, Gradient norm: 0.06174999
INFO:root:At the start of the epoch: mem (CPU python)=25209.7734375MB; mem (CPU total)=25147.53515625MB
INFO:root:[   75] Training loss: 0.62391696, Validation loss: 0.61454717, Gradient norm: 0.05466631
INFO:root:At the start of the epoch: mem (CPU python)=25260.35546875MB; mem (CPU total)=25136.78125MB
INFO:root:[   76] Training loss: 0.62380736, Validation loss: 0.61427109, Gradient norm: 0.06598844
INFO:root:At the start of the epoch: mem (CPU python)=25273.46484375MB; mem (CPU total)=25211.56640625MB
INFO:root:[   77] Training loss: 0.62351087, Validation loss: 0.61367113, Gradient norm: 0.06473378
INFO:root:At the start of the epoch: mem (CPU python)=25324.05859375MB; mem (CPU total)=25262.19921875MB
INFO:root:[   78] Training loss: 0.62327761, Validation loss: 0.61375669, Gradient norm: 0.05717155
INFO:root:At the start of the epoch: mem (CPU python)=25362.15234375MB; mem (CPU total)=25300.34375MB
INFO:root:[   79] Training loss: 0.62306032, Validation loss: 0.61322963, Gradient norm: 0.05229940
INFO:root:At the start of the epoch: mem (CPU python)=25412.77734375MB; mem (CPU total)=25351.47265625MB
INFO:root:[   80] Training loss: 0.62285332, Validation loss: 0.61383514, Gradient norm: 0.05877493
INFO:root:At the start of the epoch: mem (CPU python)=25425.84375MB; mem (CPU total)=25364.38671875MB
INFO:root:[   81] Training loss: 0.62225723, Validation loss: 0.61386119, Gradient norm: 0.05375436
INFO:root:At the start of the epoch: mem (CPU python)=25463.9375MB; mem (CPU total)=25402.5078125MB
INFO:root:[   82] Training loss: 0.62229622, Validation loss: 0.61322088, Gradient norm: 0.05472403
INFO:root:At the start of the epoch: mem (CPU python)=25576.875MB; mem (CPU total)=25453.84375MB
INFO:root:[   83] Training loss: 0.62242783, Validation loss: 0.61394591, Gradient norm: 0.06270667
INFO:root:At the start of the epoch: mem (CPU python)=25576.875MB; mem (CPU total)=25491.7421875MB
INFO:root:[   84] Training loss: 0.62200814, Validation loss: 0.61350910, Gradient norm: 0.05742611
INFO:root:At the start of the epoch: mem (CPU python)=25576.875MB; mem (CPU total)=25504.44140625MB
INFO:root:[   85] Training loss: 0.62174439, Validation loss: 0.61334359, Gradient norm: 0.05810191
INFO:root:At the start of the epoch: mem (CPU python)=25628.8203125MB; mem (CPU total)=25568.0MB
INFO:root:[   86] Training loss: 0.62147449, Validation loss: 0.61245588, Gradient norm: 0.06278654
INFO:root:At the start of the epoch: mem (CPU python)=25641.91796875MB; mem (CPU total)=25581.25390625MB
INFO:root:[   87] Training loss: 0.62126496, Validation loss: 0.61344614, Gradient norm: 0.05964333
INFO:root:At the start of the epoch: mem (CPU python)=25705.01171875MB; mem (CPU total)=25644.53515625MB
INFO:root:[   88] Training loss: 0.62125140, Validation loss: 0.61187601, Gradient norm: 0.05709252
INFO:root:At the start of the epoch: mem (CPU python)=25755.6328125MB; mem (CPU total)=25695.203125MB
INFO:root:[   89] Training loss: 0.62090528, Validation loss: 0.61208884, Gradient norm: 0.05638023
INFO:root:At the start of the epoch: mem (CPU python)=25793.734375MB; mem (CPU total)=25733.37890625MB
INFO:root:[   90] Training loss: 0.62061079, Validation loss: 0.61156813, Gradient norm: 0.06512690
INFO:root:At the start of the epoch: mem (CPU python)=25826.24609375MB; mem (CPU total)=25759.03125MB
INFO:root:[   91] Training loss: 0.62053905, Validation loss: 0.61211007, Gradient norm: 0.05784893
INFO:root:At the start of the epoch: mem (CPU python)=25857.39453125MB; mem (CPU total)=25796.9296875MB
INFO:root:[   92] Training loss: 0.62038642, Validation loss: 0.61234603, Gradient norm: 0.05907823
INFO:root:At the start of the epoch: mem (CPU python)=25895.4921875MB; mem (CPU total)=25835.07421875MB
INFO:root:[   93] Training loss: 0.62032480, Validation loss: 0.61159385, Gradient norm: 0.06538031
INFO:root:At the start of the epoch: mem (CPU python)=25908.5859375MB; mem (CPU total)=25847.7734375MB
INFO:root:[   94] Training loss: 0.62009079, Validation loss: 0.61150285, Gradient norm: 0.06208926
INFO:root:At the start of the epoch: mem (CPU python)=25959.1796875MB; mem (CPU total)=25899.01171875MB
INFO:root:[   95] Training loss: 0.61968550, Validation loss: 0.61088885, Gradient norm: 0.06697442
INFO:root:At the start of the epoch: mem (CPU python)=25959.8359375MB; mem (CPU total)=25899.36328125MB
INFO:root:[   96] Training loss: 0.61957505, Validation loss: 0.61091300, Gradient norm: 0.06696829
INFO:root:At the start of the epoch: mem (CPU python)=26047.875MB; mem (CPU total)=25987.8203125MB
INFO:root:[   97] Training loss: 0.61935458, Validation loss: 0.61076391, Gradient norm: 0.06223852
INFO:root:At the start of the epoch: mem (CPU python)=26098.5MB; mem (CPU total)=26038.484375MB
INFO:root:[   98] Training loss: 0.61931766, Validation loss: 0.61030632, Gradient norm: 0.06020413
INFO:root:At the start of the epoch: mem (CPU python)=26136.59375MB; mem (CPU total)=26076.3828125MB
INFO:root:[   99] Training loss: 0.61904696, Validation loss: 0.61022299, Gradient norm: 0.05857085
INFO:root:At the start of the epoch: mem (CPU python)=26174.69140625MB; mem (CPU total)=26114.7734375MB
INFO:root:[  100] Training loss: 0.61904427, Validation loss: 0.60949827, Gradient norm: 0.06274716
INFO:root:At the start of the epoch: mem (CPU python)=26205.59375MB; mem (CPU total)=26127.71875MB
INFO:root:[  101] Training loss: 0.61902921, Validation loss: 0.61019243, Gradient norm: 0.06732478
INFO:root:At the start of the epoch: mem (CPU python)=26238.3515625MB; mem (CPU total)=26178.31640625MB
INFO:root:[  102] Training loss: 0.61835770, Validation loss: 0.60910427, Gradient norm: 0.06082007
INFO:root:At the start of the epoch: mem (CPU python)=26251.44921875MB; mem (CPU total)=26191.78515625MB
INFO:root:[  103] Training loss: 0.61846673, Validation loss: 0.60988905, Gradient norm: 0.06342698
INFO:root:At the start of the epoch: mem (CPU python)=26352.046875MB; mem (CPU total)=26292.421875MB
INFO:root:[  104] Training loss: 0.61814581, Validation loss: 0.60989223, Gradient norm: 0.05568694
INFO:root:At the start of the epoch: mem (CPU python)=26365.16796875MB; mem (CPU total)=26305.58203125MB
INFO:root:[  105] Training loss: 0.61821954, Validation loss: 0.60867974, Gradient norm: 0.06671928
INFO:root:At the start of the epoch: mem (CPU python)=26389.92578125MB; mem (CPU total)=26281.328125MB
INFO:root:[  106] Training loss: 0.61811661, Validation loss: 0.60953099, Gradient norm: 0.06123510
INFO:root:At the start of the epoch: mem (CPU python)=26403.83203125MB; mem (CPU total)=26344.4765625MB
INFO:root:[  107] Training loss: 0.61792122, Validation loss: 0.60933840, Gradient norm: 0.06597769
INFO:root:At the start of the epoch: mem (CPU python)=26471.92578125MB; mem (CPU total)=26412.5546875MB
INFO:root:[  108] Training loss: 0.61773534, Validation loss: 0.60934952, Gradient norm: 0.06724393
INFO:root:At the start of the epoch: mem (CPU python)=26517.546875MB; mem (CPU total)=26458.21484375MB
INFO:root:[  109] Training loss: 0.61744211, Validation loss: 0.60897227, Gradient norm: 0.06184354
INFO:root:At the start of the epoch: mem (CPU python)=26530.62109375MB; mem (CPU total)=26470.734375MB
INFO:root:[  110] Training loss: 0.61717761, Validation loss: 0.61044651, Gradient norm: 0.06093339
INFO:root:At the start of the epoch: mem (CPU python)=26568.7109375MB; mem (CPU total)=26508.5625MB
INFO:root:[  111] Training loss: 0.61711072, Validation loss: 0.60939233, Gradient norm: 0.06408134
INFO:root:At the start of the epoch: mem (CPU python)=26619.30859375MB; mem (CPU total)=26559.41015625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  112] Training loss: 0.61691797, Validation loss: 0.60909526, Gradient norm: 0.06998638
INFO:root:At the start of the epoch: mem (CPU python)=26632.40234375MB; mem (CPU total)=26572.22265625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  113] Training loss: 0.61590282, Validation loss: 0.60807535, Gradient norm: 0.05464066
INFO:root:At the start of the epoch: mem (CPU python)=26695.5MB; mem (CPU total)=26635.82421875MB
INFO:root:[  114] Training loss: 0.61519365, Validation loss: 0.60841573, Gradient norm: 0.04774578
INFO:root:At the start of the epoch: mem (CPU python)=26733.59375MB; mem (CPU total)=26673.9921875MB
INFO:root:[  115] Training loss: 0.61524639, Validation loss: 0.60797319, Gradient norm: 0.05092631
INFO:root:At the start of the epoch: mem (CPU python)=26784.21484375MB; mem (CPU total)=26724.47265625MB
INFO:root:[  116] Training loss: 0.61537835, Validation loss: 0.60875312, Gradient norm: 0.05296340
INFO:root:At the start of the epoch: mem (CPU python)=26822.3125MB; mem (CPU total)=26762.88671875MB
INFO:root:[  117] Training loss: 0.61518694, Validation loss: 0.60768739, Gradient norm: 0.05030250
INFO:root:At the start of the epoch: mem (CPU python)=26822.87890625MB; mem (CPU total)=26763.640625MB
INFO:root:[  118] Training loss: 0.61525302, Validation loss: 0.60779012, Gradient norm: 0.05052890
INFO:root:At the start of the epoch: mem (CPU python)=26860.97265625MB; mem (CPU total)=26801.80859375MB
INFO:root:[  119] Training loss: 0.61510519, Validation loss: 0.60781711, Gradient norm: 0.05264541
INFO:root:At the start of the epoch: mem (CPU python)=26949.0703125MB; mem (CPU total)=26890.1328125MB
INFO:root:[  120] Training loss: 0.61485473, Validation loss: 0.60717366, Gradient norm: 0.05121152
INFO:root:At the start of the epoch: mem (CPU python)=26987.16796875MB; mem (CPU total)=26928.546875MB
INFO:root:[  121] Training loss: 0.61503504, Validation loss: 0.60723247, Gradient norm: 0.05489138
INFO:root:At the start of the epoch: mem (CPU python)=27000.26171875MB; mem (CPU total)=26943.45703125MB
INFO:root:[  122] Training loss: 0.61497270, Validation loss: 0.60818045, Gradient norm: 0.05112774
INFO:root:At the start of the epoch: mem (CPU python)=27050.8828125MB; mem (CPU total)=26994.29296875MB
INFO:root:[  123] Training loss: 0.61486790, Validation loss: 0.60721126, Gradient norm: 0.05285317
INFO:root:At the start of the epoch: mem (CPU python)=27088.98046875MB; mem (CPU total)=27032.46484375MB
INFO:root:[  124] Training loss: 0.61499901, Validation loss: 0.60776186, Gradient norm: 0.05370204
INFO:root:At the start of the epoch: mem (CPU python)=27127.07421875MB; mem (CPU total)=27070.140625MB
INFO:root:[  125] Training loss: 0.61476505, Validation loss: 0.60719600, Gradient norm: 0.05529184
INFO:root:At the start of the epoch: mem (CPU python)=27140.140625MB; mem (CPU total)=27083.08203125MB
INFO:root:[  126] Training loss: 0.61483283, Validation loss: 0.60735310, Gradient norm: 0.05116622
INFO:root:At the start of the epoch: mem (CPU python)=27165.73828125MB; mem (CPU total)=27107.28125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  127] Training loss: 0.61479433, Validation loss: 0.60796290, Gradient norm: 0.05226439
INFO:root:At the start of the epoch: mem (CPU python)=27216.33203125MB; mem (CPU total)=27157.9140625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  128] Training loss: 0.61455448, Validation loss: 0.60735137, Gradient norm: 0.05109883
INFO:root:At the start of the epoch: mem (CPU python)=27266.9296875MB; mem (CPU total)=27208.7890625MB
INFO:root:[  129] Training loss: 0.61435873, Validation loss: 0.60703058, Gradient norm: 0.04919151
INFO:root:At the start of the epoch: mem (CPU python)=27330.0234375MB; mem (CPU total)=27272.05859375MB
INFO:root:[  130] Training loss: 0.61432943, Validation loss: 0.60721970, Gradient norm: 0.04937227
INFO:root:At the start of the epoch: mem (CPU python)=27355.6484375MB; mem (CPU total)=27299.1328125MB
INFO:root:[  131] Training loss: 0.61427463, Validation loss: 0.60704611, Gradient norm: 0.04750958
INFO:root:At the start of the epoch: mem (CPU python)=27406.21484375MB; mem (CPU total)=27347.81640625MB
INFO:root:[  132] Training loss: 0.61441682, Validation loss: 0.60742640, Gradient norm: 0.04907814
INFO:root:At the start of the epoch: mem (CPU python)=27444.30859375MB; mem (CPU total)=27385.7421875MB
INFO:root:[  133] Training loss: 0.61417973, Validation loss: 0.60761971, Gradient norm: 0.04927815
INFO:root:At the start of the epoch: mem (CPU python)=27482.40625MB; mem (CPU total)=27424.40234375MB
INFO:root:[  134] Training loss: 0.61426981, Validation loss: 0.60753829, Gradient norm: 0.04831265
INFO:root:At the start of the epoch: mem (CPU python)=27482.46875MB; mem (CPU total)=27401.265625MB
INFO:root:[  135] Training loss: 0.61424306, Validation loss: 0.60713265, Gradient norm: 0.04771039
INFO:root:At the start of the epoch: mem (CPU python)=27533.59765625MB; mem (CPU total)=27480.16015625MB
INFO:root:[  136] Training loss: 0.61431219, Validation loss: 0.60720219, Gradient norm: 0.05032231
INFO:root:At the start of the epoch: mem (CPU python)=27571.69140625MB; mem (CPU total)=27518.56640625MB
INFO:root:[  137] Training loss: 0.61425763, Validation loss: 0.60713038, Gradient norm: 0.05143376
INFO:root:At the start of the epoch: mem (CPU python)=27622.3203125MB; mem (CPU total)=27567.75MB
INFO:root:[  138] Training loss: 0.61406164, Validation loss: 0.60820992, Gradient norm: 0.04895206
INFO:root:At the start of the epoch: mem (CPU python)=27660.4140625MB; mem (CPU total)=27606.16796875MB
INFO:root:[  139] Training loss: 0.61439093, Validation loss: 0.60669454, Gradient norm: 0.04930549
INFO:root:At the start of the epoch: mem (CPU python)=27673.48046875MB; mem (CPU total)=27620.08984375MB
INFO:root:[  140] Training loss: 0.61392600, Validation loss: 0.60698650, Gradient norm: 0.04981826
INFO:root:At the start of the epoch: mem (CPU python)=27736.60546875MB; mem (CPU total)=27682.25390625MB
INFO:root:[  141] Training loss: 0.61409042, Validation loss: 0.60713127, Gradient norm: 0.04735122
INFO:root:At the start of the epoch: mem (CPU python)=27774.7109375MB; mem (CPU total)=27720.421875MB
INFO:root:[  142] Training loss: 0.61415217, Validation loss: 0.60718477, Gradient norm: 0.04762579
INFO:root:At the start of the epoch: mem (CPU python)=27787.78125MB; mem (CPU total)=27733.640625MB
INFO:root:[  143] Training loss: 0.61412075, Validation loss: 0.60722749, Gradient norm: 0.04836195
INFO:root:At the start of the epoch: mem (CPU python)=27863.37890625MB; mem (CPU total)=27809.6484375MB
INFO:root:[  144] Training loss: 0.61403525, Validation loss: 0.60734449, Gradient norm: 0.04830506
INFO:root:At the start of the epoch: mem (CPU python)=27913.97265625MB; mem (CPU total)=27859.80859375MB
INFO:root:[  145] Training loss: 0.61421864, Validation loss: 0.60730056, Gradient norm: 0.04978317
INFO:root:At the start of the epoch: mem (CPU python)=27914.375MB; mem (CPU total)=27848.07421875MB
INFO:root:[  146] Training loss: 0.61426757, Validation loss: 0.60743267, Gradient norm: 0.05044703
INFO:root:At the start of the epoch: mem (CPU python)=27952.66015625MB; mem (CPU total)=27898.703125MB
INFO:root:[  147] Training loss: 0.61426929, Validation loss: 0.60767529, Gradient norm: 0.04993662
INFO:root:At the start of the epoch: mem (CPU python)=28015.7578125MB; mem (CPU total)=27962.3515625MB
INFO:root:[  148] Training loss: 0.61415990, Validation loss: 0.60723093, Gradient norm: 0.05173271
INFO:root:At the start of the epoch: mem (CPU python)=28028.8515625MB; mem (CPU total)=27975.046875MB
INFO:root:[  149] Training loss: 0.61404840, Validation loss: 0.60657904, Gradient norm: 0.04962993
INFO:root:At the start of the epoch: mem (CPU python)=28091.9453125MB; mem (CPU total)=28038.44921875MB
INFO:root:[  150] Training loss: 0.61400745, Validation loss: 0.60702636, Gradient norm: 0.04889649
INFO:root:At the start of the epoch: mem (CPU python)=28092.39453125MB; mem (CPU total)=28013.7421875MB
INFO:root:[  151] Training loss: 0.61401741, Validation loss: 0.60706392, Gradient norm: 0.05019408
INFO:root:At the start of the epoch: mem (CPU python)=28130.640625MB; mem (CPU total)=28075.875MB
INFO:root:[  152] Training loss: 0.61404273, Validation loss: 0.60723476, Gradient norm: 0.04917241
INFO:root:At the start of the epoch: mem (CPU python)=28168.734375MB; mem (CPU total)=28114.29296875MB
INFO:root:[  153] Training loss: 0.61390864, Validation loss: 0.60679351, Gradient norm: 0.04896989
INFO:root:At the start of the epoch: mem (CPU python)=28231.85546875MB; mem (CPU total)=28177.40625MB
INFO:root:[  154] Training loss: 0.61397514, Validation loss: 0.60722465, Gradient norm: 0.04967603
INFO:root:At the start of the epoch: mem (CPU python)=28307.42578125MB; mem (CPU total)=28253.484375MB
INFO:root:[  155] Training loss: 0.61404334, Validation loss: 0.60770705, Gradient norm: 0.04899548
INFO:root:At the start of the epoch: mem (CPU python)=28338.3046875MB; mem (CPU total)=28216.578125MB
INFO:root:[  156] Training loss: 0.61406788, Validation loss: 0.60716398, Gradient norm: 0.05044163
INFO:root:At the start of the epoch: mem (CPU python)=28338.3046875MB; mem (CPU total)=28266.46484375MB
INFO:root:[  157] Training loss: 0.61403676, Validation loss: 0.60704815, Gradient norm: 0.05109318
INFO:root:At the start of the epoch: mem (CPU python)=28371.7109375MB; mem (CPU total)=28318.21875MB
INFO:root:[  158] Training loss: 0.61387979, Validation loss: 0.60697914, Gradient norm: 0.04997464
INFO:root:At the start of the epoch: mem (CPU python)=28402.578125MB; mem (CPU total)=28318.71875MB
INFO:root:EP 158: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=28460.42578125MB; mem (CPU total)=28406.5390625MB
INFO:root:Training the model took 10249.532s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84542
INFO:root:EnergyScoreTrain: 0.59514
INFO:root:CRPSTrain: 0.46154
INFO:root:Gaussian NLLTrain: 1.1858
INFO:root:CoverageTrain: 0.95041
INFO:root:IntervalWidthTrain: 3.26221
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86258
INFO:root:EnergyScoreValidation: 0.60714
INFO:root:CRPSValidation: 0.47171
INFO:root:Gaussian NLLValidation: 1.20826
INFO:root:CoverageValidation: 0.94472
INFO:root:IntervalWidthValidation: 3.26349
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86329
INFO:root:EnergyScoreTest: 0.60761
INFO:root:CRPSTest: 0.47223
INFO:root:Gaussian NLLTest: 1.20964
INFO:root:CoverageTest: 0.94481
INFO:root:IntervalWidthTest: 3.26588
INFO:root:After validation: mem (CPU python)=28503.40625MB; mem (CPU total)=28447.76953125MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=28503.40625MB; mem (CPU total)=28447.76953125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=28503.66796875MB; mem (CPU total)=28448.26171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=28503.80859375MB; mem (CPU total)=28448.26171875MB
INFO:root:[    1] Training loss: 0.72495416, Validation loss: 0.72075935, Gradient norm: 0.01807595
INFO:root:At the start of the epoch: mem (CPU python)=28519.9765625MB; mem (CPU total)=28466.29296875MB
INFO:root:[    2] Training loss: 0.71931889, Validation loss: 0.71728350, Gradient norm: 0.00646854
INFO:root:At the start of the epoch: mem (CPU python)=28583.08203125MB; mem (CPU total)=28529.7734375MB
INFO:root:[    3] Training loss: 0.71363173, Validation loss: 0.70695411, Gradient norm: 0.01439162
INFO:root:At the start of the epoch: mem (CPU python)=28614.09765625MB; mem (CPU total)=28555.45703125MB
INFO:root:[    4] Training loss: 0.70643184, Validation loss: 0.70072726, Gradient norm: 0.02066771
INFO:root:At the start of the epoch: mem (CPU python)=28646.765625MB; mem (CPU total)=28593.30859375MB
INFO:root:[    5] Training loss: 0.70064766, Validation loss: 0.69420362, Gradient norm: 0.02638290
INFO:root:At the start of the epoch: mem (CPU python)=28672.36328125MB; mem (CPU total)=28618.75MB
INFO:root:[    6] Training loss: 0.69511090, Validation loss: 0.68684676, Gradient norm: 0.02653296
INFO:root:At the start of the epoch: mem (CPU python)=28746.61328125MB; mem (CPU total)=28644.6171875MB
INFO:root:[    7] Training loss: 0.68955368, Validation loss: 0.68123651, Gradient norm: 0.02961755
INFO:root:At the start of the epoch: mem (CPU python)=28761.0546875MB; mem (CPU total)=28707.7421875MB
INFO:root:[    8] Training loss: 0.68459925, Validation loss: 0.67577515, Gradient norm: 0.02859205
INFO:root:At the start of the epoch: mem (CPU python)=28811.6484375MB; mem (CPU total)=28758.83984375MB
INFO:root:[    9] Training loss: 0.68063457, Validation loss: 0.67180906, Gradient norm: 0.02905357
INFO:root:At the start of the epoch: mem (CPU python)=28849.74609375MB; mem (CPU total)=28796.73828125MB
INFO:root:[   10] Training loss: 0.67680536, Validation loss: 0.66773303, Gradient norm: 0.03035282
INFO:root:At the start of the epoch: mem (CPU python)=28862.83984375MB; mem (CPU total)=28809.67578125MB
INFO:root:[   11] Training loss: 0.67326310, Validation loss: 0.66425660, Gradient norm: 0.02986814
INFO:root:At the start of the epoch: mem (CPU python)=28900.93359375MB; mem (CPU total)=28848.06640625MB
INFO:root:[   12] Training loss: 0.67040355, Validation loss: 0.66072489, Gradient norm: 0.03017553
INFO:root:At the start of the epoch: mem (CPU python)=28939.03125MB; mem (CPU total)=28886.2421875MB
INFO:root:[   13] Training loss: 0.66791413, Validation loss: 0.65764282, Gradient norm: 0.03135226
INFO:root:At the start of the epoch: mem (CPU python)=29014.625MB; mem (CPU total)=28961.7265625MB
INFO:root:[   14] Training loss: 0.66569274, Validation loss: 0.65540382, Gradient norm: 0.03217792
INFO:root:At the start of the epoch: mem (CPU python)=29027.71875MB; mem (CPU total)=28974.75MB
INFO:root:[   15] Training loss: 0.66374149, Validation loss: 0.65277857, Gradient norm: 0.03625432
INFO:root:At the start of the epoch: mem (CPU python)=29090.81640625MB; mem (CPU total)=29038.0MB
INFO:root:[   16] Training loss: 0.66168785, Validation loss: 0.65223261, Gradient norm: 0.03449146
INFO:root:At the start of the epoch: mem (CPU python)=29128.9140625MB; mem (CPU total)=29076.17578125MB
INFO:root:[   17] Training loss: 0.65999025, Validation loss: 0.64931839, Gradient norm: 0.03283514
INFO:root:At the start of the epoch: mem (CPU python)=29129.55078125MB; mem (CPU total)=29076.4453125MB
INFO:root:[   18] Training loss: 0.65853494, Validation loss: 0.64817020, Gradient norm: 0.03500612
INFO:root:At the start of the epoch: mem (CPU python)=29192.6015625MB; mem (CPU total)=29140.03515625MB
INFO:root:[   19] Training loss: 0.65689777, Validation loss: 0.64560003, Gradient norm: 0.03616856
INFO:root:At the start of the epoch: mem (CPU python)=29205.69921875MB; mem (CPU total)=29153.25MB
INFO:root:[   20] Training loss: 0.65556449, Validation loss: 0.64436858, Gradient norm: 0.03966284
INFO:root:At the start of the epoch: mem (CPU python)=29243.79296875MB; mem (CPU total)=29191.671875MB
INFO:root:[   21] Training loss: 0.65436701, Validation loss: 0.64369860, Gradient norm: 0.03559954
INFO:root:At the start of the epoch: mem (CPU python)=29319.38671875MB; mem (CPU total)=29267.43359375MB
INFO:root:[   22] Training loss: 0.65297929, Validation loss: 0.64251018, Gradient norm: 0.04076538
INFO:root:At the start of the epoch: mem (CPU python)=29332.48828125MB; mem (CPU total)=29279.7421875MB
INFO:root:[   23] Training loss: 0.65184809, Validation loss: 0.64082403, Gradient norm: 0.04061726
INFO:root:At the start of the epoch: mem (CPU python)=29395.5859375MB; mem (CPU total)=29343.1015625MB
INFO:root:[   24] Training loss: 0.65073254, Validation loss: 0.63931348, Gradient norm: 0.04194320
INFO:root:At the start of the epoch: mem (CPU python)=29408.6796875MB; mem (CPU total)=29355.828125MB
INFO:root:[   25] Training loss: 0.64990022, Validation loss: 0.63863788, Gradient norm: 0.04546319
INFO:root:At the start of the epoch: mem (CPU python)=29445.85546875MB; mem (CPU total)=29368.73046875MB
INFO:root:[   26] Training loss: 0.64843238, Validation loss: 0.63766141, Gradient norm: 0.03962569
INFO:root:At the start of the epoch: mem (CPU python)=29509.8671875MB; mem (CPU total)=29457.30078125MB
INFO:root:[   27] Training loss: 0.64761776, Validation loss: 0.63605703, Gradient norm: 0.04347096
INFO:root:At the start of the epoch: mem (CPU python)=29547.96484375MB; mem (CPU total)=29495.45703125MB
INFO:root:[   28] Training loss: 0.64674424, Validation loss: 0.63616632, Gradient norm: 0.04671193
INFO:root:At the start of the epoch: mem (CPU python)=29548.55859375MB; mem (CPU total)=29495.94140625MB
INFO:root:[   29] Training loss: 0.64574503, Validation loss: 0.63424564, Gradient norm: 0.04426142
INFO:root:At the start of the epoch: mem (CPU python)=29636.65625MB; mem (CPU total)=29584.48046875MB
INFO:root:[   30] Training loss: 0.64501846, Validation loss: 0.63303045, Gradient norm: 0.04203993
INFO:root:At the start of the epoch: mem (CPU python)=29637.25MB; mem (CPU total)=29584.77734375MB
INFO:root:[   31] Training loss: 0.64428254, Validation loss: 0.63272312, Gradient norm: 0.05052299
INFO:root:At the start of the epoch: mem (CPU python)=29662.84375MB; mem (CPU total)=29610.2421875MB
INFO:root:[   32] Training loss: 0.64362146, Validation loss: 0.63158583, Gradient norm: 0.04714904
INFO:root:At the start of the epoch: mem (CPU python)=29700.94140625MB; mem (CPU total)=29648.7734375MB
INFO:root:[   33] Training loss: 0.64284092, Validation loss: 0.63142188, Gradient norm: 0.05010316
INFO:root:At the start of the epoch: mem (CPU python)=29751.53515625MB; mem (CPU total)=29699.796875MB
INFO:root:[   34] Training loss: 0.64173792, Validation loss: 0.63088753, Gradient norm: 0.04922921
INFO:root:At the start of the epoch: mem (CPU python)=29789.6328125MB; mem (CPU total)=29737.57421875MB
INFO:root:[   35] Training loss: 0.64142682, Validation loss: 0.63023542, Gradient norm: 0.05683834
INFO:root:At the start of the epoch: mem (CPU python)=29840.2265625MB; mem (CPU total)=29788.17578125MB
INFO:root:[   36] Training loss: 0.64065351, Validation loss: 0.62891918, Gradient norm: 0.04369100
INFO:root:At the start of the epoch: mem (CPU python)=29871.73046875MB; mem (CPU total)=29801.453125MB
INFO:root:[   37] Training loss: 0.63992014, Validation loss: 0.62950587, Gradient norm: 0.04847921
INFO:root:At the start of the epoch: mem (CPU python)=29891.41796875MB; mem (CPU total)=29839.59375MB
INFO:root:[   38] Training loss: 0.63955991, Validation loss: 0.62767555, Gradient norm: 0.05557701
INFO:root:At the start of the epoch: mem (CPU python)=29942.01171875MB; mem (CPU total)=29890.50390625MB
INFO:root:[   39] Training loss: 0.63869461, Validation loss: 0.62788205, Gradient norm: 0.04693027
INFO:root:At the start of the epoch: mem (CPU python)=29980.109375MB; mem (CPU total)=29928.859375MB
INFO:root:[   40] Training loss: 0.63810216, Validation loss: 0.62746688, Gradient norm: 0.04557849
INFO:root:At the start of the epoch: mem (CPU python)=30018.203125MB; mem (CPU total)=29966.44921875MB
INFO:root:[   41] Training loss: 0.63743655, Validation loss: 0.62630369, Gradient norm: 0.05279343
INFO:root:At the start of the epoch: mem (CPU python)=30056.30078125MB; mem (CPU total)=30004.87890625MB
INFO:root:[   42] Training loss: 0.63720672, Validation loss: 0.62636190, Gradient norm: 0.04921132
INFO:root:At the start of the epoch: mem (CPU python)=30106.89453125MB; mem (CPU total)=30055.51171875MB
INFO:root:[   43] Training loss: 0.63634407, Validation loss: 0.62499366, Gradient norm: 0.05268262
INFO:root:At the start of the epoch: mem (CPU python)=30132.4921875MB; mem (CPU total)=30081.2890625MB
INFO:root:[   44] Training loss: 0.63609604, Validation loss: 0.62529033, Gradient norm: 0.05477737
INFO:root:At the start of the epoch: mem (CPU python)=30183.0859375MB; mem (CPU total)=30132.140625MB
INFO:root:[   45] Training loss: 0.63548031, Validation loss: 0.62432044, Gradient norm: 0.05269549
INFO:root:At the start of the epoch: mem (CPU python)=30208.6796875MB; mem (CPU total)=30157.33203125MB
INFO:root:[   46] Training loss: 0.63501604, Validation loss: 0.62511870, Gradient norm: 0.05159025
INFO:root:At the start of the epoch: mem (CPU python)=30259.27734375MB; mem (CPU total)=30208.18359375MB
INFO:root:[   47] Training loss: 0.63444526, Validation loss: 0.62273587, Gradient norm: 0.05219149
INFO:root:At the start of the epoch: mem (CPU python)=30284.87109375MB; mem (CPU total)=30234.10546875MB
INFO:root:[   48] Training loss: 0.63403473, Validation loss: 0.62306403, Gradient norm: 0.05716228
INFO:root:At the start of the epoch: mem (CPU python)=30335.46875MB; mem (CPU total)=30284.74609375MB
INFO:root:[   49] Training loss: 0.63333368, Validation loss: 0.62298560, Gradient norm: 0.05344490
INFO:root:At the start of the epoch: mem (CPU python)=30348.5625MB; mem (CPU total)=30297.9296875MB
INFO:root:[   50] Training loss: 0.63294673, Validation loss: 0.62207675, Gradient norm: 0.05786330
INFO:root:At the start of the epoch: mem (CPU python)=30386.66015625MB; mem (CPU total)=30336.07421875MB
INFO:root:[   51] Training loss: 0.63253758, Validation loss: 0.62188831, Gradient norm: 0.05567594
INFO:root:At the start of the epoch: mem (CPU python)=30437.25390625MB; mem (CPU total)=30386.92578125MB
INFO:root:[   52] Training loss: 0.63220891, Validation loss: 0.62070180, Gradient norm: 0.05730676
INFO:root:At the start of the epoch: mem (CPU python)=30475.34765625MB; mem (CPU total)=30424.85546875MB
INFO:root:[   53] Training loss: 0.63169078, Validation loss: 0.62020381, Gradient norm: 0.05565025
INFO:root:At the start of the epoch: mem (CPU python)=30500.9453125MB; mem (CPU total)=30450.0390625MB
INFO:root:[   54] Training loss: 0.63135680, Validation loss: 0.62132837, Gradient norm: 0.05411371
INFO:root:At the start of the epoch: mem (CPU python)=30564.0390625MB; mem (CPU total)=30513.56640625MB
INFO:root:[   55] Training loss: 0.63092517, Validation loss: 0.62070792, Gradient norm: 0.06050402
INFO:root:At the start of the epoch: mem (CPU python)=30599.21875MB; mem (CPU total)=30489.12890625MB
INFO:root:[   56] Training loss: 0.63057260, Validation loss: 0.62029045, Gradient norm: 0.05800980
INFO:root:At the start of the epoch: mem (CPU python)=30615.23046875MB; mem (CPU total)=30564.93359375MB
INFO:root:[   57] Training loss: 0.63029656, Validation loss: 0.61928846, Gradient norm: 0.05244608
INFO:root:At the start of the epoch: mem (CPU python)=30690.828125MB; mem (CPU total)=30640.47265625MB
INFO:root:[   58] Training loss: 0.62999712, Validation loss: 0.61989205, Gradient norm: 0.06462108
INFO:root:At the start of the epoch: mem (CPU python)=30728.92578125MB; mem (CPU total)=30678.6171875MB
INFO:root:[   59] Training loss: 0.62952631, Validation loss: 0.61892611, Gradient norm: 0.05794300
INFO:root:At the start of the epoch: mem (CPU python)=30729.515625MB; mem (CPU total)=30679.1640625MB
INFO:root:[   60] Training loss: 0.62922578, Validation loss: 0.61829106, Gradient norm: 0.05438826
INFO:root:At the start of the epoch: mem (CPU python)=30780.11328125MB; mem (CPU total)=30729.76953125MB
INFO:root:[   61] Training loss: 0.62869932, Validation loss: 0.61850673, Gradient norm: 0.05471152
INFO:root:At the start of the epoch: mem (CPU python)=30818.2109375MB; mem (CPU total)=30768.0390625MB
INFO:root:[   62] Training loss: 0.62863299, Validation loss: 0.61890738, Gradient norm: 0.06024024
INFO:root:At the start of the epoch: mem (CPU python)=30849.2265625MB; mem (CPU total)=30781.22265625MB
INFO:root:[   63] Training loss: 0.62799481, Validation loss: 0.61885858, Gradient norm: 0.05784801
INFO:root:At the start of the epoch: mem (CPU python)=30894.40234375MB; mem (CPU total)=30844.2890625MB
INFO:root:[   64] Training loss: 0.62785316, Validation loss: 0.61807495, Gradient norm: 0.06360782
INFO:root:At the start of the epoch: mem (CPU python)=30944.99609375MB; mem (CPU total)=30895.140625MB
INFO:root:[   65] Training loss: 0.62744159, Validation loss: 0.61728887, Gradient norm: 0.05736784
INFO:root:At the start of the epoch: mem (CPU python)=30983.08984375MB; mem (CPU total)=30933.5390625MB
INFO:root:[   66] Training loss: 0.62698001, Validation loss: 0.61663464, Gradient norm: 0.05294301
INFO:root:At the start of the epoch: mem (CPU python)=31021.1875MB; mem (CPU total)=30971.56640625MB
INFO:root:[   67] Training loss: 0.62686702, Validation loss: 0.61638123, Gradient norm: 0.06252045
INFO:root:At the start of the epoch: mem (CPU python)=31051.66796875MB; mem (CPU total)=30997.03515625MB
INFO:root:[   68] Training loss: 0.62639711, Validation loss: 0.61586635, Gradient norm: 0.05664605
INFO:root:At the start of the epoch: mem (CPU python)=31097.3828125MB; mem (CPU total)=31047.8515625MB
INFO:root:[   69] Training loss: 0.62616320, Validation loss: 0.61627939, Gradient norm: 0.06168244
INFO:root:At the start of the epoch: mem (CPU python)=31135.4765625MB; mem (CPU total)=31086.2421875MB
INFO:root:[   70] Training loss: 0.62562796, Validation loss: 0.61525047, Gradient norm: 0.05467042
INFO:root:At the start of the epoch: mem (CPU python)=31148.57421875MB; mem (CPU total)=31099.25MB
INFO:root:[   71] Training loss: 0.62579940, Validation loss: 0.61574643, Gradient norm: 0.05880368
INFO:root:At the start of the epoch: mem (CPU python)=31199.16796875MB; mem (CPU total)=31150.1015625MB
INFO:root:[   72] Training loss: 0.62537790, Validation loss: 0.61573969, Gradient norm: 0.05693713
INFO:root:At the start of the epoch: mem (CPU python)=31224.765625MB; mem (CPU total)=31175.53125MB
INFO:root:[   73] Training loss: 0.62506207, Validation loss: 0.61503571, Gradient norm: 0.05798203
INFO:root:At the start of the epoch: mem (CPU python)=31275.36328125MB; mem (CPU total)=31226.62109375MB
INFO:root:[   74] Training loss: 0.62454004, Validation loss: 0.61553762, Gradient norm: 0.06169493
INFO:root:At the start of the epoch: mem (CPU python)=31325.953125MB; mem (CPU total)=31277.05078125MB
INFO:root:[   75] Training loss: 0.62468261, Validation loss: 0.61488808, Gradient norm: 0.06211115
INFO:root:At the start of the epoch: mem (CPU python)=31349.69140625MB; mem (CPU total)=31253.13671875MB
INFO:root:[   76] Training loss: 0.62409336, Validation loss: 0.61529272, Gradient norm: 0.05575670
INFO:root:At the start of the epoch: mem (CPU python)=31377.14453125MB; mem (CPU total)=31328.671875MB
INFO:root:[   77] Training loss: 0.62376962, Validation loss: 0.61459638, Gradient norm: 0.05930461
INFO:root:At the start of the epoch: mem (CPU python)=31427.7421875MB; mem (CPU total)=31379.53125MB
INFO:root:[   78] Training loss: 0.62357571, Validation loss: 0.61382687, Gradient norm: 0.05623233
INFO:root:At the start of the epoch: mem (CPU python)=31440.8359375MB; mem (CPU total)=31392.46875MB
INFO:root:[   79] Training loss: 0.62326264, Validation loss: 0.61377706, Gradient norm: 0.05119949
INFO:root:At the start of the epoch: mem (CPU python)=31478.9296875MB; mem (CPU total)=31430.7890625MB
INFO:root:[   80] Training loss: 0.62318115, Validation loss: 0.61333755, Gradient norm: 0.06012495
INFO:root:At the start of the epoch: mem (CPU python)=31517.02734375MB; mem (CPU total)=31468.91796875MB
INFO:root:[   81] Training loss: 0.62296221, Validation loss: 0.61294954, Gradient norm: 0.06087892
INFO:root:At the start of the epoch: mem (CPU python)=31580.12109375MB; mem (CPU total)=31532.0703125MB
INFO:root:[   82] Training loss: 0.62287656, Validation loss: 0.61230144, Gradient norm: 0.06511419
INFO:root:At the start of the epoch: mem (CPU python)=31593.21484375MB; mem (CPU total)=31545.91796875MB
INFO:root:[   83] Training loss: 0.62244186, Validation loss: 0.61303922, Gradient norm: 0.05858332
INFO:root:At the start of the epoch: mem (CPU python)=31631.3125MB; mem (CPU total)=31584.046875MB
INFO:root:[   84] Training loss: 0.62233101, Validation loss: 0.61341135, Gradient norm: 0.06616267
INFO:root:At the start of the epoch: mem (CPU python)=31694.41015625MB; mem (CPU total)=31647.328125MB
INFO:root:[   85] Training loss: 0.62198314, Validation loss: 0.61248483, Gradient norm: 0.06120926
INFO:root:At the start of the epoch: mem (CPU python)=31720.00390625MB; mem (CPU total)=31672.765625MB
INFO:root:[   86] Training loss: 0.62176154, Validation loss: 0.61244648, Gradient norm: 0.05821057
INFO:root:At the start of the epoch: mem (CPU python)=31783.09765625MB; mem (CPU total)=31736.046875MB
INFO:root:[   87] Training loss: 0.62147090, Validation loss: 0.61158488, Gradient norm: 0.06053406
INFO:root:At the start of the epoch: mem (CPU python)=31813.984375MB; mem (CPU total)=31749.296875MB
INFO:root:[   88] Training loss: 0.62107679, Validation loss: 0.61168498, Gradient norm: 0.06519416
INFO:root:At the start of the epoch: mem (CPU python)=31859.2421875MB; mem (CPU total)=31750.76171875MB
INFO:root:[   89] Training loss: 0.62115787, Validation loss: 0.61233093, Gradient norm: 0.06872615
INFO:root:At the start of the epoch: mem (CPU python)=31872.3828125MB; mem (CPU total)=31825.58203125MB
INFO:root:[   90] Training loss: 0.62073360, Validation loss: 0.61232546, Gradient norm: 0.06127611
INFO:root:At the start of the epoch: mem (CPU python)=31910.48046875MB; mem (CPU total)=31863.88671875MB
INFO:root:[   91] Training loss: 0.62042286, Validation loss: 0.61188519, Gradient norm: 0.05849928
INFO:root:At the start of the epoch: mem (CPU python)=31948.578125MB; mem (CPU total)=31902.21484375MB
INFO:root:[   92] Training loss: 0.62012704, Validation loss: 0.61087822, Gradient norm: 0.06340840
INFO:root:At the start of the epoch: mem (CPU python)=31999.171875MB; mem (CPU total)=31953.08203125MB
INFO:root:[   93] Training loss: 0.62022176, Validation loss: 0.61110904, Gradient norm: 0.05868753
INFO:root:At the start of the epoch: mem (CPU python)=32037.265625MB; mem (CPU total)=31990.98046875MB
INFO:root:[   94] Training loss: 0.62015161, Validation loss: 0.61047299, Gradient norm: 0.06198764
INFO:root:At the start of the epoch: mem (CPU python)=32037.86328125MB; mem (CPU total)=31991.60546875MB
INFO:root:[   95] Training loss: 0.61984028, Validation loss: 0.61041503, Gradient norm: 0.06186965
INFO:root:At the start of the epoch: mem (CPU python)=32138.45703125MB; mem (CPU total)=32092.62890625MB
INFO:root:[   96] Training loss: 0.61971611, Validation loss: 0.61005979, Gradient norm: 0.06618019
INFO:root:At the start of the epoch: mem (CPU python)=32176.55078125MB; mem (CPU total)=32131.046875MB
INFO:root:[   97] Training loss: 0.61938588, Validation loss: 0.61051044, Gradient norm: 0.07029714
INFO:root:At the start of the epoch: mem (CPU python)=32177.1484375MB; mem (CPU total)=32131.34375MB
INFO:root:[   98] Training loss: 0.61899405, Validation loss: 0.61000704, Gradient norm: 0.06209584
INFO:root:At the start of the epoch: mem (CPU python)=32215.2421875MB; mem (CPU total)=32169.78515625MB
INFO:root:[   99] Training loss: 0.61918604, Validation loss: 0.60979396, Gradient norm: 0.06566909
INFO:root:At the start of the epoch: mem (CPU python)=32265.8359375MB; mem (CPU total)=32220.0625MB
INFO:root:[  100] Training loss: 0.61883001, Validation loss: 0.61015045, Gradient norm: 0.06232250
INFO:root:At the start of the epoch: mem (CPU python)=32328.9296875MB; mem (CPU total)=32283.39453125MB
INFO:root:[  101] Training loss: 0.61849146, Validation loss: 0.61067895, Gradient norm: 0.06360373
INFO:root:At the start of the epoch: mem (CPU python)=32329.13671875MB; mem (CPU total)=32259.23046875MB
INFO:root:[  102] Training loss: 0.61849462, Validation loss: 0.60982737, Gradient norm: 0.06182074
INFO:root:At the start of the epoch: mem (CPU python)=32367.625MB; mem (CPU total)=32322.078125MB
INFO:root:[  103] Training loss: 0.61839333, Validation loss: 0.60893255, Gradient norm: 0.06991189
INFO:root:At the start of the epoch: mem (CPU python)=32405.71875MB; mem (CPU total)=32360.859375MB
INFO:root:[  104] Training loss: 0.61787717, Validation loss: 0.60933453, Gradient norm: 0.06559627
INFO:root:At the start of the epoch: mem (CPU python)=32443.81640625MB; mem (CPU total)=32399.0234375MB
INFO:root:[  105] Training loss: 0.61785669, Validation loss: 0.60935930, Gradient norm: 0.06561561
INFO:root:At the start of the epoch: mem (CPU python)=32494.41015625MB; mem (CPU total)=32449.234375MB
INFO:root:[  106] Training loss: 0.61766842, Validation loss: 0.61009775, Gradient norm: 0.06527289
INFO:root:At the start of the epoch: mem (CPU python)=32532.50390625MB; mem (CPU total)=32487.37890625MB
INFO:root:[  107] Training loss: 0.61753187, Validation loss: 0.61032892, Gradient norm: 0.06271144
INFO:root:At the start of the epoch: mem (CPU python)=32570.6015625MB; mem (CPU total)=32525.37109375MB
INFO:root:[  108] Training loss: 0.61704418, Validation loss: 0.60963059, Gradient norm: 0.06265047
INFO:root:At the start of the epoch: mem (CPU python)=32596.19921875MB; mem (CPU total)=32551.04296875MB
INFO:root:[  109] Training loss: 0.61699041, Validation loss: 0.60916810, Gradient norm: 0.06149507
INFO:root:At the start of the epoch: mem (CPU python)=32659.296875MB; mem (CPU total)=32614.35546875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  110] Training loss: 0.61673933, Validation loss: 0.60801803, Gradient norm: 0.06556944
INFO:root:At the start of the epoch: mem (CPU python)=32684.890625MB; mem (CPU total)=32639.82421875MB
INFO:root:[  111] Training loss: 0.61619276, Validation loss: 0.60779072, Gradient norm: 0.06103358
INFO:root:At the start of the epoch: mem (CPU python)=32697.98828125MB; mem (CPU total)=32653.015625MB
INFO:root:[  112] Training loss: 0.61569680, Validation loss: 0.60768550, Gradient norm: 0.05923283
INFO:root:At the start of the epoch: mem (CPU python)=32773.58203125MB; mem (CPU total)=32728.8515625MB
INFO:root:[  113] Training loss: 0.61559949, Validation loss: 0.60741446, Gradient norm: 0.05910528
INFO:root:At the start of the epoch: mem (CPU python)=32811.67578125MB; mem (CPU total)=32766.99609375MB
INFO:root:[  114] Training loss: 0.61546899, Validation loss: 0.60845753, Gradient norm: 0.05827540
INFO:root:At the start of the epoch: mem (CPU python)=32824.7734375MB; mem (CPU total)=32780.21875MB
INFO:root:[  115] Training loss: 0.61549884, Validation loss: 0.60821780, Gradient norm: 0.05691440
INFO:root:At the start of the epoch: mem (CPU python)=32875.3671875MB; mem (CPU total)=32830.81640625MB
INFO:root:[  116] Training loss: 0.61531178, Validation loss: 0.60748590, Gradient norm: 0.05660904
INFO:root:At the start of the epoch: mem (CPU python)=32925.96484375MB; mem (CPU total)=32881.65234375MB
INFO:root:[  117] Training loss: 0.61511355, Validation loss: 0.60763947, Gradient norm: 0.06410793
INFO:root:At the start of the epoch: mem (CPU python)=32926.55859375MB; mem (CPU total)=32882.3515625MB
INFO:root:[  118] Training loss: 0.61491297, Validation loss: 0.60811505, Gradient norm: 0.05565829
INFO:root:At the start of the epoch: mem (CPU python)=32977.15625MB; mem (CPU total)=32932.7421875MB
INFO:root:[  119] Training loss: 0.61520253, Validation loss: 0.60720373, Gradient norm: 0.06716500
INFO:root:At the start of the epoch: mem (CPU python)=33015.25MB; mem (CPU total)=32971.125MB
INFO:root:[  120] Training loss: 0.61469241, Validation loss: 0.60713802, Gradient norm: 0.05568466
INFO:root:At the start of the epoch: mem (CPU python)=33053.34375MB; mem (CPU total)=33009.4375MB
INFO:root:[  121] Training loss: 0.61469363, Validation loss: 0.60796318, Gradient norm: 0.05954977
INFO:root:At the start of the epoch: mem (CPU python)=33128.94140625MB; mem (CPU total)=33085.12109375MB
INFO:root:[  122] Training loss: 0.61454686, Validation loss: 0.60685893, Gradient norm: 0.06303220
INFO:root:At the start of the epoch: mem (CPU python)=33167.03515625MB; mem (CPU total)=33061.17578125MB
INFO:root:[  123] Training loss: 0.61453648, Validation loss: 0.60779629, Gradient norm: 0.06189382
INFO:root:At the start of the epoch: mem (CPU python)=33167.03515625MB; mem (CPU total)=33099.3125MB
INFO:root:[  124] Training loss: 0.61473613, Validation loss: 0.60763269, Gradient norm: 0.05966799
INFO:root:At the start of the epoch: mem (CPU python)=33218.2265625MB; mem (CPU total)=33175.0703125MB
INFO:root:[  125] Training loss: 0.61442069, Validation loss: 0.60751485, Gradient norm: 0.05881482
INFO:root:At the start of the epoch: mem (CPU python)=33256.3203125MB; mem (CPU total)=33212.96875MB
INFO:root:[  126] Training loss: 0.61441164, Validation loss: 0.60710324, Gradient norm: 0.06055005
INFO:root:At the start of the epoch: mem (CPU python)=33287.56640625MB; mem (CPU total)=33226.12890625MB
INFO:root:[  127] Training loss: 0.61433892, Validation loss: 0.60771259, Gradient norm: 0.05866686
INFO:root:At the start of the epoch: mem (CPU python)=33345.01171875MB; mem (CPU total)=33301.6875MB
INFO:root:[  128] Training loss: 0.61423359, Validation loss: 0.60712374, Gradient norm: 0.06139757
INFO:root:At the start of the epoch: mem (CPU python)=33383.109375MB; mem (CPU total)=33340.05859375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  129] Training loss: 0.61414567, Validation loss: 0.60635721, Gradient norm: 0.05562147
INFO:root:At the start of the epoch: mem (CPU python)=33396.203125MB; mem (CPU total)=33353.09765625MB
INFO:root:[  130] Training loss: 0.61341407, Validation loss: 0.60601273, Gradient norm: 0.05546177
INFO:root:At the start of the epoch: mem (CPU python)=33446.796875MB; mem (CPU total)=33404.2578125MB
INFO:root:[  131] Training loss: 0.61339816, Validation loss: 0.60695825, Gradient norm: 0.05705343
INFO:root:At the start of the epoch: mem (CPU python)=33472.39453125MB; mem (CPU total)=33429.97265625MB
INFO:root:[  132] Training loss: 0.61335622, Validation loss: 0.60607525, Gradient norm: 0.05603855
INFO:root:At the start of the epoch: mem (CPU python)=33522.98828125MB; mem (CPU total)=33480.4296875MB
INFO:root:[  133] Training loss: 0.61321607, Validation loss: 0.60638075, Gradient norm: 0.05312274
INFO:root:At the start of the epoch: mem (CPU python)=33573.5859375MB; mem (CPU total)=33530.96484375MB
INFO:root:[  134] Training loss: 0.61338899, Validation loss: 0.60677490, Gradient norm: 0.05522877
INFO:root:At the start of the epoch: mem (CPU python)=33604.0625MB; mem (CPU total)=33556.5859375MB
INFO:root:[  135] Training loss: 0.61316766, Validation loss: 0.60589881, Gradient norm: 0.05451008
INFO:root:At the start of the epoch: mem (CPU python)=33649.77734375MB; mem (CPU total)=33607.19140625MB
INFO:root:[  136] Training loss: 0.61328259, Validation loss: 0.60708035, Gradient norm: 0.06138368
INFO:root:At the start of the epoch: mem (CPU python)=33687.87109375MB; mem (CPU total)=33645.58203125MB
INFO:root:[  137] Training loss: 0.61308484, Validation loss: 0.60619613, Gradient norm: 0.05451052
INFO:root:At the start of the epoch: mem (CPU python)=33700.96484375MB; mem (CPU total)=33658.55859375MB
INFO:root:[  138] Training loss: 0.61254617, Validation loss: 0.60594197, Gradient norm: 0.05556105
INFO:root:At the start of the epoch: mem (CPU python)=33751.5625MB; mem (CPU total)=33709.41015625MB
INFO:root:[  139] Training loss: 0.61310946, Validation loss: 0.60645808, Gradient norm: 0.05659217
INFO:root:At the start of the epoch: mem (CPU python)=33789.65625MB; mem (CPU total)=33748.0703125MB
INFO:root:[  140] Training loss: 0.61303943, Validation loss: 0.60651459, Gradient norm: 0.05594533
INFO:root:At the start of the epoch: mem (CPU python)=33827.75MB; mem (CPU total)=33785.3359375MB
INFO:root:[  141] Training loss: 0.61287700, Validation loss: 0.60611343, Gradient norm: 0.05776943
INFO:root:At the start of the epoch: mem (CPU python)=33865.8515625MB; mem (CPU total)=33823.48046875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  142] Training loss: 0.61310103, Validation loss: 0.60599468, Gradient norm: 0.05416179
INFO:root:At the start of the epoch: mem (CPU python)=33903.9453125MB; mem (CPU total)=33861.87109375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  143] Training loss: 0.61260130, Validation loss: 0.60632341, Gradient norm: 0.05428771
INFO:root:At the start of the epoch: mem (CPU python)=33942.0390625MB; mem (CPU total)=33899.76953125MB
INFO:root:[  144] Training loss: 0.61245918, Validation loss: 0.60628805, Gradient norm: 0.05184346
INFO:root:At the start of the epoch: mem (CPU python)=33980.1328125MB; mem (CPU total)=33938.16015625MB
INFO:root:EP 144: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=34018.02734375MB; mem (CPU total)=33976.3046875MB
INFO:root:Training the model took 10351.978s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84107
INFO:root:EnergyScoreTrain: 0.59206
INFO:root:CRPSTrain: 0.46009
INFO:root:Gaussian NLLTrain: 1.19342
INFO:root:CoverageTrain: 0.94788
INFO:root:IntervalWidthTrain: 3.24798
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86144
INFO:root:EnergyScoreValidation: 0.60634
INFO:root:CRPSValidation: 0.47224
INFO:root:Gaussian NLLValidation: 1.22173
INFO:root:CoverageValidation: 0.94129
INFO:root:IntervalWidthValidation: 3.25234
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86254
INFO:root:EnergyScoreTest: 0.60711
INFO:root:CRPSTest: 0.47279
INFO:root:Gaussian NLLTest: 1.22166
INFO:root:CoverageTest: 0.94129
INFO:root:IntervalWidthTest: 3.25245
INFO:root:After validation: mem (CPU python)=34147.109375MB; mem (CPU total)=33983.3203125MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=34147.109375MB; mem (CPU total)=33983.3203125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=34147.109375MB; mem (CPU total)=33983.3203125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=34147.109375MB; mem (CPU total)=33983.07421875MB
INFO:root:[    1] Training loss: 0.72551602, Validation loss: 0.72050520, Gradient norm: 0.02300114
INFO:root:At the start of the epoch: mem (CPU python)=34147.109375MB; mem (CPU total)=34024.13671875MB
INFO:root:[    2] Training loss: 0.71999107, Validation loss: 0.71893430, Gradient norm: 0.00643986
INFO:root:At the start of the epoch: mem (CPU python)=34147.109375MB; mem (CPU total)=34061.9140625MB
INFO:root:[    3] Training loss: 0.71818178, Validation loss: 0.71583324, Gradient norm: 0.00785907
INFO:root:At the start of the epoch: mem (CPU python)=34147.109375MB; mem (CPU total)=34100.05859375MB
INFO:root:[    4] Training loss: 0.71299298, Validation loss: 0.70686093, Gradient norm: 0.01710734
INFO:root:At the start of the epoch: mem (CPU python)=34179.59375MB; mem (CPU total)=34138.44921875MB
INFO:root:[    5] Training loss: 0.70732533, Validation loss: 0.70238234, Gradient norm: 0.02818358
INFO:root:At the start of the epoch: mem (CPU python)=34217.6875MB; mem (CPU total)=34176.59375MB
INFO:root:[    6] Training loss: 0.70280733, Validation loss: 0.69739208, Gradient norm: 0.02800462
INFO:root:At the start of the epoch: mem (CPU python)=34280.78125MB; mem (CPU total)=34239.8984375MB
INFO:root:[    7] Training loss: 0.69835829, Validation loss: 0.69238778, Gradient norm: 0.03129723
INFO:root:At the start of the epoch: mem (CPU python)=34318.8828125MB; mem (CPU total)=34277.7890625MB
INFO:root:[    8] Training loss: 0.69409283, Validation loss: 0.68758545, Gradient norm: 0.03057366
INFO:root:At the start of the epoch: mem (CPU python)=34394.4765625MB; mem (CPU total)=34353.625MB
INFO:root:[    9] Training loss: 0.69034422, Validation loss: 0.68344585, Gradient norm: 0.03412893
INFO:root:At the start of the epoch: mem (CPU python)=34432.5703125MB; mem (CPU total)=34391.984375MB
INFO:root:[   10] Training loss: 0.68659792, Validation loss: 0.67941129, Gradient norm: 0.03274616
INFO:root:At the start of the epoch: mem (CPU python)=34463.57421875MB; mem (CPU total)=34405.23828125MB
INFO:root:[   11] Training loss: 0.68328075, Validation loss: 0.67604031, Gradient norm: 0.03238537
INFO:root:At the start of the epoch: mem (CPU python)=34483.76171875MB; mem (CPU total)=34443.3828125MB
INFO:root:[   12] Training loss: 0.68036389, Validation loss: 0.67146753, Gradient norm: 0.03582837
INFO:root:At the start of the epoch: mem (CPU python)=34521.86328125MB; mem (CPU total)=34481.7734375MB
INFO:root:[   13] Training loss: 0.67751145, Validation loss: 0.66961738, Gradient norm: 0.03608065
INFO:root:At the start of the epoch: mem (CPU python)=34559.95703125MB; mem (CPU total)=34520.12890625MB
INFO:root:[   14] Training loss: 0.67507662, Validation loss: 0.66596248, Gradient norm: 0.03493141
INFO:root:At the start of the epoch: mem (CPU python)=34610.5546875MB; mem (CPU total)=34571.04296875MB
INFO:root:[   15] Training loss: 0.67279838, Validation loss: 0.66505598, Gradient norm: 0.03569483
INFO:root:At the start of the epoch: mem (CPU python)=34648.6484375MB; mem (CPU total)=34608.8515625MB
INFO:root:[   16] Training loss: 0.67065282, Validation loss: 0.66090364, Gradient norm: 0.03841048
INFO:root:At the start of the epoch: mem (CPU python)=34674.2421875MB; mem (CPU total)=34633.98828125MB
INFO:root:[   17] Training loss: 0.66847442, Validation loss: 0.65957773, Gradient norm: 0.03622760
INFO:root:At the start of the epoch: mem (CPU python)=34712.3359375MB; mem (CPU total)=34672.0MB
INFO:root:[   18] Training loss: 0.66657283, Validation loss: 0.65735265, Gradient norm: 0.03794921
INFO:root:At the start of the epoch: mem (CPU python)=34750.4375MB; mem (CPU total)=34710.11328125MB
INFO:root:[   19] Training loss: 0.66469561, Validation loss: 0.65542765, Gradient norm: 0.04009478
INFO:root:At the start of the epoch: mem (CPU python)=34788.52734375MB; mem (CPU total)=34748.71875MB
INFO:root:[   20] Training loss: 0.66300162, Validation loss: 0.65288804, Gradient norm: 0.04372355
INFO:root:At the start of the epoch: mem (CPU python)=34826.62109375MB; mem (CPU total)=34786.89453125MB
INFO:root:[   21] Training loss: 0.66107176, Validation loss: 0.65092502, Gradient norm: 0.04159150
INFO:root:At the start of the epoch: mem (CPU python)=34864.72265625MB; mem (CPU total)=34824.578125MB
INFO:root:[   22] Training loss: 0.65942940, Validation loss: 0.64985296, Gradient norm: 0.04099505
INFO:root:At the start of the epoch: mem (CPU python)=34902.81640625MB; mem (CPU total)=34862.96875MB
INFO:root:[   23] Training loss: 0.65800510, Validation loss: 0.64771963, Gradient norm: 0.04587326
INFO:root:At the start of the epoch: mem (CPU python)=34940.91015625MB; mem (CPU total)=34901.11328125MB
INFO:root:[   24] Training loss: 0.65625386, Validation loss: 0.64563982, Gradient norm: 0.04481507
INFO:root:At the start of the epoch: mem (CPU python)=34979.0078125MB; mem (CPU total)=34939.43359375MB
INFO:root:[   25] Training loss: 0.65508212, Validation loss: 0.64375677, Gradient norm: 0.04282603
INFO:root:At the start of the epoch: mem (CPU python)=35017.1015625MB; mem (CPU total)=34977.83203125MB
INFO:root:[   26] Training loss: 0.65353500, Validation loss: 0.64266715, Gradient norm: 0.04566794
INFO:root:At the start of the epoch: mem (CPU python)=35055.1953125MB; mem (CPU total)=35015.9765625MB
INFO:root:[   27] Training loss: 0.65254334, Validation loss: 0.64079948, Gradient norm: 0.04807749
INFO:root:At the start of the epoch: mem (CPU python)=35093.2890625MB; mem (CPU total)=35054.3671875MB
INFO:root:[   28] Training loss: 0.65145536, Validation loss: 0.64043540, Gradient norm: 0.04723891
INFO:root:At the start of the epoch: mem (CPU python)=35131.38671875MB; mem (CPU total)=35092.265625MB
INFO:root:[   29] Training loss: 0.65048232, Validation loss: 0.63942136, Gradient norm: 0.04820737
INFO:root:At the start of the epoch: mem (CPU python)=35169.48046875MB; mem (CPU total)=35130.58203125MB
INFO:root:[   30] Training loss: 0.64934430, Validation loss: 0.63862131, Gradient norm: 0.05301305
INFO:root:At the start of the epoch: mem (CPU python)=35220.078125MB; mem (CPU total)=35181.25MB
INFO:root:[   31] Training loss: 0.64798226, Validation loss: 0.63738731, Gradient norm: 0.04662790
INFO:root:At the start of the epoch: mem (CPU python)=35258.17578125MB; mem (CPU total)=35219.1484375MB
INFO:root:[   32] Training loss: 0.64725045, Validation loss: 0.63684189, Gradient norm: 0.04704902
INFO:root:At the start of the epoch: mem (CPU python)=35296.26953125MB; mem (CPU total)=35257.76171875MB
INFO:root:[   33] Training loss: 0.64671783, Validation loss: 0.63549686, Gradient norm: 0.05974125
INFO:root:At the start of the epoch: mem (CPU python)=35296.86328125MB; mem (CPU total)=35258.24609375MB
INFO:root:[   34] Training loss: 0.64563522, Validation loss: 0.63445734, Gradient norm: 0.04850150
INFO:root:At the start of the epoch: mem (CPU python)=35334.95703125MB; mem (CPU total)=35296.171875MB
INFO:root:[   35] Training loss: 0.64487378, Validation loss: 0.63330252, Gradient norm: 0.05203799
INFO:root:At the start of the epoch: mem (CPU python)=35385.5546875MB; mem (CPU total)=35346.88671875MB
INFO:root:[   36] Training loss: 0.64422550, Validation loss: 0.63279222, Gradient norm: 0.05850681
INFO:root:At the start of the epoch: mem (CPU python)=35436.1484375MB; mem (CPU total)=35397.515625MB
INFO:root:[   37] Training loss: 0.64336224, Validation loss: 0.63243927, Gradient norm: 0.05216170
INFO:root:At the start of the epoch: mem (CPU python)=35474.2421875MB; mem (CPU total)=35435.90625MB
INFO:root:[   38] Training loss: 0.64289841, Validation loss: 0.63168787, Gradient norm: 0.05094470
INFO:root:At the start of the epoch: mem (CPU python)=35512.34375MB; mem (CPU total)=35474.01953125MB
INFO:root:[   39] Training loss: 0.64225062, Validation loss: 0.63182063, Gradient norm: 0.05388034
INFO:root:At the start of the epoch: mem (CPU python)=35550.4375MB; mem (CPU total)=35512.59375MB
INFO:root:[   40] Training loss: 0.64133172, Validation loss: 0.63091139, Gradient norm: 0.04857494
INFO:root:At the start of the epoch: mem (CPU python)=35588.53125MB; mem (CPU total)=35550.62890625MB
INFO:root:[   41] Training loss: 0.64073546, Validation loss: 0.62981302, Gradient norm: 0.05537461
INFO:root:At the start of the epoch: mem (CPU python)=35626.62890625MB; mem (CPU total)=35588.765625MB
INFO:root:[   42] Training loss: 0.64018013, Validation loss: 0.62943873, Gradient norm: 0.05255763
INFO:root:At the start of the epoch: mem (CPU python)=35689.72265625MB; mem (CPU total)=35652.16796875MB
INFO:root:[   43] Training loss: 0.63966750, Validation loss: 0.62853309, Gradient norm: 0.05274127
INFO:root:At the start of the epoch: mem (CPU python)=35689.94921875MB; mem (CPU total)=35627.76171875MB
INFO:root:[   44] Training loss: 0.63922573, Validation loss: 0.62745591, Gradient norm: 0.06206975
INFO:root:At the start of the epoch: mem (CPU python)=35751.60546875MB; mem (CPU total)=35666.12890625MB
INFO:root:[   45] Training loss: 0.63860526, Validation loss: 0.62740555, Gradient norm: 0.05750375
INFO:root:At the start of the epoch: mem (CPU python)=35754.0078125MB; mem (CPU total)=35716.98046875MB
INFO:root:[   46] Training loss: 0.63799560, Validation loss: 0.62736792, Gradient norm: 0.05351748
INFO:root:At the start of the epoch: mem (CPU python)=35792.1015625MB; mem (CPU total)=35755.0625MB
INFO:root:[   47] Training loss: 0.63761771, Validation loss: 0.62690511, Gradient norm: 0.05524031
INFO:root:At the start of the epoch: mem (CPU python)=35830.1953125MB; mem (CPU total)=35793.20703125MB
INFO:root:[   48] Training loss: 0.63696317, Validation loss: 0.62688725, Gradient norm: 0.05727883
INFO:root:At the start of the epoch: mem (CPU python)=35880.796875MB; mem (CPU total)=35843.953125MB
INFO:root:[   49] Training loss: 0.63658628, Validation loss: 0.62537416, Gradient norm: 0.05955304
INFO:root:At the start of the epoch: mem (CPU python)=35918.890625MB; mem (CPU total)=35882.3359375MB
INFO:root:[   50] Training loss: 0.63642748, Validation loss: 0.62628156, Gradient norm: 0.06187562
INFO:root:At the start of the epoch: mem (CPU python)=35969.484375MB; mem (CPU total)=35932.6640625MB
INFO:root:[   51] Training loss: 0.63567463, Validation loss: 0.62559284, Gradient norm: 0.05916678
INFO:root:At the start of the epoch: mem (CPU python)=36007.578125MB; mem (CPU total)=35970.77734375MB
INFO:root:[   52] Training loss: 0.63544002, Validation loss: 0.62466615, Gradient norm: 0.06353105
INFO:root:At the start of the epoch: mem (CPU python)=36045.67578125MB; mem (CPU total)=36009.1484375MB
INFO:root:[   53] Training loss: 0.63494546, Validation loss: 0.62364433, Gradient norm: 0.05720184
INFO:root:At the start of the epoch: mem (CPU python)=36083.76953125MB; mem (CPU total)=36047.5546875MB
INFO:root:[   54] Training loss: 0.63445108, Validation loss: 0.62374252, Gradient norm: 0.05515511
INFO:root:At the start of the epoch: mem (CPU python)=36121.86328125MB; mem (CPU total)=36085.453125MB
INFO:root:[   55] Training loss: 0.63394349, Validation loss: 0.62412136, Gradient norm: 0.05567235
INFO:root:At the start of the epoch: mem (CPU python)=36159.96875MB; mem (CPU total)=36124.12890625MB
INFO:root:[   56] Training loss: 0.63393141, Validation loss: 0.62328074, Gradient norm: 0.05715188
INFO:root:At the start of the epoch: mem (CPU python)=36198.06640625MB; mem (CPU total)=36162.1015625MB
INFO:root:[   57] Training loss: 0.63376674, Validation loss: 0.62325123, Gradient norm: 0.07366914
INFO:root:At the start of the epoch: mem (CPU python)=36236.16015625MB; mem (CPU total)=36200.27734375MB
INFO:root:[   58] Training loss: 0.63308874, Validation loss: 0.62343714, Gradient norm: 0.05468504
INFO:root:At the start of the epoch: mem (CPU python)=36274.2578125MB; mem (CPU total)=36238.421875MB
INFO:root:[   59] Training loss: 0.63279388, Validation loss: 0.62292762, Gradient norm: 0.06054461
INFO:root:At the start of the epoch: mem (CPU python)=36337.3515625MB; mem (CPU total)=36302.01171875MB
INFO:root:[   60] Training loss: 0.63241179, Validation loss: 0.62154477, Gradient norm: 0.05926696
INFO:root:At the start of the epoch: mem (CPU python)=36350.4453125MB; mem (CPU total)=36314.95703125MB
INFO:root:[   61] Training loss: 0.63198578, Validation loss: 0.62151818, Gradient norm: 0.05316457
INFO:root:At the start of the epoch: mem (CPU python)=36388.5390625MB; mem (CPU total)=36353.31640625MB
INFO:root:[   62] Training loss: 0.63179689, Validation loss: 0.62160405, Gradient norm: 0.05590536
INFO:root:At the start of the epoch: mem (CPU python)=36439.13671875MB; mem (CPU total)=36403.4453125MB
INFO:root:[   63] Training loss: 0.63113747, Validation loss: 0.62172381, Gradient norm: 0.05559927
INFO:root:At the start of the epoch: mem (CPU python)=36464.73046875MB; mem (CPU total)=36429.10546875MB
INFO:root:[   64] Training loss: 0.63104057, Validation loss: 0.62089774, Gradient norm: 0.05768884
INFO:root:At the start of the epoch: mem (CPU python)=36502.828125MB; mem (CPU total)=36467.48046875MB
INFO:root:[   65] Training loss: 0.63066040, Validation loss: 0.62091160, Gradient norm: 0.06455722
INFO:root:At the start of the epoch: mem (CPU python)=36553.42578125MB; mem (CPU total)=36518.1171875MB
INFO:root:[   66] Training loss: 0.63032506, Validation loss: 0.62108913, Gradient norm: 0.06052033
INFO:root:At the start of the epoch: mem (CPU python)=36579.01953125MB; mem (CPU total)=36543.640625MB
INFO:root:[   67] Training loss: 0.63017407, Validation loss: 0.62012119, Gradient norm: 0.07039385
INFO:root:At the start of the epoch: mem (CPU python)=36667.11328125MB; mem (CPU total)=36631.9375MB
INFO:root:[   68] Training loss: 0.62979718, Validation loss: 0.62041852, Gradient norm: 0.05397362
INFO:root:At the start of the epoch: mem (CPU python)=36705.20703125MB; mem (CPU total)=36670.05078125MB
INFO:root:[   69] Training loss: 0.62942944, Validation loss: 0.61962087, Gradient norm: 0.05810312
INFO:root:At the start of the epoch: mem (CPU python)=36736.0546875MB; mem (CPU total)=36683.05859375MB
INFO:root:[   70] Training loss: 0.62910003, Validation loss: 0.61882797, Gradient norm: 0.05692226
INFO:root:At the start of the epoch: mem (CPU python)=36736.0546875MB; mem (CPU total)=36671.359375MB
INFO:root:[   71] Training loss: 0.62906742, Validation loss: 0.61894282, Gradient norm: 0.06118044
INFO:root:At the start of the epoch: mem (CPU python)=36769.4921875MB; mem (CPU total)=36734.31640625MB
INFO:root:[   72] Training loss: 0.62857601, Validation loss: 0.61980569, Gradient norm: 0.05871433
INFO:root:At the start of the epoch: mem (CPU python)=36807.58984375MB; mem (CPU total)=36772.70703125MB
INFO:root:[   73] Training loss: 0.62866945, Validation loss: 0.61839910, Gradient norm: 0.06475224
INFO:root:At the start of the epoch: mem (CPU python)=36845.6875MB; mem (CPU total)=36810.87890625MB
INFO:root:[   74] Training loss: 0.62814112, Validation loss: 0.61871279, Gradient norm: 0.06756466
INFO:root:At the start of the epoch: mem (CPU python)=36883.78125MB; mem (CPU total)=36849.0234375MB
INFO:root:[   75] Training loss: 0.62809062, Validation loss: 0.61809716, Gradient norm: 0.06015375
INFO:root:At the start of the epoch: mem (CPU python)=36934.37890625MB; mem (CPU total)=36899.90625MB
INFO:root:[   76] Training loss: 0.62778792, Validation loss: 0.61830193, Gradient norm: 0.06164814
INFO:root:At the start of the epoch: mem (CPU python)=36947.47265625MB; mem (CPU total)=36912.8515625MB
INFO:root:[   77] Training loss: 0.62716850, Validation loss: 0.61778278, Gradient norm: 0.05755900
INFO:root:At the start of the epoch: mem (CPU python)=36985.56640625MB; mem (CPU total)=36950.6875MB
INFO:root:[   78] Training loss: 0.62742955, Validation loss: 0.61828816, Gradient norm: 0.06641043
INFO:root:At the start of the epoch: mem (CPU python)=37048.66015625MB; mem (CPU total)=37014.046875MB
INFO:root:[   79] Training loss: 0.62694021, Validation loss: 0.61743372, Gradient norm: 0.06504976
INFO:root:At the start of the epoch: mem (CPU python)=37086.7578125MB; mem (CPU total)=37051.9140625MB
INFO:root:[   80] Training loss: 0.62672972, Validation loss: 0.61664283, Gradient norm: 0.06111094
INFO:root:At the start of the epoch: mem (CPU python)=37087.3515625MB; mem (CPU total)=37052.64453125MB
INFO:root:[   81] Training loss: 0.62648177, Validation loss: 0.61720321, Gradient norm: 0.06111962
INFO:root:At the start of the epoch: mem (CPU python)=37150.44921875MB; mem (CPU total)=37115.7109375MB
INFO:root:[   82] Training loss: 0.62636308, Validation loss: 0.61766147, Gradient norm: 0.06215573
INFO:root:At the start of the epoch: mem (CPU python)=37213.546875MB; mem (CPU total)=37178.80859375MB
INFO:root:[   83] Training loss: 0.62618238, Validation loss: 0.61679190, Gradient norm: 0.06936404
INFO:root:At the start of the epoch: mem (CPU python)=37251.640625MB; mem (CPU total)=37216.8984375MB
INFO:root:[   84] Training loss: 0.62577104, Validation loss: 0.61663760, Gradient norm: 0.06152666
INFO:root:At the start of the epoch: mem (CPU python)=37252.23828125MB; mem (CPU total)=37218.9140625MB
INFO:root:[   85] Training loss: 0.62549516, Validation loss: 0.61630401, Gradient norm: 0.06284394
INFO:root:At the start of the epoch: mem (CPU python)=37290.33203125MB; mem (CPU total)=37256.390625MB
INFO:root:[   86] Training loss: 0.62527588, Validation loss: 0.61674657, Gradient norm: 0.05952734
INFO:root:At the start of the epoch: mem (CPU python)=37365.9296875MB; mem (CPU total)=37332.3359375MB
INFO:root:[   87] Training loss: 0.62506151, Validation loss: 0.61706365, Gradient norm: 0.06560375
INFO:root:At the start of the epoch: mem (CPU python)=37366.5234375MB; mem (CPU total)=37332.9375MB
INFO:root:[   88] Training loss: 0.62497241, Validation loss: 0.61664794, Gradient norm: 0.06094575
INFO:root:At the start of the epoch: mem (CPU python)=37429.6171875MB; mem (CPU total)=37395.91796875MB
INFO:root:[   89] Training loss: 0.62470927, Validation loss: 0.61595230, Gradient norm: 0.05980024
INFO:root:At the start of the epoch: mem (CPU python)=37455.21484375MB; mem (CPU total)=37421.328125MB
INFO:root:[   90] Training loss: 0.62463234, Validation loss: 0.61600069, Gradient norm: 0.07147080
INFO:root:At the start of the epoch: mem (CPU python)=37493.3125MB; mem (CPU total)=37459.71875MB
INFO:root:[   91] Training loss: 0.62435261, Validation loss: 0.61483416, Gradient norm: 0.06001974
INFO:root:At the start of the epoch: mem (CPU python)=37531.40625MB; mem (CPU total)=37497.89453125MB
INFO:root:[   92] Training loss: 0.62409399, Validation loss: 0.61545498, Gradient norm: 0.06699313
INFO:root:At the start of the epoch: mem (CPU python)=37569.50390625MB; mem (CPU total)=37536.28515625MB
INFO:root:[   93] Training loss: 0.62409974, Validation loss: 0.61518403, Gradient norm: 0.06727094
INFO:root:At the start of the epoch: mem (CPU python)=37607.59765625MB; mem (CPU total)=37574.89453125MB
INFO:root:[   94] Training loss: 0.62379877, Validation loss: 0.61456585, Gradient norm: 0.06272012
INFO:root:At the start of the epoch: mem (CPU python)=37670.69140625MB; mem (CPU total)=37638.25390625MB
INFO:root:[   95] Training loss: 0.62364145, Validation loss: 0.61481346, Gradient norm: 0.06266700
INFO:root:At the start of the epoch: mem (CPU python)=37721.28515625MB; mem (CPU total)=37688.859375MB
INFO:root:[   96] Training loss: 0.62351977, Validation loss: 0.61551485, Gradient norm: 0.06817672
INFO:root:At the start of the epoch: mem (CPU python)=37721.8828125MB; mem (CPU total)=37689.375MB
INFO:root:[   97] Training loss: 0.62325016, Validation loss: 0.61404820, Gradient norm: 0.06692303
INFO:root:At the start of the epoch: mem (CPU python)=37784.9765625MB; mem (CPU total)=37752.703125MB
INFO:root:[   98] Training loss: 0.62286494, Validation loss: 0.61526789, Gradient norm: 0.06399461
INFO:root:At the start of the epoch: mem (CPU python)=37823.07421875MB; mem (CPU total)=37790.796875MB
INFO:root:[   99] Training loss: 0.62288050, Validation loss: 0.61468753, Gradient norm: 0.06855122
INFO:root:At the start of the epoch: mem (CPU python)=37873.671875MB; mem (CPU total)=37841.6484375MB
INFO:root:[  100] Training loss: 0.62275341, Validation loss: 0.61451827, Gradient norm: 0.06617401
INFO:root:At the start of the epoch: mem (CPU python)=37873.890625MB; mem (CPU total)=37817.2265625MB
INFO:root:[  101] Training loss: 0.62261509, Validation loss: 0.61416491, Gradient norm: 0.06435436
INFO:root:At the start of the epoch: mem (CPU python)=37912.359375MB; mem (CPU total)=37880.25390625MB
INFO:root:[  102] Training loss: 0.62243583, Validation loss: 0.61496624, Gradient norm: 0.06557436
INFO:root:At the start of the epoch: mem (CPU python)=37950.453125MB; mem (CPU total)=37918.15234375MB
INFO:root:[  103] Training loss: 0.62219134, Validation loss: 0.61443699, Gradient norm: 0.06244982
INFO:root:At the start of the epoch: mem (CPU python)=37988.55078125MB; mem (CPU total)=37956.296875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  104] Training loss: 0.62191878, Validation loss: 0.61457788, Gradient norm: 0.06163894
INFO:root:At the start of the epoch: mem (CPU python)=38026.64453125MB; mem (CPU total)=37994.44140625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  105] Training loss: 0.62113834, Validation loss: 0.61274245, Gradient norm: 0.06103612
INFO:root:At the start of the epoch: mem (CPU python)=38064.7421875MB; mem (CPU total)=38033.109375MB
INFO:root:[  106] Training loss: 0.62019696, Validation loss: 0.61293299, Gradient norm: 0.05627070
INFO:root:At the start of the epoch: mem (CPU python)=38102.83984375MB; mem (CPU total)=38071.0078125MB
INFO:root:[  107] Training loss: 0.62025598, Validation loss: 0.61250872, Gradient norm: 0.05241483
INFO:root:At the start of the epoch: mem (CPU python)=38140.93359375MB; mem (CPU total)=38108.9375MB
INFO:root:[  108] Training loss: 0.62011960, Validation loss: 0.61237281, Gradient norm: 0.05412143
INFO:root:At the start of the epoch: mem (CPU python)=38179.02734375MB; mem (CPU total)=38146.74609375MB
INFO:root:[  109] Training loss: 0.61992844, Validation loss: 0.61224976, Gradient norm: 0.05422858
INFO:root:At the start of the epoch: mem (CPU python)=38217.125MB; mem (CPU total)=38184.921875MB
INFO:root:[  110] Training loss: 0.61995748, Validation loss: 0.61224622, Gradient norm: 0.05244686
INFO:root:At the start of the epoch: mem (CPU python)=38255.21875MB; mem (CPU total)=38223.3125MB
INFO:root:[  111] Training loss: 0.61975260, Validation loss: 0.61258821, Gradient norm: 0.05406636
INFO:root:At the start of the epoch: mem (CPU python)=38293.3125MB; mem (CPU total)=38261.671875MB
INFO:root:[  112] Training loss: 0.61963340, Validation loss: 0.61311458, Gradient norm: 0.05323433
INFO:root:At the start of the epoch: mem (CPU python)=38331.40625MB; mem (CPU total)=38299.5625MB
INFO:root:[  113] Training loss: 0.61944478, Validation loss: 0.61306305, Gradient norm: 0.05329869
INFO:root:At the start of the epoch: mem (CPU python)=38382.00390625MB; mem (CPU total)=38350.41015625MB
INFO:root:[  114] Training loss: 0.61956436, Validation loss: 0.61229590, Gradient norm: 0.05448597
INFO:root:At the start of the epoch: mem (CPU python)=38445.1015625MB; mem (CPU total)=38413.4140625MB
INFO:root:[  115] Training loss: 0.61940818, Validation loss: 0.61211632, Gradient norm: 0.05319400
INFO:root:At the start of the epoch: mem (CPU python)=38445.3203125MB; mem (CPU total)=38401.24609375MB
INFO:root:[  116] Training loss: 0.61972091, Validation loss: 0.61235639, Gradient norm: 0.05699402
INFO:root:At the start of the epoch: mem (CPU python)=38471.29296875MB; mem (CPU total)=38439.96875MB
INFO:root:[  117] Training loss: 0.61955630, Validation loss: 0.61230351, Gradient norm: 0.05661119
INFO:root:At the start of the epoch: mem (CPU python)=38509.38671875MB; mem (CPU total)=38478.6953125MB
INFO:root:[  118] Training loss: 0.61944400, Validation loss: 0.61247549, Gradient norm: 0.05458676
INFO:root:At the start of the epoch: mem (CPU python)=38559.98046875MB; mem (CPU total)=38529.33203125MB
INFO:root:[  119] Training loss: 0.61942212, Validation loss: 0.61252119, Gradient norm: 0.05605705
INFO:root:At the start of the epoch: mem (CPU python)=38598.07421875MB; mem (CPU total)=38567.3984375MB
INFO:root:[  120] Training loss: 0.61946673, Validation loss: 0.61269682, Gradient norm: 0.05702407
INFO:root:At the start of the epoch: mem (CPU python)=38636.171875MB; mem (CPU total)=38605.56640625MB
INFO:root:[  121] Training loss: 0.61935947, Validation loss: 0.61263087, Gradient norm: 0.05820416
INFO:root:At the start of the epoch: mem (CPU python)=38674.265625MB; mem (CPU total)=38643.734375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  122] Training loss: 0.61919404, Validation loss: 0.61225528, Gradient norm: 0.05798941
INFO:root:At the start of the epoch: mem (CPU python)=38712.359375MB; mem (CPU total)=38681.42578125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  123] Training loss: 0.61884525, Validation loss: 0.61223147, Gradient norm: 0.05248168
INFO:root:At the start of the epoch: mem (CPU python)=38775.45703125MB; mem (CPU total)=38745.03125MB
INFO:root:[  124] Training loss: 0.61891072, Validation loss: 0.61187721, Gradient norm: 0.05130368
INFO:root:At the start of the epoch: mem (CPU python)=38813.5546875MB; mem (CPU total)=38783.6640625MB
INFO:root:[  125] Training loss: 0.61892606, Validation loss: 0.61203421, Gradient norm: 0.05253237
INFO:root:At the start of the epoch: mem (CPU python)=38826.6484375MB; mem (CPU total)=38796.43359375MB
INFO:root:[  126] Training loss: 0.61871626, Validation loss: 0.61178669, Gradient norm: 0.05201134
INFO:root:At the start of the epoch: mem (CPU python)=38864.74609375MB; mem (CPU total)=38834.88671875MB
INFO:root:[  127] Training loss: 0.61868303, Validation loss: 0.61198541, Gradient norm: 0.05155393
INFO:root:At the start of the epoch: mem (CPU python)=38915.33984375MB; mem (CPU total)=38885.5859375MB
INFO:root:[  128] Training loss: 0.61864220, Validation loss: 0.61215027, Gradient norm: 0.05055026
INFO:root:At the start of the epoch: mem (CPU python)=38928.43359375MB; mem (CPU total)=38898.0703125MB
INFO:root:[  129] Training loss: 0.61867983, Validation loss: 0.61186881, Gradient norm: 0.05084704
INFO:root:At the start of the epoch: mem (CPU python)=38966.52734375MB; mem (CPU total)=38936.27734375MB
INFO:root:[  130] Training loss: 0.61866457, Validation loss: 0.61202933, Gradient norm: 0.05208010
INFO:root:At the start of the epoch: mem (CPU python)=39017.125MB; mem (CPU total)=38987.0625MB
INFO:root:[  131] Training loss: 0.61859902, Validation loss: 0.61167551, Gradient norm: 0.05111845
INFO:root:At the start of the epoch: mem (CPU python)=39080.22265625MB; mem (CPU total)=39050.640625MB
INFO:root:[  132] Training loss: 0.61855767, Validation loss: 0.61189152, Gradient norm: 0.05174884
INFO:root:At the start of the epoch: mem (CPU python)=39118.31640625MB; mem (CPU total)=39090.3125MB
INFO:root:[  133] Training loss: 0.61863624, Validation loss: 0.61159562, Gradient norm: 0.04933263
INFO:root:At the start of the epoch: mem (CPU python)=39119.05859375MB; mem (CPU total)=39078.1171875MB
INFO:root:[  134] Training loss: 0.61846869, Validation loss: 0.61177871, Gradient norm: 0.05138740
INFO:root:At the start of the epoch: mem (CPU python)=39169.5078125MB; mem (CPU total)=39141.3828125MB
INFO:root:[  135] Training loss: 0.61858918, Validation loss: 0.61092129, Gradient norm: 0.05289622
INFO:root:At the start of the epoch: mem (CPU python)=39207.6015625MB; mem (CPU total)=39179.09765625MB
INFO:root:[  136] Training loss: 0.61838969, Validation loss: 0.61195333, Gradient norm: 0.05242693
INFO:root:At the start of the epoch: mem (CPU python)=39245.6953125MB; mem (CPU total)=39217.49609375MB
INFO:root:[  137] Training loss: 0.61879571, Validation loss: 0.61159898, Gradient norm: 0.05155697
INFO:root:At the start of the epoch: mem (CPU python)=39296.29296875MB; mem (CPU total)=39267.578125MB
INFO:root:[  138] Training loss: 0.61857274, Validation loss: 0.61190188, Gradient norm: 0.05165746
INFO:root:At the start of the epoch: mem (CPU python)=39309.38671875MB; mem (CPU total)=39281.17578125MB
INFO:root:[  139] Training loss: 0.61850700, Validation loss: 0.61161751, Gradient norm: 0.05119272
INFO:root:At the start of the epoch: mem (CPU python)=39372.48046875MB; mem (CPU total)=39344.12890625MB
INFO:root:[  140] Training loss: 0.61835665, Validation loss: 0.61140608, Gradient norm: 0.05049587
INFO:root:At the start of the epoch: mem (CPU python)=39398.078125MB; mem (CPU total)=39369.56640625MB
INFO:root:[  141] Training loss: 0.61853957, Validation loss: 0.61202995, Gradient norm: 0.05174985
INFO:root:At the start of the epoch: mem (CPU python)=39473.671875MB; mem (CPU total)=39445.640625MB
INFO:root:[  142] Training loss: 0.61843515, Validation loss: 0.61204092, Gradient norm: 0.05300562
INFO:root:At the start of the epoch: mem (CPU python)=39511.76953125MB; mem (CPU total)=39483.5625MB
INFO:root:[  143] Training loss: 0.61834130, Validation loss: 0.61165126, Gradient norm: 0.05099874
INFO:root:At the start of the epoch: mem (CPU python)=39511.9921875MB; mem (CPU total)=39471.37109375MB
INFO:root:[  144] Training loss: 0.61871484, Validation loss: 0.61162832, Gradient norm: 0.05353342
INFO:root:At the start of the epoch: mem (CPU python)=39537.9609375MB; mem (CPU total)=39509.19921875MB
INFO:root:EP 144: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=39576.0546875MB; mem (CPU total)=39547.359375MB
INFO:root:Training the model took 11570.535s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85134
INFO:root:EnergyScoreTrain: 0.59931
INFO:root:CRPSTrain: 0.46762
INFO:root:Gaussian NLLTrain: 1.21233
INFO:root:CoverageTrain: 0.94935
INFO:root:IntervalWidthTrain: 3.30712
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86933
INFO:root:EnergyScoreValidation: 0.61187
INFO:root:CRPSValidation: 0.47835
INFO:root:Gaussian NLLValidation: 1.23549
INFO:root:CoverageValidation: 0.94377
INFO:root:IntervalWidthValidation: 3.30983
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87041
INFO:root:EnergyScoreTest: 0.61263
INFO:root:CRPSTest: 0.479
INFO:root:Gaussian NLLTest: 1.23653
INFO:root:CoverageTest: 0.94368
INFO:root:IntervalWidthTest: 3.30943
INFO:root:After validation: mem (CPU python)=39641.80859375MB; mem (CPU total)=39584.70703125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=39641.80859375MB; mem (CPU total)=39584.7265625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=39641.80859375MB; mem (CPU total)=39584.7265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=39641.80859375MB; mem (CPU total)=39585.37890625MB
INFO:root:[    1] Training loss: 0.72560587, Validation loss: 0.71983791, Gradient norm: 0.02353047
INFO:root:At the start of the epoch: mem (CPU python)=39651.26171875MB; mem (CPU total)=39621.41796875MB
INFO:root:[    2] Training loss: 0.71966039, Validation loss: 0.71833483, Gradient norm: 0.00600372
INFO:root:At the start of the epoch: mem (CPU python)=39751.859375MB; mem (CPU total)=39721.9609375MB
INFO:root:[    3] Training loss: 0.71761954, Validation loss: 0.71368017, Gradient norm: 0.00863909
INFO:root:At the start of the epoch: mem (CPU python)=39789.95703125MB; mem (CPU total)=39760.3828125MB
INFO:root:[    4] Training loss: 0.71072426, Validation loss: 0.70408201, Gradient norm: 0.01987635
INFO:root:At the start of the epoch: mem (CPU python)=39828.05078125MB; mem (CPU total)=39798.05859375MB
INFO:root:[    5] Training loss: 0.70390732, Validation loss: 0.69829565, Gradient norm: 0.02647960
INFO:root:At the start of the epoch: mem (CPU python)=39828.09765625MB; mem (CPU total)=39787.96484375MB
INFO:root:[    6] Training loss: 0.69807787, Validation loss: 0.69146115, Gradient norm: 0.02753745
INFO:root:At the start of the epoch: mem (CPU python)=39866.76953125MB; mem (CPU total)=39839.125MB
INFO:root:[    7] Training loss: 0.69290851, Validation loss: 0.68567375, Gradient norm: 0.02669032
INFO:root:At the start of the epoch: mem (CPU python)=39929.8359375MB; mem (CPU total)=39902.2265625MB
INFO:root:[    8] Training loss: 0.68810165, Validation loss: 0.68158731, Gradient norm: 0.02736417
INFO:root:At the start of the epoch: mem (CPU python)=39967.9296875MB; mem (CPU total)=39940.40234375MB
INFO:root:[    9] Training loss: 0.68421843, Validation loss: 0.67738267, Gradient norm: 0.02678777
INFO:root:At the start of the epoch: mem (CPU python)=39981.0546875MB; mem (CPU total)=39953.37890625MB
INFO:root:[   10] Training loss: 0.68114730, Validation loss: 0.67417822, Gradient norm: 0.02888214
INFO:root:At the start of the epoch: mem (CPU python)=40019.1484375MB; mem (CPU total)=39991.83203125MB
INFO:root:[   11] Training loss: 0.67853660, Validation loss: 0.67197983, Gradient norm: 0.02813418
INFO:root:At the start of the epoch: mem (CPU python)=40057.2421875MB; mem (CPU total)=40028.015625MB
INFO:root:[   12] Training loss: 0.67592212, Validation loss: 0.66836909, Gradient norm: 0.02888835
INFO:root:At the start of the epoch: mem (CPU python)=40082.8125MB; mem (CPU total)=40053.41796875MB
INFO:root:[   13] Training loss: 0.67369001, Validation loss: 0.66578015, Gradient norm: 0.03251525
INFO:root:At the start of the epoch: mem (CPU python)=40108.40625MB; mem (CPU total)=40079.4140625MB
INFO:root:[   14] Training loss: 0.67171369, Validation loss: 0.66336897, Gradient norm: 0.03057016
INFO:root:At the start of the epoch: mem (CPU python)=40209.00390625MB; mem (CPU total)=40179.94921875MB
INFO:root:[   15] Training loss: 0.66962209, Validation loss: 0.66133168, Gradient norm: 0.03029115
INFO:root:At the start of the epoch: mem (CPU python)=40234.59765625MB; mem (CPU total)=40205.65625MB
INFO:root:[   16] Training loss: 0.66747489, Validation loss: 0.65886364, Gradient norm: 0.03097280
INFO:root:At the start of the epoch: mem (CPU python)=40272.6953125MB; mem (CPU total)=40243.82421875MB
INFO:root:[   17] Training loss: 0.66544378, Validation loss: 0.65791668, Gradient norm: 0.03180156
INFO:root:At the start of the epoch: mem (CPU python)=40285.81640625MB; mem (CPU total)=40257.75390625MB
INFO:root:[   18] Training loss: 0.66349873, Validation loss: 0.65436508, Gradient norm: 0.03280156
INFO:root:At the start of the epoch: mem (CPU python)=40316.296875MB; mem (CPU total)=40280.48046875MB
INFO:root:[   19] Training loss: 0.66138669, Validation loss: 0.65300568, Gradient norm: 0.03286103
INFO:root:At the start of the epoch: mem (CPU python)=40374.48046875MB; mem (CPU total)=40344.1953125MB
INFO:root:[   20] Training loss: 0.65979407, Validation loss: 0.65078257, Gradient norm: 0.03470012
INFO:root:At the start of the epoch: mem (CPU python)=40374.703125MB; mem (CPU total)=40333.890625MB
INFO:root:[   21] Training loss: 0.65815051, Validation loss: 0.64833633, Gradient norm: 0.03602204
INFO:root:At the start of the epoch: mem (CPU python)=40413.171875MB; mem (CPU total)=40384.3125MB
INFO:root:[   22] Training loss: 0.65670050, Validation loss: 0.64757719, Gradient norm: 0.03645477
INFO:root:At the start of the epoch: mem (CPU python)=40463.76171875MB; mem (CPU total)=40432.98046875MB
INFO:root:[   23] Training loss: 0.65532924, Validation loss: 0.64605997, Gradient norm: 0.04003177
INFO:root:At the start of the epoch: mem (CPU python)=40501.83203125MB; mem (CPU total)=40409.3125MB
INFO:root:[   24] Training loss: 0.65387706, Validation loss: 0.64453817, Gradient norm: 0.03505484
INFO:root:At the start of the epoch: mem (CPU python)=40552.484375MB; mem (CPU total)=40522.34765625MB
INFO:root:[   25] Training loss: 0.65256905, Validation loss: 0.64228307, Gradient norm: 0.03822866
INFO:root:At the start of the epoch: mem (CPU python)=40590.578125MB; mem (CPU total)=40560.42578125MB
INFO:root:[   26] Training loss: 0.65156101, Validation loss: 0.64149337, Gradient norm: 0.04280902
INFO:root:At the start of the epoch: mem (CPU python)=40641.1484375MB; mem (CPU total)=40610.3203125MB
INFO:root:[   27] Training loss: 0.65026183, Validation loss: 0.64031092, Gradient norm: 0.03754950
INFO:root:At the start of the epoch: mem (CPU python)=40679.2421875MB; mem (CPU total)=40648.8671875MB
INFO:root:[   28] Training loss: 0.64938946, Validation loss: 0.63840718, Gradient norm: 0.04029919
INFO:root:At the start of the epoch: mem (CPU python)=40717.3359375MB; mem (CPU total)=40686.55078125MB
INFO:root:[   29] Training loss: 0.64837902, Validation loss: 0.63768422, Gradient norm: 0.04205867
INFO:root:At the start of the epoch: mem (CPU python)=40780.4375MB; mem (CPU total)=40749.89453125MB
INFO:root:[   30] Training loss: 0.64742736, Validation loss: 0.63666903, Gradient norm: 0.04026797
INFO:root:At the start of the epoch: mem (CPU python)=40780.65625MB; mem (CPU total)=40725.1796875MB
INFO:root:[   31] Training loss: 0.64665978, Validation loss: 0.63593455, Gradient norm: 0.04272675
INFO:root:At the start of the epoch: mem (CPU python)=40819.15234375MB; mem (CPU total)=40788.5390625MB
INFO:root:[   32] Training loss: 0.64592041, Validation loss: 0.63560581, Gradient norm: 0.04591832
INFO:root:At the start of the epoch: mem (CPU python)=40857.24609375MB; mem (CPU total)=40826.68359375MB
INFO:root:[   33] Training loss: 0.64500077, Validation loss: 0.63466707, Gradient norm: 0.04379598
INFO:root:At the start of the epoch: mem (CPU python)=40907.81640625MB; mem (CPU total)=40877.30078125MB
INFO:root:[   34] Training loss: 0.64404831, Validation loss: 0.63342398, Gradient norm: 0.04256925
INFO:root:At the start of the epoch: mem (CPU python)=40945.91015625MB; mem (CPU total)=40915.21875MB
INFO:root:[   35] Training loss: 0.64327497, Validation loss: 0.63281432, Gradient norm: 0.04393689
INFO:root:At the start of the epoch: mem (CPU python)=40984.00390625MB; mem (CPU total)=40953.1484375MB
INFO:root:[   36] Training loss: 0.64259366, Validation loss: 0.63139739, Gradient norm: 0.05186441
INFO:root:At the start of the epoch: mem (CPU python)=40984.60546875MB; mem (CPU total)=40954.33984375MB
INFO:root:[   37] Training loss: 0.64205396, Validation loss: 0.63174728, Gradient norm: 0.04847377
INFO:root:At the start of the epoch: mem (CPU python)=41035.19921875MB; mem (CPU total)=41004.5703125MB
INFO:root:[   38] Training loss: 0.64154280, Validation loss: 0.63131747, Gradient norm: 0.05139401
INFO:root:At the start of the epoch: mem (CPU python)=41048.29296875MB; mem (CPU total)=41017.8125MB
INFO:root:[   39] Training loss: 0.64070016, Validation loss: 0.63036613, Gradient norm: 0.04861680
INFO:root:At the start of the epoch: mem (CPU python)=41123.9140625MB; mem (CPU total)=41093.6171875MB
INFO:root:[   40] Training loss: 0.64029833, Validation loss: 0.62983533, Gradient norm: 0.05143799
INFO:root:At the start of the epoch: mem (CPU python)=41174.484375MB; mem (CPU total)=41147.359375MB
INFO:root:[   41] Training loss: 0.63959861, Validation loss: 0.62896518, Gradient norm: 0.05032617
INFO:root:At the start of the epoch: mem (CPU python)=41200.10546875MB; mem (CPU total)=41172.41015625MB
INFO:root:[   42] Training loss: 0.63925459, Validation loss: 0.62832029, Gradient norm: 0.05317989
INFO:root:At the start of the epoch: mem (CPU python)=41238.203125MB; mem (CPU total)=41210.83203125MB
INFO:root:[   43] Training loss: 0.63843334, Validation loss: 0.62813040, Gradient norm: 0.05281328
INFO:root:At the start of the epoch: mem (CPU python)=41276.30078125MB; mem (CPU total)=41248.9765625MB
INFO:root:[   44] Training loss: 0.63801654, Validation loss: 0.62811137, Gradient norm: 0.05516123
INFO:root:At the start of the epoch: mem (CPU python)=41314.390625MB; mem (CPU total)=41286.86328125MB
INFO:root:[   45] Training loss: 0.63757810, Validation loss: 0.62712178, Gradient norm: 0.05515896
INFO:root:At the start of the epoch: mem (CPU python)=41364.95703125MB; mem (CPU total)=41337.77734375MB
INFO:root:[   46] Training loss: 0.63703067, Validation loss: 0.62713504, Gradient norm: 0.05205607
INFO:root:At the start of the epoch: mem (CPU python)=41378.05859375MB; mem (CPU total)=41350.9375MB
INFO:root:[   47] Training loss: 0.63664286, Validation loss: 0.62577290, Gradient norm: 0.04765683
INFO:root:At the start of the epoch: mem (CPU python)=41428.31640625MB; mem (CPU total)=41351.8828125MB
INFO:root:[   48] Training loss: 0.63605825, Validation loss: 0.62490059, Gradient norm: 0.05360336
INFO:root:At the start of the epoch: mem (CPU python)=41466.7734375MB; mem (CPU total)=41439.4921875MB
INFO:root:[   49] Training loss: 0.63568540, Validation loss: 0.62463232, Gradient norm: 0.05569244
INFO:root:At the start of the epoch: mem (CPU python)=41504.8671875MB; mem (CPU total)=41477.90625MB
INFO:root:[   50] Training loss: 0.63516250, Validation loss: 0.62518028, Gradient norm: 0.05231878
INFO:root:At the start of the epoch: mem (CPU python)=41542.96484375MB; mem (CPU total)=41515.8046875MB
INFO:root:[   51] Training loss: 0.63472944, Validation loss: 0.62424461, Gradient norm: 0.05452466
INFO:root:At the start of the epoch: mem (CPU python)=41556.03125MB; mem (CPU total)=41528.99609375MB
INFO:root:[   52] Training loss: 0.63420309, Validation loss: 0.62415063, Gradient norm: 0.04961278
INFO:root:At the start of the epoch: mem (CPU python)=41619.15234375MB; mem (CPU total)=41592.5859375MB
INFO:root:[   53] Training loss: 0.63385639, Validation loss: 0.62301494, Gradient norm: 0.05702433
INFO:root:At the start of the epoch: mem (CPU python)=41657.25390625MB; mem (CPU total)=41630.69921875MB
INFO:root:[   54] Training loss: 0.63334445, Validation loss: 0.62340247, Gradient norm: 0.05127453
INFO:root:At the start of the epoch: mem (CPU python)=41657.82421875MB; mem (CPU total)=41631.18359375MB
INFO:root:[   55] Training loss: 0.63322189, Validation loss: 0.62210689, Gradient norm: 0.05299205
INFO:root:At the start of the epoch: mem (CPU python)=41720.91796875MB; mem (CPU total)=41694.24609375MB
INFO:root:[   56] Training loss: 0.63277585, Validation loss: 0.62249744, Gradient norm: 0.05433460
INFO:root:At the start of the epoch: mem (CPU python)=41757.75MB; mem (CPU total)=41694.9375MB
INFO:root:[   57] Training loss: 0.63226773, Validation loss: 0.62250514, Gradient norm: 0.06317985
INFO:root:At the start of the epoch: mem (CPU python)=41847.109375MB; mem (CPU total)=41820.6484375MB
INFO:root:[   58] Training loss: 0.63200039, Validation loss: 0.62105228, Gradient norm: 0.05373009
INFO:root:At the start of the epoch: mem (CPU python)=41847.33203125MB; mem (CPU total)=41808.91796875MB
INFO:root:[   59] Training loss: 0.63150765, Validation loss: 0.62143995, Gradient norm: 0.05351181
INFO:root:At the start of the epoch: mem (CPU python)=41898.296875MB; mem (CPU total)=41872.28125MB
INFO:root:[   60] Training loss: 0.63120089, Validation loss: 0.62019717, Gradient norm: 0.04985481
INFO:root:At the start of the epoch: mem (CPU python)=41898.89453125MB; mem (CPU total)=41872.765625MB
INFO:root:[   61] Training loss: 0.63071971, Validation loss: 0.62041522, Gradient norm: 0.05630081
INFO:root:At the start of the epoch: mem (CPU python)=41962.015625MB; mem (CPU total)=41935.86328125MB
INFO:root:[   62] Training loss: 0.63072049, Validation loss: 0.61998330, Gradient norm: 0.05764713
INFO:root:At the start of the epoch: mem (CPU python)=41987.5859375MB; mem (CPU total)=41960.75MB
INFO:root:[   63] Training loss: 0.63044518, Validation loss: 0.61995550, Gradient norm: 0.05878165
INFO:root:At the start of the epoch: mem (CPU python)=42038.2109375MB; mem (CPU total)=42011.37109375MB
INFO:root:[   64] Training loss: 0.63033393, Validation loss: 0.61977571, Gradient norm: 0.05580054
INFO:root:At the start of the epoch: mem (CPU python)=42101.27734375MB; mem (CPU total)=42074.69921875MB
INFO:root:[   65] Training loss: 0.62958969, Validation loss: 0.61940500, Gradient norm: 0.05058049
INFO:root:At the start of the epoch: mem (CPU python)=42139.37109375MB; mem (CPU total)=42112.84375MB
INFO:root:[   66] Training loss: 0.62922048, Validation loss: 0.61966073, Gradient norm: 0.05774198
INFO:root:At the start of the epoch: mem (CPU python)=42139.96484375MB; mem (CPU total)=42115.1953125MB
INFO:root:[   67] Training loss: 0.62902665, Validation loss: 0.61873052, Gradient norm: 0.05707649
INFO:root:At the start of the epoch: mem (CPU python)=42190.58984375MB; mem (CPU total)=42165.6171875MB
INFO:root:[   68] Training loss: 0.62851806, Validation loss: 0.61906484, Gradient norm: 0.05631871
INFO:root:At the start of the epoch: mem (CPU python)=42228.68359375MB; mem (CPU total)=42204.0078125MB
INFO:root:[   69] Training loss: 0.62845497, Validation loss: 0.61818621, Gradient norm: 0.06145914
INFO:root:At the start of the epoch: mem (CPU python)=42241.75MB; mem (CPU total)=42214.9921875MB
INFO:root:[   70] Training loss: 0.62791602, Validation loss: 0.61823913, Gradient norm: 0.05728305
INFO:root:At the start of the epoch: mem (CPU python)=42304.875MB; mem (CPU total)=42278.09375MB
INFO:root:[   71] Training loss: 0.62783112, Validation loss: 0.61868293, Gradient norm: 0.05860946
INFO:root:At the start of the epoch: mem (CPU python)=42342.97265625MB; mem (CPU total)=42315.85546875MB
INFO:root:[   72] Training loss: 0.62751604, Validation loss: 0.61735723, Gradient norm: 0.06411900
INFO:root:At the start of the epoch: mem (CPU python)=42378.921875MB; mem (CPU total)=42316.61328125MB
INFO:root:[   73] Training loss: 0.62725544, Validation loss: 0.61797010, Gradient norm: 0.05714791
INFO:root:At the start of the epoch: mem (CPU python)=42419.16015625MB; mem (CPU total)=42391.92578125MB
INFO:root:[   74] Training loss: 0.62711805, Validation loss: 0.61642957, Gradient norm: 0.05745624
INFO:root:At the start of the epoch: mem (CPU python)=42432.23046875MB; mem (CPU total)=42404.1640625MB
INFO:root:[   75] Training loss: 0.62677337, Validation loss: 0.61704568, Gradient norm: 0.06032537
INFO:root:At the start of the epoch: mem (CPU python)=42470.328125MB; mem (CPU total)=42442.30859375MB
INFO:root:[   76] Training loss: 0.62654410, Validation loss: 0.61796838, Gradient norm: 0.05912503
INFO:root:At the start of the epoch: mem (CPU python)=42508.41796875MB; mem (CPU total)=42480.9140625MB
INFO:root:[   77] Training loss: 0.62630969, Validation loss: 0.61681182, Gradient norm: 0.05745543
INFO:root:At the start of the epoch: mem (CPU python)=42567.55078125MB; mem (CPU total)=42494.08984375MB
INFO:root:[   78] Training loss: 0.62629734, Validation loss: 0.61669821, Gradient norm: 0.06371879
INFO:root:At the start of the epoch: mem (CPU python)=42622.11328125MB; mem (CPU total)=42594.6015625MB
INFO:root:[   79] Training loss: 0.62563621, Validation loss: 0.61645508, Gradient norm: 0.05982171
INFO:root:At the start of the epoch: mem (CPU python)=42635.20703125MB; mem (CPU total)=42607.7578125MB
INFO:root:[   80] Training loss: 0.62555805, Validation loss: 0.61544009, Gradient norm: 0.06036403
INFO:root:At the start of the epoch: mem (CPU python)=42698.3046875MB; mem (CPU total)=42670.8984375MB
INFO:root:[   81] Training loss: 0.62509233, Validation loss: 0.61565548, Gradient norm: 0.05325958
INFO:root:At the start of the epoch: mem (CPU python)=42711.3984375MB; mem (CPU total)=42685.78125MB
INFO:root:[   82] Training loss: 0.62525132, Validation loss: 0.61536006, Gradient norm: 0.06218917
INFO:root:At the start of the epoch: mem (CPU python)=42749.4921875MB; mem (CPU total)=42723.92578125MB
INFO:root:[   83] Training loss: 0.62478266, Validation loss: 0.61631593, Gradient norm: 0.06173456
INFO:root:At the start of the epoch: mem (CPU python)=42812.5859375MB; mem (CPU total)=42784.84375MB
INFO:root:[   84] Training loss: 0.62450602, Validation loss: 0.61553375, Gradient norm: 0.06002803
INFO:root:At the start of the epoch: mem (CPU python)=42850.68359375MB; mem (CPU total)=42822.9609375MB
INFO:root:[   85] Training loss: 0.62438999, Validation loss: 0.61484749, Gradient norm: 0.06326723
INFO:root:At the start of the epoch: mem (CPU python)=42888.78125MB; mem (CPU total)=42860.9296875MB
INFO:root:[   86] Training loss: 0.62416454, Validation loss: 0.61476386, Gradient norm: 0.06473394
INFO:root:At the start of the epoch: mem (CPU python)=42926.875MB; mem (CPU total)=42898.79296875MB
INFO:root:[   87] Training loss: 0.62391118, Validation loss: 0.61408001, Gradient norm: 0.05694522
INFO:root:At the start of the epoch: mem (CPU python)=42939.97265625MB; mem (CPU total)=42911.73828125MB
INFO:root:[   88] Training loss: 0.62347365, Validation loss: 0.61394598, Gradient norm: 0.06599278
INFO:root:At the start of the epoch: mem (CPU python)=43003.06640625MB; mem (CPU total)=42974.90234375MB
INFO:root:[   89] Training loss: 0.62330802, Validation loss: 0.61439956, Gradient norm: 0.06406714
INFO:root:At the start of the epoch: mem (CPU python)=43041.16015625MB; mem (CPU total)=43013.015625MB
INFO:root:[   90] Training loss: 0.62336587, Validation loss: 0.61480931, Gradient norm: 0.06089627
INFO:root:At the start of the epoch: mem (CPU python)=43054.25390625MB; mem (CPU total)=43028.0859375MB
INFO:root:[   91] Training loss: 0.62277338, Validation loss: 0.61426942, Gradient norm: 0.05703057
INFO:root:At the start of the epoch: mem (CPU python)=43092.3515625MB; mem (CPU total)=43066.19921875MB
INFO:root:[   92] Training loss: 0.62295411, Validation loss: 0.61351078, Gradient norm: 0.06227370
INFO:root:At the start of the epoch: mem (CPU python)=43155.44921875MB; mem (CPU total)=43129.57421875MB
INFO:root:[   93] Training loss: 0.62244230, Validation loss: 0.61491290, Gradient norm: 0.05849771
INFO:root:At the start of the epoch: mem (CPU python)=43165.453125MB; mem (CPU total)=43102.890625MB
INFO:root:[   94] Training loss: 0.62235314, Validation loss: 0.61348311, Gradient norm: 0.06216507
INFO:root:At the start of the epoch: mem (CPU python)=43206.63671875MB; mem (CPU total)=43178.48046875MB
INFO:root:[   95] Training loss: 0.62234641, Validation loss: 0.61292958, Gradient norm: 0.06538955
INFO:root:At the start of the epoch: mem (CPU python)=43244.734375MB; mem (CPU total)=43216.80859375MB
INFO:root:[   96] Training loss: 0.62189622, Validation loss: 0.61273493, Gradient norm: 0.06018341
INFO:root:At the start of the epoch: mem (CPU python)=43282.828125MB; mem (CPU total)=43255.1015625MB
INFO:root:[   97] Training loss: 0.62168256, Validation loss: 0.61336139, Gradient norm: 0.06093356
INFO:root:At the start of the epoch: mem (CPU python)=43395.92578125MB; mem (CPU total)=43368.15234375MB
INFO:root:[   98] Training loss: 0.62160504, Validation loss: 0.61292881, Gradient norm: 0.06405946
INFO:root:At the start of the epoch: mem (CPU python)=43396.14453125MB; mem (CPU total)=43345.64453125MB
INFO:root:[   99] Training loss: 0.62155255, Validation loss: 0.61306732, Gradient norm: 0.06367513
INFO:root:At the start of the epoch: mem (CPU python)=43409.73828125MB; mem (CPU total)=43383.72265625MB
INFO:root:[  100] Training loss: 0.62132025, Validation loss: 0.61288612, Gradient norm: 0.06841123
INFO:root:At the start of the epoch: mem (CPU python)=43422.70703125MB; mem (CPU total)=43394.66796875MB
INFO:root:[  101] Training loss: 0.62102801, Validation loss: 0.61209037, Gradient norm: 0.06859012
INFO:root:At the start of the epoch: mem (CPU python)=43460.8046875MB; mem (CPU total)=43432.8046875MB
INFO:root:[  102] Training loss: 0.62092780, Validation loss: 0.61195890, Gradient norm: 0.06273279
INFO:root:At the start of the epoch: mem (CPU python)=43498.8984375MB; mem (CPU total)=43471.2890625MB
INFO:root:[  103] Training loss: 0.62055828, Validation loss: 0.61233860, Gradient norm: 0.06035410
INFO:root:At the start of the epoch: mem (CPU python)=43549.49609375MB; mem (CPU total)=43521.89453125MB
INFO:root:[  104] Training loss: 0.62036778, Validation loss: 0.61164577, Gradient norm: 0.06476234
INFO:root:At the start of the epoch: mem (CPU python)=43587.59375MB; mem (CPU total)=43559.7421875MB
INFO:root:[  105] Training loss: 0.62019862, Validation loss: 0.61228117, Gradient norm: 0.06162693
INFO:root:At the start of the epoch: mem (CPU python)=43625.6875MB; mem (CPU total)=43597.671875MB
INFO:root:[  106] Training loss: 0.61991646, Validation loss: 0.61103874, Gradient norm: 0.05876480
INFO:root:At the start of the epoch: mem (CPU python)=43676.30859375MB; mem (CPU total)=43648.30859375MB
INFO:root:[  107] Training loss: 0.61956728, Validation loss: 0.61158228, Gradient norm: 0.06049038
INFO:root:At the start of the epoch: mem (CPU python)=43714.40234375MB; mem (CPU total)=43686.19921875MB
INFO:root:[  108] Training loss: 0.61960961, Validation loss: 0.61191952, Gradient norm: 0.06407612
INFO:root:At the start of the epoch: mem (CPU python)=43764.97265625MB; mem (CPU total)=43737.08203125MB
INFO:root:[  109] Training loss: 0.61957808, Validation loss: 0.61060799, Gradient norm: 0.05970512
INFO:root:At the start of the epoch: mem (CPU python)=43803.0703125MB; mem (CPU total)=43778.08984375MB
INFO:root:[  110] Training loss: 0.61935457, Validation loss: 0.61023381, Gradient norm: 0.06930521
INFO:root:At the start of the epoch: mem (CPU python)=43816.16015625MB; mem (CPU total)=43790.875MB
INFO:root:[  111] Training loss: 0.61914233, Validation loss: 0.61085944, Gradient norm: 0.06219424
INFO:root:At the start of the epoch: mem (CPU python)=43841.76171875MB; mem (CPU total)=43815.76953125MB
INFO:root:[  112] Training loss: 0.61899241, Validation loss: 0.61079410, Gradient norm: 0.06222282
INFO:root:At the start of the epoch: mem (CPU python)=43904.8828125MB; mem (CPU total)=43878.65625MB
INFO:root:[  113] Training loss: 0.61878784, Validation loss: 0.61107501, Gradient norm: 0.06352494
INFO:root:At the start of the epoch: mem (CPU python)=43917.94921875MB; mem (CPU total)=43891.56640625MB
INFO:root:[  114] Training loss: 0.61871284, Validation loss: 0.61096150, Gradient norm: 0.05975471
INFO:root:At the start of the epoch: mem (CPU python)=43968.546875MB; mem (CPU total)=43942.140625MB
INFO:root:[  115] Training loss: 0.61874263, Validation loss: 0.61065670, Gradient norm: 0.06964249
INFO:root:At the start of the epoch: mem (CPU python)=44019.16796875MB; mem (CPU total)=43992.90234375MB
INFO:root:[  116] Training loss: 0.61843793, Validation loss: 0.61069890, Gradient norm: 0.06483201
INFO:root:At the start of the epoch: mem (CPU python)=44032.234375MB; mem (CPU total)=44005.84765625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  117] Training loss: 0.61812860, Validation loss: 0.61130166, Gradient norm: 0.06367075
INFO:root:At the start of the epoch: mem (CPU python)=44070.328125MB; mem (CPU total)=44043.9921875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  118] Training loss: 0.61729862, Validation loss: 0.60964399, Gradient norm: 0.06012731
INFO:root:At the start of the epoch: mem (CPU python)=44120.92578125MB; mem (CPU total)=44094.91015625MB
INFO:root:[  119] Training loss: 0.61650420, Validation loss: 0.60997291, Gradient norm: 0.05424279
INFO:root:At the start of the epoch: mem (CPU python)=44159.0234375MB; mem (CPU total)=44132.796875MB
INFO:root:[  120] Training loss: 0.61656954, Validation loss: 0.60874483, Gradient norm: 0.05413755
INFO:root:At the start of the epoch: mem (CPU python)=44184.6171875MB; mem (CPU total)=44158.54296875MB
INFO:root:[  121] Training loss: 0.61637895, Validation loss: 0.60893256, Gradient norm: 0.05404573
INFO:root:At the start of the epoch: mem (CPU python)=44247.74609375MB; mem (CPU total)=44221.34765625MB
INFO:root:[  122] Training loss: 0.61635263, Validation loss: 0.60915779, Gradient norm: 0.05300440
INFO:root:At the start of the epoch: mem (CPU python)=44273.3125MB; mem (CPU total)=44246.875MB
INFO:root:[  123] Training loss: 0.61618596, Validation loss: 0.60978284, Gradient norm: 0.05358923
INFO:root:At the start of the epoch: mem (CPU python)=44323.93359375MB; mem (CPU total)=44298.2890625MB
INFO:root:[  124] Training loss: 0.61614136, Validation loss: 0.60901844, Gradient norm: 0.05389014
INFO:root:At the start of the epoch: mem (CPU python)=44362.02734375MB; mem (CPU total)=44336.84765625MB
INFO:root:[  125] Training loss: 0.61623951, Validation loss: 0.60900537, Gradient norm: 0.05483533
INFO:root:At the start of the epoch: mem (CPU python)=44400.12890625MB; mem (CPU total)=44374.1171875MB
INFO:root:[  126] Training loss: 0.61615099, Validation loss: 0.60878823, Gradient norm: 0.05299618
INFO:root:At the start of the epoch: mem (CPU python)=44450.6953125MB; mem (CPU total)=44424.9921875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  127] Training loss: 0.61583395, Validation loss: 0.60976230, Gradient norm: 0.05519143
INFO:root:At the start of the epoch: mem (CPU python)=44488.7890625MB; mem (CPU total)=44462.890625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  128] Training loss: 0.61563874, Validation loss: 0.60881871, Gradient norm: 0.05479895
INFO:root:At the start of the epoch: mem (CPU python)=44501.88671875MB; mem (CPU total)=44476.05078125MB
INFO:root:[  129] Training loss: 0.61560909, Validation loss: 0.60875756, Gradient norm: 0.04973542
INFO:root:At the start of the epoch: mem (CPU python)=44552.5078125MB; mem (CPU total)=44526.92578125MB
INFO:root:[  130] Training loss: 0.61548044, Validation loss: 0.60822982, Gradient norm: 0.05122229
INFO:root:At the start of the epoch: mem (CPU python)=44578.07421875MB; mem (CPU total)=44552.203125MB
INFO:root:[  131] Training loss: 0.61560838, Validation loss: 0.60979014, Gradient norm: 0.05247490
INFO:root:At the start of the epoch: mem (CPU python)=44628.69921875MB; mem (CPU total)=44603.64453125MB
INFO:root:[  132] Training loss: 0.61526846, Validation loss: 0.60826311, Gradient norm: 0.05238939
INFO:root:At the start of the epoch: mem (CPU python)=44654.265625MB; mem (CPU total)=44628.8046875MB
INFO:root:[  133] Training loss: 0.61542687, Validation loss: 0.60810957, Gradient norm: 0.05215951
INFO:root:At the start of the epoch: mem (CPU python)=44704.88671875MB; mem (CPU total)=44679.6796875MB
INFO:root:[  134] Training loss: 0.61556188, Validation loss: 0.60890892, Gradient norm: 0.05150249
INFO:root:At the start of the epoch: mem (CPU python)=44730.453125MB; mem (CPU total)=44705.33203125MB
INFO:root:[  135] Training loss: 0.61520233, Validation loss: 0.60843639, Gradient norm: 0.05064149
INFO:root:At the start of the epoch: mem (CPU python)=44764.06640625MB; mem (CPU total)=44718.30078125MB
INFO:root:[  136] Training loss: 0.61550507, Validation loss: 0.60849277, Gradient norm: 0.05232591
INFO:root:At the start of the epoch: mem (CPU python)=44794.1484375MB; mem (CPU total)=44768.84375MB
INFO:root:[  137] Training loss: 0.61539872, Validation loss: 0.60849364, Gradient norm: 0.05023024
INFO:root:At the start of the epoch: mem (CPU python)=44869.7421875MB; mem (CPU total)=44844.6796875MB
INFO:root:[  138] Training loss: 0.61533527, Validation loss: 0.60850129, Gradient norm: 0.05045262
INFO:root:At the start of the epoch: mem (CPU python)=44870.33984375MB; mem (CPU total)=44844.73828125MB
INFO:root:[  139] Training loss: 0.61554098, Validation loss: 0.60850876, Gradient norm: 0.05079252
INFO:root:At the start of the epoch: mem (CPU python)=44933.46484375MB; mem (CPU total)=44907.8359375MB
INFO:root:[  140] Training loss: 0.61529348, Validation loss: 0.60843704, Gradient norm: 0.05117919
INFO:root:At the start of the epoch: mem (CPU python)=44946.52734375MB; mem (CPU total)=44921.02734375MB
INFO:root:[  141] Training loss: 0.61530827, Validation loss: 0.60839043, Gradient norm: 0.05164671
INFO:root:At the start of the epoch: mem (CPU python)=45009.6484375MB; mem (CPU total)=44984.6171875MB
INFO:root:[  142] Training loss: 0.61534053, Validation loss: 0.60839812, Gradient norm: 0.05203858
INFO:root:At the start of the epoch: mem (CPU python)=45047.74609375MB; mem (CPU total)=45022.5078125MB
INFO:root:EP 142: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=45085.83984375MB; mem (CPU total)=45060.65234375MB
INFO:root:Training the model took 12190.697s.
INFO:root:Emptying the cuda cache took 0.03s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84625
INFO:root:EnergyScoreTrain: 0.59578
INFO:root:CRPSTrain: 0.46353
INFO:root:Gaussian NLLTrain: 1.20224
INFO:root:CoverageTrain: 0.94967
INFO:root:IntervalWidthTrain: 3.28667
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86447
INFO:root:EnergyScoreValidation: 0.60848
INFO:root:CRPSValidation: 0.47444
INFO:root:Gaussian NLLValidation: 1.22791
INFO:root:CoverageValidation: 0.94394
INFO:root:IntervalWidthValidation: 3.2895
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86595
INFO:root:EnergyScoreTest: 0.60952
INFO:root:CRPSTest: 0.47532
INFO:root:Gaussian NLLTest: 1.2291
INFO:root:CoverageTest: 0.94344
INFO:root:IntervalWidthTest: 3.28909
INFO:root:After validation: mem (CPU python)=45175.36328125MB; mem (CPU total)=45122.58203125MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=45175.36328125MB; mem (CPU total)=45122.3359375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=45175.36328125MB; mem (CPU total)=45122.58203125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=45175.36328125MB; mem (CPU total)=45122.6015625MB
INFO:root:[    1] Training loss: 0.72540279, Validation loss: 0.72059993, Gradient norm: 0.02101160
INFO:root:At the start of the epoch: mem (CPU python)=45175.36328125MB; mem (CPU total)=45117.0078125MB
INFO:root:[    2] Training loss: 0.72001826, Validation loss: 0.71912206, Gradient norm: 0.00587358
INFO:root:At the start of the epoch: mem (CPU python)=45175.36328125MB; mem (CPU total)=45117.73828125MB
INFO:root:[    3] Training loss: 0.71863308, Validation loss: 0.71784130, Gradient norm: 0.00772748
INFO:root:At the start of the epoch: mem (CPU python)=45193.4921875MB; mem (CPU total)=45168.375MB
INFO:root:[    4] Training loss: 0.71520378, Validation loss: 0.70924388, Gradient norm: 0.01279777
INFO:root:At the start of the epoch: mem (CPU python)=45256.55859375MB; mem (CPU total)=45231.71875MB
INFO:root:[    5] Training loss: 0.70741586, Validation loss: 0.70187872, Gradient norm: 0.02367800
INFO:root:At the start of the epoch: mem (CPU python)=45294.65234375MB; mem (CPU total)=45269.859375MB
INFO:root:[    6] Training loss: 0.70115483, Validation loss: 0.69475439, Gradient norm: 0.02729102
INFO:root:At the start of the epoch: mem (CPU python)=45332.75MB; mem (CPU total)=45308.00390625MB
INFO:root:[    7] Training loss: 0.69491598, Validation loss: 0.68650729, Gradient norm: 0.02879401
INFO:root:At the start of the epoch: mem (CPU python)=45358.34375MB; mem (CPU total)=45333.58984375MB
INFO:root:[    8] Training loss: 0.68815052, Validation loss: 0.67895514, Gradient norm: 0.03048252
INFO:root:At the start of the epoch: mem (CPU python)=45433.7421875MB; mem (CPU total)=45359.87109375MB
INFO:root:[    9] Training loss: 0.68239675, Validation loss: 0.67309588, Gradient norm: 0.03045572
INFO:root:At the start of the epoch: mem (CPU python)=45434.53515625MB; mem (CPU total)=45410.25390625MB
INFO:root:[   10] Training loss: 0.67739911, Validation loss: 0.66717452, Gradient norm: 0.02868455
INFO:root:At the start of the epoch: mem (CPU python)=45485.12890625MB; mem (CPU total)=45461.10546875MB
INFO:root:[   11] Training loss: 0.67312891, Validation loss: 0.66334541, Gradient norm: 0.02901890
INFO:root:At the start of the epoch: mem (CPU python)=45510.7265625MB; mem (CPU total)=45486.54296875MB
INFO:root:[   12] Training loss: 0.66966102, Validation loss: 0.65950906, Gradient norm: 0.03037777
INFO:root:At the start of the epoch: mem (CPU python)=45548.8203125MB; mem (CPU total)=45524.93359375MB
INFO:root:[   13] Training loss: 0.66672694, Validation loss: 0.65593734, Gradient norm: 0.02996649
INFO:root:At the start of the epoch: mem (CPU python)=45586.91796875MB; mem (CPU total)=45561.80859375MB
INFO:root:[   14] Training loss: 0.66410118, Validation loss: 0.65393770, Gradient norm: 0.03375442
INFO:root:At the start of the epoch: mem (CPU python)=45625.01171875MB; mem (CPU total)=45599.05859375MB
INFO:root:[   15] Training loss: 0.66166575, Validation loss: 0.65161630, Gradient norm: 0.03278755
INFO:root:At the start of the epoch: mem (CPU python)=45675.60546875MB; mem (CPU total)=45650.1875MB
INFO:root:[   16] Training loss: 0.65961603, Validation loss: 0.64924352, Gradient norm: 0.02972394
INFO:root:At the start of the epoch: mem (CPU python)=45701.203125MB; mem (CPU total)=45675.90234375MB
INFO:root:[   17] Training loss: 0.65768695, Validation loss: 0.64683824, Gradient norm: 0.02920864
INFO:root:At the start of the epoch: mem (CPU python)=45764.296875MB; mem (CPU total)=45739.16015625MB
INFO:root:[   18] Training loss: 0.65604937, Validation loss: 0.64536536, Gradient norm: 0.03216835
INFO:root:At the start of the epoch: mem (CPU python)=45764.921875MB; mem (CPU total)=45739.6328125MB
INFO:root:[   19] Training loss: 0.65427590, Validation loss: 0.64326042, Gradient norm: 0.03357885
INFO:root:At the start of the epoch: mem (CPU python)=45815.48828125MB; mem (CPU total)=45790.0234375MB
INFO:root:[   20] Training loss: 0.65266621, Validation loss: 0.64173906, Gradient norm: 0.03392032
INFO:root:At the start of the epoch: mem (CPU python)=45853.5859375MB; mem (CPU total)=45828.30078125MB
INFO:root:[   21] Training loss: 0.65123988, Validation loss: 0.63973215, Gradient norm: 0.03488366
INFO:root:At the start of the epoch: mem (CPU python)=45916.6796875MB; mem (CPU total)=45891.3125MB
INFO:root:[   22] Training loss: 0.64997151, Validation loss: 0.63926452, Gradient norm: 0.03395214
INFO:root:At the start of the epoch: mem (CPU python)=45942.2734375MB; mem (CPU total)=45917.2421875MB
INFO:root:[   23] Training loss: 0.64877990, Validation loss: 0.63766387, Gradient norm: 0.03565959
INFO:root:At the start of the epoch: mem (CPU python)=45955.3984375MB; mem (CPU total)=45930.46484375MB
INFO:root:[   24] Training loss: 0.64757247, Validation loss: 0.63664297, Gradient norm: 0.03295020
INFO:root:At the start of the epoch: mem (CPU python)=45993.4921875MB; mem (CPU total)=45968.85546875MB
INFO:root:[   25] Training loss: 0.64631698, Validation loss: 0.63518959, Gradient norm: 0.03607157
INFO:root:At the start of the epoch: mem (CPU python)=46044.0625MB; mem (CPU total)=46019.45703125MB
INFO:root:[   26] Training loss: 0.64551848, Validation loss: 0.63440070, Gradient norm: 0.03923995
INFO:root:At the start of the epoch: mem (CPU python)=46105.96484375MB; mem (CPU total)=46057.38671875MB
INFO:root:[   27] Training loss: 0.64446259, Validation loss: 0.63378601, Gradient norm: 0.04209884
INFO:root:At the start of the epoch: mem (CPU python)=46120.25390625MB; mem (CPU total)=46095.80078125MB
INFO:root:[   28] Training loss: 0.64363104, Validation loss: 0.63274612, Gradient norm: 0.04110547
INFO:root:At the start of the epoch: mem (CPU python)=46158.34765625MB; mem (CPU total)=46134.4375MB
INFO:root:[   29] Training loss: 0.64261003, Validation loss: 0.63121209, Gradient norm: 0.03831340
INFO:root:At the start of the epoch: mem (CPU python)=46221.44140625MB; mem (CPU total)=46199.07421875MB
INFO:root:[   30] Training loss: 0.64159182, Validation loss: 0.63033758, Gradient norm: 0.03779610
INFO:root:At the start of the epoch: mem (CPU python)=46259.5390625MB; mem (CPU total)=46237.33984375MB
INFO:root:[   31] Training loss: 0.64090341, Validation loss: 0.62958178, Gradient norm: 0.04291081
INFO:root:At the start of the epoch: mem (CPU python)=46260.26953125MB; mem (CPU total)=46237.82421875MB
INFO:root:[   32] Training loss: 0.64025072, Validation loss: 0.62961823, Gradient norm: 0.04129901
INFO:root:At the start of the epoch: mem (CPU python)=46335.6875MB; mem (CPU total)=46252.0MB
INFO:root:[   33] Training loss: 0.63946518, Validation loss: 0.62770690, Gradient norm: 0.04178732
INFO:root:At the start of the epoch: mem (CPU python)=46348.83203125MB; mem (CPU total)=46326.4140625MB
INFO:root:[   34] Training loss: 0.63878702, Validation loss: 0.62782478, Gradient norm: 0.04667780
INFO:root:At the start of the epoch: mem (CPU python)=46386.92578125MB; mem (CPU total)=46364.34375MB
INFO:root:[   35] Training loss: 0.63796056, Validation loss: 0.62640133, Gradient norm: 0.04138805
INFO:root:At the start of the epoch: mem (CPU python)=46462.546875MB; mem (CPU total)=46440.640625MB
INFO:root:[   36] Training loss: 0.63749884, Validation loss: 0.62647972, Gradient norm: 0.04343065
INFO:root:At the start of the epoch: mem (CPU python)=46500.640625MB; mem (CPU total)=46478.28125MB
INFO:root:[   37] Training loss: 0.63666153, Validation loss: 0.62495293, Gradient norm: 0.04221852
INFO:root:At the start of the epoch: mem (CPU python)=46538.73828125MB; mem (CPU total)=46516.6953125MB
INFO:root:[   38] Training loss: 0.63621592, Validation loss: 0.62494313, Gradient norm: 0.04879347
INFO:root:At the start of the epoch: mem (CPU python)=46539.3046875MB; mem (CPU total)=46517.1796875MB
INFO:root:[   39] Training loss: 0.63559895, Validation loss: 0.62485217, Gradient norm: 0.03995879
INFO:root:At the start of the epoch: mem (CPU python)=46602.3984375MB; mem (CPU total)=46580.4921875MB
INFO:root:[   40] Training loss: 0.63495630, Validation loss: 0.62390868, Gradient norm: 0.04294792
INFO:root:At the start of the epoch: mem (CPU python)=46640.484375MB; mem (CPU total)=46618.0MB
INFO:root:[   41] Training loss: 0.63448915, Validation loss: 0.62393744, Gradient norm: 0.04408791
INFO:root:At the start of the epoch: mem (CPU python)=46666.078125MB; mem (CPU total)=46643.55078125MB
INFO:root:[   42] Training loss: 0.63401413, Validation loss: 0.62354297, Gradient norm: 0.04406564
INFO:root:At the start of the epoch: mem (CPU python)=46696.55859375MB; mem (CPU total)=46669.48046875MB
INFO:root:[   43] Training loss: 0.63348298, Validation loss: 0.62277439, Gradient norm: 0.04609800
INFO:root:At the start of the epoch: mem (CPU python)=46742.2734375MB; mem (CPU total)=46720.0859375MB
INFO:root:[   44] Training loss: 0.63307721, Validation loss: 0.62225916, Gradient norm: 0.04496070
INFO:root:At the start of the epoch: mem (CPU python)=46755.39453125MB; mem (CPU total)=46733.27734375MB
INFO:root:[   45] Training loss: 0.63244501, Validation loss: 0.62099655, Gradient norm: 0.04240673
INFO:root:At the start of the epoch: mem (CPU python)=46818.4609375MB; mem (CPU total)=46794.8984375MB
INFO:root:[   46] Training loss: 0.63206426, Validation loss: 0.62134364, Gradient norm: 0.05007788
INFO:root:At the start of the epoch: mem (CPU python)=46831.58203125MB; mem (CPU total)=46808.0859375MB
INFO:root:[   47] Training loss: 0.63148259, Validation loss: 0.62118594, Gradient norm: 0.04572853
INFO:root:At the start of the epoch: mem (CPU python)=46882.15625MB; mem (CPU total)=46858.9921875MB
INFO:root:[   48] Training loss: 0.63101951, Validation loss: 0.61991035, Gradient norm: 0.04551859
INFO:root:At the start of the epoch: mem (CPU python)=46957.7734375MB; mem (CPU total)=46934.40625MB
INFO:root:[   49] Training loss: 0.63067966, Validation loss: 0.61953338, Gradient norm: 0.04626389
INFO:root:At the start of the epoch: mem (CPU python)=46970.84765625MB; mem (CPU total)=46947.875MB
INFO:root:[   50] Training loss: 0.63022685, Validation loss: 0.62018438, Gradient norm: 0.04582994
INFO:root:At the start of the epoch: mem (CPU python)=47021.4453125MB; mem (CPU total)=46998.48046875MB
INFO:root:[   51] Training loss: 0.62981880, Validation loss: 0.61953621, Gradient norm: 0.04438806
INFO:root:At the start of the epoch: mem (CPU python)=47084.5390625MB; mem (CPU total)=47061.578125MB
INFO:root:[   52] Training loss: 0.62951995, Validation loss: 0.61948271, Gradient norm: 0.04453165
INFO:root:At the start of the epoch: mem (CPU python)=47084.76171875MB; mem (CPU total)=47039.078125MB
INFO:root:[   53] Training loss: 0.62917977, Validation loss: 0.61939921, Gradient norm: 0.05340316
INFO:root:At the start of the epoch: mem (CPU python)=47132.73828125MB; mem (CPU total)=47088.046875MB
INFO:root:[   54] Training loss: 0.62872732, Validation loss: 0.61792872, Gradient norm: 0.04322458
INFO:root:At the start of the epoch: mem (CPU python)=47148.82421875MB; mem (CPU total)=47125.7890625MB
INFO:root:[   55] Training loss: 0.62835244, Validation loss: 0.61737724, Gradient norm: 0.04710441
INFO:root:At the start of the epoch: mem (CPU python)=47224.4453125MB; mem (CPU total)=47201.87109375MB
INFO:root:[   56] Training loss: 0.62795496, Validation loss: 0.61808665, Gradient norm: 0.04505456
INFO:root:At the start of the epoch: mem (CPU python)=47262.5390625MB; mem (CPU total)=47240.0390625MB
INFO:root:[   57] Training loss: 0.62779205, Validation loss: 0.61770462, Gradient norm: 0.05600959
INFO:root:At the start of the epoch: mem (CPU python)=47275.609375MB; mem (CPU total)=47252.78515625MB
INFO:root:[   58] Training loss: 0.62734261, Validation loss: 0.61735452, Gradient norm: 0.05716190
INFO:root:At the start of the epoch: mem (CPU python)=47338.734375MB; mem (CPU total)=47315.875MB
INFO:root:[   59] Training loss: 0.62708832, Validation loss: 0.61742100, Gradient norm: 0.04767096
INFO:root:At the start of the epoch: mem (CPU python)=47364.296875MB; mem (CPU total)=47341.5546875MB
INFO:root:[   60] Training loss: 0.62667245, Validation loss: 0.61670140, Gradient norm: 0.04990905
INFO:root:At the start of the epoch: mem (CPU python)=47364.921875MB; mem (CPU total)=47342.18359375MB
INFO:root:[   61] Training loss: 0.62633778, Validation loss: 0.61588993, Gradient norm: 0.04904832
INFO:root:At the start of the epoch: mem (CPU python)=47440.4921875MB; mem (CPU total)=47417.7265625MB
INFO:root:[   62] Training loss: 0.62588303, Validation loss: 0.61553270, Gradient norm: 0.04829451
INFO:root:At the start of the epoch: mem (CPU python)=47478.5859375MB; mem (CPU total)=47455.625MB
INFO:root:[   63] Training loss: 0.62582762, Validation loss: 0.61557559, Gradient norm: 0.04521733
INFO:root:At the start of the epoch: mem (CPU python)=47491.6796875MB; mem (CPU total)=47469.0625MB
INFO:root:[   64] Training loss: 0.62537476, Validation loss: 0.61515506, Gradient norm: 0.04936010
INFO:root:At the start of the epoch: mem (CPU python)=47554.77734375MB; mem (CPU total)=47532.09765625MB
INFO:root:[   65] Training loss: 0.62505207, Validation loss: 0.61711626, Gradient norm: 0.04924223
INFO:root:At the start of the epoch: mem (CPU python)=47592.87109375MB; mem (CPU total)=47570.2421875MB
INFO:root:[   66] Training loss: 0.62482083, Validation loss: 0.61452339, Gradient norm: 0.04991785
INFO:root:At the start of the epoch: mem (CPU python)=47618.46484375MB; mem (CPU total)=47595.9375MB
INFO:root:[   67] Training loss: 0.62472203, Validation loss: 0.61395036, Gradient norm: 0.05303274
INFO:root:At the start of the epoch: mem (CPU python)=47644.0625MB; mem (CPU total)=47621.65234375MB
INFO:root:[   68] Training loss: 0.62427911, Validation loss: 0.61361565, Gradient norm: 0.05323308
INFO:root:At the start of the epoch: mem (CPU python)=47694.65625MB; mem (CPU total)=47672.50390625MB
INFO:root:[   69] Training loss: 0.62404966, Validation loss: 0.61379871, Gradient norm: 0.05511534
INFO:root:At the start of the epoch: mem (CPU python)=47707.77734375MB; mem (CPU total)=47685.41796875MB
INFO:root:[   70] Training loss: 0.62367302, Validation loss: 0.61289496, Gradient norm: 0.04562947
INFO:root:At the start of the epoch: mem (CPU python)=47758.34375MB; mem (CPU total)=47736.30078125MB
INFO:root:[   71] Training loss: 0.62353333, Validation loss: 0.61404905, Gradient norm: 0.05664089
INFO:root:At the start of the epoch: mem (CPU python)=47796.44140625MB; mem (CPU total)=47774.4453125MB
INFO:root:[   72] Training loss: 0.62321562, Validation loss: 0.61305249, Gradient norm: 0.05400731
INFO:root:At the start of the epoch: mem (CPU python)=47834.5390625MB; mem (CPU total)=47812.59765625MB
INFO:root:[   73] Training loss: 0.62297977, Validation loss: 0.61320137, Gradient norm: 0.05090550
INFO:root:At the start of the epoch: mem (CPU python)=47872.6328125MB; mem (CPU total)=47850.41796875MB
INFO:root:[   74] Training loss: 0.62269771, Validation loss: 0.61250516, Gradient norm: 0.05398836
INFO:root:At the start of the epoch: mem (CPU python)=47910.73046875MB; mem (CPU total)=47888.86328125MB
INFO:root:[   75] Training loss: 0.62229814, Validation loss: 0.61203825, Gradient norm: 0.05733951
INFO:root:At the start of the epoch: mem (CPU python)=47961.32421875MB; mem (CPU total)=47939.5MB
INFO:root:[   76] Training loss: 0.62210674, Validation loss: 0.61212308, Gradient norm: 0.05265692
INFO:root:At the start of the epoch: mem (CPU python)=47986.91796875MB; mem (CPU total)=47965.65625MB
INFO:root:[   77] Training loss: 0.62181592, Validation loss: 0.61190265, Gradient norm: 0.05012402
INFO:root:At the start of the epoch: mem (CPU python)=48037.51953125MB; mem (CPU total)=48016.23046875MB
INFO:root:[   78] Training loss: 0.62167785, Validation loss: 0.61281524, Gradient norm: 0.05984581
INFO:root:At the start of the epoch: mem (CPU python)=48100.640625MB; mem (CPU total)=48078.62109375MB
INFO:root:[   79] Training loss: 0.62130682, Validation loss: 0.61157532, Gradient norm: 0.05230773
INFO:root:At the start of the epoch: mem (CPU python)=48138.734375MB; mem (CPU total)=48116.65234375MB
INFO:root:[   80] Training loss: 0.62125095, Validation loss: 0.61104064, Gradient norm: 0.04968689
INFO:root:At the start of the epoch: mem (CPU python)=48176.828125MB; mem (CPU total)=48154.7578125MB
INFO:root:[   81] Training loss: 0.62104474, Validation loss: 0.61122354, Gradient norm: 0.05400084
INFO:root:At the start of the epoch: mem (CPU python)=48177.3984375MB; mem (CPU total)=48155.48828125MB
INFO:root:[   82] Training loss: 0.62069797, Validation loss: 0.61153984, Gradient norm: 0.04832493
INFO:root:At the start of the epoch: mem (CPU python)=48215.4921875MB; mem (CPU total)=48193.6015625MB
INFO:root:[   83] Training loss: 0.62069678, Validation loss: 0.61063918, Gradient norm: 0.05589900
INFO:root:At the start of the epoch: mem (CPU python)=48266.0859375MB; mem (CPU total)=48244.69921875MB
INFO:root:[   84] Training loss: 0.62024834, Validation loss: 0.61118171, Gradient norm: 0.05017202
INFO:root:At the start of the epoch: mem (CPU python)=48291.68359375MB; mem (CPU total)=48269.890625MB
INFO:root:[   85] Training loss: 0.62027167, Validation loss: 0.60999761, Gradient norm: 0.05028164
INFO:root:At the start of the epoch: mem (CPU python)=48329.78125MB; mem (CPU total)=48308.20703125MB
INFO:root:[   86] Training loss: 0.61975261, Validation loss: 0.60966585, Gradient norm: 0.05133944
INFO:root:At the start of the epoch: mem (CPU python)=48367.87109375MB; mem (CPU total)=48346.83984375MB
INFO:root:[   87] Training loss: 0.61988631, Validation loss: 0.60997021, Gradient norm: 0.05191628
INFO:root:At the start of the epoch: mem (CPU python)=48430.96875MB; mem (CPU total)=48409.65234375MB
INFO:root:[   88] Training loss: 0.61925219, Validation loss: 0.61037544, Gradient norm: 0.05048634
INFO:root:At the start of the epoch: mem (CPU python)=48469.06640625MB; mem (CPU total)=48448.04296875MB
INFO:root:[   89] Training loss: 0.61938470, Validation loss: 0.61049635, Gradient norm: 0.06050618
INFO:root:At the start of the epoch: mem (CPU python)=48494.66015625MB; mem (CPU total)=48473.30859375MB
INFO:root:[   90] Training loss: 0.61905574, Validation loss: 0.60870911, Gradient norm: 0.05236977
INFO:root:At the start of the epoch: mem (CPU python)=48532.75390625MB; mem (CPU total)=48511.69921875MB
INFO:root:[   91] Training loss: 0.61901667, Validation loss: 0.60956868, Gradient norm: 0.05884205
INFO:root:At the start of the epoch: mem (CPU python)=48583.3515625MB; mem (CPU total)=48562.8359375MB
INFO:root:[   92] Training loss: 0.61860907, Validation loss: 0.61131368, Gradient norm: 0.05137004
INFO:root:At the start of the epoch: mem (CPU python)=48596.4453125MB; mem (CPU total)=48575.66796875MB
INFO:root:[   93] Training loss: 0.61845275, Validation loss: 0.60867014, Gradient norm: 0.05863628
INFO:root:At the start of the epoch: mem (CPU python)=48647.04296875MB; mem (CPU total)=48626.3359375MB
INFO:root:[   94] Training loss: 0.61854119, Validation loss: 0.60867379, Gradient norm: 0.05362116
INFO:root:At the start of the epoch: mem (CPU python)=48685.140625MB; mem (CPU total)=48664.7578125MB
INFO:root:[   95] Training loss: 0.61808596, Validation loss: 0.60929442, Gradient norm: 0.05183929
INFO:root:At the start of the epoch: mem (CPU python)=48748.26171875MB; mem (CPU total)=48728.0625MB
INFO:root:[   96] Training loss: 0.61827357, Validation loss: 0.60968046, Gradient norm: 0.05960715
INFO:root:At the start of the epoch: mem (CPU python)=48798.828125MB; mem (CPU total)=48778.734375MB
INFO:root:[   97] Training loss: 0.61803021, Validation loss: 0.60893269, Gradient norm: 0.05509207
INFO:root:At the start of the epoch: mem (CPU python)=48824.44921875MB; mem (CPU total)=48804.171875MB
INFO:root:[   98] Training loss: 0.61772707, Validation loss: 0.60851919, Gradient norm: 0.05539914
INFO:root:At the start of the epoch: mem (CPU python)=48862.546875MB; mem (CPU total)=48842.0078125MB
INFO:root:[   99] Training loss: 0.61751443, Validation loss: 0.60900698, Gradient norm: 0.05451408
INFO:root:At the start of the epoch: mem (CPU python)=48875.61328125MB; mem (CPU total)=48854.69921875MB
INFO:root:[  100] Training loss: 0.61725450, Validation loss: 0.60824259, Gradient norm: 0.04910147
INFO:root:At the start of the epoch: mem (CPU python)=48926.20703125MB; mem (CPU total)=48905.58203125MB
INFO:root:[  101] Training loss: 0.61692065, Validation loss: 0.60811464, Gradient norm: 0.05105505
INFO:root:At the start of the epoch: mem (CPU python)=48939.3046875MB; mem (CPU total)=48918.8046875MB
INFO:root:[  102] Training loss: 0.61686840, Validation loss: 0.60744026, Gradient norm: 0.05514056
INFO:root:At the start of the epoch: mem (CPU python)=48989.90234375MB; mem (CPU total)=48969.6484375MB
INFO:root:[  103] Training loss: 0.61703156, Validation loss: 0.60733884, Gradient norm: 0.05285604
INFO:root:At the start of the epoch: mem (CPU python)=49040.98046875MB; mem (CPU total)=49022.19921875MB
INFO:root:[  104] Training loss: 0.61665463, Validation loss: 0.60873186, Gradient norm: 0.05581072
INFO:root:At the start of the epoch: mem (CPU python)=49041.1171875MB; mem (CPU total)=49023.23046875MB
INFO:root:[  105] Training loss: 0.61634437, Validation loss: 0.60777046, Gradient norm: 0.05778208
INFO:root:At the start of the epoch: mem (CPU python)=49104.1875MB; mem (CPU total)=49086.35546875MB
INFO:root:[  106] Training loss: 0.61650506, Validation loss: 0.60988235, Gradient norm: 0.05546932
INFO:root:At the start of the epoch: mem (CPU python)=49142.28125MB; mem (CPU total)=49124.47265625MB
INFO:root:[  107] Training loss: 0.61623706, Validation loss: 0.60703344, Gradient norm: 0.05592740
INFO:root:At the start of the epoch: mem (CPU python)=49155.40234375MB; mem (CPU total)=49136.68359375MB
INFO:root:[  108] Training loss: 0.61582576, Validation loss: 0.60763816, Gradient norm: 0.05342370
INFO:root:At the start of the epoch: mem (CPU python)=49193.5MB; mem (CPU total)=49175.2890625MB
INFO:root:[  109] Training loss: 0.61594494, Validation loss: 0.60677988, Gradient norm: 0.06239667
INFO:root:At the start of the epoch: mem (CPU python)=49244.06640625MB; mem (CPU total)=49225.84765625MB
INFO:root:[  110] Training loss: 0.61590811, Validation loss: 0.60844054, Gradient norm: 0.05632481
INFO:root:At the start of the epoch: mem (CPU python)=49294.6640625MB; mem (CPU total)=49276.42578125MB
INFO:root:[  111] Training loss: 0.61557277, Validation loss: 0.60771830, Gradient norm: 0.05948008
INFO:root:At the start of the epoch: mem (CPU python)=49332.76171875MB; mem (CPU total)=49314.6328125MB
INFO:root:[  112] Training loss: 0.61547643, Validation loss: 0.60666806, Gradient norm: 0.05345424
INFO:root:At the start of the epoch: mem (CPU python)=49358.35546875MB; mem (CPU total)=49340.06640625MB
INFO:root:[  113] Training loss: 0.61550411, Validation loss: 0.60733703, Gradient norm: 0.05738578
INFO:root:At the start of the epoch: mem (CPU python)=49421.44921875MB; mem (CPU total)=49403.4140625MB
INFO:root:[  114] Training loss: 0.61531629, Validation loss: 0.60655143, Gradient norm: 0.05852658
INFO:root:At the start of the epoch: mem (CPU python)=49447.04296875MB; mem (CPU total)=49428.8828125MB
INFO:root:[  115] Training loss: 0.61457255, Validation loss: 0.60680030, Gradient norm: 0.05243792
INFO:root:At the start of the epoch: mem (CPU python)=49495.30859375MB; mem (CPU total)=49454.81640625MB
INFO:root:[  116] Training loss: 0.61498204, Validation loss: 0.60728238, Gradient norm: 0.05431079
INFO:root:At the start of the epoch: mem (CPU python)=49510.734375MB; mem (CPU total)=49493.50390625MB
INFO:root:[  117] Training loss: 0.61463935, Validation loss: 0.60660076, Gradient norm: 0.05756874
INFO:root:At the start of the epoch: mem (CPU python)=49548.828125MB; mem (CPU total)=49530.984375MB
INFO:root:[  118] Training loss: 0.61452374, Validation loss: 0.60545855, Gradient norm: 0.05448090
INFO:root:At the start of the epoch: mem (CPU python)=49586.92578125MB; mem (CPU total)=49569.42578125MB
INFO:root:[  119] Training loss: 0.61458974, Validation loss: 0.60604579, Gradient norm: 0.05606165
INFO:root:At the start of the epoch: mem (CPU python)=49625.0234375MB; mem (CPU total)=49607.60546875MB
INFO:root:[  120] Training loss: 0.61428075, Validation loss: 0.60540954, Gradient norm: 0.05713678
INFO:root:At the start of the epoch: mem (CPU python)=49663.1171875MB; mem (CPU total)=49645.7890625MB
INFO:root:[  121] Training loss: 0.61428565, Validation loss: 0.60569229, Gradient norm: 0.05333239
INFO:root:At the start of the epoch: mem (CPU python)=49701.2109375MB; mem (CPU total)=49684.18359375MB
INFO:root:[  122] Training loss: 0.61404637, Validation loss: 0.60506565, Gradient norm: 0.05695998
INFO:root:At the start of the epoch: mem (CPU python)=49751.80859375MB; mem (CPU total)=49734.3671875MB
INFO:root:[  123] Training loss: 0.61400862, Validation loss: 0.60567795, Gradient norm: 0.05940968
INFO:root:At the start of the epoch: mem (CPU python)=49777.40234375MB; mem (CPU total)=49759.83203125MB
INFO:root:[  124] Training loss: 0.61367500, Validation loss: 0.60627648, Gradient norm: 0.05456030
INFO:root:At the start of the epoch: mem (CPU python)=49815.49609375MB; mem (CPU total)=49797.5234375MB
INFO:root:[  125] Training loss: 0.61352049, Validation loss: 0.60391266, Gradient norm: 0.05895411
INFO:root:At the start of the epoch: mem (CPU python)=49853.59375MB; mem (CPU total)=49835.78515625MB
INFO:root:[  126] Training loss: 0.61358093, Validation loss: 0.60611573, Gradient norm: 0.05832563
INFO:root:At the start of the epoch: mem (CPU python)=49891.6875MB; mem (CPU total)=49873.9609375MB
INFO:root:[  127] Training loss: 0.61355045, Validation loss: 0.60585789, Gradient norm: 0.06817886
INFO:root:At the start of the epoch: mem (CPU python)=49942.28125MB; mem (CPU total)=49924.6015625MB
INFO:root:[  128] Training loss: 0.61313220, Validation loss: 0.60502116, Gradient norm: 0.05692394
INFO:root:At the start of the epoch: mem (CPU python)=49992.8828125MB; mem (CPU total)=49975.21484375MB
INFO:root:[  129] Training loss: 0.61320416, Validation loss: 0.60550256, Gradient norm: 0.05438767
INFO:root:At the start of the epoch: mem (CPU python)=50018.4765625MB; mem (CPU total)=50001.4453125MB
INFO:root:[  130] Training loss: 0.61295071, Validation loss: 0.60475982, Gradient norm: 0.05449110
INFO:root:At the start of the epoch: mem (CPU python)=50056.5703125MB; mem (CPU total)=50039.37890625MB
INFO:root:[  131] Training loss: 0.61310714, Validation loss: 0.60518284, Gradient norm: 0.05961544
INFO:root:At the start of the epoch: mem (CPU python)=50082.1640625MB; mem (CPU total)=50064.85546875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  132] Training loss: 0.61285485, Validation loss: 0.60453228, Gradient norm: 0.06016583
INFO:root:At the start of the epoch: mem (CPU python)=50132.76171875MB; mem (CPU total)=50115.7578125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  133] Training loss: 0.61184584, Validation loss: 0.60436444, Gradient norm: 0.05091942
INFO:root:At the start of the epoch: mem (CPU python)=50182.546875MB; mem (CPU total)=50093.6875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  134] Training loss: 0.61129511, Validation loss: 0.60378690, Gradient norm: 0.04667776
INFO:root:At the start of the epoch: mem (CPU python)=50208.94921875MB; mem (CPU total)=50155.24609375MB
INFO:root:[  135] Training loss: 0.61074801, Validation loss: 0.60367589, Gradient norm: 0.04747460
INFO:root:At the start of the epoch: mem (CPU python)=50245.484375MB; mem (CPU total)=50173.97265625MB
INFO:root:[  136] Training loss: 0.61108459, Validation loss: 0.60385028, Gradient norm: 0.04698282
INFO:root:At the start of the epoch: mem (CPU python)=50310.14453125MB; mem (CPU total)=50261.921875MB
INFO:root:[  137] Training loss: 0.61089779, Validation loss: 0.60389947, Gradient norm: 0.04743842
INFO:root:At the start of the epoch: mem (CPU python)=50310.73828125MB; mem (CPU total)=50262.40234375MB
INFO:root:[  138] Training loss: 0.61088232, Validation loss: 0.60338920, Gradient norm: 0.04682517
INFO:root:At the start of the epoch: mem (CPU python)=50348.83203125MB; mem (CPU total)=50300.546875MB
INFO:root:[  139] Training loss: 0.61060431, Validation loss: 0.60340921, Gradient norm: 0.04952336
INFO:root:At the start of the epoch: mem (CPU python)=50386.9296875MB; mem (CPU total)=50338.91796875MB
INFO:root:[  140] Training loss: 0.61062436, Validation loss: 0.60430469, Gradient norm: 0.04645184
INFO:root:At the start of the epoch: mem (CPU python)=50425.0234375MB; mem (CPU total)=50377.11328125MB
INFO:root:[  141] Training loss: 0.61076992, Validation loss: 0.60395674, Gradient norm: 0.04775181
INFO:root:At the start of the epoch: mem (CPU python)=50463.1171875MB; mem (CPU total)=50415.796875MB
INFO:root:[  142] Training loss: 0.61044750, Validation loss: 0.60302827, Gradient norm: 0.04749231
INFO:root:At the start of the epoch: mem (CPU python)=50501.21484375MB; mem (CPU total)=50455.52734375MB
INFO:root:[  143] Training loss: 0.61045347, Validation loss: 0.60350345, Gradient norm: 0.04606713
INFO:root:At the start of the epoch: mem (CPU python)=50551.80859375MB; mem (CPU total)=50506.21875MB
INFO:root:[  144] Training loss: 0.61055547, Validation loss: 0.60377817, Gradient norm: 0.04922586
INFO:root:At the start of the epoch: mem (CPU python)=50589.90234375MB; mem (CPU total)=50544.625MB
INFO:root:[  145] Training loss: 0.61086528, Validation loss: 0.60330659, Gradient norm: 0.04978930
INFO:root:At the start of the epoch: mem (CPU python)=50620.38671875MB; mem (CPU total)=50569.953125MB
INFO:root:[  146] Training loss: 0.61054292, Validation loss: 0.60327122, Gradient norm: 0.04733061
INFO:root:At the start of the epoch: mem (CPU python)=50666.1015625MB; mem (CPU total)=50620.75390625MB
INFO:root:[  147] Training loss: 0.61027428, Validation loss: 0.60280970, Gradient norm: 0.04562698
INFO:root:At the start of the epoch: mem (CPU python)=50704.19140625MB; mem (CPU total)=50659.203125MB
INFO:root:[  148] Training loss: 0.61042005, Validation loss: 0.60399506, Gradient norm: 0.04668759
INFO:root:At the start of the epoch: mem (CPU python)=50742.28515625MB; mem (CPU total)=50697.31640625MB
INFO:root:[  149] Training loss: 0.61062544, Validation loss: 0.60326026, Gradient norm: 0.04826326
INFO:root:At the start of the epoch: mem (CPU python)=50792.88671875MB; mem (CPU total)=50747.82421875MB
INFO:root:[  150] Training loss: 0.61052922, Validation loss: 0.60276107, Gradient norm: 0.04911774
INFO:root:At the start of the epoch: mem (CPU python)=50830.98046875MB; mem (CPU total)=50786.5625MB
INFO:root:[  151] Training loss: 0.61037369, Validation loss: 0.60400840, Gradient norm: 0.04729385
INFO:root:At the start of the epoch: mem (CPU python)=50867.08203125MB; mem (CPU total)=50787.3046875MB
INFO:root:[  152] Training loss: 0.61065424, Validation loss: 0.60301937, Gradient norm: 0.04660768
INFO:root:At the start of the epoch: mem (CPU python)=50894.671875MB; mem (CPU total)=50844.234375MB
INFO:root:[  153] Training loss: 0.61054452, Validation loss: 0.60321712, Gradient norm: 0.04641850
INFO:root:At the start of the epoch: mem (CPU python)=50932.765625MB; mem (CPU total)=50882.50390625MB
INFO:root:[  154] Training loss: 0.61031357, Validation loss: 0.60303141, Gradient norm: 0.04680419
INFO:root:At the start of the epoch: mem (CPU python)=50970.859375MB; mem (CPU total)=50923.59375MB
INFO:root:[  155] Training loss: 0.61047976, Validation loss: 0.60280179, Gradient norm: 0.04687394
INFO:root:At the start of the epoch: mem (CPU python)=51008.953125MB; mem (CPU total)=50961.71875MB
INFO:root:[  156] Training loss: 0.61031445, Validation loss: 0.60291465, Gradient norm: 0.04772858
INFO:root:At the start of the epoch: mem (CPU python)=51034.55078125MB; mem (CPU total)=50987.12890625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  157] Training loss: 0.61013921, Validation loss: 0.60296964, Gradient norm: 0.04731576
INFO:root:At the start of the epoch: mem (CPU python)=51085.14453125MB; mem (CPU total)=51037.859375MB
INFO:root:[  158] Training loss: 0.61000293, Validation loss: 0.60348457, Gradient norm: 0.04586079
INFO:root:At the start of the epoch: mem (CPU python)=51135.73828125MB; mem (CPU total)=51088.55078125MB
INFO:root:[  159] Training loss: 0.61013003, Validation loss: 0.60321374, Gradient norm: 0.04602049
INFO:root:At the start of the epoch: mem (CPU python)=51148.83984375MB; mem (CPU total)=51102.1484375MB
INFO:root:EP 159: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=51199.35546875MB; mem (CPU total)=51152.7265625MB
INFO:root:Training the model took 15002.172s.
INFO:root:Emptying the cuda cache took 0.031s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83821
INFO:root:EnergyScoreTrain: 0.59014
INFO:root:CRPSTrain: 0.4531
INFO:root:Gaussian NLLTrain: 1.15211
INFO:root:CoverageTrain: 0.95404
INFO:root:IntervalWidthTrain: 3.22395
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.85681
INFO:root:EnergyScoreValidation: 0.6031
INFO:root:CRPSValidation: 0.46411
INFO:root:Gaussian NLLValidation: 1.17771
INFO:root:CoverageValidation: 0.94793
INFO:root:IntervalWidthValidation: 3.22533
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.85849
INFO:root:EnergyScoreTest: 0.60427
INFO:root:CRPSTest: 0.46534
INFO:root:Gaussian NLLTest: 1.18132
INFO:root:CoverageTest: 0.94777
INFO:root:IntervalWidthTest: 3.23094
INFO:root:After validation: mem (CPU python)=51293.11328125MB; mem (CPU total)=51220.42578125MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=51293.11328125MB; mem (CPU total)=51134.71484375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=51293.11328125MB; mem (CPU total)=51134.71484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=51293.11328125MB; mem (CPU total)=51134.7734375MB
INFO:root:[    1] Training loss: 0.72686049, Validation loss: 0.72059068, Gradient norm: 0.03114637
INFO:root:At the start of the epoch: mem (CPU python)=51293.39453125MB; mem (CPU total)=51247.3125MB
INFO:root:[    2] Training loss: 0.71979511, Validation loss: 0.71910217, Gradient norm: 0.00592855
INFO:root:At the start of the epoch: mem (CPU python)=51331.484375MB; mem (CPU total)=51285.48046875MB
INFO:root:[    3] Training loss: 0.71723592, Validation loss: 0.71272164, Gradient norm: 0.00917944
INFO:root:At the start of the epoch: mem (CPU python)=51382.08203125MB; mem (CPU total)=51336.36328125MB
INFO:root:[    4] Training loss: 0.71078068, Validation loss: 0.70369960, Gradient norm: 0.01826748
INFO:root:At the start of the epoch: mem (CPU python)=51419.62890625MB; mem (CPU total)=51337.30859375MB
INFO:root:[    5] Training loss: 0.70421202, Validation loss: 0.69741040, Gradient norm: 0.02640898
INFO:root:At the start of the epoch: mem (CPU python)=51445.76953125MB; mem (CPU total)=51400.2265625MB
INFO:root:[    6] Training loss: 0.69809245, Validation loss: 0.69106066, Gradient norm: 0.02657068
INFO:root:At the start of the epoch: mem (CPU python)=51496.37109375MB; mem (CPU total)=51451.6484375MB
INFO:root:[    7] Training loss: 0.69249721, Validation loss: 0.68455939, Gradient norm: 0.02589115
INFO:root:At the start of the epoch: mem (CPU python)=51534.46484375MB; mem (CPU total)=51489.80859375MB
INFO:root:[    8] Training loss: 0.68665978, Validation loss: 0.67803847, Gradient norm: 0.02554089
INFO:root:At the start of the epoch: mem (CPU python)=51585.05859375MB; mem (CPU total)=51541.234375MB
INFO:root:[    9] Training loss: 0.68141410, Validation loss: 0.67230084, Gradient norm: 0.02754258
INFO:root:At the start of the epoch: mem (CPU python)=51623.15234375MB; mem (CPU total)=51579.33984375MB
INFO:root:[   10] Training loss: 0.67724565, Validation loss: 0.66819212, Gradient norm: 0.02679434
INFO:root:At the start of the epoch: mem (CPU python)=51654.17578125MB; mem (CPU total)=51606.328125MB
INFO:root:[   11] Training loss: 0.67339124, Validation loss: 0.66290558, Gradient norm: 0.02655378
INFO:root:At the start of the epoch: mem (CPU python)=51686.84375MB; mem (CPU total)=51644.37890625MB
INFO:root:[   12] Training loss: 0.67015157, Validation loss: 0.66020803, Gradient norm: 0.02815468
INFO:root:At the start of the epoch: mem (CPU python)=51724.9375MB; mem (CPU total)=51682.73828125MB
INFO:root:[   13] Training loss: 0.66756763, Validation loss: 0.65729324, Gradient norm: 0.02823046
INFO:root:At the start of the epoch: mem (CPU python)=51755.421875MB; mem (CPU total)=51696.05859375MB
INFO:root:[   14] Training loss: 0.66510478, Validation loss: 0.65444188, Gradient norm: 0.02737424
INFO:root:At the start of the epoch: mem (CPU python)=51801.12890625MB; mem (CPU total)=51759.3046875MB
INFO:root:[   15] Training loss: 0.66306030, Validation loss: 0.65231014, Gradient norm: 0.02986728
INFO:root:At the start of the epoch: mem (CPU python)=51851.7265625MB; mem (CPU total)=51810.0MB
INFO:root:[   16] Training loss: 0.66104469, Validation loss: 0.65065431, Gradient norm: 0.02900570
INFO:root:At the start of the epoch: mem (CPU python)=51877.3203125MB; mem (CPU total)=51835.54296875MB
INFO:root:[   17] Training loss: 0.65920996, Validation loss: 0.64902130, Gradient norm: 0.02967799
INFO:root:At the start of the epoch: mem (CPU python)=51927.91796875MB; mem (CPU total)=51886.67578125MB
INFO:root:[   18] Training loss: 0.65767282, Validation loss: 0.64675475, Gradient norm: 0.03357011
INFO:root:At the start of the epoch: mem (CPU python)=51966.01171875MB; mem (CPU total)=51924.828125MB
INFO:root:[   19] Training loss: 0.65626120, Validation loss: 0.64558004, Gradient norm: 0.03524787
INFO:root:At the start of the epoch: mem (CPU python)=52004.10546875MB; mem (CPU total)=51962.7578125MB
INFO:root:[   20] Training loss: 0.65503045, Validation loss: 0.64509324, Gradient norm: 0.04062587
INFO:root:At the start of the epoch: mem (CPU python)=52042.203125MB; mem (CPU total)=52001.1171875MB
INFO:root:[   21] Training loss: 0.65369032, Validation loss: 0.64261373, Gradient norm: 0.03497488
INFO:root:At the start of the epoch: mem (CPU python)=52067.796875MB; mem (CPU total)=52026.89453125MB
INFO:root:[   22] Training loss: 0.65214990, Validation loss: 0.64122173, Gradient norm: 0.03777845
INFO:root:At the start of the epoch: mem (CPU python)=52098.6953125MB; mem (CPU total)=52052.734375MB
INFO:root:[   23] Training loss: 0.65097549, Validation loss: 0.64101806, Gradient norm: 0.03483306
INFO:root:At the start of the epoch: mem (CPU python)=52131.48828125MB; mem (CPU total)=52090.91796875MB
INFO:root:[   24] Training loss: 0.64990504, Validation loss: 0.64022217, Gradient norm: 0.03500820
INFO:root:At the start of the epoch: mem (CPU python)=52169.5859375MB; mem (CPU total)=52129.203125MB
INFO:root:[   25] Training loss: 0.64902246, Validation loss: 0.63817232, Gradient norm: 0.03795243
INFO:root:At the start of the epoch: mem (CPU python)=52195.1796875MB; mem (CPU total)=52154.54296875MB
INFO:root:[   26] Training loss: 0.64780597, Validation loss: 0.63763872, Gradient norm: 0.04117729
INFO:root:At the start of the epoch: mem (CPU python)=52258.2734375MB; mem (CPU total)=52217.54296875MB
INFO:root:[   27] Training loss: 0.64688337, Validation loss: 0.63656728, Gradient norm: 0.03982156
INFO:root:At the start of the epoch: mem (CPU python)=52321.37109375MB; mem (CPU total)=52280.78125MB
INFO:root:[   28] Training loss: 0.64575805, Validation loss: 0.63573090, Gradient norm: 0.04098035
INFO:root:At the start of the epoch: mem (CPU python)=52321.73046875MB; mem (CPU total)=52243.8671875MB
INFO:root:[   29] Training loss: 0.64498341, Validation loss: 0.63458727, Gradient norm: 0.04927800
INFO:root:At the start of the epoch: mem (CPU python)=52357.35546875MB; mem (CPU total)=52308.78125MB
INFO:root:[   30] Training loss: 0.64418323, Validation loss: 0.63372318, Gradient norm: 0.04252251
INFO:root:At the start of the epoch: mem (CPU python)=52423.15625MB; mem (CPU total)=52384.31640625MB
INFO:root:[   31] Training loss: 0.64321548, Validation loss: 0.63295776, Gradient norm: 0.04013098
INFO:root:At the start of the epoch: mem (CPU python)=52461.25390625MB; mem (CPU total)=52422.4296875MB
INFO:root:[   32] Training loss: 0.64266107, Validation loss: 0.63219609, Gradient norm: 0.04626861
INFO:root:At the start of the epoch: mem (CPU python)=52499.34765625MB; mem (CPU total)=52460.328125MB
INFO:root:[   33] Training loss: 0.64186469, Validation loss: 0.63038909, Gradient norm: 0.04493051
INFO:root:At the start of the epoch: mem (CPU python)=52537.4453125MB; mem (CPU total)=52498.7265625MB
INFO:root:[   34] Training loss: 0.64102413, Validation loss: 0.63001913, Gradient norm: 0.04271549
INFO:root:At the start of the epoch: mem (CPU python)=52575.54296875MB; mem (CPU total)=52536.8671875MB
INFO:root:[   35] Training loss: 0.64021134, Validation loss: 0.62974657, Gradient norm: 0.04306154
INFO:root:At the start of the epoch: mem (CPU python)=52588.63671875MB; mem (CPU total)=52549.73046875MB
INFO:root:[   36] Training loss: 0.63945794, Validation loss: 0.62907253, Gradient norm: 0.04250801
INFO:root:At the start of the epoch: mem (CPU python)=52639.23046875MB; mem (CPU total)=52600.55078125MB
INFO:root:[   37] Training loss: 0.63887738, Validation loss: 0.62819921, Gradient norm: 0.04780797
INFO:root:At the start of the epoch: mem (CPU python)=52664.828125MB; mem (CPU total)=52625.76953125MB
INFO:root:[   38] Training loss: 0.63821108, Validation loss: 0.62815217, Gradient norm: 0.04052912
INFO:root:At the start of the epoch: mem (CPU python)=52715.421875MB; mem (CPU total)=52676.46484375MB
INFO:root:[   39] Training loss: 0.63771194, Validation loss: 0.62730234, Gradient norm: 0.04902335
INFO:root:At the start of the epoch: mem (CPU python)=52766.015625MB; mem (CPU total)=52727.375MB
INFO:root:[   40] Training loss: 0.63713303, Validation loss: 0.62751485, Gradient norm: 0.04776041
INFO:root:At the start of the epoch: mem (CPU python)=52804.1171875MB; mem (CPU total)=52765.51953125MB
INFO:root:[   41] Training loss: 0.63650355, Validation loss: 0.62631215, Gradient norm: 0.04711354
INFO:root:At the start of the epoch: mem (CPU python)=52817.2109375MB; mem (CPU total)=52778.85546875MB
INFO:root:[   42] Training loss: 0.63613214, Validation loss: 0.62729572, Gradient norm: 0.04331349
INFO:root:At the start of the epoch: mem (CPU python)=52880.3046875MB; mem (CPU total)=52844.015625MB
INFO:root:[   43] Training loss: 0.63549695, Validation loss: 0.62569267, Gradient norm: 0.05102288
INFO:root:At the start of the epoch: mem (CPU python)=52918.40234375MB; mem (CPU total)=52881.9140625MB
INFO:root:[   44] Training loss: 0.63491854, Validation loss: 0.62468880, Gradient norm: 0.04727139
INFO:root:At the start of the epoch: mem (CPU python)=52943.8984375MB; mem (CPU total)=52845.73046875MB
INFO:root:[   45] Training loss: 0.63448660, Validation loss: 0.62460505, Gradient norm: 0.04973838
INFO:root:At the start of the epoch: mem (CPU python)=52969.59375MB; mem (CPU total)=52933.35546875MB
INFO:root:[   46] Training loss: 0.63401944, Validation loss: 0.62518790, Gradient norm: 0.04632249
INFO:root:At the start of the epoch: mem (CPU python)=53007.6875MB; mem (CPU total)=52972.23046875MB
INFO:root:[   47] Training loss: 0.63352595, Validation loss: 0.62429496, Gradient norm: 0.05203775
INFO:root:At the start of the epoch: mem (CPU python)=53058.28515625MB; mem (CPU total)=53022.75390625MB
INFO:root:[   48] Training loss: 0.63292091, Validation loss: 0.62361087, Gradient norm: 0.04874981
INFO:root:At the start of the epoch: mem (CPU python)=53071.37890625MB; mem (CPU total)=53035.765625MB
INFO:root:[   49] Training loss: 0.63247407, Validation loss: 0.62276563, Gradient norm: 0.04610980
INFO:root:At the start of the epoch: mem (CPU python)=53134.4765625MB; mem (CPU total)=53099.01171875MB
INFO:root:[   50] Training loss: 0.63221499, Validation loss: 0.62230018, Gradient norm: 0.05036844
INFO:root:At the start of the epoch: mem (CPU python)=53185.06640625MB; mem (CPU total)=53149.76953125MB
INFO:root:[   51] Training loss: 0.63175604, Validation loss: 0.62259115, Gradient norm: 0.04506517
INFO:root:At the start of the epoch: mem (CPU python)=53210.66796875MB; mem (CPU total)=53175.36328125MB
INFO:root:[   52] Training loss: 0.63137884, Validation loss: 0.62372444, Gradient norm: 0.05524908
INFO:root:At the start of the epoch: mem (CPU python)=53248.76171875MB; mem (CPU total)=53213.23046875MB
INFO:root:[   53] Training loss: 0.63085423, Validation loss: 0.62161406, Gradient norm: 0.05369986
INFO:root:At the start of the epoch: mem (CPU python)=53286.85546875MB; mem (CPU total)=53251.390625MB
INFO:root:[   54] Training loss: 0.63077154, Validation loss: 0.62019761, Gradient norm: 0.05090511
INFO:root:At the start of the epoch: mem (CPU python)=53324.953125MB; mem (CPU total)=53289.578125MB
INFO:root:[   55] Training loss: 0.63010822, Validation loss: 0.62048721, Gradient norm: 0.05180537
INFO:root:At the start of the epoch: mem (CPU python)=53338.046875MB; mem (CPU total)=53302.60546875MB
INFO:root:[   56] Training loss: 0.62982274, Validation loss: 0.61912693, Gradient norm: 0.05314786
INFO:root:At the start of the epoch: mem (CPU python)=53413.640625MB; mem (CPU total)=53378.3671875MB
INFO:root:[   57] Training loss: 0.62930513, Validation loss: 0.61950677, Gradient norm: 0.04905828
INFO:root:At the start of the epoch: mem (CPU python)=53451.73828125MB; mem (CPU total)=53416.7578125MB
INFO:root:[   58] Training loss: 0.62907307, Validation loss: 0.61904412, Gradient norm: 0.04775571
INFO:root:At the start of the epoch: mem (CPU python)=53489.83203125MB; mem (CPU total)=53455.44921875MB
INFO:root:[   59] Training loss: 0.62861734, Validation loss: 0.61905310, Gradient norm: 0.05605915
INFO:root:At the start of the epoch: mem (CPU python)=53527.92578125MB; mem (CPU total)=53493.84765625MB
INFO:root:[   60] Training loss: 0.62831731, Validation loss: 0.61927609, Gradient norm: 0.05291858
INFO:root:At the start of the epoch: mem (CPU python)=53578.51953125MB; mem (CPU total)=53544.2734375MB
INFO:root:[   61] Training loss: 0.62797586, Validation loss: 0.61800158, Gradient norm: 0.05118439
INFO:root:At the start of the epoch: mem (CPU python)=53616.6171875MB; mem (CPU total)=53582.6328125MB
INFO:root:[   62] Training loss: 0.62754357, Validation loss: 0.61806145, Gradient norm: 0.04566523
INFO:root:At the start of the epoch: mem (CPU python)=53617.34765625MB; mem (CPU total)=53583.125MB
INFO:root:[   63] Training loss: 0.62736234, Validation loss: 0.61728231, Gradient norm: 0.05647588
INFO:root:At the start of the epoch: mem (CPU python)=53630.30859375MB; mem (CPU total)=53596.40625MB
INFO:root:[   64] Training loss: 0.62691813, Validation loss: 0.61780007, Gradient norm: 0.05445513
INFO:root:At the start of the epoch: mem (CPU python)=53680.90625MB; mem (CPU total)=53647.33984375MB
INFO:root:[   65] Training loss: 0.62646749, Validation loss: 0.61775087, Gradient norm: 0.04776811
INFO:root:At the start of the epoch: mem (CPU python)=53756.5MB; mem (CPU total)=53722.7109375MB
INFO:root:[   66] Training loss: 0.62630811, Validation loss: 0.61609732, Gradient norm: 0.05060135
INFO:root:At the start of the epoch: mem (CPU python)=53819.59375MB; mem (CPU total)=53785.98828125MB
INFO:root:[   67] Training loss: 0.62599157, Validation loss: 0.61803238, Gradient norm: 0.05584742
INFO:root:At the start of the epoch: mem (CPU python)=53857.6875MB; mem (CPU total)=53811.640625MB
INFO:root:[   68] Training loss: 0.62577635, Validation loss: 0.61691554, Gradient norm: 0.05093526
INFO:root:At the start of the epoch: mem (CPU python)=53857.9140625MB; mem (CPU total)=53798.77734375MB
INFO:root:[   69] Training loss: 0.62543678, Validation loss: 0.61511946, Gradient norm: 0.04969990
INFO:root:At the start of the epoch: mem (CPU python)=53883.87890625MB; mem (CPU total)=53836.97265625MB
INFO:root:[   70] Training loss: 0.62517209, Validation loss: 0.61533323, Gradient norm: 0.05839650
INFO:root:At the start of the epoch: mem (CPU python)=53921.97265625MB; mem (CPU total)=53875.140625MB
INFO:root:[   71] Training loss: 0.62490822, Validation loss: 0.61533222, Gradient norm: 0.05398707
INFO:root:At the start of the epoch: mem (CPU python)=53985.07421875MB; mem (CPU total)=53941.453125MB
INFO:root:[   72] Training loss: 0.62441449, Validation loss: 0.61623970, Gradient norm: 0.04915910
INFO:root:At the start of the epoch: mem (CPU python)=54023.16796875MB; mem (CPU total)=53979.88671875MB
INFO:root:[   73] Training loss: 0.62418120, Validation loss: 0.61482978, Gradient norm: 0.05055914
INFO:root:At the start of the epoch: mem (CPU python)=54061.26171875MB; mem (CPU total)=54015.10546875MB
INFO:root:[   74] Training loss: 0.62391640, Validation loss: 0.61593968, Gradient norm: 0.05656638
INFO:root:At the start of the epoch: mem (CPU python)=54099.359375MB; mem (CPU total)=54052.76953125MB
INFO:root:[   75] Training loss: 0.62379890, Validation loss: 0.61526014, Gradient norm: 0.05543056
INFO:root:At the start of the epoch: mem (CPU python)=54129.83203125MB; mem (CPU total)=54066.625MB
INFO:root:[   76] Training loss: 0.62328674, Validation loss: 0.61339058, Gradient norm: 0.05277158
INFO:root:At the start of the epoch: mem (CPU python)=54188.046875MB; mem (CPU total)=54142.44921875MB
INFO:root:[   77] Training loss: 0.62335241, Validation loss: 0.61395862, Gradient norm: 0.06043985
INFO:root:At the start of the epoch: mem (CPU python)=54201.140625MB; mem (CPU total)=54154.859375MB
INFO:root:[   78] Training loss: 0.62278408, Validation loss: 0.61374126, Gradient norm: 0.05748450
INFO:root:At the start of the epoch: mem (CPU python)=54226.65625MB; mem (CPU total)=54118.48046875MB
INFO:root:[   79] Training loss: 0.62241850, Validation loss: 0.61556265, Gradient norm: 0.05392739
INFO:root:At the start of the epoch: mem (CPU python)=54289.8359375MB; mem (CPU total)=54243.66015625MB
INFO:root:[   80] Training loss: 0.62236390, Validation loss: 0.61295081, Gradient norm: 0.05707350
INFO:root:At the start of the epoch: mem (CPU python)=54327.9296875MB; mem (CPU total)=54284.74609375MB
INFO:root:[   81] Training loss: 0.62206093, Validation loss: 0.61437234, Gradient norm: 0.05478759
INFO:root:At the start of the epoch: mem (CPU python)=54366.02734375MB; mem (CPU total)=54319.96484375MB
INFO:root:[   82] Training loss: 0.62190434, Validation loss: 0.61436303, Gradient norm: 0.05830380
INFO:root:At the start of the epoch: mem (CPU python)=54404.12109375MB; mem (CPU total)=54358.4453125MB
INFO:root:[   83] Training loss: 0.62187808, Validation loss: 0.61286960, Gradient norm: 0.05586645
INFO:root:At the start of the epoch: mem (CPU python)=54454.71484375MB; mem (CPU total)=54412.2890625MB
INFO:root:[   84] Training loss: 0.62129660, Validation loss: 0.61320271, Gradient norm: 0.05035616
INFO:root:At the start of the epoch: mem (CPU python)=54492.80859375MB; mem (CPU total)=54447.17578125MB
INFO:root:[   85] Training loss: 0.62131066, Validation loss: 0.61208086, Gradient norm: 0.05890565
INFO:root:At the start of the epoch: mem (CPU python)=54518.40625MB; mem (CPU total)=54473.58984375MB
INFO:root:[   86] Training loss: 0.62095230, Validation loss: 0.61113808, Gradient norm: 0.06119369
INFO:root:At the start of the epoch: mem (CPU python)=54556.5MB; mem (CPU total)=54510.96875MB
INFO:root:[   87] Training loss: 0.62064775, Validation loss: 0.61407286, Gradient norm: 0.05729930
INFO:root:At the start of the epoch: mem (CPU python)=54594.59765625MB; mem (CPU total)=54549.140625MB
INFO:root:[   88] Training loss: 0.62048992, Validation loss: 0.61165673, Gradient norm: 0.05246673
INFO:root:At the start of the epoch: mem (CPU python)=54645.1953125MB; mem (CPU total)=54600.93359375MB
INFO:root:[   89] Training loss: 0.62025502, Validation loss: 0.61257383, Gradient norm: 0.05290425
INFO:root:At the start of the epoch: mem (CPU python)=54645.46484375MB; mem (CPU total)=54591.8046875MB
INFO:root:[   90] Training loss: 0.62009504, Validation loss: 0.61479522, Gradient norm: 0.05569175
INFO:root:At the start of the epoch: mem (CPU python)=54696.3828125MB; mem (CPU total)=54655.28125MB
INFO:root:[   91] Training loss: 0.61992588, Validation loss: 0.61072933, Gradient norm: 0.06398034
INFO:root:At the start of the epoch: mem (CPU python)=54734.48046875MB; mem (CPU total)=54693.453125MB
INFO:root:[   92] Training loss: 0.61960421, Validation loss: 0.61071062, Gradient norm: 0.06821235
INFO:root:At the start of the epoch: mem (CPU python)=54747.57421875MB; mem (CPU total)=54706.49609375MB
INFO:root:[   93] Training loss: 0.61978478, Validation loss: 0.61078700, Gradient norm: 0.05881410
INFO:root:At the start of the epoch: mem (CPU python)=54798.16796875MB; mem (CPU total)=54757.18359375MB
INFO:root:[   94] Training loss: 0.61912231, Validation loss: 0.61089912, Gradient norm: 0.05242939
INFO:root:At the start of the epoch: mem (CPU python)=54886.26171875MB; mem (CPU total)=54845.76953125MB
INFO:root:[   95] Training loss: 0.61912106, Validation loss: 0.61100549, Gradient norm: 0.05801088
INFO:root:At the start of the epoch: mem (CPU python)=54924.359375MB; mem (CPU total)=54884.390625MB
INFO:root:[   96] Training loss: 0.61871795, Validation loss: 0.60917909, Gradient norm: 0.05630933
INFO:root:At the start of the epoch: mem (CPU python)=54924.95703125MB; mem (CPU total)=54885.125MB
INFO:root:[   97] Training loss: 0.61855411, Validation loss: 0.61072775, Gradient norm: 0.05556699
INFO:root:At the start of the epoch: mem (CPU python)=54988.05078125MB; mem (CPU total)=54948.2890625MB
INFO:root:[   98] Training loss: 0.61845387, Validation loss: 0.61342647, Gradient norm: 0.05662201
INFO:root:At the start of the epoch: mem (CPU python)=55026.1484375MB; mem (CPU total)=54986.91796875MB
INFO:root:[   99] Training loss: 0.61833134, Validation loss: 0.60965999, Gradient norm: 0.06895969
INFO:root:At the start of the epoch: mem (CPU python)=55064.2421875MB; mem (CPU total)=55025.0625MB
INFO:root:[  100] Training loss: 0.61781779, Validation loss: 0.60919637, Gradient norm: 0.06236304
INFO:root:At the start of the epoch: mem (CPU python)=55102.3359375MB; mem (CPU total)=55063.453125MB
INFO:root:[  101] Training loss: 0.61788111, Validation loss: 0.60882541, Gradient norm: 0.05493180
INFO:root:At the start of the epoch: mem (CPU python)=55127.69921875MB; mem (CPU total)=55028.06640625MB
INFO:root:[  102] Training loss: 0.61761219, Validation loss: 0.61222856, Gradient norm: 0.06853878
INFO:root:At the start of the epoch: mem (CPU python)=55141.02734375MB; mem (CPU total)=55103.125MB
INFO:root:[  103] Training loss: 0.61737077, Validation loss: 0.60845311, Gradient norm: 0.05419398
INFO:root:At the start of the epoch: mem (CPU python)=55204.12109375MB; mem (CPU total)=55166.6484375MB
INFO:root:[  104] Training loss: 0.61698131, Validation loss: 0.60810802, Gradient norm: 0.05921184
INFO:root:At the start of the epoch: mem (CPU python)=55229.71484375MB; mem (CPU total)=55192.55078125MB
INFO:root:[  105] Training loss: 0.61693792, Validation loss: 0.60993328, Gradient norm: 0.06201044
INFO:root:At the start of the epoch: mem (CPU python)=55292.8125MB; mem (CPU total)=55255.796875MB
INFO:root:[  106] Training loss: 0.61678084, Validation loss: 0.61023020, Gradient norm: 0.06073013
INFO:root:At the start of the epoch: mem (CPU python)=55305.91015625MB; mem (CPU total)=55269.0390625MB
INFO:root:[  107] Training loss: 0.61658598, Validation loss: 0.60946608, Gradient norm: 0.05769810
INFO:root:At the start of the epoch: mem (CPU python)=55356.50390625MB; mem (CPU total)=55319.6953125MB
INFO:root:[  108] Training loss: 0.61651889, Validation loss: 0.60943490, Gradient norm: 0.05596996
INFO:root:At the start of the epoch: mem (CPU python)=55419.6015625MB; mem (CPU total)=55385.390625MB
INFO:root:[  109] Training loss: 0.61638304, Validation loss: 0.60786922, Gradient norm: 0.05754348
INFO:root:At the start of the epoch: mem (CPU python)=55450.078125MB; mem (CPU total)=55373.28515625MB
INFO:root:[  110] Training loss: 0.61617597, Validation loss: 0.61093298, Gradient norm: 0.06226411
INFO:root:At the start of the epoch: mem (CPU python)=55470.7890625MB; mem (CPU total)=55436.77734375MB
INFO:root:[  111] Training loss: 0.61592107, Validation loss: 0.60937643, Gradient norm: 0.06224410
INFO:root:At the start of the epoch: mem (CPU python)=55496.3828125MB; mem (CPU total)=55462.44140625MB
INFO:root:[  112] Training loss: 0.61561851, Validation loss: 0.60912559, Gradient norm: 0.06359031
INFO:root:At the start of the epoch: mem (CPU python)=55521.98046875MB; mem (CPU total)=55490.4765625MB
INFO:root:[  113] Training loss: 0.61534960, Validation loss: 0.60913511, Gradient norm: 0.05774259
INFO:root:At the start of the epoch: mem (CPU python)=55585.078125MB; mem (CPU total)=55553.1015625MB
INFO:root:[  114] Training loss: 0.61555691, Validation loss: 0.60861290, Gradient norm: 0.05627553
INFO:root:At the start of the epoch: mem (CPU python)=55623.171875MB; mem (CPU total)=55590.1875MB
INFO:root:[  115] Training loss: 0.61554923, Validation loss: 0.60833711, Gradient norm: 0.06053715
INFO:root:At the start of the epoch: mem (CPU python)=55661.26953125MB; mem (CPU total)=55630.15625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  116] Training loss: 0.61509060, Validation loss: 0.60860411, Gradient norm: 0.05874023
INFO:root:At the start of the epoch: mem (CPU python)=55661.86328125MB; mem (CPU total)=55630.8828125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  117] Training loss: 0.61407075, Validation loss: 0.60727960, Gradient norm: 0.05155509
INFO:root:At the start of the epoch: mem (CPU python)=55736.6875MB; mem (CPU total)=55657.4609375MB
INFO:root:[  118] Training loss: 0.61340658, Validation loss: 0.60696851, Gradient norm: 0.04917979
INFO:root:At the start of the epoch: mem (CPU python)=55763.05078125MB; mem (CPU total)=55732.78125MB
INFO:root:[  119] Training loss: 0.61334588, Validation loss: 0.60752792, Gradient norm: 0.04836706
INFO:root:At the start of the epoch: mem (CPU python)=55801.1484375MB; mem (CPU total)=55770.94921875MB
INFO:root:[  120] Training loss: 0.61330334, Validation loss: 0.60794570, Gradient norm: 0.05211985
INFO:root:At the start of the epoch: mem (CPU python)=55839.24609375MB; mem (CPU total)=55809.33984375MB
INFO:root:[  121] Training loss: 0.61331640, Validation loss: 0.60767834, Gradient norm: 0.05231335
INFO:root:At the start of the epoch: mem (CPU python)=55914.83984375MB; mem (CPU total)=55884.890625MB
INFO:root:[  122] Training loss: 0.61303618, Validation loss: 0.60805585, Gradient norm: 0.05394953
INFO:root:At the start of the epoch: mem (CPU python)=55915.4375MB; mem (CPU total)=55885.62890625MB
INFO:root:[  123] Training loss: 0.61325580, Validation loss: 0.60754732, Gradient norm: 0.04728312
INFO:root:At the start of the epoch: mem (CPU python)=55953.53125MB; mem (CPU total)=55923.7734375MB
INFO:root:[  124] Training loss: 0.61311147, Validation loss: 0.60634553, Gradient norm: 0.05049471
INFO:root:At the start of the epoch: mem (CPU python)=55991.625MB; mem (CPU total)=55948.58203125MB
INFO:root:[  125] Training loss: 0.61286292, Validation loss: 0.60661968, Gradient norm: 0.05059373
INFO:root:At the start of the epoch: mem (CPU python)=56042.22265625MB; mem (CPU total)=56001.5625MB
INFO:root:[  126] Training loss: 0.61283397, Validation loss: 0.60715684, Gradient norm: 0.05070305
INFO:root:At the start of the epoch: mem (CPU python)=56055.31640625MB; mem (CPU total)=56014.17578125MB
INFO:root:[  127] Training loss: 0.61266779, Validation loss: 0.60724779, Gradient norm: 0.05122325
INFO:root:At the start of the epoch: mem (CPU python)=56105.91015625MB; mem (CPU total)=56064.80078125MB
INFO:root:[  128] Training loss: 0.61257645, Validation loss: 0.60534211, Gradient norm: 0.04962258
INFO:root:At the start of the epoch: mem (CPU python)=56181.50390625MB; mem (CPU total)=56139.41015625MB
INFO:root:[  129] Training loss: 0.61272579, Validation loss: 0.60718003, Gradient norm: 0.05401196
INFO:root:At the start of the epoch: mem (CPU python)=56194.6015625MB; mem (CPU total)=56157.23828125MB
INFO:root:[  130] Training loss: 0.61254837, Validation loss: 0.60654361, Gradient norm: 0.05045338
INFO:root:At the start of the epoch: mem (CPU python)=56207.69921875MB; mem (CPU total)=56165.515625MB
INFO:root:[  131] Training loss: 0.61259828, Validation loss: 0.60640260, Gradient norm: 0.05200336
INFO:root:At the start of the epoch: mem (CPU python)=56283.29296875MB; mem (CPU total)=56243.0234375MB
INFO:root:[  132] Training loss: 0.61263142, Validation loss: 0.60749766, Gradient norm: 0.04959628
INFO:root:At the start of the epoch: mem (CPU python)=56321.390625MB; mem (CPU total)=56278.7109375MB
INFO:root:[  133] Training loss: 0.61241224, Validation loss: 0.60689194, Gradient norm: 0.05207692
INFO:root:At the start of the epoch: mem (CPU python)=56322.1171875MB; mem (CPU total)=56280.03515625MB
INFO:root:[  134] Training loss: 0.61248903, Validation loss: 0.60757030, Gradient norm: 0.05448469
INFO:root:At the start of the epoch: mem (CPU python)=56360.078125MB; mem (CPU total)=56317.68359375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  135] Training loss: 0.61251145, Validation loss: 0.60635834, Gradient norm: 0.05572627
INFO:root:At the start of the epoch: mem (CPU python)=56373.171875MB; mem (CPU total)=56331.1171875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  136] Training loss: 0.61227972, Validation loss: 0.60728721, Gradient norm: 0.04823401
INFO:root:At the start of the epoch: mem (CPU python)=56423.76953125MB; mem (CPU total)=56383.65625MB
INFO:root:[  137] Training loss: 0.61216052, Validation loss: 0.60724066, Gradient norm: 0.04591177
INFO:root:At the start of the epoch: mem (CPU python)=56510.33203125MB; mem (CPU total)=56444.53515625MB
INFO:root:EP 137: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=56524.95703125MB; mem (CPU total)=56483.61328125MB
INFO:root:Training the model took 13965.314s.
INFO:root:Emptying the cuda cache took 0.032s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84277
INFO:root:EnergyScoreTrain: 0.59331
INFO:root:CRPSTrain: 0.46055
INFO:root:Gaussian NLLTrain: 1.18874
INFO:root:CoverageTrain: 0.94923
INFO:root:IntervalWidthTrain: 3.25427
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86105
INFO:root:EnergyScoreValidation: 0.60607
INFO:root:CRPSValidation: 0.47146
INFO:root:Gaussian NLLValidation: 1.21372
INFO:root:CoverageValidation: 0.94345
INFO:root:IntervalWidthValidation: 3.25903
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86269
INFO:root:EnergyScoreTest: 0.60723
INFO:root:CRPSTest: 0.47257
INFO:root:Gaussian NLLTest: 1.21594
INFO:root:CoverageTest: 0.94314
INFO:root:IntervalWidthTest: 3.26182
INFO:root:After validation: mem (CPU python)=56599.00390625MB; mem (CPU total)=56559.62109375MB
