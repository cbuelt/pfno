INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=581.2578125MB; mem (CPU total)=971.78125MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12460.72265625MB; mem (CPU total)=982.71484375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=12460.72265625MB; mem (CPU total)=982.8125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12460.72265625MB; mem (CPU total)=2176.7109375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=2186.9453125MB
INFO:root:[    1] Training loss: 0.78267257, Validation loss: 0.72598350, Gradient norm: 0.51867716
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3368.10546875MB
INFO:root:[    2] Training loss: 0.72356128, Validation loss: 0.72152505, Gradient norm: 0.46957764
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3406.68359375MB
INFO:root:[    3] Training loss: 0.72085831, Validation loss: 0.72104941, Gradient norm: 0.34329228
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3444.8046875MB
INFO:root:[    4] Training loss: 0.72023231, Validation loss: 0.72008729, Gradient norm: 0.30607830
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3483.30078125MB
INFO:root:[    5] Training loss: 0.71980910, Validation loss: 0.72004788, Gradient norm: 0.21377462
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3521.75390625MB
INFO:root:[    6] Training loss: 0.71950705, Validation loss: 0.71994954, Gradient norm: 0.21062008
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3560.3125MB
INFO:root:[    7] Training loss: 0.71929971, Validation loss: 0.71965892, Gradient norm: 0.32183471
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3598.25MB
INFO:root:[    8] Training loss: 0.71883353, Validation loss: 0.71876909, Gradient norm: 0.28532160
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3636.1796875MB
INFO:root:[    9] Training loss: 0.71766566, Validation loss: 0.71682707, Gradient norm: 0.20805685
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3674.765625MB
INFO:root:[   10] Training loss: 0.71173757, Validation loss: 0.70651721, Gradient norm: 0.20161162
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3713.125MB
INFO:root:[   11] Training loss: 0.70127023, Validation loss: 0.69590333, Gradient norm: 0.16282083
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3749.32421875MB
INFO:root:[   12] Training loss: 0.69047718, Validation loss: 0.68571523, Gradient norm: 0.17950516
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3788.0MB
INFO:root:[   13] Training loss: 0.68197861, Validation loss: 0.67866659, Gradient norm: 0.15664435
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3825.7421875MB
INFO:root:[   14] Training loss: 0.67511583, Validation loss: 0.67333929, Gradient norm: 0.13746175
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3864.0MB
INFO:root:[   15] Training loss: 0.67005957, Validation loss: 0.66793187, Gradient norm: 0.09943638
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3902.453125MB
INFO:root:[   16] Training loss: 0.66589997, Validation loss: 0.66522438, Gradient norm: 0.08709631
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3940.26953125MB
INFO:root:[   17] Training loss: 0.66257191, Validation loss: 0.66214218, Gradient norm: 0.08218147
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=3978.9296875MB
INFO:root:[   18] Training loss: 0.65985307, Validation loss: 0.65954560, Gradient norm: 0.08813826
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4017.125MB
INFO:root:[   19] Training loss: 0.65749341, Validation loss: 0.65812610, Gradient norm: 0.08587556
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4055.2265625MB
INFO:root:[   20] Training loss: 0.65547668, Validation loss: 0.65638601, Gradient norm: 0.07348737
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4093.61328125MB
INFO:root:[   21] Training loss: 0.65362247, Validation loss: 0.65431094, Gradient norm: 0.08175713
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4131.546875MB
INFO:root:[   22] Training loss: 0.65190967, Validation loss: 0.65396630, Gradient norm: 0.08792776
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4170.02734375MB
INFO:root:[   23] Training loss: 0.65040106, Validation loss: 0.65150465, Gradient norm: 0.09313262
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4208.00390625MB
INFO:root:[   24] Training loss: 0.64884012, Validation loss: 0.65088790, Gradient norm: 0.07006307
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4246.1640625MB
INFO:root:[   25] Training loss: 0.64775090, Validation loss: 0.64955191, Gradient norm: 0.07823388
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4284.4921875MB
INFO:root:[   26] Training loss: 0.64657596, Validation loss: 0.64841378, Gradient norm: 0.06719764
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4322.6640625MB
INFO:root:[   27] Training loss: 0.64528110, Validation loss: 0.64709252, Gradient norm: 0.06526272
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4361.2265625MB
INFO:root:[   28] Training loss: 0.64410681, Validation loss: 0.64588678, Gradient norm: 0.06743645
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4399.28125MB
INFO:root:[   29] Training loss: 0.64312519, Validation loss: 0.64543938, Gradient norm: 0.06828997
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4437.1953125MB
INFO:root:[   30] Training loss: 0.64213285, Validation loss: 0.64382508, Gradient norm: 0.07029238
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4475.99609375MB
INFO:root:[   31] Training loss: 0.64111654, Validation loss: 0.64398255, Gradient norm: 0.06766864
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4514.328125MB
INFO:root:[   32] Training loss: 0.64022029, Validation loss: 0.64254362, Gradient norm: 0.06474622
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4552.78125MB
INFO:root:[   33] Training loss: 0.63929407, Validation loss: 0.64231090, Gradient norm: 0.07248838
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4591.1796875MB
INFO:root:[   34] Training loss: 0.63835721, Validation loss: 0.64114321, Gradient norm: 0.07368900
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4629.3125MB
INFO:root:[   35] Training loss: 0.63738532, Validation loss: 0.64098643, Gradient norm: 0.07141309
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4667.6640625MB
INFO:root:[   36] Training loss: 0.63671527, Validation loss: 0.64036425, Gradient norm: 0.07006857
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4705.8515625MB
INFO:root:[   37] Training loss: 0.63579529, Validation loss: 0.63946251, Gradient norm: 0.07437154
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4743.75MB
INFO:root:[   38] Training loss: 0.63468481, Validation loss: 0.63870682, Gradient norm: 0.07401843
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4782.12890625MB
INFO:root:[   39] Training loss: 0.63410017, Validation loss: 0.63783822, Gradient norm: 0.06749207
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4820.01953125MB
INFO:root:[   40] Training loss: 0.63317297, Validation loss: 0.63724660, Gradient norm: 0.06663148
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4858.15234375MB
INFO:root:[   41] Training loss: 0.63252370, Validation loss: 0.63652452, Gradient norm: 0.07455545
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4896.28515625MB
INFO:root:[   42] Training loss: 0.63171903, Validation loss: 0.63678685, Gradient norm: 0.06843056
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4934.18359375MB
INFO:root:[   43] Training loss: 0.63104155, Validation loss: 0.63532921, Gradient norm: 0.07392563
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=4972.59375MB
INFO:root:[   44] Training loss: 0.63022357, Validation loss: 0.63509271, Gradient norm: 0.06999278
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5010.73828125MB
INFO:root:[   45] Training loss: 0.62956155, Validation loss: 0.63424387, Gradient norm: 0.07299977
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5049.12890625MB
INFO:root:[   46] Training loss: 0.62929093, Validation loss: 0.63482609, Gradient norm: 0.07014462
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5087.20703125MB
INFO:root:[   47] Training loss: 0.62840463, Validation loss: 0.63396829, Gradient norm: 0.07205690
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5125.1328125MB
INFO:root:[   48] Training loss: 0.62769888, Validation loss: 0.63265873, Gradient norm: 0.06470576
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5163.55078125MB
INFO:root:[   49] Training loss: 0.62693163, Validation loss: 0.63328809, Gradient norm: 0.08064071
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5201.6015625MB
INFO:root:[   50] Training loss: 0.62649538, Validation loss: 0.63173253, Gradient norm: 0.07070849
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5239.74609375MB
INFO:root:[   51] Training loss: 0.62562049, Validation loss: 0.63185219, Gradient norm: 0.06697738
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5278.08984375MB
INFO:root:[   52] Training loss: 0.62529050, Validation loss: 0.63137372, Gradient norm: 0.07278011
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5316.24609375MB
INFO:root:[   53] Training loss: 0.62455126, Validation loss: 0.63063846, Gradient norm: 0.06991579
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5354.171875MB
INFO:root:[   54] Training loss: 0.62408621, Validation loss: 0.63021433, Gradient norm: 0.06849573
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5392.5625MB
INFO:root:[   55] Training loss: 0.62344309, Validation loss: 0.62939740, Gradient norm: 0.07347293
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5430.69921875MB
INFO:root:[   56] Training loss: 0.62285053, Validation loss: 0.63004407, Gradient norm: 0.07116799
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5468.8828125MB
INFO:root:[   57] Training loss: 0.62230945, Validation loss: 0.62837166, Gradient norm: 0.07631449
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5507.48046875MB
INFO:root:[   58] Training loss: 0.62191093, Validation loss: 0.62846271, Gradient norm: 0.06594623
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5545.609375MB
INFO:root:[   59] Training loss: 0.62125431, Validation loss: 0.62808983, Gradient norm: 0.07625460
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5583.7734375MB
INFO:root:[   60] Training loss: 0.62066259, Validation loss: 0.62738514, Gradient norm: 0.06883433
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5621.9296875MB
INFO:root:[   61] Training loss: 0.62029588, Validation loss: 0.62794120, Gradient norm: 0.06716120
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5660.1171875MB
INFO:root:[   62] Training loss: 0.61976042, Validation loss: 0.62706488, Gradient norm: 0.07108949
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5698.37890625MB
INFO:root:[   63] Training loss: 0.61925436, Validation loss: 0.62649361, Gradient norm: 0.06963875
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5736.74609375MB
INFO:root:[   64] Training loss: 0.61872239, Validation loss: 0.62622318, Gradient norm: 0.06641635
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5774.4140625MB
INFO:root:[   65] Training loss: 0.61833729, Validation loss: 0.62594413, Gradient norm: 0.07300132
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5812.33984375MB
INFO:root:[   66] Training loss: 0.61804672, Validation loss: 0.62619465, Gradient norm: 0.07899947
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5852.93359375MB
INFO:root:[   67] Training loss: 0.61719520, Validation loss: 0.62516684, Gradient norm: 0.06872397
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5891.2265625MB
INFO:root:[   68] Training loss: 0.61691889, Validation loss: 0.62615397, Gradient norm: 0.06446237
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5928.921875MB
INFO:root:[   69] Training loss: 0.61657785, Validation loss: 0.62434303, Gradient norm: 0.07265134
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=5967.06640625MB
INFO:root:[   70] Training loss: 0.61625845, Validation loss: 0.62502394, Gradient norm: 0.07358255
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6005.45703125MB
INFO:root:[   71] Training loss: 0.61571582, Validation loss: 0.62331111, Gradient norm: 0.07243372
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6043.078125MB
INFO:root:[   72] Training loss: 0.61519422, Validation loss: 0.62421000, Gradient norm: 0.07045809
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6080.97265625MB
INFO:root:[   73] Training loss: 0.61486181, Validation loss: 0.62442371, Gradient norm: 0.06238945
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6119.36328125MB
INFO:root:[   74] Training loss: 0.61444303, Validation loss: 0.62415340, Gradient norm: 0.07181642
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6157.515625MB
INFO:root:[   75] Training loss: 0.61411003, Validation loss: 0.62360407, Gradient norm: 0.07025911
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6195.41015625MB
INFO:root:[   76] Training loss: 0.61374403, Validation loss: 0.62334330, Gradient norm: 0.06739407
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6233.42578125MB
INFO:root:[   77] Training loss: 0.61310051, Validation loss: 0.62306180, Gradient norm: 0.06668876
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6271.5703125MB
INFO:root:[   78] Training loss: 0.61299693, Validation loss: 0.62308976, Gradient norm: 0.08108282
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6309.71484375MB
INFO:root:[   79] Training loss: 0.61258446, Validation loss: 0.62239035, Gradient norm: 0.07231121
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6347.859375MB
INFO:root:[   80] Training loss: 0.61208178, Validation loss: 0.62378947, Gradient norm: 0.07065243
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6386.15625MB
INFO:root:[   81] Training loss: 0.61192867, Validation loss: 0.62292168, Gradient norm: 0.07020603
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6424.29296875MB
INFO:root:[   82] Training loss: 0.61153046, Validation loss: 0.62224876, Gradient norm: 0.07225373
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6462.68359375MB
INFO:root:[   83] Training loss: 0.61109637, Validation loss: 0.62173164, Gradient norm: 0.06747323
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6500.60546875MB
INFO:root:[   84] Training loss: 0.61085978, Validation loss: 0.62273176, Gradient norm: 0.07973562
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6539.01953125MB
INFO:root:[   85] Training loss: 0.61041579, Validation loss: 0.62129008, Gradient norm: 0.07541531
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6577.41015625MB
INFO:root:[   86] Training loss: 0.61008884, Validation loss: 0.62079012, Gradient norm: 0.06882634
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6615.5546875MB
INFO:root:[   87] Training loss: 0.60943428, Validation loss: 0.62142931, Gradient norm: 0.07390878
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6653.41015625MB
INFO:root:[   88] Training loss: 0.60939676, Validation loss: 0.62130038, Gradient norm: 0.08069646
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6691.80078125MB
INFO:root:[   89] Training loss: 0.60916708, Validation loss: 0.62087021, Gradient norm: 0.06885675
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6729.9375MB
INFO:root:[   90] Training loss: 0.60878978, Validation loss: 0.62088210, Gradient norm: 0.07621344
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6768.046875MB
INFO:root:[   91] Training loss: 0.60855131, Validation loss: 0.62096754, Gradient norm: 0.07840495
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6806.3203125MB
INFO:root:[   92] Training loss: 0.60809504, Validation loss: 0.61998465, Gradient norm: 0.07143386
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6844.203125MB
INFO:root:[   93] Training loss: 0.60764795, Validation loss: 0.62124307, Gradient norm: 0.07332881
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6882.37109375MB
INFO:root:[   94] Training loss: 0.60740447, Validation loss: 0.62060214, Gradient norm: 0.07134901
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6920.7578125MB
INFO:root:[   95] Training loss: 0.60717653, Validation loss: 0.62041753, Gradient norm: 0.07702422
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6958.90234375MB
INFO:root:[   96] Training loss: 0.60671508, Validation loss: 0.62085823, Gradient norm: 0.06769929
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=6997.046875MB
INFO:root:[   97] Training loss: 0.60632893, Validation loss: 0.62057779, Gradient norm: 0.07292611
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7034.89453125MB
INFO:root:[   98] Training loss: 0.60621563, Validation loss: 0.61968308, Gradient norm: 0.07514941
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7073.2578125MB
INFO:root:[   99] Training loss: 0.60584133, Validation loss: 0.62010735, Gradient norm: 0.07360016
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7112.375MB
INFO:root:[  100] Training loss: 0.60562594, Validation loss: 0.61991831, Gradient norm: 0.06921197
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7150.51953125MB
INFO:root:[  101] Training loss: 0.60532124, Validation loss: 0.62107472, Gradient norm: 0.07876111
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7188.7265625MB
INFO:root:[  102] Training loss: 0.60466107, Validation loss: 0.61995773, Gradient norm: 0.07134147
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7226.88671875MB
INFO:root:[  103] Training loss: 0.60467330, Validation loss: 0.61971488, Gradient norm: 0.07609822
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7264.8046875MB
INFO:root:[  104] Training loss: 0.60423830, Validation loss: 0.61936699, Gradient norm: 0.06993403
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7303.22265625MB
INFO:root:[  105] Training loss: 0.60414624, Validation loss: 0.62066657, Gradient norm: 0.06945513
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7341.39453125MB
INFO:root:[  106] Training loss: 0.60377597, Validation loss: 0.61966611, Gradient norm: 0.06944890
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7379.80078125MB
INFO:root:[  107] Training loss: 0.60356816, Validation loss: 0.61914974, Gradient norm: 0.07029711
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7418.2421875MB
INFO:root:[  108] Training loss: 0.60317076, Validation loss: 0.61990933, Gradient norm: 0.06967836
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7456.1171875MB
INFO:root:[  109] Training loss: 0.60342582, Validation loss: 0.61997644, Gradient norm: 0.08425753
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7494.48828125MB
INFO:root:[  110] Training loss: 0.60284276, Validation loss: 0.61808480, Gradient norm: 0.08004645
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7532.66796875MB
INFO:root:[  111] Training loss: 0.60225639, Validation loss: 0.61895366, Gradient norm: 0.07039824
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7570.83984375MB
INFO:root:[  112] Training loss: 0.60203082, Validation loss: 0.61914939, Gradient norm: 0.07089732
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7609.01953125MB
INFO:root:[  113] Training loss: 0.60192239, Validation loss: 0.61986514, Gradient norm: 0.07254226
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7646.87109375MB
INFO:root:[  114] Training loss: 0.60173636, Validation loss: 0.61946292, Gradient norm: 0.07870777
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7685.046875MB
INFO:root:[  115] Training loss: 0.60135474, Validation loss: 0.61835684, Gradient norm: 0.06887788
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7723.109375MB
INFO:root:[  116] Training loss: 0.60094850, Validation loss: 0.61914510, Gradient norm: 0.07361238
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7761.28125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  117] Training loss: 0.60065792, Validation loss: 0.61905321, Gradient norm: 0.06945468
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7799.578125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  118] Training loss: 0.59945389, Validation loss: 0.61803788, Gradient norm: 0.06285076
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7837.7109375MB
INFO:root:[  119] Training loss: 0.59847672, Validation loss: 0.61790393, Gradient norm: 0.05769123
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7876.1328125MB
INFO:root:[  120] Training loss: 0.59809452, Validation loss: 0.61803310, Gradient norm: 0.05836556
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7914.26171875MB
INFO:root:[  121] Training loss: 0.59794462, Validation loss: 0.61829870, Gradient norm: 0.05731347
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7952.40625MB
INFO:root:[  122] Training loss: 0.59797128, Validation loss: 0.61827811, Gradient norm: 0.06516655
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=7990.796875MB
INFO:root:[  123] Training loss: 0.59798787, Validation loss: 0.61804092, Gradient norm: 0.05800774
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8028.66015625MB
INFO:root:[  124] Training loss: 0.59777289, Validation loss: 0.61883083, Gradient norm: 0.06076027
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8066.765625MB
INFO:root:[  125] Training loss: 0.59777553, Validation loss: 0.61790116, Gradient norm: 0.06158359
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8105.09375MB
INFO:root:[  126] Training loss: 0.59763992, Validation loss: 0.61810253, Gradient norm: 0.06127025
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8143.25MB
INFO:root:[  127] Training loss: 0.59742295, Validation loss: 0.61752707, Gradient norm: 0.05842240
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8181.39453125MB
INFO:root:[  128] Training loss: 0.59751678, Validation loss: 0.61889199, Gradient norm: 0.06215174
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8219.5390625MB
INFO:root:[  129] Training loss: 0.59750715, Validation loss: 0.61830097, Gradient norm: 0.06373783
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8257.68359375MB
INFO:root:[  130] Training loss: 0.59743570, Validation loss: 0.61881773, Gradient norm: 0.06179582
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8295.796875MB
INFO:root:[  131] Training loss: 0.59722200, Validation loss: 0.61927749, Gradient norm: 0.05842979
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8334.16015625MB
INFO:root:[  132] Training loss: 0.59708829, Validation loss: 0.61862412, Gradient norm: 0.06111788
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8372.2734375MB
INFO:root:[  133] Training loss: 0.59695558, Validation loss: 0.61716105, Gradient norm: 0.06088258
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8409.71484375MB
INFO:root:[  134] Training loss: 0.59702161, Validation loss: 0.61905543, Gradient norm: 0.06048248
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8448.33203125MB
INFO:root:[  135] Training loss: 0.59684525, Validation loss: 0.61913922, Gradient norm: 0.06345054
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8486.47265625MB
INFO:root:[  136] Training loss: 0.59679005, Validation loss: 0.61850992, Gradient norm: 0.06410665
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8524.6171875MB
INFO:root:[  137] Training loss: 0.59688800, Validation loss: 0.61774919, Gradient norm: 0.06011591
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8563.0MB
INFO:root:[  138] Training loss: 0.59654833, Validation loss: 0.61781103, Gradient norm: 0.06099983
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8600.8515625MB
INFO:root:[  139] Training loss: 0.59683423, Validation loss: 0.61849253, Gradient norm: 0.06387364
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8638.97265625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  140] Training loss: 0.59676101, Validation loss: 0.61889051, Gradient norm: 0.06158722
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8677.11328125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  141] Training loss: 0.59613163, Validation loss: 0.61859294, Gradient norm: 0.05861426
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8714.921875MB
INFO:root:[  142] Training loss: 0.59577753, Validation loss: 0.61827202, Gradient norm: 0.05685833
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8753.2890625MB
INFO:root:EP 142: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12460.72265625MB; mem (CPU total)=8791.1875MB
INFO:root:Training the model took 10088.911s.
INFO:root:Emptying the cuda cache took 0.023s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84673
INFO:root:EnergyScoreTrain: 0.59641
INFO:root:CRPSTrain: 0.5152
INFO:root:Gaussian NLLTrain: 2.17848
INFO:root:CoverageTrain: 0.81447
INFO:root:IntervalWidthTrain: 3.15175
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87828
INFO:root:EnergyScoreValidation: 0.61841
INFO:root:CRPSValidation: 0.53313
INFO:root:Gaussian NLLValidation: 2.23172
INFO:root:CoverageValidation: 0.80396
INFO:root:IntervalWidthValidation: 3.1438
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88032
INFO:root:EnergyScoreTest: 0.61994
INFO:root:CRPSTest: 0.5345
INFO:root:Gaussian NLLTest: 2.23436
INFO:root:CoverageTest: 0.80294
INFO:root:IntervalWidthTest: 3.14075
INFO:root:After validation: mem (CPU python)=12460.72265625MB; mem (CPU total)=8836.39453125MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=12460.72265625MB; mem (CPU total)=8836.359375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 161480704
INFO:root:After setting up the model: mem (CPU python)=12460.72265625MB; mem (CPU total)=8837.34375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8837.33984375MB
INFO:root:[    1] Training loss: 0.78596809, Validation loss: 0.72356952, Gradient norm: 0.55806057
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8876.44921875MB
INFO:root:[    2] Training loss: 0.72165882, Validation loss: 0.72054800, Gradient norm: 0.30756271
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8913.84765625MB
INFO:root:[    3] Training loss: 0.72043789, Validation loss: 0.72025408, Gradient norm: 0.36071525
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8952.0234375MB
INFO:root:[    4] Training loss: 0.71993204, Validation loss: 0.71976057, Gradient norm: 0.35811269
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=8990.11328125MB
INFO:root:[    5] Training loss: 0.71938824, Validation loss: 0.71906110, Gradient norm: 0.21152286
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9028.49609375MB
INFO:root:[    6] Training loss: 0.71883732, Validation loss: 0.71906806, Gradient norm: 0.19468643
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9066.6328125MB
INFO:root:[    7] Training loss: 0.71819570, Validation loss: 0.71774867, Gradient norm: 0.17620484
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9105.0234375MB
INFO:root:[    8] Training loss: 0.71624465, Validation loss: 0.71403896, Gradient norm: 0.24821061
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9143.16796875MB
INFO:root:[    9] Training loss: 0.70727204, Validation loss: 0.70141783, Gradient norm: 0.18411969
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9181.75390625MB
INFO:root:[   10] Training loss: 0.69453698, Validation loss: 0.68913155, Gradient norm: 0.16495826
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9219.6796875MB
INFO:root:[   11] Training loss: 0.68359428, Validation loss: 0.67962543, Gradient norm: 0.10715144
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9258.109375MB
INFO:root:[   12] Training loss: 0.67534635, Validation loss: 0.67262215, Gradient norm: 0.13240147
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9296.265625MB
INFO:root:[   13] Training loss: 0.66944818, Validation loss: 0.66805931, Gradient norm: 0.11491951
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9334.44140625MB
INFO:root:[   14] Training loss: 0.66514946, Validation loss: 0.66429148, Gradient norm: 0.08428763
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9372.859375MB
INFO:root:[   15] Training loss: 0.66173315, Validation loss: 0.66202767, Gradient norm: 0.07997332
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9410.93359375MB
INFO:root:[   16] Training loss: 0.65892780, Validation loss: 0.65918366, Gradient norm: 0.08219977
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9449.10546875MB
INFO:root:[   17] Training loss: 0.65658343, Validation loss: 0.65698716, Gradient norm: 0.09053360
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9486.984375MB
INFO:root:[   18] Training loss: 0.65420467, Validation loss: 0.65604869, Gradient norm: 0.06929494
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9524.65625MB
INFO:root:[   19] Training loss: 0.65221133, Validation loss: 0.65341287, Gradient norm: 0.07780105
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9563.84375MB
INFO:root:[   20] Training loss: 0.65049581, Validation loss: 0.65235982, Gradient norm: 0.06489446
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9602.03515625MB
INFO:root:[   21] Training loss: 0.64896482, Validation loss: 0.65011424, Gradient norm: 0.06031137
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9640.203125MB
INFO:root:[   22] Training loss: 0.64735597, Validation loss: 0.64954888, Gradient norm: 0.07788536
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9678.30078125MB
INFO:root:[   23] Training loss: 0.64588374, Validation loss: 0.64777547, Gradient norm: 0.06491758
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9716.15625MB
INFO:root:[   24] Training loss: 0.64460703, Validation loss: 0.64639329, Gradient norm: 0.06778170
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9754.7734375MB
INFO:root:[   25] Training loss: 0.64334519, Validation loss: 0.64541271, Gradient norm: 0.06713929
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9792.90234375MB
INFO:root:[   26] Training loss: 0.64223766, Validation loss: 0.64432915, Gradient norm: 0.06275664
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9830.09375MB
INFO:root:[   27] Training loss: 0.64116795, Validation loss: 0.64392825, Gradient norm: 0.06307064
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9867.9453125MB
INFO:root:[   28] Training loss: 0.63974978, Validation loss: 0.64236022, Gradient norm: 0.06581464
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9906.078125MB
INFO:root:[   29] Training loss: 0.63882452, Validation loss: 0.64077590, Gradient norm: 0.06861290
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9944.23828125MB
INFO:root:[   30] Training loss: 0.63753968, Validation loss: 0.64154017, Gradient norm: 0.07068360
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=9982.40625MB
INFO:root:[   31] Training loss: 0.63659233, Validation loss: 0.64013550, Gradient norm: 0.07028118
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10020.56640625MB
INFO:root:[   32] Training loss: 0.63568385, Validation loss: 0.63835699, Gradient norm: 0.06792584
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10058.6796875MB
INFO:root:[   33] Training loss: 0.63458078, Validation loss: 0.63751348, Gradient norm: 0.06627122
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10095.79296875MB
INFO:root:[   34] Training loss: 0.63381844, Validation loss: 0.63693959, Gradient norm: 0.06720211
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10133.95703125MB
INFO:root:[   35] Training loss: 0.63298457, Validation loss: 0.63674870, Gradient norm: 0.06724755
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10172.64453125MB
INFO:root:[   36] Training loss: 0.63199486, Validation loss: 0.63610737, Gradient norm: 0.06890100
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10210.75MB
INFO:root:[   37] Training loss: 0.63113182, Validation loss: 0.63557776, Gradient norm: 0.07105732
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10248.89453125MB
INFO:root:[   38] Training loss: 0.63023862, Validation loss: 0.63479024, Gradient norm: 0.07283760
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10287.0390625MB
INFO:root:[   39] Training loss: 0.62960735, Validation loss: 0.63332557, Gradient norm: 0.06492138
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10325.421875MB
INFO:root:[   40] Training loss: 0.62846513, Validation loss: 0.63286596, Gradient norm: 0.06715207
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10363.56640625MB
INFO:root:[   41] Training loss: 0.62793137, Validation loss: 0.63374338, Gradient norm: 0.06624325
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10401.6953125MB
INFO:root:[   42] Training loss: 0.62695935, Validation loss: 0.63196505, Gradient norm: 0.06595622
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10439.8359375MB
INFO:root:[   43] Training loss: 0.62648085, Validation loss: 0.63158843, Gradient norm: 0.07057223
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10477.8671875MB
INFO:root:[   44] Training loss: 0.62580506, Validation loss: 0.63082987, Gradient norm: 0.07031128
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10516.2109375MB
INFO:root:[   45] Training loss: 0.62542806, Validation loss: 0.63034958, Gradient norm: 0.08351505
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10554.35546875MB
INFO:root:[   46] Training loss: 0.62449711, Validation loss: 0.62956555, Gradient norm: 0.07513820
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10592.41796875MB
INFO:root:[   47] Training loss: 0.62386367, Validation loss: 0.62930452, Gradient norm: 0.06141983
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10630.59375MB
INFO:root:[   48] Training loss: 0.62323279, Validation loss: 0.62952031, Gradient norm: 0.07107410
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10668.73828125MB
INFO:root:[   49] Training loss: 0.62259941, Validation loss: 0.62830457, Gradient norm: 0.06470021
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10706.86328125MB
INFO:root:[   50] Training loss: 0.62185110, Validation loss: 0.62773370, Gradient norm: 0.07215946
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10745.4921875MB
INFO:root:[   51] Training loss: 0.62146460, Validation loss: 0.62837103, Gradient norm: 0.07531494
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10783.640625MB
INFO:root:[   52] Training loss: 0.62063987, Validation loss: 0.62672917, Gradient norm: 0.06297747
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10821.484375MB
INFO:root:[   53] Training loss: 0.62017037, Validation loss: 0.62642314, Gradient norm: 0.06676186
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10859.109375MB
INFO:root:[   54] Training loss: 0.61989681, Validation loss: 0.62605265, Gradient norm: 0.07175334
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10897.0MB
INFO:root:[   55] Training loss: 0.61906976, Validation loss: 0.62663223, Gradient norm: 0.06716361
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10935.0703125MB
INFO:root:[   56] Training loss: 0.61865492, Validation loss: 0.62588936, Gradient norm: 0.07252046
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=10973.05859375MB
INFO:root:[   57] Training loss: 0.61811667, Validation loss: 0.62476688, Gradient norm: 0.07094436
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11011.14453125MB
INFO:root:[   58] Training loss: 0.61767004, Validation loss: 0.62405187, Gradient norm: 0.06959240
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11049.5546875MB
INFO:root:[   59] Training loss: 0.61706443, Validation loss: 0.62520962, Gradient norm: 0.06502036
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11087.6875MB
INFO:root:[   60] Training loss: 0.61677566, Validation loss: 0.62477609, Gradient norm: 0.07598240
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11125.765625MB
INFO:root:[   61] Training loss: 0.61608294, Validation loss: 0.62467343, Gradient norm: 0.07217773
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11164.15234375MB
INFO:root:[   62] Training loss: 0.61543355, Validation loss: 0.62452487, Gradient norm: 0.07155523
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11202.1953125MB
INFO:root:[   63] Training loss: 0.61547749, Validation loss: 0.62454426, Gradient norm: 0.07703605
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11240.09375MB
INFO:root:[   64] Training loss: 0.61460431, Validation loss: 0.62297927, Gradient norm: 0.07638520
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11278.44140625MB
INFO:root:[   65] Training loss: 0.61431916, Validation loss: 0.62277299, Gradient norm: 0.07022137
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11316.3203125MB
INFO:root:[   66] Training loss: 0.61382049, Validation loss: 0.62233574, Gradient norm: 0.06757828
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11354.625MB
INFO:root:[   67] Training loss: 0.61323587, Validation loss: 0.62287709, Gradient norm: 0.06732545
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11393.0MB
INFO:root:[   68] Training loss: 0.61327449, Validation loss: 0.62262275, Gradient norm: 0.08202835
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11431.13671875MB
INFO:root:[   69] Training loss: 0.61262327, Validation loss: 0.62173224, Gradient norm: 0.07213524
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11469.28125MB
INFO:root:[   70] Training loss: 0.61205721, Validation loss: 0.62103668, Gradient norm: 0.07404381
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11507.671875MB
INFO:root:[   71] Training loss: 0.61146752, Validation loss: 0.62186483, Gradient norm: 0.06359602
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11545.81640625MB
INFO:root:[   72] Training loss: 0.61120947, Validation loss: 0.62091630, Gradient norm: 0.07215779
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11584.203125MB
INFO:root:[   73] Training loss: 0.61072198, Validation loss: 0.62158955, Gradient norm: 0.07709463
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11622.34375MB
INFO:root:[   74] Training loss: 0.61047889, Validation loss: 0.62065575, Gradient norm: 0.07035061
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11660.359375MB
INFO:root:[   75] Training loss: 0.61007758, Validation loss: 0.62015312, Gradient norm: 0.07324533
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11698.53515625MB
INFO:root:[   76] Training loss: 0.60953111, Validation loss: 0.62039934, Gradient norm: 0.06380581
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11736.671875MB
INFO:root:[   77] Training loss: 0.60905487, Validation loss: 0.62011429, Gradient norm: 0.06924358
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11774.81640625MB
INFO:root:[   78] Training loss: 0.60896400, Validation loss: 0.62055464, Gradient norm: 0.07592968
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11813.20703125MB
INFO:root:[   79] Training loss: 0.60855370, Validation loss: 0.62075130, Gradient norm: 0.06610450
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11851.3515625MB
INFO:root:[   80] Training loss: 0.60807057, Validation loss: 0.61992883, Gradient norm: 0.07318803
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11889.0MB
INFO:root:[   81] Training loss: 0.60753198, Validation loss: 0.62050103, Gradient norm: 0.07205885
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11927.56640625MB
INFO:root:[   82] Training loss: 0.60757651, Validation loss: 0.61932059, Gradient norm: 0.07041381
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=11965.97265625MB
INFO:root:[   83] Training loss: 0.60707246, Validation loss: 0.61909079, Gradient norm: 0.07537899
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=12004.39453125MB
INFO:root:[   84] Training loss: 0.60656145, Validation loss: 0.61979700, Gradient norm: 0.07420700
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=12042.5703125MB
INFO:root:[   85] Training loss: 0.60642074, Validation loss: 0.61913801, Gradient norm: 0.07601990
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=12080.49609375MB
INFO:root:[   86] Training loss: 0.60601215, Validation loss: 0.61920576, Gradient norm: 0.07151533
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=12118.671875MB
INFO:root:[   87] Training loss: 0.60530953, Validation loss: 0.61916021, Gradient norm: 0.06995188
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=12157.02734375MB
INFO:root:[   88] Training loss: 0.60487060, Validation loss: 0.61915712, Gradient norm: 0.06665251
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=12194.8125MB
INFO:root:[   89] Training loss: 0.60485571, Validation loss: 0.61876909, Gradient norm: 0.07832171
INFO:root:At the start of the epoch: mem (CPU python)=12460.72265625MB; mem (CPU total)=12233.44921875MB
INFO:root:[   90] Training loss: 0.60455716, Validation loss: 0.61783958, Gradient norm: 0.07714588
INFO:root:At the start of the epoch: mem (CPU python)=12479.50390625MB; mem (CPU total)=12271.3046875MB
INFO:root:[   91] Training loss: 0.60430634, Validation loss: 0.61846207, Gradient norm: 0.07668451
INFO:root:At the start of the epoch: mem (CPU python)=12517.59765625MB; mem (CPU total)=12309.46484375MB
INFO:root:[   92] Training loss: 0.60402695, Validation loss: 0.61867075, Gradient norm: 0.07743650
INFO:root:At the start of the epoch: mem (CPU python)=12555.69140625MB; mem (CPU total)=12347.609375MB
INFO:root:[   93] Training loss: 0.60370343, Validation loss: 0.62011980, Gradient norm: 0.08916261
INFO:root:At the start of the epoch: mem (CPU python)=12593.78515625MB; mem (CPU total)=12385.75390625MB
INFO:root:[   94] Training loss: 0.60307116, Validation loss: 0.61910603, Gradient norm: 0.07454254
INFO:root:At the start of the epoch: mem (CPU python)=12631.8828125MB; mem (CPU total)=12423.8046875MB
INFO:root:[   95] Training loss: 0.60288099, Validation loss: 0.61741109, Gradient norm: 0.07565986
INFO:root:At the start of the epoch: mem (CPU python)=12669.9765625MB; mem (CPU total)=12461.98046875MB
INFO:root:[   96] Training loss: 0.60221524, Validation loss: 0.61848596, Gradient norm: 0.06546037
INFO:root:At the start of the epoch: mem (CPU python)=12708.0703125MB; mem (CPU total)=12500.12109375MB
INFO:root:[   97] Training loss: 0.60241922, Validation loss: 0.61783111, Gradient norm: 0.07387184
INFO:root:At the start of the epoch: mem (CPU python)=12746.171875MB; mem (CPU total)=12538.05859375MB
INFO:root:[   98] Training loss: 0.60193212, Validation loss: 0.61775757, Gradient norm: 0.07639524
INFO:root:At the start of the epoch: mem (CPU python)=12784.265625MB; mem (CPU total)=12576.11328125MB
INFO:root:[   99] Training loss: 0.60150470, Validation loss: 0.61844487, Gradient norm: 0.07213847
INFO:root:At the start of the epoch: mem (CPU python)=12822.359375MB; mem (CPU total)=12614.546875MB
INFO:root:[  100] Training loss: 0.60140068, Validation loss: 0.61717073, Gradient norm: 0.07481461
INFO:root:At the start of the epoch: mem (CPU python)=12860.45703125MB; mem (CPU total)=12652.66015625MB
INFO:root:[  101] Training loss: 0.60107143, Validation loss: 0.61770077, Gradient norm: 0.07662387
INFO:root:At the start of the epoch: mem (CPU python)=12898.55078125MB; mem (CPU total)=12690.80078125MB
INFO:root:[  102] Training loss: 0.60043360, Validation loss: 0.61858305, Gradient norm: 0.07408767
INFO:root:At the start of the epoch: mem (CPU python)=12936.64453125MB; mem (CPU total)=12728.9453125MB
INFO:root:[  103] Training loss: 0.60039461, Validation loss: 0.61749690, Gradient norm: 0.07401869
INFO:root:At the start of the epoch: mem (CPU python)=12974.73828125MB; mem (CPU total)=12766.59375MB
INFO:root:[  104] Training loss: 0.59995394, Validation loss: 0.61812652, Gradient norm: 0.07488356
INFO:root:At the start of the epoch: mem (CPU python)=13012.8359375MB; mem (CPU total)=12804.98046875MB
INFO:root:[  105] Training loss: 0.59972101, Validation loss: 0.61625894, Gradient norm: 0.06905919
INFO:root:At the start of the epoch: mem (CPU python)=13050.93359375MB; mem (CPU total)=12843.1640625MB
INFO:root:[  106] Training loss: 0.59959709, Validation loss: 0.61716174, Gradient norm: 0.07015287
INFO:root:At the start of the epoch: mem (CPU python)=13089.02734375MB; mem (CPU total)=12881.30078125MB
INFO:root:[  107] Training loss: 0.59898378, Validation loss: 0.61773019, Gradient norm: 0.07367908
INFO:root:At the start of the epoch: mem (CPU python)=13127.140625MB; mem (CPU total)=12919.28515625MB
INFO:root:[  108] Training loss: 0.59892994, Validation loss: 0.61674160, Gradient norm: 0.08370972
INFO:root:At the start of the epoch: mem (CPU python)=13165.22265625MB; mem (CPU total)=12957.45703125MB
INFO:root:[  109] Training loss: 0.59849151, Validation loss: 0.61782614, Gradient norm: 0.07157744
INFO:root:At the start of the epoch: mem (CPU python)=13203.31640625MB; mem (CPU total)=12995.53125MB
INFO:root:[  110] Training loss: 0.59846127, Validation loss: 0.61696751, Gradient norm: 0.07010868
INFO:root:At the start of the epoch: mem (CPU python)=13241.41015625MB; mem (CPU total)=13033.453125MB
INFO:root:[  111] Training loss: 0.59791437, Validation loss: 0.61716461, Gradient norm: 0.07806418
INFO:root:At the start of the epoch: mem (CPU python)=13279.5078125MB; mem (CPU total)=13071.31640625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  112] Training loss: 0.59740827, Validation loss: 0.61724118, Gradient norm: 0.08028847
INFO:root:At the start of the epoch: mem (CPU python)=13317.6015625MB; mem (CPU total)=13110.46484375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  113] Training loss: 0.59607496, Validation loss: 0.61697128, Gradient norm: 0.06667689
INFO:root:At the start of the epoch: mem (CPU python)=13355.6953125MB; mem (CPU total)=13148.71484375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  114] Training loss: 0.59496618, Validation loss: 0.61608026, Gradient norm: 0.05914884
INFO:root:At the start of the epoch: mem (CPU python)=13393.796875MB; mem (CPU total)=13187.16015625MB
INFO:root:[  115] Training loss: 0.59455931, Validation loss: 0.61690528, Gradient norm: 0.05728504
INFO:root:At the start of the epoch: mem (CPU python)=13431.890625MB; mem (CPU total)=13225.25MB
INFO:root:[  116] Training loss: 0.59471422, Validation loss: 0.61597239, Gradient norm: 0.05688588
INFO:root:At the start of the epoch: mem (CPU python)=13469.984375MB; mem (CPU total)=13263.42578125MB
INFO:root:[  117] Training loss: 0.59476153, Validation loss: 0.61547823, Gradient norm: 0.05917689
INFO:root:At the start of the epoch: mem (CPU python)=13508.08203125MB; mem (CPU total)=13301.6328125MB
INFO:root:[  118] Training loss: 0.59457843, Validation loss: 0.61724248, Gradient norm: 0.05828263
INFO:root:At the start of the epoch: mem (CPU python)=13546.17578125MB; mem (CPU total)=13339.7265625MB
INFO:root:[  119] Training loss: 0.59470270, Validation loss: 0.61627308, Gradient norm: 0.06011608
INFO:root:At the start of the epoch: mem (CPU python)=13584.26953125MB; mem (CPU total)=13378.109375MB
INFO:root:[  120] Training loss: 0.59405761, Validation loss: 0.61689306, Gradient norm: 0.05774979
INFO:root:At the start of the epoch: mem (CPU python)=13622.3671875MB; mem (CPU total)=13415.7421875MB
INFO:root:[  121] Training loss: 0.59444173, Validation loss: 0.61705969, Gradient norm: 0.05826316
INFO:root:At the start of the epoch: mem (CPU python)=13660.46484375MB; mem (CPU total)=13454.11328125MB
INFO:root:[  122] Training loss: 0.59437169, Validation loss: 0.61705054, Gradient norm: 0.05944808
INFO:root:At the start of the epoch: mem (CPU python)=13698.55859375MB; mem (CPU total)=13492.27734375MB
INFO:root:[  123] Training loss: 0.59411851, Validation loss: 0.61656556, Gradient norm: 0.05848059
INFO:root:At the start of the epoch: mem (CPU python)=13736.65234375MB; mem (CPU total)=13530.4453125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  124] Training loss: 0.59425121, Validation loss: 0.61648030, Gradient norm: 0.06048376
INFO:root:At the start of the epoch: mem (CPU python)=13774.75MB; mem (CPU total)=13568.62109375MB
INFO:root:[  125] Training loss: 0.59377119, Validation loss: 0.61703948, Gradient norm: 0.05662696
INFO:root:At the start of the epoch: mem (CPU python)=13812.84375MB; mem (CPU total)=13606.79296875MB
INFO:root:[  126] Training loss: 0.59382379, Validation loss: 0.61718936, Gradient norm: 0.05730485
INFO:root:At the start of the epoch: mem (CPU python)=13850.9375MB; mem (CPU total)=13644.71484375MB
INFO:root:EP 126: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=13889.03125MB; mem (CPU total)=13682.8828125MB
INFO:root:Training the model took 9716.146s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8434
INFO:root:EnergyScoreTrain: 0.59412
INFO:root:CRPSTrain: 0.51353
INFO:root:Gaussian NLLTrain: 2.42504
INFO:root:CoverageTrain: 0.81571
INFO:root:IntervalWidthTrain: 3.16054
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87556
INFO:root:EnergyScoreValidation: 0.61644
INFO:root:CRPSValidation: 0.53195
INFO:root:Gaussian NLLValidation: 2.48255
INFO:root:CoverageValidation: 0.80499
INFO:root:IntervalWidthValidation: 3.15746
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87601
INFO:root:EnergyScoreTest: 0.6168
INFO:root:CRPSTest: 0.5322
INFO:root:Gaussian NLLTest: 2.48023
INFO:root:CoverageTest: 0.80377
INFO:root:IntervalWidthTest: 3.1475
INFO:root:After validation: mem (CPU python)=13931.9921875MB; mem (CPU total)=13725.78125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=13931.9921875MB; mem (CPU total)=13725.81640625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 161480704
INFO:root:After setting up the model: mem (CPU python)=13932.390625MB; mem (CPU total)=13726.0625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=13932.4375MB; mem (CPU total)=13726.3125MB
INFO:root:[    1] Training loss: 0.78298598, Validation loss: 0.72337380, Gradient norm: 0.60631753
INFO:root:At the start of the epoch: mem (CPU python)=13972.671875MB; mem (CPU total)=13767.07421875MB
INFO:root:[    2] Training loss: 0.72181296, Validation loss: 0.72096060, Gradient norm: 0.39827779
INFO:root:At the start of the epoch: mem (CPU python)=14010.76171875MB; mem (CPU total)=13805.03515625MB
INFO:root:[    3] Training loss: 0.72025065, Validation loss: 0.71971335, Gradient norm: 0.22492868
INFO:root:At the start of the epoch: mem (CPU python)=14048.875MB; mem (CPU total)=13843.1875MB
INFO:root:[    4] Training loss: 0.71976789, Validation loss: 0.71982527, Gradient norm: 0.26123211
INFO:root:At the start of the epoch: mem (CPU python)=14086.98828125MB; mem (CPU total)=13881.59765625MB
INFO:root:[    5] Training loss: 0.71974050, Validation loss: 0.72005564, Gradient norm: 0.36181968
INFO:root:At the start of the epoch: mem (CPU python)=14125.09765625MB; mem (CPU total)=13919.0703125MB
INFO:root:[    6] Training loss: 0.71897527, Validation loss: 0.71924831, Gradient norm: 0.17314810
INFO:root:At the start of the epoch: mem (CPU python)=14163.23046875MB; mem (CPU total)=13957.57421875MB
INFO:root:[    7] Training loss: 0.71818980, Validation loss: 0.71780353, Gradient norm: 0.19500600
INFO:root:At the start of the epoch: mem (CPU python)=14201.33984375MB; mem (CPU total)=13995.6796875MB
INFO:root:[    8] Training loss: 0.71508909, Validation loss: 0.71042488, Gradient norm: 0.15064330
INFO:root:At the start of the epoch: mem (CPU python)=14239.44921875MB; mem (CPU total)=14034.05859375MB
INFO:root:[    9] Training loss: 0.70438226, Validation loss: 0.69729751, Gradient norm: 0.19276026
INFO:root:At the start of the epoch: mem (CPU python)=14277.52734375MB; mem (CPU total)=14071.98828125MB
INFO:root:[   10] Training loss: 0.69136651, Validation loss: 0.68580270, Gradient norm: 0.18530378
INFO:root:At the start of the epoch: mem (CPU python)=14315.62109375MB; mem (CPU total)=14109.91796875MB
INFO:root:[   11] Training loss: 0.68168428, Validation loss: 0.67851584, Gradient norm: 0.11638115
INFO:root:At the start of the epoch: mem (CPU python)=14353.71875MB; mem (CPU total)=14148.53125MB
INFO:root:[   12] Training loss: 0.67433117, Validation loss: 0.67292311, Gradient norm: 0.11904033
INFO:root:At the start of the epoch: mem (CPU python)=14391.81640625MB; mem (CPU total)=14186.64453125MB
INFO:root:[   13] Training loss: 0.66867812, Validation loss: 0.66797183, Gradient norm: 0.12541205
INFO:root:At the start of the epoch: mem (CPU python)=14429.91015625MB; mem (CPU total)=14224.95703125MB
INFO:root:[   14] Training loss: 0.66472089, Validation loss: 0.66367303, Gradient norm: 0.10034594
INFO:root:At the start of the epoch: mem (CPU python)=14468.0078125MB; mem (CPU total)=14263.15234375MB
INFO:root:[   15] Training loss: 0.66161175, Validation loss: 0.66181256, Gradient norm: 0.09006891
INFO:root:At the start of the epoch: mem (CPU python)=14506.1015625MB; mem (CPU total)=14301.18359375MB
INFO:root:[   16] Training loss: 0.65900683, Validation loss: 0.65933406, Gradient norm: 0.09337560
INFO:root:At the start of the epoch: mem (CPU python)=14544.1953125MB; mem (CPU total)=14338.70703125MB
INFO:root:[   17] Training loss: 0.65686376, Validation loss: 0.65723351, Gradient norm: 0.08448980
INFO:root:At the start of the epoch: mem (CPU python)=14582.2890625MB; mem (CPU total)=14376.359375MB
INFO:root:[   18] Training loss: 0.65475538, Validation loss: 0.65670683, Gradient norm: 0.08162331
INFO:root:At the start of the epoch: mem (CPU python)=14620.38671875MB; mem (CPU total)=14414.36328125MB
INFO:root:[   19] Training loss: 0.65303325, Validation loss: 0.65326881, Gradient norm: 0.08361336
INFO:root:At the start of the epoch: mem (CPU python)=14658.46484375MB; mem (CPU total)=14452.51171875MB
INFO:root:[   20] Training loss: 0.65134295, Validation loss: 0.65248752, Gradient norm: 0.07996127
INFO:root:At the start of the epoch: mem (CPU python)=14696.55859375MB; mem (CPU total)=14491.16015625MB
INFO:root:[   21] Training loss: 0.65019428, Validation loss: 0.65186528, Gradient norm: 0.10148809
INFO:root:At the start of the epoch: mem (CPU python)=14734.66015625MB; mem (CPU total)=14529.1328125MB
INFO:root:[   22] Training loss: 0.64858291, Validation loss: 0.65009999, Gradient norm: 0.07073471
INFO:root:At the start of the epoch: mem (CPU python)=14772.75390625MB; mem (CPU total)=14567.0546875MB
INFO:root:[   23] Training loss: 0.64747786, Validation loss: 0.64949166, Gradient norm: 0.07153060
INFO:root:At the start of the epoch: mem (CPU python)=14810.84765625MB; mem (CPU total)=14605.44140625MB
INFO:root:[   24] Training loss: 0.64603226, Validation loss: 0.64828977, Gradient norm: 0.07180204
INFO:root:At the start of the epoch: mem (CPU python)=14848.9453125MB; mem (CPU total)=14643.8046875MB
INFO:root:[   25] Training loss: 0.64497112, Validation loss: 0.64720726, Gradient norm: 0.06776382
INFO:root:At the start of the epoch: mem (CPU python)=14887.04296875MB; mem (CPU total)=14682.20703125MB
INFO:root:[   26] Training loss: 0.64393714, Validation loss: 0.64688482, Gradient norm: 0.07695040
INFO:root:At the start of the epoch: mem (CPU python)=14925.13671875MB; mem (CPU total)=14720.3125MB
INFO:root:[   27] Training loss: 0.64280131, Validation loss: 0.64479257, Gradient norm: 0.07023120
INFO:root:At the start of the epoch: mem (CPU python)=14963.23046875MB; mem (CPU total)=14758.22265625MB
INFO:root:[   28] Training loss: 0.64182137, Validation loss: 0.64456697, Gradient norm: 0.07363314
INFO:root:At the start of the epoch: mem (CPU python)=15001.328125MB; mem (CPU total)=14796.03515625MB
INFO:root:[   29] Training loss: 0.64098371, Validation loss: 0.64325130, Gradient norm: 0.08111472
INFO:root:At the start of the epoch: mem (CPU python)=15039.42578125MB; mem (CPU total)=14834.82421875MB
INFO:root:[   30] Training loss: 0.63991615, Validation loss: 0.64279538, Gradient norm: 0.07770009
INFO:root:At the start of the epoch: mem (CPU python)=15077.5234375MB; mem (CPU total)=14872.10546875MB
INFO:root:[   31] Training loss: 0.63877126, Validation loss: 0.64218470, Gradient norm: 0.07054715
INFO:root:At the start of the epoch: mem (CPU python)=15115.62109375MB; mem (CPU total)=14909.96484375MB
INFO:root:[   32] Training loss: 0.63783706, Validation loss: 0.64072105, Gradient norm: 0.07717100
INFO:root:At the start of the epoch: mem (CPU python)=15153.71484375MB; mem (CPU total)=14948.109375MB
INFO:root:[   33] Training loss: 0.63679926, Validation loss: 0.64032366, Gradient norm: 0.07405179
INFO:root:At the start of the epoch: mem (CPU python)=15191.80859375MB; mem (CPU total)=14986.421875MB
INFO:root:[   34] Training loss: 0.63634838, Validation loss: 0.63950881, Gradient norm: 0.07734969
INFO:root:At the start of the epoch: mem (CPU python)=15229.90234375MB; mem (CPU total)=15024.328125MB
INFO:root:[   35] Training loss: 0.63518792, Validation loss: 0.63918209, Gradient norm: 0.08033413
INFO:root:At the start of the epoch: mem (CPU python)=15268.00390625MB; mem (CPU total)=15062.4296875MB
INFO:root:[   36] Training loss: 0.63426005, Validation loss: 0.63757749, Gradient norm: 0.06705185
INFO:root:At the start of the epoch: mem (CPU python)=15306.09765625MB; mem (CPU total)=15100.78125MB
INFO:root:[   37] Training loss: 0.63352712, Validation loss: 0.63746621, Gradient norm: 0.08284606
INFO:root:At the start of the epoch: mem (CPU python)=15344.19140625MB; mem (CPU total)=15138.91796875MB
INFO:root:[   38] Training loss: 0.63272733, Validation loss: 0.63661499, Gradient norm: 0.07238539
INFO:root:At the start of the epoch: mem (CPU python)=15382.2890625MB; mem (CPU total)=15177.28515625MB
INFO:root:[   39] Training loss: 0.63170802, Validation loss: 0.63612897, Gradient norm: 0.07281938
INFO:root:At the start of the epoch: mem (CPU python)=15420.3828125MB; mem (CPU total)=15215.18359375MB
INFO:root:[   40] Training loss: 0.63101089, Validation loss: 0.63551665, Gradient norm: 0.07006063
INFO:root:At the start of the epoch: mem (CPU python)=15458.4765625MB; mem (CPU total)=15253.3125MB
INFO:root:[   41] Training loss: 0.63029921, Validation loss: 0.63510713, Gradient norm: 0.07515241
INFO:root:At the start of the epoch: mem (CPU python)=15496.5703125MB; mem (CPU total)=15291.7265625MB
INFO:root:[   42] Training loss: 0.62935975, Validation loss: 0.63422007, Gradient norm: 0.06756908
INFO:root:At the start of the epoch: mem (CPU python)=15534.66796875MB; mem (CPU total)=15329.87109375MB
INFO:root:[   43] Training loss: 0.62874607, Validation loss: 0.63367188, Gradient norm: 0.07444183
INFO:root:At the start of the epoch: mem (CPU python)=15572.76171875MB; mem (CPU total)=15368.44921875MB
INFO:root:[   44] Training loss: 0.62808007, Validation loss: 0.63379025, Gradient norm: 0.07292250
INFO:root:At the start of the epoch: mem (CPU python)=15610.85546875MB; mem (CPU total)=15406.33984375MB
INFO:root:[   45] Training loss: 0.62729220, Validation loss: 0.63309399, Gradient norm: 0.06306744
INFO:root:At the start of the epoch: mem (CPU python)=15648.953125MB; mem (CPU total)=15444.20703125MB
INFO:root:[   46] Training loss: 0.62681346, Validation loss: 0.63205970, Gradient norm: 0.07377229
INFO:root:At the start of the epoch: mem (CPU python)=15687.046875MB; mem (CPU total)=15482.59765625MB
INFO:root:[   47] Training loss: 0.62629354, Validation loss: 0.63167600, Gradient norm: 0.07946783
INFO:root:At the start of the epoch: mem (CPU python)=15725.14453125MB; mem (CPU total)=15520.7421875MB
INFO:root:[   48] Training loss: 0.62550233, Validation loss: 0.63109310, Gradient norm: 0.07688719
INFO:root:At the start of the epoch: mem (CPU python)=15763.2421875MB; mem (CPU total)=15558.875MB
INFO:root:[   49] Training loss: 0.62486097, Validation loss: 0.63188592, Gradient norm: 0.07196365
INFO:root:At the start of the epoch: mem (CPU python)=15801.3359375MB; mem (CPU total)=15597.01953125MB
INFO:root:[   50] Training loss: 0.62396143, Validation loss: 0.63065159, Gradient norm: 0.06755340
INFO:root:At the start of the epoch: mem (CPU python)=15839.4296875MB; mem (CPU total)=15636.2734375MB
INFO:root:[   51] Training loss: 0.62363032, Validation loss: 0.62968016, Gradient norm: 0.07439179
INFO:root:At the start of the epoch: mem (CPU python)=15877.5234375MB; mem (CPU total)=15674.55078125MB
INFO:root:[   52] Training loss: 0.62269644, Validation loss: 0.62963431, Gradient norm: 0.06400883
INFO:root:At the start of the epoch: mem (CPU python)=15915.62109375MB; mem (CPU total)=15712.64453125MB
INFO:root:[   53] Training loss: 0.62234011, Validation loss: 0.62943654, Gradient norm: 0.06937144
INFO:root:At the start of the epoch: mem (CPU python)=15953.71484375MB; mem (CPU total)=15750.8046875MB
INFO:root:[   54] Training loss: 0.62186159, Validation loss: 0.62965597, Gradient norm: 0.07698698
INFO:root:At the start of the epoch: mem (CPU python)=15991.8125MB; mem (CPU total)=15788.875MB
INFO:root:[   55] Training loss: 0.62124068, Validation loss: 0.62759991, Gradient norm: 0.07132296
INFO:root:At the start of the epoch: mem (CPU python)=16029.91015625MB; mem (CPU total)=15826.97265625MB
INFO:root:[   56] Training loss: 0.62078025, Validation loss: 0.62880064, Gradient norm: 0.07047378
INFO:root:At the start of the epoch: mem (CPU python)=16068.00390625MB; mem (CPU total)=15865.0625MB
INFO:root:[   57] Training loss: 0.62039138, Validation loss: 0.62827672, Gradient norm: 0.07844870
INFO:root:At the start of the epoch: mem (CPU python)=16106.09765625MB; mem (CPU total)=15903.66796875MB
INFO:root:[   58] Training loss: 0.61942218, Validation loss: 0.62729186, Gradient norm: 0.06828782
INFO:root:At the start of the epoch: mem (CPU python)=16144.19140625MB; mem (CPU total)=15941.73046875MB
INFO:root:[   59] Training loss: 0.61917262, Validation loss: 0.62669107, Gradient norm: 0.07812641
INFO:root:At the start of the epoch: mem (CPU python)=16182.2890625MB; mem (CPU total)=15979.42578125MB
INFO:root:[   60] Training loss: 0.61853381, Validation loss: 0.62646194, Gradient norm: 0.07367645
INFO:root:At the start of the epoch: mem (CPU python)=16220.3828125MB; mem (CPU total)=16017.33203125MB
INFO:root:[   61] Training loss: 0.61800485, Validation loss: 0.62635220, Gradient norm: 0.06664063
INFO:root:At the start of the epoch: mem (CPU python)=16258.48046875MB; mem (CPU total)=16055.4765625MB
INFO:root:[   62] Training loss: 0.61774317, Validation loss: 0.62607557, Gradient norm: 0.07399986
INFO:root:At the start of the epoch: mem (CPU python)=16296.57421875MB; mem (CPU total)=16093.57421875MB
INFO:root:[   63] Training loss: 0.61710453, Validation loss: 0.62435331, Gradient norm: 0.06493724
INFO:root:At the start of the epoch: mem (CPU python)=16334.671875MB; mem (CPU total)=16131.76953125MB
INFO:root:[   64] Training loss: 0.61655990, Validation loss: 0.62532368, Gradient norm: 0.06630442
INFO:root:At the start of the epoch: mem (CPU python)=16372.765625MB; mem (CPU total)=16169.65625MB
INFO:root:[   65] Training loss: 0.61633367, Validation loss: 0.62574639, Gradient norm: 0.07307472
INFO:root:At the start of the epoch: mem (CPU python)=16410.86328125MB; mem (CPU total)=16208.30859375MB
INFO:root:[   66] Training loss: 0.61574119, Validation loss: 0.62511306, Gradient norm: 0.06936357
INFO:root:At the start of the epoch: mem (CPU python)=16448.95703125MB; mem (CPU total)=16246.40234375MB
INFO:root:[   67] Training loss: 0.61506958, Validation loss: 0.62401344, Gradient norm: 0.06773367
INFO:root:At the start of the epoch: mem (CPU python)=16487.05078125MB; mem (CPU total)=16284.5MB
INFO:root:[   68] Training loss: 0.61483621, Validation loss: 0.62379236, Gradient norm: 0.06962966
INFO:root:At the start of the epoch: mem (CPU python)=16525.14453125MB; mem (CPU total)=16323.16796875MB
INFO:root:[   69] Training loss: 0.61463882, Validation loss: 0.62445356, Gradient norm: 0.06974211
INFO:root:At the start of the epoch: mem (CPU python)=16563.2421875MB; mem (CPU total)=16360.56640625MB
INFO:root:[   70] Training loss: 0.61391759, Validation loss: 0.62410958, Gradient norm: 0.07207298
INFO:root:At the start of the epoch: mem (CPU python)=16601.33984375MB; mem (CPU total)=16398.703125MB
INFO:root:[   71] Training loss: 0.61362525, Validation loss: 0.62336297, Gradient norm: 0.08158749
INFO:root:At the start of the epoch: mem (CPU python)=16639.43359375MB; mem (CPU total)=16437.046875MB
INFO:root:[   72] Training loss: 0.61317522, Validation loss: 0.62301663, Gradient norm: 0.07422810
INFO:root:At the start of the epoch: mem (CPU python)=16677.53125MB; mem (CPU total)=16475.328125MB
INFO:root:[   73] Training loss: 0.61283114, Validation loss: 0.62203962, Gradient norm: 0.06873074
INFO:root:At the start of the epoch: mem (CPU python)=16715.625MB; mem (CPU total)=16513.26171875MB
INFO:root:[   74] Training loss: 0.61262690, Validation loss: 0.62240743, Gradient norm: 0.08039945
INFO:root:At the start of the epoch: mem (CPU python)=16753.71875MB; mem (CPU total)=16551.390625MB
INFO:root:[   75] Training loss: 0.61166792, Validation loss: 0.62300362, Gradient norm: 0.06918431
INFO:root:At the start of the epoch: mem (CPU python)=16791.8125MB; mem (CPU total)=16589.53515625MB
INFO:root:[   76] Training loss: 0.61142855, Validation loss: 0.62293710, Gradient norm: 0.07325628
INFO:root:At the start of the epoch: mem (CPU python)=16829.91015625MB; mem (CPU total)=16627.63671875MB
INFO:root:[   77] Training loss: 0.61126414, Validation loss: 0.62246350, Gradient norm: 0.07003084
INFO:root:At the start of the epoch: mem (CPU python)=16868.00390625MB; mem (CPU total)=16665.96484375MB
INFO:root:[   78] Training loss: 0.61095157, Validation loss: 0.62243472, Gradient norm: 0.07527131
INFO:root:At the start of the epoch: mem (CPU python)=16906.1015625MB; mem (CPU total)=16705.0390625MB
INFO:root:[   79] Training loss: 0.61058115, Validation loss: 0.62240129, Gradient norm: 0.08253665
INFO:root:At the start of the epoch: mem (CPU python)=16944.19921875MB; mem (CPU total)=16743.1328125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   80] Training loss: 0.60987870, Validation loss: 0.62045193, Gradient norm: 0.07138070
INFO:root:At the start of the epoch: mem (CPU python)=16982.29296875MB; mem (CPU total)=16781.546875MB
INFO:root:[   81] Training loss: 0.60878263, Validation loss: 0.62128969, Gradient norm: 0.06227791
INFO:root:At the start of the epoch: mem (CPU python)=17020.38671875MB; mem (CPU total)=16819.73828125MB
INFO:root:[   82] Training loss: 0.60816699, Validation loss: 0.62032513, Gradient norm: 0.06187480
INFO:root:At the start of the epoch: mem (CPU python)=17058.484375MB; mem (CPU total)=16857.890625MB
INFO:root:[   83] Training loss: 0.60810018, Validation loss: 0.62046297, Gradient norm: 0.06150771
INFO:root:At the start of the epoch: mem (CPU python)=17096.578125MB; mem (CPU total)=16895.07421875MB
INFO:root:[   84] Training loss: 0.60777098, Validation loss: 0.62082700, Gradient norm: 0.05893012
INFO:root:At the start of the epoch: mem (CPU python)=17134.67578125MB; mem (CPU total)=16933.24609375MB
INFO:root:[   85] Training loss: 0.60786279, Validation loss: 0.62049726, Gradient norm: 0.06773739
INFO:root:At the start of the epoch: mem (CPU python)=17172.7734375MB; mem (CPU total)=16971.41015625MB
INFO:root:[   86] Training loss: 0.60745167, Validation loss: 0.62031438, Gradient norm: 0.06061482
INFO:root:At the start of the epoch: mem (CPU python)=17210.8671875MB; mem (CPU total)=17009.5390625MB
INFO:root:[   87] Training loss: 0.60723043, Validation loss: 0.62169401, Gradient norm: 0.06789412
INFO:root:At the start of the epoch: mem (CPU python)=17248.96484375MB; mem (CPU total)=17047.98828125MB
INFO:root:[   88] Training loss: 0.60705707, Validation loss: 0.62030157, Gradient norm: 0.06562289
INFO:root:At the start of the epoch: mem (CPU python)=17287.05859375MB; mem (CPU total)=17085.94140625MB
INFO:root:[   89] Training loss: 0.60683885, Validation loss: 0.61953458, Gradient norm: 0.06645460
INFO:root:At the start of the epoch: mem (CPU python)=17325.15625MB; mem (CPU total)=17124.1171875MB
INFO:root:[   90] Training loss: 0.60677548, Validation loss: 0.62036565, Gradient norm: 0.07290242
INFO:root:At the start of the epoch: mem (CPU python)=17363.25MB; mem (CPU total)=17162.29296875MB
INFO:root:[   91] Training loss: 0.60643143, Validation loss: 0.62055247, Gradient norm: 0.06730865
INFO:root:At the start of the epoch: mem (CPU python)=17401.34375MB; mem (CPU total)=17200.2109375MB
INFO:root:[   92] Training loss: 0.60609664, Validation loss: 0.61936783, Gradient norm: 0.06572830
INFO:root:At the start of the epoch: mem (CPU python)=17439.4375MB; mem (CPU total)=17238.58984375MB
INFO:root:[   93] Training loss: 0.60614338, Validation loss: 0.62040493, Gradient norm: 0.06073273
INFO:root:At the start of the epoch: mem (CPU python)=17477.53515625MB; mem (CPU total)=17276.76953125MB
INFO:root:[   94] Training loss: 0.60598873, Validation loss: 0.62030946, Gradient norm: 0.07004722
INFO:root:At the start of the epoch: mem (CPU python)=17515.62890625MB; mem (CPU total)=17314.8828125MB
INFO:root:[   95] Training loss: 0.60582118, Validation loss: 0.62129680, Gradient norm: 0.06313386
INFO:root:At the start of the epoch: mem (CPU python)=17553.7265625MB; mem (CPU total)=17353.05078125MB
INFO:root:[   96] Training loss: 0.60552878, Validation loss: 0.61994021, Gradient norm: 0.06757501
INFO:root:At the start of the epoch: mem (CPU python)=17591.82421875MB; mem (CPU total)=17390.90234375MB
INFO:root:[   97] Training loss: 0.60535495, Validation loss: 0.61899524, Gradient norm: 0.06895986
INFO:root:At the start of the epoch: mem (CPU python)=17629.91796875MB; mem (CPU total)=17429.109375MB
INFO:root:[   98] Training loss: 0.60533405, Validation loss: 0.61995516, Gradient norm: 0.06476945
INFO:root:At the start of the epoch: mem (CPU python)=17668.01171875MB; mem (CPU total)=17467.27734375MB
INFO:root:[   99] Training loss: 0.60497392, Validation loss: 0.62002487, Gradient norm: 0.06091817
INFO:root:At the start of the epoch: mem (CPU python)=17706.109375MB; mem (CPU total)=17505.65625MB
INFO:root:[  100] Training loss: 0.60486725, Validation loss: 0.62051879, Gradient norm: 0.06822581
INFO:root:At the start of the epoch: mem (CPU python)=17744.203125MB; mem (CPU total)=17543.8203125MB
INFO:root:[  101] Training loss: 0.60488245, Validation loss: 0.61960327, Gradient norm: 0.07130746
INFO:root:At the start of the epoch: mem (CPU python)=17782.296875MB; mem (CPU total)=17581.61328125MB
INFO:root:[  102] Training loss: 0.60467156, Validation loss: 0.61981906, Gradient norm: 0.07511141
INFO:root:At the start of the epoch: mem (CPU python)=17820.390625MB; mem (CPU total)=17620.1484375MB
INFO:root:[  103] Training loss: 0.60430656, Validation loss: 0.61906521, Gradient norm: 0.06846790
INFO:root:At the start of the epoch: mem (CPU python)=17858.4921875MB; mem (CPU total)=17657.77734375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  104] Training loss: 0.60411033, Validation loss: 0.62009966, Gradient norm: 0.06555269
INFO:root:At the start of the epoch: mem (CPU python)=17896.5859375MB; mem (CPU total)=17695.40234375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  105] Training loss: 0.60329853, Validation loss: 0.61933315, Gradient norm: 0.05944861
INFO:root:At the start of the epoch: mem (CPU python)=17934.6796875MB; mem (CPU total)=17733.59375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  106] Training loss: 0.60302969, Validation loss: 0.62006369, Gradient norm: 0.05686652
INFO:root:At the start of the epoch: mem (CPU python)=17972.77734375MB; mem (CPU total)=17771.47265625MB
INFO:root:EP 106: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=18010.87109375MB; mem (CPU total)=17809.61328125MB
INFO:root:Training the model took 8725.97s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85854
INFO:root:EnergyScoreTrain: 0.60462
INFO:root:CRPSTrain: 0.52815
INFO:root:Gaussian NLLTrain: 2.34843
INFO:root:CoverageTrain: 0.78942
INFO:root:IntervalWidthTrain: 3.06441
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88005
INFO:root:EnergyScoreValidation: 0.6198
INFO:root:CRPSValidation: 0.54065
INFO:root:Gaussian NLLValidation: 2.38912
INFO:root:CoverageValidation: 0.78235
INFO:root:IntervalWidthValidation: 3.06087
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88103
INFO:root:EnergyScoreTest: 0.62055
INFO:root:CRPSTest: 0.54128
INFO:root:Gaussian NLLTest: 2.39321
INFO:root:CoverageTest: 0.78117
INFO:root:IntervalWidthTest: 3.05222
INFO:root:After validation: mem (CPU python)=18053.78125MB; mem (CPU total)=17852.8203125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=18053.78125MB; mem (CPU total)=17852.8515625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=18054.26171875MB; mem (CPU total)=17853.09765625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=18054.26171875MB; mem (CPU total)=17853.09765625MB
INFO:root:[    1] Training loss: 0.77825247, Validation loss: 0.72458446, Gradient norm: 0.60026027
INFO:root:At the start of the epoch: mem (CPU python)=18092.25390625MB; mem (CPU total)=17891.34765625MB
INFO:root:[    2] Training loss: 0.72248005, Validation loss: 0.72184969, Gradient norm: 0.61648935
INFO:root:At the start of the epoch: mem (CPU python)=18130.34765625MB; mem (CPU total)=17929.2734375MB
INFO:root:[    3] Training loss: 0.72024704, Validation loss: 0.71982774, Gradient norm: 0.29940018
INFO:root:At the start of the epoch: mem (CPU python)=18168.45703125MB; mem (CPU total)=17967.453125MB
INFO:root:[    4] Training loss: 0.71979006, Validation loss: 0.71959549, Gradient norm: 0.31818725
INFO:root:At the start of the epoch: mem (CPU python)=18206.57421875MB; mem (CPU total)=18005.5859375MB
INFO:root:[    5] Training loss: 0.71949634, Validation loss: 0.71941720, Gradient norm: 0.25253911
INFO:root:At the start of the epoch: mem (CPU python)=18244.6796875MB; mem (CPU total)=18044.453125MB
INFO:root:[    6] Training loss: 0.71868849, Validation loss: 0.71846985, Gradient norm: 0.28230131
INFO:root:At the start of the epoch: mem (CPU python)=18282.79296875MB; mem (CPU total)=18082.34375MB
INFO:root:[    7] Training loss: 0.71628083, Validation loss: 0.71358133, Gradient norm: 0.21941007
INFO:root:At the start of the epoch: mem (CPU python)=18320.90234375MB; mem (CPU total)=18120.46875MB
INFO:root:[    8] Training loss: 0.70808137, Validation loss: 0.70084582, Gradient norm: 0.19485174
INFO:root:At the start of the epoch: mem (CPU python)=18359.0MB; mem (CPU total)=18158.48828125MB
INFO:root:[    9] Training loss: 0.69358509, Validation loss: 0.68816278, Gradient norm: 0.19047180
INFO:root:At the start of the epoch: mem (CPU python)=18397.09375MB; mem (CPU total)=18196.6328125MB
INFO:root:[   10] Training loss: 0.68300559, Validation loss: 0.68007562, Gradient norm: 0.14253477
INFO:root:At the start of the epoch: mem (CPU python)=18435.19140625MB; mem (CPU total)=18234.80859375MB
INFO:root:[   11] Training loss: 0.67600062, Validation loss: 0.67382253, Gradient norm: 0.12145968
INFO:root:At the start of the epoch: mem (CPU python)=18473.28515625MB; mem (CPU total)=18272.9140625MB
INFO:root:[   12] Training loss: 0.67076858, Validation loss: 0.66876839, Gradient norm: 0.11001478
INFO:root:At the start of the epoch: mem (CPU python)=18511.37890625MB; mem (CPU total)=18311.56640625MB
INFO:root:[   13] Training loss: 0.66675636, Validation loss: 0.66645451, Gradient norm: 0.12782669
INFO:root:At the start of the epoch: mem (CPU python)=18549.47265625MB; mem (CPU total)=18349.56640625MB
INFO:root:[   14] Training loss: 0.66349057, Validation loss: 0.66280099, Gradient norm: 0.09482577
INFO:root:At the start of the epoch: mem (CPU python)=18587.57421875MB; mem (CPU total)=18387.45703125MB
INFO:root:[   15] Training loss: 0.66050953, Validation loss: 0.66118207, Gradient norm: 0.09956638
INFO:root:At the start of the epoch: mem (CPU python)=18625.66796875MB; mem (CPU total)=18425.4765625MB
INFO:root:[   16] Training loss: 0.65829438, Validation loss: 0.65890501, Gradient norm: 0.09961665
INFO:root:At the start of the epoch: mem (CPU python)=18663.76171875MB; mem (CPU total)=18463.8671875MB
INFO:root:[   17] Training loss: 0.65616441, Validation loss: 0.65759924, Gradient norm: 0.08067317
INFO:root:At the start of the epoch: mem (CPU python)=18701.859375MB; mem (CPU total)=18501.765625MB
INFO:root:[   18] Training loss: 0.65468459, Validation loss: 0.65576378, Gradient norm: 0.08581627
INFO:root:At the start of the epoch: mem (CPU python)=18739.953125MB; mem (CPU total)=18538.66796875MB
INFO:root:[   19] Training loss: 0.65273794, Validation loss: 0.65372872, Gradient norm: 0.09834724
INFO:root:At the start of the epoch: mem (CPU python)=18778.046875MB; mem (CPU total)=18579.296875MB
INFO:root:[   20] Training loss: 0.65126215, Validation loss: 0.65317761, Gradient norm: 0.09724047
INFO:root:At the start of the epoch: mem (CPU python)=18816.140625MB; mem (CPU total)=18617.5859375MB
INFO:root:[   21] Training loss: 0.64983977, Validation loss: 0.65166887, Gradient norm: 0.09073491
INFO:root:At the start of the epoch: mem (CPU python)=18854.2421875MB; mem (CPU total)=18655.23046875MB
INFO:root:[   22] Training loss: 0.64841738, Validation loss: 0.65042426, Gradient norm: 0.08296462
INFO:root:At the start of the epoch: mem (CPU python)=18892.3359375MB; mem (CPU total)=18692.75390625MB
INFO:root:[   23] Training loss: 0.64722089, Validation loss: 0.64904741, Gradient norm: 0.08047041
INFO:root:At the start of the epoch: mem (CPU python)=18930.4296875MB; mem (CPU total)=18733.28125MB
INFO:root:[   24] Training loss: 0.64610295, Validation loss: 0.64782235, Gradient norm: 0.08552565
INFO:root:At the start of the epoch: mem (CPU python)=18968.52734375MB; mem (CPU total)=18770.57421875MB
INFO:root:[   25] Training loss: 0.64489827, Validation loss: 0.64744962, Gradient norm: 0.06950710
INFO:root:At the start of the epoch: mem (CPU python)=19006.62109375MB; mem (CPU total)=18808.46484375MB
INFO:root:[   26] Training loss: 0.64397998, Validation loss: 0.64626920, Gradient norm: 0.09733737
INFO:root:At the start of the epoch: mem (CPU python)=19044.71484375MB; mem (CPU total)=18846.59765625MB
INFO:root:[   27] Training loss: 0.64288866, Validation loss: 0.64566588, Gradient norm: 0.08221705
INFO:root:At the start of the epoch: mem (CPU python)=19082.8125MB; mem (CPU total)=18884.9609375MB
INFO:root:[   28] Training loss: 0.64190971, Validation loss: 0.64492908, Gradient norm: 0.09113477
INFO:root:At the start of the epoch: mem (CPU python)=19120.91015625MB; mem (CPU total)=18923.09765625MB
INFO:root:[   29] Training loss: 0.64090566, Validation loss: 0.64442953, Gradient norm: 0.07631021
INFO:root:At the start of the epoch: mem (CPU python)=19159.00390625MB; mem (CPU total)=18961.3984375MB
INFO:root:[   30] Training loss: 0.63983387, Validation loss: 0.64328205, Gradient norm: 0.08652097
INFO:root:At the start of the epoch: mem (CPU python)=19197.09765625MB; mem (CPU total)=18999.5390625MB
INFO:root:[   31] Training loss: 0.63904905, Validation loss: 0.64195648, Gradient norm: 0.08701906
INFO:root:At the start of the epoch: mem (CPU python)=19235.1953125MB; mem (CPU total)=19037.65234375MB
INFO:root:[   32] Training loss: 0.63809069, Validation loss: 0.64098308, Gradient norm: 0.08168286
INFO:root:At the start of the epoch: mem (CPU python)=19273.2890625MB; mem (CPU total)=19075.53515625MB
INFO:root:[   33] Training loss: 0.63714025, Validation loss: 0.64126857, Gradient norm: 0.07606630
INFO:root:At the start of the epoch: mem (CPU python)=19311.3828125MB; mem (CPU total)=19113.91015625MB
INFO:root:[   34] Training loss: 0.63627315, Validation loss: 0.64059808, Gradient norm: 0.07267529
INFO:root:At the start of the epoch: mem (CPU python)=19349.48046875MB; mem (CPU total)=19152.45703125MB
INFO:root:[   35] Training loss: 0.63517436, Validation loss: 0.63963588, Gradient norm: 0.07236334
INFO:root:At the start of the epoch: mem (CPU python)=19387.578125MB; mem (CPU total)=19190.32421875MB
INFO:root:[   36] Training loss: 0.63466396, Validation loss: 0.63844920, Gradient norm: 0.07191291
INFO:root:At the start of the epoch: mem (CPU python)=19425.671875MB; mem (CPU total)=19228.4609375MB
INFO:root:[   37] Training loss: 0.63386041, Validation loss: 0.63814881, Gradient norm: 0.07899189
INFO:root:At the start of the epoch: mem (CPU python)=19463.765625MB; mem (CPU total)=19266.59765625MB
INFO:root:[   38] Training loss: 0.63313862, Validation loss: 0.63726895, Gradient norm: 0.07913960
INFO:root:At the start of the epoch: mem (CPU python)=19501.86328125MB; mem (CPU total)=19304.6640625MB
INFO:root:[   39] Training loss: 0.63207480, Validation loss: 0.63660611, Gradient norm: 0.06432919
INFO:root:At the start of the epoch: mem (CPU python)=19539.95703125MB; mem (CPU total)=19343.046875MB
INFO:root:[   40] Training loss: 0.63155711, Validation loss: 0.63634377, Gradient norm: 0.09061247
INFO:root:At the start of the epoch: mem (CPU python)=19578.05078125MB; mem (CPU total)=19381.1875MB
INFO:root:[   41] Training loss: 0.63053594, Validation loss: 0.63603178, Gradient norm: 0.07908717
INFO:root:At the start of the epoch: mem (CPU python)=19616.1484375MB; mem (CPU total)=19419.15625MB
INFO:root:[   42] Training loss: 0.63004013, Validation loss: 0.63524649, Gradient norm: 0.07454220
INFO:root:At the start of the epoch: mem (CPU python)=19654.2421875MB; mem (CPU total)=19457.28515625MB
INFO:root:[   43] Training loss: 0.62931902, Validation loss: 0.63488233, Gradient norm: 0.08014985
INFO:root:At the start of the epoch: mem (CPU python)=19692.3359375MB; mem (CPU total)=19495.3984375MB
INFO:root:[   44] Training loss: 0.62842500, Validation loss: 0.63506210, Gradient norm: 0.08036598
INFO:root:At the start of the epoch: mem (CPU python)=19730.43359375MB; mem (CPU total)=19533.54296875MB
INFO:root:[   45] Training loss: 0.62810597, Validation loss: 0.63366357, Gradient norm: 0.07985095
INFO:root:At the start of the epoch: mem (CPU python)=19768.53125MB; mem (CPU total)=19571.84375MB
INFO:root:[   46] Training loss: 0.62729489, Validation loss: 0.63368561, Gradient norm: 0.07999181
INFO:root:At the start of the epoch: mem (CPU python)=19807.71875MB; mem (CPU total)=19610.9921875MB
INFO:root:[   47] Training loss: 0.62690012, Validation loss: 0.63339442, Gradient norm: 0.08304019
INFO:root:At the start of the epoch: mem (CPU python)=19845.8125MB; mem (CPU total)=19649.3515625MB
INFO:root:[   48] Training loss: 0.62582587, Validation loss: 0.63273053, Gradient norm: 0.07504449
INFO:root:At the start of the epoch: mem (CPU python)=19883.91015625MB; mem (CPU total)=19687.70703125MB
INFO:root:[   49] Training loss: 0.62552237, Validation loss: 0.63177256, Gradient norm: 0.07964494
INFO:root:At the start of the epoch: mem (CPU python)=19922.00390625MB; mem (CPU total)=19725.8359375MB
INFO:root:[   50] Training loss: 0.62495349, Validation loss: 0.63119201, Gradient norm: 0.07109944
INFO:root:At the start of the epoch: mem (CPU python)=19960.09765625MB; mem (CPU total)=19763.98046875MB
INFO:root:[   51] Training loss: 0.62429173, Validation loss: 0.63106574, Gradient norm: 0.07100462
INFO:root:At the start of the epoch: mem (CPU python)=19998.1953125MB; mem (CPU total)=19802.1171875MB
INFO:root:[   52] Training loss: 0.62388231, Validation loss: 0.63191650, Gradient norm: 0.08198277
INFO:root:At the start of the epoch: mem (CPU python)=20036.29296875MB; mem (CPU total)=19840.25390625MB
INFO:root:[   53] Training loss: 0.62319490, Validation loss: 0.63026507, Gradient norm: 0.08005547
INFO:root:At the start of the epoch: mem (CPU python)=20074.38671875MB; mem (CPU total)=19878.6015625MB
INFO:root:[   54] Training loss: 0.62249048, Validation loss: 0.63076258, Gradient norm: 0.08320818
INFO:root:At the start of the epoch: mem (CPU python)=20112.48046875MB; mem (CPU total)=19917.0MB
INFO:root:[   55] Training loss: 0.62198995, Validation loss: 0.62972123, Gradient norm: 0.06829184
INFO:root:At the start of the epoch: mem (CPU python)=20150.578125MB; mem (CPU total)=19954.875MB
INFO:root:[   56] Training loss: 0.62143805, Validation loss: 0.62929153, Gradient norm: 0.07803698
INFO:root:At the start of the epoch: mem (CPU python)=20188.671875MB; mem (CPU total)=19993.05078125MB
INFO:root:[   57] Training loss: 0.62092354, Validation loss: 0.62875661, Gradient norm: 0.07706487
INFO:root:At the start of the epoch: mem (CPU python)=20226.765625MB; mem (CPU total)=20031.1953125MB
INFO:root:[   58] Training loss: 0.62044288, Validation loss: 0.62824683, Gradient norm: 0.07923228
INFO:root:At the start of the epoch: mem (CPU python)=20264.86328125MB; mem (CPU total)=20069.5859375MB
INFO:root:[   59] Training loss: 0.62024644, Validation loss: 0.62923298, Gradient norm: 0.07499989
INFO:root:At the start of the epoch: mem (CPU python)=20302.9609375MB; mem (CPU total)=20107.7265625MB
INFO:root:[   60] Training loss: 0.61954085, Validation loss: 0.62748071, Gradient norm: 0.07264135
INFO:root:At the start of the epoch: mem (CPU python)=20341.05078125MB; mem (CPU total)=20146.11328125MB
INFO:root:[   61] Training loss: 0.61913539, Validation loss: 0.62844698, Gradient norm: 0.07937056
INFO:root:At the start of the epoch: mem (CPU python)=20379.15234375MB; mem (CPU total)=20184.54296875MB
INFO:root:[   62] Training loss: 0.61894983, Validation loss: 0.62799457, Gradient norm: 0.08554571
INFO:root:At the start of the epoch: mem (CPU python)=20417.25MB; mem (CPU total)=20223.83984375MB
INFO:root:[   63] Training loss: 0.61819197, Validation loss: 0.62854751, Gradient norm: 0.07900445
INFO:root:At the start of the epoch: mem (CPU python)=20455.34375MB; mem (CPU total)=20261.484375MB
INFO:root:[   64] Training loss: 0.61785533, Validation loss: 0.62679592, Gradient norm: 0.08079410
INFO:root:At the start of the epoch: mem (CPU python)=20493.4375MB; mem (CPU total)=20299.91015625MB
INFO:root:[   65] Training loss: 0.61715076, Validation loss: 0.62752038, Gradient norm: 0.07115105
INFO:root:At the start of the epoch: mem (CPU python)=20531.53515625MB; mem (CPU total)=20337.77734375MB
INFO:root:[   66] Training loss: 0.61705159, Validation loss: 0.62585272, Gradient norm: 0.07504361
INFO:root:At the start of the epoch: mem (CPU python)=20569.62890625MB; mem (CPU total)=20376.13671875MB
INFO:root:[   67] Training loss: 0.61660107, Validation loss: 0.62654352, Gradient norm: 0.07921734
INFO:root:At the start of the epoch: mem (CPU python)=20607.72265625MB; mem (CPU total)=20414.26953125MB
INFO:root:[   68] Training loss: 0.61603117, Validation loss: 0.62648181, Gradient norm: 0.08029304
INFO:root:At the start of the epoch: mem (CPU python)=20645.82421875MB; mem (CPU total)=20452.515625MB
INFO:root:[   69] Training loss: 0.61587376, Validation loss: 0.62594390, Gradient norm: 0.08477677
INFO:root:At the start of the epoch: mem (CPU python)=20683.921875MB; mem (CPU total)=20490.68359375MB
INFO:root:[   70] Training loss: 0.61545688, Validation loss: 0.62553625, Gradient norm: 0.07528365
INFO:root:At the start of the epoch: mem (CPU python)=20722.015625MB; mem (CPU total)=20527.56640625MB
INFO:root:[   71] Training loss: 0.61499093, Validation loss: 0.62580880, Gradient norm: 0.08160020
INFO:root:At the start of the epoch: mem (CPU python)=20760.109375MB; mem (CPU total)=20565.3515625MB
INFO:root:[   72] Training loss: 0.61449974, Validation loss: 0.62457047, Gradient norm: 0.08247164
INFO:root:At the start of the epoch: mem (CPU python)=20798.20703125MB; mem (CPU total)=20603.7578125MB
INFO:root:[   73] Training loss: 0.61401842, Validation loss: 0.62557434, Gradient norm: 0.08625102
INFO:root:At the start of the epoch: mem (CPU python)=20836.30078125MB; mem (CPU total)=20641.921875MB
INFO:root:[   74] Training loss: 0.61370051, Validation loss: 0.62542417, Gradient norm: 0.07641949
INFO:root:At the start of the epoch: mem (CPU python)=20874.3984375MB; mem (CPU total)=20680.28125MB
INFO:root:[   75] Training loss: 0.61328944, Validation loss: 0.62598371, Gradient norm: 0.07416028
INFO:root:At the start of the epoch: mem (CPU python)=20912.49609375MB; mem (CPU total)=20718.6015625MB
INFO:root:[   76] Training loss: 0.61276744, Validation loss: 0.62585190, Gradient norm: 0.07923693
INFO:root:At the start of the epoch: mem (CPU python)=20950.58984375MB; mem (CPU total)=20756.58984375MB
INFO:root:[   77] Training loss: 0.61241938, Validation loss: 0.62518769, Gradient norm: 0.07738700
INFO:root:At the start of the epoch: mem (CPU python)=20988.68359375MB; mem (CPU total)=20794.71484375MB
INFO:root:[   78] Training loss: 0.61210222, Validation loss: 0.62446942, Gradient norm: 0.08182460
INFO:root:At the start of the epoch: mem (CPU python)=21026.78125MB; mem (CPU total)=20832.8359375MB
INFO:root:[   79] Training loss: 0.61153877, Validation loss: 0.62393854, Gradient norm: 0.07293878
INFO:root:At the start of the epoch: mem (CPU python)=21064.875MB; mem (CPU total)=20871.01171875MB
INFO:root:[   80] Training loss: 0.61107870, Validation loss: 0.62484699, Gradient norm: 0.07279895
INFO:root:At the start of the epoch: mem (CPU python)=21102.96875MB; mem (CPU total)=20909.15234375MB
INFO:root:[   81] Training loss: 0.61098492, Validation loss: 0.62487272, Gradient norm: 0.07597331
INFO:root:At the start of the epoch: mem (CPU python)=21141.0625MB; mem (CPU total)=20947.54296875MB
INFO:root:[   82] Training loss: 0.61063172, Validation loss: 0.62372171, Gradient norm: 0.08201789
INFO:root:At the start of the epoch: mem (CPU python)=21179.16015625MB; mem (CPU total)=20986.0234375MB
INFO:root:[   83] Training loss: 0.61063919, Validation loss: 0.62383298, Gradient norm: 0.08867448
INFO:root:At the start of the epoch: mem (CPU python)=21217.25390625MB; mem (CPU total)=21024.125MB
INFO:root:[   84] Training loss: 0.60965048, Validation loss: 0.62351389, Gradient norm: 0.06947112
INFO:root:At the start of the epoch: mem (CPU python)=21255.34765625MB; mem (CPU total)=21062.30078125MB
INFO:root:[   85] Training loss: 0.60954647, Validation loss: 0.62347734, Gradient norm: 0.07365146
INFO:root:At the start of the epoch: mem (CPU python)=21293.44921875MB; mem (CPU total)=21100.4765625MB
INFO:root:[   86] Training loss: 0.60896362, Validation loss: 0.62198358, Gradient norm: 0.07528256
INFO:root:At the start of the epoch: mem (CPU python)=21331.54296875MB; mem (CPU total)=21138.6171875MB
INFO:root:[   87] Training loss: 0.60888319, Validation loss: 0.62335240, Gradient norm: 0.07954249
INFO:root:At the start of the epoch: mem (CPU python)=21369.63671875MB; mem (CPU total)=21176.9921875MB
INFO:root:[   88] Training loss: 0.60843208, Validation loss: 0.62234553, Gradient norm: 0.07866362
INFO:root:At the start of the epoch: mem (CPU python)=21407.73046875MB; mem (CPU total)=21215.578125MB
INFO:root:[   89] Training loss: 0.60815741, Validation loss: 0.62214773, Gradient norm: 0.07759095
INFO:root:At the start of the epoch: mem (CPU python)=21445.828125MB; mem (CPU total)=21253.75390625MB
INFO:root:[   90] Training loss: 0.60769033, Validation loss: 0.62252426, Gradient norm: 0.06589500
INFO:root:At the start of the epoch: mem (CPU python)=21483.921875MB; mem (CPU total)=21293.453125MB
INFO:root:[   91] Training loss: 0.60754031, Validation loss: 0.62203381, Gradient norm: 0.08164107
INFO:root:At the start of the epoch: mem (CPU python)=21522.015625MB; mem (CPU total)=21331.6171875MB
INFO:root:[   92] Training loss: 0.60716586, Validation loss: 0.62134623, Gradient norm: 0.07810261
INFO:root:At the start of the epoch: mem (CPU python)=21560.11328125MB; mem (CPU total)=21369.80078125MB
INFO:root:[   93] Training loss: 0.60670057, Validation loss: 0.62292931, Gradient norm: 0.07075576
INFO:root:At the start of the epoch: mem (CPU python)=21598.20703125MB; mem (CPU total)=21407.734375MB
INFO:root:[   94] Training loss: 0.60684224, Validation loss: 0.62181463, Gradient norm: 0.08545937
INFO:root:At the start of the epoch: mem (CPU python)=21636.30859375MB; mem (CPU total)=21445.91015625MB
INFO:root:[   95] Training loss: 0.60624349, Validation loss: 0.62152420, Gradient norm: 0.07672670
INFO:root:At the start of the epoch: mem (CPU python)=21674.40625MB; mem (CPU total)=21484.12890625MB
INFO:root:[   96] Training loss: 0.60597930, Validation loss: 0.62169441, Gradient norm: 0.07492873
INFO:root:At the start of the epoch: mem (CPU python)=21712.5078125MB; mem (CPU total)=21522.50390625MB
INFO:root:[   97] Training loss: 0.60559600, Validation loss: 0.62128243, Gradient norm: 0.07897423
INFO:root:At the start of the epoch: mem (CPU python)=21750.6015625MB; mem (CPU total)=21561.09765625MB
INFO:root:[   98] Training loss: 0.60516825, Validation loss: 0.62086404, Gradient norm: 0.07753454
INFO:root:At the start of the epoch: mem (CPU python)=21788.6953125MB; mem (CPU total)=21598.66796875MB
INFO:root:[   99] Training loss: 0.60496330, Validation loss: 0.62037303, Gradient norm: 0.07483519
INFO:root:At the start of the epoch: mem (CPU python)=21826.79296875MB; mem (CPU total)=21636.84765625MB
INFO:root:[  100] Training loss: 0.60502652, Validation loss: 0.62162804, Gradient norm: 0.07892162
INFO:root:At the start of the epoch: mem (CPU python)=21864.88671875MB; mem (CPU total)=21674.5546875MB
INFO:root:[  101] Training loss: 0.60440152, Validation loss: 0.62184588, Gradient norm: 0.07938478
INFO:root:At the start of the epoch: mem (CPU python)=21902.98046875MB; mem (CPU total)=21712.97265625MB
INFO:root:[  102] Training loss: 0.60425161, Validation loss: 0.62174081, Gradient norm: 0.07277368
INFO:root:At the start of the epoch: mem (CPU python)=21941.078125MB; mem (CPU total)=21751.1015625MB
INFO:root:[  103] Training loss: 0.60373482, Validation loss: 0.62115607, Gradient norm: 0.07321137
INFO:root:At the start of the epoch: mem (CPU python)=21979.17578125MB; mem (CPU total)=21789.00390625MB
INFO:root:[  104] Training loss: 0.60355620, Validation loss: 0.62186635, Gradient norm: 0.07785396
INFO:root:At the start of the epoch: mem (CPU python)=22017.26953125MB; mem (CPU total)=21827.1796875MB
INFO:root:[  105] Training loss: 0.60334602, Validation loss: 0.62087416, Gradient norm: 0.08177828
INFO:root:At the start of the epoch: mem (CPU python)=22055.36328125MB; mem (CPU total)=21865.3828125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  106] Training loss: 0.60290844, Validation loss: 0.62154925, Gradient norm: 0.07343116
INFO:root:At the start of the epoch: mem (CPU python)=22093.4609375MB; mem (CPU total)=21903.5390625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  107] Training loss: 0.60171884, Validation loss: 0.61965402, Gradient norm: 0.07916808
INFO:root:At the start of the epoch: mem (CPU python)=22131.5546875MB; mem (CPU total)=21941.6796875MB
INFO:root:[  108] Training loss: 0.60062576, Validation loss: 0.62084300, Gradient norm: 0.05779248
INFO:root:At the start of the epoch: mem (CPU python)=22169.6484375MB; mem (CPU total)=21979.859375MB
INFO:root:[  109] Training loss: 0.60045869, Validation loss: 0.62040265, Gradient norm: 0.06208001
INFO:root:At the start of the epoch: mem (CPU python)=22207.74609375MB; mem (CPU total)=22017.71875MB
INFO:root:[  110] Training loss: 0.60031262, Validation loss: 0.61926717, Gradient norm: 0.06377001
INFO:root:At the start of the epoch: mem (CPU python)=22245.83984375MB; mem (CPU total)=22055.640625MB
INFO:root:[  111] Training loss: 0.60051381, Validation loss: 0.62025555, Gradient norm: 0.06229268
INFO:root:At the start of the epoch: mem (CPU python)=22283.9375MB; mem (CPU total)=22093.57421875MB
INFO:root:[  112] Training loss: 0.60005472, Validation loss: 0.62010886, Gradient norm: 0.06392130
INFO:root:At the start of the epoch: mem (CPU python)=22322.03515625MB; mem (CPU total)=22131.76953125MB
INFO:root:[  113] Training loss: 0.59998914, Validation loss: 0.61968367, Gradient norm: 0.06106381
INFO:root:At the start of the epoch: mem (CPU python)=22360.12890625MB; mem (CPU total)=22169.40625MB
INFO:root:[  114] Training loss: 0.59982642, Validation loss: 0.62030827, Gradient norm: 0.06358523
INFO:root:At the start of the epoch: mem (CPU python)=22398.22265625MB; mem (CPU total)=22207.26171875MB
INFO:root:[  115] Training loss: 0.59970813, Validation loss: 0.61964164, Gradient norm: 0.06482941
INFO:root:At the start of the epoch: mem (CPU python)=22436.31640625MB; mem (CPU total)=22245.19140625MB
INFO:root:[  116] Training loss: 0.59940610, Validation loss: 0.62027879, Gradient norm: 0.06229830
INFO:root:At the start of the epoch: mem (CPU python)=22474.4140625MB; mem (CPU total)=22283.23828125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  117] Training loss: 0.59961178, Validation loss: 0.61958802, Gradient norm: 0.06135316
INFO:root:At the start of the epoch: mem (CPU python)=22512.51171875MB; mem (CPU total)=22321.38671875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  118] Training loss: 0.59912472, Validation loss: 0.62026899, Gradient norm: 0.05785788
INFO:root:At the start of the epoch: mem (CPU python)=22550.6015625MB; mem (CPU total)=22359.76953125MB
INFO:root:[  119] Training loss: 0.59895215, Validation loss: 0.61995437, Gradient norm: 0.05843522
INFO:root:At the start of the epoch: mem (CPU python)=22588.703125MB; mem (CPU total)=22397.9140625MB
INFO:root:EP 119: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=22626.796875MB; mem (CPU total)=22435.8125MB
INFO:root:Training the model took 10427.047s.
INFO:root:Emptying the cuda cache took 0.031s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85189
INFO:root:EnergyScoreTrain: 0.6
INFO:root:CRPSTrain: 0.5163
INFO:root:Gaussian NLLTrain: 1.93327
INFO:root:CoverageTrain: 0.81828
INFO:root:IntervalWidthTrain: 3.18097
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88073
INFO:root:EnergyScoreValidation: 0.62017
INFO:root:CRPSValidation: 0.53284
INFO:root:Gaussian NLLValidation: 1.9807
INFO:root:CoverageValidation: 0.8089
INFO:root:IntervalWidthValidation: 3.17679
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88269
INFO:root:EnergyScoreTest: 0.62159
INFO:root:CRPSTest: 0.53395
INFO:root:Gaussian NLLTest: 1.97775
INFO:root:CoverageTest: 0.80849
INFO:root:IntervalWidthTest: 3.17389
INFO:root:After validation: mem (CPU python)=22669.69921875MB; mem (CPU total)=22478.15625MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=22669.69921875MB; mem (CPU total)=22478.15625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=22669.96875MB; mem (CPU total)=22478.64453125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=22670.16796875MB; mem (CPU total)=22478.3984375MB
INFO:root:[    1] Training loss: 0.78052176, Validation loss: 0.72269165, Gradient norm: 0.51497736
INFO:root:At the start of the epoch: mem (CPU python)=22708.47265625MB; mem (CPU total)=22517.15234375MB
INFO:root:[    2] Training loss: 0.72163176, Validation loss: 0.72105283, Gradient norm: 0.38795897
INFO:root:At the start of the epoch: mem (CPU python)=22746.56640625MB; mem (CPU total)=22555.11328125MB
INFO:root:[    3] Training loss: 0.72045945, Validation loss: 0.71959528, Gradient norm: 0.33900816
INFO:root:At the start of the epoch: mem (CPU python)=22784.6796875MB; mem (CPU total)=22593.50390625MB
INFO:root:[    4] Training loss: 0.71978450, Validation loss: 0.72018457, Gradient norm: 0.22022687
INFO:root:At the start of the epoch: mem (CPU python)=22822.7890625MB; mem (CPU total)=22631.88671875MB
INFO:root:[    5] Training loss: 0.71949011, Validation loss: 0.71911097, Gradient norm: 0.28196086
INFO:root:At the start of the epoch: mem (CPU python)=22860.8984375MB; mem (CPU total)=22669.99609375MB
INFO:root:[    6] Training loss: 0.71908991, Validation loss: 0.71868411, Gradient norm: 0.18204898
INFO:root:At the start of the epoch: mem (CPU python)=22899.01953125MB; mem (CPU total)=22709.4140625MB
INFO:root:[    7] Training loss: 0.71853788, Validation loss: 0.71803597, Gradient norm: 0.20619311
INFO:root:At the start of the epoch: mem (CPU python)=22937.12109375MB; mem (CPU total)=22747.55078125MB
INFO:root:[    8] Training loss: 0.71762538, Validation loss: 0.71627756, Gradient norm: 0.20290442
INFO:root:At the start of the epoch: mem (CPU python)=22975.21484375MB; mem (CPU total)=22785.26953125MB
INFO:root:[    9] Training loss: 0.71196765, Validation loss: 0.70548215, Gradient norm: 0.16316566
INFO:root:At the start of the epoch: mem (CPU python)=23013.29296875MB; mem (CPU total)=22823.44921875MB
INFO:root:[   10] Training loss: 0.69844065, Validation loss: 0.69179408, Gradient norm: 0.12125231
INFO:root:At the start of the epoch: mem (CPU python)=23051.390625MB; mem (CPU total)=22862.1171875MB
INFO:root:[   11] Training loss: 0.68648245, Validation loss: 0.68341060, Gradient norm: 0.11196878
INFO:root:At the start of the epoch: mem (CPU python)=23089.484375MB; mem (CPU total)=22900.27734375MB
INFO:root:[   12] Training loss: 0.67815061, Validation loss: 0.67580119, Gradient norm: 0.09707638
INFO:root:At the start of the epoch: mem (CPU python)=23127.578125MB; mem (CPU total)=22938.453125MB
INFO:root:[   13] Training loss: 0.67212824, Validation loss: 0.67107432, Gradient norm: 0.08334000
INFO:root:At the start of the epoch: mem (CPU python)=23165.67578125MB; mem (CPU total)=22977.19140625MB
INFO:root:[   14] Training loss: 0.66791617, Validation loss: 0.66676689, Gradient norm: 0.09054832
INFO:root:At the start of the epoch: mem (CPU python)=23203.7734375MB; mem (CPU total)=23015.28515625MB
INFO:root:[   15] Training loss: 0.66439796, Validation loss: 0.66419625, Gradient norm: 0.10512352
INFO:root:At the start of the epoch: mem (CPU python)=23241.8671875MB; mem (CPU total)=23052.64453125MB
INFO:root:[   16] Training loss: 0.66150083, Validation loss: 0.66193371, Gradient norm: 0.08563790
INFO:root:At the start of the epoch: mem (CPU python)=23279.9609375MB; mem (CPU total)=23090.29296875MB
INFO:root:[   17] Training loss: 0.65888741, Validation loss: 0.65964902, Gradient norm: 0.08758277
INFO:root:At the start of the epoch: mem (CPU python)=23318.05859375MB; mem (CPU total)=23128.53125MB
INFO:root:[   18] Training loss: 0.65685950, Validation loss: 0.65799032, Gradient norm: 0.07635744
INFO:root:At the start of the epoch: mem (CPU python)=23356.15234375MB; mem (CPU total)=23166.6640625MB
INFO:root:[   19] Training loss: 0.65499021, Validation loss: 0.65644440, Gradient norm: 0.06550075
INFO:root:At the start of the epoch: mem (CPU python)=23394.24609375MB; mem (CPU total)=23204.80859375MB
INFO:root:[   20] Training loss: 0.65317988, Validation loss: 0.65508248, Gradient norm: 0.08457169
INFO:root:At the start of the epoch: mem (CPU python)=23432.34375MB; mem (CPU total)=23243.25390625MB
INFO:root:[   21] Training loss: 0.65165624, Validation loss: 0.65316573, Gradient norm: 0.07907116
INFO:root:At the start of the epoch: mem (CPU python)=23470.4375MB; mem (CPU total)=23281.6328125MB
INFO:root:[   22] Training loss: 0.65011973, Validation loss: 0.65202562, Gradient norm: 0.07830149
INFO:root:At the start of the epoch: mem (CPU python)=23508.53125MB; mem (CPU total)=23319.69921875MB
INFO:root:[   23] Training loss: 0.64880110, Validation loss: 0.65120517, Gradient norm: 0.07425878
INFO:root:At the start of the epoch: mem (CPU python)=23546.625MB; mem (CPU total)=23357.59375MB
INFO:root:[   24] Training loss: 0.64732641, Validation loss: 0.65024529, Gradient norm: 0.07714486
INFO:root:At the start of the epoch: mem (CPU python)=23584.72265625MB; mem (CPU total)=23395.97265625MB
INFO:root:[   25] Training loss: 0.64610147, Validation loss: 0.64848228, Gradient norm: 0.07262573
INFO:root:At the start of the epoch: mem (CPU python)=23622.8203125MB; mem (CPU total)=23434.109375MB
INFO:root:[   26] Training loss: 0.64522234, Validation loss: 0.64776228, Gradient norm: 0.06761712
INFO:root:At the start of the epoch: mem (CPU python)=23660.9140625MB; mem (CPU total)=23472.45703125MB
INFO:root:[   27] Training loss: 0.64378941, Validation loss: 0.64631835, Gradient norm: 0.08115741
INFO:root:At the start of the epoch: mem (CPU python)=23699.01171875MB; mem (CPU total)=23510.6015625MB
INFO:root:[   28] Training loss: 0.64254368, Validation loss: 0.64590880, Gradient norm: 0.06124450
INFO:root:At the start of the epoch: mem (CPU python)=23737.10546875MB; mem (CPU total)=23548.74609375MB
INFO:root:[   29] Training loss: 0.64163774, Validation loss: 0.64409439, Gradient norm: 0.07200750
INFO:root:At the start of the epoch: mem (CPU python)=23775.19921875MB; mem (CPU total)=23586.67578125MB
INFO:root:[   30] Training loss: 0.64045019, Validation loss: 0.64392833, Gradient norm: 0.06861962
INFO:root:At the start of the epoch: mem (CPU python)=23813.296875MB; mem (CPU total)=23625.3125MB
INFO:root:[   31] Training loss: 0.63957631, Validation loss: 0.64397128, Gradient norm: 0.07226571
INFO:root:At the start of the epoch: mem (CPU python)=23851.390625MB; mem (CPU total)=23663.453125MB
INFO:root:[   32] Training loss: 0.63866982, Validation loss: 0.64259680, Gradient norm: 0.06768472
INFO:root:At the start of the epoch: mem (CPU python)=23889.48828125MB; mem (CPU total)=23700.83984375MB
INFO:root:[   33] Training loss: 0.63769229, Validation loss: 0.64171690, Gradient norm: 0.07947250
INFO:root:At the start of the epoch: mem (CPU python)=23927.58203125MB; mem (CPU total)=23738.4140625MB
INFO:root:[   34] Training loss: 0.63666353, Validation loss: 0.64084066, Gradient norm: 0.06876162
INFO:root:At the start of the epoch: mem (CPU python)=23965.6796875MB; mem (CPU total)=23776.6796875MB
INFO:root:[   35] Training loss: 0.63582620, Validation loss: 0.64035859, Gradient norm: 0.07211537
INFO:root:At the start of the epoch: mem (CPU python)=24003.7734375MB; mem (CPU total)=23816.4296875MB
INFO:root:[   36] Training loss: 0.63488682, Validation loss: 0.63954876, Gradient norm: 0.07209078
INFO:root:At the start of the epoch: mem (CPU python)=24041.8671875MB; mem (CPU total)=23854.421875MB
INFO:root:[   37] Training loss: 0.63428992, Validation loss: 0.63903380, Gradient norm: 0.07321361
INFO:root:At the start of the epoch: mem (CPU python)=24079.96484375MB; mem (CPU total)=23892.73828125MB
INFO:root:[   38] Training loss: 0.63347555, Validation loss: 0.63840160, Gradient norm: 0.06603865
INFO:root:At the start of the epoch: mem (CPU python)=24118.05859375MB; mem (CPU total)=23930.90625MB
INFO:root:[   39] Training loss: 0.63248372, Validation loss: 0.63762821, Gradient norm: 0.07641893
INFO:root:At the start of the epoch: mem (CPU python)=24156.15234375MB; mem (CPU total)=23969.12109375MB
INFO:root:[   40] Training loss: 0.63186895, Validation loss: 0.63632014, Gradient norm: 0.06159197
INFO:root:At the start of the epoch: mem (CPU python)=24194.25MB; mem (CPU total)=24006.96875MB
INFO:root:[   41] Training loss: 0.63099199, Validation loss: 0.63642079, Gradient norm: 0.07057149
INFO:root:At the start of the epoch: mem (CPU python)=24232.3515625MB; mem (CPU total)=24045.38671875MB
INFO:root:[   42] Training loss: 0.63034507, Validation loss: 0.63599145, Gradient norm: 0.06704113
INFO:root:At the start of the epoch: mem (CPU python)=24270.4453125MB; mem (CPU total)=24083.3203125MB
INFO:root:[   43] Training loss: 0.62965369, Validation loss: 0.63473465, Gradient norm: 0.06517137
INFO:root:At the start of the epoch: mem (CPU python)=24308.5390625MB; mem (CPU total)=24121.25MB
INFO:root:[   44] Training loss: 0.62893918, Validation loss: 0.63478511, Gradient norm: 0.06699769
INFO:root:At the start of the epoch: mem (CPU python)=24346.63671875MB; mem (CPU total)=24159.3671875MB
INFO:root:[   45] Training loss: 0.62824354, Validation loss: 0.63428015, Gradient norm: 0.06680360
INFO:root:At the start of the epoch: mem (CPU python)=24384.73046875MB; mem (CPU total)=24197.015625MB
INFO:root:[   46] Training loss: 0.62759253, Validation loss: 0.63339937, Gradient norm: 0.07476896
INFO:root:At the start of the epoch: mem (CPU python)=24422.82421875MB; mem (CPU total)=24234.71875MB
INFO:root:[   47] Training loss: 0.62670397, Validation loss: 0.63210076, Gradient norm: 0.06791662
INFO:root:At the start of the epoch: mem (CPU python)=24460.921875MB; mem (CPU total)=24272.85546875MB
INFO:root:[   48] Training loss: 0.62629500, Validation loss: 0.63261207, Gradient norm: 0.07568546
INFO:root:At the start of the epoch: mem (CPU python)=24499.015625MB; mem (CPU total)=24310.75390625MB
INFO:root:[   49] Training loss: 0.62543432, Validation loss: 0.63122203, Gradient norm: 0.06466347
INFO:root:At the start of the epoch: mem (CPU python)=24537.11328125MB; mem (CPU total)=24349.14453125MB
INFO:root:[   50] Training loss: 0.62522102, Validation loss: 0.63188600, Gradient norm: 0.06915566
INFO:root:At the start of the epoch: mem (CPU python)=24575.20703125MB; mem (CPU total)=24387.2890625MB
INFO:root:[   51] Training loss: 0.62457210, Validation loss: 0.63163675, Gradient norm: 0.06392508
INFO:root:At the start of the epoch: mem (CPU python)=24613.3046875MB; mem (CPU total)=24425.41796875MB
INFO:root:[   52] Training loss: 0.62395949, Validation loss: 0.63087239, Gradient norm: 0.07400316
INFO:root:At the start of the epoch: mem (CPU python)=24651.3984375MB; mem (CPU total)=24463.80859375MB
INFO:root:[   53] Training loss: 0.62346573, Validation loss: 0.63113241, Gradient norm: 0.06908132
INFO:root:At the start of the epoch: mem (CPU python)=24689.4921875MB; mem (CPU total)=24501.37890625MB
INFO:root:[   54] Training loss: 0.62279643, Validation loss: 0.63057621, Gradient norm: 0.06550749
INFO:root:At the start of the epoch: mem (CPU python)=24727.58984375MB; mem (CPU total)=24539.515625MB
INFO:root:[   55] Training loss: 0.62229482, Validation loss: 0.63008011, Gradient norm: 0.06763730
INFO:root:At the start of the epoch: mem (CPU python)=24765.68359375MB; mem (CPU total)=24577.90625MB
INFO:root:[   56] Training loss: 0.62148520, Validation loss: 0.62950911, Gradient norm: 0.07029686
INFO:root:At the start of the epoch: mem (CPU python)=24803.78125MB; mem (CPU total)=24616.078125MB
INFO:root:[   57] Training loss: 0.62106377, Validation loss: 0.62865590, Gradient norm: 0.06533814
INFO:root:At the start of the epoch: mem (CPU python)=24841.875MB; mem (CPU total)=24654.4609375MB
INFO:root:[   58] Training loss: 0.62047029, Validation loss: 0.62910624, Gradient norm: 0.07124087
INFO:root:At the start of the epoch: mem (CPU python)=24879.97265625MB; mem (CPU total)=24692.58984375MB
INFO:root:[   59] Training loss: 0.61987651, Validation loss: 0.62885080, Gradient norm: 0.06502960
INFO:root:At the start of the epoch: mem (CPU python)=24918.06640625MB; mem (CPU total)=24730.3828125MB
INFO:root:[   60] Training loss: 0.61945612, Validation loss: 0.62755375, Gradient norm: 0.06245334
INFO:root:At the start of the epoch: mem (CPU python)=24956.16015625MB; mem (CPU total)=24768.7578125MB
INFO:root:[   61] Training loss: 0.61899059, Validation loss: 0.62714933, Gradient norm: 0.06502726
INFO:root:At the start of the epoch: mem (CPU python)=24994.2578125MB; mem (CPU total)=24808.046875MB
INFO:root:[   62] Training loss: 0.61821504, Validation loss: 0.62724158, Gradient norm: 0.06926933
INFO:root:At the start of the epoch: mem (CPU python)=25032.3515625MB; mem (CPU total)=24848.31640625MB
INFO:root:[   63] Training loss: 0.61810789, Validation loss: 0.62855734, Gradient norm: 0.07299247
INFO:root:At the start of the epoch: mem (CPU python)=25070.4453125MB; mem (CPU total)=24884.4140625MB
INFO:root:[   64] Training loss: 0.61710798, Validation loss: 0.62659091, Gradient norm: 0.06643125
INFO:root:At the start of the epoch: mem (CPU python)=25108.54296875MB; mem (CPU total)=24922.0234375MB
INFO:root:[   65] Training loss: 0.61711616, Validation loss: 0.62627185, Gradient norm: 0.06710422
INFO:root:At the start of the epoch: mem (CPU python)=25146.640625MB; mem (CPU total)=24960.1953125MB
INFO:root:[   66] Training loss: 0.61637756, Validation loss: 0.62576631, Gradient norm: 0.06788623
INFO:root:At the start of the epoch: mem (CPU python)=25184.734375MB; mem (CPU total)=24998.82421875MB
INFO:root:[   67] Training loss: 0.61586253, Validation loss: 0.62612762, Gradient norm: 0.06583293
INFO:root:At the start of the epoch: mem (CPU python)=25222.828125MB; mem (CPU total)=25036.4609375MB
INFO:root:[   68] Training loss: 0.61539743, Validation loss: 0.62524693, Gradient norm: 0.06795233
INFO:root:At the start of the epoch: mem (CPU python)=25260.92578125MB; mem (CPU total)=25074.8515625MB
INFO:root:[   69] Training loss: 0.61511897, Validation loss: 0.62485330, Gradient norm: 0.06807294
INFO:root:At the start of the epoch: mem (CPU python)=25299.01953125MB; mem (CPU total)=25112.99609375MB
INFO:root:[   70] Training loss: 0.61445659, Validation loss: 0.62490084, Gradient norm: 0.06554919
INFO:root:At the start of the epoch: mem (CPU python)=25337.11328125MB; mem (CPU total)=25150.890625MB
INFO:root:[   71] Training loss: 0.61400474, Validation loss: 0.62495147, Gradient norm: 0.06934902
INFO:root:At the start of the epoch: mem (CPU python)=25375.21484375MB; mem (CPU total)=25189.03515625MB
INFO:root:[   72] Training loss: 0.61372385, Validation loss: 0.62455968, Gradient norm: 0.06787970
INFO:root:At the start of the epoch: mem (CPU python)=25413.3125MB; mem (CPU total)=25227.328125MB
INFO:root:[   73] Training loss: 0.61319707, Validation loss: 0.62493406, Gradient norm: 0.07292729
INFO:root:At the start of the epoch: mem (CPU python)=25451.40234375MB; mem (CPU total)=25266.24609375MB
INFO:root:[   74] Training loss: 0.61254434, Validation loss: 0.62422673, Gradient norm: 0.06296831
INFO:root:At the start of the epoch: mem (CPU python)=25489.49609375MB; mem (CPU total)=25304.375MB
INFO:root:[   75] Training loss: 0.61239303, Validation loss: 0.62347644, Gradient norm: 0.06662577
INFO:root:At the start of the epoch: mem (CPU python)=25527.59765625MB; mem (CPU total)=25342.765625MB
INFO:root:[   76] Training loss: 0.61211438, Validation loss: 0.62413050, Gradient norm: 0.07393193
INFO:root:At the start of the epoch: mem (CPU python)=25565.69140625MB; mem (CPU total)=25380.6328125MB
INFO:root:[   77] Training loss: 0.61162091, Validation loss: 0.62373312, Gradient norm: 0.06510217
INFO:root:At the start of the epoch: mem (CPU python)=25603.78515625MB; mem (CPU total)=25419.01953125MB
INFO:root:[   78] Training loss: 0.61119471, Validation loss: 0.62243086, Gradient norm: 0.06934127
INFO:root:At the start of the epoch: mem (CPU python)=25641.8828125MB; mem (CPU total)=25457.16015625MB
INFO:root:[   79] Training loss: 0.61056726, Validation loss: 0.62314076, Gradient norm: 0.06616330
INFO:root:At the start of the epoch: mem (CPU python)=25679.9765625MB; mem (CPU total)=25494.6796875MB
INFO:root:[   80] Training loss: 0.61028999, Validation loss: 0.62353982, Gradient norm: 0.06792733
INFO:root:At the start of the epoch: mem (CPU python)=25718.0703125MB; mem (CPU total)=25533.05078125MB
INFO:root:[   81] Training loss: 0.60999943, Validation loss: 0.62202335, Gradient norm: 0.06752935
INFO:root:At the start of the epoch: mem (CPU python)=25756.16796875MB; mem (CPU total)=25571.47265625MB
INFO:root:[   82] Training loss: 0.60960970, Validation loss: 0.62295113, Gradient norm: 0.07384358
INFO:root:At the start of the epoch: mem (CPU python)=25794.26171875MB; mem (CPU total)=25609.6171875MB
INFO:root:[   83] Training loss: 0.60913297, Validation loss: 0.62221595, Gradient norm: 0.07218294
INFO:root:At the start of the epoch: mem (CPU python)=25832.359375MB; mem (CPU total)=25647.76171875MB
INFO:root:[   84] Training loss: 0.60864039, Validation loss: 0.62219353, Gradient norm: 0.06634207
INFO:root:At the start of the epoch: mem (CPU python)=25870.453125MB; mem (CPU total)=25685.66015625MB
INFO:root:[   85] Training loss: 0.60834620, Validation loss: 0.62231361, Gradient norm: 0.07147949
INFO:root:At the start of the epoch: mem (CPU python)=25908.55078125MB; mem (CPU total)=25723.72265625MB
INFO:root:[   86] Training loss: 0.60805734, Validation loss: 0.62192439, Gradient norm: 0.07279662
INFO:root:At the start of the epoch: mem (CPU python)=25946.64453125MB; mem (CPU total)=25762.10546875MB
INFO:root:[   87] Training loss: 0.60760507, Validation loss: 0.62245121, Gradient norm: 0.07019181
INFO:root:At the start of the epoch: mem (CPU python)=25984.73828125MB; mem (CPU total)=25800.49609375MB
INFO:root:[   88] Training loss: 0.60721408, Validation loss: 0.62207980, Gradient norm: 0.07103704
INFO:root:At the start of the epoch: mem (CPU python)=26022.8359375MB; mem (CPU total)=25838.640625MB
INFO:root:[   89] Training loss: 0.60661900, Validation loss: 0.62229611, Gradient norm: 0.06627632
INFO:root:At the start of the epoch: mem (CPU python)=26060.9296875MB; mem (CPU total)=25876.5390625MB
INFO:root:[   90] Training loss: 0.60627631, Validation loss: 0.62161667, Gradient norm: 0.07376628
INFO:root:At the start of the epoch: mem (CPU python)=26099.02734375MB; mem (CPU total)=25914.41015625MB
INFO:root:[   91] Training loss: 0.60595038, Validation loss: 0.62198352, Gradient norm: 0.06916398
INFO:root:At the start of the epoch: mem (CPU python)=26137.125MB; mem (CPU total)=25952.83203125MB
INFO:root:[   92] Training loss: 0.60563650, Validation loss: 0.62191293, Gradient norm: 0.07217273
INFO:root:At the start of the epoch: mem (CPU python)=26175.22265625MB; mem (CPU total)=25991.20703125MB
INFO:root:[   93] Training loss: 0.60516946, Validation loss: 0.62211803, Gradient norm: 0.06609379
INFO:root:At the start of the epoch: mem (CPU python)=26213.31640625MB; mem (CPU total)=26030.3125MB
INFO:root:[   94] Training loss: 0.60512751, Validation loss: 0.62169250, Gradient norm: 0.07289882
INFO:root:At the start of the epoch: mem (CPU python)=26251.41015625MB; mem (CPU total)=26067.96484375MB
INFO:root:[   95] Training loss: 0.60456579, Validation loss: 0.62255309, Gradient norm: 0.07119310
INFO:root:At the start of the epoch: mem (CPU python)=26289.5078125MB; mem (CPU total)=26105.6328125MB
INFO:root:[   96] Training loss: 0.60414424, Validation loss: 0.62164705, Gradient norm: 0.06464011
INFO:root:At the start of the epoch: mem (CPU python)=26327.6015625MB; mem (CPU total)=26143.24609375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   97] Training loss: 0.60384170, Validation loss: 0.62050985, Gradient norm: 0.06548748
INFO:root:At the start of the epoch: mem (CPU python)=26365.6953125MB; mem (CPU total)=26181.16015625MB
INFO:root:[   98] Training loss: 0.60233130, Validation loss: 0.62013269, Gradient norm: 0.06242561
INFO:root:At the start of the epoch: mem (CPU python)=26403.7890625MB; mem (CPU total)=26219.828125MB
INFO:root:[   99] Training loss: 0.60223051, Validation loss: 0.62068500, Gradient norm: 0.06072352
INFO:root:At the start of the epoch: mem (CPU python)=26441.890625MB; mem (CPU total)=26257.71875MB
INFO:root:[  100] Training loss: 0.60173995, Validation loss: 0.62008000, Gradient norm: 0.06170692
INFO:root:At the start of the epoch: mem (CPU python)=26479.984375MB; mem (CPU total)=26296.046875MB
INFO:root:[  101] Training loss: 0.60182316, Validation loss: 0.62001418, Gradient norm: 0.05737093
INFO:root:At the start of the epoch: mem (CPU python)=26518.078125MB; mem (CPU total)=26334.40625MB
INFO:root:[  102] Training loss: 0.60132081, Validation loss: 0.62108471, Gradient norm: 0.06386622
INFO:root:At the start of the epoch: mem (CPU python)=26556.17578125MB; mem (CPU total)=26372.53125MB
INFO:root:[  103] Training loss: 0.60122242, Validation loss: 0.62101748, Gradient norm: 0.05780128
INFO:root:At the start of the epoch: mem (CPU python)=26594.26953125MB; mem (CPU total)=26410.6640625MB
INFO:root:[  104] Training loss: 0.60089045, Validation loss: 0.62023918, Gradient norm: 0.05865590
INFO:root:At the start of the epoch: mem (CPU python)=26632.36328125MB; mem (CPU total)=26448.5703125MB
INFO:root:[  105] Training loss: 0.60088177, Validation loss: 0.62070278, Gradient norm: 0.06217144
INFO:root:At the start of the epoch: mem (CPU python)=26670.4609375MB; mem (CPU total)=26486.703125MB
INFO:root:[  106] Training loss: 0.60073329, Validation loss: 0.61978193, Gradient norm: 0.06385744
INFO:root:At the start of the epoch: mem (CPU python)=26708.5546875MB; mem (CPU total)=26525.09375MB
INFO:root:[  107] Training loss: 0.60076868, Validation loss: 0.61993824, Gradient norm: 0.06262344
INFO:root:At the start of the epoch: mem (CPU python)=26746.6484375MB; mem (CPU total)=26563.4609375MB
INFO:root:[  108] Training loss: 0.60021299, Validation loss: 0.62012414, Gradient norm: 0.06115023
INFO:root:At the start of the epoch: mem (CPU python)=26784.7421875MB; mem (CPU total)=26601.59765625MB
INFO:root:[  109] Training loss: 0.60009946, Validation loss: 0.62051966, Gradient norm: 0.06622650
INFO:root:At the start of the epoch: mem (CPU python)=26822.84375MB; mem (CPU total)=26639.48828125MB
INFO:root:[  110] Training loss: 0.59996719, Validation loss: 0.61944991, Gradient norm: 0.06333038
INFO:root:At the start of the epoch: mem (CPU python)=26860.9375MB; mem (CPU total)=26677.66015625MB
INFO:root:[  111] Training loss: 0.59971353, Validation loss: 0.62073724, Gradient norm: 0.06146090
INFO:root:At the start of the epoch: mem (CPU python)=26899.03125MB; mem (CPU total)=26715.796875MB
INFO:root:[  112] Training loss: 0.59989727, Validation loss: 0.62055576, Gradient norm: 0.06261945
INFO:root:At the start of the epoch: mem (CPU python)=26937.12890625MB; mem (CPU total)=26754.38671875MB
INFO:root:[  113] Training loss: 0.59933788, Validation loss: 0.62014921, Gradient norm: 0.06421716
INFO:root:At the start of the epoch: mem (CPU python)=26975.2265625MB; mem (CPU total)=26792.5MB
INFO:root:[  114] Training loss: 0.59917261, Validation loss: 0.62148199, Gradient norm: 0.06343114
INFO:root:At the start of the epoch: mem (CPU python)=27013.3203125MB; mem (CPU total)=26830.62890625MB
INFO:root:[  115] Training loss: 0.59913262, Validation loss: 0.61996358, Gradient norm: 0.06287293
INFO:root:At the start of the epoch: mem (CPU python)=27051.41796875MB; mem (CPU total)=26868.765625MB
INFO:root:[  116] Training loss: 0.59861609, Validation loss: 0.61967583, Gradient norm: 0.06495462
INFO:root:At the start of the epoch: mem (CPU python)=27089.515625MB; mem (CPU total)=26906.8984375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  117] Training loss: 0.59837701, Validation loss: 0.61997318, Gradient norm: 0.06104568
INFO:root:At the start of the epoch: mem (CPU python)=27127.609375MB; mem (CPU total)=26944.8125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  118] Training loss: 0.59797335, Validation loss: 0.62015126, Gradient norm: 0.05946539
INFO:root:At the start of the epoch: mem (CPU python)=27165.703125MB; mem (CPU total)=26982.9375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  119] Training loss: 0.59747432, Validation loss: 0.62126268, Gradient norm: 0.05589372
INFO:root:At the start of the epoch: mem (CPU python)=27203.80078125MB; mem (CPU total)=27020.9765625MB
INFO:root:EP 119: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=27241.89453125MB; mem (CPU total)=27059.3671875MB
INFO:root:Training the model took 11070.095s.
INFO:root:Emptying the cuda cache took 0.02s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85043
INFO:root:EnergyScoreTrain: 0.59899
INFO:root:CRPSTrain: 0.52067
INFO:root:Gaussian NLLTrain: 2.51393
INFO:root:CoverageTrain: 0.80397
INFO:root:IntervalWidthTrain: 3.13256
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88117
INFO:root:EnergyScoreValidation: 0.62044
INFO:root:CRPSValidation: 0.53825
INFO:root:Gaussian NLLValidation: 2.56856
INFO:root:CoverageValidation: 0.79364
INFO:root:IntervalWidthValidation: 3.12189
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88136
INFO:root:EnergyScoreTest: 0.62073
INFO:root:CRPSTest: 0.53858
INFO:root:Gaussian NLLTest: 2.56114
INFO:root:CoverageTest: 0.79334
INFO:root:IntervalWidthTest: 3.12331
INFO:root:After validation: mem (CPU python)=27284.7578125MB; mem (CPU total)=27101.9296875MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=27284.7578125MB; mem (CPU total)=27101.92578125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=27284.9609375MB; mem (CPU total)=27101.92578125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=27285.21484375MB; mem (CPU total)=27102.19140625MB
INFO:root:[    1] Training loss: 0.78415032, Validation loss: 0.72373371, Gradient norm: 0.70635871
INFO:root:At the start of the epoch: mem (CPU python)=27323.29296875MB; mem (CPU total)=27140.63671875MB
INFO:root:[    2] Training loss: 0.72217977, Validation loss: 0.72087604, Gradient norm: 0.41550854
INFO:root:At the start of the epoch: mem (CPU python)=27361.390625MB; mem (CPU total)=27179.05859375MB
INFO:root:[    3] Training loss: 0.72021777, Validation loss: 0.72015601, Gradient norm: 0.25175425
INFO:root:At the start of the epoch: mem (CPU python)=27399.50390625MB; mem (CPU total)=27217.03515625MB
INFO:root:[    4] Training loss: 0.71988409, Validation loss: 0.71946314, Gradient norm: 0.26685968
INFO:root:At the start of the epoch: mem (CPU python)=27437.61328125MB; mem (CPU total)=27255.1796875MB
INFO:root:[    5] Training loss: 0.71968808, Validation loss: 0.71920287, Gradient norm: 0.33628437
INFO:root:At the start of the epoch: mem (CPU python)=27475.7265625MB; mem (CPU total)=27293.28125MB
INFO:root:[    6] Training loss: 0.71893390, Validation loss: 0.71871364, Gradient norm: 0.23588444
INFO:root:At the start of the epoch: mem (CPU python)=27513.8203125MB; mem (CPU total)=27331.7578125MB
INFO:root:[    7] Training loss: 0.71768162, Validation loss: 0.71712822, Gradient norm: 0.18979050
INFO:root:At the start of the epoch: mem (CPU python)=27551.91796875MB; mem (CPU total)=27370.4140625MB
INFO:root:[    8] Training loss: 0.71283678, Validation loss: 0.70758019, Gradient norm: 0.24897610
INFO:root:At the start of the epoch: mem (CPU python)=27590.01171875MB; mem (CPU total)=27409.99609375MB
INFO:root:[    9] Training loss: 0.70011333, Validation loss: 0.69290497, Gradient norm: 0.17823952
INFO:root:At the start of the epoch: mem (CPU python)=27628.10546875MB; mem (CPU total)=27447.6171875MB
INFO:root:[   10] Training loss: 0.68694051, Validation loss: 0.68205205, Gradient norm: 0.17998975
INFO:root:At the start of the epoch: mem (CPU python)=27666.203125MB; mem (CPU total)=27486.09765625MB
INFO:root:[   11] Training loss: 0.67812204, Validation loss: 0.67528120, Gradient norm: 0.08396296
INFO:root:At the start of the epoch: mem (CPU python)=27704.296875MB; mem (CPU total)=27524.3125MB
INFO:root:[   12] Training loss: 0.67212463, Validation loss: 0.67029135, Gradient norm: 0.09149399
INFO:root:At the start of the epoch: mem (CPU python)=27742.390625MB; mem (CPU total)=27562.7421875MB
INFO:root:[   13] Training loss: 0.66788345, Validation loss: 0.66729501, Gradient norm: 0.10014006
INFO:root:At the start of the epoch: mem (CPU python)=27780.48828125MB; mem (CPU total)=27600.66015625MB
INFO:root:[   14] Training loss: 0.66457731, Validation loss: 0.66477137, Gradient norm: 0.07622756
INFO:root:At the start of the epoch: mem (CPU python)=27818.58203125MB; mem (CPU total)=27639.25MB
INFO:root:[   15] Training loss: 0.66203490, Validation loss: 0.66196838, Gradient norm: 0.08858380
INFO:root:At the start of the epoch: mem (CPU python)=27856.6796875MB; mem (CPU total)=27677.33984375MB
INFO:root:[   16] Training loss: 0.65962475, Validation loss: 0.65923726, Gradient norm: 0.07119269
INFO:root:At the start of the epoch: mem (CPU python)=27894.7734375MB; mem (CPU total)=27715.20703125MB
INFO:root:[   17] Training loss: 0.65763006, Validation loss: 0.65849665, Gradient norm: 0.09117941
INFO:root:At the start of the epoch: mem (CPU python)=27932.87890625MB; mem (CPU total)=27753.27734375MB
INFO:root:[   18] Training loss: 0.65594682, Validation loss: 0.65775246, Gradient norm: 0.08878329
INFO:root:At the start of the epoch: mem (CPU python)=27971.47265625MB; mem (CPU total)=27791.921875MB
INFO:root:[   19] Training loss: 0.65427275, Validation loss: 0.65534355, Gradient norm: 0.07375513
INFO:root:At the start of the epoch: mem (CPU python)=28009.56640625MB; mem (CPU total)=27829.609375MB
INFO:root:[   20] Training loss: 0.65280243, Validation loss: 0.65407072, Gradient norm: 0.07130380
INFO:root:At the start of the epoch: mem (CPU python)=28047.6640625MB; mem (CPU total)=27866.66015625MB
INFO:root:[   21] Training loss: 0.65160181, Validation loss: 0.65379011, Gradient norm: 0.08125680
INFO:root:At the start of the epoch: mem (CPU python)=28085.7578125MB; mem (CPU total)=27905.046875MB
INFO:root:[   22] Training loss: 0.65033478, Validation loss: 0.65226491, Gradient norm: 0.07089961
INFO:root:At the start of the epoch: mem (CPU python)=28123.8515625MB; mem (CPU total)=27942.6640625MB
INFO:root:[   23] Training loss: 0.64897315, Validation loss: 0.65039148, Gradient norm: 0.06488143
INFO:root:At the start of the epoch: mem (CPU python)=28161.953125MB; mem (CPU total)=27980.80859375MB
INFO:root:[   24] Training loss: 0.64812419, Validation loss: 0.65021184, Gradient norm: 0.08862400
INFO:root:At the start of the epoch: mem (CPU python)=28200.046875MB; mem (CPU total)=28019.19140625MB
INFO:root:[   25] Training loss: 0.64678786, Validation loss: 0.64898991, Gradient norm: 0.06850323
INFO:root:At the start of the epoch: mem (CPU python)=28238.140625MB; mem (CPU total)=28057.50390625MB
INFO:root:[   26] Training loss: 0.64598713, Validation loss: 0.64847584, Gradient norm: 0.07137117
INFO:root:At the start of the epoch: mem (CPU python)=28276.234375MB; mem (CPU total)=28096.44921875MB
INFO:root:[   27] Training loss: 0.64482388, Validation loss: 0.64734340, Gradient norm: 0.07195020
INFO:root:At the start of the epoch: mem (CPU python)=28314.33203125MB; mem (CPU total)=28134.03515625MB
INFO:root:[   28] Training loss: 0.64379733, Validation loss: 0.64675059, Gradient norm: 0.07459044
INFO:root:At the start of the epoch: mem (CPU python)=28352.42578125MB; mem (CPU total)=28172.16796875MB
INFO:root:[   29] Training loss: 0.64285219, Validation loss: 0.64647257, Gradient norm: 0.07661002
INFO:root:At the start of the epoch: mem (CPU python)=28390.51953125MB; mem (CPU total)=28210.3125MB
INFO:root:[   30] Training loss: 0.64181895, Validation loss: 0.64498987, Gradient norm: 0.07345431
INFO:root:At the start of the epoch: mem (CPU python)=28428.62109375MB; mem (CPU total)=28248.421875MB
INFO:root:[   31] Training loss: 0.64098103, Validation loss: 0.64500393, Gradient norm: 0.07226486
INFO:root:At the start of the epoch: mem (CPU python)=28466.71484375MB; mem (CPU total)=28286.8046875MB
INFO:root:[   32] Training loss: 0.64009705, Validation loss: 0.64343984, Gradient norm: 0.07214802
INFO:root:At the start of the epoch: mem (CPU python)=28504.80859375MB; mem (CPU total)=28325.1953125MB
INFO:root:[   33] Training loss: 0.63906808, Validation loss: 0.64281944, Gradient norm: 0.06863328
INFO:root:At the start of the epoch: mem (CPU python)=28542.90234375MB; mem (CPU total)=28363.33203125MB
INFO:root:[   34] Training loss: 0.63839024, Validation loss: 0.64236877, Gradient norm: 0.07352664
INFO:root:At the start of the epoch: mem (CPU python)=28581.00390625MB; mem (CPU total)=28401.46875MB
INFO:root:[   35] Training loss: 0.63760495, Validation loss: 0.64161491, Gradient norm: 0.07492485
INFO:root:At the start of the epoch: mem (CPU python)=28619.09765625MB; mem (CPU total)=28439.46875MB
INFO:root:[   36] Training loss: 0.63678056, Validation loss: 0.64096221, Gradient norm: 0.07922359
INFO:root:At the start of the epoch: mem (CPU python)=28657.19140625MB; mem (CPU total)=28478.4765625MB
INFO:root:[   37] Training loss: 0.63593422, Validation loss: 0.64110076, Gradient norm: 0.07115047
INFO:root:At the start of the epoch: mem (CPU python)=28695.29296875MB; mem (CPU total)=28516.87109375MB
INFO:root:[   38] Training loss: 0.63508189, Validation loss: 0.63902520, Gradient norm: 0.07162682
INFO:root:At the start of the epoch: mem (CPU python)=28733.3984375MB; mem (CPU total)=28556.69921875MB
INFO:root:[   39] Training loss: 0.63415701, Validation loss: 0.63939950, Gradient norm: 0.07497658
INFO:root:At the start of the epoch: mem (CPU python)=28771.48046875MB; mem (CPU total)=28594.87109375MB
INFO:root:[   40] Training loss: 0.63363594, Validation loss: 0.63855377, Gradient norm: 0.07004134
INFO:root:At the start of the epoch: mem (CPU python)=28809.578125MB; mem (CPU total)=28633.08203125MB
INFO:root:[   41] Training loss: 0.63273880, Validation loss: 0.63704184, Gradient norm: 0.07107895
INFO:root:At the start of the epoch: mem (CPU python)=28847.671875MB; mem (CPU total)=28670.96484375MB
INFO:root:[   42] Training loss: 0.63215935, Validation loss: 0.63663593, Gradient norm: 0.07551449
INFO:root:At the start of the epoch: mem (CPU python)=28885.765625MB; mem (CPU total)=28708.35546875MB
INFO:root:[   43] Training loss: 0.63117734, Validation loss: 0.63665403, Gradient norm: 0.07212339
INFO:root:At the start of the epoch: mem (CPU python)=28923.859375MB; mem (CPU total)=28746.53125MB
INFO:root:[   44] Training loss: 0.63075947, Validation loss: 0.63612330, Gradient norm: 0.07573621
INFO:root:At the start of the epoch: mem (CPU python)=28961.95703125MB; mem (CPU total)=28784.25MB
INFO:root:[   45] Training loss: 0.62989027, Validation loss: 0.63513315, Gradient norm: 0.07090208
INFO:root:At the start of the epoch: mem (CPU python)=29000.05078125MB; mem (CPU total)=28822.45703125MB
INFO:root:[   46] Training loss: 0.62928059, Validation loss: 0.63538362, Gradient norm: 0.07736096
INFO:root:At the start of the epoch: mem (CPU python)=29038.14453125MB; mem (CPU total)=28861.125MB
INFO:root:[   47] Training loss: 0.62875159, Validation loss: 0.63489679, Gradient norm: 0.07604404
INFO:root:At the start of the epoch: mem (CPU python)=29076.24609375MB; mem (CPU total)=28898.98828125MB
INFO:root:[   48] Training loss: 0.62819360, Validation loss: 0.63426126, Gradient norm: 0.07634269
INFO:root:At the start of the epoch: mem (CPU python)=29114.33984375MB; mem (CPU total)=28937.15625MB
INFO:root:[   49] Training loss: 0.62748190, Validation loss: 0.63316852, Gradient norm: 0.08347719
INFO:root:At the start of the epoch: mem (CPU python)=29152.43359375MB; mem (CPU total)=28975.34375MB
INFO:root:[   50] Training loss: 0.62671457, Validation loss: 0.63324664, Gradient norm: 0.06867375
INFO:root:At the start of the epoch: mem (CPU python)=29190.52734375MB; mem (CPU total)=29013.4296875MB
INFO:root:[   51] Training loss: 0.62625256, Validation loss: 0.63259833, Gradient norm: 0.06926683
INFO:root:At the start of the epoch: mem (CPU python)=29228.625MB; mem (CPU total)=29051.8515625MB
INFO:root:[   52] Training loss: 0.62542093, Validation loss: 0.63186431, Gradient norm: 0.06945242
INFO:root:At the start of the epoch: mem (CPU python)=29266.71875MB; mem (CPU total)=29090.609375MB
INFO:root:[   53] Training loss: 0.62514729, Validation loss: 0.63207654, Gradient norm: 0.07799847
INFO:root:At the start of the epoch: mem (CPU python)=29304.8125MB; mem (CPU total)=29128.3984375MB
INFO:root:[   54] Training loss: 0.62452197, Validation loss: 0.63145390, Gradient norm: 0.07552424
INFO:root:At the start of the epoch: mem (CPU python)=29342.91015625MB; mem (CPU total)=29166.75MB
INFO:root:[   55] Training loss: 0.62378400, Validation loss: 0.63070738, Gradient norm: 0.07656767
INFO:root:At the start of the epoch: mem (CPU python)=29381.0078125MB; mem (CPU total)=29204.2890625MB
INFO:root:[   56] Training loss: 0.62334706, Validation loss: 0.63051271, Gradient norm: 0.07754637
INFO:root:At the start of the epoch: mem (CPU python)=29419.1015625MB; mem (CPU total)=29242.73046875MB
INFO:root:[   57] Training loss: 0.62292465, Validation loss: 0.63016187, Gradient norm: 0.07537767
INFO:root:At the start of the epoch: mem (CPU python)=29457.19921875MB; mem (CPU total)=29280.8984375MB
INFO:root:[   58] Training loss: 0.62221698, Validation loss: 0.63010747, Gradient norm: 0.07836114
INFO:root:At the start of the epoch: mem (CPU python)=29495.29296875MB; mem (CPU total)=29319.08203125MB
INFO:root:[   59] Training loss: 0.62167799, Validation loss: 0.63050991, Gradient norm: 0.07576393
INFO:root:At the start of the epoch: mem (CPU python)=29533.38671875MB; mem (CPU total)=29357.26171875MB
INFO:root:[   60] Training loss: 0.62126891, Validation loss: 0.62958837, Gradient norm: 0.06612948
INFO:root:At the start of the epoch: mem (CPU python)=29571.48046875MB; mem (CPU total)=29394.921875MB
INFO:root:[   61] Training loss: 0.62087137, Validation loss: 0.62885541, Gradient norm: 0.07213779
INFO:root:At the start of the epoch: mem (CPU python)=29609.578125MB; mem (CPU total)=29433.5MB
INFO:root:[   62] Training loss: 0.62038446, Validation loss: 0.62841423, Gradient norm: 0.07629836
INFO:root:At the start of the epoch: mem (CPU python)=29647.67578125MB; mem (CPU total)=29471.26953125MB
INFO:root:[   63] Training loss: 0.61964482, Validation loss: 0.62854468, Gradient norm: 0.06619652
INFO:root:At the start of the epoch: mem (CPU python)=29685.76953125MB; mem (CPU total)=29509.4765625MB
INFO:root:[   64] Training loss: 0.61942040, Validation loss: 0.62813856, Gradient norm: 0.07715276
INFO:root:At the start of the epoch: mem (CPU python)=29723.8671875MB; mem (CPU total)=29547.87890625MB
INFO:root:[   65] Training loss: 0.61882571, Validation loss: 0.62761145, Gradient norm: 0.06924193
INFO:root:At the start of the epoch: mem (CPU python)=29761.9609375MB; mem (CPU total)=29585.64453125MB
INFO:root:[   66] Training loss: 0.61840590, Validation loss: 0.62782826, Gradient norm: 0.06883275
INFO:root:At the start of the epoch: mem (CPU python)=29800.05859375MB; mem (CPU total)=29623.828125MB
INFO:root:[   67] Training loss: 0.61793720, Validation loss: 0.62713117, Gradient norm: 0.07313001
INFO:root:At the start of the epoch: mem (CPU python)=29838.15234375MB; mem (CPU total)=29662.24609375MB
INFO:root:[   68] Training loss: 0.61749326, Validation loss: 0.62649254, Gradient norm: 0.07485406
INFO:root:At the start of the epoch: mem (CPU python)=29876.25MB; mem (CPU total)=29700.2421875MB
INFO:root:[   69] Training loss: 0.61670948, Validation loss: 0.62638757, Gradient norm: 0.06996828
INFO:root:At the start of the epoch: mem (CPU python)=29914.34375MB; mem (CPU total)=29739.04296875MB
INFO:root:[   70] Training loss: 0.61677060, Validation loss: 0.62642147, Gradient norm: 0.07576430
INFO:root:At the start of the epoch: mem (CPU python)=29952.4375MB; mem (CPU total)=29776.5859375MB
INFO:root:[   71] Training loss: 0.61597991, Validation loss: 0.62639041, Gradient norm: 0.07309772
INFO:root:At the start of the epoch: mem (CPU python)=29990.53515625MB; mem (CPU total)=29814.85546875MB
INFO:root:[   72] Training loss: 0.61562976, Validation loss: 0.62520353, Gradient norm: 0.07096821
INFO:root:At the start of the epoch: mem (CPU python)=30028.6328125MB; mem (CPU total)=29853.16015625MB
INFO:root:[   73] Training loss: 0.61529072, Validation loss: 0.62468491, Gradient norm: 0.07963191
INFO:root:At the start of the epoch: mem (CPU python)=30066.72265625MB; mem (CPU total)=29891.5625MB
INFO:root:[   74] Training loss: 0.61492565, Validation loss: 0.62569296, Gradient norm: 0.06931380
INFO:root:At the start of the epoch: mem (CPU python)=30104.82421875MB; mem (CPU total)=29929.703125MB
INFO:root:[   75] Training loss: 0.61426069, Validation loss: 0.62486322, Gradient norm: 0.06446240
INFO:root:At the start of the epoch: mem (CPU python)=30142.91796875MB; mem (CPU total)=29967.3671875MB
INFO:root:[   76] Training loss: 0.61417279, Validation loss: 0.62453319, Gradient norm: 0.07371958
INFO:root:At the start of the epoch: mem (CPU python)=30181.01171875MB; mem (CPU total)=30005.5078125MB
INFO:root:[   77] Training loss: 0.61353963, Validation loss: 0.62377219, Gradient norm: 0.08010926
INFO:root:At the start of the epoch: mem (CPU python)=30219.10546875MB; mem (CPU total)=30050.21484375MB
INFO:root:[   78] Training loss: 0.61297120, Validation loss: 0.62465123, Gradient norm: 0.06844528
INFO:root:At the start of the epoch: mem (CPU python)=30257.203125MB; mem (CPU total)=30088.25390625MB
INFO:root:[   79] Training loss: 0.61271145, Validation loss: 0.62458081, Gradient norm: 0.07005044
INFO:root:At the start of the epoch: mem (CPU python)=30295.296875MB; mem (CPU total)=30126.27734375MB
INFO:root:[   80] Training loss: 0.61232709, Validation loss: 0.62399960, Gradient norm: 0.07991528
INFO:root:At the start of the epoch: mem (CPU python)=30333.390625MB; mem (CPU total)=30163.8046875MB
INFO:root:[   81] Training loss: 0.61204972, Validation loss: 0.62390800, Gradient norm: 0.06763041
INFO:root:At the start of the epoch: mem (CPU python)=30371.4921875MB; mem (CPU total)=30202.0078125MB
INFO:root:[   82] Training loss: 0.61163222, Validation loss: 0.62333494, Gradient norm: 0.07350510
INFO:root:At the start of the epoch: mem (CPU python)=30409.5859375MB; mem (CPU total)=30240.390625MB
INFO:root:[   83] Training loss: 0.61146821, Validation loss: 0.62246186, Gradient norm: 0.07333887
INFO:root:At the start of the epoch: mem (CPU python)=30447.6796875MB; mem (CPU total)=30278.55078125MB
INFO:root:[   84] Training loss: 0.61077909, Validation loss: 0.62331112, Gradient norm: 0.07287747
INFO:root:At the start of the epoch: mem (CPU python)=30485.7734375MB; mem (CPU total)=30316.81640625MB
INFO:root:[   85] Training loss: 0.61033792, Validation loss: 0.62347039, Gradient norm: 0.06872333
INFO:root:At the start of the epoch: mem (CPU python)=30523.87109375MB; mem (CPU total)=30354.703125MB
INFO:root:[   86] Training loss: 0.60984282, Validation loss: 0.62363727, Gradient norm: 0.07283790
INFO:root:At the start of the epoch: mem (CPU python)=30561.96484375MB; mem (CPU total)=30392.78125MB
INFO:root:[   87] Training loss: 0.60993387, Validation loss: 0.62346428, Gradient norm: 0.07682017
INFO:root:At the start of the epoch: mem (CPU python)=30600.05859375MB; mem (CPU total)=30430.65625MB
INFO:root:[   88] Training loss: 0.60919498, Validation loss: 0.62234107, Gradient norm: 0.06930220
INFO:root:At the start of the epoch: mem (CPU python)=30638.15625MB; mem (CPU total)=30469.0390625MB
INFO:root:[   89] Training loss: 0.60891480, Validation loss: 0.62241512, Gradient norm: 0.07556260
INFO:root:At the start of the epoch: mem (CPU python)=30676.25MB; mem (CPU total)=30506.9375MB
INFO:root:[   90] Training loss: 0.60861184, Validation loss: 0.62156247, Gradient norm: 0.07363963
INFO:root:At the start of the epoch: mem (CPU python)=30714.34765625MB; mem (CPU total)=30545.17578125MB
INFO:root:[   91] Training loss: 0.60830716, Validation loss: 0.62208920, Gradient norm: 0.07206586
INFO:root:At the start of the epoch: mem (CPU python)=30752.4453125MB; mem (CPU total)=30582.58203125MB
INFO:root:[   92] Training loss: 0.60793086, Validation loss: 0.62152459, Gradient norm: 0.07703336
INFO:root:At the start of the epoch: mem (CPU python)=30790.5390625MB; mem (CPU total)=30620.7265625MB
INFO:root:[   93] Training loss: 0.60761782, Validation loss: 0.62178472, Gradient norm: 0.07650532
INFO:root:At the start of the epoch: mem (CPU python)=30828.6328125MB; mem (CPU total)=30658.828125MB
INFO:root:[   94] Training loss: 0.60725847, Validation loss: 0.62140350, Gradient norm: 0.07313911
INFO:root:At the start of the epoch: mem (CPU python)=30866.7265625MB; mem (CPU total)=30697.07421875MB
INFO:root:[   95] Training loss: 0.60658530, Validation loss: 0.62096699, Gradient norm: 0.06693038
INFO:root:At the start of the epoch: mem (CPU python)=30904.82421875MB; mem (CPU total)=30735.3125MB
INFO:root:[   96] Training loss: 0.60632590, Validation loss: 0.62119385, Gradient norm: 0.06963390
INFO:root:At the start of the epoch: mem (CPU python)=30942.91796875MB; mem (CPU total)=30773.20703125MB
INFO:root:[   97] Training loss: 0.60597368, Validation loss: 0.62189399, Gradient norm: 0.07305955
INFO:root:At the start of the epoch: mem (CPU python)=30981.015625MB; mem (CPU total)=30810.84375MB
INFO:root:[   98] Training loss: 0.60560666, Validation loss: 0.62162582, Gradient norm: 0.07410249
INFO:root:At the start of the epoch: mem (CPU python)=31019.11328125MB; mem (CPU total)=30848.640625MB
INFO:root:[   99] Training loss: 0.60529119, Validation loss: 0.62095214, Gradient norm: 0.07695953
INFO:root:At the start of the epoch: mem (CPU python)=31057.20703125MB; mem (CPU total)=30886.07421875MB
INFO:root:[  100] Training loss: 0.60494318, Validation loss: 0.62254681, Gradient norm: 0.06764217
INFO:root:At the start of the epoch: mem (CPU python)=31095.30078125MB; mem (CPU total)=30924.5234375MB
INFO:root:[  101] Training loss: 0.60461459, Validation loss: 0.62023369, Gradient norm: 0.07927295
INFO:root:At the start of the epoch: mem (CPU python)=31133.39453125MB; mem (CPU total)=30962.4140625MB
INFO:root:[  102] Training loss: 0.60422246, Validation loss: 0.62129470, Gradient norm: 0.07132623
INFO:root:At the start of the epoch: mem (CPU python)=31171.4921875MB; mem (CPU total)=31000.1875MB
INFO:root:[  103] Training loss: 0.60435984, Validation loss: 0.62164233, Gradient norm: 0.08194369
INFO:root:At the start of the epoch: mem (CPU python)=31209.5859375MB; mem (CPU total)=31038.33203125MB
INFO:root:[  104] Training loss: 0.60370447, Validation loss: 0.62102539, Gradient norm: 0.07156887
INFO:root:At the start of the epoch: mem (CPU python)=31247.6796875MB; mem (CPU total)=31076.41015625MB
INFO:root:[  105] Training loss: 0.60332372, Validation loss: 0.62051338, Gradient norm: 0.08129361
INFO:root:At the start of the epoch: mem (CPU python)=31285.77734375MB; mem (CPU total)=31114.796875MB
INFO:root:[  106] Training loss: 0.60287263, Validation loss: 0.62044519, Gradient norm: 0.07162277
INFO:root:At the start of the epoch: mem (CPU python)=31323.87109375MB; mem (CPU total)=31152.75MB
INFO:root:[  107] Training loss: 0.60298710, Validation loss: 0.62064613, Gradient norm: 0.07193678
INFO:root:At the start of the epoch: mem (CPU python)=31361.96875MB; mem (CPU total)=31190.875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  108] Training loss: 0.60238799, Validation loss: 0.62056799, Gradient norm: 0.07061948
INFO:root:At the start of the epoch: mem (CPU python)=31400.0703125MB; mem (CPU total)=31228.82421875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  109] Training loss: 0.60113423, Validation loss: 0.61897040, Gradient norm: 0.06147527
INFO:root:At the start of the epoch: mem (CPU python)=31438.1640625MB; mem (CPU total)=31266.97265625MB
INFO:root:[  110] Training loss: 0.60024620, Validation loss: 0.62007993, Gradient norm: 0.06107339
INFO:root:At the start of the epoch: mem (CPU python)=31476.2578125MB; mem (CPU total)=31305.109375MB
INFO:root:[  111] Training loss: 0.59993477, Validation loss: 0.61910748, Gradient norm: 0.05994102
INFO:root:At the start of the epoch: mem (CPU python)=31514.3515625MB; mem (CPU total)=31343.2421875MB
INFO:root:[  112] Training loss: 0.59987343, Validation loss: 0.62006690, Gradient norm: 0.06178589
INFO:root:At the start of the epoch: mem (CPU python)=31552.44921875MB; mem (CPU total)=31381.625MB
INFO:root:[  113] Training loss: 0.59978743, Validation loss: 0.61997125, Gradient norm: 0.05958244
INFO:root:At the start of the epoch: mem (CPU python)=31590.546875MB; mem (CPU total)=31419.76953125MB
INFO:root:[  114] Training loss: 0.59954530, Validation loss: 0.61989037, Gradient norm: 0.05782945
INFO:root:At the start of the epoch: mem (CPU python)=31628.640625MB; mem (CPU total)=31457.91015625MB
INFO:root:[  115] Training loss: 0.59944500, Validation loss: 0.61958074, Gradient norm: 0.06005715
INFO:root:At the start of the epoch: mem (CPU python)=31666.7421875MB; mem (CPU total)=31496.046875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  116] Training loss: 0.59949460, Validation loss: 0.61929790, Gradient norm: 0.06041492
INFO:root:At the start of the epoch: mem (CPU python)=31704.8359375MB; mem (CPU total)=31533.9453125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  117] Training loss: 0.59887782, Validation loss: 0.61940652, Gradient norm: 0.05824381
INFO:root:At the start of the epoch: mem (CPU python)=31742.9296875MB; mem (CPU total)=31571.83203125MB
INFO:root:[  118] Training loss: 0.59884708, Validation loss: 0.62026666, Gradient norm: 0.05744926
INFO:root:At the start of the epoch: mem (CPU python)=31781.0234375MB; mem (CPU total)=31610.4609375MB
INFO:root:EP 118: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=31819.1171875MB; mem (CPU total)=31648.60546875MB
INFO:root:Training the model took 11622.707s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85185
INFO:root:EnergyScoreTrain: 0.6
INFO:root:CRPSTrain: 0.51837
INFO:root:Gaussian NLLTrain: 1.97503
INFO:root:CoverageTrain: 0.81196
INFO:root:IntervalWidthTrain: 3.15165
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87972
INFO:root:EnergyScoreValidation: 0.61954
INFO:root:CRPSValidation: 0.53439
INFO:root:Gaussian NLLValidation: 2.02056
INFO:root:CoverageValidation: 0.8027
INFO:root:IntervalWidthValidation: 3.14618
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88066
INFO:root:EnergyScoreTest: 0.6202
INFO:root:CRPSTest: 0.53486
INFO:root:Gaussian NLLTest: 2.01647
INFO:root:CoverageTest: 0.80273
INFO:root:IntervalWidthTest: 3.14396
INFO:root:After validation: mem (CPU python)=31861.7578125MB; mem (CPU total)=31690.5MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=31861.7578125MB; mem (CPU total)=31690.40234375MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 157286400
INFO:root:After setting up the model: mem (CPU python)=31862.2890625MB; mem (CPU total)=31690.89453125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=31862.3984375MB; mem (CPU total)=31691.109375MB
INFO:root:[    1] Training loss: 0.77780010, Validation loss: 0.72232826, Gradient norm: 0.46875168
INFO:root:At the start of the epoch: mem (CPU python)=31900.5078125MB; mem (CPU total)=31730.07421875MB
INFO:root:[    2] Training loss: 0.72132554, Validation loss: 0.72201876, Gradient norm: 0.46254568
INFO:root:At the start of the epoch: mem (CPU python)=31938.6015625MB; mem (CPU total)=31770.72265625MB
INFO:root:[    3] Training loss: 0.72042244, Validation loss: 0.72045937, Gradient norm: 0.55788736
INFO:root:At the start of the epoch: mem (CPU python)=31976.71484375MB; mem (CPU total)=31808.8515625MB
INFO:root:[    4] Training loss: 0.71983778, Validation loss: 0.71930858, Gradient norm: 0.31367363
INFO:root:At the start of the epoch: mem (CPU python)=32014.82421875MB; mem (CPU total)=31847.02734375MB
INFO:root:[    5] Training loss: 0.71945478, Validation loss: 0.71907929, Gradient norm: 0.25525676
INFO:root:At the start of the epoch: mem (CPU python)=32052.91796875MB; mem (CPU total)=31884.94921875MB
INFO:root:[    6] Training loss: 0.71902949, Validation loss: 0.71879345, Gradient norm: 0.18700342
INFO:root:At the start of the epoch: mem (CPU python)=32091.015625MB; mem (CPU total)=31923.08984375MB
INFO:root:[    7] Training loss: 0.71864101, Validation loss: 0.71870161, Gradient norm: 0.22494642
INFO:root:At the start of the epoch: mem (CPU python)=32129.11328125MB; mem (CPU total)=31960.6953125MB
INFO:root:[    8] Training loss: 0.71791120, Validation loss: 0.71753080, Gradient norm: 0.23384484
INFO:root:At the start of the epoch: mem (CPU python)=32167.20703125MB; mem (CPU total)=31998.78125MB
INFO:root:[    9] Training loss: 0.71466519, Validation loss: 0.71115320, Gradient norm: 0.18669860
INFO:root:At the start of the epoch: mem (CPU python)=32205.30078125MB; mem (CPU total)=32037.41796875MB
INFO:root:[   10] Training loss: 0.70389719, Validation loss: 0.69813320, Gradient norm: 0.17188585
INFO:root:At the start of the epoch: mem (CPU python)=32243.3984375MB; mem (CPU total)=32075.59375MB
INFO:root:[   11] Training loss: 0.69273429, Validation loss: 0.68945245, Gradient norm: 0.16855683
INFO:root:At the start of the epoch: mem (CPU python)=32281.49609375MB; mem (CPU total)=32113.73828125MB
INFO:root:[   12] Training loss: 0.68535511, Validation loss: 0.68345285, Gradient norm: 0.12422409
INFO:root:At the start of the epoch: mem (CPU python)=32319.58984375MB; mem (CPU total)=32151.609375MB
INFO:root:[   13] Training loss: 0.67942517, Validation loss: 0.67700385, Gradient norm: 0.10925944
INFO:root:At the start of the epoch: mem (CPU python)=32357.6875MB; mem (CPU total)=32190.03515625MB
INFO:root:[   14] Training loss: 0.67397123, Validation loss: 0.67214232, Gradient norm: 0.10328183
INFO:root:At the start of the epoch: mem (CPU python)=32395.78515625MB; mem (CPU total)=32228.63671875MB
INFO:root:[   15] Training loss: 0.66930138, Validation loss: 0.66849865, Gradient norm: 0.11065916
INFO:root:At the start of the epoch: mem (CPU python)=32433.87890625MB; mem (CPU total)=32266.796875MB
INFO:root:[   16] Training loss: 0.66542520, Validation loss: 0.66491966, Gradient norm: 0.10466874
INFO:root:At the start of the epoch: mem (CPU python)=32471.97265625MB; mem (CPU total)=32304.48828125MB
INFO:root:[   17] Training loss: 0.66202208, Validation loss: 0.66159905, Gradient norm: 0.11216791
INFO:root:At the start of the epoch: mem (CPU python)=32510.0703125MB; mem (CPU total)=32342.59765625MB
INFO:root:[   18] Training loss: 0.65938061, Validation loss: 0.65922341, Gradient norm: 0.08853637
INFO:root:At the start of the epoch: mem (CPU python)=32548.1640625MB; mem (CPU total)=32380.47265625MB
INFO:root:[   19] Training loss: 0.65667426, Validation loss: 0.65675674, Gradient norm: 0.07888854
INFO:root:At the start of the epoch: mem (CPU python)=32586.2578125MB; mem (CPU total)=32419.12109375MB
INFO:root:[   20] Training loss: 0.65446893, Validation loss: 0.65580469, Gradient norm: 0.08165007
INFO:root:At the start of the epoch: mem (CPU python)=32624.35546875MB; mem (CPU total)=32457.49609375MB
INFO:root:[   21] Training loss: 0.65264974, Validation loss: 0.65379751, Gradient norm: 0.08501044
INFO:root:At the start of the epoch: mem (CPU python)=32662.44921875MB; mem (CPU total)=32495.39453125MB
INFO:root:[   22] Training loss: 0.65083306, Validation loss: 0.65231341, Gradient norm: 0.07144199
INFO:root:At the start of the epoch: mem (CPU python)=32700.54296875MB; mem (CPU total)=32533.5546875MB
INFO:root:[   23] Training loss: 0.64922733, Validation loss: 0.65114142, Gradient norm: 0.08174178
INFO:root:At the start of the epoch: mem (CPU python)=32738.640625MB; mem (CPU total)=32571.17578125MB
INFO:root:[   24] Training loss: 0.64756505, Validation loss: 0.64944091, Gradient norm: 0.07032468
INFO:root:At the start of the epoch: mem (CPU python)=32776.73828125MB; mem (CPU total)=32609.5546875MB
INFO:root:[   25] Training loss: 0.64622928, Validation loss: 0.64861182, Gradient norm: 0.08588230
INFO:root:At the start of the epoch: mem (CPU python)=32814.8359375MB; mem (CPU total)=32647.25MB
INFO:root:[   26] Training loss: 0.64485760, Validation loss: 0.64736729, Gradient norm: 0.07885676
INFO:root:At the start of the epoch: mem (CPU python)=32852.9296875MB; mem (CPU total)=32685.6328125MB
INFO:root:[   27] Training loss: 0.64371465, Validation loss: 0.64528681, Gradient norm: 0.08350240
INFO:root:At the start of the epoch: mem (CPU python)=32891.02734375MB; mem (CPU total)=32723.77734375MB
INFO:root:[   28] Training loss: 0.64234152, Validation loss: 0.64487489, Gradient norm: 0.08737903
INFO:root:At the start of the epoch: mem (CPU python)=32929.125MB; mem (CPU total)=32761.9140625MB
INFO:root:[   29] Training loss: 0.64128104, Validation loss: 0.64402860, Gradient norm: 0.07301014
INFO:root:At the start of the epoch: mem (CPU python)=32967.21484375MB; mem (CPU total)=32800.35546875MB
INFO:root:[   30] Training loss: 0.64021497, Validation loss: 0.64260272, Gradient norm: 0.06958538
INFO:root:At the start of the epoch: mem (CPU python)=33005.3125MB; mem (CPU total)=32838.60546875MB
INFO:root:[   31] Training loss: 0.63928219, Validation loss: 0.64248076, Gradient norm: 0.06775105
INFO:root:At the start of the epoch: mem (CPU python)=33043.41015625MB; mem (CPU total)=32876.66796875MB
INFO:root:[   32] Training loss: 0.63823434, Validation loss: 0.64085025, Gradient norm: 0.08944404
INFO:root:At the start of the epoch: mem (CPU python)=33081.50390625MB; mem (CPU total)=32915.08984375MB
INFO:root:[   33] Training loss: 0.63721967, Validation loss: 0.64061589, Gradient norm: 0.07046452
INFO:root:At the start of the epoch: mem (CPU python)=33119.59765625MB; mem (CPU total)=32953.234375MB
INFO:root:[   34] Training loss: 0.63619484, Validation loss: 0.64024084, Gradient norm: 0.09131411
INFO:root:At the start of the epoch: mem (CPU python)=33157.6953125MB; mem (CPU total)=32991.625MB
INFO:root:[   35] Training loss: 0.63503109, Validation loss: 0.63864724, Gradient norm: 0.08316688
INFO:root:At the start of the epoch: mem (CPU python)=33195.7890625MB; mem (CPU total)=33029.265625MB
INFO:root:[   36] Training loss: 0.63418151, Validation loss: 0.63735305, Gradient norm: 0.08296422
INFO:root:At the start of the epoch: mem (CPU python)=33233.8828125MB; mem (CPU total)=33067.41015625MB
INFO:root:[   37] Training loss: 0.63309362, Validation loss: 0.63692413, Gradient norm: 0.07815307
INFO:root:At the start of the epoch: mem (CPU python)=33271.984375MB; mem (CPU total)=33105.76953125MB
INFO:root:[   38] Training loss: 0.63257695, Validation loss: 0.63557599, Gradient norm: 0.07437325
INFO:root:At the start of the epoch: mem (CPU python)=33310.078125MB; mem (CPU total)=33143.90625MB
INFO:root:[   39] Training loss: 0.63184001, Validation loss: 0.63598869, Gradient norm: 0.07375626
INFO:root:At the start of the epoch: mem (CPU python)=33348.171875MB; mem (CPU total)=33182.265625MB
INFO:root:[   40] Training loss: 0.63086937, Validation loss: 0.63467374, Gradient norm: 0.07971790
INFO:root:At the start of the epoch: mem (CPU python)=33386.265625MB; mem (CPU total)=33220.1875MB
INFO:root:[   41] Training loss: 0.62997158, Validation loss: 0.63373528, Gradient norm: 0.07992967
INFO:root:At the start of the epoch: mem (CPU python)=33424.36328125MB; mem (CPU total)=33258.08203125MB
INFO:root:[   42] Training loss: 0.62919473, Validation loss: 0.63371293, Gradient norm: 0.07575346
INFO:root:At the start of the epoch: mem (CPU python)=33462.45703125MB; mem (CPU total)=33296.45703125MB
INFO:root:[   43] Training loss: 0.62870880, Validation loss: 0.63308819, Gradient norm: 0.08064795
INFO:root:At the start of the epoch: mem (CPU python)=33500.5546875MB; mem (CPU total)=33334.56640625MB
INFO:root:[   44] Training loss: 0.62782159, Validation loss: 0.63285973, Gradient norm: 0.07775175
INFO:root:At the start of the epoch: mem (CPU python)=33538.65234375MB; mem (CPU total)=33372.98046875MB
INFO:root:[   45] Training loss: 0.62718117, Validation loss: 0.63259518, Gradient norm: 0.08239814
INFO:root:At the start of the epoch: mem (CPU python)=33576.74609375MB; mem (CPU total)=33411.12109375MB
INFO:root:[   46] Training loss: 0.62657721, Validation loss: 0.63162387, Gradient norm: 0.10236017
INFO:root:At the start of the epoch: mem (CPU python)=33614.83984375MB; mem (CPU total)=33448.7734375MB
INFO:root:[   47] Training loss: 0.62577678, Validation loss: 0.63111580, Gradient norm: 0.07305791
INFO:root:At the start of the epoch: mem (CPU python)=33652.9375MB; mem (CPU total)=33487.14453125MB
INFO:root:[   48] Training loss: 0.62525004, Validation loss: 0.63000820, Gradient norm: 0.07911972
INFO:root:At the start of the epoch: mem (CPU python)=33691.03515625MB; mem (CPU total)=33525.5703125MB
INFO:root:[   49] Training loss: 0.62454864, Validation loss: 0.62964449, Gradient norm: 0.07554898
INFO:root:At the start of the epoch: mem (CPU python)=33729.12890625MB; mem (CPU total)=33564.19140625MB
INFO:root:[   50] Training loss: 0.62401685, Validation loss: 0.63000155, Gradient norm: 0.08273298
INFO:root:At the start of the epoch: mem (CPU python)=33767.22265625MB; mem (CPU total)=33602.09765625MB
INFO:root:[   51] Training loss: 0.62343533, Validation loss: 0.62918916, Gradient norm: 0.08132987
INFO:root:At the start of the epoch: mem (CPU python)=33805.3203125MB; mem (CPU total)=33640.15625MB
INFO:root:[   52] Training loss: 0.62268040, Validation loss: 0.62812588, Gradient norm: 0.07721449
INFO:root:At the start of the epoch: mem (CPU python)=33843.4140625MB; mem (CPU total)=33678.0859375MB
INFO:root:[   53] Training loss: 0.62223904, Validation loss: 0.62746507, Gradient norm: 0.08528020
INFO:root:At the start of the epoch: mem (CPU python)=33881.51171875MB; mem (CPU total)=33716.2578125MB
INFO:root:[   54] Training loss: 0.62170800, Validation loss: 0.62767476, Gradient norm: 0.08503131
INFO:root:At the start of the epoch: mem (CPU python)=33919.609375MB; mem (CPU total)=33754.6484375MB
INFO:root:[   55] Training loss: 0.62135409, Validation loss: 0.62828505, Gradient norm: 0.09086300
INFO:root:At the start of the epoch: mem (CPU python)=33957.703125MB; mem (CPU total)=33793.2109375MB
INFO:root:[   56] Training loss: 0.62097307, Validation loss: 0.62722832, Gradient norm: 0.08128659
INFO:root:At the start of the epoch: mem (CPU python)=33995.796875MB; mem (CPU total)=33831.078125MB
INFO:root:[   57] Training loss: 0.62009064, Validation loss: 0.62730968, Gradient norm: 0.06795072
INFO:root:At the start of the epoch: mem (CPU python)=34033.890625MB; mem (CPU total)=33868.9921875MB
INFO:root:[   58] Training loss: 0.61976862, Validation loss: 0.62626931, Gradient norm: 0.07896157
INFO:root:At the start of the epoch: mem (CPU python)=34071.98828125MB; mem (CPU total)=33907.37109375MB
INFO:root:[   59] Training loss: 0.61910981, Validation loss: 0.62688585, Gradient norm: 0.07985707
INFO:root:At the start of the epoch: mem (CPU python)=34110.08203125MB; mem (CPU total)=33945.46484375MB
INFO:root:[   60] Training loss: 0.61840801, Validation loss: 0.62648206, Gradient norm: 0.08471908
INFO:root:At the start of the epoch: mem (CPU python)=34148.17578125MB; mem (CPU total)=33984.359375MB
INFO:root:[   61] Training loss: 0.61812545, Validation loss: 0.62584229, Gradient norm: 0.08084639
INFO:root:At the start of the epoch: mem (CPU python)=34186.2734375MB; mem (CPU total)=34022.4296875MB
INFO:root:[   62] Training loss: 0.61753774, Validation loss: 0.62546876, Gradient norm: 0.07937779
INFO:root:At the start of the epoch: mem (CPU python)=34224.3671875MB; mem (CPU total)=34060.57421875MB
INFO:root:[   63] Training loss: 0.61708314, Validation loss: 0.62496827, Gradient norm: 0.08131049
INFO:root:At the start of the epoch: mem (CPU python)=34262.46484375MB; mem (CPU total)=34099.0234375MB
INFO:root:[   64] Training loss: 0.61642380, Validation loss: 0.62368172, Gradient norm: 0.07440623
INFO:root:At the start of the epoch: mem (CPU python)=34300.55859375MB; mem (CPU total)=34137.14453125MB
INFO:root:[   65] Training loss: 0.61607848, Validation loss: 0.62425465, Gradient norm: 0.06930082
INFO:root:At the start of the epoch: mem (CPU python)=34338.65625MB; mem (CPU total)=34175.0078125MB
INFO:root:[   66] Training loss: 0.61569934, Validation loss: 0.62448044, Gradient norm: 0.07530864
INFO:root:At the start of the epoch: mem (CPU python)=34376.75MB; mem (CPU total)=34213.65234375MB
INFO:root:[   67] Training loss: 0.61522378, Validation loss: 0.62331540, Gradient norm: 0.08106204
INFO:root:At the start of the epoch: mem (CPU python)=34414.84375MB; mem (CPU total)=34251.50390625MB
INFO:root:[   68] Training loss: 0.61484570, Validation loss: 0.62341499, Gradient norm: 0.08798146
INFO:root:At the start of the epoch: mem (CPU python)=34452.94140625MB; mem (CPU total)=34289.625MB
INFO:root:[   69] Training loss: 0.61443584, Validation loss: 0.62295233, Gradient norm: 0.08334873
INFO:root:At the start of the epoch: mem (CPU python)=34491.03515625MB; mem (CPU total)=34327.9921875MB
INFO:root:[   70] Training loss: 0.61412911, Validation loss: 0.62263227, Gradient norm: 0.08515233
INFO:root:At the start of the epoch: mem (CPU python)=34529.12890625MB; mem (CPU total)=34366.171875MB
INFO:root:[   71] Training loss: 0.61370385, Validation loss: 0.62233635, Gradient norm: 0.08350888
INFO:root:At the start of the epoch: mem (CPU python)=34567.23046875MB; mem (CPU total)=34404.10546875MB
INFO:root:[   72] Training loss: 0.61313672, Validation loss: 0.62266906, Gradient norm: 0.08093738
INFO:root:At the start of the epoch: mem (CPU python)=34605.32421875MB; mem (CPU total)=34441.921875MB
INFO:root:[   73] Training loss: 0.61289413, Validation loss: 0.62225496, Gradient norm: 0.09118189
INFO:root:At the start of the epoch: mem (CPU python)=34643.41796875MB; mem (CPU total)=34480.0390625MB
INFO:root:[   74] Training loss: 0.61234885, Validation loss: 0.62181892, Gradient norm: 0.08460574
INFO:root:At the start of the epoch: mem (CPU python)=34681.51171875MB; mem (CPU total)=34517.6640625MB
INFO:root:[   75] Training loss: 0.61171457, Validation loss: 0.62142389, Gradient norm: 0.07097257
INFO:root:At the start of the epoch: mem (CPU python)=34719.609375MB; mem (CPU total)=34555.546875MB
INFO:root:[   76] Training loss: 0.61160540, Validation loss: 0.62184824, Gradient norm: 0.07742835
INFO:root:At the start of the epoch: mem (CPU python)=34757.703125MB; mem (CPU total)=34593.65625MB
INFO:root:[   77] Training loss: 0.61124958, Validation loss: 0.62187206, Gradient norm: 0.07885327
INFO:root:At the start of the epoch: mem (CPU python)=34795.796875MB; mem (CPU total)=34631.83984375MB
INFO:root:[   78] Training loss: 0.61062519, Validation loss: 0.62095364, Gradient norm: 0.08203678
INFO:root:At the start of the epoch: mem (CPU python)=34833.89453125MB; mem (CPU total)=34669.43359375MB
INFO:root:[   79] Training loss: 0.61039628, Validation loss: 0.62144470, Gradient norm: 0.07903395
INFO:root:At the start of the epoch: mem (CPU python)=34871.98828125MB; mem (CPU total)=34707.31640625MB
INFO:root:[   80] Training loss: 0.61013975, Validation loss: 0.62060132, Gradient norm: 0.09015127
INFO:root:At the start of the epoch: mem (CPU python)=34910.0859375MB; mem (CPU total)=34745.4609375MB
INFO:root:[   81] Training loss: 0.60948242, Validation loss: 0.61995938, Gradient norm: 0.07806881
INFO:root:At the start of the epoch: mem (CPU python)=34948.1796875MB; mem (CPU total)=34783.6171875MB
INFO:root:[   82] Training loss: 0.60921009, Validation loss: 0.61984812, Gradient norm: 0.08316705
INFO:root:At the start of the epoch: mem (CPU python)=34986.27734375MB; mem (CPU total)=34821.79296875MB
INFO:root:[   83] Training loss: 0.60905005, Validation loss: 0.62043524, Gradient norm: 0.09378228
INFO:root:At the start of the epoch: mem (CPU python)=35024.37109375MB; mem (CPU total)=34860.65234375MB
INFO:root:[   84] Training loss: 0.60867537, Validation loss: 0.61932054, Gradient norm: 0.07441689
INFO:root:At the start of the epoch: mem (CPU python)=35062.46484375MB; mem (CPU total)=34898.546875MB
INFO:root:[   85] Training loss: 0.60789887, Validation loss: 0.61963431, Gradient norm: 0.07284670
INFO:root:At the start of the epoch: mem (CPU python)=35100.5625MB; mem (CPU total)=34936.375MB
INFO:root:[   86] Training loss: 0.60773672, Validation loss: 0.61973312, Gradient norm: 0.08088249
INFO:root:At the start of the epoch: mem (CPU python)=35138.66015625MB; mem (CPU total)=34974.51953125MB
INFO:root:[   87] Training loss: 0.60743454, Validation loss: 0.61978259, Gradient norm: 0.07802986
INFO:root:At the start of the epoch: mem (CPU python)=35176.7578125MB; mem (CPU total)=35012.55078125MB
INFO:root:[   88] Training loss: 0.60725271, Validation loss: 0.61917721, Gradient norm: 0.09309697
INFO:root:At the start of the epoch: mem (CPU python)=35214.85546875MB; mem (CPU total)=35051.18359375MB
INFO:root:[   89] Training loss: 0.60690504, Validation loss: 0.61946827, Gradient norm: 0.07847514
INFO:root:At the start of the epoch: mem (CPU python)=35252.94921875MB; mem (CPU total)=35089.55078125MB
INFO:root:[   90] Training loss: 0.60654590, Validation loss: 0.61848357, Gradient norm: 0.07898473
INFO:root:At the start of the epoch: mem (CPU python)=35291.04296875MB; mem (CPU total)=35127.47265625MB
INFO:root:[   91] Training loss: 0.60635001, Validation loss: 0.61868091, Gradient norm: 0.09692835
INFO:root:At the start of the epoch: mem (CPU python)=35329.13671875MB; mem (CPU total)=35166.1796875MB
INFO:root:[   92] Training loss: 0.60570326, Validation loss: 0.61884851, Gradient norm: 0.07535365
INFO:root:At the start of the epoch: mem (CPU python)=35367.234375MB; mem (CPU total)=35204.0625MB
INFO:root:[   93] Training loss: 0.60544006, Validation loss: 0.61819709, Gradient norm: 0.07702807
INFO:root:At the start of the epoch: mem (CPU python)=35405.328125MB; mem (CPU total)=35241.23828125MB
INFO:root:[   94] Training loss: 0.60525192, Validation loss: 0.61965350, Gradient norm: 0.08421566
INFO:root:At the start of the epoch: mem (CPU python)=35443.421875MB; mem (CPU total)=35279.1796875MB
INFO:root:[   95] Training loss: 0.60491633, Validation loss: 0.62020055, Gradient norm: 0.08185621
INFO:root:At the start of the epoch: mem (CPU python)=35481.51953125MB; mem (CPU total)=35317.1015625MB
INFO:root:[   96] Training loss: 0.60443118, Validation loss: 0.61854756, Gradient norm: 0.07349462
INFO:root:At the start of the epoch: mem (CPU python)=35519.6171875MB; mem (CPU total)=35355.2578125MB
INFO:root:[   97] Training loss: 0.60429634, Validation loss: 0.61810469, Gradient norm: 0.09097427
INFO:root:At the start of the epoch: mem (CPU python)=35557.7109375MB; mem (CPU total)=35393.71875MB
INFO:root:[   98] Training loss: 0.60417203, Validation loss: 0.61837436, Gradient norm: 0.08400807
INFO:root:At the start of the epoch: mem (CPU python)=35595.8046875MB; mem (CPU total)=35431.87890625MB
INFO:root:[   99] Training loss: 0.60356307, Validation loss: 0.61849335, Gradient norm: 0.08446965
INFO:root:At the start of the epoch: mem (CPU python)=35633.90234375MB; mem (CPU total)=35469.5703125MB
INFO:root:[  100] Training loss: 0.60349203, Validation loss: 0.61864610, Gradient norm: 0.08441367
INFO:root:At the start of the epoch: mem (CPU python)=35671.99609375MB; mem (CPU total)=35508.37890625MB
INFO:root:[  101] Training loss: 0.60301962, Validation loss: 0.61826092, Gradient norm: 0.09175691
INFO:root:At the start of the epoch: mem (CPU python)=35710.08984375MB; mem (CPU total)=35546.796875MB
INFO:root:[  102] Training loss: 0.60259621, Validation loss: 0.61802707, Gradient norm: 0.08190745
INFO:root:At the start of the epoch: mem (CPU python)=35748.1875MB; mem (CPU total)=35584.984375MB
INFO:root:[  103] Training loss: 0.60242985, Validation loss: 0.61830759, Gradient norm: 0.08001817
INFO:root:At the start of the epoch: mem (CPU python)=35786.28125MB; mem (CPU total)=35622.953125MB
INFO:root:[  104] Training loss: 0.60229626, Validation loss: 0.61789415, Gradient norm: 0.08817232
INFO:root:At the start of the epoch: mem (CPU python)=35824.375MB; mem (CPU total)=35661.359375MB
INFO:root:[  105] Training loss: 0.60196860, Validation loss: 0.61784071, Gradient norm: 0.07550136
INFO:root:At the start of the epoch: mem (CPU python)=35862.47265625MB; mem (CPU total)=35699.2890625MB
INFO:root:[  106] Training loss: 0.60158728, Validation loss: 0.61742269, Gradient norm: 0.07996787
INFO:root:At the start of the epoch: mem (CPU python)=35900.5703125MB; mem (CPU total)=35737.421875MB
INFO:root:[  107] Training loss: 0.60147722, Validation loss: 0.61794094, Gradient norm: 0.08113304
INFO:root:At the start of the epoch: mem (CPU python)=35938.6640625MB; mem (CPU total)=35775.83984375MB
INFO:root:[  108] Training loss: 0.60092289, Validation loss: 0.61708860, Gradient norm: 0.07429891
INFO:root:At the start of the epoch: mem (CPU python)=35976.7578125MB; mem (CPU total)=35814.0390625MB
INFO:root:[  109] Training loss: 0.60069541, Validation loss: 0.61671789, Gradient norm: 0.07987557
INFO:root:At the start of the epoch: mem (CPU python)=36014.85546875MB; mem (CPU total)=35852.20703125MB
INFO:root:[  110] Training loss: 0.60026828, Validation loss: 0.61730940, Gradient norm: 0.08014637
INFO:root:At the start of the epoch: mem (CPU python)=36052.94921875MB; mem (CPU total)=35890.3671875MB
INFO:root:[  111] Training loss: 0.60030692, Validation loss: 0.61764917, Gradient norm: 0.09196155
INFO:root:At the start of the epoch: mem (CPU python)=36091.04296875MB; mem (CPU total)=35928.80859375MB
INFO:root:[  112] Training loss: 0.59980838, Validation loss: 0.61723018, Gradient norm: 0.08191035
INFO:root:At the start of the epoch: mem (CPU python)=36129.14453125MB; mem (CPU total)=35966.60546875MB
INFO:root:[  113] Training loss: 0.59949800, Validation loss: 0.61659287, Gradient norm: 0.08173574
INFO:root:At the start of the epoch: mem (CPU python)=36167.2421875MB; mem (CPU total)=36004.7578125MB
INFO:root:[  114] Training loss: 0.59942305, Validation loss: 0.61802497, Gradient norm: 0.08634318
INFO:root:At the start of the epoch: mem (CPU python)=36205.3359375MB; mem (CPU total)=36042.97265625MB
INFO:root:[  115] Training loss: 0.59905106, Validation loss: 0.61720382, Gradient norm: 0.08825381
INFO:root:At the start of the epoch: mem (CPU python)=36243.4296875MB; mem (CPU total)=36081.40625MB
INFO:root:[  116] Training loss: 0.59886520, Validation loss: 0.61701642, Gradient norm: 0.08470484
INFO:root:At the start of the epoch: mem (CPU python)=36281.52734375MB; mem (CPU total)=36119.765625MB
INFO:root:[  117] Training loss: 0.59847643, Validation loss: 0.61724021, Gradient norm: 0.09199146
INFO:root:At the start of the epoch: mem (CPU python)=36319.62109375MB; mem (CPU total)=36157.109375MB
INFO:root:[  118] Training loss: 0.59809971, Validation loss: 0.61758525, Gradient norm: 0.08292136
INFO:root:At the start of the epoch: mem (CPU python)=36357.71484375MB; mem (CPU total)=36195.21875MB
INFO:root:[  119] Training loss: 0.59774629, Validation loss: 0.61648186, Gradient norm: 0.08390103
INFO:root:At the start of the epoch: mem (CPU python)=36395.8125MB; mem (CPU total)=36233.37890625MB
INFO:root:[  120] Training loss: 0.59767312, Validation loss: 0.61932433, Gradient norm: 0.08893120
INFO:root:At the start of the epoch: mem (CPU python)=36433.90625MB; mem (CPU total)=36271.59375MB
INFO:root:[  121] Training loss: 0.59739030, Validation loss: 0.61706824, Gradient norm: 0.08851459
INFO:root:At the start of the epoch: mem (CPU python)=36472.0MB; mem (CPU total)=36309.9921875MB
INFO:root:[  122] Training loss: 0.59682402, Validation loss: 0.61664630, Gradient norm: 0.07574230
INFO:root:At the start of the epoch: mem (CPU python)=36510.1015625MB; mem (CPU total)=36348.14453125MB
INFO:root:[  123] Training loss: 0.59661025, Validation loss: 0.61644109, Gradient norm: 0.07534773
INFO:root:At the start of the epoch: mem (CPU python)=36548.1953125MB; mem (CPU total)=36386.23828125MB
INFO:root:[  124] Training loss: 0.59658647, Validation loss: 0.61721048, Gradient norm: 0.07469167
INFO:root:At the start of the epoch: mem (CPU python)=36586.2890625MB; mem (CPU total)=36424.81640625MB
INFO:root:[  125] Training loss: 0.59619354, Validation loss: 0.61629118, Gradient norm: 0.07798192
INFO:root:At the start of the epoch: mem (CPU python)=36624.3828125MB; mem (CPU total)=36462.36328125MB
INFO:root:[  126] Training loss: 0.59590990, Validation loss: 0.61788361, Gradient norm: 0.08895119
INFO:root:At the start of the epoch: mem (CPU python)=36662.48046875MB; mem (CPU total)=36500.97265625MB
INFO:root:[  127] Training loss: 0.59565365, Validation loss: 0.61667589, Gradient norm: 0.08714384
INFO:root:At the start of the epoch: mem (CPU python)=36700.57421875MB; mem (CPU total)=36539.796875MB
INFO:root:[  128] Training loss: 0.59521976, Validation loss: 0.61773267, Gradient norm: 0.08130084
INFO:root:At the start of the epoch: mem (CPU python)=36738.66796875MB; mem (CPU total)=36577.44921875MB
INFO:root:[  129] Training loss: 0.59539766, Validation loss: 0.61847164, Gradient norm: 0.09112190
INFO:root:At the start of the epoch: mem (CPU python)=36776.765625MB; mem (CPU total)=36615.5625MB
INFO:root:[  130] Training loss: 0.59509417, Validation loss: 0.61719642, Gradient norm: 0.07792446
INFO:root:At the start of the epoch: mem (CPU python)=36814.859375MB; mem (CPU total)=36653.87890625MB
INFO:root:[  131] Training loss: 0.59487647, Validation loss: 0.61741864, Gradient norm: 0.08121483
INFO:root:At the start of the epoch: mem (CPU python)=36852.953125MB; mem (CPU total)=36691.91796875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  132] Training loss: 0.59448640, Validation loss: 0.61774362, Gradient norm: 0.08126232
INFO:root:At the start of the epoch: mem (CPU python)=36891.05078125MB; mem (CPU total)=36729.63671875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  133] Training loss: 0.59286371, Validation loss: 0.61624375, Gradient norm: 0.06987137
INFO:root:At the start of the epoch: mem (CPU python)=36929.1484375MB; mem (CPU total)=36767.7421875MB
INFO:root:[  134] Training loss: 0.59201059, Validation loss: 0.61613872, Gradient norm: 0.06666222
INFO:root:At the start of the epoch: mem (CPU python)=36967.2421875MB; mem (CPU total)=36806.34375MB
INFO:root:[  135] Training loss: 0.59161301, Validation loss: 0.61672767, Gradient norm: 0.06648671
INFO:root:At the start of the epoch: mem (CPU python)=37005.3359375MB; mem (CPU total)=36844.46875MB
INFO:root:[  136] Training loss: 0.59190456, Validation loss: 0.61615118, Gradient norm: 0.06877874
INFO:root:At the start of the epoch: mem (CPU python)=37043.43359375MB; mem (CPU total)=36882.859375MB
INFO:root:[  137] Training loss: 0.59146813, Validation loss: 0.61628434, Gradient norm: 0.06684394
INFO:root:At the start of the epoch: mem (CPU python)=37081.53125MB; mem (CPU total)=36920.6796875MB
INFO:root:[  138] Training loss: 0.59154097, Validation loss: 0.61681447, Gradient norm: 0.06745463
INFO:root:At the start of the epoch: mem (CPU python)=37119.625MB; mem (CPU total)=36959.04296875MB
INFO:root:[  139] Training loss: 0.59151148, Validation loss: 0.61697242, Gradient norm: 0.06851081
INFO:root:At the start of the epoch: mem (CPU python)=37157.7265625MB; mem (CPU total)=36997.18359375MB
INFO:root:[  140] Training loss: 0.59122206, Validation loss: 0.61687834, Gradient norm: 0.06417131
INFO:root:At the start of the epoch: mem (CPU python)=37195.8203125MB; mem (CPU total)=37035.578125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  141] Training loss: 0.59118097, Validation loss: 0.61798873, Gradient norm: 0.07287401
INFO:root:At the start of the epoch: mem (CPU python)=37233.9140625MB; mem (CPU total)=37073.71484375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  142] Training loss: 0.59075992, Validation loss: 0.61535321, Gradient norm: 0.06470580
INFO:root:At the start of the epoch: mem (CPU python)=37272.0078125MB; mem (CPU total)=37111.46875MB
INFO:root:[  143] Training loss: 0.59054371, Validation loss: 0.61690128, Gradient norm: 0.06247537
INFO:root:At the start of the epoch: mem (CPU python)=37310.10546875MB; mem (CPU total)=37149.1484375MB
INFO:root:[  144] Training loss: 0.59056250, Validation loss: 0.61601573, Gradient norm: 0.06213438
INFO:root:At the start of the epoch: mem (CPU python)=37348.19921875MB; mem (CPU total)=37187.29296875MB
INFO:root:[  145] Training loss: 0.59036903, Validation loss: 0.61709006, Gradient norm: 0.06271218
INFO:root:At the start of the epoch: mem (CPU python)=37386.29296875MB; mem (CPU total)=37225.51953125MB
INFO:root:[  146] Training loss: 0.59038345, Validation loss: 0.61701523, Gradient norm: 0.06411629
INFO:root:At the start of the epoch: mem (CPU python)=37424.39453125MB; mem (CPU total)=37263.6328125MB
INFO:root:[  147] Training loss: 0.59044654, Validation loss: 0.61724279, Gradient norm: 0.06157332
INFO:root:At the start of the epoch: mem (CPU python)=37462.48828125MB; mem (CPU total)=37301.28125MB
INFO:root:[  148] Training loss: 0.59025912, Validation loss: 0.61601335, Gradient norm: 0.06396921
INFO:root:At the start of the epoch: mem (CPU python)=37500.58203125MB; mem (CPU total)=37339.4140625MB
INFO:root:[  149] Training loss: 0.59047362, Validation loss: 0.61651011, Gradient norm: 0.06351565
INFO:root:At the start of the epoch: mem (CPU python)=37538.67578125MB; mem (CPU total)=37377.8046875MB
INFO:root:[  150] Training loss: 0.59026046, Validation loss: 0.61575895, Gradient norm: 0.06393791
INFO:root:At the start of the epoch: mem (CPU python)=37576.7734375MB; mem (CPU total)=37415.18359375MB
INFO:root:[  151] Training loss: 0.59045959, Validation loss: 0.61637777, Gradient norm: 0.06429147
INFO:root:At the start of the epoch: mem (CPU python)=37614.8671875MB; mem (CPU total)=37454.3046875MB
INFO:root:EP 151: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=37652.9609375MB; mem (CPU total)=37492.203125MB
INFO:root:Training the model took 15828.644s.
INFO:root:Emptying the cuda cache took 0.025s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83825
INFO:root:EnergyScoreTrain: 0.5904
INFO:root:CRPSTrain: 0.50552
INFO:root:Gaussian NLLTrain: 2.32784
INFO:root:CoverageTrain: 0.82683
INFO:root:IntervalWidthTrain: 3.16021
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87549
INFO:root:EnergyScoreValidation: 0.61636
INFO:root:CRPSValidation: 0.52645
INFO:root:Gaussian NLLValidation: 2.38394
INFO:root:CoverageValidation: 0.81501
INFO:root:IntervalWidthValidation: 3.15711
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87771
INFO:root:EnergyScoreTest: 0.618
INFO:root:CRPSTest: 0.52781
INFO:root:Gaussian NLLTest: 2.3844
INFO:root:CoverageTest: 0.81431
INFO:root:IntervalWidthTest: 3.15377
INFO:root:After validation: mem (CPU python)=37695.8046875MB; mem (CPU total)=37534.73828125MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=37695.8046875MB; mem (CPU total)=37534.48828125MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 163577856
INFO:root:After setting up the model: mem (CPU python)=37696.28515625MB; mem (CPU total)=37534.98046875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=37696.28515625MB; mem (CPU total)=37534.88671875MB
INFO:root:[    1] Training loss: 0.79788785, Validation loss: 0.72333804, Gradient norm: 0.37374671
INFO:root:At the start of the epoch: mem (CPU python)=37734.38671875MB; mem (CPU total)=37573.30078125MB
INFO:root:[    2] Training loss: 0.72147727, Validation loss: 0.72134286, Gradient norm: 0.26081698
INFO:root:At the start of the epoch: mem (CPU python)=37772.48828125MB; mem (CPU total)=37611.640625MB
INFO:root:[    3] Training loss: 0.72032127, Validation loss: 0.71978154, Gradient norm: 0.28685647
INFO:root:At the start of the epoch: mem (CPU python)=37810.58203125MB; mem (CPU total)=37649.8359375MB
INFO:root:[    4] Training loss: 0.71982560, Validation loss: 0.71945793, Gradient norm: 0.21020860
INFO:root:At the start of the epoch: mem (CPU python)=37848.67578125MB; mem (CPU total)=37687.765625MB
INFO:root:[    5] Training loss: 0.71946110, Validation loss: 0.71979485, Gradient norm: 0.15743398
INFO:root:At the start of the epoch: mem (CPU python)=37886.7734375MB; mem (CPU total)=37726.18359375MB
INFO:root:[    6] Training loss: 0.71898197, Validation loss: 0.71869375, Gradient norm: 0.16393005
INFO:root:At the start of the epoch: mem (CPU python)=37924.8671875MB; mem (CPU total)=37764.4921875MB
INFO:root:[    7] Training loss: 0.71785156, Validation loss: 0.71667923, Gradient norm: 0.17996121
INFO:root:At the start of the epoch: mem (CPU python)=37962.9609375MB; mem (CPU total)=37802.55859375MB
INFO:root:[    8] Training loss: 0.71441101, Validation loss: 0.71028410, Gradient norm: 0.10094344
INFO:root:At the start of the epoch: mem (CPU python)=38001.0625MB; mem (CPU total)=37841.15625MB
INFO:root:[    9] Training loss: 0.70593151, Validation loss: 0.70201840, Gradient norm: 0.11605335
INFO:root:At the start of the epoch: mem (CPU python)=38039.15625MB; mem (CPU total)=37879.078125MB
INFO:root:[   10] Training loss: 0.69669612, Validation loss: 0.69288867, Gradient norm: 0.08305069
INFO:root:At the start of the epoch: mem (CPU python)=38077.25MB; mem (CPU total)=37917.22265625MB
INFO:root:[   11] Training loss: 0.68872692, Validation loss: 0.68641308, Gradient norm: 0.09596965
INFO:root:At the start of the epoch: mem (CPU python)=38115.34375MB; mem (CPU total)=37955.859375MB
INFO:root:[   12] Training loss: 0.68281034, Validation loss: 0.68129238, Gradient norm: 0.09176646
INFO:root:At the start of the epoch: mem (CPU python)=38153.4453125MB; mem (CPU total)=37993.7265625MB
INFO:root:[   13] Training loss: 0.67769166, Validation loss: 0.67624323, Gradient norm: 0.07764229
INFO:root:At the start of the epoch: mem (CPU python)=38191.5390625MB; mem (CPU total)=38031.5390625MB
INFO:root:[   14] Training loss: 0.67326347, Validation loss: 0.67247469, Gradient norm: 0.07401687
INFO:root:At the start of the epoch: mem (CPU python)=38229.63671875MB; mem (CPU total)=38069.89453125MB
INFO:root:[   15] Training loss: 0.66957402, Validation loss: 0.66915193, Gradient norm: 0.08739733
INFO:root:At the start of the epoch: mem (CPU python)=38267.73046875MB; mem (CPU total)=38107.76171875MB
INFO:root:[   16] Training loss: 0.66604741, Validation loss: 0.66624469, Gradient norm: 0.08522102
INFO:root:At the start of the epoch: mem (CPU python)=38305.828125MB; mem (CPU total)=38146.140625MB
INFO:root:[   17] Training loss: 0.66345827, Validation loss: 0.66433740, Gradient norm: 0.07197812
INFO:root:At the start of the epoch: mem (CPU python)=38343.921875MB; mem (CPU total)=38184.3125MB
INFO:root:[   18] Training loss: 0.66080235, Validation loss: 0.66109660, Gradient norm: 0.07558643
INFO:root:At the start of the epoch: mem (CPU python)=38382.015625MB; mem (CPU total)=38222.453125MB
INFO:root:[   19] Training loss: 0.65866231, Validation loss: 0.66018595, Gradient norm: 0.06731834
INFO:root:At the start of the epoch: mem (CPU python)=38420.11328125MB; mem (CPU total)=38261.34765625MB
INFO:root:[   20] Training loss: 0.65678094, Validation loss: 0.65760457, Gradient norm: 0.07489234
INFO:root:At the start of the epoch: mem (CPU python)=38458.2109375MB; mem (CPU total)=38299.48046875MB
INFO:root:[   21] Training loss: 0.65488906, Validation loss: 0.65610599, Gradient norm: 0.07481828
INFO:root:At the start of the epoch: mem (CPU python)=38496.3046875MB; mem (CPU total)=38337.37109375MB
INFO:root:[   22] Training loss: 0.65349649, Validation loss: 0.65580625, Gradient norm: 0.07407386
INFO:root:At the start of the epoch: mem (CPU python)=38534.40234375MB; mem (CPU total)=38375.7578125MB
INFO:root:[   23] Training loss: 0.65193339, Validation loss: 0.65354629, Gradient norm: 0.06956369
INFO:root:At the start of the epoch: mem (CPU python)=38572.49609375MB; mem (CPU total)=38413.89453125MB
INFO:root:[   24] Training loss: 0.65036154, Validation loss: 0.65318494, Gradient norm: 0.06942122
INFO:root:At the start of the epoch: mem (CPU python)=38610.58984375MB; mem (CPU total)=38452.4375MB
INFO:root:[   25] Training loss: 0.64920023, Validation loss: 0.65155317, Gradient norm: 0.06934041
INFO:root:At the start of the epoch: mem (CPU python)=38648.69140625MB; mem (CPU total)=38490.49609375MB
INFO:root:[   26] Training loss: 0.64785483, Validation loss: 0.64999320, Gradient norm: 0.06100846
INFO:root:At the start of the epoch: mem (CPU python)=38686.78515625MB; mem (CPU total)=38528.8828125MB
INFO:root:[   27] Training loss: 0.64663852, Validation loss: 0.64905441, Gradient norm: 0.07209236
INFO:root:At the start of the epoch: mem (CPU python)=38724.87890625MB; mem (CPU total)=38566.75MB
INFO:root:[   28] Training loss: 0.64553728, Validation loss: 0.64779360, Gradient norm: 0.07716768
INFO:root:At the start of the epoch: mem (CPU python)=38762.97265625MB; mem (CPU total)=38604.88671875MB
INFO:root:[   29] Training loss: 0.64442097, Validation loss: 0.64713473, Gradient norm: 0.06685881
INFO:root:At the start of the epoch: mem (CPU python)=38801.0703125MB; mem (CPU total)=38643.296875MB
INFO:root:[   30] Training loss: 0.64350088, Validation loss: 0.64657797, Gradient norm: 0.06234143
INFO:root:At the start of the epoch: mem (CPU python)=38839.1640625MB; mem (CPU total)=38681.4921875MB
INFO:root:[   31] Training loss: 0.64246052, Validation loss: 0.64569698, Gradient norm: 0.07915293
INFO:root:At the start of the epoch: mem (CPU python)=38877.2578125MB; mem (CPU total)=38719.71875MB
INFO:root:[   32] Training loss: 0.64155863, Validation loss: 0.64487515, Gradient norm: 0.07138909
INFO:root:At the start of the epoch: mem (CPU python)=38915.359375MB; mem (CPU total)=38757.37109375MB
INFO:root:[   33] Training loss: 0.64062244, Validation loss: 0.64474964, Gradient norm: 0.06993086
INFO:root:At the start of the epoch: mem (CPU python)=38953.453125MB; mem (CPU total)=38795.55078125MB
INFO:root:[   34] Training loss: 0.63964985, Validation loss: 0.64336267, Gradient norm: 0.06142265
INFO:root:At the start of the epoch: mem (CPU python)=38991.546875MB; mem (CPU total)=38832.2890625MB
INFO:root:[   35] Training loss: 0.63864393, Validation loss: 0.64287247, Gradient norm: 0.06853341
INFO:root:At the start of the epoch: mem (CPU python)=39029.640625MB; mem (CPU total)=38870.73828125MB
INFO:root:[   36] Training loss: 0.63786143, Validation loss: 0.64255515, Gradient norm: 0.06929668
INFO:root:At the start of the epoch: mem (CPU python)=39067.73828125MB; mem (CPU total)=38908.80859375MB
INFO:root:[   37] Training loss: 0.63705562, Validation loss: 0.64179007, Gradient norm: 0.06833932
INFO:root:At the start of the epoch: mem (CPU python)=39105.83203125MB; mem (CPU total)=38946.44140625MB
INFO:root:[   38] Training loss: 0.63600480, Validation loss: 0.64086608, Gradient norm: 0.06861866
INFO:root:At the start of the epoch: mem (CPU python)=39143.92578125MB; mem (CPU total)=38985.02734375MB
INFO:root:[   39] Training loss: 0.63544562, Validation loss: 0.64032551, Gradient norm: 0.07692953
INFO:root:At the start of the epoch: mem (CPU python)=39182.02734375MB; mem (CPU total)=39023.47265625MB
INFO:root:[   40] Training loss: 0.63440791, Validation loss: 0.63918619, Gradient norm: 0.06705616
INFO:root:At the start of the epoch: mem (CPU python)=39220.12109375MB; mem (CPU total)=39061.85546875MB
INFO:root:[   41] Training loss: 0.63388977, Validation loss: 0.63886523, Gradient norm: 0.07162963
INFO:root:At the start of the epoch: mem (CPU python)=39258.21484375MB; mem (CPU total)=39099.5234375MB
INFO:root:[   42] Training loss: 0.63304416, Validation loss: 0.63799721, Gradient norm: 0.07204452
INFO:root:At the start of the epoch: mem (CPU python)=39296.3125MB; mem (CPU total)=39137.4453125MB
INFO:root:[   43] Training loss: 0.63234750, Validation loss: 0.63773148, Gradient norm: 0.06845687
INFO:root:At the start of the epoch: mem (CPU python)=39334.40625MB; mem (CPU total)=39175.8359375MB
INFO:root:[   44] Training loss: 0.63148905, Validation loss: 0.63679620, Gradient norm: 0.07246552
INFO:root:At the start of the epoch: mem (CPU python)=39372.5MB; mem (CPU total)=39214.203125MB
INFO:root:[   45] Training loss: 0.63063349, Validation loss: 0.63708694, Gradient norm: 0.06365973
INFO:root:At the start of the epoch: mem (CPU python)=39410.59375MB; mem (CPU total)=39252.5546875MB
INFO:root:[   46] Training loss: 0.63038010, Validation loss: 0.63652590, Gradient norm: 0.07408771
INFO:root:At the start of the epoch: mem (CPU python)=39448.69140625MB; mem (CPU total)=39291.2109375MB
INFO:root:[   47] Training loss: 0.62952737, Validation loss: 0.63570676, Gradient norm: 0.07379325
INFO:root:At the start of the epoch: mem (CPU python)=39486.78515625MB; mem (CPU total)=39328.953125MB
INFO:root:[   48] Training loss: 0.62893502, Validation loss: 0.63502860, Gradient norm: 0.06501593
INFO:root:At the start of the epoch: mem (CPU python)=39524.87890625MB; mem (CPU total)=39367.33984375MB
INFO:root:[   49] Training loss: 0.62813290, Validation loss: 0.63393052, Gradient norm: 0.06543583
INFO:root:At the start of the epoch: mem (CPU python)=39562.98046875MB; mem (CPU total)=39405.71484375MB
INFO:root:[   50] Training loss: 0.62763718, Validation loss: 0.63467575, Gradient norm: 0.07054305
INFO:root:At the start of the epoch: mem (CPU python)=39601.07421875MB; mem (CPU total)=39443.859375MB
INFO:root:[   51] Training loss: 0.62697049, Validation loss: 0.63317251, Gradient norm: 0.06866969
INFO:root:At the start of the epoch: mem (CPU python)=39639.16796875MB; mem (CPU total)=39481.296875MB
INFO:root:[   52] Training loss: 0.62640798, Validation loss: 0.63265102, Gradient norm: 0.06930861
INFO:root:At the start of the epoch: mem (CPU python)=39677.26171875MB; mem (CPU total)=39519.0625MB
INFO:root:[   53] Training loss: 0.62579565, Validation loss: 0.63338723, Gradient norm: 0.06860141
INFO:root:At the start of the epoch: mem (CPU python)=39715.359375MB; mem (CPU total)=39556.9453125MB
INFO:root:[   54] Training loss: 0.62513504, Validation loss: 0.63232355, Gradient norm: 0.06881006
INFO:root:At the start of the epoch: mem (CPU python)=39753.453125MB; mem (CPU total)=39595.2578125MB
INFO:root:[   55] Training loss: 0.62475299, Validation loss: 0.63249643, Gradient norm: 0.06989735
INFO:root:At the start of the epoch: mem (CPU python)=39791.546875MB; mem (CPU total)=39633.8203125MB
INFO:root:[   56] Training loss: 0.62402403, Validation loss: 0.63204060, Gradient norm: 0.07110073
INFO:root:At the start of the epoch: mem (CPU python)=39829.64453125MB; mem (CPU total)=39671.984375MB
INFO:root:[   57] Training loss: 0.62359888, Validation loss: 0.63125217, Gradient norm: 0.06921125
INFO:root:At the start of the epoch: mem (CPU python)=39867.7421875MB; mem (CPU total)=39709.9296875MB
INFO:root:[   58] Training loss: 0.62289686, Validation loss: 0.63081175, Gradient norm: 0.06825862
INFO:root:At the start of the epoch: mem (CPU python)=39905.8359375MB; mem (CPU total)=39747.828125MB
INFO:root:[   59] Training loss: 0.62246753, Validation loss: 0.62982246, Gradient norm: 0.06290111
INFO:root:At the start of the epoch: mem (CPU python)=39943.93359375MB; mem (CPU total)=39785.9609375MB
INFO:root:[   60] Training loss: 0.62214684, Validation loss: 0.63074112, Gradient norm: 0.06959066
INFO:root:At the start of the epoch: mem (CPU python)=39982.02734375MB; mem (CPU total)=39824.3515625MB
INFO:root:[   61] Training loss: 0.62153289, Validation loss: 0.63001322, Gradient norm: 0.06730686
INFO:root:At the start of the epoch: mem (CPU python)=40020.12109375MB; mem (CPU total)=39862.48828125MB
INFO:root:[   62] Training loss: 0.62101445, Validation loss: 0.62953119, Gradient norm: 0.07187849
INFO:root:At the start of the epoch: mem (CPU python)=40058.21875MB; mem (CPU total)=39900.80859375MB
INFO:root:[   63] Training loss: 0.62060536, Validation loss: 0.62867124, Gradient norm: 0.06435075
INFO:root:At the start of the epoch: mem (CPU python)=40096.31640625MB; mem (CPU total)=39939.15625MB
INFO:root:[   64] Training loss: 0.62002490, Validation loss: 0.62852675, Gradient norm: 0.06876847
INFO:root:At the start of the epoch: mem (CPU python)=40134.41015625MB; mem (CPU total)=39977.7421875MB
INFO:root:[   65] Training loss: 0.61935927, Validation loss: 0.62907641, Gradient norm: 0.06421390
INFO:root:At the start of the epoch: mem (CPU python)=40172.50390625MB; mem (CPU total)=40015.8671875MB
INFO:root:[   66] Training loss: 0.61919349, Validation loss: 0.62884303, Gradient norm: 0.06906602
INFO:root:At the start of the epoch: mem (CPU python)=40210.60546875MB; mem (CPU total)=40053.93359375MB
INFO:root:[   67] Training loss: 0.61885065, Validation loss: 0.62842216, Gradient norm: 0.06712732
INFO:root:At the start of the epoch: mem (CPU python)=40248.69921875MB; mem (CPU total)=40092.3046875MB
INFO:root:[   68] Training loss: 0.61830505, Validation loss: 0.62801601, Gradient norm: 0.06698628
INFO:root:At the start of the epoch: mem (CPU python)=40286.79296875MB; mem (CPU total)=40130.2265625MB
INFO:root:[   69] Training loss: 0.61782276, Validation loss: 0.62771072, Gradient norm: 0.06960269
INFO:root:At the start of the epoch: mem (CPU python)=40324.88671875MB; mem (CPU total)=40168.1484375MB
INFO:root:[   70] Training loss: 0.61758123, Validation loss: 0.62730166, Gradient norm: 0.06230461
INFO:root:At the start of the epoch: mem (CPU python)=40362.984375MB; mem (CPU total)=40206.07421875MB
INFO:root:[   71] Training loss: 0.61683100, Validation loss: 0.62750664, Gradient norm: 0.07246746
INFO:root:At the start of the epoch: mem (CPU python)=40401.078125MB; mem (CPU total)=40244.41015625MB
INFO:root:[   72] Training loss: 0.61656491, Validation loss: 0.62703219, Gradient norm: 0.07250807
INFO:root:At the start of the epoch: mem (CPU python)=40439.17578125MB; mem (CPU total)=40282.69921875MB
INFO:root:[   73] Training loss: 0.61606249, Validation loss: 0.62582944, Gradient norm: 0.07302649
INFO:root:At the start of the epoch: mem (CPU python)=40477.2734375MB; mem (CPU total)=40320.54296875MB
INFO:root:[   74] Training loss: 0.61581718, Validation loss: 0.62622843, Gradient norm: 0.06752292
INFO:root:At the start of the epoch: mem (CPU python)=40515.3671875MB; mem (CPU total)=40359.10546875MB
INFO:root:[   75] Training loss: 0.61520761, Validation loss: 0.62625863, Gradient norm: 0.06513900
INFO:root:At the start of the epoch: mem (CPU python)=40553.4609375MB; mem (CPU total)=40396.96484375MB
INFO:root:[   76] Training loss: 0.61497459, Validation loss: 0.62638795, Gradient norm: 0.06920500
INFO:root:At the start of the epoch: mem (CPU python)=40591.55859375MB; mem (CPU total)=40435.8125MB
INFO:root:[   77] Training loss: 0.61470511, Validation loss: 0.62559889, Gradient norm: 0.06450755
INFO:root:At the start of the epoch: mem (CPU python)=40629.65234375MB; mem (CPU total)=40473.7109375MB
INFO:root:[   78] Training loss: 0.61412047, Validation loss: 0.62516657, Gradient norm: 0.06894554
INFO:root:At the start of the epoch: mem (CPU python)=40667.74609375MB; mem (CPU total)=40511.8515625MB
INFO:root:[   79] Training loss: 0.61374173, Validation loss: 0.62453487, Gradient norm: 0.06213219
INFO:root:At the start of the epoch: mem (CPU python)=40705.83984375MB; mem (CPU total)=40550.4609375MB
INFO:root:[   80] Training loss: 0.61351931, Validation loss: 0.62494229, Gradient norm: 0.07509485
INFO:root:At the start of the epoch: mem (CPU python)=40743.9375MB; mem (CPU total)=40588.328125MB
INFO:root:[   81] Training loss: 0.61309375, Validation loss: 0.62509292, Gradient norm: 0.07000379
INFO:root:At the start of the epoch: mem (CPU python)=40782.03515625MB; mem (CPU total)=40626.71875MB
INFO:root:[   82] Training loss: 0.61255755, Validation loss: 0.62435962, Gradient norm: 0.07377025
INFO:root:At the start of the epoch: mem (CPU python)=40820.125MB; mem (CPU total)=40665.1640625MB
INFO:root:[   83] Training loss: 0.61207544, Validation loss: 0.62467770, Gradient norm: 0.07107135
INFO:root:At the start of the epoch: mem (CPU python)=40858.2265625MB; mem (CPU total)=40703.640625MB
INFO:root:[   84] Training loss: 0.61182321, Validation loss: 0.62379471, Gradient norm: 0.06793162
INFO:root:At the start of the epoch: mem (CPU python)=40896.3203125MB; mem (CPU total)=40741.8515625MB
INFO:root:[   85] Training loss: 0.61158400, Validation loss: 0.62348781, Gradient norm: 0.06558562
INFO:root:At the start of the epoch: mem (CPU python)=40934.4140625MB; mem (CPU total)=40779.6171875MB
INFO:root:[   86] Training loss: 0.61085449, Validation loss: 0.62319318, Gradient norm: 0.06380988
INFO:root:At the start of the epoch: mem (CPU python)=40972.5078125MB; mem (CPU total)=40817.79296875MB
INFO:root:[   87] Training loss: 0.61093089, Validation loss: 0.62289393, Gradient norm: 0.06727315
INFO:root:At the start of the epoch: mem (CPU python)=41010.60546875MB; mem (CPU total)=40856.1015625MB
INFO:root:[   88] Training loss: 0.61040727, Validation loss: 0.62452621, Gradient norm: 0.06927916
INFO:root:At the start of the epoch: mem (CPU python)=41048.69921875MB; mem (CPU total)=40894.24609375MB
INFO:root:[   89] Training loss: 0.61025706, Validation loss: 0.62380646, Gradient norm: 0.07061943
INFO:root:At the start of the epoch: mem (CPU python)=41086.79296875MB; mem (CPU total)=40932.35546875MB
INFO:root:[   90] Training loss: 0.60989285, Validation loss: 0.62388140, Gradient norm: 0.07297149
INFO:root:At the start of the epoch: mem (CPU python)=41124.890625MB; mem (CPU total)=40970.40625MB
INFO:root:[   91] Training loss: 0.60934732, Validation loss: 0.62437711, Gradient norm: 0.06826347
INFO:root:At the start of the epoch: mem (CPU python)=41162.984375MB; mem (CPU total)=41008.54296875MB
INFO:root:[   92] Training loss: 0.60908611, Validation loss: 0.62232621, Gradient norm: 0.06807044
INFO:root:At the start of the epoch: mem (CPU python)=41201.08203125MB; mem (CPU total)=41046.71875MB
INFO:root:[   93] Training loss: 0.60873139, Validation loss: 0.62194161, Gradient norm: 0.07301548
INFO:root:At the start of the epoch: mem (CPU python)=41239.1796875MB; mem (CPU total)=41085.109375MB
INFO:root:[   94] Training loss: 0.60833551, Validation loss: 0.62235005, Gradient norm: 0.07044804
INFO:root:At the start of the epoch: mem (CPU python)=41277.2734375MB; mem (CPU total)=41123.16015625MB
INFO:root:[   95] Training loss: 0.60769635, Validation loss: 0.62286142, Gradient norm: 0.07031532
INFO:root:At the start of the epoch: mem (CPU python)=41315.3671875MB; mem (CPU total)=41161.63671875MB
INFO:root:[   96] Training loss: 0.60746908, Validation loss: 0.62292426, Gradient norm: 0.06879802
INFO:root:At the start of the epoch: mem (CPU python)=41353.4609375MB; mem (CPU total)=41199.9375MB
INFO:root:[   97] Training loss: 0.60741956, Validation loss: 0.62213239, Gradient norm: 0.06813991
INFO:root:At the start of the epoch: mem (CPU python)=41391.55859375MB; mem (CPU total)=41237.953125MB
INFO:root:[   98] Training loss: 0.60696603, Validation loss: 0.62258504, Gradient norm: 0.07182231
INFO:root:At the start of the epoch: mem (CPU python)=41429.65625MB; mem (CPU total)=41276.09765625MB
INFO:root:[   99] Training loss: 0.60649122, Validation loss: 0.62179480, Gradient norm: 0.06597844
INFO:root:At the start of the epoch: mem (CPU python)=41467.75MB; mem (CPU total)=41314.46484375MB
INFO:root:[  100] Training loss: 0.60630524, Validation loss: 0.62226186, Gradient norm: 0.07230120
INFO:root:At the start of the epoch: mem (CPU python)=41505.84765625MB; mem (CPU total)=41352.640625MB
INFO:root:[  101] Training loss: 0.60591221, Validation loss: 0.62258887, Gradient norm: 0.06903482
INFO:root:At the start of the epoch: mem (CPU python)=41543.94140625MB; mem (CPU total)=41390.26171875MB
INFO:root:[  102] Training loss: 0.60556887, Validation loss: 0.62126063, Gradient norm: 0.07541510
INFO:root:At the start of the epoch: mem (CPU python)=41582.03515625MB; mem (CPU total)=41428.890625MB
INFO:root:[  103] Training loss: 0.60555652, Validation loss: 0.62061647, Gradient norm: 0.06458060
INFO:root:At the start of the epoch: mem (CPU python)=41620.12890625MB; mem (CPU total)=41467.12109375MB
INFO:root:[  104] Training loss: 0.60506298, Validation loss: 0.62171456, Gradient norm: 0.06866429
INFO:root:At the start of the epoch: mem (CPU python)=41658.23046875MB; mem (CPU total)=41504.7421875MB
INFO:root:[  105] Training loss: 0.60447112, Validation loss: 0.62159540, Gradient norm: 0.06629936
INFO:root:At the start of the epoch: mem (CPU python)=41696.32421875MB; mem (CPU total)=41543.08984375MB
INFO:root:[  106] Training loss: 0.60433113, Validation loss: 0.62237698, Gradient norm: 0.07470426
INFO:root:At the start of the epoch: mem (CPU python)=41734.41796875MB; mem (CPU total)=41581.46875MB
INFO:root:[  107] Training loss: 0.60414065, Validation loss: 0.62087779, Gradient norm: 0.06786545
INFO:root:At the start of the epoch: mem (CPU python)=41772.51953125MB; mem (CPU total)=41619.8515625MB
INFO:root:[  108] Training loss: 0.60365632, Validation loss: 0.62046154, Gradient norm: 0.07053573
INFO:root:At the start of the epoch: mem (CPU python)=41810.61328125MB; mem (CPU total)=41658.2421875MB
INFO:root:[  109] Training loss: 0.60316212, Validation loss: 0.62160991, Gradient norm: 0.06581685
INFO:root:At the start of the epoch: mem (CPU python)=41848.70703125MB; mem (CPU total)=41696.3828125MB
INFO:root:[  110] Training loss: 0.60330900, Validation loss: 0.62158018, Gradient norm: 0.07148135
INFO:root:At the start of the epoch: mem (CPU python)=41886.8046875MB; mem (CPU total)=41734.00390625MB
INFO:root:[  111] Training loss: 0.60256659, Validation loss: 0.62122274, Gradient norm: 0.06851939
INFO:root:At the start of the epoch: mem (CPU python)=41924.8984375MB; mem (CPU total)=41772.5234375MB
INFO:root:[  112] Training loss: 0.60277816, Validation loss: 0.62095701, Gradient norm: 0.07303068
INFO:root:At the start of the epoch: mem (CPU python)=41962.9921875MB; mem (CPU total)=41810.53515625MB
INFO:root:[  113] Training loss: 0.60218580, Validation loss: 0.62092594, Gradient norm: 0.07576439
INFO:root:At the start of the epoch: mem (CPU python)=42001.0859375MB; mem (CPU total)=41848.92578125MB
INFO:root:[  114] Training loss: 0.60216900, Validation loss: 0.62056289, Gradient norm: 0.07463742
INFO:root:At the start of the epoch: mem (CPU python)=42039.1875MB; mem (CPU total)=41887.3125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  115] Training loss: 0.60177621, Validation loss: 0.62050733, Gradient norm: 0.07316666
INFO:root:At the start of the epoch: mem (CPU python)=42077.28125MB; mem (CPU total)=41925.66796875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  116] Training loss: 0.60010019, Validation loss: 0.62092971, Gradient norm: 0.06738945
INFO:root:At the start of the epoch: mem (CPU python)=42115.375MB; mem (CPU total)=41963.30859375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  117] Training loss: 0.59922342, Validation loss: 0.61998632, Gradient norm: 0.05957779
INFO:root:At the start of the epoch: mem (CPU python)=42153.47265625MB; mem (CPU total)=42001.7109375MB
INFO:root:[  118] Training loss: 0.59874053, Validation loss: 0.62006660, Gradient norm: 0.05565803
INFO:root:At the start of the epoch: mem (CPU python)=42191.56640625MB; mem (CPU total)=42040.31640625MB
INFO:root:[  119] Training loss: 0.59879715, Validation loss: 0.61949712, Gradient norm: 0.05597439
INFO:root:At the start of the epoch: mem (CPU python)=42229.66015625MB; mem (CPU total)=42078.484375MB
INFO:root:[  120] Training loss: 0.59840320, Validation loss: 0.62081608, Gradient norm: 0.05692632
INFO:root:At the start of the epoch: mem (CPU python)=42267.75390625MB; mem (CPU total)=42116.73046875MB
INFO:root:[  121] Training loss: 0.59836761, Validation loss: 0.61964328, Gradient norm: 0.05653569
INFO:root:At the start of the epoch: mem (CPU python)=42305.8515625MB; mem (CPU total)=42154.35546875MB
INFO:root:[  122] Training loss: 0.59854223, Validation loss: 0.61937319, Gradient norm: 0.05743291
INFO:root:At the start of the epoch: mem (CPU python)=42343.9453125MB; mem (CPU total)=42192.29296875MB
INFO:root:[  123] Training loss: 0.59835761, Validation loss: 0.61907047, Gradient norm: 0.05709675
INFO:root:At the start of the epoch: mem (CPU python)=42382.0390625MB; mem (CPU total)=42230.9296875MB
INFO:root:[  124] Training loss: 0.59836396, Validation loss: 0.61972216, Gradient norm: 0.05809479
INFO:root:At the start of the epoch: mem (CPU python)=42420.13671875MB; mem (CPU total)=42269.05859375MB
INFO:root:[  125] Training loss: 0.59808099, Validation loss: 0.61987865, Gradient norm: 0.05622862
INFO:root:At the start of the epoch: mem (CPU python)=42458.234375MB; mem (CPU total)=42307.1796875MB
INFO:root:[  126] Training loss: 0.59809556, Validation loss: 0.62070902, Gradient norm: 0.05753927
INFO:root:At the start of the epoch: mem (CPU python)=42496.33203125MB; mem (CPU total)=42345.234375MB
INFO:root:[  127] Training loss: 0.59812209, Validation loss: 0.62025496, Gradient norm: 0.05706351
INFO:root:At the start of the epoch: mem (CPU python)=42534.4296875MB; mem (CPU total)=42383.421875MB
INFO:root:[  128] Training loss: 0.59804003, Validation loss: 0.61998646, Gradient norm: 0.05758478
INFO:root:At the start of the epoch: mem (CPU python)=42572.5234375MB; mem (CPU total)=42421.6796875MB
INFO:root:[  129] Training loss: 0.59802978, Validation loss: 0.61942678, Gradient norm: 0.05616111
INFO:root:At the start of the epoch: mem (CPU python)=42610.6171875MB; mem (CPU total)=42459.5625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  130] Training loss: 0.59814130, Validation loss: 0.62028311, Gradient norm: 0.05855701
INFO:root:At the start of the epoch: mem (CPU python)=42648.7109375MB; mem (CPU total)=42497.953125MB
INFO:root:[  131] Training loss: 0.59784355, Validation loss: 0.62121846, Gradient norm: 0.05715587
INFO:root:At the start of the epoch: mem (CPU python)=42686.80859375MB; mem (CPU total)=42535.8359375MB
INFO:root:[  132] Training loss: 0.59767527, Validation loss: 0.61985651, Gradient norm: 0.05552511
INFO:root:At the start of the epoch: mem (CPU python)=42724.90234375MB; mem (CPU total)=42573.9765625MB
INFO:root:EP 132: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=42763.0MB; mem (CPU total)=42612.578125MB
INFO:root:Training the model took 14667.782s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84901
INFO:root:EnergyScoreTrain: 0.59796
INFO:root:CRPSTrain: 0.51753
INFO:root:Gaussian NLLTrain: 2.50981
INFO:root:CoverageTrain: 0.809
INFO:root:IntervalWidthTrain: 3.13011
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.88028
INFO:root:EnergyScoreValidation: 0.61988
INFO:root:CRPSValidation: 0.53529
INFO:root:Gaussian NLLValidation: 2.56506
INFO:root:CoverageValidation: 0.79888
INFO:root:IntervalWidthValidation: 3.12411
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88103
INFO:root:EnergyScoreTest: 0.62046
INFO:root:CRPSTest: 0.5357
INFO:root:Gaussian NLLTest: 2.56375
INFO:root:CoverageTest: 0.79876
INFO:root:IntervalWidthTest: 3.12167
INFO:root:After validation: mem (CPU python)=42805.8984375MB; mem (CPU total)=42655.328125MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=42805.8984375MB; mem (CPU total)=42655.3515625MB
INFO:root:NumberParameters: 231589
INFO:root:GPU memory allocated: 161480704
INFO:root:After setting up the model: mem (CPU python)=42806.33984375MB; mem (CPU total)=42655.3515625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=42806.33984375MB; mem (CPU total)=42655.4453125MB
INFO:root:[    1] Training loss: 0.76536178, Validation loss: 0.72237686, Gradient norm: 0.76855553
INFO:root:At the start of the epoch: mem (CPU python)=42845.9375MB; mem (CPU total)=42695.6796875MB
INFO:root:[    2] Training loss: 0.72109134, Validation loss: 0.71975517, Gradient norm: 0.47460657
INFO:root:At the start of the epoch: mem (CPU python)=42884.0390625MB; mem (CPU total)=42733.8671875MB
INFO:root:[    3] Training loss: 0.71982915, Validation loss: 0.71989724, Gradient norm: 0.34675758
INFO:root:At the start of the epoch: mem (CPU python)=42922.140625MB; mem (CPU total)=42772.21875MB
INFO:root:[    4] Training loss: 0.71928649, Validation loss: 0.71902384, Gradient norm: 0.27803175
INFO:root:At the start of the epoch: mem (CPU python)=42960.234375MB; mem (CPU total)=42810.39453125MB
INFO:root:[    5] Training loss: 0.71849804, Validation loss: 0.71785384, Gradient norm: 0.21500517
INFO:root:At the start of the epoch: mem (CPU python)=42998.3359375MB; mem (CPU total)=42848.32421875MB
INFO:root:[    6] Training loss: 0.71580217, Validation loss: 0.71272252, Gradient norm: 0.31049352
INFO:root:At the start of the epoch: mem (CPU python)=43036.4296875MB; mem (CPU total)=42886.4609375MB
INFO:root:[    7] Training loss: 0.70881042, Validation loss: 0.70398797, Gradient norm: 0.22624122
INFO:root:At the start of the epoch: mem (CPU python)=43074.5234375MB; mem (CPU total)=42924.8046875MB
INFO:root:[    8] Training loss: 0.69884662, Validation loss: 0.69498912, Gradient norm: 0.18356077
INFO:root:At the start of the epoch: mem (CPU python)=43112.6171875MB; mem (CPU total)=42963.40234375MB
INFO:root:[    9] Training loss: 0.69016193, Validation loss: 0.68754031, Gradient norm: 0.14102893
INFO:root:At the start of the epoch: mem (CPU python)=43150.71484375MB; mem (CPU total)=43001.6875MB
INFO:root:[   10] Training loss: 0.68353145, Validation loss: 0.68104400, Gradient norm: 0.11980032
INFO:root:At the start of the epoch: mem (CPU python)=43188.80859375MB; mem (CPU total)=43041.10546875MB
INFO:root:[   11] Training loss: 0.67750500, Validation loss: 0.67584564, Gradient norm: 0.14381225
INFO:root:At the start of the epoch: mem (CPU python)=43226.90625MB; mem (CPU total)=43079.26171875MB
INFO:root:[   12] Training loss: 0.67231394, Validation loss: 0.67189941, Gradient norm: 0.12224770
INFO:root:At the start of the epoch: mem (CPU python)=43265.00390625MB; mem (CPU total)=43117.69140625MB
INFO:root:[   13] Training loss: 0.66830852, Validation loss: 0.66683931, Gradient norm: 0.11170505
INFO:root:At the start of the epoch: mem (CPU python)=43303.09765625MB; mem (CPU total)=43156.03515625MB
INFO:root:[   14] Training loss: 0.66505266, Validation loss: 0.66501316, Gradient norm: 0.10183200
INFO:root:At the start of the epoch: mem (CPU python)=43341.19140625MB; mem (CPU total)=43194.17578125MB
INFO:root:[   15] Training loss: 0.66208920, Validation loss: 0.66290029, Gradient norm: 0.12289998
INFO:root:At the start of the epoch: mem (CPU python)=43379.2890625MB; mem (CPU total)=43231.83984375MB
INFO:root:[   16] Training loss: 0.65949814, Validation loss: 0.65983681, Gradient norm: 0.10884600
INFO:root:At the start of the epoch: mem (CPU python)=43417.3828125MB; mem (CPU total)=43270.0703125MB
INFO:root:[   17] Training loss: 0.65741535, Validation loss: 0.65803768, Gradient norm: 0.11236619
INFO:root:At the start of the epoch: mem (CPU python)=43455.4765625MB; mem (CPU total)=43308.5MB
INFO:root:[   18] Training loss: 0.65524775, Validation loss: 0.65625820, Gradient norm: 0.09837675
INFO:root:At the start of the epoch: mem (CPU python)=43493.57421875MB; mem (CPU total)=43347.1796875MB
INFO:root:[   19] Training loss: 0.65328421, Validation loss: 0.65494929, Gradient norm: 0.08818010
INFO:root:At the start of the epoch: mem (CPU python)=43531.671875MB; mem (CPU total)=43385.28125MB
INFO:root:[   20] Training loss: 0.65176371, Validation loss: 0.65306137, Gradient norm: 0.08214618
INFO:root:At the start of the epoch: mem (CPU python)=43569.765625MB; mem (CPU total)=43423.22265625MB
INFO:root:[   21] Training loss: 0.65011790, Validation loss: 0.65237815, Gradient norm: 0.07367378
INFO:root:At the start of the epoch: mem (CPU python)=43607.859375MB; mem (CPU total)=43461.16796875MB
INFO:root:[   22] Training loss: 0.64856916, Validation loss: 0.65096490, Gradient norm: 0.07691191
INFO:root:At the start of the epoch: mem (CPU python)=43645.9609375MB; mem (CPU total)=43498.83203125MB
INFO:root:[   23] Training loss: 0.64698762, Validation loss: 0.64849640, Gradient norm: 0.07217340
INFO:root:At the start of the epoch: mem (CPU python)=43684.0546875MB; mem (CPU total)=43536.828125MB
INFO:root:[   24] Training loss: 0.64575262, Validation loss: 0.64691629, Gradient norm: 0.08306311
INFO:root:At the start of the epoch: mem (CPU python)=43722.1484375MB; mem (CPU total)=43575.17578125MB
INFO:root:[   25] Training loss: 0.64434804, Validation loss: 0.64642782, Gradient norm: 0.07810947
INFO:root:At the start of the epoch: mem (CPU python)=43760.2421875MB; mem (CPU total)=43612.99609375MB
INFO:root:[   26] Training loss: 0.64286790, Validation loss: 0.64564453, Gradient norm: 0.07097592
INFO:root:At the start of the epoch: mem (CPU python)=43798.34375MB; mem (CPU total)=43650.9375MB
INFO:root:[   27] Training loss: 0.64201768, Validation loss: 0.64550890, Gradient norm: 0.07930188
INFO:root:At the start of the epoch: mem (CPU python)=43836.4375MB; mem (CPU total)=43688.875MB
INFO:root:[   28] Training loss: 0.64087435, Validation loss: 0.64361813, Gradient norm: 0.07348782
INFO:root:At the start of the epoch: mem (CPU python)=43874.53125MB; mem (CPU total)=43727.1015625MB
INFO:root:[   29] Training loss: 0.63962904, Validation loss: 0.64358746, Gradient norm: 0.08561773
INFO:root:At the start of the epoch: mem (CPU python)=43912.62890625MB; mem (CPU total)=43765.23046875MB
INFO:root:[   30] Training loss: 0.63844505, Validation loss: 0.64254906, Gradient norm: 0.07846370
INFO:root:At the start of the epoch: mem (CPU python)=43950.72265625MB; mem (CPU total)=43803.03515625MB
INFO:root:[   31] Training loss: 0.63730729, Validation loss: 0.64157228, Gradient norm: 0.07493091
INFO:root:At the start of the epoch: mem (CPU python)=43988.81640625MB; mem (CPU total)=43841.3828125MB
INFO:root:[   32] Training loss: 0.63640976, Validation loss: 0.64066127, Gradient norm: 0.07332772
INFO:root:At the start of the epoch: mem (CPU python)=44026.9140625MB; mem (CPU total)=43879.80078125MB
INFO:root:[   33] Training loss: 0.63531043, Validation loss: 0.63966954, Gradient norm: 0.07665254
INFO:root:At the start of the epoch: mem (CPU python)=44065.0078125MB; mem (CPU total)=43918.05859375MB
INFO:root:[   34] Training loss: 0.63435907, Validation loss: 0.63844713, Gradient norm: 0.08525146
INFO:root:At the start of the epoch: mem (CPU python)=44103.10546875MB; mem (CPU total)=43956.67578125MB
INFO:root:[   35] Training loss: 0.63327596, Validation loss: 0.63787671, Gradient norm: 0.08482202
INFO:root:At the start of the epoch: mem (CPU python)=44141.19921875MB; mem (CPU total)=43994.85546875MB
INFO:root:[   36] Training loss: 0.63243617, Validation loss: 0.63710726, Gradient norm: 0.06840251
INFO:root:At the start of the epoch: mem (CPU python)=44179.296875MB; mem (CPU total)=44032.796875MB
INFO:root:[   37] Training loss: 0.63158178, Validation loss: 0.63628283, Gradient norm: 0.07745608
INFO:root:At the start of the epoch: mem (CPU python)=44217.390625MB; mem (CPU total)=44071.4375MB
INFO:root:[   38] Training loss: 0.63070339, Validation loss: 0.63482103, Gradient norm: 0.07358994
INFO:root:At the start of the epoch: mem (CPU python)=44255.48828125MB; mem (CPU total)=44109.765625MB
INFO:root:[   39] Training loss: 0.62965062, Validation loss: 0.63508953, Gradient norm: 0.07892344
INFO:root:At the start of the epoch: mem (CPU python)=44293.5859375MB; mem (CPU total)=44147.33984375MB
INFO:root:[   40] Training loss: 0.62910652, Validation loss: 0.63365159, Gradient norm: 0.07489286
INFO:root:At the start of the epoch: mem (CPU python)=44331.68359375MB; mem (CPU total)=44185.49609375MB
INFO:root:[   41] Training loss: 0.62828384, Validation loss: 0.63348123, Gradient norm: 0.07077356
INFO:root:At the start of the epoch: mem (CPU python)=44369.77734375MB; mem (CPU total)=44223.484375MB
INFO:root:[   42] Training loss: 0.62740625, Validation loss: 0.63294950, Gradient norm: 0.07415228
INFO:root:At the start of the epoch: mem (CPU python)=44407.87109375MB; mem (CPU total)=44262.16796875MB
INFO:root:[   43] Training loss: 0.62660723, Validation loss: 0.63256163, Gradient norm: 0.08013548
INFO:root:At the start of the epoch: mem (CPU python)=44445.96875MB; mem (CPU total)=44300.046875MB
INFO:root:[   44] Training loss: 0.62634496, Validation loss: 0.63172225, Gradient norm: 0.08257063
INFO:root:At the start of the epoch: mem (CPU python)=44484.0625MB; mem (CPU total)=44337.796875MB
INFO:root:[   45] Training loss: 0.62493224, Validation loss: 0.63094967, Gradient norm: 0.07084465
INFO:root:At the start of the epoch: mem (CPU python)=44522.15625MB; mem (CPU total)=44375.87109375MB
INFO:root:[   46] Training loss: 0.62452538, Validation loss: 0.63135048, Gradient norm: 0.06980620
INFO:root:At the start of the epoch: mem (CPU python)=44560.25390625MB; mem (CPU total)=44413.44921875MB
INFO:root:[   47] Training loss: 0.62388628, Validation loss: 0.63021626, Gradient norm: 0.07505059
INFO:root:At the start of the epoch: mem (CPU python)=44598.34765625MB; mem (CPU total)=44451.80078125MB
INFO:root:[   48] Training loss: 0.62329753, Validation loss: 0.62991028, Gradient norm: 0.07588573
INFO:root:At the start of the epoch: mem (CPU python)=44636.44140625MB; mem (CPU total)=44489.91015625MB
INFO:root:[   49] Training loss: 0.62264858, Validation loss: 0.62937981, Gradient norm: 0.08536555
INFO:root:At the start of the epoch: mem (CPU python)=44674.5390625MB; mem (CPU total)=44528.61328125MB
INFO:root:[   50] Training loss: 0.62170510, Validation loss: 0.62963515, Gradient norm: 0.07826849
INFO:root:At the start of the epoch: mem (CPU python)=44712.63671875MB; mem (CPU total)=44566.49609375MB
INFO:root:[   51] Training loss: 0.62135517, Validation loss: 0.62920765, Gradient norm: 0.08119649
INFO:root:At the start of the epoch: mem (CPU python)=44750.73046875MB; mem (CPU total)=44603.99609375MB
INFO:root:[   52] Training loss: 0.62089064, Validation loss: 0.62809009, Gradient norm: 0.07245129
INFO:root:At the start of the epoch: mem (CPU python)=44788.82421875MB; mem (CPU total)=44642.109375MB
INFO:root:[   53] Training loss: 0.61996705, Validation loss: 0.62786430, Gradient norm: 0.07812303
INFO:root:At the start of the epoch: mem (CPU python)=44826.921875MB; mem (CPU total)=44680.26171875MB
INFO:root:[   54] Training loss: 0.61940820, Validation loss: 0.62745067, Gradient norm: 0.07151458
INFO:root:At the start of the epoch: mem (CPU python)=44865.015625MB; mem (CPU total)=44718.70703125MB
INFO:root:[   55] Training loss: 0.61883517, Validation loss: 0.62700218, Gradient norm: 0.06833817
INFO:root:At the start of the epoch: mem (CPU python)=44903.109375MB; mem (CPU total)=44756.47265625MB
INFO:root:[   56] Training loss: 0.61840046, Validation loss: 0.62693455, Gradient norm: 0.07831989
INFO:root:At the start of the epoch: mem (CPU python)=44941.20703125MB; mem (CPU total)=44794.48828125MB
INFO:root:[   57] Training loss: 0.61802273, Validation loss: 0.62581019, Gradient norm: 0.07170305
INFO:root:At the start of the epoch: mem (CPU python)=44979.30078125MB; mem (CPU total)=44832.6328125MB
INFO:root:[   58] Training loss: 0.61743233, Validation loss: 0.62526533, Gradient norm: 0.06750185
INFO:root:At the start of the epoch: mem (CPU python)=45017.3984375MB; mem (CPU total)=44871.0390625MB
INFO:root:[   59] Training loss: 0.61684541, Validation loss: 0.62634176, Gradient norm: 0.07512385
INFO:root:At the start of the epoch: mem (CPU python)=45055.4921875MB; mem (CPU total)=44909.4296875MB
INFO:root:[   60] Training loss: 0.61626206, Validation loss: 0.62578841, Gradient norm: 0.08046571
INFO:root:At the start of the epoch: mem (CPU python)=45093.58984375MB; mem (CPU total)=44947.421875MB
INFO:root:[   61] Training loss: 0.61581951, Validation loss: 0.62496317, Gradient norm: 0.08043139
INFO:root:At the start of the epoch: mem (CPU python)=45131.68359375MB; mem (CPU total)=44985.52734375MB
INFO:root:[   62] Training loss: 0.61544315, Validation loss: 0.62502258, Gradient norm: 0.07582635
INFO:root:At the start of the epoch: mem (CPU python)=45169.77734375MB; mem (CPU total)=45023.69921875MB
INFO:root:[   63] Training loss: 0.61476158, Validation loss: 0.62560517, Gradient norm: 0.07269642
INFO:root:At the start of the epoch: mem (CPU python)=45207.875MB; mem (CPU total)=45062.20703125MB
INFO:root:[   64] Training loss: 0.61422040, Validation loss: 0.62411243, Gradient norm: 0.07153407
INFO:root:At the start of the epoch: mem (CPU python)=45245.96875MB; mem (CPU total)=45100.13671875MB
INFO:root:[   65] Training loss: 0.61384312, Validation loss: 0.62438432, Gradient norm: 0.06796726
INFO:root:At the start of the epoch: mem (CPU python)=45284.0625MB; mem (CPU total)=45137.8125MB
INFO:root:[   66] Training loss: 0.61333246, Validation loss: 0.62428756, Gradient norm: 0.06982429
INFO:root:At the start of the epoch: mem (CPU python)=45322.1640625MB; mem (CPU total)=45175.703125MB
INFO:root:[   67] Training loss: 0.61295664, Validation loss: 0.62352089, Gradient norm: 0.06607546
INFO:root:At the start of the epoch: mem (CPU python)=45360.2578125MB; mem (CPU total)=45213.91796875MB
INFO:root:[   68] Training loss: 0.61252583, Validation loss: 0.62326172, Gradient norm: 0.06951544
INFO:root:At the start of the epoch: mem (CPU python)=45398.3515625MB; mem (CPU total)=45252.5546875MB
INFO:root:[   69] Training loss: 0.61204287, Validation loss: 0.62355448, Gradient norm: 0.07336148
INFO:root:At the start of the epoch: mem (CPU python)=45436.4453125MB; mem (CPU total)=45290.68359375MB
INFO:root:[   70] Training loss: 0.61162103, Validation loss: 0.62244291, Gradient norm: 0.07260119
INFO:root:At the start of the epoch: mem (CPU python)=45474.54296875MB; mem (CPU total)=45328.8125MB
INFO:root:[   71] Training loss: 0.61149052, Validation loss: 0.62271763, Gradient norm: 0.08568092
INFO:root:At the start of the epoch: mem (CPU python)=45512.63671875MB; mem (CPU total)=45366.69921875MB
INFO:root:[   72] Training loss: 0.61091231, Validation loss: 0.62234666, Gradient norm: 0.07709943
INFO:root:At the start of the epoch: mem (CPU python)=45550.73046875MB; mem (CPU total)=45404.87109375MB
INFO:root:[   73] Training loss: 0.61040940, Validation loss: 0.62194690, Gradient norm: 0.07246504
INFO:root:At the start of the epoch: mem (CPU python)=45588.828125MB; mem (CPU total)=45443.2578125MB
INFO:root:[   74] Training loss: 0.60992165, Validation loss: 0.62233433, Gradient norm: 0.08069845
INFO:root:At the start of the epoch: mem (CPU python)=45626.921875MB; mem (CPU total)=45481.39453125MB
INFO:root:[   75] Training loss: 0.60940434, Validation loss: 0.62193927, Gradient norm: 0.07619649
INFO:root:At the start of the epoch: mem (CPU python)=45665.01953125MB; mem (CPU total)=45520.046875MB
INFO:root:[   76] Training loss: 0.60895755, Validation loss: 0.62152315, Gradient norm: 0.06748926
INFO:root:At the start of the epoch: mem (CPU python)=45703.11328125MB; mem (CPU total)=45558.15625MB
INFO:root:[   77] Training loss: 0.60878305, Validation loss: 0.62176799, Gradient norm: 0.07279989
INFO:root:At the start of the epoch: mem (CPU python)=45741.2109375MB; mem (CPU total)=45596.30078125MB
INFO:root:[   78] Training loss: 0.60831239, Validation loss: 0.62114174, Gradient norm: 0.07242808
INFO:root:At the start of the epoch: mem (CPU python)=45779.3046875MB; mem (CPU total)=45634.72265625MB
INFO:root:[   79] Training loss: 0.60776793, Validation loss: 0.62131839, Gradient norm: 0.07535578
INFO:root:At the start of the epoch: mem (CPU python)=45817.3984375MB; mem (CPU total)=45673.07421875MB
INFO:root:[   80] Training loss: 0.60758095, Validation loss: 0.62292736, Gradient norm: 0.07695669
INFO:root:At the start of the epoch: mem (CPU python)=45855.5MB; mem (CPU total)=45711.10546875MB
INFO:root:[   81] Training loss: 0.60717394, Validation loss: 0.62046436, Gradient norm: 0.07643361
INFO:root:At the start of the epoch: mem (CPU python)=45893.59375MB; mem (CPU total)=45749.66015625MB
INFO:root:[   82] Training loss: 0.60671379, Validation loss: 0.62078411, Gradient norm: 0.07379105
INFO:root:At the start of the epoch: mem (CPU python)=45931.6875MB; mem (CPU total)=45787.55859375MB
INFO:root:[   83] Training loss: 0.60657819, Validation loss: 0.62026555, Gradient norm: 0.07483763
INFO:root:At the start of the epoch: mem (CPU python)=45969.7890625MB; mem (CPU total)=45825.98046875MB
INFO:root:[   84] Training loss: 0.60620230, Validation loss: 0.62001433, Gradient norm: 0.07799299
INFO:root:At the start of the epoch: mem (CPU python)=46007.8828125MB; mem (CPU total)=45864.41015625MB
INFO:root:[   85] Training loss: 0.60566836, Validation loss: 0.62069516, Gradient norm: 0.08241262
INFO:root:At the start of the epoch: mem (CPU python)=46045.9765625MB; mem (CPU total)=45901.8828125MB
INFO:root:[   86] Training loss: 0.60541010, Validation loss: 0.62002648, Gradient norm: 0.07457082
INFO:root:At the start of the epoch: mem (CPU python)=46084.0703125MB; mem (CPU total)=45939.7265625MB
INFO:root:[   87] Training loss: 0.60516229, Validation loss: 0.61977139, Gradient norm: 0.08120656
INFO:root:At the start of the epoch: mem (CPU python)=46122.16796875MB; mem (CPU total)=45978.02734375MB
INFO:root:[   88] Training loss: 0.60465669, Validation loss: 0.61924732, Gradient norm: 0.07589355
INFO:root:At the start of the epoch: mem (CPU python)=46160.26171875MB; mem (CPU total)=46016.41796875MB
INFO:root:[   89] Training loss: 0.60416378, Validation loss: 0.61962856, Gradient norm: 0.08161927
INFO:root:At the start of the epoch: mem (CPU python)=46198.35546875MB; mem (CPU total)=46054.3828125MB
INFO:root:[   90] Training loss: 0.60397730, Validation loss: 0.61952646, Gradient norm: 0.07534625
INFO:root:At the start of the epoch: mem (CPU python)=46236.453125MB; mem (CPU total)=46092.5078125MB
INFO:root:[   91] Training loss: 0.60334275, Validation loss: 0.61954168, Gradient norm: 0.06986426
INFO:root:At the start of the epoch: mem (CPU python)=46274.546875MB; mem (CPU total)=46130.21484375MB
INFO:root:[   92] Training loss: 0.60328462, Validation loss: 0.61978712, Gradient norm: 0.07706405
INFO:root:At the start of the epoch: mem (CPU python)=46312.64453125MB; mem (CPU total)=46168.3515625MB
INFO:root:[   93] Training loss: 0.60274023, Validation loss: 0.61951198, Gradient norm: 0.07136830
INFO:root:At the start of the epoch: mem (CPU python)=46350.73828125MB; mem (CPU total)=46207.13671875MB
INFO:root:[   94] Training loss: 0.60257946, Validation loss: 0.61896249, Gradient norm: 0.07503929
INFO:root:At the start of the epoch: mem (CPU python)=46388.8359375MB; mem (CPU total)=46245.2734375MB
INFO:root:[   95] Training loss: 0.60226060, Validation loss: 0.61974165, Gradient norm: 0.08280414
INFO:root:At the start of the epoch: mem (CPU python)=46426.9296875MB; mem (CPU total)=46282.65625MB
INFO:root:[   96] Training loss: 0.60194615, Validation loss: 0.61879459, Gradient norm: 0.07408974
INFO:root:At the start of the epoch: mem (CPU python)=46465.0234375MB; mem (CPU total)=46321.21484375MB
INFO:root:[   97] Training loss: 0.60136925, Validation loss: 0.61922888, Gradient norm: 0.07560884
INFO:root:At the start of the epoch: mem (CPU python)=46503.12109375MB; mem (CPU total)=46359.3515625MB
INFO:root:[   98] Training loss: 0.60100438, Validation loss: 0.61917464, Gradient norm: 0.07487480
INFO:root:At the start of the epoch: mem (CPU python)=46541.21484375MB; mem (CPU total)=46397.49609375MB
INFO:root:[   99] Training loss: 0.60076139, Validation loss: 0.61995959, Gradient norm: 0.07584966
INFO:root:At the start of the epoch: mem (CPU python)=46579.3125MB; mem (CPU total)=46435.83984375MB
INFO:root:[  100] Training loss: 0.60062347, Validation loss: 0.61923079, Gradient norm: 0.07852935
INFO:root:At the start of the epoch: mem (CPU python)=46617.40625MB; mem (CPU total)=46473.73046875MB
INFO:root:[  101] Training loss: 0.60014396, Validation loss: 0.61840116, Gradient norm: 0.07117141
INFO:root:At the start of the epoch: mem (CPU python)=46655.50390625MB; mem (CPU total)=46512.890625MB
INFO:root:[  102] Training loss: 0.59983615, Validation loss: 0.61961504, Gradient norm: 0.07969810
INFO:root:At the start of the epoch: mem (CPU python)=46693.59765625MB; mem (CPU total)=46551.0234375MB
INFO:root:[  103] Training loss: 0.59968987, Validation loss: 0.61828687, Gradient norm: 0.07658247
INFO:root:At the start of the epoch: mem (CPU python)=46731.69140625MB; mem (CPU total)=46588.70703125MB
INFO:root:[  104] Training loss: 0.59948703, Validation loss: 0.61792618, Gradient norm: 0.07926043
INFO:root:At the start of the epoch: mem (CPU python)=46769.7890625MB; mem (CPU total)=46627.12890625MB
INFO:root:[  105] Training loss: 0.59877594, Validation loss: 0.61913075, Gradient norm: 0.07272857
INFO:root:At the start of the epoch: mem (CPU python)=46807.8828125MB; mem (CPU total)=46665.046875MB
INFO:root:[  106] Training loss: 0.59865563, Validation loss: 0.61896255, Gradient norm: 0.07716625
INFO:root:At the start of the epoch: mem (CPU python)=46845.9765625MB; mem (CPU total)=46703.38671875MB
INFO:root:[  107] Training loss: 0.59857962, Validation loss: 0.61827722, Gradient norm: 0.07665629
INFO:root:At the start of the epoch: mem (CPU python)=46884.07421875MB; mem (CPU total)=46741.47265625MB
INFO:root:[  108] Training loss: 0.59795355, Validation loss: 0.61901582, Gradient norm: 0.08015606
INFO:root:At the start of the epoch: mem (CPU python)=46922.16796875MB; mem (CPU total)=46779.74609375MB
INFO:root:[  109] Training loss: 0.59758227, Validation loss: 0.61720275, Gradient norm: 0.07094316
INFO:root:At the start of the epoch: mem (CPU python)=46960.265625MB; mem (CPU total)=46817.875MB
INFO:root:[  110] Training loss: 0.59727353, Validation loss: 0.61787308, Gradient norm: 0.07008507
INFO:root:At the start of the epoch: mem (CPU python)=46998.359375MB; mem (CPU total)=46855.76171875MB
INFO:root:[  111] Training loss: 0.59733654, Validation loss: 0.61842637, Gradient norm: 0.08311618
INFO:root:At the start of the epoch: mem (CPU python)=47036.45703125MB; mem (CPU total)=46894.12109375MB
INFO:root:[  112] Training loss: 0.59693734, Validation loss: 0.61833952, Gradient norm: 0.07874868
INFO:root:At the start of the epoch: mem (CPU python)=47074.55078125MB; mem (CPU total)=46932.51171875MB
INFO:root:[  113] Training loss: 0.59650054, Validation loss: 0.61801014, Gradient norm: 0.07968704
INFO:root:At the start of the epoch: mem (CPU python)=47112.64453125MB; mem (CPU total)=46970.41015625MB
INFO:root:[  114] Training loss: 0.59635222, Validation loss: 0.61880475, Gradient norm: 0.07294546
INFO:root:At the start of the epoch: mem (CPU python)=47150.7421875MB; mem (CPU total)=47008.796875MB
INFO:root:[  115] Training loss: 0.59600374, Validation loss: 0.61789155, Gradient norm: 0.08014388
INFO:root:At the start of the epoch: mem (CPU python)=47188.8359375MB; mem (CPU total)=47046.6640625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  116] Training loss: 0.59586376, Validation loss: 0.61779656, Gradient norm: 0.08056861
INFO:root:At the start of the epoch: mem (CPU python)=47226.93359375MB; mem (CPU total)=47085.546875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  117] Training loss: 0.59422253, Validation loss: 0.61844296, Gradient norm: 0.07404623
INFO:root:At the start of the epoch: mem (CPU python)=47265.03125MB; mem (CPU total)=47123.44140625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  118] Training loss: 0.59320249, Validation loss: 0.61752889, Gradient norm: 0.06292930
INFO:root:At the start of the epoch: mem (CPU python)=47303.125MB; mem (CPU total)=47161.59765625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:EP 118: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=47341.1875MB; mem (CPU total)=47199.7421875MB
INFO:root:Training the model took 13817.963s.
INFO:root:Emptying the cuda cache took 0.021s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-dropout
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84673
INFO:root:EnergyScoreTrain: 0.59627
INFO:root:CRPSTrain: 0.51597
INFO:root:Gaussian NLLTrain: 2.45909
INFO:root:CoverageTrain: 0.80593
INFO:root:IntervalWidthTrain: 3.08795
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87758
INFO:root:EnergyScoreValidation: 0.61807
INFO:root:CRPSValidation: 0.53353
INFO:root:Gaussian NLLValidation: 2.51001
INFO:root:CoverageValidation: 0.79593
INFO:root:IntervalWidthValidation: 3.0821
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87826
INFO:root:EnergyScoreTest: 0.61857
INFO:root:CRPSTest: 0.53394
INFO:root:Gaussian NLLTest: 2.51247
INFO:root:CoverageTest: 0.79535
INFO:root:IntervalWidthTest: 3.07747
INFO:root:After validation: mem (CPU python)=47383.9296875MB; mem (CPU total)=47242.08984375MB
