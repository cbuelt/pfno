INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=575.20703125MB; mem (CPU total)=983.27734375MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples2.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12454.140625MB; mem (CPU total)=995.4375MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.140625MB; mem (CPU total)=995.53515625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12454.140625MB; mem (CPU total)=2366.37890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=2380.234375MB
INFO:root:[    1] Training loss: 0.72542970, Validation loss: 0.72117178, Gradient norm: 0.01814071
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4118.1796875MB
INFO:root:[    2] Training loss: 0.72028238, Validation loss: 0.71932257, Gradient norm: 0.00546118
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4172.9921875MB
INFO:root:[    3] Training loss: 0.71902711, Validation loss: 0.71746348, Gradient norm: 0.00753384
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4218.7890625MB
INFO:root:[    4] Training loss: 0.71609800, Validation loss: 0.70969785, Gradient norm: 0.01619139
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4281.609375MB
INFO:root:[    5] Training loss: 0.71099852, Validation loss: 0.70442515, Gradient norm: 0.03027599
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4284.05859375MB
INFO:root:[    6] Training loss: 0.70724564, Validation loss: 0.70022888, Gradient norm: 0.04111438
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4402.69921875MB
INFO:root:[    7] Training loss: 0.70408192, Validation loss: 0.69617345, Gradient norm: 0.04214546
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4441.05859375MB
INFO:root:[    8] Training loss: 0.70113872, Validation loss: 0.69348063, Gradient norm: 0.04662086
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4398.90625MB
INFO:root:[    9] Training loss: 0.69879216, Validation loss: 0.68966619, Gradient norm: 0.05206371
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4474.37109375MB
INFO:root:[   10] Training loss: 0.69608429, Validation loss: 0.68582605, Gradient norm: 0.06107032
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4466.85546875MB
INFO:root:[   11] Training loss: 0.69381917, Validation loss: 0.68384311, Gradient norm: 0.07517372
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4513.4296875MB
INFO:root:[   12] Training loss: 0.69147675, Validation loss: 0.68114839, Gradient norm: 0.08308767
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4552.55078125MB
INFO:root:[   13] Training loss: 0.68968701, Validation loss: 0.67824313, Gradient norm: 0.08968825
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4653.12109375MB
INFO:root:[   14] Training loss: 0.68794492, Validation loss: 0.67869516, Gradient norm: 0.11158554
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4691.25MB
INFO:root:[   15] Training loss: 0.68651061, Validation loss: 0.67927543, Gradient norm: 0.15171562
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4729.60546875MB
INFO:root:[   16] Training loss: 0.68497150, Validation loss: 0.68035878, Gradient norm: 0.17192728
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4705.40234375MB
INFO:root:[   17] Training loss: 0.68383149, Validation loss: 0.68051181, Gradient norm: 0.19769315
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4818.50390625MB
INFO:root:[   18] Training loss: 0.68279248, Validation loss: 0.68353936, Gradient norm: 0.22318007
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4881.61328125MB
INFO:root:[   19] Training loss: 0.68168755, Validation loss: 0.68955496, Gradient norm: 0.26521870
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4834.12109375MB
INFO:root:[   20] Training loss: 0.68097396, Validation loss: 0.69895462, Gradient norm: 0.31734800
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4872.14453125MB
INFO:root:[   21] Training loss: 0.67976725, Validation loss: 0.69282326, Gradient norm: 0.32153662
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=4882.921875MB
INFO:root:[   22] Training loss: 0.67919118, Validation loss: 0.69905654, Gradient norm: 0.37357875
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5001.28515625MB
INFO:root:[   23] Training loss: 0.67854172, Validation loss: 0.70451423, Gradient norm: 0.43277294
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5040.796875MB
INFO:root:[   24] Training loss: 0.67785386, Validation loss: 0.70286313, Gradient norm: 0.45493184
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5023.08203125MB
INFO:root:[   25] Training loss: 0.67704515, Validation loss: 0.69170652, Gradient norm: 0.54682656
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5048.8671875MB
INFO:root:[   26] Training loss: 0.67668815, Validation loss: 0.69697509, Gradient norm: 0.56262857
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5050.58984375MB
INFO:root:[   27] Training loss: 0.67591845, Validation loss: 0.70194615, Gradient norm: 0.60155254
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5125.640625MB
INFO:root:[   28] Training loss: 0.67562509, Validation loss: 0.69163412, Gradient norm: 0.69399697
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5163.58203125MB
INFO:root:[   29] Training loss: 0.67504830, Validation loss: 0.68232875, Gradient norm: 0.73692413
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5201.890625MB
INFO:root:[   30] Training loss: 0.67450826, Validation loss: 0.69205084, Gradient norm: 0.74390603
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5264.8828125MB
INFO:root:[   31] Training loss: 0.67415004, Validation loss: 0.69753145, Gradient norm: 0.77538718
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5303.32421875MB
INFO:root:[   32] Training loss: 0.67404896, Validation loss: 0.68219892, Gradient norm: 0.96627790
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5315.86328125MB
INFO:root:[   33] Training loss: 0.67350363, Validation loss: 0.68777626, Gradient norm: 0.89355093
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5354.33984375MB
INFO:root:[   34] Training loss: 0.67293150, Validation loss: 0.68989725, Gradient norm: 0.97595525
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5392.4609375MB
INFO:root:[   35] Training loss: 0.67278394, Validation loss: 0.67964825, Gradient norm: 1.07993065
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5430.57421875MB
INFO:root:[   36] Training loss: 0.67268508, Validation loss: 0.67711661, Gradient norm: 1.16516088
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5469.20703125MB
INFO:root:[   37] Training loss: 0.67197553, Validation loss: 0.67518063, Gradient norm: 1.18561495
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5506.890625MB
INFO:root:[   38] Training loss: 0.67193075, Validation loss: 0.67087184, Gradient norm: 1.46323917
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5537.78125MB
INFO:root:[   39] Training loss: 0.67161040, Validation loss: 0.66631072, Gradient norm: 1.40388183
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5587.86328125MB
INFO:root:[   40] Training loss: 0.67124623, Validation loss: 0.66050303, Gradient norm: 1.40689732
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5633.23828125MB
INFO:root:[   41] Training loss: 0.67125146, Validation loss: 0.66041743, Gradient norm: 1.60049430
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5685.34765625MB
INFO:root:[   42] Training loss: 0.67095763, Validation loss: 0.65673018, Gradient norm: 1.58468607
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5686.578125MB
INFO:root:[   43] Training loss: 0.67072737, Validation loss: 0.65445996, Gradient norm: 1.67641529
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5760.10546875MB
INFO:root:[   44] Training loss: 0.67050876, Validation loss: 0.65477457, Gradient norm: 1.74968637
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5785.48046875MB
INFO:root:[   45] Training loss: 0.67029972, Validation loss: 0.65601934, Gradient norm: 1.77520878
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5824.0859375MB
INFO:root:[   46] Training loss: 0.67005615, Validation loss: 0.65274971, Gradient norm: 1.85010886
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5862.19921875MB
INFO:root:[   47] Training loss: 0.67009112, Validation loss: 0.65299507, Gradient norm: 2.08135598
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5875.6171875MB
INFO:root:[   48] Training loss: 0.66961970, Validation loss: 0.65236714, Gradient norm: 2.04270651
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6001.02734375MB
INFO:root:[   49] Training loss: 0.66965764, Validation loss: 0.65305161, Gradient norm: 2.21639279
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=5976.3125MB
INFO:root:[   50] Training loss: 0.66948602, Validation loss: 0.65040144, Gradient norm: 2.08386257
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6095.0MB
INFO:root:[   51] Training loss: 0.66947225, Validation loss: 0.65128947, Gradient norm: 2.32854490
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6082.75MB
INFO:root:[   52] Training loss: 0.66917949, Validation loss: 0.65149022, Gradient norm: 2.40603455
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6153.5078125MB
INFO:root:[   53] Training loss: 0.66928743, Validation loss: 0.65054203, Gradient norm: 2.40134450
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6191.8125MB
INFO:root:[   54] Training loss: 0.66941437, Validation loss: 0.65072150, Gradient norm: 2.59052608
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6222.46875MB
INFO:root:[   55] Training loss: 0.66883821, Validation loss: 0.64949734, Gradient norm: 2.52784540
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6260.81640625MB
INFO:root:[   56] Training loss: 0.66866266, Validation loss: 0.65205248, Gradient norm: 2.49906129
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6298.70703125MB
INFO:root:[   57] Training loss: 0.66873403, Validation loss: 0.65009761, Gradient norm: 2.67440750
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6336.7890625MB
INFO:root:[   58] Training loss: 0.66861434, Validation loss: 0.65000217, Gradient norm: 2.75519978
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6357.1875MB
INFO:root:[   59] Training loss: 0.66882954, Validation loss: 0.65021923, Gradient norm: 3.23339892
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6332.95703125MB
INFO:root:[   60] Training loss: 0.66859496, Validation loss: 0.64955658, Gradient norm: 3.15310971
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6408.6953125MB
INFO:root:[   61] Training loss: 0.66866361, Validation loss: 0.65082343, Gradient norm: 3.12464239
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6413.41796875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   62] Training loss: 0.66866726, Validation loss: 0.64946502, Gradient norm: 3.29611782
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6459.9765625MB
INFO:root:[   63] Training loss: 0.66749678, Validation loss: 0.64929665, Gradient norm: 2.28003554
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6498.60546875MB
INFO:root:[   64] Training loss: 0.66729268, Validation loss: 0.64889794, Gradient norm: 2.42816240
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6536.74609375MB
INFO:root:[   65] Training loss: 0.66724239, Validation loss: 0.64860703, Gradient norm: 2.61683646
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6575.359375MB
INFO:root:[   66] Training loss: 0.66732029, Validation loss: 0.64861095, Gradient norm: 2.66654396
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6613.5078125MB
INFO:root:[   67] Training loss: 0.66713046, Validation loss: 0.64864461, Gradient norm: 2.92218457
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6663.5390625MB
INFO:root:[   68] Training loss: 0.66706807, Validation loss: 0.64805064, Gradient norm: 3.20881347
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6714.9765625MB
INFO:root:[   69] Training loss: 0.66702998, Validation loss: 0.64855943, Gradient norm: 3.37067416
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6752.765625MB
INFO:root:[   70] Training loss: 0.66719294, Validation loss: 0.64797286, Gradient norm: 3.35199267
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6769.875MB
INFO:root:[   71] Training loss: 0.66688718, Validation loss: 0.64976381, Gradient norm: 3.36500485
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6891.3515625MB
INFO:root:[   72] Training loss: 0.66717720, Validation loss: 0.64812519, Gradient norm: 3.69074603
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6879.46875MB
INFO:root:[   73] Training loss: 0.66683775, Validation loss: 0.64861800, Gradient norm: 3.60901792
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6982.3828125MB
INFO:root:[   74] Training loss: 0.66706358, Validation loss: 0.64793431, Gradient norm: 3.85321622
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6908.16796875MB
INFO:root:[   75] Training loss: 0.66698223, Validation loss: 0.64828120, Gradient norm: 3.66191370
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=6982.9921875MB
INFO:root:[   76] Training loss: 0.66718713, Validation loss: 0.64827164, Gradient norm: 4.30275989
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7008.71875MB
INFO:root:[   77] Training loss: 0.66718160, Validation loss: 0.64833542, Gradient norm: 4.79071048
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7046.5546875MB
INFO:root:[   78] Training loss: 0.66709979, Validation loss: 0.64729327, Gradient norm: 4.19506044
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7122.5078125MB
INFO:root:[   79] Training loss: 0.66690770, Validation loss: 0.64723272, Gradient norm: 4.29276143
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7122.55859375MB
INFO:root:[   80] Training loss: 0.66666218, Validation loss: 0.64720216, Gradient norm: 4.35619857
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7159.77734375MB
INFO:root:[   81] Training loss: 0.66674129, Validation loss: 0.64879906, Gradient norm: 4.41078972
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7197.78515625MB
INFO:root:[   82] Training loss: 0.66675399, Validation loss: 0.64692380, Gradient norm: 4.67960513
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7235.83984375MB
INFO:root:[   83] Training loss: 0.66677886, Validation loss: 0.64832677, Gradient norm: 4.71974997
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7329.1953125MB
INFO:root:[   84] Training loss: 0.66681557, Validation loss: 0.64846326, Gradient norm: 4.38017555
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7299.55859375MB
INFO:root:[   85] Training loss: 0.66675388, Validation loss: 0.64763382, Gradient norm: 5.03690208
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7337.74609375MB
INFO:root:[   86] Training loss: 0.66679709, Validation loss: 0.64725725, Gradient norm: 5.09371888
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7376.11328125MB
INFO:root:[   87] Training loss: 0.66668126, Validation loss: 0.64889581, Gradient norm: 5.03719802
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7414.5078125MB
INFO:root:[   88] Training loss: 0.66680819, Validation loss: 0.64741212, Gradient norm: 5.55948700
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7452.38671875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   89] Training loss: 0.66658062, Validation loss: 0.64816350, Gradient norm: 5.44742917
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7490.96484375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   90] Training loss: 0.66566477, Validation loss: 0.64656233, Gradient norm: 3.80466682
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7529.0625MB
INFO:root:[   91] Training loss: 0.66556186, Validation loss: 0.64598160, Gradient norm: 2.93900170
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7578.98828125MB
INFO:root:[   92] Training loss: 0.66553167, Validation loss: 0.64645271, Gradient norm: 3.19972809
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7616.87890625MB
INFO:root:[   93] Training loss: 0.66540249, Validation loss: 0.64634390, Gradient norm: 3.44625664
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7655.0MB
INFO:root:[   94] Training loss: 0.66556837, Validation loss: 0.64589073, Gradient norm: 3.36504414
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7705.93359375MB
INFO:root:[   95] Training loss: 0.66537553, Validation loss: 0.64649111, Gradient norm: 3.50009987
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7743.89453125MB
INFO:root:[   96] Training loss: 0.66534548, Validation loss: 0.64649011, Gradient norm: 3.81903312
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7782.546875MB
INFO:root:[   97] Training loss: 0.66532756, Validation loss: 0.64604383, Gradient norm: 3.84872148
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7795.5078125MB
INFO:root:[   98] Training loss: 0.66534190, Validation loss: 0.64676026, Gradient norm: 4.47683053
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7858.55078125MB
INFO:root:[   99] Training loss: 0.66538944, Validation loss: 0.64613330, Gradient norm: 4.09180378
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7896.64453125MB
INFO:root:[  100] Training loss: 0.66537821, Validation loss: 0.64637149, Gradient norm: 4.27183457
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7922.7890625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  101] Training loss: 0.66546500, Validation loss: 0.64609494, Gradient norm: 4.08209513
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7948.45703125MB
INFO:root:[  102] Training loss: 0.66511901, Validation loss: 0.64605367, Gradient norm: 3.49545508
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=7986.5234375MB
INFO:root:[  103] Training loss: 0.66507942, Validation loss: 0.64594003, Gradient norm: 3.54649876
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8028.36328125MB
INFO:root:EP 103: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12454.140625MB; mem (CPU total)=8075.44921875MB
INFO:root:Training the model took 4020.959s.
INFO:root:Emptying the cuda cache took 0.025s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.91646
INFO:root:EnergyScoreTrain: 0.64503
INFO:root:CRPSTrain: 0.58178
INFO:root:Gaussian NLLTrain: 83585201638.9689
INFO:root:CoverageTrain: 0.54661
INFO:root:IntervalWidthTrain: 2.54002
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.91818
INFO:root:EnergyScoreValidation: 0.64626
INFO:root:CRPSValidation: 0.58352
INFO:root:Gaussian NLLValidation: 84843126747.5911
INFO:root:CoverageValidation: 0.54616
INFO:root:IntervalWidthValidation: 2.53854
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.91996
INFO:root:EnergyScoreTest: 0.64752
INFO:root:CRPSTest: 0.5851
INFO:root:Gaussian NLLTest: 84850516361.216
INFO:root:CoverageTest: 0.54772
INFO:root:IntervalWidthTest: 2.54463
INFO:root:After validation: mem (CPU python)=12454.140625MB; mem (CPU total)=8107.58984375MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=12454.140625MB; mem (CPU total)=8107.3359375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12454.140625MB; mem (CPU total)=8107.3359375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8107.81640625MB
INFO:root:[    1] Training loss: 0.72583140, Validation loss: 0.72189946, Gradient norm: 0.02281838
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8154.546875MB
INFO:root:[    2] Training loss: 0.72053982, Validation loss: 0.71869318, Gradient norm: 0.00592345
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8192.22265625MB
INFO:root:[    3] Training loss: 0.71920238, Validation loss: 0.71778601, Gradient norm: 0.00867534
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8230.12890625MB
INFO:root:[    4] Training loss: 0.71636557, Validation loss: 0.71083320, Gradient norm: 0.01691029
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8268.01171875MB
INFO:root:[    5] Training loss: 0.71065424, Validation loss: 0.70366481, Gradient norm: 0.02823235
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8306.10546875MB
INFO:root:[    6] Training loss: 0.70566408, Validation loss: 0.69793643, Gradient norm: 0.03864531
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8369.1796875MB
INFO:root:[    7] Training loss: 0.70210791, Validation loss: 0.69289098, Gradient norm: 0.04393780
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8407.76953125MB
INFO:root:[    8] Training loss: 0.69914484, Validation loss: 0.69030441, Gradient norm: 0.04987912
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8445.9609375MB
INFO:root:[    9] Training loss: 0.69677668, Validation loss: 0.68763810, Gradient norm: 0.05698361
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8483.80859375MB
INFO:root:[   10] Training loss: 0.69482648, Validation loss: 0.68549694, Gradient norm: 0.07140786
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8522.18359375MB
INFO:root:[   11] Training loss: 0.69312308, Validation loss: 0.68256784, Gradient norm: 0.07398725
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8560.3046875MB
INFO:root:[   12] Training loss: 0.69157982, Validation loss: 0.68172115, Gradient norm: 0.09573841
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8598.66796875MB
INFO:root:[   13] Training loss: 0.69020545, Validation loss: 0.68090383, Gradient norm: 0.12038320
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8612.890625MB
INFO:root:[   14] Training loss: 0.68894213, Validation loss: 0.67993396, Gradient norm: 0.12690889
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8663.47265625MB
INFO:root:[   15] Training loss: 0.68786752, Validation loss: 0.68044944, Gradient norm: 0.14128477
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8713.5703125MB
INFO:root:[   16] Training loss: 0.68688689, Validation loss: 0.68296437, Gradient norm: 0.20420250
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8752.09375MB
INFO:root:[   17] Training loss: 0.68603740, Validation loss: 0.67983138, Gradient norm: 0.20936253
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8790.45703125MB
INFO:root:[   18] Training loss: 0.68505894, Validation loss: 0.68128173, Gradient norm: 0.22822316
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8828.83203125MB
INFO:root:[   19] Training loss: 0.68422048, Validation loss: 0.68633411, Gradient norm: 0.23096653
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8892.12890625MB
INFO:root:[   20] Training loss: 0.68350606, Validation loss: 0.68436869, Gradient norm: 0.28535364
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8930.25MB
INFO:root:[   21] Training loss: 0.68252402, Validation loss: 0.68617644, Gradient norm: 0.27440181
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8943.421875MB
INFO:root:[   22] Training loss: 0.68209243, Validation loss: 0.68079992, Gradient norm: 0.35809813
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=8981.296875MB
INFO:root:[   23] Training loss: 0.68151285, Validation loss: 0.68046176, Gradient norm: 0.36096542
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9019.671875MB
INFO:root:[   24] Training loss: 0.68089051, Validation loss: 0.68279139, Gradient norm: 0.38348812
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9057.80078125MB
INFO:root:[   25] Training loss: 0.68021801, Validation loss: 0.68394276, Gradient norm: 0.44272800
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9095.62109375MB
INFO:root:[   26] Training loss: 0.67951383, Validation loss: 0.68315262, Gradient norm: 0.41905187
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9171.61328125MB
INFO:root:[   27] Training loss: 0.67938027, Validation loss: 0.68333728, Gradient norm: 0.48327571
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9209.765625MB
INFO:root:[   28] Training loss: 0.67888197, Validation loss: 0.67507832, Gradient norm: 0.57074512
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9210.2578125MB
INFO:root:[   29] Training loss: 0.67827684, Validation loss: 0.67603484, Gradient norm: 0.62106688
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9248.171875MB
INFO:root:[   30] Training loss: 0.67776344, Validation loss: 0.67442378, Gradient norm: 0.63021179
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9285.8671875MB
INFO:root:[   31] Training loss: 0.67715241, Validation loss: 0.66835572, Gradient norm: 0.65471657
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9323.7421875MB
INFO:root:[   32] Training loss: 0.67679732, Validation loss: 0.66768869, Gradient norm: 0.74267514
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9349.5625MB
INFO:root:[   33] Training loss: 0.67622383, Validation loss: 0.66666892, Gradient norm: 0.74104035
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9400.21875MB
INFO:root:[   34] Training loss: 0.67565950, Validation loss: 0.66336771, Gradient norm: 0.70009379
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9438.16796875MB
INFO:root:[   35] Training loss: 0.67550518, Validation loss: 0.66732450, Gradient norm: 0.88011885
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9475.734375MB
INFO:root:[   36] Training loss: 0.67453897, Validation loss: 0.65922352, Gradient norm: 0.89645347
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9513.70703125MB
INFO:root:[   37] Training loss: 0.67394165, Validation loss: 0.65929446, Gradient norm: 0.93936735
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9551.828125MB
INFO:root:[   38] Training loss: 0.67387539, Validation loss: 0.65764424, Gradient norm: 0.98022169
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9601.92578125MB
INFO:root:[   39] Training loss: 0.67335495, Validation loss: 0.65676822, Gradient norm: 1.07435596
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9602.14453125MB
INFO:root:[   40] Training loss: 0.67293103, Validation loss: 0.65598465, Gradient norm: 1.14471209
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9677.71484375MB
INFO:root:[   41] Training loss: 0.67263852, Validation loss: 0.65596941, Gradient norm: 1.11109307
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9678.66796875MB
INFO:root:[   42] Training loss: 0.67230715, Validation loss: 0.65539397, Gradient norm: 1.33013904
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9742.02734375MB
INFO:root:[   43] Training loss: 0.67208880, Validation loss: 0.65459239, Gradient norm: 1.51376815
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9792.62109375MB
INFO:root:[   44] Training loss: 0.67175479, Validation loss: 0.65342610, Gradient norm: 1.43766664
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9805.79296875MB
INFO:root:[   45] Training loss: 0.67165338, Validation loss: 0.65423872, Gradient norm: 1.56998322
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9869.23828125MB
INFO:root:[   46] Training loss: 0.67134047, Validation loss: 0.65371863, Gradient norm: 1.60998568
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9907.3671875MB
INFO:root:[   47] Training loss: 0.67107964, Validation loss: 0.65302659, Gradient norm: 1.74594431
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9945.2421875MB
INFO:root:[   48] Training loss: 0.67086024, Validation loss: 0.65148636, Gradient norm: 1.73214787
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9983.859375MB
INFO:root:[   49] Training loss: 0.67056501, Validation loss: 0.65217032, Gradient norm: 1.76039467
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=9972.23046875MB
INFO:root:[   50] Training loss: 0.67046050, Validation loss: 0.65200714, Gradient norm: 1.78003528
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10035.4765625MB
INFO:root:[   51] Training loss: 0.67005153, Validation loss: 0.65186275, Gradient norm: 1.90487685
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10073.875MB
INFO:root:[   52] Training loss: 0.66983546, Validation loss: 0.65155960, Gradient norm: 1.93800258
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10112.4296875MB
INFO:root:[   53] Training loss: 0.66985053, Validation loss: 0.65019354, Gradient norm: 2.18429838
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10150.6953125MB
INFO:root:[   54] Training loss: 0.66979204, Validation loss: 0.65099247, Gradient norm: 1.90237278
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10214.1953125MB
INFO:root:[   55] Training loss: 0.66946998, Validation loss: 0.65008818, Gradient norm: 2.16851672
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10252.23828125MB
INFO:root:[   56] Training loss: 0.66929044, Validation loss: 0.65084134, Gradient norm: 2.20797686
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10290.3984375MB
INFO:root:[   57] Training loss: 0.66940809, Validation loss: 0.65054828, Gradient norm: 2.48614925
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10328.51171875MB
INFO:root:[   58] Training loss: 0.66897605, Validation loss: 0.65110436, Gradient norm: 2.37566848
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10366.87109375MB
INFO:root:[   59] Training loss: 0.66877794, Validation loss: 0.65101947, Gradient norm: 2.34001545
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10404.48046875MB
INFO:root:[   60] Training loss: 0.66868724, Validation loss: 0.64979692, Gradient norm: 2.50975150
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10430.37109375MB
INFO:root:[   61] Training loss: 0.66848717, Validation loss: 0.64920961, Gradient norm: 2.25233277
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10506.140625MB
INFO:root:[   62] Training loss: 0.66853365, Validation loss: 0.64862019, Gradient norm: 2.84145455
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10544.27734375MB
INFO:root:[   63] Training loss: 0.66830038, Validation loss: 0.64791225, Gradient norm: 2.67991001
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10545.48046875MB
INFO:root:[   64] Training loss: 0.66838137, Validation loss: 0.64904990, Gradient norm: 2.78418709
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10608.515625MB
INFO:root:[   65] Training loss: 0.66811829, Validation loss: 0.64939342, Gradient norm: 2.36118228
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10659.08203125MB
INFO:root:[   66] Training loss: 0.66785996, Validation loss: 0.64898704, Gradient norm: 2.36979225
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10697.1875MB
INFO:root:[   67] Training loss: 0.66776832, Validation loss: 0.64766580, Gradient norm: 2.53586826
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10672.18359375MB
INFO:root:[   68] Training loss: 0.66769850, Validation loss: 0.64869918, Gradient norm: 3.01213156
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10771.89453125MB
INFO:root:[   69] Training loss: 0.66761262, Validation loss: 0.64722451, Gradient norm: 3.06713186
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10809.9609375MB
INFO:root:[   70] Training loss: 0.66761688, Validation loss: 0.64693624, Gradient norm: 3.21420790
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10785.140625MB
INFO:root:[   71] Training loss: 0.66731884, Validation loss: 0.64797798, Gradient norm: 2.96909594
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10873.36328125MB
INFO:root:[   72] Training loss: 0.66725918, Validation loss: 0.64803547, Gradient norm: 2.89375123
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10848.88671875MB
INFO:root:[   73] Training loss: 0.66698874, Validation loss: 0.64698137, Gradient norm: 2.86716604
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10887.24609375MB
INFO:root:[   74] Training loss: 0.66716647, Validation loss: 0.64811662, Gradient norm: 3.02790979
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10937.56640625MB
INFO:root:[   75] Training loss: 0.66692729, Validation loss: 0.64616889, Gradient norm: 3.15585319
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=10976.16015625MB
INFO:root:[   76] Training loss: 0.66667550, Validation loss: 0.64712291, Gradient norm: 2.78065529
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11013.98828125MB
INFO:root:[   77] Training loss: 0.66689159, Validation loss: 0.64803086, Gradient norm: 3.48557520
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11077.23828125MB
INFO:root:[   78] Training loss: 0.66688347, Validation loss: 0.64646904, Gradient norm: 3.63583201
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11115.34375MB
INFO:root:[   79] Training loss: 0.66663675, Validation loss: 0.64664346, Gradient norm: 3.63645851
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11153.4453125MB
INFO:root:[   80] Training loss: 0.66661864, Validation loss: 0.64585714, Gradient norm: 3.63285016
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11204.50390625MB
INFO:root:[   81] Training loss: 0.66638529, Validation loss: 0.64642885, Gradient norm: 3.15762699
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11242.60546875MB
INFO:root:[   82] Training loss: 0.66641197, Validation loss: 0.64591101, Gradient norm: 3.20769240
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11243.05859375MB
INFO:root:[   83] Training loss: 0.66634495, Validation loss: 0.64701374, Gradient norm: 3.24849264
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11318.57421875MB
INFO:root:[   84] Training loss: 0.66616608, Validation loss: 0.64602186, Gradient norm: 3.79807486
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11357.1875MB
INFO:root:[   85] Training loss: 0.66586474, Validation loss: 0.64620645, Gradient norm: 3.59676158
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11407.75390625MB
INFO:root:[   86] Training loss: 0.66585615, Validation loss: 0.64730886, Gradient norm: 3.15002955
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11445.859375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   87] Training loss: 0.66574578, Validation loss: 0.64589531, Gradient norm: 3.82338546
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11458.73828125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   88] Training loss: 0.66403296, Validation loss: 0.64328881, Gradient norm: 2.37097195
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11496.875MB
INFO:root:[   89] Training loss: 0.66324353, Validation loss: 0.64465267, Gradient norm: 1.89373129
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11535.5MB
INFO:root:[   90] Training loss: 0.66299326, Validation loss: 0.64385123, Gradient norm: 2.11516763
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11573.8515625MB
INFO:root:[   91] Training loss: 0.66309668, Validation loss: 0.64346593, Gradient norm: 2.05741377
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11611.7109375MB
INFO:root:[   92] Training loss: 0.66307753, Validation loss: 0.64382316, Gradient norm: 2.45111319
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11649.80859375MB
INFO:root:[   93] Training loss: 0.66312510, Validation loss: 0.64366579, Gradient norm: 2.38456739
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11688.1640625MB
INFO:root:[   94] Training loss: 0.66319924, Validation loss: 0.64340071, Gradient norm: 2.25128618
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11726.26953125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   95] Training loss: 0.66306177, Validation loss: 0.64403268, Gradient norm: 2.38754146
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11776.8046875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   96] Training loss: 0.66259112, Validation loss: 0.64312986, Gradient norm: 2.03551655
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11815.1875MB
INFO:root:[   97] Training loss: 0.66244635, Validation loss: 0.64323732, Gradient norm: 1.67017939
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11828.33203125MB
INFO:root:[   98] Training loss: 0.66221475, Validation loss: 0.64355399, Gradient norm: 1.89022648
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11866.6875MB
INFO:root:[   99] Training loss: 0.66226009, Validation loss: 0.64307369, Gradient norm: 1.79784596
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11930.015625MB
INFO:root:[  100] Training loss: 0.66229003, Validation loss: 0.64371376, Gradient norm: 1.82202075
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11918.484375MB
INFO:root:[  101] Training loss: 0.66231963, Validation loss: 0.64299396, Gradient norm: 1.80218132
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=11994.02734375MB
INFO:root:[  102] Training loss: 0.66218912, Validation loss: 0.64322303, Gradient norm: 1.87768661
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=12057.5546875MB
INFO:root:[  103] Training loss: 0.66217177, Validation loss: 0.64354346, Gradient norm: 1.84679295
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=12109.375MB
INFO:root:[  104] Training loss: 0.66207932, Validation loss: 0.64341176, Gradient norm: 1.86698752
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=12123.07421875MB
INFO:root:[  105] Training loss: 0.66207425, Validation loss: 0.64288636, Gradient norm: 1.92382671
INFO:root:At the start of the epoch: mem (CPU python)=12454.140625MB; mem (CPU total)=12160.94921875MB
INFO:root:[  106] Training loss: 0.66235655, Validation loss: 0.64211279, Gradient norm: 1.92861941
INFO:root:At the start of the epoch: mem (CPU python)=12456.7578125MB; mem (CPU total)=12199.078125MB
INFO:root:[  107] Training loss: 0.66207677, Validation loss: 0.64348919, Gradient norm: 1.91381183
INFO:root:At the start of the epoch: mem (CPU python)=12494.8515625MB; mem (CPU total)=12237.44921875MB
INFO:root:[  108] Training loss: 0.66227913, Validation loss: 0.64289420, Gradient norm: 1.98514937
INFO:root:At the start of the epoch: mem (CPU python)=12495.87109375MB; mem (CPU total)=12225.84765625MB
INFO:root:[  109] Training loss: 0.66219224, Validation loss: 0.64303244, Gradient norm: 1.99488573
INFO:root:At the start of the epoch: mem (CPU python)=12558.546875MB; mem (CPU total)=12299.89453125MB
INFO:root:[  110] Training loss: 0.66204410, Validation loss: 0.64268875, Gradient norm: 1.99949323
INFO:root:At the start of the epoch: mem (CPU python)=12621.640625MB; mem (CPU total)=12364.1484375MB
INFO:root:[  111] Training loss: 0.66220365, Validation loss: 0.64327519, Gradient norm: 2.25383924
INFO:root:At the start of the epoch: mem (CPU python)=12653.00390625MB; mem (CPU total)=12389.59375MB
INFO:root:[  112] Training loss: 0.66228367, Validation loss: 0.64259786, Gradient norm: 1.99606068
INFO:root:At the start of the epoch: mem (CPU python)=12710.34375MB; mem (CPU total)=12452.88671875MB
INFO:root:[  113] Training loss: 0.66224416, Validation loss: 0.64286666, Gradient norm: 2.10057304
INFO:root:At the start of the epoch: mem (CPU python)=12748.4375MB; mem (CPU total)=12490.9765625MB
INFO:root:[  114] Training loss: 0.66214766, Validation loss: 0.64303009, Gradient norm: 2.02442986
INFO:root:At the start of the epoch: mem (CPU python)=12786.53125MB; mem (CPU total)=12529.1015625MB
INFO:root:[  115] Training loss: 0.66228916, Validation loss: 0.64297823, Gradient norm: 2.08977841
INFO:root:At the start of the epoch: mem (CPU python)=12824.625MB; mem (CPU total)=12566.984375MB
INFO:root:EP 115: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12825.28515625MB; mem (CPU total)=12555.625MB
INFO:root:Training the model took 4987.09s.
INFO:root:Emptying the cuda cache took 0.027s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.91049
INFO:root:EnergyScoreTrain: 0.64079
INFO:root:CRPSTrain: 0.5671
INFO:root:Gaussian NLLTrain: 85603809125.26225
INFO:root:CoverageTrain: 0.57621
INFO:root:IntervalWidthTrain: 2.6258
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.91337
INFO:root:EnergyScoreValidation: 0.64283
INFO:root:CRPSValidation: 0.57003
INFO:root:Gaussian NLLValidation: 87791597213.01337
INFO:root:CoverageValidation: 0.57567
INFO:root:IntervalWidthValidation: 2.62437
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.91432
INFO:root:EnergyScoreTest: 0.64349
INFO:root:CRPSTest: 0.5707
INFO:root:Gaussian NLLTest: 88441053446.14398
INFO:root:CoverageTest: 0.57571
INFO:root:IntervalWidthTest: 2.62417
INFO:root:After validation: mem (CPU python)=12911.55078125MB; mem (CPU total)=12561.80078125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=12911.55078125MB; mem (CPU total)=12561.796875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12911.55078125MB; mem (CPU total)=12561.796875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12911.55078125MB; mem (CPU total)=12561.796875MB
INFO:root:[    1] Training loss: 0.72510601, Validation loss: 0.72112039, Gradient norm: 0.01810890
INFO:root:At the start of the epoch: mem (CPU python)=12911.55078125MB; mem (CPU total)=12646.609375MB
INFO:root:[    2] Training loss: 0.72052298, Validation loss: 0.71919015, Gradient norm: 0.00675424
INFO:root:At the start of the epoch: mem (CPU python)=12942.453125MB; mem (CPU total)=12682.76953125MB
INFO:root:[    3] Training loss: 0.71909408, Validation loss: 0.71738412, Gradient norm: 0.00786393
INFO:root:At the start of the epoch: mem (CPU python)=12980.56640625MB; mem (CPU total)=12720.48046875MB
INFO:root:[    4] Training loss: 0.71555573, Validation loss: 0.70852547, Gradient norm: 0.01884934
INFO:root:At the start of the epoch: mem (CPU python)=13031.1484375MB; mem (CPU total)=12771.34375MB
INFO:root:[    5] Training loss: 0.70912654, Validation loss: 0.70209104, Gradient norm: 0.02501515
INFO:root:At the start of the epoch: mem (CPU python)=13081.7578125MB; mem (CPU total)=12822.2734375MB
INFO:root:[    6] Training loss: 0.70412383, Validation loss: 0.69616411, Gradient norm: 0.02893988
INFO:root:At the start of the epoch: mem (CPU python)=13119.8671875MB; mem (CPU total)=12860.66796875MB
INFO:root:[    7] Training loss: 0.69942329, Validation loss: 0.69011189, Gradient norm: 0.03515923
INFO:root:At the start of the epoch: mem (CPU python)=13145.46484375MB; mem (CPU total)=12886.08984375MB
INFO:root:[    8] Training loss: 0.69472518, Validation loss: 0.68390373, Gradient norm: 0.03960371
INFO:root:At the start of the epoch: mem (CPU python)=13196.0625MB; mem (CPU total)=12937.9375MB
INFO:root:[    9] Training loss: 0.69055973, Validation loss: 0.67895479, Gradient norm: 0.04053034
INFO:root:At the start of the epoch: mem (CPU python)=13234.15234375MB; mem (CPU total)=12975.078125MB
INFO:root:[   10] Training loss: 0.68694454, Validation loss: 0.67419456, Gradient norm: 0.03857449
INFO:root:At the start of the epoch: mem (CPU python)=13272.25390625MB; mem (CPU total)=13013.6640625MB
INFO:root:[   11] Training loss: 0.68383039, Validation loss: 0.67067870, Gradient norm: 0.04019054
INFO:root:At the start of the epoch: mem (CPU python)=13310.34765625MB; mem (CPU total)=13051.5390625MB
INFO:root:[   12] Training loss: 0.68111850, Validation loss: 0.66691943, Gradient norm: 0.04248511
INFO:root:At the start of the epoch: mem (CPU python)=13348.44140625MB; mem (CPU total)=13089.67578125MB
INFO:root:[   13] Training loss: 0.67903499, Validation loss: 0.66463989, Gradient norm: 0.04130849
INFO:root:At the start of the epoch: mem (CPU python)=13391.734375MB; mem (CPU total)=13133.07421875MB
INFO:root:[   14] Training loss: 0.67675393, Validation loss: 0.66227530, Gradient norm: 0.04266226
INFO:root:At the start of the epoch: mem (CPU python)=13404.828125MB; mem (CPU total)=13146.25390625MB
INFO:root:[   15] Training loss: 0.67514497, Validation loss: 0.66094251, Gradient norm: 0.05235778
INFO:root:At the start of the epoch: mem (CPU python)=13442.921875MB; mem (CPU total)=13184.60546875MB
INFO:root:[   16] Training loss: 0.67380335, Validation loss: 0.65828051, Gradient norm: 0.05637006
INFO:root:At the start of the epoch: mem (CPU python)=13481.015625MB; mem (CPU total)=13222.765625MB
INFO:root:[   17] Training loss: 0.67258115, Validation loss: 0.65654203, Gradient norm: 0.05999259
INFO:root:At the start of the epoch: mem (CPU python)=13551.328125MB; mem (CPU total)=13232.0078125MB
INFO:root:[   18] Training loss: 0.67128196, Validation loss: 0.65601824, Gradient norm: 0.06539800
INFO:root:At the start of the epoch: mem (CPU python)=13569.6328125MB; mem (CPU total)=13312.35546875MB
INFO:root:[   19] Training loss: 0.67022783, Validation loss: 0.65414695, Gradient norm: 0.06499381
INFO:root:At the start of the epoch: mem (CPU python)=13607.7265625MB; mem (CPU total)=13350.78125MB
INFO:root:[   20] Training loss: 0.66927881, Validation loss: 0.65351355, Gradient norm: 0.07798504
INFO:root:At the start of the epoch: mem (CPU python)=13638.0703125MB; mem (CPU total)=13374.18359375MB
INFO:root:[   21] Training loss: 0.66849507, Validation loss: 0.65300284, Gradient norm: 0.07736169
INFO:root:At the start of the epoch: mem (CPU python)=13678.80078125MB; mem (CPU total)=13421.1171875MB
INFO:root:[   22] Training loss: 0.66758445, Validation loss: 0.65067674, Gradient norm: 0.08519557
INFO:root:At the start of the epoch: mem (CPU python)=13716.89453125MB; mem (CPU total)=13459.25MB
INFO:root:[   23] Training loss: 0.66698078, Validation loss: 0.64949069, Gradient norm: 0.09735168
INFO:root:At the start of the epoch: mem (CPU python)=13779.98828125MB; mem (CPU total)=13522.56640625MB
INFO:root:[   24] Training loss: 0.66609099, Validation loss: 0.64887643, Gradient norm: 0.10578008
INFO:root:At the start of the epoch: mem (CPU python)=13780.61328125MB; mem (CPU total)=13523.03125MB
INFO:root:[   25] Training loss: 0.66545125, Validation loss: 0.64819954, Gradient norm: 0.12669238
INFO:root:At the start of the epoch: mem (CPU python)=13831.1796875MB; mem (CPU total)=13573.8984375MB
INFO:root:[   26] Training loss: 0.66482169, Validation loss: 0.64841588, Gradient norm: 0.12470768
INFO:root:At the start of the epoch: mem (CPU python)=13881.77734375MB; mem (CPU total)=13624.5078125MB
INFO:root:[   27] Training loss: 0.66430688, Validation loss: 0.64838023, Gradient norm: 0.13723102
INFO:root:At the start of the epoch: mem (CPU python)=13894.90234375MB; mem (CPU total)=13637.67578125MB
INFO:root:[   28] Training loss: 0.66367667, Validation loss: 0.64827865, Gradient norm: 0.14442922
INFO:root:At the start of the epoch: mem (CPU python)=13945.52734375MB; mem (CPU total)=13688.5546875MB
INFO:root:[   29] Training loss: 0.66312695, Validation loss: 0.64874307, Gradient norm: 0.17367069
INFO:root:At the start of the epoch: mem (CPU python)=13971.1484375MB; mem (CPU total)=13716.1796875MB
INFO:root:[   30] Training loss: 0.66291584, Validation loss: 0.64764836, Gradient norm: 0.18770148
INFO:root:At the start of the epoch: mem (CPU python)=14013.24609375MB; mem (CPU total)=13756.296875MB
INFO:root:[   31] Training loss: 0.66233722, Validation loss: 0.64604661, Gradient norm: 0.19038268
INFO:root:At the start of the epoch: mem (CPU python)=14063.7578125MB; mem (CPU total)=13806.9921875MB
INFO:root:[   32] Training loss: 0.66174366, Validation loss: 0.64586838, Gradient norm: 0.20678053
INFO:root:At the start of the epoch: mem (CPU python)=14110.40625MB; mem (CPU total)=13853.6015625MB
INFO:root:[   33] Training loss: 0.66145930, Validation loss: 0.64598853, Gradient norm: 0.22536276
INFO:root:At the start of the epoch: mem (CPU python)=14148.50390625MB; mem (CPU total)=13891.98046875MB
INFO:root:[   34] Training loss: 0.66097194, Validation loss: 0.64529947, Gradient norm: 0.22708900
INFO:root:At the start of the epoch: mem (CPU python)=14186.6015625MB; mem (CPU total)=13929.859375MB
INFO:root:[   35] Training loss: 0.66060319, Validation loss: 0.64596362, Gradient norm: 0.26804615
INFO:root:At the start of the epoch: mem (CPU python)=14212.1953125MB; mem (CPU total)=13957.51953125MB
INFO:root:[   36] Training loss: 0.66041366, Validation loss: 0.64487097, Gradient norm: 0.29377163
INFO:root:At the start of the epoch: mem (CPU python)=14250.2890625MB; mem (CPU total)=13996.10546875MB
INFO:root:[   37] Training loss: 0.65998748, Validation loss: 0.64501322, Gradient norm: 0.28977640
INFO:root:At the start of the epoch: mem (CPU python)=14300.88671875MB; mem (CPU total)=14046.4140625MB
INFO:root:[   38] Training loss: 0.65982943, Validation loss: 0.64435968, Gradient norm: 0.32656467
INFO:root:At the start of the epoch: mem (CPU python)=14326.48046875MB; mem (CPU total)=14070.09375MB
INFO:root:[   39] Training loss: 0.65927374, Validation loss: 0.64324382, Gradient norm: 0.32884395
INFO:root:At the start of the epoch: mem (CPU python)=14364.57421875MB; mem (CPU total)=14108.47265625MB
INFO:root:[   40] Training loss: 0.65903996, Validation loss: 0.64286834, Gradient norm: 0.35165423
INFO:root:At the start of the epoch: mem (CPU python)=14402.671875MB; mem (CPU total)=14146.85546875MB
INFO:root:[   41] Training loss: 0.65899741, Validation loss: 0.64124100, Gradient norm: 0.39266509
INFO:root:At the start of the epoch: mem (CPU python)=14440.76953125MB; mem (CPU total)=14185.4765625MB
INFO:root:[   42] Training loss: 0.65844571, Validation loss: 0.64225304, Gradient norm: 0.39382731
INFO:root:At the start of the epoch: mem (CPU python)=14446.390625MB; mem (CPU total)=14190.91015625MB
INFO:root:[   43] Training loss: 0.65836583, Validation loss: 0.64085803, Gradient norm: 0.42052256
INFO:root:At the start of the epoch: mem (CPU python)=14527.46875MB; mem (CPU total)=14249.234375MB
INFO:root:[   44] Training loss: 0.65831560, Validation loss: 0.64051412, Gradient norm: 0.45313018
INFO:root:At the start of the epoch: mem (CPU python)=14555.25MB; mem (CPU total)=14299.87890625MB
INFO:root:[   45] Training loss: 0.65790041, Validation loss: 0.64084996, Gradient norm: 0.51447768
INFO:root:At the start of the epoch: mem (CPU python)=14623.34375MB; mem (CPU total)=14368.38671875MB
INFO:root:[   46] Training loss: 0.65760958, Validation loss: 0.63979306, Gradient norm: 0.47375708
INFO:root:At the start of the epoch: mem (CPU python)=14661.4375MB; mem (CPU total)=14406.515625MB
INFO:root:[   47] Training loss: 0.65747275, Validation loss: 0.64010489, Gradient norm: 0.52007932
INFO:root:At the start of the epoch: mem (CPU python)=14686.95703125MB; mem (CPU total)=14431.70703125MB
INFO:root:[   48] Training loss: 0.65718853, Validation loss: 0.63883192, Gradient norm: 0.55728059
INFO:root:At the start of the epoch: mem (CPU python)=14712.55078125MB; mem (CPU total)=14457.57421875MB
INFO:root:[   49] Training loss: 0.65687958, Validation loss: 0.63897382, Gradient norm: 0.55667155
INFO:root:At the start of the epoch: mem (CPU python)=14745.53125MB; mem (CPU total)=14490.515625MB
INFO:root:[   50] Training loss: 0.65689371, Validation loss: 0.63827245, Gradient norm: 0.65495118
INFO:root:At the start of the epoch: mem (CPU python)=14796.12109375MB; mem (CPU total)=14541.0703125MB
INFO:root:[   51] Training loss: 0.65669795, Validation loss: 0.63851253, Gradient norm: 0.63342494
INFO:root:At the start of the epoch: mem (CPU python)=14834.2265625MB; mem (CPU total)=14579.42578125MB
INFO:root:[   52] Training loss: 0.65653147, Validation loss: 0.63774402, Gradient norm: 0.68999754
INFO:root:At the start of the epoch: mem (CPU python)=14872.3203125MB; mem (CPU total)=14617.54296875MB
INFO:root:[   53] Training loss: 0.65660697, Validation loss: 0.63705405, Gradient norm: 0.71084719
INFO:root:At the start of the epoch: mem (CPU python)=14910.4140625MB; mem (CPU total)=14655.9140625MB
INFO:root:[   54] Training loss: 0.65653832, Validation loss: 0.63752751, Gradient norm: 0.74456254
INFO:root:At the start of the epoch: mem (CPU python)=14948.51171875MB; mem (CPU total)=14694.0390625MB
INFO:root:[   55] Training loss: 0.65623904, Validation loss: 0.63686318, Gradient norm: 0.74747500
INFO:root:At the start of the epoch: mem (CPU python)=14986.60546875MB; mem (CPU total)=14732.1328125MB
INFO:root:[   56] Training loss: 0.65609060, Validation loss: 0.63609825, Gradient norm: 0.83791060
INFO:root:At the start of the epoch: mem (CPU python)=15012.203125MB; mem (CPU total)=14759.20703125MB
INFO:root:[   57] Training loss: 0.65597406, Validation loss: 0.63732184, Gradient norm: 0.98264371
INFO:root:At the start of the epoch: mem (CPU python)=15086.42578125MB; mem (CPU total)=14797.546875MB
INFO:root:[   58] Training loss: 0.65620407, Validation loss: 0.63618574, Gradient norm: 0.97045971
INFO:root:At the start of the epoch: mem (CPU python)=15094.640625MB; mem (CPU total)=14842.3125MB
INFO:root:[   59] Training loss: 0.65610701, Validation loss: 0.63700892, Gradient norm: 0.92042952
INFO:root:At the start of the epoch: mem (CPU python)=15138.984375MB; mem (CPU total)=14886.8359375MB
INFO:root:[   60] Training loss: 0.65612736, Validation loss: 0.63631239, Gradient norm: 1.10095158
INFO:root:At the start of the epoch: mem (CPU python)=15214.58203125MB; mem (CPU total)=14962.6953125MB
INFO:root:[   61] Training loss: 0.65574335, Validation loss: 0.63713595, Gradient norm: 1.11734710
INFO:root:At the start of the epoch: mem (CPU python)=15252.6796875MB; mem (CPU total)=15000.8203125MB
INFO:root:[   62] Training loss: 0.65571688, Validation loss: 0.63807959, Gradient norm: 1.15151596
INFO:root:At the start of the epoch: mem (CPU python)=15290.7734375MB; mem (CPU total)=15038.68359375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   63] Training loss: 0.65560976, Validation loss: 0.63712252, Gradient norm: 1.28252394
INFO:root:At the start of the epoch: mem (CPU python)=15328.8671875MB; mem (CPU total)=15076.80859375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   64] Training loss: 0.65462389, Validation loss: 0.63583669, Gradient norm: 0.79921019
INFO:root:At the start of the epoch: mem (CPU python)=15329.5234375MB; mem (CPU total)=15066.7578125MB
INFO:root:[   65] Training loss: 0.65410751, Validation loss: 0.63546760, Gradient norm: 0.66089824
INFO:root:At the start of the epoch: mem (CPU python)=15367.55859375MB; mem (CPU total)=15117.1484375MB
INFO:root:[   66] Training loss: 0.65414000, Validation loss: 0.63530591, Gradient norm: 0.68488448
INFO:root:At the start of the epoch: mem (CPU python)=15405.65234375MB; mem (CPU total)=15155.55859375MB
INFO:root:[   67] Training loss: 0.65390824, Validation loss: 0.63525190, Gradient norm: 0.74038588
INFO:root:At the start of the epoch: mem (CPU python)=15473.75MB; mem (CPU total)=15223.83984375MB
INFO:root:[   68] Training loss: 0.65382188, Validation loss: 0.63510927, Gradient norm: 0.71119185
INFO:root:At the start of the epoch: mem (CPU python)=15511.84765625MB; mem (CPU total)=15262.2109375MB
INFO:root:[   69] Training loss: 0.65372224, Validation loss: 0.63509912, Gradient norm: 0.78658637
INFO:root:At the start of the epoch: mem (CPU python)=15542.73046875MB; mem (CPU total)=15255.75390625MB
INFO:root:[   70] Training loss: 0.65373895, Validation loss: 0.63502694, Gradient norm: 0.83372108
INFO:root:At the start of the epoch: mem (CPU python)=15545.53515625MB; mem (CPU total)=15293.875MB
INFO:root:[   71] Training loss: 0.65375520, Validation loss: 0.63452762, Gradient norm: 0.81482387
INFO:root:At the start of the epoch: mem (CPU python)=15576.52734375MB; mem (CPU total)=15322.78125MB
INFO:root:[   72] Training loss: 0.65380382, Validation loss: 0.63493923, Gradient norm: 0.88033554
INFO:root:At the start of the epoch: mem (CPU python)=15614.2265625MB; mem (CPU total)=15360.92578125MB
INFO:root:[   73] Training loss: 0.65364355, Validation loss: 0.63459280, Gradient norm: 0.88578127
INFO:root:At the start of the epoch: mem (CPU python)=15646.0703125MB; mem (CPU total)=15392.78125MB
INFO:root:[   74] Training loss: 0.65342878, Validation loss: 0.63408856, Gradient norm: 0.90619470
INFO:root:At the start of the epoch: mem (CPU python)=15696.6640625MB; mem (CPU total)=15443.64453125MB
INFO:root:[   75] Training loss: 0.65349013, Validation loss: 0.63399832, Gradient norm: 0.89412197
INFO:root:At the start of the epoch: mem (CPU python)=15772.265625MB; mem (CPU total)=15519.1328125MB
INFO:root:[   76] Training loss: 0.65359335, Validation loss: 0.63538848, Gradient norm: 0.94779588
INFO:root:At the start of the epoch: mem (CPU python)=15810.359375MB; mem (CPU total)=15557.484375MB
INFO:root:[   77] Training loss: 0.65347462, Validation loss: 0.63439643, Gradient norm: 0.97767595
INFO:root:At the start of the epoch: mem (CPU python)=15841.3828125MB; mem (CPU total)=15564.63671875MB
INFO:root:[   78] Training loss: 0.65352932, Validation loss: 0.63475029, Gradient norm: 1.00732732
INFO:root:At the start of the epoch: mem (CPU python)=15850.3046875MB; mem (CPU total)=15597.57421875MB
INFO:root:[   79] Training loss: 0.65340348, Validation loss: 0.63420498, Gradient norm: 1.01344388
INFO:root:At the start of the epoch: mem (CPU python)=15900.8984375MB; mem (CPU total)=15648.11328125MB
INFO:root:[   80] Training loss: 0.65323426, Validation loss: 0.63436057, Gradient norm: 1.06372196
INFO:root:At the start of the epoch: mem (CPU python)=15938.9921875MB; mem (CPU total)=15687.0234375MB
INFO:root:[   81] Training loss: 0.65343251, Validation loss: 0.63381163, Gradient norm: 1.06021796
INFO:root:At the start of the epoch: mem (CPU python)=15977.08984375MB; mem (CPU total)=15725.14453125MB
INFO:root:[   82] Training loss: 0.65331286, Validation loss: 0.63428127, Gradient norm: 1.12206138
INFO:root:At the start of the epoch: mem (CPU python)=16015.18359375MB; mem (CPU total)=15763.3046875MB
INFO:root:[   83] Training loss: 0.65335873, Validation loss: 0.63387790, Gradient norm: 1.06236805
INFO:root:At the start of the epoch: mem (CPU python)=16028.3984375MB; mem (CPU total)=15776.69921875MB
INFO:root:[   84] Training loss: 0.65306012, Validation loss: 0.63360260, Gradient norm: 1.11340863
INFO:root:At the start of the epoch: mem (CPU python)=16091.49609375MB; mem (CPU total)=15840.0234375MB
INFO:root:[   85] Training loss: 0.65322738, Validation loss: 0.63445658, Gradient norm: 1.12910901
INFO:root:At the start of the epoch: mem (CPU python)=16122.50390625MB; mem (CPU total)=15870.671875MB
INFO:root:[   86] Training loss: 0.65317459, Validation loss: 0.63331746, Gradient norm: 1.17126044
INFO:root:At the start of the epoch: mem (CPU python)=16172.765625MB; mem (CPU total)=15921.51953125MB
INFO:root:[   87] Training loss: 0.65314545, Validation loss: 0.63395231, Gradient norm: 1.29207660
INFO:root:At the start of the epoch: mem (CPU python)=16193.1640625MB; mem (CPU total)=15943.98828125MB
INFO:root:[   88] Training loss: 0.65309102, Validation loss: 0.63377986, Gradient norm: 1.18506745
INFO:root:At the start of the epoch: mem (CPU python)=16218.7890625MB; mem (CPU total)=15967.1875MB
INFO:root:[   89] Training loss: 0.65301178, Validation loss: 0.63319796, Gradient norm: 1.24913341
INFO:root:At the start of the epoch: mem (CPU python)=16256.8828125MB; mem (CPU total)=16005.59765625MB
INFO:root:[   90] Training loss: 0.65311357, Validation loss: 0.63459534, Gradient norm: 1.29480690
INFO:root:At the start of the epoch: mem (CPU python)=16319.94921875MB; mem (CPU total)=16068.90234375MB
INFO:root:[   91] Training loss: 0.65298594, Validation loss: 0.63471591, Gradient norm: 1.31109797
INFO:root:At the start of the epoch: mem (CPU python)=16370.54296875MB; mem (CPU total)=16119.48046875MB
INFO:root:[   92] Training loss: 0.65296613, Validation loss: 0.63345293, Gradient norm: 1.36338312
INFO:root:At the start of the epoch: mem (CPU python)=16408.64453125MB; mem (CPU total)=16157.765625MB
INFO:root:[   93] Training loss: 0.65296872, Validation loss: 0.63422663, Gradient norm: 1.38972163
INFO:root:At the start of the epoch: mem (CPU python)=16426.85546875MB; mem (CPU total)=16175.6640625MB
INFO:root:[   94] Training loss: 0.65297208, Validation loss: 0.63416117, Gradient norm: 1.34123059
INFO:root:At the start of the epoch: mem (CPU python)=16484.83203125MB; mem (CPU total)=16234.0625MB
INFO:root:[   95] Training loss: 0.65275681, Validation loss: 0.63360101, Gradient norm: 1.40548922
INFO:root:At the start of the epoch: mem (CPU python)=16535.45703125MB; mem (CPU total)=16284.2890625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   96] Training loss: 0.65277885, Validation loss: 0.63363961, Gradient norm: 1.49336043
INFO:root:At the start of the epoch: mem (CPU python)=16536.171875MB; mem (CPU total)=16271.40625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   97] Training loss: 0.65267546, Validation loss: 0.63281907, Gradient norm: 1.28869972
INFO:root:At the start of the epoch: mem (CPU python)=16586.62109375MB; mem (CPU total)=16334.95703125MB
INFO:root:[   98] Training loss: 0.65233052, Validation loss: 0.63331973, Gradient norm: 0.98654699
INFO:root:At the start of the epoch: mem (CPU python)=16587.21484375MB; mem (CPU total)=16336.671875MB
INFO:root:[   99] Training loss: 0.65228967, Validation loss: 0.63301435, Gradient norm: 1.03842174
INFO:root:At the start of the epoch: mem (CPU python)=16637.8359375MB; mem (CPU total)=16387.04296875MB
INFO:root:[  100] Training loss: 0.65225723, Validation loss: 0.63305247, Gradient norm: 1.04323970
INFO:root:At the start of the epoch: mem (CPU python)=16701.1015625MB; mem (CPU total)=16450.5546875MB
INFO:root:[  101] Training loss: 0.65236179, Validation loss: 0.63314114, Gradient norm: 1.05278598
INFO:root:At the start of the epoch: mem (CPU python)=16744.02734375MB; mem (CPU total)=16493.703125MB
INFO:root:[  102] Training loss: 0.65244204, Validation loss: 0.63254698, Gradient norm: 1.07858530
INFO:root:At the start of the epoch: mem (CPU python)=16782.125MB; mem (CPU total)=16532.546875MB
INFO:root:[  103] Training loss: 0.65240317, Validation loss: 0.63316352, Gradient norm: 1.14714741
INFO:root:At the start of the epoch: mem (CPU python)=16802.69140625MB; mem (CPU total)=16552.9609375MB
INFO:root:[  104] Training loss: 0.65234769, Validation loss: 0.63291784, Gradient norm: 1.06944991
INFO:root:At the start of the epoch: mem (CPU python)=16840.78515625MB; mem (CPU total)=16590.75MB
INFO:root:[  105] Training loss: 0.65226570, Validation loss: 0.63318181, Gradient norm: 1.11578613
INFO:root:At the start of the epoch: mem (CPU python)=16878.8828125MB; mem (CPU total)=16628.87109375MB
INFO:root:[  106] Training loss: 0.65226379, Validation loss: 0.63293009, Gradient norm: 1.14048047
INFO:root:At the start of the epoch: mem (CPU python)=16916.9765625MB; mem (CPU total)=16667.27734375MB
INFO:root:[  107] Training loss: 0.65246697, Validation loss: 0.63352363, Gradient norm: 1.10191192
INFO:root:At the start of the epoch: mem (CPU python)=16980.07421875MB; mem (CPU total)=16730.32421875MB
INFO:root:[  108] Training loss: 0.65229893, Validation loss: 0.63318732, Gradient norm: 1.17143943
INFO:root:At the start of the epoch: mem (CPU python)=17018.16796875MB; mem (CPU total)=16768.6640625MB
INFO:root:[  109] Training loss: 0.65208602, Validation loss: 0.63280626, Gradient norm: 1.19530129
INFO:root:At the start of the epoch: mem (CPU python)=17031.265625MB; mem (CPU total)=16781.62890625MB
INFO:root:[  110] Training loss: 0.65218671, Validation loss: 0.63389226, Gradient norm: 1.15931298
INFO:root:At the start of the epoch: mem (CPU python)=17069.359375MB; mem (CPU total)=16819.76953125MB
INFO:root:[  111] Training loss: 0.65231797, Validation loss: 0.63350811, Gradient norm: 1.16121645
INFO:root:At the start of the epoch: mem (CPU python)=17107.453125MB; mem (CPU total)=16856.640625MB
INFO:root:EP 111: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=17125.55078125MB; mem (CPU total)=16874.5390625MB
INFO:root:Training the model took 5447.597s.
INFO:root:Emptying the cuda cache took 0.026s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.89657
INFO:root:EnergyScoreTrain: 0.63104
INFO:root:CRPSTrain: 0.50317
INFO:root:Gaussian NLLTrain: 308668895.01333
INFO:root:CoverageTrain: 0.85905
INFO:root:IntervalWidthTrain: 3.07192
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89937
INFO:root:EnergyScoreValidation: 0.63304
INFO:root:CRPSValidation: 0.50505
INFO:root:Gaussian NLLValidation: 328899002.98667
INFO:root:CoverageValidation: 0.85857
INFO:root:IntervalWidthValidation: 3.07255
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.90144
INFO:root:EnergyScoreTest: 0.6345
INFO:root:CRPSTest: 0.50681
INFO:root:Gaussian NLLTest: 328833587.904
INFO:root:CoverageTest: 0.85837
INFO:root:IntervalWidthTest: 3.07848
INFO:root:After validation: mem (CPU python)=17252.09765625MB; mem (CPU total)=16956.35546875MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=17252.09765625MB; mem (CPU total)=16863.90234375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=17252.09765625MB; mem (CPU total)=16869.15234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=17252.09765625MB; mem (CPU total)=16869.3984375MB
INFO:root:[    1] Training loss: 0.72463089, Validation loss: 0.72057663, Gradient norm: 0.01344697
INFO:root:At the start of the epoch: mem (CPU python)=17252.09765625MB; mem (CPU total)=16969.0390625MB
INFO:root:[    2] Training loss: 0.72044072, Validation loss: 0.71966460, Gradient norm: 0.00624212
INFO:root:At the start of the epoch: mem (CPU python)=17281.42578125MB; mem (CPU total)=17032.81640625MB
INFO:root:[    3] Training loss: 0.71937764, Validation loss: 0.71873936, Gradient norm: 0.01053483
INFO:root:At the start of the epoch: mem (CPU python)=17319.53515625MB; mem (CPU total)=17070.69140625MB
INFO:root:[    4] Training loss: 0.71697957, Validation loss: 0.71161537, Gradient norm: 0.02150893
INFO:root:At the start of the epoch: mem (CPU python)=17345.15625MB; mem (CPU total)=17098.109375MB
INFO:root:[    5] Training loss: 0.71131154, Validation loss: 0.70403381, Gradient norm: 0.03249329
INFO:root:At the start of the epoch: mem (CPU python)=17358.265625MB; mem (CPU total)=17109.55859375MB
INFO:root:[    6] Training loss: 0.70614825, Validation loss: 0.69845138, Gradient norm: 0.03927684
INFO:root:At the start of the epoch: mem (CPU python)=17421.359375MB; mem (CPU total)=17172.92578125MB
INFO:root:[    7] Training loss: 0.70228725, Validation loss: 0.69420439, Gradient norm: 0.04527654
INFO:root:At the start of the epoch: mem (CPU python)=17452.328125MB; mem (CPU total)=17199.85546875MB
INFO:root:[    8] Training loss: 0.69892223, Validation loss: 0.69016874, Gradient norm: 0.05222213
INFO:root:At the start of the epoch: mem (CPU python)=17510.05078125MB; mem (CPU total)=17263.1484375MB
INFO:root:[    9] Training loss: 0.69596592, Validation loss: 0.68622108, Gradient norm: 0.04578728
INFO:root:At the start of the epoch: mem (CPU python)=17548.1484375MB; mem (CPU total)=17301.265625MB
INFO:root:[   10] Training loss: 0.69326185, Validation loss: 0.68365960, Gradient norm: 0.04357776
INFO:root:At the start of the epoch: mem (CPU python)=17573.7421875MB; mem (CPU total)=17326.6796875MB
INFO:root:[   11] Training loss: 0.69095274, Validation loss: 0.68094268, Gradient norm: 0.04988205
INFO:root:At the start of the epoch: mem (CPU python)=17611.83984375MB; mem (CPU total)=17363.69921875MB
INFO:root:[   12] Training loss: 0.68907790, Validation loss: 0.67858156, Gradient norm: 0.05467436
INFO:root:At the start of the epoch: mem (CPU python)=17674.93359375MB; mem (CPU total)=17427.015625MB
INFO:root:[   13] Training loss: 0.68722953, Validation loss: 0.67670649, Gradient norm: 0.04945919
INFO:root:At the start of the epoch: mem (CPU python)=17705.78515625MB; mem (CPU total)=17439.83203125MB
INFO:root:[   14] Training loss: 0.68558436, Validation loss: 0.67364638, Gradient norm: 0.06037721
INFO:root:At the start of the epoch: mem (CPU python)=17738.62109375MB; mem (CPU total)=17490.40625MB
INFO:root:[   15] Training loss: 0.68414355, Validation loss: 0.67268868, Gradient norm: 0.05503789
INFO:root:At the start of the epoch: mem (CPU python)=17769.55859375MB; mem (CPU total)=17505.81640625MB
INFO:root:[   16] Training loss: 0.68263031, Validation loss: 0.66956970, Gradient norm: 0.06744577
INFO:root:At the start of the epoch: mem (CPU python)=17815.32421875MB; mem (CPU total)=17569.62109375MB
INFO:root:[   17] Training loss: 0.68182859, Validation loss: 0.66916211, Gradient norm: 0.07531994
INFO:root:At the start of the epoch: mem (CPU python)=17853.41796875MB; mem (CPU total)=17607.5MB
INFO:root:[   18] Training loss: 0.68048317, Validation loss: 0.66756203, Gradient norm: 0.07143571
INFO:root:At the start of the epoch: mem (CPU python)=17891.515625MB; mem (CPU total)=17645.5859375MB
INFO:root:[   19] Training loss: 0.67946277, Validation loss: 0.66731562, Gradient norm: 0.08095723
INFO:root:At the start of the epoch: mem (CPU python)=17941.6015625MB; mem (CPU total)=17696.171875MB
INFO:root:[   20] Training loss: 0.67854286, Validation loss: 0.66542998, Gradient norm: 0.08922371
INFO:root:At the start of the epoch: mem (CPU python)=17979.6953125MB; mem (CPU total)=17733.984375MB
INFO:root:[   21] Training loss: 0.67764544, Validation loss: 0.66417759, Gradient norm: 0.09846537
INFO:root:At the start of the epoch: mem (CPU python)=18017.79296875MB; mem (CPU total)=17772.35546875MB
INFO:root:[   22] Training loss: 0.67674597, Validation loss: 0.66414706, Gradient norm: 0.09218734
INFO:root:At the start of the epoch: mem (CPU python)=18055.88671875MB; mem (CPU total)=17810.24609375MB
INFO:root:[   23] Training loss: 0.67613413, Validation loss: 0.66282561, Gradient norm: 0.11117048
INFO:root:At the start of the epoch: mem (CPU python)=18068.98046875MB; mem (CPU total)=17828.19140625MB
INFO:root:[   24] Training loss: 0.67529593, Validation loss: 0.66306368, Gradient norm: 0.11424343
INFO:root:At the start of the epoch: mem (CPU python)=18107.07421875MB; mem (CPU total)=17866.5234375MB
INFO:root:[   25] Training loss: 0.67453494, Validation loss: 0.66141491, Gradient norm: 0.13491650
INFO:root:At the start of the epoch: mem (CPU python)=18157.67578125MB; mem (CPU total)=17917.3984375MB
INFO:root:[   26] Training loss: 0.67394698, Validation loss: 0.66176485, Gradient norm: 0.13888312
INFO:root:At the start of the epoch: mem (CPU python)=18195.7734375MB; mem (CPU total)=17955.5390625MB
INFO:root:[   27] Training loss: 0.67335504, Validation loss: 0.66243638, Gradient norm: 0.15146618
INFO:root:At the start of the epoch: mem (CPU python)=18233.8671875MB; mem (CPU total)=17995.34765625MB
INFO:root:[   28] Training loss: 0.67268765, Validation loss: 0.66010632, Gradient norm: 0.15799660
INFO:root:At the start of the epoch: mem (CPU python)=18291.09765625MB; mem (CPU total)=18052.48046875MB
INFO:root:[   29] Training loss: 0.67207337, Validation loss: 0.66083333, Gradient norm: 0.16258510
INFO:root:At the start of the epoch: mem (CPU python)=18329.1796875MB; mem (CPU total)=18090.31640625MB
INFO:root:[   30] Training loss: 0.67139006, Validation loss: 0.66279055, Gradient norm: 0.17509245
INFO:root:At the start of the epoch: mem (CPU python)=18367.2734375MB; mem (CPU total)=18128.65234375MB
INFO:root:[   31] Training loss: 0.67104995, Validation loss: 0.65994235, Gradient norm: 0.20187317
INFO:root:At the start of the epoch: mem (CPU python)=18386.24609375MB; mem (CPU total)=18148.83984375MB
INFO:root:[   32] Training loss: 0.67043628, Validation loss: 0.66017221, Gradient norm: 0.23749713
INFO:root:At the start of the epoch: mem (CPU python)=18424.34375MB; mem (CPU total)=18187.20703125MB
INFO:root:[   33] Training loss: 0.66984925, Validation loss: 0.66167866, Gradient norm: 0.23174427
INFO:root:At the start of the epoch: mem (CPU python)=18462.23046875MB; mem (CPU total)=18161.0859375MB
INFO:root:[   34] Training loss: 0.66922732, Validation loss: 0.65748996, Gradient norm: 0.26816129
INFO:root:At the start of the epoch: mem (CPU python)=18488.03515625MB; mem (CPU total)=18248.171875MB
INFO:root:[   35] Training loss: 0.66842204, Validation loss: 0.65775936, Gradient norm: 0.27112900
INFO:root:At the start of the epoch: mem (CPU python)=18519.24609375MB; mem (CPU total)=18263.5859375MB
INFO:root:[   36] Training loss: 0.66796383, Validation loss: 0.65888244, Gradient norm: 0.24258034
INFO:root:At the start of the epoch: mem (CPU python)=18542.9765625MB; mem (CPU total)=18305.49609375MB
INFO:root:[   37] Training loss: 0.66737087, Validation loss: 0.65699136, Gradient norm: 0.26702058
INFO:root:At the start of the epoch: mem (CPU python)=18589.94140625MB; mem (CPU total)=18353.22265625MB
INFO:root:[   38] Training loss: 0.66662014, Validation loss: 0.65942970, Gradient norm: 0.29139569
INFO:root:At the start of the epoch: mem (CPU python)=18640.41796875MB; mem (CPU total)=18400.78125MB
INFO:root:[   39] Training loss: 0.66647914, Validation loss: 0.65666262, Gradient norm: 0.35309151
INFO:root:At the start of the epoch: mem (CPU python)=18716.1328125MB; mem (CPU total)=18478.87109375MB
INFO:root:[   40] Training loss: 0.66566123, Validation loss: 0.65879482, Gradient norm: 0.32693097
INFO:root:At the start of the epoch: mem (CPU python)=18716.35546875MB; mem (CPU total)=18466.6015625MB
INFO:root:[   41] Training loss: 0.66511818, Validation loss: 0.65257271, Gradient norm: 0.37317957
INFO:root:At the start of the epoch: mem (CPU python)=18767.203125MB; mem (CPU total)=18529.67578125MB
INFO:root:[   42] Training loss: 0.66472152, Validation loss: 0.65304736, Gradient norm: 0.43216970
INFO:root:At the start of the epoch: mem (CPU python)=18805.30078125MB; mem (CPU total)=18567.8203125MB
INFO:root:[   43] Training loss: 0.66426941, Validation loss: 0.65131595, Gradient norm: 0.47059673
INFO:root:At the start of the epoch: mem (CPU python)=18843.39453125MB; mem (CPU total)=18605.9375MB
INFO:root:[   44] Training loss: 0.66358567, Validation loss: 0.65140871, Gradient norm: 0.39661914
INFO:root:At the start of the epoch: mem (CPU python)=18856.609375MB; mem (CPU total)=18617.10546875MB
INFO:root:[   45] Training loss: 0.66342148, Validation loss: 0.65519672, Gradient norm: 0.39424257
INFO:root:At the start of the epoch: mem (CPU python)=18907.0859375MB; mem (CPU total)=18667.70703125MB
INFO:root:[   46] Training loss: 0.66285640, Validation loss: 0.64870122, Gradient norm: 0.46766168
INFO:root:At the start of the epoch: mem (CPU python)=18957.6796875MB; mem (CPU total)=18718.64453125MB
INFO:root:[   47] Training loss: 0.66234783, Validation loss: 0.64902943, Gradient norm: 0.48133712
INFO:root:At the start of the epoch: mem (CPU python)=18970.89453125MB; mem (CPU total)=18731.87109375MB
INFO:root:[   48] Training loss: 0.66167337, Validation loss: 0.64658139, Gradient norm: 0.50118838
INFO:root:At the start of the epoch: mem (CPU python)=19033.8671875MB; mem (CPU total)=18795.18359375MB
INFO:root:[   49] Training loss: 0.66130232, Validation loss: 0.64810805, Gradient norm: 0.50289041
INFO:root:At the start of the epoch: mem (CPU python)=19059.46484375MB; mem (CPU total)=18821.296875MB
INFO:root:[   50] Training loss: 0.66118602, Validation loss: 0.64640002, Gradient norm: 0.54805773
INFO:root:At the start of the epoch: mem (CPU python)=19135.18359375MB; mem (CPU total)=18897.11328125MB
INFO:root:[   51] Training loss: 0.66086409, Validation loss: 0.64565621, Gradient norm: 0.53827079
INFO:root:At the start of the epoch: mem (CPU python)=19165.984375MB; mem (CPU total)=18910.09765625MB
INFO:root:[   52] Training loss: 0.66049512, Validation loss: 0.64379816, Gradient norm: 0.56521331
INFO:root:At the start of the epoch: mem (CPU python)=19186.25390625MB; mem (CPU total)=18947.7578125MB
INFO:root:[   53] Training loss: 0.66057566, Validation loss: 0.64218373, Gradient norm: 0.65151879
INFO:root:At the start of the epoch: mem (CPU python)=19236.84765625MB; mem (CPU total)=18998.86328125MB
INFO:root:[   54] Training loss: 0.66005157, Validation loss: 0.64201959, Gradient norm: 0.61962474
INFO:root:At the start of the epoch: mem (CPU python)=19267.7890625MB; mem (CPU total)=19024.546875MB
INFO:root:[   55] Training loss: 0.65954346, Validation loss: 0.64104442, Gradient norm: 0.66632819
INFO:root:At the start of the epoch: mem (CPU python)=19313.0390625MB; mem (CPU total)=19074.875MB
INFO:root:[   56] Training loss: 0.65957274, Validation loss: 0.64164063, Gradient norm: 0.70187679
INFO:root:At the start of the epoch: mem (CPU python)=19363.75390625MB; mem (CPU total)=19125.48046875MB
INFO:root:[   57] Training loss: 0.65946115, Validation loss: 0.64105462, Gradient norm: 0.72148950
INFO:root:At the start of the epoch: mem (CPU python)=19401.85546875MB; mem (CPU total)=19164.00390625MB
INFO:root:[   58] Training loss: 0.65907124, Validation loss: 0.64075735, Gradient norm: 0.71535502
INFO:root:At the start of the epoch: mem (CPU python)=19432.87890625MB; mem (CPU total)=19176.83203125MB
INFO:root:[   59] Training loss: 0.65924068, Validation loss: 0.64037208, Gradient norm: 0.85843178
INFO:root:At the start of the epoch: mem (CPU python)=19432.87890625MB; mem (CPU total)=19189.67578125MB
INFO:root:[   60] Training loss: 0.65889043, Validation loss: 0.63994998, Gradient norm: 0.76193444
INFO:root:At the start of the epoch: mem (CPU python)=19478.51953125MB; mem (CPU total)=19239.8515625MB
INFO:root:[   61] Training loss: 0.65861741, Validation loss: 0.63891656, Gradient norm: 0.82196688
INFO:root:At the start of the epoch: mem (CPU python)=19516.61328125MB; mem (CPU total)=19280.1953125MB
INFO:root:[   62] Training loss: 0.65844430, Validation loss: 0.63950364, Gradient norm: 0.91280096
INFO:root:At the start of the epoch: mem (CPU python)=19567.2109375MB; mem (CPU total)=19331.02734375MB
INFO:root:[   63] Training loss: 0.65857810, Validation loss: 0.63849528, Gradient norm: 0.88382808
INFO:root:At the start of the epoch: mem (CPU python)=19592.8046875MB; mem (CPU total)=19356.9296875MB
INFO:root:[   64] Training loss: 0.65854697, Validation loss: 0.64070248, Gradient norm: 1.19691629
INFO:root:At the start of the epoch: mem (CPU python)=19643.3984375MB; mem (CPU total)=19407.5390625MB
INFO:root:[   65] Training loss: 0.65823427, Validation loss: 0.63850453, Gradient norm: 0.98703136
INFO:root:At the start of the epoch: mem (CPU python)=19681.4921875MB; mem (CPU total)=19445.69921875MB
INFO:root:[   66] Training loss: 0.65793461, Validation loss: 0.63852298, Gradient norm: 1.17668746
INFO:root:At the start of the epoch: mem (CPU python)=19732.09375MB; mem (CPU total)=19496.25MB
INFO:root:[   67] Training loss: 0.65772969, Validation loss: 0.63921236, Gradient norm: 1.10245185
INFO:root:At the start of the epoch: mem (CPU python)=19770.1875MB; mem (CPU total)=19534.6328125MB
INFO:root:[   68] Training loss: 0.65769881, Validation loss: 0.63844120, Gradient norm: 1.31148301
INFO:root:At the start of the epoch: mem (CPU python)=19795.78125MB; mem (CPU total)=19560.08203125MB
INFO:root:[   69] Training loss: 0.65760258, Validation loss: 0.63820642, Gradient norm: 1.17401060
INFO:root:At the start of the epoch: mem (CPU python)=19833.87890625MB; mem (CPU total)=19598.265625MB
INFO:root:[   70] Training loss: 0.65741335, Validation loss: 0.63767363, Gradient norm: 1.28926810
INFO:root:At the start of the epoch: mem (CPU python)=19871.97265625MB; mem (CPU total)=19636.890625MB
INFO:root:[   71] Training loss: 0.65733544, Validation loss: 0.63779278, Gradient norm: 1.42118838
INFO:root:At the start of the epoch: mem (CPU python)=19911.31640625MB; mem (CPU total)=19675.83984375MB
INFO:root:[   72] Training loss: 0.65719490, Validation loss: 0.63832622, Gradient norm: 1.34908036
INFO:root:At the start of the epoch: mem (CPU python)=19949.4140625MB; mem (CPU total)=19714.22265625MB
INFO:root:[   73] Training loss: 0.65700926, Validation loss: 0.63877193, Gradient norm: 1.41666678
INFO:root:At the start of the epoch: mem (CPU python)=19987.5078125MB; mem (CPU total)=19752.375MB
INFO:root:[   74] Training loss: 0.65715261, Validation loss: 0.63728805, Gradient norm: 1.45059676
INFO:root:At the start of the epoch: mem (CPU python)=20025.60546875MB; mem (CPU total)=19790.28125MB
INFO:root:[   75] Training loss: 0.65700361, Validation loss: 0.63802660, Gradient norm: 1.52694594
INFO:root:At the start of the epoch: mem (CPU python)=20063.69921875MB; mem (CPU total)=19828.90625MB
INFO:root:[   76] Training loss: 0.65661873, Validation loss: 0.63687193, Gradient norm: 1.31200772
INFO:root:At the start of the epoch: mem (CPU python)=20063.921875MB; mem (CPU total)=19827.8125MB
INFO:root:[   77] Training loss: 0.65662981, Validation loss: 0.63650264, Gradient norm: 1.62147117
INFO:root:At the start of the epoch: mem (CPU python)=20113.76171875MB; mem (CPU total)=19878.48828125MB
INFO:root:[   78] Training loss: 0.65651025, Validation loss: 0.63736457, Gradient norm: 1.60939531
INFO:root:At the start of the epoch: mem (CPU python)=20151.85546875MB; mem (CPU total)=19916.859375MB
INFO:root:[   79] Training loss: 0.65688461, Validation loss: 0.63597946, Gradient norm: 1.73378370
INFO:root:At the start of the epoch: mem (CPU python)=20202.33203125MB; mem (CPU total)=19965.3515625MB
INFO:root:[   80] Training loss: 0.65649653, Validation loss: 0.63719570, Gradient norm: 1.75244986
INFO:root:At the start of the epoch: mem (CPU python)=20240.42578125MB; mem (CPU total)=20005.48828125MB
INFO:root:[   81] Training loss: 0.65622654, Validation loss: 0.63708213, Gradient norm: 1.61324478
INFO:root:At the start of the epoch: mem (CPU python)=20314.203125MB; mem (CPU total)=20044.85546875MB
INFO:root:[   82] Training loss: 0.65612928, Validation loss: 0.63601346, Gradient norm: 1.76625186
INFO:root:At the start of the epoch: mem (CPU python)=20316.6171875MB; mem (CPU total)=20082.48828125MB
INFO:root:[   83] Training loss: 0.65636972, Validation loss: 0.63605496, Gradient norm: 1.93559497
INFO:root:At the start of the epoch: mem (CPU python)=20354.71484375MB; mem (CPU total)=20120.74609375MB
INFO:root:[   84] Training loss: 0.65629196, Validation loss: 0.63663958, Gradient norm: 1.81142505
INFO:root:At the start of the epoch: mem (CPU python)=20392.80859375MB; mem (CPU total)=20158.62890625MB
INFO:root:[   85] Training loss: 0.65602908, Validation loss: 0.63717791, Gradient norm: 1.83167254
INFO:root:At the start of the epoch: mem (CPU python)=20423.58984375MB; mem (CPU total)=20182.90234375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   86] Training loss: 0.65598198, Validation loss: 0.63679141, Gradient norm: 2.00425614
INFO:root:At the start of the epoch: mem (CPU python)=20444.0MB; mem (CPU total)=20207.65625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   87] Training loss: 0.65498324, Validation loss: 0.63555268, Gradient norm: 1.18603826
INFO:root:At the start of the epoch: mem (CPU python)=20532.09765625MB; mem (CPU total)=20295.40234375MB
INFO:root:[   88] Training loss: 0.65483149, Validation loss: 0.63479336, Gradient norm: 0.93143010
INFO:root:At the start of the epoch: mem (CPU python)=20570.19140625MB; mem (CPU total)=20333.51953125MB
INFO:root:[   89] Training loss: 0.65474436, Validation loss: 0.63519412, Gradient norm: 0.95262857
INFO:root:At the start of the epoch: mem (CPU python)=20583.2890625MB; mem (CPU total)=20346.73046875MB
INFO:root:[   90] Training loss: 0.65483348, Validation loss: 0.63536283, Gradient norm: 0.98964094
INFO:root:At the start of the epoch: mem (CPU python)=20637.6328125MB; mem (CPU total)=20401.06640625MB
INFO:root:[   91] Training loss: 0.65460284, Validation loss: 0.63490190, Gradient norm: 1.09065262
INFO:root:At the start of the epoch: mem (CPU python)=20675.73046875MB; mem (CPU total)=20439.4609375MB
INFO:root:[   92] Training loss: 0.65461026, Validation loss: 0.63554935, Gradient norm: 1.06283528
INFO:root:At the start of the epoch: mem (CPU python)=20724.42578125MB; mem (CPU total)=20488.00390625MB
INFO:root:[   93] Training loss: 0.65440686, Validation loss: 0.63516556, Gradient norm: 1.06008096
INFO:root:At the start of the epoch: mem (CPU python)=20762.5234375MB; mem (CPU total)=20526.36328125MB
INFO:root:[   94] Training loss: 0.65465856, Validation loss: 0.63506524, Gradient norm: 1.14829679
INFO:root:At the start of the epoch: mem (CPU python)=20800.6171875MB; mem (CPU total)=20564.64453125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   95] Training loss: 0.65450112, Validation loss: 0.63547011, Gradient norm: 1.18237918
INFO:root:At the start of the epoch: mem (CPU python)=20838.7109375MB; mem (CPU total)=20601.296875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   96] Training loss: 0.65434378, Validation loss: 0.63485855, Gradient norm: 0.92237500
INFO:root:At the start of the epoch: mem (CPU python)=20876.80859375MB; mem (CPU total)=20639.4140625MB
INFO:root:[   97] Training loss: 0.65440425, Validation loss: 0.63499666, Gradient norm: 0.81224118
INFO:root:At the start of the epoch: mem (CPU python)=20914.90625MB; mem (CPU total)=20677.9140625MB
INFO:root:[   98] Training loss: 0.65435049, Validation loss: 0.63470267, Gradient norm: 0.84799340
INFO:root:At the start of the epoch: mem (CPU python)=20953.0MB; mem (CPU total)=20716.109375MB
INFO:root:[   99] Training loss: 0.65420877, Validation loss: 0.63471248, Gradient norm: 0.82637312
INFO:root:At the start of the epoch: mem (CPU python)=20991.09765625MB; mem (CPU total)=20754.25390625MB
INFO:root:[  100] Training loss: 0.65429539, Validation loss: 0.63456422, Gradient norm: 0.88100846
INFO:root:At the start of the epoch: mem (CPU python)=21029.1953125MB; mem (CPU total)=20792.38671875MB
INFO:root:[  101] Training loss: 0.65423591, Validation loss: 0.63477790, Gradient norm: 0.83220663
INFO:root:At the start of the epoch: mem (CPU python)=21067.2890625MB; mem (CPU total)=20830.2734375MB
INFO:root:[  102] Training loss: 0.65422087, Validation loss: 0.63413139, Gradient norm: 0.84641351
INFO:root:At the start of the epoch: mem (CPU python)=21105.3828125MB; mem (CPU total)=20868.73046875MB
INFO:root:[  103] Training loss: 0.65436260, Validation loss: 0.63520067, Gradient norm: 0.88511015
INFO:root:At the start of the epoch: mem (CPU python)=21143.48046875MB; mem (CPU total)=20906.8359375MB
INFO:root:[  104] Training loss: 0.65429411, Validation loss: 0.63489315, Gradient norm: 0.90623410
INFO:root:At the start of the epoch: mem (CPU python)=21181.57421875MB; mem (CPU total)=20944.94921875MB
INFO:root:[  105] Training loss: 0.65433559, Validation loss: 0.63443043, Gradient norm: 0.89395689
INFO:root:At the start of the epoch: mem (CPU python)=21219.66796875MB; mem (CPU total)=20983.2890625MB
INFO:root:[  106] Training loss: 0.65430215, Validation loss: 0.63490311, Gradient norm: 0.97508299
INFO:root:At the start of the epoch: mem (CPU python)=21257.76953125MB; mem (CPU total)=21020.890625MB
INFO:root:[  107] Training loss: 0.65415694, Validation loss: 0.63476072, Gradient norm: 0.95233438
INFO:root:At the start of the epoch: mem (CPU python)=21295.86328125MB; mem (CPU total)=21058.96875MB
INFO:root:[  108] Training loss: 0.65416320, Validation loss: 0.63464623, Gradient norm: 0.96592956
INFO:root:At the start of the epoch: mem (CPU python)=21333.95703125MB; mem (CPU total)=21097.08984375MB
INFO:root:[  109] Training loss: 0.65421212, Validation loss: 0.63445715, Gradient norm: 0.94795148
INFO:root:At the start of the epoch: mem (CPU python)=21372.05078125MB; mem (CPU total)=21135.45703125MB
INFO:root:[  110] Training loss: 0.65423100, Validation loss: 0.63479483, Gradient norm: 0.99825295
INFO:root:At the start of the epoch: mem (CPU python)=21410.1484375MB; mem (CPU total)=21173.6015625MB
INFO:root:[  111] Training loss: 0.65414189, Validation loss: 0.63536743, Gradient norm: 0.96240631
INFO:root:At the start of the epoch: mem (CPU python)=21448.2421875MB; mem (CPU total)=21211.74609375MB
INFO:root:EP 111: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=21486.3359375MB; mem (CPU total)=21250.12890625MB
INFO:root:Training the model took 6063.408s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.89905
INFO:root:EnergyScoreTrain: 0.63274
INFO:root:CRPSTrain: 0.53113
INFO:root:Gaussian NLLTrain: 13217418249.10222
INFO:root:CoverageTrain: 0.73272
INFO:root:IntervalWidthTrain: 2.9096
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.90206
INFO:root:EnergyScoreValidation: 0.63488
INFO:root:CRPSValidation: 0.5335
INFO:root:Gaussian NLLValidation: 13503381139.91111
INFO:root:CoverageValidation: 0.73201
INFO:root:IntervalWidthValidation: 2.90967
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.90297
INFO:root:EnergyScoreTest: 0.63552
INFO:root:CRPSTest: 0.53411
INFO:root:Gaussian NLLTest: 13497724338.176
INFO:root:CoverageTest: 0.73236
INFO:root:IntervalWidthTest: 2.91092
INFO:root:After validation: mem (CPU python)=21529.390625MB; mem (CPU total)=21294.13671875MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=21529.390625MB; mem (CPU total)=21294.12890625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=21529.578125MB; mem (CPU total)=21294.375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=21529.7109375MB; mem (CPU total)=21294.609375MB
INFO:root:[    1] Training loss: 0.72566538, Validation loss: 0.72161740, Gradient norm: 0.01694154
INFO:root:At the start of the epoch: mem (CPU python)=21567.77734375MB; mem (CPU total)=21332.6015625MB
INFO:root:[    2] Training loss: 0.72024269, Validation loss: 0.71817090, Gradient norm: 0.00672361
INFO:root:At the start of the epoch: mem (CPU python)=21605.875MB; mem (CPU total)=21370.72265625MB
INFO:root:[    3] Training loss: 0.71646040, Validation loss: 0.70961436, Gradient norm: 0.01712823
INFO:root:At the start of the epoch: mem (CPU python)=21643.97265625MB; mem (CPU total)=21408.859375MB
INFO:root:[    4] Training loss: 0.71082193, Validation loss: 0.70387203, Gradient norm: 0.02810918
INFO:root:At the start of the epoch: mem (CPU python)=21682.06640625MB; mem (CPU total)=21447.00390625MB
INFO:root:[    5] Training loss: 0.70656203, Validation loss: 0.69843631, Gradient norm: 0.02968827
INFO:root:At the start of the epoch: mem (CPU python)=21757.66796875MB; mem (CPU total)=21522.8125MB
INFO:root:[    6] Training loss: 0.70285411, Validation loss: 0.69310427, Gradient norm: 0.03636102
INFO:root:At the start of the epoch: mem (CPU python)=21795.76171875MB; mem (CPU total)=21560.93359375MB
INFO:root:[    7] Training loss: 0.69912831, Validation loss: 0.68909971, Gradient norm: 0.04027068
INFO:root:At the start of the epoch: mem (CPU python)=21826.78125MB; mem (CPU total)=21538.2265625MB
INFO:root:[    8] Training loss: 0.69531535, Validation loss: 0.68393803, Gradient norm: 0.04171697
INFO:root:At the start of the epoch: mem (CPU python)=21826.78125MB; mem (CPU total)=21588.8125MB
INFO:root:[    9] Training loss: 0.69268889, Validation loss: 0.68086739, Gradient norm: 0.03826714
INFO:root:At the start of the epoch: mem (CPU python)=21860.04296875MB; mem (CPU total)=21626.796875MB
INFO:root:[   10] Training loss: 0.68985353, Validation loss: 0.67735831, Gradient norm: 0.04202649
INFO:root:At the start of the epoch: mem (CPU python)=21935.63671875MB; mem (CPU total)=21702.74609375MB
INFO:root:[   11] Training loss: 0.68742890, Validation loss: 0.67488712, Gradient norm: 0.04187952
INFO:root:At the start of the epoch: mem (CPU python)=21973.73046875MB; mem (CPU total)=21742.265625MB
INFO:root:[   12] Training loss: 0.68519367, Validation loss: 0.67147326, Gradient norm: 0.04274579
INFO:root:At the start of the epoch: mem (CPU python)=22012.59375MB; mem (CPU total)=21780.53125MB
INFO:root:[   13] Training loss: 0.68296100, Validation loss: 0.66889615, Gradient norm: 0.04626812
INFO:root:At the start of the epoch: mem (CPU python)=22049.92578125MB; mem (CPU total)=21817.3125MB
INFO:root:[   14] Training loss: 0.68143599, Validation loss: 0.66647870, Gradient norm: 0.05252304
INFO:root:At the start of the epoch: mem (CPU python)=22088.01953125MB; mem (CPU total)=21855.45703125MB
INFO:root:[   15] Training loss: 0.67967495, Validation loss: 0.66415473, Gradient norm: 0.05104119
INFO:root:At the start of the epoch: mem (CPU python)=22126.1171875MB; mem (CPU total)=21892.59375MB
INFO:root:[   16] Training loss: 0.67810005, Validation loss: 0.66347179, Gradient norm: 0.05294906
INFO:root:At the start of the epoch: mem (CPU python)=22164.2109375MB; mem (CPU total)=21931.0625MB
INFO:root:[   17] Training loss: 0.67695302, Validation loss: 0.66112344, Gradient norm: 0.05339849
INFO:root:At the start of the epoch: mem (CPU python)=22202.3046875MB; mem (CPU total)=21969.46875MB
INFO:root:[   18] Training loss: 0.67589040, Validation loss: 0.66030166, Gradient norm: 0.06174627
INFO:root:At the start of the epoch: mem (CPU python)=22240.3984375MB; mem (CPU total)=22007.16796875MB
INFO:root:[   19] Training loss: 0.67462761, Validation loss: 0.65788667, Gradient norm: 0.05993013
INFO:root:At the start of the epoch: mem (CPU python)=22278.5MB; mem (CPU total)=22045.5234375MB
INFO:root:[   20] Training loss: 0.67368671, Validation loss: 0.65737768, Gradient norm: 0.07145760
INFO:root:At the start of the epoch: mem (CPU python)=22316.59375MB; mem (CPU total)=22083.6484375MB
INFO:root:[   21] Training loss: 0.67278971, Validation loss: 0.65587229, Gradient norm: 0.06601774
INFO:root:At the start of the epoch: mem (CPU python)=22354.6875MB; mem (CPU total)=22121.53515625MB
INFO:root:[   22] Training loss: 0.67216554, Validation loss: 0.65628568, Gradient norm: 0.08590658
INFO:root:At the start of the epoch: mem (CPU python)=22392.78515625MB; mem (CPU total)=22159.9140625MB
INFO:root:[   23] Training loss: 0.67114792, Validation loss: 0.65452467, Gradient norm: 0.09042204
INFO:root:At the start of the epoch: mem (CPU python)=22430.87890625MB; mem (CPU total)=22197.78515625MB
INFO:root:[   24] Training loss: 0.67063772, Validation loss: 0.65414026, Gradient norm: 0.08566712
INFO:root:At the start of the epoch: mem (CPU python)=22468.97265625MB; mem (CPU total)=22236.19140625MB
INFO:root:[   25] Training loss: 0.67009381, Validation loss: 0.65345959, Gradient norm: 0.10438968
INFO:root:At the start of the epoch: mem (CPU python)=22507.06640625MB; mem (CPU total)=22274.55078125MB
INFO:root:[   26] Training loss: 0.66955241, Validation loss: 0.65300075, Gradient norm: 0.11325718
INFO:root:At the start of the epoch: mem (CPU python)=22545.16796875MB; mem (CPU total)=22312.9375MB
INFO:root:[   27] Training loss: 0.66901079, Validation loss: 0.65257025, Gradient norm: 0.12057865
INFO:root:At the start of the epoch: mem (CPU python)=22583.26171875MB; mem (CPU total)=22351.3125MB
INFO:root:[   28] Training loss: 0.66867747, Validation loss: 0.65168492, Gradient norm: 0.12730623
INFO:root:At the start of the epoch: mem (CPU python)=22621.35546875MB; mem (CPU total)=22389.24609375MB
INFO:root:[   29] Training loss: 0.66798089, Validation loss: 0.65114601, Gradient norm: 0.14685346
INFO:root:At the start of the epoch: mem (CPU python)=22659.453125MB; mem (CPU total)=22426.8984375MB
INFO:root:[   30] Training loss: 0.66763611, Validation loss: 0.65078500, Gradient norm: 0.16576027
INFO:root:At the start of the epoch: mem (CPU python)=22697.55078125MB; mem (CPU total)=22465.1484375MB
INFO:root:[   31] Training loss: 0.66697417, Validation loss: 0.65109759, Gradient norm: 0.17024393
INFO:root:At the start of the epoch: mem (CPU python)=22735.64453125MB; mem (CPU total)=22503.0234375MB
INFO:root:[   32] Training loss: 0.66669247, Validation loss: 0.64999275, Gradient norm: 0.17643905
INFO:root:At the start of the epoch: mem (CPU python)=22773.7421875MB; mem (CPU total)=22540.66015625MB
INFO:root:[   33] Training loss: 0.66602323, Validation loss: 0.65088184, Gradient norm: 0.18014277
INFO:root:At the start of the epoch: mem (CPU python)=22811.83984375MB; mem (CPU total)=22578.7734375MB
INFO:root:[   34] Training loss: 0.66574751, Validation loss: 0.64988461, Gradient norm: 0.20636984
INFO:root:At the start of the epoch: mem (CPU python)=22849.93359375MB; mem (CPU total)=22616.671875MB
INFO:root:[   35] Training loss: 0.66556208, Validation loss: 0.64871902, Gradient norm: 0.22448027
INFO:root:At the start of the epoch: mem (CPU python)=22888.03125MB; mem (CPU total)=22655.2421875MB
INFO:root:[   36] Training loss: 0.66494938, Validation loss: 0.64717805, Gradient norm: 0.22524187
INFO:root:At the start of the epoch: mem (CPU python)=22926.12890625MB; mem (CPU total)=22693.1328125MB
INFO:root:[   37] Training loss: 0.66448470, Validation loss: 0.64834998, Gradient norm: 0.22084407
INFO:root:At the start of the epoch: mem (CPU python)=22964.22265625MB; mem (CPU total)=22731.2421875MB
INFO:root:[   38] Training loss: 0.66440008, Validation loss: 0.64687638, Gradient norm: 0.26049716
INFO:root:At the start of the epoch: mem (CPU python)=23002.31640625MB; mem (CPU total)=22769.64453125MB
INFO:root:[   39] Training loss: 0.66397171, Validation loss: 0.64733841, Gradient norm: 0.28050162
INFO:root:At the start of the epoch: mem (CPU python)=23040.4140625MB; mem (CPU total)=22807.76171875MB
INFO:root:[   40] Training loss: 0.66367823, Validation loss: 0.64564212, Gradient norm: 0.28037715
INFO:root:At the start of the epoch: mem (CPU python)=23078.5078125MB; mem (CPU total)=22846.38671875MB
INFO:root:[   41] Training loss: 0.66343189, Validation loss: 0.64531943, Gradient norm: 0.31133636
INFO:root:At the start of the epoch: mem (CPU python)=23116.60546875MB; mem (CPU total)=22884.453125MB
INFO:root:[   42] Training loss: 0.66293209, Validation loss: 0.64524448, Gradient norm: 0.32880913
INFO:root:At the start of the epoch: mem (CPU python)=23154.6953125MB; mem (CPU total)=22922.625MB
INFO:root:[   43] Training loss: 0.66280814, Validation loss: 0.64459378, Gradient norm: 0.35331871
INFO:root:At the start of the epoch: mem (CPU python)=23192.796875MB; mem (CPU total)=22960.75MB
INFO:root:[   44] Training loss: 0.66272354, Validation loss: 0.64357575, Gradient norm: 0.39186082
INFO:root:At the start of the epoch: mem (CPU python)=23230.890625MB; mem (CPU total)=22998.86328125MB
INFO:root:[   45] Training loss: 0.66248091, Validation loss: 0.64486115, Gradient norm: 0.37965048
INFO:root:At the start of the epoch: mem (CPU python)=23268.984375MB; mem (CPU total)=23037.234375MB
INFO:root:[   46] Training loss: 0.66210245, Validation loss: 0.64365496, Gradient norm: 0.41212541
INFO:root:At the start of the epoch: mem (CPU python)=23307.08203125MB; mem (CPU total)=23075.11328125MB
INFO:root:[   47] Training loss: 0.66180822, Validation loss: 0.64260663, Gradient norm: 0.42046076
INFO:root:At the start of the epoch: mem (CPU python)=23345.17578125MB; mem (CPU total)=23113.16796875MB
INFO:root:[   48] Training loss: 0.66190397, Validation loss: 0.64268380, Gradient norm: 0.47543836
INFO:root:At the start of the epoch: mem (CPU python)=23383.26953125MB; mem (CPU total)=23151.078125MB
INFO:root:[   49] Training loss: 0.66148086, Validation loss: 0.64230671, Gradient norm: 0.51512483
INFO:root:At the start of the epoch: mem (CPU python)=23421.37109375MB; mem (CPU total)=23189.73828125MB
INFO:root:[   50] Training loss: 0.66135592, Validation loss: 0.64222715, Gradient norm: 0.50387750
INFO:root:At the start of the epoch: mem (CPU python)=23459.46484375MB; mem (CPU total)=23227.19140625MB
INFO:root:[   51] Training loss: 0.66127174, Validation loss: 0.64175366, Gradient norm: 0.53492385
INFO:root:At the start of the epoch: mem (CPU python)=23497.55859375MB; mem (CPU total)=23265.2890625MB
INFO:root:[   52] Training loss: 0.66105153, Validation loss: 0.64156479, Gradient norm: 0.55640215
INFO:root:At the start of the epoch: mem (CPU python)=23535.65234375MB; mem (CPU total)=23303.4140625MB
INFO:root:[   53] Training loss: 0.66084184, Validation loss: 0.64088378, Gradient norm: 0.57347346
INFO:root:At the start of the epoch: mem (CPU python)=23573.75MB; mem (CPU total)=23341.41796875MB
INFO:root:[   54] Training loss: 0.66073449, Validation loss: 0.64196132, Gradient norm: 0.68712523
INFO:root:At the start of the epoch: mem (CPU python)=23611.84375MB; mem (CPU total)=23379.76953125MB
INFO:root:[   55] Training loss: 0.66059591, Validation loss: 0.64071727, Gradient norm: 0.61874007
INFO:root:At the start of the epoch: mem (CPU python)=23649.9375MB; mem (CPU total)=23417.87890625MB
INFO:root:[   56] Training loss: 0.66064370, Validation loss: 0.64076027, Gradient norm: 0.70370727
INFO:root:At the start of the epoch: mem (CPU python)=23688.03515625MB; mem (CPU total)=23456.43359375MB
INFO:root:[   57] Training loss: 0.66034171, Validation loss: 0.64003493, Gradient norm: 0.72168139
INFO:root:At the start of the epoch: mem (CPU python)=23726.12890625MB; mem (CPU total)=23494.546875MB
INFO:root:[   58] Training loss: 0.66028116, Validation loss: 0.64049605, Gradient norm: 0.69384511
INFO:root:At the start of the epoch: mem (CPU python)=23764.22265625MB; mem (CPU total)=23532.66796875MB
INFO:root:[   59] Training loss: 0.66018788, Validation loss: 0.64014481, Gradient norm: 0.83358504
INFO:root:At the start of the epoch: mem (CPU python)=23802.3203125MB; mem (CPU total)=23570.8046875MB
INFO:root:[   60] Training loss: 0.66002426, Validation loss: 0.63972731, Gradient norm: 0.82964167
INFO:root:At the start of the epoch: mem (CPU python)=23840.41796875MB; mem (CPU total)=23609.45703125MB
INFO:root:[   61] Training loss: 0.65966668, Validation loss: 0.64111738, Gradient norm: 0.85443721
INFO:root:At the start of the epoch: mem (CPU python)=23878.51171875MB; mem (CPU total)=23647.5859375MB
INFO:root:[   62] Training loss: 0.65979358, Validation loss: 0.64064948, Gradient norm: 1.00838609
INFO:root:At the start of the epoch: mem (CPU python)=23916.60546875MB; mem (CPU total)=23685.6796875MB
INFO:root:[   63] Training loss: 0.65949297, Validation loss: 0.64007796, Gradient norm: 0.88388991
INFO:root:At the start of the epoch: mem (CPU python)=23954.703125MB; mem (CPU total)=23723.80859375MB
INFO:root:[   64] Training loss: 0.65953178, Validation loss: 0.63991073, Gradient norm: 0.90891588
INFO:root:At the start of the epoch: mem (CPU python)=23992.796875MB; mem (CPU total)=23761.9140625MB
INFO:root:[   65] Training loss: 0.65941204, Validation loss: 0.63857018, Gradient norm: 0.92597047
INFO:root:At the start of the epoch: mem (CPU python)=24030.890625MB; mem (CPU total)=23800.04296875MB
INFO:root:[   66] Training loss: 0.65937008, Validation loss: 0.63879286, Gradient norm: 1.06840907
INFO:root:At the start of the epoch: mem (CPU python)=24068.9921875MB; mem (CPU total)=23838.44921875MB
INFO:root:[   67] Training loss: 0.65934254, Validation loss: 0.63839007, Gradient norm: 0.93647343
INFO:root:At the start of the epoch: mem (CPU python)=24107.0859375MB; mem (CPU total)=23877.09765625MB
INFO:root:[   68] Training loss: 0.65942160, Validation loss: 0.63835226, Gradient norm: 1.05776405
INFO:root:At the start of the epoch: mem (CPU python)=24145.1796875MB; mem (CPU total)=23915.25390625MB
INFO:root:[   69] Training loss: 0.65913294, Validation loss: 0.63869025, Gradient norm: 1.10046494
INFO:root:At the start of the epoch: mem (CPU python)=24183.2734375MB; mem (CPU total)=23953.1328125MB
INFO:root:[   70] Training loss: 0.65923035, Validation loss: 0.63857560, Gradient norm: 1.04376472
INFO:root:At the start of the epoch: mem (CPU python)=24221.37109375MB; mem (CPU total)=23991.48828125MB
INFO:root:[   71] Training loss: 0.65905796, Validation loss: 0.63805846, Gradient norm: 1.29025749
INFO:root:At the start of the epoch: mem (CPU python)=24259.46484375MB; mem (CPU total)=24029.9140625MB
INFO:root:[   72] Training loss: 0.65888650, Validation loss: 0.63853465, Gradient norm: 1.20338198
INFO:root:At the start of the epoch: mem (CPU python)=24297.55859375MB; mem (CPU total)=24068.06640625MB
INFO:root:[   73] Training loss: 0.65889330, Validation loss: 0.63810564, Gradient norm: 1.23254219
INFO:root:At the start of the epoch: mem (CPU python)=24335.66015625MB; mem (CPU total)=24106.15234375MB
INFO:root:[   74] Training loss: 0.65863291, Validation loss: 0.63881744, Gradient norm: 1.30314706
INFO:root:At the start of the epoch: mem (CPU python)=24373.75390625MB; mem (CPU total)=24144.06640625MB
INFO:root:[   75] Training loss: 0.65864344, Validation loss: 0.63859954, Gradient norm: 1.27469417
INFO:root:At the start of the epoch: mem (CPU python)=24411.84765625MB; mem (CPU total)=24182.46484375MB
INFO:root:[   76] Training loss: 0.65841163, Validation loss: 0.63941830, Gradient norm: 1.27218168
INFO:root:At the start of the epoch: mem (CPU python)=24449.9453125MB; mem (CPU total)=24220.02734375MB
INFO:root:[   77] Training loss: 0.65843393, Validation loss: 0.63908207, Gradient norm: 1.53301226
INFO:root:At the start of the epoch: mem (CPU python)=24488.04296875MB; mem (CPU total)=24258.390625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   78] Training loss: 0.65829903, Validation loss: 0.63745332, Gradient norm: 1.22009910
INFO:root:At the start of the epoch: mem (CPU python)=24526.13671875MB; mem (CPU total)=24296.80859375MB
INFO:root:[   79] Training loss: 0.65763970, Validation loss: 0.63683717, Gradient norm: 0.95043268
INFO:root:At the start of the epoch: mem (CPU python)=24564.23046875MB; mem (CPU total)=24334.73828125MB
INFO:root:[   80] Training loss: 0.65735631, Validation loss: 0.63682196, Gradient norm: 1.04049967
INFO:root:At the start of the epoch: mem (CPU python)=24602.328125MB; mem (CPU total)=24373.26953125MB
INFO:root:[   81] Training loss: 0.65729171, Validation loss: 0.63620749, Gradient norm: 1.15000824
INFO:root:At the start of the epoch: mem (CPU python)=24640.421875MB; mem (CPU total)=24411.3984375MB
INFO:root:[   82] Training loss: 0.65718995, Validation loss: 0.63648169, Gradient norm: 1.18835701
INFO:root:At the start of the epoch: mem (CPU python)=24678.515625MB; mem (CPU total)=24449.7890625MB
INFO:root:[   83] Training loss: 0.65720461, Validation loss: 0.63716547, Gradient norm: 1.13776442
INFO:root:At the start of the epoch: mem (CPU python)=24716.61328125MB; mem (CPU total)=24487.92578125MB
INFO:root:[   84] Training loss: 0.65704181, Validation loss: 0.63623848, Gradient norm: 1.24068276
INFO:root:At the start of the epoch: mem (CPU python)=24754.7109375MB; mem (CPU total)=24525.84765625MB
INFO:root:[   85] Training loss: 0.65705263, Validation loss: 0.63661261, Gradient norm: 1.27981641
INFO:root:At the start of the epoch: mem (CPU python)=24792.8046875MB; mem (CPU total)=24564.2265625MB
INFO:root:[   86] Training loss: 0.65720773, Validation loss: 0.63629715, Gradient norm: 1.42089520
INFO:root:At the start of the epoch: mem (CPU python)=24830.8984375MB; mem (CPU total)=24602.5859375MB
INFO:root:[   87] Training loss: 0.65710338, Validation loss: 0.63601706, Gradient norm: 1.37497087
INFO:root:At the start of the epoch: mem (CPU python)=24868.99609375MB; mem (CPU total)=24640.41015625MB
INFO:root:[   88] Training loss: 0.65717408, Validation loss: 0.63761445, Gradient norm: 1.34162470
INFO:root:At the start of the epoch: mem (CPU python)=24907.08984375MB; mem (CPU total)=24678.75MB
INFO:root:[   89] Training loss: 0.65729795, Validation loss: 0.63690918, Gradient norm: 1.40954654
INFO:root:At the start of the epoch: mem (CPU python)=24945.18359375MB; mem (CPU total)=24716.625MB
INFO:root:[   90] Training loss: 0.65688574, Validation loss: 0.63759355, Gradient norm: 1.50872152
INFO:root:At the start of the epoch: mem (CPU python)=24983.28125MB; mem (CPU total)=24754.98828125MB
INFO:root:[   91] Training loss: 0.65677689, Validation loss: 0.63674643, Gradient norm: 1.29718058
INFO:root:At the start of the epoch: mem (CPU python)=25021.37890625MB; mem (CPU total)=24793.08984375MB
INFO:root:[   92] Training loss: 0.65696166, Validation loss: 0.63570884, Gradient norm: 1.45832638
INFO:root:At the start of the epoch: mem (CPU python)=25059.47265625MB; mem (CPU total)=24831.64453125MB
INFO:root:[   93] Training loss: 0.65677714, Validation loss: 0.63587399, Gradient norm: 1.44204765
INFO:root:At the start of the epoch: mem (CPU python)=25097.56640625MB; mem (CPU total)=24870.00390625MB
INFO:root:[   94] Training loss: 0.65683233, Validation loss: 0.63575137, Gradient norm: 1.46348082
INFO:root:At the start of the epoch: mem (CPU python)=25135.6640625MB; mem (CPU total)=24907.86328125MB
INFO:root:[   95] Training loss: 0.65681410, Validation loss: 0.63621014, Gradient norm: 1.47659920
INFO:root:At the start of the epoch: mem (CPU python)=25173.7578125MB; mem (CPU total)=24946.01171875MB
INFO:root:[   96] Training loss: 0.65695014, Validation loss: 0.63657898, Gradient norm: 1.71469566
INFO:root:At the start of the epoch: mem (CPU python)=25211.8515625MB; mem (CPU total)=24984.390625MB
INFO:root:[   97] Training loss: 0.65680974, Validation loss: 0.63622210, Gradient norm: 1.67683276
INFO:root:At the start of the epoch: mem (CPU python)=25249.94921875MB; mem (CPU total)=25022.47265625MB
INFO:root:[   98] Training loss: 0.65666726, Validation loss: 0.63536519, Gradient norm: 1.70345771
INFO:root:At the start of the epoch: mem (CPU python)=25288.04296875MB; mem (CPU total)=25060.86328125MB
INFO:root:[   99] Training loss: 0.65674933, Validation loss: 0.63611293, Gradient norm: 1.55142878
INFO:root:At the start of the epoch: mem (CPU python)=25326.13671875MB; mem (CPU total)=25099.03515625MB
INFO:root:[  100] Training loss: 0.65671984, Validation loss: 0.63616080, Gradient norm: 1.77948416
INFO:root:At the start of the epoch: mem (CPU python)=25364.23828125MB; mem (CPU total)=25138.03125MB
INFO:root:[  101] Training loss: 0.65667123, Validation loss: 0.63673411, Gradient norm: 1.69104853
INFO:root:At the start of the epoch: mem (CPU python)=25402.33203125MB; mem (CPU total)=25176.15625MB
INFO:root:[  102] Training loss: 0.65645961, Validation loss: 0.63528040, Gradient norm: 1.67847786
INFO:root:At the start of the epoch: mem (CPU python)=25440.42578125MB; mem (CPU total)=25214.33984375MB
INFO:root:[  103] Training loss: 0.65664122, Validation loss: 0.63607441, Gradient norm: 1.72914708
INFO:root:At the start of the epoch: mem (CPU python)=25478.51953125MB; mem (CPU total)=25252.546875MB
INFO:root:[  104] Training loss: 0.65638275, Validation loss: 0.63588423, Gradient norm: 1.73575444
INFO:root:At the start of the epoch: mem (CPU python)=25516.6171875MB; mem (CPU total)=25290.6640625MB
INFO:root:[  105] Training loss: 0.65648495, Validation loss: 0.63581018, Gradient norm: 1.76090993
INFO:root:At the start of the epoch: mem (CPU python)=25554.7109375MB; mem (CPU total)=25329.0703125MB
INFO:root:[  106] Training loss: 0.65639745, Validation loss: 0.63672998, Gradient norm: 1.83466468
INFO:root:At the start of the epoch: mem (CPU python)=25592.8046875MB; mem (CPU total)=25367.59765625MB
INFO:root:[  107] Training loss: 0.65636617, Validation loss: 0.63626081, Gradient norm: 1.67579312
INFO:root:At the start of the epoch: mem (CPU python)=25630.90234375MB; mem (CPU total)=25405.51953125MB
INFO:root:[  108] Training loss: 0.65643626, Validation loss: 0.63610103, Gradient norm: 2.00806699
INFO:root:At the start of the epoch: mem (CPU python)=25669.0MB; mem (CPU total)=25443.88671875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  109] Training loss: 0.65638850, Validation loss: 0.63571782, Gradient norm: 1.79793038
INFO:root:At the start of the epoch: mem (CPU python)=25707.09375MB; mem (CPU total)=25482.28515625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  110] Training loss: 0.65599306, Validation loss: 0.63501483, Gradient norm: 1.40350602
INFO:root:At the start of the epoch: mem (CPU python)=25745.1875MB; mem (CPU total)=25520.46484375MB
INFO:root:[  111] Training loss: 0.65571365, Validation loss: 0.63513258, Gradient norm: 1.25994920
INFO:root:At the start of the epoch: mem (CPU python)=25783.28515625MB; mem (CPU total)=25558.3515625MB
INFO:root:[  112] Training loss: 0.65540868, Validation loss: 0.63460945, Gradient norm: 1.21156543
INFO:root:At the start of the epoch: mem (CPU python)=25821.37890625MB; mem (CPU total)=25596.55859375MB
INFO:root:[  113] Training loss: 0.65569745, Validation loss: 0.63434408, Gradient norm: 1.22180335
INFO:root:At the start of the epoch: mem (CPU python)=25859.47265625MB; mem (CPU total)=25634.73046875MB
INFO:root:[  114] Training loss: 0.65570652, Validation loss: 0.63551790, Gradient norm: 1.33631428
INFO:root:At the start of the epoch: mem (CPU python)=25897.5703125MB; mem (CPU total)=25673.3515625MB
INFO:root:[  115] Training loss: 0.65565533, Validation loss: 0.63560680, Gradient norm: 1.37928701
INFO:root:At the start of the epoch: mem (CPU python)=25935.66796875MB; mem (CPU total)=25711.5078125MB
INFO:root:[  116] Training loss: 0.65589430, Validation loss: 0.63564845, Gradient norm: 1.37256070
INFO:root:At the start of the epoch: mem (CPU python)=25973.76171875MB; mem (CPU total)=25749.6640625MB
INFO:root:[  117] Training loss: 0.65549522, Validation loss: 0.63482997, Gradient norm: 1.41364907
INFO:root:At the start of the epoch: mem (CPU python)=26011.86328125MB; mem (CPU total)=25787.484375MB
INFO:root:[  118] Training loss: 0.65538715, Validation loss: 0.63492274, Gradient norm: 1.28300843
INFO:root:At the start of the epoch: mem (CPU python)=26049.95703125MB; mem (CPU total)=25825.8515625MB
INFO:root:[  119] Training loss: 0.65549384, Validation loss: 0.63450982, Gradient norm: 1.30846326
INFO:root:At the start of the epoch: mem (CPU python)=26088.05078125MB; mem (CPU total)=25864.02734375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  120] Training loss: 0.65531091, Validation loss: 0.63476988, Gradient norm: 1.47402124
INFO:root:At the start of the epoch: mem (CPU python)=26126.14453125MB; mem (CPU total)=25902.16796875MB
INFO:root:[  121] Training loss: 0.65533655, Validation loss: 0.63442536, Gradient norm: 1.10492479
INFO:root:At the start of the epoch: mem (CPU python)=26164.2421875MB; mem (CPU total)=25939.74609375MB
INFO:root:[  122] Training loss: 0.65524866, Validation loss: 0.63479471, Gradient norm: 1.16197325
INFO:root:At the start of the epoch: mem (CPU python)=26202.3359375MB; mem (CPU total)=25976.58203125MB
INFO:root:EP 122: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=26240.4296875MB; mem (CPU total)=26014.47265625MB
INFO:root:Training the model took 7377.4s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.89865
INFO:root:EnergyScoreTrain: 0.63244
INFO:root:CRPSTrain: 0.52102
INFO:root:Gaussian NLLTrain: 3536589926.96889
INFO:root:CoverageTrain: 0.80793
INFO:root:IntervalWidthTrain: 3.13421
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9019
INFO:root:EnergyScoreValidation: 0.63473
INFO:root:CRPSValidation: 0.52328
INFO:root:Gaussian NLLValidation: 3536911571.62667
INFO:root:CoverageValidation: 0.80799
INFO:root:IntervalWidthValidation: 3.13666
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.90395
INFO:root:EnergyScoreTest: 0.63617
INFO:root:CRPSTest: 0.52459
INFO:root:Gaussian NLLTest: 3579990458.368
INFO:root:CoverageTest: 0.80799
INFO:root:IntervalWidthTest: 3.13797
INFO:root:After validation: mem (CPU python)=26318.3046875MB; mem (CPU total)=26065.44140625MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=26318.3046875MB; mem (CPU total)=26065.41796875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=26318.3046875MB; mem (CPU total)=26065.40625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=26318.3046875MB; mem (CPU total)=26065.63671875MB
INFO:root:[    1] Training loss: 0.72619900, Validation loss: 0.72165888, Gradient norm: 0.02237046
INFO:root:At the start of the epoch: mem (CPU python)=26328.14453125MB; mem (CPU total)=26103.86328125MB
INFO:root:[    2] Training loss: 0.72071943, Validation loss: 0.71942137, Gradient norm: 0.00611221
INFO:root:At the start of the epoch: mem (CPU python)=26366.2421875MB; mem (CPU total)=26141.76171875MB
INFO:root:[    3] Training loss: 0.71912581, Validation loss: 0.71765080, Gradient norm: 0.00876194
INFO:root:At the start of the epoch: mem (CPU python)=26404.3359375MB; mem (CPU total)=26180.12890625MB
INFO:root:[    4] Training loss: 0.71649475, Validation loss: 0.71141481, Gradient norm: 0.01605691
INFO:root:At the start of the epoch: mem (CPU python)=26442.4296875MB; mem (CPU total)=26218.265625MB
INFO:root:[    5] Training loss: 0.71192129, Validation loss: 0.70653078, Gradient norm: 0.03011289
INFO:root:At the start of the epoch: mem (CPU python)=26480.52734375MB; mem (CPU total)=26257.91796875MB
INFO:root:[    6] Training loss: 0.70816195, Validation loss: 0.70162598, Gradient norm: 0.03087829
INFO:root:At the start of the epoch: mem (CPU python)=26518.62109375MB; mem (CPU total)=26296.30859375MB
INFO:root:[    7] Training loss: 0.70473990, Validation loss: 0.69753775, Gradient norm: 0.03342676
INFO:root:At the start of the epoch: mem (CPU python)=26556.71875MB; mem (CPU total)=26333.390625MB
INFO:root:[    8] Training loss: 0.70167322, Validation loss: 0.69325848, Gradient norm: 0.03565949
INFO:root:At the start of the epoch: mem (CPU python)=26594.8125MB; mem (CPU total)=26371.2578125MB
INFO:root:[    9] Training loss: 0.69889622, Validation loss: 0.69017094, Gradient norm: 0.03654149
INFO:root:At the start of the epoch: mem (CPU python)=26632.91015625MB; mem (CPU total)=26409.86328125MB
INFO:root:[   10] Training loss: 0.69636269, Validation loss: 0.68706179, Gradient norm: 0.03506380
INFO:root:At the start of the epoch: mem (CPU python)=26671.00390625MB; mem (CPU total)=26447.7734375MB
INFO:root:[   11] Training loss: 0.69428362, Validation loss: 0.68456878, Gradient norm: 0.04169434
INFO:root:At the start of the epoch: mem (CPU python)=26709.09765625MB; mem (CPU total)=26485.87109375MB
INFO:root:[   12] Training loss: 0.69225472, Validation loss: 0.68109809, Gradient norm: 0.03856756
INFO:root:At the start of the epoch: mem (CPU python)=26747.1953125MB; mem (CPU total)=26523.9609375MB
INFO:root:[   13] Training loss: 0.69034925, Validation loss: 0.67935220, Gradient norm: 0.04165137
INFO:root:At the start of the epoch: mem (CPU python)=26785.29296875MB; mem (CPU total)=26562.31640625MB
INFO:root:[   14] Training loss: 0.68856739, Validation loss: 0.67701374, Gradient norm: 0.04093593
INFO:root:At the start of the epoch: mem (CPU python)=26823.38671875MB; mem (CPU total)=26600.63671875MB
INFO:root:[   15] Training loss: 0.68701984, Validation loss: 0.67632673, Gradient norm: 0.04667030
INFO:root:At the start of the epoch: mem (CPU python)=26861.48046875MB; mem (CPU total)=26638.6875MB
INFO:root:[   16] Training loss: 0.68556589, Validation loss: 0.67296331, Gradient norm: 0.04572564
INFO:root:At the start of the epoch: mem (CPU python)=26899.578125MB; mem (CPU total)=26676.31640625MB
INFO:root:[   17] Training loss: 0.68425846, Validation loss: 0.67196035, Gradient norm: 0.04940341
INFO:root:At the start of the epoch: mem (CPU python)=26937.671875MB; mem (CPU total)=26714.42578125MB
INFO:root:[   18] Training loss: 0.68283870, Validation loss: 0.67033936, Gradient norm: 0.04779205
INFO:root:At the start of the epoch: mem (CPU python)=26975.765625MB; mem (CPU total)=26752.765625MB
INFO:root:[   19] Training loss: 0.68180426, Validation loss: 0.66914212, Gradient norm: 0.04924436
INFO:root:At the start of the epoch: mem (CPU python)=27013.8671875MB; mem (CPU total)=26790.89453125MB
INFO:root:[   20] Training loss: 0.68077650, Validation loss: 0.66759732, Gradient norm: 0.05669701
INFO:root:At the start of the epoch: mem (CPU python)=27051.96484375MB; mem (CPU total)=26829.01953125MB
INFO:root:[   21] Training loss: 0.67969630, Validation loss: 0.66638570, Gradient norm: 0.05865223
INFO:root:At the start of the epoch: mem (CPU python)=27090.05859375MB; mem (CPU total)=26867.37109375MB
INFO:root:[   22] Training loss: 0.67874384, Validation loss: 0.66551536, Gradient norm: 0.04951174
INFO:root:At the start of the epoch: mem (CPU python)=27128.15625MB; mem (CPU total)=26905.46875MB
INFO:root:[   23] Training loss: 0.67794993, Validation loss: 0.66442590, Gradient norm: 0.05131854
INFO:root:At the start of the epoch: mem (CPU python)=27166.25MB; mem (CPU total)=26943.84375MB
INFO:root:[   24] Training loss: 0.67707317, Validation loss: 0.66325580, Gradient norm: 0.06030908
INFO:root:At the start of the epoch: mem (CPU python)=27204.34375MB; mem (CPU total)=26981.66796875MB
INFO:root:[   25] Training loss: 0.67643222, Validation loss: 0.66164141, Gradient norm: 0.05616581
INFO:root:At the start of the epoch: mem (CPU python)=27242.4375MB; mem (CPU total)=27019.78125MB
INFO:root:[   26] Training loss: 0.67564104, Validation loss: 0.66115598, Gradient norm: 0.06563160
INFO:root:At the start of the epoch: mem (CPU python)=27280.53515625MB; mem (CPU total)=27058.1171875MB
INFO:root:[   27] Training loss: 0.67511481, Validation loss: 0.66014854, Gradient norm: 0.07597721
INFO:root:At the start of the epoch: mem (CPU python)=27318.62890625MB; mem (CPU total)=27096.23828125MB
INFO:root:[   28] Training loss: 0.67445572, Validation loss: 0.65984216, Gradient norm: 0.07119720
INFO:root:At the start of the epoch: mem (CPU python)=27356.72265625MB; mem (CPU total)=27134.61328125MB
INFO:root:[   29] Training loss: 0.67392703, Validation loss: 0.66075954, Gradient norm: 0.08644445
INFO:root:At the start of the epoch: mem (CPU python)=27394.82421875MB; mem (CPU total)=27172.50390625MB
INFO:root:[   30] Training loss: 0.67306196, Validation loss: 0.65956841, Gradient norm: 0.07274203
INFO:root:At the start of the epoch: mem (CPU python)=27432.91796875MB; mem (CPU total)=27210.59375MB
INFO:root:[   31] Training loss: 0.67262326, Validation loss: 0.65856266, Gradient norm: 0.07714212
INFO:root:At the start of the epoch: mem (CPU python)=27471.01171875MB; mem (CPU total)=27248.96875MB
INFO:root:[   32] Training loss: 0.67243814, Validation loss: 0.65890922, Gradient norm: 0.08580297
INFO:root:At the start of the epoch: mem (CPU python)=27509.10546875MB; mem (CPU total)=27287.55078125MB
INFO:root:[   33] Training loss: 0.67191085, Validation loss: 0.65699879, Gradient norm: 0.09333946
INFO:root:At the start of the epoch: mem (CPU python)=27547.203125MB; mem (CPU total)=27325.66015625MB
INFO:root:[   34] Training loss: 0.67130030, Validation loss: 0.65752101, Gradient norm: 0.11301606
INFO:root:At the start of the epoch: mem (CPU python)=27585.296875MB; mem (CPU total)=27363.79296875MB
INFO:root:[   35] Training loss: 0.67097642, Validation loss: 0.65658793, Gradient norm: 0.09529049
INFO:root:At the start of the epoch: mem (CPU python)=27623.390625MB; mem (CPU total)=27401.9453125MB
INFO:root:[   36] Training loss: 0.67039131, Validation loss: 0.65720302, Gradient norm: 0.10763519
INFO:root:At the start of the epoch: mem (CPU python)=27661.48828125MB; mem (CPU total)=27440.2890625MB
INFO:root:[   37] Training loss: 0.67001080, Validation loss: 0.65536468, Gradient norm: 0.11017273
INFO:root:At the start of the epoch: mem (CPU python)=27699.5859375MB; mem (CPU total)=27478.41796875MB
INFO:root:[   38] Training loss: 0.66955180, Validation loss: 0.65578461, Gradient norm: 0.11272681
INFO:root:At the start of the epoch: mem (CPU python)=27737.67578125MB; mem (CPU total)=27516.5078125MB
INFO:root:[   39] Training loss: 0.66931147, Validation loss: 0.65643732, Gradient norm: 0.15570945
INFO:root:At the start of the epoch: mem (CPU python)=27775.77734375MB; mem (CPU total)=27554.34765625MB
INFO:root:[   40] Training loss: 0.66892156, Validation loss: 0.65699905, Gradient norm: 0.13486934
INFO:root:At the start of the epoch: mem (CPU python)=27813.87109375MB; mem (CPU total)=27592.53125MB
INFO:root:[   41] Training loss: 0.66842887, Validation loss: 0.65817738, Gradient norm: 0.15598181
INFO:root:At the start of the epoch: mem (CPU python)=27851.96484375MB; mem (CPU total)=27630.69921875MB
INFO:root:[   42] Training loss: 0.66811105, Validation loss: 0.65439718, Gradient norm: 0.15109583
INFO:root:At the start of the epoch: mem (CPU python)=27890.05859375MB; mem (CPU total)=27669.00390625MB
INFO:root:[   43] Training loss: 0.66759160, Validation loss: 0.65481483, Gradient norm: 0.12538389
INFO:root:At the start of the epoch: mem (CPU python)=27928.15625MB; mem (CPU total)=27707.08984375MB
INFO:root:[   44] Training loss: 0.66754586, Validation loss: 0.65463751, Gradient norm: 0.14699123
INFO:root:At the start of the epoch: mem (CPU python)=27966.25MB; mem (CPU total)=27745.4296875MB
INFO:root:[   45] Training loss: 0.66700767, Validation loss: 0.65407197, Gradient norm: 0.15826449
INFO:root:At the start of the epoch: mem (CPU python)=28004.34375MB; mem (CPU total)=27783.609375MB
INFO:root:[   46] Training loss: 0.66695233, Validation loss: 0.65739724, Gradient norm: 0.16776374
INFO:root:At the start of the epoch: mem (CPU python)=28042.44140625MB; mem (CPU total)=27821.97265625MB
INFO:root:[   47] Training loss: 0.66643360, Validation loss: 0.65715086, Gradient norm: 0.16894453
INFO:root:At the start of the epoch: mem (CPU python)=28080.5390625MB; mem (CPU total)=27860.08984375MB
INFO:root:[   48] Training loss: 0.66610599, Validation loss: 0.65532308, Gradient norm: 0.18747214
INFO:root:At the start of the epoch: mem (CPU python)=28118.6328125MB; mem (CPU total)=27898.859375MB
INFO:root:[   49] Training loss: 0.66589472, Validation loss: 0.65595742, Gradient norm: 0.18396243
INFO:root:At the start of the epoch: mem (CPU python)=28156.7265625MB; mem (CPU total)=27937.37109375MB
INFO:root:[   50] Training loss: 0.66563788, Validation loss: 0.65360288, Gradient norm: 0.20819972
INFO:root:At the start of the epoch: mem (CPU python)=28194.82421875MB; mem (CPU total)=27975.78125MB
INFO:root:[   51] Training loss: 0.66534891, Validation loss: 0.65449240, Gradient norm: 0.21764736
INFO:root:At the start of the epoch: mem (CPU python)=28232.91796875MB; mem (CPU total)=28013.82421875MB
INFO:root:[   52] Training loss: 0.66489716, Validation loss: 0.65263634, Gradient norm: 0.19646044
INFO:root:At the start of the epoch: mem (CPU python)=28271.01171875MB; mem (CPU total)=28052.296875MB
INFO:root:[   53] Training loss: 0.66491388, Validation loss: 0.65180481, Gradient norm: 0.23420309
INFO:root:At the start of the epoch: mem (CPU python)=28309.109375MB; mem (CPU total)=28090.20703125MB
INFO:root:[   54] Training loss: 0.66446169, Validation loss: 0.65100295, Gradient norm: 0.23262477
INFO:root:At the start of the epoch: mem (CPU python)=28347.203125MB; mem (CPU total)=28128.44140625MB
INFO:root:[   55] Training loss: 0.66428066, Validation loss: 0.64781479, Gradient norm: 0.27959709
INFO:root:At the start of the epoch: mem (CPU python)=28385.3046875MB; mem (CPU total)=28166.80078125MB
INFO:root:[   56] Training loss: 0.66412859, Validation loss: 0.65287175, Gradient norm: 0.26218418
INFO:root:At the start of the epoch: mem (CPU python)=28423.40234375MB; mem (CPU total)=28204.6796875MB
INFO:root:[   57] Training loss: 0.66388924, Validation loss: 0.65094167, Gradient norm: 0.28083005
INFO:root:At the start of the epoch: mem (CPU python)=28461.49609375MB; mem (CPU total)=28242.73828125MB
INFO:root:[   58] Training loss: 0.66363814, Validation loss: 0.65201891, Gradient norm: 0.25267409
INFO:root:At the start of the epoch: mem (CPU python)=28499.58984375MB; mem (CPU total)=28281.09375MB
INFO:root:[   59] Training loss: 0.66325883, Validation loss: 0.65042922, Gradient norm: 0.29027641
INFO:root:At the start of the epoch: mem (CPU python)=28537.68359375MB; mem (CPU total)=28319.51171875MB
INFO:root:[   60] Training loss: 0.66293633, Validation loss: 0.64977881, Gradient norm: 0.29288749
INFO:root:At the start of the epoch: mem (CPU python)=28575.78125MB; mem (CPU total)=28357.5703125MB
INFO:root:[   61] Training loss: 0.66286712, Validation loss: 0.64722039, Gradient norm: 0.35389986
INFO:root:At the start of the epoch: mem (CPU python)=28613.875MB; mem (CPU total)=28395.9765625MB
INFO:root:[   62] Training loss: 0.66247630, Validation loss: 0.64830679, Gradient norm: 0.30311812
INFO:root:At the start of the epoch: mem (CPU python)=28651.97265625MB; mem (CPU total)=28434.0859375MB
INFO:root:[   63] Training loss: 0.66245778, Validation loss: 0.64722718, Gradient norm: 0.32718503
INFO:root:At the start of the epoch: mem (CPU python)=28690.07421875MB; mem (CPU total)=28472.0234375MB
INFO:root:[   64] Training loss: 0.66227731, Validation loss: 0.64591765, Gradient norm: 0.34444252
INFO:root:At the start of the epoch: mem (CPU python)=28728.16796875MB; mem (CPU total)=28511.734375MB
INFO:root:[   65] Training loss: 0.66211252, Validation loss: 0.64695562, Gradient norm: 0.33272678
INFO:root:At the start of the epoch: mem (CPU python)=28766.26171875MB; mem (CPU total)=28549.8203125MB
INFO:root:[   66] Training loss: 0.66198738, Validation loss: 0.64496624, Gradient norm: 0.37472742
INFO:root:At the start of the epoch: mem (CPU python)=28804.35546875MB; mem (CPU total)=28587.98046875MB
INFO:root:[   67] Training loss: 0.66180949, Validation loss: 0.64564513, Gradient norm: 0.39513026
INFO:root:At the start of the epoch: mem (CPU python)=28842.453125MB; mem (CPU total)=28626.61328125MB
INFO:root:[   68] Training loss: 0.66140812, Validation loss: 0.64430275, Gradient norm: 0.37790456
INFO:root:At the start of the epoch: mem (CPU python)=28880.546875MB; mem (CPU total)=28664.23046875MB
INFO:root:[   69] Training loss: 0.66142248, Validation loss: 0.64381887, Gradient norm: 0.39582943
INFO:root:At the start of the epoch: mem (CPU python)=28918.640625MB; mem (CPU total)=28701.7734375MB
INFO:root:[   70] Training loss: 0.66136002, Validation loss: 0.64256399, Gradient norm: 0.39981904
INFO:root:At the start of the epoch: mem (CPU python)=28956.73828125MB; mem (CPU total)=28739.90234375MB
INFO:root:[   71] Training loss: 0.66121140, Validation loss: 0.64438236, Gradient norm: 0.44074758
INFO:root:At the start of the epoch: mem (CPU python)=28994.8359375MB; mem (CPU total)=28778.203125MB
INFO:root:[   72] Training loss: 0.66111043, Validation loss: 0.64291022, Gradient norm: 0.43233973
INFO:root:At the start of the epoch: mem (CPU python)=29032.9296875MB; mem (CPU total)=28816.34375MB
INFO:root:[   73] Training loss: 0.66090814, Validation loss: 0.64238701, Gradient norm: 0.48084954
INFO:root:At the start of the epoch: mem (CPU python)=29071.02734375MB; mem (CPU total)=28854.46875MB
INFO:root:[   74] Training loss: 0.66081325, Validation loss: 0.64237839, Gradient norm: 0.46131602
INFO:root:At the start of the epoch: mem (CPU python)=29109.12109375MB; mem (CPU total)=28892.859375MB
INFO:root:[   75] Training loss: 0.66089893, Validation loss: 0.64183872, Gradient norm: 0.51951384
INFO:root:At the start of the epoch: mem (CPU python)=29147.21484375MB; mem (CPU total)=28930.92578125MB
INFO:root:[   76] Training loss: 0.66063477, Validation loss: 0.64167716, Gradient norm: 0.47756305
INFO:root:At the start of the epoch: mem (CPU python)=29185.30859375MB; mem (CPU total)=28968.8359375MB
INFO:root:[   77] Training loss: 0.66063509, Validation loss: 0.64125637, Gradient norm: 0.49394250
INFO:root:At the start of the epoch: mem (CPU python)=29223.40625MB; mem (CPU total)=29006.94921875MB
INFO:root:[   78] Training loss: 0.66042157, Validation loss: 0.64078597, Gradient norm: 0.55579098
INFO:root:At the start of the epoch: mem (CPU python)=29261.5MB; mem (CPU total)=29044.83984375MB
INFO:root:[   79] Training loss: 0.66033022, Validation loss: 0.64149471, Gradient norm: 0.56798986
INFO:root:At the start of the epoch: mem (CPU python)=29299.59765625MB; mem (CPU total)=29082.7578125MB
INFO:root:[   80] Training loss: 0.66035757, Validation loss: 0.64069520, Gradient norm: 0.60683166
INFO:root:At the start of the epoch: mem (CPU python)=29337.6953125MB; mem (CPU total)=29120.828125MB
INFO:root:[   81] Training loss: 0.66008541, Validation loss: 0.64144677, Gradient norm: 0.55785003
INFO:root:At the start of the epoch: mem (CPU python)=29375.7890625MB; mem (CPU total)=29158.40625MB
INFO:root:[   82] Training loss: 0.66030986, Validation loss: 0.64127892, Gradient norm: 0.65029810
INFO:root:At the start of the epoch: mem (CPU python)=29413.8828125MB; mem (CPU total)=29196.671875MB
INFO:root:[   83] Training loss: 0.65978198, Validation loss: 0.64042262, Gradient norm: 0.64141564
INFO:root:At the start of the epoch: mem (CPU python)=29451.9765625MB; mem (CPU total)=29235.05859375MB
INFO:root:[   84] Training loss: 0.65978798, Validation loss: 0.64037328, Gradient norm: 0.69624179
INFO:root:At the start of the epoch: mem (CPU python)=29490.07421875MB; mem (CPU total)=29274.3359375MB
INFO:root:[   85] Training loss: 0.65967723, Validation loss: 0.64112691, Gradient norm: 0.71297621
INFO:root:At the start of the epoch: mem (CPU python)=29528.16796875MB; mem (CPU total)=29312.734375MB
INFO:root:[   86] Training loss: 0.65967157, Validation loss: 0.64122902, Gradient norm: 0.69889931
INFO:root:At the start of the epoch: mem (CPU python)=29566.26171875MB; mem (CPU total)=29351.08984375MB
INFO:root:[   87] Training loss: 0.65975781, Validation loss: 0.64036669, Gradient norm: 0.84017875
INFO:root:At the start of the epoch: mem (CPU python)=29604.359375MB; mem (CPU total)=29389.3984375MB
INFO:root:[   88] Training loss: 0.65968373, Validation loss: 0.64084599, Gradient norm: 0.88416757
INFO:root:At the start of the epoch: mem (CPU python)=29642.45703125MB; mem (CPU total)=29427.265625MB
INFO:root:[   89] Training loss: 0.65949601, Validation loss: 0.64111648, Gradient norm: 0.86035947
INFO:root:At the start of the epoch: mem (CPU python)=29680.55078125MB; mem (CPU total)=29465.36328125MB
INFO:root:[   90] Training loss: 0.65943097, Validation loss: 0.64074799, Gradient norm: 0.89384513
INFO:root:At the start of the epoch: mem (CPU python)=29718.6484375MB; mem (CPU total)=29503.23046875MB
INFO:root:[   91] Training loss: 0.65939111, Validation loss: 0.63988416, Gradient norm: 0.81928671
INFO:root:At the start of the epoch: mem (CPU python)=29756.7421875MB; mem (CPU total)=29541.37109375MB
INFO:root:[   92] Training loss: 0.65914849, Validation loss: 0.63974013, Gradient norm: 0.95125815
INFO:root:At the start of the epoch: mem (CPU python)=29794.8359375MB; mem (CPU total)=29579.48828125MB
INFO:root:[   93] Training loss: 0.65924842, Validation loss: 0.63992542, Gradient norm: 0.90008170
INFO:root:At the start of the epoch: mem (CPU python)=29832.9296875MB; mem (CPU total)=29617.609375MB
INFO:root:[   94] Training loss: 0.65923080, Validation loss: 0.63959522, Gradient norm: 1.03151277
INFO:root:At the start of the epoch: mem (CPU python)=29871.02734375MB; mem (CPU total)=29656.00390625MB
INFO:root:[   95] Training loss: 0.65895711, Validation loss: 0.63922522, Gradient norm: 1.05004664
INFO:root:At the start of the epoch: mem (CPU python)=29909.12109375MB; mem (CPU total)=29693.125MB
INFO:root:[   96] Training loss: 0.65890501, Validation loss: 0.63919798, Gradient norm: 1.04386927
INFO:root:At the start of the epoch: mem (CPU python)=29947.21484375MB; mem (CPU total)=29730.765625MB
INFO:root:[   97] Training loss: 0.65913877, Validation loss: 0.63939088, Gradient norm: 1.07690169
INFO:root:At the start of the epoch: mem (CPU python)=29985.3125MB; mem (CPU total)=29768.64453125MB
INFO:root:[   98] Training loss: 0.65890608, Validation loss: 0.64003400, Gradient norm: 1.16734649
INFO:root:At the start of the epoch: mem (CPU python)=30023.41015625MB; mem (CPU total)=29806.75390625MB
INFO:root:[   99] Training loss: 0.65871086, Validation loss: 0.64007678, Gradient norm: 1.21084165
INFO:root:At the start of the epoch: mem (CPU python)=30061.50390625MB; mem (CPU total)=29844.81640625MB
INFO:root:[  100] Training loss: 0.65887368, Validation loss: 0.63882882, Gradient norm: 1.10596255
INFO:root:At the start of the epoch: mem (CPU python)=30099.59765625MB; mem (CPU total)=29882.70703125MB
INFO:root:[  101] Training loss: 0.65873741, Validation loss: 0.63927659, Gradient norm: 1.20994602
INFO:root:At the start of the epoch: mem (CPU python)=30137.6953125MB; mem (CPU total)=29920.80078125MB
INFO:root:[  102] Training loss: 0.65874034, Validation loss: 0.63928319, Gradient norm: 1.36979452
INFO:root:At the start of the epoch: mem (CPU python)=30175.7890625MB; mem (CPU total)=29959.15625MB
INFO:root:[  103] Training loss: 0.65861384, Validation loss: 0.63922869, Gradient norm: 1.39030756
INFO:root:At the start of the epoch: mem (CPU python)=30213.8828125MB; mem (CPU total)=29997.75390625MB
INFO:root:[  104] Training loss: 0.65844565, Validation loss: 0.64001115, Gradient norm: 1.39347553
INFO:root:At the start of the epoch: mem (CPU python)=30251.98046875MB; mem (CPU total)=30035.90625MB
INFO:root:[  105] Training loss: 0.65847349, Validation loss: 0.63824768, Gradient norm: 1.39691532
INFO:root:At the start of the epoch: mem (CPU python)=30290.08203125MB; mem (CPU total)=30074.03125MB
INFO:root:[  106] Training loss: 0.65828162, Validation loss: 0.63962785, Gradient norm: 1.38782485
INFO:root:At the start of the epoch: mem (CPU python)=30328.17578125MB; mem (CPU total)=30112.14453125MB
INFO:root:[  107] Training loss: 0.65843190, Validation loss: 0.63880838, Gradient norm: 1.48014460
INFO:root:At the start of the epoch: mem (CPU python)=30366.2734375MB; mem (CPU total)=30150.01171875MB
INFO:root:[  108] Training loss: 0.65837879, Validation loss: 0.63787056, Gradient norm: 1.48666380
INFO:root:At the start of the epoch: mem (CPU python)=30404.3671875MB; mem (CPU total)=30188.4375MB
INFO:root:[  109] Training loss: 0.65809780, Validation loss: 0.63862793, Gradient norm: 1.60690683
INFO:root:At the start of the epoch: mem (CPU python)=30442.4609375MB; mem (CPU total)=30226.54296875MB
INFO:root:[  110] Training loss: 0.65828736, Validation loss: 0.63872509, Gradient norm: 1.41914117
INFO:root:At the start of the epoch: mem (CPU python)=30480.5546875MB; mem (CPU total)=30264.625MB
INFO:root:[  111] Training loss: 0.65817281, Validation loss: 0.63781621, Gradient norm: 1.58586882
INFO:root:At the start of the epoch: mem (CPU python)=30518.65234375MB; mem (CPU total)=30303.01171875MB
INFO:root:[  112] Training loss: 0.65834663, Validation loss: 0.63808355, Gradient norm: 1.60680102
INFO:root:At the start of the epoch: mem (CPU python)=30556.74609375MB; mem (CPU total)=30341.328125MB
INFO:root:[  113] Training loss: 0.65795063, Validation loss: 0.63789909, Gradient norm: 1.70591169
INFO:root:At the start of the epoch: mem (CPU python)=30594.83984375MB; mem (CPU total)=30379.453125MB
INFO:root:[  114] Training loss: 0.65819526, Validation loss: 0.63807433, Gradient norm: 1.70278304
INFO:root:At the start of the epoch: mem (CPU python)=30632.9375MB; mem (CPU total)=30417.82421875MB
INFO:root:[  115] Training loss: 0.65793237, Validation loss: 0.63859209, Gradient norm: 1.70043601
INFO:root:At the start of the epoch: mem (CPU python)=30671.03515625MB; mem (CPU total)=30455.95703125MB
INFO:root:[  116] Training loss: 0.65821110, Validation loss: 0.63798837, Gradient norm: 1.78664968
INFO:root:At the start of the epoch: mem (CPU python)=30709.12890625MB; mem (CPU total)=30493.79296875MB
INFO:root:[  117] Training loss: 0.65795776, Validation loss: 0.63716152, Gradient norm: 1.93135799
INFO:root:At the start of the epoch: mem (CPU python)=30747.22265625MB; mem (CPU total)=30532.18359375MB
INFO:root:[  118] Training loss: 0.65805323, Validation loss: 0.63823760, Gradient norm: 1.69413250
INFO:root:At the start of the epoch: mem (CPU python)=30785.3203125MB; mem (CPU total)=30570.296875MB
INFO:root:[  119] Training loss: 0.65808785, Validation loss: 0.63756498, Gradient norm: 1.68797441
INFO:root:At the start of the epoch: mem (CPU python)=30823.4140625MB; mem (CPU total)=30608.390625MB
INFO:root:[  120] Training loss: 0.65804813, Validation loss: 0.63874133, Gradient norm: 1.94896410
INFO:root:At the start of the epoch: mem (CPU python)=30861.5078125MB; mem (CPU total)=30646.5078125MB
INFO:root:[  121] Training loss: 0.65791690, Validation loss: 0.63767328, Gradient norm: 1.85284840
INFO:root:At the start of the epoch: mem (CPU python)=30899.609375MB; mem (CPU total)=30685.1484375MB
INFO:root:[  122] Training loss: 0.65775890, Validation loss: 0.63768809, Gradient norm: 1.84446575
INFO:root:At the start of the epoch: mem (CPU python)=30937.703125MB; mem (CPU total)=30722.93359375MB
INFO:root:[  123] Training loss: 0.65771777, Validation loss: 0.63881246, Gradient norm: 2.07358213
INFO:root:At the start of the epoch: mem (CPU python)=30975.796875MB; mem (CPU total)=30762.5234375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  124] Training loss: 0.65784865, Validation loss: 0.63846170, Gradient norm: 2.02200465
INFO:root:At the start of the epoch: mem (CPU python)=31013.89453125MB; mem (CPU total)=30800.84765625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  125] Training loss: 0.65692169, Validation loss: 0.63653983, Gradient norm: 1.34855000
INFO:root:At the start of the epoch: mem (CPU python)=31051.98828125MB; mem (CPU total)=30839.015625MB
INFO:root:[  126] Training loss: 0.65631581, Validation loss: 0.63622395, Gradient norm: 1.11251091
INFO:root:At the start of the epoch: mem (CPU python)=31090.08203125MB; mem (CPU total)=30876.88671875MB
INFO:root:[  127] Training loss: 0.65638424, Validation loss: 0.63652669, Gradient norm: 1.15997858
INFO:root:At the start of the epoch: mem (CPU python)=31128.17578125MB; mem (CPU total)=30915.24609375MB
INFO:root:[  128] Training loss: 0.65633815, Validation loss: 0.63652613, Gradient norm: 1.16942620
INFO:root:At the start of the epoch: mem (CPU python)=31166.2734375MB; mem (CPU total)=30953.375MB
INFO:root:[  129] Training loss: 0.65644274, Validation loss: 0.63624547, Gradient norm: 1.17747468
INFO:root:At the start of the epoch: mem (CPU python)=31204.37109375MB; mem (CPU total)=30991.89453125MB
INFO:root:[  130] Training loss: 0.65647488, Validation loss: 0.63637819, Gradient norm: 1.24974344
INFO:root:At the start of the epoch: mem (CPU python)=31242.46484375MB; mem (CPU total)=31030.234375MB
INFO:root:[  131] Training loss: 0.65632761, Validation loss: 0.63666223, Gradient norm: 1.32169501
INFO:root:At the start of the epoch: mem (CPU python)=31280.5625MB; mem (CPU total)=31067.96484375MB
INFO:root:[  132] Training loss: 0.65622397, Validation loss: 0.63672081, Gradient norm: 1.22969185
INFO:root:At the start of the epoch: mem (CPU python)=31318.65625MB; mem (CPU total)=31105.86328125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  133] Training loss: 0.65603631, Validation loss: 0.63603797, Gradient norm: 1.32290258
INFO:root:At the start of the epoch: mem (CPU python)=31356.75MB; mem (CPU total)=31144.43359375MB
INFO:root:[  134] Training loss: 0.65591020, Validation loss: 0.63627300, Gradient norm: 1.06578808
INFO:root:At the start of the epoch: mem (CPU python)=31394.84375MB; mem (CPU total)=31182.3046875MB
INFO:root:[  135] Training loss: 0.65603587, Validation loss: 0.63521942, Gradient norm: 1.02821282
INFO:root:At the start of the epoch: mem (CPU python)=31432.94140625MB; mem (CPU total)=31220.48046875MB
INFO:root:[  136] Training loss: 0.65581797, Validation loss: 0.63622266, Gradient norm: 1.06707656
INFO:root:At the start of the epoch: mem (CPU python)=31471.03515625MB; mem (CPU total)=31259.07421875MB
INFO:root:[  137] Training loss: 0.65595553, Validation loss: 0.63572248, Gradient norm: 1.11321792
INFO:root:At the start of the epoch: mem (CPU python)=31509.12890625MB; mem (CPU total)=31296.94140625MB
INFO:root:[  138] Training loss: 0.65611511, Validation loss: 0.63608846, Gradient norm: 1.18135154
INFO:root:At the start of the epoch: mem (CPU python)=31547.23046875MB; mem (CPU total)=31335.30078125MB
INFO:root:[  139] Training loss: 0.65597387, Validation loss: 0.63584939, Gradient norm: 1.16635064
INFO:root:At the start of the epoch: mem (CPU python)=31585.32421875MB; mem (CPU total)=31373.28125MB
INFO:root:[  140] Training loss: 0.65601767, Validation loss: 0.63558619, Gradient norm: 1.15096063
INFO:root:At the start of the epoch: mem (CPU python)=31623.41796875MB; mem (CPU total)=31411.328125MB
INFO:root:[  141] Training loss: 0.65599055, Validation loss: 0.63598513, Gradient norm: 1.22777225
INFO:root:At the start of the epoch: mem (CPU python)=31661.515625MB; mem (CPU total)=31449.453125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  142] Training loss: 0.65592261, Validation loss: 0.63659702, Gradient norm: 1.20806397
INFO:root:At the start of the epoch: mem (CPU python)=31699.609375MB; mem (CPU total)=31487.57421875MB
INFO:root:[  143] Training loss: 0.65585841, Validation loss: 0.63636520, Gradient norm: 1.02380417
INFO:root:At the start of the epoch: mem (CPU python)=31737.703125MB; mem (CPU total)=31525.71484375MB
INFO:root:[  144] Training loss: 0.65597986, Validation loss: 0.63659408, Gradient norm: 1.01082019
INFO:root:At the start of the epoch: mem (CPU python)=31775.796875MB; mem (CPU total)=31564.1015625MB
INFO:root:EP 144: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=31813.6953125MB; mem (CPU total)=31601.98828125MB
INFO:root:Training the model took 9652.944s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.89905
INFO:root:EnergyScoreTrain: 0.63273
INFO:root:CRPSTrain: 0.53771
INFO:root:Gaussian NLLTrain: 32462804423.11112
INFO:root:CoverageTrain: 0.65219
INFO:root:IntervalWidthTrain: 2.76386
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.90374
INFO:root:EnergyScoreValidation: 0.63605
INFO:root:CRPSValidation: 0.54172
INFO:root:Gaussian NLLValidation: 33579513064.10666
INFO:root:CoverageValidation: 0.65235
INFO:root:IntervalWidthValidation: 2.76627
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.9037
INFO:root:EnergyScoreTest: 0.63602
INFO:root:CRPSTest: 0.54127
INFO:root:Gaussian NLLTest: 33331338248.192
INFO:root:CoverageTest: 0.65214
INFO:root:IntervalWidthTest: 2.76491
INFO:root:After validation: mem (CPU python)=31857.08984375MB; mem (CPU total)=31645.23828125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=31857.08984375MB; mem (CPU total)=31645.71484375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=31857.41796875MB; mem (CPU total)=31645.70703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=31857.41796875MB; mem (CPU total)=31645.9375MB
INFO:root:[    1] Training loss: 0.72666208, Validation loss: 0.72075956, Gradient norm: 0.02315762
INFO:root:At the start of the epoch: mem (CPU python)=31895.375MB; mem (CPU total)=31684.1640625MB
INFO:root:[    2] Training loss: 0.72040676, Validation loss: 0.71880914, Gradient norm: 0.00713636
INFO:root:At the start of the epoch: mem (CPU python)=31933.46484375MB; mem (CPU total)=31722.265625MB
INFO:root:[    3] Training loss: 0.71908144, Validation loss: 0.71730856, Gradient norm: 0.01357261
INFO:root:At the start of the epoch: mem (CPU python)=31971.5625MB; mem (CPU total)=31760.6015625MB
INFO:root:[    4] Training loss: 0.71615736, Validation loss: 0.71077201, Gradient norm: 0.02463349
INFO:root:At the start of the epoch: mem (CPU python)=32009.66015625MB; mem (CPU total)=31798.7109375MB
INFO:root:[    5] Training loss: 0.71098613, Validation loss: 0.70411984, Gradient norm: 0.02933681
INFO:root:At the start of the epoch: mem (CPU python)=32047.75390625MB; mem (CPU total)=31837.05859375MB
INFO:root:[    6] Training loss: 0.70611453, Validation loss: 0.69825578, Gradient norm: 0.03706559
INFO:root:At the start of the epoch: mem (CPU python)=32085.84765625MB; mem (CPU total)=31875.7265625MB
INFO:root:[    7] Training loss: 0.70217976, Validation loss: 0.69444593, Gradient norm: 0.03272832
INFO:root:At the start of the epoch: mem (CPU python)=32123.9453125MB; mem (CPU total)=31913.6328125MB
INFO:root:[    8] Training loss: 0.69860054, Validation loss: 0.69103522, Gradient norm: 0.03709684
INFO:root:At the start of the epoch: mem (CPU python)=32162.0390625MB; mem (CPU total)=31951.59375MB
INFO:root:[    9] Training loss: 0.69580880, Validation loss: 0.68682117, Gradient norm: 0.04012452
INFO:root:At the start of the epoch: mem (CPU python)=32200.1328125MB; mem (CPU total)=31989.41015625MB
INFO:root:[   10] Training loss: 0.69321437, Validation loss: 0.68387383, Gradient norm: 0.04526780
INFO:root:At the start of the epoch: mem (CPU python)=32238.23046875MB; mem (CPU total)=32027.21875MB
INFO:root:[   11] Training loss: 0.69089120, Validation loss: 0.68108518, Gradient norm: 0.04026134
INFO:root:At the start of the epoch: mem (CPU python)=32276.32421875MB; mem (CPU total)=32065.52734375MB
INFO:root:[   12] Training loss: 0.68887024, Validation loss: 0.67751891, Gradient norm: 0.04642255
INFO:root:At the start of the epoch: mem (CPU python)=32314.421875MB; mem (CPU total)=32103.9375MB
INFO:root:[   13] Training loss: 0.68732300, Validation loss: 0.67604234, Gradient norm: 0.05285754
INFO:root:At the start of the epoch: mem (CPU python)=32352.515625MB; mem (CPU total)=32142.51953125MB
INFO:root:[   14] Training loss: 0.68581634, Validation loss: 0.67364334, Gradient norm: 0.05232841
INFO:root:At the start of the epoch: mem (CPU python)=32390.61328125MB; mem (CPU total)=32180.64453125MB
INFO:root:[   15] Training loss: 0.68451925, Validation loss: 0.67174258, Gradient norm: 0.05966603
INFO:root:At the start of the epoch: mem (CPU python)=32428.70703125MB; mem (CPU total)=32217.79296875MB
INFO:root:[   16] Training loss: 0.68327379, Validation loss: 0.67043539, Gradient norm: 0.07286859
INFO:root:At the start of the epoch: mem (CPU python)=32466.80078125MB; mem (CPU total)=32255.66796875MB
INFO:root:[   17] Training loss: 0.68232636, Validation loss: 0.66909134, Gradient norm: 0.08489132
INFO:root:At the start of the epoch: mem (CPU python)=32504.8984375MB; mem (CPU total)=32294.0546875MB
INFO:root:[   18] Training loss: 0.68101718, Validation loss: 0.66802707, Gradient norm: 0.10898238
INFO:root:At the start of the epoch: mem (CPU python)=32542.99609375MB; mem (CPU total)=32332.359375MB
INFO:root:[   19] Training loss: 0.68025158, Validation loss: 0.66885755, Gradient norm: 0.11129103
INFO:root:At the start of the epoch: mem (CPU python)=32581.08984375MB; mem (CPU total)=32370.28125MB
INFO:root:[   20] Training loss: 0.67921988, Validation loss: 0.67006873, Gradient norm: 0.18381946
INFO:root:At the start of the epoch: mem (CPU python)=32619.18359375MB; mem (CPU total)=32407.93359375MB
INFO:root:[   21] Training loss: 0.67845195, Validation loss: 0.66930815, Gradient norm: 0.18669647
INFO:root:At the start of the epoch: mem (CPU python)=32657.28125MB; mem (CPU total)=32446.0390625MB
INFO:root:[   22] Training loss: 0.67732942, Validation loss: 0.67143443, Gradient norm: 0.21736085
INFO:root:At the start of the epoch: mem (CPU python)=32695.375MB; mem (CPU total)=32484.3515625MB
INFO:root:[   23] Training loss: 0.67648847, Validation loss: 0.67094319, Gradient norm: 0.24795941
INFO:root:At the start of the epoch: mem (CPU python)=32733.46875MB; mem (CPU total)=32522.484375MB
INFO:root:[   24] Training loss: 0.67581678, Validation loss: 0.67120344, Gradient norm: 0.28183266
INFO:root:At the start of the epoch: mem (CPU python)=32777.8203125MB; mem (CPU total)=32566.83203125MB
INFO:root:[   25] Training loss: 0.67499063, Validation loss: 0.67593297, Gradient norm: 0.31971381
INFO:root:At the start of the epoch: mem (CPU python)=32777.84765625MB; mem (CPU total)=32555.7421875MB
INFO:root:[   26] Training loss: 0.67482805, Validation loss: 0.68404986, Gradient norm: 0.40147786
INFO:root:At the start of the epoch: mem (CPU python)=32804.00390625MB; mem (CPU total)=32593.65234375MB
INFO:root:[   27] Training loss: 0.67384617, Validation loss: 0.67796994, Gradient norm: 0.42822915
INFO:root:At the start of the epoch: mem (CPU python)=32867.10546875MB; mem (CPU total)=32657.01171875MB
INFO:root:[   28] Training loss: 0.67340379, Validation loss: 0.66964796, Gradient norm: 0.54140057
INFO:root:At the start of the epoch: mem (CPU python)=32905.19921875MB; mem (CPU total)=32695.3984375MB
INFO:root:[   29] Training loss: 0.67294162, Validation loss: 0.67188162, Gradient norm: 0.51218198
INFO:root:At the start of the epoch: mem (CPU python)=32943.30078125MB; mem (CPU total)=32733.28515625MB
INFO:root:[   30] Training loss: 0.67234554, Validation loss: 0.67304439, Gradient norm: 0.52691411
INFO:root:At the start of the epoch: mem (CPU python)=32981.39453125MB; mem (CPU total)=32771.65234375MB
INFO:root:[   31] Training loss: 0.67179832, Validation loss: 0.67188905, Gradient norm: 0.60286311
INFO:root:At the start of the epoch: mem (CPU python)=33019.4921875MB; mem (CPU total)=32809.55078125MB
INFO:root:[   32] Training loss: 0.67134220, Validation loss: 0.66972689, Gradient norm: 0.72670681
INFO:root:At the start of the epoch: mem (CPU python)=33057.5859375MB; mem (CPU total)=32847.953125MB
INFO:root:[   33] Training loss: 0.67084359, Validation loss: 0.66226711, Gradient norm: 0.81317559
INFO:root:At the start of the epoch: mem (CPU python)=33095.68359375MB; mem (CPU total)=32886.40234375MB
INFO:root:[   34] Training loss: 0.67070462, Validation loss: 0.66235778, Gradient norm: 0.85354255
INFO:root:At the start of the epoch: mem (CPU python)=33133.77734375MB; mem (CPU total)=32924.546875MB
INFO:root:[   35] Training loss: 0.67021184, Validation loss: 0.65774622, Gradient norm: 0.96145997
INFO:root:At the start of the epoch: mem (CPU python)=33171.875MB; mem (CPU total)=32962.7734375MB
INFO:root:[   36] Training loss: 0.66988648, Validation loss: 0.65842803, Gradient norm: 0.95478233
INFO:root:At the start of the epoch: mem (CPU python)=33209.96875MB; mem (CPU total)=33001.1328125MB
INFO:root:[   37] Training loss: 0.66954787, Validation loss: 0.66138067, Gradient norm: 1.01335093
INFO:root:At the start of the epoch: mem (CPU python)=33248.0625MB; mem (CPU total)=33039.32421875MB
INFO:root:[   38] Training loss: 0.66936494, Validation loss: 0.65766402, Gradient norm: 1.20014778
INFO:root:At the start of the epoch: mem (CPU python)=33286.16015625MB; mem (CPU total)=33077.49609375MB
INFO:root:[   39] Training loss: 0.66935553, Validation loss: 0.65481510, Gradient norm: 1.31816440
INFO:root:At the start of the epoch: mem (CPU python)=33324.25390625MB; mem (CPU total)=33115.90234375MB
INFO:root:[   40] Training loss: 0.66890598, Validation loss: 0.65197446, Gradient norm: 1.48349996
INFO:root:At the start of the epoch: mem (CPU python)=33362.34765625MB; mem (CPU total)=33154.046875MB
INFO:root:[   41] Training loss: 0.66857038, Validation loss: 0.65161775, Gradient norm: 1.35330173
INFO:root:At the start of the epoch: mem (CPU python)=33400.4453125MB; mem (CPU total)=33192.19921875MB
INFO:root:[   42] Training loss: 0.66841136, Validation loss: 0.65302292, Gradient norm: 1.48853062
INFO:root:At the start of the epoch: mem (CPU python)=33438.5390625MB; mem (CPU total)=33230.7734375MB
INFO:root:[   43] Training loss: 0.66810908, Validation loss: 0.65020838, Gradient norm: 1.51589665
INFO:root:At the start of the epoch: mem (CPU python)=33476.63671875MB; mem (CPU total)=33269.92578125MB
INFO:root:[   44] Training loss: 0.66814247, Validation loss: 0.65077126, Gradient norm: 1.63328174
INFO:root:At the start of the epoch: mem (CPU python)=33514.734375MB; mem (CPU total)=33307.34765625MB
INFO:root:[   45] Training loss: 0.66811470, Validation loss: 0.64996152, Gradient norm: 1.86474694
INFO:root:At the start of the epoch: mem (CPU python)=33552.828125MB; mem (CPU total)=33345.48828125MB
INFO:root:[   46] Training loss: 0.66774715, Validation loss: 0.64988792, Gradient norm: 1.93564722
INFO:root:At the start of the epoch: mem (CPU python)=33590.921875MB; mem (CPU total)=33383.7890625MB
INFO:root:[   47] Training loss: 0.66774456, Validation loss: 0.64959621, Gradient norm: 2.02863867
INFO:root:At the start of the epoch: mem (CPU python)=33629.015625MB; mem (CPU total)=33421.88671875MB
INFO:root:[   48] Training loss: 0.66741411, Validation loss: 0.64907036, Gradient norm: 1.88902921
INFO:root:At the start of the epoch: mem (CPU python)=33667.11328125MB; mem (CPU total)=33460.03125MB
INFO:root:[   49] Training loss: 0.66764111, Validation loss: 0.64872999, Gradient norm: 2.24019645
INFO:root:At the start of the epoch: mem (CPU python)=33705.20703125MB; mem (CPU total)=33498.453125MB
INFO:root:[   50] Training loss: 0.66724220, Validation loss: 0.65043350, Gradient norm: 2.46279491
INFO:root:At the start of the epoch: mem (CPU python)=33743.30078125MB; mem (CPU total)=33536.625MB
INFO:root:[   51] Training loss: 0.66687350, Validation loss: 0.64913831, Gradient norm: 2.17937691
INFO:root:At the start of the epoch: mem (CPU python)=33781.3984375MB; mem (CPU total)=33575.3125MB
INFO:root:[   52] Training loss: 0.66693302, Validation loss: 0.64768685, Gradient norm: 2.61019997
INFO:root:At the start of the epoch: mem (CPU python)=33819.49609375MB; mem (CPU total)=33612.73828125MB
INFO:root:[   53] Training loss: 0.66665584, Validation loss: 0.64959098, Gradient norm: 2.54791373
INFO:root:At the start of the epoch: mem (CPU python)=33857.59375MB; mem (CPU total)=33652.08203125MB
INFO:root:[   54] Training loss: 0.66684932, Validation loss: 0.64761209, Gradient norm: 2.67687787
INFO:root:At the start of the epoch: mem (CPU python)=33895.6875MB; mem (CPU total)=33690.2734375MB
INFO:root:[   55] Training loss: 0.66692273, Validation loss: 0.64891530, Gradient norm: 2.88028213
INFO:root:At the start of the epoch: mem (CPU python)=33933.78515625MB; mem (CPU total)=33728.421875MB
INFO:root:[   56] Training loss: 0.66673610, Validation loss: 0.64782881, Gradient norm: 2.76959130
INFO:root:At the start of the epoch: mem (CPU python)=33971.87890625MB; mem (CPU total)=33766.8046875MB
INFO:root:[   57] Training loss: 0.66700874, Validation loss: 0.64703909, Gradient norm: 3.04461829
INFO:root:At the start of the epoch: mem (CPU python)=34009.97265625MB; mem (CPU total)=33804.734375MB
INFO:root:[   58] Training loss: 0.66659304, Validation loss: 0.64757490, Gradient norm: 2.72949462
INFO:root:At the start of the epoch: mem (CPU python)=34048.0703125MB; mem (CPU total)=33842.859375MB
INFO:root:[   59] Training loss: 0.66639099, Validation loss: 0.64667617, Gradient norm: 2.76139449
INFO:root:At the start of the epoch: mem (CPU python)=34086.1640625MB; mem (CPU total)=33881.10546875MB
INFO:root:[   60] Training loss: 0.66637937, Validation loss: 0.64721799, Gradient norm: 3.09198059
INFO:root:At the start of the epoch: mem (CPU python)=34124.2578125MB; mem (CPU total)=33919.6640625MB
INFO:root:[   61] Training loss: 0.66613526, Validation loss: 0.64790700, Gradient norm: 3.04707528
INFO:root:At the start of the epoch: mem (CPU python)=34162.359375MB; mem (CPU total)=33957.3984375MB
INFO:root:[   62] Training loss: 0.66652699, Validation loss: 0.64747658, Gradient norm: 3.63237000
INFO:root:At the start of the epoch: mem (CPU python)=34200.453125MB; mem (CPU total)=33995.26953125MB
INFO:root:[   63] Training loss: 0.66616491, Validation loss: 0.64562172, Gradient norm: 3.31884616
INFO:root:At the start of the epoch: mem (CPU python)=34238.546875MB; mem (CPU total)=34033.703125MB
INFO:root:[   64] Training loss: 0.66637709, Validation loss: 0.64721392, Gradient norm: 3.69834471
INFO:root:At the start of the epoch: mem (CPU python)=34276.640625MB; mem (CPU total)=34071.3359375MB
INFO:root:[   65] Training loss: 0.66602227, Validation loss: 0.64571907, Gradient norm: 3.52347722
INFO:root:At the start of the epoch: mem (CPU python)=34314.73828125MB; mem (CPU total)=34109.4765625MB
INFO:root:[   66] Training loss: 0.66586374, Validation loss: 0.64791987, Gradient norm: 3.55449870
INFO:root:At the start of the epoch: mem (CPU python)=34352.83203125MB; mem (CPU total)=34147.6328125MB
INFO:root:[   67] Training loss: 0.66596466, Validation loss: 0.64590221, Gradient norm: 3.74179553
INFO:root:At the start of the epoch: mem (CPU python)=34390.9296875MB; mem (CPU total)=34185.6875MB
INFO:root:[   68] Training loss: 0.66564265, Validation loss: 0.64619568, Gradient norm: 3.45252417
INFO:root:At the start of the epoch: mem (CPU python)=34429.02734375MB; mem (CPU total)=34224.73046875MB
INFO:root:[   69] Training loss: 0.66614911, Validation loss: 0.64479561, Gradient norm: 3.98983254
INFO:root:At the start of the epoch: mem (CPU python)=34467.12109375MB; mem (CPU total)=34262.08203125MB
INFO:root:[   70] Training loss: 0.66575150, Validation loss: 0.64614230, Gradient norm: 3.81552987
INFO:root:At the start of the epoch: mem (CPU python)=34505.21484375MB; mem (CPU total)=34299.98046875MB
INFO:root:[   71] Training loss: 0.66573265, Validation loss: 0.64575345, Gradient norm: 4.09449115
INFO:root:At the start of the epoch: mem (CPU python)=34543.30859375MB; mem (CPU total)=34338.60546875MB
INFO:root:[   72] Training loss: 0.66567559, Validation loss: 0.64906196, Gradient norm: 4.08734075
INFO:root:At the start of the epoch: mem (CPU python)=34581.40625MB; mem (CPU total)=34376.51171875MB
INFO:root:[   73] Training loss: 0.66569377, Validation loss: 0.64655831, Gradient norm: 4.17376747
INFO:root:At the start of the epoch: mem (CPU python)=34619.5MB; mem (CPU total)=34414.3515625MB
INFO:root:[   74] Training loss: 0.66578898, Validation loss: 0.64607381, Gradient norm: 4.39717385
INFO:root:At the start of the epoch: mem (CPU python)=34657.59375MB; mem (CPU total)=34452.71875MB
INFO:root:[   75] Training loss: 0.66569013, Validation loss: 0.64547783, Gradient norm: 4.37064919
INFO:root:At the start of the epoch: mem (CPU python)=34695.69140625MB; mem (CPU total)=34491.0859375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   76] Training loss: 0.66592516, Validation loss: 0.64846496, Gradient norm: 4.58131192
INFO:root:At the start of the epoch: mem (CPU python)=34733.7890625MB; mem (CPU total)=34529.73046875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   77] Training loss: 0.66400132, Validation loss: 0.64434724, Gradient norm: 3.21993064
INFO:root:At the start of the epoch: mem (CPU python)=34771.8828125MB; mem (CPU total)=34568.36328125MB
INFO:root:[   78] Training loss: 0.66355267, Validation loss: 0.64538377, Gradient norm: 2.55426593
INFO:root:At the start of the epoch: mem (CPU python)=34809.98046875MB; mem (CPU total)=34606.515625MB
INFO:root:[   79] Training loss: 0.66328205, Validation loss: 0.64357805, Gradient norm: 2.92890905
INFO:root:At the start of the epoch: mem (CPU python)=34848.07421875MB; mem (CPU total)=34644.453125MB
INFO:root:[   80] Training loss: 0.66358378, Validation loss: 0.64464960, Gradient norm: 2.85432759
INFO:root:At the start of the epoch: mem (CPU python)=34886.16796875MB; mem (CPU total)=34682.62109375MB
INFO:root:[   81] Training loss: 0.66352744, Validation loss: 0.64423264, Gradient norm: 3.15916905
INFO:root:At the start of the epoch: mem (CPU python)=34924.26171875MB; mem (CPU total)=34720.49609375MB
INFO:root:[   82] Training loss: 0.66327001, Validation loss: 0.64409698, Gradient norm: 3.20806549
INFO:root:At the start of the epoch: mem (CPU python)=34962.359375MB; mem (CPU total)=34758.640625MB
INFO:root:[   83] Training loss: 0.66316102, Validation loss: 0.64402110, Gradient norm: 3.52008848
INFO:root:At the start of the epoch: mem (CPU python)=35000.453125MB; mem (CPU total)=34797.203125MB
INFO:root:[   84] Training loss: 0.66327009, Validation loss: 0.64450480, Gradient norm: 3.33248009
INFO:root:At the start of the epoch: mem (CPU python)=35038.55078125MB; mem (CPU total)=34835.60546875MB
INFO:root:[   85] Training loss: 0.66317883, Validation loss: 0.64385060, Gradient norm: 3.45416733
INFO:root:At the start of the epoch: mem (CPU python)=35076.6484375MB; mem (CPU total)=34873.4765625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   86] Training loss: 0.66326555, Validation loss: 0.64454353, Gradient norm: 3.28162428
INFO:root:At the start of the epoch: mem (CPU python)=35114.7421875MB; mem (CPU total)=34911.6171875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   87] Training loss: 0.66291689, Validation loss: 0.64398369, Gradient norm: 2.79923627
INFO:root:At the start of the epoch: mem (CPU python)=35152.8359375MB; mem (CPU total)=34949.73046875MB
INFO:root:[   88] Training loss: 0.66262374, Validation loss: 0.64315923, Gradient norm: 2.56847215
INFO:root:At the start of the epoch: mem (CPU python)=35190.9296875MB; mem (CPU total)=34987.6640625MB
INFO:root:[   89] Training loss: 0.66254214, Validation loss: 0.64379020, Gradient norm: 2.53904209
INFO:root:At the start of the epoch: mem (CPU python)=35229.02734375MB; mem (CPU total)=35025.81640625MB
INFO:root:[   90] Training loss: 0.66272019, Validation loss: 0.64366049, Gradient norm: 2.57914234
INFO:root:At the start of the epoch: mem (CPU python)=35267.12109375MB; mem (CPU total)=35064.4296875MB
INFO:root:[   91] Training loss: 0.66279611, Validation loss: 0.64363216, Gradient norm: 2.69455946
INFO:root:At the start of the epoch: mem (CPU python)=35305.21484375MB; mem (CPU total)=35102.58203125MB
INFO:root:[   92] Training loss: 0.66250937, Validation loss: 0.64425747, Gradient norm: 2.67099630
INFO:root:At the start of the epoch: mem (CPU python)=35343.3125MB; mem (CPU total)=35140.24609375MB
INFO:root:[   93] Training loss: 0.66247888, Validation loss: 0.64442668, Gradient norm: 2.86492426
INFO:root:At the start of the epoch: mem (CPU python)=35381.40625MB; mem (CPU total)=35178.14453125MB
INFO:root:[   94] Training loss: 0.66254264, Validation loss: 0.64355851, Gradient norm: 2.54213177
INFO:root:At the start of the epoch: mem (CPU python)=35419.50390625MB; mem (CPU total)=35216.03125MB
INFO:root:[   95] Training loss: 0.66256207, Validation loss: 0.64351178, Gradient norm: 2.84022999
INFO:root:At the start of the epoch: mem (CPU python)=35457.6015625MB; mem (CPU total)=35254.19140625MB
INFO:root:[   96] Training loss: 0.66261102, Validation loss: 0.64321242, Gradient norm: 2.94831791
INFO:root:At the start of the epoch: mem (CPU python)=35495.6953125MB; mem (CPU total)=35292.6640625MB
INFO:root:[   97] Training loss: 0.66262995, Validation loss: 0.64308631, Gradient norm: 2.88967545
INFO:root:At the start of the epoch: mem (CPU python)=35533.7890625MB; mem (CPU total)=35331.02734375MB
INFO:root:[   98] Training loss: 0.66260491, Validation loss: 0.64338441, Gradient norm: 3.01401672
INFO:root:At the start of the epoch: mem (CPU python)=35571.8828125MB; mem (CPU total)=35369.14453125MB
INFO:root:[   99] Training loss: 0.66256576, Validation loss: 0.64342922, Gradient norm: 3.06947663
INFO:root:At the start of the epoch: mem (CPU python)=35609.98046875MB; mem (CPU total)=35407.00390625MB
INFO:root:[  100] Training loss: 0.66270845, Validation loss: 0.64325660, Gradient norm: 3.07993614
INFO:root:At the start of the epoch: mem (CPU python)=35648.07421875MB; mem (CPU total)=35445.109375MB
INFO:root:[  101] Training loss: 0.66253503, Validation loss: 0.64351253, Gradient norm: 3.02837908
INFO:root:At the start of the epoch: mem (CPU python)=35686.171875MB; mem (CPU total)=35482.84765625MB
INFO:root:[  102] Training loss: 0.66261798, Validation loss: 0.64367479, Gradient norm: 3.22040573
INFO:root:At the start of the epoch: mem (CPU python)=35724.26953125MB; mem (CPU total)=35520.953125MB
INFO:root:[  103] Training loss: 0.66251045, Validation loss: 0.64337208, Gradient norm: 3.05057747
INFO:root:At the start of the epoch: mem (CPU python)=35762.36328125MB; mem (CPU total)=35559.07421875MB
INFO:root:[  104] Training loss: 0.66248874, Validation loss: 0.64396962, Gradient norm: 3.09705788
INFO:root:At the start of the epoch: mem (CPU python)=35800.45703125MB; mem (CPU total)=35597.1875MB
INFO:root:[  105] Training loss: 0.66239073, Validation loss: 0.64338181, Gradient norm: 3.19981909
INFO:root:At the start of the epoch: mem (CPU python)=35838.55078125MB; mem (CPU total)=35635.56640625MB
INFO:root:[  106] Training loss: 0.66241065, Validation loss: 0.64342908, Gradient norm: 3.21380776
INFO:root:At the start of the epoch: mem (CPU python)=35876.6484375MB; mem (CPU total)=35673.69140625MB
INFO:root:EP 106: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=35914.7421875MB; mem (CPU total)=35711.8359375MB
INFO:root:Training the model took 7757.334s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.91243
INFO:root:EnergyScoreTrain: 0.64226
INFO:root:CRPSTrain: 0.57159
INFO:root:Gaussian NLLTrain: 80271252138.66672
INFO:root:CoverageTrain: 0.56364
INFO:root:IntervalWidthTrain: 2.54564
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.91388
INFO:root:EnergyScoreValidation: 0.64331
INFO:root:CRPSValidation: 0.57324
INFO:root:Gaussian NLLValidation: 81600376631.75107
INFO:root:CoverageValidation: 0.56283
INFO:root:IntervalWidthValidation: 2.54224
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.91496
INFO:root:EnergyScoreTest: 0.64406
INFO:root:CRPSTest: 0.5738
INFO:root:Gaussian NLLTest: 81204395016.192
INFO:root:CoverageTest: 0.56387
INFO:root:IntervalWidthTest: 2.54673
INFO:root:After validation: mem (CPU python)=35957.9296875MB; mem (CPU total)=35755.1640625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=35957.9296875MB; mem (CPU total)=35755.1640625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=35958.16796875MB; mem (CPU total)=35755.1640625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=35958.24609375MB; mem (CPU total)=35755.90234375MB
INFO:root:[    1] Training loss: 0.72606446, Validation loss: 0.72129451, Gradient norm: 0.02068684
INFO:root:At the start of the epoch: mem (CPU python)=35996.1953125MB; mem (CPU total)=35793.81640625MB
INFO:root:[    2] Training loss: 0.72067540, Validation loss: 0.71947905, Gradient norm: 0.00617214
INFO:root:At the start of the epoch: mem (CPU python)=36034.28125MB; mem (CPU total)=35831.9609375MB
INFO:root:[    3] Training loss: 0.71927963, Validation loss: 0.71856510, Gradient norm: 0.00781298
INFO:root:At the start of the epoch: mem (CPU python)=36072.37890625MB; mem (CPU total)=35870.34765625MB
INFO:root:[    4] Training loss: 0.71799415, Validation loss: 0.71524187, Gradient norm: 0.01105400
INFO:root:At the start of the epoch: mem (CPU python)=36110.47265625MB; mem (CPU total)=35908.203125MB
INFO:root:[    5] Training loss: 0.71422420, Validation loss: 0.70870335, Gradient norm: 0.02282758
INFO:root:At the start of the epoch: mem (CPU python)=36148.56640625MB; mem (CPU total)=35945.59375MB
INFO:root:[    6] Training loss: 0.70962018, Validation loss: 0.70307484, Gradient norm: 0.02690811
INFO:root:At the start of the epoch: mem (CPU python)=36186.6640625MB; mem (CPU total)=35984.3046875MB
INFO:root:[    7] Training loss: 0.70508854, Validation loss: 0.69734438, Gradient norm: 0.03090766
INFO:root:At the start of the epoch: mem (CPU python)=36224.7578125MB; mem (CPU total)=36022.234375MB
INFO:root:[    8] Training loss: 0.70056360, Validation loss: 0.69178673, Gradient norm: 0.03226097
INFO:root:At the start of the epoch: mem (CPU python)=36262.8515625MB; mem (CPU total)=36060.890625MB
INFO:root:[    9] Training loss: 0.69598654, Validation loss: 0.68518821, Gradient norm: 0.03370575
INFO:root:At the start of the epoch: mem (CPU python)=36300.94921875MB; mem (CPU total)=36098.765625MB
INFO:root:[   10] Training loss: 0.69164687, Validation loss: 0.67980357, Gradient norm: 0.03292265
INFO:root:At the start of the epoch: mem (CPU python)=36339.04296875MB; mem (CPU total)=36136.8671875MB
INFO:root:[   11] Training loss: 0.68772687, Validation loss: 0.67557484, Gradient norm: 0.03456230
INFO:root:At the start of the epoch: mem (CPU python)=36377.13671875MB; mem (CPU total)=36174.97265625MB
INFO:root:[   12] Training loss: 0.68490055, Validation loss: 0.67161482, Gradient norm: 0.03418701
INFO:root:At the start of the epoch: mem (CPU python)=36415.234375MB; mem (CPU total)=36216.421875MB
INFO:root:[   13] Training loss: 0.68202813, Validation loss: 0.66803012, Gradient norm: 0.03580089
INFO:root:At the start of the epoch: mem (CPU python)=36453.33203125MB; mem (CPU total)=36254.75MB
INFO:root:[   14] Training loss: 0.67959780, Validation loss: 0.66552471, Gradient norm: 0.03852558
INFO:root:At the start of the epoch: mem (CPU python)=36491.42578125MB; mem (CPU total)=36290.88671875MB
INFO:root:[   15] Training loss: 0.67756228, Validation loss: 0.66298778, Gradient norm: 0.04218984
INFO:root:At the start of the epoch: mem (CPU python)=36529.51953125MB; mem (CPU total)=36329.1953125MB
INFO:root:[   16] Training loss: 0.67548312, Validation loss: 0.65992390, Gradient norm: 0.03779951
INFO:root:At the start of the epoch: mem (CPU python)=36567.6171875MB; mem (CPU total)=36367.21875MB
INFO:root:[   17] Training loss: 0.67385122, Validation loss: 0.65801683, Gradient norm: 0.04373213
INFO:root:At the start of the epoch: mem (CPU python)=36605.7109375MB; mem (CPU total)=36406.03125MB
INFO:root:[   18] Training loss: 0.67226932, Validation loss: 0.65603148, Gradient norm: 0.04114130
INFO:root:At the start of the epoch: mem (CPU python)=36643.8046875MB; mem (CPU total)=36444.09375MB
INFO:root:[   19] Training loss: 0.67086633, Validation loss: 0.65468482, Gradient norm: 0.04700089
INFO:root:At the start of the epoch: mem (CPU python)=36681.90234375MB; mem (CPU total)=36482.4296875MB
INFO:root:[   20] Training loss: 0.66982259, Validation loss: 0.65288156, Gradient norm: 0.04631661
INFO:root:At the start of the epoch: mem (CPU python)=36720.0MB; mem (CPU total)=36519.6015625MB
INFO:root:[   21] Training loss: 0.66840043, Validation loss: 0.65150125, Gradient norm: 0.04390748
INFO:root:At the start of the epoch: mem (CPU python)=36758.09375MB; mem (CPU total)=36557.23046875MB
INFO:root:[   22] Training loss: 0.66767036, Validation loss: 0.65104855, Gradient norm: 0.05015809
INFO:root:At the start of the epoch: mem (CPU python)=36796.1875MB; mem (CPU total)=36595.58984375MB
INFO:root:[   23] Training loss: 0.66657853, Validation loss: 0.64979634, Gradient norm: 0.05924334
INFO:root:At the start of the epoch: mem (CPU python)=36834.28515625MB; mem (CPU total)=36633.9453125MB
INFO:root:[   24] Training loss: 0.66594025, Validation loss: 0.64858223, Gradient norm: 0.06198321
INFO:root:At the start of the epoch: mem (CPU python)=36872.37890625MB; mem (CPU total)=36672.2265625MB
INFO:root:[   25] Training loss: 0.66512936, Validation loss: 0.64805178, Gradient norm: 0.06806587
INFO:root:At the start of the epoch: mem (CPU python)=36910.47265625MB; mem (CPU total)=36710.44140625MB
INFO:root:[   26] Training loss: 0.66437846, Validation loss: 0.64704279, Gradient norm: 0.07962501
INFO:root:At the start of the epoch: mem (CPU python)=36961.0703125MB; mem (CPU total)=36760.79296875MB
INFO:root:[   27] Training loss: 0.66383740, Validation loss: 0.64777397, Gradient norm: 0.08725183
INFO:root:At the start of the epoch: mem (CPU python)=36999.16796875MB; mem (CPU total)=36798.68359375MB
INFO:root:[   28] Training loss: 0.66308935, Validation loss: 0.64606999, Gradient norm: 0.08411833
INFO:root:At the start of the epoch: mem (CPU python)=37037.26171875MB; mem (CPU total)=36836.83203125MB
INFO:root:[   29] Training loss: 0.66281247, Validation loss: 0.64655155, Gradient norm: 0.10534911
INFO:root:At the start of the epoch: mem (CPU python)=37075.35546875MB; mem (CPU total)=36874.9140625MB
INFO:root:[   30] Training loss: 0.66217113, Validation loss: 0.64725469, Gradient norm: 0.11565245
INFO:root:At the start of the epoch: mem (CPU python)=37113.453125MB; mem (CPU total)=36913.4609375MB
INFO:root:[   31] Training loss: 0.66198179, Validation loss: 0.64682305, Gradient norm: 0.11805884
INFO:root:At the start of the epoch: mem (CPU python)=37151.546875MB; mem (CPU total)=36951.30859375MB
INFO:root:[   32] Training loss: 0.66154798, Validation loss: 0.64605631, Gradient norm: 0.13571522
INFO:root:At the start of the epoch: mem (CPU python)=37189.640625MB; mem (CPU total)=36989.578125MB
INFO:root:[   33] Training loss: 0.66115740, Validation loss: 0.64623993, Gradient norm: 0.14998288
INFO:root:At the start of the epoch: mem (CPU python)=37227.73828125MB; mem (CPU total)=37027.41796875MB
INFO:root:[   34] Training loss: 0.66044774, Validation loss: 0.64763749, Gradient norm: 0.14800495
INFO:root:At the start of the epoch: mem (CPU python)=37265.83203125MB; mem (CPU total)=37065.80078125MB
INFO:root:[   35] Training loss: 0.66032271, Validation loss: 0.64710660, Gradient norm: 0.19496933
INFO:root:At the start of the epoch: mem (CPU python)=37303.9296875MB; mem (CPU total)=37103.9453125MB
INFO:root:[   36] Training loss: 0.65991177, Validation loss: 0.64840817, Gradient norm: 0.19186545
INFO:root:At the start of the epoch: mem (CPU python)=37342.0234375MB; mem (CPU total)=37141.74609375MB
INFO:root:[   37] Training loss: 0.65968569, Validation loss: 0.64926451, Gradient norm: 0.22647381
INFO:root:At the start of the epoch: mem (CPU python)=37380.12109375MB; mem (CPU total)=37180.1015625MB
INFO:root:[   38] Training loss: 0.65942463, Validation loss: 0.65123515, Gradient norm: 0.22365363
INFO:root:At the start of the epoch: mem (CPU python)=37418.21484375MB; mem (CPU total)=37218.21484375MB
INFO:root:[   39] Training loss: 0.65921297, Validation loss: 0.65175689, Gradient norm: 0.24206753
INFO:root:At the start of the epoch: mem (CPU python)=37456.30859375MB; mem (CPU total)=37256.3046875MB
INFO:root:[   40] Training loss: 0.65889868, Validation loss: 0.65006334, Gradient norm: 0.30232652
INFO:root:At the start of the epoch: mem (CPU python)=37494.40625MB; mem (CPU total)=37294.9375MB
INFO:root:[   41] Training loss: 0.65862487, Validation loss: 0.65420782, Gradient norm: 0.32741920
INFO:root:At the start of the epoch: mem (CPU python)=37532.5MB; mem (CPU total)=37332.8203125MB
INFO:root:[   42] Training loss: 0.65852860, Validation loss: 0.65241176, Gradient norm: 0.35665943
INFO:root:At the start of the epoch: mem (CPU python)=37570.59375MB; mem (CPU total)=37370.9140625MB
INFO:root:[   43] Training loss: 0.65813225, Validation loss: 0.65079710, Gradient norm: 0.34079069
INFO:root:At the start of the epoch: mem (CPU python)=37608.6953125MB; mem (CPU total)=37409.5MB
INFO:root:[   44] Training loss: 0.65806439, Validation loss: 0.64887844, Gradient norm: 0.38303737
INFO:root:At the start of the epoch: mem (CPU python)=37646.7890625MB; mem (CPU total)=37447.58984375MB
INFO:root:[   45] Training loss: 0.65766917, Validation loss: 0.65130250, Gradient norm: 0.38972945
INFO:root:At the start of the epoch: mem (CPU python)=37684.8828125MB; mem (CPU total)=37485.68359375MB
INFO:root:[   46] Training loss: 0.65782743, Validation loss: 0.65037356, Gradient norm: 0.43849257
INFO:root:At the start of the epoch: mem (CPU python)=37722.9765625MB; mem (CPU total)=37523.56640625MB
INFO:root:[   47] Training loss: 0.65764956, Validation loss: 0.65230616, Gradient norm: 0.49125403
INFO:root:At the start of the epoch: mem (CPU python)=37761.07421875MB; mem (CPU total)=37561.6875MB
INFO:root:[   48] Training loss: 0.65735027, Validation loss: 0.64520611, Gradient norm: 0.52520641
INFO:root:At the start of the epoch: mem (CPU python)=37799.16796875MB; mem (CPU total)=37600.1953125MB
INFO:root:[   49] Training loss: 0.65739080, Validation loss: 0.64390774, Gradient norm: 0.56849309
INFO:root:At the start of the epoch: mem (CPU python)=37837.26171875MB; mem (CPU total)=37638.15234375MB
INFO:root:[   50] Training loss: 0.65712265, Validation loss: 0.64447356, Gradient norm: 0.60563809
INFO:root:At the start of the epoch: mem (CPU python)=37875.359375MB; mem (CPU total)=37676.07421875MB
INFO:root:[   51] Training loss: 0.65693608, Validation loss: 0.64297344, Gradient norm: 0.67461351
INFO:root:At the start of the epoch: mem (CPU python)=37913.453125MB; mem (CPU total)=37714.48828125MB
INFO:root:[   52] Training loss: 0.65686212, Validation loss: 0.64101918, Gradient norm: 0.70401083
INFO:root:At the start of the epoch: mem (CPU python)=37951.546875MB; mem (CPU total)=37752.578125MB
INFO:root:[   53] Training loss: 0.65664171, Validation loss: 0.64111347, Gradient norm: 0.71385787
INFO:root:At the start of the epoch: mem (CPU python)=37989.64453125MB; mem (CPU total)=37790.41015625MB
INFO:root:[   54] Training loss: 0.65673464, Validation loss: 0.63959696, Gradient norm: 0.80492412
INFO:root:At the start of the epoch: mem (CPU python)=38027.7421875MB; mem (CPU total)=37828.77734375MB
INFO:root:[   55] Training loss: 0.65658852, Validation loss: 0.63852495, Gradient norm: 0.90091084
INFO:root:At the start of the epoch: mem (CPU python)=38065.8359375MB; mem (CPU total)=37867.15625MB
INFO:root:[   56] Training loss: 0.65630822, Validation loss: 0.63903210, Gradient norm: 0.83068362
INFO:root:At the start of the epoch: mem (CPU python)=38103.9296875MB; mem (CPU total)=37905.26953125MB
INFO:root:[   57] Training loss: 0.65640777, Validation loss: 0.63846217, Gradient norm: 0.87331355
INFO:root:At the start of the epoch: mem (CPU python)=38142.02734375MB; mem (CPU total)=37943.625MB
INFO:root:[   58] Training loss: 0.65692714, Validation loss: 0.63907051, Gradient norm: 1.17093659
INFO:root:At the start of the epoch: mem (CPU python)=38180.125MB; mem (CPU total)=37981.45703125MB
INFO:root:[   59] Training loss: 0.65681914, Validation loss: 0.63827183, Gradient norm: 1.03009411
INFO:root:At the start of the epoch: mem (CPU python)=38218.21875MB; mem (CPU total)=38019.578125MB
INFO:root:[   60] Training loss: 0.65678385, Validation loss: 0.63730757, Gradient norm: 1.39160038
INFO:root:At the start of the epoch: mem (CPU python)=38256.31640625MB; mem (CPU total)=38056.7265625MB
INFO:root:[   61] Training loss: 0.65674759, Validation loss: 0.63731317, Gradient norm: 1.08037144
INFO:root:At the start of the epoch: mem (CPU python)=38294.41015625MB; mem (CPU total)=38094.83984375MB
INFO:root:[   62] Training loss: 0.65628905, Validation loss: 0.63816733, Gradient norm: 1.31690326
INFO:root:At the start of the epoch: mem (CPU python)=38332.50390625MB; mem (CPU total)=38132.6796875MB
INFO:root:[   63] Training loss: 0.65666483, Validation loss: 0.63711172, Gradient norm: 1.47902128
INFO:root:At the start of the epoch: mem (CPU python)=38370.59765625MB; mem (CPU total)=38170.77734375MB
INFO:root:[   64] Training loss: 0.65667580, Validation loss: 0.63721296, Gradient norm: 1.47888933
INFO:root:At the start of the epoch: mem (CPU python)=38408.6953125MB; mem (CPU total)=38208.87890625MB
INFO:root:[   65] Training loss: 0.65658540, Validation loss: 0.63818063, Gradient norm: 1.72902395
INFO:root:At the start of the epoch: mem (CPU python)=38446.7890625MB; mem (CPU total)=38246.82421875MB
INFO:root:[   66] Training loss: 0.65640835, Validation loss: 0.63773406, Gradient norm: 1.50602942
INFO:root:At the start of the epoch: mem (CPU python)=38484.8828125MB; mem (CPU total)=38285.18359375MB
INFO:root:[   67] Training loss: 0.65658259, Validation loss: 0.63681948, Gradient norm: 1.96314287
INFO:root:At the start of the epoch: mem (CPU python)=38522.984375MB; mem (CPU total)=38323.25MB
INFO:root:[   68] Training loss: 0.65635733, Validation loss: 0.63694212, Gradient norm: 1.78713260
INFO:root:At the start of the epoch: mem (CPU python)=38561.078125MB; mem (CPU total)=38361.16015625MB
INFO:root:[   69] Training loss: 0.65656934, Validation loss: 0.63665204, Gradient norm: 1.74275862
INFO:root:At the start of the epoch: mem (CPU python)=38599.171875MB; mem (CPU total)=38399.3359375MB
INFO:root:[   70] Training loss: 0.65649998, Validation loss: 0.63579693, Gradient norm: 2.02766810
INFO:root:At the start of the epoch: mem (CPU python)=38637.265625MB; mem (CPU total)=38437.625MB
INFO:root:[   71] Training loss: 0.65661203, Validation loss: 0.63662640, Gradient norm: 1.93653120
INFO:root:At the start of the epoch: mem (CPU python)=38675.36328125MB; mem (CPU total)=38475.98046875MB
INFO:root:[   72] Training loss: 0.65630882, Validation loss: 0.63732943, Gradient norm: 2.18977354
INFO:root:At the start of the epoch: mem (CPU python)=38713.45703125MB; mem (CPU total)=38514.37890625MB
INFO:root:[   73] Training loss: 0.65637489, Validation loss: 0.63680476, Gradient norm: 2.29683224
INFO:root:At the start of the epoch: mem (CPU python)=38751.55078125MB; mem (CPU total)=38552.1796875MB
INFO:root:[   74] Training loss: 0.65619339, Validation loss: 0.63656196, Gradient norm: 2.37952905
INFO:root:At the start of the epoch: mem (CPU python)=38789.6484375MB; mem (CPU total)=38590.4453125MB
INFO:root:[   75] Training loss: 0.65634976, Validation loss: 0.63702313, Gradient norm: 2.48558753
INFO:root:At the start of the epoch: mem (CPU python)=38827.7421875MB; mem (CPU total)=38628.41796875MB
INFO:root:[   76] Training loss: 0.65610100, Validation loss: 0.63641370, Gradient norm: 2.52071680
INFO:root:At the start of the epoch: mem (CPU python)=38865.8359375MB; mem (CPU total)=38666.515625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   77] Training loss: 0.65641428, Validation loss: 0.63639251, Gradient norm: 2.21627541
INFO:root:At the start of the epoch: mem (CPU python)=38903.9375MB; mem (CPU total)=38704.60546875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   78] Training loss: 0.65526059, Validation loss: 0.63576744, Gradient norm: 1.62503226
INFO:root:At the start of the epoch: mem (CPU python)=38942.03125MB; mem (CPU total)=38743.42578125MB
INFO:root:[   79] Training loss: 0.65495258, Validation loss: 0.63538066, Gradient norm: 1.30695357
INFO:root:At the start of the epoch: mem (CPU python)=38980.125MB; mem (CPU total)=38781.51953125MB
INFO:root:[   80] Training loss: 0.65481958, Validation loss: 0.63607241, Gradient norm: 1.33027616
INFO:root:At the start of the epoch: mem (CPU python)=39018.21875MB; mem (CPU total)=38819.86328125MB
INFO:root:[   81] Training loss: 0.65474433, Validation loss: 0.63541161, Gradient norm: 1.40510733
INFO:root:At the start of the epoch: mem (CPU python)=39056.31640625MB; mem (CPU total)=38858.01171875MB
INFO:root:[   82] Training loss: 0.65476891, Validation loss: 0.63598345, Gradient norm: 1.49477140
INFO:root:At the start of the epoch: mem (CPU python)=39094.41015625MB; mem (CPU total)=38895.87890625MB
INFO:root:[   83] Training loss: 0.65467946, Validation loss: 0.63559310, Gradient norm: 1.68968877
INFO:root:At the start of the epoch: mem (CPU python)=39132.50390625MB; mem (CPU total)=38933.71484375MB
INFO:root:[   84] Training loss: 0.65486126, Validation loss: 0.63558439, Gradient norm: 1.64131888
INFO:root:At the start of the epoch: mem (CPU python)=39170.6015625MB; mem (CPU total)=38972.32421875MB
INFO:root:[   85] Training loss: 0.65468213, Validation loss: 0.63513926, Gradient norm: 1.68743467
INFO:root:At the start of the epoch: mem (CPU python)=39208.703125MB; mem (CPU total)=39010.48046875MB
INFO:root:[   86] Training loss: 0.65485139, Validation loss: 0.63493269, Gradient norm: 1.80507221
INFO:root:At the start of the epoch: mem (CPU python)=39246.796875MB; mem (CPU total)=39048.859375MB
INFO:root:[   87] Training loss: 0.65473946, Validation loss: 0.63601931, Gradient norm: 1.82938359
INFO:root:At the start of the epoch: mem (CPU python)=39284.890625MB; mem (CPU total)=39086.71875MB
INFO:root:[   88] Training loss: 0.65485116, Validation loss: 0.63511376, Gradient norm: 1.66153983
INFO:root:At the start of the epoch: mem (CPU python)=39322.984375MB; mem (CPU total)=39125.078125MB
INFO:root:[   89] Training loss: 0.65497840, Validation loss: 0.63581254, Gradient norm: 1.77608981
INFO:root:At the start of the epoch: mem (CPU python)=39361.08203125MB; mem (CPU total)=39162.93359375MB
INFO:root:[   90] Training loss: 0.65480493, Validation loss: 0.63538601, Gradient norm: 2.06316200
INFO:root:At the start of the epoch: mem (CPU python)=39399.17578125MB; mem (CPU total)=39200.953125MB
INFO:root:[   91] Training loss: 0.65463891, Validation loss: 0.63483363, Gradient norm: 1.98304240
INFO:root:At the start of the epoch: mem (CPU python)=39437.2734375MB; mem (CPU total)=39239.54296875MB
INFO:root:[   92] Training loss: 0.65455789, Validation loss: 0.63554873, Gradient norm: 2.00860552
INFO:root:At the start of the epoch: mem (CPU python)=39475.3671875MB; mem (CPU total)=39277.62109375MB
INFO:root:[   93] Training loss: 0.65466939, Validation loss: 0.63574158, Gradient norm: 1.87015733
INFO:root:At the start of the epoch: mem (CPU python)=39513.46484375MB; mem (CPU total)=39315.5MB
INFO:root:[   94] Training loss: 0.65473972, Validation loss: 0.63590498, Gradient norm: 2.13649213
INFO:root:At the start of the epoch: mem (CPU python)=39551.5625MB; mem (CPU total)=39353.89453125MB
INFO:root:[   95] Training loss: 0.65474146, Validation loss: 0.63515651, Gradient norm: 2.17011809
INFO:root:At the start of the epoch: mem (CPU python)=39589.65625MB; mem (CPU total)=39391.75MB
INFO:root:[   96] Training loss: 0.65480244, Validation loss: 0.63496989, Gradient norm: 2.15236731
INFO:root:At the start of the epoch: mem (CPU python)=39627.75MB; mem (CPU total)=39429.8671875MB
INFO:root:[   97] Training loss: 0.65488930, Validation loss: 0.63535548, Gradient norm: 2.11699297
INFO:root:At the start of the epoch: mem (CPU python)=39665.84375MB; mem (CPU total)=39467.98046875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   98] Training loss: 0.65467303, Validation loss: 0.63506046, Gradient norm: 2.20058779
INFO:root:At the start of the epoch: mem (CPU python)=39703.94140625MB; mem (CPU total)=39506.5546875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   99] Training loss: 0.65444718, Validation loss: 0.63541818, Gradient norm: 1.83744854
INFO:root:At the start of the epoch: mem (CPU python)=39742.03515625MB; mem (CPU total)=39544.140625MB
INFO:root:[  100] Training loss: 0.65403817, Validation loss: 0.63540743, Gradient norm: 1.60841899
INFO:root:At the start of the epoch: mem (CPU python)=39780.12890625MB; mem (CPU total)=39582.22265625MB
INFO:root:[  101] Training loss: 0.65422487, Validation loss: 0.63480332, Gradient norm: 1.52188430
INFO:root:At the start of the epoch: mem (CPU python)=39818.23046875MB; mem (CPU total)=39620.59375MB
INFO:root:[  102] Training loss: 0.65417074, Validation loss: 0.63521832, Gradient norm: 1.69225408
INFO:root:At the start of the epoch: mem (CPU python)=39856.328125MB; mem (CPU total)=39658.69140625MB
INFO:root:[  103] Training loss: 0.65435754, Validation loss: 0.63529002, Gradient norm: 1.59526327
INFO:root:At the start of the epoch: mem (CPU python)=39894.421875MB; mem (CPU total)=39696.77734375MB
INFO:root:[  104] Training loss: 0.65438666, Validation loss: 0.63553405, Gradient norm: 1.61083938
INFO:root:At the start of the epoch: mem (CPU python)=39932.515625MB; mem (CPU total)=39734.921875MB
INFO:root:[  105] Training loss: 0.65423185, Validation loss: 0.63513571, Gradient norm: 1.63567476
INFO:root:At the start of the epoch: mem (CPU python)=39970.61328125MB; mem (CPU total)=39772.94921875MB
INFO:root:[  106] Training loss: 0.65428385, Validation loss: 0.63526333, Gradient norm: 1.70331240
INFO:root:At the start of the epoch: mem (CPU python)=40008.70703125MB; mem (CPU total)=39811.45703125MB
INFO:root:[  107] Training loss: 0.65441312, Validation loss: 0.63466673, Gradient norm: 1.67409699
INFO:root:At the start of the epoch: mem (CPU python)=40046.80078125MB; mem (CPU total)=39849.8671875MB
INFO:root:[  108] Training loss: 0.65420277, Validation loss: 0.63494264, Gradient norm: 1.76102183
INFO:root:At the start of the epoch: mem (CPU python)=40084.8984375MB; mem (CPU total)=39887.72265625MB
INFO:root:[  109] Training loss: 0.65432902, Validation loss: 0.63503824, Gradient norm: 1.58510032
INFO:root:At the start of the epoch: mem (CPU python)=40124.4921875MB; mem (CPU total)=39927.53515625MB
INFO:root:[  110] Training loss: 0.65423387, Validation loss: 0.63525503, Gradient norm: 1.73934480
INFO:root:At the start of the epoch: mem (CPU python)=40162.58984375MB; mem (CPU total)=39965.6484375MB
INFO:root:[  111] Training loss: 0.65427599, Validation loss: 0.63487676, Gradient norm: 1.81715633
INFO:root:At the start of the epoch: mem (CPU python)=40200.6875MB; mem (CPU total)=40004.62890625MB
INFO:root:[  112] Training loss: 0.65416522, Validation loss: 0.63471361, Gradient norm: 1.78335659
INFO:root:At the start of the epoch: mem (CPU python)=40238.78125MB; mem (CPU total)=40042.5703125MB
INFO:root:[  113] Training loss: 0.65427149, Validation loss: 0.63572867, Gradient norm: 1.80471885
INFO:root:At the start of the epoch: mem (CPU python)=40276.875MB; mem (CPU total)=40080.40625MB
INFO:root:[  114] Training loss: 0.65429606, Validation loss: 0.63519551, Gradient norm: 1.74968893
INFO:root:At the start of the epoch: mem (CPU python)=40314.96875MB; mem (CPU total)=40118.484375MB
INFO:root:[  115] Training loss: 0.65423028, Validation loss: 0.63514278, Gradient norm: 1.86914415
INFO:root:At the start of the epoch: mem (CPU python)=40353.06640625MB; mem (CPU total)=40156.8125MB
INFO:root:[  116] Training loss: 0.65419902, Validation loss: 0.63539611, Gradient norm: 1.73675519
INFO:root:At the start of the epoch: mem (CPU python)=40391.16015625MB; mem (CPU total)=40195.40625MB
INFO:root:EP 116: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=40429.2578125MB; mem (CPU total)=40233.765625MB
INFO:root:Training the model took 9080.456s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.89897
INFO:root:EnergyScoreTrain: 0.63269
INFO:root:CRPSTrain: 0.53
INFO:root:Gaussian NLLTrain: 17651843356.44446
INFO:root:CoverageTrain: 0.65841
INFO:root:IntervalWidthTrain: 2.76135
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.90219
INFO:root:EnergyScoreValidation: 0.63498
INFO:root:CRPSValidation: 0.53268
INFO:root:Gaussian NLLValidation: 18138666898.77334
INFO:root:CoverageValidation: 0.65812
INFO:root:IntervalWidthValidation: 2.76231
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.90339
INFO:root:EnergyScoreTest: 0.63581
INFO:root:CRPSTest: 0.53372
INFO:root:Gaussian NLLTest: 18267914682.368
INFO:root:CoverageTest: 0.65808
INFO:root:IntervalWidthTest: 2.76356
INFO:root:After validation: mem (CPU python)=40472.28125MB; mem (CPU total)=40276.65625MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 10}
INFO:root:After creating the dataloaders: mem (CPU python)=40472.28125MB; mem (CPU total)=40276.5703125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=40472.64453125MB; mem (CPU total)=40276.5703125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=40472.64453125MB; mem (CPU total)=40276.7734375MB
INFO:root:[    1] Training loss: 0.72778416, Validation loss: 0.72133210, Gradient norm: 0.03124006
INFO:root:At the start of the epoch: mem (CPU python)=40510.7265625MB; mem (CPU total)=40314.953125MB
INFO:root:[    2] Training loss: 0.72060039, Validation loss: 0.71978834, Gradient norm: 0.00612538
INFO:root:At the start of the epoch: mem (CPU python)=40548.8203125MB; mem (CPU total)=40353.5546875MB
INFO:root:[    3] Training loss: 0.71906356, Validation loss: 0.71663401, Gradient norm: 0.00826946
INFO:root:At the start of the epoch: mem (CPU python)=40586.91796875MB; mem (CPU total)=40391.390625MB
INFO:root:[    4] Training loss: 0.71579381, Validation loss: 0.70943111, Gradient norm: 0.01668356
INFO:root:At the start of the epoch: mem (CPU python)=40625.01171875MB; mem (CPU total)=40429.97265625MB
INFO:root:[    5] Training loss: 0.71097168, Validation loss: 0.70372215, Gradient norm: 0.03033176
INFO:root:At the start of the epoch: mem (CPU python)=40663.109375MB; mem (CPU total)=40468.33203125MB
INFO:root:[    6] Training loss: 0.70648793, Validation loss: 0.69865396, Gradient norm: 0.03272529
INFO:root:At the start of the epoch: mem (CPU python)=40701.203125MB; mem (CPU total)=40506.8046875MB
INFO:root:[    7] Training loss: 0.70250945, Validation loss: 0.69375628, Gradient norm: 0.03867156
INFO:root:At the start of the epoch: mem (CPU python)=40739.296875MB; mem (CPU total)=40544.8828125MB
INFO:root:[    8] Training loss: 0.69903388, Validation loss: 0.68908596, Gradient norm: 0.04165703
INFO:root:At the start of the epoch: mem (CPU python)=40777.390625MB; mem (CPU total)=40582.69140625MB
INFO:root:[    9] Training loss: 0.69569863, Validation loss: 0.68476023, Gradient norm: 0.05001900
INFO:root:At the start of the epoch: mem (CPU python)=40815.484375MB; mem (CPU total)=40621.0703125MB
INFO:root:[   10] Training loss: 0.69295645, Validation loss: 0.68228740, Gradient norm: 0.05280805
INFO:root:At the start of the epoch: mem (CPU python)=40853.5859375MB; mem (CPU total)=40659.13671875MB
INFO:root:[   11] Training loss: 0.69040478, Validation loss: 0.67758680, Gradient norm: 0.06271420
INFO:root:At the start of the epoch: mem (CPU python)=40891.6796875MB; mem (CPU total)=40697.49609375MB
INFO:root:[   12] Training loss: 0.68830572, Validation loss: 0.67593876, Gradient norm: 0.05736185
INFO:root:At the start of the epoch: mem (CPU python)=40929.77734375MB; mem (CPU total)=40735.9609375MB
INFO:root:[   13] Training loss: 0.68628957, Validation loss: 0.67313470, Gradient norm: 0.07331930
INFO:root:At the start of the epoch: mem (CPU python)=40967.87109375MB; mem (CPU total)=40777.79296875MB
INFO:root:[   14] Training loss: 0.68458607, Validation loss: 0.67128778, Gradient norm: 0.09907988
INFO:root:At the start of the epoch: mem (CPU python)=41005.96484375MB; mem (CPU total)=40814.87109375MB
INFO:root:[   15] Training loss: 0.68302029, Validation loss: 0.67026814, Gradient norm: 0.11313434
INFO:root:At the start of the epoch: mem (CPU python)=41044.0625MB; mem (CPU total)=40852.98828125MB
INFO:root:[   16] Training loss: 0.68155687, Validation loss: 0.67245980, Gradient norm: 0.12561093
INFO:root:At the start of the epoch: mem (CPU python)=41082.15625MB; mem (CPU total)=40890.98828125MB
INFO:root:[   17] Training loss: 0.68025079, Validation loss: 0.66973480, Gradient norm: 0.15475520
INFO:root:At the start of the epoch: mem (CPU python)=41120.25MB; mem (CPU total)=40929.30859375MB
INFO:root:[   18] Training loss: 0.67905972, Validation loss: 0.67248929, Gradient norm: 0.15526456
INFO:root:At the start of the epoch: mem (CPU python)=41158.34375MB; mem (CPU total)=40967.07421875MB
INFO:root:[   19] Training loss: 0.67806404, Validation loss: 0.66763752, Gradient norm: 0.16250959
INFO:root:At the start of the epoch: mem (CPU python)=41196.4453125MB; mem (CPU total)=41005.44140625MB
INFO:root:[   20] Training loss: 0.67705145, Validation loss: 0.67519143, Gradient norm: 0.20707247
INFO:root:At the start of the epoch: mem (CPU python)=41234.5390625MB; mem (CPU total)=41043.74609375MB
INFO:root:[   21] Training loss: 0.67618100, Validation loss: 0.67518559, Gradient norm: 0.24293038
INFO:root:At the start of the epoch: mem (CPU python)=41272.6328125MB; mem (CPU total)=41081.3203125MB
INFO:root:[   22] Training loss: 0.67528866, Validation loss: 0.67940580, Gradient norm: 0.21605910
INFO:root:At the start of the epoch: mem (CPU python)=41310.73046875MB; mem (CPU total)=41119.77734375MB
INFO:root:[   23] Training loss: 0.67451903, Validation loss: 0.67350442, Gradient norm: 0.25249121
INFO:root:At the start of the epoch: mem (CPU python)=41348.828125MB; mem (CPU total)=41157.796875MB
INFO:root:[   24] Training loss: 0.67399098, Validation loss: 0.67792657, Gradient norm: 0.27301999
INFO:root:At the start of the epoch: mem (CPU python)=41386.921875MB; mem (CPU total)=41195.640625MB
INFO:root:[   25] Training loss: 0.67320114, Validation loss: 0.68273224, Gradient norm: 0.30892704
INFO:root:At the start of the epoch: mem (CPU python)=41425.015625MB; mem (CPU total)=41233.74609375MB
INFO:root:[   26] Training loss: 0.67258433, Validation loss: 0.68557431, Gradient norm: 0.34469286
INFO:root:At the start of the epoch: mem (CPU python)=41463.11328125MB; mem (CPU total)=41271.87109375MB
INFO:root:[   27] Training loss: 0.67189024, Validation loss: 0.68144526, Gradient norm: 0.31174490
INFO:root:At the start of the epoch: mem (CPU python)=41501.20703125MB; mem (CPU total)=41310.74609375MB
INFO:root:[   28] Training loss: 0.67121853, Validation loss: 0.68467454, Gradient norm: 0.36814363
INFO:root:At the start of the epoch: mem (CPU python)=41539.30078125MB; mem (CPU total)=41348.62890625MB
INFO:root:[   29] Training loss: 0.67065338, Validation loss: 0.68750820, Gradient norm: 0.33623977
INFO:root:At the start of the epoch: mem (CPU python)=41577.3984375MB; mem (CPU total)=41386.73046875MB
INFO:root:[   30] Training loss: 0.67054112, Validation loss: 0.69262506, Gradient norm: 0.44948723
INFO:root:At the start of the epoch: mem (CPU python)=41615.4921875MB; mem (CPU total)=41424.828125MB
INFO:root:[   31] Training loss: 0.66980120, Validation loss: 0.67274028, Gradient norm: 0.44482178
INFO:root:At the start of the epoch: mem (CPU python)=41653.5859375MB; mem (CPU total)=41462.91796875MB
INFO:root:[   32] Training loss: 0.66943173, Validation loss: 0.68822662, Gradient norm: 0.47355161
INFO:root:At the start of the epoch: mem (CPU python)=41691.6875MB; mem (CPU total)=41501.015625MB
INFO:root:[   33] Training loss: 0.66890332, Validation loss: 0.68616760, Gradient norm: 0.47433846
INFO:root:At the start of the epoch: mem (CPU python)=41729.78125MB; mem (CPU total)=41539.359375MB
INFO:root:[   34] Training loss: 0.66846436, Validation loss: 0.68472446, Gradient norm: 0.48313298
INFO:root:At the start of the epoch: mem (CPU python)=41767.875MB; mem (CPU total)=41577.4921875MB
INFO:root:[   35] Training loss: 0.66807979, Validation loss: 0.68969910, Gradient norm: 0.51248168
INFO:root:At the start of the epoch: mem (CPU python)=41805.96875MB; mem (CPU total)=41615.6015625MB
INFO:root:[   36] Training loss: 0.66769408, Validation loss: 0.66901016, Gradient norm: 0.67471371
INFO:root:At the start of the epoch: mem (CPU python)=41844.06640625MB; mem (CPU total)=41653.9609375MB
INFO:root:[   37] Training loss: 0.66712535, Validation loss: 0.68174562, Gradient norm: 0.65272980
INFO:root:At the start of the epoch: mem (CPU python)=41882.16015625MB; mem (CPU total)=41692.078125MB
INFO:root:[   38] Training loss: 0.66684836, Validation loss: 0.66836308, Gradient norm: 0.65840241
INFO:root:At the start of the epoch: mem (CPU python)=41920.25390625MB; mem (CPU total)=41730.4296875MB
INFO:root:[   39] Training loss: 0.66626937, Validation loss: 0.67588867, Gradient norm: 0.59402821
INFO:root:At the start of the epoch: mem (CPU python)=41958.3515625MB; mem (CPU total)=41768.76953125MB
INFO:root:[   40] Training loss: 0.66608920, Validation loss: 0.67561896, Gradient norm: 0.73500504
INFO:root:At the start of the epoch: mem (CPU python)=41996.44921875MB; mem (CPU total)=41807.140625MB
INFO:root:[   41] Training loss: 0.66579502, Validation loss: 0.67173949, Gradient norm: 0.76271764
INFO:root:At the start of the epoch: mem (CPU python)=42034.54296875MB; mem (CPU total)=41845.125MB
INFO:root:[   42] Training loss: 0.66556334, Validation loss: 0.67036074, Gradient norm: 0.91632851
INFO:root:At the start of the epoch: mem (CPU python)=42072.63671875MB; mem (CPU total)=41883.453125MB
INFO:root:[   43] Training loss: 0.66511613, Validation loss: 0.66880808, Gradient norm: 0.91754735
INFO:root:At the start of the epoch: mem (CPU python)=42110.734375MB; mem (CPU total)=41922.078125MB
INFO:root:[   44] Training loss: 0.66511278, Validation loss: 0.66037879, Gradient norm: 1.00892686
INFO:root:At the start of the epoch: mem (CPU python)=42148.828125MB; mem (CPU total)=41960.2109375MB
INFO:root:[   45] Training loss: 0.66474134, Validation loss: 0.66013201, Gradient norm: 1.02327711
INFO:root:At the start of the epoch: mem (CPU python)=42186.921875MB; mem (CPU total)=41998.41796875MB
INFO:root:[   46] Training loss: 0.66437778, Validation loss: 0.65739350, Gradient norm: 0.97614394
INFO:root:At the start of the epoch: mem (CPU python)=42225.01953125MB; mem (CPU total)=42036.60546875MB
INFO:root:[   47] Training loss: 0.66402519, Validation loss: 0.65425947, Gradient norm: 1.01179052
INFO:root:At the start of the epoch: mem (CPU python)=42263.11328125MB; mem (CPU total)=42074.94921875MB
INFO:root:[   48] Training loss: 0.66410282, Validation loss: 0.65075154, Gradient norm: 1.40200106
INFO:root:At the start of the epoch: mem (CPU python)=42301.20703125MB; mem (CPU total)=42113.3203125MB
INFO:root:[   49] Training loss: 0.66350137, Validation loss: 0.65321419, Gradient norm: 1.12180978
INFO:root:At the start of the epoch: mem (CPU python)=42339.3046875MB; mem (CPU total)=42151.1953125MB
INFO:root:[   50] Training loss: 0.66355213, Validation loss: 0.65007427, Gradient norm: 1.29998909
INFO:root:At the start of the epoch: mem (CPU python)=42377.40234375MB; mem (CPU total)=42189.28125MB
INFO:root:[   51] Training loss: 0.66314949, Validation loss: 0.64670400, Gradient norm: 1.43361652
INFO:root:At the start of the epoch: mem (CPU python)=42415.49609375MB; mem (CPU total)=42227.578125MB
INFO:root:[   52] Training loss: 0.66295851, Validation loss: 0.64552219, Gradient norm: 1.47577645
INFO:root:At the start of the epoch: mem (CPU python)=42453.58984375MB; mem (CPU total)=42265.43359375MB
INFO:root:[   53] Training loss: 0.66288875, Validation loss: 0.64538373, Gradient norm: 1.56543820
INFO:root:At the start of the epoch: mem (CPU python)=42491.6875MB; mem (CPU total)=42303.80859375MB
INFO:root:[   54] Training loss: 0.66273225, Validation loss: 0.64664373, Gradient norm: 1.62096135
INFO:root:At the start of the epoch: mem (CPU python)=42529.78125MB; mem (CPU total)=42341.17578125MB
INFO:root:[   55] Training loss: 0.66266307, Validation loss: 0.64357382, Gradient norm: 1.79509782
INFO:root:At the start of the epoch: mem (CPU python)=42567.875MB; mem (CPU total)=42379.48046875MB
INFO:root:[   56] Training loss: 0.66237760, Validation loss: 0.64345668, Gradient norm: 1.72610786
INFO:root:At the start of the epoch: mem (CPU python)=42605.97265625MB; mem (CPU total)=42422.28125MB
INFO:root:[   57] Training loss: 0.66239684, Validation loss: 0.64435318, Gradient norm: 1.57172079
INFO:root:At the start of the epoch: mem (CPU python)=42644.06640625MB; mem (CPU total)=42459.48046875MB
INFO:root:[   58] Training loss: 0.66210683, Validation loss: 0.64432807, Gradient norm: 1.74590729
INFO:root:At the start of the epoch: mem (CPU python)=42682.16015625MB; mem (CPU total)=42497.2421875MB
INFO:root:[   59] Training loss: 0.66217954, Validation loss: 0.64384689, Gradient norm: 2.03534506
INFO:root:At the start of the epoch: mem (CPU python)=42720.2578125MB; mem (CPU total)=42535.32421875MB
INFO:root:[   60] Training loss: 0.66199749, Validation loss: 0.64500585, Gradient norm: 2.13950269
INFO:root:At the start of the epoch: mem (CPU python)=42758.35546875MB; mem (CPU total)=42573.41796875MB
INFO:root:[   61] Training loss: 0.66193804, Validation loss: 0.64470198, Gradient norm: 2.00971400
INFO:root:At the start of the epoch: mem (CPU python)=42796.44921875MB; mem (CPU total)=42611.5078125MB
INFO:root:[   62] Training loss: 0.66185585, Validation loss: 0.64257968, Gradient norm: 2.28313077
INFO:root:At the start of the epoch: mem (CPU python)=42834.54296875MB; mem (CPU total)=42649.40625MB
INFO:root:[   63] Training loss: 0.66175278, Validation loss: 0.64231469, Gradient norm: 2.41072243
INFO:root:At the start of the epoch: mem (CPU python)=42872.640625MB; mem (CPU total)=42686.9453125MB
INFO:root:[   64] Training loss: 0.66171165, Validation loss: 0.64359871, Gradient norm: 2.26345762
INFO:root:At the start of the epoch: mem (CPU python)=42910.73828125MB; mem (CPU total)=42724.5234375MB
INFO:root:[   65] Training loss: 0.66152978, Validation loss: 0.64291932, Gradient norm: 2.29490963
INFO:root:At the start of the epoch: mem (CPU python)=42948.83203125MB; mem (CPU total)=42762.9765625MB
INFO:root:[   66] Training loss: 0.66179136, Validation loss: 0.64328239, Gradient norm: 2.59531876
INFO:root:At the start of the epoch: mem (CPU python)=42986.92578125MB; mem (CPU total)=42801.078125MB
INFO:root:[   67] Training loss: 0.66153198, Validation loss: 0.64231543, Gradient norm: 2.49147548
INFO:root:At the start of the epoch: mem (CPU python)=43025.0234375MB; mem (CPU total)=42839.17578125MB
INFO:root:[   68] Training loss: 0.66160314, Validation loss: 0.64312595, Gradient norm: 2.73939994
INFO:root:At the start of the epoch: mem (CPU python)=43063.1171875MB; mem (CPU total)=42877.5390625MB
INFO:root:[   69] Training loss: 0.66182426, Validation loss: 0.64268765, Gradient norm: 2.71589112
INFO:root:At the start of the epoch: mem (CPU python)=43101.2109375MB; mem (CPU total)=42915.6953125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   70] Training loss: 0.66156941, Validation loss: 0.64212335, Gradient norm: 2.90101690
INFO:root:At the start of the epoch: mem (CPU python)=43139.30859375MB; mem (CPU total)=42953.3828125MB
INFO:root:[   71] Training loss: 0.66037434, Validation loss: 0.64091407, Gradient norm: 1.81498480
INFO:root:At the start of the epoch: mem (CPU python)=43177.40234375MB; mem (CPU total)=42990.91015625MB
INFO:root:[   72] Training loss: 0.66038371, Validation loss: 0.64219358, Gradient norm: 1.85947351
INFO:root:At the start of the epoch: mem (CPU python)=43215.49609375MB; mem (CPU total)=43029.0MB
INFO:root:[   73] Training loss: 0.66028493, Validation loss: 0.64186816, Gradient norm: 2.03552394
INFO:root:At the start of the epoch: mem (CPU python)=43253.59375MB; mem (CPU total)=43066.875MB
INFO:root:[   74] Training loss: 0.66034907, Validation loss: 0.64177756, Gradient norm: 2.12299358
INFO:root:At the start of the epoch: mem (CPU python)=43291.69140625MB; mem (CPU total)=43104.94140625MB
INFO:root:[   75] Training loss: 0.66024827, Validation loss: 0.64132837, Gradient norm: 2.21754747
INFO:root:At the start of the epoch: mem (CPU python)=43329.78515625MB; mem (CPU total)=43143.03515625MB
INFO:root:[   76] Training loss: 0.66014299, Validation loss: 0.64158261, Gradient norm: 2.33583774
INFO:root:At the start of the epoch: mem (CPU python)=43367.87890625MB; mem (CPU total)=43181.73046875MB
INFO:root:[   77] Training loss: 0.66003341, Validation loss: 0.64074376, Gradient norm: 2.23714749
INFO:root:At the start of the epoch: mem (CPU python)=43405.9765625MB; mem (CPU total)=43220.12890625MB
INFO:root:[   78] Training loss: 0.66008438, Validation loss: 0.64166432, Gradient norm: 2.45908423
INFO:root:At the start of the epoch: mem (CPU python)=43444.0703125MB; mem (CPU total)=43257.76171875MB
INFO:root:[   79] Training loss: 0.66007576, Validation loss: 0.64194610, Gradient norm: 2.69112598
INFO:root:At the start of the epoch: mem (CPU python)=43482.1640625MB; mem (CPU total)=43295.90625MB
INFO:root:[   80] Training loss: 0.65990523, Validation loss: 0.64109913, Gradient norm: 2.48338584
INFO:root:At the start of the epoch: mem (CPU python)=43520.26171875MB; mem (CPU total)=43334.3125MB
INFO:root:[   81] Training loss: 0.65995264, Validation loss: 0.64188707, Gradient norm: 2.81184891
INFO:root:At the start of the epoch: mem (CPU python)=43558.35546875MB; mem (CPU total)=43372.47265625MB
INFO:root:[   82] Training loss: 0.65986791, Validation loss: 0.64189146, Gradient norm: 2.89513659
INFO:root:At the start of the epoch: mem (CPU python)=43596.453125MB; mem (CPU total)=43410.81640625MB
INFO:root:[   83] Training loss: 0.66011392, Validation loss: 0.64093423, Gradient norm: 2.99575132
INFO:root:At the start of the epoch: mem (CPU python)=43634.55078125MB; mem (CPU total)=43449.63671875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   84] Training loss: 0.65978700, Validation loss: 0.64103480, Gradient norm: 2.90873585
INFO:root:At the start of the epoch: mem (CPU python)=43672.64453125MB; mem (CPU total)=43487.37109375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   85] Training loss: 0.65927662, Validation loss: 0.64020221, Gradient norm: 2.01705510
INFO:root:At the start of the epoch: mem (CPU python)=43710.73828125MB; mem (CPU total)=43525.796875MB
INFO:root:[   86] Training loss: 0.65906850, Validation loss: 0.64022421, Gradient norm: 1.72439041
INFO:root:At the start of the epoch: mem (CPU python)=43748.83203125MB; mem (CPU total)=43563.484375MB
INFO:root:[   87] Training loss: 0.65912256, Validation loss: 0.64063317, Gradient norm: 1.80143798
INFO:root:At the start of the epoch: mem (CPU python)=43786.9296875MB; mem (CPU total)=43601.37890625MB
INFO:root:[   88] Training loss: 0.65900939, Validation loss: 0.64095369, Gradient norm: 1.77646759
INFO:root:At the start of the epoch: mem (CPU python)=43825.0234375MB; mem (CPU total)=43640.16015625MB
INFO:root:[   89] Training loss: 0.65891678, Validation loss: 0.64029398, Gradient norm: 2.08620692
INFO:root:At the start of the epoch: mem (CPU python)=43863.1171875MB; mem (CPU total)=43677.89453125MB
INFO:root:[   90] Training loss: 0.65894766, Validation loss: 0.64037736, Gradient norm: 1.88392673
INFO:root:At the start of the epoch: mem (CPU python)=43901.21484375MB; mem (CPU total)=43715.59375MB
INFO:root:[   91] Training loss: 0.65916291, Validation loss: 0.64062585, Gradient norm: 2.14803550
INFO:root:At the start of the epoch: mem (CPU python)=43939.3125MB; mem (CPU total)=43753.48828125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   92] Training loss: 0.65897663, Validation loss: 0.64070571, Gradient norm: 2.09359179
INFO:root:At the start of the epoch: mem (CPU python)=43977.40625MB; mem (CPU total)=43791.6328125MB
INFO:root:[   93] Training loss: 0.65876335, Validation loss: 0.64076466, Gradient norm: 1.70479330
INFO:root:At the start of the epoch: mem (CPU python)=44015.5MB; mem (CPU total)=43829.5546875MB
INFO:root:[   94] Training loss: 0.65879669, Validation loss: 0.64032472, Gradient norm: 1.78811093
INFO:root:At the start of the epoch: mem (CPU python)=44053.59765625MB; mem (CPU total)=43867.875MB
INFO:root:EP 94: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=44091.69140625MB; mem (CPU total)=43906.01171875MB
INFO:root:Training the model took 7995.187s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.90762
INFO:root:EnergyScoreTrain: 0.63894
INFO:root:CRPSTrain: 0.5581
INFO:root:Gaussian NLLTrain: 46562095586.41778
INFO:root:CoverageTrain: 0.59119
INFO:root:IntervalWidthTrain: 2.58039
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.90958
INFO:root:EnergyScoreValidation: 0.64035
INFO:root:CRPSValidation: 0.56
INFO:root:Gaussian NLLValidation: 47353765869.79555
INFO:root:CoverageValidation: 0.59069
INFO:root:IntervalWidthValidation: 2.57859
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.91163
INFO:root:EnergyScoreTest: 0.64181
INFO:root:CRPSTest: 0.56191
INFO:root:Gaussian NLLTest: 48023122083.84
INFO:root:CoverageTest: 0.59192
INFO:root:IntervalWidthTest: 2.58471
INFO:root:After validation: mem (CPU python)=44191.15625MB; mem (CPU total)=44006.3984375MB
