INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=577.8203125MB; mem (CPU total)=992.82421875MB
INFO:root:############### Starting experiment with config file ks/fno_sr_dropout_n_samples3.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12456.83984375MB; mem (CPU total)=1003.546875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=12456.83984375MB; mem (CPU total)=1003.546875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12456.83984375MB; mem (CPU total)=2374.6171875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=2385.4765625MB
INFO:root:[    1] Training loss: 0.72547368, Validation loss: 0.72091404, Gradient norm: 0.01826455
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4192.44140625MB
INFO:root:[    2] Training loss: 0.72041523, Validation loss: 0.71954042, Gradient norm: 0.00542519
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4230.6484375MB
INFO:root:[    3] Training loss: 0.71908304, Validation loss: 0.71725839, Gradient norm: 0.00753844
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4367.01953125MB
INFO:root:[    4] Training loss: 0.71593778, Validation loss: 0.70972060, Gradient norm: 0.01675216
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4355.30078125MB
INFO:root:[    5] Training loss: 0.71094260, Validation loss: 0.70442750, Gradient norm: 0.02750545
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4393.34765625MB
INFO:root:[    6] Training loss: 0.70715205, Validation loss: 0.69884196, Gradient norm: 0.03711255
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4384.27734375MB
INFO:root:[    7] Training loss: 0.70380048, Validation loss: 0.69557426, Gradient norm: 0.04268545
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4348.9375MB
INFO:root:[    8] Training loss: 0.70112422, Validation loss: 0.69260342, Gradient norm: 0.04754278
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4437.0625MB
INFO:root:[    9] Training loss: 0.69870543, Validation loss: 0.68972420, Gradient norm: 0.05588013
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4496.88671875MB
INFO:root:[   10] Training loss: 0.69661917, Validation loss: 0.68750667, Gradient norm: 0.06466781
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4634.15234375MB
INFO:root:[   11] Training loss: 0.69477341, Validation loss: 0.68519477, Gradient norm: 0.06853546
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4536.42578125MB
INFO:root:[   12] Training loss: 0.69314247, Validation loss: 0.68305047, Gradient norm: 0.08723735
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4710.6796875MB
INFO:root:[   13] Training loss: 0.69181993, Validation loss: 0.68105024, Gradient norm: 0.09099721
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4749.26953125MB
INFO:root:[   14] Training loss: 0.69047616, Validation loss: 0.68066624, Gradient norm: 0.11089531
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4763.57421875MB
INFO:root:[   15] Training loss: 0.68950620, Validation loss: 0.68086705, Gradient norm: 0.12891596
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4690.95703125MB
INFO:root:[   16] Training loss: 0.68862528, Validation loss: 0.68103421, Gradient norm: 0.13852285
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4702.9453125MB
INFO:root:[   17] Training loss: 0.68756944, Validation loss: 0.68053276, Gradient norm: 0.15710423
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4851.65234375MB
INFO:root:[   18] Training loss: 0.68688006, Validation loss: 0.68524327, Gradient norm: 0.19065422
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4941.55859375MB
INFO:root:[   19] Training loss: 0.68615752, Validation loss: 0.68735193, Gradient norm: 0.21225630
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=4856.05859375MB
INFO:root:[   20] Training loss: 0.68557415, Validation loss: 0.68600068, Gradient norm: 0.26255822
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5016.39453125MB
INFO:root:[   21] Training loss: 0.68470347, Validation loss: 0.68747383, Gradient norm: 0.26413904
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5029.0859375MB
INFO:root:[   22] Training loss: 0.68388535, Validation loss: 0.69090559, Gradient norm: 0.28613464
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5017.41796875MB
INFO:root:[   23] Training loss: 0.68309336, Validation loss: 0.69335032, Gradient norm: 0.30469419
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5080.3828125MB
INFO:root:[   24] Training loss: 0.68271134, Validation loss: 0.69543609, Gradient norm: 0.37044639
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5094.98828125MB
INFO:root:[   25] Training loss: 0.68187953, Validation loss: 0.68265527, Gradient norm: 0.41148300
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5059.21875MB
INFO:root:[   26] Training loss: 0.68112448, Validation loss: 0.69257076, Gradient norm: 0.41075776
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5144.7109375MB
INFO:root:[   27] Training loss: 0.68038966, Validation loss: 0.68778107, Gradient norm: 0.48887801
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5258.046875MB
INFO:root:[   28] Training loss: 0.67989674, Validation loss: 0.68709505, Gradient norm: 0.47126254
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5295.9140625MB
INFO:root:[   29] Training loss: 0.67950957, Validation loss: 0.68312010, Gradient norm: 0.57321841
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5285.578125MB
INFO:root:[   30] Training loss: 0.67899292, Validation loss: 0.69340642, Gradient norm: 0.65006034
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5398.8828125MB
INFO:root:[   31] Training loss: 0.67850385, Validation loss: 0.69306606, Gradient norm: 0.65435042
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5386.63671875MB
INFO:root:[   32] Training loss: 0.67815750, Validation loss: 0.68940702, Gradient norm: 0.73964345
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5400.40625MB
INFO:root:[   33] Training loss: 0.67750410, Validation loss: 0.68554008, Gradient norm: 0.71070573
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5489.3203125MB
INFO:root:[   34] Training loss: 0.67708471, Validation loss: 0.68202937, Gradient norm: 0.79587676
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5551.28515625MB
INFO:root:[   35] Training loss: 0.67685962, Validation loss: 0.68563388, Gradient norm: 0.98039894
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5440.32421875MB
INFO:root:[   36] Training loss: 0.67658393, Validation loss: 0.68840522, Gradient norm: 1.02785938
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5467.32421875MB
INFO:root:[   37] Training loss: 0.67648331, Validation loss: 0.67542567, Gradient norm: 1.21204368
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5517.078125MB
INFO:root:[   38] Training loss: 0.67588900, Validation loss: 0.66839007, Gradient norm: 1.29109512
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5668.07421875MB
INFO:root:[   39] Training loss: 0.67578329, Validation loss: 0.66669859, Gradient norm: 1.32045307
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5690.796875MB
INFO:root:[   40] Training loss: 0.67543675, Validation loss: 0.66320866, Gradient norm: 1.34143429
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5679.87890625MB
INFO:root:[   41] Training loss: 0.67505414, Validation loss: 0.66405923, Gradient norm: 1.44513146
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5792.47265625MB
INFO:root:[   42] Training loss: 0.67485848, Validation loss: 0.66353839, Gradient norm: 1.63666649
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5731.1328125MB
INFO:root:[   43] Training loss: 0.67471976, Validation loss: 0.65899494, Gradient norm: 1.77449427
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5732.3125MB
INFO:root:[   44] Training loss: 0.67486350, Validation loss: 0.65907435, Gradient norm: 1.79631077
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5856.76953125MB
INFO:root:[   45] Training loss: 0.67443946, Validation loss: 0.65810411, Gradient norm: 1.84228967
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5921.62109375MB
INFO:root:[   46] Training loss: 0.67435782, Validation loss: 0.65932202, Gradient norm: 1.94968094
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6009.66796875MB
INFO:root:[   47] Training loss: 0.67419878, Validation loss: 0.65612032, Gradient norm: 2.00889840
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=5923.73046875MB
INFO:root:[   48] Training loss: 0.67407441, Validation loss: 0.65758859, Gradient norm: 2.33992925
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6034.7578125MB
INFO:root:[   49] Training loss: 0.67393745, Validation loss: 0.65649018, Gradient norm: 2.35622716
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6147.82421875MB
INFO:root:[   50] Training loss: 0.67394170, Validation loss: 0.65606956, Gradient norm: 2.59561657
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6136.06640625MB
INFO:root:[   51] Training loss: 0.67385715, Validation loss: 0.65618789, Gradient norm: 2.35464060
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6099.05859375MB
INFO:root:[   52] Training loss: 0.67400341, Validation loss: 0.65835968, Gradient norm: 2.64781990
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6140.203125MB
INFO:root:[   53] Training loss: 0.67394387, Validation loss: 0.65541582, Gradient norm: 2.90041566
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6177.046875MB
INFO:root:[   54] Training loss: 0.67400078, Validation loss: 0.65708517, Gradient norm: 2.72152808
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6240.1875MB
INFO:root:[   55] Training loss: 0.67387741, Validation loss: 0.65516661, Gradient norm: 2.94594290
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6278.8359375MB
INFO:root:[   56] Training loss: 0.67386805, Validation loss: 0.65647133, Gradient norm: 3.20043109
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6292.73046875MB
INFO:root:[   57] Training loss: 0.67403108, Validation loss: 0.65669291, Gradient norm: 3.51735102
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6318.20703125MB
INFO:root:[   58] Training loss: 0.67376262, Validation loss: 0.65642247, Gradient norm: 3.35538782
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6357.35546875MB
INFO:root:[   59] Training loss: 0.67385639, Validation loss: 0.65882962, Gradient norm: 3.42436996
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6478.6640625MB
INFO:root:[   60] Training loss: 0.67383960, Validation loss: 0.65493061, Gradient norm: 3.62051655
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6541.75MB
INFO:root:[   61] Training loss: 0.67367402, Validation loss: 0.65505389, Gradient norm: 3.51119424
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6505.234375MB
INFO:root:[   62] Training loss: 0.67384677, Validation loss: 0.65619173, Gradient norm: 3.78816841
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6543.12890625MB
INFO:root:[   63] Training loss: 0.67332734, Validation loss: 0.65714378, Gradient norm: 3.42328002
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6532.5546875MB
INFO:root:[   64] Training loss: 0.67374765, Validation loss: 0.65678272, Gradient norm: 4.20338340
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6644.83984375MB
INFO:root:[   65] Training loss: 0.67355928, Validation loss: 0.65500775, Gradient norm: 3.80527864
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6657.77734375MB
INFO:root:[   66] Training loss: 0.67340132, Validation loss: 0.65742485, Gradient norm: 3.69457830
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6720.75MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   67] Training loss: 0.67404973, Validation loss: 0.65375646, Gradient norm: 4.39072879
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6709.42578125MB
INFO:root:[   68] Training loss: 0.67217588, Validation loss: 0.65476043, Gradient norm: 3.00443638
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6735.60546875MB
INFO:root:[   69] Training loss: 0.67211864, Validation loss: 0.65402571, Gradient norm: 3.56426898
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6799.07421875MB
INFO:root:[   70] Training loss: 0.67202393, Validation loss: 0.65500219, Gradient norm: 3.28040851
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6899.765625MB
INFO:root:[   71] Training loss: 0.67207560, Validation loss: 0.65334163, Gradient norm: 4.03027914
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6988.39453125MB
INFO:root:[   72] Training loss: 0.67195672, Validation loss: 0.65421812, Gradient norm: 3.63673386
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=6903.52734375MB
INFO:root:[   73] Training loss: 0.67192919, Validation loss: 0.65432901, Gradient norm: 4.37766236
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7042.16015625MB
INFO:root:[   74] Training loss: 0.67177861, Validation loss: 0.65440970, Gradient norm: 4.57844650
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7030.91796875MB
INFO:root:[   75] Training loss: 0.67180342, Validation loss: 0.65448801, Gradient norm: 4.32128495
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7020.13671875MB
INFO:root:[   76] Training loss: 0.67203766, Validation loss: 0.65408360, Gradient norm: 4.94349477
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7082.02734375MB
INFO:root:[   77] Training loss: 0.67185133, Validation loss: 0.65389728, Gradient norm: 4.91138065
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7123.078125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   78] Training loss: 0.67209681, Validation loss: 0.65540092, Gradient norm: 4.94951632
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7158.14453125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   79] Training loss: 0.67115166, Validation loss: 0.65279510, Gradient norm: 3.65438504
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7245.93359375MB
INFO:root:[   80] Training loss: 0.67078549, Validation loss: 0.65280456, Gradient norm: 2.96877432
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7284.31640625MB
INFO:root:[   81] Training loss: 0.67057923, Validation loss: 0.65262609, Gradient norm: 3.19743528
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7222.578125MB
INFO:root:[   82] Training loss: 0.67078804, Validation loss: 0.65251851, Gradient norm: 3.19316382
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7308.671875MB
INFO:root:[   83] Training loss: 0.67070231, Validation loss: 0.65250891, Gradient norm: 3.66038629
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7420.95703125MB
INFO:root:[   84] Training loss: 0.67062719, Validation loss: 0.65266501, Gradient norm: 3.81415119
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7434.1875MB
INFO:root:[   85] Training loss: 0.67065052, Validation loss: 0.65325412, Gradient norm: 4.02248325
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7398.890625MB
INFO:root:[   86] Training loss: 0.67060221, Validation loss: 0.65276374, Gradient norm: 3.80854973
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7512.17578125MB
INFO:root:[   87] Training loss: 0.67058411, Validation loss: 0.65340119, Gradient norm: 4.09392175
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7575.71875MB
INFO:root:[   88] Training loss: 0.67081526, Validation loss: 0.65324979, Gradient norm: 4.21266727
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7539.22265625MB
INFO:root:[   89] Training loss: 0.67062128, Validation loss: 0.65280971, Gradient norm: 4.04250654
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7523.90234375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   90] Training loss: 0.67072568, Validation loss: 0.65301247, Gradient norm: 4.23142760
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7563.23828125MB
INFO:root:[   91] Training loss: 0.67050694, Validation loss: 0.65209193, Gradient norm: 3.58514800
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7650.5MB
INFO:root:[   92] Training loss: 0.67035653, Validation loss: 0.65299025, Gradient norm: 3.49532114
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7714.31640625MB
INFO:root:[   93] Training loss: 0.67037159, Validation loss: 0.65255316, Gradient norm: 3.67447924
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7778.171875MB
INFO:root:[   94] Training loss: 0.67048066, Validation loss: 0.65242701, Gradient norm: 3.80595848
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7791.296875MB
INFO:root:[   95] Training loss: 0.67048087, Validation loss: 0.65215576, Gradient norm: 4.10136026
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7843.3984375MB
INFO:root:[   96] Training loss: 0.67030400, Validation loss: 0.65285119, Gradient norm: 3.88502476
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7817.87109375MB
INFO:root:[   97] Training loss: 0.67037345, Validation loss: 0.65282332, Gradient norm: 4.13106901
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7807.515625MB
INFO:root:[   98] Training loss: 0.67050778, Validation loss: 0.65283132, Gradient norm: 4.11880017
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7969.04296875MB
INFO:root:[   99] Training loss: 0.67054042, Validation loss: 0.65262403, Gradient norm: 4.03617261
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7957.21875MB
INFO:root:[  100] Training loss: 0.67027274, Validation loss: 0.65304091, Gradient norm: 3.94712048
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8006.56640625MB
INFO:root:EP 100: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12456.83984375MB; mem (CPU total)=7959.734375MB
INFO:root:Training the model took 4168.721s.
INFO:root:Emptying the cuda cache took 0.025s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92565
INFO:root:EnergyScoreTrain: 0.65154
INFO:root:CRPSTrain: 0.58328
INFO:root:Gaussian NLLTrain: 90324931360.99554
INFO:root:CoverageTrain: 0.581
INFO:root:IntervalWidthTrain: 2.63268
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.92708
INFO:root:EnergyScoreValidation: 0.65257
INFO:root:CRPSValidation: 0.58472
INFO:root:Gaussian NLLValidation: 91480991916.94218
INFO:root:CoverageValidation: 0.58082
INFO:root:IntervalWidthValidation: 2.63161
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.92869
INFO:root:EnergyScoreTest: 0.6537
INFO:root:CRPSTest: 0.58618
INFO:root:Gaussian NLLTest: 92467940491.26396
INFO:root:CoverageTest: 0.5816
INFO:root:IntervalWidthTest: 2.63459
INFO:root:After validation: mem (CPU python)=12456.83984375MB; mem (CPU total)=8047.546875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=12456.83984375MB; mem (CPU total)=7969.62890625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12456.83984375MB; mem (CPU total)=7973.84765625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=7974.09375MB
INFO:root:[    1] Training loss: 0.72577381, Validation loss: 0.72095243, Gradient norm: 0.02264791
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8062.4921875MB
INFO:root:[    2] Training loss: 0.72049383, Validation loss: 0.71862800, Gradient norm: 0.00633994
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8049.6875MB
INFO:root:[    3] Training loss: 0.71907319, Validation loss: 0.71731398, Gradient norm: 0.00856988
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8137.515625MB
INFO:root:[    4] Training loss: 0.71574592, Validation loss: 0.70999365, Gradient norm: 0.01655450
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8200.41015625MB
INFO:root:[    5] Training loss: 0.70997686, Validation loss: 0.70267739, Gradient norm: 0.02745475
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8263.484375MB
INFO:root:[    6] Training loss: 0.70517067, Validation loss: 0.69716614, Gradient norm: 0.03728053
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8301.60546875MB
INFO:root:[    7] Training loss: 0.70155176, Validation loss: 0.69285421, Gradient norm: 0.04366016
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8289.73046875MB
INFO:root:[    8] Training loss: 0.69878928, Validation loss: 0.68962563, Gradient norm: 0.05443572
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8327.6328125MB
INFO:root:[    9] Training loss: 0.69639755, Validation loss: 0.68725517, Gradient norm: 0.05868090
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8355.01171875MB
INFO:root:[   10] Training loss: 0.69460065, Validation loss: 0.68415498, Gradient norm: 0.07417088
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8428.58984375MB
INFO:root:[   11] Training loss: 0.69282180, Validation loss: 0.68388057, Gradient norm: 0.08129806
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8442.4609375MB
INFO:root:[   12] Training loss: 0.69136096, Validation loss: 0.68158537, Gradient norm: 0.11126474
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8430.6640625MB
INFO:root:[   13] Training loss: 0.69003022, Validation loss: 0.68231872, Gradient norm: 0.13683629
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8543.4609375MB
INFO:root:[   14] Training loss: 0.68903228, Validation loss: 0.68272088, Gradient norm: 0.14293277
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8556.4296875MB
INFO:root:[   15] Training loss: 0.68789841, Validation loss: 0.68835752, Gradient norm: 0.17834630
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8594.58203125MB
INFO:root:[   16] Training loss: 0.68715689, Validation loss: 0.69112706, Gradient norm: 0.23706336
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8633.89453125MB
INFO:root:[   17] Training loss: 0.68608836, Validation loss: 0.69327096, Gradient norm: 0.27851191
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8622.0390625MB
INFO:root:[   18] Training loss: 0.68514131, Validation loss: 0.69557609, Gradient norm: 0.24074582
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8660.17578125MB
INFO:root:[   19] Training loss: 0.68429378, Validation loss: 0.70520700, Gradient norm: 0.28502115
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8772.20703125MB
INFO:root:[   20] Training loss: 0.68374681, Validation loss: 0.70912109, Gradient norm: 0.39244438
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8735.87890625MB
INFO:root:[   21] Training loss: 0.68279619, Validation loss: 0.70093249, Gradient norm: 0.29501528
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8848.78125MB
INFO:root:[   22] Training loss: 0.68247517, Validation loss: 0.69905483, Gradient norm: 0.39742094
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8938.21484375MB
INFO:root:[   23] Training loss: 0.68181692, Validation loss: 0.69986895, Gradient norm: 0.42494219
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8951.12109375MB
INFO:root:[   24] Training loss: 0.68133757, Validation loss: 0.69987937, Gradient norm: 0.53771936
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8940.25390625MB
INFO:root:[   25] Training loss: 0.68094512, Validation loss: 0.70391653, Gradient norm: 0.55989654
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8978.390625MB
INFO:root:[   26] Training loss: 0.68022116, Validation loss: 0.71153152, Gradient norm: 0.50028544
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=8966.34765625MB
INFO:root:[   27] Training loss: 0.67985872, Validation loss: 0.70065623, Gradient norm: 0.59102561
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9054.65234375MB
INFO:root:[   28] Training loss: 0.67939805, Validation loss: 0.70412832, Gradient norm: 0.64592451
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9042.58203125MB
INFO:root:[   29] Training loss: 0.67902045, Validation loss: 0.70586753, Gradient norm: 0.66679183
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9154.63671875MB
INFO:root:[   30] Training loss: 0.67859928, Validation loss: 0.69850454, Gradient norm: 0.67601973
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9192.79296875MB
INFO:root:[   31] Training loss: 0.67811544, Validation loss: 0.68571223, Gradient norm: 0.75500356
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9256.515625MB
INFO:root:[   32] Training loss: 0.67788452, Validation loss: 0.67906120, Gradient norm: 1.05953705
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9219.10546875MB
INFO:root:[   33] Training loss: 0.67753732, Validation loss: 0.68015668, Gradient norm: 0.96494051
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9233.48828125MB
INFO:root:[   34] Training loss: 0.67708318, Validation loss: 0.67431362, Gradient norm: 1.05028892
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9370.5390625MB
INFO:root:[   35] Training loss: 0.67661360, Validation loss: 0.68094974, Gradient norm: 0.96080649
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9310.109375MB
INFO:root:[   36] Training loss: 0.67626078, Validation loss: 0.67102925, Gradient norm: 1.13678525
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9347.96484375MB
INFO:root:[   37] Training loss: 0.67604022, Validation loss: 0.66863641, Gradient norm: 1.06004120
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9385.71875MB
INFO:root:[   38] Training loss: 0.67585174, Validation loss: 0.66831247, Gradient norm: 1.40585595
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9423.88671875MB
INFO:root:[   39] Training loss: 0.67531734, Validation loss: 0.66236254, Gradient norm: 1.31891582
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9536.66015625MB
INFO:root:[   40] Training loss: 0.67519883, Validation loss: 0.66286488, Gradient norm: 1.47038600
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9599.71484375MB
INFO:root:[   41] Training loss: 0.67494864, Validation loss: 0.66282633, Gradient norm: 1.48308866
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9564.21875MB
INFO:root:[   42] Training loss: 0.67477194, Validation loss: 0.66030232, Gradient norm: 1.59009986
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9602.328125MB
INFO:root:[   43] Training loss: 0.67446608, Validation loss: 0.65821012, Gradient norm: 1.51636250
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9639.234375MB
INFO:root:[   44] Training loss: 0.67407131, Validation loss: 0.65790010, Gradient norm: 1.70601708
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9652.3125MB
INFO:root:[   45] Training loss: 0.67381563, Validation loss: 0.65905040, Gradient norm: 1.75719771
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9741.61328125MB
INFO:root:[   46] Training loss: 0.67377885, Validation loss: 0.65807148, Gradient norm: 1.95098777
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9729.34765625MB
INFO:root:[   47] Training loss: 0.67355886, Validation loss: 0.65672289, Gradient norm: 1.90736461
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9767.03125MB
INFO:root:[   48] Training loss: 0.67355544, Validation loss: 0.65685811, Gradient norm: 2.03991190
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9830.1953125MB
INFO:root:[   49] Training loss: 0.67335745, Validation loss: 0.65685552, Gradient norm: 2.25125831
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9894.50390625MB
INFO:root:[   50] Training loss: 0.67325002, Validation loss: 0.65545895, Gradient norm: 2.36586811
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9881.7109375MB
INFO:root:[   51] Training loss: 0.67291385, Validation loss: 0.65618514, Gradient norm: 2.02161307
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9994.47265625MB
INFO:root:[   52] Training loss: 0.67303351, Validation loss: 0.65663119, Gradient norm: 2.30365500
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=9958.92578125MB
INFO:root:[   53] Training loss: 0.67279578, Validation loss: 0.65452437, Gradient norm: 2.62911902
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10020.99609375MB
INFO:root:[   54] Training loss: 0.67266235, Validation loss: 0.65563884, Gradient norm: 2.48283370
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10060.4375MB
INFO:root:[   55] Training loss: 0.67268394, Validation loss: 0.65498134, Gradient norm: 2.70675475
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10073.3671875MB
INFO:root:[   56] Training loss: 0.67246634, Validation loss: 0.65432629, Gradient norm: 2.80467732
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10160.46875MB
INFO:root:[   57] Training loss: 0.67226971, Validation loss: 0.65522631, Gradient norm: 3.00464445
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10174.625MB
INFO:root:[   58] Training loss: 0.67238921, Validation loss: 0.65458365, Gradient norm: 2.98734906
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10187.33984375MB
INFO:root:[   59] Training loss: 0.67235469, Validation loss: 0.65525696, Gradient norm: 2.96316801
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10225.46484375MB
INFO:root:[   60] Training loss: 0.67211710, Validation loss: 0.65434561, Gradient norm: 2.87060288
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10287.546875MB
INFO:root:[   61] Training loss: 0.67228741, Validation loss: 0.65565215, Gradient norm: 3.20749252
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10376.328125MB
INFO:root:[   62] Training loss: 0.67217012, Validation loss: 0.65268570, Gradient norm: 3.10417264
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10364.04296875MB
INFO:root:[   63] Training loss: 0.67206945, Validation loss: 0.65445895, Gradient norm: 3.17794706
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10428.85546875MB
INFO:root:[   64] Training loss: 0.67144807, Validation loss: 0.65411338, Gradient norm: 2.62666151
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10416.78125MB
INFO:root:[   65] Training loss: 0.67218167, Validation loss: 0.65343162, Gradient norm: 3.43637292
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10454.6640625MB
INFO:root:[   66] Training loss: 0.67201123, Validation loss: 0.65521254, Gradient norm: 3.55166749
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10492.77734375MB
INFO:root:[   67] Training loss: 0.67172457, Validation loss: 0.65335088, Gradient norm: 3.65256922
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10554.15234375MB
INFO:root:[   68] Training loss: 0.67167094, Validation loss: 0.65579223, Gradient norm: 3.67977530
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10592.81640625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   69] Training loss: 0.67165440, Validation loss: 0.65593669, Gradient norm: 3.76327717
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10629.83203125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   70] Training loss: 0.67019185, Validation loss: 0.65284139, Gradient norm: 2.39019585
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10694.1328125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   71] Training loss: 0.66935563, Validation loss: 0.65187045, Gradient norm: 1.83823289
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10732.046875MB
INFO:root:[   72] Training loss: 0.66925603, Validation loss: 0.65168220, Gradient norm: 1.68365898
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10719.8125MB
INFO:root:[   73] Training loss: 0.66895517, Validation loss: 0.65106873, Gradient norm: 1.78930165
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10808.66015625MB
INFO:root:[   74] Training loss: 0.66911686, Validation loss: 0.65154027, Gradient norm: 1.87774809
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10796.37109375MB
INFO:root:[   75] Training loss: 0.66897227, Validation loss: 0.65184566, Gradient norm: 1.80638543
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10834.484375MB
INFO:root:[   76] Training loss: 0.66912354, Validation loss: 0.65126176, Gradient norm: 2.03805595
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10972.90625MB
INFO:root:[   77] Training loss: 0.66892554, Validation loss: 0.65084951, Gradient norm: 1.97143696
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11011.6796875MB
INFO:root:[   78] Training loss: 0.66893376, Validation loss: 0.65121107, Gradient norm: 2.12105119
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10950.5625MB
INFO:root:[   79] Training loss: 0.66901177, Validation loss: 0.65224420, Gradient norm: 2.07075756
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=10988.44140625MB
INFO:root:[   80] Training loss: 0.66908547, Validation loss: 0.65140465, Gradient norm: 2.27734106
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11026.57421875MB
INFO:root:[   81] Training loss: 0.66887680, Validation loss: 0.65178148, Gradient norm: 2.18268333
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11088.97265625MB
INFO:root:[   82] Training loss: 0.66891390, Validation loss: 0.65138787, Gradient norm: 2.28133133
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11128.484375MB
INFO:root:[   83] Training loss: 0.66880784, Validation loss: 0.65110119, Gradient norm: 2.24744826
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11191.453125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   84] Training loss: 0.66882821, Validation loss: 0.65075378, Gradient norm: 2.36944117
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11203.67578125MB
INFO:root:[   85] Training loss: 0.66871316, Validation loss: 0.65064537, Gradient norm: 1.92030888
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11316.96875MB
INFO:root:[   86] Training loss: 0.66879396, Validation loss: 0.65080196, Gradient norm: 1.94516580
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11329.93359375MB
INFO:root:[   87] Training loss: 0.66870072, Validation loss: 0.65137029, Gradient norm: 1.97805200
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11417.7890625MB
INFO:root:[   88] Training loss: 0.66872574, Validation loss: 0.65052432, Gradient norm: 2.20607682
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11382.05078125MB
INFO:root:[   89] Training loss: 0.66878400, Validation loss: 0.65102058, Gradient norm: 2.21643183
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11394.40234375MB
INFO:root:[   90] Training loss: 0.66869103, Validation loss: 0.65117833, Gradient norm: 2.07378906
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11408.28515625MB
INFO:root:[   91] Training loss: 0.66871226, Validation loss: 0.65096332, Gradient norm: 2.06896296
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11520.3671875MB
INFO:root:[   92] Training loss: 0.66867234, Validation loss: 0.65118668, Gradient norm: 2.26342388
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11608.63671875MB
INFO:root:[   93] Training loss: 0.66865881, Validation loss: 0.64999473, Gradient norm: 2.31403586
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11547.3671875MB
INFO:root:[   94] Training loss: 0.66869741, Validation loss: 0.65047302, Gradient norm: 2.12551260
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11561.02734375MB
INFO:root:[   95] Training loss: 0.66872438, Validation loss: 0.65145702, Gradient norm: 2.47498158
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11599.140625MB
INFO:root:[   96] Training loss: 0.66856534, Validation loss: 0.65129719, Gradient norm: 2.36106894
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11637.02734375MB
INFO:root:[   97] Training loss: 0.66876422, Validation loss: 0.65133400, Gradient norm: 2.41852144
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11724.13671875MB
INFO:root:[   98] Training loss: 0.66863663, Validation loss: 0.65119047, Gradient norm: 2.57361652
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11737.2890625MB
INFO:root:[   99] Training loss: 0.66861786, Validation loss: 0.65146683, Gradient norm: 2.34396029
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11801.34765625MB
INFO:root:[  100] Training loss: 0.66870565, Validation loss: 0.65067847, Gradient norm: 2.48681193
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11789.4140625MB
INFO:root:[  101] Training loss: 0.66852415, Validation loss: 0.65168836, Gradient norm: 2.41896538
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11876.48828125MB
INFO:root:[  102] Training loss: 0.66862220, Validation loss: 0.65116983, Gradient norm: 2.47656617
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11889.8984375MB
INFO:root:EP 102: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12456.83984375MB; mem (CPU total)=11954.4609375MB
INFO:root:Training the model took 4713.075s.
INFO:root:Emptying the cuda cache took 0.027s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92182
INFO:root:EnergyScoreTrain: 0.64889
INFO:root:CRPSTrain: 0.57327
INFO:root:Gaussian NLLTrain: 81617918907.73335
INFO:root:CoverageTrain: 0.60298
INFO:root:IntervalWidthTrain: 2.66618
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9244
INFO:root:EnergyScoreValidation: 0.65073
INFO:root:CRPSValidation: 0.57602
INFO:root:Gaussian NLLValidation: 83589417314.98662
INFO:root:CoverageValidation: 0.60272
INFO:root:IntervalWidthValidation: 2.66573
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.92484
INFO:root:EnergyScoreTest: 0.65104
INFO:root:CRPSTest: 0.57604
INFO:root:Gaussian NLLTest: 83724025987.07198
INFO:root:CoverageTest: 0.60265
INFO:root:IntervalWidthTest: 2.66491
INFO:root:After validation: mem (CPU python)=12456.83984375MB; mem (CPU total)=11980.28125MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=12456.83984375MB; mem (CPU total)=11980.28125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12456.83984375MB; mem (CPU total)=11980.28125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=11980.5234375MB
INFO:root:[    1] Training loss: 0.72510483, Validation loss: 0.72071176, Gradient norm: 0.01814564
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=12111.65234375MB
INFO:root:[    2] Training loss: 0.72045408, Validation loss: 0.71948652, Gradient norm: 0.00628589
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=12149.81640625MB
INFO:root:[    3] Training loss: 0.71902577, Validation loss: 0.71690165, Gradient norm: 0.00867272
INFO:root:At the start of the epoch: mem (CPU python)=12456.83984375MB; mem (CPU total)=12108.01953125MB
INFO:root:[    4] Training loss: 0.71471282, Validation loss: 0.70739482, Gradient norm: 0.01963855
INFO:root:At the start of the epoch: mem (CPU python)=12500.796875MB; mem (CPU total)=12171.37109375MB
INFO:root:[    5] Training loss: 0.70862267, Validation loss: 0.70196766, Gradient norm: 0.02811465
INFO:root:At the start of the epoch: mem (CPU python)=12565.921875MB; mem (CPU total)=12284.3671875MB
INFO:root:[    6] Training loss: 0.70391602, Validation loss: 0.69578398, Gradient norm: 0.03325677
INFO:root:At the start of the epoch: mem (CPU python)=12604.03515625MB; mem (CPU total)=12322.48828125MB
INFO:root:[    7] Training loss: 0.69931269, Validation loss: 0.68866327, Gradient norm: 0.03823800
INFO:root:At the start of the epoch: mem (CPU python)=12629.62890625MB; mem (CPU total)=12347.8671875MB
INFO:root:[    8] Training loss: 0.69461210, Validation loss: 0.68343797, Gradient norm: 0.03820707
INFO:root:At the start of the epoch: mem (CPU python)=12667.72265625MB; mem (CPU total)=12386.24609375MB
INFO:root:[    9] Training loss: 0.69074828, Validation loss: 0.67942260, Gradient norm: 0.04128254
INFO:root:At the start of the epoch: mem (CPU python)=12697.58203125MB; mem (CPU total)=12416.875MB
INFO:root:[   10] Training loss: 0.68748170, Validation loss: 0.67490353, Gradient norm: 0.04660464
INFO:root:At the start of the epoch: mem (CPU python)=12732.734375MB; mem (CPU total)=12450.609375MB
INFO:root:[   11] Training loss: 0.68462187, Validation loss: 0.67191681, Gradient norm: 0.04809796
INFO:root:At the start of the epoch: mem (CPU python)=12768.8046875MB; mem (CPU total)=12415.99609375MB
INFO:root:[   12] Training loss: 0.68217898, Validation loss: 0.66751942, Gradient norm: 0.05260099
INFO:root:At the start of the epoch: mem (CPU python)=12834.375MB; mem (CPU total)=12479.82421875MB
INFO:root:[   13] Training loss: 0.68016945, Validation loss: 0.66532472, Gradient norm: 0.05816922
INFO:root:At the start of the epoch: mem (CPU python)=12858.41796875MB; mem (CPU total)=12577.0703125MB
INFO:root:[   14] Training loss: 0.67823727, Validation loss: 0.66288867, Gradient norm: 0.05593258
INFO:root:At the start of the epoch: mem (CPU python)=12896.51171875MB; mem (CPU total)=12615.19921875MB
INFO:root:[   15] Training loss: 0.67670172, Validation loss: 0.66105721, Gradient norm: 0.05682546
INFO:root:At the start of the epoch: mem (CPU python)=12926.98828125MB; mem (CPU total)=12516.09765625MB
INFO:root:[   16] Training loss: 0.67520085, Validation loss: 0.65918988, Gradient norm: 0.07032532
INFO:root:At the start of the epoch: mem (CPU python)=12935.078125MB; mem (CPU total)=12605.3203125MB
INFO:root:[   17] Training loss: 0.67382739, Validation loss: 0.65785726, Gradient norm: 0.07336333
INFO:root:At the start of the epoch: mem (CPU python)=13008.44140625MB; mem (CPU total)=12705.9140625MB
INFO:root:[   18] Training loss: 0.67272524, Validation loss: 0.65736884, Gradient norm: 0.08375542
INFO:root:At the start of the epoch: mem (CPU python)=13048.796875MB; mem (CPU total)=12769.22265625MB
INFO:root:[   19] Training loss: 0.67170484, Validation loss: 0.65540244, Gradient norm: 0.09891640
INFO:root:At the start of the epoch: mem (CPU python)=13051.5703125MB; mem (CPU total)=12677.05859375MB
INFO:root:[   20] Training loss: 0.67080272, Validation loss: 0.65571372, Gradient norm: 0.09614728
INFO:root:At the start of the epoch: mem (CPU python)=13087.6953125MB; mem (CPU total)=12809.53515625MB
INFO:root:[   21] Training loss: 0.67018546, Validation loss: 0.65424347, Gradient norm: 0.11598745
INFO:root:At the start of the epoch: mem (CPU python)=13118.16796875MB; mem (CPU total)=12820.4453125MB
INFO:root:[   22] Training loss: 0.66906188, Validation loss: 0.65495629, Gradient norm: 0.13960510
INFO:root:At the start of the epoch: mem (CPU python)=13176.05859375MB; mem (CPU total)=12895.73046875MB
INFO:root:[   23] Training loss: 0.66843828, Validation loss: 0.65360833, Gradient norm: 0.13835804
INFO:root:At the start of the epoch: mem (CPU python)=13261.828125MB; mem (CPU total)=12934.0546875MB
INFO:root:[   24] Training loss: 0.66773131, Validation loss: 0.65336878, Gradient norm: 0.16985784
INFO:root:At the start of the epoch: mem (CPU python)=13261.828125MB; mem (CPU total)=12959.7265625MB
INFO:root:[   25] Training loss: 0.66713325, Validation loss: 0.65258465, Gradient norm: 0.18176296
INFO:root:At the start of the epoch: mem (CPU python)=13329.60546875MB; mem (CPU total)=12999.125MB
INFO:root:[   26] Training loss: 0.66659336, Validation loss: 0.65219104, Gradient norm: 0.20199630
INFO:root:At the start of the epoch: mem (CPU python)=13342.875MB; mem (CPU total)=13062.734375MB
INFO:root:[   27] Training loss: 0.66598552, Validation loss: 0.65375546, Gradient norm: 0.22353385
INFO:root:At the start of the epoch: mem (CPU python)=13379.1015625MB; mem (CPU total)=13025.63671875MB
INFO:root:[   28] Training loss: 0.66516199, Validation loss: 0.65209172, Gradient norm: 0.21770330
INFO:root:At the start of the epoch: mem (CPU python)=13415.18359375MB; mem (CPU total)=13113.47265625MB
INFO:root:[   29] Training loss: 0.66473556, Validation loss: 0.65302983, Gradient norm: 0.24849334
INFO:root:At the start of the epoch: mem (CPU python)=13505.4609375MB; mem (CPU total)=13224.83984375MB
INFO:root:[   30] Training loss: 0.66422412, Validation loss: 0.65235607, Gradient norm: 0.25017904
INFO:root:At the start of the epoch: mem (CPU python)=13543.55859375MB; mem (CPU total)=13262.7734375MB
INFO:root:[   31] Training loss: 0.66386275, Validation loss: 0.65293260, Gradient norm: 0.29758508
INFO:root:At the start of the epoch: mem (CPU python)=13581.48828125MB; mem (CPU total)=13231.265625MB
INFO:root:[   32] Training loss: 0.66340782, Validation loss: 0.65415082, Gradient norm: 0.28581336
INFO:root:At the start of the epoch: mem (CPU python)=13581.48828125MB; mem (CPU total)=13194.01171875MB
INFO:root:[   33] Training loss: 0.66297667, Validation loss: 0.65406745, Gradient norm: 0.33204233
INFO:root:At the start of the epoch: mem (CPU python)=13586.9375MB; mem (CPU total)=13307.57421875MB
INFO:root:[   34] Training loss: 0.66271379, Validation loss: 0.64989055, Gradient norm: 0.36023643
INFO:root:At the start of the epoch: mem (CPU python)=13645.90234375MB; mem (CPU total)=13366.4296875MB
INFO:root:[   35] Training loss: 0.66216687, Validation loss: 0.65003893, Gradient norm: 0.38188514
INFO:root:At the start of the epoch: mem (CPU python)=13708.99609375MB; mem (CPU total)=13429.75MB
INFO:root:[   36] Training loss: 0.66185308, Validation loss: 0.65073736, Gradient norm: 0.39520305
INFO:root:At the start of the epoch: mem (CPU python)=13747.09375MB; mem (CPU total)=13466.76953125MB
INFO:root:[   37] Training loss: 0.66136740, Validation loss: 0.65238303, Gradient norm: 0.39440905
INFO:root:At the start of the epoch: mem (CPU python)=13760.109375MB; mem (CPU total)=13479.6640625MB
INFO:root:[   38] Training loss: 0.66110842, Validation loss: 0.64616399, Gradient norm: 0.45613839
INFO:root:At the start of the epoch: mem (CPU python)=13798.15234375MB; mem (CPU total)=13419.48828125MB
INFO:root:[   39] Training loss: 0.66083453, Validation loss: 0.64597024, Gradient norm: 0.47662810
INFO:root:At the start of the epoch: mem (CPU python)=13834.73046875MB; mem (CPU total)=13507.3125MB
INFO:root:[   40] Training loss: 0.66067065, Validation loss: 0.64971185, Gradient norm: 0.44855350
INFO:root:At the start of the epoch: mem (CPU python)=13936.81640625MB; mem (CPU total)=13583.06640625MB
INFO:root:[   41] Training loss: 0.66031792, Validation loss: 0.64514543, Gradient norm: 0.52697190
INFO:root:At the start of the epoch: mem (CPU python)=13936.81640625MB; mem (CPU total)=13614.49609375MB
INFO:root:[   42] Training loss: 0.66001292, Validation loss: 0.64449528, Gradient norm: 0.52060457
INFO:root:At the start of the epoch: mem (CPU python)=13936.81640625MB; mem (CPU total)=13652.640625MB
INFO:root:[   43] Training loss: 0.65975554, Validation loss: 0.64282073, Gradient norm: 0.58879241
INFO:root:At the start of the epoch: mem (CPU python)=13963.72265625MB; mem (CPU total)=13613.7109375MB
INFO:root:[   44] Training loss: 0.65944966, Validation loss: 0.64425523, Gradient norm: 0.57618427
INFO:root:At the start of the epoch: mem (CPU python)=14027.01171875MB; mem (CPU total)=13748.4921875MB
INFO:root:[   45] Training loss: 0.65912748, Validation loss: 0.64297270, Gradient norm: 0.62393809
INFO:root:At the start of the epoch: mem (CPU python)=14057.39453125MB; mem (CPU total)=13759.9140625MB
INFO:root:[   46] Training loss: 0.65913707, Validation loss: 0.64245269, Gradient norm: 0.61681609
INFO:root:At the start of the epoch: mem (CPU python)=14076.98828125MB; mem (CPU total)=13748.22265625MB
INFO:root:[   47] Training loss: 0.65902300, Validation loss: 0.64176785, Gradient norm: 0.68261618
INFO:root:At the start of the epoch: mem (CPU python)=14093.9453125MB; mem (CPU total)=13790.05078125MB
INFO:root:[   48] Training loss: 0.65911444, Validation loss: 0.64013423, Gradient norm: 0.67928220
INFO:root:At the start of the epoch: mem (CPU python)=14154.140625MB; mem (CPU total)=13800.703125MB
INFO:root:[   49] Training loss: 0.65887381, Validation loss: 0.64194366, Gradient norm: 0.77630579
INFO:root:At the start of the epoch: mem (CPU python)=14269.04296875MB; mem (CPU total)=13918.1796875MB
INFO:root:[   50] Training loss: 0.65878893, Validation loss: 0.64028053, Gradient norm: 0.97638091
INFO:root:At the start of the epoch: mem (CPU python)=14269.04296875MB; mem (CPU total)=13950.84765625MB
INFO:root:[   51] Training loss: 0.65840645, Validation loss: 0.64000616, Gradient norm: 0.75950294
INFO:root:At the start of the epoch: mem (CPU python)=14318.48828125MB; mem (CPU total)=14039.17578125MB
INFO:root:[   52] Training loss: 0.65821916, Validation loss: 0.63982251, Gradient norm: 0.80808202
INFO:root:At the start of the epoch: mem (CPU python)=14348.83203125MB; mem (CPU total)=14029.23046875MB
INFO:root:[   53] Training loss: 0.65820074, Validation loss: 0.64023128, Gradient norm: 1.01482432
INFO:root:At the start of the epoch: mem (CPU python)=14348.83203125MB; mem (CPU total)=14067.28125MB
INFO:root:[   54] Training loss: 0.65789346, Validation loss: 0.63889395, Gradient norm: 0.94305693
INFO:root:At the start of the epoch: mem (CPU python)=14432.19140625MB; mem (CPU total)=14080.91015625MB
INFO:root:[   55] Training loss: 0.65779388, Validation loss: 0.63790399, Gradient norm: 1.18811296
INFO:root:At the start of the epoch: mem (CPU python)=14445.7890625MB; mem (CPU total)=14169.0703125MB
INFO:root:[   56] Training loss: 0.65742987, Validation loss: 0.63782112, Gradient norm: 0.96119950
INFO:root:At the start of the epoch: mem (CPU python)=14505.078125MB; mem (CPU total)=14207.21484375MB
INFO:root:[   57] Training loss: 0.65743254, Validation loss: 0.63880529, Gradient norm: 1.09151305
INFO:root:At the start of the epoch: mem (CPU python)=14524.40625MB; mem (CPU total)=14246.55859375MB
INFO:root:[   58] Training loss: 0.65708095, Validation loss: 0.63858544, Gradient norm: 1.06885620
INFO:root:At the start of the epoch: mem (CPU python)=14538.9453125MB; mem (CPU total)=14261.68359375MB
INFO:root:[   59] Training loss: 0.65714059, Validation loss: 0.63753103, Gradient norm: 1.39246842
INFO:root:At the start of the epoch: mem (CPU python)=14652.0390625MB; mem (CPU total)=14374.73828125MB
INFO:root:[   60] Training loss: 0.65671606, Validation loss: 0.63745166, Gradient norm: 1.31920670
INFO:root:At the start of the epoch: mem (CPU python)=14690.13671875MB; mem (CPU total)=14412.8515625MB
INFO:root:[   61] Training loss: 0.65670650, Validation loss: 0.63783261, Gradient norm: 1.31396391
INFO:root:At the start of the epoch: mem (CPU python)=14690.2265625MB; mem (CPU total)=14397.08984375MB
INFO:root:[   62] Training loss: 0.65653459, Validation loss: 0.63795505, Gradient norm: 1.37007855
INFO:root:At the start of the epoch: mem (CPU python)=14690.2265625MB; mem (CPU total)=14336.13671875MB
INFO:root:[   63] Training loss: 0.65656233, Validation loss: 0.63702365, Gradient norm: 1.55479280
INFO:root:At the start of the epoch: mem (CPU python)=14750.41015625MB; mem (CPU total)=14398.47265625MB
INFO:root:[   64] Training loss: 0.65638664, Validation loss: 0.63596482, Gradient norm: 1.42505597
INFO:root:At the start of the epoch: mem (CPU python)=14788.5703125MB; mem (CPU total)=14511.2734375MB
INFO:root:[   65] Training loss: 0.65608933, Validation loss: 0.63701218, Gradient norm: 1.35914735
INFO:root:At the start of the epoch: mem (CPU python)=14876.5390625MB; mem (CPU total)=14525.88671875MB
INFO:root:[   66] Training loss: 0.65611308, Validation loss: 0.63756736, Gradient norm: 1.46267977
INFO:root:At the start of the epoch: mem (CPU python)=14876.5390625MB; mem (CPU total)=14514.8046875MB
INFO:root:[   67] Training loss: 0.65584428, Validation loss: 0.63640318, Gradient norm: 1.49884254
INFO:root:At the start of the epoch: mem (CPU python)=14890.17578125MB; mem (CPU total)=14515.22265625MB
INFO:root:[   68] Training loss: 0.65579491, Validation loss: 0.63696000, Gradient norm: 1.70839392
INFO:root:At the start of the epoch: mem (CPU python)=14967.51171875MB; mem (CPU total)=14564.8984375MB
INFO:root:[   69] Training loss: 0.65566184, Validation loss: 0.63540912, Gradient norm: 1.63318296
INFO:root:At the start of the epoch: mem (CPU python)=14991.546875MB; mem (CPU total)=14713.8046875MB
INFO:root:[   70] Training loss: 0.65549573, Validation loss: 0.63593998, Gradient norm: 1.58746717
INFO:root:At the start of the epoch: mem (CPU python)=15042.14453125MB; mem (CPU total)=14764.40234375MB
INFO:root:[   71] Training loss: 0.65558465, Validation loss: 0.63564215, Gradient norm: 1.62842415
INFO:root:At the start of the epoch: mem (CPU python)=15080.23828125MB; mem (CPU total)=14802.51953125MB
INFO:root:[   72] Training loss: 0.65539521, Validation loss: 0.63502340, Gradient norm: 1.62122030
INFO:root:At the start of the epoch: mem (CPU python)=15118.33203125MB; mem (CPU total)=14840.96875MB
INFO:root:[   73] Training loss: 0.65502772, Validation loss: 0.63458320, Gradient norm: 1.76586301
INFO:root:At the start of the epoch: mem (CPU python)=15131.8828125MB; mem (CPU total)=14833.18359375MB
INFO:root:[   74] Training loss: 0.65514792, Validation loss: 0.63558466, Gradient norm: 1.83157205
INFO:root:At the start of the epoch: mem (CPU python)=15172.0234375MB; mem (CPU total)=14896.52734375MB
INFO:root:[   75] Training loss: 0.65491170, Validation loss: 0.63635887, Gradient norm: 1.78414058
INFO:root:At the start of the epoch: mem (CPU python)=15209.38671875MB; mem (CPU total)=14815.33984375MB
INFO:root:[   76] Training loss: 0.65505319, Validation loss: 0.63622851, Gradient norm: 1.47542675
INFO:root:At the start of the epoch: mem (CPU python)=15270.58203125MB; mem (CPU total)=14922.59375MB
INFO:root:[   77] Training loss: 0.65486098, Validation loss: 0.63483592, Gradient norm: 1.79712115
INFO:root:At the start of the epoch: mem (CPU python)=15308.8125MB; mem (CPU total)=15032.8515625MB
INFO:root:[   78] Training loss: 0.65472904, Validation loss: 0.63495609, Gradient norm: 1.87298469
INFO:root:At the start of the epoch: mem (CPU python)=15309.03125MB; mem (CPU total)=15010.36328125MB
INFO:root:[   79] Training loss: 0.65442655, Validation loss: 0.63519276, Gradient norm: 2.03349867
INFO:root:At the start of the epoch: mem (CPU python)=15347.734375MB; mem (CPU total)=15072.953125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   80] Training loss: 0.65441940, Validation loss: 0.63531929, Gradient norm: 2.04489953
INFO:root:At the start of the epoch: mem (CPU python)=15372.5859375MB; mem (CPU total)=15077.45703125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   81] Training loss: 0.65386544, Validation loss: 0.63404614, Gradient norm: 1.19138772
INFO:root:At the start of the epoch: mem (CPU python)=15436.2734375MB; mem (CPU total)=15160.3125MB
INFO:root:[   82] Training loss: 0.65312364, Validation loss: 0.63280883, Gradient norm: 1.05331688
INFO:root:At the start of the epoch: mem (CPU python)=15453.61328125MB; mem (CPU total)=15177.55859375MB
INFO:root:[   83] Training loss: 0.65302431, Validation loss: 0.63367597, Gradient norm: 1.02426653
INFO:root:At the start of the epoch: mem (CPU python)=15537.38671875MB; mem (CPU total)=15261.3671875MB
INFO:root:[   84] Training loss: 0.65301824, Validation loss: 0.63373505, Gradient norm: 1.13327122
INFO:root:At the start of the epoch: mem (CPU python)=15575.4921875MB; mem (CPU total)=15299.5234375MB
INFO:root:[   85] Training loss: 0.65307937, Validation loss: 0.63507883, Gradient norm: 1.21695521
INFO:root:At the start of the epoch: mem (CPU python)=15613.91015625MB; mem (CPU total)=15339.2109375MB
INFO:root:[   86] Training loss: 0.65299896, Validation loss: 0.63355663, Gradient norm: 1.12960848
INFO:root:At the start of the epoch: mem (CPU python)=15614.13671875MB; mem (CPU total)=15290.42578125MB
INFO:root:[   87] Training loss: 0.65283107, Validation loss: 0.63330520, Gradient norm: 1.16768219
INFO:root:At the start of the epoch: mem (CPU python)=15664.89453125MB; mem (CPU total)=15389.4140625MB
INFO:root:[   88] Training loss: 0.65288410, Validation loss: 0.63404574, Gradient norm: 1.22155278
INFO:root:At the start of the epoch: mem (CPU python)=15695.375MB; mem (CPU total)=15384.21875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   89] Training loss: 0.65291081, Validation loss: 0.63362288, Gradient norm: 1.22712442
INFO:root:At the start of the epoch: mem (CPU python)=15737.4609375MB; mem (CPU total)=15419.72265625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   90] Training loss: 0.65270826, Validation loss: 0.63310365, Gradient norm: 1.05111281
INFO:root:At the start of the epoch: mem (CPU python)=15757.04296875MB; mem (CPU total)=15380.0390625MB
INFO:root:[   91] Training loss: 0.65251926, Validation loss: 0.63297276, Gradient norm: 0.81476187
INFO:root:At the start of the epoch: mem (CPU python)=15817.39453125MB; mem (CPU total)=15542.19140625MB
INFO:root:EP 91: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=15830.27734375MB; mem (CPU total)=15555.1171875MB
INFO:root:Training the model took 4677.156s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.89669
INFO:root:EnergyScoreTrain: 0.63118
INFO:root:CRPSTrain: 0.5262
INFO:root:Gaussian NLLTrain: 7221335441.63556
INFO:root:CoverageTrain: 0.6783
INFO:root:IntervalWidthTrain: 2.73087
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89945
INFO:root:EnergyScoreValidation: 0.63317
INFO:root:CRPSValidation: 0.52864
INFO:root:Gaussian NLLValidation: 7390288313.45777
INFO:root:CoverageValidation: 0.6779
INFO:root:IntervalWidthValidation: 2.73071
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.90187
INFO:root:EnergyScoreTest: 0.6349
INFO:root:CRPSTest: 0.53089
INFO:root:Gaussian NLLTest: 7586244632.576
INFO:root:CoverageTest: 0.67722
INFO:root:IntervalWidthTest: 2.73157
INFO:root:After validation: mem (CPU python)=15863.78125MB; mem (CPU total)=15581.46484375MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=15863.78125MB; mem (CPU total)=15499.2890625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=15863.78125MB; mem (CPU total)=15503.76953125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=15863.78125MB; mem (CPU total)=15504.01171875MB
INFO:root:[    1] Training loss: 0.72458741, Validation loss: 0.72076405, Gradient norm: 0.01328502
INFO:root:At the start of the epoch: mem (CPU python)=15935.96484375MB; mem (CPU total)=15592.58203125MB
INFO:root:[    2] Training loss: 0.72028928, Validation loss: 0.71926675, Gradient norm: 0.00670891
INFO:root:At the start of the epoch: mem (CPU python)=15971.60546875MB; mem (CPU total)=15576.17578125MB
INFO:root:[    3] Training loss: 0.71910786, Validation loss: 0.71751361, Gradient norm: 0.01147365
INFO:root:At the start of the epoch: mem (CPU python)=15993.43359375MB; mem (CPU total)=15639.80859375MB
INFO:root:[    4] Training loss: 0.71614448, Validation loss: 0.70964220, Gradient norm: 0.02165676
INFO:root:At the start of the epoch: mem (CPU python)=16049.78515625MB; mem (CPU total)=15727.1328125MB
INFO:root:[    5] Training loss: 0.70996921, Validation loss: 0.70215097, Gradient norm: 0.03317388
INFO:root:At the start of the epoch: mem (CPU python)=16089.4609375MB; mem (CPU total)=15744.30078125MB
INFO:root:[    6] Training loss: 0.70459400, Validation loss: 0.69667911, Gradient norm: 0.04314759
INFO:root:At the start of the epoch: mem (CPU python)=16127.7265625MB; mem (CPU total)=15779.39453125MB
INFO:root:[    7] Training loss: 0.70057932, Validation loss: 0.69133559, Gradient norm: 0.03806012
INFO:root:At the start of the epoch: mem (CPU python)=16142.65234375MB; mem (CPU total)=15766.78515625MB
INFO:root:[    8] Training loss: 0.69749403, Validation loss: 0.68762166, Gradient norm: 0.04429106
INFO:root:At the start of the epoch: mem (CPU python)=16178.9296875MB; mem (CPU total)=15904.55859375MB
INFO:root:[    9] Training loss: 0.69428204, Validation loss: 0.68433215, Gradient norm: 0.04222232
INFO:root:At the start of the epoch: mem (CPU python)=16291.96484375MB; mem (CPU total)=15875.03125MB
INFO:root:[   10] Training loss: 0.69168232, Validation loss: 0.68154345, Gradient norm: 0.04967154
INFO:root:At the start of the epoch: mem (CPU python)=16291.96484375MB; mem (CPU total)=15884.23828125MB
INFO:root:[   11] Training loss: 0.68931369, Validation loss: 0.67853252, Gradient norm: 0.04390656
INFO:root:At the start of the epoch: mem (CPU python)=16320.71484375MB; mem (CPU total)=15972.7578125MB
INFO:root:[   12] Training loss: 0.68701770, Validation loss: 0.67484931, Gradient norm: 0.04654574
INFO:root:At the start of the epoch: mem (CPU python)=16320.71484375MB; mem (CPU total)=15983.22265625MB
INFO:root:[   13] Training loss: 0.68482679, Validation loss: 0.67219975, Gradient norm: 0.05824011
INFO:root:At the start of the epoch: mem (CPU python)=16372.0MB; mem (CPU total)=16075.68359375MB
INFO:root:[   14] Training loss: 0.68255197, Validation loss: 0.66858936, Gradient norm: 0.05974209
INFO:root:At the start of the epoch: mem (CPU python)=16435.46484375MB; mem (CPU total)=16038.1875MB
INFO:root:[   15] Training loss: 0.68042094, Validation loss: 0.66578661, Gradient norm: 0.06362941
INFO:root:At the start of the epoch: mem (CPU python)=16470.453125MB; mem (CPU total)=16099.0546875MB
INFO:root:[   16] Training loss: 0.67827259, Validation loss: 0.66371980, Gradient norm: 0.06099299
INFO:root:At the start of the epoch: mem (CPU python)=16483.69140625MB; mem (CPU total)=16211.5390625MB
INFO:root:[   17] Training loss: 0.67651924, Validation loss: 0.66093114, Gradient norm: 0.06205574
INFO:root:At the start of the epoch: mem (CPU python)=16546.7890625MB; mem (CPU total)=16274.625MB
INFO:root:[   18] Training loss: 0.67498371, Validation loss: 0.65890787, Gradient norm: 0.07810366
INFO:root:At the start of the epoch: mem (CPU python)=16579.2890625MB; mem (CPU total)=16242.0390625MB
INFO:root:[   19] Training loss: 0.67370967, Validation loss: 0.65723286, Gradient norm: 0.07600497
INFO:root:At the start of the epoch: mem (CPU python)=16622.84765625MB; mem (CPU total)=16301.90234375MB
INFO:root:[   20] Training loss: 0.67230389, Validation loss: 0.65708597, Gradient norm: 0.09303397
INFO:root:At the start of the epoch: mem (CPU python)=16685.8203125MB; mem (CPU total)=16288.6328125MB
INFO:root:[   21] Training loss: 0.67147490, Validation loss: 0.65567528, Gradient norm: 0.10209753
INFO:root:At the start of the epoch: mem (CPU python)=16729.16796875MB; mem (CPU total)=16456.32421875MB
INFO:root:[   22] Training loss: 0.67056541, Validation loss: 0.65789052, Gradient norm: 0.12013417
INFO:root:At the start of the epoch: mem (CPU python)=16759.8671875MB; mem (CPU total)=16418.078125MB
INFO:root:[   23] Training loss: 0.66963670, Validation loss: 0.65513497, Gradient norm: 0.13909017
INFO:root:At the start of the epoch: mem (CPU python)=16824.3828125MB; mem (CPU total)=16503.171875MB
INFO:root:[   24] Training loss: 0.66895002, Validation loss: 0.65537376, Gradient norm: 0.13813688
INFO:root:At the start of the epoch: mem (CPU python)=16824.3828125MB; mem (CPU total)=16470.86328125MB
INFO:root:[   25] Training loss: 0.66834408, Validation loss: 0.65531961, Gradient norm: 0.17451768
INFO:root:At the start of the epoch: mem (CPU python)=16826.45703125MB; mem (CPU total)=16480.2734375MB
INFO:root:[   26] Training loss: 0.66765535, Validation loss: 0.65618091, Gradient norm: 0.18195068
INFO:root:At the start of the epoch: mem (CPU python)=16863.16015625MB; mem (CPU total)=16547.41015625MB
INFO:root:[   27] Training loss: 0.66696511, Validation loss: 0.65676739, Gradient norm: 0.21434080
INFO:root:At the start of the epoch: mem (CPU python)=16877.7734375MB; mem (CPU total)=16534.609375MB
INFO:root:[   28] Training loss: 0.66656634, Validation loss: 0.65615701, Gradient norm: 0.24698553
INFO:root:At the start of the epoch: mem (CPU python)=16990.30078125MB; mem (CPU total)=16669.375MB
INFO:root:[   29] Training loss: 0.66598434, Validation loss: 0.65629729, Gradient norm: 0.23608576
INFO:root:At the start of the epoch: mem (CPU python)=17028.93359375MB; mem (CPU total)=16757.1484375MB
INFO:root:[   30] Training loss: 0.66556229, Validation loss: 0.65806345, Gradient norm: 0.27237427
INFO:root:At the start of the epoch: mem (CPU python)=17042.03125MB; mem (CPU total)=16769.23828125MB
INFO:root:[   31] Training loss: 0.66505301, Validation loss: 0.65776114, Gradient norm: 0.31789455
INFO:root:At the start of the epoch: mem (CPU python)=17080.12890625MB; mem (CPU total)=16806.8671875MB
INFO:root:[   32] Training loss: 0.66440010, Validation loss: 0.66295894, Gradient norm: 0.33150306
INFO:root:At the start of the epoch: mem (CPU python)=17117.53125MB; mem (CPU total)=16796.60546875MB
INFO:root:[   33] Training loss: 0.66413929, Validation loss: 0.65611954, Gradient norm: 0.34557197
INFO:root:At the start of the epoch: mem (CPU python)=17156.11328125MB; mem (CPU total)=16763.109375MB
INFO:root:[   34] Training loss: 0.66382275, Validation loss: 0.65595016, Gradient norm: 0.38780377
INFO:root:At the start of the epoch: mem (CPU python)=17194.4140625MB; mem (CPU total)=16922.796875MB
INFO:root:[   35] Training loss: 0.66335346, Validation loss: 0.65416544, Gradient norm: 0.40163654
INFO:root:At the start of the epoch: mem (CPU python)=17225.2578125MB; mem (CPU total)=16935.265625MB
INFO:root:[   36] Training loss: 0.66307799, Validation loss: 0.66226453, Gradient norm: 0.50372431
INFO:root:At the start of the epoch: mem (CPU python)=17295.6015625MB; mem (CPU total)=17023.578125MB
INFO:root:[   37] Training loss: 0.66299229, Validation loss: 0.65710101, Gradient norm: 0.50398468
INFO:root:At the start of the epoch: mem (CPU python)=17333.69921875MB; mem (CPU total)=17061.703125MB
INFO:root:[   38] Training loss: 0.66251321, Validation loss: 0.65605492, Gradient norm: 0.56567838
INFO:root:At the start of the epoch: mem (CPU python)=17370.9765625MB; mem (CPU total)=17074.83984375MB
INFO:root:[   39] Training loss: 0.66230197, Validation loss: 0.65927539, Gradient norm: 0.54781510
INFO:root:At the start of the epoch: mem (CPU python)=17384.88671875MB; mem (CPU total)=17112.99609375MB
INFO:root:[   40] Training loss: 0.66204300, Validation loss: 0.65761774, Gradient norm: 0.59679950
INFO:root:At the start of the epoch: mem (CPU python)=17397.98828125MB; mem (CPU total)=17125.76953125MB
INFO:root:[   41] Training loss: 0.66202611, Validation loss: 0.64923753, Gradient norm: 0.78132499
INFO:root:At the start of the epoch: mem (CPU python)=17511.7890625MB; mem (CPU total)=17117.94140625MB
INFO:root:[   42] Training loss: 0.66144033, Validation loss: 0.65058626, Gradient norm: 0.68620982
INFO:root:At the start of the epoch: mem (CPU python)=17511.7890625MB; mem (CPU total)=17106.90234375MB
INFO:root:[   43] Training loss: 0.66121959, Validation loss: 0.64993429, Gradient norm: 0.65864577
INFO:root:At the start of the epoch: mem (CPU python)=17511.7890625MB; mem (CPU total)=17169.97265625MB
INFO:root:[   44] Training loss: 0.66124286, Validation loss: 0.64394404, Gradient norm: 0.86163411
INFO:root:At the start of the epoch: mem (CPU python)=17553.515625MB; mem (CPU total)=17258.5546875MB
INFO:root:[   45] Training loss: 0.66106141, Validation loss: 0.64664213, Gradient norm: 0.86281201
INFO:root:At the start of the epoch: mem (CPU python)=17590.33984375MB; mem (CPU total)=17318.67578125MB
INFO:root:[   46] Training loss: 0.66115298, Validation loss: 0.64451288, Gradient norm: 0.93120253
INFO:root:At the start of the epoch: mem (CPU python)=17624.765625MB; mem (CPU total)=17309.84375MB
INFO:root:[   47] Training loss: 0.66108609, Validation loss: 0.64387790, Gradient norm: 0.88962045
INFO:root:At the start of the epoch: mem (CPU python)=17691.828125MB; mem (CPU total)=17323.453125MB
INFO:root:[   48] Training loss: 0.66112297, Validation loss: 0.64376067, Gradient norm: 1.24729413
INFO:root:At the start of the epoch: mem (CPU python)=17725.71484375MB; mem (CPU total)=17335.484375MB
INFO:root:[   49] Training loss: 0.66102622, Validation loss: 0.64118354, Gradient norm: 1.35889509
INFO:root:At the start of the epoch: mem (CPU python)=17742.71875MB; mem (CPU total)=17472.33203125MB
INFO:root:[   50] Training loss: 0.66089699, Validation loss: 0.64328079, Gradient norm: 1.30136671
INFO:root:At the start of the epoch: mem (CPU python)=17833.94140625MB; mem (CPU total)=17434.74609375MB
INFO:root:[   51] Training loss: 0.66055101, Validation loss: 0.64135800, Gradient norm: 1.19135268
INFO:root:At the start of the epoch: mem (CPU python)=17846.81640625MB; mem (CPU total)=17497.59375MB
INFO:root:[   52] Training loss: 0.66056412, Validation loss: 0.64237407, Gradient norm: 1.26621886
INFO:root:At the start of the epoch: mem (CPU python)=17907.59375MB; mem (CPU total)=17588.41015625MB
INFO:root:[   53] Training loss: 0.66060814, Validation loss: 0.64209252, Gradient norm: 1.54235687
INFO:root:At the start of the epoch: mem (CPU python)=17946.984375MB; mem (CPU total)=17676.78515625MB
INFO:root:[   54] Training loss: 0.66043944, Validation loss: 0.64110839, Gradient norm: 1.66823308
INFO:root:At the start of the epoch: mem (CPU python)=17985.08203125MB; mem (CPU total)=17715.1484375MB
INFO:root:[   55] Training loss: 0.66022528, Validation loss: 0.64123992, Gradient norm: 1.54510223
INFO:root:At the start of the epoch: mem (CPU python)=17994.41796875MB; mem (CPU total)=17724.2421875MB
INFO:root:[   56] Training loss: 0.66022996, Validation loss: 0.64098943, Gradient norm: 1.75881792
INFO:root:At the start of the epoch: mem (CPU python)=18007.515625MB; mem (CPU total)=17737.42578125MB
INFO:root:[   57] Training loss: 0.66035282, Validation loss: 0.64248443, Gradient norm: 1.81267301
INFO:root:At the start of the epoch: mem (CPU python)=18070.41796875MB; mem (CPU total)=17699.58203125MB
INFO:root:[   58] Training loss: 0.66017362, Validation loss: 0.64056076, Gradient norm: 1.80749474
INFO:root:At the start of the epoch: mem (CPU python)=18108.5MB; mem (CPU total)=17738.45703125MB
INFO:root:[   59] Training loss: 0.65981744, Validation loss: 0.64105427, Gradient norm: 1.99604735
INFO:root:At the start of the epoch: mem (CPU python)=18145.81640625MB; mem (CPU total)=17827.00390625MB
INFO:root:[   60] Training loss: 0.65974276, Validation loss: 0.64179765, Gradient norm: 1.98812395
INFO:root:At the start of the epoch: mem (CPU python)=18161.7265625MB; mem (CPU total)=17816.1796875MB
INFO:root:[   61] Training loss: 0.65957414, Validation loss: 0.64047998, Gradient norm: 1.86834092
INFO:root:At the start of the epoch: mem (CPU python)=18202.99609375MB; mem (CPU total)=17932.47265625MB
INFO:root:[   62] Training loss: 0.65985953, Validation loss: 0.64029703, Gradient norm: 2.30218831
INFO:root:At the start of the epoch: mem (CPU python)=18261.08984375MB; mem (CPU total)=17991.03125MB
INFO:root:[   63] Training loss: 0.65964899, Validation loss: 0.64052285, Gradient norm: 2.41108447
INFO:root:At the start of the epoch: mem (CPU python)=18273.7578125MB; mem (CPU total)=17928.953125MB
INFO:root:[   64] Training loss: 0.65966394, Validation loss: 0.63993440, Gradient norm: 2.38205263
INFO:root:At the start of the epoch: mem (CPU python)=18317.12890625MB; mem (CPU total)=17945.34375MB
INFO:root:[   65] Training loss: 0.65960130, Validation loss: 0.64135880, Gradient norm: 2.43919853
INFO:root:At the start of the epoch: mem (CPU python)=18350.375MB; mem (CPU total)=18080.328125MB
INFO:root:[   66] Training loss: 0.65947652, Validation loss: 0.63926588, Gradient norm: 2.48624518
INFO:root:At the start of the epoch: mem (CPU python)=18388.47265625MB; mem (CPU total)=18118.453125MB
INFO:root:[   67] Training loss: 0.65937950, Validation loss: 0.63936125, Gradient norm: 2.53945975
INFO:root:At the start of the epoch: mem (CPU python)=18425.12890625MB; mem (CPU total)=18061.45703125MB
INFO:root:[   68] Training loss: 0.65918441, Validation loss: 0.64020986, Gradient norm: 2.59132307
INFO:root:At the start of the epoch: mem (CPU python)=18469.6640625MB; mem (CPU total)=18200.41796875MB
INFO:root:[   69] Training loss: 0.65917193, Validation loss: 0.64069896, Gradient norm: 2.38725840
INFO:root:At the start of the epoch: mem (CPU python)=18505.96484375MB; mem (CPU total)=18163.1484375MB
INFO:root:[   70] Training loss: 0.65926506, Validation loss: 0.63975796, Gradient norm: 2.77051991
INFO:root:At the start of the epoch: mem (CPU python)=18545.48828125MB; mem (CPU total)=18196.0234375MB
INFO:root:[   71] Training loss: 0.65918610, Validation loss: 0.63958696, Gradient norm: 2.69956586
INFO:root:At the start of the epoch: mem (CPU python)=18625.04296875MB; mem (CPU total)=18309.2890625MB
INFO:root:[   72] Training loss: 0.65901898, Validation loss: 0.64163291, Gradient norm: 2.71054305
INFO:root:At the start of the epoch: mem (CPU python)=18692.04296875MB; mem (CPU total)=18422.43359375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   73] Training loss: 0.65908385, Validation loss: 0.63909937, Gradient norm: 2.93801039
INFO:root:At the start of the epoch: mem (CPU python)=18692.49609375MB; mem (CPU total)=18364.68359375MB
INFO:root:[   74] Training loss: 0.65802913, Validation loss: 0.63763938, Gradient norm: 1.85524441
INFO:root:At the start of the epoch: mem (CPU python)=18717.91015625MB; mem (CPU total)=18348.19921875MB
INFO:root:[   75] Training loss: 0.65797728, Validation loss: 0.63866620, Gradient norm: 1.81618675
INFO:root:At the start of the epoch: mem (CPU python)=18756.109375MB; mem (CPU total)=18412.55078125MB
INFO:root:[   76] Training loss: 0.65795730, Validation loss: 0.63833171, Gradient norm: 2.01745781
INFO:root:At the start of the epoch: mem (CPU python)=18794.33984375MB; mem (CPU total)=18450.6640625MB
INFO:root:[   77] Training loss: 0.65777026, Validation loss: 0.63913458, Gradient norm: 1.83461471
INFO:root:At the start of the epoch: mem (CPU python)=18862.51953125MB; mem (CPU total)=18592.875MB
INFO:root:[   78] Training loss: 0.65790049, Validation loss: 0.63849673, Gradient norm: 2.26680739
INFO:root:At the start of the epoch: mem (CPU python)=18918.5234375MB; mem (CPU total)=18527.13671875MB
INFO:root:[   79] Training loss: 0.65775646, Validation loss: 0.63807796, Gradient norm: 2.26734433
INFO:root:At the start of the epoch: mem (CPU python)=18933.7109375MB; mem (CPU total)=18664.31640625MB
INFO:root:[   80] Training loss: 0.65767526, Validation loss: 0.63846011, Gradient norm: 2.08837941
INFO:root:At the start of the epoch: mem (CPU python)=18964.1171875MB; mem (CPU total)=18627.265625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   81] Training loss: 0.65772098, Validation loss: 0.63835099, Gradient norm: 2.36645975
INFO:root:At the start of the epoch: mem (CPU python)=18981.3359375MB; mem (CPU total)=18595.03125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   82] Training loss: 0.65738457, Validation loss: 0.63749839, Gradient norm: 1.78300468
INFO:root:At the start of the epoch: mem (CPU python)=19049.79296875MB; mem (CPU total)=18681.86328125MB
INFO:root:[   83] Training loss: 0.65690275, Validation loss: 0.63777620, Gradient norm: 1.44754040
INFO:root:At the start of the epoch: mem (CPU python)=19049.79296875MB; mem (CPU total)=18671.55859375MB
INFO:root:[   84] Training loss: 0.65695554, Validation loss: 0.63689201, Gradient norm: 1.60247714
INFO:root:At the start of the epoch: mem (CPU python)=19100.85546875MB; mem (CPU total)=18733.4375MB
INFO:root:[   85] Training loss: 0.65699631, Validation loss: 0.63702799, Gradient norm: 1.49430797
INFO:root:At the start of the epoch: mem (CPU python)=19114.16015625MB; mem (CPU total)=18846.24609375MB
INFO:root:[   86] Training loss: 0.65717956, Validation loss: 0.63736798, Gradient norm: 1.47030020
INFO:root:At the start of the epoch: mem (CPU python)=19200.37890625MB; mem (CPU total)=18932.32421875MB
INFO:root:[   87] Training loss: 0.65705121, Validation loss: 0.63792726, Gradient norm: 1.70108977
INFO:root:At the start of the epoch: mem (CPU python)=19234.83203125MB; mem (CPU total)=18820.140625MB
INFO:root:[   88] Training loss: 0.65687376, Validation loss: 0.63719689, Gradient norm: 1.56598658
INFO:root:At the start of the epoch: mem (CPU python)=19234.83203125MB; mem (CPU total)=18861.984375MB
INFO:root:[   89] Training loss: 0.65696219, Validation loss: 0.63749162, Gradient norm: 1.76650684
INFO:root:At the start of the epoch: mem (CPU python)=19241.15625MB; mem (CPU total)=18949.53125MB
INFO:root:[   90] Training loss: 0.65702050, Validation loss: 0.63758709, Gradient norm: 1.67250658
INFO:root:At the start of the epoch: mem (CPU python)=19329.22265625MB; mem (CPU total)=19039.58984375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   91] Training loss: 0.65700293, Validation loss: 0.63684269, Gradient norm: 1.78190809
INFO:root:At the start of the epoch: mem (CPU python)=19390.8515625MB; mem (CPU total)=19124.1796875MB
INFO:root:[   92] Training loss: 0.65674502, Validation loss: 0.63744311, Gradient norm: 1.46577773
INFO:root:At the start of the epoch: mem (CPU python)=19421.33203125MB; mem (CPU total)=19061.41015625MB
INFO:root:[   93] Training loss: 0.65674752, Validation loss: 0.63761415, Gradient norm: 1.43304609
INFO:root:At the start of the epoch: mem (CPU python)=19466.32421875MB; mem (CPU total)=19098.28515625MB
INFO:root:[   94] Training loss: 0.65688295, Validation loss: 0.63740178, Gradient norm: 1.47047562
INFO:root:At the start of the epoch: mem (CPU python)=19466.32421875MB; mem (CPU total)=19087.98828125MB
INFO:root:[   95] Training loss: 0.65677257, Validation loss: 0.63719953, Gradient norm: 1.48390389
INFO:root:At the start of the epoch: mem (CPU python)=19521.98828125MB; mem (CPU total)=19253.9296875MB
INFO:root:[   96] Training loss: 0.65675717, Validation loss: 0.63787277, Gradient norm: 1.54789131
INFO:root:At the start of the epoch: mem (CPU python)=19606.23046875MB; mem (CPU total)=19239.95703125MB
INFO:root:[   97] Training loss: 0.65682363, Validation loss: 0.63703537, Gradient norm: 1.55737038
INFO:root:At the start of the epoch: mem (CPU python)=19619.41015625MB; mem (CPU total)=19278.12109375MB
INFO:root:[   98] Training loss: 0.65660960, Validation loss: 0.63689665, Gradient norm: 1.49818896
INFO:root:At the start of the epoch: mem (CPU python)=19682.52734375MB; mem (CPU total)=19291.37890625MB
INFO:root:[   99] Training loss: 0.65672409, Validation loss: 0.63766675, Gradient norm: 1.60349807
INFO:root:At the start of the epoch: mem (CPU python)=19682.52734375MB; mem (CPU total)=19383.4140625MB
INFO:root:[  100] Training loss: 0.65665512, Validation loss: 0.63757799, Gradient norm: 1.64894626
INFO:root:At the start of the epoch: mem (CPU python)=19733.6640625MB; mem (CPU total)=19320.4765625MB
INFO:root:EP 100: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19769.6171875MB; mem (CPU total)=19454.78125MB
INFO:root:Training the model took 5591.541s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.90324
INFO:root:EnergyScoreTrain: 0.63584
INFO:root:CRPSTrain: 0.54532
INFO:root:Gaussian NLLTrain: 21066212056.1778
INFO:root:CoverageTrain: 0.65317
INFO:root:IntervalWidthTrain: 2.7042
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9055
INFO:root:EnergyScoreValidation: 0.63748
INFO:root:CRPSValidation: 0.54731
INFO:root:Gaussian NLLValidation: 21594663958.75556
INFO:root:CoverageValidation: 0.65202
INFO:root:IntervalWidthValidation: 2.70121
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.90639
INFO:root:EnergyScoreTest: 0.6381
INFO:root:CRPSTest: 0.54806
INFO:root:Gaussian NLLTest: 21443263299.584
INFO:root:CoverageTest: 0.65237
INFO:root:IntervalWidthTest: 2.70336
INFO:root:After validation: mem (CPU python)=19769.6171875MB; mem (CPU total)=19432.31640625MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=19769.6171875MB; mem (CPU total)=19432.30859375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=19769.6171875MB; mem (CPU total)=19432.80078125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=19769.6171875MB; mem (CPU total)=19432.79296875MB
INFO:root:[    1] Training loss: 0.72560095, Validation loss: 0.72157298, Gradient norm: 0.01686493
INFO:root:At the start of the epoch: mem (CPU python)=19853.22265625MB; mem (CPU total)=19487.78515625MB
INFO:root:[    2] Training loss: 0.72029778, Validation loss: 0.71837870, Gradient norm: 0.00621846
INFO:root:At the start of the epoch: mem (CPU python)=19853.22265625MB; mem (CPU total)=19549.203125MB
INFO:root:[    3] Training loss: 0.71618560, Validation loss: 0.70966949, Gradient norm: 0.01731563
INFO:root:At the start of the epoch: mem (CPU python)=19879.53125MB; mem (CPU total)=19612.00390625MB
INFO:root:[    4] Training loss: 0.71048371, Validation loss: 0.70352610, Gradient norm: 0.02578218
INFO:root:At the start of the epoch: mem (CPU python)=19917.4765625MB; mem (CPU total)=19575.46875MB
INFO:root:[    5] Training loss: 0.70641209, Validation loss: 0.69876765, Gradient norm: 0.03047404
INFO:root:At the start of the epoch: mem (CPU python)=20014.48046875MB; mem (CPU total)=19626.30078125MB
INFO:root:[    6] Training loss: 0.70229208, Validation loss: 0.69376299, Gradient norm: 0.03170665
INFO:root:At the start of the epoch: mem (CPU python)=20020.57421875MB; mem (CPU total)=19753.2890625MB
INFO:root:[    7] Training loss: 0.69857648, Validation loss: 0.68838812, Gradient norm: 0.03667793
INFO:root:At the start of the epoch: mem (CPU python)=20020.62109375MB; mem (CPU total)=19668.99609375MB
INFO:root:[    8] Training loss: 0.69526112, Validation loss: 0.68466900, Gradient norm: 0.03592271
INFO:root:At the start of the epoch: mem (CPU python)=20075.03125MB; mem (CPU total)=19808.71875MB
INFO:root:[    9] Training loss: 0.69219373, Validation loss: 0.68084068, Gradient norm: 0.03913253
INFO:root:At the start of the epoch: mem (CPU python)=20107.98828125MB; mem (CPU total)=19841.1328125MB
INFO:root:[   10] Training loss: 0.68985279, Validation loss: 0.67815452, Gradient norm: 0.04018116
INFO:root:At the start of the epoch: mem (CPU python)=20146.23828125MB; mem (CPU total)=19783.2109375MB
INFO:root:[   11] Training loss: 0.68737829, Validation loss: 0.67466069, Gradient norm: 0.03909010
INFO:root:At the start of the epoch: mem (CPU python)=20189.14453125MB; mem (CPU total)=19821.33203125MB
INFO:root:[   12] Training loss: 0.68510641, Validation loss: 0.67172266, Gradient norm: 0.04372658
INFO:root:At the start of the epoch: mem (CPU python)=20197.3125MB; mem (CPU total)=19859.13671875MB
INFO:root:[   13] Training loss: 0.68328355, Validation loss: 0.66982850, Gradient norm: 0.04954012
INFO:root:At the start of the epoch: mem (CPU python)=20282.74609375MB; mem (CPU total)=19997.109375MB
INFO:root:[   14] Training loss: 0.68138663, Validation loss: 0.66652632, Gradient norm: 0.04848273
INFO:root:At the start of the epoch: mem (CPU python)=20282.74609375MB; mem (CPU total)=19930.58984375MB
INFO:root:[   15] Training loss: 0.67965258, Validation loss: 0.66494009, Gradient norm: 0.04841720
INFO:root:At the start of the epoch: mem (CPU python)=20349.0625MB; mem (CPU total)=20081.22265625MB
INFO:root:[   16] Training loss: 0.67817954, Validation loss: 0.66425576, Gradient norm: 0.05187413
INFO:root:At the start of the epoch: mem (CPU python)=20379.53515625MB; mem (CPU total)=20086.8984375MB
INFO:root:[   17] Training loss: 0.67707020, Validation loss: 0.66125562, Gradient norm: 0.05028481
INFO:root:At the start of the epoch: mem (CPU python)=20437.125MB; mem (CPU total)=20045.3359375MB
INFO:root:[   18] Training loss: 0.67562027, Validation loss: 0.65944790, Gradient norm: 0.05466202
INFO:root:At the start of the epoch: mem (CPU python)=20448.8515625MB; mem (CPU total)=20158.09375MB
INFO:root:[   19] Training loss: 0.67465226, Validation loss: 0.65950008, Gradient norm: 0.05890443
INFO:root:At the start of the epoch: mem (CPU python)=20513.94140625MB; mem (CPU total)=20246.3828125MB
INFO:root:[   20] Training loss: 0.67380244, Validation loss: 0.65767519, Gradient norm: 0.06503538
INFO:root:At the start of the epoch: mem (CPU python)=20576.16796875MB; mem (CPU total)=20260.01953125MB
INFO:root:[   21] Training loss: 0.67296227, Validation loss: 0.65735621, Gradient norm: 0.07326621
INFO:root:At the start of the epoch: mem (CPU python)=20612.29296875MB; mem (CPU total)=20249.671875MB
INFO:root:[   22] Training loss: 0.67228769, Validation loss: 0.65622367, Gradient norm: 0.08785519
INFO:root:At the start of the epoch: mem (CPU python)=20612.29296875MB; mem (CPU total)=20240.06640625MB
INFO:root:[   23] Training loss: 0.67154552, Validation loss: 0.65463728, Gradient norm: 0.09525719
INFO:root:At the start of the epoch: mem (CPU python)=20663.0859375MB; mem (CPU total)=20324.14453125MB
INFO:root:[   24] Training loss: 0.67087404, Validation loss: 0.65453582, Gradient norm: 0.08970970
INFO:root:At the start of the epoch: mem (CPU python)=20729.35546875MB; mem (CPU total)=20387.7421875MB
INFO:root:[   25] Training loss: 0.67004526, Validation loss: 0.65446533, Gradient norm: 0.09138417
INFO:root:At the start of the epoch: mem (CPU python)=20729.35546875MB; mem (CPU total)=20381.921875MB
INFO:root:[   26] Training loss: 0.66986381, Validation loss: 0.65272759, Gradient norm: 0.11827510
INFO:root:At the start of the epoch: mem (CPU python)=20729.35546875MB; mem (CPU total)=20445.00390625MB
INFO:root:[   27] Training loss: 0.66915874, Validation loss: 0.65233610, Gradient norm: 0.10527264
INFO:root:At the start of the epoch: mem (CPU python)=20750.203125MB; mem (CPU total)=20483.60546875MB
INFO:root:[   28] Training loss: 0.66849116, Validation loss: 0.65120220, Gradient norm: 0.13009521
INFO:root:At the start of the epoch: mem (CPU python)=20835.53125MB; mem (CPU total)=20496.7109375MB
INFO:root:[   29] Training loss: 0.66802853, Validation loss: 0.65158081, Gradient norm: 0.12163368
INFO:root:At the start of the epoch: mem (CPU python)=20851.3984375MB; mem (CPU total)=20584.71484375MB
INFO:root:[   30] Training loss: 0.66763179, Validation loss: 0.64988550, Gradient norm: 0.14143891
INFO:root:At the start of the epoch: mem (CPU python)=20864.4921875MB; mem (CPU total)=20597.91796875MB
INFO:root:[   31] Training loss: 0.66708787, Validation loss: 0.65043259, Gradient norm: 0.15878485
INFO:root:At the start of the epoch: mem (CPU python)=20927.27734375MB; mem (CPU total)=20606.28515625MB
INFO:root:[   32] Training loss: 0.66658145, Validation loss: 0.64943836, Gradient norm: 0.16959312
INFO:root:At the start of the epoch: mem (CPU python)=20965.30078125MB; mem (CPU total)=20644.90625MB
INFO:root:[   33] Training loss: 0.66622124, Validation loss: 0.64953935, Gradient norm: 0.16891582
INFO:root:At the start of the epoch: mem (CPU python)=20978.78125MB; mem (CPU total)=20712.96875MB
INFO:root:[   34] Training loss: 0.66579064, Validation loss: 0.64829602, Gradient norm: 0.20910566
INFO:root:At the start of the epoch: mem (CPU python)=21016.875MB; mem (CPU total)=20751.32421875MB
INFO:root:[   35] Training loss: 0.66531265, Validation loss: 0.64938589, Gradient norm: 0.19352917
INFO:root:At the start of the epoch: mem (CPU python)=21104.71875MB; mem (CPU total)=20764.4609375MB
INFO:root:[   36] Training loss: 0.66503135, Validation loss: 0.64778426, Gradient norm: 0.21158958
INFO:root:At the start of the epoch: mem (CPU python)=21117.63671875MB; mem (CPU total)=20802.62109375MB
INFO:root:[   37] Training loss: 0.66464247, Validation loss: 0.64700775, Gradient norm: 0.23976370
INFO:root:At the start of the epoch: mem (CPU python)=21155.21484375MB; mem (CPU total)=20865.94140625MB
INFO:root:[   38] Training loss: 0.66427390, Validation loss: 0.64602375, Gradient norm: 0.24373401
INFO:root:At the start of the epoch: mem (CPU python)=21191.0703125MB; mem (CPU total)=20904.0859375MB
INFO:root:[   39] Training loss: 0.66387487, Validation loss: 0.64764607, Gradient norm: 0.26464915
INFO:root:At the start of the epoch: mem (CPU python)=21207.35546875MB; mem (CPU total)=20942.22265625MB
INFO:root:[   40] Training loss: 0.66360420, Validation loss: 0.64599349, Gradient norm: 0.26813342
INFO:root:At the start of the epoch: mem (CPU python)=21245.44921875MB; mem (CPU total)=20984.58203125MB
INFO:root:[   41] Training loss: 0.66328527, Validation loss: 0.64655391, Gradient norm: 0.31740032
INFO:root:At the start of the epoch: mem (CPU python)=21308.4453125MB; mem (CPU total)=20973.6640625MB
INFO:root:[   42] Training loss: 0.66285647, Validation loss: 0.64478545, Gradient norm: 0.29381585
INFO:root:At the start of the epoch: mem (CPU python)=21345.41796875MB; mem (CPU total)=21060.6640625MB
INFO:root:[   43] Training loss: 0.66283764, Validation loss: 0.64529902, Gradient norm: 0.34838122
INFO:root:At the start of the epoch: mem (CPU python)=21381.875MB; mem (CPU total)=21098.734375MB
INFO:root:[   44] Training loss: 0.66260530, Validation loss: 0.64395429, Gradient norm: 0.36223693
INFO:root:At the start of the epoch: mem (CPU python)=21419.91796875MB; mem (CPU total)=21136.890625MB
INFO:root:[   45] Training loss: 0.66235500, Validation loss: 0.64471141, Gradient norm: 0.37621655
INFO:root:At the start of the epoch: mem (CPU python)=21435.921875MB; mem (CPU total)=21176.421875MB
INFO:root:[   46] Training loss: 0.66213851, Validation loss: 0.64411399, Gradient norm: 0.41034937
INFO:root:At the start of the epoch: mem (CPU python)=21497.3828125MB; mem (CPU total)=21214.90625MB
INFO:root:[   47] Training loss: 0.66184756, Validation loss: 0.64361363, Gradient norm: 0.41800292
INFO:root:At the start of the epoch: mem (CPU python)=21535.32421875MB; mem (CPU total)=21252.80859375MB
INFO:root:[   48] Training loss: 0.66190913, Validation loss: 0.64386875, Gradient norm: 0.42409299
INFO:root:At the start of the epoch: mem (CPU python)=21600.2109375MB; mem (CPU total)=21341.12109375MB
INFO:root:[   49] Training loss: 0.66129156, Validation loss: 0.64317660, Gradient norm: 0.45491481
INFO:root:At the start of the epoch: mem (CPU python)=21638.2421875MB; mem (CPU total)=21277.16796875MB
INFO:root:[   50] Training loss: 0.66121046, Validation loss: 0.64216584, Gradient norm: 0.48821788
INFO:root:At the start of the epoch: mem (CPU python)=21651.40234375MB; mem (CPU total)=21312.3515625MB
INFO:root:[   51] Training loss: 0.66076330, Validation loss: 0.64161282, Gradient norm: 0.52705369
INFO:root:At the start of the epoch: mem (CPU python)=21689.21484375MB; mem (CPU total)=21380.1640625MB
INFO:root:[   52] Training loss: 0.66077185, Validation loss: 0.64166918, Gradient norm: 0.54282140
INFO:root:At the start of the epoch: mem (CPU python)=21702.59375MB; mem (CPU total)=21443.30078125MB
INFO:root:[   53] Training loss: 0.66074055, Validation loss: 0.64080107, Gradient norm: 0.53483614
INFO:root:At the start of the epoch: mem (CPU python)=21790.6875MB; mem (CPU total)=21531.359375MB
INFO:root:[   54] Training loss: 0.66054880, Validation loss: 0.64175597, Gradient norm: 0.59483620
INFO:root:At the start of the epoch: mem (CPU python)=21790.91015625MB; mem (CPU total)=21519.828125MB
INFO:root:[   55] Training loss: 0.66025431, Validation loss: 0.64068725, Gradient norm: 0.61031253
INFO:root:At the start of the epoch: mem (CPU python)=21839.2578125MB; mem (CPU total)=21558.171875MB
INFO:root:[   56] Training loss: 0.66030281, Validation loss: 0.64130853, Gradient norm: 0.67968662
INFO:root:At the start of the epoch: mem (CPU python)=21854.9765625MB; mem (CPU total)=21596.09375MB
INFO:root:[   57] Training loss: 0.66001908, Validation loss: 0.64141976, Gradient norm: 0.62708700
INFO:root:At the start of the epoch: mem (CPU python)=21918.0703125MB; mem (CPU total)=21659.94140625MB
INFO:root:[   58] Training loss: 0.65966798, Validation loss: 0.64013703, Gradient norm: 0.64135520
INFO:root:At the start of the epoch: mem (CPU python)=21948.4765625MB; mem (CPU total)=21672.87890625MB
INFO:root:[   59] Training loss: 0.65996205, Validation loss: 0.64025146, Gradient norm: 0.77017062
INFO:root:At the start of the epoch: mem (CPU python)=22016.0MB; mem (CPU total)=21685.78125MB
INFO:root:[   60] Training loss: 0.65947827, Validation loss: 0.64038161, Gradient norm: 0.79387511
INFO:root:At the start of the epoch: mem (CPU python)=22031.61328125MB; mem (CPU total)=21723.92578125MB
INFO:root:[   61] Training loss: 0.65973374, Validation loss: 0.64010009, Gradient norm: 0.79409027
INFO:root:At the start of the epoch: mem (CPU python)=22045.44921875MB; mem (CPU total)=21787.0234375MB
INFO:root:[   62] Training loss: 0.65958037, Validation loss: 0.63997862, Gradient norm: 0.84119265
INFO:root:At the start of the epoch: mem (CPU python)=22107.23046875MB; mem (CPU total)=21800.1953125MB
INFO:root:[   63] Training loss: 0.65948909, Validation loss: 0.63928541, Gradient norm: 0.88084167
INFO:root:At the start of the epoch: mem (CPU python)=22142.0390625MB; mem (CPU total)=21863.34765625MB
INFO:root:[   64] Training loss: 0.65925313, Validation loss: 0.64013865, Gradient norm: 0.95841833
INFO:root:At the start of the epoch: mem (CPU python)=22184.73828125MB; mem (CPU total)=21926.67578125MB
INFO:root:[   65] Training loss: 0.65913208, Validation loss: 0.63859738, Gradient norm: 1.00925069
INFO:root:At the start of the epoch: mem (CPU python)=22220.171875MB; mem (CPU total)=21939.59375MB
INFO:root:[   66] Training loss: 0.65889497, Validation loss: 0.63924290, Gradient norm: 0.90460584
INFO:root:At the start of the epoch: mem (CPU python)=22260.9296875MB; mem (CPU total)=22002.9609375MB
INFO:root:[   67] Training loss: 0.65912257, Validation loss: 0.63883684, Gradient norm: 1.01653039
INFO:root:At the start of the epoch: mem (CPU python)=22297.43359375MB; mem (CPU total)=22016.1875MB
INFO:root:[   68] Training loss: 0.65895902, Validation loss: 0.64017494, Gradient norm: 1.08426221
INFO:root:At the start of the epoch: mem (CPU python)=22336.94921875MB; mem (CPU total)=21999.94140625MB
INFO:root:[   69] Training loss: 0.65897481, Validation loss: 0.63887930, Gradient norm: 1.18423781
INFO:root:At the start of the epoch: mem (CPU python)=22373.4453125MB; mem (CPU total)=22066.22265625MB
INFO:root:[   70] Training loss: 0.65851964, Validation loss: 0.63965095, Gradient norm: 1.11594952
INFO:root:At the start of the epoch: mem (CPU python)=22412.7421875MB; mem (CPU total)=22103.74609375MB
INFO:root:[   71] Training loss: 0.65848903, Validation loss: 0.63808983, Gradient norm: 1.17103657
INFO:root:At the start of the epoch: mem (CPU python)=22446.76953125MB; mem (CPU total)=22167.109375MB
INFO:root:[   72] Training loss: 0.65863677, Validation loss: 0.63852273, Gradient norm: 1.30912581
INFO:root:At the start of the epoch: mem (CPU python)=22512.96875MB; mem (CPU total)=22205.515625MB
INFO:root:[   73] Training loss: 0.65826120, Validation loss: 0.63835937, Gradient norm: 1.12337980
INFO:root:At the start of the epoch: mem (CPU python)=22525.91015625MB; mem (CPU total)=22218.734375MB
INFO:root:[   74] Training loss: 0.65813113, Validation loss: 0.63819695, Gradient norm: 1.28545526
INFO:root:At the start of the epoch: mem (CPU python)=22564.75390625MB; mem (CPU total)=22252.1171875MB
INFO:root:[   75] Training loss: 0.65820306, Validation loss: 0.63799847, Gradient norm: 1.17518118
INFO:root:At the start of the epoch: mem (CPU python)=22578.7890625MB; mem (CPU total)=22320.171875MB
INFO:root:[   76] Training loss: 0.65820006, Validation loss: 0.63741174, Gradient norm: 1.47017319
INFO:root:At the start of the epoch: mem (CPU python)=22641.77734375MB; mem (CPU total)=22306.6953125MB
INFO:root:[   77] Training loss: 0.65793666, Validation loss: 0.63839882, Gradient norm: 1.23027047
INFO:root:At the start of the epoch: mem (CPU python)=22702.05078125MB; mem (CPU total)=22396.66796875MB
INFO:root:[   78] Training loss: 0.65779742, Validation loss: 0.63846808, Gradient norm: 1.34942515
INFO:root:At the start of the epoch: mem (CPU python)=22715.06640625MB; mem (CPU total)=22435.05859375MB
INFO:root:[   79] Training loss: 0.65768919, Validation loss: 0.63830588, Gradient norm: 1.33202615
INFO:root:At the start of the epoch: mem (CPU python)=22750.67578125MB; mem (CPU total)=22472.94921875MB
INFO:root:[   80] Training loss: 0.65762547, Validation loss: 0.63777661, Gradient norm: 1.47319813
INFO:root:At the start of the epoch: mem (CPU python)=22791.84375MB; mem (CPU total)=22511.23828125MB
INFO:root:[   81] Training loss: 0.65742037, Validation loss: 0.63796450, Gradient norm: 1.54067277
INFO:root:At the start of the epoch: mem (CPU python)=22827.359375MB; mem (CPU total)=22549.31640625MB
INFO:root:[   82] Training loss: 0.65769110, Validation loss: 0.63743372, Gradient norm: 1.44685152
INFO:root:At the start of the epoch: mem (CPU python)=22845.4609375MB; mem (CPU total)=22587.44140625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   83] Training loss: 0.65753008, Validation loss: 0.63772840, Gradient norm: 1.55579204
INFO:root:At the start of the epoch: mem (CPU python)=22906.6171875MB; mem (CPU total)=22625.58984375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   84] Training loss: 0.65644490, Validation loss: 0.63589540, Gradient norm: 1.05439411
INFO:root:At the start of the epoch: mem (CPU python)=22921.65234375MB; mem (CPU total)=22663.76171875MB
INFO:root:[   85] Training loss: 0.65622128, Validation loss: 0.63569107, Gradient norm: 0.98001153
INFO:root:At the start of the epoch: mem (CPU python)=22984.1328125MB; mem (CPU total)=22671.8046875MB
INFO:root:[   86] Training loss: 0.65614406, Validation loss: 0.63612106, Gradient norm: 0.91672261
INFO:root:At the start of the epoch: mem (CPU python)=23021.25MB; mem (CPU total)=22715.1328125MB
INFO:root:[   87] Training loss: 0.65597661, Validation loss: 0.63618077, Gradient norm: 1.03188866
INFO:root:At the start of the epoch: mem (CPU python)=23059.4140625MB; mem (CPU total)=22778.26953125MB
INFO:root:[   88] Training loss: 0.65598622, Validation loss: 0.63562014, Gradient norm: 0.94065122
INFO:root:At the start of the epoch: mem (CPU python)=23098.0703125MB; mem (CPU total)=22791.68359375MB
INFO:root:[   89] Training loss: 0.65600263, Validation loss: 0.63590315, Gradient norm: 1.14791314
INFO:root:At the start of the epoch: mem (CPU python)=23112.12890625MB; mem (CPU total)=22853.84765625MB
INFO:root:[   90] Training loss: 0.65597897, Validation loss: 0.63559326, Gradient norm: 1.07993285
INFO:root:At the start of the epoch: mem (CPU python)=23150.2265625MB; mem (CPU total)=22892.44921875MB
INFO:root:[   91] Training loss: 0.65591075, Validation loss: 0.63626000, Gradient norm: 1.04310124
INFO:root:At the start of the epoch: mem (CPU python)=23210.5MB; mem (CPU total)=22930.578125MB
INFO:root:[   92] Training loss: 0.65594175, Validation loss: 0.63640893, Gradient norm: 1.11514747
INFO:root:At the start of the epoch: mem (CPU python)=23251.3125MB; mem (CPU total)=22914.78125MB
INFO:root:[   93] Training loss: 0.65591027, Validation loss: 0.63556603, Gradient norm: 1.13691000
INFO:root:At the start of the epoch: mem (CPU python)=23264.51171875MB; mem (CPU total)=23007.0703125MB
INFO:root:[   94] Training loss: 0.65592362, Validation loss: 0.63567032, Gradient norm: 1.06722706
INFO:root:At the start of the epoch: mem (CPU python)=23302.60546875MB; mem (CPU total)=23045.16796875MB
INFO:root:[   95] Training loss: 0.65593261, Validation loss: 0.63525798, Gradient norm: 1.16295361
INFO:root:At the start of the epoch: mem (CPU python)=23361.00390625MB; mem (CPU total)=23083.4609375MB
INFO:root:[   96] Training loss: 0.65599834, Validation loss: 0.63584212, Gradient norm: 1.14274771
INFO:root:At the start of the epoch: mem (CPU python)=23378.79296875MB; mem (CPU total)=23121.3203125MB
INFO:root:[   97] Training loss: 0.65576298, Validation loss: 0.63566042, Gradient norm: 1.12226319
INFO:root:At the start of the epoch: mem (CPU python)=23416.89453125MB; mem (CPU total)=23159.6640625MB
INFO:root:[   98] Training loss: 0.65590227, Validation loss: 0.63554435, Gradient norm: 1.25154618
INFO:root:At the start of the epoch: mem (CPU python)=23454.98828125MB; mem (CPU total)=23197.7578125MB
INFO:root:[   99] Training loss: 0.65589163, Validation loss: 0.63531526, Gradient norm: 1.24621607
INFO:root:At the start of the epoch: mem (CPU python)=23493.08203125MB; mem (CPU total)=23235.84765625MB
INFO:root:[  100] Training loss: 0.65577542, Validation loss: 0.63525767, Gradient norm: 1.17066288
INFO:root:At the start of the epoch: mem (CPU python)=23531.1796875MB; mem (CPU total)=23274.421875MB
INFO:root:[  101] Training loss: 0.65587373, Validation loss: 0.63548912, Gradient norm: 1.23017401
INFO:root:At the start of the epoch: mem (CPU python)=23615.609375MB; mem (CPU total)=23312.31640625MB
INFO:root:[  102] Training loss: 0.65579056, Validation loss: 0.63634830, Gradient norm: 1.31774676
INFO:root:At the start of the epoch: mem (CPU python)=23632.2265625MB; mem (CPU total)=23300.48828125MB
INFO:root:[  103] Training loss: 0.65578079, Validation loss: 0.63521961, Gradient norm: 1.39927625
INFO:root:At the start of the epoch: mem (CPU python)=23669.85546875MB; mem (CPU total)=23390.0234375MB
INFO:root:[  104] Training loss: 0.65577085, Validation loss: 0.63510481, Gradient norm: 1.27840430
INFO:root:At the start of the epoch: mem (CPU python)=23704.0859375MB; mem (CPU total)=23428.24609375MB
INFO:root:[  105] Training loss: 0.65588015, Validation loss: 0.63542094, Gradient norm: 1.48993111
INFO:root:At the start of the epoch: mem (CPU python)=23746.65234375MB; mem (CPU total)=23491.3359375MB
INFO:root:[  106] Training loss: 0.65558286, Validation loss: 0.63538385, Gradient norm: 1.30744478
INFO:root:At the start of the epoch: mem (CPU python)=23782.38671875MB; mem (CPU total)=23504.30859375MB
INFO:root:[  107] Training loss: 0.65568158, Validation loss: 0.63525241, Gradient norm: 1.34041540
INFO:root:At the start of the epoch: mem (CPU python)=23822.44140625MB; mem (CPU total)=23542.5078125MB
INFO:root:[  108] Training loss: 0.65575317, Validation loss: 0.63561920, Gradient norm: 1.33317174
INFO:root:At the start of the epoch: mem (CPU python)=23885.9375MB; mem (CPU total)=23630.828125MB
INFO:root:[  109] Training loss: 0.65556681, Validation loss: 0.63630999, Gradient norm: 1.45765491
INFO:root:At the start of the epoch: mem (CPU python)=23898.1875MB; mem (CPU total)=23618.98828125MB
INFO:root:[  110] Training loss: 0.65576824, Validation loss: 0.63595380, Gradient norm: 1.35593805
INFO:root:At the start of the epoch: mem (CPU python)=23912.1328125MB; mem (CPU total)=23656.65625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  111] Training loss: 0.65588608, Validation loss: 0.63582994, Gradient norm: 1.60177404
INFO:root:At the start of the epoch: mem (CPU python)=23969.859375MB; mem (CPU total)=23695.296875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  112] Training loss: 0.65530734, Validation loss: 0.63554974, Gradient norm: 1.20187450
INFO:root:At the start of the epoch: mem (CPU python)=24011.61328125MB; mem (CPU total)=23733.43359375MB
INFO:root:[  113] Training loss: 0.65525230, Validation loss: 0.63502451, Gradient norm: 1.04287219
INFO:root:At the start of the epoch: mem (CPU python)=24051.25390625MB; mem (CPU total)=23716.7421875MB
INFO:root:[  114] Training loss: 0.65543312, Validation loss: 0.63443370, Gradient norm: 1.11583234
INFO:root:At the start of the epoch: mem (CPU python)=24089.51171875MB; mem (CPU total)=23755.546875MB
INFO:root:[  115] Training loss: 0.65522695, Validation loss: 0.63557675, Gradient norm: 1.05190980
INFO:root:At the start of the epoch: mem (CPU python)=24125.45703125MB; mem (CPU total)=23847.96875MB
INFO:root:[  116] Training loss: 0.65534519, Validation loss: 0.63578984, Gradient norm: 1.05172803
INFO:root:At the start of the epoch: mem (CPU python)=24140.703125MB; mem (CPU total)=23886.12109375MB
INFO:root:[  117] Training loss: 0.65512317, Validation loss: 0.63507738, Gradient norm: 1.13962403
INFO:root:At the start of the epoch: mem (CPU python)=24198.984375MB; mem (CPU total)=23924.51171875MB
INFO:root:[  118] Training loss: 0.65532035, Validation loss: 0.63424921, Gradient norm: 1.12382968
INFO:root:At the start of the epoch: mem (CPU python)=24216.8984375MB; mem (CPU total)=23962.83203125MB
INFO:root:[  119] Training loss: 0.65527173, Validation loss: 0.63537212, Gradient norm: 1.16491729
INFO:root:At the start of the epoch: mem (CPU python)=24254.9921875MB; mem (CPU total)=24000.44921875MB
INFO:root:[  120] Training loss: 0.65526585, Validation loss: 0.63490607, Gradient norm: 1.11186270
INFO:root:At the start of the epoch: mem (CPU python)=24316.609375MB; mem (CPU total)=24038.58984375MB
INFO:root:[  121] Training loss: 0.65529550, Validation loss: 0.63486771, Gradient norm: 1.09210168
INFO:root:At the start of the epoch: mem (CPU python)=24356.18359375MB; mem (CPU total)=24027.54296875MB
INFO:root:[  122] Training loss: 0.65539340, Validation loss: 0.63510987, Gradient norm: 1.11518980
INFO:root:At the start of the epoch: mem (CPU python)=24369.27734375MB; mem (CPU total)=24114.88671875MB
INFO:root:[  123] Training loss: 0.65520966, Validation loss: 0.63494324, Gradient norm: 1.18756951
INFO:root:At the start of the epoch: mem (CPU python)=24432.33984375MB; mem (CPU total)=24099.0703125MB
INFO:root:[  124] Training loss: 0.65532330, Validation loss: 0.63546111, Gradient norm: 1.18320917
INFO:root:At the start of the epoch: mem (CPU python)=24467.09375MB; mem (CPU total)=24190.56640625MB
INFO:root:[  125] Training loss: 0.65520401, Validation loss: 0.63526395, Gradient norm: 1.16637103
INFO:root:At the start of the epoch: mem (CPU python)=24507.5546875MB; mem (CPU total)=24197.90625MB
INFO:root:[  126] Training loss: 0.65532664, Validation loss: 0.63505980, Gradient norm: 1.13756315
INFO:root:At the start of the epoch: mem (CPU python)=24521.66015625MB; mem (CPU total)=24266.1875MB
INFO:root:[  127] Training loss: 0.65510422, Validation loss: 0.63478919, Gradient norm: 1.17690547
INFO:root:At the start of the epoch: mem (CPU python)=24559.7578125MB; mem (CPU total)=24304.03515625MB
INFO:root:EP 127: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=24617.2734375MB; mem (CPU total)=24342.421875MB
INFO:root:Training the model took 7855.319s.
INFO:root:Emptying the cuda cache took 0.03s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.89951
INFO:root:EnergyScoreTrain: 0.63302
INFO:root:CRPSTrain: 0.50652
INFO:root:Gaussian NLLTrain: 2374447958.18666
INFO:root:CoverageTrain: 0.83479
INFO:root:IntervalWidthTrain: 3.11148
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.90245
INFO:root:EnergyScoreValidation: 0.63512
INFO:root:CRPSValidation: 0.50867
INFO:root:Gaussian NLLValidation: 2406836188.72889
INFO:root:CoverageValidation: 0.83433
INFO:root:IntervalWidthValidation: 3.11373
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.90459
INFO:root:EnergyScoreTest: 0.63662
INFO:root:CRPSTest: 0.51033
INFO:root:Gaussian NLLTest: 2480528089.088
INFO:root:CoverageTest: 0.83414
INFO:root:IntervalWidthTest: 3.11665
INFO:root:After validation: mem (CPU python)=24660.80078125MB; mem (CPU total)=24364.66796875MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=24660.80078125MB; mem (CPU total)=24364.65625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=24660.80078125MB; mem (CPU total)=24364.65625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=24660.80078125MB; mem (CPU total)=24364.88671875MB
INFO:root:[    1] Training loss: 0.72617327, Validation loss: 0.72166614, Gradient norm: 0.02231472
INFO:root:At the start of the epoch: mem (CPU python)=24729.33203125MB; mem (CPU total)=24474.11328125MB
INFO:root:[    2] Training loss: 0.72068741, Validation loss: 0.71905972, Gradient norm: 0.00647698
INFO:root:At the start of the epoch: mem (CPU python)=24791.71484375MB; mem (CPU total)=24413.82421875MB
INFO:root:[    3] Training loss: 0.71918342, Validation loss: 0.71783806, Gradient norm: 0.00839993
INFO:root:At the start of the epoch: mem (CPU python)=24830.5078125MB; mem (CPU total)=24576.078125MB
INFO:root:[    4] Training loss: 0.71650861, Validation loss: 0.71162184, Gradient norm: 0.01633177
INFO:root:At the start of the epoch: mem (CPU python)=24918.58203125MB; mem (CPU total)=24590.01953125MB
INFO:root:[    5] Training loss: 0.71189342, Validation loss: 0.70617692, Gradient norm: 0.02470474
INFO:root:At the start of the epoch: mem (CPU python)=24918.58203125MB; mem (CPU total)=24577.6875MB
INFO:root:[    6] Training loss: 0.70790433, Validation loss: 0.70114506, Gradient norm: 0.03163874
INFO:root:At the start of the epoch: mem (CPU python)=24944.7421875MB; mem (CPU total)=24616.03125MB
INFO:root:[    7] Training loss: 0.70429319, Validation loss: 0.69629932, Gradient norm: 0.03524978
INFO:root:At the start of the epoch: mem (CPU python)=24959.14453125MB; mem (CPU total)=24706.8359375MB
INFO:root:[    8] Training loss: 0.70115333, Validation loss: 0.69241061, Gradient norm: 0.03389287
INFO:root:At the start of the epoch: mem (CPU python)=25045.98046875MB; mem (CPU total)=24794.6484375MB
INFO:root:[    9] Training loss: 0.69842681, Validation loss: 0.68980025, Gradient norm: 0.03528303
INFO:root:At the start of the epoch: mem (CPU python)=25055.33984375MB; mem (CPU total)=24780.8203125MB
INFO:root:[   10] Training loss: 0.69586204, Validation loss: 0.68709304, Gradient norm: 0.03964718
INFO:root:At the start of the epoch: mem (CPU python)=25122.17578125MB; mem (CPU total)=24868.8515625MB
INFO:root:[   11] Training loss: 0.69365726, Validation loss: 0.68375185, Gradient norm: 0.04124549
INFO:root:At the start of the epoch: mem (CPU python)=25131.43359375MB; mem (CPU total)=24757.44140625MB
INFO:root:[   12] Training loss: 0.69169196, Validation loss: 0.68149819, Gradient norm: 0.04056115
INFO:root:At the start of the epoch: mem (CPU python)=25221.92578125MB; mem (CPU total)=24895.4140625MB
INFO:root:[   13] Training loss: 0.68976163, Validation loss: 0.67854673, Gradient norm: 0.03965971
INFO:root:At the start of the epoch: mem (CPU python)=25221.92578125MB; mem (CPU total)=24834.2109375MB
INFO:root:[   14] Training loss: 0.68818133, Validation loss: 0.67729459, Gradient norm: 0.04067599
INFO:root:At the start of the epoch: mem (CPU python)=25223.62109375MB; mem (CPU total)=24946.96484375MB
INFO:root:[   15] Training loss: 0.68649452, Validation loss: 0.67392050, Gradient norm: 0.03978788
INFO:root:At the start of the epoch: mem (CPU python)=25309.0078125MB; mem (CPU total)=25011.734375MB
INFO:root:[   16] Training loss: 0.68502553, Validation loss: 0.67275219, Gradient norm: 0.04056358
INFO:root:At the start of the epoch: mem (CPU python)=25309.0078125MB; mem (CPU total)=25052.09765625MB
INFO:root:[   17] Training loss: 0.68366618, Validation loss: 0.67101578, Gradient norm: 0.04359281
INFO:root:At the start of the epoch: mem (CPU python)=25413.81640625MB; mem (CPU total)=25041.56640625MB
INFO:root:[   18] Training loss: 0.68261654, Validation loss: 0.67036820, Gradient norm: 0.04863126
INFO:root:At the start of the epoch: mem (CPU python)=25413.81640625MB; mem (CPU total)=25051.36328125MB
INFO:root:[   19] Training loss: 0.68155538, Validation loss: 0.66849306, Gradient norm: 0.04932293
INFO:root:At the start of the epoch: mem (CPU python)=25490.03515625MB; mem (CPU total)=25164.78125MB
INFO:root:[   20] Training loss: 0.68065897, Validation loss: 0.66739092, Gradient norm: 0.05973658
INFO:root:At the start of the epoch: mem (CPU python)=25501.43359375MB; mem (CPU total)=25152.5078125MB
INFO:root:[   21] Training loss: 0.67922278, Validation loss: 0.66574657, Gradient norm: 0.05317636
INFO:root:At the start of the epoch: mem (CPU python)=25566.13671875MB; mem (CPU total)=25140.984375MB
INFO:root:[   22] Training loss: 0.67863876, Validation loss: 0.66537864, Gradient norm: 0.04970735
INFO:root:At the start of the epoch: mem (CPU python)=25566.13671875MB; mem (CPU total)=25280.37109375MB
INFO:root:[   23] Training loss: 0.67765169, Validation loss: 0.66407789, Gradient norm: 0.05798610
INFO:root:At the start of the epoch: mem (CPU python)=25617.4140625MB; mem (CPU total)=25368.48046875MB
INFO:root:[   24] Training loss: 0.67691255, Validation loss: 0.66253051, Gradient norm: 0.06999510
INFO:root:At the start of the epoch: mem (CPU python)=25655.515625MB; mem (CPU total)=25406.37890625MB
INFO:root:[   25] Training loss: 0.67616776, Validation loss: 0.66200216, Gradient norm: 0.05943293
INFO:root:At the start of the epoch: mem (CPU python)=25718.23828125MB; mem (CPU total)=25345.125MB
INFO:root:[   26] Training loss: 0.67525790, Validation loss: 0.66008773, Gradient norm: 0.05960396
INFO:root:At the start of the epoch: mem (CPU python)=25718.23828125MB; mem (CPU total)=25330.640625MB
INFO:root:[   27] Training loss: 0.67467736, Validation loss: 0.66033809, Gradient norm: 0.06990257
INFO:root:At the start of the epoch: mem (CPU python)=25766.0546875MB; mem (CPU total)=25469.9453125MB
INFO:root:[   28] Training loss: 0.67406319, Validation loss: 0.65962430, Gradient norm: 0.06849982
INFO:root:At the start of the epoch: mem (CPU python)=25807.89453125MB; mem (CPU total)=25558.0546875MB
INFO:root:[   29] Training loss: 0.67352807, Validation loss: 0.65896665, Gradient norm: 0.06787949
INFO:root:At the start of the epoch: mem (CPU python)=25820.98828125MB; mem (CPU total)=25571.6640625MB
INFO:root:[   30] Training loss: 0.67285496, Validation loss: 0.65741833, Gradient norm: 0.07535028
INFO:root:At the start of the epoch: mem (CPU python)=25884.0859375MB; mem (CPU total)=25634.5234375MB
INFO:root:[   31] Training loss: 0.67236028, Validation loss: 0.65688486, Gradient norm: 0.07129721
INFO:root:At the start of the epoch: mem (CPU python)=25944.609375MB; mem (CPU total)=25670.90625MB
INFO:root:[   32] Training loss: 0.67172123, Validation loss: 0.65717157, Gradient norm: 0.08280639
INFO:root:At the start of the epoch: mem (CPU python)=25974.02734375MB; mem (CPU total)=25724.2421875MB
INFO:root:[   33] Training loss: 0.67138281, Validation loss: 0.65659252, Gradient norm: 0.07910325
INFO:root:At the start of the epoch: mem (CPU python)=25974.25MB; mem (CPU total)=25647.21484375MB
INFO:root:[   34] Training loss: 0.67071831, Validation loss: 0.65645928, Gradient norm: 0.08898939
INFO:root:At the start of the epoch: mem (CPU python)=26034.6796875MB; mem (CPU total)=25735.5078125MB
INFO:root:[   35] Training loss: 0.67027187, Validation loss: 0.65545217, Gradient norm: 0.11303836
INFO:root:At the start of the epoch: mem (CPU python)=26034.6796875MB; mem (CPU total)=25674.0078125MB
INFO:root:[   36] Training loss: 0.67002952, Validation loss: 0.65610828, Gradient norm: 0.10367668
INFO:root:At the start of the epoch: mem (CPU python)=26087.65625MB; mem (CPU total)=25838.69921875MB
INFO:root:[   37] Training loss: 0.66951294, Validation loss: 0.65605139, Gradient norm: 0.08144721
INFO:root:At the start of the epoch: mem (CPU python)=26150.23828125MB; mem (CPU total)=25751.23046875MB
INFO:root:[   38] Training loss: 0.66910822, Validation loss: 0.65425241, Gradient norm: 0.10160925
INFO:root:At the start of the epoch: mem (CPU python)=26163.46484375MB; mem (CPU total)=25863.41796875MB
INFO:root:[   39] Training loss: 0.66871912, Validation loss: 0.65480679, Gradient norm: 0.08940906
INFO:root:At the start of the epoch: mem (CPU python)=26226.40625MB; mem (CPU total)=25904.01953125MB
INFO:root:[   40] Training loss: 0.66831243, Validation loss: 0.65370432, Gradient norm: 0.10602017
INFO:root:At the start of the epoch: mem (CPU python)=26263.62109375MB; mem (CPU total)=25991.26953125MB
INFO:root:[   41] Training loss: 0.66797904, Validation loss: 0.65385682, Gradient norm: 0.12846260
INFO:root:At the start of the epoch: mem (CPU python)=26263.62109375MB; mem (CPU total)=25903.55859375MB
INFO:root:[   42] Training loss: 0.66740552, Validation loss: 0.65381264, Gradient norm: 0.11432106
INFO:root:At the start of the epoch: mem (CPU python)=26316.23046875MB; mem (CPU total)=26065.50390625MB
INFO:root:[   43] Training loss: 0.66728464, Validation loss: 0.65241581, Gradient norm: 0.11974373
INFO:root:At the start of the epoch: mem (CPU python)=26404.32421875MB; mem (CPU total)=26153.8125MB
INFO:root:[   44] Training loss: 0.66694493, Validation loss: 0.65340747, Gradient norm: 0.11989921
INFO:root:At the start of the epoch: mem (CPU python)=26404.3671875MB; mem (CPU total)=26092.57421875MB
INFO:root:[   45] Training loss: 0.66674160, Validation loss: 0.65281861, Gradient norm: 0.13128659
INFO:root:At the start of the epoch: mem (CPU python)=26478.07421875MB; mem (CPU total)=26180.828125MB
INFO:root:[   46] Training loss: 0.66644407, Validation loss: 0.65296788, Gradient norm: 0.13355056
INFO:root:At the start of the epoch: mem (CPU python)=26491.171875MB; mem (CPU total)=26218.92578125MB
INFO:root:[   47] Training loss: 0.66628310, Validation loss: 0.65047171, Gradient norm: 0.13955496
INFO:root:At the start of the epoch: mem (CPU python)=26606.70703125MB; mem (CPU total)=26357.1875MB
INFO:root:[   48] Training loss: 0.66576954, Validation loss: 0.65171465, Gradient norm: 0.17460573
INFO:root:At the start of the epoch: mem (CPU python)=26644.8046875MB; mem (CPU total)=26395.5234375MB
INFO:root:[   49] Training loss: 0.66560237, Validation loss: 0.65119369, Gradient norm: 0.13853279
INFO:root:At the start of the epoch: mem (CPU python)=26645.56640625MB; mem (CPU total)=26358.2734375MB
INFO:root:[   50] Training loss: 0.66526088, Validation loss: 0.65216281, Gradient norm: 0.14498790
INFO:root:At the start of the epoch: mem (CPU python)=26645.56640625MB; mem (CPU total)=26247.578125MB
INFO:root:[   51] Training loss: 0.66506584, Validation loss: 0.65079573, Gradient norm: 0.14987382
INFO:root:At the start of the epoch: mem (CPU python)=26659.08984375MB; mem (CPU total)=26409.5MB
INFO:root:[   52] Training loss: 0.66500563, Validation loss: 0.65039912, Gradient norm: 0.18648091
INFO:root:At the start of the epoch: mem (CPU python)=26718.515625MB; mem (CPU total)=26423.06640625MB
INFO:root:[   53] Training loss: 0.66470512, Validation loss: 0.65003829, Gradient norm: 0.19767152
INFO:root:At the start of the epoch: mem (CPU python)=26718.515625MB; mem (CPU total)=26462.78515625MB
INFO:root:[   54] Training loss: 0.66464936, Validation loss: 0.64906927, Gradient norm: 0.20899413
INFO:root:At the start of the epoch: mem (CPU python)=26822.8515625MB; mem (CPU total)=26526.13671875MB
INFO:root:[   55] Training loss: 0.66432075, Validation loss: 0.65129376, Gradient norm: 0.19273167
INFO:root:At the start of the epoch: mem (CPU python)=26822.8515625MB; mem (CPU total)=26564.421875MB
INFO:root:[   56] Training loss: 0.66397216, Validation loss: 0.65079301, Gradient norm: 0.17136259
INFO:root:At the start of the epoch: mem (CPU python)=26874.54296875MB; mem (CPU total)=26554.80859375MB
INFO:root:[   57] Training loss: 0.66389794, Validation loss: 0.64988285, Gradient norm: 0.20092385
INFO:root:At the start of the epoch: mem (CPU python)=26936.16015625MB; mem (CPU total)=26616.9375MB
INFO:root:[   58] Training loss: 0.66363488, Validation loss: 0.65048560, Gradient norm: 0.18685336
INFO:root:At the start of the epoch: mem (CPU python)=26950.7578125MB; mem (CPU total)=26704.9921875MB
INFO:root:[   59] Training loss: 0.66373983, Validation loss: 0.65108809, Gradient norm: 0.23432633
INFO:root:At the start of the epoch: mem (CPU python)=26951.20703125MB; mem (CPU total)=26591.5625MB
INFO:root:[   60] Training loss: 0.66328765, Validation loss: 0.64976771, Gradient norm: 0.23147119
INFO:root:At the start of the epoch: mem (CPU python)=26976.9453125MB; mem (CPU total)=26728.1796875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   61] Training loss: 0.66318544, Validation loss: 0.64759146, Gradient norm: 0.23521981
INFO:root:At the start of the epoch: mem (CPU python)=27038.23046875MB; mem (CPU total)=26741.08984375MB
INFO:root:[   62] Training loss: 0.66224088, Validation loss: 0.64771563, Gradient norm: 0.17452857
INFO:root:At the start of the epoch: mem (CPU python)=27126.0MB; mem (CPU total)=26829.9765625MB
INFO:root:[   63] Training loss: 0.66224604, Validation loss: 0.64817457, Gradient norm: 0.20925622
INFO:root:At the start of the epoch: mem (CPU python)=27126.0MB; mem (CPU total)=26867.88671875MB
INFO:root:[   64] Training loss: 0.66188287, Validation loss: 0.64879629, Gradient norm: 0.19195228
INFO:root:At the start of the epoch: mem (CPU python)=27177.2109375MB; mem (CPU total)=26881.32421875MB
INFO:root:[   65] Training loss: 0.66203261, Validation loss: 0.64641308, Gradient norm: 0.21046673
INFO:root:At the start of the epoch: mem (CPU python)=27193.6796875MB; mem (CPU total)=26947.76171875MB
INFO:root:[   66] Training loss: 0.66195953, Validation loss: 0.64807195, Gradient norm: 0.21459074
INFO:root:At the start of the epoch: mem (CPU python)=27255.5234375MB; mem (CPU total)=27007.6640625MB
INFO:root:[   67] Training loss: 0.66186309, Validation loss: 0.64739133, Gradient norm: 0.23513632
INFO:root:At the start of the epoch: mem (CPU python)=27255.5234375MB; mem (CPU total)=26896.25MB
INFO:root:[   68] Training loss: 0.66184097, Validation loss: 0.64774078, Gradient norm: 0.23072302
INFO:root:At the start of the epoch: mem (CPU python)=27306.71484375MB; mem (CPU total)=27058.16796875MB
INFO:root:[   69] Training loss: 0.66160473, Validation loss: 0.64716346, Gradient norm: 0.24437432
INFO:root:At the start of the epoch: mem (CPU python)=27369.80859375MB; mem (CPU total)=27121.35546875MB
INFO:root:[   70] Training loss: 0.66168822, Validation loss: 0.64635203, Gradient norm: 0.22594245
INFO:root:At the start of the epoch: mem (CPU python)=27432.7109375MB; mem (CPU total)=27110.29296875MB
INFO:root:[   71] Training loss: 0.66164428, Validation loss: 0.64721258, Gradient norm: 0.23958198
INFO:root:At the start of the epoch: mem (CPU python)=27432.7109375MB; mem (CPU total)=27072.078125MB
INFO:root:[   72] Training loss: 0.66151330, Validation loss: 0.64705034, Gradient norm: 0.25142060
INFO:root:At the start of the epoch: mem (CPU python)=27459.09375MB; mem (CPU total)=27210.2890625MB
INFO:root:[   73] Training loss: 0.66152373, Validation loss: 0.64570762, Gradient norm: 0.25319264
INFO:root:At the start of the epoch: mem (CPU python)=27497.19140625MB; mem (CPU total)=27248.66015625MB
INFO:root:[   74] Training loss: 0.66153424, Validation loss: 0.64715517, Gradient norm: 0.29115811
INFO:root:At the start of the epoch: mem (CPU python)=27535.28515625MB; mem (CPU total)=27288.31640625MB
INFO:root:[   75] Training loss: 0.66137875, Validation loss: 0.64591938, Gradient norm: 0.29326225
INFO:root:At the start of the epoch: mem (CPU python)=27623.3828125MB; mem (CPU total)=27376.6484375MB
INFO:root:[   76] Training loss: 0.66139204, Validation loss: 0.64580115, Gradient norm: 0.32854085
INFO:root:At the start of the epoch: mem (CPU python)=27623.60546875MB; mem (CPU total)=27288.97265625MB
INFO:root:[   77] Training loss: 0.66114002, Validation loss: 0.64429697, Gradient norm: 0.29721921
INFO:root:At the start of the epoch: mem (CPU python)=27647.15234375MB; mem (CPU total)=27376.8125MB
INFO:root:[   78] Training loss: 0.66116413, Validation loss: 0.64458876, Gradient norm: 0.32877055
INFO:root:At the start of the epoch: mem (CPU python)=27687.66796875MB; mem (CPU total)=27439.8515625MB
INFO:root:[   79] Training loss: 0.66109255, Validation loss: 0.64589910, Gradient norm: 0.31932823
INFO:root:At the start of the epoch: mem (CPU python)=27700.76171875MB; mem (CPU total)=27455.0MB
INFO:root:[   80] Training loss: 0.66108519, Validation loss: 0.64392259, Gradient norm: 0.33538238
INFO:root:At the start of the epoch: mem (CPU python)=27788.859375MB; mem (CPU total)=27466.8515625MB
INFO:root:[   81] Training loss: 0.66103572, Validation loss: 0.64457190, Gradient norm: 0.33673721
INFO:root:At the start of the epoch: mem (CPU python)=27826.44921875MB; mem (CPU total)=27529.2734375MB
INFO:root:[   82] Training loss: 0.66091676, Validation loss: 0.64450973, Gradient norm: 0.34911151
INFO:root:At the start of the epoch: mem (CPU python)=27865.05078125MB; mem (CPU total)=31071.19921875MB
INFO:root:[   83] Training loss: 0.66082442, Validation loss: 0.64506561, Gradient norm: 0.33802505
INFO:root:At the start of the epoch: mem (CPU python)=27895.52734375MB; mem (CPU total)=31125.4921875MB
INFO:root:[   84] Training loss: 0.66072679, Validation loss: 0.64440762, Gradient norm: 0.34601584
INFO:root:At the start of the epoch: mem (CPU python)=27940.5MB; mem (CPU total)=31206.5625MB
INFO:root:[   85] Training loss: 0.66064017, Validation loss: 0.64382363, Gradient norm: 0.39156238
INFO:root:At the start of the epoch: mem (CPU python)=27955.5859375MB; mem (CPU total)=31361.671875MB
INFO:root:[   86] Training loss: 0.66055727, Validation loss: 0.64412453, Gradient norm: 0.37996896
INFO:root:At the start of the epoch: mem (CPU python)=28015.58984375MB; mem (CPU total)=31414.38671875MB
INFO:root:[   87] Training loss: 0.66067332, Validation loss: 0.64404252, Gradient norm: 0.40784271
INFO:root:At the start of the epoch: mem (CPU python)=28030.5234375MB; mem (CPU total)=31570.87109375MB
INFO:root:[   88] Training loss: 0.66058721, Validation loss: 0.64354557, Gradient norm: 0.38528607
INFO:root:At the start of the epoch: mem (CPU python)=28030.65234375MB; mem (CPU total)=31575.3203125MB
INFO:root:[   89] Training loss: 0.66032566, Validation loss: 0.64385236, Gradient norm: 0.37891074
INFO:root:At the start of the epoch: mem (CPU python)=28131.71875MB; mem (CPU total)=31807.62890625MB
INFO:root:[   90] Training loss: 0.66040580, Validation loss: 0.64357260, Gradient norm: 0.41406865
INFO:root:At the start of the epoch: mem (CPU python)=28169.8125MB; mem (CPU total)=31913.90625MB
INFO:root:[   91] Training loss: 0.66053742, Validation loss: 0.64343421, Gradient norm: 0.42488319
INFO:root:At the start of the epoch: mem (CPU python)=28200.88671875MB; mem (CPU total)=31898.36328125MB
INFO:root:[   92] Training loss: 0.66049977, Validation loss: 0.64394283, Gradient norm: 0.44451181
INFO:root:At the start of the epoch: mem (CPU python)=28270.9921875MB; mem (CPU total)=32055.08984375MB
INFO:root:[   93] Training loss: 0.66020871, Validation loss: 0.64310319, Gradient norm: 0.42017706
INFO:root:At the start of the epoch: mem (CPU python)=28281.59375MB; mem (CPU total)=32108.73046875MB
INFO:root:[   94] Training loss: 0.66042795, Validation loss: 0.64261935, Gradient norm: 0.45786849
INFO:root:At the start of the epoch: mem (CPU python)=28295.6015625MB; mem (CPU total)=32293.41015625MB
INFO:root:[   95] Training loss: 0.66035283, Validation loss: 0.64203229, Gradient norm: 0.49817519
INFO:root:At the start of the epoch: mem (CPU python)=28310.10546875MB; mem (CPU total)=32297.16796875MB
INFO:root:[   96] Training loss: 0.66016321, Validation loss: 0.64368229, Gradient norm: 0.47186989
INFO:root:At the start of the epoch: mem (CPU python)=28323.3828125MB; mem (CPU total)=32478.12890625MB
INFO:root:[   97] Training loss: 0.65999170, Validation loss: 0.64219507, Gradient norm: 0.48247552
INFO:root:At the start of the epoch: mem (CPU python)=28436.484375MB; mem (CPU total)=32659.6015625MB
INFO:root:[   98] Training loss: 0.65993876, Validation loss: 0.64281089, Gradient norm: 0.52161914
INFO:root:At the start of the epoch: mem (CPU python)=28474.578125MB; mem (CPU total)=32765.8515625MB
INFO:root:[   99] Training loss: 0.66011481, Validation loss: 0.64265545, Gradient norm: 0.48066056
INFO:root:At the start of the epoch: mem (CPU python)=28512.67578125MB; mem (CPU total)=32872.875MB
INFO:root:[  100] Training loss: 0.66013670, Validation loss: 0.64312318, Gradient norm: 0.50633737
INFO:root:At the start of the epoch: mem (CPU python)=28550.76953125MB; mem (CPU total)=32978.0859375MB
INFO:root:[  101] Training loss: 0.65994966, Validation loss: 0.64249279, Gradient norm: 0.58345288
INFO:root:At the start of the epoch: mem (CPU python)=28588.86328125MB; mem (CPU total)=33083.30078125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  102] Training loss: 0.65978174, Validation loss: 0.64202948, Gradient norm: 0.51242832
INFO:root:At the start of the epoch: mem (CPU python)=28601.95703125MB; mem (CPU total)=33088.5390625MB
INFO:root:[  103] Training loss: 0.65909340, Validation loss: 0.64245036, Gradient norm: 0.43911165
INFO:root:At the start of the epoch: mem (CPU python)=28665.0546875MB; mem (CPU total)=33295.8125MB
INFO:root:[  104] Training loss: 0.65916605, Validation loss: 0.64201465, Gradient norm: 0.46691052
INFO:root:At the start of the epoch: mem (CPU python)=28703.15234375MB; mem (CPU total)=33399.19921875MB
INFO:root:[  105] Training loss: 0.65931926, Validation loss: 0.64148690, Gradient norm: 0.44764187
INFO:root:At the start of the epoch: mem (CPU python)=28741.16015625MB; mem (CPU total)=33429.234375MB
INFO:root:[  106] Training loss: 0.65917116, Validation loss: 0.64183904, Gradient norm: 0.50191655
INFO:root:At the start of the epoch: mem (CPU python)=28741.16015625MB; mem (CPU total)=33559.578125MB
INFO:root:[  107] Training loss: 0.65921847, Validation loss: 0.64178957, Gradient norm: 0.45972306
INFO:root:At the start of the epoch: mem (CPU python)=28792.44140625MB; mem (CPU total)=33691.29296875MB
INFO:root:[  108] Training loss: 0.65921311, Validation loss: 0.64169390, Gradient norm: 0.47247517
INFO:root:At the start of the epoch: mem (CPU python)=28827.96875MB; mem (CPU total)=33745.5390625MB
INFO:root:[  109] Training loss: 0.65922308, Validation loss: 0.64153457, Gradient norm: 0.53547943
INFO:root:At the start of the epoch: mem (CPU python)=28866.12890625MB; mem (CPU total)=33776.18359375MB
INFO:root:[  110] Training loss: 0.65939606, Validation loss: 0.64133800, Gradient norm: 0.52138244
INFO:root:At the start of the epoch: mem (CPU python)=28929.4296875MB; mem (CPU total)=33879.83984375MB
INFO:root:[  111] Training loss: 0.65922563, Validation loss: 0.64206356, Gradient norm: 0.53204588
INFO:root:At the start of the epoch: mem (CPU python)=28929.4296875MB; mem (CPU total)=34085.76171875MB
INFO:root:[  112] Training loss: 0.65914874, Validation loss: 0.64138581, Gradient norm: 0.54479426
INFO:root:At the start of the epoch: mem (CPU python)=28957.91796875MB; mem (CPU total)=34192.015625MB
INFO:root:[  113] Training loss: 0.65904166, Validation loss: 0.64171226, Gradient norm: 0.58244893
INFO:root:At the start of the epoch: mem (CPU python)=29019.609375MB; mem (CPU total)=34293.59375MB
INFO:root:[  114] Training loss: 0.65900792, Validation loss: 0.64103611, Gradient norm: 0.54205728
INFO:root:At the start of the epoch: mem (CPU python)=29083.9140625MB; mem (CPU total)=34372.2265625MB
INFO:root:[  115] Training loss: 0.65902843, Validation loss: 0.64227232, Gradient norm: 0.58603210
INFO:root:At the start of the epoch: mem (CPU python)=29096.52734375MB; mem (CPU total)=34477.125MB
INFO:root:[  116] Training loss: 0.65902441, Validation loss: 0.64178170, Gradient norm: 0.64917485
INFO:root:At the start of the epoch: mem (CPU python)=29183.5078125MB; mem (CPU total)=34581.14453125MB
INFO:root:[  117] Training loss: 0.65909654, Validation loss: 0.64118651, Gradient norm: 0.59584819
INFO:root:At the start of the epoch: mem (CPU python)=29183.5078125MB; mem (CPU total)=34609.32421875MB
INFO:root:[  118] Training loss: 0.65920291, Validation loss: 0.64114502, Gradient norm: 0.60194133
INFO:root:At the start of the epoch: mem (CPU python)=29186.48828125MB; mem (CPU total)=34812.0546875MB
INFO:root:[  119] Training loss: 0.65924394, Validation loss: 0.64132004, Gradient norm: 0.62762351
INFO:root:At the start of the epoch: mem (CPU python)=29221.046875MB; mem (CPU total)=34893.08203125MB
INFO:root:[  120] Training loss: 0.65923051, Validation loss: 0.64097626, Gradient norm: 0.63379813
INFO:root:At the start of the epoch: mem (CPU python)=29285.94921875MB; mem (CPU total)=34995.6171875MB
INFO:root:[  121] Training loss: 0.65897735, Validation loss: 0.64112776, Gradient norm: 0.69302842
INFO:root:At the start of the epoch: mem (CPU python)=29375.7734375MB; mem (CPU total)=35198.828125MB
INFO:root:[  122] Training loss: 0.65913502, Validation loss: 0.64174886, Gradient norm: 0.65640714
INFO:root:At the start of the epoch: mem (CPU python)=29413.875MB; mem (CPU total)=35301.6640625MB
INFO:root:[  123] Training loss: 0.65914607, Validation loss: 0.64058264, Gradient norm: 0.65655352
INFO:root:At the start of the epoch: mem (CPU python)=29451.96875MB; mem (CPU total)=35407.19921875MB
INFO:root:[  124] Training loss: 0.65903545, Validation loss: 0.64095824, Gradient norm: 0.66108041
INFO:root:At the start of the epoch: mem (CPU python)=29465.0625MB; mem (CPU total)=35484.23828125MB
INFO:root:[  125] Training loss: 0.65910437, Validation loss: 0.64107416, Gradient norm: 0.69630393
INFO:root:At the start of the epoch: mem (CPU python)=29478.15625MB; mem (CPU total)=35561.734375MB
INFO:root:[  126] Training loss: 0.65901177, Validation loss: 0.64091586, Gradient norm: 0.70545598
INFO:root:At the start of the epoch: mem (CPU python)=29509.01171875MB; mem (CPU total)=35644.3515625MB
INFO:root:[  127] Training loss: 0.65911609, Validation loss: 0.64116321, Gradient norm: 0.74256526
INFO:root:At the start of the epoch: mem (CPU python)=29554.1328125MB; mem (CPU total)=35698.8828125MB
INFO:root:[  128] Training loss: 0.65906988, Validation loss: 0.64155036, Gradient norm: 0.73524587
INFO:root:At the start of the epoch: mem (CPU python)=29588.04296875MB; mem (CPU total)=35849.73046875MB
INFO:root:[  129] Training loss: 0.65897821, Validation loss: 0.64073269, Gradient norm: 0.71144234
INFO:root:At the start of the epoch: mem (CPU python)=29655.48046875MB; mem (CPU total)=35905.828125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  130] Training loss: 0.65880863, Validation loss: 0.64111767, Gradient norm: 0.70678880
INFO:root:At the start of the epoch: mem (CPU python)=29718.45703125MB; mem (CPU total)=36007.875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  131] Training loss: 0.65853659, Validation loss: 0.64063307, Gradient norm: 0.60731420
INFO:root:At the start of the epoch: mem (CPU python)=29718.45703125MB; mem (CPU total)=36158.203125MB
INFO:root:[  132] Training loss: 0.65852522, Validation loss: 0.64051039, Gradient norm: 0.53383608
INFO:root:At the start of the epoch: mem (CPU python)=29719.6484375MB; mem (CPU total)=36158.734375MB
INFO:root:[  133] Training loss: 0.65847569, Validation loss: 0.64015457, Gradient norm: 0.54729966
INFO:root:At the start of the epoch: mem (CPU python)=29782.921875MB; mem (CPU total)=36387.95703125MB
INFO:root:[  134] Training loss: 0.65822593, Validation loss: 0.64036831, Gradient norm: 0.54940324
INFO:root:At the start of the epoch: mem (CPU python)=29870.98046875MB; mem (CPU total)=36440.21484375MB
INFO:root:[  135] Training loss: 0.65819054, Validation loss: 0.64107040, Gradient norm: 0.56604992
INFO:root:At the start of the epoch: mem (CPU python)=29909.109375MB; mem (CPU total)=36640.0234375MB
INFO:root:[  136] Training loss: 0.65834039, Validation loss: 0.64034279, Gradient norm: 0.56766795
INFO:root:At the start of the epoch: mem (CPU python)=29941.37890625MB; mem (CPU total)=36669.70703125MB
INFO:root:[  137] Training loss: 0.65829542, Validation loss: 0.64047535, Gradient norm: 0.60410212
INFO:root:At the start of the epoch: mem (CPU python)=29941.37890625MB; mem (CPU total)=36720.37890625MB
INFO:root:[  138] Training loss: 0.65823951, Validation loss: 0.64062444, Gradient norm: 0.57036820
INFO:root:At the start of the epoch: mem (CPU python)=29972.4375MB; mem (CPU total)=36771.3515625MB
INFO:root:[  139] Training loss: 0.65826315, Validation loss: 0.64057199, Gradient norm: 0.60556169
INFO:root:At the start of the epoch: mem (CPU python)=30011.62890625MB; mem (CPU total)=36875.73828125MB
INFO:root:[  140] Training loss: 0.65820685, Validation loss: 0.64015174, Gradient norm: 0.60522676
INFO:root:At the start of the epoch: mem (CPU python)=30047.890625MB; mem (CPU total)=37024.91796875MB
INFO:root:[  141] Training loss: 0.65818081, Validation loss: 0.64053896, Gradient norm: 0.61330459
INFO:root:At the start of the epoch: mem (CPU python)=30187.68359375MB; mem (CPU total)=37299.91796875MB
INFO:root:[  142] Training loss: 0.65826653, Validation loss: 0.64080759, Gradient norm: 0.60889441
INFO:root:At the start of the epoch: mem (CPU python)=30187.68359375MB; mem (CPU total)=37304.359375MB
INFO:root:[  143] Training loss: 0.65834755, Validation loss: 0.64060814, Gradient norm: 0.60755635
INFO:root:At the start of the epoch: mem (CPU python)=30187.68359375MB; mem (CPU total)=37318.37109375MB
INFO:root:[  144] Training loss: 0.65834317, Validation loss: 0.64029799, Gradient norm: 0.60394135
INFO:root:At the start of the epoch: mem (CPU python)=30196.953125MB; mem (CPU total)=37478.4921875MB
INFO:root:[  145] Training loss: 0.65826052, Validation loss: 0.64077290, Gradient norm: 0.62816290
INFO:root:At the start of the epoch: mem (CPU python)=30265.0625MB; mem (CPU total)=37632.74609375MB
INFO:root:[  146] Training loss: 0.65821698, Validation loss: 0.64038800, Gradient norm: 0.63845970
INFO:root:At the start of the epoch: mem (CPU python)=30352.07421875MB; mem (CPU total)=37632.421875MB
INFO:root:[  147] Training loss: 0.65836608, Validation loss: 0.64076488, Gradient norm: 0.64323362
INFO:root:At the start of the epoch: mem (CPU python)=30352.07421875MB; mem (CPU total)=37783.7578125MB
INFO:root:[  148] Training loss: 0.65826110, Validation loss: 0.64050415, Gradient norm: 0.64101285
INFO:root:At the start of the epoch: mem (CPU python)=30354.14453125MB; mem (CPU total)=37835.1953125MB
INFO:root:[  149] Training loss: 0.65814548, Validation loss: 0.64038075, Gradient norm: 0.67200623
INFO:root:At the start of the epoch: mem (CPU python)=30367.4453125MB; mem (CPU total)=37982.60546875MB
INFO:root:EP 149: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=30402.7109375MB; mem (CPU total)=38002.55078125MB
INFO:root:Training the model took 10285.427s.
INFO:root:Emptying the cuda cache took 0.03s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.90413
INFO:root:EnergyScoreTrain: 0.63641
INFO:root:CRPSTrain: 0.50732
INFO:root:Gaussian NLLTrain: 8192.50603
INFO:root:CoverageTrain: 0.87624
INFO:root:IntervalWidthTrain: 3.1203
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.90965
INFO:root:EnergyScoreValidation: 0.64036
INFO:root:CRPSValidation: 0.5114
INFO:root:Gaussian NLLValidation: 3281.58813
INFO:root:CoverageValidation: 0.8746
INFO:root:IntervalWidthValidation: 3.12474
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.90973
INFO:root:EnergyScoreTest: 0.6404
INFO:root:CRPSTest: 0.51116
INFO:root:Gaussian NLLTest: 2315.84653
INFO:root:CoverageTest: 0.87502
INFO:root:IntervalWidthTest: 3.12615
INFO:root:After validation: mem (CPU python)=30436.0703125MB; mem (CPU total)=38146.828125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=30436.0703125MB; mem (CPU total)=38174.62890625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=30436.0703125MB; mem (CPU total)=38175.609375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=30436.0703125MB; mem (CPU total)=38208.1171875MB
INFO:root:[    1] Training loss: 0.72664145, Validation loss: 0.72105869, Gradient norm: 0.02310264
INFO:root:At the start of the epoch: mem (CPU python)=30566.06640625MB; mem (CPU total)=38424.73046875MB
INFO:root:[    2] Training loss: 0.72039511, Validation loss: 0.71932069, Gradient norm: 0.00706196
INFO:root:At the start of the epoch: mem (CPU python)=30596.5390625MB; mem (CPU total)=38496.91015625MB
INFO:root:[    3] Training loss: 0.71898748, Validation loss: 0.71723433, Gradient norm: 0.01421470
INFO:root:At the start of the epoch: mem (CPU python)=30642.2578125MB; mem (CPU total)=38501.3515625MB
INFO:root:[    4] Training loss: 0.71608280, Validation loss: 0.71053321, Gradient norm: 0.02192829
INFO:root:At the start of the epoch: mem (CPU python)=30642.2578125MB; mem (CPU total)=38612.46484375MB
INFO:root:[    5] Training loss: 0.71076301, Validation loss: 0.70359218, Gradient norm: 0.02878385
INFO:root:At the start of the epoch: mem (CPU python)=30718.4453125MB; mem (CPU total)=38824.4296875MB
INFO:root:[    6] Training loss: 0.70591311, Validation loss: 0.69807234, Gradient norm: 0.03654983
INFO:root:At the start of the epoch: mem (CPU python)=30780.59375MB; mem (CPU total)=38877.7890625MB
INFO:root:[    7] Training loss: 0.70180204, Validation loss: 0.69447906, Gradient norm: 0.03185887
INFO:root:At the start of the epoch: mem (CPU python)=30780.59375MB; mem (CPU total)=38898.25MB
INFO:root:[    8] Training loss: 0.69852663, Validation loss: 0.69086004, Gradient norm: 0.03948357
INFO:root:At the start of the epoch: mem (CPU python)=30780.59375MB; mem (CPU total)=38988.8515625MB
INFO:root:[    9] Training loss: 0.69555206, Validation loss: 0.68742458, Gradient norm: 0.04042336
INFO:root:At the start of the epoch: mem (CPU python)=30820.828125MB; mem (CPU total)=39172.890625MB
INFO:root:[   10] Training loss: 0.69291472, Validation loss: 0.68337483, Gradient norm: 0.03882196
INFO:root:At the start of the epoch: mem (CPU python)=30883.92578125MB; mem (CPU total)=39293.10546875MB
INFO:root:[   11] Training loss: 0.69070170, Validation loss: 0.68022975, Gradient norm: 0.03513612
INFO:root:At the start of the epoch: mem (CPU python)=30943.18359375MB; mem (CPU total)=39322.22265625MB
INFO:root:[   12] Training loss: 0.68898261, Validation loss: 0.67867548, Gradient norm: 0.04288603
INFO:root:At the start of the epoch: mem (CPU python)=30956.375MB; mem (CPU total)=39468.35546875MB
INFO:root:[   13] Training loss: 0.68740284, Validation loss: 0.67693982, Gradient norm: 0.04535103
INFO:root:At the start of the epoch: mem (CPU python)=30998.18359375MB; mem (CPU total)=39472.734375MB
INFO:root:[   14] Training loss: 0.68601944, Validation loss: 0.67617494, Gradient norm: 0.05049104
INFO:root:At the start of the epoch: mem (CPU python)=31036.03125MB; mem (CPU total)=39618.4296875MB
INFO:root:[   15] Training loss: 0.68486824, Validation loss: 0.67353804, Gradient norm: 0.06012177
INFO:root:At the start of the epoch: mem (CPU python)=31074.203125MB; mem (CPU total)=39715.37109375MB
INFO:root:[   16] Training loss: 0.68410197, Validation loss: 0.67231850, Gradient norm: 0.07481197
INFO:root:At the start of the epoch: mem (CPU python)=31136.30859375MB; mem (CPU total)=39792.93359375MB
INFO:root:[   17] Training loss: 0.68292076, Validation loss: 0.67118784, Gradient norm: 0.07238671
INFO:root:At the start of the epoch: mem (CPU python)=31150.59375MB; mem (CPU total)=39990.09375MB
INFO:root:[   18] Training loss: 0.68243884, Validation loss: 0.67029428, Gradient norm: 0.09027171
INFO:root:At the start of the epoch: mem (CPU python)=31213.6875MB; mem (CPU total)=40119.9765625MB
INFO:root:[   19] Training loss: 0.68152590, Validation loss: 0.66991664, Gradient norm: 0.09031156
INFO:root:At the start of the epoch: mem (CPU python)=31251.56640625MB; mem (CPU total)=40137.7265625MB
INFO:root:[   20] Training loss: 0.68102802, Validation loss: 0.66918504, Gradient norm: 0.13032733
INFO:root:At the start of the epoch: mem (CPU python)=31289.41796875MB; mem (CPU total)=40284.7890625MB
INFO:root:[   21] Training loss: 0.68033089, Validation loss: 0.67043772, Gradient norm: 0.15451241
INFO:root:At the start of the epoch: mem (CPU python)=31302.94140625MB; mem (CPU total)=40336.72265625MB
INFO:root:[   22] Training loss: 0.67987790, Validation loss: 0.67435412, Gradient norm: 0.16531258
INFO:root:At the start of the epoch: mem (CPU python)=31316.06640625MB; mem (CPU total)=40454.92578125MB
INFO:root:[   23] Training loss: 0.67929006, Validation loss: 0.67062245, Gradient norm: 0.21587144
INFO:root:At the start of the epoch: mem (CPU python)=31429.1640625MB; mem (CPU total)=40535.01953125MB
INFO:root:[   24] Training loss: 0.67892715, Validation loss: 0.67238894, Gradient norm: 0.26023848
INFO:root:At the start of the epoch: mem (CPU python)=31429.1640625MB; mem (CPU total)=40629.17578125MB
INFO:root:[   25] Training loss: 0.67846010, Validation loss: 0.67379610, Gradient norm: 0.25997579
INFO:root:At the start of the epoch: mem (CPU python)=31455.25390625MB; mem (CPU total)=40678.60546875MB
INFO:root:[   26] Training loss: 0.67801951, Validation loss: 0.67447194, Gradient norm: 0.29725285
INFO:root:At the start of the epoch: mem (CPU python)=31568.37890625MB; mem (CPU total)=40877.296875MB
INFO:root:[   27] Training loss: 0.67759388, Validation loss: 0.67750917, Gradient norm: 0.30910922
INFO:root:At the start of the epoch: mem (CPU python)=31606.546875MB; mem (CPU total)=41046.1796875MB
INFO:root:[   28] Training loss: 0.67704672, Validation loss: 0.68069310, Gradient norm: 0.30422643
INFO:root:At the start of the epoch: mem (CPU python)=31644.640625MB; mem (CPU total)=41148.7578125MB
INFO:root:[   29] Training loss: 0.67682039, Validation loss: 0.68105237, Gradient norm: 0.40152709
INFO:root:At the start of the epoch: mem (CPU python)=31645.09375MB; mem (CPU total)=41070.4765625MB
INFO:root:[   30] Training loss: 0.67641512, Validation loss: 0.68020306, Gradient norm: 0.42469602
INFO:root:At the start of the epoch: mem (CPU python)=31720.828125MB; mem (CPU total)=41348.31640625MB
INFO:root:[   31] Training loss: 0.67629324, Validation loss: 0.67520718, Gradient norm: 0.60216571
INFO:root:At the start of the epoch: mem (CPU python)=31721.0546875MB; mem (CPU total)=41340.94921875MB
INFO:root:[   32] Training loss: 0.67618117, Validation loss: 0.67896669, Gradient norm: 0.57764332
INFO:root:At the start of the epoch: mem (CPU python)=31797.01953125MB; mem (CPU total)=41539.7265625MB
INFO:root:[   33] Training loss: 0.67561192, Validation loss: 0.67168733, Gradient norm: 0.64328882
INFO:root:At the start of the epoch: mem (CPU python)=31797.359375MB; mem (CPU total)=41440.12109375MB
INFO:root:[   34] Training loss: 0.67532553, Validation loss: 0.67621319, Gradient norm: 0.65993710
INFO:root:At the start of the epoch: mem (CPU python)=31797.359375MB; mem (CPU total)=41633.55859375MB
INFO:root:[   35] Training loss: 0.67526323, Validation loss: 0.67582996, Gradient norm: 0.75543532
INFO:root:At the start of the epoch: mem (CPU python)=31836.30859375MB; mem (CPU total)=41761.078125MB
INFO:root:[   36] Training loss: 0.67498891, Validation loss: 0.67083592, Gradient norm: 0.78155059
INFO:root:At the start of the epoch: mem (CPU python)=31949.28125MB; mem (CPU total)=41780.7109375MB
INFO:root:[   37] Training loss: 0.67465336, Validation loss: 0.66794326, Gradient norm: 0.81071729
INFO:root:At the start of the epoch: mem (CPU python)=31949.28125MB; mem (CPU total)=41958.4609375MB
INFO:root:[   38] Training loss: 0.67482395, Validation loss: 0.66859636, Gradient norm: 0.95792267
INFO:root:At the start of the epoch: mem (CPU python)=31975.59375MB; mem (CPU total)=42076.69140625MB
INFO:root:[   39] Training loss: 0.67498665, Validation loss: 0.66875483, Gradient norm: 1.09422067
INFO:root:At the start of the epoch: mem (CPU python)=31988.6875MB; mem (CPU total)=42151.3203125MB
INFO:root:[   40] Training loss: 0.67477209, Validation loss: 0.66517764, Gradient norm: 1.09642760
INFO:root:At the start of the epoch: mem (CPU python)=32026.78515625MB; mem (CPU total)=42247.53125MB
INFO:root:[   41] Training loss: 0.67510881, Validation loss: 0.66192094, Gradient norm: 1.30962818
INFO:root:At the start of the epoch: mem (CPU python)=32064.8828125MB; mem (CPU total)=42342.03515625MB
INFO:root:[   42] Training loss: 0.67463064, Validation loss: 0.66176280, Gradient norm: 1.27545325
INFO:root:At the start of the epoch: mem (CPU python)=32127.9765625MB; mem (CPU total)=42466.58203125MB
INFO:root:[   43] Training loss: 0.67468078, Validation loss: 0.65998627, Gradient norm: 1.52441873
INFO:root:At the start of the epoch: mem (CPU python)=32141.0703125MB; mem (CPU total)=42533.421875MB
INFO:root:[   44] Training loss: 0.67438311, Validation loss: 0.66029831, Gradient norm: 1.47234110
INFO:root:At the start of the epoch: mem (CPU python)=32179.16796875MB; mem (CPU total)=42634.8125MB
INFO:root:[   45] Training loss: 0.67450474, Validation loss: 0.65827877, Gradient norm: 1.65014513
INFO:root:At the start of the epoch: mem (CPU python)=32192.17578125MB; mem (CPU total)=42571.38671875MB
INFO:root:[   46] Training loss: 0.67438209, Validation loss: 0.65903155, Gradient norm: 1.65993074
INFO:root:At the start of the epoch: mem (CPU python)=32255.35546875MB; mem (CPU total)=42747.28125MB
INFO:root:[   47] Training loss: 0.67447405, Validation loss: 0.65913485, Gradient norm: 1.82115080
INFO:root:At the start of the epoch: mem (CPU python)=32293.41796875MB; mem (CPU total)=42699.078125MB
INFO:root:[   48] Training loss: 0.67424247, Validation loss: 0.65785352, Gradient norm: 1.93895295
INFO:root:At the start of the epoch: mem (CPU python)=32318.82421875MB; mem (CPU total)=42752.16796875MB
INFO:root:[   49] Training loss: 0.67410808, Validation loss: 0.65867208, Gradient norm: 2.08299132
INFO:root:At the start of the epoch: mem (CPU python)=32369.640625MB; mem (CPU total)=42962.5859375MB
INFO:root:[   50] Training loss: 0.67406381, Validation loss: 0.65749396, Gradient norm: 2.16232467
INFO:root:At the start of the epoch: mem (CPU python)=32400.1171875MB; mem (CPU total)=42932.23046875MB
INFO:root:[   51] Training loss: 0.67421112, Validation loss: 0.65851891, Gradient norm: 2.23342728
INFO:root:At the start of the epoch: mem (CPU python)=32445.8359375MB; mem (CPU total)=43151.81640625MB
INFO:root:[   52] Training loss: 0.67399764, Validation loss: 0.65666745, Gradient norm: 2.27111037
INFO:root:At the start of the epoch: mem (CPU python)=32558.58984375MB; mem (CPU total)=43276.8515625MB
INFO:root:[   53] Training loss: 0.67450223, Validation loss: 0.65781500, Gradient norm: 2.63430431
INFO:root:At the start of the epoch: mem (CPU python)=32572.0234375MB; mem (CPU total)=43394.28125MB
INFO:root:[   54] Training loss: 0.67433116, Validation loss: 0.65983452, Gradient norm: 2.53159702
INFO:root:At the start of the epoch: mem (CPU python)=32608.60546875MB; mem (CPU total)=43446.171875MB
INFO:root:[   55] Training loss: 0.67449632, Validation loss: 0.65738420, Gradient norm: 2.78211149
INFO:root:At the start of the epoch: mem (CPU python)=32648.21484375MB; mem (CPU total)=43587.6328125MB
INFO:root:[   56] Training loss: 0.67444346, Validation loss: 0.65906068, Gradient norm: 2.89840521
INFO:root:At the start of the epoch: mem (CPU python)=32678.58984375MB; mem (CPU total)=43615.328125MB
INFO:root:[   57] Training loss: 0.67427431, Validation loss: 0.65898042, Gradient norm: 2.82307533
INFO:root:At the start of the epoch: mem (CPU python)=32678.58984375MB; mem (CPU total)=43679.5MB
INFO:root:[   58] Training loss: 0.67445058, Validation loss: 0.65699673, Gradient norm: 3.49404522
INFO:root:At the start of the epoch: mem (CPU python)=32711.0234375MB; mem (CPU total)=43806.30859375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   59] Training loss: 0.67464495, Validation loss: 0.65784238, Gradient norm: 3.19963224
INFO:root:At the start of the epoch: mem (CPU python)=32798.5MB; mem (CPU total)=43946.82421875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   60] Training loss: 0.67328297, Validation loss: 0.65723209, Gradient norm: 2.17219521
INFO:root:At the start of the epoch: mem (CPU python)=32806.07421875MB; mem (CPU total)=43951.2109375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   61] Training loss: 0.67280235, Validation loss: 0.65608403, Gradient norm: 2.04220024
INFO:root:At the start of the epoch: mem (CPU python)=32876.69921875MB; mem (CPU total)=44090.453125MB
INFO:root:[   62] Training loss: 0.67253026, Validation loss: 0.65607449, Gradient norm: 1.75043872
INFO:root:At the start of the epoch: mem (CPU python)=32889.8515625MB; mem (CPU total)=44167.06640625MB
INFO:root:[   63] Training loss: 0.67256921, Validation loss: 0.65642043, Gradient norm: 1.69058429
INFO:root:At the start of the epoch: mem (CPU python)=32889.8515625MB; mem (CPU total)=44256.3203125MB
INFO:root:[   64] Training loss: 0.67255388, Validation loss: 0.65640777, Gradient norm: 1.61058539
INFO:root:At the start of the epoch: mem (CPU python)=32988.7890625MB; mem (CPU total)=44360.37109375MB
INFO:root:[   65] Training loss: 0.67257774, Validation loss: 0.65558582, Gradient norm: 1.85361692
INFO:root:At the start of the epoch: mem (CPU python)=33028.9765625MB; mem (CPU total)=44474.37109375MB
INFO:root:[   66] Training loss: 0.67269966, Validation loss: 0.65653070, Gradient norm: 1.74616153
INFO:root:At the start of the epoch: mem (CPU python)=33028.9765625MB; mem (CPU total)=44501.703125MB
INFO:root:[   67] Training loss: 0.67253678, Validation loss: 0.65574384, Gradient norm: 2.01335875
INFO:root:At the start of the epoch: mem (CPU python)=33105.359375MB; mem (CPU total)=44740.296875MB
INFO:root:[   68] Training loss: 0.67245313, Validation loss: 0.65647608, Gradient norm: 1.93625626
INFO:root:At the start of the epoch: mem (CPU python)=33135.84375MB; mem (CPU total)=44793.23828125MB
INFO:root:[   69] Training loss: 0.67252806, Validation loss: 0.65597891, Gradient norm: 1.81400064
INFO:root:At the start of the epoch: mem (CPU python)=33155.90625MB; mem (CPU total)=44809.3203125MB
INFO:root:[   70] Training loss: 0.67255976, Validation loss: 0.65582263, Gradient norm: 2.09101216
INFO:root:At the start of the epoch: mem (CPU python)=33169.64453125MB; mem (CPU total)=44984.22265625MB
INFO:root:[   71] Training loss: 0.67249115, Validation loss: 0.65641623, Gradient norm: 2.34908727
INFO:root:At the start of the epoch: mem (CPU python)=33232.62890625MB; mem (CPU total)=44999.2890625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   72] Training loss: 0.67248447, Validation loss: 0.65592543, Gradient norm: 2.10345168
INFO:root:At the start of the epoch: mem (CPU python)=33295.6171875MB; mem (CPU total)=45151.03515625MB
INFO:root:[   73] Training loss: 0.67227794, Validation loss: 0.65649244, Gradient norm: 1.88422257
INFO:root:At the start of the epoch: mem (CPU python)=33295.6171875MB; mem (CPU total)=45141.42578125MB
INFO:root:[   74] Training loss: 0.67239038, Validation loss: 0.65574957, Gradient norm: 1.80533375
INFO:root:At the start of the epoch: mem (CPU python)=33321.84765625MB; mem (CPU total)=45267.28515625MB
INFO:root:[   75] Training loss: 0.67236622, Validation loss: 0.65535874, Gradient norm: 1.96493631
INFO:root:At the start of the epoch: mem (CPU python)=33384.00390625MB; mem (CPU total)=45380.32421875MB
INFO:root:[   76] Training loss: 0.67231848, Validation loss: 0.65619579, Gradient norm: 2.04039524
INFO:root:At the start of the epoch: mem (CPU python)=33448.21875MB; mem (CPU total)=45607.1796875MB
INFO:root:[   77] Training loss: 0.67243477, Validation loss: 0.65554462, Gradient norm: 2.04353106
INFO:root:At the start of the epoch: mem (CPU python)=33478.6953125MB; mem (CPU total)=45521.93359375MB
INFO:root:[   78] Training loss: 0.67218615, Validation loss: 0.65579708, Gradient norm: 1.87119260
INFO:root:At the start of the epoch: mem (CPU python)=33499.41015625MB; mem (CPU total)=45772.9375MB
INFO:root:[   79] Training loss: 0.67234384, Validation loss: 0.65540553, Gradient norm: 2.02294791
INFO:root:At the start of the epoch: mem (CPU python)=33537.50390625MB; mem (CPU total)=45859.7421875MB
INFO:root:[   80] Training loss: 0.67232515, Validation loss: 0.65607983, Gradient norm: 2.04693156
INFO:root:At the start of the epoch: mem (CPU python)=33575.56640625MB; mem (CPU total)=45837.50390625MB
INFO:root:[   81] Training loss: 0.67228631, Validation loss: 0.65624561, Gradient norm: 2.17523925
INFO:root:At the start of the epoch: mem (CPU python)=33588.60546875MB; mem (CPU total)=45976.0234375MB
INFO:root:[   82] Training loss: 0.67219981, Validation loss: 0.65547825, Gradient norm: 1.97630837
INFO:root:At the start of the epoch: mem (CPU python)=33622.12890625MB; mem (CPU total)=46102.515625MB
INFO:root:[   83] Training loss: 0.67224479, Validation loss: 0.65547542, Gradient norm: 2.12070765
INFO:root:At the start of the epoch: mem (CPU python)=33639.88671875MB; mem (CPU total)=46189.83984375MB
INFO:root:[   84] Training loss: 0.67232714, Validation loss: 0.65600269, Gradient norm: 2.08893237
INFO:root:At the start of the epoch: mem (CPU python)=33726.49609375MB; mem (CPU total)=46216.7890625MB
INFO:root:EP 84: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=33766.078125MB; mem (CPU total)=46403.12109375MB
INFO:root:Training the model took 6266.209s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.92856
INFO:root:EnergyScoreTrain: 0.65359
INFO:root:CRPSTrain: 0.57858
INFO:root:Gaussian NLLTrain: 54926550257.20888
INFO:root:CoverageTrain: 0.62957
INFO:root:IntervalWidthTrain: 2.72411
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.9314
INFO:root:EnergyScoreValidation: 0.65562
INFO:root:CRPSValidation: 0.58123
INFO:root:Gaussian NLLValidation: 56096329218.27557
INFO:root:CoverageValidation: 0.62939
INFO:root:IntervalWidthValidation: 2.72503
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.93185
INFO:root:EnergyScoreTest: 0.65592
INFO:root:CRPSTest: 0.58152
INFO:root:Gaussian NLLTest: 56250222772.22399
INFO:root:CoverageTest: 0.63028
INFO:root:IntervalWidthTest: 2.72873
INFO:root:After validation: mem (CPU python)=33767.109375MB; mem (CPU total)=46409.5078125MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=33767.109375MB; mem (CPU total)=46441.73046875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=33767.109375MB; mem (CPU total)=46442.22265625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=33767.109375MB; mem (CPU total)=46466.83984375MB
INFO:root:[    1] Training loss: 0.72603608, Validation loss: 0.72096690, Gradient norm: 0.02059821
INFO:root:At the start of the epoch: mem (CPU python)=33767.109375MB; mem (CPU total)=46496.890625MB
INFO:root:[    2] Training loss: 0.72050624, Validation loss: 0.71954940, Gradient norm: 0.00591800
INFO:root:At the start of the epoch: mem (CPU python)=33777.0625MB; mem (CPU total)=46619.58203125MB
INFO:root:[    3] Training loss: 0.71934142, Validation loss: 0.71783138, Gradient norm: 0.00724212
INFO:root:At the start of the epoch: mem (CPU python)=33819.484375MB; mem (CPU total)=46663.609375MB
INFO:root:[    4] Training loss: 0.71772495, Validation loss: 0.71417694, Gradient norm: 0.01235892
INFO:root:At the start of the epoch: mem (CPU python)=33855.1015625MB; mem (CPU total)=46808.47265625MB
INFO:root:[    5] Training loss: 0.71367611, Validation loss: 0.70750442, Gradient norm: 0.02301541
INFO:root:At the start of the epoch: mem (CPU python)=33895.7421875MB; mem (CPU total)=46856.76171875MB
INFO:root:[    6] Training loss: 0.70923922, Validation loss: 0.70248580, Gradient norm: 0.03062967
INFO:root:At the start of the epoch: mem (CPU python)=33933.72265625MB; mem (CPU total)=46945.8984375MB
INFO:root:[    7] Training loss: 0.70493576, Validation loss: 0.69705893, Gradient norm: 0.03292465
INFO:root:At the start of the epoch: mem (CPU python)=33971.140625MB; mem (CPU total)=47098.1875MB
INFO:root:[    8] Training loss: 0.70089118, Validation loss: 0.69155915, Gradient norm: 0.03017541
INFO:root:At the start of the epoch: mem (CPU python)=34035.140625MB; mem (CPU total)=47233.640625MB
INFO:root:[    9] Training loss: 0.69623373, Validation loss: 0.68452478, Gradient norm: 0.03318831
INFO:root:At the start of the epoch: mem (CPU python)=34045.1875MB; mem (CPU total)=47283.8359375MB
INFO:root:[   10] Training loss: 0.69187443, Validation loss: 0.67942907, Gradient norm: 0.03392112
INFO:root:At the start of the epoch: mem (CPU python)=34084.828125MB; mem (CPU total)=47345.4453125MB
INFO:root:[   11] Training loss: 0.68814612, Validation loss: 0.67609424, Gradient norm: 0.03663235
INFO:root:At the start of the epoch: mem (CPU python)=34099.4296875MB; mem (CPU total)=47471.8046875MB
INFO:root:[   12] Training loss: 0.68508990, Validation loss: 0.67217123, Gradient norm: 0.03287437
INFO:root:At the start of the epoch: mem (CPU python)=34185.4375MB; mem (CPU total)=47504.35546875MB
INFO:root:[   13] Training loss: 0.68241516, Validation loss: 0.66851014, Gradient norm: 0.03802290
INFO:root:At the start of the epoch: mem (CPU python)=34198.875MB; mem (CPU total)=47634.05078125MB
INFO:root:[   14] Training loss: 0.67984788, Validation loss: 0.66488602, Gradient norm: 0.03278746
INFO:root:At the start of the epoch: mem (CPU python)=34238.71484375MB; mem (CPU total)=47693.875MB
INFO:root:[   15] Training loss: 0.67792643, Validation loss: 0.66319518, Gradient norm: 0.04129771
INFO:root:At the start of the epoch: mem (CPU python)=34274.828125MB; mem (CPU total)=47846.78125MB
INFO:root:[   16] Training loss: 0.67613314, Validation loss: 0.66118957, Gradient norm: 0.04074584
INFO:root:At the start of the epoch: mem (CPU python)=34289.90234375MB; mem (CPU total)=47939.828125MB
INFO:root:[   17] Training loss: 0.67453073, Validation loss: 0.65971985, Gradient norm: 0.04011062
INFO:root:At the start of the epoch: mem (CPU python)=34349.02734375MB; mem (CPU total)=48032.9609375MB
INFO:root:[   18] Training loss: 0.67308517, Validation loss: 0.65736687, Gradient norm: 0.04437441
INFO:root:At the start of the epoch: mem (CPU python)=34390.328125MB; mem (CPU total)=48100.87890625MB
INFO:root:[   19] Training loss: 0.67186995, Validation loss: 0.65588785, Gradient norm: 0.04367836
INFO:root:At the start of the epoch: mem (CPU python)=34404.19140625MB; mem (CPU total)=48220.375MB
INFO:root:[   20] Training loss: 0.67064595, Validation loss: 0.65413301, Gradient norm: 0.04660146
INFO:root:At the start of the epoch: mem (CPU python)=34464.3203125MB; mem (CPU total)=48321.75390625MB
INFO:root:[   21] Training loss: 0.66951696, Validation loss: 0.65310401, Gradient norm: 0.06158738
INFO:root:At the start of the epoch: mem (CPU python)=34480.3828125MB; mem (CPU total)=48405.8671875MB
INFO:root:[   22] Training loss: 0.66853624, Validation loss: 0.65245705, Gradient norm: 0.05615915
INFO:root:At the start of the epoch: mem (CPU python)=34543.296875MB; mem (CPU total)=48456.05078125MB
INFO:root:[   23] Training loss: 0.66778809, Validation loss: 0.65183155, Gradient norm: 0.07203458
INFO:root:At the start of the epoch: mem (CPU python)=34581.5703125MB; mem (CPU total)=48616.6484375MB
INFO:root:[   24] Training loss: 0.66694350, Validation loss: 0.65085728, Gradient norm: 0.06504867
INFO:root:At the start of the epoch: mem (CPU python)=34644.515625MB; mem (CPU total)=48637.52734375MB
INFO:root:[   25] Training loss: 0.66613846, Validation loss: 0.64944262, Gradient norm: 0.07249469
INFO:root:At the start of the epoch: mem (CPU python)=34644.515625MB; mem (CPU total)=48779.84375MB
INFO:root:[   26] Training loss: 0.66549120, Validation loss: 0.65037372, Gradient norm: 0.08722065
INFO:root:At the start of the epoch: mem (CPU python)=34695.859375MB; mem (CPU total)=48905.33984375MB
INFO:root:[   27] Training loss: 0.66509028, Validation loss: 0.64843573, Gradient norm: 0.10424828
INFO:root:At the start of the epoch: mem (CPU python)=34708.953125MB; mem (CPU total)=48971.21875MB
INFO:root:[   28] Training loss: 0.66410171, Validation loss: 0.65161382, Gradient norm: 0.10690904
INFO:root:At the start of the epoch: mem (CPU python)=34771.46484375MB; mem (CPU total)=49064.48046875MB
INFO:root:[   29] Training loss: 0.66372740, Validation loss: 0.65160657, Gradient norm: 0.12671323
INFO:root:At the start of the epoch: mem (CPU python)=34810.01171875MB; mem (CPU total)=49107.98828125MB
INFO:root:[   30] Training loss: 0.66322622, Validation loss: 0.65163823, Gradient norm: 0.12404203
INFO:root:At the start of the epoch: mem (CPU python)=34844.24609375MB; mem (CPU total)=49250.48828125MB
INFO:root:[   31] Training loss: 0.66284092, Validation loss: 0.65451123, Gradient norm: 0.13865677
INFO:root:At the start of the epoch: mem (CPU python)=34886.08984375MB; mem (CPU total)=49326.734375MB
INFO:root:[   32] Training loss: 0.66249770, Validation loss: 0.65753724, Gradient norm: 0.17141526
INFO:root:At the start of the epoch: mem (CPU python)=34922.671875MB; mem (CPU total)=49436.390625MB
INFO:root:[   33] Training loss: 0.66202870, Validation loss: 0.65493865, Gradient norm: 0.17318090
INFO:root:At the start of the epoch: mem (CPU python)=34958.73828125MB; mem (CPU total)=49537.484375MB
INFO:root:[   34] Training loss: 0.66158641, Validation loss: 0.65941950, Gradient norm: 0.19061231
INFO:root:At the start of the epoch: mem (CPU python)=34999.68359375MB; mem (CPU total)=49621.44140625MB
INFO:root:[   35] Training loss: 0.66131273, Validation loss: 0.65365311, Gradient norm: 0.23784270
INFO:root:At the start of the epoch: mem (CPU python)=35038.72265625MB; mem (CPU total)=49746.22265625MB
INFO:root:[   36] Training loss: 0.66094408, Validation loss: 0.65846273, Gradient norm: 0.26063024
INFO:root:At the start of the epoch: mem (CPU python)=35073.84765625MB; mem (CPU total)=49810.51171875MB
INFO:root:[   37] Training loss: 0.66045853, Validation loss: 0.66117972, Gradient norm: 0.28120020
INFO:root:At the start of the epoch: mem (CPU python)=35110.6171875MB; mem (CPU total)=49906.453125MB
INFO:root:[   38] Training loss: 0.66032244, Validation loss: 0.66158378, Gradient norm: 0.25789120
INFO:root:At the start of the epoch: mem (CPU python)=35153.0078125MB; mem (CPU total)=50026.80859375MB
INFO:root:[   39] Training loss: 0.65998056, Validation loss: 0.66091496, Gradient norm: 0.30764102
INFO:root:At the start of the epoch: mem (CPU python)=35187.3671875MB; mem (CPU total)=50092.57421875MB
INFO:root:[   40] Training loss: 0.65953022, Validation loss: 0.66159318, Gradient norm: 0.30115346
INFO:root:At the start of the epoch: mem (CPU python)=35229.05078125MB; mem (CPU total)=50139.3046875MB
INFO:root:[   41] Training loss: 0.65969681, Validation loss: 0.66114118, Gradient norm: 0.35171462
INFO:root:At the start of the epoch: mem (CPU python)=35242.29296875MB; mem (CPU total)=50276.3203125MB
INFO:root:[   42] Training loss: 0.65931234, Validation loss: 0.66605498, Gradient norm: 0.43818796
INFO:root:At the start of the epoch: mem (CPU python)=35303.6328125MB; mem (CPU total)=50376.6796875MB
INFO:root:[   43] Training loss: 0.65888359, Validation loss: 0.66264592, Gradient norm: 0.38974289
INFO:root:At the start of the epoch: mem (CPU python)=35340.80859375MB; mem (CPU total)=50460.8828125MB
INFO:root:[   44] Training loss: 0.65893387, Validation loss: 0.66384915, Gradient norm: 0.43604018
INFO:root:At the start of the epoch: mem (CPU python)=35380.4609375MB; mem (CPU total)=50560.41796875MB
INFO:root:[   45] Training loss: 0.65870795, Validation loss: 0.65811150, Gradient norm: 0.56490920
INFO:root:At the start of the epoch: mem (CPU python)=35394.67578125MB; mem (CPU total)=50651.19140625MB
INFO:root:[   46] Training loss: 0.65839593, Validation loss: 0.65947454, Gradient norm: 0.47514293
INFO:root:At the start of the epoch: mem (CPU python)=35432.76953125MB; mem (CPU total)=50744.41796875MB
INFO:root:[   47] Training loss: 0.65808793, Validation loss: 0.65813572, Gradient norm: 0.53606111
INFO:root:At the start of the epoch: mem (CPU python)=35492.99609375MB; mem (CPU total)=50841.38671875MB
INFO:root:[   48] Training loss: 0.65823213, Validation loss: 0.66033661, Gradient norm: 0.59082665
INFO:root:At the start of the epoch: mem (CPU python)=35508.9609375MB; mem (CPU total)=50926.5390625MB
INFO:root:[   49] Training loss: 0.65839293, Validation loss: 0.65131457, Gradient norm: 0.72329232
INFO:root:At the start of the epoch: mem (CPU python)=35547.0546875MB; mem (CPU total)=51028.35546875MB
INFO:root:[   50] Training loss: 0.65770040, Validation loss: 0.65562804, Gradient norm: 0.66426279
INFO:root:At the start of the epoch: mem (CPU python)=35606.6875MB; mem (CPU total)=51111.2890625MB
INFO:root:[   51] Training loss: 0.65766353, Validation loss: 0.65722273, Gradient norm: 0.71520601
INFO:root:At the start of the epoch: mem (CPU python)=35646.4375MB; mem (CPU total)=51185.390625MB
INFO:root:[   52] Training loss: 0.65766212, Validation loss: 0.65346771, Gradient norm: 0.76693743
INFO:root:At the start of the epoch: mem (CPU python)=35686.2578125MB; mem (CPU total)=51250.4921875MB
INFO:root:[   53] Training loss: 0.65741143, Validation loss: 0.64964287, Gradient norm: 0.79337603
INFO:root:At the start of the epoch: mem (CPU python)=35699.4375MB; mem (CPU total)=51393.41796875MB
INFO:root:[   54] Training loss: 0.65789220, Validation loss: 0.64512514, Gradient norm: 1.04384803
INFO:root:At the start of the epoch: mem (CPU python)=35756.80859375MB; mem (CPU total)=51490.34765625MB
INFO:root:[   55] Training loss: 0.65769541, Validation loss: 0.64834459, Gradient norm: 1.00873558
INFO:root:At the start of the epoch: mem (CPU python)=35825.62890625MB; mem (CPU total)=51521.2890625MB
INFO:root:[   56] Training loss: 0.65748614, Validation loss: 0.64688397, Gradient norm: 1.00670383
INFO:root:At the start of the epoch: mem (CPU python)=35863.72265625MB; mem (CPU total)=51726.93359375MB
INFO:root:[   57] Training loss: 0.65741151, Validation loss: 0.64790552, Gradient norm: 1.14399653
INFO:root:At the start of the epoch: mem (CPU python)=35901.81640625MB; mem (CPU total)=51809.29296875MB
INFO:root:[   58] Training loss: 0.65725894, Validation loss: 0.64906526, Gradient norm: 1.16615389
INFO:root:At the start of the epoch: mem (CPU python)=35914.75390625MB; mem (CPU total)=51804.19140625MB
INFO:root:[   59] Training loss: 0.65714758, Validation loss: 0.64187032, Gradient norm: 1.33037510
INFO:root:At the start of the epoch: mem (CPU python)=35950.6796875MB; mem (CPU total)=51949.15234375MB
INFO:root:[   60] Training loss: 0.65707357, Validation loss: 0.64119051, Gradient norm: 1.42630166
INFO:root:At the start of the epoch: mem (CPU python)=36015.75MB; mem (CPU total)=52017.0234375MB
INFO:root:[   61] Training loss: 0.65693763, Validation loss: 0.64119125, Gradient norm: 1.25678511
INFO:root:At the start of the epoch: mem (CPU python)=36051.96875MB; mem (CPU total)=52139.46875MB
INFO:root:[   62] Training loss: 0.65672279, Validation loss: 0.64025873, Gradient norm: 1.34426770
INFO:root:At the start of the epoch: mem (CPU python)=36092.2109375MB; mem (CPU total)=52175.41796875MB
INFO:root:[   63] Training loss: 0.65671474, Validation loss: 0.63798345, Gradient norm: 1.49444051
INFO:root:At the start of the epoch: mem (CPU python)=36104.56640625MB; mem (CPU total)=52296.49609375MB
INFO:root:[   64] Training loss: 0.65661012, Validation loss: 0.63959896, Gradient norm: 1.52650520
INFO:root:At the start of the epoch: mem (CPU python)=36138.98046875MB; mem (CPU total)=52407.68359375MB
INFO:root:[   65] Training loss: 0.65660783, Validation loss: 0.63877401, Gradient norm: 1.80133751
INFO:root:At the start of the epoch: mem (CPU python)=36176.5078125MB; mem (CPU total)=52509.58203125MB
INFO:root:[   66] Training loss: 0.65648329, Validation loss: 0.63726682, Gradient norm: 1.68101898
INFO:root:At the start of the epoch: mem (CPU python)=36217.4765625MB; mem (CPU total)=52598.12109375MB
INFO:root:[   67] Training loss: 0.65633118, Validation loss: 0.63708000, Gradient norm: 1.64214112
INFO:root:At the start of the epoch: mem (CPU python)=36255.7890625MB; mem (CPU total)=52665.09375MB
INFO:root:[   68] Training loss: 0.65629116, Validation loss: 0.63645930, Gradient norm: 1.72619192
INFO:root:At the start of the epoch: mem (CPU python)=36320.42578125MB; mem (CPU total)=52763.97265625MB
INFO:root:[   69] Training loss: 0.65631297, Validation loss: 0.63676854, Gradient norm: 1.95393602
INFO:root:At the start of the epoch: mem (CPU python)=36330.8515625MB; mem (CPU total)=52872.484375MB
INFO:root:[   70] Training loss: 0.65617091, Validation loss: 0.63794723, Gradient norm: 1.91817610
INFO:root:At the start of the epoch: mem (CPU python)=36371.890625MB; mem (CPU total)=52947.7265625MB
INFO:root:[   71] Training loss: 0.65620947, Validation loss: 0.63642687, Gradient norm: 2.04263219
INFO:root:At the start of the epoch: mem (CPU python)=36410.16015625MB; mem (CPU total)=53080.33203125MB
INFO:root:[   72] Training loss: 0.65600452, Validation loss: 0.63595819, Gradient norm: 2.06778991
INFO:root:At the start of the epoch: mem (CPU python)=36440.5703125MB; mem (CPU total)=53154.375MB
INFO:root:[   73] Training loss: 0.65588442, Validation loss: 0.63701070, Gradient norm: 2.09142403
INFO:root:At the start of the epoch: mem (CPU python)=36482.98828125MB; mem (CPU total)=53247.93359375MB
INFO:root:[   74] Training loss: 0.65591162, Validation loss: 0.63589193, Gradient norm: 2.25979712
INFO:root:At the start of the epoch: mem (CPU python)=36523.24609375MB; mem (CPU total)=53300.3046875MB
INFO:root:[   75] Training loss: 0.65599121, Validation loss: 0.63616725, Gradient norm: 2.35210804
INFO:root:At the start of the epoch: mem (CPU python)=36561.99609375MB; mem (CPU total)=53327.92578125MB
INFO:root:[   76] Training loss: 0.65562336, Validation loss: 0.63591442, Gradient norm: 2.28204241
INFO:root:At the start of the epoch: mem (CPU python)=36600.109375MB; mem (CPU total)=53379.140625MB
INFO:root:[   77] Training loss: 0.65576724, Validation loss: 0.63666208, Gradient norm: 2.47504452
INFO:root:At the start of the epoch: mem (CPU python)=36636.2578125MB; mem (CPU total)=53481.11328125MB
INFO:root:[   78] Training loss: 0.65595725, Validation loss: 0.63572488, Gradient norm: 2.54868498
INFO:root:At the start of the epoch: mem (CPU python)=36671.47265625MB; mem (CPU total)=53571.93359375MB
INFO:root:[   79] Training loss: 0.65557812, Validation loss: 0.63695758, Gradient norm: 2.25891128
INFO:root:At the start of the epoch: mem (CPU python)=36714.53515625MB; mem (CPU total)=53646.82421875MB
INFO:root:[   80] Training loss: 0.65577172, Validation loss: 0.63737933, Gradient norm: 2.65335027
INFO:root:At the start of the epoch: mem (CPU python)=36728.01953125MB; mem (CPU total)=53752.49609375MB
INFO:root:[   81] Training loss: 0.65543422, Validation loss: 0.63607554, Gradient norm: 2.68762848
INFO:root:At the start of the epoch: mem (CPU python)=36791.11328125MB; mem (CPU total)=53877.33203125MB
INFO:root:[   82] Training loss: 0.65573999, Validation loss: 0.63565517, Gradient norm: 2.66521040
INFO:root:At the start of the epoch: mem (CPU python)=36829.2109375MB; mem (CPU total)=53963.609375MB
INFO:root:[   83] Training loss: 0.65574555, Validation loss: 0.63565668, Gradient norm: 2.83960106
INFO:root:At the start of the epoch: mem (CPU python)=36864.4765625MB; mem (CPU total)=54031.76953125MB
INFO:root:[   84] Training loss: 0.65570774, Validation loss: 0.63499616, Gradient norm: 2.91241000
INFO:root:At the start of the epoch: mem (CPU python)=36928.60546875MB; mem (CPU total)=54128.91796875MB
INFO:root:[   85] Training loss: 0.65548492, Validation loss: 0.63870023, Gradient norm: 2.82861676
INFO:root:At the start of the epoch: mem (CPU python)=36943.49609375MB; mem (CPU total)=54232.9375MB
INFO:root:[   86] Training loss: 0.65549324, Validation loss: 0.63492337, Gradient norm: 3.00247431
INFO:root:At the start of the epoch: mem (CPU python)=37003.421875MB; mem (CPU total)=54252.91796875MB
INFO:root:[   87] Training loss: 0.65544117, Validation loss: 0.63641921, Gradient norm: 2.84912580
INFO:root:At the start of the epoch: mem (CPU python)=37017.98828125MB; mem (CPU total)=54371.265625MB
INFO:root:[   88] Training loss: 0.65559543, Validation loss: 0.63601092, Gradient norm: 3.00337375
INFO:root:At the start of the epoch: mem (CPU python)=37055.69921875MB; mem (CPU total)=54483.3046875MB
INFO:root:[   89] Training loss: 0.65552661, Validation loss: 0.63581845, Gradient norm: 3.07433392
INFO:root:At the start of the epoch: mem (CPU python)=37094.8125MB; mem (CPU total)=54586.6953125MB
INFO:root:[   90] Training loss: 0.65544354, Validation loss: 0.63511647, Gradient norm: 2.83131478
INFO:root:At the start of the epoch: mem (CPU python)=37135.4453125MB; mem (CPU total)=54613.79296875MB
INFO:root:[   91] Training loss: 0.65537842, Validation loss: 0.63444886, Gradient norm: 2.99803891
INFO:root:At the start of the epoch: mem (CPU python)=37172.55859375MB; mem (CPU total)=54761.03515625MB
INFO:root:[   92] Training loss: 0.65530443, Validation loss: 0.63505505, Gradient norm: 3.01838565
INFO:root:At the start of the epoch: mem (CPU python)=37236.6640625MB; mem (CPU total)=54906.78125MB
INFO:root:[   93] Training loss: 0.65545063, Validation loss: 0.63471132, Gradient norm: 3.28873512
INFO:root:At the start of the epoch: mem (CPU python)=37274.7578125MB; mem (CPU total)=54987.953125MB
INFO:root:[   94] Training loss: 0.65523973, Validation loss: 0.63425293, Gradient norm: 3.02239248
INFO:root:At the start of the epoch: mem (CPU python)=37312.85546875MB; mem (CPU total)=55086.25MB
INFO:root:[   95] Training loss: 0.65532552, Validation loss: 0.63515302, Gradient norm: 3.30882893
INFO:root:At the start of the epoch: mem (CPU python)=37313.078125MB; mem (CPU total)=55124.1875MB
INFO:root:[   96] Training loss: 0.65575465, Validation loss: 0.63552116, Gradient norm: 3.48175426
INFO:root:At the start of the epoch: mem (CPU python)=37362.20703125MB; mem (CPU total)=55182.33203125MB
INFO:root:[   97] Training loss: 0.65507369, Validation loss: 0.63560061, Gradient norm: 3.11773842
INFO:root:At the start of the epoch: mem (CPU python)=37377.140625MB; mem (CPU total)=55310.07421875MB
INFO:root:[   98] Training loss: 0.65530944, Validation loss: 0.63396808, Gradient norm: 3.42703936
INFO:root:At the start of the epoch: mem (CPU python)=37415.234375MB; mem (CPU total)=55392.2421875MB
INFO:root:[   99] Training loss: 0.65526971, Validation loss: 0.63455830, Gradient norm: 3.25802955
INFO:root:At the start of the epoch: mem (CPU python)=37478.33203125MB; mem (CPU total)=55511.671875MB
INFO:root:[  100] Training loss: 0.65524634, Validation loss: 0.63580507, Gradient norm: 3.60778134
INFO:root:At the start of the epoch: mem (CPU python)=37541.42578125MB; mem (CPU total)=55633.125MB
INFO:root:[  101] Training loss: 0.65508637, Validation loss: 0.63533393, Gradient norm: 3.63806779
INFO:root:At the start of the epoch: mem (CPU python)=37554.5234375MB; mem (CPU total)=55686.86328125MB
INFO:root:[  102] Training loss: 0.65495836, Validation loss: 0.63622031, Gradient norm: 2.80613277
INFO:root:At the start of the epoch: mem (CPU python)=37615.5078125MB; mem (CPU total)=55706.484375MB
INFO:root:[  103] Training loss: 0.65513772, Validation loss: 0.63688581, Gradient norm: 3.79961967
INFO:root:At the start of the epoch: mem (CPU python)=37615.5078125MB; mem (CPU total)=55849.9375MB
INFO:root:[  104] Training loss: 0.65522724, Validation loss: 0.63384861, Gradient norm: 3.70295869
INFO:root:At the start of the epoch: mem (CPU python)=37668.8125MB; mem (CPU total)=55961.92578125MB
INFO:root:[  105] Training loss: 0.65511141, Validation loss: 0.63441703, Gradient norm: 3.78198206
INFO:root:At the start of the epoch: mem (CPU python)=37706.90625MB; mem (CPU total)=56060.32421875MB
INFO:root:[  106] Training loss: 0.65525558, Validation loss: 0.63453342, Gradient norm: 3.85767076
INFO:root:At the start of the epoch: mem (CPU python)=37767.3203125MB; mem (CPU total)=56142.6484375MB
INFO:root:[  107] Training loss: 0.65508870, Validation loss: 0.63463429, Gradient norm: 3.68922428
INFO:root:At the start of the epoch: mem (CPU python)=37778.97265625MB; mem (CPU total)=56210.80859375MB
INFO:root:[  108] Training loss: 0.65516769, Validation loss: 0.63465807, Gradient norm: 3.64424714
INFO:root:At the start of the epoch: mem (CPU python)=37821.19140625MB; mem (CPU total)=56333.3671875MB
INFO:root:[  109] Training loss: 0.65550772, Validation loss: 0.63569431, Gradient norm: 3.86900744
INFO:root:At the start of the epoch: mem (CPU python)=37884.29296875MB; mem (CPU total)=56435.13671875MB
INFO:root:[  110] Training loss: 0.65511722, Validation loss: 0.63518520, Gradient norm: 3.96599268
INFO:root:At the start of the epoch: mem (CPU python)=37884.7421875MB; mem (CPU total)=56484.86328125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  111] Training loss: 0.65533633, Validation loss: 0.63528704, Gradient norm: 3.95234564
INFO:root:At the start of the epoch: mem (CPU python)=37960.453125MB; mem (CPU total)=56552.0078125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  112] Training loss: 0.65372552, Validation loss: 0.63264920, Gradient norm: 2.40504312
INFO:root:At the start of the epoch: mem (CPU python)=37973.375MB; mem (CPU total)=56604.953125MB
INFO:root:[  113] Training loss: 0.65292884, Validation loss: 0.63195218, Gradient norm: 1.78516174
INFO:root:At the start of the epoch: mem (CPU python)=38010.90625MB; mem (CPU total)=56734.2109375MB
INFO:root:[  114] Training loss: 0.65292621, Validation loss: 0.63339255, Gradient norm: 1.89154839
INFO:root:At the start of the epoch: mem (CPU python)=38049.765625MB; mem (CPU total)=56867.9609375MB
INFO:root:[  115] Training loss: 0.65277475, Validation loss: 0.63215242, Gradient norm: 1.92528177
INFO:root:At the start of the epoch: mem (CPU python)=38081.66015625MB; mem (CPU total)=56934.43359375MB
INFO:root:[  116] Training loss: 0.65281234, Validation loss: 0.63328322, Gradient norm: 2.05337341
INFO:root:At the start of the epoch: mem (CPU python)=38146.83984375MB; mem (CPU total)=57033.0703125MB
INFO:root:[  117] Training loss: 0.65276547, Validation loss: 0.63170025, Gradient norm: 2.04138896
INFO:root:At the start of the epoch: mem (CPU python)=38164.0546875MB; mem (CPU total)=57054.65625MB
INFO:root:[  118] Training loss: 0.65286943, Validation loss: 0.63320791, Gradient norm: 2.37644326
INFO:root:At the start of the epoch: mem (CPU python)=38177.14453125MB; mem (CPU total)=57208.7265625MB
INFO:root:[  119] Training loss: 0.65281456, Validation loss: 0.63238931, Gradient norm: 2.48766606
INFO:root:At the start of the epoch: mem (CPU python)=38239.828125MB; mem (CPU total)=57269.2890625MB
INFO:root:[  120] Training loss: 0.65268469, Validation loss: 0.63285876, Gradient norm: 2.41190167
INFO:root:At the start of the epoch: mem (CPU python)=38253.33984375MB; mem (CPU total)=57383.1484375MB
INFO:root:[  121] Training loss: 0.65275142, Validation loss: 0.63271294, Gradient norm: 2.55422361
INFO:root:At the start of the epoch: mem (CPU python)=38316.43359375MB; mem (CPU total)=57507.93359375MB
INFO:root:[  122] Training loss: 0.65273597, Validation loss: 0.63289804, Gradient norm: 2.41263782
INFO:root:At the start of the epoch: mem (CPU python)=38354.52734375MB; mem (CPU total)=57592.5859375MB
INFO:root:[  123] Training loss: 0.65269133, Validation loss: 0.63358565, Gradient norm: 2.45743478
INFO:root:At the start of the epoch: mem (CPU python)=38392.59375MB; mem (CPU total)=57632.48828125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  124] Training loss: 0.65289493, Validation loss: 0.63241654, Gradient norm: 2.62968901
INFO:root:At the start of the epoch: mem (CPU python)=38428.12890625MB; mem (CPU total)=57757.73046875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  125] Training loss: 0.65246020, Validation loss: 0.63242425, Gradient norm: 1.91823257
INFO:root:At the start of the epoch: mem (CPU python)=38468.8125MB; mem (CPU total)=57780.609375MB
INFO:root:[  126] Training loss: 0.65231634, Validation loss: 0.63252971, Gradient norm: 1.80089709
INFO:root:At the start of the epoch: mem (CPU python)=38506.9140625MB; mem (CPU total)=57956.375MB
INFO:root:EP 126: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=38544.8671875MB; mem (CPU total)=58012.03515625MB
INFO:root:Training the model took 10102.836s.
INFO:root:Emptying the cuda cache took 0.03s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.89547
INFO:root:EnergyScoreTrain: 0.63022
INFO:root:CRPSTrain: 0.54155
INFO:root:Gaussian NLLTrain: 59451624288.71116
INFO:root:CoverageTrain: 0.5976
INFO:root:IntervalWidthTrain: 2.62667
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.89851
INFO:root:EnergyScoreValidation: 0.63238
INFO:root:CRPSValidation: 0.5444
INFO:root:Gaussian NLLValidation: 61245401133.5111
INFO:root:CoverageValidation: 0.59711
INFO:root:IntervalWidthValidation: 2.62483
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.89945
INFO:root:EnergyScoreTest: 0.63303
INFO:root:CRPSTest: 0.54501
INFO:root:Gaussian NLLTest: 61260414058.49601
INFO:root:CoverageTest: 0.59782
INFO:root:IntervalWidthTest: 2.62713
INFO:root:After validation: mem (CPU python)=38545.98046875MB; mem (CPU total)=58065.828125MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.2, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=38545.98046875MB; mem (CPU total)=58089.64453125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=38545.98046875MB; mem (CPU total)=58089.890625MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=38545.98046875MB; mem (CPU total)=58127.79296875MB
INFO:root:[    1] Training loss: 0.72772357, Validation loss: 0.72127874, Gradient norm: 0.03127792
INFO:root:At the start of the epoch: mem (CPU python)=38713.734375MB; mem (CPU total)=58243.046875MB
INFO:root:[    2] Training loss: 0.72062738, Validation loss: 0.71888216, Gradient norm: 0.00643278
INFO:root:At the start of the epoch: mem (CPU python)=38713.734375MB; mem (CPU total)=58343.81640625MB
INFO:root:[    3] Training loss: 0.71903986, Validation loss: 0.71681654, Gradient norm: 0.00829289
INFO:root:At the start of the epoch: mem (CPU python)=38713.734375MB; mem (CPU total)=58415.0546875MB
INFO:root:[    4] Training loss: 0.71562199, Validation loss: 0.70993604, Gradient norm: 0.01814212
INFO:root:At the start of the epoch: mem (CPU python)=38736.22265625MB; mem (CPU total)=58504.20703125MB
INFO:root:[    5] Training loss: 0.71061715, Validation loss: 0.70349098, Gradient norm: 0.02862462
INFO:root:At the start of the epoch: mem (CPU python)=38778.72265625MB; mem (CPU total)=58549.9765625MB
INFO:root:[    6] Training loss: 0.70599647, Validation loss: 0.69794109, Gradient norm: 0.03642452
INFO:root:At the start of the epoch: mem (CPU python)=38791.921875MB; mem (CPU total)=58682.359375MB
INFO:root:[    7] Training loss: 0.70201222, Validation loss: 0.69206942, Gradient norm: 0.03790543
INFO:root:At the start of the epoch: mem (CPU python)=38855.01953125MB; mem (CPU total)=58803.921875MB
INFO:root:[    8] Training loss: 0.69816308, Validation loss: 0.68744318, Gradient norm: 0.04354303
INFO:root:At the start of the epoch: mem (CPU python)=38930.61328125MB; mem (CPU total)=58860.90234375MB
INFO:root:[    9] Training loss: 0.69500794, Validation loss: 0.68325055, Gradient norm: 0.05469675
INFO:root:At the start of the epoch: mem (CPU python)=38931.078125MB; mem (CPU total)=58901.75390625MB
INFO:root:[   10] Training loss: 0.69242660, Validation loss: 0.68043859, Gradient norm: 0.06782362
INFO:root:At the start of the epoch: mem (CPU python)=39055.4609375MB; mem (CPU total)=59118.8203125MB
INFO:root:[   11] Training loss: 0.69025898, Validation loss: 0.67795001, Gradient norm: 0.07772572
INFO:root:At the start of the epoch: mem (CPU python)=39055.4609375MB; mem (CPU total)=59089.06640625MB
INFO:root:[   12] Training loss: 0.68823573, Validation loss: 0.67612174, Gradient norm: 0.09141277
INFO:root:At the start of the epoch: mem (CPU python)=39055.4609375MB; mem (CPU total)=59206.73046875MB
INFO:root:[   13] Training loss: 0.68667394, Validation loss: 0.67577956, Gradient norm: 0.12481731
INFO:root:At the start of the epoch: mem (CPU python)=39105.125MB; mem (CPU total)=59329.69140625MB
INFO:root:[   14] Training loss: 0.68504456, Validation loss: 0.67501858, Gradient norm: 0.14434674
INFO:root:At the start of the epoch: mem (CPU python)=39121.0234375MB; mem (CPU total)=59384.8203125MB
INFO:root:[   15] Training loss: 0.68349365, Validation loss: 0.67679042, Gradient norm: 0.13556357
INFO:root:At the start of the epoch: mem (CPU python)=39134.78125MB; mem (CPU total)=59503.4921875MB
INFO:root:[   16] Training loss: 0.68228782, Validation loss: 0.67617454, Gradient norm: 0.17603487
INFO:root:At the start of the epoch: mem (CPU python)=39197.4921875MB; mem (CPU total)=59570.6640625MB
INFO:root:[   17] Training loss: 0.68122154, Validation loss: 0.67503890, Gradient norm: 0.24205846
INFO:root:At the start of the epoch: mem (CPU python)=39210.9765625MB; mem (CPU total)=59677.60546875MB
INFO:root:[   18] Training loss: 0.67988083, Validation loss: 0.68110670, Gradient norm: 0.26023714
INFO:root:At the start of the epoch: mem (CPU python)=39249.0703125MB; mem (CPU total)=59776.953125MB
INFO:root:[   19] Training loss: 0.67868577, Validation loss: 0.68286343, Gradient norm: 0.27307253
INFO:root:At the start of the epoch: mem (CPU python)=39309.5859375MB; mem (CPU total)=59842.90625MB
INFO:root:[   20] Training loss: 0.67772204, Validation loss: 0.69054670, Gradient norm: 0.27017401
INFO:root:At the start of the epoch: mem (CPU python)=39350.0703125MB; mem (CPU total)=59896.64453125MB
INFO:root:[   21] Training loss: 0.67700399, Validation loss: 0.69522684, Gradient norm: 0.30223322
INFO:root:At the start of the epoch: mem (CPU python)=39387.19921875MB; mem (CPU total)=60024.1484375MB
INFO:root:[   22] Training loss: 0.67612608, Validation loss: 0.69240516, Gradient norm: 0.35104740
INFO:root:At the start of the epoch: mem (CPU python)=39425.515625MB; mem (CPU total)=60104.70703125MB
INFO:root:[   23] Training loss: 0.67517029, Validation loss: 0.68943810, Gradient norm: 0.33974156
INFO:root:At the start of the epoch: mem (CPU python)=39463.87109375MB; mem (CPU total)=60197.50390625MB
INFO:root:[   24] Training loss: 0.67470134, Validation loss: 0.70038131, Gradient norm: 0.45178200
INFO:root:At the start of the epoch: mem (CPU python)=39500.7578125MB; mem (CPU total)=60296.2109375MB
INFO:root:[   25] Training loss: 0.67375288, Validation loss: 0.69539585, Gradient norm: 0.40734989
INFO:root:At the start of the epoch: mem (CPU python)=39515.73828125MB; mem (CPU total)=60402.3125MB
INFO:root:[   26] Training loss: 0.67341101, Validation loss: 0.69850755, Gradient norm: 0.48121345
INFO:root:At the start of the epoch: mem (CPU python)=39553.83203125MB; mem (CPU total)=60494.109375MB
INFO:root:[   27] Training loss: 0.67254506, Validation loss: 0.70614344, Gradient norm: 0.47482834
INFO:root:At the start of the epoch: mem (CPU python)=39614.8046875MB; mem (CPU total)=60593.29296875MB
INFO:root:[   28] Training loss: 0.67202388, Validation loss: 0.69211198, Gradient norm: 0.57374606
INFO:root:At the start of the epoch: mem (CPU python)=39650.20703125MB; mem (CPU total)=60669.53515625MB
INFO:root:[   29] Training loss: 0.67149647, Validation loss: 0.69951235, Gradient norm: 0.57174100
INFO:root:At the start of the epoch: mem (CPU python)=39691.29296875MB; mem (CPU total)=60765.453125MB
INFO:root:[   30] Training loss: 0.67101284, Validation loss: 0.69962837, Gradient norm: 0.63136622
INFO:root:At the start of the epoch: mem (CPU python)=39727.4375MB; mem (CPU total)=60835.640625MB
INFO:root:[   31] Training loss: 0.67043726, Validation loss: 0.69595615, Gradient norm: 0.63208908
INFO:root:At the start of the epoch: mem (CPU python)=39793.16015625MB; mem (CPU total)=60963.078125MB
INFO:root:[   32] Training loss: 0.67001771, Validation loss: 0.69976383, Gradient norm: 0.67649926
INFO:root:At the start of the epoch: mem (CPU python)=39807.40625MB; mem (CPU total)=61061.76171875MB
INFO:root:[   33] Training loss: 0.66969267, Validation loss: 0.69942549, Gradient norm: 0.86720450
INFO:root:At the start of the epoch: mem (CPU python)=39870.453125MB; mem (CPU total)=61106.78125MB
INFO:root:[   34] Training loss: 0.66915440, Validation loss: 0.69429695, Gradient norm: 0.83246419
INFO:root:At the start of the epoch: mem (CPU python)=39883.59765625MB; mem (CPU total)=61237.44140625MB
INFO:root:[   35] Training loss: 0.66878407, Validation loss: 0.69648100, Gradient norm: 0.86535319
INFO:root:At the start of the epoch: mem (CPU python)=39896.69140625MB; mem (CPU total)=61311.92578125MB
INFO:root:[   36] Training loss: 0.66854206, Validation loss: 0.68727706, Gradient norm: 0.97421909
INFO:root:At the start of the epoch: mem (CPU python)=39957.73046875MB; mem (CPU total)=61371.984375MB
INFO:root:[   37] Training loss: 0.66814697, Validation loss: 0.68534411, Gradient norm: 1.02197443
INFO:root:At the start of the epoch: mem (CPU python)=39996.98828125MB; mem (CPU total)=61450.95703125MB
INFO:root:[   38] Training loss: 0.66742480, Validation loss: 0.68136742, Gradient norm: 0.92023258
INFO:root:At the start of the epoch: mem (CPU python)=40034.96484375MB; mem (CPU total)=61549.93359375MB
INFO:root:[   39] Training loss: 0.66713262, Validation loss: 0.68075686, Gradient norm: 0.96481770
INFO:root:At the start of the epoch: mem (CPU python)=40049.0859375MB; mem (CPU total)=61664.0390625MB
INFO:root:[   40] Training loss: 0.66679452, Validation loss: 0.66765764, Gradient norm: 1.12236037
INFO:root:At the start of the epoch: mem (CPU python)=40087.17578125MB; mem (CPU total)=61750.171875MB
INFO:root:[   41] Training loss: 0.66653650, Validation loss: 0.66478839, Gradient norm: 1.25599511
INFO:root:At the start of the epoch: mem (CPU python)=40150.16796875MB; mem (CPU total)=61793.29296875MB
INFO:root:[   42] Training loss: 0.66621906, Validation loss: 0.66033667, Gradient norm: 1.27774035
INFO:root:At the start of the epoch: mem (CPU python)=40185.31640625MB; mem (CPU total)=61931.05859375MB
INFO:root:[   43] Training loss: 0.66613375, Validation loss: 0.65900897, Gradient norm: 1.48553794
INFO:root:At the start of the epoch: mem (CPU python)=40248.96484375MB; mem (CPU total)=62065.58203125MB
INFO:root:[   44] Training loss: 0.66582123, Validation loss: 0.65488157, Gradient norm: 1.52926179
INFO:root:At the start of the epoch: mem (CPU python)=40279.4453125MB; mem (CPU total)=62115.8515625MB
INFO:root:[   45] Training loss: 0.66577190, Validation loss: 0.65150139, Gradient norm: 1.59862545
INFO:root:At the start of the epoch: mem (CPU python)=40279.4453125MB; mem (CPU total)=62198.5625MB
INFO:root:[   46] Training loss: 0.66555694, Validation loss: 0.65308472, Gradient norm: 1.67523737
INFO:root:At the start of the epoch: mem (CPU python)=40340.34765625MB; mem (CPU total)=62261.1953125MB
INFO:root:[   47] Training loss: 0.66556457, Validation loss: 0.65185475, Gradient norm: 1.74118371
INFO:root:At the start of the epoch: mem (CPU python)=40377.6328125MB; mem (CPU total)=62360.5625MB
INFO:root:[   48] Training loss: 0.66538121, Validation loss: 0.65021188, Gradient norm: 2.02967018
INFO:root:At the start of the epoch: mem (CPU python)=40391.94921875MB; mem (CPU total)=62465.171875MB
INFO:root:[   49] Training loss: 0.66506505, Validation loss: 0.64948446, Gradient norm: 1.87009792
INFO:root:At the start of the epoch: mem (CPU python)=40430.04296875MB; mem (CPU total)=62555.265625MB
INFO:root:[   50] Training loss: 0.66519806, Validation loss: 0.64722541, Gradient norm: 2.15610267
INFO:root:At the start of the epoch: mem (CPU python)=40468.13671875MB; mem (CPU total)=62654.6796875MB
INFO:root:[   51] Training loss: 0.66499270, Validation loss: 0.64680874, Gradient norm: 2.09132264
INFO:root:At the start of the epoch: mem (CPU python)=40506.234375MB; mem (CPU total)=62732.41796875MB
INFO:root:[   52] Training loss: 0.66480750, Validation loss: 0.64603062, Gradient norm: 2.02028014
INFO:root:At the start of the epoch: mem (CPU python)=40594.19140625MB; mem (CPU total)=62797.72265625MB
INFO:root:[   53] Training loss: 0.66482324, Validation loss: 0.64603085, Gradient norm: 2.41380163
INFO:root:At the start of the epoch: mem (CPU python)=40594.19140625MB; mem (CPU total)=62920.8125MB
INFO:root:[   54] Training loss: 0.66470861, Validation loss: 0.64710062, Gradient norm: 2.48772364
INFO:root:At the start of the epoch: mem (CPU python)=40641.23828125MB; mem (CPU total)=62999.75MB
INFO:root:[   55] Training loss: 0.66462216, Validation loss: 0.64748175, Gradient norm: 2.53995034
INFO:root:At the start of the epoch: mem (CPU python)=40658.61328125MB; mem (CPU total)=63088.3828125MB
INFO:root:[   56] Training loss: 0.66461550, Validation loss: 0.64681555, Gradient norm: 2.51411442
INFO:root:At the start of the epoch: mem (CPU python)=40696.7109375MB; mem (CPU total)=63185.3671875MB
INFO:root:[   57] Training loss: 0.66480630, Validation loss: 0.64721258, Gradient norm: 2.90384468
INFO:root:At the start of the epoch: mem (CPU python)=40759.8046875MB; mem (CPU total)=63291.78125MB
INFO:root:[   58] Training loss: 0.66458399, Validation loss: 0.64551305, Gradient norm: 2.88635000
INFO:root:At the start of the epoch: mem (CPU python)=40793.44140625MB; mem (CPU total)=63353.3046875MB
INFO:root:[   59] Training loss: 0.66447784, Validation loss: 0.64597896, Gradient norm: 3.08945335
INFO:root:At the start of the epoch: mem (CPU python)=40833.3359375MB; mem (CPU total)=63425.48046875MB
INFO:root:[   60] Training loss: 0.66500124, Validation loss: 0.64524632, Gradient norm: 3.46982163
INFO:root:At the start of the epoch: mem (CPU python)=40872.26171875MB; mem (CPU total)=63509.54296875MB
INFO:root:[   61] Training loss: 0.66487040, Validation loss: 0.64652480, Gradient norm: 3.37284545
INFO:root:At the start of the epoch: mem (CPU python)=40887.1875MB; mem (CPU total)=63563.1328125MB
INFO:root:[   62] Training loss: 0.66473947, Validation loss: 0.64642044, Gradient norm: 3.21745552
INFO:root:At the start of the epoch: mem (CPU python)=40946.4296875MB; mem (CPU total)=63614.0625MB
INFO:root:[   63] Training loss: 0.66463160, Validation loss: 0.64460187, Gradient norm: 2.92787158
INFO:root:At the start of the epoch: mem (CPU python)=40982.421875MB; mem (CPU total)=63690.73828125MB
INFO:root:[   64] Training loss: 0.66469214, Validation loss: 0.64510832, Gradient norm: 3.44853542
INFO:root:At the start of the epoch: mem (CPU python)=41001.46875MB; mem (CPU total)=63767.51953125MB
INFO:root:[   65] Training loss: 0.66447564, Validation loss: 0.64482337, Gradient norm: 3.20756789
INFO:root:At the start of the epoch: mem (CPU python)=41064.17578125MB; mem (CPU total)=63838.9765625MB
INFO:root:[   66] Training loss: 0.66474660, Validation loss: 0.64514875, Gradient norm: 3.88812385
INFO:root:At the start of the epoch: mem (CPU python)=41127.62890625MB; mem (CPU total)=63909.4921875MB
INFO:root:[   67] Training loss: 0.66474301, Validation loss: 0.64588470, Gradient norm: 3.92346726
INFO:root:At the start of the epoch: mem (CPU python)=41139.01953125MB; mem (CPU total)=64034.6015625MB
INFO:root:[   68] Training loss: 0.66474287, Validation loss: 0.64517250, Gradient norm: 3.99396297
INFO:root:At the start of the epoch: mem (CPU python)=41153.85546875MB; mem (CPU total)=64127.78515625MB
INFO:root:[   69] Training loss: 0.66480539, Validation loss: 0.64675884, Gradient norm: 3.97566951
INFO:root:At the start of the epoch: mem (CPU python)=41216.94921875MB; mem (CPU total)=64250.8984375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[   70] Training loss: 0.66499749, Validation loss: 0.64625322, Gradient norm: 4.03734585
INFO:root:At the start of the epoch: mem (CPU python)=41278.0390625MB; mem (CPU total)=64327.1953125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[   71] Training loss: 0.66349582, Validation loss: 0.64626218, Gradient norm: 2.90780383
INFO:root:At the start of the epoch: mem (CPU python)=41292.98828125MB; mem (CPU total)=64339.08984375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[   72] Training loss: 0.66290794, Validation loss: 0.64440193, Gradient norm: 2.22330688
INFO:root:At the start of the epoch: mem (CPU python)=41306.234375MB; mem (CPU total)=64490.8203125MB
INFO:root:[   73] Training loss: 0.66249306, Validation loss: 0.64398958, Gradient norm: 1.82027482
INFO:root:At the start of the epoch: mem (CPU python)=41344.328125MB; mem (CPU total)=64569.29296875MB
INFO:root:[   74] Training loss: 0.66243529, Validation loss: 0.64414071, Gradient norm: 1.84451283
INFO:root:At the start of the epoch: mem (CPU python)=41382.42578125MB; mem (CPU total)=64655.89453125MB
INFO:root:[   75] Training loss: 0.66237362, Validation loss: 0.64377170, Gradient norm: 2.14002928
INFO:root:At the start of the epoch: mem (CPU python)=41445.5MB; mem (CPU total)=64697.46484375MB
INFO:root:[   76] Training loss: 0.66246276, Validation loss: 0.64423714, Gradient norm: 2.09058088
INFO:root:At the start of the epoch: mem (CPU python)=41478.01171875MB; mem (CPU total)=64836.9375MB
INFO:root:[   77] Training loss: 0.66252639, Validation loss: 0.64362209, Gradient norm: 2.01361292
INFO:root:At the start of the epoch: mem (CPU python)=41521.37109375MB; mem (CPU total)=64888.9609375MB
INFO:root:[   78] Training loss: 0.66255251, Validation loss: 0.64382873, Gradient norm: 2.26383349
INFO:root:At the start of the epoch: mem (CPU python)=41642.90234375MB; mem (CPU total)=64981.859375MB
INFO:root:[   79] Training loss: 0.66235325, Validation loss: 0.64458851, Gradient norm: 2.17456872
INFO:root:At the start of the epoch: mem (CPU python)=41642.90234375MB; mem (CPU total)=65103.6640625MB
INFO:root:[   80] Training loss: 0.66255599, Validation loss: 0.64439728, Gradient norm: 2.47528287
INFO:root:At the start of the epoch: mem (CPU python)=41642.90234375MB; mem (CPU total)=65180.7421875MB
INFO:root:[   81] Training loss: 0.66253961, Validation loss: 0.64443636, Gradient norm: 2.50536120
INFO:root:At the start of the epoch: mem (CPU python)=41671.1953125MB; mem (CPU total)=65277.671875MB
INFO:root:[   82] Training loss: 0.66243704, Validation loss: 0.64405188, Gradient norm: 2.42822472
INFO:root:At the start of the epoch: mem (CPU python)=41687.19140625MB; mem (CPU total)=65370.90625MB
INFO:root:[   83] Training loss: 0.66233883, Validation loss: 0.64408968, Gradient norm: 2.61477254
INFO:root:At the start of the epoch: mem (CPU python)=41725.28515625MB; mem (CPU total)=65446.9609375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[   84] Training loss: 0.66247740, Validation loss: 0.64470800, Gradient norm: 2.74482465
INFO:root:At the start of the epoch: mem (CPU python)=41763.37890625MB; mem (CPU total)=65538.90625MB
INFO:root:[   85] Training loss: 0.66229185, Validation loss: 0.64365977, Gradient norm: 2.48450620
INFO:root:At the start of the epoch: mem (CPU python)=41820.66796875MB; mem (CPU total)=65638.265625MB
INFO:root:[   86] Training loss: 0.66233628, Validation loss: 0.64363378, Gradient norm: 2.32379505
INFO:root:At the start of the epoch: mem (CPU python)=41862.796875MB; mem (CPU total)=65715.87890625MB
INFO:root:EP 86: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=41902.6640625MB; mem (CPU total)=65804.57421875MB
INFO:root:Training the model took 7435.49s.
INFO:root:Emptying the cuda cache took 0.027s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.91291
INFO:root:EnergyScoreTrain: 0.64269
INFO:root:CRPSTrain: 0.56913
INFO:root:Gaussian NLLTrain: 56664674085.54665
INFO:root:CoverageTrain: 0.575
INFO:root:IntervalWidthTrain: 2.54626
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.91471
INFO:root:EnergyScoreValidation: 0.64399
INFO:root:CRPSValidation: 0.57097
INFO:root:Gaussian NLLValidation: 57506467566.93331
INFO:root:CoverageValidation: 0.57467
INFO:root:IntervalWidthValidation: 2.54538
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.91647
INFO:root:EnergyScoreTest: 0.64522
INFO:root:CRPSTest: 0.57256
INFO:root:Gaussian NLLTest: 57746279301.12001
INFO:root:CoverageTest: 0.57613
INFO:root:IntervalWidthTest: 2.55203
INFO:root:After validation: mem (CPU python)=41903.62109375MB; mem (CPU total)=65853.484375MB
