INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:: mem (CPU python)=569.78125MB; mem (CPU total)=1058.97265625MB
INFO:root:############### Starting experiment with config file ks/fno_sr_reparam_n_samples3.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'KS', 'max_training_set_size': 10000, 'downscaling_factor': 1, 'temporal_downscaling': 2, 'init_steps': 20, 't_start': 0, 'pred_horizon': 20}
INFO:root:After loading the datasets: mem (CPU python)=12448.66015625MB; mem (CPU total)=1062.44921875MB
INFO:root:###1 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=12448.66015625MB; mem (CPU total)=1062.44921875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 2097152
INFO:root:After setting up the model: mem (CPU python)=12448.66015625MB; mem (CPU total)=2269.6875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=2279.1015625MB
INFO:root:[    1] Training loss: 0.72473743, Validation loss: 0.72024479, Gradient norm: 0.01831437
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3519.2890625MB
INFO:root:[    2] Training loss: 0.71975838, Validation loss: 0.71912561, Gradient norm: 0.00535776
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3582.33203125MB
INFO:root:[    3] Training loss: 0.71783079, Validation loss: 0.71424176, Gradient norm: 0.00685317
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3570.83984375MB
INFO:root:[    4] Training loss: 0.71120038, Validation loss: 0.70475694, Gradient norm: 0.01650625
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3633.9453125MB
INFO:root:[    5] Training loss: 0.70406894, Validation loss: 0.69807342, Gradient norm: 0.02441069
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3672.0MB
INFO:root:[    6] Training loss: 0.69854843, Validation loss: 0.69082555, Gradient norm: 0.02893134
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3710.328125MB
INFO:root:[    7] Training loss: 0.69279048, Validation loss: 0.68509410, Gradient norm: 0.02949733
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3748.421875MB
INFO:root:[    8] Training loss: 0.68696259, Validation loss: 0.67775359, Gradient norm: 0.02989675
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3786.50390625MB
INFO:root:[    9] Training loss: 0.68169476, Validation loss: 0.67286623, Gradient norm: 0.02882308
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3824.61328125MB
INFO:root:[   10] Training loss: 0.67722834, Validation loss: 0.66803938, Gradient norm: 0.02981184
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3863.09765625MB
INFO:root:[   11] Training loss: 0.67334291, Validation loss: 0.66345251, Gradient norm: 0.02985798
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3901.19140625MB
INFO:root:[   12] Training loss: 0.67003681, Validation loss: 0.65951659, Gradient norm: 0.03181240
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3939.48828125MB
INFO:root:[   13] Training loss: 0.66737446, Validation loss: 0.65783769, Gradient norm: 0.03585513
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=3976.83984375MB
INFO:root:[   14] Training loss: 0.66527419, Validation loss: 0.65573114, Gradient norm: 0.03400365
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4014.78125MB
INFO:root:[   15] Training loss: 0.66292143, Validation loss: 0.65342415, Gradient norm: 0.03340317
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4053.1484375MB
INFO:root:[   16] Training loss: 0.66118941, Validation loss: 0.65026601, Gradient norm: 0.03454772
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4091.77734375MB
INFO:root:[   17] Training loss: 0.65943008, Validation loss: 0.65063167, Gradient norm: 0.03389531
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4181.5546875MB
INFO:root:[   18] Training loss: 0.65809954, Validation loss: 0.64818751, Gradient norm: 0.03777430
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4169.20703125MB
INFO:root:[   19] Training loss: 0.65641675, Validation loss: 0.64730447, Gradient norm: 0.03708979
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4207.2421875MB
INFO:root:[   20] Training loss: 0.65504370, Validation loss: 0.64490433, Gradient norm: 0.03858060
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4245.73828125MB
INFO:root:[   21] Training loss: 0.65381474, Validation loss: 0.64440500, Gradient norm: 0.03701249
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4283.95703125MB
INFO:root:[   22] Training loss: 0.65255544, Validation loss: 0.64277184, Gradient norm: 0.03912374
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4322.17578125MB
INFO:root:[   23] Training loss: 0.65157118, Validation loss: 0.64115293, Gradient norm: 0.03943357
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4360.23828125MB
INFO:root:[   24] Training loss: 0.65046940, Validation loss: 0.64054308, Gradient norm: 0.04303072
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4398.5234375MB
INFO:root:[   25] Training loss: 0.64956878, Validation loss: 0.63954158, Gradient norm: 0.03964926
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4436.484375MB
INFO:root:[   26] Training loss: 0.64869024, Validation loss: 0.63895030, Gradient norm: 0.04352506
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4474.640625MB
INFO:root:[   27] Training loss: 0.64770260, Validation loss: 0.63785015, Gradient norm: 0.04316380
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4512.9453125MB
INFO:root:[   28] Training loss: 0.64680534, Validation loss: 0.63640378, Gradient norm: 0.04522080
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4551.12890625MB
INFO:root:[   29] Training loss: 0.64607676, Validation loss: 0.63657348, Gradient norm: 0.04587531
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4589.1640625MB
INFO:root:[   30] Training loss: 0.64500569, Validation loss: 0.63467965, Gradient norm: 0.04695909
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4627.3828125MB
INFO:root:[   31] Training loss: 0.64447114, Validation loss: 0.63409107, Gradient norm: 0.04825396
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4665.53515625MB
INFO:root:[   32] Training loss: 0.64374974, Validation loss: 0.63313474, Gradient norm: 0.05058730
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4703.78125MB
INFO:root:[   33] Training loss: 0.64285191, Validation loss: 0.63293314, Gradient norm: 0.04801713
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4741.96484375MB
INFO:root:[   34] Training loss: 0.64235805, Validation loss: 0.63274933, Gradient norm: 0.05045450
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4780.265625MB
INFO:root:[   35] Training loss: 0.64174079, Validation loss: 0.63204623, Gradient norm: 0.04888076
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4819.65625MB
INFO:root:[   36] Training loss: 0.64099427, Validation loss: 0.63085314, Gradient norm: 0.04619698
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4857.81640625MB
INFO:root:[   37] Training loss: 0.64049701, Validation loss: 0.63055715, Gradient norm: 0.05172775
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4896.0078125MB
INFO:root:[   38] Training loss: 0.63990667, Validation loss: 0.62904278, Gradient norm: 0.05161327
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4934.3125MB
INFO:root:[   39] Training loss: 0.63945472, Validation loss: 0.62870892, Gradient norm: 0.05069644
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=4972.7734375MB
INFO:root:[   40] Training loss: 0.63877732, Validation loss: 0.62958351, Gradient norm: 0.05054189
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5011.1796875MB
INFO:root:[   41] Training loss: 0.63827612, Validation loss: 0.62778601, Gradient norm: 0.05760443
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5049.0859375MB
INFO:root:[   42] Training loss: 0.63763737, Validation loss: 0.62764031, Gradient norm: 0.04891757
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5086.74609375MB
INFO:root:[   43] Training loss: 0.63722901, Validation loss: 0.62681840, Gradient norm: 0.04806073
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5125.12109375MB
INFO:root:[   44] Training loss: 0.63683317, Validation loss: 0.62735913, Gradient norm: 0.05130763
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5163.28125MB
INFO:root:[   45] Training loss: 0.63639463, Validation loss: 0.62581975, Gradient norm: 0.05229594
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5201.8359375MB
INFO:root:[   46] Training loss: 0.63575784, Validation loss: 0.62549247, Gradient norm: 0.05539670
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5289.78125MB
INFO:root:[   47] Training loss: 0.63545568, Validation loss: 0.62544969, Gradient norm: 0.04961932
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5278.00390625MB
INFO:root:[   48] Training loss: 0.63491056, Validation loss: 0.62510282, Gradient norm: 0.05038586
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5316.41015625MB
INFO:root:[   49] Training loss: 0.63443391, Validation loss: 0.62436902, Gradient norm: 0.05305342
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5354.5625MB
INFO:root:[   50] Training loss: 0.63403942, Validation loss: 0.62391581, Gradient norm: 0.04897477
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5392.72265625MB
INFO:root:[   51] Training loss: 0.63365718, Validation loss: 0.62395210, Gradient norm: 0.04845504
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5430.63671875MB
INFO:root:[   52] Training loss: 0.63330410, Validation loss: 0.62399693, Gradient norm: 0.06105547
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5468.8125MB
INFO:root:[   53] Training loss: 0.63301691, Validation loss: 0.62370194, Gradient norm: 0.05916741
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5507.12109375MB
INFO:root:[   54] Training loss: 0.63270570, Validation loss: 0.62310221, Gradient norm: 0.05628287
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5545.1796875MB
INFO:root:[   55] Training loss: 0.63204078, Validation loss: 0.62274053, Gradient norm: 0.05710643
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5583.59765625MB
INFO:root:[   56] Training loss: 0.63171554, Validation loss: 0.62231670, Gradient norm: 0.05720227
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5622.7265625MB
INFO:root:[   57] Training loss: 0.63157640, Validation loss: 0.62237639, Gradient norm: 0.05156387
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5660.875MB
INFO:root:[   58] Training loss: 0.63097689, Validation loss: 0.62196583, Gradient norm: 0.05483667
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5699.26953125MB
INFO:root:[   59] Training loss: 0.63072029, Validation loss: 0.62129606, Gradient norm: 0.05312485
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5737.5390625MB
INFO:root:[   60] Training loss: 0.63035324, Validation loss: 0.62067847, Gradient norm: 0.05701520
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5775.68359375MB
INFO:root:[   61] Training loss: 0.63018767, Validation loss: 0.62066703, Gradient norm: 0.05364382
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5813.7890625MB
INFO:root:[   62] Training loss: 0.62995608, Validation loss: 0.62043705, Gradient norm: 0.05318915
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5852.1796875MB
INFO:root:[   63] Training loss: 0.62948939, Validation loss: 0.62000879, Gradient norm: 0.05206294
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5890.5703125MB
INFO:root:[   64] Training loss: 0.62922538, Validation loss: 0.62071893, Gradient norm: 0.05275863
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5928.71484375MB
INFO:root:[   65] Training loss: 0.62909857, Validation loss: 0.62001357, Gradient norm: 0.06022180
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=5967.10546875MB
INFO:root:[   66] Training loss: 0.62880529, Validation loss: 0.61897393, Gradient norm: 0.05638367
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6005.00390625MB
INFO:root:[   67] Training loss: 0.62830404, Validation loss: 0.61918646, Gradient norm: 0.06118615
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6043.27734375MB
INFO:root:[   68] Training loss: 0.62815415, Validation loss: 0.61904816, Gradient norm: 0.06088565
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6081.66015625MB
INFO:root:[   69] Training loss: 0.62795766, Validation loss: 0.61823584, Gradient norm: 0.05393637
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6119.52734375MB
INFO:root:[   70] Training loss: 0.62754948, Validation loss: 0.61809118, Gradient norm: 0.05688448
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6157.671875MB
INFO:root:[   71] Training loss: 0.62720176, Validation loss: 0.61725548, Gradient norm: 0.05137035
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6195.55859375MB
INFO:root:[   72] Training loss: 0.62676842, Validation loss: 0.61736222, Gradient norm: 0.05657071
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6233.703125MB
INFO:root:[   73] Training loss: 0.62703444, Validation loss: 0.61751773, Gradient norm: 0.07009559
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6271.84375MB
INFO:root:[   74] Training loss: 0.62644455, Validation loss: 0.61674001, Gradient norm: 0.05459619
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6309.98828125MB
INFO:root:[   75] Training loss: 0.62598362, Validation loss: 0.61662453, Gradient norm: 0.05299617
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6347.88671875MB
INFO:root:[   76] Training loss: 0.62581435, Validation loss: 0.61639639, Gradient norm: 0.05242079
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6386.27734375MB
INFO:root:[   77] Training loss: 0.62583146, Validation loss: 0.61648288, Gradient norm: 0.05613541
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6424.421875MB
INFO:root:[   78] Training loss: 0.62568609, Validation loss: 0.61624494, Gradient norm: 0.05974256
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6462.53515625MB
INFO:root:[   79] Training loss: 0.62533389, Validation loss: 0.61524265, Gradient norm: 0.06135874
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6500.95703125MB
INFO:root:[   80] Training loss: 0.62506187, Validation loss: 0.61557361, Gradient norm: 0.05400281
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6538.85546875MB
INFO:root:[   81] Training loss: 0.62483191, Validation loss: 0.61516395, Gradient norm: 0.05429010
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6577.46875MB
INFO:root:[   82] Training loss: 0.62466071, Validation loss: 0.61525343, Gradient norm: 0.05702228
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6615.59765625MB
INFO:root:[   83] Training loss: 0.62454796, Validation loss: 0.61449130, Gradient norm: 0.05826772
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6654.2421875MB
INFO:root:[   84] Training loss: 0.62419049, Validation loss: 0.61466581, Gradient norm: 0.06064774
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6692.375MB
INFO:root:[   85] Training loss: 0.62396654, Validation loss: 0.61577717, Gradient norm: 0.05799340
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6730.51953125MB
INFO:root:[   86] Training loss: 0.62368113, Validation loss: 0.61467796, Gradient norm: 0.05659778
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6768.625MB
INFO:root:[   87] Training loss: 0.62358298, Validation loss: 0.61459056, Gradient norm: 0.05677743
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6806.5234375MB
INFO:root:[   88] Training loss: 0.62339215, Validation loss: 0.61483130, Gradient norm: 0.06024362
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6844.9140625MB
INFO:root:[   89] Training loss: 0.62310482, Validation loss: 0.61424487, Gradient norm: 0.06149606
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6883.05859375MB
INFO:root:[   90] Training loss: 0.62283528, Validation loss: 0.61404143, Gradient norm: 0.05994875
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6921.234375MB
INFO:root:[   91] Training loss: 0.62265418, Validation loss: 0.61368875, Gradient norm: 0.06718674
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6959.37890625MB
INFO:root:[   92] Training loss: 0.62270434, Validation loss: 0.61385512, Gradient norm: 0.05981351
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=6997.5234375MB
INFO:root:[   93] Training loss: 0.62241275, Validation loss: 0.61335958, Gradient norm: 0.06593784
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7035.9140625MB
INFO:root:[   94] Training loss: 0.62200896, Validation loss: 0.61316605, Gradient norm: 0.05499501
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7073.77734375MB
INFO:root:[   95] Training loss: 0.62192723, Validation loss: 0.61319665, Gradient norm: 0.06743414
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7111.8359375MB
INFO:root:[   96] Training loss: 0.62176669, Validation loss: 0.61311132, Gradient norm: 0.05607433
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7150.23828125MB
INFO:root:[   97] Training loss: 0.62180706, Validation loss: 0.61257191, Gradient norm: 0.06659905
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7188.14453125MB
INFO:root:[   98] Training loss: 0.62131974, Validation loss: 0.61247871, Gradient norm: 0.06284290
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7226.765625MB
INFO:root:[   99] Training loss: 0.62125804, Validation loss: 0.61203967, Gradient norm: 0.06768093
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7264.9609375MB
INFO:root:[  100] Training loss: 0.62133064, Validation loss: 0.61199995, Gradient norm: 0.06586094
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7302.875MB
INFO:root:[  101] Training loss: 0.62092922, Validation loss: 0.61193278, Gradient norm: 0.06113065
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7341.37109375MB
INFO:root:[  102] Training loss: 0.62079720, Validation loss: 0.61161173, Gradient norm: 0.05963969
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7379.52734375MB
INFO:root:[  103] Training loss: 0.62047939, Validation loss: 0.61187949, Gradient norm: 0.05380946
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7417.65625MB
INFO:root:[  104] Training loss: 0.62037941, Validation loss: 0.61180256, Gradient norm: 0.06191870
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7455.5546875MB
INFO:root:[  105] Training loss: 0.62022201, Validation loss: 0.61102783, Gradient norm: 0.05522693
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7494.48046875MB
INFO:root:[  106] Training loss: 0.62007301, Validation loss: 0.61116173, Gradient norm: 0.06003882
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7532.640625MB
INFO:root:[  107] Training loss: 0.61978836, Validation loss: 0.61177896, Gradient norm: 0.06170276
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7570.94921875MB
INFO:root:[  108] Training loss: 0.61971895, Validation loss: 0.61184483, Gradient norm: 0.06804485
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7608.98046875MB
INFO:root:[  109] Training loss: 0.61962223, Validation loss: 0.61109538, Gradient norm: 0.06572248
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7647.38671875MB
INFO:root:[  110] Training loss: 0.61938483, Validation loss: 0.61156647, Gradient norm: 0.06041310
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7685.796875MB
INFO:root:[  111] Training loss: 0.61936933, Validation loss: 0.61126292, Gradient norm: 0.06544301
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7723.703125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  112] Training loss: 0.61908987, Validation loss: 0.61027993, Gradient norm: 0.06161006
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7761.6015625MB
INFO:root:[  113] Training loss: 0.61812949, Validation loss: 0.61028890, Gradient norm: 0.05583508
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7800.01171875MB
INFO:root:[  114] Training loss: 0.61810688, Validation loss: 0.60919205, Gradient norm: 0.05113855
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7837.921875MB
INFO:root:[  115] Training loss: 0.61781179, Validation loss: 0.60989170, Gradient norm: 0.05535465
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7876.0859375MB
INFO:root:[  116] Training loss: 0.61781455, Validation loss: 0.61028296, Gradient norm: 0.05124556
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7914.24609375MB
INFO:root:[  117] Training loss: 0.61780277, Validation loss: 0.61008632, Gradient norm: 0.05748605
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7952.65234375MB
INFO:root:[  118] Training loss: 0.61756767, Validation loss: 0.61027038, Gradient norm: 0.05327166
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=7990.5703125MB
INFO:root:[  119] Training loss: 0.61735835, Validation loss: 0.61021091, Gradient norm: 0.05400187
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8028.484375MB
INFO:root:[  120] Training loss: 0.61753985, Validation loss: 0.60974628, Gradient norm: 0.05680757
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8066.89453125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  121] Training loss: 0.61725349, Validation loss: 0.60942747, Gradient norm: 0.05447388
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8104.66015625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  122] Training loss: 0.61687911, Validation loss: 0.60908522, Gradient norm: 0.04963597
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8143.20703125MB
INFO:root:[  123] Training loss: 0.61646517, Validation loss: 0.60924195, Gradient norm: 0.04763998
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8180.9765625MB
INFO:root:[  124] Training loss: 0.61649242, Validation loss: 0.60956258, Gradient norm: 0.04760191
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8219.12109375MB
INFO:root:[  125] Training loss: 0.61630300, Validation loss: 0.60877094, Gradient norm: 0.05037372
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8257.31640625MB
INFO:root:[  126] Training loss: 0.61639465, Validation loss: 0.60958595, Gradient norm: 0.04889173
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8295.4765625MB
INFO:root:[  127] Training loss: 0.61609086, Validation loss: 0.60938297, Gradient norm: 0.04893946
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8333.88671875MB
INFO:root:[  128] Training loss: 0.61613856, Validation loss: 0.60894152, Gradient norm: 0.04934994
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8371.76171875MB
INFO:root:[  129] Training loss: 0.61628689, Validation loss: 0.60924491, Gradient norm: 0.05194053
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8409.90625MB
INFO:root:[  130] Training loss: 0.61629603, Validation loss: 0.60904616, Gradient norm: 0.04783086
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8448.05078125MB
INFO:root:[  131] Training loss: 0.61634549, Validation loss: 0.60865295, Gradient norm: 0.05150525
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8486.2265625MB
INFO:root:[  132] Training loss: 0.61616706, Validation loss: 0.60905318, Gradient norm: 0.04888498
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8574.73046875MB
INFO:root:[  133] Training loss: 0.61633639, Validation loss: 0.60841709, Gradient norm: 0.04888787
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8562.703125MB
INFO:root:[  134] Training loss: 0.61620355, Validation loss: 0.60871005, Gradient norm: 0.05084178
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8601.84375MB
INFO:root:[  135] Training loss: 0.61638522, Validation loss: 0.60873324, Gradient norm: 0.05055732
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8639.98828125MB
INFO:root:[  136] Training loss: 0.61626046, Validation loss: 0.60882252, Gradient norm: 0.05015197
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8654.1640625MB
INFO:root:[  137] Training loss: 0.61614256, Validation loss: 0.60892720, Gradient norm: 0.04966767
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8691.32421875MB
INFO:root:[  138] Training loss: 0.61608037, Validation loss: 0.60840316, Gradient norm: 0.04931854
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8729.5MB
INFO:root:[  139] Training loss: 0.61620509, Validation loss: 0.60905676, Gradient norm: 0.05345426
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8792.84375MB
INFO:root:[  140] Training loss: 0.61614982, Validation loss: 0.60934591, Gradient norm: 0.05053606
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8830.95703125MB
INFO:root:[  141] Training loss: 0.61604245, Validation loss: 0.60925346, Gradient norm: 0.04929226
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8869.1015625MB
INFO:root:[  142] Training loss: 0.61593297, Validation loss: 0.60800171, Gradient norm: 0.04980604
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8907.26953125MB
INFO:root:[  143] Training loss: 0.61603875, Validation loss: 0.60907512, Gradient norm: 0.04956455
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8945.16796875MB
INFO:root:[  144] Training loss: 0.61590392, Validation loss: 0.60916180, Gradient norm: 0.04890356
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=8983.06640625MB
INFO:root:[  145] Training loss: 0.61591178, Validation loss: 0.60829787, Gradient norm: 0.05178828
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9021.45703125MB
INFO:root:[  146] Training loss: 0.61576202, Validation loss: 0.60896061, Gradient norm: 0.05136061
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9059.84765625MB
INFO:root:[  147] Training loss: 0.61578390, Validation loss: 0.60869625, Gradient norm: 0.05109205
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9098.0MB
INFO:root:[  148] Training loss: 0.61569511, Validation loss: 0.60876991, Gradient norm: 0.04976880
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9136.14453125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  149] Training loss: 0.61577123, Validation loss: 0.60853464, Gradient norm: 0.05047193
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9174.2265625MB
INFO:root:[  150] Training loss: 0.61567833, Validation loss: 0.60849874, Gradient norm: 0.04892161
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9262.5546875MB
INFO:root:[  151] Training loss: 0.61569416, Validation loss: 0.60864153, Gradient norm: 0.04865928
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9225.80859375MB
INFO:root:EP 151: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=12448.66015625MB; mem (CPU total)=9288.66015625MB
INFO:root:Training the model took 6569.395s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84808
INFO:root:EnergyScoreTrain: 0.59704
INFO:root:CRPSTrain: 0.46425
INFO:root:Gaussian NLLTrain: 1.19987
INFO:root:CoverageTrain: 0.94854
INFO:root:IntervalWidthTrain: 3.27086
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86488
INFO:root:EnergyScoreValidation: 0.60876
INFO:root:CRPSValidation: 0.47428
INFO:root:Gaussian NLLValidation: 1.2242
INFO:root:CoverageValidation: 0.94276
INFO:root:IntervalWidthValidation: 3.27163
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86613
INFO:root:EnergyScoreTest: 0.60962
INFO:root:CRPSTest: 0.47512
INFO:root:Gaussian NLLTest: 1.22593
INFO:root:CoverageTest: 0.94257
INFO:root:IntervalWidthTest: 3.27469
INFO:root:After validation: mem (CPU python)=12448.66015625MB; mem (CPU total)=9342.35546875MB
INFO:root:###2 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=12448.66015625MB; mem (CPU total)=9342.3515625MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=12448.66015625MB; mem (CPU total)=9342.84375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9342.84375MB
INFO:root:[    1] Training loss: 0.72516023, Validation loss: 0.72043188, Gradient norm: 0.02248975
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9524.6328125MB
INFO:root:[    2] Training loss: 0.71969884, Validation loss: 0.71807846, Gradient norm: 0.00580481
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9563.0234375MB
INFO:root:[    3] Training loss: 0.71730731, Validation loss: 0.71305023, Gradient norm: 0.00967113
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9475.84765625MB
INFO:root:[    4] Training loss: 0.71021208, Validation loss: 0.70421867, Gradient norm: 0.01697039
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9564.421875MB
INFO:root:[    5] Training loss: 0.70371212, Validation loss: 0.69793416, Gradient norm: 0.02357812
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9576.59765625MB
INFO:root:[    6] Training loss: 0.69838324, Validation loss: 0.69247646, Gradient norm: 0.02822631
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9665.19140625MB
INFO:root:[    7] Training loss: 0.69380246, Validation loss: 0.68685234, Gradient norm: 0.02649253
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9603.4609375MB
INFO:root:[    8] Training loss: 0.69004357, Validation loss: 0.68268483, Gradient norm: 0.02841882
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9716.53125MB
INFO:root:[    9] Training loss: 0.68645941, Validation loss: 0.67916475, Gradient norm: 0.02727432
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9754.9140625MB
INFO:root:[   10] Training loss: 0.68357046, Validation loss: 0.67605563, Gradient norm: 0.02874182
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9792.8125MB
INFO:root:[   11] Training loss: 0.68084339, Validation loss: 0.67302469, Gradient norm: 0.03162551
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9831.19921875MB
INFO:root:[   12] Training loss: 0.67835486, Validation loss: 0.67012999, Gradient norm: 0.03063922
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9844.359375MB
INFO:root:[   13] Training loss: 0.67609652, Validation loss: 0.66794441, Gradient norm: 0.03034932
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9907.734375MB
INFO:root:[   14] Training loss: 0.67411382, Validation loss: 0.66631798, Gradient norm: 0.03258716
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9970.578125MB
INFO:root:[   15] Training loss: 0.67235159, Validation loss: 0.66477708, Gradient norm: 0.03463993
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9933.5859375MB
INFO:root:[   16] Training loss: 0.67060499, Validation loss: 0.66254999, Gradient norm: 0.03460287
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=9971.69921875MB
INFO:root:[   17] Training loss: 0.66906976, Validation loss: 0.66019605, Gradient norm: 0.03426339
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10059.78125MB
INFO:root:[   18] Training loss: 0.66746456, Validation loss: 0.65974273, Gradient norm: 0.03240346
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10097.078125MB
INFO:root:[   19] Training loss: 0.66612929, Validation loss: 0.65730102, Gradient norm: 0.03419003
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10086.24609375MB
INFO:root:[   20] Training loss: 0.66509468, Validation loss: 0.65611241, Gradient norm: 0.03575157
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10199.51953125MB
INFO:root:[   21] Training loss: 0.66371184, Validation loss: 0.65455026, Gradient norm: 0.03310909
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10237.171875MB
INFO:root:[   22] Training loss: 0.66275609, Validation loss: 0.65577397, Gradient norm: 0.03725211
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10200.1796875MB
INFO:root:[   23] Training loss: 0.66158650, Validation loss: 0.65242529, Gradient norm: 0.03728028
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10263.5234375MB
INFO:root:[   24] Training loss: 0.66040608, Validation loss: 0.65212400, Gradient norm: 0.03547443
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10351.41796875MB
INFO:root:[   25] Training loss: 0.65958017, Validation loss: 0.65059337, Gradient norm: 0.03908094
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10389.80859375MB
INFO:root:[   26] Training loss: 0.65854474, Validation loss: 0.64999883, Gradient norm: 0.03633617
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10428.30078125MB
INFO:root:[   27] Training loss: 0.65780896, Validation loss: 0.64811526, Gradient norm: 0.04167260
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10466.453125MB
INFO:root:[   28] Training loss: 0.65681171, Validation loss: 0.64781059, Gradient norm: 0.04398064
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10504.4140625MB
INFO:root:[   29] Training loss: 0.65595162, Validation loss: 0.64667072, Gradient norm: 0.04214902
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10494.0859375MB
INFO:root:[   30] Training loss: 0.65521545, Validation loss: 0.64568530, Gradient norm: 0.03941252
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10555.93359375MB
INFO:root:[   31] Training loss: 0.65437769, Validation loss: 0.64508304, Gradient norm: 0.04089515
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10669.46875MB
INFO:root:[   32] Training loss: 0.65360935, Validation loss: 0.64445346, Gradient norm: 0.04395215
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10707.31640625MB
INFO:root:[   33] Training loss: 0.65289832, Validation loss: 0.64358303, Gradient norm: 0.04313748
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10670.34375MB
INFO:root:[   34] Training loss: 0.65228410, Validation loss: 0.64327276, Gradient norm: 0.04272451
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10683.37109375MB
INFO:root:[   35] Training loss: 0.65139181, Validation loss: 0.64379860, Gradient norm: 0.04367596
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10721.78125MB
INFO:root:[   36] Training loss: 0.65094352, Validation loss: 0.64277084, Gradient norm: 0.04336068
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10735.2578125MB
INFO:root:[   37] Training loss: 0.65030262, Validation loss: 0.64054958, Gradient norm: 0.04662647
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10822.62109375MB
INFO:root:[   38] Training loss: 0.64950860, Validation loss: 0.63987139, Gradient norm: 0.04562577
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10860.81640625MB
INFO:root:[   39] Training loss: 0.64909038, Validation loss: 0.64082782, Gradient norm: 0.04826532
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10923.93359375MB
INFO:root:[   40] Training loss: 0.64863179, Validation loss: 0.63951728, Gradient norm: 0.04713347
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=10962.734375MB
INFO:root:[   41] Training loss: 0.64782902, Validation loss: 0.63910344, Gradient norm: 0.04363129
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11025.734375MB
INFO:root:[   42] Training loss: 0.64735142, Validation loss: 0.63819088, Gradient norm: 0.04623110
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11063.65234375MB
INFO:root:[   43] Training loss: 0.64673633, Validation loss: 0.63796054, Gradient norm: 0.04149770
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11051.61328125MB
INFO:root:[   44] Training loss: 0.64641442, Validation loss: 0.63730842, Gradient norm: 0.05038657
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11114.72265625MB
INFO:root:[   45] Training loss: 0.64574352, Validation loss: 0.63595937, Gradient norm: 0.05084802
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11102.84765625MB
INFO:root:[   46] Training loss: 0.64515019, Validation loss: 0.63567321, Gradient norm: 0.04714423
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11116.40234375MB
INFO:root:[   47] Training loss: 0.64479987, Validation loss: 0.63495847, Gradient norm: 0.04756193
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11204.01171875MB
INFO:root:[   48] Training loss: 0.64408816, Validation loss: 0.63461464, Gradient norm: 0.04779034
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11267.375MB
INFO:root:[   49] Training loss: 0.64378380, Validation loss: 0.63559948, Gradient norm: 0.04990684
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11305.29296875MB
INFO:root:[   50] Training loss: 0.64337269, Validation loss: 0.63377225, Gradient norm: 0.04871643
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11244.07421875MB
INFO:root:[   51] Training loss: 0.64286930, Validation loss: 0.63403749, Gradient norm: 0.05292039
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11257.27734375MB
INFO:root:[   52] Training loss: 0.64259235, Validation loss: 0.63373751, Gradient norm: 0.04960913
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11394.546875MB
INFO:root:[   53] Training loss: 0.64194612, Validation loss: 0.63185045, Gradient norm: 0.04772447
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11432.703125MB
INFO:root:[   54] Training loss: 0.64176283, Validation loss: 0.63219355, Gradient norm: 0.04541532
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11521.296875MB
INFO:root:[   55] Training loss: 0.64138768, Validation loss: 0.63302645, Gradient norm: 0.04804069
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11559.73046875MB
INFO:root:[   56] Training loss: 0.64102748, Validation loss: 0.63116521, Gradient norm: 0.05239174
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11572.78125MB
INFO:root:[   57] Training loss: 0.64055874, Validation loss: 0.63114576, Gradient norm: 0.04971007
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11610.9375MB
INFO:root:[   58] Training loss: 0.64009308, Validation loss: 0.63086086, Gradient norm: 0.05131868
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11624.5390625MB
INFO:root:[   59] Training loss: 0.63985816, Validation loss: 0.63027374, Gradient norm: 0.05043914
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11587.23046875MB
INFO:root:[   60] Training loss: 0.63941801, Validation loss: 0.63169396, Gradient norm: 0.05680219
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11676.51171875MB
INFO:root:[   61] Training loss: 0.63889768, Validation loss: 0.62953784, Gradient norm: 0.05196422
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11663.48828125MB
INFO:root:[   62] Training loss: 0.63858057, Validation loss: 0.62944029, Gradient norm: 0.05266078
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11776.578125MB
INFO:root:[   63] Training loss: 0.63848583, Validation loss: 0.62946616, Gradient norm: 0.05925822
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11939.796875MB
INFO:root:[   64] Training loss: 0.63785443, Validation loss: 0.62840910, Gradient norm: 0.04852630
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11852.8671875MB
INFO:root:[   65] Training loss: 0.63771900, Validation loss: 0.62944927, Gradient norm: 0.04902530
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11941.1953125MB
INFO:root:[   66] Training loss: 0.63736105, Validation loss: 0.62860442, Gradient norm: 0.05405039
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11979.33984375MB
INFO:root:[   67] Training loss: 0.63709802, Validation loss: 0.62835580, Gradient norm: 0.05133976
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=11942.859375MB
INFO:root:[   68] Training loss: 0.63679093, Validation loss: 0.62723986, Gradient norm: 0.05015925
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12005.98828125MB
INFO:root:[   69] Training loss: 0.63629429, Validation loss: 0.62779383, Gradient norm: 0.04923265
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12044.37109375MB
INFO:root:[   70] Training loss: 0.63611932, Validation loss: 0.62833954, Gradient norm: 0.05308218
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12082.26953125MB
INFO:root:[   71] Training loss: 0.63590891, Validation loss: 0.62663540, Gradient norm: 0.05132257
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12145.859375MB
INFO:root:[   72] Training loss: 0.63574431, Validation loss: 0.62652143, Gradient norm: 0.05760096
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12133.81640625MB
INFO:root:[   73] Training loss: 0.63538979, Validation loss: 0.62567907, Gradient norm: 0.05725664
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12121.77734375MB
INFO:root:[   74] Training loss: 0.63506047, Validation loss: 0.62588208, Gradient norm: 0.05836060
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12260.04296875MB
INFO:root:[   75] Training loss: 0.63466533, Validation loss: 0.62743805, Gradient norm: 0.05349262
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12298.1875MB
INFO:root:[   76] Training loss: 0.63454989, Validation loss: 0.62521980, Gradient norm: 0.05173434
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12336.33203125MB
INFO:root:[   77] Training loss: 0.63436771, Validation loss: 0.62449849, Gradient norm: 0.06135028
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12324.53125MB
INFO:root:[   78] Training loss: 0.63399045, Validation loss: 0.62548225, Gradient norm: 0.05726079
INFO:root:At the start of the epoch: mem (CPU python)=12448.66015625MB; mem (CPU total)=12387.66015625MB
INFO:root:[   79] Training loss: 0.63373204, Validation loss: 0.62577422, Gradient norm: 0.05474217
INFO:root:At the start of the epoch: mem (CPU python)=12482.421875MB; mem (CPU total)=12425.66796875MB
INFO:root:[   80] Training loss: 0.63338387, Validation loss: 0.62611075, Gradient norm: 0.05303883
INFO:root:At the start of the epoch: mem (CPU python)=12494.73046875MB; mem (CPU total)=12388.859375MB
INFO:root:[   81] Training loss: 0.63330544, Validation loss: 0.62594101, Gradient norm: 0.05483265
INFO:root:At the start of the epoch: mem (CPU python)=12533.61328125MB; mem (CPU total)=12477.203125MB
INFO:root:[   82] Training loss: 0.63299738, Validation loss: 0.62462655, Gradient norm: 0.05183947
INFO:root:At the start of the epoch: mem (CPU python)=12571.7109375MB; mem (CPU total)=12515.5859375MB
INFO:root:[   83] Training loss: 0.63297937, Validation loss: 0.62402278, Gradient norm: 0.06099398
INFO:root:At the start of the epoch: mem (CPU python)=12632.0234375MB; mem (CPU total)=12528.74609375MB
INFO:root:[   84] Training loss: 0.63264473, Validation loss: 0.62463518, Gradient norm: 0.05468465
INFO:root:At the start of the epoch: mem (CPU python)=12672.8984375MB; mem (CPU total)=12616.859375MB
INFO:root:[   85] Training loss: 0.63236655, Validation loss: 0.62370317, Gradient norm: 0.05560493
INFO:root:At the start of the epoch: mem (CPU python)=12710.99609375MB; mem (CPU total)=12654.7890625MB
INFO:root:[   86] Training loss: 0.63189162, Validation loss: 0.62405478, Gradient norm: 0.05076705
INFO:root:At the start of the epoch: mem (CPU python)=12799.08984375MB; mem (CPU total)=12743.36328125MB
INFO:root:[   87] Training loss: 0.63195407, Validation loss: 0.62358724, Gradient norm: 0.05581371
INFO:root:At the start of the epoch: mem (CPU python)=12837.18359375MB; mem (CPU total)=12781.5390625MB
INFO:root:[   88] Training loss: 0.63155572, Validation loss: 0.62264774, Gradient norm: 0.05144821
INFO:root:At the start of the epoch: mem (CPU python)=12875.26171875MB; mem (CPU total)=12745.0390625MB
INFO:root:[   89] Training loss: 0.63152228, Validation loss: 0.62340150, Gradient norm: 0.05492196
INFO:root:At the start of the epoch: mem (CPU python)=12961.875MB; mem (CPU total)=12807.921875MB
INFO:root:[   90] Training loss: 0.63118532, Validation loss: 0.62396636, Gradient norm: 0.05132438
INFO:root:At the start of the epoch: mem (CPU python)=12961.875MB; mem (CPU total)=12845.75MB
INFO:root:[   91] Training loss: 0.63085396, Validation loss: 0.62264225, Gradient norm: 0.05375193
INFO:root:At the start of the epoch: mem (CPU python)=12964.56640625MB; mem (CPU total)=12909.07421875MB
INFO:root:[   92] Training loss: 0.63071312, Validation loss: 0.62268875, Gradient norm: 0.05517471
INFO:root:At the start of the epoch: mem (CPU python)=13002.6640625MB; mem (CPU total)=12946.9609375MB
INFO:root:[   93] Training loss: 0.63058284, Validation loss: 0.62215199, Gradient norm: 0.05487383
INFO:root:At the start of the epoch: mem (CPU python)=13065.7578125MB; mem (CPU total)=13010.328125MB
INFO:root:[   94] Training loss: 0.63042328, Validation loss: 0.62114750, Gradient norm: 0.05439351
INFO:root:At the start of the epoch: mem (CPU python)=13103.8515625MB; mem (CPU total)=13048.44140625MB
INFO:root:[   95] Training loss: 0.63012445, Validation loss: 0.62140719, Gradient norm: 0.05389251
INFO:root:At the start of the epoch: mem (CPU python)=13116.953125MB; mem (CPU total)=13061.6015625MB
INFO:root:[   96] Training loss: 0.62997226, Validation loss: 0.62220061, Gradient norm: 0.05522438
INFO:root:At the start of the epoch: mem (CPU python)=13155.046875MB; mem (CPU total)=13099.73046875MB
INFO:root:[   97] Training loss: 0.62992401, Validation loss: 0.62201856, Gradient norm: 0.05610059
INFO:root:At the start of the epoch: mem (CPU python)=13168.140625MB; mem (CPU total)=13112.78125MB
INFO:root:[   98] Training loss: 0.62970935, Validation loss: 0.62335528, Gradient norm: 0.06260405
INFO:root:At the start of the epoch: mem (CPU python)=13177.1796875MB; mem (CPU total)=13075.7578125MB
INFO:root:[   99] Training loss: 0.62935295, Validation loss: 0.62132123, Gradient norm: 0.05640170
INFO:root:At the start of the epoch: mem (CPU python)=13269.33203125MB; mem (CPU total)=13214.0234375MB
INFO:root:[  100] Training loss: 0.62913687, Validation loss: 0.62171606, Gradient norm: 0.05323038
INFO:root:At the start of the epoch: mem (CPU python)=13307.42578125MB; mem (CPU total)=13252.06640625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  101] Training loss: 0.62920082, Validation loss: 0.62173696, Gradient norm: 0.06228616
INFO:root:At the start of the epoch: mem (CPU python)=13345.51953125MB; mem (CPU total)=13290.71875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  102] Training loss: 0.62819764, Validation loss: 0.61967419, Gradient norm: 0.05050432
INFO:root:At the start of the epoch: mem (CPU python)=13383.6171875MB; mem (CPU total)=13328.89453125MB
INFO:root:[  103] Training loss: 0.62752401, Validation loss: 0.62026542, Gradient norm: 0.04654466
INFO:root:At the start of the epoch: mem (CPU python)=13444.2890625MB; mem (CPU total)=13316.88671875MB
INFO:root:[  104] Training loss: 0.62723270, Validation loss: 0.62016817, Gradient norm: 0.04613697
INFO:root:At the start of the epoch: mem (CPU python)=13444.2890625MB; mem (CPU total)=13330.078125MB
INFO:root:[  105] Training loss: 0.62725842, Validation loss: 0.61932806, Gradient norm: 0.04730572
INFO:root:At the start of the epoch: mem (CPU python)=13447.90625MB; mem (CPU total)=13393.44140625MB
INFO:root:[  106] Training loss: 0.62710672, Validation loss: 0.62094252, Gradient norm: 0.04847109
INFO:root:At the start of the epoch: mem (CPU python)=13536.0MB; mem (CPU total)=13481.5390625MB
INFO:root:[  107] Training loss: 0.62728549, Validation loss: 0.62008575, Gradient norm: 0.04746010
INFO:root:At the start of the epoch: mem (CPU python)=13574.09375MB; mem (CPU total)=13519.94921875MB
INFO:root:[  108] Training loss: 0.62714764, Validation loss: 0.61997788, Gradient norm: 0.04762065
INFO:root:At the start of the epoch: mem (CPU python)=13635.421875MB; mem (CPU total)=13482.9765625MB
INFO:root:[  109] Training loss: 0.62690788, Validation loss: 0.62049803, Gradient norm: 0.04804112
INFO:root:At the start of the epoch: mem (CPU python)=13650.28515625MB; mem (CPU total)=13596.03125MB
INFO:root:[  110] Training loss: 0.62688727, Validation loss: 0.61996885, Gradient norm: 0.04738629
INFO:root:At the start of the epoch: mem (CPU python)=13688.37890625MB; mem (CPU total)=13634.19140625MB
INFO:root:[  111] Training loss: 0.62696753, Validation loss: 0.62001546, Gradient norm: 0.04651773
INFO:root:At the start of the epoch: mem (CPU python)=13688.65625MB; mem (CPU total)=13598.41015625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  112] Training loss: 0.62706857, Validation loss: 0.61969389, Gradient norm: 0.04896557
INFO:root:At the start of the epoch: mem (CPU python)=13741.578125MB; mem (CPU total)=13687.5546875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  113] Training loss: 0.62668048, Validation loss: 0.61967031, Gradient norm: 0.04522485
INFO:root:At the start of the epoch: mem (CPU python)=13779.671875MB; mem (CPU total)=13725.9921875MB
INFO:root:[  114] Training loss: 0.62655292, Validation loss: 0.61950864, Gradient norm: 0.04569284
INFO:root:At the start of the epoch: mem (CPU python)=13867.765625MB; mem (CPU total)=13814.09375MB
INFO:root:[  115] Training loss: 0.62649123, Validation loss: 0.61907996, Gradient norm: 0.04595296
INFO:root:At the start of the epoch: mem (CPU python)=13867.96875MB; mem (CPU total)=13777.12109375MB
INFO:root:[  116] Training loss: 0.62659999, Validation loss: 0.61937387, Gradient norm: 0.04451229
INFO:root:At the start of the epoch: mem (CPU python)=13893.95703125MB; mem (CPU total)=13840.44140625MB
INFO:root:[  117] Training loss: 0.62642795, Validation loss: 0.61893351, Gradient norm: 0.04645195
INFO:root:At the start of the epoch: mem (CPU python)=13932.05078125MB; mem (CPU total)=13878.6484375MB
INFO:root:[  118] Training loss: 0.62624294, Validation loss: 0.61896327, Gradient norm: 0.04500253
INFO:root:At the start of the epoch: mem (CPU python)=13970.14453125MB; mem (CPU total)=13916.79296875MB
INFO:root:[  119] Training loss: 0.62651348, Validation loss: 0.61891662, Gradient norm: 0.04451412
INFO:root:At the start of the epoch: mem (CPU python)=14008.24609375MB; mem (CPU total)=13955.18359375MB
INFO:root:[  120] Training loss: 0.62639743, Validation loss: 0.61917766, Gradient norm: 0.04535979
INFO:root:At the start of the epoch: mem (CPU python)=14021.3359375MB; mem (CPU total)=13968.09765625MB
INFO:root:[  121] Training loss: 0.62630164, Validation loss: 0.61920327, Gradient norm: 0.04549338
INFO:root:At the start of the epoch: mem (CPU python)=14184.26953125MB; mem (CPU total)=14007.2265625MB
INFO:root:[  122] Training loss: 0.62615130, Validation loss: 0.61906694, Gradient norm: 0.04422532
INFO:root:At the start of the epoch: mem (CPU python)=14184.26953125MB; mem (CPU total)=14020.171875MB
INFO:root:[  123] Training loss: 0.62630980, Validation loss: 0.61915946, Gradient norm: 0.04487564
INFO:root:At the start of the epoch: mem (CPU python)=14184.26953125MB; mem (CPU total)=14107.4453125MB
INFO:root:[  124] Training loss: 0.62621906, Validation loss: 0.61893208, Gradient norm: 0.04518606
INFO:root:At the start of the epoch: mem (CPU python)=14198.72265625MB; mem (CPU total)=14145.58984375MB
INFO:root:[  125] Training loss: 0.62626188, Validation loss: 0.61867154, Gradient norm: 0.04418579
INFO:root:At the start of the epoch: mem (CPU python)=14311.81640625MB; mem (CPU total)=14258.9921875MB
INFO:root:[  126] Training loss: 0.62615724, Validation loss: 0.61921792, Gradient norm: 0.04328693
INFO:root:At the start of the epoch: mem (CPU python)=14324.9140625MB; mem (CPU total)=14272.20703125MB
INFO:root:[  127] Training loss: 0.62610690, Validation loss: 0.61917261, Gradient norm: 0.04477484
INFO:root:At the start of the epoch: mem (CPU python)=14363.0078125MB; mem (CPU total)=14310.3515625MB
INFO:root:[  128] Training loss: 0.62622501, Validation loss: 0.61933251, Gradient norm: 0.04577051
INFO:root:At the start of the epoch: mem (CPU python)=14401.10546875MB; mem (CPU total)=14348.49609375MB
INFO:root:[  129] Training loss: 0.62621564, Validation loss: 0.61930695, Gradient norm: 0.04478065
INFO:root:At the start of the epoch: mem (CPU python)=14489.203125MB; mem (CPU total)=14436.578125MB
INFO:root:[  130] Training loss: 0.62615929, Validation loss: 0.61996089, Gradient norm: 0.04523838
INFO:root:At the start of the epoch: mem (CPU python)=14489.4765625MB; mem (CPU total)=14399.80078125MB
INFO:root:[  131] Training loss: 0.62626588, Validation loss: 0.61882104, Gradient norm: 0.04413698
INFO:root:At the start of the epoch: mem (CPU python)=14489.4765625MB; mem (CPU total)=14362.72265625MB
INFO:root:[  132] Training loss: 0.62617598, Validation loss: 0.61893358, Gradient norm: 0.04446793
INFO:root:At the start of the epoch: mem (CPU python)=14553.484375MB; mem (CPU total)=14500.98828125MB
INFO:root:[  133] Training loss: 0.62620304, Validation loss: 0.61870948, Gradient norm: 0.04432104
INFO:root:At the start of the epoch: mem (CPU python)=14591.58203125MB; mem (CPU total)=14538.88671875MB
INFO:root:[  134] Training loss: 0.62614447, Validation loss: 0.61927376, Gradient norm: 0.04632062
INFO:root:At the start of the epoch: mem (CPU python)=14604.67578125MB; mem (CPU total)=14552.29296875MB
INFO:root:EP 134: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=14642.76953125MB; mem (CPU total)=14590.4375MB
INFO:root:Training the model took 6817.764s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.86245
INFO:root:EnergyScoreTrain: 0.60711
INFO:root:CRPSTrain: 0.47676
INFO:root:Gaussian NLLTrain: 1.23609
INFO:root:CoverageTrain: 0.94623
INFO:root:IntervalWidthTrain: 3.32877
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.87948
INFO:root:EnergyScoreValidation: 0.61902
INFO:root:CRPSValidation: 0.48707
INFO:root:Gaussian NLLValidation: 1.25961
INFO:root:CoverageValidation: 0.94083
INFO:root:IntervalWidthValidation: 3.33095
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.88009
INFO:root:EnergyScoreTest: 0.61944
INFO:root:CRPSTest: 0.48735
INFO:root:Gaussian NLLTest: 1.25997
INFO:root:CoverageTest: 0.94058
INFO:root:IntervalWidthTest: 3.33036
INFO:root:After validation: mem (CPU python)=14685.8359375MB; mem (CPU total)=14632.72265625MB
INFO:root:###3 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=14685.8359375MB; mem (CPU total)=14633.3203125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=14686.07421875MB; mem (CPU total)=14633.8125MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=14686.234375MB; mem (CPU total)=14633.8125MB
INFO:root:[    1] Training loss: 0.72434507, Validation loss: 0.71995494, Gradient norm: 0.01890645
INFO:root:At the start of the epoch: mem (CPU python)=14724.2734375MB; mem (CPU total)=14672.06640625MB
INFO:root:[    2] Training loss: 0.71983606, Validation loss: 0.71909955, Gradient norm: 0.00572923
INFO:root:At the start of the epoch: mem (CPU python)=14862.3671875MB; mem (CPU total)=14810.640625MB
INFO:root:[    3] Training loss: 0.71787641, Validation loss: 0.71409005, Gradient norm: 0.00795376
INFO:root:At the start of the epoch: mem (CPU python)=14900.46484375MB; mem (CPU total)=14848.78515625MB
INFO:root:[    4] Training loss: 0.71049729, Validation loss: 0.70376791, Gradient norm: 0.01803667
INFO:root:At the start of the epoch: mem (CPU python)=14900.74609375MB; mem (CPU total)=14786.80859375MB
INFO:root:[    5] Training loss: 0.70299997, Validation loss: 0.69644465, Gradient norm: 0.02465543
INFO:root:At the start of the epoch: mem (CPU python)=14901.6875MB; mem (CPU total)=14850.18359375MB
INFO:root:[    6] Training loss: 0.69713923, Validation loss: 0.69083650, Gradient norm: 0.02981568
INFO:root:At the start of the epoch: mem (CPU python)=14914.78125MB; mem (CPU total)=14863.33984375MB
INFO:root:[    7] Training loss: 0.69163820, Validation loss: 0.68359414, Gradient norm: 0.03102260
INFO:root:At the start of the epoch: mem (CPU python)=14977.875MB; mem (CPU total)=14926.68359375MB
INFO:root:[    8] Training loss: 0.68619384, Validation loss: 0.67765846, Gradient norm: 0.02941004
INFO:root:At the start of the epoch: mem (CPU python)=14990.97265625MB; mem (CPU total)=14939.3359375MB
INFO:root:[    9] Training loss: 0.68142200, Validation loss: 0.67317253, Gradient norm: 0.03073176
INFO:root:At the start of the epoch: mem (CPU python)=15079.0703125MB; mem (CPU total)=15027.6953125MB
INFO:root:[   10] Training loss: 0.67733367, Validation loss: 0.66833653, Gradient norm: 0.03394696
INFO:root:At the start of the epoch: mem (CPU python)=15079.5234375MB; mem (CPU total)=15015.3203125MB
INFO:root:[   11] Training loss: 0.67349379, Validation loss: 0.66393758, Gradient norm: 0.03300604
INFO:root:At the start of the epoch: mem (CPU python)=15153.14453125MB; mem (CPU total)=15053.48046875MB
INFO:root:[   12] Training loss: 0.67006066, Validation loss: 0.66024760, Gradient norm: 0.03634158
INFO:root:At the start of the epoch: mem (CPU python)=15153.14453125MB; mem (CPU total)=15091.8125MB
INFO:root:[   13] Training loss: 0.66716245, Validation loss: 0.65638203, Gradient norm: 0.03333901
INFO:root:At the start of the epoch: mem (CPU python)=15181.453125MB; mem (CPU total)=15129.62890625MB
INFO:root:[   14] Training loss: 0.66423672, Validation loss: 0.65344281, Gradient norm: 0.03491751
INFO:root:At the start of the epoch: mem (CPU python)=15219.546875MB; mem (CPU total)=15168.0390625MB
INFO:root:[   15] Training loss: 0.66227563, Validation loss: 0.65164780, Gradient norm: 0.03688330
INFO:root:At the start of the epoch: mem (CPU python)=15307.64453125MB; mem (CPU total)=15256.14453125MB
INFO:root:[   16] Training loss: 0.66025263, Validation loss: 0.64905638, Gradient norm: 0.03509699
INFO:root:At the start of the epoch: mem (CPU python)=15345.7421875MB; mem (CPU total)=15294.30859375MB
INFO:root:[   17] Training loss: 0.65827933, Validation loss: 0.64736620, Gradient norm: 0.03722925
INFO:root:At the start of the epoch: mem (CPU python)=15346.0390625MB; mem (CPU total)=15282.28125MB
INFO:root:[   18] Training loss: 0.65663286, Validation loss: 0.64622687, Gradient norm: 0.04095789
INFO:root:At the start of the epoch: mem (CPU python)=15446.93359375MB; mem (CPU total)=15395.5859375MB
INFO:root:[   19] Training loss: 0.65502486, Validation loss: 0.64420707, Gradient norm: 0.04176811
INFO:root:At the start of the epoch: mem (CPU python)=15485.02734375MB; mem (CPU total)=15433.83203125MB
INFO:root:[   20] Training loss: 0.65349323, Validation loss: 0.64295446, Gradient norm: 0.04217244
INFO:root:At the start of the epoch: mem (CPU python)=15485.4765625MB; mem (CPU total)=15421.79296875MB
INFO:root:[   21] Training loss: 0.65220250, Validation loss: 0.64112096, Gradient norm: 0.04571418
INFO:root:At the start of the epoch: mem (CPU python)=15511.21875MB; mem (CPU total)=15460.109375MB
INFO:root:[   22] Training loss: 0.65073741, Validation loss: 0.63993201, Gradient norm: 0.04119766
INFO:root:At the start of the epoch: mem (CPU python)=15549.30859375MB; mem (CPU total)=15498.28515625MB
INFO:root:[   23] Training loss: 0.64966159, Validation loss: 0.63884442, Gradient norm: 0.04435354
INFO:root:At the start of the epoch: mem (CPU python)=15587.40625MB; mem (CPU total)=15536.41796875MB
INFO:root:[   24] Training loss: 0.64835140, Validation loss: 0.63744060, Gradient norm: 0.04275131
INFO:root:At the start of the epoch: mem (CPU python)=15600.50390625MB; mem (CPU total)=15549.578125MB
INFO:root:[   25] Training loss: 0.64758790, Validation loss: 0.63743987, Gradient norm: 0.04409095
INFO:root:At the start of the epoch: mem (CPU python)=15663.6015625MB; mem (CPU total)=15612.953125MB
INFO:root:[   26] Training loss: 0.64642592, Validation loss: 0.63582407, Gradient norm: 0.04495138
INFO:root:At the start of the epoch: mem (CPU python)=15676.6953125MB; mem (CPU total)=15625.6171875MB
INFO:root:[   27] Training loss: 0.64571921, Validation loss: 0.63520216, Gradient norm: 0.04613988
INFO:root:At the start of the epoch: mem (CPU python)=15714.7890625MB; mem (CPU total)=15664.27734375MB
INFO:root:[   28] Training loss: 0.64485503, Validation loss: 0.63421370, Gradient norm: 0.05098005
INFO:root:At the start of the epoch: mem (CPU python)=15827.88671875MB; mem (CPU total)=15702.875MB
INFO:root:[   29] Training loss: 0.64362580, Validation loss: 0.63346412, Gradient norm: 0.04488134
INFO:root:At the start of the epoch: mem (CPU python)=15827.88671875MB; mem (CPU total)=15740.58984375MB
INFO:root:[   30] Training loss: 0.64291411, Validation loss: 0.63251660, Gradient norm: 0.04445430
INFO:root:At the start of the epoch: mem (CPU python)=15878.07421875MB; mem (CPU total)=15777.96484375MB
INFO:root:[   31] Training loss: 0.64226861, Validation loss: 0.63212792, Gradient norm: 0.04875072
INFO:root:At the start of the epoch: mem (CPU python)=15878.07421875MB; mem (CPU total)=15765.92578125MB
INFO:root:[   32] Training loss: 0.64140789, Validation loss: 0.63121251, Gradient norm: 0.04790066
INFO:root:At the start of the epoch: mem (CPU python)=15955.26953125MB; mem (CPU total)=15904.0625MB
INFO:root:[   33] Training loss: 0.64076751, Validation loss: 0.63154550, Gradient norm: 0.05432696
INFO:root:At the start of the epoch: mem (CPU python)=16018.36328125MB; mem (CPU total)=15967.421875MB
INFO:root:[   34] Training loss: 0.64000008, Validation loss: 0.63014064, Gradient norm: 0.04776029
INFO:root:At the start of the epoch: mem (CPU python)=16056.45703125MB; mem (CPU total)=16005.28125MB
INFO:root:[   35] Training loss: 0.63944818, Validation loss: 0.62960180, Gradient norm: 0.04938375
INFO:root:At the start of the epoch: mem (CPU python)=16056.6796875MB; mem (CPU total)=15993.2734375MB
INFO:root:[   36] Training loss: 0.63890818, Validation loss: 0.62753365, Gradient norm: 0.04885149
INFO:root:At the start of the epoch: mem (CPU python)=16082.6484375MB; mem (CPU total)=16031.6640625MB
INFO:root:[   37] Training loss: 0.63820449, Validation loss: 0.62784467, Gradient norm: 0.04676865
INFO:root:At the start of the epoch: mem (CPU python)=16145.5859375MB; mem (CPU total)=16020.85546875MB
INFO:root:[   38] Training loss: 0.63760865, Validation loss: 0.62733014, Gradient norm: 0.05450116
INFO:root:At the start of the epoch: mem (CPU python)=16205.9375MB; mem (CPU total)=16107.953125MB
INFO:root:[   39] Training loss: 0.63713026, Validation loss: 0.62697619, Gradient norm: 0.05351043
INFO:root:At the start of the epoch: mem (CPU python)=16205.9375MB; mem (CPU total)=16146.09765625MB
INFO:root:[   40] Training loss: 0.63646755, Validation loss: 0.62739993, Gradient norm: 0.04844068
INFO:root:At the start of the epoch: mem (CPU python)=16309.87109375MB; mem (CPU total)=16185.44140625MB
INFO:root:[   41] Training loss: 0.63600792, Validation loss: 0.62664075, Gradient norm: 0.05719521
INFO:root:At the start of the epoch: mem (CPU python)=16309.87109375MB; mem (CPU total)=16222.5703125MB
INFO:root:[   42] Training loss: 0.63528168, Validation loss: 0.62606508, Gradient norm: 0.04719996
INFO:root:At the start of the epoch: mem (CPU python)=16361.22265625MB; mem (CPU total)=16310.68359375MB
INFO:root:[   43] Training loss: 0.63485106, Validation loss: 0.62494851, Gradient norm: 0.04629082
INFO:root:At the start of the epoch: mem (CPU python)=16424.31640625MB; mem (CPU total)=16374.41796875MB
INFO:root:[   44] Training loss: 0.63448698, Validation loss: 0.62439001, Gradient norm: 0.05396335
INFO:root:At the start of the epoch: mem (CPU python)=16424.45703125MB; mem (CPU total)=16337.42578125MB
INFO:root:[   45] Training loss: 0.63380374, Validation loss: 0.62433278, Gradient norm: 0.05011387
INFO:root:At the start of the epoch: mem (CPU python)=16425.5078125MB; mem (CPU total)=16375.0703125MB
INFO:root:[   46] Training loss: 0.63371221, Validation loss: 0.62412643, Gradient norm: 0.05168975
INFO:root:At the start of the epoch: mem (CPU python)=16488.6015625MB; mem (CPU total)=16438.41015625MB
INFO:root:[   47] Training loss: 0.63328581, Validation loss: 0.62322949, Gradient norm: 0.05475912
INFO:root:At the start of the epoch: mem (CPU python)=16551.6953125MB; mem (CPU total)=16501.6328125MB
INFO:root:[   48] Training loss: 0.63287502, Validation loss: 0.62295038, Gradient norm: 0.05397142
INFO:root:At the start of the epoch: mem (CPU python)=16564.734375MB; mem (CPU total)=16415.73828125MB
INFO:root:[   49] Training loss: 0.63222105, Validation loss: 0.62315084, Gradient norm: 0.05371350
INFO:root:At the start of the epoch: mem (CPU python)=16602.85546875MB; mem (CPU total)=16479.59375MB
INFO:root:[   50] Training loss: 0.63193921, Validation loss: 0.62216341, Gradient norm: 0.05156556
INFO:root:At the start of the epoch: mem (CPU python)=16602.85546875MB; mem (CPU total)=16541.65234375MB
INFO:root:[   51] Training loss: 0.63155248, Validation loss: 0.62257236, Gradient norm: 0.05475240
INFO:root:At the start of the epoch: mem (CPU python)=16679.08203125MB; mem (CPU total)=16629.5078125MB
INFO:root:[   52] Training loss: 0.63102041, Validation loss: 0.62194565, Gradient norm: 0.05576915
INFO:root:At the start of the epoch: mem (CPU python)=16767.1796875MB; mem (CPU total)=16717.859375MB
INFO:root:[   53] Training loss: 0.63072115, Validation loss: 0.62254032, Gradient norm: 0.04786813
INFO:root:At the start of the epoch: mem (CPU python)=16805.2734375MB; mem (CPU total)=16756.0390625MB
INFO:root:[   54] Training loss: 0.63030200, Validation loss: 0.62296184, Gradient norm: 0.05097769
INFO:root:At the start of the epoch: mem (CPU python)=16818.3671875MB; mem (CPU total)=16769.73828125MB
INFO:root:[   55] Training loss: 0.63021180, Validation loss: 0.62040605, Gradient norm: 0.06203885
INFO:root:At the start of the epoch: mem (CPU python)=16856.46484375MB; mem (CPU total)=16807.90234375MB
INFO:root:[   56] Training loss: 0.62967408, Validation loss: 0.62030075, Gradient norm: 0.05454889
INFO:root:At the start of the epoch: mem (CPU python)=16856.82421875MB; mem (CPU total)=16795.87890625MB
INFO:root:[   57] Training loss: 0.62904236, Validation loss: 0.62015521, Gradient norm: 0.05368292
INFO:root:At the start of the epoch: mem (CPU python)=16857.65625MB; mem (CPU total)=16809.359375MB
INFO:root:[   58] Training loss: 0.62919683, Validation loss: 0.62134344, Gradient norm: 0.05759414
INFO:root:At the start of the epoch: mem (CPU python)=16970.68359375MB; mem (CPU total)=16848.48828125MB
INFO:root:[   59] Training loss: 0.62835478, Validation loss: 0.61985966, Gradient norm: 0.05117303
INFO:root:At the start of the epoch: mem (CPU python)=16970.68359375MB; mem (CPU total)=16809.98828125MB
INFO:root:[   60] Training loss: 0.62835617, Validation loss: 0.61900512, Gradient norm: 0.05262134
INFO:root:At the start of the epoch: mem (CPU python)=17021.94140625MB; mem (CPU total)=16973.4453125MB
INFO:root:[   61] Training loss: 0.62798886, Validation loss: 0.61941170, Gradient norm: 0.05609936
INFO:root:At the start of the epoch: mem (CPU python)=17083.0625MB; mem (CPU total)=16986.63671875MB
INFO:root:[   62] Training loss: 0.62784671, Validation loss: 0.61982312, Gradient norm: 0.06510736
INFO:root:At the start of the epoch: mem (CPU python)=17083.0625MB; mem (CPU total)=17024.50390625MB
INFO:root:[   63] Training loss: 0.62733960, Validation loss: 0.61851034, Gradient norm: 0.05570952
INFO:root:At the start of the epoch: mem (CPU python)=17111.078125MB; mem (CPU total)=16987.7578125MB
INFO:root:[   64] Training loss: 0.62715178, Validation loss: 0.61890598, Gradient norm: 0.05688870
INFO:root:At the start of the epoch: mem (CPU python)=17111.078125MB; mem (CPU total)=17050.6875MB
INFO:root:[   65] Training loss: 0.62679232, Validation loss: 0.61886934, Gradient norm: 0.05329455
INFO:root:At the start of the epoch: mem (CPU python)=17237.4140625MB; mem (CPU total)=17090.0859375MB
INFO:root:[   66] Training loss: 0.62665159, Validation loss: 0.61754661, Gradient norm: 0.05689951
INFO:root:At the start of the epoch: mem (CPU python)=17237.4140625MB; mem (CPU total)=17128.64453125MB
INFO:root:[   67] Training loss: 0.62610118, Validation loss: 0.61818975, Gradient norm: 0.05561262
INFO:root:At the start of the epoch: mem (CPU python)=17263.609375MB; mem (CPU total)=17216.984375MB
INFO:root:[   68] Training loss: 0.62609574, Validation loss: 0.61774424, Gradient norm: 0.05359153
INFO:root:At the start of the epoch: mem (CPU python)=17326.703125MB; mem (CPU total)=17280.34765625MB
INFO:root:[   69] Training loss: 0.62572132, Validation loss: 0.61716713, Gradient norm: 0.05430726
INFO:root:At the start of the epoch: mem (CPU python)=17339.80078125MB; mem (CPU total)=17293.28515625MB
INFO:root:[   70] Training loss: 0.62552933, Validation loss: 0.61834605, Gradient norm: 0.05407011
INFO:root:At the start of the epoch: mem (CPU python)=17402.89453125MB; mem (CPU total)=17356.6484375MB
INFO:root:[   71] Training loss: 0.62528742, Validation loss: 0.61702391, Gradient norm: 0.05649724
INFO:root:At the start of the epoch: mem (CPU python)=17415.98828125MB; mem (CPU total)=17369.89453125MB
INFO:root:[   72] Training loss: 0.62491103, Validation loss: 0.61678551, Gradient norm: 0.05900033
INFO:root:At the start of the epoch: mem (CPU python)=17529.0859375MB; mem (CPU total)=17483.1953125MB
INFO:root:[   73] Training loss: 0.62442031, Validation loss: 0.61695187, Gradient norm: 0.05337099
INFO:root:At the start of the epoch: mem (CPU python)=17541.9609375MB; mem (CPU total)=17422.2265625MB
INFO:root:[   74] Training loss: 0.62432550, Validation loss: 0.61645084, Gradient norm: 0.05489923
INFO:root:At the start of the epoch: mem (CPU python)=17541.9609375MB; mem (CPU total)=17458.91796875MB
INFO:root:[   75] Training loss: 0.62421931, Validation loss: 0.61676375, Gradient norm: 0.05783836
INFO:root:At the start of the epoch: mem (CPU python)=17568.37109375MB; mem (CPU total)=17522.08984375MB
INFO:root:[   76] Training loss: 0.62387087, Validation loss: 0.61646626, Gradient norm: 0.05787202
INFO:root:At the start of the epoch: mem (CPU python)=17606.46875MB; mem (CPU total)=17560.50390625MB
INFO:root:[   77] Training loss: 0.62373996, Validation loss: 0.61486766, Gradient norm: 0.05393384
INFO:root:At the start of the epoch: mem (CPU python)=17607.203125MB; mem (CPU total)=17548.38671875MB
INFO:root:[   78] Training loss: 0.62352811, Validation loss: 0.61526327, Gradient norm: 0.05651690
INFO:root:At the start of the epoch: mem (CPU python)=17657.65625MB; mem (CPU total)=17611.68359375MB
INFO:root:[   79] Training loss: 0.62296440, Validation loss: 0.61565459, Gradient norm: 0.05737410
INFO:root:At the start of the epoch: mem (CPU python)=17695.75390625MB; mem (CPU total)=17649.84765625MB
INFO:root:[   80] Training loss: 0.62288264, Validation loss: 0.61472482, Gradient norm: 0.05816148
INFO:root:At the start of the epoch: mem (CPU python)=17696.03515625MB; mem (CPU total)=17636.6015625MB
INFO:root:[   81] Training loss: 0.62295752, Validation loss: 0.61427139, Gradient norm: 0.06069005
INFO:root:At the start of the epoch: mem (CPU python)=17721.9453125MB; mem (CPU total)=17675.046875MB
INFO:root:[   82] Training loss: 0.62258503, Validation loss: 0.61419835, Gradient norm: 0.05389494
INFO:root:At the start of the epoch: mem (CPU python)=17810.0390625MB; mem (CPU total)=17763.39453125MB
INFO:root:[   83] Training loss: 0.62234083, Validation loss: 0.61577519, Gradient norm: 0.06550863
INFO:root:At the start of the epoch: mem (CPU python)=17848.140625MB; mem (CPU total)=17801.31640625MB
INFO:root:[   84] Training loss: 0.62224424, Validation loss: 0.61456317, Gradient norm: 0.05684516
INFO:root:At the start of the epoch: mem (CPU python)=17961.234375MB; mem (CPU total)=17914.6484375MB
INFO:root:[   85] Training loss: 0.62191779, Validation loss: 0.61570518, Gradient norm: 0.05953240
INFO:root:At the start of the epoch: mem (CPU python)=17974.328125MB; mem (CPU total)=17927.21875MB
INFO:root:[   86] Training loss: 0.62169481, Validation loss: 0.61406669, Gradient norm: 0.06447217
INFO:root:At the start of the epoch: mem (CPU python)=17974.58203125MB; mem (CPU total)=17865.234375MB
INFO:root:[   87] Training loss: 0.62132940, Validation loss: 0.61384284, Gradient norm: 0.06103767
INFO:root:At the start of the epoch: mem (CPU python)=18025.51953125MB; mem (CPU total)=17978.5859375MB
INFO:root:[   88] Training loss: 0.62108788, Validation loss: 0.61520733, Gradient norm: 0.05674437
INFO:root:At the start of the epoch: mem (CPU python)=18088.61328125MB; mem (CPU total)=18041.953125MB
INFO:root:[   89] Training loss: 0.62095007, Validation loss: 0.61357894, Gradient norm: 0.05450044
INFO:root:At the start of the epoch: mem (CPU python)=18126.7109375MB; mem (CPU total)=18080.51171875MB
INFO:root:[   90] Training loss: 0.62089604, Validation loss: 0.61323741, Gradient norm: 0.05627512
INFO:root:At the start of the epoch: mem (CPU python)=18127.125MB; mem (CPU total)=18068.6171875MB
INFO:root:[   91] Training loss: 0.62055224, Validation loss: 0.61383715, Gradient norm: 0.05913946
INFO:root:At the start of the epoch: mem (CPU python)=18152.90234375MB; mem (CPU total)=18106.51953125MB
INFO:root:[   92] Training loss: 0.62055673, Validation loss: 0.61401403, Gradient norm: 0.06581630
INFO:root:At the start of the epoch: mem (CPU python)=18187.578125MB; mem (CPU total)=18120.19140625MB
INFO:root:[   93] Training loss: 0.62039653, Validation loss: 0.61397334, Gradient norm: 0.06589972
INFO:root:At the start of the epoch: mem (CPU python)=18279.09375MB; mem (CPU total)=18233.25MB
INFO:root:[   94] Training loss: 0.62012939, Validation loss: 0.61277195, Gradient norm: 0.05673566
INFO:root:At the start of the epoch: mem (CPU python)=18279.35546875MB; mem (CPU total)=18221.55859375MB
INFO:root:[   95] Training loss: 0.61983441, Validation loss: 0.61332896, Gradient norm: 0.05876029
INFO:root:At the start of the epoch: mem (CPU python)=18380.28125MB; mem (CPU total)=18335.40625MB
INFO:root:[   96] Training loss: 0.61966626, Validation loss: 0.61312201, Gradient norm: 0.06197470
INFO:root:At the start of the epoch: mem (CPU python)=18418.37890625MB; mem (CPU total)=18373.19140625MB
INFO:root:[   97] Training loss: 0.61939429, Validation loss: 0.61315384, Gradient norm: 0.05736849
INFO:root:At the start of the epoch: mem (CPU python)=18456.4765625MB; mem (CPU total)=18411.11328125MB
INFO:root:[   98] Training loss: 0.61945057, Validation loss: 0.61325475, Gradient norm: 0.05863209
INFO:root:At the start of the epoch: mem (CPU python)=18494.5703125MB; mem (CPU total)=18449.5234375MB
INFO:root:[   99] Training loss: 0.61922884, Validation loss: 0.61397681, Gradient norm: 0.06142633
INFO:root:At the start of the epoch: mem (CPU python)=18555.05859375MB; mem (CPU total)=18462.70703125MB
INFO:root:[  100] Training loss: 0.61910326, Validation loss: 0.61174792, Gradient norm: 0.06101244
INFO:root:At the start of the epoch: mem (CPU python)=18555.05859375MB; mem (CPU total)=18425.2109375MB
INFO:root:[  101] Training loss: 0.61887704, Validation loss: 0.61257454, Gradient norm: 0.06922647
INFO:root:At the start of the epoch: mem (CPU python)=18555.05859375MB; mem (CPU total)=18463.40625MB
INFO:root:[  102] Training loss: 0.61854868, Validation loss: 0.61240671, Gradient norm: 0.05976892
INFO:root:At the start of the epoch: mem (CPU python)=18621.94921875MB; mem (CPU total)=18576.95703125MB
INFO:root:[  103] Training loss: 0.61842010, Validation loss: 0.61209860, Gradient norm: 0.05709982
INFO:root:At the start of the epoch: mem (CPU python)=18660.046875MB; mem (CPU total)=18614.859375MB
INFO:root:[  104] Training loss: 0.61830368, Validation loss: 0.61216924, Gradient norm: 0.05829255
INFO:root:At the start of the epoch: mem (CPU python)=18660.41015625MB; mem (CPU total)=18577.8671875MB
INFO:root:[  105] Training loss: 0.61800879, Validation loss: 0.61180201, Gradient norm: 0.06207590
INFO:root:At the start of the epoch: mem (CPU python)=18761.109375MB; mem (CPU total)=18642.4296875MB
INFO:root:[  106] Training loss: 0.61807740, Validation loss: 0.61211167, Gradient norm: 0.06940964
INFO:root:At the start of the epoch: mem (CPU python)=18761.109375MB; mem (CPU total)=18653.67578125MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  107] Training loss: 0.61756227, Validation loss: 0.61227092, Gradient norm: 0.06104208
INFO:root:At the start of the epoch: mem (CPU python)=18762.4296875MB; mem (CPU total)=18717.52734375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  108] Training loss: 0.61685845, Validation loss: 0.61187883, Gradient norm: 0.05170026
INFO:root:At the start of the epoch: mem (CPU python)=18850.5234375MB; mem (CPU total)=18805.87890625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  109] Training loss: 0.61587900, Validation loss: 0.61031387, Gradient norm: 0.05013811
INFO:root:At the start of the epoch: mem (CPU python)=18888.22265625MB; mem (CPU total)=18744.59375MB
INFO:root:[  110] Training loss: 0.61565750, Validation loss: 0.61025788, Gradient norm: 0.05003869
INFO:root:At the start of the epoch: mem (CPU python)=18926.58984375MB; mem (CPU total)=18807.87109375MB
INFO:root:[  111] Training loss: 0.61557474, Validation loss: 0.61019969, Gradient norm: 0.04903892
INFO:root:At the start of the epoch: mem (CPU python)=18926.58984375MB; mem (CPU total)=18845.5234375MB
INFO:root:[  112] Training loss: 0.61573703, Validation loss: 0.61083504, Gradient norm: 0.04879618
INFO:root:At the start of the epoch: mem (CPU python)=19002.90234375MB; mem (CPU total)=18958.8046875MB
INFO:root:[  113] Training loss: 0.61536942, Validation loss: 0.61065307, Gradient norm: 0.04850922
INFO:root:At the start of the epoch: mem (CPU python)=19065.8203125MB; mem (CPU total)=18948.48828125MB
INFO:root:[  114] Training loss: 0.61584868, Validation loss: 0.61044437, Gradient norm: 0.04910279
INFO:root:At the start of the epoch: mem (CPU python)=19065.8203125MB; mem (CPU total)=18959.95703125MB
INFO:root:[  115] Training loss: 0.61539743, Validation loss: 0.61028345, Gradient norm: 0.05029315
INFO:root:At the start of the epoch: mem (CPU python)=19065.8203125MB; mem (CPU total)=18998.31640625MB
INFO:root:[  116] Training loss: 0.61546193, Validation loss: 0.61069780, Gradient norm: 0.05041288
INFO:root:At the start of the epoch: mem (CPU python)=19155.28515625MB; mem (CPU total)=19111.859375MB
INFO:root:[  117] Training loss: 0.61549005, Validation loss: 0.61075797, Gradient norm: 0.04948549
INFO:root:At the start of the epoch: mem (CPU python)=19193.3828125MB; mem (CPU total)=19150.00390625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  118] Training loss: 0.61538617, Validation loss: 0.61024189, Gradient norm: 0.04904477
INFO:root:At the start of the epoch: mem (CPU python)=19193.8359375MB; mem (CPU total)=19113.00390625MB
INFO:root:[  119] Training loss: 0.61503715, Validation loss: 0.61046311, Gradient norm: 0.04667911
INFO:root:At the start of the epoch: mem (CPU python)=19219.5703125MB; mem (CPU total)=19176.1015625MB
INFO:root:[  120] Training loss: 0.61526561, Validation loss: 0.61019106, Gradient norm: 0.04888458
INFO:root:At the start of the epoch: mem (CPU python)=19232.66796875MB; mem (CPU total)=19189.21875MB
INFO:root:[  121] Training loss: 0.61528859, Validation loss: 0.61023724, Gradient norm: 0.04872085
INFO:root:At the start of the epoch: mem (CPU python)=19320.76171875MB; mem (CPU total)=19283.22265625MB
INFO:root:[  122] Training loss: 0.61496575, Validation loss: 0.60979601, Gradient norm: 0.04799780
INFO:root:At the start of the epoch: mem (CPU python)=19383.85546875MB; mem (CPU total)=19346.328125MB
INFO:root:[  123] Training loss: 0.61545812, Validation loss: 0.61043006, Gradient norm: 0.04991794
INFO:root:At the start of the epoch: mem (CPU python)=19384.03515625MB; mem (CPU total)=19334.37109375MB
INFO:root:[  124] Training loss: 0.61529313, Validation loss: 0.61050632, Gradient norm: 0.04830649
INFO:root:At the start of the epoch: mem (CPU python)=19435.0546875MB; mem (CPU total)=19397.23828125MB
INFO:root:[  125] Training loss: 0.61501006, Validation loss: 0.61096318, Gradient norm: 0.04883051
INFO:root:At the start of the epoch: mem (CPU python)=19435.3515625MB; mem (CPU total)=19385.375MB
INFO:root:[  126] Training loss: 0.61504129, Validation loss: 0.61073377, Gradient norm: 0.04997473
INFO:root:At the start of the epoch: mem (CPU python)=19586.24609375MB; mem (CPU total)=19548.62890625MB
INFO:root:[  127] Training loss: 0.61521575, Validation loss: 0.61047044, Gradient norm: 0.04822905
INFO:root:At the start of the epoch: mem (CPU python)=19586.24609375MB; mem (CPU total)=19436.66796875MB
INFO:root:[  128] Training loss: 0.61509403, Validation loss: 0.61035182, Gradient norm: 0.04695766
INFO:root:At the start of the epoch: mem (CPU python)=19586.24609375MB; mem (CPU total)=19474.4375MB
INFO:root:[  129] Training loss: 0.61524992, Validation loss: 0.61039609, Gradient norm: 0.04756937
INFO:root:At the start of the epoch: mem (CPU python)=19650.30859375MB; mem (CPU total)=19514.05859375MB
INFO:root:[  130] Training loss: 0.61503065, Validation loss: 0.61030151, Gradient norm: 0.04817795
INFO:root:At the start of the epoch: mem (CPU python)=19650.30859375MB; mem (CPU total)=19576.19921875MB
INFO:root:[  131] Training loss: 0.61507860, Validation loss: 0.61038173, Gradient norm: 0.04892974
INFO:root:At the start of the epoch: mem (CPU python)=19726.7265625MB; mem (CPU total)=19688.98046875MB
INFO:root:EP 131: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=19739.8203125MB; mem (CPU total)=19701.91796875MB
INFO:root:Training the model took 7478.974s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84777
INFO:root:EnergyScoreTrain: 0.59677
INFO:root:CRPSTrain: 0.46298
INFO:root:Gaussian NLLTrain: 1.19115
INFO:root:CoverageTrain: 0.95064
INFO:root:IntervalWidthTrain: 3.26696
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86744
INFO:root:EnergyScoreValidation: 0.61055
INFO:root:CRPSValidation: 0.47479
INFO:root:Gaussian NLLValidation: 1.21724
INFO:root:CoverageValidation: 0.94469
INFO:root:IntervalWidthValidation: 3.27293
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86868
INFO:root:EnergyScoreTest: 0.61141
INFO:root:CRPSTest: 0.47544
INFO:root:Gaussian NLLTest: 1.21847
INFO:root:CoverageTest: 0.94397
INFO:root:IntervalWidthTest: 3.2712
INFO:root:After validation: mem (CPU python)=19740.7421875MB; mem (CPU total)=19626.08203125MB
INFO:root:###4 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=19740.7421875MB; mem (CPU total)=19626.08203125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=19740.7421875MB; mem (CPU total)=19626.57421875MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=19740.7421875MB; mem (CPU total)=19626.57421875MB
INFO:root:[    1] Training loss: 0.72418285, Validation loss: 0.72028803, Gradient norm: 0.01389021
INFO:root:At the start of the epoch: mem (CPU python)=19795.94140625MB; mem (CPU total)=19708.05859375MB
INFO:root:[    2] Training loss: 0.71969529, Validation loss: 0.71885077, Gradient norm: 0.00549604
INFO:root:At the start of the epoch: mem (CPU python)=19832.5625MB; mem (CPU total)=19721.3125MB
INFO:root:[    3] Training loss: 0.71777263, Validation loss: 0.71383279, Gradient norm: 0.00838013
INFO:root:At the start of the epoch: mem (CPU python)=19832.5625MB; mem (CPU total)=19758.98828125MB
INFO:root:[    4] Training loss: 0.71041785, Validation loss: 0.70323226, Gradient norm: 0.01945586
INFO:root:At the start of the epoch: mem (CPU python)=19858.13671875MB; mem (CPU total)=19772.359375MB
INFO:root:[    5] Training loss: 0.70290877, Validation loss: 0.69659622, Gradient norm: 0.02452695
INFO:root:At the start of the epoch: mem (CPU python)=19995.0078125MB; mem (CPU total)=19935.37109375MB
INFO:root:[    6] Training loss: 0.69688774, Validation loss: 0.69029693, Gradient norm: 0.02781831
INFO:root:At the start of the epoch: mem (CPU python)=20011.73828125MB; mem (CPU total)=19973.26171875MB
INFO:root:[    7] Training loss: 0.69201450, Validation loss: 0.68474403, Gradient norm: 0.02954835
INFO:root:At the start of the epoch: mem (CPU python)=20049.83203125MB; mem (CPU total)=20011.62109375MB
INFO:root:[    8] Training loss: 0.68779702, Validation loss: 0.68015657, Gradient norm: 0.03048156
INFO:root:At the start of the epoch: mem (CPU python)=20062.84375MB; mem (CPU total)=19949.90625MB
INFO:root:[    9] Training loss: 0.68425136, Validation loss: 0.67725789, Gradient norm: 0.03081993
INFO:root:At the start of the epoch: mem (CPU python)=20076.0234375MB; mem (CPU total)=20037.52734375MB
INFO:root:[   10] Training loss: 0.68130565, Validation loss: 0.67358840, Gradient norm: 0.03041442
INFO:root:At the start of the epoch: mem (CPU python)=20114.1171875MB; mem (CPU total)=20000.99609375MB
INFO:root:[   11] Training loss: 0.67853483, Validation loss: 0.67125955, Gradient norm: 0.03280644
INFO:root:At the start of the epoch: mem (CPU python)=20125.83203125MB; mem (CPU total)=20038.6484375MB
INFO:root:[   12] Training loss: 0.67603848, Validation loss: 0.66865544, Gradient norm: 0.03137751
INFO:root:At the start of the epoch: mem (CPU python)=20160.76953125MB; mem (CPU total)=20076.546875MB
INFO:root:[   13] Training loss: 0.67388204, Validation loss: 0.66636219, Gradient norm: 0.03278103
INFO:root:At the start of the epoch: mem (CPU python)=20228.375MB; mem (CPU total)=20090.08984375MB
INFO:root:[   14] Training loss: 0.67156215, Validation loss: 0.66389276, Gradient norm: 0.03102196
INFO:root:At the start of the epoch: mem (CPU python)=20266.5MB; mem (CPU total)=20228.06640625MB
INFO:root:[   15] Training loss: 0.66985602, Validation loss: 0.66173240, Gradient norm: 0.03233771
INFO:root:At the start of the epoch: mem (CPU python)=20279.59375MB; mem (CPU total)=20240.95703125MB
INFO:root:[   16] Training loss: 0.66802001, Validation loss: 0.66030774, Gradient norm: 0.03187618
INFO:root:At the start of the epoch: mem (CPU python)=20391.79296875MB; mem (CPU total)=20254.39453125MB
INFO:root:[   17] Training loss: 0.66640648, Validation loss: 0.65817704, Gradient norm: 0.03593567
INFO:root:At the start of the epoch: mem (CPU python)=20391.79296875MB; mem (CPU total)=20242.83203125MB
INFO:root:[   18] Training loss: 0.66481025, Validation loss: 0.65640398, Gradient norm: 0.03415573
INFO:root:At the start of the epoch: mem (CPU python)=20467.171875MB; mem (CPU total)=20330.8984375MB
INFO:root:[   19] Training loss: 0.66336808, Validation loss: 0.65492421, Gradient norm: 0.03519140
INFO:root:At the start of the epoch: mem (CPU python)=20531.9765625MB; mem (CPU total)=20494.078125MB
INFO:root:[   20] Training loss: 0.66190961, Validation loss: 0.65353683, Gradient norm: 0.03620172
INFO:root:At the start of the epoch: mem (CPU python)=20570.07421875MB; mem (CPU total)=20532.22265625MB
INFO:root:[   21] Training loss: 0.66070607, Validation loss: 0.65249587, Gradient norm: 0.03656790
INFO:root:At the start of the epoch: mem (CPU python)=20583.16796875MB; mem (CPU total)=20545.4765625MB
INFO:root:[   22] Training loss: 0.65958140, Validation loss: 0.65033847, Gradient norm: 0.03935302
INFO:root:At the start of the epoch: mem (CPU python)=20621.26171875MB; mem (CPU total)=20584.16796875MB
INFO:root:[   23] Training loss: 0.65835519, Validation loss: 0.64890162, Gradient norm: 0.04366204
INFO:root:At the start of the epoch: mem (CPU python)=20621.5390625MB; mem (CPU total)=20497.69140625MB
INFO:root:[   24] Training loss: 0.65722801, Validation loss: 0.64793946, Gradient norm: 0.04067726
INFO:root:At the start of the epoch: mem (CPU python)=20645.484375MB; mem (CPU total)=20585.5234375MB
INFO:root:[   25] Training loss: 0.65623001, Validation loss: 0.64724299, Gradient norm: 0.04802334
INFO:root:At the start of the epoch: mem (CPU python)=20709.390625MB; mem (CPU total)=20623.66015625MB
INFO:root:[   26] Training loss: 0.65503356, Validation loss: 0.64659360, Gradient norm: 0.04141671
INFO:root:At the start of the epoch: mem (CPU python)=20748.59765625MB; mem (CPU total)=20587.12109375MB
INFO:root:[   27] Training loss: 0.65404029, Validation loss: 0.64500278, Gradient norm: 0.04061590
INFO:root:At the start of the epoch: mem (CPU python)=20786.74609375MB; mem (CPU total)=20750.0859375MB
INFO:root:[   28] Training loss: 0.65294439, Validation loss: 0.64409751, Gradient norm: 0.04481279
INFO:root:At the start of the epoch: mem (CPU python)=20786.74609375MB; mem (CPU total)=20713.30078125MB
INFO:root:[   29] Training loss: 0.65206764, Validation loss: 0.64307598, Gradient norm: 0.03958455
INFO:root:At the start of the epoch: mem (CPU python)=20887.93359375MB; mem (CPU total)=20851.07421875MB
INFO:root:[   30] Training loss: 0.65116353, Validation loss: 0.64297722, Gradient norm: 0.04119491
INFO:root:At the start of the epoch: mem (CPU python)=20898.0703125MB; mem (CPU total)=20814.54296875MB
INFO:root:[   31] Training loss: 0.65072865, Validation loss: 0.64079669, Gradient norm: 0.04685205
INFO:root:At the start of the epoch: mem (CPU python)=20989.12890625MB; mem (CPU total)=20952.80859375MB
INFO:root:[   32] Training loss: 0.64952756, Validation loss: 0.64053430, Gradient norm: 0.04126776
INFO:root:At the start of the epoch: mem (CPU python)=20989.33984375MB; mem (CPU total)=20865.89453125MB
INFO:root:[   33] Training loss: 0.64880769, Validation loss: 0.63970267, Gradient norm: 0.04608917
INFO:root:At the start of the epoch: mem (CPU python)=21015.1484375MB; mem (CPU total)=20879.578125MB
INFO:root:[   34] Training loss: 0.64822448, Validation loss: 0.63856931, Gradient norm: 0.05026773
INFO:root:At the start of the epoch: mem (CPU python)=21015.1484375MB; mem (CPU total)=20941.96875MB
INFO:root:[   35] Training loss: 0.64727380, Validation loss: 0.63801616, Gradient norm: 0.04619439
INFO:root:At the start of the epoch: mem (CPU python)=21116.45703125MB; mem (CPU total)=20980.421875MB
INFO:root:[   36] Training loss: 0.64657834, Validation loss: 0.63731059, Gradient norm: 0.04983661
INFO:root:At the start of the epoch: mem (CPU python)=21116.45703125MB; mem (CPU total)=21043.2734375MB
INFO:root:[   37] Training loss: 0.64600473, Validation loss: 0.63665590, Gradient norm: 0.04428564
INFO:root:At the start of the epoch: mem (CPU python)=21142.703125MB; mem (CPU total)=21106.640625MB
INFO:root:[   38] Training loss: 0.64522872, Validation loss: 0.63608342, Gradient norm: 0.04623380
INFO:root:At the start of the epoch: mem (CPU python)=21230.796875MB; mem (CPU total)=21194.71484375MB
INFO:root:[   39] Training loss: 0.64475698, Validation loss: 0.63579448, Gradient norm: 0.04875882
INFO:root:At the start of the epoch: mem (CPU python)=21268.890625MB; mem (CPU total)=21233.10546875MB
INFO:root:[   40] Training loss: 0.64402364, Validation loss: 0.63468545, Gradient norm: 0.04858327
INFO:root:At the start of the epoch: mem (CPU python)=21269.1875MB; mem (CPU total)=21170.9140625MB
INFO:root:[   41] Training loss: 0.64328190, Validation loss: 0.63497201, Gradient norm: 0.04532478
INFO:root:At the start of the epoch: mem (CPU python)=21317.91015625MB; mem (CPU total)=21160.3203125MB
INFO:root:[   42] Training loss: 0.64269931, Validation loss: 0.63354283, Gradient norm: 0.05402386
INFO:root:At the start of the epoch: mem (CPU python)=21332.8203125MB; mem (CPU total)=21222.45703125MB
INFO:root:[   43] Training loss: 0.64232425, Validation loss: 0.63273755, Gradient norm: 0.05052838
INFO:root:At the start of the epoch: mem (CPU python)=21394.6953125MB; mem (CPU total)=21286.60546875MB
INFO:root:[   44] Training loss: 0.64183057, Validation loss: 0.63303826, Gradient norm: 0.05162778
INFO:root:At the start of the epoch: mem (CPU python)=21394.6953125MB; mem (CPU total)=21348.4921875MB
INFO:root:[   45] Training loss: 0.64126326, Validation loss: 0.63182871, Gradient norm: 0.05979793
INFO:root:At the start of the epoch: mem (CPU python)=21419.82421875MB; mem (CPU total)=21336.46875MB
INFO:root:[   46] Training loss: 0.64051205, Validation loss: 0.63137416, Gradient norm: 0.05206540
INFO:root:At the start of the epoch: mem (CPU python)=21460.52734375MB; mem (CPU total)=21350.15234375MB
INFO:root:[   47] Training loss: 0.64026974, Validation loss: 0.63016131, Gradient norm: 0.04706579
INFO:root:At the start of the epoch: mem (CPU python)=21548.625MB; mem (CPU total)=21438.51953125MB
INFO:root:[   48] Training loss: 0.63959217, Validation loss: 0.62998250, Gradient norm: 0.04848647
INFO:root:At the start of the epoch: mem (CPU python)=21548.625MB; mem (CPU total)=21451.09765625MB
INFO:root:[   49] Training loss: 0.63924851, Validation loss: 0.62901060, Gradient norm: 0.04650313
INFO:root:At the start of the epoch: mem (CPU python)=21572.05078125MB; mem (CPU total)=21514.2265625MB
INFO:root:[   50] Training loss: 0.63870590, Validation loss: 0.62883095, Gradient norm: 0.05237784
INFO:root:At the start of the epoch: mem (CPU python)=21687.9453125MB; mem (CPU total)=21652.24609375MB
INFO:root:[   51] Training loss: 0.63838810, Validation loss: 0.62851919, Gradient norm: 0.05184823
INFO:root:At the start of the epoch: mem (CPU python)=21688.1171875MB; mem (CPU total)=21565.31640625MB
INFO:root:[   52] Training loss: 0.63797805, Validation loss: 0.62855076, Gradient norm: 0.05494039
INFO:root:At the start of the epoch: mem (CPU python)=21714.1328125MB; mem (CPU total)=21678.890625MB
INFO:root:[   53] Training loss: 0.63752377, Validation loss: 0.62779115, Gradient norm: 0.05270886
INFO:root:At the start of the epoch: mem (CPU python)=21777.2265625MB; mem (CPU total)=21742.48046875MB
INFO:root:[   54] Training loss: 0.63719777, Validation loss: 0.62779012, Gradient norm: 0.06045070
INFO:root:At the start of the epoch: mem (CPU python)=21790.32421875MB; mem (CPU total)=21755.671875MB
INFO:root:[   55] Training loss: 0.63652424, Validation loss: 0.62685314, Gradient norm: 0.05347219
INFO:root:At the start of the epoch: mem (CPU python)=21878.421875MB; mem (CPU total)=21842.76953125MB
INFO:root:[   56] Training loss: 0.63616705, Validation loss: 0.62676070, Gradient norm: 0.05047120
INFO:root:At the start of the epoch: mem (CPU python)=21916.51953125MB; mem (CPU total)=21880.66015625MB
INFO:root:[   57] Training loss: 0.63606784, Validation loss: 0.62709231, Gradient norm: 0.06204863
INFO:root:At the start of the epoch: mem (CPU python)=21916.71875MB; mem (CPU total)=21843.8828125MB
INFO:root:[   58] Training loss: 0.63536341, Validation loss: 0.62673154, Gradient norm: 0.05455315
INFO:root:At the start of the epoch: mem (CPU python)=22017.7109375MB; mem (CPU total)=21982.1171875MB
INFO:root:[   59] Training loss: 0.63504773, Validation loss: 0.62568432, Gradient norm: 0.05408112
INFO:root:At the start of the epoch: mem (CPU python)=22017.93359375MB; mem (CPU total)=21894.71875MB
INFO:root:[   60] Training loss: 0.63485273, Validation loss: 0.62590985, Gradient norm: 0.05645409
INFO:root:At the start of the epoch: mem (CPU python)=22041.1953125MB; mem (CPU total)=21883.53515625MB
INFO:root:[   61] Training loss: 0.63453216, Validation loss: 0.62590070, Gradient norm: 0.06511727
INFO:root:At the start of the epoch: mem (CPU python)=22106.77734375MB; mem (CPU total)=21947.51953125MB
INFO:root:[   62] Training loss: 0.63412024, Validation loss: 0.62462455, Gradient norm: 0.05425610
INFO:root:At the start of the epoch: mem (CPU python)=22106.77734375MB; mem (CPU total)=22034.6328125MB
INFO:root:[   63] Training loss: 0.63393378, Validation loss: 0.62449327, Gradient norm: 0.05703497
INFO:root:At the start of the epoch: mem (CPU python)=22158.18359375MB; mem (CPU total)=22122.9765625MB
INFO:root:[   64] Training loss: 0.63353211, Validation loss: 0.62396472, Gradient norm: 0.05405625
INFO:root:At the start of the epoch: mem (CPU python)=22246.25MB; mem (CPU total)=22136.875MB
INFO:root:[   65] Training loss: 0.63319529, Validation loss: 0.62358543, Gradient norm: 0.05985690
INFO:root:At the start of the epoch: mem (CPU python)=22246.25MB; mem (CPU total)=22174.80078125MB
INFO:root:[   66] Training loss: 0.63286725, Validation loss: 0.62425352, Gradient norm: 0.05526439
INFO:root:At the start of the epoch: mem (CPU python)=22297.47265625MB; mem (CPU total)=22262.875MB
INFO:root:[   67] Training loss: 0.63236243, Validation loss: 0.62247808, Gradient norm: 0.05033069
INFO:root:At the start of the epoch: mem (CPU python)=22335.5703125MB; mem (CPU total)=22301.01953125MB
INFO:root:[   68] Training loss: 0.63215793, Validation loss: 0.62336232, Gradient norm: 0.05292343
INFO:root:At the start of the epoch: mem (CPU python)=22373.01953125MB; mem (CPU total)=22239.2890625MB
INFO:root:[   69] Training loss: 0.63199891, Validation loss: 0.62229400, Gradient norm: 0.05878199
INFO:root:At the start of the epoch: mem (CPU python)=22386.7578125MB; mem (CPU total)=22350.81640625MB
INFO:root:[   70] Training loss: 0.63147760, Validation loss: 0.62219407, Gradient norm: 0.04964579
INFO:root:At the start of the epoch: mem (CPU python)=22398.45703125MB; mem (CPU total)=22313.83984375MB
INFO:root:[   71] Training loss: 0.63145879, Validation loss: 0.62183203, Gradient norm: 0.05452137
INFO:root:At the start of the epoch: mem (CPU python)=22487.8125MB; mem (CPU total)=22302.80078125MB
INFO:root:[   72] Training loss: 0.63102973, Validation loss: 0.62246216, Gradient norm: 0.05950284
INFO:root:At the start of the epoch: mem (CPU python)=22487.8125MB; mem (CPU total)=22440.7890625MB
INFO:root:[   73] Training loss: 0.63056340, Validation loss: 0.62147710, Gradient norm: 0.05569786
INFO:root:At the start of the epoch: mem (CPU python)=22564.140625MB; mem (CPU total)=22528.86328125MB
INFO:root:[   74] Training loss: 0.63050090, Validation loss: 0.62040282, Gradient norm: 0.05390019
INFO:root:At the start of the epoch: mem (CPU python)=22602.23828125MB; mem (CPU total)=22567.0078125MB
INFO:root:[   75] Training loss: 0.63025685, Validation loss: 0.62144535, Gradient norm: 0.05947316
INFO:root:At the start of the epoch: mem (CPU python)=22665.33203125MB; mem (CPU total)=22630.58984375MB
INFO:root:[   76] Training loss: 0.63005846, Validation loss: 0.62087502, Gradient norm: 0.06318664
INFO:root:At the start of the epoch: mem (CPU python)=22666.46484375MB; mem (CPU total)=22568.3203125MB
INFO:root:[   77] Training loss: 0.62979366, Validation loss: 0.62132294, Gradient norm: 0.05984238
INFO:root:At the start of the epoch: mem (CPU python)=22691.5234375MB; mem (CPU total)=22656.6484375MB
INFO:root:[   78] Training loss: 0.62940370, Validation loss: 0.61974724, Gradient norm: 0.05824267
INFO:root:At the start of the epoch: mem (CPU python)=22691.765625MB; mem (CPU total)=22619.6875MB
INFO:root:[   79] Training loss: 0.62932133, Validation loss: 0.62007231, Gradient norm: 0.05860265
INFO:root:At the start of the epoch: mem (CPU python)=22742.7109375MB; mem (CPU total)=22707.984375MB
INFO:root:[   80] Training loss: 0.62874563, Validation loss: 0.62032179, Gradient norm: 0.05948903
INFO:root:At the start of the epoch: mem (CPU python)=22780.8046875MB; mem (CPU total)=22746.7265625MB
INFO:root:[   81] Training loss: 0.62857825, Validation loss: 0.61959778, Gradient norm: 0.05828603
INFO:root:At the start of the epoch: mem (CPU python)=22818.90625MB; mem (CPU total)=22785.1015625MB
INFO:root:[   82] Training loss: 0.62861193, Validation loss: 0.61987805, Gradient norm: 0.06373737
INFO:root:At the start of the epoch: mem (CPU python)=22882.0MB; mem (CPU total)=22848.86328125MB
INFO:root:[   83] Training loss: 0.62797288, Validation loss: 0.61930006, Gradient norm: 0.05513037
INFO:root:At the start of the epoch: mem (CPU python)=22915.00390625MB; mem (CPU total)=22836.43359375MB
INFO:root:[   84] Training loss: 0.62789455, Validation loss: 0.61849932, Gradient norm: 0.05987723
INFO:root:At the start of the epoch: mem (CPU python)=22915.00390625MB; mem (CPU total)=22849.671875MB
INFO:root:[   85] Training loss: 0.62767011, Validation loss: 0.61784885, Gradient norm: 0.06625864
INFO:root:At the start of the epoch: mem (CPU python)=23021.23046875MB; mem (CPU total)=22862.36328125MB
INFO:root:[   86] Training loss: 0.62750953, Validation loss: 0.61831535, Gradient norm: 0.05819213
INFO:root:At the start of the epoch: mem (CPU python)=23034.37890625MB; mem (CPU total)=22926.74609375MB
INFO:root:[   87] Training loss: 0.62714535, Validation loss: 0.61875397, Gradient norm: 0.06316310
INFO:root:At the start of the epoch: mem (CPU python)=23045.3203125MB; mem (CPU total)=22988.8828125MB
INFO:root:[   88] Training loss: 0.62701497, Validation loss: 0.61791557, Gradient norm: 0.05408139
INFO:root:At the start of the epoch: mem (CPU python)=23135.4140625MB; mem (CPU total)=23028.22265625MB
INFO:root:[   89] Training loss: 0.62666351, Validation loss: 0.61822736, Gradient norm: 0.05924977
INFO:root:At the start of the epoch: mem (CPU python)=23173.66796875MB; mem (CPU total)=23140.3515625MB
INFO:root:[   90] Training loss: 0.62676244, Validation loss: 0.61779422, Gradient norm: 0.06805988
INFO:root:At the start of the epoch: mem (CPU python)=23211.76171875MB; mem (CPU total)=23179.12109375MB
INFO:root:[   91] Training loss: 0.62638477, Validation loss: 0.61704314, Gradient norm: 0.05714211
INFO:root:At the start of the epoch: mem (CPU python)=23212.015625MB; mem (CPU total)=23141.72265625MB
INFO:root:[   92] Training loss: 0.62610139, Validation loss: 0.61817412, Gradient norm: 0.05884370
INFO:root:At the start of the epoch: mem (CPU python)=23212.4609375MB; mem (CPU total)=23105.73828125MB
INFO:root:[   93] Training loss: 0.62607898, Validation loss: 0.61820083, Gradient norm: 0.06743615
INFO:root:At the start of the epoch: mem (CPU python)=23325.171875MB; mem (CPU total)=23193.109375MB
INFO:root:[   94] Training loss: 0.62589380, Validation loss: 0.61666178, Gradient norm: 0.06194648
INFO:root:At the start of the epoch: mem (CPU python)=23364.14453125MB; mem (CPU total)=23231.546875MB
INFO:root:[   95] Training loss: 0.62557219, Validation loss: 0.61685995, Gradient norm: 0.06171591
INFO:root:At the start of the epoch: mem (CPU python)=23364.14453125MB; mem (CPU total)=23220.484375MB
INFO:root:[   96] Training loss: 0.62521917, Validation loss: 0.61668010, Gradient norm: 0.06140753
INFO:root:At the start of the epoch: mem (CPU python)=23440.33203125MB; mem (CPU total)=23407.453125MB
INFO:root:[   97] Training loss: 0.62523657, Validation loss: 0.61696130, Gradient norm: 0.05972066
INFO:root:At the start of the epoch: mem (CPU python)=23440.5546875MB; mem (CPU total)=23320.76171875MB
INFO:root:[   98] Training loss: 0.62501261, Validation loss: 0.61588450, Gradient norm: 0.06386857
INFO:root:At the start of the epoch: mem (CPU python)=23491.53125MB; mem (CPU total)=23458.96484375MB
INFO:root:[   99] Training loss: 0.62466385, Validation loss: 0.61679314, Gradient norm: 0.06418813
INFO:root:At the start of the epoch: mem (CPU python)=23504.625MB; mem (CPU total)=23471.92578125MB
INFO:root:[  100] Training loss: 0.62448127, Validation loss: 0.61698261, Gradient norm: 0.06169394
INFO:root:At the start of the epoch: mem (CPU python)=23542.58984375MB; mem (CPU total)=23442.16796875MB
INFO:root:[  101] Training loss: 0.62433465, Validation loss: 0.61515869, Gradient norm: 0.06062499
INFO:root:At the start of the epoch: mem (CPU python)=23580.8203125MB; mem (CPU total)=23553.66796875MB
INFO:root:[  102] Training loss: 0.62427301, Validation loss: 0.61732742, Gradient norm: 0.05917425
INFO:root:At the start of the epoch: mem (CPU python)=23668.62890625MB; mem (CPU total)=23518.14453125MB
INFO:root:[  103] Training loss: 0.62393283, Validation loss: 0.61525486, Gradient norm: 0.06442274
INFO:root:At the start of the epoch: mem (CPU python)=23682.0078125MB; mem (CPU total)=23655.4375MB
INFO:root:[  104] Training loss: 0.62378972, Validation loss: 0.61562290, Gradient norm: 0.06263888
INFO:root:At the start of the epoch: mem (CPU python)=23720.1015625MB; mem (CPU total)=23693.58984375MB
INFO:root:[  105] Training loss: 0.62362437, Validation loss: 0.61565127, Gradient norm: 0.05775883
INFO:root:At the start of the epoch: mem (CPU python)=23833.19921875MB; mem (CPU total)=23806.67578125MB
INFO:root:[  106] Training loss: 0.62362117, Validation loss: 0.61588140, Gradient norm: 0.06665803
INFO:root:At the start of the epoch: mem (CPU python)=23871.296875MB; mem (CPU total)=23844.78515625MB
INFO:root:[  107] Training loss: 0.62363019, Validation loss: 0.61569105, Gradient norm: 0.06932075
INFO:root:At the start of the epoch: mem (CPU python)=23871.5390625MB; mem (CPU total)=23757.625MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  108] Training loss: 0.62309059, Validation loss: 0.61457959, Gradient norm: 0.06180685
INFO:root:At the start of the epoch: mem (CPU python)=23895.09375MB; mem (CPU total)=23845.890625MB
INFO:root:[  109] Training loss: 0.62226272, Validation loss: 0.61455677, Gradient norm: 0.05650109
INFO:root:At the start of the epoch: mem (CPU python)=23895.09375MB; mem (CPU total)=23784.453125MB
INFO:root:[  110] Training loss: 0.62192212, Validation loss: 0.61397544, Gradient norm: 0.05104974
INFO:root:At the start of the epoch: mem (CPU python)=24048.67578125MB; mem (CPU total)=24022.375MB
INFO:root:[  111] Training loss: 0.62166292, Validation loss: 0.61458474, Gradient norm: 0.05490774
INFO:root:At the start of the epoch: mem (CPU python)=24048.9921875MB; mem (CPU total)=23985.8984375MB
INFO:root:[  112] Training loss: 0.62173647, Validation loss: 0.61446035, Gradient norm: 0.05435083
INFO:root:At the start of the epoch: mem (CPU python)=24048.9921875MB; mem (CPU total)=23998.83203125MB
INFO:root:[  113] Training loss: 0.62157176, Validation loss: 0.61383040, Gradient norm: 0.05610610
INFO:root:At the start of the epoch: mem (CPU python)=24062.9609375MB; mem (CPU total)=24036.96875MB
INFO:root:[  114] Training loss: 0.62149559, Validation loss: 0.61433925, Gradient norm: 0.05159454
INFO:root:At the start of the epoch: mem (CPU python)=24063.0625MB; mem (CPU total)=24000.25MB
INFO:root:[  115] Training loss: 0.62139554, Validation loss: 0.61344855, Gradient norm: 0.05875750
INFO:root:At the start of the epoch: mem (CPU python)=24164.15625MB; mem (CPU total)=24138.078125MB
INFO:root:[  116] Training loss: 0.62125812, Validation loss: 0.61410055, Gradient norm: 0.05591281
INFO:root:At the start of the epoch: mem (CPU python)=24202.25MB; mem (CPU total)=24176.18359375MB
INFO:root:[  117] Training loss: 0.62132551, Validation loss: 0.61414467, Gradient norm: 0.05930370
INFO:root:At the start of the epoch: mem (CPU python)=24202.53125MB; mem (CPU total)=24164.41796875MB
INFO:root:[  118] Training loss: 0.62104140, Validation loss: 0.61290157, Gradient norm: 0.05515061
INFO:root:At the start of the epoch: mem (CPU python)=24253.44140625MB; mem (CPU total)=24227.7109375MB
INFO:root:[  119] Training loss: 0.62112124, Validation loss: 0.61375815, Gradient norm: 0.06054817
INFO:root:At the start of the epoch: mem (CPU python)=24291.4609375MB; mem (CPU total)=24141.78515625MB
INFO:root:[  120] Training loss: 0.62147973, Validation loss: 0.61367855, Gradient norm: 0.05855495
INFO:root:At the start of the epoch: mem (CPU python)=24291.4609375MB; mem (CPU total)=24228.84375MB
INFO:root:[  121] Training loss: 0.62090848, Validation loss: 0.61306702, Gradient norm: 0.05676766
INFO:root:At the start of the epoch: mem (CPU python)=24317.72265625MB; mem (CPU total)=24292.20703125MB
INFO:root:[  122] Training loss: 0.62075531, Validation loss: 0.61396844, Gradient norm: 0.05513959
INFO:root:At the start of the epoch: mem (CPU python)=24430.8203125MB; mem (CPU total)=24405.53515625MB
INFO:root:[  123] Training loss: 0.62098576, Validation loss: 0.61369741, Gradient norm: 0.05690734
INFO:root:At the start of the epoch: mem (CPU python)=24468.91796875MB; mem (CPU total)=24443.67578125MB
INFO:root:[  124] Training loss: 0.62078084, Validation loss: 0.61382196, Gradient norm: 0.06116913
INFO:root:At the start of the epoch: mem (CPU python)=24477.2109375MB; mem (CPU total)=24406.921875MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  125] Training loss: 0.62077504, Validation loss: 0.61365355, Gradient norm: 0.05808040
INFO:root:At the start of the epoch: mem (CPU python)=24520.0859375MB; mem (CPU total)=24420.8984375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  126] Training loss: 0.62024854, Validation loss: 0.61278875, Gradient norm: 0.05442900
INFO:root:At the start of the epoch: mem (CPU python)=24555.56640625MB; mem (CPU total)=24458.08203125MB
INFO:root:[  127] Training loss: 0.61967593, Validation loss: 0.61320198, Gradient norm: 0.05142064
INFO:root:At the start of the epoch: mem (CPU python)=24596.2109375MB; mem (CPU total)=24472.03125MB
INFO:root:[  128] Training loss: 0.61996292, Validation loss: 0.61329927, Gradient norm: 0.05091446
INFO:root:At the start of the epoch: mem (CPU python)=24596.2109375MB; mem (CPU total)=24509.19921875MB
INFO:root:[  129] Training loss: 0.61957816, Validation loss: 0.61281013, Gradient norm: 0.05086232
INFO:root:At the start of the epoch: mem (CPU python)=24645.25390625MB; mem (CPU total)=24597.69921875MB
INFO:root:[  130] Training loss: 0.61967023, Validation loss: 0.61237592, Gradient norm: 0.04855538
INFO:root:At the start of the epoch: mem (CPU python)=24683.3828125MB; mem (CPU total)=24610.546875MB
INFO:root:[  131] Training loss: 0.61966067, Validation loss: 0.61318643, Gradient norm: 0.05095641
INFO:root:At the start of the epoch: mem (CPU python)=24720.9375MB; mem (CPU total)=24673.83984375MB
INFO:root:[  132] Training loss: 0.61946476, Validation loss: 0.61248538, Gradient norm: 0.05381658
INFO:root:At the start of the epoch: mem (CPU python)=24811.77734375MB; mem (CPU total)=24786.9296875MB
INFO:root:[  133] Training loss: 0.61958175, Validation loss: 0.61256728, Gradient norm: 0.05159677
INFO:root:At the start of the epoch: mem (CPU python)=24823.53125MB; mem (CPU total)=24750.1796875MB
INFO:root:[  134] Training loss: 0.61969240, Validation loss: 0.61279854, Gradient norm: 0.05129809
INFO:root:At the start of the epoch: mem (CPU python)=24823.53125MB; mem (CPU total)=24788.01953125MB
INFO:root:[  135] Training loss: 0.61960919, Validation loss: 0.61291505, Gradient norm: 0.05130766
INFO:root:At the start of the epoch: mem (CPU python)=24898.296875MB; mem (CPU total)=24801.46875MB
INFO:root:[  136] Training loss: 0.61949997, Validation loss: 0.61223872, Gradient norm: 0.05201277
INFO:root:At the start of the epoch: mem (CPU python)=24938.20703125MB; mem (CPU total)=24814.40625MB
INFO:root:[  137] Training loss: 0.61968571, Validation loss: 0.61201824, Gradient norm: 0.05381876
INFO:root:At the start of the epoch: mem (CPU python)=24976.96875MB; mem (CPU total)=24902.78125MB
INFO:root:[  138] Training loss: 0.61938317, Validation loss: 0.61239743, Gradient norm: 0.05030875
INFO:root:At the start of the epoch: mem (CPU python)=25040.1796875MB; mem (CPU total)=24942.1875MB
INFO:root:[  139] Training loss: 0.61939032, Validation loss: 0.61344945, Gradient norm: 0.05126099
INFO:root:At the start of the epoch: mem (CPU python)=25040.1796875MB; mem (CPU total)=25004.35546875MB
INFO:root:[  140] Training loss: 0.61941487, Validation loss: 0.61235222, Gradient norm: 0.05142550
INFO:root:At the start of the epoch: mem (CPU python)=25116.5390625MB; mem (CPU total)=25092.68359375MB
INFO:root:[  141] Training loss: 0.61939448, Validation loss: 0.61283298, Gradient norm: 0.05373775
INFO:root:At the start of the epoch: mem (CPU python)=25116.76171875MB; mem (CPU total)=25030.67578125MB
INFO:root:[  142] Training loss: 0.61913402, Validation loss: 0.61258526, Gradient norm: 0.05057736
INFO:root:At the start of the epoch: mem (CPU python)=25217.73046875MB; mem (CPU total)=25193.6171875MB
INFO:root:[  143] Training loss: 0.61950544, Validation loss: 0.61202124, Gradient norm: 0.05348821
INFO:root:At the start of the epoch: mem (CPU python)=25255.828125MB; mem (CPU total)=25232.0390625MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  144] Training loss: 0.61941641, Validation loss: 0.61262096, Gradient norm: 0.05516495
INFO:root:At the start of the epoch: mem (CPU python)=25293.921875MB; mem (CPU total)=25270.18359375MB
INFO:root:[  145] Training loss: 0.61924482, Validation loss: 0.61213114, Gradient norm: 0.04975285
INFO:root:At the start of the epoch: mem (CPU python)=25294.14453125MB; mem (CPU total)=25258.58203125MB
INFO:root:[  146] Training loss: 0.61911896, Validation loss: 0.61254927, Gradient norm: 0.05071113
INFO:root:At the start of the epoch: mem (CPU python)=25317.1484375MB; mem (CPU total)=25271.80078125MB
INFO:root:EP 146: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=25333.15625MB; mem (CPU total)=25309.46484375MB
INFO:root:Training the model took 9395.516s.
INFO:root:Emptying the cuda cache took 0.028s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85203
INFO:root:EnergyScoreTrain: 0.59984
INFO:root:CRPSTrain: 0.46665
INFO:root:Gaussian NLLTrain: 1.20027
INFO:root:CoverageTrain: 0.95286
INFO:root:IntervalWidthTrain: 3.30799
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.8702
INFO:root:EnergyScoreValidation: 0.61249
INFO:root:CRPSValidation: 0.4775
INFO:root:Gaussian NLLValidation: 1.22443
INFO:root:CoverageValidation: 0.9469
INFO:root:IntervalWidthValidation: 3.3091
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.87124
INFO:root:EnergyScoreTest: 0.61323
INFO:root:CRPSTest: 0.47806
INFO:root:Gaussian NLLTest: 1.22526
INFO:root:CoverageTest: 0.94683
INFO:root:IntervalWidthTest: 3.30894
INFO:root:After validation: mem (CPU python)=25382.40625MB; mem (CPU total)=25359.19921875MB
INFO:root:###5 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=25382.40625MB; mem (CPU total)=25359.2421875MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=25382.83203125MB; mem (CPU total)=25359.734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=25382.83203125MB; mem (CPU total)=25359.74609375MB
INFO:root:[    1] Training loss: 0.72489266, Validation loss: 0.72076244, Gradient norm: 0.01810790
INFO:root:At the start of the epoch: mem (CPU python)=25439.65625MB; mem (CPU total)=25416.7890625MB
INFO:root:[    2] Training loss: 0.71940881, Validation loss: 0.71748284, Gradient norm: 0.00624528
INFO:root:At the start of the epoch: mem (CPU python)=25477.75390625MB; mem (CPU total)=25455.48828125MB
INFO:root:[    3] Training loss: 0.71347416, Validation loss: 0.70771185, Gradient norm: 0.01366326
INFO:root:At the start of the epoch: mem (CPU python)=25565.84765625MB; mem (CPU total)=25543.5390625MB
INFO:root:[    4] Training loss: 0.70646885, Validation loss: 0.70086332, Gradient norm: 0.02258154
INFO:root:At the start of the epoch: mem (CPU python)=25566.12109375MB; mem (CPU total)=25531.73828125MB
INFO:root:[    5] Training loss: 0.70105847, Validation loss: 0.69465441, Gradient norm: 0.02474319
INFO:root:At the start of the epoch: mem (CPU python)=25617.0390625MB; mem (CPU total)=25495.25390625MB
INFO:root:[    6] Training loss: 0.69562929, Validation loss: 0.68849962, Gradient norm: 0.02622066
INFO:root:At the start of the epoch: mem (CPU python)=25630.13671875MB; mem (CPU total)=25607.99609375MB
INFO:root:[    7] Training loss: 0.69014083, Validation loss: 0.68192664, Gradient norm: 0.02706387
INFO:root:At the start of the epoch: mem (CPU python)=25693.23046875MB; mem (CPU total)=25671.40234375MB
INFO:root:[    8] Training loss: 0.68548825, Validation loss: 0.67703047, Gradient norm: 0.02881579
INFO:root:At the start of the epoch: mem (CPU python)=25781.3046875MB; mem (CPU total)=25685.16796875MB
INFO:root:[    9] Training loss: 0.68134652, Validation loss: 0.67265996, Gradient norm: 0.02774009
INFO:root:At the start of the epoch: mem (CPU python)=25781.3046875MB; mem (CPU total)=25647.90625MB
INFO:root:[   10] Training loss: 0.67790412, Validation loss: 0.66941844, Gradient norm: 0.02948858
INFO:root:At the start of the epoch: mem (CPU python)=25907.515625MB; mem (CPU total)=25886.015625MB
INFO:root:[   11] Training loss: 0.67442739, Validation loss: 0.66508883, Gradient norm: 0.02914351
INFO:root:At the start of the epoch: mem (CPU python)=25945.609375MB; mem (CPU total)=25923.9140625MB
INFO:root:[   12] Training loss: 0.67155208, Validation loss: 0.66166060, Gradient norm: 0.03081435
INFO:root:At the start of the epoch: mem (CPU python)=25946.015625MB; mem (CPU total)=25886.921875MB
INFO:root:[   13] Training loss: 0.66888928, Validation loss: 0.65970087, Gradient norm: 0.03092086
INFO:root:At the start of the epoch: mem (CPU python)=25946.015625MB; mem (CPU total)=25899.91796875MB
INFO:root:[   14] Training loss: 0.66704741, Validation loss: 0.65647710, Gradient norm: 0.03230617
INFO:root:At the start of the epoch: mem (CPU python)=25984.8984375MB; mem (CPU total)=25962.76953125MB
INFO:root:[   15] Training loss: 0.66467772, Validation loss: 0.65441033, Gradient norm: 0.03105654
INFO:root:At the start of the epoch: mem (CPU python)=25985.3515625MB; mem (CPU total)=25925.5MB
INFO:root:[   16] Training loss: 0.66279000, Validation loss: 0.65254308, Gradient norm: 0.03574722
INFO:root:At the start of the epoch: mem (CPU python)=26011.08984375MB; mem (CPU total)=25988.84375MB
INFO:root:[   17] Training loss: 0.66101548, Validation loss: 0.65037803, Gradient norm: 0.03508581
INFO:root:At the start of the epoch: mem (CPU python)=26049.18359375MB; mem (CPU total)=26026.98046875MB
INFO:root:[   18] Training loss: 0.65956320, Validation loss: 0.64809836, Gradient norm: 0.03585612
INFO:root:At the start of the epoch: mem (CPU python)=26112.27734375MB; mem (CPU total)=26090.35546875MB
INFO:root:[   19] Training loss: 0.65789251, Validation loss: 0.64716425, Gradient norm: 0.03670846
INFO:root:At the start of the epoch: mem (CPU python)=26175.375MB; mem (CPU total)=26153.69921875MB
INFO:root:[   20] Training loss: 0.65642202, Validation loss: 0.64556421, Gradient norm: 0.03739222
INFO:root:At the start of the epoch: mem (CPU python)=26188.46875MB; mem (CPU total)=26167.13671875MB
INFO:root:[   21] Training loss: 0.65521315, Validation loss: 0.64412084, Gradient norm: 0.04054997
INFO:root:At the start of the epoch: mem (CPU python)=26251.5625MB; mem (CPU total)=26230.41796875MB
INFO:root:[   22] Training loss: 0.65373944, Validation loss: 0.64250459, Gradient norm: 0.04036670
INFO:root:At the start of the epoch: mem (CPU python)=26289.66015625MB; mem (CPU total)=26268.41796875MB
INFO:root:[   23] Training loss: 0.65255239, Validation loss: 0.64097348, Gradient norm: 0.03616555
INFO:root:At the start of the epoch: mem (CPU python)=26327.7578125MB; mem (CPU total)=26306.01171875MB
INFO:root:[   24] Training loss: 0.65150101, Validation loss: 0.64017724, Gradient norm: 0.03941912
INFO:root:At the start of the epoch: mem (CPU python)=26365.8515625MB; mem (CPU total)=26344.15625MB
INFO:root:[   25] Training loss: 0.65040721, Validation loss: 0.63861199, Gradient norm: 0.04140831
INFO:root:At the start of the epoch: mem (CPU python)=26403.9453125MB; mem (CPU total)=26382.578125MB
INFO:root:[   26] Training loss: 0.64944857, Validation loss: 0.63885560, Gradient norm: 0.04382234
INFO:root:At the start of the epoch: mem (CPU python)=26465.97265625MB; mem (CPU total)=26370.9921875MB
INFO:root:[   27] Training loss: 0.64837063, Validation loss: 0.63701910, Gradient norm: 0.04335846
INFO:root:At the start of the epoch: mem (CPU python)=26480.14453125MB; mem (CPU total)=26458.828125MB
INFO:root:[   28] Training loss: 0.64740123, Validation loss: 0.63604188, Gradient norm: 0.04063653
INFO:root:At the start of the epoch: mem (CPU python)=26493.23828125MB; mem (CPU total)=26472.046875MB
INFO:root:[   29] Training loss: 0.64647745, Validation loss: 0.63593927, Gradient norm: 0.04104834
INFO:root:At the start of the epoch: mem (CPU python)=26604.83203125MB; mem (CPU total)=26535.390625MB
INFO:root:[   30] Training loss: 0.64584286, Validation loss: 0.63390715, Gradient norm: 0.04687681
INFO:root:At the start of the epoch: mem (CPU python)=26619.2890625MB; mem (CPU total)=26523.96875MB
INFO:root:[   31] Training loss: 0.64469566, Validation loss: 0.63274311, Gradient norm: 0.04269815
INFO:root:At the start of the epoch: mem (CPU python)=26619.2890625MB; mem (CPU total)=26561.62109375MB
INFO:root:[   32] Training loss: 0.64413447, Validation loss: 0.63218736, Gradient norm: 0.04347098
INFO:root:At the start of the epoch: mem (CPU python)=26645.62109375MB; mem (CPU total)=26624.7109375MB
INFO:root:[   33] Training loss: 0.64326665, Validation loss: 0.63177903, Gradient norm: 0.04255812
INFO:root:At the start of the epoch: mem (CPU python)=26705.4921875MB; mem (CPU total)=26662.85546875MB
INFO:root:[   34] Training loss: 0.64228437, Validation loss: 0.63046171, Gradient norm: 0.04491573
INFO:root:At the start of the epoch: mem (CPU python)=26771.64453125MB; mem (CPU total)=26651.29296875MB
INFO:root:[   35] Training loss: 0.64196631, Validation loss: 0.63099372, Gradient norm: 0.05830426
INFO:root:At the start of the epoch: mem (CPU python)=26771.64453125MB; mem (CPU total)=26665.18359375MB
INFO:root:[   36] Training loss: 0.64125527, Validation loss: 0.63000738, Gradient norm: 0.04271606
INFO:root:At the start of the epoch: mem (CPU python)=26773.00390625MB; mem (CPU total)=26752.28125MB
INFO:root:[   37] Training loss: 0.64047682, Validation loss: 0.62919668, Gradient norm: 0.04461914
INFO:root:At the start of the epoch: mem (CPU python)=26836.09765625MB; mem (CPU total)=26815.41015625MB
INFO:root:[   38] Training loss: 0.63984855, Validation loss: 0.62928302, Gradient norm: 0.04877347
INFO:root:At the start of the epoch: mem (CPU python)=26897.69140625MB; mem (CPU total)=26803.5859375MB
INFO:root:[   39] Training loss: 0.63922770, Validation loss: 0.62844402, Gradient norm: 0.04729566
INFO:root:At the start of the epoch: mem (CPU python)=26936.43359375MB; mem (CPU total)=26866.3125MB
INFO:root:[   40] Training loss: 0.63854942, Validation loss: 0.62725684, Gradient norm: 0.04912218
INFO:root:At the start of the epoch: mem (CPU python)=26950.38671875MB; mem (CPU total)=26929.71875MB
INFO:root:[   41] Training loss: 0.63786932, Validation loss: 0.62732557, Gradient norm: 0.04496855
INFO:root:At the start of the epoch: mem (CPU python)=27013.48046875MB; mem (CPU total)=26992.80859375MB
INFO:root:[   42] Training loss: 0.63738018, Validation loss: 0.62613962, Gradient norm: 0.04597171
INFO:root:At the start of the epoch: mem (CPU python)=27051.57421875MB; mem (CPU total)=27030.9453125MB
INFO:root:[   43] Training loss: 0.63689879, Validation loss: 0.62539809, Gradient norm: 0.05442108
INFO:root:At the start of the epoch: mem (CPU python)=27139.671875MB; mem (CPU total)=27119.265625MB
INFO:root:[   44] Training loss: 0.63647747, Validation loss: 0.62492613, Gradient norm: 0.05100126
INFO:root:At the start of the epoch: mem (CPU python)=27139.89453125MB; mem (CPU total)=27107.47265625MB
INFO:root:[   45] Training loss: 0.63602352, Validation loss: 0.62452493, Gradient norm: 0.04714260
INFO:root:At the start of the epoch: mem (CPU python)=27140.859375MB; mem (CPU total)=27120.94140625MB
INFO:root:[   46] Training loss: 0.63526968, Validation loss: 0.62418229, Gradient norm: 0.04978796
INFO:root:At the start of the epoch: mem (CPU python)=27203.95703125MB; mem (CPU total)=27184.28515625MB
INFO:root:[   47] Training loss: 0.63473682, Validation loss: 0.62431043, Gradient norm: 0.04814913
INFO:root:At the start of the epoch: mem (CPU python)=27242.0546875MB; mem (CPU total)=27222.33984375MB
INFO:root:[   48] Training loss: 0.63429026, Validation loss: 0.62327910, Gradient norm: 0.04930385
INFO:root:At the start of the epoch: mem (CPU python)=27280.1484375MB; mem (CPU total)=27259.95703125MB
INFO:root:[   49] Training loss: 0.63377439, Validation loss: 0.62298340, Gradient norm: 0.04783171
INFO:root:At the start of the epoch: mem (CPU python)=27280.59765625MB; mem (CPU total)=27248.125MB
INFO:root:[   50] Training loss: 0.63350927, Validation loss: 0.62258319, Gradient norm: 0.05622376
INFO:root:At the start of the epoch: mem (CPU python)=27354.40234375MB; mem (CPU total)=27286.546875MB
INFO:root:[   51] Training loss: 0.63302968, Validation loss: 0.62125561, Gradient norm: 0.05153789
INFO:root:At the start of the epoch: mem (CPU python)=27354.40234375MB; mem (CPU total)=27299.4921875MB
INFO:root:[   52] Training loss: 0.63237740, Validation loss: 0.62191250, Gradient norm: 0.04982213
INFO:root:At the start of the epoch: mem (CPU python)=27457.52734375MB; mem (CPU total)=27437.99609375MB
INFO:root:[   53] Training loss: 0.63223838, Validation loss: 0.62164616, Gradient norm: 0.05620378
INFO:root:At the start of the epoch: mem (CPU python)=27457.52734375MB; mem (CPU total)=27376.21875MB
INFO:root:[   54] Training loss: 0.63171413, Validation loss: 0.62033022, Gradient norm: 0.04730664
INFO:root:At the start of the epoch: mem (CPU python)=27483.72265625MB; mem (CPU total)=27464.0546875MB
INFO:root:[   55] Training loss: 0.63146225, Validation loss: 0.62124126, Gradient norm: 0.05423175
INFO:root:At the start of the epoch: mem (CPU python)=27521.81640625MB; mem (CPU total)=27502.4453125MB
INFO:root:[   56] Training loss: 0.63106042, Validation loss: 0.62106495, Gradient norm: 0.05898141
INFO:root:At the start of the epoch: mem (CPU python)=27559.91015625MB; mem (CPU total)=27540.48046875MB
INFO:root:[   57] Training loss: 0.63051410, Validation loss: 0.62019293, Gradient norm: 0.05149337
INFO:root:At the start of the epoch: mem (CPU python)=27560.36328125MB; mem (CPU total)=27528.6875MB
INFO:root:[   58] Training loss: 0.63014403, Validation loss: 0.62040471, Gradient norm: 0.05144294
INFO:root:At the start of the epoch: mem (CPU python)=27610.1640625MB; mem (CPU total)=27566.79296875MB
INFO:root:[   59] Training loss: 0.62978107, Validation loss: 0.61916422, Gradient norm: 0.05317455
INFO:root:At the start of the epoch: mem (CPU python)=27699.17578125MB; mem (CPU total)=27580.5078125MB
INFO:root:[   60] Training loss: 0.62962439, Validation loss: 0.61812041, Gradient norm: 0.05354793
INFO:root:At the start of the epoch: mem (CPU python)=27699.17578125MB; mem (CPU total)=27593.69140625MB
INFO:root:[   61] Training loss: 0.62907271, Validation loss: 0.61905108, Gradient norm: 0.05120850
INFO:root:At the start of the epoch: mem (CPU python)=27748.8203125MB; mem (CPU total)=27706.69921875MB
INFO:root:[   62] Training loss: 0.62871798, Validation loss: 0.61943557, Gradient norm: 0.05562011
INFO:root:At the start of the epoch: mem (CPU python)=27748.8203125MB; mem (CPU total)=27694.4140625MB
INFO:root:[   63] Training loss: 0.62848188, Validation loss: 0.61702661, Gradient norm: 0.05781429
INFO:root:At the start of the epoch: mem (CPU python)=27826.578125MB; mem (CPU total)=27733.2890625MB
INFO:root:[   64] Training loss: 0.62831701, Validation loss: 0.61981146, Gradient norm: 0.05830665
INFO:root:At the start of the epoch: mem (CPU python)=27864.67578125MB; mem (CPU total)=27845.82421875MB
INFO:root:[   65] Training loss: 0.62814865, Validation loss: 0.61743068, Gradient norm: 0.06102816
INFO:root:At the start of the epoch: mem (CPU python)=27952.76953125MB; mem (CPU total)=27934.15234375MB
INFO:root:[   66] Training loss: 0.62740862, Validation loss: 0.61726726, Gradient norm: 0.05167940
INFO:root:At the start of the epoch: mem (CPU python)=27965.86328125MB; mem (CPU total)=27947.3046875MB
INFO:root:[   67] Training loss: 0.62725695, Validation loss: 0.61627862, Gradient norm: 0.05767018
INFO:root:At the start of the epoch: mem (CPU python)=27965.86328125MB; mem (CPU total)=27835.90625MB
INFO:root:[   68] Training loss: 0.62689779, Validation loss: 0.61683625, Gradient norm: 0.05794276
INFO:root:At the start of the epoch: mem (CPU python)=28042.0546875MB; mem (CPU total)=28023.61328125MB
INFO:root:[   69] Training loss: 0.62646638, Validation loss: 0.61574621, Gradient norm: 0.05345277
INFO:root:At the start of the epoch: mem (CPU python)=28130.1484375MB; mem (CPU total)=28111.96484375MB
INFO:root:[   70] Training loss: 0.62617710, Validation loss: 0.61603890, Gradient norm: 0.05338442
INFO:root:At the start of the epoch: mem (CPU python)=28143.25MB; mem (CPU total)=28124.91015625MB
INFO:root:[   71] Training loss: 0.62594753, Validation loss: 0.61624461, Gradient norm: 0.05681394
INFO:root:At the start of the epoch: mem (CPU python)=28143.625MB; mem (CPU total)=28087.88671875MB
INFO:root:[   72] Training loss: 0.62544051, Validation loss: 0.61541014, Gradient norm: 0.05773911
INFO:root:At the start of the epoch: mem (CPU python)=28194.44140625MB; mem (CPU total)=28176.67578125MB
INFO:root:[   73] Training loss: 0.62558456, Validation loss: 0.61576340, Gradient norm: 0.05542058
INFO:root:At the start of the epoch: mem (CPU python)=28257.53515625MB; mem (CPU total)=28239.58984375MB
INFO:root:[   74] Training loss: 0.62521186, Validation loss: 0.61434106, Gradient norm: 0.05550084
INFO:root:At the start of the epoch: mem (CPU python)=28257.98828125MB; mem (CPU total)=28203.3359375MB
INFO:root:[   75] Training loss: 0.62501961, Validation loss: 0.61452681, Gradient norm: 0.06226303
INFO:root:At the start of the epoch: mem (CPU python)=28257.98828125MB; mem (CPU total)=28216.2734375MB
INFO:root:[   76] Training loss: 0.62445999, Validation loss: 0.61468864, Gradient norm: 0.05421020
INFO:root:At the start of the epoch: mem (CPU python)=28257.98828125MB; mem (CPU total)=28229.38671875MB
INFO:root:[   77] Training loss: 0.62423286, Validation loss: 0.61460702, Gradient norm: 0.05796893
INFO:root:At the start of the epoch: mem (CPU python)=28359.91796875MB; mem (CPU total)=28342.4453125MB
INFO:root:[   78] Training loss: 0.62420020, Validation loss: 0.61474299, Gradient norm: 0.05692310
INFO:root:At the start of the epoch: mem (CPU python)=28423.01171875MB; mem (CPU total)=28405.7890625MB
INFO:root:[   79] Training loss: 0.62372558, Validation loss: 0.61568134, Gradient norm: 0.05749082
INFO:root:At the start of the epoch: mem (CPU python)=28486.109375MB; mem (CPU total)=28468.88671875MB
INFO:root:[   80] Training loss: 0.62351177, Validation loss: 0.61402452, Gradient norm: 0.05816387
INFO:root:At the start of the epoch: mem (CPU python)=28499.203125MB; mem (CPU total)=28482.078125MB
INFO:root:[   81] Training loss: 0.62322842, Validation loss: 0.61436627, Gradient norm: 0.05627777
INFO:root:At the start of the epoch: mem (CPU python)=28512.26171875MB; mem (CPU total)=28370.9296875MB
INFO:root:[   82] Training loss: 0.62319607, Validation loss: 0.61288259, Gradient norm: 0.05862617
INFO:root:At the start of the epoch: mem (CPU python)=28512.26171875MB; mem (CPU total)=28482.7421875MB
INFO:root:[   83] Training loss: 0.62273804, Validation loss: 0.61279088, Gradient norm: 0.05505235
INFO:root:At the start of the epoch: mem (CPU python)=28638.48828125MB; mem (CPU total)=28621.5625MB
INFO:root:[   84] Training loss: 0.62252312, Validation loss: 0.61270648, Gradient norm: 0.06228569
INFO:root:At the start of the epoch: mem (CPU python)=28638.7109375MB; mem (CPU total)=28510.171875MB
INFO:root:[   85] Training loss: 0.62227156, Validation loss: 0.61191692, Gradient norm: 0.05686908
INFO:root:At the start of the epoch: mem (CPU python)=28663.8828125MB; mem (CPU total)=28572.76953125MB
INFO:root:[   86] Training loss: 0.62220410, Validation loss: 0.61213754, Gradient norm: 0.06135437
INFO:root:At the start of the epoch: mem (CPU python)=28677.7734375MB; mem (CPU total)=28661.11328125MB
INFO:root:[   87] Training loss: 0.62183633, Validation loss: 0.61231738, Gradient norm: 0.05953423
INFO:root:At the start of the epoch: mem (CPU python)=28740.69140625MB; mem (CPU total)=28624.765625MB
INFO:root:[   88] Training loss: 0.62161126, Validation loss: 0.61141167, Gradient norm: 0.06097375
INFO:root:At the start of the epoch: mem (CPU python)=28803.96875MB; mem (CPU total)=28712.56640625MB
INFO:root:[   89] Training loss: 0.62122256, Validation loss: 0.61272511, Gradient norm: 0.05785230
INFO:root:At the start of the epoch: mem (CPU python)=28803.96875MB; mem (CPU total)=28750.2578125MB
INFO:root:[   90] Training loss: 0.62121869, Validation loss: 0.61233290, Gradient norm: 0.06114201
INFO:root:At the start of the epoch: mem (CPU python)=28830.15625MB; mem (CPU total)=28813.19921875MB
INFO:root:[   91] Training loss: 0.62093352, Validation loss: 0.61337743, Gradient norm: 0.06172199
INFO:root:At the start of the epoch: mem (CPU python)=28868.25390625MB; mem (CPU total)=28851.3359375MB
INFO:root:[   92] Training loss: 0.62071501, Validation loss: 0.61213825, Gradient norm: 0.06052671
INFO:root:At the start of the epoch: mem (CPU python)=28956.34765625MB; mem (CPU total)=28939.6328125MB
INFO:root:[   93] Training loss: 0.62047111, Validation loss: 0.61112726, Gradient norm: 0.05929765
INFO:root:At the start of the epoch: mem (CPU python)=28956.6328125MB; mem (CPU total)=28902.671875MB
INFO:root:[   94] Training loss: 0.62019977, Validation loss: 0.61098261, Gradient norm: 0.06147700
INFO:root:At the start of the epoch: mem (CPU python)=29032.5390625MB; mem (CPU total)=29015.9765625MB
INFO:root:[   95] Training loss: 0.62042204, Validation loss: 0.61049867, Gradient norm: 0.06028310
INFO:root:At the start of the epoch: mem (CPU python)=29032.65625MB; mem (CPU total)=29004.18359375MB
INFO:root:[   96] Training loss: 0.61999531, Validation loss: 0.61075597, Gradient norm: 0.05740856
INFO:root:At the start of the epoch: mem (CPU python)=29058.7265625MB; mem (CPU total)=29042.328125MB
INFO:root:[   97] Training loss: 0.61971333, Validation loss: 0.61068221, Gradient norm: 0.06301287
INFO:root:At the start of the epoch: mem (CPU python)=29146.71875MB; mem (CPU total)=29031.48828125MB
INFO:root:[   98] Training loss: 0.61954041, Validation loss: 0.61016857, Gradient norm: 0.05823366
INFO:root:At the start of the epoch: mem (CPU python)=29146.71875MB; mem (CPU total)=29118.33984375MB
INFO:root:[   99] Training loss: 0.61934339, Validation loss: 0.61081903, Gradient norm: 0.06088722
INFO:root:At the start of the epoch: mem (CPU python)=29223.015625MB; mem (CPU total)=29206.69921875MB
INFO:root:[  100] Training loss: 0.61904372, Validation loss: 0.61005785, Gradient norm: 0.06477620
INFO:root:At the start of the epoch: mem (CPU python)=29286.0859375MB; mem (CPU total)=29095.03125MB
INFO:root:[  101] Training loss: 0.61910367, Validation loss: 0.61035705, Gradient norm: 0.06965927
INFO:root:At the start of the epoch: mem (CPU python)=29286.0859375MB; mem (CPU total)=29258.28125MB
INFO:root:[  102] Training loss: 0.61887599, Validation loss: 0.61122166, Gradient norm: 0.06786168
INFO:root:At the start of the epoch: mem (CPU python)=29334.55859375MB; mem (CPU total)=29271.15625MB
INFO:root:[  103] Training loss: 0.61879075, Validation loss: 0.61121719, Gradient norm: 0.06490272
INFO:root:At the start of the epoch: mem (CPU python)=29334.55859375MB; mem (CPU total)=29284.1015625MB
INFO:root:[  104] Training loss: 0.61833015, Validation loss: 0.60857735, Gradient norm: 0.06370901
INFO:root:At the start of the epoch: mem (CPU python)=29388.49609375MB; mem (CPU total)=29372.4296875MB
INFO:root:[  105] Training loss: 0.61836180, Validation loss: 0.60923440, Gradient norm: 0.06004460
INFO:root:At the start of the epoch: mem (CPU python)=29475.91796875MB; mem (CPU total)=29386.328125MB
INFO:root:[  106] Training loss: 0.61812513, Validation loss: 0.61036468, Gradient norm: 0.06215888
INFO:root:At the start of the epoch: mem (CPU python)=29475.91796875MB; mem (CPU total)=29424.00390625MB
INFO:root:[  107] Training loss: 0.61781973, Validation loss: 0.60892157, Gradient norm: 0.06478072
INFO:root:At the start of the epoch: mem (CPU python)=29526.125MB; mem (CPU total)=29487.37109375MB
INFO:root:[  108] Training loss: 0.61756021, Validation loss: 0.61015488, Gradient norm: 0.06182801
INFO:root:At the start of the epoch: mem (CPU python)=29565.875MB; mem (CPU total)=29550.40234375MB
INFO:root:[  109] Training loss: 0.61760397, Validation loss: 0.60956722, Gradient norm: 0.05939864
INFO:root:At the start of the epoch: mem (CPU python)=29578.1875MB; mem (CPU total)=29538.609375MB
INFO:root:[  110] Training loss: 0.61745753, Validation loss: 0.61044624, Gradient norm: 0.06867030
INFO:root:At the start of the epoch: mem (CPU python)=29642.0625MB; mem (CPU total)=29626.68359375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  111] Training loss: 0.61734551, Validation loss: 0.61020004, Gradient norm: 0.06773871
INFO:root:At the start of the epoch: mem (CPU python)=29705.12890625MB; mem (CPU total)=29616.11328125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  112] Training loss: 0.61614367, Validation loss: 0.60986831, Gradient norm: 0.05570577
INFO:root:At the start of the epoch: mem (CPU python)=29705.12890625MB; mem (CPU total)=29653.02734375MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  113] Training loss: 0.61559150, Validation loss: 0.60803482, Gradient norm: 0.05359472
INFO:root:At the start of the epoch: mem (CPU python)=29731.35546875MB; mem (CPU total)=29716.6796875MB
INFO:root:[  114] Training loss: 0.61525504, Validation loss: 0.60725627, Gradient norm: 0.05094071
INFO:root:At the start of the epoch: mem (CPU python)=29744.30078125MB; mem (CPU total)=29655.05078125MB
INFO:root:[  115] Training loss: 0.61534573, Validation loss: 0.60766413, Gradient norm: 0.04979747
INFO:root:At the start of the epoch: mem (CPU python)=29744.30078125MB; mem (CPU total)=29692.8125MB
INFO:root:[  116] Training loss: 0.61507368, Validation loss: 0.60795603, Gradient norm: 0.04970456
INFO:root:At the start of the epoch: mem (CPU python)=29845.640625MB; mem (CPU total)=29831.078125MB
INFO:root:[  117] Training loss: 0.61510128, Validation loss: 0.60744004, Gradient norm: 0.04890328
INFO:root:At the start of the epoch: mem (CPU python)=29883.734375MB; mem (CPU total)=29868.9453125MB
INFO:root:[  118] Training loss: 0.61486612, Validation loss: 0.60648601, Gradient norm: 0.05010868
INFO:root:At the start of the epoch: mem (CPU python)=29921.83203125MB; mem (CPU total)=29907.08203125MB
INFO:root:[  119] Training loss: 0.61500158, Validation loss: 0.60743246, Gradient norm: 0.04734547
INFO:root:At the start of the epoch: mem (CPU python)=29934.92578125MB; mem (CPU total)=29920.234375MB
INFO:root:[  120] Training loss: 0.61483105, Validation loss: 0.60752421, Gradient norm: 0.05213114
INFO:root:At the start of the epoch: mem (CPU python)=29998.01953125MB; mem (CPU total)=29983.609375MB
INFO:root:[  121] Training loss: 0.61517998, Validation loss: 0.60760038, Gradient norm: 0.05095898
INFO:root:At the start of the epoch: mem (CPU python)=30036.12109375MB; mem (CPU total)=30021.75390625MB
INFO:root:[  122] Training loss: 0.61490374, Validation loss: 0.60776713, Gradient norm: 0.04968061
INFO:root:At the start of the epoch: mem (CPU python)=30099.21484375MB; mem (CPU total)=30085.05859375MB
INFO:root:[  123] Training loss: 0.61469700, Validation loss: 0.60728662, Gradient norm: 0.04997171
INFO:root:At the start of the epoch: mem (CPU python)=30162.30859375MB; mem (CPU total)=30148.1875MB
INFO:root:[  124] Training loss: 0.61506356, Validation loss: 0.60791552, Gradient norm: 0.05036623
INFO:root:At the start of the epoch: mem (CPU python)=30162.73046875MB; mem (CPU total)=30086.3125MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  125] Training loss: 0.61481795, Validation loss: 0.60773223, Gradient norm: 0.05186330
INFO:root:At the start of the epoch: mem (CPU python)=30238.5MB; mem (CPU total)=30224.578125MB
INFO:root:[  126] Training loss: 0.61464827, Validation loss: 0.60749783, Gradient norm: 0.04861430
INFO:root:At the start of the epoch: mem (CPU python)=30238.55859375MB; mem (CPU total)=30187.30078125MB
INFO:root:[  127] Training loss: 0.61475834, Validation loss: 0.60731289, Gradient norm: 0.04838080
INFO:root:At the start of the epoch: mem (CPU python)=30339.69140625MB; mem (CPU total)=30325.56640625MB
INFO:root:EP 127: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=30339.91796875MB; mem (CPU total)=30165.0859375MB
INFO:root:Training the model took 9090.197s.
INFO:root:Emptying the cuda cache took 0.03s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.8455
INFO:root:EnergyScoreTrain: 0.59516
INFO:root:CRPSTrain: 0.46004
INFO:root:Gaussian NLLTrain: 1.17925
INFO:root:CoverageTrain: 0.95269
INFO:root:IntervalWidthTrain: 3.25267
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86337
INFO:root:EnergyScoreValidation: 0.60769
INFO:root:CRPSValidation: 0.47071
INFO:root:Gaussian NLLValidation: 1.2029
INFO:root:CoverageValidation: 0.94702
INFO:root:IntervalWidthValidation: 3.2563
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86504
INFO:root:EnergyScoreTest: 0.60887
INFO:root:CRPSTest: 0.47169
INFO:root:Gaussian NLLTest: 1.20475
INFO:root:CoverageTest: 0.9468
INFO:root:IntervalWidthTest: 3.25643
INFO:root:After validation: mem (CPU python)=30339.91796875MB; mem (CPU total)=30212.75MB
INFO:root:###6 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=30339.91796875MB; mem (CPU total)=30212.78125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=30339.91796875MB; mem (CPU total)=30213.2734375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=30339.91796875MB; mem (CPU total)=30213.8125MB
INFO:root:[    1] Training loss: 0.72548822, Validation loss: 0.72056289, Gradient norm: 0.02287131
INFO:root:At the start of the epoch: mem (CPU python)=30339.91796875MB; mem (CPU total)=30320.5546875MB
INFO:root:[    2] Training loss: 0.71993700, Validation loss: 0.71857092, Gradient norm: 0.00599738
INFO:root:At the start of the epoch: mem (CPU python)=30472.3203125MB; mem (CPU total)=30459.15234375MB
INFO:root:[    3] Training loss: 0.71812694, Validation loss: 0.71535469, Gradient norm: 0.00907646
INFO:root:At the start of the epoch: mem (CPU python)=30472.5625MB; mem (CPU total)=30447.08203125MB
INFO:root:[    4] Training loss: 0.71265513, Validation loss: 0.70690950, Gradient norm: 0.01884913
INFO:root:At the start of the epoch: mem (CPU python)=30473.51171875MB; mem (CPU total)=30386.5MB
INFO:root:[    5] Training loss: 0.70691182, Validation loss: 0.70164984, Gradient norm: 0.02497354
INFO:root:At the start of the epoch: mem (CPU python)=30511.484375MB; mem (CPU total)=30448.98046875MB
INFO:root:[    6] Training loss: 0.70223069, Validation loss: 0.69683609, Gradient norm: 0.02824605
INFO:root:At the start of the epoch: mem (CPU python)=30574.703125MB; mem (CPU total)=30487.64453125MB
INFO:root:[    7] Training loss: 0.69801321, Validation loss: 0.69138431, Gradient norm: 0.03010503
INFO:root:At the start of the epoch: mem (CPU python)=30662.796875MB; mem (CPU total)=30650.15625MB
INFO:root:[    8] Training loss: 0.69398778, Validation loss: 0.68729991, Gradient norm: 0.03297591
INFO:root:At the start of the epoch: mem (CPU python)=30663.25390625MB; mem (CPU total)=30613.73828125MB
INFO:root:[    9] Training loss: 0.69021513, Validation loss: 0.68402800, Gradient norm: 0.03082024
INFO:root:At the start of the epoch: mem (CPU python)=30738.98828125MB; mem (CPU total)=30726.546875MB
INFO:root:[   10] Training loss: 0.68668931, Validation loss: 0.67976380, Gradient norm: 0.03534606
INFO:root:At the start of the epoch: mem (CPU python)=30752.08203125MB; mem (CPU total)=30739.97265625MB
INFO:root:[   11] Training loss: 0.68343622, Validation loss: 0.67540651, Gradient norm: 0.03244211
INFO:root:At the start of the epoch: mem (CPU python)=30787.16015625MB; mem (CPU total)=30753.19140625MB
INFO:root:[   12] Training loss: 0.68069450, Validation loss: 0.67270859, Gradient norm: 0.03607708
INFO:root:At the start of the epoch: mem (CPU python)=30828.27734375MB; mem (CPU total)=30741.8828125MB
INFO:root:[   13] Training loss: 0.67794009, Validation loss: 0.66982433, Gradient norm: 0.03678032
INFO:root:At the start of the epoch: mem (CPU python)=30841.37109375MB; mem (CPU total)=30829.5MB
INFO:root:[   14] Training loss: 0.67556222, Validation loss: 0.66693294, Gradient norm: 0.03484920
INFO:root:At the start of the epoch: mem (CPU python)=30954.46484375MB; mem (CPU total)=30942.87109375MB
INFO:root:[   15] Training loss: 0.67307329, Validation loss: 0.66538194, Gradient norm: 0.03460994
INFO:root:At the start of the epoch: mem (CPU python)=30954.69140625MB; mem (CPU total)=30855.48046875MB
INFO:root:[   16] Training loss: 0.67102255, Validation loss: 0.66208987, Gradient norm: 0.03768740
INFO:root:At the start of the epoch: mem (CPU python)=30954.69140625MB; mem (CPU total)=30918.5078125MB
INFO:root:[   17] Training loss: 0.66888787, Validation loss: 0.65981098, Gradient norm: 0.03631073
INFO:root:At the start of the epoch: mem (CPU python)=30968.75MB; mem (CPU total)=30956.61328125MB
INFO:root:[   18] Training loss: 0.66701647, Validation loss: 0.65809944, Gradient norm: 0.04122349
INFO:root:At the start of the epoch: mem (CPU python)=31056.84765625MB; mem (CPU total)=31044.94140625MB
INFO:root:[   19] Training loss: 0.66475598, Validation loss: 0.65485880, Gradient norm: 0.03859134
INFO:root:At the start of the epoch: mem (CPU python)=31094.9453125MB; mem (CPU total)=31083.6015625MB
INFO:root:[   20] Training loss: 0.66293761, Validation loss: 0.65318216, Gradient norm: 0.03865871
INFO:root:At the start of the epoch: mem (CPU python)=31158.0390625MB; mem (CPU total)=30996.91015625MB
INFO:root:[   21] Training loss: 0.66100811, Validation loss: 0.65048676, Gradient norm: 0.04003870
INFO:root:At the start of the epoch: mem (CPU python)=31158.0390625MB; mem (CPU total)=31110.19140625MB
INFO:root:[   22] Training loss: 0.65934217, Validation loss: 0.64980663, Gradient norm: 0.04181568
INFO:root:At the start of the epoch: mem (CPU python)=31159.23046875MB; mem (CPU total)=31073.4140625MB
INFO:root:[   23] Training loss: 0.65771143, Validation loss: 0.64782947, Gradient norm: 0.04357744
INFO:root:At the start of the epoch: mem (CPU python)=31247.32421875MB; mem (CPU total)=31236.109375MB
INFO:root:[   24] Training loss: 0.65605792, Validation loss: 0.64532052, Gradient norm: 0.04269709
INFO:root:At the start of the epoch: mem (CPU python)=31285.41796875MB; mem (CPU total)=31274.5546875MB
INFO:root:[   25] Training loss: 0.65483524, Validation loss: 0.64423355, Gradient norm: 0.04327379
INFO:root:At the start of the epoch: mem (CPU python)=31285.875MB; mem (CPU total)=31262.26953125MB
INFO:root:[   26] Training loss: 0.65326337, Validation loss: 0.64277346, Gradient norm: 0.04190025
INFO:root:At the start of the epoch: mem (CPU python)=31311.609375MB; mem (CPU total)=31300.4140625MB
INFO:root:[   27] Training loss: 0.65219542, Validation loss: 0.64210256, Gradient norm: 0.04363231
INFO:root:At the start of the epoch: mem (CPU python)=31424.703125MB; mem (CPU total)=31413.6953125MB
INFO:root:[   28] Training loss: 0.65104064, Validation loss: 0.64117896, Gradient norm: 0.05176746
INFO:root:At the start of the epoch: mem (CPU python)=31462.8046875MB; mem (CPU total)=31452.109375MB
INFO:root:[   29] Training loss: 0.64991968, Validation loss: 0.63875328, Gradient norm: 0.04955598
INFO:root:At the start of the epoch: mem (CPU python)=31500.8984375MB; mem (CPU total)=31490.0390625MB
INFO:root:[   30] Training loss: 0.64892822, Validation loss: 0.63755194, Gradient norm: 0.04802744
INFO:root:At the start of the epoch: mem (CPU python)=31538.9921875MB; mem (CPU total)=31528.1796875MB
INFO:root:[   31] Training loss: 0.64798715, Validation loss: 0.63719341, Gradient norm: 0.05051353
INFO:root:At the start of the epoch: mem (CPU python)=31539.4453125MB; mem (CPU total)=31516.38671875MB
INFO:root:[   32] Training loss: 0.64702181, Validation loss: 0.63642729, Gradient norm: 0.05089907
INFO:root:At the start of the epoch: mem (CPU python)=31565.18359375MB; mem (CPU total)=31554.40234375MB
INFO:root:[   33] Training loss: 0.64599917, Validation loss: 0.63527866, Gradient norm: 0.04671787
INFO:root:At the start of the epoch: mem (CPU python)=31565.640625MB; mem (CPU total)=31517.33984375MB
INFO:root:[   34] Training loss: 0.64497894, Validation loss: 0.63499627, Gradient norm: 0.04785753
INFO:root:At the start of the epoch: mem (CPU python)=31641.37109375MB; mem (CPU total)=31556.4609375MB
INFO:root:[   35] Training loss: 0.64431116, Validation loss: 0.63370303, Gradient norm: 0.05068700
INFO:root:At the start of the epoch: mem (CPU python)=31704.47265625MB; mem (CPU total)=31620.69140625MB
INFO:root:[   36] Training loss: 0.64374902, Validation loss: 0.63321822, Gradient norm: 0.05077767
INFO:root:At the start of the epoch: mem (CPU python)=31742.56640625MB; mem (CPU total)=31733.58203125MB
INFO:root:[   37] Training loss: 0.64306457, Validation loss: 0.63247877, Gradient norm: 0.05635301
INFO:root:At the start of the epoch: mem (CPU python)=31804.48046875MB; mem (CPU total)=31647.14453125MB
INFO:root:[   38] Training loss: 0.64236838, Validation loss: 0.63218481, Gradient norm: 0.05056275
INFO:root:At the start of the epoch: mem (CPU python)=31804.48046875MB; mem (CPU total)=31734.73046875MB
INFO:root:[   39] Training loss: 0.64185832, Validation loss: 0.63099020, Gradient norm: 0.05930575
INFO:root:At the start of the epoch: mem (CPU python)=31831.8515625MB; mem (CPU total)=31823.08984375MB
INFO:root:[   40] Training loss: 0.64115238, Validation loss: 0.63145337, Gradient norm: 0.04843730
INFO:root:At the start of the epoch: mem (CPU python)=31869.9453125MB; mem (CPU total)=31861.59375MB
INFO:root:[   41] Training loss: 0.64066585, Validation loss: 0.63005045, Gradient norm: 0.06210442
INFO:root:At the start of the epoch: mem (CPU python)=31908.04296875MB; mem (CPU total)=31899.77734375MB
INFO:root:[   42] Training loss: 0.63995872, Validation loss: 0.62953651, Gradient norm: 0.05569569
INFO:root:At the start of the epoch: mem (CPU python)=31946.140625MB; mem (CPU total)=31937.94921875MB
INFO:root:[   43] Training loss: 0.63931003, Validation loss: 0.62892425, Gradient norm: 0.06608644
INFO:root:At the start of the epoch: mem (CPU python)=32034.23828125MB; mem (CPU total)=32026.30859375MB
INFO:root:[   44] Training loss: 0.63862563, Validation loss: 0.62870659, Gradient norm: 0.05191466
INFO:root:At the start of the epoch: mem (CPU python)=32034.4609375MB; mem (CPU total)=31938.73046875MB
INFO:root:[   45] Training loss: 0.63825671, Validation loss: 0.62775044, Gradient norm: 0.05485757
INFO:root:At the start of the epoch: mem (CPU python)=32085.4296875MB; mem (CPU total)=32077.2109375MB
INFO:root:[   46] Training loss: 0.63766968, Validation loss: 0.62749383, Gradient norm: 0.05566458
INFO:root:At the start of the epoch: mem (CPU python)=32123.5234375MB; mem (CPU total)=32115.38671875MB
INFO:root:[   47] Training loss: 0.63747091, Validation loss: 0.62750661, Gradient norm: 0.05429278
INFO:root:At the start of the epoch: mem (CPU python)=32186.6171875MB; mem (CPU total)=32178.76171875MB
INFO:root:[   48] Training loss: 0.63674646, Validation loss: 0.62662743, Gradient norm: 0.05333613
INFO:root:At the start of the epoch: mem (CPU python)=32224.7109375MB; mem (CPU total)=32216.51953125MB
INFO:root:[   49] Training loss: 0.63629885, Validation loss: 0.62584254, Gradient norm: 0.05448672
INFO:root:At the start of the epoch: mem (CPU python)=32225.1015625MB; mem (CPU total)=32180.59765625MB
INFO:root:[   50] Training loss: 0.63577672, Validation loss: 0.62645632, Gradient norm: 0.05253152
INFO:root:At the start of the epoch: mem (CPU python)=32275.90234375MB; mem (CPU total)=32268.921875MB
INFO:root:[   51] Training loss: 0.63540723, Validation loss: 0.62458909, Gradient norm: 0.06335898
INFO:root:At the start of the epoch: mem (CPU python)=32288.99609375MB; mem (CPU total)=32182.26953125MB
INFO:root:[   52] Training loss: 0.63509811, Validation loss: 0.62556553, Gradient norm: 0.06160250
INFO:root:At the start of the epoch: mem (CPU python)=32349.0625MB; mem (CPU total)=32319.75MB
INFO:root:[   53] Training loss: 0.63448185, Validation loss: 0.62419268, Gradient norm: 0.05531516
INFO:root:At the start of the epoch: mem (CPU python)=32365.19140625MB; mem (CPU total)=32357.88671875MB
INFO:root:[   54] Training loss: 0.63427871, Validation loss: 0.62373091, Gradient norm: 0.05813539
INFO:root:At the start of the epoch: mem (CPU python)=32453.28515625MB; mem (CPU total)=32446.24609375MB
INFO:root:[   55] Training loss: 0.63359582, Validation loss: 0.62327723, Gradient norm: 0.05996146
INFO:root:At the start of the epoch: mem (CPU python)=32491.3828125MB; mem (CPU total)=32484.375MB
INFO:root:[   56] Training loss: 0.63335518, Validation loss: 0.62358448, Gradient norm: 0.05496900
INFO:root:At the start of the epoch: mem (CPU python)=32529.4765625MB; mem (CPU total)=32522.4609375MB
INFO:root:[   57] Training loss: 0.63305937, Validation loss: 0.62347771, Gradient norm: 0.05584190
INFO:root:At the start of the epoch: mem (CPU python)=32529.8515625MB; mem (CPU total)=32485.8203125MB
INFO:root:[   58] Training loss: 0.63244751, Validation loss: 0.62322361, Gradient norm: 0.05973512
INFO:root:At the start of the epoch: mem (CPU python)=32555.6640625MB; mem (CPU total)=32549.109375MB
INFO:root:[   59] Training loss: 0.63225302, Validation loss: 0.62213621, Gradient norm: 0.05592196
INFO:root:At the start of the epoch: mem (CPU python)=32556.1015625MB; mem (CPU total)=32486.94140625MB
INFO:root:[   60] Training loss: 0.63213934, Validation loss: 0.62217948, Gradient norm: 0.06521200
INFO:root:At the start of the epoch: mem (CPU python)=32631.859375MB; mem (CPU total)=32526.34375MB
INFO:root:[   61] Training loss: 0.63154688, Validation loss: 0.62208516, Gradient norm: 0.05701519
INFO:root:At the start of the epoch: mem (CPU python)=32644.953125MB; mem (CPU total)=32638.42578125MB
INFO:root:[   62] Training loss: 0.63126036, Validation loss: 0.62214809, Gradient norm: 0.05272151
INFO:root:At the start of the epoch: mem (CPU python)=32683.05078125MB; mem (CPU total)=32676.29296875MB
INFO:root:[   63] Training loss: 0.63078660, Validation loss: 0.62176406, Gradient norm: 0.05912380
INFO:root:At the start of the epoch: mem (CPU python)=32746.14453125MB; mem (CPU total)=32739.78125MB
INFO:root:[   64] Training loss: 0.63068129, Validation loss: 0.62092221, Gradient norm: 0.06280209
INFO:root:At the start of the epoch: mem (CPU python)=32784.23828125MB; mem (CPU total)=32777.96484375MB
INFO:root:[   65] Training loss: 0.63019061, Validation loss: 0.62018036, Gradient norm: 0.06248578
INFO:root:At the start of the epoch: mem (CPU python)=32797.33203125MB; mem (CPU total)=32790.8984375MB
INFO:root:[   66] Training loss: 0.62998815, Validation loss: 0.62034999, Gradient norm: 0.06113242
INFO:root:At the start of the epoch: mem (CPU python)=32835.4296875MB; mem (CPU total)=32830.46875MB
INFO:root:[   67] Training loss: 0.62954200, Validation loss: 0.62007721, Gradient norm: 0.06360170
INFO:root:At the start of the epoch: mem (CPU python)=32923.5234375MB; mem (CPU total)=32917.7890625MB
INFO:root:[   68] Training loss: 0.62925686, Validation loss: 0.61982952, Gradient norm: 0.05964678
INFO:root:At the start of the epoch: mem (CPU python)=32961.6171875MB; mem (CPU total)=32955.9921875MB
INFO:root:[   69] Training loss: 0.62912519, Validation loss: 0.61896365, Gradient norm: 0.06020174
INFO:root:At the start of the epoch: mem (CPU python)=32999.71875MB; mem (CPU total)=32994.13671875MB
INFO:root:[   70] Training loss: 0.62862447, Validation loss: 0.61886693, Gradient norm: 0.05494300
INFO:root:At the start of the epoch: mem (CPU python)=33037.8125MB; mem (CPU total)=33032.296875MB
INFO:root:[   71] Training loss: 0.62841509, Validation loss: 0.61898233, Gradient norm: 0.05594109
INFO:root:At the start of the epoch: mem (CPU python)=33123.50390625MB; mem (CPU total)=33070.390625MB
INFO:root:[   72] Training loss: 0.62837640, Validation loss: 0.61882098, Gradient norm: 0.06698518
INFO:root:At the start of the epoch: mem (CPU python)=33123.50390625MB; mem (CPU total)=33108.59765625MB
INFO:root:[   73] Training loss: 0.62789140, Validation loss: 0.61857701, Gradient norm: 0.06631680
INFO:root:At the start of the epoch: mem (CPU python)=33152.09765625MB; mem (CPU total)=33146.51171875MB
INFO:root:[   74] Training loss: 0.62768174, Validation loss: 0.61932199, Gradient norm: 0.06297436
INFO:root:At the start of the epoch: mem (CPU python)=33214.578125MB; mem (CPU total)=33159.69140625MB
INFO:root:[   75] Training loss: 0.62732236, Validation loss: 0.61852303, Gradient norm: 0.05945496
INFO:root:At the start of the epoch: mem (CPU python)=33214.578125MB; mem (CPU total)=33197.85546875MB
INFO:root:[   76] Training loss: 0.62711155, Validation loss: 0.61803741, Gradient norm: 0.06207012
INFO:root:At the start of the epoch: mem (CPU python)=33262.78515625MB; mem (CPU total)=33210.81640625MB
INFO:root:[   77] Training loss: 0.62679900, Validation loss: 0.61780441, Gradient norm: 0.06311911
INFO:root:At the start of the epoch: mem (CPU python)=33262.78515625MB; mem (CPU total)=33249.23828125MB
INFO:root:[   78] Training loss: 0.62685621, Validation loss: 0.61712490, Gradient norm: 0.06688220
INFO:root:At the start of the epoch: mem (CPU python)=33292.57421875MB; mem (CPU total)=33287.41015625MB
INFO:root:[   79] Training loss: 0.62632785, Validation loss: 0.61703864, Gradient norm: 0.06058122
INFO:root:At the start of the epoch: mem (CPU python)=33380.671875MB; mem (CPU total)=33375.90234375MB
INFO:root:[   80] Training loss: 0.62627450, Validation loss: 0.61698421, Gradient norm: 0.06692463
INFO:root:At the start of the epoch: mem (CPU python)=33418.765625MB; mem (CPU total)=33413.9453125MB
INFO:root:[   81] Training loss: 0.62597654, Validation loss: 0.61690479, Gradient norm: 0.06583574
INFO:root:At the start of the epoch: mem (CPU python)=33431.859375MB; mem (CPU total)=33426.8828125MB
INFO:root:[   82] Training loss: 0.62579733, Validation loss: 0.61718863, Gradient norm: 0.06724568
INFO:root:At the start of the epoch: mem (CPU python)=33494.953125MB; mem (CPU total)=33490.21875MB
INFO:root:[   83] Training loss: 0.62536097, Validation loss: 0.61640787, Gradient norm: 0.05984763
INFO:root:At the start of the epoch: mem (CPU python)=33558.05078125MB; mem (CPU total)=33553.34765625MB
INFO:root:[   84] Training loss: 0.62502762, Validation loss: 0.61746834, Gradient norm: 0.05863776
INFO:root:At the start of the epoch: mem (CPU python)=33571.14453125MB; mem (CPU total)=33492.5703125MB
INFO:root:[   85] Training loss: 0.62507459, Validation loss: 0.61639800, Gradient norm: 0.06524184
INFO:root:At the start of the epoch: mem (CPU python)=33609.23828125MB; mem (CPU total)=33604.62109375MB
INFO:root:[   86] Training loss: 0.62493113, Validation loss: 0.61624215, Gradient norm: 0.06789985
INFO:root:At the start of the epoch: mem (CPU python)=33672.3359375MB; mem (CPU total)=33667.84375MB
INFO:root:[   87] Training loss: 0.62430133, Validation loss: 0.61622757, Gradient norm: 0.06188807
INFO:root:At the start of the epoch: mem (CPU python)=33672.66796875MB; mem (CPU total)=33630.93359375MB
INFO:root:[   88] Training loss: 0.62420517, Validation loss: 0.61650394, Gradient norm: 0.06174664
INFO:root:At the start of the epoch: mem (CPU python)=33672.66796875MB; mem (CPU total)=33644.12890625MB
INFO:root:[   89] Training loss: 0.62385388, Validation loss: 0.61609483, Gradient norm: 0.06077803
INFO:root:At the start of the epoch: mem (CPU python)=33761.625MB; mem (CPU total)=33757.34375MB
INFO:root:[   90] Training loss: 0.62359136, Validation loss: 0.61513338, Gradient norm: 0.06188392
INFO:root:At the start of the epoch: mem (CPU python)=33799.71875MB; mem (CPU total)=33795.5078125MB
INFO:root:[   91] Training loss: 0.62362583, Validation loss: 0.61526492, Gradient norm: 0.06167325
INFO:root:At the start of the epoch: mem (CPU python)=33859.64453125MB; mem (CPU total)=33808.68359375MB
INFO:root:[   92] Training loss: 0.62335825, Validation loss: 0.61591196, Gradient norm: 0.07304013
INFO:root:At the start of the epoch: mem (CPU python)=33859.64453125MB; mem (CPU total)=33846.58203125MB
INFO:root:[   93] Training loss: 0.62344080, Validation loss: 0.61514899, Gradient norm: 0.06035665
INFO:root:At the start of the epoch: mem (CPU python)=33889.00390625MB; mem (CPU total)=33884.6953125MB
INFO:root:[   94] Training loss: 0.62303164, Validation loss: 0.61492706, Gradient norm: 0.06128438
INFO:root:At the start of the epoch: mem (CPU python)=33977.09765625MB; mem (CPU total)=33972.8671875MB
INFO:root:[   95] Training loss: 0.62304872, Validation loss: 0.61428655, Gradient norm: 0.06609190
INFO:root:At the start of the epoch: mem (CPU python)=33977.21484375MB; mem (CPU total)=33910.890625MB
INFO:root:[   96] Training loss: 0.62273858, Validation loss: 0.61535175, Gradient norm: 0.07152916
INFO:root:At the start of the epoch: mem (CPU python)=34003.29296875MB; mem (CPU total)=33999.51953125MB
INFO:root:[   97] Training loss: 0.62242568, Validation loss: 0.61427876, Gradient norm: 0.06052177
INFO:root:At the start of the epoch: mem (CPU python)=34003.6015625MB; mem (CPU total)=33987.72265625MB
INFO:root:[   98] Training loss: 0.62229863, Validation loss: 0.61467399, Gradient norm: 0.06809960
INFO:root:At the start of the epoch: mem (CPU python)=34104.48046875MB; mem (CPU total)=34100.953125MB
INFO:root:[   99] Training loss: 0.62221860, Validation loss: 0.61438825, Gradient norm: 0.05975617
INFO:root:At the start of the epoch: mem (CPU python)=34105.1796875MB; mem (CPU total)=34063.890625MB
INFO:root:[  100] Training loss: 0.62191516, Validation loss: 0.61406953, Gradient norm: 0.06403506
INFO:root:At the start of the epoch: mem (CPU python)=34180.671875MB; mem (CPU total)=34102.70703125MB
INFO:root:[  101] Training loss: 0.62145574, Validation loss: 0.61406036, Gradient norm: 0.06466737
INFO:root:At the start of the epoch: mem (CPU python)=34193.765625MB; mem (CPU total)=34190.3828125MB
INFO:root:[  102] Training loss: 0.62145480, Validation loss: 0.61422749, Gradient norm: 0.06265751
INFO:root:At the start of the epoch: mem (CPU python)=34256.859375MB; mem (CPU total)=34259.94921875MB
INFO:root:[  103] Training loss: 0.62132681, Validation loss: 0.61513599, Gradient norm: 0.06950290
INFO:root:At the start of the epoch: mem (CPU python)=34294.9609375MB; mem (CPU total)=34297.546875MB
INFO:root:[  104] Training loss: 0.62125005, Validation loss: 0.61377051, Gradient norm: 0.06561307
INFO:root:At the start of the epoch: mem (CPU python)=34333.0546875MB; mem (CPU total)=34335.44140625MB
INFO:root:[  105] Training loss: 0.62109120, Validation loss: 0.61296638, Gradient norm: 0.06687768
INFO:root:At the start of the epoch: mem (CPU python)=34333.32421875MB; mem (CPU total)=34323.7109375MB
INFO:root:[  106] Training loss: 0.62082179, Validation loss: 0.61359879, Gradient norm: 0.06135830
INFO:root:At the start of the epoch: mem (CPU python)=34359.24609375MB; mem (CPU total)=34357.48828125MB
INFO:root:[  107] Training loss: 0.62075351, Validation loss: 0.61305075, Gradient norm: 0.07030628
INFO:root:At the start of the epoch: mem (CPU python)=34447.33984375MB; mem (CPU total)=34445.84765625MB
INFO:root:[  108] Training loss: 0.62060276, Validation loss: 0.61402579, Gradient norm: 0.06889763
INFO:root:At the start of the epoch: mem (CPU python)=34485.43359375MB; mem (CPU total)=34483.7734375MB
INFO:root:[  109] Training loss: 0.62038035, Validation loss: 0.61346542, Gradient norm: 0.06459924
INFO:root:At the start of the epoch: mem (CPU python)=34519.12109375MB; mem (CPU total)=34471.96875MB
INFO:root:[  110] Training loss: 0.62034462, Validation loss: 0.61369902, Gradient norm: 0.07171803
INFO:root:At the start of the epoch: mem (CPU python)=34519.12109375MB; mem (CPU total)=34509.890625MB
INFO:root:[  111] Training loss: 0.61993928, Validation loss: 0.61323204, Gradient norm: 0.06247084
INFO:root:At the start of the epoch: mem (CPU python)=34574.72265625MB; mem (CPU total)=34573.046875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  112] Training loss: 0.62012961, Validation loss: 0.61268287, Gradient norm: 0.07674066
INFO:root:At the start of the epoch: mem (CPU python)=34587.81640625MB; mem (CPU total)=34586.234375MB
INFO:root:[  113] Training loss: 0.61874406, Validation loss: 0.61259892, Gradient norm: 0.06577097
INFO:root:At the start of the epoch: mem (CPU python)=34675.9140625MB; mem (CPU total)=34674.37109375MB
INFO:root:[  114] Training loss: 0.61855451, Validation loss: 0.61195828, Gradient norm: 0.05756803
INFO:root:At the start of the epoch: mem (CPU python)=34676.1875MB; mem (CPU total)=34662.671875MB
INFO:root:[  115] Training loss: 0.61831714, Validation loss: 0.61253022, Gradient norm: 0.05642516
INFO:root:At the start of the epoch: mem (CPU python)=34727.1015625MB; mem (CPU total)=34726.078125MB
INFO:root:[  116] Training loss: 0.61851598, Validation loss: 0.61177864, Gradient norm: 0.06589058
INFO:root:At the start of the epoch: mem (CPU python)=34765.1953125MB; mem (CPU total)=34763.51171875MB
INFO:root:[  117] Training loss: 0.61823432, Validation loss: 0.61156991, Gradient norm: 0.05975764
INFO:root:At the start of the epoch: mem (CPU python)=34778.29296875MB; mem (CPU total)=34776.8359375MB
INFO:root:[  118] Training loss: 0.61805670, Validation loss: 0.61180032, Gradient norm: 0.05921393
INFO:root:At the start of the epoch: mem (CPU python)=34891.38671875MB; mem (CPU total)=34889.92578125MB
INFO:root:[  119] Training loss: 0.61821780, Validation loss: 0.61171839, Gradient norm: 0.05983262
INFO:root:At the start of the epoch: mem (CPU python)=34891.83984375MB; mem (CPU total)=34877.9921875MB
INFO:root:[  120] Training loss: 0.61822396, Validation loss: 0.61166827, Gradient norm: 0.06746343
INFO:root:At the start of the epoch: mem (CPU python)=34917.58203125MB; mem (CPU total)=34916.375MB
INFO:root:[  121] Training loss: 0.61778154, Validation loss: 0.61163851, Gradient norm: 0.05587084
INFO:root:At the start of the epoch: mem (CPU python)=34980.67578125MB; mem (CPU total)=34905.21875MB
INFO:root:[  122] Training loss: 0.61785955, Validation loss: 0.61143287, Gradient norm: 0.05923010
INFO:root:At the start of the epoch: mem (CPU python)=34980.67578125MB; mem (CPU total)=34917.38671875MB
INFO:root:[  123] Training loss: 0.61775904, Validation loss: 0.61111589, Gradient norm: 0.05812017
INFO:root:At the start of the epoch: mem (CPU python)=35081.8671875MB; mem (CPU total)=35080.9140625MB
INFO:root:[  124] Training loss: 0.61771439, Validation loss: 0.61236108, Gradient norm: 0.06155404
INFO:root:At the start of the epoch: mem (CPU python)=35119.9609375MB; mem (CPU total)=35118.1171875MB
INFO:root:[  125] Training loss: 0.61757537, Validation loss: 0.61131139, Gradient norm: 0.06068674
INFO:root:At the start of the epoch: mem (CPU python)=35120.25390625MB; mem (CPU total)=35106.890625MB
INFO:root:[  126] Training loss: 0.61753565, Validation loss: 0.61168637, Gradient norm: 0.06216279
INFO:root:At the start of the epoch: mem (CPU python)=35121.1484375MB; mem (CPU total)=35120.2734375MB
INFO:root:[  127] Training loss: 0.61749858, Validation loss: 0.61172819, Gradient norm: 0.06585011
INFO:root:At the start of the epoch: mem (CPU python)=35159.24609375MB; mem (CPU total)=35158.32421875MB
INFO:root:[  128] Training loss: 0.61735289, Validation loss: 0.61112777, Gradient norm: 0.06306051
INFO:root:At the start of the epoch: mem (CPU python)=35247.12890625MB; mem (CPU total)=35196.21484375MB
INFO:root:[  129] Training loss: 0.61749077, Validation loss: 0.61063948, Gradient norm: 0.05845098
INFO:root:At the start of the epoch: mem (CPU python)=35260.4375MB; mem (CPU total)=35259.62109375MB
INFO:root:[  130] Training loss: 0.61711260, Validation loss: 0.61147175, Gradient norm: 0.06062311
INFO:root:At the start of the epoch: mem (CPU python)=35260.70703125MB; mem (CPU total)=35247.828125MB
INFO:root:[  131] Training loss: 0.61718665, Validation loss: 0.61128059, Gradient norm: 0.06316863
INFO:root:At the start of the epoch: mem (CPU python)=35361.62890625MB; mem (CPU total)=35361.10546875MB
INFO:root:[  132] Training loss: 0.61690720, Validation loss: 0.61115799, Gradient norm: 0.06177378
INFO:root:At the start of the epoch: mem (CPU python)=35399.72265625MB; mem (CPU total)=35399.1484375MB
INFO:root:[  133] Training loss: 0.61706336, Validation loss: 0.61032202, Gradient norm: 0.06240293
INFO:root:At the start of the epoch: mem (CPU python)=35437.81640625MB; mem (CPU total)=35437.28515625MB
INFO:root:[  134] Training loss: 0.61679926, Validation loss: 0.61046544, Gradient norm: 0.06386217
INFO:root:At the start of the epoch: mem (CPU python)=35475.9140625MB; mem (CPU total)=35401.27734375MB
INFO:root:[  135] Training loss: 0.61695760, Validation loss: 0.61080955, Gradient norm: 0.06471749
INFO:root:At the start of the epoch: mem (CPU python)=35489.0078125MB; mem (CPU total)=35488.61328125MB
INFO:root:[  136] Training loss: 0.61662693, Validation loss: 0.61086784, Gradient norm: 0.06067430
INFO:root:At the start of the epoch: mem (CPU python)=35575.33203125MB; mem (CPU total)=35501.7734375MB
INFO:root:[  137] Training loss: 0.61675935, Validation loss: 0.61101222, Gradient norm: 0.06222084
INFO:root:At the start of the epoch: mem (CPU python)=35575.33203125MB; mem (CPU total)=35514.65625MB
INFO:root:[  138] Training loss: 0.61643020, Validation loss: 0.61111837, Gradient norm: 0.06349596
INFO:root:At the start of the epoch: mem (CPU python)=35653.296875MB; mem (CPU total)=35653.16796875MB
INFO:root:[  139] Training loss: 0.61665753, Validation loss: 0.61096938, Gradient norm: 0.05873734
INFO:root:At the start of the epoch: mem (CPU python)=35691.390625MB; mem (CPU total)=35691.3359375MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  140] Training loss: 0.61623227, Validation loss: 0.61107456, Gradient norm: 0.06411900
INFO:root:At the start of the epoch: mem (CPU python)=35691.67578125MB; mem (CPU total)=35629.60546875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  141] Training loss: 0.61600366, Validation loss: 0.61010323, Gradient norm: 0.05655202
INFO:root:At the start of the epoch: mem (CPU python)=35767.58203125MB; mem (CPU total)=35767.640625MB
INFO:root:[  142] Training loss: 0.61565695, Validation loss: 0.61048845, Gradient norm: 0.05508130
INFO:root:At the start of the epoch: mem (CPU python)=35805.67578125MB; mem (CPU total)=35806.17578125MB
INFO:root:[  143] Training loss: 0.61556382, Validation loss: 0.60980469, Gradient norm: 0.05769136
INFO:root:At the start of the epoch: mem (CPU python)=35843.61328125MB; mem (CPU total)=35770.16796875MB
INFO:root:[  144] Training loss: 0.61543308, Validation loss: 0.60991396, Gradient norm: 0.05506152
INFO:root:At the start of the epoch: mem (CPU python)=35843.61328125MB; mem (CPU total)=35782.65234375MB
INFO:root:[  145] Training loss: 0.61534599, Validation loss: 0.61044011, Gradient norm: 0.05534424
INFO:root:At the start of the epoch: mem (CPU python)=35894.96484375MB; mem (CPU total)=35896.1796875MB
INFO:root:[  146] Training loss: 0.61541698, Validation loss: 0.60943422, Gradient norm: 0.05605041
INFO:root:At the start of the epoch: mem (CPU python)=35933.05859375MB; mem (CPU total)=35934.09375MB
INFO:root:[  147] Training loss: 0.61544902, Validation loss: 0.61058086, Gradient norm: 0.05685326
INFO:root:At the start of the epoch: mem (CPU python)=35971.15625MB; mem (CPU total)=35972.20703125MB
INFO:root:[  148] Training loss: 0.61518893, Validation loss: 0.60955596, Gradient norm: 0.05665643
INFO:root:At the start of the epoch: mem (CPU python)=36009.25MB; mem (CPU total)=36010.3359375MB
INFO:root:[  149] Training loss: 0.61547711, Validation loss: 0.60986806, Gradient norm: 0.05772738
INFO:root:At the start of the epoch: mem (CPU python)=36047.34375MB; mem (CPU total)=36047.98046875MB
INFO:root:[  150] Training loss: 0.61528161, Validation loss: 0.61092026, Gradient norm: 0.05510746
INFO:root:At the start of the epoch: mem (CPU python)=36085.4375MB; mem (CPU total)=36085.7734375MB
INFO:root:[  151] Training loss: 0.61530559, Validation loss: 0.61066737, Gradient norm: 0.05667709
INFO:root:At the start of the epoch: mem (CPU python)=36098.53515625MB; mem (CPU total)=36099.2109375MB
INFO:root:[  152] Training loss: 0.61523711, Validation loss: 0.60976617, Gradient norm: 0.05715793
INFO:root:At the start of the epoch: mem (CPU python)=36136.62890625MB; mem (CPU total)=36137.35546875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  153] Training loss: 0.61516468, Validation loss: 0.60994264, Gradient norm: 0.05823060
INFO:root:At the start of the epoch: mem (CPU python)=36199.20703125MB; mem (CPU total)=36150.515625MB
INFO:root:[  154] Training loss: 0.61489133, Validation loss: 0.60995371, Gradient norm: 0.05499079
INFO:root:At the start of the epoch: mem (CPU python)=36199.20703125MB; mem (CPU total)=36188.203125MB
INFO:root:[  155] Training loss: 0.61513920, Validation loss: 0.60928115, Gradient norm: 0.05500881
INFO:root:At the start of the epoch: mem (CPU python)=36275.67578125MB; mem (CPU total)=36226.41015625MB
INFO:root:[  156] Training loss: 0.61519238, Validation loss: 0.60973907, Gradient norm: 0.05400148
INFO:root:At the start of the epoch: mem (CPU python)=36314.01953125MB; mem (CPU total)=36314.73046875MB
INFO:root:[  157] Training loss: 0.61513782, Validation loss: 0.61000462, Gradient norm: 0.05238779
INFO:root:At the start of the epoch: mem (CPU python)=36314.578125MB; mem (CPU total)=36228.80859375MB
INFO:root:[  158] Training loss: 0.61491235, Validation loss: 0.61018180, Gradient norm: 0.05488059
INFO:root:At the start of the epoch: mem (CPU python)=36365.2109375MB; mem (CPU total)=36366.08984375MB
INFO:root:[  159] Training loss: 0.61483789, Validation loss: 0.60931383, Gradient norm: 0.05431461
INFO:root:At the start of the epoch: mem (CPU python)=36378.3046875MB; mem (CPU total)=36379.1875MB
INFO:root:[  160] Training loss: 0.61486545, Validation loss: 0.60959114, Gradient norm: 0.05563602
INFO:root:At the start of the epoch: mem (CPU python)=36466.3984375MB; mem (CPU total)=36468.15625MB
INFO:root:[  161] Training loss: 0.61483736, Validation loss: 0.60964697, Gradient norm: 0.05488141
INFO:root:At the start of the epoch: mem (CPU python)=36529.51171875MB; mem (CPU total)=36530.59765625MB
INFO:root:[  162] Training loss: 0.61485998, Validation loss: 0.61033104, Gradient norm: 0.05355602
INFO:root:At the start of the epoch: mem (CPU python)=36567.60546875MB; mem (CPU total)=36568.7734375MB
INFO:root:[  163] Training loss: 0.61490597, Validation loss: 0.60927757, Gradient norm: 0.05294763
INFO:root:At the start of the epoch: mem (CPU python)=36567.84765625MB; mem (CPU total)=36556.7890625MB
INFO:root:[  164] Training loss: 0.61485627, Validation loss: 0.61029281, Gradient norm: 0.05446960
INFO:root:At the start of the epoch: mem (CPU python)=36643.796875MB; mem (CPU total)=36645.1484375MB
INFO:root:[  165] Training loss: 0.61504797, Validation loss: 0.60977881, Gradient norm: 0.05464767
INFO:root:At the start of the epoch: mem (CPU python)=36656.890625MB; mem (CPU total)=36658.0859375MB
INFO:root:[  166] Training loss: 0.61474061, Validation loss: 0.61015568, Gradient norm: 0.05360455
INFO:root:At the start of the epoch: mem (CPU python)=36694.984375MB; mem (CPU total)=36696.5MB
INFO:root:[  167] Training loss: 0.61508894, Validation loss: 0.60997101, Gradient norm: 0.05446379
INFO:root:At the start of the epoch: mem (CPU python)=36695.37890625MB; mem (CPU total)=36684.4296875MB
INFO:root:[  168] Training loss: 0.61468455, Validation loss: 0.60991433, Gradient norm: 0.05522102
INFO:root:At the start of the epoch: mem (CPU python)=36721.17578125MB; mem (CPU total)=36722.6328125MB
INFO:root:[  169] Training loss: 0.61475490, Validation loss: 0.61033661, Gradient norm: 0.05502205
INFO:root:At the start of the epoch: mem (CPU python)=36809.26953125MB; mem (CPU total)=36810.9921875MB
INFO:root:[  170] Training loss: 0.61459457, Validation loss: 0.60988691, Gradient norm: 0.05428129
INFO:root:At the start of the epoch: mem (CPU python)=36809.4921875MB; mem (CPU total)=36749.03515625MB
INFO:root:[  171] Training loss: 0.61492815, Validation loss: 0.60982343, Gradient norm: 0.05325215
INFO:root:At the start of the epoch: mem (CPU python)=36910.46484375MB; mem (CPU total)=36912.80078125MB
INFO:root:[  172] Training loss: 0.61482424, Validation loss: 0.60977836, Gradient norm: 0.05460372
INFO:root:At the start of the epoch: mem (CPU python)=36948.55859375MB; mem (CPU total)=36950.71484375MB
INFO:root:[  173] Training loss: 0.61475897, Validation loss: 0.60899894, Gradient norm: 0.05540855
INFO:root:At the start of the epoch: mem (CPU python)=36948.9296875MB; mem (CPU total)=36888.74609375MB
INFO:root:[  174] Training loss: 0.61504059, Validation loss: 0.61055278, Gradient norm: 0.05556766
INFO:root:At the start of the epoch: mem (CPU python)=37024.75MB; mem (CPU total)=36953.10546875MB
INFO:root:[  175] Training loss: 0.61477015, Validation loss: 0.60999043, Gradient norm: 0.05737106
INFO:root:At the start of the epoch: mem (CPU python)=37024.75MB; mem (CPU total)=36916.17578125MB
INFO:root:[  176] Training loss: 0.61462721, Validation loss: 0.61032900, Gradient norm: 0.05356242
INFO:root:At the start of the epoch: mem (CPU python)=37050.9375MB; mem (CPU total)=37053.1328125MB
INFO:root:[  177] Training loss: 0.61481923, Validation loss: 0.60993565, Gradient norm: 0.05509443
INFO:root:At the start of the epoch: mem (CPU python)=37114.03515625MB; mem (CPU total)=37116.4765625MB
INFO:root:[  178] Training loss: 0.61496783, Validation loss: 0.60976875, Gradient norm: 0.05530980
INFO:root:At the start of the epoch: mem (CPU python)=37152.1328125MB; mem (CPU total)=37154.265625MB
INFO:root:[  179] Training loss: 0.61471338, Validation loss: 0.61013422, Gradient norm: 0.05565815
INFO:root:At the start of the epoch: mem (CPU python)=37152.58203125MB; mem (CPU total)=37117.296875MB
INFO:root:[  180] Training loss: 0.61462734, Validation loss: 0.60945279, Gradient norm: 0.05463018
INFO:root:At the start of the epoch: mem (CPU python)=37152.58203125MB; mem (CPU total)=37130.48828125MB
INFO:root:[  181] Training loss: 0.61472051, Validation loss: 0.60851920, Gradient norm: 0.05558165
INFO:root:At the start of the epoch: mem (CPU python)=37266.41796875MB; mem (CPU total)=37268.45703125MB
INFO:root:[  182] Training loss: 0.61479362, Validation loss: 0.61049469, Gradient norm: 0.05732632
INFO:root:At the start of the epoch: mem (CPU python)=37304.51171875MB; mem (CPU total)=37306.87890625MB
INFO:root:[  183] Training loss: 0.61479556, Validation loss: 0.60989770, Gradient norm: 0.05665792
INFO:root:At the start of the epoch: mem (CPU python)=37342.60546875MB; mem (CPU total)=37345.0546875MB
INFO:root:[  184] Training loss: 0.61473325, Validation loss: 0.60941840, Gradient norm: 0.05579753
INFO:root:At the start of the epoch: mem (CPU python)=37380.69921875MB; mem (CPU total)=37383.19921875MB
INFO:root:[  185] Training loss: 0.61515511, Validation loss: 0.61070098, Gradient norm: 0.05621637
INFO:root:At the start of the epoch: mem (CPU python)=37381.15625MB; mem (CPU total)=37370.8828125MB
INFO:root:[  186] Training loss: 0.61448496, Validation loss: 0.60985806, Gradient norm: 0.05346947
INFO:root:At the start of the epoch: mem (CPU python)=37456.89453125MB; mem (CPU total)=37459.2109375MB
INFO:root:[  187] Training loss: 0.61476802, Validation loss: 0.61006709, Gradient norm: 0.05363401
INFO:root:At the start of the epoch: mem (CPU python)=37457.296875MB; mem (CPU total)=37447.5078125MB
INFO:root:[  188] Training loss: 0.61452983, Validation loss: 0.61002410, Gradient norm: 0.05572134
INFO:root:At the start of the epoch: mem (CPU python)=37483.08984375MB; mem (CPU total)=37485.71484375MB
INFO:root:[  189] Training loss: 0.61475480, Validation loss: 0.61011618, Gradient norm: 0.05726391
INFO:root:At the start of the epoch: mem (CPU python)=37571.18359375MB; mem (CPU total)=37574.04296875MB
INFO:root:[  190] Training loss: 0.61450087, Validation loss: 0.60956296, Gradient norm: 0.05544849
INFO:root:At the start of the epoch: mem (CPU python)=37584.1875MB; mem (CPU total)=37513.08984375MB
INFO:root:EP 190: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=37647.375MB; mem (CPU total)=37650.125MB
INFO:root:Training the model took 15093.554s.
INFO:root:Emptying the cuda cache took 0.03s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84505
INFO:root:EnergyScoreTrain: 0.59491
INFO:root:CRPSTrain: 0.46004
INFO:root:Gaussian NLLTrain: 1.18039
INFO:root:CoverageTrain: 0.95429
INFO:root:IntervalWidthTrain: 3.27011
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86637
INFO:root:EnergyScoreValidation: 0.6098
INFO:root:CRPSValidation: 0.47274
INFO:root:Gaussian NLLValidation: 1.20812
INFO:root:CoverageValidation: 0.9476
INFO:root:IntervalWidthValidation: 3.27378
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86777
INFO:root:EnergyScoreTest: 0.61077
INFO:root:CRPSTest: 0.47364
INFO:root:Gaussian NLLTest: 1.20989
INFO:root:CoverageTest: 0.9471
INFO:root:IntervalWidthTest: 3.27304
INFO:root:After validation: mem (CPU python)=37648.2109375MB; mem (CPU total)=37574.76953125MB
INFO:root:###7 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 1234567, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=37648.2109375MB; mem (CPU total)=37574.5234375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=37648.2109375MB; mem (CPU total)=37574.5234375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=37648.2109375MB; mem (CPU total)=37574.7578125MB
INFO:root:[    1] Training loss: 0.72558927, Validation loss: 0.72019151, Gradient norm: 0.02345842
INFO:root:At the start of the epoch: mem (CPU python)=37727.40625MB; mem (CPU total)=37582.2578125MB
INFO:root:[    2] Training loss: 0.71966232, Validation loss: 0.71879601, Gradient norm: 0.00554887
INFO:root:At the start of the epoch: mem (CPU python)=37727.40625MB; mem (CPU total)=37641.44921875MB
INFO:root:[    3] Training loss: 0.71745401, Validation loss: 0.71341879, Gradient norm: 0.00870957
INFO:root:At the start of the epoch: mem (CPU python)=37850.06640625MB; mem (CPU total)=37680.33203125MB
INFO:root:[    4] Training loss: 0.71069210, Validation loss: 0.70417352, Gradient norm: 0.01988746
INFO:root:At the start of the epoch: mem (CPU python)=37850.06640625MB; mem (CPU total)=37743.73828125MB
INFO:root:[    5] Training loss: 0.70381936, Validation loss: 0.69747502, Gradient norm: 0.02695066
INFO:root:At the start of the epoch: mem (CPU python)=37850.06640625MB; mem (CPU total)=37731.078125MB
INFO:root:[    6] Training loss: 0.69804987, Validation loss: 0.69093293, Gradient norm: 0.02836084
INFO:root:At the start of the epoch: mem (CPU python)=37861.29296875MB; mem (CPU total)=37818.671875MB
INFO:root:[    7] Training loss: 0.69262066, Validation loss: 0.68627945, Gradient norm: 0.02816554
INFO:root:At the start of the epoch: mem (CPU python)=37951.546875MB; mem (CPU total)=37832.29296875MB
INFO:root:[    8] Training loss: 0.68807173, Validation loss: 0.68107463, Gradient norm: 0.02783389
INFO:root:At the start of the epoch: mem (CPU python)=37951.546875MB; mem (CPU total)=37946.171875MB
INFO:root:[    9] Training loss: 0.68447718, Validation loss: 0.67725175, Gradient norm: 0.02835070
INFO:root:At the start of the epoch: mem (CPU python)=38078.77734375MB; mem (CPU total)=38084.7109375MB
INFO:root:[   10] Training loss: 0.68110911, Validation loss: 0.67339110, Gradient norm: 0.02797366
INFO:root:At the start of the epoch: mem (CPU python)=38116.87109375MB; mem (CPU total)=38122.53125MB
INFO:root:[   11] Training loss: 0.67833624, Validation loss: 0.67036986, Gradient norm: 0.03087876
INFO:root:At the start of the epoch: mem (CPU python)=38117.46484375MB; mem (CPU total)=38085.5390625MB
INFO:root:[   12] Training loss: 0.67568175, Validation loss: 0.66814595, Gradient norm: 0.03052224
INFO:root:At the start of the epoch: mem (CPU python)=38117.46484375MB; mem (CPU total)=38049.015625MB
INFO:root:[   13] Training loss: 0.67320716, Validation loss: 0.66557047, Gradient norm: 0.03211808
INFO:root:At the start of the epoch: mem (CPU python)=38180.9609375MB; mem (CPU total)=38112.62890625MB
INFO:root:[   14] Training loss: 0.67120238, Validation loss: 0.66351333, Gradient norm: 0.03223098
INFO:root:At the start of the epoch: mem (CPU python)=38180.9609375MB; mem (CPU total)=38150.28125MB
INFO:root:[   15] Training loss: 0.66879876, Validation loss: 0.66070469, Gradient norm: 0.03091405
INFO:root:At the start of the epoch: mem (CPU python)=38232.34765625MB; mem (CPU total)=38238.578125MB
INFO:root:[   16] Training loss: 0.66678201, Validation loss: 0.65854230, Gradient norm: 0.03261649
INFO:root:At the start of the epoch: mem (CPU python)=38270.4453125MB; mem (CPU total)=38276.23828125MB
INFO:root:[   17] Training loss: 0.66467280, Validation loss: 0.65529524, Gradient norm: 0.03275876
INFO:root:At the start of the epoch: mem (CPU python)=38283.5390625MB; mem (CPU total)=38289.66796875MB
INFO:root:[   18] Training loss: 0.66273967, Validation loss: 0.65340212, Gradient norm: 0.03587608
INFO:root:At the start of the epoch: mem (CPU python)=38346.63671875MB; mem (CPU total)=38353.01171875MB
INFO:root:[   19] Training loss: 0.66066723, Validation loss: 0.65107233, Gradient norm: 0.03399433
INFO:root:At the start of the epoch: mem (CPU python)=38346.859375MB; mem (CPU total)=38290.796875MB
INFO:root:[   20] Training loss: 0.65929246, Validation loss: 0.64981169, Gradient norm: 0.03492110
INFO:root:At the start of the epoch: mem (CPU python)=38418.80859375MB; mem (CPU total)=38354.1796875MB
INFO:root:[   21] Training loss: 0.65750854, Validation loss: 0.64723967, Gradient norm: 0.03662301
INFO:root:At the start of the epoch: mem (CPU python)=38458.0234375MB; mem (CPU total)=38392.5625MB
INFO:root:[   22] Training loss: 0.65599238, Validation loss: 0.64664417, Gradient norm: 0.03614891
INFO:root:At the start of the epoch: mem (CPU python)=38472.21484375MB; mem (CPU total)=38430.4609375MB
INFO:root:[   23] Training loss: 0.65455740, Validation loss: 0.64470619, Gradient norm: 0.03711535
INFO:root:At the start of the epoch: mem (CPU python)=38537.11328125MB; mem (CPU total)=38543.57421875MB
INFO:root:[   24] Training loss: 0.65318514, Validation loss: 0.64271094, Gradient norm: 0.03861650
INFO:root:At the start of the epoch: mem (CPU python)=38573.55078125MB; mem (CPU total)=38506.828125MB
INFO:root:[   25] Training loss: 0.65212225, Validation loss: 0.64183284, Gradient norm: 0.03927732
INFO:root:At the start of the epoch: mem (CPU python)=38613.3046875MB; mem (CPU total)=38619.89453125MB
INFO:root:[   26] Training loss: 0.65093394, Validation loss: 0.64036200, Gradient norm: 0.03711629
INFO:root:At the start of the epoch: mem (CPU python)=38673.6015625MB; mem (CPU total)=38608.3671875MB
INFO:root:[   27] Training loss: 0.64994344, Validation loss: 0.63942600, Gradient norm: 0.03922860
INFO:root:At the start of the epoch: mem (CPU python)=38713.73828125MB; mem (CPU total)=38571.8671875MB
INFO:root:[   28] Training loss: 0.64882669, Validation loss: 0.63815165, Gradient norm: 0.03943136
INFO:root:At the start of the epoch: mem (CPU python)=38727.58984375MB; mem (CPU total)=38734.453125MB
INFO:root:[   29] Training loss: 0.64799113, Validation loss: 0.63798538, Gradient norm: 0.04361756
INFO:root:At the start of the epoch: mem (CPU python)=38790.61328125MB; mem (CPU total)=38723.14453125MB
INFO:root:[   30] Training loss: 0.64714174, Validation loss: 0.63689861, Gradient norm: 0.04600842
INFO:root:At the start of the epoch: mem (CPU python)=38790.61328125MB; mem (CPU total)=38710.84765625MB
INFO:root:[   31] Training loss: 0.64613126, Validation loss: 0.63514882, Gradient norm: 0.04316397
INFO:root:At the start of the epoch: mem (CPU python)=38813.5390625MB; mem (CPU total)=38773.9453125MB
INFO:root:[   32] Training loss: 0.64550841, Validation loss: 0.63513377, Gradient norm: 0.04663113
INFO:root:At the start of the epoch: mem (CPU python)=38879.97265625MB; mem (CPU total)=38887.2578125MB
INFO:root:[   33] Training loss: 0.64438826, Validation loss: 0.63291101, Gradient norm: 0.04348480
INFO:root:At the start of the epoch: mem (CPU python)=38943.06640625MB; mem (CPU total)=38950.92578125MB
INFO:root:[   34] Training loss: 0.64368009, Validation loss: 0.63283208, Gradient norm: 0.04512002
INFO:root:At the start of the epoch: mem (CPU python)=38943.2890625MB; mem (CPU total)=38888.7890625MB
INFO:root:[   35] Training loss: 0.64299671, Validation loss: 0.63216110, Gradient norm: 0.04507273
INFO:root:At the start of the epoch: mem (CPU python)=39019.03125MB; mem (CPU total)=38926.92578125MB
INFO:root:[   36] Training loss: 0.64223008, Validation loss: 0.63104681, Gradient norm: 0.04984983
INFO:root:At the start of the epoch: mem (CPU python)=39032.3515625MB; mem (CPU total)=39040.17578125MB
INFO:root:[   37] Training loss: 0.64140816, Validation loss: 0.63037750, Gradient norm: 0.04618155
INFO:root:At the start of the epoch: mem (CPU python)=39095.4140625MB; mem (CPU total)=38954.01953125MB
INFO:root:[   38] Training loss: 0.64068316, Validation loss: 0.62947422, Gradient norm: 0.05038264
INFO:root:At the start of the epoch: mem (CPU python)=39131.16796875MB; mem (CPU total)=39041.6328125MB
INFO:root:[   39] Training loss: 0.64018145, Validation loss: 0.62900009, Gradient norm: 0.05199782
INFO:root:At the start of the epoch: mem (CPU python)=39219.37109375MB; mem (CPU total)=39179.8984375MB
INFO:root:[   40] Training loss: 0.63958768, Validation loss: 0.62836823, Gradient norm: 0.04700135
INFO:root:At the start of the epoch: mem (CPU python)=39259.734375MB; mem (CPU total)=39267.98046875MB
INFO:root:[   41] Training loss: 0.63883627, Validation loss: 0.62775428, Gradient norm: 0.04964924
INFO:root:At the start of the epoch: mem (CPU python)=39297.828125MB; mem (CPU total)=39306.24609375MB
INFO:root:[   42] Training loss: 0.63846974, Validation loss: 0.62868522, Gradient norm: 0.05130063
INFO:root:At the start of the epoch: mem (CPU python)=39335.43359375MB; mem (CPU total)=39195.30078125MB
INFO:root:[   43] Training loss: 0.63770325, Validation loss: 0.62678104, Gradient norm: 0.04833434
INFO:root:At the start of the epoch: mem (CPU python)=39335.43359375MB; mem (CPU total)=39207.79296875MB
INFO:root:[   44] Training loss: 0.63712972, Validation loss: 0.62695437, Gradient norm: 0.04860878
INFO:root:At the start of the epoch: mem (CPU python)=39337.11328125MB; mem (CPU total)=39345.8359375MB
INFO:root:[   45] Training loss: 0.63675912, Validation loss: 0.62630448, Gradient norm: 0.04742529
INFO:root:At the start of the epoch: mem (CPU python)=39373.8828125MB; mem (CPU total)=39308.84765625MB
INFO:root:[   46] Training loss: 0.63631836, Validation loss: 0.62556324, Gradient norm: 0.05002455
INFO:root:At the start of the epoch: mem (CPU python)=39413.19921875MB; mem (CPU total)=39297.36328125MB
INFO:root:[   47] Training loss: 0.63577240, Validation loss: 0.62568148, Gradient norm: 0.05716284
INFO:root:At the start of the epoch: mem (CPU python)=39451.3984375MB; mem (CPU total)=39460.25390625MB
INFO:root:[   48] Training loss: 0.63527491, Validation loss: 0.62417178, Gradient norm: 0.04952557
INFO:root:At the start of the epoch: mem (CPU python)=39487.38671875MB; mem (CPU total)=39473.0MB
INFO:root:[   49] Training loss: 0.63504713, Validation loss: 0.62414037, Gradient norm: 0.05831999
INFO:root:At the start of the epoch: mem (CPU python)=39549.35546875MB; mem (CPU total)=39411.5078125MB
INFO:root:[   50] Training loss: 0.63443795, Validation loss: 0.62339708, Gradient norm: 0.05596261
INFO:root:At the start of the epoch: mem (CPU python)=39549.35546875MB; mem (CPU total)=39524.28515625MB
INFO:root:[   51] Training loss: 0.63394880, Validation loss: 0.62258178, Gradient norm: 0.05116612
INFO:root:At the start of the epoch: mem (CPU python)=39651.43359375MB; mem (CPU total)=39587.40625MB
INFO:root:[   52] Training loss: 0.63350977, Validation loss: 0.62256820, Gradient norm: 0.05309894
INFO:root:At the start of the epoch: mem (CPU python)=39666.78125MB; mem (CPU total)=39601.02734375MB
INFO:root:[   53] Training loss: 0.63304747, Validation loss: 0.62238663, Gradient norm: 0.05850482
INFO:root:At the start of the epoch: mem (CPU python)=39679.97265625MB; mem (CPU total)=39688.85546875MB
INFO:root:[   54] Training loss: 0.63281693, Validation loss: 0.62247340, Gradient norm: 0.05316939
INFO:root:At the start of the epoch: mem (CPU python)=39743.06640625MB; mem (CPU total)=39751.921875MB
INFO:root:[   55] Training loss: 0.63234481, Validation loss: 0.62164180, Gradient norm: 0.05584531
INFO:root:At the start of the epoch: mem (CPU python)=39743.46484375MB; mem (CPU total)=39690.078125MB
INFO:root:[   56] Training loss: 0.63216120, Validation loss: 0.62234126, Gradient norm: 0.06165193
INFO:root:At the start of the epoch: mem (CPU python)=39793.93359375MB; mem (CPU total)=39729.20703125MB
INFO:root:[   57] Training loss: 0.63148406, Validation loss: 0.62107854, Gradient norm: 0.05400266
INFO:root:At the start of the epoch: mem (CPU python)=39882.35546875MB; mem (CPU total)=39891.47265625MB
INFO:root:[   58] Training loss: 0.63104686, Validation loss: 0.62131087, Gradient norm: 0.05179582
INFO:root:At the start of the epoch: mem (CPU python)=39895.44921875MB; mem (CPU total)=39830.71875MB
INFO:root:[   59] Training loss: 0.63096564, Validation loss: 0.62036289, Gradient norm: 0.05311456
INFO:root:At the start of the epoch: mem (CPU python)=39958.515625MB; mem (CPU total)=39793.40625MB
INFO:root:[   60] Training loss: 0.63044635, Validation loss: 0.62011695, Gradient norm: 0.05837113
INFO:root:At the start of the epoch: mem (CPU python)=39971.640625MB; mem (CPU total)=39981.1484375MB
INFO:root:[   61] Training loss: 0.62997711, Validation loss: 0.61940462, Gradient norm: 0.05224773
INFO:root:At the start of the epoch: mem (CPU python)=40032.078125MB; mem (CPU total)=39969.23046875MB
INFO:root:[   62] Training loss: 0.62983490, Validation loss: 0.62015273, Gradient norm: 0.06164797
INFO:root:At the start of the epoch: mem (CPU python)=40071.46484375MB; mem (CPU total)=40057.38671875MB
INFO:root:[   63] Training loss: 0.62965282, Validation loss: 0.61889565, Gradient norm: 0.05837880
INFO:root:At the start of the epoch: mem (CPU python)=40085.9296875MB; mem (CPU total)=40095.28515625MB
INFO:root:[   64] Training loss: 0.62918431, Validation loss: 0.61913021, Gradient norm: 0.05544066
INFO:root:At the start of the epoch: mem (CPU python)=40086.21875MB; mem (CPU total)=40058.26171875MB
INFO:root:[   65] Training loss: 0.62886573, Validation loss: 0.61786484, Gradient norm: 0.05530286
INFO:root:At the start of the epoch: mem (CPU python)=40111.90234375MB; mem (CPU total)=40021.75390625MB
INFO:root:[   66] Training loss: 0.62857157, Validation loss: 0.61829588, Gradient norm: 0.05604812
INFO:root:At the start of the epoch: mem (CPU python)=40175.21484375MB; mem (CPU total)=40184.97265625MB
INFO:root:[   67] Training loss: 0.62824418, Validation loss: 0.61804176, Gradient norm: 0.05916843
INFO:root:At the start of the epoch: mem (CPU python)=40212.42578125MB; mem (CPU total)=40147.94921875MB
INFO:root:[   68] Training loss: 0.62807780, Validation loss: 0.61844853, Gradient norm: 0.06857343
INFO:root:At the start of the epoch: mem (CPU python)=40247.8125MB; mem (CPU total)=40236.27734375MB
INFO:root:[   69] Training loss: 0.62771173, Validation loss: 0.61771376, Gradient norm: 0.06271443
INFO:root:At the start of the epoch: mem (CPU python)=40289.265625MB; mem (CPU total)=40199.7109375MB
INFO:root:[   70] Training loss: 0.62738535, Validation loss: 0.61678119, Gradient norm: 0.05561823
INFO:root:At the start of the epoch: mem (CPU python)=40289.265625MB; mem (CPU total)=40262.9453125MB
INFO:root:[   71] Training loss: 0.62720862, Validation loss: 0.61734423, Gradient norm: 0.06370771
INFO:root:At the start of the epoch: mem (CPU python)=40365.6875MB; mem (CPU total)=40375.734375MB
INFO:root:[   72] Training loss: 0.62678441, Validation loss: 0.61684454, Gradient norm: 0.05578600
INFO:root:At the start of the epoch: mem (CPU python)=40453.7890625MB; mem (CPU total)=40464.0546875MB
INFO:root:[   73] Training loss: 0.62653638, Validation loss: 0.61740626, Gradient norm: 0.05814597
INFO:root:At the start of the epoch: mem (CPU python)=40466.8515625MB; mem (CPU total)=40402.84765625MB
INFO:root:[   74] Training loss: 0.62639815, Validation loss: 0.61625839, Gradient norm: 0.05717770
INFO:root:At the start of the epoch: mem (CPU python)=40529.8046875MB; mem (CPU total)=40465.73046875MB
INFO:root:[   75] Training loss: 0.62612043, Validation loss: 0.61557410, Gradient norm: 0.06631000
INFO:root:At the start of the epoch: mem (CPU python)=40529.8046875MB; mem (CPU total)=40454.23828125MB
INFO:root:[   76] Training loss: 0.62566043, Validation loss: 0.61606177, Gradient norm: 0.06006155
INFO:root:At the start of the epoch: mem (CPU python)=40529.8046875MB; mem (CPU total)=40490.8828125MB
INFO:root:[   77] Training loss: 0.62563969, Validation loss: 0.61569422, Gradient norm: 0.06886895
INFO:root:At the start of the epoch: mem (CPU python)=40569.19921875MB; mem (CPU total)=40480.04296875MB
INFO:root:[   78] Training loss: 0.62514530, Validation loss: 0.61560195, Gradient norm: 0.05915341
INFO:root:At the start of the epoch: mem (CPU python)=40569.19921875MB; mem (CPU total)=40567.140625MB
INFO:root:[   79] Training loss: 0.62511974, Validation loss: 0.61552359, Gradient norm: 0.05909653
INFO:root:At the start of the epoch: mem (CPU python)=40645.453125MB; mem (CPU total)=40655.44140625MB
INFO:root:[   80] Training loss: 0.62461868, Validation loss: 0.61581854, Gradient norm: 0.05584428
INFO:root:At the start of the epoch: mem (CPU python)=40733.546875MB; mem (CPU total)=40743.796875MB
INFO:root:[   81] Training loss: 0.62448370, Validation loss: 0.61596719, Gradient norm: 0.05545634
INFO:root:At the start of the epoch: mem (CPU python)=40796.64453125MB; mem (CPU total)=40806.23046875MB
INFO:root:[   82] Training loss: 0.62425426, Validation loss: 0.61432000, Gradient norm: 0.06051069
INFO:root:At the start of the epoch: mem (CPU python)=40797.09765625MB; mem (CPU total)=40794.98828125MB
INFO:root:[   83] Training loss: 0.62430059, Validation loss: 0.61407099, Gradient norm: 0.06370803
INFO:root:At the start of the epoch: mem (CPU python)=40797.09765625MB; mem (CPU total)=40758.484375MB
INFO:root:[   84] Training loss: 0.62383294, Validation loss: 0.61400649, Gradient norm: 0.05810986
INFO:root:At the start of the epoch: mem (CPU python)=40860.8125MB; mem (CPU total)=40771.9453125MB
INFO:root:[   85] Training loss: 0.62366560, Validation loss: 0.61420047, Gradient norm: 0.06916177
INFO:root:At the start of the epoch: mem (CPU python)=40860.8125MB; mem (CPU total)=40834.6171875MB
INFO:root:[   86] Training loss: 0.62328455, Validation loss: 0.61416375, Gradient norm: 0.05894565
INFO:root:At the start of the epoch: mem (CPU python)=40962.12109375MB; mem (CPU total)=40823.71484375MB
INFO:root:[   87] Training loss: 0.62308758, Validation loss: 0.61382101, Gradient norm: 0.05950036
INFO:root:At the start of the epoch: mem (CPU python)=40962.12109375MB; mem (CPU total)=40910.8125MB
INFO:root:[   88] Training loss: 0.62259104, Validation loss: 0.61295212, Gradient norm: 0.05698403
INFO:root:At the start of the epoch: mem (CPU python)=41011.26953125MB; mem (CPU total)=40974.1875MB
INFO:root:[   89] Training loss: 0.62269221, Validation loss: 0.61307056, Gradient norm: 0.05796863
INFO:root:At the start of the epoch: mem (CPU python)=41076.40625MB; mem (CPU total)=41087.875MB
INFO:root:[   90] Training loss: 0.62252245, Validation loss: 0.61343310, Gradient norm: 0.06139853
INFO:root:At the start of the epoch: mem (CPU python)=41076.6640625MB; mem (CPU total)=41025.8515625MB
INFO:root:[   91] Training loss: 0.62209762, Validation loss: 0.61252592, Gradient norm: 0.06062986
INFO:root:At the start of the epoch: mem (CPU python)=41102.59765625MB; mem (CPU total)=41113.65625MB
INFO:root:[   92] Training loss: 0.62188571, Validation loss: 0.61212251, Gradient norm: 0.05853847
INFO:root:At the start of the epoch: mem (CPU python)=41165.69140625MB; mem (CPU total)=41177.0546875MB
INFO:root:[   93] Training loss: 0.62182489, Validation loss: 0.61251974, Gradient norm: 0.06174255
INFO:root:At the start of the epoch: mem (CPU python)=41253.7890625MB; mem (CPU total)=41265.13671875MB
INFO:root:[   94] Training loss: 0.62182518, Validation loss: 0.61225112, Gradient norm: 0.06562483
INFO:root:At the start of the epoch: mem (CPU python)=41254.24609375MB; mem (CPU total)=41153.22265625MB
INFO:root:[   95] Training loss: 0.62131750, Validation loss: 0.61275960, Gradient norm: 0.05851558
INFO:root:At the start of the epoch: mem (CPU python)=41254.9765625MB; mem (CPU total)=41266.44140625MB
INFO:root:[   96] Training loss: 0.62122106, Validation loss: 0.61200905, Gradient norm: 0.05989213
INFO:root:At the start of the epoch: mem (CPU python)=41340.45703125MB; mem (CPU total)=41254.453125MB
INFO:root:[   97] Training loss: 0.62121795, Validation loss: 0.61224724, Gradient norm: 0.06814959
INFO:root:At the start of the epoch: mem (CPU python)=41353.92578125MB; mem (CPU total)=41292.8359375MB
INFO:root:[   98] Training loss: 0.62107289, Validation loss: 0.61197266, Gradient norm: 0.06621548
INFO:root:At the start of the epoch: mem (CPU python)=41369.11328125MB; mem (CPU total)=41281.59765625MB
INFO:root:[   99] Training loss: 0.62084675, Validation loss: 0.61171715, Gradient norm: 0.06873938
INFO:root:At the start of the epoch: mem (CPU python)=41432.359375MB; mem (CPU total)=41444.28515625MB
INFO:root:[  100] Training loss: 0.62034707, Validation loss: 0.61063571, Gradient norm: 0.05945698
INFO:root:At the start of the epoch: mem (CPU python)=41468.5MB; mem (CPU total)=41382.29296875MB
INFO:root:[  101] Training loss: 0.62018106, Validation loss: 0.61112518, Gradient norm: 0.06010704
INFO:root:At the start of the epoch: mem (CPU python)=41558.55078125MB; mem (CPU total)=41570.7109375MB
INFO:root:[  102] Training loss: 0.62018379, Validation loss: 0.61118398, Gradient norm: 0.06149810
INFO:root:At the start of the epoch: mem (CPU python)=41558.77734375MB; mem (CPU total)=41458.59375MB
INFO:root:[  103] Training loss: 0.62010870, Validation loss: 0.61121498, Gradient norm: 0.06555784
INFO:root:At the start of the epoch: mem (CPU python)=41558.77734375MB; mem (CPU total)=41496.5703125MB
INFO:root:[  104] Training loss: 0.61973950, Validation loss: 0.61083328, Gradient norm: 0.05664812
INFO:root:At the start of the epoch: mem (CPU python)=41592.7109375MB; mem (CPU total)=41534.953125MB
INFO:root:[  105] Training loss: 0.61942301, Validation loss: 0.61125984, Gradient norm: 0.06204435
INFO:root:At the start of the epoch: mem (CPU python)=41634.96875MB; mem (CPU total)=41598.08203125MB
INFO:root:[  106] Training loss: 0.61958741, Validation loss: 0.61223670, Gradient norm: 0.06403167
INFO:root:At the start of the epoch: mem (CPU python)=41699.03515625MB; mem (CPU total)=41711.35546875MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  107] Training loss: 0.61938536, Validation loss: 0.61100641, Gradient norm: 0.06805106
INFO:root:At the start of the epoch: mem (CPU python)=41699.2578125MB; mem (CPU total)=41674.36328125MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  108] Training loss: 0.61816732, Validation loss: 0.60998005, Gradient norm: 0.05636482
INFO:root:At the start of the epoch: mem (CPU python)=41750.22265625MB; mem (CPU total)=41762.72265625MB
INFO:root:[  109] Training loss: 0.61760554, Validation loss: 0.60867180, Gradient norm: 0.05057837
INFO:root:At the start of the epoch: mem (CPU python)=41811.23046875MB; mem (CPU total)=41775.69140625MB
INFO:root:[  110] Training loss: 0.61733995, Validation loss: 0.60960638, Gradient norm: 0.05240580
INFO:root:At the start of the epoch: mem (CPU python)=41900.55078125MB; mem (CPU total)=41839.30859375MB
INFO:root:[  111] Training loss: 0.61747610, Validation loss: 0.60943662, Gradient norm: 0.05016707
INFO:root:At the start of the epoch: mem (CPU python)=41900.55078125MB; mem (CPU total)=41827.38671875MB
INFO:root:[  112] Training loss: 0.61727701, Validation loss: 0.60953833, Gradient norm: 0.05256812
INFO:root:At the start of the epoch: mem (CPU python)=41927.24609375MB; mem (CPU total)=41890.14453125MB
INFO:root:[  113] Training loss: 0.61727628, Validation loss: 0.60952680, Gradient norm: 0.04978992
INFO:root:At the start of the epoch: mem (CPU python)=41990.703125MB; mem (CPU total)=42003.44921875MB
INFO:root:[  114] Training loss: 0.61717121, Validation loss: 0.60943710, Gradient norm: 0.05247506
INFO:root:At the start of the epoch: mem (CPU python)=42002.234375MB; mem (CPU total)=41966.1640625MB
INFO:root:[  115] Training loss: 0.61713592, Validation loss: 0.60866579, Gradient norm: 0.05250255
INFO:root:At the start of the epoch: mem (CPU python)=42091.890625MB; mem (CPU total)=42104.70703125MB
INFO:root:[  116] Training loss: 0.61715392, Validation loss: 0.60939485, Gradient norm: 0.05474786
INFO:root:At the start of the epoch: mem (CPU python)=42104.98828125MB; mem (CPU total)=42117.8203125MB
INFO:root:[  117] Training loss: 0.61703419, Validation loss: 0.60970865, Gradient norm: 0.05330128
INFO:root:At the start of the epoch: mem (CPU python)=42105.20703125MB; mem (CPU total)=42056.08984375MB
INFO:root:[  118] Training loss: 0.61675828, Validation loss: 0.60892740, Gradient norm: 0.05362892
INFO:root:At the start of the epoch: mem (CPU python)=42156.17578125MB; mem (CPU total)=42169.0546875MB
INFO:root:[  119] Training loss: 0.61697054, Validation loss: 0.60900090, Gradient norm: 0.05328647
INFO:root:At the start of the epoch: mem (CPU python)=42218.07421875MB; mem (CPU total)=42207.453125MB
INFO:root:[  120] Training loss: 0.61705169, Validation loss: 0.60949520, Gradient norm: 0.05498413
INFO:root:At the start of the epoch: mem (CPU python)=42257.3671875MB; mem (CPU total)=42171.67578125MB
INFO:root:[  121] Training loss: 0.61689797, Validation loss: 0.60922336, Gradient norm: 0.05378783
INFO:root:At the start of the epoch: mem (CPU python)=42270.4609375MB; mem (CPU total)=42283.97265625MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  122] Training loss: 0.61663924, Validation loss: 0.60912965, Gradient norm: 0.05349711
INFO:root:At the start of the epoch: mem (CPU python)=42305.39453125MB; mem (CPU total)=42198.2734375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  123] Training loss: 0.61650969, Validation loss: 0.60857503, Gradient norm: 0.05249451
INFO:root:At the start of the epoch: mem (CPU python)=42371.65625MB; mem (CPU total)=42385.41015625MB
INFO:root:[  124] Training loss: 0.61625347, Validation loss: 0.60957570, Gradient norm: 0.05107149
INFO:root:At the start of the epoch: mem (CPU python)=42456.5234375MB; mem (CPU total)=42448.77734375MB
INFO:root:[  125] Training loss: 0.61619975, Validation loss: 0.60873767, Gradient norm: 0.04906736
INFO:root:At the start of the epoch: mem (CPU python)=42456.5234375MB; mem (CPU total)=42436.73046875MB
INFO:root:[  126] Training loss: 0.61618282, Validation loss: 0.60869383, Gradient norm: 0.05058872
INFO:root:At the start of the epoch: mem (CPU python)=42456.5234375MB; mem (CPU total)=42449.60546875MB
INFO:root:[  127] Training loss: 0.61602701, Validation loss: 0.60884341, Gradient norm: 0.04922477
INFO:root:At the start of the epoch: mem (CPU python)=42548.82421875MB; mem (CPU total)=42463.99609375MB
INFO:root:[  128] Training loss: 0.61608318, Validation loss: 0.60898009, Gradient norm: 0.05077051
INFO:root:At the start of the epoch: mem (CPU python)=42548.82421875MB; mem (CPU total)=42500.91015625MB
INFO:root:[  129] Training loss: 0.61621734, Validation loss: 0.60826925, Gradient norm: 0.05144455
INFO:root:At the start of the epoch: mem (CPU python)=42550.22265625MB; mem (CPU total)=42564.85546875MB
INFO:root:[  130] Training loss: 0.61626995, Validation loss: 0.60825484, Gradient norm: 0.05015764
INFO:root:At the start of the epoch: mem (CPU python)=42635.49609375MB; mem (CPU total)=42602.77734375MB
INFO:root:[  131] Training loss: 0.61624171, Validation loss: 0.60775862, Gradient norm: 0.04948964
INFO:root:At the start of the epoch: mem (CPU python)=42676.41796875MB; mem (CPU total)=42691.09765625MB
INFO:root:[  132] Training loss: 0.61610348, Validation loss: 0.60819486, Gradient norm: 0.05107141
INFO:root:At the start of the epoch: mem (CPU python)=42689.47265625MB; mem (CPU total)=42630.06640625MB
INFO:root:[  133] Training loss: 0.61604290, Validation loss: 0.60841557, Gradient norm: 0.05025401
INFO:root:At the start of the epoch: mem (CPU python)=42689.47265625MB; mem (CPU total)=42692.171875MB
INFO:root:[  134] Training loss: 0.61599934, Validation loss: 0.60806126, Gradient norm: 0.05061594
INFO:root:At the start of the epoch: mem (CPU python)=42790.58984375MB; mem (CPU total)=42731.515625MB
INFO:root:[  135] Training loss: 0.61608806, Validation loss: 0.60795833, Gradient norm: 0.05055801
INFO:root:At the start of the epoch: mem (CPU python)=42790.58984375MB; mem (CPU total)=42694.27734375MB
INFO:root:[  136] Training loss: 0.61601964, Validation loss: 0.60836391, Gradient norm: 0.04997965
INFO:root:At the start of the epoch: mem (CPU python)=42816.890625MB; mem (CPU total)=42831.2109375MB
INFO:root:[  137] Training loss: 0.61615642, Validation loss: 0.60859531, Gradient norm: 0.05188934
INFO:root:At the start of the epoch: mem (CPU python)=42929.98828125MB; mem (CPU total)=42944.73828125MB
INFO:root:[  138] Training loss: 0.61625514, Validation loss: 0.60850649, Gradient norm: 0.05318155
INFO:root:At the start of the epoch: mem (CPU python)=42943.0859375MB; mem (CPU total)=42957.9296875MB
INFO:root:[  139] Training loss: 0.61619416, Validation loss: 0.60877744, Gradient norm: 0.05421107
INFO:root:At the start of the epoch: mem (CPU python)=42981.1796875MB; mem (CPU total)=42996.3046875MB
INFO:root:[  140] Training loss: 0.61593786, Validation loss: 0.60767006, Gradient norm: 0.05049590
INFO:root:At the start of the epoch: mem (CPU python)=42994.27734375MB; mem (CPU total)=43009.23828125MB
INFO:root:[  141] Training loss: 0.61578804, Validation loss: 0.60901009, Gradient norm: 0.04985351
INFO:root:At the start of the epoch: mem (CPU python)=42994.45703125MB; mem (CPU total)=42972.27734375MB
INFO:root:[  142] Training loss: 0.61587075, Validation loss: 0.60761155, Gradient norm: 0.04960905
INFO:root:At the start of the epoch: mem (CPU python)=43145.46484375MB; mem (CPU total)=43160.6328125MB
INFO:root:[  143] Training loss: 0.61596770, Validation loss: 0.60841427, Gradient norm: 0.05155679
INFO:root:At the start of the epoch: mem (CPU python)=43146.2265625MB; mem (CPU total)=43122.86328125MB
INFO:root:[  144] Training loss: 0.61604062, Validation loss: 0.60894529, Gradient norm: 0.05278790
INFO:root:At the start of the epoch: mem (CPU python)=43171.65625MB; mem (CPU total)=43185.98828125MB
INFO:root:[  145] Training loss: 0.61601509, Validation loss: 0.60846943, Gradient norm: 0.04979741
INFO:root:At the start of the epoch: mem (CPU python)=43171.87890625MB; mem (CPU total)=43173.84765625MB
INFO:root:[  146] Training loss: 0.61591914, Validation loss: 0.60816208, Gradient norm: 0.05236703
INFO:root:At the start of the epoch: mem (CPU python)=43171.87890625MB; mem (CPU total)=43137.0703125MB
INFO:root:[  147] Training loss: 0.61596572, Validation loss: 0.60849337, Gradient norm: 0.05180961
INFO:root:At the start of the epoch: mem (CPU python)=43207.59375MB; mem (CPU total)=43200.19921875MB
INFO:root:[  148] Training loss: 0.61609852, Validation loss: 0.60784618, Gradient norm: 0.05133301
INFO:root:At the start of the epoch: mem (CPU python)=43249.0390625MB; mem (CPU total)=43263.05078125MB
INFO:root:[  149] Training loss: 0.61590310, Validation loss: 0.60815885, Gradient norm: 0.05115962
INFO:root:At the start of the epoch: mem (CPU python)=43307.0078125MB; mem (CPU total)=43276.625MB
INFO:root:[  150] Training loss: 0.61608045, Validation loss: 0.60787895, Gradient norm: 0.05032055
INFO:root:At the start of the epoch: mem (CPU python)=43396.765625MB; mem (CPU total)=43266.3125MB
INFO:root:[  151] Training loss: 0.61607920, Validation loss: 0.60801200, Gradient norm: 0.05177783
INFO:root:At the start of the epoch: mem (CPU python)=43463.32421875MB; mem (CPU total)=43478.484375MB
INFO:root:EP 151: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=43501.41796875MB; mem (CPU total)=43516.3828125MB
INFO:root:Training the model took 13292.281s.
INFO:root:Emptying the cuda cache took 0.03s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.84759
INFO:root:EnergyScoreTrain: 0.59668
INFO:root:CRPSTrain: 0.46228
INFO:root:Gaussian NLLTrain: 1.18716
INFO:root:CoverageTrain: 0.95381
INFO:root:IntervalWidthTrain: 3.28481
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86438
INFO:root:EnergyScoreValidation: 0.6084
INFO:root:CRPSValidation: 0.47228
INFO:root:Gaussian NLLValidation: 1.20865
INFO:root:CoverageValidation: 0.94857
INFO:root:IntervalWidthValidation: 3.28639
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86616
INFO:root:EnergyScoreTest: 0.60965
INFO:root:CRPSTest: 0.47341
INFO:root:Gaussian NLLTest: 1.21088
INFO:root:CoverageTest: 0.94795
INFO:root:IntervalWidthTest: 3.28598
INFO:root:After validation: mem (CPU python)=43544.359375MB; mem (CPU total)=43559.69140625MB
INFO:root:###8 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 12345678, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=43544.359375MB; mem (CPU total)=43559.4453125MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=43544.78515625MB; mem (CPU total)=43559.9375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=43544.78515625MB; mem (CPU total)=43559.96875MB
INFO:root:[    1] Training loss: 0.72537444, Validation loss: 0.72031446, Gradient norm: 0.02089516
INFO:root:At the start of the epoch: mem (CPU python)=43575.24609375MB; mem (CPU total)=43501.36328125MB
INFO:root:[    2] Training loss: 0.71986354, Validation loss: 0.71913492, Gradient norm: 0.00592394
INFO:root:At the start of the epoch: mem (CPU python)=43575.24609375MB; mem (CPU total)=43564.8671875MB
INFO:root:[    3] Training loss: 0.71864998, Validation loss: 0.71690668, Gradient norm: 0.00681527
INFO:root:At the start of the epoch: mem (CPU python)=43613.859375MB; mem (CPU total)=43627.7421875MB
INFO:root:[    4] Training loss: 0.71499240, Validation loss: 0.70949375, Gradient norm: 0.01427919
INFO:root:At the start of the epoch: mem (CPU python)=43676.95703125MB; mem (CPU total)=43691.05078125MB
INFO:root:[    5] Training loss: 0.70800954, Validation loss: 0.70141222, Gradient norm: 0.02488919
INFO:root:At the start of the epoch: mem (CPU python)=43677.30078125MB; mem (CPU total)=43654.3203125MB
INFO:root:[    6] Training loss: 0.70200229, Validation loss: 0.69585505, Gradient norm: 0.02957134
INFO:root:At the start of the epoch: mem (CPU python)=43751.63671875MB; mem (CPU total)=43717.765625MB
INFO:root:[    7] Training loss: 0.69666292, Validation loss: 0.68924297, Gradient norm: 0.02595667
INFO:root:At the start of the epoch: mem (CPU python)=43766.2421875MB; mem (CPU total)=43781.04296875MB
INFO:root:[    8] Training loss: 0.69161923, Validation loss: 0.68463890, Gradient norm: 0.02848849
INFO:root:At the start of the epoch: mem (CPU python)=43804.3359375MB; mem (CPU total)=43820.33203125MB
INFO:root:[    9] Training loss: 0.68659851, Validation loss: 0.67766180, Gradient norm: 0.02856734
INFO:root:At the start of the epoch: mem (CPU python)=43842.43359375MB; mem (CPU total)=43858.359375MB
INFO:root:[   10] Training loss: 0.68172432, Validation loss: 0.67227601, Gradient norm: 0.02881049
INFO:root:At the start of the epoch: mem (CPU python)=43930.52734375MB; mem (CPU total)=43946.671875MB
INFO:root:[   11] Training loss: 0.67729624, Validation loss: 0.66842106, Gradient norm: 0.02794711
INFO:root:At the start of the epoch: mem (CPU python)=43930.75MB; mem (CPU total)=43809.8046875MB
INFO:root:[   12] Training loss: 0.67356279, Validation loss: 0.66428312, Gradient norm: 0.02709025
INFO:root:At the start of the epoch: mem (CPU python)=43956.640625MB; mem (CPU total)=43898.16015625MB
INFO:root:[   13] Training loss: 0.67010841, Validation loss: 0.66005124, Gradient norm: 0.02914008
INFO:root:At the start of the epoch: mem (CPU python)=43969.81640625MB; mem (CPU total)=43986.03125MB
INFO:root:[   14] Training loss: 0.66694495, Validation loss: 0.65670776, Gradient norm: 0.02842291
INFO:root:At the start of the epoch: mem (CPU python)=44032.91015625MB; mem (CPU total)=44049.43359375MB
INFO:root:[   15] Training loss: 0.66443161, Validation loss: 0.65395245, Gradient norm: 0.02980696
INFO:root:At the start of the epoch: mem (CPU python)=44071.00390625MB; mem (CPU total)=44087.39453125MB
INFO:root:[   16] Training loss: 0.66211045, Validation loss: 0.65235274, Gradient norm: 0.03188082
INFO:root:At the start of the epoch: mem (CPU python)=44071.45703125MB; mem (CPU total)=44075.59375MB
INFO:root:[   17] Training loss: 0.65996750, Validation loss: 0.64987562, Gradient norm: 0.03070130
INFO:root:At the start of the epoch: mem (CPU python)=44197.09765625MB; mem (CPU total)=44088.83203125MB
INFO:root:[   18] Training loss: 0.65819231, Validation loss: 0.64771181, Gradient norm: 0.03074721
INFO:root:At the start of the epoch: mem (CPU python)=44197.09765625MB; mem (CPU total)=44101.5234375MB
INFO:root:[   19] Training loss: 0.65642727, Validation loss: 0.64536439, Gradient norm: 0.03448410
INFO:root:At the start of the epoch: mem (CPU python)=44198.390625MB; mem (CPU total)=44215.05078125MB
INFO:root:[   20] Training loss: 0.65478144, Validation loss: 0.64347802, Gradient norm: 0.03292224
INFO:root:At the start of the epoch: mem (CPU python)=44311.484375MB; mem (CPU total)=44253.93359375MB
INFO:root:[   21] Training loss: 0.65341621, Validation loss: 0.64286068, Gradient norm: 0.03691019
INFO:root:At the start of the epoch: mem (CPU python)=44349.484375MB; mem (CPU total)=44291.88671875MB
INFO:root:[   22] Training loss: 0.65217595, Validation loss: 0.64176961, Gradient norm: 0.03980661
INFO:root:At the start of the epoch: mem (CPU python)=44361.55859375MB; mem (CPU total)=44304.3359375MB
INFO:root:[   23] Training loss: 0.65073418, Validation loss: 0.64071158, Gradient norm: 0.03807376
INFO:root:At the start of the epoch: mem (CPU python)=44361.55859375MB; mem (CPU total)=44342.41015625MB
INFO:root:[   24] Training loss: 0.64956180, Validation loss: 0.63906996, Gradient norm: 0.03843732
INFO:root:At the start of the epoch: mem (CPU python)=44363.86328125MB; mem (CPU total)=44380.55078125MB
INFO:root:[   25] Training loss: 0.64851748, Validation loss: 0.63730611, Gradient norm: 0.03962841
INFO:root:At the start of the epoch: mem (CPU python)=44476.95703125MB; mem (CPU total)=44493.6015625MB
INFO:root:[   26] Training loss: 0.64738583, Validation loss: 0.63640950, Gradient norm: 0.04433258
INFO:root:At the start of the epoch: mem (CPU python)=44477.1796875MB; mem (CPU total)=44456.6015625MB
INFO:root:[   27] Training loss: 0.64640698, Validation loss: 0.63427203, Gradient norm: 0.04037498
INFO:root:At the start of the epoch: mem (CPU python)=44527.5703125MB; mem (CPU total)=44519.9140625MB
INFO:root:[   28] Training loss: 0.64540625, Validation loss: 0.63490728, Gradient norm: 0.04302556
INFO:root:At the start of the epoch: mem (CPU python)=44591.24609375MB; mem (CPU total)=44611.53515625MB
INFO:root:[   29] Training loss: 0.64466675, Validation loss: 0.63417013, Gradient norm: 0.04011586
INFO:root:At the start of the epoch: mem (CPU python)=44654.33984375MB; mem (CPU total)=44674.41796875MB
INFO:root:[   30] Training loss: 0.64371307, Validation loss: 0.63214013, Gradient norm: 0.04148254
INFO:root:At the start of the epoch: mem (CPU python)=44654.59765625MB; mem (CPU total)=44612.1640625MB
INFO:root:[   31] Training loss: 0.64277835, Validation loss: 0.63184593, Gradient norm: 0.03944020
INFO:root:At the start of the epoch: mem (CPU python)=44702.2890625MB; mem (CPU total)=44675.46875MB
INFO:root:[   32] Training loss: 0.64224568, Validation loss: 0.63154059, Gradient norm: 0.05023394
INFO:root:At the start of the epoch: mem (CPU python)=44702.2890625MB; mem (CPU total)=44688.30859375MB
INFO:root:[   33] Training loss: 0.64136274, Validation loss: 0.63021927, Gradient norm: 0.04448497
INFO:root:At the start of the epoch: mem (CPU python)=44756.72265625MB; mem (CPU total)=44776.73046875MB
INFO:root:[   34] Training loss: 0.64069400, Validation loss: 0.63078859, Gradient norm: 0.04475910
INFO:root:At the start of the epoch: mem (CPU python)=44867.859375MB; mem (CPU total)=44839.7890625MB
INFO:root:[   35] Training loss: 0.64014683, Validation loss: 0.62825913, Gradient norm: 0.04674284
INFO:root:At the start of the epoch: mem (CPU python)=44867.859375MB; mem (CPU total)=44852.27734375MB
INFO:root:[   36] Training loss: 0.63937947, Validation loss: 0.62766327, Gradient norm: 0.04543597
INFO:root:At the start of the epoch: mem (CPU python)=44946.0078125MB; mem (CPU total)=44965.71875MB
INFO:root:[   37] Training loss: 0.63847048, Validation loss: 0.62795247, Gradient norm: 0.04749729
INFO:root:At the start of the epoch: mem (CPU python)=44984.10546875MB; mem (CPU total)=45003.64453125MB
INFO:root:[   38] Training loss: 0.63813455, Validation loss: 0.62689208, Gradient norm: 0.05022524
INFO:root:At the start of the epoch: mem (CPU python)=44984.48046875MB; mem (CPU total)=44917.21484375MB
INFO:root:[   39] Training loss: 0.63763009, Validation loss: 0.62650534, Gradient norm: 0.04776313
INFO:root:At the start of the epoch: mem (CPU python)=44985.29296875MB; mem (CPU total)=45005.00390625MB
INFO:root:[   40] Training loss: 0.63684733, Validation loss: 0.62537157, Gradient norm: 0.04313263
INFO:root:At the start of the epoch: mem (CPU python)=45073.390625MB; mem (CPU total)=45093.65625MB
INFO:root:[   41] Training loss: 0.63637473, Validation loss: 0.62499880, Gradient norm: 0.04879977
INFO:root:At the start of the epoch: mem (CPU python)=45073.61328125MB; mem (CPU total)=45056.71875MB
INFO:root:[   42] Training loss: 0.63588942, Validation loss: 0.62514334, Gradient norm: 0.04666245
INFO:root:At the start of the epoch: mem (CPU python)=45074.578125MB; mem (CPU total)=45094.5546875MB
INFO:root:[   43] Training loss: 0.63521839, Validation loss: 0.62408491, Gradient norm: 0.04508905
INFO:root:At the start of the epoch: mem (CPU python)=45087.67578125MB; mem (CPU total)=45107.53125MB
INFO:root:[   44] Training loss: 0.63487101, Validation loss: 0.62412708, Gradient norm: 0.04630081
INFO:root:At the start of the epoch: mem (CPU python)=45200.76953125MB; mem (CPU total)=45220.83984375MB
INFO:root:[   45] Training loss: 0.63447357, Validation loss: 0.62308256, Gradient norm: 0.04736199
INFO:root:At the start of the epoch: mem (CPU python)=45200.9921875MB; mem (CPU total)=45208.81640625MB
INFO:root:[   46] Training loss: 0.63394457, Validation loss: 0.62198764, Gradient norm: 0.05278497
INFO:root:At the start of the epoch: mem (CPU python)=45226.9609375MB; mem (CPU total)=45247.20703125MB
INFO:root:[   47] Training loss: 0.63352042, Validation loss: 0.62359523, Gradient norm: 0.04529204
INFO:root:At the start of the epoch: mem (CPU python)=45265.05859375MB; mem (CPU total)=45285.03125MB
INFO:root:[   48] Training loss: 0.63314586, Validation loss: 0.62198145, Gradient norm: 0.04791856
INFO:root:At the start of the epoch: mem (CPU python)=45303.15234375MB; mem (CPU total)=45322.94921875MB
INFO:root:[   49] Training loss: 0.63259036, Validation loss: 0.62185110, Gradient norm: 0.05056550
INFO:root:At the start of the epoch: mem (CPU python)=45366.24609375MB; mem (CPU total)=45386.390625MB
INFO:root:[   50] Training loss: 0.63238719, Validation loss: 0.62113796, Gradient norm: 0.05133756
INFO:root:At the start of the epoch: mem (CPU python)=45404.34375MB; mem (CPU total)=45424.31640625MB
INFO:root:[   51] Training loss: 0.63174354, Validation loss: 0.62193362, Gradient norm: 0.05129394
INFO:root:At the start of the epoch: mem (CPU python)=45417.4375MB; mem (CPU total)=45437.484375MB
INFO:root:[   52] Training loss: 0.63142151, Validation loss: 0.62060585, Gradient norm: 0.05419575
INFO:root:At the start of the epoch: mem (CPU python)=45530.53125MB; mem (CPU total)=45550.5546875MB
INFO:root:[   53] Training loss: 0.63112493, Validation loss: 0.62103046, Gradient norm: 0.04997818
INFO:root:At the start of the epoch: mem (CPU python)=45530.75390625MB; mem (CPU total)=45513.80859375MB
INFO:root:[   54] Training loss: 0.63058850, Validation loss: 0.61968098, Gradient norm: 0.05109165
INFO:root:At the start of the epoch: mem (CPU python)=45556.72265625MB; mem (CPU total)=45576.57421875MB
INFO:root:[   55] Training loss: 0.63027499, Validation loss: 0.61951690, Gradient norm: 0.04828365
INFO:root:At the start of the epoch: mem (CPU python)=45594.8203125MB; mem (CPU total)=45614.66796875MB
INFO:root:[   56] Training loss: 0.63000891, Validation loss: 0.61998031, Gradient norm: 0.05344982
INFO:root:At the start of the epoch: mem (CPU python)=45682.12109375MB; mem (CPU total)=45628.56640625MB
INFO:root:[   57] Training loss: 0.62958346, Validation loss: 0.61883515, Gradient norm: 0.05050905
INFO:root:At the start of the epoch: mem (CPU python)=45696.01171875MB; mem (CPU total)=45715.96484375MB
INFO:root:[   58] Training loss: 0.62926036, Validation loss: 0.61816983, Gradient norm: 0.05415600
INFO:root:At the start of the epoch: mem (CPU python)=45709.10546875MB; mem (CPU total)=45728.91015625MB
INFO:root:[   59] Training loss: 0.62895062, Validation loss: 0.61820164, Gradient norm: 0.05136119
INFO:root:At the start of the epoch: mem (CPU python)=45747.19921875MB; mem (CPU total)=45766.8828125MB
INFO:root:[   60] Training loss: 0.62841695, Validation loss: 0.61743355, Gradient norm: 0.04653012
INFO:root:At the start of the epoch: mem (CPU python)=45785.296875MB; mem (CPU total)=45805.36328125MB
INFO:root:[   61] Training loss: 0.62814828, Validation loss: 0.61777924, Gradient norm: 0.05501677
INFO:root:At the start of the epoch: mem (CPU python)=45823.390625MB; mem (CPU total)=45843.4296875MB
INFO:root:[   62] Training loss: 0.62801404, Validation loss: 0.61737779, Gradient norm: 0.05336797
INFO:root:At the start of the epoch: mem (CPU python)=45886.484375MB; mem (CPU total)=45906.7734375MB
INFO:root:[   63] Training loss: 0.62761022, Validation loss: 0.61720129, Gradient norm: 0.04779850
INFO:root:At the start of the epoch: mem (CPU python)=45886.94140625MB; mem (CPU total)=45820.3515625MB
INFO:root:[   64] Training loss: 0.62746330, Validation loss: 0.61703088, Gradient norm: 0.05845701
INFO:root:At the start of the epoch: mem (CPU python)=45962.6796875MB; mem (CPU total)=45983.10546875MB
INFO:root:[   65] Training loss: 0.62717237, Validation loss: 0.61678973, Gradient norm: 0.06008906
INFO:root:At the start of the epoch: mem (CPU python)=46000.7734375MB; mem (CPU total)=45921.58984375MB
INFO:root:[   66] Training loss: 0.62667085, Validation loss: 0.61723003, Gradient norm: 0.05238737
INFO:root:At the start of the epoch: mem (CPU python)=46000.7734375MB; mem (CPU total)=46009.2578125MB
INFO:root:[   67] Training loss: 0.62632267, Validation loss: 0.61639272, Gradient norm: 0.05041989
INFO:root:At the start of the epoch: mem (CPU python)=46075.92578125MB; mem (CPU total)=46022.921875MB
INFO:root:[   68] Training loss: 0.62631721, Validation loss: 0.61532195, Gradient norm: 0.05973029
INFO:root:At the start of the epoch: mem (CPU python)=46075.92578125MB; mem (CPU total)=46060.59765625MB
INFO:root:[   69] Training loss: 0.62605294, Validation loss: 0.61576592, Gradient norm: 0.05120230
INFO:root:At the start of the epoch: mem (CPU python)=46078.15234375MB; mem (CPU total)=46098.6796875MB
INFO:root:[   70] Training loss: 0.62564985, Validation loss: 0.61596543, Gradient norm: 0.05091612
INFO:root:At the start of the epoch: mem (CPU python)=46216.25MB; mem (CPU total)=46237.1953125MB
INFO:root:[   71] Training loss: 0.62553937, Validation loss: 0.61587274, Gradient norm: 0.05338193
INFO:root:At the start of the epoch: mem (CPU python)=46216.47265625MB; mem (CPU total)=46175.86328125MB
INFO:root:[   72] Training loss: 0.62501907, Validation loss: 0.61420176, Gradient norm: 0.05544748
INFO:root:At the start of the epoch: mem (CPU python)=46217.44140625MB; mem (CPU total)=46238.37109375MB
INFO:root:[   73] Training loss: 0.62507942, Validation loss: 0.61547621, Gradient norm: 0.06316868
INFO:root:At the start of the epoch: mem (CPU python)=46255.53515625MB; mem (CPU total)=46276.984375MB
INFO:root:[   74] Training loss: 0.62480735, Validation loss: 0.61430745, Gradient norm: 0.05577292
INFO:root:At the start of the epoch: mem (CPU python)=46256.06640625MB; mem (CPU total)=46264.609375MB
INFO:root:[   75] Training loss: 0.62435920, Validation loss: 0.61442806, Gradient norm: 0.05097023
INFO:root:At the start of the epoch: mem (CPU python)=46356.7265625MB; mem (CPU total)=46377.89453125MB
INFO:root:[   76] Training loss: 0.62424484, Validation loss: 0.61379749, Gradient norm: 0.05964033
INFO:root:At the start of the epoch: mem (CPU python)=46394.8203125MB; mem (CPU total)=46416.3828125MB
INFO:root:[   77] Training loss: 0.62404552, Validation loss: 0.61442655, Gradient norm: 0.06010277
INFO:root:At the start of the epoch: mem (CPU python)=46407.91796875MB; mem (CPU total)=46429.61328125MB
INFO:root:[   78] Training loss: 0.62378520, Validation loss: 0.61376595, Gradient norm: 0.05829125
INFO:root:At the start of the epoch: mem (CPU python)=46496.015625MB; mem (CPU total)=46517.4609375MB
INFO:root:[   79] Training loss: 0.62341639, Validation loss: 0.61457407, Gradient norm: 0.05346699
INFO:root:At the start of the epoch: mem (CPU python)=46534.109375MB; mem (CPU total)=46555.83984375MB
INFO:root:[   80] Training loss: 0.62328049, Validation loss: 0.61325594, Gradient norm: 0.05820894
INFO:root:At the start of the epoch: mem (CPU python)=46534.52734375MB; mem (CPU total)=46543.8203125MB
INFO:root:[   81] Training loss: 0.62303707, Validation loss: 0.61292171, Gradient norm: 0.06085943
INFO:root:At the start of the epoch: mem (CPU python)=46560.30078125MB; mem (CPU total)=46582.109375MB
INFO:root:[   82] Training loss: 0.62281825, Validation loss: 0.61279484, Gradient norm: 0.05332192
INFO:root:At the start of the epoch: mem (CPU python)=46620.42578125MB; mem (CPU total)=46619.890625MB
INFO:root:[   83] Training loss: 0.62270523, Validation loss: 0.61198777, Gradient norm: 0.05580540
INFO:root:At the start of the epoch: mem (CPU python)=46661.48828125MB; mem (CPU total)=46683.51171875MB
INFO:root:[   84] Training loss: 0.62241063, Validation loss: 0.61211570, Gradient norm: 0.05667512
INFO:root:At the start of the epoch: mem (CPU python)=46722.15625MB; mem (CPU total)=46721.34765625MB
INFO:root:[   85] Training loss: 0.62227462, Validation loss: 0.61257565, Gradient norm: 0.05243221
INFO:root:At the start of the epoch: mem (CPU python)=46762.68359375MB; mem (CPU total)=46784.12890625MB
INFO:root:[   86] Training loss: 0.62200959, Validation loss: 0.61133489, Gradient norm: 0.06352968
INFO:root:At the start of the epoch: mem (CPU python)=46800.77734375MB; mem (CPU total)=46822.7578125MB
INFO:root:[   87] Training loss: 0.62161071, Validation loss: 0.61272853, Gradient norm: 0.06076491
INFO:root:At the start of the epoch: mem (CPU python)=46838.59375MB; mem (CPU total)=46786.234375MB
INFO:root:[   88] Training loss: 0.62138568, Validation loss: 0.61155187, Gradient norm: 0.05586518
INFO:root:At the start of the epoch: mem (CPU python)=46901.96875MB; mem (CPU total)=46924.24609375MB
INFO:root:[   89] Training loss: 0.62124948, Validation loss: 0.61234999, Gradient norm: 0.05455570
INFO:root:At the start of the epoch: mem (CPU python)=46940.0625MB; mem (CPU total)=46962.328125MB
INFO:root:[   90] Training loss: 0.62140291, Validation loss: 0.61133306, Gradient norm: 0.05804008
INFO:root:At the start of the epoch: mem (CPU python)=46940.515625MB; mem (CPU total)=46925.61328125MB
INFO:root:[   91] Training loss: 0.62102722, Validation loss: 0.61111928, Gradient norm: 0.05897865
INFO:root:At the start of the epoch: mem (CPU python)=46940.515625MB; mem (CPU total)=46864.125MB
INFO:root:[   92] Training loss: 0.62073640, Validation loss: 0.61141489, Gradient norm: 0.05605416
INFO:root:At the start of the epoch: mem (CPU python)=47029.34765625MB; mem (CPU total)=47052.08203125MB
INFO:root:[   93] Training loss: 0.62046494, Validation loss: 0.61147628, Gradient norm: 0.05395037
INFO:root:At the start of the epoch: mem (CPU python)=47042.4453125MB; mem (CPU total)=47064.97265625MB
INFO:root:[   94] Training loss: 0.62056679, Validation loss: 0.61116738, Gradient norm: 0.05592360
INFO:root:At the start of the epoch: mem (CPU python)=47105.54296875MB; mem (CPU total)=47128.25390625MB
INFO:root:[   95] Training loss: 0.62037687, Validation loss: 0.61133897, Gradient norm: 0.06392969
INFO:root:At the start of the epoch: mem (CPU python)=47143.640625MB; mem (CPU total)=47166.9453125MB
INFO:root:[   96] Training loss: 0.62013163, Validation loss: 0.60989054, Gradient norm: 0.06387895
INFO:root:At the start of the epoch: mem (CPU python)=47144.08984375MB; mem (CPU total)=47154.05078125MB
INFO:root:[   97] Training loss: 0.61975279, Validation loss: 0.61125903, Gradient norm: 0.05398170
INFO:root:At the start of the epoch: mem (CPU python)=47194.828125MB; mem (CPU total)=47217.35546875MB
INFO:root:[   98] Training loss: 0.61984768, Validation loss: 0.61013062, Gradient norm: 0.05735006
INFO:root:At the start of the epoch: mem (CPU python)=47232.92578125MB; mem (CPU total)=47255.04296875MB
INFO:root:[   99] Training loss: 0.61954614, Validation loss: 0.60998781, Gradient norm: 0.06225507
INFO:root:At the start of the epoch: mem (CPU python)=47295.7734375MB; mem (CPU total)=47244.234375MB
INFO:root:[  100] Training loss: 0.61918244, Validation loss: 0.60995884, Gradient norm: 0.05649256
INFO:root:At the start of the epoch: mem (CPU python)=47295.7734375MB; mem (CPU total)=47256.19140625MB
INFO:root:[  101] Training loss: 0.61912379, Validation loss: 0.61056674, Gradient norm: 0.05245469
INFO:root:At the start of the epoch: mem (CPU python)=47372.1796875MB; mem (CPU total)=47295.875MB
INFO:root:[  102] Training loss: 0.61913028, Validation loss: 0.60994214, Gradient norm: 0.06442804
INFO:root:At the start of the epoch: mem (CPU python)=47410.3046875MB; mem (CPU total)=47432.65234375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  103] Training loss: 0.61889115, Validation loss: 0.61012019, Gradient norm: 0.05824405
INFO:root:At the start of the epoch: mem (CPU python)=47448.40234375MB; mem (CPU total)=47471.06640625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  104] Training loss: 0.61804238, Validation loss: 0.60873494, Gradient norm: 0.05030841
INFO:root:At the start of the epoch: mem (CPU python)=47461.5MB; mem (CPU total)=47484.49609375MB
INFO:root:[  105] Training loss: 0.61738683, Validation loss: 0.60854158, Gradient norm: 0.04602385
INFO:root:At the start of the epoch: mem (CPU python)=47522.4921875MB; mem (CPU total)=47472.71875MB
INFO:root:[  106] Training loss: 0.61718676, Validation loss: 0.60885381, Gradient norm: 0.05313339
INFO:root:At the start of the epoch: mem (CPU python)=47522.4921875MB; mem (CPU total)=47461.94140625MB
INFO:root:[  107] Training loss: 0.61722301, Validation loss: 0.60906894, Gradient norm: 0.04816976
INFO:root:At the start of the epoch: mem (CPU python)=47550.78125MB; mem (CPU total)=47573.71484375MB
INFO:root:[  108] Training loss: 0.61712883, Validation loss: 0.60810614, Gradient norm: 0.04907585
INFO:root:At the start of the epoch: mem (CPU python)=47588.87890625MB; mem (CPU total)=47612.05859375MB
INFO:root:[  109] Training loss: 0.61706474, Validation loss: 0.60882900, Gradient norm: 0.04920452
INFO:root:At the start of the epoch: mem (CPU python)=47701.71484375MB; mem (CPU total)=47576.1015625MB
INFO:root:[  110] Training loss: 0.61713902, Validation loss: 0.60851518, Gradient norm: 0.04969513
INFO:root:At the start of the epoch: mem (CPU python)=47740.0703125MB; mem (CPU total)=47763.2890625MB
INFO:root:[  111] Training loss: 0.61691110, Validation loss: 0.60875592, Gradient norm: 0.04866848
INFO:root:At the start of the epoch: mem (CPU python)=47753.1328125MB; mem (CPU total)=47702.67578125MB
INFO:root:[  112] Training loss: 0.61712526, Validation loss: 0.60783101, Gradient norm: 0.04955693
INFO:root:At the start of the epoch: mem (CPU python)=47763.91015625MB; mem (CPU total)=47739.828125MB
INFO:root:[  113] Training loss: 0.61691253, Validation loss: 0.60750582, Gradient norm: 0.05081276
INFO:root:At the start of the epoch: mem (CPU python)=47804.3515625MB; mem (CPU total)=47826.98828125MB
INFO:root:[  114] Training loss: 0.61681660, Validation loss: 0.60833257, Gradient norm: 0.04669021
INFO:root:At the start of the epoch: mem (CPU python)=47842.44921875MB; mem (CPU total)=47864.87890625MB
INFO:root:[  115] Training loss: 0.61691892, Validation loss: 0.60757287, Gradient norm: 0.05330024
INFO:root:At the start of the epoch: mem (CPU python)=47843.05078125MB; mem (CPU total)=47827.890625MB
INFO:root:[  116] Training loss: 0.61680379, Validation loss: 0.60830754, Gradient norm: 0.05043880
INFO:root:At the start of the epoch: mem (CPU python)=47943.640625MB; mem (CPU total)=47965.71484375MB
INFO:root:[  117] Training loss: 0.61677564, Validation loss: 0.60751230, Gradient norm: 0.04940362
INFO:root:At the start of the epoch: mem (CPU python)=47943.74609375MB; mem (CPU total)=47953.6953125MB
INFO:root:[  118] Training loss: 0.61696757, Validation loss: 0.60816536, Gradient norm: 0.05008285
INFO:root:At the start of the epoch: mem (CPU python)=47944.8359375MB; mem (CPU total)=47966.92578125MB
INFO:root:[  119] Training loss: 0.61663333, Validation loss: 0.60864641, Gradient norm: 0.04940987
INFO:root:At the start of the epoch: mem (CPU python)=48032.9296875MB; mem (CPU total)=48056.1171875MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  120] Training loss: 0.61662218, Validation loss: 0.60798720, Gradient norm: 0.04938752
INFO:root:At the start of the epoch: mem (CPU python)=48071.0234375MB; mem (CPU total)=48093.69921875MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  121] Training loss: 0.61639596, Validation loss: 0.60802011, Gradient norm: 0.04582110
INFO:root:At the start of the epoch: mem (CPU python)=48109.12109375MB; mem (CPU total)=48131.86328125MB
INFO:root:[  122] Training loss: 0.61621936, Validation loss: 0.60828897, Gradient norm: 0.04676996
INFO:root:At the start of the epoch: mem (CPU python)=48196.390625MB; mem (CPU total)=48195.1484375MB
INFO:root:EP 122: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=48196.390625MB; mem (CPU total)=48158.171875MB
INFO:root:Training the model took 11711.916s.
INFO:root:Emptying the cuda cache took 0.029s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.85025
INFO:root:EnergyScoreTrain: 0.59853
INFO:root:CRPSTrain: 0.46642
INFO:root:Gaussian NLLTrain: 1.20423
INFO:root:CoverageTrain: 0.9485
INFO:root:IntervalWidthTrain: 3.28718
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.86446
INFO:root:EnergyScoreValidation: 0.60846
INFO:root:CRPSValidation: 0.47482
INFO:root:Gaussian NLLValidation: 1.22274
INFO:root:CoverageValidation: 0.94361
INFO:root:IntervalWidthValidation: 3.28648
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86655
INFO:root:EnergyScoreTest: 0.6099
INFO:root:CRPSTest: 0.47617
INFO:root:Gaussian NLLTest: 1.22551
INFO:root:CoverageTest: 0.94341
INFO:root:IntervalWidthTest: 3.2915
INFO:root:After validation: mem (CPU python)=48196.390625MB; mem (CPU total)=48163.79296875MB
INFO:root:###9 out of 9 training parameter combinations ###
INFO:root:Training parameters: {'seed': 123456789, 'model': 'FNO', 'uncertainty_quantification': 'scoring-rule-reparam', 'batch_size': 64, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.001, 'lr_schedule': 'step', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 100, 'weight_decay': 0, 'dropout': 0.1, 'fourier_dropout': None, 'hidden_channels': 20, 'projection_channels': 128, 'lifting_channels': 128, 'n_modes': (10, 12), 'n_samples': 20}
INFO:root:After creating the dataloaders: mem (CPU python)=48196.390625MB; mem (CPU total)=48102.46484375MB
INFO:root:NumberParameters: 234406
INFO:root:GPU memory allocated: 54525952
INFO:root:After setting up the model: mem (CPU python)=48196.390625MB; mem (CPU total)=48102.46484375MB
INFO:root:Training starts now.
INFO:root:At the start of the epoch: mem (CPU python)=48196.390625MB; mem (CPU total)=48102.39453125MB
INFO:root:[    1] Training loss: 0.72679456, Validation loss: 0.72054301, Gradient norm: 0.03117632
INFO:root:At the start of the epoch: mem (CPU python)=48266.75390625MB; mem (CPU total)=48290.12109375MB
INFO:root:[    2] Training loss: 0.71982836, Validation loss: 0.71817216, Gradient norm: 0.00592149
INFO:root:At the start of the epoch: mem (CPU python)=48266.97265625MB; mem (CPU total)=48202.828125MB
INFO:root:[    3] Training loss: 0.71709750, Validation loss: 0.71241482, Gradient norm: 0.00977965
INFO:root:At the start of the epoch: mem (CPU python)=48417.9453125MB; mem (CPU total)=48441.49609375MB
INFO:root:[    4] Training loss: 0.71042147, Validation loss: 0.70432076, Gradient norm: 0.01993928
INFO:root:At the start of the epoch: mem (CPU python)=48456.0390625MB; mem (CPU total)=48479.27734375MB
INFO:root:[    5] Training loss: 0.70369679, Validation loss: 0.69694957, Gradient norm: 0.02233871
INFO:root:At the start of the epoch: mem (CPU python)=48456.31640625MB; mem (CPU total)=48392.08984375MB
INFO:root:[    6] Training loss: 0.69792524, Validation loss: 0.69125327, Gradient norm: 0.02659210
INFO:root:At the start of the epoch: mem (CPU python)=48457.23046875MB; mem (CPU total)=48480.41796875MB
INFO:root:[    7] Training loss: 0.69270503, Validation loss: 0.68486505, Gradient norm: 0.02642422
INFO:root:At the start of the epoch: mem (CPU python)=48495.32421875MB; mem (CPU total)=48518.5625MB
INFO:root:[    8] Training loss: 0.68732675, Validation loss: 0.67847496, Gradient norm: 0.02618022
INFO:root:At the start of the epoch: mem (CPU python)=48533.421875MB; mem (CPU total)=48556.65625MB
INFO:root:[    9] Training loss: 0.68216840, Validation loss: 0.67262179, Gradient norm: 0.02822539
INFO:root:At the start of the epoch: mem (CPU python)=48533.64453125MB; mem (CPU total)=48520.26953125MB
INFO:root:[   10] Training loss: 0.67791950, Validation loss: 0.66908399, Gradient norm: 0.02738873
INFO:root:At the start of the epoch: mem (CPU python)=48559.61328125MB; mem (CPU total)=48583.63671875MB
INFO:root:[   11] Training loss: 0.67406787, Validation loss: 0.66469087, Gradient norm: 0.02748477
INFO:root:At the start of the epoch: mem (CPU python)=48622.70703125MB; mem (CPU total)=48646.4765625MB
INFO:root:[   12] Training loss: 0.67080052, Validation loss: 0.66092230, Gradient norm: 0.03045792
INFO:root:At the start of the epoch: mem (CPU python)=48685.80078125MB; mem (CPU total)=48709.63671875MB
INFO:root:[   13] Training loss: 0.66800213, Validation loss: 0.65828891, Gradient norm: 0.02769165
INFO:root:At the start of the epoch: mem (CPU python)=48723.8984375MB; mem (CPU total)=48748.01171875MB
INFO:root:[   14] Training loss: 0.66565035, Validation loss: 0.65469932, Gradient norm: 0.02940387
INFO:root:At the start of the epoch: mem (CPU python)=48811.984375MB; mem (CPU total)=48761.66015625MB
INFO:root:[   15] Training loss: 0.66328410, Validation loss: 0.65224572, Gradient norm: 0.03149073
INFO:root:At the start of the epoch: mem (CPU python)=48825.0859375MB; mem (CPU total)=48849.51953125MB
INFO:root:[   16] Training loss: 0.66133606, Validation loss: 0.65072802, Gradient norm: 0.03399356
INFO:root:At the start of the epoch: mem (CPU python)=48825.54296875MB; mem (CPU total)=48812.6484375MB
INFO:root:[   17] Training loss: 0.65952374, Validation loss: 0.64948611, Gradient norm: 0.03266986
INFO:root:At the start of the epoch: mem (CPU python)=48826.40625MB; mem (CPU total)=48850.7421875MB
INFO:root:[   18] Training loss: 0.65793420, Validation loss: 0.64772467, Gradient norm: 0.03702987
INFO:root:At the start of the epoch: mem (CPU python)=48914.32421875MB; mem (CPU total)=48864.39453125MB
INFO:root:[   19] Training loss: 0.65641352, Validation loss: 0.64582757, Gradient norm: 0.03679901
INFO:root:At the start of the epoch: mem (CPU python)=48952.47265625MB; mem (CPU total)=48977.24609375MB
INFO:root:[   20] Training loss: 0.65507047, Validation loss: 0.64455374, Gradient norm: 0.03351663
INFO:root:At the start of the epoch: mem (CPU python)=48990.56640625MB; mem (CPU total)=49014.8984375MB
INFO:root:[   21] Training loss: 0.65361476, Validation loss: 0.64330435, Gradient norm: 0.03739829
INFO:root:At the start of the epoch: mem (CPU python)=48990.84375MB; mem (CPU total)=49003.12890625MB
INFO:root:[   22] Training loss: 0.65241601, Validation loss: 0.64173688, Gradient norm: 0.04027459
INFO:root:At the start of the epoch: mem (CPU python)=49016.75390625MB; mem (CPU total)=49041.4765625MB
INFO:root:[   23] Training loss: 0.65112875, Validation loss: 0.64091201, Gradient norm: 0.04049884
INFO:root:At the start of the epoch: mem (CPU python)=49017.17578125MB; mem (CPU total)=49029.8125MB
INFO:root:[   24] Training loss: 0.65005100, Validation loss: 0.63986419, Gradient norm: 0.04396862
INFO:root:At the start of the epoch: mem (CPU python)=49092.9453125MB; mem (CPU total)=49118.13671875MB
INFO:root:[   25] Training loss: 0.64899377, Validation loss: 0.63808807, Gradient norm: 0.04073677
INFO:root:At the start of the epoch: mem (CPU python)=49206.04296875MB; mem (CPU total)=49231.41796875MB
INFO:root:[   26] Training loss: 0.64817068, Validation loss: 0.63788660, Gradient norm: 0.04629097
INFO:root:At the start of the epoch: mem (CPU python)=49244.140625MB; mem (CPU total)=49269.53125MB
INFO:root:[   27] Training loss: 0.64703915, Validation loss: 0.63535467, Gradient norm: 0.04468150
INFO:root:At the start of the epoch: mem (CPU python)=49282.234375MB; mem (CPU total)=49307.21484375MB
INFO:root:[   28] Training loss: 0.64601086, Validation loss: 0.63584203, Gradient norm: 0.04388335
INFO:root:At the start of the epoch: mem (CPU python)=49320.328125MB; mem (CPU total)=49345.5859375MB
INFO:root:[   29] Training loss: 0.64509144, Validation loss: 0.63450732, Gradient norm: 0.03991471
INFO:root:At the start of the epoch: mem (CPU python)=49320.7265625MB; mem (CPU total)=49334.01953125MB
INFO:root:[   30] Training loss: 0.64421787, Validation loss: 0.63293015, Gradient norm: 0.04212645
INFO:root:At the start of the epoch: mem (CPU python)=49346.51953125MB; mem (CPU total)=49371.99609375MB
INFO:root:[   31] Training loss: 0.64337572, Validation loss: 0.63311471, Gradient norm: 0.04485411
INFO:root:At the start of the epoch: mem (CPU python)=49459.61328125MB; mem (CPU total)=49484.79296875MB
INFO:root:[   32] Training loss: 0.64257490, Validation loss: 0.63161810, Gradient norm: 0.04270421
INFO:root:At the start of the epoch: mem (CPU python)=49497.70703125MB; mem (CPU total)=49523.2109375MB
INFO:root:[   33] Training loss: 0.64183806, Validation loss: 0.63080681, Gradient norm: 0.04444736
INFO:root:At the start of the epoch: mem (CPU python)=49497.9765625MB; mem (CPU total)=49436.96484375MB
INFO:root:[   34] Training loss: 0.64097807, Validation loss: 0.62995111, Gradient norm: 0.04213294
INFO:root:At the start of the epoch: mem (CPU python)=49573.90234375MB; mem (CPU total)=49599.32421875MB
INFO:root:[   35] Training loss: 0.64042797, Validation loss: 0.62960917, Gradient norm: 0.04371797
INFO:root:At the start of the epoch: mem (CPU python)=49611.99609375MB; mem (CPU total)=49637.26171875MB
INFO:root:[   36] Training loss: 0.63975944, Validation loss: 0.62940892, Gradient norm: 0.04495172
INFO:root:At the start of the epoch: mem (CPU python)=49612.24609375MB; mem (CPU total)=49500.6796875MB
INFO:root:[   37] Training loss: 0.63913233, Validation loss: 0.62789360, Gradient norm: 0.04463918
INFO:root:At the start of the epoch: mem (CPU python)=49612.24609375MB; mem (CPU total)=49613.5078125MB
INFO:root:[   38] Training loss: 0.63839774, Validation loss: 0.62799273, Gradient norm: 0.04614985
INFO:root:At the start of the epoch: mem (CPU python)=49676.12109375MB; mem (CPU total)=49627.6796875MB
INFO:root:[   39] Training loss: 0.63783063, Validation loss: 0.62809996, Gradient norm: 0.04312204
INFO:root:At the start of the epoch: mem (CPU python)=49676.12109375MB; mem (CPU total)=49689.64453125MB
INFO:root:[   40] Training loss: 0.63759308, Validation loss: 0.62670774, Gradient norm: 0.05111590
INFO:root:At the start of the epoch: mem (CPU python)=49752.47265625MB; mem (CPU total)=49777.75390625MB
INFO:root:[   41] Training loss: 0.63674343, Validation loss: 0.62662353, Gradient norm: 0.04519046
INFO:root:At the start of the epoch: mem (CPU python)=49752.734375MB; mem (CPU total)=49740.5546875MB
INFO:root:[   42] Training loss: 0.63626190, Validation loss: 0.62544799, Gradient norm: 0.05403117
INFO:root:At the start of the epoch: mem (CPU python)=49878.66015625MB; mem (CPU total)=49904.12109375MB
INFO:root:[   43] Training loss: 0.63566046, Validation loss: 0.62504743, Gradient norm: 0.04647942
INFO:root:At the start of the epoch: mem (CPU python)=49916.7578125MB; mem (CPU total)=49942.546875MB
INFO:root:[   44] Training loss: 0.63522479, Validation loss: 0.62427546, Gradient norm: 0.04573902
INFO:root:At the start of the epoch: mem (CPU python)=49929.85546875MB; mem (CPU total)=49955.41796875MB
INFO:root:[   45] Training loss: 0.63469092, Validation loss: 0.62392282, Gradient norm: 0.04681137
INFO:root:At the start of the epoch: mem (CPU python)=49967.94921875MB; mem (CPU total)=49993.93359375MB
INFO:root:[   46] Training loss: 0.63413629, Validation loss: 0.62484347, Gradient norm: 0.04829410
INFO:root:At the start of the epoch: mem (CPU python)=50006.04296875MB; mem (CPU total)=50031.94921875MB
INFO:root:[   47] Training loss: 0.63374352, Validation loss: 0.62397306, Gradient norm: 0.05207886
INFO:root:At the start of the epoch: mem (CPU python)=50044.140625MB; mem (CPU total)=50069.6328125MB
INFO:root:[   48] Training loss: 0.63330682, Validation loss: 0.62315943, Gradient norm: 0.04395603
INFO:root:At the start of the epoch: mem (CPU python)=50044.4453125MB; mem (CPU total)=50057.84375MB
INFO:root:[   49] Training loss: 0.63298151, Validation loss: 0.62232527, Gradient norm: 0.05297781
INFO:root:At the start of the epoch: mem (CPU python)=50070.328125MB; mem (CPU total)=50095.796875MB
INFO:root:[   50] Training loss: 0.63250813, Validation loss: 0.62307152, Gradient norm: 0.05280536
INFO:root:At the start of the epoch: mem (CPU python)=50108.42578125MB; mem (CPU total)=50134.47265625MB
INFO:root:[   51] Training loss: 0.63198463, Validation loss: 0.62125584, Gradient norm: 0.05447702
INFO:root:At the start of the epoch: mem (CPU python)=50171.5234375MB; mem (CPU total)=50198.109375MB
INFO:root:[   52] Training loss: 0.63158966, Validation loss: 0.62237109, Gradient norm: 0.05175904
INFO:root:At the start of the epoch: mem (CPU python)=50171.74609375MB; mem (CPU total)=50186.08203125MB
INFO:root:[   53] Training loss: 0.63119940, Validation loss: 0.62135243, Gradient norm: 0.04733693
INFO:root:At the start of the epoch: mem (CPU python)=50297.71484375MB; mem (CPU total)=50324.62890625MB
INFO:root:[   54] Training loss: 0.63080912, Validation loss: 0.62101002, Gradient norm: 0.04713594
INFO:root:At the start of the epoch: mem (CPU python)=50298.30078125MB; mem (CPU total)=50287.61328125MB
INFO:root:[   55] Training loss: 0.63032570, Validation loss: 0.62033507, Gradient norm: 0.04780393
INFO:root:At the start of the epoch: mem (CPU python)=50423.90234375MB; mem (CPU total)=50376.5MB
INFO:root:[   56] Training loss: 0.63006352, Validation loss: 0.62006253, Gradient norm: 0.05127778
INFO:root:At the start of the epoch: mem (CPU python)=50423.90234375MB; mem (CPU total)=50339.30078125MB
INFO:root:[   57] Training loss: 0.62985464, Validation loss: 0.62034165, Gradient norm: 0.05057670
INFO:root:At the start of the epoch: mem (CPU python)=50423.90234375MB; mem (CPU total)=50427.44921875MB
INFO:root:[   58] Training loss: 0.62923441, Validation loss: 0.61868283, Gradient norm: 0.04991906
INFO:root:At the start of the epoch: mem (CPU python)=50438.19140625MB; mem (CPU total)=50465.3671875MB
INFO:root:[   59] Training loss: 0.62900559, Validation loss: 0.61824730, Gradient norm: 0.04732957
INFO:root:At the start of the epoch: mem (CPU python)=50438.53125MB; mem (CPU total)=50452.921875MB
INFO:root:[   60] Training loss: 0.62877579, Validation loss: 0.61792729, Gradient norm: 0.05262285
INFO:root:At the start of the epoch: mem (CPU python)=50464.3828125MB; mem (CPU total)=50491.07421875MB
INFO:root:[   61] Training loss: 0.62844439, Validation loss: 0.61855830, Gradient norm: 0.04655543
INFO:root:At the start of the epoch: mem (CPU python)=50502.4765625MB; mem (CPU total)=50529.2265625MB
INFO:root:[   62] Training loss: 0.62800874, Validation loss: 0.61762922, Gradient norm: 0.04690541
INFO:root:At the start of the epoch: mem (CPU python)=50590.56640625MB; mem (CPU total)=50543.19140625MB
INFO:root:[   63] Training loss: 0.62779352, Validation loss: 0.61785795, Gradient norm: 0.05161508
INFO:root:At the start of the epoch: mem (CPU python)=50653.6640625MB; mem (CPU total)=50681.51953125MB
INFO:root:[   64] Training loss: 0.62747201, Validation loss: 0.61752929, Gradient norm: 0.05562946
INFO:root:At the start of the epoch: mem (CPU python)=50691.76171875MB; mem (CPU total)=50719.13671875MB
INFO:root:[   65] Training loss: 0.62717634, Validation loss: 0.61738953, Gradient norm: 0.05593518
INFO:root:At the start of the epoch: mem (CPU python)=50704.85546875MB; mem (CPU total)=50732.5625MB
INFO:root:[   66] Training loss: 0.62682911, Validation loss: 0.61723388, Gradient norm: 0.05092309
INFO:root:At the start of the epoch: mem (CPU python)=50717.94921875MB; mem (CPU total)=50745.71875MB
INFO:root:[   67] Training loss: 0.62663271, Validation loss: 0.61716048, Gradient norm: 0.05395585
INFO:root:At the start of the epoch: mem (CPU python)=50781.05078125MB; mem (CPU total)=50808.7578125MB
INFO:root:[   68] Training loss: 0.62633391, Validation loss: 0.61616799, Gradient norm: 0.05270457
INFO:root:At the start of the epoch: mem (CPU python)=50781.4140625MB; mem (CPU total)=50722.296875MB
INFO:root:[   69] Training loss: 0.62585861, Validation loss: 0.61548938, Gradient norm: 0.05066454
INFO:root:At the start of the epoch: mem (CPU python)=50830.5390625MB; mem (CPU total)=50835.40234375MB
INFO:root:[   70] Training loss: 0.62578043, Validation loss: 0.61626827, Gradient norm: 0.05403809
INFO:root:At the start of the epoch: mem (CPU python)=50870.3359375MB; mem (CPU total)=50898.15234375MB
INFO:root:[   71] Training loss: 0.62538305, Validation loss: 0.61714290, Gradient norm: 0.05626900
INFO:root:At the start of the epoch: mem (CPU python)=50908.4296875MB; mem (CPU total)=50936.78515625MB
INFO:root:[   72] Training loss: 0.62524456, Validation loss: 0.61534015, Gradient norm: 0.05236081
INFO:root:At the start of the epoch: mem (CPU python)=50946.5234375MB; mem (CPU total)=50974.703125MB
INFO:root:[   73] Training loss: 0.62484646, Validation loss: 0.61568319, Gradient norm: 0.05246921
INFO:root:At the start of the epoch: mem (CPU python)=51034.4453125MB; mem (CPU total)=50988.94921875MB
INFO:root:[   74] Training loss: 0.62469401, Validation loss: 0.61554771, Gradient norm: 0.05445700
INFO:root:At the start of the epoch: mem (CPU python)=51072.71875MB; mem (CPU total)=51100.93359375MB
INFO:root:[   75] Training loss: 0.62441533, Validation loss: 0.61367731, Gradient norm: 0.05303000
INFO:root:At the start of the epoch: mem (CPU python)=51073.4765625MB; mem (CPU total)=51063.9609375MB
INFO:root:[   76] Training loss: 0.62407827, Validation loss: 0.61472698, Gradient norm: 0.05635283
INFO:root:At the start of the epoch: mem (CPU python)=51073.90625MB; mem (CPU total)=51102.09375MB
INFO:root:[   77] Training loss: 0.62385091, Validation loss: 0.61394835, Gradient norm: 0.05499970
INFO:root:At the start of the epoch: mem (CPU python)=51162.00390625MB; mem (CPU total)=51190.41015625MB
INFO:root:[   78] Training loss: 0.62336045, Validation loss: 0.61356020, Gradient norm: 0.05321637
INFO:root:At the start of the epoch: mem (CPU python)=51200.09765625MB; mem (CPU total)=51228.86328125MB
INFO:root:[   79] Training loss: 0.62326241, Validation loss: 0.61330076, Gradient norm: 0.05203651
INFO:root:At the start of the epoch: mem (CPU python)=51238.19140625MB; mem (CPU total)=51267.03125MB
INFO:root:[   80] Training loss: 0.62300825, Validation loss: 0.61354955, Gradient norm: 0.05192302
INFO:root:At the start of the epoch: mem (CPU python)=51251.28515625MB; mem (CPU total)=51280.171875MB
INFO:root:[   81] Training loss: 0.62287198, Validation loss: 0.61307151, Gradient norm: 0.05098017
INFO:root:At the start of the epoch: mem (CPU python)=51314.3828125MB; mem (CPU total)=51343.79296875MB
INFO:root:[   82] Training loss: 0.62232099, Validation loss: 0.61351307, Gradient norm: 0.05055603
INFO:root:At the start of the epoch: mem (CPU python)=51377.4765625MB; mem (CPU total)=51406.58984375MB
INFO:root:[   83] Training loss: 0.62232174, Validation loss: 0.61322646, Gradient norm: 0.06008015
INFO:root:At the start of the epoch: mem (CPU python)=51415.57421875MB; mem (CPU total)=51444.7265625MB
INFO:root:[   84] Training loss: 0.62209274, Validation loss: 0.61402833, Gradient norm: 0.05196101
INFO:root:At the start of the epoch: mem (CPU python)=51453.671875MB; mem (CPU total)=51482.82421875MB
INFO:root:[   85] Training loss: 0.62190540, Validation loss: 0.61191446, Gradient norm: 0.05286849
INFO:root:At the start of the epoch: mem (CPU python)=51454.125MB; mem (CPU total)=51421.08203125MB
INFO:root:[   86] Training loss: 0.62180501, Validation loss: 0.61409875, Gradient norm: 0.05775969
INFO:root:At the start of the epoch: mem (CPU python)=51454.125MB; mem (CPU total)=51459.2265625MB
INFO:root:[   87] Training loss: 0.62164935, Validation loss: 0.61208412, Gradient norm: 0.05519209
INFO:root:At the start of the epoch: mem (CPU python)=51542.95703125MB; mem (CPU total)=51572.2265625MB
INFO:root:[   88] Training loss: 0.62137501, Validation loss: 0.61268871, Gradient norm: 0.06048321
INFO:root:At the start of the epoch: mem (CPU python)=51631.05078125MB; mem (CPU total)=51660.4609375MB
INFO:root:[   89] Training loss: 0.62097076, Validation loss: 0.61154538, Gradient norm: 0.05391463
INFO:root:At the start of the epoch: mem (CPU python)=51669.14453125MB; mem (CPU total)=51698.59765625MB
INFO:root:[   90] Training loss: 0.62089338, Validation loss: 0.61240696, Gradient norm: 0.05282869
INFO:root:At the start of the epoch: mem (CPU python)=51669.54296875MB; mem (CPU total)=51661.5703125MB
INFO:root:[   91] Training loss: 0.62072588, Validation loss: 0.61185353, Gradient norm: 0.06229828
INFO:root:At the start of the epoch: mem (CPU python)=51669.54296875MB; mem (CPU total)=51650.0234375MB
INFO:root:[   92] Training loss: 0.62035081, Validation loss: 0.61097176, Gradient norm: 0.05006845
INFO:root:At the start of the epoch: mem (CPU python)=51708.4296875MB; mem (CPU total)=51738.3828125MB
INFO:root:[   93] Training loss: 0.62015138, Validation loss: 0.61149381, Gradient norm: 0.05588659
INFO:root:At the start of the epoch: mem (CPU python)=51796.52734375MB; mem (CPU total)=51826.49609375MB
INFO:root:[   94] Training loss: 0.62014411, Validation loss: 0.61129687, Gradient norm: 0.05765137
INFO:root:At the start of the epoch: mem (CPU python)=51809.625MB; mem (CPU total)=51839.00390625MB
INFO:root:[   95] Training loss: 0.61974666, Validation loss: 0.61029988, Gradient norm: 0.06187505
INFO:root:At the start of the epoch: mem (CPU python)=51847.71875MB; mem (CPU total)=51877.21875MB
INFO:root:[   96] Training loss: 0.61947421, Validation loss: 0.61203194, Gradient norm: 0.05586550
INFO:root:At the start of the epoch: mem (CPU python)=51910.8125MB; mem (CPU total)=51940.5625MB
INFO:root:[   97] Training loss: 0.61941135, Validation loss: 0.61100991, Gradient norm: 0.05436067
INFO:root:At the start of the epoch: mem (CPU python)=51948.90625MB; mem (CPU total)=51978.70703125MB
INFO:root:[   98] Training loss: 0.61928197, Validation loss: 0.61103232, Gradient norm: 0.05658292
INFO:root:At the start of the epoch: mem (CPU python)=51949.48046875MB; mem (CPU total)=51966.66796875MB
INFO:root:[   99] Training loss: 0.61897433, Validation loss: 0.61021750, Gradient norm: 0.05949083
INFO:root:At the start of the epoch: mem (CPU python)=52000.09765625MB; mem (CPU total)=52030.30078125MB
INFO:root:[  100] Training loss: 0.61881169, Validation loss: 0.61095194, Gradient norm: 0.05807148
INFO:root:At the start of the epoch: mem (CPU python)=52038.19140625MB; mem (CPU total)=52068.4296875MB
INFO:root:[  101] Training loss: 0.61866604, Validation loss: 0.61004640, Gradient norm: 0.06060785
INFO:root:At the start of the epoch: mem (CPU python)=52049.0234375MB; mem (CPU total)=52056.41015625MB
INFO:root:[  102] Training loss: 0.61826138, Validation loss: 0.60921248, Gradient norm: 0.05310868
INFO:root:At the start of the epoch: mem (CPU python)=52089.38671875MB; mem (CPU total)=52119.265625MB
INFO:root:[  103] Training loss: 0.61846302, Validation loss: 0.61004673, Gradient norm: 0.06547499
INFO:root:At the start of the epoch: mem (CPU python)=52127.48046875MB; mem (CPU total)=52157.39453125MB
INFO:root:[  104] Training loss: 0.61805101, Validation loss: 0.60952613, Gradient norm: 0.05593612
INFO:root:At the start of the epoch: mem (CPU python)=52127.9375MB; mem (CPU total)=52145.6015625MB
INFO:root:[  105] Training loss: 0.61792488, Validation loss: 0.60990893, Gradient norm: 0.05913615
INFO:root:At the start of the epoch: mem (CPU python)=52178.671875MB; mem (CPU total)=52209.08984375MB
INFO:root:[  106] Training loss: 0.61776968, Validation loss: 0.60863482, Gradient norm: 0.06045539
INFO:root:At the start of the epoch: mem (CPU python)=52213.8125MB; mem (CPU total)=52222.28125MB
INFO:root:[  107] Training loss: 0.61761121, Validation loss: 0.61003682, Gradient norm: 0.05929282
INFO:root:At the start of the epoch: mem (CPU python)=52254.859375MB; mem (CPU total)=52285.6875MB
INFO:root:[  108] Training loss: 0.61774449, Validation loss: 0.60836176, Gradient norm: 0.06698755
INFO:root:At the start of the epoch: mem (CPU python)=52342.95703125MB; mem (CPU total)=52373.80078125MB
INFO:root:[  109] Training loss: 0.61724828, Validation loss: 0.61082764, Gradient norm: 0.06008277
INFO:root:At the start of the epoch: mem (CPU python)=52356.05078125MB; mem (CPU total)=52386.9296875MB
INFO:root:[  110] Training loss: 0.61701321, Validation loss: 0.60990523, Gradient norm: 0.05701073
INFO:root:At the start of the epoch: mem (CPU python)=52369.1484375MB; mem (CPU total)=52399.875MB
INFO:root:[  111] Training loss: 0.61689951, Validation loss: 0.60891909, Gradient norm: 0.05932766
INFO:root:At the start of the epoch: mem (CPU python)=52457.24609375MB; mem (CPU total)=52487.69921875MB
INFO:root:[  112] Training loss: 0.61685159, Validation loss: 0.60875882, Gradient norm: 0.05733702
INFO:root:At the start of the epoch: mem (CPU python)=52457.625MB; mem (CPU total)=52475.375MB
INFO:root:[  113] Training loss: 0.61661049, Validation loss: 0.60901798, Gradient norm: 0.06195142
INFO:root:At the start of the epoch: mem (CPU python)=52483.4375MB; mem (CPU total)=52513.51953125MB
INFO:root:[  114] Training loss: 0.61656506, Validation loss: 0.60743058, Gradient norm: 0.05735684
INFO:root:At the start of the epoch: mem (CPU python)=52546.53125MB; mem (CPU total)=52576.86328125MB
INFO:root:[  115] Training loss: 0.61615805, Validation loss: 0.60760189, Gradient norm: 0.05747596
INFO:root:At the start of the epoch: mem (CPU python)=52609.62890625MB; mem (CPU total)=52639.98828125MB
INFO:root:[  116] Training loss: 0.61611825, Validation loss: 0.60882194, Gradient norm: 0.05153305
INFO:root:At the start of the epoch: mem (CPU python)=52647.7265625MB; mem (CPU total)=52678.12109375MB
INFO:root:[  117] Training loss: 0.61596833, Validation loss: 0.60778448, Gradient norm: 0.05894250
INFO:root:At the start of the epoch: mem (CPU python)=52685.8203125MB; mem (CPU total)=52716.5078125MB
INFO:root:[  118] Training loss: 0.61581477, Validation loss: 0.60790068, Gradient norm: 0.05639764
INFO:root:At the start of the epoch: mem (CPU python)=52686.234375MB; mem (CPU total)=52704.69921875MB
INFO:root:[  119] Training loss: 0.61577648, Validation loss: 0.60725907, Gradient norm: 0.06897643
INFO:root:At the start of the epoch: mem (CPU python)=52836.765625MB; mem (CPU total)=52817.97265625MB
INFO:root:[  120] Training loss: 0.61567635, Validation loss: 0.60747896, Gradient norm: 0.06053552
INFO:root:At the start of the epoch: mem (CPU python)=52836.765625MB; mem (CPU total)=52831.15234375MB
INFO:root:[  121] Training loss: 0.61567521, Validation loss: 0.60788391, Gradient norm: 0.06355258
INFO:root:At the start of the epoch: mem (CPU python)=52863.203125MB; mem (CPU total)=52894.25MB
INFO:root:[  122] Training loss: 0.61538866, Validation loss: 0.60943677, Gradient norm: 0.05795106
INFO:root:At the start of the epoch: mem (CPU python)=52926.296875MB; mem (CPU total)=52957.40234375MB
INFO:root:[  123] Training loss: 0.61507329, Validation loss: 0.60739022, Gradient norm: 0.06773489
INFO:root:At the start of the epoch: mem (CPU python)=52964.390625MB; mem (CPU total)=52995.453125MB
INFO:root:[  124] Training loss: 0.61511672, Validation loss: 0.60680208, Gradient norm: 0.05689547
INFO:root:At the start of the epoch: mem (CPU python)=52964.84375MB; mem (CPU total)=52958.45703125MB
INFO:root:[  125] Training loss: 0.61452878, Validation loss: 0.60717911, Gradient norm: 0.05669398
INFO:root:At the start of the epoch: mem (CPU python)=52965.58203125MB; mem (CPU total)=52996.39453125MB
INFO:root:[  126] Training loss: 0.61451561, Validation loss: 0.60826692, Gradient norm: 0.05492984
INFO:root:At the start of the epoch: mem (CPU python)=53028.6796875MB; mem (CPU total)=53060.38671875MB
INFO:root:[  127] Training loss: 0.61450490, Validation loss: 0.60807474, Gradient norm: 0.05518663
INFO:root:At the start of the epoch: mem (CPU python)=53091.7734375MB; mem (CPU total)=53123.32421875MB
INFO:root:[  128] Training loss: 0.61448528, Validation loss: 0.60683451, Gradient norm: 0.06665911
INFO:root:At the start of the epoch: mem (CPU python)=53154.87109375MB; mem (CPU total)=53186.6015625MB
INFO:root:[  129] Training loss: 0.61414944, Validation loss: 0.60797887, Gradient norm: 0.06162787
INFO:root:At the start of the epoch: mem (CPU python)=53155.09375MB; mem (CPU total)=53025.578125MB
INFO:root:[  130] Training loss: 0.61409265, Validation loss: 0.60728557, Gradient norm: 0.05727310
INFO:root:At the start of the epoch: mem (CPU python)=53155.09375MB; mem (CPU total)=53162.84375MB
INFO:root:Learning rate reduced to: 0.0005
INFO:root:[  131] Training loss: 0.61403587, Validation loss: 0.60704819, Gradient norm: 0.06002648
INFO:root:At the start of the epoch: mem (CPU python)=53194.15234375MB; mem (CPU total)=53225.6640625MB
INFO:root:Learning rate reduced to: 0.00025
INFO:root:[  132] Training loss: 0.61273197, Validation loss: 0.60540572, Gradient norm: 0.05436000
INFO:root:At the start of the epoch: mem (CPU python)=53232.25MB; mem (CPU total)=53263.78515625MB
INFO:root:[  133] Training loss: 0.61243873, Validation loss: 0.60600924, Gradient norm: 0.04825557
INFO:root:At the start of the epoch: mem (CPU python)=53270.34375MB; mem (CPU total)=53302.20703125MB
INFO:root:[  134] Training loss: 0.61221512, Validation loss: 0.60553593, Gradient norm: 0.04942832
INFO:root:At the start of the epoch: mem (CPU python)=53358.4375MB; mem (CPU total)=53390.20703125MB
INFO:root:[  135] Training loss: 0.61228948, Validation loss: 0.60575317, Gradient norm: 0.05158912
INFO:root:At the start of the epoch: mem (CPU python)=53371.5390625MB; mem (CPU total)=53403.40625MB
INFO:root:[  136] Training loss: 0.61214543, Validation loss: 0.60533816, Gradient norm: 0.05432624
INFO:root:At the start of the epoch: mem (CPU python)=53384.6328125MB; mem (CPU total)=53416.42578125MB
INFO:root:[  137] Training loss: 0.61179824, Validation loss: 0.60563833, Gradient norm: 0.05112032
INFO:root:At the start of the epoch: mem (CPU python)=53422.7265625MB; mem (CPU total)=53454.3359375MB
INFO:root:[  138] Training loss: 0.61201214, Validation loss: 0.60514809, Gradient norm: 0.04945400
INFO:root:At the start of the epoch: mem (CPU python)=53460.82421875MB; mem (CPU total)=53492.49609375MB
INFO:root:[  139] Training loss: 0.61185413, Validation loss: 0.60579567, Gradient norm: 0.04781183
INFO:root:At the start of the epoch: mem (CPU python)=53498.91796875MB; mem (CPU total)=53530.87890625MB
INFO:root:[  140] Training loss: 0.61188708, Validation loss: 0.60527536, Gradient norm: 0.05225514
INFO:root:At the start of the epoch: mem (CPU python)=53562.01171875MB; mem (CPU total)=53594.63671875MB
INFO:root:[  141] Training loss: 0.61184473, Validation loss: 0.60522265, Gradient norm: 0.04908105
INFO:root:At the start of the epoch: mem (CPU python)=53600.10546875MB; mem (CPU total)=53632.62890625MB
INFO:root:[  142] Training loss: 0.61176746, Validation loss: 0.60560546, Gradient norm: 0.05027836
INFO:root:At the start of the epoch: mem (CPU python)=53638.203125MB; mem (CPU total)=53670.76171875MB
INFO:root:[  143] Training loss: 0.61150614, Validation loss: 0.60595291, Gradient norm: 0.05232842
INFO:root:At the start of the epoch: mem (CPU python)=53676.30078125MB; mem (CPU total)=53708.90625MB
INFO:root:[  144] Training loss: 0.61169961, Validation loss: 0.60559540, Gradient norm: 0.05002842
INFO:root:At the start of the epoch: mem (CPU python)=53689.39453125MB; mem (CPU total)=53721.703125MB
INFO:root:Learning rate reduced to: 0.000125
INFO:root:[  145] Training loss: 0.61154738, Validation loss: 0.60608583, Gradient norm: 0.05312059
INFO:root:At the start of the epoch: mem (CPU python)=53751.265625MB; mem (CPU total)=53760.33984375MB
INFO:root:Learning rate reduced to: 6.25e-05
INFO:root:[  146] Training loss: 0.61127200, Validation loss: 0.60547141, Gradient norm: 0.04787122
INFO:root:At the start of the epoch: mem (CPU python)=53790.5859375MB; mem (CPU total)=53823.8203125MB
INFO:root:[  147] Training loss: 0.61122286, Validation loss: 0.60542670, Gradient norm: 0.04761630
INFO:root:At the start of the epoch: mem (CPU python)=53828.6796875MB; mem (CPU total)=53861.96484375MB
INFO:root:[  148] Training loss: 0.61113981, Validation loss: 0.60508269, Gradient norm: 0.04652079
INFO:root:At the start of the epoch: mem (CPU python)=53866.7734375MB; mem (CPU total)=53899.8515625MB
INFO:root:[  149] Training loss: 0.61123446, Validation loss: 0.60584816, Gradient norm: 0.04701135
INFO:root:At the start of the epoch: mem (CPU python)=53879.87109375MB; mem (CPU total)=53912.92578125MB
INFO:root:[  150] Training loss: 0.61110848, Validation loss: 0.60514201, Gradient norm: 0.04558829
INFO:root:At the start of the epoch: mem (CPU python)=53942.96484375MB; mem (CPU total)=53976.140625MB
INFO:root:[  151] Training loss: 0.61106697, Validation loss: 0.60545259, Gradient norm: 0.04842707
INFO:root:At the start of the epoch: mem (CPU python)=53943.2421875MB; mem (CPU total)=53939.05078125MB
INFO:root:[  152] Training loss: 0.61116146, Validation loss: 0.60480035, Gradient norm: 0.04655875
INFO:root:At the start of the epoch: mem (CPU python)=54066.7265625MB; mem (CPU total)=54077.7734375MB
INFO:root:[  153] Training loss: 0.61105819, Validation loss: 0.60456568, Gradient norm: 0.04632798
INFO:root:At the start of the epoch: mem (CPU python)=54082.25390625MB; mem (CPU total)=54115.91796875MB
INFO:root:[  154] Training loss: 0.61106315, Validation loss: 0.60557766, Gradient norm: 0.04734745
INFO:root:At the start of the epoch: mem (CPU python)=54082.53515625MB; mem (CPU total)=54104.10546875MB
INFO:root:[  155] Training loss: 0.61116355, Validation loss: 0.60468422, Gradient norm: 0.04752541
INFO:root:At the start of the epoch: mem (CPU python)=54108.4453125MB; mem (CPU total)=54142.203125MB
INFO:root:[  156] Training loss: 0.61112238, Validation loss: 0.60502270, Gradient norm: 0.04647194
INFO:root:At the start of the epoch: mem (CPU python)=54121.5390625MB; mem (CPU total)=54154.96484375MB
INFO:root:[  157] Training loss: 0.61103544, Validation loss: 0.60491574, Gradient norm: 0.04800984
INFO:root:At the start of the epoch: mem (CPU python)=54234.6328125MB; mem (CPU total)=54239.34375MB
INFO:root:[  158] Training loss: 0.61096449, Validation loss: 0.60497717, Gradient norm: 0.04908444
INFO:root:At the start of the epoch: mem (CPU python)=54296.76953125MB; mem (CPU total)=54277.00390625MB
INFO:root:[  159] Training loss: 0.61094129, Validation loss: 0.60511854, Gradient norm: 0.04768609
INFO:root:At the start of the epoch: mem (CPU python)=54296.76953125MB; mem (CPU total)=54290.63671875MB
INFO:root:[  160] Training loss: 0.61084940, Validation loss: 0.60477442, Gradient norm: 0.04947813
INFO:root:At the start of the epoch: mem (CPU python)=54323.91796875MB; mem (CPU total)=54328.28515625MB
INFO:root:[  161] Training loss: 0.61105970, Validation loss: 0.60466880, Gradient norm: 0.04773688
INFO:root:At the start of the epoch: mem (CPU python)=54324.5234375MB; mem (CPU total)=54318.6015625MB
INFO:root:[  162] Training loss: 0.61086613, Validation loss: 0.60410375, Gradient norm: 0.04825046
INFO:root:At the start of the epoch: mem (CPU python)=54350.11328125MB; mem (CPU total)=54356.640625MB
INFO:root:[  163] Training loss: 0.61084956, Validation loss: 0.60542196, Gradient norm: 0.04833844
INFO:root:At the start of the epoch: mem (CPU python)=54388.20703125MB; mem (CPU total)=54397.65625MB
INFO:root:[  164] Training loss: 0.61075215, Validation loss: 0.60470601, Gradient norm: 0.04673319
INFO:root:At the start of the epoch: mem (CPU python)=54501.30078125MB; mem (CPU total)=54511.625MB
INFO:root:[  165] Training loss: 0.61099910, Validation loss: 0.60565453, Gradient norm: 0.04855457
INFO:root:At the start of the epoch: mem (CPU python)=54539.39453125MB; mem (CPU total)=54549.73828125MB
INFO:root:[  166] Training loss: 0.61097301, Validation loss: 0.60454791, Gradient norm: 0.04970577
INFO:root:At the start of the epoch: mem (CPU python)=54552.3828125MB; mem (CPU total)=54512.85546875MB
INFO:root:[  167] Training loss: 0.61099798, Validation loss: 0.60512133, Gradient norm: 0.04806058
INFO:root:At the start of the epoch: mem (CPU python)=54640.1328125MB; mem (CPU total)=54551.984375MB
INFO:root:[  168] Training loss: 0.61060179, Validation loss: 0.60452690, Gradient norm: 0.04744686
INFO:root:At the start of the epoch: mem (CPU python)=54640.1328125MB; mem (CPU total)=54614.296875MB
INFO:root:[  169] Training loss: 0.61105599, Validation loss: 0.60491003, Gradient norm: 0.05071918
INFO:root:At the start of the epoch: mem (CPU python)=54641.78125MB; mem (CPU total)=54652.68359375MB
INFO:root:[  170] Training loss: 0.61101052, Validation loss: 0.60496714, Gradient norm: 0.04753805
INFO:root:At the start of the epoch: mem (CPU python)=54704.875MB; mem (CPU total)=54716.15234375MB
INFO:root:[  171] Training loss: 0.61071892, Validation loss: 0.60500171, Gradient norm: 0.04843517
INFO:root:At the start of the epoch: mem (CPU python)=54742.96875MB; mem (CPU total)=54754.29296875MB
INFO:root:EP 171: Early stopping
INFO:root:After finishing all epochs: mem (CPU python)=54756.06640625MB; mem (CPU total)=54767.78125MB
INFO:root:Training the model took 17509.739s.
INFO:root:Emptying the cuda cache took 0.03s.
INFO:root:Starting evaluation: model FNO & uncertainty quantification scoring-rule-reparam
INFO:root:Evaluating the model on Train data.
INFO:root:MSETrain: 0.83929
INFO:root:EnergyScoreTrain: 0.59093
INFO:root:CRPSTrain: 0.4564
INFO:root:Gaussian NLLTrain: 1.16896
INFO:root:CoverageTrain: 0.95453
INFO:root:IntervalWidthTrain: 3.25718
INFO:root:Evaluating the model on Validation data.
INFO:root:MSEValidation: 0.85919
INFO:root:EnergyScoreValidation: 0.60479
INFO:root:CRPSValidation: 0.46815
INFO:root:Gaussian NLLValidation: 1.19505
INFO:root:CoverageValidation: 0.94856
INFO:root:IntervalWidthValidation: 3.2614
INFO:root:Evaluating the model on Test data.
INFO:root:MSETest: 0.86076
INFO:root:EnergyScoreTest: 0.60587
INFO:root:CRPSTest: 0.46927
INFO:root:Gaussian NLLTest: 1.19755
INFO:root:CoverageTest: 0.94826
INFO:root:IntervalWidthTest: 3.26522
INFO:root:After validation: mem (CPU python)=54764.93359375MB; mem (CPU total)=54717.3359375MB
