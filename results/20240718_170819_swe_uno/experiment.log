INFO:root:Starting the logger.
INFO:root:Using cuda.
INFO:root:############### Starting experiment with config file swe/uno.ini ###############
INFO:root:###1 out of 1 data set parameter combinations ###
INFO:root:Data parameters: {'dataset_name': 'SWE', 'max_training_set_size': 1000, 'downscaling_factor': 1, 'temporal_downscaling': 4, 'init_steps': 10, 't_start': 0, 'pred_horizon': 10}
INFO:root:###1 out of 21 training parameter combinations ###
INFO:root:Training parameters: {'model': 'UNO', 'uncertainty_quantification': 'scoring-rule-dropout', 'batch_size': 32, 'n_epochs': 1000, 'early_stopping': 10, 'init': 'default', 'learning_rate': 0.0001, 'lr_schedule': 'no', 'optimizer': 'adam', 'gradient_clipping': 1, 'layer_normalization': True, 'data_loader_pin_memory': False, 'data_loader_num_workers': 0, 'distributed_training': False, 'alpha': 0.05, 'n_samples_uq': 10, 'weight_decay': 0, 'dropout': 0.01, 'fourier_dropout': None, 'hidden_channels': 8, 'projection_channels': 32, 'lifting_channels': 16, 'n_samples': 3, 'uno_out_channels': [16, 32, 64, 128, 64, 32, 16], 'uno_scalings': [[1.0, 0.75, 0.75], [1.0, 0.67, 0.67], [1.0, 0.5, 0.5], [1.0, 1.0, 1.0], [1.0, 2.0, 2.0], [1.0, 1.5, 1.5], [1.0, 1.33, 1.33]], 'uno_n_modes': [[4, 20, 20], [4, 14, 14], [4, 6, 6], [7, 6, 6], [7, 6, 6], [10, 14, 14], [10, 20, 20]]}
INFO:root:NumberParameters: 14532089
INFO:root:Memory allocated: 75497472
INFO:root:Training starts now.
INFO:root:[    1] Training loss: 1.07727763, Validation loss: 0.22763180, Gradient norm: 12.06598370
INFO:root:[    2] Training loss: 0.17289003, Validation loss: 0.15293612, Gradient norm: 4.14841245
INFO:root:[    3] Training loss: 0.14599712, Validation loss: 0.13868114, Gradient norm: 1.44767102
INFO:root:[    4] Training loss: 0.13446560, Validation loss: 0.13006646, Gradient norm: 1.46565225
INFO:root:[    5] Training loss: 0.12806214, Validation loss: 0.12493977, Gradient norm: 1.80949598
INFO:root:[    6] Training loss: 0.12525330, Validation loss: 0.12909602, Gradient norm: 2.23263940
INFO:root:[    7] Training loss: 0.12394844, Validation loss: 0.12580803, Gradient norm: 3.47306625
INFO:root:[    8] Training loss: 0.11650761, Validation loss: 0.11710941, Gradient norm: 1.87507015
INFO:root:[    9] Training loss: 0.11666443, Validation loss: 0.12914342, Gradient norm: 2.22966881
INFO:root:[   10] Training loss: 0.11935736, Validation loss: 0.12433595, Gradient norm: 3.96686032
INFO:root:[   11] Training loss: 0.11210085, Validation loss: 0.10833765, Gradient norm: 2.78910206
INFO:root:[   12] Training loss: 0.10900375, Validation loss: 0.11700157, Gradient norm: 2.55625479
INFO:root:[   13] Training loss: 0.11147911, Validation loss: 0.11245042, Gradient norm: 3.47472753
