[META]
results_path = results/
data_path = data/
experiment_name = ks_test

[TRAININGPARAMETERS]
model = 'FNO'
uncertainty_quantification = 'scoring-rule-reparam' #['scoring-rule-dropout', 'scoring-rule-reparam', 'laplace', 'dropout']  # 'laplace', 'dropout', 'scoring-rule-dropout', 'scoring-rule-reparam'
batch_size =  [64]
n_epochs = 1000
early_stopping = 10
init = 'default' # he, xavier, default
learning_rate = 0.0005
lr_schedule = 'no' # 'no', 'step'
optimizer = 'adam'
gradient_clipping = 1
layer_normalization = True
data_loader_pin_memory = False 
data_loader_num_workers = [0]
distributed_training = False
alpha = 0.05
n_samples_uq = 100
weight_decay = 0
### Model Parameters
dropout = 0.05
fourier_dropout = None
hidden_channels = 20
projection_channels = 128
lifting_channels = 128
n_modes = (10, 12) 
### PFNO
n_samples = [5,10,50]

[DATAPARAMETERS]
dataset_name = ['KS']
max_training_set_size = 10000
downscaling_factor = 1  # int
temporal_downscaling = 2
init_steps = 20 # Initial steps
t_start = 0 # Where to start input
pred_horizon = 20 # Prediction horizon across time domain
